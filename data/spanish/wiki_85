<doc id="21387" url="https://es.wikipedia.org/wiki?curid=21387" title="Harry S. Truman">
Harry S. Truman

Harry S. Truman (Lamar, Estados Unidos, 8 de mayo de 1884-Kansas City, Estados Unidos, 26 de diciembre de 1972) fue el presidente de los Estados Unidos desde 1945 hasta 1953. Previamente, fue el vicepresidente durante el breve cuarto mandato de Franklin Delano Roosevelt entre enero y abril de 1945 y llegó a la presidencia el 12 de abril de ese año, debido al fallecimiento de Roosevelt.

Durante la Primera Guerra Mundial, Truman fue oficial de artillería, convirtiéndose en el único presidente del país que combatió en esa guerra (su sucesor, Eisenhower, entrenó equipos de artilleros en Pensilvania). Después de que la guerra se convirtiese en parte de la maquinaria política del jefe policial Tom Pendergast y fuese elegido comisionado del condado en Missouri, se convirtió en senador demócrata de los Estados Unidos. Después de ganar fama a nivel nacional como Jefe de la Comisión Truman, sustituyó al vicepresidente Henry A. Wallace como compañero de fórmula de Roosevelt en las elecciones de 1944.

Como presidente, Truman se enfrentó a complicados asuntos internos. La reconversión desordenada de posguerra de la economía de los Estados Unidos estuvo marcada por una grave escasez, numerosas huelgas, y la aprobación de la Ley de Trabajo y Mantenimiento contra los sindicatos por el Congreso y por encima del veto presidencial. Contra todo pronóstico ganó las elecciones de 1948, ayudado por su famoso Whistle Stop Tour. Después de su elección, solo fue capaz de sacar adelante una de las propuestas de su programa llamado Fair Deal. Usó las órdenes ejecutivas para iniciar la desmovilización de las fuerzas armadas y creó «controles de lealtad», despidiendo a miles de simpatizantes comunistas de sus cargos. Su firme oposición a los juramentos de lealtad obligatoria para los empleados gubernamentales, le costó acusaciones de que su gobierno estaba siendo «blando» con el comunismo. La presidencia de Truman estuvo llena de acontecimientos internacionales, como el fin de la Segunda Guerra Mundial y su decisión de usar armas nucleares contra Japón —en los que murieron más de 220 000 personas—, la fundación de las Naciones Unidas, el Plan Marshall para reconstruir Europa, la Doctrina Truman para contener el comunismo, el comienzo de la Guerra Fría, el puente aéreo de Berlín, la creación de la Organización del Tratado del Atlántico Norte (OTAN), la Guerra Civil China y la Guerra de Corea. La corrupción en la administración Truman, vinculada a ciertos miembros del gabinete y altos funcionarios de la Casa Blanca, fue un tema central en las elecciones presidenciales de 1952 y provocó que Adlai Stevenson, el candidato presidencial demócrata en las elecciones de 1952, perdiese ante el republicano Dwight D. Eisenhower.

Truman, cuya actitud era distinta a la de Roosevelt, fue un presidente tranquilo, sin pretensiones. Popularizó frases como "The buck stops here" («Yo soy el responsable») y "If you can't stand the heat, you better get out of the kitchen" («Si no puedes soportar el calor, es mejor salir de la cocina»). Superó las bajas expectativas de muchos observadores políticos, que lo comparaban desfavorablemente con su muy respetado predecesor. En distintos momentos de su presidencia, Truman tuvo el nivel más bajo de aprobación pública registrada hasta 1991. A pesar de la opinión negativa de los ciudadanos durante su mandato, las evaluaciones posteriores y académicas de su presidencia llegaron a ser positivas después de su retiro de la política, y la publicación de sus memorias. La inesperada victoria de Truman en 1948 es a menudo invocada por los candidatos presidenciales con menores posibilidades.

Harry S. Truman nació el 8 de mayo de 1884 en Lamar, Misuri, y era el hijo mayor de John Anderson Truman (1851-1914) y Martha Ellen Young Truman (1852-1947). Sus padres eligieron el nombre de Harry por el nombre del hermano de su madre, Harrison Young (1846-1916), el tío de Harry. Sus padres eligieron "S" como su "segundo nombre", en un intento de complacer a los dos abuelos de Harry, Anderson Shipp Truman y Solomon Young. La S en realidad no significaba nada, una práctica común entre los escoceses-irlandeses.

La inicial de Truman provocó un desliz inusual cuando por primera vez llegó a la presidencia y tomó el juramento presidencial. En una reunión en la Sala del Gabinete, el Juez presidente Harlan Stone comenzó a leer el juramento diciendo: «Yo, Harry Shipp Truman...,» y Truman respondió: «Yo, Harry S Truman...,»

Algunas fuentes emplean el segundo nombre Swinomish, basándose en una anécdota ocurrida en Seattle en noviembre de 1955, cuando Martin J. Sampson, jefe de los indígenas swinomish, le concedió el nombre de su tribu para reemplazar la S inicial, regalo que Truman aceptó de buena gana.

En su autobiografía, Truman declaró: ""Yo tengo el nombre por... Harrison Young. Me dieron el diminutivo de Harry, por lo que podría haber dos iniciales de mi nombre, y se añadió la letra S. Mi abuelo se llamaba Anderson Shippe Truman"". Alguna vez bromeaba diciendo que la S era un nombre, pero en su biblioteca se muestra que la S era una inicial y no un nombre. La Biblioteca y Museo Presidencial de Harry S. Truman tiene numerosos ejemplos de la firma por escrito en varias ocasiones durante toda la vida de Truman. Sin embargo, el uso de su inicial no es universal. Antes de 2008, su biografía oficial de Casa Blanca no la tenía. Todos los listados oficiales de la Armada de los Estados Unidos llevan la inicial, como en el "USS Harry S. Truman (CVN-75)".

John Truman, el padre de Harry, era un agricultor y vendedor de ganado. La familia vivió en Lamar hasta que Harry tuvo diez meses. Luego se trasladaron a una granja cerca de Harrisonville, luego a Belton, y en 1887 a la granja de sus abuelos en Grandview. Cuando Truman tenía seis años, sus padres trasladaron a la familia a Independence, para que pudiera asistir a la Iglesia Presbiteriana de la Escuela Dominical. Truman no asistió a la primaria hasta que tuvo los ocho años.

Cuando era niño, Truman tenía tres intereses principales: la música, la lectura y la historia, todos incitados por su madre. Mantuvo una estrecha relación con su madre durante el tiempo que esta vivió, y como presidente siguió consultándole, incluso pidiéndole algunos consejos políticos. Se levantaba a las cinco todas las mañanas para practicar piano, y tuvo un profesor de música dos veces a la semana hasta que tuvo quince años. Truman también leyó mucho de la historia popular. Estuvo en la Convención Nacional Demócrata de 1900 en Kansas City.

Después de graduarse en la Escuela Secundaria de Independence en 1901, Truman trabajó como cronometrador en la estación de ferrocarril de Santa Fe, durmiendo en "campos de vagabundos", cerca de las líneas de ferrocarril; posteriormente, trabajó en una serie de empleos locales. Trabajó brevemente en la sala de correo de Kansas City. Truman decidió no unirse a la Unión Internacional de Tipógrafos. Regresó a la granja de Grandview en 1906 y permaneció allí hasta 1917, cuando entró en el servicio militar.

El trabajo físicamente exigente que se le puso en la granja de Grandview fue una experiencia formativa. Durante este período, cortejó a Bess Wallace y hasta le propuso matrimonio en 1911. Ella lo rechazó, y Truman dijo que quería hacer más dinero que un agricultor antes de proponerle de nuevo el matrimonio.

Truman se alistó en el Guardia Nacional de Misuri en 1905, y estuvo en ella hasta 1911. En su examen físico de 1905, su vista había obtenido un 20/50 inaceptable en el ojo derecho y un 20/40 en el izquierdo. Según las informaciones, entró memorizando en secreto la tabla de los ojos.

Con el inicio de la participación estadounidense en la Primera Guerra Mundial, Truman se reincorporó en la Guardia. Antes de ir a Francia, fue enviado al campo Doniphan, cerca de Lawton, Oklahoma para el entrenamiento. Estuvo en la cantina del campamento con Edward Jacobson, quien tenía experiencia como empleado en una tienda de ropa de Kansas City. En el Ft. Still también se reunió con el teniente James M. Pendergast, el sobrino de Tom Pendergast, un político de Kansas City. Los dos hombres iban a tener una profunda influencia en la vida posterior de Truman.

Truman fue elegido para ser oficial, y después para ser comandante de batería de un regimiento de artillería en Francia. Su unidad fue la batería D, 129.º campaña de artillería y la 60º brigada, 35.ª División de Infantería, conocida por sus problemas de disciplina. Durante un ataque repentino por los alemanes en la cordillera de los Vosgos, la batería comenzó a dispersarse, Truman ordenó su posición mediante blasfemias que había "aprendido mientras trabajaba en el ferrocarril de Santa Fe". Impresionados por el estallido, sus hombres se reagruparon y lo siguieron con seguridad. Bajo el mando del Capitán Truman en Francia, la batería no perdió un solo hombre. Su batería también prestó apoyo a los tanques de la brigada de George Patton durante la ofensiva de Meuse-Argonne. El 11 de noviembre de 1918 su unidad de artillería disparó algunos de los últimos disparos de la Primera Guerra Mundial en posiciones alemanas tras el armisticio que se firmó a las 5 de la mañana, pero antes de que el alto el fuego entrase en vigor pasaron seis horas. En una carta lamentando el final de la guerra, escribió: ""Es una lástima que no podamos entrar y devastar Alemania y cortarle las manos a los niños alemanes y los pies y la cabellera a los ancianos"". La guerra fue una experiencia transformadora que llevó a las cualidades del liderazgo de Truman; que más tarde fue ascendido al rango de coronel en la Reserva del Ejército, y su historial de guerra hizo posible su posterior carrera política en Misuri.

Al final de la guerra, Truman volvió a Independence como capitán y se casó con su antiguo amor, Bess Wallace, el 28 de junio de 1919, el mismo día que se firmó el Tratado de Versalles. La pareja tuvo una hija, Margaret Truman (1924-2008).

Truman fue el único presidente que no compitió después de 1897 por obtener un título universitario, ya que los problemas de visión le impidieron la entrada en West Point, que había sido su sueño desde la infancia, y las limitaciones financieras le impidieron obtener un título en otro lugar. Sin embargo, estudió durante dos años para un título de abogado en la Facultad de Derecho de la Universidad de Kansas City a principios de la década de 1920. Más adelante, a los 60 años, Truman fue invitado para unirse a la Fraternidad Nacional de Alpha Delta Gamma y a la Fraternidad Lambda Chi Alpha de Kansas City-Misuri, aceptó las invitaciones y se le reconoció como un miembro honorario de ambas organizaciones.

Un mes antes de que Truman se casase, Truman y Edward Jacobson, uno de sus compañeros durante su entrenamiento en Fort Still, abrieron una mercería del mismo nombre en Kansas City. Después de algunos años de éxito, la tienda fue a la bancarrota durante la recesión de 1921, que afectó en gran medida la economía agrícola. Truman culpó de la caída de los precios agrícolas a los republicanos; trabajó para pagar las deudas hasta 1934, justo cuando iba a ser miembro del Senado, sin embargo, el banquero William T. Kemper recuperó la nota durante la venta de un banco en bancarrota y permitió a Truman saldar sus deudas mediante un pago de 1000 dólares al banco. Al mismo tiempo Kemper hizo una donación de 1000 dólares a la campaña senatorial de Truman.

Los antiguos camaradas de armas y socios de negocios, Jacobson y Truman siguieron siendo amigos íntimos de por vida. Décadas más tarde, Jacobson aconsejó a Truman que reconociese a Israel como nación.

El 9 de febrero de 1909, Harry Truman fue incluido en la Masonería mediante el Rito Escocés Antiguo y Aceptado en la logia de Belton, Misuri. En 1911 ayudó a establecer la Logia de Grandview, y sirvió como su primer Maestro Venerable. En 1940, Harry Truman fue elegido como el 97.º Gran Maestre de los Masones de Misuri. En 1945, fue nombrado 33.º Soberano y Gran Inspector General y un miembro honorario del consejo supremo en Washington D.C.. En 1959, fue galardonado con el premio de los 50 años, el único presidente de los Estados Unidos en llegar a ese aniversario.

En 1922, con la ayuda de la clientela demócrata de Kansas City liderada por el jefe Tom Pendergast, Truman fue elegido como juez de la Corte del Condado del Distrito Este del Condado Jackson, un puesto administrativo, no judicial, similar a los comisionados del condado en otros lugares.

En 1922, Truman dio a un amigo 10 dólares para una cuota de iniciación en el Ku Klux Klan, pero más tarde pidió recuperar su dinero, ya que Truman nunca perteneció, nunca asistió a una reunión, y nunca pretendió ser miembro de la organización. Aunque Truman, a veces expresó ira hacia los judíos en sus diarios, su socio y amigo Edward Jacobson era judío. Las actitudes de Truman hacia los negros eran típicas de Missouri en su época, y se expresaron en su el uso ocasional de términos como "nigger", que era un término despectivo. Años más tarde, otra medida de sus actitudes raciales vendrían a la vanguardia: los relatos de los abusos, la violencia y la persecución sufrida por muchos veteranos afroamericanos en su regreso de la Segunda Guerra Mundial enfurecieron a Truman, y fueron un factor importante en su decisión de emitir la Orden Ejecutiva 9981, en julio de 1948, para respaldar las iniciativas de los derechos civiles y eliminar la segregación racial en las fuerzas armadas.

No fue reelegido en 1924, pero en 1926 fue elegido el presidente del tribunal de la corte, y fue elegido nuevamente como juez del Condado Jackson en 1930. En 1930, Truman coordinó el "Plan de los Diez Años", que transformó el Condado de Jackson y el horizonte de Kansas City con nuevos proyectos de obras públicas, incluyendo una extensa serie de caminos, un nuevo edificio de la Corte del Condado, y monumentos en honor a las mujeres pioneras.

En 1933, Truman fue nombrado director de Missouri para el programa Federal de Re-Empleo (parte de la Administración de Obras Civiles) a petición del Director General de Correos, James Farley, como pago a Pendergast para la entrega de la votación de Kansas City a Franklin D. Roosevelt en las elecciones presidenciales de 1932.

Después de servir como juez, Truman quería competir para gobernador o para el Congreso, pero Pendergast rechazó estas ideas. En 1934, los ayudantes de Pendergast sugirieron que Truman fuese el candidato a senador; después de que otros tres hombres rechazasen la idea, Pendergast, a regañadientes, respaldó la campaña senatorial de Truman para su candidatura en las elecciones de 1934 en Misuri. Durante las primarias, Truman derrotó a John J . Cochran y a Tuck Milligan. Luego Truman derrotó al titular republicano, Roscoe C. Patterson, en casi un 20% de los votos.

Truman asumió el cargo bajo el mote de "el senador de Pendergast." Dio las decisiones de patrocinio a Pendergast, pero siempre mantuvo que votó a su conciencia. Truman siempre defendió el patrocinio diciendo que al ofrecer un poco, salvaba un montón.

En su primer mandato como senador, Truman habló sin rodeos en contra de la avaricia corporativa, y advirtió sobre los peligros de los especuladores de Wall Street y que otros intereses adinerados particulares alcanzasen demasiada influencia en los asuntos nacionales. Fue, sin embargo, en gran parte ignorado por el presidente Roosevelt, que parecía no haberlo tomado en serio en esa etapa. Truman tenía también problemas en hacer que los oficiales de la Casa Blanca les devolviesen las llamadas.

La elección de 1936 respaldada por el candidato a gobernador-títere de Pendergast, Lloyd C. Stark, reveló irregularidades aún más grandes entre los votantes en Misuri, que habían sido descubiertas en 1934. Milligan procesó 278 acusados en casos de fraude electoral y condenó a 259. Stark se volvió hacia Pendergast, le hizo un juicio, y fue capaz de arrebatar el patrocinio federal de la maquinaria de Pendergast.

En los últimos momentos Milligan descubrió que Pendergast no había pagado los impuestos federales entre 1927 y 1937 y había llevado a cabo una estafa de seguros fraudulentas. En 1939, Pendergast se declaró culpable y recibió una multa de 10.000 dólares y una condena de 15 meses en la prisión federal de Leavenworth. No se formularon cargos en contra de Truman.

Las perspectivas de Truman para una reelección en el Senado parecían sombrías. En 1940, tanto Stark como Maurice Milligan lo desafiaron en las primarias demócratas para el Senado. Robert E. Hannegan, que controlaban la política demócrata de San Luis, dio su apoyo en las elecciones a Truman. Truman luchó sin descanso y competitivamente. Al final, Stark y Milligan dividieron el voto anti-Pendergast en las primarias demócratas y tuvieron más votos combinados que Truman.

En septiembre de 1940, durante la campaña electoral, Truman fue elegido Gran Maestro de la Gran Logia Masonería de Missouri. En noviembre de ese año, derrotó al senador estatal de Kansas City, Manvel H. Davis, por más de 40.000 votos y retuvo su cargo en el Senado. Truman dijo más tarde que la elección masónica aseguró su victoria en las elecciones generales sobre el Senador estatal, Manvel H. Davis.

Su exitosa campaña senatorial de 1940 es considerada por muchos biógrafos como un triunfo personal, junto con las elecciones de 1948, fue una elección en la que también estuvo subestimado. Fue el punto de inflexión de su carrera política.

Truman ganó fama y respeto cuando su comisión de preparación (popularmente conocida como la "Comisión Truman") investigó el escándalo de despilfarro militar mediante la exposición de fraude y de mala gestión. El gobierno de Roosevelt había temido inicialmente que la comisión fuese a hacer daño a la moral de la guerra, y el subsecretario de Guerra, Robert P. Patterson, escribió al presidente declarando que estaba "en el interés público", para suspender la comisión. Truman escribió una carta al presidente diciendo que la comisión estaba "al cien por cien detrás de la administración" y que no tenía ninguna intención de criticar la conducta militar estadounidense en la guerra. La comisión fue considerada un éxito por los investigadores e historiadores y se informó que había ahorrado al menos 15.000 millones de dólares y miles de vidas. El sentido común de ahorro de Truman para el ejército llamó mucho la atención. En 1943, su trabajo como presidente de la comisión le hizo ganar su primera aparición en la portada de la revista Time. También fue elegido hombre del año en la misma revista en 1945 y 1948. Después de años como una figura marginal en el Senado, Truman alcanzó el centro de atención nacional después del éxito de la Comisión Truman.

Tras meses de incertidumbre sobre la preferencia del presidente Roosevelt por un compañero de fórmula, Truman fue elegido como compañero de fórmula de Franklin D. Roosevelt para las elecciones de 1944 como resultado de un acuerdo elaborado por Hannegan, quien fue el presidente del Comité Nacional Demócrata de ese año.

A pesar de que su imagen pública seguía siendo la de un líder fuerte, la condición física de Roosevelt se deterioraba rápidamente a mediados de 1944. Un puñado clave de asesores del presidente, incluyendo el presidente saliente del Comité Nacional Demócrata, Frank C. Walker, el presidente entrante, Robert Hannegan, el tesorero del partido, Edwin W. Pauley, el estratega Ed Flynn y el lobbista George E. Allen, cerraron los Rankings en 1944 para "mantener a Henry A. Wallace fuera de juego". A su juicio, Wallace, el vicepresidente en ejercicio, era demasiado liberal, y había serias preocupaciones sobre la posibilidad de su ascensión a la presidencia. Allen más tarde recordaría que cada uno de estos hombres "se dio cuenta de que el hombre próximo compañero de fórmula de Roosevelt, con toda probabilidad sería el próximo presidente."

Después de reunirse personalmente con los líderes del partido, Roosevelt accedió a reemplazar a Wallace como vicepresidente, sin embargo, Roosevelt decidió dejar la selección final de un compañero de fórmula sin resolver, al menos hasta las últimas etapas de la Convención Nacional Demócrata en Chicago. James F. Byrnes de Carolina del Sur se vio favorecido al principio, pero los líderes sindicales se oponían a él. Roosevelt también se opuso a Byrnes, pero se mostró reacio a decepcionar a todos los candidatos y no quería decirle directamente a Byrnes que se oponía a él, por lo que el presidente le dijo a Hannegan que "quitase los obstáculos de la nominación de Byrnes con Sidney", que quería decir líder sindical y oponente de Byrnes, Sidney Hillman, unos días antes de la convención. Además, la actitud segregacionista de Byrnes le dio problemas con los liberales del Norte, y se le consideraba también vulnerables a causa de sus creencias católicas. Según los informes, Roosevelt ofreció el puesto de vicepresidente al gobernador Henry F. Schricker de Indiana, pero éste se negó. Antes de la convención comenzó, Roosevelt escribió una nota que decía que aceptaría a Truman o al juez de la Corte Suprema, William O. Douglas, pero la mayor parte de los líderes del partido de la zona preferían a Truman. El propio Truman no hizo campaña directa para la vicepresidencia, y siempre mantuvo que él no quería el puesto de vicepresidente. Como resultado, Roosevelt tuvo que poner mucha presión sobre Truman para que aceptase el puesto. El 19 de julio, los jefes del partido convocaron a Truman a una suite en el Hotel Blackstone para que escuchase una llamada telefónica que, desconocido para el senador, había ensayado previamente con el Presidente. Durante la conversación, Roosevelt preguntó a los jefes del partido si Truman aceptaría el puesto. Cuando dijo que no, Roosevelt acusó enojado de que Truman estaba perturbando la unidad del Partido Demócrata y luego colgó. Sintiendo que no tenía otra opción, Truman accedió a regañadientes a convertirse en el compañero de fórmula de Roosevelt para las elecciones de 1944.

La candidatura de Truman fue llamada humorísticamente el segundo "Compromiso de Misuri" durante la Convención Nacional Demócrata de 1944 en Chicago, como su llamamiento a la dirección del partido en contraste con el liberal Wallace y el conservador Byrnes. La candidatura fue bien recibida, y el equipo de Roosevelt–Truman pasó a una victoria con 432 contra 99 votos electorales del derrotado gobernador Thomas E. Dewey de Nueva York y del gobernador John Bricker de Ohio. Truman fue juramentado como vicepresidente el 20 de enero de 1945, y estuvo en el cargo menos de tres meses.

La breve vicepresidencia de Truman estuvo relativamente sin complicaciones, y Roosevelt rara vez estaba en contacto con él, ni siquiera para informarle de las decisiones más importantes. Truman sorprendió a muchos cuando asistió al funeral de su patrón Tom Pendergast menos de una semana después de haber sido juramentado como vicepresidente. Truman omitió las críticas, diciendo simplemente: "Siempre fue mi amigo y yo siempre lo he sido de él."

El 12 de abril de 1945, Truman había aplazado su reunión en el Senado para más tarde y se disponía a tomar una copa en la oficina del Presidente de la Cámara de Representantes, Sam Rayburn, cuando recibió el mensaje urgente de que tenía que ir inmediatamente a la Casa Blanca. A su llegada la Casa Blanca la Primera Dama, Eleanor Roosevelt, le informó de que el presidente había muerto poco antes de su llegada por una hemorragia cerebral masiva. Truman le preguntó si había algo que él pudiese hacer por ella y ésta le contestó: ""¿Hay algo que podamos hacer por usted? ¡Usted es el único en problemas ahora!""

Truman había sido vicepresidente tan sólo 82 días, cuando murió el presidente Roosevelt, el 12 de abril de 1945. Había tenido una muy escasa comunicación con Roosevelt acerca de los asuntos mundiales o de la política interna después de asumir como vicepresidente, y estaba completamente desinformado sobre la conducción de la guerra, incluyendo, en particular, el Proyecto Manhattan, que estaba próximo a probar la primera bomba nuclear de la historia.

Poco después asumir el cargo, Truman dijo a los reporteros: ""Muchachos, si alguna vez rezáis, rezad por mí ahora. No sé si alguno de vosotros alguna vez os ha caído una carga de heno encima, pero cuando me dijeron lo que había pasado ayer, sentí que la Luna, las estrellas y todos los planetas me habían caído encima.""

Al acceder a la presidencia, Truman pidió a todos los miembros del gabinete de Roosevelt que permaneciesen en sus puestos, les dijo que estaba abierto a sus consejos, y estableció un principio central en su administración: que el sería él que tomase las decisiones y que ellos serían los que le apoyasen. Pocas semanas después de que tomase el cargo, en su sexagésimo primer cumpleaños, los Aliados lograron la victoria en Europa.

Truman era mucho más difícil de controlar para el Servicio Secreto que Roosevelt. Cuando Roosevelt, que debía usar silla de ruedas, necesitaba ir a algún sitio, sus agentes del Servicio Secreto le llevaban a su propio ritmo, sin embargo, Truman era un ávido caminante y salía a pasear con regularidad por los alrededores de Washington.

Truman fue informado sobre el Proyecto Manhattan por el Secretario de Guerra, Henry L. Stimson, el día en que Roosevelt murió, después de su primera reunión de gabinete como presidente. Mientras estaba en Europa por la Conferencia de Potsdam, se enteró de la noticia de que la Prueba Trinity, la primera bomba atómica del mundo, había sido un éxito. Lanzó una indirecta a Iósif Stalin, de que los Estados Unidos estaban a punto de utilizar un nuevo tipo de arma contra los japoneses. Aunque esta era la primera vez que a los soviéticos se les había dado información oficial acerca de la bomba atómica, Stalin, a través de su servicio de espionaje, era ya muy consciente del proyecto de la bomba atómica y había estado aprendiendo sobre ello mucho antes que Truman.

En agosto de 1945, después de que Japón rechazase la Declaración de Potsdam, Truman autorizó el uso de armas atómicas contra Japón.

En la mañana del 6 de agosto de 1945, a las 8:15, el bombardero B-29 "Enola Gay" dejó caer una bomba atómica llamada Little Boy, sobre Hiroshima. Dos días más tarde, después de no haber oído respuesta del gobierno de Japón los militares estadounidenses prosiguieron con sus planes de dejar caer una segunda bomba atómica. El 9 de agosto, Nagasaki también fue devastada con una bomba, Fat Man, que fue arrojada por el bombardero B-29 "Bockscar". Las bombas mataron a unas 140.000 personas en Hiroshima y unas 80.000 en Nagasaki, a finales de 1945, la mitad de esas muertes ocurrieron en los días de los bombardeos. Truman recibió la noticia del bombardeo, mientras estaba a bordo del crucero USS Augusta (CA-31) en su camino de regreso a los Estados Unidos después de la Conferencia de Potsdam. Los japoneses se rindieron el 14 de agosto.

Los partidarios de la decisión de Truman sobre usar la bomba atómica argumentan que salvó a cientos de miles de vidas que se habrían perdido en una invasión del archipiélago japonés. En 1954, Eleanor Roosevelt dijo que Truman "tomó la única decisión que podía", y que el uso de la bomba era necesario "para evitar el tremendo sacrificio de vidas estadounidenses." Otros han argumentado que el uso de la bomba atómica era innecesario e intrínsecamente inmoral, siendo esta la única vez en la historia de la humanidad que se ha utilizado un arma de destrucción masiva de esta índole. 

El propio Truman escribió después de la presidencia: ""Sabía lo que estaba haciendo cuando detuve la guerra... no me arrepiento y, bajo las mismas circunstancias, lo volvería a hacer.""

El fin de la Segunda Guerra Mundial fue seguido por una transición incómoda de una economía de guerra a una economía de tiempos de paz. El presidente se enfrentó a la renovación de los conflictos laborales que habían permanecido en un estado latente durante los años de guerra, una grave escasez de vivienda y productos de consumo, y una insatisfacción generalizada con la inflación, que llegó a subir un 6% en solo un mes. En este ambiente polarizado, se produjo una oleada de huelgas que desestabilizaron las principales industrias, y cuya respuesta fue vista generalmente como ineficaz. En la primavera de 1946, una huelga ferroviaria a nivel nacional, algo que nunca había ocurrido en el país, llevó prácticamente a todos los pasajeros y sus equipajes a permanecer en un punto muerto durante más de un mes. Cuando los trabajadores ferroviarios rechazaron una propuesta de acuerdo, Truman tomó el control de los ferrocarriles y amenazó con llevar el asunto de los trabajadores en huelga a las fuerzas armadas. Mientras pronunciaba un discurso ante el Congreso solicitando autoridad para este plan, Truman recibió la noticia de que la huelga se había desconvocado. Anunció este desenlace al Congreso y recibió una ovación tumultuosa que se repitió durante semanas en los noticiarios. Aunque la resolución de la huelga ferroviaria hizo que se revolviese un teatro político, en realidad le costó a Truman muchas de sus políticas: su solución propuesta fue vista por muchos como prepotente, y los votantes obreros, ya cautelosos por los problemas entre Truman y los trabajadores, fueron enajenados profundamente.

Como un Wilsoniano internacionalista, Truman apoyó firmemente la creación de las Naciones Unidas, y puso a la ex-primera dama Eleanor Roosevelt como la primera delegada a la Asamblea General de las Naciones Unidas. Ante el abandono comunista de parte de los compromisos firmados en la Conferencia de Potsdam, y con los avances comunistas en Irán, Grecia, que después entró en una guerra civil y en Turquía, Truman y sus asesores de política exterior tomaron una línea dura contra los soviéticos.

A pesar de que no tenía ninguna experiencia personal en asuntos extranjeros, Truman ganó el apoyo bipartidista con su Doctrina Truman, que formalizó una política de contención, y el Plan Marshall, cuyo objetivo era ayudar a reconstruir la Europa de la posguerra. Para lograr que el Congreso gastase grandes sumas necesarias de dinero para reactivar la moribunda economía europea, Truman utilizó un argumento ideológico, diciendo que el comunismo florecía en las zonas económicamente desfavorecidas. Como parte de la estrategia de Estados Unidos en la Guerra Fría, Truman firmó la Ley de Seguridad Nacional de 1947 y reorganizó las fuerzas militares mediante la fusión del Departamento de Guerra y el Departamento de la Marina en el Establecimiento Militar Nacional, que sería más tarde conocido como el Departamento de Defensa, y la creación de la Fuerza Aérea. La ley también creó la Agencia Central de Inteligencia (CIA) y el Consejo Nacional de Seguridad.

Después de muchos años de mayorías demócratas en el Congreso y dos presidentes demócratas, la fatiga de los votantes con los demócratas entregó una nueva mayoría a los republicanos en las elecciones del congreso de 1946, y los republicanos recogieron 55 escaños en la Cámara de Representantes y varios escaños en el Senado. Aunque Truman cooperó estrechamente con los líderes republicanos en política exterior, luchó contra ellos amargamente en los asuntos internos. No pudo evitar los recortes de impuestos o la eliminación de los controles de precios. El poder de los sindicatos obreros se redujo significativamente por la Ley de Trabajo y Mantenimiento, que fue promulgada por encima del veto de Truman.

Mientras se preparaba para las elecciones de 1948, Truman dejó clara su identidad como un demócrata de la tradición del New Deal, prometió un seguro nacional sanitario, la derogación de la antisindical Ley de Trabajo y Mantenimiento, y un agresivo programa de derechos civiles. En conjunto, todo ello constituyó un amplio programa legislativo que se llamó "Fair Deal" ("Trato justo").

Las propuestas de Truman no fueron bien recibidas por el Congreso, incluso después de las inesperada victoria demócrata en las elecciones de 1948. Sólo uno de los principales proyectos de ley del Fair Deal, la Ley de Vivienda de 1949, se promulgó en el Congreso.

Truman tomó la decisión de reconocer la creación del Estado de Israel ignorando las declaraciones del Secretario de Estado, George Marshall, que temía que esto pudiera dañar las relaciones con los estados árabes. En una reunión en la Casa Blanca el 10 de noviembre de 1945, le dijo a los enviados a Arabia Saudita, Siria, Líbano y Egipto: «Lo siento, señores, pero tengo que responder a cientos de miles que están ansiosos por el éxito del sionismo: no tengo cientos de miles de árabes entre mis electores.»

Ignorando las advertencias de los árabes, ingleses, y del Departamento de Estado que temía la inmigración judía a Palestina y que un Estado judío pudiera desestabilizar el Medio Oriente, Truman y el Congreso siguieron apoyando la creación de un hogar para el pueblo judío. Los responsables políticos estadounidenses entre 1947 y 1948 acordaron que el principal objetivo de la política exterior era contener el comunismo, tal y como ocurrió en la Guerra Fría. Desde la perspectiva de Washington, Palestina era secundaria en la meta de proteger el "Nivel del Norte" de Grecia, Turquía, Irán del comunismo, como fue prometido en la Doctrina Truman. Truman estableció tres objetivos para la región: una solución pacífica, evitar la necesidad de enviar tropas estadounidenses, y evitar la penetración soviética.

Según George Lenczowski, la política de Truman en Palestina fue influenciado por los grupos de presión judíos. En sus memorias, Truman escribió que los líderes judíos en los Estados Unidos le presionaron para que promoviese las aspiraciones judías en Palestina. A instancias de los británicos, una comisióm especial de la ONU, la UNSCOP, recomendó la división inmediata de Palestina en dos Estados. Con el apoyo de Truman, el plan para dicha partición fue aprobado por la Asamblea General el 29 de noviembre de 1947. El Secretario de Estado, George Marshall, y otros expertos en asuntos exteriores siguieron oponiéndose a la creación de un Estado judío en Palestina. Cuando Truman accedió a reunirse con Jaim Weizmann, el Secretario de Estado se opuso, pero no declaró públicamente su decisión. El Secretario de Defensa, James Forrestal, advirtió sobre los peligros de despertar una hostilidad árabe, que podría desembocar en la denegación de acceso a los recursos petrolíferos de la zona, y sobre "el impacto de esta cuestión sobre la seguridad de los Estados Unidos." Truman reconoció al Estado de Israel el 14 de mayo de 1948, once minutos después de que se independizase como nación.

Truman escribió:

El 24 de junio de 1948, la Unión Soviética bloqueó el acceso a Berlín a los tres sectores occidentales. Los Aliados nunca habían negociado un acuerdo para garantizar el abastecimiento permanente de los sectores occidentales, dentro de la zona soviética. El comandante de la zona de ocupación estadounidense en Alemania, el general Lucius D. Clay, propuso el envío de una gran columna blindada que atravesase la zona soviética hasta Berlín Occidental, con instrucciones de defenderse si eran detenidos o atacados. Truman estimó que eso supondría un riesgo de guerra inaceptable, y aprobó un plan para abastecer a la ciudad bloqueada, por el aire. El 25 de junio, los Aliados iniciaron el puente aéreo de Berlín, una campaña que entregó alimentos, carbón y otros suministros, utilizando aviones militares a gran escala. Nada remotamente parecido se había realizado hasta entonces, y ninguna nación tenía la capacidad, ya sea logística o material, de repetirla. El acceso por tierra fue acordado nuevamente el 11 de mayo de 1949. El puente aéreo continuó durante varios meses más, y fue uno de los grandes éxitos de la política exterior de Truman como presidente y, significativamente, le ayudó a su campaña presidencial de 1948.

Truman adoptó una estrategia de desmovilización rápida después de la Segunda Guerra Mundial con la suspensión de actividad de los buques y la desmovilización de los veteranos. Las razones de esta estrategia, que persistieron durante el primer mandato de Truman y hasta casi el final del segundo, fueron en gran parte financieras. Para financiar las necesidades internas de gasto, Truman había abogado por una política de recortes en el programa de defensa para las Fuerzas Armadas al final de la guerra. La mayoría republicana en el Congreso, ansiosa de promulgar numerosos recortes de impuestos, aprobaron el plan de Truman de "mantener la línea" en los gastos de defensa. Además, la experiencia de Truman en el Senado lo dejó con sospechas persistentes de que grandes sumas de dinero se estaban desperdiciando en el Pentágono. En 1949, Truman nombró a Louis A. Johnson como Secretario de Defensa. Impresionados por los avances de los Estados Unidos en el desarrollo de la bomba atómica, Truman y Johnson creyeron inicialmente que la bomba atómica convertía a las fuerzas convencionales en gran medida irrelevantes para el campo de batalla moderno. Esta suposición fue finalmente errónea porque la Unión Soviética detonó su primera bomba atómica en ese mismo año.

Sin embargo, la continua reducción, afectó negativamente la disposición de defensa convencional de los Estados Unidos. Tanto Truman como Johnson tenían una antipatía especial a las solicitudes de presupuesto de la Armada y del Cuerpo de Marines. Truman propuso la disolución del Cuerpo de Marines por completo como parte del plan de reorganización nacional de defensa de 1948, pero la idea fue abandonada después de una campaña de cartas y de la intervención de influyentes veteranos de la Marina.

En 1950, muchos barcos de la Marina fueron vendidos a otros países o se desguazaron. La Armada, frente a la alta rotación de personal experimentado, recortó los ejercicios de entrenamiento, y alivió las normas de reclutamiento. El equipamiento fue desechado o vendido y el número de municiones fue recortado. El Cuerpo de Marines, con su menguante presupuesto, se redujo a inventarios excedentes de acaparamiento de armas y equipamiento de la Segunda Guerra Mundial. No fue hasta después de la invasión de Corea del Sur por Corea del Norte en 1950 cuando Truman envió numerosas solicitaciones presupuestarias al Congreso para el Cuerpo de Marines e inició lo que podría considerarse la época moderna de los gastos de defensa en los Estados Unidos.

Las elecciones presidenciales de 1948 son mayormente recordadas por la inesperada victoria de Truman. En la primavera de 1948, el índice de aprobación pública de Truman se situó en el 36%, y el presidente fue casi mundialmente considerado como incapaz de ganar las elecciones. Incluso el hijo del expresidente Roosevelt, James Roosevelt, quería dar la nominación demócrata al general Dwight D. Eisenhower, una figura muy popular, cuyas opiniones políticas eran totalmente desconocidas. Eisenhower enfáticamente se negó a aceptar, y Truman derrotó a todos los opositores de su candidatura.

En la Convención Nacional Demócrata de 1948, Truman intentó relajar la política interna mediante una estrategia de derechos civiles en la plataforma del partido, cuyo objetivo era relajar los conflictos internos entre las alas del norte y del sur del partido. Los eventos que ocurrieron, sin embargo, superaron sus esfuerzos de alcanzar un compromiso. Una dirección fuerte dada por el alcalde de Mineápolis, Hubert Humphrey, convenció a la Convención de que se hiciese una política de derechos civiles más fuerte y Truman la aprobó con entusiasmo. Todos los delegados de Alabama, y una parte de los de Mississippi, se retiraron de la convención en señal de protesta. Sin inmutarse, Truman pronunció un discurso de aceptación agresivo atacando al 80º Congreso del partido e hizo la promesa de ganar las elecciones y "hacer a los republicanos de esa manera."

Dos semanas después de la Convención, Truman emitió la Orden Ejecutiva 9981, que permitía la integración racial en las Fuerzas Armadas. Truman corrió un riesgo político considerable con su apoyo a los derechos civiles, y a muchos demócratas veteranos les preocupó que la pérdida de apoyo pudiera deshacer el Partido Demócrata. El temor parecía bien justificado, ya que Strom Thurmond anunció su candidatura a la presidencia y encabezó numerosas revueltas en los estados del Sur, proclamando los derechos de los defensores. Esta rebelión derechista fue acompañada de una revuelta izquierdista, liderada por el ex-vicepresidente Henry A. Wallace como candidato presidencial del Partido Progresista. Inmediatamente después de su primera convención después de la muerte de Franklin D. Roosevelt, el Partido Demócrata parecía que se iba a desintegrar. La victoria en las elecciones parecía remota, no sólo por estar dividido, sino por estar divido en tres partidos.

A ello siguió una odisea presidencial notable de 21.928 millas (35.290 kilómetros), algo que nunca antes había realizado ningún presidente en toda la nación. Truman y sus colaboradores recorrieron el país con el llamado tren presidencial de los Estados Unidos, el "Whistlestop", con la táctica de dar discursos breves en la plataforma trasera del ferrocarril, este acto llegó a representar toda la campaña. Sus apariciones combativas, como las de la plaza de la ciudad de Harrisburg, Illinois, capturó la imaginación popular y atrajo a grandes multitudes. Seis paradas en Michigan reunieron a un total de medio millón de personas; y también un millón de personas asistieron al desfile presidencial en Nueva York.

La gran mayoría de las reuniones espontáneas y eventos de Truman fueron un importante signo de un cambio fundamental en el pulso de la campaña, pero este cambio pasó prácticamente desapercibido por la prensa nacional, que siguió la presentación de informes que daban una aparente, inminente e inevitable victoria al republicano Thomas E. Dewey. Una de las razones para la proyección inexacta de la prensa fueron las encuestas llevadas a cabo principalmente por teléfono en un momento en que muchas personas, incluyendo gran parte de la base de votantes de Truman, no eran propietarias de un teléfono. Este sesgo de datos indicaba una base de apoyo más fuerte para Dewey de la que existía, y esto desembocó en un error de proyección indeseable y no detectado que pudo haber contribuido a la percepción de las posibilidades sombrías de Truman. Las tres principales encuestadoras abandonaron la elaboración de nuevas encuestas antes de las elecciones del 2 de noviembre, como por ejemplo, Roper en septiembre, y Crossley y Gallup en octubre.

Al final, Truman consiguió sumar a sus bases del medio oeste progresista y ganó la mayoría de los estados del sur, a pesar de su defensa de derechos civiles. El saldo final mostró que el presidente había asegurado 303 votos electorales para Truman, 189 para Dewey, y sólo el 39 para Thurmond. Henry A. Wallace no consiguió ninguno. La imagen de la definición de la campaña se produjo después de la jornada electoral, cuando Truman salió en la portada del Chicago Tribune y éste decía incorrectamente: "Dewey derrota a Truman". Truman no tenía un vicepresidente en su primer mandato. Su compañero de fórmula y vicepresidente eventual por el plazo que se inició el 20 de enero de 1949, fue el senador y congresista Alben W. Barkley.

La investidura presidencial de Truman en 1949 fue la primera investidura televisada a nivel nacional. Su segundo mandato fue agotador, en gran medida debido a la política exterior y a su política de contención. Por ejemplo, rápidamente el monopolio nuclear estadounidense terminó. Mediante la información proporcionada por sus redes de espionaje estadounidenses, supo que el proyecto de la bomba atómica de la Unión Soviética avanzaba mucho más rápido de lo previsto y ésta explotó su primera bomba atómica el 29 de agosto de 1949. El 7 de enero de 1953, Truman anunció la detonación de la primera bomba de hidrógeno de los Estados Unidos.

Truman era un firme partidario de la Organización del Tratado del Atlántico Norte (OTAN), que estableció una alianza militar formal en tiempos de paz con Canadá y muchos de los países democráticos europeos que no habían caído bajo control soviético tras la Segunda Guerra Mundial. Truman propuso con éxito la creación del tratado en el Senado en 1949. Los objetivos declarados de la OTAN fueron «detener la expansión soviética en Europa y enviar un mensaje claro a los líderes comunistas de que las democracias del mundo estaban dispuestas y eran capaces de construir nuevas estructuras de seguridad en apoyo a los ideales democráticos». Los Estados Unidos, Reino Unido, Francia, Italia, los Países Bajos, Bélgica, Luxemburgo, Noruega, Dinamarca, Portugal, Islandia y Canadá fueron los firmantes del tratado original, Grecia y Turquía se sumaron en 1952.

El 21 de diciembre de 1949, Chiang Kai-shek y su Ejército Nacional Revolucionario del oriente de la China continental, huyó a la isla de Taiwán debido a los exitosos ataques por parte del ejército comunista dirigido por Mao Zedong durante la Guerra Civil China. En junio de 1950, Truman ordenó a la Séptima Flota de los Estados Unidos que se colocase en el estrecho de Taiwán para evitar nuevos conflictos entre el gobierno comunista en la China continental y la República de China en Taiwán. Truman también avisó a la República de China de que no hiciese más ataques contra la República Popular de China.

A lo largo de su presidencia, Truman tuvo que hacer frente a las acusaciones de que el gobierno federal estaba albergando a espías soviéticos del más alto nivel. El testimonio del Congreso sobre este tema atrajo la atención nacional, y miles de personas fueron despedidas "por seguridad". Un hombre como Truman dudaba de los informes sobre la penetración potencial comunista soviética en el gobierno federal estadounidense, y su respuesta fue muy citada para descartar las acusaciones como un "arenque rojo".

En agosto de 1948, Whittaker Chambers, un ex espía soviético y antiguo editor de la revista Time, confesó ante el Comité de Actividades Antiestadounidenses y presentó una lista de posibles miembros de una red secreta de comunistas que trabajaron en el gobierno de Estados Unidos durante la década de 1930. Uno de ellos fue Alger Hiss, un alto funcionario del Departamento de Estado, pero Hiss negó las acusaciones.

Las declaraciones del Comité llevaron a una crisis en la cultura política estadounidense, siendo Hiss declarado culpable de perjurio, en un polémico juicio. El 9 de febrero de 1950, el senador republicano Joseph McCarthy acusó al Departamento de Estado de contar con comunistas en sus servicios, y específicamente se decía también que el Secretario de Estado, Dean Acheson, lo sabía y que estaba protegiendo a 205 comunistas en el Departamento de Estado. Se trataba de si Truman había quitado a todos los agentes "subversivos" que habían entrado en el gobierno durante los años de Roosevelt. McCarthy insistió en que él no lo había hecho.

Al señalar este problema y atacar a la administración de Truman, McCarthy rápidamente se estableció como una figura nacional, y sus alegatos explosivos dominaron los titulares. Sus afirmaciones tuvieron pocos detalles confirmables, pero sin embargo, paralizó a la nación que luchaba con miedo a las nuevas realidades: la explosión de una bomba nuclear soviética, la pérdida de los secretos de la bomba atómica por parte de los Estados Unidos, la conversión de China al comunismo, y las nuevas revelaciones de la penetración del espionaje soviético dentro de otras agencias estadounidenses, incluyendo el Departamento del Tesoro. Truman, un hombre pragmático que había hecho concesiones a los gustos de Tom Pendergast y Stalin, rápidamente desarrolló un odio inquebrantable hacia Joseph McCarthy. Truman contraatacó diciendo:

Sin embargo, Truman nunca fue capaz de librarse de su imagen entre el público de no poder purgar a su gobierno de las supuestas influencias subversivas.

El presidente Truman reconoció el recién creado Pakistán en 1947, convirtiendo a los Estados Unidos en uno de los primeros países del mundo en hacerlo. El presidente Truman invitó personalmente al primer ministro pakistaní, Liaqat Ali Khan, y su esposa, Begum Ra'ana, a los Estados Unidos para conversar. Liaqat Ali Khan aceptó la invitación y llegó a Washington D.C. en mayo de 1950. Liaqat dio una gira por los Estados Unidos y dio también varios discursos en Senado. En el momento de la visita, Pakistán no estaba alineado entre el bloque occidental dirigido por los Estados Unidos o el bloque oriental dirigido por la Unión Soviética. Pakistán había reconocido a la República Popular China como un gobierno comunista propio, ignorando la oposición de Washington hacia Pekín. A pesar del éxito de su gira por los Estados Unidos, el Gobierno de Liaquat Ali no hizo ningún cambio drástico en su política exterior, no aliándose con ninguno del bloques dirigentes de la Guerra Fría. En el Consejo de Seguridad de la ONU, todos se opusieron a la agresión de Corea del Norte contra Corea del Sur, pero se negaron a enviar tropas de combate de Pakistán para que se uniesen a la ONU en la península de Corea. Esto se debió principalmente a que Pakistán se estaba recuperando de su reciente guerra contra la India en la disputada por Cachemira en 1948.

El 25 de junio de 1950, el Ejército Popular de Corea del Norte bajo el mando de Kim Il-sung invadió Corea del Sur, lo que precipitó el estallido de la Guerra de Corea. Mal entrenados y equipados, sin tanques o apoyo aéreo, el Ejército de Corea del Sur fue empujado rápidamente hacia atrás, perdiendo rápidamente la capital, Seúl.

Truman pidió un bloqueo naval de Corea, sólo para descubrir que, debido a recortes presupuestarios, la marina estadounidense ya no poseía un número suficiente de buques de guerra para hacer cumplir una medida como esa. Truman rápidamente instó a las Naciones Unidas a intervenir; lo hizo, autorizando a la defensa armada por primera vez en su historia. La Unión Soviética, que estaba boicoteando las Naciones Unidas en ese momento, no estuvo presente en la votación que aprobó la medida. Sin embargo, Truman decidió no consultar al Congreso, un error que debilitó mucho su posición en el conflicto.

En las primeras cuatro semanas del conflicto, las fuerzas de infantería estadounidenses desplegadas a toda prisa en Corea demostraron ser escasas y mal equipadas. El Octavo Ejército de Japón se vio obligado a reacondicionar los tanques Sherman de la Segunda Guerra Mundial desde los almacenes y monumentos para su uso en Corea.

Respondiendo a las críticas sobre la preparación, Truman despidió a su muy criticado Secretario de Defensa, Louis A. Johnson, reemplazándolo por el general retirado, George Marshall. Truman, con la aprobación de las Naciones Unidas, decidió en una votación una nueva política, es decir, la conquista de Corea del Norte. Las fuerzas de la ONU dirigidas por el General Douglas MacArthur hicieron un contraataque, obteniendo una impresionante victoria sorpresa con un desembarco anfibio en Inchon que casi atrapó a los invasores. Las fuerzas de la ONU a continuación, marcharon hacia el norte, hacia la frontera del río Yalu con China, con el objetivo de reunir a Corea bajo los auspicios de las Naciones Unidas.

China sorprendió a las fuerzas de la ONU con una invasión a gran escala en noviembre. Las fuerzas de la ONU fueron obligadas a retroceder por debajo del paralelo 38, pero luego se recuperaron; a principios de 1951 la guerra se convirtió en un feroz punto muerto sobre el paralelo 38, donde había empezado. Las víctimas de las Naciones Unidas y los Estados Unidos fueron abundantes. Truman rechazó la petición de MacArthur de atacar las bases de abastecimiento chinas al norte del Yalu, pero MacArthur expuso su plan al líder republicano, Joseph Martin, quien lo filtró a la prensa. A Truman le preocupa gravemente que una mayor escalada de la guerra arrastrara a la Unión Soviética aún más en el conflicto, ya que suministraba armas y proporcionaba aviones de combate a las fuerzas norcoreanas. El 11 de abril de 1951, Truman despidió a MacArthur de todos sus mandos en Corea y Japón.

La destitución del general Douglas MacArthur fue una de las decisiones políticas menos populares de la historia presidencial. La calificaciones de aprobación de Truman se desplomaron, y se enfrentó a las llamadas para su Impeachment desde, entre otros, el senador Robert Taft. El Chicago Tribune proclamó un Impeachment inmediato contra Truman:

Las fuertes críticas desde prácticamente todos los sectores acusaron a Truman de negarse a asumir la culpa de una guerra echada a perder y culpar a sus generales en su lugar. Muchos ciudadanos prominentes y funcionarios, incluyendo a Eleanor Roosevelt, apoyaron, sin embargo, la decisión de Truman. MacArthur por su parte, regresó a los Estados Unidos con una bienvenida de héroe, y, después de su famoso discurso ante el Congreso, se informó de que Truman había dicho que eran un montón de "gilipolleces". Se rumoreaba incluso que MacArthur se presentaría como candidato a la presidencia.

La guerra siguió en un punto muerto frustrante para los dos años que la siguieron, con más de 30.000 estadounidenses muertos, hasta que un acuerdo de paz restauró las fronteras y puso fin al conflicto. En el ínterin, las dificultades en Corea y el clamor popular en contra de la animadversión de Truman hacia MacArthur ayudó a hacer al presidente tan impopular que los demócratas empezaron a girar a otros candidatos. En las primarias de Nuevo Hampshire el 11 de marzo de 1952, Truman perdió contra Estes Kefauver, que ganó la encuesta de preferencia con 19.800 contra 15.927 de Truman y los ocho delegados. Truman se vio obligado a cancelar su campaña de reelección. En febrero de 1952, la marca de aprobación de Truman fue del 22% según las encuestas Gallup, que fueron, hasta 2008, la marca de homologación más baja de todos los tiempos para un presidente estadounidense. Sin embargo, no duró hasta más allá de marzo.

La participación de los Estados Unidos en Indochina se amplió durante el gobierno de Truman. El día de la victoria en 1945, el líder comunista vietnamita Hồ Chí Minh declaró la independencia de Francia, pero los Estados Unidos anunció su apoyo a la restauración del poder francés. En 1950, Hồ Chí Minh volvió a declarar la independencia de Vietnam, que fue reconocida por la China comunista y la Unión Soviética. Hồ Chí Minh controlaba un territorio muy alejado a lo largo de la frontera con China, mientras que Francia controlaba el resto. "La política de contención" de Truman y su oposición a la expansión comunista, llevó a los Estados Unidos a seguir reconociendo el dominio francés, el apoyo del gobierno provisional francés y aumentar la ayuda a Vietnam. Sin embargo, una diferencia básica surgió: Los norteamericanos querían una fuerte e independiente Vietnam, mientras que a los franceses les importaba poco la contención de China, sino que querían suprimir el nacionalismo local y la integración de Indochina en la Unión Francesa.

En 1948, Truman ordenó una adición polémica en el exterior de la Casa Blanca: un balcón del segundo piso en el pórtico sur, que llegó a ser conocido como el "Balcón Truman". La obra fue impopular.

Poco después, los expertos de ingeniería concluyeron que el edificio, de mucho más de 130 años de edad, estaba en una condición peligrosa. En agosto, una sección del piso se derrumbó y el propio dormitorio y baño de Truman fueron cerrados por no ser seguros. Ningún anuncio público sobre los graves problemas estructurales de la Casa Blanca se hicieron públicos hasta después de ganar las elecciones de 1948, y para entonces Truman había sido informado de que su balcón nuevo era la única parte del edificio en buen estado. La familia de Truman se trasladó a la Blair House, la nueva Ala Oeste y el Despacho Oval se mantuvieron abiertos, Truman tuvo que caminar al trabajo por la calle cada mañana y tarde. En su momento se tomó la decisión de demoler y reconstruir todo el interior principal de la Casa Blanca, así como la excavación de nuevos niveles de sótano que sustentasen las bases. El famoso exterior de la estructura, sin embargo, fue apoyado y retenido, mientras que las renovaciones procedieron en su interior. El trabajo duró desde diciembre de 1949 hasta marzo de 1952.

El 1 de noviembre de 1950, los nacionalistas puertorriqueños, Griselio Torresola y Oscar Collazo intentaron asesinar a Truman en la Blair House. En la calle fuera de la residencia, Torresola hirió de muerte a un policía de la Casa Blanca, Leslie Coffelt, que disparó a muerte a Torresola antes de morir el mismo. Collazo, como co-conspirador de un delito grave que se convirtió en un homicidio, fue declarado culpable de asesinato y fue condenado a muerte en 1952. Truman conmutó su condena a cadena perpetua. Reconociendo la importancia de la cuestión de la independencia de Puerto Rico, Truman permitió un plebiscito en Puerto Rico para determinar el estado de su relación con los Estados Unidos. El ataque, que fácilmente podría haber tomado la vida del presidente, llamó la atención sobre nuevos problemas de seguridad en torno a su residencia de la Blair House. Había saltado de su siesta y estaba viendo el tiroteo desde la ventana abierta de su habitación hasta que un transeúnte le gritó que se pusiese a cubierto.

En respuesta a una gestión de mano de obra derivados de amargos desacuerdos sobre los controles de precios y salarios, Truman ordenó a su Secretario de Comercio, Charles W. Sawyer, que tomase el control de numerosas fábricas de acero de la nación en abril de 1952. Truman citó su autoridad como Comandante en Jefe y la necesidad de mantener un suministro ininterrumpido de acero para las municiones destinadas a la Guerra de Corea. La Corte Suprema consideró las acciones de Truman como anticonstitucionales y revocó la orden en una gran separación de poderes, Youngstown Sheet & Tube Co. v. Sawyer. La decisión de 6-3, que sostuvo que la afirmación de la autoridad Truman era demasiado vaga y no tenía raíces en la acción legislativa del Congreso, fue emitida por un tribunal compuesto íntegramente por jueces nombrados por Truman o Roosevelt. El revés del alto tribunal a la orden de Truman fue una de las más notables derrotas de su presidencia. Después de que los mineros de carbón se declarasen en huelga en la primavera de 1946, Truman amenazó con involucrar al Ejército si los mineros no volvían al trabajo, o reemplazar a los trabajadores por miembros del ejército.

En 1950, el Senado, dirigido por Estes Kefauver, investigó numerosos cargos de corrupción entre altos funcionarios de la administración, algunos de los cuales recibieron abrigos de piel y congeladores para favores. El Servicio de Impuestos Internos (IRS) estaba involucrado. En 1950, 166 empleados del IRS renunciaron o fueron despedidos, y muchos se enfrentaron a acusaciones del Departamento de Justicia en una variedad de fijación de impuestos y cargos de soborno, incluido el asistente del Fiscal general a cargo de la División de Impuestos. Cuando el Fiscal general, Howard McGrath despidió al procurador especial por ser demasiado celoso, Truman despidió a McGrath. Los historiadores coinciden en que el propio Truman era inocente. En 1945, la Sra. Truman recibió un congelador nuevo, caro, y muy difícil de conseguir. El hombre de negocios que siempre le conseguía regalos era el presidente de una empresa de perfumes y, gracias a la ayuda de Truman y del confidente general Harry Vaughan, se le dio prioridad de volar a Europa días después de la guerra, donde compró nuevos perfumes. En el camino de regreso a los Estados Unidos "chocó" con un veterano herido que también estaba regresando al país. La divulgación del episodio en 1949 humilló a Truman. El Presidente respondió enérgicamente defendiendo a Vaughan, un viejo amigo con una oficina propia en la Casa Blanca. Vaughan fue relacionado con el tiempo a múltiples escándalos de tráfico.

Las acusaciones de que agentes soviéticos se habían infiltrado en el gobierno de Truman se convirtieron en un tema importante en campaña de Eisenhower en 1952. En 1947, Truman emitió la Orden Ejecutiva 9835 para crear tablas lealtad e investigar el espionaje en los empleados del gobierno. Entre 1947 y 1952, cerca de 20.000 empleados gubernamentales fueron investigados, alrededor de 2500 renunciaron voluntariamente, y 400 fueron despedidos. Truman, sin embargo, se opuso fuertemente a los juramentos de lealtad obligatorios para los empleados gubernamentales, una postura que condujo a acusaciones de que su gobierno había sido blando con el comunismo. En 1953, el senador Joseph McCarthy y el Fiscal general, Herbert Brownell Jr., afirmaron que Truman sabía que Harry Dexter White era un espía soviético cuando lo nombró para el Fondo Monetario Internacional.

Un informe de 1947 de la administración de Truman, titulado "Para Garantizar Estos Derechos", presentó una agenda detallada de diez puntos con las reformas de los derechos civiles. En febrero de 1948, el presidente presentó una agenda de derechos civiles al Congreso, en la cual propuso la creación de varias oficinas federales dedicadas a cuestiones como los derechos de voto y prácticas justas de empleo. Esto provocó una tormenta de críticas por parte de los demócratas del Sur en el período previo a la convención nacional de nominación, pero Truman se negó a transigir, diciendo: ""mis antepasados eran confederados, pero mi sensible estómago y yo nos dimos la vuelta cuando supimos que los soldados negros, que acababan de regresar del extranjero, estaban siendo golpeados por los ejércitos de Misisipi. En la jubilación, sin embargo, Truman fue menos progresista sobre esta cuestión. Describió que las marchas de Selma a Montgomery habían sido muy tontas y que no "habían logrado una maldita cosa.""

En lugar de abordar los derechos civiles, en una necesidad de caso por caso, Truman quería hacer frente a los derechos civiles a nivel nacional. Truman preparó tres órdenes ejecutivas que eventualmente se convirtieron en una estructura para la futura legislación de derechos civiles. La primera orden ejecutiva fue la Orden Ejecutiva 9981 en 1948, es generalmente conocida como el acto que inicio la desegregación racial en las Fuerzas Armadas. Éste fue un hito en un largo camino hacia la eliminación completa de la segregación racial de las Fuerzas Armadas. Después de varios años de planificación, las recomendaciones y revisiones entre Truman, la Comisión de Igualdad de Trato y Oportunidades y las diversas ramas de las fuerzas armadas, hasta que finalmente todas las unidades se vieron racialmente integradas. Este proceso se vio también beneficiado por la presión de la escasez de mano de obra durante la Guerra de Corea, como reemplazo de las unidades previamente separadas, ahora podían ser de cualquier raza.

La segunda orden ejecutiva, también en 1948, declaró ilegal discriminar a las personas que solicitasen puestos de servicio civil, basándose en la raza. La tercera orden ejecutiva, en 1951, estableció la Comisión Gubernamental de Cumplimiento de Contratos. Esta comisión aseguró que los contratistas de defensa de las Fuerzas Armadas no pudiesen discriminar a una persona por razones raciales.

Todos los miembros del gabinete de Truman cuando se hizo presidente en 1945 habían estado sirviendo anteriormente bajo Franklin D. Roosevelt.
Truman designó a los siguientes jueces en la Corte Suprema de los Estados Unidos:


Los nombramientos judiciales de Truman fueron llamados críticamente como "inexcusables". Un ex-ayudante de Truman confesó que era el aspecto más débil de la presidencia de Truman. El New York Times condenó el nombramiento de Tom C. Clark y Sherman Minton, en particular, como ejemplos de favoritismo en los candidatos no calificados.

Los cuatro jueces designados por Truman se unieron a los jueces Felix Frankfurter, Robert H. Jackson, y Stanley Reed para crear un bloque sustancial conservador de siete miembros en la Corte Suprema. Éste regresó a la corte una vez en el conservadurismo de la época de Taft.

Además de los cuatro jueces que designó en la Corte Suprema, Truman designó a 27 jueces de las Cortes de Apelaciones, y a 101 jueces de las cortes de distrito de los Estados Unidos.

En 1951, los Estados Unidos ratificaron la Vigesimosegunda Enmienda, que decía que un presidente no podía ser elegido tres veces, o que no podía ser elegido por segunda vez después de haber cumplido más de dos años del mandato de un presidente anterior. La última cláusula se habría aplicado a Truman en 1952, excepto que una cláusula de exención de la enmienda excluía explícitamente el actual presidente de esta disposición. Sin embargo, Truman decidió no presentarse a la reelección.

En el momento de las primarias de Nuevo Hampshire de 1952, ningún candidato había ganado el apoyo de Truman. Su primera elección, el juez Fred M. Vinson, se había negado a hacerlo; el gobernador de Illinois, Adlai Stevenson había también vencido a Truman; el vicepresidente Barkley fue considerado demasiado viejo, y Truman desconfiaba y no le gustaba el senador Estes Kefauver, a quien en privado llamado "Cowfever" ("Fiebre de Vaca").

Truman participó en las primarias electorales de Nuevo Hampshire, pero Kefauver le ganó. El 29 de marzo, Truman anunció su decisión de no postularse para la reelección. Stevenson, que reconsideró sus ambiciones presidenciales, recibió el apoyo de Truman y ganó la nominación demócrata.

Dwight D. Eisenhower, un republicano y el candidato presidencial del partido, hizo una campaña contra lo que él denunciaba como los fracasos de Truman sobre "Corea, el comunismo, la corrupción y el desorden en Washington", y se comprometió en "ir a Corea." Eisenhower derrotó a Stevenson en las urnas, poniendo fin a 20 años de gobierno demócrata. Mientras Truman y Eisenhower habían sido buenos amigos, Truman se sintió traicionado por Eisenhower, ya que éste no denunció a Joseph McCarthy durante la campaña.

Truman volvió a Independence, para vivir en la casa de su esposa, Bess, que habían compartido durante años con su madre. Cuatro meses después de dejar el cargo, Truman fue invitado a dirigirse a la Asociación de Oficiales de Reserva de Filadelfia. Negándose al transporte oficial, Truman fue con su nuevo Chrysler New Yorker de segunda generación, con Bess acompañándole en el asiento del pasajero. El viaje, que incluyó paradas en Washington D.C., Nueva York, y varios pueblos pequeños, causó sensación en los medios de comunicación, sobre todo cuando el expresidente fue detenido por un policía por conducir demasiado despacio en una línea de pase.

El predecesor de Truman, Franklin D. Roosevelt, había organizado su propia biblioteca presidencial, pero la legislación que permite a los expresidentes hacer algo similar, aún no se promulgada. Truman trabajó para reunir las donaciones privadas para construir una biblioteca presidencial, que luego donó al gobierno federal para que la administrara, una práctica adoptada por todos sus sucesores.

Una vez fuera del cargo, Truman decidió que no iba a estar en una nómina empresarial, en la creencia que sacar ventaja de las oportunidades financieras de su condición de expresidente, disminuiría la integridad de la más alta magistratura de la nación. También rechazó numerosas ofertas para los endosos comerciales. Desde que sus emprendimientos anteriores se habían vuelto remunerativos, no tenía ahorros personales. Como resultado, se enfrentó a problemas financieros. Una vez que Truman abandonó la Casa Blanca, su único ingreso fue su antigua pensión del ejército por $ 112.56 al mes. Los antiguos miembros del Congreso y los tribunales federales recibían un bono o pensión de retiro federal, el propio presidente Truman aseguró para los antiguos funcionarios de la rama ejecutiva del gobierno, un apoyo similar. En 1953, sin embargo, no había bono o pensión beneficios para los expresidentes.

Sacó un préstamo personal de un banco de Misuri poco después de dejar el cargo, y luego se dedicó a establecer otro precedente para futuros ex-jefes ejecutivos: un libro de sus memorias mientras estaba en el cargo. Ulysses S. Grant había superado problemas financieros similares con sus propias memorias, pero los libros habían sido publicados a título póstumo, y él se había negado a escribir sobre la vida en la Casa Blanca muy detalladamente. Por sus memorias Truman sólo recibió un pago fijo de 670.000 dólares, y tuvo que pagar dos tercios de los ello en impuestos; calculó que había obtenido 37.000 dólares después de pagar a sus asistentes.

Las memorias de Truman fueron un éxito comercial y con muy buenas críticas, éstas se publicaron en dos volúmenes en 1955 y 1956 por Doubleday y Hodder & Stoughton. Los libros fueron "Memorias de Harry S. Truman: Año de las Decisiones" y "Memorias de Harry S. Truman: Años de juicios y esperanza."

Truman dijo en 1957 al entonces líder de la mayoría de la Cámara de Representantes, John McCormack: ""Si no hubiera sido por el hecho de que yo podía vender una propiedad que mi hermano, hermana, y yo heredamos de nuestra madre, yo sería prácticamente el alivio, pero con la venta de esa propiedad no estoy económicamente avergonzado.""

En 1958, el Congreso aprobó la Ley de expresidentes, que ofrecía una pensión de 25.000 dólares anuales a cada expresidente, y es probable que la situación financiera de Truman desempeñase un papel en la promulgación de la ley.El otro expresidente vivo, Herbert Hoover, también tomó la pensión, a pesar de que no necesitaba el dinero, al parecer, lo hizo para evitar avergonzar a Truman. Hoover podría haber recordado un viejo favor: Poco después de convertirse en presidente, Truman invitó a Hoover a la Casa Blanca para tener una charla informal sobre las condiciones en Europa. Esta fue la primera visita de Hoover a la Casa Blanca después de haber salido del cargo, ya que el gobierno de Roosevelt había rechazado a Hoover. Los dos siguieron siendo buenos amigos para el resto de sus vidas.

En 1956, Truman viajó a Europa con su esposa. En Reino Unido recibió un doctorado honorífico en Derecho Cívico de la Universidad de Oxford y se reunió con Winston Churchill. Cuando regresó a Estados Unidos, se convirtió en partidario de la segunda candidatura presidencial de Adlai Stevenson, a pesar de que inicialmente había favorecido al gobernador demócrata, W. Averell Harriman, de Nueva York.

Al cumplir los 80 años, Truman fue agasajado en el Senado de los Estados Unidos, como parte de una nueva norma que concedía a los expresidentes voz ante la cámara. También hizo campaña para algunos candidatos senatoriales. Después de una caída en su casa a finales de 1964, su estado físico se vio negativamente afectado. En 1965, el presidente Lyndon B. Johnson firmó la ley de Medicare en la Biblioteca de Truman y le dio las dos primeras tarjetas de Medicare a Truman y a su esposa Bess en honor a la lucha por el cuidado de salud de su gobierno durante su presidencia.

El 5 de diciembre de 1972, fue trasladado al Hospital y Centro Médico de Investigación de Kansas City con una congestión pulmonar debida a una neumonía. Desarrolló un fallo multiorgánico y falleció a las 7:50 de la mañana del 26 de diciembre a la edad de 88 años. Su esposa murió casi diez años después, el 18 de octubre de 1982. Están enterrados en la Biblioteca y Museo Presidencial de Harry S. Truman en Independence. Bess Truman optó por un simple servicio privado en la biblioteca de su marido en lugar de un funeral de estado en Washington DC. Dignatarios extranjeros asistieron al funeral en la Catedral Nacional de Washington, una semana después.

Cuando dejó el cargo en 1953, Truman había sido uno de los presidentes más impopulares de la historia. Su índice de aprobación en el cargo, del 22% en la encuesta de Gallup de febrero de 1952, fue menor que la de Richard Nixon en agosto de 1974, que era del 24%, el mes en que Nixon dimitió. El sentimiento público estadounidense hacia Truman se fue haciendo cada vez más negativo con el paso de los años. Sin embargo, el período inmediatamente después a su muerte se vivió una rehabilitación parcial entre los historiadores y miembros del público en general. Ya en 1962, una encuesta de 75 historiadores destacados realizado por Arthur M. Schlesinger, Sr., colocó a Truman entre los mejores presidentes. Desde que dejara el cargo, a Truman le fue bien en las encuestas de valoración presidencial. Su presidencia nunca ha caído por debajo del noveno puesto de entre todas las presidencias históricas, y más recientemente ha llegado a colocarse en el quinto en una encuesta de C-SPAN en 2009.

También ha tenido sus críticos. Después de una revisión de la información disponible de Truman sobre la presencia de actividades de espionaje en el gobierno estadounidense, el senador demócrata Daniel Patrick Moynihan, llegó a la conclusión de que Truman había sido "casi deliberadamente negligente" sobre el peligro del comunismo estadounidense. Ya en la década de 1960, historiadores revisionistas empezaron a criticar a Truman. En la actualidad, el consenso entre los historiadores es que "Harry Truman sigue siendo un presidente polémico."

Truman falleció en un momento en que la nación estaba consumida por las crisis en Vietnam y el Watergate, y su muerte trajo una nueva ola de atención a su carrera política. A principios y mediados de la década de 1970, Truman capturó la imaginación popular tanto como lo había hecho en 1948, esta vez emergiendo como una especie de héroe popular político, un presidente que se creía que era un ejemplo de una integridad y la responsabilidad que muchos observadores sentían que faltaba en la Casa Blanca de Nixon. Truman ha sido retratado en la pantalla muchas veces, varias actuaciones que han ganado el aplauso generalizado, y la banda de pop Chicago tocó una canción nostálgica en 1975 llamada "Harry Truman."

Debido al papel fundamental de Truman en la decisión de que el gobierno estadounidense reconociese a Israel, el pueblo israelí de Beit Harel fue renombrado Kfar Truman en 1949.

Irónicamente, en vista del intento de Truman para reducir la producción naval, que condujo a la revuelta de almirantes de 1949, el Cuerpo de Marines decidió renombrar un portaaviones en su honor. El portaaviones destinado a recibir el nombre , fue rebautizado el 7 de septiembre de 1996, antes de la puesta en grada de la quilla. Se daba la circunstancia de que era el mismo nombre del portaaviones que Truman había cancelado en 1949.

La Beca Truman, un programa federal que honra a estudiantes de universidades estadounidenses que ejemplifican la dedicación al servicio público y el liderazgo en las políticas públicas, se creó en 1975. La en la Comunidad de Seguridad Nacional de la Ciencia e Ingeniería del Presidente Harry S. Truman, una distinguida cita posdoctoral de tres años en el Laboratorio Nacional Sandia, fue creada en 2004. La Universidad de Misuri estableció la Escuela de Asuntos Públicos de Harry S. Truman para avanzar en el estudio y la práctica de la gobernanza. Con motivo de la transformación de una mascota universitaria al nombre de Truman, una escuela normal estatal, la Northeast Missouri State University se convirtió en la Truman State University el 1 de julio de 1996, para honrar al único misurense en convertirse en presidente. Una institución miembro de los Colegios de la Ciudad de Chicago, la Harry S. Truman College en Chicago fue nombrado en honor del presidente por su dedicación a las universidades públicas. La sede del Departamento de Estado de Estados Unidos, construido en la década de 1930 fue renombrado (no oficialmente) en el Edificio Harry S. Truman en el 2000.

En 1991, Truman fue admitido en el Salón de Famosos Misurenses, y un busto de bronce que le representa, está en exhibición permanente en la rotonda del Capitolio Estatal de Misuri. Thomas Daniel, uno de los nietos de Truman, aceptó una estrella en el Paseo de la Fama de Misuri en 2006 para honrar a su difunto abuelo. John Truman, sobrino de Truman, aceptó una estrella para Bess Truman en 2007. El Paseo de la Fama está Marshfield, Misuri, una ciudad que Truman visitó en 1948.

Truman fue honrado por el Servicio Postal en la serie de grandes estadounidense con el vigésimo sello postal de la serie.





</doc>
<doc id="21390" url="https://es.wikipedia.org/wiki?curid=21390" title="Fotografía digital">
Fotografía digital

La fotografía digital consiste en la obtención de imágenes mediante una cámara oscura, de forma similar a la fotografía química. Sin embargo, así como en esta última las imágenes quedan grabadas sobre una película fotosensible y se revelan posteriormente mediante un proceso químico, en la fotografía digital las imágenes son capturadas por un sensor electrónico que dispone de múltiples unidades fotosensibles, las cuales aprovechan el efecto fotoeléctrico para convertir la luz en una señal eléctrica, la cual es digitalizada y almacenada en una memoria.

La ventaja de este sistema respecto a la fotografía química es que permite disponer de las imágenes grabadas al instante, sin necesidad de llevar la película al laboratorio y revelar los negativos para poder ver las imágenes; esta ventaja en la rapidez en la disponibilidad de la imagen permite que el fotógrafo haga los cambios en el momento y realice las correcciones que considere pertinentes de forma inmediata, facilitando así lograr la imagen que se desea.

En la cámara digital pueden verse en una pantalla las fotos que se acaban de tomar. La cámara se puede conectar a una computadora u otro dispositivo capaz de mostrar las fotos en un monitor. Como están en un formato digital, las fotos pueden enviarse directamente por correo electrónico, publicarse en la web y se pueden procesar con programas de tratamiento fotográfico en una computadora, para ampliarlas o reducirlas, realizar un reencuadre (una parte de la foto), rectificar los colores y el brillo, y realizar otras muchas posibles modificaciones según el programa que se utilice.

Otra gran ventaja de la fotografía digital es que cada vez que la cámara toma una foto crea un archivo de metadatos exif (datos no visuales) y guarda dentro del archivo de imagen información relevante de la captura como la fecha, la hora, la apertura del diafragma, la velocidad de obturación, velocidad del ISO. Esta información es muy útil para estudiar las imágenes y entender más acerca de cada fotografía y también facilita el ordenamiento y el manejo de los archivos fotográficos.

Otros recursos útiles existentes en fotografía digital son el histograma de brillo, que es un gráfico que muestra la distribución de los píxeles de la imagen según sus niveles de brillo; así como el histograma RGB que muestra la distribución de los píxeles en los diferentes canales de color: en el caso del modo RGB, serán los canales de rojo (R: "red"), Verde (G: "green"), y Azul (B: "blue"). Este recurso no existe en fotografía química.

Las cámaras digitales profesionales tienen la opción de personalizar diferentes tipos de usuario, permitiendo ajustar características importantes de la imagen como la saturación, el contraste, la nitidez y el tono de color. Además permiten un manejo personalizado del balance del blancos, lo cual puede variar notablemente la gama cromática y también permiten capturar imágenes en blanco y negro, sepia, con filtros, etc. El control fácil y rápido de la sensibilidad ISO ayuda a resolver los problemas de falta o exceso de luz.

Las cámaras digitales favorecen por otra parte una mayor producción de fotografías, en tanto el límite del costo y la cantidad de fotogramas de las películas desaparece, quedando reducido al poco conocido dato de la vida útil del obturador digital.

El costo por fotografía impresa -en comparación con el sistema químico- es menor; esto considerando que se pueden realizar múltiples tomas, y elegir para la impresión solamente fotografías deseadas.

La convergencia tecnológica ha llevado las cámaras digitales a los teléfonos móviles y otros dispositivos como las tabletas, aumentando el número de usuarios de la fotografía exponencialmente y cada vez los nuevos modelos mejoran la calidad óptica y la resolución de la imagen, esto ha causado que la tarea del fotógrafo deba ser repensada y reestructurada. La fotografía digital ha creado una revolución del medio fotográfico. Las imágenes se visualizan cada vez más en pantallas que en papel.

En el 2010, ya son millones de usuarios los que comparten sus imágenes a través de las redes sociales como Facebook y otros sitios web especializados como Flickr o Picasa, que permiten almacenar, ordenar, buscar y compartir fotografías en línea.

Autores como Fred Richtin, Joan Fontcuberta, o Pedro Meyer han analizado estos fenómenos en el marco de lo que se ha dado en llamar "posfotografía". Estos autores apuntan que la facilidad de acceso de la fotografía digital y la abundancia de imágenes están diluyendo el rol tradicional del fotógrafo, la función social de la fotografía y las barreras de la privacidad, entre otros aspectos.

La resolución de una película de 35 mm es alrededor de 320 píxeles por milímetro, siendo aproximadamente de 87 megapíxeles. En cambio expertos fotógrafos dicen que una buena cámara de película química, con un objetivo de alta resolución, una película de alta calidad y un buen revelado equivaldría a unos 40 megapíxeles. Sin embargo, en la mayoría de los casos, las fotografías en película de 35 mm —en especial con película de bajo costo— no sobrepasan los 6 000 000 de puntos, debido al tipo de cámara e inexperiencia de la persona que está fotografiando. En cambio, con una cámara digital de relativa calidad y una persona inexperta, se pueden obtener imágenes de mejor resolución que con su contra parte química. Hoy en día (año 2011) algunas cámaras digitales han alcanzado los 45 megapíxeles en el formato 35 mm, como es el caso de la cámara Sigma SD1.

Las cámaras digitales con sensor "full frame" presentan una mejor que la película química, especialmente en sensibilidades ISO bajas. Por otra parte, y como una visión un tanto más subjetiva, algunos fotógrafos consideran que el grano de la película de 35 mm es más agradable a la vista que el ruido de la cámara digital; el grano es siempre —o casi siempre— monocromático, mientras que el ruido se expresa en puntos de colores, que interrumpen la uniformidad de la imagen.

Debido al calentamiento del dispositivo electrónico por el flujo continuo de corriente, el sensor agrega ruido a las imágenes cuando estas se obtienen mediante una exposición prolongada; en sistemas profesionales, esto se corrige generalmente utilizando una celda Peltier, que mantiene el dispositivo a una temperatura baja, evitando de esta manera la aparición de ruido térmico, y en algunos casos (fotografía astronómica) es frecuente el uso de líquidos a muy baja temperatura para la refrigeración del sensor (nitrógeno e hidrógeno líquidos); otra forma que existe de reducir el ruido es lo que se conoce como apilado de exposición o "exposure stacking", que superpone varias imágenes tomadas durante el tiempo general de la captura para restar el patrón de ruido de la imagen final.

Otra desventaja de las cámaras digitales es el costo más elevado de éstas, comparado con las máquinas convencionales, aunque día a día esta brecha se acorta.

Una desventaja de las cámaras réflex digitales DSLR (réflex digitales de único objetivo) es que son más delicadas que las réflex de película, ya que el sensor que digitaliza la imagen es muy frágil y puede rayarse o deteriorarse con facilidad; además éste suele ensuciarse con frecuencia durante el cambio de objetivos, de tal forma que se hace necesario un delicado proceso de limpieza periódicamente. En el caso de la película química, la posibilidad de la aparición de polvo se ve disminuida debido a que la superficie sensible se cambia continuamente, desplazando cualquier posible rastro de suciedad.

En algunas ocasiones las cámaras digitales se demoran mientras guardan la información del archivo en la tarjeta de memoria y aparece el anuncio de "BUSY" (ocupado), impidiendo que se tomen nuevas imágenes hasta que se termine de procesar la información, esto es molesto por que algunas imágenes no se pueden capturar y se escapan mientras ocurre este proceso de archivado, esto no ocurre en la fotografía química donde el motor de arrastre es el encargado del desplazamiento de la película y de dejar la cámara lista para la siguiente toma.

Lograr un efecto de exposición múltiple es más fácil en fotografía química que en digital.

Al igual que en la fotografía clásica, existen muy diversos tipos de cámaras digitales, ya sean de tamaño de bolsillo, medianas o para uso avanzado o profesional, con ópticas más o menos completas, y con sistemas más o menos sofisticados. Una característica peculiar de las cámaras digitales es, sin embargo, la resolución. También en la fotografía clásica se habla de resolución, pero en este caso depende del tipo de película que se usa, ya que es el tamaño de los granos fotosensibles y la dimensión física de la película lo que determina la resolución independientemente de la cámara. También se habla de la "resolución magnífica", pero debe ser tenida en cuenta solamente la del sensor, ya que la interpolación consiste en un proceso que amplía la imagen sin ganancia de calidad (incluso puede perderla ligeramente), puesto que se parte siempre de la resolución del sensor y ésta se interpola con procedimientos matemáticos en los que es imposible obtener los detalles que no captó el sensor.

Se caracterizan por tener una gran facilidad de uso, tamaño bastante reducido (la mayoría similares a un teléfono celular) y operación simplificada; este diseño limita las capacidades creativas de capturar imágenes, limitándose al uso aficionado. Por las características ópticas y electrónicas (sensor reducido, objetivos con poca luminosidad), presentan casi siempre una profundidad de campo bastante amplia. Esto permite que varios objetos estén enfocados al mismo tiempo, lo cual facilita el uso, aunque es también una de las razones por las cuales los fotógrafos avanzados encuentran las imágenes tomadas por estas cámaras planas o artificiales. Estas cámaras son ideales para tomar paisajes y uso ocasional. Frecuentemente guardan los archivos de imagen en formato JPEG, poseen un rango dinámico limitado y muchas de ellas aplican reducción de ruido en las imágenes, incluso en la sensibilidad más baja disponible.

Estas cámaras permiten un mayor control de las tomas y tienen más calidad y prestaciones que las anteriores. Físicamente, poseen un tamaño mayor, más mandos y botones y una empuñadura más grande, con lo cual se asemejan a las cámaras réflex, y comparten algunas de sus funciones. Generalmente tienen "zoom" óptico largo (de ahí su nombre) que asegura una mayor capacidad creativa. Algunas veces son comercializadas como y confundidas con cámaras SLR digitales (dSLR) ya que los cuerpos de cámara se parecen entre sí. En algunos modelos, pueden añadirse convertidores de rosca para mejorar el alcance o la cobertura angular, pueden tomar vídeo, grabar audio y la composición de la escena se lleva a cabo en la pantalla de cristal líquido o en un visor electrónico. La velocidad de respuesta de estas cámaras tiende a ser menor que la de una verdadera SLR digital, pero pueden lograr una muy buena calidad de imagen siendo más ligeras y compactas. Muchas de estas cámaras guardan las fotografías en formato JPEG y cada vez hay más que pueden hacerlo en formato RAW.

Las cámaras réflex digitales son el equivalente a las cámaras de película química. Están orientadas al sector del fotoperiodismo, a la fotografía artística y otros usos avanzados/profesionales, debido a que sus características de respuesta y calidad de imagen son —por lo general— superiores a las de las cámaras compactas. Respecto a las cámaras compactas, tienen un sensor de mayores dimensiones, lo cual equivale a una mayor relación señal/ruido que se traduce en una mejor calidad de imagen. El diseño de los componentes electrónicos está optimizado para proveer un tiempo de respuesta similar al de las cámaras réflex tradicionales. Poseen la capacidad de grabar en formatos de mayor calidad (JPEG de baja compresión, RAW), lo cual es útil en las labores de posprocesamiento de la imagen. Comercialmente se encuentran divididas por sectores: aficionado (pocos controles, funciones automáticas asistidas, tamaño reducido), aficionado avanzado (mayor personalización de la captura, accesorios adicionales) y profesional (alta velocidad de disparo y respuesta, rendimiento ISO elevado, sensor de formato completo).

La resolución en fotografía digital se mide multiplicando el alto por el ancho de las fotografías que permite obtener la cámara y generalmente comienza con un millón de píxeles, para las cámaras más económicas, y va en aumento hasta más de diez millones de píxeles, para las cámaras profesionales. El término "píxel" (del inglés "picture element"), es la unidad más pequeña que capta un valor gris o de color de la fotografía. Una cámara de cuatro millones de píxeles generará imágenes más grandes que una de dos millones, lo que permite obtener una copia impresa de hasta 50 × 75 cm, pero no necesariamente de mayor calidad ya que en este aspecto tiene una mayor importancia la calidad de la óptica utilizada. Sin embargo, dado que a más megapíxeles las cámaras son más caras, es habitual que también posean mejores objetivos.

Otra característica de la fotografía digital es el "zoom digital". Mediante este zoom se puede ampliar una foto, pero el efecto no es el de un "zoom óptico". El "zoom" óptico acerca y amplia lo que se quiere fotografiar sin mermar la resolución de la cámara, ya que el acercamiento se consigue con el objetivo. El zoom digital, por el contrario, amplia la imagen que ya ha recibido, de forma que disminuye la resolución, al igual que ocurriría encargando una ampliación al laboratorio o utilizando un programa de edición de gráficos.

Actualmente las cámaras digitales también permiten tomar vídeos, generalmente en resoluciones desde 320×240 hasta 1920×1080 píxeles y de entre 12 y 60 fotogramas por segundo, a veces con sonido (normalmente monofónico) en el caso de los modelos más completos. Estos vídeos están alcanzando un nivel tan alto de calidad que son muchos los profesionales que están utilizando cámaras réflex en lugar de cámaras de vídeo.

La primera cámara digital fue desarrollada por Kodak, que encargó a Steve Sasson la construcción de una el 12 diciembre de 1975. Ésta tenía el tamaño de una tostadora y una calidad equivalente a 0,01 megapíxeles. Necesitaba 23 segundos para guardar una fotografía en blanco y negro en una cinta de casete y otros tantos en recuperarla.




</doc>
<doc id="21391" url="https://es.wikipedia.org/wiki?curid=21391" title="Joaquín Sorolla">
Joaquín Sorolla

Joaquín Sorolla y Bastida (Valencia; 27 de febrero de 1863-Cercedilla; 10 de agosto de 1923) fue un pintor español. Artista prolífico, dejó más de 2200 obras catalogadas. Su obra madura ha sido etiquetada como impresionista, postimpresionista y luminista.

Cuando apenas contaba dos años de edad, fallecieron sus padres víctimas de una epidemia de cólera. Al quedar huérfanos fueron acogidos, su hermana Eugenia y él, por su tía Isabel, hermana de su madre, y su marido, de profesión cerrajero. Pasados los años, su tío intentó enseñarle, en vano, el oficio de la cerrajería, advirtiendo pronto que su verdadera vocación era la pintura. Estudió dibujo en la Escuela de Artesanos de Valencia. Compartió estudio en la planta baja de la calle Las Avellanas nº 12 de Valencia con José Vilar y Torres, los hermanos Benlliure y Pinazo.Al acabar su formación comenzó a enviar sus obras a concursos provinciales y exposiciones nacionales de bellas artes, como la de Madrid en mayo de 1881, donde presentó tres marinas valencianas que pasaron inadvertidas, pues no encajaban con la pintura oficial, de temática histórica y dramática. Al año siguiente estudió la obra de Velázquez y otros autores en el Museo del Prado. Tras visitar el Museo del Prado, Sorolla pintó en 1883 el lienzo inédito "Estudio de Cristo", descubierto recientemente, donde se observa la influencia del "Cristo crucificado" de Velázquez. Comienza así su 'etapa realista', siendo su profesor Gonzalo Salva. Por fin, en 1883, consiguió una medalla en la Exposición Regional de Valencia, y en 1884 alcanzó la gloria al conseguir la Medalla de segunda clase en la Exposición Nacional gracias a su obra "Defensa del parque de artillería de Monteleón", obra melodramática y oscura, hecha expresamente para la exposición; tal y como le dijo a un colega suyo: «Aquí, para darse a conocer y ganar medallas hay que hacer muertos».

Cosechó otro gran éxito en Valencia con su obra "El crit del palleter" sobre la Guerra de la Independencia. De esta manera, fue pensionado por la Diputación Provincial de Valencia para viajar a Roma, donde, a la vez que trabajaba, conoció el arte clásico y renacentista, así como los grandes museos, contactando, además, con otros artistas.

Con su amigo, el también pintor Pedro Gil, se desplazó a París durante el primer semestre de 1885, y conoció de cerca la pintura impresionista, que produjo en él, ya de regreso en Roma, variaciones en su temática y estilo, llegando a pintar el cuadro religioso "El entierro de Cristo", con el que no tuvo el éxito esperado. Tomó así contacto con las vanguardias europeas, destacando el impacto que le produjeron las obras de los pintores John Singer Sargent, Giovanni Boldini y Anders Leonard Zorn.
En 1888 contrajo matrimonio con Clotilde García del Castillo en Valencia, aunque vivirían un año más en Italia, esta vez en la localidad de Asís. A esa época se relacionan algunas de sus obras, entre ellas "Vendiendo melones" (Museo Carmen Thyssen Málaga), época en la que pintaba temas costumbristas y anecdóticos, por su fácil venta. Por lo general eran pequeñas acuarelas que comercializaba su marchante, Francisco Jover.

En 1889 el pintor y su familia se instalaron en Madrid y, en apenas cinco años, Sorolla alcanzaría gran renombre como pintor. En 1894 viajó de nuevo a París, donde desarrolló un estilo pictórico denominado «luminismo», que sería característico de su obra a partir de entonces. Comenzó a pintar al aire libre, dominando con maestría la luz y combinándola con escenas cotidianas y paisajísticas de la vida mediterránea. En obras como "La vuelta de la pesca", "La playa de Valencia" o "Triste herencia" describió el sentimiento que producía la visión del mar Mediterráneo, comunicando el esplendor de una mañana de playa con un colorido vibrante y un estilo suelto y vigoroso. Con "Triste herencia" recibió, en 1900, el "Grand Prix" en el certamen internacional de París. Además, siguió con su pintura de denuncia social que tantos éxitos le había reportado en los últimos años con obras como "Y aún dicen que el pescado es caro" (1894).
A finales del año 1900, en el mes de agosto, estando en Valencia, su amigo el escultor Ricardo Causarás Casaña fue a visitar a Sorolla para pedirle que posara de modelo vivo para esculpir una estatua de terracota y yeso, algo mayor del natural, que Causarás tenía pensado exponer en la Exposición General de Bellas Artes de Madrid del año 1901. Sorolla estuvo en el mes de enero de 1901 en el estudio de escultura, posando de modelo durante veinte días para su amigo Causarás, que, además de esculpir su estatua, también esculpió aparte un busto-retrato de su cabeza, solamente en terracota, y el vaciado en yeso de la mano derecha de Sorolla en posición de pintar. En el mes de mayo de 1901 la estatua "Sorolla" fue expuesta en la Exposición General de Bellas Artes de Madrid, siendo premiada por el jurado con «Consideración de Medalla de Tercera Clase en Escultura». Posteriormente permaneció expuesta en Valencia desde 1901 hasta 1925, en la sala principal del Círculo de Bellas Artes, siendo finalmente regalada al Ayuntamiento de Valencia, que la depositó hasta mediados del mes de agosto de 1930 en los Reales Jardines de los Viveros de Valencia. 

Por aquel entonces Valencia lo nombró hijo predilecto y meritorio, y le fue dado su nombre a una calle. Tras muchos viajes por Europa, principalmente Inglaterra y Francia, celebró una exposición en París con más de medio millar de obras, lo que le dio un reconocimiento internacional inusitado, conociéndose su obra pictórica por toda Europa y América.
Hacia el verano de 1905 está en Jávea y realiza una serie de pinturas de niños desnudos, una de sus series más famosas y que le valieron el posterior encargo de la Hispanic Society of America. Uno de los cuadros más destacados de la serie es "El baño", de 1905 y que pertenece a la colección del Museo Metropolitano de Nueva York.

En 1905, el pintor adquirió un solar en el Paseo del Obelisco de Madrid (luego calle del General Martínez Campos), junto a la residencia de la actriz María Guerrero. En 1909, encargó el proyecto al arquitecto Enrique María de Repullés y Vargas. Poco después compró un segundo solar contiguo que le permitiría ampliar la zona construida e incorporar tres jardines a la vivienda. Sorolla inauguró en 1911 su nuevo hogar en Madrid, tras pasar por diversos estudios y domicilios en la ciudad —plaza el Progreso, pasaje de la Alhambra, calle de Miguel Ángel—.Su éxito económico es evidente desde 1905. En parte, también provino de su exposición en Nueva York en 1909, que cosechó un éxito sin precedentes, con obras como "Sol de tarde" o "Nadadores", entre otras muchas. También triunfó en 1911, en el Museo de Arte de San Luis y en el Instituto de Arte de Chicago. 
En noviembre de ese mismo año firmó un encargo para la Sociedad Hispánica de América, por el que realizaría catorce murales que decorarían las salas de la institución, y dedicados a "las Regiones de España". Con esta obra realizada entre 1913 y 1919, de tres metros y medio de alto por setenta metros de largo, alzó un imborrable monumento a España, pues en ella se representaban escenas características de diversas provincias tanto españolas como portuguesas. Necesitó casi todo el año de 1912 para viajar por todo el país, haciendo bocetos y trabajos de costumbres y paisajes. De esta tarea destacan los óleos pintados en 1916 dedicados a niños y mujeres en las playas de Valencia, donde predomina la libertad de pincelada y la luz de su tierra. Algunos ejemplos son "Madre e hija" o "Pescadora valenciana".

Otra importante faceta que desarrolló en aquellos años fue la de retratista. Posaron para él personajes como Cajal, Galdós, Machado, su paisano Vicente Blasco Ibáñez, o políticos como Emilio Castelar, el rey Alfonso XIII, el presidente William Howard Taft, además de una buena colección de retratos de su familia y algunos autorretratos. 

En 1914 había sido nombrado académico y, cuando terminó los trabajos para la Hispanic Society, trabajó como profesor de composición y color en la Escuela de Bellas Artes de Madrid. En 1920, mientras pintaba en el jardín de su casa el retrato de la mujer de Ramón Pérez de Ayala, sufrió una hemiplejia que mermó sus facultades físicas, impidiéndole seguir pintando. Murió tres años después en su residencia veraniega de Cercedilla, el 10 de agosto de 1923.

Más tarde, su casa de Madrid fue reabierta como Museo Sorolla. Su principal discípulo fue Teodoro Andreu.









</doc>
<doc id="21394" url="https://es.wikipedia.org/wiki?curid=21394" title="Dwight D. Eisenhower">
Dwight D. Eisenhower

Dwight David «Ike» Eisenhower (Denison, 14 de octubre de 1890-Washington D.C., 28 de marzo de 1969) fue un militar y político que sirvió como el presidente de los Estados Unidos entre 1953 y 1961. General de cinco estrellas del ejército de los Estados Unidos durante la Segunda Guerra Mundial, fue comandante supremo de las fuerzas aliadas occidentales en Europa y responsable de la planificación y supervisión de la invasión del norte de África en la Operación Torch entre 1942 y 1943 y de la exitosa invasión de Francia y Alemania entre 1944 y 1945 en el frente occidental. En 1951, se convirtió en el primer comandante supremo de la OTAN.

Descendiente de inmigrantes alemanes asentados en Pensilvania, Eisenhower se crio en una numerosa familia en el estado de Kansas y sus padres le dieron una sólida formación religiosa. Se graduó en West Point en 1915 y más tarde se casó con Mamie Doud, con quien tuvo dos hijos. Tras la Segunda Guerra Mundial, Eisenhower fue jefe del Estado Mayor del ejército durante la presidencia de Harry S. Truman y después ejerció como presidente de la Universidad de Columbia. Eisenhower entró en la carrera presidencial de 1952 de la mano del Partido Republicano para contrarrestar las políticas de no intervención defendidas por el senador republicano Robert A. Taft e hizo campaña contra «el comunismo, Corea y la corrupción». Consiguió derrotar por amplio margen al candidato demócrata Adlai Stevenson y así puso fin a dos décadas de hegemonía demócrata y a la llamada «coalición del New Deal». Fue el primer presidente estadounidense en ver sus mandatos constitucionalmente limitados por la Vigesimosegunda Enmienda.

Los principales objetivos de Eisenhower durante su presidencia fueron mantener la presión sobre la Unión Soviética a través de la llamada doctrina Eisenhower y reducir el déficit federal. En el primer año de su presidencia, amenazó con usar armas nucleares en un esfuerzo por poner fin a la guerra de Corea; su nueva imagen política priorizó la construcción en masa de armas nucleares baratas para la disuasión nuclear, mientras reducía los fondos para las fuerzas militares convencionales. Ordenó los golpes de Estado en Irán y Guatemala y negó ayuda material de importancia a Francia en Indochina, aunque sí aportó ayuda financiera y daría un fuerte apoyo económico a la recién creada Vietnam del Sur. El Congreso apoyó su solicitud de 1955 para la resolución de Formosa, lo que obligó a Estados Unidos a apoyar militarmente al gobierno prooccidental de la República de China en Taiwán y mantener el aislamiento de la República Popular China, que dominaba el territorio continental.

Después de que la Unión Soviética pusiera en órbita el primer satélite artificial de la historia en 1957, Eisenhower autorizó la creación de la NASA y con ella el inicio de la carrera espacial. Durante la crisis de Suez de 1956, Eisenhower condenó la invasión israelí, británica y francesa de Egipto, y los obligó a retirarse. A su vez condenó la invasión soviética durante la Revolución húngara de 1956, pero no tomó ningún otro tipo de acción. Envió 15 000 soldados a Líbano en 1958 para evitar el derrocamiento del gobierno prooccidental a manos de una revolución inspirada en los principios del gobierno del presidente egipcio Nasser. Hacia el final de su mandato, sus esfuerzos por celebrar una reunión con los soviéticos se vinieron abajo tras el incidente del U-2. En su discurso de despedida a la nación del 17 de enero de 1961, Eisenhower avisó sobre los peligros del enorme gasto militar del país y en particular sobre el déficit que este generaba y los contratos que el gobierno tenía con los fabricantes privados de armamento, y acuñó el término «complejo industrial-militar».

En Estados Unidos, durante las dos legislaturas de Eisenhower se vivió una considerable prosperidad económica, a excepción de la fuerte recesión de entre 1958 y 1959. Opuesto, aunque no públicamente, a Joseph McCarthy, contribuyó a poner fin al macartismo con un amplio uso de su llamado «privilegio ejecutivo». Conservador moderado, mantuvo los organismos del New Deal y amplió la Seguridad Social. Puso en marcha el Sistema Interestatal de Autopistas, las agencias DARPA y NASA, estableció una sólida educación científica a través de la National Defense Education Act y alentó el uso pacífico de la energía nuclear gracias a la Atomic Energy Act; sin embargo, Eisenhower a menudo dejaba la mayor parte de la actividad política a nivel nacional en manos de su vicepresidente, Richard Nixon.

Aclamado por las encuestas de Gallup como el «hombre más admirado» en doce ocasiones, logró una estima popular generalizada, tanto durante como después de su presidencia. Desde finales del , existe consenso entre los estudiosos occidentales para situar a Dwight Eisenhower como uno de los presidentes de Estados Unidos mejor valorados.

David Dwight Eisenhower (el apellido original alemán es Eisenhauer) nació en la ciudad de Denison, en el estado de Texas, el 14 de octubre de 1890. Eisenhower fue el tercero de los tres hijos del matrimonio formado por Jacob David Eisenhower e Ida Elizabeth Stover. Sus orígenes familiares se hallaban en Alemania, más concretamente en Karlsbrunn, en el Sarre, ya que su antepasado Hans Nicolas Eisenhauer y su familia emigraron desde allí en 1741 hacia Lancaster, en el estado de Pensilvania. Su familia se estableció posteriormente en Abilene, Kansas, en 1892. En 1895 su madre llegó a formar parte de los Testigos de Jehová, habilitando la casa familiar como lugar de reuniones de los Testigos de Jehová entre 1896 y 1915.

A la edad de trece años, sufrió una caída banal que le produjo una ligera herida cortante en una rodilla. No comunicó el hecho a sus padres y a los pocos días la infección habìa llegado hasta la ingle. El médico participante aconsejó la amputación. Dwight enterado de ello alegó que prefería la muerte y le hizo jurar a su hermano menor que no permitiría la amputación, permaneciendo este de guardia frente a la puerta del dormitorio durante más de dos días, sin retirarse siquiera para comer. Tras las oraciones de toda la familia y a sorpresa del médico, comenzó una franca mejoría, que permitió a la postre salvar su pierna.

Aunque su nombre era David Dwight, la familia y amigos le llamaban simplemente Dwight. Más adelante, cambió el orden de sus nombres de pila (según el personal de la Biblioteca y el Museo de Eisenhower, el cambio de nombre se produjo más tarde, cuando se matriculó en la Academia Militar de West Point). Eisenhower se graduó en la "High School" de Abilene en 1909.

En 1911 Eisenhower ingresó en la Academia Militar de West Point. Con ese motivo, al parecer, se relajó su vinculación con los Testigos de Jehová, que no son favorables al uso de las armas.

En 1915 se graduó de la Academia Militar de West Point, con el grado de Subteniente de infantería, pasando a ocupar sus primeros cargos como militar de carrera.
En 1916 participa como teniente en la expedición punitiva para atrapar a Pancho Villa, quien era buscado por Estados Unidos por atacar el pueblo de Columbus.

Durante la Primera Guerra Mundial, en la que Estados Unidos se incorporó a los aliados en 1917, en las últimas fases de la guerra, Eisenhower se encargó del adiestramiento de las tropas reclutadas para su envío al Frente Occidental, sin llegar pues a adquirir experiencia real de combate, aunque alcanzó el grado de mayor para el final de la guerra.

Acabada la guerra, y tras ampliar los estudios efectuados en la Academia Militar, fue destinado al Estado Mayor del Ejército, donde permanecería la mayor parte de su carrera, hasta 1935. La presencia en oficinas de planificación marcaría su carrera posterior, encarada a la planificación de operaciones militares.

En 1935, Eisenhower acompaña a Douglas MacArthur a las Filipinas, donde sirve como asistente militar del gobierno filipino. Durante su estancia en las Filipinas aprende a volar, aunque nunca fue calificado como piloto militar.

Cuando el 7 de diciembre de 1941 los japoneses lanzaron su ataque de Pearl Harbor, Estados Unidos entró en la Segunda Guerra Mundial, formando parte de los Aliados, Dwight Eisenhower ya había ascendido a general, y fue enviado a principios de 1942 a Londres para iniciar contactos con el Ejército británico con el fin de organizar un segundo frente en Europa para luchar contra la Alemania nazi, lo que estaba reclamando la Unión Soviética para reducir la presión que ejercía la Wehrmacht sobre el Ejército Rojo.

Finalmente, se sentaron las bases para un desembarco conjunto de británicos y estadounidenses en el norte de África, la llamada Operación Torch. Para la planificación definitiva de la compleja operación, Eisenhower instaló su cuartel general en el punto más cercano posible, en la base naval británica de Gibraltar, desde donde inició discretos contactos con las autoridades de la Francia de Vichy en Marruecos, Argelia y Túnez para lograr el éxito del desembarco, contactos que llegaron a efectuarse con el almirante François Darlan, uno de los líderes del Gobierno de Vichy (y que el día del desembarco se hallaba presente en Argel), y con Henri Giraud, en quien estadounidenses y británicos veían una posible alternativa a la Francia Libre del general Charles de Gaulle, así como con Alphonse Juin, jefe de las tropas de Vichy en la zona. Los contactos fueron llevados a cabo por Robert Murphy, representante personal del presidente Franklin D. Roosevelt.

Tras el éxito del desembarco, ejecutado el 8 de noviembre de 1942, Eisenhower fue puesto al mando de todas las tropas de los Aliados en la Campaña en África del Norte, quedándole subordinado el general británico Bernard Montgomery, con quien tuvo algunos roces, debido al afán de protagonismo de Montgomery.

Debido al cargo que ocupaba, empezó a ocuparse de diversos aspectos políticos, intentando en un primer momento mantener alejados del norte de África a los partidarios de De Gaulle, con quien los anglosajones ya habían tenido algunos roces. Sin embargo, tras el asesinato en Argel del almirante Darlan el 24 de diciembre de 1942 cometido por el joven gaullista Fernand Bonnier de La Chapelle, desaparecieron esos problemas políticos, reconociendo los franceses de África como jefe a De Gaulle, con lo que Eisenhower pudo ocuparse en planificación del siguiente paso militar, la campaña de Túnez, lugar a donde se había retirado el Afrika Korps del mariscal Erwin Rommel, que había recibido mientras tanto importantes refuerzos.

A pesar del mal inicio de la campaña, con la derrota sufrida por el II Cuerpo de Ejército estadounidense en el paso de Kasserine el 16 de febrero de 1943, Eisenhower, que había reclamado al general George Patton para que asumiese el mando del II Cuerpo tras la derrota en el paso de Kasserine, logró la capitulación de las tropas del Eje en África el 13 de mayo de 1943.

Para el regreso a Europa de las tropas aliadas, se eligió la zona de Sicilia, que ofrecía claras ventajas: se atacaba a Italia, el miembro más débil de la alianza nazi-fascista, en su propio territorio, cerca de las bases establecidas por los Aliados en el norte de África recién conquistado, y se daba un paso definitivo para el control del mar Mediterráneo, expulsando de él a los alemanes. Era además una buena oportunidad para probar las capacidades de los Aliados para llevar a cabo una operación militar de gran envergadura, con la vista puesta en el futuro.

Eisenhower decidió que la Operación Husky, nombre que recibió la invasión, fuese llevada a cabo conjuntamente por tropas británicas y estadounidenses, para lo que se creó un Grupo de ejércitos, el 15.º Grupo de Ejércitos, a cuyo frente se puso al mariscal británico Harold Alexander, que estaría formado por el 7.º Ejército estadounidense, mandado por George Patton, y el 8.º Ejército británico, al mando de Bernard Montgomery. Por su parte, el Eje contaba con tropas italianas, el 6.º Ejército, al mando del general italiano Alfredo Guzzoni, pero también con el 14.º Ejército alemán al mando del general Albert Kesselring, estando nominalmente al frente de todas las tropas del Eje en la isla el italiano Guzzoni.

Por otra parte, con el fin de reducir el coste en vidas humanas de la operación, se iniciaron discretos contactos con la mafia, a través de Lucky Luciano, quien a la sazón se hallaba encarcelado en Nueva York. Los contactos fructificaron, debido además a que el Fascismo había mostrado su radical voluntad de acabar con la mafia.

Finalmente, el 10 de julio de 1943, con un importante despliegue aéreo y naval, se efectuaron los desembarcos previstos, iniciándose una carrera entre jefes de los dos ejércitos Aliados por ver quién llegaba antes a Mesina dando por acabada la campaña. Patton resultó vencedor en esta lucha personal con Montgomery, entrando en Mesina el 17 de agosto.

Con la toma de Sicilia quedaba despejado el camino para seguir el avance, ahora a través de un desembarco en la península italiana.

Siempre desde su cuartel general, que había instalado en Argel, Dwight D. Eisenhower inició pues la planificación del siguiente paso, la invasión de Italia, con el objetivo puesto en apartar a Italia de la guerra, provocando la caída del régimen fascista de Benito Mussolini. Sin embargo, las circunstancias se precipitaron debido al hecho de que Mussolini fue defenestrado por una mayoría de los miembros del Gran Consejo Fascista, el máximo órgano del Partido Nacional Fascista italiano, en una operación urdida por el rey Víctor Manuel III, tras lo cual se iniciaron conversaciones secretas en Lisboa con vistas a la firma de un armisticio, a solicitud de los italianos.

Las conversaciones acabaron por desembocar en la firma del armisticio de Cassibile, por el cual Italia abandonaba su alianza con el Tercer Reich, aunque los italianos rogaron que la firma del armisticio permaneciese en secreto hasta el desembarco en Italia de las tropas de los Aliados. En cumplimento de los acuerdos pactados, el 3 de septiembre de 1943 los Aliados cruzaron desde Sicilia el estrecho de Mesina, ocupando sin excesiva oposición italiana el puerto de Mesina. Se trataba de una estrategia sumamente conservadora, ya que las circunstancias posiblemente hubiesen permitido el desembarco en algún lugar más al norte, con lo que la campaña de Italia que tuvo lugar a continuación hubiese sido mucho menos lenta.

En cualquier caso, los acontecimientos en Italia se precipitaron. Por un lado, Mussolini fue liberado por los alemanes del confinamiento a que se encontraba sometido, formando la llamada República Social Italiana, que seguía colaborando con la Alemania nazi. Por otro, el mariscal Pietro Badoglio, aunque mantenido aparte por los Aliados, intentó organizar un Ejército italiano que luchase junto con las tropas de los Aliados. Finalmente, se avanzó lentamente hacia el norte, tan lentamente que en diciembre los Aliados se vieron frenados unos 100km al sur de Roma por las defensas apresuradamente preparadas por los alemanes en la "Línea Gustav".

El 28 de noviembre de 1943 se inició en Teherán (Irán) la llamada Conferencia de Teherán, celebrada con asistencia de los tres principales líderes políticos de los Aliados: Churchill por los británicos, Roosevelt por los estadounidenses y Stalin por los soviéticos. Entre los varios acuerdos tomados en la misma, destacaba el de la apertura de un segundo frente en Europa, que debería añadirse al ya existente en Italia y al Frente Oriental, a petición de Stalin, ya que el Ejército Rojo estaba llevando el peso de la lucha en Europa contra la Wehrmacht.

Puesto que los Estados Unidos iban a ser los suministradores de la mayor parte de los hombres que tomarían parte en el previsto desembarco, y puesto que la mayor parte del material militar con el que estarían equipadas las tropas iba a ser estadounidense, se decidió que fuese también un estadounidense quien estuviese al mando de la operación y de sus preparativos. Roosevelt no deseaba desprenderse de su consejero militar, el general George Catlett Marshall, con lo que finalmente optó por encargar la planificación y ejecución de la operación a un hombre que ya había probado sus dotes de planificación y de mando en las campañas en el norte de África y en Italia. Otra alternativa hubiese sido el general George Patton, pero la mala imagen que arrastraba desde algunos incidentes en Sicilia y los enfrentamientos que había sostenido con el general británico Bernard Montgomery hicieron que se le relegase, aunque se le encargó poner a punto un "ejército fantasma" simulado con el que se iba a encubrir la operación real, amenazando a los alemanes con una posible invasión en la zona de Calais, la Operación Fortitude, tarea en la que Patton obtuvo un éxito total.

Eisenhower se encargó pues de planificar las operaciones militares del Desembarco de Normandía, el 6 de junio de 1944, así como de efectuar todos los contactos políticos necesarios en función de la gran complejidad de la operación y del gran número de países Aliados que participaron en la operación: Francia Libre, Bélgica, Luxemburgo, Holanda, Checoslovaquia, Polonia o Grecia tuvieron participación, además de Estados Unidos y el Reino Unido, sin olvidar a dominios británicos como Canadá, Sudáfrica, Nueva Zelanda o Australia, además de la India. También participaron Brasil y otros países aportaron voluntarios como Argentina y Uruguay. Basta la mera enumeración de países cuyas unidades militares tomaron parte en el desembarco y las operaciones subsiguientes para comprender la enormidad de la tarea.

El general Eisenhower y su equipo de ayudantes eligieron la costa de Normandía para el desembarco, prefiriéndola a otras posibles alternativas. Especialmente interesante era el hecho de que las playas en las que se realizaría el desembarco quedaban dentro del radio de acción de los aviones con base en Gran Bretaña, sin olvidar que en el canal de la Mancha era muy fácil lograr una absoluta supremacía aérea y naval para los Aliados.

La planificación de la operación, la mayor operación de desembarco de tropas llevada a cabo hasta hoy en día, supuso un esfuerzo considerable, para el que se tuvieron en cuenta innumerables factores: desde los climatológicos, con análisis de las condiciones meteorológicas previstas en la zona de desembarco en la fecha del mismo y en los días posteriores, hasta la forma de abastecer a las tropas una vez desembarcadas, para lo que se llegó a diseñar puertos artificiales (puertos Mulberry) o incluso un oleoducto que trasladaría el carburante necesario a través del canal, PLUTO, pasando por el diseño y construcción, por parte de los británicos, de carros de combate especializados pensados especialmente para apoyar y facilitar el desembarco.

Sin embargo, pese a las dotes diplomáticas de Eisenhower, se plantearon graves problemas respecto de la Francia Libre de Charles de Gaulle, ya que los franceses entendían que se les dejaba al margen de la toma de decisiones. Presionado por Winston Churchill, Eisenhower se negó a otorgar mayor protagonismo a los franceses libres hasta que se hubiesen celebrado elecciones en Francia. Estos hechos comportaron consecuencias de cara a la situación posterior en la campaña de Francia, especialmente en agosto de 1944, al tratarse la posible Liberación de París.

La operación planificada comportaba un desembarco en cinco playas distintas, con los siguientes nombres en clave: "Utah", "Omaha", "Gold", "Juno" y "Sword". El primer objetivo del desembarco era el de asegurar las propias playas, para lo cual se lanzaron tropas paracaidistas desperdigadas por todo el interior de Normandía, la 82.ª División Aerotransportada y la 101.ª División Aerotransportada estadounidenses y la 6.ª División Aerotransportada británica. La misión de los paracaidistas era la de retrasar o evitar la llegada de refuerzos alemanes, especialmente de las divisiones blindadas desplegadas en la zona de Caen y que el engaño de George Patton con su Operación Fortitude mantenía allí en espera de una hipotética invasión.

Una vez logrado el control de las playas, el objetivo para la semana siguiente a la operación era el de asegurar el interior de Normandía, con la finalidad de garantizar la supervivencia de las tropas desembarcadas, tras lo que se lanzaría un asalto hacia los principales puertos de la zona (especialmente Cherburgo) para poder desembarcar en ellos suministros y nuevas tropas con las que poder desplegar la capacidad de combate en forma de hombres y equipamiento militar de los Aliados.

Tras varios sucesivos aplazamientos, finalmente, aunque Eisenhower seguía teniendo dudas, quedó definitivamente fijado el día de la invasión, el "Día D", para el 6 de junio de 1944.

A pesar de algunos contratiempos, que afectaron en mayor medida a algunas de las playas del desembarco, y a pesar de los temores del propio Eisenhower, finalmente la batalla de Normandía abrió la puerta a la recuperación de la Francia ocupada por los alemanes.

Fue también el impulsor del Programa de Monumentos, Arte y Archivos

Con la consolidación de la presencia militar de los Aliados en Europa tras el exitoso resultado de la batalla de Normandía, "Ike" Eisenhower quedaba acreditado como quien había conducido a la victoria a los Aliados, y ello desde los primeros compases de la presencia en el conflicto de las tropas estadounidenses. Lógicamente, fue el encargado de planificar la siguiente fase de la guerra en el Frente Occidental. Se ponía el acento en el rápido avance hacia el este, presionando a los alemanes en retirada, asegurando el control de la costa del canal de la Mancha, y dejando de lado el interior de Francia. Para completar la presión ejercida, a la vez que para intentar superar la férrea oposición que los alemanes mantenían en Italia, el equipo de Eisenhower planeó un desembarco en el sur de Francia, en la costa del Mediterráneo, lo que sería finalmente la Operación Anvil, realizada el 15 de agosto de 1944.

Respecto de la Liberación de París, Eisenhower pretendía pasar de largo la ciudad de París por el norte, para poder aprovechar la situación de desorganización de la Wehrmacht y alcanzar la línea del río Rin antes de que pudiesen reaccionar y acabar la guerra antes de finalizar 1944.

Sin embargo, el general Charles de Gaulle ordenó en agosto al jefe de la 2.ª División Blindada de la Francia Libre, el general Leclerc, que se dirigiese hacia París, contraviniendo las órdenes del superior de Leclerc, el general estadounidense Leonard T. Gerow, y del propio Eisenhower. De Gaulle pretendía apoyar la sublevación de la población de París, evitando que la misma fuese utilizada como medio propagandístico por el Partido Comunista Francés. Igualmente, De Gaulle buscaba sustraer a Francia de quedar sometida tras la liberación a un Allied Military Government of Occupied Territories (AMGOT), es decir, a un control militar de los anglosajones sobre el país. Finalmente, De Gaulle comprendía que la liberación de París serviría como palanca para lograr no sólo la consolidación de su persona al frente de la Francia Libre sino también la conversión de la propia Francia Libre en el elemento de conexión de Francia con los Aliados vencedores.

No obstante, ante la situación de hecho creada por el avance hacia París de la 2.ª División Blindada francesa en solitario y sin autorización, Eisenhower, aunque molesto al tener que asumir el coste de alimentar a los ciudadanos parisienses tras la liberación, lo que iba a sobrecargar las líneas de suministros de sus ejércitos, se rindió a la evidencia, aceptando los hechos consumados y enviando como respaldo de la operación, además de para obtener réditos políticos y propagandísticos, a la 4.ª División de Infantería estadounidense hacia París.

En cualquier caso, Eisenhower y su equipo dieron comienzo a la planificación a la siguiente fase de la ofensiva, la campaña en Bélgica y los Países Bajos para controlar la desembocadura del Rin.

Tras los resultados de la campaña en Francia, la estrategia diseñada por Eisenhower buscó un equilibrio entre las exigencias de dos de los principales líderes militares de los Aliados, el general británico Bernard Law Montgomery y el general estadounidense George Patton.

Debido a la escasez de suministros, puesto que los Aliados no habían ocupado todavía o no habían logrado poner en servicio ninguno de los grandes puertos franceses del Atlántico, bien en el canal de la Mancha bien en el golfo de Vizcaya, el avance de las tropas hacia Alemania empezaba a reducir su impulso. Por otro lado, el propio Eisenhower había estimado mal la capacidad de resistencia de los alemanes, esperando tardar mucho más tiempo en avanzar hasta la antigua frontera francoalemana del que realmente había sido necesario.

Ante esta situación, Patton pretendía obtener prioridad en el suministro de carburante, recambios y abastecimientos en general para sus tropas, con lo que lograría un avance rápido hacia la frontera alemana, atravesando el río Rin y penetrando en el corazón industrial de Alemania, esperando poner rápidamente fin a la guerra. Adicionalmente, Montgomery debería guardar su flanco, avanzando hacia el valle del Ruhr.

Por el contrario, la visión de Montgomery era diferente, y solicitaba ser él quien recibiese prioridad en los suministros, para avanzar pegado al canal de la Mancha, atravesando Bélgica y los Países Bajos para penetrar por el norte en Alemania, por la desembocadura del Rin. En esta concepción, sería Patton quien guardaría el flanco de Montgomery en su avance.

Es decir, ambos deseaban atribuirse la gloria del avance, y que fuese el otro el que asumiese el trabajo menos brillante.

La decisión inicial de Eisenhower fue pues buscar un equilibrio entre ambas concepciones, con lo que se atuvo al plan inicial, de avance más lento a lo largo de toda la línea del frente. Sin embargo, debido a consideraciones de tipo político para con sus aliados británicos, finalmente Eisenhower optó por dar mayor prioridad de suministros a Montgomery, ya que además esperaba que el avance por la orilla del canal de la Mancha les permitiese a los Aliados la toma del importante puerto de Amberes, solventando así los problemas de falta de suministros.

Finalmente, Montgomery presentó un nuevo plan, que sería el finalmente aceptado por Eisenhower, y que desembocaría en la llamada Operación Market Garden.

La versión definitiva del plan propuesto por Montgomery y aceptado por Eisenhower para la Operación Market Garden era sumamente ambiciosa, comportando dos partes diferenciadas, Market y Garden.

Market era una operación aérea, para la que se utilizaría a tropas paracaidistas británicas, estadounidenses y polacas, que consistía en el lanzamiento de los paracaidistas en una serie de puentes a lo largo de Bélgica y los Países Bajos, con la misión de tomarlos antes de que fuesen destruidos por los alemanes, conservándolos intactos en su poder hasta la llegada de las tropas terrestres de los Aliados.

Garden era una operación terrestre, que suponía el avance rápido en columna de las tropas Aliadas, a la mayor velocidad posible, relevando a su llegada a los paracaidistas y asegurando la zona, siguiendo inmediatamente al siguiente puente, como si los paracaidistas hubiesen tendido una alfombra a través de la cual se desplazasen las tropas terrestres, atravesando definitivamente el Rin.

Ciertamente, el plan ofrecía una serie de ventajas en caso de realizarse con éxito. En primer lugar, permitiría controlar el vital puerto de Ámsterdam, poniendo fin definitivamente a la penuria de suministros. En segundo lugar, se habría evitado forzar la Línea Sigfrido, barrera defensiva establecida en sus fronteras por los alemanes, y que se pensaba que estaba bien protegida. En tercer lugar, esta estrategia iba a permitir tomar los puntos de lanzamiento de los cohetes V-2 alemanes contra Londres y los puertos y ciudades ingleses. Y para terminar, se lograría avanzar en un sector que se hallaba protegido al norte por las costas del canal de la Mancha y del mar del Norte, que se hallaba además más cercano a las bases aéreas de la Royal Air Force y de la USAAF en el Reino Unido.

Sin embargo, el plan adolecía de muy graves defectos. En primer lugar, la propia complejidad de la operación hacía que cualquier mínimo imprevisto afectase muy negativamente a las siguientes fases de la operación, como de hecho así sucedería posteriormente. La marcha de las tropas de tierra a través de una única carretera practicable, en una zona situada a veces bajo el nivel del mar y muy fácilmente inundable favorecía la defensa alemana. Puesto que la operación era en realidad una carrera contrarreloj, cualquier retraso sería fatal para los paracaidistas lanzados en los puntos más lejanos de la línea de avance prevista.

En segundo lugar, se produjo un fallo de gran alcance en los servicios de información aliados, que minusvaloraron la calidad y cantidad de las tropas alemanas desplegadas en la zona. Mientras que según los servicios de información se trataba de tropas escasas, mal equipadas y de escasa moral de combate, en realidad se ignoró la llegada a la zona de dos divisiones de las SS, la 9.ª División Panzer SS Hohenstaufen y la 10.ª División Panzer SS Frundsberg, divisiones experimentadas en combate y que ya se habían enfrentado a los Aliados en la batalla de Normandía, y que habían sido enviadas a la zona para reponerse de los combates anteriores.

En definitiva, tal como indica el libro del periodista e historiador Cornelius Ryan dedicado a esta batalla, la operación requería para su completo éxito la toma de un "puente demasiado lejano", el situado en la ciudad holandesa de Arnhem sobre el río Rin.

Finalmente, el 16 de septiembre de 1944 dieron inicio las operaciones, con el bombardeo aéreo de las posiciones alemanas, seguido el 17 a primera hora del lanzamiento de los paracaidistas en los lugares designados. A mediodía, tras saber que los paracaidistas habían tomado la mayor parte de los objetivos asignados, se inició la parte terrestre de la operación, con el avance del XXX Cuerpo de Ejército británico. Aunque el avance fue inicialmente rápido, pronto aparecieron los problemas, ya que algunos de los puentes habían sido destruidos por los alemanes, debiendo tender puentes Bailey los ingenieros británicos, con los consiguientes retrasos que se iban acumulando. Además, el avance directo a través de una única carretera hacía que las constantes escaramuzas ralentizasen todavía más el avance, ya que era necesario eliminar todos y cada uno de los puntos de resistencia alemanes antes de proseguir el avance.

Además, a lo largo de los días siguientes, el mal tiempo impidió el envío de refuerzos y suministros a las unidades paracaidistas, con lo que las tropas de la 1.ª División Aerotransportada británica, que habían sido lanzadas en el extremo más alejado hacia el norte de la operación, en Arnhem, no pudieron recibir suministros ni refuerzos, además de constatar que por defectos de diseño sus radios no les permitían comunicarse con sus bases en la retaguardia y ni siquiera entre sí. Con mucho retraso, y cuando la situación ya era insostenible, recibieron como refuerzo a la 1.ª Brigada Independiente de Paracaidistas polacos, al mando del general Sosabowski, cuando ya sólo podía lograrse incrementar el número de bajas y prisioneros con dicho lanzamiento.

El día 25 de septiembre se dio la orden de retirada a los británicos y polacos que se hallaban combatiendo en Arnhem, sin que se hubiese pues logrado la conquista de una cabeza de puente al otro lado del río Rin como pretendía la operación, que se saldó pues con un fracaso respecto de los planteamientos iniciales.

Tras el fracaso en el avance que había supuesto la Operación Market Garden, con la llegada del invierno Eisenhower dio por terminadas las operaciones de envergadura, dedicándose a la consolidación de los territorios recuperados desde la partida de Normandía un par de meses antes, así como a la acumulación de recursos para reemprender el avance con el buen tiempo.

Sin embargo, el respiro fue también aprovechado por los alemanes, a la vez que Adolf Hitler encargaba a Gerd von Rundstedt la preparación de una contraofensiva, que pretendía que expulsase a los Aliados de Bélgica, los Países Bajos y Luxemburgo, tomando el puerto de Amberes y soñando incluso con una reedición de la batalla de Francia en 1940 que volviese a abrir a los alemanes las puertas de París. La contraofensiva fue denominada por los alemanes "Operación Wacht Am Rhein", y dio lugar a la batalla de las Ardenas.

En consecuencia, el 16 de diciembre de 1944 el 5.º Ejército Panzer, con siete divisiones, y el 6.º Ejército Panzer, con nueve divisiones, lanzaron un ataque, que arrolló a las primeras líneas defensivas de los Aliados, formadas por tropas inexpertas del Ejército estadounidense. El avance alemán estaba protegido en sus flancos por el 15.º Ejército y por el 7.º Ejército. El ataque produjo el desconcierto entre los Aliados, incluyendo a Eisenhower, ya que se pensaba que los alemanes estaban escasos de tropas y de recursos y, además, bajos de moral. Una de las claves de los primeros éxitos de los alemanes fue el mal tiempo, que impidió el despegue de la aviación aliada, para labores de observación del avance y para castigar a las columnas alemanas en marcha.

Tras unos primeros momentos en que cundió la alarma entre los Aliados, Eisenhower ordenó a las tropas del Tercer Ejército de Estados Unidos de George Patton, que se hallaban al sur, en la zona de la Lorena, y al Noveno Ejército de Estados Unidos del general William Hood Simpson, que se hallaba al norte de la zona atacada, que apoyasen al Primer Ejército de Estados Unidos de general Courtney Hodges, que era el que estaba soportando la parte principal de la ofensiva. Finalmente, tras la mejora del buen tiempo, que permitió la actividad aérea de los Aliados, y el agotamiento de las reservas de combustible de la Wehrmacht, que fracasó en conseguir capturar los almacenes de suministros Aliados, la batalla se dio por concluida hacia finales de enero de 1945, habiendo supuesto el agotamiento definitivo de la capacidad de los alemanes por mantener una mínima iniciativa estratégica.

Desde la derrota sufrida por los alemanes, pues, quedaban abiertas definitivamente las puertas para el siguiente paso a dar, la invasión del propio territorio alemán, y para el avance hacia el interior de Alemania, para lo cual iba a ser necesario atravesar la importante barrera que suponía el Rin.

Para la invasión de Alemania, Eisenhower tomó la decisión de avanzar por el norte, en las tierras llanas de la cuenca baja del Rin, desestimando las propuestas de Patton de hacerlo más al norte, y concediendo nuevamente el protagonismo a Montgomery.

Así, el 8 de febrero de 1945 dio comienzo la Operación Veritable, ejecutada por Montgomery, con el 2.º Ejército británico y el Ejército canadiense, agrupados en el 21.º Grupo de Ejércitos, para despejar el terreno para preparar el cruce de Rin, en el marco de la llamada Operación Grenade. Aunque en líneas generales Veritable cumplió con lo previsto, los estadounidenses no lograron impedir la destrucción de las presas en el río Ruhr, con lo que la operación se saldó con un fracaso.

Se inició entonces la búsqueda de un puente intacto sobre el río Rin, hasta que se dio con un puente intacto en la localidad renana de Remagen: el puente de Remagen. El puente fue tomado el 7 de marzo de 1945 por tropas de la 9.ª División Blindada estadounidense (Decimosegundo Grupo de Ejército de Estados Unidos, del general Omar Bradley), con lo que Eisenhower, modificando sus previsiones iniciales, ordenó el paso del mayor número de tropas posible a la orilla oriental del río, antes del hundimiento del viejo puente el 17 de noviembre. Aunque posteriormente se logró habilitar otros pasos en el río, la toma de este puente fue la que abrió definitivamente el corazón del territorio alemán a la ofensiva aliada, que se abrió en varias líneas de avance.

Por un lado, se ordenó a los británicos de Bernard Law Montgomery el avance hacia Hamburgo y Dinamarca, mientras que los estadounidenses de George Patton avanzaban por el centro de Alemania, siguiendo camino hasta alcanzar Praga, en Checoslovaquia, al acabar la guerra, no sin protestas de Patton, que deseaba haber avanzado hacia Berlín para arrebatar al Ejército Rojo la gloria de su conquista. Para terminar, tropas estadounidenses y francesas penetraban hacia el sur de Alemania, por Baviera, alcanzando Austria, aunque tampoco lograron llegar a Viena antes que el Ejército Rojo.

Finalmente, tras la batalla de Berlín el almirante Karl Dönitz, que había sucedido a Adolf Hitler tras el suicidio de éste, aceptó la rendición incondicional del Tercer Reich, el 7 de mayo de 1945. Eisenhower recibió en Reims a la delegación alemana enviada para firmar la rendición.

Una vez finalizada la guerra, tras regresar a los Estados Unidos, fue nombrado jefe del Estado Mayor de Ejército, aunque en 1947 solicitó una excedencia en su carrera militar, pasando a ejercer la presidencia de la Universidad de Columbia.

Aún regresó a la carrera militar posteriormente, siendo nombrado en 1950 comandante en jefe de las fuerzas de la Organización del Tratado del Atlántico Norte, en momentos de tensión con la Unión Soviética por coincidir con los inicios de la llamada "Guerra Fría".

Durante su carrera militar, y especialmente en los años de la Segunda Guerra Mundial, Eisenhower había estado siempre más cerca de los despachos en que se trataba de asuntos políticos que de los campos de batalla, con lo que había acumulado una amplia experiencia política en contactos con la mayor parte de la clase política, tanto en Europa como en Estados Unidos.

Por ese motivo, en 1951 Eisenhower aceptó participar en la carrera electoral por la presidencia de los Estados Unidos, en las filas del Partido Republicano, el más próximo a sus ideas políticas. Sin embargo, ya había sido cortejado para las elecciones presidenciales de Estados Unidos de 1948 por ambos partidos, tanto por el Republicano como por el Partido Demócrata, ofreciéndole el presidente Harry S. Truman ocupar la vicepresidencia en su candidatura.

Eisenhower dio inicio en 1951 a una larga campaña, que le condujo a lo largo de 45 de los estados de los Estados Unidos, durante la que buscó especialmente dar seguridades a los ciudadanos estadounidenses, sin jamás mencionar el nombre de su oponente, el demócrata Adlai Stevenson, a la vez que sistemáticamente se dedicaba a criticar los resultados de las presidencias demócratas anteriores.

Centró su campaña en tres temas principales: poner fin al estado de corrupción que, según él, reinaba en la clase política; poner fin a la Guerra de Corea; y acabar con la subversión que suponía, en su opinión, el comunismo.

Durante las primarias internas del Partido Republicano, Eisenhower se impuso a sus adversarios: el senador por Ohio Robert A. Taft, el gobernador de California Earl Warren, el gobernador de Minnesota Harold Stassen, el general Douglas MacArthur y el gobernador Thomas E. Dewey, recibiendo en la primera vuelta de la Convención del Partido Republicano el voto de 595 delegados y el de 845 delegados en segunda vuelta.

Para la campaña eligió como vicepresidente a Richard Nixon, quien fue acusado en la misma campaña de malversación de fondos, aunque logró zafarse de la acusación. Eisenhower recibió igualmente el apoyo del ultraconservador senador Joseph McCarthy, presidente del Comité de Actividades Antiestadounidenses, quien afirmaba que la clase política demócrata estaba completamente infiltrada por agentes comunistas al servicio de la Unión Soviética.

En las elecciones del 4 de noviembre de 1952, la pareja Eisenhower-Nixon logró 34075529 votos, el 55,2% del electorado, con 442 delegados, mientras que los candidatos demócratas, Adlai Stevenson y John Sparkman, lograron 27375090 votos, el 44,3% del censo, con 89 delegados. Eisenhower logró la victoria en la mayor parte de los estados, salvo en los estados del sur.

Como consecuencia de su victoria, el 20 de enero de 1953 Dwight D. Eisenhower fue investido como 34.º presidente de los Estados Unidos, teniendo como vicepresidente a Richard Nixon. La política exterior de Eisenhower estuvo fuertemente marcada por el secretario de Estado John Foster Dulles (hasta 1959).

Uno de los primeros actos de su mandato fue la creación, el 1 de abril, de un Ministerio de la Salud, Educación y Asuntos Sociales. El 22 de abril firmó la ley de las tierras sumergidas, que sustraía a los estados el control de los recursos mineros existentes en las aguas territoriales del país para atribuirlo al Gobierno federal, lo que comportaba la atribución de las concesiones de explotación de las plataformas petrolíferas.

El 26 de julio de ese mismo año de 1953, Eisenhower dio cumplimiento a una de sus promesas electorales, la de poner fin a la Guerra de Corea, mediante la firma de un armisticio que consagró la división del país en dos estados, separados por el paralelo 38: Corea del Norte y Corea del Sur. El 1 de agosto, prosiguiendo con sus medidas de tipo social, firmó una prórroga de la ley sobre el seguro médico; y el 7 de agosto, una ley por la que Estados Unidos recibiría a 241000 refugiados, a añadir a la cuota normal de inmigración fijada por las leyes.

El 8 de octubre, Eisenhower anunció que la Unión Soviética había hecho explotar su primera bomba de hidrógeno. El 8 de diciembre propuso en un discurso ante la Organización de las Naciones Unidas ("Átomos para la Paz") el uso de la energía nuclear con fines pacíficos, lo que desembocaría en la creación de la Organismo Internacional de Energía Atómica (AIEA).

El 23 de abril de 1954 (y hasta el 17 de junio), el senador McCarthy pasó a presidir una Comisión encargada de la eliminación de los simpatizantes comunistas en el seno del Ejército de los Estados Unidos. No obstante, en esas mismas fechas Eisenhower rechazó apoyar directamente a Francia en la Guerra de Indochina que mantenía con el Viet Minh para no extender el conflicto, aunque proveyó a Francia del material de guerra necesario llegando a las dos terceras partes del material de guerra usado al final; guerra que concluyó tras la derrota francesa en la batalla de Dien Bien Phu en mayo con la Conferencia de Ginebra, por la que Francia abandonaba Indochina, aceptándose la división del país en dos mitades, como había sucedido en Corea: Vietnam del Norte y Vietnam del Sur; apoyándose económica y militarmente al sur frente al norte comunista.

El 13 de mayo, Eisenhower firmó un acuerdo con Canadá que permitía la apertura de una vía de comunicación marítima entre la región de los Grandes Lagos y el océano Atlántico, a través del río San Lorenzo.

El 16 de marzo de 1955, Eisenhower declaró que los Estados Unidos estaban dispuestos a utilizar sus armas nucleares en caso de un conflicto con la China comunista. El 21 de julio propuso en Ginebra, en el curso de una Conferencia entre las grandes potencias, un derecho a sobrevolar las instalaciones militares de otros países para fomentar de ese modo una confianza mutua.

El 24 de septiembre de 1955 sufrió un ataque cardíaco, a pesar de lo cual el 29 de febrero de 1956 anunció públicamente que optaría a un segundo mandato presidencial, para lo cual intentó (sin éxito) convencer a Richard Nixon de que no le acompañase como vicepresidente.

En fecha 6 de febrero de 1956, el presidente Eisenhower aprobó la creación de la PFIAB (President's Foreign Intelligence Advisory Board o Junta Asesora de Inteligencia Exterior del Presidente, una Agencia de la Oficina Ejecutiva del Presidente cuya misión es la de asesorar al presidente del país respecto de los datos e informaciones recabados por otras agencias gubernamentales. Eisenhower nombró como primer presidente de la nueva Agencia a James Killian.

El 31 de mayo de 1956, Eisenhower autorizó que los aviones espía U-2 efectuasen vuelos secretos de espionaje sobre el territorio de la Unión Soviética. El 29 de junio aprobó la creación de una red de autopistas sometidas al control del Gobierno federal, cuya misión en principio era la de servir a la defensa de la nación.

El 1 de octubre de 1956 Eisenhower aprobó una medida de largo alcance, al suprimir la normativa que obligaba a los negros a ceder su asiento a los blancos en el transporte público.

Tras haber anunciado su presentación a la reelección, Eisenhower fue elegido sin oposición candidato a las elecciones presidenciales de 1956 por el Partido Republicano en la Convención Nacional Republicana de 1956, celebrada en San Francisco. Como candidato para la vicepresidencia iba nuevamente acompañado de Richard Nixon, a pesar de haberle insistido para que no se presentase. El Partido Demócrata eligió nuevamente como candidato a la presidencia a Adlai Stevenson, gobernador de Illinois, acompañado de Estes Kefauver, senador por Tennessee, como candidato a la vicepresidencia.

Durante la campaña electoral, Eisenhower se vio reforzado por dos crisis internacionales, la Revolución húngara de 1956 y la Guerra del Sinaí, en la que Eisenhower dejó a su suerte a Francia y Reino Unido, sin intervenir en el conflicto. Adlai Stevenson basó su campaña en un aumento del gasto social y en acuerdos con la Unión Soviética.

En las elecciones, el dúo Eisenhower-Nixon obtuvo 35.579.180 votos, el 57,4% de los votos, y 457 compromisarios, mientras que la pareja formada por Stevenson y Kefauver obtuvo 26028028 votos, es decir, el 42,0%, con sólo 73 delegados.

El 5 de enero de 1957, Eisenhower definió la línea geopolítica de los Estados Unidos, especialmente en lo relativo a la situación en Oriente Medio y Extremo Oriente, la "doctrina Eisenhower", que comportaba igualmente apoyo económico a los países que se viesen amenazados por la expansión comunista. El 20 de enero tomó posesión para su segundo mandato como presidente de los Estados Unidos.

El 9 de septiembre, Eisenhower firmó una ley sobre derechos civiles, siendo la primera de dicho tipo que se aprobaba desde los tiempos de Abraham Lincoln. El 25 de noviembre padeció un segundo ataque cardíaco.

El 31 de enero de 1958, los Estados Unidos lanzaron al espacio exterior su primer satélite artificial, el Explorer 1, habiendo sido adelantados por el programa espacial soviético, que había lanzado el Sputnik 1 el 4 de octubre de 1957. El siguiente 2 de abril, Eisenhower propuso la creación de una Agencia civil estadounidense encargada del programa espacial estadounidense, aprobándose la creación de la NASA el 29 de julio de 1958. La medida fue consecuencia de creer Eisenhower y su equipo de colaboradores que la carrera espacial con la Unión Soviética era esencial para la seguridad de los Estados Unidos.

El 3 de enero de 1959 se incorporó a los Estados Unidos como un estado de pleno derecho el estado número 49.º, Alaska, mientras que el 21 de agosto se incorporó el número 50, Hawái.

Del 15 al 27 de septiembre el secretario general del Partido Comunista de la Unión Soviética, Nikita Jrushchov, giró una visita oficial a los Estados Unidos. Del mismo modo, el gobierno estadounidense se acercó a América Latina, participando en la fundación del Banco Interamericano de Desarrollo.

El 1 de mayo de 1960, un avión espía estadounidense U-2 fue derribado por la artillería del Ejército Rojo mientras sobrevolaba la Unión Soviética en una misión de espionaje, lo que trajo como consecuencia la anulación de la cumbre entre las dos grandes potencias, Estados Unidos y a Unión Soviética, que estaba previsto se celebrase dos semanas más tarde en París; por otro lado, se produjo un incremento de la tensión en las relaciones entre ambos países.

Finalmente, el 8 de noviembre de 1960, John Fitzgerald Kennedy, el candidato del Partido Demócrata, derrotó en las elecciones presidenciales de Estados Unidos de 1960 a Richard Nixon, el vicepresidente de Eisenhower, que había sido elegido candidato en las elecciones por el Partido Republicano.

El 17 de enero de 1961, Eisenhower pronunció la alocución final (retransmitida por televisión) de su mandato,

acuñando en la misma una frase que se hizo célebre, que advertía de la peligrosa influencia del reciente complejo industrial-militar de los Estados Unidos, aunque el propio Eisenhower admite en ese mismo discurso que se trata de un elemento necesario para la defensa de la nación, pero entendiendo que su existencia debe conjugarse con una sabia y vigilante tutela activa por parte de la ciudadanía, para que los fines de dicho complejo concuerden con los ideales de libertad y democracia a los que necesariamente deben servir.

En materia de política exterior, las dos administraciones de Eisenhower estuvieron marcadas por una política de contención y de firmeza ante la Unión Soviética, en un contexto claramente dominado por la Guerra fría. Ello tuvo entre sus consecuencias inmediatas una expansión de la carrera de armamentos con la Unión Soviética, y la consolidación y expansión del armamento nuclear estadounidense. Esta situación generó en el mundo un estado de temor permanente ante la posibilidad de que cualquiera de las dos potencias presionara el botón que desencadenaría un ataque nuclear.

Sin embargo, con la muerte de Stalin en 1953, Eisenhower comprendió que ese hecho iba a modificar las relaciones Este-Oeste, y se prestó a un relajamiento de la tensión entre los dos grandes bloques políticos y militares mediante la firma de los acuerdos que pusieron fin a la Guerra de Corea (27 de julio de 1953), a la vez que rechazaba comprometerse junto con Francia en la Guerra de Indochina que los franceses mantenían con el Viet Minh, y su apoyo se redujo al envío de material de guerra. Tras la derrota de Francia, la independencia de Camboya y Laos y la partición del Vietnam en dos estados, Vietnam del Norte y Vietnam del Sur, sembró a su vez la semilla para el inicio poco después de la Guerra de Vietnam, en la que los Estados Unidos se implicaron profundamente al sostener el régimen del sur contra el norte comunista.

Sin embargo, aunque de puertas afuera se presentaba esa política de contención de los enfrentamientos, paralelamente se llevaron a cabo diversas acciones encubiertas, llevadas a cabo por la CIA, destacando el derrocamiento en agosto de 1953 del primer ministro izquierdista iraní, Mohammad Mosaddeq, que había nacionalizado el petróleo iraní el 20 de marzo de 1951, y el establecimiento de una dictadura por parte del sah Mohammad Reza Pahlavi con el apoyo de los Estados Unidos. También destacó el derrocamiento en junio de 1954 del gobierno de Jacobo Arbenz Guzmán en Guatemala, el golpe de estado en Vietnam del Sur en abril de 1955 y el establecimiento de la dictadura de Ngo Dinh Diem y el intento de golpe de estado en Indonesia en 1958. También se apoyó discretamente la Revolución húngara de 1956, aunque sin ninguna implicación directa en un país que era miembro del Pacto de Varsovia. Igualmente, "marines" estadounidenses desembarcaron en el Líbano en 1958.
Dentro de su doctrina de contención militar respecto de la Unión Soviética, impulsó todo un conjunto de pactos militares de tipo regional, para configurar un "cordón sanitario" alrededor de la URSS: Pacto de Bagdad ( CENTO), SEATO impulsó al rearme de las Fuerzas Armadas de la República Federal Alemana Bundeswehr y la creación de la OTAN.

Eisenhower estableció una política pacifista pero sin perder firmeza ante la Unión Soviética lidiando con un congreso en que la política de persecución contra simpatizantes comunistas llegaba a niveles paranoicos.

En 1959, Eisenhower recibió a Nikita Jrushchov en suelo estadounidense y sostuvieron un diálogo sobre las situaciones que mantenían el presente estado de tensión entre las potencias. Ike manifestó a Nikita que sus militares lo presionaban a lo que el líder soviético manifestó la misma situación, entonces Eisenhower dijo: "-Tenemos que hacer un pacto-." Este episodio representa fielmente el carácter transparente de Eisenhower y que contribuyó a que la llamada Guerra Fría no fuese más que un temor omnipresente en el concierto mundial. Temor que perduraría más de 30 años más.

Por otra parte, ante el éxito del programa espacial soviético, que logró lanzar al espacio el primer satélite artificial (el Sputnik 1, el 4 de octubre de 1957), creyendo que la superioridad soviética en el espacio podría comprometer en el futuro la seguridad de los Estados Unidos, impulsó un programa espacial estadounidense, que se inició el 31 de enero de 1958, con el lanzamiento exitoso al espacio del satélite Explorer 1, y que se desarrolló con la creación de la NASA el 29 de julio siguiente. Todo ello desembocó en la llamada "carrera espacial" mantenida entre los Estados Unidos y la Unión Soviética paralelamente a la carrera de armamentos que ya mantenían desde el final de la Segunda Guerra Mundial.
Eisenhower declaró que la NASA dirigida completamente por civiles era el uso pacífico del espacio exterior y para la expansión del conocimiento humano. De hecho, usó un programa llamado SCORE donde un satélite que llevaba grabada su voz anunciaba mediante el uso de las ondas de radio al mundo, un mensaje de buena voluntad que ayudó mucho a relajar la tensión mundial.

En lo relativo a los aspectos de política interior, los mandatos del presidente Eisenhower se caracterizaron por una relativa prosperidad económica, así como por el relanzamiento del consumo tras los años de cierta restricción debido a la Segunda Guerra Mundial. Su gran impulso a la red de autopistas del país (es el responsable de la existencia de casi 65.000 km de autopistas) contribuyó a la mejora de las comunicaciones entre los diversos estados, comportando un impacto en el modo de vida estadounidense. Por otra parte, dotó de un cierto impulso a algunos programas sociales, extendido por ejemplo el seguro médico, extendiendo la jubilación para las mujeres a los 62 años o incrementando los derechos sindicales.

El aspecto más controvertido sucedido durante sus mandatos lo constituye el senador Joseph McCarthy, creador del "Macarthismo" a través del Comité de Actividades Antiestadounidenses. El senador, aunque jamás logró obtener ninguna inculpación de ningún supuesto espía soviético infiltrado en la Administración, sí que era considerado por muchos ciudadanos estadounidenses un valladar contra una presunta infiltración comunista. Eisenhower recibió el apoyo de McCarthy en la primera elección presidencial, en 1952; sin embargo, si bien nunca se enfrentó frontalmente con él, sí que mantuvo ciertas distancias. Cuando McCarthy intentó una nueva "caza de brujas" en el Pentágono, los dirigentes del Ejército de los Estados Unidos y el propio Eisenhower maniobraron hasta lograr que el Senado de los Estados Unidos aprobase un voto de censura contra el senador McCarthy en 1954, lo que quebró abruptamente el "macarthismo". No obstante, las actividades del senador McCarthy supusieron graves consecuencias para muchas personas acusadas injustamente, siendo el caso más claro el de Julius y Ethel Rosenberg, acusados de espionaje y ejecutados el 19 de junio de 1953.

Durante su mandato igualmente comenzó a despuntar el conflicto racial entre negros y blancos, propiciado por el conjunto de cambios sociales producidos en el país en los años de la Segunda Guerra Mundial. Para desactivar el problema, sus gobiernos aprobaron y propiciaron algunos cambios legislativos, como una decisión de la Corte Suprema en mayo de 1954 prohibiendo la segregación racial en las escuelas o la admisión de una estudiante de raza negra en 1955 en una universidad de un estado del profundo sur, Alabama. Fue la época del nacimiento del Movimiento por los Derechos Civiles en Estados Unidos, dirigido por Martin Luther King.

Por último, uno de los aspectos destacados de su política interior fue el fortalecimiento del Gobierno federal, en detrimento de los poderes de los estados. Ello se manifestó en la ley sobre el control federal de las aguas territoriales o en la ley que propugnó la misma medida respecto de las autopistas. La propia situación de lucha por los derechos civiles propició el incremento del poder federal, aunque éste no logró asegurar el cumplimento total de las leyes de integración racial.

Concluido su segundo mandato, Eisenhower fue muy solicitado para dictar conferencias y para diversas actividades (incluyendo el asesoramiento de sus sucesores en la presidencia), a la vez que se dedicó a la preparación de sus "Memorias". Dwight D. Eisenhower falleció el 28 de marzo de 1969 en el "Walter Reed Army Hospital" de Washington.

Eisenhower contrajo matrimonio con Mamie Geneva Doud (1896-1979), natural de Denver, en Colorado el 1 de julio de 1916. La pareja tuvo dos hijos: Doud Dwight Eisenhower (1917-1921) y John David Sheldon Doud Eisenhower (1922-2013). Mamie llegó a ser muy querida por la opinión pública estadounidense por su rol de abnegada esposa del comandante de las Fuerzas Aliadas.

Sin embargo, la tremenda responsabilidad de Eisenhower en los días previos a la Operación Overlord venía acompañada de una solitaria vida privada lejos de su patria en guerra. Ike confesó, en aquellos aciagos días, en algunas cartas dirigidas a su esposa, que se sentía solitario (de compañía femenina).

Eisenhower había ordenado un cambio en el "staff" de chóferes soldados asignados a la oficialidad del ejército, el cambio era la sustitución de hombres por mujeres soldados enviando a los hombres a un puesto activo en combate. El cadillac de Eisenhower fue entonces conducido por la sargento Kay Summersby, quien congenió rápidamente con su superior. No solo fue su chofer personal, sino también su secretaria privada. Acompañó a Eisenhower por casi todos los escenarios y cuando Eisenhower descansaba, Summersby lo acompañaba a veces y podían conversar temas que no estaban relacionados con el escenario bélico. Se enamoraron y la relación entre Eisenhower y la sargento Summersby se tornó íntima, convirtiéndose en amantes aunque manteniendo su relación en el más completo anonimato posible.

Para cuando terminó la guerra, "Ike" Eisenhower logró la visa y nacionalidad estadounidense para su secretaria personal y siguieron frecuentándose.

Para esa época, Eisenhower pensó seriamente la posibilidad de divorciarse de Mamie y casarse con Summersby; pero la negativa de George Marshall y la posterior posibilidad de postularse como presidente de los Estados Unidos con grandes posibilidades de ganar la alta posición y los consejos de cercanos políticos del partido Republicano al cual pertenecía lo hicieron desistir y la relación terminó sin volver a verse nunca más. Eisenhower continuó casado con Mamie hasta su muerte en 1969, Summersby falleció en 1975 no sin haber dado la autorización para publicar un libro donde detalla la relación íntima con el entonces comandante supremo de las Fuerzas Aliadas.

De su matrimonio con Mary "Mamie" Geneva Doud, Dwight D. Eisenhower tuvo dos hijos:


Robert Duvall lo encarnó en la película "Ike" (1979). Tom Selleck protagonizó la película para televisión llamada "Ike: Countdown to D-Day" (2004), en la cual el actor interpreta a Eisenhower durante los 90 días previos al Día D.






</doc>
<doc id="21398" url="https://es.wikipedia.org/wiki?curid=21398" title="Lyndon B. Johnson">
Lyndon B. Johnson

Lyndon Baines Johnson (Stonewall, Texas, 27 de agosto de 1908-ibídem, 22 de enero de 1973), conocido por sus iniciales, LBJ, fue el trigésimo sexto Presidente de los Estados Unidos, asumiendo el cargo tras la muerte de su predecesor John F. Kennedy en 1963 y ocupándolo hasta 1969.

De modestos orígenes, Johnson inició su carrera política en 1937, al ser elegido para la Cámara de Representantes por Texas como miembro del Partido Demócrata; luego fue electo senador en 1949 y rápidamente escaló puestos hasta asumir como jefe del bloque demócrata del Senado en 1953, cargo que ocuparía hasta su elección como Vicepresidente. Kennedy le incorporó a su candidatura presidencial como vicepresidente en virtud de su experiencia parlamentaria y de sus orígenes sureños; de modo que, tras la victoria electoral de 1960, se convirtió en vicepresidente en 1961.

Johnson lideró a los demócratas del Senado durante la totalidad de los ocho años de la administración republicana de Eisenhower, como líder de la minoría en los dos primeros años y como líder de la mayoría de los últimos seis. Al dirigir una estrecha mayoría, Johnson confió en su poder de persuasión para mantener unida a la bancada demócrata y reunir más votos entre los senadores republicanos. Como líder de la mayoría, Johnson jugó un papel decisivo en la aprobación de las primeras leyes de derechos civiles en más de ochenta años en 1957 y 1960. Un ataque al corazón en 1955 amenazó con poner fin a su carrera política, pero se recuperó totalmente y reasumió sus funciones. La elevación de Johnson a la vicepresidencia dejó su escaño en el Senado vacante en 1961, y el republicano John G. Tower ganó una elección especial para sucederle.

En 1952 y 1956, Johnson había intentado pero no logró ser nombrado vicepresidente en la fórmula demócrata, refiriéndose a sí mismo como un candidato "occidental". La legislatura de Texas aprobó una medida para permitir que Johnson compitiera de forma simultánea para la presidencia y la reelección al Senado en 1960. A pesar de estas maniobras, su precandidatura a la Casa Blanca en 1960 fracasó, y se conformó con ser el vicepresidente de John F. Kennedy. Muchos comentaristas políticos creen que sin Johnson como su compañero de fórmula, Kennedy habría perdido las elecciones frente al republicano Richard Nixon. Johnson fue nombrado por Kennedy para encabezar el Comité del Presidente sobre la igualdad de oportunidades en el empleo, cargo que le permitió trabajar en nombre de los negros y otras minorías. Como vicepresidente, también llevó a cabo algunas misiones en el extranjero, que le ofreció información limitada sobre los problemas internacionales.

Johnson asumió el cargo de Presidente, después del asesinato de John F. Kennedy el 22 de noviembre de 1963, en el avión que trasladaba los restos de este desde Dallas. Johnson aprobó la Ley de Derechos Civiles de 1964, esta ley prohibió la discriminación racial en establecimientos públicos y en cualquier negocio o institución que recibiera fondos federales. Una vez que la Ley se puso en práctica, sus efectos fueron de largo alcance y tuvo una enorme repercusión a largo plazo en todo el país. Se prohibió la discriminación en los centros públicos, en el gobierno, y en el empleo, invalidando las leyes de Jim Crow en el sur de Estados Unidos. Se convirtió ilegal obligar a la segregación de las razas en las escuelas, la vivienda, o en contratación de empleados.

En 1965, se logró la aprobación de un segundo proyecto de ley de los derechos civiles llamada la Ley de derecho al voto, que prohibió la discriminación en el voto, permitiendo así a millones de negros del sur votar por primera vez en varios estados, "siete de los once estados del sur de la antigua confederación" (Alabama, Carolina del Sur, Carolina del Norte, Georgia, Louisiana, Mississippi, Virginia). En 1967, Johnson nominó al abogado de derechos civiles Thurgood Marshall para ser el primer afroamericano Juez Asociado del Tribunal Supremo. Para dirigir el nuevo Departamento de Vivienda y Desarrollo Urbano, Johnson designó a Robert C. Weaver -el primer secretario del gabinete afroamericano en cualquier administración presidencial en Estados Unidos. 

Johnson, tomó como propia la lucha contra la pobreza y por la educación pública en Texas, creía fervientemente que la educación era una cura para la ignorancia y la pobreza, y era un componente esencial del sueño americano, especialmente para las minorías que soportaban las malas instalaciones y presupuestos bajos por parte de las administraciones locales, en especial en el Sur profundo. Hizo de la educación la máxima prioridad de la agenda social, con un énfasis en ayudar a los niños pobres, lanzando como objetivo duplicar el gasto federal en educación desde 4 mil millones a 8 mil millones.

Johnson fue elegido para un nuevo período presidencial el 3 de noviembre de 1964, ganando las elecciones con un 61.1 % de los votos populares contra apenas un 38.5 % que obtuvo su rival republicano Barry Goldwater.

Alentado por su gran victoria electoral, Johnson envió al Congreso muchos programas sociales que fueron aprobados por éste: ayuda federal para la educación, las artes y las humanidades; seguro de salud para los ancianos (Medicare) y para los pobres (Medicaid); viviendas de bajo coste y renovación urbana. La Ley de Derecho al Voto de 1965 que finalmente permitió a los afroamericanos estadounidenses acudir a las urnas. La discriminación hacia la inmigración también llegó a su fin: se abolieron las cuotas por origen nacional, lo que permitió un gran aumento en el número de visados de inmigración para países extraeuropeos (véase: 
Ley de Inmigración y Nacionalidad de 1965).

Aunque para entonces la mayoría de los estadounidenses había alcanzado la prosperidad, el libro de Michael Harrington, "La otra América", de 1962, identificó la persistente pobreza: en los barrios bajos urbanos, en la mayoría de los vecindarios de negros y entre los blancos pobres de las montañas Apalaches orientales. El presidente Johnson respondió con su programa "Guerra contra la Pobreza", que incluía educación preescolar especial para los niños pobres, capacitación vocacional para quienes habían abandonado la escuela y empleos de servicio comunitario para los jóvenes de los barrios bajos.

Con todos estos programas, el objetivo de Johnson era construir una gran sociedad ("The Great Society"): una nación donde la igualdad de oportunidades y una alta calidad de vida fueran el patrimonio de todos. Aunque en 1965 había muchas razones para sentirse optimista acerca del futuro de la nación, ya que la pobreza iba en descenso y los estadounidenses gozaban de una mayor prosperidad y mejor educación que en cualquier otro período anterior de su historia. El 22 de octubre de 1968, Lyndon Johnson firmó la Ley de Control de Armas de 1968, uno de los más grandes y de mayor alcance leyes de control de armas federal en la historia estadounidense. Gran parte de la motivación para esta gran expansión de las regulaciones federales de armas se produjo como respuesta a los asesinatos de John F. Kennedy, Robert F. Kennedy y Martin Luther King Jr.
Durante la administración de Johnson, la NASA llevó a cabo el programa espacial tripulado "Gemini", desarrolló el cohete Saturno V y su base de lanzamiento, y se preparó para hacer los primeros viajes tripulados del programa Apolo.

En 1964, a petición de Johnson, el Congreso aprobó la Ley de Ingresos de 1964 y la Ley de Oportunidad Económica, como parte de la guerra contra la pobreza. Johnson estableció en la normativa de movimiento la creación de programas como Head Start, cupones de alimentos y de trabajo y estudio. [128] Durante los años de Johnson en la presidencia, la pobreza nacional se redujo de manera significativa entre los estadounidenses que vivían por debajo del umbral de la pobreza, al pasar de un 23 por ciento a menos del 12 por ciento.

Hubo dos hechos que provocaron que no se presentara a la reelección de 1968: el movimiento por los derechos civiles en Estados Unidos de la población negra y la segunda y la más importante, fue la Guerra de Vietnam.

Lyndon B. Johnson murió el lunes 22 de enero de 1973 a las 4:33 P.M., de su tercer ataque al corazón en su rancho en la ciudad estadounidense de Johnson City, Texas, a la edad de 64 años. El expresidente tuvo graves enfermedades del corazón. Había sufrido un segundo ataque al corazón en abril de 1972, pero había sido incapaz de dejar de fumar. Fue encontrado por agentes del Servicio Secreto en su cama, con un teléfono en la mano. ("The Age", 23 de enero de 1973, pág. 1).



</doc>
<doc id="21402" url="https://es.wikipedia.org/wiki?curid=21402" title="Pascual Ortiz Rubio">
Pascual Ortiz Rubio

Pascual José Rodrigo Gabriel Ortiz Rubio (Morelia, Michoacán; 10 de marzo de 1877 – Ciudad de México; 4 de noviembre de 1963), diplomático, geógrafo e historiador. Fue presidente de México de 1930 a 1932, año en que presentó su renuncia, siendo el último presidente mexicano en dimitir el cargo.

El ingeniero Ortiz Rubio nació en Morelia, estado de Michoacán, un 10 de marzo de 1877. Fue el segundo hijo del matrimonio de Leonor Rubio Cornelis y el Lic. Pascual Ortiz de Ayala y Huerta, este, su padre, se distinguió entre los liberales moderados ocupando puestos en la administración federal y estatal como magistrado de la Suprema Corte de Justicia de la Nación, regente del Colegio de San Nicolás, secretario de gobierno, diputado local y senador.

El ingeniero Ortiz Rubio contrajo matrimonio en dos ocasiones, primero con Francisca Acéves originaria de la Piedad Michoacán y en segundas nupcias con Josefina Ortiz el 13 de agosto de 1920. De esta unión nacieron tres hijos: Ofelia (dedicada al hogar, 18 de mayo de 1921), Pascual (ingeniero civil, 13 de julio de 1923) y Eugenio Ortiz Rubio (arquitecto, 13 de noviembre de 1924 - 18 de abril del 2002).

Efectuó sus estudios de ingeniería en la Universidad de San Nicolás (Hoy Universidad Michoacana de San Nicolás de Hidalgo, (UMSNH), de donde fue expulsado en 1895 a causa de sus actividades antireeleccionistas.
Completó la carrera de ingeniero topógrafo en la Escuela Nacional de Minería (actual UNAM).

Vuelve a Michoacán y en 1910 se une al movimiento maderista con Joaquín Mass. Como diputado de la XXVI Legislatura sufre encarcelamiento al triunfo del cuartelazo del general Victoriano Huerta. Se adhiere al Ejército Constitucionalista y alcanza el grado de coronel. Viaja a Estados Unidos para hacerse cargo de la impresión de papel moneda, para el gobierno. En 1917 es nombrado gobernador de su estado natal Michoacán, cargo que ocupa hasta 1920, cuando se afilia con Rafael M. Pedrajo al Plan de Agua Prieta encabezado por Álvaro Obregón.

Durante su gestión en la gobernatura de Michoacán, elevó a categoría de universidad su "alma mater". Fue secretario de Comunicaciones y Obras Públicas en los gobiernos de Adolfo de la Huerta y Álvaro Obregón.

Cierto día se hartó y decidió alejarse. Renunció por fricciones con el gabinete. De esta manera, comenzó a viajar. Primero radicó en Barcelona, España, donde él y su esposa establecieron un negocio de libros y una tabaquería. Posteriormente, don Pascual se trasladó a Egipto, lugar en el que permaneció por seis meses mientras estudiaba los sistemas de riego que los ingleses habían llevado a ese país.

Estando en Alemania, el presidente Obregón le confiere, en 1925, la embajada de México en Berlín. Allá se quedó fascinado con el país y con las amistades entabladas entre los altos mandos del ejército alemán. Para sorpresa y disgusto de don Pascual, en 1926, llegó un telegrama que lo mandaba lejos del invierno, hasta Brasil. Y allá permanecería durante tres años, hasta que en 1929, el presidente Emilio Portes Gil le solicitó su regreso a tierras mexicanas, para ocupar la titularidad de la Secretaría de Gobernación y después contender por la silla presidencial.

Siendo embajador en Brasil fue llamado urgentemente por Plutarco Elías Calles, quien le propuso, según confesión propia:

Para algunos autores su nombramiento se debe a su neutralidad, es decir, la falta de apoyo por parte de partido o de grupo político alguno. Esta circunstancia lo hacía más manejable para su mentor, el jefe del Partido Nacional Revolucionario, organizado por el propio Plutarco Elías Calles para agrupar a todos los miembros de la familia revolucionariaria y dirigir la acción política mexicana.

Así, resultó electo candidato oficial en la convención de Querétaro de marzo de 1929, frente a la candidatura de Aarón Sáenz.

Su triunfo electoral fue considerado como el mayor fraude político de la historia mexicana. El 17 de noviembre de 1929 se llevaron a cabo las elecciones presidenciales extraordinarias, organizadas por el presidente interino Emilio Portes Gil, luego del asesinato del presidente electo Álvaro Obregón.

Durante las elecciones extraordinarias, Ortiz Rubio se enfrentó, por una parte, al candidato obregonista Aarón Sáenz y, sobre todo, se enfrentó a la candidatura ciudadana del ex rector de la UNAM, José Vasconcelos Calderón, candidato del Partido Nacional Antirreleccionista. Su elección estuvo plagada de irregularidades, fue muy disputada y existen dudas sobre la veracidad de los resultados oficiales que permitieron a Ortiz Rubio convertirse en presidente. Tras su discutido triunfo, se convirtió en presidente de México tomando posesión el 5 de febrero de 1930. Como ya era tradición, Ortiz Rubio tomó posesión en el Estadio Nacional sobre la calzada de La Piedad. Terminada la ceremonia el nuevo mandatario se dirigió a Palacio Nacional para instalar a su cuerpo diplomático y recibir felicitaciones.

Al salir por la puerta de honor para dirigirse al automóvil convertible que lo esperaba, se percató de que el coche de su esposa estaba estacionado y que dentro iba la señora, acompañada por su hermana y una sobrina.

Porque mientras avanzaba el automóvil, un individuo llamado Daniel Flores González disparó hiriendo al presidente en un carrillo. Dos meses duró la convalecencia de don Pascual en el hospital de la Cruz Roja. Daniel Flores fue detenido y sentenciado a 19 años de prisión en marzo de 1931 y el 23 de abril del año siguiente, la prensa informó que había sido encontrado muerto en su celda de la penitenciaría.

Como consecuencia del atentado padeció un trauma psíquico, que le produjo una neurosis incurable después de tres semanas de hospitalización, durante las cuales estuvo obligadamente al margen de la escena política. Ésta siguió protagonizada por Plutarco Elías Calles pese a sus elocuentes declaraciones de abstención política.

Aunque su régimen fue breve, tuvo gran importancia ya que reconoció la Segunda República Española, expidió leyes en favor de la ciudadanía, ratificó la libertad de cultos, delimitó los territorios peninsulares y amplió la red telefónica.

La dinámica propia del Maximato, en el que el expresidente Calles, el autoproclamado ""Jefe Máximo de la Revolución Mexicana"", mantenía cuotas importantes de poder, hizo insostenible la presidencia de Ortiz Rubio, por lo que, al cabo de dos años, presentó su renuncia al cargo en 1932. Antes de irse y haciendo eco a la atmósfera de golpe de Estado que se respiraba afirmó:

Entregó la presidencia provisionalmente a Abelardo L. Rodríguez para después viajar hacia los Estados Unidos. En 1935 regresó a México porque el presidente en turno, Lázaro Cárdenas, quien además era amigo suyo; lo nombró gerente de la compañía Petromex. Una vez aquí, se ocupó de atender algunos encargos presidenciales y sus negocios personales y se dedicó a viajar por el país. Murió en la ciudad de México, a la edad de 86 años, el 4 de noviembre de 1963.



</doc>
<doc id="21408" url="https://es.wikipedia.org/wiki?curid=21408" title="Década">
Década

Una década (del griego "δεκάς" a través del latín "decada") es una colección de diez elementos. Uno de los usos más habituales es a la colección de diez años consecutivos. En este sentido, se refiere especialmente a cada una de las decenas de siglo; por lo tanto, cada década después de la era común comienza en un año terminado en "1" y finaliza en el siguiente año terminado en "0". Sin embargo, a veces es empleado como sinónimo de decenio, o como referencia a lapsos que no son exactamente de 10 años (por ejemplo en década infame).

Cuando se aplica a años se refiere, en sentido estricto, a las decenas de un siglo. Por ejemplo: «la sexta década del siglo pasado», «la década de los sesenta».
En los calendarios gregoriano y juliano) no existe el año cero, sino que el primer año del primer siglo es el año 1, por lo que la primera década empieza en el año 1 EC y termina en el año 9 EC. De igual forma, cada década inicia en un año terminado en "0" y como dura 10 años, finaliza en el siguiente año terminado en "9".

Un decenio es la unidad de tiempo equivalente a diez años, que no se ajusta necesariamente a una de las diez décadas de un siglo.
El término tiene su origen en el latín "decennium", por la unión de las palabras "decem" (diez) y "annus" (años).

Uno de los usos más comunes de los decenios es el de aquellos que comparten todas sus cifras salvo la última; es decir, que empieza en año finalizado en "0" y termina en el finalizado en "9". Generalmente se hace referencia a estos como "los años...". Por ejemplo, los años 2000, es el decenio comprendido entre el año 2000 (del siglo XX), y el año 2009 (del siglo XXI).

También puede ser utilizado para referirse a los últimos diez años (ej: decenio -);
u otros decenios de comienzo y finalización distinta, por ejemplo Decenio de las Naciones Unidas para la Mujer (1975-1985).

El término década también es empleado para referirse a períodos que no son exactamente decenas de siglo. Ya sea porque no comienzan junto con el siglo, sino que están desfasados; por lo que serían decenios (como la década ganada de 2003 a 2013), o que ni siquiera duran 10 años (como la década infame de 1930 a 1943).



</doc>
<doc id="21410" url="https://es.wikipedia.org/wiki?curid=21410" title="Francisco González Bocanegra">
Francisco González Bocanegra

Francisco De Paula González Bocanegra (San Luis Potosí país Mexico, 8 de enero de 1824 — Ciudad de México, 11 de abril de 1861), fue un poeta lírico, dramaturgo, crítico teatral, orador y articulista, autor de los versos del Himno Nacional Mexicano.

Fue hijo del español José María González Yánez y de Francisca Bocanegra Villalpando, nativa de Pinos, Zacatecas, hermana de José María Bocanegra, ministro de relaciones exteriores en el gabinete de Vicente Guerrero. Nació en San Luis Potosí, debido a que su padre era de origen español, fue desterrado con su familia en 1827.El 28 de diciembre de 1836, la familia regresó a México, a la ciudad de San Luis Potosí, donde el joven Francisco se dedicó al comercio, tres años después de que España reconociera la Independencia de México. El 8 de junio se casa con su prima, Guadalupe González del Pino y Villalpando,teniendo con ella cuatro hijas. Siguió dedicadose a sus empleos públicos, hasta que, perseguido por los enemigos de la administración que servía, en 1861 tuvo que refugiarse en la casa de un amigo.

En México, frecuentaba los centros de reunión literaria, como la Academia de Letrán, en donde conoció a destacados poetas, literatos y periodistas. Dejó el comercio ingresando a la administración pública donde desempeñó diferentes cargos. Fue administrador general de caminos, censor de teatro y editor del "Diario Oficial del Supremo Gobierno". Perteneció a diferentes asociaciones, entre ellas el Liceo Hidalgo.

Separado de su familia, Francisco González Bocanegra enfermó de tifus, muriendo en la Ciudad de México, el 11 de abril de 1861, sus restos fueron sepultados en el panteón de San Fernando y después trasladados al panteón civil de Dolores, a la "Rotonde de las Personas Ilustres" en 1901.


El 12 de noviembre de 1853, el gobierno del general Antonio López de Santa Anna lanzó una convocatoria mediante el ministerio de Fomento, Colonización, Industria y Comercio, cuyo oficial mayor era Miguel Lerdo de Tejada. El objetivo era recibir composiciones poéticas entre las que habría de seleccionarse la letra del Himno nacional mexicano, y a la cual, posteriormente, se arreglaría la música de algún destacado maestro. 

Como González Bocanegra no se animaba a escribir una composición para el concurso, su novia Guadalupe González del Pino se propuso hacerlo concursar. Un día que llegó a visitarla, lo invitó a pasar a una de las piezas de los interiores de su casa, y le mostró sobre un escritorio, papel para escribir, diciéndole que no lo dejaría salir de ese cuarto, hasta que hubiese compuesto la letra del Himno Nacional. Salió y cerró con llave la puerta. Y después de cuatro horas de trabajo, esas páginas pasaron por debajo de la puerta cerrada. La letra original del himno consta de diez estrofas en octavas italianas con versos decasílabos y agudos en cuarto y octavo lugar y la cuarteta del coro con agudos en segundo y cuarto. Con el triunfo del liberalismo, dos estrofas fueron prohibidas, las dedicadas al emperador mexicano Agustín de Iturbide y al presidente Antonio López de Santa Anna. 

Entre las 26 composiciones que fueran recibidas el fallo del jurado favoreció a González Bocanegra; sin embargo, no se otorgó ningún premio al autor. El estreno oficial del Himno se llevó a cabo el 16 de septiembre de 1854 con la música y bajo la batuta de Jaime Nunó cantado por la soprano Balbina Steffenone y el tenor Lorenzo Salvi.

Contrajo fiebre tifoidea y murió en la Ciudad de México el 11 de abril de 1861 a los 37 años de edad. Los periódicos de la capital, en breves líneas, hablaron de la muerte del "joven poeta que tanto prometía".





</doc>
<doc id="21412" url="https://es.wikipedia.org/wiki?curid=21412" title="Siglo">
Siglo

Un siglo o centuria es una unidad de tiempo equivalente a un periodo de 100 años (36526 en días). De la propia definición de siglo se deduce que el siglo I terminó el 31 de diciembre del año 100, y el siglo XX acabó el 31 de diciembre de 2000. Por ello el siglo XXI se inició el 1 de enero de 2001. Actualmente los siglos se representan con números romanos debido a la gran influencia de este gran imperio que creó uno de los primeros calendarios.



</doc>
<doc id="21413" url="https://es.wikipedia.org/wiki?curid=21413" title="Milenio">
Milenio

Un milenio es una unidad de tiempo equivalente a un periodo de 1000 años. El primer milenio después de Cristo consta de los (mil) años, 1 hasta 1000 (más precisamente, desde el 1 de enero del año 1 hasta el 31 de diciembre del año 1000); el primer milenio antes de Cristo consiste en los (mil) años -1 hasta -1000 (con que el año -x = el año x antes de Cristo). La era cristiana (al origen en combinación con el calendario juliano, hoy en día en combinación con el calendario gregoriano), por definición, comienza con el año 1, es decir, carece de año cero. En consecuencia, el primer milenio terminó en el año 1000, y el segundo comenzó en el 1001. Y el segundo milenio terminó en 2000 y el tercero comenzó en 2001.

</table>





</doc>
<doc id="21417" url="https://es.wikipedia.org/wiki?curid=21417" title="Residuo radiactivo">
Residuo radiactivo

Los "residuos radiactivos" son residuos que contienen elementos químicos radiactivos que no tienen un propósito práctico. Es frecuentemente el subproducto de un proceso nuclear, como la fisión nuclear. El residuo también puede generarse durante el proceso de combustible para los reactores o armas nucleares o en las aplicaciones médicas como la radioterapia o la medicina nuclear.

Se pueden clasificar por motivos de gestión en:




Los residuos nucleares, cuyo aspecto es igual al del combustible nuevo, emiten radiación alfa, beta y gamma, además de generar calor como consecuencia de la desintegración radiactiva. Además contienen diferentes sustancias que desarrollan su radiactividad independientemente, lo que dificulta el tratamiento de los residuos; por ejemplo, aunque el principal elemento sea el uranio (95% de los residuos), son los productos de fisión del combustible (2% de los residuos) los que mantienen mayor actividad durante los primeros 150-200 años. Entre estos residuos se encuentran también el plutonio 240, que tiene un período de semidesintegración de aproximadamente 6600 años; y el neptunio 237, con un período de 2.130.000 años.

Se genera un peligro importante en el transporte de los residuos desde las centrales al almacén temporal centralizado, se realiza en el interior de unos grandes cilindros de metal extremadamente resistentes.[

Los residuos de alta actividad requieren sistemas de gestión que garanticen su aislamiento y confinamiento. Las dos opciones que existen para su almacenamiento son el almacenamiento temporal prolongado y el almacenamiento definitivo a gran profundidad. El almacenamiento temporal prolongado permite guardar el combustible entre 100 y 300 años y puede llevarse a cabo con la tecnología,existente en la actualidad a través de los almacenes temporales centralizados. Respecto a la segunda opción, el almacenamiento geológico profundo, aún ha de demostrarse que sea efectivo para periodos extremadamente largos o al menos similares a los del almacenamiento temporal prolongado.



</doc>
<doc id="21422" url="https://es.wikipedia.org/wiki?curid=21422" title="Interruptor diferencial">
Interruptor diferencial

Un interruptor diferencial (ID), también conocido como RCD, RCCB o dispositivo diferencial residual (DDR), es un dispositivo electromecánico que se instala en las instalaciones eléctricas de corriente alterna con el fin de proteger a las personas de los contactos directos e indirectos provocados por el contacto con partes activas de la instalación (contacto directo) o con elementos sometidos a potencial debido, por ejemplo, a una derivación por falta de aislamiento de partes activas de la instalación (contacto indirecto). También protegen contra los incendios que pudieran provocar dichas derivaciones.

Es un dispositivo de protección muy importante en toda instalación, tanto doméstica, como industrial, que actúa conjuntamente con la puesta a tierra de enchufes y masas metálicas de todo aparato eléctrico. De esta forma, el ID desconectará el circuito en cuanto exista una derivación o defecto a tierra mayor que su sensibilidad. Si no existe la conexión a tierra y se produce un contacto de un cable u elemento activo a la carcasa de una máquina, por ejemplo, el ID no se percatará hasta que una persona no aislada de tierra toque esta masa, entonces la corriente recorrerá su cuerpo hacia tierra provocando un defecto a tierra y superando ésta la sensibilidad del ID, que disparará protegiendo a la persona y evitando así su electrocución.

Si nos fijamos en la Figura 1, vemos que la intensidad (I) que circula entre el punto a y la carga debe ser igual a la (I) que circula entre la carga y el punto b (I = I) y por tanto los campos magnéticos creados por ambas bobinas son iguales y opuestos, por lo que la resultante de ambos es nula. Éste es el estado normal del circuito.

Si ahora nos fijamos en la Figura 2, vemos que la carga presenta una derivación a tierra por la que circula una corriente de fuga (I), por lo que ahora I = I - I y por tanto menor que I.

Los transformadores de suministro eléctrico sujetos al régimen de neutro TT (95 % en España) tienen conectado a tierra su terminal neutro y por tanto se cierra circuito eléctrico en cuanto se pone en contacto cualquiera de los hilos de fase con tierra. Es aquí donde el dispositivo desconecta el circuito para prevenir electrocuciones, porque hay derivación de corriente hacia la toma de tierra que deben tener todos los elementos metálicos de los aparatos eléctricos.

La diferencia entre las dos corrientes de los hilos del suministro es la que produce un campo magnético resultante, que no es nulo y que por tanto producirá una atracción sobre el núcleo N, desplazándolo de su posición de equilibrio, provocando la apertura de los contactos C y C e interrumpiendo el paso de corriente hacia la carga, en tanto no se rearme manualmente el dispositivo.

Antes de rearmar el dispositivo se recomienda examinar la causa de su actuación y corregirla o habrá riesgo de prolongar una grave situación de inseguridad, de todas formas el sistema de mecanismo libre no dejará rearmar el ID hasta que no haya fuga a tierra menor que su sensibilidad (IΔn).

Hay que tener en cuenta que estos dispositivos solo protegen aguas abajo del mismo, es decir, desde donde se conecte el diferencial hasta la carga. Este hecho lo podemos entender con la siguiente figura:

Vemos que, por ejemplo, al producirse un fallo en el aislante del cable (representado por un rayo), provoca una derivación a tierra que permitirá la circulación de una corriente desde la tierra conectada al neutro del generador, hasta el fallo producido por este. En el caso de que el fallo se produzca aguas arriba del mismo (entre éste y el transformador), el ID no entraría en funcionamiento, porque las corrientes entrante y saliente seguirían siendo iguales. Por esta razón se debe instalar lo más cerca posible del origen de la fuente de energía eléctrica, que en una vivienda sería el punto de entrada de la derivación individual en el local o la vivienda del usuario, para que la instalación quede totalmente protegida.

Aunque existen interruptores para distintas intensidades de actuación, en España el Reglamento Electrotécnico de Baja Tensión (REBT) en su ITC-BT-24 exige que en las instalaciones domésticas se instalen interruptores diferenciales de alta sensibilidad (IΔn) con una corriente de fuga menor o igual a 30 mA y un tiempo de respuesta de 50 ms, lo cual garantiza una protección adecuada para las personas.

La norma UNE 21302 describe las características del interruptor diferencial.

Hay diferenciales con valores superiores, aunque el umbral de disparo en todos los casos es de entre 0,5 y 1 milésimas de la intensidad nominal. Por ejemplo para el diferencial de 30 A sería correcto que disparase entre 15 y 30 mA.

Las características que definen un interruptor diferencial son el amperaje, número de polos, y sensibilidad, por ejemplo: "Interruptor diferencial 16A-IV-30mA"







Una conexión de bajada domiciliaria deberá respetar la posición de los interruptores por los siguientes motivos:

Además esta posición de los interruptores tiene dos ventajas:





</doc>
<doc id="21427" url="https://es.wikipedia.org/wiki?curid=21427" title="Bajo">
Bajo

Bajo hace referencia a varios artículos:













</doc>
<doc id="21428" url="https://es.wikipedia.org/wiki?curid=21428" title="Años 0">
Años 0

Se llama años 0 a la década que abarca a los años 1 a 9 después de Cristo, los primeros nueve años del siglo I. Nótese que no hay año cero (0) ni en el calendario gregoriano ni en el juliano. De ahí que el año 1 sea precedido por el año 1 a. C.




</doc>
<doc id="21429" url="https://es.wikipedia.org/wiki?curid=21429" title="Años 10">
Años 10

"Nota: A veces la expresión años 10 (o los 10) puede usarse para referirse a los años 2010, a los años 1910, a los años 1810 o a cualquier otra década acabada 10 en los diferentes siglos."




</doc>
<doc id="21430" url="https://es.wikipedia.org/wiki?curid=21430" title="Años 20">
Años 20

"Nota: A veces la expresión años 20 (o los 20) puede usarse para referirse a los años 1920, a los años 1820 o a cualquier otra década acabada 20 en los diferentes siglos."


</doc>
<doc id="21431" url="https://es.wikipedia.org/wiki?curid=21431" title="Años 30">
Años 30

"Nota: A veces la expresión años 30 (o los 30) puede usarse para referirse a los años 1930, a los años 1830 o a cualquier otra década acabada en 30."




</doc>
<doc id="21432" url="https://es.wikipedia.org/wiki?curid=21432" title="Años 40">
Años 40

"Nota: A veces la expresión años 40 (o los 40) puede usarse para referirse a los años 1940, a los años 1840 o a cualquier otra década acabada 40 en los diferentes siglos."




</doc>
<doc id="21433" url="https://es.wikipedia.org/wiki?curid=21433" title="Años 50">
Años 50

"Nota: A veces la expresión años 50 (o los 50) puede usarse para referirse a los años 1950, a los años 1850 o a cualquier otra década acabada 50 en los diferentes siglos."



</doc>
<doc id="21434" url="https://es.wikipedia.org/wiki?curid=21434" title="Años 60">
Años 60

"Nota: A veces la expresión años 60 (o los 60) puede usarse para referirse a los años 1960, a los años 1860 o a cualquier otra década acabada 60 en los diferentes siglos."



 y tenia amor y paz

</doc>
<doc id="21435" url="https://es.wikipedia.org/wiki?curid=21435" title="Años 70">
Años 70

"Nota: A veces la expresión años 70 (o los 70) puede usarse para referirse a los años 1970, a los años 1870 o a cualquier otra década acabada 70 en los diferentes siglos."



</doc>
<doc id="21436" url="https://es.wikipedia.org/wiki?curid=21436" title="Años 80">
Años 80

"Nota: A veces la expresión años 80 (o los 80) puede usarse para referirse a los años 1980, a los años 1880 o a cualquier otra década acabada 80 en los diferentes siglos."




</doc>
<doc id="21437" url="https://es.wikipedia.org/wiki?curid=21437" title="Años 90">
Años 90

"Nota: A veces la expresión años 90 (o los 90) puede usarse para referirse a los años 1990, a los años 1890 o a cualquier otra década acabada 90 en los diferentes siglos."




</doc>
<doc id="21438" url="https://es.wikipedia.org/wiki?curid=21438" title="Años 100">
Años 100




</doc>
<doc id="21439" url="https://es.wikipedia.org/wiki?curid=21439" title="Años 110">
Años 110


115: * 3 o 13 de diciembre: en Antioquía (Turquía), durante la noche, se produce un terremoto de 7,5 grados en la escala sismológica de Richter (intensidad de XI en la escala de Mercalli), dejando un saldo de 260.000 muertos. También se registra un tsunami.


</doc>
<doc id="21440" url="https://es.wikipedia.org/wiki?curid=21440" title="Años 120">
Años 120



</doc>
<doc id="21441" url="https://es.wikipedia.org/wiki?curid=21441" title="Años 130">
Años 130


GALENO(130)


</doc>
<doc id="21442" url="https://es.wikipedia.org/wiki?curid=21442" title="Años 140">
Años 140




</doc>
<doc id="21443" url="https://es.wikipedia.org/wiki?curid=21443" title="Años 150">
Años 150




</doc>
<doc id="21444" url="https://es.wikipedia.org/wiki?curid=21444" title="Años 160">
Años 160




</doc>
<doc id="21445" url="https://es.wikipedia.org/wiki?curid=21445" title="Años 170">
Años 170





</doc>
<doc id="21446" url="https://es.wikipedia.org/wiki?curid=21446" title="Años 180">
Años 180





</doc>
<doc id="21447" url="https://es.wikipedia.org/wiki?curid=21447" title="Años 190">
Años 190




</doc>
<doc id="21448" url="https://es.wikipedia.org/wiki?curid=21448" title="Años 200">
Años 200



</doc>
<doc id="21449" url="https://es.wikipedia.org/wiki?curid=21449" title="Años 210">
Años 210



</doc>
<doc id="21450" url="https://es.wikipedia.org/wiki?curid=21450" title="Años 220">
Años 220




</doc>
<doc id="21451" url="https://es.wikipedia.org/wiki?curid=21451" title="Años 230">
Años 230



</doc>
<doc id="21452" url="https://es.wikipedia.org/wiki?curid=21452" title="Años 240">
Años 240



</doc>
<doc id="21453" url="https://es.wikipedia.org/wiki?curid=21453" title="Años 250">
Años 250



</doc>
<doc id="21454" url="https://es.wikipedia.org/wiki?curid=21454" title="Años 260">
Años 260



</doc>
<doc id="21455" url="https://es.wikipedia.org/wiki?curid=21455" title="Años 270">
Años 270



</doc>
<doc id="21456" url="https://es.wikipedia.org/wiki?curid=21456" title="Años 280">
Años 280



</doc>
<doc id="21457" url="https://es.wikipedia.org/wiki?curid=21457" title="Años 290">
Años 290



</doc>
<doc id="21458" url="https://es.wikipedia.org/wiki?curid=21458" title="Años 300">
Años 300



</doc>
<doc id="21459" url="https://es.wikipedia.org/wiki?curid=21459" title="Años 310">
Años 310



</doc>
<doc id="21460" url="https://es.wikipedia.org/wiki?curid=21460" title="Años 320">
Años 320



</doc>
<doc id="21461" url="https://es.wikipedia.org/wiki?curid=21461" title="Años 330">
Años 330



</doc>
<doc id="21462" url="https://es.wikipedia.org/wiki?curid=21462" title="Años 340">
Años 340



</doc>
<doc id="21463" url="https://es.wikipedia.org/wiki?curid=21463" title="Años 350">
Años 350




</doc>
<doc id="21464" url="https://es.wikipedia.org/wiki?curid=21464" title="Años 360">
Años 360



</doc>
<doc id="21465" url="https://es.wikipedia.org/wiki?curid=21465" title="Años 370">
Años 370

—Emigración masiva de los visigodos desde el Danubio al Imperio romano de Occidente presionados por otras tribus.

—Las huestes de bárbaros arrasan todo a su paso en el este de Europa.

—Aparecen en el Imperio romano los primeros hospitales públicos, el primero, fundado por San Basilio.


</doc>
<doc id="21466" url="https://es.wikipedia.org/wiki?curid=21466" title="Años 380">
Años 380



</doc>
<doc id="21467" url="https://es.wikipedia.org/wiki?curid=21467" title="Años 390">
Años 390



</doc>
<doc id="21468" url="https://es.wikipedia.org/wiki?curid=21468" title="Años 400">
Años 400



</doc>
<doc id="21469" url="https://es.wikipedia.org/wiki?curid=21469" title="Años 410">
Años 410


</doc>
<doc id="21470" url="https://es.wikipedia.org/wiki?curid=21470" title="Años 420">
Años 420



</doc>
<doc id="21471" url="https://es.wikipedia.org/wiki?curid=21471" title="Años 430">
Años 430



</doc>
<doc id="21472" url="https://es.wikipedia.org/wiki?curid=21472" title="Años 440">
Años 440



</doc>
<doc id="21473" url="https://es.wikipedia.org/wiki?curid=21473" title="Años 450">
Años 450



</doc>
<doc id="21474" url="https://es.wikipedia.org/wiki?curid=21474" title="Años 460">
Años 460



</doc>
<doc id="21475" url="https://es.wikipedia.org/wiki?curid=21475" title="Años 470">
Años 470



</doc>
<doc id="21476" url="https://es.wikipedia.org/wiki?curid=21476" title="Años 480">
Años 480



</doc>
<doc id="21477" url="https://es.wikipedia.org/wiki?curid=21477" title="Años 490">
Años 490



</doc>
<doc id="21478" url="https://es.wikipedia.org/wiki?curid=21478" title="Años 500">
Años 500



</doc>
<doc id="21479" url="https://es.wikipedia.org/wiki?curid=21479" title="Años 510">
Años 510



</doc>
<doc id="21480" url="https://es.wikipedia.org/wiki?curid=21480" title="Años 520">
Años 520



</doc>
<doc id="21481" url="https://es.wikipedia.org/wiki?curid=21481" title="Años 530">
Años 530



</doc>
<doc id="21482" url="https://es.wikipedia.org/wiki?curid=21482" title="Años 540">
Años 540



</doc>
<doc id="21483" url="https://es.wikipedia.org/wiki?curid=21483" title="Años 550">
Años 550



</doc>
<doc id="21484" url="https://es.wikipedia.org/wiki?curid=21484" title="Años 560">
Años 560



</doc>
<doc id="21485" url="https://es.wikipedia.org/wiki?curid=21485" title="Años 570">
Años 570




</doc>
<doc id="21486" url="https://es.wikipedia.org/wiki?curid=21486" title="Años 580">
Años 580



</doc>
<doc id="21487" url="https://es.wikipedia.org/wiki?curid=21487" title="Años 590">
Años 590



</doc>
<doc id="21488" url="https://es.wikipedia.org/wiki?curid=21488" title="Años 600">
Años 600



</doc>
<doc id="21489" url="https://es.wikipedia.org/wiki?curid=21489" title="Años 610">
Años 610



</doc>
<doc id="21490" url="https://es.wikipedia.org/wiki?curid=21490" title="Años 620">
Años 620



</doc>
<doc id="21491" url="https://es.wikipedia.org/wiki?curid=21491" title="Años 630">
Años 630



</doc>
<doc id="21492" url="https://es.wikipedia.org/wiki?curid=21492" title="Años 640">
Años 640



</doc>
<doc id="21493" url="https://es.wikipedia.org/wiki?curid=21493" title="Años 650">
Años 650



</doc>
<doc id="21494" url="https://es.wikipedia.org/wiki?curid=21494" title="Años 660">
Años 660



</doc>
<doc id="21495" url="https://es.wikipedia.org/wiki?curid=21495" title="Años 670">
Años 670



</doc>
<doc id="21496" url="https://es.wikipedia.org/wiki?curid=21496" title="Años 680">
Años 680



</doc>
<doc id="21497" url="https://es.wikipedia.org/wiki?curid=21497" title="Años 690">
Años 690



</doc>
<doc id="21498" url="https://es.wikipedia.org/wiki?curid=21498" title="Años 700">
Años 700


</doc>
<doc id="21499" url="https://es.wikipedia.org/wiki?curid=21499" title="Años 710">
Años 710




</doc>
<doc id="21500" url="https://es.wikipedia.org/wiki?curid=21500" title="Años 720">
Años 720

Beda "el venerable" escribe su "Historia Ecclesiastica Gentis Anglorum".


</doc>
<doc id="21501" url="https://es.wikipedia.org/wiki?curid=21501" title="Años 730">
Años 730



</doc>
<doc id="21502" url="https://es.wikipedia.org/wiki?curid=21502" title="Años 740">
Años 740

En el mundo islámico:


</doc>
<doc id="21503" url="https://es.wikipedia.org/wiki?curid=21503" title="Años 750">
Años 750

En el mundo islámico:


</doc>
<doc id="21504" url="https://es.wikipedia.org/wiki?curid=21504" title="Años 760">
Años 760

En el mundo islámico


</doc>
<doc id="21505" url="https://es.wikipedia.org/wiki?curid=21505" title="Años 770">
Años 770



</doc>
<doc id="21506" url="https://es.wikipedia.org/wiki?curid=21506" title="Años 780">
Años 780

La Mezquita de Córdoba habría sido iniciada bajo el reinado del primer emir omeya Abderramán I entre el 780 y el 785.


</doc>
<doc id="21507" url="https://es.wikipedia.org/wiki?curid=21507" title="Años 790">
Años 790



</doc>
<doc id="21508" url="https://es.wikipedia.org/wiki?curid=21508" title="Años 800">
Años 800

Carlomagno, rey de los francos, unifico gran parte de las tierras de Europa occidental.


</doc>
<doc id="21509" url="https://es.wikipedia.org/wiki?curid=21509" title="Años 810">
Años 810



</doc>
<doc id="21510" url="https://es.wikipedia.org/wiki?curid=21510" title="Años 820">
Años 820



</doc>
<doc id="21511" url="https://es.wikipedia.org/wiki?curid=21511" title="Años 830">
Años 830



</doc>
<doc id="21512" url="https://es.wikipedia.org/wiki?curid=21512" title="Años 840">
Años 840



</doc>
<doc id="21513" url="https://es.wikipedia.org/wiki?curid=21513" title="Años 850">
Años 850



</doc>
<doc id="21514" url="https://es.wikipedia.org/wiki?curid=21514" title="Años 860">
Años 860





</doc>
<doc id="21515" url="https://es.wikipedia.org/wiki?curid=21515" title="Años 870">
Años 870





</doc>
<doc id="21516" url="https://es.wikipedia.org/wiki?curid=21516" title="Años 880">
Años 880






</doc>
<doc id="21517" url="https://es.wikipedia.org/wiki?curid=21517" title="Años 890">
Años 890



</doc>
<doc id="21518" url="https://es.wikipedia.org/wiki?curid=21518" title="Años 900">
Años 900

China, 906. El colapso de la dinastía Tang produce 54 años de desunión cuando el gobierno pasa entre cinco dinastías diferentes.
Partes del norte de China están bajo el dominio de diez reinos no chinos.


</doc>
<doc id="21519" url="https://es.wikipedia.org/wiki?curid=21519" title="Años 910">
Años 910



</doc>
<doc id="21520" url="https://es.wikipedia.org/wiki?curid=21520" title="Años 920">
Años 920



</doc>
<doc id="21521" url="https://es.wikipedia.org/wiki?curid=21521" title="Años 930">
Años 930



</doc>
<doc id="21522" url="https://es.wikipedia.org/wiki?curid=21522" title="Años 940">
Años 940



</doc>
<doc id="21523" url="https://es.wikipedia.org/wiki?curid=21523" title="Años 950">
Años 950



</doc>
<doc id="21524" url="https://es.wikipedia.org/wiki?curid=21524" title="Años 960">
Años 960



</doc>
<doc id="21525" url="https://es.wikipedia.org/wiki?curid=21525" title="Años 970">
Años 970



</doc>
<doc id="21526" url="https://es.wikipedia.org/wiki?curid=21526" title="Años 980">
Años 980



</doc>
<doc id="21527" url="https://es.wikipedia.org/wiki?curid=21527" title="Años 990">
Años 990



</doc>
<doc id="21528" url="https://es.wikipedia.org/wiki?curid=21528" title="Años 1000">
Años 1000



</doc>
<doc id="21529" url="https://es.wikipedia.org/wiki?curid=21529" title="Años 1010">
Años 1010



</doc>
<doc id="21530" url="https://es.wikipedia.org/wiki?curid=21530" title="Años 1020">
Años 1020



</doc>
<doc id="21531" url="https://es.wikipedia.org/wiki?curid=21531" title="Años 1030">
Años 1030



</doc>
<doc id="21532" url="https://es.wikipedia.org/wiki?curid=21532" title="Años 1040">
Años 1040



</doc>
<doc id="21533" url="https://es.wikipedia.org/wiki?curid=21533" title="Años 1050">
Años 1050



</doc>
<doc id="21534" url="https://es.wikipedia.org/wiki?curid=21534" title="Años 1060">
Años 1060



</doc>
<doc id="21535" url="https://es.wikipedia.org/wiki?curid=21535" title="Años 1070">
Años 1070



</doc>
<doc id="21536" url="https://es.wikipedia.org/wiki?curid=21536" title="Años 1080">
Años 1080


</doc>
<doc id="21537" url="https://es.wikipedia.org/wiki?curid=21537" title="Años 1110">
Años 1110



</doc>
<doc id="21538" url="https://es.wikipedia.org/wiki?curid=21538" title="Años 1120">
Años 1120



</doc>
<doc id="21539" url="https://es.wikipedia.org/wiki?curid=21539" title="Años 1130">
Años 1130





</doc>
<doc id="21540" url="https://es.wikipedia.org/wiki?curid=21540" title="Años 1140">
Años 1140



</doc>
<doc id="21541" url="https://es.wikipedia.org/wiki?curid=21541" title="Años 1150">
Años 1150



</doc>
<doc id="21542" url="https://es.wikipedia.org/wiki?curid=21542" title="Años 1160">
Años 1160



</doc>
<doc id="21543" url="https://es.wikipedia.org/wiki?curid=21543" title="Años 1170">
Años 1170



</doc>
<doc id="21544" url="https://es.wikipedia.org/wiki?curid=21544" title="Años 1180">
Años 1180



</doc>
<doc id="21545" url="https://es.wikipedia.org/wiki?curid=21545" title="Años 1190">
Años 1190




</doc>
<doc id="21546" url="https://es.wikipedia.org/wiki?curid=21546" title="Años 1200">
Años 1200



</doc>
<doc id="21547" url="https://es.wikipedia.org/wiki?curid=21547" title="Años 1210">
Años 1210



</doc>
<doc id="21548" url="https://es.wikipedia.org/wiki?curid=21548" title="Años 1220">
Años 1220



</doc>
<doc id="21549" url="https://es.wikipedia.org/wiki?curid=21549" title="Años 1230">
Años 1230



</doc>
<doc id="21550" url="https://es.wikipedia.org/wiki?curid=21550" title="Años 1240">
Años 1240



</doc>
<doc id="21551" url="https://es.wikipedia.org/wiki?curid=21551" title="Años 1250">
Años 1250



</doc>
<doc id="21552" url="https://es.wikipedia.org/wiki?curid=21552" title="Años 1260">
Años 1260



</doc>
<doc id="21553" url="https://es.wikipedia.org/wiki?curid=21553" title="Años 1270">
Años 1270




</doc>
<doc id="21554" url="https://es.wikipedia.org/wiki?curid=21554" title="Años 1280">
Años 1280



</doc>
<doc id="21555" url="https://es.wikipedia.org/wiki?curid=21555" title="Años 1290">
Años 1290



</doc>
<doc id="21556" url="https://es.wikipedia.org/wiki?curid=21556" title="Años 1300">
Años 1300




</doc>
<doc id="21557" url="https://es.wikipedia.org/wiki?curid=21557" title="Años 1310">
Años 1310




</doc>
<doc id="21558" url="https://es.wikipedia.org/wiki?curid=21558" title="Años 1320">
Años 1320



</doc>
<doc id="21559" url="https://es.wikipedia.org/wiki?curid=21559" title="Años 1330">
Años 1330




</doc>
<doc id="21560" url="https://es.wikipedia.org/wiki?curid=21560" title="Años 1340">
Años 1340

Década que comenzó el 1 de enero de 1340 y finalizó el 31 de diciembre de 1349.



</doc>
<doc id="21561" url="https://es.wikipedia.org/wiki?curid=21561" title="Años 1350">
Años 1350




</doc>
<doc id="21562" url="https://es.wikipedia.org/wiki?curid=21562" title="Años 1360">
Años 1360



</doc>
<doc id="21563" url="https://es.wikipedia.org/wiki?curid=21563" title="Años 1370">
Años 1370



</doc>
<doc id="21564" url="https://es.wikipedia.org/wiki?curid=21564" title="Años 1380">
Años 1380


</doc>
<doc id="21565" url="https://es.wikipedia.org/wiki?curid=21565" title="Años 1390">
Años 1390




</doc>
<doc id="21566" url="https://es.wikipedia.org/wiki?curid=21566" title="Años 1400">
Años 1400



</doc>
<doc id="21567" url="https://es.wikipedia.org/wiki?curid=21567" title="Años 1410">
Años 1410



</doc>
<doc id="21568" url="https://es.wikipedia.org/wiki?curid=21568" title="Años 1420">
Años 1420



</doc>
<doc id="21569" url="https://es.wikipedia.org/wiki?curid=21569" title="Años 1430">
Años 1430




</doc>
<doc id="21570" url="https://es.wikipedia.org/wiki?curid=21570" title="Años 1440">
Años 1440




</doc>
<doc id="21571" url="https://es.wikipedia.org/wiki?curid=21571" title="Años 1450">
Años 1450




</doc>
<doc id="21572" url="https://es.wikipedia.org/wiki?curid=21572" title="Años 1460">
Años 1460



</doc>
<doc id="21573" url="https://es.wikipedia.org/wiki?curid=21573" title="Años 1470">
Años 1470




</doc>
<doc id="21574" url="https://es.wikipedia.org/wiki?curid=21574" title="Años 1480">
Años 1480



</doc>
<doc id="21575" url="https://es.wikipedia.org/wiki?curid=21575" title="Años 1490">
Años 1490

Década que comienza el 1 de enero de 1490 y finaliza el 31 de diciembre de 1949. Fue también la última década del Siglo XV (aunque el año 1500 también perteneció a este siglo).


</doc>
<doc id="21576" url="https://es.wikipedia.org/wiki?curid=21576" title="Años 1510">
Años 1510




</doc>
<doc id="21577" url="https://es.wikipedia.org/wiki?curid=21577" title="Años 1520">
Años 1520



</doc>
<doc id="21578" url="https://es.wikipedia.org/wiki?curid=21578" title="Años 1530">
Años 1530



</doc>
<doc id="21579" url="https://es.wikipedia.org/wiki?curid=21579" title="Años 1540">
Años 1540



</doc>
<doc id="21580" url="https://es.wikipedia.org/wiki?curid=21580" title="Años 1550">
Años 1550



</doc>
<doc id="21581" url="https://es.wikipedia.org/wiki?curid=21581" title="Años 1560">
Años 1560



</doc>
<doc id="21582" url="https://es.wikipedia.org/wiki?curid=21582" title="Años 1580">
Años 1580




</doc>
<doc id="21583" url="https://es.wikipedia.org/wiki?curid=21583" title="Años 1590">
Años 1590



</doc>
<doc id="21584" url="https://es.wikipedia.org/wiki?curid=21584" title="Años 1600">
Años 1600

La década de 1600 se extendió desde el 1 de enero de 1600 hasta el 31 de diciembre de 1609.



</doc>
<doc id="21585" url="https://es.wikipedia.org/wiki?curid=21585" title="Años 1610">
Años 1610



</doc>
<doc id="21586" url="https://es.wikipedia.org/wiki?curid=21586" title="Años 1620">
Años 1620



</doc>
<doc id="21587" url="https://es.wikipedia.org/wiki?curid=21587" title="Años 1630">
Años 1630




</doc>
<doc id="21588" url="https://es.wikipedia.org/wiki?curid=21588" title="Años 1640">
Años 1640




</doc>
<doc id="21589" url="https://es.wikipedia.org/wiki?curid=21589" title="Años 1650">
Años 1650




</doc>
<doc id="21590" url="https://es.wikipedia.org/wiki?curid=21590" title="Años 1660">
Años 1660




</doc>
<doc id="21591" url="https://es.wikipedia.org/wiki?curid=21591" title="Años 1670">
Años 1670



</doc>
<doc id="21592" url="https://es.wikipedia.org/wiki?curid=21592" title="Años 2010">
Años 2010

Los años 2010 es la década actual, que comprende el periodo entre el 1 de enero de 2010 al 31 de diciembre de 2019.

Una década que en su primera mitad sigue fuertemente marcada por la crisis económica mundial que se inició en 2008. Al día de hoy, se habla de ella como la «Segunda Gran Recesión». La crisis de deuda soberana puso en jaque a la Unión Europea, ya que cuatro estados miembros de la Zona Euro (Grecia, Irlanda, Portugal y Chipre) tuvieron que ser rescatados, y además se le unió una crisis inédita en el Estado de Bienestar europeo. El Reino Unido en 2016, tras un referéndum, se convirtió en el primer estado miembro de la UE que abandona la Unión.

La Primavera Árabe marcó los primeros meses del año 2011. Unas revoluciones sin precedentes en varios países árabes, sirvieron para acabar con regímenes dictatoriales que los gobernaron por varias décadas, en países como Túnez, Egipto o Libia. Sin embargo, la gran inestabilidad de los países árabes provocó que grupos fundamentalistas islámicos como el Estado Islámico aparecieran y tomaran extensas zonas en Siria, Iraq, Egipto y Libia. Aunque se formó una coalición contra el EI, no se evitó que éste cometiera , entre los que destacan Francia (7-E y 13-N, ambos en 2015, y 14-J en 2016), Bélgica (22-M, 2016), Suecia (7-A, 2017), Alemania (19-D, 2016), Reino Unido (22-Marzo, 22-Mayo y 3-J, 2017) y España (17-A, 2017). Además los terroristas islámicos cometieron numerosos atentados en países musulmanes como Turquía, Túnez, Egipto, Irak, en varios países africanos y en Rusia.

De hecho, la guerra civil siria (2011-presente) es el conflicto que domina la primera mitad de la década, debido a la mezcla de intereses políticos y geoestratégicos de las potencias mundiales y regionales, el aumento del terrorismo, los conflictos religiosos, las tensiones sociales, la crisis económica, y la inestabilidad en países vecinos como Irak o Turquía. Además, esta guerra provocó una avalancha de millones de refugiados en las fronteras europeas.

Otro conflicto destacable es la crisis iniciada en 2013 en Ucrania, que en 2014 provocó que Rusia se hiciera con Crimea y estallara una Guerra civil en el este de Ucrania. Algunos hablan de una nueva Guerra Fría. En 2014, Estados Unidos restableció sus relaciones diplomáticas con Cuba, tras 50 años de embargo y al año siguiente la comunidad internacional alcanzó un acuerdo con Irán para paralizar su programa nuclear. Fueron dos de los grandes logros de la presidencia de Barack Obama (2009-2017), a quien sustituiría en la presidencia de los Estados Unidos, contra todo pronóstico, el candidato republicano Donald Trump.

La prolongación de la crisis económica mundial provocó a mitad de la década una fuerte caída de las materias primas lo que afectó a los "países emergentes" como Brasil, Rusia o China. Fue especialmente intensa la caída del precio del petróleo, debido a la crisis y el apogeo de la fractura hidráulica (fracking), provocando importantes cambios económicos y geopolíticos a nivel mundial. Se empiezan a utilizar masivamente los drones, tanto de forma militar como civil, así como las impresoras 3D, y se desarrolla la tecnología del grafeno. Continúa el desarrollo de la inteligencia artificial de los robots. También se produce el auge de los deportes electrónicos (conocidos como "eSports"). Aumenta el uso de las Criptomonedas como medio de pago.

El Calentamiento Global es uno de los problemas más críticos de ésta década, debido al aumento en los gases de efecto invernadero que han provocado el derretimiento de los polos, poniendo así a la calidad ambiental en un estado crítico. También ocurrieron desastres naturales que provocaron miles de muertos como el Terremoto de Haití de 2010, el Terremoto de Yushu de 2010, las Inundaciones en Pakistán de 2010, el Terremoto y tsunami de Japón de 2011 (con el añadido de un Accidente nuclear en Fukushima), el Terremoto de Nepal de abril de 2015 , el Terremoto de Ecuador de 2016 y el Terremoto de Puebla de 2017 (También conocido como 19-S). Otras catástrofes provocadas por la mano del hombre, como el hundimiento de la plataforma petrolífera Deepwater Horizon o las Explosiones en Tianjin de 2015, provocaron graves daños medioambientales.

Es una época en la que se producen relevos en varias monarquías europeas, como Bélgica, Países Bajos (2013) y España (2014).

En el segundo Cónclave del III Milenio (en 2013) fue elegido el argentino Jorge Mario Bergoglio como Papa Francisco, convirtiéndose en el primer papa americano en la historia.













 se independiza formalmente el 9 de julio de 2011.


Principales referencias:
Principal referencia:

Principal referencia:

Principal referencia:

Principal referencia:


Principal referencia:


Principal referencia:


Principal referencia:


Principal referencia:


Principal referencia:

Principal referencia:

Principal referencia:

Principal referencia:

Principal referencia:


Principal referencia:































A nivel mundial el juego vendió aproximadamente 4,6 millones de unidades, en comparación con el Batman: Arkham Asylum, que vendió 2 millones de unidades en su primera semana, lo que convirtió a Arkham City como uno de los juegos más vendidos durante su primera semana. El 8 de febrero de 2012, se anunció que más de 6 millones de unidades del juego habían sido vendidas. Durante la primera semana de ventas en el Reino Unido, Batman: Arkham City se convirtió en el juego más vendido de todos los formatos disponibles,superando a Fifa 12,Gears of War 3 y La noire y a su vez duplico las ventas de arkham asylum en su primera semana en el año 2009. Según NPD Group, Batman: Arkham City fue el segundo juego más vendido en los Estados Unidos en el mes de octubre del año 2011, vendiendo 1.5 millones de copias en todos formatos disponibles; además fue el décimo mejor juego vendido en noviembre y el séptimo mejor juego en general durante el 2011.















Principal referencia:


Principal referencia:


Principal referencia:


Principal referencia:


Principal referencia:


Principal referencia:


Principal referencia:


Principal referencia:





</doc>
<doc id="21604" url="https://es.wikipedia.org/wiki?curid=21604" title="Siglo XXII">
Siglo XXII

El siglo XXII es el próximo siglo. Comenzará el 1 de enero de 2101 y terminará el 31 de diciembre de 2200.






</doc>
<doc id="21606" url="https://es.wikipedia.org/wiki?curid=21606" title="Paul Klee">
Paul Klee

Paul Klee (Münchenbuchsee, Suiza, 18 de diciembre de 1879 - Muralto, Suiza, 29 de junio de 1940) fue un pintor alemán nacido en Suiza, cuyo estilo varía entre el surrealismo, el expresionismo y la abstracción.

Klee nació en Münchenbuchsee, cerca de Berna, Suiza, en una familia de músicos, de padre alemán y madre suiza. De su padre obtuvo la ciudadanía alemana, que usaría toda su vida, dado que Suiza se negó a darle ciudadanía tras su exilio durante la persecución nazi. Estudió arte en Múnich con Heinrich Knirr y Franz von Stuck. A sus diecisiete años pintó a tinta "Mi habitación" (1896). 

Klee trabajaba al óleo, acuarela, tinta y otros materiales, generalmente combinándolos en un solo trabajo. Sus cuadros frecuentemente aluden a la poesía, la música y los sueños, y a veces incluyen palabras o notas musicales.

Al regresar de un viaje a Italia, se asentó en Múnich, donde conoció a Vasili Kandinski, Franz Marc y otras figuras de vanguardia, y se asoció al Blaue Reiter.

En 1911 Wassily Kandinski y Franz Marc fundaron en Múnich un grupo de artistas vinculado al expresionismo. Paul Klee no era oficialmente miembro de esta asociación, pero con todo se sentía muy unido al círculo de artistas que la integraban y participó en sus exposiciones. Entre los miembros del Blaue Reiter se contaban August Macke, Gabriele Münter y Marianne von Werefkin. Todos compartían un interés por el arte gótico y primitivo y por los movimientos modernos del "fovismo" y el "cubismo". 
El nombre del grupo deriva de una obra pictórica de Kandinsky de 1903 que a partir de 1912 sirvió de ilustración para los títulos de un anuario con ese mismo nombre.
La primera de las dos exposiciones del Blaue Reiter se inauguró el 18 de diciembre de 1911 y permaneció en la Galería Moderna de Heinrich Thannhauser, en Múnich, hasta el 1 de enero de 1912. En ella se incluyeron 49 obras de Henri Rousseau, Albert Bloch, Heinrich Campendonk, Robert Delaunay, Kandinsky, Klee y Macke. Tras este período, la exposición inició su itinerancia por otras ciudades alemanas, entre ellas Colonia y Berlín.

En 1914, visitó Túnez y quedó impresionado con la calidad de la luz del lugar, por lo que escribió en su diario: 

También visitó Italia en 1901 y Egipto en 1928, siendo ambos lugares una fuerte influencia para su arte. Klee era uno de los Die Blaue Vier (Los Cuatro Azules) junto a Kandinski, Feininger y Jawlensky. Esta agrupación, formada en 1923 expuso conjuntamente en los Estados Unidos en 1924.

Después de la Primera Guerra Mundial, donde participó como soldado por ser ciudadano alemán, Klee enseñó en la Bauhaus, y a partir de 1931, en la Academia de Bellas Artes de Düsseldorf, antes de ser denunciado por los nazis por producir «arte degenerado».

En 1933 dejó la enseñanza y regresó a Berna, donde realizó una gran exposición en la Kunsthalle (1935). En 1936 se le diagnosticó esclerodermia, una grave enfermedad degenerativa que le acompañaría el resto de su vida, aunque siguió trabajando a buen ritmo. En 1940 fue internado en una clínica de Muralto-Locarno, donde falleció el 29 de junio.

Pamela Kort escribió: "Los dibujos de 1933 de Klee enfrentan al espectador con la inigualable oportunidad de observar el aspecto central de su estética, en cuanto a combinación de parodia e ingenio. Y es aquí donde radica su verdadero significado, especialmente para aquellas personas que no llegan a percibir las dimensiones políticas del arte de Klee.

A lo largo de su vida, Paul Klee usó el color de maneras variadas y únicas, y mantuvo con él una relación que progresó con el tiempo. Para un artista que amaba tanto la naturaleza parece algo extraño que en sus comienzos Klee despreciara el color, creyendo que no era sino una decoración.

Con el tiempo Klee cambió de idea y llegó a manipular el color con una enorme precisión y pasión, hasta tal punto que terminó enseñando teoría del color y de su mezcla en la Escuela de la Bauhaus. Esta progresión, por sí misma, es de gran importancia porque le permitió escribir sobre el color con una mirada única entre sus contemporáneos.


Escritos de Paul Klee





</doc>
<doc id="21607" url="https://es.wikipedia.org/wiki?curid=21607" title="2006">
2006

2006 (MMVI) fue un año común comenzado en domingo según el calendario gregoriano. Fue designado:









- Comienza en el club de golf "The K Club" de Straffan en el Condado de Kildare (Irlanda) la Ryder Cup, el torneo de golf por equipos más importante del mundo.
- Empieza a emitirse en ABC la exitosa serie de TV LOST.










</doc>
<doc id="21608" url="https://es.wikipedia.org/wiki?curid=21608" title="2007">
2007

2007 (MMVII) fue un año común comenzado en lunes según el calendario gregoriano, y fue designado como:


















































































Harry Potter y la orden del Fénix, se estrena el 28 de Junio de 2007





</doc>
<doc id="21609" url="https://es.wikipedia.org/wiki?curid=21609" title="2008">
2008

2008 (MMVIII) fue un según el calendario gregoriano, y fue designado como:





















































































































</doc>
<doc id="21611" url="https://es.wikipedia.org/wiki?curid=21611" title="2009">
2009

2009 (MMIX) fue un en el calendario gregoriano. Fue designado como:




































usain bolt rompe el record del mundo de 100 metros lisos 9,58 segundos y de 200 metros lisos 19,19 segundos






9 de septiembre: en España el equipo de fútbol Levante Unión Deportiva, cumple 100 años (1909-2009). El centenario es celebrado a partir del día 9 de septiembre (Día en que se funda el club en 1909) hasta final de la temporada 2009/2010, siendo el Levante U.D. de segunda división española y el equipo más veterano de toda la Comunidad Valenciana.
También el FC Barcelona ganaría en total 6 torneos, los cuales son Liga Española, Copa del Rey, UEFA Champions League, Supercopa de España, Supercopa de Europa y el Mundial de clubes.




















</doc>
<doc id="21612" url="https://es.wikipedia.org/wiki?curid=21612" title="2010">
2010

2010 () fue un en el calendario gregoriano. Es también el número 2010 anno Dómini o de la designación de Era Cristiana, además del décimo del tercer milenio y el primero de la década de los 2010.

Fue designado como el Año del tigre, según el horóscopo chino; el Año del Centenario de la Revolución mexicana, según el Gobierno de México; el Año del Bicentenario de la Independencia de México, según el Gobierno de México, el Año Internacional de la Diversidad Biológica, según la ONU; el Año Internacional de Acercamiento de las Culturas, según la ONU; el Año del Bicentenario del inicio del proceso de Independencia de Argentina, según el Gobierno de Argentina; el "Año 52 de la Revolución", según el Gobierno de Cuba; el Año del Bicentenario de la Independencia de Colombia, según el Gobierno de Colombia; el Año del Bicentenario del inicio del proceso de la Independencia de Chile, según el Gobierno de Chile; el Año del 1100 aniversario del Reino de León y el Año del Marino, según la OMI.














































































En la serie de televisión "Los Simpson", se fecha la muerte de Seymour Skinner en este año.







</doc>
<doc id="21623" url="https://es.wikipedia.org/wiki?curid=21623" title="2021">
2021

2021 () será un en el calendario gregoriano.



</doc>
<doc id="21624" url="https://es.wikipedia.org/wiki?curid=21624" title="2022">
2022

2022 () será un año normal comenzado en sábado en el calendario gregoriano.






</doc>
<doc id="21625" url="https://es.wikipedia.org/wiki?curid=21625" title="2023">
2023

2023 () será un año normal comenzado en domingo en el calendario gregoriano.







</doc>
<doc id="21627" url="https://es.wikipedia.org/wiki?curid=21627" title="2025">
2025

2025 () será un año normal en el calendario gregoriano comenzando el día miércoles.





</doc>
<doc id="21628" url="https://es.wikipedia.org/wiki?curid=21628" title="2026">
2026

2026 () será un año normal comenzado en jueves en el calendario gregoriano.






</doc>
<doc id="21629" url="https://es.wikipedia.org/wiki?curid=21629" title="2027">
2027

2027 () será un año normal comenzado en viernes en el calendario gregoriano.


</doc>
<doc id="21630" url="https://es.wikipedia.org/wiki?curid=21630" title="2028">
2028

2028 () será un año bisiesto comenzado en sábado en el calendario gregoriano.








</doc>
<doc id="21631" url="https://es.wikipedia.org/wiki?curid=21631" title="2029">
2029

2029 () será un año normal comenzado en lunes en el calendario gregoriano.




</doc>
<doc id="21632" url="https://es.wikipedia.org/wiki?curid=21632" title="2030">
2030

2030 () será un año normal comenzado en martes en el calendario gregoriano.





</doc>
<doc id="21633" url="https://es.wikipedia.org/wiki?curid=21633" title="2031">
2031

2031 () será un año común comenzado en miércoles según el calendario gregoriano. 






</doc>
<doc id="21634" url="https://es.wikipedia.org/wiki?curid=21634" title="2032">
2032

2032 () será un año bisiesto comenzado en jueves en el calendario gregoriano.




En este año está basada la película Demolition Man


</doc>
<doc id="21635" url="https://es.wikipedia.org/wiki?curid=21635" title="2033">
2033

2033 () será un año normal comenzado en sábado en el calendario gregoriano.



</doc>
<doc id="21636" url="https://es.wikipedia.org/wiki?curid=21636" title="2034">
2034

2034 () será un año normal comenzado en domingo en el calendario gregoriano.



</doc>
<doc id="21637" url="https://es.wikipedia.org/wiki?curid=21637" title="2035">
2035

2035 () será un año normal comenzado en lunes en el calendario gregoriano.




</doc>
<doc id="21639" url="https://es.wikipedia.org/wiki?curid=21639" title="2037">
2037

2037 () será un año normal comenzado en jueves en el calendario gregoriano.


31 de Febrero, será el único año donde habrá un 31 de febrero y por fin te amará pero morirá atropellada alv por tu culpa buen amigo.





</doc>
<doc id="21640" url="https://es.wikipedia.org/wiki?curid=21640" title="2038">
2038

2038 () será un año normal comenzado en viernes en el calendario gregoriano.






</doc>
<doc id="21641" url="https://es.wikipedia.org/wiki?curid=21641" title="2039">
2039

2039 () será un año normal comenzado en sábado en el calendario gregoriano.







</doc>
<doc id="21642" url="https://es.wikipedia.org/wiki?curid=21642" title="2040">
2040

2040 () será un año bisiesto comenzando en domingo en el calendario gregoriano.




</doc>
<doc id="21643" url="https://es.wikipedia.org/wiki?curid=21643" title="2041">
2041

2041 () será un año normal comenzado en martes en el calendario gregoriano.




</doc>
<doc id="21645" url="https://es.wikipedia.org/wiki?curid=21645" title="2043">
2043

2043 () será un año normal comenzado en jueves en el calendario gregoriano.





</doc>
<doc id="21646" url="https://es.wikipedia.org/wiki?curid=21646" title="2044">
2044

2044 () será un año bisiesto comenzado en viernes en el calendario gregoriano.



</doc>
<doc id="21647" url="https://es.wikipedia.org/wiki?curid=21647" title="2045">
2045

2045 () será un año normal comenzado en domingo en calendario gregoriano.






</doc>
<doc id="21648" url="https://es.wikipedia.org/wiki?curid=21648" title="2046 (película)">
2046 (película)

2046 es una película de cine proveniente de Hong Kong (filmada en Shanghái), escrita y dirigida por Wong Kar-wai. Fue estrenada en el año 2004. Es una secuela de "Días Salvajes", en inglés "Days of Being Wild" (estrenada en 1991) y "Deseando amar" (también conocida como "Con ánimo de amar", estrenada en 2000). Ésta, continúa la vida amorosa que tiene Chow Mo-wan en la década de los años 60 de Hong Kong e incluye algunos elementos de la ciencia ficción, mezclando géneros de manera innovadora. Además de cantonés y mandarín, se habla japonés, y la banda sonora cuenta con temas en español. La película sigue la línea estética de las anteriores, destacando el uso de iluminaciones singulares, encuadres muy estudiados y movimientos de cámara hiperlentos, junto con una devoción por interiorismos de glamour decadente.



Un periodista y escritor "free lancer" se aloja en el cuarto 2046 de un hotel, en el cual reflexionará sobre los significados y misterios de su vida amorosa, todo eso relacionado con una novela de ciencia ficción que escribirá. La trama representa una metáfora sobre las diferentes maneras de superar los amores imposibles del pasado y el miedo al amor futuro, a través de diferentes historias con el nexo común del protagonista.

"Si hubiera nacido en otra época, mi vida hubiera sido diferente", afirma el personaje, "No sirve de nada encontrar a la persona indicada si el momento no es el adecuado", "El amor es una cuestión de tiempo".




</doc>
<doc id="21715" url="https://es.wikipedia.org/wiki?curid=21715" title="Meme">
Meme

Un meme es, en las teorías sobre la difusión cultural, la unidad teórica de información cultural
transmisible de un individuo a otro, o de una mente a otra, o de una generación a la siguiente. Es un neologismo acuñado por Richard Dawkins en "El gen egoísta" ("The Selfish Gene"), por la semejanza fonética con «gene» —"gen" en idioma inglés— y para señalar la similitud con «memoria» y «mimesis».

Según Dawkins, poseemos dos tipos de procesadores informativos distintos:

La tesis más importante de Dawkins es que los rasgos culturales, o memes, también se replican. Por analogía con la agrupación genética en los cromosomas, se considera que los memes también se agrupan en dimensiones culturales, que incrementan con nuevas adquisiciones culturales. La gran diferencia es que, mientras los cromosomas son unidades naturales independientes de nuestras acciones, las dimensiones culturales son nuestras construcciones. Así, la cultura no es tanto un conjunto de formas conductuales, sino más bien información que las especifica.

Para el conjunto de los memes se dan las características propias de todo proceso evolutivo: fecundidad (algunas ideas son especialmente efectivas), longevidad (persisten durante mucho tiempo) y fidelidad en la replicación (conservadurismo tradicional, especialmente el enseñado como parte de la educación infantil).

A su vez, los memes se dan en un amplio campo de variación, se replican a sí mismos por mecanismos de imitación y transmisión de cerebro a cerebro y engendran un amplio abanico de copias que subsisten en diversos medios. Con ello tenemos el marco general de un proceso evolutivo que Dawkins compara con la evolución biológica, e incluso llega a aceptar que los memes deben ser considerados como estructuras vivientes no sólo metafóricamente, sino técnicamente. Los memes alternativos, que pueden servir para efectuar la misma función, son llamados alelomemes o memes homólogos. A su vez, los memes pueden agruparse formando macromemes, que constituyen un sistema de muchos memes estructurados e interrelacionados que forman un objeto cultural complejo, tal como una lengua, una teoría, una mitología, etc. En general, la mayor parte de las construcciones teóricas que sustentan la teoría de la evolución de las especies, son aplicadas por los defensores de las tesis de Dawkins a la teoría de los memes.

De la misma manera que los genes se autorreplican porque sí (ergo, inconscientemente), los memes tienden a replicarse igualmente; las buenas ideas no lo son propiamente si son incapaces, a la vez, de replicarse bien. Así, los memes son indiferentes a la verdad, como los genes son ajenos a cualquier clasificación. Este mecanismo de autorreplicación no es exclusivo de sistemas vivos, como el ADN y el ARN: ciertos polímeros y cristales, y los virus informáticos muestran este comportamiento, por lo cual no debería resultar ilógico en algo inerte como un meme, ya que como vemos se trata de un patrón visible en muchos elementos naturales. Los genes de un ser vivo, conforme pasan las generaciones, alcanzan proporciones insignificantes en sus descendientes. De este modo el equipo o colección de genes de un individuo tiende a desaparecer. Sin embargo una buena idea o un invento puede perdurar casi intacta durante siglos y siglos.
Los memes y los genes a menudo se refuerzan los unos a los otros pero esto no siempre es así; por ejemplo un gen para el celibato sería erradicado rápidamente del acervo génico pues estaría condenado al fracaso, en cambio un meme para el celibato puede tener mucho éxito en el acervo de memes. El medio de transmisión es la influencia
humana de diversa índole, palabra escrita, hablada, el ejemplo personal, entre otros.

La teoría de los memes está siendo desarrollada por varios investigadores, que la unen a las tesis de Lumsden y Wilson o que las vinculan con los estudios de Luigi Luca Cavalli-Sforza. Además del mismo Dawkins, F. T. Cloak, J. M. Cullen, E. Moritz, A. Lynch y algunos otros autores, son los representantes de esta concepción de la transmisión y evolución cultural.

Como explicación de la evolución de la cultura, todavía aparece como una pre-teoría en fase de acumulación de datos y de elaboración de un aparato matemático suficiente. Los estudios de Cavalli-Sforza y Marc Feldman proporcionan una buena base de partida para el estudio cuantitativo de la transmisión y evolución cultural, aunque estos autores no defienden exactamente la teoría principal de los memes de Dawkins. En cualquier caso estos estudios iniciados desde la perspectiva de la genética, la sociobiología y la etología son la primera aproximación no meramente cualitativa al proceso de la transmisión y evolución cultural, y pretenden ampararse en la tradición científica del evolucionismo.

Pero mientras los procesos evolutivos biológicos se rigen siempre por el modelo darwiniano, la evolución de la cultura, con intervención humana directa, parece seguir a veces un modelo de tipo lamarckiano de transmisión de caracteres adquiridos, lo que permite una evolución rapidísima —potenciada por la velocidad casi instantánea de los medios de comunicación— comparada con los procesos darwinianos. En cualquier caso, la constitución genética humana está determinada por unos 3.000 millones de nucleótidos procedentes del ADN materno y otros tantos procedentes del ADN paterno. Pero las neuronas del sistema nervioso son 100 veces más numerosas y las conexiones entre ellas todavía muchísimo más. De ahí que intentar la creación de un modelo matemático que permita entender la evolución cultural, sea todavía una empresa muy difícil que, no obstante, empieza a ser acometida por los autores mencionados y por los teóricos de la inteligencia artificial. 

Filósofos como Daniel Dennett, Donald Davidson y Jesús Mosterín han contribuido a desarrollar una teoría de la cultura que saca partido a la noción de meme. En particular, y según Mosterín, la cultura actual de un individuo en un momento determinado sería el conjunto de los memes presentes en el cerebro de ese individuo en ese momento. A su vez, la noción vaga de cultura de un grupo social es analizada por el mismo autor en varias nociones precisas distintas, definidas todas ellas en función de los memes presentes en los cerebros de los miembros del grupo.

Otros autores han señalado una idea semejante y han propuesto otros términos para designar estas unidades mínimas de información cultural. Así, por ejemplo, Edward O. Wilson y C.J. Lumsden han propuesto el término culturgen, y aunque en las obras de dichos autores hay un más amplio tratamiento cuantitativo de la transmisión de los culturgenes, se ha acabado imponiendo la terminología de Dawkins, aunque no todos los defensores de la teoría memética compartan todas las tesis de dicho autor.

La utilización de la teoría de los memes se ha extendido por varias ramas de la ciencia y el pensamiento, pero no es aceptada universalmente, ni siquiera en el contexto de los estudios evolucionistas. Para algunos es una simple ocurrencia de Dawkins, un paralelismo innecesario que intentaría extrapolar al mundo de la cultura su teoría de los genes egoístas, lo que incluso podría llevar a conclusiones indeseables si se aplica al mundo de la política.
Contra esta teoría se ha manifestado Marvin Harris en "Teorías sobre la cultura en la era posmoderna". Considera que la ﬁliación última de esta teoría ideacional de la cultura es el platonismo.





</doc>
<doc id="21716" url="https://es.wikipedia.org/wiki?curid=21716" title="Felix Klein">
Felix Klein

Felix Christian Klein (Düsseldorf, 25 de abril de 1849 - Gotinga 22 de junio de 1925) fue un
matemático alemán que demostró que las geometrías métricas, euclidianas o no euclidianas, constituyen casos particulares de la geometría proyectiva. En 1872, presentó una notable clasificación de la geometría, el "programa de Erlangen", que puso fin a la escisión entre geometría pura y geometría analítica. En esta clasificación el concepto de grupo desempeña un papel fundamental, ya que el objeto de cada geometría se convierte en el estudio del grupo de transformaciones que la caracteriza. 

Al igual que Bernhard Riemann, Klein consideraba la teoría de funciones de variable compleja como una teoría geométrica y traspasó directamente el concepto a la física. Su estudio de las funciones modulares sigue siendo esencial para los investigadores. 

Profesor de la Universidad de Gotinga (1886), fue el fundador de la "Gran Enciclopedia de las matemáticas" (1895) y uno de los abogados y artífices de la renovación de la enseñanza de las matemáticas en los estudios secundarios. Klein fue además un importante organizador de grupos científicos y de actividades docentes en equipo. Se le considera como uno de los principales contribuyentes a que Gotinga se transformara en un importante centro para el desarrollo de la matemática en Europa. 

Lleva su nombre la célebre botella de Klein, superficie con una sola cara.

Klein estudió en Bonn, siendo discípulo de Rudolf Lipschitz y Julius Plücker, de quien más tarde fue su asistente. Tras la muerte de Plückers, Alfred Clebsch asumió la labor editorial de su obra inconclusa y delegó en parte este trabajo al talentoso Klein. Klein obtuvo su doctorado en 1868 bajo la tutoría de Lipschitz con un tema de geometría aplicada a la mecánica. 
En 1869 estuvo en la Universidad de Berlín y asistió allí a una cátedra de Leopold Kronecker sobre formas cuadráticas. Participó en los seminarios de Ernst Kummer y Karl Weierstrass, donde también conoció a Sophus Lie, con quien trabó amistad y estuvo en 1870 en París en viaje de estudios. Debido a la guerra francoalemana regresó a Alemania. Obtuvo el grado y habilitación como profesor en 1871 con Clebsch en Gotinga y permaneció allí entre 1871 y 1872 como docente privado.

Por gestiones de Clebsch obtuvo en 1872 un llamamiento como profesor en Erlangen. La trayectoria de su carrera lo llevó en 1875 a la Universidad Técnica de Múnich. En ese mismo año contrajo matrimonio con Anna Hegel, una nieta de Georg Wilhelm Friedrich Hegel.

En el año 1880 Klein recibió el requerimiento de ir a Leipzig como profesor de geometría. En este período de Leipzig tuvo lugar su etapa creativa más productiva científicamente. Así, mantenía correspondencia con Henri Poincaré y se dedicaba simultáneamente a la organización de la docencia. Esta doble carga de trabajo condujo finalmente a un colapso corporal. En 1886 aceptó un nombramiento en Gotinga, donde permaneció hasta su muerte. Aquí se dedicó sobre todo e intensivamente a las tareas de organización científica, mientras David Hilbert, quien había sido llamado a Gotinga gracias a su gestión en 1895 continuó expandiendo la fama de Gotinga como uno de los centros mundiales de la matemática de aquel entonces. En 1914 obtuvo el Premio Ackermann Teubner. Desde 1908 representó a la Universidad de Gotinga en la Cámara del Parlamento de Prusia. En 1924 Klein fue nombrado miembro honorario del DMV, siendo su presidente en 1897, 1903 y 1908. Fue sepultado en el Cementerio de la ciudad en la calle "Kasseler Landstraße" de Gotinga.





</doc>
<doc id="21718" url="https://es.wikipedia.org/wiki?curid=21718" title="Alfonso Herrera (actor)">
Alfonso Herrera (actor)

Alfonso Herrera Rodríguez (28 de agosto de 1983) es un actor mexicano. 

Alfonso comenzó su carrera interpretando un papel antagónico en la película "Amarte duele" (2002), es hasta su papel en la telenovela "Rebelde" (2004) que alcanzó fama internacional, formando además parte del exitoso grupo RBD. 

En 2009, con la terminación de la agrupación, anunció su retiró del mundo de la música para dedicarse a la actuación. Luego de tener el papel protagónico en la telenovela "Camaleones" (2009), retomó su carrera como actor de cine participando en películas como "Venezzia" (2009) y "Así es la suerte" (2011). 

Realizó participaciones en series de televisión, como "El equipo" (2011), "El Diez" (2011) y "Sense8" (2015), así como también obras de teatro tan diversas tales como "Rain Man" (2010) y "Nadando con tiburones" (2012).

Alfonso Herrera nació el 28 de agosto de 1983 en la Ciudad de México. Paso su infancia dividida entre México, D.F. y la ciudad de Guadalajara. Inició su carrera en el teatro con obras como "Las brujas de Salem", "Cómo matar a un ruiseñor" y "Antígona". En 2002 realizó su primer participación en la película mexicana "Amarte duele" del director Fernando Sariñana. Luego de su participación en el cine, el productor Pedro Damián le dio la oportunidad de interpretar el papel de Juan David en la telenovela "Clase 406". 

En 2004, Alfonso trabajó nuevamente con el productor, en esta ocasión para la telenovela mexicana "Rebelde", en la que dio vida al personaje de Miguel Arango. Ese mismo año se integró a la banda RBD, conformada además por Anahí, Dulce María, Maite Perroni, Christopher Uckermann y Christian Chávez, sus compañeros de telenovela. En noviembre de 2004, RBD lanzó su álbum debut titulado "Rebelde", el disco obtuvo reconocimiento de disco de diamante y oro en México por vender más de medio millón de ejemplares. Con RBD, Alfonso lanzó siete álbumes de estudio, tres álbumes en vivo y siete DVDs, la agrupación consiguió múltiples discos de platino, oro y diamante, realizó giras por la gran mayoría de lugares en el mundo, lo que significó uno de los acontecimientos populares más importante de la música mexicana de las últimas décadas. Visitó más de 23 países, cantó en 116 ciudades, vendió más de 57 000 000 sus producciones musicales, 17 000 000 descargas digitales, cuatro millones de DVD y vendió más de dos millones de entradas de sus conciertos aunado a más de 20 000 000 artículos de merchandising. 

En 2007, el actor inició las grabaciones de la serie mexicana "", el cual narra, de forma ficticia, la vida de los integrantes de la banda. En noviembre de 2007, Alfonso comenzó las grabaciones de la comedia romántica "Volverte a ver", del director Gustavo Garzón, creador de "Cansada de besar sapos". La película se estrenó el 25 de diciembre de 2008 en los cines. En marzo de 2008, regresó a sus inicios al integrarse al elenco de la puesta en escena "Pillow Man", con un papel pequeño para no interferir con las presentaciones de RBD. En septiembre de 2008 protagonizó la primera temporada de la serie "Terminales" junto a la actriz Ana Claudia Talancón. 

A mediados de 2008, RBD anunció su separación y su último tour titulado Gira del Adiós, después de cuatro años de éxito, lanzaron el disco con sus mejores éxitos. En el 2009 publican su último disco en estudio titulado "Para olvidarte de mí".

En abril de 2009, Alfonso trabajó en la segunda temporada de la telenovela Mujeres asesinas interpretando el papel de Esteban en el episodio . El 27 de julio de 2009, recibió un papel protagónico en la telenovela de Rosy Ocampo, "Camaleones", donde interpretó a Sebastián Jaramillo y en la que compartió créditos con la cantante mexicana Belinda. 

En septiembre de 2009 prestó su voz al personaje principal de la película "Igor", dirigida por Tony Leondis. El 13 de octubre de 2009 salió al aire el undécimo episodio de la tercera temporada de la serie Tiempo final, titulado "El billete", en el cual interpretó el papel de Arturo. El 25 de septiembre de 2009 se estrenó la película venezolana "Venezzia" en la que trabajó junto a las actrices venezolanas Ruddy Rodríguez y Johanna Morales. Herrera recibió por su actuación el premio al mejor actor en el "Festival Internacional de Cine de Canadá". La película dramática se hizo acreedora de siete premios internacionales. 
En abril de 2010 participó en el juego especial de fútbol entre famosos y ex integrantes de la selección nacional de Estados Unidos para MTV llamado "Rock N' Gol". El 19 de noviembre de 2010 se estrenó la obra "Rain man", inspirada en la película de 1988, "Rain Man". Alfonso interpretó al personaje de Charlie Babbitt. En julio de 2010 inició el rodaje de la película "Así es la suerte", dirigida por Juan Carlos de Llaca, donde interpretó el papel de Guillermo. El 11 de mayo de 2011 se estrenó la serie mexicana "El equipo" en la cual interpretó el papel de Fermín. 

El 19 de agosto de 2011 se estrenó en los cines "Así es la suerte". El 1 de septiembre de 2011, se estrenó la serie para televisión "El Diez", basada en el fútbol y transmitida por ESPN Deportes. El 16 de noviembre de 2011 se estrenó el segundo episodio, Los Mártires de Puebla, de la serie "El encanto del águila" en la cual interpretó el papel de Aquiles Serdan.

El 26 de enero de 2012 se estrenó la obra de teatro "Nadando con tiburones", producida por Tina Galindo y Claudio Carrera, donde Herrera trabajó junto a Demián Bichir y Ana de la Reguera. El 30 de marzo de 2012 se estrenó la película Dr. Seuss' The Lorax, el actor realizó el doblaje del personaje Ted. El 24 de octubre de 2012, se presentó en el Teatro Victoria el "Réquiem a Pedro Infante", como invitado especial en la ciudad de Durango acompañado de alumnos de la Prepa Tec de la misma ciudad.
El 24 de marzo de 2013 se estrenó la película animada "Los Croods" en la cual Herrera realizó el doblaje del personaje Guy. En abril de 2013 se estrenó la película dramática "Obediencia perfecta" en la cual interpreta el papel de Sacramento Santos. 

El 1 de noviembre de 2013 se estrenó la película de terror titulada "Espectro", Alfonso compartió elenco con Paz Vega y Maya Zapata, y en la cual el actor interpretó a Mario. El 15 de noviembre de 2013 se estrenó la película argentina "Metegol", del director argentino Juan José Campanella, donde Herrera realizó el doblaje del personaje Amadeo. 

El 13 de enero de 2014 se estrenó el programa SuperCerebros, transmitido por National Geographic Channel en el cual el actor realiza la tarea de jurado. 

El 27 de abril de 2015 se estrenó la segunda temporada del programa "La ciencia de lo absurdo" en NatGeo conducida por Herrera.

El 5 de junio de 2015 se estrenó la serie "Sense8", dirigida por las hermanas Wachowski, en la cual Alfonso interpreta a Hernando, pareja del personaje Lito Rodríguez, interpretado por Miguel Ángel Silvestre.
El 9 de julio de 2015 se estrenó en México la película animada "Minions" donde Herrera realizó el doblaje del personaje Gru.

El 26 de octubre de 2015 se estrenó la serie "El Dandy", donde Herrera interpretó a José Montaño, un policía encubierto que se hace llamar Daniel "el Dandy" Bracho, el cual se introduce en una banda de narcotraficantes que opera en la Zona Rosa capitalina. La serie cuenta con 70 episodios transmitidos por TNT Series. 

En 2016 actuó en la serie de televisión de FX, "El exorcista", dando vida al personaje de un sacerdote de nombre Tomás Ortega.Ese mismo año interpretó el papel protagonista en "El elegido", película de Antonio Chavarrías sobre el asesinato de Leon Trotsky por Ramón Mercader.

Alfonso Herrera ha trabajado en diversas campañas de concientización y trabajos humanitarios, en julio de 2012 se convirtió en embajador de la "Fundación Non Violence", creada por Yoko Ono, con motivo de ayuda para erradicar la violencia y llevar un mensaje de paz. En octubre de 2012 se convirtió en vocero de la campaña "Toxic Tours", creada por la organización Greenpeace, el motivo principal fue denunciar la contaminación en cuerpos de agua en México. 

Herrera se convirtió en la imagen de "Running Day", que tuvo comienzo el 10 de febrero de 2013, se trató de la primera clínica desarrollada en México para compartir con los corredores las técnicas, tips, métodos de entrenamiento y alimentación, que ayuden a los deportistas en su desarrollo. En marzo de 2013, el actor se convirtió en el vocero de la campaña "Va por mi cuenta", el principal objetivo es garantizar que los niños en situación vulnerable en México tengan acceso a una alimentación integral y balanceada.





</doc>
<doc id="21724" url="https://es.wikipedia.org/wiki?curid=21724" title="Himno de la Comunidad de Madrid">
Himno de la Comunidad de Madrid

El Himno de la Comunidad de Madrid es un poema escrito por Agustín García Calvo, con música del compositor Pablo Sorozábal Serrano. La composición es el himno oficial de la Comunidad de Madrid (España) desde el 24 de diciembre de 1983, fecha de su publicación en el diario oficial de la región.

El himno fue compuesto a petición del gobierno de la Comunidad de Madrid que llegó al poder en 1983, año de su constitución. Durante el proceso de reorganización territorial del Estado, se decidió que la provincia madrileña fuera una autonomía uniprovincial, separada de ambas Castillas. El primer presidente de la Comunidad de Madrid, Joaquín Leguina, encargó al filósofo Agustín García Calvo la composición del himno. Éste aceptó por el simbólico precio de una peseta.

La letra del himno es un poema que trata con cierta sorna la nueva organización territorial del Estado español y la propia existencia de la Comunidad de Madrid. A diferencia de los himnos de otras autonomías, como Comunidad Valenciana ("Himne de l'Exposició"), Cataluña ("Els Segadors"), Andalucía ("Himno de Andalucía") o Asturias ("Asturias, patria querida"), este himno tiene un uso testimonial, prácticamente relegado a algunos actos oficiales, como la conmemoración del levantamiento del 2 de mayo de 1808.

1

2

3


</doc>
<doc id="21727" url="https://es.wikipedia.org/wiki?curid=21727" title="Peter Cushing">
Peter Cushing

Peter Wilton Cushing (Kenley, Londres, 26 de mayo de 1913-Canterbury, Kent, 11 de agosto de 1994) fue un actor británico de cine, teatro y televisión.

Él y su hermano mayor, David, se criaron en Dulwich Village, un suburbio del sur de Londres, y más tarde volvieron a Surrey con su madre, Nellie Marie, y su padre, George Edward Cushing, que era agrimensor.

A edad temprana, Cushing fue atraído por la actuación, inspirado por su tía favorita, que era una actriz de la época. Mientras, en la escuela, un joven Cushing seguía interesado en la actuación y el dibujo, un talento al que él dio buen uso más tarde en su primer trabajo como un ayudante de agrimensor del gobierno en Surrey. En este periodo, Peter se metió también en el teatro local como aficionado, hasta que se mudó a Londres aprovechando una beca para la Escuela Municipal de Música y Drama. Trabajó en el teatro de la época, decidiendo en 1939 dirigirse a Hollywood, donde hizo su interpretación en la película "El hombre de la máscara de hierro" (1939). Otras películas de Hollywood en que participó fueron "A Chump at Oxford" (1939), con Stan Laurel y Oliver Hardy; "Vigil in the Night" (1940), y "They Dare Not Love" (1941). Sin embargo, después de una corta estancia, Cushing volvió a Inglaterra.

Más tarde apareció en Nueva York haciendo interpretaciones en Broadway y luego en Canadá. En apoyo a su patria, contribuyó al esfuerzo de la guerra durante la Segunda Guerra Mundial uniéndose a la Asociación de Servicios Militares de Entretenimiento.

Después de la guerra, Cushing tuvo su gran aparición con "sir" Laurence Olivier en la película "Hamlet" (1948), en la cual el futuro compañero de Cushing, Christopher Lee, tuvo un pequeño papel. Ambos actores también aparecieron en "Moulin Rouge" (1952), pero no coincidieron de nuevo hasta que filmaron sus últimas películas de terror. Durante la década de 1950 Cushing llegó a ser una cara familiar en la televisión inglesa, apareciendo en numerosas películas para este medio, como "Beau Brummell" y "La criatura", hasta que a finales de la década comenzó su trabajo con la asociación legendaria Hammer Productions en sus nuevas versiones del terror clásico de 1930. Su trabajo en la productora está íntimamente relacionado al del director Terence Fisher, realizando papeles relevantes en muchas de sus películas, como "La maldición de Frankenstein" (1957), Drácula (1958), "El perro de los Baskerville" (1959) y "La momia" (1959).

Cushing siguió interpretando los papeles de doctor Frankenstein y de doctor Van Helsing, así como también otros personajes de horror, en películas de la Hammer durante los siguientes veinte años. Peter Cushing apareció también en muchas películas para la otra gran productora de cine de terror de la época, la Amicus Productions, incluyendo "Dr. Terror" (1965) y sus antologías posteriores de horror, un par de películas del Dr. Who (1965, 1966), "I, Monster" (1971), y otras. A mediados de la década de 1970, estas compañías habían parado la producción, pero Cushing, firmemente establecido como una estrella de terror, continuó con el género en varias ocasiones.

En 1976 es convocado para la película "", donde apareció como uno de los personajes más reconocidos, el Gran Moff Tarkin, a pesar de haber sido originalmente considerado para el papel de Obi-Wan Kenobi. Cushing aceptó el papel por una sencilla cuestión: «Mi criterio para la aceptación de un papel no se basa en lo que me gustaría hacer. Trato de tener en cuenta lo que al público le gustaría verme hacer y yo pensaba en los niños que adoran Star Wars».

Durante la producción, Cushing fue presentado con botas de montar que no le calzaban bien, y le pellizcaban los pies tanto que George Lucas le dio permiso para desempeñar el papel usando zapatillas. Los operadores de cámara lo filmaron por encima de las rodillas o de pie detrás de la mesa de la sala de conferencias.

Para "", Lucas quería a Cushing, ya difunto, para repetir su papel de Tarkin mediante el uso de imágenes de archivo y de la tecnología digital, pero las técnicas de edición no estaban al nivel y finalmente esto se hizo imposible. Además, la escena en cuestión requería una apariencia de cuerpo entero de Tarkin, pero como Cushing había grabado sus escenas con zapatillas en lugar de botas no había ninguna disponible. Finalmente, Wayne Pygram tomó el papel. Pygram fue elegido porque se consideró que se parecía mucho a Cushing. 

Para la película de 2016 "Rogue One: una historia de Star Wars", el actor inglés Guy Henry interpretó al Gran Moff Tarkin, y luego en post-producción reemplazaron digitalmente su cara por la de Cushing.

Cushing también fue un actor de extensa carrera en la televisión desde los inicios de la misma. Fue invitado en decenas de series, como "Pride and Prejudice" (1952), "Epitaph for a Spy" (1953), "BBC Sunday-Night Theatre", "ITV Television Playhouse", "Los vengadores", "Great Mysteries", "", "Los nuevos vengadores" y "Hammer House of Horror", entre muchas.

También interpretó a Sherlock Holmes en dieciséis episodios, en la serie del mismo nombre, repitiendo el papel en la película "Sherlock Holmes and the Masks of Death" ("Sherlock Holmes y las máscaras de la muerte") (1984), con John Mills en el papel de Dr. John Watson.

Su último trabajo fue como conarrador en "Flesh and Blood, the Hammer Heritage of Horror", producido por el escritor y director estadounidense Ted Newsom.

En 1989 fue nombrado Oficial del Imperio británico en reconocimiento por sus contribuciones a la profesión interina en el Reino Unido y en el ámbito internacional.

Peter Cushing falleció de cáncer el 11 de agosto de 1994 en Canterbury, Inglaterra.



</doc>
<doc id="21728" url="https://es.wikipedia.org/wiki?curid=21728" title="Kenny Baker">
Kenny Baker

Kenneth George Baker (Birmingham, Inglaterra, 24 de julio de 1934 — Mánchester, Inglaterra, 13 de agosto de 2016) fue un actor que se dedicó al mundo del espectáculo y al cine junto con su amigo Jack Purvis, y famoso por interpretar al androide R2-D2 en la saga cinematográfica "Star Wars".

Sus interpretaciones en el mundo del cine fueron en su mayoría papeles menores, destacando "Circus of Horrors" (1960). En 1977 trabajó en "Wombling Free", pero ese año tuvo su papel más importante, interpretando al mundialmente famoso robot R2-D2 en "La guerra de las galaxias" de George Lucas, repitiendo papel en "El Imperio contraataca" de 1980 y en "El retorno del Jedi" de 1983. En esta saga compartiría gran parte de sus escenas con el actor Anthony Daniels, quien interpreta al inseparable robot C-3PO. Cabe destacar que en esta saga, Purvis apareció en las tres películas haciendo diferentes papeles pequeños. 

También apareció en "El hombre elefante", "Flash Gordon" (ambas de 1980), en "The Hunchback of Notre Dame" (1982), "Amadeus" (1984), "Mona Lisa" (1986), volviendo a trabajar con George Lucas en "Labyrinth" (1986). Sus papeles repetían la constante en películas de relatos y cuentos fantásticos en su mayoría ("Willow" (1988), etc). 

Volvió a ser llamado a las filas por George Lucas para volver a interpretar a R2-D2 en "La amenaza fantasma" en 1999, volviendo a encontrarse con su compañero de reparto Anthony Daniels, actuando ambos también en "El ataque de los clones" (2002) y "La venganza de los Sith" (2005), con lo que se consolidaron como los personajes que han actuado en todas las películas de la saga "Star Wars".

Baker interpretó nuevamente a R2-D2, en "", estrenada en diciembre de 2015.

Kenny Baker falleció el 13 de agosto de 2016 a los 82 años de edad tras sufrir una larga enfermedad.



</doc>
<doc id="21729" url="https://es.wikipedia.org/wiki?curid=21729" title="Billy Dee Williams">
Billy Dee Williams

William December Williams Jr. (n. 6 de abril de 1937 en Nueva York), más conocido como Billy Dee Williams, es un actor estadounidense, famoso por haber interpretado a Lando Calrissian en las películas "" (1980) y "" (1983).

Estudió arte dramático antes de empezar su carrera en "The Last Angry Man" (1959), interpretando a un malvado de la calle, y comenzó a actuar en diversos filmes durante los años 1970, como "The Out of Towners" (1970), "Lady Sings the Blues" junto a Diana Ross (1972), "Hit!" (1973), "The Take" (1974). También trabajó en diversos papeles para la televisión de la época. Hizo una interpretación en "The Bingo Long Traveling AllStars & Motor Kings"" (1976) y apareció en "El Imperio contraataca" (1980), de la saga de "Star Wars", interpretando al personaje de Lando Calrissian, papel que repitió para la continuación de la saga en "" (1983). En 1981 apareció junto a Sylvester Stallone en "Nighthawks".

A partir de entonces ha realizado papeles menores, como en el caso de la película de "Batman" de Tim Burton (1989) que interpretaba a Harvey Dent. Tras su ausencia en "Batman Returns", se dijo que en efecto, veríamos la transformación de Dent en el villano Dos Caras en "Batman Forever". Al final, Dos Caras fue interpretado por Tommy Lee Jones en la versión de Joel Schumacher.

Más recientemente Billy Dee Williams ha aparecido en series como "Lost", en la tercera temporada, en el capítulo 14 "Exposé". También ha actuado en "Private Practice", en "Scrubs", en "White Collar" y "Modern Family".

En cuanto a películas, en el año 2009 realizó un pequeño papel en la película "Fanboys" junto a su compañera en "Star Wars", Carrie Fisher.

El 2 de marzo de 2015 se anunció que iba a realizar un cameo en , aunque finalmente no apareció en la película.



</doc>
<doc id="21730" url="https://es.wikipedia.org/wiki?curid=21730" title="Frank Oz">
Frank Oz

Richard Frank Oznowicz, más conocido como Frank Oz (Hereford, Reino Unido, 25 de mayo de 1944), es un director de cine, actor y titiritero inglés nacionalizado estadounidense.

Nació en Hereford, Reino Unido de padres franceses. Su padre era judío y su madre católica. Oz se trasladó a California, Estados Unidos con sus padres cuando tenía cinco años.

Oz comenzó sus trabajos con títeres desde los 12 años. Se unió al equipo de Jim Henson de titiriteros siete años después y llegó a ser gradualmente el colaborador más cercano de Henson, en las series de televisión para niños "Sesame Street", "Los Muppets" y sus películas. Así pues Oz es quien ha dado vida a personajes tan entrañables como la cerdita Miss Piggy, el oso Fozzie, Beto, Archibaldo, el Monstruo Comegalletas entre otros.

Ha dirigido varios largometrajes, entre ellos codirigió la película de fantasía "The Dark Crystal" (1982). 

Preparado para extenderse más allá del mundo de The Muppets, realizó una nueva versión musical estilizada de "Little Shop of Horrors" (1986), que probó su brío como cineasta. Desde entonces ha dirigido comedias más convencionales como "Dirty Rotten Scoundrels" (1988), "¿Qué pasa con Bob?" (1991), y "Esposa por sorpresa" (1992). 

Oz hizo algunos cameos en cuatro películas de John Landis: "The Blues Brothers" (1980), "Un hombre lobo americano en Londres" (1981), "Trading Places" (1983) y "Espías como nosotros" (1985).

Otro de sus trabajos más conocidos fue dar vida a Yoda, el sabio Maestro Jedi de Star Wars, a quien Frank Oz daba voz y movimiento (en los Episodios V y VI, pues en el Episodio II y III se creó digitalmente). 

Algunos de sus trabajos más destacados son




</doc>
<doc id="21731" url="https://es.wikipedia.org/wiki?curid=21731" title="Jeremy Bulloch">
Jeremy Bulloch

Jeremy Bulloch (16 de febrero de 1945) es un actor británico nacido en Market Harborough, Leicestershire, Inglaterra.

Jeremy nació en el pueblo de Market Harborough en el centro de Inglaterra. Pertenecía a una familia de cinco hermanos. A la edad de cinco años ya disfrutaba actuando para la escuela. Después de suspender un examen de escuela a la edad de once años, Jeremy pareció sellar su destino y pronto asistía a la Escuela de Drama de la Academia de la Corona, donde pronto haría su primera aparición profesional a la edad de doce años en un anuncio para un cereal de desayuno.

Tras sus muchas apariciones en la televisión infantil, su carrera cambió enormemente a los 17 años cuando tuvo un papel importante en la película musical "Summer Holiday" (1963). En breve Jeremy Bulloch participó en la BBC con "The Newcomers" (1965) que duró tres años y le convirtió en un nombre conocido en las casas del Reino Unido. En 1969, Jeremy fue a Madrid para interpretar un papel importante en una película musical llamada "Las Leandras" (1969). A esta película le siguieron dos películas mayores: "La Virgen y el gitano" (1970) y "María, la Reina de los escoceses" (1971). 

Durante los años 70 Bulloch realizó muchas otras apariciones en pantalla, inclusive en películas de James Bond. En 1977 Jeremy estuvo seis meses en Oriente, donde pasó por Singapur y viajó a las Filipinas, Hong-Kong, Malasia, Tailandia y filmó en Indonesia un documental del drama que BBC llamó 'El Proyecto de Sadrina'. Este documental se diseñó para enseñar el inglés a la gente en Oriente, principalmente a los chinos. En un viaje unos 15 años después a China, fue reconocido instantáneamente por centenares de personas que le decían que habían aprendido su inglés del Proyecto de Sadrina.

En 1978 Jeremy Bulloch protagonizó una serie de humor "Agony" (1979), que era co-escrita por un americano llamado Len Richmond. Estaba trabajando en esta serie cuando se le preguntó si quería interpretar un papel en "El Imperio contraataca " de la saga de George Lucas. Instantáneamente contestó que sí. Su papel fue el de Boba Fett, un cazador de recompensas. El personaje tuvo un éxito asombroso y fue y sigue siendo el favorito de muchos fans de la saga. Pronto siguió "" (1983) y llamaron a Jeremy para que volviese a interpretar a Boba Fett. También tuvo el papel de un Almirante en "El Imperio contraataca ", en La Ciudad de las Nubes, es el almirante que sostiene a Leia Organa cuando le dice a Luke Skywalker que es una trampa.
Desde entonces ha interpretado muchos papeles en la televisión y en la época final del western. 
Bulloch ha hecho también dos viajes mundiales de teatro que cubren Europa y Oriente. Jeremy apareció regularmente en la serie favorita de TV, "Robin de Sherwood" (1984), donde participó también su hijo Robbie. 'Robin de Sherwood' tiene muchos seguidores por todas partes del mundo, y Jeremy asiste la convención 'el Espíritu de Sherwood' en Novi, Michigan cada año, si el trabajo lo permite. Otra serie popular en la que él ha aparecido es "Doctor Who" (1963).El Ha dado conferencias muy importantes En "Expo-comics" (Comic-con,Con-comics, etc.) Lamentablemente muchos no conocen su trabajo y no es muy reconocido.
Desde que se relanzó la saga de Star Wars en 1997, el interés en el personaje de Boba Fett le ha brindado a Jeremy que sea invitado a muchas convenciones de la ciencia ficción y acontecimientos por todas partes el mundo. Su correo de fans ha aumentado cinco veces, y trata de contestar de algún modo a todos los que le escriben. 
Jeremy Bulloch disfruta del placer de viajar; en los últimos años él ha estado más tiempo en el exterior que en casa. Ha reunido una cantidad impresionante de cosas memorables de Boba Fett, regalos de fans y amigos. Su oficina se parece a un museo de Boba Fett.

Jeremy tiene tres hijos, y vive en Londres con su esposa Maureen.


</doc>
<doc id="21733" url="https://es.wikipedia.org/wiki?curid=21733" title="Fernando Vizcaíno Casas">
Fernando Vizcaíno Casas

Fernando Vizcaíno Casas (Valencia, 23 de febrero de 1926 – Madrid, 2 de noviembre de 2003) fue un escritor, periodista y abogado laboralista español.

Hijo de un fabricante de paraguas y abanicos, en 1948 se inició en el periodismo en "Acción", órgano del Sindicato Español Universitario (SEU), como crítico de cine. Colaboró con Radio Nacional de España y los diarios "Las Provincias" y "Jornada". En 1950 se trasladó de Valencia a Madrid para cursar estudios de Derecho. Consideraba al periodismo como su verdadera vocación, y con el tiempo llegaría a ser columnista en medios de líneas editoriales tan diferentes como el diario "El Alcázar" y la revista "Interviú". 

Como abogado laboralista se especializó en los aspectos jurídicos concernientes al teatro, la cinematografía y los derechos de los actores. Publicó "Summa de legislación del espectáculo" (1962) y "La nueva legislación cinematográfica española" (1964). Además publicó un completo "Diccionario de cine español (1896-1966)" (1968).

En 1949 ganó el Premio Teatral para Universitarios Hispanoamericanos, con su comedia "La senda iluminada". De esa manera inició una carrera como dramaturgo y guionista que lo llevó a obtener numerosos premios y distinciones, como el Premio para Noveles fue para su obra "Los derrotados" (1950), el Premio Nacional de Teatro Calderón de la Barca por "El baile de los muñecos" (1951), el Premio Valencia de Teatro con "El escultor de sus sueños" (1953) y la Medalla del Círculo de Escritores Cinematográficos (1955). En 1984 la Editorial Planeta en conjunto con el gremio de libreros de Madrid lo eligieron "Escritor del año". Obtuvo la Medalla de Oro al Mérito en el Trabajo en 2001, y en julio de 2002 fue electo miembro del "Consejo Valenciano de Cultura".

Tuvo una destacada labor como guionista de cine y de telenovelas y otros programas para TVE, de 1963 a 1965, tarea que le hizo merecedor a su segunda Medalla del Círculo Escritores Cinematográficos a la mejor labor literaria (1966), el Premio del Ministerio de Información y Turismo en la categoría de periodismo cinematográfico (1966) y el Premio Periodístico de la Fundación Nacional Francisco Franco (1978). Incluso actúo en adaptaciones de sus obras y en producciones televisivas. Varias de sus obras fueron llevadas al cine ("Niñas... ¡al salón!", "Hijos de papá", "...Y al tercer año, resucitó", "Las autonosuyas", "La boda del señor cura", etc.) en su mayoría dirigidas por Rafael Gil.

A partir de 1971, con su libro de crónicas "Contando los 40", comenzó a publicar narrativa, ensayos, crónica, sátira política, testimonios autobiográficos, obra en la cual abarcó gran parte de las diversas etapas de la historia española del siglo XX. En 1978 alcanzó su primer gran éxito de ventas con la novela "...Y al tercer año, resucitó", a la que calificó de historia-ficción, y que juega con la idea de la contemplación que de la sociedad española posfranquista tendría un Franco resucitado. De ahí en más se convirtió en un auténtico superventas con más de cuatro millones de ejemplares vendidos de su obra, convirtiéndose en uno de los autores contemporáneos más leídos de España y de Hispanoamérica.

La sátira política, la nostalgia, la ironía, el humor corrosivo, las caricaturas apenas disimuladas o explícitas de políticos y otros personajes camaleónicos y acomodaticios del momento, y la visión crítica de los años posteriores al final del franquismo caracterizan buena parte de su narrativa. Muchas de sus obras son testimonio de su nostalgia por personajes, lugares, ámbitos sociales y costumbres desaparecidas en España. Admirador del pensamiento de José Antonio Primo de Rivera, también realizó una defensa explícita del franquismo, en particular en "¡Viva Franco! (con perdón)" (1980). Una de sus principales preocupaciones era transmitir su visión de dicho período, del cual afirmaba que sentó las bases para el posterior despegue económico y social español. Vizcaíno Casas sostenía que esa etapa no era transmitida con justicia e imparcialidad a las nuevas generaciones.

En "De camisa vieja a chaqueta nueva" (1976) retrató cuarenta años de historia española, período que va desde los años de la guerra hasta el inicio de la Transición, desde la perspectiva de un militante del bando sublevado que termina plegándose a sectores de izquierda a fin de mantener los privilegios obtenidos gracias a su cercanía a los gobernantes de turno. 

En "Las autonosuyas" (1981) satirizó el debate sobre el estado de las autonomías que tuvo su auge en la década de los 70, sin dejar de reconocer la justicia de los reclamos de las nacionalidades históricas de España, como se encargó de aclarar en la introducción a esta novela:

Las novelas "Cien años de honradez" (1984), "Los descamisados" (1989), "El señor de los bonsáis" (1992), "...Y los 40 ladrones" (1994), "Todos al paro" (1995) son a un tiempo sátira, crónica y crítica desencantada y humorística de la transición a la democracia y de los posteriores gobiernos del PSOE, presididos por Felipe González. Los cuentos de "Niñas... ¡Al salón!" (1976) y las novelas "La boda del señor cura" (1979), "Hijos de papá" (1979), "Hijas de María" (1983) y "Chicas de servir" (1985) reflejan las principales transformaciones que la sociedad española experimentó durante el siglo XX. 

"Zona Roja" (1986) describe la vida en Valencia durante la Guerra Civil, mientras esta ciudad era retaguardia y capital provisional de la República y donde Vizcaíno Casas vivió su niñez. "La sangre también es roja" (1996) muestra su visión sobre la Guerra Civil. El período de la Posguerra española es retratado en "La España de la posguerra 1939-1953" (1975) y en "Los rojos no usaban sombrero: anecdotario menudo de la posguerra" (1996).

Publicó también ucronías como "Los rojos ganaron la guerra" (1989), entrevistas como las realizadas para "Café y copa con los famosos" (1990), crónicas, reflexiones y análisis históricos y políticos de diversos períodos de España como "Un año menos: diario" (1979) y tres crónicas sobre importantes episodios del período franquista: "1973, El año en que volaron a Carrero Blanco" y "1975, El año que Franco murió en la cama" (ambas en 1993) y "1969, El año en que Franco hizo rey a don Juan Carlos" (1994). En 2002 apareció la tercera y última parte de sus memorias, "Los pasos contados".

Falleció a los 77 años, luego de años de padecer cáncer, lo cual no le impidió trabajar hasta último momento en su despacho de abogado. Ni concluir su último trabajo, "Nietos de papá: novela de historia-ficción", que fue publicado en forma póstuma. Sus restos fueron sepultados en Navacerrada.








</doc>
<doc id="21738" url="https://es.wikipedia.org/wiki?curid=21738" title="Al Qaeda">
Al Qaeda

Al Qaeda (, transcripción: "al-Qā""idah", transliteración: "alQaⱶᴉdë" : ‘la base’), o Al Qaida, es una organización paramilitar, yihadista, que emplea prácticas terroristas y se plantea como un movimiento de resistencia islámica alrededor del mundo, mientras que es comúnmente señalada como una red de terrorismo internacional. Su fundador, líder y mayor colaborador fue Osama Bin Laden (1957-2011), un multimillonario de origen saudí que estudió Religión y Ciencias Económicas en la Universidad del Rey Abdul Aziz. Aymán al-Zawahirí le sucedió como único jefe de la organización.

Investigaciones recientes —periodistas, investigadores, analistas y especialistas— afirman que Bin Laden fue financiado por la CIA en la lucha contra las tropas de la Unión Soviética en Afganistán durante la llamada guerra de Afganistán (1978-1992) en plena Guerra Fría. El apoyo iba desde la instrucción en combate hasta la entrega de armamento.

Su estructura organizativa basada en células de militantes y redes de contactos clandestinos, muy parecida al modus operandi de los cárteles de narcotraficantes, le ha dado una muy amplia movilidad de acción y una gran dificultad para desarticularla (véase: guerra red).

El nombre viene del sustantivo árabe "qāʕidah", que significa 'fundamento, cimiento, base' y que también puede referirse a una base militar. "al-" es la forma del artículo definido árabe "al-". Sería, por tanto, la base o "el fundamento".
El político británico Robin Cook señaló que el nombre indicaría "la base de datos", ya que Bin Laden gestionaba las operaciones financieras en un fichero informático llamado "al Qaida" (literalmente ‘la base [de datos]’). Desde entonces, muchos combatientes miembros de los "muyajidín" se fueron asociando a la red Al Qaida.

Bin Laden explicó el origen del nombre en una entrevista con el periodista de Al Jazeera Tayseer Alouni en octubre de 2001.

A finales de los años 70, las facciones del Partido Comunista Afgano competían por el poder, interviniendo la URSS en favor de aquella que le era más afecta (la facción de Taraki), enviando sus ejércitos y batallones de comando, quienes asesinan al Presidente Amín (facción entonces en el poder) iniciándose la guerra de Afganistán. En este período bélico, de gran trascendencia e influencia en la situación interna de la URSS, el pueblo afgano, sus distintas etnias y sus dirigentes religiosos, inician un levantamiento y guerra popular contra el ejército soviético y las milicias comunistas afganas que le eran subordinadas. Durante la guerra, las fuerzas soviéticas alcanzaron un número cercano a los 200 000. hombres, con entrenamiento y armamento de última tecnología. Coincidiendo las circunstancias con la descomposición y derrumbe del socialismo real, la guerra de Afganistán se transformó en el "Vietnam" de la URSS, a la que el pueblo ruso se resistía en colaborar y tras diez años de guerra popular islámica, las fuerzas comunistas fueron derrotadas y el ejército soviético se batió en retirada.

A la victoria islámica, confluyen diversas razones: la convicción de los afganos de estar luchando contra odiados invasores históricos; una visión religiosa del mundo, que ubica en la primera línea de sus adversarios al comunismo ateo; una mística que despertó la solidaridad de los pueblos del mundo, especialmente de los países islámicos, los que enviaron batallones de muyahidines a liberar Afganistán, entrenándose en las bases que los países árabes y occidente —especialmente los EE. UU.— apoyaban y financiaban con firmeza y resolución. Una de aquellas bases —La Base— fue fundada y dirigida por un joven saudí, de convicciones religiosas sunnitas, fundamentalista y radicalmente anticomunista.

Concluida la guerra contra los soviéticos, Al Qaeda (La Base), no fue desmovilizada por su caudillo, quien pronto se involucró en la lucha de facciones que siguió a la derrota de los comunistas. En ella, Bin Laden, alineó a su grupo con los Talibanes, participando también en operaciones significativas para el mundo musulmán, como en la extinta Yugoslavia (para detener el genocidio musulmán en Bosnia y Herzegovina). En parte originada en su radical fundamentalismo, en parte por la dinámica propia de los alineamientos ocurridos en la guerra civil afgana, Bin Laden, terminó combatiendo a quien le prestó apoyo y aliento (los EE. UU.), país al que consideran esencialmente antireligioso, prosionista y erosionador del modo de vida islámico. A su vez, Al Qaeda, es rápidamente visualizado por los EE. UU., como un grupo que deriva hacia el terrorismo antioccidental, que amenaza la seguridad estadounidense y de occidente y la estabilidad de los países árabes aliados.

En 1993 los Estados Unidos de América enviaron tropas a Somalia, para el reparto de alimento y agua, además de garantizar la seguridad de los civiles ante la guerra civil que sufría el país. Dos UH-60 Black Hawks fueron derribados durante una misión de captura que llevaron a cabo el primer destacamento de fuerzas de operaciones especiales Delta (Delta Force) y el 75.º Regimiento Ranger. Posteriormente la inteligencia del servicio militar de los Estados Unidos concluyó que gran parte de la milicia somalí fue entrenada por miembros de Al-Qaeda, algo que quedaría verificado en mayo del 2006 cuando el país se volvió a sumergir en una segunda guerra civil entre la Alianza para la Restauración de la Paz y Contra el Terrorismo (ARPCT) y milicias leales a la Unión de Tribunales Islámicos. Para el 5 de junio al menos 350 personas habían muerto en el fuego cruzado.

La organización ha construido campos de entrenamiento para aquellos militantes repartidos por el mundo, entrenando a miles en técnicas de guerrilla, uso de explosivos y conocimientos de la práctica paramilitar. Sus agentes se han involucrado en numerosos ataques, como los atentados terroristas a las embajadas estadounidenses en 1998, oportunidad en la que destruyeron las embajadas estadounidenses en Nairobi, Kenia y Dar es Salaam, en Tanzania. En Dar-es-Salaam fallecieron once personas, mientras que en Nairobi perecieron 213 personas, y sólo doce eran estadounidenses. El 12 de octubre de 2000 Al Qaida realizó el ataque suicida con bomba contra el buque de guerra estadounidense "USS Cole" en las costas de Yemen, dejando 17 "marineros" muertos e hiriendo a 39 más.

En 2001 atentaron contra las torres gemelas de Nueva York y El Pentágono de Washington secuestrando 4 aviones. Fue el ataque donde destruyeron dos de los edificios más altos de Estados Unidos y dañaron la sede central del Ejército de Estados Unidos.

En el año 2008 unas amenazas por parte de Al-Qaeda provocaron la suspensión total del Rally Dakar 2008 que a partir de entonces pasó a desarrollarse en Sudamérica.

El 26 de diciembre de 2009 fue detenido a tiempo Umar Faruk Abdulmutallab, quien intentó explotar un avión con 278 pasajeros a bordo que se dirigía a Detroit.

El 1 de mayo de 2011 es asesinado el líder de esta organización, Osama Bin Laden, por el ejército estadounidense en la localidad de Abbottabad, situada al norte de la capital de Pakistán.

En 2001 se creía que Bin Laden y otros líderes de Al Qaeda se encontraban bajo la protección de los talibanes, un grupo islámico que controlaba la mayor parte de Afganistán. En ese mismo año cambió radicalmente la actividad de este grupo, alcanzando cuotas de terror nunca antes imaginadas. Según la CIA y el FBI, 19 militantes de Al Qaeda dirigidos por el egipcio Mohammed Atta llevaron a cabo el 11-S (atentado del 11 de septiembre) contra El Pentágono y el Centro Mundial de Comercio (WTC). Aquel fue el atentado sucedido en EE. UU. más terrible de la historia de este país, con unos 3000 muertos.

Inicialmente según "los planes de al Qaeda" en 1995 era proyectar aviones como misiles a edificios de los Estados Unidos y derrumbar los iconos del poder estadounidense; dentro de estos puntos figuraban: la Torre Sears (Chicago), El Pentágono (Washington D.C.), Pirámide Transamérica (San Francisco), World Trade Center (Nueva York), La Casa Blanca (Washington D.C.) el Empire State Building (Nueva York) el Capitolio de los Estados Unidos (Washington D.C.) y el U.S. Bank Tower (Los Ángeles).

EE. UU. respondió iniciando un ataque masivo contra las fuerzas talibanes y de Al Qaeda en Afganistán, matando y capturando a miles de militantes y civiles sin relación alguna con el conflicto, obligando al resto de sus líderes a sumirse inicialmente en la clandestinidad. A pesar de la subsiguiente captura de varios de sus miembros claves (incluyendo el militante que supuestamente planeó y organizó los ataques del 11-S), la actividad del grupo y sus franquicias, lejos de desaparecer, cambiaron de organización para convertirse en una organización internacional y coordinada con militantes repartidos por todo el mundo.

Los siguientes ataques esta vez fueron en Indonesia:
Posteriormente en 2003, atentados en Arabia Saudita dejaron 35 muertos en edificios habitados por occidentales, entre otras acciones coordinadas en un esfuerzo por desestabilizar a la monarquía saudita. El 16 de mayo una cadena de atentados suicidas en Casablanca contra tres establecimientos de hostelería, entre ellos la "Casa de España", la Alianza Israelí y un cementerio judío, costaron la vida a 45 personas.

En los últimos tiempos y ya varios años después del 11-S, reaparecen con células de Al Qaeda en Europa, atribuyéndose la autoría de los atentados de Londres del 7 de julio de 2005 con más de 50 muertos, atentado del 11-M en Madrid en los que fallecieron 191 personas y 1858 resultaron heridas, e intentando ataques fallidos en Barcelona y Alemania, además de amenazar a países como Francia, Estados Unidos, Reino Unido, España, Portugal, Italia, Polonia, Dinamarca, Australia, Hungría, República Checa, Eslovaquia, Eslovenia, Estonia, Letonia, Lituania, Malta, Chipre, Israel y Kuwait.

También están amenazados todos los países miembros de la La Organización del Tratado Atlántico Norte OTAN encabezada por Estados Unidos y la Unión Europea y todos los países miembros de la Comunidad de Estados Independientes CEI encabezada por Rusia.

Paralelamente a esto, facciones de Al Qaeda en Irak luchan ferozmente contra la ocupación estadounidense, el grupo Tawhid wal Jihad dirigido por el jordano Abu Musab Al Zarqawi, el cual fue abatido por las tropas estadounidenses en junio de 2006, realizan acciones diarias contra las tropas de ocupación estadounidenses y británicas, e iraquíes afines al nuevo gobierno además de civiles. Estos ataques suman miles de muertos entre las fuerzas armadas de ambos bandos, pero especialmente han causado bajas entre la población civil.

El 11 de abril de 2007 el brazo armado de Al Qaeda en el Magreb perpetró un atentado en Argel (Argelia), dejando al menos 24 muertos y 222 heridos. Este mismo día Al Qaeda se atribuyó los atentados perpetrados el 10 de abril de 2007 en Casablanca (Marruecos).

El 1 de mayo de 2011, el presidente de Estados Unidos, Barack Obama, anunció que el líder Osama Bin Laden murió en un operativo militar estadounidense en Pakistán.
El nuevo líder de la organización es el egipcio de 60 años, Aymán al-Zawahirí.

El martes 5 de junio de 2012 el Pentágono norteamericano informaba que el día anterior un ataque con drones sobre un lugar en la región noroeste de Pakistán había causado la muerte de Abu Yaliya al Libi, supuesto número dos de Al Qaeda. De confirmarse la noticia se trataría del mayor éxito obtenido por el ejército estadounidense desde la muerte de Osama Bin Laden, ya que Libi estaba considerado como el jefe de operaciones de la organización terrorista.

Los atentados del 11 de marzo de 2004 (conocidos también por el numerónimo 11-M) fueron una serie de ataques terroristas en cuatro trenes de la red de Cercanías de Madrid llevados a cabo por terroristas yihadistas.

Se trata del segundo mayor atentado cometido en Europa hasta la fecha, con 10 explosiones casi simultáneas en cuatro trenes a la hora punta de la mañana (entre las 07:36 y las 07:40). Más tarde, tras un intento de desactivación, la policía detonaría, de forma controlada, dos artefactos que no habían estallado, desactivando un tercero que permitiría, gracias a su contenido, iniciar las primeras pesquisas que conducirían a la identificación de los autores. Fallecieron 191 personas, y 1.858 resultaron heridas.

En la tarde del 13 de marzo una llamada efectuada al canal de televisión Telemadrid permitió localizar en una papelera un vídeo en el que un hombre con acento marroquí, que afirmaba ser Abu Dujan al Afgani, posteriormente condenado por estos atentados, autodenominándose portavoz militar de Al Qaeda en Europa, reivindicaba su autoría.

El 3 de abril de 2004, la policía localizó y rodeó a varios miembros del comando terrorista en Leganés. Al verse acorralados, sus miembros se suicidaron haciendo estallar el piso en el que se habían atrincherado —siendo esto el primer atentado suicida de Europa— cuando los Geos iniciaban el asalto. En esta acción murió un agente del grupo policial, además de todos los miembros de la célula islamista allí presentes.

La rama de Al Qaeda del Magreb Islámico (AQMI) reivindicó el 8 de diciembre del 2009 por la mañana el secuestro de los tres voluntarios españoles en Mauritania, el 29 de noviembre, así como el de un botánico francés cuatro días antes en Malí. Los españoles son Albert Vilalta, Alicia Gámez y Roque Pascual.

El Ministerio español de Asuntos Exteriores dio credibilidad a la reivindicación, realizada en una cinta de audio pasada a la cadena de televisión con sede en Doha, tras someterla a estudio por parte de un comité técnico, dijo en un comunicado. "Se trata de una grabación de audio que menciona explícitamente el nombre de los secuestrados", dijo la nota del ministerio.

El portavoz del grupo islamista, que se identificó como Saleh Abu Mohammad, dijo que "Francia y España serán informadas posteriormente de las legítimas demandas de los muyahidines", refiriéndose también al secuestro de un francés en el este de Malí el 30 de noviembre.

Los tres voluntarios de la ONG catalana Barcelona Acció Solidària desaparecieron el 29 de noviembre en Mauritania cuando fueron secuestrados del convoy en el que llevaban ayuda humanitaria a varios países africanos y que se dirigía por la carretera entre Nuadibú y la capital, Nuakchot.

El convoy partió de Barcelona el 22 de noviembre, atravesó Marruecos, se dirigía a Senegal e iba a terminar el Gambia con 100.000 kilos de material de ayuda que pensaba distribuir como parte de su caravana anual.

La Audiencia Nacional abrió una investigación sobre el secuestro por tratarse de un delito contra españoles en el extranjero y por ser un posible delito de terrorismo.

Francia ha pedido a sus ciudadanos que dejen el norte y el este de Malí ante el aumento de la amenaza integrista.

Alicia Gámez fue liberada el 10 de marzo de 2010. Albert Vilalta y Roque Pascual fueron liberados el 23 de agosto de 2010.

Básicamente, la visión de la ideología de al-Qaeda es una forma extrema de Islam, la yihad, ante países o gobiernos que supuestamente actúan contra el Islam, las comunidades religiosas y los grupos étnicos como la única posibilidad de representar los intereses del Islam. Al-Qaeda cree que la única respuesta es que el Islam desarrolle el papel que le corresponde en el mundo, que hay una conspiración de varias partes del mundo contra el Islam, la cual es liderada por Israel, EE. UU. y los países de Europa Occidental. Además, se muestra convencida que mientras exista Israel y siga las influencias políticas y culturales de Occidente, la sociedad musulmana, el Islam, no puede estar unida.

Como justificación de sus acciones al-Qaeda señala varias enseñanzas religiosas y mensajes tomados del Corán. 
Para lo cual, se basa principalmente en la llamada forma primitiva del Islam, en el cual se interpreta que el enfoque se sitúa en la guerra contra los infieles, su conversión y la unificación de todos los musulmanes bajo uno califato común. En gran parte de la organización se observa un marcado antisemitismo, resultado de la lucha durante décadas contra Israel. 

Algunos miembros de al-Qaeda, como Mohammed Atta tienen o tenían una visión del mundo parecido a la de los nazis (ejemplo: Atentados del 11 de septiembre de 2001, en qué Nueva York se veía como un supuesto centro del "selecto mundo judío", como la meta). En esta visión del mundo, los judíos son considerados como infieles que no se pueden convertir, o incluso anti-musulmanes que controlan los países democráticos liberales y los estados ex-socialistas y controlan estos a su vez en contra del Islam. Ambos, supuestamente creados y controlados por los supuestos sistemas enemigos primarios, son los archienemigos escogidos de Al-Qaeda. Al-Qaeda lucha contra estas dos ideologías menos por el qué hacen que por el qué representan: el socialismo porque predica la igualdad de todas las personas y especialmente porque sus seguidores prefieren el ateísmo y los países liberales occidentales porque sus empresas son vistas como desenfrenadas y sin religión.

Osama bin Laden declaró en una entrevista en 1999, que para él y sus seguidores, no hay civiles, sino sólo enemigos para matar, sin excepción; este es el sagrado deber de todo musulmán.

Los primeros ataques se llevaron a cabo en la década de 1990, como el Atentado del World Trade Center de 1993. La operación antiterrorista del gobierno de Clinton empezó a partir de entonces y comportó ataques terroristas contra las embajadas de Estados Unidos en Dar se Salaam y Nairobi y ataques aéreos contra bases de Al-Qaeda en Sudán y Afganistán. En el año 2000 se produjo un ataque de los islamistas en el mercado navideño de Estrasburgo que fue frustrado por las autoridades de seguridad alemanas. De entrada no se pudo probar ante el tribunal un presunto vínculo con la red terrorista Al-Qaeda. La razón de esto es que Alemania es, aparte de los EE. UU., el aliado más cercano de Israel. Por otro lado, el estilo de vida se percibe, como en otros países europeos, como una forma liberal, pecaminosa y vulgar de la vida (relaciones sexuales ilegítimas, consumo de alcohol, homosexualidad legal) y como una imposición para los musulmanes que viven en Alemania.

Al-Qaeda también se basa en la propaganda, sobre todo en las sociedades árabes y musulmanas. Ve la violencia como medio para unir a todos los musulmanes en la "guerra de liberación" contra el dominio de Occidente. Estos actos de terrorismo también se llevan a cabo contra civiles musulmanes considerados como "colaboradores" o víctimas del terrorismo como variables aleatorias en la negociación. El campo de acción principal después del último llamamiento de Bin Laden a Irak, el mayor número de víctimas, así como los autores mismos, son miembros del Islam. Una nueva característica aquí es la legitimidad de los ataques suicidas que antes no se utilizaban debido a las reservas religiosas.

Al-Qaeda ha encontrado en Irak poco apoyo uniforme y está apoyada sobre todo por los terroristas extranjeros. La organización ha encontrado en Pakistán, Indonesia y Arabia Saudí un apoyo más fuerte. Además de las causas políticas, como las persistentes guerras civiles, la opresión tradicional, también se contemplan como causa de origen la tradición duradera de la esclavitud, el tráfico de personas, la misoginia y una interpretación particularmente estricta del Islam como el wahhabismo y las atrasadas culturas tribales como el pashtunwali.

Los líderes de pensamiento de Al-Qaeda también se basan en las normas islámicas de acuerdo con las cuales cada estado y forma social que esté más allá de la Sharia es reprobable y, por lo tanto, es legítimo destruir el mundo de los "infieles" con el terrorismo. Los perpetradores son mayoritariamente hombres jóvenes de baja condición social. Otros asesinos especialmente en operaciones importantes, como la del 11 de septiembre de 2001 son graduados muy entrenados. Algunos dirigentes y líderes, como el fundador Ossama bin Laden, provienen de una familia de clase alta.

En particular, en Irak, los soldados occidentales son denominados también "cruzados". El trasfondo de este calificativo son los efectos de la masacre de Maarat an-Numan (1098).

Los objetivos finales de al-Qaeda no son a corto plazo, sino que la red espera que se logren sólo en años o décadas. El objetivo principal no es necesariamente conseguir estos objetivos en sí mismos, sino poner en movimiento una cadena de acontecimientos que en última instancia tendrían que conducir a los resultados deseados. 
Cómo que el núcleo de al-Qaeda opera en secreto y lleva a cabo, entre otros, operaciones de falsa bandera, sus objetivos reales son difíciles de determinar. Después hay los vínculos con otros movimientos islamistas que persiguen intereses independientes.

Osama bin Laden, Khalid Cheikh Mohammed, Ayman al-Zawahirí y otros líderes de al-Qaeda han creado objetivos que tratan de trabajar en red con todos los medios a su alcance.

Una gran parte de sus esfuerzos al-Qaeda los ha invertido en la guerra o yihad en contra de occidente, puesto que este es el principal obstáculo para todos los pasos subsiguientes de su dominio económico y del poder político. También considera que la cooperación y el apoyo de algunos países occidentales (sobre todo la de Estados Unidos y Francia) de algunos países árabes (como Jordania, Arabia Saudí, Emiratos Árabes Unidos y Líbano) como una injerencia en los asuntos árabes internos, el propósito de los cuales sería impedir la unificación del mundo islámico y fortalecer la posición de Israel. Esta guerra de tipo al-Qaeda especialmente con los ataques terroristas contra objetivos civiles en los países de destino, para aterrorizar a la población para desestabilizar el país políticamente y dañar la economía. A menudo, los turistas son el blanco de ataques en los países musulmanes.
Está estrechamente relacionado con el ataque a la difusión del estilo de vida occidental y la exportación de los valores de la cultura islámica. El objetivo previsto es la preservación de la sociedad musulmana contra las influencias occidentales (no basadas en la jurisprudencia de la sharia para que los nacidos musulmanes sean capaces de elegir libremente su religión, la igualdad de género, que en la opinión pública se muestren abiertamente las mujeres, el consumo de alcohol, la homosexualidad legal, las relaciones sexuales ilegítimas, ...)

Mientras se logran los resultados deseados, además de la ejecución exitosa de los ataques terroristas, sus actividades incluyen la colocación de durmientes en las estructuras opuestas posibles en lugares clave o reclutar personas de ideas afines que ya están en las posiciones correspondientes (cómo Nidal Malik Hasan) y la fusión global y la creación de redes entre los islamistas y movimientos y grupos yihadistas. (El estrecho contacto con los gobernantes locales, como los talibanes, la planificación de la operación conjunta y acciones coordinadas con las organizaciones terroristas de la red, como Laichkar-al-Toiba o Abu Sayyaf).

Al-Qaeda también combate a todas las organizaciones no gubernamentales que representan una amenaza para al-Qaeda y sus objetivos. Esto es especialmente cierto para la Interpol y las Naciones Unidas. La causa de esto es principalmente la consideración de la ONU como garante de las condiciones existentes, que con sus esfuerzos de paz pone en peligro los objetivos de al-Qaeda. Así, los programas de la ONU en Somalia como por ejemplo las misiones de paz en la década de los noventa Unosom, Unosom II, y la organización del gobierno de transición de Somalia de la ONU con la prevención que los islamistas tomaran el control completo del país, mediante el movimiento al-Qaeda en Somalia. Por otro lado, las Naciones Unidas han aprobado una serie de resoluciones para frenar el terrorismo transnacional de al-Qaeda. (Compromiso de los estados miembros de la ONU para imponer sanciones a las personas que están vinculadas a al-Qaeda, listas de miembros de al-Qaeda, despliegue del ISAF, disposiciones contra la propagación de las ADM). 

Uno de los principales objetivos es el derribo de la familia real saudí y todos los otros gobiernos de los países de mayoría musulmana que no se rigen por los principios islámicos o trabajan o son amigos de potencias no islámicas (Jordania, Pakistán, Egipto...): esto es seguido por la aplicación de base de la ley islámica coránica (Sharia) en todos los países musulmanes.

Desde principios de 1990, al-Qaeda está estrechamente vinculada con los grupos separatistas musulmanes, los objetivos de los cuales se superponen con los de la red de Bin Laden. Por lo tanto, la separación de todos los territorios musulmanes y regiones de la mayoría de los otros países de credos diferentes (Mindanao de Filipinas, Daguestán, Chechenia, Ufá, y Tatarstán de Rusia, Ogaden de Etiopía, Kosovo de Serbia...) es vista como un paso importante hacia la unificación del Islam. Durante la guerra de Bosnia hubo numerosas atrocidades cometidas por los muyahidínes, entre otros, bajo el liderazgo del jefe del ejército bosnio, Rasim Delić, contra los serbios y croatas en Bosnia central y la región de Ozren. Por orden de Osama bin Laden, los muyahidínes de al-Qaeda lucharon durante la guerra con el ejército bosnio en la vanguardia. También lucharon los partidarios de al-Qaeda en Kosovo junto al UÇK. 

Llegados a este punto, las esperanzas de Al-Qaeda son que Occidente haya sido derrotado militarmente y económicamente, por lo cual espera tener las manos libres para todas las acciones adicionales:







</doc>
<doc id="21739" url="https://es.wikipedia.org/wiki?curid=21739" title="Operación Bojinka">
Operación Bojinka

Operación Bojinka (también conocido como Proyecto Bojinka) ("Bojinka", lengua árabe: بجنكة; la palabra quiere decir «explosión») fue un proyecto desarrollado por Ramzi Yousef y Jálid Sheij Mohámed, dos miembros de Al Qaeda para efectuar un ataque terrorista a gran escala previo a los ataques del 11 de septiembre. El Proyecto Bojinka fue descubierto luego de que un fuego químico atrayera la atención de la policía filipina en el 6 y 7 de enero, pero algunas lecciones aprendidas ayudaron a los que planificaron el 11 de septiembre.

Los terroristas planearon destruir once aviones en rutas entre Asia y Estados Unidos cuando estos volaran sobre el Océano Pacífico para causar unas 4 000 víctimas mortales, matar al papa Juan Pablo II durante su visita a la celebración de la Jornada Mundial de la Juventud de Manila 1995, y estrellar un avión en contra del edificio de la CIA en Langley, Virginia, todo esto pretendían llevarlo a cabo entre los días 15 y 22 de enero de 1995. La trama fue descubiera por policías de Manila (Filipinas), quienes abortaron el proyecto el 6 de enero de 1995.

Se considera como parte de la operación el atentado al Vuelo 434 de Philippine Airlines en el que una bomba explotó mientras el avión se dirigía desde Manila (Filipinas) hasta el aeropuerto de Tokio-Narita, con escala en la ciudad de Cebú, la detonación provocó la muerte de un pasajero y heridas a otros diez, el ataque se trató de una prueba previa al desarrollo del plan masivo, ya que se buscaba comprobar la efectividad de los explosivos que se utilizarían.

Los fondos para la realización de la operación fueron aportados directamente por Osama bin Laden y Riduan Isamuddin, junto con organizaciones operadas por Mohammed Jamal Khalifa, cuñado de bin Laden. Si bien las tres personas citadas eran quienes aportaban el dinero, quien fungía como financiero de los terroristas fue Wali Khan Amin Shah, un afgano residente en Manila quien inició una operación de lavado de dinero con la ayuda de su novia y otras mujeres residentes en la ciudad, el financiero del proyecto lograba abrir cuentas a nombre de otras personas mediante regalos o vacaciones. También se contó con la asistencia de una compañía denominada Konsojaya que permitía asistencia financiera y lavado de dinero a la célula terrorista.

Las transferencias de dinero se realizaban en pequeñas cantidades que rondaban entre los 12 000 y los 24 000 pesos filipinos (entre 500 y 1000 dólares de la época), los fondos eran dirigido a nombre de una persona llamada "Adam Sali", alias utilizado por Ramzi Yousef quien recogía la cuenta en un banco filipino a nombre de Omar Abu Omar, un jordano que trabajaba en el Centro de Relaciones Internacionales e Información, organización islámica manejada por Mohammed Jamal Khalifa.

Yousef, quien había sido responsable del Atentado del World Trade Center de 1993 fue el encargado de de iniciar la célula terrorista en Manila junto con otros afganos que habían llegado al país tras haberse reunido con Amin Shah en Singapur a principios de 1994.

En un principio Yousef había decido ausentarse de la ciudad de Manila, pero a su regreso fue recibido por emisarios de bin Laden quienes le pidieron que atentara contra el entonces Presidente de Estados Unidos, Bill Clinton, quien llegaría a la ciudad el 12 de noviembre como parte de una gira por Asia. Yousef pensó en distintas maneras de llevar a cabo el objetivo, pero todas fueron descartadas debido a la dificultad de realizarlas, sin embargo, esto motivó que se incluyera al papa Juan Pablo II en la lista de objetivos.

A finales de 1994, Yousef y Jálid Sheij Mohámed comenzaron a probar la seguridad del aeropuerto. Yousef reservó un vuelo entre el Aeropuerto Internacional Kai Tak en Hong Kong y el Aeropuerto Internacional Taiyuan de Taiwán, cerca de Taipéi. Mohámed reservó un vuelo entre el Aeropuerto Internacional Ninoy Aquino, cerca de Manila y el Aeropuerto Internacional de Gimpo, en las cercanías de Seúl. Los dos ya habían convertido catorce botellas de solución de lentes de contacto, que estaba fácilmente disponible en Filipinas, en botellas que contenían nitroglicerina. Yousef había pegado una varilla de metal al arco de su pie, que serviría de detonador. Los dos llevaban joyas y ropa con metal para confundir la seguridad aeroportuaria. Para sostener su afirmación de que estaban conociendo a mujeres, empaquetaron preservativos en sus bolsas.

En el mes de diciembre llegó a Manila, el pakistaní Abdul Hakim Murad para reunirse con Yousef y continuar con los preparativos. El 8 de diciembre, los dos miembros se trasladaron a los Apartamentos Doña Josefa, Yousef se encargó de los trámites bajo el alias "Najy Awaita Haddad". En el momento del registro se cometió un posible error ya que llenó un segundo formulario, las encargadas del complejo de vivienda creyeron que había tenido un error tipográfica, cuando en realidad había escrito su verdadero nombre en el primer formulario, tras pagar las cuotas de alquiler ocuparon el Apartamento 603. El complejo departamental se encontraba a unos 200 metros de la nunciatura apostólica de Manila y a medio kilómetro de la comisaría de policía número 9, el piso se convirtió en el lugar elegido para la preparación de los atentados. Los ocupantes despertaron las sospechas de los vecinos del complejo pues se trataba de personas con actitudes muy secretas y solían llevar cajas sin pedirle ayuda a nadie, las personas de administración pensaban que se trataban de estudiantes, cuando en realidad fabricaban bombas y transportaban químicos adquiridos a proveedores en Manila y Ciudad Quezón.

Debido a la complejidad del atentado, la célula terrorista determinó la realización de una serie de ataques como forma de prueba. El primero de ellos fue llevado a cabo a finales de noviembre en un centro comercial de la ciudad de Cebú. Se colocó un pequeño dispositivo de nitroglicerina en una sala de generadores, provocó daños menores pero demostró a Yousef que los explosivos que fabricaron funcionaban y eran aptos para su uso.

El 1 de diciembre de 1994 se llevó a cabo el segundo atentado preparativo, Amin Shah colocó una bomba bajo un asiento del Teatro Greenbelt de Manila, con el objetivo de probar el comportamiento de la bomba en el caso de estar colocada debajo del asiento de un avión, el artefacto estalló provocando heridas a varios clientes.

La tercera prueba se llevó a cabo el 11 de diciembre, Yousef abordó un vuelo entre el Aeropuerto de Manila y el de Tokio-Narita haciendo escala en la terminal aérea de Mactán-Cebú, el atacante colocó la bomba dentro de un chaleco salvavidas ubicado debajo de su asiento (26K), tras esto abandonó la aeronave durante la escala en Cebú. Yousef abordó el vuelo bajo el nombre "Arnaldo Forlani", usando un pasaporte italiano falso, programó la bomba para que hiciera explosión cuatro horas después de haber sido colocada, esperando que detonara cuando sobrevolaba el mar, sin embargo la aeronave se vio afectada por un retraso de 38 minutos en el aeropuerto.

La bomba explotó cuando el avión sobrevolaba la isla de Minami Daitō perteneciente a la Prefectura de Okinawa. Un fabricante de máquinas de coser japonés de 24 años, llamado Haruki Ikegami, murió en la explosión al haber ocupado el asiento 26K en Cebú, otras 10 personas resultaron heridas. El terrorista plantó el artefacto en el lugar, creyendo que se encontraba sobre el tanque de combustible, como suele ser habitual en los Boeing 747, lo que haría que al explotar se partiera en dos el avión incluso si la explosión no fuese tan potente, sin embargo, este aparato fue utilizado previamente por la aerolínea escandinava SAS y contaba con una configuración de asientos diferente a la habitual, por lo que el lugar 26K se localizaba dos filas por delante del depósito de turbosina. El artefacto explosivo causó daños pues arrancó una porción de 0,2 m² (dos pies cuadrados) de la planta de la cabina, sin embargo el fuselaje del avión permaneció intacto. Por otro lado, la demora de 38 minutos en el despegue de Cebú significó que el avión no se encontrara tan lejos de la costa, lo que contribuyó al aterrizaje de emergencia. El equipo de pilotos tomó el control del avión y pudo realizar un aterrizaje de emergencia en el Aeropuerto de Naha donde el resto de pasajeros y la tripulación fueron evacuados. Tras observar el funcionamiento de su bomba, Yousef determinó iniciar con la segunda etapa.

La primera fase del plan terrorista consistía en asesinar al papa Juan Pablo II durante su visita a Filipinas en el marco de la Jornada Mundial de la Juventud 1995. El 15 de enero un terrorista suicida se disfrazaría como sacerdote católico y se haría explotar al paso de la caravana del Sumo Pontífice que se dirigiría al Seminario de San Carlos localizado en la ciudad de Macati. El atentado serviría como un distractor para planificar adecuadamente la segunda fase de la operación. Se dice que Yousef había entrenado a unos 20 hombres para lograr su objetivo.

Los detalles de la segunda fase se conocieron durante las investigaciones en el Apartamento 603 del edificio Doña Josefa.

El segundo plan contaba con la participación de por lo menos cinco terroristas: Yousef, Amin Shah, Murad y otros dos atacantes desconocidos. Los atentados se desarrollarían entre los días 21 y 22 de enero de 1995, los atacantes colocarían bombas en once aviones de pasajeros de aerolíneas estadounidenses con destino a ese país de América del Norte, los objetivos harían escala en distintos puntos del Sudeste Asiático y Asia Oriental. Todos los vuelos elegidos tenían por lo menos dos fases de vuelo. Los artefactos explosivos iban a ser colocados debajo de los asientos escondidos en chalecos salvavidas, replicando el modo de ataque del vuelo 434 de Philippine Airlines, todos los atacantes bajarían del avión en la primera escala para posteriormente tomar vuelos rumbo a Lahore (Pakistán). El proceso implicaba que los hombres no necesitarían de un visado estadounidense debido a que el proceso se realizaría exclusivamente en suelo asiático.

Los terroristas eligieron únicamente aerolíneas estadounidenses en lugar de asiáticas con el objetivo de aumentar el efecto de shock por parte de la población norteamericana. Los vuelos elegidos fueron renombrados con nombres en clave: "Zyed", "Majbos", "Markoa", "Mirqas" y "Obaid". Este último se refería a Abdul Hakim Murad quien después de colocar el artefacto en un primer vuelo volaría a Singapur para atentar contra otro perteneciente a United Airlines.

Los reportes informan que "Zyed", era un nombre probablemente referido a Ramzi Yousef, quien atacaría tres aviones: el Vuelo 30 de Northwest, un vuelo de United entre Taipéi y Honolulu además de otro aparato de la misma línea aérea que cubría la ruta Bangkok - Taipéi - San Francisco.

Las explosiones debían ser programadas por los atacantes antes de descender al avión. Los aparatos debieron de haber estallado cuando las aeronaves se encontraran sobrevolando el Océano Pacífico y el Mar de la China Meridional. Si el plan hubiera tenido éxito probablemente varios millares de personas habrían muerto y el tráfico aéreo de todo el mundo podría haber sido cerrado en su totalidad. El FBI estima que podría haber causado alrededor de 4 000 víctimas, lo que hubiera convertido en el atentado terrorista más mortífero en la historia reciente, superando incluso en número de afectados al 11-S.

Los artefactos explosivos eran microbombas denominadas "Mark II" que tendrían relojes digitales Casio a modo de temporizador, estabilizadores parecidos a bolas de algodón y una cantidad indeterminada de nitroglicerina funcionando como explosivo. También incluirían otros ingredientes como glicerina, nitrato, ácido sulfúrico y pequeñas concentraciones de nitrobenceno, azida de plata y acetona líquida. En cada bomba se usarían dos baterías de 9 voltios como fuente de energía. Las pilas estarían conectadas a filamentos de bombillas que servirían para detonar la carga explosiva. Además habría un enchufe externo que sería ocultado cuando el terrorista empujara los alambres bajo la base del reloj. La modificación del reloj era mínima, incluso podía seguir funcionando de manera normal.

En el atentado del Vuelo 434, Yousef utilizó un artefacto explosivo similar, las baterías las consiguió tras pasar los controles de seguridad del aeropuerto y las ocultó en el hueco de los talones de sus zapatos, mientras que la nitroglicerina fue llevada a bordo en forma de contrabando tras ocultarla en un contenedor que contenía solución para limpieza de lentes de contacto.




La fase III de la operación fue detallada por Abdul Hakim Murad en una confesión hecha a la Policía de Manila, la cual fue dada a conocer el 3 de junio por el diario australiano "The Advertiser".

Murad estaría implicado en la realización del atentado cuyo primer paso consistía en rentar, comprar o secuestrar una aeronave pequeña, preferiblemente un Cessna. El aeroplano sería llenado con explosivos para posteriormente ser estrellado en contra del cuartel general de la Agencia Central de Inteligencia en Langley (Virginia). Murad había recibido instrucción como piloto aéreo en Carolina del Norte y probablemente se hubiera desempeñado como piloto suicida.

Había un plan alterno, que implicaría el ataque a un décimo segundo avión comercial que sería secuestrado para dirigirlo a su objetivo, esta idea surgió como consecuencia de los problemas que habían dado las pruebas de explosivos en Manila. Jálid Sheij Mohámed sería el encargado de realizar esta opción alternativa.

El gobierno de Filipinas envió un primer reporte a los Estados Unidos el 20 de enero de 1995, el memorándum decía: "Lo que el sujeto tiene en su mente es que se embarcará en cualquier avión comercial estadounidense pretendiendo ser un pasajero ordinario. Entonces se secuestrará dicho avión, tomará el control de su cabina de mando y se estrellará en la sede de la CIA".

Otro complot implicaría el secuestro de diez aviones comerciales en Estados Unidos que podrían dirigirse hacia objetivos como el World Trade Center (Ciudad de Nueva York), El Pentágono (Arlington, Virginia), el Capitolio de los Estados Unidos, la Casa Blanca (ambos en Washington D. C.), los cuarteles generales de la CIA y el FBI, la Torre Sears (Chicago, Illinois), la U.S. Bank Tower (Los Ángeles, California), el Columbia Center (en Seattle, Washington) y algunas plantas nucleares en suelo estadounidense. En su declaración Murad aseguró que se había abandonado el plan por no poder conseguir suficientes reclutas dispuestos a cometer tal misión. Sin embargo, esta fase del complot se convirtió en la base para la realización de los Atentados del 11 de septiembre de 2001 que implicaron el secuestro de vuelos comerciales (en lugar de pequeñas aeronaves cargadas con explosivos) los cuales fueron dirigidos contra el World Trade Center (que fue destruido totalmente) y El Pentágono (que sufrió daños parciales).

La tarde del 6 de enero de 1995, se desató un incendio en el complejo de Apartamentos Doña Josefa, justo 6 días antes del inicio de la visita del papa Juan Pablo II a Manila. Este hecho provocó que los terroristas abortaran el plan de los ataques.

Según reportes de la policía de Manila, el fuego inició alrededor de las 6 de la tarde, cuando Abdul Hakim Murad inició un incendio químico al verter agua sobre una sustancia que estaba en el fregadero de la cocina del Apartamento 603, ubicado en el sexto piso del bloque de viviendas. Alrededor de las 11:00 pm los vecinos se quejaron de un olor extraño, la administradora del edificio llamó al cuerpo de bomberos local, sin embargo el olor y el fuego llamaron la atención del cuerpo de policía, que contaba con una oficina a 500 metros del lugar que ocupaban los terroristas. El primer operativo de revisión fue cancelado debido a que un teléfono comenzó a sonar, lo que provocó la huida de los agentes quienes creyeron que se trataba de una trampa explosiva. En septiembre de 2002 un reportero de Los Angeles Times señaló que el fuego en el apartamento había sido provocado por agentes de policía, que se infiltraron en lugar con la intención de provocar la salida de los terroristas.

Como consecuencia del operativo policial fue arrestado un hombre que se hacía llamar "Ahmed Saeed", sobre quien más tarde se descubrió que se trataba de Abdul Hakim Murad, en su declaración inicial el terrorista explicó a la policía filipina que se trataba de un piloto aéreo que se encontraba de vacaciones, y se dirigía al apartamento para explicar que se había tratado de una explosión de petardos. Murad trató de escapar en un principio, pero fue arrestado después de tropezar con la raíz de un árbol. El pakistaní fue llevado a comisaría, en el transcurso del viaje ofreció a los policías una cantidad de 110 740 pesos filipinos (unos 2 000 dólares americanos) a cambio de su libertad. En sede policial, Murad firmó una declaración donde aseguraba su inocencia, alegando que se trataba de un turista que visitaba a un amigo dedicado al negocio de la importación y exportación de químicos. Fuentes policiales aseguran que tras firmar el documento murmuró la frase "dos satanes deben ser destruidos: el Papa y América".

A las 2:30 de la madrugada del día 7 de enero, las fuerzas de policía de Manila encabezadas por el comandante Francisco F. Bautista y la comandante de vigilancia Aida D. Fariscal volvieron al apartamento y comenzaron a revisar el lugar en busca de pruebas, encontraron toda una serie de objetos incriminatorios: compuestos químicos; aparatos de medición como termómetros, temporizadores y embudos; fotografías del papa Juan Pablo II; crucifijos y ropas de sacerdote. Estos objetos, junto con la grabación de un mensaje de voz dejado en el teléfono que hablaba sobre una sotana "lista para pruebas" y la inminente llegada del Pontífice al país, sirvieron para que Bautista estuviera seguro de haber evitado un plan para asesinar al líder de la Iglesia católica.

A las 4:00 de la mañana, las fuerzas de seguridad lograron obtener una orden de allanamiento y registro del apartamento, anteriormente se había tratado de obtener el permiso en unas 11 ocasiones previas puesto que Fariscal sospechaba de los habitantes del lugar y los relacionaba con la reciente ola de ataques que afectaban a la zona de Gran Manila y el atentado al Vuelo 434, algunos de ellos cometidos por Ramzi Yousef.

El registro de la vivienda continuó y las autoridades encontraron más productos químicos como ácidos sulfúrico, pícrico y nítrico, clorato de sodio, nitrobenzol, amoníaco, nitrato de plata, metanfetaminas y ANFO. Se encontraron también dos grandes latas de gasolina y botellas de jugo donde se guardaba nitroglicerina. Equipo como termómetros, probetas, grandes teteras para cocinar, embudos, fusibles, filtros, soldadores, vasos, morteros, pilas, diferentes sistemas de fusibles electrónicos, temporizadores, interruptores y disyuntores. También se descubrió en la búsqueda una bomba de tubo de latón a control remoto, así como otra bomba de tubos que estaba a punto de ser empaquetada. El apartamento también contenía un libro de texto de química y diccionario químico, una revista Time cuya portada trataba sobre terrorismo internacional, además se descubrió un recibo de farmacia y una botella de solución de lentes de contacto. En un armario debajo del lavaplatos se encontró una bomba de tiempo acabada y otros relojes Casio.

Sin embargo, la prueba más concluyente representó el hallazgo de un manual escrito en árabe donde se describía la manera de hacer una bomba líquida.

La policía también descubrió una pila con 12 pasaportes falsos de nacionalidades noruega, saudita y pakistaní. Los investigadores también encontraron una tarjeta de negocios perteneciente a Mohammed Jamal Khalifa; se dice que Saeed poseía una lista con por lo menos cinco números telefónicos pertenecientes a Khalifa, además se encontró un número perteneciente a Rose Masquera, novia de Mohammed.

El proyecto de Yousef fue descubierto en cuatro disquetes y en un portátil Toshiba que se encontraban en su apartamento, el hallazgo se realizó dos semanas antes de que se pusiera en marcha la fase II de la operación. Varios archivos cifrados en el disco duro del portátil contenían horarios de vuelo, cálculos de tiempos de detonación y otros elementos. La primera cadena de texto en uno de los archivos decía: "Todas las personas que apoyan al gobierno de Estados Unidos son nuestros objetivos en nuestros planes futuros y eso es porque todas esas personas son responsables de las acciones de su gobierno y apoyan la política exterior de EE.UU. Si el gobierno estadounidense sigue apoyando a Israel, entonces continuaremos llevando a cabo operaciones dentro y fuera de los Estados Unidos para incluir ... " el texto finalizó en esa frase.

Se encontró además un archivo llamado "Bojinka" en donde se listaban once vuelos entre Asia y los Estados Unidos, que fueron agrupados en cinco nombres clave, se encontraron cadenas de palabras como:
Los códigos posiblemente se referían al Vuelo 80 de United y al 30 de Northwest.

El portátil tenía nombres de docenas de asociados, incluyendo algunas fotografías de algunos de ellos e información de contacto de Mohammed Jamal Khalifa. Se encontraron además registros de información sobre hoteles de cinco estrellas, tratos con una corporación comercial de Londres, un dueño de mercado de carne en Malasia y un centro islámico en Tucson, Arizona. Se encontró información sobre cómo se movía el dinero a través de una firma bancaria de Abu Dabi.

Una comunicación firmada como "Khalid Shaikh + Bojinka" también fue encontrada en la computadora de Yousef que amenazó con atacar objetivos "en respuesta a la ayuda financiera, política y militar dada al Estado judío en la tierra ocupada de Palestina por el Gobierno de los Estados Unidos". La carta también decía que los terroristas afirmaban tener "capacidad para fabricar y usar productos químicos y gas venenoso... para su uso contra instituciones, poblaciones vitales y las fuentes de agua potable".

La carta también amenazó con asesinar a Fidel V. Ramos, el presidente de Filipinas en ese momento, así como atacar aviones si Estados Unidos no cumplía con las demandas del grupo. La carta decía que el grupo que reclamaba la responsabilidad era la "Quinta División del Ejército de Liberación"

La evidencias encontradas en el Edificio de Apartamentos Doña Josefa llenó tres camionetas policiales.

Wali Khan Amin Shah fue arrestado en un complejo de apartamentos el 11 de enero, después de que la policía vio que un buscapersonas que habïa sido llamado por Yousef estaba registrado en el nombre de la novia de Shah. El detenido escapó de su custodia unas 77 horas más tarde. Shah resultó ser un conspirador después de que las autoridades vieron fotos de él escaneadas en la computadora portátil que contenían información sobre la trama, así como números de teléfono celular que llevaban a los investigadores al apartamento. Yousef y Khalid Sheikh Mohammed pudieron escapar de Filipinas a Pakistán. El 31 de enero de 1995, Yousef voló de Pakistán a Tailandia en un intento de colocar maletas bomba en aviones de Delta y United Airlines. Tras fracasar, regresó a Pakistán.

Después de recibir la llamada telefónica de Murad, Yousef hizo planes para irse y voló a Singapur unas cinco horas después del arresto de Murad. Un día después de que la operación Bojinka fuera descubierta, Yousef se dirigió a Pakistán. Mohammed escapó a Pakistán, sin saber exactamente el número de días o semanas después.

Filipinas envió detalles sobre la operación Bojinka a los Estados Unidos en abril de 1995. La cúpula directiva de Konsojaya fue escuchada a través de espionaje telefónico, por sospechas al estar frecuentemente en contacto con la organización benéfica de Mohammed Jamal Khalifa, la intervención telefónica duró hasta que la trama fue descubierta.

Yousef fue arrestado en la casa de huéspedes Su-Casa en Islamabad, Pakistán, el 7 de febrero de 1995, por agentes del Servicio de Seguridad Diplomática de los Estados Unidos, después de una cacería de 23 días. Wali Khan Amin Shah, el financiero, fue detenido en Malasia en diciembre de 1995. Su identidad fue revelada después de que se le tomaron las huellas dactilares. Shah también fue extraditado a los Estados Unidos.

Los tres conspiradores recibieron penas de cadena perpetua por participar en la conspiración. Yousef además fue condenado a 240 años de prisión en conjunto a su sentencia de cadena perpetua por haber cometido el atentado del World Trade Center de 1993. Yousef fue sentenciado el 8 de enero de 1998 y Murad fue sentenciado el 16 de mayo del mismo año. Shah comenzó a cooperar con el gobierno desde agosto de 1998.

Mohammed Jamal Khalifa, un empresario saudita de Yeda, que estaba casado con una de las hermanas de Osama bin Laden, estuvo en Filipinas a principios de 1994. Fue detenido el mismo año en Mountain View, California, por conspirar en el atentado del World Trade Center de 1993. Estaba financiando la operación Bojinka, según el contenido que los investigadores filipinos enviaron a los Estados Unidos. El Servicio de Inmigración y Naturalización de los Estados Unidos deportó a Khalifa a Jordania en mayo de 1995. Fue absuelto por el tribunal jordano y se trasladó a Arabia Saudita. Fue asesinado en su habitación de hotel en Madagascar el día 31 de enero de 2007.

Jálid Sheij Mohámed fue capturado en Rawalpindi, Pakistán el 1 de marzo de 2003 en una acción conjunta entre la Agencia Central de Inteligencia y los Inter-Services Intelligence pakistaníes. En 2006 fue trasladado desde una prisión secreta de la CIA al Centro de detención de Guantánamo. En marzo de 2007 confesó haber sido el cerebro de la organización de los atentados del 11 de septiembre de 2001, los Atentados de Bali de 2002, el Atentado del World Trade Center de 1993, el intento de hacer explotar un avión entre el Aeropuerto de París-Charles de Gaulle y Aeropuerto Internacional de Miami el 22 de diciembre de 2001 y otros atentados fallidos.

Los investigadores de los Estados Unidos tardaron años en encontrar la conexión entre Jálid Sheij Mohámed y la red terrorista Al Qaeda. Los atentados del 11 de septiembre fueron una evolución de lo aprendido en la Operación Bojinka, puesto que Sheij determinó que utilizar aviones cargados con explosivos era una maniobra riesgosa para el éxito de la trama prefirió utilizar la alternativa planteada de secuestrar aviones comerciales.

La Operación Bojinka fue incluida en diversos documentales y series sobre los atentados del 11-S, al ser considerada como un precursor de la tragedia sucedida en 2001.



</doc>
<doc id="21741" url="https://es.wikipedia.org/wiki?curid=21741" title="Osama bin Laden">
Osama bin Laden

Usāma bin Muhammad bin `Awad bin Lādin (, "Usāmah bin Muḥammad bin ""Awaḍ bin Lādin", Riad, Arabia Saudita, 10 de marzo de 1957-Abbottabad, Pakistán, 2 de mayo de 2011), conocido como Osama bin Laden o Usama bin Ladin (أسامة بن لادن), fue un terrorista yihadista de origen saudí, miembro de la familia bin Laden y conocido por ser el fundador de la red terrorista Al Qaeda.

Aunque en un principio fue entrenado y financiado por la CIA estadounidense en la guerra de Afganistán contra la URSS y los comunistas afganos, según confesión y reivindicación del mismo Bin Laden, fue el responsable de numerosos ataques terroristas contra los Estados Unidos y otras potencias occidentales, incluyendo los ataques a las embajadas de Estados Unidos en Kenia y Tanzania el 7 de agosto de 1998, los ataques del 11 de septiembre de 2001 al World Trade Center y al Pentágono en el condado de Arlington en Virginia. Hasta el momento de su muerte, el FBI tenía a Bin Laden encausado por los atentados a las embajadas estadounidenses de Kenia y Tanzania, y por su conexión «con otros ataques terroristas en todo el mundo».

Durante mucho tiempo parte de la opinión pública internacional afirmó la posibilidad de que Osama bin Laden pudiese llevar varios años fallecido, algo que fue claramente desmentido por el grupo terrorista Al-Qaeda a través de Aymán al-Zawahirí, 2º jefe al mando de la organización, en una entrevista emitida por la cadena árabe de televisión Al Jazeera. También fue desmentida su muerte por parte de la CIA (Agencia Central de Inteligencia), más específicamente por su director Michael Vincent Hayden, quien dijo que Bin Laden seguía vivo pero aislado. También se ha señalado que su figura se ha mitificado en Europa y Estados Unidos como cabeza absoluta de Al Qaeda, simplificando la estructura descentralizada de la organización.

Había una recompensa por Osama bin Laden de 50 000 000 de dólares. Adicionalmente se entregarían otros 2 000 000 de dólares a través de un programa establecido por la Asociación de Pilotos de Aerolíneas y la Asociación del Transporte Aéreo.

Sobre las 23:30 horas del domingo 1 de mayo de 2011 (hora de Washington D. C.; en Pakistán y otras partes del mundo era ya el día 2 de mayo), el presidente de los Estados Unidos Barack Obama anunció de manera oficial la muerte de Bin Laden, tras un operativo militar realizado por comandos estadounidenses en una residencia en las afueras de Abbottabad, Pakistán.

Nacido en Riad (Arabia Saudita), fue el decimoséptimo hijo (entre más de cincuenta) de Mohammad bin Awad bin Laden, uno de los empresarios de la construcción más ricos de ese país, y su décima mujer, Hamida al-Attas. Bin Laden fue criado como musulmán wahhabi. De 1968 a 1976 asistió a una escuela secular de élite llamada Al-Thager. Estudió en la Universidad Rey Abdul Aziz aunque no se conoce con certeza si se graduó con una licenciatura en Administración de Empresas o Ingeniería. Cuando su padre murió en un accidente de avioneta en 1967, su enorme imperio industrial, el Grupo Saudi Binladin, pasó a manos de sus hijos.

Bin Laden creía que la restauración de la ley Sharia haría del mundo islámico un lugar mejor y se oponía al resto de las ideologías —panarabismo, socialismo, comunismo, democracia—. Llegó a afirmar que Afganistán, bajo el gobierno del líder talibán Mullah Omar, era el único 'país islámico' en el mundo musulmán. Siempre apoyó el uso de la violencia en forma de yihad para así combatir las injusticias perpetradas por Estados Unidos y en ocasiones por países occidentales contra el mundo árabe, acabar con el Estado de Israel y empujar a Estados Unidos a abandonar Oriente Medio. Además, descalificó al pueblo estadounidense en una carta escrita en 2002, condenándolo por «sus actos inmorales de fornicación, homosexualidad, drogadicción, ludopatía y usura».

Probablemente, la idea que hizo más impopular a Bin Laden fue aquella que justificaba la muerte de civiles (incluidos mujeres y niños) como daños inevitables de la santa yihad. Bin Laden era antijudío y antiisraelí, como demostraban sus advertencias en contra de supuestas conspiraciones judías: «Los judíos son grandes usureros, así como traidores natos. No dejarán nada para ti, ni en este mundo ni en el siguiente». Tachaba a los musulmanes chiitas, junto con los «herejes» –EE. UU. e Israel–, como las cuatro grandes amenazas para el mundo islámico en su ideología de clases de la organización terrorista Al-Qaeda.

De acuerdo con las creencias sunitas Wahhabis, Bin Laden se oponía a la existencia de la música en el ámbito religioso, y su aceptación de la tecnología no era plena. Estaba interesado en la mecánica del movimiento planetario terrestre, así como en la ingeniería genética de las plantas. Sus métodos lo habrían llevado a ser calificado de terrorista por académicos, periodistas del "New York Times", la British Broadcasting Corporation, la cadena informativa Al Jazeera e incluso por varios analistas, como por ejemplo Peter Bergen, Marc Sageman o Bruce Hoffman.

Poco después de que la Unión Soviética interviniera en Afganistán, Bin Laden, así como miles de otros islamistas alrededor del mundo, se unió a la «guerra santa». En 1980 comenzó a reclutar guerrilleros y estableció sus primeros campamentos. Entrenado por la CIA, aprendió cómo mover dinero a través de sociedades fantasmas y paraísos fiscales; a preparar explosivos; a utilizar códigos cifrados para comunicarse; y a ocultarse. Por esa época, los Estados Unidos colaboraban incondicionalmente con los grupos afganos, debido a su participación en la guerra contra la URSS (entre 1979 y 1989 los estadounidenses entregaron cerca de tres mil millones de dólares a la resistencia afgana, que favoreció a Bin Laden). Después de la retirada soviética en 1989, Bin Laden regresó a su país como un héroe, pero su objeción a la presencia de tropas estadounidenses en Arabia Saudí durante la guerra del Golfo lo llevó a una creciente desavenencia con los líderes de su país. A pesar de este progresivo alejamiento en la década de 1990 de las posturas del gobierno saudí y sus aliados occidentales, aún en 1993 la prensa británica describía a Bin Laden como «un guerrero antisoviético que pone a su ejército en el camino hacia la paz».

Entre agosto de 1988 y finales de 1989 creó una red terrorista conocida como al Qaeda (en árabe: القاعدة "al-qā`ida", ‘la Base’), la cual consistía, en gran medida, en militantes musulmanes que Bin Laden había conocido en Afganistán, tales como su lugarteniente Aymán al-Zawahirí, junto con el propio Bin Laden. El grupo presuntamente financió y organizó varios ataques por todo el mundo, incluidos la detonación de coches bomba contra blancos estadounidenses en Arabia Saudí en 1996, el asesinato de turistas en Egipto en 1997 y los ataques con bomba simultáneos a las embajadas estadounidenses en Nairobi (Kenia) y en Dar es Salaam (Tanzania) en 1998, los cuales terminaron con la vida de 224 personas y miles de heridos.

En 1994, después de que el Gobierno saudí confiscó su pasaporte tras acusarlo de subversión, Bin Laden huyó a Sudán, donde se lo acusa de haber organizado campos de entrenamiento terroristas y de donde fue expulsado finalmente en 1996. Luego regresó a Afganistán, donde recibió protección de los talibán, la milicia gobernante.

Entre 1996 y 1998, Bin Laden emitió una serie de "fatwas" (en árabe: ‘decretos religiosos’) declarando una guerra santa contra los Estados Unidos, al cual acusó, entre otras cosas, de saquear los recursos naturales del mundo musulmán y de ayudar e incitar a los enemigos del Islam. Al parecer la meta de Bin Laden era involucrar a los Estados Unidos en una guerra a gran escala en el mundo musulmán, que terminaría con los Gobiernos musulmanes moderados y restablecería el califato (es decir, un único Estado musulmán). Con este fin, al Qaeda entrenó y equipó a terroristas con la ayuda de la considerable riqueza de Bin Laden. Tuvo miles de seguidores por todo el mundo, en lugares tan diversos como Arabia Saudí, Yemen, Libia, Bosnia, Chechenia y las Filipinas.

El 11 de septiembre de 2001 se secuestraron cuatro aviones comerciales de los cuales dos se estrellaron en el World Trade Center, uno en El Pentágono y uno en Pensilvania. Las autoridades estadounidenses lo culparon de la preparación y financiación del atentado tras la reivindicación hecha por el propio Bin Laden. Ante la negativa del régimen talibán de entregarlo, el ejército estadounidense invadió Afganistán para encontrarlo.

La búsqueda fue infructuosa: se dio con el paradero de los principales líderes del régimen talibán, pero a pesar de haber acorralado a Bin Laden en la región de Tora Bora, éste consiguió escapar a Pakistán. Llegó a afirmarse que ya había muerto en alguno de los bombardeos que tuvieron lugar durante la invasión. Sin embargo, en la ciudad de Jalalabad localizaron un vídeo donde aparecía bin Laden reivindicando los atentados, con lo cual el Gobierno estadounidense pudo justificar la invasión a Afganistán, ya que ello constituía una prueba de su culpabilidad.

Algunos dudan que la persona que aparece en dicho vídeo sea realmente Osama bin Laden argumentando:

Hay quien opina que el vídeo no es más que una falsificación para culpar a Bin Laden y tener una justificación de la invasión de Afganistán y la culpabilidad de Al Qaeda. A pesar de todo esto, las autoridades estadounidenses afirman que el vídeo es auténtico, que el que aparece en él es Osama bin Laden y que por tanto el vídeo es una prueba de que fue el autor intelectual de los atentados del 11 de septiembre.

Bin Laden reivindicó los atentados en octubre de 2004, es decir, tres años después de cometidos, justo antes de las elecciones presidenciales en Estados Unidos, enviando un vídeo a la cadena de televisión Al Jazeera, en el que se lo ve con aparente buena salud, leyendo un papel, y haciendo gestos a cámara para enfatizar parte del discurso (Hay que recordar que en julio de 2001 estaba gravemente enfermo).

El papel de Bin Laden en el 11-S sigue sin estar claro. En la página de los 10 fugitivos más buscados del FBI, se le atribuían varios atentados terroristas pero no se mencionó específicamente los del 11-S, limitándose a constatar que se le buscaba por su conexión con "atentados en todo el mundo", siguiendo la práctica habitual de encausar a los fugitivos sólo por uno o dos delitos, con independencia del número real de delitos que se le atribuyen. El periodista Ed Haas (editor y redactor del "Muckraker Report") se comunicó el 5 de junio de 2006 con el cuartel general del FBI sobre este asunto. Rex Tomb, jefe retirado de Publicidad Investigativa del FBI, le dijo: «La razón de por qué el 11/9 no es mencionado en la página de Osama bin Laden como más buscado es porque el FBI no tiene evidencia convincente de su conexión con el 11 de septiembre» Todo esto sido mencionado por el Movimiento por la verdad del 11-S. El FBI desautorizó las declaraciones de Tomb, argumentando que la información que poseía éste no era precisa y que Tomb no es especialista en terrorismo. La posición oficial del FBI es que Bin Laden es responsable de los atentados del USS Cole, las embajadas de Kenia y Tanzania y que su implicación en los atentados del 11-S es irrefutable.

El 2 de noviembre de 2007, Benazir Bhutto reveló que Osama bin Laden fue asesinado por Ahmed Omar Saeed Sheikh. Esta revelación fue suprimida por la BBC de la entrevista original.

Bin Laden aparece en 2007 en un nuevo vídeo y según miembros del servicio de inteligencia de Estados Unidos aseguran que la cinta es «genuina y que la voz emanada del vídeo pertenece al líder de al-Qaeda».

El 31 de enero de 2010, el diario español "El País" y el periódico colombiano "El Tiempo", presentaron una entrevista a Sultan Tarar, «mano derecha» del fugitivo talibán Mullah Omar, en la cual afirma que Bin Laden murió de un cáncer de riñón entre mayo y junio de 2002.

Sin embargo, el 25 de marzo de 2010 Osama bin Laden aparece y envía una advertencia al Gobierno de los Estados Unidos a través de un audio emitido por la cadena de televisión qatarí Al Jazeera, Bin Laden dijo que el día que EE. UU. tome la decisión de ejecutar a Jálid Sheij Mohámed, supuesto cerebro de estos atentados, Al Qaeda ejecutará a todos los estadounidenses en su poder.

Osama Bin Laden tuvo más de 20 hijos con cinco esposas. Algunas esposas y amantes han declarado sobre su personalidad. Su primera esposa fue su prima Najwa Ghanem, con quien tuvo 11 hijos pero luego lo dejó y se marchó de Afganistán unos meses antes del 11 de septiembre. Su segunda esposa Khadija Sharif, tres hijos, no soportó la vida austera en Sudán, divorciándose en la década de 1990. Su tercera esposa Khairiah Sabar, con un hijo, no sobreviviría a los bombardeos de Afganistán del 2001.

Su amante africana Kola Boof, entre 1996 y 1998, confesó que la violó en algunas ocasiones y hasta llegó a secuestrarla durante 10 meses en un hotel marroquí. Comentó que tenía una actitud violenta en el sexo, le pegaba para que consintiera sus caprichos sexuales, mordía muy fuerte hasta hacerle gritar de dolor, además de emitir unos sonidos animales espantosos y de tener un olor corporal horrible, tal como revela en su "Diario de una chica perdida". También lo calificó de genio, poeta, racista, muy apasionado, muy delicado y confundido, además con amor por la cultura occidental, obsesión por la cantante Whitney Houston, así como por la marihuana.

Su cuarta esposa Siham Sabar, le dio cuatro hijos y lo abandonó cuando llegó la última esposa de 17 años, declarando a ABC que "trataba a su familia como perros" y lo describió como un monstruo que vivía en constante alerta, solo dormía dos o tres horas y comía muy poco. El quinto matrimonio sólo duró 48 horas. Su última esposa fue Amal Ahmed Abdul Fatah, por quien pagó cinco mil dólares, 26 años menor que él, muy religiosa, con quien probablemente tuvo seis hijos y que fue herida durante el asesinato de Bin Laden por defenderlo, pues le tenía mucha admiración. Las fuerzas especiales estadounidenses encontraron en su casa de Abbottabad, abundante material pornográfico, tanto en videos como en sus computadoras.

Por otro lado, es probable que las relaciones maritales de bin Laden fueran su perdición. De acuerdo con Shaukat Qadir, un general de brigada pakistaní retirado, una de sus esposas lo habría delatado con las fuerzas estadounidenses. Al parecer, su tercera esposa Khairiah no habría muerto en 2001, sino que huyó a Irán, donde quedó bajo arresto domiciliario y luego se reencontró con bin Laden en Pakistán en 2011. Luego de la muerte de bin Laden, sus viudas se reencontraron en Islamabad bajo la custodia de las fuerzas de seguridad; allí Khairiah (61), que habría vivido apartada en el piso inferior en Abbottabad, acusaba a Amal (29), su última esposa, de ser una prostituta que acaparaba las 24 horas a Osama. A su vez Amal acusaba a Khairiah de traición y de ser la real asesina de Osama. Otros familiares apoyaron a Amal; uno de los hijos llamado Khalid habría advertido a bin Laden de una probable traición por parte de Khairiah. Sin embargo ni el gobierno estadounidense ni el pakistaní han confirmado estos hechos.

Ha existido un gran número de reclamaciones no verificadas acerca de su estado y ubicación, incluidos los rumores de su muerte en varios años, y las reivindicaciones de sus visitas a diversos países. Sin embargo, aunque hay grabaciones de vídeo donde aparece Bin Laden no se pudo saber con exactitud su localización en esa época.

Después de los atentados del 11 de septiembre de 2001, los Estados Unidos pidieron a las autoridades talibanes entregar a Bin Laden para que enfrentara cargos por terrorismo. Los talibanes se negaron a entregar a Bin Laden sin pruebas o indicios de su implicación en los atentados del 11 de septiembre e hizo una contraoferta para que Bin Laden fuese a un tribunal islámico o lo extraditaran a otro país. Ambas ofertas fueron rechazadas por el gobierno de los Estados Unidos.

Los rumores de su muerte siguieron, se decía que estaba muerto o fatalmente herido durante los bombardeos de Estados Unidos después de los atentados del 11 de septiembre, o que había muerto por causas naturales. De acuerdo con Gary Berntsen, en su libro de 2005, "Jawbreaker", un número de al-Qaeda detenidos más tarde confirmó que Bin Laden había escapado de Pakistán, a través de una ruta oriental a través de montañas cubiertas de nieve en el área de Parachinar, Pakistán. Los medios de comunicación informaron de que Bin Laden sufría de una enfermedad renal que lo obligaba a tener acceso a servicios médicos avanzados, posiblemente diálisis renal. Ayman al-Zawahiri que es el segundo Jefe al mando de Al Qaeda es quien ha brindado atención médica a Bin Laden.

La CIA afirmaba por aquel entonces que Osama bin Laden estaba vivo y escondido en el noroeste de Pakistán, en gran parte aislado de las operaciones diarias de Al Qaeda.

Por otra parte, en el mes de enero de 2010 el FBI divulgó unas imágenes virtuales de Osama bin Laden, en las que proyectaba el aspecto que tendría en ese momento el líder de Al Qaeda. Los expertos forenses del FBI aseguraron que Bin Laden seguiría teniendo barba, además, se especulaba que el líder de Al Qaeda caminaría con un bastón.

Declaraciones sobre la ubicación de Osama bin Laden fueron realizadas desde diciembre de 2001, aunque ninguna fue probada definitivamente y algunas han puesto Osama en lugares diferentes durante períodos de tiempo superpuestos. Dado que una gran ofensiva militar en Afganistán a raíz de los ataques de Al Qaeda en los Estados Unidos no lograron descubrir su paradero, Pakistán había sido identificado regularmente como sospecha de su escondite.

El 1 de mayo de 2011, se informó de que Osama bin Laden murió durante una acción militar de EE. UU.Se confirmó la identidad de Bin Laden comparando muestras conservadas de ADN de su hermana muerta con ADN del cuerpo sin vida. El cadáver fue tomado por elementos de fuerzas armadas de EE. UU. tras el ataque, y quedó en su posesión.

Ese día, a las 22:40 (GMT -05:00), el presidente Obama se dirigió a la nación afirmando, previa confirmación por parte de funcionarios estadounidenses, que Osama bin Laden había muerto en una operación secreta en Abbottabad, Pakistán, ciudad 50 kilómetros al noreste de Islamabad y 150 kilómetros al este de Peshawar. Obama indicó que la operación fue obra de un pequeño grupo que actuó bajo sus órdenes y contó con ayuda del gobierno pakistaní.

La localización y muerte de bin Laden fue facilitada al seguir los pasos de uno de los miembros y mensajeros de su grupo íntimo. Dos años antes, los servicios de inteligencia estadounidenses localizaron la región en donde operaba su mensajero. A partir de esos datos en agosto de 2010 fue localizada la zona en que podía vivir, a unos 55 kilómetros al norte de la capital de Pakistán, Islamabad, en una mansión fortificada. En febrero de 2011, los servicios de inteligencia ya estaban seguros de que en la residencia objeto de investigación se encontraba la familia Bin Laden. En marzo, el presidente de los Estados Unidos, Barack Obama, tuvo conocimiento de los datos de inteligencia y el 29 de abril aprobó la operación. Ésta no fue comunicada a ningún país, ni siquiera a Pakistán, y se desarrolló en 40 minutos por un grupo de élite reducido del ejército estadounidense. Falleció en la operación el propio Bin Laden —de dos tiros, uno en el pecho y otro en la cabeza—, un hijo de éste, una mujer no identificada, el mensajero que había servido para localizarlo y un hermano del mismo. Según informaciones posteriores facilitadas por la administración estadounidense, Bin Laden no estaba armado al ser abatido, pero sí lo estaba la mujer que intentó protegerlo; la cual disparó a los comandos estadounidenses y por eso fue herida en una pierna (pero no resultó muerta como se informó al principio).

Su cuerpo, fue trasladado al portaaviones USS "Carl Vinson", donde tras celebrarse un funeral según los ritos islámicos, fue sepultado en el mar.

No obstante, algunos analistas conocidos por haber planteado con anterioridad explicaciones alternativas a los atentados del 11-S, han señalado que el anuncio de la muerte de Bin Laden es incongruente y las circunstancias que la rodearon, extrañas. En relación con lo anterior han sugerido que su asesinato pudo ser un montaje del gobierno estadounidense, ya que, según los datos que manejan podría haber fallecido mucho tiempo antes, incluso en diciembre de 2001. Entre las varias versiones conspirativas se encuentra la del periodista estadounidense Seymour Hersh, quien piensa que el ISI paquistaní retenía a bin Laden desde 2006 y que tras la muerte de este, provocada por soldados estadounidenses guiados por espías paquistaníes, su cuerpo no fue lanzado al océano.





</doc>
<doc id="21757" url="https://es.wikipedia.org/wiki?curid=21757" title="Determinante">
Determinante

Determinante puede ser en referencia a:



</doc>
<doc id="21758" url="https://es.wikipedia.org/wiki?curid=21758" title="Arenaria hispanica">
Arenaria hispanica

Arenaria hispanica es una especie de planta fanerógama perteneciente a la familia Cariofilácea, nativa de España. Es una especie muy próxima a "Arenaria leptoclados", lo que las hace difícil de separar.

Es una hierba anual, ramosa desde la base, que alcanza un tamaño de hasta 25(30) cm de altura. Tallos robustos, con indumento de pelos glandulosos articulados, patentes, entremezclados con pelos glandulosos muy cortos. Hojas 4 x 1-6(11) mm; las inferiores, espatuladas, atenuadas en pecíolo ancho, el resto, de oblanceoladas a ovadolanceoladas o lanceoladas, sésiles, planas, uninervias, ciliadas en la base. Inflorescencia cimosa; pedicelos fructíferos de hasta 20(25) mm. Cáliz 3,5-5(6) mm, con pelos glandulares; sépalos de ovado-elípticos a lanceolados, obtusos, con (5)7-9 nervios manifiestos, a menudo de color púrpura en el ápice. Pétalos 5-9(10) mm, enteros o emarginados, blancos, mayores que los sépalos. Antenas 0,7-1,2 mm. Cápsula 5-6,5 mm, ovoideo-elipsoidal, submembranácea. Semillas (0,6)0,7-0,9 mm, globosas, negras, con testa lisa y brillante o muy finamente papilosa. 

Típica en prados terofíticos. De distribución extendida. Se encuentra en campos de cultivo, cunetas, olivares, playas y medios alterados en general, preferentemente sobre suelos arcilloso-calizos; a una altitud de 0-800 metros en la Península Ibérica, (Andalucía) y Norte de África. 

"Arenaria aggregata" fue descrita por Kurt Sprengel y publicado en "Syst. Veg." 2: 396 1825. 

Número de cromosomas de "Arenaria hispanica" (Fam. Caryophyllaceae) y táxones infraespecíficos: n=9

Arenaria: nombre genérico que deriva del término latino "arenarius" = "de arena, arenoso". Adjetivo sustantivado: la planta a la que J.Bauhin dio este nombre en 1631 vive en terreno arenoso.

hispanica: epíteto geográfico que alude a su localización en Hispania.





</doc>
<doc id="21771" url="https://es.wikipedia.org/wiki?curid=21771" title="BBEdit">
BBEdit

BBEdit es un editor de texto para Mac OS y, desde su aparición, también para Mac OS X. Fue diseñado originalmente para editar HTML y está especialmente diseñado para programadores y diseñadores web. Este editor está creado por la empresa Bare Bones Software.

La primera versión de BBEdit era una versión de prueba, para sustituir al editor por defecto en el sistema, esta versión no podía leer archivos de más de 32K. Debido a su gran soporte para plugins y al éxito del plugin para HTML, los desarrolladores decidieron comprar los derechos a su autor e incluirlos en el editor Las herramientas se incluyeron de forma opcional en la versión 4, y en la versión 5.0 se añadió un menú.

BBEdit estaba disponible de forma gratuita en su lanzamiento inicial en 1991, pero fue comercializado en mayo de 1993 con el lanzamiento de la versión 2.5 

Al mismo tiempo, Bare Bones Software también hizo una versión menos equipada de BBEdit 2.5 llamada BBEdit Lite disponible de forma gratuita. Esta versión fue suspendida en la versión 6.1 y lo reemplazó con TextWrangler, que estaba disponible a un menor coste. Varios años más tarde, también fue liberado de forma gratuita.

BBEdit está diseñado para su uso por desarrolladores de software y diseñadores web. Tiene soporte nativo para muchos lenguajes de programación y los módulos personalizados pueden ser creados por los usuarios para apoyar cualquier idioma. BBEdit no es un procesador de textos, no formatea el texto.

BBEdit soporta el subrayado en muchos lenguajes de programación. Algunos son: ANSI C, C++, Fortran , HTML, Java, JavaScript, JSP, Object Pascal, Perl, PHP, Python, Ruby, SQL, Tcl, TeX, scripts Unix y XML. 



</doc>
<doc id="21777" url="https://es.wikipedia.org/wiki?curid=21777" title="Lápiz">
Lápiz

Un lápiz o lapicero es un instrumento de escritura o de dibujo. Consiste en una mina o barrita de pigmento (generalmente de grafito y una grasa o arcilla especial. También puede ser pigmento coloreado de carbón de leña) y encapsulado generalmente en un cilindro de madera fina, aunque también en envolturas de papel y plásticas.

Un lápiz que tenga una mina hecha con más arcilla mezclada con el grafito es un lápiz más resistente. Se diferencian, por una parte, con las letras H (del inglés "hard" = duro) y B (del inglés "black" = negro), y, por otra parte, con un número de 1 a 4, siendo el número 4 el más duro. También puede haber combinaciones de las letras: HH, por ejemplo, se refiere a una mina muy dura.

Los lápices modernos se fabrican industrialmente mezclando el polvo de grafito y arcilla molidos finamente, agregando agua, formando minas largas que se cuecen en un horno (compartimientos térmicamente aislados). Las minas resultantes se sumergen en aceite o cera fundida, que se filtra en los agujeros minúsculos del material, dando por resultado una escritura más lisa. Un tablón de madera con varios surcos paralelos largos se corta para formar un listón, y las tiras de grafito y arcilla se insertan en los surcos. Otro tablón acanalado se pega encima, de manera que el ensamble final es cortar todo en lápices individuales, que luego se barnizan o se pintan.

En 1564, un depósito enorme de grafito fue descubierto en Seathwaite Fell, cerca de Borrowdale, Cumbria, en Inglaterra. Los lugareños descubrieron que era muy útil para marcar ovejas. Este depósito particular de grafito era extremadamente puro y sólido, y podría ser fácilmente aserrado en barritas. Este era y sigue siendo el único depósito a gran escala de grafito encontrado en esta forma sólida. La química estaba en su infancia y los químicos de la época consideraron, equivocadamente, que esa sustancia era probablemente una forma de plomo; por lo tanto, el grafito recibió el nombre de "plumbago" (relacionado con "plumbum", «plomo» en latín). Incluso en la actualidad la mina de un lápiz se denomina "lead" (plomo) en inglés, a pesar de que no contiene plomo. En realidad, el grafito de una mina de lápiz no es venenoso; el grafito es inofensivo si se llega a consumir.

El valor del grafito pronto pasó a ser enorme, principalmente porque podría ser utilizado para alinear los moldes para las bolas de cañón, y el control de las minas fue asumido y resguardado por la Corona británica.

El grafito, al ser blando, requiere un tipo de funda o cubierta. Las minas de grafito, al principio, se envolvían en cordeles o en cuero de oveja para darles estabilidad. La fama de la utilidad de estos primeros lápices se extendió, atrayendo la atención de artistas por todo el “mundo conocido”.

Aunque se encontraron depósitos de grafito en otras partes del mundo, no poseían la misma pureza y calidad que los de Borrowdale, y el grafito tuvo que ser reducido a polvo para eliminar impurezas. Inglaterra continuó disfrutando de un monopolio en la producción de lápices hasta que se encontró un método de reconstituir el polvo del grafito. Los característicos lápices cuadrados ingleses continúan haciéndose con barritas cortadas de grafito natural desde 1860. Hoy, la ciudad de Keswick, cercana a la zona del hallazgo original del bloque de grafito, tiene un museo del lápiz.

La primera tentativa de fabricar las minas con grafito pulverizado se llevó a cabo en Núremberg, Alemania, en el año de 1662. Se utilizó una mezcla de grafito, azufre y antimonio.

Fueron los italianos los primeros en idear una sujeción de madera. Alrededor de 1760, la pareja Simonio y Lyndiana Bernacotti fueron los primeros en crear lo que probablemente fue el diseño para el moderno lápiz de carpintero con cuerpo de madera; sin embargo, su versión era chata, ovalada, un tipo de lápiz muy compacto. Al principio perforaban un cilindro de madera de enebro para luego insertar la mina de grafito. Poco después crearon una técnica mejorada: preparaban dos medio cilindros de madera, colocaban entre ellos la mina de grafito y luego pegaban las dos mitades. Esencialmente, el mismo método sigue vigente hoy día.

Los lápices ingleses y alemanes no estaban al alcance de los franceses durante las guerras napoleónicas. El interés de un oficial del ejército de Napoleón cambió esta situación de dependencia. En 1795, Nicolas-Jacques Conté inventó un método para endurecer el grafito pulverizado mezclándolo con agua y arcilla y horneándolas convenientemente. Variando la proporción de grafito/arcilla se obtenían diferentes durezas de la mina. Este método de fabricación, que había sido descubierto anteriormente por el austriaco Josef Hardtmuth de Koh-I-Noor en 1790, se sigue empleando hoy.

Los colonos estadounidenses importaron los lápices de Europa hasta después de la Guerra de Independencia de los Estados Unidos. Benjamin Franklin hizo la publicidad de los lápices para la venta en su gaceta de Pensilvania en 1729 y George Washington utilizó un lápiz de tres pulgadas cuando exploró el territorio de Ohio en 1762. Se dice que William Munroe, ebanista en Concord, Massachusetts, hizo los primeros lápices de madera estadounidenses en 1812. Esta no era la única fábrica de lápices en Concord. Según Henry Petroski, el filósofo transcendentalista Henry David Thoreau descubrió cómo hacer un buen lápiz a raíz de grafito de baja calidad usando la arcilla como cubierta; esta invención fue incitada por la fábrica de lápices de su padre en Concord, que empleó el grafito encontrado en Nuevo Hampshire en 1821 por Charles Dunbar.

El método de fabricación de lápices de Munroe era cuidadosamente lento, y en la ciudad vecina de Acton, el dueño de un molino de lápices llamado Ebenezer Wood decidió automatizar este proceso en su propio molino de lápices situado en el arroyo de Nashoba, a lo largo del viejo camino de Davis. Para ello utilizó la primera sierra circular en la producción de lápices y construyó las primeras cubiertas de lápiz hexagonales y octogonales que tenemos hoy. Ebenezer no patentó su invención y compartía sus técnicas con quien le preguntara. Uno de esos fue Eberhard Faber, de Nueva York, que se convirtió en el líder de la producción de lápices.

Joseph Dixon, inventor y empresario implicado en la cantera de granito de Tantiusques en Sturbridge, Massachusetts, desarrolló un método para producir lápices masivamente. Antes de 1870, la Joseph Dixon Crucible Company ya era el distribuidor autorizado y consumidor de grafito más grande del mundo, que más adelante se convertiría en Dixon Ticonderoga, la compañía contemporánea proveedora de lápices y elementos artísticos.

El 30 de marzo de 1858, Hymen Lipman recibió la primera patente por pegar un borrador al extremo de un lápiz. En 1862, Lipman vendió su patente a Joseph Reckendorfer por 100 000 dólares, que fueron destinados a demandar al fabricante del lápiz Faber por infracción. En 1875 el Tribunal Supremo de los Estados Unidos dictaminó contra Reckendorfer declarando la patente como inválida.

Muchos lápices en el mundo, y casi todos en Europa, se clasifican con el sistema europeo que usa una graduación continua descrita por H (para la dureza; del inglés Hard" = ‘duro’) y B (para el grado de oscuridad; del inglés Black" = ‘negro’), así como F (para el grado de finura; del inglés "Fine" = ‘fino’). El lápiz estándar para escritura es el "HB". Según Petroski, este sistema se habría desarrollado a principios del siglo XX por Brookman, fabricante inglés de lápices. Utilizó la "B" para el negro y la "H" para la dureza; el grado de un lápiz se describió por una secuencia de H sucesivas y B sucesivas, tal como BB o BBB para minas cada vez más suaves, y HH o HHH para minas cada vez más duras.

Hoy en día, el sistema de clasificación de lápices se extiende desde muy duro con trazo fino y claro, hasta blando de trazo grueso y oscuro, abarcando desde el más duro al más blando, como se ve en la siguiente tabla:

Koh-I-noor ofrece veinte graduaciones de 10H a 8B para sus 1500 series; Derwent produce veinte graduaciones de 9H a 9B para sus lápices gráficos y Staedtler produce diecinueve de 9H a 8B para sus lápices de Mars Lumograph. El mercado principal para tan amplia gama de grados es el de los artistas, que están interesados en crear una gama completa de tonos de gris claro a negro. Los ingenieros prefieren lápices más duros que permitan un mayor control de la forma de la mina. Esto se refleja en la manera en que se empaquetan los lápices. Por ejemplo, para sus lápices gráficos, Derwent ofrece tres paquetes de 12 lápices cada uno: Técnico (graduación dura de 9H a B), para bosquejos (graduación suave de H a 9B), y de diseño (con graduación media de 4H a 6B).

Los lápices clasificados mediante este sistema se utilizan para medir la "dureza" y la "resistencia" de barnices y de pinturas. La resistencia de una capa de barniz o pintura (también conocida como la "dureza del lápiz") se determina como el grado del lápiz más duro que no marca la capa, cuando este es presionado firmemente contra la capa a un ángulo de 45º.

Otro método común utiliza una escala numérica para señalar la graduación de un lápiz. Fue creado por Conté y adoptado inicialmente en los Estados Unidos por Thoreau en el siglo XIX. La tabla siguiente muestra las equivalencias aproximadas entre los dos sistemas:

<nowiki>*</nowiki>También visto como 2-4/8, 2.5, 2-5/10. Aunque estén aceptados extensamente, no todos los fabricantes lo utilizan; por ejemplo, Faber-Castell utiliza una tabla diferente de equivalencias en sus lápices Grip 2001: 1=2B, 2=B, 2 1/2=HB, 3=H, 4=2H.
Para los lápices de grafito, los diversos grados de lápiz se obtienen alterando la proporción de grafito y arcilla: cuanta más arcilla se utilice, más duro es el lápiz. Dos lápices del mismo grado y de diferentes fabricantes no producirán el mismo tono ni tendrán necesariamente la misma dureza.

La mayoría de los lápices fabricados en los Estados Unidos están pintados exteriormente de amarillo. Según Henry Petroski, esta tradición comenzó en 1890 cuando la L&C Hardtmuth Company del Imperio austrohúngaro introdujo su marca de fábrica «Koh-I-Noor», tomando su nombre del famoso diamante. La intención era convertirse en el mejor y más costoso lápiz del mundo y, en un momento en que la mayoría de los lápices eran pintados en colores oscuros o ni siquiera se pintaban, los de Koh-I-Noor eran amarillos para distinguirse. El color se pudo haber inspirado por la bandera austrohúngara; era también sugestivo del Oriente, en un momento en que el grafito de la mejor calidad venía de Siberia. Otras compañías copiaron el color amarillo de modo que sus lápices fueran asociados a esta marca de alta calidad, y eligieron marcas de fábrica con referencias orientales explícitas, tales como Mikado (retitulado Mirado) y Mongol.

No todos los países utilizaron el amarillo en sus lápices; los lápices alemanes, por ejemplo, son a menudo verdes, basados en los colores de la marca registrada de Faber-Castell, una importante compañía alemana fabricante de artículos de escritorio.

Los lápices de color (es decir, aquellos con mina de color) generalmente están pintados exteriormente del mismo color que la mina.

Estos son los tipos más comunes de lápices. Se hacen de una mezcla de arcilla y grafito y su oscuridad varía de gris claro a negro. Su composición permite trazos más lisos.

Se hacen del carbón de leña y proporcionan negros más llenos que los lápices del grafito, pero tienden a manchar fácilmente y son más abrasivos que el grafito. Los lápices en tono sepia y blancos están también disponibles para la técnica duotone.

Conocidos comúnmente como lápices coloreados, estos tienen una mina de cera con el pigmento y otros aditivos. Múltiples colores se mezclan a menudo juntos. La variedad de un conjunto de lápices de color se puede determinar por el número de colores únicos que contiene.

También conocidos como marcadores de China. Escriben virtualmente en cualquier superficie (incluyendo vidrio, plástico, metal y fotografías). Los lápices de grasa más comúnmente encontrados están envueltos en papel (Berol y Sanford adhesivos), pero pueden también estar envueltos en madera (Staedtler Omnichrom).

Estos se diseñan para el uso con técnicas de acuarela. Los lápices se pueden utilizar solos para las líneas agudas y en negrilla. Los trazos hechos por el lápiz se pueden también saturar con agua y extender con pinceles.

Estos lápices tienen dos características principales: su forma ovalada les evita rodar y su mina es fuerte. El lápiz más viejo que subsiste es un lápiz de carpintería alemán que data a del siglo XVII y ahora está en la colección de Faber-Castell y Lyra Industrial.

Estos son lápices de grafito con un tinte agregado que crea una marca indeleble. Fueron inventados a fines del siglo XIX para la imprenta de la prensa y como un substituto práctico para las plumas. Sus marcas son a menudo visualmente indistinguibles de las de los lápices estándar del grafito, pero cuando están humedecidas sus marcas se disuelven a una tinta coloreada, que luego se imprime a otra pieza de papel. Se utilizó hasta comienzos del siglo XX, en que el bolígrafo los sustituyó lentamente.

Contrario a los lápices de color a base de cera, estos pueden ser borrados fácilmente. Se usa principalmente en bosquejos, donde el objetivo es crear un esquema usando el mismo color que otros medios (tales como lápices de cera, o pinturas de acuarela) llenarían, o cuando el objetivo es explorar el bosquejo del color. Algunos animadores prefieren lápices borrables de color a los lápices del grafito porque estos no manchan fácilmente, y los diversos colores permiten una mejor separación de objetos en el bosquejo. Copio-editores los encuentran útiles también, pues sus marcas se destacan más que el grafito pero pueden ser borradas.

Los lápices azules "non-photo", como Sanford's Copy-not o Staedtler' Mars Non-photo, o "whiteprint", como Staedtler' s Mars Non-Print, hacen marcas que no son reproducidas por las fotocopiadoras o por las copiadoras.

Se espera que estos lápices sean muy confiables, y su mina es a prueba de roturas. Los lápices del estenógrafo se afilan a veces en ambos extremos.

Los llamados lápices de golf son generalmente cortos (una longitud común es los 9 cm) y muy baratos. También se conocen como lápices de biblioteca, ya que muchas bibliotecas los ofrecen como instrumentos de escritura desechables e inderramables.



Hay también lápices que utilizan métodos mecánicos para empujar la mina a través de un agujero hacia el extremo. Los borradores son también desprendibles (y así reemplazables), y cubren generalmente un lugar para almacenar las minas en la parte superior del portaminas. Este tipo de lápices mecánicos (o portaminas) son populares por su longevidad y el hecho de que nunca necesitan ser afilados.

Los tipos de mina se basan en el grosor y al igual que los lápices pueden variar en los tonos y firmezas, inclusive existen minas de colores. Los tamaños comunes son "0.3", "0.5", "0.7", "0.9", "1.1", "1.3", y "1.6" milímetros. El tamaño de 2.0 milímetros es de uso común en el diseño, ilustraciones, e ingeniería. Por otra parte, las minas de 0.5 y 0.7 suele ser usada de manera más general para trabajos escolares y de oficina.

Suele suceder que, para algunas marcas, las minas usadas en los portaminas son demasiado frágiles, lo que ocasiona que se rompan con frecuencia en la escritura cotidiana, o también sucede cuando el dibujante aprieta muy fuerte el lápiz y ocasiona una rotura de la mina, sin embargo, existen nuevas tecnologías que usan polímeros para reforzar la estructura de las minas, siendo estas características de marcas de prestigio. No obstante, suele importar más el trazo y la fuerza con la que es usado un lapicero que la marca de las minas que se usan.





</doc>
<doc id="21780" url="https://es.wikipedia.org/wiki?curid=21780" title="Getafe">
Getafe

Getafe es una ciudad española situada en la zona sur de la Comunidad de Madrid y uno de los municipios más industrializados del área metropolitana de Madrid. La importancia de esta localidad proviene también de su base aérea militar, una de las más antiguas de España; del Cerro de los Ángeles, tradicionalmente considerado el centro geográfico de la península ibérica; y de la Universidad Carlos III, cuyo rectorado se halla en la ciudad.

La cercanía de Getafe a Madrid ha propiciado un gran desarrollo industrial a lo largo del siglo XX, aumentando así la población hasta los 178 288 habitantes (INE 2017), aunque gracias a su gran red industrial y de servicios es un municipio con entidad propia que ha evitado convertirse en una ciudad dormitorio, ya que una gran proporción de sus residentes trabajan o estudian en Getafe. El incremento de población ha obligado a construir numerosas vías de acceso, ha hecho ampliar la oferta de servicios públicos y ha impulsado la creación de nuevos barrios a lo largo del siglo XX.

La ciudad se sitúa a 13 km al sur del centro de Madrid, en la parte sur del área metropolitana de la capital, en una zona llana de la Meseta Central perteneciente a la cuenca del río Manzanares. Se divide en los siguientes barrios: El Bercial, Las Margaritas, Sector III (que incluye el de Arroyo Culebro), Alhóndiga, la zona Centro-San Isidro, Juan de la Cierva, Getafe Norte, Los Molinos y Buenavista, a los que hay que sumar la pedanía de Perales del Río y cinco polígonos industriales.

El escudo de armas oficial de Getafe fue aprobado en 1967 y es descrito en el lenguaje heráldico del modo siguiente:

Estas armas son del tipo denominado alusivas, remitiendo por una parte al monumento dedicado al Sagrado Corazón de Jesús y por otra, al aeródromo militar, ambos ubicados en el término municipal.

Por su parte, la bandera es de color carmesí en cuyo centro se dispone el escudo oficial.
En la Edad Media, en el actual término municipal de Getafe convivían varias aldeas, y una de las más importantes era Alarnes, situada muy cerca del actual centro urbano. En 1326, los pobladores de dichas aldeas se unieron en un pueblo situado a lo largo del camino real que unía Madrid con Toledo. A este nuevo pueblo se le llamó "Xatafi". Este nombre venía de la palabra árabe "Jata", que significa “algo largo”. De ahí se dedujo que "Xatafi" se refería a la larga calle principal del pueblo, que no era otra que el camino real. Por tanto, "Xetafe" significa “calle larga”. A partir de ahí, el nombre evolucionó pasando por "Xetafi", "Jetafee", "Jetaphe", "Jetafe" y, finalmente, "Getafe".

La historia de Getafe se puede dividir en tres fases claramente marcadas. En la primera etapa, que va desde la prehistoria hasta 1326, distintas civilizaciones y aldeas habitaron el término municipal, aunque Getafe no existía como pueblo. En la segunda, que empieza en el siglo XIV y acaba en el siglo XX, Getafe se formaba como pueblo y se iba desarrollando lentamente con diversas construcciones. En la tercera fase, que comienza en el siglo XX, Getafe pasó de ser un pueblo agrícola a convertirse en una gran ciudad industrial, con un gran aumento de la actividad comercial e industrial, de la población, y de la superficie urbana. A continuación se desarrollan estas tres fases.

Los restos prehistóricos hallados en el término municipal de Getafe ponen de manifiesto la existencia de un asentamiento humano en esta época remota. La presencia humana en Getafe se remonta al Paleolítico Inferior (antes del 100000 a. C.), en una terraza del río Manzanares, donde se han encontrado varios útiles de piedra (hachas, lascas, puntas de flecha, raspadores y cuchillos), pertenecientes a la Edad de Piedra, y vasijas y brazaletes, todos ellos pertenecientes a la Edad de los Metales, y en concreto al final de la Edad de Bronce y al inicio de la Edad de Hierro. Los prehistoriadores, basándose en la nutrida representación de animales domésticos encontrados en estos yacimientos de la Edad de los Metales, afirman que la actividad preferente de los pobladores de la zona era la ganadería. Carne, leche, queso (han aparecido queseras) y pieles serían los principales productos obtenidos.

Del siglo II al III d. C. se produjo la llegada de los romanos al término municipal, construyendo la villa romana de La Torrecilla, emplazada en la ribera del Manzanares. Los visigodos (s. VI-VII) dejaron su huella con una necrópolis cercana a La Torrecilla.

En el siglo VIII, la zona donde actualmente se halla Getafe fue invadida por los musulmanes y, en 1085, Alfonso VI conquistó las aldeas entonces situadas en el actual término municipal. En 1326, los habitantes de Alarnes y de otras aldeas se trasladaron al entorno del camino real Madrid-Toledo, creándose una concentración de viviendas y naciendo así Getafe. Para estructurar el nuevo pueblo, en ese mismo siglo se construyó la primitiva ermita de la Magdalena, que más tarde sería derruida. Otras fuentes, basadas en documentos históricos, sitúan la fundación de Getafe en la época musulmana, es decir, entre los siglos VIII y XI.

En 1492 el hambre y la peste asolaron Getafe y en 1529 se creó el Hospitalillo de San José. En 1549 Alonso de Covarrubias comenzó a construir la iglesia de Nuestra Señora de la Magdalena (actual catedral) sobre el solar de la antigua ermita y en 1610 se construyó la ermita de Nuestra Señora de los Ángeles en el Cerro de los Ángeles. En 1737 se fundó el colegio de las Escuelas Pías en Getafe, La Inmaculada - PP. Escolapios; y en 1763, bajo el reinado de Carlos III, se construyó el nuevo camino de Aranjuez (cuyo último destino era Cádiz) que pasaba por el pie de las laderas del Cerro de los Ángeles. Entre 1808 y 1812 las tropas napoleónicas ocuparon Getafe y en 1851 se inauguró el tramo ferroviario Madrid-Aranjuez, pasando este por el municipio.

El 22 de diciembre de 1897 se inauguró el alumbrado público en Getafe. En 1911 se estableció con carácter permanente la base aérea, y dos años después, se creó la Escuela de Aviación Civil. El 30 de mayo de 1919 Alfonso XIII inauguró el primer monumento al Sagrado Corazón en el Cerro de los Ángeles y en 1924 la empresa C.A.S.A. instaló su factoría en el municipio. En ese mismo año, en la base aérea, se realizaba el primer vuelo en el autogiro, creado por Juan de la Cierva.

La cercanía de Getafe a Madrid proporcionó un fuerte desarrollo industrial a principios del siglo XX, convirtiendo al municipio en ciudad dormitorio y provocando un rápido crecimiento de la población a partir de los años 1950. En 1956 se instaló en el municipio la fábrica de John Deere y un año después hacía lo mismo Siemens AC. A partir de los 1970 se crearon nuevos barrios como San Isidro, El Bercial, Juan de la Cierva y Las Margaritas con motivo del fuerte aumento de la población que experimentaba la ciudad.

En 1961 el canal de Isabel II abasteció de agua al municipio y en 1979 se celebraron las primeras elecciones democráticas municipales, después de la Constitución de 1978. En 1988 comenzaron las obras de la Universidad Carlos III. Entre 1979 y 1988 se construyó el barrio del Sector III, a finales de los años 1990 se hizo lo mismo con el barrio de Getafe Norte y el Arroyo Culebro. Actualmente se ha ampliado el barrio de El Bercial y se han creado dos nuevos barrios, Los Molinos y Buenavista. A fecha de 2014, Getafe cuenta con los siguientes barrios, ordenados por densidad de población: Centro, Juan de la Cierva, Sector III, La Alhóndiga, Getafe Norte, El Bercial, Las Margaritas, Perales del Río, San Isidro, Buenavista, Los Molinos.

En abril de 2003 se inauguró la línea 12 del Metro de Madrid, uniendo así las ciudades del Sur con la capital.

Algunas personas famosas que han vivido en Getafe son:

Actualmente, la alcaldesa del municipio es Sara Hernández Barroso, del Partido Socialista Obrero Español, quien ocupa el cargo desde 2015. Los partidos políticos más relevantes en el ámbito local, además del PSOE, son el Partido Popular, cuyo actual portavoz es Manuel Ortiz Lázaro, y partidos a la izquierda del PSOE como la candidatura de unidad popular Ahora Getafe o IUCM, antiguo referente de Izquierda Unida en Madrid expulsados de la federación. Getafe se ha caracterizado tradicionalmente por poseer una población mayoritariamente obrera; asimismo, a lo largo de su historia, los partidos políticos más influyentes han sido los del ala izquierda: sobre todo, el PSOE; aunque en alguna excepción ha ganado el PP.

En las elecciones municipales de 2015, el PP obtuvo 9 ediles (28,57 % de los votos), convirtiéndose en la fuerza política más votada. Sin embargo, el PSOE se hizo con la alcaldía tras un pacto entre los partidos de izquierda, que juntos sumaban mayoría absoluta. Las elecciones municipales de Getafe se celebran cada cuatro años, junto con las elecciones autonómicas. Los próximos comicios al gobierno local se celebrarán en el año 2019.

El Ayuntamiento de Getafe se estructura en diferentes áreas: de hacienda, patrimonio y seguridad ciudadana; de urbanismo; de función pública, régimen interior y cultura; de desarrollo económico, formación y empleo; social, participación ciudadana y drogodependencias; de acción ciudadana; y de gestión de las empresas municipales de limpieza y medio ambiente y del suelo y la vivienda. El ayuntamiento celebra plenos ordinarios cada mes, aunque con frecuencia se celebran plenos extraordinarios, con el fin de debatir temas y problemas que afectan al municipio.

Getafe es una de las ciudades más destacadas en la lucha obrera debido a la gran cantidad de población que trabajaba en la industria local. Los sindicatos con mayor impacto en el municipio son Comisiones Obreras (CCOO), CSIT UNIÓN PROFESIONAL y UGT. Dichas formaciones tienen sucursal en Getafe y cuentan con una gran afiliación.

El concepto de deuda viva contempla solo las deudas con cajas y bancos relativas a créditos financieros, valores de renta fija y préstamos o créditos transferidos a terceros, excluyéndose, por tanto, la deuda comercial.

La deuda viva municipal por habitante en 2014 ascendía a 218,37 €.

Getafe está situado en la zona sur de la Comunidad de Madrid, en España, en el suroeste de Europa, en el norte de la Submeseta Sur (división de la Meseta Central), en la cuenca del río Manzanares, y entre los 610 y 640 metros de altitud. Sus coordenadas son 40º 18' N 3º 43' O. Tradicionalmente se considera que en Getafe se encuentra el centro geográfico de la península ibérica, aunque según el Instituto Geográfico Nacional la ubicación exacta del mismo es difícil de determinar, muy dependiente de la metodología utilizada, y algunos estudios modernos lo sitúan más al oeste, en la provincia de Toledo.

El término municipal de Getafe tiene una superficie de 78,74 km², un perímetro de 46,5 km y una forma alargada de oeste a este, con una distancia máxima en esta dirección de 16 km, y 7 km de norte a sur. La parte más oriental del término municipal está dentro del Parque Regional del Sureste, abarcando las terrazas del río Manzanares, parte del arroyo Culebro y los cerros de la Marañosa.

La céntrica situación de Getafe en la península ibérica hace que no diste más de 725,6 km de ninguna capital de provincia de la España peninsular. Estas son las distancias a algunas ciudades, a los mares que bañan la costa española y a las fronteras con Portugal y Francia:

El relieve del término municipal de Getafe es bastante llano, con una inclinación menor del 5 % hacia el este y con una altitud media de 631 metros sobre el nivel del mar. La altitud mínima se encuentra en el extremo este, en el río Manzanares, con 540 metros, y la máxima elevación está en el cerro Buenavista, con 704 metros, situado en el extremo oeste del término municipal, limitando con Leganés. La zona más accidentada es la de los cerros de la Marañosa, situados en el sureste, cuya máxima elevación es de 698 metros. En el centro del término municipal está el Cerro de los Ángeles (670 metros). El suelo de Getafe se erosiona con facilidad ante la acción del agua, y para evitar esto, en las laderas de cerros como el de los Ángeles y los de la Marañosa se han plantado bosques de pinos carrascos.

Por la parte más oriental del término municipal pasan 9,5 km del río Manzanares, por toda la zona sur transcurren 16,5 km del arroyo Culebro, y en el sureste descienden 2 km del barranco de Filipinas desde los cerros de la Marañosa. Hay dos canales artificiales que transcurren por ambos lados del río Manzanares y paralelos a este, cuya función es regar los cultivos de regadío aledaños al río. A 2 km al este del Cerro de los Ángeles están las lagunas de Perales, unas de las pocas que quedan en la zona. El arroyo Culebro y el barranco de Filipinas llevan un caudal escaso y nulo en la estación estival, mientras que el río Manzanares lleva agua todo el año. Por tanto, el término municipal de Getafe se halla dentro de la cuenca del río Manzanares, salvo una pequeña parte del sureste, que pertenece a la del río Jarama.

El término municipal de Getafe limita con los siguientes términos municipales: al norte con Villaverde y Villa de Vallecas (distritos de Madrid), al este con Rivas-Vaciamadrid, al sureste con San Martín de la Vega, al sur con Pinto, al suroeste con Fuenlabrada, y al oeste con Leganés.

El clima de Getafe, igual que el de Madrid, es un clima mediterráneo típico. De acuerdo con los criterios de la clasificación climática de Köppen el clima de Getafe en el periodo de referencia 1981-2010 se clasifica como un clima de tipo "BSk" (semiárido templado). La temperatura media (periodo de referencia: 1981-2010) se sitúa en torno a los 15 °C.

Los inviernos son fríos, con una temperatura media en enero de unos 6 °C, unas máximas medias de entre 10 y 11 °C, y mínimas de alrededor de 1 °C. Las heladas son frecuentes en invierno y las nevadas ocasionales (unos 3 días de nieve al año). Por el contrario los veranos son calurosos, con medias en el mes más cálido (julio) que rondan los 26 °C, máximas medias de alrededor de los 33 °C y mínimas en torno a los 17 °C. La aplitud térmica diaria es alta (entre 11 y 12 °C). La amplitud térmica anual es también alta, situándose en torno a los 20 °C.

La precipitación anual no llega a los 400 mm, con un mínimo marcado en verano (especialmente en julio y agosto). La humedad media a lo largo del año se sitúa alrededor del 57 %, con una gran oscilación entre las épocas frías, mucho más húmedas, y las cálidas, que resultan muy secas.

A continuación se muestran los valores climatológicos del observatorio de la AEMET situado en la base aérea de Getafe, a 620 msnm, tomando los años 1981-2010 como periodo de referencia. Nótese que los valores extremos están también tomados en dicho periodo.

A continuación algunos de los valores extremos registrados en el observatorio meteorológico de la base aérea de Getafe tomados a partir de 1951 para la temperatura y precipitación y a partir de 1961 para el viento: la temperatura máxima absoluta de 41,6 °C registrados el 24 de julio de 1995 y la temperatura mínima absoluta de -12 °C registrada 5 de febrero de 1963, la precipitación máxima en un día de 64,6 mm registrada el 28 de septiembre de 2012 y la máxima racha de viento de 126 km/h registrada el 30 de diciembre de 1981.

La vegetación autóctona de Getafe es la característica del bosque mediterráneo, compuesto por encinas y, en menor medida, alcornoques. En cuanto a las formaciones arbustivas, las especies autóctonas, pero no abundantes, son la jara y la retama. Este bosque y sotobosque autóctono solo ocupa el 16 % de la superficie del término municipal, localizado en los cerros de la Marañosa y en la zona este. En las riberas del río Manzanares y del arroyo Culebro podemos encontrar árboles de hoja caduca y cañas.

La mayor parte del suelo no urbanizado corresponde a cultivos cerealísticos (trigo en su mayoría), y en menor medida de regadío, con huertas en la vega del río Manzanares. Algunas zonas están reforestadas con pinos piñoneros y carrascos, como es el caso del cerro de los Ángeles, el Prado Acedinos, parte de los cerros de la Marañosa y parte del parque del Sector III. En los parques y calles de la ciudad, los árboles más abundantes son el "plátano" o falso castaño, la acacia de tres puntas, el olmo y el pino piñonero. Con menor presencia, se pueden encontrar cedros, cipreses, pinos carrascos, ciruelos, chopos, abetos y palmeras.

Respecto de la fauna local, cabe destacar la importante población de ciertas aves pequeñas que viven en la propia ciudad como los gorriones y las palomas. En la zona este del término municipal se pueden encontrar aves de mayor tamaño, conejos, zorros, jabalíes y comadrejas. En Perales del Río, habita la mayor comunidad del mundo de cernícalo primilla, un ave de la familia del halcón.

El espacio urbano de Getafe se organiza de una manera casi longitudinal, de nordeste a suroeste. Así, la forma alargada que tiene hoy se debe principalmente a la cercanía de la base aérea, que impide su crecimiento hacia el sureste. Las calles más importantes de la ciudad son las calles Madrid y Toledo. Esas dos vías, peatonales en su parte más céntrica, son hoy lo que fue en la Edad Media el camino real de Madrid-Toledo. Getafe tiene otras calles y avenidas importantes que estructuran sus barrios, como es la avenida de España, la avenida de Los Ángeles, la avenida de las Ciudades, la avenida de Juan Carlos I y la calle del Ferrocarril.

Los edificios de la arquitectura popular de Getafe se caracterizan por tener, generalmente, dos plantas, una cubierta inclinada con tejas, varios pequeños balcones en la segunda planta y fachada de ladrillo visto y de color suave, características propias de la arquitectura castellana. Este tipo de casas se encuentran en el barrio centro, pero cada vez hay menos, porque cuando quedan deshabitadas a menudo son demolidas para construir en su lugar un nuevo bloque de viviendas. Una característica especial del urbanismo de Getafe es que la altura media de sus edificios es de cinco plantas, o lo que es lo mismo, unos 17 metros. Esta peculiaridad es debida a la cercanía de la base aérea, y hace que Getafe sea una ciudad de edificios bajos, algo poco común en las ciudades de la zona sur de Madrid. De esta forma, las edificaciones de Getafe que superan las 8 plantas son escasas.

Pese a los límites urbanísticos impuestos por la base aérea y los propios límites del término municipal, la ciudad tiene una serie de espacios verdes con una superficie importante. Dos de los parques más grandes del municipio son los del Sector III y de La Alhóndiga, ambos unidos. Estas zonas verdes tienen un lago y un río artificiales, dos pinares y numerosos caminos. Ocupan una superficie semejante a la del barrio centro y están ubicados al oeste del centro urbano, separado de este por la autovía de Toledo (A-42) y a espaldas del Hospital Universitario de Getafe. Dentro de la ciudad hay una serie de parques de diversos tamaños y características, los cuales son el de Castilla-La Mancha, el de San Isidro, el de las Escuelas Pías y el de El Casar. Fuera de la ciudad hay dos pinares con merenderos, fuentes y quioscos, los cuales son el del cerro de los Ángeles y el del Prado Acedinos.

Actualmente se están llevando a cabo varias ampliaciones del suelo urbano. Una de ellas es la del barrio de El Bercial y dos de reciente adjudicación: Los Molinos y el Cerro Buenavista. La ampliación de El Bercial hará cuadriplicar la superficie del barrio y hará crecer la ciudad hacia el Noroeste, uniéndose El Bercial con el centro urbano. Así mismo, se está ampliando hacia el este el polígono industrial de Los Olivos, y Perales del Río está creciendo hacia el oeste, quedándose estos dos barrios cada vez más cerca. En la zona sur, junto a la autovía M-50, se está construyendo el Área Tecnológica del Sur, una zona en la que se crearán salones de exposiciones y espacios para nuevas industrias.

El ayuntamiento de Getafe tiene varios proyectos para ampliar el suelo urbano de la ciudad con el fin de agrandar barrios. Uno de estos proyectos, ya en marcha, es la ampliación del Sector III, en el que se va a construir viviendas en las inmediaciones del depósito del cerro Buenavista. Otro proyecto es la creación del barrio residencial de Los Molinos, situado al este de Getafe Norte y al norte del polígono de Los Ángeles.

Antes del siglo XX, la ciudad tenía solo un barrio, que corresponde al barrio centro y La Alhóndiga. Perales del Río es también uno de los barrios más antiguos del municipio, ya que data de, aproximadamente, el siglo XVII. A partir de la década de los 1960 el rápido aumento de la población obligó la creación de nuevos barrios como los de San Isidro en el sur, Juan de la Cierva en el este, Las Margaritas en el norte y El Bercial en el oeste. En los años 1980, se construyó el Sector III en el suroeste, se amplió Perales del Río, y en la década siguiente se creó Getafe Norte. Hoy en día, Getafe está dividido en once barrios y cinco polígonos industriales. A continuación se enumeran:













Esta ciudad ha crecido mucho en las últimas décadas, induciendo un incremento análogo en el número de dotaciones y equipamientos. Algunas de estas son las siguientes:

El municipio cuenta con varios periódicos locales con ediciones impresas y digitales, tales como "Getafe Capital", que tiene su periódico en papel quincenal y de distribución gratuita y página web. Desde diciembre de 2009 se distribuye quincenalmente Al cabo de… La Calle, medio también presente en la red. Asimismo, en febrero de 2013 nace Más Getafe, un periódico creado por un grupo de periodistas que pone el acento en la cultura y los temas sociales y se encuentra de forma semanal todos los miércoles en kioscos y puntos de venta. También con página web y gestión activa de las redes sociales. La localidad madrileña cuenta asimismo con otros destacados medios como El Buzón, uno de los más seguidos que cuenta también con su edición digital o El Iceberg también con renovados contenidos diarios en internet. Otros, como el veterano de los medios locales Acción Getafense, han desaparecido. También desaparecieron ya Vivir en Getafe, Getafe Ahora o Getafe al Día y Mercado. El Ayuntamiento edita también su Boletín municipal.

La emisora local "Radio Getafe" desapareció absorbida por Cadena COPE (101.8 FM). La ciudad tiene además una emisora comunitaria, "Radio Ritmo" (99.9 FM), que está adherida a la Red de Medios Comunitarios. La ciudad contó en los años 1990 con una emisora de televisión llamada "Tele Getafe". Existen otros medios solo digitales como Capital del Sur, Getafe Digital o Getafe Hoy. Cope Madrid Sur (89.7 FM) realiza semanalmente programas con la intervención de los políticos de todos los partidos con representación en el municipio, programas que puedes escuchar en formato podcast en su web www.copemadridsur.es, en la que además, actualiza diariamente las noticias del sur de la CAM. La emisora 'SER Madrid Sur' (94.4 FM y www.sermadridsur.com) da también cobertura a la localidad además de al resto de la zona sur de la Comunidad madrileña.

Getafe tiene unos medios de transporte propios de una gran ciudad, como son las autopistas y autovías, paradas de taxi, autobuses, trenes y cuenta con la línea 12 del metro de Madrid (Metrosur).

Cuatro autopistas y autovías pasan por Getafe, dos radiales (A-42 y A-4), y dos de circunvalación a Madrid (M-45 y M-50). Otra carretera de dos carriles por sentido comunica Getafe con Leganés, y dos carreteras provinciales comunican Perales del Río. A continuación se enumeran:






La población de Getafe, cifrada en 170.115 habitantes en 2011 según el INE, está distribuida de manera desigual en los distintos barrios que la conforman: Sector III, San Isidro, Perales del Río, Las Margaritas, La Alhóndiga, Juan de la Cierva, Getafe Norte, El Bercial y Centro.

El barrio que más viviendas tiene es el Centro, con 12.574; seguido de Juan de la Cierva, con 12.072. En tanto que Perales del Río, con 1815 y, El Bercial, con 1820, son los que menos; aunque estos últimos verán incrementado su número considerablemente con los desarrollos urbanísticos programados. Los barrios más poblados son Juan de la Cierva, Centro y Sector III, con 32.925, 32.160 y 24.217 habitantes respectivamente. En el municipio viven 30.000 personas entre los 20 y los 40 años, y 24 personas de 100 ó más años (de las cuales 21 son mujeres y 3 son hombres); en términos agregados, predominan las mujeres sobre los hombres, siendo estas 79.514 y los varones, 78.849.

La población extranjera aumenta año tras año en Getafe, y actualmente se sitúa en torno al 9 % respecto al total. Los inmigrantes que llegan a la ciudad proceden principalmente de Hispanoamérica, Europa del este y Europa Occidental. La tasa de crecimiento anual constante se sitúa entre 0,01 y 3,00 %, la tasa de natalidad está entre el 0,01 y el 8 ‰, la tasa de mortalidad entre el 4 y el 8 ‰, y el crecimiento vegetativo del periodo que va de 1996 al 2002 es de entre el 5 y el 10 ‰. El índice de juventud es del 13%, el índice de envejecimiento del 12 %, y la edad media de los habitantes es menor de 22 años. En cuanto a la religión, más del 85% de los habitantes se consideran católicos, pero cerca del 20% de ellos son practicantes que acuden semanalmente a un templo católico.

La población de Getafe ha experimentado un fuerte crecimiento a lo largo de la segunda mitad del siglo XX. Durante toda la Edad Media y hasta 1900, la población rondaba entre los 2.500 y los 6.000 habitantes. En 1950 la población era de 12.254, en 1970 de 69.424, en 1977 de 124.601, y en 1988 de 136.162 habitantes. Los datos demuestran el fortísimo incremento de población ocurrido a partir de 1960 hasta la actualidad. Hoy en día, la población de la ciudad crece de manera continua y moderada, a razón de una media de 1.700 personas por año. Sin embargo, 2006 fue el primer año desde el siglo XVII en que la población descendió, concretamente 2.043 personas respecto del año anterior. Actualmente, Getafe es un claro ejemplo de "ciudad dormitorio" en que cerca de la mitad de su población trabaja en Madrid.

Getafe ocupa el puesto 40 en el orden de ciudades más pobladas de España, detrás de Albacete y delante de Salamanca. En la Comunidad de Madrid es la sexta ciudad más poblada, detrás de Leganés y delante de Alcorcón. El gentilicio de Getafe es "getafense" o "getafeño", aunque la más usada es la primera forma. Los códigos postales de la ciudad son: 28901 - 28902 - 28903 - 28904 - 28905 - 28906 - 28907 - 28909

El municipio, que tiene una superficie de 78,38 km², cuenta según el padrón municipal para del INE con habitantes y una densidad de  hab./km².

Entre 1842 y 1857, crece el término del municipio porque incorpora a Perales del Río.

Desglose de población según el Padrón Continuo por Unidad Poblacional del INE.

La economía de Getafe comenzó siendo principalmente agrícola: el sector primario fue el más importante durante gran parte de su historia. A principios del siglo XX aparecieron en el municipio las primeras fábricas, pero no fue hasta la segunda mitad de ese siglo que la industria comenzó a cobrar protagonismo. En la década de los 1960 ésta ya era el principal sector de la economía local.

Hoy en día la economía getafense es mayormente industrial, puesto que la ciudad cuenta con cinco polígonos industriales. Después de Madrid, Getafe es la ciudad más industrializada de la Comunidad de Madrid, teniendo numerosas industrias como John Deere, Siemens o Construcciones Aeronáuticas SA, entre otras muchas. La ciudad cuenta con cinco polígonos industriales repartidos en las zonas periféricas. En cuanto al tipo de actividad industrial, la industria getafense se divide así: el 34 % es de metalurgia, el 20% de alimentación, el 14% de madera y mueble, y el 6 % de textil y piel; otras industrias como el papel y artes gráficas o la construcción ocupan porcentajes menores. En cuanto a la minería, existen unas canteras en la zona este del término municipal que se explotan intensivamente.

El sector de servicios comenzó a despuntar a finales de los años noventa con la creación de nuevos centros comerciales y de ocio, y las nuevas oficinas instaladas en el centro urbano. Actualmente este sector está en constante crecimiento. Los sábados por la mañana hay un mercadillo ambulante en el aparcamiento de la estación de Cercanías de Las Margaritas.

El peso de la agricultura en la economía local se ve ya muy reducido, aunque la zona este del término municipal conserva buenas extensiones de cultivo de secano y regadío. El cultivo predominante es el trigo, y existen pequeñas extensiones de olivo, vid y huertas. La ganadería, cada vez menos presente, aún se conserva en las inmediaciones del Cerro Buenavista y, sobre todo, en los pastos próximos al río Manzanares. Los vinos que se elaboran en Getafe reciben la Denominación de Origen de Vinos de Madrid y se enmarcan dentro de la Subzona Arganda, que abarca todo el sureste de la Comunidad de Madrid.

La renta per cápita media de los habitantes de Getafe es de 10.000 €, por debajo de la media de la Comunidad de Madrid, que es de 12.500 €. Los barrios más "ricos" son el Sector III y Getafe Norte con 13.000 € de media, y los más "pobres" la Alhóndiga, Centro y San Isidro con 9.000 €. En el mes de enero de 2006, la tasa de desempleo era del 8,4 %, y tiene una suave tendencia a bajar.

El turismo está poco desarrollado en la ciudad, pese a que el patrimonio histórico de Getafe es importante. Curiosamente, las plazas hoteleras de la ciudad son numerosas y a menudo son muy solicitadas, debido a que los turistas que visitan Madrid y el centro de España, encuentran en Getafe una variada oferta hostelera muy cercana a la capital.

Getafe tiene una serie de monumentos y lugares de interés que representan un fiel reflejo de su historia. El lugar más famoso y visitado de Getafe es el Cerro de los Ángeles, pero hay otros lugares importantes como es la Catedral de Nuestra Señora de La Magdalena, el Hospitalillo de San José y el colegio de los Padres Escolapios de este municipio.


El Cerro de los Ángeles es un famoso cerro situado en la zona de polígonos industriales. Su fama reside en que tradicionalmente se consideraba el centro geográfico de la península Ibérica, aunque según el Instituto Geográfico Nacional la ubicación exacta del mismo es difícil de determinar, muy dependiente de la metodología utilizada, y algunos estudios modernos lo sitúan más al Oeste, en la provincia de Toledo. En su cima están la ermita de Nuestra Señora de los Ángeles y el monumento al Sagrado Corazón, así como un convento de Carmelitas Descalzas. El cerro, casi siempre visible desde Getafe, se eleva sobre los edificios haciendo de telón de fondo.

La catedral de Getafe es sede del obispado de la zona sur de la Comunidad de Madrid. Este templo renacentista data del siglo XVIII, tiene una torre mudéjar y un retablo barroco. En 1958 es declarada Monumento Histórico Artístico y es la sede de la Diócesis de Getafe.

El Hospitalillo de San José es un antiguo hospital construido, en 1529, para mejorar la precaria salud de los getafenses de entonces. Mantiene un estilo muy castellano con su patio central porticado y su pequeña capilla.

Monasterio de Carmelitas Descalzas situado en el paraje de La Aldehuela de Perales del Río.

La Universidad Carlos III de Madrid tiene su rectorado y tres de sus facultades en Getafe. Algunas de estas se emplazan en edificios que funcionaron como cuarteles militares, a principios del siglo XX.

El municipio cuenta con dos hostales en el casco urbano, dos moteles, un hotel y un camping en la Autovía del Sur (A-4), y dos hoteles cerca de la Autovía de Toledo (A-42).

Los dos hoteles más céntricos son:


En la Autovía del Sur (A-4) están los siguientes establecimientos:


Cerca de la Autovía de Toledo (A-42) están los siguientes hoteles:


La cultura en Getafe se ve representada en instituciones como la Universidad Carlos III, cuyo rectorado y tres facultades de humanidades y ciencias jurídicas se encuentran en Getafe. Esta universidad tiene un coro y una orquesta galardonados y reconocidos en numerosas ocasiones en todo el territorio español. El Conservatorio Profesional de Música de Getafe, que fue inaugurado en el 2000, resulta ser el conservatorio público de toda la zona sur de la comunidad. El Teatro Auditorio Federico García Lorca, uno de los más grandes e importantes de la zona sur de Madrid, fue inaugurado a finales de los 1990 y en él se hacen multitud de obras de teatro y conciertos. Además, ocho centros cívicos y una serie de bibliotecas municipales se reparten por los diferentes barrios de Getafe. Junto a la biblioteca del Sector III se encuentra el "Centro de Poesía José Hierro", un lugar de creación y de estudio donde se pueden realizar consultas, reuniones y actividades formativas, cuyo objetivo es recopilar documentos y crear un patrimonio literario. En este centro hay un gran legado del poeta José Hierro, revistas históricas, una fototeca y una videoteca. En 2005 se planeó construir el "Museo de la Aviación de Getafe", con diseño encargado al arquitecto Norman Foster, proyecto que sin embargo quedó abandonado.

La actividad cultural independiente está muy presente en Getafe. Existe una gran cantidad de músicos y bandas de todos los estilos y disciplinas. Buena parte de los actos culturales al aire libre se realizan en base un empleo abusivo de decibelios como instrumento de reclamo, para que estos se escuchen a bastante más distancia de donde se encuentra el público al que supuestamente van destinados, y se emplazan al lado de viviendas en vez de lugares más apropiados como parques, teatros, colegios ó polideportivos. Son estos espectáculos que suponen un perjuicio en cuanto a ruido, tanto para los que acuden voluntariamente como para los que no pueden elegir, aunque esto sea lo habitual en este siglo y lo que promueven los municipios de la zona.

Al hablar de cultura en Getafe hay que hablar de Cultura Inquieta, plataforma de la música y las artes que, con raíces y sede en Getafe, desarrolla su actividad a lo largo de todo el año por diferentes escenarios españoles, edita su revista internacional de arte "Inquieta Magazine", informa diariamente de lo que ocurre en el mundo en el ámbito del arte, la fotografía, el erotismo o la música a través de su web (www.culturainquieta.com) y sus redes sociales y culmina su actividad anual con el Festival Cultura Inquieta, un encuentro multidisciplinar que se desarrolla a lo largo del mes de julio entero en Getafe.

Cerca del 40% de los habitantes de Getafe proceden de comunidades autónomas distintas a la madrileña. Parte de estos colectivos han creado las "Casas Regionales", lugares de encuentro donde se hacen actividades y actos culturales. Algunas de estas Casas Regionales son las de Extremadura, Castilla-La Mancha, Murcia, Andalucía y Castilla y León.

Getafe cuenta con Aula Universitaria de la UNED, integrado en el Centro Asociado Madrid Sur de la UNED. La presencia de la UNED en Getafe se remonta al curso 1984-85. Las instalaciones se encuentran ubicadas en el IES Alarnes. El Centro Madrid Sur cuenta con más de 8000 alumnos, estando alrededor de 1000 matriculados en el Aula de Getafe.

Las instalaciones cuentan con 6 aulas con capacidad para 35 alumnos, una sala de usos múltiples para 80 personas, un aula de estudio, un despacho para tareas administrativas y servicio de cafetería.

En Getafe se imparten las titulaciones de (ofertadas en 2015-2016):
Acceso a la universidad para mayores de 25 y 45 años,
Ciencias Políticas,
Ciencias Jurídicas de las Administraciones Públicas,
Derecho,
Sociología,
Programa Senior para mayores de 50 años,
Idiomas: Alemán B1 e inglés B1

Las Fiestas Patronales de Getafe se celebran cuarenta días después del Domingo de Resurrección lo que significa que cada año se celebran en una fecha diferente entre mediados y finales de mayo y principios de junio. Las fiestas comienzan oficialmente en sábado, pero oficiosamente el pistoletazo de salida lo da una romería que tiene lugar nueve días antes, el día de la Ascensión, en la que se baja desde el Cerro de los Ángeles a la patrona, la Virgen de los Ángeles. A la llegada al pueblo, el alcalde cede a la virgen el bastón de mando de la ciudad de manera simbólica para luego concluir la romería en la Catedral de Getafe. Ese día es tradición tomar limonada en lugares como la plaza del Ayuntamiento.

El comienzo de las fiestas se produce, como ya se ha indicado, nueve días después de la bajada de la Virgen. El "sábado de las fiestas", como se le conoce popularmente, arranca con un pregón en la Plaza de la Constitución seguido de una mascletá en la Calle Jardines. Durante estos días, se monta una feria en el recinto ferial, se colocan las casetas de los partidos políticos en la Calle Ferrocarril, al lado de la estación de tren de Getafe Central y se hacen numerosas actividades culturales, algunos conciertos, , unas pequeñas fallas, y varias corridas de toros. Una semana después de comenzar las fiestas se celebra una cabalgata que pasa por el centro de la ciudad en la que se lanzan caramelos y otras baratijas. Las Fiestas Patronales de Getafe concluyen ocho días después del pregón con la subida al Cerro de los Ángeles de la virgen que abandona el pueblo hasta el año siguiente.

Durante los días de Navidad se realizan varias actividades culturales, como conciertos especiales de Navidad, el montaje de un gran belén murciano en el patio interior del Hospitalillo de San José y la cabalgata de los Reyes Magos del 5 de enero. También es tradición celebrar los Carnavales con cabalgatas de disfraces, y actos culturales. Durante la Semana Santa se realizan entre dos y cuatro procesiones religiosas que salen de diversas iglesias y recorren las calles de la ciudad.

La oferta educativa pública de Getafe cuenta con seis colegios de educación infantil (hasta 5 años), 23 colegios de enseñanza infantil y primaria (hasta 12 años) y catorce institutos de educación segundaria. Uno de ellos, el Instituto Laguna de Joatzel, lleva a cabo un proyecto de enseñanza bilingüe al que se van a sumar otros institutos más adelante. Las escuelas concertadas no son muy numerosas, destacándose La Inmaculada - P.P. Escolapios un prestigioso colegio de los PP.Escolapios con Educación Infantil, Primaria y Secundaria concertada, con Bachiller y F.P. privado; Divina Pastora (M.M. Calasancias), San José y Colegio Jesus Nazareno, todos de educación religiosa. El Colegio Los Ángeles situado en el Prado Acedinos con educación desde 1 año hasta 2º de Bachillerato y con un polideportivo de próxima inauguración y el Colegio Europeo Aristos, bilingüe, ateo y privado cuya oferta educativa va desde las escuelas infantiles hasta el Bachillerato, y que cuenta con un club deportivo y piscina cubierta. En la ciudad hay también varios centros de formación profesional de primer y segundo ciclo y un centro de educación de adultos dependiente de la Comunidad de Madrid, el C.E.P.A. "Casa de la Cultura". Por último, el rectorado de la Universidad Carlos III tiene su sede en Getafe junto a tres de sus facultades de humanidades y ciencias jurídicas. Junto a la universidad está la residencia de estudiantes Fernando de los Ríos. El porcentaje de personas mayores de 16 años con título universitario es del 14 % y la tasa de analfabetismo es del 12%.

La gastronomía típica de Getafe es muy similar, por no decir igual, a la de Madrid. El clima, los productos del campo y la historia han configurado esta variada gastronomía. Los platos más representativos son el cocido madrileño, los callos a la madrileña, el potaje de garbanzos, la tortilla de patata, el besugo a la madrileña, la lombarda y las rosquillas tontas y listas, entre otros. En cuanto a los vinos, se destacan los de la Comunidad de Madrid, entre los cuales, los más famosos son los de San Martín de Valdeiglesias, Arganda del Rey y Navalcarnero. Tanto en los grandes centros comerciales y en las calles céntricas de Getafe podemos encontrar una variada oferta de restaurantes.

Getafe es una ciudad para las compras y el ocio; cuenta con muchas tiendas situadas en el centro urbano y varios grandes centros comerciales y de ocio en zonas más periféricas. En el centro de Getafe, la zona con más tiendas y comercios es el eje de la Calle Toledo y la Calle Madrid, que atraviesa el municipio de Norte a Sur. Gran parte de este bulevar es peatonal, lo que hace más cómodo el ir de compras a pie. Otra zona céntrica muy comercial es la avenida de Juan de la Cierva.

Según nos alejamos del centro, nos encontramos con el centro comercial "Getafe 3", situado en el barrio del Sector III, y cuenta con un Alcampo, varios restaurantes y un gran número de tiendas de ropa y calzado. En el barrio de Getafe Norte, está el "Bulevar", que cuenta con un Carrefour, varios restaurantes, y tiendas de ropa. El mayor centro comercial y de ocio de Getafe, es "Nassica", situado en el Área Tecnológica del Sur, al que se llega por la M-50, a 5 km del centro urbano. El centro cuenta con tiendas de informática, de muebles, un "Factory", 25 restaurantes, una bolera, juegos recreativos, un mercadillo permanente y 20 salas de cine. En el barrio de El Bercial está centro comercial más nuevo de la ciudad, el cual se llama "El Bercial". Alberga un El Corte Inglés, un Hipercor y dos cafeterías-restaurante. La zona con más ambiente nocturno es el Barrio Centro, donde están la mayoría de bares de tapas y discotecas de la ciudad.

A pesar de la cercanía a Madrid, el municipio tiene dos buenos pinares que cuentan con mesas, merenderos, barbacoas, campos de fútbol y parques infantiles. Estas instalaciones están preparadas para pasar una jornada en contacto con la naturaleza. Uno de ellos es el Prado Acedinos, situado al Sur del casco urbano, al que se llega por la salida 16 de la autovía A-42. El otro es el Cerro de los Ángeles, al que se llega por la autovía A-4.

Como en el resto de España, el fútbol goza de gran popularidad en Getafe. El club profesional de fútbol de la ciudad es el Getafe Club de Fútbol SAD, fundado en 1983. El 19 de junio de 2004 el equipo logró ascender a la Primera División de la liga española, donde militó hasta el año 2016. Ha sido en dos ocasiones subcampeón de la Copa del Rey de fútbol (2007 y 2008) y adquirió fama internacional con su actuación en la Copa de la UEFA la temporada 2007/08, donde se quedó a las puertas de alcanzar las semifinales.

Uno de los deportistas más laureados de la ciudad es el futbolista Alfonso Pérez Muñoz, quien fue campeón olímpico en Barcelona 1992. Hoy, el estadio local lleva su nombre en su honor.

Cada mes de junio, en las fiestas locales, se celebra "el día de la bicicleta", jornada en la que decenas de miles de getafenses sacan sus bicicletas a la calle para hacer una ruta por la ciudad sin fines competitivos. Otro evento deportivo importante es el "Media Maratón Villa de Getafe", que se celebra cada enero y que cuenta con una gran afluencia de atletas.

Entre los equipos destacados de balonmano, están por una parte el Balonmano Getasur, que tiene equipos masculinos y femeninos el cual compite en la temporada 2007-2008 en la categoría de 1ª Nacional. Y por otra el Club Balonmano Getafe, que también cuenta con equipos masculinos y femeninos, de los cuales sus categorías "seniors" compiten en la temporada 2007-2008 en 2ª Nacional.

La ciudad cuenta con siete polideportivos repartidos en los distintos barrios, pero los más grandes e importantes son los de San Isidro y Las Margaritas. Getafe cuenta, además, con un "skate park" que se encuentra detrás del Consevatorio del Sector III, tres piscinas municipales, que son la del Sector III, la de Getafe Norte y la de Perales del Río. También se destaca el estadio de fútbol Coliseum Alfonso Pérez, con una capacidad para 16.555 espectadores. Con motivo del ascenso a la primera división del equipo local de fútbol, se ha construido una ciudad deportiva situada junto a la piscina municipal de Getafe Norte.

La tradición aeronáutica en Getafe se refleja en El Club Ultraligeros que ha sido numerosas veces campeón de España, campeón de Europa en 2004 y campeón del Mundo en 2009.

Getafe tiene un buen servicio sanitario, tanto público como privado. En la ciudad hay once centros de salud públicos repartidos en los barrios de Juan de la Cierva, Las Margaritas, La Alhóndiga, Getafe Norte, Sector III, El Bercial y Perales del Río. El Hospital Universitario de Getafe, inaugurado en abril de 1991, es el principal centro de salud de la población. Este centro hospitalario, situado junto al barrio de La Alhóndiga, es famoso en toda España por su unidad de quemados. Junto al Prado Acedinos, a 5 km al Sur del centro urbano, está la "Apanid", una residencia para personas con síndrome de Down. Este centro es único en toda la zona sur de la Comunidad de Madrid.

La diócesis de Getafe es una de las más nuevas de España. Fue erigida canónicamente por el papa Juan Pablo II el día 23 de julio de 1991, el mismo día de la creación de la nueva diócesis de Alcalá de Henares. Ambas fueron desmembradas de la Archidiócesis de Madrid-Alcalá, de la cual son diócesis sufragáneas. La creación de estas dos nuevas diócesis se debió al gran crecimiento demográfico de la Archidiócesis de Madrid que, a principios de los años 1990, llegaba ya a los cinco millones de habitantes, de los cuales alrededor del 90% son considerados católicos.

El territorio diocesano de Getafe abarca toda la zona sur de la Comunidad de Madrid, ocupando una extensión de 2295 km², con una población de 1 122 601 habitantes, distribuidos en 115 parroquias. La catedral de Getafe es la iglesia de La Magdalena, consagrada como catedral el 23 de julio de 1995. La patrona de la diócesis es "Nuestra Señora de los Ángeles", cuya devoción está unida, según dice la tradición, a su santuario en el Cerro de los Ángeles, junto al camino que se dirige desde Madrid al sur de la península. La diócesis cuenta con el Seminario Diocesano Nuestra Señora de los Apóstoles, que está ubicado en el Cerro de los Ángeles, sobre la autovía del Sur, en el kilómetro 13.

El primer obispo de Getafe fue Francisco José Pérez y Fernández-Golfín, quien fue nombrado en su cargo el 23 de julio de 1991 y falleció el 24 de febrero de 2004. El actual obispo es Joaquín María López de Andújar y Cánovas del Castillo, nombrado en el cargo el 29 de octubre de 2004, y como obispo auxiliar oficia José Rico Pavés.

La ciudad de Getafe participa activamente en la iniciativa de hermanamiento de ciudades promovida, entre otras instituciones, por la Unión Europea.






</doc>
<doc id="21782" url="https://es.wikipedia.org/wiki?curid=21782" title="Contenido libre">
Contenido libre

El contenido libre o información libre es un concepto que abarca cualquier obra funcional, de arte u otro contenido creativo, que no posea restricciones legales significativas en relación con el derecho de uso, la redistribución y la creación de versiones modificadas o derivadas por parte de terceros.

El contenido libre abarca todas las obras del dominio público y aquellas que tienen derecho de autor pero que están sujetas a una licencia que otorga y protege las libertades mencionadas. Dado que por omisión la ley otorga a los propietarios de derechos un control total sobre sus creaciones (todos los derechos reservados) es necesario declarar de forma explícita que una obra es libre, generalmente por medio de la referencia o inclusión de cláusulas de licencia que acompañen la obra.

Sin embargo, si los derechos de autor han expirado una obra que esté en el dominio público puede en ciertos casos dejar nuevamente de ser libre, y por consecuencia las obras derivadas también dejarán de serlo, si la ley de derechos cambia.

La cultura libre es una corriente de pensamiento que promueve la libertad en la distribución y modificación de trabajos creativos basándose en el principio del contenido libre para distribuir o modificar trabajos y obras creativas, usando Internet así como otros medios. La cultura libre está conformada por cuatro diferentes tipos de corrientes o pensamientos: El dominio público, el copyleft, las licencias Creative Commons y las licencias de programas libres (software libre). Las obras en dominio público pueden utilizar también formatos libres.

Desde hace más de 100 milenios la humanidad ha vivido en libertad y ha dejado plasmadas muchas obras culturales las cuales han carecido de derechos de autor, por lo que han podido ser estudiadas y copiadas o reproducidas por cualquier otra persona. 

Desde hace tres siglos se creó el derecho de autor o la propiedad intelectual la cual da derechos a un autor sobre las obras que ha creado. Una obra en dominio público también puede ser aquella cuyo autor ha abandonado y que no puede ya afirmar control sobre la distribución y uso de la obra. De esta manera, cualquier otra persona puede manipular, distribuir y utilizar el trabajo sin consecuencias legales. Un trabajo liberado al dominio público por su autor es material libre.

Creative Commons es un grupo de licencias que permiten compartir trabajos en forma abierta o gratuita bajo varias condiciones. Su sitio web fue creado por Lawrence Lessig, en él se puede encontrar un listado de licencias que nos permiten compartir bajo varias condiciones, y también nos ofrece una búsqueda en línea de varios proyectos de Creative Commons.

Desde los inicios de la humanidad la cultura ha sido libre, fue hasta hace tres siglos cuando se inició el concepto de derechos de autor. Tradicionalmente, el derecho o los derechos de autor (en inglés "copyright", traducido literalmente como «derecho de copia») es un concepto legal que otorga al autor o creador de una obra los derechos legales para controlar la distribución y exhibición de su trabajo. 

El derecho de autor suele tener una vigencia limitada dependiendo del país de publicación, la cual oscila entre 5 y 7 décadas. un período de tiempo después del cual el trabajo ingresa al dominio público. Durante la vigencia de los derechos, las obras sólo pueden ser distribuidas, exhibidas o modificadas con el permiso del autor, generalmente a través de una licencia o permiso. 

La mayoría de obras publicadas antes de 1940 se encuentran hoy en día bajo el dominio público. Muchos autores de obras de finales del siglo XX y principios del siglo XXI han decidido publicar sus obras en dominio público o con licencias copyleft o Creative Commons en lugar de publicarlas con derechos reservados.

La cultura libre y las obras bajo licencias Creative Commons se oponen a las medidas restrictivas de las leyes de derechos de autor, que varios miembros del movimiento alegan que también obstaculizan la creatividad. Los usos tradicionales del derecho de autor son restrictivos en varias formas. Limitan la distribución del trabajo a aquellos que pueden o están dispuestos a pagar las regalías al autor por el uso del contenido. Además, crea una barrera perceptual entre los autores, lo que limita las modificaciones del trabajo, como en collages y contenido colaborativo.



</doc>
<doc id="21813" url="https://es.wikipedia.org/wiki?curid=21813" title="Polioxometalato">
Polioxometalato

Los polioxometalatos (abreviado POMs) son agregados inorgánicos de carácter aniónico y están formados principalmente por oxígeno y metales de transición (M) en su estado de oxidación más alto. Los metales más comunes en los polyoxometalatos son Mo y W, aunque también se puden encontrar otros en menor proporción como V, Ti, Zr, etc. A parte de estos metales, otros elementos pueden estar presentes en la estructura, son lo denominados heteroátomos (X) y habitualmente son Al, Si, P o S. Los POMs se pueden describir como fragmentos discretos de óxidos metálicos, de tamaño y forma bien definidos, formados por la reacción de condensación de complejos de coordinación, generalmente octaedros, tetraedros y pirámides de base cuadrada. Estos clústers metálicos tienen un amplio rango de propiedades físicas y químicas, pudiendo actuar como bloques de construcción de nuevos materiales.

El tamaño de los polioxometalatos varía desde los que contienen un número pequeño de centros metálicos, por ejemplo el anión tipo Lindqvist: (MO), hasta los que contienen un gran número de metales como el anión tipo Preyssler: (NaPWO) (ver figura). Existen también polioxomolibdatos gigantes que han sido ampliamente estudiados por el Prof. Achim Müller y colaboradores.

Tienen interés por sus aplicaciones prácticas, por ejemplo:
y como compuestos modelo para estudios de magnetoquímica. Han sido objeto de numerosos estudios teóricos con herramientas de la química cuántica.



</doc>
<doc id="21816" url="https://es.wikipedia.org/wiki?curid=21816" title="Ácido etilendiaminotetraacético">
Ácido etilendiaminotetraacético

El ácido etilendiaminotetraacético, también denominado EDTA o con menor frecuencia AEDT, es una sustancia utilizada como agente quelante que puede crear complejos con un metal que tenga una estructura de coordinación octaédrica. Coordina a metales pesados de forma reversible por cuatro posiciones acetato y dos amino, lo que lo convierte en un ligando hexadentado, y el más importante de los ligandos quelatos.

El EDTA y sus derivados tienen la valiosa propiedad química de combinarse con iones metálicos polivalentes en solución para formar complejos coordinados cíclicos no iónicos, solubles en agua y virtualmente no disociables. A estos complejos se les conoce como quelatos.

EDTA, ácido etilendiaminotetraacético, tiene cuatro carboxilos y dos grupos amino; grupos que pueden actuar como donantes de pares electrones, o bases de Lewis. La capacidad de EDTA para potencialmente donar sus seis pares de electrones para la formación de enlaces covalentes coordinados a cationes metálicos hace al EDTA un ligando hexadentado. Sin embargo, en la práctica EDTA suele estar parcialmente ionizado, y, por tanto, formar menos de seis enlaces covalentes coordinados con cationes metálicos. 

El disodio EDTA se utiliza comúnmente para estandarizar las soluciones acuosas de cationes de metales de transición. Teniendo en cuenta que la forma abreviada de NaHY se puede utilizar para representar a cualquier especie de EDTA, con la designación de x número de protones ácidos enlazados a la molécula de EDTA. 

EDTA forma un complejo octaédrico con la mayoría de cationes metálicos 2+, M, en solución acuosa. La razón principal de que el EDTA se utiliza de manera amplia en la normalización de los cationes metálicos de soluciones es que la constante de formación para la mayoría de complejos cationes metálicos con EDTA es muy alta, lo que significa que el equilibrio de la reacción: 

se encuentra ahora a la derecha. Llevar a cabo la reacción en una solución tampón básico elimina H , cuando este se forma, lo que también favorece la formación de los complejos de EDTA con cationes metálicos como producto de la reacción. Para la mayoría de los propósitos se puede considerar que la formación de los complejos EDTA con cationes metálicos es completa, y esta es la principal razón por el cual el EDTA se utiliza en valoraciones/estandarizaciones de este tipo [1].

El EDTA y sus sales sódicas derivadas se utilizan para precipitar metales pesados tóxicos de manera que puedan ser excretados por la orina. La fijación de plomo, cadmio, níquel por el EDTA, muestra una relación favorable en el cuerpo humano, sin embargo, la unión a cobre, hierro y cobalto no es tan fuerte.

Para ser útil, el EDTA y cualquier otro agente quelante, deben tener un grado determinado de pH para que su actividad fijadora para cada metal sea óptima. EDTA concretamente, actúa en un estrecho margen de pH, dentro del cual se encuentran el pH de la sangre y de los líquidos tisulares de forma que el EDTA puede actuar óptimamente dentro del cuerpo humano.

El EDTA puede ser aplicado intravenosa o tópicamente. Se puede dar oralmente y su absorción en la vía digestiva es buena, aunque se prefiera administrar de forma intraveno en virtud de ser más eficaz para aumentar la tasa de excreción urinaria de los quelatos.

Tras la administración, el fármaco se absorbe y después de 6 horas puede detectarse en orina de un 60 a un 90% de la cantidad administrada. A las 25 horas puede recuperarse hasta un 99%. El resto aparece en las heces.

Los efectos farmacológicos del EDTA resultan de la formación de quelatos con metales divalentes y trivalentes en el cuerpo. En la forma de edetato de calcio disódico se aplica para quelar metales con gran afinidad al quelante más que al calcio iónico.

Es de gran utilidad para quelar el plomo que se encuentra en hueso. En sangre, el fármaco puede encontrarse en plasma y debido a que se excreta por vía urinaria, el paciente debe ser evaluado cuidadosamente y certificar que tiene una función renal adecuada. Se ha detectado un pequeño porcentaje en el fluido espinal.

La principal toxicidad del EDTA es en el riñón. Las dosis repetidas puede causar anomalías en el túbulo contorneado proximal. Cuando se detectan estos efectos, la descontinuación de la terapia favorece la desaparición de los efectos anormales.

Entre los derivados del EDTA se encuentran el ácido hidroxietiletilendiaminotriacético (HEDTA), el ácido dihidroxietiletilendiaminodiacético, el ácido dietilentriaminopentaacético (DTPA), el ácido trietilentetraminohexaacético (TTHA) y el etilendiaminotetraacetato de calcio y disodio (CaNaEDTA). El uso en niños del CaNaEDTA para el tratamiento de la encefalopatía por plomo ha dado buenos resultados.

EL EDTA es muy utilizado para quelación del plomo en la intoxicación por este metal. Regularmente se utiliza en la forma de CaNaEDTA porque el EDTA sódico, cuando se utiliza solo, puede causar tetania por hipocalcemia.

En Odontología, el EDTA se utiliza como ensanchador químico en Endodoncia, ampliamente difundido entre las soluciones utilizadas con mayor frecuencia para la irrigación y aprovechando su propiedad de quelante, capta el Calcio de los tejidos dentarios. También puede ser combinado con Cetrimide para formar EDTAC (se agrega a la composición un bromuro cuaternario amoniado, para reducir la tensión superficial y así favorecer la penetración) logrando remover el barrillo dentinario o smear layer.

En la industria de alimentos tiene utilidad para evitar la reacción de pardeamiento enzimático , ya que este es un potente agente quelante del cobre, sustrato de la Enzíma Polifenoloxidasa (PPO) responsable de la aparición de color en vegetales y frutas. Sin embargo posee mayor efectividad cuando se le utiliza en combinación de ácido ascórbico o ácido cítrico.

También existen aplicaciones en la industria agrícola. Este compuesto está presente en productos agrícolas que contribuyen a la eficacia de herbicidas, insecticidas, entre otros. Se utiliza EDTA en acondicionadores de agua y acidificantes para corregir la dureza del agua o la mezcla.



</doc>
<doc id="21819" url="https://es.wikipedia.org/wiki?curid=21819" title="Sublimación (desambiguación)">
Sublimación (desambiguación)

Sublimación puede referir a los siguientes conceptos:


</doc>
<doc id="21821" url="https://es.wikipedia.org/wiki?curid=21821" title="Código objeto">
Código objeto

En programación, se llama código objeto al código que resulta de la compilación del código fuente. Puede ser en lenguaje máquina o bytecode, y puede distribuirse en varios archivos que corresponden a cada código fuente compilado. Luego un enlazador (linker) se encarga de juntar todos los archivos de código objeto para obtener el programa ejecutable. 
Código objeto: Conjunto de instrucciones y datos escritos en un lenguaje que entiende el ordenador directamente: binario o código máquina. Provienen de la traducción de cierto código fuente, es un fragmento del programa final y es específico de la plataforma de ejecución.

Consiste en lenguaje máquina o bytecode y se distribuye en varios archivos que corresponden a cada código fuente compilado.
Para obtener un programa ejecutable se han de enlazar todos los archivos de código objeto con un programa llamado enlazador ("linker").

Un claro ejemplo de lenguaje de programación que usa código objeto en sus librerías es Pauscal. Esto le permite aumentar la velocidad de compilación de los programas y reducir su tamaño (ya que cada librería objeto puede ser comprimida), también permite a programadores compartir sus librerías y funciones sin tener la necesidad de liberar su código fuente original. Incluso puede permitir a distintos lenguajes de programación compartir funciones sin necesidad de tener que reescribir el código plano a sus respectivas sintaxis.

Los archivos de código objeto pueden ser muy útiles en muchas situaciones y que nos pueden facilitar el trabajo diario, sin embargo consigo traen problemas que pueden generar errores muy difíciles de corregir, por ejemplo cuando un objeto importa funciones de otro archivo de código objeto que ha sido modificado, el intento de la librería o el programa que importó tal librería de ejecutar el código con parámetros incorrectos o inexistentes puede generar un error que generalmente el compilador no detecta, ya que el código objeto no es verificado, únicamente enlazado. Este tipo de error se puede solucionar reescribiendo el código de manera correcta y re compilarlo a código objeto.


</doc>
<doc id="21822" url="https://es.wikipedia.org/wiki?curid=21822" title="DJGPP">
DJGPP

DJGPP es un sistema de desarrollo en C/C++ de 32 bits para ordenadores 386 y compatibles que se ejecuta en MS-DOS. Fue desarrollado por D.J. Delorie, quien inició el proyecto en 1989 y es una migración del conocido compilador gcc para la interfaz en modo protegido MS-DOS (DPMI).



</doc>
<doc id="21824" url="https://es.wikipedia.org/wiki?curid=21824" title="Puntero (desambiguación)">
Puntero (desambiguación)

Puntero tiene diferentes acepciones según el contexto:


</doc>
<doc id="21825" url="https://es.wikipedia.org/wiki?curid=21825" title="Cafeína">
Cafeína

La cafeína es un alcaloide del grupo de las xantinas, sólido cristalino, blanco y de sabor amargo, que actúa como una droga psicoactiva, levemente disociativa y estimulante por su acción antagonista no selectiva de los receptores de adenosina. La cafeína fue descubierta en 1819 por el químico alemán Friedlieb Ferdinand Runge: fue él quien acuñó el término "Kaffein", un compuesto químico presente en el café, término que pasaría posteriormente al español como cafeína. La cafeína recibe también otros nombres (guaranina, teína, mateína) relativos a las plantas de donde se puede extraer y porque contiene otras sustancias que aparecen en esos casos. La denominada guaranina del guaraná, y la teína del té, son en realidad la misma molécula de cafeína, hecho que se ha confirmado en análisis de laboratorio. Estas plantas contienen algunos alcaloides adicionales como los estimulantes cardíacos teofilina y teobromina y a menudo otros compuestos químicos como polifenoles, que pueden formar complejos insolubles con la cafeína.

Es consumida por los humanos principalmente en infusiones extraídas del fruto de la planta del café y de las hojas del arbusto del té, así como también en varias bebidas y alimentos que contienen productos derivados de la nuez de cola. Otras fuentes incluyen la yerba mate, el fruto de la Guaraná y el acebo de Yaupón.

En los humanos, la cafeína es un estimulante del sistema nervioso central que produce un efecto temporal de restauración del nivel de alerta y eliminación de la somnolencia. Las bebidas que contienen cafeína, tales como el café, el té, algunas bebidas no alcohólicas (especialmente los refrescos de cola) y las bebidas energéticas gozan una gran popularidad. La cafeína es la sustancia psicoactiva más ampliamente consumida en el mundo. En Norteamérica, el 90 % de los adultos consumen cafeína todos los días. En los Estados Unidos, la Food and Drug Administration (Administración de Drogas y Alimentos) se refiere a la cafeína como una "sustancia alimentaria Generalmente Reconocida Como Segura (Generally Recognized As Safe) utilizada para múltiples propósitos".

La cafeína tiene propiedades diuréticas, si se administra en dosis suficientes a individuos que no tienen tolerancia a ella. Los consumidores regulares, sin embargo, desarrollan una fuerte tolerancia a este efecto, y los estudios generalmente no han podido demostrar la creencia general de que el consumo regular de bebidas cafeinadas contribuye significativamente a la deshidratación.

La cafeína se encuentra en muchas especies de plantas, donde actúa como pesticida natural. Según ciertos estudios, los altos niveles de cafeína presentes en plantas jóvenes que aún están desarrollando follaje pero carecen de protección mecánica logran paralizar y matar ciertos insectos que se alimentan de la planta. Se han encontrado también altos niveles de cafeína en los suelos alrededor de los vástagos en los granos de café germinados. Se deduce de ello que la cafeína tiene una función natural no sólo como pesticida natural sino también en calidad de sustancia inhibidora de la germinación de otros granos cercanos de café dando por lo tanto mejor oportunidad de supervivencia a las plantas en crecimiento.

Las fuentes de cafeína más comúnmente usadas son el café, el té y en menor medida el cacao. Otras fuentes de cafeína usadas con menor frecuencia incluyen las plantas de yerba mate y guaraná, las cuales a veces son utilizadas en la preparación de infusiones y bebidas energéticas. Dos de los nombres alternativos de la cafeína, mateína y guaranina, son derivados de los nombres de estas plantas. Algunos entusiastas de la yerba mate afirman que la mateína es en realidad un estereoisómero de la cafeína, por lo que sería una sustancia completamente distinta. Esto no es cierto puesto que la cafeína es una molécula no quiral y por lo tanto no tiene enantiómeros, ni tampoco tiene otros estereoisómeros. La disparidad en la experiencia y los efectos entre las variadas fuentes naturales de cafeína podría deberse al hecho de que las plantas que son fuente de cafeína también contienen mezclas ampliamente variables de otros alcaloides xantínicos, incluyendo los estimulandes cardíacos teofilina y teobromina, así como otras sustancias que junto a la cafeína pueden formar complejos insolubles, como los polifenoles.

Una de las fuentes primarias de cafeína en todo el mundo es el grano de café (la semilla de la planta de café), del cual se prepara la bebida de café. El contenido de cafeína en el café varía ampliamente dependiendo del tipo de grano de café y el método de preparación usados; incluso los granos que se encuentran en un mismo arbusto pueden presentar variaciones en la concentración. En general, una porción de café varía entre 40 miligramos para un expreso de unos 30 mililitros de la variedad "arábica", hasta cerca de 100 miligramos para una taza (120 mililitros) de café. Generalmente el café tostado tiene menos cafeína que el café claro porque el proceso de tostado reduce el contenido de cafeína del grano. El café de la variedad "arábica" normalmente contiene menos cafeína que el de la variedad "robusta". El café también contiene cantidades traza de teofilina, pero no de teobromina.

El té es otra fuente común de cafeína. A pesar de que el té contiene más cafeína que el café, una porción típica contiene una cantidad mucho menor, puesto que el té se prepara normalmente en una infusión mucho más diluida. Además de la mayor o menor concentración de la infusión, las condiciones de crecimiento, las técnicas de procesamiento y otras variables también afectan al contenido de cafeína. Ciertos tipos de té pueden contener más cafeína que otros. El té contiene pequeñas cantidades de teobromina y niveles ligeramente más altos de teofilina que el café. La preparación y otros factores tienen un impacto significativo en el té, y el color es un indicador muy pobre del contenido de cafeína. Algunas variedades como el té verde pálido japonés "gyokuro", por ejemplo, contienen más cafeína que otros más oscuros como el "lapsang souchong", que contiene muy poca.

La cafeína es también un ingrediente común de muchas bebidas no alcohólicas (especialmente bebidas gaseosas), como refrescos de cola originalmente preparados a partir de la nuez de cola. Estas bebidas contienen típicamente entre 10 y 50 miligramos de cafeína por ración. En contraste, las bebidas energéticas pueden contener más de 80 miligramos de cafeína por ración. La cafeína en estas bebidas está presente en los ingredientes usados en ellas, o se añade. El guaraná, un ingrediente primario en las bebidas energéticas, contiene grandes cantidades de cafeína con pequeñas cantidades de teofilina y teobromina junto a un excipiente natural que produce una lenta liberación de estas sustancias.

En los años recientes algunos fabricantes han comenzado a añadir cafeína a productos de higiene como el champú y el jabón, asegurando que la cafeína puede absorberse a través de la piel. La efectividad de tales productos, sin embargo, no ha sido comprobada, y es probable que tengan poco efecto sobre el sistema nervioso central ya que la cafeína no se absorbe con facilidad a través de la piel.

Algunos fabricantes comercializan pastillas de cafeína, aduciendo que la cafeína de calidad farmacéutica favorece la alerta mental. Estos efectos han sido sugeridos por estudios que muestran que el uso de cafeína (ya sea en forma de pastillas o no) origina un descenso en la sensación de fatiga y un aumento en la capacidad de atención. Estas pastillas son comúnmente usadas por estudiantes que se preparan para sus exámenes y por personas que trabajan o conducen durante muchas horas.

En 1819, el químico alemán Friedrich Ferdinand Runge aisló por primera vez una cafeína relativamente pura. Realizó este trabajo a petición de Johann Wolfgang von Goethe. Pierre Joseph Pelletier y Pierre Jean Robiquet la describieron en 1821. M. Oudry aisló la téina del té en 1827, y Gerardus Mulder y Jobst demostraron en 1838, que se trataba de la misma sustancia que la cafeína. La estructura de la cafeína fue elucidada hacia el final del siglo XIX por Hermann Emil Fischer que fue el primero en conseguir su síntesis total. Fischer fue por otra parte premiado con el Premio Nobel de química en 1902 en parte por este trabajo.

El carácter aromático de la cafeína se debe a que los átomos de nitrógeno están prácticamente en un mismo plano (en el orbital de hibridación sp²). Generalmente la cafeína no se produce por síntesis porque está disponible en grandes cantidades como subproducto de la decafeinización.

Se puede sintetizar la cafeína a partir de la dimetilurea y del ácido malónico.

 Muchas culturas tienen leyendas que atribuyen el descubrimiento de tales plantas a personas que habrían vivido muchos miles de años antes, como es el caso del emperador chino Shennong.

Según una leyenda popular china, Shennong habría reinado alrededor del 3000 AC, descubrió accidentalmente que cuando algunas hojas caían en agua hirviendo, el resultado era una bebida aromática y restauradora. Shennong también es mencionado en el Cha Jing de Lu Yu, el famoso primer trabajo monográfico sobre el té. La historia del café ha sido registrada desde el siglo IX. En esa época los granos de café sólo estaban disponibles en el hábitat natural de la planta, Etiopía. Una leyenda popular atribuye su descubrimiento a un criador de cabras llamado Kaldi, el cual aparentemente habría observado que las cabras se tornaban eufóricas y perdían el sueño por las noches después de haber pastado junto a los arbustos de café y, habiendo probado los frutos que las cabras había estado comiendo, experimentó la misma vitalidad. La primera mención literaria del café podría ser una referencia a Bunchum en los trabajos del médico persa del siglo IX Al-Razi. En 1587, Malaye Jaziri compiló un trabajo trazando la historia y las controversias legales del café, titulado "Undat al safwa fi hill al-qahwa". En este trabajo, Jaziri registró que un jeque, Jamal-al-Din al-Dhabhani, muftí de Adén, fue el primero en adoptar el uso del café en 1454, y que en el siglo XV los sufís de Yemen usaban café para mantenerse despiertos durante las oraciones de forma rutinaria.

Cerca del final del sigo XVI, el uso del café fue registrado por un europeo residente en Egipto, y alrededor de este periodo se introduce su uso general en el Oriente próximo. La apreciación del café como bebida en Europa, donde fue conocido inicialmente como «vino árabe», data del siglo XVII. Durante este período se establecieron «casas de café», abriéndose las primeras en Constantinopla y Venecia.

Tras Italia, se extendió por España, y de ahí pasó a Francia. Su apogeo se inicia en el Sitio de Viena, en 1683. Marco d'Aviano, padre capuchino, usó el café abandonado por los turcos en su retirada, hizo una infusión y la mezcló con nata.

El café era considerado una medicina y un afrodisíaco, lo cual le mereció el calificativo de "diabólico" por parte algunos miembros de la Iglesia Católica. Es muy conocida la anécdota (de cuya veracidad hay dudas) que protagonizó Clemente VIII, cuyos consejeros querían prohibir el café definitivamente. El papa, antes de tomar tal decisión, quiso probar la bebida y declaró ""Questa bevanda del diavolo è così buona... che dovremmo cercare di ingannarlo e battezzarlo" (Esta bebida del diablo es tan buena... que deberíamos ver cómo engañarlo y bautizarla)". Tras la aprobación papal, su consumo fue en aumento. Otra versión, indica que el médico personal del papa, Andrea Cesalpino, le recetó café para mitigar los trastornos emocionales que sufría el pontífice (probablemente ansiedad o trastorno bipolar). Cesalpino era también botánico y fue el primero en Europa en describir en detalle la planta del café, incluyendo los efectos de la cafeína.

En Gran Bretaña, las primeras casas de café se abrieron en Londres en 1652, en St Michael’s Alley, Cornhill. Pronto se volvieron populares en toda Europa Oriental, y jugaron un papel significativo en las relaciones sociales durante los siglos XVII y XVIII.

Al parecer, tanto la nuez de cola, como el fruto del café y la hoja de té, tienen orígenes antiguos. Es masticada en varias culturas africanas occidentales, de forma individual o en formación social, para restaurar la vitalidad y aplacar la sensación de hambre. En 1911, la cola se convirtió en el foco de atención de uno de los primeros temores documentados sobre la salud, cuando el gobierno de los Estados Unidos incautó 40 toneles y 20 barriles de sirope de Coca-Cola en Chattanooga, Tennessee, alegando que la cafeína en su bebida era «perjudicial para la salud». El 13 de marzo de 1911, el gobierno inició el caso de "Los Estados Unidos versus cuarenta toneles y 20 barriles de Coca-Cola", esperando forzar a Coca-Cola a que eliminara la cafeína de su fórmula alegando argumentos como que el uso excesivo de Coca-Cola en un colegio de señoritas condujo a «desenfrenos nocturnos, quebrantamiento de las reglas de la escuela y de los modales femeninos, e incluso inmoralidades». A pesar de que el juez falló a favor de Coca-Cola, se introdujeron dos iniciativas de ley en la Cámara de Representantes en 1912 con el fin de enmendar el Acta de Alimentos Puros y Drogas, agregando la cafeína a la lista de sustancias «creadoras de hábito» y «dañinas» que debían listarse en la etiqueta de los productos.

La cafeína es un alcaloide de la familia metilxantinas, cuyos metabolitos incluyen los compuestos teofilina y teobromina, con estructura química similar y similares efectos (aunque de menor intensidad a las mismas dosis). En estado puro es un polvo blanco muy amargo. Fue descubierta en 1819 por Runge y descrita en 1821 por Pelletier y Robiquet.

Su fórmula química es CHNO, su nombre sistemático es 1,3,7-<nowiki>tri</nowiki>metilxantina o 3,7-dihidro-1,3,7-trimetil-1H-purina-2,6-diona y su estructura puede verse en los diagramas incluidos.

Una taza de café contiene de 80 (instantáneo) a 125 (filtrado) mg de cafeína. El café descafeinado, en España, debe contener una cantidad de cafeína no superior al 0,3 %. La cafeína se puede conseguir también en píldoras estimulantes de hasta 800 mg.

El consumo global de cafeína fue estimado en 120 000 toneladas por año, convirtiéndola así en la sustancia psicoactiva más popular. La cafeína es un estimulante metabólico y del sistema nervioso central, y es usada tanto recreacionalmente como médicamente para reducir la fatiga física y restaurar el estado de alerta mental en los casos que exista una inusual debilidad o aletargamiento. La cafeína y otros derivados de metilxantina se usan también en recién nacidos para tratar la apnea y para corregir latidos irregulares. La cafeína activa el sistema nervioso central a niveles más altos, provocando un incremento en la alerta y en la vigilia, un flujo de pensamiento más rápido y claro, un aumento de la atención y una mejora de la coordinación corporal. Luego actúa a nivel de la médula espinal cuando se encuentra en dosis altas. Una vez dentro del cuerpo, posee una química compleja que actúa a través de diferentes mecanismos de acción que se describen más abajo.

El estómago y el intestino delgado absorben la cafeína del café y otras infusiones durante los 45 minutos que siguen a la ingesta para luego ser distribuida a través de todos los tejidos del cuerpo. Su eliminación sigue una cinética de primer orden. La cafeína puede ser ingerida también por vía rectal, como demuestra la prescripción de supositorios de tartrato de ergotamina y cafeína (para el alivio de la migraña), y clorobutanol y cafeína (para el tratamiento de la hiperémesis).

"El café produce un beneficio rápido (Ana Adan, Gemma Prat , 2008)

"El efecto de la cafeína es casi inmediato. Aunque estudios anteriores mostraban que la activación comenzaba a los 30-45 minutos de la ingesta, pero el nuevo estudio demuestra que la mejoría empieza apenas a los 10 minutos. Para la investigadora, “45 minutos es el tiempo necesario para alcanzar la máxima concentración en sangre, pero a los pocos minutos, la mitad de esa concentración está ya en la sangre”."

"Los expertos fijan el tiempo de duración del efecto de la cafeína entre las dos y tres horas, aunque hay algunos autores que lo prolongan hasta cuatro o cinco, dependiendo de la sensibilidad del individuo y el ritmo de metabolización, que varía muchísimo con la edad.""

Referencia bibliográfica:

Ana Adan, Gemma Prat, Marco Fabbri, Miquel Sánchez-Turet. “Early effects of caffeinated and decaffeinated coffee on subjective state and gender differences”. "Progress in Neuro-Psychopharmacology & Biological Psychiatry 32 1698–1703" OCT 2008"."

La vida media de la cafeína —esto es, el tiempo requerido para que el cuerpo elimine la mitad de la cantidad total inicial de cafeína— varía ampliamente entre individuos de acuerdo a ciertos factores como la edad, función hepática, embarazo, algunas drogas concurrentes y el nivel de enzimas en el hígado necesarias para el metabolismo de la cafeína. En adultos sanos, la vida media de la cafeína es de unas 4-9 horas. En mujeres bajo administración de anticonceptivos de vía oral, la vida media es de 5-10 horas., y en mujeres embarazadas la vida media es de aproximadamente de 9-11 horas. La cafeína puede acumularse en individuos con enfermedades hepáticas severas, incrementando su vida media incluso hasta 96 horas. En bebés y niños la vida media puede ser más amplia que en adultos; la vida media en un recién nacido puede ser de hasta 30 horas. Otros factores como el tabaquismo pueden acortar el tiempo de vida media de la cafeína. La fluvoxamina reduce la eliminación de cafeína en un 91,3 %, y prolonga su vida media una 11,4 veces respecto a la normal (esto es de 4,9 horas a 56 horas).

La cafeína es metabolizada en el hígado por el sistema enzimático del Citocromo P450 oxidasa (específicamente, la isoenzima 1A2) en tres productos metabólicos de la dimetilxantina, donde cada uno posee sus propios efectos en el cuerpo, que son:
Cada uno de estos metabolitos es luego metabolizado y excretado en la orina.

El principal modo de acción de la cafeína es como un antagonista de los receptores de adenosina que se encuentran en las células del cerebro.

La cafeína cruza fácilmente la barrera hematoencefálica que separa a los vasos sanguíneos del encéfalo. Una vez en el cerebro, el principal modo de acción es como un antagonista no selectivo del receptor de adenosina. La molécula de cafeína es estructuralmente similar a la adenosina y por lo tanto se une a los receptores de adenosina en la superficie de las células sin activarlos (un mecanismo de acción "antagonista"). Entonces, la cafeína actúa como un inhibidor competitivo.

La adenosina se encuentra en casi cualquier parte del cuerpo, debido a que desempeña un papel fundamental en el metabolismo energético relacionado al ATP, pero en el cerebro, la adenosina desempeña funciones especiales. Existen evidencias que indican que las concentraciones de adenosina cerebral se ven aumentadas por varios tipos de estrés metabólico, entre los cuales citamos: hipoxia e isquemia. La evidencia indica también que la adenosina cerebral actúa protegiendo el cerebro mediante la supresión de la actividad neuronal y también mediante el incremento del flujo sanguíneo a través de los receptores A y A ubicados en el músculo liso vascular. Al contrarrestar a la adenosina, la cafeína reduce el flujo cerebral de reposo en 22 a 30 %. La cafeína también posee un efecto desinhibitorio general sobre la actividad neuronal. De todas formas, no se ha demostrado cómo esos efectos causan un incremento en la vigilia y la alerta.

La adenosina es liberada al cerebro mediante un mecanismo complejo. Hay evidencia que indica que la adenosina funciona como un neurotransmisor liberado en los espacios sinápticos en algunos casos, sin embargo, los incrementos de adenosina relacionada con el estrés, parecerían ser producidos principalmente mediante el metabolismo extracelular del ATP. Ciertamente, la adenosina no es el neurotransmisor primario de ningún grupo de neuronas, pero es liberada junto a otros neurotransmisores por algunos tipos de neuronas. A diferencia de muchos neurotransmisores, al parecer, la adenosina no es almacenada en vesículas que son dependientes del voltaje, por lo cual, la posibilidad de que se dé ese mecanismo no ha sido completamente descartada.
Varias clases de receptores de adenosina han sido descritos, cada una con ubicaciones anatómicas diferentes. Los receptores A están ampliamente distribuidos y actúan inhibiendo la absorción de calcio. Los receptores A están densamente concentrados en los ganglios basales, un área que desempeña un papel crítico en el control del comportamiento, pero también pueden ser encontrados en otras partes del cerebro pero en densidades más bajas. Hay evidencia de que los receptores A interactúan con el sistema dopaminérgico, el cual está involucrado en el estado de vigilia y recompensa. Los receptores A pueden ser hallados también en las paredes arteriales y en las membranas celulares de las células de la sangre.

Más allá de sus efectos de neuroprotección, existen razones para creer que la adenosina puede estar más específicamente involucrada en el control de los ciclos de sueño-vigilia. Robert McCarley y sus colegas opinan que la acumulación de adenosina puede ser una causa primaria de la sensación de sueño que sigue a una prolongada actividad mental, y que los efectos pueden ser mediados tanto por inhibición de las neuronas promotoras de la vigilia mediante los receptores A, y por la activación de las neuronas promotoras del sueño mediadas por efectos indirectos en los receptores A. Estudios recientes han aportado evidencias adicionales sobre la importancia de los receptores A, pero no para los A.
Algunos de los efectos secundarios de la cafeína son probablemente causados por efectos no relacionados con la adenosina. Como otras xantinas metiladas, la cafeína es también un:

Los inhibidores de fosfodiesterasa ejercen su inhibición sobre las enzimas cAMP-fosfodiesterasa (cAMP-PDE), que convierten al AMP cíclico en su forma no cíclica dentro de las células, entonces, de esta manera permiten la producción de AMPc dentro de las células. El AMP cíclico participa en la activación de la proteína quinasa A (PKA) que inician a su vez la fosforilación de enzimas específicas que intervienen en la síntesis de glucosa. Mediante el bloqueo de su degradación, la cafeína intensifica y prolonga los efectos de la epinefrina y las drogas tipo epinefrina como las anfetaminas, metanfetaminas o metilfenidatos. A su vez, las concentraciones altas de AMPc en las células parietales provocan un aumento en la activación de la proteína quinasa A dependiente de AMPc que a su vez incrementa la activación de la bomba de protones, específicamente la H+/K+ ATPasa, teniendo como efecto último, un incremento en la secreción de jugos gástricos ácidos.

El AMP cíclico también incrementa la actividad de la corriente I, que a su vez, incrementa directamente la frecuencia cardíaca. La cafeína es también un análogo estructural de la estricnina y como ella (aunque mucho menos potente) es un antagonista competitivo de los receptores ionotrópicos de glicina.

También los metabolitos de la cafeína contribuyen a sus efectos. La paraxantina es responsable del incremento del proceso de lipolisis, el cual libera glicerol y ácidos grasos al torrente sanguíneo para que sean usados como energía por los músculos. La teobromina es un vasodilatador que aumenta la cantidad de flujo de oxígeno y nutrientes al cerebro y músculos. La teofilina actúa como un relajante del músculo liso que afecta principalmente a los bronquiolos y también actúa como una sustancia cronotrópica e inotrópica incrementando la frecuencia cardíaca y su eficiencia.



Se sugiere un aumento en la educación pública sobre los potenciales problemas de salud asociados al consumo de cafeína, y se recomienda más control de la cafeína en el entorno psiquiátrico. El uso masivo de la utilización de cafeína en pacientes psiquiátricos puede acarrear la exacerbación de la sintomatología de dichos pacientes.

Se observa además interacciones farmacocinéticas y farmacodinámicas entre altas dosis de cafeína y fármacos antipsicóticos. Varios psicofármacos interaccionan con la cafeína in vitro formando precipitados insolubles, pudiendo ocurrir in vivo y evitando la absorción tanto de la cafeína como de los antipsicóticos y probablemente aumentando los síntomas psicóticos al ser menor la dosis de medicamento absorbida que la prescrita.

También se cita antagonismo competitivo entre la cafeína y algunas benzodiacepinas como es el diazepam en áreas de ligación del sistema nervioso central. Sugieren que la cafeína bloquea in vivo dichas áreas para las benzodiacepinas con altas dosis, dando consigo una inversión de los efectos tranquilizantes del diazepam provocando ansiedad en vez de efecto ansiolítico. Así como el uso de cafeína con los sedantes hipnóticos antagonizando su acción.

El consumo en cantidades muy grandes puede provocar una intoxicación. Sus síntomas son: insomnio, nerviosismo, excitación, cara rojiza, aumento de la diuresis y problemas gastrointestinales. En algunas personas los síntomas aparecen cuando se consumen cantidades muy pequeñas, del orden de 250 mg por día. Más allá de un gramo al día puede producir contracciones musculares involuntarias conocidas como fasciculaciones, desvaríos, arritmia cardíaca, y agitaciones psicomotrices. Los síntomas de la intoxicación con cafeína son similares a los del pánico y de ansiedad generalizada, con efectos propios de drogas disociativas como la despersonalización. La LD estimada de la cafeína es de 10 g, cuyo equivalente es de un promedio de 100 tazas de café.

Diversas publicaciones científicas y entidades regulatorias, como la European Food Safety Authority (EFSA), advierten de que el consumo creciente de bebidas y otros productos, con concentraciones considerables de cafeína tanto en el deporte como en otros ámbitos, puede tener efectos negativos sobre la salud, en particular entre niños y jóvenes.

En niños sanos, la cafeína produce efectos modestos e inocuos. La Asociación Canadiense de Salud recomienda que a niños menores de 12 años, no se les suministre más de 2,5 miligramos de cafeína por kilogramo de peso corporal.

Estudios recientes, muestran que la cafeína puede usarse para tratar niños con déficit de atención. La investigación encontró que 200-300 mg de cafeína producen un efecto similar que el ritalin, sin sus efectos secundarios.

La cafeína fue estudiada por su posible beneficio en actividades deportivas que requieren capacidad de resistencia. Los primeros estudios demostraron la existencia de mejoras notables en la resistencia de los ciclistas al compararlas con las obtenidas cuando se consumía una bebida placebo.

Según un estudio realizado en 2011 por un equipo de la Facultad de Ingeniería de la UNICEN, es posible afirmar que la "mateína" no existe como tal. Este equipo llegó a la conclusión de que el estimulante natural presente en la yerba mate es en realidad cafeína.





</doc>
<doc id="21838" url="https://es.wikipedia.org/wiki?curid=21838" title="Amina">
Amina

Las aminas son compuestos químicos orgánicos que se consideran como derivados del amoníaco y resultan de la sustitución de uno o varios de los hidrógenos de la molécula de amoníaco por otros sustituyentes o radicales. Según se sustituyan uno, dos o tres hidrógenos, las aminas son primarias, secundarias o terciarias, respectivamente.


Las aminas son simples cuando los grupos alquilo son iguales y mixtas si estos son diferentes.

Las aminas son compuestos muy polares. Las aminas primarias y secundarias pueden formar puentes de hidrógeno. Las aminas terciarias puras no pueden formar puentes de hidrógeno, sin embargo pueden aceptar enlaces de hidrógeno con moléculas que tengan enlaces O-H o N-H.
Como el nitrógeno es menos electronegativo que el oxígeno, el enlace N-H es menos polar que el enlace O-H. Por lo tanto, las aminas forman puentes de hidrógeno más débiles que los alcoholes de pesos moleculares semejantes.

Las aminas primarias y secundarias tienen puntos de ebullición menores que los de los alcoholes, pero mayores que los de los éteres de peso molecular semejante. Las aminas terciarias, sin puentes de hidrógeno, tienen puntos de ebullición más bajos que las aminas primarias y secundarias de pesos moleculares semejantes.

Las aminas se clasifican de acuerdo con el número de átomos de hidrógeno del amoniaco que se sustituyen por grupos orgánicos. Las que tienen un solo grupo se llaman aminas primarias, las que tienen dos se llaman aminas secundarias y las que tienen tres, aminas terciarias.

Las aminas sencillas se nombran enumerando los grupos que sustituyen a los átomos de hidrógeno del amoniaco y terminando con amina. Si hay varios grupos o radicales sustituyentes iguales se usan los prefijos di o tri. Cuando se trata de grupos diferentes estos se nombran por orden alfabético (etil antes que metil, o butil antes que propil, prescindiendo del tamaño) y terminando con la terminación amina. 

Ejemplos: 

1.1. Se identifica la cadena principal que tenga el grupo amino y se enumera por el carbono al cual se encuentra unido el grupo amino. Si existen dos o más grupos amino se nombran desde el extremo que dé lugar a los menores prefijos localizadores (posición) de los sustituyentes y se nombran en orden alfabético con la palabra amina.
el compuesto número 3 se llama 3-etil-6-metil-1,8-octanodiamina

1.2. Cuando hay radicales complejos (que no sean radicales alquilo) sustituyendo al hidrógeno del grupo amino, se utiliza la letra N (mayúscula) por cada sustituyente y se procede a nombrar al compuesto.

1.3. Si el grupo amino se encuentra como sustituyente junto a otro grupo funcional más importante y en el caso de existir varios en una cadena se utiliza los prefijos como (amino, metilamino, aminometil). El grupo amino debe quedar en la menor posición.

1.4. Cuando varios átomos de nitrógeno formen parte de la cadena principal se enumera normalmente viendo que su posición sea la más baja posible y nombra con el vocablo "aza"


</doc>
<doc id="21839" url="https://es.wikipedia.org/wiki?curid=21839" title="Solitaire">
Solitaire

Solitaire ("juego del solitario" en inglés) es un algoritmo de cifrado fuerte inventado por Bruce Schneier para la novela "Criptonomicón" de Neal Stephenson y que para su aplicación requiere únicamente de una baraja inglesa. 




</doc>
<doc id="21845" url="https://es.wikipedia.org/wiki?curid=21845" title="Manila">
Manila

Manila (en inglés: ; en tagalo: "Maynila" ; en pampango: "Menila"; en zambal: "Ibali") es la capital de las Filipinas y la segunda ciudad del país por número de habitantes.

La ciudad está situada en la costa oriental de la bahía de Manila, en la isla de Luzón, junto a la desembocadura del río Pásig; la ciudad limita al norte con las ciudades de Navotas y Caloocan; al nordeste con Ciudad Quezón; al este con San Juan y Mandaluyong; al sudeste con Makati y al sur con Pasay.

Manila tiene una población total de 1 652 171 de acuerdo con el censo de 2013, siendo la segunda ciudad más poblada del país después de la cercana Ciudad Quezón. La población habita un área de apenas , lo que hace a Manila una de las ciudades más densamente pobladas del mundo.
El Gran Manila es el área metropolitana más poblada de toda Filipinas y la , con una población estimada en 20,5 millones.

La ciudad se divide en seis distritos legislativos y consiste en dieciséis distritos geográficos: Binondo, Ermita, Intramuros, Malate, Paco, Pandacán, Port Area, Quiapo, Sampaloc, San Andrés, San Miguel, San Nicolás, Santa Ana, Santa Cruz, Santa Mesa y Tondo. El comercio más activo y algunos de los lugares más históricos y emblemáticos de gran importancia cultural en el país, como la sede del Ejecutivo filipino y la Suprema Corte de las Filipinas, se encuentran en esta ciudad. Manila es sede de varias instituciones científicas y educativas, numerosas instalaciones deportivas, así como de un amplio elenco de entidades culturales del país y otros lugares cultural e históricamente significativos.

El primer relato escrito acerca de la ciudad es la Inscripción de la Laguna Copperplate, que data del siglo X. La ciudad fue invadida por Bolkiah, sultán de Brunéi, y fue cristianizada ya en el siglo XVI, cuando los exploradores españoles llegaron por primera vez. Fue incorporada el 24 de junio de 1571 por el conquistador español Miguel López de Legazpi. Manila se convirtió finalmente en el centro de las actividades españolas en el Lejano Oriente y destino de la ruta comercial del Galeón de Acapulco a Manila, el cual conectaba a la América Española con Asia. La ciudad recibió el apodo de la "Perla de Oriente", como resultado de su ubicación central en las vitales rutas del comercio marítimo por el Pacífico. Varias insurrecciones chinas, revueltas locales, una ocupación británica y un motín cipayo se produjeron tiempo después de eso. Manila también vio el surgimiento de la Revolución filipina, que fue seguida por la ocupación estadounidense, contribuyendo a la planificación urbana de la ciudad y al desarrollo sólo para que la mayoría de dichas mejoras se perdiera por la devastación de la Segunda Guerra Mundial. Después de esto, la ciudad ha sido reconstruida.

Su nombre original "Maynila" proviene de la frase en tagalo "May nilad" que significa ""(donde) hay nílad"". El nílad ("nila" en tagalo moderno) es un arbusto que crece en la zona. 

El gentilicio es "manileño".

La ciudad de Manila se divide en dieciséis distritos administrativos oficialmente definidos, que agrupan 897 barangays, conocidos por números secuenciales en vez de nombres.
Estos distritos sólo existen a los efectos administrativos y carecen de cargos electos. Cada distrito se divide geográficamente en "zonas", oficialmente definidas, que son grupos de dos o más barangays.

Además de la división de los dieciséis distritos geográficos, la ciudad se divide en los seis distritos legislativos que sirven como distritos electorales para la elección de los representantes de la ciudad a la Cámara Baja del Congreso de Filipinas y de los miembros regulares de la "Sangguniang Panlungsod" (SP, Ayuntamiento). Cada distrito elige a un representante y seis miembros de SP al Consejo o concejales. La ciudad, junto con el resto de la nación, elige a 12 senadores como un distrito en general.

En la ribera meridional del río Pásig se encuentra la ciudad originaria, Intramuros, fundada en 1571 y que, a pesar de la despiadada destrucción llevada a cabo por los estadounidenses y los japoneses durante la Segunda Guerra Mundial, contiene aún notables ejemplos de la arquitectura española del siglo XVII, junto a una muralla que la rodea y que se comenzó a construir en 1590, gobernando Filipinas Gómez Pérez das Mariñas.

Manila, antes de la llegada de los españoles, era un enclave musulmán en el que ya se desarrollaba un floreciente comercio con China y otros puntos de Asia Oriental. En 1570, tras haber sido obligado a retirarse de Cebú por piratas portugueses, Miguel López de Legazpi, sabiendo de una próspera ciudad musulmana en Luzón, decidió hacerla su capital. Así que envió a su lugarteniente, Martín de Goiti, para que localizara el sultanato y averiguara su potencial económico. Goiti ancló su flota en Cavite e intentó implantar la autoridad de la corona española por medios pacíficos, enviando un mensaje de amistad al Rajá Soleymán. Este le contestó, intentando ganar tiempo para concentrar sus fuerzas y aniquilar a los españoles, que quería establecer lazos amigables con los españoles, pero que no se sometía como súbdito del rey. Los conquistadores entendieron esta respuesta como un acto de guerra y tras demandar refuerzos, se atacó a los musulmanes en junio de 1570. Después de conquistar la ciudad, Goiti volvió a Panay, donde se encontraba el gobernador. Finalmente, Legazpi volvió con sus tropas en 1571. Los islámicos prendieron fuego a la ciudad y la abandonaron, instalándose en Tondo y otros pueblos vecinos. El 9 de junio de 1571 comenzó la construcción del fuerte.

Solimán, el rajá destronado, tras intentar sin éxito el apoyo del rajá de Tondo, llamado Lacandula, y de los pampangueños y pangasineños, reunió un fuerte contingente de nativos tagalos. Atacó entonces a los españoles, quienes nuevamente lo derrotaron, muriendo en el intento en la batalla de Bangcusay. Después de la revuelta comenzó la labor evangelizadora. Manila se constituiría en capital de la evangelización católica del Sudeste asiático. Primero llegaron los agustinos, seguidos de franciscanos, dominicos, jesuitas y agustinos recoletos. Los españoles decretaron el monopolio comercial, tal como acostumbraban a hacer las naciones coloniales de entonces. Los chinos se vieron perjudicados por estas medidas y se produjeron disturbios, rápidamente controlados. Como castigo, los chinos fueron sometidos a nuevos y fuertes tributos.

Ya en 1574, el pirata chino Li Ma Hong, al frente de una flota con 62 naves que transportaba 3.000 hombres, intentó sin éxito conquistar la ciudad. El gobernador Guido de Lavezares y el maestre de campo Juan de Salcedo, al mando de 500 españoles, expulsaron a la flota mercenaria chino-japonesa. Tras el desastre que supuso para los chinos, los españoles, desconfiando de sus hermanos de raza del interior de la ciudad, sabiamente decidieron concentrarlos en el Parian de la Alcaicería.

En 1595 Manila fue designada capital del archipiélago, así como capital de su provincia, que abarcaba casi toda la isla de Luzón.

En 1601 los jesuitas fundaron en Manila un seminario para nobles, que fue la primera institución educativa del país.

Tras la independencia del virreinato de México o Nueva España, a cuya jurisdicción administrativa pertenecían las islas, fue la propia metrópoli la que se encargó directamente de la administración de Manila, reforzándose esta vez el poder administrativo de las órdenes religiosas. La amplia provincia manileña, llamada posteriormente de Corregimiento de Tondo, fue seccionándose y formando otras provincias.
La capital colonial española se vio enriquecida con gran cantidad de monumentos: palacios privados y públicos, amplios conventos, bellos templos. Aquí se erigió la primera universidad de Asia, llamada la Real y Pontificia de Santo Tomás, mucho antes de que existieran las universidades de India o de las colonias inglesas de América. En sus aulas se formaron las primeras generaciones de "ilustrados" (una clase educada de criollos, mestizos y nativos).

Hay una breve etapa de ocupación británica, durante la guerra de los Siete Años. Tras un asedio prolongado, una flota inglesa logró asaltar la ciudad el 5 de octubre de 1762. De 1762 a 1764, los ingleses ocuparon Manila. El saqueo de la ciudad por los ingleses fue espantoso, perdiéndose infinidad de documentos y de obras de arte. El dominio británico terminó al firmarse el Tratado de Paz de París en 1763.

A principio del siglo XIX comenzó a sentirse la influencia de los movimientos independentistas sudamericanos. El 1 de febrero de 1818 arribó el capitán Hipólito Bouchard, corsario de las Provincias Unidas de Sudamérica, a bordo de la fragata La Argentina. Durante dos meses mantuvo bloqueada la bahía de Manila capturando un gran número de pontines e inmovilizando a las fuerzas navales españolas. Además cerró el acceso a la bahía por el este con un bloqueo en el estrecho de San Bernandino.

Las ideas liberales, traídas por los mismos elementos españoles o "peninsulares", fueron rápidamente asimiladas por las clases ilustradas de mestizos y castizos. La masonería, de suyo anticlerical por propiciar el ateísmo, racionalismo y liberalismo en los pueblos, originó los primeros focos de descontento contra las autoridades coloniales y especialmente contra el omnímodo poder del clero regular. Una organización secreta llamada Katipunán, aguerridamente antiespañola, apoyada por elementos masones de la burguesía manileña, provocó algunos alborotos que fueron rápidamente instrumentalizados por la oposición liberal contra el gobernador. El movimiento se extendió por otras zonas de la isla, pero sin alcanzar especial intensidad.

En agosto de 1898, durante la guerra hispano-estadounidense y tras la batalla de Cavite, el ejército de Estados Unidos ocupó y arrasó la ciudad. La escuálida y anticuada flota española había sido ampliamente derrotada en la bahía. Tras la intervención estadounidense, el movimiento independentista tomaría especial fuerza, ayudado por las aportaciones económicas de los estadounidenses.

Sin embargo, los insurgentes contra España no tardarían en sufrir amarga sorpresa al ver que los estadounidenses, que se habían presentado como liberadores, se instituían ahora en nuevos amos coloniales. Buena prueba de ello fue la batalla de Mock, el 13 de agosto de aquel mismo año, en la que los nuevos invasores derrotaron y expulsaron de Manila a las tropas independentistas filipinas. A esto siguió un movimiento de brutal represión, torturas y ejecuciones masivas por parte de los norteamericanos. Hasta el 31 de julio de 1901, los estadounidenses gobernaron militarmente tanto el país como la ciudad, ya capital del "Protectorado," fecha en que el Ayuntamiento fue transferido a un grupo de colaboracionistas pertenecientes a la burguesía manileña.

Tras el ataque a Pearl Harbor por la Marina Imperial Japonesa, que tuvo lugar el 7 de diciembre de 1941, tropas japonesas desembarcaron en Filipinas y tomaron la ciudad de Manila que, bajo la ocupación militar japonesa, se convirtió en la sede de un Gobierno colaboracionista pro-japonés.

Durante la Segunda Guerra Mundial, Manila sufrió una nueva hecatombe por parte de los soldados estadounidenses, quienes queriendo acabar con las tropas japonesas ocupantes no dudaron en bombardear y arrasar la ciudadela colonial de Intramuros, ocasionando de paso un elevadísimo número de víctimas civiles. Por su parte, las fuerzas japonesas se dedicaron a efectuar masacres entre la indefensa población civil de la ciudad.

La ciudad de Manila ocupa una posición única en Filipinas, tanto por ser la capital del país como por ser igualmente la capital de su área metropolitana, compuesta por varias ciudades y trece municipios.

Limita al norte con las ciudades de Navotas y Caloocan, al nordeste con Ciudad Quezón y San Juan del Monte y al sur la ciudad de Pásay. Al oeste de la ciudad se encuentra la maravillosa bahía de Manila.
Situada en la costa oriental de la vasta y profunda bahía homónima, bien protegida por la península de Bataán y cerrada su salida hacia el mar de la China por el islote de Corregidor, se extiende en la desembocadura del Pásig que la divide en dos partes. Al sur se encuentra el antiguo centro español de Intramuros, solar de la ciudad amurallada. En el norte se extienden los modernos barrios residenciales y comerciales. La zona industrial se concentra en la zona del puerto.

Destruida durante la Segunda Guerra Mundial, fue reconstruida bajo criterios urbanísticos estadounidenses. Dejó de ser una elegante ciudad de corte hispánico y europeo para convertirse en una metrópolis con largas calles rectilíneas e insulsos rascacielos, caracterizada por un tráfico caótico y ruidoso. Sus numerosos barrios superan ya los límites provinciales: El de Makati, en torno al parque Forbes, es un centro residencial muy importante. El incremento demográfico ha sido enorme: tenía 100.000 habitantes en 1890, 300.000 en 1920 y 600.000 en vísperas de Segunda Guerra Mundial.

Las iglesias barrocas de San Agustín y de Santo Domingo, con el conjunto conventual anexo, las antiguas fortificaciones españolas y los restos del Fuerte Santiago, además de algunos modernos e interesantes edificios como el Coliseo, son los principales lugares artísticos.

Manila es un importante centro cultural, sede de la Universidad de Santo Tomás y de la Academia Filipina de la Lengua Española. Posee varios museos, así como bibliotecas y un observatorio.

Un relativamente nuevo rumbo se ha tomado con la incorporación de todas las ciudades y municipios que componen el área metropolitana, en una nueva “megaciudad” denominada “Gran Manila”.

La dirige un gobernador que gestiona sus servicios a través de diferentes escalones administrativos.

Gran Manila (llamada Metro Manila) está compuesta por las localidades de Caloocan, Manila, Navotas, Malabón, Valenzuela, Marikina, Pásay, Pásig, Mandaluyong, San Juan, Makati, Ciudad Quezon, Taguig, Parañaque, Las Piñas y Muntinlupa.

De acuerdo con el sistema de clasificación climática de Köppen, Manila presenta un clima tropical de sabana (Köppen: "Aw") que limita con el tropical monzónico (Köppen: "Am"). Justo con el resto de las Filipinas, Manila se encuentra enteramente dentro de los trópicos. Su proximidad al ecuador significa que la oscilación térmica es mínima, rara vez se baja de los 20 °C, o sube de los 38 °C. Sin embargo, los niveles de humedad usualmente están muy elevados lo que hace sentir mayor calor (Varía de un promedio de 71% en marzo a un promedio de 85% en septiembre). Cuenta con una clara aunque relativamente corta estación seca que va desde enero hasta abril, y una estación húmeda relativamente prolongada, impulsada por el monzón, que va desde mayo hasta diciembre.
<noinclude>
Según el censo del 2010, la población de la ciudad era de 1 652 171 habitantes, convirtiéndose en la segunda ciudad más poblada de Filipinas.

Es la ciudad más densamente poblada del mundo, con 43 079 habitantes por km²; siendo el Distrito 6º el más denso con 68 266 habitantes por km². La densidad poblacional de Manila empequeñece a las de Calcuta (27 774 habitantes por km²), Bombay (22 937 habitantes por km²), París (20 164 habitantes por km²), Daca (19 447 habitantes por km²), Shanghái (27 774 habitantes por km²), Bogotá (15 410 habitantes por km²) y Tokio (10 087 habitantes por km²).

La lengua vernácula es el filipino (una lengua criolla basada mayormente en el tagalo hablado en los alrededores de la ciudad), idioma que se ha convertido en la lingua franca del país, habiéndose extendido por todo el archipiélago a través de los medios de comunicación y el entretenimiento. Entretanto, el inglés es el idioma más empleado en la educación, los negocios, y en gran medida en el uso cotidiano en toda la región metropolitana de Manila y en la propia Filipinas. Un número de residentes mayores todavía habla un español básico, ya que era una materia obligatoria en el plan de estudios de las universidades y colegios en Filipinas, así como muchos hijos de europeos, árabes, indios, latinoamericanos u otros inmigrantes o expatriados hablan también las lenguas de sus padres en casa, aparte de inglés y / o filipino para el uso cotidiano. El min nan es hablado por la comunidad sinofilipina.

Luego de la independencia de 1947, hubo un cambio en la política económica de las Filipinas: de promoción de la exportación a la sustitución de la importación. El beneficiario de las políticas de la sustitución de las importaciones fue la región de la capital.

La base industrial de la ciudad se ha incrementado en décadas recientes para incluir productos textiles, publicaciones, e imprentas, comida procesada, y la manufactura de tabaco, pintura, medicina, aceites, jabón y madera.

Manila fue la ciudad sede de los Juegos Asiáticos de 1954.


Manila es sede de varias escuelas y universidades. Entre ellas están:



</doc>
<doc id="21846" url="https://es.wikipedia.org/wiki?curid=21846" title="Plenum">
Plenum

El plénum (del latín "plēnum" «completo, lleno») es un espacio cerrado en donde existen aire u otros gases a bajas velocidades y presiones ligeramente superiores a la atmosférica, como resultado de la acción de un ventilador o soplador mecánico. El diseño de esta cámara tiene como resultado que la presión del gas introducido se reparta de igual manera en toda la superficie interna de éste.

El plénum se utiliza muy frecuentemente en instalaciones de Climatización en los cuales se inyecta aire (pasándose a llamar "plénum de inyección") en donde se reparte aire a todo el interior de dicho volumen, permitiendo que cualquier tipo de salida o arranque desde este espacio se produzcan a una misma presión.

Otra aplicación práctica del plénum es su utilización en los edificios con falso techo en sus plantas. Mediante una inyección de aire exterior en el espacio entre el forjado y el falso techo se consigue una pequeña sobrepresión que evita que el aire caliente que existe en una planta suba hasta dicho espacio y se acumule, provocando con el paso del tiempo una acumulación de aire viciado que da lugar a malos olores, pudiendo incluso generar condensaciones de vapor de agua en algunos lugares cerrados.

Dicha aportación de aire es utilizada por los fancoils situados en el techo falso para proporcionar aire acondicionado a partir del aire existente en dicho espacio.

También se emplea en el cable coaxial.


</doc>
<doc id="21849" url="https://es.wikipedia.org/wiki?curid=21849" title="Traducción automática">
Traducción automática

La traducción automática (TA o MT, esta última del inglés "machine translation") es un área de la lingüística computacional que investiga el uso de software para traducir texto o habla de un lenguaje natural a otro. En un nivel básico, la traducción por computadora realiza una sustitución simple de las palabras atómicas de un lenguaje natural por las de otro. Por medio del uso de corpora lingüísticos se pueden intentar traducciones más complejas, lo que permite un manejo más apropiado de las diferencias en la tipología lingüística, el reconocimiento de frases, la traducción de expresiones idiomáticas y el aislamiento de anomalías.

Hoy en día, algunos software de traducción automática permiten escoger un campo especializado o profesión en el cual se desea realizar la traducción, lo cual ayuda a delimitar el ámbito de términos a sustituir en el idioma de llegada. Esta técnica es efectiva en campos especializados los cuales ya tienen un modo de expresión establecido. Esto hace más fácil la traducción automática de textos jurídicos en comparación de textos menos estandarizados.

Este proceso de traducción también puede ser mejorado gracias a la intervención humana, por ejemplo, algunos sistemas permiten al traductor escoger con anticipación los nombres propios, evitando que estos se traduzcan automáticamente. Con la ayuda de este tipo de técnicas, la traducción automática puede llegar a ser una herramienta de gran utilidad para los traductores, o incluso puede llegar a producir resultados que se puedan usar sin ningún tipo de modificación.

Los sistemas de traducción actuales permiten establecer parámetros (por ejemplo, limitando el rango de sustituciones permitidas) de acuerdo con el dominio o la profesión en la que se hace la traducción, lo que efectivamente mejora el resultado. Esta técnica es particularmente útil en campos donde se emplea un lenguaje formal o basado en formularios, como los reportes del tiempo y los documentos legales o administrativos. Dado que la traducción automática (estadística) es entrenada con grandes volúmenes de texto, existe una correlación entre calidad de traducción y recursos lingüísticos disponibles. La idea de que su uso no es viable para traducción de conversaciones ha sido superada con la llegada de servicios como Skype Translator. IBM Watson ofrece una API de traducción específicamente para el dominio conversacional. Evidentemente, traducir un libro de literatura antigua de un idioma con pocos registros escritos, sería una tarea más difícil. En este caso, un traductor humano especializado será un agente mejor capacitado para realizar la conversión.

En las últimas décadas, ha habido un fuerte impulso en el uso de técnicas estadísticas para el desarrollo de sistemas de traducción automática. Para la aplicación de estas técnicas a un par de lenguas dado, se requiere la disponibilidad de un corpus paralelo para dicho par. Mediante este corpus se estiman parámetros de sendos modelos estadísticos que establecen la probabilidad con la que ciertas palabras son susceptibles de traducirse por otras, así como las posiciones más probables que tienden a ocupar las palabras de la lengua destino en función de las palabras correspondientes de la frase origen. El atractivo de estas técnicas radica en que el desarrollo de un sistema para un par de lenguas dado puede hacerse de manera muy automática, con una muy reducida necesidad de trabajo experto por parte de especialistas en lingüística.

La intervención humana puede mejorar la calidad de la salida: por ejemplo, algunos sistemas pueden traducir con mayor exactitud, si el usuario ha identificado previamente las palabras que corresponden a nombres propios. Con la ayuda de estas técnicas, la traducción por computadora ha mostrado ser un auxiliar útil para los traductores humanos. Sin embargo, y aún cuando en algunos casos pueden producir resultados utilizables «tal cual», los sistemas actuales son incapaces de producir resultados de la misma calidad que un traductor humano, particularmente cuando el texto a traducir usa lenguaje coloquial o familiar. Por otro lado, es un hecho que las traducciones humanas también contienen errores. Como respuesta a esto, recientemente se han visto desarrollos en corrección automática de TA, como el caso de la funcionalidad SmartCheck de la empresa de traducción Unbabel, basada en Machine Learning.

En esta dirección, recientemente están cobrando especial interés las técnicas estadísticas de traducción asistida basadas en una aproximación interactiva-predictiva, en la que el computador y el traductor humano trabajan en estrecha colaboración mutua. Tomando como base el texto fuente a traducir, el sistema ofrece sugerencias sobre posibles traducciones a la lengua destino. Si alguna de estas sugerencias es aceptable, el usuario la selecciona y, en caso contrario, corrige lo necesario hasta obtener un fragmento correcto. A partir de este fragmento, el sistema produce mejores predicciones. El proceso continúa de esta manera hasta obtener una traducción completamente aceptable por el usuario. Según las evaluaciones realizadas con usuarios reales en el proyecto TransType-2, este proceso permite reducir considerablemente el tiempo y esfuerzo necesarios para obtener traducciones de calidad.

La traducción es hoy en día el principal cuello de botella de la sociedad de la información y su mecanización supone un importante avance frente al problema de la avalancha informativa y la necesidad de la comunicación translingüística.

Los primeros desarrollos informáticos reseñables se realizaron en el famoso ordenador Eniac en 1946. Entre los investigadores pioneros hay que citar a Warren Weaver, de la Fundación Rockefeller. Él fue quien dio a conocer públicamente la disciplina anticipando posibles métodos científicos para abordarla: el uso de técnicas criptográficas, la aplicación de los teoremas de Shannon y la utilidad de la estadística, así como la posibilidad de aprovechar la lógica subyacente al lenguaje humano y sus aparentes propiedades universales.

En la actualidad se obtienen altos niveles de calidad para la traducción entre lenguas romances (español, portugués, catalán, gallego y otros). Sin embargo, los resultados empeoran notablemente cuanto más tipológicamente alejadas sean las lenguas entre sí, como es el caso de la traducción entre español e inglés o alemán. Sin embargo, este hecho no es estático, sino dinámico: la tecnología de traducción mejora día a día.

Otro factor muy influyente en la calidad es el grado de especialización de los sistemas de traducción, que mejoran en la medida en que se adecúan al tipo de texto y vocabulario que se vaya a traducir. Un sistema que se especialice en la traducción de partes meteorológicos conseguirá una calidad aceptable incluso para traducir textos entre lenguas tipológicamente muy dispares, pero será inservible para abordar, por ejemplo, crónicas deportivas o financieras. Un sistema de producción que utilice traducción automática también incorporará tecnologías como detección de idioma, detección de dominio o tema y generación automática de vocabularios. 

Traducir tradicionalmente ha sido un arte y un oficio, que requiere talento y dedicación. Una crítica común al cambio de paradigma de traducción consiste en pensar que las computadoras sólo sustituyen una palabra por otra igual de otro idioma. Sin embargo, sistemas de TA en producción son integraciones de diferentes tecnologías lingüísticas que van mucho más allá de traducir palabra por palabra. Un análisis lingüístico de un texto arrojará información sobre morfología (la forma en que se construyen las palabras a partir de pequeñas unidades provistas de significado), sintaxis (la estructura de una frase) y semántica (el significado), lo cual ciertamente es útil para tareas de traducción. También hay que considerar cuestiones de estilo y de discurso o pragmáticas.

En cuanto al tema de la ambigüedad, no todos los humanos la entienden. Es posible que un traductor humano comprenda incorrectamente una frase o palabra ambigua. A favor del enfoque computacional, podemos mencionar el uso de algoritmos de desambiguación que, por ejemplo, utiliza Wikipedia para diferenciar páginas que tienen un título igual o muy similar.

Los mejores resultados de traducción automática provienen de los métodos estadísticos basados en frases, que realizan traducciones sin reparar en cuestiones gramaticales. En la actualidad, la tendencia es a integrar todo tipo de metodologías: lingüísticas, por reglas, con posedición, etcétera, pero el componente principal, como en la mayoría de tecnologías que utilizan grandes cantidades de datos (Big Data), es Aprendizaje Automático (o Machine Learning).

La idea de la traducción automática puede remontarse al siglo XVII. En 1629, René Descartes propuso un lenguaje universal, con las ideas equivalentes en lenguas diferentes que comparten un mismo símbolo.

En la década de 1950, el experimento de Georgetown (1954) consistía en una traducción totalmente automática de más de sesenta oraciones del ruso al inglés. El experimento fue todo un éxito y marcó el comienzo de una era con una importante financiación para la investigación de tecnologías que permitiesen la traducción automática. Los autores afirmaban que, en un plazo de tres a cinco años, la traducción automática sería un problema resuelto.

El mundo salía de una guerra mundial que en el plano científico había incentivado el desarrollo de métodos computacionales para descifrar mensajes en clave. A Weaver se le atribuye haber dicho: "Cuando veo un artículo escrito en ruso, me digo: "Esto en realidad está en inglés, aunque codificado con símbolos extraños. ¡Vamos a decodificarlo ahora mismo!"" (citado por Barr y Feigenbaum, 1981). No hace falta decir que tanto los ordenadores como las técnicas de programación de aquellos años eran muy rudimentarias (se programaba mediante el cableado de tableros en lenguaje máquina), por lo que las posibilidades reales de probar los métodos eran mínimas.

El progreso real fue mucho más lento. El financiamiento para las investigaciones se redujo considerablemente tras el informe de ALPAC (1966), a causa de que encontró que la investigación que había durado diez años no había cumplido sus expectativas. A partir de los finales de la década de 1980, el poder de la computación aumentó la potencia de cálculo y la hizo menos costosa, y fue demostrado mayor interés en modelos estadísticos para la traducción automática.

La idea de utilizar las computadoras digitales para la traducción de las lenguas naturales ya se propuso en 1946 por A. D. Booth y posiblemente también otros. El experimento de Georgetown no fue de ninguna manera la primera de estas aplicaciones. Se efectuó una demostración en 1954 con el equipo APEXC en el Birkbeck College (Universidad de Londres) de una traducción rudimentaria del inglés al francés. En ese momento, se publicaron varios trabajos de investigación sobre el tema, e incluso artículos en revistas populares (véase, por ejemplo, "Wireless World", septiembre de 1955, Cleave y Zacharov). Una aplicación similar, también pionera en la Birkbeck College de aquel entonces, fue la lectura y la composición de textos en braille por la computadora.

Un referente obligado para conocer con más detalle la evolución de la traducción automática es el académico británico John Hutchins, cuya bibliografía puede consultarse libremente en Internet. En el artículo principal se sigue el esquema simplificado de Jhonatan Slocum, que aborda la historia de la traducción automática por décadas.

Si disponen de suficiente información, las traducciones automáticas pueden funcionar bastante bien, permitiendo que personas con una lengua materna determinada sean capaces de hacerse una idea de lo que ha escrito otra persona en su idioma. El problema principal reside en obtener la información adecuada para cada uno de los métodos de traducción.

Según su aproximación, los sistemas de traducción automática se pueden clasificar entre dos grandes grupos: los que se basan en reglas lingüísticas por una parte, y los que utilizan corpus textuales por otra.

La traducción automática mediante reglas consiste en realizar transformaciones a partir del original, reemplazando las palabras por su equivalente más apropiado. Al conjunto de este tipo de transformaciones del texto original se le llama preedición de textos.

Por ejemplo, algunas reglas comunes para el inglés son:

En general, en una primera fase se analizará un texto, creando habitualmente una representación simbólica interna. Dependiendo de la abstracción de esta representación, también es posible encontrar diferentes grados: desde los directos, que básicamente hacen traducciones palabra por palabra, hasta interlingua, que utiliza una representación intermedia completa.

En la traducción por transferencia, el análisis del original juega un papel más importante, y da paso a una representación interna que es la que se utiliza como "enlace" para traducir entre idiomas distintos.

La traducción automática a partir de un lenguaje intermedio es un caso particular de la traducción automática basada en reglas. El lenguaje original, por ejemplo un texto que debe ser traducido, es transformado a un lenguaje intermedio, cuya estructura es independiente a la del lenguaje original y a la del lenguaje final. El texto en el lenguaje final se obtiene a partir de la representación del texto en el lenguaje intermedio. En general a esta lengua intermedia se la llama "interlingua".

La traducción automática a partir de un "corpus" lingüístico se basa en el análisis de muestras reales con sus respectivas traducciones. Entre los mecanismos que utilizan "corpus" se incluyen los métodos estadísticos y los basados en ejemplos.

El objetivo de la traducción automática estadística es generar traducciones a partir de métodos estadísticos basados en corpus de textos bilingües, como por ejemplo las actas del parlamento europeo, que se encuentran traducidas en todos los idiomas oficiales de la UE. A medida que se generan y se analizan corpus de textos multilingües, se mejoran iterativamente los resultados al traducir textos de ámbitos similares.

El primer programa de traducción automática estadística fue Candide, desarrollado por IBM. Google utilizó los servicios de SYSTRAN durante algunos años, pero desde octubre de 2007 utiliza su propia tecnología de traducción automática basada en estadística. En el 2005, Google mejoró las capacidades de traducción al analizar 200 mil millones de palabras de documentos de las Naciones Unidas.

El progreso de la traducción automática no es un fenómeno aislado. Las tecnologías de información en su conjunto presentan un progreso exponencial, gracias en buena parte a disciplinas como Machine Learning, inteligencia artificial, estadística que, nutridos de Big Data y Big Language, han dado resultados asombrosos en el reconocimiento del lenguaje, en la síntesis de texto a voz y en la traducción de voz en tiempo real.

La traducción automática basada en ejemplos se caracteriza por el uso de un corpus bilingüe como principal fuente de conocimiento en tiempo real. Es esencialmente una traducción por analogía y puede ser interpretada como una implementación del razonamiento por casos base empleado en el aprendizaje automático, que consiste en la resolución de un problema basándose en la solución de problemas similares.

La traducción automática basada en el contexto utiliza técnicas basadas en hallar la mejor traducción para una palabra fijándose en el resto de palabras que la rodean, básicamente este método se basa en tratar el texto en unidades de entre 4 y 8 palabras, de manera que se traduce cada una de ellas por su traducción al idioma destino, y se eliminan las traducciones que han generado una "frase" sin sentido. Luego, se mueve la ventana una posición (palabra), retraduciendo la mayoría de ellas de nuevo y volviendo a filtrar dejando sólo las frases coherentes. Se repite dicho paso para todo el texto. Y luego se pasa a concatenar los resultados de dichas ventanas de manera que se logre una única traducción del texto.

El filtrado que se realiza donde se decide si es una frase con sentido utiliza un corpus del lenguaje destino, donde se cuentan el número de apariciones de la frase buscada.

Se trata, por tanto, de un método basado en ideas bastante simples que ofrecen muy buenos resultados en comparación a otros métodos.

Como ventajas, aporta también la facilidad de añadir nuevas lenguas, ya que sólo se necesita:


La investigación en España ha pasado a través de tres etapas importantes. Desde 1985, se inicia la investigación con un interés repentino en España. Después de un año a su entrada a la Comunidad Europea. Fueron tres compañías transnacionales quienes financiaron la creación de varios grupos de investigación. IBM, Siemens y Fujitsu. Paradójicamente, 1992, que era el año de la celebración del 5.º centenario del descubrimiento de América y de los juegos olímpicos también se llevaban a cabo en Barcelona. Primero IBM y luego Siemens, formaron en 1985 grupos de I+D en sus laboratorios de Madrid y Barcelona, liderados por Luis de Sopeña y Montserrat Meya, respectivamente. IBM utilizó el Centro de Investigación en inteligencia artificial de la Universidad Autónoma de Madrid como sede de un equipo especializado en lenguaje natural. Este equipo tomó parte primero en el diseño del prototipo Mentor, junto con otro centro IBM de Israel, y más tarde en la adaptación al espańol de LMT, sistema diseñado en el T.J. Watson Research Center de Estados Unidos. A tenor de las publicaciones del grupo en la revista Procesamiento del lenguaje natural, entre los años 1985 y 1992 trabajaron en los proyectos de IBM al menos los siguientes especialistas: Teo Redondo, Pilar Rodríguez, Isabel Zapata, Celia Villar, Alfonso Alcalá, Carmen Valladares, Enrique Torrejón, Begoña Carranza, Gerardo Arrarte y Chelo Rodríguez.

Por su parte, Siemens decidió acercar a Barcelona el desarrollo del módulo español de su prestigioso sistema Metal. Montserrat Meya, que hasta entonces había trabajado en los laboratorios centrales de Siemens en Múnich, contactó con el filólogo e ingeniero Juan Alberto Alonso, y juntos formaron el núcleo de un equipo en el que luego participaría una interminable lista de colaboradores: Xavier Gómez Guinovart, Juan Bosco Camón, Begoña Navarrete, Ramón Fanlo, Clair Corbishley, Begońa Vázquez, etc. Después de 1992 el grupo dedicado a proyectos lingüísticos se constituyó en empresa independiente, Incyta. Tras un convenio con la Generalidad de Cataluña y la Universidad Autónoma de Barcelona, se desarrolló el módulo catalán, que es ahora su principal línea de actividad.

A finales de 1986 se crearon en Barcelona y Madrid dos nuevos grupos entre quienes se repartió el desarrollo de los módulos del sistema EUROTRA, financiado por la Comisión Europea. Ramón Cerdá reunió en la Universidad de Barcelona a un nutrido grupo de especialistas, integrado por, entre otros, Jesús Vidal, Juan Carlos Ruiz, Toni Badia, Sergi Balari, Marta Carulla y Nuria Bel. Mientras este grupo se ocupaba de las cuestiones de sintaxis y semántica, otro grupo se encargaba en Madrid de los aspectos de morfología y lexicografía, liderados por Francisco Marcos Marín. Colaboraban con él, entre otros, Antonio Moreno, Pilar Salamanca y Fernando Sánchez-León.

Un año más tarde, en 1987, se formó en los laboratorios de I+D de la empresa Fujitsu en Barcelona un quinto grupo para el desarrollo de los módulos de traducción al español del sistema japonés Atlas. Este grupo estaba liderado por el ingeniero Jorge Vivaldi y los filólogos José Soler, procedente de Eurotra, y Joseba Abaitua. Juntos crearán el embrión de un equipo al que más adelante se incorporaron Elisabet Cayuelas, Lluis Hernández, Xavier Lloré y Ana de Aguilar-Amat. La empresa interrumpió esta línea de investigación en 1992.

Otro grupo dedicado a la traducción automática por aquellos años fue el formado por Isabel Herrero y Elisabeth Nebot en la Universidad de Barcelona. Este grupo, tutelado por Juan Alberto Alonso, creó un prototipo de traducción árabe - español en colaboración con la Universidad de Túnez.

Está claro que la traducción automática fue el principal catalizador del nacimiento de la lingüística computacional en Espańa. No es casualidad que la Sociedad Española para el Procesamiento del Lenguaje Natural (SEPLN) se constituyera en 1983. Junto a Felisa Verdejo, otras dos personas se destacaron en su fundación, los citados Montserrat Meya y Luis de Sopeña, quienes por aquel entonces lideraban, como se ha dicho, grupos de traducción automática. El tercer congreso de la asociación (entonces todavía bajo la denominación de Ťjornadas técnicasť) se celebró en julio de 1987 en la Universidad Politécnica de Cataluña, con dos platos fuertes sobre traducción automática: una conferencia de Sergei Nirenburg, entonces adscrito al Center for Machine Translation de la Universidad Carnegie Mellon, y una mesa redonda participada por Jesús Vidal y Juan Carlos Ruiz (de Eurotra), Luis de Sopeńa (de IBM), Juan Alberto Alonso (de Siemens), y el propio Nirenburg.

Algunos datos estadísticos constatan la relevancia de la traducción automática en la SEPLN entre los ańos 1987 y 1991. Durante aquellos ańos, de los 60 artículos publicados en la revista de la asociación, Procesamiento del lenguaje natural, 23 (más de un tercio) versaron sobre traducción automática. El nivel de participación refleja la relevancia de los grupos: ocho describen Eurotra, siete las investigaciones de IBM, cuatro Metal, de Siemens, y 3 Atlas, de Fujitsu. Sólo uno de los artículos publicados, de los 23, era ajeno a los cuatro proyectos estrella. Éste fue el presentado en el congreso de 1990 por Gabriel Amores, actual investigador del área de traducción automática, con los resultados de su investigación en el Centre for Computational Linguistics de Umist. Se han citado 35 personas y esta cifra da una idea de la actividad. En una estimación aproximada, se puede calcular que en 1989 la investigación en traducción automática contaba en España con un presupuesto anual de unos 200 millones de pesetas, una cifra que, por modesta que parezca, multiplica varias veces la cantidad que se maneja hoy en día en nuestro país, una década después.

Desde 1998, el Departamento de Lenguajes y Sistemas Informáticos de la Universidad de Alicante desarrolla sistemas de traducción automática entre lenguas románicas: interNostrum, entre el español y el catalán; Traductor Universia, entre el español y el portugués, y, más recientemente, Apertium, un sistema de traducción automática de código abierto desarrollado en colaboración con un consorcio de empresas y universidades españolas, que actualmente traduce entre las lenguas del Estado español y otras lenguas románicas.

Desde 1994 AutomaticTrans ha desarrollado su plataforma lingüística corporativa que incorpora motores híbridos de traducción automática de alto rendimiento. La plataforma la completan un conjunto de componentes necesarios para resolver la problemática multilingüe y multiformato de organizaciones grandes.

En 2010, Pangeanic se convirtió en la primera empresa del mundo en aplicar el traductor estadístico Moses en un entorno comercial (AMTA 2010 http://www.mt-archive.info/10/AMTA-2010-TOC.htm) desarrollando una plataforma con autoaprendizaje, limpieza de corpus y reentrenamiento junto con el Instituto Técnico de Informática de Valencia (ITI) y el grupo de investigación Pattern Recognition and Human Language Technology (https://www.prhlt.upv.es/wp/es/) de la Politècnica de València. Miembro fundador de TAUS, Pangeanic consiguió el mayor contrato de infraestructuras de traducción automática para la Comisión Europea con su proyecto iADAATPA (https://pangeanic.es/noticias/iadaatpa-pangeanic-logra-el-mayor-contrato-de-infraestructuras-digitales-europeas-de-traduccion-automatica-segura/) en 2017.



[http://www.mt-archive.info/10/AMTA-2010-TOC.htm
"PangeaMT: Putting Open Standards to Work..Well", por E. Yuste, Manuel Herranz, Alexandre Helle, Francisco Casacuberta et al. (2010)
Artículo en inglés]


</doc>
<doc id="21854" url="https://es.wikipedia.org/wiki?curid=21854" title="Entorno de desarrollo integrado">
Entorno de desarrollo integrado

Un entorno de desarrollo integrado o entorno de desarrollo interactivo, en inglés "Integrated Development Environment" (IDE), es una aplicación informática que proporciona servicios integrales para facilitarle al desarrollador o programador el desarrollo de software.

Normalmente, un IDE consiste de un editor de código fuente, herramientas de construcción automáticas y un depurador. La mayoría de los IDE tienen auto-completado inteligente de código ("IntelliSense"). Algunos IDE contienen un compilador, un intérprete, o ambos, tales como NetBeans y Eclipse; otros no, tales como SharpDevelop y Lazarus.

El límite entre un IDE y otras partes del entorno de desarrollo de software más amplio no está bien definido. Muchas veces, a los efectos de simplificar la construcción de la interfaz gráfica de usuario (GUI, por sus siglas en inglés) se integran un sistema controlador de versión y varias herramientas. Muchos IDE modernos también cuentan con un navegador de clases, un buscador de objetos y un diagrama de jerarquía de clases, para su uso con el desarrollo de software orientado a objetos.

Los IDE están diseñados para maximizar la productividad del programador proporcionando componentes muy unidos con interfaces de usuario similares. Los IDE presentan un único programa en el que se lleva a cabo todo el desarrollo. Generalmente, este programa suele ofrecer muchas características para la creación, modificación, compilación, implementación y depuración de software. Esto contrasta con el desarrollo de software utilizando herramientas no relacionadas, como Vi, "GNU Compiler Collection" (GCC) o Make.

Uno de los propósitos de los IDE es reducir la configuración necesaria para reconstruir múltiples utilidades de desarrollo, en vez de proveer el mismo set de servicios como una unidad cohesiva. Reduciendo ese tiempo de ajustes, se puede incrementar la productividad de desarrollo, en casos donde aprender a usar un IDE es más rápido que integrar manualmente todas las herramientas por separado.

Una mejor integración de todos los procesos de desarrollo hace posible mejorar la productividad en general, más que únicamente ayudando con los ajustes de configuración. Por ejemplo, el código puede ser continuamente armado, mientras es editado, previendo retroalimentación instantánea, como cuando hay errores de sintaxis. Esto puede ayudar a aprender un nuevo lenguaje de programación de una manera más rápida, así como sus librerías asociadas.

Algunos IDE están dedicados específicamente a un lenguaje de programación, permitiendo que las características sean lo más cercanas al paradigma de programación de dicho lenguaje. Por otro lado, existen muchos IDE de múltiples lenguajes tales como Eclipse, ActiveState Komodo, IntelliJ IDEA, MyEclipse, Oracle JDeveloper, NetBeans, Codenvy y Microsoft Visual Studio. Xcode, Xojo y Delphi están dedicados a un lenguaje cerrado o a un tipo de ajustes de tipos de lenguajes de programación.

Mientras la mayoría de los IDE modernos son gráficos, los editores de textos (como Turbo Pascal) eran populares antes de que los sistemas de ventanas se hicieran disponibles, tales como Microsoft Windows y X Window System (X11). Estos usan funciones por medio de teclas rápidas para ejecutar comandos o macros frecuentemente usados.

Los IDE fueron posibles cuando se desarrollaba vía consola o terminal de la computadora. Los primeros sistemas no podían soportarlos, porque los programas eran preparados usando diagramas de flujo, introduciendo programas con tarjetas agujeradas (o papel cartón, etcétera) antes de enviarlos a un compilador. Dartmouth BASIC fue el primer lenguaje en ser creado con un IDE (también fue el primero en ser diseñado para ser utilizado enfrente de la consola o la terminal). Este IDE (parte de "Dartmouth Time Sharing System") fue basado en código y basado en comandos, y por esto no se parecía mucho a los IDE tan gráficos actuales. Sin embargo, la edición integrada, manejo de archivos, compilación, depurador y ejecutable en una manera consistente con los IDE modernos.

""Maestro I"" es un producto de Softlab Múnich y fue el primer sistema de desarrollo integrado IDE, para software, creado en 1975. Maestro I fue instalado por 22.000 programadores en todo el mundo. Hasta 1989, existían 6.000 instalaciones en la República Federal de Alemania. Maestro fue sin duda el líder mundial en este campo durante los años 1970 y 1980. Uno de los últimos Maestro I puede ser encontrado en el Museo de Tecnología e Informática en Arlington.

Uno de los primeros IDE con un concepto de "plug-in" fue Softbench. En 1995 "Computerwoche" comentó que el uso de un IDE no era bien recibido por los programadores, ya que afectaría su creatividad.

La programación visual es un marco de usuario en la que generalmente se requiere una IDE. Los IDE visuales le permiten a los usuarios crear nuevas aplicaciones de programación en movimiento, bloques de construcción, o nodos de código para crear diagramas de flujo o diagramas de estructura que luego son compilados o interpretados. Estos diagramas de flujo muchas veces se basan en el lenguaje de modelado unificado.

Esta interfaz ha sido popularizada con los Lego Mindstorms, y se ha mantenido activa por un número de compañías deseando capitalizar el poder de los buscadores personalizados como los fundados en Mozilla. KTechlab apoya el "flowcode" y es un IDE de código abierto ("opensource") y un simulador para desarrollar software para micro-controladores. 

La programación visual también es responsable del poder de la distribución de software (LabVIEW y software EICASLAB). Un primitivo sistema visual de programación, Max, fue modelado a partir de un sintetizador de diseño análogo siendo desarrollado para utilizar el desempeño de la música en tiempo real desde los años 1980. Otro ejemplo primitivo fue Prograph, un programa a base de flujo de datos, originalmente desarrollado para la Macintosh. El ambiente de programación gráfica "Grape" es usado para programar "qfix robot kits".

Este acercamiento es también utilizado por software especializados, tales como Openlab, donde el usuario final quiere la flexibilidad completa de un lenguaje de programación, sin la tradicional curva de aprendizaje.

Algunos IDE soportan múltiples lenguajes, tales como GNU Emacs basados en C y Emacs Lisp, y Eclipse, IntelliJ IDEA, MyEclipse o NetBeans, todos basados en Java, o MonoDevelop, basados en C#.

Normalmente, el soporte para lenguajes alternativos regularmente es proveído por un "plug-in", permitiéndoles ser instalados en el mismo IDE, al mismo tiempo. Eclipse, y Netbeans tienen plugins para C/C++, Ada, (por ejemplo AdaGIDE), Perl, Python, Ruby, y PHP, los cuales son seleccionados entre extensión de archivos, ambientes o ajustes de proyectos.

Los programadores Unix pueden combinar herramientas de línea de comandos POSIX en un entorno de desarrollo completo, capaz de desarrollar grandes programas como el kernel de Linux y su entorno. Las herramientas GNU de software libre (GNU Compiler Collection (GCC), depurador GNU (gdb), GNU make) están disponibles en muchas plataformas, incluyendo Windows. Los desarrolladores que prefieren herramientas orientadas a la línea de comandos pueden utilizar los editores con soporte para muchos estándares de Unix y herramientas de construcción GNU, construyendo una IDE con programas como Emacs o Vim. El Data Display Debugger está destinado a ser un front-end gráfico avanzado para muchas herramientas estándar depurador basados en texto. Algunos programadores prefieren Administración de makefiles y sus derivados a las herramientas similares de construcción de código incluidos en un IDE completo. Por ejemplo, muchas contribuciones a las bases de datos de PostgreSQL usan mark y gdb directamente a desarrollar nuevas características. Aún cuando se construya PostgreSQL para Microsoft Windows utilizando Visual C++, se utilizan scripts Perl como reemplazo para el make, en lugar de depender de cualquier característica del IDE. Algunos IDE de Linux como Atom.io o Geany intentan proporcionar una interfaz gráfica para las operaciones de construcción tradicionales.

En las diversas plataformas de Microsoft Windows, rara vez se utilizan herramientas de línea de comandos para el desarrollo. Como consecuencia, hay muchos productos comerciales y no comerciales. Sin embargo, cada uno tiene un diseño diferente creando comúnmente incompatibilidades. La mayoría de los vendedores más importantes del compilador para Windows todavía proporcionan copias gratuitas de sus herramientas de línea de comandos, incluyendo Microsoft (Visual C++, Plataforma SDK, .NET Framework SDK, utilidad nmake), Embarcadero Technologies (compilador bcc32, utilidad make).

Los IDE siempre han sido populares en Mac OS de Apple Macintosh, que se remonta al Taller de los programadores Macintosh, de los ambientes Turbo Pascal, THINK Pascal y THINK C de mediados de la década de 1980. A 2015 los programadores Mac OS X pueden elegir entre IDE nativos como Xcode y herramientas de código abierto como Eclipse y Netbeans. ActiveState Komodo es un IDE multilenguaje propietaria apoyado en el Mac OS.

Con el advenimiento de la computación en nube, algunos IDE están disponibles en línea y se ejecutan dentro de los navegadores web.



</doc>
<doc id="21855" url="https://es.wikipedia.org/wiki?curid=21855" title="Visual Basic">
Visual Basic

Visual Basic (VB) es un lenguaje de programación dirigido por eventos, desarrollado por Alan Cooper para Microsoft. Este lenguaje de programación es un dialecto de BASIC, con importantes agregados. Su primera versión fue presentada en 1991, con la intención de simplificar la programación utilizando un ambiente de desarrollo 

La última versión fue la 6, liberada en 1998, para la que Microsoft extendió el soporte hasta marzo de 2008.

En 2001 Microsoft propuso abandonar el desarrollo basado en la API Win32 y pasar a un framework o marco común de librerías, independiente de la versión del sistema operativo .NET Framework, a través de Visual Basic .NET (y otros lenguajes como C Sharp (C#) de fácil transición de código entre ellos); fue el sucesor de Visual Basic 6. 

Aunque Visual Basic es de propósito general, también provee facilidades para el desarrollo de aplicaciones de bases de datos usando Data Access Objects, Remote Data Objects o ActiveX Data Objects.

Visual Basic contiene un entorno de desarrollo integrado o IDE que integra editor de textos para edición del código fuente, un depurador, un compilador (y enlazador) y un editor de interfaces gráficas o GUI.

Todas las versiones de Visual Basic para Windows son muy conocidas, aunque la Microsoft Visual Basic 1.0 desarrollada para el sistema operativo MS-DOS (ediciones Profesional y Estándar), que data de 1992, fue menos difundida. Esta proveía un entorno que, aunque en modo texto, incluía un diseñador de formularios en el que se podían arrastrar y soltar distintos controles.

La última versión que únicamente generaba aplicaciones de 16 bits fue la 3.0 y no incluía una biblioteca detallada de componentes para toda clase de usos. Durante la transición de los sistemas Windows 3.11 a Windows 95, en 1995: hizo su aparición la versión 4.0 de Visual Basic; esta podía generar programas tanto de 16 como de 32 bits, a partir del mismo código fuente, aunque a costa de un gran aumento en el tamaño de los archivos necesarios en tiempo de ejecución ("runtime"). Además, se sustituyeron los controles denominados VBX por los nuevos OCX. Con la siguiente versión, la 5.0, se estuvo a punto de implementar por primera vez la posibilidad de compilar a código nativo, obteniendo una mejora de rendimiento considerable. Tanto esa como la sucesora 6.0 soportaban ciertas características propias de los lenguajes orientados a objetos, pero carecían de algunas importantes, tales como herencia y sobrecarga; pero, de hecho, no fue pensado como lenguaje orientado a objetos.
La versión 6.0, que puede generar código ejecutable directo en 32 bits, todavía continúa utilizándose masivamente, y es compatible con las últimas versiones de los sistemas Windows, como Windows 7 y Windows 8.

Visual Basic evolucionó para integrar la plataforma .NET; allí perdió su propia identidad como lenguaje único adquirible, pasando a integrar un paquete de productos, llamado precisamente Microsoft .NET; dentro de ese paquete o framework se encuentra el nuevo y llamado Visual Basic .NET, que trabaja sobre el entorno Microsoft Visual Studio. Esta nueva versión del lenguaje posee profundas diferencias en la forma de programar respecto de Visual Basic 6, pero gran semejanza en su sintaxis básica.

Cabe mencionar que, aunque fue menos conocido, se desarrolló también una versión gratuita de Visual Basic 5.0, orientada al desarrollo de controles y componentes; su nombre específico era Microsoft Visual Basic 5.0 Control Creation Edition (Visual Basic 5 CCE). También hubo versiones orientadas al desarrollo de aplicaciones para dispositivos móviles basados en Windows CE y Pocket PC, conocidas como Embedded (Visual Basic).

Los compiladores de Visual Basic generan código que requiere una o más librerías de enlace dinámico para que funcione, conocidas comúnmente como DLL (sigla en inglés de "Dynamic-Link Library"); en algunos casos reside en el archivo llamado MSVBVMxy.DLL (siglas de "MicroSoft Visual Basic Virtual Machine x.y", donde x.y es la versión) y en otros en VBRUNXXX.DLL ("Visual Basic Runtime X.XX"). Estas bibliotecas DLL proveen las funciones básicas implementadas en el lenguaje, conteniendo rutinas en código ejecutable que son cargadas "bajo demanda" en tiempo de ejecución. Además de las esenciales, existe un gran número de bibliotecas del tipo DLL con variedad de funciones, tales como las que facilitan el acceso a la mayoría de las funciones del sistema operativo o las que proveen medios para la integración con otras aplicaciones.

Dentro del mismo Entorno de desarrollo integrado (IDE) de Visual Basic se puede ejecutar el programa que esté desarrollándose, es decir en modo intérprete (en realidad pseudo-compila el programa muy rápidamente y luego lo ejecuta, simulando la función de un intérprete puro). Desde ese entorno también se puede generar el archivo en código ejecutable (exe); ese programa así generado en disco puede luego ser ejecutado sin requerir del ambiente de programación (incluso en modo stand alone), aunque sí será necesario que las librerías DLL requeridas por la aplicación desarrollada se encuentren también instaladas en el sistema para posibilitar su ejecución.

El propio Visual Basic provee soporte para empaquetado y distribución; es decir, permite generar un "módulo instalador" que contiene al programa ejecutable y las bibliotecas DLL necesarias para su ejecución. Con ese módulo la aplicación desarrollada se distribuye y puede ser instalada en cualquier equipo (que tenga un sistema operativo compatible).

Así como bibliotecas DLL, hay numerosas aplicaciones desarrolladas por terceros que permiten disponer de variadas y múltiples funciones, incluso mejoras para el propio Visual Basic; las hay también para el empaquetado y distribución, y hasta para otorgar mayor funcionalidad al entorno de programación (IDE).

Existe un único entorno de desarrollo para Visual Basic, desarrollado por Microsoft: 
Microsoft Visual Basic x.0, correspondientes a versiones desde la 2.0 hasta la 20.0, (con respectivas diferencias entre versiones del lenguaje).

El entorno de desarrollo es muy similar al de otros lenguajes. Realizando una instalación típica del producto, las características básicas se presentan de la siguiente forma:




Se designa como objeto cualquier elemento, por ejemplo, un formulario, una imagen, un control, tal como una caja de texto; a su vez, los objetos tienen propiedades, que en el caso de la caja de texto una es la propiedad "text" que se encarga de contener el texto que aparecerá en la caja. A los objetos se les puede asociar eventos. Un evento es la ocurrencia de un suceso, comúnmente la acción que realiza el usuario sobre el objeto, que como resultado puede, por ejemplo, provocar un cambio en alguna propiedad de un objeto. Por ejemplo: Visual Basic tiene un evento llamado KeyPress, que ocurre cuando el usuario presiona una tecla; ese evento se puede asociar a la caja de texto, y en él definirá (por programación) qué acción se tomará cuando se oprima una tecla.

En síntesis, un objeto posee propiedades, responde a eventos y puede ejecutar métodos asociados a él.

Algunos eventos comunes definidos en Visual Basic son: 

Imagínese un auto como un objeto; el auto tiene diversas propiedades como color, modelo, etc. Algunas con solamente 2 posibles valores, como encendido y apagado, incluso otras que a simple vista no se ven, como podría ser la cantidad de gasolina. Para definir el color de este objeto Auto, según Visual Basic, se haría de la siguiente manera:

y para definirle un evento podría ser como el siguiente ejemplo:

El siguiente fragmento de código muestra un cuadro de mensaje, en una ventana, que dice "¡Hola, mundo!": 


Las críticas hechas en las ediciones de Visual Basic anteriores a VB.NET son variadas; se citan entre ellas:


Existen múltiples alternativas dentro y fuera de Windows que intentan imitar este lenguaje y su mecánica de desarrollo. El más conocido y popular es Gambas: 


Otras opciones conocidas son Real Basic o PureBasic, que permiten desarrollar bajo Windows, Linux, Mac OS e independientemente. PureBasic permite desarrollar también para Amiga OS. A diferencia de Gambas, estas son soluciones comerciales y no son libres.



</doc>
<doc id="21856" url="https://es.wikipedia.org/wiki?curid=21856" title="Christian Marclay">
Christian Marclay

Christian Marclay es un artista visual y compositor suizo radicado en Nueva York, que explora los patrones de lenguaje que conecta el sonido, la fotografía, el video y el cine.

Marclay utiliza discos de vinilo y giradiscos para sus performances, tanto solo como en colaboración con músicos como John Zorn, William Hooker, Otomo Yoshihide, Butch Morris y otros. Considerado como «una de las figuras más influyentes desde fuera del hip hop», Marclay manipula y rompe vinilos para producir "loops" continuos y brincos y, como dice él, prefiere utilizar sonidos procedentes de discos comprados en mercados de pulgas.




</doc>
<doc id="21857" url="https://es.wikipedia.org/wiki?curid=21857" title="Tenedor">
Tenedor

Un tenedor es un utensilio de mesa que consta de un mango y una cabeza con dientes largos a modo de clavos (normalmente tres o cuatro puntas) y es utilizado para pinchar o sostener un trozo de comida. Fue empleado, primeramente, en Occidente, mientras que en Oriente fueron más usados los palillos. Hoy en día, sin embargo, los tenedores se utilizan también en Asia.

En particular se utiliza para llevar comida a la boca o para fijar algo mientras se cocina o se corta. El transporte a menudo se realiza simplemente colocando la comida sobre los dientes horizontales. Existen diferentes tipos de tenedor según el uso al que vaya dirigido, por ejemplo, si es para carne, pescado o postre.

Aunque ya había utensilios parecidos en la Grecia clásica y el Imperio romano para trinchar, el tenedor apareció como tal hacia 1077. Llegó a Europa procedente de Constantinopla a principios del siglo XI de la mano de Teodora, hija del emperador de Bizancio Constantino X Ducas. Lo llevó a Venecia al contraer matrimonio con Domenico Selvo, dux de aquella república. Pero Teodora para sus contemporáneos era tachada, por esta y otras refinadas maneras orientales, como escandalosa y reprobable y hasta San Pedro Damián amonestó desde el púlpito estas extravagancias, llegando a llamarlo «"instrumentum diaboli"».

Mas fue en Francia donde se hizo realmente popular, allá por el siglo XVI, gracias a Catalina de Médici que lo introdujo en la corte francesa al casarse con el rey Enrique II. Como curiosidad cabe añadir que además de usar el tenedor para comer, Catalina lo usó para rascarse la espalda. La fama de cursi que tenía este utensilio de mesa lo hizo quedar en un segundo plano frente a comer con las manos hasta el siglo XVIII.



</doc>
<doc id="21865" url="https://es.wikipedia.org/wiki?curid=21865" title="Escudo de Nicaragua">
Escudo de Nicaragua

El " escudo nacional de Nicaragua" fue creado, junto con la actual Bandera de Nicaragua, por el Decreto Legislativo del 5 de septiembre de 1908, siendo Presidente de La República José Santos Zelaya López, fijándose de modo definitivo el Escudo y la Bandera actuales de Nicaragua. Se basa en el escudo que perteneció a las Provincias Unidas del Centro de América. 

Consta de dos elementos, el central y el periférico, siendo el primero un triángulo equilátero de oro que representa la igualdad y la rectitud de la Patria y sus instituciones. 

En la parte inferior, una cordillera de cinco volcanes verde amarillentos, entre dos océanos en tono azul ultramar, representan la unidad y la fraternidad de las cinco repúblicas centroaméricanas al igual que los volcanes y cordilleras del país. 

Los mares representan el Mar Caribe y el Océano Pacífico que bañan las costas del Este y el Oeste del país respectivamente. 

Un gorro frigio en tono rojo bermellón ilumina la escena con rayos blancos de luz, desde la parte central del triángulo, representando la libertad, teniendo como fondo un cielo en tono azul pálido que simboliza la gloria, el heroísmo y el sacrificio por la libertad. 

Un arco iris de siete franjas que cubre las montañas, debajo del cual está dicho gorro, representa la paz y el sendero por el cual Centroamérica va hacia la consecución de su elevado destino. 

Alrededor del triángulo el elemento periférico formado por la leyenda en letras de oro: "República de Nicaragua - América Central"; la figura circular que forma la leyenda o divisa simboliza el cielo, la perfección y la eternidad. Señala a la vez la unidad de los elementos interiores del escudo y el oro de las letras y el borde del triángulo simbolizan las riquezas minerales del país. 

Este escudo se parece al Escudo de El Salvador, con las diferencias que el Escudo salvadoreño tiene 5 banderas detrás del triángulo, la corona de laurel a su alrededor y debajo el lema "Dios - Unión - Libertad".

Nicaragua, como parte de las Provincias Unidas del Centro de América, adoptó la bandera y el escudo de armas aprobados por la Asamblea Nacional Constituyente de Centroamérica, según decreto No. 29 del 21 de agosto de 1823. La Bandera de las Provincias Unidas del Centro de América, constaba de tres franjas horizontales: azules la superior e inferior y blanca la del centro.

Durante el período federal cada Estado quedó en libertad de modificar el escudo de armas de las Provincias Unidas del Centro de América. Nicaragua lo reformó agregándole cañones y fusiles al pie del triángulo equilátero y una lanza para sostener el gorro frigio.
Separada Nicaragua de la Federación Centroamericana el 30 de abril de 1838, se continuaron usando la bandera azul y blanca y el escudo de armas modificado hasta que la Representación Nacional de Centroamérica formada por los Estados de Nicaragua, Honduras y El Salvador decretó nuevas insignias el 22 de abril de 1851.

El 8 de noviembre de 1849, los Estados de Nicaragua, El Salvador y Honduras acordaron en la ciudad de León un Pacto de Confederación, que debería ser arreglado por medio de una Dieta. La Representación Nacional de Centroamérica, se instaló solamente el 9 de enero de 1851, en Chinandega integrada por el Licenciado Pablo Buitrago Benavente y don Hermenegildo Zepeda Fernández por Nicaragua, don José Guerrero por Honduras, don Francisco Barrundia y don José Silva por el Salvador. De inmediato se procedió a organizar su directorio, siendo nombrado presidente don Hermenegildo Zepeda Fernández, Primer Secretario don José Silva y Segundo Secretario el Lic. Pablo Buitrago Benavente.

El 22 de abril de 1851 la Representación Nacional de Centroamérica decretó obligatoria la bandera azul y blanca y el escudo de la Confederación de Centroamérica; este último sería un triángulo equilátero; en su base aparecería una cordillera de tres volcanes colocada en un terreno bañado por ambos mares; en el vértice el arco iris que los cubra y bajo éste el gorro de la Libertad difundiendo luces, y con tres estrellas en la parte superior. En torno del triángulo y en figura circular se escribirá en letras de oro, “FEDERACIÓN DE CENTROAMÉRICA”.

El 16 de mayo de 1853 don Fruto Chamorro Pérez como Director Supremo del Estado de Nicaragua, convocó a una Asamblea Nacional Constituyente, después de algunas dificultades para reunir a los electos, se inauguró en Managua el 22 de enero de 1854. Una de las primeras disposiciones tomadas por la Asamblea fue decretar el 28 de febrero del mismo año que el Estado de Nicaragua se llamaría República y el gobernante llevaría el título de presidente para ejercer el cargo en un período de cuatro años.

La Asamblea se atribuyó facultades para elegir al presidente en el primer período del 1 de marzo de 1855 a 1859 eligiéndose al general Fruto Chamorro Pérez, quedando como presidente provisorio mientras empezaba el período legal. La nueva República emitió una ley creando el cambio de color de la bandera, el cual debería ser amarillo, blanco y nácar, según decreto legislativo; en cuanto al escudo ya no aparecerían cinco volcanes sino solamente uno.

No se sabe por cuanto tiempo se usaron estos emblemas, ya que el país adoptó por segunda vez las enseñas de 1823, que conservó hasta 1908.

Al asumir la presidencia de la república el general José Santos Zelaya López el 16 de septiembre de 1893, prometió trabajar por el reaparecimiento de la Patria Centroamericana; ya que Nicaragua era una porción disgregada de la República de Centroamérica. El general Zelaya López aprovechó la amistad con los presidentes de Honduras y El Salvador, doctor Policarpo Bonilla y general Rafael Antonio Gutiérrez para promover la unión de las tres repúblicas, porque los presidentes de Costa Rica y Guatemala no mostraban interés en dicha unión.

El 20 de junio de 1895 los plenipotenciarios de Nicaragua, El Salvador y Honduras doctores don Manuel Coronel Matus, don Jacinto Castellanos y don Constantino Fiallos suscriben en el puerto de Amapala (Honduras) el Tratado de Unión que se conoce con el nombre de “Pacto de Amapala”; el que erige a las Repúblicas de Nicaragua, El Salvador y Honduras en una sola entidad política para el ejercicio de su soberanía bajo el nombre de República Mayor de Centroamérica. Esta denominación persistirá hasta que las Repúblicas de Guatemala y Costa Rica acepten voluntariamente el presente convenio en cuyo caso se llamará República de Centroamérica. En el artículo número once de dicho convenio se adopta la bandera y el escudo de armas de la antigua federación, variando únicamente la divisa o leyenda.

El 3 de agosto de 1895 el Tratado de Amapala fue ratificado por el Presidente de la República, quedando por tanto incluido oficialmente Nicaragua dentro de la República Mayor de Centroamérica. Después de la ratificación del tratado por los tres gobiernos antes citados, se instaló en San Salvador la Dieta de la República Mayor de Centroamérica. Reunido el Congreso Constituyente en la ciudad de Managua el día 27 de agosto de 1898, aprobó la Constitución de los Estados Unidos de Centroamérica. Poco después la unión llegó a su fin debido al golpe de Estado del general Tomás Regalado (1898-1903), quién depuso el 13 de noviembre de 1898 al Presidente de El Salvador, general Rafael Antonio Gutiérrez, y de inmediato declaró la separación de este país; rompiéndose el pacto firmado en Amapala y finalizando el ideal de unidad centroamericana del general José Santos Zelaya López.

El presidente general Zelaya, devoto de la causa de la Unión Centroamericana, quería que Nicaragua volviera a usar la bandera y escudo de las Provincias Unidas de Centroamérica, con ligeras variantes, y el 5 de septiembre de 1908 firmó el siguiente Decreto Legislativo.
Lamentablemente en el Decreto transcrito no se indicó el tamaño de la bandera de Nicaragua, pues en los años y décadas siguientes a la bandera se le daba de forma caprichosa cualquier tamaño, pues no lo había oficialmente. Las franjas azules se hacían de cualquier tonalidad de azul y el escudo no se ceñía a las especificaciones que claramente explica el Decreto, ya que le ponían una corona de laurel, banderas detrás del triángulo (tal como las tiene el Escudo de El Salvador), el gorro de la libertad o gorro frigio se ponía sobre un asta, los cinco volcanes no los hacían del mismo tamaño y se pintaban de cualquier tonalidad de verde. Fue hasta 1971, 63 años después de su creación, que se regularon los tamaños y colores de la bandera y el escudo, junto con el Himno Nacional, Salve a ti.

El viernes 27 de agosto de 1971, siendo Presidente de la República Anastasio Somoza Debayle, fue publicado en La Gaceta, Diario Oficial No.194, el Decreto Legislativo No. 1908 "Ley sobre Características y Uso de los Símbolos Patrios", que especifica el uso del Escudo Nacional: los cinco volcanes son de color verde amarillento; el cielo donde está el arcoiris es de color azul pálido; el gorro frigio es rojo bermellón; los mares son azul ultramar y las letras mayúsculas, de igual tamaño, son de oro metálico.

Dicha Ley fue reformada por la Ley No. 433 del 2 de julio de 2002, publicada en La Gaceta No. 135 del 18 del mismo mes y año, siendo Presidente de la República el Ingeniero Enrique Bolaños Geyer y Presidente de la Asamblea Nacional el expresidente Doctor Arnoldo Alemán Lacayo pocos meses después de entregar el poder a Bolaños.

A finales del mes de enero de 2007, poco después de que el presidente Daniel Ortega Saavedra tomara posesión del poder el 10 del mismo mes y año, se comenzó a publicar en el lado izquierdo de la papelería oficial del gobierno un escudo psicodélico que simula al Escudo Nacional, pero suprime la leyenda que lo rodea, la raya izquierda es más larga que las demás y encima de esta está el eslogan de campaña del partido oficialista Frente Sandinista de Liberación Nacional (FSLN) ""Unida Nicaragua triunfa"", en vez de la leyenda "República de Nicaragua - América Central". La primera reacción oficial fue la del Ministro de Educación, Licenciado Miguel de Castilla Urbina, quien declaró que no era el escudo de la nación, sino más bien una metáfora: “No hay cambio de escudo, son dos cosas distintas. No veo en eso el escudo nacional, pues el nuestro no tiene volcanes color rojo, es verde, amarillo y celeste. Lo que veo es una metáfora de colores alegres, a mí me gusta, además no siento que la patria esté siendo lastimada”, afirmó.

De Castilla afirmó que el logotipo vino de la Secretaría de Comunicación y Ciudadanía, que es coordinada por la Primera Dama Rosario Murillo. “Este logotipo será utilizado como el oficial en las instancias de Gobierno”, dijo el Ministro de Educación. Esto causó polémica entre los partidos de la oposición, sobre todo en la Alianza Liberal Nicaragüense (ALN), por el irrespeto al Escudo que llegó al extremo de aparecer en las páginas web del gobierno, la cual emitió la siguiente resolución publicada en el periódico El Nuevo Diario el 10 de febrero del 2007.




</doc>
<doc id="21866" url="https://es.wikipedia.org/wiki?curid=21866" title="Historia de Nicaragua">
Historia de Nicaragua

El origen del nombre Nicaragua no está del todo claro, y aún hoy divide a los historiadores y estudiosos del lenguaje. Según una versión, proviene del náhuatl "nic-anahuac" ("hasta aquí los de anahuac"), otra versión, considera que proviene de una voz maya. Existe, entre otras, la más difundida versión aunque también la menos respaldada por los expertos, según la cual el nombre "Nicaragua" se deriva del nombre de Nicarao, quien supuestamente fue un jefe amerindio asentado en el territorio del actual departamento de Rivas que recibió a los primeros conquistadores españoles a orillas del actual Lago Cocibolca, de Granada o Gran Lago de Nicaragua, al que Gil González Dávila llamó ""la Mar dulce"".
Cristóbal Colón, descubrió la costa Caribe de Nicaragua, el 12 de septiembre de 1502, cuando se refugió de una tormenta al doblar la desembocadura del río Coco en el cabo Gracias a Dios en su cuarto y último viaje. Posteriormente, desembarco en la desembocadura del río Grande de Matagalpa al que llamó ""río del Desastre"" porque en sus fuertes corrientes perdió una de sus naves.

Gil González Dávila fue el primer explorador de conquista que visitó parte de las regiones costeras del Pacífico nicaragüense en 1522-1523, durante su recorrido tuvo contacto con un poderoso cacique indígena llamado Nicaragua, Niqueragua o Nicarao, en cuyos dominios se bautizaron 9.017 personas y se recogieron 18.506 pesos de oro bajo. Después González Dávila se trasladó a un territorio llamado Nochari, situado unas seis leguas al norte de la corte del rey Nicarao, donde habitaban cinco reyes llamados Ochomogo, Nandapia, Mombacho, Morati y Gotega (Coatega). Allí se bautizaron 12,607 personas más, y un poderoso jefe llamado Diriangén vino con un suntuoso cortejo a entrevistarse con ´los españoles, pero a los pocos días, el 17 de abril de 1523, regresó para enfrentarlos en combate. La expedición logró vencer a los guerreros de Diriangén, pero tuvo que retirarse a los dominios de Nicarao, donde hubo otro enfrentamiento con los indígenas. Finalmente, González Dávila optó por marchar hacia el sur, y en el golfo de Nicoya se reembarcó con destino a Panamá, sin haber dejado fundación alguna.

En 1524, Francisco Hernández de Córdoba, enviado por el gobernador de Castilla del Oro Pedrarias Dávila, fundó las dos primeras ciudades en lo que seria más tarde Nicaragua: Granada, a orillas del Lago Cocibolca, y Santiago de los Caballeros de León, a orillas del Lago Xolotlán.

Bajo la gobernación de Pedrarias Dávila (1528-1531), la tierra que luego sería llamada Nicaragua sufrió una alarmante despoblación por los abusos de Pedrarias, quien hizo gala un extremado salvajismo en su búsqueda de recursos y esclavos para las minas de en el cerro Potosí, y para servir de ""cargueros"". A lo anterior se unieron las epidemias de enfermedades desconocidas, algunas de origen europeo que aniquilaban a los indígenas, y las propias de la tierra, que hacían mella en los conquistadores. Los abusos que este gobernador cometía en su continua búsqueda de la riqueza forzó a huir a la población. Indios y españoles (mando a decapitar al Capitan Hernández de Córdoba, acusándolo falsamente de traición), fueron víctimas por igual de los métodos de exacción que Pedrarias puso en práctica. Pedrarias murió con 96 años el 6 de marzo de 1531 y le sucedió Rodrigo de Contreras que gobernó el territorio desde 1534 hasta 1542 siguiendo la senda de abusos que Dávila había iniciado.

Durante el periodo colonial, Nicaragua formó parte de la Capitanía General de Guatemala. Durante ese periodo Nicaragua fue la principal vía de comunicación entre el Pacífico y el Atlántico ya que tenía un sistema de transporte lacustre que facilitaba el movimiento de materias y personas a regiones aledañas. El Realejo fue en particular uno de los puertos principales en el Pacífico donde se construyeron gran parte de los galeones entre Manila y Acapulco. El Realejo, entre los siglos XVI y principios del XIX, sirvió como uno de los puertos principales en el comercio de esclavos para las colonias en el Pacífico como Perú, Ecuador, Colombia, Acapulco, y como punto de concentración de las riquezas que se obtuvieron por medio del comercio bimetálico (Plata para China por medio de Manila, y oro para España. Gran parte de esos movimientos, pasaron por Nicaragua ya que era la más fácil y mejor protegida, aun así Nicaragua fue atacada por diferentes naciones, Inglaterra en particular.

En el siglo XVII, los ingleses se establecieron un protectorado en la Costa de los Mosquitos, así llamada por el nombre de los habitantes indígenas misquitos, con los que los ingleses se mantuvieron en buenas relaciones. Fundaron allí la ciudad de Bluefields y posteriormente ayudaron al establecimiento del llamado Reino de la Mosquitia.

Hasta fines del siglo XVIII, el actual territorio nicaragüense estaba dividido en una gobernación de Nicaragua, con capital en León, y los corregimientos de Chontales, El Realejo, Matagalpa, Monimbó y Quezalguaque. En 1787, estos corregimientos fueron suprimidos y, junto con el corregimiento de Nicoya, anexados a Nicaragua, que se convirtió en una Intendencia, con sede León, del reino de Guatemala.

En las Cortes de Cádiz, la Intendencia de Nicaragua estuvo representada por el licenciado José Antonio López de la Plata, quien junto con su colega de Costa Rica Florencio del Castillo logró en 1812 que se creara la Provincia de Nicaragua y Costa Rica, como unidad política y administrativa distinta de Guatemala. Esta provincia desapareció debido a la restauración absolutista de 1814 y fue restablecida en 1820, al ponerse nuevamente en vigencia la Constitución de Cádiz. El Intendente de Nicaragua, Miguel González Saravia y Colarte, se convirtió en Jefe Político Superior de la Provincia de Nicaragua y Costa Rica. La provincia se dividía en siete partidos: Costa Rica, El Realejo, Granada, León, (Rivas), Nicoya y Nueva Segovia.

Los acontecimientos independentistas de México, en concreto la puesta en marcha del Plan de Iguala, provocaban mucha agitación en las provincias que habían pertenecido al reino de Guatemala y que en el marco de la Constitución de Cádiz ya había dejado de ser una sola unidad política: Chiapas, Guatemala (con El Salvador), Comayagua (Honduras), y la Provincia de Nicaragua y Costa Rica.

Con la total indiferencia de las clases populares, los grandes terratenientes y la jerarquía católica se habían ido definiendo en dos grande grupos y cada uno de ellos editaba un periódico. El grupo proindependentista, que editaba el diario "El editor constitucional", estaba encabezado por Pedro Molina, José María Castilla, Manuel Monfúfar y José Francisco Barrundia. El otro grupo era partidario de estar a la expectativa y ver que pasaba. Este editaba el diario "El amigo de la patria" y lo encabezaban José Cecilio del Valle. 

El territorio de Chiapas, que hasta 1820 había pertenecido al reino de Guatemala, se adhirió al plan de Iguala anexionándose a México. Cinco días después, el 15 de septiembre de 1821, se realizó una reunión de personas nobles de la Ciudad de Guatemala convocada por el Jefe Político Superior de Guatemala Gabino Gaínza en donde se llegó al acuerdo de declarar la independencia pero hacerla efectiva tras la aprobación en un Congreso de las provincias. Se constituyó una Junta Provisional Consultiva presidida por Gaínza, de la que formó parte como Ministro de Hacienda el jurisconsulto Miguel Larreynaga, nacido en Telica. 

En un pequeño intervalo de tiempo, menos de 6 años, España perdía la mayoría de sus posesiones en América, para el 2 de diciembre de 1821 solo mantenía Cuba, Puerto Rico y unos pocos puntos aislados en la costa de Colombia. En la península el desorden imperaba por todos los lados, guerrillas operando en Galicia, Cataluña y Castilla, sublevación incluso de la guardia real y el país al borde de la guerra civil llegando a la intervención extranjera en 1823 de los llamados Cien Mil Hijos de San Luis, lo que en 1763 era un fuerte imperio mundial se veía convertido en una mera sombra.

Los puntos básicos del plan de Iguala, que estaba ejecutando Iturbide en México, eran: independencia del país, unidad de criollos y españoles, religión oficial la Católica y organización política como monarquía constitucional bajo Fernando VII, eran apoyados, y hechos suyos, por la oligarquía de Guatemala. Esto producía la independencia del país pero sin ningún cambio social. 

La similitud de intereses y el hecho de la anexión de Chiapas a México, llevó a Gabino Gaínza, jefe político superior, a convocar una reunión el 5 de enero de 1822 para proponer la incorporación de Guatemala a México. La propuesta fue aceptada, y Guatemala pasó a integrase en el Imperio Mexicano de Agustín de Iturbide.

El 11 de octubre de 1822 la Diputación Provincial de Nicaragua y Costa Rica, reunida en León, proclamó la independencia absoluta de España y la anexión a México. Aunque todos los pueblos apoyaron la independencia, los partidos de Granada y Costa Rica se separaron de la provincia, y constituyeron Juntas Gubernativas separadas de las autoridades de León. Pronto se exacerbaron los ánimos y a principios de 1823, estalló una guerra civil cuando León atacó Granada, sin éxito.

El 19 de marzo de 1823 el general mexicano Antonio López de Santa Anna emprendió una campaña militar contra Iturbide y logró derrotarlo. Los partidarios de la independencia total llamaron a la organización de un Congreso de las cinco provincias del reino de Guatemala. El general Filísola convocó el congreso, al que no asistió Chiapas, confirmando así su definitiva separación de Guatemala. El congreso se reunió en la Ciudad de Guatemala el 24 de junio de 1823 y el 1 de julio se proclamaba que 

Nacían de esta forma las Provincias Unidas de Centroamérica, un nuevo estado compuesto por la unión de las cinco provincias Nicaragua, Guatemala, Honduras, El Salvador y Costa Rica.

El congreso del nuevo estado redactó la Constitución que se proclamó el 22 de noviembre de 1824 y rebautizó al país con el nombre de "República Federal Centroamericana" y las provincias pasaron a ser Estados. La constitución fue jurada el 15 de abril en los cinco estados. En Nicaragua la juró Manuel Antonio de la Cerda. En Nicaragua tardaron en consolidarse las instituciones, debido a la guerra civil causada por la rivalidad entre las ciudades de Granada y León.

Granada era el principal centro conservador del país, ya que en ella residían los más importantes terratenientes, productores principalmente de café y de azúcar. En León, en cambio, predominaban las clases medias artesanales y mercantiles. En tanto que Granada era el bastión del conservatismo político, León era el principal centro del liberalismo de Nicaragua. La rivalidad ideológica entre estas dos ciudades marcará la historia del siglo XIX en Nicaragua. 

El primer Jefe Supremo del Estado de Nicaragua fue el granadino Manuel Antonio de la Cerda, antiguo dirigente independentista, que asumió el poder el 10 de abril de 1825. Su vicejefe, Juan Argüello, conspiró contra él y lo derrocó al año siguiente. Tuvo lugar una nueva guerra civil entre los partidarios de Cerda y los de Argüello. Argüello estableció la capital en León, pero Granada se negó a reconocer su autoridad. El 27 de noviembre de 1829, De la Cerda fue fusilado por orden de Argüello. Finalmente, los enviados del gobierno federal de las Provincias Unidas lograron la pacificación de Nicaragua, tras el nombramiento como Jefe Supremo de Dionisio Herrera, que se mantendría en el poder entre 1830 y 1833. Pocos años después, siendo Jefe Supremo José Núñez (1838-1841), Nicaragua optó por separarse de la Federación centroamericana.

La constitución de la República Federal de Centroamérica fue hecha a la medida de los intereses de la oligarquía local de cada una de las antiguas provincias que buscaban mantener su libertad de acción en sus territorios. Los ejemplos de la revolución de Haití, con el levantamiento de los negros y mulatos, o la de Venezuela con la rebelión de las clases populares aterraban a estos terratenientes y les obligó a encerrarse en su provincia, ahora convertida en República. Esto hizo que se desbaratara la frágil unidad que había dejado la Constitución de tal forma que el 30 de abril de 1838 Nicaragua nacía como estado independiente. 

El 12 de noviembre de ese mismo año se establecía la primera Constitución de Nicaragua, que declaraba "la soberanía" de la nueva nación, y "establecía un régimen parlamentario". Según la constitución, el poder ejecutivo correspondía a un "Supremo Director", cuyo mandato duraría dos años. 

Los quince años siguientes (1838-1853) se denominan en la historia de Nicaragua, por este motivo, el "período del Directorio" que estuvo marcado por el caos político y social que imponía la rivalidad de leoneses y granadinos que propició la invasión del país por tropas procedentes de El Salvador y Honduras (1844-1845), bajo el mando del general salvadoreño Francisco Malespín, que saqueó la ciudad de León. 

En 1852, siendo Senador Director del Estado Fulgencio Vega (apoyado por el General Fruto Chamorro, la capital se fijó de manera definitiva en Managua, con el propósito de poner fin a la sempiterna rivalidad entre León y Granada, aunque esta decisión no se haría efectiva hasta 1858. 

El 26 de febrero de 1853 fue elegido Supremo Director del Estado de Nicaragua el conservador Fruto Chamorro. Bajo su mandato, una nueva Asamblea Constituyente elaboró una nueva Constitución, que puso fin al período del Directorio y dio inicio al periodo Presidencial. 

Durante este período, Nicaragua se había convertido en "objeto de deseo" para dos grandes potencias, Gran Bretaña y Estados Unidos, dadas las condiciones que su territorio ofrecía para la construcción de un canal entre los océanos Atlántico y Pacífico.

El 12 de agosto de 1841 el superintendente de Belice acompañado por el supuesto monarca mosquito desembarcan en San Juan del Norte y comunican a las autoridades nicaragüenses que esa ciudad y el resto de la Costa Atlántica pertenece al reino de Mosquitia. El 10 de septiembre el embajador inglés hace saber al gobierno nicaragüense que el reino de Mosquitia es un protectorado británico cuyos límites se extienden desde el cabo Honduras hasta la desembocadura del río San Juan.

Detrás de esta decisión y de la creación de este "reino" en la llamada Costa de los Mosquitos estaba la posibilidad de la construcción de un canal interoceánico (Nicaragua y Panamá son los lugares idóneos para la construcción de un canal que una los dos océanos, para 1835 los estadounidenses ya habían comenzado sus movimientos para la construcción de un canal por Panamá por lo que Inglaterra solo tenía la posibilidad de hacerlo en Nicaragua) para ello se aprovecharía el tramo navegable del río San Juan que desde su desembocadura llegaba hasta el Lago de Nicaragua. San Juan del Norte quedó incorporado al reino de Mosquitia y paso a denominarse "Greytown".

El reino de Mosquitia no continúo al sur, en Costa Rica, dado que el gobierno de ese país se opuso por las armas, bajo el mando del presidente Braulio Carrillo.

Nicaragua mandó al General Trinidad Muñoz a tomar la plaza pero el 1 de enero de 1848 los ingleses la recuperaron de nuevo para la Mosquitia. Después hubo otra escaramuza con Muñoz y de nuevo los ingleses, el 8 de febrero entraron en San Juan y subieron por el río hasta San Carlos. 

Nicaragua optó por la vía diplomática y establece conversaciones con Inglaterra implicando a los Estados Unidos. De esas conversaciones surgió el tratado Clayton-Bulwer, firmado el 19 de abril de 1850 por británicos y estadounidenses, en el que Gran Bretaña renunció a sus pretensiones sobre un futuro canal interoceánico en Nicaragua y que San Juan del Norte fuera declarado "puerto libre y territorio neutral" bajo el reino de Mosquitia.

En 1854 Nicaragua se constituyó en República y se instituyó la Presidencia por un período de cuatro años. El primer Presidente de Nicaragua fue el propio Fruto Chamorro, que asumió el nuevo cargo ese mismo año. Sin embargo, estalló una nueva guerra civil entre "legitimistas" (conservadores) y "democráticos" (liberales), por lo cual la nueva Constitución no llegó a entrar en vigor.

El 17 de octubre llegaron las tropas contratadas por Byron Cole al puerto de San Juan del Sur y se dirigieron a la conquista del fuerte de San Carlos como pasajeros en uno de los vapores de la compañía. Fueron repelidos y se vieron obligados a volver a su punto de partida. Poco después, el capitán del fuerte dio el alto a un vapor de la compañía. El capitán del barco no obedeció la orden y desde el fuerte se ordenó abrir fuego. El resultado fue la muerte de una mujer y un niño. Walker, que permanecía en Granada, reaccionó mandando fusilar a Mateo Mayorga, Ministro de Relaciones Exteriores del gobierno de Estrada.

Granada recibió la visita del embajador estadounidense, demostrándose con este hecho el apoyo de su gobierno al filibustero. Poco después, Castellón ascendió a Walker a general de brigada. Al poco tiempo, el 30 de octubre, Walker nombró presidente del gobierno provisional a Patricio Rivas desconociendo la autoridad de Castellón.

Estos sucesos se basaron en el acuerdo que Walker había firmado con el general Ponciano Del Corral, que estaba al mando de las fuerzas de Rivas, por el cual Corral sería nombrado Ministro de la Guerra y Walker Jefe militar. Cinco días después, el general Corral fue detenido y juzgado por alta traición. Condenado a muerte, murió fusilado el 8 de noviembre de 1855.

El 23 de noviembre se publicó un decreto del presidente Rivas por el cual cada adulto que llegara a Nicaragua recibiría 250 acres de tierra, cien más si era casado. Alentados por estas promesas, llegaron al país 1.200 estadounidenses más como colonos, que supusieron un importante refuerzo para Walker.

La Compañía de Tránsito pasó a ser codiciada por William Walker y para ello hizo que el presidente Rivas nombrara Ministro de Hacienda a Parker R. French, hombre de confianza del filibustero. Los dueños de la Compañía reaccionaron y lograron que el presidente de los Estados Unidos, Franklyn Pierce, prohibiera que los estadounidenses se pudieran sumar a las tropas de Walker bajo la amenaza de que iban a dejar de estar bajo el protectorado de los Estados Unidos.

Después de intentar la vía diplomática para lograr el favor del presidente de EE.UU. sin conseguirlo, el 18 de febrero de 1856 el gobierno nicaragüense publicó un decreto por el que suspendía las actividades de la Compañía y embargaba sus propiedades. Al día siguiente la concesión fue otorgada a dos hombres de confianza de Walker, quien se alió con los otros socios de Vanderbilt, a espaldas de éste. Un mes después, Valderbilt suspendió el servicio de barcos de Estados Unidos a Nicaragua.

El interés británico por San Juan del Norte, que querían integrar dentro del "Reino de la Mosquitia", la amenaza que percibía Costa Rica sobre su territorio y negocios al verse amenazado el puerto de San Juan del Norte que también era usado por los costarricenses, hicieron que se fraguara una alianza de los países vecinos, con apoyo inglés, para combatir al filibustero. A principios de 1856 ya existían condiciones para que pudieran enfrentarse con posibilidades de éxito, contra las tropas de Walker.

Después de una campaña de descrédito contra Costa Rica orquestada por Walker desde Granada, el filibustero intentó infructuosamente que un hombre de su confianza, el coronel Luis Schlessinguer, se entrevistara con el presidente costarricense Juan Rafael Mora Porras.

El presidente de Costa Rica Juan Rafael Mora Porras, contaba con un cuerpo de oficiales e infantería entrenados por instructores franceses por los últimos tres años, lo que le permitió tomar la decisión de encabezar una columna militar hacia Nicaragua. El entrenamiento y organización de los militares costarricenses era completamente desconocido por Walker.

Las tropas de Walker y las costarricenses se enfrentaron el 20 de marzo cerca de la frontera con Nicaragua, en la Hacienda Santa Rosa en Costa Rica. Las tropas de Walker fueron derrotadas en 15 minutos. Los sobrevivientes huyeron hacia Nicaragua, informando a sus superiores que fueron atacados por columnas regulares del ejército francés, dado que ellos pensaban firmemente que los pobladores centroamericanos, no poseían ninguna capacidad militar.

Una vez asegurada la Hacienda Santa Rosa los costarricenses tomaron San Juan del Sur, La Virgen y Rivas. El contraataque de Walker contra la ciudad de Rivas fue rechazado el día 11 de abril, pero una semana después el cólera arrasó la ciudad, obligando a los costarricenses a regresar a su país.

El control de la ruta de tránsito era codiciado tanto por los británicos, como por los estadounidenses, que lo hacían a través de Walker y el gobierno de Patricio Rivas.

Walker depuso al presidente Patricio Rivas el 20 de junio de 1856 y nombró presidente de Nicaragua a Fermín Ferrer. Walker, acusado de traición por Patricio Rivas, convocó elecciones presidenciales en Granada y Rivas cuyo resultado dieron la presidencia del al filibustero. Walker fue investido presidente en un solemne acto en el cual el presidente saliente fue Fermín Ferrer. El gobierno de Walker fue reconocido inmediatamente por los Estados Unidos.

En León, Máximo Jerez contaba con una fuerza de unos 500 hombres que iba creciendo con los que llegaban de El Salvador y Guatemala. En septiembre había en León más de 3.000 soldados.

El 22 de septiembre, Walker decretó el establecimiento de la esclavitud en Nicaragua (que había sido abolida en 1824), con lo que se ganó el apoyo de los estados del sur de Estados Unidos. El 24 de septiembre, las fuerzas de León ocuparon Managua, el 2 de octubre entraron en Masaya y el 31 en Rivas. El 8 de diciembre, Walker atacó el puerto de San Jorge e incendió la ciudad de Granada. Tomó San Jorge, que abandonó para tomar Rivas. San Jorge quedó en manos de los aliados y Walker y los suyos quedaron aislados en Rivas y San Juan del Norte. El cerco se mantuvo la primera mitad del año 1857, en que se comenzó a recibir asistencia desde EEUU.

Desde San Juan del Norte, Walker lanzó una ofensiva sobre los puestos de La Trinidad y el Castillo Viejo en el río San Juan, donde fue derrotado por los costarricenses, quienes efectuaron una operación anfibia, capturando todos los vapores de la Ruta del Tránsito y tomando prisioneros al personal de Walker sin disparar un tiro. El 22 de marzo comenzó el asalto a Rivas por parte de los aliados. Los soldados de Costa Rica tomaron el centro de la ciudad, pero se continuaba luchando en los barrios. El día 26 llegó el resto de las tropas, que fue conquistando la ciudad barrio a barrio. El 11 de abril todavía había resistencia en la ciudad. Mientras tanto, frente a San Juan del Sur se hallaba la corbeta de guerra Saint Mary de la armada de EE.UU.

Por el otro lado, por el puerto de San Juan del Norte en la desembocadura del río San Juan, llegaban tropas filibusteras y las tropas costarricenses que habían tomado previamente la Ruta del Tránsito y que se encontraban fuertemente armadas, se dispusieron a tomar la plaza. Un destacamento naval inglés se encuentra frente a la misma y su capitán, Comodoro John Erskine, se presta a servir de intermediario. El 13 de abril de 1857 abandonan la plaza de San Juan del Norte las tropas filibusteras.

En Rivas, Walker resiste en el centro de la ciudad. El 27 de abril los aliados cargan contra las posiciones de Walker y el capitán de la corbeta de guerra de EE.UU. Saint Mary, Charles Davis, interviene logrando sacar a Walker en su barco que deja aguas nicas a comienzos de mayo.

A finales de noviembre de 1857 William Walker ataca la ciudad de San Juan del Norte. Había obtenido recursos de los estados del sur de EE.UU. que se había ganado con el establecimiento de la esclavitud en Nicaragua. El objetivo era que Nicaragua pasara a ser un estado esclavista más de la Unión. Tras San Juan del Norte cayó Castillo Viejo y cuando ya se estaba preparando de nuevo la campaña para volver a expulsar al filibustero, éste se rinde ante el Capitán estadounidense de una flota de guerra compuesta por naves estadounidenses e inglesas, así lograr salvar su vida y regresa a los Estados Unidos.

Walker volvería a Centroamérica en 1860, esta vez a Honduras donde sería apresado y fusilado en Trujillo el 12 de septiembre de 1860.

Al concluir la Guerra Nacional de Nicaragua con la victoria deL Ejército Aliado Centroamericano, producto del Pacto Providencial entre legitimistas y democráticos, se constituye el Gobierno "Binario" ("Chachagua"), con dos Presidentes, los Generales Tomás Martínez y Máximo Jerez Tellería. 

El 15 de abril de 1858 se firmó con Costa Rica el llamado tratado Cañas-Jerez como una solución a la creciente tensión limítrofe que existía entre los dos países.

Ese mismo año se promulgó una tercera constitución, que fue la vigente durante las tres décadas siguientes, período de la historia política conocido como "Primera República Conservadora" o ""Treinta años conservadores"". Con 35 años de vigencia, es hasta hoy el período de vida democrática más duradera de la historia de Nicaragua.

Tras el período transitorio de un año en que la jefatura del estado fue ocupada por dos presidentes ("gobierno binario"), el conservador Tomás Martínez fue elegido presidente de Nicaragua para el período 1859-1863. Aunque según la Constitución de 1858 no era posible presentarse a un segundo mandato presidencial, Martínez se hizo reelegir en 1863, lo cual motivó la insurrección del liberal Máximo Jerez y del conservador Fernando Chamorro. Ambas insurrecciones fueron vencidas, y Tomás Martínez gobernó hasta 1867.

Le sucedió Fernando Guzmán (1867-1871), durante cuyo mandato continuó la inestabilidad política. Una nueva guerra civil, que estalló el 25 de junio de 1869, se resolvió gracias a la mediación estadounidense. Le sucedieron Vicente Quadra (1871-1875), Pedro Joaquín Chamorro (1875-1879), Joaquín Zavala (1879-1883), Adán Cárdenas (1883-1887), Evaristo Carazo (1887-1889) y Roberto Sacasa (1889-1893). Durante todo este período estuvo en vigencia el sufragio censitario, según el cual solo los grandes propietarios tenían derecho a emitir su voto. La normalidad fue interrumpida por el levantamiento del militar liberal José Santos Zelaya, que puso fin en 1893 a las tres décadas de dominio conservador. 

Durante la última parte de los "treinta años conservadores", el café se convirtió en el centro de la economía del país. Para dar salida a las exportaciones de este producto se mejoraron notablemente los transportes, con la introducción del ferrocarril. Se promulgaron leyes agrarias que favorecían a los grandes terratenientes cultivadores de café. 

La Costa de los Mosquitos, protectorado británico, pasó a Honduras en 1859 y, finalmente, a Nicaragua, en 1860. Sin embargo, mantendría su autonomía hasta 1894, cuando el general José Santos Zelaya, que el año anterior había llegado al poder gracias a una revolución liberal, la reintegró a Nicaragua.

El Doctor y General José Santos Zelaya (1853-1919) gobernó Nicaragua durante dieciséis años, entre 1893 y 1909, ejerciendo un gobierno ilustrado, aunque dictatorial. 

Su gestión gubernamental provocó gran desarrollo en el país de Nicaragua. Reformó al Estado promulgando leyes, códigos y reglamentos modernos, creó nuevas instituciones e introdujó el Habeas Corpus. Zelaya convirtió a Nicaragua en la nación más próspera y rica de Centroamérica. Instauró la educación primaria gratuita y obligatoria, construyó escuelas, se aumentó la cobertura del telégrafo y el servicio de correo postal. Bajo su gobierno, se dio impulso a la construcción de líneas ferroviarias, y al transporte marítimo, con la introducción de la navegación a vapor en el lago Managua y la realización de importantes obras en los puertos de San Juan del Sur y San Juan del Norte.

Bajo el signo del progreso, Zelaya inició además una serie de reformas en el país, como la institución de la enseñanza laica y del matrimonio civil, y decretó la confiscación de los bienes de la Iglesia, incluyeno la "secularización" de los cementerios que pasaron a ser administrados por el Estado.

Era partidario de la creación de unos "Estados Unidos de América Central", lo que le llevó a apoyar a otros partidos liberales de distintos países centroamericanos que pudieran defender el mismo proyecto, y a promover diversas conferencias unionistas centroamericanos, especialmente las cumbres presidenciales celebradas en Corinto y el Pacto de Corinto. Esto se evidenció en el establecimiento de una efímera federación de naciones centroamericanas, la República Mayor de Centroamérica, que duró tres años (1895-1898) y de la que solamente formaron parte, además de Nicaragua, El Salvador y Honduras. 

Su mayor logro fue en 1894 con la reintegración a Nicaragua del territorio de la Costa de los Mosquitos, o reino de Mosquitia, que estaba bajo protectorado británico.

En 1860, Inglaterra reconocía los derechos de Nicaragua sobre la Mosquitia pero aun así se reservaba ciertos privilegios que había cuidado de introducir en el tratado firmado ese año entre ambos países. Desde esa fecha la Mosquitia dejó de ser un reino y pasó a ser una reserva cuya autoridad máxima era un Jefe de la etnia misquito con la característica que el cargo de jefatura era hereditario.

Inglaterra, apoyada por Austria, que actuaba como árbitro, declaró en 1888 que Nicaragua no podía mantener fuerzas policiales ni militares en el territorio de la Mosquitia. 

En 1894 Nicaragua entra en una corta guerra contra Honduras y en el marco de este conflicto desplaza tropas a Bluefields. La presencia de los soldados nicaragüenses hace que haya cierto revuelo entre los pobladores, y el General Rigoberto Cabezas Figueroa, que comandaba las tropas, decide tomar la plaza, desconocer la autoridad del Jefe Mosco y declarar la ley marcial el 12 de febrero de 1894. Los ingleses respondieron desembarcando tropas desde el navío "Cleopatra", lanzando un ultimátum que el general Cabezas desconoce, se llegó a un acuerdo y se constituyó una autoridad provisional con representación mosquita e inglesa. 

En junio se produjeron levantamientos en Corn Island, el día 3, y en Bluefields dos días después. Los levantamientos estaban encabezados por el jefe de la reserva, Robert Henry Clarence, pero auspiciados por el vicecónsul británico E. D. Hatch (en realidad su título era de "procónsul" y no tenía "exaquátur" del gobierno de Nicaragua). En el levantamiento participaron, además de los comerciantes de Bluefields, ciudadanos estadounidenses, ingleses, jamaicanos y alemanes. Los ingleses participaron con las tropas de los navíos "Cleopatra", "Mahauk" y "Magicienme", y el capitán del crucero estadounidense "Marblehead" actuó como mediador en ciertas ocasiones.

La lucha se entabló en la ciudad de Bluefields y en El Bluff, que cayeron en manos nicaragüenses el 3 de agosto y el 31 de julio respectivamente, tomadas por las tropas al mando del General Cabezas.

La administración de Zelaya mantuvo tensas relaciones y desacuerdos con Estados Unidos, lo que llevó a éste a dar ayuda a los opositores conservadores de Zelaya en Nicaragua. 

En 1907, luego de la victoria nicaragüense en una breve guerra contra Honduras y El Salvador, resuelta en lo político con la mediación de Estados Unidos, en un tratado firmado en Chicago el 23 de abril de 1907, según el cual cada nación debería abstenerse de inmiscuirse en los asuntos de las demás, y, en caso de conflicto, las cuatro se comprometían a aceptar la decisión de un Tribunal de Justicia Centroamericano, cuya sede se instituyó en Cartago (Costa Rica). A pesar del tratado, buques de guerra estadounidenses ocuparon diversos puertos de Nicaragua. La situación llegó al punto de existir un conflicto interno entre los liberales nicaragüenses por un lado, y los conservadores y Estados Unidos por otro (que los financiaba).

Para 1909 el presidente Zelaya se negaba a contratar empréstitos financieros en Nueva York y no quería negociar la posible vía interoceánica en las condiciones que los Estados Unidos querían imponer, Zelaya buscaba el apoyo de otras potencias, ese mismo año contrató con Inglaterra un empréstito por 1.250.000 libras esterlinas para impulsar el ferrocarril al Atlántico y mejorar las finanzas del país. Al mismo tiempo, se habló de una oferta de concesión de un canal interoceánico por Nicaragua, al Japón o Alemania. 

El 10 de octubre de 1909 estalló la costa oriental (caribeña o atlántica)una rebelión contra el gobierno de Zelaya. El movimiento "revolucionario" era dirigido por el general Juan José Estrada Morales, gobernador liberal de la Costa Atlántica; por el tenedor de los libros (contador) de las minas "La Luz y Los Ángeles", Adolfo Díaz Recinos; por un militar representante de los terratenientes conservadores, Emiliano Chamorro Vargas y por el general, conservador, Luis Mena Vado. 

El cónsul estadounidense Thomas Moffat aparecía como el "Deus ex machina" del movimiento "contrarrevolucionario". El mismo Juan Estrada, ya no siendo más presidente de Nicaragua, confesaba así los hechos, en una entrevista al New York Times:

También colaboraron los dueños de las minas "La Luz and Los Angeles Mining Company", quienes se vieron obligados a entregarlas al gobierno de Nicaragua, por incumplimiento de las cláusulas del contrato de concesión. Por mera casualidad el secretario de Estado, Knox, tenía a su cargo la asesoría legal de la familia Fletcher, ex concesionaria de las minas mencionadas. 

Al enfrentar la rebelión. la superioridad del ejército leal al gobierno se sintió desde el comienzo del conflicto. 

Entonces el ministro estadounidense en Costa Rica, Willian L. Merry; se dirigió, en noviembre de 1909 al presidente de ese país, Cleto González, insinuándole que se uniera a Guatemala y El Salvador en una guerra contra Nicaragua. Estados Unidos se comprometían a proporcionar todo lo que necesitaran. Pero el plan estadounidense fracasó, dado que el interés de Costa Rica era el desarrollo económico y social de la región y una guerra solamente aumentaría los problemas sociales.

Para sofocar la rebelión, Zelaya se vio obligado a perseguir a los rebeldes en territorio costarricense. Nuevamente, el ministro estadounidense pidió que Costa Rica rompiese con Zelaya. Otra vez el gobierno costarricense se negó a luchar contra Nicaragua, dado que era claro el trasfondo político del accionar estadounidense.

Ante la negativa del gobierno de Costa Rica, Estados Unidos tomaron la opción de fortalecer el movimiento contrarrevolucionario. No había más remedio que enfrentarse abiertamente, al gobierno de Nicaragua, y no faltaron razones ni coyuntura inmediata para ello.

El gobierno del presidente William Howard Taft, que había sido elegido en las elecciones presidenciales de 1909 nombró secretario de Estado a Philander C. Knox un abogado que tenía como clientes a los dueños de las minas de oro nicaragüenses "La Luz" y "Los Ángeles Mining Company".

La recién incorporada Mosquitia estaba bajo la autoridad del general Juan José Estrada Morales que era liberal y apoyaba a Zelaya. Estrada comenzó a mantener relaciones con el cónsul estadounidense Thomas Noffat que, a su vez, mantenía excelentes relaciones con el general Emiliano Chamorro, éste conservador. Estrada se aseguró del apoyo de los Estados Unidos para un hipotético levantamiento contra Zelaya. Este apoyo se confirmó a principios de septiembre de 1909. Al día siguiente el cónsul Thomas informaba del levantamiento contra el gobierno de Zelaya por parte de los generales Juan José Estrada y Emiliano Chamorro que, según él, se produciría el día 8 de septiembre pidiendo a su gobierno apoyo y reconocimiento para el futuro gobierno. En la información que Thomas mandaba a Washington se decía que el nuevo gobierno respetaría los intereses extranjeros y que seguramente el presidente Zelaya no iba a oponer resistencia armada.

El levantamiento se produjo el día 10 de septiembre de 1909 y el secretario de Estado Knox ordenó a los barcos de guerra estadounidenses estacionados frente a Bluefields, el "Paducah" y el "Dubuque", que intervinieran en apoyo de los insurrectos. Este episodio fue la primera intervención directa de los Estados Unidos en Nicaragua, intervención que duró hasta 1925.

En 1909 algunos mercenarios extranjeros fueron capturados y ejecutados por el gobierno de Zelaya, lo que sirvió para que Estados Unidos considerase la acción como una provocación para la guerra, y el derrocamiento de Zelaya por medio de la Nota Knox, enviada por Philander Chase Knox, Secretario de Estado de Estados Unidos.

Los estadounidenses Lee Roy Cannon y Leonardo Groce y el francés Edmundo Couture, fueron sometidos a un cuidadoso proceso. Llenadas todas las formalidades y plenamente confirmada su culpabilidad, incluso se les dejó un día antes despedirse de sus familiares, así dictan como prueba sus últimas se les pasó por las armas.

Estos dos mercenarios estadounidenses militaban en el ejército rebelde (financiado por EEUU). El 2 de diciembre el encargado de negocios nicaragüense en Washington recibía una nota del gobierno estadounidense, la conocida como "Nota Knox", en la cual le decían:

Zelaya dimite el 18 de diciembre como presidente justificando su decisión con estas palabras: 

1. La coyuntura inmediata fue que dos estadounidenses, Cannon y Groce, habían sido sorprendidos con bombas en su poder destinadas a volar los barcos del gobierno de Nicaragua que navegaban en el río San Juan. Tropas de Zelaya los tomaron in fraganti. Fueron sometidos a un cuidadoso proceso. Llenadas todas las formalidades y plenamente confirmada su culpabilidad, se les pasó por las armas. 

La culpabilidad de los dos estadounidenses era indudable y su muerte fue el pretexto final para la intervención abierta de Estados Unidos en Nicaragua. 

2. Pero no era solo eso: Zelaya se había negado a aceptar un empréstito que le ofrecieron los banqueros estadounidenses con el aval del gobierno de Estados Unidos. 

3. Al mismo tiempo, Zelaya contrató un empréstito con los banqueros ingleses de la Casa Ethelburg que tenía como objetivo la construcción de un ferrocarril que uniera el Atlántico al Pacífico del país, y para, como dice el mismo Zelaya, ""Liberar al comercio nacional de ser tributario del ferrocarril de Panamá... y realizar, además, la consolidación de nuestra deuda externa"".

Pero había algo más: Estados Unidos tenía el propósito de conseguir la concesión canalera por Nicaragua y no encontraban las facilidades con Zelaya, ya que éste exigía que se garantizara la soberanía de Nicaragua y una cantidad de dinero correspondiente a la importancia de la obra. 

La actitud del gobierno de Nicaragua no encuadraba dentro de los planes políticos y financieros de la burguesía estadounidense. Zelaya era un estorbo para la diplomacia del dólar y era preciso eliminarlo.

A los países reacios a la aceptación de empréstitos de los banqueros estadounidenses, se les inducía a aceptarlos coaccionando su voluntad por medios muy variados y que resultaban tanto más eficaces cuanto más pobre y débil era el país al que oficialmente quería proteger los Estados Unidos con su apoyo pecuniario.

En el caso de Nicaragua, además de las razones económicas y financieras, la diplomacia del dólar respondía también, a razones geopolíticas ligadas a la posibilidad de la construcción de un canal Interoceánico.

Zelaya luchó contra el tremendo empuje de los estadounidenses que apoyaban y protegían a los partidarios de la contrarrevolución y de la intervención estadounidense.

La Asamblea Nacional (el Congreso designó Presidente al también liberal José Madriz Rodríguez que no fue del agrado de Estados Unidos (ya lo había expresado en la Nota Knox cuando hacía referencia a ""un candidato a la presidencia íntimamente ligado con el viejo régimen"").Madriz mandó tropas a Bluefields contra los insurrectos y toma el fuerte de El Bluff que cierra el puerto de la ciudad quedando está bajo su control. La infantería de Marina de Estados Unidos fue desembarcada en la ciudad en mayo de 1910 por lo que esta se mantuvo del lado rebelde al no poderla tomar las tropas gubernamentales. Las aduanas de Bluefields quedaban bajo control de Madriz pero la Armada de Estados Unidos estableció otra aduana bajo autoridad de Estrada, y el gobierno de EE.UU. manifestó, ante la protesta del gobierno de Nicaragua, que "cada fracción cobre derechos sólo en el territorio que se halle bajo su dominio".
José Madriz renuncia a la presidencia el 19 de agosto y poco después entran en Managua los generales Estrada Morales y Chamorro Vargas. La nueva Asamblea Nacional nombra Presidente a José Dolores Estrada Morales, quien cedió el poder a su hermano, el general sublevado Juan José, siendo nombrado vicepresidente Adolfo Díaz, que había sido empleado de las minas La Luz y Los Ángeles y era conocido por el secretario de Estado Knox. 

El día 1 de enero de 1911 los Estados Unidos reconocen al nuevo gobierno de Nicaragua. Estrada Morales firmó con Estados Unidos los Pactos Dawson (por Thomas C. Dawson, enviado del gobierno estadounidense), y convocó elecciones para formar una nueva Asamblea Constituyente, que elaboró una nueva Constitución. Entre otros cambios, el catolicismo se convertía en la religión oficial del estado, a instancias del conservador Emiliano Chamorro. Poco después Estrada Morales se ve obligado a renunciar y Díaz es nombrado Presidente de Nicaragua.

La influencia de Estados Unidos se incrementó durante el gobierno del presidente Adolfo Díaz, que puso en manos estadounidenses el control de las principales empresas estatales. 

El 29 de julio de 1912 estalló una nueva sublevación, a instancias del General Luis Mena Vado, conservador, y apoyada luego por el Doctor y General Benjamín Zeledón, liberal. Esta rebelión se conoce como la Revolución libero-conservadora de 1912 que es mal llamada "Guerra de Mena". 

Los rebeldes toman varias ciudades entre las que están Granada, bastión conservador, León y Masaya, bastiones liberales. 

El gobierno de Díaz pide la ayuda militar de los Estados Unidos y el gobierno estadounidense responde con el desembarco en puerto Corinto de Marines que sitian y atacan Granada tomada por las fuerzas del general Mena, quien la entrega sin oponer resistencia, hecho prisionero Mena es exiliado hacia Panamá. 

El mando supremo recae en el general Zeledón, quien se hace fuerte en los cerros "Coyotepe" y "La Barranca", cercanos a la asediada Masaya, los cuales mantiene hasta la batalla decisiva del 4 de octubre, cuando es abatido por soldados conservadores de "La Constabularia", leales a Díaz y conocidos como "caitudos". 

Para poner fin a esta corta pero sangrienta guerra civil nicaragüense, los Estados Unidos movilizaron hacia Nicaragua a 2.500 hombres y 8 buques de guerra. Después de la batalla de Coyotepe, solamente dejó a 400 soldados como parte de la llamada "Legación Americana".

Como consecuencia de esta última intervención, el país permanecería ocupado por Estados Unidos hasta 1933 (desde 1912 hasta el 3 de agosto de 1925, y luego desde 1926 hasta 1933, con un breve intervalo de nueve meses en medio). 

En 1914 se firmó el Tratado Bryan-Chamorro, mediante el cual se cedían a Estados Unidos todos los derechos para la construcción de un futuro canal interoceánico, a cambio de tres millones de dólares. A pesar de que el Canal de Panamá había sido construido ya en 1903, la zona continuaba siendo de interés estratégico. También por este tratado, se daba a Estados Unidos el derecho de establecer una base militar en el golfo de Fonseca durante un período de 99 años, y se le cedían en arriendo las Islas del Maíz (Corn Island), por idéntico lapso de tiempo.

Entre 1917 y 1926 Nicaragua estuvo dominada por el partido conservador. Los marines estadounidenses, presentes en el país desde 1912, se retiraron en agosto de 1925. Al año siguiente, sin embargo, se produjo un nuevo levantamiento liberal, que produjo una nueva guerra civil, la denominada Guerra Constitucionalista. 

Las negociaciones en el llamado Pacto del Espino Negro en Tipitapa entre el gobierno y los rebeldes, impulsadas por Estados Unidos, dieron lugar a un gobierno de coalición. Sin embargo, dado que el gobierno era incapaz de controlar los nuevos focos de insurrección, los marines desembarcaron de nuevo en diciembre de 1926.

En las elecciones de 1920 salió elegido Presidente Diego Manuel Chamorro que tomó posesión de su cargo ya en el año siguiente. Chamorro murió en 1923 y lo sucedió el que era su vicepresidente, Bartolomé Martínez que se marcó como objetivo el liquidar la deuda que el país tenía con unos banqueros estadounidenses. El objetivo fue cumplido el año siguiente de haber subido a la presidencia y ya libre de la carga económica, se convocaron elecciones para el mes de octubre de ese mismo año para las cuales se realizó una candidatura única entre conservadores y liberales. Como presidente iba Carlos Solórzano, conservador y para vicepresidente el liberal Juan Bautista Sacasa. 

Solórzano fue investido presidente en enero de 1925 y para agosto de aquel año ya habían salido todos los soldados estadounidenses del territorio nicaragüense. En octubre Emiliano Chamorro se alza en armas contra el gobierno y toma la Loma de Tiscapa. Para aplacar la rebelión y por consejo del gobierno de EE.UU. Solórzano nombra a Chamorro "jefe de la fuerza pública". 

Las tensiones entre ambos acaban con la dimisión del presidente que pasa los poderes presidenciales al senador Sebastián Uriza y este se los pasa a Chamorro y finalmente acaban en manos de Adolfo Díaz quedando Sacasa fuera. 

En mayo de 1926 el partidario de Sacasa, el general José María Moncada se alza en armas pidiendo el poder para Sacasa. La insurrección de los liberales estaba apoyada por el gobierno mexicano de Elías Calles. 

La respuesta de los Estados Unidos que apoyaban a los conservadores fue la de mandar de nuevo a la infantería de marina. El día de Nochebuena de 1926 desembarcaban las tropas estadounidenses en Puerto Cabezas. Para el día de Reyes de 1927 había en suelo nicaragüense más de 5.000 soldados y marinos estadounidenses apoyados por 16 buques de guerra. Adolfo Díaz justificó la intervención con estas palabras 

En febrero de 1927 ocurren los combates fratricidas más destructivos cuando los 500 hombres del llamado Ejército Liberal Constitucionalista de Occidente se enfrentan contra las tropas conservadoras leales a Díaz apoyadas por los marines en la batalla de Chinandega.

Augusto C. Sandino, que entonces contaba con 31 años de edad, acababa de volver después de pasar 5 años trabajando de mecánico en México, Honduras y Guatemala. Cuando se enteró de la insurrección liberal de Sacasa formó una fuerza armada que se sumó a las fuerzas liberales. Tras algunas derrotas se internó en las montañas de Nueva Segovia. Cuando se enteró que los mexicanos habían mandado armas se dirigió, bajando por el río Coco, a Puerto Cabezas para pedirle a Sacasa que le armara.
En Puerto Cabezas, la intervención de las tropas estadounidenses había logrado desarmar a los liberales. Los estadounidenses arrojaron las armas enviadas por lo mexicanos al mar. Cuando llegó Sandino se encontró que no había armas y que estas estaban en el fondo de la bahía. Con la ayuda de unos cuantos adeptos, entre los que se encontraban un número relevante de mujeres de la ciudad, logró recuperar 30 fusiles y 6.000 cartuchos. Después de hablar con Moncada en la ciudad de Prinzapolka se dirigió de nuevo a su base en Las Segovias.

Las fuerzas de Sandino fueron creciendo. Durante la primera mitad del año 1927 combatió a los conservadores a los que fue venciendo y tomando varias posiciones, según las indicaciones de Moncada. La última plaza tomada fue el cerro de "El Común" en Boaquillo donde permaneció hasta el Pacto del Espino Negro en Tipitapa el 4 de mayo, que según palabras de Sandino fue donde 

Por este pacto, en el que participaron el coronel estadounidense Henry L. Stimson (enviado especial del presidente Calvin Coolidge y delegado omnipotenciario del presidente de Nicaragua Adolfo Díaz), Eberhard (ministro de EE.UU. en Nicaragua), el contralmirante Julian Latimer, tres delegados de Sacasa y el general Moncada. Acordaron que Díaz seguiría de presidente hasta las elecciones de 1928 y que EE.UU. requisaría todas las armas de ambos bandos a la vez que supervisaba el proceso electoral.

Sandino se negó a aceptar el acuerdo. En contra de las indicaciones de Moncada, Sandino difundió un comunicado en el cual pedía al pueblo de Nicaragua que se sublevara contra los extranjeros. En los intentos de convencer a Sandino para que aceptara el pacto, Moncada llegó a mandar a su padre, amigo personal de él, para que le hablara y el comandante de las fuerzas de EE.UU. en Ocotal (Nueva Segovia) le hizo llegar una carta pidiéndole que depusiera las armas y las entregara bajo la amenaza de proscribirle y perseguirle. Sandino le respondió: 

No paso un día cuando el 15 de julio de 1927 las tropas de Sandino se toman la ciudad de Ocotal dando lugar Batalla de Ocotal. La ciudad fue defendida por los Marines estadounidenses y los Guardias Nacionales nicaragüenses quienes se atrincheraron en los cuarteles. Sandino se negó a incendiar la ciudad, tal como le pedían algunos de sus hombres para obligar a los marines y guardias nacionales a rendirse o aniquilarlos. Después de los "insurrectos" abandonaran Ocotal, cuando la aviación estadounidense bombardeaba y diezma la ciudad.

La persecución de Sandino se realizó con la destrucción aldeas campesinas y las matanzas de muchos campesinos por la sospecha del apoyo que podrían estar prestándole. Las tropas sandinistas sufrieron varias derrotas como la de San Fernando, en julio, o la de Las Flores poco después.

Con la llegada del otoño comenzó una campaña victoriosa tomando Telpaneca y saliendo victorioso en Las Cruces, Trincheras, Varillal y Plan Grande. Estableció su cuartel general en El Chipote, una de las alturas de Las Segovias.

Realizó diversas incursiones como el atacar y destruir la mina de La Luz, propiedad del ex secretario de Estado estadounidense Knox o la batalla de Bramadero. Las acciones de Sandino le fueron dando fama por todo el país y por los otros países de Hispanoamérica. Esa fama producía que muchos hombres llegaran dispuestos a integrarse en sus filas. A mediados de 1928 Henri Barbusse le llamaba General de Hombres Libres.

A finales del mes de noviembre de 1928 el contralmirante D.F. Sallers le invitaba a abandonar la lucha y obtener así "los consiguientes beneficios" la respuesta de Sandino fue; 

Las elecciones presidenciales de noviembre de 1928 fueron ganadas por el liberal Moncada. Moncada tomó posesión el 1 de enero de 1929. Moncada prosiguió colaborando con los estadounidenses en la persecución de Sandino. Para el mes de marzo de ese año ya se habían arrasado 70 pueblos, los bombardeos eran continuos e incluso llegaron a afectar a la vecina ciudad hondureña de Las Limas.

Sandino realizó un viaje a México para intentar conseguir apoyo. A su vuelta, el 7 de mayo de 1930 se encontró que los estadounidenses habían formado una "guardia nacional" para combatir a la guerrilla. Esa guardia se debía de pagar con fondos nicaragüenses. Debido a la endeble economía del país se cerraron las escuelas públicas para hacer frente a esos gastos. 

Para julio de 1931 los sandinistas contaban con 8 columnas de guerrilleros repartidas por todo el territorio nicaragüense. Al año era el propio Sandino el que hacía públicos los informes de las actividades de sus fuerzas. Ante las elecciones de 1932 Sandino hizo una campaña de abstención. Para esas elecciones el candidato del partido liberal era Sacasa (aunque la preferencia de la embajada estadounidense habría sido Anastasio Somoza pero este era demasiado joven e inexperto).

Sacasa ganó la presidencia y Sandino respondió nombrado al general Juan Gregorio Colindres presidente provisional del "Territorio Libre de Las Segovias" y tomó la población de San Francisco Carnicero, cerca de Managua, para apoderarse de los sellos oficiales.

Las victorias de Sandino estaban desprestigiando a los Estados Unidos y el coste de la guerra se hacía inaguantable en una economía que estaba en plena crisis, de tal forma que la población empezó a presionar a su gobierno para que abandonara Nicaragua. Una vez que Sacasa fue elegido las tropas estadounidenses empezaron a abandonar Nicaragua y cuando fue envestido presidente, el 1 de enero de 1933 ya no quedaban soldados estadounidenses en suelo nicaragüense.

Al no haber soldados extranjeros en Nicaragua y por otras presiones, Sandino llegó a un acuerdo de paz con Sacasa. La Guardia Nacional al mando de Anastasio Somoza (creada por los Estados Unidos y comandada por un hombre de su confianza) seguía con la represión en contra de los hombres de Sandino aun cuando este pedía al presidente que parara las acciones de la Guardia.

El 21 de febrero de 1934 Sandino en compañía de su padre, Gregorio Sandino, el escritor Sofonías Salvatierra y los generales Estrada y Umanzor acudían a una cena en la casa presidencial invitados por Sacasa. A la salida de dicho evento el coche en el que viajaban fue detenido justo a la salida de los jardines de la casa presidencial. El cabo de guardia que les detuvo era en realidad un mayor disfrazado, un tal Delgadillo, que les condujo a la cárcel del Hormiguero. Los detenidos pidieron que llamaran a Somoza, pero les respondieron que no podían localizarlo, por otro lado la hija de Sacasa le comunicó a su padre la detención, ya que la había visto, y Sacasa se puso en contacto con la embajada de Estados Unidos para intentar detener el asesinato.

Sandino, Estrada y Umanzor fueron llevados al monte llamado La Calavera en el campo de Larreynaga y allí, a la señal de Delgadillo, el batallón que custodiaba a los prisioneros abrió fuego matando a los tres generales. Eso ocurría a las 11 de la noche. Al oír los disparos, según testimonio de Salvatierra, Gregorio Sandino dijo, 

Un año después, Anastasio Somoza, que llegó a decir que recibió las órdenes del asesinato de Sandino del embajador estadounidense Arthur Bliss Lane, se haría con el poder del país.

Antes de salir de Nicaragua, los "marines" traspasaron el mando de los 4,000 soldados alistados en Guardia Nacional a Anastasio Somoza García, un sobrino político del presidente Sacasa que se había ganado la confianza del embajador y de los altos oficiales estadounidenses. Pronto convertiría esta fuerza militar en un formidable instrumento de poder personal. El 21 de febrero de 1934 el nuevo jefe director de la Guardia Nacional inició su ofensiva, haciendo asesinar a Sandino cuando éste salía de una cena en la casa de gobierno, a la que había sido invitado por el propio mandatario. El día siguiente desató una matanza de más de trescientos campesinos sandinistas, incluyendo mujeres y niños, que se encontraban en una cooperativa agrícola en Wiwilí, al este de Las Segovias. Luego, reorganizó las fuerzas armadas, purgando a sus adversarios y colocando a sus allegados en posiciones clave en todo el país. Finalmente, se concentró en fortalecer su influencia en el Congreso y el Partido Liberal, utilizando para ello el presupuesto del ejército, que representaba más de la mitad de los ingresos fiscales del Estado. Logrado esto, pasó a desplegar una abierta campaña para llegar a la presidencia, pese a que la Constitución vigente le inhibía de ocupar ese cargo, dado su parentesco con Sacasa y su condición de militar activo.
Con apoyo estadounidense, Anastasio Somoza García se deshizo de sus rivales políticos, incluido Sandino, que fue asesinado por oficiales de la Guardia Nacional en febrero de 1934. En 1936, Somoza se convirtió en presidente de Nicaragua. Su familia se mantendría en el poder hasta 1979.
Anastasio Somoza fue presidente de 1937 a 1947, y de 1950 a 1956 (en el intervalo, no abandonó el poder, sino que siguió detentándolo mediante hombres de paja). La primera oposición al régimen de Somoza procedió de la clase media y de la clase alta, normalmente conservadora, que vieron con disgusto como el nuevo gobernante ponía el país en manos de su familia y amigos. A causa de las limitaciones de la libertad de expresión, los esfuerzos para resistir a Somoza no tuvieron ningún resultado. Muchos opositores abandonaron el país, exiliándose en Estados Unidos. Una excepción notable fue Pedro Chamorro, editor del diario "La Prensa", el más popular del país, cuya reputación internacional y continuo rechazo de la violencia le hicieron intocable para el régimen. 

La oposición liberal fue pronto eclipsada por la marxista, de carácter más radical. El 21 de septiembre de 1956, un joven poeta liberal, Rigoberto López Pérez, logró infiltrarse en una fiesta en la que se encontraba Somoza García, disparándole en el pecho y terminando con su vida (Somoza moriría a causa de la herida poco tiempo después).

En 1961 los jóvenes políticos Carlos Fonseca Amador, Tomás Borge Martínez y Silvio Mayorga inspirados en las ideas de Augusto Sandino fundan el Frente Sandinista de Liberación Nacional y emprenden la lucha insurreccional contra la dictadura de la familia Somoza.

Los diferentes gobiernos de los Somoza contaban con el respaldo del gobierno de los Estados Unidos, el FSLN emprende una lucha de guerrillas tanto urbanas como rurales con la intención de derrocar al gobierno nicaragüense estas son conocidas como las Jornadas de Pancasán y las guerrillas de Raití y Bocay en las cuales cayeron algunos miembros de la Organización tales como Filemón Rivera, Oscar Danilo Rosales, Rigoberto Cruz mejor conocido como Pablo Úbeda y muchos más, el fracaso de estos primeros intentos guerrilleros se debió a la falta de conocimiento de la zona de operaciones y al desinterés de las poblaciones en donde operaban pues eran lugares muy despoblados. Pasada la experiencia de Pancasán se pasa a un período conocido como la de Acumulación de Fuerzas en Silencio aunque inclusive en estos años se dieron choques con la Guardia Nacional. Dada la circunstancias el FSLN se divide en tres tendencias, cada una de ellas con una visión diferente de llevar a cabo el derrocamiento de la dictadura somocista. La Tendencia Guerra Popular Prolongada, propugnaba por la lucha en la montaña sobre la base de la experiencia de la revolución cubana y sobre todo de Ernesto Che Guevara, la Tendencia Proletaria, afirmaba que el derrocamiento se daría cuando el proletariado es decir los obreros y campesinos se uniera para derribar la tiranía y por último la Tendencia Insurreccional o Tercerista que llamaba a armar al pueblo y resultó a la postre la forma a través de la cual caería Anastasio Somaza Debayle. Precisamente buscando la unidad de las tres tendencias pierde la vida Carlos Fonseca el 7 u 8 de noviembre de 1976 en Boca de Piedra, Zinica. Aunque para disminuir la represión desatada a raíz de algunos incidentes en las montañas se da el operativo conocido como Diciembre Victorioso cuando un grupo de guerrilleros bajo el mando de Eduardo Contreras se toma la casa de un ministro somocista el 27 de diciembre de 1974 fecha a partir de la cual el mundo conoció la existencia del FSLN.

En 1978, consigue un golpe magistral contra la dictadura, al llevarse a cabo un operativo, denominado ""Operación Chanchera"", efectuado por un comando guerrillero, que conllevó a la toma del edificio Palacio Nacional sede del Congreso de la República, y un número considerable de sus miembros, poniendo en evidencia las debilidades de logísticas de la Guardia Nacional.

La ofensiva guerrillera lanzada desde el norte, con el apoyo de los campesinos, de las clases obreras e industriales cansadas de la política somocista y apoyada por la acción política y la presión internacional logra que el 19 de julio de 1979 entrar triunfante en la capital, Managua, mientras que el dictador Anastasio Somoza Debayle y su familia abandona el país.
Llegando victoriosos ala plaza de las victorias un 19 de julio de 1979. Roberto Carlos Alfaro anuncia la llegada de los sandinistas y grita el famoso dicho hasta la victoria siempre.

La entrada en Managua de las tropas del FSLN (Frente Sandinista de Liberación Nacional) pone fin al poder dictatorial de los Somoza que durante 43 años se habían mantenido en el poder. El 19 de julio de 1979 da comienzo un cambio radical en Nicaragua, cambio que tendría consecuencias continentales y llevaría a la intervención, nuevamente, de Estados Unidos. Tras la intervención de EEUU comenzará un proceso de inestabilidad política y social que llevará a una Guerra Civil promovida por EEUU al final de la presidencia de Ronald Reagan y continuada por Bush padre. Los acuerdos de paz no se firmarán hasta la década de los noventa. Paralelamente comienza la llamada Revolución sandinista que se desarrollaría hasta 1990.

Acorde a una concepción ideológica socialista e incluso comunista, con fuerte presencia marxista, y con una influencia muy grande de la teología de la liberación, trataron de introducir reformas en los aspectos socioeconómicos y políticos del estado nicaragüense, tratando además los problemas relativos a la sanidad y a la educación que el país sufría. La reforma agraria fue una de las principales medidas que el nuevo gobierno puso en marcha. Sobre la base de las tierras confiscadas a la familia Somoza y los otro miembros principales de la oligarquía nicaragüense. La universalización de la sanidad con el desarrollo de un sistema de salud universal y la cruzada ce alfabetización que redujo el analfabetismo endémico de la población nicaragüense del 50% a algo menos del 13% en un corto período; fueron las acciones inmediatas en las que se empeñaron los nuevos gobernantes. El gobierno revolucionario encontró apoyo en Cuba, la URSS y otros países, en su mayoría europeos.

El cambio de gobierno en los Estados Unidos, con la pérdida de las elecciones de los demócratas y la entrada de Ronald Reagan, del partido republicano, hacen que las voces de los disidentes y contrarios a los sandinistas, sean estimadas en la Casa Blanca; que comienza a organizar, con restos de la Guardia Nacional una serie de grupos armados, denominados contras (de contrarrevolucionarios y en contraposición de la palabra "compa", de compañero, que era como se denominaban los sandinistas) que comienzan una lucha armada contra el nuevo gobierno de izquierdas. EEUU actuaría direcctamente en acciones de guerra y sería llevado ante el Tribunal Internacional de la Haya por el gobierno nicaragüense siendo condenado por el mismo (ver Nicaragua contra Estados Unidos) llegando, el gobierno estadounidense, a desobedecer el mandato de su Congreso que impedía la ayuda directa a las tropas irregulares de la Contra, produciéndose el escándalo conocido como Irangate.

Tras varios años de guerra civil y agresión que impidió el desarrollo de Nicaragua al tener que dedicar una importante parte del presupuesto del país en la defensa y tras varias negociaciones de ámbito internacional, en las elecciones de febrero de 1990 Daniel Ortega, líder y presidenciable del FSLN pierde las elecciones a la presidencia de la República.

La revolución sandinista intentó transformar el modelo histórico de relaciones entre el Estado y la sociedad nicaragüense mediante el desarrollo acelerado de la capacidad regulatoria e interventora del Estado. Esta estrategia no fue acompañada de un esfuerzo efectivo por desarrollar una capacidad social para controlar y democratizar la acción estatal. La ausencia de mecanismos de participación efectiva terminó afectando la legitimidad del régimen. De la creciente ilegitimidad del régimen sandinista se alimentó el movimiento contrarrevolucionario que se constituyó en instrumento de la política exterior de Estados Unidos de América. A partir de la instalación del gobierno del presidente Ronald Reagan en Washington, esta política se orientó hacia el desmantelamiento del proyecto revolucionario sandinista.

Las contradicciones generadas por el modelo políticoinstitucional estatista del FSLN, la guerra contrarrevolucionaria y las presiones económicas impuestas por Estados Unidos al gobierno sandinista coincidieron con el momento en el que la Unión Soviética iniciaba un proceso de transformaciones internas que eventualmente terminarían en su desolución.

En 1986 el presidente soviético Mijail Gorbachvo introdujo su programa de reestructuración económica conocido como "perestroika". Este programa tenía como objetivo la liberalización de la economía soviética para lograr su desarrollo e integración efectiva dentro de la economía mundial. La perestroika fue acompañada de un proceso de democratización del sistema político soviético ("glassnost"), y de importantes esfuerzos por mejorar las relaciones entre Washington y Moscú.

Las políticas reformistas introducidas por Gorbachov y la disensión entre la Unión Soviética y Estados Unidos debilitaron la posición del FSLN, que en poco tiempo vio reducido el apoyo político, económico y militar que el proyecto revolucionario recibía de los países del bloque soviético. Más aún, las reformas emprendidas por Gorbachov iniciaron el desmoronamiento del modelo normativo económico y político de organización del mundo socialista que el FSLN utilizaba como eje de referencia para su proyecto revolucionario.

En tan desfavorable contexto internacional, la revolución sandinista tuvo que enfrentar el virtual colapso de la economía nacional -producto del desgaste ocasionado por la guerra, la complejidad del experimento revolucionario, los errores cometidos por los responsables de la política económica del gobierno, y las presiones de Estados Unidos-, así como el agotamiento de la población nicaragüense. Para enfrentar la crisis económica, el gobierno emprendió en 1988 un programa de estabilización y ajuste macroeconómico que tuvo un impacto directo y negativo en las condiciones de vida de los sectores populares.

Las reformas de 1988 restablecieron el centralismo del mercado como eje ordenador de la economía nicaragüense. Con estas reformas, además, del Estado nicaragüense se acompasaba a las presiones e influencias de los organismos financieros internacionales, distanciándose de la sociedad y sus demandas. El proceso de adecuación del Estado nicaragüense a las fuerzas que operaban en su contexto global, y la ampliación de la brecha entre el Estado y la sociedad nicaragüense generada por este proceso iban a mantenerse y agudizarse durante la década de 1990.

En Costa del Sol, en El Salvador, el 14 de febrero de 1989 -víspera de la retirada de las tropas soviéticas de Afganistán-, los presidentes centroamericanos firmaron el "Acuerdo de Tesoro", que establecía compromisos concretos para la pacificación de la región, y que incluía la celebración de elecciones en Nicaragua en febrero de 1990.

Los acuerdos de Costa del Sol fueron ratificados en la Cumbre de Tela en agosto de 1989. A partir de ese momento los sandinistas empezaron a organizarse para la contienda electoral, en tanto que Estados Unidos iniciaba una serie de esfuerzos para asegurar la victoria de la Unión Nacional Opositora (UNO), una coalición de partidos organizados en torno al objetivo común de derrotar al sandinismo.

En febrero de 1990 se celebraron las elecciones presidenciales que otorgaron la victoria a Violeta Barrios de Chamorro, candidata de la UNO. El triunfo de la UNO se sustentó en un consenso social real, pero precario. La desesperación causada por la guerra, el fracaso del modelo sandinista en lo político y en lo económico, y la intervención de Estados Unidos, se combinaron para crear un acuerdo nacional mayoritario cuyo eje no era la índole del régimen que se quería institucionalizar, sino la oposición al régimen que se quería eliminar.

El lapso de dos meses entre la derrota del FSLN en las urnas y el traspaso del gobierno a la presidenta electa Violeta Barrios de Chamorro se caracterizó por un clima de tensa incertidumbre. Los sectores de "línea dura" de la Unión Nacional Opositora (UNO), aglutinados en torno al vicepresidente Virgilio Godoy, Arnoldo Alemán -alcalde de Managua- y los 20.000 combatientes de la Resistencia Nicaragüense (Contra), exigían el desmantelamiento de las fuerzas armadas sandinistas, la inmediata devolución de todas la propiedades confiscadas y la privatización de las empresas estatales. Mientras tanto, el FSLN proclamaba su intención de "gobernar desde abajo" con el respaldo de las organizaciones de masa, y demandaba el respeto a la integridad del Ejército Popular Sandinista, que a la fecha contaba con 96.660 soldados.

El convulso ambiente socio-político demandaba un acuerdo institucional a fin de desactivar la amenaza de una nueva guerra civil, o una intervención militar estadounidense. El 27 de febrero de 1990 se conformaron dos equipos negociadores presididos por el general Humberto Ortega y el ingeniero Antonio Lacayo, yerno de Violeta Barrios de Chamorro. La participación de Joao Soares, Secretario General de la OEA; Elliot Richardson, representante del Secretario General de las Naciones Unidas, y Jimmy Carter, expresidente de los Estados Unidos, en calidad de observadores internacionales, facilitó las conversaciones. Estas culminaron el 27 de marzo con la firma del Protocolo para la Transferencia del Mando Presidencial, conocido como "Protocolo de Transición", cuyos acuerdos más importantes contemplaban: el reconocimiento de las elecciones como base para la construcción de la democracia y la paz; seguridad jurídica a los beneficiarios de donaciones estatales de propiedades urbanas y rurales, asignadas antes del 25 de febrero de 1990; respeto a los rangos, escalafones y mandos del ejército, incluyendo la permanencia de Humberto Ortega como general en jefe del EPS (Ejército Popular Sandinista); subordinación de las fuerzas armadas y cuerpos de seguridad al poder ejecutivo; reducción significativa del ejército, y desmovilización de la Resistencia Nicaragüense antes del 25 de abril, para garantizar el traspaso de gobierno en un clima de paz.

El Protocolo de Transición reflejaba una posición pragmática que reconocía la fuerza organizativa del FSLN, y daba prioridad a la estabilidad política. No obstante, fue rechazado por la "línea dura" de la UNO, que demandaba la destitución inmediata del Comandante Ortega. Así también, exigía la penalización de la "piñata" -nombre que se dio a la distribución de millones de dólares en propiedades estatales entre dirigentes y cuadros del FSLN, a raíz de su derrota electoral-. Como resultado, ocho de los catorce partidos de la UNO se negaron a asistir al acto de toma de posesión de la presidenta Chamorro y, en adelante, obstaculizarían su administración desde los gobiernos municipales bajo su control.

Por su parte, la Resistencia Nicaragüense condicionó su desmovilización a la firma de nuevos acuerdos, según los cuales el gobierno procedió a delimitar veintidós "polos de desarrollo" -que abarcaban, en su conjunto, un área de 20.000 km cuadrados- donde los ex combatientes de la Contra recibieron tierras y recursos productivos para asentarse con sus familias, bajo la protección de fuerzas especiales de Naciones Unidas. Después de la desmovilización, concluida el 27 de junio de 1990, ex miembros de la Resistencia Nicaragüense fueron incorporados a la Policía Nacional, y encargados de garantizar el orden dentro de estas zonas de seguridad. Además, se reconoció a la Contra como una organización política legal, y algunos de sus principales dirigentes recibieron cargos en la burocracia estatal. Por otra parte, el gobierno llegó a un acuerdo con el ejército para dar inicio a un rápido proceso de reducción de efectivos, ofreciendo a los ex militares diversos beneficios, como indemnizaciones por años de servicio y asignación de viviendas o tierras. Mediante este proceso de licenciamiento gradual, se desmovilizó a 72.000 soldados en el lapso de tres años.

El desarme de la "Contra" y la drástica reducción del ejército significó tan solo el inicio del proceso de pacificación de Nicaragua. Esta meta exigía la reinserción estable de los ex combatientes a la vida civil, pero su consecución enfrentó graves problemas. La entrega de la ayuda material prometida dependía de la cooperación externa, y los trámites burocráticos frenaron el ritmo de su flujo hacia los "polos de desarrollo". Impacientes, muchos ex combatientes de la RN (Resistencia Nicaragüense) decidieron retornar a sus lugares de origen, o se dispersaron por el área rural, invadiendo empresas estatales, fincas privadas y cooperativas sandinistas. Hacia fines de 1990, alrededor de 4,000 hombres, comandados por un "Estado Mayor" integrado por cuadros intermedios de la RN, se levantaron en armas en el norte y centro del país, exigiendo la entrega inmediata de títulos agrarios y recursos productivos. Ante el surgimiento de los "recontras", unos 3,000 campesinos sandinistas y ex miembros del EPS (Ejército Popular Sandinista) se rearmaron; organizados en el Movimiento de Auto-defensa Nacional, los llamados "recompas" presentaron sus propias reivindicaciones al gobierno. A estos dos grupos se sumó un tercero: El Frente Norte "Prudencio Serrano", conocido tanto por excombatientes de la RN como del EPS.

Según datos oficiales del ejército, a mediados de 1992 el número de rearmados ascendía a 21,905 hombres, que disponían de fusiles automáticos, ametralladoras, morteros, minas e incluso misiles antiaéreos y antiblindados. A esa fecha, habían realizado alrededor de 1,600 acciones militares, que incluían asaltos a bancos y vehículos de transporte público, secuestros de funcionarios gubernamentales o productores privados, tomas de tierras y poblados, en unos veintiséis municipios rurales del interior del país. Entre 1990 y 1994, la administración de Barrios de Chamorro suscribió 48 acuerdos para lograr la desmovilización de casi un centenar de bandas armadas, a cambio de entrega de 97,863,878 dólares en ayuda material para facilitar la reinserción de los ex combatientes en la vida productiva. Además, redistribuyó un total de 701,500 manzanas de tierra a unos 24,542 beneficiarios, dando prioridad a los desmovilizados y campesinos repatriados. En adelante, el gobierno suspendió toda negociación, y los nuevos rearmados pasaron a ser perseguidos por el ejército como "bandas delictivas", al margen de su filiación política.

La transición política nicaragüense coincidió con el colapso de la Unión Soviética y de los modelos políticoeconómicos socialistas del Europa Oriental, es decir, coincidió con el final de la Guerra Fría. Estos dramáticos eventos redujeron las opciones históricas para el desarrollo político de los países del Tercer Mundo, y crearon condiciones apropiadas para el surgimiento de la democracia liberal como contraparte política del desarrollo de economías de mercado en todo el mundo.

Este contexto de fuerzas y tendencias mundiales, más que el desarrollo endógeno de la sociedad nicaragüense, explica la transición política de 1990. Así pues, en lo fundamental, el experimento democrático nicaragüense fue producto de condicionamientos externos, y no de transformaciones reales en la naturaleza de las relaciones entre el Estado y la sociedad nicaragüense. Sobre un Estado históricamente dependiente del exterior y distanciado de la sociedad civil se impuso en 1990 un sistema político de democracia electoral que ampliaría los derechos políticos de la ciudadanía dentro de un rango sumamente restringido de opciones sociales y económicas.

En lo nacional, la transición de 1990 estuvo marcada por la fragmentación política, por la virtual paralización de la economía nacional y por el debilitamiento de los niveles de solidaridad social entre los nicaragüenses. La fragmentación política tuvo su expresión en las tensiones existentes entre la Unión Nacional Opositora (UNO) y el derrotado FSLN, así como en la desarticulación de la red de organizaciones populares que habían surgido durante la década de la revolución.

En lo económico, la transición de 1990 tuvo lugar en un momento en que la estructura productiva del país se encontraba prácticamente en ruinas. Un informe del gobierno de Violeta Barrios de Chamorro señalaba que, para 1989, el Producto Interno Bruto del país había caído al 42% de su nivel en 1977; el valor de las exportaciones se había reducido en un 53%, y los salarios reales a un 24%. Más aún, en 1989 la deuda externa per cápita era la más alta de América Latina: 3,000 dólares estadounidenses (treinta y tres veces el valor de las exportaciones del país). Además de la polarización política y del colapso económico del país, Nicaragua sufría en 1990 el desgarramiento social producido por la guerra civil.

El gobierno Barrios de Chamorro señalaba que la guerra y la militarización había sustraído a la juventud de las actividades del país, interrumpiendo así el proceso intergeneracional de transferencia de actitudes y habilidades, lo que dejó a los jóvenes sin motivación y sin el entrenamiento necesarios para trabajar.

Con una sociedad débil y fragmentada, y un Estado subordinado, en lo político y en lo económico, a la política exterior estadounidense, a la cooperación externa y a las pautas de los organismos financieros internacionales, se organizó un sistema político de democracia electoral que creó condiciones para la participación del pueblo nicaragüense en la elección de sus gobernantes, pero no necesariamente para el desarrollo de una capacidad social que pudiese condicionar la acción del Estado. En este sentido, la transición política en Nicaragua produjo una democracia externamente restringida, por cuanto los procesos electorales que constituían su característica principal operarían dentro de un marco normativo que limitaba el rango de opciones sociales y económicas que el nuevo sistema político ofrecía a la población.

Dentro de los espacios de participación creados por la transición de 1990, surgieron en Nicaragua un conjunto de organizaciones cívicas no gubernamentales de diversas orientaciones políticas, y de diferentes especialidades profesionales y temáticas. Estas organizaciones recibieron un apoyo importante de parte de la cooperación internacional interesada en promover la conformación de una "sociedad civil" en Nicaragua.

La sociedad civil nicaragüense, sin embargo, no logró constituirse en un mecanismo efectivo para la agregación de demandas sociales, debido a su fragmentación, a su bajo nivel de representatividad popular efectiva, y a su dependencia respecto de la cooperación internacional. Quizá el sector más exitoso dentro del proceso de formación de la sociedad civil nicaragüense durante el periodo 1990-1996 haya sido el de las organizaciones feministas, que en 1995 lograron trascender las divisiones políticoideológicas que fragmentaban a la sociedad nicaragüense y consolidaron la Coalición Nacional de Mujeres.

La debilidad de los partidos políticos y de las organizaciones de la sociedad civil crearon las condiciones para que la Iglesia católica nicaragüense recuperara el terreno político que había perdido durante la década de 1980. El nuevo poder de la iglesia católica se manifestó en la consolidación de su líder, el cardenal Miguel Obando y Bravo, como la personalidad pública que gozó de mayor legitimidad entre el pueblo nicaragüense durante el periodo 1990-1996.

El poder de la Iglesia Católica se manifestó también en su capacidad para condicionar las políticas del Estado, especialmente en el área de la educación. La agenda del Ministerio de Educación durante el gobierno de Barrios de Chamorro estuvo articulada en torno a dos ejes: a) un rechazo total al sandinismo como movimiento político y como experiencia histórica; b) la voluntad de introducir en los programas de educación un fuerte componente religioso, fundamentalmente determinado por los intereses de la Iglesia católica nicaragüense.

Al finalizar el régimen de Barrios de Chamorro la dependencia externa del Estado nicaragüense se expresaba en su total acatamiento del marco normativo neoliberal para pautar su política económica, así como en los altos niveles de participación de la cooperación externa en el financiamiento de los gastos estatales. Durante el periodo 1990-1996 el monto promedio anual otorgado por la cooperación externa al gobierno de Nicaragua fue de 538.4 millones de dólares estadounidenses. Este monto equivalía al 30.2% del Producto Interno Bruto promedio anual del país durante este mismo período. Mientras tanto, la pobreza afectaba a un 56.4% de la población del país, según un estudio elaborado por la Fundación Internacional para el Desarrollo Económico Global.

Por otra parte, la sociedad civil había ganado visibilidad durante el régimen de Barrios de Chamorro, aunque era mínima su capacidad para incidir en la acción del Estado al concluir este período. Así pues, la democracia nicaragüense era en 1996 una democracia política diseñada para institucionalizar la práctica del voto popular y las libertades propias del sistema democrático electoral, dentro de los límites normativos que imponía el sistema económico internacional y sus instituciones.

En resumen, eran enormes los retos que enfrentaba el país en 1996 para ampliar y profundizar el modelo de gobernabilidad democrática adoptado en 1990: un explosivo nivel de pobreza, una economía desarticulada y sin un claro sentido de orientación estratégica, una débil estructura de derechos ciudadanos, un Estado dependiente de la cooperación externa y de los organismos financieros internacionales, y las presiones de la globalización. Al mismo tiempo, el gobierno de Violeta Barrios de Chamorro terminaba su mandato habiendo logrado un alto nivel de pacificación en la zonas del país afectadas por los conflictos armados que surgieron después de concluida la guerra civil. El gobierno Barrios de Chamorro, además, dejaba como legado político una relación cívico militar estable, y un respeto a la libertad de prensa sin precedentes en la historia del país.

El gobierno de la presidenta Barrios de Chamorro se propuso impulsar un cambio estructural en el ámbito económico, a fin de sustituir la economía mixta y planificada del régimen sandinista por una economía de libre mercado. La tarea no era fácil, pues la capacidad productiva del país se encontraba gravemente deteriorada. En 1990 el Producto Interno Bruto per cápita era de US$ 400.00 (cuatrocientos dólares estadounidenses), aproximadamente la mitad del existente en 1980. Las exportaciones cayeron de US$ 680 millones en 1978 a un promedio de US$ 284 millones durante el quiquenio 1985-1990. Mientras tanto, la deuda externa pasó de US$ 1,500 millones en 1980 a US$ 10,000 millones en 1990 -cifra cinco veces mayor que el valor del Producto Interno Bruto del país-. La hiperinflación era del orden del 13,500 por ciento. La crisis económica colocaba al nuevo gobierno en una situación de alta dependencia con respecto a los organismos financieros internacionales. Estos condicionaron el flujo de recursos externos para reactivar la economía a la adopción de un severo programa de estabilización y ajuste estructural, que debía aplicarse bajo la supervisión del Fondo Monetario Internacional (FMI).

En abril de 1990 el gobierno anunció un plan que prometía reducir la inflación a cero en cien días. Éste contemplaba la acuñación de una nueva moneda -el córdoba oro- cuyo valor se fijó a la par del dólar estadounidense, así como un conjunto de medidas neoliberales: reducción masiva del sector público y de los gastos sociales, eliminación del subsidio al precio de productos de consumo básico, restricción del crédito, y aumento en las tarifas de los servicios públicos e impuestos directos. Además, se anunció el inicio de la privatización de las empresas estatales, con el doble objetivo de devolver aquellas propiedades injustamente confiscadas, y vender las restantes para sanear las finanzas públicas. La respuesta del FSLN fue una violenta huelga general que paralizó Managua, obligando al gobierno a buscar un pacto económico y social, que se concretó con la firma de los llamados acuerdos de Concertación I y II, entre octubre de 1990 y agosto de 1991. El logro más importante del FSLN fue el compromiso del gobierno de transferir el 25 por ciento de las empresas estatales a los trabajadores, representados por sus sindicatos.

La relativa "paz social" obtenida mediante estos pactos socioeconómicos permitió a la administración Barrios de Chamorro acceder a un considerable flujo de recursos externos. Entre 1990 y 1996 la cooperación internacional representó un promedio del 30 por ciento del PIB anual; aunque la amortización de la deuda externa consumía el 60% de la ayuda económica neta recibida cada año por el país. No obstante, cabe anotar que al satisfacer a sus acreedores, el gobierno pudo negociar la condonación de 6,092 millones de dólares de la deuda contraída durante la década de 1980. Hacia 1993 la administración Barrios de Chamorro había logrado la estabilidad macroeconómica del país. Después de una década de estancamiento y recesión, la economía mostró un crecimiento del 3.2 por ciento en 1994 y del 4 por ciento en 1995.

Estas metas se alcanzaron a un grave costo social para las mayorías empobrecidas. Las políticas de ajuste estructural conllevaron una reducción del gasto público del 14% en 1996, con relación a 1990. Tal recorte mermó la capacidad del gobierno de enfrentar la pobreza extrema, un fenómeno estructural que se había venido extendiendo de manera creciente desde la década de 1970. En efecto, los altos niveles de pobreza legados por el régimen somocista se agravaron como resultado de la guerra las políticas de estabilización iniciadas por el FSLN en 1988. La aplicación aún más estricta de tales políticas bajo la administración Barrios de Chamorro, amplió la brecha de la pobreza y agudizó la polarización social. Entre 1991 y 1996 el desempleo abierto creció a un promedio anual del 6.4%. El presupuesto para educación y salud fue recortado, en tanto que los programas integrales de bienestar social fueron sustituidos por proyectos coyunturales, con escaso financiamiento. De acuerdo con un estudio realizado por Naciones Unidas en 1994, el 75% de las familias nicaragüenses vivía por debajo del nivel de pobreza, y el 44% se encontraba en una situación de extrema pobreza.

Uno de los aspectos más controversiales de la transición a una economía de mercado impulsada por la administración Barrios de Chamorro, se refiere al destino de las empresas industriales y agropecuarias que aún quedaron en manos del Estado después de la "piñata" sandinista. El nuevo gobierno creó la Corporación Nacional del Sector Público (Cornap) para llevar a cabo su privatización. Este proceso se desarrolló mediante decretos ejecutivos, sin una adecuada supervisión por parte de la Contraloría General de la República.

En el año 1996 la Cornap informó haber vendido 495 empresas por un valor de 26 millones de dólares, e incurrido en pérdidas por el orden de los 59.8 millones de dólares, debido a los altos costos de operación estas transacciones. A pesar de ello, un estudio del economista Mario De Franco divulgado a través de la CEPAL demostró que las transferencias realmente efectuadas por la Cornap a empresarios privados fluctuaron entre los 155 y los 833 millones de dólares; es decir entre 6 y 32 veces el valor de las ventas brutas reportado. El informe final de la Cornap no incluyó información sobre la identidad de los adquirientes de las propiedades estatales, lo que alimentó las dudas en cuanto a la transparencia de los procedimientos utilizados.

El proceso de privatización conllevó otros problemas jurídicos, relacionados con la inscripción de las propiedades en los registros públicos, sobre todo en el sector rural. En vista de la presión por la tierra, las UPE, o empresas agropecuarias estatales, fueron redistribuidas. Hacia finales de 1993 el 80 por ciento de éstas habían sido privatizadas: un 35% devueltas a sus antiguos dueños; un 31% divididas entre ex trabajadores de las UPE, y el 34% restante asignadas a desmovilizados de la Resistencia y el Ejército. Este proceso generó muchos conflictos en torno a los derechos de propiedad. El problema era de gran magnitud, pues el 40% de las tierras se hallaba en litigio, enfrentandoa 122,000 familias de todos los estratos sociales y políticos: campesinos contra campesinos, campesinos contra hacendados, élite tradicional versus la nueva élite sandinista, e incluso dirigentes del FSLN entre sí. Las disputas legales con frecuencia devinieron en confrontaciones violentas, sobre todo a raíz del retorno al país de miles de exiliados, que reivindicaban sus derechos de posesión sobre tierras confiscadas en la década anterior.

Por otro lado, la desaparición de las UPE (empresas agropecuarias estatales) implicó la reducción de los empleos permanentes en el campo en un 72%. Este proceso fue acompañado por una drástica caída del financiamiento (crédito) para los pequeños y medianos productores agropecuarios. Las tasas de interés cobradas por el Banco Nacional de Desarrollo (Banades) pasaron a ser las más altas en Centroamérica. Entre 1990 y 1992 el número de clientes rurales que recibieron préstamos disminuyó en un 80%, y la porción del crédito concentrado en los grandes productores aumentó en un 40%. Las políticas de apoyo a la producción en gran escala estimularon el aumento d las exportaciones, cuyo valor pasó de 284 millones de dólares en 1990 a 350 millones en 1994, y a 490 millones en 1995. No obstante, en ese último año el Banades entró en crisis, debido a la incapacidad de recobrar la cartera de préstamos en mora, otorgados sin garantías adecuadas a personas allegadas a los círculos de poder. La mitad de la suma adeudada al Banades había ido a parar a manos de 22 grandes deudores, entre los que figuraban altos funcionarios de esa institución estatal.

Mientras tanto, estrangulados por la falta de recursos productivos, decenas de miles de beneficiarios de la reforma agraria se vieron obligados a vender sus tierras y emigrar a los países vecinos en busca de empleos. El descontento provocado por las políticas económicas y sociales de la administración de la presidente Barrios de Chamorro se reflejó en los resultados de las elecciones presidenciales, celebradas en octubre del año 1996. El partido Proyecto Nacional (Pronal), fundado por Antonio Lacayo, ministro de la Presidencia y yerno de la presidenta saliente, recibió apenas el 9,323 votos. En contraste, el candidato de la Alianza Liberal, Arnoldo Alemán, obtuvo 904,908 votos gracias a promesas de una pronta mejoría económica, pero sobre todo a su habilidad para capitalizar el miedo de un 51% de los ciudadanos nicaragüenses a un retorno del comandante Daniel Ortega al poder.

Veintitrés partidos y alianzas políticas participaron en las elecciones del 20 de octubre de 1996. De estas 23 organizaciones, la Alianza Liberal -liderada por su candidato Arnoldo Alemán- y el FSLN -liderado por su candidato Daniel Ortega- constituían las principales fuerzas políticas del país.

Durante la campaña electoral, la Alianza Liberal logró capitalizar a su favor el recuerdo de la guerra y de la crisis económica sufridas en el país durante la década de la revolución, para crear un ambiente electoral que indujera a la población a escoger entre el "pasado sandinista" o la continuación de la apertura democrática. El FSLN, por su parte, intentó presentar una imagen democrática y renovada. Por otra parte, los múltiples esfuerzos que emprendieras diversas agrupaciones políticas por organizar un movimiento de "centro" se articuló simplemente como un proyecto político que se ubicada ideológicamente entre el FSLN y la Alianza Liberal.

La estrategia política de la Alianza Liberal recibió un impulso decisivo durante la última fase de la campaña electoral, cuando la Iglesia católica nicaragüense hizo explícito su apoyo a la candidatura de Arnoldo Alemán. El 17 de octubre de 1996, durante el periodo de "silencio electoral" establecido por la ley antes de las elecciones, el cardenal Miguel Obando y Bravo ofició una misa en la catedral metropolitana de Managua ante la presencia del candidato presidencial liberal y del candidato liberal a la alcaldía de Managua. En su homilía, el cardenal Obando y Bravo recurrió a una parábola para prevenir al pueblo contra los engaños de las "víboras". Era una clara alusión al candidato sandinista Daniel Ortega, a quien Arnoldo Alemán había llamado "culebra" durante la campaña. Para reforzar el impacto y la efectividad del mensaje político del cardenal Obando y Bravo, los diarios "La Prensa" y "La Tribuna" publicaron el día de las votaciones una fotografía a color en la que aparecía el cardenal Obando y Bravo bendiciendo a Arnoldo Alemán y a su compañero de fórmula (el ingeniero Enrique Bolaños Geyer).

Los resultados electorales pusieron en evidencia el virtual monopolio que habían logrado imponer el FSLN y la Alianza Liberal sobre el electorado nicaragüense. La Alianza Liberal recibió el 51.3% de los votos, en tanto que el FSLN obtuvo el 37.75% por ciento. Tal y como lo señalara la revisto Envío, "los otros partidos que participaron en las elecciones a la Presidencia acumularon entre todos el 11.22% de los votos válidos. De estos partidos, 19 no lograron alcanzar ni siquiera el 0.60% del total de los votos válidos del electorado nacional".

Durante el gobierno liberal de Arnoldo Alemán, el Estado continuó dependiendo de la cooperación externa y adecuándose a los requerimientos de los organismos internacionales. De acuerdo con el Programa de las Naciones Unidas para el Desarrollo (PNUD), en 1999 el monto de la cooperación externa recibida por este gobierno equivalía a un 22% del Producto Interno Bruto del país. Mientras tanto, continuaron debilitándose las organizaciones populares surgidas durante la revolución sandinista. Las organizaciones de la sociedad civil que habían surgido a partir de 1990, por su parte, impulsaron múltiples e infructuosos esfuerzos por desarrollar una capacidad social para democratizar la acción del Estado.

Ni siquiera la crisis social generada por el huracán "Mitch" en octubre de 1998 demostró tener la fuerza suficiente para contrarrestar la brecha que separaba al Estado de la sociedad nicaragüense. Los daños humanos, ecológicos y materiales ocasionados por el huracán "Mitch" fueron calificados por varios observadores como "de proporciones bíblicas".

La propuesta de desarrollo formulada por la sociedad civil nicaragüense para la reconstrucción del país tras el huracán "Mitch" estaba basada en una premisa básica: la solución de la vulnerabilidad social y ecológica en Centroamérica requería la transformación de las estructuras sociales que definían la distribución del poder la riqueza social en la región. A su vez, la transformación de tales estructuras requería la revisión de los modelos de desarrollo que habían guiado la evolución histórica de la región y, especialmente, la evolución de las relaciones entre Estado y sociedad en Nicaragua. La Coordinadora Civil para la Emergencia y Reconstrucción de Nicaragua señalaba: "Queremos una reconstrucción que no nos regrese a la 'normalidad' en la que estábamos antes del huracán, sino que nos permita superar la exclusión y la marginalidad en la que han vivido amplios sectores de la población, y una utilización más adecuada de nuestros recursos naturales".

El impacto del huracán "Mitch", lejos de debilitar el modelo de relaciones entre el Estado y la sociedad nicaragüense, fue transformado en un evento facilitador del desarrollo y consolidación de este modelo. El alivio de la deuda externa, la obtención de nuevos recursos externos, y la solicitud del ingreso de Nicaragua a la iniciativa de alivio de deuda del Banco Mundial fueron medidas que se tradujeron en un mayor nivel de autonomía estatal respecto de la sociedad civil, la que, pese a sus esfuerzos, demostró carecer de los derechos ciudadanos y de la fuerza política necesaria para condicionar las prioridades y la acción del Estado.

La dependencia externa del Estado y la debilidad de la sociedad civil nicaragüense facilitaron la externalización del conflicto social; es decir, su desplazamiento fuera del espacio político y legal nicaragüense. Así, el debate generado por el impacto social del huracán Mitch no se organizó dentro del marco políticoinstitucional nicaragüense, sino más bien en torno a la comunidad donante, que se constituyó en fuente de recursos financieros y también de legitimidad. En estas circunstancia, los afectados por el huracán se vieron convertidos en elementos pasivos que dependían de la interacción entre las organizaciones de la sociedad civil, el Estado, los países donantes y los organismos internacionales.

La ausencia de mecanismos de participación políticas capaces de regular la acción del Estado creó las condiciones para la proliferación de la corrupción administrativa y para la impunidad. Durante el período 1990-1996 varios funcionarios del régimen Barrios de Chamorro se vieron envueltos en casos de corrupción. Además, el proceso de privatización impulsado por este gobierno se efectuó con muy poca transparencia.

Fue durante el régimen de Arnoldo Alemán, sin embargo, cuando la corrupción se convirtió en un problema sistémico que llegó a alcanzar niveles comparables a los del somocismo. En la lucha contra la corrupción, los medios de comunicación desempeñaron un papel protagónico al desenmascarar a los culpables y presentar evidencias de su responsabilidad.

Un estudio realizado entre la población urbana de Managua por el Instituto de Encuestas y Sondeos de la revista Envío, en abril de 1999, mostraba que el 45.2% de los entrevistados pensaba que el gobierno de Arnoldo Alemán había sido el más corrupto de la historia de Nicaragua. Un 26.5% opinaba que todos los gobiernos de Nicaragua habían sido igualmente corruptos. Un 16.8% señalaba al gobierno del FSLN como el más corrupto de la historia del país, en tanto que apenas un 1.8% señalaba al gobierno de Violeta Barrios de Chamorro como el más corrupto de los gobiernos nicaragüenses. El resto de los entrevistados opinó que la corrupción le era indiferente, o no supo responder.

Para febrero del año 2000 una encuesta de opinión realizada por el Instituto de Estudios Nicaragüense (IEN) mostraba que el 89% de la opinión pública pensaba que la corrupción afectaba al funcionamiento del gobierno y la administración pública del país. Las principales expresiones de este fenómeno, según los entrevistados, eran la vida ostentosa de los funcionarios públicos, el rápido e inexplicable aumento de sus patrimonios personales, el aprovechamiento de sus cargos públicos para la promoción de sus negocios particulares, sus sueldos exorbitantes y el tráfico de influencias.

Durante el régimen de Arnoldo Alemán la corrupción administrativa, la impunidad de los culpables y la incapacidad del sistema judicial para aplicar las leyes del país mostraron con dramática claridad las debilidades del modelo de gobernabilidad democrática adoptado en 1990, y, más específicamente, la ausencia de una sociedad civil con la capacidad para condicionar la acción del Estado. Esta debilidad es particularmente notable si se toma en cuenta que el gobierno de Alemán -a diferencia de los gobiernos somocistas- no contaba con el apoyo de un aparato represivo para sofocar las presiones sociales. Así pues, diez años después de la transición hacia un modelo de gobernabilidad democrática, el Estado nicaragüense continuaba gravitando sobre una sociedad que no contaba con la capacidad para controlar la conducta de sus gobernantes.

Al concluir el siglo XX, el Estado y el sistema político del país habían caído bajo el control del partido gobernante y del FSLN, los que poco después de las elecciones de 1996 habían iniciado un proceso de acercamiento y colaboración. Este proceso alcanzó su expresión más concreta en enero de 1999, cuando el Partido Liberal Constitucionalista (PLC) del presidente Arnoldo Alemán y el FSLN (liderado por Daniel Ortega) consumaron un pacto que tendría graves consecuencias para el desarrollo político nicaragüense. El pacto entre el PLC y el FSLN se vio respaldada por la influencia ideológica que la Iglesia católica nicaragüense mantenía sobre un importante sector de la población y, en particular, por la ambigua posición que adoptara esta institución religiosa ante el fenómeno de la corrupción y la impunidad.

Sobre la base del pacto PLC-FSLN, estas dos organizaciones políticas se repartieron el poder de la Corte Suprema de Justicia, en el Consejo Supremo Electoral, en el Consejo Superior de la Contraloría, en la Procuraduría de Derechos Humanos y en la Superintendencia de Bancos. El pacto, además, hizo posible la aprobación de una ley que resolvió el problema de "la piñata": la adquisición fraudulenta, por parte de miembros del FSLN, de propiedades del Estado y de particulares durante los meses posteriores a su derrota electoral en el año 1990. El pacto, por otra parte, dejó abiertas las puertas para la introducción de una reforma constitucional que perpetuaría el poder de los dos partidos pactantes.

Así pues, el precario orden social nicaragüense aparecía organizado dentro de una estructura informal de colaboración entre tres instituciones: el gobernante PLC, el FSLN y la Iglesia católica nicaragüense. Cada uno de estos tres actores apostaba por mantener y desarrollar su poder dentro de esa relación de mutua conveniencia. El pacto político les aseguraba al Frente Sandinista de Liberación Nacional y al Partido Liberal Constitucionalista la posición de gobierno o de partido principal de oposición dentro del sistema político nicaragüense. El colaboracionismo entre la Iglesia y el PLC, por otra parte, le otorgaba a la jerarquía católica un importante grado de influencia dentro del sistema político nicaragüense, así como el apoyo del Estado en su lucha contra la creciente popularidad de las religiones protestantes. Por su parte, el FSLN intentaba acercarse a la Iglesia católica, cuyo apoyo parecía indispensable para mantener el orden social en un país sometido a los explosivos niveles de probreza que sufría Nicaragua: para 1998 este nivel alcanzaba al 72.6% de la población, de acuerdo con los cálculos del Programa de las Naciones Unidas para el Desarrollo.

A comienzos del siglo XXI Nicaragua vivía una crisis de gobernabilidad que se hacía evidente en la corrupción que afectaba el funcionamiento de la administración pública del país, en el fenómeno de la impunidad -denunciado repetidamente por los medios de comunicación- y en la pérdida de legitimidad del Estado y del sistema político nicaragüense -registrada en numerosas encuestas de opinión pública realizadas durante ese periodo-. Esta crisis de gobernabilidad generaba a su vez una crisis de seguridad ciudadana que se manifestaba en la desesperanza expresada por el pueblo nicaragüense en diversos reportajes periódicos e investigaciones académicas; y en el sentimiento de amenaza contra la seguridad personal revelado por múltiples encuestas.

Se entiende la gobernabilidad como la capacidad que posee el Estado y el sistema político de un país para resolver sus conflictos sociales. De tal manera que una crisis de gobernabilidad es la existencia de una condición real o potencial de desorden social que se deriva de la incapacidad de un sistema político y de sus respectivas instituciones públicas de regular las tensiones y contradicciones propias de la vida en sociedad.

La seguridad ciudadana, por su parte, es una condición psicosocial que consiste en la confianza que poseen los miembros de una sociedad para organizar, controlar y planificar su existencia. Así, la inseguridad es la ausencia de tal confianza. El desarrollo de una situación de seguridad ciudadana requiere la existencia de condiciones sociales humanamente adecuadas, estables, y predecibles; en tanto que el concepto de gobernabilidad se refiere a la existencia de una capacidad políticoinstitucional para crear y reproducir estas condiciones.

El orden social y la seguridad ciudadana que generan los sistemas consolidados de gobernabilidad democrática dependen fundamentalmente, en primer lugar, de la existencia de Estados que cuenten con la capacidad para filtrar influencias externas así como para organizar y regular las relaciones sociales que operan dentro de su base territorial; y, en segundo lugar, de la existencia de sociedades civiles organizadas que cuenten con la capacidad de condicionar el poder del Estado. La capacidad soberana y de regulación del Estado facilita la construcción política del orden social en lo nacional, mientras que el control democrático de esta capacidad asegura que el orden generado por la acción estatal responda a las necesidades y demandas de la sociedad.

En la gran mayoría de los países de América Latina, el desarrollo histórico de las relaciones entre Estado y sociedad no han logrado generar las condiciones necesarias para la consolidación de sistemas de gobernabilidad democrática. La dependencia externa del Estado, aunada a la exclusión abierta y sistemática de amplios sectores sociales, ha facilitado el desarrollo de estructuras de poder estatal que hasta el día de hoy gozan de altos niveles de autonomía respecto de la sociedad. A su vez, ello ha hecho posible el surgimiento de gobiernos que disponen de la facultad de ignorar las demandas y necesidades de la población.

La doble condición de dependencia externa y de autonomía doméstica que caracteriza al Estado latinoamericano adquiere ribetes especiales en el caso nicaragüense, por el fenómeno de la intervención extranjera que desde el periodo inmediatamente posterior a la independencia dificultó no sólo la democratización del Estado, sino su misma nacionalización.

Desde esta perspectiva, lo que caracteriza el desarrollo histórico de las relaciones entre Estado y sociedad en Nicaragua no es simplemente la ausencia de una estructura de derechos ciudadanos capaz de democratizar el funcionamiento del Estado, sino la ausencia de élites y movimientos sociales capaz de nacionalizarlo. La nacionalización del Estado consiste en generar niveles de soberanía que faciliten un control nacional mínimo sobre los factores que determinan el desarrollo histórico de una sociedad.

Así pues, las luchas por la independencia, los vaivenes de las Provincias Unidas del Centro de América antes de su fragmentación, la presidencia de William Walker y la Guerra Nacional, la precaria estabilidad social de los Treinta Años Conservadores, la caída de Zelaya, el proyecto de ingeniería social que se inicia a partir de 1909, el somocismo, y la derrota del sandinismo han sido eventos y procesos históricos fuertemente condicionados -y en algunos casos simplemente determinados- por fuerzas e influencias externas.

Los condicionamientos externos que históricamente han contribuido a separar el Estado de la sociedad nicaragüense adquirieron una relevancia especial durante el periodo de la revolución sandinista. Inicialmente la revolución fue un proyecto fundamentado en valores que desafiaban la dinámica histórica nicaragüense. Frente a la dependencia externa de un país condicionado por la constante repetición del fenómeno de la intervención extranjera, la revolución sandinista aspiraba a la construcción a la construcción de una patria soberana; y frente a la realidad de la pobreza y desigualdad social en Nicaragua, la revolución liderada por el Frente Sandinista de Liberación Nacional (FSLN) proponía la edificación de una sociedad organizada según la "lógica de las grandes mayorías".

Señalar que la soberanía y la justicia social fueron dos de los valores centrales que guiaron el desarrollo inicial del proyecto revolucionario sandinista no es glorificar o idealizar la conducta y el pensamiento político del FSLN, sino simplemente señalar una realidad que se expresó claramente en el discurso y en la práctica revolucionaria de esta organización política antes y después del triunfo de julio de 1979. Los abusos de poder, la corrupción y la violación de los derechos humanos que ocurrieron durante la década de 1980 son realidades que coexistieron con el proyecto de creación de una Nicaragua justa y soberana.

Sin embargo, a finales de la década de 1990 el sistema político nicaragüense estaba ampliamiente dominado bajo el espectro del pacto suscrito entre Arnoldo Alemán del PLC (partido gobernante), y Daniel Ortega del FSLN (partido de oposición), en el que aseguraban la repartición de poder en las principales entidades del Estado y sus poderes.

Nicaragua entró al período preelectoral, que culminaría el 04 de noviembre de 2001, en un ambiente marcado por el pacto entre el PLC y el FSLN. el 28de enero de 2001 se llevaba a cabo la convención del PLC, de la que emergió como candidato a la presidencia Enrique Bolaños Geyer, vicepresidente del país con Alemán. Bolaños, nacido el 13 de mayo de 1928 en Masaya y graduado en Ingeniería en la universidad estadounidense de Saint Louis, tenía en su haber una dilatada y exitosa carrera empresarial desarrollada en los ámbitos del agro y la industria. Asímismo, fue un caracterizado dirigente de organizaciones patronales a partir de 1979, cuando fue elegido presidente de la Asociación de Algodoneros de Oriente (ADADO), director de la Unión de Productores Agropecuarios de Nicaragua (UPANIC) y director de la Cámara de Industrias de Nicaragua (CADIN). También fue dirigente del Consejo Superior de la Empresa Privada (COSEP). Decidido opositor del régimen sandinista, fue detenido por breve tiempo en tres ocasiones, acusado de violar las leyes de excepción implantadas por el gobierno para hacer frente a las guerrillas de la "Contra", mientras parte de sus fincas eran expropiadas en el curso de la reforma agraria y algunas de sus plantas fabriles eran confiscadas. Con tal motivo, fue indemnizado por el Estado en la década de 1990.

Por otro lado, el 25 de febrero de 2001 el congreso del FSLN confirmó la candidatura de Daniel Ortega Saavedra para las elecciones presidenciales de noviembre de ese mismo año, a las que concurriría, en coalición con varios partidos políticos pequeños de variadas tendencias; esta agrupación sería denominada Convergencia Nacional. Se trató de la cuarta vez que el líder sandinista, de 55 años de edad para entonces, disputó la jefatura del Estado; en 1984 había obtenido la victoria, mientras que fue derrotado en 1990 por Violeta Barrios de Chamorro y en 1996 por Arnoldo Alemán. Pero tanto la imagen como el discurso de Ortega en la campaña electoral de 2001 poco tenían que ver con su pasado revolucionario.

Tras 16 años de gobiernos neoliberales y conservadores en las lecciones celebradas el 5 de noviembre de 2006 el candidato sandinista, Daniel Ortega vence con un 38% de los votos.

Las políticas liberales y conservadoras de los gobiernos de Chamorro, Alemán y Bolaños llevaron al país a una situación en la que el 80% de sus casi seis millones de habitantes en el umbral de la pobreza (ingresos de menos de dos dólares diarios), la mitad en paro o en subempleo, salarios de 100 dólares al mes y una deuda externa de 6.500 millones de dólares tras la condonación de cuatro de cada cinco dólares que debía. Aunque en ese periodo la economía de Nicaragua fuera una de las de mayor crecimiento en América Central y el FSLN mantuviera una amplia presencia en los diferentes ámbitos de poder.

El FSLN, con varias escisiones como la del Movimiento Renovador Sandinista (que obtenía un 6,89% de los votos) realizó una campaña basada en la reconciliación y como segundo hombre, detrás de Ortega, puso Jaime Morales Carazo, un antiguo "contra", supuesto agente de la CIA. La coyuntura latinoamericana, con Venezuela Bolivariana, con Bolivia, Ecuador, Brasil y otros países con gobiernos progresistas favorecieron el sandinista.

Las primeras acciones de gobierno del FSLN fueron el restablecer la gratuidad de los servicios de Educación y Salud. En educación se prohíbe el cobro en las escuelas públicas, de matrículas, mensualidades, material escolar y otros insumos. En Salud se eliminan las consultas privadas en los centros públicos y se restablece la gratuidad de los medicamentos, las operaciones quirúrgicas y las pruebas clínicas que se realicen en los centros sanitarios dependientes del Estado.

En las elecciones municipales nicaragüenses del pasado 9 de noviembre del 2008, el FSLN obtuvo el 48.79% de los votos frente a su rival más inmediato el Partido Liberal Constitucionalista que obtuvo el 45.88%, mientras que el ALN obtuvo el 3.80% de los votos, PRN O.86% y AC 0.67%. El FSLN ganó 10 departamentos (Nueva Segovia, Estelí, Madriz, Chinandega, León, Managua, Masaya, Carazo, Rivas y Matagalpa) y el PLC: 7 (Granada, Chontales, Boaco, Jinotega, RACCN, RACCS y Río San Juan). Para un total de 105 alcaldías (13 cabeceras departamentales) incluyendo la capital Managua, en contraposición a 37 del PLC (5 cabeceras departamentales) y el ALN ganó 4 Alcaldías (ninguna cabecera departamental).Sin embargo, ciertas anomalías y la falta de observadores internacionales en las elecciones, originó un descontento social y el rechazo de los resultados por parte de la oposición.




</doc>
<doc id="21867" url="https://es.wikipedia.org/wiki?curid=21867" title="GNU Bison">
GNU Bison

GNU bison es un programa generador de analizadores sintácticos de propósito general perteneciente al proyecto GNU disponible para prácticamente todos los sistemas operativos, se usa normalmente acompañado de flex aunque los analizadores léxicos se pueden también obtener de otras formas.

Bison convierte la descripción formal de un lenguaje, escrita como una gramática libre de contexto LALR, en un programa en C, C++, o Java que realiza análisis sintáctico. Es utilizado para crear analizadores para muchos lenguajes, desde simples calculadoras hasta lenguajes complejos. Para utilizar "Bison", es necesaria experiencia con la sintaxis usada para describir gramáticas. 

GNU bison tiene compatibilidad con Yacc: todas las gramáticas bien escritas para Yacc, funcionan en Bison sin necesidad de ser modificadas. Cualquier persona que esté familiarizada con Yacc podría utilizar Bison sin problemas.

Bison fue escrito en un principio por Robert Corbett; Richard Stallman lo hizo compatible con Yacc y Wilfred Hansen de la Carnegie Mellon University añadió soporte para literales multicaracter y otras características.



</doc>
<doc id="21874" url="https://es.wikipedia.org/wiki?curid=21874" title="Cobalto">
Cobalto

El cobalto (del alemán "kobalt", voz derivada de "kobolds", los "gnomos" que, según los mineros de Sajonia de la Edad Media, eran espíritus de la tierra que tenían embrujado el mineral, por lo que, aunque parecía mena de cobre, no producía este elemento con el tratamiento habitual) es un elemento químico de número atómico 27 y símbolo Co situado en el grupo 9 de la tabla periódica de los elementos.

Se le denominaba "kobold" en la Edad Media por los mineros que consideraban este metal sin valor y tenían la creencia de que un buen duende (un "kobold") lo ponía en sustitución de la plata que había robado. En el diccionario castellano del siglo XVIII aparece como "cobalt".

El cobalto es un metal ferromagnético, de color blanco azulado. Su temperatura de Curie es de 1388 K. Normalmente se encuentra junto con níquel, y ambos suelen formar parte de los meteoritos de hierro. Es un elemento químico esencial para los mamíferos en pequeñas cantidades. El Co-60, un radioisótopo de cobalto, es un importante trazador y agente en el tratamiento del cáncer.

El cobalto metálico está comúnmente constituido de una mezcla de dos formas alotrópicas con estructuras cristalinas hexagonal y cúbica centrada en las caras siendo la temperatura de transición entre ambas de 722 K.

Se emplea sobre todo en superaleaciones de alto rendimiento, siendo éstas normalmente más caras que las de níquel. Es un metal eminentemente de aleación, al igual que el níquel o el zinc, por ejemplo. Dichos metales suelen agregarse a otros que actúan de base, aunque cuando el Cobalto actúa de base suele hacerlo en aleaciones con cromo. Su principal característica es su elevadísima dureza y resistencia al desgaste. Son aleaciones normalmente poco usadas ya que su virtud no compensa la gran cantidad que hay que abonar por ellas. El cobalto posee características muy similares a sus elementos vecinos, hierro y níquel, con los cuales comparte más rasgos que con los elementos de su propio grupo en la tabla periódica.
Ni cobalto ni níquel suelen mezclarse con la plata ni el mercurio (siendo ambos raras excepciones) además de que comparten el efecto magnético del hierro. El cobalto es el metal más escaso de estos tres, es el menos rentable y también el más caro. Encuentra pocos usos en la industria en comparación a sus vecinos inmediatos. Se trata de uno de los pocos elementos químicos monoisotópicos. El cobalto tiene poca resistencia química aunque es más estable que el hierro ya que se mantiene en aire y agua siempre que no se encuentren otros elementos corrosivos en dichos medios.

Presenta estados de oxidación bajos. Los compuestos en los que el cobalto tiene un estado de oxidación de +4 son poco comunes. El estado de oxidación +2 es muy frecuente, así como el +3. También existen complejos importantes con el estado de oxidación +1.

Los compuestos de cobalto se han utilizado durante siglos para obtener un color azul intenso de vidrio, los esmaltes y cerámicas. Se ha detectado cobalto en esculturas egipcias y en joyas persas desde el tercer milenio aC, en las ruinas de Pompeya (destruida en el año 79 dC), y en China, en la dinastía Tang (618-907 dC) y la dinastía Ming (1368-1644 dC).

El cobalto se ha empleado para colorear el vidrio desde la Edad del Bronce. La excavación del naufragio Uluburun encontró un lingote de cristal azul, que fue confeccionado durante el siglo XIV AC. artículos de cristal azul de Egipto son de color con el cobre, el hierro o el cobalto. La más antigua de cobalto de color de cristal era de la época de la dinastía XVIII de Egipto (1550-1292 aC). Se desconoce el lugar donde se obtuvieron los compuestos de cobalto.

El elemento fue descubierto por el químico sueco George Brandt. La fecha del descubrimiento varía en las diversas fuentes entre 1730 y 1737. Mostrando que es un nuevo elemento hasta entonces desconocido diferente de bismuto y otros metales tradicionales, y decir que es un nuevo "semi-metal". Brandt fue capaz de demostrar que el cobalto era el responsable del color azul del vidrio que previamente se atribuía al bismuto. El cobalto se convirtió en el primer metal descubierto desde la época pre-histórica, en la que todos los metales conocidos (hierro, cobre, plata, oro, zinc, mercurio, estaño, plomo y bismuto) no tenían descubridores registrados.

Su nombre proviene del alemán "kobalt" de "kobold", llamado así por los mineros por su color, toxicidad y los problemas que ocasionaba ya que al igual que el níquel contaminaba y degradaba los elementos que se deseaba extraer. Los primeros intentos de fundición de estas menas para obtener metales como el cobre o el níquel, fracasaban dando en su lugar simplemente un polvo (óxido de cobalto (II)). Además, debido a que los minerales primarios de cobalto siempre contienen arsénico, la fundición de estas menas oxidaba el contenido de arsénico para dar el altamente tóxico y volátil, óxido de arsénico, lo que también disminuye el aprecio de estas menas para los mineros.

Durante el siglo XIX, una parte significativa de la producción mundial, entre el 70 y 80%, de azul cobalto (un tinte hecho con compuestos de cobalto y alúmina) y esmalte (vidrio de cobalto en polvo para uso con fines de pigmento en cerámica y pintura) se llevó a cabo en la fábrica noruega Blaafarveværket adquirida en 1823 por el barón W. C. Benecke y el industrial prusiano Benjamin Wegner. Las primeras minas para la producción de esmalte entre los siglos XVI al XVIII se encontraban en Noruega, Suecia, Sajonia y Hungría. Con el descubrimiento de mineral de cobalto en Nueva Caledonia en 1864 la extracción de cobalto en Europa disminuyó. Con el descubrimiento de yacimientos minerales en Ontario, Canadá en 1904 y de yacimientos aún mayores en la provincia de Katanga en el Congo en 1914, las operaciones mineras cambiaron de nuevo. Por el conflicto de Shaba a partir de 1978, la principal fuente de cobalto, las minas de cobre de la provincia de Katanga, casi detuvieron su producción. El impacto en la economía mundial de cobalto de este conflicto fue menor de lo esperado, porque la industria establecida formas efectivas para reciclar de materiales de cobalto y en algunos casos fue capaz de cambiar a alternativas sin cobalto.

En 1938 John Livingood y Glenn Seaborg descubrieron el cobalto-60. La primera máquina de radioterapia, "bomba de cobalto", construida en Canadá por un equipo liderado por Ivan Smith y Roy Errington se utilizó en un paciente el 27 de octubre de 1951; el equipo se encuentra actualmente expuesto en el "Saskatoon Cancer Centre", en la ciudad de Saskatoon (Saskatchewan).

Después de la Segunda Guerra Mundial, los EE. UU. quería asegurase de que nunca le faltaría el mineral de cobalto necesario, como le había ocurrido a los alemanes y fue la exploración de una fuente dentro de la frontera de los EE. UU. Un buen suministro de los minerales necesarios se encuentra en Idaho cerca del cañón Blackbird en la ladera de una montaña. La Compañía Minera Calera comenzó la producción en este lugar

En 2005, los depósitos de cobre en la provincia de Katanga (antigua provincia de Shaba) de la República Democrática del Congo fueron el principal productor de cobalto con casi el 40% cuota mundial, según informa el Servicio Geológico Británico. La situación política en el Congo influye en el precio de cobalto de manera significativa.

El proyecto de la Montaña Mukondo, operado por la Central African Mining and Exploration Company (CAMEC) en Katanga, puede ser la más rica reserva de cobalto en el mundo. Se estima que será capaz de producir alrededor de un tercio de la producción total mundial de cobalto en el 2008. En julio de 2009 CAMEC anunció un acuerdo a largo plazo en virtud del cual CAMEC entregaría toda su producción anual de concentrado de cobalto de la Montaña Mukondo a "Zhejiang Galico Cobalt & Nickel Materials" de China.

Existen varios métodos para separar el cobalto del cobre y níquel. Dependen de la concentración de cobalto y la composición exacta del mineral utilizado. Una etapa de separación implica flotación por espuma, en el que los tensioactivos se unen a los diferentes componentes del mineral, dando lugar a un enriquecimiento de mena de cobalto. Tras el tostado se convierte la mena a sulfato de cobalto, mientras que el cobre y el hierro se oxida al óxido. La lixiviación con agua extrae el sulfato junto con los arseniatos. Los residuos están además lixiviado con ácido sulfúrico obteniéndose una solución de sulfato de cobre. El cobalto también puede ser lixiviado de la escoria de la fundición de cobre.

Los productos de los procesos mencionados anteriormente se transforman en óxido de cobalto (CoO). Este óxido se reduce al metal por la reacción aluminotérmica o reducción con carbono en un alto horno.


Debido a los varios estados de oxidación que presenta, existe un abundante número de compuestos de cobalto. Los óxidos CoO (temperatura de Néel 291 K) y CoO (temperatura de Néel 40 K) son ambos antiferromagnéticos a baja temperatura.

Se han caracterizado 22 radioisótopos siendo los más estables el Co-60, el Co-57 y el Co-56 con periodos de semidesintegración de 5,2714 años, 271,79 días y 70,86 días respectivamente. Los demás isótopos radiactivos tiene periodos de semidesintegración inferiores a 18 horas y la mayoría menores de 1 segundo. El cobalto presenta además cuatro metaestados, todos ellos con periodos de semidesintegración menores de 15 minutos.

La masa atómica de los isótopos del cobalto oscila entre 50 uma (Co-50) y 73 uma (Co-73). Los isótopos más ligeros que el estable (Co-59) se desintegran principalmente por captura electrónica originando isótopos de hierro, mientras que los más pesados que el isótopo estable se desintegran por emisión beta dando lugar a isótopos de níquel.

El cobalto-60 se usa en radioterapia en sustitución del radio por su menor precio (y considerando que el radio se desintegra en radon que es un elemento radiactivo y se presenta en forma de gas, por lo que es difícil encapsularlo para evitar contaminación radiactiva). Produce dos rayos gamma con energías de 1,17 MeV y 1,33 MeV y al ser la fuente empleada de unos dos centímetros de radio provoca la aparición de zonas de penumbra dispersando la radiación en torno a la dirección de radiación. El metal tiende a producir un polvo muy fino que dificulta la protección frente a la radiación. La fuente de Co-60 tiene una vida útil de aproximadamente 5 años, pero superado ese tiempo sigue siendo muy radiactivo, por lo que estas fuentes han perdido, en cierta medida, su popularidad en occidente.

El cobalto es esencial en todos los animales, incluyendo los humanos. Forma parte de la cobalamina (Vitamina B12). Una deficiencia de cobalto puede llevar a anemia. Pese a ello, la anemia secundaria por déficit de cobalto es muy rara, debido a que basta con consumir trazas del elemento para mantener la correcta homeostasis. Además, el cobalto es un elemento que se encuentra en varios alimentos, siendo difícil un déficit por baja ingesta. 

Las proteínas basadas en la cobalamina usan el anillo de corrina para mantener unido el cobalto. La coenzima B12 proporciona el enlace C-Co, el cual participa en las reacciones.

El cobalto metálico en polvo finamente dividido es inflamable. Los compuestos de cobalto en general deben manipularse con precaución por la ligera toxicidad del metal.

El Co-60 es radiactivo y la exposición a su radiación puede provocar cáncer. La ingestión de Co-60 conlleva la acumulación de alguna cantidad en los tejidos, cantidad que se elimina muy lentamente. En una eventual confrontación nuclear, la emisión de neutrones convertiría el hierro en Co-60 multiplicando los efectos de la radiación tras la explosión y prolongando en el tiempo los efectos de la contaminación radioactiva; con este propósito se diseñan algunas armas nucleares denominadas "bombas sucias" (del inglés "dirty bomb"). En ausencia de guerra nuclear, el riesgo proviene de la inadecuada manipulación o mantenimiento de las unidades de radioterapia.




</doc>
<doc id="21875" url="https://es.wikipedia.org/wiki?curid=21875" title="Níquel">
Níquel

El níquel es un elemento químico cuyo número atómico es 28 y su símbolo es Ni, situado en el grupo 10 de la tabla periódica de los elementos.

El 87 % de las hidrogenasas contienen níquel, especialmente en aquellas cuya función es oxidar el hidrógeno. El níquel sufre cambios en su estado de oxidación lo que indica que el núcleo de níquel es la parte activa de la enzima.

El níquel está también presente en la enzima metil con reductasa y en bacterias metanogénicas.

Es un metal de transición de color blanco con un ligerísimo tono amarillo, conductor de la electricidad y del calor, muy dúctil y maleable por lo que se puede laminar, pulir y forjar fácilmente, y presentando ferromagnetismo a temperatura ambiental. Es otro de los metales muy densos como el hierro, iridio y osmio. Se encuentra en distintos minerales, en meteoritos (aleado con hierro) y, en principio, hay níquel en el interior de la Tierra principalmente en su núcleo, donde se trata del segundo metal más abundante por detrás del hierro, metal con el que comparte numerosas características similares.

El níquel es aleado con hierro para proporcionar tenacidad y resistencia a la corrosión, en los aceros austeníticos el níquel es esencial puesto que al ser un metal gammágeno estabiliza la austenita. Es resistente a la corrosión y se suele utilizar como recubrimiento, mediante electro deposición. El metal y alguna de sus aleaciones, como la aleación Monel, se utilizan para manejar el flúor y algunos fluoruros debido a que reacciona con dificultad con estos productos. Su coste roza la mayoría de las veces el primer puesto entre los precios de los metales comunes en los mercados dedicados a los metales.
Es un producto absolutamente esencial para el desarrollo de la industria, además de uno de los metales más demandados. Reacciona con dificultad en medios agresivos y se considera resistente a la corrosión; no sufre el llamado efecto "galleo" el cual sí padece el cobre, por ejemplo.

Su estado de oxidación más normal es +2. Puede presentar otros, se han observado estados de oxidación 0, +1 y +3 en complejos, pero son muy poco característicos.

El uso del níquel se remonta aproximadamente al siglo IV a. C., generalmente junto con el cobre, ya que aparece con frecuencia en los minerales de este metal. Bronces originarios de la actual Siria tienen contenidos de níquel superiores al 2%. Manuscritos chinos sugieren que el «cobre blanco» se utilizaba en Oriente hacia 1700 al 1400 a. C.; sin embargo, la facilidad de confundir las menas de níquel con las de plata induce a pensar que en realidad el uso del níquel fue posterior, hacia el siglo IV a. C.

Los minerales que contienen níquel, como la niquelina, se han empleado para colorear el vidrio. En 1751 Axel Frederik Cronstedt, intentando extraer cobre de la niquelina, obtuvo un metal blanco que llamó níquel, ya que los mineros de Hartz atribuían al «viejo Nick» (el diablo) el que algunos minerales de cobre no se pudieran trabajar; y el metal responsable de ello resultó ser el descubierto por Cronstedt en la niquelina, o "Kupfernickel", diablo del cobre, como se llama aún al mineral en idioma alemán.

Según un diccionario etimológico italiano, níquel proviene del sueco "nickel", que viene del alemán "Kupfernickel", propiamente ‘falso cobre’, compuesto de "Kupfer" (cobre) y "Nickel" (sobrenombre de Nikolaus), nombre dado por los mineros a los minerales inútiles, usado en broma para indicar un mineral que del cobre tiene sólo el color.

Hoy en día es muy frecuente encontrarlo en las monedas de cualquier país, donde debido a su elevado coste se alea con cobre. Estas monedas suplantaron a las de plata alrededor de mediados del siglo XX, provocando en ocasiones confusión. Algunos ejemplos son los cinco céntimos de Estados Unidos o el disco interno de una moneda de un euro.

La primera moneda de níquel puro se acuñó en 1881.

El níquel aparece en forma de metal en los meteoritos junto con el hierro (formando las aleaciones kamacita y taenita). También se encuentra en el núcleo de la Tierra junto al hierro, iridio y osmio, formando con estos tres metales una aleación de estructura metálica. Combinado se encuentra en minerales diversos como garnierita, millerita, pentlandita y pirrotina.

Las minas del Canadá, Cuba y Rusia producen hoy día el 70 % del níquel consumido. Otros productores mayores son Bolivia, Colombia, Nueva Caledonia provincia de ultramar de Francia y República Dominicana.

La niquelina (NiAs), la garnierita (SiO[Ni, Mg]•2 HO), este último es uno de los minerales más utilizados en la extracción del níquel, también existen los sulfuros, de ellos los más importantes son los sulfuros de hierro y níquel, pentlandita y pirrotita (Ni, Fe) xSy, otros minerales que se encuentran en la naturaleza son los arseniuros, silicatos, sulfoarseniuros.

En la naturaleza se encuentran 5 isótopos estables: Ni, Ni, Ni, Ni y Ni, siendo el más ligero y el más abundante (68,077 %). Se han caracterizado además 18 isótopos radioactivos de los que los más estables son el Ni, el Ni y el Ni con periodos de semidesintegración de 76.000 años, 100,1 años y 6,077 días respectivamente. Los demás radioisótopos, con masas atómicas desde 52 uma (Ni) a 74 uma (Ni), tienen periodos de semidesintegración inferiores a 60 horas y la mayoría no alcanzan los treinta segundos. El níquel tiene además un estado metaestable.

El Ni se produce en grandes cantidades en supernovas de tipo II correspondiendo la forma de la curva de luz a la desintegración del Ni en Co y éste en Fe.

El Ni es un isótopo de larga vida obtenido por cosmogénesis. Este isótopo ha encontrado diversas aplicaciones en la datación radiométrica de meteoritos y en la determinación de la abundancia de polvo extraterrestre en hielos y sedimentos. El Ni es hijo del Fe (periodo de semidesintegración de 1,5 millones de años) cuya persistencia en el sistema Solar en concentraciones suficientemente altas ha podido causar variaciones observables en la composición isotópica del Ni, de este modo, el análisis de la abundancia de Ni en materiales extraterrestres puede proporcionar información sobre el origen del sistema solar y su historia primordial.

La exposición al níquel metalico y sus compuestos solubles no debe superar los 0,05 mg/cm medidos en niveles de níquel equivalente para una exposición laboral de ocho horas diarias y cuarenta semanales. Los vapores y el polvo de sulfato de níquel se sospecha que sean cancerígenos.

El carbonilo de níquel (Ni(CO)), generado durante el proceso de obtención del metal, es un gas extremadamente tóxico.

Las personas sensibilizadas pueden manifestar alergias al níquel. La cantidad de níquel admisible en productos que puedan entrar en contacto con la piel está regulada en la Unión Europea; a pesar de ello, la revista "Nature" publicó en 2002 un artículo en el que investigadores afirmaban haber encontrado en monedas de 1 y 2 euros niveles superiores a los permitidos, se cree que debido a una reacción galvánica.

Aproximadamente el 65 % del níquel consumido se emplea en la fabricación de acero inoxidable austenítico y otro 12 % en superaleaciones de níquel. El restante 23 % se reparte entre otras aleaciones, baterías recargables, catálisis, acuñación de moneda, recubrimientos metálicos y fundición:




</doc>
<doc id="21877" url="https://es.wikipedia.org/wiki?curid=21877" title="Spirit of St. Louis">
Spirit of St. Louis

Spirit of St. Louis "(El Espíritu de San Luis)" es el nombre del aeroplano con el que el piloto Charles Lindbergh cruzó el Atlántico en un vuelo en solitario sin escalas de Nueva York a París en mayo de 1927. Aunque sea conocido como el primer vuelo que atravesó el Atlántico, la realidad es que ya en 1922, los portugueses Gago Coutinho y Sacadura Cabral, habían hecho la ruta Lisboa-Río de Janeiro. Cuatro años más tarde, en 1926 el español Ramón Franco realizó un vuelo con escalas entre Palos de la Frontera y Buenos Aires, a bordo del Plus Ultra.

El avión fue fabricado en San Diego, California. Los industriales que financiaron el vuelo transatlántico eran hombres de Saint Louis, por lo que se le dio al avión el nombre de esa ciudad. Lindbergh participó en el diseño y en la construcción del aparato, modelo Ryan NYP (una adaptación del Ryan M-2), siendo un proyecto de Donald Hall. En sólo dos meses había terminado la fabricación del "Spirit of St. Louis". Se trataba de un avión con alas de implantación alta, con estructura de madera. El fuselaje era de tubos de acero, y el revestimiento exterior era de tela.

Contrariamente a los aviones de los competidores de Lindbergh, su avión era un monomotor equipado con un Wright Whirlwind J-5C de 223 C.V. Lindbergh opinaba que era mejor disponer de un solo motor, ya que a un avión con carga máxima un segundo motor tampoco podría mantenerlo en el aire si fallaba el primero. Además, un avión con dos o tres motores era más propenso a tener fallos en alguno de ellos. 

El depósito de combustible principal quedó alojado delante del puesto de mando, por razones de centrado del peso, como en todos los aviones, es decir que independientemente de la cantidad de combustible restante la posición del centro de gravedad no varía. De esta forma,al aumentar su capacidad al máximo, Lindbergh sacrificó la visibilidad hacia adelante, la cual quedó reducida a lo que podía ver a través de un periscopio que tenía delante. La capacidad total de combustible fue de 1.705 L, lo que significó un peso superior a la mitad del peso total del avión, que fue de 2.380 kg.

El avión fue diseñado en todas sus piezas de forma que ofreciese la mínima resistencia al aire y que su peso fuese también lo más bajo posible. Para ello se prescindió de numerosos elementos que en otros aviones eran usuales, como, por ejemplo, el instrumento indicador del nivel de combustible y el aparato de radio. Incluso el asiento del piloto fue sustituido por una ligera silla de mimbre.

Despegue: de San Diego en vuelo hacia Nueva York.
Durante este trayecto bate un récord de velocidad. 
El 20 de mayo de 1927 salió de un campo de aviación en Nueva York, "Roosevelt Field", en dirección a París. Allí llegó 33 h y 32 min más tarde, a las 10:22, aterrizando en el aeródromo de "Le Bourget", donde fue recibido con un enorme entusiasmo por miles de personas. Lindbergh había volado sin interrupción 3.600 millas.

Después de volar a Bélgica e Inglaterra, el Spirit of St. Louis viajó de vuelta a Estados Unidos en el crucero de guerra USS Memphis (CL-13) (junio 1927). Tras los festejos y numerosos vuelos promocionales por Estados Unidos, Centroamérica, Colombia y Venezuela y finalmente el Caribe, fue entregado al Instituto Smithsoniano para su conservación el 30 de abril de 1928. 
El Spirit of St. Louis se encuentra actualmente expuesto en el Museo del Aire y del Espacio, Washington, DC, EE. UU. Numerosas copias se han hecho a lo largo de la historia para vuelos conmemorativos y para exhibición en museos.



</doc>
<doc id="21878" url="https://es.wikipedia.org/wiki?curid=21878" title="Zinc">
Zinc

El zinc (del alemán "Zink"), también escrito cinc, es un elemento químico esencial de número atómico 30 y símbolo Zn, situado en el grupo 12 de la tabla periódica de los elementos.

La etimología de zinc parece que viene del alemán "Zink", este del "Zinken" (en español pico, diente), para indicar el aspecto con filos dentados del mineral calamina, luego fue asumido para el metal obtenido a partir de él, aunque otras fuentes consideran que viene de la palabra persa para "piedra".

En el español, las variantes gráficas «zinc» y «cinc» son ambas aceptadas como válidas. Sin embargo, la forma con "z", «zinc», es la más coherente con el origen de la palabra y, por tanto, con su símbolo químico internacional (Zn).

El zinc es un metal, a veces clasificado como metal de transición aunque estrictamente no lo sea, ya que tanto el metal como su ion positivo presentan el conjunto orbital completo. Este elemento presenta cierto parecido con el magnesio, y con el cadmio de su grupo, pero del mercurio se aparta mucho por las singulares propiedades físicas y químicas de este (contracción lantánida y potentes efectos relativistas sobre orbitales de enlace). Es el 23.º elemento más abundante en la Tierra y una de sus aplicaciones más importantes es el galvanizado del acero.

Es un metal de color blanco azulado que arde en el aire con llama verde azulada. El aire seco no le ataca pero en presencia de humedad se forma una capa superficial de óxido o carbonato básico que aísla al metal y lo protege de la corrosión. Prácticamente el único estado de oxidación que presenta es el +2. En el año 2004 se publicó en la revista "Science" el primer y único compuesto conocido de zinc en estado de oxidación +1, basado en un complejo organometálico con el ligando pentametilciclopentadieno. Reacciona con ácidos no oxidantes pasando al estado de oxidación +2 y liberando dihidrógeno (antiguamente llamado hidrógeno) y puede disolverse en bases y ácido acético.

El metal presenta una gran resistencia a la deformación plástica en frío que disminuye en caliente, lo que obliga a laminarlo por encima de los 100 °C. No se puede endurecer por y presenta el fenómeno de fluencia a temperatura ambiente —al contrario que la mayoría de los metales y aleaciones— y pequeñas cargas el más importante.

Las aleaciones de zinc se han utilizado durante siglos —piezas de latón datadas en 1000-1500 a. C. se han encontrado en Canaán y otros objetos con contenidos de hasta el 87% de zinc han aparecido en la antigua región de Transilvania— sin embargo, por su bajo punto de fusión y reactividad química el metal tiende a evaporarse por lo que la verdadera naturaleza del metal no fue comprendida por los antiguos.

Se sabe que la fabricación de latón era conocida por los romanos hacia 30 a. C. Plinio y Dioscórides describen la obtención de "aurichalcum" (latón) por el procedimiento de calentar en un crisol una mezcla de "cadmia" (calamina) con cobre; el latón obtenido posteriormente era fundido o forjado para fabricar objetos.

La fundición y extracción de zinc impuro se llevó a cabo hacia el año 1000 en la India —en la obra "Rasarnava" (c. 1200) de autor desconocido se describe el procedimiento— y posteriormente en China y a finales del siglo XIV los indios conocían ya la existencia del zinc como metal distinto de los siete conocidos en la Antigüedad, el octavo metal. En 1597 Andreas Libavius describe una «peculiar clase de estaño» que había sido preparada en la India y llegó a sus manos en pequeña cantidad a través de un amigo; de sus descripciones se deduce que se trataba del zinc aunque no llegó a reconocerlo como el metal procedente de la calamina.

En occidente, hacia 1248, Alberto Magno describe la fabricación de latón en Europa, y en el siglo XVI ya se conocía la existencia del metal. Georgius Agricola (1490-1555) observó en 1546 que podía rascarse un metal blanco condensado de las paredes de los hornos en los que se fundían minerales de zinc; añadiendo en sus notas que un metal similar denominado "zincum" se producía en Silesia. Paracelso fue el primero en sugerir que el "zincum" era un nuevo metal y que sus propiedades diferían de las de los metales conocidos sin dar, no obstante, ninguna indicación sobre su origen; en los escritos de Basilio Valentino se encuentran también menciones del "zincum". A pesar de ello, en tratados posteriores las frecuentes referencias al zinc, con sus distintos nombres, se refieren generalmente al mineral no al metal libre y en ocasiones se confunde con el bismuto.

Johann Kunkel en 1677 y poco más tarde Stahl en 1702 indican que al preparar el latón con el cobre y la calamina esta última se reduce previamente al estado de metal libre, el zinc, que fue aislado por el químico Anton von Swab en 1742 y por Andreas Marggraf en 1746, cuyo exhaustivo y metódico trabajo "Sobre el método de extracción del cinc de su mineral verdadero, la calamina" cimentó la metalurgia del zinc y su reputación como descubridor del metal.

En 1743 se fundó en Bristol el primer establecimiento para la fundición del metal a escala industrial pero su procedimiento quedó en secreto por lo que hubo que esperar 70 años hasta que Daniel Dony desarrollara un procedimiento industrial para la extracción del metal y se estableciera la primera fábrica en el continente europeo.

Tras el desarrollo de la técnica de flotación del sulfuro de zinc se desplazó a la calamina como mena principal. El método de flotación es hoy día empleado en la obtención de varios metales.

La principal aplicación del zinc —cerca del 50 % del consumo anual— es el galvanizado del acero para protegerlo de la corrosión, protección efectiva incluso cuando se agrieta el recubrimiento ya que el zinc actúa como ánodo de sacrificio. Otros usos son éstos:


El zinc es un elemento químico esencial para los seres humanos y ciertos animales. El cuerpo humano contiene alrededor de 40 mg de zinc por kg y muchas enzimas funcionan con su concurso: interviene en el metabolismo de proteínas y ácidos nucleicos, estimula la actividad de aproximadamente 100 enzimas, colabora en el buen funcionamiento del sistema inmunitario, es necesario para la cicatrización de las heridas, interviene en las percepciones del gusto y el olfato y en la síntesis del ADN. El metal se encuentra en la insulina, las proteínas dedo de zinc ("zinc finger") y diversas enzimas como la superóxido dismutasa.

Hay 2-4 gramos de zinc distribuidos en todo el cuerpo humano. La mayoría del zinc se encuentra en el cerebro, los músculos, los huesos, el riñón y el hígado, con las concentraciones más altas en la próstata y las partes del ojo. El semen es particularmente rico en zinc, siendo un factor clave en la correcta función de la glándula prostática y en el crecimiento de los órganos reproductivos.

El zinc aumenta la testosterona en sangre indirectamente, funcionando como coenzima en el metabolismo de las hormonas masculinas por medio de su formación a través de la hormona luteinizante (LH), que estimula las células de Leydig. También previene que la testosterona se degrade en estrógeno por medio de la enzima aromatasa.

En el cerebro, el zinc se almacena en determinadas vesículas sinápticas mediante neuronas glutamatérgicas y puede "modular la excitabilidad del cerebro". Desempeña un papel clave en la plasticidad sináptica y por lo tanto en el aprendizaje. Sin embargo, ha sido llamado el "caballo oscuro del cerebro" (“the brain's dark horse”) ya que también puede comportarse como una neurotoxina, lo que sugiere que la adecuada homeostasis del cinc desempeña un papel fundamental en el funcionamiento normal del cerebro y del sistema nervioso central.

Se cree que el aguijón de los escorpiones contienen cinc con una pureza de 1/4 partes.

La deficiencia de zinc perjudica al sistema inmunitario, genera retardo en el crecimiento y puede producir pérdida del cabello, diarrea, impotencia, lesiones oculares y de piel, pérdida de apetito, pérdida de peso, tardanza en la cicatrización de las heridas y anomalías en el sentido del olfato y el gusto. Las causas que pueden provocar una deficiencia de zinc son la deficiente ingesta y la mala absorción del mineral —caso de alcoholismo que favorece su eliminación en la orina o dietas vegetarianas en las que la absorción de zinc es un 50% menor que de las carnes— o por su excesiva eliminación debido a desórdenes digestivos.

La carencia de zinc en los períodos de rápido crecimiento afecta negativamente el desarrollo cognitivo, cerebral y sexual.

Según el CSIC, este elemento tiene un papel de suma importancia en las funciones mediadas por neurotransmisores, actuando como modulador de la excitabilidad neuronal. En este sentido la deficiencia de zinc puede causar trastornos del humor y neurodegeneración, como depresión y Alzheimer.

La disminución de los niveles de LH y testosterona circulantes a causa de la deficiencia de cinc afecta negativamente la actividad de las células de Leydig.

El exceso de zinc, denominado hipercincemia, se ha asociado con bajos niveles de cobre, alteraciones en la función del hierro, disminución de la función inmunológica y de los niveles del colesterol bueno HDL, vómitos, diarrea, daños a los riñones y depresión mental.

El zinc se encuentra en diversos alimentos, especialmente en aquellos ricos en proteínas, ya que el zinc queda retenido entre las mismas, como ostras, carnes rojas, carne de cerdo, cordero, aves de corral, algunos pescados y mariscos. Otras fuentes ricas en zinc son las habas, nueces, granos enteros y levadura. Las frutas y las verduras no son habitualmente buenas fuentes, porque el zinc en las proteínas vegetales no tiene tanta biodisponibilidad para el ser humano como el zinc de las proteínas animales.

Los cereales integrales, las legumbres y los frutos secos son ricos en fitatos, que son conocidos bloqueantes del zinc. La biodisponibilidad del zinc en el pan leudado es mayor que en los productos sin levadura, ya que el proceso de leudado activa la fitasa, que descompone el ácido fítico. El resultado es que mejora la biodisponibilidad del zinc.

La ingesta diaria recomendada de zinc ronda los 11-20 mg para hombres adultos, menor para bebés, niños, adolescentes y mujeres adultas (por su menor peso corporal) y algo mayor para mujeres embarazadas y durante la lactancia. La absorción del zinc es muy variable (entre un 20 y un 30 %), y aumenta cuando el consumo es bajo o cuando aumentan las necesidades.

Aunque los adultos vegetarianos tienen a menudo una ingesta menor que la de los omnívoros, parece que en general presentan un nivel adecuado de zinc, como se refleja en los niveles de zinc en sangre y en los estudios sobre el balance de zinc. Se ha visto que a lo largo del tiempo se produce una adaptación a la dieta vegetariana, dando como resultado una mejor utilización de este elemento. Los hombres vegetarianos y no vegetarianos tienen un consumo de zinc similar mientras que las mujeres vegetarianas presentan un consumo significativamente más bajo. Incluso aunque estas últimas consuman menos zinc, sus niveles son similares a los niveles de las mujeres omnívoras. Las personas de la tercera edad, independientemente de su tipo de dieta, tienen un mayor riesgo de deficiencia de zinc.

Como el zinc, en general, se absorbe de manera menos efectiva a partir de una dieta vegetariana que de una dieta omnívora, es importante que los vegetarianos seleccionen alimentos ricos en zinc.

La producción mundial de zinc durante 2011 alcanzó un total de 12,40 millones de toneladas métricas. El principal país productor es China, seguido por Perú y Australia.

El zinc es el 23.º elemento más abundante en la corteza terrestre. Las menas más ricas contienen cerca de un 10% de hierro y entre el 40 y el 50% de zinc. Los minerales de los que se extrae son el sulfuro de zinc, conocido como esfalerita en EE.UU. y blenda en Europa, la smithsonita (carbonato) en Estados Unidos, pero calamina en Europa, la hemimorfita, (silicato), y la franklinita, (óxido).

De acuerdo con la información recogida en el informe anual del United States Geological Survey (USGS), las estimaciones señalan que las reservas económicamente explotables de zinc en 2011 a nivel mundial alcanzarían las 250 millones de toneladas métricas, repartidas entre China, Estados Unidos, Perú y Kazajistán.
Las reservas conocidas (incluyendo aquellas cuya explotación hoy día no es rentable) rozan los 2000 millones de toneladas.

La producción del zinc comienza con la extracción del mineral, que puede realizarse tanto a cielo abierto como en yacimientos subterráneos. Los minerales extraídos se trituran con posterioridad y se someten a un proceso de flotación para obtener el concentrado.

Los minerales con altos contenidos de hierro se tratan por vía seca: primeramente se tuesta el concentrado para transformar el sulfuro en óxido, que recibe la denominación de "calcina", y a continuación se reduce éste con el carbono contenido en el carbón, obteniendo el metal (el agente reductor es en la práctica el monóxido de carbono formado). Las reacciones en ambas etapas son:

Otra forma más sencilla y económica de reducir el óxido de zinc es con carbón. Se colocan los dos moles óxido de zinc (ZnO), y un mol de carbono (C), en un recipiente al vacío para evitar que el metal se incendie con el aire en el momento de purificarse, dando como resultado nuevamente óxido de cinc. En esta etapa, la reducción del óxido de zinc, se expresa de la siguiente manera:

2 ZnO + C → 2 Zn + CO

Por vía húmeda primeramente se realiza el tueste obteniendo el óxido que se lixivia con ácido sulfúrico diluido; las lejías obtenidas se purifican separando las distintas fases presentes. El sulfato de zinc se somete posteriormente a electrólisis con ánodo de plomo y cátodo de aluminio sobre el cual se deposita el zinc formando placas de algunos milímetros de espesor que se retiran cada cierto tiempo. Los "cátodos" obtenidos se funden y se cuela el metal para su comercialización.

Como subproductos se obtienen diferentes metales como mercurio, óxido de germanio, cadmio, oro, plata, cobre y plomo, en función de la composición de los minerales. El dióxido de azufre obtenido en la tostación del mineral se usa para producir ácido sulfúrico que se reutiliza en el lixiviado comercializando el excedente producido.

Los tipos de cinc obtenidos se clasifican según la norma ASTM en función de su pureza:

La norma EN 1179 considera cinco grados Z1 a Z5 con contenidos de cinc entre 99,995% y 98,5% y existen normas equivalentes en Japón y Australia. Para armonizar todas ellas, la Organización Internacional de Normalización publicó en 2004 la norma ISO 752 sobre clasificación y requisitos del cinc primario.

Las aleaciones más empleadas son las de aluminio (3,5-4,5%, Zamak; 11-13%, Zn-Al-Cu-Mg; 22%, Prestal, aleación que presenta superplasticidad) y cobre (alrededor del 1%) que mejoran las características mecánicas del cinc y su aptitud al moldeo.

Es componente minoritario en aleaciones diversas, principalmente de cobre como latones (3 a 45% de cinc), alpacas (Cu-Ni-Zn) y bronces (Cu-Sn) de moldeo.

El óxido de zinc es el más conocido y utilizado industrialmente, especialmente como base de pigmentos blancos para pintura, pero también en la industria del caucho y en cremas solares. Otros compuestos importantes son: sulfato de zinc (nutriente agrícola y uso en minería), cloruro de zinc (desodorantes) y sulfuro de zinc (pinturas luminiscentes).

El zinc existente en la naturaleza está formado por cuatro isótopos estables, Zn-64 (48,6%), Zn-66, Zn-67, y Zn-68. Se han caracterizado 22 radioisótopos de los que los más estables son Zn-65 y Zn-72 con periodos de semidesintegración de 244,26 días y 46,5 horas respectivamente; el resto de isótopos radiactivos tienen periodos de semidesintegración menores que 14 horas y la mayoría menores que un segundo. El cinc tiene cuatro estados metaestables.

El zinc metal no está considerado como tóxico pero sí algunos de sus compuestos como el óxido y el sulfuro.
En la década de los 40 se observó que en la superficie del acero galvanizado se forman con el tiempo "bigotes de zinc" ("zinc whiskers") que pueden liberarse al ambiente provocando cortocircuitos y fallos en componentes electrónicos. Estos bigotes se forman tras un período de incubación que puede durar días o años y crecen a un ritmo del orden de 1 mm al año. El problema causado por estos bigotes se ha agudizado con el paso del tiempo por haberse construido las salas de ordenadores y equipos informáticos sobre suelos elevados para facilitar el cableado en las que era común el uso de acero galvanizado, tanto en la estructura portante como en la parte posterior de las baldosas. Las edades de dichas salas, en muchos casos de 20 o 30 años propician la existencia de pelos en cantidades y longitudes peligrosas susceptibles de provocar fallos informáticos. Además, la progresiva miniaturización de los equipos disminuye la longitud necesaria para provocar el fallo y los pequeños voltajes de funcionamiento impiden que se alcance la temperatura de fusión del metal provocando fallos crónicos que pueden ser incluso intermitentes.





</doc>
<doc id="21881" url="https://es.wikipedia.org/wiki?curid=21881" title="Verano">
Verano

El verano es una de las cuatro estaciones de las zonas templadas. Es la más cálida de ellas. Ocurre entre la primavera y el otoño. El verano se caracteriza porque los días son más largos y las noches más cortas. Astronómicamente, el solsticio de verano (alrededor del 21 de diciembre el austral y el 21 de junio el boreal) marca el comienzo de esta estación, y el equinoccio de otoño (alrededor del 21 de marzo el austral y el 22-23 de septiembre el boreal) marca el término de esta estación y el comienzo del invierno.

En diversas culturas, las estaciones comienzan en diferentes fechas, basadas en fenómenos astronómicos o meteorológicos. Sin embargo, cuando el verano ocurre en el hemisferio sur es invierno en el hemisferio norte. Según se observe, el verano puede ser boreal, cuando ocurre en el hemisferio norte, o austral, cuando ocurre en el hemisferio sur.

Sin embargo, a veces, el verano se define como la totalidad de los meses de diciembre, enero y febrero en el hemisferio sur y como la totalidad de los meses de junio, julio y agosto en el hemisferio norte. En la zona intertropical a veces se emplea el término "verano" para referirse a la estación seca, e "invierno" para la estación lluviosa.

En el número de las cuatro diosas de las estaciones existentes en la villa de Albaoi, el Estío (sinónimo de verano) está representado corriendo con una antorcha encendida en cada mano. En un sepulcro fuera de Roma, donde en estuco estaban representadas las Cuatro Estaciones, en una mano el Estío tenía una hoja de trébol. 

Entre las pinturas de Herculano (Italia) hay una figura vestida de amarillo con una azada de muchas puntas. Sobre la urna cineraria que representa las bodas de Tetis y Peleo, al verano se le representa más gallardamente vestido (provisto de una corona) que al invierno y al otoño. Se le designaba también por la caza del león. Se le pintaba igualmente con una túnica amarilla, con un manto azul celeste, color que indica la constante serenidad del cielo durante esta estación, sobre todo en los países cálidos. El amarillo indica la madurez de las mieses.

Los modernos la simbolizan por una joven vestida de amarillo coronada de espigas y portando una antorcha encendida. Otros representan al verano casi desnudo, coronado de espigas, sosteniendo en una mano el cuerno de la abundancia, rebosante de toda especie de granos y frutas, y en la otra una hoz.


</doc>
<doc id="21882" url="https://es.wikipedia.org/wiki?curid=21882" title="Otoño">
Otoño

El otoño es una de las cuatro estaciones del año y una de las dos de la zona intertropical. Astronómicamente, comienza con el equinoccio de otoño (alrededor del 21 de septiembre en el hemisferio norte y 21 de marzo en el hemisferio sur) y termina con el solsticio de invierno (alrededor del 21 de diciembre en el hemisferio norte y 21 de junio en el hemisferio sur).

Sin embargo, habitualmente se conoce como otoño el período que comprende los meses de septiembre, octubre y noviembre en el hemisferio norte y marzo, abril y mayo en el hemisferio sur.

En ambos hemisferios, es la estación de las cosechas, por ejemplo, del maíz y el girasol. En la literatura, el otoño, en sentido figurado, representa la madurez.

Su nombre proviene del latín “autumnus”, palabra que se ha vinculado a la raíz “augeo-”: aumentar. De este modo, los etimologistas latinos explicaban la palabra como “auctus (participio pasado de augeo) annus”: el aumento o la plenitud del año. Compárese con el castellano el término "auge", que proviene de idéntica raíz. Otros autores como Breyer y Ernout-Meillet, vinculan la palabra latina “autumnus” con la raíz etrusca; “autu-” que implica la idea del cambio y aparece, también, en el nombre de la divinidad etrusca Vertumno, quien —entre otras funciones—, predecía el cambio de las estaciones.

Durante esta estación la temperatura comienza a descender. Las hojas de los árboles caducos cambian su color verde por tonos ocres, hasta que se secan y caen ayudadas por el viento que sopla con mayor fuerza. Este cambio de color se observa más claramente en diversas regiones del mundo, como América del Norte, el Este de Asia (incluyendo China, Corea y Japón), Europa, zonas centro, sur y austral de Chile, centro y sur de Argentina, Australia oriental y la isla sur de Nueva Zelanda.

Canadá y Nueva Inglaterra son destinos muy populares para observar el follaje otoñal.

Durante el otoño se desarrollan numerosas festividades. Las más conocidas son Halloween y el Día de Acción de Gracias, muy populares en el ámbito anglosajón. En España y Latinoamérica septentrional, el día más importante es el Día de Todos los Santos (día primero de noviembre), que al igual que Halloween, era en su inicio una festividad de origen pagano vinculada al culto y en países como México el Día de los Fieles Difuntos (día dos de noviembre) en respeto de los difuntos, donde se les recuerda con actividades como la quema de veladoras y de oración dedicadas a familiares y amigos que han fallecido.



</doc>
<doc id="21883" url="https://es.wikipedia.org/wiki?curid=21883" title="Invierno">
Invierno

El invierno es una de las cuatro estaciones de clima templado. 
Esta estación se caracteriza por días más cortos, noches más largas y temperaturas más bajas a medida que nos alejamos del Ecuador. En algunos países de la zona intertropical se denomina invierno a la estación lluviosa de mayor precipitación y pluviosidad.

La palabra "invierno" proviene del español antiguo "ivierno", y este del latín vulgar "hibernum", del latín "tempus hibernum", estación invernal.

Como las demás estaciones del año, el invierno es causado por la inclinación de 23,44 grados 
del eje terrestre sobre su plano orbital.

Desde un punto de vista astronómico, comienza con el solsticio de invierno, el día 21 de diciembre en el hemisferio norte y el 21 de junio en el hemisferio sur, y termina con el equinoccio de primavera, alrededor del 21 de marzo en el Hemisferio norte y el 21 de septiembre en el hemisferio sur, variando las fechas levemente según el año. El hecho que la órbita de la Tierra sea elíptica, se traduce en una duración menor del invierno en el hemisferio norte y mayor respecto a éste en el sur, ya que en julio se produce el afelio, durante el invierno austral, y en enero el perihelio durante el boreal. En resumen, el invierno dura aproximadamente cuatro días más en el hemisferio austral que en el boreal.

Desde una óptica meteorológica, en cambio, se suelen considerar invernales los meses enteros de diciembre, enero y febrero en el hemisferio norte y junio, julio y agosto en el hemisferio sur.

El invierno es la estación más fría del año, y sus características son inevitablemente definidas en contraste con las otras estaciones del año; ya que durante los días invernales las temperaturas son más bajas y hay menos horas de luz solar. Estas características se acentúan a medida que nos alejamos de los trópicos y nos acercamos a los círculos polares. 

En algunas regiones del planeta, según su latitud, altitud y determinadas condiciones meteorológicas, se puede observar la caída de nieve.

En la mitología griega, Hades, dios del inframundo, rapta a la bella Perséfone para hacerla su esposa. Zeus le ordena a Hades que la devuelva y se la entregue a Deméter, diosa de la tierra y su madre. Sin embargo, Hades engaña a Perséfone y le hace comer semillas de granada, comida del inframundo que la obliga a quedarse allí para siempre. Deméter, sin su hija Perséfone no tiene felicidad por lo tanto no cuida a la tierra. Zeus, viendo que la tierra quedaba desolada, las plantas se secaban y morían, llega a un acuerdo para que Perséfone pase seis meses con Deméter y seis meses con Hades. Durante el tiempo en que su hija está con Hades, Deméter se entristece y provoca el otoño y el invierno.



</doc>
<doc id="21885" url="https://es.wikipedia.org/wiki?curid=21885" title="Tikal">
Tikal

Tikal (o Tik'al, de acuerdo con la ortografía maya moderna) es uno de los mayores yacimientos arqueológicos y centros urbanos de la civilización maya precolombina. Está situado en el municipio de Flores, en el departamento de Petén, en el territorio actual de la República de Guatemala y forma parte del Parque nacional Tikal, que fue declarado Patrimonio de la Humanidad, por Unesco, en 1979. Según los glifos encontrados en el yacimiento, su nombre maya habría sido Yax Mutul.

Tikal fue la capital de un estado beligerante, que se convirtió en uno de los reinos más poderosos de los antiguos mayas.
Aunque la arquitectura monumental del sitio se remonta hasta el siglo  a. C., Tikal alcanzó su apogeo durante el Período Clásico, entre el 200 y el 900 d. C. Durante este tiempo, la ciudad dominó gran parte de la región maya, en el ámbito político, económico y militar y mantenía vínculos con otras regiones, a lo largo de Mesoamérica, incluso con la gran metrópoli de Teotihuacan, en el lejano Valle de México.

Después del Clásico Tardío, no se construyeron monumentos mayores.

Con una larga lista de gobernantes dinásticos, el descubrimiento de muchas de sus respectivas tumbas y el estudio de sus monumentos, templos y palacios, Tikal es probablemente la mejor comprendida de las grandes ciudades mayas de las tierras bajas de Mesoamérica.

El nombre Tikal puede ser una derivación de las palabras "ti ak'al", en el idioma maya yucateco, que significa «en el pozo de agua». Aparentemente, el nombre fue aplicado por cazadores y viajeros de la región y se refería a una de las antiguas reservas de agua del sitio.
Una explicación alternativa sugiere que el nombre viene del idioma maya itzá y que significa «lugar de las voces», o «lugar de las lenguas».

Sin embargo, Tikal no es el antiguo nombre del sitio, sino más bien el nombre que se adoptó poco después de su redescubrimiento, en la década de 1840.
Las inscripciones glíficas en escritura maya, en las ruinas, se refieren a la antigua ciudad como Yax Mutal o Yax Mutul, cuyo significado es «primer mutal».
Es posible que Tikal fuese llamada así para distinguirla de Dos Pilas, que llegó a utilizar el mismo glifo emblema. Los gobernantes de la ciudad, aparentemente, querían distinguirse como la primera ciudad llevando este nombre.
El reino, en su conjunto, se llamaba Mutul, siendo la lectura del glifo emblema que se ve en la foto incluida. Su significado exacto no está claro, aunque algunos científicos piensan que hace referencia al peinado del "Ku'hul Ahaw", o máximo gobernante.

Tikal está ubicado a aproximadamente 64 km, al noreste de Flores y Santa Elena y aproximadamente 303 km, al norte de la ciudad de Guatemala. La ciudad se encuentra a 19 km, al sur de la antigua ciudad maya de Uaxactún, a 30 km, al noroeste de Yaxhá, a 100 km, al sureste de Calakmul, su gran rival del Período Clásico y a 85 km, al noroeste de El Caracol, el aliado de Calakmul, ahora en Belice.

La ciudad, que cubre un área de más de 16 km², ha sido completamente cartografiada e incluye alrededor de 3000 estructuras.
La topografía del lugar se compone de una serie de colinas de piedra caliza, elevándose encima de tierras pantanosas. La arquitectura principal del sitio se agrupa en zonas más elevadas, que son interconectadas por calzadas que atraviesan los pantanos.

Las ruinas se encuentran en medio de la selva tropical, en la cuenca del Petén, que formó la cuna de la civilización maya en las tierras bajas de Mesoamérica. La ciudad está ubicada en medio de suelos fértiles, con tierras elevadas y puede haber dominado la ruta comercial natural, que corre de este a oeste, a través de la península de Yucatán.

A pesar de ser una de las mayores ciudades mayas del Clásico, Tikal no tenía otras fuentes de agua, que no fuera el agua de lluvia, que se recogió y se almacenó en diez embalses. Los arqueólogos que trabajaron en Tikal, durante el siglo , restauraron uno de los antiguos depósitos de agua, para su propio uso.
La ausencia de fuentes, ríos y lagos en las cercanías de Tikal, pone de relieve un hecho prodigioso: la construcción de una gran ciudad, contando exclusivamente con entregas almacenadas de lluvias estacionales. Tikal prosperó con técnicas de agricultura intensiva, que eran mucho más avanzadas que los métodos de tala y quema originalmente teorizados por los arqueólogos. Sin embargo, la dependencia de las lluvias estacionales constituyó una vulnerabilidad, ante las sequías prolongadas y algunos científicos consideran que esta vulnerabilidad ha jugado un papel en el colapso maya.

La población de Tikal experimentó un crecimiento continuo, a partir del Período Preclásico (aproximadamente entre el 2000 a. C. y el 200 d. C.), alcanzando su pico en el Clásico Tardío, con un crecimiento rápido entre el 700 y el 830 d. C., seguido por un fuerte descenso.

Las estimaciones de población de la ciudad de Tikal varían, de 10 000, hasta más de 90 000 habitantes, siendo la cifra más probable la del extremo superior de este rango.
Debido al bajo contenido en sal de la dieta maya, se estima que Tikal tenía que importar 131 toneladas de sal cada año, con base en una estimación conservadora, de una población de 45 000 habitantes.

Para el área de 120 km² (que demarcaría un círculo con un diámetro de 21,9 km), que se ubica dentro del perímetro de los terraplenes de defensa, la población máxima se estima en 517 habitantes por km². Dentro de un diámetro de 24 km del centro del sitio, la población máxima se estima en 120 000 habitantes y la densidad de población se estima en 265 habitantes por km². Dentro de un diámetro de 50 km del centro del sitio, que incluye algunas ciudades satélite, la población máxima se estima en 425 000, con una densidad de 216 habitantes por km². Estas cifras de población son aún más impresionantes, por los extensos pantanos, que no eran aptos para la agricultura, ni la construcción de viviendas. Sin embargo, algunos arqueólogos, como David Webster, consideran que estas cifras son demasiado altas.

La línea dinástica de Tikal, fundada ya en el siglo , abarcó 800 años e incluyó al menos 33 gobernantes.

Existen huellas de una agricultura temprana en Tikal, que datan del preclásico medio, aproximadamente en el 1000 a. C.
En un chultún sellado, una cavidad subterránea en forma de botella, fue descubierto un escondite con cerámica maya, que data de alrededor del 700 al 400 a. C.

En el preclásico tardío, por primera vez alrededor del 400 al 300 a. C., ya se realizaron construcciones importantes en Tikal, incluyendo la construcción de pirámides y plataformas, aunque la ciudad estaba siendo eclipsada por otros sitios más poderosos, situados al norte, como El Mirador y Nakbé.

En aquel momento, Tikal era parte de la cultura Chikanel, que dominaba la zona central y norte de Mesoamérica, una región que comprendía toda la Península de Yucatán, incluso el norte y el este de Guatemala y el territorio de Belice.

Dos templos, que datan del Chikanel tardío, tenían paredes de mampostería, cuyas superestructuras pueden haber sido arcos mayas, aunque esto no ha sido probado. Uno de estos templos tenía elaboradas pinturas, en las paredes exteriores, que muestran figuras humanas sobre un fondo de figuras decorativas, pintado en amarillo, negro, rosado y rojo.

En el siglo d. C., aparecieron por primera vez sepulturas ricas y Tikal experimentó un florecimiento político y cultural, tras la declinación de sus poderosos vecinos en el norte.
A finales del Preclásico Tardío, el arte y la arquitectura de estilo Izapa, de la costa del Pacífico, comenzó a ejercer su influencia en Tikal, como lo demuestran los primeros murales en la ciudad y una escultura, rota, en la acrópolis.

El gobierno dinástico, un régimen común entre los mayas de las tierras bajas, estuvo fuertemente arraigado en Tikal. De acuerdo con registros glíficos posteriores, la dinastía fue fundada por Yax-Moch-Xoc, posiblemente en el siglo .
Al inicio del Clásico Temprano, el poder en la región maya se concentró en Tikal y Calakmul, en el núcleo de la región central maya.

Es posible que Tikal se haya beneficiado de la caída de los grandes estados del Preclásico, como El Mirador. En el Clásico Temprano, Tikal se desarrolló rápidamente en la ciudad más dinámica de la región maya, estimulando el desarrollo de otras ciudades mayas cercanas.

Sin embargo, Tikal se encontraba frecuentemente en guerra y las inscripciones mencionan alianzas y conflictos con otros estados mayas, como Uaxactún, El Caracol, Naranjo y Calakmul. A finales del Clásico Temprano, Tikal fue derrotado por El Caracol, que sustituyó a Tikal, como principal centro del poder, en las tierras bajas mayas del sur.
Durante la primera parte del Clásico Temprano, también ocurrieron hostilidades entre Tikal y la ciudad vecina de Uaxactún, de las que en Uaxactún existen inscripciones, referentes a la captura de prisioneros de Tikal.

Parece haber ocurrido una ruptura en la sucesión masculina de la dinastía, en el 317 d. C., cuando la señora Une' B'alam llevó a cabo una ceremonia de fin de katún, al parecer como reina de la ciudad.

El decimocuarto rey de Tikal era Chak Tok Ich'aak (Gran Garra de Jaguar).
Chak Tok Ich'aak construyó un palacio, que fue conservado y ampliado por los gobernantes posteriores, hasta convertirse en el núcleo de la acrópolis central.
Poco se sabe acerca de Chak Tok Ich'aak, excepto que fue asesinado el 14 de enero del 378 d. C. El mismo día, Siyah K'ak' (‘Nace el Fuego’) llegó desde el oeste, después de pasar por El Perú, un sitio al oeste de Tikal, el 8 de enero.
Las inscripciones de la estela 31, se refieren a él como «Señor del Occidente».
Siyah K’ak’ fue, probablemente, un general extranjero, que servía a una figura representada por un glifo atípico para los mayas, compuesto de un lanzadardos, en combinación con un búho, un glifo que se conoce de la gran metrópoli de Teotihuacan, en el distante Valle de México. El Búho lanzadardos, incluso, puede haber sido el gobernante de Teotihuacan. Estos eventos registrados, sugieren que Siyah K'ak' lideró una invasión de Teotihuacan, que derrotó al rey nativo de Tikal, que fue capturado y ejecutado de inmediato.
Siyah K'ak' parece haber recibido el apoyo de una poderosa facción política, en Tikal mismo. Más o menos coincidiendo con esa conquista, un grupo de indígenas de Teotihuacan residía cerca del complejo Mundo Perdido, según parece.
También ejerció el control sobre otras ciudades en la zona, como Uaxactún, donde se convirtió en rey, pero no tomó el trono de Tikal para sí mismo.
En el curso de un año, el hijo de Búho lanzadardos, Yax Nuun Ayiin I (primer cocodrilo), fue instalado como el décimo rey de Tikal, mientras todavía era un niño.
Su reino duró 47 años y Tikal siguió siendo vasallo de Siyah K'ak', durante el tiempo que éste vivió. Parece probable que Yax Nuun Ayiin I se casó con una de las esposas pre-existentes, de la derrotada dinastía de Tikal, con el propósito de legitimar el derecho de gobernar de su hijo, Siyaj Chan K'awiil II.

Río Azul, un sitio pequeño, a 100 kilómetros al noreste de Tikal, fue conquistado por éste, durante el reinado de Yax Nuun Ayiin I. El sitio se convirtió en un puesto de avanzada de Tikal, protegiéndola de las ciudades hostiles en el norte y también se convirtió en un vínculo para el comercio con el Caribe.

A pesar de que los nuevos gobernantes de Tikal eran extranjeros, sus descendientes se adaptaron rápidamente a la cultura maya. Tikal se convirtió en el principal aliado y socio comercial de Teotihuacan, en las tierras bajas mayas. Después de su conquista por Teotihuacan, Tikal rápidamente dominó el norte y el este del Petén. Uaxactún, junto con los pueblos más pequeños de la región, fueron absorbidos en el reino de Tikal. Otros sitios, como Bejucal y Motul de San José, cerca del lago Petén Itzá, se convirtieron en vasallos de su vecino más poderoso en el norte. A mediados del siglo , Tikal tenía un territorio núcleo de, por lo menos, 25 kilómetros en todas las direcciones.

Alrededor del siglo , un impresionante sistema de fortificaciones, compuesto de zanjas y construcciones de tierra, fue construido a lo largo de la periferia norte de la zona interior de Tikal, uniéndose a las defensas naturales, proporcionadas por largas áreas pantanosas, situadas al este y al oeste de la ciudad. Fortificaciones adicionales fueron, probablemente, construidas en el sur, cercando un área de, aproximadamente, 120 kilómetros cuadrados. Estas defensas dieron protección a la población nuclear de Tikal y a sus recursos agrícolas.
Sin embargo, investigaciones recientes sugieren que las obras de tierra pueden haber sido parte de un sistema de recolección de agua, en lugar de tener una finalidad defensiva.

En el siglo , el poder de Tikal se expandió hacia el sur, hasta incorporar a la ciudad de Xukpi (actual Copán), cuyo fundador, K'inich Yax K'uk' Mo', tenía vínculos con Tikal.
Xukpi no se encontraba en una región étnicamente maya y la fundación de la dinastía de Xukpi, probablemente, implicaba la intervención directa de Tikal.
K'inich Yax K'uk' Mo' llegó a Xukpi (Copán) en diciembre de 426 y el análisis de los huesos de sus restos demuestra que pasó su infancia y juventud en Tikal.
Una persona conocida como Ajaw K'uk' Mo' (señor K'uk' Mo') es mencionada en un texto temprano de Tikal y bien puede ser la misma persona.
Su tumba tenía características de Teotihuacan y en retratos posteriores fue representado, vestido con el traje guerrero de Teotihuacan. Textos glíficos se refieren a él como «Señor del Oeste», al igual que Siyah K'ak'.
Al mismo tiempo, a finales de 426, Copán fundó el sitio cercano de Quiriguá, posiblemente patrocinado por Tikal.
La fundación de ambos centros puede haber sido parte de un esfuerzo para imponer la autoridad de Tikal, en la parte sureste de la región maya.
La interacción entre estos sitios y Tikal fue intensa, durante los siguiente tres siglos.

En el siglo  surgió una rivalidad duradera entre Tikal y Calakmul, con cada una de las dos ciudades formando su propia red de alianzas mutuamente hostiles, en lo que se ha descrito como una guerra de larga duración entre las dos superpotencias mayas. Los reyes de las dos capitales adoptaron el título "Kaloomte"', un término que no ha sido traducido con precisión, pero que tiene un significado semejante a Gran Rey.

A principios del siglo , hubo otra reina como gobernante de la ciudad, únicamente conocida como la Señora de Tikal, que era probablemente una hija de Chak Tok Ich'aak II. Parece que nunca gobernó en su propio derecho, ya que fue asociada con cogobernantes masculinos. El primero de ellos fue Kaloomte' B'alam, quien parece haber tenido una larga carrera como general de Tikal, antes de convertirse en corregente, siendo el decimonoveno en la secuencia dinástica. La Señora de Tikal no parece haber sido contabilizada en la numeración dinástica. Al parecer, fue posteriormente emparejada con el señor Garra de Pájaro, del que se presume representa el vigésimo gobernante.

A mediados del siglo , El Caracol parece haberse aliado con Calakmul, logrando derrotar a Tikal y marcando el cierre del Clásico Temprano.
El «hiato de Tikal» se refiere a un período comprendido entre finales del siglo  y finales del siglo , en el que se registró un descenso en la escritura de inscripciones y una reducción de la construcción a gran escala, en Tikal. En la segunda mitad del siglo , la ciudad fue afectada por una grave crisis, en la que no fueron erigidas nuevas estelas y se experimentó una deliberada y amplia mutilación de las esculturas públicas.
Este hiato (o receso) en la actividad en Tikal, quedó sin explicación durante mucho tiempo, hasta que se determinó, mediante desciframientos epigráficos posteriores, que el receso fue impulsado por la completa derrota de Tikal, por los estados aliados de Calakmul y El Caracol, en el año 562, una derrota que parece haber dado lugar a la captura y el sacrificio del rey de Tikal.
El muy erosionado Altar 21, en El Caracol, describe cómo Tikal sufrió esta desastrosa derrota, en una guerra mayor que tuvo lugar en el año 562. Parece que El Caracol era un aliado de Calakmul, en un conflicto más amplio entre esa última ciudad y Tikal, con la derrota de Tikal teniendo un impacto duradero sobre la ciudad.
Tikal no fue saqueada, sino que su poder e influencia fueron quebrados.
Después de su gran victoria, El Caracol creció rápidamente y una parte de la población de Tikal pudo haber sido trasladada, a la fuerza, allí. Durante el hiato, por lo menos uno de los gobernantes de Tikal se refugió con Janaab' Pakal de Palenque, otra de las víctimas de Calakmul.
Calakmul prosperó, durante el largo período de receso experimentado por Tikal.

El inicio del hiato de Tikal ha servido como un marcador con el que los arqueólogos frecuentemente sub-dividen el período Clásico de la cronología mesoamericana, en el Clásico Temprano y Clásico Tardío.

En el año 629, Tikal fundó Dos Pilas, un puesto de avanzada militar, a unos 110 kilómetros al sudoeste, con el fin de controlar el comercio a lo largo del curso del río La Pasión.
En 635, B'alaj Chan K'awiil fue instalado en el trono del nuevo puesto de avanzada, a la edad de cuatro años y durante muchos años sirvió como un leal vasallo de su hermano, el rey de Tikal.
Aproximadamente veinte años después, Dos Pilas fue atacado y derrotado por Calakmul. B'alaj Chan K'awiil fue capturado por el rey de Calakmul pero, en lugar de ser sacrificado, fue reinstalado en su trono, como vasallo de su antiguo enemigo y atacó a Tikal en 657, lo que obligó a Nuun Ujol Chaak, el entonces rey de Tikal, a temporalmente abandonar la ciudad.
Los dos primeros gobernantes de Dos Pilas siguieron utilizando el «mutal», el glifo emblema de Tikal y, probablemente, sentían que tenían un derecho legítimo al trono de Tikal mismo. Por alguna razón, B'alaj Chan K'awiil no fue instalado como el nuevo gobernante de Tikal y se quedó en Dos Pilas. Tikal contraatacó a Dos Pilas, en el año 672, obligando a B'alaj Chan K'awiil a exiliarse, durante cinco años.
Calakmul trató de cercar a Tikal dentro de un área dominada por sus aliados, como El Perú, Dos Pilas y El Caracol.

En 682, Jasaw Chan K'awiil erigió el primer monumento, fechado en Tikal en 120 años y se adjudicó el título de "Kaloomte"', poniendo así fin al hiato. Inició un programa de nueva construcción y revirtió la relación con Calakmul, cuando en 695 capturó al ajaw Yuknoom Yich'aak K'ahk', dejando al estado enemigo en una larga declinación, de la que nunca se recuperó. Tras esta derrota, Calakmul nunca más erigió un monumento celebrando alguna victoria militar.
Con esta derrota de Calakmul, se restauró la preeminencia de Tikal en la región maya central, pero nunca más en el suroeste del Petén, donde Dos Pilas mantuvo su presencia.

En el siglo , no hubo presencia activa de Teotihuacan en cualquier sitio maya y el centro de Teotihuacan había sido arrasado, hacia el 700 d. C. No obstante, el traje de guerra formal, ilustrando los monumentos, se mantuvo en el estilo de Teotihuacan.
Jasaw Chan K'awiil I y su heredero Yik'in Chan K'awiil continuaron con las hostilidades en contra de Calakmul y sus aliados e impusieron un control regional firme, sobre el área alrededor de Tikal, extendiéndose hasta el territorio alrededor del lago Petén Itzá. Estos dos gobernantes fueron responsables de gran parte de la impresionante arquitectura visible en la actualidad.

En 738, Quiriguá, un vasallo de Copán, el aliado clave de Tikal en el sur, cambió de lealtad, favoreciendo a Calakmul, derrotó a Copán y obtuvo su propia independencia.
Esto fue, aparentemente, el efecto de un esfuerzo consciente por parte de Calakmul, para lograr el colapso de los aliados al sur de Tikal.
Esto alteró el equilibrio de poder en el sur de la región maya y resultó en la declinación de Copán.

En el siglo , los gobernantes de Tikal recogieron monumentos de todas partes de la ciudad y los trasladaron al frente de la acrópolis norte.
A finales del siglo  y principios de siglo , se desaceleró la actividad de construcción en Tikal. Todavía se construyó arquitectura impresionante, pero son pocas las inscripciones glíficas que se refieren a los gobernantes posteriores.

En el siglo , la crisis del colapso maya del periodo clásico se extendía por toda la región, con una población en caída libre y una ciudad tras otra cayendo en el silencio.
Cada vez más, la guerra endémica en la región maya obligó a la población rural que sostuvo a Tikal, a concentrarse cerca de la ciudad misma, acelerando el uso de la agricultura intensiva y el correspondiente deterioro del medio ambiente.
La construcción continuó a principios del siglo, con la erección del Templo 3, el último de las pirámides importantes de la ciudad, y la erección de monumentos, para conmemorar el decimonoveno k'atun en 810.

El comienzo del décimo bak'tun, en 830, pasó sin celebración alguna y marca el comienzo de un hiato de 60 años, probablemente como resultado del colapso del control central de la ciudad.
Durante este receso, sitios satélites, que tradicionalmente quedaban bajo el control de Tikal, comenzaron a erigir sus propios monumentos, protagonizando los gobernantes locales y empezaron a utilizar el glifo emblema Mutul, mientras que Tikal, al parecer, carecía de autoridad, o de poder, para reprimir estas tentativas de ganar independencia.
En 849, Jewel K'awiil es mencionado en las escrituras de una estela de Ceibal, como el «divino Señor de Tikal» visitando esta ciudad, pero esta visita no es registrada en otros lugares y el poder de Tikal, una vez tan grande, era poco más que un recuerdo. Los sitios de Ixlu y Jimbal ahora habían heredado el glifo emblema Mutul, que antes era exclusivo de Tikal.

Como Tikal y sus alrededores alcanzaron su población máxima, el área se vio afectada por la deforestación, erosión y la pérdida de nutrientes, seguido de una rápida disminución de la población. Tikal y sus alrededores, aparentemente, perdieron la mayoría de su población entre 830 y 950 y la autoridad central pudo haberse colapsado rápidamente.
No hay mucha evidencia de que la ciudad de Tikal se viera afectada directamente por la guerra endémica, que afectó partes de la región maya durante el Clásico Terminal, aunque la afluencia de refugiados de la región de Petexbatún pudo haber exacerbado los problemas derivados de la insuficiencia de recursos disponibles en el medio ambiente.

En la segunda mitad del siglo , hubo un intento de reinstaurar el poder real en la muy reducida ciudad de Tikal, como lo demuestra una estela erigida en la Gran Plaza por Jasaw Chan K'awiil II, en el año 869. Este fue el último monumento erigido en Tikal antes de que la ciudad finalmente cayera en el silencio. Los antiguos satélites de Tikal, como Jimbal y Uaxactún, no duraron mucho más tiempo, erigiendo sus monumentos finales en 889.
A finales del siglo , la gran mayoría de la población de Tikal había abandonado la ciudad. Sus palacios fueron ocupados por ocupantes ilegales y se construyeron sencillas viviendas, con techo de paja, en las plazas ceremoniales de la ciudad. Los nuevos ocupantes bloquearon algunas entradas en las habitaciones de las estructuras monumentales del sitio y dejaron basura, que incluía una mezcla de residuos domésticos y artículos no utilitarios, tales como instrumentos musicales. Estos habitantes reutilizaron los monumentos para sus propios rituales, muy alejados de los de la dinastía real que los había levantado.
Algunos monumentos fueron dañados y algunos fueron trasladados a nuevos lugares. Antes del abandono final de la ciudad, había desaparecido todo el respeto por los antiguos gobernantes, ya que las tumbas de la necrópolis norte fueron exploradas en busca de jade y las más accesibles fueron saqueadas. Después del año 950, Tikal estaba casi desierta, a pesar de que una población remanente pudo haber permanecido en chozas perecederas, intercaladas entre las ruinas.
En el siglo  o , estos últimos habitantes también abandonaron la ciudad y la selva reclamó las ruinas durante los siguientes mil años.
Una parte de la población de Tikal pudo haber migrado a la región de los lagos del Petén, una zona que se mantuvo densamente poblada, a pesar de una caída en los niveles de población en la primera mitad del siglo .

La causa más probable del colapso de Tikal fue la sobrepoblación y la decadencia agraria. Tikal, con su antigua dinastía, había estado en la vanguardia de la vida cortesana, del arte y de la arquitectura durante más de mil años. Su caída fue un duro golpe al corazón de la civilización maya clásica.

Investigaciones de Kohler et coll. han logrado demostrar que la ciudad habia alcazado niveles de inegualdades insostenibles al final de su historia.

En 1525, el conquistador español Hernán Cortés pasó a pocos kilómetros de las ruinas de Tikal, pero no las mencionó en sus cartas.

Como sucede a menudo con grandes ruinas antiguas, el conocimiento del sitio nunca se perdió completamente en la región. Aparentemente la población de la región nunca se olvidó de Tikal y, en la década de 1840, guiaron expediciones guatemaltecas a las ruinas. Algunos relatos de segunda o tercera mano de Tikal aparecieron en prensa, a partir del siglo  y fueron seguidos por los escritos de John Lloyd Stephens, en el siglo . (Durante sus viajes, de 1839-1840, en la región, Stephens y Frederick Catherwood, su ilustrador, escucharon rumores de una ciudad perdida, con edificios blancos, cuyas partes superiores dominaron la selva).

Debido a la lejanía del sitio, ningún explorador visitó las ruinas de Tikal hasta que Modesto Méndez y Ambrosio Tut, respectivamente el corregidor y el gobernador de Petén, las visitaron en 1848, junto con Vicente Díaz, Bernabé Castellanos y el maestro Eusebio Lara, quien los acompañó, para elaborar las primeras ilustraciones de los monumentos. En el último párrafo del infome que remitió al gobierno de Carrera, escribió: «Yo debo de cumplir con mi deber, pues me sería sensible que otros curiosos extranjeros vengan a dar publicidad a todos los objetos que estoy viendo y palpando. Vengan en hora buena esos viajeros con mayores posibilidades y facultades intelectuales, hagan excavaciones al pie de las estatuas, rompan los palacios y saquen las curiosidades y tesoros que no podrán llevar, jamás, sin el debido permiso; pero nunca podrán nulificar, ni eclipsar el lugar que me corresponde, al haber sido el primero en descubrir estas ruinas; sin gravar los fondos públicos, les abrí camino, y tuve el honor de comunicar al supremo gobierno de la república, cuanto interesante y superior se encuentra en la capital de este imperio; sin miras de interés personal o particular, únicamente satisfecho y persuadido que mi persona y cortos bienes pertenecen a la patria, al gobierno y a mis hijos».

En 1853, tras la publicación del diario de Méndez en la Gaceta de Guatemala, se dio a conocer el redescubrimiento a la comunidad científica, mediante una publicación de la Academia de Ciencias de Berlín.>

A finales del siglo  y principios del siglo , varias otras expediciones siguieron, para profundizar las investigaciones, incluyendo la expedición de Alfred P. Maudslay en 1881-82 y los arqueólogos pioneros comenzaron a limpiar, dibujar mapas y registrar las ruinas, en la década de 1880.
En 1951, una pequeña pista de aterrizaje fue construida cerca de las ruinas, a las que previamente sólo se podía acceder tras un viaje de varios días por la selva, a pie, o en mulas.
En 1956, el proyecto Tikal comenzó a dibujar mapas de la ciudad, en una escala nunca antes vista en la región maya. De 1956, a 1970, excavaciones arqueológicas importantes fueron realizadas por el Proyecto Tikal de la Universidad de Pensilvania; mapearon la mayor parte del sitio y excavaron y restauraron muchas de las estructuras.
De 1957 a 1969, las excavaciones dirigidas por Edwin M. Shook y más tarde por William R. Coe, de la Universidad de Pensilvania, se enfocaron en la Acrópolis Norte y la Plaza Central. El Proyecto Tikal logró registrar más de 200 monumentos en el yacimiento.

En 1979, el gobierno guatemalteco inició un nuevo proyecto arqueológico en Tikal, que continuó hasta 1984.

Una ilustración del Templo I de Tikal fue incluida en el reverso del billete de 50 centavos del Quetzal guatemalteco.

Las ruinas de Tikal, como parte del Parque nacional Tikal, fueron el primer sitio arqueológico en ser declarado Patrimonio de la Humanidad, en 1979 y, asimismo, el primer Patrimonio de la Humanidad mixto (ecológico y arqueológico) del mundo.
En la actualidad, Tikal, en medio de su propio parque nacional, se ha convertido en una atracción turística importante, y cuenta con un museo, construido en 1964.

Tikal ha sido parcialmente restaurada por la Universidad de Pensilvania y el Gobierno de Guatemala. Fue uno de las ciudades mayas más importantes del periodo Clásico y una de las más grandes del continente americano.
La arquitectura de la antigua ciudad está construida de piedra caliza e incluye los restos de los templos, que se elevan más de 70 metros, grandes palacios reales, además de una serie de pirámides menores, palacios, residencias, edificios administrativos, plataformas y monumentos de piedra con inscripciones.
Hay, incluso, un edificio con barras de madera en las ventanas y puertas, que parecía haber sido una cárcel. También hay siete pistas para jugar el juego de pelota mesoamericano, incluyendo un conjunto de tres pistas, en la Plaza de los Siete Templos, una característica única en Mesoamérica.

La piedra caliza utilizada para la construcción fue extraída de canteras en el lugar mismo. Las depresiones que se formaron por la extracción de la piedra fueron recubiertas e impermeabilizadas para utilizarlas como depósitos de agua o embalses, junto con algunas depresiones naturales impermeabilizadas. Las plazas principales, cuya superficie estaba revertida de estuco, fueron establecidas en un gradiente para canalizar el agua de lluvia, en un sistema de canales que alimentaron los embalses

La zona residencial de Tikal cubre una superficie de aproximadamente 60 km², la cual, en gran parte, aún no ha sido limpiada, mapeada, o excavada. En la década de 1960 se descubrió un extenso conjunto de terraplenes, cercando Tikal con una zanja de 6 metros de ancho detrás de una muralla.
Puede haber encerrado un área de unos 125 km² (véase abajo). Las estimaciones de población ponen el tamaño demográfico del sitio, entre 10.000 y 90.000 habitantes y, posiblemente, hasta 425.000 habitantes, cuando se incluye el área circundante. Recientemente, la exploración de los terraplenes de defensa ha demostrado que su magnitud es muy variable y que en muchos lugares es intrascendente, como un elemento defensivo. Además, algunas partes de los terraplenes están integradas en un sistema de canales. El conjunto de terraplenes de Tikal varía de manera significativa, en la cobertura de lo que se propuso originalmente, y parece ser mucho más complejo y multifacético de lo que se pensaba, originalmente.

A finales del Clásico Tardío, una red de "sacbéob" (calzadas), con una longitud de varios kilómetros, atravesó el núcleo urbano, vinculando las diferentes partes de la ciudad. Estas calzadas eran anchas y fueron construidas de piedra caliza y yeso. No solo sirvieron de vía de comunicación durante la época de lluvias, sino también de diques.
Han sido nombradas, en honor de los primeros exploradores y arqueólogos, las calzadas Maler, Maudslay, Tozzer y Méndez.

La calzada Maler corre al norte de la ciudad, por atrás del Templo I, hasta el Grupo H. Un gran bajorrelieve, tallado en roca caliza, se encuentra a lo largo de una parte de la calzada, justo al sur del Grupo H. Data del Clásico Tardío y muestra a dos prisioneros atados.

La calzada Maudsley corre al noreste, sobre 0,8 km, del Templo IV, al Grupo H.

La calzada Méndez corre al sureste, de la Plaza del Oriente, al Templo VI, sobre una distancia de aproximadamente 1,3 km.

La calzada Tozzer corre al oeste, de la Gran Plaza, al Templo IV.

La Gran Plaza está ubicada en el centro de la ciudad, flanqueada por dos grandes templos piramidales a sus lados este y oeste. Al norte, está bordeada por la Acrópolis Norte y, en el sur, por la Acrópolis Central.

La Acrópolis Central es un complejo de palacios, ubicado justo al sur de la Gran Plaza.

La Acrópolis Norte, junto a la Gran Plaza, inmediatamente al sur, es uno de los conjuntos arquitectónicos más estudiados de la región maya. El Proyecto Tikal excavó una larga zanja en todo el complejo, estudiando a fondo la historia de la construcción. Es un conjunto complejo, cuya construcción se inició en el período Preclásico, alrededor del 350 a. C. Se convirtió en un complejo funerario de la dinastía gobernante de la época clásica, con cada entierro real añadiendo nuevos templos, en la parte superior de las estructuras más antiguas. Después del año 400 d. C., se agregó una fila de altas pirámides a la antigua plataforma Norte, que mide 100 por 80 metros, escondiéndola gradualmente de la vista. Ocho templos piramidales fueron construidos en el siglo . Cada uno de ellos tenía una elaborada crestería y una escalinata, flanqueada por máscaras de los dioses. Hacia el siglo , se habían erigido 43 estelas y 30 altares, en la Acrópolis Norte. 18 de estos monumentos fueron tallados con Escritura maya y retratos reales. La Acrópolis Norte continuó recibiendo los entierros, en el período Posclásico.
La Acrópolis Sur se encuentra junto al Templo V. Se construyó sobre una gran plataforma de base que cubre un área de más de 20 000 metros cuadrados.

La Plaza de los Siete Templos se encuentra al oeste de la Acrópolis Sur. Su límite oriental está bordeado por una serie de templos casi idénticos, por palacios en los lados sur y oeste, y por una inusual triple pista de juego de pelota en el lado norte.>

El Conjunto G se encuentra justo al sur de la calzada Méndez. El complejo data del Clásico Tardío y se compone de estructuras tipo palacio y es uno de los grupos más grandes de su tipo en Tikal. Tiene dos pisos, pero la mayoría de las habitaciones están en la planta baja, un total de 29 cuartos abovedados. Los restos de dos habitaciones más, pertenecen a la planta superior. Una de las entradas del conjunto fue marcada por una gigantesca máscara.

El Conjunto H se centra en una larga plaza, al norte de la Gran Plaza. Está bordeado por templos que datan del Clásico Tardío.
Hay nueve complejos de pirámides gemelas en Tikal, una de las cuales se desmanteló por completo, en tiempos antiguos y algunas otras fueron parcialmente destruidas. Varían en tamaño, pero todas consisten de dos pirámides, una frente a otra, en un eje este-oeste.
Estas pirámides son aplanadas y tienen escaleras en los cuatro lados. Una fila de estelas lisas se encuentra inmediatamente al oeste de la pirámide oriental y otra al norte de las pirámides. Ubicada a una misma distancia de las pirámides, se encuentra una serie de pares de estructuras, compuestas de un altar y una estela esculpida. En el lado sur de estos complejos hay un largo edificio abovedado, que contiene una sola habitación con nueve puertas.
El complejo entero fue construido en un mismo tiempo y estos complejos fueron construidos durante el Clásico Tardío, a intervalos de un "k'atun" (20 años).
El primer complejo de pirámides gemelas fue construido a principios del siglo , en la Plaza Oriental. Anteriormente se pensaba que estas pirámides gemelas eran exclusivas de Tikal, pero recientemente se han encontrado algunos otros ejemplos, en sitios como Yaxhá y Ixlu, lo que puede reflejar el grado de dominio político de Tikal, en el Clásico Tardío.

Conjunto Q es uno de los más grandes complejos de pirámides gemelas de Tikal. Fue construido por Yax Nuun Ayiin II, en el año 771, para marcar el fin del decimoséptimo K'atun.
La mayor parte del complejo ha sido restaurado y sus monumentos han sido reconstruidos.

Conjunto R es otro complejo de pirámides gemelas, que data de 790. Se encuentra cerca de la calzada Maler.

Tikal cuenta con miles de antiguas estructuras arquitectónicas, de las que sólo una fracción ha sido excavada, después de décadas de trabajo arqueológico. Entre los edificios más prominentes se incluyen seis pirámides muy grandes, cada uno soportando la estructura de un templo, en la parte superior. Algunas de estas pirámides tienen una altura de más de 60 metros. Fueron numeradas secuencialmente (templo I - VI), durante el estudio de campo inicial del yacimiento. Se estima que cada uno de estos grandes templos podría haberse construido en tan sólo dos años.

Las pirámides de Tikal fueron posicionadas una frente a otra y las salas que se construyeron en la parte superior de las pirámides tienen depresiones en las paredes de piedra, que sirven como amplificadores del sonido de la voz. Aquí, el diseño arquitectónico maya se realiza plenamente y la voz de los Ahau adquirió cualidades casi divinas. Debido a los resonadores de piedra en la parte superior de una pirámide, la voz de una persona, hablando a un volumen normal, puede ser escuchado por otra persona que se sitúa en la parte superior de otra pirámide, a una distancia sorprendente.

La mayoría de las pirámides visibles en la actualidad, se construyeron durante el resurgimiento, después del hiato de Tikal; es decir, a partir de finales del siglo , a principios del siglo . Sin embargo, cabe señalar que la mayoría de estas estructuras arquitectónicas tienen subestructuras, que se construyeron antes del Hiato de Tikal.

El Templo I (también conocido como "Templo de Ah Cacao" o "Templo del Gran Jaguar") es una pirámide funeraria, dedicada a Jasaw Chan K'awil, que fue sepultado en esta estructura, en el año 734.
La pirámide tiene una altura de 47 metros, y su construcción fue finalizada alrededor del 740 al 750.
La crestería masiva que encabeza el templo, fue originalmente decorada con una gigantesca escultura del rey en su trono, pero poco sobrevive de esta decoración.
La tumba del rey data del Clásico Tardío y fue descubierta en 1962.
Entre los objetos recuperados de la tumba, se encuentra una grande colección de tubos de huesos humanos y animales, con inscripciones y bandejas con escenas representando deidades y personas, finamente talladas y frotadas con bermellón, así como ornamentos de jade, de conchas y recipientes de cerámica, llenos de ofrendas, como alimentos y bebidas.
El santuario en la cumbre de la pirámide tiene tres cámaras consecutivas, con las entradas cruzadas por dinteles de madera, hechos de múltiples vigas. El dintel exterior era liso, pero los dos interiores eran tallados. Algunas de las vigas fueron removidas en el siglo  y se desconoce su ubicación actual. Otros fueron llevados a algunos museos de Europa.
El Templo II (también conocido como "Templo de las Máscaras") se construyó en torno al año 700, y tiene una altura de 38 metros. Al igual que otros grandes templos de Tikal, el santuario en su cumbre tenía tres cámaras consecutivas, con las entradas cruzadas por dinteles de madera, de los que sólo la mitad fue tallada. El templo era dedicado a la esposa de Jasaw Chan K'awil, aunque no se encontró su tumba. El retrato de la reina fue tallado en el dintel cruzando la entrada del santuario en la cumbre. Una de las vigas de este dintel se encuentra ahora en el Museo Americano de Historia Natural de Nueva York.

Templo III (también conocido como "Templo del Gran Sacerdote" o "Templo del Sacerdote Jaguar") fue la última de las grandes pirámides que se construyó en Tikal. Se levanta 55 metros y contenía un dintel de techo elaboradamente esculpido, pero dañado, que, posiblemente, muestra al rey Sol Oscuro, participando en una danza ritual, alrededor del año 810.
El santuario del templo tiene dos cámaras.

El Templo IV (también conocida como "Templo de la Serpiente Bicéfala"), es el más alto templo-pirámide de Tikal. Mide 70 metros, desde el nivel del suelo de la plaza, hasta la parte superior de su crestería.
Marca el reinado de Yik’in Chan Kawil (Gobernante B, el hijo del Gobernante A o Jasaw Chan K'awiil I); dos dinteles de madera tallada sobre la entrada que conduce al templo en la cumbre de la pirámide, muestra una fecha en cuenta larga (9.15.10.0.0), que corresponde al año 741. Templo IV es la pirámide más grande construida en toda la región maya, en el siglo , y en la actualidad es la más alta estructura precolombina en las Américas, a pesar de que la Pirámide del Sol, en Teotihuacan, originalmente pudo haber sido más alta, como también lo pudo haber sido una de las estructuras en El Mirador.

El Templo V se encuentra al sur de la Acrópolis Central y es la pirámide funeraria de un gobernante aún no identificado. El templo tiene una altura de 57 metros y es la segunda estructura más alta de Tikal - sólo el Templo IV es más alto.
El templo data del Clásico Tardío y ha sido fechado alrededor del año 700, mediante datación por radiocarbono. La cerámica asociada con la estructura, sitúa su construcción en el reinado de Nun Bak Chak, en la segunda mitad del siglo .

El Templo VI, también conocido como "Templo de las Inscripciones", fue dedicado en el año 766. Se nota por su crestería, que se eleva 12 metros. Paneles de glifos cubren la parte trasera y los lados de la crestería. El templo está en frente de una plaza ubicada al oeste y su fachada no ha sido restaurada.

El Templo 33 es una pirámide funeraria, erigida sobre la tumba de Siyaj Chan K'awiil I, (conocida como Entierro 48) en la Acrópolis Norte. Su construcción se inició en el Clásico Temprano, como una amplia plataforma basal, decorada con grandes mascarones de estuco, que flanqueaban la escalera. Siempre en el Clásico Temprano, se añadió una nueva superestructura, con sus propias máscaras y paneles decorados. Durante el Hiato de Tikal, se construyó una tercera etapa sobre las construcciones anteriores, la escalera fue demolida y el entierro real de un gobernante no identificado fue incluido en la estructura (Entierro 23). Durante la construcción de la nueva pirámide, se insertó la tumba de otra persona de alto rango (Entierro 24), en el núcleo de escombros del edificio. La pirámide se completó después, con una altura de 33 metros.

Estructura 34 es una pirámide en la Acrópolis Norte, que fue construida por Siyaj Chan K'awiil II, sobre la tumba de su padre, Yax Nuun Ayiin I. La pirámide fue coronado por un santuario de tres cámaras, las habitaciones situadas una detrás de otra.
La Estructura 5D-43 es un templo radial inusual, ubicado en la Plaza Oriental. Fue construida sobre un complejo de pirámides gemelas, en el extremo de la Plaza Juego de Pelota Oriental y tenía cuatro puertas de entrada y tres escaleras. La cuarta escalera, al lado sur, no fue construida, probablemente porque estaba demasiado cerca de la Acrópolis Central, como para tener una escalera en ese lado.
El edificio tiene el perfil de una plataforma "talud-tablero", modificada del estilo original encontrado en Teotihuacan y posiblemente más parecido al estilo de El Tajín y Xochicalco, que de Teotihuacan. Los paneles verticales del tablero son posicionados entre paneles de talud inclinados y tienen pares de símbolos de discos, como decoración. Símbolos de grandes flores, vinculados con los símbolos del planeta Venus y la estrella utilizados en Teotihuacan, son puestos en los paneles de talud inclinados. El techo de la estructura estaba decorada con frisos, aunque en la actualidad sólo permanecen fragmentos, mostrando una cara monstruosa, posiblemente la de un jaguar, con otra cabeza saliendo de la boca.
La segunda cabeza posee una lengua bifurcada, pero probablemente no es la de una serpiente.
El templo y el campo de juego de pelota asociado, probablemente datan del reinado de Nuun Ujol Chaak, o su hijo Jasaw Chan K'awiil I, de finales del siglo .

La Estructura 5C-49 data del siglo  y posee una relación evidente con el estilo arquitectónico de Teotihuacan. Cuenta con una fachada talud-tablero y balaustradas, un elemento arquitectónico muy raro en la región maya.
Está ubicada cerca de la pirámide del Mundo Perdido.

La Estructura 5C-53 es una pequeña plataforma de estilo teotihuacano, que data del año 600, aproximadamente. Tenía escaleras en los cuatro lados y no contaba con una superestructura.
La Pirámide Mundo Perdido (Estructura 5C-54) se encuentra en la parte suroeste del núcleo central de Tikal, al sur del Templo III y al oeste del Templo V.
Estaba decorada con máscaras de estuco del dios del sol y data del Preclásico Tardío.
Esta pirámide es parte de un complejo encerrado de estructuras, que se mantuvieron intactas y que no fueron afectadas por actividades de construcción posterior en Tikal. A finales del Preclásico Tardío, esta pirámide fue una de las estructuras más grandes en la región maya.
Obtuvo su forma definitiva durante el reinado de Chak Tok Ich'aak, en el siglo , en el Clásico Temprano y tiene una altura de 30 metros, con escaleras en sus cuatro lados. La parte superior es plana y, posiblemente, soportaba una superestructura construida con materiales perecederos.
A pesar de que la plaza fue afectada por una significativa alteración posterior, la organización de un grupo de templos, en el lado oriental de este complejo, se adhiere a la disposición de los llamados «Conjuntos E», identificados como observatorios solares.

La Estructura 5D-96 es el templo central, en el lado oriental de la Plaza de los Siete Templos. Ha sido restaurada y el exterior de la pared trasera está decorada con patrones de calavera y tibias cruzadas.

El Conjunto 6C-16 es un complejo residencial de la élite, que ha sido ampliamente excavado. Se encuentra a unos cientos de metros, al sur del complejo Mundo Perdido y las excavaciones han revelado elaboradas máscaras de estuco, pinturas murales de peloteros, esculturas en relieve y edificios con características del estilo de Teotihuacan.

El Juego de Pelota de la Gran Plaza es una pequeña pista del juego de pelota, que se encuentra entre el Templo I y la Acrópolis Central.

El Palacio de los Murciélagos, también conocida como el Palacio de las Ventanas, se encuentra al oeste del Templo III.
Tiene dos pisos, con dos series de cámaras en el piso inferior y una serie única, en el piso superior, que ha sido restaurado. El palacio tiene antiguas pintadas y cuenta con ventanas bajas.

El Complejo N se encuentra al oeste del Palacio de los Murciélagos y del Templo III. El complejo data del 711.

Altar 5 muestra dos nobles esculpidos, uno de los cuales es, probablemente, Jasaw Chan K'awiil I. Están llevando a cabo un ritual, con los huesos de una mujer importante.
Altar 5 se encuentra en el Complejo N, que se sitúa al oeste del Templo III.

Altar 8 muestra la escultura de un prisionero atado.
Se encontró dentro del Complejo P, en el Conjunto H. Actualmente se encuentra en el Museo Nacional de Arqueología y Etnología en la Ciudad de Guatemala.

Altar 9 está asociada con la Estela 21 y lleva la escultura de un prisionero atado. Se encuentra frente al Templo VI.

Altar 10 muestra la escultura de un prisionero atado a un andamio.
Se encuentra en el recinto norte del Conjunto Q, que consiste de un complejo de pirámides gemelas, que ha sido afectado por la erosión.

Altar 35 es un monumento sencillo, asociado con la Estela 43. La estela-altar está situada en la base de la escalera del Templo IV.

En Tikal, vigas talladas, hechas de la madera de "Manilkara zapota", fueron utilizadas como dinteles para las entradas interiores de los templos. Son los dinteles tallados más elaborados que han sobrevivido en toda la región maya.

El Dintel 3 del Templo IV fue trasladado a Basilea en Suiza, en el siglo . Representa a Yik'in Chan K'awiil sentado en un palanquín y está en condiciones casi perfecta.

Estelas son lajas de piedra tallada, a menudo esculpidas con figuras y glifos. Una selección de las estelas más notables de Tikal, incluye las siguientes:

La Estela 1 data del siglo  y representa al rey Siyaj Chan K'awiil II, de pie.

La Estela 4 data de 396 d. C.; es decir, del reinado de Yax Nuun Ayiin y después de la intrusión de Teotihuacan en el área maya.
La estela muestra una mezcla de características mayas y teotihuacanas, así como una mezcla de deidades de ambas culturas. Incluye un retrato del rey, con el Dios Jaguar del inframundo bajo uno de sus brazos y el Tláloc mexicano bajo el otro. Su casco es una versión simplificada de la Serpiente de Guerra de Teotihuacan. Yax Nuun Ayiin es representado con la cara de frente y no de perfil, algo inusual para una escultura maya, pero típico de Teotihuacan,
La Estela 5 fue dedicada en 744, por Yik'in Chan K'awiil.

La Estela 6 es un monumento muy dañado, que data de 514 d. C. Lleva el nombre de la Señora de Tikal, que está celebrando el final del cuarto K'atun de ese año.

La Estela 10 está emparejada con la Estela 12, pero está muy dañada. Describió la consagración de Kaloomte' B'alam, a principios del siglo  y eventos anteriores de su carrera, incluyendo la captura de un prisionero, representado en el monumento.

La Estela 11 fue el último monumento erigido en Tikal. Fue dedicada en 869 d. C., por Jasaw Chan K'awiil II.

La Estela 12 está asociada con la reina conocida como la Señora de Tikal y el rey Kaloomte' B'alam. La reina es descrita llevando a cabo los rituales de fin de año, pero el monumento fue dedicado en honor al rey.

La Estela 16 fue dedicada en el año 711, durante el reinado de Jasaw Chan K'awiil I. La escultura se limita a la parte frontal del monumento e incluye el retrato del rey y un texto glífico.
Fue encontrada en el Complejo N, al oeste del Templo III.

La Estela 19 fue dedicada en 790, por Yax Nuun Ayiin II.

La Estela 20, encontrada en el Complejo P, del Conjunto H, fue trasladada al Museo Nacional de Arqueología y Etnología en la Ciudad de Guatemala.

La Estela 21 fue dedicada en 736, por Yik'in Chan K'awiil.
Sólo la parte inferior de la estela quedó intacta. El resto ha sido mutilado en tiempos antiguos. La parte restante de la escultura es de buena calidad y consiste de los pies de una figura y del texto glífico correspondiente. La estela es asociada con el Altar 9 y se encuentra frente al Templo VI.>

La Estela 24 fue erigida, junto con Altar 7, al pie del Templo III en 810 d. C. Ambos fueron quebrados en tiempos antiguos, aunque el nombre del gobernante Sol Oscuro sobrevive, en tres de los fragmentos.

La Estela 29 incluye una fecha en cuenta larga (8.12.14.8.15) equivalente a 292 d. C., la primera fecha en cuenta larga superviviente de las tierras bajas mayas.
La estela es también el monumento más antiguo a incluir el glifo emblema de Tikal. Tiene una escultura del rey, girado hacia la derecha, sosteniendo la cabeza de un dios jaguar del inframundo, una de las deidades protectoras de la ciudad. La estela fue deliberadamente destruida, en el siglo , o algún tiempo después. La parte superior fue tirada en un basurero cercano al Templo III, para ser descubiertos por arqueólogos en 1959.

La Estela 30 fue el primer monumento sobreviviente que se erigió, después del Hiato de Tikal. Su estilo y la iconografía es similar a la de El Caracol, uno de los más importantes enemigos de Tikal.

La Estela 31 es el monumento que marca la consagración de Siyaj Chan K'awiil II. Incluye también dos retratos de su padre, Yax Nuun Ayiin, vestido como un guerrero joven de Teotihuacan. Lleva un lanzadardos en una mano y un escudo decorado con la cara de Tláloc, el dios de la guerra de Teotihuacan.
En la antigüedad, la escultura se rompió y la parte superior se trasladó a la cumbre del Templo 33, donde fue ritualmente enterrado.
La Estela 31 ha sido descrita como la más importante de las esculturas supervivientes de Tikal, del Clásico Temprano. Un largo texto glífico está tallado en la parte posterior del monumento, el más largo conocido del Clásico Temprano.
Describe la llegada de Siyah K'ak' en El Perú y Tikal, en enero de 378 y fue la primera estela de Tikal en ser tallada por sus cuatro caras.

La Estela 32 es un monumento fragmentado, con una escultura en estilo teotihuacano, que parece representar al gobernante de la ciudad con atributos de Tláloc, el dios de la tormenta del centro de México, incluyendo sus ojos saltones y su tocado.

La Estela 39 es un monumento quebrado, que fue erigido en el complejo Mundo Perdido. Falta la parte superior de la estela, pero la parte restante muestra las piernas y la parte inferior del cuerpo de Chak Tok Ich'aak, sosteniendo un hacha de pedernal en la mano izquierda. Está pisoteando la figura de un prisionero atado y ricamente vestido. El monumento data de 376 d. C. El texto en la parte posterior del monumento, describe un ritual de derramamiento de sangre, para celebrar un fin de Katun.
La estela también identifica el nombre del padre de Chak Tok Ich'aak como K'inich Muwaan Jol.
La Estela 40 lleva el retrato de Kan Chitam y data del año 468 d. C.

La Estela 43 es emparejada con el Altar 35. Es un monumento sencillo, ubicado a la base de la escalera del Templo IV.

Entierro 1 es una tumba, ubicada en el complejo Mundo Perdido, donde se recuperó un tazón de cerámica fina, con el mango formado por la cabeza y el cuello de un pájaro, que surge del cuerpo pintado en la tapa.

Entierro 10 es la tumba de Yax Nuun Ayiin.
Se encuentra por debajo de la Estructura 34, en la Acrópolis Norte. La tumba contenía un amplio abanico de ofrendas, incluyendo recipientes de cerámica y alimentos y nueve jóvenes fueron sacrificados, para acompañar al difunto rey.
Un perro fue también sepultado con el rey difunto. Las macetas encontradas en la tumba eran estucadas y pintadas, muchas en una mezcla de estilos mayas y teotihuacanos.
Entre las ofrendas había un incensario, en forma de un viejo dios del inframundo, sentado en un banco de huesos humanos y sosteniendo una cabeza cortada en las manos.
La tumba fue sellada con una bóveda, encima de la cual fue construida la pirámide.

Entierro 48 es generalmente aceptada como la tumba de Siyaj Chan K'awil. Se encuentra bajo el Templo 33, en la Acrópolis Norte.
La cámara de la tumba fue tallada de la roca madre y contenía los restos del rey, junto con los de dos adolescentes, que habían sido sacrificados para acompañar al gobernante fallecido.
Las paredes de la tumba eran cubiertas con estuco de color blanco con glifos pintados que incluían el equivalente en cuenta larga del 20 de marzo de 457, probablemente, la fecha de la muerte o del entierro del rey.
Al esqueleto del rey le faltaba el cráneo, sus fémures y una de sus manos, mientras que los esqueletos de las víctimas sacrificadas estaban intactos.

El Entierro 85 es una tumba que data del Preclásico Tardío y que fue encerrada por una plataforma, con una primitiva bóveda ménsula. La tumba contenía el esqueleto de un varón, que carecía de cráneo y de fémures.
El fundador de la dinastía de Tikal, Yax Ehb' Xook, ha sido vinculado a esta tumba, que se encuentra en el corazón de la Acrópolis Norte.
El difunto, probablemente, había fallecido en batalla, en la que su cuerpo fue mutilado por sus enemigos, antes de ser recuperado y enterrado por sus seguidores. Los huesos fueron cuidadosamente envueltos en textiles, para formar un paquete en posición vertical.
La cabeza fue reemplazada por una pequeña máscara de piedra verde con incrustaciones de concha, para representar los dientes y los ojos, llevando una diadema real de tres puntas.
Esta máscara tiene un emblema de gobernante en la frente y es un raro retrato de un rey maya del Preclásico.
El contenido de la tumba incluía también la columna vertebral de una raya, una concha del género "spondylus" y veintiséis recipientes de cerámica.

Entierro 116 es la tumba de Jasaw Chan K'awiil I. Es una cámara abovedada grande, ubicada en medio de la pirámide, por debajo del nivel de la Gran Plaza. La tumba contenía ricas ofrendas de jadeíta, cerámica, conchas y obras de arte. El cuerpo del rey fue cubierto con una gran cantidad de ornamentos de jade, incluyendo un collar con cuentas muy grandes, como se muestran en los retratos esculpidos del rey. Una de las piezas sobresalientes que se recuperó de la tumba, fue un recipiente de jade, adornado con el retrato del propio rey, esculpido en la tapa.

Entierro 195 es una tumba que se inundó de lodo en la antigüedad, cubriendo los objetos de madera, que se habían podrido completamente, cuando la tumba fue excavada, dejando huecos en el barro seco. Posteriormente, los arqueólogos llenaron estos huecos con estuco y, de esta manera, obtuvieron cuatro efigies del dios K'awiil, a pesar de que las originales, de madera, habían desaparecidas desde hacía mucho tiempo.

Entierro 196 es una tumba real del Clásico Tardío, que contenía un recipiente de mosaico de jade, rematada con la cabeza del dios del maíz.

1999-2001 una producción con un enfoque científico Imax,voz Narrativa Harrison Ford
Editada en 5 idiomas,




</doc>
<doc id="21889" url="https://es.wikipedia.org/wiki?curid=21889" title="Variable aleatoria">
Variable aleatoria

Una variable aleatoria es una función que asigna un valor, usualmente numérico, al resultado de un experimento aleatorio. Por ejemplo, los posibles resultados de tirar un dado dos veces: (1, 1), (1, 2), etc. o un número real (p.e., la temperatura máxima medida a lo largo del día en una ciudad concreta).

Los valores posibles de una variable aleatoria pueden representar los posibles resultados de un experimento aún no realizado, o los posibles valores de una cantidad cuyo valor actualmente existente es incierto (p.e., como resultado de medición incompleta o imprecisa). Intuitivamente, una variable aleatoria puede tomarse como una cantidad cuyo valor no es fijo pero puede tomar diferentes valores; una distribución de probabilidad se usa para describir la probabilidad de que se den los diferentes valores. En términos formales una variable aleatoria es una función definida sobre un espacio de probabilidad.

Las variables aleatorias suelen tomar valores reales, pero se pueden considerar valores aleatorios como valores lógicos, funciones o cualquier tipo de elementos (de un espacio medible). El término "elemento aleatorio" se utiliza para englobar todo ese tipo de conceptos relacionados. Un concepto relacionado es el de proceso estocástico, un conjunto de variables aleatorias ordenadas (habitualmente por orden o tiempo).

Una variable aleatoria puede concebirse como un valor numérico que está afectado por el azar. Dada una variable aleatoria no es posible conocer con certeza el valor que tomará esta al ser medida o determinada, aunque sí se conoce que existe una distribución de probabilidad asociada al conjunto de valores posibles. Por ejemplo, en una epidemia de cólera, se sabe que una persona cualquiera puede enfermar o no (suceso), pero no se sabe cuál de los dos sucesos va a ocurrir. Solamente se puede decir que existe una probabilidad de que la persona enferme.

Para trabajar de manera sólida con variables aleatorias en general es necesario considerar un gran número de experimentos aleatorios, para su tratamiento estadístico, cuantificar los resultados de modo que se asigne un número real a cada uno de los resultados posibles del experimento. De este modo se establece una relación funcional entre elementos del espacio muestral asociado al experimento y números reales.

Una variable aleatoria (v.a.) "X" es una función real definida en el espacio de probabilidad, formula_1, asociado a un experimento aleatorio.

La definición formal anterior involucra conceptos matemáticos sofisticados procedentes de la teoría de la medida, concretamente la noción σ-álgebra o la de medida de probabilidad. Dado un espacio de probabilidad formula_2 y un espacio medible formula_3, una aplicación formula_4 es una variable aleatoria si es una aplicación formula_5-medible. En el uso ordinario, los puntos de formula_6 no son directamente observables, sólo el valor de la variable en el punto formula_7 por lo que el elemento probabilístico reside en el desconocimiento que se tiene del punto concreto formula_8 .

En la mayoría de usos práctios se tiene que el espacio medible de llegada es formula_9, quedando pues la definición de esta manera:
Se llama rango de una variable aleatoria "X" y lo denotaremos R, a la imagen o rango de la función formula_10, es decir, al conjunto de los valores reales que ésta puede tomar, según la aplicación X. Dicho de otro modo, el rango de un v.a. es el recorrido de la función por la que ésta queda definida:...
Supongamos que se lanzan dos monedas al aire. El espacio muestral, esto es, el conjunto de resultados elementales posibles asociado al experimento, es:
donde ("c" representa "sale cara" y "x", "sale cruz"). Podemos asignar entonces a cada suceso elemental del experimento el número de caras obtenidas. De este modo se definiría la variable aleatoria X como la función

dada por

El recorrido o rango de esta función, R, es el conjunto

El nivel "X" de precipitación registrado un día concreto del año, en una ciudad por una estación meteorológica concreta. El espacio muestral que incluye todos los posibles resultados puede representarse por el intervalo formula_15. En este caso el espacio muestral es más complicado porque incluiría especificar el estado de la atmósfera completo (una aproximación sería describir el conjunto de posiciones y velocidades de todas las moléculas de la atmósfera, que sería una cantidad de información monumental o usar un modelo más o menos complejo en términos de variables macroscópicas, como los modelos meteorológicos usados actualmente).

Podemos revisar la serie histórica de precipitaciones y aproximar la distribución de probabilidad formula_16 de "X" y consturir una aproximación formula_17. Nótese que en este caso la distribución de probabilidad no es conocida, sólo se conoce la distribución muestral (la serie histórica) y se conjetura que la distribución real no se aleja mucho de esta aproximaxión formula_18. Si la serie histórica es suficientemente larga y representa un clima que no difiere significativamente del actual estas dos úlitmas funciones diferirán muy poco.

Para comprender de una manera más amplia y rigurosa los tipos de variables, es necesario conocer la definición de conjunto discreto. Un conjunto es discreto si está formado por un número finito de elementos, o si sus elementos se pueden enumerar en secuencia de modo que haya un primer elemento, un segundo elemento, un tercer elemento, y así sucesivamente (es decir, un cojunto infinito numerable sin puntos de acumulación). Para variables con valores en formula_19 las variables aleatorias se clasifican usualmente en:
Las definiciones anteriores pueden generalizarse fácilmente a variables aleatorias con valores sobre formula_20 o formula_21. Esto no agota el tipo de variables aleatorias ya que el valor de una variable aleatoria puede ser también una partición, como sucede en el proceso estocástico del restaurante chino o el conjunto de valores de una variable aleatoria puede ser un conjunto de funciones como el proceso estocástico de Dirichlet.

La distribución de probabilidad de una v.a. X, también llamada función de distribución de X es la función formula_16, que asigna a cada evento definido sobre formula_10 una probabilidad dada por la siguiente expresión:

Y de manera que se cumplan las siguientes tres condiciones:

La distribución de probabilidad de una v.a. describe teóricamente la forma en que varían los resultados de un experimento aleatorio. Intuitivamente se trataría de una lista de los resultados posibles de un experimento con las probabilidades que se esperarían ver asociadas con cada resultado.

La función de densidad de probabilidad (FDP) o, simplemente, función de densidad, representada comúnmente como "f(x)", se utiliza con el propósito de conocer cómo se distribuyen las probabilidades de un suceso o evento, en relación al resultado del suceso.

La FDP es la derivada (ordinaria o en el sentido de las distribuciones) de la función de distribución de probabilidad "F(x)", o de manera inversa, la función de distribución es la integral de la función de densidad:

La función de densidad de una v.a. determina la concentración de probabilidad alrededor de los valores de una variable aleatoria continua.

Sea una variable aleatoria formula_26 sobre formula_27 y una función medible de Borel formula_28, entonces formula_29 será también una variable aleatoria sobre formula_30, dado que la composición de funciones medibles también es medible a no ser que formula_31 sea una función medible de Lebesgue. El mismo procedimiento que permite ir de un espacio de probabilidad formula_32 a formula_33 puede ser utilizado para obtener la distribución de formula_34. La función de probabilidad acumulada de formula_34 es

Si la función "g" es invertible, es decir "g existe, y es monótona creciente, entonces la anterior relación puede ser extendida para obtener

y, trabajando de nuevo bajo las mismas hipótesis de invertibilidad de "g" y asumiendo además diferenciabilidad, podemos hallar la relación entre las funciones de densidad de probabilidad al diferenciar ambos términos respecto de "y", obteniendo

Si "g" no es invertible pero cada "y" tiene un número finito de raíces, entonces la relación previa con la función de densidad de probabilidad puede generalizarse como

donde "x = g(y)". Las fórmulas de densidad no requieren que "g" sea creciente.

Sea "X" una variable aleatoria real continua y sea "Y" = "X".

Si "y" < 0, entonces P("X" = "y") = 0, por lo tanto

Si "y" ≥ 0, entonces

por lo tanto

La función de densidad o la distribución de probabilidad de una variable aleatoria (v.a.) contiene exhaustivamente toda la información sobre la variable. Sin embargo, resulta conveniente resumir sus características principales con unos cuantos valores numéricos. Entre estos están la esperanza y la varianza (aunque para caracterizar completamente la distribución de probabilidad se necesitan parámetros estadísticos adicionales).

La esperanza matemática (o simplemente esperanza) o valor esperado de una v.a. es la suma del producto de la probabilidad de cada suceso por el valor de dicho suceso. Si todos los sucesos son de igual probabilidad la esperanza es la media aritmética. Para una variable aleatoria discreta con valores posibles formula_36 y sus probabilidades representadas por la función de probabilidad formula_37 la esperanza se calcula como:

Para una variable aleatoria continua la esperanza se calcula mediante la integral de todos los valores y la función de densidad formula_38:
La esperanza también se suele simbolizar con formula_41

El concepto de esperanza se asocia comúnmente en los juegos de azar al de beneficio medio o beneficio esperado a largo plazo.

La varianza es una medida de dispersión de una variable aleatoria formula_42 respecto a su esperanza formula_43. Se define como la esperanza de la transformación formula_44: 

Dada una distribución de probabilidad continua el conjunto de sus momentos caracteriza completamente la distribución. Dos de estos momentos ya han aparecido, el valor esperado coincide con el momento de primer orden, mientras que la varianza puede expresarse como una combinación del momento de segundo orden y el cuadrado del momento de primer orden. En general, el momento de orden "n" de una variable aleatoria real con densidad de probabilidad definida casi en todas partes se calcula como:

Estos momentos pueden obtenerse a partir de las derivadas "n"-ésimas de la función característica formula_45 asociada a la variable "X":

o análogamente la función generadora de momentos:



</doc>
<doc id="21891" url="https://es.wikipedia.org/wiki?curid=21891" title="Quiché (etnia)">
Quiché (etnia)

Quiché (o k'iche' ) es el nombre de un pueblo nativo de Guatemala, así como el de su idioma y su nación en tiempos precolombinos. El término "quiché" proviene de "qui", o "quiy", que significa "muchos", y "che", palabra maya original, que alude a un bosque o tierra de muchos árboles. El Quiché es también el nombre de un departamento de Guatemala.

El pueblo quiché es uno de los pueblos mayas nativos del altiplano guatemalteco. En tiempos precolombinos los quichés establecieron uno de los más poderosos estados de la región. Aunque en la actualidad se habla de los pueblos indigenas guatemaltecos como los Quiches, Kacchiqueles, Zutuiles, Mams etc. como pueblos Mayas, estos no lo son, ya que provienen del imperio Azteca en el año 900 d.c. hasta el 1100 d.c. y se convierten en pueblos tributarios del imperio Maya ocupando las tierras que aun en la actualidad ocupan. La última ciudad capital era Gumarcaaj, también conocida como Utatlán, cuyas ruinas se encuentran a dos kilómetros de Santa Cruz del Quiché, en el departamento de El Quiché, Guatemala.

Fueron conquistados por el español Pedro de Alvarado a principios del siglo XVI, en 1524. El último comandante del ejército quiché fue Tecún Umán, quien fue muerto por de Alvarado en la batalla de los Llanos del Pinal. Tecún Umán es todavía un héroe popular nacional y figura de leyenda, también es el héroe nacional de Guatemala.

El departamento de Quiché fue nombrado así en alusión a este pueblo que en su inicio ocupó el territorio denominado "Quix Ché" que significa "árboles con espinas" pues en la región abundaron los magueyes, nopales, ortigas, etc. Este departamento es el hogar central del pueblo quiché, aunque en tiempos recientes se ha dispersado sobre un área más amplia del territorio guatemalteco.

La agricultura ha constituido la base de la economía maya desde la época precolombina y el maíz su principal cultivo, además del algodón, los frijoles (judías), el camote (batata), la yuca (o mandioca) y el cacao. Las técnicas del hilado, el tinte y el tejido consiguieron un elevado grado de perfección. Los mayas domesticaron el pavo, pero carecían de animales de tiro o vehículos con ruedas. Fabricaban finos objetos de cerámica, que difícilmente se han superado en el Nuevo Mundo fuera de Perú. Como unidad de cambio se utilizaban las semillas de cacao y las campanillas de cobre, material que se empleaba también para trabajos ornamentales, al igual que el oro, la plata, el jade, las conchas de mar y las plumas de colores. Sin embargo, desconocían las herramientas metálicas. Los pueblos maya formaban una sociedad muy jerarquizada. Estaban gobernados por una autoridad política, el "halach vinic", cuya dignidad era hereditaria por línea masculina. Éste delegaba la autoridad sobre las comunidades de poblados a jefes locales o bataboob, que cumplían funciones civiles, militares y religiosas.

El quiché es parte de la familia de lenguas mayenses. El número de hablantes es entre 1 y 2 millones de personas, principalmente en los departamentos de El Quiché, Totonicapán, Sololá, Quetzaltenango, Huehuetenango y Suchitepéquez. Es el idioma maya con más hablantes en Guatemala y el segundo del país después del español. La mayoría de los indígenas quichés también habla el idioma español, excepto en algunas áreas rurales aisladas.

El texto más famoso en idioma quiché es el Popol Vuh, que narra del origen de este pueblo desde la creación del mundo, de los dioses y de los primeros hombres y mujeres, formados de maíz, hasta la conquista española.

Rigoberta Menchú, que obtuvo el Premio Nobel de la Paz en 1992, forma parte de la etnia quiché.

Humberto Ak'abal, autor quiché mundialmente reconocido y ganador de diversos premios a nivel internacional.



</doc>
<doc id="21892" url="https://es.wikipedia.org/wiki?curid=21892" title="Andrew S. Tanenbaum">
Andrew S. Tanenbaum

Andrew Stuart "Andy" Tanenbaum (nacido el 16 de marzo de 1944), también conocido como ast o Papá Tanenbaum, es profesor de ciencias de la computación de la Universidad Libre de Ámsterdam, Países Bajos. 

Tanenbaum es más conocido por ser el creador de Minix, una réplica gratuita del sistema operativo UNIX con propósitos educativos, y por sus libros sobre ciencias de la computación.

Tanenbaum nació en la ciudad de Nueva York, Estados Unidos aunque creció en White Plains. Se licenció en física en el Instituto Tecnológico de Massachusetts (más conocido como MIT), en 1965. 

En 1971 consiguió el doctorado en física en la Universidad de California, Berkeley. 
Posteriormente se trasladó a los Países Bajos para vivir con su esposa, pero aún conserva la ciudadanía estadounidense. 

Desde 2004 es profesor de Arquitectura de ordenadores y sistemas operativos en la Universidad Libre de Ámsterdam (Vrije Universiteit Amsterdam) donde lidera un grupo de sistemas de computación.

En 1987 creó el sistema operativo Minix, un sistema Unix-like gratuito con propósitos educativos, que posteriormente inspiró Linux. 

En 1992 participó en Usenet en un encendido debate con Linus Torvalds, el creador de Linux, sobre los méritos de la idea de Linus de utilizar un núcleo monolítico en vez de los diseños basados en un micronúcleo que Tanenbaum creía que serían la base de los sistemas operativos futuros. Dicho debate se originó en el grupo de noticias comp.os.minix cuando Andrew envió un mensaje con el título "LINUX is obsolete" (en español, LINUX está obsoleto).

Tanenbaum es el autor, junto a otros miembros de la Universidad Libre de Ámsterdam, del sistema operativo distribuido de investigación Amoeba, basado en una arquitectura de micronúcleo. Tanenbaum también es el creador de Globe, un software que provee una infraestructura para un sistema distribuido a nivel mundial.

Tanenbaum es ampliamente conocido por sus libros sobre materia informática, muy utilizados en centros de enseñanza superior, destacando, entre otros:

En los siguientes enlaces se puede encontrar una lista exhaustiva de los libros y publicaciones realizados por Tanenbaum:

En 2004 crea Electoral-vote.com, un sitio web donde se analizaban los sondeos de opinión para las elecciones presidenciales de Estados Unidos de 2004 para prever cual sería la composición del Colegio Electoral.

Durante la mayor parte de campaña, Tanenbaum oculta su identidad bajo el seudónimo de «Votemaster», aunque reconociendo que tiene una preferencia personal por el candidato John Kerry. El 1 de noviembre de 2004, el día anterior a las elecciones, Tanenbaum revela su identidad y las razones por las que creó la página web.

En 2006, la web Electoral-vote.com es nuevamente utilizada para analizar los sondeos de las elecciones para el Congreso de Estados Unidos de 2006.

Tanembaum ha recibido diversos premios por su trabajo:



</doc>
<doc id="21896" url="https://es.wikipedia.org/wiki?curid=21896" title="Perro sin pelo del Perú">
Perro sin pelo del Perú

El perro sin pelo del Perú, perro peruano sin pelo, perro calato o viringo es una raza de perro sin pelo originaria del Perú empleada usualmente como animal de compañía. Ha sido reconocido oficialmente como Patrimonio Nacional del Perú.

El 12 de junio de 1995, la Federación Cinológica Internacional (FCI), con sede en Thuin (Bélgica), reconoció y registró al perro sin pelo del Perú en su nomenclatura de razas con el número 310, clasificándolo en el Grupo V, tipo Spitz, que es para aquellos perros atléticos y ágiles ideales para carreras y en la sección 6 en la que se ubican los perros tipo primitivos.

Al calificársele de perro primitivo, se le reconoce como de raza pura, es decir, la naturaleza los hizo tal como son, no habiendo variado sus características morfológicas en miles de años, tal como puede apreciarse en diferentes huacos preincas.

El Instituto Nacional de Cultura del Perú mediante la resolución directiva 001-INC de enero de 2001 dispuso la ubicación de perros sin pelo del Perú en todos los museos de sitio y zonas arqueológicas ubicados en la costa peruana y que cuenten con las condiciones necesarias que permitan su desarrollo natural y su crianza.

A su vez, el Congreso de la República del Perú, mediante el decreto ley número 27537 del 22 de octubre de 2001 incluyó a esta raza como patrimonio de la nación peruana y la reconoció como oriunda de este país.

El 8 de marzo de 2013, el Gobierno del Perú designó a la arqueóloga Denise Pozzi-Escot representante del Ministerio de Cultura ante el Comité Nacional de Protección del Perro sin Pelo del Perú.

Existen representaciones que aparecen en los ceramios de distintas culturas preincas, como Vicús, Mochica, Chancay, Chancay con influencia tiahuanacoide, Sicán y Chimú. En estas representaciones, el perro sin pelo hace su aparición entre el año 300 a. C. hasta el 1460.

Se han encontrado también huesos del perro peruano que datan de tiempos precolombinos. En 1987, el arqueólogo Walter Alva descubrió en el centro de una gran plataforma de barro conocida como "Huaca Rajada", la tumba de un personaje importante moche a quien llamó el Señor de Sipán, que descansaba en una caja mortuoria, rodeado de los esqueletos de ocho varones, dos mujeres y un perro.

Los incas lo llamaban "allqu" (‘perro’); en el Perú también se conoció como "kaclla". El nombre "viringo" parece ser el original usado por los moches o mochicas, cuyos descendientes (entre Piura y Trujillo) hasta el día de hoy los nombran así.

Estos perros cumplieron un rol importante dentro de las costumbres y mitos de los incas. Las crónicas de la época de la conquista española y el Virreinato dieron testimonio de la presencia de los "viringos". La gente del campo conservó el perro sin pelos, asociado a su cultura propia y lo usó para fines medicinales.

Debido a la carencia de pelo, esta raza mantiene su cuerpo más caliente para protegerse del ambiente. Pedro Weiss señala en sus investigaciones que el perro sin pelo del Perú genéticamente tiene un síndrome de hipoplasia ectodérmica, lo cual significa que posee piel cálida que al entrar en contacto con la piel humana la puede calentar, lo cual ha sido base para atribuirle propiedades medicinales, por ejemplo para aliviar el reumatismo.

Hay quienes le han atribuido al perro peruano la capacidad de evitar alergias, problemas bronquiales y asma, pues no tiene pelo que podría causar problemas respiratorios, tampoco pulgas ni garrapatas, ya que estas no tienen dónde anidar.

Existen tres tipos de razas según su talla:

El peso está en relación con los tres tamaños para los machos y para las hembras:

La piel del perro peruano sin pelo es muy variable, hay ejemplares de color negro pizarra con pelo negro, negro azulado con pelo rubio,y marrón con pelo castaño. Hay ejemplares de color entero (color que oscila entre los mostrados en las fotos, y el negro) y hay otros que presentan manchas blancas o rosadas, principalmente en la cara y en el pecho.

Muy rara vez, cuando nace una nueva camada, uno de los cachorros nace con pelo, debido a un gen recesivo.

En la mayoría de los casos los perros sin pelo del Perú no ofrecen problemas relacionados con la reproducción. Los ejemplares de talla grande suelen tener camadas más numerosas que los de talla pequeña. Debido a la ausencia de pelo es importante mantenerlos en una zona cálida y vigilar que la temperatura ambiental no baje de los 23 grados, es recomendable que cuenten con alguna fuente de calor si el área donde están alojados no alcanza la temperatura anteriormente indicada. Es fundamental suministrar a la hembra una alimentación equilibrada rica en proteínas, los piensos de fabricación industrial de gama alta son los más indicados para el buen fin de la reproducción.

La ausencia de pelo en el perro viringo o calato es consecuencia de una mutación natural de tipo dominante. Los genes dominantes para la calvicie presenta una estructura heterocigota (dominancia parcial), con lo que en la descendencia entre ejemplares pelones nacerán mayoritariamente perros sin pelo, no obstante, aquellos canes que porten dos genes dominantes no se gestarán ya que este gen en homocigosis es letal.

En la cruza de dos ejemplares sin pelo, puede nacer algún ejemplar con pelo, esto se debe a la estructura hetorocigota de los alelos que portan los progenitores, concretamente la variedad con pelo hereda los alelos en homocigosis para el gen recesivo.

La variedad con pelo es valorada por muchos criadores apasionados a esta raza ya que fortalece la genética del perro peruano, en estos casos, el resultado de la cruza entre un ejemplar sin pelo y otro con manto normal es de un 50% de cachorros desnudos, el resto con manto peludo. Cabe destacar que los canes que nacen con pelo normal no presentan las anomalías típicas de los perros desnudos, como es el caso de la pérdida prematura de algunas piezas dentales.

El gen causante de la desnudez se denomina «gen Foxi3» y también está presente en otras razas de perros desnudos como es el caso del xoloitzcuintle o el crestado chino.



</doc>
<doc id="21898" url="https://es.wikipedia.org/wiki?curid=21898" title="Organización Internacional de la Francofonía">
Organización Internacional de la Francofonía

Se denomina Francofonía al conjunto de países, comunidades o individuos que emplean habitualmente el francés. La Organización Internacional de la Francofonía es una organización internacional que designa la comunidad de 900 millones de personas y países en el mundo que usan este idioma. Son miembros de pleno derecho cuarenta y nueve estados, además de cuatro miembros asociados y diez miembros observadores. La mayoría de los estados miembros son francófonos. 

Sus actividades no se centran exclusivamente en la lengua, sino también en la difusión de la cultura, la educación, extensión de la democracia y reducción de las diferencias como consecuencia de las nuevas tecnologías. Se organiza en Cumbres de Jefes de Estado y de Gobierno que se celebran cada dos años, la Conferencia de Ministros y la Comisión Permanente que actúa como órgano ejecutivo. 

Desde 2015 al frente de la Secretaría General de la Francofonía se encuentra la canadiense Michaëlle Jean.

Fue fundada el 20 de marzo de 1970 en Niamey, Níger. La iniciativa surgió, en especial, por los países de habla francesa de África. Sus principales impulsores fueron los Jefes de Estado Habib Bourguiba (Túnez), Norodom Sihanouk (Camboya), Hamani Diori (Níger), Charles Hélou (Líbano) y Léopold Sédar Senghor (Senegal). Actualmente la sede central está en París y agrupa a Estados francófonos que tienen un nexo cultural. 

Hay que distinguir entre los países donde el francés es lengua oficial, aquellos donde es la lengua materna de gran parte de la población, aquellos donde es lengua de difusión cultural, aquellos donde es empleado por determinadas clases sociales, etc. Estas categorías no tienen por qué coincidir: en muchos de los países en los que el francés es lengua oficial, no es la lengua materna de la población.

En 2008 la Francofonía estaba compuesta por cuarenta y nueve Estados miembros que albergan el 10 por 100 de la población mundial. Sus actividades no se centran exclusivamente en la lengua, sino también en la difusión de la cultura, la educación, extensión de la democracia y reducción de las diferencias como consecuencia de las nuevas tecnologías. Se organiza en Cumbres de Jefes de Estado y de Gobierno que se celebran cada dos años, la Conferencia de Ministros y la Comisión Permanente que actúa como órgano ejecutivo.

Mantiene cinco agencias internacionales con un presupuesto en conjunto de 230 millones de euros:

La Francofonía proclama entre sus principios y valores fundamentales los siguientes:

La palabra fue acuñada por Onésimo Reclus.





</doc>
<doc id="21899" url="https://es.wikipedia.org/wiki?curid=21899" title="Francés (desambiguación)">
Francés (desambiguación)

Francés puede referirse a:


Asimismo, puede hacer referencia a:






</doc>
<doc id="21915" url="https://es.wikipedia.org/wiki?curid=21915" title="Modelismo ferroviario">
Modelismo ferroviario

El modelismo ferroviario es una actividad recreativa cuyo objeto es imitar a escala trenes y sus entornos. Los trenes pueden ser estáticos o en movimiento. En este último caso, normalmente se utiliza electricidad de bajo voltaje (entre 9 y 24 voltios) tanto para el movimiento como para los accesorios, iluminación, etc. y son conocidos comúnmente como trenes eléctricos a escala. Durante parte del siglo XX también han sido populares los de cuerda y existen modelos de locomotoras propulsadas por vapor real.

La escala normalizada más popular a finales del siglo XX y principios del XXI es la H0, seguida de la N. Pero existen otras.

En el Reino Unido, las escalas habituales son distintas y están basadas en la reducción de medidas imperiales a sistema métrico. Se suelen denominar por el número de milímetros a escala que corresponden a un pie real:

Por otra parte, se fabrican nuevamente ferrocarriles de escalas grandes, como las antiguas, con las cuales los aficionados consiguen una reproducción muy detallada de las locomotoras y los vagones. Algunas de las marcas que fabrican trenes de estas escalas disponen de modelos a prueba de intemperie, lo que permite montar los circuitos y hacer circular los trenes al aire libre, incluso cuando llueve. La escala G (1:24), desarrollada en 1968, también se conoce como la Escala de jardín, ya que a menudo se usa al aire libre. Este tamaño es conocido por una artesanía y detalle impresionantes, pero requiere una gran cantidad de espacio de modo que no es la elección más común para los coleccionistas interiores.

Desde los principios del modelismo ferroviario, la velocidad de los trenes se controlaba variando la tensión presente en la vía, de la cual se alimentan los motores de los mismos. Existen dos sistemas principales: el de corriente continua, con dos carriles, y el de tres carriles, de corriente alterna.

El sistema de dos carriles usa corriente continua y alimenta las locomotoras y vagones por uno de los carriles y retorna por el otro. Los carriles tienen, por tanto, polaridad. Variando esta polaridad se consigue invertir el sentido de la marcha.

El sistema de tres carriles utiliza corriente alterna que alimenta por los carriles de circulación por un lado y tiene un tercer carril central, entre ellos, para el retorno. Dado que la corriente alterna no tiene una polaridad constante, para invertir el sentido de la marcha se envía a la locomotora una sobretensión de aproximadamente 20 a 24 voltios que activa un mecanismo mecánico o electrónico de inversión. 

Las locomotoras de dos carriles y las de tres carriles no son compatibles entre sí. Los vagones pueden serlo, de acuerdo con las siguientes reglas:


A mediados de los 90, se empezaron a popularizar los sistemas de control basados en la electrónica y, actualmente, se ha pasado a los que usan microcontroladores. Este sistema se ha normalizado en gran parte gracias a la NMRA (North American Model Railways Association, o asociación norteamericana de modelismo ferroviario). Los sistemas normalizados reciben el nombre genérico de DCC (Digital Command Control). El sistema requiere que las locomotoras tengan instalado un circuito electrónico capaz de mover el motor o los accesorios (luces, generadores de humo, etc.) de acuerdo a las órdenes digitales recibidas por la vía mediante circuitos electrónicos. El circuito de la locomotora recibe el nombre de decodificador, y la operación de instalarlo se suele denominar "digitalizar".

Los sistemas DCC también existen en versiones de dos y de tres carriles. A diferencia de los sistemas tradicionales, el tipo de corriente que circula por la vía puede ser en ambos casos la misma. En realidad los sistemas de dos y tres carriles tradicionales tenían cada uno sus ventajas en la manera de mover las composiciones de modos distintos en el mismo circuito. Los sistemas digitales llevan el control individualizado mediante microcircuitos, independientemente del sistema de alimentación.

Respecto del sistema de control tradicional, el control DCC presenta las siguientes ventajas:

Los inconvenientes del sistema DCC frente al tradicional son:

Los trenes eléctricos tienen vagones de ferrocarril a escala.


Sus orígenes se remontan a fines del siglo XIX en consonancia con la aparición de juguetes ingeniosos que aplicaran las tecnologías novedosas, con lo que se diseñan unos trenes pequeños fabricados en chapa de hierro y movidos por un motor eléctrico. 1891, en la Feria de Leipzig, Märklin presentó la primera locomotora funcional a escala de la historia (1:32 o escala 1). Construida en hojalata, poseía un mecanismo de reloj de cuerda que le permitía ponerse en movimiento sobre rieles y circular sobre ellos. Carlisle y Finch presentaron la primera composición de un tren completo con motor eléctrico en 1897. A principios del siglo XX Joshua Lionel Cowen creó un tren eléctrico para el escaparate de su juguetería, pero recibió tantas peticiones que la atracción publicitaria acabó por convertirse en un clásico de la industria juguetera. 




</doc>
<doc id="21917" url="https://es.wikipedia.org/wiki?curid=21917" title="GNUstep">
GNUstep

GNUstep es un conjunto de Frameworks o bibliotecas orientadas a objetos, aplicaciones y herramientas escritas en el lenguaje Objective-C, para el desarrollo de aplicaciones de escritorio. 

Es a su vez una implementación libre de las especificaciones OpenStep, creadas por NeXT, que después fue comprada por Apple. Con el surgimiento del sistema operativo Mac OS X de Apple, basado en OpenStep, GNUstep también planea compatibilidad con este sistema.

GNUstep incorpora dos herramientas de desarrollo (RAD). Project Center, para la creación de proyectos, y GORM, para la creación de interfaces gráficas. Ambas herramientas son las equivalentes a Project Builder e Interface Builder, respectivamente, de NeXTSTEP. 

GNUstep se conforma básicamente de cuatro paquetes Make, Base, GUI y Back. Cada uno tiene diferentes funciones:

Este paquete facilita la creación de los Makefiles de los proyectos creados con GNUstep. De tal forma que se hace sencilla la configuración, instalación y empaquetado de la aplicación.

Este es el Framework que contiene todas las clases no visuales. Las clases que están basadas en las originales de NeXTSTEP comienzan con las letras NS, y las que han sido añadidas por el proyecto GNUstep comienzan con las letras GS.

Este es el Framework que contiene todas las clases visuales. Al igual que en el Framework Base las clases que están basadas en las originales de NeXTSTEP comienzan con las letras NS, y las añadidas comienzan con las letras GS.

Este paquete es el Back-end del Framework GUI. Y es el encargado de las rutinas para dibujar los componentes visuales de las aplicaciones creadas con GNUstep.

La apariencia de las aplicaciones hechas con GNUstep se asemeja en general a las creadas con NeXTSTEP. Aunque esta puede variar de un sistema operativo a otro, así como de la configuración de las bibliotecas. En los sistemas GNU/Linux, BSD, Solaris, etc. las aplicaciones tienen un menú vertical y desligado de cualquier ventana. En estos sistemas también se hace uso de los AppIcons y Miniwindows, los cuales pueden ser manejados con la herramienta IconManager (en el escritorio WindowMaker esta herramienta no es necesaria). Sin embargo, es posible configurar GNUstep para utilizar la barra de tareas para minimizar las ventanas, así como configurar las aplicaciones para tener el menú en ventana (aquellas que soporten este estilo).

En el sistema Mac OS el menú es como el de cualquier aplicación nativa de esa plataforma. En el sistema Windows puede tenerse el menú en ventana para las aplicaciones que han sido diseñadas con soportar para este estilo.







</doc>
<doc id="21931" url="https://es.wikipedia.org/wiki?curid=21931" title="Heterodino">
Heterodino

En telecomunicación, el término heterodino tiene los siguientes significados:

1. Generar nuevas frecuencias mediante la mezcla de dos o más señales en un dispositivo no lineal, tal como un diodo, una válvula termoiónica o un transistor.

2. La frecuencia producida por la mezcla de dos o más señales en un dispositivo no lineal se denomina heterodina.

Una aplicación de la heterodinación la tenemos en los receptores de radio superheterodinos, donde cualquier frecuencia entrante seleccionada es convertida mediante este principio en una frecuencia intermedia común, con lo que se facilita la amplificación y se mejora la selectividad.

La heterodinación se utiliza ampliamente en la ingeniería de comunicaciones para generar nuevas frecuencias y mover información de un canal de frecuencia a otro. Además de su uso en el receptor superheterodino que se encuentra en casi todos los receptores de radio y televisión, que se utiliza en transmisores de radio, módems, satélites de comunicaciones y set-top boxes, radares, radiotelescopios, telemetría, sistemas de telefonía celular, cabeceras y descodificadores de televisión por cable, relés de microondas, detectores de metales, relojes atómicos y sistemas de contramedidas electrónicas militares (jamming).

En las redes de telecomunicaciones de gran escala, tales como troncos de redes telefónicas, relé de microondas, redes de televisión por cable y enlaces de sistemas de comunicación por satélite, se comparten enlaces de ancho de banda de gran capacidad por muchos canales de comunicación individuales, mediante el uso de heterodino para mover la frecuencia de las señales individuales a diferentes frecuencias, que comparten el canal. Esto se conoce como multiplexación por división de frecuencia (FDM).

Por ejemplo, un cable coaxial utilizado por un sistema de televisión por cable, puede llevar 500 canales de televisión al mismo tiempo, debido a que cada uno se le da una frecuencia diferente, por lo que no interfiere uno con el otro. En la fuente de cable o cabecera, supra-convertidores (o ascen-convertidores) electrónicos convierten cada canal de televisión entrante a una nueva frecuencia, superior. Lo hacen mediante la mezcla de la frecuencia de señal de televisión, f con un oscilador local a una frecuencia mucho más alta f , creando un heterodino en la suma f+f, que se añade al cable. En el hogar del consumidor, el descodificador de cable tiene un infra-convertidor (o descen-convertidor) que mezcla la señal de entrada a la frecuencia f+f con el mismo oscilador local de frecuencia f creando la diferencia heterodina, convirtiendo el canal de televisión de nuevo a su frecuencia original: (f+f)-f= f. Cada canal se mueve a una frecuencia más alta diferente. La frecuencia de base inferior original de la señal se llama banda base, mientras que el canal más alto al que se ha trasladado, se llama banda de paso.



</doc>
<doc id="21933" url="https://es.wikipedia.org/wiki?curid=21933" title="Libro">
Libro

Un libro (del latín "liber", "libri") es una obra impresa, manuscrita o pintada en una serie de hojas de papel, pergamino, vitela u otro material, unidas por un lado (es decir, encuadernadas) y protegidas con tapas, también llamadas cubiertas. Un libro puede tratar sobre cualquier tema.

Según la definición de la Unesco, un libro debe poseer 25 hojas mínimo (49 páginas), pues de 24 hojas sería un folleto y de una hasta cuatro páginas se consideran hojas sueltas (en una o dos hojas).

También se llama "libro" a una obra de gran extensión publicada en varias unidades independientes, llamados "tomos" o "volúmenes". Otras veces se llama también "libro" a cada una de las partes de una obra, aunque físicamente se publiquen todas en un mismo volumen (ejemplo: Libros de la Biblia).

Hoy en día, no obstante, esta definición no queda circunscrita al mundo impreso o de los soportes físicos, dada la aparición y auge de los nuevos formatos documentales y especialmente de la World Wide Web. El libro digital o libro electrónico, conocido como "e-book", está viendo incrementado su uso en el mundo del libro y en la práctica profesional bibliotecaria y documental. Además, el libro también puede encontrarse en formato audio, en cuyo caso se denomina audiolibro.

Desde los orígenes, la humanidad ha tenido que hacer frente a una cuestión fundamental: la forma de preservar y transmitir su cultura, es decir, sus creencias y conocimientos, tanto en el espacio como en el tiempo.

El planteamiento de esta cuestión supone: por un lado, determinar la forma de garantizar la integridad intelectual del contenido de la obra y la conservación del soporte en el que fue plasmada, y por otro, encontrar el medio por el cual se mantendrá inalterada la intención o finalidad para la cual se concibió.

Los orígenes de la historia del libro se remontan a las primeras manifestaciones pictóricas de nuestros antepasados, la pintura rupestre del hombre del paleolítico. Con un simbolismo, posiblemente cargado de significados mágicos, estas pinturas muestran animales, cacerías y otras escenas cotidianas del entorno natural del hombre antiguo, que trataba de dominar las fuerzas adversas de la naturaleza capturando su esencia mediante su representación. Son el más antiguo precedente de los primeros documentos impresos de que se tiene memoria.

Las señales gestuales fueron la primera forma de expresar y transmitir mensajes. La palabra hablada es la manera más antigua de contar historias. Mediante fórmulas de valor mnemotécnico se estructuraban narraciones, que pasaban de generación en generación como valiosa herencia cultural de los más diversos grupos humanos. Dichas reglas mnemotécnicas ayudaban tanto a la memorización como a la difusión de los relatos. Es el caso de los poemas homéricos, que han merecido valiosos estudios sobre el particular. Posiblemente, gran parte de las tradiciones y leyendas han tenido semejante inicio. Esta transmisión oral tenía el inconveniente de los «ruidos» que deformaban el mensaje. La mayoría de las veces era el narrador (rapsoda, aeda, juglar) quien en función de sus intereses la deformaba de una u otra forma.

Cuando los sistemas de escritura fueron inventados en las antiguas civilizaciones, el hombre utilizó diversos soportes de escritura: tablillas de arcilla, ostracon, placas de hueso o marfil, tablas de madera, papiros, tablillas enceradas, planchas de plomo, pieles curtidas, etc.

La escritura fue el resultado de un proceso lento de evolución con diversos pasos: imágenes que reproducían objetos cotidianos (pictografía); representación mediante símbolos (ideografía); y la reproducción de sílabas y letras.

Los más antiguos vestigios de escritura se encuentran, hacia finales del IV milenio a. C., en el Antiguo Egipto, con jeroglíficos, y la antigua Mesopotamia, mediante signos cuneiformes (escritura cuneiforme; utilizaban una varilla con sección triangular, que al hendir en placas de arcilla, dejaba una marca en forma de cuña). La usaron los sumerios, acadios, asirios, hititas, persas, babilonios etc. La escritura egipcia, que perduró más de tres milenios, mediante jeroglíficos, representaba ideas abstractas, objetos, palabras, sílabas, letras y números. Evolucionó en las escrituras hierática y demótica. Otros pueblos, como los hititas y los aztecas también tuvieron tipos propios de escritura.

La escritura china más antigua que se conoce son 50000 inscripciones sobre conchas de tortuga que incorporan 4500 caracteres distintos, y data del 1400 a. C. en el yacimiento de Xiaotun, en la provincia de Henan. Pero los primeros libros reconocibles de China corresponden al siglo VI a. C., los jiance o jiandu, rollos de finas tiras de bambú o madera grabados con tinta indeleble y atados con cordel. Estos textos servían principalmente a causas institucionales , era la obra de funcionarios civiles o militares.

Desde Confucio en adelante (551-479 a. C.) los libros se convirtieron en importantes instrumentos de aprendizaje, se escribieron tratados de filosofía, medicina, astronomía y cartografía.

En el período de los reinos combatientes (475-221 a. C.) La seda se usó mucho como soporte para escribir. La tela era ligera, resistente al clima húmedo, absorbía bien la tinta y proporcionaba al texto un fondo blanco, sin embargo era mucho más cara que el bambú, es por esto que en ocasiones se hacía una copia en bambú antes de grabarse en seda los textos importantes.

La invención del papel según la tradición china, se atribuye a un eunuco de la corte imperial llamado Cai Lin en el 105 d. C. Usando nuevos ingredientes (trapos viejos, cáñamo, corteza de árbol y redes de pescar) creó un método de fabricación de papel muy similar al que se usa hoy en día. Pero el papel tardó cientos de años en reemplazar al bambú y la seda, fue hasta finales del siglo II d. C. que la corte imperial lo usó en cantidades importantes.

Esta innovación no se propagó fuera de China hasta el 610 d. C. aproximadamente, y alcanzó Europa a través de España hasta el siglo XII.

A mediados del siglo VIII los chinos inventaron la impresión xilográfica, o el grabado en madera, y la necesidad de reproducir un gran número de textos e imágenes budistas, calendarios, manuales de adivinación y diccionarios promovió una rápida y temprana propagación de la xilografía. El primer libro impreso chino que se ha encontrado es el Sutra del diamante del 868 d. C.

Los impresores chinos crearon los tipos móviles hacia el siglo XI, el escritor chino Ch'en Kua (1030-1095) narra la historia de esta invención en su libro de cosas vistas y oídas (Mengshi Pitan), según el escritor el herrero JenTsung de la dinastía de los Song del norte entre 1041-1049 logró crear caracteres móviles, para esto utilizó arcilla endurecida al fuego sobre la cual había grabado unos caracteres móviles que fijo sobre una plancha de hierro impregnada de resina de pino, cera y cenizas. También se le atribuye la creación de una mesa giratoria para guardar los caracteres, esta técnica se llamaba tipografía tablearia. Hacia el 1300 Wang- Tcheng, un técnico agrónomo, emplazó la arcilla por madera de azufaifo, que era mucho más dura. Pero este avance no revolucionó la imprenta hasta el punto que lo hizo Gutenberg en Europa 400 años después. A diferencia de las lenguas europeas, el chino escrito requiere miles de caracteres únicos, lo que hace mucho más eficaz los bloques de madera individuales que los enormes conjuntos de tipos reutilizables. En contraste con el declive de las artes de los escribas en occidente en los siglos que siguieron a la creación de la imprenta de tipos móviles, la caligrafía china conservó su prestigio, era un arte. No obstante, a finales del siglo XV, China había producido más libros que el resto del mundo junto.

Los árabes aprendieron la técnica para fabricar papel de sus contactos con China en el siglo VIII, y este se introdujo en Europa en el siglo XII a través de la España musulmana.

La obra xilográfica más antigua encontrada hasta nuestros días es el Dharani Sutra de Corea, datado en el 751 a. C., aunque no se sabe quién fue el inventor de la xilografía los chinos y coreanos fueron los que impulsaron la impresión xilográfica, principalmente para editar textos religiosos. El budismo chino y coreano fue el vehículo que trasmitió la xilografía a Japón. Pero Corea realizó muchos otros avances que revolucionaron la manera de imprimir y en consecuencia el libro.

Entre 1234 y 1239 los coreanos que se habían refugiado en la isla de Gwanghwa, debido a la invasión mongol, no disponían de madera dura fue entonces que imprimieron 28 ejemplares de los 50 volúmenes del Go geum sang jeong ye mun con caracteres móviles metálicos. La obra del año 1239 describe el método utilizado y termina diciendo: impreso para la eternidad con caracteres de nueva fabricación. Más tarde el rey Taejong puso en funcionamiento un taller que contribuía a la difusión de la escritura y en 1403, el tercer año de su reinado, se restableció la fundición nacional, el Jujaso, donde se fabricaban caracteres móviles de imprenta, realizó la primera fundición de tipos móviles en bronce. Cabe señalar que la invención de la tipografía coreana es de primordial importancia para la religión, particularmente el budismo, el confucionismo, y el taoísmo.
Durante el reinado del tercer hijo de Taejong, Sejong aumentó el número de centros dedicados a la enseñanza. En la capital existían cuatro escuelas, un colegio para el pueblo y una escuela para la familia real y sus parientes. El libro se convirtió en la herramienta primordial de los esfuerzos de alfabetización que, incluso llegaron a las provincias y pueblos lejanos. Los niños varones tenían que seguir las clases que les inculcaban las nociones básicas como la escritura y la lectura.

Los caracteres fueron mejorando con el tiempo, buscaban una forma más cuadrada y más regular que los precedentes, facilitando así la composición. Durante la invasión japonesa (1592-1598) un general japonés llevó caracteres móviles y libros a Japón, así Japón pudo desarrollar su imprenta, en cambio, la imprenta coreana retrocedió a partir de ese momento, se volvió a la madera para la fabricación de tipos móviles y cada la producción de libros decayó.

Sin duda alguna la dinastía Joseon fue el gran periodo para los libros coreanos, se sabe de 32 fundiciones de caracteres móviles metálicos y más de 350 modelos diferentes. A pesar de las dificultades Corea supo desarrollar e incluso exportar sus técnicas de imprenta. China no utilizó caracteres móviles hasta finales del siglo XV, en 1490, por su parte, Japón adoptó la técnica tipográfica coreana a finales del siglo XVI en 1592.

Egipto creó el papiro y lo exportó a todo el mediterráneo, se usaba para plasmar textos en Egipto, Grecia y Roma. La fabricación del papiro era complicada y dado que las láminas de papiro estaban hechas de dos capas superpuestas, por cada cara discurría una veta distinta, de ahí que se denomine recto donde el grano discurría de forma horizontal y verso en donde el grano discurría en vertical, sin embargo solo se escribía en la cara interna que era la más lisa. Las láminas se pegaban para hacer un rollo.

A partir del siglo I d. C. El pergamino comenzó a competir con el papiro, se cree que surgió en Pérgamo, en la actual Turquía. El pergamino tenía la ventaja de resistir condiciones de humedad, era más duradero y podía doblarse sin romperse, también podía rasparse para limpiarlo y ser reutilizado.

Es muy poco lo que se conoce de las bibliotecas egipcias, un pequeño testimonio es el templo de Horus, donde en uno de los muros están los títulos de 37 libros que eran parte de las bibliotecas.

La escritura alfabética hizo más accesible la lectura y la escritura. El alfabeto griego se desarrolló en el siglo VI y V a. C., era puramente fonético a diferencia de los ideogramas chinos, un erudito chino podía dedicar toda su vida a dominar miles de caracteres, en comparación, el alfabeto griego podía aprenderse en unos días. El uso de la escritura se incrementó en Atenas hacia el siglo V a. C.

En la Roma imperial los escritos podían encontrarse en todas partes. La administración cotidiana produjo un flujo constante de documentos, la alfabetización rudimentario era habitual, incluso en las clases bajas, lo que provocó que en el siglo I d. C. hubiera un crecimiento del público lector, ya no se escribía para un círculo de amigo íntimos, sino para un público anónimo, pero la clase alta siguió conservando la cultura literaria oral tradicional.

En el siglo III d. C. empezó el declive del imperio romano y las invasiones bárbaras causaron una contracción de la cultura escrita. Muchas instituciones escolásticas cayeron, a excepción de las mantenidas por la iglesia cristiana.

Durante los primeros siglos de la era cristiana apareció el códice, una de las más importantes y perdurables revoluciones de la historia del libro. Era más compacto y fácil de manejar que los rollos, podía utilizarse ambas caras del papel, lo que le permitía contener más texto. Aunque el códice tenía claras ventajas, el rollo siguió en uso durante varios siglos. La monarquía inglesa continuó usando rollos para registrar sus leyes hasta la edad media.

Con el advenimiento de la imprenta, se inicia la época de expansión bibliográfica, de la modernidad y del pensamiento crítico, facilitado en la actualidad con el acceso a la información en otro tipo de fuentes, tales como periódicos, revistas, Internet, etc. No obstante, el valor del libro es perdurable a través del tiempo.

El libro comprendido como una unidad de hojas impresas que se encuentran encuadernadas en determinado material que forman un volumen ordenado, puede dividir su producción en dos grandes períodos: desde la invención de la imprenta de tipos móviles hasta 1801, y el periodo de producción industrializada.

Así libro antiguo es aquel libro que fue producido en el período manual de la imprenta, es decir que fue impreso con tipos móviles metálicos, estos libros fueron publicados desde la creación de la imprenta en el siglo XV hasta el siglo XIX.

La aparición de la imprenta de tipos móviles en 1440, revolucionó el proceso de producción del libro, aunque algunos procesos de la fabricación se mantuvieron igual que en la época de los scriptoria, la imprenta hizo relativamente más sencilla la producción de libros.

La coexistencia del desarrollo de la imprenta con el comienzo del movimiento humanista y la reforma luterana impulsaron el crecimiento de la industria del libro, puesto que vieron en él un medio de difusión masivo. Pero también existían otras circunstancias que ayudaron a la propagación del libro impreso, el auge de las universidades desarrolló un mercado más amplio para los libros entre las élites intelectuales laicas y religiosas. En medio siglo, la segunda mitad del siglo XV, el libro impreso se convirtió en un importante negocio internacional, los libreros e impresores fueron ante todo empresarios. Pero el libro también debe su expansión a la atención que algunos monarcas y religiosos pusieron en la imprenta, en 1468 el papa Paulo II ordenó imprimir las epístolas de san Jerónimo, por su parte el rey de Francia Carlos VII mandó a Nicolás Jenson a Alemania para aprender la técnica de impresión, con el tiempo los más importantes soberanos en Europa protegieron el desarrollo de la imprenta.

La superioridad de la imprenta sobre la xilografía fue incuestionable, la escritura era regular, impresión a ambas caras, rapidez de impresión y la posibilidad de volver a utilizar los caracteres para imprimir otros textos.

Se puede establecer una cronología del libro antiguo dividida en siglos, tomando como base ciertas características comunes en un siglo determinado:
No es sino hasta mediados del siglo XVIII, una vez que el libro ha superado las dificultades tecnológicas que le impedían convertirse en una mercancía, que este inicia su rápido ascenso dentro del gusto de las minorías ilustradas de la sociedad.

La invención de la imprenta y el desarrollo del papel, así como la aparición de centros de divulgación de las ideas, permitieron la aparición del escritor profesional que depende de editores y libreros principalmente y ya no del subsidio público o del mecenazgo de los nobles o de los hombres acaudalados.

Además, surge una innovación comercial que convierte al libro en una mercancía de fácil acceso a los plebeyos y los pobres, que consiste en las librerías ambulantes, donde el librero cobra una cantidad mensual para prestar libros, que al ser devueltos le permiten al lector-usuario recibir otro a cambio.

El mismo libro, se convierte en un avance que da distinción a los lectores como progresistas en un siglo en que el progreso es una meta social ampliamente deseada y a la que pueden acceder por igual nobles y plebeyos, creando una meritocracia de nuevo cuño.

A pesar de lo anterior, la minoría que cultiva el gusto por el libro se encuentra entre los nobles y las clases altas y cultivadas de los plebeyos, pues sólo estos grupos sociales saben leer y escribir, lo que representa el factor cultural adicional para el inevitable auge del libro.
Otro importante factor que fomentó el aprecio por los libros fue la Censura, que si bien solía ejercerse también en periodos anteriores a los siglos XVII y XVIII, es precisamente en esta época cuando adquiere mayor relevancia, puesto que los libros se producen por millares, multiplicando en esa proporción la posibilidad de difundir ideas que el Estado y la Iglesia no desean que se divulguen.

En 1757 se publicó en París un decreto que condenaba a muerte a los editores, impresores y a los autores de libros no autorizados que se editarán, a pesar de carecer de dicha autorización. La draconiana medida fue complementada con un decreto que prohibía a cualquiera que no estuviera autorizado a publicar libros de tema religioso. En 1774, otro decreto obligaba a los editores a obtener autorizaciones antes y después de publicar cada libro y en 1787, se ordenó vigilar incluso los lugares libres de censura.

Estas medidas lo único que lograron fue aumentar el precio de los libros y obligar a los libreros ambulantes a no incluirlos en su catálogo, con lo cual incrementaron el negocio de los libros prohibidos, que de esta manera tenían un mayor precio y despertaban un mayor interés entre la clase alta que podía pagar el sobrevalor, con lo cual se fomentaron en el exterior, en Londres, Ámsterdam, Ginebra y en toda Alemania, las imprentas que publicaban libros en francés. Así fueron editados hasta la saciedad Voltaire, Rousseau, Holbach, Morell y muchos más, cuyos libros eran transportados en buques que anclaban en El Havre, Boulogne y Burdeos, desde donde los propios nobles los transportaban en sus coches para revenderlos en París.

En tanto la censura se volvió inefectiva e incluso los censores utilizaron dicha censura como medio para promover a astutos escritores y editores. Así, por ejemplo, cuando el todopoderoso ministro Guillaume-Chrétien de Lamoignon de Malesherbes revocó la autorización para publicar L'Encyclopédie, fue él mismo quien protegió a la obra cumbre de la Ilustración para después distribuirla de manera más libre, lo mismo hizo para proteger "Emile" y "La nouvelle Éloise".

Normalmente, un libro es impreso en grandes hojas de papel, donde se alojan 8 páginas a cada lado. Cada una de estas grandes hojas es doblada hasta convertirla en una signatura de 16 páginas. Las signaturas se ordenan y se cosen por el lomo. Luego este lomo es redondeado y se le pega una malla de tela para asegurar las partes. Finalmente las páginas son alisadas por tres lados con una guillotina y el lomo pegado a una tapa de cartón. Toda esta tarea se realiza en serie, inclusive la encuadernación.

En el caso de que las hojas no sean alisadas mediante un proceso de corte, se habla de un libro intonso.

Las imprentas más modernas pueden imprimir 16, 32 y hasta 64 páginas por cara de grandes hojas, luego, como se mencionara más arriba, se las corta y se las dobla. Muchas veces el texto de la obra no alcanza a cubrir las últimas páginas, lo que provoca que algunos libros tengan páginas vacías al final del mismo, aunque muchas veces son cubiertas con propaganda de la editorial sobre textos del mismo autor o inclusive otros de su plantilla.

Los importantes avances en desarrollo de software y las tecnologías de impresión digital han permitido la aplicación de la producción bajo demanda (en inglés el acrónimo P.O.D.) al mundo del libro. Esto está permitiendo eliminar el concepto de "Libro Agotado" al poder reimprimirse títulos desde un solo ejemplar, y se está fomentando la edición de libros en tiradas muy cortas que antes no eran rentables por los medios tradicionales.

Cómo aplicación más innovadora, las librerías electrónicas más reconocidas están además ofertando a todo el mundo libros que no son fabricados hasta que son vendidos. Esto es posible solo por estar dados de alta en los sistemas de producción de compañías internacionales como Lightning Source, Publidisa, Booksurge, Anthony Rowe, etc.

A finales de 1971 comenzó a desarrollarse lo que hoy denominamos libro digital o electrónico. Michael Hart fue el impulsor del Proyecto Gutenberg, (que consistía en la creación de una biblioteca digital totalmente gratis), donde podíamos encontrar obras de autores como Shakespeare, Poe y Dante entre otros, todas ellas obras de dominio público. En 1981 se produce un importante avance, ya que sale a la venta el primer libro electrónico: "Random House's Electronic Dictionary". Sin embargo, fue en marzo de 2001 cuando el libro digital (también conocido como eBook) experimentó su máxima expansión gracias al novelista Stephen King, quien lanzó al mercado a través de la red su novela "Riding the Bullet". La obra, en apenas 48 horas, vendió 400 000 copias, al precio de dos dólares y medio la copia. El mes siguiente Vladímir Putin también sacó a través de Internet sus memorias.

Desde este momento comenzaron a aparecer varias editoriales electrónicas y muchas tiendas virtuales empezaron a incorporar libros electrónicos en sus catálogos.

En el año 2000 se recogían los siguientes datos:
“Si la celebridad de un individuo consiste en que se escriba un libro sobre él, [...] Jesucristo es aun el personaje que goza de más fama en el mundo actual”, dice el periódico británico "The Guardian". Una investigación que tomó como base los libros de la Biblioteca del Congreso de Estados Unidos, con sede en Washington, D.C., reveló la existencia de 17 239 obras acerca de Jesús, casi el doble que de William Shakespeare, quien alcanza el segundo lugar, con 9801. Vladimir Lenin resulta el tercero, con 4492, seguido de Abraham Lincoln, con 4378, y de Napoleón I, con 4007. El séptimo puesto, con 3595, lo ocupa María, la madre de Jesús, quien es la única mujer entre los treinta principales. La siguiente es Juana de Arco, con 545. Encabeza la nómina de compositores Richard Wagner, tras quien vienen Mozart, Beethoven y Bach. Picasso es el número uno de los pintores, seguido de Leonardo da Vinci y Miguel Ángel. Da Vinci, sin embargo, se lleva la palma en la lista de científicos e inventores, superando a Charles Darwin, Albert Einstein y Galileo Galilei. “No figura ningún personaje vivo en los treinta primeros lugares”, agrega el rotativo.


De acuerdo con el contenido los libros se pueden clasificar en:
En las bibliotecas se suele utilizar el Sistema Dewey de clasificación por materias.




</doc>
<doc id="21938" url="https://es.wikipedia.org/wiki?curid=21938" title="Lenguaje unificado de modelado">
Lenguaje unificado de modelado

El lenguaje unificado de modelado (UML, por sus siglas en inglés, "Unified Modeling Language") es el lenguaje de modelado de sistemas de software más conocido y utilizado en la actualidad; está respaldado por el "Object Management Group" (OMG).

Es un lenguaje gráfico para visualizar, especificar, construir y documentar un sistema. UML ofrece un estándar para describir un "plano" del sistema (modelo), incluyendo aspectos conceptuales tales como procesos, funciones del sistema, y aspectos concretos como expresiones de lenguajes de programación, esquemas de bases de datos y compuestos reciclados. 

Es importante remarcar que UML es un "lenguaje de modelado" para especificar o para describir métodos o procesos. Se utiliza para definir un sistema, para detallar los artefactos en el sistema y para documentar y construir. En otras palabras, es el lenguaje en el que está descrito el modelo.

Se puede aplicar en el desarrollo de software gran variedad de formas para dar soporte a una metodología de desarrollo de software (tal como el Proceso Unificado Racional, "Rational Unified Process" o RUP), pero no especifica en sí mismo qué metodología o proceso usar.

UML no puede compararse con la programación estructurada, pues UML significa Lenguaje Unificado de Modelado, no es programación, solo se diagrama la realidad de una utilización en un requerimiento. Mientras que programación estructurada es una forma de programar como lo es la orientación a objetos, la programación orientada a objetos viene siendo un complemento perfecto de UML, pero no por eso se toma UML solo para lenguajes orientados a objetos.

UML cuenta con varios tipos de diagramas, los cuales muestran diferentes aspectos de las entidades representadas.

Desde el año 2005, UML es un estándar aprobado por la ISO como ISO/IEC 19501:2005 Information technology — Open Distributed Processing — Unified Modeling Language (UML) Versión 1.4.2.

En el año 2012 se actualizó la norma a la última versión definitiva disponible en ese momento, la 2.4.1, dando lugar a las normas ISO/IEC 19505-1 e ISO/IEC 19505-2.

Después de que la "Rational Software Corporation" contratara a James Rumbaugh de General Electric, en 1994, la compañía se convirtió en la fuente de los dos esquemas de modelado orientado a objetos más populares de la época: "Object-Modeling Technique" (OMT) de Rumbaugh, que era mejor para análisis orientado a objetos, y el Método Booch (de Grady Booch) que era mejor para el diseño orientado a objetos. Poco después se les unió Ivar Jacobson, el creador del método de ingeniería de software orientado a objetos. Jacobson se unió a Rational, en 1995, después de que su compañía Objectory AB fuera comprada por Rational. Los tres metodologistas eran conocidos como los "Tres Amigos", porque se sabía de sus constantes discusiones sobre las prácticas metodológicas.

En 1996 Rational concluyó que la abundancia de lenguajes de modelado estaba alentando la adopción de la tecnología de objetos, y para orientarse hacia un método unificado, encargaron a los "Tres Amigos" que desarrollaran un "lenguaje unificado de modelado" abierto. Se consultó con representantes de compañías competidoras en el área de la tecnología de objetos durante la OOPSLA '96; eligieron "cajas" para representar clases en lugar de la notación de Booch que utilizaba símbolos de "nubes".

Bajo la dirección técnica de los "Tres Amigos" (Rumbaugh, Jacobson y Booch) fue organizado un consorcio internacional llamado "UML Partners" en 1996 para completar las especificaciones del UML, y para proponerlo como una respuesta al OMG RFP. El borrador de la especificación UML 1.0 de "UML Partners" fue propuesto a la OMG en enero de 1997. Durante el mismo mes, la "UML Partners" formó una Fuerza de Tarea Semántica, encabezada por Cris Kobryn y administrada por Ed Eykholt, para finalizar las semánticas de la especificación y para integrarla con otros esfuerzos de estandarización. El resultado de este trabajo, el UML 1.1, fue presentado ante la OMG en agosto de 1997 y adoptado por la OMG en noviembre de 1997.

Como notación de modelado, la influencia de la OMT domina UML (por ejemplo, el uso de rectángulos para clases y objetos). Aunque se quitó la notación de "nubes" de Booch, sí se adoptó la capacidad de Booch para especificar detalles de diseño en los niveles inferiores. La notación de "Casos de Uso" del "Objectory" y la notación de componentes de Booch fueron integrados al resto de la notación, pero la integración semántica era relativamente débil en UML 1.1, y no se arregló realmente hasta la revisión mayor de UML 2.0.

Conceptos de muchos otros métodos orientados a objetos (MOO) fueron integrados superficialmente en UML con el propósito de hacerlo compatible con todos los MOO. Además, el grupo tomó en cuenta muchos otros métodos de la época, con el objetivo de asegurar amplia cobertura en el dominio de los sistemas en tiempo real. Como resultado, UML es útil en una gran variedad de problemas de ingeniería, desde procesos sencillos y aplicaciones de solamente un usuario a sistemas concurrentes y distribuidos.

UML ha madurado considerablemente desde UML 1.1, varias revisiones menores (UML 1.3, 1.4 y 1.5) han corregido defectos y errores de la primera versión de UML. A estas le ha seguido la revisión mayor UML 2.0 que fue adoptada por el OMG en 2005.

Aunque UML 2.1 nunca fue lanzado como una especificación formal, las versiones 2.1.1 y 2.1.2, aparecieron en 2007, seguidas por UML 2.2 en febrero de 2009. UML 2.3 fue lanzado oficialmente en mayo de 2010. UML 2.4.1 fue lanzado oficialmente en agosto de 2011. UML 2.5 fue lanzado en octubre de 2012 como una versión "En proceso" que fue formalmente liberada en junio de 2015.

Muestran la estructura estática de los objetos en un sistema.

Muestran el comportamiento dinámico de los objetos en el sistema.


Los diagramas de secuencia de UML forman parte de un modelo UML y solo existen dentro de los proyectos de modelado UML. Para crear un diagrama de secuencia UML, en el menú Arquitectura, haga clic en Nuevo diagrama de capas o UML. Obtenga más información sobre elementos de diagrama de secuencia UML o diagramas de modelado UML en general. Para ver una demostración en vídeo, consulte Esbozar interacciones mediante diagramas de secuencia (2010).





</doc>
<doc id="21943" url="https://es.wikipedia.org/wiki?curid=21943" title="Slashdot">
Slashdot

Slashdot (literalmente, "barrapunto", abreviado frecuentemente como "/.") es un sitio de noticias orientado a la tecnología. Fue creado en septiembre de 1997 por Rob Malda. Actualmente pertenece a la Open Source Development Network, parte de VA Software. La mayor parte de los contenidos de Slashdot consisten de resúmenes breves de historias de otras páginas web y enlaces a ellas. Los usuarios de Slashdot pueden comentar sobre cada noticia y cada noticia obtiene generalmente entre 200 y 2000 comentarios durante el tiempo en que figura en la página principal. Los resúmenes de cada historia son generalmente provistos por los mismos lectores de Slashdot y los editores son los encargados de aceptar o rechazar cada contribución.

El nombre "Slashdot" fue elegido por la forma curiosa en que suena dentro de una URL. En inglés barra es "slash" y punto es "dot", por lo que al leer "http://slashdot.org" el resultado es "http colon slash slash "slashdot" dot org".

Slashdot corre sobre un programa llamado Slash. El código Slash está liberado bajo los términos de la licencia GNU GPL, por lo que algunos sitios de noticias lo han utilizado.

Todo usuario, a partir de cierto momento, puede moderar las opiniones de otros, calificándolas de divertidas, interesantes, inspiradas, informativas, infravaloradas, sobrevaloradas, trolls, inflamadoras, fuera del tema o redundantes. Las calificaciones afectan a la visibilidad de los comentarios, y a una puntuación o "karma" del usuario que ha sido calificado. Los usuarios con buen karma tienen mayor visibilidad y tienen opción de moderar comentarios de otros con mayor frecuencia.

Todo usuario, a partir de cierto momento, puede metamoderar moderaciones de otros, para evitar que se abuse del sistema de moderación. Los usuarios que hacen moderaciones consideradas injustas por los metamoderadores ven disminuida su capacidad de moderación.

Hay un sinnúmero de bromas internas y temas recurrentes en slashdot, entre ellos:





</doc>
<doc id="21944" url="https://es.wikipedia.org/wiki?curid=21944" title="Peluca">
Peluca

Una peluca es una cabellera postiza de cabello sintético o natural, usado en la cabeza principalmente por motivos estéticos. 

Muchos hombres y mujeres usan pelucas para disimular su pérdida de cabello. Las denominadas prótesis capilares, estas pueden ser indetectables a simple vista. Los actores usan pelucas para conseguir mayor similitud con sus personajes.

Los egipcios fueron buenos artesanos elaborando pelucas que se confeccionaban con cabellos naturales. Hoy en día, se conservan buenos ejemplos de dichas confecciones en diferentes museos del mundo. También eran populares las pelucas entre los pueblos asirio y fenicio.

Eran más extrañas en el lejano oriente, que solo se usaban entre los actores de teatro, por ejemplo están las pelucas katsura usadas en el teatro tradicional Japonés. También eran usadas por las geishas

Las pelucas también eran populares en la época clásica, en Grecia y Roma. En el siglo I A.C. tuvieron gran aceptación las pelucas rubias en Roma, confeccionadas con cabellos de los pueblos germánicos sometidos por el Imperio. 

La Iglesia trató de eliminar repetidamente su uso por su relación con actividades festivas o licenciosas. En el 629 d. C. el Concilio de Constantinopla excomulgó a los cristianos que se resistieran a prescindir de dicho complemento. Así a partir de la caída del Imperio romano el uso de pelucas entró en decadencia. 

En el siglo XVI se volvió a rescatar el uso de pelucas con la finalidad de compensar la calvicie. Por ejemplo a medida que envejecía la reina Isabel I de Inglaterra se fue haciendo con una importante colección de pelucas rojas, elaboradas y peinadas al estilo romano. Las pelucas también tenían el propósito de prevenir la tiña y los piojos, enfermedades muy frecuentes en aquella época debidas a las malas condiciones de higiene, así como encubrir la suciedad. Mientras, el rey Luis XIII de Francia puso de moda a partir del siglo XVII que los hombres llevaran pelucas. La pelucas se introdujeron en el mundo anglosajón en la época del rey Carlos II de Inglaterra durante la restauración del trono en Inglaterra después de un largo exilio en Francia. Estas pelucas llegaban a la altura de los hombros, imitando los largos cabellos tan de moda entre los hombres desde la década de 1620. Siendo las pelucas una prenda obligatoria para los hombres de prácticamente toda extracción social, el gremio de los peluqueros, que se estableció en Francia en 1665, ganó un prestigio considerable. Las pelucas en esa época eran muy elaboradas y cubrían fácilmente los hombros y el pecho. No es extraño que fueran pesadas e incómodas. La pelucas más caras se elaboraban con cabellos humanos, no obstante había materiales alternativos más económicos como el pelo de caballo y cabra.

En el siglo XVIII las pelucas se llevaban empolvadas, para darles su color blanco característico. Las que usaban las damas de la corte solían ser tan recargadas y voluminosas que se veían obligadas a viajar con la cabeza gacha en sus carruajes para no estropear el efecto de sus aparatosos tocados. Sin embargo, en la época georgiana en Inglaterra, el primer ministro William Pitt impuso un impuesto para que quien quisiera usar una peluca empolvada lo pagase. Sin embargo, al ver que era un impuesto ridículo y desmesurado que los elaboradores de pelucas cobraban, la misma gente optó por empolvarlas por sí mismos con harina o cal.

En el siglo XIX existía una gran variedad de pelucas disponibles, si bien las pelucas completas no estuvieron de moda a lo largo de dicho siglo y a principios del XX, pues las utilizaban las damas mayores que habían perdido su cabello. 
Las pelucas se llevaban habitualmente durante los comienzos de la historia estadounidense. Así lo hicieron John Adams, Thomas Jefferson, James Madison y Alexander Hamilton.

Actualmente, en la mayoría de los países de la Commonwealth, las pelucas especiales son llevadas por abogados, jueces y un cierto número de oficiales del Parlamento como símbolo de su oficio. Hasta 1823, también todos los obispos del Reino Unido utilizaban pelucas ceremoniales.

Desde finales del siglo XVII hasta principios del XIX las tropas usaban uniformes que imitaban más o menos las modas de la época. Como parte de los uniformes los oficiales llevaban pelucas más adecuadas para los salones que para el campo de batalla. Así, a finales del siglo XVIII los oficiales llevaban pelucas muy largas de color natural, pero en el siglo XVIII los civiles adoptaron pelucas más cortas, empolvadas y recogidas con una trenza, que acabarían adoptando los militares ya que eran más prácticas para aguantar los rigores de la vida militar que las más elaboradas que se usaban en las cortes.
Aun en los climas extremos de la India y África o en cualquier colonia del mundo los oficiales británicos debían usar una peluca empolvada por incomodo que fuese. Por esta razón, las pelucas comenzaron a elaborarse de algodón tratado para ser un poco menos incomodas.

El significado de las pelucas ha sido trasladado paulatinamente al campo del humor, enriqueciendo y fortaleciendo de esta manera su relación con el lenguaje.

En el Diccionario de la Real Academia Española (RAE) se hace referencia el término peluca como un coloquialismo para designar, con ironía, a la persona que usa pelucas. Peluca es también una reprensión furiosa y despectiva que se usa para humillar a un inferior, según el Diccionario.

En la actualidad la mayoría de las pelucas y postizos se fabrican industrialmente, pero todavía existen profesionales que son capaces de realizar este trabajo a mano.

En España había una gran industria en los años 1960 casi hasta 1990. Las modas, el cierre de la aduana a EE.UU. y, por supuesto, la globalización han hecho cerrar al 99% de la industria en España.

Actualmente en Madrid y como sucesión de la empresa familiar creada por Hipólito Jarillo en 1968 (documentado en la cámara de comercio con licencia para la realización de obras de pelo natural) continúan fabricando “obras de cabello natural” a medida y a mano bajo el nombre comercial de NHC (Natural Hair Center).


</doc>
<doc id="21945" url="https://es.wikipedia.org/wiki?curid=21945" title="Cabeza">
Cabeza

La cabeza es la parte superior del cuerpo, y superior o anterior de muchos animales, donde se encuentran algunos órganos de los sentidos y el cerebro: el cuerpo humano está formado por cabeza, tronco y extremidades. 
La cabeza (o "testa", que puede ser o bien la cabeza en sí o la frente), de un animal, es la parte anterior del cuerpo que contiene la boca, el cerebro y varios órganos sensoriales (generalmente órganos de visión, audición, olfato y gusto). 
El máximo grado de cefalización se da en los artrópodos (sobre todo insectos) y en los vertebrados; en estos animales, la cabeza está netamente diferenciada del resto del cuerpo y provista de órganos sensoriales muy eficientes. 

Los animales más sencillos, como las esponjas, y los que presentan simetría radial (cnidarios y ctenóforos) no poseen cabeza, pero sí la tienen la mayoría de las formas con simetría bilateral (Bilateria); estos animales poseen un eje antero-posterior de manera que en la parte anterior del cuerpo se concentran el cerebro y los órganos sensoriales; el grado de cefalización es variable en los distintos filos bilaterales; muchos poseen una cabeza incipiente (platelmintos, anélidos, nematodos, moluscos). Dentro de los bilaterales, hay también grupos sin cabeza como los bivalvos, briozoos, equinodermos, etc.

Los artrópodos son los invertebrados con un grado mayor de cefalización, lo que se traduce en la posesión de un cerebro complejo. El cerebro está formado por la fusión de los tres pares de ganglios de los tres primeros segmentos del cuerpo, de modo que se puede distinguir tres regiones: 

Los escleritos de la cabeza están también fusionados entre sí, formando una estructura compacta denominada "cápsula cefálica".
Una cabeza de insecto típico se compone de ojos compuestos, antenas, y los componentes de la boca. Estos componentes difieren sustancialmente de insecto a insecto, formando importantes enlaces de identificación . Los ojos en la cabeza se encuentra, en varios tipos de insectos, están en la forma de un par de ojos compuestos con múltiples caras. En muchos otros tipos de insectos los ojos compuestos se ven en una "faceta individual o grupo de facetas individuales". En algunos casos, los ojos pueden ser vistos como marcas en el dorsal o localizados cerca o hacia la cabeza, dos o tres ocelos (órganos individuales como facetas ). 

Las antenas en la cabeza del insecto se encuentra en forma de accesorios segmentados, de dos en dos, que por lo general se encuentran entre los ojos. Estos son en diferentes formas y tamaños, en forma de filamentos o en diferentes forma ampliada o Clubbed. 

Los insectos tienen partes bucales de diferentes formas dependiendo de sus hábitos de alimentación. Labrum es el "labio superior", que es en la zona frontal de la cabeza y es la parte más exterior. Un par de mandíbula se encuentra en la parte posterior del labrum que flanquea el lado de la boca, sucedido por un par de cada uno de los maxilares que se conoce como palpo maxilar.. En el lado posterior de la boca es el labio o el labio inferior. También hay una parte de la boca extra en algunos insectos que se denomina como hipofaringe que normalmente se encuentra entre las maxillas.

La evolución de la cabeza, en los vertebrados se ha producido por la fusión de un número fijo de segmentos anteriores, de la misma manera que en otros "animales heterónomamente segmentados". En algunos casos los segmentos o una porción de los segmentos desaparecen. Los segmentos de la cabeza también pierden la mayor parte de sus sistemas excepto para el sistema nervioso. Con el desarrollo progresivo de la cefalización, "la cabeza incorpora más y más de los segmentos adyacentes en su estructura, por lo que en general se puede decir que cuanto mayor es el grado de cepahalization mayor es el número de segmentos que componen la cabeza".

La región anteroinferior de la cabeza, donde se encuentran los ojos, nariz y boca, es llamada cara o rostro, la región superior a esta, frente, y el mentón el extremo inferior. Una vez privada la cabeza de las partes blandas, queda su esqueleto, la cabeza ósea, que se articula con la primera vértebra del raquis, el atlas, mediante el occipital.
Los huesos de la cabeza ósea se organizan en dos grupos claramente diferenciados: cráneo y cara:
Además, en ella se fijan los músculos de la mímica, y se alojan órganos de los sentidos o sus anexos: ojos, fosas nasales, lengua. A su vez, cráneo y cara están formados por diversos huesos, todos ellos pares, excepto cuatro: tres del cráneo (frontal, etmoide, occipital), y uno de la cara (vómer).




</doc>
<doc id="21946" url="https://es.wikipedia.org/wiki?curid=21946" title="Instituto Tecnológico de Durango">
Instituto Tecnológico de Durango

El Instituto Tecnológico de Durango (ITD), fundado el 2 de agosto de 1948, se encuentra localizado en la ciudad de Victoria de Durango, Durango, México (coordenadas: 24°01'52.39" N 104°38'48.89" O). 

El ITD es el primer instituto tecnológico público en la provincia mexicana y es miembro del sistema del Tecnológico Nacional de México. 

Las licenciaturas ofrecidas en el instituto son:
Los programas de posgrado que ofrece son:

El ITD cuenta además con una unidad de Educación a distancia.

El ITD tiene programas deportivos en las disciplinas de Fútbol Americano, Voleibol, Basquetbol, Atletismo, Natación, Béisbol, Fútbol soccer, Karate Do, Tae Kwon Do, Volibol de playa, Frontenis, Tenis y Ajedrez.

El programa de Fútbol americano del ITD se fundó en 1973, tiene categorías infantiles, juveniles y ocasionalmente de intermedia. En esta última categoría, en 2008 y 2009 participaron en la Conferencia Guillermo "Chucus" Olascoaga de la CONOFAI. En 2011 no tuvieron actividad ni en juvenil, ni en intermedia. Actualmente tienen categorías intermedias y flag femenil.

Burros Blancos ITD (también conocidos como "Burros del Tecno"), es el nombre genérico de los equipos deportivos representativos del instituto, y en especial del equipo de fútbol americano.




</doc>
<doc id="21948" url="https://es.wikipedia.org/wiki?curid=21948" title="Espejo">
Espejo

Un espejo (del lat. "specullum") es una superficie pulida en la que, después de incidir, la luz se refleja siguiendo las leyes de la reflexión. 

El más sencillo es el espejo plano, en el que un haz de rayos de luz paralelos puede cambiar de dirección completamente en conjunto y continuar siendo un haz de rayos paralelos, pudiendo producir así una imagen virtual de un objeto con el mismo tamaño y forma que el real. La imagen resulta derecha pero invertida en el eje normal al espejo.

También existen espejos curvos que pueden ser cóncavos o convexos. En un espejo cóncavo cuya superficie forma un paraboloide de revolución, todos los rayos que inciden paralelos al eje del espejo, se reflejan pasando por el foco, y los que inciden pasando por el foco, se reflejan paralelos al eje.

Los espejos son objetos que reflejan casi toda la luz que choca contra su superficie, debido a este fenómeno podemos observar nuestra imagen en ellos. Los espejos en realidad son cristales que contienen detrás una capa de aluminio (o de otro material, pero es más fácil de aluminio).

Los espejos como utensilios de tocador y objeto manual fueron muy usados en las civilizaciones egipcia, griega, etrusca y romana. Fue usado en la cultura hebrea, era parte de la fuente de metal que estaba a la entrada del Tabernáculo de la Reunión. Al lavarse los sacerdotes, podían ver sus imperfecciones (Éxodo 38:7-9; 30:18; escrito aproximadamente en el 1447 a. C). 

Se elaboraban siempre con metal bruñido, generalmente cobre, plata o bronce, a este proceso se le conoce como plateo. Tenían forma de placa redonda u oval, decorada ordinariamente con grabados o relieves mitológicos en el reverso (los romanos carecen de grabados, pero no de relieves) y con mango tallado para asirlos cómodamente; de ellos, se conservan todavía muchos ejemplares en algunos museos arqueológicos. Durante la alta Edad Media, apenas se hizo uso del espejo, hasta que en el siglo XIII se inventó la fabricación de los de vidrio y de cristal de roca sobre lámina metálica (o con amalgama de plomo o estaño que son los "espejos azogados"), sin dejar por esto de construirse los de solo metal hasta el siglo XVIII. 

El espejo, como mueble de habitación, empieza con el siglo XVI, pues aunque durante los dos siglos anteriores se citan algunos ejemplares históricos apenas era conocido y su uso era poco corriente. En dicho siglo, se presenta con marco elegante y pie artístico y ocupa lugar distinguido en el salón como objeto movible y de dimensiones reducidas. Hacia fines del siglo XVII las fábricas venecianas logran construir espejos de gran tamaño y desde entonces sirven como objetos singularmente decorativos en los salones, en los que ocupan un lugar destacado. 

Los espejos modernos consisten en una delgada capa de plata o aluminio depositado sobre una plancha de vidrio, la cual protege el metal y hace al espejo más duradero. Este proceso se conoce como plateado.

Para una imagen formada por un espejo parabólico (o esférico de pequeña abertura, donde sea válida la aproximación paraxial), se cumple que: formula_1 , en la que "f" es la distancia del foco al espejo, "s" la distancia del objeto al espejo, y "s"' la distancia de la imagen formada al espejo, se lee: 

«La inversa de la distancia focal es igual a la suma de la inversa de la distancia del objeto al espejo con la inversa de la distancia de la imagen al espejo» 
y formula_2 , en la que "m" es la magnificación o agrandamiento lateral.

El espejo ocupa un lugar importante en la mitología y las supersticiones de muchos pueblos. La imagen que en él se refleja se identifica a menudo con el alma o espíritu de la persona: de ahí por ejemplo que los vampiros, cuerpos sin alma, no se reflejen en él. Cuando un moribundo está a punto de dejar este mundo, es común que se cubran los espejos, por temor a que el alma del agonizante quede encerrada en ellos. 

El espejo se concibe, así, como ventana al mundo de los espíritus. La leyenda urbana de Verónica aprovecha ejemplarmente esta visión. Viceversa, el mundo de los espíritus tiende a imaginarse como una contrapartida especular del de los vivos. Lewis Carroll desarrolla magistralmente la idea del espejo como entrada a un mundo inverso en la segunda parte de las aventuras de Alicia.

El espejo es también objeto frecuente de consulta: se le juzga capaz de mostrar sucesos y objetos distantes en el tiempo o el espacio. En el cuento de "Blancanieves", el espejo tiene la facultad de hablar y responde a las preguntas que le fórmula la madrastra. J. R. R. Tolkien retoma con su célebre «espejo de Galadriel» la tradición del espejo capaz de mostrar el futuro. En la novela "Harry Potter y la piedra filosofal", de J. K. Rowling, aparece el espejo de Oesed ("Deseo" leído a la inversa), que no refleja la imagen de quien lo contempla, sino sus deseos más profundos.

También es notable el Espejo de la Sabiduría (en el que se refleja «todas las cosas del cielo y de la tierra excepto el rostro de quien se mira en él»), descrito por Oscar Wilde en el cuento «El pescador y su alma».




</doc>
<doc id="21949" url="https://es.wikipedia.org/wiki?curid=21949" title="Eric Cartman">
Eric Cartman

Eric Theodore Cartman es un personaje ficticio y el principal antagonista de la serie de dibujos animados "South Park". 

Fue creado improvisadamente por Trey Parker y Matt Stone como un garabato y modelo base de un corto llamado "Jesús Vs. Frosty", que debutó oficialmente en el capítulo titulado "Cartman Tiene Una Sonda Anal" estrenado el 13 de agosto de 1997. 

Es uno de los personajes principales de la serie, y más manipulador, malintencionado, rencoroso, racista y discriminador, además de ser inteligente y estratega. Gracias a esto, ha resultado ser uno de los más conocidos en la historia de la animación moderna en la televisión estadounidense. También es el enemigo jurado de Kyle Broflovski (otro de los protagonistas), a quien le hace la vida imposible por ser judío. Este personaje representa la mayoría de los estereotipos negativos asociados a un estadounidense.
A partir de la temporada 20 el personaje cambia radicalmente su personalidad tras recibir una brutal golpiza del nuevo director de la escuela primaria (Director PC).
Esto conlleva un redireccionamiento completo de la serie, que pasa de ser una vulgar y bizarra comedia sin códigos de respeto, para convertirse en una aguda serie involucrada con los problemas que atraviesa la sociedad moderna.

Eric Cartman tiene 10 años y es el más desagradable e inmoral de su grupo de amigos (Kyle, Stan y Kenny). Es un chico gordo, malcriado, egoísta al punto del narcisismo, temperamental, desleal, extremista, xenófobo, racista, chovinista, psicotico, Sociopata especialmente antisemita, insultando a Kyle constantemente y disfrazándose de Hitler en varias ocasiones, agresivo y burlón (se ha demostrado que no es homofobico) Incluso con aquellos quienes lo consideran su amigo, razón por la que generalmente es el más solitario de los 4 (de hecho, juega al té con sus muñecos: La Rana Clyde con quien se siente muy allegado, Mariquita Pérez, Peter Panda, entre otros). Cuando se lo propone, Eric logra burlar a sus amigos y salirse con la suya usando su gran capacidad, normalmente es atrapado después de que ya pierde el control de sus proyectos. También adora a los gatos, ya que en un capítulo esconde gatos en su ático, a lo que Kenny lo descubre y empieza a quesear con ellos. En ocasiones es especísta, lo que quiere decir que da por sentado a cualquier especie que no sea la humana, pero ha habido episodios en donde no lo es, tal vez por su amor por los gatos y por su gran racismo y desprecio por otros humanos.

Si bien Eric cumple el papel de antihéroe en la serie, ha habido episodios en donde ha desarrollado una mentalidad extremadamente psicópata, apática e insensible con cualquier persona en general. Uno de los episodios donde probablemente alcanzó a la cumbre de su maldad fue en "Scott Tenorman Debe Morir" (de la temporada 5), donde, por venganza, ingenió un plan con el que mató a los padres de un adolescente, los cortó en pedazos, los cocinó en chile y se los dio al mismo chico a comer. Desde ese famoso y recordado episodio, Eric pasó a ser el antagonista principal de la serie, y demostrando que su maldad no era en sí la "inocencia" de un niño. Aunque Cartman ha demostrado tener cierta parte de bondad. Por ejemplo en "El Gran Tetaje" se mostró preocupado por Kenny cuando "queseo", y salvo a algunos gatos del barrio, o en "Liberen a Wilsix" se unió a los chicos para liberar a la ballena, y contuvo a Kyle cuando creyó que la ballena iba a morir. (La cual posteriormente murió por que la enviaron en un cohete a la luna).

La pésima dieta de Eric le condena a la obesidad, y sus amigos, para burlarse, le llaman normalmente "culo gordo" o "culón". Él siempre contesta que no está gordo, sino que es "de huesos anchos" o "fuertecito". De Cartman es característica su papada y su cuerpo que es el doble de ancho que el de sus amigos. César trabajó para el en los primeros episodios, ya que cuando tienen que hacer una pareja en grupo, Nil va con Jhuliam. A partir de la 7ª temporada, el único que trabaja para él es Butters, ya que lo considera su amigo y no sabe que Eric le traiciona, pero en la mayoría de los casos Eric termina más humillado que él.

Tal vez sea su familia la culpable de su naturaleza: su madre Liane es una reina del porno, además de que es hermafrodita, que resultó ser su padre en el episodio dos de la segunda temporada "La madre de Eric Cartman sigue siendo una puta sucia" (pero una madre muy dulce al mismo tiempo), aunque en el episodio "201" de la temporada 14 desmienten esto, revelando que el verdadero padre de Eric es Jack Tenorman. Al parecer todos los demás familiares de Cartman parecen tener exactamente su mismo humor.

En el episodio "201", se reveló la verdadera identidad del padre de Eric Cartman: Jack Tenorman, ex jugador de los Broncos de Denver , a quien Cartman asesinó junto a su esposa y se lo dio de comer a Scott. (Quien resulta ser su medio hermano).

En otro capítulo confiesa estar enamorado de una niña llamada Patty Nelson y que fantaseaba con besarla, sólo aparece en esa escena.

Su enemistad con Kyle es la suprema de la serie, pero aun así se suelen considerar amigos. Kyle es la razón por la que Cartman odia a los judíos y a los pelirrojos. Por otro lado, Kyle a veces siente envidia por las ideas ingeniosas de Cartman y hace todo lo posible para que sus planes se arruien. En un episodio, cuando a Cartman le diagnostican Sida, Kyle no puede contener su risa y tiene que salir de la habitación para reírse en el pasillo, mientras todos los que están adentro escuchan en silencio las carcajadas de Kyle. En pocos episodios se han visto como buenos amigos, pero Cartman siempre desea que Kyle sea humillado. A diferencia de Butters o Kenny, Kyle no cae tan fácil en sus bromas por ser inteligente y casi nunca teme enfrentarse a él. Sin Kyle, Cartman no tendría de quien burlarse o a quien insultar, por lo que su vida sería aburrida.

También fue el superhéroe conocido como "El mapache", que "salva el crimen" confundiendo las cosas y le importaba más ser famoso y reconocido, rivalizando con el superhéroe Mysterion quien era más adorado, y resultó ser Kenny. Posteriormente forma un grupo de superhéroes con sus amigos, pero él está solamente interesado en ser famoso y chantajear al Capitán Hindsight (el superhéroe más amado de South Park) que en salvar al crimen y las personas por lo que sus amigos deciden sacarlo. Luego, creyendo que él es el héroe y que sus amigos fueron "hechizados por un poder maligno", decide hacer alianza con el dios Cthulhu, quien se toma como la deidad más malvada del universo creyendo que debía "unirse al enemigo", y manipula a Cthulhu para destruir sinagogas, matar hippies y a Justin Bieber, y desterrar a sus amigos al oscuro olvido, pero luego él y Cthulhu son derrotados por Mint-berry Crunch, uno de los superhéroes del grupo que sí tenía un superpoder.

Cartman se ha hecho famoso por las malas acciones que recurrentemente hace en la serie. Aquí hay algunas de ellas:

Temporada 1



Temporada 2


Temporada 3










Temporada 4






Temporada 5




Temporada 6





Temporada 7
Kyle teniendo un cargo de conciencia decide confesar el hecho, por lo que Eric decide matarlo para evitar que se sepa la verdad. Luego de dos intentos fallidos de matar a Kyle, Eric decide adelantarse y confesar el acto ante la directora de su colegio con lo que se le recompensa con un castigo menos drástico y menos prolongado que el de Kyle, Stan y Kenny. 




Temporada 8








Temporada 9






Temporada 10









Temporada 11





Temporada 12






Temporada 13


nota, se trató que en Somalía le dicen piratería a los delincuentes, y bajo un comentario sarcástico de Kyle
pudo ir, aunque este lo siguió pues se llevó a Ike, más los supuestos crímenes era por el sable de luz de Kevin, el cual le creyó con el tesoro pero uno de los delincuentes los sensibilizó a excepción de Cartman pues este describió a Somalía como el paraíso, aunque Kyle le replico que se refiere a lo sumisa que la población. Al final matan a toda la piratería a excepción de los chicos cosa que molesta a Cartman. 



Temporada 14






Temporada 15








Temporada 16 


Temporada 17




</doc>
<doc id="21950" url="https://es.wikipedia.org/wiki?curid=21950" title="Stan Marsh">
Stan Marsh

Stanley "Stan" Marsh es un personaje la serie de televisión animada South Park. Es interpretado y basado en el co-creador de la serie Trey Parker. Stan es el protagonista de la serie y uno de los personajes principales junto con sus amigos Kyle Broflovski, Kenny McCormick y Eric Cartman. Debutó en televisión cuando South Park se emitió por primera vez el 13 de agosto de 1997, después de haber aparecido por primera vez en los cortos "The Spirit of Christmas" creado por Parker y Matt Stone, en 1992 ("Jesús vs. Frosty") y 1995 ("Jesús vs. Santa").

Stan es un estudiante de cuarto grado que comúnmente tiene excéntricas experiencias no muy típicas de la vida tradicional de un pequeño pueblo en su ciudad natal ficticia de South Park, Colorado. Stan es generalmente representado como amable, eficiente, servicial y relajado. A menudo comparte con su mejor amigo Kyle un papel de liderazgo como protagonista del show. Stan no tiene reservas al expresar su distinta falta de estima por los adultos y sus influencias, ya que los residentes adultos de South Park rara vez hacen uso de sus facultades críticas.

Al igual que los otros personajes de South Park, Stan es animado por computadora para emular el método original del programa de animación de recorte. También aparece en la película (1999), así como en los medios y mercancías relacionados con South Park. Mientras que Parker y Stone describen a Stan un chico normal con tendencias infantiles comunes, su diálogo a menudo tiene la intención de reflejar posturas y puntos de vista sobre temas más orientados a adultos y ha sido citado frecuentemente en numerosas publicaciones por expertos en los campos de política, religión, cultura popular y filosofía.

Stan vive en South Park con su familia, compuesta por su padre Randy, un geólogo, su madre Sharon, una secretaria en una rinoplastia clínica, su hermana Shelley de 12 años de edad, que lo intimida y golpea regularmente, y su centenario abuelo Marvin en silla de ruedas, que llama a Stan "Billy" y ha tratado de influir en Stan para cometer una muerte misericordiosa sobre él. Él asiste a la clase de cuarto grado de primaria del Sr. Garrison. Durante los primeros 58 episodios de la serie (1997 antes del episodio de la cuarta temporada "4.º Grado" en el 2000), Stan y los otros personajes principales estaban en el tercer grado. Stan es con frecuencia avergonzado y/o molestado por las travesuras de su padre y los frecuentes actos de ebriedad en público. Stan tiene una relación como el sobrino de su tío Jimbo recibiendo una atención moderada en la primeras dos temporadas de la serie.

Entre los personajes principales de la serie, Kyle se define como el único niño judío, Cartman es reconocido por su obesidad y su naturaleza cruel, y Kenny se caracteriza por ser pobre y las muertes que con frecuencia le ocurren. En lugar de tener un rasgo distintivo importante, Stan es retratado (en palabras de la página web oficial de la serie) como "normal, promedio, americano, niño común".

Stan es el modelo de Parker, mientras que Kyle sigue el modelo de Stone.Y el Bart Simpson del día de hoy sigue el reflejo de una mezcla entre Stan y Cartman. Stan y Kyle son los mejores amigos, y su relación, que tiene por objeto reflejar la amistad en la vida real entre Parker y Stone, es un tema común en toda la serie. Los dos tienen sus desacuerdos, pero siempre se reconcilian sin ningún daño a largo plazo para su amistad. Como es el caso con sus otros amigos y compañeros de clase, Stan esta frecuentemente en desacuerdo con Cartman, resintiendo el comportamiento de Cartman y abiertamente burlándose de su peso. Stan también comparte una estrecha amistad con Kenny, mientras que Kenny confiesa que Stan es uno de "los mejores amigos de un hombre podría tener". Stan puede entender la voz apagada de Kenny a la perfección, y por lo general, exclama el lema "¡Oh Dios mio, han matado a Kenny!", a raíz de una de las muertes de Kenny, que permite a Kyle seguir con "¡hijos de puta!". Stan es el único personaje en el grupo que tuvo una novia estable, Wendy Testaburger, y su relación fue un tema recurrente en las temporadas anteriores de la serie. A pesar de la conciliación y la declaración que volvieron de nuevo en el episodio de la temporada de 11 (2007) "La Lista".


</doc>
<doc id="21951" url="https://es.wikipedia.org/wiki?curid=21951" title="Kyle Broflovski">
Kyle Broflovski

Kyle Broflovski es un personaje ficticio de la serie animada "South Park", interpretado en inglés por Matt Stone. Matt Stone ha afirmado que Kyle está basado en él cuando era más joven. De hecho, el apellido Broflovski está basado en el apellido de sus padres (Broflovski).

Usa una ushanka verde, una chaqueta naranja con bolsillos al frente, pantalones verde oscuro y guantes verdes. Casi nunca es visto sin su gorro, pero se puede ver que tiene un peinado afro o cabello liso y es pelirrojo. Sufrió de diabetes durante un tiempo muy corto hasta que se le trasplantó un riñón de Eric Cartman, que se le extrajo mediante el engaño de sus otros amigos.

La frase más famosa de Kyle es el grito "¡Hijos de puta!" (en el primer doblaje de México decía "mondrigos") después de la frase de Stan "¡Oh Dios mío, mataron a Kenny!". También en un episodio él mismo asesina a Kenny y dice "¡Oh Dios Mío, maté a Kenny!, ¡Hijo de Puta! ".que es similar al clásico "pequeño demonio" (en la segunda película también decía "mondrigo") de Homer Simpson medio segundo antes de estrangular a Bart. Otra de sus expresiones famosas figura el tradicional ""¿Listo Ike?, patea al bebé"", precedido de Ike diciendo ""No patea al bebé"" y Kyle le responde diciendo ""¡patea al bebé!"" y pateando a Ike mandándolo a volar (literalmente).

La primera vez que kyle se enamoró fue, de una chica llamada Rebeca (conectada al "mono de la fonética"). Con ella se mostró muy cariñoso , después del cual Rebeca no vuelve a aparecer en la serie. En otro capítulo se enamora de la maestra sustituta en la temporada 19 capítulo 10, Kyle se enamora de lesly a la cual protegía del director pc .A pesar de todo esto Kyle demuestra ser una persona o individuo listo y sagaz defensor de los derechos y buen amigo .
Kyle es el más listo de los cuatro protagonistas pero es más ingenuo que Stan. Su más cercano amigo del grupo es Stan Marsh. Kyle y su hermano menor adoptivo, Ike Broflovski, son los únicos niños judíos en el pueblo, aunque en el primer episodio de la serie aparece un niño con kipá, que afirma que su papá es un abogado. A diferencia de su mejor amigo Stan, Kyle es más precavido y tiende a involucrarse menos en situaciones peligrosas. A veces muestra mejores valores morales que el resto de sus amigos, y tiene una obsesión por la higiene y fobia al pis. Por ser el único niño judío (además de su hermano menor), Kyle es frecuentemente objeto de los insultos de Eric Cartman, ya que este último es antisemita. Sin embargo, Kyle parece no tener miedo de enfrentarse a Cartman y lo ha atacado en repetidas ocasiones. Cuando Cartman y Kyle discuten, usualmente Kyle es el ganador del argumento, aunque ha habido excepciones. A pesar de su aparente odio hacia Cartman, Kyle aún lo considera un amigo de cierta forma. De hecho, es el optimismo idealista de Kyle el que demuestra que en todas las personas hay un lado bueno, incluso en Cartman. Casualmente es el primero en descubrir los planes de Cartman para engañar a las personas o ganar dinero aunque nadie lo ve de esa manera y le trae varios problemas sociales. Kyle ha salvado la ciudad y a sus amigos en muchas ocasiones junto a Stan, generalmente uno de ellos o ambos dicen una reflexión al final del episodio, pero los adultos pocas veces se toman esto en serio.

Su madre, Sheila, es muy sobreprotectora y exagera todos los problemas cada vez que su hijo se ve "amenazado" por ellos. Instigó una guerra entre Estados Unidos y Canadá en por la indignación que le causa la extremadamente escatológica película de los canadienses Terrance y Phillip.

Su hermano menor Ike es canadiense, cuando se dio cuenta de ello Kyle no lo aceptó, pero luego llegó a apreciarlo. Su padre, Gerald es un abogado, aunque en un capítulo quiso ser un delfín. Kyle asegura que a pesar de la profesión de su padre, su familia no es tan rica como la familia de Token Black, cuyo padre es también un abogado.



</doc>
<doc id="21952" url="https://es.wikipedia.org/wiki?curid=21952" title="Kenny McCormick">
Kenny McCormick

Kenneth "Kenny" McCormick, interpretado por Matt Stone, es un personaje ficticio de la serie animada South Park. Es famoso porque no se le entiende bien cuando habla debido a la capucha de su abrigo (de ahí que el momento en que se quita la capucha al final de fuera "dramático"), aunque en muy pocos episodios sí se le entiende, pero habla muy poco. También es conocido por morir en casi todos los episodios, a lo cual normalmente sigue una exclamación de "¡Oh, Dios mío! ¡Han matado a Kenny! ¡Hijos de puta!" por parte de sus amigos Stan y Kyle.

En el episodio 13 de la quinta temporada (la muerte de Kenny) muere de forma aparentemente definitiva tras una enfermedad muscular de carácter terminal, pero vuelve a aparecer en el episodio 17 de la sexta (Abajo el trineo rojo).

En la decimotercera temporada se descubre que Kenny tiene una doble identidad y que trabaja en las noches siendo un superhéroe llamado Mysterion, Cartman fue el primero en percatar su presencia pero en un principio sospechaba que era Kyle digamos que Mysterion ha aparecido en tres episodios El Coon (al principio ese episodio fue llamado "El Mapache"), un especial llamado El Coon vs Coon y Amigos (que consta de 3 capítulos de South Park) y El Chico Pobre.

Le gusta ver revistas pornográficas y es uno de los más listos y audaces del grupo. Kenny es uno de los personajes menos violentos que hay en la serie; se caracteriza principalmente por ser un personaje reservado, tranquilo, gracioso y excéntrico amante de la pornografía (llegó incluso a sacrificar su vida por sus amigos). En un capítulo, llamado "Pelea de inválidos", se insinuó que el origen de su repetidas muertes era su vestimenta, pero se cree que también es porque sus padres asistieron a una reunión de Cthulhu, al principio tuvo una novia llamada Kelly en la temporada 3, pero en la temporada 13 salió con Tammy Warner hasta que murió de sífilis debido a que Tammy "se la chupó". 
Kenny es un personaje muy reservado , pero a veces se descontrola.
Kenny muere en casi todos los capítulos, pero siempre volviendo a revivir, apareciendo nuevamente en su cama, por lo que en un capítulo se dice que es inmortal. 

Hasta 2001 en la temporada 5, Kenny moría en todos los capítulos. A partir de ese año, sus muertes se volvieron inusuales y desapareció la exclamación que sus amigos hacían después de su muerte.

En su grupo no tiene mejor amigo a pesar de que en ocasiones considere a Cartman como tal, ya que éste a veces lo trata mal especialmente por ser pobre. Su relación con Stan y Kyle es buena, pero se ha visto en pocos episodios. Kenny normalmente sigue a sus amigos y juega con ellos sin tener mucha relevancia, y solo habla para algunas situaciones especiales. En algunos episodios sí se le entiende lo que dice pero habla con una voz muy discreta y de baja intensidad, excepto cuando es Mysterion, con una voz más grave.

Cortos "Espíritu de Navidad"



Temporada 1













Temporada 2

















Temporada 3
















Temporada 4
















Temporada 5













Temporada 6

Kenny estuvo ausente en esta temporada debido a su muerte "permanente", aparece de nuevo al final del último episodio de esta temporada.
Temporada 7

Temporada 8

Temporada 9



Temporada 10

Con excepción de la muerte de su personaje en World of Warcraft, esta es la primera temporada en la que no muere Kenny.
Temporada 11

Temporada 12

Esta es la segunda temporada donde en la que no muere Kenny.
Temporada 13



Temporada 14



Temporada 15

Temporada 16

Temporada 17

Con excepción de su muerte y resucitacion rápida en la sequencia de anime del "La Princesa Kenny", esta es la tercera temporada en la que no muere Kenny.
Temporada 18

Esta es la cuarta temporada en la que no muere Kenny.
Temporada 19

Esta es la quinta temporada en la que no muere Kenny.
Temporada 20

Esta es la sexta temporada en la que no muere Kenny.
Temporada 21

En una entrega de los Premios (Emmy) a fines de los 90, los cuatro chicos de South Park presentaron un premio. Después de anunciar al ganador, una estatua gigante del Emmy, cae sobre Kenny y lo mata.
Pero al Final del episodio Kenny aparece ileso con Stan , Kyle y Cartman.
En la película "", Kenny intenta probarle a Cartman que los pedos son combustibles (Producto de la película de Terrance y Philip) consigo mismo, quemándose vivo, posteriormente un camión arrojaría accidentalmente una montaña de sal sobre él; pero lo que de verdad causaría su muerte sería cuando, en el hospital, el "Dr. Doctor" remplazaría su corazón por una patata al horno procedente de un microondas que aparentemente debía ser de uso médico pero que uso uno de los enfermeros para calentar su almuerzo, eventualmente esto le devuelve la vida por tres segundos y luego fallece, explotando su cuerpo. 

Durante su estadía en el infierno, Kenny intentaría convencer a Satanás que no se deje manipular por su esposo Saddam Hussein, que tarde o temprano terminaría quitándole el trono, pero Satanás es demasiado débil para enfrentarlo; por lo que Kenny aparecería como fantasma en la habitación de Cartman, aunque éste saldría corriendo. 

Al final, cuando Saddam Hussein y Satanás invaden la tierra, de alguna forma Kenny logra colarse y salir a la tierra; donde finalmente convence a Satanás de dejar a Saddam, quien es arrojado a las rocas del infierno donde es atravesado por una estalagmita.por haberle mostrado que lo estaban manipulando y en agradecimiento Satanás está dispuesto a concederle un deseo a Kenny, éste desea que todo volviera a ser como antes, aunque eso significaba que Kenny volvería a morir y regresar al infierno, sin embargo a Kenny ya no le importaría ya que estaba haciendo lo correcto no solo por sus amigos si no por la tierra en general, eventualmente se quita la capucha, revela su rostro y cabello para después despedirse de sus amigos, desapareciendo lentamente, para así partir solo que esta vez, Kenny entraría al cielo de manera definitiva por lo que se ganaría sus Alas y su Aureola (Las cuales son otorgadas por ángeles femeninos desnudos) confirmando que su deseo prácticamente limpio el resto de sus pecados exitosamente.

En el episodio 4x05 Cartman se une a Nambla se ve cuando Kenny muere, la madre de Kenny tiene otro hijo después (si Kenny no muriese tendría un total de 53 hermanos Hasta ese episodio), este evento se repite otra vez en el capítulo de tres partes en la temporada 14 "El Coon vs Coon y Amigos", cuando Kenny admite ser inmortal en el final de ese episodio se ve cómo su madre lo vuelve a parir y lo deja sobre la cama, se infiere que crece rápidamente y recupera su memoria (o bien nunca la pierde). Este poder lo tiene porque sus padres asisten a una reunión del culto a Cthulhu, muy probablemente y por coincidencia de fechas, cuando la mamá de Kenny está embarazada de él.

En el episodio Pelea de Inválidos, se insinúa que la causa a las muertes de Kenny es su vestimenta. Timmy regaló a Jimmy una capucha naranja similar a la de Kenny; Jimmy por poco muere en 7 ocasiones:
Adicionalmente en Campamento de/para gordos un niño vestido con la capucha de Kenny muere dentro del útero de la Srta. Verónica Crabtree.

Pero curiosamente en el episodio de Los Jeffersons y Pee, Kenny muere pero sin su vestimenta, solo llevaba puesto una mascara en Los Jeffersons y solo va con traje de baño en Pee pero al final raramente aparece con su traje de baño y con una toalla en la cabeza.

El co-creador de la serie Trey Parker explicó que las continuas muertes (y resurrecciones) de Kenny y la falta de interés de sus amigos en ellas están basadas en un amigo de infancia: el amigo de Parker era el niño más pobre del vecindario y también se llamaba Kenny; debido a que era muy pobre constantemente no podía ir a la escuela, así que cuando Parker y sus otros amigos esperaban el autobús y notaban su ausencia decían a manera de broma que había muerto y seguían con su día; tras unos días Kenny volvía a aparecer sin que nada hubiera pasado.

Kenny también es famoso por casi nunca aparecer sin su capucha anaranjada, aunque se la quita en la película (mostrando que es rubio) y en la segunda, la cual se ve durante más tiempo. 
















</doc>
<doc id="21954" url="https://es.wikipedia.org/wiki?curid=21954" title="Manuel de Landa">
Manuel de Landa

Manuel de Landa (Ciudad de México, 1952) Escritor, artista y filósofo mexicano radicado en Nueva York quien cuenta con una muy variada y excepcional obra multidisciplinar. Ha escrito intensamente acerca de dinámicas no lineales, teorías de auto-organización, vida e inteligencia artificial (A.I), teoría del caos, arquitectura e historia de la ciencia. Actualmente, de Landa es profesor de la Escuela de Graduados de Columbia University en Nueva York en el área de arquitectura y es titular de la Cátedra Gilles Deleuze en la European Graduate School en Saas-Fee, Suiza. Se trasladó a New York en 1975 donde se hizo director de cine. En 1980 se interesó por la informática, fue programador pionero y realizó arte con el computador, cuando resalta como uno de los más destacados teóricos en el campo de la cibernética. 

En 1975, Manuel de Landa llega a la Ciudad de Nueva York para estudiar cine. Al tercer año de carrera logra que sus películas sean exhibidas en la Bienal del Museo Whitney y posteriormente, en 1979 uno de sus cortos es elegido para el Festival de cine de Nueva York. Sin embargo, decide dejar la carrera por las exigencias de tiempo.

Más tarde, De Landa decide reinventarse y adquirir una computadora Cromemco de 64k la cual debía ser previamente ensamblada para su uso. Al no haber software disponible para la máquina, De Landa comenzó a interesarse en la programación, iniciando en Basic para continuar en Pascal.

Estas dos etapas de su vida, en adición a su interés por las matemáticas y la filosofía de Deleuze, Foucault y Guattari lo impulsaron finalmente a dedicarse a la filosofía. En 1981 Escribe un primer ensayo titulado "Wittgenstein en el cine" y entre 1986 y 1989 escribe su libro La guerra en la era de las máquinas inteligentes. Más tarde, en 1997, publica "Mil años de historia no lineal", en donde hace un profundo análisis sobre la historia humana, la cultura y la relación que existe entre ambas desde las diferentes perspectivas geológica, biológica, ecológica, tecnológica y social.

De Landa está fuertemente influenciado por el pensamiento de Gilles Deleuze y Felix Guattari. Es uno de los representantes del nuevo materialismo, reinterpretando y reelaborando la filosofía y los conceptos de Deleuze. De Landa afirma que la ciencia puede estar al servicio de la filosofía siempre que ésta sea materialista, pues la filosofía fenomenológica no lleva a nada más que a una especulación vacua de la realidad.

Para conocer la realidad, primero hay que estar conscientes de nuestra materialidad, haciéndola nuestra y comprendiéndola. La morfogénesis (del griego ‘morphê’, forma y ‘génesis’ creación, literalmente el “origen de la forma”) es, en su filosofía, la producción de estructuras estables surgidas de flujos materiales y representa un concepto fundamental para la comprensión de dicho materialismo.

Este nuevo tipo de materialismo se basa en los tres estados de la materia –que coexisten sin eliminarse mutuamente–, asegurando que el líquido es el más interesante, pues se reinventa, se autoorganiza, cambia y crea su propia forma. Esta idea también la aplica a una teoría sobre la ética, la historia, el caos, complejidad social y el arte.

Pronunciándose en contra del uso y sacralización de un solo método, el científico, De Landa habla de tres tipos de razonamiento o estrategias explicativas que en filosofía deberían usarse conjuntamente para una comprensión más clara y profunda de un sistema o fenómeno.

Surgió con Darwin y Mendel y sus descubrimientos sobre selección natural y herencia genética. Este tipo de razonamiento se basa en el factor evolutivo de organismos o sistemas. La regla general que De Landa utiliza para explicarlo es: “Cualquier población de replicadores variables emparentados con algún filtro conducen a la evolución”.

Esta parte del método es utilizado por Deleuze para hablar de los fenómenos, sistemas o cosas en sí, no de sus orígenes, de su funcionamiento, ni comportamiento.

Proviene de la termodinámica, disciplina científica surgida en el siglo XVI que revolucionó la concepción de las máquinas, pues, a diferencia de los mecanismos de cuerda que hasta ese entonces habían existido, la moción y energía provenían de la máquina misma.

Este pensamiento parte del principio de que la energía es necesaria para el funcionamiento de todo. Ésta, si se añade a los factores propios del pensamiento poblacional, propiciará la morfogénesis, la creación de cuerpos biológicos y no biológicos en donde se dan intercambios de energía. 

Para explicar lo anterior, De Landa retoma la distinción de las magnitudes en la termodinámica: las extensivas y las intensivas. Las primeras son divisibles (volumen, área, longitud, etc.), las segundas no (presión, temperatura, velocidad, densidad, concentración, etc.). Lo que las magnitudes intensivas aportan a este estudio, es que, cuando en éstas se producen diferencias, como lo sería el cambio de temperatura, se generan cambios y flujos en los procesos, movimiento. De esta forma, las diferencias intensivas funcionan como combustible no sólo en dichos procesos, sino también en otros de mayor escala, como en la historia, el clima, la economía y la evolución. 

Las propiedades o magnitudes intensivas también presentan umbrales o puntos críticos. El agua por ejemplo, presenta dos, al calentarse hasta los 100º C y al enfriarse hasta los 0º C: evaporación y solidificación. Son puntos en los cuales las variaciones en cantidad son también variaciones de cualidad, mismas que se pueden desembocar en eventos morfogénicos.

La parte intensiva del método es utilizada para explicar orígenes.

El pensamiento topológico es utilizado para calcular espacios de posibilidad, o sea, todo fin posible de una cosa en términos de cambios. Todo lo material posee capacidades y tendencias. Las capacidades pueden ser reales –que verdaderamente suceden– o virtuales, que no suceden pero tienen el potencial de suceder. Esta estructura del espacio de posibilidades puede ser representada gráficamente, por medio de los avances en la medición de espacios tridimensionales logrados por Friedrich Gauss y Bernhard Riemann. Por medio de una variedad, lograron deshacerse del plano cartesiano como referencia para la medición de dichos espacios, al utilizar como variable la curvatura inmediata y sus cambios. A este cambio de curvatura, De Landa le llama “velocidad de devenir”, ya que, si la variedad se utiliza como método de representación, mostrará cómo las los sistemas que con ella se calculan cambian y devienen en algo más. 

Los espacios fásicos juegan un importante papel en este modelo, ya que representan los espacios de estados posibles. Para lograr la representación primero se necesita identificar las variables relevantes que repercuten en el sistema. Un péndulo, en este caso, podría variar en velocidad y posición. Posteriormente se debe crear una variedad con tantas dimensiones como grados de libertad (variables) tenga el sistema para después, con puntos distribuidos en este espacio denominados series de estados (trayectorias formadas por “estados del sistema”, que representan puntos en el espacio de posibilidades), trazar el espacio de posibilidad completo; un espacio que dará posible respuesta al comportamiento de sistemas más complejos al acercarse estas trayectorias a los atractores ubicados en un punto de la variedad. Los atractores representan estados estables, de equilibrio o el casi equilibrio del sistema. Sin embargo, si a un sistema se le estudia desde su punto de equilibrio absoluto, no se desplegará su repertorio completo de capacidades virtuales.

Estos tres tipos de razonamiento deben ser utilizados en conjunto para poder aprehender planamente un sistema y su funcionamiento al proporcionar una visión no linear de su desarrollo.

De Landa habla de los procesos históricos como cambios de estado. Al hablar del pensamiento intensivo, se refiere a umbrales críticos como el origen del cambio. La historia, pensada bajo esta lógica, obedecería también a transformaciones, específicamente de estado.

Según De Landa, ha habido dos modelos historiográficos: el basado en la física (específicamente en la termodinámica) y el basado en el evolucionismo. Sin embargo afirma que ambos se han visto limitados, pues el primero responde siempre en términos de equilibrio, y el segundo en términos del “mejor diseño”, dejando así sólo una posible vía para los eventos históricos. De este modo, la propuesta sería alejarse del equilibrio y de la búsqueda del mejor diseño para tener más posibilidades históricas, tomando en cuenta las fluctuaciones menores y propiedades emergentes como determinantes de cambios o bifurcaciones en los sistemas.

De Landa estructura el libro en tres capítulos, cada uno con una distinta narrativa histórica que abarca el periodo de mil años del siglo XI al XX.

De Landa habla de los procesos históricos como cambios de estado. Al hablar del pensamiento intensivo, se refiere a umbrales críticos como el origen del cambio. La historia, pensada bajo esta lógica, obedecería también a transformaciones, específicamente de estado.

Según De Landa, ha habido dos modelos historiográficos: el basado en la física (específicamente en la termodinámica) y el basado en el evolucionismo. Sin embargo afirma que ambos se han visto limitados, pues el primero responde siempre en términos de equilibrio, y el segundo en términos del “mejor diseño”, dejando así sólo una posible vía para los eventos históricos. De este modo, la propuesta sería alejarse del equilibrio y de la búsqueda del mejor diseño para tener más posibilidades históricas, tomando en cuenta las fluctuaciones menores y propiedades emergentes como determinantes de cambios (bifurcaciones) en los sistemas.

En éste, De Landa habla de las ciudades como ecosistemas simplificados. La narrativa se enfoca en los flujos de materia orgánica como gérmenes, plantas y animales. Se trata a las empresas coloniales como medios que “reorientan los flujos de alimentos hacia los territorio de las ciudades” y como “medios por el cual los genes de múltiples especies no humanas han invadido y conquistado ecosistemas extraños”.

Se habla del flujo de los materiales lingüísticos. Por qué algunas lenguas lograron predominar sobre otras por medio de la fluidez a diferencia del estado pétreo de, por ejemplo, el latín culto, que se solidificó al estandarizarse.

En este libro, De Landa traza la historia de la guerra y la tecnología a través de la utilización de armas y bombas inteligentes y su relación con la deshumanización de la guerra, la mistificación de tecnologías, la obsesión de la vigilancia y la conversión de un conflicto en entrenimiento.

Es un intento de De Landa por desafiar el paradigma sociológico de realizar análisis fructíferos por medio de la reducción del estudio en pequeña y gran escala, o sea, desde las acciones particulares de los individuos hasta el comportamiento de las sociedades como un todo. Utiliza la teoría de ensamblajes de Deleuze para estudiar a las entidades sociales a todas las escalas.




</doc>
<doc id="21964" url="https://es.wikipedia.org/wiki?curid=21964" title="Oro (heráldica)">
Oro (heráldica)

En heráldica, oro es la denominación de uno de los dos metales que se emplean en la representación de las armerías; el otro es la plata o argén. Representa al metal homónimo.

Convencionalmente se lo representa mediante los colores oro, dorado o amarillo. A veces se recomienda, para este fin, utilizar un amarillo mezclado algo de color ocre, de manera que tenga un tinte cálido, pero siempre teniendo en cuenta que el color final no debe ser tan rojizo que se lo pueda confundir con el esmalte anaranjado.

En ocasiones el artista puede emplear pintura dorada o un metal dorado para representar al oro heráldico; estas prácticas por lo general se ven en blasones que han sido trabajados con una intención ornamental o especialmente artística.

Cuando no se dispone de colores se representa al oro mediante un patrón de puntos equidistantes alternados respecto de la línea siguiente, según el método atribuido al jesuita Silvestre Pietra Santa. Este es el método de representación que se ve comúnmente en grabados a una tinta.

Siguen tres ejemplos antiguos y notables del uso del oro en heráldica.

De las armas de Federico I Barbarroja derivaría el Escudo del Sacro Imperio Romano Germánico y, a través de este, el actual escudo de Alemania.

Hacia el inicio del Renacimiento se desarrolló un sistema de correspondencias simbólicas para los colores heráldicos que hoy se encuentra en desuso.
Es de notar que hacia 1828 este sistema era considerado absurdo por el heraldista inglés William Berry, aunque el español Francisco Piferrer, en 1858, lo comenta como si todavía fuese válido.

Si bien Jean Courtois, Heraldo Sicilia del Reino de Aragón, menciona en su tratado "Le blason des couleurs" (1414) que cualquiera de estas asociaciones del oro heráldico puede usarse para blasonar, en la práctica es posible que solamente se hayan usado el sistema planetario y el sistema de piedras preciosas. Para Alberto y Arturo García Caraffa (1919), el blasonado con gemas correspondía a los títulos y el de planetas a los soberanos.
Arthur Fox-Davies cita un ejemplo de blasonado con piedras preciosas que data de 1458.

Debajo se dan algunas de las antiguas correspondencias simbólicas del oro heráldico, así como algunos de los nombres «griegos» que se le atribuyeron.
Además, el oro sería «el más noble» de los colores heráldicos.

El otro metal heráldico:

Los principales esmaltes heráldicos:
Y además:


</doc>
<doc id="21965" url="https://es.wikipedia.org/wiki?curid=21965" title="Transrapid">
Transrapid

El Transrapid es un tren de tecnología alemana que se desplaza mediante levitación magnética. El tren circula sobre una viga situada sobre pilares a varios metros de altura sobre el suelo. La vía está constituida por un caballete de hormigón que incorpora un sistema de levitación magnética que eleva el tren a 15mm, de forma que no existe rozamiento. En ambos lados de la vía existen otros electroimanes, cuya función es la de guiar el tren y mantenerlo en la posición correcta.

La velocidad máxima comercial del Transrapid es de 430km/h, con lo cual aventaja a los trenes convencionales de alta velocidad, que alcanzan una velocidad de 320km/h. No obstante, no se obtienen prácticamente ventajas en cuanto a consumo de energía o ruido. Sus principales desventajas son la imposibilidad de utilizar la red ferroviaria existente o de circular a nivel del suelo, la necesidad de túneles de mayor sección, estrictas demandas de gran limpieza de la vía y, además, la lentitud de operación de los cambios de vía (entre 1 minuto y 30 segundos contra 5 segundos o menos en el ferrocarril convencional). A lo largo de los 37 años de experimentación del Transrapid, según cifras de la Unión Internacional de Ferrocarriles (UIC), se han inaugurado 9400km de líneas de alta velocidad con el sistema convencial rueda-carril y otros 8295km están en construcción.






































luego del abandono del proyecto de Múnich.




Después de 37 años de pruebas y experimentos, los 31 km del tramo entre el aeropuerto de Shanghai y Pudong constituyen el único maglev de alta velocidad en servicio en el mundo. Puesto en servicio el 31 de diciembre de 2002, es una operación antieconómica y que no llega al centro de la ciudad. Ha sido definido por varios medios como un caro transporte para turistas.

Según un artículo de la "Deutsche Welle" titulado "La muerte de un dinosaurio técnico": "Incluso en países donde, debido a que es necesario salvar grandes distancias, podría tener sentido, nadie se interesa por él. Por ello, más allá de las lágrimas de cocodrilo de muchos políticos, el antiguo proyecto modelo de la ingeniería alemana se había transformado desde hace tiempo en un lastre político." 

"Unos 1.000 millones de euros en subvenciones ha costado ya. Pero en funcionamiento comercial se halla solamente en China, donde une el aeropuerto con el centro de Shanghái, una distancia de poco menos de 40 km. Sin embargo, tampoco allí es el éxito técnico en que un puñado de “fans” quiere creer."
"Lo demuestra el hecho de que surgieron rumores en Alemania de que Siemens y Thyssen-Krupp, que han desarrollado juntos la tecnología, estarían dispuestos a vender los derechos de ésta e incluso las patentes enteras, de inmediato desde China llegaron noticias de que no existía interés por comprarlos. La tecnología es demasiado cara, se argumentó. Exactamente ésa es la cuestión."

"Para Beckstein, el fin del tramo de Múnich significa en definitiva el entierro de todos los sueños de construir un tren de levitación magnética que opere en condiciones comerciales en Alemania. “El proyecto de Múnich era la última oportunidad. Pero igual hay que seguir impulsando la técnica. Al fin y al cabo hay interesados en China, los EE. UU. y el área árabe”, agregó en tono de consuelo."

"No puede descartarse, sin embargo, que esos interesados existan más en la imaginación de los políticos que en la realidad. El Transrapid «es el invento más hermoso desde que existen las subvenciones estatales”, se lee hoy en la prensa alemana. Efectivamente, desde que el tren convencional alemán ICE alcanzara una velocidad de 330 km/h y el TGV francés incluso de 360 km/h, no queda muy claro que puede tener la cara técnica de levitación magnética, que puede llegar a un máximo de unos 400 km/h de velocidad operativa».



</doc>
<doc id="21968" url="https://es.wikipedia.org/wiki?curid=21968" title="Salasaca">
Salasaca

Sala-saca es una parroquia en el cantón de Pelileo, provincia de Tungurahua (provincia), Ecuador. La gente que vive allí es mayormente del pueblo indígena quichua.

La gente principalmente trabaja la tierra para producir comida para su propio consumo. Los cultivos más importantes son la papa y el maíz. 

Ubicación

El pueblo quichua Salasaca, se encuentra ubicado en la provincia de Tungurahua, en el centro de los Andes del Ecuador. Su población es de aproximadamente 12,000 habitantes, hablan el idioma Kichwa. Están organizados en ayllus, integrado por el padre, madre y sus hijos y los hijos políticos. Los hijos desde muy temprana edad son miembros activos en las tareas de producción familiar. 

Tradición

Los kichwas Salasacas subsisten de la producción agrícola, ganadera y artesanal. Una de las expresiones culturales que identifica a los Salasacas es el tejido de tapices y ponchos 
de diferentes motivos y diseños elaborados en telares manuales, los cuales relatan sus vivencias. La actividad agrícola es para su autoconsumo y se la realiza en dos pisos ecológicos, el alto y bajo. 
El centro social para los Salasacas en la actualidad es la plaza central, allí se localizan la Casa Comunal, la Escuela, el Colegio, el Subcentro de Salud Pública, el Mercado Artesanal y algunos almacenes artesanales, entre otros. 

Sin embargo, el centro histórico de los Salasacas era la comunidad de Chilcapamba. El cambio entre estos dos centros ha sido gradual probablemente a efecto de la construcción de la carretera entre Ambato y Baños en 1934 y como evidencia de que el centro de Salasaca había cambiado el 11 de junio de 1989 se celebró en el actual centro por vez primera la fiesta de la Octava Grande (Jatun Utava), festividad que se realizaba en Chilcapamba. 

Están organizados por comunas y son 21, las cuales pertenecen al Consejo de Gobierno del Pueblo Salasaca, esta a su vez pertenece al MIT (Movimiento Indígena de Tungurahua) y por ende a la ECUARUNARI-CONAIE, los trabajos se los realiza en minga y las decisiones se toman democráticamente en las Asambleas convocadas por la organización.




</doc>
<doc id="21969" url="https://es.wikipedia.org/wiki?curid=21969" title="Copa Davis">
Copa Davis

La Copa Davis es una competición internacional de tenis, organizada por la Federación Internacional de Tenis (ITF). A diferencia de la mayoría de los torneos de tenis internacionales, en la Copa Davis no participan jugadores a título individual, sino equipos nacionales compuestos por diversos jugadores designados por su federación nacional deportiva. La Copa Davis, disputada desde 1900, es un torneo masculino realizado anualmente, siendo la Copa Fed su equivalente para tenistas femeninas.

Es el mayor torneo deportivo anual, contando con 130 equipos nacionales diferentes durante su edición de 2016. El país con más títulos es Estados Unidos con treinta y dos. El actual campeón es Francia, que consiguió su décimo título tras derrotar a Bélgica en la ciudad de Villeneuve-d'Ascq.

La Copa Davis lleva el nombre de su creador, Dwight Filley Davis, tenista y político estadounidense nacido el 5 de julio de 1879. Junto a Holcombe Ward ganó el campeonato nacional de los Estados Unidos de América en modalidad de dobles durante tres años consecutivos, de 1899 a 1901. En ese periodo, Davis concibió la idea de crear una competición por equipos nacionales en la que se enfrentaran los mejores estadounidenses contra un equipo de las Islas Británicas. El primer encuentro se preparó en 1900 en el Longwood Cricket Club de Brookline, en las afueras de Boston, venciendo los estadounidenses a los británicos por 3-0. Davis, que jugó con el equipo de Estados Unidos, donó el dinero necesario para la elaboración de una copa de plata, según un diseño de Rowlan Rhodes basado en una ponchera rematada con adornos de flores de 33 cm de alto y 43 cm de diámetro. En el interior de esta mal llamada ensaladera se grabó el nombre del torneo: "International Lawn Tennis Challenge Trophy", y en su lateral quedaron anotados los nombres de los participantes. La competición tuvo una continuidad insospechada y a partir de 1945, año en que murió Davis (28 de noviembre), pasó a llamarse Copa Davis.

La costumbre de grabar en la Copa los nombres de los finalistas y vencedores y el hecho de que no se entregara en propiedad, hizo que pronto faltase sitio para nuevas anotaciones. En 1921, Davis donó una bandeja de plata de 95 cm de diámetro como base de la ponchera, en la que se grabaron las finales de 1921 a 1933. Cuando ésta se llenó, se construyó una peana de madera con placas en las que continuó la inscripción de 34 ediciones más. En 1969 fue necesario añadir una segunda peana, más ancha, que disponía de espacio hasta 2002, año en que se agregó una tercera.

Los países compiten teniendo en cuenta su calidad tenística y su ubicación geográfica.

Cada ronda consta de cinco partidos, proclamándose vencedor aquél que obtenga tres victorias. Los primeros dos encuentros son de individuales, el tercero es de dobles y en los últimos dos partidos los jugadores individuales jugarán nuevamente pero cruzándose. No hay restricción a quién debe jugar el partido de dobles: los dos jugadores de individuales, otros dos jugadores (generalmente especialistas de dobles) o alguna combinación.

Se sortea exclusivamente el orden de partidos del primer día, en el que juegan el nº 1 de un país contra el nº 2 del contrario y viceversa. El segundo día se juegan los dobles y el tercer día juegan primero los dos números 1, y el último partido lo juegan los dos número 2.

Los partidos son siempre al que gane 3 sets, con un máximo de 5 sets jugados, con tie-break en los cinco sets (hasta el 2015 el 5° set se jugaba sin tie break). En caso de que la eliminatoria quede decidida antes de disputarse todos los partidos, los partidos restantes se juegan al que gane 2 sets.


Desde este año el campeón vigente no accede directamente a la final del año siguiente que alberga en su casa.

Fecha de actualización: 26 de noviembre de 2017



<onlyinclude>
</onlyinclude>


</doc>
<doc id="21980" url="https://es.wikipedia.org/wiki?curid=21980" title="InterCityExpress">
InterCityExpress

InterCityExpress, normalmente abreviado como ICE, designa al sistema de trenes de alta velocidad de los ferrocarriles de Alemania que circulan por dicho país y por países vecinos.

El InterCityExpress es el tren más rápido y cómodo de la Deutsche Bahn AG y es considerado como el «buque insignia» de la empresa y sucesor del InterCity (IC). El IC sirvió aproximadamente a unas 180 estaciones que en gran medida usa actualmente el ICE en Alemania y seis países vecinos (Austria, Suiza, Francia, Bélgica, Países Bajos y Dinamarca).
El nombre de marca «ICE» es una de las marcas más conocidas de Alemania, con un conocimiento de la marca cercana al 100%, según el DB.

El nombre «ICE» también se utiliza para los vehículos utilizados en el sistema, que fueron desarrollados específicamente para el sistema a partir de comienzos del decenio de 1980. 

En la actualidad hay 259 trenes en cinco versiones diferentes de los vehículos ICE en circulación, llamados ICE 1 (lanzados en 1991), ICE 2 (1996), ICE-T (1999), el ICE 3 (1999) y el ICE-TD (2001-2003, nuevamente en servicio desde 2007). El ICE 3, incluyendo su variante de los modelos, se fabrica tanto por Bombardier como Siemens.

Estos trenes fueron desarrollados a partir del año 1985 por Siemens AG según las indicaciones de los Ferrocarriles Federales Alemanes (Deutsche Bundesbahn o DB). La primera generación, conocida como "ICE 1", alcanza una velocidad máxima de 280 km/h. Los trenes están formados por dos unidades motrices, una en cada extremo, y entre 10 y 14 remolques. La capacidad de los convoyes con 12 remolques es de 645 pasajeros. Los ferrocarriles alemanes utilizan en la actualidad 59 trenes de este tipo.

Posteriormente se desarrolló una variante del primer tren, denominada "ICE 2". La diferencia con el primer tipo consiste en que los convoyes pueden ser divididos en dos mitades iguales, para aquellos trayectos en los que interesa disponer a partir de una determinada ciudad trenes con menor capacidad que se dirigen a dos destinos diferentes. Ello se consigue dotando a los convoyes completos, que disponen de una unidad motriz en cada extremo al igual que los ICE 1, de dos remolques con puesto de conducción situados en la mitad del tren. De esta forma, al dividir el tren en dos, cada una de las dos mitades dispone de una unidad motriz y un remolque con puesto de conducción en el extremo opuesto, lo que le permite circular en ambos sentidos. Estos trenes fueron puestos en servicio en 1997. Los ferrocarriles alemanes cuentan con 44 unidades.

Desde 2000 están circulando los "ICE 3", la versión más moderna y más rápida de estos trenes, que alcanza una velocidad de 330 km/h. Este tren es capaz de subir pendientes de un cuatro por mil sin merma de velocidad. Contrariamente a los modelos anteriores, el ICE 3 no dispone de unidades motrices, sino que el equipo de tracción se distribuye a lo largo del convoy, alimentando los motores en cada uno de los ejes, así que cada coche contribuye a la aceleración del tren. Esa configuración también permite que los compartimentos de los pasajeros lleguen hasta el lugar donde se encuentra el maquinista, ofreciendo la visión hacia la vía a través del cristal que separa los pasajeros del puesto de conducción. Los ferrocarriles alemanes utilizan actualmente 37 trenes de este tipo, y se encuentran en producción otros 13, que son fabricados por el consorcio Siemens AG y Bombardier Transportation.

El diseño fue realizado por el diseñador industrial alemán Alexander Neumeister.

El accidente de Eschede (Alemania)
El 3 de junio de 1998, un tren Intercity Express (ICE) descarriló a 200 km por hora, dejando un total de 101 muertos y otro centenar de heridos. El accidente se produjo en el pueblo de Eschede, situado en el estado federado de Baja Sajonia, cuando el tren ICE que circulaba entre Múnich y Hamburgo-Altona descarriló y chocó contra el pilar de un puente. La investigación posterior determinó que el fallo se produjo en una de las ruedas de un remolque, que colapsó por fatiga de material. 

Se utilizaron ruedas elásticas formadas por tres partes: un anillo exterior de acero (bandaje), separado por una capa de goma del cuerpo de la rueda. Esta construcción sirve para evitar vibraciones. Con el tiempo se producen fisuras en el metal, que son difíciles de detectar. A pesar de conocer los problemas relacionados con esta construcción de rueda, la Deutsche Bahn no tenía implementado un sistema fiable de detectar las fisuras.

Tres minutos antes del accidente, la rueda perdió su anillo exterior que se incrustó en el suelo del remolque, atravesándolo –lo cual fue advertido por un pasajero-. Este hecho provocó, unos 5 km más adelante, que la rueda enganchara un contracarril de un desvío y lo arrancara en toda su longitud, atravesando todo el remolque e insertándose en el remolque inmediatamente posterior. Simultáneamente, la rueda rota cambió la posición del desvío, que se encontraba unos metros antes de un puente de hormigón. Los tres primeros remolques y la cabeza tractora rebasaron el puente, pero el cuarto remolque tomó el desvío que había cambiado la rueda rota del segundo remolque y se desvió del raíl original ocasionando el descarrilamiento de éste y los siguientes remolques. El remolque chocó contra el pilar del puente a tal velocidad que causó su derribo. Los remolques siguientes fueron chocando en zig zag contra el primero.

Después del accidente se reemplazaron las ruedas elásticas con bandaje por ruedas normales monobloc en los trenes ICE. Para compensar las vibraciones de este tipo de ruedas se incorporaron a todos los bogies suspensión neumática.




</doc>
<doc id="21988" url="https://es.wikipedia.org/wiki?curid=21988" title="Shinkansen">
Shinkansen

El Shinkansen ( "nueva línea troncal") es la red ferroviaria de alta velocidad de Japón, operada inicialmente por la compañía Japanese National Railways JNR. Desde que en 1964 se abrió la línea Tōkaidō Shinkansen la red se ha ido expandiendo para conectar la mayor parte de las ciudades de las islas de Honshū y Kyūshū, con una longitud de 3.050 km (incluyendo Mini-Shinkansen) y unas velocidades de hasta 320 km/h.

La palabra "Shinkansen" significa literalmente "Nueva Línea Troncal" y se refiere estrictamente al trazado de las vías, mientras que los trenes propiamente dichos se denominan oficialmente "Super Expresos" (超特急, "chō-tokkyū"), aunque esta distinción es rara incluso en el propio Japón. Inicialmente se llamaron "Súper Expreso de los Sueños" ("Yume no chō-tokkyū"). Al contrario de la red original, el Shinkansen utiliza el ancho de vía estándar (1.435 mm) y se vale de túneles y viaductos para atravesar obstáculos, en vez de rodearlos.

Debido a los problemas inherentes a la contaminación acústica, el aumento de la velocidad máxima está siendo cada vez más difícil, particularmente por el "efecto pistón" que aparece cuando los trenes entran en túneles a una velocidad elevada. A pesar de esto en 2015 se aumentó la velocidad de la Tōkaidō Shinkansen hasta los 285 km/h gracias a los trenes N700A, y hay otro aumento programado para 2020, hasta los 360 km/h, usando los trenes E5 y los futuros H5 en parte de la Tōhoku Shinkansen.
Las últimas inauguraciones fueron las del tramo Nagano-Kanazawa en 2015 y el primer tramo de la Hokkaidō Shinkansen, desde Aomori hasta Hakodate (en 2016) a través del Túnel Seikan. También se está trabajando para extender la red: la Hokkaidō Shinkansen desde Hakodate hasta Sapporo en 2031, el ramal de la línea Kyūshū Shinkansen hasta Nagasaki en 2023, y completar la conexión entre Kanazawa y Osaka cuyo primer tramo, hasta Tsuruga, estará finalizado en 2023.

El proyecto de la línea Narita Shinkansen para conectar Tokio con el Aeropuerto Internacional de Narita, iniciado en la década de 1970 pero interrumpido en 1983 después de protestas de los propietarios de los terrenos, fue oficialmente cancelado y eliminado del Plan Básico que delineaba la construcción del Shinkansen.

Las líneas Shinkansen son:


Con posterioridad se añadieron otras dos líneas, conocidas como Mini-Shinkansen (ミニ新幹線), al actualizar y cambiar al ancho estándar (1.435 mm) secciones de línea existentes (Zairaisen) con ancho de 1.067 mm que mantienen el mismo gálibo para el material rodante, de ahí que los trenes deban ser más estrechos que los otros Shinkansen y por eso el apodo de "mini":


Existen una línea con ancho de vía estándar (1.435 mm) que no está técnicamente clasificada como línea Shinkansen, aunque cuenta con servicios Shinkansen durante la temporada de esquí. Se trata de la línea Gala-Yuzawa, técnicamente un ramal del Jōetsu Shinkansen.

Muchas de las líneas Shinkansen fueron propuestas durante el "boom" del inicio de los 70, aunque aún tienen que ser construidas. Se denominan Seibi Shinkansen (整備新幹線) o "Shinkansen Planeado". Una de esas líneas, la Narita Shinkansen hasta el Aeropuerto de Narita, fue cancelada oficialmente, aunque otras tantas continúan en proyecto.


Los primeros trenes Shinkansen comenzaron a circular el 1 de octubre de 1964 a una velocidad máxima de 210 km/h entre Tokio y Shin-Osaka, y tuvieron que pasar 22 años, hasta noviembre de 1986, para que aumentasen su velocidad hasta los 220 km/h. Los siguientes pasos fueron alcanzar los 240 km/h en la Tōhoku Shinkansen en marzo de 1985, y los 275 km/h en el Jōetsu Shinkansen en marzo de 1990. Los 300 km/h fueron alcanzados por la Serie 500 en la Sanyō Shinkansen en marzo de 1997, llegando a unir Osaka y Hakata a 242 km/h de media en 2003, más rápido que ahora. Finalmente se alcanzaron los 320 km/h gracias a la Serie E5 en el Tōhoku Shinkansen el 16 de marzo de 2013. En esta misma línea, y con esos mismos trenes (y los futuros H5), está previsto alcanzar los 360 km/h en el año 2020.

Por otra parte la primera línea, la Tōkaidō Shinkansen, tenía limitada su velocidad máxima a 270 km/h desde 1992 debido al reducido radio de sus curvas (solo 2.500 metros). Sin embargo, desde marzo de 2015 los trenes N700A alcanzan los 285 km/h gracias a su sistema de basculación pasiva que, además, permite pasar esas curvas a 270 km/h en vez de a 250.

Igualmente las velocidades medias fueron aumentando extraordinariamente a lo largo de los años. El trayecto Tokio-Osaka comenzó en los 129 km/h en 1964 para llegar hasta los 218 km/h desde 2015. La línea con mayor velocidad media es la Sanyo, con 234 km/h entre Osaka y Hakata, aunque el trayecto más rápido es el Hiroshima-Okayama, a 241,7. Por contra, las líneas con menor velocidad media son, aparte de las Mini-Shinkansen, son el Jōetsu Shinkansen y el Hokuriku Shinkansen con, respectivamente, 186 y 184 km/h desde Tokio. La nueva Hokkaidō Shinkansen alcanza los 204 km/h desde Tokio hasta Hakodate, y el Kyushu Shinkansen tiene una velocidad media de 198 km/h entre Hakata y Kagoshima.

Los trenes Shinkansen tienen formaciones de hasta 16 coches. Como cada coche puede medir hasta 25 m de largo, los trenes más largos llegan a los 405 m de longitud total, que es el largo máximo para el que se han diseñado los andenes; esta medida es similar a la utilizada en los trenes rápidos europeos. Sin embargo, el gálibo utilizado en las vías de alta velocidad permite trenes de hasta 3,38 m de ancho, que es mayor que el utilizado en Europa, lo que permite el uso de configuraciones de asientos de mayor capacidad (por ejemplo, 2+2 en primera clase y hasta 3+3 en clase turista).

Los trenes Mini-Shinkansen están diseñados para circular por las líneas de alta velocidad, y luego continuar por vías antiguas de ancho 1.067 mm cuyo ancho de vía ha sido modificado para permitir la continuidad del servicio. Sin embargo, estas líneas no han visto modificado su gálibo, y por ello estos trenes son más estrechos en su construcción (2,945 m). Al detenerse en las estaciones de líneas nuevas (diseñadas para trenes más anchos), deben utilizar unas plataformas retráctiles que facilitan el acceso hasta el andén.





Actualizada al 31 de marzo de 2016
N700A en Tokaido: 323

N700 de 8 coches en Sanyo: 271

E5: 177 en Tohoku y 78 en Joetsu

E7/W7 en Hokuriku: 118 (incluye Tsurugi)

800 en Kyushu: 125

Fuente: IHRA

Los ferrocarriles que usan la tecnología Shinkansen no se limitan únicamente a los que existen en Japón.

Taiwan High Speed Rail tiene en circulación desde 2007 30 trenes para 300 km/h Serie 700T, construidos por la Kawasaki Heavy Industries. China tiene en circulación desde 2007 60 trenes para 250 km/h basados en el diseño de la Serie E2, 3 de ellos construidos en Japón por un consorcio formado por la Kawasaki Heavy Industries, la Mitsubishi Electric Corporation y la Hitachi. Para la línea HS1 de conexión de Londres al Eurotúnel, se exportaron trenes construidos por Hitachi, basados en el A Train, para su uso como regionales de alta velocidad bajo el nombre de Javelin, class 395. La misma compañía entregará entre 2017 y 2019 trenes eléctricos y duales, class 800 y 801.

La red Shinkansen ha sido (hasta 2012, cuando fue superada por la china) la red de alta velocidad más transitada del mundo. Poco antes del cincuentenario de su inauguración alcanzó la cifra de diez mil millones de viajeros transportados, mientras que Francia alcanzó los dos mil en 2013, después de 32 años.

Número de viajeros (en millones):
Miles de millones de viajeros-km (mucho más preciso, ya que también tiene en cuenta los km recorridos):
(1) Hay viajeros que son contados dos veces al viajar por distintas líneas; así, el total es menor que la suma de las líneas.

Fuentes: 1964/1993 1964/2008 1968/1989 
1964/2011 
2007/2012 y anuarios de las compañías. JR East 2012 y Kyushu 2011 y 2012

A pesar de que originalmente se había pensado hacer circular trenes de pasajeros y mercancías día y noche, lo cierto es que en las líneas Shinkansen sólo circulan trenes de pasajeros. El sistema cierra entre las 0:00 y las 6:00 todos los días para efectuar operaciones de mantenimiento. Los trenes nocturnos que aún circulan en Japón lo hacen en la red de ancho métrico japonés (1.067 mm).

Servicios Shinkansen en marzo de 2015
Nota: las paradas incluyen origen y destino, así que para dos trayectos hay que quitar una.





</doc>
<doc id="21991" url="https://es.wikipedia.org/wiki?curid=21991" title="HMS Bounty">
HMS Bounty

El HMS "Bounty, también denominado HMAV "Bounty, fue un barco de vela de la armada británica en el que tuvo lugar el 28 de abril de 1789 un famoso motín, el motín del Bounty. 

El barco fue construido inicialmente como buque mercante bajo el nombre de "Bethia", aunque más tarde, tras su adquisición por la Royal Navy, fue sometido a importantes reformas para realizar una expedición al mar del Sur transportando una carga de árboles del pan desde Tahití, en la Polinesia, hasta el Caribe, que pudiera servir para alimentar a los esclavos de las plantaciones de Jamaica y de otras colonias británicas de las Antillas que sufrían por entonces de periódicas hambrunas. La utilidad de la planta ya había sido advertida en 1769, por el capitán James Cook que comprobó que además de ser bastante común en aquellas islas servía de alimento a los polinesios. Cuando estas noticias se difundieron tras la muerte del famoso navegante y explorador, algunos plantadores antillanos plantearon al Presidente de la Royal Society, el naturalista "sir" Joseph Banks, la posibilidad de transportarla al Caribe para comprobar si era posible su plantación extensiva. El propio Banks fue quien, una vez aceptada esa iniciativa, que sería patrocinada por la armada real, intercedió ante los responsables del Almirantazgo para que fuese designado para dirigir la expedición el teniente William Bligh, de 33 años de edad, con el que había compartido uno de los viajes de exploración de James Cook por el Pacífico unos años antes. 

Al mando de una tripulación de 44 hombres, Bligh zarpó el 23 de diciembre de 1787 del estuario del Támesis. Las órdenes que tenía eran llegar a las islas de La Sociedad, actual Polinesia francesa, por el sur de América atravesando el cabo de Hornos. Sin embargo, temporales desusados y persistentes vientos contrarios le impidieron atravesar hasta el Pacífico, por lo que tuvo que volver al Atlántico para arribar a la Polinesia vía el cabo de Buena Esperanza y el océano Índico. Tras diez meses de navegación, el Bounty llegó finalmente a Tahití, fondeando en la bahía de Matavai el 25 de octubre de 1788. 
Debido al retraso sufrido, Bligh hubo de permanecer cinco meses en la isla aguardando a la estación propicia para trasplantar los brotes del árbol, espera que lejos de ser tediosa les permitió disfrutar de los encantos naturales de la paradisíaca isla y de las atenciones de los hospitalarios tahitianos, especialmente de las del género femenino. 

Una vez llevados a bordo 1051 plantones, el 4 de abril de 1789 el Bounty se hizo de nuevo a la vela rumbo al Caribe. Cierto día, cuando se encontraban entre las islas de Tofoa y Kotoo, Bligh advirtió que faltaban algunas nueces de coco. Acusó a la tripulación de haberlas robado e insultó gravemente al oficial adjunto al segundo, llamado Fletcher Christian, al que públicamente tildó de "perro maldito". El comandante ordenó que se redujeran las raciones de grog y amenazó con echar al mar a quienes fueran sorprendidos en algún robo. Su actitud violenta exasperó los ánimos de los marineros y sobre todo provocó la rabia de Christian al verse tratado tan ofensiva e injustamente. A tenor de las posteriores declaraciones de los testigos ante la corte marcial parece que el motín no fue premeditado sino que se concertó a última hora, tal vez esa misma madrugada. Presa de una fuerte agitación (algún testigo dijo haberlo visto llorar aquella noche en la proa del barco) Christian parecía decidido en un primer momento a abandonar el navío, pero luego cambió de opinión y decidió tomar medidas más drásticas, aprovechando que por una casualidad fatal su cuarto de guardia coincidía con el servicio de varios tripulantes a quienes el irascible Bligh había castigado repetidas veces y que debían de tener motivos también para vengarse de su comandante. 

Pasadas las cinco de la mañana del 28 de abril, según las declaraciones tomadas por los jueces militares, los conjurados aparecieron en el puente armados con fusiles y bayonetas y pese a ser unos pocos, se apoderaron del buque con rapidez sin hallar prácticamente ninguna oposición. Tras amenazar al comandante con matarlo si se resistía, lo embarcaron en la chalupa junto a otros 18 tripulantes, un sextante, algunos barriles de agua y algo de comida. Otros 13 marineros que rehusaron unirse a los amotinados tuvieron que permanecer en el navío por falta de espacio en el bote.
A las 8 de la mañana la chalupa se apartó del Bounty y Bligh y su compañeros quedaron abandonados a su suerte en las proximidades de la isla de Tafoa, muy lejos de cualquier enclave o puerto europeo. El viaje que realizó a continuación en aquella frágil embarcación de 7,5 metros de eslora hasta Malasia constituye una verdadera hazaña náutica, teniendo en cuenta que se trataba de un pequeño bote sin cubierta y carente por tanto de protección contra el sol, la lluvia y las olas. Carecían de cartas náuticas adecuadas e iba sobrecargado de peso disponiendo de menguados recursos de agua y comida. Pese a ello y valiéndose de sus indudables conocimientos técnicos, Bligh consiguió llegar al puerto holandés de la isla de Timor en Las Molucas, tras 41 días de singladura. Había recorrido unos 5.800 km en mar abierto y pese a ello solo hubo que lamentar la pérdida de un hombre, muerto en un enfrentamiento con los nativos en el curso de una de las recaladas para aprovisionarse de agua y víveres, si bien varios más fallecieron en las semanas siguientes a su arribada a Timor debido a las penalidades sufridas en su larga odisea. Cuando Bligh llegó a Inglaterra, hubo de someterse a una corte marcial por la pérdida del navío, pero el juicio se saldó con su libre absolución. La Armada despachó a la fragata HMS Pandora al mando del capitán Edward Edwards con la misión de traer a Inglaterra al resto de la tripulación y esclarecer su participación en los hechos. 

A bordo del Bounty habían quedado 25 hombres en total, de los que realmente estaban implicados en el motín Christian y ocho o nueve marineros. Tras echar por la borda las macetas con las plantas, decidieron volver a Tahití. Allí desembarcaron a 16 hombres, a la espera de que un barco inglés los llevase de retorno a la patria. Los amotinados se hicieron después a la vela llevando consigo a 17 nativos, seis hombres y once mujeres, una de ellas con un bebé. Tras varios días de navegación, avistaron la isla de Pitcairn, situada a unas 1.300 millas al Sureste del archipiélago de Tahití, que por aquel entonces figuraba cartografiada en una posición errónea, lo que la convertía en un refugio idóneo al no ser localizable por los barcos de la Royal Navy que con toda seguridad serían enviados en su búsqueda. El 23 de enero de 1790, una vez trasladados los enseres de a bordo y desmantelado una parte del casco quemaron el resto para borrar toda huella del navío. Con las maderas y herramientas construyeron varias cabañas que también camuflaron convenientemente para no ser vistas desde el mar.

De los 10 prisioneros sobrevivientes al naufragio del HMS Pandora, cuatro contaron con el testimonio favorable de Bligh y fueron absueltos; otros dos fueron condenados pero posteriormente recibieron el indulto real; uno más fue condenado, pero exculpado por un tecnicismo legal. Los tres restantes fueron condenados y ejecutados en la horca. 

Sobre las incidencias de aquel memorable viaje, Bligh publicó en 1790 una narración, lógicamente en sentido exculpatorio, titulada en el estilo de la época "Relación de los sucesos ocurridos en el navío el Bounty, perteneciente al rey de Inglaterra y mandado por el teniente W. Bligh, con el viaje subsiguiente de este oficial y de una parte de su tripulación en la chalupa desde las islas de La Amistad en el mar del Sur hasta Timor, establecimiento holandés de las islas Molucas".

Se han hecho versiones literarias y cinematográficas sobre el motín del "Bounty"; entre ellas:






</doc>
<doc id="21998" url="https://es.wikipedia.org/wiki?curid=21998" title="Historia de América del Norte">
Historia de América del Norte

La Historia de Norteamérica es rica en cuanto a sus diversas culturas y civilizaciones, desde esquimales en el extremo norte del continente, hasta las civilizaciones azteca, olmeca y maya al sur.

La prehistoria de Groenlandia es la historia repetida de inmigraciones inuit desde las tierras de América del Norte. Según las sagas nórdicas, Groenlandia es descubierta hacia el año 900 por el navegante noruego Gunnbjörn. Durante la década de 980, los vikingos asentados en Islandia fueron los primeros visitantes europeos de Groenlandia, explorando la deshabitada costa sudoccidental de la isla. En 1536, Dinamarca y Noruega se unieron oficialmente, y Groenlandia empezó a ser considerada más una dependencia danesa que noruega. Actualmente, el gobierno local groenlandés se presenta como una "nación inuit". Los nombres de lugares en danés han sido remplazados por nombres locales. Godthåb, el centro de la civilización danesa en la isla, ahora se llama Nuuk, la capital de un gobierno prácticamente soberano. En 1985 se estableció la bandera de Groenlandia, a partir de los colores de la bandera de Dinamarca. Sin embargo, el movimiento en busca de una soberanía total todavía no ha ganado consenso.

Los primeros habitantes de la región fueron diversos pueblos provenientes de Siberia, que llegaron a través del Estrecho de Bering, y un poco más tarde llegaron los últimos pueblos inuit (esquimales) provenientes de Asia (ver amerindios de Canadá). En el siglo XVIII, estalló un conflicto entre Francia y Gran Bretaña que se propagó a las colonias; ese conflicto terminó con una victoria británica. En 1763, con el Tratado de París, la Nueva Francia pasó a ser una colonia británica. Pocos años después, Gran Bretaña oficialmente reconoció el derecho civil francés y garantizó la libertad religiosa y lingüística de la población de habla francesa de Canadá. En 1982, tuvo lugar una importante reforma constitucional: la Ley de América del Norte británica de 1867 y sus numerosas enmiendas pasaron a ser la Ley constitucional de 1982, actual Constitución de Canadá. Estos últimos años, los quebequenses se han pronunciado sobre la cuestión de la unidad nacional. Dos veces, una en 1980 y otra en 1995, votaron en referendos sobre la soberanía de la provincia. La mayoría obtenida en las votaciones estuvo a favor de la continuación de Quebec en Canadá.


Se atribuye el descubrimiento a Juan Bermúdez, de Palos de la Frontera, Huelva, España, posiblemente en 1503. Regresó en 1515, no intentaron atracar a causa del mal tiempo.

El primer asentamiento se produjo en 1609 por colonos ingleses que se dirigían a Virginia. Durante una tormenta, el barco llamado "Sea Venture" se separó del resto de la flota y chocó con los arrecifes, toda la tripulación se salvó, después construyeron dos barcos y el capitán se dirigió a Virginia nuevamente. Inglaterra se interesó en el archipiélago y en 1612 envió un contingente de 60 colonos.

Las islas fueron arrendadas a los Estados Unidos como base militar en 1941 por 99 años. En 1995 las bases estadounidenses fueron clausuradas y en 2002 devolvieron las tierras de sus bases.

Las Bermudas están bajo supervisión del Comité de Descolonización de las Naciones Unidas.

México prehispánico es un período de la historia del país anterior a la conquista y colonización española a partir de 1521. Es necesario aclarar que México es un Estado moderno cuyas fronteras fueron fijadas a mediados del siglo XIX. Por lo tanto, la historia mexicana de la época prehispánica es la historia de los pueblos que vivieron en ese territorio, no la historia del estado mexicano en la época precolombina.

La historia prehispánica de México comienza con la llegada de sus primeros pobladores. Sobre el poblamiento de América se han propuesto numerosas hipótesis, pero la que cuenta con mayor aceptación y evidencia de apoyo señala que los humanos entraron al continente a través de Beringia durante la época de las glaciaciones. Esta teoría está demostrada por estudios recientes de ADN basados en los haplogrupos del cromosoma Y (ADN-Y) y los haplogrupos del ADN mitocondrial (ADNmt). La época en que esto ocurrió es motivo de debate entre quienes defienden la teoría del poblamiento temprano y la del poblamiento tardío. En el caso de México, algunos autores han querido ver evidencia que apoya la primera, como los hallazgos de El Cedral (San Luis Potosí), a los que se atribuye una antigüedad de 33 mil años


</doc>
<doc id="22004" url="https://es.wikipedia.org/wiki?curid=22004" title="Magnitud (matemática)">
Magnitud (matemática)

La magnitud es una medida asignada a cada uno de los objetos de un conjunto medible, formados por objetos matemáticos. La noción de magnitud concebida así puede abstraerse a objetos del mundo físico o propiedades físicas que son susceptibles de ser medidos.

Las medidas de propiedades físicas usualmente son representables mediante números reales o "n"-tuplas de números reales, y usualmente para ser interpretables requieren del uso de una unidad de medida pertinente. Una propiedad importante de muchas magnitudes es admitan grados de comparación "más que", "igual que" o "menos que".

Una magnitud matemática usada para representar un proceso físico es el resultado de una medición; en cambio las magnitudes matemáticas admiten definiciones abstractas, mientras que las magnitudes físicas se miden con instrumentos apropiados.

Los griegos distinguían entre varios tipos de magnitudes, incluyendo:

Probaron que los dos primeros tipos no podían ser iguales, o siquiera sistemas isomorfos de magnitud. No consideraron que las magnitudes negativas fueran significativas, y el concepto se utilizó principalmente en contextos en los que cero era el valor más bajo.

La noción abstracta de magnitud implica la existencia de una función real que asignar a una colección de "objetos medibles" formula_1 un valor numérico real, ya que los números reales son un cuerpo totalmente ordenado con operaciones compatibles con dicha ordenación. Es decir, para cada magnitud "M" existe una función:

En las medidas usadas asociadas a conceptos métricos, los objetos medibles son subconjuntos de un espacio métrico o alternativamente un espacio de medida, no siendo en general cualquier subconjunto de dicho espacio (se requieren ciertas condiciones de regularidad para que la magnitud de un objeto esté bien definda). amando tanto a los coreanos

La magnitud de cualquier número "x" se denomina usualmente su "valor absoluto" o "módulo", indicado por |"x"|. 

El valor absoluto de un número real "r" se define como:
Se puede considerar como la distancia numérica entre el cero y la recta numérica real. Por ejemplo, el valor absoluto tanto de 7 como de -7 es 7. En este caso el conjunto de objetos medibles en la función es formula_2 y la magnitud asociada al valor absoluto es la función: formula_3 dada por formula_4

Un número complejo "z" puede visualizarse como la posición del punto "P" en un espacio euclídeo bidimensional, llamado plano complejo.

El valor absoluto de "z" puede considerarse como la distancia desde el origen de tal espacio hasta "P". La fórmula para el valor absoluto de z es similar a la de la norma euclidea del espacio bidimensional: 

donde ℜ("z") y ℑ("z") son respectivamente la parte real y la parte imaginaria de "z" y "z*" es su complejo conjugado. Por ejemplo, el módulo de −3 + 4"i" es 5. En este caso se tiene formula_5 y formula_6 dada por formula_7.

Dado un espacio métrico formula_8 la distancia es una magnitud definida sobre pares de puntos. Por tanto, el conjunto de objetos medibles son todos los pares de puntos formula_9, es decir, formula_10

Dado un espacio vectorial con producto escalar formula_11, se puede dotar a dicho espacio de una norma vectorial dada por: formula_12 lo que a su vez permite definir el ángulo entre dos vectores mediante la fórmula:
\frac{\mathbf{v}\cdot \mathbf{w}}{\|\mathbf{v}\| \|\mathbf{w}\|} \right) </math>
En este caso el conjunto de objetos medibles viene dado por formula_13 y además se cumplirá que formula_14

En una variedad de Riemann orientable de dimensión "n" > 2 en general podrán definirse longitudes (1-medidas), superficies (2-medidas), volúmenes (3-medidas), etc. En este caso los conjuntos de objetos medibles formula_1 serán subvariedades diferenciables.

En un espacio de medida formula_16 también es posible construir medidas de conjuntos, aunque en general no todo subconjunto del espacio de medida será medible, sino sólo una cierta σ-álgebra. En este caso el conjunto de objetos medibles es precisamente formula_17 y la magnitud asociada a la medida de estos conjuntos viene dada por la función formula_18 definida por formula_19. Existen dos casos interesanes de este tipo de medidas:

En un conjunto finito "F" puede definirse una magnitud sencilla asociada a la "cantidad de objetos" de un subconjunto. En ese caso, el conjunto de objetos medibles es formula_25 el conjunto de partes de "F", y la magnitud asociada se llama número de elementos o cardinal: formula_26 dada por formula_27.

Nótese que la "cantidad de objetos" de hecho es un caso particular de espacio de medida, donde la σ-álgebra coincide con el cojunto de partes del conjunto base usado para construir las medidas.




</doc>
<doc id="22006" url="https://es.wikipedia.org/wiki?curid=22006" title="Diodo Varicap">
Diodo Varicap

El diodo Varicap conocido como diodo de capacidad variable o varactor, es un diodo que aprovecha determinadas técnicas constructivas para comportarse, ante variaciones de la tensión aplicada, como un condensador variable. Polarizado en inversa, este dispositivo electrónico presenta características que son de suma utilidad en circuitos sintonizados (L-C), donde son necesarios los cambios de capacidad.

Cuando un diodo Varicap es polarizado en inversa, la barrera de potencial o juntura que forman los materiales N y P a partir del punto de unión de las junturas se produce una capacitancia. Visto en forma metafórica y práctica, es el equivalente a dos placas de un condensador que van separándose a medida que la tensión de alimentación se incrementa. Este incremento de tensión provoca una disminución de la capacidad equivalente final en los terminales del diodo (a mayor distancia entre placas, menor capacidad final). Por este motivo queda claro el concepto de que la mayor capacidad que puede brindar un diodo de esta naturaleza se encuentra en un punto de baja tensión de alimentación (no cero), mientras que la mínima capacidad final estará determinada por cuánta tensión inversa pueda soportar entre sus terminales. Sin llegar a valores extremos, los más habituales suelen encontrarse entre 3 o 4 picofaradios y 50 picofaradios para ejemplos como el diodo BB148 de NXP. Con una tensión menor a un voltio alcanza su máxima capacidad, llegando al mínimo valor con 12 o 13V, según podemos ver en la gráfica obtenida de su hoja de datos.

Para poder medir la capacidad de estos diodos se puede recurrir a la fórmula de MBR:

formula_1

donde C = capacidad del diodo con polarización inversa (Faradios)

V= voltaje de polarización inversa del diodo (Voltios), (formula_2 es la magnitud del voltaje de polarización inversa del diodo, siempre positiva)

C= C 



</doc>
<doc id="22009" url="https://es.wikipedia.org/wiki?curid=22009" title="El libro de los cuentos perdidos">
El libro de los cuentos perdidos

El libro de los cuentos perdidos es el título de los dos primeros volúmenes, editados por Christopher Tolkien en los años 1983 y 1984, de la serie de doce libros denominada "La historia de la Tierra Media" en la que el autor analiza los manuscritos no publicados de su padre, J. R. R. Tolkien.

Contiene las primeras versiones de las historias comenzadas entre 1916 y 1917, cuando Tolkien padre tenía veinticinco años, y que fueron abandonadas varios años después. Es, en realidad, el principio de toda la concepción de la mitología de la Tierra Media y el primer esbozo de los mitos y leyendas que constituirían "El Silmarillion". Es notable que aunque son muy primitivos en estilo y contenido, son muy cercanos a los trabajos posteriores en muchas formas. Cada uno de los "Cuentos" es seguido por notas y comentarios detallados de Christopher Tolkien. 

El marco narrativo es el largo viaje hacia el oeste que emprende un marinero a Tol Eressëa, la isla solitaria donde habitan los elfos. En las primeras versiones de los "Cuentos perdidos" este hombre es llamado Eriol, originario del norte de Europa. Sin embargo, en las versiones posteriores es conocido como Ælfwine, un inglés de la Edad Media. Allí conoce los cuentos perdidos de Elfinesse, en los que aparecen las ideas y concepciones más tempranas sobre los valar, elfos, enanos, balrogs y orcos, los Silmarili, los Dos Árboles de Valinor, Nargothrond, Gondolin, y la geografía y cosmología de la Tierra Media y de todo Arda.

Este libro nos muestra los primeros esbozos de lo que se convertiría en la base mitológica de la conformación de la «Tierra Media». Los "Cuentos" relatados, al estar acompañados de notas y comentarios, ayudan al lector a entender de mejor forma el proceso creativo de J. R. R. Tolkien.

Aunque muchos nombres en el libro son idénticos o cercanos a los que aparecen en versiones posteriores, algunos de ellos no presentan ningún parecido con sus formas finales. J. R. R. Tolkien modificaba los nombres frecuentemente, muchas veces con nuevas variantes (rechazadas a su vez) escritas en un manuscrito único. Desconcertantemente, algunas veces los nombres utilizados para una cosa posteriormente eran usados para referirse a otra distinta, y el manuscrito original era abandonado. Por ejemplo, la casa de los elfos llamada «teleri» en "El libro de los cuentos perdidos" no es la misma que en "El Silmarillion". Aquí los «teleri» eran los que posteriormente Tolkien llamó vanyar mientras que los solosimpi eran los posteriores teleri.

Existen más cambios visibles dentro del libro y este no es consistente internamente, debido en parte a que mientras Tolkien escribía tranquilamente los relatos comenzaba a reescribir e incluso desechar partes de las ideas tempranas a medida que su mundo imaginario iba cambiando. Los "Cuentos" finalmente fueron abandonados, pero resucitaron como parte del «Esbozo de la mitología» que se convertiría en "El Silmarillion".

Para su publicación este libro fue dividido en dos volúmenes, una simple división editorial. Ambos volúmenes están separados en varios "Cuentos perdidos". 



"The New York Times" admiró la tenacidad de Christopher Tolkien, junto con el poder creativo de su padre, y admitía que «sin duda, los devotos a Tolkien se regocijarán, pero para los lectores no iniciados que no estén completamente familiarizado con las otras obras, los comentarios pueden ser un poco enigmáticos». 



</doc>
<doc id="22010" url="https://es.wikipedia.org/wiki?curid=22010" title="Alfonso García Robles">
Alfonso García Robles

José Alfonso Eufemio Nicolás de Jesús García Robles (n. Zamora, Michoacán, México; 20 de marzo de 1911 - f. 2 de septiembre de 1991) fue un diplomático mexicano, galardonado en 1982 con el premio Nobel de la Paz junto a la sueca Alva Reimer Myrdal.

Su labor más destacada fue la firma del Tratado de Tlatelolco (1967) referente a la no proliferación nuclear y su participación en las Sesiones Especiales para el Desarme de la Asamblea General de la ONU en 1978 y 1982.

Alfonso García Robles, nació en Zamora, Michoacán, México el 20 de marzo de 1911. 

Estudió Derecho, licenciándose por la Universidad Nacional Autónoma de México y realizando estudios de posgrado en el Instituto de Altos Estudios Internacionales, que actualmente es parte de la Universidad de París II Panthéon-Assas, en 1936 y en la Academia de Derecho Internacional de La Haya en 1938.

Se incorporó al servicio exterior de su país en 1939 como tercer secretario de la Embajada de México en Suecia. 

Fue trasladado a México en 1941 para incorporarse a la Secretaría de Relaciones Exteriores (SRE), donde permaneció cinco años como Subdirector de Asuntos Políticos del Servicio Diplomático.

Con el cargo de Secretario de Asuntos Internacionales de la Comisión Nacional de Planeación para la Paz, participó en la Conferencia de las Naciones Unidas sobre Organización Internacional en San Francisco en 1945, donde se sentaron las bases jurídicas de la Organización de las Naciones Unidas (ONU).

De 1946 a 1956 radicó en Nueva York, trabajando para la ONU como Jefe de la División Política del Departamento de Asuntos del Consejo de Seguridad. 

Fue el representante de la ONU en la Conferencia Panamericana de Bogotá (1948), en la que se firmó la Carta de la Organización de los Estados Americanos.

En 1950 se casó con Juana María Szyszlo, una joven peruana, funcionaria de la ONU, con quien tendría dos hijos.

De 1958 a 1960 fue Director en Jefe para Asuntos de Europa, Asia y Organismos Internacionales en la SRE. En esta época se ocupó del Derecho del Mar participando en conferencias en Ginebra de 1958 y 1960.

De 1962 a 1964 ocupó el puesto de Embajador en Brasil.
De 1964 a 1970 fue Subsecretario de la Secretaría de Relaciones Exteriores.

Como Presidente de la Comisión Preparatoria para la Desnuclearización de América Latina presidió las reuniones que se celebraron en la Ciudad de México a partir de 1964 y que concluyeron con la apertura a firma el 14 de febrero de 1967 del Tratado para la Proscripción de las Armas Nucleares en América Latina, mejor conocido como el Tratado de Tlatelolco. 

García Robles desempeñó un papel crucial en lanzar e implementar el acuerdo. Le han llamado el padre del acuerdo de Tlatelolco. Este, propuesto por Adolfo López Mateos, presidente de México en ese entonces, era el resultado de la crisis en Cuba. La idea era asegurar la prohibición de los armamentos nucleares y de que esta parte del mundo no estuviera implicada en ningún conflicto entre las grandes potencias rivales. Las negociaciones fueron conducidas por García Robles, su habilidad de empresa y diplomacia merece una gran medida de crédito para el hecho de que el acuerdo fue concluido con éxito después de algunos años de negociación.

De 1971 a 1975 fue Embajador de México en las Naciones Unidas y presidió el Grupo de los 77.

Ingresó a El Colegio Nacional el 4 de abril de 1972, con la conferencia "El desarme y las Naciones Unidas", fue presentado por el Dr. Antonio Gómez Robledo.

En 1976 fue Secretario de Relaciones Exteriores.
Desde 1977 fue el representante permanente de México en el Comité sobre el Desarme de las Naciones Unidas en Ginebra. 

En 1978 fue presidente de la delegación mexicana en la primera Sesión Especial para el Desarme de la Asamblea General de la ONU y fue uno de los responsables de la adopción de "el documento final".

En 1981 el Presidente de la República lo designó Embajador Emérito.

En septiembre de 1982 se le otorgó la Condecoración del Servicio Exterior Mexicano.
En octubre de 1982 obtuvo el premio Nobel de la Paz por “su magnífico trabajo en las negociaciones de desarme de las Naciones Unidas”, distinción que compartió con la diplomática y escritora sueca Alva Reimer Myrdal.

Murió el dos de septiembre de mil novecientos noventa y uno en la Ciudad de México. Fue enterrado en el Panteón Español, Miguel Hidalgo.

El archivo personal de García Robles y su biblioteca de 1100 volúmenes fueron donados por su viuda a la Universidad de Virginia en Estados Unidos en 1998.

El 24 de abril de 2003 se develó su nombre escrito con letras de oro en uno de los muros del recinto legislativo de San Lázaro, sede de la Cámara de Diputados de México.

Durante los festejos del quincuagésimo aniversario de la Facultad de Derecho de la Universidad La Salle, se develó en su honor el busto que da pauta a que los esfuerzos y grandes sacrificios obtienen sus grandes recompensas.




</doc>
<doc id="22012" url="https://es.wikipedia.org/wiki?curid=22012" title="Fullereno">
Fullereno

Un fullereno (también, fulereno) es una molécula compuesta por carbono que puede adoptar una forma geométrica que recuerda a una esfera, un elipsoide, un tubo (llamado nanotubo) o un anillo. Los fullerenos son similares al grafito, compuesto de hojas de anillos hexagonales enlazadas, pero conteniendo anillos pentagonales y a veces heptagonales, lo que impide que la hoja sea plana. Los fullerenos son la tercera forma molecular estable conocida de carbono, tras el grafito y el diamante.

Los fullerenos fueron descubiertos en 1985 por Harold Kroto, Robert Curl y Richard Smalley, lo que les valió la concesión del Premio Nobel de Química en 1996.

El primer fullereno descubierto fue el , que consta de 12 pentágonos y 20 hexágonos. Cada pico corresponde a un átomo de carbono y cada lado a un enlace covalente. Tiene una estructura idéntica a la cúpula geodésica o un balón de fútbol. Por esta razón, se le llama «buckminsterfullereno» (en homenaje al arquitecto Buckminster Fuller quien diseñó la cúpula geodésica) o «futboleno». Los fullerenos esféricos reciben a menudo el nombre de "buckyesferas" y los cilíndricos el de "buckytubos" o nanotubos. 
Destacan por su versatilidad para la síntesis de nuevos compuestos. Su naturaleza y forma se han hecho ampliamente conocidas en la ciencia y en la cultura en general, por sus características físicas, químicas, matemáticas y estéticas.

El fullereno más conocido es el formado por 60 átomos de carbono (C), en el que ninguno de los pentágonos que lo componen comparten un borde; si los pentágonos tienen una arista en común, la estructura estará desestabilizada (véase pentaleno). La estructura de C es la de un icosaedro truncado, que se asemeja al balón de fútbol cuyo diseño se inició con el Telstar 1970. Está configurado por 20 hexágonos y 12 pentágonos, con un átomo de carbono en cada una de las esquinas de los hexágonos y un enlace a lo largo de cada arista. Aunque su nombre viene de Richard Buckminster Fuller por sus domos geodésicos -el primero de 1948-, fue el ingeniero alemán el que en 1912 inició la construcción de una obra con esa forma para la empresa de instrumentos ópticos de Carl Zeiss, en Jena.
El dibujo más antiguo conocido del icosaedro truncado es el de Piero della Francesca y el más conocido el que Leonardo da Vinci hizo para el libro La Divina Proporción por encargo de Luca Pacioli.

El fullereno C es el más pequeño de todos, no tiene hexágonos, sólo 12 pentágonos formando un dodecaedro, mientras que el C, tiene 12 pentágonos al igual que el buckminsterfullereno, pero tiene más hexágonos, y su forma en este caso se asemeja a un balón de rugby. 

Un nanotubo es una estructura formada por fullerenos cilíndricos polimerizados, en los que los átomos de carbono a partir de un determinado punto enlazan con los átomos de carbono del siguiente fullereno. Estas estructuras presentan propiedades muy aprovechables para la industria tal como la permisibilidad eléctrica. La fuerza entre los enlaces lo hace un material muy sólido y resistente a altas temperaturas. Además, puede ser dopado con otros materiales para cambiar sus propiedades, tales como ductibilidad o fuerza del enlace lo que permitiría la creación por ejemplo de una nueva generación de chips electrónicos a bajo costo.

Hasta el siglo XX, el grafito y el diamante eran las únicas formas alotrópicas conocidas del carbono. En experimentos de espectroscopia molecular, se observaron picos que correspondían a moléculas con una masa molecular exacta de 60, 70 ó más átomos de carbono. Harold Kroto, de la Universidad de Sussex, James Heath, Sean O'Brien, Robert Curl y Richard Smalley, de la Universidad de Rice, descubrieron el C y otros fullerenos en 1985, en un experimento que consistió en hacer incidir un rayo láser sobre un trozo de grafito. Ellos esperaban efectivamente descubrir nuevos alótropos del carbono, pero suponían que serían moléculas largas, en lugar de las formas esféricas y cilíndricas que encontraron. A Kroto, Curl y a Smalley se les concedió el premio Nobel de Química en 1996, por su colaboración en el descubrimiento de esta clase de compuestos. El C y otros fullerenos fueron más adelante observados fuera del laboratorio (ej. en el hollín de una vela). Hacia el año 1991, era relativamente fácil producir unos cuantos gramos de polvo de fullereno usando las técnicas de Donald Huffman y Wolfgang Krätschmer. La purificación del fullereno era un desafío para los químicos hasta la primera década del presente siglo, cuando un equipo de investigadores españoles desarrolló un nuevo proceso de obtención. Los fullerenos "endoédricos" han incorporado, entre los átomos de la red, iones u otras moléculas más pequeñas. El fullereno es un reactivo habitual en muchas reacciones orgánicas como por ejemplo en la reacción de Bingel, descubierta en 1993.

En julio de 2010 la NASA anunció el descubrimiento de fullerenos en el espacio. Al usar la visión infrarroja sensible del telescopio Spitzer, los investigadores han confirmado la presencia de C en la nebulosa planetaria Tc1. Los astrónomos creen que los fullerenos son creados en las capas exteriores de una estrella, como nuestro sol, y posteriormente son expulsadas al espacio después de la explosión de las mismas.

Desde su descubrimiento, las propiedades químicas y físicas de los fullerenos todavía continúan bajo un intenso estudio. Entre las propiedades físicas más relevantes se encuentra el gap de energía entre el orbital ocupado de más alta energía (HOMO) y el orbital desocupado de menor energía (LUMO), cuya medida es ca. 1,7 eV. La simetría del estado base del fulereno C corresponde al grupo puntual Ih. En esta simetría los orbitales HOMO y LUMO están cinco y tres veces degenerados, h y t respectivamente. Debido a este hecho, transiciones electrónicas desde HOMO a LUMO están prohibidas por simetría. El fulereno C presenta 174 modos normales de vibración (3N - 6, donde N = 60 átomos de carbono) en la región del infrarrojo. No obstante, solo cuatro modos normales son activos.

En el icosaedro truncado y los cuerpos geométricos semejantes a él -los hexapentas- la clave matemática está en la relación geométrica entre los hexágonos y los pentágonos que los configuran. La demostración de la armonía en los hexapentas en general, dada la consonancia entre sus hexágonos y pentágonos componentes (considerando que ambas figuras en cada caso tienen la misma longitud de sus lados o aristas del poliedro), está dada en la relación de sus apotemas mediante el Número Áureo (ф = 1,618…).

En el campo de la nanomedicina, el fulereno C se ha estudiado su potencial uso medicinal como fijador de antibióticos espécificos en su estructura para atacar bacterias resistentes y ciertas células cancerígenas, tales como el melanoma.

Los fullerenos no son muy reactivos debido a la estabilidad de los enlaces tipo grafito, y son también muy poco solubles en la mayoría de disolventes. Entre los disolventes comunes para los fullerenos se incluyen el tolueno y el disulfuro de carbono. Las disoluciones de buckminsterfullereno puro tienen un color púrpura intenso. El fullereno es la única forma alotrópica del carbono que puede ser disuelta. Los investigadores han podido aumentar su reactividad uniendo grupos activos a las superficies de los fullerenos. El buckminsterfullereno no presenta "superaromaticidad", es decir, los electrones de los anillos hexagonales no pueden deslocalizar en la molécula entera.

Se pueden atrapar otros átomos dentro de los fullerenos; de hecho existen evidencias de ello gracias al análisis del gas noble conservado en estas condiciones tras el impacto de un meteorito a finales del periodo Pérmico. En el campo de la nanotecnología, la resistencia térmica y la superconductividad son algunas de las características más profundamente estudiadas.

Un método habitual para producir fullerenos es hacer pasar una corriente eléctrica intensa entre dos electrodos de grafito próximos en atmósfera inerte. El arco resultante entre los dos electrodos produce un depósito de hollín del que se pueden aislar muchos fullerenos diferentes.

Aunque se piensa que las buckyesferas son en teoría relativamente inertes, una presentación dada a la Sociedad Química Estadounidense en marzo de 2004 y descrita en un artículo publicado en la revista New Scientist el 3 de abril de 2004, sugiere que la molécula es perjudicial para los organismos. Un experimento llevado a cabo por Eva Oberdörster en la Southern Methodist University, en el que introdujo fullerenos en agua en concentraciones de 0,5 partes por millón, mostró que un pez (Micropterus salmoides) "Black Bass" sufrió un daño celular en el tejido cerebral 17 veces superior, 48 horas después. El daño consistía en una peroxidación lipídica a nivel de la membrana celular, lo que deteriora el funcionamiento de ésta. Se produjeron también inflamaciones en el hígado y la activación de genes relacionados con la síntesis de enzimas reparadoras.

La siguiente lista muestra los disolventes en orden decreciente de solubilidad para una mezcla de C/C). Los valores entre paréntesis indican la concentración de saturación.


En términos matemáticos, la estructura de un fullereno es un poliedro convexo con caras pentagonales y hexagonales.

Con ayuda de la fórmula de Euler: caras + Vértices - aristas = 2, además del hecho de que cada vértice en una estructura de fullereno pertenece exactamente a tres caras, se puede demostrar fácilmente que en un fullereno hay exactamente 12 pentágonos. El fullereno más pequeño es el C, el dodecaedro. No existen fullerenos con 22 vértices. El número de fullerenos C diferentes crece de manera muy rápida al aumentar el valor de n; por ejemplo, hay 1.812 fullerenos C, pero sólo uno de ellos, el buckminsterfullereno, no tiene pentágonos adyacentes.

Es conveniente saber que B. Fuller creó la fórmula matemática al aplicarlas a las estructuras arquitectónicas de su amigo el escultor Kenneth Snelsson, quien en los años 70 diseñó estructuras que consistían en barras metálicas rígidas y alambres de acero. Fuller creó el término "Tensegrity", para describir el tipo de estructuras de tensión interna estables que proyectara.

El físico que se transformó en artista Julian Voss-Andreae ha creado diversas esculturas que simbolizan la dualidad onda-partícula en los buckminsterfullerenos. Voss-Andreae participó en investigaciones realizadas para demostrar que objetos tan grandes como los buckminsterfullerenos también obedecen a las peculiares leyes de la física cuántica. Después de esto, Voss-Andreae decidió cambiar su profesión para convertirse en artista de tiempo completo. A partir de entonces ha diseñado objetos tales como la estructura de bronce de 60 centímetros de diámetro llamada "Buckyesfera Cuántica" (2004) que consiste en cuatro buckyesferas anidadas. Su escultura más grande basada en fullerenos se ubica en un parque privado en Portland, Oregon (Estados Unidos). "Realidad Cuántica (Gran Buckyesfera Rodeada de Árboles)" (2007) es una estructura de acero de 9 metros de diámetro atravesada por varios árboles que crecen libremente en medio de ella y la sostienen en el aire justo por encima del alcance de los brazos.







</doc>
<doc id="22015" url="https://es.wikipedia.org/wiki?curid=22015" title="Talcott Parsons">
Talcott Parsons

Talcott Parsons (13 de diciembre de 1902 – 8 de mayo de 1979) fue un sociólogo estadounidense de la tradición clásica de la sociología, mejor conocido por su teoría de la acción social y su enfoque estructural-funcionalista. Parsons es considerado una de las figuras más influyentes en el desarrollo de la sociología en el siglo XX.Luego de obtener un doctorado en economía, trabajó en la facultad de la Universidad de Harvard desde 1927 a 1979, y en 1930 estuvo entre los primeros profesores del recientemente creado departamento de sociología.

Basada en datos empíricos, la teoría de la acción social de Parsons fue la primera teoría de sistemas sociales desarrollada en Estados Unidos de carácter amplio, sistemático y generalizable.  Una de las más grandes contribuciones de Parsons a la sociología en el mundo anglófono fueron sus traducciones de las obras de Max Weber y sus análisis de los trabajos de Weber, Émile Durkheim y Vilfredo Pareto. El trabajo de estos autores influenció fuertemente la perspectiva de Parsons y fue la base de su teoría de la acción social, en la cual vio la acción voluntarística a través del prisma de los valores culturales y las estructuras sociales que constriñen las elecciones y que, en último término, determinan todas las acciones sociales, en oposición a la idea de que las acciones están determinadas con base en procesos psicológicos internos. Aunque Parsons es generalmente considerado un estructural-funcionalista, hacia el final de su carrera en 1975 publicó un artículo en el que declara que los términos "funcional" y "estructural-funcionalista" eran formas inapropiadas de describir el carácter de su teoría.

A inicios de la década de 1970, una nueva generación de sociólogos criticó las teorías de Parsons, viéndolas como socialmente conservadoras y con una prosa innecesariamente compleja.  Desde entonces, los cursos de sociología han puesto menos énfasis en sus teorías en comparación al auge de su popularidad entre las décadas de 1940 y 1970. Sin embargo, se reconoce un resurgimiento del interés en sus ideas.

Talcott Parsons nació el 13 de diciembre de 1902 en Colorado Springs. Fue el hijo de Edward Smith Parsons (1863-1943) y Mary Augusta Ingersoll (1863-1949). Su padre asistió al Yale Divinity School y fue ordenado como ministro congregacionalista, sirviendo primero como ministro de una comunidad pionera en Greeley. Al momento del nacimiento de Talcott Parsons, Edward Parsons era profesor de inglés y vicepresidente en el Colorado College.

Durante su periodo de ministro congregacionalista en Greeley, Edward Parsons había empatizado con el evangelio social, aunque manteniendo una posición teológica superior, al tiempo que mostró hostilidad al socialismo tratándolo como mera ideología. En aquel tiempo, Edward Parsons y su hijo Talcott eran cercanos a la teología de Jonathan Edwards. El padre se volvería después el presidente del Marietta College en Ohio.

La familia Parsons es una de las más antiguas familias de la historia de Estados Unidos. Sus ancestros fueron unos de los primeros en llegar desde Inglaterra en la primera mitad del siglo XVII. La herencia familiar consistió de dos lineas Parsons separadas e independientes, las cuales remiten a los tempranos días de Estados Unidos y a la historia de Inglaterra. Por el lado paterno, la familia puede ser rastreada hasta los Parsons de York. Por el lado materno, la línea Ingersoll estuvo conectada con Jonathan Edwards, y desde éste en adelante habría una nueva e independiente línea Parsons, ya que su hermana mayor Sarah Edwards se casó con Elihu Parsons el 11 de junio de 1750.

Parsons comenzó estudiando biología, sociología y filosofía en el Amherst College, recibiendo su grado de "Bachelor of Arts" en 1924. El Amherst College fue una institución a la que asistió la familia Parsons por tradición: el padre y el tío de Talcott asistieron a él, así como su hermano mayor Charles Edward Parsons. Inicialmente, Talcott Parsons estaba atraído por la carrera de medicina, inspirado en su hermano mayor, lo que lo llevó a estudiar extensamente biología y a pasar un verano trabajando en la Institución Oceanográfica de Woods Hole.

Los profesores de biología de Parsons en el Amherst College fueron Otto Glaser y Henry Plough. Parsons también se volvió uno de los estudiantes más destacados en la institución. Tomó clases con Walton Hamilton y el filósofo Clarence Edwin Ayres, ambos conocidos como "economistas institucionales", quienes le mostraron las obras de Thorstein Veblen, John Dewey, William Graham Sumner, entre otros. Parsons tomó también un curso con George Brown sobre la filosofía de Immanuel Kant, así como uno sobre la filosofía moderna alemana con Otto Manthey-Zorn, quien era un destacado intérprete de Kant. Parsons mostró tempranamente un gran interés por la filosofía, lo cual probablemente era una reminiscencia del gran interés de su padre por la teología en la tradición en la cual fue socializado, posición que contrastaba con la perspectiva de los profesores de Talcott Parsons.

Se han rescatado dos ensayos finales que Parsons escribió como estudiante de Clarence Ayres en la clase de Filosofía III en el Amherst College, los cuales han sido referidos como los "Amherst Papers" y han resultado de gran interés para los estudiosos de Parsons. El primero fue escrito el 19 de diciembre de 1922 y se titula "The Theory of Human Behavior in its Individual and Social Aspects" (La teoría del comportamiento humano en sus aspectos individuales y sociales). El segundo ensayo final fue escrito el 27 de marzo de 1923 y se titula "A Behavioristic Conception of the Nature of Morals" (Una concepción conductista de la naturaleza de la moral). Los ensayos revelan en parte el temprano interés de Parsons por las cuestiones sobre la evolución social. Los "Amherst Papers" también revelan que Parsons no estaba de acuerdo con sus profesores institucionalistas, ya que sostenía que el desarrollo tecnológico y el progreso moral eran dos procesos empíricos estructuralmente independientes.

Luego de su estadía en el Amherst College, estudió en la London School of Economics (LSE) por un año, donde fue expuesto al trabajo de R. H. Tawney, Bronislaw Malinowski y Leonard Trelawny Hobhouse. Durante su paso por la LSE hizo amistad con Edward Evan Evans-Pritchard, Meyer Fortes y Raymond Firth (quienes participaron en el seminario de Malinowski), y tuvo una fuerte amistad personal con Arthur Burns y Eveline Burns.

Mientras estudió en la LSE, conoció a una joven estadounidense en los cuartos comunes de estudiantes, cuyo nombre era Helen Bancroft Walker y con quien se casaría el 30 de abril de 1927. La pareja tuvo tres hijos: Anne, Charles y Susan, y eventualmente cuatro nietos. El padre de Helen nació en Canadá, pero se mudó al área de Boston y se volvió un ciudadano estadounidense.

Parsons fue luego a la Universidad de Heidelberg, donde recibió su doctorado en sociología y economía en 1927. Durante su estadía en esta universidad, trabajó con Alfred Weber (hermano de Max Weber), Edgar Salin (quien era su tutor de disertación), Emil Lederer y Karl Mannheim. Además, realizó un examen sobre la Crítica de la razón pura de Kant con el filósofo Karl Jaspers. Parsons también fue examinado en esta universidad por Willy Andreas sobre la Revolución Francesa. La tesis doctoral de Parsons fue escrita bajo el título "The Concept of Capitalism in the Recent German Literature" (El concepto del capitalismo en la reciente literatura alemana) y se enfocó en el trabajo de Werner Sombart y Max Weber. Resulta claro de su discusión el rechazo a las visiones cuasi idealísticas de Sombart y la adherencia a los intentos de Weber por lograr un equilibrio entre historicismo e idealismo, así como a una aproximación neokantiana.

El descubrimiento más crucial para Parsons en Heidelberg fue su encuentro con la obra de Max Weber, a quien nunca había escuchado antes de llegar a Alemania. Weber se volvió tremendamente imporante para Parsons pues, considerando su crianza con un padre liberal pero fuertemente religioso, la cuestión del rol de la cultura y la religión en los procesos básicos de la historia mundial se volvió un persistente enigma para él. En este sentido, Weber fue el primer académico que realmente le proveyó a Parsons una convincente respuesta teórica a esta cuestión, razón por la cual Parsons estuvo absorto honda y extensamente en la lectura de la obra de Weber.

Parsons decidió entonces traducir la obra de Weber al inglés, acercándose a Marianne Weber, la esposa de Max Weber, con este propósito. Durante su estadía en Heidelberg, Parsons fue invitado por Marianne Weber a "meriendas sociológicas", las cuales eran reuniones de estudio grupal que Marianne tenía en la biblioteca del antiguo apartamento de ella y Max Weber. Uno de los académicos que Parsons conoció en Heidelberg que compartía su entusiasmo por Weber fue Alexander von Schelting. Posteriormente, Parsons escribió una reseña en el libro de Von Schelting sobre Weber. En general, Parsons leyó extensivamente literatura sobre religión, especialmente obras enfocadas en la sociología de la religión. Un académico que se volvió especialmente importante para Parsons a este respecto fue Ernst Troeltsch. Parsons también leyó ampliamente sobre el tópico del calvinismo, incluyendo las obras de Emile Doumerque, Eugéne Choisy y Henri Hauser.

En 1927, luego de un año enseñando en el Amherst College, Parsons entró a Harvard como instructor en el Departamento de Economía , donde siguió las lecciones de Frank William Taussig sobre Alfred Marshall y se volvió amigo del economista e historiador Edwin Gay, quien fuera el fundador de la Escuela de Negocios de Harvard. Parsons también se volvió un cercano asociado de Joseph Schumpeter y siguió su curso en Economía General. Parsons estuvo generalmente en desacuerdo con algunas de las tendencias del Departamento, que en esos días tenía una orientación altamente técnica y matemática, por lo que buscó otras opciones en Harvard y dio cursos en Ética Social y Sociología de la Religión. Aunque Parsons entró a Harvard a través del Departamento de Economía, nunca apuntó a volverse un economista; todas sus actividades y su interés intelectual básico lo impulsaron hacia la sociología, aunque no existió un Departamento de Sociología en los primeros años que estuvo en Harvard. Sin embargo, Harvard estuvo en esos años trabajando para establecer uno y Parsons se posicionó a sí mismo de varias formas escribiendo y enseñando, por lo que estaba listo para unirse al Departamento de Sociología cuando fue finalmente establecido. Parsons nunca fue forzado a abandonar el Departamento de Economía, sino que su salida fue una decisión voluntaria y deliberada.

La posibilidad de establecerse en la sociología llegó en 1930, cuando el primer Departamento de Sociología fue creado en Harvard por Pitirim Sorokin.  Sorokin había llegado a Estados Unidos en 1923 escapando de la Revolución Rusa. Parsons se volvió uno de los dos instructores del reciente creado departamento, junto a Carl Joslyn, y estableció lazos cercanos con el bioquímico y sociólogo Lawrence Joseph Henderson, quien tuvo interés personal por la carrera de Parsons en Harvard. Parsons también formó parte del grupo de estudio de Pareto, formado por el mismo Henderson, en el cual participaron algunos de los más importantes intelectuales de Harvard: Crane Brinton, George Casper Homans y Charles Curtis. A raíz de la lectura de Pareto, Parsons escribió un artículo sobre su teoría y luego explicitó la adopción de su concepto de sistema social. Parsons también hizo estrechas relaciones con dos otros influenciales intelectuales, con los cuales se envió correspondencia por varios años: el economista Frank Hyneman Knight y Chester Barnard, uno de los empresarios más dinámicos de Estados Unidos. Las relaciones entre Parsons y Sorokin se tensaron rápidamente, en parte por el profundo disgusto de Sorokin por la civilización estadounidense, a la que consideraba una cultura sensata en decadencia. Los escritos de Sorokin se volvieron progresivamente anticientíficos en sus últimos años, ampliando su brecha con el trabajo de Parsons y volviendo en su contra a una comunidad sociológica en Estados Unidos que se estaba volviendo crecientemente positivista. Incluso Sorokin llegó a menospreciar todas las tendencias sociológicas que diferían de sus obras, llegando en 1934 a ser un académico bastante impopular en Harvard.

Algunos de los estudiantes a los que enseñó Parsons en los primeros años del nuevo Departamento de Sociología fueron Robin Williams Jr., Robert K. Merton, Kingsley Davis, Wilbert Moore, Edward Devereux, Logan Wilson, Nicholas Demereth, John Riley Jr. y Mathilda White Riley. Generaciones posteriores de estudiantes incluyeron a Harry Johnson, Bernard Barber, Marion Levy y Jesse Richard Pitts. A pedido de los estudiantes, Parsons estableció un pequeño e informal grupo de estudio que se reunía anualmente. Hacia el final de la carrera de Parsons, el teórico de sistemas Niklas Luhmann también asistió a sus clases.

En el período académico 1939-1940, Parsons y Schumpeter dirigieron un seminario informal de facultad en Harvard realizado en el Salón Emerson y que buscaba discutir sobre el concepto de racionalidad. Entre los participantes se encontraban Abram Bergson, Wassily Leontief, Gottfried Haberler y Paul Sweezy. Schumpeter contribuyó al seminario con su ensayo "Rationality in Economics" (Racionalidad en economía), mientras que Parsons lo hizo con su artículo "The Role of Rationality in Social Action" (El rol de la racionalidad en la acción social). Schumpeter le propuso a Parsons escribir y editar conjuntamente un libro acerca de la racionalidad, pero el proyecto nunca se concretó.

Frente a la discusión entre economistas neoclásicos e institucionalistas, que fue uno de los conflictos prevalentes en la economía entre las décadas de 1920 y 1930, Parsons trazó una línea muy delgada. Él era muy crítico de la teoría neoclásica, actitud que permaneció durante toda su vida y se reflejó en las críticas a Milton Friedman y Gary Becker. Particularmente, se oponía al sesgo utilitarista de la teoría neoclásica. Sin embargo, Parsons estaba de acuerdo parcialmente con el estilo teórico y metodológico de este enfoque. Por lo tanto, se vio imposibilitado de aceptar la solución propuesta por la economía institucional, a la que consideraba como primariamente empírica, descriptiva y sin enfoque teórico.

Parsons regresó a Alemania el verano de 1930 y fue testigo directo de la febril atmósfera en la República de Weimar, durante la cual el Partido Nazi llegó al poder. Parsons recibió constantes reportes del ascenso del nazismo a través de su amigo Edward Yarnall Hartshorne. A fines de la década de 1930, Parsons comenzó a advertir a la opinión pública estadounidense sobre la amenaza nazi, pero tuvo poco éxito. Un sondeo de la época evidencia que el 91% del país se oponía a la Segunda Guerra Mundial. También la mayoría del pueblo estadounidense pensaba que el país debió mantenerse al margen de la Primera Guerra Mundial y que los nazis no representaban amenaza, pese a lo que hicieron en Europa. Incluso algunos estadounidenses simpatizaban con Alemania debido a su ascendencia en ese país y a la opinión de que, siendo ambos países fuertemente anticomunistas, sólo Alemania logró salir de la Gran Depresión. Uno de los primeros artículos que Parsons escribió sobre el nazismo fue "New Dark Age Seen If Nazis Should Win" (Nuevos años oscuros si los nazis ganan), lo que lo volvió uno de los iniciadores claves del Comité de Defensa de Harvard, el cual apuntaba a unificar la opinión pública estadounidense contra los nazis. Parsons difundió este mensaje a través de las estaciones de radio locales en Boston y en una reunión llevada a cabo en Harvard, la cual fue agitada por activistas en contra de la guerra. Junto a Charles Orlando Porter, Parsons buscó unificar a los estudiantes graduados en Harvard para ir a la guerra. Incluso, durante la guerra, Parsons dirigió un grupo de estudio especial en Harvard que buscaba analizar lo que sus miembros consideraban las causas del nazismo, incluyéndose para el análisis expertos en el tema.

Parsons generó un sistema teorético general para el análisis de la sociedad que denominó teoría de la acción. Esta teoría tiene un fundamento metodológico y epistemológico en el principio del realismo analítico, mientras que su supuesto ontológico es el de la acción voluntarista. El concepto de Parsons de realismo analítico se puede entender como una suerte de compromiso entre las visiones nominalista y realista de la naturaleza de la realidad y del conocimiento humano. Parsons creía que la realidad objetiva se podía relacionar sólo con una visión particular de dicha realidad, y que la comprensión intelectual general es plausible a través de esquemas conceptuales y teorías. La interacción con la realidad objetiva en el nivel intelectual se debe entender siempre como una aproximación. Con frecuencia Parsons explicaba el significado del realismo analítico citando a Lawrence Joseph Henderson: "Un hecho es una declaración sobre la experiencia en términos de esquema conceptual".

En general, Parsons sostuvo que su inspiración con respecto al realismo analítico ha estado en Lawrence J. Henderson y Alfred North Whitehead, aunque probablemente tuvo esta idea con anterioridad. El concepto de realismo analítico le permite insistir en la referencia a una realidad objetiva y, con esto, marcar una diferencia importante con el ficcionalismo de Hans Vaihinger.

"La estructura de la acción social" es la obra más famosa de Parsons. Su figura central fue Weber y los otros dos autores claves, Durkheim y Pareto, fueron agregados a la discusión conforme la idea central tomaba forma. Una importante publicación que ayudó a Parsons a desarrollar el argumento central de esta obra fue encontrada inesperadamente en 1932: se trata de "La formation du radicalisme philosophique" de Élie Halévy, particularmente el tercer volumen, obra que le permitió aclarar los supuestos del utilitarismo inglés.

La teoría de la acción que Parsons desarrolló en "La Estructura de la Acción Social" puede caracterizarse como un intento de mantener el rigor científico del positivismo al tiempo que se destaca la necesidad de la dimensión subjetiva de la acción humana, incorporada en las teorías sociológicas hermenéuticas. Resulta capital en la visión teórica y metodológica general de Parsons la comprensión de la acción humana en conjunción con el componente motivacional del acto humano. Por esta razón, se plantea que las ciencias sociales deben considerar el problema de los fines, propósitos e ideales en el análisis de la acción humana. La fuerte reacción del autor tanto a la teoría conductista como a las aproximaciones materialistas puras se deriva del intento de estas posiciones teóricas de eliminar los fines, propósitos e ideales como factores del análisis. En sus ensayos escritos en el Amherst College, Parsons ya estaba criticando los intentos de reducir la comprensión de la vida humana a fuerzas psicológicas, biológicas y materialistas. Para Parsons, resultaba esencial en la vida humana el modo en que la cultura era codificada, la cual constituía una variable independiente que no se puede deducir de otro factor del sistema social. Algunos de estos temas fueron presentados anteriormente por Parsons en un ensayo escrito dos años antes de la publicación de "La Estructura de la Acción Social".

Hay tres conceptos que yacen en el núcleo de la teoría de la acción: el acto-unidad, el voluntarismo y la "verstehen". El fenómeno más básico de la teoría de la acción es lo que Parsons denominó el acto-unidad, definido por sus cuatro componentes: 

El voluntarismo hace referencia a las elecciones que hacen los actores en las situaciones sociales en las que se encuentran. Esto no significa que los actores sean totalmente libres al hacer su elección, pues el concepto de voluntarismo implica una conciencia. Por último, la "verstehen" refiere a la necesidad de analizar la acción desde una perspectiva subjetiva.

La solución propuesta por Parsons a las polarizaciones anteriores a su tiempo fue una teoría general de la sociedad, que piensa la vida social como una totalidad y que pueda constituirse como un gran relato, con capacidad explicativa y predictiva sobre la vida social (al modo de Comte). Sin embargo Parsons va a encontrarse con un problema que le dará bastantes quebraderos de cabeza durante toda su vida: el papel del individuo. Frente a una teoría tan generalista, cabe preguntarse por cuál es el lugar del individuo dentro de un universo tan grande de supraentidades. Y, es más, si se tienen en cuenta las implicaciones del estructuralismo funcional, para el que los individuos están encajados en celdas de la estructura social, que determinan lo que socialmente son, y el objetivo de éstos es cumplir una función social, es decir, que ya tienen determinado hasta lo que tienen que hacer, ¿dónde queda la decisión individual?

Parsons para elaborar su teoría se basa en varias relaciones. Principalmente toma a Durkheim, utilizando su definición de sociedad, pero considerada como un sistema y no un organismo, en contraposición a Marx. Toma de Weber el concepto de "acción social", lo que es una conducta con significado referente a la cultura.

También retoma cuestiones de autores externos a la disciplina sociológica, como Freud, utilizando su segunda tópica, que plantea a la personalidad compuesta por tres componentes: el "ello" (tendencias naturales de los organismos vivos), el "superyó" (el Yo ideal) y el "yo" (la parte del "ello" modificada por la educación y la influencia cultural). Con esto se basa en el libro de Freud "El malestar en la cultura", que presenta la sociedad como represora de nuestros instintos, ya que en el caso de las represiones del "superyó" son todas de conformación social.

Por último, toma de Bertalanffy, biólogo y padre de la teoría general de sistemas, su propuesta de un modelo que amplíe la visión científica bajo un nuevo aspecto de ordenamiento y relación a través del modelo de sistema.


Parsons es conocido en la historia de la sociología, como el autor de la Teoría estructural funcionalista, que se llama “A.G.I.L.”. El esquema ágil, o el modelo de las cuatro funciones, como es la Teoría estructural funcionalista, que es lo mismo, no fue ni el primero ni el más importante, es decir, el más lucido, de los intentos parsoniano por resolver este problema. Parsons elaboró muchos intentos de Teoría, todos ellos muy sugestivos, muy interesantes, muy atractivos. Uno de ello alcanzó cierto notable éxito en la comunidad sociológica internacional. Fue el modelo AGIL. Pero lo interesante es que Parsons intenta superar la distinción entre acción y sistema, entre subjetivismo y objetivismo en Teoría sociológica. Curiosamente cada uno de los momentos de su Teoría se fue desplazando, y en el fondo inconscientemente terminó siendo el representante de cada uno de esos enfoques.

Parsons analiza a cada sistema como inmerso en una jerarquía y cualificado por su apertura a las variaciones del sistema inmediatamente "superior".

Ya entendiendo esto, podemos entender la teoría sistémica de Parsons. El sistema que lo engloba todo es el "sistema cultural", el cual es el que regula las orientaciones; adentro de este está el "sistema social" el cual es que engloba los medios y condiciones; y adentro de este sistema, está el "sistema de la personalidad", que es el que ubica al actor y sus necesidades individuales. También se puede decir que dentro del sistema de la personalidad esta el biológico. 

En general, un individuo dentro de un sistema social siempre va tener un estatus, que es su ubicación en la sociedad y un rol que es la función que cumple dentro un sistema social. Todo sistema social tiene siempre necesidades mínimas de satisfacer, estas son los prerrequisitos funcionales, los cuales son necesidades del sistema social en general. Y con esto, Parsons solucionaría el problema del orden hobbesiano, ya que los individuos funcionarían a través de sus roles para cumplir con estos prerrequisitos, los cuales son: primero, los sistemas sociales deben estar estructurados de manera que sean compatibles con otros sistemas; segundo, el sistema social debe contar con el apoyo de otros sistemas; tercero, debe satisfacer una parte significativa de las necesidades de los actores; cuarto, debe fomentar en sus miembros una participación suficiente; quinto, debe ejercer control sobre las conductas potencialmente desintegradoras; sexto, si surge un conflicto lo debe controlar; y, séptimo, requiere un lenguaje para poder sobrevivir.

Estos prerrequisitos hacen los cuatro subsistemas famosos de Parsons, formados por cuatro imperativos funcionales (AGIL) necesarios en todo sistema, que son: la "adaptación" (A), esto es, todo sistema debe abarcar las situaciones externas, debe adaptarse a su entorno y adaptar el entorno a sus necesidades; la "capacidad para alcanza metas" (G); la "integración" (I), es decir, regular la interrelación entre los otros imperativos funcionales; la "latencia" (L), un sistema debe proporcionar, mantener y renovar la motivación de los individuos y las pautas culturales que crean y mantienen la motivación. El sistema general de la acción está compuesto en la adaptación por el "sistema orgánico", en las metas por el "sistema de personalidad", en la integración por el "sistema social" y en la latencia por el "sistema cultural". Ejemplificando, este sistema sería como un juego de muñecas rusas, y Parsons se da el lujo de describirnos como es adentro del sistema social: en la adaptación está la economía, en metas está la política, en la integración está la comunidad y en la latencia esta endoculturación. La gracia es que estos sistemas interactúen entre sí y funcionen como sistema.

Procesos sociales: el funcionamiento de todo sistema supone resolver los siguientes problemas.

Quien más haya cumplido con los fines va a estar más alto en la pirámide social. Según Parsons cada persona tiene el lugar que se merece dentro de la pirámide. El fracaso de las sociedades es el fracaso individual.

Parsons desarrolló sus ideas durante un periodo en el que la teoría de sistemas y la cibernética estaban tomando relevancia en las ciencias sociales y del comportamiento. Tomando elementos de estos enfoques, postuló que los sistemas relevantes tratados en dichas ciencias eran abiertos, esto es, insertos en un entorno con otros sistemas. Para las ciencias sociales y del comportamiento, el sistema más amplio es el sistema de acción, consistente en la interrelación de los comportamientos de los seres humanos inserta en un entorno físico-orgánico.

En la medida que Parsons fue desarrollando su teoría, se vinculó crecientemente a los campos de la cibernética y la teoría de sistemas, tomando los conceptos de homeostasis de Alfred Emerson y de procesos teleonómicos acuñado por Ernst Mayr. Con esto, Parsons intentó equilibrar, por una parte, el psicologismo de la fenomenología con el idealismo y, por otra parte, los tipos puros de lo que él denominaba el complejo utilitario-positivista.

La teoría de Parsons incluye una teoría general sobre la evolución social y una interpretación concreta de los mayores impulsos de la historia mundial. En su teoría sobre la historia y la evolución, plantea que la simbolización cognitiva-constitutiva de la jerarquía cibernética de los niveles de acción sistémicos desempeña, en principio, una función equivalente a la que tiene la información genética del ADN sobre el control de la evolución biológica. Sin embargo, esto no quiere decir que el factor del control meta-sistémico determine los resultados, sino que más bien define los límites de orientación de la acción.

Para Parsons, los procesos y entidades transformativas en el nivel constitutivo de la sociedad están, generalmente, en al menos un nivel de análisis empírico, el cual es desempeñado y actualizado por los mitos y religiones. Sin embargo, la filosofía, los sistemas del arte e incluso la semiótica del comportamiento de consumo pueden también, en principio, desempeñar las mismas funciones.

La teoría de Parsons refleja una visión de un concepto unificado de las ciencias sociales y de los sistemas vivos en general. Su aproximación difiere esencialmente de la teoría de Niklas Luhmann, ya que Parsons rechaza la idea de que los sistemas puedan ser autopoiéticos, se trate de sistemas de acción actual o de actores individuales. Para él, los sistemas tienen capacidades inmanentes, pero sólo como resultado de los procesos institucionalizados de los sistemas de acción, correspondientes, en último análisis, al esfuerzo histórico de actores individuales. Mientras Luhmann se queda en la inmanencia sistémica pura, Parsons insiste en que la pregunta por los procesos autocatalíticos y homeostáticos no es excluyente de la pregunta sobre cuál es el primer movilizador del actor. En este sentido, los procesos homeostáticos pueden ser necesarios si es que ocurren, pero la acción es necesaria.

Los dichos de Parsons sobre la referencia última en el marco de la acción deben entenderse como la idea de que los sistemas de mayor orden cibernético en la historia tenderán a controlar las formas sociales organizadas en menores niveles de la jerarquía cibernética. Para Parsons, los niveles más altos de la jerarquía cibernética en el nivel general de la acción corresponden a la parte constitutiva del sistema cultural (es decir, la "Latency" en el esquema AGIL). Sin embargo, en los procesos de interacción al interior del sistema, el análisis debe centrarse especialmente en el eje cultural-expresivo (la línea L-G en AGIL). El término "constitutivo" es entendido por Parsons como referente a valores culturales altamente codificados, sobre todo elementos religiosos. No obstante, no queda clara la interpretación de dicho término a lo largo de su obra.

Los sistemas culturales tienen un estatus independiente de las pautas normativas y orientadoras del sistema social, razón por la cual ninguno de estos sistemas es reductible al otro. Por ejemplo, la cuestión sobre el capital cultural de un sistema social como entidad histórica pura (o sea, en su función como sistema fiduciario) no es equivalente a los mayores valores culturales de ese sistema. Esto ocurre porque en el sistema cultural está encarnado una lógica metaestructural que no puede ser reducida a ningún sistema social dado o no puede ser vista como una deducción materialista (o comportamental) de las necesidades del sistema social. En ese contexto, la cultura tendría un poder de transición independiente, no sólo como factor de las unidades socioculturales actuales (como la civilización occidental), sino que también como bases culturales originales que tienden a universalizarse mediante la interpenetración y expansión sobre un gran número de sistemas sociales. Lo segundo ocurrió con la Grecia Clásica y el antiguo Israel, en donde las bases sociales originales desaparecieron, pero el sistema cultural sobrevivió como una pauta cultural independiente y en funcionamiento (lo que se evidencia en los casos de la filosofía griega o del cristianismo como derivación modificada de sus orígenes en Israel).

La diferencia entre Parsons y Jürgen Habermas reside principalmente en el modo en que Habermas usa la teoría de la acción de Parsons para establecer las proposiciones básicas de la suya. Habermas rescata la separación hecha por Parsons entre las dimensiones internas y externas del sistema social, denominando a las primeras "mundo de la vida" (I y L en AGIL) y a las segundas "sistema" (A y G en AGIL). Desde el punto de vista de Parsons, este modelo presenta dos problemas. En primer lugar, el conflicto dentro del sistema social puede surgir en realidad desde cualquier punto relacional, y no simplemente de la dicotomía sistema/mundo de la vida. En segundo lugar, al relacionar el modelo de sistema/mundo de la vida a un tipo de liberación, Habermas plantearía la noción utópica de que el conflicto potencial al interior de un sistema social tiene una solución final, generando un concepto confuso de la naturaleza del conflicto sistémico.


En español


</doc>
<doc id="22018" url="https://es.wikipedia.org/wiki?curid=22018" title="Miffy">
Miffy

Miffy es un personaje infantil creado por Dick Bruna. Miffy es una conejita. Su nombre original en el idioma neerlandés es "Nijntje", que viene de "konijntje", el cual se traduce como "conejito". En neerlandés su apellido es "Pluis". (Nijntje [ˈnɛɪ̯ncǝ])

El primer libro de Miffy fue producido en 1955, y casi 30 más lo han seguido. En total, vendieron más de 85 millones de copias en 40 idiomas y dieron lugar a dos series de televisión diferentes, así como artículos de ropa y juguetes con el dibujo del personaje. Un largometraje, "Miffy the Movie", fue lanzado el 30 de enero de 2013. En España se estrenó con el título "Miffy y sus amigos".
Se han producido al menos dos series de televisión basadas en el personaje: "Miffy y sus amigos", que se emitió del 2003 al 2007 en la cadena de televisión por cable Nick Jr., en Estados Unidos, y "Las aventuras de Miffy, grandes y pequeñas", que se estrenó el 2 de octubre de 2015 en la misma cadena. Esta segunda serie se emite en España, en la cadena de televisión Clan RTVE.

Miffy se convirtió en conejito hembra después de que Bruna decidiera que quería dibujar un vestido en lugar de pantalones a su conejo. Dependiendo de la historia, Miffy puede tener una edad que va desde ser bebé hasta tener cuatro años.

Al principio, Miffy parecía un animal de juguete con orejas caídas pero, en 1963 ya se veía como la vemos hoy, una forma estilizada de un conejo. Miffy es dibujada con el estilo línea clara, muy pocas líneas y uno o dos colores primarios, introducido por Hergé. Bruna eligió usar solo negro, blanco, los colores primarios (rojo, amarillo y azul), verde y naranja. Es este uso de colores primarios lo que hace a Miffy reconocible al instante, y también popular entre los preescolares, debido a sus brillantes e intensos colores sencillos.

Ahora ya hay casi 32 títulos de Miffy y muchos más de los otros personajes. Bruna ha producido un total de 124 álbumes ilustrados para niños. Los libros de Miffy contienen cada uno doce páginas de historia. Cada página tiene una ilustración y cuatro líneas de verso, la última palabra de la segunda línea rima con la última de la cuarta. Tratan sobre temas que los niños pueden entender y situaciones que enfrentarán, como ir al hospital o a la escuela, y siempre tienen un final feliz. Algunos libros no tienen texto, como "Miffy's Dream".

Los libros están impresos en pequeño formato. Bruna considera importante que su público sienta que sus libros están ahí para ellos, no para sus padres. La mayoría de los libros de Miffy están recomendados para edades entre 4 y 8 años.

Miffy nació en 1955, cuando Dick Bruna contaba a su hijo de un año historias sobre un pequeño conejo que habían visto ese mismo día.

Los libros de Bruna se han traducido a más de 50 idiomas diferentes y se han vendido más de 85 millones de copias en todo el mundo. Ha ganado muchos premios por sus libros, como el "Golden Brush" en 1990, por "Boris Beer ("El oso Boris")" y "Silver Brush" por " nijntje in de tent" ("Miffy en la tienda") en 1996. En 1997, recibió el "Silver Slate "por lieve oma pluis ("Querida abuela Bunny"), un libro donde la abuela de Miffy enferma y muere. En 2016 le concedieron el prestigioso premio trianual Max Velthuijs.

Otros personajes que aparecen en los libros son su familia: los padres de Miffy, su abuela y su abuelo paterno, su tía paterna Alicia, y el tío Brian, un amigo de la familia, que aparece en "Miffy va a volar". Miffy tendrá un nuevo hermano o hermana " kleine pluis" ("El bebé"). También tiene muchos amigos, los osos Boris y Barbara, que aparecieron por primera vez en 1989 y son pareja, Poppy Pig, que apareció en 1977 y su sobrina Grunty, Snuffy, que apareció en 1969, y otros conejitos como Aggie y Melanie. 

Miffy fue, en origen, un personaje de álbum infantil, pero su diseño se usa ahora en muchas otras cosas, como ropa, artículos de papelería, juguetes, vasos, artículos para el hogar, etc.

A principios de la década de 1990, una ilustración de Miffy sosteniendo una llave ajustable detrás de su espalda, apareció en folletos producidos por personas que tomaban acciones directas contra el programa de construcción de carreteras del gobierno del Reino Unido. Este uso no autorizado del personaje se propagó y Miffy se convirtió en mascota para los grupos involucrados en la acción directa ecológica radical.

Miffy apareció en su primer programa de televisión en 1992, llamado "Dick's bruna Miffy Storybook Classics". Cada episodio fue animado de manera tradicional y duraba aproximadamente cinco minutos. El programa se emitió en los Países Bajos, en el Reino Unido , en Canadá, en Australia y en los Estados Unidos.

De 2003 a 2007, "Miffy y sus amigos" se emitió en canales de televisión infantiles como Treehouse en Canadá y Noggin en los Estados Unidos. Luego se trasladó a la televisión pública. El programa agregó varios personajes nuevos, como la familia africana de Melanie y la familia del primo común de Boris y Bárbara, Umik. La serie fue producida por Pedri Animation BV, una compañía holandesa de animación stop-motion.

A veces se cree que Miffy es un personaje japonés, por el estilo de línea similar de Hello Kitty, creado por Sanrio en 1974. La marca Miffy es muy popular en Japón, con grandes ventas de sus productos fabricados en en país. En una entrevista para The Daily Telegraph, Bruna expresó su aversión por Hello Kitty. 

Además, el 26 de agosto de 2010, Mercis BV, en representación de Bruna, presentó una demanda contra Sanrio alegando que uno de los personajes acompañantes de Hello Kitty, un conejo llamado Cathy, infringía los derechos de autor y la marca registrada de Miffy. El 2 de noviembre de 2010, un tribunal holandés falló en contra de Sanrio y ordenó a la empresa que dejara de comercializar productos de Cathy en Bélgica, Luxemburgo y los Países Bajos. El 7 de junio de 2011, después del terremoto y tsunami de Tōhoku en Japón, Sanrio y Mercis llegaron a un acuerdo extrajudicial por el que Sanrio detendría la producción de artículos de Cathy. En lugar de continuar la batalla judicial, las dos compañías anunciaron que donarían las tarifas legales que habrían gastado en ella, a la ayuda a las víctimas del terremoto.

En la ciudad natal de Bruna, Utrecht, hay una plaza llamada así por Nijntje, Nijntjepleintje (iluminada: la placita Nijntje) y en 2006, el Centraal Museum abrió una exposición permanente, el "Dick Bruna huis" (casa de Dick Bruna).

Los homónimos de Miffy incluyen una nueva especie de insecto de Perú. Al insecto se le dio el nombre científico "Trichadenotecnum miffy" en 2008, porque su epítopo, un apéndice en su abdomen, se asemeja a un pequeño conejo.

En julio de 2014, Bruna anunció su retiro; los derechos del personaje de Miffy no se venderán.

El 16 de febrero de 2017, Dick Bruna murió a la edad de 89 años.


Algunos libros de Miffy traducidos al español



</doc>
<doc id="22021" url="https://es.wikipedia.org/wiki?curid=22021" title="Apollon (Cliente P2P)">
Apollon (Cliente P2P)

Apollon es un cliente para redes de distribución de archivos entre pares (P2P) para el proyecto KDE, distribuido bajo los términos de la licencia GNU.

Apollon utiliza el demonio giFT para comunicarse con los distintos protocolos de red, el cual debe haber sido instalado previamente. Apollon (o más justamente, giFT) soporta por el momento los protocolos FastTrack (utilizado por Kazaa), OpenFT ("Open FastTrack"), Gnutella y Ares.

Apollon cuenta con una interfaz similar a la de otros clientes de redes de archivos modernos, dividida en cinco secciones: información, búsqueda, transferencias, directorios compartidos y reproductor multimedia.

El nombre Apollon fue elegido por el dios griego de las artes, Apolo (también conocido como "Apolón").




</doc>
<doc id="22022" url="https://es.wikipedia.org/wiki?curid=22022" title="GiFT">
GiFT

giFT es un demonio (programa de computadora o servicio) creado para servir de nexo entre los distintos protocolos de redes de distribución de archivos y una interfaz gráfica. Utiliza "plugins" para cargar dinámicamente los diferentes protocolos a medida que un cliente lo solicite.

Los clientes que implementen interfaces gráficas para giFT se comunican con el proceso usando un protocolo de red ligero. Esto permite que el código del protocolo de red sea abstraído de la interfaz de usuario. giFT es escrito utilizando código multiplataforma C, que significa que puede ser compilado y ejecutado en una gran variedad de sistemas operativos. Existen varias GUI para OS como Microsoft Windows, Apple y Unix-like.

giFT (giFT Internet File Transfer) es un acrónimo recursivo, que quiere decir que una de las letras representa el propio acrónimo.
Uno de los inconvenientes del núcleo de giFT es que actualmente carece de soporte unicode, lo que impide el intercambio de archivos con nombres que contengan caracteres unicode (como "ø","ä", "å", "é" etc). También, giFT carece de muchas características necesarias para usar la red Gnutella efectivamente. 

Los protocolos soportados actualmente por giFT son: Gnutella, Ares Galaxy y OpenFT. Un plugin para FastTrack (el protocolo utilizado por Kazaa) se encuentra en estado beta, mientras que otro para OpenNap se encuentra en etapa temprana de desarrollo.

El proyecto giFT se encuentra fuertemente ligado al proyecto OpenFT, una reimplementación del protocolo FastTrack producido a través del conocimiento adquirido de la ingeniería inversa de FastTrack. OpenFT implementa nodos de búsqueda y supernodos índices al igual que FastTrack.

Para la comunicación con la interfaz gráfica utiliza un protocolo liviano, el cual permite una abstracción completa del protocolo de red utilizado. Existen múltiples interfaces disponibles para giFT, tanto para Windows, Macintosh o GNU/Linux.



</doc>
<doc id="22024" url="https://es.wikipedia.org/wiki?curid=22024" title="Demonio (desambiguación)">
Demonio (desambiguación)

Por demonio se puede entender:

Grupo musical

Software

Fenómeno Atmosférico

Demonio de Tasmania

Personajes

Fiestas

</doc>
