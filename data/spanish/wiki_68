<doc id="15216" url="https://es.wikipedia.org/wiki?curid=15216" title="Astronáutica">
Astronáutica

La astronáutica es la teoría y práctica de la navegación fuera de la atmósfera de la Tierra por parte de objetos artificiales, tripulados o no, es decir, el estudio de las trayectorias, navegación, exploración y supervivencia humana en el espacio. Abarca tanto la construcción de los vehículos espaciales como el diseño de los lanzadores que habrán de ponerlos en órbita, o llevarlos hasta los planetas, satélites naturales, asteroides, cometas, etc.

Se trata de una rama amplia y de gran complejidad, debido a las condiciones difíciles bajo las que deben funcionar los aparatos que se diseñen. En la actualidad, la exploración espacial se ha mostrado como una disciplina de gran utilidad, en la cual están participando cada vez más países.

En términos generales, los campos propios de la astronáutica, y en la que colaboran las diversas especialidades científicas y tecnológicas (astronomía, matemáticas, física, cohetería, robótica, electrónica, computación, bioingeniería, medicina, ciencia de materiales, etc.) son:


La astronáutica, en combinación con la astronomía y la astrofísica, ha dado origen y potenciado a nuevas disciplinas científicas: astrodinámica, astrofotografía, telemetría espacial, astrogeofísica, astroquímica, astrometeorología, etc.

Todo diseño de un ingenio espacial debe tomar en cuenta:

1º El medio en que se desplaza (atmósfera, espacio).

2º La utilidad a que ha sido destinado (carga, transporte de seres humanos, investigación, comunicaciones, militar, etc.).

3º El sistema de propulsión ideado y el tipo de carburante empleado (combustibles líquidos, combustibles sólidos, combinados, o de otra naturaleza).

4º La fuerza de gravedad que deben vencer al abandonar o acercarse a la Tierra u otros cuerpos celestes.

Las naves deben desplazarse, a través de la atmósfera (en el proceso de despegue o en el reingreso), y a través del espacio, orbital o interplanetario; si tienen que navegar en la atmósfera de la Tierra o de otros mundos, deben adoptar una forma aerodinámica que suele ser dada por la presencia de alas, timones de dirección, escudos refractarios. Estos elementos son esenciales en el despegue, la ascensión, el frenado, reingreso, aterrizaje. Existen naves que prescinden de la mayor parte de los elementos señalados, aunque no renuncian a alguna forma básica que les permita un frenado efectivo para emplear sistemas de paracaídas u otros que le permitan tocar la superficie de la Tierra u otros mundos de manera segura (tal fue el caso de los módulos de servicio de todas las naves de los programas Gemini y Apolo, los cuales tenían una forma cónica oponible a la fricción de la atmósfera).

Si las naves deben desplazarse en el espacio, su forma no tiene la obligación de adoptar elementos aerodinámicos, pues en ausencia de aire esos elementos son inútiles, y para proporcionar dirección a los aparatos, éstos deben hacer uso de otros mecanismos (chorros de gas direccionales, uso de los motores o de la energía orbital); por lo tanto, la forma de la nave puede responder libremente a los otros condicionantes señalados. Por ejemplo, las estaciones espaciales prescinden totalmente de elementos aerodinámicos, pues su función no es navegar en la atmósfera, sino exclusivamente en el espacio.

El diseño debe contemplar una estructura capaz de resistir las aceleraciones, el impacto de los micrometeoritos y la acción de los vientos solares, fuerzas capaces de desestabilizar cualquiera de los sistemas de las naves, inclusive de provocar su inutilización parcial o destrucción total. Esta estructura está conformada por ciertos materiales dotados de propiedades que le permite enfrentar los rigores del despegue, la navegación y el reingreso. Mediante avanzados programas computacionales, los diseñadores suelen simular las condiciones y tensiones que deberán soportar los materiales y elementos que conformarán los diversos aparatos espaciales. Los materiales cumplen con elevados estándares de resistencia al impacto de micrometeoritos, de gran capacidad refractaria del calor, capaces de resistir las enormes presiones y vibraciones que significa el despegue, la aceleración o el frenado, absorbentes al máximo posible de las mortales radiaciones espaciales, pero a la vez capaces de captar la energía lumínica mediante su aplicación en los paneles solares. Sin embargo, los materiales deben cumplir con la limitación que impone el uso de los combustibles químicos tradicionales, que exigen naves con la menor masa posible: a menor masa de la nave, menor gasto de combustible y mayores posibilidades de realizar viajes largos con retorno incluido (el caso de las astronaves); a mayor masa, mayores gastos y menores posibilidades de realizar lo anterior. Por ejemplo, la gran masa de los transbordadores de la NASA les impide realizar vuelos extraorbitales(p.ej. de exploración lunar) dado que sus reservas de combustible son limitadas. Por lo tanto, el ideal es que los materiales utilizados procuren el máximo de resistencia, solidez estructural y funcionalidad, pero con ahorro en todo lo posible de masa.

El diseño de las naves que deben trabajar en ambientes muy hostiles, con condiciones extremas de calor, frío o presión, deben contar con una tecnología que las haga soportarlas. Por ejemplo, las sondas espaciales soviéticas de nombre Venera, que exploraron Venus a partir de 1961, contemplaban en su diseño materiales capaces de resistir temperaturas que derretían el plomo, pudiendo operar por algunas horas en la superficie venusiana.

En cuanto al segundo aspecto (utilidad) los ingenios espaciales suelen clasificarse en satélites artificiales, cuando orbitan la Tierra en función de alguna utilidad específica, como fue por ejemplo el satélite ruso Sputnik I, primer objeto orbital puesto por el hombre en el espacio, en astronaves, cuando están tripuladas por al menos una persona y disponen de propulsante propio que les permite maniobrar en el espacio y/o en la atmósfera, como por ejemplo los trasbordadores, o como fueron los módulos del programa norteamericano Apolo, sondas espaciales, cuando las naves están destinadas a la investigación en dirección al espacio profundo, sea en demanda de los cuerpos celestes del Sistema Solar o fuera de él, como por ejemplo las sondas del programa Viking, de la NASA, destinadas a explorar Marte, y las estaciones espaciales, complejos orbitales en torno a la Tierra que pueden albergar un número mayor de ocupantes y con medios de supervivencia que les permitan largas estadías, como por ejemplo la estación soviética Salyut 1.

Por otra parte, la utilidad que se le asigne a una nave espacial condicionará su morfología, su masa (peso) y su tamaño. Por ejemplo, la variación en las formas, pesos y tamaños que tienen los satélites es enorme, abarcando desde la forma absolutamente esférica (como el satélite norteamericano Explorer IX, lanzado en febrero de 1961 y de sólo 6 kg de peso) hasta formas cilíndricas, cónicas, estrelladas, etc. Más condicionada puede resultar la morfología de los diversos tipos de sondas, astronaves y estaciones espaciales, en que dominan ciertas estructuras características: paneles solares, antenas, cohetes, tanques de combustible, bodegas de carga y alas(como es el caso de los transbordadores), módulos de servicio (como es el caso de las astronaves de exploración lunar), secciones modulares de construcción (como es el caso de las actuales estaciones espaciales), etc.

En cuanto al tercero (los sistemas de propulsión) y cuarto aspecto (la gravedad a vencer), la nave destinada a operar a partir de un despegue directo de la superficie terrestre, deberá ser diseñada para soportar las fuertes tensiones que significa el funcionamiento de los cohetes por un determinado espacio de tiempo. Así mismo, deberá contar con el volumen suficiente de almacenamiento de combustible, dependiendo de la misión que emprenda. Una nave tripulada destinada a la exploración de un cuerpo celeste, tiene por lo general estructuras de almacenamiento de mayor tamaño que una no tripulada, pues tiene contemplado el regreso a la Tierra en el más breve lapso de tiempo, mientras que las no tripuladas cuentan con márgenes mayores de tiempo, suelen aprovechar con eficiencia los impulsos gravitatorios y son en su mayoría desechables. El diseño deberá tener en cuenta el tipo de carburante o propulsante; hasta hoy los carburantes usados son de tipo químico, y ocupan un cierto volumen.

La cantidad y la calidad del combustible inicial, así como el sistema de propulsión, estarán en función de la masa total de la nave. A mayor masa a elevar, mayor será el gasto de combustible a utilizar, por lo que el diseño de la nave deberá contemplar las medidas de volumen y los materiales de fabricación adecuados, para sostener una estructura capaz de soportar la fuerza necesaria que la llevará al espacio, o la hará navegar en él.

Toda nave espacial, independientemente de la utilidad que tenga, está estructurada sobre la base de los siguientes sistemas operativos básicos: propulsión, navegación, energético de alimentación (almacenamiento, acumulación y distribución de la energía eléctrica) y comunicación. La propulsión suele lograrse mediante el empleo de los sistemas de cohetes; la navegación mediante el empleo de sofisticados sistemas computacionales, giroscópicos y direccionales y de alarma; la administración de la electricidad mediante baterías, paneles solares, transformadores, etc; la comunicación, mediante un sistema de radio y antenas especialmente orientadas.

Especial cuidado tiene el diseño de las naves tripuladas; fuera de todos los sistemas antedichos, las naves tripuladas, y en particular las destinadas al reingreso, cuentan con otra serie de sistemas adicionales: sistema de control de la temperatura y humedad interna, presión y provisión de aire, alimentos y líquidos, un volumen interior mínimo que permita el trabajo y el descanso de los astronautas, uno de acceso y salida de la nave por parte de sus ocupantes, un sistema de acople que permita a los astronautas acceder a otro vehículo en el espacio, en fin, todos los sistemas necesarios para la supervivencia humana. Además, cuentan con un eficiente sistema de aterrizaje, constituido por paracaídas, o por alas y trenes de aterrizaje de carácter aeronáutico, o especialmente diseñados para el descenso en otros cuerpos celestes.

El medio esencial de propulsión que tienen las naves espaciales, especialmente en su etapa de despegue, es el uso del sistema de cohetes alimentado por propergoles especiales; también son usados para su evolución orbital o para la navegación profunda. Una vez en órbita las naves pueden aprovechar el impulso inercial -a la manera de un proyectil lanzado por una honda- que les comunica movimiento propio en torno a la Tierra, para impulsarse en dirección al espacio profundo, sea en dirección a la Luna, los otros planetas o fuera del Sistema Solar.

En su forma básica, los cohetes destinados a la astronáutica responden al siguiente diseño: una forma más o menos cilíndrica que tiene en su interior, por regla general, dos contenedores en que se encuentran los propergoles a reaccionar: el de combustible (p.ej: hidrógeno líquido) y el de comburente (p.ej: oxígeno líquido). Ambos se ponen en contacto en el momento del encendido en una cámara de ignición inferior; los gases producidos en la combustión son eyectados al exterior través de una tobera. Gracias al principio de acción y reacción la eyección del gas en un sentido provoca el movimiento de la nave en el sentido opuesto. La velocidad de la nave, si sólo se toma en cuenta la fuerza de empuje proporcionada por los cohetes, dependerá de la velocidad de eyección de los gases, y ésta aumentará en la medida en que se calienten y disminuyan su densidad.

Los combustibles más usados son la hidracina, el queroseno, el hidrógeno líquido y el amoniaco líquido. Los oxidantes más usados son el oxígeno líquido, el peróxido de nitrógeno y el peróxido de hidrógeno.

Las técnicas de lanzamiento suponen, dada la casi imposibilidad de obtener el empuje a partir de un único sistema de cohetes, la aplicación de un sistema compuesto, es decir, un vehículo en varias etapas o secciones dotadas de carburante propio, que se van desprendiendo en la medida en que lo van agotando, Los vehículos conocidos se trasladan a velocidad mas o menos constante. El cohete lo hace acelerando fuertemente al iniciar su marcha al mismo tiempo que disminuye notablemente su masa. Esta gran aceleración contribuye a disminuir notablemente la pérdida por gravitación. Este diseño llegó al extremo con los gigantescos y poderosos cohetes Saturno V (de tres fases) capaces de elevar 130 toneladas a una órbita baja y lanzar 45 toneladas en dirección a la Luna; un nuevo avance lo constituyó el sistema compuesto de los transbordadores espaciales, estructurado sobre la base de dos cohetes laterales y un gran contenedor central que alimenta el motor de las lanzaderas.

El tipo de propulsante que utilizan las astronaves en la actualidad, tanto para despegar como para navegar en el espacio, es el constituido por los combustibles químicos, ya sean en estado líquido o sólido, aunque tienen el inconveniente que sirven sólo para cortos períodos de aceleración, ya que se agotan rápidamente una vez producida la ignición. Un futuro prometedor tiene la aplicación de propulsión iónica, la cual permite largos períodos de aceleración en viajes de mayor distancia, con un costo relativamente bajo y con la posibilidad teórica de alcanzar grandes velocidades.

Otros sistemas de propulsión propuestos se encuentran en etapa de investigación teórica. Ejemplos son: la propulsión lumínica (la aceleración se obtendría mediante la proyección de rayos luminosos); la propulsión mediante velas solares (la aceleración se obtendría mediante la captación del viento solar); la propulsión nuclear (la aceleración se obtendría mediante una serie de explosiones nucleares controladas). Esta última ha sido prohibida por tratados internacionales, poniendo fin a antiguos proyectos, como el Orión, consistente en una nave interestelar capaz de alcanzar, teóricamente, velocidades prácticamente lumínicas. Todos estos proyectos tienen como dificultad práctica el que las aceleraciones obtenidas son muy progresivas, lo que implica dificultad en su aplicación en los espacios cercanos a la Tierra, estando más bien diseñados para vuelos en el espacio profundo.

Mientras no se descubra algún principio de propulsión totalmente ajeno a la ciencia y tecnología actuales, seguirá siendo la propulsión convencional mediante cohetes, a partir de la ignición de combustibles químicos, el principal medio de obtener una aceleración rápida de las naves espaciales

Este tema tiene relación con las velocidades de escape que deben alcanzar los ingenios espaciales al momento de despegar de la Tierra o de otro cuerpo celeste, las velocidades mínimas que deben adquirir para sostener una órbita segura en torno a la Tierra y los otros cuerpos, la velocidad mínima que deben adquirir para alcanzar éstos o abandonar el Sistema Solar. El tema incluye el cálculo, la ejecución y seguimiento de los movimientos orbitales de las naves en torno a los cuerpos celestes, las diferentes alturas a alcanzar en la realización de las órbitas, la determinación de las trayectorias más eficientes en términos de gasto de combustible y tiempo de aquellas naves que pretenden alcanzar los mundos del Sistema Solar, tanto interiores como exteriores; así mismo, se aborda el cálculo de las trayectorias de reingreso de las naves a la atmósfera de la Tierra.

Respecto a las velocidades que deben alcanzar las naves, existe una primera llamada de satelización (7,9 km/s,), que es la velocidad mínima que les permite sostener una órbita circular sin caer a la Tierra. Al aumentar la velocidad, las órbitas serán cada vez más elípticas. Al alcanzar los 11,2 km/seg (velocidad parabólica) la nave se libera de la atracción gravitatoria de la Tierra y entra en la del Sol a la manera de un pequeño asteroide. Al alcanzar los 42 km/s (velocidad hiperbólica) la nave es capaz de liberarse de la atracción del Sol, y escapar del sistema solar.

Cuanto más cerca se encuentre una nave orbitando la Tierra, más rápido deberá moverse para sostener su órbita; de lo contrario, caerá en las capas altas de la atmósfera. Por lo tanto, el período de vida orbital de toda nave dependerá de la altura que hayan alcanzado (p. ej. el satélite Explorer I tenía una velocidad de 28 000 km/h para alcanzar un apogeo de 2475 km a partir de la superficie). La duración de la órbita de una nave dependerá de la distancia en altura que haya alcanzado.

Las órbitas satelitales pueden ser descritas en cualquier sentido en relación al Ecuador terrestre, aunque se prefieren trayectorias predeterminadas que permitan un seguro rastreo por parte de las estaciones de Tierra.

En cuanto a las trayectorias y velocidades requeridas para la exploración de la Luna, las naves deben alcanzar el punto de equilibrio entre la atracción terrestre y la lunar. La velocidad establecida para alcanzar este punto es de 10,9 km/s, lo que permite a los artefactos orbitar la Luna sin el peligro de estrellarse en su superficie o pasar de largo. Debido a que la Luna tiene una fuerza de gravedad inferior a la de la Tierra, su velocidad de escape es de 2.3 km/s. 

Las velocidades y trayectorias elípticas, que llevan a las naves a la exploración del resto de los cuerpos celestes del Sistema Solar, plantea condiciones de cálculo de trayectorias y velocidades más difíciles, pues se deben tomar en cuenta una serie de factores: movimiento de la Tierra, atracción gravitatoria del Sol y de los planetas, cercanía o lejanía del cuerpo a explorar, velocidad de dichos cuerpos, capacidad de combustible y empuje desarrollados por la nave. En términos generales, resulta más fácil para los científicos y controladores la exploración de los mundos interiores del Sistema Solar que los mundos exteriores; en el primer caso las naves aprovechan la fuerza gravitatoria del Sol, mientras que en el segundo deben vencer dicha fuerza, y la de los otros cuerpos mediante un mayor gasto de combustible, y efectuando complejos cálculos de trayectorias que las hagan alcanzar su objetivo. En este último caso, las trayectorias elegidas suelen ser las más largas, pero las más económicas en términos de gasto de combustible. Básicamente, las naves destinadas a los mundos exteriores, lanzadas en dirección al Este, deben aprovechar la fuerza inercial que les otorga el movimiento de rotación de la Tierra(unos 1.670 km/h), a lo que suman su propio impulso proporcionado por los cohetes.

Previamente a la realización del viaje a lo largo de la trayectoria elegida, las naves deben ser colocadas en una órbita terrestre llamada de aparcamiento.

El mejor momento para iniciar el viaje a los planetas interiores(como es el caso de Venus) es cuando éstos se encuentran en conjunción, es decir, entre la Tierra y el Sol. En cambio, para iniciar el viaje a los planetas exteriores(como es el caso de Marte) se debe esperar el momento en que éstos se encuentran en oposición, es decir, de la parte opuesta del Sol respecto a la Tierra.

Durante la navegación espacial, las naves deben ir controlando permanentemente su ruta mediante la guía de poderosas computadoras, tanto a bordo como ubicadas en Tierra. Sorprenden los extraordinarios logros alcanzados en materia del cálculo y control en la época previa a la invención de los microprocesadores, con limitadas velocidades de procesamiento y de memoria por parte de los ordenadores. En órbita en torno a la Tierra, el horizonte del planeta es una referencia válida para la orientación de las naves. Durante la navegación profunda, la computadora interna de la nave suele guiarla usando una serie de referencias estelares. La estrella Canopus es la más usada como guía.

En toda navegación, e incluso en el despegue y en el aterrizaje, juega un importante papel el sistema de alarma. Este sistema tiene como finalidad avisar a los tripulantes y/o a las computadoras a bordo, merced a las órdenes de Tierra, que se deben corregir situaciones de posición, trayectoria, impulso, movimiento, u otros, o bien activar protocolos de misión, o detectar fallos en los sistemas, o, en el peor de los casos, avisar de un peligro real. Tanto el sistema de alarma del control en Tierra como el de la propia nave están interconectados, aunque en la medida en que éstas se alejen de aquel en dirección a los astros el sistema interno de la nave pasa a jugar un papel más autónomo.

Las técnicas de lanzamiento contemplan cuidadosos controles internos de los sistemas de la nave, regidos por una cuenta regresiva, y un cuidadoso control de las condiciones del tiempo atmosférico. Una vez terminada la cuenta comienza la ignición de la fase inicial del sistema de cohetes. Este momento reviste especial dramatismo, en especial para las tripulaciones que pueden encontrarse a bordo. La nave acelera con constantes impulsos para alcanzar la velocidad requerida. Las fuertes tensiones, el ruido y los movimientos que genera el empuje, pone a prueba la resistencia de los materiales y el entrenamiento de los astronautas. Una vez alcanzadas las capas superiores de la atmósfera el rozamiento de la nave disminuye, así como el ruido y el movimiento. Las diversas secciones de la nave se van desprendiendo una a una y la nave entra en la órbita asignada.

Otras técnicas de lanzamiento están en fase de propuesta teórica: "Catapultas electromagnéticas" proporcionarían la aceleración de las naves mediante largas rampas de lanzamiento, aplicando el principio del electromagnetismo, a modo de un "cañón espacial". También se ha pensado en la construcción de un ascensor espacial, mediante un sistema de anclaje puesto en órbita. La propuesta más factible, es la construcción de una lanzadera que despegue a manera de un avión convencional, o que sea lanzada a una órbita baja por un transporte aéreo de gran altura.

La fase de descenso a la Tierra genera otra serie de inconvenientes que deben ser resueltos. En primer lugar, determinar y acertar el ángulo correcto de re-entrada a la atmósfera, un verdadero "corredor" de ingreso. El ángulo no puede ser ni muy oblicuo ni muy vertical. Un ángulo muy vertical provocaría que la nave se estrellase prácticamente con la capa de aire, aumentando fuertemente la fricción y el calor, lo que ocasionaría su destrucción. Por el contrario, un ángulo demasiado oblicuo y a mucha velocidad hará que la nave rebote en las capas superiores, describiendo una parábola y pasando de largo; a menor velocidad la nave rebotará, pero ingresará en la atmósfera más allá del punto fijado como óptimo. En un ángulo correcto y a la velocidad correcta, la nave cortará progresivamente las capas atmosféricas superiores, disminuirá su velocidad, y reducirá los niveles de roce y calor. Previamente al re-ingreso, la nave enciende sus cohetes de frenado, disminuyendo drásticamente su velocidad y perdiendo altura; durante el proceso la nave debe ser girada en tal forma que ofrezca su flanco más resistente a la zona de fricción. Afortunadamente, las naves poseen un eficiente escudo térmico que disipa el calor.

Hasta el momento dos han sido los métodos de aterrizaje usados en las naves, en particular las tripuladas: el empleo de paracaídas, a partir de unos 15 km de altura, seguido por un amerizaje (técnica empleada por EE. UU.), o por un descenso directo en tierra (técnica empleada por la ex Unión Soviética), o bien el empleo del método aeronáutico de planeo (transbordadores de EE. UU.) seguido de un aterrizaje en una pista convencional.

Un momento de gran incertidumbre durante el re-ingreso, lo constituye el paso de las naves por la llamada franja de silencio, que dura unos cinco minutos, produciéndose en cierta región de la atmósfera, y que supone la interrupción completa de las comunicaciones radiales con el control de tierra.

Es objetivo esencial de toda misión tripulada consiste en llevar al espacio en forma segura a los seres humanos, permitirles su navegación y trabajo, y traerlos vivos y en las mejores condiciones de salud de vuelta a la Tierra. La supervivencia humana en el espacio está en función de la habilitación de un medio ambiente seguro, sea en el interior de las naves, en el exterior, al momento del despegue, en la navegación, en la exploración directa de los cuerpos celestes(ej: en el alunizaje), en el trabajo exterior, y en el re-ingreso y aterrizaje de las naves. El diseño de este medio debe recrear al máximo posible las condiciones que el organismo humano encuentra en la superficie terrestre, vale decir, de presión, temperatura, humedad, respiración, procesos alimenticios, aseo, desechos orgánicos, ejercicio, descanso y sueño. Para lograr esto, la bioingeniería debe tomar en cuenta los factores hostiles que presenta el espacio al cuerpo humano y que no suelen encontrarse en la Tierra: el vacío espacial y la carencia absoluta de aire, las violentas oscilaciones térmicas, la acción del viento solar y los rayos cósmicos, la presencia de los micrometeoritos, la ausencia de gravedad, el rompimiento de los patrones de día y noche, etc; a esto se suma el espacio reducido en que deben trabajar los astronautas en el interior de sus naves y la obligada convivencia entre ellos. Un factor clave en la supervivencia humana, es el diseño interior y exterior de las astronaves y estaciones espaciales, así como el diseño de los trajes espaciales.

Para enfrentar las difíciles condiciones del despegue, del espacio y el re-ingreso, los astronautas se someten a programas de riguroso entrenamiento que intentan simular las diversas situaciones: respuesta frente a la aceleración extrema, a la ingravidez, a la navegación, al confinamiento, a la convivencia, al trabajo, a la manutención, a enfrentar situaciones imprevistas, al re-ingreso en la atmósfera. Sólo los sujetos más aptos psicológica y físicamente serán los seleccionados para las misiones.

El primer problema que plantea el viaje espacial es el despegue mismo. Mientras no se descubra o invente algo totalmente distinto, la aplicación de fuerza bruta seguirá siendo la forma más eficaz de elevar una nave al espacio, por lo que los astronautas deberán seguir soportando las fuertes tensiones que genera una aceleración violenta. En esta fase es fundamental la utilización de los trajes y sillas especialmente acondicionados para aminorar sus efectos.

En segundo lugar está el problema de la ingravidez. La ingravidez obliga al cuerpo humano a re-acondicionar todos sus sistemas, en especial, el cardiovascular, el óseo y el muscular. La ingravidez provoca, durante los trayectos largos, la pérdida de tejido óseo y muscular, lo que afecta incluso al corazón. Estos efectos negativos son combatidos mediante rigurosas rutinas de ejercicio, lo que contrarresta, en parte, la pérdida de tejido.

La ingravidez ocasiona que las funciones más básicas, como alimentarse y beber líquidos, sean experiencias complejas; las partículas y los líquidos tienden a flotar libremente por el interior de la nave, lo que puede ocasionar desperfectos; alimentos y líquidos son llevados especialmente preparados(compactos, herméticamente sellados). Otro problema es la evacuación de los desechos orgánicos del cuerpo, los cuales suelen ser procesados, almacenados y sellados para un posterior análisis.

La ingravidez presenta especiales problemas al trabajo extra-vehicular de los astronautas, que resulta muy complejo en gravedad cero, pues existe la posibilidad de alejarse accidentalmente en el espacio, el cuerpo tiende a girar al realizar movimientos al trabajar con llaves de apriete, los medios de locomoción son limitados, etc; y a todo esto se suma la rigidez del traje espacial.

Dada la ausencia total de atmósfera en el espacio, todo el aire respirable, así como los líquidos, deben ser llevados íntegramente de la Tierra. Es tarea esencial de los sensores a bordo el monitoreo constante de los niveles de oxígeno y de dióxido de carbono, así como de la presión. El dióxido de carbono sobrante es absorbido por materiales adecuados. Por otra parte, técnicas de generación del oxígeno a partir de un ciclo natural, con la presencia de algas resistentes a los rayos cósmicos, se han ensayado desde la década de 1960. En este sentido el alga chlorella es muy fácil de cultivar, se reproduce rápido y hasta se puede comer. Por su parte, el reciclaje del agua usada está dentro de las funciones de las misiones.

Es necesaria la manutención de la temperatura ambiente en torno a unos 20 °C. El sistema eléctrico juega un papel capital en la calefacción o en la extracción del calor interno. Las violentas oscilaciones térmicas externas obligan al uso de materiales de revestimiento exterior (refractarios al calor durante la exposición al Sol) e interior (que impide la disipación del calor interior). Es conveniente que las naves giren lentamente sobre sí mismas para evitar recalentamientos; también se puede revestir el vehículo, entre las paredes exteriores e interiores, de una capa de fluidos destinados a absorber el calor. Además, las naves cuentan con mecanismos de absorción de energía solar y transmisión al interior para su aprovechamiento en los momentos en que orbitan el lado oscuro de la Tierra.

Inclusive en el interior de naves no tripuladas, se debe mantener una temperatura adecuada y una atmósfera de aire para evitar el mal funcionamiento de los instrumentos.

También es difícil la adaptación de los astronautas a sus nuevos patrones de vigilia y sueño, dado que el ciclo natural diurno y nocturno se rompe. En la medida de lo posible, se trata de mantener los ciclos de 24 h, estableciendo horarios de descanso, trabajo y recreación.

Los astronautas deben adaptarse a trabajar en espacios más bien pequeños. Al principio de la exploración espacial la movilidad era muy reducida. Con el programa Apolo aumentó un tanto el espacio disponible; pero fue gracias a la implementación de las estaciones espaciales y los transbordadores que los astronautas encontraron mayores disponibilidades de espacio, lo que les ha permitido un trabajo más holgado, algo de privacidad, y la realización de ejercicios. Aun así, los espacios habitables siguen siendo agobiantemente reducidos.

La presencia de los compañeros ayuda al astronauta disipar el fuerte sentimiento de soledad y lejanía que se experimenta en el espacio, pero a la vez obliga a convivir y a soportar caracteres que pueden mostrarse disímiles. Sólo la selección de equipos de trabajo muy afianzados, con una mentalidad muy profesional, ayuda a enfrentar los posibles problemas de convivencia, en especial si las misiones son de largo aliento. La estabilidad psicológica de los astronautas es uno de los objetivos esenciales del programa de supervivencia espacial, permitiéndoseles cultivar sus espacios recreativos, de ocio y comunicación con sus familiares en Tierra.

Otra preocupación es la acción de las radiaciones solares y cósmicas, que son nocivas para la salud. Aun disponiendo de los mejores revestimientos absorbentes, tanto en el exterior como en el interior de las naves, y en los trajes espaciales, el cuerpo humano está sometido a mayores niveles de radiación que en la superficie de la Tierra, con consecuencias a largo plazo imprevisibles.

Otro motivo de preocupación es el impacto de los micrometeoritos, los cuales pueden perforar el casco de las nave o estropear el instrumental. Frente a esto, las paredes de las naves ofrecen una cierta protección, aunque no por cierto frente a objetos de mayor tamaño, los cuales podrían impactar a decenas de miles de km/h. Afortunadamente, la probabilidad de ser impactado por un meteorito de mayor tamaño es ínfima, dada la extensión del espacio. Mayor peligro revisten los desechos espaciales, es decir, las miríadas de objetos que orbitan la Tierra y que constituyen los restos de anteriores misiones: la “chatarra espacial”, que está formada por objetos que pueden ser de dimensiones minúsculas (p.ej: una tuerca desprendida accidentalmente) o del tamaño de un autobús (p.ej: antiguos satélites en desuso). Aunque no se hayan reportado accidentes graves, estos no se pueden descartar. A pesar de que las principales agencias llevan un cuidadoso rastreo de los objetos de mayor tamaño en desuso, existen miles que no son detectados, y aunque la mayoría de ellos termina por caer tarde o temprano en la atmósfera, existen otros tantos que se mantendrán en órbita por miles de años. La basura espacial, en progresivo aumento, constituye, de no tomarse medidas de contención radicales, una serie amenaza para la navegación orbital futura.

Como se ha dicho anteriormente, el traje espacial reviste capital importancia para la supervivencia humana. Básicamente, el traje está formado por cuatro unidades esenciales: el casco, el cuerpo del traje, los guantes y el sistema de supervivencia (reservas de aire, batería, sistema de comunicación, etc.), adosado en su mayor parte en la espalda del astronauta a modo de una mochila. El traje es fabricado con una serie de materiales, dispuestos en sucesivas capas de menor o mayor densidad, que le permite mantener la presión de aire, la temperatura interna, controlar la humedad, absorber hasta cierto punto las radiaciones nocivas, defender al astronauta del impacto de ciertos micrometeoritos, y hasta, en ocasiones, recoger los desechos orgánicos. No obstante, el traje sólo permite una movilidad más bien reducida, dada su rigidez. La utilización del traje permite soportar mejor las tensiones del despegue y del aterrizaje, del trabajo en el espacio extravehicular (manutención, experimentación, implementación de equipos) o en la exploración del suelo lunar. Además, es la mejor garantía de supervivencia en caso de darse una situación extrema.

Pero los astronautas no sólo deben sobrevivir a la misión misma, sino que también a su readaptación a las condiciones de la Tierra. Para esto tienen que seguir rigurosos programas médicos de apoyo para que los cuerpos recuperen sus plenas capacidades en proceso de atrofia durante la misión.

La supervivencia humana precisa una buena dosis de iniciativa y trabajo en equipo en caso de situaciones imprevistas o, peor aún, peligro extremo, como fue el accidentado viaje del Apolo XIII, astronave que en misión a la Luna, sufrió graves desperfectos, obligando a su tripulación a desplegar toda su inteligencia para volver sana y salva a la Tierra. Los astronautas tienen plena conciencia de que se encuentran solos, y que las soluciones prácticas de las contingencias depende sólo de ellos.

El alto riesgo de la exploración espacial tripulada es un factor que siempre estará presente en todas las misiones. El vuelo espacial tripulado no es algo “rutinario”, aunque lo pueda parecer para el público general. Las grandes agencias lo han aprendido a costa de sonados fracasos, como fueron los dos grandes accidentes mortales que afectaron a los transbordadores Challenger y Columbia. En la actualidad, las agencias, en particular la NASA, han optado por la política de no escatimar gastos en materia de seguridad y supervivencia humana en el espacio.

Asociada a la supervivencia humana en el espacio está el tema de la supervivencia en otros mundos, tema que corresponde al de la exploración y colonización del espacio.

La comunicación espacial tiene como objetivo la transmisión de información desde y hacia la Tierra o entre naves que se encuentren operando en un determinado sector del espacio. La necesidad de comunicación ha dado origen a la telemetría espacial, la que tiene por finalidad el llevar el rastreo del movimiento de las naves, así como la predicción de sus posiciones en el espacio y la transmisión de datos. Un papel fundamental de la comunicación espacial, tanto entre las naves y la Tierra, como entre las mismas naves, lo juega, sin duda, el empleo de las ondas de radio, en su diversas gamas y frecuencias, y en menor medida, el empleo de medios ópticos y lumínicos. La comunicación radial debe tomar en cuenta, en primer lugar, la distancia entre las fuentes emisoras y receptoras, que determinará el tiempo transcurrido entre la emisión y la recepción de los mensajes: poco en las inmediaciones de la Tierra,y mucho, en términos relativos, para las naves que se encuentran en el espacio profundo y que establecen contacto con nuestro planeta. Este último aspecto ha estimulado, en el desarrollo de las misiones de exploración a los mundos lejanos, la utilización de sistemas computacionales y robóticos cada vez con mayores grados de autonomía; de esta manera se suple en parte la lentitud de las comunicaciones.

Junto con la exploración del espacio ha estado desde siempre en los sueños de los padres de la astronáutica, así como en todos sus continuadores, sin exceptuar ninguna de las agencias y naciones comprometidas en los diversos programas, así como en la mente de los escritores de ciencia-ficción, la eventual colonización del espacio, sea en términos del espacio orbital terrestre como el del espacio profundo, vale decir, la colonización de los cuerpos celestes que conforman el Sistema Solar, y, por qué no decirlo, de la Galaxia si fuera posible. El porqué de este anhelo humano obedece, simplemente, a la necesidad de la especie de habilitar nuevos hábitats que favorezcan su desarrollo; el espacio no puede ser la excepción. Escritores como Isaac Asimov, Carl Sagan y otros han postulado que la expansión y colonización espacial es el medio que evitará el estancamiento y retroceso de la especie humana, así como su destrucción fortuita o, peor aún, su autodestrucción. Recientemente, el físico Stephen Hawking ha reafirmado esta tesis, alertando a la humanidad acerca de la necesidad urgente de colonizar el espacio como un medio de evitar la extinción. En lo inmediato, la colonización del espacio ha reportado grandes dividendos tecnológicos, en términos de investigación, desarrollo de nueva tecnología espacial y productos derivados que son usados masivamente por la población humana.

Una limitante que pesa en la opinión pública, a manera de mito, son los costos económicos "prohibitivos" que supondría la exploración y colonización del espacio, a pesar de que en la práctica y a más largo plazo, la actividad astronáutica devuelve con creces cada dólar, euro o rublo invertida en ella.

Al margen de lo anterior, las acciones tendentes a la exploración y la ocupación progresiva del espacio cercano, por los diferentes entes que participan o participaron en esta aventura, han estado dictadas por múltiples intereses, que no son excluyentes entre sí: prestigio político, finalidad militar, satisfacción de ciertas demandas tecnológicas de algún sector de la industria, necesidades comunicacionales, climáticas y geográficas, o el conocimiento científico puro, etc.

Tales intereses se han concretado en las siguientes acciones generales de exploración y colonización:


Las estaciones han posibilitado la creación de ambientes más amplios y acogedores para los astronautas, la posibilidad de realizar experimentos científicos sin los acotados límites de tiempo con que cuentan las astronaves; las estaciones son puntos de observación directa de las condiciones climáticas y otra índole que se dan en la Tierra, la estadía en las estaciones ha permitido estudiar en detalle el comportamiento psicológico y fisiológico del hombre, ya sea en soledad o en compañía. En ciernes está la posibilidad de usar las estaciones como puertos de embarque hacia otros mundos del Sistema Solar.

La presencia humana en el espacio, esta vez de manera permanente, plantea nuevos desafíos e interrogantes acerca de los costos y beneficios que supone la colonización, acerca del comportamiento de la fisiología humana y sus posibilidades de adaptación al entorno espacial y de otros mundos, acerca de las posibilidades efectivas de ocupar los mundos cercanos, vale decir, la Luna y Marte, y acerca de las posibilidades futuras de autosustentación de la colonización.

La primera mención de un vuelo de tipo "astronáutico" está consignado en el mito griego de Dédalo e Ícaro, quienes se fabricaron alas de plumas unidas por cera para escapar de Creta; el último tuvo la temeridad de volar en dirección al Sol, pagando con su vida la extrema curiosidad, al derretírsele la cera que unía sus alas.

Durante siglos el tema del acceso humano a los otros cuerpos celestes se trató en forma pintoresca y sin fundamento científico. Fue a partir de la obra de Kepler en que se fundaron las bases teóricas de la futura Astronáutica, al describir las leyes que rigen los movimientos de los cuerpos celestes. Cyrano de Bergerac en su "Historia cómica de un viaje a la Luna" (1650) describe por primera vez el uso de un sistema compuesto de cohetes de pólvora capaz de elevar una nave en dirección a la Luna.

La Astronáutica recibió un nuevo impulso con la obra de Julio Verne "De la Tierra a la Luna" (1866) en que el autor describe, con poco rigor científico, un viaje a la Luna mediante un sistema balístico. La obra de Verne estimuló el interés por la Astronáutica y dio origen al prolífico género literario de la ciencia ficción, la cual tiene en los viajes astronáuticos una inagotable fuente de inspiración.

El verdadero abuelo de la Astronáutica fue el ingeniero peruano Pedro Paulet quien basó sus estudios en el desplazamiento del calamar, cuyo estudio le dio la idea del desplazamiento mediante la propulsión a chorro, que actualmente usan los cohetes espaciales. Este invento se difundió en una serie de sellos de correos estadounidenses, con colaboración de la NASA, en el año 1974, al cumplirse 100 años del nacimiento del peruano. Científicos como el ruso Konstantín Tsiolkovski (1857-1935), el norteamericano Robert Goddard (1882-1945) y el rumano Hermann Oberth (1894-1989) trabajaron por separado y establecieron las bases teóricas y prácticas de la Astronáutica actual.
En 1927 se fundó en Breslau la Sociedad Astronáutica, que fue frecuentada por Oberth, Werner von Braun y otros.

Un salto significativo en el desarrollo de la Astronáutica fue la fabricación y utilización para fines militares, por obra de los nazis, de los cohetes V2, que serían el modelo tecnológico que usarían los rusos y los norteamericanos para sus propios ingenios espaciales en la década siguiente, después de la Segunda Guerra Mundial.

Durante la década de 1950, rusos y norteamericanos compitieron por llevar el primer objeto al espacio orbital. El mérito lo tienen los rusos, los cuales pusieron en órbita el primer satélite artificial, el Sputnik I (4 de octubre de 1957), hito que marca el comienzo oficial de la Astronáutica práctica. A esto siguió el primer vuelo espacial orbital realizado por un hombre, hazaña que correspondió nuevamente a la rusos, al enviar al espacio al cosmonauta Yuri Gagarin (12 de abril de 1961). Por su parte, los norteamericanos respondieron con los programas Gémini y Apolo, destinados a llevar al hombre a la Luna. Hitos de este objetivo fueron el viaje circumlunar del Apolo VIII (21 al 27 de diciembre de 1968), que demostró la posibilidad práctica de alcanzar, mediante un vuelo tripulado por el espacio profundo, otro astro del Sistema Solar; y, como es natural, el primer desembarco en la Luna realizado por la tripulación del Apolo XI, el 20 de julio de 1969 (21,57, hora del centro espacial de Houston) y 2,57 GMT del 21 de julio: los astronautas Neil Armstrong y Buzz Aldrin pusieron pie en la Luna y exploraron por algunas horas su superficie, mientras su compañero Michael Collins esperaba en órbita.























Además de los programas espaciales bien consolidados de Estados Unidos, la URSS, Japón y Europa (a través de la Agencia Espacial Europea), se ha producido el florecimiento a partir de los años 1980 de programas espaciales en países en vías de desarrollo, ya sea en naciones con cierta tradición como China (tercera agencia espacial que ha llevado a cabo misiones tripuladas, después de Estados Unidos y Rusia) o la India (que posee lanzadores de satélites propios) como en otras que han empezado recientemente. Son destacables los programas espaciales de Brasil, México, Chile y Argentina.

Para algunos países en vías de desarrollo, los satélites artificiales han supuesto la forma más fácil de mejorar sus redes internas de telecomunicaciones, en especial en aquellos cuya orografía u otras causas hacen difíciles los medios de comunicación tradicionales. Tal es el caso de los satélites domésticos que emplea Indonesia, o la serie de satélites compartidos por las naciones árabes (Arabsat).

El primer satélite lanzado por un país del continente americano fue el "Explorer 1" de EEUU, lanzado el 31 de enero de 1958 a bordo de un cohete Jupiter C (antecesor del Juno I). Posteriormente Brasil, con sus cohetes VLS (""Veículo Lançador de Satélites"") y VSB-30, se convirtió el 24 de octubre de 2004, en la segunda potencia espacial americana. Y por último Argentina lanzo en 2007 Tronador I y Tronador II (en desarrollo), convirtiéndose en unas de las potencias espaciales americanas.

El 11 de febrero de 1970 Japón puso en órbita su primer satélite lanzado con un cohete nacional. El 24 de abril del mismo año le siguió China, con su cohete Larga Marcha, poniendo en órbita otro satélite. Algo más tarde, se les unirá India, que logra su primer lanzamiento exitoso el 18 de junio de 1980 con el cohete SLV, al que le seguirán el PSLV y el GSLV.

El primer satélite artificial del mundo fue desarrollado y lanzado por la URSS (luego Rusia) el 4 de octubre de 1957. Se trataba del "Sputnik 1", de 83,6 kg de peso, para cuya satelización se empleó el cohete R-7. En la Europa occidental, Francia desarrolló y lanzó el cohete Diamant, poniendo en órbita el 26 de noviembre de 1965 su satélite "Asterix A1".

El tercer país europeo en disponer de capacidad de acceso propio al espacio sería el Reino Unido, que en octubre de 1971 puso en órbita su satélite "Prospero X-3" gracias a un cohete de fabricación totalmente británica, el Black Arrow.

Entre 1963 y 1973 una conferencia internacional de países de la Europa occidental, dirigida por Reino Unido, Francia y Alemania, trató de poner en marcha un programa espacial integrado por los proyectos de cohete Europa I y Europa II. Posteriormente, tras el fracaso de todos los prototipos anteriores, surgió la ESA en 1974, cuyo cohete Ariane obtuvo su primer éxito el 24 de diciembre de 1979.

Desde 1999 Ucrania dispone del cohete lanzador de satélites Dnepr-1.

Existe antecedentes de avances en la materia a en la segunda mitad del siglo XX cuando el presidente Adolfo López Mateos emitió un decreto en el Diario Oficial de la Federación del 31 de agosto de 1962 que creó la Comisión Nacional del Espacio Exterior (CONEE), adscrita a la Secretaría de Comunicaciones y Transportes con el fin de fomentar la investigación, explotación y utilización pacífica del espacio exterior; Comisión que continuó con los trabajos de cohetería, telecomunicaciones y estudios atmosféricos en el país.

México cuenta actualmente con ocho satélites y con la empresa ex profeso SATMEX.

Actualmente la Agencia Espacial Mexicana (AEM) es una agencia recién creada (31 de julio de 2010) encargada de asuntos espaciales. Este proyecto pretende agrupar y coordinar los trabajos de México en actividades espaciales.
La situación de la astronáutica en España está a un nivel algo inferior al que correspondería a su nivel de desarrollo, careciendo de capacidad de lanzamiento de satélites.

El 15 de noviembre de 1974 se lanza el Intasat, primer satélite español, en un cohete Delta estadounidense. Durante las décadas de 1970 y 1980, se realizaron numerosos lanzamientos de cohetes sonda suborbitales desde la base de El Arenosillo, el más avanzado de los cuales fue el INTA-300. A principios de la década de 1990, se proyectó la construcción de un lanzador orbital de microsatélites (hasta 50 kg), denominado Capricornio, desarrollado por el Instituto Nacional de Técnica Aeroespacial, pero finalmente fue cancelado por razones presupuestarias. Fue en esta época en que varias universidades españolas se interesaron por los microsatélites, pero al final, sólo los hicieron la Universidad Politécnica de Madrid (el UPM/LB-Sat 1 en 1995), y el propio INTA, con el Minisat 01, en 1997, el Minisat 02 y el Nanosat 01, en 2004. El primero y el tercero fueron lanzados como carga útil por cohetes Ariane de la ESA, mientras que el segundo fue puesto en órbita desde Canarias por un cohete Pegasus XL estadounidense.

El programa científico se reduce a unos pocos satélites de pequeño tamaño, como el Intasat, el Minisat y UPM Sat. En cuanto a satélites de telecomunicaciones, se dispone del programa Hispasat, que cuenta con varios satélites geoestacionarios en servicio, y el programa Amazonas, con varios satélites dedicados al mercado hispano-americano. Además, el estado español cuenta con el servicio del Spainsat y el Xtar-Eur, dedicados a comunicaciones militares y gubernamentales. También es operativo el Deimos-2, capaz de tomar imágenes de muy alta resolución, cuya función es la observación de la Tierra y el seguimiento de catástrofes.

España ha contribuido con un astronauta, Pedro Duque, que salió al espacio por primera vez en 1998, en el transbordador Discovery, y por segunda vez en la misión "Cervantes", en 2003, habitando durante diez días la Estación Espacial Internacional. Actualmente, continúa formando parte de la plantilla de astronautas de la ESA.




</doc>
<doc id="15219" url="https://es.wikipedia.org/wiki?curid=15219" title="Forth">
Forth

Forth o FORTH es un lenguaje de programación y un ambiente de programación para computadores ideado por Charles H. Moore y Elisabeth Rather entre los años 1965 y 1970 en el National Radio Astronomy Observatory de Kitt Peak, Arizona.

Su nombre es una contracción de la palabra inglesa fourth, dado que sus creadores le consideraban destinado a la cuarta generación de computadoras, pero la primera edición del lenguaje fue preparada para un IBM 1130, que solo permitía nombres con una longitud máxima de cinco letras; su nombre se quedó ya para siempre en FORTH. Forth es deletreado a veces con todas las letras en mayúsculas siguiendo el uso acostumbrado durante los primeros años, aunque el nombre no es un acrónimo.

Inicialmente diseñado para una aplicación muy concreta, la astronomía (cálculo de trayectorias de cuerpos en órbita, cromatografías, análisis de espectros de emisión), ha evolucionado hasta ser aplicable a casi todos los demás campos relacionados o no con esa rama de la ciencia (cálculos de probabilidad, bases de datos, análisis estadísticos y hasta financieros).

Posteriormente, un programa para la adquisición automática y continua de datos realizado en este lenguaje ha descubierto al menos la mitad de los cúmulos interestelares conocidos en la actualidad.

Forth es un lenguaje de programación de computadoras procedimental, estructurado, imperativo, reflexivo, basado en pila y sin comprobación de tipos. Forth ofrece tanto la ejecución interactiva de comandos (haciéndolo conveniente como shell para los sistemas que carecen de un sistema operativo más formal) como la capacidad de compilar secuencias de comandos para la ejecución posterior. Algunas implementaciones del Forth (usualmente las versiones tempranas o las escritas para ser extremadamente portable) compilan código enhebrado (threaded code), pero muchas implementaciones de hoy generan código de máquina optimizado como otros compiladores de lenguajes.

Una de sus importantes características es la utilización de una pila de datos para pasar los argumentos entre las palabras, que son los constituyentes de un programa en Forth.

Aunque no es tan popular como otros sistemas de programación, Forth tiene suficiente soporte para mantener varios vendedores y contratistas lenguaje en el negocio. Forth es usado actualmente en cargadores (boot loaders) tales como Open Firmware, aplicaciones espaciales, y otros sistemas empotrados. Una implementación de Forth por el Proyecto GNU es activamente mantenida, y su último lanzamiento fue en noviembre de 2008. El estándar de 1994 está actualmente siendo sometido a revisión, llamado provisionalmente Forth 200x.

Un ambiente Forth combina el compilador con una shell interactivo. El usuario interactivamente define y corre subrutinas, o "palabras", en una máquina virtual similar al ambiente de runtime. Las palabras pueden ser probadas, redefinidas, y depuradas a medida que el código fuente es ingresado sin recompilar o reiniciar el programa entero. Todos los elementos sintácticos, incluyendo las variables y los operadores básicos, aparecen como tales procedimientos (en forma de palabras). Incluso si una particular palabra es optimizada para no requerir una llamada de subrutina, todavía sigue también disponible como subrutina. Por otro lado, la shell puede compilar comandos interactivamente mecanografiados en código de máquina antes de correrlos. (Este comportamiento es común, pero no requerido). Los ambientes Forth varían en cómo es almacenado el programa resultante, pero idealmente, correr el programa tiene el mismo efecto que entrar manualmente el código fuente de nuevo. Esto contrasta con la combinación de C con los shells de UNIX, en donde las funciones compiladas son una clase especial de objetos de programa y los comandos interactivos son estrictamente interpretados . La mayor parte de las características únicas de Forth resultan de este principio. Al incluir la interacción, el scripting, y la compilación, Forth fue popular en los computadores con recursos limitados, tales como el BBC Micro y las series del Apple II, y permanece así en aplicaciones tales como firmware y pequeños microcontroladores. Donde los compiladores C ahora pueden generar código más compacto y con mejor desempeño, Forth conserva la ventaja de la interactividad.

Cada ambiente de programación con subrutinas implementa una pila para el flujo de control. Esta estructura típicamente también almacena las variables locales, incluyendo los parámetros de la subrutina (en un sistema de llamada por valor como en C). Con frecuencia, sin embargo, Forth no tiene variables locales, ni es llamado-por-valor. En lugar de eso, los valores intermedios son mantenidos en una segunda pila. Las palabras operan directamente en los valores superiores de esta pila. Por lo tanto, puede ser llamado la pila de "parámetro" o de "datos", pero lo más a frecuentemente simplemente "la" pila. La pila de llamada de funciones es entonces llamado la pila de retorno o del "encadenamiento" (o en inglés "linkage" o "return stack"), abreviado "rstack". Las funciones especiales de manipulación del "rstack" proporcionadas por el núcleo permiten que sea usado para el almacenamiento temporal dentro de una palabra, pero no puede ser usado de otra manera para pasar parámetros o para manipular datos.

La mayoría de las palabras son especificadas en términos de su efecto sobre la pila. Típicamente, los parámetros son colocados el tope de la pila antes de que la palabra se ejecute. Después de la ejecución, los parámetros han sido borrados y substituidos por valores de retorno. Para los operadores aritméticos, esto sigue la regla de la notación polaca inversa. Ver abajo para los ejemplos que ilustran el uso de la pila.

Forth es un lenguaje simple y extensible; su modularidad y extensibilidad permiten la escritura de programas de alto nivel tales como sistemas de CAD. Sin embargo, la extensibilidad también ayuda a que programadores pobres escriban código incomprensible, que ha dado a Forth una reputación como "lenguaje de solo escritura". Forth ha sido usado con éxito en proyectos grandes y complejos, mientras que las aplicaciones desarrolladas por profesionales competentes y disciplinados han probado ser de fácil mantenimiento en plataformas de hardware cambiantes durante décadas de uso.
Forth tiene un nicho tanto en aplicaciones astronómicas como espaciales.
Todavía hoy, Forth es usado en muchos sistemas empotrados (pequeños dispositivos computarizados), debido a su portabilidad, uso eficiente de la memoria, corto tiempo de desarrollo, y rápida velocidad de ejecución. Ha sido implementado eficientemente en procesadores RISC modernos, y han sido producidos procesadores que usan Forth como lenguaje de máquina.
Otros usos de Forth incluyen Open Firmware, boot ROMs usadas por Apple, IBM, Sun, y OLPC XO-1; y la primera estapa del controlador de arranque basada en FICL del sistema operativo FreeBSD.

Forth se desarrolló a partir del sistema de programación personal de Charles H. Moore, que había estado en desarrollo continuo desde 1958.
Forth fue expuesto por primera vez a otros programadores a principios de los años 1970, comenzando con Elizabeth Rather en el National Radio Astronomy Observatory de los Estados Unidos. Después de su trabajo en NRAO, Charles Moore y Elizabeth formaron Forth, inc. en 1973, refinando y portando sistemas Forth a docenas de otras plataformas en la siguiente década.

Forth fue nombrado así porque en 1968 "el archivo conteniendo el interpretador fue etiquetado FOURTH, por la 4.ª (siguiente) generación de software - pero el sistema operativo del IBM 1130 restringía los nombres de archivo a 5 caracteres".
Moore vio a Forth como el sucesor de compilar-encadenar-ejecutar de los lenguajes de tercera generación, o software para hardware "de cuarta generación", no en el sentido de un lenguaje de programación de cuarta generación como ha venido a ser usado el término.

Debido a que Charles Moore se había trasladado con frecuencia de un trabajo al trabajo en su carrera, una presión temprana en el lenguaje de desarrollo era la facilidad de portarlo a diversas arquitecturas de computadora. Un sistema Forth ha sido usado con frecuencia para "levantar" un nuevo hardware. Por ejemplo, Forth fue el primer software residente en el nuevo chip Intel 8086 en 1978 y MacFORTH era el primer sistema de desarrollo residente para el primer Apple Macintosh en 1984.

Comenzando en 1976, el microFORTH de Forth inc. fue desarrollado para los microprocesadores Intel 8080, Motorola 6800, y el Zilog Z80. MicroFORTH fue usado después por aficionados para generar sistemas Forth para otras arquitecturas, tales como los MOS 6502 de 1978. La amplia diseminación finalmente llevó a la estandarización del lenguaje. La práctica común era codificada en los estándares de facto de FORTH-79
y FORTH-83
de los años 1979 y 1983, respectivamente. Estos estándares fueron unificados por el ANSI en 1994, comúnmente referenciado como ANS Forth.

Forth llegó a ser muy popular en los años 1980 porque estaba bien adaptado a los pequeños microcomputadores de ese tiempo, pues es compacto y portable. Por lo menos un computador personal, el Jupiter Ace británico, tenía a Forth en su sistema operativo residente en ROM. El Canon Cat también usaba Forth para su programación de sistema. Rockwell también produjo los microcomputadores en un simple chip, el R65F11 y el R65F12, con núcleos Forth residentes.

Forth confía fuertemente en el uso explícito de un pila de datos y de la notación polaca inversa (RPN o notación postfija, comúnmente usada en calculadoras de Hewlett-Packard. En RPN, el operador es colocado después de sus operandos, a diferencia de la más común notación infija donde es colocado entre los operandos. La notación postfija hace al lenguaje más fácil analizar gramaticalmente (parse) y extender; Forth no usa una gramática BNF, y no tiene un compilador monolítico. Extender el compilador solo requiere la escritura de una nueva palabra, en vez de modificar una gramática y de cambiar la implementación subyacente.

Usando RPN, se puede conseguir al resultado de la expresión matemática (25 * 10 + 50) de esta manera:

Esta línea de comando primero pone los números y en la pila implicada.
La palabra multiplica los dos números en el tope de la pila y los sustituye por su producto.
Entonces el número se pone en la pila.
La palabra lo agrega al producto anterior. Finalmente, el comando imprime el resultado al terminal de usuario.

Incluso las características estructurales del Forth son basadas en la pila. Por ejemplo:

Este código define una nueva palabra llamada usando los comandos siguientes (otra vez, "palabra" es el término usado para una subrutina):


El texto entre paréntesis es un comentario, advirtiendo que esta palabra espera un número en la pila y retornará un número posiblemente cambiado. La palabra es equivalente a esta función escrita en el lenguaje de programación C:

Esta función se escribe más sucintamente como:

Se puede correr esta palabra como sigue:

Primero el interpretador empuja (push) un número (1 u 8) sobre la pila, después llama a FLOOR5, que retira (pop) este número otra vez y empuja el resultado. Finalmente, una llamada a "." retira el resultado de la pila y lo imprime al terminal del usuario.

El analizador sintáctico (parser) de Forth es simple, puesto que no tiene una gramática explícita. El interpretador lee una línea de entrada desde un dispositivo de entrada de usuario, la cual es entonces analizada sintácticamente para una palabra usando los espacios como delimitadores; algunos sistemas reconocen caracteres de espacio en blanco adicionales. Cuando el interpretador encuentra una palabra, intenta encontrar la palabra en el "diccionario". Si la palabra es encontrada, el interpretador ejecuta el código asociado con la palabra, y después retorna para analizar (parse) el resto del flujo de entrada (stream). Si la palabra no es encontrada, se asume que la palabra es un número, y se hace una tentativa de convertirlo el texto que lo representa en un número y de empujarlo (push) en la pila; si se tiene éxito, el interpretador continúa analizando el flujo de entrada. De lo contrario, si las operaciones de búsqueda de la palabra y la conversión del número fallan, el interpretador imprime la palabra seguida por un mensaje de error indicando que la palabra no es reconocida, se limpia (flush) el flujo de entrada, y se espera la nueva entrada del usuario.

La definición de una nueva palabra comienza con la palabra (dos puntos) y finaliza con la palabra (punto y coma). Por ejemplo:

Esto compilará la palabra , y hace el nombre hallable en el diccionario. Cuando es ejecutada al mecanografíar, por ejemplo, en la consola esto imprimirá .

La mayoría de los sistemas Forth incluyen un ensamblador especializado que produce palabras ejecutables. El ensamblador es un dialecto especial del compilador. Los ensambladores Forth frecuentemente usan una sintaxis polaca inversa en la cual los parámetros de una instrucción preceden a la instrucción. El diseño usual del ensamblador Forth es para construir la instrucción en la pila, después la copia en memoria como el paso pasado. Los registros pueden ser referidos por el nombre usado por el fabricante, numerado (0..n, según lo usado en el código de operación real) o nombrado para su propósito en el sistema Forth: ej. "S" para el registro usado como puntero de la pila.

Los sistemas Forth clásicos tradicionalmente no usan ni el sistema operativo ni el sistema de archivos. En lugar de almacenar el código en archivos, el código fuente es almacenado en bloques escritos a direcciones físicas del disco. La palabra es empleada para traducir el número de un bloque de disco de 1 KB de tamaño hacia la dirección de un buffer que contiene los datos, el cual es manejado automáticamente por el sistema Forth. Algunos sistemas implementan archivos de disco contiguos usando el acceso al disco del sistema, donde los archivos están situados en los rangos de bloques de disco fijos. Usualmente éstos se implementan como registros binarios de longitud fija, con un número entero de registros por bloque del disco. Una búsqueda rápida es alcanzada por el acceso hash en los datos clave.

La multitarea, (más comúnmente por planificación Round-robin cooperativa), está normalmente disponible (aunque las palabras multitarea y el soporte no son cubiertos por el estándar del ANSI Forth). La palabra es usada para guardar el contexto de ejecución de la tarea actual, para localizar la siguiente tarea, y restaurar su contexto de ejecución. Cada tarea tiene sus propias pilas, copias privadas de algunas variables de control y un área de scratch. Como resultado, el intercambio de tareas es simple y eficiente, Las multitareas del Forth están disponibles incluso en los microcontroladores muy simples tales como el Intel 8051, Atmel AVR, y TI MSP430.

Por contraste, algunos sistemas Forth corren bajo un sistema operativo anfitrión como Microsoft Windows, Linux o una versión de UNIX y usan el sistema de archivos del sistema operativo anfitrión para los archivos de fuente y de datos; el estándar ANSI Forth describe las palabras usadas para la entrada-salida. Otras facilidades no estándar incluyen un mecanismo para hacer llamadas al SO o al sistema de ventanas anfitrión, y muchos proporcionan extensiones que emplean la previsiones proporcionadas por el sistema operativo. Típicamente tienen un conjunto más grande y diferente de palabras que la palabra por defecto del Forth, para la creación, suspensión, destrucción y modificación de prioridad de la tarea.

Un sistema Forth con todas las facilidades, con todo el código fuente, se compilará a sí mismo, con una técnica comúnmente llamada por los programadores Forth como metacompilación (aunque el término no equivale exactamente a la metacompilación como se define normalmente). Usualmente el método consiste en redefinir un puñado de palabras que ponen bits compilados en la memoria. Las palabras del compilador usan versiones especialmente nombradas de fetch y store que son redireccionadas a un área de buffer en memoria. El área del buffer simula o accesa un área de memoria comenzando en una dirección diferente que el buffer de código. Tales compiladores definen palabras para acceder tanto a la memoria del computador destino como la memoria del computador anfitrión (compilación).

Después de que las operaciones de fetch y store son redefinidas para el espacio del código, el compilador, ensamblador, etc. son recopilados usando la nueva definición de fetch y store. Esto efectivamente rehúsa todo el código del compilador y del interpretador. Entonces, el código del sistema Forth es compilado, pero esta versión es almacenada en el buffer. El buffer en memoria es escrito al disco, y se proporcionan las maneras de cargarlo temporalmente en la memoria para pruebas. Cuando la nueva versión parece trabajar, se escribe sobre la versión previa.

Hay numerosas variaciones de tales compiladores para diversos ambientes. Para los sistemas embebidos, el código puede ser escrito en otro computador, una técnica conocida como compilación cruzada, sobre un puerto serial o aún por un solo bit TTL, mientras se mantienen los nombres de las palabras y otras partes no ejecutables del diccionario en la computadora de compilación original. Las definiciones mínimas para este compilador Forth son las palabras fetch y store para un byte, y la palabra que ordena sea ejecutada una palabra de Forth. Con frecuencia la parte que consume más tiempo de escribir un puerto remoto es construir el programa inicial para implementar fecth, store y execute, pero muchos microprocesadores modernos tienen características de depuradores integrados (tales como el Motorola CPU32) que eliminan esta tarea.

La estructura básica de datos de Forth es el "diccionario" que mapea "palabras" a código ejecutable o a estructuras de datos con nombre. El diccionario descansa en la memoria como árbol de lista encadenada con los enlaces procediendo desde la última palabra definida (la más reciente) hasta la más antigua, hasta que es encontrado un centinela, usualmente un puntero NULL. Un cambio de contexto causa que la búsqueda de la lista comience en una hoja diferente y la búsqueda de la lista encadenada continúa de tal manera que la rama se combina en el tronco principal de nuevo dirigiéndose eventualmente al centinela (NULL), la raíz (en raros casos como en meta-compilación el diccionario puede estar aislado, hay varios). El efecto es un uso sofisticado de espacio de nombres (namespaces) y críticamente puede tener el efecto de sobrecargar palabras claves, el significado es contextual.

Una palabra definida generalmente consiste en un encabezado (head) y un cuerpo (body), con el encabezado consistiendo en el "name field" (NF) y el "link field" (LF) y un cuerpo consistiendo del "code field" (CF) y el "parameter field" (PF).

El encabezado y al cuerpo de una entrada de diccionario son tratados separadamente porque ellos pueden no estar contiguos. Por ejemplo, cuando un programa de Forth es recompilado para una nueva plataforma, el,encabezado puede quedar en el computador de compilación, mientras que el cuerpo va a la nueva plataforma. En algunos ambientes (tales como sistemas empotrados) los encabezados ocupan memoria innecesariamente. Sin embargo, algunos compiladores cruzados pueden poner las cabezas en el computador destino si se espera que este computador soporte un sistema Forth interactivo.

El formato exacto de una entrada de diccionario no está prescrito, y las implementaciones varían. Sin embargo, ciertos componentes casi siempre están presentes, aunque el tamaño exacto y la orden pueden variar. Descrito como estructura, una entrada de diccionario pudo verse así:

El campo nombre comienza con un prefijo que da la longitud del nombre de la palabra (típicamente hasta 32 bytes), y varios bits para los flags. Entonces, la representación de caracteres del nombre de la palabra sigue al prefijo. Dependiendo de la implementación particular del Forth, puede haber para alineación, uno o más bytes NUL ("\0").

El campo link contiene un puntero a la palabra previamente definida. El puntero puede ser un desplazamiento relativo o una dirección absoluta que apunta al hermano anterior.

El puntero del campo del código será: o la dirección de la palabra que ejecutará el código, o datos en el campo del parámetro, o el principio del código de máquina que el procesador ejecutará directamente. Para las palabras definidas por la palabra "dos puntos" , el puntero del campo del código apunta a la palabra que guardará el puntero de instrucción actual (IP) de Forth en la pila de retorno, y carga el IP con la nueva dirección desde la cual continuar la ejecución de palabras. Esto es lo mismo que lo que hacen las instrucciones call/return del procesador.

El compilador en sí mismo consiste de palabras Forth visibles al sistema, no es un programa monolítico. Esto permite que un programador cambie las palabras del compilador para propósitos especiales.

El flag de "tiempo de compilación" en el campo nombre es ajustado para las palabras con comportamiento en "tiempo de compilación". La mayoría de las palabras simples ejecutan el mismo código si están mecanografiadas en una línea de comandos, o insertadas en otro código. Al compilar éstas, el compilador simplemente coloca el código o un puntero enhebrado (threaded pointer) hacia la palabra.

Los ejemplos clásicos de palabras de tiempo de compilación son las estructuras de control, como por ejemplo y . Todas las estructuras de control de Forth, y casi todo su compilador son implementados como palabras de tiempo de compilación. Todas las palabras de flujo de control de Forth son ejecutadas durante la compilación para compilar varias combinaciones de las palabras primitivas y (branch y branch if false). Durante la compilación, la pila de datos es usado para soportar el balanceo, anidado, y backpatching de las direcciones de bifurcación de las estructuras de control. El pequeño código de ejemplo:

será compilado como la siguiente secuencia dentro de una definición:

Los números después de representan direcciones relativas de saltos (jump). LIT es la palabra primitiva para empujar (push) un número "literal" sobre la pila de datos.

La palabra (dos puntos) analiza sintácticamente (parse)un nombre como parámetro, crea una palabra (una definición de "dos puntos") y entra en el estado de compilación. El intérprete continúa leyendo palabras delimitadas por espacio desde el dispositivo de entrada del usuario. Si una palabra es encontrada, el intérprete ejecuta la "semántica de compilación" asociada a la palabra, en vez de la "semántica de interpretación". Por defecto la semántica de compilación de una palabra es añadir su semántica de interpretación a la definición actual.

La palabra (punto y coma) finaliza la definición actual y retorna al "estado de interpretación". Ella es un ejemplo de una palabra cuya semántica de compilación difiere de la que se tiene por defecto. La semántica de interpretación de (punto y coma), la de la mayoría de las palabras de flujo de control, y la de algunas otras palabras están indefinidas en ANS Forth, lo que significa que ellas solo deben ser usadas dentro de definiciones y no en la línea interactiva de comando.

El estado del intérprete puede ser cambiado manualmente con las palabras y (corchete izquierdo y corchete derecho) entran en el estado de interpretación o en el estado de compilación, respectivamente. Estas palabras pueden ser usadas con la palabra para calcular un valor durante una compilación e insertarlo en la actual definición de dos puntos. El tiene la semántica de compilación para tomar un objeto de la pila de datos y añadir la semántica a la definición actual de dos puntos para poner ese objeto en la pila de datos.

En ANS Forth, el estado actual del intérprete puede ser leído desde el flag que contiene el valor true cuando está en estado de compilación y false en caso contrario. Esto permite la implementación de palabras de "estado inteligente" con un comportamiento que cambia según el estado actual del intérprete.

La palabra marca la definición dos puntos más reciente como una "palabra inmediata", reemplazando efectivamente su semántica de compilación por su semántica de interpretación. Las palabras inmediatas son normalmente ejecutadas durante la compilación, no se compilan, pero esto puede ser sobreescrito por el programador, en cualquier estado. es un ejemplo de una palabra inmediata. En el ANS Forth, la palabra toma un nombre como un parámetro y añade la semántica de compilación de la palabra nombrada a la definición actual, incluso si la palabra era marcado inmediata. Forth-83 definió las palabras separadas y para forzar la compilación de palabras no-inmediatas e inmediatas, respectivamente.

En ANS Forth, las palabras sin nombre pueden ser definidas con la palabra (sin nombre) que compila las palabras siguientes hasta el próximo (punto y coma) y deja un token de ejecución en la pila de datos. El token de ejecución proporciona un manejador (handle) opaco para la semántica de compilación, similar a los punteros de función del lenguaje de programación C.

Los tokens de ejecución pueden ser almacenados en variables. La palabra toma un token de ejecución de la pila de datos y realiza la semántica asociada. La palabra , (compila-coma) toma un token de ejecución de la pila de datos y añade la semántica asociada a la definición actual.

La palabra (comilla sencilla) toma el nombre de una palabra como parámetro, y retorna en la pila de datos, el token de ejecución asociado con esa palabra. En el estado de interpretación, es equivalente a .

Las palabras (dos puntos) y (tick) son ejemplos de palabras que toman sus argumentos del dispositivo de entrada del usuario en vez de la pila de datos. Otro ejemplo es la palabra (paréntesis abierto) la cual lee e ignora las siguientes palabras hasta, e incluyendo, el paréntesis cerrado y es usada para poner comentarios. Similarmente, la palabra (barra de división hacia atrás) es usada para los comentarios que continúan hasta el extremo de la línea actual. {tecla|(}} (paréntesis abierto) y (barra de división hacia atrás) son palabras como el resto, y por ello tienen que estar separadas de lo que las sigue (en este caso el comentario) por al menos un espacio en blanco.

En la mayoría de los sistemas Forth, el cuerpo de una definición de código consiste en lenguaje de máquina o una cierta forma de código enhebrado (threaded code). La Forth original que sigue el estándar informal del Forth Interest Group (FIG), es un Threaded Interpretive Language (TIL). Esto también es llamado código enhebrado indirecto (indirect-threaded code), pero el enhebrado directo (direct-threaded) y la subrutina de Forth también han llegado a ser populares en tiempos modernos. Los más rápidos Forth modernos usan enhebrado de subrutinas (subrutine threading), insertan palabras simples como macros, y realizan la optimización de peephole u otras estrategias de optimización para hacer el código más pequeño y más rápido.

Cuando una palabra es una variable u otro objeto de datos, el CF apunta al código de tiempo de ejecución asociado con la definición de la palabra que lo creó. Una palabra de definición tiene un característico "comportamiento de definición" (creando una entrada de diccionario y posiblemente asignando e inicializando un espacio para los datos) y también especifica el comportamiento de una instancia de la clase de las palabras construidas por esta palabra de definición. Los ejemplos incluyen:

Forth también proporciona una facilidad por la cual un programador puede definir las nuevas palabras de definición específicas a una aplicación, especificando tanto un comportamiento de la definición (en tiempo de compilación) como un comportamiento de la instancia (en tiempo de ejecución). Algunos ejemplos incluyen buffers circulares, bits con nombres en puertos de E/S, y arreglos automáticamente indexados.

Los objetos de datos definidos por estas palabras y similares, son globales en alcance. La función para variables locales proporcionada en otros lenguajes, en Forth es proporcionada por la pila de datos (aunque Forth también tiene variables locales reales). Comparado con otros lenguajes, el estilo de programación en Forth usa muy pocos objetos de datos con nombre; tales objetos de datos son usados típicamente para contener datos que son usados por un número de palabras o de tareas (en una implementación multitarea).

Forth no hace cumplir la consistencia en el uso de tipos de datos; es responsabilidad del programador usar los operadores apropiados para leer (fetch) y para almacenar (store) los valores o para realizar otras operaciones con los datos.

Las palabras escritas en Forth son compiladas en una forma ejecutable. Las implementaciones clásicas de "enhebrado indirecto" (indirect threaded) compilan listas de las direcciones de las palabras a ser ejecutadas; muchos sistemas modernos generan código de máquina real (incluyendo llamadas a ciertas palabras y códigos externos para otros ampliados en el mismo lugar). Algunos sistemas tienen compiladores de optimización. Hablando en términos generales, un programa Forth es guardado como la imagen de memoria del programa compilado con un solo comando (ej., RUN) que es ejecutado cuandoes cargada la versión compilada.

Durante el desarrollo, el programador usa al interpretador para ejecutar y probar cada pequeña pieza a medida que es desarrollada. Por lo tanto, la mayoría de los programadores Forth defienden un diseño de arriba hacia abajo (top-down) flojo, y el desarrollo de abajo hacia arriba (bottom-up) con la prueba y la integración continuos.

El diseño de arriba hacia abajo es generalmente una separación del programa en "vocabularios" que entonces son usados como conjuntos de herramientas de alto nivel para escribir el programa final. Un programa Forth bien diseñado se lee como el lenguaje natural, e implementa no solo una sola simple solución, sino también un conjunto de herramientas para atacar problemas relacionados.

Puesto que la máquina virtual del Forth es simple de implementar y no tiene ninguna referencia estándar de implementación, hay una plétora de implementaciones del lenguaje. Además de soportar las variedades estándar de los sistemas de computadora de escritorio (POSIX, Microsoft Windows, Mac OS X), muchos de estos sistemas Forth también apuntan a una variedad de sistemas embebidos. Listados aquí están algunos de los sistemas más prominentes que se conforman al estándar ANS Forth 1994.

Cabe destacar también una implementación en el mod de Minecraft, RedPower 2 como sistema de control.





</doc>
<doc id="15220" url="https://es.wikipedia.org/wiki?curid=15220" title="Francis Bacon">
Francis Bacon

Francis Bacon, primer barón Verulam, primer vizconde de Saint Albans y canciller de Inglaterra (Strand, Londres, -Highgate, Middlesex, ) fue un célebre filósofo, político, abogado y escritor inglés, padre del empirismo filosófico y científico.

Desarrolló en su "De dignitate et augmentis scientiarumn" ("De la dignificación y progreso de la ciencia") una teoría empírica del conocimiento y precisó las reglas del método científico experimental en su "Novum organum", lo que hizo de él uno de los pioneros del pensamiento científico moderno. Asimismo, introdujo el género del ensayo en Inglaterra.

Era el hijo menor de sir Nicholas Bacon, nombrado guardián del Gran Sello por la reina Isabel I. Su madre, Anne Cooke Bacon, segunda esposa de sir Nicholas, era sobrina de sir Anthony Cooke, hablaba cinco idiomas y estaba considerada una de las mujeres más ilustradas de su época. Fue educado por su madre en los principios del puritanismo calvinista.

Aunque no se haya establecido con seguridad, hay razones para creer que Bacon fue educado por preceptores en su casa durante sus primeros años, y su salud durante este período, al igual que después, fue bastante frágil. En 1573, a la edad de trece años, ingresó en el "Trinity College" de Cambridge, institución en la que cursó estudios hasta 1576 en compañía de su hermano mayor, Anthony.

En Cambridge su investigación en diversas ciencias lo llevó a la conclusión de que los métodos empleados y los resultados obtenidos no se correspondían y eran erróneos. Su reverencia por Aristóteles, de quien a pesar de todo no parecía tener excesivos conocimientos, contrastaba con su despego de la filosofía aristotélica. A su juicio, la filosofía precisaba de un verdadero cometido y nuevos métodos para alcanzarlo. Con este primer germen de la idea que lo consagraría, Bacon abandonó la universidad.

El 27 de junio de 1576 ambos hermanos ingresaron en "De societate magistrorum" y unos meses más tarde fueron destinados a Francia como agregados del embajador sir Amyas Paulet. La situación política y social en Francia durante el reinado de Enrique III le proporcionó al joven Francis una valiosísima experiencia política, al verse envuelto en algunas gestiones diplomáticas complejas y delicadas. Aunque vivió en Poitiers, visitó también París y las principales ciudades francesas y recogió informes sobre los recursos y la situación política de diferentes países europeos, informes que se han venido publicando entre sus obras bajo el título de "Notes on the State of Christendom" ("Notas sobre el estado de la Cristiandad"), pese a que, como apuntó el historiador James Spedding, parece ser trabajo más bien de un ayudante de su hermano Anthony. Posteriormente, además, leyó los "Ensayos" del francés Michel de Montaigne (1580 y 1595), género que afianzó su escepticismo racionalista y que introdujo posteriormente en Inglaterra escribiendo él mismo unos "Ensayos" (1597).

Al conocer la súbita muerte de su padre en 1579, Francis regresó a Inglaterra. La modestísima herencia que le dejó, insuficiente para situar a su hijo menor en una posición desahogada, lo obligó a adoptar la profesión del derecho. Con estos estudios y sus trabajos literarios y diplomáticos Bacon aspiraba a conseguir un puesto político importante, así que frecuentó el círculo del conde de Essex, quien se convirtió en su protector durante el reinado de Isabel I de Inglaterra, y llegó a ser miembro de la Cámara de los Comunes (1592). Por fin entró en la órbita regia cuando Jacobo I de Inglaterra advino al trono en 1603. El monarca era un amante de la erudición y Bacon destacó entre sus preferidos. Recibió así progresivos y crecientes cargos y honores: letrado real (1607), procurador general (1613), fiscal general (1615), miembro del Consejo Privado (1616), ministro de justicia (1617), lord guardián del sello y finalmente lord canciller a los cincuenta y siete años (1618), culmen de su carrera política. También se le concedió el título de barón de Verulam y de vizconde de San Albano. Como hombre de leyes fue el juez que condenó a muerte a sir Walter Raleigh (1618) y a sir Thomas Howard (1619).

Posteriormente Bacon se vio envuelto en intrigas políticas que lo acusaban de desprestigiar al Rey; incluso en 1621 fue acusado de corrupción y maltrato a sus subordinados. Sin embargo Bacon logró salir airoso de estas insidias y con una gran fortuna acumulada en el ejercicio de su labor pública, con la cual pudo retirarse dedicado en adelante y en exclusiva a sus trabajos filosóficos y científicos. Tras publicar sus obras principales, falleció en Londres en 1626 a causa de una neumonía.

Se propuso ante todo reorganizar el método de estudio científico. Percibió que el razonamiento deductivo destacaba entonces a expensas del razonamiento inductivo y creyó que, eliminando toda noción preconcebida del mundo, se podía y debía estudiar al hombre y su entorno mediante observaciones detalladas y controladas, realizando generalizaciones cautelosas. Para ello, el estudio que el hombre de ciencia hace de los particulares debe realizarse mediante observaciones que deben validarse. Los científicos deben ser ante todo escépticos y no aceptar explicaciones que no se puedan probar por la observación y la experiencia sensible (empirismo).

Los escritos de Bacon se engloban en tres categorías: filosófica, literaria y política. Sus obras filosóficas más prominentes son "El avance del saber" (1605), y "Novum organum o indicaciones relativas a la interpretación de la naturaleza" (1620).

La filosofía de Bacon influyó en las ideas, que la modernidad haría cada vez más generales, de que la gente es a la vez sierva e intérprete de la naturaleza, la verdad no nace directamente de la autoridad y el conocimiento deriva ante todo de la experiencia. Se le reconoce haber aportado a la Lógica el método experimental inductivo, ya que anteriormente se practicaba la inducción mediante la simple enumeración, es decir, extrayendo conclusiones generales de datos particulares. El método de Bacon consistió en inferir a partir del uso de la analogía, desde las características o propiedades del mayor grupo al que pertenece el dato en concreto, dejando para una posterior experiencia la corrección de los errores evidentes. Este método representó un avance fundamental en el método científico al ser muy significativo en la mejora de las hipótesis científicas.

Su "Novum organum" influyó mucho en la aceptación en la ciencia de una observación y experimentación precisas. En esta obra mantenía que había que abandonar todos los prejuicios y actitudes preconcebidas, que llamó en griego «"eidola"» («ídolos»), ya fueran la propiedad común de la especie debido a modos comunes de pensamiento («ídolos de la tribu») o propios del individuo («ídolos de la caverna»), o se debieran a una dependencia excesiva del lenguaje («ídolos del foro») o de la tradición («ídolos del teatro»). Los principios que se plantean en "Novum organum" tuvieron gran importancia en el subsiguiente desarrollo del empirismo.

Como escritor, se le debe además la creación del género ensayístico en inglés, con sus "Ensayos sobre moral y política", (1597) que siguen la estela de los de Montaigne, en los que muestra un estilo en apariencia poco ornamentado y una gran capacidad aforística.

En "La Nueva Atlántida" ofrece la primera utopía tecnológica, donde los gobernantes serán los científicos de la «Casa de Salomón», especie de gran universidad donde se concentraría el conocimiento. Previó en su época grandes adelantos científicos como máquinas voladoras, submarinos y telecomunicaciones.

La teoría baconiana sobre la autoría de las obras de Shakespeare, propuesta por primera vez a mediados del siglo XIX, sostiene que Francis Bacon escribió las obras de teatro que se atribuyen en forma convencional a William Shakespeare, en contra del punto de vista aceptado de que fue William Shakespeare de Stratford quien escribió los poemas y obras que llevan su nombre.

La principal evidencia baconiana se funda en la presentación de un motivo para el ocultamiento, las circunstancias que rodean la primera puesta en escena de "La comedia de las equivocaciones", la proximidad de Bacon a la carta de William Strachey a partir de la cual muchos estudiosos creen que se basó "La Tempestad", interpretación de alusiones en las obras al conocimiento legal de Bacon, los numerosos supuestos paralelismos con las obras publicadas de Bacon y anotaciones en el "Promus" (su libro de notas personal), el interés de Bacon en las historias civiles, y alusiones sostensiblemente autobiográficas en las obras de teatro. Como Bacon contaba con conocimiento de primera mano de los métodos de codificación del gobierno, muchos baconianos piensan que él escribió pistas de su autoría en la obra de Shakespeare en forma codificada.

La mayoría de los estudiosos de fuste rechazan todos estos argumentos en favor de Bacon, y critican a la poesía atribuida a Bacon como demasiado diferente de la de Shakespeare como para haber sido escrita por la misma persona.

A menudo Francis Bacon se encontraba con otros hombres en el "Gray's Inn" para discutir sobre política y filosofía, y para ensayar actos de obras de teatro que estaba escribiendo. La supuesta conexión de Bacon con los Rosacruces y la Francmasonería ha sido ampliamente comentada en numerosos libros por distintos autores y estudiosos. Sin embargo, otros entre los que se encuentra Daphne du Maurier (en su biografía de Bacon), han sostenido que no existe evidencia sustancial que avale la teoría de su relación con los Rosacruces. Frances Yates no indica que Bacon fuera un Rosacruz, pero, presenta pruebas de que él se encontraba vinculado con algunos de los movimientos intelectuales más herméticos de su época. Yates sostiene que la iniciativa de Bacon sobre la promoción de la enseñanza se encontraba muy ligada con el movimiento Rosacruz alemán, mientras que en la obra "La Nueva Atlántida" Bacon presenta una tierra que es gobernada por los Rosacruces. Probablemente él consideraba que su movimiento por la promoción del aprendizaje se encontraba alineado con los ideales de los Rosacruces.

La influencia de Francis Bacon es evidente sobre un conjunto variado de autores religiosos y espirituales, y en grupos que han utilizado sus escritos en sus propios sistemas de creencias.

Dentro de la doctrina baconiana se hallan dos grandes e importantes asuntos que se van desarrollando durante su estudio. El primero de ellos es un estudio exhaustivo sobre los problemas del método científico; el segundo hace referencia a la técnica aplicada a la vida humana. Bacon emprende una lucha decisiva focalizada en Aristóteles, debido a que este había, según él, imposibilitado el progreso de la ciencia aplicada. Tanto la Antigüedad como la Edad Media no concibieron la posibilidad de mejorar las condiciones de vida humana por medio de los descubrimientos de la ciencia aplicada; por ello Bacon orientó su atención a tal problema, proclamando una ruptura concentrada específicamente en la doctrina de Aristóteles, pues este pensador, según Bacon, es quien manifestó los más grandes errores que alimentaban a la época renacentista, hasta tenerlo como modelo.

Además criticaba su ineficaz método; su inutilidad práctica, debido a que este así como su filosofía, tenían solo una utilidad discursiva, dispuesta únicamente para debates y discusiones, pero no en provecho de producir obras que sirvieran a la vida humana; pues la llegada de la Revolución Industrial impondría más adelante nuevos desafíos en donde los hombres hallarían en la tierra toda serie de materiales, que querrían posteriormente darles usos prácticos a lo que la lógica aristotélica no acogería, por no ser de utilidad, tales casos.

Bacon, se refiere a la lógica aristotélica, como aquella que deja sin bases a la investigación científica, porque su silogística gira en torno a un grupo de conocimientos, con el fin de solo reafirmarlos, a esto llama anticipaciones de la naturaleza; a su propuesta metodológica la designa interpretaciones de la naturaleza, estas consistían en tener un acercamiento sistemático a la experiencia y así, gradualmente ascender a premisas generales, para después retornar al estado sensible y hallar el carácter práctico del conocimiento, pero para llevar a cabo lo anterior, se debe aplicar la verdadera inducción que va en contra de la inducción por enumeración simple; esta última, es rechazada en sus conclusiones, al tropezarse con un caso, donde las mismas (conclusiones) no pueden aplicarse. Es por ello que la verdadera inducción es la más viable, en cuanto que, toma los casos negativos y tras un gran número de ellos, concluye los afirmativos.

Al controvertir la filosofía y especialmente el método del estagirita, a la vez hace notorio la idea preponderante de su pensamiento; de aumentar el dominio sobre la naturaleza, para así, mejorar la vida del hombre. Bacon, hace una analogía entre el nuevo científico y la abeja, pues el primero debe ser como las segundas en cuanto que ellas recolectan de las flores el material para transformarlo después en miel. Su propuesta de una nueva lógica, es experimental, para así poder dominar la naturaleza, a través del obrar.

El "Novum organum" (o "Indicaciones relativas a la interpretación de la naturaleza", publicada en 1620) concibe la ciencia como una técnica que puede dar al ser humano el dominio sobre la naturaleza. Trata sobre la lógica del procedimiento técnico-científico que se contrapone deliberadamente a la aristotélica (cuyo tratado se titulaba, precisamente, "Órganon"), ya que, según Bacon, resultaba buena solo para la disputa verbal.

Así pues, la inteligencia humana debe apropiarse de instrumentos eficaces para dominar la naturaleza, algo descuidado por Aristóteles. Este instrumento son los experimentos, que interpretan y dan forma a los datos de la experiencia sensible: el llamado empirismo. El entendimiento humano es demasiado débil y está por todas partes limitado por todo tipo de obstáculos que hay que limpiar para obtener conclusiones claras, por lo cual es necesario librarse de estos prejuicios, que él denomina en griego «"eidola"», «ídolos»; Bacon los clasifica de la siguiente manera:


La teoría de los prejuicios constituye la parte crítica y destructiva del tratado. La parte constructiva estudia el modo en que debe ser organizada la experiencia. Es un discurso sobre el método científico. La viga maestra de este método es la inducción lógica. Para organizar e interpretar los datos de la experiencia (y para hacer experimentos) Bacon propuso su «teoría de las tres tablas» (o tres registros):


Se realizarán tablas de estos hechos antes de sacar conclusión empírica alguna.





</doc>
<doc id="15223" url="https://es.wikipedia.org/wiki?curid=15223" title="Idioma emiliano-romañol">
Idioma emiliano-romañol

El emiliano-romañol (también erróneamente llamado simplemente emiliano) es una lengua del grupo galoitaliano de las lenguas romances. Se habla en Italia noroccidental, en la Emilia-Romaña, en el sur de Lombardía, norte de Toscana (Lunigiana) y en el norte de Las Marcas. También se usa en San Marino.

El número de hablantes en la Emilia-Romaña se estima en 3.500.000 aproximadamente (dato de 1987). En San Marino el 83% de la población (20.100 habitantes) hablan el sanmarinés (dato de 1993), que es un dialecto del Emiliano-Romañol. El emiliano-romañol está reconocido como lengua minoritaria de Europa desde 1981 (Informe 4745 del Consejo de Europa). También la UNESCO lo incluyó en su "Libro Rojo de las Lenguas Amenazadas", entre los idiomas dignos de protección. La autoridad de registro de la norma ISO 639-3 le ha asignado el código "".

En Italia tradicionalmente se le ha denominado "dialetto" ("dialecto"), terminología que puede resultar confusa fuera de Italia ya que el emiliano-romañol no es una variante dialectal del italiano, sino una evolución paralela del latín. Las variedades de emiliano-romañol tienen rasgos morfológicos, sintácticos y léxicos diferenciados del italiano, y de hecho comparten un buen número de isoglosas con el galorromance y el occitanorromance que no son compartidas por las lenguas italianas centromeridionales.

Los dialectos del emiliano-romañol se dividen en dos componentes principales, cada uno de los cuales incluye distintos subdialectos.

En Emiliano los subdialectos son:
Y en Romañol existen:

La siguiente tabla compara algunos cambios fonéticos, como la caída de vocales finales y palatalizaciones diversas en emiliano-romañol y otras variedades galoitalianas:
Los numerales en diferentes variedades galoitalianas son:

Los numerales '1', '2' y '3' distinguen entre formas de masculino y femenino.


</doc>
<doc id="15225" url="https://es.wikipedia.org/wiki?curid=15225" title="Mesías">
Mesías

Mesías (del latín bíblico "Messĭas", y este a su vez del hebreo "Māšîaḥ", pronunciado [] pronunciación aproximada "Mashiaj", que significa «ungido») es, en las religiones abrahámicas, el Rey descendiente de David, prometido por los profetas al pueblo hebreo, aquel hombre lleno del Espíritu Santo de Dios. A lo largo de la historia existieron muchas personas a las que se les consideró Mesías, pero generalmente, se entiende que este título en particular se asigna al enviado escogido por Dios, que traerá la paz a la humanidad instaurando el Reino de Dios.

El término «Mesías» proviene del hebreo מָשִׁיחַ ("mashíaj", ‘ungido’), de la raíz verbal ("mašáḥ" ‘ungir’) y se refería a un esperado rey, del linaje de David, que liberaría a los judíos de las servidumbre extranjera y restablecería la edad dorada de Israel. Se le denominaba así ya que era costumbre ungir en aceites a los reyes cuando se los proclamaba. El término equivalente en griego es χριστός ("khristós" ‘ungido’), derivado de χρίσμα ("khrísma" ‘unción’). El término griego, ampliamente utilizado en la "Septuaginta" y el "Nuevo Testamento", dio en español la forma Cristo, que unida al nombre de Jesús, que los cristianos consideran el mesías definitivo, Dios Jesucristo.

De las religiones monoteístas en el mundo, podemos destacar tres ramas principales y la relación que ellas tienen con la creencia en un Mesías. El judaísmo, cristianismo y el islam.

Dentro del judaísmo, la creencia en el Mesías se fundamentó en la revelación de Dios, hecha a través de la Torá o Ley de Dios. Desde el Génesis se registraron muchas profecías mesiánicas dentro de la ley, que permitirían reconocerlo cuando llegase. Posteriormente, cobró auge durante el cautiverio de Babilonia, al adquirir una mayor importancia la concepción del mesías como salvador. Sin embargo la doctrina del Mesías no ha sido un tema importante de estudio debido a que esta no es eje central del judaísmo.

Maimónides, teólogo judío de la Edad Media y sus escrituras son base para el entendimiento del concepto de Mesías para los judíos, siendo uno de los personajes que más ha tratado este tema. Él afirmó: «Yo creo con fe absoluta en la llegada del Mesías, y aunque tardare, con todo lo esperaré cualquier día».

La escatología judía indica que la venida del Mesías vendrá acompañada de una serie de eventos específicos que no han ocurrido todavía, incluido el retorno de todos los judíos a la Tierra Prometida, la reconstrucción del Templo, la era de la paz y entendimiento en la cual «el conocimiento de Dios» llenará la tierra.

Los judíos han visto tradicionalmente a Jesús de Nazareth como uno de tantos falsos mesías que han aparecido a lo largo de la historia. Se le ve como el que más ha influido en su pueblo y, por ello, el que más daño ha causado.

El judaísmo nunca ha aceptado ninguna de las profecías que los cristianos atribuyen a Jesús, y para ellos, ninguna de las prerrogativas que anunciarán la venida del mesías han ocurrido durante su vida, por lo que no puede considerarse siquiera como candidato a Mesías.

La Biblia parece hacer referencia a varias facetas del Mesías, una como rey, gobernante y restaurador, y otra como siervo sufriente. Esto ha dado lugar a distintas posiciones acerca de cómo debería ser el mesías.

Los cristianos denominan Mesías a Jesús de Nazaret, llamándole Cristo, traducción literal del hebreo Mesías. Según la Torá la promesa de la venida del Mesías se extiende a toda la descendencia de Abraham, Isaac y Jacob (luego Israel), de quien surgieron las 12 tribus de Israel. Según la tradición cristiana, la promesa hecha a Israel en realidad debería entenderse como realizada a todos los hombres, razón por la que Jesús sería entonces el Mesías y el redentor de la humanidad.

Para los Testigos de Jehová, la concepción de mesías no es igual que en el resto de corrientes cristianas (aunque también para ellos cobra gran importancia el advenimiento o Segunda Venida de Jesús), pues no creen en la doctrina de la Trinidad, por lo que el mesías, en este caso, no adquiere personalidad divina, sino solo de enviado de Jehová, aunque lo consideran como la persona que vino a reparar lo que Adán dañó al pecar y así santificar el nombre de Jehová.

El Islam señala a I'sa (Jesús de Nazaret), Mahdi o el bien guiado, como los que inaugurarán una era de justicia.

Para la parte mayoritaria del Islam, el concepto de Mahdi tiene una escatología según la cual el Mahdi nacerá én los "Últimos Tiempos", por lo que no se admite que fuera una persona concreta que ya hubiera existido. También se ha indicado que Mahdi tendrá una relación especial con los pobres. En muchos ámbitos se confunde el término de Mesías adjudicándolo al Mahdi, quien guiará a la Umma, hacía un retorno a la creencia, siendo el Mesías Isa (Jesús) Hijo de María, quien retornará para luchar junto al Mahdi contra el Al-Dajjal (Anticristo)

Actualmente, hay importantes Shaykhs Sunnis que afirman que estamos en la época de la venida de Mahdi. Incluso hay algunos que afirman haber tenido contacto con Mahdi.

El emperador Haile Selassie I de Etiopía, que según la tradición es descendiente directo de Salomón hijo de David, es considerado por el Movimiento rastafari como la tercera reencarnación –después de Melquisedec y Jesús– de Jah, el Mesías.

Gran parte de esta creencia se debe a la «profecía» de Marcus Garvey, que consideran reencarnación de Juan el bautista:

Selassie, devoto cristiano, negó ser el Mesías, aun así los Rastas creen que él es un mensajero de Dios.


Las siguientes obras incluyen el concepto de un mesías como líder de una causa o liberador de un pueblo:



</doc>
<doc id="15226" url="https://es.wikipedia.org/wiki?curid=15226" title="Motor térmico">
Motor térmico

Un motor térmico es una máquina térmica que transforma calor en trabajo mecánico por medio del aprovechamiento del gradiente de temperatura entre una fuente de calor (foco caliente) y un sumidero de calor (foco frío). El calor se transfiere de la fuente al sumidero y, durante este proceso, algo del calor se convierte en trabajo por medio del aprovechamiento de las propiedades de un fluido de trabajo, usualmente un gas o el vapor de un líquido.

El calor necesario para el funcionamiento de una máquina térmica procede de la energía química liberada en una combustión, siendo absorbido por un fluido motor que pone en movimiento una serie de piezas mecánicas.

Si la combustión tiene lugar fuera del motor, las máquinas reciben el nombre de máquinas de combustión externa, y si la combustión tiene lugar dentro de la máquina, las máquinas reciben el nombre de máquinas de combustión interna. El movimiento producido puede ser alternativo o rotativo.

El fluido motor suele ser el vapor de agua, el aire o la mezcla de gases resultantes de la combustión del petróleo o de gases combustibles. En los motores de combustión interna la combustión se realiza en el fluido motor, y en los motores de combustión externa existen dos fluidos, donde se intercambia calor entre ambos. En las centrales nucleares el calor procede de la energía liberada en la fisión nuclear del uranio o del plutonio, siendo extraído por una sustancia refrigerante que lo cede a un circuito secundario a través de un cambiador de calor.

En 1765 el escocés James Watt fabricó la primera máquina de vapor eficiente, y significó además el comienzo de la Revolución Industrial, nacida como consecuencia de la sustitución del esfuerzo muscular por el trabajo de las máquinas. La máquina de vapor fue un triunfo de la tecnología que hizo surgir fábricas en la mayoría de países, al mismo tiempo que elevaba el nivel de bienestar de la sociedad.

Un siglo más tarde los motores de combustión interna revolucionaron el transporte terrestre, marítimo y aéreo. La ciencia dio lugar al Sistema Internacional de Unidades.

La máquina de vapor es una máquina de combustión externa que aprovecha la fuerza expansiva del vapor de agua para mover un émbolo y producir trabajo.

En 1691, el ingeniero militar inglés Thomas Savery fue pionero en utilizar la presión del vapor de agua para extraer agua de minas y pozos y mover una rueda hidráulica. Normalmente la presión del vapor de agua solía reventar calderas y tuberías, y además, era poco eficaz porque se perdía el calor del vapor de agua cada vez que se enfriaba el recipiente.

En 1698 Thomas Savery patentó su descubrimiento, y el herrero inglés Thomas Newcomen construyó una máquina más perfecta, que trabajaba a bajas presiones. Además, contaba con un pistón y un cilindro. Con la presión del aire podía mover el pistón.

En 1765 el mecánico escocés James Watt mejoró la máquina de Thomas Newcomen, y en 1782 construyó la primera máquina de vapor.

En 1787 el inventor estadounidense John Fitch construyó un barco de vapor, aunque éste fracasó financieramente.

En 1807 Robert Fulton botó el "Clermont", el primer barco de vapor.

En 1814 el inglés George Stephenson construyó la primera locomotra de vapor.


El proceso de expansión del vapor de agua contra el émbolo es adiabático pero no reversible, por lo que no es isoentrópico.

Para que una máquina térmica siguiese el ciclo de Carnot habría que detener la condensación del vapor antes de que se licue por completo y, por medio de un compresor, conseguir que la mezcla vapor-líquido alcance su licuación completa a la temperatura de la caldera.

Como esto resulta imposible, el ingeniero escocés J. M. Rankine propuso una modificación del ciclo de Carnot, denominado ciclo de Rankine.


En un ciclo de Rankine con sobrecalentamiento, la temperatura media a la que se absorbe el calor implica un mayor rendimiento. El vapor permanece seco durante toda la expansión adiabática, por lo que disminuye los peligros a la corrosión.

La potencia de una máquina de vapor depende de la presión y la cantidad de vapor de agua admitida por el cilindro en la unidad de tiempo. Como la presión varía, se considera un valor promedio llamado presión media efectiva.

La cantidad de vapor de agua por unidad de tiempo es igual al volumen del cilindro correspondiente a cada revolución multiplicado por el número de revoluciones en unidad de tiempo. El volumen se calcula multiplicando la sección del émbolo por la longitud de la carrera.

formula_1

siendo


Cuando el vapor de agua actúa sobre ambas caras del émbolo, la potencia teórica desarrollada es el doble de este valor.

A causa de rozamientos y otras pérdidas, realmente la potencia suele ser un 70 o un 90% que la potencia citada.

El tamaño de la máquina de vapor se limita a potencias de 1000 CV, a velocidades de 213 m/min, a presiones de 14 kp/cm², a temperaturas de 315 °C y a rendimientos del 30%.

Las máquinas de vapor se han utilizado como órganos motrices de locomotoras, y barcos. Actualmente han sido sustituidas por motores de combustión.

En la turbina de vapor el vapor de agua se distribuye por cuatro tubos y actúa directamente sobre las paletas de una rueda, haciéndola girar con una velocidad de unas 10.000 rpm.

La turbina de vapor carece de cilindro motor y de órganos transformadores del movimiento, por lo que el rendimiento es mayor.

Actualmente la turbina de vapor se emplea en las centrales eléctricas, en la propulsión de buques y en las instalaciones soplantes de altos hornos.


En un motor térmico se producen una serie de transformaciones que conducen a un estado inicial (es decir, tiene un ciclo cerrado). En el transcurso de estas transformaciones, el motor recibe energía térmica en forma de calor y devuelve energía mecánica en forma de trabajo. 

La eficiencia de varios motores térmicos propuestos o usados hoy en día oscila entre el 3 % (97 % de calor desperdiciado) para los sistemas de conversión de energía térmica del océano, el 25 % para la mayor parte de los motores de automóviles, el 35 % para una planta generadora de carbón supercrítico, y el 60 % para una turbina de gas de ciclo combinado con enfriamiento de vapor. Todos estos procesos obtienen su eficiencia (o la pierden) debido a la depresión de la temperatura a través de ellos. Por ejemplo, los sistemas de conversión de energía térmica del océano emplean una diferencia de temperatura entre el agua sobre la superficie y el agua en las profundidades del océano, es decir, una diferencia de tal vez 25 ºC, por lo que la eficiencia debe ser baja. Las turbinas de ciclo combinado utilizan quemadores de gas natural para calentar aire hasta cerca de 1530 ºC, es decir, una diferencia de hasta 1500 ºC, por lo que la eficiencia puede ser mayor cuando se añade el ciclo de enfriamiento de vapor.

Para la clasificación de los motores térmicos, además de los criterios ya mencionados en el caso de máquinas de fluido, se tienen en consideración dos aspectos adicionales:


El fundamento de los motores de combustión interna es la realización de la combustión en el interior del cilindro de la máquina, en los que el agente motor es el combustible mezclado con el aire necesario para la combustión.

Existen distintos tipos de máquinas de combustión interna dependiendo del combustible utilizado, las condiciones de la combustión y el número de carreras que efectúa el pistón en un ciclo. El movimiento puede ser alternativo, que lo realizan los motores de explosión y de combustión, o rotativo, que lo realizan las turbinas de de explosión y de combustión.

En las máquinas de movimiento alternativo, la combustión es instantánea, producida por una chispa eléctrica, debiendo utilizarse combustibles gaseosos o líquidos muy volátiles, como por ejemplo la gasolina. En las máquinas de movimiento rotativo se realiza de una forma progresiva y a presión constante, utilizándose como combustibles líquidos menos volátiles, como por ejemplo el gasóleo.

En las máquinas de combustión interna, los gases de la combustión son los que circulan por la propia máquina. En este caso, la máquina será necesariamente de ciclo abierto, y el fluido motor será el aire (no condensable) empleado como comburente en la combustión.

El motor de explosión de uso más común es el motor de cuatro tiempos, que está formado por los siguientes componentes.


Una máquina térmica sigue el ciclo ideado en 1862 por Beau de Rochas y usado por primera vez en 1877 por Nikolaus Otto, denominando así al ciclo como ciclo de Otto.

El ciclo de Otto se efectúa por un gas perfecto, y consta de dos procesos adiabáticos y dos isocoros, que reciben el nombre de tiempos.


El rendimiento del ciclo de Otto viene dado por la expresión:

formula_7

donde R es el grado de compresión de la mezla, y formula_8 es el coeficiente adiabático.

En los motores de gasolina existe un límite por encima del cual no puede elevarse el grado de compresión, ya que a temperaturas y presiones elevadas el carburante explosiona antes de saltar la chispa. Se dice que se ha alcanzado el nivel de autoignición.

Esta [[detonación produce un choque audible que perjudica al motor y disminuye el rendimiento. Añadiendo sustancias antidetonantes o [[catalizador]]es se consigue grados de compresión de 8 a 10.

Las razones por el bajo rendimiento son las siguientes:


Las gasolinas de alto poder antidetonante son aquellas en las que predominan los [[Hidrocarburo cíclico|hidrocarburos cícliclos]] y los [[Hidrocarburo de cadena ramificada|hidrocarburos de cadena ramificada]], que detonan con mayor dificultad. Para comparar las propiedades antidetonantes se utiliza el [[Índice de octano|índice]] o [[número de octano]], donde se toman como [[hidrocarburo]]s el [[isooctano]] y el [[n-heptano]], a los que se asignan poderes antidetonantes de 100 y 0.

El índice o número de octano es el tanto por ciento en volumen de isooctano en una mezcla de isooctano y n-heptano que tenga el mismo poder antidetonante que la gasolina.

La gasolina de aviación tiene un número de octano superior a 100, y constan de un 20% de [[Hidrocarburo aromático|hidrocarburos aromáticos]].

Para disminuir la detonación y aumentar el índice o número de octano de una gasolina, antiguamente se utilizaban [[antidetonante]]s, que actuaban como catalizadores negativos de las reacciones de combustión de los hidrocarburos. El más completo fue el [[tetraetilo de plomo]], que se añadía un 0,1% a la gasolina. Al explosionar la gasolina quedaban libres plomo metálico y [[óxido de plomo]], que estropeaban el motor y contaminaban el [[aire]]. Actualmente se utilizan gasolinas sin plomo empleando otro tipo de catalizadores.

Las causas que limitan el rendimiento de las [[Motor de combustión externa|máquinas de combustión externa]] radican en la imposibilidad de alcanzar temperaturas elevadas en la caldera, debido a la presión que se alcanza; y la dificultad de conseguir un aprovechamiento de la [[energía calorífica]] del [[carbón]] y otro [[combustible]].

Si la combustión es externa, el calor de la combustión se transfiere al fluido a través de una pared, por ejemplo en un [[intercambiador de calor]]. Este tipo de máquinas no exige un proceso de combustión, como sucede en las instalaciones nucleares, si bien es el procedimiento usual. Dado que el fluido motor no sufre degradación alguna, estas máquinas pueden ser de ciclo cerrado, a lo que actualmente se tiende por razones económicas.


[[Categoría:Motores térmicos]]

</doc>
<doc id="15227" url="https://es.wikipedia.org/wiki?curid=15227" title="Poncio Pilato">
Poncio Pilato

Poncio Pilato  fue un miembro del orden ecuestre y quinto prefecto de la provincia romana de Judea, entre los años 26 y 36. Los evangelios canónicos lo presentan como responsable ejecutivo del suplicio y crucifixión de Jesús de Nazaret, siendo éste uno de los pocos episodios en los que se menciona a este personaje conocido también por autores judíos (Filón, Flavio Josefo), romanos (Tácito) y un testimonio arqueológico epigráfico.

En castellano su cognomen suele ser "Pilatos", quizás por influencia de la forma griega; "Πιλάτος" o también reflejando el nominativo latino "Pilatus". Aun cuando Pilato puede considerarse la forma más correcta, Pilatos ha sido sancionado por el uso y, por ello, está reconocido por las Academias de la Lengua, las cuales la emplean en diversas entradas del "Diccionario de la lengua española".

Los detalles de la biografía de Poncio Pilato antes y después de su nombramiento como prefecto de Judea y tras su participación en el proceso contra Jesús de Nazaret son desconocidos. Aunque varias fuentes textuales posteriores (los "Annales" de Tácito y los escritos de Flavio Josefo) lo mencionan como "procvrator" (procurador) o como "praeses" (gobernador), su denominación oficial fue la de "praefectus" que, según había ya sospechado O. Hirschfeld en 1905, era la que correspondía a tal cargo hasta la época de Claudio. Este dato quedó documentado sin duda tras el hallazgo en 1961, entre los restos del teatro de Cesarea (importante puerto antiguo, entre Tel-Aviv y Haifa), de una inscripción fragmentaria oficial, en la que Pilato dedicaba (o rehacía) un "Tiberieum" o templo de culto al emperador Tiberio. Su texto se suele restituir de la siguiente forma:
La inscripción de Poncio Pilato se puede ver comentada en español, con imágenes del original, en un reciente artículo que reúne fuentes textuales romanas y judías no cristianas sobre Jesús de Nazaret.

Muchos detalles que carecen de cualquier confirmación por otras vías (especialmente relativos a sus supuestos arrepentimiento, suicidio o condena y decapitación) han sido añadidos a la tradición biográfica a partir de las "Actas de Pilato", un relato contenido en los evangelios apócrifos, que circularon con más profusión por Oriente; entre aquellos se cuentan también un nombre para su esposa, Claudia Prócula (que, junto a él, fue canonizada como santa por la Iglesia ortodoxa etíope, y sola por la bizantina), o un (improbable) nacimiento de Pilato en Tarraco (Tarragona). Lo cierto, sin embargo, es que históricamente no se sabe nada seguro sobre los lugares de nacimiento y muerte de Pilato, ya que su rastro histórico se pierde en los años 36-37 cuando, destituido de su cargo, regresó a Roma.

Fue designado prefecto de Judea por Tiberio, a instancias de su prefecto para el pretorio, Sejano, adversario de Agripina y destacado antijudío.

Intentó introducir imágenes del emperador en Jerusalén y de construir un acueducto con los fondos del Templo. Algunos autores señalan que estas desavenencias con el pueblo judío lo llevaron a trasladar su centro de mando de Cesarea a Jerusalén para controlar mejor las revueltas, en especial porque comenzaban a actuar en la provincia grupos armados contrarios al poder romano. Se supone que el personaje mencionado en los evangelios, Barrabás, era parte de una de estas bandas.

Poncio Pilato fue relevado del mando de Judea en el año 36, después de reprimir fuertemente una revuelta de los samaritanos, durante la cual crucificó a varios alborotadores.

Existen varias referencias históricas sobre Poncio Pilato. 
Las más antiguas corresponden al filófoso judío Filón de Alejandría.

Este autor, quien vivió en el siglo I y actuó como representante de su comunidad ante las autoridades imperiales, narra un acto de Pilato durante su gobierno en Judea. En esa ocasión el conflicto se relacionó con unos escudos de oro que llevaban los nombres de Pilato y Tiberio, y que el prefecto había colocado en su residencia de Jerusalén. Los judíos apelaron al emperador de Roma, ya que en virtud de los tratados vigentes debía respetarse la ley judía en la ciudad, y Pilato recibió la orden de llevar los escudos a Cesarea. (Sobre la embajada ante Cayo, XXXVIII, 299-305). Filón se refiere a Poncio Pilato como un hombre «de carácter inflexible y duro, sin ninguna consideración». Más aún, según este escritor de Alejandría, el gobierno de Poncio se caracterizó por su «corruptibilidad, robos, violencias, ofensas, brutalidades, condenas continuas sin proceso previo, y una crueldad sin límites».

Cronológicamente, las siguientes menciones de Pilato en fuentes históricas corresponden a las obras de Flavio Josefo, historiador judío y ciudadano romano, quien escribió en el último cuarto del siglo I. En efecto, tanto en la "Guerra de los judíos," publicada entre los años 75 y 79, como en las "Antigüedades judías", de la década del 90, aparece varias veces como gobernador de Judea entre los años 26 y 36. Según este historiador, Pilato tuvo un mal comienzo en lo que respecta a las relaciones con los judíos de su provincia: de noche envió a Jerusalén soldados romanos que llevaban estandartes militares con imágenes del emperador. Y la situación se complicó porque las insignias fueron colocadas en la Torre Antonia, cuartel general de las cohortes romanas, es decir, justo frente a uno de los ángulos del complejo del Templo, con el añadido de que los judíos creyeron que los auxiliares romanos quemaban incienso frente a las imágenes de Tiberio y Augusto. Este suceso provocó un gran resentimiento debido a que vulneraba la prohibición de la Torah del uso de ídolos, y una delegación de principales entre los judíos (representantes del Sanedrín) viajó a Cesarea para protestar por la presencia de las insignias y exigir que las quitasen.
Después de cinco días de discusión, Pilato intentó atemorizar a los que hicieron la petición, amenazándolos con que sus soldados los ejecutarían, pero la enconada negativa de aquellos a doblegarse (pues incluso se inclinaron en tierra y mostraron sus cuellos para ser degollados, aunque Pilato sólo había pretendido engañarlos para que cedieran) y dado el alto coste político (ya que Pilato llevaba apenas seis semanas en el puesto y habría tenido que ejecutar en esa sola ocasión hasta a seis mil judíos) le hizo acceder a su demanda. (Antigüedades Judías, libro XVIII, capítulo III, sección 1.)

Josefo aún menciona otro alboroto: a expensas de la tesorería del templo de Jerusalén, Pilato construyó un acueducto para llevar agua a Jerusalén desde una distancia de casi 40 km. Pilato solicitó del Gran Sanedrín fondos del Tesoro del Templo para financiar la obra, bajo la advertencia de que si eran negados tendría que aumentar los impuestos. Los sacerdotes se negaron en principio alegando que era dinero sagrado, pero cedieron bajo la condición de que se ocultara el origen de los fondos y de que el principal flujo del líquido llegara a los depósitos del propio Templo, pero el acuerdo fue descubierto. Grandes multitudes vociferaron contra este acto cuando Pilato visitó la ciudad. Pilato envió soldados disfrazados para que se mezclasen entre la multitud y la atacasen al recibir una señal, lo que resultó en que muchos judíos muriesen o quedasen heridos. (Antigüedades Judías, libro XVIII, capítulo III, sección 2; La Guerra de los Judíos, libro II, capítulo IX, sección 4.)

Josefo informa que la posterior destitución de Pilato fue el resultado de las quejas que los samaritanos presentaron a Vitelio, por entonces gobernador de Siria y superior inmediato de Pilato. La queja tenía que ver con la matanza ordenada por Pilato de varios samaritanos a los que engañó un impostor, reuniéndolos en el monte Guerizim con la esperanza de descubrir los tesoros sagrados que supuestamente había escondido allí Moisés. Vitelio mandó a Pilato a Roma para comparecer ante Tiberio, y puso a Marcelo en su lugar. Tiberio murió en el año 37, mientras Pilato todavía estaba en camino a Roma (Antigüedades Judías, libro XVIII, capítulo IV, secciones 1 y 2.) temeroso de ser juzgado y ejecutado por su antigua relación con Sejano, ya que tras la caída de éste, todos los que se relacionaron con él fueron tratados como enemigos por el emperador Tiberio y en su mayoría ejecutados. Incluso, se ha llegado a relacionar su decisión de ceder ante la presión del Sanedrín judío en el juicio de Jesús (cuando los sacerdotes le recordaron que si soltaba a un supuesto subversivo como Jesús, que se proclamaba rey, entonces no era amigo de César, es decir, del emperador de ese momento, Tiberio), para salvar su carrera e incluso su vida y así evitar que Tiberio sospechara de su lealtad y lo mandara llamar a Roma para investigarlo y juzgarlo como asociado a Sejano. Además, y ya que Sejano había hostilizado en vida a la colonia judía de Roma, después de su muerte, Tiberio ordenó a Pilato cambiar hacia una política favorable a las costumbres judías.

El historiador romano Tácito, nacido alrededor del año 55, que no era amigo del cristianismo, escribió poco después del año 100, menciona a Pilato en relación con la persecución neroniana y el origen de los cristianos: “Cristo, el fundador del nombre, había sufrido la pena de muerte en el reinado de Tiberio, sentenciado por el procurador Poncio Pilato, y la perniciosa superstición (el cristianismo) se detuvo momentáneamente, pero surgió de nuevo, no solamente en Judea, donde comenzó aquella peste, sino en la capital misma (Roma)...”.

El apologista y filósofo cristiano Justino Mártir, quien escribió a mediados del siglo II, señala a propósito de la muerte de Jesús: “Por las "Actas de Poncio Pilato" puedes determinar que estas cosas sucedieron”. Un texto que ha sido controvertido porque supone la existencia de un testimonio legal sobre el juicio de Jesús de Nazaret. Agrega que estos mismos registros mencionaban los milagros de Jesús, de los cuales dice: “De las "Actas de Poncio Pilato" puedes aprender que Él hizo esas cosas”. Según algunos autores estos registros oficiales, que no se conservan, pudieron existir todavía en el siglo II, por lo cual Justino instaba a sus lectores a comprobar con ellas la veracidad de lo que decía. Del mismo modo, en su "Apologeticus", escrito en 197, Tertuliano informó de datos originales sobre Pilato según los cuales el gobernador habría hecho un informe al emperador sobre los acontecimientos en Judea en relación con Cristo. Este informe también es mencionado por Jerónimo de Estridón en su "Chronicon" ("c." 380), y en el "Cronicón pascual", si bien no se sabe si tomaban el dato de una fuente independiente o se apoyaban en las noticias de Justino . Las Actas de Pilato que se conservan actualmente son una obra apócrifa que no parece tener relación con la mencionada por Justino y, ciertamente, son muy posteriores.

Según los Evangelios sinópticos Jesús fue apresado por un grupo de hombres armados pertenecientes a la guardia del Templo, por orden de Caifás y los sumos sacerdotes. En cambio, el evangelio de Juan afirma que fue apresado por una compañía romana al mando de un tribuno (Juan 18:12), lo que daría a entender que fue por orden del prefecto. Los evangelios dicen que, luego de un interrogatorio nocturno, los líderes saduceos llevaron a Jesús ante el procurador romano por la mañana temprano (los romanos solo hacían juicios antes del mediodía), solicitando a Pilato que lo ejecutara, ya que le habían hallado culpable de blasfemia, pero la pena capital solo podía ser aplicada por los romanos. Pilato envía a Jesús a Herodes Antipas debido a un conflicto con la jurisdicción correspondiente a un reo de Galilea. Al ser devuelto a sus manos, Pilato se declara incompetente para resolver asuntos religiosos y declara no hallarle culpable. Los líderes judíos entonces cambian la acusación sobre Jesús a sedición. A pesar de no hallarlo culpable, Pilato -sabiendo que era víspera de Pascuas- deja que el pueblo decida entre liberar a un preso de nombre Barrabás o liberar a Jesús.

El pueblo, dirigido por los sumos sacerdotes, escoge la liberación de Barrabás y la crucifixión de Jesús. Ante esa decisión Pilato simbólicamente se lavó las manos para indicar que no quería ser parte de la decisión tomada por la muchedumbre. Pilato dice «No soy responsable por la sangre de este hombre». A lo que la multitud responde: «Que su sangre caiga sobre nosotros y sobre nuestros descendientes». Se narra también que Pilato ordena la flagelación de Jesús antes de su ejecución, pero los evangelios discrepan en cuanto a si esta medida fue tomada como un intento de sustitución de la ejecución, o si era simplemente parte del proceso de la ejecución.

En cuanto a los "Evangelios apócrifos", existe un muy breve y tardío "Evangelio de la muerte de Poncio Pilatos" y un mucho más importante "Evangelio de Nicodemo", también llamado "Hechos de Pilatos" ("Acta Pilati").

Según Pérez-Rioja, «Pilato se ha convertido en un símbolo tradicional de la vileza y de la sumisión a los bajos intereses de la política».
El acto de «lavarse las manos» protagonizado por Pilato en el evangelio de Mateo, junto con otros temas simbólicos emblemáticos de la pasión de Cristo (las treinta monedas de plata, el beso de Judas, el canto del gallo), dejó su marca en el lenguaje cotidiano y en las imágenes.

Según J. L. McKenzie, el acto de «lavarse las manos» no formaba parte del proceso legal: ya no había audiencia ni interrogatorio de testigos, sino más bien una forma de hacer comunicar a la muchedumbre, por medio de una costumbre judía, su desapego al caso. La sentencia estaba implícita. El factor importante no era ya el proceso, sino las presiones que provocaron el resultado del proceso. Los evangelios implican claramente que Pilato se dio cuenta de que no había ningún cargo auténtico contra Jesús, y el lavatorio simbólico de las manos añadido por Mateo, viene a subrayarlo. Este acto quedó en la cultura como símbolo de quien, por conveniencia personal, cede ante la presión de otros al tiempo que pretende desentenderse de un veredicto injusto. El lavatorio de manos implica un acto de purificación vacío de contenido que no consigue en conciencia eludir la responsabilidad, puesto que quien condena a un hombre inocente por presiones no está moralmente muy por encima de los que las ejercen.

Estéticamente, Poncio Pilato ha llamado la atención e imaginación de escritores (su persona se convirtió en personaje casi obligado en cualquier representación de la pasión de Jesucristo), de artistas plásticos, y de productores y directores cinematográficos.

Poncio Pilato es el personaje principal de «El procurador de Judea», de Anatole France, publicado en "Le Temps" del 25 de diciembre de 1891, y recogido luego en la colección de relatos "El estuche de nácar" (1892). Posteriormente, el cuento se editó por separado en ediciones de bibliófilo, la primera de ellas en 1902 con ilustraciones de Eugène Grasset.
En dicho relato, Poncio Pilato, retirado ya en Sicilia, se encuentra con Aelio Lamia, un conocido de su período como procurador de Judea. En dos conversaciones sucesivas hacen repaso a los acontecimientos que vivieron juntos. Ambos exponen una visión radicalmente contrapuesta sobre la historia y los judíos.

El cuento se anticipa en más una década a la denuncia del antisemitismo que se manifestará en la sociedad francesa a raíz del caso Dreyfus.

En 1980, Leonardo Sciascia tradujo «El procurador de Judea» al italiano, ya que lo consideraba uno de los más perfectos de su género. Sirvió de inspiración a Joyce para "Dublineses", en especial para el relato más conocido, «Los muertos».
Cabe destacar también la alusión a su nombre en el personaje de «Poncia», del drama «La Casa de Bernarda Alba», de Federico García Lorca.

En 2012 se publicó en línea la novela "La Santa Palangana" (La Pasión según Pilato), escrita por Juan Antonio de Lucas quien se presenta como el editor de un texto de un catedrático llamado Jân Gröb. La novela se supone basada en documentos del mismo Pilato que habrían permanecido ocultos. Narra el proceso judicial contra Jesucristo con un desenlace muy diferente al histórico.

Poncio Pilato se retrata en «El Maestro y Margarita» de Mikhail Bulgakov como despiadado, y sin embargo, complejo y humano. La novela describe su encuentro con Jesús el Nazareno, mostrando el reconocimiento de una afinidad y la necesidad espiritual de él, y su renuente entrega, aunque resignada y pasiva, a los que querían matarlo. Aquí Pilato ejemplifica la afirmación "La cobardía es el peor de los vicios", y, por lo tanto, sirve como modelo, en una interpretación alegórica de la obra, para todas las personas que se han "lavado las manos" en silencio o tomado parte activa en los crímenes cometidos por José Stalin.

En la cinematografía, diversos actores representaron el papel de Poncio Pilato.


</doc>
<doc id="15228" url="https://es.wikipedia.org/wiki?curid=15228" title="Carrier sense multiple access with collision detection">
Carrier sense multiple access with collision detection

En comunicaciones, CSMA/CD (del inglés "Carrier Sense Multiple Access with Collision Detection") o, en español, acceso múltiple con escucha de portadora y detección de colisiones, es un algoritmo de acceso al medio compartido. Su uso está especialmente extendido en redes Ethernet donde es empleado para mejorar sus prestaciones. En CSMA/CD, los dispositivos de red escuchan el medio antes de transmitir, es decir, es necesario determinar si el canal y sus recursos se encuentran disponibles para realizar una transmisión. Además, mejora el rendimiento de CSMA finalizando el envío cuando se ha detectado una colisión.

Una red en donde los equipos pueden transmitir de forma simultánea varios paquetes es propensa a sufrir colisiones que generan, en el mejor de los casos, retardos en la entrega de estos paquetes y, en otros, la pérdida de información. Para evitar estas situaciones se desarrollaron las técnicas de control de acceso al medio.

Las bajas prestaciones de los primeros mecanismos empleados: Aloha y Aloha ranurado, provocaron la aparición de nuevas técnicas encaminadas a la gestión más eficiente de los recursos de una red, dando lugar al algoritmo CSMA y posteriormente a su evolución CSMA/CD (CSMA con detección de colisiones).

La trama empleada en CSMA/CD está formada por ocho campos:








El algoritmo CSMA/CD puede estar basado en cualquiera de los siguientes procedimientos:




Habitualmente suele ser utilizado el algoritmo 1-persistente, pues es empleado en el estándar IEEE_802.3.

En CSMA/CD, cada estación que desea transmitir debe realizar una escucha del medio –detección de portadora– para comprobar si éste se encuentra libre, es decir, para comprobar que ninguna otra estación está en ese instante transmitiendo un mensaje. Si el medio se encuentra libre entonces tiene lugar dicha transmisión. Aun así, puede ocurrir que varias estaciones tengan mensajes para enviar y que comiencen a transmitir una trama en el mismo instante. Cuando esto se sucede, se dice que ha ocurrido una colisión en la red. La estación que ha detectado la colisión procederá a enviar un mensaje de "jam" de 32 bits al resto de estaciones para notificar dicho evento. Una vez que todas las estaciones han sido notificadas, automáticamente se paran todas las transmisiones y se ejecuta un algoritmo "de backoff" (o de postergación) que consiste en esperar un tiempo aleatorio ("backoff") antes de volver a intentar la transmisión. Durante los 10 primeros intentos el valor medio del tiempo de espera se duplica mientras que durante los 6 siguientes intentos adicionales, se mantiene. Tras 16 intentos fallidos, el algoritmo notificará un error a las capas superiores.



En las redes inalámbricas proceder a la escucha del medio y por lo tanto detectar las colisiones producidas, puede resultar complicado. Esto se manifiesta en dos problemáticas:

Estos problemas fueron resueltos con la implementación del algoritmo CSMA/CA (MultiAccess Collision Avoidance)

CSMA/CD puede encontrarse en alguno de los siguientes estados:
El período de contienda se encuentra formado por ranuras de longitud 2τ y será el tiempo que una estación tardará en darse cuenta de que su trama colisionó: si una estación A comienza a transmitir en el instante t0, la señal tardará un tiempo τ (tiempo de transmisión de la trama) en llegar a la estación más alejada de ella (llamémosla B). Ahora bien, B podrá comenzar a transmitir hasta un instante antes de que la señal de A llegue; si lo hace inmediatamente luego se dará cuenta de que hubo una colisión y abortará su transmisión. Sin embargo, el "ruido" causado por la colisión no llegará hasta la estación A hasta un tiempo igual al doble de propagación de la señal entre A y B, es decir, 2τ. Esto implica que una estación no pueda estar segura de que obtuvo el canal sino hasta haber transmitido durante 2τ sin tener una colisión.

Teniendo en cuento lo anterior, algunos de los parámetros de CSMA/CD quedan definidos como:





CSMA/CD fue usado en las -ahora obsoletas- variantes de Ethernet 10BASE5 y 10BASE2. Actualmente las modernas redes Ethernet construidas con switches y conexiones full-duplex lo mantienen como modo de retrocompatibilidad.





</doc>
<doc id="15229" url="https://es.wikipedia.org/wiki?curid=15229" title="ISO 14000">
ISO 14000

La serie de normas ISO 14000 es un conjunto de normas que cubre aspectos del ambiente, de productos y organizaciones, destacando la Norma ISO 14001, un estándar internacional de gestión ambiental publicado en 1996, tras el éxito de la serie de normas ISO 9000 para sistemas de gestión de la calidad.

La serie de normas ISO 14000 es un conjunto de normas internacionales publicadas por la Organización Internacional de Normalización (ISO), que incluye la Norma ISO 14001 que expresa cómo establecer un Sistema de Gestión Ambiental (SGA) efectivo. 

La norma ISO 14000 es aplicable a cualquier organización, de cualquier tamaño o sector, que esté buscando reducir los impactos en el ambiente y cumplir con la legislación en materia ambiental.

El surgimiento de la serie de normas ISO 14000 es consecuencia directa de la ronda de negociaciones del GATT en Uruguay y la cumbre de Río de Janeiro de la Naciones Unidas sobre el ambiente, que se realizaron en 1992.

Debido a la rápida aceptación de la Serie de Normas ISO 9000 y al surgimiento de una gran cantidad de normas ambientales alrededor del mundo, ISO reconoce la necesidad de crear estándares administrativos en el área ambiental. En 1991, se había creado el Grupo Estratégico de Consultas en el Ambiente (SAGE) y en 1992 debido a las recomendaciones de este grupo se crea el comité ISO/TC 207 quien agruparía representantes de la industria, organismos de normas, el gobierno y organismos ambientales.

Se debe tener presente que las normas estipuladas por ISO 14000 no fijan metas ambientales para la prevención de la contaminación, ni tampoco se involucran en el desempeño ambiental a nivel mundial, sino que, establecen herramientas y sistemas enfocadas a los procesos de producción al interior de una empresa u organización, y de los efectos o externalidades que de estos deriven al ambiente.

Cabe resaltar dos vertientes de la ISO 14000:

La ISO 14000 se basa en la norma británica BS7750, que fue publicada oficialmente por la British Standards Institution (BSI) previa a la Reunión Mundial de la ONU sobre el Medio Ambiente (ECO 92).

La norma ISO 14000 es un conjunto de documentos de gestión ambiental que, una vez implantados, afectará todos los aspectos de la gestión de una organización en sus responsabilidades ambientales y ayudará a las organizaciones a tratar sistemáticamente asuntos ambientales, con el fin de mejorar el comportamiento ambiental y las oportunidades de beneficio económico. Los estándares son voluntarios, no tienen obligación legal y no establecen un conjunto de metas cuantitativas en cuanto a niveles de emisiones o métodos específicos de medir esas emisiones. Por el contrario, ISO 14000 se centra en la organización proveyendo un conjunto de estándares basados en procedimiento y unas pautas desde las que una empresa puede construir y mantener un sistema de gestión ambiental.

En este sentido, cualquier actividad empresarial que desee ser sostenible en todas sus esferas de acción, tiene que ser consciente que debe asumir de cara al futuro una actitud preventiva, que le permita reconocer la necesidad de integrar la variable ambiental en sus mecanismos de decisión empresarial.

La norma se compone de ocho elementos, los mismos que se relacionan a continuación con su respectivo número de identificación:

La adopción de las Normas Internacionales facilita a los proveedores basar el desarrollo de sus productos en el contraste de amplios datos de mercado de sus sectores, permitiendo así a los industriales concurrir cada vez más libremente y con eficacia en muchos más mercados del mundo.

Ahorro de costos: la ISO 14001 puede proporcionar un ahorro del costo a través de la reducción de residuos y un uso más eficiente de los recursos naturales tales como la electricidad, el agua y el gas. Organizaciones con certificaciones ISO 14001 están mejor situadas de cara a posibles multas y penas futuras por incumplimiento de la legislación ambiental, y a una reducción del seguro por la vía de demostrar una mejor gestión del riesgo.

Reputación: como hay un conocimiento público de las normas, también puede significar una ventaja competitiva, creando más y mejores oportunidades comerciales.

Participación del personal: se mejora la comunicación interna y puede encontrar un equipo más motivado a través de las sugerencias de mejora ambiental.

Mejora continua: el proceso de evaluación regular asegura se puede supervisar y mejorar el funcionamiento medioambiental en las empresas.

Cumplimiento: la implantación ISO 14001 demuestra que las organizaciones cumplen con una serie de requisitos legales. Esto puede mitigar los riesgos de juicios.

Sistemas integrados: ISO 14001 se alinea con otras normas de sistemas de gestión como la ISO 9001 o la OHSAS 18001 de seguridad y salud laboral, que proporciona una más efectiva y eficiente gestión de sistemas en general.

Las Normas Internacionales proporcionan las bases tecnológicas y científicas que sostienen la salud, la legislación sobre seguridad y calidad medio ambiental.

Las Normas Internacionales constituyen una fuente importante del know-how tecnológico, definiendo las características que se esperan de los productos y servicios a ser colocados en los mercados de exportación, las Normas Internacionales dan así una base a estos países para tomar decisiones correctas al invertir con acierto sus escasos recursos y así evitar malgastarlos.

La conformidad de productos y servicios a las Normas Internacionales proporciona el aseguramiento de su calidad, seguridad y fiabilidad.

Las Normas Internacionales pueden contribuir a mejorar la calidad de vida en general asegurando que el transporte, la maquinaria, los productos e instrumentos que usamos estén sanos y seguros para el consumo humano.

Porque al existir Normas Internacionales sobre el aire, el agua y la calidad de suelo, así como sobre las emisiones de gases y la radiación, podemos contribuir al esfuerzo de conservar el ambiente.

La ISO desarrolla solo aquellas normas para las que hay una exigencia de mercado. El trabajo es realizado por expertos provenientes de los sectores industriales, técnicos y de negocios que han solicitado las normas y que posteriormente se proponen emplear. Estos expertos pueden unirse a otros con conocimientos relevantes, tales como: los representantes de agencias de gobierno, organizaciones de consumidores, las academias, los laboratorios de pruebas y en general expertos internacionales en sus propios campos.

El objetivo de estas normas es facilitar a las empresas metodologías adecuadas para la implantación de un sistema de gestión ambiental, similares a las propuestas por la serie ISO 9000 para la gestión de la calidad.

La serie de normas ISO 14000 sobre gestión ambiental incluye las siguientes normas:









</doc>
<doc id="15233" url="https://es.wikipedia.org/wiki?curid=15233" title="Indosasa">
Indosasa

Indosasa, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Asia, principalmente de China y Vietnam. Comprende 39 especies descritas y de estas, solo 20 aceptadas.
Son arbustos perennifolios. Los tallos de flores de hoja verde. Tallos leñosos y persistentes; cilíndricos; ramificados arriba. Los nodos de los culmos surcados. Hojas no agregadas basalmente; con setas auriculares. La lámina de hoja ancha (grande); no cordada, no sagitada; pseudopeciolada; desarticuladas las vainas. Plantas bisexuales, con espiguillas bisexuales; con flores hermafroditas. La inflorescencia débilmente indeterminada ; con pseudo espigas; que comprende ramas cortas vagamente agrupados alrededor de un nodo, las espiguillas en racimos apretados. 
El género fue descrito por Floyd Alonzo McClure y publicado en "Lingnan University Science Bulletin" 9: 28. 1940. La especie tipo es: "Indosasa crassiflora" McClure 
A continuación se brinda un listado de las especies del género "Indosasa" aceptadas hasta noviembre de 2013, ordenadas alfabéticamente. Para cada una se indica el nombre binomial seguido del autor, abreviado según las convenciones y usos. 



</doc>
<doc id="15237" url="https://es.wikipedia.org/wiki?curid=15237" title="Rectificador">
Rectificador

En electrónica, un rectificador es el elemento o circuito que permite convertir la corriente alterna en corriente continua. Esto se realiza utilizando diodos rectificadores, ya sean semiconductores de estado sólido, válvulas al vacío o válvulas gaseosas como las de vapor de mercurio (actualmente en desuso). 

Dependiendo de las características de la alimentación en corriente alterna que emplean, se les clasifica en monofásicos, cuando están alimentados por una fase de la red eléctrica, o trifásicos cuando se alimentan por tres fases.

Atendiendo al tipo de rectificación, pueden ser de media onda, cuando sólo se utiliza uno de los semiciclos de la corriente, o de onda completa, donde ambos semiciclos son aprovechados.

El tipo más básico de rectificador es el rectificador monofásico de media onda, constituido por un único diodo entre la fuente de alimentación alterna y la carga.

La rectificación no controlada requiere un estudio previo de las necesidades, ya que el circuito rectificador tan solo funcionará de la forma correcta si todas las condiciones de contorno con las que se ha realizado el cálculo se cumplen. Es decir, tanto la tensión de entrada como la carga RL han de ser las especificadas.

Es construido con un diodo ya que este puede mantener el flujo de corriente en una sola dirección, se puede utilizar para cambiar una señal de CA a una de CC. En la figura I. se muestra un circuito rectificador de media onda. Cuando la tensión de entrada es positiva, el diodo se polariza en directo y se puede sustituir por un corto circuito. Si la tensión de entrada es negativa el diodo se polariza en inverso y se puede remplazar por un circuito abierto. Por tanto cuando el diodo se polariza en directo, la tensión de salida a través de la carga se puede hallar por medio de la relación de un divisor de tensión. Sabemos además que el diodo requiere 0.7 voltios para polarizarse, así que la tensión de salida está reducida en esta cantidad (este voltaje depende del material de la juntura del diodo). Cuando la polarización es inversa, la corriente es cero, de manera que la tensión de salida también es cero. Este rectificador no es muy eficiente debido a que durante la mitad de cada ciclo la entrada se bloquea completamente desde la salida, perdiendo así la mitad de la tensión de alimentación. El voltaje de salida en este tipo de rectificador es aproximadamente 0.45 veces el voltaje eficaz de la señal de entrada (este 0.45 surge de calcular formula_1). La forma de onda que observamos a la salida se muestra en la figura I.

Un rectificador de onda completa convierte la totalidad de la forma de onda de entrada en una polaridad constante (positiva o negativa) en la salida, mediante la inversión de las porciones (semiciclos) negativas (o positivas) de la forma de onda de entrada. Las porciones positivas (o negativas) se combinan con las inversas de las negativas (positivas) para producir una forma de onda parcialmente positiva (negativa).

El circuito, representado en la "Figura 2", funciona como sigue:

El transformador convierte la tensión alterna de entrada en otra tensión alterna del valor deseado, esta tensión es rectificada durante el primer semiciclo por el diodo D1 y durante el segundo semiciclo por el diodo D2, de forma que a la carga R le llega una tensión continua pulsante muy impura ya que no está filtrada ni estabilizada.

En este circuito tomamos el valor de potencial 0 en la toma intermedia del transformador.

Se trata de un rectificador de onda completa en el que, a diferencia del anterior, sólo es necesario utilizar transformador si la tensión de salida debe tener un valor distinto de la tensión de entrada.

En la Figura 3 está representado el circuito de un rectificador de este tipo.

A fin de facilitar la explicación del funcionamiento de este circuito vamos a denominar D-1 al diodo situado más arriba y D-2, D-3 y D-4 a los siguientes en orden descendente.

Punto superior del secundario --> Diodo D-1 --> (+)Resistencia de carga R(-) --> Diodo D-4 --> punto inferior del secundario.
Punto inferior del secundario --> Diodo D-2 --> (+)Resistencia de carga R (-) --> Diodo D-3 --> punto superior del secundario.

En este caso, vemos como circula corriente por la carga, en el mismo sentido, en los dos semiciclos, con lo que se aprovechan ambos y se obtiene una corriente rectificada más uniforme que en el caso del rectificador de media onda, donde durante un semiciclo se interrumpe la circulación de corriente por la carga. 

En ambos tipos de rectificadores de onda completa, la forma de onda de la corriente rectificada de salida, será la de una corriente continua pulsatoria, pero con una frecuencia de pulso doble de la corriente alterna de alimentación.

Como se puede apreciar en las Figuras 2 y 3 la corriente obtenida en la salida de los rectificadores no es propiamente continua y dista mucho de ser aceptablemente constante, lo que la inutilizaría para la mayoría de las aplicaciones electrónicas. 

Para evitar este inconveniente se procede a un filtrado para eliminar el rizado de la señal pulsante rectificada. Esto se realiza mediante filtros RC (resistencia-capacitancia) o LC (inductancia-capacitancia), obteniéndose finalmente a la salida una corriente continua con un rizado que depende del filtro y la carga, de modo que sin carga alguna, no existe rizado. Debe notarse que este filtro no es lineal, por la existencia de los diodos que cargan rápidamente los condensadores, los cuales a su vez, se descargan lentamente a través de la carga.

La tensión de rizado (Vr) será mucho menor que V si la constante de tiempo del condensador R·C es mucho mayor que el período de la señal. Entonces consideraremos la pendiente de descarga lineal y, por tanto, Vr = Vpico·T / (R·C)
Siendo R·C la cte de tiempo del condensador, T el período de la señal y Vpico la tensión de pico de la señal.

Es un tipo de regulación mucho más complicada de implementar, pero proporciona un control total de la carga. El esquema de este tipo de rectificadores seria como el de los anteriormente expuestos, añadiendo entre la carga y la salida rectificada, de forma conceptual, un interruptor. Este 'interruptor' denominados tiristores (SCR) permitiría o cortar el paso de la señal dentro de un ángulo correspondiente entre 0 y 180 grados de la onda Senoidal, permitiendo un control de potencia dentro de esos ángulos de disparo.

Cabe añadir que la complejidad reside en el diseño del sistema de control, donde el 'interruptor' conceptual ha de ser sustituido por un circuito tan complicado como requiera el dispositivo.

Hay aplicaciones en las que la caída de tensión directa en los diodos (V) causa que tengan una baja eficiencia, como el caso de algunos convertidores DC-DC. Un rectificador síncrono sustituye los diodos por transistores MOSFET, gobernados por un circuito de control que los corta cuando la tensión entra en su ciclo negativo. Esta técnica tiene tres ventajas frente a los diodos:


</doc>
<doc id="15238" url="https://es.wikipedia.org/wiki?curid=15238" title="Desseria">
Desseria

Desseria es un género de microorganismos parásitos de la familia "Haemogregarinidae", filo "Apicomplexa".



</doc>
<doc id="15240" url="https://es.wikipedia.org/wiki?curid=15240" title="Cucurbitaceae">
Cucurbitaceae

Las cucurbitáceas (Cucurbitaceae) son una familia de plantas típicamente trepadoras por zarcillos, en general herbáceas y geófitas o anuales, con el ovario ínfero y el fruto inmaduro de un pepónide, que al madurar se diversificó adaptándose a diferentes síndromes de dispersión; que producen cucurbitacinas que vuelven partes vegetativas y frutos inmaduros y a veces también maduros de sabor muy amargo y tóxicos para la mayoría de los animales. Las partes amargas de algunas cucurbitáceas se encuentran entre los sabores más amargos conocidos provenientes de las plantas, las cucurbitacinas se encuentran diversificadas pero todas comparten una parte de la vía biosintética, un solo gen basta para explicar su presencia o ausencia en las diferentes partes de la planta; las variedades cultivadas para consumo humano perdieron las cucurbitacinas en algunos órganos. Muchas poseen gran importancia horticultural y varios géneros de "calabazas" y muchas variedades de fruto inmaduro "dulce" (no amargo) pertenecen a esta familia. Algunos ejemplos son los zapallos y zapallitos (ayotes, pipianes, calabazas y calabacines, "Cucurbita pepo, C. maxima, C. moschata, C. argyrosperma"), el chilacayote o alcayota ("Cucurbita ficifolia"), el melón y el pepino ("Cucumis melo" maduro y "Cucumis sativus" inmaduro respectivamente), la sandía ("Citrullus lanatus"), la calabaza vinatera o porongo o mate ("Lagenaria siceraria"), la sicana o calabaza melona o curuguay ("Sicana odorifera"), el estropajo o esponja vegetal ("Luffa"), el chayote o papa del aire y el tacaco de Costa Rica ("Sechium edule" y "Sechium tacaco"), la caigua o achojcha ("Cyclanthera pedata"), entre otras muchas comestibles en África y Asia maduras o inmaduras (géneros "Benincasa", "Momordica", "Trichosanthes", "Coccinia").

Poseen una sola hoja por nudo. APWeb: "Las cucurbitáceas son fáciles de reconocer. Son enredaderas herbáceas o lianas con hojas usualmente más bien cubiertas por tricomas (pelos) toscos, sin estípulas, con venación palmada. En la axila de la hoja hay usualmente una yema vegetativa, una flor, desplazado hacia el lateral un zarcillo ramificado, o alguna organización más compleja que esa. Las plantas son dioicas o monoicas, y las flores tienen hipanto, un androceo muchas veces complejo formado por anteras monotecas onduladas sigmoideamente, y un ovario ínfero con placentación parietal. La corola es usualmente más o menos amarilla, a veces colorada. Las semillas son más o menos aplanadas".

Las cucurbitáceas se diferencian de las similares Vitaceae (las vides) y Passifloraceae (la pasión de Cristo o mbaracuyás) en la posición de sus zarcillos, que es "lateral" al pecíolo, o al menos no opuesta al pecíolo como en Vitaceae, ni en la axila de la hoja como en Passifloraceae (Dieterle 1976 para Guatemala).

Las variedades silvestres también son diferenciables por el sabor de las cucurbitacinas.

Schaefer y Renner en Kubitzki (2011): "".

Las floras latinoamericanas que se ocupan de regiones de climas templados a cálidos y las españolas tienen una descripción morfológica de la familia y los géneros que se encuentran en la región que describen, se puede acceder a ellas en las bibliotecas de instituciones dedicadas a la botánica como universidades o jardines botánicos. Las floras pueden ser antiguas y no encontrarse en ellas las últimas especies descriptas en la región, por lo que una consulta a la última literatura taxonómica primaria (las últimas monografías taxonómicas y catálogos de ocurrencias ("checklists") de la familia y sus géneros en la región) o con un especialista local puede ser necesaria. La diversidad global de la familia se encuentra en una flora global hasta género, en inglés y que se ha vuelto un referente, en Schaefer y Renner en Kubitzki (2011), otras "online" son la de Watson y Dallwitz (1992 en adelante) con su clave de identificación interactiva, y la del APWeb. Las 3 últimas incorporan la clasificación del APG (2009) -pueden tener algunas diferencias-, si bien la familia es antigua y estable en la conceptualización que hoy conocemos de ella. Un libro relativamente reciente, en inglés, ha sido dedicado a la descripción de los diferentes aspectos de la familia, incluidos cultivo, usos, etc. y se ha vuelto de lectura obligada para iniciarse en la familia, es el Robinson y Decker-Walters (1997) "Cucurbits".

La diversidad taxonómica de las cucurbitáceas está presentada en detalle por Schaefer y Renner en Kubitzki (ed., 2011).

A continuación una pequeña lista incompleta de la diversidad de cucurbitáceas. Las descripciones son deliberadamente incompletas. Para más información siga los enlaces.

El fruto de "Luffa" al madurar es un pixidio con mesocarpio fibroso.

Fruto: sandía. Mesocarpio interno jugoso, mesocarpio medio (blanco) sólido y formando parte de la "armadura".

Fruto: Melón, pepino.

Fruto: zapallos, alcayota. Exocarpio leñoso, son "calabazas".

Fruto: calabazas de exocarpio muy leñoso, de durabilidad de varios años.

Fruto: calabaza de pulpa acuosa, durabilidad unos 6 meses, pulpa algo similar al melón.

Fruto: calabaza de pulpa acuosa, durabilidad algo más de un año por la capa cerosa que la recubre.

Fruto: inmaduro es el "pepino de rellenar".

"Coccinia" se encuentra restringida al continente africano, salvo una especie comestible, "Coccinia grandis". El fruto de "Coccinia" madura en una baya colorada o anaranjada desde el sector distal al proximal. La última monografía taxonómica del género es la de Holstein (2015).

Los frutos de "Trichosanthes" son similares exteriormente a "Coccinia" (las semillas pueden ser oscuras), pero están distribuidas en Asia tropical y Australia salvo "Trichosanthes cucumerina" var. "anguina" que se cultiva también en África. Además de su fruto posee pétalos típicamente blancos y fimbriados, de tubo floral alargado y fragantes, adaptados a la polinización nocturna por lepidópteros. 

El único árbol de la familia, "Dendrosicyos" con su única especie, es un paquicaulo que ganó el hábito arborescente a partir del hábito trepador ancestral. En inglés lo llaman "cucumber tree", el "árbol de pepino". Sus ramas herbáceas son péndulas. Sobrevive como un relicto en la isla de Socotra (frente a la costa del cuerno de África) pero es el doble de antiguo que ella, por lo que se postula que anteriormente estaba más ampliamente distribuido.

La hipótesis filogenética más moderna del orden y su clasificación en familias y géneros (con especial detalle en Cucurbitaceae) puede ser encontrada en Schaefer y Renner (2011), publicada el mismo año que el artículo "Cucurbitaceae" en la flora de Kubitzki (ed.). Ver también en el APWeb (en inglés).

Literatura taxonómica primaria:

Linneo en su "Species Plantarum" (1753) nombró al género "Cucurbita" L. que en ese momento contenía 5 especies que hoy son 3 variedades de "Cucurbita pepo" y dos especies transferidas a otros géneros: la calabaza vinatera "Lagenaria siceraria" y la sandía "Citrullus lanatus". Más tarde Antoine-Laurent de Jussieu asignó los géneros a familias y utilizó "Cucurbita" como género tipo de la familia Cucurbitaceae, publicada en "Genera Plantarum" 393–394. 1789. 

La clasificación actual suele estar basada en el APG, ver especialmente la descripción de la familia y sus géneros en Schaeffer y Renner en Kubitzki (2011).

Una "checklist" de las cucurbitáceas de India fue publicada por Renner y Pandey (2012).

Sus especies comestibles tienen más importancia económica que lo que normalmente se reconoce, ya que son típicamente utilizadas como alimento y comercialización local en el mismo lugar donde se las cultiva, en sistemas agrícolas pequeños y sustentables, cuyos datos no son tabulados. Prácticamente todos los huertos familiares de climas templados a cálidos cultivan al menos una de ellas.

Dos libros se han publicado sobre cucurbitáceas, la familia de los pepónides:






</doc>
<doc id="15241" url="https://es.wikipedia.org/wiki?curid=15241" title="Carbunco">
Carbunco

El carbunco ("anthrax" en inglés, y también conocido como ántrax maligno o ántrax en español, aunque este último término es también sinónimo de furunculosis por "Staphylococcus aureus") es una enfermedad contagiosa, aguda y grave, que puede afectar a todos los homeotermos y entre ellos al hombre, causada por "Bacillus anthracis", un bacilo Gram positivo, aerobio estricto y esporogénico que se encuentra en el suelo. La severidad del carbunco en el hombre varía según el modo de contagio y la velocidad del tratamiento; el carbunco cutáneo, la manifestación más común de la enfermedad presenta una mortalidad baja. En cambio, el carbunco pulmonar es letal en la mayoría de los casos. Las esporas de "B. anthracis" se han investigado como agentes de guerra biológica, y fueron utilizadas en los ataques con carbunco en 2001.

El agente causante del carbunco es la bacteria "Bacillus anthracis", un microorganismo esporogénico que puede permanecer 
en el ambiente durante muchos años. La célula es grande, entre 1 y en longitud, y 1 y de anchura. Las esporas tienen un tamaño de aproximadamente . Las esporas son muy resistentes; para su destrucción se requiere la ebullición durante 10 minutos, el autoclave a o el horno a durante 6 minutos.

Existe un reservorio animal representado por los animales enfermos o los cadáveres de animales muertos por el proceso, y un reservorio extraanimal, telúrico y más importante desde el punto de vista epidemiológico, integrado por los terrenos contaminados a partir de los excrementos y secreciones de los animales enfermos. Estos animales liberan grandes cantidades de bacterias por la sangre eliminada por boca, nariz y ano. En contacto con el oxígeno ambiental las bacterias esporulan y contaminan el terreno circundante donde pueden pervivir durante décadas con plena capacidad germinativa. Estas esporas presentes en el suelo pueden pasar a su forma vegetativa y multiplicarse si existen las condiciones edafológicas y climáticas óptimas (terrenos calcáreos o alcalinos ricos en materia orgánica y una temperatura entre 30 y 35 °C) transformándose así el terreno en lo que se conoce como «área incubadora». El organismo sobrevive en las capas superficiales de suelo, normalmente hasta unos de profundidad, por lo cual no se suelen encontrar en terrenos bien drenados y de uso intenso para la agricultura.

La transmisión en animales se produce normalmente por ingestión. Los herbívoros pueden infectarse al ingerir esporas vehiculadas en plantas y pasto o beber agua con cieno en suspensión. Los brotes se suelen producir en épocas de lluvias fuertes, inundaciones o sequías. Los carnívoros se suelen infectar tras la ingestión de carne contaminada procedente de animales infectados, mientras que los carroñeros y las moscas pueden diseminar la enfermedad tras alimentarse de despojos y depositar gotas de vómito en las plantas. Las picaduras por moscas también pueden contribuir a propagar la enfermedad, aunque este modo de transmisión es más raro. 

En humanos se puede producir un contagio cutáneo al contactar con animales infectados o sus productos contaminados (pellejo, lana y sangre), bien directamente por su manipulación o indirectamente vehiculado por diversos insectos hematófagos. Este es el modo más corriente de transmisión. Asimismo es posible el contagio tras inhalar esporas; este modo de contagio está asociado a procesos como el curtimiento de pieles o tratamiento de la lana. También se puede producir el contagio por inhalación, digestivo tras consumir carne procedente de animales infectados; el consumo de leche no parece transmitir la enfermedad, y la transmisión de persona a persona es muy rara.

Existe distinta susceptibilidad a la infección en función de la especie afectada. Las especies más sensibles son los rumiantes, tanto salvajes como domésticos, mientras que los carnívoros, suidos y equinos manifiestan una sensibilidad intermedia. Dentro de esta sensibilidad intermedia podemos también incluir al género humano. Las aves son consideradas prácticamente como refractarias a la enfermedad, pudiendo este hecho estar en relación con su alta temperatura corporal.

Esta enfermedad se encuentra diseminada por todo el mundo, siendo especialmente frecuente en ciertas regiones de África, Asia y Oriente medio y el sureste europeo.

Las endosporas penetran a través de heridas, mediante ingestión o inhalación. Cuando el contagio es por ingestión o por contacto, las esporas germinan en las mucosas, dañando los tejidos circundantes. En el carbunco por inhalación las esporas son fagocitadas por los macrófagos alveolares, que las trasladan hasta los ganglios linfáticos regionales. En su interior las endosporas germinan, transformándose en bacterias vegetativas; En ambos casos las bacterias pueden pasar al sistema linfático y sanguíneo donde se multiplican y diseminan produciendo septicemia.

Hasta 1954 se pensaba que "B. anthracis" causaba la muerte por obstrucción capilar, debido a los elevados números de bacterias presentes en la sangre, pero se demostró que los síntomas podían darse incluso en la ausencia de infección, inyectando una exotoxina presente en el plasma de los organismos infectados en animales sanos. Esta exotoxina, codificada por genes en el plásmido pXO1, consta de tres proteínas o factores diferentes, que actúan en concierto para interferir con la señalización celular en los macrófagos:

El plásmido pXO2 codifica otro factor de virulencia, la cápsula antifagocítica. Este proteína, de menor nivel de toxicidad, participa en las etapas iniciales de la infección, dificultando la fagocitosis por los macrófagos circulantes.

La expresión de los genes de los factores de virulencia está condicionada por diversos factores ambientales tales como la temperatura y la concentración de CO.

El periodo de incubación oscila entre 1 y 20 días, aunque en la mayoría de los casos la enfermedad se hace evidente a partir de los 3-7 días de la infección. Este periodo de incubación es sensiblemente superior en el caso del cerdo (1-2 semanas). En el caso del hombre, se han observado periodos de incubación de hasta varias semanas.

En los rumiantes puede producirse una forma aguda caracterizada por tambaleos, temblores y disnea, seguido por convulsiones y muerte en menos de tres días. Se suelen producir hemorragias por los orificios corporales. Puede producirse también una forma crónica caracterizada por edema subcutáneo generalizado o bien localizado en la parte ventral del cuello, tórax y abdomen. Los caballos presentan fiebre, anorexia, depresión y cólico con diarrea hemorrágica. También pueden desarrollar edema en las zonas declives del cuerpo (cuello, esternón, abdomen y zona genital). La muerte se produce 1 a 3 días después del comienzo de los síntomas.

En el hombre se pueden producir tres formas clínicas de la enfermedad según el modo de contagio: carbunco cutáneo, intestinal o inhalatorio. Las dos últimas pueden ser difíciles de diagnosticar a tiempo, al presentar síntomas coincidentes con los de otras enfermedades. 


Para el diagnóstico de la enfermedad es muy importante investigar la profesión del paciente y la oportunidad de contagio por contacto con animales enfermos. El diagnóstico se puede confirmar por la presencia de las bacterias en la sangre, lesiones cutáneas, vómitos, heces o expectoraciones.

Los animales muertos de carbunco normalmente no presentan "rigor mortis". El cadáver está hinchado y se descompone rápidamente, observándose pérdida de sangre oscura y no coagulada por todos los orificios naturales. En el caballo puede producirse un edema subcutáneo muy evidente en las zonas ventrales del cuello, tórax y abdomen. Si existe sospecha de carbunco está desaconsejada la realización de la necropsia, pues la exposición al aire de las bacterias fomenta la formación de esporas.
Al abrir el cadáver se hace evidente un típico cuadro septicémico, con presencia de sangre oscura y no coagulada, con hemorragias petequiales o equimóticas en ganglios linfáticos, abdomen y tórax, pudiéndose producir asimismo hemorragias y úlceras en mucosa intestinal. La cavidad peritoneal puede albergar líquido. El bazo se encuentra agrandado y de color oscuro y el hígado y riñones usualmente se encuentran hinchados y congestivos.

Se recomienda el uso inicial de altas dosis de antibióticos. En el caso de infección por inhalación, se recomienda al menos dos tipos diferentes de antibióticos (como ciprofloxacina o doxiciclina en combinación con penicilina) hasta que se obtengan los resultados de susceptibilidad de la cepa responsable de la infección. El tratamiento también puede incluir corticosteroides, para tratar el edema y otros efectos inflamatorios asociados a la toxina.

Las medidas preventivas se basan en mantener alejados a los animales de los pastizales reconocidos tradicionalmente como peligrosos y vacunación sistemática anual en zonas endémicas, y medidas de control que incluyen la separación de los animales sanos de los enfermos, la cuarentena de las granjas afectadas, con la prohibición expresa de su apertura, así como la desinfección exhaustiva de las camas y del utillaje contaminado. No se debe incinerar los cadáveres de animales debido a que la presencia de gas en su interior puede provocar una explosión y favorecer a la diseminación de la bacteria; se recomienda enterrar los cadáveres en un pozo con un agregado de cal.

Existe una vacuna basada en el antígeno protector. Su administración se recomienda a personas sanas de entre 18 y 65 años de edad que corran el riesgo de entrar en contacto con las esporas debido a su profesión. Requiere tres inyecciones subcutáneas administradas con 2 semanas de intervalo, y una dosis de recuerdo anual. Produce inmunidad en el de los casos.

Las esporas de " se pueden usar en la guerra biológica. Para este fin, se utilizan cepas extremadamente virulentas. Las esporas deben prepararse sin formar grumos, que dificultarían la penetración en los alveolos pulmonares necesaria para causar la variante más letal de la enfermedad y en una alta concentración, pues se requieren de 8000 a 50 000 esporas para causar la patología en una persona. Esto requiere condiciones de preparación altamente complejas.

El uso del carbunco como arma biológica comenzó a explorarse durante la Segunda Guerra Mundial, pero no se llegó a utilizar en este conflicto. Durante la Guerra Fría continuaron las investigaciones en Gran Bretaña, Estados Unidos y la Unión Soviética. Su efectividad como agente letal quedó demostrada al producirse una fuga accidental de esporas en una instalación militar en las cercanías de la ciudad soviética de Sverdlovsk (hoy Ekaterimburgo) en 1979. La epidemia, atribuida por las autoridades al consumo de carne contaminada, causó más de 96 víctimas mortales, que hubieran sido más numerosas de haber soplado el viento hacia la ciudad en vez de en la dirección contraria.

En 2001 tuvo lugar un ataque terrorista en Estados Unidos en el cual se usaron esporas introducidas en cartas de correo. Este ataque causó 17 casos de carbunco y 5 fallecimientos

En caso de sospecha de un ataque, los expertos recomiendan informar adecuadamente a la población sobre el riesgo y su control, y dotar a los laboratorios y centros médicos para poder identificar y tratar rápidamente el brote. Las máscaras antigás se consideran inefectivas, por ser las esporas invisibles a la vista e inodoras. El almacenamiento preventivo de antibióticos tampoco se aconseja, pues su efectividad depende de la cepa bacteriana utilizada.


</doc>
<doc id="15243" url="https://es.wikipedia.org/wiki?curid=15243" title="Wilfred Benítez">
Wilfred Benítez

Wilfred o Wilfredo Benítez (nacido en 12 de septiembre de 1958) es un puertorriqueño que fue campeón mundial de boxeo en tres distintas divisiones. A Benítez también se le conoce como "Wilfredo". Sus apodos sobre el cuadrilátero eran "El Radar" y "La Biblia del Boxeo".

Benítez nació en Nueva York, de padres puertorriqueños. En plena juventud, se mudó a Carolina, Puerto Rico. Allí se haría compañero de otros famosos del boxeo, como Esteban De Jesús y Josué Marquez. Benítez sacó un acta de nacimiento falsa en Nueva York a los 15 años de edad, y le fue permitido boxear profesionalmente.

A los 17 años de edad, el 17 de marzo de 1976, reta a Antonio Cervantes por el título mundial peso Welter Junior de la Asociación Mundial de Boxeo, (AMB), que ostentaba el colombiano. Benítez se convirtió en el campeón mundial más joven de la historia al derrotar a Cervantes por decisión dividida en quince asaltos. Defendió la corona tres veces y la dejó vacante.

Benítez subió de categoría en 1979 para retar al campeón mundial Welter del Consejo Mundial de Boxeo (CMB), el Mexicano Carlos Palomino, ganando otra vez el título mundial por decisión en quince asaltos. Luego de una defensa exitosa, Benítez perdió por primera vez, derrotado por nocaut en el asalto número quince por Sugar Ray Leonard, para perder la corona Welter, en noviembre del mismo año.

En 1981, Benítez se convirtió en el quinto boxeador en lograr coronas mundiales en tres categorías diferentes, el primer latinoamericano en lograrlo, el primero en hacerlo desde que Henry Armstrong lo lograra cuatro décadas antes, y el más joven en lograrlo, cuando noqueo al campeón mundial Jr. Mediano del Consejo Mundial, el Trinitense Maurice Hope en doce asaltos. 

Defendió la corona con éxito dos veces, ambas ante exitosos exponentes del boxeo: el futuro campeón mundial Carlos Santos y el legendario ex campeón ligero y welter del mundo Roberto Durán. Ambos fueron derrotados por puntos en quince asaltos en Las Vegas, Nevada. La pelea con Santos fue la primera vez en la historia del boxeo en que dos puertorriqueños se medían por un título mundial. Pierde esta corona del mundo el 3 de diciembre de 1982 ante Thomas Hearns.

De ahí en adelante, la carrera de Benítez y su salud fueron deteriorándose paulatinamente. En 1987, Benítez visitó Argentina para una pelea. Cuando su dinero y sus documentos les fueron robados, tuvo que pasar un año en ese país antes de poder regresar a Puerto Rico. 

Benítez vivió con su madre, Doña Clara Benítez, en Puerto Rico, hasta la muerte de esta en el 2008. Benítez requiere de asistencia médica constante debido a los golpes sufridos durante sus años como boxeador. Entre otros, Félix Trinidad y Héctor Camacho (este último antes de fallecer en el 2012) le han brindado ayuda.

Benítez tuvo un registro de 53 victorias, 8 derrotas (la mayoría de ellas cuando ya estaba en declive de salud), y un empate, con 31 victorias por nocaut.

Desde 1996, Benítez es integrante del Salón de la Fama Internacional del Boxeo.


</doc>
<doc id="15245" url="https://es.wikipedia.org/wiki?curid=15245" title="Teresa de Lisieux">
Teresa de Lisieux

Teresa del Niño Jesús y de la Santa Faz o, simplemente, Santa Teresita (Alenzón, Normandía; 2 de enero de 1873-Lisieux, Normandía; 30 de septiembre de 1897) fue una religiosa carmelita descalza francesa declarada santa en 1925 y proclamada Doctora de la Iglesia en 1997 por Juan Pablo II.

María Francisca Teresa Martin Guérin nació en la calle Saint-Blaise de Alenzón, Normandía, al noroeste de Francia, el 2 de enero de 1873, de Luis Martin y María Celia Guérin (canonizados el domingo 18 de octubre de 2015). De esta unión nacieron nueve hijos, de los cuales cuatro murieron a temprana edad, solo sobrevivieron 5 niñas: María (1860-1940), Paulina (1861-1951), Leonia (1863-1941), Celina (1869-1959) y Teresa, que fue la menor. Todas ellas abrazarían después la vida religiosa.

Fue bautizada dos días después de su nacimiento, el 4 de enero de 1873, en la iglesia de Nuestra Señora de Alenzón. Sus padrinos fueron Paul Boul, hijo de un amigo de la familia, y su hermana mayor, María.
En marzo de ese año, a los dos meses de edad, estuvo a punto de morir y debió ser confiada a una enfermera, Rosa Taillé, que ya había estado cuidando a dos hijos de la pareja Martin. Se mejoró rápidamente y creció en la campiña normanda, en la granja Semallé, a una distancia de casi ocho kilómetros. A su regreso a Alençon el 2 de abril de 1874, su familia la rodea de afecto. Su madre dice que "es de una inteligencia superior a Celina, pero mucho menos dulce, y sobre todo es de una obstinación casi invencible. Cuando ella dice que no, nada puede hacerla cambiar." Es juguetona y traviesa, pero también es emocional y a menudo llora. Teresa siempre se refirió a este primer periodo de su vida como el más feliz.

El hogar de los esposos Martin era un verdadero jardín de virtudes y santidad. Amaban sinceramente a cada una de sus hijas, aunque no toleraban ninguna clase de mal comportamiento y lo corregían al instante. La fe cristiana era el sustento familiar. Cuando no estaban en la iglesia como familia, celebraban las fiestas religiosas y/o rezaban el rosario en casa como familia. Ya a su temprana edad asistía junto a su familia a misa cada día a las 5:30 de la mañana. La familia Martin adhiere estrictamente ayunando y orando al ritmo del año litúrgico. Los Martin también practicaban la caridad y ocasionalmente dan la bienvenida a algún pobre a su mesa; visitaban a los enfermos y los ancianos. Las niñas crecieron viendo en sus padres dos grandes modelos de santidad.

Desde 1865 Celia Martin se queja de dolores en su interior. En diciembre de 1876 un médico revela un “tumor fibroso” de gravedad. Es demasiado tarde para intentar una operación. El 24 de febrero de 1877, Celia pierde a su hermana María Luisa, que murió de tuberculosis en el Convento de la Visitación de Le Mans, con el nombre de hermana María Dositea. Después de su muerte, sus sufrimientos se agudizan, pero todo se lo esconde a su familia. En julio de 1877 Celia participa de una peregrinación al Santuario de Lourdes pidiendo la gracia de su curación, pero no recibe tal gracia.

Finalmente, Celia Martin muere el 28 de agosto de 1877 a causa de un cáncer de mama, cuando Teresa tenía apenas 4 años. En noviembre de 1877 Luis Martin decidió trasladarse a la ciudad de Lisieux, donde residía la familia de su esposa, quienes prometieron a Celia cuidar de sus hijas después de su muerte.

La familia Guerin los ayudó a instalarse en una casa rodeada de arbustos: los Buissonnets. Allí viviría Teresa los siguientes años hasta su entrada en el Carmelo de Lisieux.

Teresa sintió profundamente el cambio de atmósfera. Echa de menos a su madre aún más y sobre esto escribió: ""Desde que mamá murió, mi alegría característica cambió completamente; yo que era tan viva, tan expansiva, me convertí en tímida y dulce, sensible al exceso"”. A pesar del amor prodigado a su padre y a Paulina, a quien después de la muerte de su madre adoptó como su "segunda madre", la vida era austera en los Buissonnets y tendría en cuenta más tarde que este fue "el segundo período de su existencia, el más dolorosa de los tres".

A los siete años, en 1880, Teresa se confiesa por primera vez. En esta ocasión ignora el miedo y los escrúpulos que ya tanto la fastidiaban, dice: "Desde que regresé de la confesión por todas las grandes fiestas ha sido un verdadero placer para mí cada vez que he ido”. El 13 de mayo de 1880, se hace presente en la primera comunión de Celina, que comparte con alegría: ""Creo que he recibido grandes gracias de ese día y le considero uno de los más hermosos de mi vida"". También ella está a la espera de recibir la sagrada comunión y decide aprovechar los tres años que le quedan para prepararse para el evento.

A los ocho años y medio, el 3 de octubre de 1881, Teresa entró en el colegio de las Benedictinas en Lisieux. Regresaba a su casa por las noches, ya que su familia residía muy cerca. Haber recibido previamente lecciones de Paulina y María le dio buenas bases y se puso rápidamente a la cabeza de su clase. Sin embargo, se encuentra con una vida en comunidad a la que no está acostumbrada. Es perseguida por compañeras de más edad que le tienen celos. Ella llora pero no se atreve a quejarse. No le gusta el recreo, tan ajetreado y ruidoso. Su maestra la describe como una estudiante obediente, tranquila y pacífica, a veces pensativa o incluso triste. Teresa dijo más tarde que estos cinco años fueron los más tristes de su vida, y encontró consuelo en la presencia de su "querida Celina".

Durante esta época desarrolla su gusto por la lectura, especialmente la que satisfacía sus necesidades de calma; historias caballerescas y apasionadas. También comienza a sentir una gran admiración por Juana de Arco. Ella piensa que ha nacido para una gloria oculta: "“el Buen Dios me hizo comprender que si mi gloria no aparece a los ojos mortales, podría llegar a ser una gran santa!!!"...

Durante el verano de 1882, cuando Teresa tenía nueve años, se entera por accidente del deseo de su hermana Paulina de convertirse en monja carmelita. La idea de perder a su segunda madre le causa gran tristeza y desesperación. Paulina, tratando de consolarla, le explica cómo es la vida dentro del Carmelo, y entonces Teresa también se siente llamada al Carmelo. Después escribió: ""Sentí que el Carmelo era el desierto donde Dios quería que yo me fuera a ocultar... me sentía tan fuertemente llamada que no había ninguna duda en mi corazón, no era un sueño de la infancia que viaja lejos, sino la certeza de una llamada divina; yo quería ir al Carmelo no por Paulina, sino solamente por Jesús..." "

Un domingo, Teresa logra ir al Carmelo de Lisieux y entrevistarse con la Madre Superiora, María de Gonzaga, quien le dijo, sin que Teresa hubiera mencionado sus deseos: ""cuando vengas a vivir con nosotras, mi querida hija, os llamaréis Teresa del Niño Jesús"", cosa que la Santa interpretó como "una delicadeza de mi amado Niño Jesús". Pero también le dijo que no podían aceptar aspirantes menores de dieciséis años.

El lunes 2 de octubre de 1882, Paulina entra en el Carmelo de Lisieux, donde tomó el nombre de “Sor Inés de Jesús”. Fue un día aún más triste para Teresa, quien había vuelto a la escuela por un año más, pues no podía saltarse un grado ya que estaba en tercero, donde se hace la preparación para la Primera Comunión. La enseñanza religiosa será una de las materias importantes, en la que sobresale Teresa. La perspectiva de la comunión, como se esperaba, es un rayo de sol.

En diciembre de 1882, la salud de Teresa empieza a empeorar de manera extraña: sufre continuamente de dolores de cabeza, dolores en el costado, come poco y duerme mal. Su carácter también cambia: a veces se enoja con María y pelea incluso con Celina, con quien siempre habían sido muy buenas amigas. En el locutorio del Carmelo, Paulina está preocupada por su hermana menor, a quien le ofrece asesoramiento y cariñosas reprimendas.
En ese mismo año el médico Alfonso H. Notta diagnosticó la enfermedad de Teresita como una reacción a una frustración emocional con un ataque neurótico, sin duda causado por la partida de su hermana Paulina al monasterio carmelita de Lisieux el 2 de octubre de ese mismo año.

Durante las vacaciones de Semana Santa de 1883, Luis Martin organiza un viaje a París con María y Leonia. El tío Guérin acoge a Celina y Teresa en su hogar. El 25 de marzo en la tarde, mientras cenaban junto a Celina, Teresa se derrumba en lágrimas. La llevan a su cama; pasó una noche muy inquieta. Preocupado, su tío llamó al día siguiente a un médico, quien diagnóstico ""una enfermedad muy grave que nunca atacaba a los niños"." Dada la gravedad de su estado, envían un telegrama a Luis, quien regresa a toda prisa a Lisieux.

Varias veces al día, Teresa sufre de temblores nerviosos, alucinaciones y ataques de terror. Está pasando por una gran debilidad y, a pesar de que conserva toda su lucidez, no pueden dejarla sola. Sin embargo, la paciente repite que quiere asistir a la toma de hábito de Paulina, programada para el 6 de abril. La mañana del fatídico día, después de una fuerte crisis, Teresa se levanta, y curada en apariencia milagrosamente, va con su familia al Carmelo. Continúa transcurriendo todo el día, llena de alegría y entusiasmo. Pero al día siguiente tiene una recaída repentina: se llena de delirios que parecen privarla de la razón. El médico, muy preocupado, todavía no puede encontrar la cura de su enfermedad. Luis Martin temía que su "pobre niña" fuera a morir o a volverse loca.

Durante meses sufrió de dolores de cabeza y alucinaciones. Toda su familia estaba desesperada pensando que la muerte podría llegarle pronto. Su padre mandó incluso oficiar varias misas por su curación en el santuario de Nuestra Señora de las Victorias en París. El 13 de mayo de 1883, el día de Pentecostés, Luis Martin, Leonia, Celina y María, que permanecen junto a la cama de Teresa, se sienten impotentes para poder aliviarla, se arrodillan a los pies de la cama y se dirigen a una imagen de la Virgen. Más adelante, Teresa contaría: ""Al no encontrar ayuda en la tierra, la pobre Teresa también se vuelca hacia su Madre del cielo, orando con todo su corazón para que finalmente tenga misericordia de ella"...". En ese momento Teresa se siente abrumada por la belleza de la Virgen, y especialmente por su sonrisa: “"La Santísima Virgen me ha sonreído. ¡Qué feliz soy!"". En ese momento, la paciente se estabiliza delante de sus hermanas y su padre que están atónitos. Al día siguiente, todos los rastros de la enfermedad desaparecen, excepto dos pequeñas alertas en los siguientes meses. Teresa aún esta frágil, pero no va a sufrir en el futuro de ninguna nueva manifestación de estos trastornos.

En 1883, Teresa regresa al colegio y de inmediato se coloca a la cabeza en las clases de catecismo. También se prepara en los Buissonnets. Cada semana, Paulina escribe desde el Carmelo aconsejando a sus hermanas sacrificios y oraciones diarias para ofrecer a Jesús. Teresa toma estas listas en serio y se aplica a seguir cada una escrupulosamente.
El 8 de mayo de 1884, Teresa hizo su primera comunión en la iglesia del colegio de las Benedictinas en Lisieux.
Durante la misa, Teresa llora profusamente de alegría y no de tristeza. Describiría a la perfección la intensidad de este primer encuentro místico: ""¡Ah! Ese fue el primer beso de Jesús en mi alma ... Fue un beso de amor, me sentí amada, y le dije también: "Te amo, me entrego a ti para siempre. No hubo demandas, no hay luchas, sacrificios; hace mucho tiempo, Jesús y Teresita se habían mirado pobres y se habían entendido."” La profundidad espiritual de este día no impide que sea una oportunidad para disfrutar de la celebración con la familia y de los muchos regalos que recibe.

El 14 de junio de 1884 es confirmada por el obispo Abel Antoine-Flavien Hugonin, obispo de Lisieux. Su madrina de confirmación es su hermana Leonia. Al recibir el Espíritu Santo, la joven confirmada se deja maravillar por este ""Sacramento de Amor"", que, ella está segura, le dará la “"fuerza para sufrir"".

En 1885, después de escuchar un sermón del Padre Domin sobre los pecados mortales y el juicio final, las "penas del alma", que habían atormentado a Teresa y que parecían haber desaparecido, despiertan bruscamente. La niña, tan frágil, volverá a caer en la "terrible enfermedad de los escrúpulos." Teresa se convence de su pecado y desarrolla un fuerte sentimiento de culpa por todo. "Las acciones y pensamientos más simples se convierten en motivo de trastorno. "No se atreve a contarle sus penas a Paulina, que parece tan lejana en su Carmelo. Por suerte tiene aún a María, su "última madre", a quien ahora le cuenta todo, incluyendo sus pensamientos más "extravagantes". Esta le ayuda a preparar sus confesiones dejando de lado todos los temores. Dócil, Teresa le obedece. Esto tiene como consecuencia que oculta su "fea enfermedad" a sus confesores, privándose así de sus consejos.

En octubre de ese mismo año, Teresa regresa a la escuela, pero tiene que seguir afrontando las ofensas de algunas de sus compañeras y esta vez sola, pues su hermana Celina ya se graduaría pronto. En octubre de 1886 su hermana mayor María también entra en el Carmelo de Lisieux, donde llegará a ser la hermana María del Sagrado Corazón, mientras Leonia entra como religiosa en el convento de las Benedictinas de Lisieux, de donde sale al cabo de poco tiempo. Sorprendido y entristecido, Luis Martin conserva con él en los Buissonnets a sus dos hijas más jóvenes. Después de la partida de María su "tercera madre", Teresa pasa por un período de depresión y llora con frecuencia.

Sus ataques de escrúpulos alcanzaron su clímax y ella no sabe ya en quién confiar ahora que María ingresó en el Carmelo. La solución llegaría cuando empieza a rezar espontáneamente a sus cuatro hermanos que murieron siendo aun muy pequeños ("María Helena, José Luis, José Juan Bautista y María Melania Teresa"); Ella les habla con sencillez, para pedirles que intercedan por la paz para su alma. La respuesta fue inmediata y se siente definitivamente calmada, ella diría después: ""me di cuenta de que si era amada en la tierra, también lo era en el cielo".”

Uno de los episodios más recordados en su vida fue el de la gran conversión de la Navidad de 1886. Al llegar de la misa de Nochebuena junto con su padre y su hermana Celina, como era costumbre, corría para ver los zapatitos que ella dejaba allí para Papá Noel y descubrirlos llenos de juguetes pero los encontró vacíos. Su padre le dijo que subiese a cambiarse para cenar y algo cansado le dijo a Celina: "Afortunadamente este es el último año en que suceden estas cosas".
Ella explica el misterio de esta maravillosa conversión en sus escritos. Hablando de Jesús decía: "Esa noche fue cuando Él se hizo débil y sufriente por mi amor, y me hizo fuerte y valiente." Luego descubre la alegría de olvidarse de sí misma y añade: “Sentí, en una palabra, que la caridad entraba en mi corazón, la necesidad de que me olvide de buscar agradar, y desde entonces yo fui feliz." De repente, queda libre de los defectos e imperfecciones de su infancia, como su tremenda sensibilidad. Con esta gracia del Niño Jesús, que nacía esa noche, encontró "la fortaleza que había perdido" cuando su madre murió.

Muchas cosas van a cambiar después de esta Nochebuena de 1886, que marca el comienzo de la tercera parte de su vida, "la más bella". A la que ella llama la ""noche de mi conversión"" y escribió: ""Desde esa noche bendita, ya no fui derrotada en ningún combate, en lugar de eso fui de victoria en victoria y comencé, por así decirlo, una carrera de gigantes.""

Poco después de la “"gran gracia de la Navidad"”, oyó hablar de un hombre que había asesinado a tres mujeres en París, cuyo nombre era Enrique Pranzini. Teresa decidió adoptarlo como su primer hijo espiritual y ofreció sacrificios y varias misas, que mandó hacer con ayuda de su hermana Celina, para alcanzar de Dios la conversión de este pecador antes de su ejecución, o por lo menos algún signo de arrepentimiento. Pranzini había sido sentenciado a muerte y fue ejecutado el 31 de agosto de 1887, pero unos días después llegó a su casa el periódico católico "La Croix" (en español 'La Cruz') informando que, aunque Pranzini no quiso confesarse, antes de subir a la guillotina pidió un crucifijo para luego besarlo repetidas veces. Así, ella sintió que sus sacrificios y plegarias habían sido escuchadas.

La respuesta misericordiosa de Dios a sus oraciones por la conversión de Pranzini marca profundamente a Teresa y refuerza su vocación, también se vería más adelante que esto influiría bastante en su doctrina respecto de la misericordia divina que tanto la caracteriza. Y se decide completamente a convertirse en monja del Carmelo, para orar por todos los pecadores. 

Cuando contaba 14 años ya había tomado la resolución de convertirse en religiosa carmelita, sabe que tendrá que superar muchos obstáculos y pensando quizá en Juana de Arco, se dice a sí misma que ""conquistar la fortaleza del Carmelo es solo la punta de la espada"."

Se decide a obtener primero el consentimiento de su familia, incluyendo a su padre. Determinada, pero tímida, se decide a comentarle a su padre al respecto. Durante un momento duda entregándole su secreto, sobre todo porque Luis Martin sufrió un par de semanas antes, un pequeño ataque que lo dejó paralizado durante varias horas. El 2 de junio de 1887, el día de Pentecostés, después de orar todo el día, le presenta su solicitud en la noche, en el jardín de los Buissonnets. Luis, que según Teresa parecía tener una “"expresión celestial y llena de paz"” recibe la confesión de su hija con un profundo sentimiento de alegría y agradecimiento. Añade que Dios le hizo ""el gran honor de llamar a todas sus hijas"."

Pero el mayor obstáculo será el tío Isidoro Guerin, tutor de las niñas Martín, ya que vetará el proyecto de su sobrina. Aunque él no pone en duda la vocación religiosa de Teresa, le pidió que esperara a la edad de diecisiete años. La niña confía en que Paulina podrá ayudarla a obtener el permiso de su tío. Finalmente acepta el 22 de octubre de ese año.

Aun así siguió teniendo muchos inconvenientes para su entrada al convento, ya que ahora se enfrentaría a la negativa del Padre Delatroëtte, superior del Carmelo de Lisieux. Dolida por el fracaso de un caso similar al de ella, del que todo el mundo habla en Lisieux, acerca de que ya no aceptarán postulantes menores de veintiún años. Sólo el obispo podía autorizar tal cosa. Para consolar a su hija que llora constantemente, Luis le promete un encuentro con el obispo Monseñor Hugonin. Él la recibe en Bayeux el 31 de octubre de ese año, y la escucha expresar el deseo de consagrarse a Dios dentro de los muros del Carmelo, y de que lo conserva desde muy niña. Pero el obispo decide aplazar su decisión hasta después, cuando él haya tomado el consejo del Padre Delatroëtte.

Solo les queda una esperanza: hablar directamente con el papa. Luis Martin pronto comenzaría a preparar todo para una peregrinación a Roma, por el Jubileo sacerdotal del papa León XIII, organizada por las Diócesis de Coutances y Bayeux. Teresa y Celina viajarán con él. La partida está fijada para el 4 de noviembre de 1887.

Liderada por el obispo de Coutances, la peregrinación reunió a cerca de doscientos peregrinos, entre ellos setenta y cinco sacerdotes. El viaje comenzó en París, Luis Martin tuvo la oportunidad de visitar la capital con sus hijas. Fue durante una misa en Nuestra Señora de las Victorias (actualmente basílica menor), que Teresa logró derribar todas las dudas acerca de que si la Virgen le habría sonreído verdaderamente en su enfermedad de 1883 o no. Durante los últimos años había sufrido mucho al respecto, por su problema con los escrúpulos. Pero ahora lo tenía por verdad absoluta. Allí ella le confía el viaje y su vocación.

Un tren especial los lleva a Italia, después de cruzar Suiza. La chica no se cansaba de admirar los paisajes. Los peregrinos, casi todos de alto rango, son recibidos en los mejores hoteles. Una vez tímida y reservada, Teresa se siente algo incómoda con todo este lujo en medio de la sociedad que solo buscaba los bienes de este mundo. Es la más joven de la peregrinación, muy alegre y bonita, con sus hermosos vestidos, no pasa desapercibida.

Es durante este viaje que Teresa, que hasta el momento no había tenido un contacto cercano con muchos sacerdotes, que se da cuenta de las imperfecciones, debilidades y grandes defectos que tienen muchos de los sacerdotes que viajaban con ella. Todo esto la invitó con más fuerza a ofrecer su vida en el monasterio, orando cada día por los sacerdotes del mundo. Ella dice: “"En esta peregrinación comprendí que mi vocación era orar y sacrificarme por la santificación de los sacerdotes"”.

Durante la peregrinación logran visitar Milán, Venecia, Bolonia, el santuario de nuestra señora de Loreto. Finalmente, fue la llegada a Roma. El Coliseo, Teresa y Celina hacen caso omiso de las prohibiciones y entran en la arena para besar la arena donde la sangre de los mártires fue derramada. En ese lugar pide la gracia de ser martirizada por Jesús, y luego añadió: ""Sentí profundamente en el alma que mi oración fue contestada"”.

Pero Teresa no olvida el propósito de su viaje. Una carta de su hermana Paulina la animó a presentar su petición personalmente al Papa. El 20 de noviembre de 1887, por la mañana, los peregrinos asisten en la capilla papal a una misa celebrada por el Papa León XIII. Luego viene el momento tan esperado de la audiencia: el vicario general asigna los turnos para ver al Papa. Pero se prohíbe que se le dirija la palabra al Santo Padre pues sus setenta y siete años ya no le permiten gastarse durante mucho tiempo. Aun así, cuando le llega el turno a Teresa, previamente Celina como cómplice la había animado a que hablara, se arrodilla y sollozando dice : ""Santísimo Padre, tengo que pedirle una gracia muy grande"". El vicario le dice que se trata de una chica que quiere entrar en el Carmelo. ""Hija Mía, haced lo que los superiores le digan"" respondió el Papa. La chica insiste: ""Oh Santo Padre, si usted dice que sí, todo el mundo lo aprobaría"". León XIII replicó: ""Vamos a ver... Entrará si Dios lo quiere!"". Pero Teresa quiere una palabra decisiva y espera, con las manos cruzadas sobre las rodillas del papa. Dos guardias deben luego levantarla suavemente y llevarla a la salida.

Esa misma noche ella escribió sobre el fracaso a Paulina para decirle: "Tengo el corazón pesado. Sin embargo, Dios no puede darme alguna prueba que esté más allá de mis fuerzas. Él me dio el valor para soportar esta dura prueba”. Pronto, toda la peregrinación conoce el secreto de Teresa, incluso en Lisieux un periodista del diario El Universo publicó el incidente.

El viaje continúa, visitan Pompeya, Nápoles, Asís; entonces es hora de volver por Pisa y Génova. En Niza, aparece un rayo de esperanza para Teresa. El vicario hace algunas promesas diciéndole que apoyaría su solicitud. El 2 de diciembre, llegan a París, y, finalmente, al día siguiente, regresan a Lisieux. Así terminó una peregrinación de casi un mes que para Teresa fue un ""fiasco"”.

Inmediatamente después de regresar, Teresa fue al locutorio del Carmelo, donde se está desarrollando una estrategia. Pero el padre Delatroëtte se mantiene desafiante y desconfía de sus intenciones para ingresar. Él regaña a la superiora, madre Genoveva, la fundadora del Carmelo de Lisieux, y la Madre María de Gonzaga que llegaron a defender la causa de Teresa. El tío Guérin interviene a su vez, pero todo es en vano. El 14 de diciembre, Teresa escribió al obispo Hugonin y a su vicario general, a quien recuerda la promesa hecha en Niza. Humanamente, todo ha sido juzgado, ahora debe esperar y orar. En la víspera de Navidad, aniversario de su conversión, Teresa asistió a la misa de medianoche. Ella no puede contener las lágrimas, pero siente que la prueba hace crecer su fe y abandono a la voluntad de Dios: que era un error tratar de imponer una fecha para su ingreso al Carmelo.

Finalmente, el 1 de enero de 1888, la víspera de su décimo quinto cumpleaños, recibe una carta de la Madre María de Gonzaga informándole que el Obispo ha cambiado de opinión y que permite que las puertas del convento se abran para ella. Por un consejo de Paulina se decide que se retrase su ingreso hasta abril, después de los rigores de la Cuaresma. Esta expectativa es una nueva prueba para la futura postulante, que sin embargo ve una oportunidad para prepararse en su intimidad.

La fecha de entrada se establece finalmente para el 9 de abril de 1888, el día de la Anunciación. Teresa ingresa con quince años y tres meses. Cabe señalar que en aquel tiempo, una chica podría hacer su profesión religiosa a los dieciocho años. No era raro ver, en las órdenes religiosas, postulantes y novicios de tan sólo dieciséis años. La precocidad de Teresa, dadas las costumbres de la época, no es excepcional.

El 9 de abril de 1888 fue recibida en el monasterio de las carmelitas descalzas de Lisieux. En el monasterio ya estaban sus hermanas Paulina y María. Comenzó así su postulantado.

Los primeros meses dentro del monasterio fueron duros, llenos de trabajos que nunca había realizado y que le costaban bastante hacer a la perfección. Ella les prohíbe a sus hermanas que le faciliten los trabajos o la ayuden de alguna manera, pues insistían en cuidarla como si estuviera en los Buissonnets. Pero aun así, la joven postulante se adapta bien a su nuevo entorno. Teresa escribió: ""El Buen Dios me dio la gracia de no tener ninguna ilusión al entrar en el Carmelo: He encontrado la vida religiosa como me imaginé que sería. Ningún sacrificio me asombró”".

La madre superiora, María de Gonzaga, que antes se había dado a conocer como amable y gentil, la trata muy fríamente, con bastantes exigencias y hasta con una que otra humillación, pero todo lo hace para formarle un carácter propio de la vida religiosa, probar su vocación y que dejara a un lado cualquier rastro de orgullo y vanidad, lo cual Teresa se lo agradeció siempre e incluso siempre sintió una gran admiración hacia esta. La misma superiora comenta: "“Yo nunca habría pensado que tenía un juicio tan avanzado para tener quince años de edad! No hay una palabra que decir, todo es perfecto”".

Durante su postulado, Teresa también debe someterse a algunas intimidaciones por parte de otras hermanas, a causa de su falta de aptitud para la artesanía. Al igual que cualquier religiosa, descubre los desafíos de la vida en comunidad, relacionados con diferencias en el temperamento, el carácter, la susceptibilidad a los problemas o discapacidades. 
A finales de octubre de 1888, el capítulo provincial aprobó su toma de hábito. Aunque recibió la noticia con alegría, fue opacada un poco con la noticia de la recaída de salud de su padre, que solo unos meses antes se había escapado de casa sin sentido de razón hasta encontrarlo en la ciudad cercana de El Havre, preocupando así a toda la familia tanto fuera como dentro del monasterio. Finalmente, el 10 de enero de 1889, tomó los hábitos de la orden en la capilla del monasterio en presencia de su padre, hermanas y el resto de la familia. En la misma ceremonia, además de recibir el velo de novicia, también cambió su nombre al de "Teresa del Niño Jesús y la Santa Faz" (sagrado rostro).

En este período, se profundiza el sentido de su vocación: llevar una vida oculta, orar y ofrecer sus sufrimientos por los sacerdotes, olvidando su orgullo, se multiplican los actos discretos de caridad. Quiere convertirse en una gran santa pero no se hace ilusiones sobre sí misma. Escribió: ""me apliqué en especial en practicar las pequeñas virtudes, ya que no tengo la facilidad de practicar las grandes"."

En el transcurso de 1890, leyó las obras de San Juan de la Cruz, al que convirtió en su maestro espiritual. La contemplación de la Santa Faz nutre su vida interior. Profundiza su conocimiento y amor por Cristo meditando en su humillación con el pasaje del Libro de Isaías sobre el siervo sufriente (Isaías 53: 1-2). Esta meditación también la ayuda a comprender la situación humillante de su padre por la degeneración que le ha causado una terrible arterioesclerosis en el cerebro. Ella siempre lo había visto como una figura de su ""Padre Celestial"". Ahora encuentra señas de Luis Martin a través de Cristo, humillado e irreconocible.

El 8 de septiembre de 1890, a los diecisiete años y medio, hizo su profesión religiosa. La joven carmelita recuerda por qué responde a esta vocación: ""Yo he venido para salvar almas y, especialmente, para orar por los sacerdotes”". El 24 de septiembre 1890 se celebró la ceremonia, pública, donde toma el velo negro de profesa. Su padre no puede asistir, lo que entristece enormemente a Teresa. Es, sin embargo, la Madre María de Gonzaga, quien manifiesta que esta niña tiene diecisiete años y medio y la razón de alguien de treinta años, la perfección religiosa de una vieja novicia , que se consume en el alma y la posesión de sí misma, es una perfecta religiosa.

El 12 de mayo de 1892, se encontró por última vez con su padre. El 24 de junio de ese mismo año su hermana Leonia ingresó por segunda vez, en esta ocasión en el monasterio de la Visitación de Caen. Luis Martin murió el 29 de julio de 1894, después de ser custodiado y cuidado por Celina, su cuarta hija. También ella piensa, desde hace varios años, en entrar en el Carmelo. Con el apoyo de las cartas de Teresa, sostuvo el deseo de consagrarse a Dios en lugar de acceder al matrimonio. Celina aun así vacila entre la vida carmelita y una vida más activa, cuando se le propuso embarcarse en una misión encabezada por el padre Pichon en Canadá. Finalmente, siguiendo el consejo de sus hermanas, eligió el Carmelo. Ingresó el 14 de septiembre de 1894. En agosto de 1895, cuatro hermanas Martin se encuentran en el mismo. También se unirá a ellas su prima María Guerin, compañera de juegos de la infancia de Teresa.

Los años que siguen son los de la maduración de su vocación. Teresa ora sin grandes emociones sensibles, pero con fidelidad. Evita la intromisión en los debates que a veces perturban la comunidad. Multiplica los pequeños actos de caridad y preocupación por los demás, prestando servicios pequeños, sin hacerlos notar. Ella acepta en silencio las críticas, incluso de aquellas que pueden ser injustas y favorecer a las hermanas que son desagradables con ella. Trata de hacer todo, incluso las más pequeñas cosas con amor y la sencillez. Siempre reza mucho por los sacerdotes.

Durante 1891-1892, en el invierno, una epidemia de gripe cae en Francia. El Carmelo de Lisieux no es la excepción. Cuatro monjas mueren a causa de esta enfermedad. Y todas las hermanas se enferman, excepto tres de ellas, incluyendo a Teresa. Entonces procura darse de todo a sus hermanas postradas en cama. Les brinda atención, participa en la organización de la vida diaria del Carmelo, demostrando coraje y fortaleza en la adversidad, sobre todo cuando tiene que preparar el entierro de monjas fallecidas. La comunidad, que a veces la consideraba de poco valor e indiferente ahora la ha descubierto bajo una luz diferente.

Su vida espiritual se alimenta sobre todo de los Evangelios, que siempre lleva con ella. Esa costumbre no era común en la época, ni siquiera entre las religiosas de clausura. Ellas prefieren leer los comentarios de la Biblia que referirse directamente a ésta. Teresa prefiere mirar directamente ""la palabra de Jesús"," que la ilumina en sus oraciones y en su vida diaria, además de ser la base desde la que consolida su doctrina.

Su hermana Paulina (Inés de Jesús) es elegida priora del monasterio de Lisieux el 20 de febrero de 1893 y ella designa a Teresa el difícil cargo de ser vice-maestra de novicias, tratando de imprimir con gran dedicación la regla carmelitana a sus pupilas, para esto se ayudaba contando historias y hasta inventado parábolas. Fueron ellas las primeras en conocer su doctrina sobre “"el caminito"”. Entre las novicias a las que enseñaba sor María de la Trinidad se convertiría en su primera discípula.

En 1894, Teresa escribió sus primeras recreaciones piadosas. Estas son pequeñas obras de teatro, interpretada por algunas religiosas de la comunidad, con motivo de alguna festividad. Su primera recreación se la dedica a Juana de Arco, que siempre había admirado, y cuya causa de beatificación ya se ha introducido. Su talento para la escritura se le es reconocido. Otros escritos le serán asignados, un segundo sobre Juana de Arco, que se llevó a cabo en enero de 1895, además de unos poemas espirituales, a petición de otras religiosas.

A principios de este año, comenzó a sentir dolor de garganta y dolor en el pecho. Desafortunadamente, la madre Inés no se atreve a llamar a un médico que no sea el médico oficial de la comunidad.

En 1894 se celebró el centenario del martirio de los carmelitas de Compiègne. Este evento tiene una gran repercusión en toda Francia, y más aún en los monasterios carmelitas de Francia. Las monjas del Carmelo de Compiègne piden a sus hermanas de Lisieux contribuir a la decoración de su capilla. Teresa del Niño Jesús y Teresa de San Agustín bordan banderas para ser regaladas a este otro carmelo. Sor Teresa de San Agustín, al testificar en el proceso de la beatificación de Teresita, resalta el celo y la dedicación que se dio en esta ocasión. Dijo incluso que Santa Teresa decía: ""¡Qué felicidad si tuviéramos la misma suerte" (del martirio)"! Qué gracia”".

Teresa entró en el Carmelo con el deseo de convertirse en una gran santa. Pero a finales de 1894 después de seis años reconoce que este objetivo es imposible de alcanzar. Piensa que todavía tiene muchas imperfecciones y carece del carisma de Teresa de Jesús, Pablo de Tarso y muchos otros. Sigue siendo muy pequeña y está aun muy lejos del gran amor que le gustaría practicar.
Ella entiende que es en esta misma pequeñez en la que puede confiar para pedir la ayuda de Dios. Leyendo las sagradas escrituras, en el libro de los proverbios lee: "El que sea incauto, que venga a mí!" ("Prov. 9 - 4") esto le da una respuesta inicial. Siente que aunque es tan pequeña e incapaz puede entregarse a Dios con confianza. Pero entonces, ¿qué va a pasar con eso? Un pasaje del libro de Isaías da una respuesta que anima profundamente: "Ustedes serán como niños de pecho llevados en brazos y acariciados sobre las rodillas. Como un hijo a quien consuela su madre, así yo los consolaré a ustedes" ("Is 66, 12-13"). Concluye que el mismo Jesús la llevará a la cima de la santidad. Después escribiría: ""El ascensor que me debe elevar al cielo son tus brazos, ¡Oh Jesús! Por esto, yo no necesito crecer, por el contrario, tengo que seguir siendo pequeña, cada vez más y más"".

La pequeñez de Teresa, sus limitaciones se convierten en alegría, más que en desaliento. Porque es allí donde se realiza el amor misericordioso de Dios para con ella. En sus manuscritos lo describe como el descubrimiento del ""caminito"". En febrero de 1895 empezara a firmar sus cartas añadiendo regularmente "pequeña" antes de su nombre. Desde ese momento, Teresa utiliza el vocabulario de la pequeñez para recordar su deseo de una vida oculta y discreta. Ahora también lo utiliza para expresar su esperanza: cuanto más se sienta pequeña ante Dios, más se podrá contar con él.

El 9 de junio de 1895, en la fiesta de la Santísima Trinidad, Teresa tiene una inspiración repentina sobre ofrecerse a sí misma como víctima de holocausto al "amor misericordioso." Su intención era la de sufrir, a la imagen de Cristo y en unión con él, para reparar las ofensas contra Dios y ofrecer las penitencias que no hacían los pecadores.

De esta manera, 11 de junio, se ofrece al amor misericordioso de Dios para recibir de Dios ese amor que le falta para completar todo lo que quiere hacer: ""Oh, Dios mío! Santísima Trinidad, deseo amarte y hacerte amar, trabajar para la glorificación de la Santa Iglesia salvando las almas" [...] "Deseo cumplir perfectamente tu voluntad y alcanzar el grade de gloria que me has preparado en tu reino celestial. En resumen: deseo ser santa, pero conozco mi impotencia y mi debilidad, y te pido Dios mío, que tú mismo seas mi santidad”".

Unos días más tarde, cuando rezaba el viacrucis, ella es inflamada con un intenso amor por el buen Dios: "“Yo estaba quemándome de amor y sentí en un minuto, ni un segundo más, que no podría aguantar más esto sin morir"". Ella reconoce en esta experiencia, que es seguida rápidamente por la sensación de sequía espiritual, la confirmación de que su acto de ofrecimiento era aceptado por Dios.

En octubre de 1895, un joven seminarista, el padre Maurice Bellière pide al Carmelo de Lisieux la ayuda de una religiosa a través de la oración y el sacrificio, para su vocación misionera. La madre Inés se lo encarga a Teresa, que siempre ha soñado con tener un hermano sacerdote y lo recibe con gran alegría. Entonces comienza a multiplicar los pequeños sacrificios que ofrece para la misión del futuro sacerdote, y lo alienta en sus cartas. Y en febrero de 1896 le llega otra alegría con la profesión religiosa de su hermana Celina (Sor Genoveva, en el Carmelo).

Durante la Cuaresma de 1896, Teresa sigue rigurosamente los ejercicios y el ayuno. En la noche del jueves al viernes santo, sufrió un primer ataque de hemoptisis. Informó a la Madre María de Gonzaga, aunque le decía que no era nada serio. Una segunda crisis se produce de nuevo la noche siguiente. Esta vez, a la priora le preocupa y le permite llamar a su primo, el Dr.La Neele, para revisarla. El cree que el sangrado podría venir de la ruptura de un vaso sanguíneo en la garganta. Teresa no se hace ilusiones sobre su salud, pero al mismo tiempo no sentía miedo. Por el contrario, con la muerte pronto podría ascender al cielo y encontrar lo que ella había escogido en el Carmelo: su alegría estaba en su apogeo. Aun así sigue participando en todas las actividades de la comunidad, sin escatimar fuerzas.

Este período difícil es también un período de abandono, también llamado la "noche de la fe". Durante la Semana Santa de 1896, entró de repente en una oscuridad interior. El sentido de la fe que la animó tantos años, que la hacía feliz hasta el punto de querer "morir de amor" por Jesús, desapareció de su alma. En su oscuridad, oyó una voz interior que parecía burlarse de ella y la felicidad que ella esperaba en la muerte, a medida que avanza hacia la "noche de la nada". Sus luchas no son acerca de la existencia de Dios, sino en la creencia en la vida eterna, y si ella la merecería.

Ahora solo tiene una impresión: va a morir joven, para nada. No podía continuar su vida de carmelita. Sólo las canciones y poemas, que ella sigue componiendo, a petición de las hermanas, la ayudan en su lucha interior: ""Mi cielo es sonreír al Dios que adoro cuando él trata de ocultarse a mi fe"." La oscuridad sigue envolviéndola y persistirá hasta su muerte un año después. Sin embargo, vio esa noche como la batalla final, la oportunidad de demostrar su confianza inquebrantable en Dios. Negándose a ceder a este miedo a la nada, multiplica los actos de sacrificio. Quiere decirse con esto que sigue creyendo, aunque su mente ha sido invadida por las objeciones y dudas. Y aunque esta lucha es aún más dolorosa, aprovecha para compartir con sus hermanas su deseo de ser activa y hacer mucho bien después de su muerte.

A partir de mayo de 1896 la madre María de Gonzaga pide a Teresa patrocinar con su oración a un segundo misionero: el padre Adolfo Roulland. La correspondencia con sus hermanos espirituales es una oportunidad para desarrollar su concepto de la santidad: ""¡Ah! Hermano, la bondad y el amor misericordioso de Jesús son poco conocidos! ... Es cierto que para disfrutar de estos tesoros hay que humillarse, reconocer nuestra nada, y esto es lo que muchas almas no quieren".
En septiembre de 1896 Teresa todavía experimenta muchos deseos, quiere abarcarlo todo en la Iglesia: apóstol, sacerdote, misionero, mártir y doctor. Leyendo las cartas de San Pablo, en la Primera Epístola a los Corintios capítulo 13, es iluminada en lo profundo, como un rayo que la atraviesa. Entonces el significado más profundo de su vocación aparece de repente frente a ella, ""Por fin he encontrado mi vocación, MI VOCACIÓN ES EL AMOR ..."" De hecho, la vocación al amor incluye a todas las demás ; Así se cumplen todos los deseos de Teresa. ""Comprendí que el amor encierra todas las vocaciones, que el amor lo es todo, que el amor abarca todos los tiempos y todos los lugares, en una palabra, que el amor es eterno”." Teresa se esfuerza, cada vez más, para vivir enteramente por el amor. Y se esfuerza por vivir este amor en la compañía de todas sus hermanas de comunidad, especialmente con las que tienen temperamentos difíciles.

El padre Roulland le presentó a Teófano Vénard. Ella descubre sus escritos en noviembre de 1896 y Teófano se convierte para ella su modelo favorito. En su correspondencia ella le confiesa: ""Estos son mis pensamientos; mi alma es como la suya”". Luego copiará varios pasajes de Teófano Vénard en su testamento.

En enero de 1897, cuando Teresa acababa de cumplir veinticuatro años, escribe: ""Yo creo que mi carrera no durará mucho tiempo"". Sin embargo, a pesar del empeoramiento de la enfermedad durante el invierno, se las arregla para engañar a las Carmelitas y tomar su lugar de nuevo en la comunidad. En la primavera los vómitos, dolor severo en el pecho, y el toser sangre se convierten en algo diario y así, muy lentamente, se va apagando.

En junio, La madre María de Gonzaga le pide continuar escribiendo sus memorias (que le habían sido mandadas escribir en 1894 por su hermana Paulina cuando era priora a petición de varias de las hermanas de la comunidad. Después de su muerte estos manuscritos, tres en total, se unirían para publicar la primera edición de la Historia de un alma). Ahora los escribiría en el jardín, en una silla de ruedas especial utilizada por su padre en los últimos años de su enfermedad, y luego trasladada al carmelo. Su condición empeora, el 8 de julio de 1897 es llevada a la enfermería, donde permaneció durante doce semanas hasta su muerte.

Aun cuando ya sabía que esta era su última enfermedad, y todavía estando viviendo esa "noche de la fe", ya nada la priva de una certeza interior sobre la vida después de la muerte, Teresa se aferra a esta esperanza. El 17 de julio, se le escucha decir: ""Siento que pronto va a empezar mi misión de hacer amar a Dios como yo le amo, y de enseñar a muchos el camino espiritual de la sencillez y de la infancia espiritual. El deseo que le he expresado al buen Dios es el de pasar mi cielo haciendo el bien en la tierra, hasta el fin del mundo. Sí, quiero pasar mi cielo haciendo el bien sobre la tierra"."

El 17 de agosto, el Dr.La Neele examina a Teresa. El diagnóstico es claro: se trata de una tuberculosis pulmonar en su etapa más avanzada, uno de sus pulmones ya está perdido y el otro en parte, incluso llega a afectar a los intestinos. Su sufrimiento es extremo que ""alcanza a perder la razón"". Unos meses antes de su muerte; Teresa toma un poco de fuerza, y se encuentra incluso con algo de humor en medio de su lecho de enfermedad. Sus hermanas deberán registrar sus palabras (estas últimas palabras y conversaciones, anotadas desde mayo a septiembre de 1897, luego también serían publicadas bajo el título de últimas conversaciones). Le preguntan cómo deberían llamarla cuando la invoquen en la oración; ella responde que quiere ser llamada "Teresita".

El 29 de septiembre de 1897 comienza su agonía. Pasa una noche difícil, mientras sus hermanas la cuidaban. Por la mañana, dijo: ""Todo es pura agonía sin mezcla de consuelo"". Ella pide estar espiritualmente preparada para morir. La Madre María de Gonzaga la tranquiliza diciendo que siempre ha practicado la humildad, y su preparación ya está hecha. Teresa pensó por un momento y luego respondió: ""Sí, creo que siempre he buscado la verdad; sí, entendí la humildad de corazón..."". Su respiración se está haciendo más corta y se ahoga. Después de dos días de agonía, se siente agotada por el dolor: ""Nunca pensé que fuera posible sufrir tanto! ¡Nunca! ¡Nunca! No lo puedo explicar sino por el anhelo que tengo de salvar almas"". Sobre las 7: 20 de la noche del 30 de septiembre de 1897, y mientras apretaba fuertemente un crucifijo entre sus manos, dijo sus últimas palabras: ""Oh! le amo! ... Dios mío... te amo..."". Inmediatamente cae levemente sobre su almohada, y luego vuelve a abrir sus ojos por última vez. De acuerdo con las Carmelitas que estuvieron allí presentes, entró en un éxtasis que duró el espacio de un credo, antes de exhalar su último aliento. Permaneció con los ojos fijos cerca de la imagen de la Virgen María que le había sonreído de pequeña y que sus hermanas habían instalado en la enfermería desde que fue trasladada allí. Al instante de fallecer su rostro recuperó el suave color que le era natural. ""Yo no muero, yo entró en la Vida"", escribió en una de sus últimas cartas.

Inmediatamente la noticia fue llevada por Sor Inés de Jesús ("Paulina") a su hermana Leonia, que en una tercera y definitiva ocasión persevera en su vocación religiosa en el convento de La Visitación de Caen, y demás familiares que desde hace varios días se mantenían pendientes de la enfermedad y agonía de Teresa. Su cuerpo fue inmediatamente trasladado al coro del monasterio donde fue velado durante cuatro días. A sus funerales asistieron más personas que a los de cualquier otra carmelita fallecida antes de ella en ese mismo monasterio. Muchas personas pedían que las demás religiosas frotaran sus rosarios y objetos de devoción en el ataúd de la hermana recién fallecida. Fue sepultada el 4 de octubre de 1897, y según los testigos aún su cuerpo se encontraba rosado y flexible, como si acabase de morir. Fue la primera en ocupar el nuevo espacio que el monasterio había comprado en el cementerio de Lisieux. Las carmelitas, obedeciendo su voto de clausura, no pueden acompañar el desfile fúnebre hasta el cementerio, solo hacen una pequeña procesión hasta el coche fúnebre.

Poco después de la publicación de sus manuscritos autobiográficos en 1898, se desata en todas partes un "“Huracán de Gloria”" y cientos de peregrinos de toda Francia y de algunos otros países empiezan a llegar a Lisieux para orar sobre la tumba de la pequeña carmelita. La devoción a Teresita crece rápidamente y es acompañada por testimonios de curaciones físicas y conversiones. Pero es especialmente durante el periodo de la Primera Guerra Mundial cuando cientos de soldados franceses llevan estampas y medallas de la carmelita y cargan en sus bolsillos una versión más corta de su autobiografía llamada "“una rosa deshojada”". Después de la guerra peregrinan a Lisieux para agradecer a Teresa el haberlos ayudado y regresado con vida a casa. Muchos dejan sus condecoraciones y medallas militares como acción de gracias. Los testimonios enviados al Carmelo de Lisieux entre 1914 y 1918 son de casi 592 páginas. En 1914, el Carmelo de Lisieux recibe en promedio quinientas cartas al día.

Pronto es necesario colocar rejas de hierro que protejan la tumba de los peregrinos que desean llevarse flores o tierra de su sepultura. El papa San Pío X responde al clamor de miles de fieles que le piden se abra lo más pronto posible el proceso de Beatificación y Canonización de Sor Teresa del Niño Jesús, el 14 de junio de 1914 es introducida oficialmente su causa.

El proceso apostólico, por mandato de la Santa Sede, comienza en Bayeux en 1915. Pero es retrasado por la guerra, que termina en 1917. En ese tiempo se necesitaba un período de cincuenta años después de la muerte de un candidato a la canonización, pero el papa Benedicto XV exime a Teresa de ese período. El 14 de agosto de 1921, se promulgó el decreto sobre sus virtudes heroicas.

Son requeridos dos milagros para la Beatificación. El primero se da en un joven seminarista, de nombre Charles Anne, en 1906. Charles sufría de tuberculosis pulmonar y su estado era considerado desesperanzador por su médico. Después de dos novenas dirigidas a Sor Teresa del Niño Jesús, recupera pronto la salud. Un estudio radiográfico en 1921 muestra la estabilidad de la curación y que había desaparecido el agujero en el pulmón. El segundo milagro aparece en una religiosa, Luisa de San Germán, que sufría de una afección del estómago, ya muy avanzada para una cirugía. Pide a Sor Teresa durante dos novenas, después su condición mejora. Dos médicos confirman la curación.

Presentadas y aceptadas estas curaciones milagrosas, Teresa es Beatificada el 29 de abril de 1923 por el papa Pío XI.

Luego de su beatificación aparecen cientos de testimonios sobre prodigios y milagros, dos de estos son presentados ante el Vaticano para alcanzar su canonización, el primero es el caso de una joven belga, María Pellemans, con una tuberculosis pulmonar e intestinal avanzada y milagrosamente sanada en la tumba de Teresa. El otro caso es el de una italiana, la hermana Gabrielle Trimusi, que sufría de una artritis de la rodilla y tuberculosis en las vértebras que la llevaron a usar un corsé; se libera de forma repentina de sus enfermedades y deja el corsé después de un Triduo celebrado en honor de la Beata Teresa. El decreto de aprobación de los milagros es publicado en marzo de 1925.

En la Ciudad del Vaticano, el papa Pío XI manda celebrar por todo lo alto la canonización de Teresa y pide que toda la fachada de la Basílica de San Pedro sea decorada con miles de velas de sebo que la iluminaran en la noche. Esta era una costumbre que no se hacía desde hace 55 años. En América, el diario norteamericano "The New York Times" publica en primera plana "“Toda Roma admira la Basílica de San Pedro iluminada por una nueva santa”". Otro periódico aseguró que la ceremonia contaría con alrededor de 60.000 fieles. Una multitud que no se veía desde hace 22 años durante la coronación del papa Pío X.

Teresa del Niño Jesús es canonizada el 17 de mayo de 1925 por el mismo pontífice. A la ceremonia asistieron medio millón de personas, de entre las cuales se ha llegado a decir que estuvo San Pío de Pietrelcina gracias a su don de Bilocación. El papa Pío XI la llama la ""estrella de su pontificado"". Durante la canonización, Pío XI afirma acerca de Teresa de Lisieux:

""El Espíritu de la verdad le abrió y manifestó las verdades que suele ocultar a los sabios e inteligentes y revelar a los pequeños, pues ella, como atestigua nuestro inmediato predecesor, destacó tanto en la ciencia de las cosas sobrenaturales, que señaló a los demás el camino cierto de la salvación.""

En 1927 es proclamada patrona de las misiones pese a no haber abandonado nunca el convento, pero siempre rezaba por los misioneros y siempre fue su deseo ardiente el serlo hasta en los últimos confines de la tierra. Y en 1944 es proclamada copatrona de Francia junto a Santa Juana de Arco.

Es importante mencionar la gran devoción que manifestó el papa Pío XI a santa Teresita. La consideraba como "la estrella de su pontificado", incluso inauguró una estatua suya en los jardines vaticanos el 17 de mayo de 1927.

Edificada en su honor, la Basílica de Santa Teresa, en Lisieux, es uno de los edificios religiosos más grandes de Francia y el segundo lugar de peregrinación más importante del país, después del Santuario de Lourdes. Su construcción fue iniciada en 1929, bendecida por el Cardenal Eugenio Pacelli, futuro Pio XII, el 11 de julio de 1937 y consagrada en 1954.

El 19 de octubre de 1997, durante las celebraciones del primer centenario de su muerte, el papa San Juan Pablo II la proclamó Doctora de la Iglesia Universal, siendo la tercera mujer en recibir ese título —anteriormente, habían sido declaradas doctoras Santa Teresa de Jesús, también carmelita, y Santa Catalina de Siena. La siguió Santa Hildegarda de Bingen en el 2012.

Durante la ceremonia de la proclamación de su Doctorado, el papa le concedió el título de "“Doctor Amoris”" (Doctora del Amor) y afirmó sobre la santa:

"“Su enseñanza no sólo es acorde con la Escritura y la fe católica, sino que también resalta por la profundidad y la síntesis sapiencial lograda. Su doctrina es, a la vez, una profesión de la fe de la Iglesia, una experiencia del misterio cristiano y un camino hacia la santidad. Teresa ofrece una síntesis madura de la espiritualidad cristiana: une la teología y la vida espiritual, se expresa con vigor y autoridad, con gran capacidad de persuasión y de comunicación, como lo demuestra la aceptación y la difusión de su mensaje en el pueblo de Dios.”." (...) ""Tal vez en los escritos de Teresa de Lisieux no encontramos, como en otros Doctores, una presentación científicamente elaborada de las cosas de Dios, pero en ellos podemos descubrir un testimonio iluminado de la fe que, mientras acoge con amor confiado la condescendencia misericordiosa de Dios y la salvación en Cristo, revela el misterio y la santidad de la Iglesia.""

En la misma ceremonia también aseguraría:

"“Así pues, con razón se puede reconocer en la santa de Lisieux el carisma de Doctora de la Iglesia, tanto por el don del Espíritu Santo, que recibió para vivir y expresar su experiencia de fe, como por su particular inteligencia del misterio de Cristo. En ella confluyen los dones de la ley nueva, es decir, la gracia del Espíritu Santo, que se manifiesta en la fe viva que actúa por medio de la caridad”."

Publicada por primera vez en 1898 (un año después de la muerte de Teresa) es uno de los clásicos espirituales más famosos del último siglo. Ha sido traducido a 42 idiomas. Su lectura ha conmovido a millones de personas alrededor del mundo y ha arrastrado a la conversión a muchísimos más. Especialmente en este libro se consigue sumergirse no solo en la vida de Teresita sino además en su intensa vida espiritual y profundidad doctrinal. Es en estos manuscritos donde salta a la vista su profundo conocimiento de las sagradas escrituras, con más de mil citas bíblicas, 400 del Antiguo Testamento y 600 del Nuevo. 
Está compuesto por los manuscritos A, B y C que Teresita escribió por orden de su superiora, en aquel entonces Inés de Jesús (su hermana Paulina), y por petición de toda la comunidad del monasterio. Luego de su muerte en 1897 los manuscritos se editaron, se unieron y se publicaron como una sola obra bajo el título de “Historia de un alma” que inmediatamente comenzó a inspirar y levantar la fe de miles de personas.

El manuscrito A lo dedica a la Madre Inés durante el año de 1895. Durante el invierno de 1894 la hermana Teresa, priora del Carmelo, le ordenó escribir todos los recuerdos de su infancia. A finales de enero de 1895 Teresa compró un pequeño cuaderno de escuela y se puso manos a la obra, por lo general escribía en la noche después del oficio de Completas. Con humor y un tono alegre, sin plan establecido, no escribe la historia de su vida, más bien la ""historia de su alma"", que ella llamaba Historia de primavera de una pequeña flor blanca. Esta relectura es beneficiosa porque le ayuda a comprender mejor el significado de lo que vivió. Al final, llena seis cuadernos a lo largo de 1895 y se lo entrega a la priora el 20 de enero de 1896.

El manuscrito B es un conjunto de cartas a la madrina de Teresa, su hermana María (María del Sagrado Corazón). Se podria definir como el corazón de su autobiografia por ser el manuscrito que recoge gran parte de doctrina espiritual. 
En septiembre de 1896, mientras que Teresa sabe la gravedad de su enfermedad y entraba en la "noche de la fe", comenzó su retiro anual. Aprovecha los momentos de silencio y meditación para escribir cartas dirigidas directamente a Jesús. Ella describe lo que vivió durante unos meses, pero sobre todo las gracias recibidas en septiembre de 1896 e hizo el gran descubrimiento de que "el amor era su vocación". María le pidió que preparara una presentación de su "pequeña doctrina", ella le entrega las letras que componen ""La carta de la pequeña voz de la infancia"".

El manuscrito C que fue escrito en obediencia a la Madre María de Gonzaga, en realidad era para la madre Inés, que al darse cuenta de que su hermana va a morir, le suplico a la priora para que mandara a Teresa seguir con la historia de su vida. Empieza a escribir en una pequeña libreta de cubierta negra del 3 al 4 de junio de 1897. Describe las gracias que recibió en su vida, descubrimientos espirituales que ha hecho, incluyendo el ""caminito"". A principios de julio, afectada por una fiebre cada vez más fuerte, ya no puede mantener firme su pluma y continuó con un pequeño lápiz. A finales de agosto, carcomida por la enfermedad, debe renunciar a escribir para siempre.

Cartas: escribió más de 250 cartas. Las primeras dirigidas a diferentes familiares, amigos y conocidos pero es especialmente durante su vida religiosa cuando escribió muchas cartas que arrojan luz sobre el desarrollo de su espiritualidad, especialmente las dirigidas a su hermana Celina y sus hermanos espirituales, los padres Roulland y Bellière. Postrada en la cama, durante sus últimas semanas de vida, Teresa pasa más tiempo escribiendo, pero la enfermedad la va derrotando y el 16 de julio, escribe sus últimas cartas, despidiéndose.
Poemas: escribió 62 poesías, la primera de ellas, "el rocío divino o la leche virginal" fue dedicada a Sor Teresa de San Agustín, durante febrero de 1893. A esta primera le seguirían varias otras que hoy destacan como "vivir de amor", "mi canto de hoy", "arrojar flores", "mis armas", "mis deseos junto a Jesús escondido" y muchas otras más donde ella expresa lo que se encuentra en lo profundo de su corazón.

Oraciones: Dejó 21 oraciones en las que se puede confirmar su profunda consagración a Dios, animada por la intercesión de la virgen María y de los santos e inflamada por el deseo de salvar muchas almas. De entre ellas "La ofrenda como holocausto al amor misericordioso" es la más conocida y compartida, también se puede destacar otras como el "billete de su profesión" y la "oración para alcanzar la humildad".

Recreaciones piadosas: también escribe 8 recreaciones piadosas (obras de teatros), la primera en enero de 1894 para festejar a la Priora. Ella eligió el tema de Juana de Arco, a la que considera su ""querida hermana"" y cuya beatificación ya estaba en marcha. Es aplaudida por las Carmelitas que descubren su talento y ahora con frecuencia la solicitan para componer otras obras, teniéndola en cuenta como la ""poeta de la comunidad"". Compone muy libremente, se inspira en su lectura, especialmente el Cantar de los Cantares, y expresa sus deseos, sus miedos, su amor de Jesús sin ""preocuparse por el estilo"".

Al año siguiente, ella escribió y dirigió una pieza dramática con seis personajes disfrazados llamada "Juana de Arco cumpliendo su misión". Ella misma hace el papel de Juana, y luego posa para unas fotografías junto a Celina, la priora le permitió mantener su cámara, un hecho excepcional en el Carmelo en ese momento. De las 47 fotos que se conservan de ella, 4 antes de entrar al monasterio y 43 ya dentro, estas son de las más curiosas junto a las que se tomaron algunas horas después de su muerte.

La Doctrina de Teresa es ante todo una pedagogía de la santidad en medio de la vida cotidiana. Su enseñanza es un estímulo para buscar la santidad, incluyendo a los cristianos que dudan de su capacidad para responder a esta llamada apoyándose en la afirmación de que solo los que se ven así mismo como niños pobres e indefensos totalmente necesitados del padre Dios, son los dignos del Reino de los cielos.

En la época de Teresa, marcada por la herencia jansenista, muchos pensaban que la santidad era reservada para algunas almas elegidas, viviendo impresionantes fenómenos místicos o haciendo grandes cosas. A pesar de que no había hecho nada especial, Teresa todavía pensaba constantemente que ella podría convertirse en una santa.

En su búsqueda de la santidad, ella creía que no era necesario llevar a cabo actos heroicos, o grandes obras, con el fin de alcanzar la santidad y para expresar su amor a Dios. Ella escribió:

"“El amor en sí se demuestra con hechos, así que ¿cómo yo hago para mostrar mi amor?, las grandes obras me son imposibles. La única manera en que puedo demostrar mi amor es por la dispersión de flores y estas flores son cada pequeño sacrificio, cada mirada, cada palabra, y el hacer por amor hasta los actos más pequeños”."

Entre 1893 a 1894, como resultado de su discernimiento interior, ella confía su pequeñez ante Dios y lo invita a actuar en ella, este sería el nacimiento del caminito o pequeña vía. En 1895, escribió: ""Siempre siento la misma confianza audaz para convertirme en una gran santa, porque no dependo de mis méritos, ya que no tengo ninguno, solo espero en Aquel que es la virtud, incluso la santidad misma. Es sólo Él, contentándose de mis débiles esfuerzos, quien me va a levantar hacia Él mismo y, cubriéndome con sus infinitos méritos, podre ser santa"."

En sus escritos, Teresa solo menciona el caminito una vez y nunca se refiere a el cómo "infancia espiritual". Fue su hermana Paulina quien agregó esta palabra para definir mejor su enseñanza sobre la humildad y el Abandono total, como un niño, en los brazos de Dios. Ella misma aclaró que Teresita nunca había utilizado esa palabra. En mayo de 1897, Teresa escribió al Padre Adolfo Roulland: ""Mi camino es todo confianza y amor"." Para el padre Mauricio Bellière ella escribió: ""y yo, con mi manera, haré más que tú, así que espero que un día Jesús te haga caminar por el mismo camino que yo"." 

El abandono en su espiritualidad y doctrina marca uno de los puntos esenciales para poder caminar por su caminito. Para Teresa de Lisieux el renunciar y abandonarse no significa vivir una continuidad de sufrimientos y penitencias extremas. Ella lo enseña como una disposición del corazón, que cuando ya ha renunciado a todo lo que le ata al mundo, a sus vanidades, preocupaciones y al orgullo que nos lleva a pensar en que solos somos capaces de vivir y existir, es por fin libre de entregarse del todo al Padre del Cielo y depender únicamente de su voluntad. Es así pues el abandono fruto del ejercicio de la humildad, que ya mucho antes de ella también exponía San Francisco de Asís, y también el instrumento perfecto para cumplir lo dicho en el evangelio: "El que quiera venir en pos de Mí, niéguese a sí mismo (Mt. 16, 24)". Escribiría al respecto:

"“A veces, cuando leo tratados espirituales en la que se muestra la perfección con mil obstáculos, rodeado por una multitud de ilusiones, mi pobre mente rápidamente se cansa. Cierro el libro que está rompiéndome la cabeza y secando mi corazón, abro la Sagrada Escritura. Entonces todo parece luminoso para mí; una sola palabra descubre para mi alma horizontes infinitos; la perfección parece simple; Veo que es suficiente reconocer la propia nada y abandonarse, como un niño, en los brazos de Dios. Dejando a las grandes almas, a las grandes mentes, los libros hermosos que no puedo entender, me alegra ser pequeña porque sólo los niños, y los que son como ellos, serán admitidos al banquete celestial”."

Pasajes como este han dejado abierto el camino a la acusación de que su espiritualidad es sentimental e inmadura. Sus defensores responden que ella desarrolló un enfoque para la vida espiritual que la gente de todos los orígenes pueda entender y adoptar.

Otro punto esencial en su doctrina es la confianza en la misericordia y el amor de Dios. Por encima de todo antepuso siempre la misericordia divina, ante la cual confía y con la que nada hay que temer. Ante todo, Dios es Padre; y Jesús es su Hijo misericordioso. Escribió: ""¡Oh Jesús!... estoy segura de que, si por un imposible, encontraras un alma más débil, más pequeña que la mía, te complacerías en colmarla de favores aún más grandes, si ella se abandona con entera confianza a tu misericordia infinita."" (Manuscrito B).

En una carta del 17 de septiembre de 1896 a su hermana escribió la frase que resume el mensaje e ideario de sus ideas y pensamientos más arraigados, el motor de su existencia: ""La confianza, y nada más que la confianza, es la que debe conducirnos al amor de Dios"." Se ha llegado a decir que Teresa de Lisieux ya había encontrado el tesoro teológico de la misericordia divina, varios años antes de que Santa Faustina Kowalska recibiera las revelaciones de Jesús misericordioso en 1931.

Este sentido de la misericordia es crucial en los últimos meses de su vida, cuando pasa a través de la prueba de la ""noche de la fe"". Durante este período, se ve acosada de tales tentaciones que logra entender mejor lo que viven los más grandes pecadores. Sin embargo, ella sigue creyendo en la infinita misericordia de Dios para con los que se entregan a Él. En julio de 1897, cuando ya está en sus últimos meses, su hermana Paulina le dice que su confianza en Dios se debe a que ella había sido preservada del pecado mortal. Teresa le contesta: ""Dices bien, mi madre, aunque yo hubiera cometido todos los crímenes posibles tendría una gran confianza en Dios, porque todos nuestros pecados, si confiamos en la divina misericordia, son como una gota de agua arrojada a un gran horno encendido"."

Su última carta al padre Bellière en agosto de 1897, termina con estas palabras: ""No puedo temer a un Dios que se hizo tan pequeño por mí... Lo amo... Porque Él solo es amor y misericordia!"".

Teresa ha demostrado, a través de su vida y sus escritos, que la santidad es accesible para todos. Es también una anticipación del Concilio Vaticano II, la Constitución dogmática sobre la Iglesia (Lumen Gentium) del Concilio hace hincapié en que todos los cristianos están llamados a la santidad.

A lo largo de los años, miles de personas, creyentes y no creyentes, se han sentido atraídos por el testimonio que Teresa dejó en sus escasos 24 años de vida. Y por esto mismo ha despertado una gran devoción en el mundo, prueba de ello es la gran afluencia de peregrinos que, después de Lourdes, visitan Lisieux donde los puntos imperdibles son los Buissonnets, el Carmelo ("donde reposan la mayor parte de sus reliquias"), la monumental Basílica, una de las más grandes iglesias de toda Francia, construida en su honor y el cementerio donde reposaron sus restos durante 26 años. Bien se puede decir que junto a San Francisco de Asís, con quien tiene mucho en común en cuanto a su humilde pero intensa vida espiritual, se ha convertido en una de las figuras más importantes de la historia del catolicismo. Entre los devotos más famosos que ha tenido "“Teresita”", varios de ellos ya en los altares, se puede nombrar a:

Santos:

Beatos:

Venerables:

Siervos de Dios:

La vida de Santa Teresita del Niño Jesús ha sido llevada al cine y la televisión en las siguientes producciones:






</doc>
<doc id="15248" url="https://es.wikipedia.org/wiki?curid=15248" title="Evangelio de Juan">
Evangelio de Juan

El Evangelio de Juan, también llamado Evangelio según san Juan o Evangelio según Juan, y conocido como «el cuarto evangelio», es uno de los evangelios canónicos constitutivos del Nuevo Testamento, caracterizado por las marcadas diferencias estilísticas y temáticas, como así también por las divergencias en su esquema cronológico y topográfico respecto de los otros tres, llamados evangelios sinópticos (Mateo, Marcos y Lucas). El Evangelio de Juan no solo contiene muchos pasajes sin equivalente en los otros evangelios canónicos, sino que aun los pasajes con cierta similitud son presentados de forma totalmente diversa en cuanto al contenido, al lenguaje, a las expresiones y giros con que predica Jesús de Nazaret y a los lugares de su ministerio. La tradición apostólica atribuye la autoría de este evangelio a Juan el apóstol y evangelista aunque, dada la falta de unidad en su redacción final, el estilo y la fecha supuesta de redacción (en torno al año 90 d. C.), entre otros puntos, se cuestiona tanto la autoría en sí como sus alcances (redactor, comunidad responsable). Existe la posibilidad de que el Evangelio de Juan fuera fruto de la comunidad fundada alrededor de uno de los discípulos de Jesús, presentado en el evangelio con el título de «discípulo a quien Jesús amaba», seguramente la de Éfeso.

Entre las características del Evangelio de Juan, se acepta ampliamente la de ser un escrito para la meditación en el que sobresalen los discursos como forma de reflexión en torno a la figura de Jesús de Nazaret, a quien se presenta desde el prólogo como el "Logos", la Palabra eterna de Dios. Es un evangelio sumamente simbólico y litúrgico, que enmarca el ministerio público de Jesús en la sucesión de festividades judías (entre ellas, la Pascua judía, la Fiesta de la dedicación o de las luminarias y la Fiesta de los tabernáculos o de las tiendas). Muchos estudiosos han visto en el Evangelio de Juan un carácter marcadamente místico.

Las polémicas de que fue y es objeto el Evangelio de Juan son el resultado de su singularidad. No se trata de una obra corriente: se disputa su autor, el ambiente que haya podido influir en su pensamiento y sus modos de expresión, su estructura literaria, sus fuentes y hasta la naturaleza del libro. Con todo, siempre fue recibido sin reticencias por parte de la Iglesia. La bibliografía sobre el Evangelio de Juan se acrecentó mucho en el último siglo, y hoy es sumamente abundante. Junto con los numerosos análisis que de él se hicieron, se puso aún más de manifiesto su profundidad, que supera el marco estrictamente religioso (cristológico, soteriológico y eclesiológico) y que, a través del tiempo, alcanzó los más diversos campos de la cultura y de las artes.

Existen numerosos papiros que contienen fragmentos del Evangelio de Juan. Algunos de ellos presentan una escritura que data de fechas muy próximas al momento estimado de redacción del evangelio.
Se destacan particularmente los siguientes, catalogados según la clasificación de Aland y Aland, como "papiros de Categoría I":


La datación mayoritaria sitúa a este evangelio en los años 90 d.C.

Las dataciones más tardías están limitadas por el papiro P52 (hacia 125-150), y por las menciones al Evangelio de Juan que hacen Ireneo de Lyon y el Fragmento muratoriano hacia el año 180, así como Clemente de Alejandría y Tertuliano hacia 200.

Las dataciones más tempranas (P. Gardner-Smith; A. T. Olmstead; E. R. Goodenough; H. E. Edwards; B. P. W. Starther Hunt; K. A. Eckhardt; R. M. Grant; G. A. Turner; J. Mantey; W. Gericke; E. K. Lee; L. Morris; S. Temple; J. A. T. Robinson) se basan en los siguientes argumentos:

Ireneo de Lyon (ca. 130 - ca. 202) señaló a Éfeso como lugar de composición del Evangelio de Juan, ya en tiempos del emperador Trajano (98 a 117). La época del comienzo del mandato de Trajano coincidiría con la datación de muchos especialistas, tal como se mencionó anteriormente.

La mayoría de los escrituristas acepta el dato del lugar de composición propuesto por Ireneo. En cambio, B. P. W. Stather-Hunt y G. W. Broomfield se inclinaron por Alejandría (considerando la difusión que el Evangelio de Juan tuvo en Egipto). W. Bauer y Burney argumentaron a favor de Antioquía u otro lugar de Siria. También se ha propuesto algún lugar hacia el este del lago de Tiberíades dentro del reino de Herodes Agripa II. Pero estos argumentos han recibido escasa aceptación. En la consideración de Raymond Edward Brown, Éfeso continúa ostentando la primacía entre las demás candidaturas a la identificación como lugar en que se compuso el Evangelio de Juan, por la casi unanimidad de las voces antiguas que tratan del tema y por el paralelismo entre el Evangelio de Juan y el Apocalipsis, obra que pertenece claramente al área de influencia de Éfeso.

En nuestros días, se admite en general que la lengua original del Evangelio de Juan es la koiné, una variedad del griego. Algunos autores plantearon la hipótesis de un texto original desaparecido en arameo. Esta hipótesis fue revisada extensamente, pero no tuvo aceptación entre los especialistas.

El evangelio presenta una interrupción notable al final del capítulo 12 admitida por todos los comentaristas, por lo que la obra queda dividida en dos partes principales, a la que se suma un añadido o epílogo general.

En la primera parte se reitera con insistencia que "todavía no ha llegado la hora". En el capítulo 12 se anuncia que esa hora ha llegado, y en la segunda parte se describe lo que sucede en esa hora, ya desde su prólogo: se trata de "la hora de Jesús de pasar de este mundo al Padre", la hora de su glorificación.

Así, en el Evangelio de Juan se distinguen dos tiempos: la primera parte, cuando "todavía no ha llegado la hora", Jesús se revela a través de "signos" o "gestos simbólicos". En la segunda parte, "habiendo llegado la hora", la revelación se produce en la crucifixión y muerte de Jesucristo, tiempo de su glorificación.

Una característica propia del Evangelio de Juan es su gran obertura coral, la introducción (1:1-5) que ha sido y es base del Credo cristiano. Solo el Evangelio de Juan inicia su obra con un himno para ser cantado por la comunidad antes de la lectura del evangelio. El origen de este himno es desconocido y se discute si el mismo autor del evangelio lo escribió o si lo tomó de otra fuente. Se suele sostener la hipótesis de que el autor del evangelio, una vez que su obra estuvo terminada, escribió el prólogo como himno que contiene las ideas centrales del evangelio, las claves para su comprensión.

En el prólogo del Evangelio de Juan se presenta al Logos (Λóγος), la «Palabra» de Dios, en su itinerario desde antes de la creación hasta la encarnación de Jesucristo. En el desarrollo del Evangelio de Juan se presenta que la Palabra estaba en Dios, que es una con el Padre, y que preexistía a la creación del mundo; que fue enviada al mundo por el Padre, para llevar a cabo su misión: transmitir al mundo la gracia y la verdad, y que concluida su misión vuelve al Padre. Juan 1:1 dice:

Se percibe que algunos pasajes del Evangelio de Juan parecen desordenados o, al menos, no muy elaborados en su edición definitiva. Hay textos que no corresponden con el contexto, se producen cortes llamativos y hay falta de unidad en varios relatos y discursos. Esto se puede ilustrar con varios ejemplos.

También es curiosa la falta de unidad del relato, que se descubre en varios pasajes:

Se han presentado varios intentos de explicación. La teoría actualmente más difundida es la de las ediciones múltiples, es decir, que el Evangelio de Juan es el resultado de un texto que creció con el transcurso del tiempo, con añadidos y notas provenientes del mismo autor o de otros miembros de la comunidad (Raymond E. Brown propuso la existencia de una comunidad joánica que habría participado en la edición y quizá en la redacción final del evangelio).

Los puntos notables de este evangelio son (1) la relación entre el Hijo y el Padre, (2) entre el redentor y los creyentes, (3) el anuncio del Espíritu Santo como Consolador, y (4) el énfasis sobre el amor como un elemento de carácter cristiano.

El evangelio fue escrito para personas conocedoras de la cultura judía y al mismo tiempo en contacto con el pensamiento griego; además se les pone en guardia frente al gnosticismo.

El lenguaje de una obra suele ser un descriptor de la personalidad del autor y de su relación con el grupo en que vive. Comparando la cantidad de veces que aparecen ciertas palabras en los Evangelios sinópticos, en los "Hechos de los Apóstoles" y en el Evangelio de Juan (Tabla 1), se observa la terminología que domina al cuarto evangelio, y la importancia que éste otorga a considerar a Dios como «Padre» y a vivir la «vida» verdadera, que para el autor del evangelio consiste en «permanecer» en el «amor», la «luz» y la «verdad», ya que viviendo así se «conoce» a Dios, se «cree» en él, y se «da testimonio» de él.

El texto que nos ha llegado se caracteriza por gran sobriedad en las formas. En general pese a que los encabezados de los textos están realzados con frases relativamente complejas de gran elegancia, el grueso del texto es pobre tanto en vocabulario como en estructuras gramaticales, resultando en algún caso manifiestamente oscuro. Como señala Castro Sánchez, el evangelio «ha sido compuesto en un estilo extremadamente sencillo, con una sintaxis elemental y un vocabulario reducido. Sólo encontramos unas mil palabras diferentes. El lenguaje es directo. Usa con mucha frecuencia el presente histórico. Las frases se unen muchas veces con la partícula kai (“y”). A pesar de esta pobreza, se ha logrado una obra que pudiéramos denominar artística, porque ha dotado a ciertos vocablos vulgares de una dignidad y profundidad insospechadas».

En el Evangelio de Juan, se encuadra la vida pública de Jesús con dos escenas en las que aparece su madre. Se trata de las bodas de Caná, y de la crucifixión y muerte de Jesús. El Evangelio de Juan guarda al respecto ciertas particularidades:

En el Evangelio de Juan, María es vista no solo como personalidad real sino además con un valor simbólico:

El Evangelio de Juan presenta la figura del discípulo a quien Jesús amaba en cinco pasajes. La mayoría de los estudiosos concuerda en que se trata de un personaje real, un testigo sobre cuyo testimonio fiable descansa la veracidad del propio evangelio: «El que lo vio lo atestigua, y su testimonio es verdadero; y él sabe que dice verdad, para que también vosotros creáis» (Juan 19, 35). La tradición cristiana lo ha identificado con Juan el Apóstol, aunque el Evangelio de Juan nunca lo menciona por su nombre. Existen discrepancias entre los exégetas sobre la identificación de esta figura, sin que al presente pueda asegurarse una solución que satisfaga a todos.

Al igual que en el caso de la madre de Jesús, el Evangelio de Juan otorga al personaje del discípulo amado un valor simbólico adicional al de su identidad histórica.

Considerando la dimensión simbólica del Evangelio de Juan, el discípulo amado por el Señor se identifica con el discípulo ideal de Jesús. El discípulo amado es aquel que:

En algunos pasajes del Evangelio de Juan, los adversarios de Jesús de Nazaret son designados como «los judíos», en tanto que en ciertos versículos se refiere a Jesús y sus discípulos como si no fueran judíos.

En algunos casos, los enemigos de Jesús son presentados como «judíos» aunque se tratara de galileos, es decir, habitantes de Galilea que murmuraban de él, o que discutían entre sí sobre él. El Evangelio de Juan puntualiza que nadie hablaba abiertamente de Jesús «por temor a los judíos». También Jesús se presenta refiriendo a sus adversarios como judíos, y aparecen en el evangelio expresiones tales como: «Jesús dijo a los judíos...». Jesús es llamado «judío» solamente por los extranjeros: por la mujer samaritana, y por Poncio Pilato. Como varios grupos religiosos no son mencionados (saduceos, zelotes, herodianos, etc.), «judíos» sería un término usado por el evangelista para designar a todos esos grupos en general y a las autoridades religiosas de Jerusalén de esa época en particular.
Esto aparece incluso en diálogos que involucran a otros personajes, como los padres del ciego de nacimiento quienes, aunque supuestamente eran judíos, actuaban regidos por su «temor a los judíos»:

De todo lo anterior surge que el Evangelio de Juan utiliza en general el término «judío» para designar mayormente a aquellos que no aceptaban a Jesús. Con todo, se puede también observar que el término «judío» no aparece siempre con acepción peyorativa, porque el evangelista retuvo el texto en el que este nombre aparece unido al mayor elogio puesto en labios de Jesús de Nazaret en su diálogo con la mujer samaritana:

Además, el término «israelita» se usa en el Evangelio de Juan como título honorífico, y varios personajes que son presentados como judíos aparecen rodeados por una luz positiva, como sucede con Nicodemo, «notable entre los judíos», que defendió a Jesús ante los fariseos, y junto con José de Arimatea se ocupó de sepultarlo luego de su muerte. Incluso se menciona en varios pasajes a judíos que creyeron en Jesús.

El evangelista parece sugerir que la práctica de la excomunión y exclusión de la sinagoga existía ya en tiempos de Jesús, como también sugieren los manuscritos del Mar Muerto. Pero es posible que el Evangelio de Juan describa conflictos que tuvo la comunidad cristiana del evangelista con los miembros de la comunidad judía y que los proyecte hacia el pasado. En efecto, el Evangelio de Juan fue probablemente escrito tras la destrucción del templo de Jerusalén en el año 70, época en la que los seguidores de Jesús de origen judío fueron expulsados oficialmente de las sinagogas. Así, el Evangelio de Juan estaría adelantando a los tiempos de Jesús la situación particular que sufrió la comunidad joánica.

El Evangelio de Juan es el evangelio canónico en que más asiduamente se cita a los apóstoles. Según Chapman, el Evangelio de Juan menciona nombres de apóstoles 74 veces, contra 50 del Evangelio de Marcos, 43 del Evangelio de Lucas y 40 del Evangelio de Mateo. Entre ellas se destacan las siguientes citaciones: 40 veces a Simón Pedro (como Simón, Pedro, Simón Pedro, o Cefas), 5 veces a Andrés, 12 a Felipe, 1 a Judas –no el Iscariote– (probable Judas Tadeo), 7 a Tomás, y 11 a Judas Iscariote.

Llamativamente, el Evangelio de Juan no hace mención de Juan el Apóstol siquiera una vez, ni tampoco de su hermano Santiago el Mayor. Aun la expresión que los agrupa a ambos, «hijos de Zebedeo», aparece únicamente una vez, en el apéndice que la gran mayoría de los estudiosos clasifica como un agregado posterior a la redacción del "corpus" del evangelio. Ese silencio absoluto respecto de Juan el Apóstol y de su hermano Santiago es tanto más sugestivo cuanto que Juan el Apóstol aparece 17 veces en los Evangelios sinópticos, en tanto que Santiago el Mayor es mencionado 15 veces y la expresión «hijos de Zebedeo» –sin nombrarlos expresamente– 3 veces.

Para este silencio se han propuesto razones diversas que no satisfacen a los estudiosos de forma unánime. El escriturista Luis H. Rivas, señala: «no se ha encontrado una explicación satisfactoria para este silencio». John Chapman propuso que el autor del evangelio habría velado su propio nombre. J. de Maldonado sugirió que la comunidad cristiana de Asia, durante la redacción final del Evangelio de Juan, pudo velar el nombre de Juan el Apóstol bajo el título de «discípulo a quien Jesús amaba», cuya persona y méritos habrían conocido personalmente. El silencio del Evangelio de Juan sobre la figura de Juan el Apóstol parece tan deliberado como el silencio sobre la identidad del «discípulo amado». Este punto es reconocido también por Joseph N. Sanders, aunque este autor no está de acuerdo con la identificación de Juan el Apóstol con la figura del «discípulo amado».

En el Evangelio de Juan, Juan el Bautista recibe como único título el de «testigo», es decir, el que ha venido a dar testimonio.

En los evangelios sinópticos:

En cambio, en el Evangelio de Juan:

Además, el Evangelio de Juan remarca dos diferencias entre Jesús y Juan el Bautista:

Todo esto sugiere un aparente interés del evangelista por evitar dar un relieve muy marcado a la figura de Juan el Bautista.

El libro de los "Hechos de los Apóstoles" indica que en Éfeso, Pablo de Tarso conoció gente que solamente sabía del bautismo de Juan el Bautista y no del bautismo de Jesús, tal el caso de Apolo. Resulta sugestiva la coincidencia de que estos seguidores del Bautista se encontraban en el mismo lugar en que se supone fue redactado el Evangelio de Juan. Además, el Evangelio de Juan señala que los primeros discípulos de Jesús surgieron de las filas de los seguidores de Juan el Bautista. Esto lleva a suponer que, más allá de la grandeza que los evangelios confieren a Juan el Bautista, el evangelista quiere situarlo en un plano inferior al de Jesús de Nazaret, tal las palabras que pone en labios de Juan el Bautista:

El capítulo 3 del Evangelio de Juan aparece dominado por el encuentro de Jesús de Nazaret con Nicodemo, personaje que reaparecerá posteriormente en otros pasajes.

El Evangelio de Juan presenta a Nicodemo como fariseo, designado como «"arjōn" entre los judíos», que significa principal, notable. Se trata de un título con el que además se podía hacer referencia a un miembro del Sanedrín. Se dice que Nicodemo era «maestro de Israel», por lo que el evangelista resume en él a los judíos eruditos que conocían la Ley. El evangelista insiste en mencionar que Nicodemo fue a Jesús «de noche». Se trata de un significado simbólico: el diálogo de Nicodemo con Jesús se desarrolló «en la oscuridad», como el de alguien que no capta todavía el verdadero significado de la persona de Jesús. Sin embargo, el evangelista señala que «en la noche», Nicodemo fue a Jesús. Con ello lo diferencia de personajes como Judas Iscariote quien, durante la última cena, se alejó de Jesús «hacia la noche».

De igual forma que Nicodemo representa a los judíos eruditos conocedores de la Ley, la mujer samaritana representa en el Evangelio de Juan a todos los paganos. De igual forma que los profetas acusaban de adulterio al pueblo de Israel cuando abandonaba al Dios único para ir detrás de los dioses falsos, el Evangelio de Juan presenta el siguiente diálogo entre Jesús y la samaritana:

Se puede entender estas frases en sentido literal o alegórico. En el primer caso, cabe preguntarse si se trata de matrimonios sucesivos, o de adulterios de la mujer. Para la moral de los judíos, aunque se tratara de matrimonios sucesivos, resultaba ilegal tener cinco uniones porque no se permitían más de tres. Pero también se le da una interpretación alegórica, en relación a los cinco pueblos de donde provenían los antiguos samaritanos y a las divinidades que habían adorado en la Antigüedad. Si bien el Antiguo Testamento enumera 7 dioses, Flavio Josefo señala que «eran cinco pueblos y cada uno llevó consigo su propio dios». Así, el Evangelio de Juan reprocharía al pueblo samaritano, representado por la mujer, por haber adherido antiguamente a las falsas divinidades.





</doc>
<doc id="15252" url="https://es.wikipedia.org/wiki?curid=15252" title="Garo (etnia)">
Garo (etnia)

Garo es el nombre de un grupo étnico del estado de Meghalaya, en la India, conocido también como Achik.

Los Achik (Garo) y los Khasis-Jaintia (Hynniewtrep) de Meghalaya comenzaron sus reclamaciones para un estado separado en los años ochenta. Una de las primeras organizaciones fue el Hynniewtrep Achik Liberation Council (HALC), pero cuando se fraccionó en 1992, las dos etnias formaron organizaciones diferentes: representando a Khasis y Jaintias de Meghalaya el Hynniewtrep National Liberation Council (HNLC), dirigido por Julius K Dorphang; y el Achik Liberation Matgrik Army (ALMA), que luchaba por un estado de Garoland para los Garos.

La mayoría de los militantes de ALMA se rindieron en 1994 pero una parte se reorganizó y creó el Achik National Volunteer Council (ANVC) en diciembre de 1995 con la intención de crear un estado llamado Achikland en los Montes Garo de Meghalaya y en parte de los distritos de Kamrup y Goalpaa en Asam, donde los Achik o Garo son mayoría. Están dirigidos por Dilash R. Marak y su cuartel general está en Cheram en los Montes Garo. Están aliados al Nagaland Socialist Council of Nagalim (IM), al National Democratic Front of Bodoland y al United Liberation Front of Assam, y hasta ahora ha rechazado las invitaciones al diálogo. 

Otro grupo procedente del ALMA formó el People’s Liberation Front of Meghalaya (PLF-M) o Achik National Council (ANC), aliado sin embargo al ANVC. La bandera Achik podría ser la bandera reportada por Minahan en su libro "Nations witouth state". Una foto de un acto público relacionado con los Garos-Achik muestra una pancarta donde los tres colores se utilizan.
Finalmente otra organización, el Garo National Council, sólo reclama un estado de Garoland en los distritos Garos de Maghalaya.


</doc>
<doc id="15256" url="https://es.wikipedia.org/wiki?curid=15256" title="Gato (dispositivo)">
Gato (dispositivo)

El gato es una máquina empleada para la elevación de cargas pesadas mediante el accionamiento manual de una manivela o una palanca, o bien mediante un sistema de accionamiento asistido por un motor eléctrico o por un compresor de aire.

Se diferencian dos tipos, según su principio de funcionamiento: 
Las formas más comunes son las de gato de coche, y la de gato de suelo o de taller, que elevan los vehículos de manera que se pueda realizar su mantenimiento, aunque también existen otros tipos de gatos especiales que tienen múltiples aplicaciones en la construcción o la industria.

Estos dispositivos se clasifican generalmente por su capacidad máxima de elevación (por ejemplo 1,5 toneladas o 3 toneladas), y para algunas aplicaciones también es importante fijar la máxima distancia a la que pueden desplazar la carga.

Los gatos mecánicos se utilizan preferentemente para cargas relativamente pequeñas, y es habitual que estén diseñados para accionarse manualmente o mediante pequeños motores (como en el caso de los gatos que se incluyen en los automóviles para sustituir una rueda en caso de avería).

Sus principales ventajas son su simplicidad de construcción, sus mínimos requerimientos de mantenimiento, y su reducido precio. Por el contrario, sus principales inconvenientes son su lentitud de accionamiento (y también de repliegue) y su limitada capacidad de carga.

Esto los hace adecuados para aplicaciones de uso ocasional (como el caso ya citado de los gatos que portan la inmensa mayoría de los automóviles para la sustitución de una rueda averiada), en los que prima la simplicidad y la ligereza, aun a costa de un accionamiento lento y en ocasiones engorroso. Así mismo, en procesos de edificación sencillos (como la sujeción de encofrados o cimbras), se utilizan mecanismos de izado muy sencillos, que son meramente sistemas de vástagos roscados, que se accionan manualmente con barras metálicas que se utilizan como palancas.

Los sistemas habituales utilizados en los gatos están basados en "máquinas simples" (como son las palancas, los engranajes o los tornos), que utilizan el principio de la equivalencia del momento de fuerzas (una fuerza manual pequeña formula_1 con un gran brazo de palanca formula_2; es capaz de equilibrar una fuerza mayor formula_3 como el peso de un vehículo, pero que dispone de un brazo de acción muy corto formula_4):
de donde se deduce que: 
siendo el cociente formula_7 el coeficiente de multiplicación mecánica que proporciona el gato.

En términos de energía, una fuerza pequeña aplicada a lo largo de una gran distancia, es capaz de desplazar una gran masa a una distancia pequeña. En un gato de tijera, este coeficiente (despreciando las fuerzas de rozamiento y el efecto del cambio de geometría del cuadrángulo, que hará que vaya variando la relación entre el desplazamiento horizontal del husillo y el vertical del punto de soporte; en este ejemplo se supone que se está accionando cuando las cuatro varillas del gato forman aproximadamente un cuadrado) depende de la longitud de la manivela con la que se acciona el gato, y del paso de la rosca que desplaza el husillo.

Los gatos hidráulicos se utilizan en aplicaciones que requieren una gran capacidad de carga, o bien una máxima facilidad y velocidad de accionamiento (especialmente en las operaciones de plegado, que son inmediatas) para cargas medianas. Sus principales ventajas están relacionadas con su potencia y velocidad, con la posibilidad de controlarse mediante servomecanismos, y con la minimización de las pérdidas mecánicas asociadas con el rozamiento. Su principal inconveniente es que suelen ser equipos de una cierta complejidad de mantenimiento (especialmente en todos los aspectos relacionados con la ausencia absoluta de fugas del fluido que sirve para transmitir las cargas).

Los fluidos utilizados suelen ser aceites sintéticos de baja viscosidad debido a su capacidad de auto-lubricarse y a su estabilidad. 

Los gatos más potentes utilizan bombas eléctricas, capaces de proporcionar la presión hidráulica necesaria para actuar a distancias considerables y con capacidad para desplazar grandes tonelajes de carga.

El funcionamiento del gato hidráulico responde al principio de Pascal, que establece que la presión aplicada sobre un fluido contenido en un recipiente cerrado se transmite de forma uniforme en todos sus puntos. 

El dispositivo, en su forma más sencilla, tiene dos émbolos dispuestos en forma de "U", uno de sección muy pequeña (en el que se aplica la presión al fluido mediante una palanca o una bomba), y el otro de sección muy grande (donde se coloca la carga que se quiere elevar). La clave del funcionamiento son las válvulas unidireccionales, que permiten el paso del fluido en un solo sentido. Así, cuando se acciona el émbolo pequeño, una válvula permite el paso del fluido hacia el émbolo mayor, pero no su retorno. De igual forma, una segunda válvula permite la entrada del fluido desde un depósito hacia el émbolo pequeño cuando se alza la palanca, quedando listo el dispositivo para un nuevo ciclo de impulsión.

Según el principio de Pascal, la presión formula_9 es la misma en los dos émbolos, lo que significa que entre el émbolo pequeño (con sección formula_10 y fuerza formula_1) y en el émbolo grande (con sección formula_12 y fuerza formula_13, correspondiente al peso a izar), se cumple la ecuación:
lo que equivale a que:
siendo el cociente formula_16 el coeficiente de multiplicación de la fuerza aplicada.

Es un tipo de gato hidráulico especial, que utiliza aire comprimido -por ejemplo, aire procedente de un compresor- en vez de un líquido para producir el efecto de izado. Algunos modelos diseñados para sustituir a los gatos de tijera en automoción, constan de un saco de lona plastificada o de caucho de forma cilíndrica, con la resistencia suficiente para poderse inflar con una presión semejante a la de un neumático (unos 2 kilopondios por cm) y con el tamaño necesario para izar un coche (basta una base de 50 cm y una altura de unos 50 cm para izar 1000 kg) para sustituir una rueda. Desde el punto de vista energético no son muy eficientes (en el proceso de compresión del aire se desprende mucho calor), pero pueden ser útiles para evitar esfuerzos manuales cuando se dispone de alguna fuente mecanizada de aire comprimido.

Desde la más remota antigüedad existen ejemplos de máquinas simples utilizadas para multiplicar la fuerza humana o animal necesaria para realizar determinadas tareas (como la construcción de grandes monumentos de piedra), tan sencillas como los planos inclinados, o tan complejas como los polipastos, cuyos principios de funcionamiento ya se conocían en la época de Arquímedes.

Sin embargo, hay que esperar hasta el Renacimiento (cuando se empieza a desarrollar el conocimiento práctico y teórico de cómo funcionan engranajes y piezas roscadas) para encontrar los primeros diseños de mecanismos mecánicos para la elevación de cargas pesadas (relacionados con lo que hoy en día se conocen como gatos mecánicos); como atestiguan algunos dibujos del siglo XVI contenidos en el Codex Atlanticus de Leonardo da Vinci.

La enorme difusión actual de este instrumento está asociada al auge de la industria del automóvil, que lo ha venido incluyendo desde sus primeros modelos como una herramienta imprescindible para la sustitución de las ruedas pinchadas (los primeros coches equipados con una rueda de repuesto inflada fueron los Rambler en 1906.), aunque desde finales del siglo XX se haya extendido paulatinamente en algunos modelos la decisión de sustituir la rueda de repuesto (y en consecuencia, el gato), por un espray de espuma, que aplicado a una rueda pinchada, permite rodar algunos kilómetros hasta un taller.

Respecto al gato hidráulico, pese a que el principio en el que está basado se conoce desde el siglo XVII, cuando lo formuló el físico francés Blaise Pascal, hubo que esperar hasta 1851 para que se le concediese al inventor estadounidense Richard Dudgeon una patente para una "prensa portable hidráulica", lo que ahora se conoce como gato hidráulico, una herramienta que probó ser muy superior a los gatos de tornillo usados por entonces. Dudgeon también diseñó otros tipos de gatos hidráulicos, como los utilizados para el izado de vehículos ferroviarios.

Además de su uso más conocido y extendido en la automoción, los gatos tienen diversas aplicaciones en la construcción y en la industria, tanto para la elevación o empuje de cargas pesadas, como para el tesado de piezas metálicas. 






</doc>
<doc id="15257" url="https://es.wikipedia.org/wiki?curid=15257" title="Centro Internacional de la Papa">
Centro Internacional de la Papa

El Centro Internacional de la Papa o CIPOTATO (en inglés "International Potato Center") es uno de los mayores centros dedicados a la investigación científica en el mundo en papa, camote, yuca y otros tubérculos y raíces, con el objetivo de obtener el pleno alcance de sus capacidades alimenticias para beneficiar a los países en vías de desarrollo y c. Fue fundado y tiene su sede en Lima, Perú, desde 1971.

Tiene centros experimentales en Huancayo, en las alturas andinas, y en San Ramón, bosque pluvial del oriente peruano, de pendientes con cobertura, aprovechando de esta manera la variedad geográfica y de climas que posee el Perú. El CIP tiene otra área experimental en los Andes, en Quito, Ecuador así como una red de oficinas regionales y colaboradores alrededor del mundo, incluyendo Asia y África.

El CIP es una organización internacional financiada por el CGlAR, una alianza mundial de investigación agrícola que agrupa 15 centros de investigación. Recibe sus fondos principales de 58 gobiernos, fundaciones privadas y organizaciones internacionales y regionales. 

El Centro Internacional de la Papa tiene por objetivo disminuir la pobreza y alcanzar la seguridad alimentaria sobre bases sostenibles en los países en desarrollo, mediante la investigación científica y actividades relacionadas con la papa, el camote y otras raíces y tubérculos, y el manejo de los recursos naturales. 

El CIP promueve mejorar el rendimiento de la papa por hectárea cultivada teniendo como objetivo triplicar la capacidad de producción por hectárea mejorando el manejo de los recursos y especialmente la tecnología, habida cuenta del ritmo de crecimiento de la población mundial. 

Personal de casi 30 países de Asia, África, Europa, Oceanía y América Latina, investigan e intercambian constantemente información sobre todas las variedades de papa actualmente existentes en el mundo. La investigación está dirigida a incrementar la producción de alimentos y fortalecer los sistemas agrícolas, para mejorar la calidad de vida de los países en desarrollo beneficiando a aquellos que no tienen ni capital, ni recursos, ni la semilla de calidad que el CIP les ofrece.

Son cuatro las áreas de investigación en el CIP:

El CIP tiene un banco genético con unos 5.000 tipos diferentes de papa silvestre y cultivada, 6.500 variedades de camote y más de 1.300 tipos de otras raíces y tubérculos andinos provenientes de Bolivia, Ecuador y Perú. 

Igualmente, el CIP produce semillas de papa mejoradaspara resistir a enfermedades, heladas y sequías. Asimismo, conserva una provisión de semilla sexual de cada papa, libre de contaminaciones y de fácil transporte, para ser usada en ocasión de catástrofes naturales y otras emergencias que se presenten en los países del mundo.

El CIP se realizó el año (2014), en Lima, con la coordinación del presidente del CIP Guy H. Hareau.




</doc>
<doc id="15258" url="https://es.wikipedia.org/wiki?curid=15258" title="Servidor de archivos">
Servidor de archivos

Un servidor de archivos es un tipo de servidor que almacena y distribuye diferentes tipos de archivos informáticos entre los clientes de una red de computadoras.

Su función es permitir el acceso remoto de otros nodos a los archivos que almacena o sobre los que tiene acceso.

En principio, cualquier computadora conectada a una red, con el software apropiado, puede funcionar como servidor de archivos.

Desde el punto de vista del cliente de red de un servidor de archivos, la localización de los archivos compartidos es transparente, es decir, en la práctica no hay diferencias perceptibles si un archivo está metido dentro de en un servidor de archivos remoto o en el disco de la propia máquina.

Los protocolos que suelen emplearse en las transferencias de los archivos son:



</doc>
<doc id="15259" url="https://es.wikipedia.org/wiki?curid=15259" title="Servidor de disco">
Servidor de disco

Un servidor de disco es un dispositivo de redes de computadoras destinado a compartir discos físicos, conectados al dispositivo, con una red. Generalmente, estos dispositivos poseen una gran cantidad de espacio físico en disco (en la orden de terabytes) disponible, que son exportados como varios discos lógicos, a través de una interfaz de interconexión como SCSI o Fiberchannel.

La entidad compartida por estos servidores son discos, o dispositivos de bloque, y por lo tanto las funciones de gerenciamento de disco, particionamiento, sistema de archivos etc son todos hechos por el sistema operativo del ordenador cliente.
A diferencia de un servidor de archivos, esta clase de servidores no ve la organización interna de los datos almacenados (o sea, el servidor puede ver bloques de bytes, pero no archivos, como una entidad). Sin embargo, el mismo dispositivo puede actuar como un servidor de discos y de archivos al mismo tiempo, utilizando áreas de almacenamiento distintos.
Es el componente de la red que comparte y ofrece recursos e información con otros equipos al mismo tiempo a través de un Sistema Operativo que lo permita. La clase de información, o servicios que ofrezca determina el tipo de servidor que es; servidor de impresión, de archivos, de páginas web, de correo, de usuarios, de IRS (Charlas en internet), de base de datos.

</doc>
<doc id="15262" url="https://es.wikipedia.org/wiki?curid=15262" title="Organización territorial de Andorra">
Organización territorial de Andorra

La organización territorial de Andorra se estructura en siete parroquias ("parròquies" en catalán), que son las primeras y últimas instancias administrativas por debajo del gobierno andorrano. Algunas parroquias tienen circunscripciones territoriales menores: Ordino, La Massana y San Julián de Loria están divididas en cuartos ("quarts"), y la parroquia de Canillo está distribuida en vecindades ("veïnats"). Las parroquias reciben el nombre del núcleo de población que ejerce de capital.

La parroquia tiene tanto una función eclesiástica como civil. Como jurisdicción civil tiene el nombre de "comú" (comuna). El Consejo de la Comuna (en catalán "Consell del comú") se elige cada cuatro años por sufragio universal entre la población de nacionalidad andorrana (minoritaria en el país debido a una muy restrictiva política de adquisición de la nacionalidad), de la que también están excluidos como candidatos los ciudadanos que no disponen de la nacionalidad, aun habiendo nacido en el país o habiendo residido en él desde varios decenios. Está compuesto por el cónsul mayor, el cónsul menor y de 8 a 14 consejeros comunales.

El sistema administrativo del Principado de Andorra hace que la unión de la fuerza de los diferentes "comuns" sumen más poder que el propio gobierno central. El "comú" puede presentar proyectos de ley al Consejo General de Andorra.

Popularmente las parroquias de los valles de la Valira Oriental y de la Valira del Norte, es decir las parroquias de Encamp, Canillo, la Massana y Ordino, se han conocido como las "parroquias altas". Por contraposición la resta se las denomina, aunque no tan frencuentemente, "paroquias bajas". También se puede encontrar la denominación de "parroquias centrales" para las de Andorra la Vieja y Escaldes-Engordany.

Las siete parroquias siguen este orden protocolario:
</div>

Nota: Los límites entre Canillo y Encamp están discutidos por el llamado Terreno de Concordia.



</doc>
<doc id="15263" url="https://es.wikipedia.org/wiki?curid=15263" title="Earth Simulator">
Earth Simulator

Earth Simulator, literalmente, "Simulador de la Tierra" es un superordenador desarrollado por las agencias japonesas NASDA, JAERI y JAMSTEC y en operación desde finales del año 2001, para aplicaciones de carácter científico. Es utilizado principalmente en simulaciones climáticas y de convección en el interior terrestre.

Hasta finales del año 2003, ostentó el título de superordenador más rápido del mundo, con una capacitad computacional de más de 35 Teraflops.



</doc>
<doc id="15264" url="https://es.wikipedia.org/wiki?curid=15264" title="Constitución española de 1812">
Constitución española de 1812

La Constitución Política de la Monarquía Española, más conocida como Constitución española de 1812 o Constitución de Cádiz, conocida popularmente como la Pepa, fue promulgada por las Cortes Generales españolas reunidas extraordinariamente en Cádiz el 19 de marzo de 1812. Se le ha otorgado una gran importancia histórica por tratarse de la primera Constitución promulgada en España, además de ser una de las más liberales de su tiempo.

Oficialmente estuvo en vigor solo dos años, desde su promulgación hasta su derogación en Valencia el 4 de mayo de 1814, tras el regreso a España del borbón Fernando VII. Sin embargo, apenas sí entró en vigor "de facto", puesto que en su período de gestación buena parte de España se encontraba en manos del gobierno afrancesado de José I Bonaparte, otra en mano de juntas interinas más preocupadas en organizar su oposición a José I y el resto de los territorios de la Corona española, los virreinatos, se hallaban en un estado de confusión y vacío de poder causado por la guerra de Independencia. Posteriormente se volvió a aplicar desde el 8 de marzo de 1820, cuando en Madrid (España), Fernando VII es obligado a jurar la Constitución española de 1812, estando vigente durante el Trienio Liberal (1820-1823), así como durante un breve período en 1836-1837, bajo el gobierno progresista que preparaba la Constitución de 1837.

La Constitución establecía la soberanía en la Nación —ya no en el rey—, la monarquía constitucional, la separación de poderes, la limitación de los poderes del rey, el sufragio universal masculino indirecto, la libertad de imprenta, la libertad de industria, el derecho de propiedad o la fundamental abolición de los señoríos, entre otras cuestiones, por lo que «no incorporó una tabla de derechos y libertades, pero sí recogió algunos derechos dispersos en su articulado». Además, incorporaba la ciudadanía española para todos los nacidos en territorios americanos, prácticamente fundando un solo país junto a las colonias americanas.

Por el contrario, el texto consagraba a España como Estado confesional católico, prohibiendo expresamente en su artículo duodécimo cualquier otra confesión, y el rey lo seguía siendo «por la gracia de Dios y la Constitución». Del mismo modo, este texto constitucional no contempló el reconocimiento de ningún derecho para las mujeres, ni siquiera el de ciudadanía (la palabra «mujer» misma aparece escrita una sola vez, en una cita accesoria dentro del artículo veintidós), aunque con ello estaban en plena sintonía con la mayoría de la sociedad hispana y europea del momento. Con todo, se le reconoce, en gran estima, su carácter liberal, su afán en la defensa de los derechos individuales, su posicionamiento en querer modificar caducas instituciones propias del Antiguo Régimen, y en general, de recoger medidas regeneradoras enfocadas, con espíritu idealista, en mejorar la sociedad.

La Constitución de 1812 se publicó hasta tres veces en España —1812, 1820 y 1836—, se convirtió en el hito democrático en la primera mitad el siglo XIX, transcendió a varias constituciones europeas e impactó en los orígenes constitucionales y parlamentarios de la mayor parte de los estados americanos durante y tras su independencia. La Constitución de Cádiz de 1812 provocó limitar el poder de la monarquía, la abolición del feudalismo, la igualdad entre peninsulares y americanos y finalizó la inquisición.

Sin embargo, la mayor parte de las investigaciones dedicadas a su estudio omiten o minusvaloran la influencia que la revolución liberal y burguesa española tuvo al transformar el imperio colonial español en provincias de un nuevo Estado, y convertir en nuevos ciudadanos a los antiguos súbditos del absolutismo, y que incluía en su definición de ciudadanos españoles no solo a los europeos, o sus descendientes americanos, sino también a las castas y a los indígenas de los territorios de América, lo que se tradujo, en tercer lugar, en su trascendencia para las nacientes legislaciones americanas.

Las Cortes abrieron sus puertas el 24 de septiembre de 1810 en el teatro de la Isla de León para, posteriormente, trasladarse al oratorio de San Felipe Neri, en la ciudad de Cádiz. Allí se reunían los diputados electos por el decreto de febrero de 1810, que había convocado elecciones tanto en la Península como en los territorios americanos y asiáticos. A estos se les unieron los suplentes elegidos en el mismo Cádiz para cubrir la representación de aquellas provincias de la monarquía ocupadas por las tropas francesas o por los movimientos insurgentes americanos. Las Cortes, por tanto, estuvieron compuestas por algo más de trescientos diputados, de los cuales cerca de sesenta fueron americanos.Sus principios eran la soberanía nacional , la igualdad ante la ley y la defensa de la propiedad privada . 

En los primeros días, hubo propuestas americanas encaminadas a abolir el entramado colonial y poner las bases de un mercado nacional con dimensiones hispánicas que abarcaran también a los territorios de América, con disminución de aranceles a los productos americanos, apertura de más puertos coloniales para el comercio, etcétera. Un proyecto anterior en un siglo a la Commonwealth de Gran Bretaña. Los decretos gaditanos tuvieron una amplia repercusión y trascendencia durante las décadas posteriores, tanto en la península como en América.

La Constitución se juró en América, y su legado es notorio en la mayor parte de las repúblicas que se independizaron entre 1820 y 1830. Y no sólo porque les sirvió como modelo constitucional sino, también, porque esta Constitución estaba pensada, ideada y redactada por representantes americanos como un proyecto global hispánico y revolucionario. Parlamentarios como el mexicano Miguel Ramos Arizpe, el chileno Fernández de Leiva, el peruano Vicente Morales Duárez, el ecuatoriano José Mejía Lequerica, entre otros, en los años posteriores se convirtieron en influyentes forjadores de las constituciones nacionales de sus respectivas repúblicas.

Sin duda, a ello contribuyó la fluida comunicación entre América y la península, y viceversa: cartas privadas, decretos, diarios, periódicos, el propio "Diario de Sesiones" de Cortes, panfletos, hojas volantes, correspondencia mercantil, literatura, obras de teatro, canciones patrióticas, etcétera, que a bordo de navíos españoles, ingleses o neutrales informaban sobre los acontecimientos ocurridos en uno y otro continente. Hubo ideas, pero también hubo acción, dado que se convocaron procesos electorales municipales, provinciales y a Cortes, y se verificaron las elecciones, lo cual provocó una intensa politización en ambos espacios.

Asimismo, el envío de numerario por parte de consulados de comercio, dueños de minas, hacendados, recaudaciones patrióticas, etcétera, al Gobierno peninsular fue constante, e imprescindible para pagar la intervención de los ingleses, así como el armamento de las partidas guerrilleras tras la derrota del ejército español en la batalla de Ocaña, el 19 de noviembre de 1809.

Es importante insistir en que estas medidas contaban con el respaldo de las mayor parte de la burguesía criolla americana, partidaria de los cambios autonomistas y no necesariamente de una independencia que implicase la ruptura completa con la Monarquía.

El producto de este intento de revolución fue una constitución con caracteres nítidamente hispanos. Los debates constitucionales comenzaron el 25 de agosto de 1811 y terminaron a finales de enero de 1812. La discusión se desarrolló en pleno asedio de Cádiz por las tropas francesas, una ciudad bombardeada, superpoblada con refugiados de toda España y con una epidemia de fiebre amarilla. El heroísmo de sus habitantes queda para la historia.

La redacción del artículo 1 constituye un claro ejemplo de la importancia que para el progreso español tuvo América. Fue el primero, y por ello, el más importante. Este es su famoso texto:

La construcción queda definida desde parámetros hispanos. La revolución iniciada en 1808 adquiría, en 1812, otros caracteres especiales que los puramente peninsulares. Aludía a unas dimensiones geográficas que compondrían España, la americana, la asiática y la peninsular. La Nación española quedaba constitucionalmente definida.

La cuestión americana estaba planteada, por tanto, desde el primer artículo. El Estado liberal tenía parámetros ultraoceánicos. La problemática de su realización se evidenció en la discusión de la redacción de los artículos 10 y 11. Por el primero se estableció entre americanos y peninsulares un primer acuerdo para organizar en provincias el nuevo Estado. Es notorio que esta primera redacción contó con el rechazo de los americanos, disconformes con la manifiesta diferencia numérica a favor de las provincias peninsulares frente a las americanas (que equivalían aproximadamente a cada Virreinato o Capitanía General, mientras que las provincias peninsulares se identificaban con los reinos históricos de España).

Esto se convertiría en una cuestión política, ya que los americanos reclamaban un mayor número de provincias y una organización del Estado que se aproximase al federalismo. El artículo 11 solventó coyunturalmente el problema: tras un intenso debate, se decidió retrasar la estructura definitiva del Estado para una posterior ley, cuando las «circunstancias de la nación» —la urgencia en la metrópoli de combatir la invasión francesa, la urgencia americana de luchar con la insurgencia— garantizaran una discusión sosegada. La Cámara reconocía en la práctica su incapacidad para definir los territorios de su Estado. Y este problema sobrevenía, insistamos, por la incorporación de América como un conjunto de provincias en igualdad de derechos y de representación en el Estado nacional hispano.

Otros artículos fueron especialmente significativos, como el 18 y el 29. En el primero se decía que «Son ciudadanos aquellos españoles que por ambas líneas traen su origen de los dominios españoles de ambos hemisferios, y están avecindados en cualquier pueblo de los mismos dominios», y en el segundo, al explicitar el art. 28 («La base para la representación nacional es la misma en ambos hemisferios»), se dice que «Esta base es la población compuesta de los naturales que por ambas líneas sean originarios de los dominios españoles, y de aquellos que hayan obtenido de las Cortes carta de ciudadano, como también de los comprendidos en el art. 21».

De especial trascendencia fueron los artículos constitucionales referidos a ayuntamientos y diputaciones provinciales, en cuya redacción la comisión adoptó la Memoria presentada por Miguel Ramos de Arizpe, diputado por Coahuila, para la organización y gobierno político de las Provincias Internas del Oriente de Nueva España. Fue de vital importancia para desentrañar un aspecto importante del proceso revolucionario de la península y América, como fue, a partir de sanción constitucional, la creación de ayuntamientos en todas las poblaciones que tuvieran al menos 1000 habitantes. La propuesta provino del propio Miguel Ramos de Arizpe. Esto provocó una explosión de ayuntamientos en la península y, especialmente, en América, al procederse, tras la aprobación de la Constitución, a convocar elecciones municipales mediante sufragio universal indirecto y masculino. Eso constituiría un aspecto clave para la consolidación de un poder local criollo y un ataque directo a los derechos jurisdiccionales, privilegiados, de la aristocracia, aspecto fundamental para acabar con el régimen señorial en la península y con el colonial en América.
Ese respaldo americano a la Constitución se articuló a través de su promulgación por autoridades locales y vecinos en cabildos abiertos, en cuya conmemoración proliferaron plazas y monumentos dedicados a la Constitución por todo el continente americano.
Sin embargo, tras el vuelco absolutista de Fernando VII en 1814, fueron destruidos la mayoría de ellos, y con los procesos de independencia en Iberoamérica tan sólo han quedado algunas plazas caso de Montevideo y el Zócalo de la Ciudad de México y un par de monumentos documentados: el de Ciudad de San Agustín de la Florida Oriental, y Comayagua en Honduras.

La revolución iniciada en Cádiz suscitó la contrarrevolución fernandina. El 4 de mayo de 1814 el recién restaurado rey Fernando VII decretó la disolución de las Cortes, la derogación de la Constitución y la detención de los diputados liberales, entre los que se encontraba el diputado Ramón Olaguer Feliú. Comenzaba el regreso del absolutismo. El día 10 el general Eguía tomó Madrid militarmente proclamando a Fernando como rey absoluto. Previamente, se había gestado todo un clima de bienvenida popular.

Fernando VII se opone a los decretos y a la constitución de las Cortes de Cádiz porque significan el paso de un Estado absolutista a uno constitucional. Es obvio, pero también hay que subrayarlo con énfasis, porque tras los decretos de igualdad de derechos y de representación, tras una constitución para «ambos hemisferios», y tras decretar la constitución de un Estado nacional en el cual los territorios americanos se integraban como provincias, la Corona perdía no sólo su privilegio absoluto sobre el resto de individuos, sino las rentas de todo el continente americano que pasaban directamente a poder del aparato administrativo estatal y no del monarca, al establecer el nuevo Estado nacional una sustancial diferencia entre la «hacienda de la nación» y la "hacienda real". No podría consentirlo Fernando VII.

Por otra parte, la representación política y la igualdad de derechos de los americanos se tradujo en una reivindicación de soberanía que colisionaba con la nacional, al estar ésta concebida por los liberales peninsulares como única, central y soberana. El conflicto se estableció no solo entre un rey absoluto y la soberanía nacional y sus instituciones y representantes sino también entre una concepción centralista del Estado (basada en el gobierno de Madrid) y una descentralizada. Nada nuevo en el universo de las revoluciones burguesas, podría concluirse, pero la cuestión es que no era, estrictamente, sólo una revolución española, si se precisan no sólo la nacionalidad sino también los territorios del Estado en cuestión.

Hasta la década de 1820, la mayor parte del criollismo era autonomista, no independentista. Podía asumir una condición nacional española, pero a cambio de un autonomismo en América para todas las cuestiones de política interna, lo que implicaba la descentralización política y las libertades económicas. Para lograr sus pretensiones, los americanos planteaban una división de la soberanía a tres niveles: la nacional, representada en las Cortes; la provincial, depositada en las diputaciones; y la municipal, que residía en los ayuntamientos. Esta triple división de la soberanía, combatida por los liberales peninsulares, se legitimaba en los procesos electorales. Con estas propuestas, el autonomismo americano estaba planteando un Estado nacional no sólo con caracteres hispanos, sino también desde concepciones federales.

Los americanos depositaron toda la organización del Estado en la capacidad representativa y administrativa de las "diputaciones provinciales" como instituciones capaces de canalizar, administrar y recaudar las pretensiones y necesidades del criollismo de cada provincia. Esto provocó una doble reacción: por una parte el rey se opuso al federalismo, dado que los Estados que eran federales o confederales tenían la república como forma de Estado: los Estados Unidos de América y Suiza. Pero además, federalismo era sinónimo, en aquellos momentos, de democracia, asociada a elementos de disolución del Estado absolutista, y por ende tachados de «anárquicos». En segundo lugar, la propuesta federal de los americanos provocó una reacción cada vez más centralista entre los liberales peninsulares, que insistían en que la soberanía nacional (al ser indivisible) no podía delegarse en modo alguno en "diputaciones provinciales" y la maquinaria administrativa debería ser manejada sólo desde la Península.

Tras la década absolutista, frustrada la opción autonomista gaditana, el nacionalismo ultramarino optó por la insurrección armada, lo que condicionó la situación final revolucionaria española hasta el triunfo de las independencias continentales americanas en 1825.

La Constitución de Cádiz, traducida al italiano y con algunas pequeñas modificaciones, fue puesta en vigencia como primera Constitución del Reino de Sicilia el 12 de julio de 1812 por decisión del parlamento siciliano y, después, con la Constitución del Reino de las Dos Sicilias por decisión del parlamento de ese país el 9 de diciembre de 1820 y sancionada por el rey Fernando I, con el siguiente preámbulo:













</doc>
<doc id="15266" url="https://es.wikipedia.org/wiki?curid=15266" title="Onda longitudinal">
Onda longitudinal

Las ondas longitudinales son ondas en las que el desplazamiento a través del medio está en la misma dirección de desplazamiento de la onda, independiente del sentido.

Las ondas longitudinales mecánicas también se llaman ondas de compresión u ondas de compresibilidad, ya que producen compresión y rarefacción cuando viaja a través de un medio, y las ondas de presión producen aumentos y disminuciones en la presión.

La primera figura ilustra el caso de una onda sonora. Si el centro de la figura es un foco puntual generador de la onda, los frentes de onda se desplazan alejándose del foco, transmitiendo el sonido a través del medio de propagación, por ejemplo aire.

Por otra parte, cada partícula de un frente de onda cualquier oscila en dirección de la propagación, inicialmente es empujada en la dirección de propagación por efecto del incremento de presión provocado por el foco, retornando a su posición anterior por efecto de la disminución de presión provocada por su desplazamiento. De esta manera, las consecutivas capas de aire (frentes) se empujan unas a otras transmitiendo el sonido, y por esa razón las ondas sonoras son ondas longitudinales, y necesitan de un medio material para desplazarse (sólido, líquido o gas).

El otro tipo principal de onda es la onda transversal, en la que los desplazamientos a través del medio son en ángulo recto hacia la dirección de propagación. Algunas ondas transversales son mecánicas, lo que significa que la onda necesita un medio por donde viajar. Las ondas mecánicas transversales también se llaman "ondas T" o "ondas de corte".

Se incluye en el concepto de onda longitudinal: las ondas de sonido (vibraciones en la presión, desplazamiento de partículas y velocidad de las partículas propagada en un medio elástico) y las ondas sísmicas de tipo P (creadas por los terremotos y explosiones).

En las ondas longitudinales, el desplazamiento del medio es paralelo a la propagación de la onda, lo que significa que una onda que se propaga en la longitud de un muelle ("Slinky toy"), donde la distancia entre los bucles aumenta y disminuye, es una buena visualización. Las ondas de sonido en el aire son ondas de presión longitudinales.

En el caso de las ondas de sonido longitudinales armónicas, las relaciones entre el desplazamiento, el tiempo y la frecuencia pueden describirse con la fórmula

formula_1

donde:
La cantidad x / c es el tiempo que tarda la onda en recorrer la distancia x.

La frecuencia ordinaria de la onda (f) es dada por:

formula_2

La longitud de onda, que se puede calcular como la relación entre la velocidad y la frecuencia ordinaria:

formula_3

Es la distancia entre dos puntos consecutivos a lo largo del eje de la propagación que presentan la misma presión.

Para las ondas de sonido, la amplitud de la onda es la diferencia entre la presión del aire que no ha sido alterado y la máxima presión causada por la onda.

La velocidad de propagación del sonido depende del tipo, temperatura y composición del medio a través del cual se propaga.

En un medio elástico con una determinada rigidez, una oscilación armónica de una onda de presión tiene la forma:

formula_4

donde:
La fuerza de restauración, que actúa devolviendo el medio a su posición original, es dada por el módulo de compresibilidad.

Las ecuaciones de Maxwell llevan a la predicción de las ondas electromagnéticas en el vacío, que son transversales (donde los campos eléctricos y los campos magnéticos varían perpendicularmente en la dirección de propagación). Sin embargo, las ondas pueden existir en plasmas o espacios confinados, llamadas así ondas de plasma, que pueden ser longitudinales, transversales, o una mezcla de las dos. Además, las ondas de plasma también pueden existir en los campos magnéticos que estén libres de fuerzas.

En los inicios del desarrollo del electromagnetismo, había algunos científicos como Alexandru Proca (1897-1955), conocido por el desarrollo de las ecuaciones de los campos cuánticos relativos que llevan su nombre (ecuaciones de Proca) hasta los masivos.

En las últimas décadas, algunos teóricos electromagnéticas extendidos, como Jean-Pierre Vigier y Bo Lehnert de la Real Sociedad Sueca, han utilizado la ecuación de Proca en un intento de demostrar la masa del fotón como un componente electromagnético longitudinal de las ecuaciones de Maxwell, lo que sugiere que las ondas electromagnéticas longitudinales podrían existir en un vacío Dirac polarizado.

Tras varios intentos de Heaviside para generalizar las ecuaciones de Maxwell, Heaviside llegó a la conclusión de que las ondas electromagnéticas no se encuentran en forma de ondas longitudinales en el "espacio libre" o en medios homogéneos. Pero las ecuaciones de Maxwell conducen a la aparición de ondas longitudinales en algunas circunstancias, por ejemplo, en ondas de plasma o en ondas guiadas. Diferente básicamente de las ondas de "espacio libre", como estudió Hertz en sus experimentos UHF, son las ondas Zenneck. Los modos longitudinales de una cavidad resonante son los patrones de ondas estacionarias particulares formados por las ondas confinadas dentro de una cavidad. Entonces, los modos longitudinales se corresponden a las longitudes de onda de la onda que se refuerzan por interferencia constructiva después de muchos reflejos de las superficies reflectantes de la cavidad.

Recientemente, Haifeng Wang junto con otros científicos ha propuesto un método que puede generar una onda longitudinal electromagnética (luz) en el espacio libre, y esta onda se puede propagar sin divergencias.






</doc>
<doc id="15267" url="https://es.wikipedia.org/wiki?curid=15267" title="Contracción muscular">
Contracción muscular

La contracción muscular es el proceso fisiológico en el que los músculos desarrollan tensión y se acortan o estiran (o bien pueden permanecer de la misma longitud) por razón de un previo estímulo de extensión. Estas contracciones producen la fuerza motora de casi todos los músculos superiores, por ejemplo, para desplazar el contenido de la cavidad a la que recubren (músculo liso) o mueven el organismo a través del medio o para mover otros objetos (músculo estriado).

Las contracciones involuntarias son controladas por el sistema nervioso central, mientras que el cerebro controla las contracciones voluntarias, y la médula espinal controla los reflejos involuntarios.

Las contracciones como la locomoción,la respiración y la masticación pueden iniciarse tanto consciente como inconscientemente, pero se continúan por medio de un reflejo inconsciente.

La contracción muscular se puede explicar como un desplazamiento de los miofilamentos, es decir, la cabeza de la miosina se ancla a la actina produciéndose así el dicho desplazamiento. Cabe decir que la contracción muscular está regulada por el calcio, el ATP y el Magnesio, aunque se desconoce por qué el Magnesio causa contracción en músculos después de la muerte, esto está bajo investigación.

Para que la contracción esté sincronizada entre las células, se necesita que existan uniones tipo gap que permitan el paso de los iones y pasen el estímulo eléctrico.

El músculo esquelético y cardíaco son músculos estriados por razón de su apariencia en estrías bajo el microscopio, debido al altamente organizado patrón de bandas A y bandas I. 
En estado de relajación las fibras de miosina y actina, las proteínas en los filamentos de la zona A, apenas se superponen entre sí, mientras que la actina se superpone casi al completo sobre los filamentos de miosina en el estado de contracción. Los filamentos de actina, se han desplazado sobre los filamentos de miosina y sobre ellos mismos, de tal manera que se entrelazan entre sí en mayor mecanismo de deslizamiento de filamentos. 

La contracción dependerá de los iones de Ca citoplasmático. El calcio al unirse a la troponina que recubre la actina, deja libre los puntos de unión de ésta con la miosina. El hecho de que aumenten las concentraciones citoplasmáticas radica en la inervación que tiene el músculo estriado. Cuando una neurona motora desarrolla un PA (potencial de acción) sobre el músculo estriado esquelético (el cardiaco tiene contracción propia, sin neurona motora) se liberará acetilcolina sobre las células musculares (uniéndose a su receptor nicotinico ionotrópico), esto provocará una despolarización en la membrana que se transmitirá a lo largo del músculo. La despolarización llegará al "retículo sarcoplásmico" y gracias a los Tubulos T se aproximará el potencial para la liberación intracelular del Ca acumulado. 
Esta concentración de [Ca] aún no será suficiente para producir la contracción, por lo que también habrá una entrada de calcio extracelular por los canales de Ca. De esta manera los puntos de unión miosina-actina están libres y al unirse se produce la contracción. 
Cuando llega el momento de la relajación habrá que romper los enlaces para que el músculo no este contraído. Estos enlaces se rompen gracias a la acción de la miosina como ATP, que por hidrolisis de ATP rompe el enlace. 
Este proceso se vera favorecido solo cuando las [Ca] disminuyan. Esto es posible gracias a la existencia de bombas de Ca en el retículo sarcoplasmico que vuelven a guardar el Ca (1ATP hidrolizado por cada 2Ca que entran), la presencia del intercambiador Na-Ca en la membrana celular permitirá la salida de más Ca al medio extracelular.
Si alguna de estas bombas fallaran se produciría la Tetanización (los músculos quedan contraídos)
Los filamentos de actina se deslizan hacia adentro entre los filamentos de miosina debido a fuerzas de atracción resultantes de fuerzas mecánicas, químicas y electrostáticas generadas por la interacción de los puentes cruzados de los filamentos de actina.

En todo este proceso también se necesita energía para mantener la contracción muscular, que proviene de los enlaces ricos en energía del adenosintrifosfato (ATP), que se desintegra en adenosindifosfato (ADP) para proporcionar la energía requerida.

Mal llamadas contracciones isotónicas, ya que isotónicas significa "de igual tensión", aspecto que no se da en estas contracciones, ya que su tensión varia a lo largo del recorrido de la contracción en sus diferentes puntos.

Las contracciones heterométricas son las más comunes en la mayoría de los deportes, actividades físicas y actividades correspondientes a la vida diaria, ya que en la mayoría de las tensiones musculares que se ejercen suelen ir acompañadas por acortamiento y alargamiento de las fibras musculares de un músculo determinado.

Las contracciones heterométricas se dividen en: concéntricas y excéntricas.

Una contracción concéntrica ocurre cuando un músculo desarrolla una tensión suficiente para superar una resistencia, de forma tal que éste se acorta, y moviliza una parte del cuerpo venciendo dicha resistencia. Un claro ejemplo es cuando llevamos un vaso de agua a la boca para beber, existe acortamiento muscular concéntrico, ya que los puntos de inserción de los músculos se juntan, se acortan o se contraen.

En el gimnasio podríamos poner los siguientes ejemplos:



En síntesis, decimos que cuando los puntos de inserción de un músculo se acercan, la contracción que se produce es «concéntrica».

Cuando una resistencia dada es mayor que la tensión ejercida por un músculo determinado, de forma que éste se alarga, se dice que dicho músculo ejerce una contracción excéntrica. En este caso el músculo desarrolla tensión alargándose, es decir, extendiendo su longitud. Un ejemplo claro es cuando llevamos el vaso desde la boca hasta apoyarlo en la mesa, en este caso el bíceps braquial se contrae excéntricamente. En este caso actúa la fuerza de gravedad, ya que si no, se produciría una contracción excéntrica y se relajarían los músculos del brazo, y el vaso caería hacia el suelo a la velocidad de la fuerza de gravedad. Para que esto no ocurra, el músculo se extiende contrayéndose en forma excéntrica.

En este caso podemos decir que cuando los puntos de inserción de un músculo se alargan, se produce una contracción excéntrica. Aquí se suele utilizar el término alargamiento bajo tensión. Este vocablo «alargamiento», suele prestarse a confusión ya que si bien el músculo se alarga y extiende, lo hace bajo tensión y yendo más lejos no hace más que volver a su posición natural de reposo.



En el caso de querer desarrollar la musculatura, se debe trabajar tanto en contracción concéntrica como en contracción excéntrica, ya que ambas van a tener que usarse en nuestra vida tanto cotidiana como deportiva.

La palabra isométrica significa igual medida o igual longitud.

En este caso el músculo permanece estático, sin acortarse ni alargarse, pero aunque permanece estático genera tensión. Un ejemplo de la vida cotidiana sería cuando cargamos un peso y lo mantenemos elevado con el brazo, sin moverlo, manteniendo el peso en la misma posición. Los músculos generan tensión continua, y no se produce ni acortamiento ni alargamiento de las fibras musculares.

En el deporte se produce en muchos casos, un ejemplo podría ser en ciertos momentos del wind surf, cuando debemos mantener la vela en una posición fija. Con lo cual podríamos decir que se genera una contracción estática, cuando generando tensión no se produce modificación en la longitud de un músculo determinado.

Este caso es cuando se combinan contracciones heterométricas con contracciones isométricas. Al iniciarse la contracción, se acentúa más la parte heterométrica, mientras que al final de la contracción se acentúa más la isométrica.

Un ejemplo práctico de este tipo de contracción lo encontramos cuando se trabaja con «"extensores"». El extensor se estira hasta un cierto punto, el músculo se contrae concéntricamente, mantenemos unos segundos estáticamente (isométricamente) y luego volvemos a la posición inicial con una contracción en forma excéntrica.

Se trata más bien de un nuevo tipo de contracción, por lo menos en lo que refiere a su aplicación en la práctica deportiva. Se define como una contracción máxima a velocidad constante en toda la gama de movimiento. Son comunes en aquellos deportes en lo que no se necesita generar una aceleración en el movimiento, es decir, en aquellos deportes en los que lo que necesitamos es una velocidad constante y uniforme, como puede ser la natación o el remo. El agua ejerce una fuerza constante y uniforme, cuando aumentamos la fuerza, el agua aumenta en la resistencia. Para ello se diseñaron los aparatos isocinéticos, para desarrollar a velocidad constante y uniforme durante todo el movimiento.

Aunque las contracciones isocinéticas e isotónicas son ambas concéntricas y excéntricas, no son idénticas, sino por el contrario son bastante distintas, ya que como dijimos anteriormente las contracciones isocinéticas son a velocidad constante regulada y se desarrolla una tensión máxima durante todo el movimiento. En las contracciones isotónicas no se controla la velocidad del movimiento con ningún dispositivo, y además no se ejerce la misma tensión durante el movimiento, ya que por una cuestión de palancas óseas varía la tensión a medida que se realiza el ejercicio. Por ejemplo, en extensiones de cuádripces cuando comenzamos el ejercicio, ejercemos mayor tensión que al finalizar por varias razones:

En el caso de los ejercicios isocinéticos, éstas máquinas están preparadas para que ejerzan la misma tensión y velocidad en toda la gama de movimiento.

Para realizar un entrenamiento con máquinas isocinéticas se necesitan equipos especiales. Dichos equipos contienen básicamente, un regulador de velocidad, de manera que la velocidad del movimiento se mantiene constante, cualquiera que sea la tensión producida en los músculos que se contraen. De modo que si alguien intenta que el movimiento sea tan rápido como resulte posible, la tensión engendrada por los músculos será máxima durante toda la gama de movimiento, pero su velocidad se mantendrá constante.

Es posible regular la velocidad del movimiento en muchos de estos dispositivos isocinéticos y la misma puede variar entre 0º y 200º de movimiento por segundo. Muchas velocidades de movimiento durante diversas pruebas atléticas reales superan los 100º/s .

Otras de estas máquinas tienen la posibilidad de leer e imprimir la tensión muscular generada.

Lamentablemente, dichos dispositivos solo están disponibles en centros de alto rendimiento deportivo por sus altos costos. No cabe duda que la ganancia de fuerza muscular es mucho mayor con dichos tipos de entrenamiento, pero hay que tener en cuenta que en muchos deportes se necesita vencer la inercia y generar una aceleración, y por ello este tipo de dispositivos no serían muy adecuados para ello, ya que controlan la inercia y la aceleración.

La relajación es el momento en que la contracción da fin. Las diferentes fibras (miosina, actina) entran en su lugar y se encuentran con la aparición de la estría H. La relajación es el resultado del fin del impulso nervioso en la placa neuromuscular. Para que se produzca dicha relajación, se debe eliminar el Calcio del citoplasma celular y se debe aportar una molécula de ATP a la miosina.



</doc>
<doc id="15269" url="https://es.wikipedia.org/wiki?curid=15269" title="Política de Albania">
Política de Albania

La Política de Albania toma lugar en una república parlamentaria democrática representativa, a través de la cual el Primer Ministro es el jefe de gobierno. El poder ejecutivo es ejercido por el gobierno. El poder legislativo se le confiere al gobierno y al Parlamento ("Kuvendi i Republikës së Shqipërisë").

El Presidente es el jefe de estado de Albania, y es elegido por un periodo de 5 años por la Asamblea de la República por votación secreta. Se requiere que reciba la mayoría de 50%+1 de los votos de todos los diputados. El actual presidente es Bujar Nishani, elegido en julio de 2012.

El presidente tiene poder para garantizar la observación de la constitución del país y de todas las leyes, bien así es el comandante en jefe de las fuerzas armadas, además de exercir los poderes de la Asamblea de la República mientras esta no esté en sesión, y de apuntar el Jefe del Consejo de Ministros (primer ministro).

El (Jefe del Consejo de Ministros) es apuntado por el presidente. Los demás ministros son escogidos por el presidente bajo indicación del primer ministro. La Asamblea de Albania tiene la palabra final respecto a la composición del Gabinete.



</doc>
<doc id="15270" url="https://es.wikipedia.org/wiki?curid=15270" title="Agustín Acosta Bello">
Agustín Acosta Bello

José Agustín Acosta y Bello (Matanzas, Cuba, 12 de noviembre de 1886 - Miami, Florida, Estados Unidos, 12 de marzo de 1979). Es uno de los más célebres escritores cubanos del siglo XX.

Nació en la ciudad de Matanzas el 12 de noviembre de 1886. Estudió leyes, graduándose con el título de Doctor en Leyes. Ejerció la profesión en su ciudad natal mientras que alcanzó también una vida política de triunfos después de haber sufrido cárcel por su oposición al gobierno del presidente Gerardo Machado. Siempre se expresó y actuó de acuerdo a sus convicciones políticas y morales. A la caída del machadato pasó a ocupar la gobernación provisional de la provincia de Mantanzas (1933-1934) y ejerció la secretaría de la presidencia durante el gobierno del presidente Carlos Mendieta. También fue electo senador de la República, y sirvió como tal de 1936 al 1944. Fue presidente del Partido Unión Nacionalista. 

A partir de 1938 fue miembro de la Academia Nacional de Artes y Letras de Cuba, de la prestigiosa Academia Cubana de la Lengua y fue nombrado Poeta Nacional por el Congreso Cubano en 1955. Colaboró en varias publicaciones nacionales de reconocida importancia, tales como Letras, El Fígaro, El Cubano Libre, Orto, Social, Carteles, Diario de la Marina, Las Antillas, Ariel, Archipiélago y otros periódicos y revistas importantes.

En la obra de Acosta se incluyen algunos de los primeros poemas líricos libres del pesimismo que dominó en la poesía cubana el principio de la república. Junto con Regino Boti y José Manuel Poveda es uno de los representantes del renacimiento lírico que tuvo lugar en las provincias antes de la década del 1920. Su estilo se destaca por la sencillez de los postmodernistas con acentos, en ciertos poemas bien definidos, del modernismo y romanticismo. Fue precursor de la poesía social en Cuba. En muchas de sus poesía supo expresar su amor a la tierra cubana. Algunos de sus poemas han sido traducidos al francés. 

Por razones de familia abandonó la Isla con su esposa en diciembre de 1972 para estar junto a su hija. Murió en la ciudad de Miami, Florida el 12 de marzo de 1979.




</doc>
<doc id="15273" url="https://es.wikipedia.org/wiki?curid=15273" title="Gastón Baquero">
Gastón Baquero

Gastón Baquero (Banes, Cuba, 4 de mayo de 1914-Madrid, 15 de mayo de 1997) fue un importante escritor y poeta cubano del siglo XX, que después de la revolución cubana vivió exiliado en España.

Baquero nació en Banes, pueblo perteneciente a la antigua provincia de Oriente, zona que hoy es parte de la provincia de Holguín. Estudió Agronomía, pero nunca ejerció la profesión: prefirió consagrarse a las actividades literarias y periodísticas.

En los años 40 se vincula con el grupo vanguardista de poetas e intelectuales que toma su nombre de la revista "Orígenes" (1944-1956), que funda y dirige José Lezama Lima y en la que colaboran, entre otros, Eliseo Diego, Virgilio Piñera y Cintio Vitier. Baquero también colabora en la creación de las revistas literarias "Verbum" (1937), "Espuela de plata" (1939-1941) y "Clavileño" (1942-1944).

La publicación de "Poemas", en 1942, al que le sigue el mismo año "Saúl sobre su espada", lo colocan de inmediato en el grupo de poetas clave de la literatura cubana. En aquellos años su principal campo de acción es el periodismo, en el que destaca. Llega a ser jefe de redacción del influyente y conservador "Diario de la Marina". En la década siguiente obtiene cargos oficiales —se relaciona con la dictadura de Fulgencio Batista— y prácticamente deja de escribir poesía, aunque sus reseñas periodísticas —políticas, culturales y literarias— son recibidas con gran aclamo y solidifican su reputación de intelectual eminente.

"Son los años del hombre ilustre y conservador, del refinado "bon vivant" que tiene chófer y cargos oficiales, y que continúa llevando su íntima homosexualidad con la discreción que siempre la llevó", escribe Luis Antonio de Villena en "Gastón Baquero, magias de verso y cultura".

Contrario a la revolución de Fidel Castro, se ve obligado a irse del país: escoltado por tres embajadores acreditados en La Habana toma un vuelo con rumbo a Madrid, donde el régimen de Francisco Franco lo acoge y le proporciona empleo. Trabajó en el Instituto de Cultura Hispánica, en la Escuela de Periodismo y en Radio Exterior de España. Al mismo tiempo, escribió ensayos y artículos literarios para varias publicaciones, principalmente para la revista "Mundo Hispánico". 

El exilio convierte a Baquero, que en Cuba era una figura intelectual de poderosa influencia, en un hombre gris y aislado, ignorado por sus contemporáneos españoles y borrado por el gobierno de Castro de la historia intelectual cubana. Pero es en el exilio que Baquero regresa a la poesía. "Poemas escritos en España" aparece en 1960 y en 1966 se publica "Memorial de un testigo", uno de sus libros más aclamados. En 1984 el poeta boliviano Pedro Shimose publica en Madrid (Instituto de Cooperación Iberoamericana) sus poemas completos hasta el momento bajo el título de "Magias e invenciones". Desde entonces, los jóvenes poetas y estudiantes de literatura buscan su compañía y le rinden homenajes, a los cuales Baquero reacciona con su modestia habitual.

En 1988 fue candidato al Premio Príncipe de Asturias de las Letras y en 1992, finalista del Premio Nacional de Literatura en la modalidad de Poesía por su obra "Poemas invisibles". Ese año también recibe el homenaje de la Universidad de Alcalá de Henares y es propuesto para el Premio Reina Sofía. Participa, junto a Octavio Paz y Luis Alberto de Cuenca, en las sesiones de lectura poética en el Palacio Real. En 1993 la Cátedra Poética Fray Luis de León de la Universidad Pontificia de Salamanca celebra una semana de homenaje a su obra y al año siguiente recoge en un volumen, "Celebración de la existencia", las aportaciones de los participantes. En 1994, por primera vez desde 1959, se ofrece en la Universidad de La Habana una conferencia sobre su obra poética, y en 2001 se permite la publicación de una antología poética, "La patria sonora de los frutos" (Editorial Letras Cubanas), editada por Efraín Rodríguez Santana.

En mayo de 1997 el Círculo de Bellas Artes, la Residencia de Estudiantes y Radio Nacional de España convocan a un homenaje a Baquero, gesto que tal vez hubiera sido el comienzo del reconocimiento que tanto merecía. Pero ya Baquero había entrado en el hospital donde fallecería el 15 de mayo de un infarto cerebral.

Baquero mantuvo hasta su muerte un rechazo al gobierno totalitario de Fidel Castro. La manipulación por el régimen castrista de una de las figuras que más admiraba, José Martí, le llevó a escribir en una ocasión: "No hay comparación posible entre Martí y la realidad cubana actual. Es algo de pena que alguna persona se atreva a equiparar la personalidad de Martí o a poner a Martí como precursor de todo esto: de las colas, del hambre, de la dictadura". Sin embargo, Baquero deseaba la unión cultural de las dos Cubas (la de dentro y la de fuera) con la generosidad intelectual que lo caracterizaba. En la dedicatoria de su último libro escribió: "El orgullo común por la poesía nuestra de antaño, escrita en o lejos de Cuba, se alimenta cada día al menos en mí, por la poesía que hacen hoy —¡y seguirán haciendo mañana y siempre!— los que viven en Cuba como los que viven fuera de ella. Hay en ambas riberas jóvenes maravillosos. ¡Benditos sean! Nada puede secar el árbol de la poesía".




</doc>
<doc id="15275" url="https://es.wikipedia.org/wiki?curid=15275" title="Echium plantagineum">
Echium plantagineum

Echium plantagineum, comúnmente llamada buglosa o flor morada, es una planta incluida en el género "Echium". Es una hierba anual que puede alcanzar los 70 cm de altura. Se desarrolla abundantemente en praderas a pleno sol y tolera media sombra.

Anual o bienal. Planta herbácea de hasta 70 cm de altura, con tallos ramificados.
Toda la planta se halla densamente cubierta de un indumento de pelos rígidos que le dan un tacto microáspero.
Las hojas son lanceoladas, salvo las de la roseta basal que son oblongas.
Forma una inflorescencia erecta. Las flores son de color azul-violeta intenso con los pétalos soldados en casi toda su longitud, solamente tienen pelos sobre los nervios, hecho que marca la diferencia de "Echium plantagineum" con respecto a "Echium sabulicola" (más pequeña y con pilosidad en la corola de la flor).

Florece en el hemisferio boreal, según la región y su clima, de febrero a julio.

Zonas llanas de toda Europa a lo largo de caminos y tierras baldías. En España ampliamente extendida por todo el territorio.

Esta es también la especie invasora y plaga por excelencia (comparable con la expansión de los conejos) en la mayor parte del sur de Australia, donde infecta los antiguamente productivos pastos nativos. Fue introducida en los primeros años de colonización desde Europa por la familia Patterson para embellecer su jardín pero en poco tiempo se pudo ver su imparable expansión a través de los anteriormente productivos pastos circundantes. Hoy en día se sigue luchando por su erradicación con todos los medios posibles.

Mucílagos, cinogloxina, consolicina, nitratos, tanino.
Esta especie contiene, como todas las demás pertenecientes a este género, pequeñísimas cantidades de un alcaloide bastante tóxico llamado equiína, que se asemeja, en su modo de actuación, al curare que usan los indios sudamericanos para envenenar las flechas. De hecho, se han descrito muertes de reses por haber pastado en zonas donde medraba esta especie y haberla ingerido en grandes cantidades.

El jugo se usa en cosmética como eficaz emoliente para pieles delicadas y enrojecidas.
Se usan cataplasmas de flores frescas para curar forúnculos y uñeros; usando las extremidades florales, que se recolectan en julio.

La raíz da un colorante rojo para los tejidos.

"Echium plantagineum" fue descrita por Jean-Baptiste Lamarck y publicado en "Mantissa Plantarum" 2: 202. 1771.
Número de cromosomas de "Echium plantagineum" (Fam. Boraginaceae) y táxones infraespecíficos: n=8
Echium: nombre genérico que deriva del griego "echium", lo que significa víbora, por la forma triangular de las semillas que recuerdan vagamente a la cabeza de una víbora. Este hecho también explica que en la Edad Media se tuviera a esta planta como protectora frente a las víboras y se utilizara, por asociación, como remedio contra las picaduras de este ofidio.

plantagineum: epíteto que alude a la semejanza foliar con especies del género "Plantago". 




</doc>
<doc id="15277" url="https://es.wikipedia.org/wiki?curid=15277" title="Norbert Wiener">
Norbert Wiener

Norbert Wiener (Columbia, Misuri, Estados Unidos, 26 de noviembre de 1894-Estocolmo, Suecia, 18 de marzo de 1964) fue un matemático estadounidense, conocido como el fundador de la cibernética. Acuñó el término en su libro "Cibernética o el control y comunicación en animales y máquinas", publicado en 1948.

Su padre, Leo Wiener fue profesor en lenguas eslavas en la Universidad de Harvard. Norbert se educó en casa hasta los siete años, edad a la que empezó a asistir al colegio, pero durante poco tiempo. Siguió con sus estudios en casa hasta que volvió al colegio en 1903, graduándose en el instituto de Ayer en 1906.

En septiembre de 1906, a la edad de once años, ingresó en la Universidad Tufts para estudiar matemáticas. Se licenció en 1909 y entró en Harvard, en donde estudió zoología, pero en 1910 se trasladó a la Universidad Cornell para emprender estudios superiores en filosofía; sin embargo, meses después, volvió a Harvard. Wiener obtuvo el doctorado en dicha universidad en 1912, con una tesis que versaba sobre lógica matemática.

De Harvard pasó a Cambridge, Inglaterra, donde estudió con Bertrand Russell y G. H. Hardy. En 1914 estudió en Gotinga, Alemania con David Hilbert y Edmund Landau. Luego regresó a Cambridge y de ahí a los EE.UU. Entre 1915 y 1916 enseñó filosofía en Harvard y trabajó para la General Electric y la Encyclopedia Americana antes de dedicarse a trabajar en cuestiones de balística en el campo de pruebas de Aberdeen ("Aberdeen Proving Ground"), en Maryland. Permaneció en Maryland hasta el final de la guerra, cuando consiguió un puesto de profesor de matemáticas en el MIT.

Durante el tiempo que trabajó en el MIT hizo frecuentes viajes a Europa y es en esa época cuando entabla contacto con Leonardo Torres Quevedo y su máquina "El Ajedrecista". En 1926 se casó con Margaret Engemann y regresó a Europa con una beca Guggenheim. Pasó casi todo el tiempo en Gotinga o con Hardy en Cambridge. Trabajó en el movimiento browniano, la integral de Fourier, el problema de Dirichlet, el análisis armónico y en los teoremas tauberianos, entre otros problemas. Ganó el premio Bôcher en 1933.

Durante la Segunda Guerra Mundial trabajó para las Fuerzas Armadas de los Estados Unidos en un proyecto para guiar a la artillería antiaérea de forma automática mediante el empleo del radar. El objetivo del proyecto era predecir la trayectoria de los bombarderos y con ella orientar adecuadamente los disparos de las baterías, mediante correcciones basadas en las diferencias entre trayectoria prevista y real, conocidas como "innovaciones" del proceso. Como resultado de los descubrimientos realizados en este proyecto introduce en la ciencia los conceptos de "feedback" o retroalimentación, y de "cantidad de información", con lo que se convierte en precursor de la teoría de la comunicación o la psicología cognitiva. Posteriormente, en 1956, formulará parte del concepto de Causalidad de Granger.


Además de los conceptos matemáticos que llevan su nombre, se tiene que:



</doc>
<doc id="15278" url="https://es.wikipedia.org/wiki?curid=15278" title="José Ángel Buesa">
José Ángel Buesa

José Ángel Buesa (Cienfuegos, Cuba 1910-Santo Domingo, República Dominicana, 1982) fue un poeta romántico con un claro tono de melancolía a través de toda su obra poética, que es primordialmente elegíaca. Se le ha llamado el "poeta enamorado". Ha sido considerado como el más popular de los poetas en la Cuba de su época. Su popularidad se debía en gran parte a la claridad y profunda sensibilidad de su obra. Muchos de sus poemas han sido traducidos al inglés, portugués, ruso, polaco, japonés y chino. Otros muchos han sido musicalizados o recitados en unos 40 discos de larga duración. Fue también novelista y escritor de libretos para la radio (novelas radiofónicas) y la televisión cubana, también fue director de célebres programas radiales en las estaciones RHC-Cadena Azul y CMQ, ya inexistentes.

Buesa nació el 2 de septiembre de 1910 en Cruces, cerca de Cienfuegos, Cuba. A los 7 años empezó a escribir sus primeros versos. En su adolescencia se mudó a Cienfuegos a continuar sus estudios en el Colegio de los Hermanos Maristas. La gente, los cañaverales, y todo el medio de Cienfuegos, ejerció un embrujo en el alma del poeta, que empezó a plasmar en sus versos la magia del paisaje que lo rodea. Aún joven, se trasladó a La Habana, donde se incorporó a los grupos literarios existentes y comenzó a publicar sus versos a los 22 años (1932) con gran éxito.

Tras una primera etapa muy productiva, Buesa se vio obligado a abandonar Cuba para empezar una penosa peregrinación por España, Islas Canarias, El Salvador y finalmente Santo Domingo. Los últimos años de su vida los vivió en el exilio, y se dedicó a la enseñanza, ejerciendo como catedrático de literatura en la Universidad Nacional Pedro Henríquez Ureña en la República Dominicana, donde murió el 14 de agosto de 1982. En el poema que dedica a su madre, Buesa refleja claramente el sufrimiento causado por haber tenido que abandonar su tierra natal.

Aparentemente estuvo enterrado en Santo Domingo durante unos años, pero un grupo de fanáticos de sus poemas de Puerto Rico consiguieron, con la anuencia de su viuda, que sus restos fueran llevados a Miami, donde ahora descansan.

Sus principales obras son: "La fuga de las horas" (1932), 
"Misas paganas" (1933), 
"Babel" (1936), 
"Canto final" (1936), 
"Oasis", "Hyacinthus", "Prometeo", "La vejez de Don Juan", "Odas por la victoria" y "Muerte diaria" (todas publicadas en 1943), 
"Cantos de Proteo" (1944), 
"Lamentaciones de Proteo", "Canciones de Adán" (ambas de 1947), 
"Poemas en la arena", "Alegría de Proteo" (ambas de 1948), 
"Nuevo oasis", "Poeta enamorado" (ambas de 1949) y 
"Poemas prohibidos" (1959). 
Su libro "Oasis" (1943) se reeditó en más de 26 ocasiones, así como "Nuevo Oasis".

Algunas antologías de sus poemas son: "Doble antología" (1952) y "Los mejores poemas" (1960). Póstumamente se han editado las antologías "Pasarás por mi vida" (1997) y "Nada llega tarde" (2001).

Sus libros se agotaban tan pronto salían. Se dice que de un poema suyo fueron los primeros versos que se oyeron en la televisión cubana en el año 1961. Catalogado por algunos críticos como poeta menor, cursi y fácil, no obstante podría afirmarse que ningún poeta cubano ha hecho mejor gala del neo-romanticismo americano.



</doc>
<doc id="15281" url="https://es.wikipedia.org/wiki?curid=15281" title="Duguetia">
Duguetia

Duguetia es un género de plantas fanerógamas con una especie perteneciente a la familia de las anonáceas. Son nativas de América meridional. 
"Duguetia" A. St.-Hil. (Annonaceae) es un género de árboles y arbustos que crecen casi exclusivamente en los trópicos de América del sur, con una extensión cruzando el istmo de Panamá. El género comprende alrededor de 100 especies, considerando la inclusión reciente de cuatro taxas africanos considerados anteriormente como "Pachypodanthium" Engler & Diels. El género "Duguetia" es uno de los más numerosos en la familia Annonaceae después de "Guatteria" y "Annona". Muchos estudios se han realizado sobre los metabolitos secunsdarios presentes en diferentes partes de las plantas de "Duguetia", a partir de los cuales se han aislado y caracterizado aceites esenciales, compuestos aromáticos, monoterpenos, diterpenos, triterpenos, flavonoides, y principalmente alcaloides. Al igual que otras familias de "angiospermas primitivas," las especies de "Duguetia" acumulan alcaloides isoquinolínicos, más específicamente 1-bencil-1,2,3,4-tetrahidroisoquinolinas, usualmente nombrados como "bencilisoquinolinas" y sus derivados biogenéticos.
La literatura reporta estudios de los alcaloides de 16 especies de "Duguetia" (una de las cuales no fue claramente identificada) resultando en el aislamiento e identificación de 105 alcaloides diferentes.
El género fue descrito por Augustin Saint-Hilaire y publicado en "Flora Brasiliae Meridionalis" (quarto ed.) 1: 28. 1825[1824]. La especie tipo es: "Duguetia lanceolata" A. St.-Hil.










































</doc>
<doc id="15282" url="https://es.wikipedia.org/wiki?curid=15282" title="Bonifacio Byrne">
Bonifacio Byrne

Bonifacio Byrne (Matanzas, Cuba, 3 de marzo de 1861 — "Ibíd.", 5 de julio de 1936) fue un poeta cubano. Después de un período juvenil de iniciación en la poesía modernista, se convirtió, a partir de 1896, en el intérprete de los entusiasmos y agonías de su pueblo en la lucha por su independencia de la corona española.

Realizó sus estudios en Matanzas. Desde la adolescencia tuvo inclinación por la literatura. En 1890 fundó los periódicos "La Mañana" y "La Juventud Liberal". Publicó su primer libro de versos en 1893.

Pocos años más tarde, en 1896, tuvo que emigrar a los Estados Unidos al publicar sus sonetos en ocasión del fusilamiento de Domingo Mejía. En el exilio se dedicó a labores separatistas y fundó en Tampa, el Club Revolucionario, del cual fue secretario. Durante su estancia en esa ciudad floridana trabajó como lector de tabaquerías y colaboró en "Patria", "El Porvenir" y en "El Expedicionario".

Regresó a Cuba en 1899. Durante el período republicano fue secretario del Gobierno Provincial de Matanzas y de la Superintendencia Provincial de Escuelas. En 1909 fundó el periódico "El Yucayo". Colaboró en "La Primavera", "El Ateneo", "Diario de Matanzas", "El Fígaro" y en "La Discusión". Fue declarado Hijo Eminente de Matanzas en 1915. Ese mismo año se trasladó a Nueva York para reponer su quebrantada salud. Obtuvo galardones poéticos en los Juegos Florales de Sancti Spíritus (1916) y Matanzas (1934). Fue miembro fundador del Grupo Índice (1935). Era socio correspondiente de la Academia Nacional de Artes y Letras. Fue enterado en la Necrópolis de San Carlos Borromeo de Matanzas en 1936.

Un gran número de sus composiciones poéticas quedaron sin ser publicadas o agrupadas en una bien merecida antología. Raimundo Lazo lo llama «el último poeta patriótico de los tiempos coloniales».

Desde la publicación en 1897 en la ciudad estadounidense de Filadelfia del poemario "Efigies", conformado por sonetos patrióticos, a este autor se le considera, por la gran aceptación de esa obra, como uno de los poetas de la guerra Cubano-Española.

Quizás su poesía más conocida, es la que incluimos aquí. Fue compuesta por el autor al regresar a Cuba después de terminada la Guerra Hispano-Americana, y en ella expresa su angustia frente a la incertidumbre del futuro nacional amenazado por una bandera extranjera (Estados Unidos), que él pudo ver desde el barco en que entraba en la bahía de la Habana, izada en la fortaleza del Morro junto a la bandera cubana.

Mi Bandera

"Al volver de distante ribera,con el alma enlutada y sombría,afanoso busqué mi bandera¡y otra he visto además de la mía!"

"¿Dónde está mi bandera cubana,la bandera más bella que existe?¡Desde el buque la vi esta mañana,y no he visto una cosa más triste... !"

"Con la fe de las almas austeras,hoy sostengo con honda energía,que no deben flotar dos banderasdonde basta con una: ¡la mía!"

"En los campos que hoy son un osariovio a los bravos batiéndose juntos,y ella ha sido el honroso sudariode los pobres guerreros difuntos."

"Orgullosa lució en la pelea,sin pueril y romántico alarde;¡al cubano que en ella no crease le debe azotar por cobarde!"

"En el fondo de obscuras prisionesno escuchó ni la queja más leve,
y sus huellas en otras regionesson letreros de luz en la nieve... "

"¿No la veis? Mi bandera es aquellaque no ha sido jamás mercenaria,y en la cual resplandece una estrella,con más luz cuanto más solitaria."

"Del destierro en el alma la trajeentre tantos recuerdos dispersos,y he sabido rendirle homenajeal hacerla flotar en mis versos."

"Aunque lánguida y triste tremola,mi ambición es que el Sol, con su lumbre,la ilumine a ella sola, ¡a ella sola!en el llano, en el mar y en la cumbre."

"Si deshecha en menudos pedazosllega a ser mi bandera algún día...¡nuestros muertos alzando los brazosla sabrán defender todavía!..."


</doc>
<doc id="15283" url="https://es.wikipedia.org/wiki?curid=15283" title="Vida extraterrestre">
Vida extraterrestre

El término vida extraterrestre se refiere a las muchas formas de vida que puedan haberse originado, existido o existir todavía en otros lugares del universo, fuera del planeta Tierra.
Una porción creciente de la comunidad científica se inclina a considerar que pueda existir alguna forma de vida extraterrestre en lugares donde las condiciones sean propicias, aunque generalmente se considera que probablemente tal vida exista solo en formas básicas. Una hipótesis alternativa es la panspermia, que sugiere que la vida podría surgir en un lugar y después extenderse entre otros planetas habitables. Estas dos hipótesis no son mutuamente excluyentes. Se especula con formas de vida extraterrestre que van desde bacterias, que es la posición mayoritaria, hasta otras formas de vida más evolucionadas, que puedan haber desarrollado inteligencia de algún tipo. La disciplina que estudia la viabilidad y posibles características de la vida extraterrestre se denomina exobiología.

Debido a tal falta de pruebas a favor o en contra, cualquier enfoque científico del tema toma siempre la forma de conjeturas y estimaciones. Aunque cabe notar que el tema posee también una gran cantidad de teorías informales y paracientíficas, que exceden con facilidad los criterios de cualquier epistemología científica, por ejemplo, haciendo afirmaciones infalsables según el criterio de Popper, y son por tanto consideradas seudociencias.

Toda vida en la Tierra requiere de elementos químicos, hidrógeno, oxígeno, carbono, nitrógeno, azufre, fósforo, así como de otros muchos en menores cantidades, como ciertos minerales; requiere además de agua líquida como solvente en el cual las reacciones tienen lugar. Cantidad suficiente de carbono y demás elementos constituyentes de la vida, junto con el agua, harían posible la formación de organismos vivientes en otros planetas con una química, presión y temperatura similares a las de la Tierra. Como la Tierra y otros planetas están hechos de "polvo estelar", es muy probable que otros planetas se hayan formado con semejante composición de elementos químicos que los terrestres.
La combinación de carbono y agua en la forma de carbohidratos, como el azúcar, puede ser una fuente de energía química de la que depende la vida, mientras que a la vez provee elementos de estructura y codificación genética. 
El agua pura es útil, pues tiene un pH neutro debido a la continuada disociación entre sus iones de hidronio e hidróxido. Como resultado, puede disolver ambos tipos de iones, positivos (metálicos) y negativos (no metálicos) con igual habilidad.

Debido a su relativa abundancia y utilidad en el sostenimiento de la vida, muchos han hipotetizado que todas las formas de vida, donde quiera que se produzcan, se valdrían también de estos materiales básicos. Aun así, otros elementos y solventes pueden proveer una cierta base de vida. 
Se ha señalado al silicio como una alternativa posible al carbono; basadas en este elemento, se han propuesto formas de vida con una morfología cristalina, teóricamente capaces de existir en condiciones de alta temperatura, como en planetas que orbiten muy cercanos a su estrella.

También se han sugerido formas de vida basadas en otros solventes, pues existen compuestos químicos capaces de mantener su estado líquido en diferentes rangos de temperatura, ampliando así las zonas habitables consideradas viables. Así por ejemplo, se estudia el amoníaco como solvente alternativo al agua. La vida en un océano de amoníaco podría aparecer en un planeta mucho más lejano a su estrella. 

Técnicamente, la vida es básicamente una reacción que se replica a sí misma, por lo que bajo esta simple premisa podría surgir la vida bajo una amplia gama de condiciones e ingredientes diferentes, si bien la vía carbono-oxígeno parece la más óptima y conductiva. Existen incluso teorías sobre reacciones autorreplicantes que podrían ocurrir en el plasma de una estrella, aunque éste sería un tipo de "vida" altamente extremo y nada convencional.

Hubo un cambio dramático en el pensamiento con la invención del telescopio y el heliocentrismo. Una vez que quedó claro que la Tierra era meramente un planeta entre innumerables cuerpos en el universo, la teoría de vida extraterrestre comenzó a convertirse en un tema en la comunidad científica. Uno de los primeros fue el filósofo italiano Giordano Bruno, que argumentó en el siglo XVI que para un universo infinito en el cual todas las estrellas estuvieran rodeadas de su propio sistema planetario, habría otros mundos con "no menos virtud ni una naturaleza distinta a la de nuestra tierra" y, como la tierra, "contienen animales y habitantes".

La posibilidad de vida extraterrestre era una trivialidad del discurso educado durante el siglo XVII, aunque en el poema "El paraíso perdido" (1667) Milton empleó cautelosamente este tema cuando el ángel sugiere a Adán la posibilidad de vida en la Luna:

Fontanelle expandió la esfera creativa del Creador, en lugar de negarla, en su obra "Conversaciones sobre la pluralidad de los mundos". Y en "La excursión"" (1728), David Mallet exclamó: "Diez mil mundos resplandecen; cada uno con su carga/De mundos poblados".

En la literatura, otro ejemplo sería "El otro mundo: las sociedades y gobiernos de la Luna", del poeta Cyrano de Bergerac, donde las sociedades extraterrestres se presentan como parodias humorísticas o irónicas de la sociedad terrena.

En 1752, Voltaire publica el cuento corto "Micromegas", que avanza muchas de las nociones que luego se ven expresadas de forma recurrente en la ciencia ficción incipiente y contemporánea. En particular, la idea de que los alienígenas pueden viajar entre las estrellas y venir a la Tierra (hasta llega a sugerir cierta propulsión luminosa, análoga a una vela solar), y que son distintos a los humanos de forma fundamental (en este caso, en talla, tiempo de vida y cantidad de sentidos).

El género de la ciencia ficción se desarrolla durante el siglo XIX con Julio Verne en "Alrededor de la Luna" (1870), que ofrece una discusión sobre la posibilidad de vida en la Luna, pero con la conclusión de que es estéril, y "La guerra de los mundos", de H. G. Wells (1898), con la idea popular de la "invasión marciana”.

Debido a que es un fenómeno que por el momento permanece esencialmente fuera del alcance de la ciencia (al no disponer de datos, y por tanto de la posibilidad de experimentar y refutar las hipótesis), no existe una disciplina "formal" que estudie la vida extraterrestre, ni ningún currículo académico que forme expertos en ello. Aquellos que se han aproximado al tema de manera científica son por lo general expertos en áreas diversas, que por interés meramente personal han elaborado hipótesis sobre las posibilidades de vida en otros mundos, y han compartido sus puntos de vista a través de algún medio. Pese a ello, ha surgido una enorme cantidad de trabajos y publicaciones serias sobre el tema, de modo que puede hablarse de una cuasi-ciencia dedicada a estudiar y teorizar sobre este fenómeno, a pesar de la ausencia de pruebas. La proto-ciencia que estudia la vida extraterrestre se llama exobiología o astrobiología, y esencialmente se dedica a especular sobre los límites en los que, según nuestros conocimientos científicos, podría darse la vida.

Hay muchas preguntas acerca de cómo puede ser la vida extraterrestre, para las que la ciencia todavía no tiene respuesta, como por ejemplo:

Los detractores de la idea de que pueda existir vida extraterrestre indican que no es científico hipotetizar sobre hechos no conocidos o probados, tales como formas de vida que no se basen en el carbono, ecosistemas avanzados que no sean ricos en gases hormonales, o planetas con biosferas significativamente distintas a la de la propia Tierra (temperatura media, tipo de estrella que orbitan, satélites, geología, etc.).

Debido a que el único ejemplo de vida que conocemos en el universo es la vida en el planeta Tierra, los que se interesan en el tema siguiendo un enfoque racional suelen seguir el principio científico de mediocridad, al afirmar que la vida en el planeta Tierra no es un caso especial, y por lo tanto la vida como la conocemos puede ser considerada un ejemplo típico de lo que la vida sería en todas partes. Esta presunción es relevante, pues determina fuertemente las acciones que emprenden los que buscan probar científicamente la existencia de la vida fuera de la Tierra.
Dicho principio de mediocridad, pese a su estatuto de conjetura, permite aventurar algunas predicciones sobre los posibles atributos de la vida extraterrestre. En particular, se admite que existen "atributos universales" de la vida. Por ejemplo, se acepta que la evolución darwiniana es universalmente válida, y que toda potencial criatura viviente debería sus características a un proceso de selección natural, tanto en la Tierra como en cualquier otro lugar del universo.

Existen otros atributos o características cuasi-universales en las especies que, al repetirse sucesivamente de diferentes formas en diferentes especies en la biosfera terrestre —un proceso caracterizado como evolución convergente—, se consideran como altamente probables en una hipotética biosfera alienígena. Entre estas características cabe destacar la aparición de los sentidos, las extremidades adaptadas para diferentes medios y, muy probablemente, la fotosíntesis cuando hablemos del reino vegetal.

En este sentido, existe una gran diversidad de formas que podría adoptar la vida extraterrestre. Existen otros atributos más particulares que muchas veces se dan por sentados, pero que según los expertos no lo serían, ya que no responden mejor que otros a una necesidad evolutiva, y no se dan en todas las especies presentes en un mismo hábitat, por lo cual éstos pueden variar o no existir, como por ejemplo órganos como la mano humana, o una posición de ojos, nariz y boca similares a la humana. También hay otros atributos, entre ellos por ejemplo el esqueleto, que aunque se consideran una necesidad para criaturas de cierta talla, podrían ser muy diferentes a lo que conocemos. Así por ejemplo la columna vertebral sería una invención terrestre, ya que no se presenta en todos los organismos del planeta Tierra.

Los detractores de esta hipótesis de la evolución convergente indican que para que ésta exista deben darse, entre otros factores, condiciones medioambientales muy similares que por estadística es muy difícil que ocurran, pues que no se conoce la existencia de planetas con biosferas significativamente similares a la de la Tierra.

En contraposición al principio de mediocridad, están los que afirman que la vida en la Tierra no es un caso mediocre, y que las condiciones necesarias para su aparición son tan únicas y particulares que bien puede ser posible que existan muy pocas, o incluso sólo un planeta con vida en el universo: la Tierra.

Los defensores de esta hipótesis alegan que la vida en la Tierra, y en particular la vida humana, parecen depender de una larga y extremadamente afortunada cadena de eventos y circunstancias, que bien podrían ser irrepetibles incluso en la escala cósmica. Por ejemplo, se menciona con regularidad que sin una Luna tan grande como la que tiene la Tierra, el planeta tendería a presentar una precesión mucho más importante, cambiando drásticamente de inclinación en su rotación y afectando así de manera caótica el clima y, muy posiblemente, imposibilitando la vida como la conocemos.

Se mencionan también otras aparentes casualidades afortunadas, como el hecho de que el Sol esté en un lugar de la Vía Láctea relativamente libre de supernovas, en contraposición al centro galáctico, o que el Sol es del tamaño justo para dar energía suficiente, y durar lo suficiente, como para que la vida haya aparecido.

Otra positiva casualidad para la vida en la Tierra es la existencia de un planeta del tamaño de Júpiter, como apuntan los autores del libro "Rare Earth", en una órbita estable, casi circular y a la distancia suficiente de la Tierra para atrapar numerosos cometas y asteroides que, de otro modo, terminarían impactando con el planeta, arruinando todo tipo de vida incipiente. Esas, entre muchas otras casualidades, separadamente pueden parecer triviales, pero juntas convierten a la Tierra en un lugar cósmicamente "especial".

Sin embargo, desde fines del siglo XX, y producto de nuevos descubrimientos, tales como la existencia de moléculas orgánicas en el espacio, la presunta existencia de un océano de agua líquida en Europa, o el demostrado hecho de que los planetas extrasolares son relativamente comunes, y de que por tanto algunos de ellos podrían presentar condiciones factibles para la vida, han hecho que esta hipótesis ya no sea compartida por buena parte de la comunidad científica.

La panspermia es la teoría que sostiene que la vida en la Tierra proviene del espacio, especulando que la vida llegó de otros cuerpos celestes (quizás de planetas extrasolares) en forma de esporas, viajando en meteoros y polvo cósmico que serían arrojados al espacio por choques meteóricos. Existe una variante de esta teoría, que afirma que la vida es estrictamente originaria del sistema solar, pero que sí se difundió a la Tierra (o incluso, desde la Tierra hacia otros cuerpos) a través de esporas en meteoros; a esta teoría se le llama transpermia. Sin embargo y aceptando, por supuesto, la validez de las precitadas teorías, es preciso no perder de vista otro enfoque científico de la vida extraterrestre: su búsqueda mediante las señales de radio provenientes del espacio profundo. Durante los últimos meses, se ha dicho y escrito bastante sobre la captación de señales que provienen, supuestamente, de galaxias extremadamente lejanas. No obstante, es necesario esperar a que, mediante la Metodología de la Investigación Científica, se niegue o, bien, se corrobore que dichas señales son reales. 

La especulación sobre las posibles formas de vida extraterrestres, especialmente las inteligentes, así como sus posibles civilizaciones y relaciones con los seres humanos han sido y son tratadas también por la ciencia ficción y la ufología.

Los científicos buscan vida extraterrestre principalmente de tres maneras:

Debido a que, en la práctica, los únicos cuerpos celestes que el ser humano puede visitar son los de nuestro sistema solar, la búsqueda directa de vida extraterrestre se ha limitado a dicho sistema; principalmente a la búsqueda de vida microscópica, ya sea fósil o activa. Sin embargo no todos los cuerpos del sistema solar se consideran aptos para la presencia de vida. Actualmente se considera como posibles objetivos de búsqueda a:




Debido a la recientemente adquirida capacidad para detectar planetas extrasolares o exoplanetas orbitando estrellas distintas a nuestro Sol, entre la comunidad astronómica se ha generado un fuerte interés en descubrir mundos comparables en tamaño y propiedades a la Tierra; planetas que apenas empiezan a ser detectados. También hay un fuerte interés en la posibilidad de observar realmente tales mundos usando telescopios mucho más perfeccionados que los disponibles actualmente.
Hasta la fecha sólo hay un ejemplo de observación directa de un planeta extrasolar ("véase GQ Lupi"); y aunque empieza a ser posible detectar planetas de tamaño equivalente a la Tierra ("véase Gliese 876") en otro sistemas, obtener fotografías de ellos todavía no es posible, debido a que los instrumentos disponibles no son lo suficientemente sensibles para separar el enorme brillo de la estrella del de sus planetas.
Eso puede cambiar en un futuro cercano, cuando telescopios como el Terrestrial Planet Finder de la NASA o el proyecto Darwin de la ESA entren en funcionamiento.
Entre las funciones de tales dispositivos está la de obtener fotografías de los planetas, y detectar propiedades fundamentales de los mismos, como su temperatura, o la presencia o ausencia de atmósfera, así como detalles sobre su composición (mediante espectroscopia).

Existen quienes creen que tales métodos permitirían detectar mundos paralelos donde existan procesos biológicos comparables a los presentes en la Tierra. La idea está respaldada por el hecho de que la luz que refleja nuestro planeta lleva consigo "marcas" que revelan la presencia de la vida; por ejemplo, la presencia de un alto nivel de oxígeno, y ciertas variaciones del espectro infrarrojo, que revelan la presencia de vegetación. 

Desde luego, tales métodos de detección asumen que la vida en la Tierra es un caso mediocre, y que las características de la luz reflejada por la Tierra son compartidas por todos los casos. Este método de detección tiene la ventaja de permitir la detección de mundos con vida primitiva (y que no transmiten ondas de radio como lo espera el SETI), con la condición de que dicha vida haya modificado la atmósfera, de manera análoga a como la vida ha cambiado la atmósfera terrestre desde su aparición.

Por otro lado, se ha teorizado que cualquier sociedad tecnológica estará trasmitiendo información: radiaciones electromagnéticas generadas por el hombre son detectables en un radio de más de 50 años luz de la Tierra, y están en constante expansión. El proyecto SETI ("Search for Extraterrestrial Intelligence") o "Búsqueda de Inteligencia Extraterrestre", analiza los datos recogidos por los grandes radiotelescopios y los analiza buscando pautas artificiales utilizando superordenadores, así como un gran proyecto de computación distribuida en el mundo; "SETI@home". Hasta la fecha, no obstante, tan solo la señal Wow! ha sido reseñable en esta búsqueda.

A lo largo del tiempo se han producido también una serie de iniciativas en sentido contrario: no buscar la señal de una posible inteligencia extraterrestre, sino informar de nuestra presencia a potenciales civilizaciones que estén a la escucha. La primera fue el llamado Mensaje de Arecibo, lanzado en 1974 en dirección al cúmulo de estrellas de M13. A bordo de las sondas Pioneer 10 (en dirección a la estrella Aldebarán) y Pioneer 11 (en dirección a la constelación de Aquila) se encuentran sendos mensajes ("véase Placa de la Pioneer") destinados a una posible civilización extraterrestre que pudiese interceptar las sondas. Lo mismo ocurre en el caso del Disco de oro de las Voyager, en las sondas Voyager 1 (en dirección a la constelación de Ofiuco) y Voyager 2 (en dirección a la estrella Ross 248). Más recientemente, en 2008, un equipo de científicos ucranianos ha enviado mensajes en dirección al sistema Gliese 876. El 5 de febrero del mismo año a las 0:00 UTC la NASA transmitió la canción "Across the universe"de la banda británica The Beatles en dirección a la estrella Polaris que se encuentra a 431 años luz de la tierra, utilizando una antena de 70m en el DSN's a las afueras de Madrid con el fin de celebrar el 50 aniversario de la NASA, el 45 aniversario de la Deep Spacial Network (DSN) y el 40 aniversario de la canción.

Varios científicos del SETI han advertido que tratar de contactar con hipotéticas civilizaciones extraterrestres enviando transmisiones de radio al espacio es imprudente, acientífico, falto de ética y potencialmente catastrófico.





</doc>
<doc id="15284" url="https://es.wikipedia.org/wiki?curid=15284" title="Euskera">
Euskera

El euskera, eusquera, euskara, éuskara, vascuence, vasco, éuskaro o vascongado (en euskera batua: "euskara"; y en algunos dialectos denominado "euskera", "eskuara", "eskuera", "uskera" o "üskara"), conocido en la Edad Moderna como vizcaíno, es la lengua que se habla en Euskal Herria, un territorio que abarca el norte de España y el suroeste de Francia, que está dividido por los Pirineos. Lingüísticamente, es una de las pocas lenguas no indoeuropeas de Europa (solo las lenguas ugrofinesas son no indoeuropeas), y la única de Europa occidental. El euskera es además la única lengua aislada de Europa, es decir, que no tiene ninguna relación o conexión lingüística conocida con ningún otro idioma (vivo o desaparecido), y es la única lengua que sobrevivió a la llegada de los pueblos indoeuropeos, lo que ha suscitado el interés de lingüistas de todo el mundo.

Se desconoce cuál es exactamente el origen de los vascos y de su idioma. Aunque léxicamente el euskera ha tomado una gran cantidad de préstamos de las lenguas romances (especialmente del latín y del castellano), mantiene una estructura gramatical única. Asimismo, el euskera tuvo una importante influencia en las lenguas romances, especialmente en las de la península ibérica (castellano, catalán y gallego).

El 28,4% de los habitantes de Euskal Herria tiene el euskera como idioma nativo. De éstos, el 93,2% () vive en España y el 6,8% () restante en Francia. Aproximadamente otras personas son además bilingües pasivos (entienden el euskera pero tienen dificultades para hablarlo), lo que elevaría el porcentaje de personas que tienen algún conocimiento del euskera (no rudimentario o básico, sino suficiente para poder entenderlo) hasta el 40%, aproximadamente. A pesar de lo expuesto, los hablantes nativos del euskera no se distribuyen uniformemente por el territorio de Euskal Herria, sino que se concentran en una zona geográfica continua. Todas las provincias que componen Euskal Herria tienen al menos una región mayoritariamente poblada por hablantes nativos. La mayor parte de Vizcaya (al este de la ría del Nervión), la práctica totalidad de las provincias de Guipúzcoa, Baja Navarra y Sola, la zona septentrional de Navarra, parte de Labort y unos pocos municipios de Álava son las zonas en las que se concentran los hablantes del euskera.

Alrededor del año 1 d. C, el euskera se hablaba no solo en la totalidad de Euskal Herria, sino más allá de sus actuales fronteras, ocupando un espacio geográfico delimitado aproximadamente por el cauce de los ríos Garona en Francia y Ebro en España. Desde entonces, lleva siglos en retroceso, desde el punto de vista geográfico, en buena medida debido a las divisiones administrativas del territorio, que llevó a su vez a la división lingüística del euskera (que hasta entonces estaba unificado) en dialectos o "euskalkis", y a la falta de reconocimiento oficial o estatal, así como por su escasa literatura (que no surge hasta la Edad Media), que redujo en buena medida su difusión.

En Francia, el advenimiento de la Revolución francesa, llevó a la proclamación de la igualdad de todos los franceses, lo que se tradujo en que todos los franceses tenían una única lengua: el francés, con la consiguiente falta de reconocimiento oficial del euskera y del resto de lenguas de ese país, que se mantiene hasta hoy día. En España, durante los siglos XIX y buena parte del XX el Estado era centralista, por lo que el euskera carecía de reconocimiento. Durante la Restauración y la dictadura de Francisco Franco, el uso del euskera en público fue estigmatizado y perseguido, lo que redujo aún más su número de hablantes. A partir de la década de 1960, los esfuerzos por suprimir el euskera cesaron: el idioma volvió a utilizarse en educación, resurgieron las ikastolas, y se dio un renacimiento de la literatura en euskera. Así, surge un movimiento que busca revivir el euskera y adaptarlo a los tiempos modernos, cuya máxima expresión fue la estandarización del idioma en un único conjunto de normas gramaticales y ortográficas: el euskera batua, que es el que se utiliza en el ámbito administrativo, periodístico, literario, etc., aunque los dialectos siguen vivos en el habla cotidiana y muchos ayuntamientos han promovido la conservación de sus propias variantes dialectales del euskera.

España reconoce el euskera como un bien cultural que es objeto de especial respeto y protección. Ello, unido a la política lingüística del Gobierno Vasco, ha dado lugar a un gran aumento del número de hablantes del euskera, revirtiendo la tendencia histórica del retroceso. Actualmente, el euskera es lengua oficial y propia en la Comunidad Autónoma Vasca (CAV) y en la zona vascófona de Navarra. En Francia, la Constitución francesa establece que la única lengua oficial de Francia es el francés, aunque los distintos municipios que integran el País Vasco francés han tomado medidas en el ámbito de su competencia para conservar la lengua.

El euskera es la única lengua no indoeuropea de la península Ibérica. El hecho de que durante la Alta Edad Media fuera hablada, además de en los territorios actuales vascoparlantes, en áreas de la Rioja Alta, la Riojilla Burgalesa y la Bureba pudo hacer que tuviera influencia en la conformación del castellano y singularmente en su sistema fonológico de 5 vocales (véase sustrato vasco en lenguas romances). Tras un periodo de prolongado declive desde la Baja Edad Media, acentuado en los siglos XVIII y XIX, que hizo que dejara de ser hablado paulatinamente en áreas de Burgos, La Rioja, Navarra y Álava, desde finales de la década de 1950 y principios de la de 1960 fueron puestas en práctica diversas iniciativas para evitar su desaparición, entre ellas la adopción de un estándar lingüístico superador de la fragmentación dialectal. Con la llegada de la democracia a España, la Constitución de 1978 facultó a las comunidades autónomas a declarar también oficiales en su territorio lenguas distintas al castellano, lo que sería materializado para el País Vasco por el Estatuto de Guernica, que recoge la cooficialidad del euskera y en donde ha logrado volver a ganar espacios de uso en la vida pública. Asimismo, en el artículo 9.2 de la Ley Orgánica de Reintegración y Amejoramiento del Régimen Foral de Navarra de 10 de agosto de 1982, se estableció también la oficialidad del euskera en la zona vascoparlante de Navarra. La posterior Ley Foral del Vascuence de 1986 reconoció al castellano y al euskera el carácter de lenguas propias de Navarra, delimitando en el marco del concepto legal del predominio lingüístico la 'Zona Vascófona' en la que el euskera es lengua cooficial. En el País Vasco francés, al igual que el resto de lenguas regionales francesas, el euskera no goza de la condición de lengua oficial y es el único de los ámbitos territoriales de la lengua en el que el conocimiento y uso del euskera entre la población disminuye hoy en día.

Se discute cuál es el origen exacto de la voz "euskara"; no obstante parece acreditada la identificación de dicho término con la identidad cultural vasca. Así, de la palabra "euskara" se deriva la palabra "euskaldun" (literalmente ‘el que posee euskara’), que designa al hablante del euskera. Asimismo, de la voz "euskara" se originó el término "Euskal Herria," denotativo del territorio en que se hablaba euskera (‘la tierra del euskera’) y que en el Estatuto de autonomía del País Vasco es utilizado como sinónimo de «pueblo vasco». El neologismo "Euskadi", creado como alternativa de la expresión "Euskal Herria" y actualmente sinónimo de País Vasco, también procede de la voz "euskara". Se discute la relación que las palabras «vasco» y «gascón» presentan con "euskara". Para designar a todos los demás idiomas, los vascohablantes usan la palabra "erdara" y a las personas no vascohablantes se les conoce genéricamente como "erdaldunak" (literalmente ‘los poseedores de otra lengua’, no vascoparlantes).

El filólogo Alfonso Irigoyen propone que la palabra "euskara" procede del verbo "decir" en vasco antiguo, reconstruida como "*enautsi" (mantenida en formas verbales como el vizcaíno "dinotzat", "yo le digo"), y del sufijo "-(k)ara", "forma (de hacer algo)". Por tanto, "euskara" significaría literalmente "forma de decir", "forma de hablar", "habla" o "lenguaje". Irigoyen presenta como evidencia para sostener esta teoría la obra "Compendio Historial" (1571), del vasco Esteban Garibay, donde el autor afirma que el nombre nativo de la lengua vasca es «enusquera». Véase también eusk- < *ausc-, del nombre del importante pueblo aquitano de los auscos (Auch, Gers).

Es tema discutido la extensión que tuvo el ámbito lingüístico euskérico en la antigüedad y Alta Edad Media. Algunos estudios apuntan a que llegó a abarcar un área territorial que se extendía desde el golfo de Vizcaya hasta el Pirineo catalán, incluyéndose en dicho ámbito los territorios de la hoy Gascuña, La Rioja, este de Cantabria, norte de Huesca, nordeste de Burgos, noroeste de Zaragoza y parte de la provincia de Lérida, así como parte del actual departamento francés de los Altos Pirineos. Otras opiniones defienden que la versión primitiva del actual euskera tiene su origen en la región de Aquitania y creen que sería ya en tiempos históricos cuando se produjo su expansión a los territorios españoles en los que se habla actualmente. Durante los siglos VIII y XI se estima que el euskera vivió un segundo periodo de expansión, extendiéndose por territorios de la Rioja Alta y la provincia de Burgos, periodo del que la toponimia claramente euskérica de estas áreas (Herramélluri, Ochánduri, Bardauri, Sajazarra, etc) sería prueba.

En la actualidad, dentro de España el euskera es hablado como primera o segunda lengua en las tres provincias del País Vasco (Álava, Vizcaya y Guipúzcoa), así como también en parte de la Comunidad Foral de Navarra. La lengua se enseña también en el enclave de Treviño (Castilla y León).

En la totalidad del territorio de Guipúzcoa, en el centro y oriente de Vizcaya, así como en algunos pocos municipios del norte de Álava y en el tercio septentrional de Navarra, el euskera es la lengua tradicional de la mayoría de la población. Por el contrario, en el occidente de Vizcaya (Las Encartaciones y Gran Bilbao) y en la mayor parte de Álava y Navarra, además de en el enclave de Treviño, la lengua tradicional es el castellano.

Dentro de Francia el euskera es hablado en los territorios de Labort, Baja Navarra y Sola, comúnmente denominados en conjunto como País Vasco francés ("Iparralde" en euskera, ‘Zona Norte’) e integrantes junto a Bearne del departamento de Pirineos Atlánticos. El euskera es la lengua tradicional predominante de Baja Navarra (excepto el enclave gascoparlante de La Bastida de Clarenza), de Sola y de la mayor parte de Labort, en tanto que el extremo noroccidental de este último territorio es predominantemente francófono y gascoparlante.

Para el caso del País Vasco, los datos de la VI Encuesta Sociolingüística (2016) realizada por el Gobierno Vasco, el Gobierno de Navarra y la Oficina Pública del Euskera del País Vasco francés señalaba que un 33,9 % de la población mayor de 16 años era vascoparlante bilingüe (631 000 habitantes), un 19,1 % vascoparlante bilingüe pasivo (356 000) y un 47 % era castellanoparlante exclusivo (877 000). Según ese estudio, el número de vascoparlantes era mayoritario en Guipúzcoa (50,6 % de vascoparlantes bilingües, 20,4 % bilingües pasivos, 32,1 % castellanoparlantes exclusivos) y minoritario en Vizcaya (27,6 % bilingües, 17,8 % bilingües pasivos, 52 % castellanoparlantes monolingües) y Álava (19,2 % vascoparlantes bilingües, 18,4 % bilingües pasivos y 62,4 % castellanoparlantes monolingües). Los datos muestran una tendencia de aumento del número de vascoparlantes bilingües y bilingües pasivos y un descenso de monolingües castellanoparlantes en los tres territorios, especialente en Álava (pasando del 7% de vascoparlantes bilingües en 1991 a 19,2% en 2016). Este incremento se debe al número de vascoparlantes entre la población joven (71,4% entre 16 y 25 años). 

En el caso de Navarra, este último estudio sociolingüístico realizado en 2016 indicó que para el conjunto de la población de Navarra el porcentaje de vascoparlantes activos en mayores de 16 años era del 12,9 % (69 000), además de un 10,3 % (55 000) de bilingües pasivos, frente a un 76,8 % de navarros que eran exclusivamente castellanoparlantes. Los datos muestran una tendencia de aumentos de vascoparlantes activos (3,4 puntos más que en 1991) y especialmente de bilingües pasivos (5,7 puntos más que en 1991) y un descenso de monolingües castellanoparlantes (9,1 puntos menos que en 1991). Esta tendencia también se debe al número de vascoparlantes entre la población joven (25,8% entre 16 y 25 años, frente al 10% en 1991). 
El conocimiento del euskera en Navarra presenta realidades muy distintas en función de las zonas que estableció la Ley Foral del Vascuence en 1986. Así, en la zona de predominio lingüístico vascoparlante de Navarra hay un 61,1% de vascohablantes activos, mientras que en la Zona Mixta es del 11,3% y en la "Zona no vascófona" del 2,7%. Los datos de la VI Encuesta Sociolingüística referidos a Navarra se concretarán más a mediados de este año. 

En el País Vasco francés no se tienen estudios oficiales ni de la Región de Aquitania ni del Departamento de Pirineos Atlánticos anteriores a 2016. El Organismo Público de la Lengua Vasca del País Vasco francés publicará a principios del año que viene los datos de la VI Encuesta Sociolingüística realizada junto al Gobierno Vasco y Gobierno de Navarra referidos al territorio. No obstante, estudios sociolingüísticos dirigidos desde el Gobierno Vasco estimaron en 2011 el número de vascoparlantes en 51 100 (el 21,4 % de la población del País Vasco francés). La tendencia ha sido de descenso en el número de hablantes debido a un mayor número de hablantes entre la población mayor, si bien se trata de un descenso ralentizado debido a cierto aumento de conocimiento entre la población joven.

Fuera de Europa, existen algunas comunidades vascohablantes en el continente americano, en las cuales se pueden encontrar vascos de segunda y tercera generación que siguen hablando la lengua en el dialecto original, e incluso híbridos de los dialectos tradicionales, resultado del encuentro de vascos de diferentes regiones. Muy llamativa es, por ejemplo, la existencia de una comunidad de origen vasco en el estado estadounidense de Idaho que ha logrado mantener vivo el idioma. De hecho existen muchas teorías no contrastadas acerca del uso del euskera por parte del ejército estadounidense durante la Segunda Guerra Mundial para impedir que sus comunicaciones internas no pudieran ser interceptadas por las Potencias del Eje .

En 2009 fue mencionado en el libro rojo de la Unesco sobre lenguas en peligro como un lenguaje vulnerable.

El estatus detentado por el euskera en los territorios en los que es hablado es diverso.

Tanto España como Francia fueron signatarios en 1992 de la Carta Europea de las Lenguas Regionales o Minoritarias promovida por el Consejo de Europa. No obstante, solo España procedería a ratificar la carta por instrumento depositado en 2001 mediante el que se declara que la efectividad plena de la aplicación de los compromisos, obligaciones y garantías que se derivan de la Carta alcanzará a todas aquellas lenguas españolas declaradas cooficiales por las distintas comunidades autónomas; lo que en el caso del euskera supone su aplicación al territorio del País Vasco, por un lado, y a la zona vascófona de Navarra, por otro.

En el caso de España, la vigente Constitución de 1978 declara en el artículo 3 que el castellano es la «lengua española oficial del Estado», y que «las demás lenguas españolas serán también oficiales en las respectivas Comunidades Autónomas de acuerdo con sus Estatutos».

Así, en el País Vasco, su Estatuto de Autonomía de 1979 establece que tanto el euskera como el castellano son lenguas oficiales en todo su territorio, independientemente de la existencia de áreas tradicionalmente vascoparlantes y áreas tradicionalmente castellanoparlantes en el territorio de la comunidad autónoma. Tal declaración sería desarrollada posteriormente por la "Ley 10/1982 Básica de Normalización del uso del Euskera" que regula el régimen de oficialidad de las dos lenguas en las esferas administrativa, educativa y social, disponiendo la obligatoriedad de la enseñanza del euskera, bien como asignatura, bien como lengua vehicular.
En el caso de Navarra, el Amejoramiento del Fuero otorga al castellano el carácter de lengua oficial de Navarra y también al euskera, pero en este caso solo para las zonas vascoparlantes de la comunidad foral; disponiéndose que una ley foral sería la que delimitase de manera concreta la extensión de esa área vascoparlante en la que el euskera sería cooficial. Así, en 1986 se aprobó la Ley Foral del Vascuence que efectuó dicha delimitación de acuerdo al concepto legal de predominio lingüístico, determinando que las «zonas vascoparlantes de Navarra» a las que alude el Amejoramiento del Fuero serían las incluidas en la denominada «Zona Vascófona», área esta en la que tanto el euskera como el castellano serían lenguas cooficiales, mientras que en las zonas castellanoparlantes de Navarra (las denominadas «Zona Mixta» y «Zona No Vascófona») la única lengua oficial sería el castellano.

Para la Zona Vascófona se estableció la obligatoriedad de la enseñanza del euskera en el sistema educativo (bien como asignatura o bien como lengua vehicular), así como la regulación del uso oficial y normal de ambas lenguas. Además, la ley foral estableció que dentro de las zonas castellanoparlantes de Navarra se reconocería para una de ellas, la Zona Mixta, una regulación especial consistente en el derecho de los ciudadanos a recibir la enseñanza en euskera o del euskera de acuerdo con la demanda, así como la facultad de que los ciudadanos de esta zona pudieran «dirigirse» (aunque no relacionarse con la administración o recibir los servicios públicos en esa lengua, como sí se establece para la Zona Vascófona) a las administraciones públicas en euskera sin que la administración pudiese requerir a los ciudadanos la traducción de su escrito al castellano; dándose el hecho de que a causa de la concentración macrocefálica de la población navarra en el Área Metropolitana de Pamplona y el fenómeno de despoblamiento sufrido por la Montaña de acuerdo con los datos de la "Encuesta Sociolingüística de 2001" el mayor número de vascoparlantes de Navarra en términos absolutos se concentre precisamente en esta llamada "Zona Mixta".

El estatus oficial del euskera en el País Vasco francés viene determinado por la Constitución de la República Francesa, que establece que la única lengua oficial de Francia es el francés, por lo que el resto de lenguas habladas en territorio galo, como el euskera, no tienen carácter de lengua oficial, ni están incorporadas al sistema educativo. En 2001, un acuerdo entre el Gobierno nacional francés, la región de Aquitania, el departamento de Pirineos Atlánticos y un comité de cargos públicos electos del País Vasco francés permitió la creación de la "Office Public de la Langue Basque" como entidad oficialmente reconocida para accionar una política en favor de la lengua y cultura vascas, y a la que se le atribuye la facultad de expedir los certificados acreditativos de aptitud en esa lengua.

El euskera es una lengua de tipología aglutinante y genéticamente aislada, es decir, no muestra un origen común claro con otras lenguas, lo que ha llevado a diversas y múltiples teorías sobre el origen de esta lengua.

Aunque hay muchas hipótesis sobre el origen y parentescos del euskera, todas ellas carecen de fundamentos sólidos. La única probada es la que lo relaciona con el antiguo aquitano, euskera arcaico o vasquitano del cual sólo se conservan unas 400 breves inscripciones fúnebres dispersas por la actual Aquitania, Aragón, La Rioja, Navarra y el País Vasco. Es por ello que el único parentesco que se considera demostrado es el del euskera con el antiguo idioma aquitano, ya desde los trabajos de Luchaire en 1877, ampliados posteriormente por Mitxelena y Gorrochategui. De hecho, los especialistas en historia del euskera consideran que el aquitano es simplemente vasco antiguo.

Tres son las teorías historiográficas principales sobre el parentesco:

El más conocido defensor de esta teoría fue el padre de la lingüística moderna, Wilhelm von Humboldt, que afirmaba que el idioma íbero era de hecho el antecesor del euskera; tesis que defendería también Miguel de Unamuno. Dentro del vasco-iberismo algunos investigadores propugnaron la relación filológica entre estas lenguas, mientras que para otros la relación entre las lenguas íbericas y el vascuence se limitaría a ser de sprachbund. Una tercera opinión defendería que ambas lenguas pertenecían a un mismo grupo lingüístico, pero que el íbero no sería el antepasado del euskera.



Al margen de los estudios puramente lingüísticos, desde la antropología y la historiografía se ha intentado dar respuestas al origen del euskera a partir de los datos obtenidos en la investigación del origen de los vascos, siendo también tres las propuestas más conocidas en este aspecto:



Con independencia de las teorías sobre su parentesco lingüístico, la onomástica y la toponimia histórica atestiguan que la versión primitiva del euskera ocupó durante la Edad Antigua un área de extensión mayor que la que tendría posteriormente al producirse la caída del Imperio romano de Occidente, y que las sucesivas llegadas de pueblos de lengua indoeuropea desde el fin de la Edad del Bronce y el comienzo de la Edad del Hierro, supusieron para el euskera como para el resto de lenguas paleohispánicas una disminución de su área de extensión geográfica.

Es habitual la consideración de que los vascones (pueblo prerromano que las fuentes clásicas sitúan en el territorio del norte y centro de la actual Navarra, además de en las Cinco Villas aragonesas y en la desembocadura del río Bidasoa) eran de habla eúskara, así como también los aquitanos (establecidos según las fuentes romanas en el extremo suroccidental de la actual región de Aquitania); resulta polémica sin embargo la filiación lingüística que presentaban el resto de pueblos prerromanos que las fuentes clásicas sitúan en áreas limítrofes con los vascones (los iberos iacetanos y las tribus celtas de várdulos, caristios, autrigones y berones).

Con la Conquista de Hispania y la infiltración romana en el territorio de los vascones, se ha presumido que el euskera recibiría una intensa influencia de la lengua latina, contextualizándose precisamente en esta época la primera gran adopción por el euskera de palabras de raigambre latina.

Tras la caída del Imperio romano de Occidente y la conformación dos siglos después del núcleo del primitivo Reino de Pamplona el euskera viviría un periodo de expansión en el contexto de las repoblaciones que trajo consigo la Reconquista como atestiguan fuentes documentales como la "fazaña de Ojacastro".

A partir de la Baja Edad Media, en cambio, el euskera iniciaría un periodo de lenta regresión desplazado en un primer momento por el gascón y el navarro-aragonés, y en un segundo, por el castellano y el francés.

Pese a este declive, a comienzos de la Edad Moderna el euskera era todavía la lengua ampliamente predominante entre la población de Guipúzcoa, la mitad septentrional de Navarra, la práctica totalidad de Vizcaya y la mitad norte de Álava; una situación que se mantendría sin cambios sustanciales hasta los procesos sociales, económicos políticos y culturales puestos en marcha con la industrialización y el liberalismo siglo XIX que ocasionarían el gran retroceso del euskera que llevaría ya en el siglo XX a la creación de la Sociedad de Estudios Vascos y la Real Academia de la Lengua Vasca y al incremento de iniciativas en favor del euskera que conjurasen el riesgo de su desparición.

Siendo patente que una de las causas que facilitaban el retroceso acelerado del euskera en los territorios en los que todavía se hablaba era el alto grado de fragmentación dialectal que el vascuence presentaba, en los primeros años del siglo XX se fue extendiendo el convencimiento de que el euskera sólo podría tener futuro como lengua de comunicación y expresión, en tanto que se lograra superar la situación de fragmentación con la creación de un registro escrito único reconocido por todo el ámbito vascohablante. De esta manera, el proceso para la unificación literaria sería iniciado ya en 1918 con la fundación de la Real Academia de la Lengua Vasca ("Euskaltzaindia") y la presentación de distintas propuestas. Entre ellas, una corriente de opinión apostaba por utilizar como base el "labortano clásico" de Axular de acuerdo con la misma función que tuvo el toscano en la unificación de la lengua italiana, siendo Federico Krutwig el principal defensor de este modelo y seguido por personas como Gabriel Aresti y Luis Villasante. Aunque en sus inicios ganó apoyos, finalmente la propuesta acabó siendo rechazada por la mayoría de los escritores y estudiosos por encontrarse demasiado alejada de la base sociológica de la lengua. El debate sobre la unificación culminaría en 1968, en la reunión del Santuario de Aránzazu ("Arantzazuko Batzarra") en la que la Real Academia de la Lengua Vasca durante la celebración de su 50 aniversario decidió apoyar y promover formalmente el informe de las Decisiones del Congreso de Bayona ("Baionako Biltzarraren Erabakiak") de 1964 redactado por el Departamento Lingüístico de la Secretaría Vasca ("Euskal Idazkaritza") de Bayona, apoyado por distintos literatos éuskaros a través de la recién creada "Idazleen Alkartea" (Asociación de Escritores) y "Ermuako Zina" (Juramento de Ermua) de 1968. Los postulados de este informe fueron recogidos en la ponencia presentada por el académico Koldo Mitxelena, quien se encargaría de entonces en adelante y junto con Luis Villasante de dirigir el proceso de la unificación literaria.

El resultado sería el "euskera batua" (literalmente ‘euskera unificado’ o ‘euskera unido’), que es el soporte normativo (o registro) del euskera escrito. Se basa en los dialectos centrales del euskera como el dialecto navarro, dialecto navarro-labortano y el dialecto central del euskera, y se encuentra influido por el labortano clásico del siglo XVII, precursor de la literatura en euskera y lazo de unión entre los dialectos españoles y franceses.

Este registro, adoptado oficialmente a partir del reconocimiento de la autoridad normativa de la Real Academia de la Lengua Vasca por las instituciones de Navarra y el País Vasco, es el preferido y potenciado en la administración, la enseñanza y los medios de comunicación.

Desde los primeros años de la vigencia del batúa se ha desarrollado una importante polémica sobre el efecto que el batúa iba a tener sobre los dialectos del euskera real, hablado hasta esa fecha. Así, escritores como Oskillaso y Matías Múgica sostuvieron que el euskera batúa y el impulso institucional que llevaba a cabo iba a ser letal para los dialectos matando al 'euskera auténtico' en pos de la variante unificada, artificialmente creada. No obstante, otros escritores como Koldo Zuazo han venido sosteniendo que el batúa no es más que el registro destinado a ser utilizado en los ámbitos más formales (como la educación, la televisión pública, los boletines oficiales...) y viene a complementar al resto de los dialectos, no a sustituirlos; argumentó incluso que la extensión del batúa ayuda a reforzar los dialectos al incidir en la recuperación general de la lengua.

A pesar de la no concluida polémica sobre la existencia de grafitis en euskera en los siglos III a V de nuestra era, se considera que los textos más antiguos de esta lengua encontrados hasta ahora son varias palabras aparecidas en epitafios del siglo II d. C. en Aquitania, investigadas por primera vez por Achille Luchaire, después por Julio Caro Baroja y Koldo Mitxelena, y en épocas más recientes por Joaquín Gorrochategui. En el municipio navarro de Lerga (Estela de Lerga) se encontró una estela funeraria hispanorromana con antropónimos indígenas, datada en el siglo I. Mitxelena definió el parentesco entre la inscripción de Lerga y la epigrafía aquitana, así como con las inscripciones hispánicas éuscaras que se encontraría posteriormente. Es por ello que hoy en día se considera que el aquitano es simplemente vasco antiguo o euskera arcaico.

La información disponible sobre el euskera medieval es bastante escasa y fragmentaria. La mayor parte de la información sobre el euskera medieval proviene del estudio de la toponimia y la antroponimia, además de algunas pocas palabras (como términos jurídicos del Fuero General de Navarra) y algunas frases cortas. El latín y los romances fueron las lenguas del saber, de las minorías cultas y de la administración oficial, tanto civil como eclesiástica. Pero aquellos grupos también debían de conocer la lengua de los collazos y siervos. Los escribanos utilizaban el romance para escribir, aunque la lengua de uso cotidiano fuera el euskera. Del siglo XI se cree que son las glosas halladas en el monasterio de San Millán de la Cogolla, en La Rioja, pequeñas anotaciones de traducción en un texto latino, las llamadas Glosas Emilianenses, escritas en latín y romance salvo la 31 y 42 que son frases en algún dialecto desconocido del euskera. Estas glosas son las siguientes:

No hay total acuerdo sobre el significado de esas dos glosas. Nótese que la placa conmemorativa situada en el monasterio comete el pequeño error de reproducir el texto con una grafía modernizada, utilizando la letra zeta, cuando en el texto original se observa claramente la ce cedilla. En los primeros siglos del segundo milenio de nuestra era, las referencias al uso del euskera en el área pirenaica son diversas. Así, en una escritura del siglo XI, la donación del monasterio de Ollazábal (Guipúzcoa), además de fórmulas latinas, están los detalles ofrecidos de los linderos del terreno en euskera. También se encuentran huellas de esta lengua en una guía para peregrinos de Santiago de Compostela del siglo XII y atribuida a Aimeric Picaud, que incluye un pequeño vocabulario en euskera. Así mismo en 1349, en la ciudad de Huesca se promulga un decreto que sanciona a los que hablaran en el mercado en árabe, hebreo o "basquenç" con 30 soles de multa.

A medida que avanza la Edad Media la información es más abundante, aunque no llegamos a tener textos extensos hasta los siglos XV y XVI. El fragmento original más extenso en lengua vasca se contiene en una carta bilingüe intercambiada en 1416 entre el secretario del rey navarro Carlos III y el jefe del tesoro del reino, la llamada "carta bilingüe de Matxin de Zalba". Son de gran interés los fragmentos de romances y cantares que citan las crónicas históricas, como el Cantar fúnebre de Milia de Lastur que recoge en sus "Memorias" Esteban de Garibay en 1596. "Refranes y sentencias" publicado por la misma época en Pamplona es un recopilatorio de refranes populares, probablemente del entorno de Bilbao, según Joseba Lakarra. Cartas personales y otros textos manuscritos o actas de testigos en juicios se consideran de un valor preciadísimo, como raros testimonios del euskera hablado en aquellos siglos. Entre la correspondencia personal destaca la de fray Juan de Zumárraga, primer obispo de México, que en 1537 escribió a su familia una carta redactada en dialecto vizcaíno y en castellano. Por su importancia, esta carta ha sido publicada por la revista "Euskera", órgano oficial de la Real Academia de la Lengua Vasca. Es probablemente el texto vasco en prosa más largo conocido anterior a los primeros libros en euskera.

El primer libro conocido se imprimió en 1545, con el título "Linguae Vasconum Primitiae" (‘Primicias de la lengua de los vascos’) y firmado por el sacerdote bajonavarro Bernat Dechepare. Es una colección de poemas de tema erótico, autobiográfico y religioso. Dedica también versos al euskera, y es de reseñar que el autor es consciente de que el suyo es el primer intento de llevar su lengua a la imprenta. En su poema "Kontrapas" dice lo siguiente:

Entre 1564 y 1567 Juan Pérez de Lazarraga escribe su manuscrito, recientemente descubierto y compuesto por 106 páginas. En él podemos encontrar poesías y novela pastoril renacentista.

La siguiente obra conocida es la traducción del Nuevo Testamento "(Iesu Christ Gure Iaunaren Testamentu Berria"), encargada por la reina de Navarra Juana de Albret al ministro calvinista Joanes Leizarraga, impresa en 1571 en La Rochelle.

La Contrarreforma trajo consigo una nueva «política lingüística» por parte de la Iglesia Católica. Así pues, se tradujeron catecismos y otras obras de la literatura cristiana, destinados a la formación de los fieles. En el siglo XVII en el País Vasco francés hay un grupo de escritores, hoy día llamado «la escuela de Sara», que basándose en el habla de la costa de Labort (zona de gran importancia económica) desarrollará un modelo literario para la lengua vasca. El mayor exponente de estos escritores es Pedro Axular.

En el País Vasco español a partir del siglo XVII también aparecerán libros impresos en euskera, consagrando el uso literario de los dialectos vizcaíno y guipuzcoano primero, y del resto con el devenir de los siglos. Es preciso reconocer que inicialmente, en el siglo XVIII, esta labor literaria se limitó a traducciones mediocres de textos religiosos, aunque Agustín Kardaberaz destacara por la calidad de su obra religiosa y retórica.

Dejando a un lado estos antecedentes, junto con otros manuscritos encontrados en el siglo XX, el que podría considerarse el primer clásico de la literatura en euskera fue la obra ascética "Gero" (‘Después’) del también sacerdote Pedro de Agerre Azpilikueta, escrita en «labortano clásico» e impresa por primera vez el año 1643 en Pau. Su prosa fue tomada como ejemplo del buen escribir entre los escritores tanto al norte como al sur del Pirineo. Manuel de Larramendi se refiere a Axular como maestro.

Hasta muy tardíamente los escritores laicos fueron una excepción y la mayoría de las obras publicadas fueron de temática religiosa, limitándose principalmente a traducciones de doctrinas y catecismos, biografías de santos y algunos tratados teológico-filosóficos. Entre las obras que tratan temas profanos encontramos gramáticas, apologías (que pretendían demostrar la pureza y perfección de la lengua de los vascos, aunque casi todas fueron escritas en castellano), antologías de refranes y poemas, además de obras del teatro tradicional vasco o pastorales.

En el siglo XVIII, uno de los grandes dinamizadores culturales y políticos de Vasconia fue el padre jesuita Manuel Larramendi (1690-1766), quien fue autor de una gramática y un diccionario vascongado. Su influencia marcó un antes y un después en la literatura vasca. Se ocupaba de corregir los manuscritos de muchos escritores de su época antes de imprimirlos, y puede considerársele uno de los líderes o referentes en su tiempo.

En la segunda mitad del siglo XIX, la derrota en las Guerras Carlistas y los cambios que se estaban dando en la sociedad originaron cierta preocupación sobre el futuro de la lengua, lo cual motivó la fundación de asociaciones como la Sociedad Euskara de Navarra, la celebración de certámenes literarios y juegos florales y la aparición de las primeras publicaciones en euskera. La lingüística europea comenzó a interesarse por ella y empezó a estudiarse la lengua de manera científica. Floreció la literatura y los folcloristas y musicólogos se interesaron por recuperar la tradición oral. En 1918 se fundó la Sociedad de Estudios Vascos-Eusko Ikaskuntza con el patrocinio de las cuatro diputaciones vasconavarras y un año después, la Real Academia de la Lengua Vasca ("Euskaltzaindia") fue fundada por Alfonso XIII.

Por el contrario, algunos intelectuales vascos de la época como Miguel de Unamuno llamaban a aceptar con dolor y resignación la muerte del euskera, lengua con la que —según él— no podían transmitirse ideas abstractas. El filósofo llegaba a afirmar en momentos de íntimo pesimismo depresivo que los vascos debían abandonar su lengua y tradiciones para así poder entrar en la modernidad española.

Siendo esta postura, con algunas excepciones, la mayoritaria entre la izquierda y el liberalismo vascos de aquel momento, tanto en España como en Francia, los mayores defensores de la lengua fueron los sectores foralistas, tradicionalistas y nacionalistas.

Entre 1848 y 1936, se produjo el llamado "euskal pizkundea" o renacimiento vasco, cuando se encuentra la poesía cultista de autores como Nicolás Ormaetxea "Orixe", Xabier Lizardi o Esteban Urkiaga "Lauaxeta", impregnada del estilo de los poetas simbolistas. Sin embargo, la guerra civil y su desenlace pospusieron esa etapa de maduración literaria y social.

La identificación del euskera con la vida rural y por lo tanto con una idealizada Arcadia vasca, tan atractiva para muchos vascos, tuvo que durar hasta el relevo generacional de los años cincuenta y sesenta. Es entonces cuando en un ambiente de efervescencia cultural y política, el euskera empezó a oírse en boca de los jóvenes universitarios y ambientes urbanos.

El euskera aún era hablado por la mayoría de los habitantes de la zona norteña de Euskal Herria inmediatamente antes de la industrialización. Según los datos de 1866-1868 que maneja Ladislao de Velasco, lo hablaban 170 000 de los 176 000 habitantes de Guipúzcoa (140 000 de manera habitual), 149 000 de los 183 000 vizcaínos (de los que 6000 eran extranjeros y 28 000 vivían en el distrito de Valmaseda-Encartaciones, donde el euskera desapareció a finales del siglo XVIII y principios del XIX, con el final de la Primera Guerra Carlista), 12 000 de los 120 000 alaveses, 60 000 de los 300 000 habitantes de la Navarra española y 80 000 de los 124 000 habitantes del País Vasco francés.

Tipológicamente el euskera es una lengua fuertemente aglutinante. En cuanto a la clasificación genética, actualmente el euskera es una lengua aislada, ya que carece de lenguas emparentadas. Sería sucesora directa del euskera arcaico o histórico de los siglos I a III d. C.

El euskera, por su situación geográfica, adoptó el alfabeto latino cuando comenzó a desarrollarse como lengua escrita en el siglo XVI. Generalmente se escribía según los sistemas del castellano y del francés, adaptándolas con mayor o menor éxito a la fonética vascongada. El líder nacionalista Sabino Arana diseñó un particular sistema ortográfico, logrando cierto éxito entre sus seguidores. Tras la Guerra Civil del 36, el sistema aranista fue abandonándose porque las consonantes tildadas que precisaba encarecían las ediciones y resultaban muy poco prácticas.

La Academia de la Lengua vasca fue estableciendo a partir de 1968 una normativa unificada. Actualmente el alfabeto vasco está compuesto de las siguientes letras:

En total 27 letras, las mismas que en castellano ("ü, ç, é" no se consideran letras separadas).

Asimismo, tiene los siguientes dígrafos: "dd, rr, tt, tx" (pronunciada como la «che» en español), "ts" (pronunciada como una "che" suave), "tz" (pronunciada como la «zz» italiana en «pizza»).

En el caso de algunas consonantes precedidas de la "i", cambian su sonido después de pronunciar la «i»: "il" (la "l" se pronuncia como la «ll» en España; ej.: "ilea" se pronuncia "illea"), "in" (la "n" se pronuncia como la «ñ» en español pero más suave; ej.: "ikurrina" se pronuncia "ikurriña" con el sonido de la ñ suave), "is" (la "s" se pronuncia como la «x» del euskera), "its" (la "ts" se pronuncia como la «tx» en euskera).

En las variedades más orientales, en algunas palabras existe la posibilidad de aspiración después de consonante, lo que ha solido reflejarse en la literatura de estos dialectos. Ejemplos: "aphez, ithurri, kherestu, orho, alha, unhatu."

No existen las tildes o acentos ortográficos más que en préstamos y modismos de otras lenguas, ya que el acento en euskera no tiene valor fonológico, como sí ocurre en el castellano. Normalmente la sílaba fuerte en la entonación es la segunda empenzando por la izquierda.



Las letras raras "c, q, v, w, y" son denominadas "ze, ku, uve, uve bikoitza, i grekoa"; la letra modificada "ç" es denominada "ze hautsia".

En suletino, hay vocales nasales ("õ, û") y sibilantes sonoras ("ss, zz"), pero nunca se reflejan en la escritura.

Consonantes
Vocales (euskera general)

El suletino además además incluye la vocal anterior labializada /y/ usualmente escrita como "ü".


En vasco, el acento no se representa ortográficamente pero sí que existen sílabas átonas y tónicas y es muy diferente a las lenguas románicas. La unidad de acentuación no tiene por qué estar en una palabra como sucede en castellano sino en el sintagma. Es decir, la sílaba tónica puede desplazarse dentro de una misma palabra dependiendo de lo que le acompañe.

Normalmente, en euskera, se tiende a acentuar la segunda sílaba y la última, si bien el acento de la última sílaba no se marca tanto como el de la segunda.

La morfología del euskera es muy rica en la estructura del sintagma nominal y verbal.

La forma de construir los grupos nominales y verbales es compleja, debido a la declinación, a la ergatividad (caso "nork") y a la gran cantidad de información que el verbo contiene, no sólo sobre el sujeto, sino también sobre el objeto directo e indirecto. Además, en la forma de tratamiento familiar ("hika"), el verbo varía sus desinencias según el sexo de la persona a la que se habla, en la segunda persona del singular del alocutivo.

Los sintagmas nominales: la declinación

La lengua vasca dispone de dos medios para reflejar la relación entre los sintagmas de la oración: la declinación y las postposiciones.

La declinación es el conjunto de marcas del sintagma nominal para expresar la función sintáctica que desempeña, es decir, los casos gramaticales (sujeto, complemento directo e indirecto), casos de lugar-tiempo (complementos circunstanciales) y otros complementos.

Las principales características de la declinación vasca son:

Ejemplo: dativo singular (caso "nori"), "-ari": "gizon-ari, anaia-ari, beltz-ari, katu-ari" (al hombre, al hermano, al negro, al gato). Si termina en -a: "osaba+ari" = "osaba-ri" (al tío).
Ejemplo: dativo singular: "-ari" / dativo plural: "-ei" / dativo indefinido: "-(r) i": Gizonari eman dio / Gizonei eman die / Zein gizoni eman dio? (Lo ha dado al hombre / Lo ha dado a los hombres / ¿A qué hombre(s) se lo ha dado?

Sin embargo, cuando el sintagma nominal tiene función de objeto directo, pero se encuentra en una frase interrogativa o negativa con un valor no determinado, el caso que se utiliza es el partitivo y la marca que se añade es "-(r) ik": "Ez daukat dirurik" (No tengo dinero).

Ergativo: es el caso donde el sintagma nominal cumple la función de sujeto de un verbo transitivo y la marca que se añade es "-(e) k". "Mendiek gero eta zuhaitz gutxiago dituzte" (Los montes cada vez tienen menos árboles).
Dativo: en este caso, el sintagma nominal adopta la función de objeto indirecto en aquellas oraciones con tres elementos "nor-nori-nork", o de dos elementos "nor-nori". La marca que se añade es "-(r) i", por ejemplo, "Umeari esan diot" (Se lo he dicho al niño).
Los casos de lugar: Los casos de lugar varían si se añaden a un nombre animado o a uno inanimado. "Ama-rengana joan naiz" (He ido donde la madre)/ "Etxe-ra joan naiz" (He ido a casa).
Otras declinaciones: son las correspondientes a los siguientes casos: instrumental (acerca de qué/quién; mediante qué/quién), sociativo (con qué/quién), genitivo (de quién), motivativo (a causa de qué/quién), destinativo (para quién) y prolativo ([tomado] por qué/quién). Las declinaciones empezadas por "nor" se refieren a seres vivos (a excepción de plantas); las empezadas por "zer", a objetos inanimados y a plantas.

En euskera los determinantes pueden ir incluidos en la palabra:

O también pueden ir fuera de la palabra:


Los cardinales son:
1-bat, 2-bi, 3-hiru, 4-lau, 5-bost, 6-sei, 7-zazpi, 8-zortzi, 9-bederatzi, 10-hamar, 11-hamaika, 12-hamabi (diez dos), 13-hamahiru (diez tres), 14-hamalau (diez cuatro)... 18-hamazortzi o hemezortzi, 19-hemeretzi, 20-hogei, 21-hogeita bat (veinte y uno), 22-hogeita bi (veinte y dos)... 30-hogeita hamar (veinte y diez), 31-hogeita hamaika (veinte y once), 32-hogeita hamabi (veinte y diez dos), 33-hogeita hamahiru (veinte y diez tres)... 40-berrogei (doble veinte), 41-berrogeita bat (doble veinte y uno)... 50-berrogeita hamar (doble veinte y diez), 51-berrogeita hamaika (doble veinte y once), 52-berrogeita hamabi (doble veinte y diez dos)... 60-hirurogei (tres veintes), 61-hirurogeita bat (tres veintes y uno)... 70-hirurogeita hamar (tres veintes y diez), 71-hirurogeita hamaika (tres veintes y once)... 80-laurogei (cuatro veintes), 81-laurogeita bat (cuatro veintes y uno)... 90-laurogeita hamar (cuatro veintes y diez), 99-laurogeita hemeretzi (cuatro veintes y diez nueve), 100-ehun, 200-berrehun, 300-hirurehun, 400-laurehun, 500-bostehun, 600-seiehun, 700-zazpiehun, 1000-mila, 1001-mila eta bat... 1 000 000-milioi

Ordinales:
1.-lehen/aurren, 2.-bigarren, 3.-hirugarren... n-garren.

Distributivos:
1-bana (uno para cada uno), 2-bina (dos para cada uno)... 10-hamarna... n-na.
Ergativo

Además del léxico patrimonial heredado del protoeuskera existen formas léxicas que son préstamos de otras lenguas, procedentes de:

En 1729, el jesuita Manuel de Larramendi publicó en Salamanca una gramática del euskera, a la que titula "El Imposible Vencido. El arte de la lengua bascongada", donde hablaba de los diversos dialectos: cita al guipuzcoano, al vizcaíno y al navarro o labortano ("que comúnmente es uno mismo", dice).
Una clasificación posterior de los dialectos fue obra del vascófilo Louis-Lucien Bonaparte, sobrino de Napoleón Bonaparte. El mapa fue revisado por el sacerdote y primer presidente de la Academia de la Lengua Vasca, Resurrección María de Azkue (1864-1951).

En 1998, el lingüista Koldo Zuazo realizó una renovación de la distribución de los dialectos, basándose en criterios desconocidos o ignorados por los anteriores autores. Esta clasificación moderna divide al euskera en seis dialectos (en euskera llamados "euskalkiak"): dialecto occidental; dialecto central; navarro, navarro oriental, navarro-labortano y suletino. Bonaparte consideraba el dialecto roncalés un subdialecto del suletino ("suletino español"), mientras que Azkue lo clasificó como dialecto diferenciado. Esta variante hablada antiguamente en los siete pueblos del valle de Roncal (Navarra), desapareció definitivamente en 1991 con la muerte de Fidela Bernat, su última hablante. Se podría hablar también de un dialecto alavés, hoy día extinto, aunque por la toponimia y los testimonios escritos que se conocen sabemos que era muy parecido al dialecto occidental. La principal fuente de información del euskera hablado en Álava es hoy día el recientemente descubierto manuscrito de Juan Pérez de Lazarraga (siglo XVI), ya que se trata del testimonio escrito más completo.

Los mapas se realizan uniendo en grupos las hablas con coincidencias generales, ya que el euskera se caracteriza por su variedad en giros y acentos. Las diferencias se pueden apreciar de una localidad a otra, e incluso de un barrio a otro. Por ejemplo, si tomamos la palabra "ogia" (el pan), a lo largo de los territorios vascohablantes encontraremos variantes de la misma palabra como "ogiya, ogiye, ogixa, ogixe, uía, uíe, uíxe, oía," etc.

Las diferencias fonológicas, morfosintácticas y léxicas entre dos dialectos geográficamente distantes pueden ser tantas como las que existen entre el catalán y el castellano. Éste es el caso del vizcaíno (extremo occidental) y del suletino (extremo oriental), que se caracterizan por su lejanía respecto a los demás dialectos, y que son hablados precisamente en los dos extremos del dominio lingüístico del euskera. Aun así, para la mayoría de los vascohablantes hablar dialectos diferentes no es un obstáculo insalvable para entenderse. Por otra parte, la inteligibilidad mutua puede depender, además de la distancia geográfica, de la costumbre y el "don de lenguas" de los hablantes, además del nivel de escolarización y del consiguiente conocimiento de la propia lengua más allá del registro coloquial. Un caso ilustrativo puede ser el del vizcaíno: un vascohablante navarro, por ejemplo, puede entender sin grandes dificultades a alguien que habla una variedad occidental, gracias a que no le son extrañas las palabras que utiliza, las cuales ha podido leer en los libros y usarlas en un registro formal. Además, el vascohablante navarro puede acostumbrarse a escuchar euskera vizcaíno en los medios de difusión y hacerse entender con interlocutores vizcaínos, hablando cada uno en su respectivo dialecto, sin excesivas complicaciones. Esto, dicho está, depende de la predisposición, pronunciación, o nivel cultural de los interlocutores. Estas situaciones son habituales en lenguas que se caracterizan por su diversidad dialectal, como son los casos del alemán y el italiano.

A este respecto, el lingüista Koldo Mitxelena opina que
Muchas personas han aprendido principalmente el euskera unificado, con mayor o menor influencia del habla de su región. Aunque el euskera batúa es la versión oficial del idioma, los dialectos son muy utilizados en las radios y publicaciones locales, con el objetivo de acercarse más al lenguaje cotidiano. En los casos del dialecto occidental y del suletino, también están presentes en la enseñanza y la propia academia ha dictado normas sobre su escritura. Ello no se contrapone al uso del euskera batúa, pues se considera que la convivencia entre los dialectos y el vasco estándar es una condición indispensable para garantizar la vitalidad de la lengua.

Por las condiciones históricas en las que la literatura vasca se ha desarrollado, la comunidad lingüística no ha dispuesto de un único modelo para el uso escrito, sino varios, que no pudiendo imponerse completamente al resto, se han ido desarrollando paralelamente desde el siglo XVI. En los manuales de historia de la literatura vasca se habla de los "dialectos literarios" guipuzcoano, vizcaíno, labortano y suletino, ya que estos son los más utilizados en la producción literaria. Tanto el guipuzcoano al sur de los Pirineos, como el labortano al norte, han sido durante siglos los más utilizados como estándar, y son variedades que ganaron cierto prestigio en sus áreas de influencia, siendo referenciales a la hora de emprender el proyecto de la unificación en los años 60.

Labortano

""Alabainan Jainkoak altean du mundua maithatu, non bere Seme bekharra eman baitu, hunen baithan sinhesten duen nihor ez dadien gal, aitzitik izan dezan bethiko bizitzea""

Suletino

""Zeren Jinkoak hain du maithatü mundia, nun eman beitü bere Seme bekhotxa, amorekatik hartan sinhesten dian gizoneratik batere eztadin gal, bena ükhen dezan bethiereko bizitzia""

Guipuzcoano

""Zergatik ain maite izan du Jaungoikoak mundua, non eman duen bere Seme Bakarra beragan fedea duan guzia galdu ez dedin, baizik izan dezan betiko bizia""

La forma "euskera" (de los dialectos guipuzcoano, vizcaíno y altonavarro) es más usada que el término "vascuence" entre los hispanohablantes vascos y es la adoptada en el Diccionario de la Real Academia de la Lengua Española en su XXIIª edición. En cambio, en batúa se le denomina únicamente "euskara" (la más común en los dialectos centrales). También, según la región, se le llama "euskala", "eskuara", "eskuera", "eskara", "eskera", "eskoara", "euskiera", "auskera", "oskara", "uskera", "uskaa", "uska" o "üskara".







</doc>
<doc id="15285" url="https://es.wikipedia.org/wiki?curid=15285" title="Valle glaciar">
Valle glaciar

Un valle glaciar, también llamado artesa glaciar, se define como aquel valle por el que circula o ha circulado un glaciar de dimensiones importantes que ha dejado una geomorfología clara de glaciarismo.

Los valles glaciares son ríos de hielo. Se forman cuando el espesor del hielo acumulado en el circo es grande. El hielo de las capas inferiores se desplaza fuera del circo y se derrama valle abajo. Los fragmentos rocosos que contienen hielo ensanchan el valle. También excavan cubetas en las zonas de roquedo menos resistente. Estas cubetas, al fundirse el hielo, se convierten en lagos.

Los valles glaciares se caracterizan por presentar un perfil transversal en "U" o artesa, considerado éste en geomorfología el rasgo principal que permite diferenciar este tipo de canales por los que se desliza o deslizó una lengua de hielo. Otras características de los valles glaciares son las huellas de abrasión y sobreexcavación provocada por la fricción del hielo y el arrastre de material, existencia de canales de aludes, fondos planos con alternancia de umbrales y cubetas, vertientes muy verticales labradas que dan lugar a una ruptura de pendiente en hombrera y a la formación de valles colgados o suspendidos.

Los antiguos glaciares dieron origen a la formación de depósitos de materiales que previamente habían sido erosionados por los hielos. Dichos materiales son muy heterogéneos y forman a menudo diversos tipos de morrenas (terminales, laterales, de retroceso, etc.) en las que suelen formar lagos de origen glaciar, como los que se encuentran en el borde de los Alpes europeos (Como, Mayor, Garda, Ginebra, Constanza, etc.) o en la Suecia central y en muchas otras partes. También la sobreexcavación puede producir condiciones apropiadas para la formación de lagos de origen glaciar. En el caso de Venezuela, la Laguna de Mucubají está represada por la morrena terminal del glaciar que bajaba en el Pleistoceno desde el Páramo de Mucuñuque. En cambio, a unos 2 km hacia el SE, la Laguna Negra está represada por un umbral o dique natural de rocas resistentes precedidas por otras más débiles, las cuales fueron eliminadas por los hielos del glaciar y vaciadas formando lo que ahora es un profundo lago.

Cuando los glaciares secundarios confluyen en el fondo del valle principal por el que se desplaza o desplazó un glaciar más importante y de mayor profundidad, se producen los valles suspendidos o valles colgados. Tal es el caso, en la Sierra de Mérida (Venezuela), del valle donde se encuentra la Cascada del Sol: este valle descendió desde el Pico Bolívar pero al llegar al valle principal, excavado más de 100 metros más abajo por la mayor cantidad de hielo, decapitó al pequeño glaciar que ahora forma el valle suspendido. Es un fenómeno muy frecuente en Argentina, Alaska, Canadá, Chile, Nueva Zelanda, en la Península Escandinava, Rusia y desde luego, en las cordilleras asiáticas y en los Alpes. En el caso de los fiordos noruegos, los valles suspendidos constituyen un gran atractivo turístico, ya que producen cascadas de gran altura que caen directamente al mar en el interior de dichos fiordos.



</doc>
<doc id="15288" url="https://es.wikipedia.org/wiki?curid=15288" title="Vuelo sin motor">
Vuelo sin motor

El vuelo sin motor (también conocido como "vuelo a vela"), es un deporte aéreo, que consiste en pilotar un velero o planeador para recorrer distancias y elevarse sin más ayuda que los movimientos de las masas de aire en el seno de la atmósfera.

Aunque hay numerosos precedentes de vuelo planeado se considera a Otto Lilienthal como el padre del vuelo sin motor. Sin embargo, el verdadero comienzo de este deporte se realiza en Alemania en 1920, con el primer concurso de planeadores celebrado en la Wasserkuppe. Alemania sigue siendo hoy en día el país donde más practicantes hay y donde más innovaciones técnicas se producen.

Los planeadores se lanzaban en el comienzo del deporte, en los años 20 y 30 del siglo XX, desde lo alto de una ladera ayudados por un sistema de gomas elásticas. Los veleros se elevan actualmente remolcados por un avión o por un torno, que es un motor que enrolla un cable de cientos de metros al que se une el velero y que este puede soltar al llegar a la altura deseada o a la vertical del torno. Al llegar a la altura deseada, el velero se desengancha del cable que le une al avión o al torno y prosigue su vuelo.

Un velero es una aeronave sin motor, por lo que siempre está descendiendo. Por eso, en todas las modalidades del vuelo a vela se buscan masas de aire ascendentes, que hagan elevarse al velero porque suben más que lo que baja de manera natural la máquina. Un ejemplo: imaginemos un planeador que avanza a 100 km/h y cae un metro cada segundo (1 m/s), pero el piloto se las arregla para permanecer en una corriente ascendente de 5 m/s durante 60 segundos: habrá ganado 240 metros y habrá recorrido algo más de 1,6 km.

Las modalidades básicas de vuelo a vela son el vuelo a térmica, ladera y onda de montaña. En el vuelo a térmica, corrientes térmicas producidas por el calentamiento diferencial del suelo por el Sol se elevan en la atmósfera, de tal manera que con el planeador buscamos permanecer en su interior para subir (habitualmente, girando dentro de ellas). En el vuelo de ladera, el viento que incide de manera más o menos perpendicular a una ladera se ve forzado a subir. Si la ladera tiene la suficiente dimensión y el viento está bien orientado con la fuerza suficiente, un velero situado en posición óptima puede volar apoyado en el viento sin perder altura o incluso subiendo.

Por último, la onda de montaña es un fenómeno más complejo que se produce a sotavento de cadenas montañosas sobre las que incide un fuerte viento. Este viento origina un fenómeno ondulatorio más allá de las montañas, en el que en determinadas condiciones se puede volar y alcanzar grandes alturas.

Cada país tiene su reglamentación para obtener la licencia o permiso necesarios para pilotar planeadores. Además, existen títulos o diplomas reconocidos intenacionalmente por la Federación Aéronáutica Internacional () para determinados logros. Estos empiezan en la actualidad con el "C" de plata, que requiere haber conseguido 1) una distancia en línea recta de al menos 50 kilómetros 2) una ganancia de altura de 1000 metros y 3) una permanencia en el aire de al menos 5 horas. Los antiguos títulos A, B y C cayeron en desuso hace años cuando los planeadores fueron capaces de cada vez mayores prestaciones. Otros títulos como el C de oro y los diplomas (por ejemplo de 1000 kilómetros) están pensados para reconocer vuelos más difíciles.

Una medida simple del rendimiento de un velero es el coeficiente de planeo. Se trata de una medida de la distancia máxima que puede planear un velero en condiciones óptimas, desde una altura dada. Así, un coeficiente de planeo de 30:1 indica que el velero puede (teóricamente) planear 30 kilómetros desde una altura de 1 kilómetro (1.000 metros). En la vida real hay muchos factores que influyen en esa distancia (viento a favor o en contra, estado de la atmósfera, limpieza del avión, por citar algunos). Además, tampoco es la única característica del avión interesante de cara a considerar su rendimiento. Sin embargo, es una medida fácil de utilizar y ampliamente reconocida.

Los planeadores primitivos eran de estructura de madera recubiertos de tela. Los adelantos técnicos desde el inicio del deporte se pueden resumir en tres etapas: 1) los veleros de madera con progresivamente cada vez más alargamiento y fineza aerodinámica, dotados con perfiles aerodinámicos clásicos, que culminaron a finales de los años 30 con veleros que tenían coeficientes de planeo de aproximadamente 30:1. 2) En los años 50 se aplican y desarrollan los perfiles laminares aumentando progresivamente el rendimiento de los veleros hasta coeficientes de planeo de más de 40:1. 3) A finales de los años 60 se generaliza la construcción en materiales compuestos (fibra de vidrio y plástico, posteriormente también fibras de carbono y kevlar), que permiten obtener superficies de vuelo mucho más limpias aerodinámicamente, llegando hasta los coeficientes de planeo máximos de 60-70:1 de los veleros más avanzados de hoy.

Una medida un poco más completa es la «polar» del velero, una curva que indica, para cada velocidad con respecto al viento, la tasa a la que cae el velero, por lo que indica también cuál es el coeficiente máximo de planeo. Actualmente son apreciados los veleros con una polar bastante plana, es decir, que mantienen una baja tasa de caída para velocidades altas (200 km/h o superiores).

El interés de observar la polar de un velero viene porque dos veleros distintos pueden tener un coeficiente de planeo de 30:1 a una velocidad de 90 km/h, pero si uno de ellos tiene un coeficiente de 25:1 a 150 km/h, mientras que otro tiene un coeficiente de 20:1 a esta velocidad, preferiremos el primero, ya que nos permite desplazarnos más rápido perdiendo menos altura, lo cual es muy útil, entre otras cosas, para permanecer poco tiempo dentro de corrientes descendentes.

Hay tres tipos de planeadores: 
1ºPlaneadores primarios, usados para entrenamiento, tienen un armazón central al que van unidas las alas y los dispositivos estabilizadores y de control. El piloto se sitúa en un asiento desprotegido, al frente del armazón. 
2º Los veleros que se construyen como aviones ordinarios con fuselaje y con una cabina cerrada para una o dos personas. Están diseñados para conseguir la máxima eficiencia aerodinámica. 
3º Los planeadores de carga, están diseñados para uso militar o civil. Son naves de gran tamaño diseñadas para transportar grandes pesos. Están construidos no para remontarse, sino para ser remolcados en grupos detrás de un potente avión para incrementar la carga del aeroplano. Las grandes ventajas de este tipo de planeador son su capacidad para transportar grandes cargas y su flexibilidad para aterrizar a baja velocidad que les permite descender en espacios demasiado restringidos para los aviones comunes.

En la actualidad los límites del vuelo a vela se han extendido a fronteras inimaginables hace pocos años. Un ejemplo: el alemán Klaus Ohlmann superó la barrera de los 3000 km en el año 2003 (un solo vuelo, de día, sin motor) con un vuelo de distancia libre usando tres puntos de viraje, en un Schempp-Hirth Nimbus 4DM. El vuelo se realizó partiendo de Chapelco, Argentina, y volando fundamentalmente en onda. Se considera el límite práctico de la tecnología actual.




</doc>
<doc id="15289" url="https://es.wikipedia.org/wiki?curid=15289" title="Xylopia">
Xylopia

Xylopia es un género de plantas de la familia de las annonáceas, orden Magnoliales, subclase Magnólidas, subdivisión Magnoliophytina, división Spermatophyta.
Son arbustos o árboles con hojas cartáceas a subcoriáceas, el nervio principal plano o impreso en el haz; pecíolos canaliculados. Flores solitarias o inflorescencias de pocas flores, axilares o dispuestas en las ramas viejas; sépalos valvados, connados solamente en la base o fusionados en una cúpula; pétalos 6, valvados, subiguales, carnosos, lineares a ovados; estambres numerosos, anteras con conectivos ensanchados, discoides o alargados; carpelos pocos a numerosos, ovarios incluidos en el androceo, óvulos 2–10. Fruto un fascículo de monocarpos cortamente estipitados, cilíndricos a subglobosos o claviformes, dehiscentes por medio de una sutura opuesta a la sutura carpelar; semillas negras con arilo blanco.
El género fue descrito por Carlos Linneo y publicado en "Systema Naturae, Editio Decima" 2: 1241, 1250, 1378. 1759. La especie tipo es: "Xylopia muricata" L. 



</doc>
<doc id="15290" url="https://es.wikipedia.org/wiki?curid=15290" title="Xanthophyceae">
Xanthophyceae

Xanthophyceae, Xanthophyta o algas verde-amarillas es un pequeño grupo de algas pertenecientes al filo Heterokontophyta, fundamentalmente de aguas continentales y suelo, aunque algunas especies son marinas. Los pigmentos de los cloroplastos les dan su característico color verde-amarillento. El grupo comprende unas 600 especies, algunas de las cuales son unicelulares, pero otras se agrupan en colonias.

Algunas algas verde-amarillas se presentan en formas unicelulares, a veces flageladas, aunque tienden a agruparse en colonias de filamentos simples o ramificados, también pueden aparecer estados palmeloide. No forman colonias móviles, pero pueden aparecer gametos o zoosporas flagelados. Las células son uninucleadas, si bien existen formas cenocíticas.

Las células presentan flagelos heterocontos, el más largo es mastigonemado o pleuronemático, con mastigonemas en dos filas. La pared celular es de celulosa o de pectina, en algunos géneros está formada por piezas en forma de H que encajan unas en otras.

Los cloroplastos suelen ser discoidales y presentarse en posición parietal. Presentan DNA dispuesto en forma de anillos, El número presente de membranas en el cloroplasto es de 4 originada por una segunda endosimbiósis entre dos microorganismos Eucariontes uno heterótrofo y el otro autótrofo. Almacenan lípidos y crisolaminarina (leucosina) como nutriendo de reserva, también pueden almacenar manitol y otros polisacáridos, nunca presentan almidón. Presentan clorofilas "a" y "c", β-caroteno, xantofilas, diadinoxantina (verde amarillenta), vaucherioxantina, nunca presentan fucoxantina. Los tilacoides se agrupan de tres en tres, en "Tribonema" hay una lamela periférica ceñidora, pero puede estar ausente en otros géneros. El cloroplasto puede incluir un pirenoide. 

La reproducción es por división celular y por fragmentación. Las esporas son móviles o inmóviles y algunas zoosporas son pluriflageladas. Pueden aparecer planosporas (zoosporas) o aplanosporas. La reproducción sexual solo se conoce en algunas especies. 





Las xantofitas se dividen en dos órdenes, dependiendo principalmente de las estructuras reproductivas:



A continuación se muestran distintas estructuras de "Vaucheria".


</doc>
<doc id="15292" url="https://es.wikipedia.org/wiki?curid=15292" title="OVA">
OVA

OVA, sigla de , como su nombre lo indica, son producciones animadas destinadas para su consumo en video, donde comenzaba el auge de los reproductores Beta y posteriormente el VHS. Los OVA tienen su origen en los años 80, donde una generación de jóvenes animadores abren sus propias casas productoras "freelance" independientes después de haber trabajado para grandes o medianas empresas productoras de animación para la televisión. Así mismo, estas producciones no estaban atadas a ningún tipo de limitaciones, llámese censura de ningún tipo, y se realizaban con tanta libertad posible para expandir el mercado a sectores maduros, equivalente a las producciones en formato de historietas impresas (manga), que también satisfacía a varios sectores en el mercado. Fuera de Japón se les ha llamado OAV por su correcta pronunciación al inglés "original animation video", sin embargo en Japón se continúa llamando OVA para no llegar a confusiones con las siglas AV de "adult video".

En los comienzos de la década de 1980, cuando los reproductores de video comenzaron a hacerse populares en Japón, la industria del anime creció hasta alcanzar proporciones descomunales, la demanda del anime, como normalmente se abrevia, era masiva, hasta el punto de que los consumidores iban a los videoclubs no para alquilar, sino para comprar las últimas novedades en animación. Lo que resultó en la creación de muchas series con el objetivo de salir directamente en video. En Japón, la demanda era tan grande que se convirtió en una necesidad del mercado. Muchas series populares e influyentes como "Bubblegum Crisis" o "Tenchi Muyō!" salieron a la venta en formato OVA. Aunque el "anime" para su venta directa en un video comenzó a aparecer a finales de los años 1970, la primera serie que indicaba claramente ser un OVA fue "Dallos" (1983), dirigida por Mamoru Oshii y distribuida por Bandai. Otras compañías se sumaron rápidamente a la iniciativa, y a mediados de la década de 1980 el mercado estaba inundado de OVA. Un OVA no se ve atado a las restricciones de un capítulo de televisión, por lo que su duración puede ser la que crean necesaria, aunque generalmente si el OVA es la continuación de una serie, se respetan los tiempos. En un promedio general de duración de un OVA se diría que oscilan entre los 45 y los 60 minutos. 

Durante el auge de este revolucionario formato para video, los jóvenes animadores "freelance" explotaron al máximo su potencial en el campo de la animación, creando producciones originales con una calidad similar a las películas animadas proyectadas en los teatros de cine, y rápidamente acató la atención de los consumidores amantes de la animación en Japón. Los OVA contaban historias en su mayoría, meramente originales, sin llevar el adjetivo de "adaptación" de algún manga antes publicado. Esa fue su ventaja competitiva en aquel entonces, sumando la excelsa calidad visual y frescura con la que contaban. Esto conlleva a que las grandes empresas de la animación nipona subcontrataran a estos animadores independientes para grandes proyectos televisivos y ganar mayores oportunidades y fama en el medio. Es aquí donde la animación comercial expande de igual manera sus productos animados en el vasto mercado. Muchas de estas producciones animadas de formato OVA o formato TV llamaron la atención de países extranjeros como Francia y los Estados Unidos, que rápidamente compraban las licencias para difundirlas en sus respectivas naciones. Animadores de renombre obtuvieron la oportunidad de trabajar en proyectos extranjeros en esa misma década. 

La tendencia de producir OVA fue tomada por las grandes empresas japonesas para crear especiales para video de series ya populares como la famosa serie "Dragon Ball", basada en el manga de Akira Toriyama, Saint Seiya de Masami Kurumada, Ranma 1/2 de Rumiko Takahashi, y otras series más. Esta tendencia ha perdurado hasta hoy en día. Llevan de igual manera el título "original video animation" por ser historias propias de los estudios de sus respectivas empresas, donde cronológicamente no coinciden con el argumento original del cual se ha basado la serie misma. 

Generalmente en el fandom extranjero, los OVA se confunden con capítulos especiales para la TV, pero esto es incorrecto, ya que dichos capítulos se lanzan en VHS, DVD y actualmente en Blu-Ray de una serie ya transmitida. Salen directamente a la venta, y es posible adquirir una licencia para transmitirlo por televisión, una vez pasado cierto tiempo, como en una película transmitida en cine, y, por lo general, las OVA tienen una calidad superior a una serie realizada para ese medio. Debido a la popularidad del "anime", las OVA pueden encontrarse en cualquier tienda sobre el tema. Generalmente salen a la venta ni bien es terminada, y producir un capítulo de 20 minutos (que es lo más normal) toma varios meses (por lo general tres, dependiendo de la calidad de animación y otros factores), por eso es normal esperar varios meses antes de poder seguir la historia, aunque existen algunos casos en que se hace de manera tal que la espera sea prácticamente de un mes, dando así tiempo a que la gente disfrute de una OVA antes de adquirir otra.

Tras el deterioro de la economía japonesa, a mediados de los años 1990, la salida de OVA al mercado comenzó a escasear. El hecho de que las series se empezaran a crear de 13 episodios, en lugar del estándar de 26, facilitó su comercialización, lo que restó popularidad a las OVA. Probablemente la serie de OVA más larga de la historia sea "Legend of the Galactic Heroes", contando con 110 episodios, 52 episodios de historias secundarias y 3 películas. Por último, los OVA también se usan actualmente como un medidor del impacto que tiene entre el público, con el fin de determinar su viabilidad para que una programadora haga una serie animada con su temática. Aunque en 1999 las OVA seguían siendo utilizadas como por ejemplo en la franquicia "Digimon".

Actualmente en Japón no solo se producen OVA, sino también ONA ("original net animation") que se conciben para estrenarse dentro de Internet. Estas producciones de nueva generación pueden ser vistas por los cibernautas en páginas especializadas en video, como el popular NicoNico Douga, que para acceder al evento, hay que adquirir una cuenta premium, de pago. 


</doc>
<doc id="15295" url="https://es.wikipedia.org/wiki?curid=15295" title="Ático">
Ático

El término ático puede referirse:


</doc>
<doc id="15296" url="https://es.wikipedia.org/wiki?curid=15296" title="Sueño paradójico">
Sueño paradójico

Fase del sueño en la que los ojos se mueven rápidamente; por eso también se llama sueño REM (Rapid Eye Movement). Es el momento en que el individuo está más relajado, aunque es relativamente fácil despertarlo, de ahí su nombre de paradójico. Empieza aproximadamente una hora y media después de haberse dormido. Sus características son: respiración rápida y superficial, discreta aceleración del ritmo cardiaco, excitación sexual (en ocasiones una polución nocturna) y fenómeno de ensoñación.

Durante el sueño REM el trazado electroencefalográfico se asemeja al que registramos en vigilia. La supresión selectiva de esta fase, en animales de experimentación, termina provocando graves trastornos de conducta, y agresividad.

La hipótesis de que el sueño participa en la consolidación de la memoria reciente ha sido investigada mediante cuatro paradigmas: 


Estos estudios confirman convincentemente la idea de que el sueño está profundamente implicado en las funciones de la memoria en humanos y animales. Sin embargo, los datos disponibles aún son demasiado escasos para confirmar o rechazar inequívocamente la recientemente expuesta hipótesis de que la consolidación de memorias no-declarativa y declarativa respectivamente dependan de los procesos de sueño REM y NREM.


</doc>
<doc id="15299" url="https://es.wikipedia.org/wiki?curid=15299" title="Principios generales del derecho">
Principios generales del derecho

Los principios generales del derecho son los enunciados normativos más generales que, a pesar de no haber sido integrados formalmente en los ordenamientos jurídicos particulares, recogen de manera abstracta el contenido de un grupo de ellos. Son conceptos o proposiciones de naturaleza axiológica o técnica que informan la estructura, la forma de operación y el contenido mismo de las normas, grupos normativos, conjuntos normativos y del propio derecho como totalidad. 

Estos principios son utilizados por los jueces, los legisladores, los creadores de doctrina y por los juristas en general, sea para integrar derechos legales o para interpretar normas jurídicas cuya aplicación resulta dudosa.

Los principios generales del derecho son enunciados normativos que expresan un juicio deontológico acerca de la conducta a seguir en cierta situación o sobre otras normas del ordenamiento jurídico. Cada uno de estos principios, es un criterio que expresa un deber de conducta para los individuos, el principio o un estándar para el resto de las normas. El hacer cumplir los deberes del individuo es su prioridad.

Además se aplica en defecto de la ley y de la costumbre.

Respecto a los principios generales del derecho se ha desarrollado una polémica acerca de si ellos son extraños o externos al derecho positivo, o si son una parte de él.

Según la posición de la escuela del derecho natural racionalista, hoy ya superada, los principios generales, serían principios de un derecho natural entendido como orden jurídico separado del derecho positivo.

Según la doctrina positivista, también ya superada, o al menos en vías de superación en la mayoría de los países, los principios mencionados serían una parte del derecho positivo. Sin embargo, nunca podrían imponer una obligación que no fuera sancionada por el mismo ordenamiento positivo por lo que se entiende que cada ordenamiento positivo tiene sus particulares principios generales y que no existen principios jurídicos de carácter universal.

La posición racionalista escinde el derecho en dos órdenes jurídicos específicos y distintos: el natural y el positivo –el primero conforme a la razón, es decir son normas que emanan de la naturaleza y son de carácter axiólogico, y el segundo, producto de la voluntad del sistema político. 
Otra posición indica que el derecho, producto típicamente humano, es una obra de la inteligencia humana: ella es la que descubre, desarrolla y combina criterios que enuncian un comportamiento entendido como justo; por ello, el derecho también es llamado jurisprudencia, es decir, de lo justo, y la prudencia se entiende como un hábito de la inteligencia. Si bien el derecho, conjunto de criterios, es obra de la inteligencia, su efectivo cumplimiento, el comportarse los hombres de acuerdo a los criterios jurídicos, es obra de la voluntad.

Cada principio tiene su propio ámbito de acción y su propia efectividad, lo cual no afecta la contribución de todos al fin común de un orden interamericano justo, democrático y estable. 

Los principios generales del derecho tienen tres funciones que tienen incidencia importante en las normas del ordenamiento, estas son: la función creativa, la función interpretativa, y la función integradora.


Los principios generales del derecho internacional público sirven no solo para guiar el ordenamiento sino también para situaciones donde no esté regulado, los principios como la costumbre sirven para guiar a dos países en guerra

El Art 38 del estatuto de la corte internacional de justicia habla sobre cómo aplicar las convenciones, la costumbre, los principios generales de derecho reconocidos por las naciones civilizadas y decisiones judiciales para la interpretación de las normas.

Principios de equidad, libertad, justicia, fraternidad, igualdad, inocencia, entre otros.

 Exige una conducta recta u honesta en relación con las partes interesadas en un acto, contrato o proceso. Además de poner al bien público sobre el privado dando a entender que se beneficiará las causas públicas sobre la de los gobernadores o sectores privados.

Hace referencia al obrar con honradez, veracidad, lealtad, lo que lleva implícita la creencia de que se está actuando conforme a lo que prescribe el ordenamiento jurídico.

El principio de la buena fe es de suma importancia en materia de interpretación de la ley, de los contratos, de la posesión, de la prescripción, del matrimonio.
Es de carácter absoluto, contemplado en la Convención de Viena de 1969 sobre el Derecho de los Tratados. En su artículo 26 dice taxativamente: “todo tratado en vigor obliga a las partes y debe ser cumplido por ellos de buena fe”

Se define como unión de intereses o propósitos entre los países, y la cohesión social entre ellos, basada en la dependencia de los Estados

La ayuda humanitaria es una forma de solidaridad o cooperación, que generalmente es destinada a las poblaciones pobres, o a las que han sufrido una crisis humanitaria, como la provocada por una catástrofe natural o una guerra. Debe seguir los Principios humanitarios de imparcialidad, neutralidad, humanidad e independencia operacional.


El no intervencionismo es la doctrina en política exterior que indica la obligación de los Estados de abstenerse o intervenir, directa o indirectamente, en los asuntos internos de otro Estado con la intención de afectar su voluntad y obtener su subordinación.

El artículo 38.1.c del Estatuto de la Corte Internacional de Justicia considera a los principios generales del derecho una fuente formal del derecho internacional, al lado de la costumbre internacional y los tratados internacionales, por lo cual el tribunal estaría obligado a aplicarlos sin necesidad de que exista una laguna en cuanto al alcance de estas dos últimas fuentes; es decir, opera como fuente autónoma y no subsidiaria.

El antiguo Código Civil de la Nación Argentina, redactado por Dalmacio Vélez Sarsfield, consagraba -desde 1871- en su artículo 16, el siguiente enunciado: "Si una cuestión civil no puede resolverse, ni por las palabras, ni por el espíritu de la ley, se atenderá a los principios de leyes análogas; y si aún la cuestión fuere dudosa, se resolverá por los principios generales del derecho, teniendo en consideración las circunstancias del caso".
Buena parte de la doctrina iusfilosófica nacional ha entendido a este enunciado como una manifestación de la negación de las lagunas jurídicas en el derecho argentino, mientras que otros doctrinarios lo ven como una pauta dirigida al juez en casos concretos en los cuales no haya ley que rija el caso, para que llene las lagunas del derecho con base al derecho natural.

La Constitución Política Colombiana de 1991, en su artículo 230, enseña que los principios generales del derecho son criterios auxiliares en caso de insuficiencia de la ley, es decir, en caso de oscuridad o vacíos normativos, posición antiformalista que influye en la jurisprudencia colombiana desde 1936 –época de la "Corte de Oro"– en una nueva interpretación del artículo 8 de la Ley 153 de 1887, la cual, desde un punto de vista eminentemente influido por la escuela de la libre investigación científica y el conceptualismo alemán, acogió la equidad y los demás principios generales del derecho como punta de lanza para la solución justa de los conflictos jurídicos.

Según el artículo 1.1 del Código Civil, las fuentes del ordenamiento jurídico son la ley, la costumbre y los principios generales del derecho. Y en su artículo 1.4 enuncia: "Los principios generales del derecho se aplicarán en defecto de ley o costumbre, sin perjuicio de su carácter informador del ordenamiento jurídico".

En el derecho mexicano, el artículo 14 de la Constitución política vigente señala que los juicios de orden civil deberán fallarse conforme a la letra o a la interpretación de la ley, y a falta de la misma, se fundará en los "principios generales del derecho". Este reenvío, según Rafael Preciado Hernández, vincula el derecho mexicano a la mejor tradición iusnaturalista de la civilización occidental. También en la Ley Federal del Trabajo en su artículo 17, se hace un reenvío a los principios generales del derecho y a la equidad, que es uno de ellos. De igual forma, también se establecen en el Código Civil Federal, el Código de Comercio, la Ley General de Instituciones y Procedimientos Electorales, la Ley General de Salud, la Ley General de Educación, y, en prácticamente todos los ordenamientos de carácter federal y local, sean sustantivos o adjetivos.




</doc>
<doc id="15300" url="https://es.wikipedia.org/wiki?curid=15300" title="NTFS">
NTFS

NTFS (siglas en inglés de "New Technology File System") es un sistema de archivos de Windows NT incluido en las versiones de Windows NT 3.1, Windows NT 3.5, Windows NT 3.51, Windows NT 4.0, Windows 2000, Windows XP, Windows Server 2003, Windows Server 2008, Windows Vista, Windows 7, Windows 8 y Windows 10. Está basado en el sistema de archivos HPFS de IBM/Microsoft usado en el sistema operativo OS/2, y también tiene ciertas influencias del formato de archivos HFS diseñado por Apple.

NTFS permite definir el tamaño del clúster a partir de 512 bytes (tamaño mínimo de un sector) de forma independiente al tamaño de la partición. 

Es un sistema adecuado para las particiones de gran tamaño requeridas en estaciones de trabajo de alto rendimiento y servidores. Puede manejar volúmenes de, teóricamente, hasta 2–1 clústeres. En la práctica, el máximo volumen NTFS soportado es de 2–1 clústeres (aproximadamente 16 TiB usando clústeres de 4 KiB).

Su principal inconveniente es que necesita para sí mismo una buena cantidad de espacio en disco duro, por lo que no es recomendable su uso en discos con menos de 400 MiB libres..

El tamaño mínimo recomendado para la partición es de 10 GiB (10240MiB). Aunque son posibles tamaños
mayores, el máximo recomendado en la práctica para cada volumen es de 2 TiB (Tebibytes). 
El tamaño máximo de fichero viene limitado por el tamaño del volumen. Tiene soporte para 
archivos dispersos.

Hay tres versiones de NTFS: v1.2 en NT 3.51, NT 4, v3.0 en Windows 2000 y v3.1 en 
Windows XP, Windows Server 2003, Windows Vista y v5.1 en Windows Server 2008. 
Estas versiones reciben en ocasiones las denominaciones v4.0, v5.0, v5.1, v 5.2, y 
v6.0 en relación con la versión de Windows en la que fueron incluidas. Las versiones 
más recientes han incluido algunas características nuevas, tales como cuotas de disco 
y puntos de montaje de volúmenes.


El número de versión NTFS.sys (por ejemplo, v5.0 en Windows 2000) no se debe confundir con el número de versión en formato NTFS (v3.1, solo Windows XP).

Todo lo que tiene que ver con los ficheros se almacena en forma de metadatos. Esto permitió una fácil ampliación de características durante el desarrollo de Windows NT. Un ejemplo lo hallamos en la inclusión de campos de indizado añadidos para posibilitar el funcionamiento de Active Directory.

Los nombres de archivo son almacenados en Unicode (UTF-16), y la estructura de ficheros en árboles-B, una estructura de datos compleja que acelera el acceso a los ficheros y reduce la fragmentación, que era lo más criticado del sistema FAT.

Se emplea un registro transaccional (journal) para garantizar la integridad del sistema de ficheros (pero no la de cada archivo). Los sistemas que emplean NTFS han demostrado tener una estabilidad mejorada, que resultaba un requisito ineludible considerando la naturaleza inestable de las versiones más antiguas de Windows NT.

Sin embargo, a pesar de lo descrito anteriormente, este sistema de archivos posee un funcionamiento prácticamente secreto, ya que Microsoft no ha liberado su código, como hizo con FAT.

Gracias a la ingeniería inversa, aplicada sobre el sistema de archivos, se desarrollaron controladores como el NTFS-3G que actualmente proveen a sistemas operativos GNU/Linux, Solaris, MacOS X o BSD, entre otros, de soporte completo de lectura y escritura en particiones NTFS.

Microsoft provee medios para convertir particiones FAT32 a NTFS, pero no en sentido contrario, (NTFS a FAT32). Partition Magic de Symantec y el proyecto de código abierto NTFSResize son ambos capaces de redimensionar particiones NTFS.

Con la herramienta "convert" incluida en los sistemas NT (Windows NT en adelante), se puede cambiar un disco con sistema de ficheros FAT32 a NTFS sin perder ningún dato con la instrucción "convert [unidad]:/fs:ntfs" 

Por razones históricas, absolutamente todas las versiones de Windows que todavía no soportan NTFS almacenan internamente la fecha y hora como hora local, y consecuentemente los sistemas de ficheros correspondientes a esas versiones de Windows, también tratan la hora localmente. Sin embargo, Windows NT y sus sucesores almacenan la hora en formato GMT/UTC, y hacen las conversiones apropiadas en el momento de mostrar las fechas. De este modo, al copiar archivos entre un volumen NTFS y uno no NTFS, deben hacerse las conversiones "al vuelo", lo que puede originar ambigüedades si el horario de verano está activo en la copia de unos archivos y no en el de otros, pudiendo dar lugar a ficheros cuya marca de hora esté una hora desplazada.

MacOS X provee soporte de sólo lectura a particiones formateadas como NTFS. NTFS-3G es una utilidad de licencia GPL que permite lectura y escritura en particiones NTFS. Los desarrolladores de NTFS-3G también proveen una versión comercial y de alto rendimiento denominada Tuxera NTFS para Mac.

En español:

En inglés:


</doc>
<doc id="15302" url="https://es.wikipedia.org/wiki?curid=15302" title="Sorghum halepense">
Sorghum halepense

El sorgo de Alepo (Sorghum halepense) es una cereal producto de una hibridación de introgresión con otra especie del género "Sorghum" ("Sorghum bicolor") en la familia Poaceae.

El origen del sorgo se localiza en África central (Etiopía o Sudán), pues es en esta zona donde se encuentra la mayor diversidad varietal de la especie. Esta diversidad disminuye hacia el norte de África y Asia. Existen, sin embargo, ciertas evidencias de que surgió de forma independiente tanto en África como en la India. Es precisamente en este último país de donde datan en el siglo I d.C. las primeras referencias escritas. También se encuentran en Siria esculturas que tratan el desarrollo de dicha especie.

No se sabe exactamente cuándo se introdujo la planta por primera vez en América, aunque se asume que las semillas de esta especie llegaron al Nuevo Continente en barcos que transportaban esclavos desde África. Ingresó en Estados Unidos procedente de Turquía hacia 1830. El primer informe escrito de su presencia en México es de 1913, aunque para esa fecha había llegado hasta Yucatán y era una importante maleza en Nuevo León (Alcaraz, 1913).

El nombre científico, "Shorgum halepensis" (L.) Pers. hace referencia a la ciudad de Haleb (Aleppo) en Siria.
Recibe varios nombres comunes: cañota, hierba johnson, pasto johnson, sorguillo, canuto, pasto ruso, paja johnson, zacate johnson, pasto silvestre, sorgo silvestre, sorgo de Alepo.





Se considera que esta maleza es autógama pero no completa, exhibiendo un 6 a 8 % de alogamia. La dispersión de las semillas puede producirse a través de distintos agentes, como es el agua de irrigación (en los sistemas bajo riego) y también por escorrentía superficial en campos con pendiente en los sistemas de producción de secano. Los herbívoros que consumen esta maleza eliminan las semillas a través de las heces, con diferente nivel de dormición, sin pérdida de viabilidad. Probablemente las aves puedan dispersar a gran distancia esta maleza.

Las dos fuentes principales de dispersión secundaria son los granos o semillas para la siembra contaminadas con esta maleza y el equipo de cosecha: muchas semillas pueden ser transportadas largas distancias desde el sitio original en los distintos enseres del equipo de cosecha (sinfines, volquetes, carros tolvas y vehículos complementarios), los que pueden incluso alojar semillas en la banda de rodamiento de sus neumáticos.

Las semillas recién dispersadas exhiben elevada viabilidad (superior al 85 %) y un alto grado de dormición. En el suelo se suelen encontrar fracciones o subpoblaciones de semillas con diferente nivel de este efecto y diferentes requerimientos para su activación. Este complejo mecanismo evolutivo permite a las semillas no sólo detectar la existencia de canopeos, sino también medir la profundidad a la que se encuentran, lo cual está muy relacionado con sus probabilidades de éxito tras la emergencia.

Los rizomas constituyen un mecanismo de propagación muy eficaz y -desde el punto de vista evolutivo- constituyen uno de los pilares de la persistencia de esta mala hierba en una gran variedad de agroecosistemas y amplias latitudes, desde que replican genotipos resistentes y adaptados. Los rizomas constituyen, en promedio, el 30 % de la biomasa total que acumula una planta durante todo su ciclo.

Si se realiza una estimación periódica de la biomasa de rizomas durante todo el año, se obtiene una función de tipo sinusoidal, la cual exhibe valores máximos hacia el fin del verano e inicios del otoño y valores mínimos hacia el fin del invierno e inicios de la primavera. Tanto el consumo de sustrato por respiración durante el invierno, como la removilización de reservas para sustentar el crecimiento de estructuras aéreas (macollas) caracterizan el segmento decreciente de la biomasa de rizomas. Los procesos involucrados en el segmento creciente comprenden a la formación de fotoasimilados y su transporte hacia el sistema subterráneo, con una tasa de acumulación elevada. Durante la etapa de acumulación de biomasa subterránea las concentraciones de los carbohidratos aumentan.

Es importante recalcar que la fracción decreciente se reinicia toda vez que el sistema aéreo se destruye; como consecuencia de la perturbación del sistema de macollas por bajas temperaturas invernales (heladas), a causa de un control mecánico durante la primavera o el verano, por la acción de herbicidas de contacto o por una pobre actividad de un herbicida sistémico.

Aunque muestra marcada preferencia por los climas cálidos, aparece igualmente en zonas más frías. De hecho, tras ser introducida en el sur de Estados Unidos de América como forrajera y comprobarse su proceso de naturalización se pensó que sólo afectaría a las regiones de clima templado-cálido, constatándose posteriormente su capacidad para colonizar áreas mucho más frías y extenderse hacia latitudes mucho más septentrionales, llegando actualmente al límite con Canadá. En España aparece tanto en estaciones ruderales como en campos de cultivo, especialmente en los viñedos, cultivos de cítricos, arrozales, campos de remolacha y de maíz, así como en cursos de agua (acequias, canales, etc.). 

a) Temperatura: en general se sabe que el desarrollo de las plantas del pasto Johnson, tanto para el crecimiento y desarrollo de la parte aérea como para el de raíces y rizomas, es óptimo a 32 °C.

Para la formación de rizomas existe un límite mínimo de 15 a 20 °C y un límite máximo de 40 °C. Para la germinación de las yemas de los rizomas el máximo es de 39, con un óptimo de 28-30 °C y un mínimo de 15 °C. Se sabe que la temperatura máxima que soportan los rizomas es de 50 a 60 °C por espacio de 3 días, cuando se localizan a 2.5 cm de profundidad en el suelo. Su tolerancia a las bajas temperaturas aumenta con la profundidad a la que se encuentran enterrados los rizomas y bajas temperaturas edáficas limitan la expansión de la especie, mientras que la floración está regulada por la temperatura y no por los factores nutricionales.

Se necesita una temperatura sostenida de -9 °C para causar la muerte de los rizomas de esta especie, sobreviviendo al frío si se localizan a 20 cm o más de profundidad en el suelo. Respecto a la germinación de semillas, esta es nula a 10-15 °C, siendo su óptimo de 39 °C.

b) Luz: se ha podido demostrar que el sorgo tiene un desarrollo óptimo con un fotoperíodo de alrededor de 12 a 13 horas. Para un fotoperíodo de 12 horas, el crecimiento de esta gramínea es óptimo a 27 °C, pese a que en las etapas iniciales el crecimiento sea óptimo a 32 °C.

En otro estudio se encontró que mediante la interrupción del periodo oscuro de 8 h, las plantas de sorgo no florecen y su producción de rizomas disminuye grandemente, sin afectar la producción de raíces, proponiendo esta estrategia como un posible medio para evitar la diseminación de la especie.

c) Profundidad y tipo de suelo: prefiere suelos profundos, sin exceso de sales, con buen drenaje, sin capas endurecidas, de buena fertilidad y un pH que varía de ligeramente ácido a alcalino.

Existen diferencias en cuanto a la producción y distribución de los rizomas de acuerdo a la textura del suelo, en un suelo franco-arenoso, la producción de rizomas fue casi el doble que en un suelo arcilloso. En un suelo franco-arcilloso-limoso la producción de rizomas fue 10% menor que en el anterior. Además se encontró que un suelo arcilloso el 80% de los rizomas se localizan en los 7.5 cm de la superficie del suelo, contrastando con el mismo estrato en un suelo franco-arenoso, siendo la emergencia de rizomas mayor en este tipo de suelos que en un suelo arcilloso.

d) Agua: Requerimiento en el ciclo:
Es fundamental que el suelo tenga una adecuada humedad en el momento de la germinación para que se dé una emergencia rápida y homogénea. Las mayores exigencias en agua comienzan unos 30 días después de emergencia y continúan hasta el llenado de los granos, siendo las etapas más críticas las de panojamiento y floración.

Con frecuencia, en una campaña se cosechan dos o tres cortes de heno; es un pasto valioso, pero las plantas jóvenes pueden contener cantidades notables de HCN, y por lo tanto debe pastarse con prudencia.

Leyenda: MS (Materia seca), PC (Proteína bruta), Cen. (cenizas), EE (extracto etéreo), ELN (extracto libre de nitrógeno), FB (fibra bruta), Ref. (Referencia)

A pesar de ser un buen forraje, como se ha mencionado presenta el inconveniente de tener un glucósido cianogénico tóxico llamado "dhurrina" que se incrementa en condiciones de sequía, helada, alto contenido de nitrógeno y bajo contenido de fósforo en el suelo, además de ser más común en plantas jóvenes. Los casos de envenenamiento son más frecuentes en ganado vacuno y se pueden evitar mediante el ensilaje, proceso en el cual la dhurrina es inactivada. Los animales afectados por su consumo en fresco presentan dolores de abdomen. Las aves pueden consumirla sin que les produzca efectos adversos.

El sorgo de Alepo es una de las 10 malas hierbas más dañinas a la agricultura mundial, ocupando esta el sexto lugar, localizándose en áreas templadas, subtropicales y tropicales del sur de Estados Unidos, México, centro y Sudamérica, zona mediterránea de Europa, África, India y Australia.

Las plantas que cuentan con este tipo de asimilación toleran altas intensidades lumínicas, altas temperaturas, baja concentración de CO y alta concentración de O en la atmósfera sin afectar su proceso fotosintético, además de que no presentan el fenómeno de fotorrespiración por lo que son altamente competitivas.

Estos sorgos son plantas C4, debiendo en gran parte su agresividad a esta cualidad. De esta forma, algunas autores afirman que una ingesta de sorgo de Alepo en maíz reduce 2/3 partes del peso seco del grano, y 60-100 kg/ha de potasio. De la misma manera, las infecciones de esta hierba parásita en maíz reducen el crecimiento y tamaño del cultivo retardando la diferenciación de los órganos vegetativos y reproductivos, y reduce el área de las hojas y el tamaño de las mazorcas, causando esterilidad de muchas flores debido a la competencia entre ambas. El pasto de Johnson puede reducir en más del 45 % los rendimientos de caña de azúcar y soya. 

Actúa como hospedante de un díptero plaga conocido como mosquito del sorgo ("Contarinia sorghicola", "Cecidomyiidae") bastante específico del sorgo cultivado que hiberna en las semillas de la mala hierba, desde donde infecta al cultivo. Se considera también un contaminante del polen del sorgo cultivado y un hospedante del virus del mosaico de la caña de azúcar (de ahí la bajada de rendimiento). Además es hospedera alternante de otras importantes plagas y enfermedades como son: el mildiú velloso ("Aclerospora sorghi") y el antracnosis ("Colletotrichum graminicolum").

Debido a que su presencia se circunscribe a entornos agrícolas es suficiente con considerar las prácticas llevadas a cabo habitualmente en este tipo de medios. Es esencial desarrollar estrategias preventivas que contemplen el uso de semillas o mezclas de éstas (como las empleadas habitualmente en la creación de céspedes forrajeros) y de sustratos absolutamente exentos de propágulos de esta especie.

El arranque manual puede efectuarse por medio de herramientas agrícolas, tales como cultivadoras azadas, arados, rotator y etc. Este tipo de control arranca la hierba a la vez que se remueve el suelo pudiendo beneficiar al cultivo al extraer los rizomas. No obstante, el uso de control mecánico en especies de malas hierbas perennes es limitado debido a que se reproducen vegetativamente. Con el sorgo de Alepo las posibilidades de éxito con este tipo de control son muy limitadas ya que se ha demostrado que una planta proveniente de semilla o rizoma, de más de 20 días de edad, soporta 8 cortes semanales consecutivos sin morir.

En algunos terrenos se acostumbra rastrear los terrenos infestados con esta maleza para exponer sus rizomas al medio y causar su muerte por desecación o daños de heladas. Sin embargo, se ha observado que los rizomas de esta especie soportan una desecación de hasta un 75% de su peso fresco sin perder su viabilidad. Además estos órganos toleran -9 °C sin morir, por lo que este tipo de prácticas no aseguran un buen control de esta maleza y pese aque pueden ser eficientes, se requiere de una cantidad extraordinaria de mano de obra, lo cual se refleja en un mayor coste.

La inundación es una opción viable en algunas zonas. Hasta el momento no se conocen agentes de control biológicos específicos y efectivos.

El estudio de ciertos biotipos de E.E.U.U. exhibe resistencia simple y cruzada a los herbicidas graminicidas tipo ACCASE, además de ALS (imidazolinonas) y dinitroanilinas (trifluralina). 

En países donde aparece como planta parásita de otros cultivos, principalmente soja, se está convirtiendo en los últimos años en un auténtico problema por los altos niveles de resistencia que presenta a herbicidas, y concretamente, a glifosato. En la siguiente publicación argentina de alertas de malezas se puede leer lo siguiente:

El control debe asentarse en el cumplimiento oportuno y sistemático de cuatro objetivos básicos:

a) Destruir la población de yemas existentes en los rizomas.
b) Impedir la formación de nuevos rizomas.
c) Impedir la producción y/o aportes de semillas.
d) Disminuir la población de semillas en el banco, y en los productores de semillas.

Los cuatro objetivos deben enmarcarse en el programa de rotaciones o secuencias de cultivos y sus respectivos barbechos, de manera de optimizar tanto las tácticas de control como la habilidad competitiva de los cultivos. La detección y eliminación temprana de los focos de invasión y la prevención constituyen las mejores inversiones, las que bajo formas y metodologías relativamente sencillas, pueden evitar la diseminación de la maleza en todo el campo.



</doc>
<doc id="15303" url="https://es.wikipedia.org/wiki?curid=15303" title="Stipa clandestina">
Stipa clandestina

Stipa clandestina, conocida como zacate picudo, esparto o hack, es una especie de pasto de la familia "Poaceae".

Es una planta perenne, amacollada, de 30 a 80 cm de altura. Tallos con uno o tres nudos glabros o pubescentes, y entrenudos glabros. Hoja con vaina de 8 a 20 cm de largo, lisa y glabra, verde claro o verde amarillenta, más larga que los entrenudos, abiertas hasta la base con el margen hialino y festoneado al menos en la zona cercana al cuello, donde está abierta en forma de “V” y en ocasiones en pilosa; lígula formada de cerdas de 2 a 3 mm de largo, blanquecina; lámina linear de 2 a 6 dm de largo y 2 a 2,5 mm de ancho, margen revoluto, por lo que su anchura es de 1 mm y con una apariencia de alambre; suave cuando es tierna, dura y punzante cuando es madura; haz escabroso, envés liso. Inflorescencia: panícula de 15 a 35 cm de largo; péndula, sus ejes secundarios flexuosos. Espiguilla unifloscular que se desarticula por encima de las glumas, la articulación es oblicua y deja un cuello barbado en el flósculo; glumas iguales o subiguales de 4 a 7 mm de largo, bordes hialinos, color verdoso o purpúreo que permanece en la inflorescencia después de que se desprende la cariópsis; flósculo tan largo o menores que las glumas, purpúreo, piloso, con una arista de 12 a 18 mm de largo, geniculada y tortuosa. Fruto presente en forma de cariópsis dispersa y envuelta en un flósculo formado por una pálea y un lema retozas, fácilmente desprendibles del cariópse. La lema muestra una arista muy larga, retorcida y frágil, el flósculo es de color verdoso o purpúreo.

Cariópsis de contorno aovado o casi aovado, de forma clavada de 2,1 a 2,7 mm de largo y de 0, a 1,2 mm de ancho, de sección transversal casi circular, aunque en ocasiones aparece como rombo levemente irregular; cara dorsal con una costilla generalmente bifurcada levemente o ensanchada hacia la mitad inferior del fruto; la cara ventral y las laterales generalmente presentan también una costilla en su parte media, pero no está bifurcada y frecuentemente es poco conspicua. Ápice del fruto con una prolongación corta, base del fruto agudo con la cicatriz de inserción a un lado; superficie casi lisa o con verruga escasamente prominente y pequeña, color verde amarillento a amarillento parduzco, con una mancha apical purpúrea presente en ocasiones.

Tiene coleóptilo alargado rasgado, con frecuencia de 3 a 15 mm, hialino, dos nervaduras convergentes conspicuas, del mismo tamaño que la vaina de la primera hoja. Primera hoja con vaina del mismo tamaño que el coleóptilo, lígula formada por cerdas blanquecinas, lámina linear de 7 a 25 mm de largo, frecuentemente incurva cuando se seca, de 0,5 mm de largo, glabra. Segunda hoja también similar, lámina de 8 a 37 mm de largo y 0,5 a 1 mm de ancho, linear, de sección acanalada, ápice segundo, con nervaduras conspicuas. No existe una descripción de las inflorescencias y frutos basales y axilares.

Planta presente en alfalfares de tres años o más donde puede ser muy abundante y difícil de controlar. Además de ruderal y pionera se encuentra en las orillas de los canales. Esta especie se asocia con alfalfares sometidos a cortes, el paso aparece sobre los bordos de las melgas y regaderas, áreas en las cuales el corte no es tan bajo, lo que permite la formación de los macollos y la producción de semillas basales.

La producción de semillas basales o cleistógamas se ha conocido como un fenómeno de polimorfismo somático. Los frutos aéreos son más pequeños y numerosos que los subterráneos y son dispersados por el viento; mientras que los frutos subterráneos nunca abandonan la planta madre muerta, germinando y emergiendo a través de sus tejidos, entonces; los frutos aéreos sirven para la dispersión de la planta hacia nuevos hábitats, mientras que los frutos subterráneos están adaptados para aumentar la supervivencia de la especie en el hábitat ya ocupado. El fenómeno de cleistogamia no es raro entre diversas familias y especie, se describe a "Stipa leucotricha" como una especie que produce abundantes espiguillas cleistógamas básales, bajo ciertas condiciones ambientales, además se consideran a la baja humedad en el suelo como una condición para la inducción a la producción de flores cleistógamas en "G. micranta.

La semilla es la unidad de reproducción sexual por excelencia en las plantas superiores, y es la encargada de propagar la especie y dispersarla espacial y temporalmente. De acuerdo con esto las semillas de plantas, y por supuesto malezas, tiene la habilidad de permanecer en estado de actividad mínima durante largos periodos, la germinación desde el punto de vista fisiológico es el proceso que se inicia con el suministro de agua a la semilla y termina cuando el crecimiento de la plántula se inicia, siendo este momento más comúnmente considerado cuando se da la salida de la radícala a través del tegumento

Existen tres fases fundamentales en el proceso de germinación de las semillas: fase de hidratación o imbibición, la cual consiste en la absorción de agua por los tejidos de la semilla y un aumento considerable en a rasa de respiración de la misma; la fase de germinación, en la que suceden profundos cambios metabólicos, en esta fase se reduce considerablemente la absorción de agua, y la fase de crecimiento, en la que suceden cambios morfológicos evidentes, como la elongación de la radícala, y se caracteriza por el constante aumento en la absorción de agua y de la respiración.

Aun cuando las condiciones ambientales sean adecuadas para la germinación de semillas, muchas de ellas no lo hacen, aunque permanezcan viables. La no-germinación de las semillas, también se conoce como latencia o letargo (Zimdahl, 1993), y está ligada a causas intrínsecas de las semillas o frutos, pero también a efectos ambientales.

El balance en la concentración de O2 y CO2 en la atmósfera del suelo, es importante en la germinación de malezas. En los suelos compactos o con deficiente drenaje, con frecuencia se tienen contenidos de O2 inferiores a los necesarios para la germinación de las semillas. Una de la razón por las que la mayoría de las semillas germinan cerca de la superficie del suelo, es la mayor concentración de oxígeno.

Existen temperaturas por debajo o encima de las cuales una semilla no germina. La temperatura óptima para la germinación de las semillas depende de la especie. Temperaturas muy bajas o muy altas, por consecuencia inducen el letargo.

La latencia es la principal causa de supervivencia de las semillas de malas hierbas en el suelo, por lo que es la razón de la infestación prolongada de los cultivos por la maleza. En los suelos agrícolas, la reserva de semillas puede ser importante, y se puede encontrar hasta 120 millones de semillas (o más) por m³ en el transcurso del siguiente año de cultivo, generalmente más del 10% de este potencial semillero aparece. Esta variabilidad de respuestas germinativas lleva a una heterogeidad de los estados latentes de las semillas que quedan en la superficie del suelo o enterradas haciendo difícil la previsión de las infestaciones en los cultivos. 

La permanencia en la superficie o en el interior de la semilla viable y capaz de germinar es provocada, generalmente, por la inhibición de la germinación y la latencia secundaria, hasta que aparecen las condiciones favorables para el establecimiento de sus plántulas.

Este es el método más frecuente utilizado para aumentar la germinación de las semillas con tegumento duro. Las técnicas de escarificación pueden eliminar parcialmente tegumento o apenas alterarlo para que la germinación suceda. Existe esencialmente dos tipos: la escarificación mecánica y la química.

La escarificación mecánica puede hacerse por medio de un escarificador eléctrico o con cualquier abrasivo que corte, perfore o raspe el tegumento. El método de escarificación química se realiza por inmersión de las semillas en ácido sulfúrico concentrado, por un tiempo el cual depende de cada especie.

Algunos factores que afectan la producción de semillas son:


Todas las "Stipa" se reconocen por tener unas aristas muy largas, en el caso de "Stipa capensis" las aristas tienen entre 5 y 10 cm, y cuando son maduras se enrollan entre ellas quedando completamente enmarañadas (esta especie también se la ha llamado "Stipa retorta" ). Es una gramínea que forma prados relativamente densos, pero nunca se levanta mucho del suelo; siempre se encuentra en zonas bastante secas y abiertas.
"Stipa clandestina" fue descrita por Eduard Hackel y publicado en "Repertorium Specierum Novarum Regni Vegetabilis" 8: 516. 1910. 
Stipa: nombre genérico que deriva del griego "stupe" (estopa, estopa) o "stuppeion" (fibra), aludiendo a las aristas plumosas de las especies euroasiáticas, o (más probablemente) a la fibra obtenida de pastos de esparto.

clandestina: epíteto latíno que significa "oculta".


</doc>
<doc id="15304" url="https://es.wikipedia.org/wiki?curid=15304" title="Lengua construida">
Lengua construida

Una lengua construida, también llamada idioma artificial, ideolengua o conlang, es un idioma que ha sido total o parcialmente construido, planeado o diseñado por seres humanos a partir del estudio de las lenguas naturales —los lenguajes de programación son lenguajes formales y no son considerados ideolenguas porque no son idiomas; tampoco se considera ideolengua a la evolución histórica y, por lo tanto, no planeada conscientemente de cualquier lengua natural—.

Las motivaciones que impulsan el surgimiento de estas lenguas no naturales son básicamente dos:

El término español ideolengua fue propuesto por Alex Condori en 2000 para traducir el término "conlang" (Constructed Language) y ha tenido cierta extensión en la red desde entonces.

La mayor parte de las lenguas construidas pueden dividirse en tres grupos:

Una clasificación más detallada incluye varios factores, tales como su intención de uso, su propósito de creación y el origen del vocabulario y la gramática.

Las lenguas construidas pueden dividirse en dos grandes grupos según su intención de uso: lenguas auxiliares y lenguas artísticas. Las primeras buscan ser un medio de comunicación real entre seres humanos, mientras que las segundas son habladas por personajes ficticios surgidos de la imaginación u obra del autor de la lengua, sin pretender que sean habladas por personas reales.

Estos propósitos pueden subdividirse:

Inventar una lengua puede tener propósitos utilitarios o creativos. Entre los propósitos utilitarios se encuentran el propósito de la comunicación universal, la exploración de formas de comunicación, lenguajes secretos, la ambientación de un escenario de ficción, etc. Entre los propósitos creativos, aquellos inmersos dentro de una creación mayor (p.ej. las lenguas de la Tierra Media como el quenya, de J. R. R. Tolkien) o aquellos que existen "per se".

Otro buen número de lenguas ficcionales han sido creadas por lingüistas aficionados, lo cual ha servido tanto de entretenimiento como una manera de comprender ciertos aspectos de la teoría lingüística.

Si bien las lenguas auxiliares suelen tener un propósito utilitario y los idiomas ficticios acostumbran tener un propósito creativo, esta relación dista de ser unívoca, pues una lengua auxiliar puede provenir de la intención creativa del autor.

Una diferencia entre el idioma klingon, creado por Marc Okrand para el universo de Star Trek, y el sindarin, creado por J. R. R. Tolkien para el universo de la Tierra Media, es que el primero tiene un propósito utilitario, ya que los productores querían una lengua original y diferente para los klingons, mientras que Tolkien inventó sus lenguas, características de la Tierra Media, para ambientar sus lenguajes, tal como lo describe en su carta "El vicio secreto". Esto no demerita la posible calidad artística de la obra de Okrand ni minimiza la creatividad que desarrolló en su creación.

En Eurovisión, se ha llegado a usar tres veces un idioma artificial. Dos veces, los usó Bélgica (en 2003 y 2008) aunque de distinto «idioma», nunca teniendo un vocabulario desarrollado y sólo usado en la canción, poniendo en duda algún significado concreto o traducción a algún idioma. Lo mismo sucedió con los Países Bajos en 2006.

Las lenguas auxiliares parten de un problema, el cual puede resolverse mediante un idioma diseñado para ese propósito, mientras que los idiomas ficticios surgen de la inquietud de su creador.

Las lenguas artificiales suelen dividirse en dos tipos de según el origen de su vocabulario o su gramática: a priori y a posteriori. Una lengua a priori es aquella cuya gramática y/o vocabulario son creados o inventados sin referencia a alguna lengua natural. Una lengua a posteriori es aquella en la cual su gramática y su vocabulario se derivan de una o varias lenguas existentes.

El lojban es una lengua con gramática y vocabulario a priori, pues si bien sus morfemas básicos proceden de elementos comunes o combinados de los cinco idiomas más hablados (chino, inglés, español, hindi y árabe), estos son reconstruidos según las normas fonéticas y gramaticales que se prescriben. Esto, junto con el hecho de que su gramática busca parecerse a la lógica simbólica, es completamente apriorístico.

La Lengua universal de Sotos Ochando también son idiomas a priori, y diversos intentos de lenguas filosóficas como los de John Wilkins ("Essay towards a Real Character, and a Philosophical Language", 1668) y George Dalgarno ("Ars Signorum", 1661).

Las lenguas a posteriori se pueden clasificar en esquemáticas y naturalistas. Esquemáticas son las que toman los elementos básicos de la lengua desde las lenguas naturales y son regularizados según un esquema predeterminado. Son naturalistas cuando tratan de no ser muy diferentes a las lenguas naturales, sobre todo en su vocabulario, sino algo similar para facilitar su entendimiento rápido, aún sacrificando en parte la regularidad.

El proceso de selección de vocabulario puede ser más o menos sistemático. La interlingua de IALA utiliza un proceso sistemático de selección basado en cuatro lenguas básicas y dos lenguas de control. Es adoptada toda palabra común a por lo menos tres de los idiomas básicos: español, francés, inglés e italiano y si sólo es común a dos de estos idiomas, toma el alemán y el ruso como control para decidir qué palabra adoptar.

El esperanto es también una lengua a posteriori a pesar de no tener un sistema mecánico para seleccionar el vocabulario y de que contiene varios elementos inventados o a priori.

Entre las lenguas ficcionales y ficticias, existen también dos tipos de lenguas a posteriori. 

Del primer grupo es ejemplo Tolkien, quien definió una familia de lenguas partiendo de una lengua madre (a priori) y derivando lenguas hijas utilizando procesos de derivación similares a los naturales. Estas lenguas derivadas son por ello a posteriori. Este proceso de derivación se ha aplicado a lenguas existentes para crear «idiomas del futuro» o lenguas ficcionales, como el brithenig, que sería la lengua que hablarían en el oeste de Inglaterra si el latín hubiera sobrevivido hasta nuestros días.

Ejemplo del otro tipo de lenguas ficcionales a posteriori es el recurso utilizado en La Guerra de las Galaxias, que consiste en usar elementos de gramática y vocabulario de lenguas indígenas poco conocidas, para después combinarlos en formas poco reconocibles.

Un tipo especial de lenguas a posteriori son las lenguas controladas, que son adaptaciones de idiomas naturales buscando una gramática simple y un vocabulario reducido para permitir que más personas, que no sean hablantes nativos del idioma base, puedan con poco estudio leer o escuchar textos en la lengua controlada, como por ejemplo el inglés básico.
Otro ejemplo es el Anglo Rom una lengua recientemente inventada cuyo vocabulario se construye partiendo de las raíces del latín y que se rige por solo 19 reglas.

Las lenguas naturales suelen clasificarse según criterios filogenéticos y tipológicos. 
El primero de estos, el filogenético, no se aplica generalmente a las lenguas artificiales, por tratarse de creaciones humanas deliberadas y no derivar estas lenguas de ningún ancestro o protolengua común, pero en ocasiones las lenguas artificiales se crean muy deliberadamente como evoluciones de un ancestro construido, y en ese caso sí que podría aplicarse el criterio filogenético o método comparativo.

El segundo, el criterio tipológico, por el contrario, siempre es perfectamente aplicable a todas las lenguas artificiales. En ese sentido las lenguas construidas son prácticamente tan variadas como las lenguas naturales, aunque en muchas de ellas han predominado los rasgos tipológicos de las lenguas europeas e indoeuropeas, como sucede en el esperanto, el volapük, el latino sine flexione, etc. Otras ideolenguas de éxito como el klingon uno de cuyos creadores, Marc Okrand, trabajó sobre el idioma mutsun lengua indígena de California de la familia uti, parece tener características reminiscentes de esa lengua indígena.




</doc>
<doc id="15307" url="https://es.wikipedia.org/wiki?curid=15307" title="Alpha">
Alpha

El término Alpha puede referirse a:


</doc>
<doc id="15308" url="https://es.wikipedia.org/wiki?curid=15308" title="Legión Cóndor">
Legión Cóndor

La Legión Cóndor (en alemán: Legion Condor) fue el nombre dado a la fuerza de intervención mayoritariamente aérea que el III Reich envió en ayuda de las fuerzas del general Franco para luchar en la Guerra Civil Española. Adolf Hitler, canciller alemán, a sugerencia del jefe de la Luftwaffe, Hermann Göring, y con la intención de probar el arma aérea alemana en una guerra convencional, ofreció a Franco de forma secreta apoyo aéreo para su ejército terrestre. Esta ayuda consistió en apoyo logístico, transporte de tropas, suministros, tropas, carros de combate (sobre todo Panzer I) y artillería, creándose la primera escuela de carros de combate, bajo el mando del coronel del ejército alemán Wilhelm von Thoma, en el Castillo de las Arguijuelas de Arriba en las cercanías de la ciudad de Cáceres.

La intervención alemana en la Guerra Civil permitió a Hitler mejorar la calidad de sus aparatos y reparar los defectos de su arma aérea, preparándola para la ofensiva mundial que estaba planeando. Un ataque normal podía consistir en un vuelo previo de toma fotográfica. A continuación los bombarderos (unos 80 Junkers y Heinkel alemanes en 1936) eran custodiados por cazas italianos y más aviones de captura fotográfica. La precisión de sus bombas era sorprendente y revela un estudio detallado de los objetivos. Con el tiempo, se demostró como una de las piezas elementales en la victoria de Franco.

El 18 de julio de 1936 estalló una rebelión militar en el Protectorado español de Marruecos, que acabaría degenerando en una auténtica Guerra Civil. Lo cierto es que tanto los sublevados como las fuerzas gubernamentales no eran lo suficientemente fuertes como para vencer al contrario, pero el problema de los sublevados en Marruecos era mucho más grave: La flota se había mantenido fiel al gobierno y controlaba las aguas del Estrecho de Gibraltar con lo que el paso a la península estaba cortado. Se necesitaba del empleo de aviones y el comandante del Ejército de África envió telegramas solicitando ayuda a los únicos líderes internacionales con posibilidad de que respondieran: Adolf Hitler y Benito Mussolini. El dictador italiano accedió al envío de una decena de aparatos de transporte y suministros militares, mientras que Hitler demoró su decisión hasta la intervención del entonces Ministro de Economía de Reich, Hermann Göring. En el Marruecos español se encontraba un importante hombre de negocios, Johannes Bernhardt, y sería él quién bajo sus influencias constituiría la figura en la sombra que tejía la ayuda alemana a Franco. Así, mediante la "Operación fuegos mágicos" ("Unternehmen Feuerzauber") se dio comienzo a los preparativos para la aventura española, en la que el III Reich utilizaría España como un particular campo de tiro. El 24 de julio Bernhardt y Adolf Langenheim, el líder local del NSDAP en el Marruecos español, aterrizaron en el aeropuerto de Berlín-Tempelhof. Rudolf Hess, secretario de Adolf Hitler, organizó una reunión con el "Führer" al día siguiente, en el Festival de Bayreuth, después de una actuación de "Sigfrido" de Richard Wagner.

En la noche del 25 al 26 de julio, en Bayreuth, tuvo lugar la conversación de Hitler con Langenheim y Bernhardt, quienes transmitieron la petición de Franco del envío de aviones de transporte, y finalmente se tomó la decisión fundamental de apoyar al general español. Estaban involucrados en la decisión (además de Hitler) el Ministro del Aire, Göring, y el Ministro de la Guerra, Von Blomberg, quienes también estaban presentes en Bayreuth.

En los primeros momentos de la sublevación militar, Benito Mussolini había aprobado el envío de armas, equipo y pertrechos militares a los militares sublevados contra la República española, ayuda que más tarde aumentaría hasta el envío de un cuerpo de ejército bien equipado, el CTV. Hitler, aunque vaciló más en su decisión, al final lo hizo apoyando el envío de armas y suministros a Franco. Y es que, para Hitler existían una serie de hechos que le servirían en un futuro para su política expansionista y militarista:


Entre finales de julio y principios de septiembre de 1936 hubo distintos envíos de material y técnicos militares como apoyo de los militares sublevados en la guerra, destacando el envío de Junkers Ju 52 para transporte de las tropas africanas y algunos cazas Heinkel He 51 que dieron un momentáneo control de los cielos a los sublevados.

Sin embargo, el contingente de mayor importancia salió el 6 de noviembre de Alemania hacia Sevilla, el núcleo de lo que ya sería conocido como "Legión Cóndor", en una operación que recibió el nombre clave de "Rügen Winter", al mando del general Von Sperrle y con el coronel Von Richtofen como jefe de Estado mayor. El envío contenía aviones, así como artillería antitanque, artillería antiaérea, y varias secciones de carros de combate. En total, el personal de esta primitiva fuerza se elevaba a unos 3 800 hombres, siendo aumentada esa cifra poco tiempo después hasta los 5.000. En algunos aspectos, la Legión Cóndor era una unidad revolucionaria, aunque su equipo y armamento eran todavía muy primitivos; para empezar, sus aviones volaron casi siempre sin radio y las ametralladoras había que cargarlas a mano. Entonces, los bombarderos aún eran Junkers 52 y los cazas Heinkel 51, aparatos que, como se demostraría con posterioridad, eran mucho más pesados y lentos que sus homólogos rusos que ya empezaban a llegar desmontados a los puertos de Cartagena, Alicante y Valencia.

El grupo primitivo se encontraba apoyado por unidades de cañones antiaéreos y antitanques, así por dos unidades blindadas formadas por cuatro compañías, cada una compuesta por cuatro Panzer I. De los equipos antiaéreos, una parte fue adjuntada a las unidades de la "Luftwaffe" como defensa de los aeródromos mientras que la restante quedó como defensa antiaérea de las fuerzas terrestres. Dichas fuerzas se encontraban al mando de von Thoma, luego famoso experto en la guerra de blindados durante la Segunda Guerra Mundial, que en España se distinguiría por el uso de tácticas blindadas luego ampliamente empleadas durante dicha guerra.

A instancias suyas y otros técnicos alemanes acabaría creándose la primera escuela de carros de combate, bajo el mando de Von Thoma, en el Castillo de las Arguijuelas de Arriba en las cercanías de la ciudad de Cáceres. Los tanques Panzer I resultaron totalmente inferiores frente a los T-26 soviéticos, a pesar de que fueron enviados unos 200 tanques en total El propio Von Thoma reconoció en un interrogatorio a los americanos (al final de la Segunda Guerra Mundial) que había participado en unas 192 acciones de carros de combate a lo largo de toda la guerra española. Durante la Ofensiva de Aragón, Von Thoma tuvo que intervenir ante la decisión de Franco de distribuir los tanques al modo militar tradicional. En ese momento el cuerpo blindado que mandaba Thoma, comprendía cuatro batallones, cada uno con tres compañías, de las cuales cada una estaba equipada con 15 tanques ligeros. Este cuerpo iba así mismo acompañado de treinta compañías antitanque, con seis cañones de 37 mm. cada una.

Otra pieza elemental empleada por los equipos militares (eso sí, tanto de tierra como de aire) fue el empleo del cañón Flak 18 de 88 mm, un arma que demostró sus verdaderas capacidades en la guerra de España y que lo haría aún más durante la siguiente guerra.

A las unidades aéreas y terrestres de la primitiva Legión Cóndor se unió después un Grupo del Mar del Norte formado por especialistas en artillería naval, minas y señales, que actuaban desde los acorazados de bolsillo "Deutschland" y "Admiral Scheer". A esta flota se le unirían el crucero ligero Leipzig así como algunos destructores. Así mismo dos submarinos (el "U-33" y el "U-34") salieron para el Mediterráneo para realizar misiones secretas, en realidad para entrenar a las nuevas tripulaciones de submarinos. La presencia de estos buques provocó no pocos incidentes: el U-34 sería el responsable del hundimiento del submarino republicano "C-3" en las costas de Málaga, el 13 de diciembre de 1936.

Por otro lado, en la tarde del 26 de mayo de 1937 fue bombardeado el acorazado de bolsillo "Deutschland" causándole más de una veintena de muertos y graves daños. Al ser informado de los sucesos, Hitler montó en cólera y ordenó el bombardeo de Valencia (entonces capital de la República). Asesorado por sus consejeros militares, decide el bombardeo de la ciudad de Almería. Así pues, el 31 de mayo el acorazado de bolsillo "Admiral Scheer" se presentó junto a 4 destructores frente al puerto andaluz y realizó 200 disparos contra la indefensa ciudad. Los daños tanto materiales como humanos fueron numerosos y Alemania resolvió a retirarse de las patrullas navales del Comité de No intervención, decisión seguida también por Italia.

En el momento clímax de la Batalla de Madrid, hacía el 6 de noviembre salió de Alemania el grueso de las fuerzas de los componentes aéreos de la Legión Cóndor la composición de las fuerzas aéreas "(Luftwaffe)" pertenecientes a la Legión Cóndor, cuya organización y composición era la siguiente:

Legión Cóndor
"Comandante superior": Generalmajor Hugo Sperrle
"Unidades aéreas" (Fuerza de 136 aviones):

Conforme avanzó la guerra, aumentó el número de aviones que componían la Legión Cóndor, pero también aumentó tanto la calidad de sus aparatos como de sus pilotos y técnicos. Después de la derrota de Franco frente a Madrid, los alemanes vieron la necesidad de aumentar los envíos de material y hombres. Ante las perspectivas de una guerra larga, enviaron su mejor armamento para probarlo en el particular "Polígono de tiro español". Al final de la guerra los alemanes habían enviado unos 600 aviones a España, entre los que se contaban 136 aviones Messerschmitt Bf 109, 125 aparatos Heinkel He 51, 93 Heinkel He 111 y 63 Junkers Ju 52. También destacaron 33 aviones Heinkel He 45 y otros 20 aparatos Heinkel He 46, así como 31 aparatos Dornier Do 17 y 5 Junkers Ju 87, el luego famoso "Stuka".


Al inicio de la Batalla de Madrid, llegó el primer contingente importante de tropas y equipo de la primitiva Legión Cóndor. Una vez instalados en bases españolas (la sección de hidroaviones lo hizo en Palma de Mallorca, mientras que el resto de unidades en la Península) las unidades aéreas se dedicaron a bombardeos estratégicos sobre Madrid (iniciados ya por los sublevados, ahora continuados por los alemanes) con una intensidad cada vez mayor. Lo cierto es que los asesores militares alemanes buscaban ver el comportamiento de la población madrileña ante este tipo de bombardeos y su reacción. Las operaciones posteriores al asalto a Madrid (especialmente durante los combates en el Jarama) significaron un fracaso para Franco porque no pudo doblegar la capital pero para la Legión Cóndor supuso todo un campo de aprendizaje en el empleó a gran escala armas modernas en una batalla terrestre que tácticamente no había cambiado mucho desde las de la Primera Guerra Mundial.

Tras la derrota italiana de Guadalajara, las escuadrillas de la Legión Cóndor se trasladarían al frente norte y solo volverían al centro con motivo del Contraataque republicano en Brunete. Aquí las tropas republicanas lograron conseguir un importante éxito inicial pero, como sería habitual en sus ofensivas, ésta se agotó después de unos días. Y al contraataque sublevado se unió la respuesta aérea de la Legión Cóndor, que con la presencia de los nuevos Messerschmitt Bf 109 y los Heinkel He 111 concedió el dominio absoluto del aire a los sublevados, y Brunete fue reconquistado de nuevo. Las pérdidas de la Legión Cóndor fueron mínimas en comparación con el daño infligido a las Aviación republicana.

Madrid resultó un hueso muy duro de roer para Franco, por lo que este puso sus ojos sobre el frente norte, militarmente débil y políticamente desunido. Las escuadrillas alemanas se estaban trasladando hacia el Cantábrico cuando se produjo el bombardeo de Durango, antesala de otro en el que la futura Lutfwaffe sería partícipe.

La "Operación Rügen" —como se llamó en clave el bombardeo de Guernica— el 26 de abril de 1937 fue la primera vez que la acción de la fuerza aérea alemana causó un gran número de víctimas civiles. Se dieron órdenes a los pilotos de bombardear el puente de Rentería y la ciudad vasca de Guernica, poblada por 7.000 habitantes. El puente, que constituía el principal objetivo militar del bombardeo aéreo, se salvó paradójicamente. La operación dio lugar a una mordaz condena internacional. Fue entonces cuando la atención internacional se centró en la participación de la Alemania nazi y la Italia fascista en el conflicto. Hasta entonces, la política alemana de ayuda militar y de personal técnico se había negado públicamente o había sido silenciada. Con el bombardeo fue comunicada públicamente, de conformidad con la posición de neutralidad que había declarado durante la firma del "Pacto de no intervención", aunque ni Francia ni Gran Bretaña hicieron reacciones al respecto.

Con posterioridad, esta destrucción ha recibido amplia cobertura mediática y ha creado una percepción internacional de lo que fue la participación alemana en el conflicto español. El régimen de Franco, ante el rechazo internacional, siempre intentó negar su participación en el bombardeo y acusó al bando republicano de ser el responsable de la destrucción de la villa vasca en clara alusión a lo ocurrido durante la Batalla de Irún el año anterior. Con posterioridad reconoció que el bando republicano no había sido el responsable, aunque advirtió que "solo los oficiales alemanes son responsables del ataque", a pesar de que su personal lo había aprobado, de conformidad con las tácticas de terror de masas empleadas en Bilbao, Madrid y Barcelona. No obstante, nunca ha estado del todo aclarada la participación y el grado de conocimiento que el bando sublevado tuvo respecto a la planificación del ataque. El Gobierno vasco de la época cifró las víctimas del bombardeo en 1.654 muertos y 889 heridos —sin precedentes en bombardeos de objetivos civiles hasta el momento—. La publicación de estas cifras provocó una protesta internacional, que sería la inspiración de la pintura "Guernica" de Pablo Picasso, que desde entonces se ha convertido en icono de los horrores de la guerra. El bombardeo de Guernica muestra, de alguna manera, cómo las fuerzas fascistas del general Franco en España habían llegado a depender en gran medida de la pericia de los pilotos alemanes e italianos, pero también la independencia con que actuaban estas respecto al Bando sublevado.


Johannes Bernhardt era un empresario alemán que antes de la guerra había emigrado de Alemania a España por la Gran Depresión, estableciéndose en el Protectorado español de Marruecos. Allí había hecho grandes negocios en él, extendiendo su red de influencia entre algunos sectores económicos y militares.

La Sociedad Hispano-Marroquí de Transportes (HISMA) fue una empresa fantasma constituida en Tetuán el 31 de julio de 1936, controlada por el Partido Nazi y que tenía como finalidad servir de tapadera al tráfico de armas para el bando franquista durante la Guerra Civil española. Su labor fue fundamental en la operación para transferir una parte del Ejército de África a la península Ibérica. También organizó el primer contingente alemán en el bando franquista. Las ayudas de Hitler a Franco, que recibía a través de HISMA, eran compensadas por medio de exportaciones a través de otra empresa ficticia alemana creada por orden de Hermann Göring, la ROWAK (Rohstoff und Wareneinkaufgesellschaft). Sin embargo, quién verdaderamente controlaba todas las operaciones económicas en España era Johannes Bernhardt.

En 1939, los envíos alemanes se habían realizado en 180 expediciones a lo largo de toda la contienda. Las fuerzas alemanas presentes durante la Guerra Civil Española se elevaron como máximo a unos 10.000 hombres, aunque en el desfile de Berlín de mayo de 1939 participaron unos 14.000 veteranos. Los alemanes que ayudaron a los sublevados probablemente fueron más de 16.000, muchos de los cuales eran personal civil e instructores. Sin embargo, el núcleo de estos era la Legión Cóndor, y ésta siempre estuvo compuesta por un número que no superó los 5000 efectivos. De todo el conjunto, murieron a lo largo de la guerra unos 300 alemanes.

La Cruz española ("Spanienkreuz") fue la condecoración entregada a los veteranos de la "Legión Cóndor" por las autoridades nazis desde el 14 de abril de 1939. Debido a la naturaleza secreta de las actividades alemanas en España durante la guerra, hasta entonces no había sido entregada ninguna condecoración oficial por parte de las autoridades militares alemanas, aunque algunos militares alemanes habían recibido condecoraciones por parte de las autoridades franquistas en agradecimiento a sus servicios durante algunas operaciones militares. Durante el Desfile de la Victoria celebrado el 19 de mayo en Madrid participaron algunos miembros de la "Legión Cóndor", al igual que en la concentración aérea que tuvo lugar en el Aeropuerto de Barajas. Después de abandonar la península a bordo de varios buques (entre ellos, el luego famoso MV Wilhelm Gustloff), tuvieron un gran recibimiento en Alemania, especialmente durante una parada militar el 6 de junio a la que asistió el propio Hitler. Con el comienzo de la Segunda Guerra Mundial, gran parte de los voluntarios que habían luchado en España tuvieron una destacada actuación en la misma, especialmente Richthofen, Sperrle, Von Thoma o Galland. Otros, como Werner Mölders, morirían durante la guerra.

Hasta principios de los 90 no existió en la RFA un activo movimiento de recriminación por las actividades de la "Legión Cóndor" en España y la presencia de ciudadanos alemanes entre los que ejecutaron el Bombardeo de Guernica. En 1997, en el 60º Aniversario de la "Operación Rügen", el entonces Presidente de la República Roman Herzog escribió una carta a los supervivientes del bombardeo donde se disculpaba públicamente en nombre del pueblo y el estado alemanes. Herzog expresó que quería tender "una mano de amistad y reconciliación" en nombre de todos los ciudadanos alemanes. Este sentimiento ha sido después ratificado por miembros del Parlamento alemán que en 1997 aprobaron eliminar a todos los miembros de la "Legión Cóndor" que fueran nombrados en los registros militares alemanes a militares heroicos.




</doc>
<doc id="15309" url="https://es.wikipedia.org/wiki?curid=15309" title="Isaac Asimov">
Isaac Asimov

Isaac Asimov (ˈaɪzək ˈæzəməf; en ruso А́йзек Ази́мов —Áyzek Azímov—, nombre original: Исаáк Ю́дович Ози́мов —Isaak Yúdovich Ozímov— Petróvichi, RSFS de Rusia, -Nueva York, Estados Unidos, 6 de abril de 1992) fue un escritor y profesor de bioquímica en la facultad de medicina de la Universidad de Boston de origen ruso, nacionalizado estadounidense, conocido por ser un prolífico autor de obras de ciencia ficción, historia y divulgación científica. Asimov, así mismo, tenía un dilatado conocimiento sobre las ciencias naturales en todo su conjunto.

La obra más famosa de Asimov es la "Saga de la Fundación", también conocida como "Trilogía o Ciclo de Trántor", que forma parte de la serie del Imperio Galáctico y que más tarde combinó con su otra gran serie sobre los robots. También escribió obras de misterio y fantasía, así como una gran cantidad de textos de no ficción. En total, firmó más de 500 volúmenes y unas 9000 cartas o postales. Sus trabajos han sido publicados en 9 de las 10 categorías del Sistema Dewey de clasificación.

Asimov, junto con Robert A. Heinlein y Arthur C. Clarke, fue considerado en vida como uno de los «tres grandes» escritores de ciencia ficción. 

La mayoría de sus libros de divulgación explican los conceptos científicos siguiendo una línea histórica, retrotrayéndose lo más posible a tiempos en que la ciencia en cuestión se encontraba en una etapa elemental. A menudo brinda la nacionalidad, las fechas de nacimiento y muerte de los científicos que menciona, así como las etimologías de las palabras técnicas.

Asimov fue miembro de Mensa durante mucho tiempo, a cuyos miembros describía como «intelectualmente combativos». Disfrutaba más de la presidencia de la Asociación Humanista Estadounidense, una organización de ideología atea.

En 1981 se nombró a un asteroide, el (5020) Asimov, en su honor.

Se considera que Isaac Asimov nació el 2 de enero de 1920 en Petróvichi, República Socialista Federativa Soviética de Rusia (desde 1929 y hasta ahora Óblast de Smolensk, Federación de Rusia, a 400 km al suroeste de Moscú y a 16 kilómetros de la frontera con Bielorrusia actual).

Sus padres, Judah Asimov y Anna Rachel Berman, de origen judeo-ruso, se trasladaron a Nueva York el 11 de enero de 1923, cuando el autor tenía tres años.

Su infancia transcurrió en el barrio neoyorquino de Brooklyn, donde el joven Isaac aprendió por sí mismo a leer a la edad de cuatro o cinco años; cabe destacar que nunca aprendió ruso. La juventud del futuro escritor transcurrió entre los estudios y el trabajo en las distintas tiendas de golosinas que su padre regentaba en el barrio de Brooklyn. Fue entre esos estantes llenos de revistas donde el joven Asimov se encontró por primera vez con la ciencia ficción. Comenzó a escribir en su adolescencia temprana y, a los 19 años, empezó a publicar sus relatos de ciencia ficción en las revistas de ficción llamadas "pulps".

Tenía tal miedo a volar que solo viajó en avión dos veces en toda su vida, lo que le hizo pensar que podía padecer de acrofobia. Asimismo padecía claustrofilia, lo opuesto de la claustrofobia, es decir, le gustaban los lugares pequeños y cerrados. 

Se graduó como bioquímico en la Universidad de Columbia en 1939. Al ser rechazado para ingresar en las escuelas de medicina de las universidades de Nueva York, regresó a Columbia y decidió hacer un postgrado de química, título que obtuvo en 1941. El siguiente año, 1942, fue particularmente significativo para Asimov; al partir hacia la ciudad de Filadelfia obtuvo un trabajo como investigador químico en los astilleros de la marina de guerra estadounidense, empleo que mantuvo durante el transcurso de la Segunda Guerra Mundial. En 1948 consiguió el doctorado en química, lo que le permitió el acceso a la Universidad de Boston donde permaneció como asociado, pero sin opción a enseñar. La universidad dejó de pagarle el salario en 1958, pero, para entonces, los ingresos procedentes de su trabajo como escritor eran mayores que los que conseguía con su labor universitaria. Asimov permaneció en la facultad como profesor asociado, y en 1979 le ascendieron a profesor titular. Sus documentos personales de los años 1965 en adelante se archivaron en la Biblioteca Mugar Memorial de la Universidad de Boston, donde ocupan 464 cajas en 71 m de estanterías. En 1985 fue elegido Presidente honorario de la Asociación Humanista Estadounidense, cargo que ocupó hasta su muerte en 1992. Su sucesor fue su amigo y colega Kurt Vonnegut. Fue también vicepresidente honorario del club Mensa hasta la muerte de su directora Margot Seitelman el 5 de noviembre de 1989.

Asimov se casó el 26 de julio de 1942 con Gertrude Blugerman, con la que tuvo dos hijos: David y Robyn, nacidos respectivamente en 1951 y 1955. Tras un largo periodo de separación se divorciaron en 1973 y a final de ese año Isaac se casó con Janet Opal Jeppson.

Asimov murió el 6 de abril de 1992 tras un fallo coronario y renal. Le sobrevivieron su viuda Janet y sus hijos habidos en su primer matrimonio. En 2002, Janet reveló en su propia biografía que la muerte de Isaac Asimov fue debida al sida, tras contraer VIH por una transfusión de sangre durante una operación de baipás vascular en 1983.

Isaac Asimov fue un humanista y un racionalista. No se oponía a las convicciones religiosas genuinas de los demás, pero se enfrentó a las supersticiones y a las creencias infundadas. 

Asimov era un progresista en temas políticos y partidario del Partido Demócrata de los Estados Unidos. En una entrevista televisiva a principios de los setenta, respaldó públicamente a George McGovern. Se sintió muy desilusionado cuando vio las tácticas, que él consideraba irracionales, de los activistas progresistas desde finales de los años sesenta en adelante.

Su defensa de las aplicaciones civiles de la energía nuclear, sobre todo tras el accidente nuclear de la Isla de las Tres Millas, dañó sus relaciones con la izquierda. En una carta reimpresa en " Tuyo, Isaac Asimov," afirmaba que: «prefería una casa cerca de una planta de energía nuclear que en una colonia en el Canal del amor o cerca de una planta de isocianato de metilo de la Union Carbide» (referencia al desastre de Bhopal).

Publicó mucho sobre el control de la natalidad, reflejando la perspectiva articulada por Paul R. Ehrlich y en los últimos años de su vida, Asimov condenó el deterioro de la calidad de vida que percibía en la ciudad de Nueva York al reducirse las inversiones por la huida de la clase media a los suburbios. Su último libro de no ficción, "La ira de la Tierra", escrito junto con otro autor de ciencia ficción, Frederik Pohl, trata de aspectos medioambientales como el calentamiento global y la destrucción de la capa de ozono.

La carrera de Asimov puede dividirse en varios períodos. En sus primeros años el tema dominante fue la ciencia ficción, iniciándose con relatos cortos en 1939. En 1950 publicó su primera novela, "Un guijarro en el cielo". Esta etapa duró hasta 1958, terminando con la publicación de "El sol desnudo". Posteriormente disminuyó de manera importante su producción de libros de ficción mientras se dedicaba a otros temas y en los siguientes 25 años publicó solamente cuatro libros de ciencia ficción. A partir de 1982, se inició la segunda etapa de su actividad en la ciencia ficción con la publicación de "Los límites de la Fundación". Desde entonces y hasta su muerte, Asimov publicaría muchas secuelas de sus novelas ya escritas, dándoles un tratamiento de conjunto en una forma que seguramente él mismo no había previsto. Se estima en 429 los libros escritos por Asimov. 

Asimov pensaba que sus contribuciones más duraderas serían las Tres Leyes de la Robótica y la Saga de la Fundación (véase "Yours, Isaac Asimov," p. 329). Más aún, el "Diccionario de inglés de Oxford" le da crédito al introducir las palabras "positrónico," "psicohistoria" y "robótica" en el idioma inglés. La primera de estas palabras se aplica a una tecnología enteramente ficticia, aunque basada en el nombre de la partícula subatómica de antimateria opuesta al electrón, el positrón, mientras que la segunda se utiliza con frecuencia en un sentido diferente al empleado por Asimov; sin embargo, el uso de robótica continúa aplicándose con el sentido dado por Asimov.

Durante los últimos años de la década de los cincuenta y hasta entrada la década de los sesenta, Isaac Asimov redujo sustancialmente su producción de ficción y enfocó sus intereses hacia los ensayos. Entre "El Sol Desnudo" de 1957 y "Los Límites de la Fundación" de 1982, solo publicó cuatro novelas, dos de las cuales fueron de misterio. En este mismo periodo, incrementó en gran medida su producción literaria en otras áreas, escribiendo casi siempre sobre temas científicos. El lanzamiento del Sputnik en 1957 despertó el interés del público sobre la ciencia, interés que los editores de Asimov le pidieron que cubriera con cuanto material fuera capaz de escribir. Al mismo tiempo, la revista mensual "Magazine of Fantasy and Science Fiction" le invitó a continuar su habitual columna, que había comenzado en la ya cerrada revista bimestral del mismo grupo, "Venture Science Fiction", especializada en la divulgación científica, y le dio a Asimov una completa libertad para publicar. La primera de las contribuciones a esta revista mensual "F&SF" apareció en noviembre de 1958 y continuó desde entonces con otras 399 colaboraciones, hasta que su estado de salud le impidió seguir. Estas columnas, coleccionadas periódicamente en libros por su principal editor, Doubleday, ayudaron a Asimov a crearse una reputación como gran divulgador de ciencia y, según él, fueron las únicas obras de divulgación que escribió en las que no tenía que suponer de sus lectores una completa ignorancia en los temas discutidos. La popularidad de su primer trabajo de gran envergadura, la "Guía de la Ciencia para el Hombre Inteligente", también le permitió desprenderse de gran parte de sus responsabilidades académicas y convertirse esencialmente en escritor a tiempo completo.

Asimov publicó la "Guía Asimov para la Biblia" en dos volúmenes que comprendían el Antiguo Testamento (1967) y el Nuevo Testamento (1969), y luego los combinó en un solo volumen de 1300 páginas en 1981. Lleno de mapas y tablas, la guía conduce a través de los libros de la Biblia en orden, explicando la historia de cada uno y las influencias políticas que les habían afectado, como también información biográfica sobre los personajes importantes.

También escribió bastantes ensayos sobre las convenciones sociales de su día, incluyendo "Thinking About Thinking" y "Science: Knock Plastic" (1967).

La gran variedad de información que cubren los escritos de Asimov llevaron a Kurt Vonnegut a preguntarle en una ocasión: «¿Cómo se siente sabiéndolo todo?». Asimov le respondió que él solo sabía cómo se sentía al tener esta reputación de omnisciente: inquieto (ver "In Joy Still Felt", capítulo 10). En la introducción de su colección de historias "Slow Learner", el novelista estadounidense Thomas Pynchon admitió que obtenía en las obras de divulgación científica de Asimov y en el "Oxford English Dictionary" todos sus conocimientos sobre la entropía.

La faceta como divulgador científico resaltaba en su libro de divulgación científica "El Universo" (publicado en 1966 en inglés, en español en 1971), en el que expone, sin utilizar un lenguaje muy técnico, todo el conjunto de certidumbres científicas existentes sobre el Universo a través de la descripción de diferentes hechos astronómicos y físicos.

De entre sus obras de ciencia ficción, las más conocidas pertenecen al Ciclo de Trántor o la serie de las Fundaciones. La trilogía original ("Fundación", "Fundación e imperio" y "Segunda Fundación") recibió el premio Hugo a la mejor serie de ciencia ficción de todos los tiempos. Posteriormente, se escribió "Los límites de la Fundación" y "Fundación y Tierra", que siguen con los acontecimientos de "Segunda Fundación". En "Fundación y Tierra", Asimov enlaza la serie de la Fundación con las novelas de robots al introducir a uno de sus más conocidos personajes: R. Daneel Olivaw. Sus novelas de robots destacan por ser de tipo policíaco, por lo cual Asimov es considerado como un pionero en la ciencia ficción policíaca. En las novelas de robots ("Las bóvedas de acero", "El sol desnudo", "Los robots del amanecer", "Robots e Imperio") Asimov crea a otro de sus grandes personajes: Elijah Baley. En "Preludio a la Fundación" y "Hacia la Fundación", Asimov narra los orígenes de la psicohistoria, máxima creación de Hari Seldon. Estas novelas sirven también de nexo entre las novelas de robot y las de la Fundación, al presentar el encuentro de Hari Seldon con Daneel.

La obra de Asimov no es ajena al humor, en la revista "Astounding Science Fiction" publicó, en 1948, un artículo seudocientífico y humorístico titulado "Las asombrosas propiedades endocrónicas de la tiotimolina resublimada", cuyo tema era una sustancia que se disuelve exactamente 1,2 segundos «antes» de que se le agregue agua.

También destacaron sus antologías de ciencia ficción, especialmente la serie "La edad de oro de la Ciencia Ficción", en la que publicó en forma de recopilación los cuentos leídos por Asimov a los 11 años y releídos y seleccionados en su madurez, añadiendo al comienzo de ellos comentarios del autor y en qué revista se publicó.





A partir de 1965 y hasta mediados de los setenta, Asimov compagina la creación literaria de ficción con la divulgación histórica a través de varios libros que comprenden las más importantes civilizaciones y periodos históricos. Como por ejemplo la civilización egipcia, griega y romana, pasando por la Edad Media, el descubrimiento del Nuevo Mundo y la formación de Estados Unidos. El autor trata de atraer al gran público al conocimiento de la historia a través de una narración amena y sencilla. Se trata principalmente de historia político/militar.

Esta serie de obras ha sido común e informalmente denominada Historia Universal Asimov y está compuesta por 14 volúmenes, con mapas y cronología incluidos en cada uno de los mismos.

Volúmenes de la serie 


Asimov también escribió historias de misterio ("El negociante de muerte", "Asesinato en la convención", las historias de los Viudos Negros: "Cuentos de los viudos negros" [1971,1972,1973,1974], "Más cuentos de los viudos negros" [1976] y "El archivo de los viudos negros" [1980]) y de fantasía ("Azazel").

Hacia el fin de su vida Asimov publicó una serie de recopilaciones de "limericks" (clase popular de poemas humorísticos de cinco líneas), siendo la mayoría su propia obra, comenzando con "Versos humorísticos lascivos" (1975). "" ("Versos: Demasiado brutos"), cuyo título muestra su amor a los juegos de palabras, contiene 144 "limericks" de Asimov y un número igual del poeta John Ciardi. "Tesoros del humor de Asimov" es a la vez un libro de chistes y un tratado sobre su teoría de humor. Según Asimov, el elemento más esencial del humor es un cambio súbito de punto de vista que de repente mueve el foco desde lo importante a lo trivial, o desde lo sublime a lo ridículo.

Asimov publicó su autobiografía en dos tomos: "En la memoria todavía verde" (1979) y "En la alegría todavía sentida" (1980). Una tercera autobiografía, "", se publicó en 1994. El epílogo lo escribió su viuda, Janet Asimov, poco después de la muerte de Isaac. "Ha sido una buena vida" (2002), redactada por Janet, es una versión resumida de las tres autobiografías.

Gran parte de la ficción de Asimov se basa en el tema del paternalismo. Su primera historia de robots, "Robbie", cuenta la historia de una niñera robótica. A medida que los robots se hacen más sofisticados, sus intervenciones son más sutiles. En "Evidencia" un robot camuflado como humano consigue un cargo electo. En "El conflicto evitable", los robots le quitan el protagonismo a la Humanidad, actuando como niñeras de la especie humana.

Posteriormente, en "Robots e Imperio", un robot desarrolla lo que se llama la «Ley Cero de la robótica», que establece que «un robot no puede dañar a la Humanidad, o, por inacción, permitir que ésta se ponga en peligro». También decide que la presencia robótica está sofocando la libertad de la Humanidad, por lo que la mejor línea de acción es la desaparición por sí mismos, la de los robots. Una historia que no es de robots, "El fin de la eternidad", muestra un conflicto similar y una misma resolución.

En la serie de la Fundación, que originalmente no tenía robots, el personaje Hari Seldon desarrolla la ciencia llamada psicohistoria a través de la que podrá lograrse crear un imperio después de 1.000 años. Esta serie tiene su propia versión de los guardianes de la República de Platón en el libro "Segunda Fundación", que perfeccionan y protegen el plan. Cuando Asimov termina de escribir la serie en los años cincuenta, la Segunda Fundación eran presentados como los protectores de la Humanidad. Cuando en los años ochenta revisita la serie, le da un tono aún más explícito al tema paternalista.

En "Los límites de la Fundación" introduce el planeta «Gaia», obviamente basándose en la hipótesis Gaia. Todo animal, planta y mineral de Gaia participan de una conciencia común, formando una super-mente que trabaja conjuntamente para el bien común. Al final de esta novela, el protagonista Golan Trevize debe decidir si permite o no el desarrollo de «Galaxia», una mayor versión de Gaia que abarca toda la galaxia. Además se introduce a los robots en el universo de la Fundación.

Aun así, es en "Fundación y Tierra" donde aparecen los primeros robots de la serie que interactúan con los personajes. Y las posteriores precuelas, "Preludio a la Fundación" y "Hacia la Fundación", exploran su comportamiento con mayor detalle. Los robots se han revelado como ocultos benefactores de la humanidad.

Otro tema frecuente, tal vez el revés del paternalismo, es la opresión social. "Las corrientes del espacio" toma lugar en un planeta donde crece un fibro-vegetal único, y a los campesinos los explotan los aristócratas de un planeta cercano. El héroe de «En la arena estelar» ayuda a un planeta que es oprimido por un arrogante imperio interplanetario, los Tyrann.

Las víctimas de la opresión son muchas veces la gente de la Tierra (a diferencia de colonos en el espacio) o los robots. En «El hombre Bicentenario» un robot lucha contra el prejuicio para hacerse aceptar como humano. En "Bóvedas de acero", la gente de la Tierra siente antipatía hacia los ricos «espaciales» de otros planetas y trata a los robots (asociados con los espaciales) de una forma semejante a la de los estadounidenses blancos trataban a los negros a principios del siglo XX, por ejemplo, dirigiéndose a ellos como "muchacho". "El guijarro en el cielo" muestra una situación parecida: el Imperio Galáctico gobierna la Tierra y su gente usa términos tales como "Miserable terrícola" (Earthie-squaw), sucio terráqueo o simplemente terráqueo, pero la Tierra es una dictadura teocrática que impone la eutanasia a todos a la edad de sesenta años. Los héroes son Bel Arvardan, hidalgo galáctico que tiene que superar sus prejuicios y Joseph Schwartz, un sesentón estadounidense del siglo XX que había emigrado desde Europa, donde su pueblo fue perseguido (es bien posible que fuera judío), y se encuentra transportado en el tiempo hasta la época de Arvardan. Tiene que decidir si ayuda a una sociedad oprimida que no lo considera apto para seguir viviendo.

Otro tema frecuente de Asimov es el pensamiento racional. Fusionó el misterio policíaco con la ciencia ficción en la novela "Bóvedas de acero" (1954) y en los cuentos de "Misterios de Asimov", en los que generalmente jugaba limpio con el lector introduciendo temprano toda ciencia y tecnología involucrada en la resolución de la trama. Más tarde produjo obras de ficción policíaca, incluyendo la novela "Asesinato en la convención" y los "Cuentos de los viudos negros", en los que siguió la misma regla. Frecuentemente en toda su ficción, las escenas importantes son esencialmente debates, siendo el ganador el lado más racional, el más humanitario, o simplemente el más persuasivo.

En una entrevista en 1988 con Bill Moyers, Asimov propuso el aprendizaje electrónico, donde la gente usaría computadoras para encontrar información sobre temas en los que estaban interesados y esto haría más interesante aprender, puesto que la gente tendría la libertad de escoger qué aprender y ayudaría a difundir el conocimiento alrededor del mundo.

Las principales críticas a la obra temprana de Asimov giraban en torno a que no abordaba temas de sexualidad de sus personajes y que tampoco incluía criaturas extraterrestres, lo que a los ojos de algunos lectores dotaba a sus libros de cierta frialdad y cientifismo difícil de asimilar. Sin embargo, en sus obras más tardías intentó compensar estas críticas introduciendo este tema, ya fuese en forma jocosa, como en "Playboy y el Dios mucoso", o seriamente, como en la novela "Los propios dioses" ("The Gods Themselves"), escrita en 1972 y ganadora de los premios Hugo y Nébula, que parece haber sido escrita como una respuesta a estas críticas. En ella trata ampliamente ambas temáticas. Asimov se mostró especialmente satisfecho de esta obra y a la parte central de la novela la consideró lo mejor de sus escritos.

La razón para no incluir extraterrestres en sus obras es explicada por el propio Asimov en uno de sus libros, en uno de los comentarios previos al relato (que según el propio autor algunos lectores consideran mejores que los relatos en sí). En una de sus primeras historias, "Homo Sol", la civilización humana entra en contacto con la "Federación", compuesta por seres humanoides, que no son humanos. Los humanos, aunque más atrasados en lo tecnológico cuentan con un gran potencial de expansión y aprendizaje. Esto pareció agradar bastante a John W. Campbell (editor de Asimov y escritor anterior a la edad de oro). Sin embargo, para Campbell «humano» significaba, por defecto, occidental del norte de Europa. Este enfoque no fue del agrado de Asimov (de origen ruso-judío) y para evitar este tipo de conflictos, decidió crear galaxias únicamente humanas, en las que no se hace referencia a razas.

Otros criticaban la falta de personajes fuertes femeninos en sus obras iniciales. Asimov se excusó aduciendo su falta de experiencia inicial como escritor prácticamente juvenil. Sin embargo, a medida que avanza en su obra, los personajes femeninos ganan importancia, como Susan Calvin en "Yo, Robot", Noys Lambert en "El Fin de la Eternidad", Arkady en "Segunda Fundación", Bliss en "Fundación y Tierra", Gladia Solaria en "Los robots del amanecer" o Dors Venabili además de Bayta Darell ("Fundación e Imperio") en las secuelas de la "trilogía original de Las Fundaciones". 

Durante la década de 1980, embarcado por presiones editoriales en sucesivas continuaciones de la serie "Fundación" y en pleno auge del movimiento Ciberpunk, la visión positiva de Asimov de la ciencia y la tecnología fue denostada por esta corriente literaria, más crítica hacia sus desviaciones y abusos.

Varias obras de Isaac Asimov han sido la fuente de muchas películas.

"El fin de la eternidad" tuvo una versión cinematográfica soviética ("Konets vechnosti", 1987).

"Anochecer" (1988), también conocida como "La muerte de los soles", de Paul Mayersberg.
Adaptación para televisión de un relato de Asimov en el que se cuenta la historia de un planeta en el que no conocen la noche al contar con tres soles. Cuando se produce un eclipse, el caos y el miedo se apoderan de sus habitantes.
Con David Birney y Sarah Douglas.

En 1999, Chris Columbus dirigió una adaptación cinematográfica de la novela "El hombre bicentenario" protagonizada por Robin Williams, "El hombre bicentenario".

En 2004 se produce una película Yo, robot, dirigida por Alex Proyas y protagonizada por Will Smith. Aunque se atribuye la historia a las Series de Robots del mismo nombre, Yo, robot, en realidad está basada en un guion de Jeff Vintar, titulado Hardwired. Algunas ideas de Asimov acerca de los robots —la más importante, las tres leyes de la robótica— fueron añadidas al guion de Vintar después de que los productores adquirieron los derechos sobre el título del libro. La película tiene también alguna semejanza con un cuento de ciencia ficción de 1939 (pre-Asimov), Yo, robot, de Eando Blinder, que trata de un robot humanoide “inteligente”, quien es culpado de la muerte de su creador.

Asimov también colaboró en Star Trek como asesor científico. En los 70 y 80 fue un asiduo de las convenciones organizadas por los "fans" de la serie de televisión "Star Trek". «"Star Trek" es el programa de ciencia ficción más inteligente que se hace para televisión», declaró Asimov en una convención.

En abril de 2018, se conoció la noticia de que Apple preparaba una adaptación a televisión de la saga de la Fundación. La serie televisiva será escrita y producida por David S. Goyer y Josh Friedman, y detrás de la producción estaría la empresa Skydance, quienes producen Grace and Frankie y Altered Carbon para Netflix y Jack Ryan para Amazon.

En honor de Asimov se nombró al asteroide, (5020) Asimov y al cráter Asimov, en el planeta Marte.

A lo largo de su dilatada trayectoria literaria recibió numerosos premios y honores entre los que destacan:

En 1965, Asimov tenía catorce doctorados honoris causa por diferentes universidades.




</doc>
<doc id="15310" url="https://es.wikipedia.org/wiki?curid=15310" title="Ficus benghalensis">
Ficus benghalensis

El baniano (Ficus benghalensis), nombre común que comparte con otras especies del género "Ficus", es un árbol endémico de Bangladés, India y Sri Lanka. 

Puede crecer hasta convertirse en un árbol gigante que se extiende por varias hectáreas. "Ficus benghalensis" produce raíces aéreas en las ramas que crecen hacia abajo como si fueran lianas. Una vez que estas raíces llegan al suelo, arraigan y se vuelven leñosas y de soporte, se vuelven raíces fúlcreas.

Recibe otros nombres más sugerentes, por ejemplo higuera de Bengala, higuerote o higuera estranguladora. Lo de higuera se debe a que ésta también es de la familia de los ficus y lo de estranguladora a que empieza siendo epífito, es decir, apoyándose en otro árbol al que termina asfixiando. De este hecho procede también otro nombre de muchas especies de Ficus con el que se conoce en Venezuela y en otros países americanos: el de matapalo.

Esta planta es original de la India y de Ceylán (Sri Lanka). Los banianos, al igual que las distintas especies de matapalos, se reproducen fácilmente por semilla o por estaca, y a menudo se van extendiendo desde el lugar original mediante raíces aéreas que anclan en el suelo y comienzan a crecer y engrosarse hasta el punto de que se "independizan" del tronco original, logrando así "emigrar" a veces a grandes distancias, tal como se ve en la imagen tomada en Caracas. En dicha imagen puede verse como el tronco original de un baniano se inclina hacia la calle (Avenida La Salle en Caracas) desarrollando numerosas raíces que pueden soldarse y convertirse en troncos que sirven de sostén, con lo que pueden alcanzar cierta distancia hasta llegar a un lugar donde existe un mayor grado de insolación, en este caso, la propia avenida, lejos de los edificios que hay a ambos lados de la misma. Se trata de una simple adaptación a unas condiciones ecológicas muy complejas.

Las semillas de los banianos pueden caer y crecer cerca de un árbol, a veces del propio árbol de donde proceden las mismas, y también suelen fructificar en alguna oquedad de un tronco o de una pared o roca. Poco a poco empiezan a crecer ya que tienen gran capacidad de apoyarse como epífitas en cualquier objeto que les sirva para ascender en busca de los rayos solares. En condiciones normales, el árbol crece hasta que alcanza un nivel donde consigue la mayor cantidad de luz solar, por lo cual su altura puede variar considerablemente. Por ello, donde este árbol predomina en un lugar, más que crecer en altura se van extendiendo en superficie, buscando los claros que quedan sin vegetación. Por lo general, la copa de este árbol se extiende sobre un diámetro bastante superior a su altura.

Muchos pueblos de Asia hacen vida social debajo de los banianos, pues les protege de los rayos del Sol. A través de sus raíces y ramas la gente pasea, construye templos, y pone mercadillos. De hecho, el nombre de baniano viene de los mercadillos. Los mercaderes ambulantes recibían el nombre de banianos. Como era habitual que pusieran sus tenderetes bajo estos árboles, se llegó a identificar el nombre de los árboles con el de los vendedores ambulantes.

Budistas e hindúes lo consideran un árbol sagrado. De sus frutos se han obtenido medicinas contra la lepra y la diabetes . El sabor del fruto no es muy atractivo para los humanos, pero hay monos a los que les encanta . Lo mismo ocurre con murciélagos y ciertas aves. Los elefantes comen sus hojas con deleite.

El baniano más famoso es el del Jardín Botánico de Calcuta. Tiene más de 230 años de edad y ocupa una superficie de 12.000 metros cuadrados; más o menos un círculo con un diámetro de 120 m. La circunferencia del tronco principal es de más de doce metros. 

A pesar de esa fama, el libro Guinness de Récords nos dice que el más grande también está en un ciudad india, en la ciudad de Kadiri. El árbol en cuestión se llama "Thimmamma Marrimanu". 

Thimmamma, según los lugareños, es el nombre de una mujer que salvó a su marido con su devoción. Una leyenda local dice que si una pareja sin hijos reza a Thimmamma bajo el árbol, al año siguiente tendrá un hijo.

En España hay buenos ejemplares de baniano, especialmente en la isla de Tenerife, aunque nada comparable a los de Calcuta o Kadiri.

En inglés se le llama "Banyan".

"Ficus benghalensis" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 1059–1060. 1753.
Ficus: nombre genérico que se deriva del nombre dado en latín al higo.

benghalensis: epíteto geográfico que alude a su localización en Bengala.





</doc>
<doc id="15313" url="https://es.wikipedia.org/wiki?curid=15313" title="Poliomielitis">
Poliomielitis

La poliomielitis (del griego "πολιός", "poliós": gris; y de "µυελός", "myelós": refiriéndose a la médula espinal) es una enfermedad infecciosa, también llamada de forma abreviada polio, que afecta principalmente al sistema nervioso. La enfermedad la produce el virus poliovirus. Se llama infantil porque las personas que contraen la enfermedad son principalmente niños. Se transmite de persona a persona a través de secreciones respiratorias o por la ruta fecal oral. La mayoría de las infecciones de polio son asintomáticas. Solo en el 1% de casos, el virus entra al sistema nervioso central (SNC) vía la corriente sanguínea. Dentro del SNC, el poliovirus preferentemente infecta y destruye las neuronas motoras, lo cual causa debilidad muscular y "parálisis aguda flácida".

La poliomielitis es más probable que ocurra en niños de 4 a 15 años en climas templados, en verano cálido e invierno un poco frío. Es una enfermedad muy infecciosa, pero se combate con la vacunación. La enfermedad afecta al sistema nervioso central. En su forma aguda causa inflamación en las neuronas motoras de la médula espinal y del cerebro y lleva a la parálisis, atrofia muscular y muy a menudo deformidad. En el peor de los casos puede causar parálisis permanente o la muerte al paralizarse el diafragma.

El 24 de octubre se celebra el Día Mundial contra la Poliomielitis.

La enfermedad fue descrita por primera vez por el alemán Jakob Heine en 1840. Durante las epidemias agudas de polio a principios del siglo XX, se definieron varias categorías de poliomielitis para clasificar la extensión y gravedad de la enfermedad. Dos patrones básicos de infección por polio se describieron: una de menor cuantía, que no afectaba el sistema nervioso central (SNC), llamado "polio abortivo", y la enfermedad mayor, con parálisis o no. 

La poliomielitis empezó a controlarse en 1949 cuando el bacteriólogo John Franklin Enders logró hacer crecer los virus en laboratorio dentro de tejidos. Basándose en esa técnica el epidemiólogo Jonas Edward Salk desarrolló una vacuna para los tres tipos de poliomielitis conocidos. Tras las pruebas clínicas pertinentes que demostraron que era segura, en 1954 se empezó la inoculación. La vacuna Salk, como se la conoce, es inyectable.

En 1964 se autorizó otra vacuna que había sido desarrollada por Albert Bruce Sabin. Se la llamó trivalente porque atacaba a los tres tipos de virus mencionados. A diferencia de la vacuna de Salk, esta se administraba por vía oral, por lo que muy rápidamente la Sabin sustituyó a la Salk.

En muy poco tiempo hubo campañas masivas de vacunación y como consecuencia de todo ello, el 21 de junio de 2002, la Organización Mundial de la Salud (OMS) declaró a la región europea libre del virus de la polio. Esta región está formada por 51 países y 850 millones de habitantes. El último caso, en esta región, se dio en Turquía en noviembre de 1998.

En 1988, la OMS emprendió un programa mundial de erradicación. «Cuando iniciamos la campaña de erradicación en 1988, la polio dejaba paralíticos todos los días a más de mil niños», informó la doctora Gro Harlem Brundtland, la entonces directora general de la OMS, quien añadió: «En 2001 hubo mucho menos de mil casos en todo el año». La polio ya solo está activa en menos de diez países. 
En mayo de 2014, la OMS hizo pública una nota de alerta por la situación de extensión de la poliomielitis en áreas endémicas y no endémicas, en concreto Pakistán y Afganistán en Asia central, Siria e Iraq en Oriente Medio, y Camerún y Guinea Ecuatorial en África central.

La Organización Mundial de la Salud declara que una zona está libre de una enfermedad cuando transcurren tres años sin que se dé ningún caso.

En 1994, la OMS consideró a la región de América (36 países) libre de polio, en el año 2000 lo hizo con la región del Pacífico (37 países, incluyendo China). En junio de 2002 se declaró a Europa zona libre de polio, lo que supone para sus 870 millones de habitantes “el mayor logro del nuevo milenio en materia de salud pública”.

La OMS empezó su campaña para erradicar la poliomielitis en 1988. En esa época seguía siendo endémica en todo el mundo, y de hecho aquel año hubo 350.000 infectados. Durante 2005, sólo unas 1.880 personas en todo el mundo contrajeron la enfermedad. A comienzos de 2006, y después de haber sido erradicada de Egipto y Níger, la OMS ha declarado que sólo quedan cuatro países en el mundo en que la enfermedad sigue siendo endémica. Estos son Nigeria, India, Pakistán y Afganistán. La OMS, Unicef, los Centros para el Control y la Prevención de Enfermedades de Estados Unidos (CDC) y Rotary International han anunciado que redoblarán los esfuerzos en aquellos países, con lo cual estiman que en dos años más no se producirán nuevos casos de la enfermedad. Luego habrá que esperar tres años más para que la poliomielitis sea declarada oficialmente como erradicada.

Si se consigue será la tercera enfermedad infecciosa eliminada de la faz de la Tierra. La primera fue la viruela, y la segunda la peste bovina. No obstante, en 2014, este objetivo se ve aún no cercano ya que se ha comprobado transmisión del virus y la presencia de la enfermedad en diversos países, como: Pakistán, Afganistán, Iraq, Siria, Nigeria, Guinea Ecuatorial, Camerún y Etiopía. Se han notificado en los 4 primeros meses de 2014 un total de 68 casos incluyendo algunos en países no endémicos (en 2013 fueron 417 casos registrados)

La poliomielitis es una infección causada por un miembro del género Enterovirus conocido como poliovirus (PV). Este grupo de virus ARN prefiere el tracto gastrointestinal e infecta y causa enfermedad solo en los seres humanos. Su estructura es muy sencilla, compuesta de un solo genoma ARN de sentido (+) encerrado en una cáscara de proteínas llamada cápside. Además de proteger el material genético del virus, las proteínas de la cápside del poliovirus permite la infección exclusiva de ciertos tipos de células en el hospedador. Se han identificado tres serotipos de poliovirus: el poliovirus tipo 1 (PV1), tipo 2 (PV2), y el tipo 3 (PV3), cada uno con una secuencia de proteínas en la cápside ligeramente diferentes. Los tres serotipos son extremadamente virulentos y producen los mismos síntomas de la enfermedad. El PV1 es la forma más común, y la más estrechamente relacionada con la parálisis causada por la poliomielitis.

Las personas expuestas al virus, ya sea por infección o por la inmunización con la vacuna contra la poliomielitis, desarrollan inmunidad protectora. Los individuos inmunes tienen los anticuerpos IgA contra la poliomielitis presentes en las amígdalas y el tracto gastrointestinal y son capaces de bloquear la replicación del virus, mientras que los anticuerpos IgG e IgM contra PV puede prevenir la propagación del virus a las neuronas motoras del sistema nervioso central. La infección o la vacunación con un serotipo de poliovirus no proporciona inmunidad contra los otros serotipos, y la inmunidad plena requiere la exposición a cada serotipo.

La poliomielitis es altamente contagiosa y se propaga fácilmente de persona a persona.<ref name=Kew_2005>


</doc>
<doc id="15315" url="https://es.wikipedia.org/wiki?curid=15315" title="APL">
APL

APL ("A Programing Language)" es un lenguaje de programación que se originó a partir de la notación matemática desarrollada por Kenneth Iverson en 1957, quien lo implementó en 1962 cuando fue contratado por IBM ese mismo año. 

El APL es un lenguaje aplicativo o un lenguaje para aplicar algo, similar a un lenguaje funcional.

Utiliza operadores parametrizables por lo que es muy conciso. Su sintaxis está basada en (pocos) "operadores" y utiliza un conjunto especial de caracteres no presentes en el código ASCII. Básicamenteguage, debido a que su conjunto de operaciones se fundamente en un álgebra lineal abstracta.
Por lo que es un lenguaje idóneo para trabajar con vectores y matrices. 
Cuenta con un repertorio de operadores que le permite componer nuevas operaciones lógicas o matemáticas. 

Al contar con productos cruz y puntos generalizados, una sola sentencia puede traducirse en muchas líneas de otros lenguajes, como Fortran, Basic, PL1, C, etc. ya que, en esos, estas operaciones y otras se implementan mediante loops o ciclos iterativos.

Un ejemplo de ello, es el lenguaje de simulación de circuitos, SIAL, el cual ocupaba cerca de 25 000 sentencias en Fortran-Assembler y, al ser reescrito en APL, todo el programa podía ser impreso en dos folios. Por otra parte, a pesar de ser un lenguaje de tan alto nivel, también es capaz de manipular a escala de bits y tiene interfaces con lenguajes de programación de bajo nivel (C, ensamblador, etc) mediante los llamados procesadores auxiliares.

Tiene la propiedad de que desde una rutina se puede (en tiempo de ejecución) crear, compilar y ejecutar, otras, lo que lo hace también muy apropiado para la elaboración automática de compiladores e intérpretes.

Algunas dificultades prácticas radican en que:

APL puede resolver un sistema de ecuaciones en una sola sentencia si lo aplicamos a un sistema de ecuaciones concreto. Por ejemplo:

7x + 4y + 2z = 4

6x + 8y + 9z = 7

4x + 2y + 1z = 2

Basta ejecutar UNA ÚNICA sentencia de APL, cuya sintaxis es:

4 7 2 [÷] 3 3 ρ 7 4 2 6 8 9 4 2 1

Donde el operador ρ (rho) formatea la lista de números en una matriz de 33 Para obtener. 
El operador de [÷] calcula la inversa de la matriz y la multiplica por el vector 4 7 2, generando la solución para cada variable (x, y, z):

0 1.1 -0.2

El programa anterior, podría utilizar bibliotecas para las operaciones con matrices, Fortran permite arreglos redimensionables, y es adecuado para el cómputo en paralelo. Pero se necesitan algunas declaraciones para los arreglos y llamar a las sub-rutinas, y en otros lenguajes poco flexibles para crear sub-rutinas con arreglos, todavía es más complicado porque se tienen que codificar mediante loops la inversión de la matriz y el producto, mínimo unas 20 líneas.

El APL, permite pensar directamente en las operaciones algebraicas que se pueden expresar de manera muy concisa, por ello permite tiempos de desarrollo y pruebas muy cortos. Por ello es un lenguaje muy adecuado para campos muy variados, tales como los de Matemáticas, Estadística, Negocios, Inteligencia artificial, Desarrollo de prototipos, etc.

Entre sus aplicaciones más conocidas está su uso en la película Tron, de Walt Disney, para la generación de los efectos especiales, y en el sistema Deep Blue, de IBM, que venció a Kasparov en ajedrez..

Como curiosidad, en la novela Cheap Complex Devices, de J. C. Sundman, el autor afirma que el contenido del libro ha sido escrito automáticamente por un ordenador, usando código generado en APL, lo que le valió el premio Douglas R. Hofstadter, de creación de novelas por ordenador, en 1997. Todo ello, naturalmente, es un artificio literario.

Kenneth Iverson, posteriormente, estuvo al frente del desarrollo de un lenguaje de programación, que presentaban como el sucesor de APL, llamado J. Una de las características particulares de J es lo que se ha dado en denominar programación funcional tácita, en que se considera que, para expresar programas, no es necesario nombrar variables, ni parámetros a funciones (Estos conceptos de programación tácita han sido incorporados al lenguaje Logo en la biblioteca LogoFE). En J, la variedad de las rutinas (que en APL se llaman "operadores"), es mucho mayor.

John Backus en la cátedra que dio al recibir el premio Turing, presentó FP/FFP. FP es un lenguaje funcional y FFP son formas funcionales, que se basaron en el lenguaje aplicativo APL. Un ejemplo de las formas funcionales en APL es la operación reduce codice_1 que reduce un vector aplicando el operador. codice_2 computa codice_3, en algunos lenguajes como algunos dialectos de Lisp conservó el nombre reduce, que se heredó a otros lenguajes funcionales.



</doc>
<doc id="15316" url="https://es.wikipedia.org/wiki?curid=15316" title="Huelga">
Huelga

La huelga es una forma de protesta en la que sus participantes o miembros se abstienen de realizar la actividad que realizan normalmente en perjuicio de aquellos a los que dirigen sus reivindicaciones o sus quejas. El tipo más importante y extendido es la huelga laboral o paro que es la suspensión colectiva de su actividad por parte de los trabajadores con el fin de reivindicar mejoras en las condiciones de trabajo o manifestarse contra recortes en los derechos sociales; según la Organización Internacional del Trabajo, es uno de los medios legítimos fundamentales de que disponen los ciudadanos y específicamente los trabajadores (a través del movimiento sindical y las organizaciones sindicales) para la promoción y defensa de sus intereses económicos y sociales.

La primera "huelga" documentada ocurrió en el Antiguo Egipto, organizada por los trabajadores y artesanos de Set Maat (actual Deir el-Medina) durante el reinado de Ramsés III, hacia el año 1166 a. C.

La huelga está asociada a la demanda de mejores condiciones de trabajo, al desarrollo del movimiento sindical y a la expansión del sindicalismo internacional y, en general, a la lucha de clases. Aunque sus orígenes se remontan a la Revolución francesa de 1789 su pleno desarrollo se produce con la Revolución industrial y la generalización del trabajo asalariado a finales del siglo XVIII y principios del siglo XIX.

El origen de la huelga unido al movimiento sindical: Los primeros movimientos obreros se sitúan en Inglaterra. Allí apareció el "ludismo" conducido por Ned Ludd y conocido como el movimiento de los "rompedores de máquinas" (1810-1811). En años posteriores, 1830, aparecen las primeras organizaciones obreras de carácter gremial (trabajadores que se dedican sólo a un oficio). En Inglaterra tomaron el nombre de "trade-unions" (literalmente «agrupaciones gremiales») y más adelante, por la tendencia a abreviar en inglés, "unions" («sindicato» o «unión sindical»). 

A los movimientos sindicales de distinto signo (anarquismo, comunismo, socialismo) van también asociados al desarrollo teórico de la existencia de una clase trabajadora obligada a desarrollar una lucha de clases para el reconocimiento de valor como fuerza de trabajo en la creación de riqueza. La práctica de la huelga es considerada como una herramienta para reivindicar mejoras en las condiciones de trabajo. El derecho de huelga es otra de la reivindicaciones del movimiento sindical. En este sentido las Combination Acts (leyes inglesas que prohibían los sindicatos) no fueron derogadas hasta 1824.

El inicio del desarrollo teórico se produce básicamente por Karl Marx y Engels en el «Manifiesto Comunista» y el posterior desarrollo en libros como El Capital en el que se propugna, para alcanzar objetivos de la clase trabajadora, una revolución.

El desarrollo de la socialdemocracia en el siglo XX contribuyó a que la huelga laboral dejara de estar severamente penalizada. Fue entonces cuando el derecho de huelga fue reconocido internacionalmente como un derecho esencial de los trabajadores constitutivo de la libertad sindical. Se trata de uno de los derechos de segunda generación, que se reconoce en la actualidad en la mayoría de los ordenamientos internos y en tratados internacionales de alcance universal como el Pacto Internacional de Derechos Económicos, Sociales y Culturales.

Las huelgas, como modo de protesta y reivindicación, pueden clasificarse del siguiente modo:


La huelga laboral, dependiendo de sus características, puede ser:

Además, puede ser:


En algunos países como México, Argentina, Chile, Ecuador y Perú, se le denomina comúnmente paro. Este término se refiere generalmente al abandono de tareas laborales, aunque también comúnmente se llama paro a toda movilización, protesta, manifestación, reclamo público, abandono de tareas o actuación de piquetes.

En algunos países como Ecuador, el Derecho del Trabajo y en concreto el código de trabajo ecuatoriano en su artículo 525 indica que la "huelga" es la suspensión de actividades organizada por trabajadores y el "paro" (cierre patronal), es realizado por los empleadores.





</doc>
<doc id="15318" url="https://es.wikipedia.org/wiki?curid=15318" title="Steve Jobs">
Steve Jobs

Steven Paul Jobs (San Francisco, California, 24 de febrero de 1955-Palo Alto, California, 5 de octubre de 2011), más conocido como Steve Jobs, fue un empresario y magnate de los negocios del sector informático y de la industria del entretenimiento estadounidense. Fue cofundador y presidente ejecutivo de Apple Inc. y máximo accionista individual de The Walt Disney Company.

Fundó Apple en 1976 junto con un amigo de la adolescencia, Steve Wozniak, con ayuda del excompañero de Jobs en Atari, Ron Wayne en el garaje de su casa. Aupado por el éxito del Apple II Jobs obtuvo una gran relevancia pública, siendo portada de "Time" en 1982. Contaba 26 años y ya era millonario gracias a la exitosa salida a bolsa de la compañía a finales del año anterior. La década de los 80 supuso la entrada de potentes competidores en el mercado de los ordenadores personales, lo que originó las primeras dificultades empresariales.
Su reacción fue innovar, o mejor dicho, implementar: a principios de 1984 su compañía lanzaba el Macintosh 128K, que fue el primer ordenador personal que se comercializó exitosamente que usaba una interfaz gráfica de usuario (GUI) y un ratón en vez de la línea de comandos. Después de tener problemas con la cúpula directiva de la empresa que el mismo fundó, renunció. Jobs vendió entonces todas sus acciones, salvo una. Ese mismo año recibía la Medalla Nacional de Tecnología del presidente Ronald Reagan, cerrando con este reconocimiento esta primera etapa como emprendedor. Regresó en 1997 a la compañía, que se encontraba en graves dificultades financieras, y fue su director ejecutivo hasta el 24 de agosto de 2011. En ese verano Apple sobrepasó a Exxon como la empresa con mayor capitalización del mundo.

Durante los años 90 transformó una empresa subsidiaria adquirida a Lucasfilm en Pixar, que revolucionó la industria de animación con el lanzamiento de "Toy Story". La integración de esta compañía en Disney, de la que era proveedor, convertiría a Jobs en el mayor accionista individual del gigante del entretenimiento. En el año de su muerte, su fortuna se valoraba en 8300 millones de dólares y ocupaba el puesto 110 en la lista de grandes fortunas de la revista "Forbes".

En su segunda etapa en Apple, también cambió el modelo de negocio de la industria musical: aprobó el lanzamiento del iPod en 2001, y en 2003 la tienda "online" de música de iTunes, que en siete años vendió más de 10 000 millones de canciones y dominó completamente el negocio de música en línea, a un precio de 0,99  USD por canción descargada. Ya en 2009 lograba acaparar el 25 por ciento de la venta de música en los Estados Unidos, y es la mayor tienda musical por volumen de ventas de la historia. Según el registro de patentes de los Estados Unidos, 323 patentes de Jobs figuran a nombre de Apple.

Steve Jobs nació en San Francisco (California) en el año 1955, fruto de la relación entre Abdulfattah Jandali, un inmigrante sirio musulmán, y Joanne Carole Schieble, una estadounidense de ascendencia suiza y alemana, dos jóvenes estudiantes universitarios que lo entregarían en adopción a una pareja de clase media, Paul y Clara Jobs (Hagopian) de origen armenio. Sus padres biológicos se casarían luego y tendrían otra hija, la novelista Mona Simpson, a quien Steve no conocería hasta la edad adulta. En esa nueva familia Steve creció junto a su otra hermana, Patty. Su padre, Paul Jobs, era maquinista en la compañía estatal de transporte ferroviario y su madre ama de casa.

En 1961 la familia se trasladó a Mountain View, una ciudad al sur de Palo Alto que empezaba a convertirse en un centro importante de la industria de la electrónica. Allí asistió a la escuela primaria Cupertino Middle School y a la secundaria Homestead H.S., también en Cupertino. A Jobs le interesaban bastante la electrónica y los gadgets, razón que le llevó a unirse a un club llamado "Hewlett-Packard Explorer Club", donde ingenieros de Hewlett-Packard mostraban a los jóvenes sus nuevos productos. Fue allí donde Steve vio su primera computadora, a la edad de 12 años. Quedó tan impresionado que supo de inmediato que él quería trabajar con computadores. 

Ya en la secundaria asiste a charlas de Hewlett-Packard. En una ocasión, Steve preguntó al por entonces presidente de la compañía, William Hewlett, sobre algunas partes que necesitaba para completar un proyecto de clase. William quedó tan impresionado que se las proporcionó y le ofreció realizar unas prácticas de verano en su compañía. Steve sería luego contratado como empleado veraniego, coincidiendo allí con Steve Wozniak por medio de un amigo mutuo, Bill Fernandez.

En 1972 entra en la universidad Reed College de Portland (Oregón). Asiste a ella tan solo 6 meses antes de abandonarla, debido al alto coste de sus estudios. En lugar de regresar a casa, continúa asistiendo a clases como oyente unos 18 meses más, viviendo a base de trabajos con ingresos ínfimos. Curiosamente, sus estudios en caligrafía, enseñada por Robert Palladino, le serían de utilidad cuando diseñara las tipografías del primer Mac. 

Tras dos años fuera de casa, en otoño de 1974 regresa a California con el objetivo de realizar un retiro espiritual en la India y consigue un trabajo como técnico en la empresa fabricante de juegos de video Atari Inc., donde colaboró en la creación del juego "Breakout". De la mano de Steve Wozniak comienza a asistir a las reuniones del Homebrew Computer Club, donde Wozniak le contó que estaba intentando construir un pequeño computador casero. Jobs se mostró especialmente fascinado con las posibilidades mercantiles de la idea de Wozniak y le convence para fabricar y vender uno. Steve Jobs se encarga de las ventas y negociaciones y Steve Wozniak, en secreto, de construir la máquina electrónica.

Según afirma Nolan Bushnell, luego de su regreso de la India a donde fue acompañado por un antiguo compañero de la escuela secundaria, y más tarde primer empleado de Apple, Daniel Kottke, decidió renunciar a Atari y fundar "Apple Computer", Steve ofreció a Bushnell un porcentaje de Apple, 50 000 dólares, el cual no aceptó.
Durante este tiempo, experimentó con drogas psicodélicas, LSD, llamando a sus experiencias como "una de las dos o tres cosas más importantes que había hecho en su vida".

Debido a las exigencias de su contrato con Hewlett-Packard, Wozniak tuvo que dar a conocer su intención de construir un computador personal a la empresa, que desechó la idea por considerarla ridícula. Fue así como en 1976 nació Apple Computer Company.

Tras la consecución del primer computador personal, bautizado como Apple I, Jobs se dedicó a su promoción entre otros aficionados a la informática, tiendas y ferias de electrónica digital, llegando a vender unos 200 ejemplares. A partir de entonces, el crecimiento de Apple fue notable. En tan solo 10 años, Apple se convirtió en una empresa con 4000 empleados y Jobs, con 27 años, era el millonario más joven de 1982. 
A principios de 1983 vio la luz Lisa, el primer computador personal con Interfaz gráfica del usuario diseñado especialmente para gente con poca experiencia en informática. Su precio, más caro que el de la mayoría de ordenadores personales de la competencia, no facilitó que el nuevo producto fuese precisamente un éxito de ventas, perdiendo Apple aproximadamente la mitad de su cuota de mercado en favor de IBM.

En un intento por mantener la competitividad de la compañía, Steve Jobs, ya convertido en ejecutivo, convenció a John Sculley, director ejecutivo de Pepsi-Cola, para tomar las riendas de Apple.

En la conferencia anual de Apple del 24 de enero de 1984, Jobs presentó con grandes expectativas, el Apple Macintosh, el primer ordenador personal de Apple con ratón. Sin embargo Macintosh no alcanzó las expectativas comerciales esperadas.

Hacia finales de 1984 las diferencias entre Sculley y Jobs se iban haciendo cada vez más insalvables, hasta el punto de deteriorarse la relación, principalmente por el proyecto macintosh. En mayo de 1985, en medio de una profunda reestructuración interna que se saldó con el despido de 1200 empleados, Sculley relegó a Jobs de sus funciones como líder de la división de Macintosh.

Tras varios meses de resignación, el 17 de septiembre de 1985, Steve Jobs abandonó la compañía que él mismo había fundado.

En esa época Jobs había desarrollado un estilo gerencial agresivo y un liderazgo irrespetuoso con sus empleados; a pesar de todo, se le consideró como el empresario más exitoso de su generación.

Tras abandonar Apple en 1986, Steve Jobs compra por 5 millones de dólares la empresa The Graphics Group destinando otros 5 millones adicionales como inversión, conocida en lo sucesivo como Pixar, una subsidiaria de Lucasfilm especializada en la producción de gráficos por computador. 

Steve Jobs empezó a firmar varios acuerdos para producir películas animadas para la compañía Walt Disney. En 1995 se estrenó en los cines "Toy Story", el primer largometraje generado completamente por computadora, conseguido con su propio software de renderización, RenderMan. Toy Story fue el mayor éxito de taquilla de 1995 y la primera película del binomio Walt Disney-Pixar en ganar un premio Óscar.

En noviembre de 2001, Pixar estrena "Monsters, Inc.", recaudando con ella 780 millones de dólares en todo el mundo, convirtiéndose en la película animada más taquillera hasta ese momento. Sus éxitos siguieron con "Buscando a Nemo" (2003), "Cars" (2006), "WALL-E" (2008) y "Up" (2009), entre otras, las cuales obtuvieron la aprobación de la crítica y el público.

En los años 2003 y 2004, cuando el contrato de Pixar con Disney se estaba acabando, el director ejecutivo de Disney, Michael Eisner, intentó sin éxito negociar un nuevo acuerdo, y en los comienzos de 2004, Jobs anunció que Pixar podría buscar un nuevo socio para distribuir sus películas después de que expirara su contrato con Disney. En octubre de 2005, Bob Iger sustituyó a Eisner en Disney y trabajó rápidamente para enmendar las relaciones con Jobs y Pixar. El 24 de enero de 2006, Jobs e Iger anunciaron que Disney había acordado comprar Pixar en una transacción de acciones por valor de $7,400 millones. Cuando el acuerdo se cerró, Jobs se convirtió en el mayor accionista individual en la compañía de Walt Disney, con aproximadamente el siete por ciento de las acciones de la empresa. Una vez completada la fusión, Jobs recibió ese 7% y se incorporó al Consejo de Administración como el mayor accionista individual. Después de la muerte de Jobs, sus acciones de Disney fueron trasladadas al Fideicomiso Steven P. Jobs dirigido por Laurene Jobs.

Tras dejar Apple, a los 30 años de edad, decidió continuar su carrera empresarial en la industria de la computación y fundó la empresa NeXT Computer Inc., con una inversión de $7 millones de dólares. Reunió para el nuevo proyecto a 7 de sus antiguos empleados en Apple: Bud Tribble, George Crow, Rich Page, Susan Barnes, Susan Kare y Dan'l Lewin. En el plan de negocios se estableció que, al igual que se hacía en Apple, la compañía vendiese al cliente no solo el hardware, sino también el sistema operativo y parte del software de usuario.

La primera estación de trabajo de NeXT fue presentada el 12 de octubre de 1988. Recibiría oficialmente el nombre de NeXT Computer, si bien fue ampliamente conocida como "El Cubo" ("The Cube", en idioma inglés) por su distintiva caja de aleación de magnesio en forma de cubo. El sistema operativo de la nueva máquina fue bautizado como NeXTSTEP. 

Las ventas de los computadores de NeXT fueron relativamente modestas, con un total estimado de 50 000 unidades en los 10 años que estuvo operativa la división de hardware. Su sistema operativo orientado a objetos y entorno de desarrollo fueron, en cambio, muy influyentes. A pesar de su escasa penetración en el mercado, uno de estos equipos sirvió para que el científico Tim Berners Lee creara el concepto de World Wide Web que revolucionaría a la red Internet.

Como consecuencia, Jobs en 1993 centró la estrategia de su compañía en la producción de software, cambiando el nombre de la empresa por el de Next Software Inc. Uno de las decisiones más llamativas fue la venta de equipos NeXT construidos alrededor de los microprocesadores Intel 486 y SPARC.

Apple Computer anunció el 20 de diciembre de 1996 la adquisición de NeXT Software por 400 millones de dólares con el fin de actualizar el sistema operativo de las computadoras Macintosh, después del fracaso de la compañía con "Copland", un proyecto que nunca llegó a terminarse. Así, Steve Jobs volvió a formar parte de la compañía Apple.

La vuelta de Steve Jobs a la empresa Apple se produjo cuando la empresa se encontraba en declive, así que se decidió a recuperar el control de ésta, se ganó la confianza de la dirección de la compañía en detrimento del entonces director ejecutivo, Gil Amelio, logrando que se lo nombrara director interino el 16 de septiembre de 1997.

Algunas de las primeras medidas de Jobs en su nuevo puesto fueron firmar un acuerdo con Microsoft, por el cual esta empresa invertiría dinero en Apple a cambio de un 4% de sus acciones, aunque este porcentaje no le diera el derecho a voto en las decisiones de la junta directiva de la empresa; el suministro del software de ofimática Office para los computadores Macintosh y el fin de las disputas por la interfaz gráfica. La noticia de esta medida no fue bien recibida.

De similar aceptación resultaron la cancelación del programa de licencias de Mac OS a otros fabricantes de hardware, como "Power Computing", empresa que sería finalmente adquirida por Apple, lo que impidió la popularización de esta plataforma informática y el descontinuar el "Apple Newton", un dispositivo de características similares a un asistente digital personal. 
Estas medidas, sin embargo, permitieron a la compañía centrar sus esfuerzos en mejorar sus productos y probar nuevas líneas de negocio, como la tienda digital de música "iTunes Store", los reproductores de audio iPod y los computadores iMac, que resultaron ser un gran éxito.

En 2006 Jobs firmó un contrato con Intel para utilizar procesadores de la arquitectura x86 en todos sus computadores de escritorio y portátiles.

En diciembre de 2009 Steve Jobs fue elegido director ejecutivo del año por la revista "Harvard Business Review" por «incrementar en 150 000 millones el valor en bolsa de Apple en los últimos 12 años».

El 24 de agosto de 2011 presentó su renuncia como CEO de Apple, y fue sustituido por Tim Cook. A partir de esta fecha y hasta su muerte, fue el presidente de la Junta Directiva de Apple.Horas después del anuncio, se redujo en 5 puntos porcentuales el valor de las acciones de Apple. Según la revista de finanzas Forbes, la renuncia afectaría negativamente a Apple y otras empresas, incluyendo Walt Disney Company donde Jobs era director. El día 24 de agosto de 2011, el valor de las acciones de Walt Disney Co. se redujo en 1,5 puntos porcentuales.

Estuvo casado desde 1991 con Laurene Powell, a quien conoció en la Universidad de Stanford. Vivieron en Palo Alto, California, con sus tres hijos. Steve tuvo además otra hija llamada Lisa, fruto de una relación de juventud con Chris Ann Brennan, su paternidad no la reconoció sino hasta 1991. Sufrió varios problemas graves de salud. En 2004 se le diagnosticó un cáncer de páncreas, enfermedad que superó tras un tratamiento en una clínica oncológica californiana. A principios del 2009 anunció que padecía un desequilibrio hormonal y que debía apartarse necesariamente de la compañía, y delegó la mayor parte de sus responsabilidades en Timothy Cook, por entonces jefe de comunicaciones. En abril de 2009 se sometió a un trasplante de hígado, y en septiembre de ese mismo año volvió al trabajo. El 17 de enero de 2011, Jobs dejó nuevamente Apple por problemas médicos, a poco más de un mes de la presentación del iPad 2. Mientras tanto, la compañía quedó a cargo de Tim Cook.Jobs presentó públicamente el iPad 2 el miércoles 2 de marzo.No obstante, declaró que desde su residencia seguiría ocupándose de las decisiones más relevantes de la compañía, como en efecto ocurrió.

En octubre de 2003 se le diagnosticó un cáncer, y a mediados de 2004 anunció a sus empleados que tenía un tumor canceroso en el páncreas.

A principios de agosto de 2006 Jobs realizó una presentación en la Conferencia Anual de Desarrolladores de Apple (WWDC). Su aspecto demacrado y delgado y su inusual presentación apática, junto con la delegación de la exposición de partes importantes a otros participantes, suscitó una oleada de especulaciones acerca de su salud. Sin embargo, de acuerdo con un artículo de Ars Technica los asistentes a la Conferencia que vieron a Jobs dijeron que tenía buen aspecto. Después de la presentación un portavoz de Apple dijo que Steve tenía una salud de hierro.

Dos años después también surgieron preocupaciones tras la presentación de la WWDC de 2008. Los responsables de Apple afirmaron que Jobs padecía una afección corriente y que estaba tomando antibióticos, mientras que otros achacaban su estado demacrado al procedimiento Whipple aplicado en su cirugía. Durante una conferencia en julio en la que se discutía sobre los beneficios de Apple, los participantes respondieron a las preguntas sobre la salud de Jobs que era un “asunto privado”. Otros opinaron que los accionistas tenían el derecho a saber más dado el estilo personal de Jobs al dirigir la compañía. "The New York Times" 
publicó un artículo basado en una conversación telefónica “extraoficial” con Jobs en la que decía que “aunque sus problemas de salud eran más que una afección corriente, no suponían una amenaza a su vida y que no tenía ninguna reaparición de cáncer.”

El 28 de agosto de 2008 el servicio de noticias de empresa Bloomberg publicó por error un obituario de Jobs de 2500 palabras que contenía espacios para su edad y la causa de la muerte. (Las agencias de noticias suelen ir actualizando obituarios para facilitar la salida de noticias para el caso en que una persona conocida muera de forma repentina). Aunque el error se rectificó inmediatamente, muchas agencias de noticias escribieron sobre él, intensificando los rumores sobre la salud de Jobs. Jobs respondió en el discurso de apertura de “Let's Rock” de septiembre de 2008 citando a Mark Twain:
“Las noticias de mi muerte son muy exageradas.” En un acto posterior Jobs terminó su presentación con una diapositiva en la que se leía “110/70”, en referencia a su presión sanguínea, y dijo que no respondería más preguntas sobre su salud.

El 16 de diciembre de 2008 Apple anunció que el vicepresidente de marketing Philip W. Schiller daría el último discurso en la Conferencia Macworld de 2009. Esto reactivó las preguntas sobre la salud de Jobs. En una declaración del 5 de enero de 2009 en Apple.com, Jobs dijo que había estado sufriendo un desequilibrio hormonal durante varios meses.

El 14 de enero de 2009 en un memorando interno de Apple Jobs escribió que la semana anterior supo que los asuntos relacionados con su salud eran más complejos de lo que pensaba, y anunció una excedencia de seis meses hasta el final de junio de 2009 para poder centrarse en su salud. Tim Cook, que anteriormente había sido Director Ejecutivo durante la ausencia de Jobs en 2004, volvió a ser Director Ejecutivo en funciones, estando Jobs involucrado en las “decisiones estratégicas fundamentales”.

En abril de 2009, Jobs fue sometido a un trasplante de hígado en el Methodist University Hospital Transplant Institute en Memphis, Tennessee. El diagnóstico fue descrito como “excelente”.

El 17 de enero de 2011, un año y medio después de su trasplante de hígado, Apple anunció que le había concedido una excedencia por enfermedad. Jobs anunció su salida en una carta a sus empleados, afirmando que tomó su decisión “para poder centrarse en su salud”. Como en la excedencia por enfermedad de 2009, Apple anunció que Tim Cook llevaría las operaciones cotidianas y que Jobs seguiría involucrado en las decisiones estratégicas importantes. A pesar de la excedencia, tuvo apariciones en el lanzamiento del iPad 2 el 2 de marzo, la presentación WWDC introduciendo iCloud el 6 de junio, y ante el Ayuntamiento de Cupertino el 7 de junio.

Jobs anunció su renuncia como Director Ejecutivo de Apple el 24 de agosto de 2011. “Desafortunadamente, ese día ha llegado”, escribió Jobs, “porque ya no puedo cumplir mis deberes y expectativas como Director Ejecutivo de Apple”. Jobs pasó a Presidente del Consejo de Administración y nombró a Tim Cook como su sucesor. Jobs trabajó para Apple hasta el día antes de su muerte.

Steve Jobs falleció en su casa de California a las 3 de la tarde del 5 de octubre de 2011, a los 56 años, a consecuencia de un paro respiratorio derivado de las metástasis del cáncer de páncreas que le fue descubierto en 2004, por el que en 2009 había recibido un trasplante de hígado. 
El día anterior había perdido la conciencia y murió estando su esposa, hijos y hermana a su lado.
Su muerte fue anunciada por Apple con una declaración:

Jobs deja a Laurene, su esposa durante 20 años, tres hijos y a Lisa Brennan-Jobs, su hija de una relación anterior. Su familia hizo una declaración diciendo que murió en paz.

Según dijo en el funeral su hermana biológica, Mona Simpson, Jobs miró a su hermana Patty, luego a sus hijos durante un largo rato, después a su esposa Laurene. Sus últimas palabras dichas unas horas antes de su muerte fueron 

En las dos semanas posteriores a su muerte la Web de Apple presentó una página con el nombre de Jobs, su fecha de nacimiento y fallecimiento y un retrato en blanco y negro. Haciendo clic en la imagen se presentaba la nota necrológica que decía:

También Pixar dedicó a Jobs su página web. John Lasseter y Ed Catmull, escribieron un discurso que decía:

Un pequeño funeral privado tuvo lugar el 7 de octubre de 2011 cuyos detalles no han sido revelados por respeto a la familia de Jobs. 

Jobs está enterrado en Alta Mesa Memorial Park, el único cementerio no confesional de Palo Alto.

Importantes personalidades declararon su pesar por el fallecimiento de Steve Jobs, entre ellos: Barack Obama (presidente de los Estados Unidos), Bill Gates y Paul Allen (cofundadores de Microsoft Windows), Sergey Brin y Larry Page (cocreadores de Google), Steven Spielberg (reconocido cineasta estadounidense), Steve Wozniak (compañero cofundador de Apple) y Mark Zuckerberg (fundador de Facebook) entre otros.

Bill Gates:
Steve Wozniak:
Steven Spielberg:
Mark Zuckerberg:

Richard Stallman es fundador del movimiento por el software libre en el mundo y de la GNUPedia, considerada como un antecedente directo de la Wikipedia: 

El pionero del software libre Richard Stallman disintió de las hagiografías mayoritarias para centrar la atención en el férreo control que Apple tuvo sobre las computadoras y los aparatos portátiles, cómo Apple restringió el acceso a los periodistas y cómo violó la privacidad continuamente: “Steve Jobs, el pionero de la computadora como una cárcel hecha atractiva, diseñada para recortar a los necios su libertad, ha muerto”.

El reportero de Silicon Valley Dan Gillmor dijo: 

Aunque los reporteros escribieron elegías elogiosas tras la muerte de Jobs, el crítico James Rainey de Los Angeles Times escribió que: 
Malcolm Gladwell en The New Yorker afirmó que: 

El día de su muerte la capitalización bursátil de "Apple" era de 350 670 millones de dólares. Cuando salió a bolsa en 1980 una acción costaba, según su precio ajustado, lo que hoy serían unos dos euros. El día en que murió, una acción valía más de 280 euros (377 dólares) incluyendo unos intereses financieros envidiables. Estos datos avalan el reconocimiento como ejecutivo que lo acompañó en la última etapa de su carrera. En palabras de Rupert Murdoch, «Steve Jobs fue simplemente el mejor consejero delegado de su generación.» Coincidía en ello con la revista "Harvard Business Review", que ya lo reconoció como tal a finales del 2009.








</doc>
<doc id="15320" url="https://es.wikipedia.org/wiki?curid=15320" title="Butano">
Butano

El butano, también llamado n-butano, es un hidrocarburo saturado, parafínico o alifático, inflamable, gaseoso que se licúa a presión atmosférica a -0,5 °C, formado por cuatro átomos de carbono y por diez de hidrógeno, cuya fórmula química es CH.También puede denominarse con el mismo nombre a un isómero de este gas: el isobutano o metilpropano.

Como es un gas incoloro e inodoro, en su elaboración se le añade un odorizante (generalmente un mercaptano) que le confiere olor desagradable. Esto le permite ser detectado en una fuga, porque es altamente volátil y puede provocar una explosión.

En caso de extinción de un fuego por gas butano se emplea dióxido de carbono (CO), polvo químico o niebla de agua para enfriar y dispersar vapores.

El butano comercial es un gas licuado, obtenido por destilación del petróleo, compuesto principalmente por butano normal (60%), propano (9%), isobutano (30%) y etano (1%).

La principal aplicación del gas butano (CH) es como combustible en hogares para la cocina y agua caliente, y en los encendedores de gas. No suele consumirse en grandes cantidades debido a sus limitaciones de transporte y almacenaje. Aunque también se emplea como combustible para encendedores de bolsillo.

En España el gas butano se transporta en la típica bombona o garrafa de butano, que es un envase cilíndrico, que se dilata cuando la temperatura del butano aumenta en exceso, de paredes de acero, normalmente de color naranja (también llamado por ello "color butano"), y que contiene 12,5 kg de butano. También existen nuevas bombonas de butano más ligeras, fabricadas con acero inoxidable en lugar de hierro fundido.

Su regulación aparece en el Real Decreto 1085/1992 de 11 de septiembre por el que se aprueba el Reglamento de la actividad de distribución de Gases Licuados del Petróleo. En su artículo 22, determina las obligaciones de los titulares de los contratos de dicho suministro. Entre ellas, se encuentra la revisión de la instalación cada cinco años por una empresa instaladora legalmente habilitada para ello.Similares medidas se han tomado en otros países.

Su fórmula estructural es:





</doc>
<doc id="15321" url="https://es.wikipedia.org/wiki?curid=15321" title="Bartsia trixago">
Bartsia trixago

Bartsia trixago es una planta anual común en caminos y cunetas (rara en cultivos) originaria de Europa circum-mediterránea y Norte de África.
Se trata de una planta hemiparásita -de raíces y sin huésped específico-, en pastizales y herbazales de secano. 
Lo más llamativo de su inflorescencia es la corola bilabiada, que puede ser discolora, y sus grandes brácteas. Sus flores pueden variar de tonos blancos a rosados, pero es habitual encontrar ejemplares con flores completamente amarillas, pudiendo confundirse con "Parentucellia viscosa", de aspecto muy similar.

Llega hasta 70 cm de altura, pero normalmente no pasa de los 40-50 cm. Los tallos son erectos, simples o poco ramificados. Las hojas (14)20–60(73) por (2)4–9(12) mm, opuestas, amplexicaules, erecto–patentes, rectas o incurvas, lineares o linear–lanceoladas, remotamente aserradas, estrigosas. La inflorescencia mide 2–16 cm, en racimo espiciforme, denso y las brácteas hasta 25 por 8(12) mm, con indumento muy denso, las inferiores foliáceas, las superiores enteras, ovadas, cordadas. Las flores son zigomorfas, hermafroditas, pentámeras, subsésiles con un cáliz 4–10 mm, ventricoso, dividido en 2 labios laterales bilobados y una de corola 10–20 mm, bilabiada, puberulento–glandulosa, blanca con tonos rosados o amarilla, con labio superior galeado y tubo de 8–10 mm, más largo que el cáliz.
El fruto es una cápsula de 6–12 por 4–6 mm, ovoidea, pelosa con semillas de 0,6–0,7 por 0,4–0,5 mm, algo reniformes, pardo–claras, casi rosadas. El número de cromosomas es de 2n = 24.

Esta especie de origen circummediterráneo ha sido introducida en América, Australia y Sudáfrica. También ha llegado a colonizar las Islas Canarias y Madeira, probablemente como especie exótica invasora.

Tiene gran indiferencia edáfica, pues está ligada a la presencia de plantas que parasita, que será el único requisito para su establecimiento. Pero muestra cierta predilección por suelos básicos, zonas calizas y yesíferas.
La podemos encontrar en herbazales y pastizales efímeros, cunetas y claros de matorral, a veces con cierto comportamiento ruderal.

Crece desde el nivel del mar hasta los 1.300 metros, ocupando los pisos termo y mesomediterráneo. Ombroclima seco. 





</doc>
<doc id="15322" url="https://es.wikipedia.org/wiki?curid=15322" title="Justo José de Urquiza">
Justo José de Urquiza

Justo José de Urquiza (Talar de Arroyo Largo, hoy Arroyo Urquiza, Virreinato del Río de la Plata, 18 de octubre de 1801-Palacio San José, cerca de Concepción del Uruguay, Entre Ríos, 11 de abril de 1870) fue un militar y político argentino. Fue varias veces gobernador de la provincia de Entre Ríos, líder del Partido Federal y de la Confederación Argentina entre 1854 y 1860. Fue asesinado durante la presidencia de Domingo Faustino Sarmiento.

Su padre, Joseph Narciso de Urquiza y Álzaga, era un colono español que se unió en matrimonio con la infanzona María Cándida Ramón-García Monzón de origen luso-hispano-argentino, siendo ésta una descendiente de los portugueses Inés Nunes Cabral de Melo y de Gil Gonçalves de Moura.
Ambos se radicaron en la Intendencia de Buenos Aires, en la actual provincia de Entre Ríos, dedicándose a la actividad rural y a la función pública. Luego de la Revolución de Mayo, en 1810, emigraron a la Banda Oriental para seguir siendo fieles al Reino de España.

Regresaron en 1812, y cinco años más tarde Justo José fue enviado al Colegio de San Carlos en Buenos Aires.

En 1819 se instaló en la pujante villa Arroyo de La China, actual Concepción del Uruguay, dedicándose a la actividad rural y comercial, para la cual demostró una enorme capacidad. Su hermano mayor, Cipriano de Urquiza, fue secretario y luego ministro del primer gran caudillo entrerriano, Francisco Ramírez.

En 1820 tuvo su primera hija extramatrimonial; más tarde tendría muchos más hijos ilegítimos. Una ley sancionada durante su presidencia legalizaría varios de ellos. Le fueron legalmente reconocidos 23 hijos por la Ley Federal Nº 41 en donde ponía en un pie de igualdad a los 11 hijos legítimos con los extramatrimoniales que tuvo de soltero (hay versiones que señalan que tuvo entre 105 y 114 hijos en toda su vida).

En la década de 1820, contando ya con una fortuna que lo respaldaba, se interesó en la política en un período especialmente turbulento en la historia de Entre Ríos. Como muchos jóvenes del interior, su partido era el Federal.

En 1826 fue electo por los vecinos de Concepción del Uruguay para representarlos como diputado en el congreso provincial. Dirigió la oposición a la Constitución Argentina de 1826, que fue rechazada por su provincia.

Desde 1828 en adelante fue comandante militar y civil de Concepción del Uruguay. Dos años más tarde apoyó la invasión a su provincia del general unitario Juan Lavalle y de Ricardo López Jordán (padre). Tras el fracaso de esa invasión, apoyó otra en 1831 que, al fracasar también, lo obligó a refugiarse en Santa Fe, bajo la protección del caudillo Estanislao López.

Al año siguiente acompañó a Pascual Echagüe en la campaña militar que llevaría a éste a la gobernación de Entre Ríos. Bajo su gobierno, Entre Ríos conoció un período de paz, reforzado por la influencia pacificadora del gobernador porteño Juan Manuel de Rosas. A partir de 1835, éste gobernó como un dictador electo por el voto popular de su provincia. Extendió su dominio sobre las demás provincias, ejerciendo de hecho un poder central que no le correspondía de derecho. Echagüe hizo un gobierno progresista y se ahorró problemas apoyando a Rosas en su oposición a la sanción de una constitución nacional.

Urquiza fue nombrado comandante de toda la costa del río Uruguay, con el grado de coronel. Durante esa década se convirtió en uno de los hacendados y comerciantes más ricos del país y extendió una poderosa red de clientelismo económico, que le serviría más tarde de apoyo político.

Entre Ríos era un territorio que ocupaba una posición estratégica, ya que estaba cerca de Buenos Aires, de la conflictiva Banda Oriental, del Imperio del Brasil y de la provincia de Corrientes. En su territorio se dieron grandes batallas.

A mediados de 1838, la tranquilidad de la provincia se vio amenazada por la sublevación de Fructuoso Rivera, que derrocó al presidente uruguayo Manuel Oribe. También ese año murió Estanislao López, y Echagüe forzó la ubicación en la gobernación santafesina de su hermano Juan Pablo López.

La primera provincia en rebelarse militarmente contra Rosas fue Corrientes. Su gobernador, Genaro Berón de Astrada retiró la delegación de las relaciones exteriores a Rosas y le declaró la guerra, como así también a Echagüe. Berón tuvo que enfrentar con sus solas fuerzas el ataque que le lanzó Echagüe, uno de cuyos jefes de división era Urquiza.

Los ejércitos se encontraron en la batalla de Pago Largo, cerca de Curuzú Cuatiá, el 31 de marzo de 1839. Fue una completa victoria de los federales, en la que Urquiza tuvo una actuación destacada, y Berón resultó muerto en la persecución que siguió a la batalla. Después de la misma, centenares de prisioneros fueron ejecutados; en general, los correntinos acusaron a Urquiza por esos crímenes.

Después de colocar un gobernador federal en Corrientes, Echagüe pasó con su ejército a Uruguay. Rivera lo derrotó en la batalla de Cagancha, el 29 de diciembre, en la que la indecisión del general Lavalleja fue más importante que la brillante actuación de Urquiza. Desde ese momento, las relaciones de Urquiza con Echagüe fueron muy malas.

En su ausencia, Lavalle había invadido la provincia, pasando a continuación a Corrientes. Allí reunió un nuevo ejército, con el que a mediados de 1840 invadió Entre Ríos. Mientras Urquiza controlaba la costa del Uruguay, Echagüe lo enfrentó en dos batallas indecisas. Urquiza derrotó a uno de los coroneles unitarios en Arroyo del Animal, cerca de Gualeguay. Poco después, Lavalle pasaba hacia la provincia de Buenos Aires; allí intentaría ocupar la capital, pero sería derrotado sin lucha e iniciaría una marcha hacia el norte, encontrando la derrota en Tucumán y la muerte en Jujuy.

Algunos meses después, Echagüe invadió Corrientes, dejando a Urquiza protegiendo sus espaldas. El nuevo comandante de Corrientes era José María Paz que derrotó fácilmente a Echagüe en la batalla de Caaguazú, el 28 de noviembre de 1841.

Poco después de la derrota venció el cuarto mandato de Echagüe. El 15 de diciembre de 1841, la legislatura eligió gobernador a Justo José de Urquiza. No dejaría el poder en la provincia hasta su muerte, casi treinta años más tarde. Fue gobernador durante 18 años, a lo que hay que sumar seis años de federalización de la provincia bajo su propia presidencia, y cuatro de un empleado suyo. En total, 28 años; más que Rosas en Buenos Aires.

La situación era muy delicada; Urquiza emitió una proclama, en que decía que 

Enseguida delegó el mando en Vicente Zapata, y abandonó la capital. Días después, Paz ocupaba Paraná y Rivera Concepción del Uruguay. Urquiza se retiró a la isla del Tonelero, protegida por pantanos y arroyos, donde se puso a organizar un ejército con miles de voluntarios entrerrianos, a quienes formó militarmente. Entre ellos estaba un joven, hijo de un viejo general que estaba prisionero de Rosas por unitario: era Ricardo López Jordán. Durante un corto período se trasladó a la provincia de Buenos Aires.

Paz se hizo elegir gobernador, pero la falta de ayuda del gobernador correntino Pedro Ferré lo obligó a ir en busca de Rivera, cruzando la provincia. En el camino perdió casi todo su ejército, que pasó a engrosar el de Urquiza. Éste ocupó Paraná sin oposición, y enseguida inició la campaña en el interior de la provincia.

Simultáneamente, Manuel Oribe regresaba desde el norte, donde había derrotado a Lavalle, y atacó al gobernador santafesino Juan Pablo López (que se había pasado de bando), derrotándolo con facilidad. Echagüe se hizo cargo del gobierno santafesino y Oribe cruzó el Paraná, siguiendo su marcha hacia el Uruguay.

Rivera tomó el mando del ejército unido uruguayo-unitario. Urquiza se unió a Oribe y juntos avanzaron hacia el río Uruguay, cerca del cual derrotaron completamente a sus enemigos en la batalla de Arroyo Grande, el 6 de diciembre de 1842.

Mientras Oribe continuaba su avance hacia Montevideo, ocupando la mayor parte del territorio uruguayo, Urquiza invadió Corrientes, donde colocó un gobernador federal, Pedro Cabral, y dejó una guarnición entrerriana en Goya, al mando del general José Miguel Galán.

Después acompañó el lento - demasiado lento - avance de Oribe hacia la capital uruguaya, a la que puso sitio. Así se iniciaba el período que los uruguayos llaman la "Guerra Grande".

En Corrientes, una reacción dirigida por Joaquín y Juan Madariaga tomó el poder y expulsó a los entrerrianos. Enseguida atacaron Entre Ríos; la defensa quedó a cargo del general uruguayo Eugenio Garzón, mientras una rebelión en el interior de la provincia costaba la muerte de Cipriano de Urquiza. Los correntinos evacuaron Entre Ríos, y Urquiza pudo seguir sus campañas en el Uruguay; allí derrotó a Rivera junto al río Yí, y el 27 de marzo de 1845 lo venció definitivamente en la batalla de India Muerta. Nuevamente fue acusado de haber ejecutado cientos de prisioneros.

El bloque anglo – francés y las actividades de corsarios al servicio del gobierno de Montevideo continuaron afectando al gobierno entrerriano. El capitán italiano Giuseppe Garibaldi saqueó Gualeguaychú; y a los pocos días el griego Cardassy capturó todos los barcos del puerto de Paraná.

En Corrientes, los Madariaga habían puesto al frente de su ejército al general Paz, que organizó un nuevo ejército. Urquiza invadió la provincia y derrotó a Juan Madariaga en la batalla de Laguna Limpia, tomándolo prisionero. Por su archivo se enteró de que Paz pretendía llevarlo hasta el extremo norte de la provincia, para derrotarlo en una trampa parecida a la que había usado para vencer a Echagüe. Por eso continuó avanzando, saqueó la provincia, se hizo amigos correntinos y al llegar hasta la trampa de Paz dio media vuelta y regresó a Entre Ríos.

Desde allí inició negociaciones con el gobernador correntino a través de su hermano. Paz se opuso e intentó derrocar a Madariaga, pero fracasó y terminó huyendo. Urquiza firmó el Tratado de Alcaraz con el gobierno correntino, por el cual se arreglaba la paz y se devolvía el encargo de las relaciones exteriores a Rosas, pero Corrientes quedaba liberada de la obligación de apoyar la guerra en el Uruguay, y además se preveía la pronta convocatoria a un congreso constituyente.

Rosas rechazó el tratado y, contra su voluntad, Urquiza se vio obligado a invadir nuevamente Corrientes. Derrotó a los Madariaga en la batalla de Vences o de Rincón de Vences, el 27 de noviembre de 1847. Según sus detractores, Urquiza habría perpetrado allí su peor matanza de prisioneros. Aunque es probable que ésta haya ocurrido, posiblemente se debió a sus aliados correntinos.

Los Madariaga huyeron al Brasil, y Urquiza puso en el gobierno correntino a su amigo Benjamín Virasoro. La guerra había terminado; por supuesto, aún quedaba Oribe sitiando Montevideo, pero se descontaba que la ciudad caería de un momento a otro.

Su gobierno fue paternalista, en el sentido de que gobernó sin consultar al pueblo, pero en beneficio de éste. Gobernaba desde Concepción del Uruguay o desde su campamento militar de Calá. En varios sentidos fue muy similar a Rosas y a otros caudillos de la época. Protegió a la ganadería, favoreció la instalación de saladeros de carne vacuna, hizo exigir la papeleta de conchabo a todos los peones rurales, mejoró los caminos y los puertos, instaló molinos de agua, y ayudó al establecimiento de pequeñas industrias. Ejerció un poder de policía muy eficaz, pero muy cruel, ya que a la menor falta, los delincuentes eran sencillamente ejecutados.

Ordenó llevar la contabilidad con una precisión desconocida hasta entonces. Impuso un control fiscal estricto, y una dedicación intensa a los funcionarios y empleados; redujo el gasto público sin descuidar las funciones del estado, e hizo publicar mes por mes los gastos e ingresos por la prensa.

Su principal preocupación fue la educación; extendió las escuelas primarias que había fundado su antecesor y fundó nuevas escuelas secundarias, públicas y modernas. La primera que fundó fue la de Paraná, dirigida por Manuel Erausquin. Tras una serie de conflictos con el gobierno de esa ciudad, el cuerpo de profesores pasó al otro colegio fundado por Urquiza, el actual Colegio Nacional de Concepción del Uruguay. Tendría un gran auge durante el tiempo en que Buenos Aires se separara de la Confederación, bajo la dirección de Alberto Larroque, que lo transformó en el colegio secundario más moderno de su época, y por muchos años compitió en prestigio con el de Buenos Aires y el de Córdoba.

Se llegaron a publicar tres periódicos simultáneamente; se fundaron teatros, escuelas secundarias de mujeres, bibliotecas públicas, etc. Llamó a su provincia a varios emigrados ilustres, sobre todo a federales antirrosistas, como Pedro Ferré, Manuel Leiva y Nicasio Oroño, pero también a unitarios como Marcos Sastre y otros. El ambiente que se respiraba en la provincia era mucho más libre que el de Buenos Aires u otras ciudades del interior.

El ambiente de libertad, que tanto contrastaba con el de Buenos Aires, llamó la atención de los emigrados y unitarios. Muchos, como Sarmiento o el general Paz, comenzaron a pensar que Urquiza sería el elegido por la historia para convocar un congreso constituyente y derrocar a Rosas.

A pesar de que la ciudad de Montevideo estaba sitiada y en guerra con las provincias argentinas, Urquiza logró mantener abiertos los puertos de su provincia al comercio con esa plaza. Según el punto de vista de Rosas, se trataba de contrabando; pero como el gobernador porteño necesitaba a Urquiza, lo permitió de hecho.

Rosas seguía sosteniendo que, dado que el país no estaba en paz, no era tiempo aún de sancionar una constitución. Pero también es cierto que la misma política exterior de Rosas mantenía el estado de conflicto exterior constante. De hecho, Rosas fue repetidamente acusado de mantener a la Confederación en guerra, para así posponer indefinidamente la sanción de la Constitución.

A mediados de 1850, cuando la ciudad sitiada de Montevideo estaba por caer, el Imperio del Brasil decidió apoyar a los sitiados. En respuesta, Rosas inició el proceso para llegar a una guerra contra el Imperio. Varios opositores interpretaron que el gobernador porteño estaba abriendo un nuevo frente de conflicto, para seguir posponiendo el momento de la sanción de la Constitución; Urquiza se plegó a esa interpretación, pero aún no mostró ningún síntoma en ese sentido.

Rosas lo nombró comandante del ejército de operaciones contra Brasil, y le envió armamento y refuerzos. Pero, al mismo tiempo, le exigió suspender el tráfico mercantil con Montevideo.

Urquiza comenzó a contactar a los emigrados de Montevideo, y posteriormente también a los representantes del Imperio. Para lanzarse a la aventura de enfrentar a Rosas, necesitaba dinero y la seguridad de que sería apoyado. A principios del año siguiente comenzó a llegar ese dinero, en abundancia, provisto por la cancillería brasileña. Entonces Urquiza hizo su primer movimiento.

En enero de 1851 apareció en el periódico "La Regeneración" de Concepción del Uruguay titulado "El año 1851", que indicó el puntapié inicial de la ruptura con Rosas.

El 1.º de mayo de 1851, se anunció el llamado "Pronunciamiento de Urquiza". Se trató de un anuncio de la legislatura entrerriana, en que se aceptaban las repetidas renuncias de Rosas a la gobernación de Buenos Aires y a seguir haciéndose cargo de las relaciones exteriores. Reasumía también el manejo de la política exterior y de guerra de la provincia. Por último, se reemplazaba de los documentos el ya familiar "¡Mueran los salvajes unitarios!", por la frase "¡Mueran los enemigos de la organización nacional!".

Dejando de lado el eufemismo de aceptar las renuncias de Rosas, se trataba de una reacción contra la dominación política y económica de la provincia de Buenos Aires, con objetivos políticos y económicos, ocupando en principio la organización constitucional un lugar secundario.

La única provincia que apoyó el Pronunciamiento fue Corrientes; las demás condenaron en todos los documentos públicos la actitud de Urquiza y, siguiendo el modelo de la prensa porteña, lo tacharon de "loco, traidor, salvaje, unitario…"

A fines de mayo se firmó un tratado entre Entre Ríos, el gobierno de Montevideo y el Imperio del Brasil. Acordaba una alianza entre los tres para expulsar a Oribe, llamar a elecciones libres en todo el territorio uruguayo, y enfrentar juntos a Rosas, si éste declaraba la guerra a una de las partes, lo que se daba por descontado.

En julio de ese año, el ejército entrerriano cruzó el río Uruguay. En el camino se le unió la mayor parte del ejército de Oribe, que se puso a órdenes del general Garzón, candidato a presidente de los aliados. Y por el norte entraron los brasileños. El ejército avanzó sin oposición hasta las inmediaciones del campamento del Cerrito, donde se iniciaron conversaciones de paz con Oribe. El 8 de octubre se firmó un pacto entre las partes, por el que las fuerzas de Oribe se incorporaban al ejército de Urquiza, y un olvido de todas las querellas, "ni vencedores, ni vencidos". Oribe se retiró a su estancia, donde moriría pocos años después.

Urquiza incorporó a su ejército, a la fuerza, las tropas argentinas que sitiaban Montevideo, pero dejó escapar a sus jefes. Entre los que se retiraron a Buenos Aires se contaban algunos jefes valiosos, como los coroneles Jerónimo Costa, Hilario Lagos y Mariano Maza.

El congreso uruguayo tuvo que firmar un tratado con el Brasil, por el que se le reconocía al Imperio el derecho de intervenir en su política interna y se le entregaba una gran franja limítrofe, hasta entonces en disputa entre los dos países, poco menos de la tercera parte de su superficie.

Rosas declaró públicamente la guerra al Brasil, lo que permitió a Urquiza firmar un nuevo tratado de alianza contra el gobernante argentino.

Urquiza regresó a Entre Ríos, donde reunió el llamado "Ejército Grande", formado por tropas entrerrianas, correntinas, los emigrados unitarios, los soldados argentinos del sitio, unidades "coloradas" del ejército uruguayo y tropas del Imperio. Con ellas cruzó el río Paraná en buques brasileños y, aprovechando la defección de varias unidades del ejército de Rosas, derrocó al gobernador santafesino Echagüe.

En camino hacia Buenos Aires ocurrió un hecho que mostraba la lealtad de los porteños hacia Rosas. Un regimiento entero se pasó a las fuerzas de Buenos Aires, asesinando al coronel unitario Pedro León Aquino y a casi todos los oficiales; eran de las fuerzas porteñas que habían sido obligadas a unirse a Urquiza en Montevideo.

Como de costumbre, Rosas puso al mando de las fuerzas de la provincia al general Ángel Pacheco; pero éste no respondió como debía y dejó avanzar al ejército hacia Buenos Aires. De modo que Rosas cometió un grave error estratégico: asumió él mismo el mando de su ejército y esperó a Urquiza cerca de su campamento de Santos Lugares.

El 3 de febrero de 1852 se encontraron los 24 mil hombres de Urquiza con los 23 mil de Rosas en la batalla de Caseros. 

Tras pocas horas de batalla, la victoria fue para Urquiza. Hubo muchos ejecutados, como los coroneles Martiniano Chilavert y Martín Santa Coloma; y todos los soldados del regimiento de Aquino, que fueron colgados de los árboles del parque de Palermo.

Rosas se exilió en Inglaterra, y Urquiza asumió por sí mismo el gobierno provincial. Dos días después de la batalla nombró gobernador a Vicente López y Planes.

El 20 de febrero, el comandante brasileño anunció el desfile triunfal en Buenos Aires. Pero Urquiza recorrió la ciudad sin esperar al ejército brasileño, ya que era una humillación especialmente buscada, dado que era el aniversario de la victoria argentina de Ituzaingó.

Apenas llegada a Montevideo y a los demás países vecinos la noticia de Caseros, los emigrados emprendieron el regreso a Buenos Aires. Los rosistas, por su parte, no se resignaban a perder su lugar destacado en la sociedad. Así se formaron dos grupos políticos netamente diferenciados: por un lado, los federales o urquicistas, que defendían el proceso de organización nacional bajo un poder federal. Entre sus integrantes estaban Vicente López y Planes, su hijo Vicente Fidel López, Francisco Pico y Juan María Gutiérrez. Por su parte, el Partido Liberal –muy heterogéneo– estaba formado por los partidarios de la ruptura con la Confederación. En sus filas destacaban Valentín Alsina, Bartolomé Mitre, Dalmacio Vélez Sársfield y Domingo Faustino Sarmiento. Todos ellos se oponían a la política de Urquiza, a quien consideraban un caudillo provinciano que aspiraba a dominar a la provincia, a la capitalización de Buenos Aires, y a la nacionalización de los derechos de la aduana. Proponían el aislacionismo de la provincia y aun la secesión de la misma del Estado nacional.

Apenas entrado en Buenos Aires, Urquiza envió una misión a las provincias, para explicar sus intenciones de restablecer la vigencia del Pacto Federal y emprender la organización constitucional. Bernardo de Irigoyen cumplió eficazmente su cometido: las provincias delegaron en Urquiza el manejo de las relaciones exteriores y aceptaron el proyecto de organización nacional.

El 6 de abril, los representantes de Buenos Aires, Corrientes, Entre Ríos y Santa Fe firmaron el Protocolo de Palermo, que restablecía la vigencia del Pacto Federal, delegaba en Urquiza el manejo de las relaciones exteriores y le encargaba la reunión de un Congreso Constituyente. Para agilizar la reunión del congreso constituyente y fundamentar legalmente su autoridad, Urquiza invitó a los gobernadores de todas las provincias a una reunión que se celebraría en San Nicolás de los Arroyos.

El 31 de mayo se firmó el Acuerdo de San Nicolás. El mismo establecía –entre otros puntos– la vigencia del Pacto Federal de 1831; la reunión de un congreso general constituyente en Santa Fe a partir de agosto de ese mismo año, integrado por dos diputados por cada provincia, los cuales actuarían sin instrucciones que restringieran sus poderes; y la creación del cargo de "Director provisorio de la Confederación Argentina", que recayó en el general Urquiza, cuyas funciones no estaban claramente definidas.

El Acuerdo fue ratificado por todas las provincias, con la única excepción de la de Buenos Aires. Allí, la Sala de Representantes, reunida el 1 de mayo y en la que los liberales tenían una amplia mayoría, rechazó el acuerdo argumentando que el poder otorgado a Urquiza era dictatorial.

El gobernador López y Planes presentó su renuncia, que le fue aceptada, y en su reemplazo fue nombrado el presidente de la Legislatura, general Manuel Guillermo Pinto, con carácter provisional. Pero Urquiza —que estaba todavía en Palermo— reaccionó con rapidez: el 24 de junio ordenó a su ejército ocupar la capital, disolvió la Sala de Representantes, repuso en su puesto a López y ordenó la detención y destierro de varios opositores.

El 26 de julio, ante una nueva renuncia de López, Urquiza asumió personalmente el gobierno de Buenos Aires. En su carácter de director provisorio de la Confederación, dispuso la convocatoria al Congreso Constituyente, prohibió la confiscación de bienes en toda la Nación, abolió la pena de muerte por delitos políticos y declaró que el producto de las aduanas exteriores era un ingreso de la Nación.

También reconoció a nombre de la Confederación la independencia del Paraguay –que nunca había sido reconocida por Rosas– por medio de un convenio. A continuación declaró libre la navegación de los ríos por dos decretos de agosto y octubre de 1852.

En septiembre de 1852, Urquiza partió hacia Santa Fe para iniciar las sesiones del Congreso Constituyente, dejando como delegado al general José Miguel Galán.

El 11 de septiembre de 1852 estalló un levantamiento militar con apoyo civil contra la autoridad de Urquiza y su delegado, que se embarcó hacia Entre Ríos. Parte de las tropas correntinas tuvieron una activa participación en la revolución; incluso los antiguos rosistas se unieron a la revolución. Restablecida, la Sala de Representantes desconoció al Congreso Constituyente, ordenó el regreso de los dos diputados porteños a la misma y reasumió el manejo de sus relaciones exteriores.

En un primer momento, Urquiza ocupó San Nicolás de los Arroyos, decidido a volver a Buenos Aires. Pero allí tuvo conocimiento que el apoyo con que contaba la revolución era mayor que el esperado, y que incluso los federales se habían plegado a ella. De modo que regresó a Entre Ríos.

A partir de ese momento, el llamado Estado de Buenos Aires se manejó como un país independiente de la Confederación. Tras un breve interinato del general Pinto, en octubre fue nombrado gobernador Valentín Alsina.

El general José María Paz fue nombrado comandante de las fuerzas acantonadas en San Nicolás, con las que se planeaba invadir Santa Fe. Mientras tanto, las fuerzas correntinas fueron enviadas de regreso a su provincia, con la misión de invadir Entre Ríos en su camino. Pero las fuerzas desembarcadas en Concepción del Uruguay fueron derrotadas y debieron huir a Corrientes; y otra división se reembarcó hacia Buenos Aires. De modo que la proyectada invasión de Paz al interior fue suspendida.

Los planes del gobierno porteño de lanzarse a la guerra contra la Confederación causaron una rebelión de los oficiales del interior de la provincia, casi todos de origen rosista: el 1 de diciembre, el general Hilario Lagos se pronunció contra el gobierno de Alsina, que presentó la renuncia, y por tercera vez asumió el gobierno provisional el general Pinto.

Las tropas federales pusieron sitio a la ciudad de Buenos Aires, mientras que las escasas fuerzas del gobierno porteño en el interior de la provincia fueron derrotadas. Incluso Paz fue llamado a Buenos Aires, desguarneciendo a San Nicolás.

Urquiza se trasladó al sitio de Buenos Aires al frente de algunas divisiones entrerrianas, y la escuadra de la Confederación bloqueó la ciudad. Periódicamente había choques en los alrededores de la capital y combates navales en el Río de la Plata y el Paraná. Lagos formó un gobierno paralelo en San José de Flores e intentó normalizar un gobierno para el interior de la provincia.

El gobierno porteño resolvió la crisis por medio del soborno: primeramente coaccionó a varios jefes federales para abandonar el sitio, y luego sobornó al comandante de la escuadra de la Confederación, el norteamericano John Halstead Coe, para entregar su flota al gobierno porteño. En julio de 1853, el ejército sitiador se disolvió y Urquiza regresó a Entre Ríos.

En 1852, Justo José de Urquiza creó una comisión de 14 miembros para la redacción de los Códigos Civil, Penal, Comercial y de Procedimientos. Pero la revolución del 11 de septiembre de ese año, que culminó con la separación de la Provincia de Buenos Aires de la Confederación Argentina, impidió que el proyecto fuera concretado.

En noviembre de 1852 se inauguraron las sesiones del Congreso Constituyente en Santa Fe. Quien lo había gestado y tratado de reunir luego de incansables años de lucha, el general Urquiza, no pudo asistir debido a la invasión porteña a Entre Ríos. Los diputados habían sido elegidos por los gobernadores con la anuencia de Urquiza, y éste presionó activamente sobre ellos para destrabar algunas discusiones. Algunos debieron renunciar a su representación debido a que Urquiza se negó a pagarles los sueldos.

La tarea de redactar el proyecto recayó fundamentalmente en el diputado Benjamín Gorostiaga, que presentó un texto muy parecido al proyecto de constitución que había propuesto Juan Bautista Alberdi en "Bases y puntos de partida para la organización política de la República Argentina"; el mismo estaba inspirado, a su vez, en la Constitución de los Estados Unidos de América y las constituciones argentinas de 1819 y 1826, que seguían la tradición de la Constitución española de 1812. Aunque la Constitución nombraba al país como Confederación Argentina, el régimen establecido era el de una república federal. En la práctica, durante la primera década el sistema político funcionaría como una federación de provincias, aunque unidas por un vínculo más firme que el que había existido durante el régimen rosista.

El 1 de mayo de 1853 fue sancionada la Constitución, la cual fue jurada en asambleas públicas en las capitales provinciales.

Hasta la reunión del Congreso Nacional, el Congreso Constituyente se hizo cargo del Poder Legislativo. Las principales leyes que sancionó fueron la que designaba a Paraná capital provisoria del país hasta que Buenos Aires se uniera al mismo, y otra aprobando un tratado de libre navegación de los ríos con Francia e Inglaterra, que declaraba que la navegación de los ríos interiores de la Confederación estaba sujeta a las mismas condiciones que la navegación en alta mar, completamente libre de todo control.

En el mes de junio, el sitio de Buenos Aires seguía sin solucionarse, y las fuerzas sitiadoras se desmoralizaban; de modo que el gobierno porteño resolvió la crisis por medio del soborno: primeramente coaccionó a varios jefes federales para abandonar el sitio, y luego sobornó al comandante de la escuadra de la Confederación, el norteamericano John Halstead Coe, para entregar su flota al gobierno porteño; semanas más tarde, el ejército sitiador se disolvió. Urquiza estuvo a punto de caer en manos de los porteños, pero logró embarcarse hacia Paraná en un buque inglés, mientras sus tropas huían hacia Santa Fe.

Realizadas las elecciones, fue elegido presidente Justo José de Urquiza, acompañado por el unitario sanjuanino Salvador María del Carril como vicepresidente. La capital fue establecida en forma provisional en la capital de la provincia de Entre Ríos; para ello se federalizó todo el territorio de la provincia, que pasó a estar gobernada directamente por el presidente. De este modo, Urquiza seguía gobernando su provincia, aunque las municipalidades conservaron cierta autonomía. 

Urquiza asumió la presidencia el 5 de marzo de 1854. Pocos días después viajó a Córdoba a presidir una reunión de los gobernadores de las provincias vecinas, con lo cual quiso mostrar la firme unión entre las mismas, amenazadas tanto por la política de Buenos Aires como por la reciente historia de divisiones entre ellas.

Una vez establecido en Paraná, Urquiza convocó a elecciones de diputados y senadores, inaugurando las primeras sesiones del Congreso Nacional el 22 de octubre de 1854. La organización del Poder Judicial presentó mayores dificultades debido a la escasez de personal capacitado: si bien el presidente designó a los miembros de la Corte Suprema de Justicia y sancionó la ley para la organización de las Cámaras Federales, la Justicia Federal nunca llegó a funcionar.

Nacionalizó el Colegio y la Universidad de Córdoba y el Colegio de Concepción del Uruguay; hizo construir edificios públicos en Paraná.

La Confederación no tenía recursos políticos ni económicos para llevar adelante grandes iniciativas públicas. Una de las materias en que logró más éxitos fue la conformación de un ejército nacional. Las fuerzas provinciales se mantuvieron autónomas, pero el gobierno logró organizar regiones militares que pudieran funcionar como unidades militares en el futuro.

Durante casi la mitad del tiempo de su gobierno, Urquiza no residió en Paraná, sino que gobernaba desde el Palacio San José, que se estaba construyendo cerca de Concepción del Uruguay. Durante sus ausencias lo reemplazó Del Carril, como establece la Constitución, pero éste tenía muy malas relaciones con el ministro del interior, Santiago Derqui; con el tiempo, ambos terminaron liderando partidos opuestos dentro del mismo gobierno.

Se hizo un primer intento de crear un ferrocarril para unir Rosario –la ciudad de más rápido crecimiento en ese período, que pronto sería la más poblada del interior– con Chile, favoreciendo en su camino zonas desérticas. Los primeros estudios en ese sentido dieron resultados desalentadores, por lo que el gobierno pensó en combinar ese plan con un ferrocarril a Córdoba, que por sí mismo financiara la construcción del primer tramo del ferrocarril a Chile; el plan desarrollado por el ingeniero William Wheelwright no pudo ser llevado a cabo por el gobierno de la Confederación por falta de recursos financieros.

Para reemplazar al inexistente ferrocarril, las comunicaciones se modernizaron estableciendo ""mensajerías"", empresas privadas que llevaban pasajeros, correspondencia y cargas de alto valor en galeras, uniendo la mayor parte de las ciudades del país. y que también recorría el interior de la provincia de Buenos Aires.

En las provincias de la Confederación, los propietarios de tierras carecían de acceso al crédito, ya que no contaban recursos económicos ni financieros para expandirse. Por ello, el crecimiento de la producción agropecuaria en las provincias del litoral estuvo motorizado por la creación de colonias agrícolas en su territorio, atrayendo hacia ellas a inmigrantes europeos. La primera colonia agrícola exitosa fue la de Esperanza (Santa Fe), fundada por Aarón Castellanos en 1855, con inmigrantes suizos. Otras muchas colonias fueron fundadas en Santa Fe y Entre Ríos en esos años; un caso muy conocido es el de la Colonia San José, fundada por el general Urquiza en 1857. No obstante, para que el sistema se generalizara sería necesario el apoyo del ferrocarril, que sólo se extendería en años posteriores.

La división entre la Confederación y Buenos Aires planteó un problema a los representantes diplomáticos acreditados en la Argentina: si bien reconocían la autoridad de Urquiza sobre todo el país, la enorme mayoría de sus intereses comerciales y sus ciudadanos residentes estaban en Buenos Aires. De modo que sostuvieron ministros plenipotenciarios en Paraná y cónsules en Buenos Aires, tratando de mediar a favor de la unión nacional.

Pese a la importancia que el gobierno nacional daba a las relaciones con las principales potencias extranjeras, su primera prioridad fue lograr el reconocimiento de la independencia argentina por parte de España. Juan Bautista Alberdi representó a la Confederación ante la corona española, logrando la firma de un tratado con España el 9 de julio de 1859, por el cual la antigua metrópoli reconocía la independencia argentina; el mismo fue rechazado por Buenos Aires, debido a que se reconocía la ciudadanía española de los hijos de españoles nacidos en la Argentina, esto es, el ius sanguinis, lo que significaba convertir a la muy necesaria inmigración en una amenaza a la nacionalidad argentina.

Gran Bretaña logró la anulación del tratado de 1849, por el cual Rosas había obligado a ese país a reconocer la soberanía argentina sobre sus ríos interiores.

También se reiniciaron relaciones diplomáticas con la Santa Sede, con la cual la Argentina no había tenido relación alguna desde las discusiones sobre el patronato eclesiástico durante la década de 1830.

Las relaciones con el Brasil estuvieron orientadas principalmente a la cuestión de la navegación de los ríos y a las relaciones de ambos países con el Paraguay. La relación con este último país —celoso defensor de todos los atributos de su soberanía— se vieron empañadas por la firme actitud del gobierno paraguayo ante las potencias extranjeras, especialmente con relación a Estados Unidos, que estuvo a punto de atacar a ese país por un incidente menor. La favorable resolución de ese problema facilitó la mediación paraguaya para resolver los conflictos entre Buenos Aires y la Confederación en 1859.

La Confederación inició su etapa constitucional con serios problemas económicos y financieros: falta de recursos, dependencia del puerto de Buenos Aires para el comercio exterior, trabas interiores derivadas de las aduanas provinciales y derechos de tránsito, dificultades en las comunicaciones y en el tránsito de mercaderías, escaso desarrollo de la agricultura y estancamiento de la industria artesanal. La organización del tesoro nacional presentó dificultades por la escasa recaudación de las aduanas exteriores de la Confederación y la falta de un sistema impositivo eficiente; de allí la penuria económica de la administración confederal. Tampoco se acertaba a crear un sistema bancario confiable, por lo que el crédito le resultaba muy costoso y los sucesivos intentos de emitir papel moneda terminaron en tantos fracasos.

Un proyecto del ministro de Hacienda, Mariano Fragueiro, llevó a la creación del Banco Nacional de la Confederación, que abrió sus puertas en 1854 y emitió papel moneda. Pero éste carecía de respaldo, de modo que se debió declararlo de curso forzoso; las provincias lo rechazaron y los comerciantes se negaron a aceptarlo. El banco debió cerrar y se retiró de circulación el papel moneda.

Entonces se decidió atacar la estructura económica del país dividido, que beneficiaba a Buenos Aires: la Ley de Derechos Diferenciales –sancionada en 1856– buscó incrementar el comercio de la Confederación con las potencias extranjeras y perjudicar los intereses de Buenos Aires. La ley establecía que las mercaderías extranjeras provenientes de cabos adentro –esto es, previamente desembarcadas en otro puerto del Río de la Plata– que se introdujesen en la Confederación pagarían el doble del derecho ordinario al que estaban sujetas las que entraban directamente a los puertos de la Confederación; una ley posterior estableció derechos diferenciales a la exportación.

Sin embargo, las medidas no dieron los resultados esperados: aunque aumentó el volumen comercial en el puerto de Rosario e incluso un financista brasileño —el Barón de Mauá— fundó un banco en esa ciudad, Buenos Aires seguía siendo el centro financiero del país. La necesidad apremiante de dinero fue solucionada con nuevos empréstitos, como los contratados con Mauá, pero los intereses a que se pudo conseguir el dinero fueron excepcionalmente altos, llegando al 24%. Urquiza llegaría a la conclusión de que el único camino para terminar con los problemas económicos de la Confederación era la reincorporación de la provincia disidente a cualquier precio.

Durante la gobernación de Pastor Obligado, la provincia rebelde sancionó su propia constitución y disfrutó un rápido crecimiento económico.

Tras la derrota de Lagos, la mayor parte de los federales porteños habían emigrado a Paraná, Rosario o Montevideo, desde donde planeaban regresar por medio de la invasión de su provincia. En enero de 1854, Lagos ocupó brevemente el norte de la provincia por pocos días. En noviembre del mismo año, el general Jerónimo Costa avanzó al frente de 600 hombres, pero fue derrotado.

En diciembre de 1855 hubo un nuevo intento, cuando José María Flores desembarcó en Ensenada, mientras Costa lo hacía cerca de Zárate con menos de 200 hombres. El gobernador Obligado dictó la pena de muerte para todos los oficiales implicados en esa invasión, declarándolos oficialmente bandidos. Flores logró huir, pero Costa avanzó hacia Buenos Aires con sus escasas tropas. El 31 de enero de 1856 fue derrotado por Emilio Conesa cerca de San Justo; la mayor parte de los soldados fueron muertos cuando se rendían, y los oficiales fueron fusilados dos días más tarde.

Los federales clamaron por venganza, pero Urquiza decidió ser más prudente: firmó un Tratado de Pacificación con Buenos Aires, que permitió a ambos bandos gozar de tres años de paz.

Durante la gobernación de Valentín Alsina, elegido en 1857, el gobierno porteño adoptó una política muy agresiva, rechazando la Ley de Derechos Diferenciales, y dejando de lado los tratados de paz. Para quebrar la resistencia de la Confederación, apoyó en las provincias movimientos tendientes a integrarse en un proceso de unidad bajo su dirección. La prensa porteña se volvió aún más agresiva, incitando al gobierno porteño a la guerra contra la Confederación o a la independencia definitiva.

Las provincias interiores eran periódicamente sacudidas por revoluciones; las dos más estables eran las de Santiago del Estero y Corrientes, cuyos gobiernos eran considerados más inclinados hacia la política de Buenos Aires que a la de Urquiza.

El asesinato, en 1859, del caudillo sanjuanino Nazario Benavídez fue festejado por la prensa porteña: Sarmiento consideró su muerte como un triunfo de la "civilización" y el diario "La Tribuna" le auguró el mismo destino a Urquiza. El presidente Urquiza envió una intervención federal, que descubrió abundantes vinculaciones de los revolucionarios con el gobierno de Buenos Aires.

La intervención de los porteños en la política interna de otra provincia causó gran indignación en el gobierno de Paraná: una ley desconoció todo acto público generado por el gobierno porteño, y en mayo de 1859, el Congreso ordenó la movilización militar de la población y autorizó a Urquiza resolver el problema de la unidad nacional 

El jefe del ejército porteño, coronel Bartolomé Mitre, recibió orden de invadir la provincia de Santa Fe.

Ante la inminencia del conflicto, Estados Unidos, Reino Unido, Brasil y Paraguay trataron de interceder amistosamente. Pero ni Alsina ni Mitre aceptaban nada que no fuera la renuncia de Urquiza o la guerra. Por su parte, Urquiza –que desde 1852 había intentado negociar siempre– estaba ahora particularmente furioso por el asesinato de Benavídez y por la apología del crimen en que habían incurrido los periódicos porteños.

Los buques de guerra porteños bloquearon el puerto de Paraná, pero un motín en uno de estos barcos, que fue entregado al gobierno nacional, obligó a levantar el bloqueo. A mediados de octubre, tras un breve combate naval, la escuadra federal se presentó frente a Buenos Aires.

El ejército de la Confederación, dirigido por Urquiza, inició la campaña hacia Buenos Aires desde Rosario; estaba formado por 14 000 hombres –de los cuales 10 000 de caballería y 3 000 de infantería– con 35 cañones y obuses; varias divisiones de indígenas ranqueles figuraban como auxiliares.

El ejército porteño operaba desde San Nicolás de los Arroyos; contaba con 9000 hombres –de los cuales, 4700 infantes y 4000 jinetes– con 24 piezas de artillería,bajo el mando de Mitre, ministro de guerra. Las fuerzas porteñas estaban muy disminuidas porque gran parte de sus fuerzas debían proteger la frontera de su provincia de las invasiones de los indígenas, algunos de los cuales –como Juan Calfucurá– eran aliados de Urquiza y sus incursiones formaban parte de la estrategia de éste.

El 23 de octubre se inició la Batalla de Cepeda. Antes de lanzarse al ataque, Urquiza arengó a sus tropas: 

La ventaja inicial favoreció a la infantería porteña, pero un hábil uso de la caballería por parte de Urquiza le permitió tomar la ofensiva, e incluso tres batallones porteños fueron destruidos. Una maniobra de flanco ordenada por Mitre desorganizó toda la formación, y la noche detuvo la batalla cuando la victoria de la Confederación era ya evidente.

Los porteños sufrieron muchas bajas: 100 muertos, 90 heridos y 2000 prisioneros, además de 21 cañones. Los nacionales tuvieron 300 bajas fatales. En medio de la noche, Mitre comandó una ordenada retirada hacia San Nicolás, adonde llegó pasado el mediodía siguiente con sólo 2000 hombres. A continuación embarcó todo su ejército, y –tras un breve combate– logró trasladarlo a Buenos Aires.

Urquiza avanzó rápidamente sobre la ciudad; en su camino envió a la ciudad varias proclamas pacifistas, como la que decía:

Aunque hubiera podido entrar a Buenos Aires por la fuerza, prefirió acampar cerca de ella –en el pueblo de San José de Flores– desde donde inició negociaciones. Durante todas las tratativas, Urquiza mantuvo la amenaza de un inmediato asalto a la ciudad, con lo que el 8 de noviembre obtuvo la renuncia de Valentín Alsina.

Como consecuencia de complicadas negociaciones –durante las cuales ofició de mediador Francisco Solano López, hijo del presidente paraguayo– el 11 de noviembre se firmó el Pacto de San José de Flores, también llamado de Unión Nacional, entre Urquiza y el gobernador provisional Felipe Llavallol. El mismo establecía que Buenos Aires se declaraba parte integrante de la Confederación y renunciaba al manejo de sus relaciones exteriores, pero revisaría la Constitución de 1853 por medio de una convención provincial y propondría reformas a la misma. Se declaraba nacionalizada la Aduana de Buenos Aires, pero la Nación compensaría los ingresos de la provincia de Buenos Aires durante cinco años, en la medida en que fueran inferiores a los del año 1859. Una cláusula que no fue incorporada al Pacto pero que fue acordada de palabra entre las partes establecía que la reincorporación de la provincia a la Nación se haría después de finalizado el período presidencial de Urquiza.

Muchos federales del interior estuvieron en desacuerdo con el Pacto: desde su punto de vista, Urquiza había llegado a San José de Flores como vencedor, y había negociado como si él hubiera sido el vencido; en vez de castigar a la provincia por su rebeldía, se la había premiado. Uno de los críticos fue el general Ricardo López Jordán, uno de los jefes vencedores en Cepeda.

En mayo de 1860, Urquiza entregó el gobierno nacional a su sucesor, Santiago Derqui.

Poco después se dejó sin efecto la federalización de la provincia de Entre Ríos, quedando fuera de la misma la ciudad de Paraná. Y una nueva constitución provincial declaró a Concepción del Uruguay capital de la provincia. Como era de esperarse, el gobernador electo fue Urquiza, apenas 50 días después de dejar la presidencia.

Durante la presidencia de Derqui, la Confederación acordó con el Estado de Buenos Aires el Convenio Complementario del 6 de junio de 1860 y se realizó la reforma constitucional de 1860; una convención provincial propuso una serie de reformas, que fueron aceptadas en su gran mayoría sin debate por la Convención Nacional reunida al efecto. Entre las reformas introducidas se destacan la validación oficial de tres nombres oficiales para el país: Provincias Unidas del Río de la Plata, República Argentina y Confederación Argentina (art. 35); se eliminó la disposición que declaraba a Buenos Aires como capital de la Nación, ya que la misma se fijaría por una ley del Congreso; se redujeron las atribuciones del Estado Nacional y aumentó el grado de autonomía de las provincias; se estableció que las provincias se reservaban también las facultades que se hubieren reservado al tiempo de su incorporación. se suprimió la obligación de las provincias de garantizar la educación gratuita (art. 5) se prohibió establecer diferencias fiscales entre aduanas y otorgar preferencias a puertos determinados.
Continuó su política de promoción de la educación y la colonización, pero se entrometió continuamente en el gobierno de Derqui. Para sacarse de encima su tutela, éste se apoyó en Mitre, pero eso sólo sirvió para debilitar su gobierno.

Una serie de conflictos con Buenos Aires, incluyendo nuevos problemas en San Juan y el rechazo de los diputados por Buenos Aires por una cuestión legal, llevaron a que Mitre desconociera el Pacto de San José.

Entonces Derqui se preparó para una nueva guerra contra la provincia rebelde. Reunió un importante ejército en Córdoba y lo unió a las fuerzas de Urquiza. Éste fue puesto al mando del ejército.

Pero Urquiza no quería pelear; trató por todos los medios de llegar a un arreglo con Mitre. Se sentía traicionado por el presidente dado su intento de reemplazarlo por Juan Saá, y decidió que no iba a vencer para dejarle el triunfo. Le dijo a su amigo Molinas que
Mitre se negó a cualquier trato e invadió la provincia de Santa Fe. Los ejércitos se enfrentaron en la batalla de Pavón, el 17 de septiembre de 1861. Aunque el resultado de la batalla no parecía inclinarse a favor de ninguno de los contrincantes, Urquiza se retiró, dejando la victoria en manos de Mitre. Su caballería había destrozado a la porteña, y si la infantería de Mitre pudo desplazar a la de Urquiza, fue sólo porque éste no la empleó a fondo; ni siquiera movió su reserva.

Sin atender los pedidos del presidente ni de sus propios comandantes de caballería, entre ellos López Jordán, Urquiza regresó a Entre Ríos. Mitre, que se había retirado derrotado a San Nicolás, tardó varias semanas en comprender que había quedado vencedor por abandono. Invadió Santa Fe, masacró a la reserva federal en Cañada de Gómez y envió un ejército a ocupar Córdoba y otro a Cuyo.

Debilitado política y económicamente, Derqui se exilió en Montevideo. Urquiza consideró caducado el gobierno nacional, en lo que fue imitado por los demás gobernadores. El vicepresidente Juan Esteban Pedernera renunció en diciembre, y declaró disuelto el gobierno.

Mitre asumió el mismo gobierno nacional que había denunciado como despótico cuando lo ejerció Urquiza en 1852, reemplazó a todos los gobiernos federales de las provincias, y meses más tarde se hizo elegir presidente de la Nación.

Urquiza mantuvo la autonomía del gobierno de su provincia y conservó el cargo de gobernador. No hubo un acuerdo explícito, pero sí un acuerdo tácito con Mitre, por el cual éste nunca amenazó a Urquiza. A cambio, Urquiza se mantuvo neutral durante todas las rebeliones federales de esa década. En La Rioja, el general Ángel Vicente Peñaloza mantuvo una larga rebelión hasta que fue asesinado en 1863. Cuatro años más tarde, Felipe Varela y Juan Saá dirigieron otra rebelión en Cuyo y La Rioja, pero ésta fue aplastada. Estas y otras revoluciones federales se hicieron en nombre de Urquiza, y sus dirigentes pidieron repetidamente ayuda y órdenes al jefe natural del Partido Federal, que era Urquiza; pero Urquiza no se movió.

Gobernó una especie de autocracia patriarcal en su provincia, y su gobierno no fue tan progresista como los anteriores. Su provincia se vio beneficiada por la política librecambista de Mitre, si bien las incipientes industrias tuvieron que cerrar. Pero, a cambio, la ganadería floreció más que nunca. La provincia vivía sobre todo de la ganadería... y Urquiza era un ganadero.

Reforzó su sistema casi feudal: nadie podía vender ni campos ni hacienda sin primero darle aviso a Urquiza, que tenía el derecho de prioridad. De esa manera pudo aumentar sin riesgos su ya enorme fortuna.

En las elecciones de 1864, promovió la candidatura de José María Domínguez contra la del general López Jordán, que seguía siéndole leal, pero podía pretender actuar con autonomía. Ortiz, en cambio, gobernó como un dependiente del caudillo.

Al estallar la "Guerra Chiquita" en Uruguay, iniciada en 1863 por la invasión del general Venancio Flores, Urquiza se mantuvo también neutral. La mayor parte de los federales entrerrianos trataban de ayudar al gobierno uruguayo, pero Urquiza mantuvo su alianza con el presidente Mitre, que apoyaba abiertamente a Flores. Cuando la ciudad de Paysandú fue atacada por la flota brasileña y las fuerzas de Flores, hasta dejarla destruida, muchos federales entrerrianos y porteños – entre éstos, Rafael y José Hernández – lucharon a favor de los defensores. El bombardeo se veía desde Concepción del Uruguay, y se oía desde el Palacio San José; a Urquiza le llegaron cientos de cartas invitándolo a entrar en acción, pero Urquiza no se movió.

La caída del gobierno uruguayo provocó la Guerra del Paraguay. Mitre llamó a todas las provincias a movilizarse contra el gobierno de Francisco Solano López, y Urquiza repitió el llamamiento al pueblo entrerriano. Los federales entrerrianos estaban indignados; escribían contra la guerra y a favor del gobierno paraguayo. López Jordán escribió a Urquiza: 

Pero Urquiza estaba obteniendo un gran provecho de la guerra: lo primero que hizo fue reunir la mayor parte de los caballos de la provincia y vendérselos a Brasil.

Poco después ordenó movilizar todas las fuerzas provinciales en el campamento de Calá. Curiosamente, en un gesto insólitamente racista, ordenó movilizar a todos los “pardos y morenos” entre los 20 y los 30 años. Se presentaron 8.000 voluntarios, la mayor parte de ellos convencidos de que iban a unirse a los paraguayos contra los brasileños. Fueron reunidos en cinco columnas y comenzaron a marchar hacia el norte; pero al llegar al pueblo de Basualdo, se enteraron de qué lado iban a pelear: simplemente se fueron a sus casas.

Poco después, por medio de amenazas, logró reunir otra vez a su gente, pero al llegar al campamento de Toledo, nuevamente desertaron en masa. Esta vez, Urquiza hizo fusilar a varios, pero ni aun así logró reunir un tercer contingente. Entonces envió los 800 soldados de infantería de línea de su provincia y los embarcó a la fuerza hacia el frente.

El prestigio de Urquiza estaba cayendo rápidamente. El gobierno cerró los periódicos opositores y arrestó a sus directores.

En 1868 se presentó a las elecciones presidenciales como candidato del partido federal, pero perdió por una diferencia aplastante contra el candidato de una parte del unitario: Sarmiento. En cambio, logró hacerse elegir nuevamente gobernador de su provincia, y en mayo de ese año asumió nuevamente el gobierno provincial.

En 1870 terminaba la Guerra del Paraguay; para festejarlo, Urquiza recibió en su Palacio San José, con gran despliegue de desfiles y brindis, al presidente Sarmiento, el más terrible enemigo de los federales. Era la sanción visible del acuerdo tácito del caudillo con los unitarios, y los federales lo tomaron como un insulto.

La oposición decidió no esperar más un pronunciamiento a su favor de parte de Urquiza, y decidió lanzarse a derrocarlo.

El general López Jordán organizó rápidamente la revolución; el primer objetivo era apoderarse de la persona del gobernador, para forzarlo a renunciar o expulsarlo del país. Envió en su busca al coronel Simón Luengo, un oficial cordobés que había luchado contra los porteños en el interior del país.

Una versión de historia novelada relata: En el atardecer del 11 de abril de 1870 una partida de 50 hombres armados, al mando del coronel Robustiano Vera, hicieron ruidosa irrupción en San José. Venían a apresar al gobernador y caudillo gritando: "¡Abajo el tirano Urquiza! ¡Viva el general López Jordán!" Un grupo de cinco a las órdenes del coronel Simón Luengo, cordobés y protegido del general, se encamina a las dependencias privadas del dueño de casa. Integran el grupo Nicomedes Coronel, capataz de una de las estancias de Urquiza, oriental de origen, el tuerto Álvarez, cordobés, el pardo Luna, oriental y el capitán José María Mosqueira, entrerriano, nacido en Gualeguaychú. El general que está tomando mate debajo del corredor se incorpora, sorprendido por el bullicio y, comprendiendo que se trata de un asalto, grita: "¡Son asesinos! Y corre a proveerse de un arma. Los asaltantes se acercan. ¡No se mata así a un hombre en su casa, canallas!" Les espeta, haciendo un disparo que hirió en el hombro a Luna. "Álvarez, entonces –explica el coronel Carlos Anderson, ayudante de Urquiza y jefe de la Guardia del Palacio, testigo presencial de los sucesos- le tiró con un revólver, y le pegó al lado de la boca: era herida mortal, sin vuelta. El general cayó en el vano de la puerta y en esa posición Nico Coronel le pegó dos puñaladas y tres el cordobés Luengo, el único que venía de militar y que lo alcanzó cuando ya la señora Dolores y Lola, la hija, tomaban el cuerpo y lo entraban en un cuarto, en el cual se encerraron con él yendo a recostarlo en la esquina del frente, donde se conservan hasta ahora, las manchas de sangre en las baldosas".

Ese mismo día eran asesinados en Concordia también sus hijos Justo Carmelo y Waldino; los dos eran amigos íntimos de López Jordán, lo que parece probar que los asesinos no actuaron por orden de López Jordán.

Tres días más tarde, López Jordán era elegido gobernador por la Legislatura. En su discurso de asunción apoyó la revolución, y apenas mencionó de paso que
La mayor parte de los federales apoyaron la revolución, e incluso José Hernández llegó a hablar de "…su muerte, mil veces merecida."

Más tarde, López Jordán fue acusado de haber querido encabezar una rebelión contra el gobierno nacional. Un año más tarde la provincia fue sometida por la fuerza: los federales, tanto jordanistas como urquicistas, fueron proscriptos, y las garantías que Mitre había acordado tácitamente con Urquiza desaparecieron. La provincia fue ocupada militarmente y perdió la importancia que había tenido.

El asesinato de Urquiza contó con apoyo popular entre los entrerrianos. Esto se debió a las actitudes asumidas por Urquiza: la retirada de la batalla de Pavón, su neutralidad frente al bombardeo de Paysandú, su participación en la guerra contra el Paraguay, las maniobras para evitar la elección de López Jordán y la entrega de la recaudación de impuestos en manos de un particular.

En vida, Urquiza fue condecorado por Brasil con la Orden Imperial de Cristo (en 1851) y la Gran Cruz de la Orden Imperial de la Cruz del Sur (en 1856).

Sus restos descansan en la Basílica de la Inmaculada Concepción, en Concepción del Uruguay, provincia de Entre Ríos, República Argentina.Los pequeños poblados de la zona llevan nombres como: 1º de Mayo (de 1852), Pronunciamiento (01/05/1852), Caseros(por la Batalla), San Justo, San Cipriano (nombre de su hermano y uno de sus hijos).

Varias localidades de la Argentina llevan el nombre de su primer presidente constitucional: Villa Urquiza, en la provincia de Entre Ríos; General Urquiza, en la provincia de Misiones; Juan Anchorena, Estación Urquiza, en la provincia de Buenos Aires; el barrio de Villa Urquiza, en la Ciudad de Buenos Aires. También el Ferrocarril General Urquiza, varias estaciones de ferrocarril, y el Aeropuerto General Justo José de Urquiza, de la ciudad de Paraná.

Gran cantidad de localidades del país llevan su nombre en calles y plazas. En muchas de ellas existen monumentos y bustos con la imagen del general. El parque Urquiza en Rosario y el parque Urquiza en Paraná son algunos ejemplos. Además, en la Ciudad Autónoma de Buenos Aires, se encuentra la escuela secundaria "Justo José de Urquiza" con su nombre por conmemoración.




</doc>
<doc id="15323" url="https://es.wikipedia.org/wiki?curid=15323" title="Dionne Warwick">
Dionne Warwick

Marie Dionne Warrick, de nombre artístico Dionne Warwick (n. East Orange, Nueva Jersey, 12 de diciembre de 1940), es una cantante estadounidense de soul y pop. Hermana de Dee Dee Warwick, sobrina de Cissy Houston y prima de Whitney Houston.

El trabajo musical más elogiado de Dionne Warwick es el que realizó con los compositores Hal David y Burt Bacharach. 

Se inició en la música como cantante gospel con su familia. Su debut en solitario de la mano de Burt Bacharach en 1962 ("Don't Make Me Over") apareció por una errata de imprenta bajo el apellido "Warwick", no "Warrick"; un error que propició el nombre artístico de Dionne para toda su carrera. Este sencillo tuvo un cierto éxito, situación que no volvería a repetirse hasta 1964 con "Anyone Who Had a Heart" y "Walk on By", este último un éxito en el Reino Unido. Les sucederían otros hasta 1971 en la que abandonó el sello "Scepter" por una fuerte disputa mantenida con Bacharach.

Entre sus interpretaciones más recordadas, se pueden citar otras como "Alfie", la famosísima "I Say A Little Prayer For You", "Promises, Promises", "This Girl's In Love With You", "Endless Love" (canción que grabó con Barry White y que también ha interpretado con Tom Jones), "I Always Get Caught in The Rain", "Who Can I Turn To", "I'll Never Fall in Love Again"...

En su etapa posterior en "Warner", sólo consiguió el éxito con el tema "Then Came You", de 1974 escrito por Thom Bell y Linda Creed e interpretado en un dueto con "The Spinners". En la década de los 80, y tras un nuevo cambio de sello discográfico, obtuvo un nuevo éxito con "Heartbreaker" en 1982, canción compuesta por The Bee Gees con la voz de Barry Gibb en el coro. A partir de entonces sus grabaciones se fueron espaciando, hasta un repunte de popularidad en 2006 con un álbum de duetos ("My friends & me").

En el 16 de octubre de 2002, Dionne Warwick fue nombrada Embajadora de Buena Voluntad de la Organización de las Naciones Unidas para la Agricultura y la Alimentación (FAO).

En marzo de 2013, saltó la noticia de que la cantante se había declarado en bancarrota, con deudas acumuladas de unos diez millones de dólares.




</doc>
<doc id="15324" url="https://es.wikipedia.org/wiki?curid=15324" title="Mayo de 1968 en Francia">
Mayo de 1968 en Francia

Se conoce como Mayo francés o Mayo del 68 a la cadena de protestas que se llevaron a cabo en Francia y, especialmente, en París durante los meses de mayo y junio de 1968. Esta serie de protestas fue iniciada por grupos estudiantiles de izquierda contrarios a la sociedad de consumo, a los que posteriormente se unieron grupos de obreros industriales, los sindicatos y el Partido Comunista Francés. Como resultado, tuvo lugar la mayor revuelta estudiantil y la mayor huelga general de la historia de Francia, y posiblemente de Europa occidental, secundada por más de nueve millones de trabajadores. El movimiento estudiantil tuvo influencias del movimiento "hippie" que se extendía entonces.

La magnitud de las protestas no había sido prevista por el gobierno francés, y puso contra las cuerdas al gobierno de Charles de Gaulle, que llegó a temer una insurrección de carácter revolucionario tras la extensión de la huelga general. Sin embargo, la mayor parte de los sectores participantes en la protesta no llegaron a plantearse la toma del poder ni la insurrección abierta contra el Estado, y ni tan siquiera el Partido Comunista Francés llegó a considerar seriamente esa salida. El grueso de las protestas finalizó cuando De Gaulle anunció las elecciones anticipadas que tuvieron lugar el 23 y 30 de junio.

Los sucesos de mayo y junio en Francia se encuadran dentro de una ola de protestas protagonizadas, principalmente, por sectores politizados de la juventud que recorrió el mundo durante 1968. Estos sucesos se extendieron por la República Federal Alemana, Suiza, España, México, Argentina, Uruguay, Estados Unidos, Checoslovaquia e Italia, lo cual ampliaba la escala del antiguo refrán del siglo XIX afirmando que "cuando París estornuda, toda Europa se resfría".

La crisis de mayo de 68 en Francia surge al término de una década de prosperidad económica sin precedentes. Sin embargo, desde hacía un año se manifestaban los primeros síntomas serios de un grave deterioro de la situación económica. El número de desempleados aumentaba de forma notoria, y al empezar 1968 ya eran 500.000. La juventud se veía particularmente afectada, y las circunstancias habían llevado el gobierno a crear en 1967 la ANPE ("Agence nationale pour l'emploi"). La crisis industrial amenazaba ya a muchos sectores, y la larga huelga de los mineros de 1963 había sido muestra del profundo malestar de la minería francesa ante un declive imparable. En 1968, dos millones de trabajadores cobraban el SMIG ("Salaire minimum interprofessionnel garanti", salario mínimo interprofesional) y se sentían excluidos de la prosperidad. Los sueldos reales empezaban a bajar y crecía la preocupación por las condiciones de trabajo.

En las afueras de las grandes urbes, unas extensas barriadas de chabolas, los "bidonvilles", se habían extendido desde mediados de la década de 1950. El más poblado, el de Nanterre, alcanzaba los 14.000 habitantes en 1965 y se encontraba justo enfrente de la universidad donde iban a surgir los primeros movimientos contestatarios estudiantiles.

Internacionalmente, la década de 1960 vivió una serie de cambios a nivel mundial que llevaron al cuestionamiento del sistema de dominación europeo y, sobre todo, estadounidense sobre los territorios coloniales o recientemente independizados de África, Asia y América Latina. El triunfo de la Revolución cubana y el auge de movimientos izquierdistas en Latinoamérica, y especialmente la guerra de Vietnam generaron un amplio movimiento de solidaridad en gran parte de Europa y de los propios Estados Unidos que canalizaron la oposición al imperialismo.

En Francia estos movimientos tienen su génesis durante la guerra de Indochina y de Argelia, que provocaron una fuerte polarización en la sociedad francesa desde principios de la década de 1960. En octubre de 1961 una manifestación pacífica de argelinos en París acabó con una fuerte represión policial que provocó más de 200 muertos, cuyos cuerpos fueron arrojados al Sena en una acción que fue silenciada en el primero de los grandes apagones informativos de esta época. También a raíz de este suceso aparece públicamente por primera vez una corriente estudiantil radical que se manifestará contra la actuación policial a través de dos organizaciones recientemente creadas: el Comité Anticolonialista y el Frente Universitario Antifascista (FUA). Al año siguiente, en febrero de 1962, una manifestación convocada por el Partido Comunista Francés y la Confederación General del Trabajo acabó con nueve muertos aplastados en la estación de metro de Charonne. Estos dos sucesos provocaron un sentimiento de rechazo hacia los CRS (policía antidisturbios). Durante este periodo, grupos estudiantiles como el sindicato universitario Unión Nacional de Estudiantes de Francia se desplazaron hacia la izquierda en el contexto de oposición a la guerra de Argelia, al tiempo que iban surgiendo nuevos movimientos como el Comité Vietnam de Base y el Comité Vietnam Nacional (aparecidos en 1967 y 1966 respectivamente) que organizaron importantes movilizaciones antimperialistas y protagonizaron gran parte de la agitación universitaria anterior a 1968. El desarrollo de la Revolución Cultural en China también generó un nuevo referente para una parte de los sectores izquierdistas franceses, que vieron en el maoísmo una nueva base ideológica, alejada del PCF y de la Unión Soviética, y menos dogmática y mucho más innovadora con respecto al marxismo clásico soviético.

También a raíz de la guerra de Argelia surgen importantes movimientos ultraderechistas que abogaban por la defensa de la Argelia francesa, como la OAS (Organización del Ejército Secreto, por sus siglas en francés) y los grupos Occident, Ordre Nouveau o Jeune Nation. Estos movimientos se enfrentaron durante la década de los 60 con los movimientos estudiantiles y obreros izquierdistas tanto en las universidades como en las calles de las principales ciudades, generando una polarización cada vez mayor en los distintos sectores de la sociedad francesa.

En cuanto al gobierno francés, la figura del general De Gaulle, en el poder desde 1958, sufre un desgaste palpable en los resultados electorales. En las elecciones a la presidencia de la República de 1965, las primeras con sufragio universal desde 1948, De Gaulle no había logrado la mayoría absoluta requerida en la primera ronda de votaciones, seguido de cerca por François Mitterand ante la sorpresa general. En las elecciones de 1967 a la Cámara de los diputados, su mayoría había dependido de un sólo escaño. La oposición seguía reprochándole la manera en la que había accedido al poder en 1958, y la legitimidad del régimen gaullista se veía cada vez más ensombrecida por acusaciones de "golpe de Estado". A pesar de la bonanza económica de los últimos años, de los éxitos políticos (fin de la Guerra de Independencia de Argelia y procesos de descolonización) y de cierta aclimatación al régimen presidencialista de la V República Francesa, las prácticas autoritarias del general De Gaulle levantaban cada vez más críticas.

Por su parte, el movimiento obrero francés va a experimentar en esta década una fuerte radicalización y cierto alejamiento de las cúpulas sindicales mayoritarias como la CGT. Desde 1961 se van a suceder huelgas violentas y ocupaciones de fábricas, en muchas ocasiones de forma más o menos espontánea y contra los acuerdos de la dirigencia sindical. En 1963 se realizó una huelga violenta de mineros en la que se rechazaron los acuerdos de los sindicatos; en 1964 hubo huelgas de los obreros de Renault (bajo la consigna "queremos tiempo para vivir") y en los astilleros de Nantes; los obreros del grupo químico Rhodiaceta de Lyon y Besançon mantuvieron una huelga durante todo el mes de diciembre de 1967 y, en enero de 1968, se produjeron disturbios en Caen en los que participaron obreros, agricultores y estudiantes y que se saldó con más de 200 heridos. Estas fueron las primeras huelgas desde 1936 en las que los obreros ocuparon las fábricas, y durante toda la década gran parte de Francia se vio afectada por este movimiento obrero. Grupos estudiantiles e intelectuales comenzaron una estrategia de acercamiento a los conflictos obreros en este periodo, comenzando a trabajar en las fábricas como parte de la actividad militante y realizando encuentros en las casas de los obreros. En este plano de acercamiento entre movimiento estudiantil y un movimiento obrero radicalizado al margen de las cúpulas sindicales se sentaban las bases para la agitación de mayo y junio.

Los años 60 en Francia - al igual que en el resto de occidente - fueron una época de acelerados cambios culturales. La época estaba caracterizada por la aceleración del éxodo rural y el surgimiento de la sociedad de consumo, cada vez más influida por los medios masivos de comunicación (mass media) que generalizaban la cultura de masas.

Es además en los años 60 cuando los jóvenes se convierten en una categoría socio-cultural logrando su reconocimiento como un actor social que establece procesos de adscripción y diferenciación entre sus opciones y las de los adultos. Estos procesos se desarrollan a través de las subculturas juveniles nacidas a partir de finales de los años 1950, dentro de movimientos contraculturales como la cultura underground y los movimientos beatnik y hippie. Esta juventud tenía sus propios ídolos musicales como los Beatles, Rolling Stones, cantautores como Bob Dylan y Léo Ferré, etc. "Muchos de estos movimientos cuestionaron y criticaron el estilo de vida plástico ofrecido por el mercado de consumo y la organización capitalista de la posguerra".

En el plano filosófico varias obras y autores tuvieron gran influencia en una parte del movimiento: Wilhelm Reich, freudomarxista, cuyo manifiesto, "La revolución sexual", daba nombre a una de las consignas más repetidas; Herbert Marcuse con "El hombre unidimensional", publicado en Francia en 1964 y que tuvo que ser reeditado en el 68; Raoul Vaneigem, con el "Traité de savoir-vivre à l'usage des jeunes générations" de 1967; Guy Debord con "La sociedad del espectáculo", también del 1967. Pierre Bourdieu y Jean-Claude Passeron publicaban en 1965 "Les étudiants et leurs études" donde hacían una ácida crítica al sistema educativo francés y sus mecanismos de reproducción social, que permitían a las elites conservar su poder de generación en generación. Mientras tanto en École Normale Supérieure, el filósofo marxista Louis Althusser formaba una generación de pensadores marxista-leninistas que formaron el embrión de las primeras organizaciones maoístas.

El 8 de enero de 1968, el ministro de Juventud y Deporte, François Missoffe, acude a la inauguración de una piscina en la Universidad de Nanterre. Los estudiantes recibieron al ministro con un sonoro abucheo a causa de su "Libro Blanco" acerca del estado de la juventud estudiantil. Durante el suceso un joven estudiante de sociología, Daniel Cohn-Bendit, provocó al ministro, reprochándole que su libro no tratara el problema sexual entre los jóvenes. Pese a que este incidente se quedó en una mera anécdota, permitió la visualización de Cohn-Bendit como una de las figuras mediáticas de los sucesos de mayo. Unos meses después, el 22 de marzo de 1968 un grupo de estudiantes se encierra en la Universidad de Nanterre en protesta por las normativas internas del centro, desocupando las instalaciones tras algunas negociaciones y la aparición de la policía. Esta acción daría origen al Movimiento 22 de marzo, el cual sería uno de los referentes de las movilizaciones de mayo y junio de ese año.

El 22 de abril de 1968, 1.500 estudiantes acudieron a una nueva protesta en Nanterre contra la detención de varios estudiantes del Comité Vietnam Nacional, acusados de atentar contra empresas estadounidenses, en la cual intervendría la policía. El 28 de ese mismo mes el decano de la Facultad ordena el cierre de la misma, al tiempo que los estudiantes anuncian el boicot a los exámenes parciales y se producen enfrentamientos con miembros de la Federación Nacional de Estudiantes de Francia, de ideología derechista, los cuales asaltarían la universidad del 2 de mayo y acusarían a los estudiantes movilizados de "terroristas". Los movimientos derechistas y ultraderechistas estudiantiles previeron que el movimiento de los estudiantes iba a desarrollarse y afirmaron que el deber de los estudiantes moderados y del gobierno era "pararlo en seco". Al mismo tiempo, miembros del grupo de extrema derecha Occident marcharon por el Barrio Latino gritando "¡Vietcongs asesinos!" con el objetivo de contrarrestar el crecimiento del movimiento.

El 3 de mayo ocho estudiantes implicados en las protestas, entre los que se encontraba Daniel Cohn-Bendit, acudieron a declarar a París mientras en la plaza de la Sorbona comenzaba a congregarse una gran cantidad de estudiantes vigilados por la policía, que finalmente cargaría contra la concentración. Ante esta situación, la Unión Nacional de Estudiantes y el Sindicato de Profesores llamaron a la huelga exigiendo la retirada de la policía y la reapertura de La Sorbona, así como la liberación de los estudiantes detenidos hasta el momento.

El lunes 6 de mayo los "ocho de Nanterre" acudieron a declarar ante el Comité de Disciplina de la Universidad. A su salida se realizó una nueva manifestación que concluyó con grandes enfrentamientos entre las barricadas levantadas en el Barrio Latino. La violencia de la policía provocó un sentimiento de solidaridad entre la mayor parte de la sociedad francesa (un 61% de los franceses simpatizaban en estos momentos con los estudiantes). Las manifestaciones se repiten al día siguiente, llegando hasta las inmediaciones del Eliseo

El punto de inflexión del movimiento se da en la noche del 10 de mayo, conocida como "la noche de las barricadas". Decenas de miles de estudiantes acuden a las barricadas del Barrio Latino. Las negociaciones iniciadas con el rectorado de la Sorbona fracasan, al tiempo que las autoridades siguen sin aceptar la liberación de los detenidos. La policía disuelve las barricadas por la fuerza, produciéndose los más duros enfrentamientos de todo el mes de mayo con cientos de heridos. Al día siguiente, carros blindados se desplegaron por la capital francesa.

Ante los sucesos de los días anteriores se convocaría una huelga general para el lunes 13 de mayo. La manifestación de ese día congregó a 200.000 personas, mientras 9 millones de trabajadores en toda Francia seguían la convocatoria de huelga. Tras la misma, grupos de estudiantes marcharon a la Sorbona, que había reabierto sus puertas tras la llegada del primer ministro Georges Pompidou de un viaje por Asia Central, ocupándola. La toma de la Sorbona estará dirigida por un Comité de Ocupación que dotará a la Universidad de una serie de servicios básicos para los estudiantes alzados (enfermería, comedores e incluso guardería). Al día siguiente los trabajadores de Sud Aviation en Nantes y los de Renault en Cleon, Flins, Le Mans y Boulogne Billancourt ocuparon sus fábricas. Poco a poco la huelga se extiende, paralizando la mayor parte de la Francia industrial.

Con la transformación de un movimiento estudiantil surgido en una universidad del extrarradio en una huelga espontánea, los estudiantes tratarán de crear una unión con los trabajadores. Varios miles de estudiantes marcharon el 16 de mayo a Boulogne-Billancourt a encontrarse con los obreros encerrados en las fábricas pero, aunque se realizarán muestras recíprocas de solidaridad (ambos colectivos cantarán "La Internacional" en las puertas de las fábricas ocupadas), las verjas de los puestos de trabajo que los separaban no llegarán a abrirse. El 17 de mayo es creado el Consejo por el Mantenimiento de las Ocupaciones que apoya las huelgas salvajes y se opone a la moderación de los sindicatos.

En los días siguientes se sumarán a la huelga los controladores aéreos así como los trabajadores del carbón, del transporte, del gas y la electricidad y los periodistas de la radio y la televisión. En Nantes, los obreros y los agricultores cortaron los accesos a la ciudad y controlaron el precio de los productos ofrecidos en las tiendas, las cuales solo podían abrir con autorización del Comité de Huelga. En estos momentos, en muchos de los centros de trabajo en huelga, comienza a plantearse la cuestión del poder obrero en las empresas, poniendo verdaderamente en cuestión la autoridad del Estado y generando un auténtico vacío de poder.

Ante esta situación, el gabinete de Pompidou acepta, el 25 de mayo, el abrir negociaciones con los representantes de los obreros en huelga. Estas negociaciones se plantean a tres bandas: patronos, sindicatos y gobierno. Las negociaciones concluyen el 27 de mayo con los Acuerdos de Grenelle, en los que se recoge un incremento del 35% en el salario mínimo industrial y del 12% de media para todos los trabajadores. Sin embargo, la mayor parte de los trabajadores en huelga rechazan el acuerdo. Al día siguiente François Mitterrand, en rueda de prensa, pide al gobierno de De Gaulle su dimisión, afirmando que desde el 3 de mayo "no había Estado", y se postula como candidato a la presidencia.

El 29 de mayo De Gaulle desaparece sin llegar a asistir al Consejo de Ministros convocado para esa mañana. En las calles de París, los manifestantes que se dirigían hacia la Estación ferroviaria de San Lázaro (la "Gare Saint-Lazare"), donde se concentraban los ferroviarios en huelga bajo el lema ""Por un cambio político de progreso social y de democracia"", y gritan consignas como "¡Adiós De Gaulle!" Los gaullistas, por su parte, convocan para el 30 de mayo una manifestación ""En defensa de la República"" en los Campos Elíseos, a la que acuden más de 300.000 personas mostrando su apoyo al Presidente.

Con estas declaraciones, queda claro que la única forma de derribar al gobierno es mediante un alzamiento que ninguno de los sectores en lucha está dispuesto a llevar a cabo. Sin embargo los disturbios aún continúan, pese a que distintas empresas comienzan a retornar al trabajo tras diversas conversaciones locales que tomaban como base los Acuerdos de Grenelle, aceptándose el pago de los días de huelga. Los incidentes se trasladaron de París a los núcleos industriales donde continuaban las huelgas. El 7 de junio en Flins se produjeron violentos enfrentamientos entre los CRS, que acudieron a desalojar a los trabajadores encerrados en las fábricas, y los estudiantes y obreros en huelga. El día 10 un joven estudiante de secundaria muere en los enfrentamientos, lo que provoca nuevos disturbios en París. El 12 de junio, De Gaulle decreta la disolución e ilegalización de los grupos de extrema izquierda y prohíbe las manifestaciones callejeras durante dieciocho meses. En total una decena de colectivos izquierdistas son ilegalizados, sus publicaciones prohibidas y varios de sus líderes arrestados. El día 15 Raymond Marcellin, Ministro de Interior desde el 31 de mayo, amnistió a 50 militantes presos de la OAS condenados por asesinato, entre los que se encontraban generales de la extrema derecha como Raoul Salan (que habían conspirado para derrocar a De Gaulle) con el objetivo de crear grupos de acción ciudadana contra los "elementos incontrolables". Durante un violento mes de junio, la totalidad de los centros de trabajo vuelven a la normalidad, bien por acuerdos de los trabajadores, bien por la intervención policial.

Los días 23 y 30 de junio se celebrarían las elecciones legislativas, de las que la gaullista Unión de Demócratas por la República saldría fortalecida con un 38% de los votos y 293 diputados, contando con sus aliados. El Partido Comunista, por su parte, sufrió un fuerte descenso en su representación en la cámara (no así en porcentaje de votos), pasando del 15 % de los sufragios y setenta y tres representantes al 20 % y treinta y cuatro diputados. Idéntica suerte sufrío la Federación de la Izquierda Democrática y Socialista (FGDS, por sus siglas en francés) de François Mitterrand, que perdió la mitad de sus diputados (61 frente a los 121 conseguidos el año anterior). La radicalización de los estudiantes franceses mostraba en la práctica una fuerte simpatía por el anarquismo y un rechazo por las estructuras políticas vigentes, incluyendo los sindicatos y partidos ya existentes y cuya disciplina no era del agrado de los manifestantes. Este estado de ánimo hizo que muchos obreros y estudiantes, si bien unidos en el rechazo al autoritarismo degaullista, rechazaran el liderazgo de los partidos comunistas y socialistas, negando la validez de su autoridad.

Tras las elecciones de junio, el gobierno francés reconoció la necesidad de emprender una política de reformas profundas para hacer frente al malestar social existente en el país. En abril de 1969 se celebró un referéndum sobre el proyecto de regionalización (una de las principales reivindicaciones políticas de aquellos momentos era una mayor descentralización del Estado) y la reforma del Senado, que De Gaulle planteó como un plebiscito sobre su gestión al anunciar que abandonaría la presidencia si no triunfaba el SÍ. Sin embargo, los franceses votaron mayoritariamente por el no, provocando la retirada de De Gaulle de la escena política. Estos resultados mostraron que De Gaulle y su generación no eran, para la población francesa, los que podían llevar a cabo la reforma social y política que necesitaba el país. La derrota gaullista marca el inicio del fin de la generación de líderes políticos que habían dirigido Europa Occidental desde el fin de la II Guerra Mundial, al tiempo que enterraba el modelo de liderazgo personalista que hasta el momento había marcado la Quinta República francesa.

Por su parte, el sindicalismo comenzó en 1969 las conversaciones previstas en los Acuerdos de Grenelle. Durante los primeros años de la década de los 70 se registraron nuevos conflictos laborales, en ocasiones con carácter violento como las huelgas de Renault durante marzo y abril de 1973. También se produjeron experiencias excepcionales como la de la empresa Lip, en la que mil trabajadores ocuparon la fábrica de relojes amenazada de cierre y durante 3000 días continuaron la producción bajo control obrero, hasta conseguir un acuerdo final que salvaba los puestos de trabajo. Se va a experimentar, por tanto, un mantenimiento de la conflictividad laboral en Francia durante los años posteriores a 1968 si bien la postura de las principales centrales sindicales no va a variar sustancialmente durante los congresos confederales que se celebrarán entre 1969 y 1970.





</doc>
<doc id="15325" url="https://es.wikipedia.org/wiki?curid=15325" title="Espionaje">
Espionaje

Se denomina espionaje a la práctica y al conjunto de técnicas asociadas a la obtención encubierta de datos o información confidencial. Las técnicas comunes del espionaje han sido históricamente la infiltración y la penetración, en ambas es posible el uso del soborno y el chantaje.



De ambos métodos, las agencias de inteligencia y los diferentes servicios de espionaje prefieren la penetración, dado que es más segura y requiere un menor esfuerzo logístico que la infiltración.

La preocupación en el espionaje industrial y de personas ha llevado al diseño de las Salas Tempest y protección tempest para empresas y ordenadores, por el robo de datos de personas famosas y de empresas. Por ejemplo, esta protección no está presente en los ordenadores de las consultas de la medicina pública o seguridad social en España.


En cualquier caso, dichas técnicas se basaban en la utilización de "informantes" , que como tales personas, son susceptibles de ser utilizadas y cuyos datos son acopiados por agentes de inteligencia quienes remiten informes una «central de análisis» que tiene la misión de separar los hechos concretos, de las suposiciones o aportes subjetivos del informante, comparar los datos recibidos (exactos, inexactos, completos o incompletos) con los hechos conocidos y verificados a fin de dar una clasificación sobre la exactitud de la información recibida y sobre la veracidad de la fuente.
"En el pasado del espionaje, cabe destacar el avance soviético. El espionaje internacional impartido por la Unión Soviética se basaba en varios métodos de fuente humana como:




Conexión entre Rezident y espía en general: cabe destacar aunque se aleja del tema el avance creado por la Unión Soviética. La instalación de radio por onda ultra corta (UHF) se emplea por comunicación entre los agentes y los Rezidents o entre los mismo Rezidents. Este se basa en el envío de un mensaje de voz corto. Con el fin de encontrarse o enviar su posición al compañero. Este es indetectable debido a que se usa solamente en distancias cortas y su contenido es muy bajo para ser detectado.

Con el desarrollo de las nuevas tecnologías, han aparecido técnicas que permiten obtener información objetiva como fotografías, conversaciones, etc. sin intervención humana. Así, existe hoy día una floreciente industria destinada a facilitar sofisticados medios tecnológicos, desde satélites espía hasta microcámaras, tanto para el espionaje como para la protección de la información. Laptops, computadoras y celulares también constituyen en la actualidad medios tecnológicos espías que se encargan de grabar, audio, vídeo, receptar datos, ideología y pensamiento a través del INTERNET y constituir un medio de rastreo.

El espionaje industrial es la obtención ilícita de información relativa a la investigación, desarrollo y fabricación de prototipos, mediante las cuales las empresas pretenden adelantarse a sus competidores en la puesta en el mercado de un producto novedoso. La creciente reducción de los plazos transcurridos entre la "idea" novedosa y la puesta en el mercado del producto, así como la cada día mayor obsolescencia de los productos de las nuevas tecnologías, hacen que estos sectores industriales sean el caldo de cultivo ideal para este tipo de actividades ilícitas.

Igualmente, con la aparición de los nuevos medios de transmisión de la información, del que internet es uno de los más populares exponentes, se encuentran en auge las técnicas para codificar la información, no sólo técnica sino incluso privada, que dificultan la decodificación de un mensaje interceptado por un tercero.




</doc>
<doc id="15327" url="https://es.wikipedia.org/wiki?curid=15327" title="Tiempo medio de Greenwich">
Tiempo medio de Greenwich

El tiempo medio de Greenwich o GMT ("Greenwich Mean Time" // ) es un estándar de tiempo que originalmente se refería al tiempo solar medio en el Real Observatorio de Greenwich, en Greenwich, cerca de Londres, Inglaterra, que en 1884 fue elegido por la Conferencia Internacional del Meridiano como el primer meridiano.

Antes de la introducción del tiempo universal coordinado (UTC) el 1 de enero de 1972, el tiempo medio de Greenwich (también conocido como Hora ZULU) era la misma que la del horario universal, que es un concepto estándar astronómico que se utiliza en muchos campos técnicos. Los astrónomos ya no utilizan el término "Greenwich Mean Time".

En el Reino Unido, GMT es el tiempo oficial solo durante el invierno; en verano se utiliza el horario de verano.

Durante muchos años los relojes más precisos que existían eran el movimiento de la Tierra alrededor de su eje y alrededor del Sol. A partir de ellos se definía todo lo demás relacionado con el tiempo. Una vuelta de la Tierra alrededor del Sol era un año, una vuelta de la Tierra sobre sí misma era un día, que se dividía en 24 horas, la hora en 60 minutos y el minuto en 60 segundos. En 1900 se definió un segundo como 1/86.400 de un día solar medio.

Esto era suficientemente preciso para las actividades cotidianas, pero poco a poco se fue observando que la Tierra no era el mejor reloj. Las mareas hacen disminuir su giro con cierta regularidad pero, además, hay otras influencias que hacen que la duración de ese giro no sea constante. Las diferencias no afectan a la vida cotidiana pero sí pueden afectar a la precisión de la navegación o a la posición de los satélites artificiales, por ejemplo.

Con el avance del conocimiento del átomo se descubrió un reloj más preciso, la frecuencia de resonancia de ciertos átomos cuando pasaban de un estado a otro. En 1950, en el Laboratorio Nacional de Física un estadounidense construyó el primer reloj basado en esa propiedad de los átomos, al cual se denominó reloj atómico. En su construcción se utilizaron átomos de cesio. Su precisión era tan alta que en 1967 los organismos de normas internacionales cambiaron la definición de segundo basada en el movimiento de la Tierra por una definición basada en el átomo de cesio: el segundo, unidad de tiempo del Sistema Internacional de Unidades, es la duración de 9.192.631.770 períodos de la radiación asociada a la transición hiperfina del estado base del átomo de cesio 133, con la siguiente observación: el estado base se define con campo magnético cero.

El error de los relojes atómicos basados en el cesio es de una parte en 10 . Son mucho más precisos que el giro de la Tierra y suplantaron a ésta en la definición del tiempo internacional. En 1972 se adoptó una medida universal que utiliza la definición atómica de segundo. A ese tiempo se le llama en todas las lenguas UTC (Tiempo Universal Coordinado).

Dado que el giro de la Tierra es menos uniforme que el comportamiento de los relojes atómicos, hay una cierta discrepancia entre el tiempo solar medio, base del GMT, y el UTC. Para que haya sincronía entre los dos tiempos, lo que se hace es controlar con extrema precisión el giro de la Tierra. Se admite que UTC y GMT son correctos si no difieren en más de 0,9 segundos. Si difieren en más de esa cantidad, se añade o se quita un segundo a los relojes atómicos.

La primera vez que se hizo la adaptación fue el 30 de junio de 1972 a las doce de la noche, con lo que los tiempos UTC y GMT quedaron sincronizados el 1 de julio. Las siguientes veces que se ha hecho, hasta hoy en día, siempre ha sido añadir un segundo, pero también podría haber sido restar un segundo si la rotación de la Tierra hubiese variado de otro modo.





</doc>
<doc id="15329" url="https://es.wikipedia.org/wiki?curid=15329" title="Bormujos">
Bormujos

Bormujos es un municipio español de la provincia de Sevilla, Andalucía. Se encuentra a unos 7 km de la capital de la provincia y tiene 12,2 km². Cuenta con una población (2016) de 21.476 habitantes.

Los autores no se ponen todavía de acuerdo sobre el origen del nombre del pueblo. Según García de Diego, dicho nombre puede provenir del latín "Mormolium" (manania). Pero también es igualmente probable que provenga del nombre dado a una alquería musulmana, "Boromuj". De esta época quedan aún vestigios como los hallados en la hacienda de Valencinilla del Hoyo. La primera referencia a la alquería de Bormujos la proporciona la documentación medieval cristiana, en 1253, mediante las voces "Mormuios" y "Mormoios", defendiendo Antequera Luengo su raíz arábiga: "Borg-muzn" o "Borg-muhur". En este sentido, el topónimo no ha tenido asiento sino hasta tiempos modernos, con variantes, de manera que aún a fines del XVIII la localidad era conocida, también, como "Mormujos", pervivencia bajomedieval. Solo en el espacio de dos años (1787-1788) aparecen tres variantes: "Mormujos", "Borbujos" y una mezcla de ambas, Bormujos, que prosperó como producto de la disimilación de nasales.

El valle del Guadalquivir fue conquistado por Fernando III en el siglo XIII. En el repartimento firmado por su hijo, Alfonso X, aparece esta villa con el nombre de Mormojos o Mormujos. Fue concedida el 15 de septiembre de 1253, junto con las alquerías de Mairena, Paterna, Alcaudín, Malharomata y Albarat, a "doscientos cavalleros fisjosdalgo", aparte de otra serie de privilegios y propiedades, por el buen servicio que prestaron en la Reconquista.

Así rezan las concesiones:

Poco después, la villa pasó a depender del Ayuntamiento de Sevilla hasta finales del siglo XVII o principios del XVIII. En ese momento pasó a manos de los condes de Olivares (de la casa Guzmán). Esto duraría hasta la abolición de los señoríos a comienzos del siglo XIX. Desde entonces se constituyó como un municipio independiente.

En 1999 se inauguró en la localidad el primer campus universitario privado de Andalucía. Fue diseñado como una filial de la universidad madrileña CEU San Pablo.

A lo largo de los años 2000 la población se duplicó, pasando de los 8.223 en 1999 a 16.548 en 2007. La siguiente tabla muestra la evolución en los últimos diez años:

Se trata de un edificio de la Baja Edad Media. Fue reformado entre 1678 y 1681 por Antonio Rodríguez y Francisco Romero. La portada principal y la del lateral izquierdo fueron decoradas entre 1778 y 1779 y probablemente sean obra de Pedro de Silva.

Es un edificio de planta rectangular con tres naves. Las bóvedas de las naves están sostenidas por arcos de medio punto apoyados en columnas. La capilla bautismal se encuentra en la nave izquierda, junto a la entrada principal. Al final del templo, adosada a la nave derecha, hay un edificio de planta cuadrada adosado al mismo, que es la capilla del Sagrario.

El retablo mayor cuenta es de 1770. Está decorado con temas de rocalla y flanqueando su parte central hay dos columnas estriadas. En la parte central hay un gran camarín con un grupo escultórico de la Anunciación del ángel Gabriel la Virgen y sobre él hay otro camarín más pequeño con un crucificado del siglo XVIII.

La cofradía de la Vera Cruz es la segunda más antigua de la localidad. Se tienen noticias de su fundación en 1634. En 1687 se fusionó con la hermandad sacramental de su parroquia. Posteriormente desapareció y fue refundada a principios de la década de 1990. También es titular la Virgen de los Dolores. Procesiona el Miércoles Santo.

En Bormujos hay constancia de la devoción al Rosario y de una Cofradía ya en 1673. En el informe de la Visita Diocesana de ese año se especifica que aún no tenía reglas y se manda la elabore y presente. Su instituto principal consistía en la celebración de fiestas mensuales.

En las primeras décadas del XVIII, al igual que en otros lugares, pudo refundarse esta cofradía,coincidiendo con la hechura del retablo e imagen y con unas predicaciones cuaresmales que a comienzos del XVIII pronunciara un fraile dominico de Porta Coeli que marcaron profundamente la sensibilidad de pueblo, tal y como figura en una visita pastoral de la época.

En el inventario parroquial de 1781, que reproduce Pineda Novo, se dice textualmente:

""...en la iglesia nueva un altar de Ntra.Sra.del Rosario,de madera,pintado de encarnado y verde, con un Señor Crucificado a el fin del altar;y la Señora tiene un vestido de raso encarnado con punta de plata, con un Niño Jesús vestido de lo propio y un rosario engarsado en plata,con cuentas encarnadas; y asimismo un velo de raso pajizo y blanco y un velo de gasa el Señor"" En otro lugar se mencionan las coronas de plata de la Virgen y el Niño.

La gran artífice de la Renovada Hermandad se llama Dolores Vázquez, quien es nombrada mayordoma y capiller a instancia de las cofradías por el propio Arzobispo Benito Sanz y Forés en 26 de Noviembre de 1890 sin límite temporal, lo que luego se ratificará en cabildo general del 29 del mismo mes, al decidirse que su mandato fuera perpetuo. Desde 1899 se la denomina Hermana Mayor.

Fue una hermandad de mujeres exclusivamente, aunque entre 1902 y 1903 se permite la inscripción de seis cofrades varones. Desde 1917 no se registra más actividad en este libro hasta que tiene efecto muchos años después, en 1 de Noviembre de 1950, una refundación de la Hermandad. En el cabildo constituyente presidido por el párroco Domingo Márquez y al que asisten 43 cofradas (denominadas socias) se nombra presidenta a Juana Gordillo Librero. También se decide actualizar el inventario y las cuotas así como celebrar solemne Función Principal el 7 de Octubre próximo.

Hermandad en la actualidad

En la actualidad la Hermandad cuenta con numerosos actos a lo largo del año, pero los más importantes sin duda son las Fiestas de Octubre en las cuales se realizan diversos actos para mayor honor y Gloria de María Santísima Nuestra Señora del Rosario.
El primer fin de semana de Septiembre se celebra su velá en la denominada "Plazoleta el Cano" donde todos los hermanos y vecinos de Bormujos acuden a una serie de actuaciones programadas por la hermandad donde se pueden disfrutar tapas a precios populares a beneficio de esta hermandad. 

A finales de Septiembre se celebra su pregón, y la presentación del cartel de las fiestas del Rosario,siendo esto el comienzo de las Gloriosas Fiestas de Octubre. En días posteriores se celebra la salida del Simpecado de gala de la hdad por las calles del pueblo, acompañado musicalmente por el Coro de Campanilleros Santo Domingo de Silos de nuestra localidad.

Una vez concluido el rezo del santo Rosario por las calles del pueblo acompañando al simpecado de gala, se procede a celebrar el triduo en honor y Gloria de María Santísima del Rosario.

El dia 7 de Octubre, día de nuestra titular, se celebra la Función Principal de Instituto y el Solemne Besamanos, donde se puede ver de cerca a nuestra madre bendita y besar su mano.

El Domingo siguiente a su festividad tiene lugar la salida procesional de María Santísima del Rosario por las calles de Bormujos siendo el broche de oro de las fiestas del Rosario en la cual todos los hermanos, devotos y feligreses la acompañan por las calles de su pueblo entre Vítores, Flores y Alabanzas a María.

A las afueras existe un convento de dominicas construido en 1976. En su capilla alberga numerosas piezas antiguas de tres conventos fusionados: el de Santa María de Gracia, el de Santa María de los Reyes y el de Santa María la Real. Tiene un coro con decoración geométrica de mediados del siglo XVII. En la pared hay un sagrario de madera dorada de la segunda mitad del siglo XVI. A la izquierda hay una Virgen del Rosario del siglo XVIII y en el lado derecho hay un crucificado a tamaño natural del siglo XVI. También alberga una imagen de santo Domingo del siglo XVIII. También puede destacarse un lienzo de santa Teresa del siglo XVII.

En la parte alta del convento hay un salón con diversas piezas de valor artístico, como un Juan Bautista de Juan de Mesa, una Piedad de Cristóbal Ramos, un san Miguel arcángel de la segunda mitad del siglo XVIII y una pintura de la inmaculada de la escuela madrileña de mediados del siglo XVIII.

Al igual que en otros muchos pueblos, e incluso en las afueras de muchas ciudades, hay ejemplos de arquitectura rural andaluza. La Hacienda de Belén se encuentra donde pudo estar el origen del pueblo. Es un edificio de arquitectura rural andaluza que hoy tiene usos municipales. La Hacienda del Cristo de la Mata se encuentra a las afueras. Antiguamente ahí había una alquería musulmana. El actual caserío data del siglo XVII. Originalmente se le llamó Hacienda de la Mata del Almíjar. Existen otras tres haciendas, aunque en mal estado de conservación: la de la Peregrina, la de Marchalomar y la de Valencinilla del Hoyo.

Hay 46 ha de cultivos herbáceos, de las cuales 20 ha son de trigo y 2 ha de avena. En cultivos leñosos hay 447 ha, de las cuales 408 ha de olivar de aceituna de mesa. Al sur del núcleo urbano está el polígono industrial Almargen y al norte el polígono industrial Aceitunillo.




</doc>
<doc id="15330" url="https://es.wikipedia.org/wiki?curid=15330" title="Espacio regional">
Espacio regional

Uno de los problemas clásicos de la geografía es determinar qué y cuál es el espacio regional, o región. Una región es un espacio que se organiza de forma homogénea y de manera diferenciada.

Según el criterio que se utilice para dar coherencia al espacio tendremos un tipo de región u otro. Estos criterios dependen de la escala, por lo que frecuentemente las regiones están solapadas. Se puede distinguir entre: región natural, histórica, económica, urbana, etc. Dado el carácter multidisciplinar de la geografía, y de las distintas escalas y espacios que utilizamos, los fenómenos se distribuyen en las regiones solapándose unos con otros. Es prácticamente imposible que a una región geográfica la podamos definir por todos los criterios. Debemos, pues, elegir un fenómeno dominante para definir las regiones en el espacio.

El estudio de la región tuvo gran importancia en la geografía de Paul Vidal de la Blache, pero su rígido concepto de región tendió a provocar anquilosamiento de su geografía.


</doc>
<doc id="15331" url="https://es.wikipedia.org/wiki?curid=15331" title="Fosfeno">
Fosfeno

Un fosfeno es un fenómeno caracterizado por la sensación de ver manchas luminosas que está causado por la estimulación mecánica, eléctrica o magnética de la retina o corteza visual. Un ejemplo de fosfeno son los patrones luminosos que se ven al frotar los párpados con bastante presión. Los fosfenos son un fenómeno entóptico.

Se ha relacionado los fosfenos con la neuritis óptica.

En 1918 Lowënstein y Borchard descubrieron que tras la estimulación eléctrica del córtex visual aparecían fosfenos. Penfield y su grupo de investigación en la década de 1950 confirmaron los fosfenos y que la estimulación eléctrica de ciertas zonas del cerebro producían imágenes (fosfenos) como sonidos, sensaciones táctiles.

Brindley y Lewin, en la Universidad de Cambridge, y un grupo de investigadores de la Universidad de Utah, dirigidos por Dobelle, estudiaron a fondo los fosfenos y establecieron los cimientos para hacer una prótesis visual basada en señales eléctricas inyectadas mediante electrodos en el córtex visual. En 1976 el grupo de Dobelle logró que ciegos de larga duración lograran ver caracteres Braille utilizando seis electrodos. La lectura era mucho más rápida que con el tacto.

Eran los primeros intentos de realizar prótesis neuronales. Hoy todavía no están bien establecidas pues sigue habiendo problemas con la implantación permanente de electrodos en el cerebro: oxidación, inflamación de las meninges, etc. 

En 2002 el Instituto de Astrofísica de Canarias desarrolló un programa de sustitución sensorial en el que se crea un espacio visual sonoro. Se crea un espacio sonoro que los ciegos pueden interpretar. Pensemos por ejemplo que todos los objetos se recubren de campanillas que suenan al mismo volumen, la distancia viene señalada por el nivel de dicho volumen.


</doc>
<doc id="15338" url="https://es.wikipedia.org/wiki?curid=15338" title="Religión mexica">
Religión mexica

Los mexicas originalmente eran una de las tribus nahuas y cuando llegaron al valle de México, traían sus propias creencias y divinidades. La más importante de sus divinidades era Huitzilopochtli, cuyo nombre puede traducirse literalmente como "colibrí izquierdo", "el colibrí zurdo" o "colibrí del sur"; sin embargo, según Laurette Séjourné, en el lenguaje esotérico náhuatl se puede traducir como "el alma del guerrero que viene del paraíso".

Al llegar al valle de México o valle del Anáhuac, los mexicas trataron de incorporar la cultura y los dioses de las civilizaciones más avanzadas que ya estaban establecidas, así como los de civilizaciones más antiguas como la tolteca; así, incluyeron a Tláloc, Tezcatlipoca y a Quetzalcóatl.

Sin embargo, algunos dirigentes mexicas (como Tlacaelel) modificaron la historia para poner a su dios tribal, Huitzilopochtli, al mismo nivel que los demás dioses nahuas.

Conforme los mexicas comenzaron a conquistar a otros pueblos, fueron aceptando nuevos dioses y enlazando sus historias con las de los dioses que ya tenían.

Estudiosos como Miguel León-Portilla sugieren que, en la época de la conquista, los mexicas estaban en un proceso de sincretización donde todos los dioses serían sólo expresiones de las potencias de una deidad principal, Ometéotl/Omecíhuatl. 

Ésta es una antigua pareja de dioses; sus nombres literalmente significan "Señor dios, Señora dios", pero usualmente se traduce como "nuestro señor/señora de la dualidad", lo que implica un dios con características femeninas y masculinas. Este dios es mucho más antiguo que la civilización nahua, y según algunas leyendas es el origen de todos los dioses. El pueblo difícilmente lo conocía, pero entre las clases superiores se le rendía una especie de culto. Otros nombre que recibía eran: "El señor del cerca y junto", "El inventor de sí mismo" y Tonacatecuhtli ("El señor de nuestra carne").

Por fuera de la religión popular, llena de dioses con complicadas historias y parentescos, producto del sincretismo de las civilizaciones nahuas y de la herencia tolteca, los sacerdotes y los tlamatinime (sabios) desarrollaron una profunda visión monista (según los eruditos más destacados, como Alfonso Caso y León-Portilla). Otros investigadores, como A. R. Sandstrom, con base en investigaciones sobre las comunidades nahuas del México actual, sostienen que la concepción era panteísta, postura que es apoyada por Hunt, Markman, Florescano y Ortiz de Montellano.

La síntesis de estas concepciones se centra en la figura de Téotl ("q.v."), y su traducción a la religión popular en el dios dual (o pareja de dioses) Ometéotl.

La cultura mexica es particularmente notable por la práctica de sacrificios humanos; los ofrecimientos a Huitzilopochtli serían hechos para restaurar la sangre que perdió, ya que el sol era confrontado en una batalla diaria. Esto prevendría el fin del mundo que podría suceder en cada ciclo de 52 años. La dedicación del gran templo en Tenochtitlán fue divulgado por los mexicas según lo referido, con un sacrificio de más de 84.000 prisioneros; sin embargo, este número probablemente fue una exageración de los mismos mexicas para infundir miedo entre sus enemigos, pues en el relato insisten en que el Tlatoani sacrificó personalmente a todas las víctimas en el curso de 4 días. Como medida de comparación, en los días finales del campo de concentración de Dachau, con tecnología moderna las 24 horas, se podía disponer de 4.500 víctimas al día.

Las víctimas sacrificadas a Xipe Tótec eran atadas a un poste y eran cubiertas por completo por flechas que les eran lanzadas. Posteriormente el cadáver sería desollado y un sacerdote se cubriría con la piel. Representan la renovación de la tierra para volver a ser fértil. La Madre Tierra, Teteoinnan, requería víctimas femeninas desolladas. Tláloc requería niños enfermos masculinos.

Los mexicas frecuentemente iniciaban guerras - las llamadas guerras floridas - con el intento de capturar prisioneros para usarlos en los sacrificios. Existen múltiples relatos de los conquistadores capturados que fueron sacrificados durante las guerras de la conquista española de México, aunque solamente Bernal Díaz afirmó ser un testigo de ello.

En ocasiones, los mexicas mataban a los cautivos más aristocráticos, notables por su valor en combate ritual: encadenaban la víctima al piso, quien vestía solamente un taparrabos, le daban un arma falsa y un escudo, y era muerto luchando contra un guerrero jaguar completamente armado. Se dice que cuando un pueblo era derrotado, los sacerdotes mexicas seleccionaban de los cautivos, al guerrero más destacado de los adversarios y lo tiraban por las escaleras del Templo Mayor. Al terminar su caída, los intestinos eran utilizados para las fieras del zoológico, y el cuerpo era entregado al guerrero. Este hervía el cuerpo y separaba la carne, se quedaba con los huesos como trofeo y partía la carne en fragmentos muy pequeños que ofrecía a los señores, incluso de otros pueblos. Los señores pretendían comerla, pero según algunos relatos, como el Códice Ramírez, y la relación del nieto de Nezahualcóyotl, la carne en sí, se consideraba que carecía de valor, por lo que era sustituida por carne de guajolote (pavo). A cambio de esta carne, el guerrero recibía grandes obsequios: Joyas, plumas ricas, mantas finas y esclavos. Este era un método para estimular a los guerreros exitosos y ayudarlos a subir en la escala social.

Tezcatlipoca requería un sacrificio voluntario. Cada año un joven era ofrecido como víctima. Durante un año lo honrarían como dios en la tierra, y entonces éste sería sacrificado. Tláloc requería niños llorones (enfermos). Xilonen requería ahogar a dos jóvenes.

A pesar de los relatos populares, los mexicas no hacían sacrificios humanos cada día. Los sacrificios se hacían sólo en los días festivos. Un día festivo por cada uno de sus 18 meses. Cada mes estaba dedicado a un dios distinto.

También se hacían sacrificios de animales, había dos razas de perros criados expresamente para ello, y la gente también hacía autosacrificio, ofrendando su propia sangre y sufrimiento a sus dioses.

En la adoración del Sol de las religiones mexica, inca y maya los sacrificios humanos eran algo común. Los aztecas celebraban unos constantes ciclos de fiestas religiosas con sacrificios humanos a sus diversos dioses, especialmente al adorar al dios-Sol Tezcatlipoca. Además, en la fiesta al dios del fuego, Xiuhtecuhtli (Huehueteotl), "a los prisioneros de guerra se les hacía danzar con sus captores y [...] se les hacía girar alrededor de un fuego intenso y entonces se les arrojaba en las brasas y se les alzaba mientras todavía estaban vivos para sacarles el corazón todavía palpitante y ofrecerlo a los dioses”.

Las formas y manifestaciones del Sol son un componente central de la cosmogonía mexica. Por lo tanto, no habrá de sorprender que sus calendarios (ver calendario azteca) sean solares y estén directamente vinculados a diversas formas religiosas. El calendario mesoamericano está integrado por 18 meses de 20 días cada uno, más 5 días nefastos.




</doc>
<doc id="15339" url="https://es.wikipedia.org/wiki?curid=15339" title="Thomas Alva Edison">
Thomas Alva Edison

Thomas Alva Edison (Milan, Ohio, 11 de febrero de 1847 - West Orange, Nueva Jersey, 18 de octubre de 1931) fue un empresario y un prolífico inventor, considerado el inventor más importante de Estados Unidos. Desarrolló muchos dispositivos que han tenido gran influencia en todo el mundo, como el fonógrafo, la cámara de cine o una duradera bombilla incandescente. Apodado «El mago de Menlo Park», Edison fue uno de los primeros inventores en aplicar los principios de la producción en cadena y el trabajo en equipo a gran escala al proceso de invención, motivos por los cuales se le reconoce la creación del primer laboratorio de investigación industrial.

Edison fue un inventor prolífico que registró 1093 patentes a su nombre en Estados Unidos, además de otras en Reino Unido, Francia y Alemania. Pero más importante que sus muchas patentes fue el amplio impacto que tuvieron algunas de sus invenciones: la luz eléctrica y el suministro público de electricidad, la grabación de sonido y la cinematografía se convirtieron en nuevas y poderosas industrias en todo el mundo. Sus inventos contribuyeron en particular a las telecomunicaciones, como una máquina de voto, una batería para un automóvil eléctrico, la energía eléctrica, la grabación de música y las películas. Sus avanzados trabajos en estos campos no fueron más que una continuación de su primer trabajo como radiotelegrafista. Edison desarrolló un sistema de generación y distribución de energía eléctrica a las casas, negocios y fábricas, un avance crucial para el mundo industrializado moderno.

Hijo de Samuel Ogden Edison, Jr. (1804-1896) y Nancy Matthews Elliott (1810-1871). Sus antepasados provenían de Ámsterdam y se establecieron en el río Passaic, en Nueva Jersey. John Edison, el abuelo del inventor, se alistó en el bando de los británicos durante la Guerra de Independencia y, a final de la misma, tuvo que refugiarse en Nueva Escocia. Después de un tiempo se trasladó a Canadá para residir en Bangham, en la zona del lago Erie. Cuando estalló la rebelión canadiense en 1837, Samuel Edison (padre del inventor) se unió a los insurgentes. Una vez más la familia se vio obligada a huir a los Estados Unidos.

En 1840 Samuel Edison estableció una pequeña maderería en Milan, Ohio. Antes de que la familia se estableciera en Milan, su esposa Nancy, una canadiense de ascendencia escocesa, había tenido cuatro hijos. Posteriormente tuvo tres más, pero murieron tres de los primeros en la década de 1840 y los sobrevivientes tenían catorce, dieciséis y dieciocho años cuando el 11 de febrero de 1847, la esposa de Samuel Edison dio a luz a su séptimo hijo. Le llamaron "Thomas" por un antepasado de la familia, y "Alva" en honor del capitán Alva Bradley.

En 1855 a los ocho años y medio Edison entra a la escuela. Después de tres meses de estar asistiendo, regresó a su casa llorando, informando que el maestro lo había calificado de alumno "estéril e improductivo". Es imposible establecer si Nancy Edison tomó muy en serio la opinión de su maestro o si pensó que ella era mejor que el profesor de su hijo. El caso es que Edison recordó durante el resto de su vida el resultado del dichoso incidente.

En 1859 empezó a vender diarios en el tren matutino que iba de Port Huron a Detroit, así como verduras, mantequilla y moras. En Detroit el tren hacía una parada de seis horas, las cuales aprovechaba pasándolas en el salón de lectura de la Asociación de Jóvenes (después Biblioteca Gratuita de Detroit). Ahí, comenzaba por leer el primer libro que se encontraba en el anaquel inferior y seguía por orden con los demás hasta terminar con toda la hilera.

Edison no quedaba satisfecho con solo leer, y comenzó a realizar diversos experimentos basándose en lo que leía en los libros de Ciencia. Utilizaba un vagón vacío como laboratorio, donde también instaló una pequeña prensa de mano que se agenció cuando un amigo del "Detroit Free Press" le regaló algunos tipos. El resultado fue inmediato: el "Grand Trunk Herald", semanario del que Edison tiraba cuatrocientos ejemplares.

Tras salvar a un niño en las vías del tren en Port Huron, el agradecido padre de la criatura J. U. Mackenzie (telegrafista de la estación) le enseñó código morse y telegrafía. A los quince años obtuvo su primer trabajo como telegrafista, reemplazando a uno de los operadores de telégrafo que habían ido a servir en la Guerra Civil.

A los 16 años, después de trabajar en varias oficinas de telégrafos, donde realizó numerosos experimentos, finalmente llegó con su primera auténtica invención, llamada "repetidor automático", que transmite señales de telégrafo entre estaciones sin personal, lo que permite que prácticamente cualquiera pueda traducir fácilmente y con precisión un código a su propio ritmo y conveniencia. Curiosamente, nunca patentó la versión inicial de esta idea.

Edison ideó un instrumento sencillo para el recuento mecánico de votos en 1868. Se podía colocar en la mesa de cada representante; tenía dos botones, uno para el voto en pro y otro para el voto en contra. Para tramitar la patente, Edison contrató al abogado Carroll D. Wright. El instrumento se llevó ante un comité del Congreso de Washington. Ahí el veredicto fue brusco pero honesto: "Joven, si hay en la tierra algún invento que no queremos aquí, es exactamente el suyo. Uno de nuestros principales intereses es evitar fraudes en las votaciones, y su aparato no haría otra cosa que favorecerlos".

En 1869, Edison y Franklin Pope ofrecieron sus servicios como ingenieros electricistas, una especialidad desconocida por entonces. Pero Edison se retiró porque sentía que no ganaba suficiente. En Nueva York, consiguió un empleo de condiciones muy ventajosas tras reparar una grave avería en un indicador telegráfico que señalaba los precios del oro en la Bolsa.

Trabajó en la compañía telegráfica Western Union como inventor y reparador, aunque poco después se independiza y en 1877 lleva a cabo uno de sus más importantes inventos, el fonógrafo.

En 1876, Edison se mudó de Newark a Menlo Park, Nueva Jersey, donde reunió un grupo de ayudantes y mecánicos y estableció una "fábrica de inventos". En 1887, cuando dejó Menlo Park, contaba con una lista de casi cuatrocientas patentes.

Aunque se le atribuye la invención de la lámpara incandescente, esta en realidad solo fue perfeccionada por él, quien, tras muchos intentos consiguió un filamento que alcanzara la incandescencia sin fundirse. Este filamento no era de metal, sino de bambú carbonatado. Así, el 21 de octubre de 1879, consiguió que su primera bombilla luciera durante 48 horas seguidas. En la víspera de Año Nuevo del mismo año, se hizo funcionar con éxito en Menlo Park el primer sistema de alumbrado, construido por Edison, constituido por cincuenta y tres focos.

En 1880 se asocia con J. P. Morgan para fundar la Edison Electric. Después J. P. Morgan le quitaría sus acciones para crear General Electric.

En el ámbito científico, descubrió el efecto Edison, patentado en 1883, que consistía en el paso de electricidad desde un filamento a una placa metálica dentro de un globo de lámpara incandescente. Aunque ni él ni los científicos de su época le dieron importancia, estableció los fundamentos de la válvula de la radio y de la electrónica (el denominado "efecto Edison").

Las aportaciones de Edison al mundo del cine también fueron muy importantes. En 1889 comercializa la película en celuloide en formato de 35 mm, aunque no la pudo patentar porque un tiempo antes George Eastman ya lo había hecho; aunque sí pudo patentar las perforaciones laterales que tiene este tipo de película.

En 1894 los quinetoscopios de Edison llegan por primera vez a Europa; más concretamente a Francia. Dos años después, en 1896, presenta el vitascopio en Nueva York con la pretensión de reemplazar a los quinetoscopios y acercarse al cinematógrafo inventado por los hermanos Lumière.

Por último, en 1897, Edison comenzará la llamada «guerra de patentes» con los hermanos Lumière respecto al invento de la primera máquina de cine.

Muere el 18 de octubre de 1931, en West Orange, Nueva Jersey. Como homenaje póstumo, fueron apagadas las luces de varias ciudades durante un minuto.

Es el inventor más prolífico de la historia: la obtención de su última patente, la 1093.ª, fue a sus 83 años.

Su genio y actividad significó una transformación en la actividad de inventar, desde un simple entretenimiento a la creación de una empresa.






</doc>
<doc id="15340" url="https://es.wikipedia.org/wiki?curid=15340" title="Iglesia de Roma (desambiguación)">
Iglesia de Roma (desambiguación)

Iglesia romana o de Roma puede referirse a:

En contextos actuales:

En contextos históricos:

</doc>
<doc id="15342" url="https://es.wikipedia.org/wiki?curid=15342" title="Mesolítico">
Mesolítico

Mesolítico es el término que se utiliza para resumir el período de la prehistoria que sirve de transición entre el Paleolítico y el Neolítico. Significa "Edad media de la piedra" (del griego μεσος, "mesos"=medio; y λίθος, "líthos"=piedra) por contraposición al Paleolítico ("Edad antigua de la piedra") y al Neolítico ("Edad nueva de la piedra"), identificándose con las últimas sociedades de cazadores-recolectores. Los hábitos de las culturas del Mesolítico eran básicamente nómadas, con asentamientos estacionales de invierno y campamentos de verano, aunque en algunas regiones costeras europeas y en el Oriente Próximo (allí donde encontraron recursos suficientes y regulares) comenzaron a vivir de una manera más sedentaria. Esto fue posible gracias a la ampliación del espectro alimentario, que incluyó una gran variedad de alimentos que los especializados cazadores del Paleolítico superior no consumían. Relacionado con estos cambios de dieta estaría la mayor diversificación, especialización y cantidad de utensilios líticos, así como la desaparición de la pintura rupestre figurativa paleolítica, reemplazada por un arte más abstracto.

El término Mesolítico fue acuñado por John Lubbock en su obra "Prehistoric Times", de 1865, cuando estableció la división de la Edad de Piedra anteriormente mencionada. Durante mucho tiempo fue visto únicamente como una etapa de transición, de decadencia incluso, entre los otros dos grandes períodos. Pero a principios del siglo XX se demostró que había una clara continuidad cultural, por lo que se acuñó un término nuevo para definir esta fase: Epipaleolítico ("Por encima del Paleolítico"), que no fue aceptado en todo el mundo científico. Actualmente, en el ámbito anglosajón generalmente se utilizan ambos términos como sinónimos, mientras que en el área de influencia académica francesa se suele establecer una clara diferencia entre ellos: 

Una tercera tendencia sería la de aquellos autores que identifican Epipaleolítico con las sociedades del Holoceno inicial de clara tradición paleolítica y Mesolítico con sus sucesoras.

Por último, hay quien propone un tercer término para este periodo:

El Mesolítico comenzaría con la transición del Pleistoceno al Holoceno, hace unos 12 000 años, y finalizaría con la aparición de los modos de vida productores, cuya cronología varía mucho de unas regiones a otras y de un continente a otro: mientras que en el Oriente Próximo la neolitización despuntaba sobre el 9000 a. C., a Escandinavia y ciertas áreas de la Europa atlántica no llegó hasta el 4000 a. C.

En el Oriente Próximo la dieta de espectro amplio empezó a adoptarse hacia el 12000 a. C. con los grupos natufienses, herederos de los kebarienses, que presentan las primeras muestras de urbanismo en el yacimiento de Nahal Oren. El natufiense es un complejo cultural que se extendió por todo el Levante mediterráneo y se caracteriza por la existencia de pequeñas aldeas formadas por cabañas circulares con zócalos de piedra que, en ocasiones, tienen silos anexos donde se guardaba el cereal silvestre recolectado, aunque también sirvieron como lugar de enterramiento. De forma paralela se desarrollaron los grupos de Karim Shair en el norte de Irak, los cuales recolectaban también vegetales y empezaban a ensayar la domesticación de la cabra. Hay procesos similares y contemporáneos en el Alto Egipto y Nubia. Hacia el 10300 a. C. éstos comienzan a darse en el norte de India, en el estado de Uttar Pradesh. Sobre el 9000 a. C. en el sur de China, en la provincia de Yunnan, así como en Japón, México, costa peruana y valle del río Misisipi.

Esta época estuvo marcada por la finalización del último periodo glacial y la progresiva implantación de un clima templado/cálido que permitió el aumento de los bosques y la biodiversidad, aunque también provocó la inundación de amplias zonas costeras. Cambios que influyeron necesariamente en el comportamiento y en la cultura material de los humanos de la época.

La retirada de los hielos en Eurasia y América del Norte condujo a la formación de extensas praderas temporales que fueron pronto sustituidas por frondosos bosques. Alrededor de los trópicos se crearon amplias fajas esteparias y/o semidesérticas. Como consecuencia de estos cambios ecológicos y, posiblemente, de la presión cinegética del "Homo sapiens", la megafauna pleistocénica se extinguió, aunque mamíferos como el reno y el bisonte emigraron hacia latitudes más nórdicas. Prosperaron animales de costumbres forestales y menos gregarias, cuya caza resultaba más compleja: el ciervo, el alce o el jabalí.

Al comenzar el Holoceno, el Levante mediterráneo presentaba un variado mosaico de ecosistemas formado por llanuras costeras, una franja boscosa, estepas mesetarias y desiertos. Estos ambientes soportaban una rica fauna y flora que permitió a sus pobladores asentarse de manera más o menos estable en aldeas manteniendo una economía de caza-recolección.

Al desaparecer o emigrar los animales que suponía la base de la dieta humana en el Paleolítico superior el espectro alimentario tuvo que ser ampliado. Para cazar las especies forestales el hombre debió utilizar perros, el primer animal que domesticó, ya a finales del Paleolítico superior en Europa occidental. La dieta se diversificó enormemente, incluyendo entonces otros pequeños mamíferos y aves como los gansos, tordos, faisanes, palomas, etc. La recolección de frutos y raíces se extendió, y aumentó espectacularmente el consumo de caracoles y conchas, como lo demuestran los enormes "concheros" de la vertiente atlántica europea y los "caracoleros" de las cuevas pirenaicas. También se comenzó a desarrollar la pesca fuera de la costa, en mar abierto.

Se fabricaron trineos, en un principio tirados por hombres y luego por perros, y canoas hechas con pieles o cortezas de árboles. De la corteza del abedul extraían un producto utilizado como cola. Aunque en Europa nunca se abandonaron del todo las cuevas, se construían también chozas de troncos y ramas a orillas de los ríos, en las cuales vivían al aire libre, y de las cuales se conservan pocos vestigios, pero en cuyos emplazamientos se localizan objetos de piedra tallada; tales lugares son conocidos como "talleres de sílex". En lugares costeros ricos en pesca y marisco se establecieron los primeros asentamientos permanentes de gran tamaño.

La industria lítica muestra una clara tendencia a la fabricación de pequeños utensilios adaptados a las nuevas situaciones y usos, muy especializados, los microlitos. Estos eran utilizados para la recolección de moluscos y para su apertura, como puntas de flecha, como raspadores, buriles, etc. Las armas más abundantes fueron los arcos, hechos de madera y tendones de animales, con flechas que incorporaban en su punta microlitos de variadas formas geométricas: triángulos, trapecios, etc. También se usaron flechas manufacturadas enteramente en hueso, en asta o en madera.

En el Próximo Oriente se produjo un aumento en la densidad de la población, que comenzó claramente a hacerse más sedentaria. En la que se conoce como cultura natufiense ya se anticipaban los grandes cambios del Neolítico. Eran cazadores-recolectores altamente especializados en la caza de la gacela y en la recolección de cereales silvestres, que almacenaban en silos situados en campamentos base ocupados durante todo el año. Estos estaban formados por aglomeraciones de viviendas circulares, semiexcavadas en el suelo, de una sola habitación y probablemente construidas con troncos y ramas. Utilizaban molinos y morteros de piedra de gran tamaño (algunos de ellos decorados en sus bordes), hoces y cuchillos de hueso adornados con figuras de animales, y enterraban a sus muertos en necrópolis cercanas a los poblados (en cuevas) o bajo el suelo de las casas. En los ajuares de estos enterramientos se comienzan a apreciar diferencias sociales que pueden estar relacionadas con unas incipientes jerarquización y desigualdad sociales, inexistentes hasta el momento, pero que tendieron a aumentar en los siguientes períodos.

Al terminar el Paleolítico Superior también desaparecieron con él sus espléndidas manifestaciones artísticas, apareciendo otras nuevas, influenciadas, inevitablemente, por los cambiantes factores climáticos y los nuevos hábitos socio-económicos. El problema de este nuevo arte postpaleolítico es que resulta muy difícil de datar y los investigadores no se ponen de acuerdo acerca de su periodización. Unos opinan que representaciones como las del arte naturalista levantino son ya del Neolítico inicial, otros que es anterior. De cualquier manera el arte no desapareció y lo seguimos encontrando en abrigos rocosos (arte parietal) y en objetos personales (arte mueble).

El arte se volvió conceptual y racionalista, basado en lo geométrico y lo abstracto. La cultura aziliense de la cornisa cantábrica y del Pirineo francés nos ha deparado abundantes cantos rodados decorados con seriaciones de bandas, puntos, ramiformes, etc., de carácter abstracto, y a los que se les otorga un significado mágico/simbólico. La cultura natufiense destaca, entre otras cosas, por sus características representaciones de animales en morteros de mano, mangos de hoz o cuchillos, o sea, por su arte mueble.

En el Levante español grupos humanos dejaron pinturas que muestran una evolución del arte rupestre hacia modelos más esquemáticos, que representaban movimiento. En las paredes de los abrigos rocosos estos hombres pintaron complejas escenas de caza, de danzas y ritos mágicos. Las figuras están hechas con pigmentos negros o rojizos, y son muy estilizadas. A pesar de ello se pueden identificar personajes como hechiceros/chamanes, gracias a los tocados que les cubren la cabeza, a los bastones que llevan y a los adornos que les cuelgan de rodillas y brazos; también se aprecian hombres con plumajes y brazaletes en brazos y tobillos, mientras que las mujeres lucen largas faldas. Hay mucho movimiento (como contraste con el arte paleolítico) y las luchas entre grupos aparecen con relativa frecuencia, con batallas de arqueros que incluso llegan al cuerpo a cuerpo.

En Sierra Morena (Andalucía) se han encontrado figuras antropomórficas y teriomórficas (especialmente de cabras montesas y ciervos) muy esquematizadas, junto a signos del tipo de círculos, puntos, soles, ondulaciones. Otras representaciones importantes se han descubierto en Alpera (Albacete), Cogul (Lérida), "Barranco de los Gascones" (Teruel), Villar del Humo (Cuenca) o "Barranco de Gazulla" (Castellón).

Para ciertos autores la revolución neolítica comenzó a gestarse realmente durante el Mesolítico. Para B. Hayden y A. Testart durante este período aparecieron grupos de cazadores-recolectores especializados en unos pocos tipos de recursos abundantes y seguros, que se podían almacenar durante buena parte del año, lo que les permitió aumentar su demografía y sedentarizarse. La acumulación de bienes habría provocado las primeras desigualdades sociales y la aparición de jerarquías, encabezadas por aquellos que se habrían encargado de la gestión de los excedentes. Así habrían surgido las jefaturas, ligadas siempre en sus tomas de decisiones a los chamanes. Para Testart, la recolección y la caza intensivas de unas pocas especies, habría llevado gradualmente a una serie de mejoras técnicas que seleccionaron artificialmente aquellas, desembocando naturalmente en su posterior domesticación. Por todo ello, ambos consideran que la verdadera revolución se produjo en el Mesolítico, cuando fueron establecidas las bases económico-sociales que se desarrollaron posteriormente, durante el Neolítico.




</doc>
<doc id="15343" url="https://es.wikipedia.org/wiki?curid=15343" title="Imperio sasánida">
Imperio sasánida

El Imperio sasánida (en persa medio: , "Erānšahr" o "Iranšæhr"; tr.: "Dominios de los iranios") es el nombre que recibe el segundo Imperio persa durante su cuarta dinastía irania (226-651). La dinastía sasánida fue fundada por Ardacher I tras derrocar al último rey arsácida, Artabán IV de Partia, y terminó cuando el último Shahanshah ("Rey de reyes") sasánida Yazdgerd III (632-651) perdió una prolongada guerra de 14 años contra el primero de los califatos islámicos. El territorio del Imperio persa sasánida comprendía los actuales países de Irán, Irak, Armenia, Afganistán y partes del este de Turquía y Siria, además de parte de Pakistán, el Cáucaso, Asia Central y Arabia. Además, durante el gobierno de Cosroes II (590-628), se anexionaron al imperio los territorios de los actuales Egipto, Israel, Jordania, Líbano y los Territorios Palestinos, llegando a ejercer un "protectorado" sobre territorios actualmente correspondientes a Omán y Yemen.

El periodo sasánida, que comprende todo el periodo final de la antigüedad clásica e incluso la sobrevive unos siglos, se considera uno de los periodos históricos más importantes e influyentes de la historia de Irán. En muchos aspectos, el periodo sasánida alcanzó los mayores logros de la cultura persa, y constituyó el último gran imperio iranio antes de la conquista islámica de Persia y la adopción del islam como religión en todo el territorio. La Persia sasánida fue rival de la civilización romana por el control de Oriente Próximo y Mesopotamia. Su influencia cultural se extendió mucho más allá de los territorios fronterizos de ambos imperios, llegando hasta la Europa occidental, África, China e India, y jugó un papel fundamental en la formación del arte medieval europeo y asiático. Esta influencia llegó a través del mundo islámico que adoptó muchos aspectos de su arte y protocolo. La cultura aristocrática y exclusiva de la dinastía sasánida transformó la conquista islámica de Irán en un ‘renacimiento’ persa. Gran parte de lo que posteriormente sería conocido como ‘cultura islámica’ (arquitectura, escritura y otras habilidades) fueron adopciones del amplio mundo islámico a partir de los modelos persas sasánidas.

La dinastía sasánida fue establecida por Ardacher I (226-241), descendiente de una línea de sacerdotes de la diosa Anahita en Istajr, en la provincia persa de Fars, quienes a principios del siglo III habían accedido al gobierno de la provincia. El padre de Ardacher, de nombre Papag (también conocido como ‘Papak’ o ‘Babak’) era en principio el gobernante de un pequeño pueblo llamado Jeir, pero en el año 205 depuso al último rey de los Bazrangi, Gocihr (señor local que actuaba en calidad de cliente de los arsácidas), proclamándose nuevo gobernante. Su madre, Rodhagh, era la hija del gobernador provincial de Peris. El fundador epónimo de la línea dinástica fue el abuelo paterno de Ardacher I, llamado Sasán, gran sacerdote del templo de Anahita.

Los esfuerzos de Pabag por apoderarse de la provincia escaparon a la atención del emperador arsácida Artabán IV de Partia, que en aquellos días se encontraba envuelto en un conflicto dinástico con su hermano Vologases VI en Mesopotamia. Aprovechando la oportunidad que estas circunstancias le ofrecían, Pabag y su primogénito Sapor trataron de expandir su poder sobre toda Persia. Se ignoran los acontecimientos que siguieron debido a lo incompleto de las fuentes, pero se cree que tras la muerte de Pabhag sobre el año 220, Ardacher, que era entonces gobernador de Darabgird, disputó el poder a su hermano mayor Sapor. Las fuentes nos dicen que en el 222 Sapor murió al derrumbarse el edificio donde iba a reunirse con su hermano.

En ese momento, Ardacher trasladó su capital aún más al sur de Persis, fundando una ciudad en Ardashir-Jwarrah (antiguamente conocida como "Gur" y actualmente Firuzabad). La localidad, ubicada entre altas montañas, era fácilmente defendible gracias a sus estrechos accesos, y se convirtió en el centro del poder sasánida. Estaba además rodeada por una alta muralla circular, copiada probablemente de la de Darabgid. Al norte se construyó un gran palacio del cual aún se conservan algunos restos.

Tras establecer su dominio sobre Persis, Ardacher I extendió rápidamente su territorio, exigiendo la lealtad de los príncipes locales de Fars y obteniendo el control sobre las provincias vecinas de Kermán, Isfahán, Susiana y Menese (la actual Kuwait). Esta rápida expansión llamó la atención de Artabán IV (216-224), del cual Ardacher era vasallo.

Inicialmente, Artabán ordenó al gobernador del Juzestán marchar contra Ardacher en el año 224, pero el enfrentamiento concluyó con una importante victoria de Ardacher. Posteriormente fue el mismo Artabán quien organizó una segunda campaña contra Ardacher, y ambos ejércitos se enfrentaron en Hormizdeghan, donde Artabán IV resultó muerto.

Ardacher marchó entonces a invadir las provincias occidentales del difunto emperador arsácida. En el año 226 fue coronado en Ctesifonte único señor de Persia y comenzó a utilizar el título de Shahanshah ("rey de reyes"), terminando con cuatro siglos de imperio parto y dando principio a otros tantos de gobierno sasánida.

Durante los años siguientes, y tras algunas rebeliones locales a lo largo del Imperio, Ardacher I amplió aún más su nuevo Estado hacia el este y noroeste, conquistando las provincias de Sistán, Gorgán, Jorasán, Margiana (en el actual Turkmenistán), Balj y Corasmia. Además, anexionó Baréin y Mosul a las posesiones sasánidas. Posteriores inscripciones sasánidas afirman también la sumisión de los reinos de Kushán, Turán y Mekrán a Ardacher, aunque basándose en las pruebas numismáticas es más probable que estos reinos fueran sometidos por el hijo de este, Sapor I. Al oeste, las campañas contra Hatra, Armenia y Adiabene tuvieron menos éxito.

El hijo de Ardacher, Sapor I (241-272), continuó la expansión emprendida por su padre, conquistando Bactria y Kushán, al tiempo que llevaba a cabo numerosas campañas contra Roma. Penetrando profundamente en territorio romano, Sapor I se adueñó de Antioquía, en Siria (253 o 256), y derrotó finalmente a los emperadores romanos Gordiano III (238-244), a Filipo el Árabe (244-249) y a Valeriano (253-260). Este último fue hecho prisionero en el 259 tras la batalla de Edesa, una tremenda hecatombe sin parangón en la historia romana. Sapor I celebró su victoria encargando la talla de los impresionantes relieves de Najsh-i-Rostam o Naqsh-e Rostam, así como una monumental inscripción en persa y griego en las proximidades de Persépolis. Entre 260 y 263, empero, perdió algunos de los territorios recientemente conquistados a manos de Odenato, aliado de Roma.

Sapor I tenía un intensivo plan de desarrollo. Fundó un importante número de ciudades, habitadas algunas de ellas por emigrantes procedentes de territorio romano. Entre estos inmigrantes se incluían cristianos y judíos, que podían profesar su fe libremente bajo el gobierno sasánida. En el aspecto religioso Sapor favoreció particularmente el maniqueísmo; protegió a Mani y envió misioneros maniqueos por doquier. Asimismo, trabó amistad con un rabino judío babilonio llamado Samuel, relación que fue ventajosa para la comunidad judía, ya que le dio un respiro de las opresivas leyes dictadas hasta entonces contra ella.

Posteriores reyes abandonaron la tolerancia religiosa de Sapor. Su propio sucesor, Bahram I (273-276), persiguió a Mani y a sus correligionarios. Mani fue encarcelado y Bahram I ordenó su ejecución, aunque una leyenda posterior afirma que murió en prisión mientras esperaba a ser ajusticiado.

Bahram II (276-293) continuó la política religiosa de su padre. Fue un gobernante débil que perdió numerosas provincias occidentales a manos del emperador romano Caro (282-283). Durante su reinado, la mayor parte de Armenia, que había permanecido en manos persas durante medio siglo, pasó a control de Diocleciano (284-305).

Tras el breve reinado de Bahram III en 293, Narsés (293-302) se embarcó en una nueva guerra contra Roma. Tras el éxito inicial obtenido contra el futuro emperador romano Galerio (305-311) cerca de Callinicum, junto al Éufrates en 296, Narsés fue derrotado en una emboscada mientras se encontraba con su harén en Armenia el año 297. En el tratado que concluyó esta guerra, los sasánidas cedieron todas las tierras al oeste del Tigris y acordaron no entrometerse en los asuntos de Armenia y Georgia.

Después de esta aplastante derrota, Narsés abdicó en 301; falleció un año más tarde. Su hijo Ormuz II (302-309) ascendio entonces al trono. Aunque aplastó las revueltas que estallaron en Sistán y Kushán, fue otro monarca débil e incapaz de dominar a los nobles. Fue asesinado el año 309 por unos beduinos mientras cazaba.

La muerte de Ormuz II coincidió con el principio de una serie de correrías de los árabes desde el sur, en las que estos asaltaron algunas de las ciudades meridionales del Imperio y penetraron incluso en la provincia de Fars, cuna de los reyes sasánidas. Mientras tanto, los nobles persas asesinaron al primogénito de Ormuz II, cegaron a su segundo hijo y encarcelaron al tercero (que posteriormente huyó a territorio romano). El trono se reservó para el hijo no nacido de una de las viudas de Ormuz II.

Se dice que Sapor II (309-379) podría haber sido el único rey de la historia coronado antes de nacer. De hecho, colocaron la corona sobre el vientre de su madre. El niño nació, por lo tanto, siendo ya rey. Durante su juventud, el Imperio estuvo controlado por su madre y los nobles. Al alcanzar la edad adulta, asumió el poder y demostró con rapidez que era un gobernante activo y capaz.

En primer lugar, llevó a su pequeño aunque disciplinado ejército a luchar contra los árabes; los derrotó y aseguró así las tierras meridionales del Imperio. Tras esto acometió su primera campaña contra los romanos en el oeste, en la que obtuvo al comienzo algunas victorias. Tras el asedio de Singara, sin embargo, tuvo que abadonar sus conquistas por culpa de las incursiones nómadas a lo largo de las fronteras orientales del Imperio. Estas pusieron en peligro Transoxiana, una zona estratégica y vital para el control de la Ruta de la seda. Además, las fuerzas sasánidas eran insuficientes para conservar todo el territorio conquistado en el oeste; en consecuencia, Sapor firmó una tregua con Constantino II (337-340).

Hecho esto, marchó hacia Transoxiana, al encuentro de los nómadas orientales. Aplastó a las tribus de Asia Central y se apoderó de la región, que organizó como nueva provincia. A la victoria le siguió la expansión cultural y el arte sasánida penetró en el Turquestán, llegando incluso hasta China. Sapor II, junto al rey nómada Grumbates, emprendió una nueva campaña contra los romanos en el 359, esta vez empleando todo su poderío militar y gozando de la colaboración de los nómadas. Fue una campaña tremendamente exitosa en la que los persas arrebataron a los romanos un total de cinco provincias.

Sapor II siguió una rígida política religiosa. Durante su reinado se completaron los Avesta, los textos sagrados del zoroastrismo, se castigó la herejía y la apostasía y se persiguió de nuevo a los cristianos y también a los judíos. Estas persecuciones anticristianas y también antijudías fueron parte de una reacción contra la cristianización y legalización del judaísmo en el Imperio romano efectuadas por Constantino I el Grande (324-337). Sin embargo, Sapor II (al igual que Sapor I) fue un monarca que amparó a los judíos emigrantes (quienes vivieron en relativa libertad y obtuvieron muchas ventajas durante este período, no así los conversos de origen persa).

A la muerte de Sapor II, el Imperio persa era más fuerte que nunca, habiendo derrotado a sus enemigos del este y sometido Armenia.

Desde la muerte de Sapor II y hasta la primera coronación de Kavad I, Persia disfrutó de una relativa estabilidad, con sólo algunas guerras contra el Imperio bizantino. A lo largo de esta época, la política religiosa del Imperio sasánida cambió radicalmente de un rey a otro. Con la excepción de una serie de monarcas débiles, el sistema administrativo establecido por Sapor II permaneció fuerte, y el Imperio siguió funcionando con normalidad.

Sapor II dejó a su muerte en 379 el poderoso Imperio persa a su hermanastro Ardacher II (379-383), hijo de Vahram de Kushan, y posteriormente heredaría su hijo Sapor III (383-388). Ninguno de ellos demostró tener el talento de su insigne predecesor.

Ardacher II, quien fue elevado al poder por ser hermanastro del emperador, fracasó al tratar de ocupar el hueco dejado por éste, siendo lo más célebre de su reinado la construcción de una nueva capital en Taq-I Bustán, y Sapor III tenía un carácter demasiado débil como para alcanzar grandes logros.

Bahram IV (388-399), aunque fue un monarca más activo que su padre, tampoco supo proporcionar al imperio logros de importancia. Durante este tiempo, Armenia fue dividida por un tratado entre los imperios romano y sasánida. Los sasánidas restablecieron su dominio sobre la mayor parte de Armenia, mientras los bizantinos obtuvieron una pequeña porción del occidente de Armenia.

Al hijo de Barham IV, Yazdegerd I (399-421) se le compara con frecuencia con Constantino I. Como él, fue un personaje fuerte, tanto física como diplomáticamente. Como su contraparte romana, Yazdegerd I uso el poder de una forma oportunista. Al igual que Constantino el Grande, Yazdegerd practicó la tolerancia religiosa y dio libertad al auge de las religiones minoritarias. Detuvo la persecución contra los cristianos, castigando a los nobles y sacerdotes que les persiguieran. Su reino abarcó una época de relativa paz. Hizo la paz con los romanos e incluso tuvo al joven Teodosio II (408-450) bajo su custodia. También se casó con una princesa judía, quien le dio un hijo llamado Narsi.

A Yazdegerd I le sucedió su hijo Bahram V (421-438), que es uno de los reyes sasánidas mejor conocidos, y héroe de numerosos mitos posteriores pues esas leyendas persistieron incluso después de la destrucción del Imperio sasánida por los árabes. Bahram V, obtuvo la corona tras la repentina muerte (o asesinato) de su padre Yazdegerd I, y ello con la oposición de la nobleza del reino, que contaba con la ayuda de Al-Mundhir, de la dinastía árabe (lajmida) de al-Hirah. La madre de Bahram V era Soshandukht, hija de exiliados judíos.

En el año 427, Bahram V aplastó la invasión de los nómadas heftalitas en el este, extendiendo su influencia por Asia Central, donde su retrato sobrevivió durante siglos en las monedas de Bujará (la actual Uzbekistán). Bahram V depuso también el reino vasallo de la Armenia persa, convirtiendo la región en otra provincia.

Bahram V es un referente en la tradición persa, que relata muchas historias sobre su valor y belleza, de sus victorias sobre romanos, turcos, hindúes y etíopes axumitas, y sobre sus aventuras en la caza y el amor. Se le llamó Bahram-e Gur (Gur significa en persa "onagro"), por su amor a la caza y en particular a la caza del onagro. Bahram V es el paradigma de un rey en la cúspide de una edad de oro. Obtuvo su corona disputándola a su hermano, y aunque pasó bastante tiempo combatiendo a sus enemigos exteriores, prefería estar de caza y organizando fiestas en la corte con su famoso grupo de damas y cortesanas. Personalizaba la prosperidad real. Durante su reinado se escribieron las mejores obras de la literatura sasánida, se compusieron notables obras musicales y deportes como el polo se convirtieron en el pasatiempo real, una tradición que continúa todavía en muchos reinos.

Yazdegerd II (438-457), hijo de Bahram V, fue un gobernante justo y moderado, aunque en contraste con Yazdegerd I, practicó una política religiosa represiva con las minorías, especialmente con los cristianos.

Al principio de su reinado, Yazdegerd II reunió un ejército integrado por varias naciones, incluyendo a sus aliados hindúes, y atacó al Imperio romano de Oriente, que estaba construyendo fortificaciones en territorio persa, cerca de Carrae (una estratagema usada por los romanos para lanzar expediciones desde ellas). Los persas tomaron a los romanos por sorpresa, y de no haber sido por una fuerte inundación, Yazdegerd podría haberse internado mucho más en territorio romano. El emperador bizantino Teodosio II pidió la paz enviando a su comandante a negociar al campamento de Yazdegerd. En 441, ambos imperios se comprometían a no construir más fortificaciones en la frontera. Sin embargo, Yazdegerd II estaba en mejor situación que los bizantinos para negociar, y si no exigió más concesiones se debió a las incursiones de los kidaritas en Partia y Corasmia. Reunió sus fuerzas en Neishabur en 443, lanzando una prolongada campaña contra los kidaritas. Finalmente, y tras algunas batallas, aplastó a los kidaritas, expulsándoles más allá del río Oxus en 450.

Durante su campaña en el este, Yazdegerd II empezó a sospechar de los cristianos que componían su ejército, lo que hizo que fueran expulsados tanto del ejército como del gobierno. Entonces comenzó una persecución contra los cristianos y, en menor medida, también contra los judíos. Para restablecer el zoroastrismo en Armenia, aplastó un levantamiento de cristianos armenios en la batalla de Avarayr, en 451. Sin embargo, los armenios siguieron siendo mayoritariamente cristianos. En sus últimos años, se enfrentaría de nuevo con los kidaritas, hasta que murió en 457.

Hormizd III (457-459), el hijo menor de Yazdegerd II, ascendió entonces al trono. Durante su corto reinado luchó continuamente contra su hermano mayor Peroz, que tenía el apoyo de la nobleza, y contra los heftalitas en Bactriana. Finalmente fue asesinado en 459 por su hermano.

A principios del siglo V, los heftalitas (hunos blancos), junto con otros grupos nómadas, atacaron Persia. Al principio, Bahram V y Yazdegerd II infligieron decisivas derrotas a estos grupos, haciéndoles retroceder hacia el este. Los hunos volvieron a finales del siglo V y derrotaron a Peroz I (457-484) en el año 483. Tras esta victoria, los hunos invadieron y saquearon partes del este de Persia durante dos años, e incluso recaudaron fuertes impuestos durante varios años más tras estos saqueos.

Los ataques hunos trajeron inestabilidad y caos al reino. Peroz I intentó de nuevo expulsar a los heptalitas, pero en el camino hacia Herat, él y su ejército fueron emboscados por los hunos en el desierto. Peroz I fue asesinado, y su ejército destruido. Tras esta victoria, los heftalitas avanzaron hacia la ciudad de Herat, convirtiendo el imperio persa en un caos.

Un noble persa de la antigua familia de Karen: Zarmihr (o Sokhra), restauró un poco el orden. Elevó a Balash, uno de los hermanos de Peroz I al trono, a pesar de que la amenaza de los hunos persistió hasta el reinado de Cosroes I "Anusarvan".

Balash (484-488) fue un monarca suave y generoso, que hizo concesiones a los cristianos, aunque no tomó medidas contra los enemigos del Imperio, en especial contra los hunos blancos. Tras un reinado de cuatro años, Balash fue cegado y depuesto, y su sobrino Kavadh I fue elevado al trono.

Kavadh I (488-531) fue un gobernante enérgico y reformista. Dio su apoyo a la secta heterodoxa "comunista" fundada por Mazdak, hijo de Bamdad, quien propugnaba que los ricos debían compartir sus mujeres y propiedades con los pobres. La intención de Kavadh era, por supuesto, terminar con la influencia de los magnates y de la opulenta aristocracia. Estas reformas llevaron a su derrocamiento y su encarcelación en el "Castillo del olvido", en Susa, y su hermano menor, Djamasp fue elevado al trono en 496. Sin embargo, Kavadh escapó de prisión en 498 y encontró refugio junto al rey de los hunos blancos.

Djamasp (o Ŷamasp, 496-498) se instaló en el trono sasánida tras el derrocamiento de Kavadh I por miembros de la nobleza. Djamasp fue un buen rey que redujo los impuestos para favorecer a los campesinos y los pobres. También profesó cierta simpatía por la secta de los Mazdakitas, simpatías que a su hermano le habían costado el trono y la libertad. Su reinado duró poco, ya que su hermano Kavadh regresó al frente de un gran ejército cedido por el rey de los heftalitas. Los leales a Djamasp depusieron sus armas y restauraron en el trono sasánida a Kavadh I. No se vuelve a mencionar en las fuentes a Djamasp tras la restauración de su hermano, aunque se presume que fue bien tratado en la corte de Kavadh I.

La segunda edad de oro comenzó tras el inicio del segundo reinado de Kavadh I. Con el apoyo de los heftalitas, Kavadh lanzó una campaña contra los romanos. En el año 502 tomó Teodosiópolis (Erzurum), en Armenia. En 503 tomó Amida (Diyarbakır), junto al Tigris. En 505, una invasión de Armenia por parte de los hunos occidentales desde el Cáucaso dio lugar a un armisticio. Durante este armisticio, los romanos pagaron tributo a los persas por el mantenimiento de las fortificaciones en el Cáucaso. En el año 525, Kavadh acabó con las revueltas producidas en Lázica (al sudoeste de Georgia), y volvió a capturar Georgia. Su ejército, con ayuda de los árabes nestorianos lajmidas, de Hira un reino vasallo de los sasánidas, derrotó al ejército bizantino comandado por Belisario, el famoso general de Justiniano, en dos ocasiones: una en el año 530, en la batalla de Nísibis, y otra en el 531, en la batalla de Calinico. aunque no podía librarse del yugo de los heftalitas, Kavadh consiguió restablecer el orden dentro del Imperio y llevar a cabo exitosas campañas contra los bizantinos, fundar muchas ciudades, algunas de las cuales adoptaron su nombre, y comenzó a regular los impuestos.

Tras Kavadh I, su hijo Cosroes I, también llamado "Kusro I Anosharvan", (Alma inmortal), que gobernó entre 531 y 579, ascendió al trono de Persia. Es el más famoso de los reyes sasánidas. Cosroes I se hizo famoso por sus reformas en el aparato de gobierno sasánida. En ellas introdujo un sistema racional de impuestos basado en la inspección de las posesiones en tierras, labor que había empezado su padre, y también trató por todos los medios de incrementar la beneficencia y los ingresos de su Imperio. Los anteriores grandes señores feudales equipaban sus propios ejércitos, a sus seguidores y criados. Cosroes I desarrolló una nueva fuerza de "dekhans" o "caballeros", pagados y equipados por el gobierno central. Acercó al ejército y a la burocracia hacia el poder central, alejándolos de la influencia de los señores locales.

A pesar de que el emperador bizantino Justiniano I (527-565) había pagado la suma de cuatrocientas cuarenta mil piezas de oro para mantener la paz, en 540 Cosroes I rompìó la «paz eterna» firmada en 532 e invadió Siria, donde capturó y saqueó la ciudad de Antioquía. Durante su camino de regreso, recaudó dinero de diferentes ciudades bizantinas.

En 565 murió Justiniano I, siendo sucedido en el trono bizantino por Justino II (565-578), quien decidió dejar de pagar a los cabecillas árabes para impedir que siguieran efectuando incursiones en territorio bizantino en Siria. Un año antes, el gobernador sasánida de Armenia, de la familia Suren, había construido un templo consagrado al fuego en Dvin, cerca de la moderna Ereván, matando además a un influyente miembro de la familia Mamikonia, lo que provocó una revuelta que condujo a la masacre del gobernador persa y toda su guardia en 571. Justino II se aprovechó de la revuelta en Armenia para terminar con los pagos anuales a Khosrau I por la defensa de los pasos del Cáucaso. Los armenios fueron recibidos como aliados y se envió un ejército al territorio persa que asedió Nísibis en 572. Sin embargo, las discrepancias entre los generales bizantinos no sólo llevó al abandono del asedio, sino que además el ejército bizantino fue asediado a su vez en la ciudad de Dara, que finalmente fue tomada por los persas.

Posteriormente el ejército persa saqueó Siria, provocando una nueva petición de paz por parte de Justino II. La rebelión armenia terminó con una amnistía general otorgada por Cosroes I, que devolvió a Armenia al control sasánida.

Sobre el 570, Ma al-Karib, hermanastro del rey de Yemen, pidió la intervención de Cosroes I en su país contra la intervención del reino cristiano de Etiopía, enviando Cosroes I una flota y un pequeño ejército bajo el mando de un comandante llamado Vahriz a las cercanías de la actual Adén que marchó contra la capital del país, Sanaa, la cual ocuparon. Saif, hijo de Mard-Karib, que había acompañado a la expedición, se convirtió en rey entre 575 y 577. Además, los sasánidas establecieron una base en el sur de Arabia para controlar el comercio marítimo con el este. Posteriormente, los reinos del sur de Arabia renunciaron al vasallaje que les ataba con los sasánidas, y hubo de enviarse una nueva expedición persa en el 598 que consiguió anexionarse el sur de Arabia como otra provincia del Imperio. Estas provincias se conservaron hasta la problemática época que siguió a la muerte de Cosroes II.

El reinado de Cosroes contempló el auge de los "dighans" (literalmente, "señores de las villas"), la pequeña nobleza terrateniente, que constituyeron el esqueleto de lo que luego se convirtió en la administración provincial sasánida y el sistema de recaudación de impuestos. Cosroes I fue un gran constructor que embelleció su capital, fundando nuevos barrios y construyendo nuevos edificios. Reconstruyó los canales y repuso las granjas destruidas en las guerras. También construyó poderosas fortificaciones en los pasos, y emplazó a ciertas tribus en pueblos cuidadosamente seleccionados de las fronteras para que hicieran de guardianes contra posibles invasiones. Fue un monarca tolerante con todas las religiones, a pesar de decretar la oficialidad del zoroastrismo para todo el estado. Tampoco pareció molestarse cuando uno de sus hijos se convirtiese al cristianismo.

Tras Cosroes I, Ormuz IV (579-590) tomó el trono. Ormuz IV fue un gobernante enérgico que mantuvo la prosperidad iniciada por sus predecesores. Durante el reinado de su sucesor, Cosroes II (590-628), la revuelta del general Bahram Chobin (proclamado como Bahram VI en oposición al monarca oficial) provocó una breve crisis en el reino, aunque Cosroes II consiguió restablecer su control sobre el Imperio. Además, y aprovechando la guerra civil que sacudía al Imperio bizantino, lanzó una invasión a gran escala. El sueño sasánida de restablecer el dominio persa sobre Armenia estuvo cerca de cumplirse cuando cayeron Damasco y Jerusalén. Egipto cayó poco después. en 626, Cosroes II sitió Constantinopla con la ayuda de fuerzas eslavas y ávaras, sólo para contemplar, como otros antes y después también lo harían, las inexpugnables murallas de la capital bizantina.

Esta importante expansión vino acompañada de un período igualmente brillante del arte persa, de la música y de la arquitectura.

Aunque muy exitosa, la campaña de Cosroes II se realizó a costa de una importantísima presión fiscal. El emperador bizantino Heraclio (610-641) contraatacó con un movimiento táctico, abandonando su sitiada capital y navegando hasta el Mar Negro para atacar Persia desde la retaguardia. Mientras tanto, la mutua desconfianza entre Cosroes II y su general Shahrbaraz, agravadas por las cartas falsas que agentes bizantinos hicieron llegar hasta el general persa, y donde supuestamente Cosroes II planeaba su ejecución, hicieron que Shahbaraz permaneciera neutral durante este periodo crítico. Persia perdió el apoyo de uno de sus mayores ejércitos y de uno de sus mejores generales. Para mayor infortunio de Cosroes, Shanin, el otro gran sostén del ejército sasánida, que había conquistado el Cáucaso y Anatolia, murió de forma repentina, lo que acabó de desequilibrar la balanza en favor de los bizantinos.

Heraclio, con ayuda de los kázaros y otras tropas turcas, aprovechó la ausencia de Shanin y Shabaraz para obtener varias victorias devastadoras contra el estado sasánida, debilitado por quince años de guerras.

La campaña de Heraclio culminó en la batalla de Nínive, donde los bizantinos (ya sin la ayuda de los kázaros, que habían abandonado a Heraclio) derrotaron al ejército persa comandado por Rhahzadh. Entonces Heraclio marchó hacia Mesopotamia y el oeste de Persia, saqueando Tajt-e Soleimán y el palacio de Dastugerd, donde recibió noticias del asesinato de Cosroes II.

Tras el asesinato de Cosroes II en 628 se produjo el caos y la guerra civil. Durante un período de cuatro años (628-632) se sucedieron entre doce y catorce soberanos/as, incluyendo dos hijas de Cosroes II y el mismo general Shahbaraz. El Imperio sasánida se debilitó considerablemente. El poder central pasó a manos de los generales. Pasaron muchos años hasta la aparición de un rey fuerte, y desde entonces, el Imperio no volvió a recuperarse por completo.

En la primavera de 632, un nieto de Cosroes II, Yezdegard III, quien había vivido escondido, ascendió al trono y fue el último soberano sasánida. Aquel mismo año, los primeros escuadrones árabes efectuaron incursiones en territorio persa. Los años de guerra habían agotado tanto a los bizantinos como a los persas. Los sasánidas se encontraban aún más debilitados por el declive económico, los altos impuestos, los problemas religiosos, la rígida estratificación social, el creciente poder de los terratenientes y los sucesivos cambios de gobierno, factores todos ellos que facilitaron la invasión árabe.

En realidad, los sasánidas nunca opusieron una verdadera resistencia a la presión ejercida por los primeros ejércitos árabes. Yezdegard III era sólo un muchacho a merced de sus consejeros, e incapaz de unir a un vasto país reducido a un grupo de pequeños reinos feudales, a pesar de que los bizantinos, sometidos a similar presión por parte de los árabes, ya no constituían una amenaza. El primer encuentro entre los sasánidas y los musulmanes árabes se produjo en la batalla del Puente de 634, que se saldó con una victoria persa que, sin embargo, no detuvo la conquista árabe. Estos reaparecieron poco después, comandados por el gran estratega Jalid ibn al-Walid, uno de los antiguos compañeros de Mahoma y jefe del ejército árabe.

Un ejército musulmán al mando del califa Úmar ibn al-Jattab derrotó al más numeroso ejército persa que mandaba el general Rostam Farrojzad en las llanuras de al-Qadisiyyah en 637; asedió luego Ctesifonte, que terminó cayendo tras un prolongado sitio. Yazdegard huyó entonces hacia el este, dejando tras de sí la mayor parte del enorme tesoro imperial.

Es presumible que, de no haberse encontrado el Imperio sasánida exhausto, dividido y sin un gobierno eficiente en el momento de la invasión árabe, la caballería "asawara" persa habría podido derrotarles con toda seguridad. Sin embargo, las fuerzas persas nunca llegaron a unirse a tiempo, y se movían bajo el vacío de poder imperante. El resultado de esta debacle fue la conquista islámica. Cierto número de gobernadores sasánidas intentaron combinar sus fuerzas para hacer retroceder a los invasores, pero estos esfuerzos resultaron baldíos debido a la falta de una autoridad central, y los gobernadores fueron derrotados en la batalla de Nihavand. A partir de entonces, el Imperio, con sus estructuras de mando militar inexistentes, sus tropas diezmadas, con sus recursos económicos destruidos y la casta de caballeros "asawara" desaparecida, se mostraba indefenso ante su invasor.

Al tener noticias de las derrotas en Nihawand y en Al-Qadisiyyah, Yezdegard III, con la mayor parte de la nobleza persa, huyó aún más hacia el noreste (huyendo de provincia en provincia de lo que quedaba de su antiguo imperio), a la provincia de Jorasán. Yezdegard fue asesinado por un molinero en Merv (Sogdiana), a finales del 651, mientras el resto de los nobles se asentaban en Asia Central (principalmente en Corasmia), donde contribuyeron en gran medida a la difusión de la cultura persa y su lengua en aquella región, estableciendo la primera dinastía nativa iraní: la dinastía samánida, que resucitó las tradiciones y la cultura sasánida tras la invasión del islam.

La abrupta caída del Imperio sasánida se completó en un periodo de cinco años, y la mayor parte de su territorio fue absorbido en el califato islámico de los omeyas. Sin embargo, muchas ciudades iraníes resistieron, luchando contra los invasores en multitud de ocasiones en las décadas siguientes. La población aceptó lentamente el islam, una religión con mensaje basado en la igualdad y la justicia, al compararlo con el despotismo de los reyes que gobernaban Persia. Miles de fieles zoroástricos huyeron hacia el este dando origen a la comunidad parsi en el noroeste de la India. Al igual que en el Oriente Próximo y el Magreb, los nobles y habitantes de las ciudades se convirtieron pronto mientras la religión tradicional persistía por más tiempo en el campo y las zonas rurales. En las apartadas zonas junto al Caspio y la Transoxiana, la cultura y religión sasánidas se mantuvieron hasta dos siglos después de la conquista musulmana. Los árabes respetaron la cultura persa y tradujeron muchos de sus libros profanos, cuentos y poesía, al árabe mientras los libros sagrados zoroástricos a veces fueron quemados.

Los sasánidas establecieron su imperio cubriendo aproximadamente el mismo territorio de los aqueménidas, con capital en Ctesifonte, en la provincia de Khvarvaran. Los gobernantes sasánidas adoptaron el título de Shahanshah (rey de reyes), convirtiéndose a un tiempo en señores supremos y en guardianes del fuego sagrado, símbolo de la religión nacional. Esta simbología se muestra en las monedas sasánidas, donde el monarca reinante, con su corona y los atributos de su cargo, aparece en una de las caras mientras ocupa el reverso de la moneda la llama sagrada. Las reinas sasánidas tenían el título de Banebshenan barebshen (reina de reinas).

A menor escala, el territorio era gobernado por gobernadores pertenecientes a la familia real sasánida, conocidos como Shahrdar (شهردار), bajo la supervisión directa del Shahanshah. El gobierno sasánida se caracterizaba por una considerable centralización, por sus ambiciosos planes urbanísticos, el desarrollo de la agricultura y la investigación tecnológica. A las órdenes del rey, una poderosa burocracia se encargaba de la mayor parte de los asuntos del gobierno. La cabeza de esta burocracia y vicecanciller era el "Vuzorg (Bozorg) Farmadar" (بزرگ فرمادار). Dentro de este aparato burocrático, los sacerdotes zoroastrianos eran inmensamente poderosos. La cabeza de la clase sacerdotal era el Mobadan (موبدان), quien junto con el comandante en jefe, el Iran (Eran) Spahbod (ايران سپهد) y el jefe del sindicato de comerciantes, "Ho Tokhshan Bod" (هوتوخشان بد), que era también ministro de agricultura "Vastrioshansalar" (واستریوشانسالار) y jefe de los granjeros eran los hombres más poderosos del estado sasánida, sólo por debajo del emperador.

Los monarcas sasánidas actuaban frecuentemente como asesores de sus ministros, los cuales componían un consejo de estado. El historiador musulmán Al-Masudi alababa la «excelente administración de los reyes sasánidas, su ordenada política, el cuidado de sus súbditos y la prosperidad de sus dominios».

En tiempos normales, el cargo imperial era hereditario, aunque podía ser transmitido por el rey a un hijo menor. En dos momentos de su historia, el poder supremo estuvo en manos de sendas reinas. Cuando no existía un heredero directo disponible, los nobles y prelados elegían a un gobernante, aunque esta elección estaba restringida a los miembros de la familia real.

La nobleza sasánida era una mezcla de los antiguos clanes partos, las familias aristocráticas persas y las familias nobles de los territorios súbditos del Imperio. Tras la disolución de la dinastía parta surgieron muchas familias nobles, al tiempo que los que una vez fueron los siete clanes partos dominantes conservaban una gran importancia social. En al corte de Ardacher I, las viejas familias arsácidas de Suen-Pahlav y Karen-Pahlav, junto con numerosas familias persas, los Varazes y Andiganos, ostentaban puestos de gran honor. El sucesor de Ardacher, Sapor I, utilizó como símbolo el blasón de Gondophar (un círculo rodeado por un creciente), que podría indicar la relación de este monarca a través de su madre con la casa de Suran-Pahlav.

Por regla general, las familias de clase más alta (Bozorgan), ostentaban los cargos de mayor poder en la administración imperial, incluyendo a los gobernadores de las provincias fronterizas (Marzban, مرزبان). La mayor parte de estos cargos eran patrimoniales, y en muchos casos eran heredados dentro de la misma familia durante generaciones. A los Marzban de más veteranía se les permitía tener un trono de plata, mientras a los de las provincias de mayor importancia estratégica como el Cáucaso se les permitía un trono de oro. Durante las campañas militares, los Marzban podían actuar como mariscales de campo, mientras los menos numerosos Spahbods podían comandar los ejércitos.

Culturalmente, los sasánidas implementaron un sistema de estratificación social. Este sistema tenía su base en el zoroastrismo, establecido como la religión oficial del estado. El resto de las religiones fueron tratadas con bastante tolerancia (aunque con puntuales episodios de persecución). Los emperadores sasánidas buscaron de forma consciente resucitar las tradiciones persas, tratando de borrar la influencia cultural griega.

La columna vertebral del ejército persa (Spah) en la época sasánida estaba compuesta por la caballería pesada, evolucionada desde la época de los partos: los caballeros savaranos. Esta fuerza de caballería, compuesta por la élite de la nobleza, entrenada desde su juventud para el servicio militar, estaba apoyada por la caballería ligera, la infantería y los arqueros. Las tácticas sasánidas se centraban en la distracción y debilitamiento del enemigo mediante el uso de los arqueros, montados o a pie, para así permitir a los savaranos maximizar el poder de su carga.

Al contrario que sus predecesores partos, los sasánidas desarrollaron técnicas avanzadas de asedio. Este desarrollo le proporcionó ventaja en sus conflictos con Roma; una ventaja basada en la capacidad de asediar ciudades y puestos fortificados. Inversamente, también desarrollaron técnicas para defender sus propias ciudades de un ataque. El ejército sasánida era famoso por su caballería pesada, heredada del anterior ejército parto, aunque mucho más avanzada y letal. El historiador griego Amiano Marcelino describió a la caballería de Sapor II, manifestando su alto nivel de equipamiento:
La cantidad de dinero necesaria para mantener a un guerrero de la casta Asawara hacía necesario que estos dispusieran de tierras, y en efecto, los caballeros savaranos (asawara) las obtuvieron de la Corona. A cambio, fueron los más notables defensores de la corona en tiempos de guerra.

Los sasánidas, al igual que los partos, mantuvieron una constante hostilidad contra el Imperio romano. Tras la división del Imperio romano en el 395, el Imperio romano de Oriente, con capital en Constantinopla, reemplazó al Imperio romano como principal enemigo de Persia. Las hostilidades entre ambos imperios se hicieron aún más frecuentes. Los sasánidas, al igual que los romanos, estaban en continuo conflicto con los reinos vecinos y con las hordas nómadas. A pesar de que el peligro de las incursiones nómadas nunca llegó a ser completamente resuelto, los sasánidas tuvieron con estas más éxito del que tuvieron en su lucha contra los romanos, ya que su política militar estuvo más centrada en la coordinación de las campañas contra el peligro nómada.

En el oeste, el territorio sasánida lindaba con el extenso y estable Imperio romano, pero en el este sus vecinos más cercanos eran el Imperio kushán y tribus nómadas, como la de los hunos blancos. La construcción de fortificaciones como la ciudadela de Tus o la ciudad de Nishapur, convertida posteriormente en centro de estudios y comercio, ayudaron a defender las provincias orientales de los ataques.

Al sur, en Arabia central, las tribus beduinas corrían de forma ocasional las fronteras surorientales del Estado sasánida. El reino de al-Hirah, vasallo sasánida, se estableció a modo de estado tapón entre el territorio imperial y las tribus beduinas. La disolución del reino de al-Hirah por Cosroes II en 602 contribuyó en gran medida a la derrota sasánida frente a los beduinos árabes que acaeció al final de ese mismo siglo; las victorias de las tribus beduinas, convertidas al islam, les permitieron apoderarse del territorio del Imperio sasánida.

Al norte, los jázaros y otras tribus turcas asaltaban con frecuencia las provincias septentrionales del imperio. Estas tribus saquearon el territorio de los medos en 634. Poco más tarde, el ejército persa los derrotó y expulsó. Los sasánidas construyeron numerosas fortificaciones en la región del Cáucaso para detener estas acometidas.

Como sus predecesores partos, el Imperio sasánida mantuvo una relación exterior muy intensa con China, región a la que los embajadores persas viajaban con frecuencia. Los documentos chinos dan cuenta de trece embajadas sasánidas. El comercio terrestre y marítimo entre los dos imperios fue importante tanto para los sasánidas como para los chinos. Al sur de China se ha encontrado una gran cantidad de monedas sasánidas que corroboran el comercio marítimo entre las dos regiones.

En diferentes ocasiones, los reyes sasánidas enviaron a sus más dotados músicos y bailarines a la corte imperial china. Ambos imperios se beneficiaron del comercio a lo largo de la ruta de la seda y compartieron el interés por mantenerlo y protegerlo. Cooperaron en la custodia de las rutas de los mercaderes en Asia Central y construyeron puestos avanzados en las áreas fronterizas para mantener a las caravanas a salvo de las tribus nómadas y los bandidos.

Se conocen además los esfuerzos de sasánidas y chinos por forjar alianzas contra su enemigo común, los heftalitas. Dado el creciente control de Asia Central por parte de los nómadas de origen turco, también se produjo una colaboración entre China y el Imperio sasánida para rechazar el avance de estos.

Tras la invasión del Imperio por los árabes musulmanes, Peroz, hijo de Yazdegard III, escapó junto con algunos nobles persas y se refugió en la corte imperial china. Piroz y su hijo Narseh obtuvieron títulos de nobleza en la corte china. Al menos en dos ocasiones, la última probablemente en 670, fueron enviadas tropas chinas al mando de Peroz para que recobrase el trono, con resultados mediocres. Uno de estos intentos concluyó con un corto periodo de gobierno de Peroz en Sistán, del que se conserva un escaso registro numismático. Narseh alcanzó más tarde el cargo de jefe de la guardia imperial china, y sus descendientes vivieron en China como respetados príncipes.

Tras haber asegurado Irán y sus regiones vecinas bajo el reinado de Ardacher I, el segundo emperador, Sapor I (240-270), extendió su autoridad más aún al este, en el moderno Pakistán y la parte noroccidental de la India. Los kushán, antes autónomos, se vieron obligados a aceptar su autoridad. A pesar de que el Imperio kushán estaba en decadencia hacia el fin del siglo y fue sustituido por el gupta en el siglo , el cambio no afectó a la influencia sasánida, que siguió siendo notable en la parte noroccidental de la India durante este periodo de transición.

Persia y el noroeste indio entablaron un intercambio cultural y político durante este periodo, y ciertas prácticas sasánidas se extendieron por el territorio kushán. En particular, la influencia sasánida se plasmó en su concepto de realeza y en el comercio de la plata y los textiles. Este intercambio cultural no incluyó sin embargo las prácticas religiosas sasánidas o su actitud hacia los kushán. Mientras los sasánidas siempre tuvieron un concepto religioso ligado a la política proselitista estatal, y esporádicamente perseguían o obligaban a la conversión de las minorías religiosas, los kushán eran más tolerantes.

También tuvieron lugar durante este periodo intercambios culturales de menor nivel entre la India y Persia. Por ejemplo, los persas importaron el juego del ajedrez, cambiando el nombre del juego de "chaturanga" a "shatreng"; a cambio, los persas introdujeron el backgammon en la India.

Durante el reinado de Cosroes I se llevaron a Persia numerosos libros indios, que se tradujeron al persa medio, el idioma del Imperio sasánida. Algunos de estos volúmenes fueron luego incorporados a la literatura del mundo islámico. Un ejemplo notable de este tráfico literario fue la traducción del "Panchatantra" indio por uno de los ministros de Cosroes, Burzoe. La traducción de esta obra, conocida como el "Kelileh va Demmeh", llegó con posterioridad a Arabia y Europa. Los detalles del viaje legendario de Burzoe a la India y su atrevida adquisición del "Panchatantra" se describe con todo detalle en el "Libro de los Reyes" de Ferdousí.

La sociedad y la civilización propiciada por los sasánidas fue de las más florecientes de su tiempo. En su ámbito geográfico sólo rivalizaba con la sociedad bizantina. La importancia de los intercambios científicos e intelectuales entre ambos imperios es un ejemplo de competición y cooperación de estas cunas de civilizaciones.

La diferencia fundamental entre la sociedad parta y la sasánida fue el énfasis que la última puso en conseguir un gobierno centralizado y carismático. En la teoría social sasánida, la sociedad ideal era aquella que podía mantener la estabilidad y la justicia, y el instrumento necesario para ello era una monarquía fuerte.

La sociedad sasánida era tremendamente compleja, con sistemas de organización separados gobernando numerosos grupos diferentes a lo largo del Imperio. Los historiadores consideran que la sociedad estaba dividida en cuatro clases: la sacerdotal ("Atorbanan", en persa: آتروبانان), los guerreros ("Arteshtaran", en persa: ارتشتاران), los escribas ("Debiran", en persa: دبيران) y los plebeyos o campesinos ("Vasteryoshan-Hootkheshan", en persa: هوتخشان-واستريوشان). Como centro del sistema de castas sasánida se encontraba el Shahansha, gobernando sobre todos los nobles. Las princesas reales, los pequeños mandatarios, los grandes terratenientes y los sacerdotes constituían un estamento privilegiado, y se les conocía como "Bozorgan" (بزرگان) o nobles. Al parecer, era un sistema social bastante rígido.

La pertenencia a una clase social se basaba en el nacimiento, si bien era posible de forma excepcional que una persona cambiara de clase al obtener ciertos méritos. La función del rey era asegurarse de que cada clase se mantuviera dentro de sus propios límites, es decir, que los fuertes no oprimieran a los débiles, y los débiles no derrocaran a los fuertes. Mantener este equilibrio social era la esencia de la justicia del rey, y de esta justicia dependía la glorificación de la figura del monarca sobre las otras clases.

A un nivel más bajo, la sociedad sasánida estaba dividida entre los Azatan u hombres libres (آزادان) y la masa de campesinado de origen no ario. Los azatan formaban una amplia aristocracia de administradores de bajo nivel que vivían principalmente en pequeñas propiedades, guardando celosamente su estatus de descendientres de los antiguos conquistadores arios. Militarmente, los azatan constituían la columna vertebral de la caballería sasánida.

Los reyes sasánidas fueron mecenas de las letras y la filosofía. Cósroes I dispuso de los trabajos de Platón y Aristóteles traducidos al Pahlevi y que se enseñaban en Gundishapur, e incluso él mismo los leyó. Durante su reinado fueron compilados gran cantidad de anales históricos, de los cuales sólo se conserva el "Karnamak-i Artaxshir-i Papakan" (Los hechos de Ardacher), una mezcla de historia y romance que sirvió como base para la épica nacional iraní, el "Shahnama". Cuando Justiniano I cerró las escuelas de Atenas, siete de sus profesores huyeron a Persia y encontraron refugio en la corte de Cósroes. Con el tiempo, sintieron nostalgia de su tierra, y en los tratados de 533 entre Justiniano y el rey sasánida se estipuló que se permitiera a los sabios griegos regresar a su tierra libres de cualquier persecución.

Bajo Cósroes I, el colegio de Gundishapur, fundado en el siglo IV, se convirtió en "el mayor centro intelectual del mundo", acudiendo a él estudiantes y maestros de todas las partes del mundo. Incluso los cristianos nestorianistas fueron recibidos en Gundishapur, aportando las traducciones al sirio de los trabajos griegos sobre medicina y filosofía. También acudieron a Gundishapur los neoplatónicos, quienes plantaron la semilla del misticismo sufí, así como los eruditos de la India, Persia, Siria y Grecia, que se mezclaron para dar lugar al una floreciente escuela de medicina.

Artísticamente, el periodo sasánida fue testigo de los mayores avances de la civilización persa, gran parte de los cuales se fundieron con lo que se conoció como "cultura islámica", incluyendo la arquitectura y la literatura. En su punto álgido, el Imperio sasánida se extendía desde Siria hasta el norte de la India, pero su influencia llegó mucho más allá de sus límites políticos. Se han hallado motivos sasánidas en el arte de Asia Central y China, en el Imperio bizantino, e incluso en la Francia merovingia. Sin embargo, el verdadero heredero del arte sasánida fue el arte islámico, que asimiló sus conceptos y formas y al mismo tiempo, les insufló nueva vida y un vigor renovado. Como expresa el historiador americano Will Durant:

Los relieves sasánidas de Taq-e Bostan y Naqsh-e Rustam fueron en su origen policromadas, al igual que gran parte de los palacios, aunque sólo se conservan trazas de aquellos colores. La literatura, en cambio, deja claro que la pintura fue un arte floreciente en la época sasánida. Se sabe que el profeta Mani fundó una escuela de pintura; Ferdousí cuenta cómo los magnates persas adornaban sus mansiones con pinturas de los héroes iraníes, y el poeta al-Buhnturi describe los murales del palacio de Ctesifonte. A la muerte de los reyes sasánidas, los mejores pintores del momento eran convocados para pintar un retrato del difunto rey para la colección del tesoro real.

La pintura, escultura, alfarería y otras formas de decoración compartieron sus diseños con el arte textil sasánida. Sedas, bordados, brocados, damasquinados, tapices, tapicerías, doseles, techados y alfombras se tejían con paciencia servil por manos maestras, y eran introducidas en tintes calientes de amarillo, azul y verde. Casi cada persa, exceptuando los campesinos y los sacerdotes, aspiraban a vestir por encima de los de su clase. Los regalos se hacían frecuentemente en forma de suntuosas prendas de vestir, y las alfombras de vistosos colores eran señal de riqueza en el este desde los días de los asirios.

Las dos docenas de tejidos sasánidas que escaparon a la acción del tiempo están entre las fabricaciones humanas más valoradas. Incluso en su tiempo, el textil sasánida era admirado e imitado desde Egipto al lejano oriente, y durante las cruzadas, estos productos paganos eran apreciados para vestir las reliquias de los santos cristianos. Cuando Heraclio capturó el palacio de Khosru Parvez en Dastagird, los delicados bordados y las inmensas alfombras estaban entre sus más preciados despojos. Era famosa la "alfombra de invierno", también conocida como "la primavera de Cósroes" (قالى بهارستان) o "Khosru Anushirvan", diseñada para hacerle olvidar el invierno con sus escenas primaverales y veraniegas: flores y frutos hechos con rubíes y diamantes, además de caminos de plata y arroyos de perlas trazados sobre un fondo de oro. Harun al-Rashid se mostraba orgulloso sobre su espaciosa alfombra sasánida, intrincadamente labrada con joyas. Los persas incluso escibieron poemas de amor acerca de sus alfombras.

La influencia de los tejidos sasánidas, además de impregnar al arte textil del Imperio bizantino, se extendió tras la caída del Imperio a manos musulmanas por todos los dominios árabes, llegando hasta Al-Andalus, en el extremo oriental de estos dominios.

Los estudios sobre los restos muestran que los reyes sasánidas utilizaron alrededor de cien tipos de coronas. Las diferentes coronas sasánidas muestran la situación cultural, económica, social e histórica de cada periodo. También muestran el carácter de cada rey. Los diferentes símbolos y signos sobre las coronas, la luna, las estrellas, el águila y la mano nos ilustran acerca de las creencias religiosas de sus propietarios.

La dinastía sasánida, al igual que la aqueménida, se originó en la provincia de Persis (Fars). Los sasánidas se veían a sí mismos como sucesores de los aqueménidas tras el interludio de dominio helenístico y parto, y estaban convencidos de que su destino último era restaurar la grandeza de Persia.

Al revivir las glorias del pasado aqueménida, los sasánidas no fueron unos meros imitadores. El arte de este periodo revela una asombrosa vitalidad, anticipándose en ciertos aspectos a las aspectos claves del arte islámico. El arte sasánida combinaba elementos del arte tradicional persa con elementos e influencias helenísticas. La conquista de Persia por Alejandro el Grande originó la expansión del arte helenístico en Asia occidental. Aunque el este aceptó estas influencias artísticas de forma externa, nunca asimiló realmente su espíritu. Incluso en el periodo parto, el arte helenístico era interpretado libremente por los pueblos del cercano oriente. Así, el periodo sasánida fue una reacción contra estas formas artísticas. El arte sasánida resucitó formas y tradiciones nativas de Persia, y ya en el periodo islámico, estas formas alcanzaron las costas del Mediterráneo. Según Fergusson:

Los palacios supervivientes ilustran el esplendor en el que vivían los monarcas sasánidas. Sirvan como ejemplo los palacios de Firouzabad y Bishapur en Fars y en la capital del Imperio en Ctesifonte, en la provincia de Khvarvaran, en Irak. Además de las tradiciones locales, la arquitectura parta ejerció también influencia sobre las características de la arquitectura sasánida. Ambas se caracterizan por las bóvedas de medio cañón, introducidas durante el periodo parto. En el periodo sasánida, éstas alcanzaron enormes proporciones, especialmente en Ctesifonte. Allí, el arco el gran salón abovedado, atribuido al reinado de Sapor I (241-272) tenía un ancho de más de veintiséis metros, alcanzando una altura de casi cuarenta. Esta magnífica estructura fascinó a los arquitectos de los siguientes siglos, y está considerada como uno de los más importantes ejemplos de la arquitectura persa. Muchos de los palacios contenían un salón de audiencias interior consistente, como en el de Firuzabad, en una cámara cubierta por una cúpula. Los persas resolvieron el problema de construir una cúpula circular sobre un edificio cuadrado empleando arcos construidos en cada esquina del cuadrado, convirtiendo a éste de hecho en un octógono sobre el cual era más sencillo emplazar la cúpula. La cúpula de la cámara del palacio de Firouzabad es el ejemplo más antiguo que se conserva del uso de estos arcos, lo que sugiere que esta técnica arquitectónica es, probablemente, original de Persia.

La característica exclusiva de la arquitectura sasánida es el uso distintivo del espacio. Los arquitectos sasánidas concibieron sus edificios en términos de masas y superficies. Esto dio lugar al uso en abundancia de muros de ladrillo decorados con estuco moldeado o tallado. Las decoraciones sobre muros de estuco aparecen en Bishapur, aunque se dan mejores ejemplos de la misma en Chal Tarkhan, cerca de Rayy (del sasánida tardío o principios de la época islámica), y en Ctesifonte y Kish, en Mesopotamia. Los paneles muestran figuras animales en corro, bustos humanos y motivos geométricos o florales.

En Bishapur, algunos de los suelos fueron decorados con mosaicos que muestran escenas de júbilo, como en un banquete. Aquí, la influencia romana aparece clara, y los mosaicos podrían haber sido creados por prisioneros romanos. Los edificios fueron decorados con pinturas murales, de las que se dan buenos ejemplos en las encontradas en Kuh-i-Khwaja, en Sistan.

La industria persa bajo el gobierno sasánida se desarrolló desde el ámbito doméstico hasta el urbano. Se crearon numerosos gremios. Las vestiduras de seda fueron introducidas desde China, y las sedas sasánidas llegaron a todas partes, sirviendo como modelo para las artes textiles en Bizancio, China, Corea y Japón. La influencia de los productos textiles y la platería sasánida llegó a lugares tan lejanos como Hispania. Los mercaderes chinos llegaban a Irán para vender seda en bruto y comprar alfombras, joyas, maquillajes... Armenios, sirios y judíos conectaban Persia con Bizancio y Roma en un lento intercambio. Las buenas carreteras y puentes, bien vigilados, permitían el establecimiento de postas y caravanas de mercancías que unían Ctesifonte con todas las provincias. Se construyeron puertos en el Golfo Pérsico para facilitar el comercio con la India. Los mercantes sasánidas llegaron lejos y a muchas partes, desplazando a los romanos de las lucrativas rutas comerciales oceánicas con la India. Recientes descubrimientos arqueológicos muestran un hecho interesante: los sasánidas usaban etiquetas especiales sobre sus mercancías como forma de promocionar sus marcas y distinguir entre diferentes calidades.

Cósroes I extendió aún más la ya vasta red comercial. El Estado sasánida pretendió tomar el control monopolístico del comercio, con las mercancías lujosas asumiendo un papel primordial en el mismo, y una gran actividad en construcción de puertos, puestos de caravanas, puentes, y donde el objetivo era unir el comercio con la urbanización. Los persas dominaron el comercio internacional, tanto con el océano Índico como en Asia Central y el sur de Rusia en tiempos de Cósroes, a pesar de que la competencia con los bizantinos en aquel tiempo era intensa. Los asentamientos sasánidas en Omán y Yemen dan fe de la importancia del comercio con la India, aunque el comercio de la seda con China estuvo principalmente en manos de los vasallos de los sasánidas y de los pueblos iranios, como los sogdianos.

Las principales productos exportados por los sasánidas fueron los tejidos de seda, lana y dorados, las alfombras y tapices, las pieles y cueros y las perlas del golfo Pérsico. También hubo tráfico de mercancías procedentes de China (papel, seda) y la India (especias) sobre las que las aduanas sasánidas imponían aranceles y que eran reexportadas desde el Imperio a Europa.

Esta etapa supuso también un incremento de la producción metalúrgica, de tal forma que Irán se ganó la reputación de ser la «armería de Asia». Gran parte de los centros de minería sasánida se encontraban en la periferia del Imperio: en Armenia, en el Cáucaso, y sobre todo, en la Transoxiana. La extraordinaria riqueza mineral de las montañas de Pamir, en las fronteras orientales del Imperio, originó la leyenda sobre los tayikos, el pueblo iranio que allí habitaba y cuya leyenda aún perdura. Se dice que cuando Dios creó el mundo, viajó sobre los montes Pamir, dejando caer su jarra de minerales que se esparcieron a lo largo de la región.

La religión del estado sasánida era el zoroastrismo, si bien el zoroastrismo sasánida tenía claras diferencias sobre las prácticas reflejadas en el Avesta, el libro sagrado del zoroastrismo. El clero zoroastrista sasánida modificó la religión de forma que satisficiera sus intereses, provocando una sustancial intranquilidad religiosa. Las políticas religiosas sasánidas contribuyeron al florecimiento de numerosos movimientos reformistas religiosos, los más importantes de los cuales fueron las religiones de Mani y Mazdak.

El extremado y pronunciado dualismo constituyeron la característica más reseñable del zoroastrismo. "Ormazd" y "Ahriman", los principios del bien y del mal, eran considerados como gemelos, que vinieron en un principio para crear la vida y la muerte, y para establecer cómo sería el mundo. No había prioridad en la existencia de uno sobre el otro, y tampoco una decidida superioridad. Ambos, siendo contemporáneos, contendían desde el principio de los tiempos y seguirían haciéndolo por toda la eternidad, no siendo ninguno de ellos capaz de desbancar al otro.
Estos dos principios eran representados como personas. "Ormazd" era el creador de vida, terrenal y espiritual, creador de los cuerpos celestiales, la tierra, el agua y los árboles. "Ormazd" era bueno, sagrado, puro, verdadero. Significaba la suprema felicidad, y estaba en posesión de todas las bendiciones: salud, riqueza, virtud, sabiduría e inmortalidad. De él procedían todos los dones de los que el hombre podía disfrutar. Al igual que recompensaba la bondad, también castigaba la maldad, si bien éste era un aspecto de su esencia raramente representado.

El culto zoroastrista estaba íntimamente conectado con los templos y altares dedicados al fuego. En todas las ciudades importantes del Imperio se mantenía un templo del fuego, y en cada uno de ellos se veneraba a una llama sagrada, de la que se creía que había sido encendida desde los cielos y se mantenía perpetuamente encendida por los sacerdotes. Se decía de esta llama que era "inextinguible". Es probable que los altares del fuego también existieran de forma independiente de los templos. A lo largo de la historia de los sasánidas, el altar del fuego tuvo un lugar prominente en la numismática como la más frecuente impresión del reverso de las monedas. Se representaba este altar con la llama surgiendo del mismo, y en ocasiones con una cabeza en la llama. El pie de este altar solía ornamentarse con guirnaldas o cintas, y a cada lado, como protectores o devotos, se representaban dos figuras, en ocasiones mirando la llama, y en otras vueltos de espaldas a ésta, como guardándola de los enemigos externos.

Además del zoroastrismo, coexistían en la sociedad sasánida otras religiones minoritarias, principalmente el judaísmo, el cristianismo y el budismo, las cuales fueron en muchos periodos libres de practicar sus cultos y de predicar sus creencias.

La idea heterodoxa de un Cristo Humano y Divino pero separado en dos personas se conoce como nestorianismo.Cuando tras el Concilio de Éfeso (año 431) el nestorianismo fue considerado herejía, y por tanto fue desterrado del Imperio romano, la diáspora de los cristianos nestorianos encontró refugio en el Imperio sasánida. Gran parte de los habitantes cristianos del imperio persa (en especial en Irak) y los Lajmidas abrazaron la denominación cristiana conocida en Occidente (incluyendo aquí a Siria y al Imperio Bizantino como partes del Occidente) con el citado adjetivo de "nestorianismo".

Bajo el gobierno sasánida floreció una populosa comunidad judía, cuyos centros más prósperos eran Isfahán, Babilonia y Jorasán, y con una autoridad religiosa semiautónoma establecida en Mesopotamia. Esta comunidad judía en Persia, de hecho, continuó siendo floreciente hasta la llegada del sionismo a finales del siglo XIX. Las comunidades judías sufrieron, sin embargo, persecuciones ocasionales, aunque en términos generales, disfrutaron de una relativa libertad religiosa, y gozaban de privilegios que se le negaban a otras comunidades religiosas minoritarias. Sapor I ("Shabur Malka" en arameo) fue particularmente amistoso con los judíos. Su amistad con el rabino Samuel conllevó muchas ventajas para la comunidad judía. Incluso ofreció a los judíos del Imperio sasánida un magnífico caballo, por si llegara el Mesías, de quien se pensaba que llegaría a lomos de un burro o una mula.

Sapor II, cuya madre era judía, conservó una amistad parecida con el rabino babilonio Raba. La amistad con Raba aseguró a los judíos la relajación de las opresivas leyes dictadas contra los judíos en el Imperio persa. En esta coyuntura de tolerancia, en los territorios orientales del Imperio varios lugares de adoración budista, especialmente Bamiyán, experimentaron cierto auge a medida que el budismo se hacía más popular en la región (actuales Afganistán y Pakistán).





</doc>
<doc id="15345" url="https://es.wikipedia.org/wiki?curid=15345" title="Hipótesis de Sapir-Whorf">
Hipótesis de Sapir-Whorf

La hipótesis de Sapir-Whorf establece que existe una cierta relación entre las categorías gramaticales del lenguaje que una persona habla y la forma en que la persona entiende y conceptualiza el mundo. También se conoce a esta hipótesis como PRL (Principio —o hipótesis— de Relatividad Lingüística). El primer lingüista en mencionar este concepto fue Harry Hoijer.

Podemos distinguir una formulación fuerte y una más débil del siguiente modo:
La hipótesis de Sapir-Whorf ha sido uno de los principales temas dentro de las discusiones en torno al relativismo lingüístico.

La hipótesis original fue formulada por Edward Sapir y su discípulo Benjamin Lee Whorf. Whorf tomaría las teorías de su maestro para desarrollarlas a lo largo de la década de 1940. En su versión fuerte la hipótesis Sapir-Whorf puede considerarse una forma de determinismo lingüístico, aunque el interés de los psicólogos por la influencia del lenguaje en el pensamiento es anterior a la formulación de la hipótesis de Sapir-Whorf como tal. Julia Penn, en su libro "Linguistic Relativity versus Innate Ideas. The Origins of the Sapir-Whorf Hypothesis in German Thought", remonta los cimientos teóricos de esta hipótesis al trabajo del pensador pietista alemán Johann Georg Hamann (1730–1788), elaborando luego una línea evolutiva para esta corriente interpretativa del lenguaje que incluiría a Johann Gottfried Herder (1744–1803), Wilhelm von Humboldt (1767–1835) y Jan Baudouin de Courtenay (1845–1929), mientras que Franz Boas (1858–1942) y Edward Sapir (1884–1935) se apartarían en una rama diferente del árbol evolutivo de la corriente. En el esquema de Penn, Benjamin Lee Whorf (1897–1941) tomaría elementos de estos pensadores, especialmente de Sapir, para elaborar la hipótesis tratada en este artículo.

Una hipótesis muy revisada de la versión «débil» de la hipótesis whorfiana es conocida como la hipótesis Whorf-Korzybski. Julia Penn considera esta hipótesis altamente probable y la define de la siguiente forma:

Penn se apoya, para contemplar esta hipótesis como posible, en los experimentos realizados por John B. Carrol y Joseph H. Casagrande con hablantes de hopi y navajo. Sin embargo, según Xabier Zabaltza, en su libro "Una historia de las lenguas y los nacionalismos", cabe destacar que esta hipótesis se refiere al habla individual (lo cual en términos de Saussure se denominaría "parole") y no a la propia lengua ("langue"), que es una actividad social. Zabaltza destaca la diferencia entre los dos conceptos en el idioma francés, observando que en el alemán no existe la diferencia entre ellos, siendo que los dos comparten la misma denominación: "sprache".

La posición de que la estructura y categorías de la propia lengua materna condiciona el pensamiento fue argumentada convincentemente por Bhartrihari (siglo VI d. C.) y fue tema de siglos de debate en la tradición lingüística de la India. Nociones relacionadas en Occidente, como el principio de que el lenguaje tiene efectos de control en el pensamiento pueden ser identificados en el ensayo de Wilhelm von Humboldt "Über das vergleichende Sprachstudium" ("Sobre el estudio comparativo de las lenguas"), y la noción ha sido asimilada de manera importante en el pensamiento occidental. Karl Kerenyi empezó su traducción de "Dionysus" al inglés en 1976 con este pasaje:

El origen de la Hipótesis de Sapir-Whorf como un análisis más riguroso de esta percepción cultural familiar puede ser remontada al trabajo de Franz Boas, el fundador de la antropología en Estados Unidos. Boas fue educado en Alemania a finales del siglo XIX durante la época en la que científicos como Ernst Mach y Ludwig Boltzmann estaban tratando de entender la fisiología de la sensación.

Una aproximación importante de la época era el renacido interés en el trabajo de Immanuel Kant. Éste decía que el conocimiento era resultado del trabajo cognitivo concreto de parte del individuo; la realidad («intuición sensitiva») estaba en constante flujo y el entendimiento provenía de interpretar dicha intuición mediante las «categorías del entendimiento». Individuos diferentes pueden entonces percibir la realidad noumenal como instancias fenoménicas de sus diferentes conceptos individuales.

En EE. UU., Boas encontró lenguas amerindias de diferentes familias lingüísticas, todas distintas a las lenguas semíticas e indoeuropeas estudiadas por la gran mayoría de académicos europeos. Boas se dio cuenta de lo grandes que pueden ser las diferencias entre las categorías gramaticales y formas de vida de un lugar a otro. Como resultado, Boas llegó a la conclusión de que la cultura y las formas de vida de un pueblo estaban reflejados en el lenguaje hablado por éste.

Edward Sapir fue uno de los estudiantes más notables de Boas, y profundizó su argumento notando que los lenguajes eran sistemas formal y sistemáticamente completos. Así que no se trataba de que alguna palabra en particular expresara una forma de pensar o comportarse, sino de que la naturaleza sistemática y coherente del lenguaje interactuaba en un nivel más amplio con el pensamiento y el comportamiento. Aunque sus ideas cambiaron con el paso del tiempo, pareciera que hacia el final de su vida Sapir llegó a creer que el lenguaje no era un mero reflejo de la cultura, sino que el lenguaje y el pensamiento podían de hecho tener una relación de mutua influencia e inclusive de determinación. Whorf le dio todavía más precisión a esta idea al examinar los mecanismos gramaticales particulares mediante los cuales el pensamiento influía en el lenguaje.

Sapir afirmó: 

Esta expresión, que en el fondo manifiesta un prejuicio, indica que la forma de hablar de los porqueros macedónicos no era inferior a la forma de hablar de Platón, y que Confucio no tenía una capacidad sintáctica superior a la de los cazadores de cabezas de Assam. La crítica a esta hipótesis se estructurará sobre el argumento de que la forma lingüística de todos los seres humanos es equivalente.

Existen hechos que parecen difíciles de explicar si aceptamos la hipótesis Sapir-Whorf en su versión fuerte. Así por ejemplo se ha podido comprobar que los bebés, chimpancés e incluso las palomas son capaces de categorizar y agrupar categorías de objetos en conceptos, a pesar de carecer de lenguaje.

Sin embargo, la cuestión parece diferente cuando consideramos la hipótesis débil. Desde hace tiempo se sabe que la memoria y la percepción psicológica se ven afectadas o influidas por la disponibilidad de las palabras y de las expresiones apropiadas, por ejemplo, sustantivos de colores. Ciertos experimentos han mostrado que las memorias visuales de las personas tienden a distorsionarse con el tiempo, de modo que los recuerdos visuales terminan pareciéndose cada vez más a las categorías lingüísticas comúnmente usadas por dichas personas.

Se mostró, por ejemplo, que los hablantes monolingües de zuñi, una lengua amerindia hablada en Nuevo México cuyo vocabulario no diferencia entre «naranja» y «amarillo», experimentaban mayor dificultad que los zuñi que también sabían inglés o los que sólo hablaban inglés a la hora de reconocer después de cierto tiempo objetos de un color fácilmente codificable y expresable en inglés, pero no en lengua zuñi o zuni.

En el experimento se mostraba a un individuo un objeto de color amarillo o anaranjado; al cabo de cierto tiempo se le mostraba dos objetos iguales, uno amarillo y otro anaranjado, entre los cuales estaba el que el sujeto había visto anteriormente, y se le pedía que identificara el que se le había mostrado la otra vez. Se ha mostrado, además, que no es que los hablantes de zuñi fueran incapaces de percibir la diferencia entre un amarillo y un objeto anaranjado, si se les pedía que los compararan cuando los tenían presentes, sino un efecto de memoria al cabo del tiempo para recordar la tonalidad.

Estos experimentos parecen confirmar parcialmente la hipótesis de Sapir-Whorf, pero no proveen suficiente evidencia en favor de la formulación fuerte de la misma. Parece razonable aceptar que el lenguaje que uno habla tiene influencia sobre la memoria y la manera en como se codifican en ella algunas cosas, tal como se ha dicho, pero es dudoso que el lenguaje sea en realidad el que provee todos los patrones de pensamiento del individuo (ciertos experimentos muestran la existencia de pensamiento no verbal). 

Varios experimentos recientes parecen confirmar la plausibilidad de una versión débil de la relatividad lingüística. Este es el caso de, por ejemplo, John Lucy, que ha conducido estudios comparativos con hablantes nativos de inglés y de maya yucateco, en los que mostró que los que tenían el inglés como lengua materna tendían a seleccionar los objetos por su forma, mientras que los hablantes de yucateco solían preferir el material de que estaban hechos. Así, por ejemplo, si se les pedía que eligieran un objeto parecido a una caja de cartón, los hablantes de inglés seleccionarían cajas, aunque fueran de plástico, mientras que los de yucateco elegían objetos de cartón aunque no tuvieran forma de caja. Lucy atribuyó esta diferencia en la conceptualización de objetos a la presencia, en yucateco, de unos clasificadores que deben acompañar el sustantivo siempre que éste se presente detrás de un numeral; estos clasificadores son los que indican lingüísticamente la forma de los objetos, por lo que para los hablantes de yucateco el aspecto más importante de los sustantivos no sería la forma, sino más bien la materia.

Dan Slobin también ha llevado a cabo varios experimentos en los que estudia los efectos de la gramática a la hora de conceptualizar; en concreto, defendió que dos lenguas diferentes pueden dar lugar a dos narrativas inconmensurables de un mismo evento. Su estudio versó sobre la forma en que hablantes nativos de inglés, turco y español, divididos por rangos de edad, narraban una misma sucesión de imágenes. De acuerdo con sus conclusiones, había una correlación entre la lengua hablada y aquellos aspectos de la escena que los participantes narraban; así, por ejemplo, los hablantes nativos de español tendían a destacar más el tiempo en que la acción transcurría, los hablantes de inglés solían destacar en qué dirección espacial se orientaba lo que sucedía, mientras que los hablantes de turco destacaban qué protagonistas de la escena habían contemplado lo que ocurría. Como conclusión, Slobin ha postulado la existencia de una serie de categorías mentales que son adquiridas a través del lenguaje y que son utilizadas únicamente para la expresión lingüística; se trataría, pues, de una versión de la relatividad lingüística limitada a contextos puramente lingüísticos.

Alfred Bloom también ha trabajado en el tema de las diversas narrativas, trabajando sobre el chino mandarín. Bloom condujo un experimento donde mostró a unos hablantes nativos de inglés un texto que contenía construcciones en subjuntivo, mientras mostraba a unos hablantes nativos de chino una traducción literal del mismo a su lengua, en la que esta construcción gramatical es inexistente. El resultado fue que, cuando se preguntó a los participantes si los acontecimientos narrados en el texto habían o no sucedido, los hablantes de chino fallaron en un porcentaje mucho mayor que los de inglés; la conclusión era, pues, que resulta imposible traducir literalmente de una lengua a otra, y esto debe ser debido a que cada una de ellas conceptualiza la realidad de una manera diferente. Lera Boroditsky también ha trabajado en estudios comparativos entre el inglés y el chino mandarín, y ha mostrado que los hablantes de cada una de estas concibe el tiempo de una manera distinta: mientras que el inglés asocia el transcurso del tiempo con un movimiento horizontal, el chino lo asocia a uno vertical. Ahora bien, esta autora también ha defendido la posibilidad de que los hablantes de una lengua aprendan a conceptualizar del mismo modo que los de la otra sin necesidad de aprender la otra lengua, así que aboga por una versión débil - no determinista - de la relatividad lingüística.

Hoy en día esta hipótesis está desacreditada en su forma fuerte. Los ejemplos en los que se basaron Sapir y Whorf son irreales. Por ejemplo, ellos decían que los amerindios zuñi no tenían vocablo diferente para el «amarillo» y el «naranja» y que eso tendría que condicionar su modo de pensar. La verdad es que no tienen esos vocablos, pero diferencian perfectamente lo amarillo de lo naranja. Lo que ocurre es que en su modo de vida la diferencia es irrelevante, aunque como explica Lyons, sus hábitos de memoria sí parecen afectados por la existencia de la distinción léxica.

En relación a los experimentos con colores ha habido una larga polémica que comenzó con el universalismo sobre los términos de color que comportaban los resultados de los experimentos llevados a cabo por Berlin y Kay. Estos experimentos confirman la existencia de universales lingüísticos en cuanto a los términos para nombrar los colores básicos. Así pues, la fisiología y la percepción, de carácter universal, jugarían un papel determinante a la hora de establecer la semántica de una lengua.

Una posible prueba del error de Sapir-Whorf sería el hecho de que los traductores son capaces de traducir lo que se dice en una lengua a otra. No se podría hablar por lo tanto de que el lenguaje determinase la forma en que pensamos, sería más exacto y correcto decir que influye en el pensamiento.

Los experimentos de Bloom sobre el subjuntivo han sido cuestionados por Au, quien dirigió una serie de experimentos similares a los conducidos por Bloom; según mostró, el problema de los experimentos de este último fue el hecho de que la traducción al chino que había realizado resultaba confusa por ser demasiado literal, y una vez la traducción fue adaptada a un chino más común, las diferencias que había entre los hablantes de ambas lenguas desaparecieron.

Las principales críticas a la hipótesis del relativismo lingüístico serían, por tanto:

Steven Pinker también ha atacado con fuerza la hipótesis de la relatividad lingüística, defendiendo la universalidad del mentalés o lenguaje del pensamiento. Según defiende, el pensamiento funcionaría de manera análoga a una máquina de Turing, y por tanto resulta absurdo considerar que este esté condicionado por una lengua particular - como tampoco podría estarlo la fisiología, por lo que el lenguaje no podría alterar nunca la percepción.

Otra crítica que se realiza a esta teoría es la visión nacionalista, o incluso racista, que podría acarrear, ya que al distinguir el funcionamiento de la mente humana en función de la lengua del hablante, se estaría sosteniendo que los individuos tendrían capacidades intelectuales diferentes según su idioma, en caso de hablar una única lengua, por supuesto. Xabier Zabaltza escribe: «La hoy conocida como hipótesis Sapir-Whorf [...] ha servido de coartada intelectual a todos los nacionalismos lingüísticos» ("Una historia de las lenguas y los nacionalismos". Xabier Zabaltza, 2006). Ahora bien, cabría decir que tanto Sapir como Whorf admitían la unidad psíquica de la humanidad, y que la relación de determinación del lenguaje no era tanto hacia la manera de razonar como hacia la cosmovisión sostenida por los hablantes.





</doc>
<doc id="15346" url="https://es.wikipedia.org/wiki?curid=15346" title="Hypericum perforatum">
Hypericum perforatum

Hypericum perforatum, también conocida como hipérico, hipericón, corazoncillo o hierba de San Juan , es la especie más abundante de la familia de las gutíferas (Guttiferae) o hipericáceas (Hypericaceae).

Es una planta común en los terrenos de baja y media altura. Se encuentra prácticamente en toda Europa, hasta el este de Rusia, y se ha aclimatado en numerosas partes del mundo: China, Australia, Norte de África y América.

Hipócrates la recomendó como remedio refrescante y antiinflamatorio.

Dioscórides escribe lo siguiente (con la ortografía de las traducciones antiguas): "El Hyperico, llamado Androsemo por unos, por otros Corio, y por otros Camepytis, que quiere decir Pinillo, porque su resina huele a resina de pino, es una mata ramosa, roxeta y de un palmo de alta, que produce las hojas como la ruda, y de flor amarilla: la qual frotada entre los dedos, resuda un liquor semejante a la sangre, de do vino a llamarse Androsemo que significa sangre humana. Nace el hyperico en lugares cultivados y ásperos. Tiene facultad de mover la orina y, aplicado por baxo, provoca el menstruo. Bebido con vino, extermina las tertianas y las quartanas. Su simiente bevida por una quarentena de días, cura la sciática y las hojas con la simiente aplicadas en forma de emplastro, sanan las quemaduras del fuego"

Es una hierba originaria de Europa, que se ha naturalizado en América y Australia. Los pétalos de la flor son de color amarillo dorado, con pequeñas motas negras en sus bordes, el apelativo latino "perforatum" proviene de las pequeñas perforaciones -en realidad son bolsas de aceite esencial- que pueden verse al trasluz en cada una de las hojas de esta planta. Son el doble de largos que los sépalos. Una peculiaridad de esta hierba es que, al aplastar entre los dedos alguna de sus hojitas, deja una mancha en la piel, su savia anaranjada.

En Australia y en los Estados Unidos se la considera como una maleza o una especie invasora y se la combate por medio de controles biológicos tales como los escarabajos del género "Chrysolina", que se especializan en esta planta.




"Hypericum perforatum" es una planta medicinal con múltiples aplicaciones. Por ejemplo, su aplicación tópica sirve para acelerar la cicatrización de las heridas.

Sin embargo, las propiedades de esta hierba que más han atraído a los investigadores se vinculan con su uso tradicional para el tratamiento de la depresión leve a moderada y la ansiedad. Esta indicación ha sido validada en las últimas décadas por las agencias de salud de algunos países como Alemania, donde ha sido incluida en la farmacopea oficial, y se prescribe ampliamente con ese propósito terapéutico.

Cuando el hipérico se utiliza como medicamento fitoterapéutico, generalmente se administra en forma de extractos estandarizados, con concentraciones fijas de los principios activos a los cuales se atribuyen los efectos farmacológicos; se estima que el más importante de estos es la hipericina, aunque estudios recientes reportan una mayor actividad de la hiperforina. Esta conclusión se basa fundamentalmente en un ensayo con resultado negativo llevado a cabo por el Centro Nacional de Medicina Complementaria y Alternativa de los Estados Unidos.

Para este fin (tratamiento de la depresión), la hierba de San Juan puede conseguirse en diversas presentaciones: como hierba, como gragea o cápsula, en bolsas de té o en tinturas.

El hipérico es un potente inductor enzimático del citocromo P450 (isoenzima CYP3A4) y posiblemente también de la glucoproteína P. Puede producir interacciones con otras sustancias, tales como la digoxina o anticoagulantes orales. 

Asimismo, se han documentado casos de rechazo de trasplante de corazón en dos pacientes que combinaron el tratamiento inmunosupresor (ciclosporina) y la toma de hipérico. En ambos casos, todo parece indicar que el hipérico provocó un descenso de las concentraciones plasmáticas de ciclosporina por debajo del nivel terapéutico, lo que causó el rechazo del injerto. Un estudio formal posterior demostró que el hipérico reduce la concentración plasmática de indinavir.
Debido a la importancia de estos datos, parece prudente no asociar la toma de hipérico con la de ningún fármaco de metabolismo hepático. "Véase el apartado" Tabla de interacciones con diversas sustancias.

Hypericum perforatum puede interferir con la absorción de hierro y otros minerales. El responsable de la toxicidad de esta planta, es la hipericina, se trata de un pigmento heliantrono de color rojo encarnado y fluorescente que se encuentra en las manchas negras dispersas en la superficie de las hojas y pétalos florales del vegetal. Este compuesto se encuentra presente en la planta en todo momento y persiste cuando se seca o es henificada.

La hipericina es la responsable de la fototoxicidad, desde la antigüedad, se han observado trastornos de la piel en animales que habían comido de esta planta. Sólo en casos graves por sobrealimentación, se observaron convulsiones epilépticas, crisis hemolíticas o muerte del animal. Como consecuencia de la fotosensibilización también se observan trastornos hepáticos e ictericia, al tiempo que las partes poco pigmentadas de la piel pueden necrosarse o desprenderse, dando lugar a cicatrices de curación muy lenta. Por otra parte, los animales hembras que comen de esta planta han mostrado una menor secreción láctea. En personas que hayan tomado esta planta y que se expongan al sol posteriormente, se puede presentar una pigmentación discreta de la piel (eritemas) o prurito.

Hypericum perforatum ha demostrado ser solo ligeramente tóxico tras una única dosis oral o intraperitoneal. A nivel experimental, la DL han sido las siguientes:

La administración oral repetida del extracto de Hypericum perforatum a dosis de 300, 900 y 2700 mg/kg de peso corporal diarios en ratas y perros durante un período de 26 semanas no provocó cambios específicos de la sustancia. A dosis superiores a 900 mg/kg peso corporal diarios se desarrollaron signos inespecíficos de intoxicación: peso reducido, ligeros cambios en el hemograma, cambios en la química clínica y morfológicos los cuales, causados por la alta dosis, indicaron un daño leve, por sobrecarga, en el hígado y riñones.

Los estudios se llevaron a cabo con ratas y conejos y no hubo evidencia ninguna de cambios teratogénicos hasta dosis situadas en el rango de la toxicidad materna. Los efectos embrio-fetotóxicos, aparecieron a dosis tóxicas para la madre y se observó:
En el estudio de fertilidad con ratas, no se mostraron efectos sobre las mismas. Cabe destacar que, en las ratas, la hipericina se acumula en la leche pudiendo llegar a alcanzar concentraciones superiores a las del plasma materno, pero debido al amplio margen de seguridad que muestra la hipericina es improbable que la cantidad ingerida con la leche represente peligro alguno para el niño aunque no se dispone de información suficiente en lo relativo a la lactancia. Como precaución general, no se debe emplear ni en el primer trimestre del embarazo ni durante la lactancia.

Se han llevado a cabo estudios de mutagenicidad in vitro e in vivo concluyendo la inexistencia de riesgo mutagénico para el hombre con extracto de Hypericum.

Sobre el potencial carcinogénico no se tienen suficientes datos como para concluir la existencia o no de potencial

La fotosensibilidad es el principal riesgo de toxicidad, siendo de tipo primaria puesto que se produce por absorción digestiva de la planta, pero en raras ocasiones pueden aparecer trastornos gastrointestinales, cansancio o intranquilidad

Como se ha dicho previamente, la hipericina es el causante de la fotosensibilización (un tipo de reacción alérgica) en el ganado ovino provocando un exantema o la enfermedad conocida como St. Johnsword. Estos pigmentos de la planta, son ingeridos en ocasiones de manera abundante por los ovinos en pastoreo. Posteriormente llegan a la piel desde el torrente circulatorio donde oxidan los aminoácidos, histidina, triptófano y tirosina, modificando así la estructura y permeabilidad de las células. La gravedad va a depender de la dosis, de la duración de la ingesta así como de la intensidad de la radiación solar.

La clínica aparece en zonas no pigmentadas ni revestidas de lana, es decir, en cabeza, orejas, extremidades y mama donde aparecen inflamaciones, sobre todo en la cabeza recibiendo el nombre de “cabeza hinchada”, y en las zonas de la piel, ésta, estará hinchada, caliente y edematosa; esta patología, se continua con la exudación de un líquido seroso y desprendimiento del epitelio. Como mecanismo de defensa, los animales tratan de encontrar la sombra. En etapas posteriores, pueden necrosarse partes de la piel afectada así como las puntas de las orejas.

En ocasiones, aunque no es tan frecuente, puede aparecer:
Destacar que las intoxicaciones por Hypericum se producen, fundamentalmente, en animales ovinos durante la ingesta del pasto. Suelen ser los animales jóvenes los más afectados, debido a la competencia por el alimento en el pasto así como la falta de experiencia de estos últimos a la hora de elegir los alimentos no tóxicos.

Las intoxicaciones infantiles por Hypericum, según el Servicio de Información Toxicológica, se producen ocasionalmente, dado que estos pueden llevarse a la boca los fitofármacos que contengan el extracto de Hypericum que toman sus familiares adultos

La Agencia Española del Medicamento considera necesario advertir que los productos que incluyen en su composición al Hypericum perforatum, tienen la capacidad de interaccionar con distintos medicamentos. Las interacciones son producto de la capacidad inductora del Hypericum perforatum sobre ciertas isoenzimas del citocromo hepático P450. Como consecuencia puede aparecer una disminución de las concentraciones plasmáticas y una pérdida del efecto terapéutico; teniendo en cuenta este mecanismo de la interacción, al dejar de administrar Hypericum perforatum puede también provocar un aumento de los niveles sanguíneos de algunos medicamentos con la consiguiente aparición de toxicidad, siendo especialmente importante en medicamentos de estrecho margen terapéutico. La interacción con los IMAO es de especial importancia debido a que conduce a una situación peligrosa porque puede dar lugar a crisis hipertensivas. Ocurre lo mismo en el caso de una ingestión de alimentos ricos en tiramina por la ingestión de esta planta.

Un ejemplo concreto es la interacción con los inhibidores de la proteasa en los cuales se produce una disminución significativa de las concentraciones plasmáticas de los mismos por la inducción de la isoenzima 3A4 del citocromo P450. Como resultado de ello, no se alcanzan concentraciones plasmáticas terapéuticas de este tipo de fármaco pudiendo desarrollarse resistencias y falta de eficacia del tratamiento.

La administración de los extractos de esta hierba es motivo de debate. Aunque existe evidencia limitada que sugiere su eficacia y seguridad, no ha sido evaluada sistemáticamente en lo que respecta a la incidencia de efectos secundarios e interacciones con otras drogas, con los riesgos que esto conlleva. Aun así, se menciona que, en el caso de algunos tratamientos, reduce su efecto como en los tratamientos para personas con VIH.

Se la considera un agente primario de la fotosensibilización en bovinos, en los cuales la hipericina se acumula en el tejido subcutáneo y reacciona con la luz solar, y provoca cuadros de inflamación de la dermis, especialmente de las partes menos pigmentadas, las cuales pueden desprenderse del animal.

Esta especie se conoce con numerosos nombres comunesen español: amnica, cientoenrama, corazón de ciervo, corazoncillo, corión, espantadiablos, hierba del agua, hierba de la sangre, hierba de las heridas, hierba de las machacauras, hierba de San Juan, hierba militar, hipericón, hipericón oficinal, hipérico, hipérico horadado, hipérico común, perforada, perforata, pericó, pericón, pericón amarillo, pericón común, pericón silvestre, perico, pericote, periquito, San Juan, sanjuanera, sanjuanes, san juanes, sanjuanines, té borde, trescalar, tresflorina, yerba de San Juan, yerbuca de San Juan.

"Hypericum perforatum" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 785. 1753.
Hipérico: nombre genérico que deriva del griego ὑπερικόν "hyperikón". Su nombre está compuesto de ὑπ- "debajo" y ἐρείκη "Erica arborea" o "brezo blanco", y por tanto significa "brezo bajo". La planta es mencionada 143 veces por los médicos grecolatinos. Es fantasioso afirmar que procede del griego ὑπέρ "por encima" y εἰκών "imagen", queriendo decir "por encima de todo lo imaginable".

perforatum: epíteto que se debe a las glándulas de aceite situadas en sus hojas y sépalos que le dan a la planta un aspecto perforado, si se observa al trasluz.
"Hypericum perforatum" ha sido designado a lo largo de la historia con distintos nombres científicos, considerados sinónimos:



nuevo
En inglés:


</doc>
<doc id="15348" url="https://es.wikipedia.org/wiki?curid=15348" title="Transiberiano">
Transiberiano

El ferrocarril Transiberiano ( "Transibírskaia maguistral, Transsib") es una red ferroviaria que conecta la Rusia europea con las provincias del Lejano Oriente ruso, Mongolia, República Popular China y conecta con Corea del Norte.

La ruta principal fue inaugurada después de trece años de trabajo, el 21 de julio de 1904. Con una extensión de 9288 km, une Moscú con la costa rusa del océano Pacífico, más precisamente con Vladivostok (localizada en el mar del Japón, y cuyo significado en ruso es “poder sobre oriente”), atravesando la mayor parte de la que fue Asia Zarista. Esta vía, que atraviesa ocho zonas horarias y cuyo recorrido demanda cerca de 7 días de viaje, constituye el servicio ferroviario continuo más largo del mundo, con excepción de la ruta que se hace dos veces al mes regularmente, y que sirve de conexión entre Moscú y Pionyang. Hay ramales a China, a través de Mongolia y Manchuria, con servicio continuo a Corea del Norte.

Otro ramal de importancia dentro de esta extensa red ferroviaria es el Transmanchuriano, cuyo recorrido coincide con el Transiberiano hasta Társkaya, unos 1000 km al este del lago Baikal. Desde la ciudad de Társkaya, el Transmanchuriano enfila al sureste hacia China, y sigue su recorrido hasta finalizar en Pekín.

La tercera de las rutas primarias es el Transmongoliano, que coincide en su traza con el Transiberiano hasta Ulán Udé, en la ribera este del lago Baikal. Desde Ulán Udé, el Transmongoliano enfila al sur hasta Ulán Bator, tras lo cual sigue en dirección sudeste hasta Pekín.

En 1991 fue completada una cuarta ruta, cuyo recorrido se encuentra más al norte, tras más de cinco décadas de obras esporádicas. Conocida como Ferrocarril Baikal-Amur, esta extensión se separa del Transiberiano varios cientos de kilómetros al oeste del Lago Baikal, y lo atraviesa por su extremo norte. Esta ruta alcanza el océano Pacífico al noreste de Jabárovsk, en Sovétskaya Gavan. Si bien brinda acceso a la notable costa norte del Baikal, este ramal se caracteriza también por atravesar zonas consideradas peligrosas.

La ruta principal, recorrida por el tren No. 1, que se conoce con el nombre de "Rossía" ("Rusia" en ruso), pasa por las siguientes ciudades:
Entre 1956 y 2001, el tren "Rossía" seguía un recorrido vía Yaroslavl en lugar de hacerlo por Nizhny Nóvgorod. Otros trenes todavía circulan por la ruta de Yaroslavl, o la ruta más sureña de Kazán.

La mayoría de los viajeros recorren en el "Rossía" tan sólo una parte del trayecto, pues este tren realiza un servicio relativamente rápido entre ciudades importantes, tales como Ekaterimburgo, Novosibirsk o Irkutsk.

El Transmanchuriano sigue el mismo recorrido que el Transiberiano entre Moscú y Chitá, para luego atravesar las siguientes poblaciones en su camino hacia China:

El Transmongoliano sigue el mismo recorrido que el Transiberiano entre Moscú y Ulán Udé, para luego atravesar las siguientes poblaciones en su camino hacia Mongolia y China:

A finales del siglo XIX, el desarrollo de Siberia se vio dificultado por las malas comunicaciones de transporte dentro de la región, así como con el resto del país. Aparte de la Ruta siberiana, no existían buenos caminos adecuados para el transporte sobre ruedas. Durante unos cinco meses del año, los ríos eran los principales medios de transporte. Durante la mitad fría del año, la carga y los pasajeros viajaron en trineos tirados por caballos sobre los caminos en invierno, muchos de los cuales eran los mismos ríos, pero cubierto de hielo.

El primer barco de vapor en el río Ob, el "Osnova" de Nikita Miasnikov, se puso en marcha en 1844. Los inicios fueron difíciles y no fue hasta 1857 que la navegación en barco de vapor comenzó a desarrollarse en el Ob de manera seria. Los barcos de vapor comenzaron a funcionar en el Yeniséi en 1863, en el Lena y Amur, en la década de 1870.

Mientras que la relativa planitud de Siberia Occidental era, por lo menos, bastante bien servida por el gigantesco sistema del río Ob-Irtysh-Tobol-Chulym, los poderosos ríos de Siberia Oriental —como el Yeniséi, el curso superior del río Angara y el Lena— eran en su mayoría navegables sólo en la dirección norte-sur. Un intento de remediar en parte la situación mediante la construcción del Canal de Ob-Yeniséi no fue particularmente exitoso. Sólo un ferrocarril podría ser una solución real a los problemas de transporte de la región.

Los primeros proyectos ferroviarios en Siberia surgieron después de la finalización de la línea ferroviaria San Petersburgo-Moscú en 1851. Uno de los primeros fue el proyecto de Irkutsk-Chitá, propuesto por el empresario estadounidense Perry Collins y apoyado por el ministro de Transporte Constantine Possiet con miras a conectar Moscú hasta el río Amur y, en consecuencia, con el Océano Pacífico. El gobernador de Siberia, Nikolay Muravyov-Amursky, estaba ansioso por avanzar en la colonización del Lejano Oriente ruso, pero sus planes no pudieron materializarse, siempre y cuando los colonos tuvieron que importar cereales y otros alimentos de China y Corea. Fue por iniciativa de Muravyov que se llevaron a cabo encuestas para un ferrocarril en la región de Jabárovsk.

Antes de 1880, el gobierno central ignoró prácticamente estos proyectos, debido a la debilidad de las empresas de Siberia, una burocracia torpe y miedo al riesgo financiero. En 1880, hubo un gran número de solicitudes rechazadas y futuros de autorización para la construcción de vías férreas para conectar Siberia con el Pacífico, pero no el este de Rusia. Esto preocupó al gobierno e hizo que conectase Siberia con Rusia central una preocupación apremiante. El proceso de diseño duró diez años. Junto con la ruta finalmente construida, se propusieron proyectos alternativos: una ruta del sur, a través de Kazajstán, Barnaul, Abakán y Mongolia; y una ruta del norte, a través de Tiumén, Tobolsk, Tomsk, Yeniseysk y la moderna línea Baikal-Amur o incluso a través de Yakutsk.

La línea se divide en siete secciones, sobre la totalidad o la mayor parte de las cuales se trabajó simultáneamente, utilizando una mano de obra de 90 000 hombres. El costo total se estima en 35 millones de libras esterlinas; la primera sección (de Cheliábinsk al río Ob) fue terminado a un costo de 900 000 libras esterlinas menos de lo estimado. Los ferroviarios ofrecieron sugerencias para ahorrar fondos, por ejemplo, mediante la instalación de los transbordadores en lugar de puentes sobre los ríos hasta que el tráfico se incrementó. Los diseñadores insistieron y aseguraron la decisión de construir un ferrocarril ininterrumpido.

A diferencia de los rechazados proyectos privados que pretendían conectar las ciudades existentes y que necesitaban transporte, el Transiberiano no tenía tal prioridad. Por lo tanto, para ahorrar dinero y evitar enfrentamientos con los propietarios de las tierras, se decidió establecer el ferrocarril fuera de las ciudades existentes. Tomsk era la ciudad más grande y la más desafortunada, ya que los bancos pantanosos del río Ob cerca de él fueron considerados inapropiados para un puente. El ferrocarril fue colocado a 70 km al sur (en lugar de cruzar el Ob en Novo Nikolaevsk, más tarde llamado Novosibirsk); y simplemente un ramal sin salida lo conectaba con Tomsk, privando a la ciudad del tráfico ferroviario de tránsito prospectivo y el comercio.



Otros grandes trenes relacionados con el Transiberiano:



</doc>
<doc id="15351" url="https://es.wikipedia.org/wiki?curid=15351" title="Potencial evocado visual">
Potencial evocado visual

Los potenciales evocados visuales (PEV) resultan de los cambios producidos en la actividad bioeléctrica cerebral tras estimulación luminosa. El estímulo más frecuentemente utilizado para obtener PEV, es una imagen en damero (en tablero de ajedrez), con una serie de cuadros blancos y negros, que van alternándose (PEV-pattern). Consigue evocar potenciales grandes y reproducibles. Precisa la colaboración del paciente. 

En pacientes no colaboradores o que no consiguen ver la pantalla con el damero, se utilizan otros estímulos como destellos luminosos. Estos producen respuestas evocadas con gran variabilidad inter-individual, en morfología y latencias, por lo que únicamente sirven para determinar si llega el estímulo luminoso a la corteza cerebral, y para comparar la respuesta de ambos ojos, en busca de asimetrías.
Es la única prueba clínicamente objetiva para valorar el estado funcional del sistema visual. Registra las variaciones de potencial en la corteza occipital provocada por un estímulo sobre la retina. Por esta razón puede evaluar la función retinocortical en niños, retrasados mentales y pacientes afásicos. También puede distinguir entre pacientes con ceguera psicológica y los que la padecen por una causa orgánica. 

Podemos explorar los PEV-pattern por hemicampos, cuando existe sospecha de lesión quiasmática, que suele comenzar por la afectación de las fibras del hemicampo visual externo.

Los potenciales evocados visuales representan una exploración neurofisiológica muy sensible, ya que se alteran en una elevada proporción de pacientes con anomalías visuales, incluso en pacientes con afección subclínica de la vía visual, como ocurre en la esclerosis múltiple. Sin embargo, es una exploración poco específica a la hora de determinar el tipo de patología, ya que cualquier problema que se interponga entre el estímulo y el registro en corteza occipital, puede provocar anomalías en los potenciales visuales siempre que cause suficiente disfunción visual (defecto de corrección óptica, catarata densa, retinopatía, glaucoma, neuropatía óptica, infarto cerebral, etc). Deben, por tanto, evaluarse con precaución y dentro de un contexto clínico. Además, debemos tener en cuenta que lesiones postquiasmáticas con disfunción visual pueden cursar sin anomalías en los PEV.

Otra característica de enorme valor de los potenciales evocados visuales, es que aportan datos cuantificables de latencia y amplitud. Esto nos permite identificar una disfunción en la vía visual, orientando si predominan los fenómenos desmielinizantes, con retraso de los potenciales (aumento de latencia) o si predomina un defecto de activación axonal en la vía visual (reducción de amplitud). Por otro lado, nos permite realizar un seguimiento evolutivo, pudiendo evaluar la posible eficacia de un tratamiento, o la progresión de una enfermedad. 

Cuando los potenciales evocados visuales muestran anomalías en un sólo ojo, podemos deducir que existe patología prequiasmática en ese lado. Si las anomalías son bilaterales, no podemos definir la localización de la lesión, ya que las fibras correspondientes a la retina nasal decusan al lado contralateral en el quiasma.

Los potenciales evocados visuales se realizan situando al paciente frente a una pantalla en la que aparece un tablero de ajedrez con cuadrados blancos y negros con un punto guía en el centro del tablero. Una vez haya comenzado la estimulación dichos cuadrados alternarán rítmicamente según una frecuencia establecida, quedando fijo el punto guía en el centro de la pantalla. 

El paciente será preparado colocándole una serie de electrodos o sensores en la parte posterior de la cabeza, en la región occipital. Dichos sensores se ubican en la línea media occipital, inion, occipital izquierdo y occipital derecho tomando como referencia otro sensor situado en la zona anterior de la cabeza y común a todos los demás. Estos sensores serán los encargados de escuchar las variaciones bioeléctricas que se produzcan por cada estímulo, transmitiéndolos a un aparato que promediará y procesará las señales recogidas.

Una vez preparado el paciente y situado frente a la pantalla se le pedirá que mire fijamente al punto guía, procurando no perderlo de vista ni distraerse con el movimiento alterno de los cuadrados. El paciente deberá permanecer atento y concentrado evitando quedarse dormido.

Una vez comience la prueba los cuadrados de la pantalla comenzarán a cambiar de color de forma alterna provocando una reacción nerviosa que es trasmitida por la retina al nervio óptico y por éste hasta la zona occipital del cerebro donde serán recogidos los cambios que se produzcan por los sensores y llevados al promediador o aparato para su procesamiento.

Generalmente se evocan dos series de cien estímulos por cada ojo quedando tapado el ojo que no es estimulado y utilizando, al menos, dos frecuencias espaciales para el tablero de ajedrez, es decir, una frecuencia baja con cuadrados grandes y en menor número y una frecuencia alta con cuadrados más pequeños y en mayor número.

Se deberá realizar la exploración sin cristales correctores si bien se pueden utilizar éstos para poner de manifiesto posibles defectos de refracción o cuando se sospeche una neuropatía del nervio óptico por esclerosis múltiple.

En el PEV FLASH se utiliza un estroboscopio o flash en lugar de la pantalla con el tablero de ajedrez. Se realiza situando el estroboscopio frente al ojo a estimular y dando las series de destellos luminosos establecidas quedando el otro ojo tapado. La colocación de los sensores o electrodos en el paciente es similar al pev pattern.

Estas pruebas son del todo indoloras e inocuas y no provocan efectos secundarios importantes en los pacientes salvo, en ocasiones, cefaleas, mareos y/o somnolencia.



</doc>
<doc id="15352" url="https://es.wikipedia.org/wiki?curid=15352" title="Electroencefalografía">
Electroencefalografía

La electroencefalografía (EEG) es una exploración neurofisiológica que se basa en el registro de la actividad bioeléctrica cerebral en condiciones basales de reposo, en vigilia o sueño, y durante diversas activaciones (habitualmente hiperpnea y estimulación luminosa intermitente) mediante un equipo de electroencefalografia (producto sanitario).

Richard Birmick Caton (1842-1926), médico de Liverpool (Reino Unido), presentó en 1875 sus hallazgos sobre los fenómenos bioeléctricos en los hemisferios cerebrales de ratones y monos, expuestos por craniectomía.
En 1912 Vladimir Vladimirovich Pravdich-Neminsky publicó el primer EEG y potenciales evocados de perros.
Hans Berger (1873-1941) comenzó sus estudios sobre electroencefalografía en humanos en 1920.

Actividad de fondo
Métodos de activación

Grafoelementos específicos del sueño

Fases del sueño
"Estadiaje de Rechtschaffen y Kales"


"En términos generales:"

En la ciencia ficción comienzan a aparecer obras literarias centradas en la codificación neuronal y en las inmensas posibilidades con las que jugar si llegara el ser humano a ser capaz de descifrar las comunicaciones cerebrales.

La novela "El Código Sináptico" de José Luis Peñalver, publicada en marzo de 2014, abraza esta temática: un equipo de científicos investiga los impulsos motores del cerebro humano, analizando en detalle los resultados de baterías de pruebas de electroencefalografía, con la ayuda de potentes herramientas informáticas y criptográficas. El objetivo es diseñar una prótesis robótica para un paciente que ha perdido un brazo: el robot deberá decodificar las señales eléctricas provenientes de la corteza motora humana, entenderlas y moverse tal y como la persona desea, ejecutando la acción mecánica de manera similar a como lo hubiera hecho el miembro natural.

En la misma línea, la novela "77 grados Kelvin" del mismo autor y mayor éxito, utiliza la criónica como puerta de entrada a un tiempo futuro en donde el protagonista descubre que se han decodificado las percepciones eléctricas sensoriales. Un pequeño implante cerebral es capaz de entender y manipular los impulsos eléctricos que van desde los ojos o los oídos a las áreas del cerebro correspondientes. Así, las personas pueden disfrutar de contenido informático superpuesto en la visión natural, o recibir sonido directamente de la red. A su vez, lo que perciben los ojos o los oídos se puede descifrar y volcar al chip en un formato estándar de vídeo o audio, o bien compartirlo por la red. Las aplicaciones que han invadido el mercado son revolucionarias y asombrosas en el campo de la comunicación o el entretenimiento, pero no sin riesgos.




</doc>
<doc id="15353" url="https://es.wikipedia.org/wiki?curid=15353" title="Superhéroe">
Superhéroe

Un superhéroe es un personaje de ficción pues sus características superan las del héroe clásico, generalmente con poderes sobrehumanos aunque no necesariamente, y entroncado con la ciencia ficción. Generados a finales de los años 1930 en la industria del "comic book" estadounidense, que contribuyeron a levantar,han gozado de multitud de adaptaciones a otros medios, especialmente el cine. 

La historia del género puede ser dividida en las siguientes "eras" o "edades":

Desde finales de los años 1920, el concepto se estaba incubando en las series de aventuras de grafismo realista y las "pulp magazines". Lee Falk sería el guionista de "The Phantom" (1936), que puede considerarse un precursor estético del género, cuando no su pionero.Tradicionalmente se considera, sin embargo, que el primer superhéroe de la historia fue "Superman" (1938), cuyo éxito fue enorme y generó un sinfín de imitaciones que sostuvieron la industria del "comic book" durante años. Pero es imprescindible observar que, antes que los estadounidenses The Phantom y Superman, en Argentina surge "Patoruzú" (1928) y en Japón, "Fantasmagórico" (1930 o 1931), personaje este último que anticipa características obvias (apariencia espectral así como la habilidad para volar) que luego se asocian con The Phantom, Superman y Batman. Hay que recordar que Fantasmagórico es el nombre castellano del héroe japonés; su nombre original es "Ōgon Bat"; "el Murciélago Dorado".

Después de Patoruzú, Fantasmagórico, The Phantom, Superman, nacen personajes como "Namor" en abril de 1939 y Batman en mayo de 1939, y al año siguiente la Antorcha Humana, Flash o Linterna Verde. Como señala Oscar Masotta, "no es casual que el período que va desde el "crack" del 29, pasando por los años de la guerra civil española, hasta el comienzo de la segunda guerra mundial, coincida con la aparición de Superman, Batman o Capitán Marvel".

Las primeras historias de superhéroes contenían esquemas narrativos muy parecidos a los de las más recientes tiras de aventuras: historia entre la realidad y la ficción, en forma de serie continua, basada en un protagonista carismático con doble identidad, máscara o disfraz y otros complementos. Bien visto, lo único que añadieron algunos superhéroes fueron los superpoderes, pero desde el punto de vista industrial acabarían revolucionando el mercado.

Igual que las historietas japonesas coetáneas, pronto se dejarán imbuir del espíritu bélico de la segunda guerra mundial, presentando en muchas ocasiones nombres o uniformes relacionados con sus símbolos nacionales y enfrentándose a los enemigos del país. Es el caso de The Shield de MLJ Magazines y Uncle Sam de Quality Comics, que surgieron en 1940, y la "Mujer Maravilla" de William Moulton Marston y el "Capitán América" de Joe Simon y Jack Kirby, ambos de 1941. Gracias al marco histórico en el que nacieron lograron un gran éxito comercial, pero al finalizar la guerra fueron cayendo en el olvido. Muy diferente es el renovador "The Spirit" (1940) de Will Eisner.

En Italia, Vincenzo Baggioli y Carlo Cossio crean en 1938 a "Dick Fulmine", un superhéroe autóctono, aunque carecía de poderes.

Tras la segunda guerra mundial, el éxito de las historietas de superhéroes empezó a disminuir, fueron sustituidas por todo tipo de géneros como la serie negra, historietas infantiles, románticas, de monstruos, westerns, etc. Por si esto fuera poco, el psiquiatra Fredric Wertham (en su obra "La seducción del inocente") afirmaba a finales de los años 1950 que los superhéroes creaban una distorsión de la realidad. Citaba, entre otros ejemplos, que el hecho de que Superman pudiera volar generaba falsas esperanzas, que Batman y Robin tenían una relación pedófila y que la Mujer Maravilla no podía estar como igual en un grupo de hombres como la Liga de la Justicia. Además afirmaba que todos estos ejemplos eran una mezcla volátil que daba como resultado conductas agresivas así como el desencadenamiento de la violencia juvenil.

Todo eso cambió en 1961 cuando, siguiendo la estela de la Liga de la Justicia de DC, la editorial Marvel Comics decidió crear su propio grupo de superhéroes y se lo encargó al editor y guionista Stan Lee, que trabajó con varios dibujantes.

El primer número de Los 4 Fantásticos, obra de Lee y del dibujante Jack Kirby, apareció en noviembre de 1961, y la humanidad de los personajes, sumada a la combinación de elementos de otros géneros mucho más comerciales de la época, catapultó a la serie en las listas de ventas. Azuzados por este éxito, Stan Lee, Jack Kirby y Steve Ditko se lanzaron a la creación de una gran cantidad de personajes: "Hulk", "Thor", "Spider-Man", "Daredevil" o "X-Men", todos ellos superhéroes con problemas de diferente índole (de salud, de aceptación social, económicos, etc.).

Uno de los méritos de Stan Lee es la humanización de los personajes, así como el hecho de convertir en héroes a personas con problemas. Spider-Man es un joven del que abusan sus compañeros de clase, en parte porque es impopular; Daredevil es ciego; Thor, cuando es humano, es cojo; Iron Man es un enfermo del corazón; los X-Men en sus orígenes eran jóvenes marginados, etc. En cierta medida, este universo de superhéroes es un reflejo de los cambios profundos que comenzaba a vivir E.E.U.U. con las luchas por los derechos civiles".

Las relaciones de tipo humano entre los superhéroes pasaron a ser más importantes, pudiendo haber enfrentamientos, o por lo menos retos, entre los buenos, como sucede entre la Antorcha Humana y Spider-Man. También hay que destacar que estos superhéroes procuran no matar cuando actúan y que sus motivaciones son principios de justicia abstractos, no venganzas personales.

En otras editoriales estadounidenses aparecieron Mr. A y The Question (1967). En Reino Unido había emergido Zarpa de Acero cinco años antes. Finalmente, en la España de Franco se prohibieron en 1964 estas series estadounidenses ""porque los poderes de estos personajes les acercaban más a dioses que a héroes.""

Las historietas de superhéroes no sólo presentaban las angustias personales de sus protagonistas, sino que empezaron a reflejar los asuntos de candente actualidad. Es el caso de la reunión de Linterna Verde y Flecha Verde que Dennis O'Neil y Neal Adams realizaron en 1970. Jack Kirby, en cambio, opta por todo lo contrario, y crea las series de "El Cuarto Mundo".

La revista británica "2000 AD" (1977) será el caldo de cultivo de toda una hornada de nuevos autores británicos que a partir de 1982 vendrían a revitalizar el comic-book de superhéroes estadounidense con obras como "Watchmen" (1986), de Alan Moore/Dave Gibbons, junto a nativos como Frank Miller. La primera mostraba un futuro más negro y realista de la forma en que interactuarían los ciudadanos normales con respecto a las consecuencias de las acciones de los héroes que se suponía debían protegerlos. Destacaba la humanidad en ellos como imperfecciones y problemas sociales de sus alter ego, lo que permitía verlos como personas con dificultades normales. Trabajos como The Dark Knight Returns, de Frank Miller, en el caso de Batman, denotaron un ambiente más adulto para la historieta de superhéroes. También hay que destacar eventos como Crisis en Tierras Infinitas, que fueron la antesala a un proceso evolutivo dentro de la historieta de superhéroes.

Los artistas que fundaron Image Comics en 1992 crearon nuevas series como "Spawn" o "The Maxx".

Actualmente, el género se ha revitalizado, apareciendo nuevos autores (Mark Millar, Brian Bendis, Michael Straczynski) y recuperando a otros (Chris Claremont, Kurt Busiek, Alan Davis). Así, los superhéroes constituyen la mayor parte de la industria del cómic en los Estados Unidos.

Además, los superhéroes han sido objeto de innumerables adaptaciones cinematográficas y televisivas, facilitadas últimamente por la mejora de los efectos especiales debida a la tecnología digital. Podemos destacar películas clásicas como "" (1978), de Richard Donner, "Batman" (1989) y "Batman Returns" (1992), ambas de Tim Burton. El éxito de películas como Blade (1998), X-Men o Spiderman (2002) ha motivado la aparición de una multitud de proyectos cinematográficos y televisivos protagonizados por superhéroes tan dispares como Daredevil, Catwoman, Hellboy o Hulk.

Como género puede considerarse el trasunto moderno de "varios estilos ancestralmente populares: los relatos mitológicos, los cuentos guerreros y las sagas familiares"con la diferencia de que el elemento religioso ha sido sustituido por la ciencia ficción.

Otras características típicas de los superhéroes son:

En 1940 ya existían parodias del género como Super Ratón (un personaje de cómic llamado "Super Mouse", y un personaje de dibujos animados llamado "Mighty Mouse").

Al ir estableciéndose los estereotipos de superhéroes, creadores de muchos campos tomaron elementos de este subgénero y lo combinaron con su propia obra. Por ejemplo, en 1969, la editorial Mondadori, responsable de las historietas de personajes Disney, dotó al pato Donald de otra identidad como "Paperinik" (en español Patomas o Superpato), influido por superhéroes como Batman y por otros personajes de ficción. Patomas actuaba a veces como un superhéroe y otras como un supervillano. Goofy también ha sido dotado de una identidad como superhéroe (Supergoofy o Supertribi), adquiriendo superpoderes semejantes a los de Superman o Marvelman al comer un tipo especial de cacahuetes.

En España, Antonio Ayné creó "El conejito atómico" en 1953 para la revista infantil "Yumbo" y seis años más tarde, el Pumby de José Sanchis se transformaba en el superhéroe de Villa Rabitos en su propia revista, "Super Pumby". En este caso, los poderes aparecían gracias al consumo de zumo de naranja (Sanchis es valenciano). Podríamos decir que más tarde o más temprano, muchos personajes han pagado su tributo a este subgénero del cómic, adquiriendo por un tiempo superpoderes (como en el cómic de Mortadelo y Filemón "Los superpoderes"). Es posible afirmar siguiendo la misma línea de razonamiento que tal conversión (aunque sea momentánea) es el resultado de la maduración de un personaje: el autor prueba con ese escenario como uno más.

En 1966 aparece la serie televisiva Batman, la cual era al mismo tiempo una serie de entretenimiento y una parodia (en estilo del teatro del absurdo) al género superheroico. Tras el éxito de esta serie (un éxito conocido como la batmanía) se masificaron definitivamente las parodias en distintos segmentos mediáticos.

Un ejemplo a nivel de esta sucesión de parodias superheroicas, en animación fue la serie Batfink de fines de los años 1960, y una de las más famosas con actores fue la realizada a principios de la década de 1970 por el mexicano Roberto Gómez Bolaños "Chespirito", llamada El Chapulín Colorado; héroe torpe, cobarde y jactancioso cuya mayor característica era su gran corazón y bondad. En la misma serie mexicana también destacó un personaje secundario llamado "SuperSam", interpretado por el actor Ramón Valdés, que parodiaba a un héroe basado en el ideal de vida estadounidense.

Las mismas editoriales que han desarrollado el cómic de superhéroes también se han dado cuenta de los aspectos absurdos y tópicos que se repiten y han publicado cómics que ridiculizan las convenciones del género. Por ejemplo, Marvel editó What the...?, serie que presentaba en cada número varias historietas paródicas cortas creadas por los mismos autores que creaban los cómics "serios" de superhéroes. Sergio Aragonés ha realizado trabajos de este tipo tanto para Marvel como para DC.

En 1973, el dibujante Jan creó a "Superlópez", que en esencia es una parodia de Superman, para la Editorial Bruguera, que lo incluía en su línea de historietas cómicas. Superlópez es el superhéroe español más leído y ya se han publicado más de 40 álbumes. En los 1990, Jan creó a "Superioribus", para Comics Forum, la editorial que publicaba las traducciones de Marvel en España. Las parodias de Superioribus eran historietas de una página que se incluían en las revistas de superhéroes "serios".

Cels Piñol también vio publicadas sus historietas paródicas breves de Fan letal en los cómics Forum, como complemento a las historietas "serias". Posteriormente ha publicado otras parodias de superhéroes y ciencia-ficción, como Fanhunter, en álbumes completos.

Por último, desde la década de 1990 y hasta la actualidad, en canales televisivos privados de animación como Cartoon Network se han vuelto frecuentes y muy populares las parodias superheroicas con personajes antiguos como el "Fantasma del Espacio" (en Fantasma del Espacio de costa a costa), "Los Superamigos" o "Fabulman y Dinamita" (en cortos con tono de comedia), o el nuevo "Capitanazo" (en "La Casa de los Dibujos").

En Estados Unidos, la palabra "Super Hero" ("superhéroe", en inglés) es una marca registrada de forma conjunta por DC Comics y Marvel Comics, por lo que sólo ellas pueden utilizarla legalmente en sus productos y campañas comerciales. .

Al parecer, ambas editoriales solicitaron la concesión de la marca registrada en 1979, siéndoles concedida en 1981 al no haber ninguna reclamación al respecto. Según la propia solicitud original, la palabra llevaba utilizándose comercialmente al menos desde 1966.

Al tratarse de una marca registrada, y no un copyright, esto no impediría el calificar como "superhéroe" a un personaje de otra editorial en el interior de sus historias. Pero, en la práctica, muchas otras editoriales estadounidenses evitan el uso de la palabra, utilizando en su lugar términos como "metahumano" o "mutante".

DC y Marvel han demandado en el pasado a otras empresas, o amenazado con hacerlo, por utilizar sin permiso la palabra "super hero" en sus productos; algunos ejemplos son el "Gunstar Super Heroes" de Sega o el cómic "Super Hero Happy Hour" de Dan Taylor.


 y para superheroína.


</doc>
<doc id="15354" url="https://es.wikipedia.org/wiki?curid=15354" title="Space opera">
Space opera

La space opera, ópera espacial u opereta espacial es un subgénero de la ciencia ficción donde se relatan historias acerca de aventuras tratadas de forma futurista, tecnológica y en ocasiones romántica y que en la mayor parte de los casos tienen lugar en el espacio. Se puede considerar la "space opera" como la continuación natural de las novelas de aventuras sobre escenarios propios de la ciencia ficción. Los personajes suelen pertenecer al arquetipo héroe-villano, y los argumentos típicos tratan sobre viajes estelares, batallas, imperios galácticos, exhibiendo vistosos logros tecnológicos.

El escritor Wilson Tucker utilizó por primera vez el término "space opera" de forma peyorativa en 1941 para referirse a lo que él percibía como vicios y clichés de la ciencia ficción de su tiempo, haciendo alusión al género de las soap operas, programas de radio dramatizados populares en Estados Unidos en aquel momento. Estas mismas se llamaban así en relación a las marcas de jabón ("soap" en inglés) que solían patrocinarlas, y a las "horse operas", como se había empezado a denominar a los western. De hecho algunos críticos y fans han hecho notar que muchas tramas utilizadas en space operas son una traducción directa de las historias del oeste al contexto del espacio exterior, como parodiaba la famosa portada trasera del primer número de "Galaxy Science Fiction". Antes de que este término se popularizara, las historias publicadas en revistas de ciencia ficción a finales de los años 20 y principios de los 30 a menudo se denominaban "super-science epics" ("super-ciencia épica").

Como hacen notar David G. Hartwell y Kathryn Cramer en su antología de space operas "The Space Opera Renaissance" (2006), "no hay consenso sobre lo que es la space opera, qué autores son un mejor ejemplo de ella o incluso qué trabajos quedarían englobados en ella". Más aún, los autores resaltan que la space opera ha tenido diferentes claves y definiciones a lo largo de su historia, que se han visto afectadas por la política literaria del momento. Lo que ahora se conoce como space opera es lo que solía ser llamado "fantasía científica", mientras que aquello a lo que originalmente se conocía con el término ha dejado de existir.

En su forma más familiar, el género es un producto de las revistas pulp de los años 1920-1940. La ciencia ficción en general tomó del género pulp y de aventuras, el western e historias en emplazamientos exóticos como Oriente o África, y la space opera no es una excepción. Existen numerosos paralelismos entre las naves tradicionales y las espaciales, entre los exploradores de la época colonialista y los exploradores del espacio, entre los piratas marítimos y los piratas espaciales, etc. La space opera clásica es una transposición de los viejos temas de los libros de vaqueros, o "westerns" a la ciencia ficción, reemplazando el revólver Colt por la pistola láser, el caballo por la nave espacial, la fiebre del oro por los mineros de los asteroides, etcétera. El mayor auge del subgénero se dio durante la edad de oro de la ciencia ficción, en la década de 1940. En cierto modo, fue la space opera la que le dio mala fama a la ciencia ficción, debido a que la mayor parte de sus exponentes tenía una baja calidad literaria. 

Una novela muy temprana de proto-ciencia ficción podría ser también considerada la primera space opera. Se trata de "Edison's Conquest of Mars" de Garrett P. Serviss, publicada en 1898, qué aunque precede el término space opera contiene todos los clichés que caracterizan al género: naves espaciales, viaje a otros planetas, coches voladores, batallas contra malvados alienígenas, armas militares de gran potencia destructiva, doncellas en apuros, e incluso una primera aparición del "rayo desintegrador". 

El prototipo de space opera "pulp" es la novela de E. E. Smith "The Skylark of Space" (publicada por primera vez en "Amazing Stories" en 1928), en la que un científico construye una nave espacial y viaja con una compañera femenina en busca de civilizaciones alienígenas y a luchar contra un poderoso archienemigo. La serie más tardía de Smith, Lensman, y el trabajo de Edmond Hamilton y Jack Williamson en los 1930 y 1940 fueron muy populares entre los lectores y muy imitados por otros escritores. Fueron estos imitadores los que inspiraron a Tucker y otros fanes a usar la etiqueta para denominar a esta producción. 

La space opera entró en decadencia después de que la ciencia ficción abandonara la fijación en la aventura y en la tecnología para adentrarse en el estudio de las sociedades futuras, a partir de la "nueva ola", en la década de 1960. Con el tiempo, el análisis de los mejores ejemplos del género ha llevado a una revaluación del término y a una resurrección de la space opera. Escritores como Poul Anderson y Gordon R. Dickson han mantenido el género de aventura espacial de grandes dimensiones vivo durante los 50, seguidos por -entre otros muchos - M. John Harrison y C. J. Cherryh en los 70 y Iain M. Banks, Lois McMaster Bujold, y Paul J. McAuley en los 80. Pasada la borrachera de la "nueva ola", la literatura de ciencia ficción comenzó a regresar a los viejos temas (salvo por el cyberpunk), aunque con una mirada más madura. Con el tiempo el término space opera ha dejado de tener esa connotación negativa para pasar a definir un tipo de novela concreto, aunque el subgénero sigue siendo percibido como un estereotipo de la ciencia ficción.

En el terreno cinematográfico, el final de la edad dorada de la space opera lo marcó la película "", mientras que "Star Wars hizo volver con gloria y majestad al género, que desde entonces sigue teniendo éxitos.

Series de ciencia ficción de gran popularidad como Star Trek, Babylon 5, Lexx y Stargate son en general clasificadas como Space Operas siendo la exploración espacial, las guerras entre imperios galácticos y las aventuras a raíz del contacto entre civilizaciones el tema central.

Las historias suelen estar situadas en el espacio exterior o en un planeta ficticio. Para evitar que la historia se torne aburrida, los personajes de estas historias casi siempre son capaces de viajar distancias ilimitadas en relativamente muy poco tiempo, y sus naves no se ven afectadas por complicaciones como la necesidad de desacelerar antes de detener un vehículo que ha viajado a velocidades mucho mayores a la de la luz, o la necesidad de una fuente de poder capaz de proporcionar energía a una nave que puede desarrollar tales velocidades (aparte de la energía necesaria para otras funciones características de esas naves, como un sistema de armamento). Los planetas que aparecen en historias de ópera espacial a menudo son capaces de sostener el funcionamiento del organismo humano, y están poblados por seres exóticos. Es común encontrar civilizaciones alienígenas similares a algunas civilizaciones antiguas de la Tierra, como la civilización egipcia, griega o vikinga, pero adornadas con algunos rasgos futuristas. Estas civilizaciones extraterrestres casi siempre están formadas por seres antropomórficos o por humanos de aspecto extraño, que son capaces de hablar el idioma de los protagonistas. Algunos dispositivos típicos encontrados en estas historias son las pistolas de rayos, los vehículos voladores o naves para un tripulante, así como androides.



</doc>
<doc id="15355" url="https://es.wikipedia.org/wiki?curid=15355" title="Detección precoz">
Detección precoz

En medicina un programa de detección precoz es un programa epidemiológico de salud pública, de aplicación sistemática o universal, para detectar en una población determinada y asintomática, una enfermedad grave, con el objetivo de disminuir la tasa de mortalidad asociada.


La prevención secundaria se basa en los cribados poblacionales y para aplicar éstos, han de cumplirse unas condiciones predeterminadas definidas en 1975 por Frame y Carslon para justificar el "screening" de una patología que son:




</doc>
<doc id="15356" url="https://es.wikipedia.org/wiki?curid=15356" title="Ferrocarril">
Ferrocarril

El ferrocarril (del latín: "ferrum", ‘hierro’, y carril) o transporte ferroviario es un sistema de transporte de personas y mercancías guiado sobre una via férrea. 

Aunque normalmente se entiende que los carriles o rieles son de acero o hierro, que hacen el camino o vía férrea sobre la cual circulan los trenes, dentro de esta clasificación se incluyen medios de transporte que emplean otros tipos de guiado, tales como los trenes de levitación magnética.

Se trata de un transporte con ventajas comparativas en ciertos aspectos, tales como el consumo de combustible por tonelada/kilómetro transportada, la entidad del impacto ambiental que causa o la posibilidad de realizar transportes masivos, que hacen relevante su uso en el mundo moderno.

 

La primera noticia de un sistema de transporte sobre carriles fue una línea de 3 kilómetros que seguía el camino Diolkos, que se utilizaba para transportar botes sobre plataformas a lo largo del istmo de Corinto durante el siglo VI a. C. Las plataformas eran empujadas por esclavos y se guiaban por hendiduras excavadas sobre la piedra. La línea se mantuvo funcionando durante 600 años.

Los transportes sobre carriles comenzaron a reaparecer en Europa tras la Alta Edad Media. La primera noticia sobre un transporte de este tipo en el continente europeo en este periodo aparece en una vidriera en la catedral de Friburgo de Brisgovia en torno a 1350. En 1515, el cardenal Matthäus Lang describió un funicular en el castillo de Hohensalzburg (Austria) llamado «Reisszug». La línea utilizaba carriles de madera y se accionaba mediante una cuerda de cáñamo movida por fuerza humana o animal. La línea continúa funcionando actualmente, aunque completamente sustituida por material moderno, siendo una de las líneas más antiguas que aún están en servicio.

A partir de 1550, las líneas de vía estrecha con carriles de madera empezaron a generalizarse en las minas europeas. Durante el siglo XVII las vagonetas de madera trasladaban el mineral desde el interior de las minas hasta canales donde se trasbordaba la carga al transporte fluvial o a carros. La evolución de estos sistemas llevó a la aparición del primer tranvía permanente en 1810, el «Leiper Railroad» en Pensilvania.

El primer ferrocarril propiamente tal (esto es, con carriles de hierro) tenia raíles formados por un cuerpo de madera recubierto por una chapa, y fue fabricado en 1768. Esto permitió la elaboración de aparatos de vía más complejos. En un principio solo existían lazos de final de línea para invertir las composiciones, pero pronto aparecieron los cambios de agujas. A partir de 1790 se utilizaron los primeros carriles completamente de acero en Reino Unido. En 1803, William Jessop inauguró la línea «Surrey Iron Railway» al sur de Londres, siendo el primer ferrocarril público de tracción de sangre (tirado por caballos). La invención del hierro forjado en 1820 permitió superar los problemas de los primeros carriles de hierro, que eran frágiles y cortos, aumentando su longitud a 15 metros. En 1857 comenzaron a fabricarse carriles de acero definitivamente.

El desarrollo del motor de vapor impulsó la idea de crear locomotoras de vapor que pudieran arrastrar trenes por líneas. La primera fue patentada por James Watt en 1769 y revisada en 1782, pero los motores eran demasiado pesados y generaban poca presión como para ser empleados en locomotoras. En 1804, utilizando un motor de alta precisión, Richard Trevithick presentó la primera locomotora capaz de arrastrar un tren en Merthyr Tydfil (Reino Unido). Realizada junto a Andrew Vivian, la prueba tuvo un éxito relativo, ya que la locomotora rompió los frágiles railes de chapa de hierro.

En 1811, John Blenkinsop diseñó la primera locomotora funcional que se presentó en la línea entre Middleton y Leeds. La locomotora, denominada "Salamanca", se construyó en 1812. En 1825, George Stephenson construyó la "Locomotion" para la línea entre Stockton y Darlington, al noreste de Inglaterra, que fue la primera locomotora de vapor que arrastró trenes de transporte público. En 1829 también construyó la locomotora "The Rocket". El éxito de estas locomotoras llevó a Stephenson a crear la primera compañía constructora de locomotoras de vapor que fueron utilizadas en las líneas de Europa y Estados Unidos.

En 1830 se inauguró la primera línea de ferrocarril interurbano, la línea entre Liverpool y Mánchester. La vía utilizada era del mismo tipo que otras anteriores, como la del ferrocarril entre Stockton y Darlington. Su ancho era de 1.435 mm, actualmente conocido como ancho internacional ya que es utilizado por aproximadamente el 60% de los ferrocarriles actuales. El mismo año se inauguró el primer tramo de la línea entre Baltimore y Ohio, la primera en unir líneas individuales en una red.

En los años siguientes, el éxito de las locomotoras de vapor hizo que las líneas de ferrocarril y las locomotoras se extendieran por todo el mundo.

Las primeras pruebas con trenes eléctricos las inició Rober Davidson en 1838, cuando construyó un carruaje equipado por baterías capaz de alcanzar 6,4 km/h. El primer ferrocarril con suministro eléctrico en la vía fue el tranvía que circulaba en 1883 entre Portrush y Giant's Causeway, al norte de Irlanda, que utilizaba alimentación por un tercer carril. Los cables de alimentación a ferrocarriles se introdujeron en 1879, por Siemens en Berlín, en tranvías que hasta entonces eran arrastrados por mulas o caballos.

La primera línea de ferrocarril convencional electríficada fue la línea Roslag en Suecia. En la década de 1890 algunas grandes ciudades, como Londres, París y México, utilizaron esta nueva técnica para construir líneas de metro urbanas. En ciudades medias, los tranvías se hicieron algo común y fueron el único medio de transporte público durante varias décadas. Todas estas líneas utilizaron corriente continua, y la primera línea que utilizó corriente alterna fue inaugurada en Austria en 1904.

Las locomotoras de vapor necesitan un mantenimiento bastante elevado para funcionar. Tras la Segunda Guerra Mundial, los costes de personal se incrementaron de modo muy importante, lo que hizo que la tracción a vapor se encareciera sobre el resto. Al mismo tiempo, la guerra impulsó el desarrollo de los motores de combustión interna, que hicieron a las locomotoras diésel más baratas y potentes. Esto causó que varias compañías ferroviarias iniciaran programas para convertir todas sus locomotoras para líneas no electrificadas en locomotoras diésel.

Como consecuencia de la construcción a gran escala de autovías tras la guerra, el transporte por ferrocarril se hizo menos popular, y el transporte aéreo comenzó a ocupar el mercado de los viajes de muy larga distancia. Muchos tranvías fueron sustituidos por autobuses, mientras que la necesidad de trasbordos hizo poco rentable el traslado de mercancías en distancias medias. Además, sucesos como el Gran escándalo del tranvía de Estados Unidos hicieron que el transporte por ferrocarril se redujera considerablemente.

La crisis del petróleo de 1973 cambió la tendencia a la baja de los tranvías. Hizo que los que no se habían desmantelado, continúasen hasta nuestros días, al ser de nuevo más rentables. También la introducción de los contenedores contribuyó a mejorar la rentabilidad del transporte de mercancías por ferrocarril.

El primer tren comercial de alta velocidad fue inaugurado en 1939 en Italia con el ElettroTreno ETR 200, alcanzando el para entonces récord mundial de 204 km/h, cerca de Milán.

Actualmente se considera de Alta Velocidad el ferrocarril que supera los 250 km/h de media. En este sentido, en 1964, se inauguró en Japón la primera línea de Alta velocidad ferroviaria, llamado Shinkansen, "tren bala", para resolver el problema de transporte entre las pobladas ciudades del país. Con el tiempo, este sistema se extendió por otros países, como Francia, España y Alemania, lo que hizo recuperar al viajero interurbano.

A lo largo de los años 70, se introdujo una automatización mayor, especialmente en el transporte interurbano, reduciendo los costes de operación. Algunas líneas de tranvía fueron transformadas en líneas de tren ligero, otras líneas se construyeron en ciudades que habían eliminado el tranvía décadas atrás. En los años 90, el foco de atención se situó en mejorar la accesibilidad, convirtiendo el tren en la solución al transporte de los discapacitados.

La innovación en nuevos sistemas de ferrocarril continúan actualmente, especialmente en campos como la alta velocidad.

El material rodante está constituido por todos los equipos que circulan (ruedan) a lo largo de las vías del ferrocarril. Se dividen en dos grupos: el material de tracción, las locomotoras, y el material o equipos de arrastre, que son todos los que la locomotora arrastra o empuja acoplados a ella, sobre las vías. Al conjunto de equipos rodantes unidos entre sí que arrastra o empuja la locomotora, o están en la vía en espera de serlo, se denomina composición o formación. Al conjunto de la locomotora con la composición se conoce como tren. Según el tipo de servicio que prestan, los trenes se llaman: de carga, de pasajeros, de servicios, de obras o mixtos.

A su vez se puede realizar una división por estos tipos de vehículos entre: locomotoras, coches de viajeros, vagones, automotores y unidades de tren.

Serie de vagones enganchados a una locomotora. También los vagones puede llevar mercancías o pasajeros, lo cual significa que hay dos tipos de tren. Una variante más reciente es el tren autopropulsado, en el que los vagones, todos, o algunos, tienen motores en sus ruedas, sin llevar una locomotora propiamente dicha.


La infraestructura ferroviaria incluye todas las instalaciones y edificaciones necesarias para el funcionamiento del ferrocarril: estaciones, vías, puentes y túneles, sistema de señales y comunicaciones, infraestructura de bloqueo de trenes y guiado, agujas, etc.

También hay tramos de vías cuádruples. En estas los recorridos centrales son para el transporte de mercancías y las laterales o externos, para el transporte de pasajeros ya que los andenes exteriores permiten mejor acceso. Una variante es aquella en que las vías centrales se reservan a ferrocarriles de larga distancia (más rápidos, con menos paradas) y las laterales a viajes de cercanías.

Se llama ancho de vía o trocha a la distancia entre la cabeza (u hongo) interna plana de ambos rieles por los que circulan lo trenes.

La regulación del tráfico ferroviario se realiza mediante señales, estas pueden ser fijas o móviles, manuales, mecánicas o eléctricas.

Una estación ferroviaria o estación de ferrocarril es el punto de acceso de viajeros y mercancías al ferrocarril.

Se denomina explotación ferroviaria al conjunto de técnicas, medios y modos que garantizan la circulación de trenes con seguridad y fluidez, y que encamina cada tren hacia su destino según el horario establecido.

Se denomina electrificación un sistema de alimentación de tracción por el cual la energía eléctrica alimenta las unidades de tracción ferroviaria.

El ferrocarril forma parte de una amplia gama de transporte terrestre en todo el mundo, ya sea marítimo y aéreo que, en su conjunto, permite y realiza el transporte de personas y mercancías del lugar donde se encuentran al lugar donde quieren ir o donde son necesarias. En la actualidad se emplea una conjunción de medios (marítimos, carreteros, ferroviarios, etc.) actuando coordinadamente para este fin.


Sentido de la circulación en las dobles vías de diversos países.









Se circula en parte por la derecha y en parte por la izquierda en:







</doc>
<doc id="15360" url="https://es.wikipedia.org/wiki?curid=15360" title="Cíborg">
Cíborg

Un cíborg o cyborg (del acrónimo en inglés "cyborg": de cyber [‘cibernético’] y organism [‘organismo’], ‘organismo cibernético’) es una criatura compuesta de elementos orgánicos y dispositivos cibernéticos generalmente con la intención de mejorar las capacidades de la parte orgánica mediante el uso de tecnología.

El término fue acuñado por Manfred E. Clynes y Nathan S. Kline en 1960 para referirse a un ser humano mejorado que podría sobrevivir en entornos extraterrestres. Llegaron a esa idea después de pensar sobre la necesidad de una relación más íntima entre los humanos y las máquinas en un momento en que empezaba a trazarse la nueva frontera representada por la exploración del espacio. Diseñador de instrumentación fisiológica y de sistemas de procesamiento de datos, Clynes era el director científico del Laboratorio de simulación dinámica de Rockland State Hospital, en Nueva York. El término apareció por primera vez en forma impresa, 5 meses antes, cuando The New York Times reportó sobre los aspectos psicofisiológicos del Espacio Simposio de vuelo donde Clynes y Kline presentaron por primera vez su papel: “Un cyborg es esencialmente un sistema hombre-máquina en el cual los mecanismos de control de la porción humana son modificados externamente por medicamentos o dispositivos de regulación para que el ser pueda vivir en un entorno diferente al normal”.

De acuerdo con algunas definiciones del término, la conexión física y metafísica de la humanidad con la tecnología, ya ha empezado a influir en la evolución futura del ser humano, al empezar a convertirnos en cíborgs. Por ejemplo, una persona a la que se le haya implantado un marcapasos podría considerarse un cíborg, puesto que sería incapaz de sobrevivir sin ese componente mecánico. Otras tecnologías médicas, como el implante coclear, que permite que un sordo oiga a través de un micrófono externo conectado a su nervio auditivo, también hacen que sus usuarios adquieran acceso a un sentido gracias a la tecnología, aproximando su experiencia a la de un cíborg. 

A finales del siglo XX,la imagen del cíborg como ser que no es ni humano ni máquina, ni hombre ni mujer, fue recuperado por autoras ciberfeministas, como Donna Haraway en su "Manifiesto Ciborg".

El término se suele utilizar erróneamente en numerosos escritos al confundirlo con robot del tipo androide.

El concepto del híbrido hombre-máquina fue y es generalizado en la ciencia ficción antes de que ocurriera la Segunda Guerra Mundial. En “The Man That Was Used Up” (1839), Edgar Allan Poe, por ejemplo, describe a John A. B. C. Smith, un héroe de guerra con un cuerpo compuesto de múltiples prótesis. En 1910, el escritor francés Jean de la Hire presenta a "Nyctalope" (para algunos el primer superhéroe y también el primer cíborg literario) en la novela "L'homme qui peut vivre dans l'eau" (El hombre que puede vivir en el agua). Por su parte, en “The Comet Doom” (1928), el estadounidense Edmon Hamilton describe exploradores espaciales cuyos cuerpos combinan partes orgánicas y mecánicas. Este mismo autor es conocido por el peculiar cerebro viviente y parlante, siempre flotando en un receptáculo transparente, que acompaña al superhéroe "Capitán Futuro" (1939). Hamilton utiliza el término de forma explícita en el cuento "After a Judgmente Day" (1962) para referirse a los "las copias mecánicas de humanos" llamadas "Charlies" explicando que "cíborgs es como se les había llamado, desde el primero [el primer Charlie] a inicios de la década de 1960...organismos cibernéticos".

Traducido de , exactamente la versión https://en.wikipedia.org/wiki/Cyborg, bajo licencia GFDL y CC-BY-SA 3.0

Debido a avances en TI (tecnologías de la información), inversionistas humanos han sido capaces de emplear computadoras para participar en operaciones a una mayor velocidad a través de fronteras nunca antes vistas. Las finanzas en la actualidad se están viendo afectadas en parte por los seres humanos y en parte por las máquinas, por lo que ahora se define como “finanza cíborg”.
El nuevo inversionista cíborg es distinto a las concepciones anteriores debido a que esta nueva concepción es más rápida, se ve una mayor orientación a los datos automatizados, a su vez una mayor cantidad de información.
Una característica clave de la “finanza cíborg” es el uso de ordenadores verdaderamente rápidos y poderosos para analizar y ejecutar oportunidades comerciales basadas en modelos matemáticos complejos.

En medicina, hay 2 tipos de cíborg: los de restauración y de mejora. Las tecnologías de restauración se encargan de “restaurar funciones perdidas, órganos y extremidades”. El aspecto clave de la “ciborgización” restaurativa es la reparación de procesos tanto rotos o faltantes para revertirlos y convertirlos a un nivel de función saludable o a un nivel promedio. No hay ninguna mejora a las facultades originales y los procesos perdidos.
Por el contrario, el cíborg encargado de mejora “sigue un principio, el principio de rendimiento óptimo, el cuan consiste en la maximización de salida y la minimización de las entradas”. Por lo tanto, un cíborg mejorado intenta superar los procesos normales o incluso adquirir nuevas funciones que originalmente no estaban presentes.
Aunque las prótesis en general suplementan cuerpos dañados o perdidos con la integración de un artificio mecánico, implantes biónicos en medicina permiten que modelos de órganos o partes del cuerpo sean capaces de imitar la función origina de una manera más exacta. Michael Chorost escribió un libro de memorias de su experiencia con implantes cocleares, u oídos biónicos, titulado “Rebuilt: How Becoming Part Computer Made Me More Human”. Jesse Sullivan se convirtió en una de las primeras personas en operar una extremidad totalmente robótica a través de un injerto de nervio-músculo, permitiéndole un rango complejo de movimientos más allá de las prótesis anteriormente utilizadas.
Para el 2004, un corazón artificial completamente funcional fue desarrollado. El continuo desarrollo tecnológico de la biónica y la nanotecnología empieza a plantear preguntas de la mejora, y las futuras posibilidades de cíborgs que sobrepasan la funcionalidad original del modelo biológico. La ética y el deseo por “prótesis mejoradas” han sido debatidas; sus proponentes incluyen el movimiento transhumanista, con su creencia respecto a que las tecnologías emergentes pueden asistir a la raza humana para el desarrollo más allá de sus presentes, limitaciones normativas como el envejecimiento y las enfermedades, así como incapacidades más generales, como lo son las limitaciones en velocidad, fuerza, resistencia e inteligencia. Los oponentes del concepto describen lo que creen respecto a los sesgos que impulsan el desarrollo y la aceptación de dichas tecnologías, a saber, un sesgo hacía la funcionalidad y eficiencia que podría obligar a asentir una perspectiva del ser humano que resta importancia al definir las características de las manifestaciones actuales sobre humanidad y la persona, a favor de la definición de términos de mejoras, versiones y utilidad.

Investigaciones de organizaciones militares se han enfocado en la utilización de cíborgs animales con el propósito de una supuesta ventaja táctica. DARPA ha anunciado su interés en el desarrollo de “insectos cíborg” para transmitir información a través de sensores implantados en el insecto durante la etapa de pupa. El movimiento se controla desde un sistema microelectromecánico (MEMS) y que posiblemente podría ser capaz de examinar el entorno o detectar explosivos y gas.
A su vez, DARPA está desarrollando un implante neural para controlar el movimiento de los tiburones. El sentido único de los tiburones podría ser explotado para proporcionar retroalimentación de información en relación al movimiento de un barco enemigo o podría revelar la presencia de explosivos bajo el agua.

El concepto de cíborg es normalmente asociado con ciencia ficción. Sin embargo, muchos artistas han intentado crear una consciencia pública de organismos cibernéticos; estos yendo desde pinturas hasta instalaciones. Algunos artistas que crearon un sinnúmero de trabajos son Neil Harbisson, Moon Ribas, Patricia Piccinini, Steve Mann, Orlan H.R. Giger, Lee Bul, Wafaa Bilal, Tim Hawkinson y Stelarc.
Las máquinas son cada vez más omnipresentes en el proceso artístico, con cuadernos de dibujo computarizados remplazando a la pluma y el papel, y cajas de ritmo volviéndose tan populares como los bateristas humanos. Esto es tal vez lo más notable en el arte y música generativos. Compositores como Brian Eno han desarrollado y utilizado software capaz de construir partituras completas con tan solo un poco de parámetros matemáticos básicos.
Scott Draves es un artista generativo cuyo trabajo es explícitamente descrito como una “mente cibernética”. Su proyecto “Oveja Electrónica” genera arte abstracto mediante la combinación de trabajo de un sinnúmero de computadoras y personas a través del internet.

Como una tecnología médica se convierte en una ciencia más avanzada, algunas técnicas e innovaciones han sido adoptadas por la comunidad de modificación del cuerpo. Si bien todavía no son cíborgs, en la definición de Manfred Clynes y Nathan Kline, los desarrollos tecnológicos como la seda electrónica de silicio implantable, y códigos QR se han ido acercando a la conexión entre la tecnología y el cuerpo humano. Tecnologías hipotéticas como la de las interfaces de tatuajes digitales podrían mezclar la estética de modificación del cuerpo con la interactividad y funcionalidad, brindando una manera de vida transhumanista en la realidad actual.

Más allá del imaginario de la ciencia ficción, Kevin Warwick es tal vez la figura más importante en el desarrollo de una verdadera unión entre el humano y la máquina. El 24 de agosto de 1998 Warwick llevó a cabo el experimento "Cyborg 1.0", en el cual se le implantó debajo de la piel un chip RFID (usando exclusivamente anestesia local) con el cual fue capaz de controlar puertas, luces, calentadores y computadoras sólo con la señal emitida por el chip. 

Un segundo experimento, todavía más importante, fue el "Cyborg 2.0" el 14 de marzo de 2004, en el cual un chip de mayor complejidad fue implantado en el sistema nervioso de Warwick por medio del cual se conectó a Internet en la Universidad de Columbia de Nueva York y logró mover un brazo robótico situado en la Universidad de Reading del Reino Unido. Además, se le implantó también a su esposa un microchip (con el objetivo de crear alguna clase de telepatía o empatía) permitiendo así la primera comunicación puramente electrónica entre dos sistemas nerviosos humanos.

Después de los experimentos no se encontraron ninguna clase de daños o interferencias en el sistema nervioso, lo cual determinó su éxito.

En 2004, el artista británico Neil Harbisson, cocreó y se instaló un "eyeborg" en la cabeza para poder escuchar los colores que le rodean. El mismo año, el gobierno británico le prohibió renovar su pasaporte británico por el hecho de llevar un aparato electrónico en la cabeza. Harbisson empezó una campaña para defender sus derechos como cíborg y justificó que el ojo electrónico no es un aparato electrónico sino parte de su cuerpo y extensión de sus sentidos. Después de semanas con correspondencias, incluyendo cartas de su universidad y de su doctor, su ojo electrónico fue finalmente aceptado como parte de su cuerpo y su foto con el "eyeborg" incluida en el pasaporte.

La "Cyborg Foundation" es la primera organización internacional del mundo dedicada exclusivamente a ayudar a los humanos a convertirse en cíborgs. La fundación fue creada en 2010 por el cíborg Neil Harbisson y Moon Ribas como respuesta a la multitud de cartas y correos electrónicos recibidos de personas interesadas en convertirse en cíborg. Los principales objetivos de la fundación son extender los sentidos y las capacidades humanas creando y aplicando extensiones cibernéticas en el cuerpo, promover el uso de la cibernética en eventos culturales y defender los derechos de los cíborgs. En 2010, la fundación, establecida en Mataró (Barcelona), fue galardonada con el Premio Cre@tic otorgado por Tecnocampus Mataró.





</doc>
<doc id="15362" url="https://es.wikipedia.org/wiki?curid=15362" title="Pintura de los Estados Unidos">
Pintura de los Estados Unidos

La pintura de los Estados Unidos tiene una historia de dos siglos, a partir de la independencia del país. A finales del siglo XVIII y principios del XIX, los artistas pintaron sobre todo paisajes y retratos en un estilo realista. Las tendencias del arte moderno en Europa llegaron a los Estados Unidos a través de exposiciones en Nueva York como el Armory Show de 1913. Con anterioridad, los artistas estadounidenses habían basado la mayoría de su obra en la pintura occidental y las artes europeas. Después de la Segunda Guerra Mundial, Nueva York reemplazó a París como el centro del mundo artístico. Desde entonces, muchos movimientos estadounidenses han marcado el arte moderno y postmoderno.

Durante la época colonial y las primeras décadas de la nueva nación el único arte que se consideraba admisible, en un entorno puritano y laborioso, eran los retratos. La mayoría de los artistas de la época eran autodidactas. Hoy, los cientos de antiguos retratos que aún existen, realizados a partir de finales del siglo XVII, son altamente valorados por los coleccionistas. Entre los pintores destacados de la época cabe citar al neoyorquino Robert Feke o al escocés John Smybert. Smybert estudió con sir James Thornhill, y en 1728 acompañó al obispo Berkeley a América, con la intención de convertirse en profesor de bellas artes en la universidad que Berkeley pretendía fundar en las Bermudas, lo que nunca ocurrió. En 1731 pintó al "Decano George Berkeley y su familia", cuadro también titulado "El grupo de las Bermudas" (Galería de Arte de la Universidad de Yales); desde este famoso núcleo de las colonias lo que se pretendía era incorporar el joven arte estadounidense al ámbito más amplio del arte británico de la época. Por ello, en los años precedentes a la guerra de independencia de Estados Unidos hubo destacados artistas que viajaron a Europa y algunos de ellos se quedaron allí. John Singleton Copley es considerado como el pintor con el que comienza la escuela de pintura estadounidense. Realizó emblemáticos retratos de la clase comercial progresivamente próspera, pero marchó a Inglaterra en 1774 y allí su obra pareció perder fuerza. 
En Londres ya vivía, desde 1763, Benjamin West, quien llegó a ser pintor de la corte del rey Jorge III de Inglaterra y actuó como presidente de la Real Academia durante 28 años. A lo largo de cincuenta años, por su taller fueron pasando pintores estadounidense que buscaban formarse en Europa, por lo que a través de estos alumnos, su estilo influyó en la pintura de la nueva nación. Está considerado el primer pintor que se inspiró en la conquista del Nuevo Mundo, citándose su obra "Tratado de Penn con los indios" como un cuadro que ejerció gran influencia en la pintura de historia estadounidense posterior. 

Entre los artistas que visitaron el taller de West en Londres estuvieron Gilbert Stuart y John Trumbull, quienes desarrollaron su carrera después de la Declaración de Independencia en 1776. La nueva nación necesitaba una historia, y parte de esa historia se expresaría visualmente, tanto mediante retratos como en pintura de historia. Stuart pintó a los nuevos cargos del gobierno, siendo famoso por los numerosos retratos que hizo de George Washington, a lo que se dedicó igualmente Charles Willson Peale. Por su parte, Trumbull representó grandes escenas de batallas de la guerra de independencia, renovando el género de composiciones neoclásicas de temática patriótica.

Comienzan a surgir las primeras instituciones artísticas: la Academia de Bellas Artes de Pensilvania se fundó en 1805 en Filadelfia, mientras que la Academia Nacional vio la luz en 1825 en Nueva York. A pesar de ello, los artistas siguieron acudiendo a formarse a Europa, a lugares como Londres, París o Düsseldorf.

No tuvo gran éxito la pintura romántica estadounidense que seguía el academicismo europeo, como la pintura mitológica de Washington Allston o John Vanderlyn, suscitando escándalo este último por el desnudo de "Ariadna en Naxos" (1815). Más aceptación tenía la representación del paisaje, en todas sus formas, como los panoramas de Robert Fulton o los cosmoramas. El «recogimiento ante la naturaleza» se ha citado como uno de los rasgos de la cultura estadounidense, como se encuentra en Emerson, Thoreau o Walt Whitman. Por ello no es de extrañar que la primera escuela de pintura originalmente estadounidense se centrara, precisamente, en el paisaje. Se trata de la Escuela del río Hudson, que apareció en 1820. Los artistas percibieron que el Nuevo Mundo ofrecía temas propios y únicos. En este caso, la expansión hacia el Oeste de los asentamientos atrajo la atención de los pintores hacia la belleza trascendente de los paisajes de la frontera. Con Thomas Cole a la cabeza, los pintores del río Hudson combinaron su gran destreza técnica con el paisaje romántico. Sus pinturas eran exploraciones visuales de la luz y de las maravillas de la naturaleza. En la segunda mitad del siglo se produjo una auténtica explosión de cuadros representando el paisaje nacional en lienzos inmensos con un carácter espectacular. A esta escuela pertenecieron también John Frederick Kensett, Frederic Edwin Church y Albert Bierstadt. 
Comenzaron a surgir igualmente pinturas del Gran Oeste, que transmitían en particular el puro tamaño de la tierra y las culturas de los pueblos nativos que en ellas vivían. Artistas como George Caleb Bingham, que reflejó el Medio Oeste, o George Catlin especialista en retratar a los indios, se apartaron de la forma tradicional de presentar la tierra, que hasta entonces pretendía mostrar cuánto era propiedad del sujeto; ellos prefirieron mostrar de la manera más fiel posible el Oeste y su gente, incluidos los indios y su folklore. 

Ha de destacarse el éxito de la escena de género a partir de 1830, motivada sobre todo por la creciente ilustración, los periódicos y las revistas, que acostumbraron al público a escenas de la vida cotidiana. En esta línea sobresalió William Sidney Mount.

Después de la Guerra de Secesión se produjo una bifurcación en los caminos de la pintura estadounidense. Por un lado, estaba los artistas «estadounidensistas», que promovían una visión puramente estadounidense, interesándose por los problemas de la vida real y dotando de gran valor al ser humano. Cultivan una pintura realista, influida por el enfoque directo y la visión sencilla de la escuela del río Hudson. Winslow Homer representó al mundo rural estadounidense: el mar, las montañas y las gentes que vivían cerca de ellos. La vida urbana de clase media encontró su pintor en Thomas Eakins, un realista intransigente cuyos retratos desolados, sin artificios, se apartaban del sentimentalismo romántico que la gente «educada» de su tiempo había favorecido. Con él estudió Henry Ossawa Tanner, uno de los primeros pintores afroestadounidenses importantes. En esta línea también trabajaron George Inness, a quien llamaban el «Corot estadounidense», y el más subjetivo Albert Pinkham Ryder. Esta temática de escenas de la vida cotidiana, como ocurrió antes con la del paisaje estadounidense, tiene por origen una misma preocupación estadounidense por hacer del arte algo no exclusivo de una élite, sino que debe ser comprendido por todos y en este sentido es un arte democrático; pero además debe ensalzar también las peculiaridades de una nación, y por ello es un arte nacionalista. 

Diferente es el segundo camino, el que siguieron los pintores estadounidenses que siguieron los estilos europeos academicistas. A esta tendencia pertenece William Merritt Chase. Algunos son considerados estadounidenses, pero desarrollaron gran parte de su carrera en Europa, encontrándose con otros artistas europeos en París y Londres, como la impresionista Mary Cassatt o Whistler. A John Singer Sargent se le acaba considerando estadounidense sólo por su nacionalidad al haber nacido en Florencia (Italia) de padres estadounidenses; famoso retratista, que también pintó paisajes, fue un expatriado que pasó gran parte de su vida en Europa.

La controversia pronto llegó a ser una forma de vida para los artistas estadounidenses. De hecho, al igual que Europa después de los futuristas italianos, gran parte de la escultura y la pintura en Estados Unidos desde 1900 ha sido una serie de rebeliones contra la tradición. «Al infierno con los valores artísticos», proclamó Robert Henri (1865-1929). Henri encabezó el grupo de los Ocho, lo que los críticos apodaron la escuela «del basurero» o «cubo de basura» "(Ashcan school)" o incluso «banda negra revolucionaria» porque los retratos realistas del grupo mostraban los aspectos más pobres de la vida en la ciudad. Eligieron un realismo académico describiendo escenas rurales y urbanas estadounidenses, por lo que su novedad radica más en los temas que en la técnica. Desarrollaron en sus obras una iconografía de conciencia social. Del "grupo de los Ocho" fue famoso George W. Bellows por sus temas de boxeo. 
Apenas unos años más tarde, los artistas «del basurero» fueron desplazados por la llegada desde Europa de movimientos de vanguardia como el cubismo y la abstracción, defendidos por el fotógrafo Alfred Stieglitz desde el 291 de la Quinta Avenida de Nueva York, auténtico baluarte de la vanguardia pictórica. Tras la Primera Guerra Mundial, muchos artistas estadounidenses desarrollaron las tendencias modernas que emanaban del Armory Show o «Exposición del Arsenal», que en 1913 expuso al público estadounidense obras europeas de vanguardia junto a otras autóctonas de realismo social. Artistas estadounidenses se relacionaron de manera estrecha con los nuevos artistas europeos. Así, Max Weber se relacionó con Matisse y Picasso, siendo el primer cubista estadounidense, mientras que Lyonel Feininger se integró en el Blaue Reiter. Entre ellos pueden citarse: John Marin, Arthur Dove , Arthur Bowen Davies y Georgia O'Keeffe. 

En este período de entreguerras la pintura estadounidense estuvo marcada sobre todo por el cubismo, entendido muchas veces como mera geometrización. Dentro del orfismo cabe citar a Patrick Henry Bruce, Morgan Russell y Stanton Macdonald-Wright; estos dos últimos, además, concibieron el sincronismo en París, con el estudio de la relación entre el color, la luz y la música. Joseph Stella prefirió el cubismo futurista integrando con Charles Demuth y Charles Sheeler lo que se llamó el grupo «precisionista», o los «inmaculados», que emplearon el cubismo para retratar el paisaje industrial, desarrollándose entre 1915 y la década de los treinta. Destacó en esta línea Edward Hopper, que reflejó con original realismo las ciudades y los pueblos estadounidenses. El dadaísmo tuvo como referencia a Marcel Duchamp, de nacionalidad francesa, pero nacionalizado estadounidense en los años cincuenta y que influyó tanto en París como en Nueva York, y al pintor y fotógrafo Man Ray, a quien ya en el Nueva York de 1915 puede considerársele precursor del dadá.

Después de la Primera Guerra Mundial, la terminación del ferrocarril de Santa Fe permitió a los colonos estadounidenses viajar hacia el oeste, llegando hasta la costa californiana. Nuevas colonias de artistas comenzaron a crecer alrededor de Santa Fe y Taos. La principal materia de los artistas fueron los pueblos y los paisajes del Suroeste, cuyas imágenes se hicieron populares en la publicidad, usándose de manera significativa el ferrocarril de Santa Fe para animar a los colonos a ir al Oeste y disfrutar de los «paisajes no mancillados». Entre los artistas más prolíficos del Suroeste estuvieron William Henry Jackson y Georgia O'Keeffe.

El Renacimiento de Harlem fue otro desarrollo significativo en el arte estadounidense. En los años veinte y treinta una nueva generación de afroestadounidenses apoyaron sociedades literarias y exposiciones artísticas para combatir los estereotipos racistas. Aunque este movimiento incluyó artistas de todo el país, se centró en Harlem, donde trabajaron. El artista gráfico Aaron Douglas y el fotógrafo James Van Der Zee se convirtieron en emblemas del movimiento. Entre otros, estuvieron en este movimiento Romare Bearden y Charles Alston.

Cuando estalló la Gran Depresión, el "New Deal" del presidente Roosevelt creó varios programas de arte públicos, con el propósito de dar trabajo a artistas y decorar edificios públicos, normalmente con un tema nacional. El primero de estos proyectos, el Public Works of Art Project (PWAP), fue creado después de que hicieran presión, con éxito, artistas desempleados de la Artists' Union. El PWAP duró menos de un año y produjo casi 15.000 obras de arte. Le siguió el Federal Art Project (FAP, Proyecto de Artes Federales) de la Works Progress Administration (WPA, la Administración para el Desarrollo del Trabajo) en 1935, que proporcionó recursos a algunos de los artistas estadounidenses más conocidos. Se produjo un arte de protesta social, estilísticamente similar al que promovieron algunos artistas en la Unión Soviética y los muralistas en México. En todas partes, los artistas crearon extraordinarios ataques pictóricos a los sistemas sociales en multitud de pinturas y murales públicos. En ninguna otra parte tantos artistas se pronunciaron de manera tan franca e idealista sobre lo que estaba mal en su país, a menudo viviendo a cargo del presupuesto oficial, como cuando cientos de artistas fueron incluidos en la nómina de Estados Unidos como parte del esfuerzo del gobierno federal por proporcionar empleos.

Varios movimientos separados y relacionados entre sí comienzan y se desarrollan durante la Gran Depresión, incluyendo la escena de género estadounidense, el regionalismo y el realismo social. Un renovado sentimiento nacionalista animó a los artistas a redescubrir y explorar lo que se denomina «Americana» (la colección de documentos y objetos que relatan la historia, cultura y arte de Estados Unidos). El regionalismo recordaba a la Nueva Objetividad alemana, ensalzando artísticamente el Medio Oeste y su vida provinciana; el pintor más conocido de esta tendencia es, Grant Wood, cuya obra de 1930 está considerada un icono de la cultura estadounidense del siglo XX.

En los años posteriores a la Segunda Guerra Mundial, un grupo de artistas neoyorquinos formaron el primer movimiento de arte abstracto genuinamente estadounidense: el expresionismo abstracto. Este término, que fue usado por vez primera en 1919 en Berlín, fue retomado en 1946 por Robert Coates en el New York Times, y asumido por los dos principales críticos de arte de la época, Harold Rosenberg y Clement Greenberg. Siempre se ha criticado como demasiado grande y paradójico, sin embargo la definición común implica el uso del arte abstracto para expresar sentimientos, emociones, lo que hay dentro del artista y no lo que queda fuera de él. Aunque los numerosos artistas abarcados por esta denominación tienen estilos ampliamente diferentes, los críticos contemporáneos encontraron varios puntos comunes entre ellos. Puede caracterizarse por dos elementos principales: en primer lugar, el gran tamaño de los lienzos usados, parcialmente inspirados por los frescos mexicanos y las obras que hicieron para la WPA en los años 30; en segundo lugar, el fuerte e insólito uso de pinceladas y aplicación de pintura experimental con un nuevo entendimiento de proceso. La mayor parte de los expresionistas abstractos abandonaron la composición formal y la representación de objetos reales. A menudo intentaron composiciones espontáneas, intuitivas e instintivas de espacio, línea, forma y color. 

La primera generación de expresionistas abstractos estuvo compuesta por artistas como Jackson Pollock, Willem de Kooning, Mark Rothko, Franz Kline, Arshile Gorky, Robert Motherwell, Clyfford Still, Barnett Newman, Adolph Gottlieb, Philip Guston, Ad Reinhardt, Hans Hofmann, James Brooks, William Baziotes, Mark Tobey, Bradley Walker Tomlin, Theodoros Stamos, Jack Tworkov y otros. Muchos expresionistas abstractos de la primera generación estuvieron influidos tanto por las obras cubistas, que conocieron a través de copias en blanco y negro en críticas de arte y también de manera directa, en la Galería 291 o el Armory Show; pero también por los surrealistas europeos, por Pablo Picasso y Henri Matisse.

Se distinguen dos tendencias. La primera fue la "Action Painting" o «pintura de acción», practicada por Pollock, De Kooning y Kline. Se caracteriza por la reacción espontánea, las pinceladas poderosas, la pintura goteada "(dripping)" y arrojada y los fuertes movimientos físicos usados en la producción de un cuadro. Jackson Pollock es un ejemplo de «pintor de acción»: su "proceso creativo" implicaba arrojar pintura, o gotearla desde un palo o verterla directamente de la lata; con ello revolucionó los métodos de pintura. Hay un dicho famoso de De Kooning respecto a Pollock: «rompió el hielo para el resto de nosotros». Irónicamente, las extensiones repetitivas y grandes de Pollock de campos lineales son también características de la segunda tendencia, la «pintura de los campos de color» o "Color-field painting"; así lo señaló el crítico de arte Michael Fried en su ensayo para el catálogo de "Three American painters: Kenneth Noland, Jules Olitski, Frank Stella" en el Museo de Arte Fogg en 1965. Dos de los principios aplicados a este movimiento son el énfasis e intensificación del color y las amplias superficies. Esta "colour-field painting" fue cultivada en los años cincuenta por Newman, Rothko, Still, Reinhardt, Gottlieb y Motherwell. En los sesenta, siguieron esta tendencia Jules Olitski, Kenneth Noland y Helen Frankenthaler, quienes buscaron hacer cuadros que eliminasen la retórica superflua con color amplio y plano. 

El expresionismo abstracto marca un punto decisivo de la historia de la pintura estadounidense. Renace en él la tradición abstracta a partir de finales de la década de los cuarenta. Con él surge el primer movimiento pictórico original de los Estados Unidos, en un momento en el que el centro del mundo artístico internacional pasa de París a Nueva York, coincidiendo con el fin de la Segunda Guerra Mundial, cuando los Estados Unidos aparecen como potencia hegemónica de Occidente, tanto desde el punto de vista económico como político. Desde este momento en adelante, muchos movimientos pictóricos surgen en Estados Unidos y desde allí se difunden a Europa y el resto del mundo; al mismo tiempo, otras tendencias nacidas fuera son seguidas y cultivadas en Estados Unidos.

Algunas de estas tendencias ulteriores derivaron directamente de una de las dos clases de expresionismo abstracto, como la pintura de borde duro o de perfil duro "(hard edge," cultivado por Ellsworth Kelly) o la pintura de "shaped canvas" (lienzo con formato distinto al tradicional, ejemplificada en Frank Stella). Frankenthaler y Morris Louis siguieron con la pintura abstracta aun en los años sesenta, cuando triunfaba el "pop art", con cuadros en los que predominaba el uso del color. Dentro del arte informal se pueden clasificar a Sam Francis, principal exponente del tachismo, y Mark Tobey, inclinado más bien hacia la caligrafía con un hondo significado filosófico y espiritual propio de Oriente.

Entre 1955 y 1970, aproximadamente, se desarrolló el arte pop (en inglés, "Pop art", abreviatura de "popular art") en Estados Unidos, donde arraiga con más fuerza que en ningún otro lugar, a pesar de las reticencias de algunos críticos como Harold Rosenberg, dada la fuerza que el expresionismo abstracto tenía en todas las instancias de la industria del arte. Los neodadaístas Jasper Johns y Robert Rauschenberg, que crearon arte a partir de materiales de desecho en los cincuenta se consideran precursores del "pop art". Johns usó fotos, papeles de periódico y objetos descartados en sus composiciones. Su técnica de pintar a paletazos recordaba a expresionistas abstractos como De Kooning. 

Al hacerse eco de la sociedad de consumo y sus estereotipos, este estilo se suele considerar el epítome del arte imperialista estadounidense. La iconografía pop era fácilmente asimilable como algo puramente estadounidense y esto era importante en aquel continente pues siempre, tanto artistas como coleccionistas, estaban de un cierto modo en lucha o competición con lo europeo. La confirmación de esto se produjo con la exposición titulada «El Pop Art y la tradición estadounidense» en el Milwaukee Art Center en 1965. Este aspecto nacionalista era lo único que lo acercaba a la generación de los expresionistas abstractos; en lo demás todo es opuesto: los artistas pop ironizaban sobre la caligrafía y el gesto característicos de los expresionistas (las obras de Lichtenstein en las que amplifica una pincelada esquematizada gráficamente), o los enormes cuadros de Rosenquist en los que amplifica espaguetis como recordando las nervaciones de los "drippings" («goteos») de Pollock, y en general el interés puesto en desechar de la obra toda traza de la intervención manual del artista. El grupo "pop art" lo forman Andy Warhol, Roy Lichtenstein, James Rosenquist, Jim Dine, Robert Indiana, Tom Wesselmann, Ronald Kitaj y Claes Oldenburg. En la periferia del pop estadounidense se encuadran Alex Katz y Larry Rivers. Warhol, Rivers y Lichtenstein reprodujeron, con cuidado satírico, objetos cotidianos e imágenes de la cultura popular estadounidense, como botellas de Coca-Cola, latas de sopa o tiras cómicas. Aunque todos estos artistas son pop, difieren entre sí. Warhol pretendía eliminar de la obra de arte cualquier traza o signo de manualidad; muchas de sus obras están hechas a partir de fotografías proyectadas sobre el lienzo. Lichtenstein toma sus motivos de las tiras de cómics y los amplía a enormes dimensiones dejando visibles los puntos que resultan del proceso de impresión. Dine combina objetos reales con fondos pintados. Oldenburg fabrica objetos de la vida cotidiana (hamburguesas, navajas, etc.) a tamaños descomunales que instala en ocasiones en espacios al aire libre. Indiana pinta rótulos gigantescos que reclaman la atención del espectador al tiempo que lo amonestan.

Durante los años cincuenta la pintura abstracta en los Estados Unidos evolucionó hacia movimientos como el neodadaísmo, la abstracción postpictórica o el "Op Art", aunque continuó cultivándose el expresionismo abstracto. En gran medida, muchas de estas tendencias fueron desbancadas a partir de 1960 por la aparición del minimalismo, que marcó un nuevo periodo de interés por la geometría y la estructura, del objeto consigo mismo. Toma del "pop art" las «definiciones claras y desprovistas de ambigüedad», y de la abstracción el libre empleo de los colores. Está representado en la obra de Frank Stella, Carl Andre y el artista famoso por sus instalaciones de luces fluorescentes Dan Flavin. 

Alfonso A. Ossorio es la representación estadounidense dentro del "art brut" de los años cincuenta. En esta misma década surgió, en San Francisco (California), y como reacción a la falta de objetividad del expresionismo abstracto, el "Funk art".

Más tarde surgieron otros movimientos abstractos como Fluxus y el posminimalismo (un término acuñado por vez primera por Robert Pincus-Witten en un artículo publicado en la revista "Artforum" en 1969; refiriéndose a la obra de la artista Eva Hesse, dijo que era "post minimal art" o «arte posminimalista»). Estos movimientos, como la abstracción lírica, buscaron expandir los límites de la pintura abstracta y el minimalismo centrándose en el proceso, los nuevos materiales y las nuevas vías de expresión. La abstracción lírica comparte semejanzas con la pintura de los campos de color y el expresionismo abstracto especialmente en el uso despreocupado de la pintura - textura y superficie. El dibujo directo, el uso caligráfico de la línea, los efectos de la pintura salpicada, manchada y vertida se asemejan superficialmente a los efectos vistos en el expresionismo abstracto y la pintura de los campos de color. Sin embargo los estilos son marcadamente diferentes. El posminimalismo a menudo incorporó materiales industriales, materia bruta, objetos encontrados, instalaciones, repeticiones seriales y a menudo con referencias al dadaísmo y el surrealismo está ejemplificada mejor en las esculturas de Eva Hesse. Esta artista, junto con otros «posminimalistas» como Richard Serra, se encuentran dentro de la tendencia de "arte procesual".

El realismo, a pesar del enorme éxito de movimientos no figurativos como el expresionismo abstracto, no dejó de ser popular, como prueban las ilustraciones de Norman Rockwell. Además del "Pop Art", hubo otros movimientos figurativos que reaccionaron ante la abstracción, como el movimiento figurativo de la zona de la Bahía o, en los setenta, el neoexpresionismo. En ciertos lugares el expresionismo abstracto nunca prendió. Un ejemplo de ello es Chicago, en el que el estilo artístico dominante fue un realismo grotesco y simbólico, como muestran los "Chicago Imagists", entre los que se encuentra Nancy Spero. 

Otros movimientos figurativos de la segunda mitad del siglo son el fotorrealismo y el nuevo realismo. El hiperrealismo, "photorealism" o "superrealism" realiza cuadros figurativos muy detallados y fríos; surgió en los Estados Unidos hacia 1965 y sobresalen en esta tendencia Richard Estes y Chuck Close. El "new realism" (nuevo realismo) que se desarrolló entre 1960 y 1970 tuvo en Alex Katz y Alice Neel sus máximos representantes estadounidenses. En los años ochenta se revitalizó lo figurativo, si bien a través de propuestas muy diversas que van desde Keith Haring y sus formas simples inspiradas por el "graffiti" hasta la "Bad painting" de Julian Schnabel, David Salle o Jean-Michel Basquiat. La "Bad painting" surgió a principios de la década de los ochenta; es una «mala pintura» que recuerda al "art brut" y que forma parte de un movimiento internacional más amplio (con los nuevos fauves alemanes o la transvanguardia italiana) en la que se abandonaba el intelectualismo del arte conceptual y se reivindicaba el «mal gusto» del arte marginal.

Desde mediados de los años sesenta y a lo largo de los setenta aparecieron nuevas tendencias que ampliaron los límites del arte contemporáneo. El arte conceptual, surgido en Nueva York en torno a 1965, considera que lo prioritario es el concepto, la idea, y no su realización física en un objeto artístico determinado; conceptuales son, por ejemplo, Joseph Kosuth y Dennis Oppenheim. Para finales de la década de los setenta, sin embargo, se consideró «fracasado» el arte conceptual, y se intentó un nuevo discurso artístico cuyo ejemplo inicial fue la exposición "Pictures", celebrada en Nueva York en 1977, en la que expusieron artistas como Jack Goldstein, Robert Longo y Sherrie Levine. Hubo quien recicló obras o logotipos previos, haciendo una especie de copias de copias (simulacionistas) o bien artículos de revistas de una manera que recordaba al "pop art" (apropiacionistas, entre los que se encuentra Jeff Koons).

El "Land Art" tiene como material de su obra la propia tierra, primando más que el resultado artístico los testimonios que de la obra quedan, en fotografía o vídeo; artista "land" destacado fue Robert Smithson. El videoarte surgió hacia el año 1963, simultáneamente en Estados Unidos y en Europa, y fue utilizado por las otras corrientes de la época, como fluxus o el arte conceptual. Otras novedades fueron las "performances" o el arte de instalaciones. Vito Acconci y Dennis Oppenheim cultivaron el arte corporal o "body art". 

Una de las corrientes que aportó algo nuevo fue la "pattern painting", surgido en California en 1975, que presenta de manera repetitiva motivos decorativos; son sus cultivadoras artistas femeninas que se oponen así a la severidad del minimalismo, utilizando muchas veces técnicas artesanales tradicionalmente consideradas femeninas como, por ejemplo, el "patchwork." En cierto sentido tuvo como precursor el llamado arte feminista, realizado por mujeres y teniendo como tema la condición femenina, que surge a finales de la década de los sesenta, en paralelo con el movimiento "Women's Lib." 

Todas estas vanguardias del último tercio del siglo XX se centraron en experimentar con diversos medios que la tecnología ponía a su disposición. No es ajeno a ello ni los ordenadores, que dan lugar a un arte digital, ni internet, que permite el "net.art." La informática permitió, a partir de mediados de los sesenta, que se crearan imágenes artísticas por medios digitales, esto es, imágenes generadas por ordenador. A mediados de los noventa se dio un salto cualitativo, logrando creaciones artísticas a través de la red, lo que desafía conceptos clásicos de autoría o identidad del artista.



 yessenia rebolledo

</doc>
<doc id="15363" url="https://es.wikipedia.org/wiki?curid=15363" title="Economía de Portugal">
Economía de Portugal

Portugal se ha transformado en una economía de mercado bien diversificada y basada en servicios después de entrar en la Comunidad Económica Europea en 1986. Durante los últimos dos decenios, sucesivos gobiernos privatizaron muchas compañías estatales y sectores claves de la economía, incluyendo el sector financiero y las telecomunicaciones. El país se unió a la Unión Monetaria Europea en 1998 y adoptó el euro el 1 de enero del 2002.

Durante los años noventa el crecimiento económico portugués se situó por encima de la media de la Unión Europea, pero cayó entre el 2001 y el 2008. Su producto interior bruto está cerca de los 2/3 de la media de la UE.

Bajo el gobierno conservador de Pedro Passos Coelho (2011-2015), Portugal se compromete en una "política de austeridad" destinada a reducir el déficit público y revitalizar el sector privado: reducción del salario mínimo y de las pensiones de jubilaciónes, aumento de los impuestos y reducción de las ayudas estatales. Sin embargo, el déficit se mantiene en el 4,4% del PIB, lo que genera amenazas de sanciones por parte de la Unión Europea, la precariedad y la pobreza aumentan en el país.


[[Imagen:RentaEspPorMex.png|thumb|350px|right|Comparación del PIB per cápita nominal de España, Portugal y México, durante el siglo XX, basado en "World Population, GDP and per cápita GDP".
(Convertidos según paridad del poder de compra). Año 2000

17 193,56 € (Tipo conversión: 1 dólar = 1,0882 € al 30/01/01)








Según datos de 1999, los porcentajes de ocupación por sectores productivos fueron:

Según los datos de la Unión Europea, la tasa de paro presentó la siguiente evolución entre 2000 y 2005:

Su moneda anterior era el [[escudo portugués]]; desde el 1 de enero de 2002 es el [[euro]].

A pesar de su grado de desarrollo, el escaso peso demográfico de Portugal hace que su influencia específica en el contexto internacional sea menor que el de otras potencias europeas. Según datos del [[Banco Mundial]], Portugal ocupa el puesto 30º en el ranking de mayores economías por [[PIB]], y el puesto 24.º si el indicador que utilizamos es la [[Renta per Cápita]]. Portugal tiene una de las tasas de natalidad más bajas del mundo por que si... (menos de un niño por mujer) lo que provocará un inminente pérdida de población si no se corrige la tendencia en las próximas décadas. Según [[Eurostat]], la sanidad portuguesa tiene también unos indicadores muy positivos (267 médicos y 365 camas por cada 100.000 habitantes). A pesar de ello, Portugal es el país europeo con mayor ratio de muertes por [[VIH]] (155 personas por cada 100.000 habitantes). Por otra parte, según el [[Foro Económico Mundial]], Portugal es el 46.º país del mundo en el Índice de Competitividad Global. En la siguiente tabla se puede analizar el contexto socio-económico de Portugal a partir de datos del Banco Mundial, Eurostat y el Foro Económico Mundial:

Se presentan a continuación las mercancías de mayor peso en las importaciones de Portugal para el período 2010-hasta abril de 2015. Las cifras están expresadas en [[Dólar estadounidense|dólares estadounidenses]] valor [[Free on board|FOB]].

[[File:Importaciones de Portugal del periodo 2010-hasta junio 2015 expresadas en USD valor FOB.png|thumb|right|Importaciones de Portugal del periodo 2010-hasta junio de 2015 expresadas en USD valor FOB.]]

Se presentan a continuación los principales socios comerciales de Portugal para el periodo 2010-hasta abril de 2015.La mayoría de sus importadores están en [[Europa]] salvo [[Estados Unidos]] y [[Angola]]. Las cifras expresadas son en [[Dólar estadounidense|dólares estadounidenses]] valor [[Free on board|FOB]].

[[File:Exportaciones de Portugal del periodo 2010-hasta junio 2015 expresadas en USD valor FOB.png|thumb|right|Exportaciones de Portugal del periodo 2010-hasta junio de 2015 expresadas en USD valor FOB.]]


[[Categoría:Economía de Portugal]]

</doc>
<doc id="15365" url="https://es.wikipedia.org/wiki?curid=15365" title="Narrativa gótica">
Narrativa gótica

La narrativa gótica es un género literario relacionado estrechamente con el de terror y subsumido en éste, al punto de que es difícil diferenciar uno del otro.

No puede decirse que haya existido la novela de terror sino hasta la aparición del terror gótico; estrictamente hablando, la primera novela gótica fue "El castillo de Otranto" (1765), de Horace Walpole, Entre estos autores, el género se desarrolló con obras como "Vathek", de William Beckford (1786, originalmente en francés); "Los misterios de Udolfo", de Ann Radcliffe (1794); "Las aventuras de Caleb Williams", de William Godwin (Londres, 1794); "El monje", de Matthew Lewis (1796), y "Manuscrito encontrado en Zaragoza", de Jan Potocki (1805).

Dentro del subgénero narrativo denominado novela, es preciso distinguirla de la narración popular fantástica del folklore y de los cuentos tradicionales de aparecidos, porque se desarrolla fundamentalmente desde fines del siglo XVIII a la actualidad y posee características distintas asociadas al movimiento estético conocido como Romanticismo. En algunos manuales de literatura se hace referencia a la novela gótica también como novela negra, si bien este término puede dar lugar en la actualidad a equívocos.

Las características de este género pasan en primer lugar por una ambientación romántica: paisajes sombríos, bosques tenebrosos, ruinas medievales y castillos con sus respectivos sótanos, criptas y pasadizos bien poblados de fantasmas, ruidos nocturnos, cadenas, esqueletos, demonios... Personajes fascinantes, extraños e insólitos, grandes peligros y a menudo cándidas muchachas en apuros; los elementos sobrenaturales podían aparecer directamente o solamente ser sugeridos. Estas ubicaciones y personajes, en tiempo y espacio, respondían a la demanda de temas exóticos característica de la tendencia al medievalismo, el exotismo y el orientalismo propia de la sensibilidad romántica.

Pese a que no existió un movimiento definido como en otras partes de Europa, diversos escritores rusos incursionaron también en el género aportando relatos que exhiben como tema principal las brujas, los hombres lobos y otros personajes oscuros, propios del folclore eslavo. El primer autor, y más prolífico, en dedicar su pluma a los relatos de terror es Gógol, con algunos cuentos cortos como "Viy" (que cuenta con más de una adaptación cinematográfica), "La noche de San Juan", y "La noche de mayo o la ahogada". Otros autores rusos que introdujeron historias de terror fueron, Baratynski ("El anillo"), Somov ("El hombre lobo"), Karamzin ("La isla de Bornholm") y Lermontov ("Stuss").

El adjetivo "gótico" deriva de "godo", y, en efecto, en el contexto de este subgénero literario, gran parte de las historias trascurren en castillos y monasterios medievales. En sentido estricto, el terror gótico fue una moda literaria, de origen fundamentalmente anglosajón, que se extendió desde finales del siglo XVIII hasta finales del siglo XIX, como reacción al Racionalismo. En la literatura de terror moderna los viejos arquetipos no desaparecieron totalmente.

El movimiento gótico surge en Inglaterra a finales del siglo XVIII. El renacimiento del gótico fue la expresión emocional, estética y filosófica que reaccionó contra el pensamiento dominante de la Ilustración, según el cual la humanidad sería capaz, solo en uso de la Razón, de llegar a obtener el conocimiento verdadero y la felicidad y virtud perfectas; aunque el Romanticismo demostraría que tan insaciable apetito de conocimiento dejaba de lado la idea de que el miedo podía ser también sublime.

Las ideas de orden de la Ilustración van siendo relegadas y dan paso a la afición por el gótico en Inglaterra y así se va abriendo camino para la fundación de una escuela de este tipo de literatura, derivada de modelos alemanes.

Las narrativas góticas abundan entre 1765 y 1820, con la iconografía que nos es conocida: cementerios, páramos y castillos tenebrosos repletos de misterios, villanos infernales, hombres lobo, vampiros, doppelgänger (transmutadores, o doble personalidad) y demonios, etc..
Los ingredientes de este subgénero son castillos embrujados, criptas, fantasmas o monstruos, así como las tormentas y tempestades, la nocturnidad y el simple detalle truculento, todo ello surgido muchas veces de leyendas populares. La obra fundadora del gótico es "El castillo de Otranto", de Horace Walpole (1765). Otras obras claves de esta corriente son "Vathek" (1786), de William Beckford, "Los misterios de Udolfo" (1794), de Ann Radcliffe, "El Monje", de Matthew Lewis, publicada en 1796, "Melmoth el errabundo" (1820), de Charles Robert Maturin y "Manuscrito encontrado en Zaragoza" de Jan Potocki. El Romanticismo exploró a fondo esta literatura, casi siempre inspiradora de negredor de sentimientos morbosos y angustiantes, que alcanzó su máximo esplandor en el siglo XIX, a impulsos del descubrimiento del juego mórbido con el inconsciente.

Aunque Julio Verne cultivó sobre todo los géneros de aventuras y de la ciencia-ficción, existe una novela suya poco conocida que posee las características de la novela gótica: "El castillo de los Cárpatos". Dicha novela es considerada como una "rara avis" en la producción de Verne y suele considerarse como su única incursión en el género de la novela gótica, reuniendo todos los elementos que la caracterizan: un castillo tenebroso abandonado, una bella cantante de ópera supuestamente secuestrada por un malvado noble (el Barón Gortz), un héroe enamorado dispuesto a rescatarla hasta enloquecer, supersticiones populares sobre fantasmas y aparecidos, etc... Escrita cinco años antes que "Drácula" comparte no pocos elementos con la obra de Bram Stoker.
Obras de pleno siglo XIX, como "Carmilla" de Sheridan Le Fanu, "Frankenstein" de Mary Shelley, "El corazón delator" de Edgar Allan Poe, y, más adelante, "Janet, la del cuello torcido" de R. L. Stevenson, "El Horla" de Guy de Maupassant, "Otra vuelta de tuerca" de Henry James, etc., puede decirse que superan ampliamente el terror gótico, pues o van más allá, o no reúnen las citadas características. Salvo en casos excepcionales, tienden al formato corto del cuento en menoscabo de la novela; no se recurre a las monjas ensangrentadas, ni son elementos necesarios los aullidos espectrales y los truenos, rayos y centellas de tormentas; no tienen por qué transcurrir en escenarios ruinosos, castillos y monasterios medievales; los fantasmas que presentan no están "encadenados"; apenas tienen que ver con leyendas populares... Por lo tanto pueden considerarse ya como obras plenamente representativas del terror moderno que alcanzará a nuestros días, si bien en este punto la opinión de los críticos está dividida.

En los relatos propiamente góticos se advierte un erotismo larvado y un amor por lo decadente y ruinoso. La depresión profunda, la angustia, la soledad, el amor enfermizo, aparecen en estos textos vinculados con lo oculto y lo sobrenatural. La mayoría de los autores sostiene que el gótico ha sido el padre del género de terror, que con posterioridad explotó el fenómeno del miedo con menor interés en los sentimientos de depresión, decadencia y exaltación de lo ruinoso y macabro que fueron el sello de la literatura romántica goticista, y más énfasis en otros elementos.

Fueron también escritores de terror el romántico español Gustavo Adolfo Bécquer (1836-1870), quien incluyó en sus "Leyendas" algunos relatos de miedo muy meritorios como "Maese Pérez, el Organista", "El Miserere" y "El Monte de las Ánimas".

A fines del siglo XIX, Oscar Wilde tomó este subgénero con humor en su relato "El fantasma de Canterville".

"Los cantos de Maldoror", de Isidore Ducasse -Conde de Lautréamont- es una obra considerada como precursora del surrealismo. No obstante, contiene elementos narrativos que permiten rastrear rasgos e influencias de obras como "Melmoth el errabundo", según señala Marcelyn Pleynet en su estudio sobre Lautréamont. En el caso de maldoror, éste es presentado como un ser que mediante la metamorfosis acecha a los hombres. Maurice Blanchot y Gaston Bachelard analizan el bestiario de las formas animales adoptadas por Maldoror; éste suele denominarse a sí mismo con los apelativos de: "el vampiro", "aquel que no sabe llorar", "el montevideano", entre otros.

Ya en el siglo XX, la escritora estadounidense Anne Rice, cuyas obras mezclan lo cotidiano con historias de vampiros y de erotismo oscuro, ha tratado de revitalizar, temáticamente, el terror gótico. H. P. Lovecraft, por su parte, lograría sintetizar en las primeras décadas del siglo XX la tradición que partía de lo gótico con la ciencia ficción contemporánea. Actualmente, muy de moda nuevamente por el cine, lo gótico ha sido rescatado por autores anglosajones (al menos en determinadas obras) como Angela Carter, P. McGrath, A. S. Byatt, etc.

Según el ensayista César Fuentes Rodríguez, entre las características específicas de la novela gótica se encuentran las siguientes:








El terror moderno es la etapa de la literatura de terror que se desarrolla ya a partir de la primera mitad del siglo XIX por obra de precursores, como el norteamericano Edgar Allan Poe (1809-1849) y el irlandés Joseph Sheridan Le Fanu (1814-1873), cuyas aportaciones, especialmente el llamado terror psicológico, supusieron una profunda transformación de la literatura de terror gótico anterior, de raíces estrictamente románticas, y que, como se ha visto, utilizaba como principal recurso el "susto" y otras técnicas que hoy podrían. pasar por anticuadas y rudimentarias.

Ya en las postrimerías del siglo XIX el cuento de horror o de fantasmas experimentaría nuevamente un gran avance a resultas de las aportaciones de los grandes cultivadores que encontró esta modalidad en Inglaterra (alguno sería de otra nacionalidad, como el francés Guy de Maupassant), en las épocas victoriana y eduardiana. Autores como Robert Louis Stevenson, M. R. James, Henry James, Saki (Héctor Hugh Munro) y Arthur Machen, entre otros, ejercerían una profunda renovación de estilos, temas y contenidos que, ya en pleno siglo XX, acabaría desembocando en el último autor mayor del género: el norteamericano Howard Phillips Lovecraft (1890-1937). Con él, el género macabro experimentaría nuevamente un giro de 180 grados.

Este autor, cuyo principal referente, según él mismo confesaba, era su compatriota Poe, fue el creador del llamado "cuento materialista de terror" (por oposición al "espiritualismo" a ultranza propio del relato de fantasmas tradicional). Introdujo, además, en el género elementos y contenidos propios de la naciente ciencia-ficción, lo que tendría amplias repercusiones en toda la literatura y el cine posteriores. Lovecraft, orientándose en principio a partir de las subyugantes fantasías que le proporcionaba su propio mundo onírico, supo conciliar éstas con las enseñanzas de autores de su predilección como el citado Poe, Lord Dunsany, Ambrose Bierce, Algernon Blackwood y William Hope Hodgson, lo que dio como resultado la asombrosa invención de una nueva mitología pagana en pleno siglo XX, los Mitos de Cthulhu, a través de la cual logró dar cumplida expresión a los muchos terrores y obsesiones que anidaban en su personalidad enfermiza. Con todo, desde el punto de vista estilístico, en ocasiones se ha achacado a Lovecraft un estilo encorsetado, abundante en adjetivos y fórmulas repetitivas, que hace que sus argumentos pueden predecirse con facilidad a medida que el lector asimila la técnica del autor.

Es necesario mencionar en este punto al grupo de autores que acompañó a Lovecraft en su alucinante periplo literario, publicando relatos en la famosa revista norteamericana Weird Tales, unos pertenecientes al Círculo de Lovecraft y otros independientes: Robert Bloch, Clark Ashton Smith, Fritz Leiber, Frank Belknap Long, Henry Kuttner, Seabury Quinn, August Derleth, Robert E. Howard, Donald Wandrei, etc., algunos de los cuales, a juzgar por la opinión de ciertos críticos, de valores literariamente discutibles.

Otro autor de interés en este campo, no tan conocido como las versiones cinematográficas de sus obras, es Robert Bloch, autor de la novela "Psicosis", uno de los últimos textos que se han añadido al canon de la literatura de terror. otras de sus novelas destacadas son "Cría cuervos" y "Pirómanos". Los lovecraftianos Fritz Leiber y Henry Kuttner escribieron sobre todo novelas de fantasía y ciencia ficción. La mayor contribución de August Derleth, discípulo directo de Lovecraft, ha sido la edición de los textos del mismo, aunque es autor de algún relato de mérito. Robert E. Howard centró su atención más en la fantasía épica: Conan y Sonya la Roja, entre otros personajes famosos, particularmente por las versiones cinematográficas y los cómics.

Uno de los modelos de Lovecraft es el autor inglés, ya citado, William Hope Hodgson al cual se considera precursor del género de horror cósmico creado por aquel. Nacido en 1875 y muerto en 1918, su obra "La casa en el confín de la tierra" narra en primera persona las peripecias del habitante de una pequeña aldea irlandesa que es raptado por unos seres mitad hombres, mitad bestias, y transportado a otra dimensión.

Pero el escritor que gran parte de la crítica sitúa al lado de Poe, Lovecraft y Maupassant en el panteón de ilustres cultivadores del miedo, es el norteamericano Ambrose Bierce (1842-1914?), quien a través de contundentes filigranas como "Un terror sagrado", "La ventada cegada" o "La cosa maldita" se evidenció como maestro absoluto en la recreación de tensas atmósferas desasosegantes en medio de las cuales estalla de pronto un horror absorbente y feroz.

El tópico del hombre lobo fue introducido en el género por Guy Endore, con su novela "El hombre lobo en París", de 1933, aunque hay claros antecedentes en "Capitán de lobos" de Alejandro Dumas padre.

La última hornada del género de terror cuenta con figuras literariamente controvertidas, la mayoría procedentes del mundo anglosajón, como Stephen King, Ramsey Campbell y Clive Barker, autores de gran número de best-sellers, algunos de los cuales han sido adaptados con éxito al cine. En los últimos años, la producción de este género se ha trasladado, en gran parte, desde el campo de la literatura al de la cinematografía, la historieta, la televisión y los video-juegos, dando origen a un nuevo subgénero de terror, el "gore" ('sangre espesa', 'coágulo' en inglés), caracterizado por el fácil recurso a las escenas sangrientas y la casquería barata.

Stephen King resulta muy controvertido por la enorme difusión que ha alcanzado, pero deben discriminarse, dentro de la enorme cantidad de textos que ha producido, los más literarios, como "Danza macabra", "Salem's Lot" o "Estaciones diferentes", de los decididamente comerciales, y de gran repercusión igualmente, como "El ciclo del hombre lobo". Los textos de Clive Barker frisan a veces con el "gore" más descarado. Son de gran interés por los altos vuelos de imaginación en ellos desplegados sus "Libros de sangre", con historias de horror "experimental", como "Cabal" o "En las colinas, las ciudades", y otras que han tenido gran difusión por sus versiones cinematográficas, como "Hellraiser", adaptada al cine.

Ramsey Campbell, T. E. D. Klein, Brian Lumley y Anne Rice son autores igualmente dignos de figurar en este apartado. Anne Rice (pseudónimo de Howard Allen Frances O'Brien), es famosa por la novela "Entrevista con el vampiro", y por su versión cinematográfica, además de otras obras como "Crónicas vampíricas" y "Brujas". Son continuaciones de la primera "Lestat" y "La reina de los condenados", de la que también existe una versión cinematográfica, además de "El ladrón de cuerpos". La autora últimamente ha conciliado ambas series en varias novelas.





</doc>
<doc id="15366" url="https://es.wikipedia.org/wiki?curid=15366" title="H. P. Lovecraft">
H. P. Lovecraft

Howard Phillips Lovecraft ( Providence, Estados Unidos, 20 de agosto de 1890 – ibídem, 15 de marzo de 1937), mejor conocido como H. P. Lovecraft, fue un escritor estadounidense, autor de novelas y relatos de terror y ciencia ficción. Se le considera un gran innovador del cuento de terror, al que aportó una mitología propia (los mitos de Cthulhu), desarrollada en colaboración con otros autores y aún vigente. Su obra constituye un clásico del horror cósmico, una corriente que se aparta de la temática tradicional del terror sobrenatural (satanismo, fantasmas), incorporando elementos de ciencia ficción (razas alienígenas, viajes en el tiempo, existencia de otras dimensiones). Lovecraft cultivó asimismo la poesía, el ensayo y la literatura epistolar. Se le considera uno de los autores más influyentes del siglo XX en el género de la literatura fantástica.

El erudito lovecraftiano Rafael Llopis escribió sobre el autor: «Educado en un santo temor al género humano (exceptuando de este a las “buenas familias” de origen anglosajón), creía que nadie es capaz de comprender ni de amar a nadie y se sentía un extranjero en su patria. Para él “el pensamiento humano [...] es quizá el espectáculo más divertido y más desalentador del globo terráqueo”».

"The Penguin Encyclopedia of Horror and the Supernatural" recoge sobre el escritor de Providence: «Algunos han criticado sus obras por su estilo ampuloso, repleto de adjetivos, pero la armonía y el equilibrio en sus mejores cuentos justifican plenamente esa práctica como deliberada. Se formó a conciencia en este género apropiándose de sus recursos, manipulándolos a su antojo y llevándolos al límite con convincente facilidad. Lovecraft dedicó gran atención a la estética de la literatura de terror, como atestiguan numerosos pasajes de sus cartas. El largo ensayo "El horror sobrenatural en la literatura" (1927, revisado en 1936) representa una exposición competente de los principios del relato sobrenatural, demostrando un dominio exhaustivo de la materia. En él trató de definir el atractivo peculiar de la historia de terror, en la que "debe haber presente una cierta atmósfera de mortal terror inesperado a fuerzas exteriores desconocidas", y describió la evolución de la novela gótica a través de las obras de Walpole, Radcliffe, Lewis y Maturin».

En su estudio "Danza macabra" (1981), el escritor de horror Stephen King afirma que Lovecraft es «el príncipe oscuro y barroco de la historia del horror del siglo XX». Además, por contraposición al mal interno o psicológico, «el concepto de mal externo tiene más alcance, es más impresionante. Lovecraft así lo entendió, y es lo que hace a sus historias de extraordinaria, ciclópea maldad, tan efectivas cuando son buenas. [sus mejores cuentos] nos hacen sentir el peso del universo suspendido sobre nuestras cabezas, sugieren fuerzas sombrías capaces de destruirnos a todos solo con gruñir en sueños».

Para su biógrafo S. T. Joshi, Lovecraft «no era un “extraño en este siglo”, como afirma de sí mismo el protagonista de su cuento "El extraño". Si se estudian detenidamente sus historias se observará en ellas algo más que los sueños escapistas de un anticuario caduco: enseguida encontramos datos como el descubrimiento de Plutón, citado en "El que susurra en la oscuridad" (1930), o la entonces todavía controvertida teoría de la deriva continental, en la novela "En las montañas de la locura" (1931). Y ahondando más, en la ficción más tardía, nos topamos repetida y significativamente con Albert Einstein, Max Planck y Werner Heisenberg, y también las metáforas sobre el futuro desarrollo estético, político y económico de la humanidad, que se transparentan en las civilizaciones alienígenas que aparecen en "El Túmulo" (1929-1930; publicado en 1940 como obra de Zealia Bishop), "En las montañas de la locura" (1931; publicado en 1932) y "En la noche de los tiempos" (1935; publicado en 1936)"."

Según la destacada escritora estadounidense Joyce Carol Oates, «la mística identificación de Lovecraft con sus escenarios del Massachusetts rural y las antiguas colonias de Salem, Marblehead y Providence, sugiere un trascendentalismo paródico en el que el “espíritu” reside en todas partes excepto, posiblemente, en los seres humanos». Lovecraft, en suma, como ocurre con Edgar Allan Poe desde el siglo XIX, ha ejercido «una influencia incalculable sobre sucesivas generaciones de escritores de ficción terrorífica».

Por su parte, el novelista francés Michel Houellebecq declaró: «Yo descubrí a H.P.L. a los dieciséis años gracias a un "amigo". Como impacto, fue de los fuertes. No sabía que la literatura podía hacer eso. Y, además, todavía no estoy seguro de que pueda. Hay algo en Lovecraft que "no es del todo literario" [subrayado del autor]».

H. P. Lovecraft nació el 20 de agosto de 1890 a las 9 de la mañana en el hogar familiar situado en el n.º 194 (hoy 454) de Angell Street, en Providence, capital del estado de Rhode Island. La casa fue derribada en 1961.

Howard Phillips Lovecraft era el hijo único de Winfield Scott Lovecraft (1853-1898) —representante de ventas de la Gorham Silver Company, dedicada al comercio de la plata, metales preciosos y joyería— y de Sarah Susan Phillips (1857-1921), la segunda de los cuatro hijos de Whipple Van Buren Phillips y Rhoby Alzada Place. Para ambos era su primer matrimonio, aunque los dos habían superado los 30 años cuando firmaron el enlace.

Lovecraft procedía de unos ancestros distinguidos: en cuanto a su línea materna, los Phillips, se podía rastrear su linaje casi hasta el "Mayflower", ya que los antepasados maternos se remontaban a la llegada de George Phillips a Massachusetts en 1630. Cuando Lovecraft visitó algunas de las tierras de sus antepasados al este del estado de Rhode Island, el apellido de Phillips era recordado con cariño y respeto (ver "Selected Letters" 2,81f.); su línea paterna también era de origen británico y Lovecraft pudo rastrear su apellido (Lovecraft o Lovecroft) hasta el siglo XV.

Al pequeño y solitario Howard le gustaba frecuentar parajes extraños y apartados para poder dar rienda suelta a su exaltada imaginación. En esos sitios (cuevas, arboledas alejadas, etc.) recreaba situaciones históricas o se ensimismaba en la observación de pequeños detalles que pasaban inadvertidos al resto de las personas, pero que a Lovecraft le fascinaban; como detenerse a escuchar a las hadas del bosque, o imaginar lo que podría existir en el espacio exterior. Quizás una de las razones por las que le gustaba tanto evadirse era por la estricta atadura a la que lo sometía su madre, diciéndole que él no debía jugar con niños de menor categoría o insistiendo en que era feo y que nunca llegaría a triunfar.

Cuando Lovecraft tenía casi tres años, su padre sufrió una crisis nerviosa en la habitación de un hotel de Chicago, donde se encontraba alojado por motivos de trabajo: le ingresaron en el Butler Hospital, Centro Psiquiátrico de Providence y fue incapacitado legalmente debido a una serie de trastornos de índole neurológica. A partir de ese momento y durante los cinco años siguientes, permaneció ingresado en ese hospital, donde murió el 19 de julio de 1898 con el diagnóstico de paresia general, una fase terminal de la neurosífilis. Aunque algunos biógrafos afirman que al niño Lovecraft le informaron de que su padre estaba paralizado y en estado comatoso durante ese período, todas las evidencias parecen demostrar que no fue así.

Con la muerte del padre de Lovecraft, la educación del niño recayó sobre su madre, sus dos tías (Lillian Delora Phillips y Annie Emeline Phillips) y en especial sobre su abuelo materno, un importante empresario llamado Whipple Van Buren Phillips. Todos residían en la casa familiar.

Lovecraft fue un niño prodigio: recitaba poesía a los dos años, leía a los tres y empezó a escribir a los seis o siete años de edad. Uno de los géneros que más le apasionó en su infancia fue el de las novelas policíacas, llevándolo incluso a formar la «Agencia de detectives de Providence» a la edad de trece años. A los quince escribió su primer relato como tal, "La bestia en la cueva", imitación de los cuentos de horror góticos. A los dieciséis escribía una columna de astronomía para el "Providence Tribune".

Su abuelo materno lo alentaba a la lectura y, siendo ésta una de sus aficiones favoritas, no tardó en pasarse horas y horas en la inmensa biblioteca de su abuelo. En ella descubrió (con un ejemplar de la "Ilíada" para niños entre las manos) el paganismo grecolatino y "Las mil y una noches", aunque a una edad muy temprana (los cinco años) se declaró ateo, convicción que mantuvo hasta su muerte. Esto ayudó a que su imaginación se desarrollase rápidamente en comparación con el resto de los chicos de su edad, produciéndole una falta de adaptación con estos. Cuando ellos querían jugar con espadas o a juegos fundamentalmente físicos, él prefería llevar a cabo entretenimientos más pausados e imaginativos, como representaciones históricas.

Debido a su falta de perseverancia y de salud, no asistió al colegio hasta los ocho años y tuvo que dejarlo después de un año. Durante su absentismo escolar, seguía leyendo con voracidad. Adquirió conocimientos de química y astronomía, llegando incluso a escribir como aficionado en algunas revistas científicas. Publicó varias revistas de circulación limitada, comenzando en 1899 con "La gaceta científica". Cuatro años después, regresó a la escuela pública Hope Street, donde cursó dos años y medio en la educación secundaria, hasta que abandonó definitivamente los estudios.

En 1904 falleció su abuelo materno, Whipple Van Buren Phillips, afectando sobremanera al joven Lovecraft, de catorce años de edad. La mala gestión de las propiedades y del dinero familiar dejó a la familia en tan malas condiciones económicas que se vieron obligados a mudarse al n.º 598 (hoy un dúplex en 598-600) de Angell Street. Lovecraft quedó tan afectado por la pérdida de su abuelo y la casa que le vio nacer, que consideró el suicidio durante un tiempo. En 1908, antes de su graduación, sufrió un colapso nervioso y no recibió su diploma. S. T. Joshi, biógrafo de Lovecraft, sugiere que este colapso pudo deberse a sus dificultades con las matemáticas, una materia que necesitaba dominar para convertirse en astrónomo profesional. Este fracaso en su educación (él quería estudiar en la Universidad de Brown) fue una fuente de desilusión y vergüenza hasta el final de sus días.

Aunque su mentalidad respondía a un racionalismo empirista, a Lovecraft le atraía la literatura imaginativa, seguramente influido por su escepticismo; encerrado en el pesimismo de la soledad y considerando que «el pensamiento humano es el espectáculo más divertido y más desalentador de la Tierra».
Lovecraft escribió algunos relatos de ficción, pero desde 1908 hasta 1913, principalmente trató la poesía, mientras vivía como un ermitaño y teniendo apenas contacto con el mundo exterior, a excepción de su madre y sus tías. Esta situación cambió al escribir una carta a la revista "Argosy", quejándose sobre lo insípido de las historias de amor de uno de los escritores más populares de la publicación, Fred Jackson. El debate entre los defensores de Jackson y Lovecraft en la columna de opinión llamó la atención de Edward F. Daas, presidente de la United Amateur Press Association (UAPA), que invitó a Lovecraft a unirse a ellos en 1914. La UAPA infundió un nuevo vigor a Lovecraft, sacándole de su voluntaria reclusión y le incitó a contribuir con sus poemas y ensayos. Un tiempo después, se convirtió en presidente de la UAPA, e incluso llegó a ser presidente de la NAPA, la rival de la UAPA. En 1917, a petición de algunos amigos, volvió a la ficción con historias mucho más pulidas, como "La tumba" y "Dagon". Esta última fue su primer trabajo publicado de forma profesional, apareciendo en "Weird Tales" en 1923. Sobre esta época, comenzó a formarse poco a poco una enorme red de admiradores y amigos, entre los que se encontraban Robert Bloch, Clark Ashton Smith y Robert E. Howard, creador este último de "Conan el Bárbaro". La extensión y frecuencia de sus cartas con esas amistades lo convertirían en uno de los más prolíficos escritores del género epistolar. Según su biógrafo L. Sprague de Camp, a lo largo de su vida Lovecraft escribió alrededor de 100.000 cartas.

La muerte de su padre habría tenido en el niño Lovecraft, debido a que prácticamente no tuvo tiempo de conocerlo, escasas repercusiones, pero la de su madre, en 1921, le habría supuesto una fuerte conmoción. Ocurrió después de una larga enfermedad, que algunos biógrafos suelen relacionar con la sífilis de su padre, aunque en cualquier caso la realidad es que la causa inmediata de la muerte fue un post-operatorio deficiente después de una intervención quirúrgica de vesícula biliar. Fue ingresada en el Butler Hospital, como su marido antes que ella. Durante su ingreso, escribía frecuentemente cartas a su hijo, con el que permaneció muy unida hasta su muerte, el 21 de mayo de 1921. Lovecraft contaba 31 años de edad.

Muchos críticos consideran a la madre de Lovecraft la causante de todos los comportamientos peculiares y un tanto extravagantes que el escritor mostró durante su existencia. Parece ser que después de la muerte de su esposo Winfield, Sarah, mujer tradicional y puritana, descargó todas las frustraciones de una burguesa venida a menos sobre su único hijo, sobreprotegiéndolo hasta límites demenciales y tratándolo como si fuera su único bien en la tierra, favoreciendo así el desarrollo de unas determinadas características de personalidad, comunes en estos casos, que condicionarían su patrón de conducta mientras vivió; entre otros aspectos destacados, prefiriendo las relaciones humanas con su pequeño entorno que le ofrecía una mayor seguridad antes que con un entorno social más amplio y desconocido que no controlaba debido a ese déficit en habilidades sociales óptimas por falta de aprendizajes adecuados en su infancia y adolescencia.

La muerte de su madre en 1921 y el agotamiento de lo poco que quedaba de la riqueza familiar lo llevaron a abandonar la idea de llevar una vida ociosa dedicada a la escritura, obligándolo a trabajar en pequeños encargos, que en la mayoría de las situaciones consistirían en retocar escritos de otros autores. Gracias a este tipo de trabajos conoció a muchos de los que después formarían el llamado Círculo de Lovecraft, entre ellos Robert E. Howard, Clark Ashton Smith, Robert Bloch, Frank Belknap Long, August Derleth y otros más. Para estos escritores y «amigos», Lovecraft presentaba una gran diferencia entre su personalidad de solitario introvertido y erudito a través de las cartas y su forma de ser en persona. Lo definían como entusiasta y generoso, creativo, prodigio de inteligencia y con una faceta racista que no abandonó hasta los últimos meses de su vida. 

Respecto a las mujeres, Lovecraft no había llevado una vida de muchas relaciones con el sexo opuesto. De hecho, el autor es recordado por su «aparente falta de masculinidad» tal como explica el cineasta Guillermo del Toro en el documental sobre su vida y obra "". El retrato que el citado director de cine hace del autor de Providence es el de un «tipo anglófilo que parecía haber llegado a América en el "Mayflower": un tipo raro que no se acostó con muchas mujeres».

Dos meses después de la muerte de su madre, Lovecraft acudió a una convención de escritores aficionados en Boston, donde conoció a Sonia H. Greene. Nacida en 1883, hija de inmigrantes judíos procedentes de Ucrania, era viuda y siete años mayor que Lovecraft. Se casaron en 1924, y se mudaron al municipio de Brooklyn, en la ciudad de Nueva York. Las tías de Lovecraft, muy tradicionales, no vieron con buenos ojos esta boda, ya que Sonia era una mujer de carácter fuerte, independiente, propietaria de una tienda de sombreros y escritora aficionada en la United Amateur Press Association. Inicialmente Lovecraft quedó embelesado con Nueva York, pero pronto la pareja se vio inmersa en dificultades económicas. Sonia perdió su tienda, tuvo problemas de salud y Lovecraft no conseguía encontrar un trabajo, por lo que su esposa se mudó a Cleveland al encontrar trabajo allí mientras Lovecraft se quedaba en el barrio Red Hook de Brooklyn, donde comenzó a sentir una profunda aversión por la vida neoyorquina. En efecto, la desalentadora realidad sobre la imposibilidad de mantener un trabajo en un lugar cuya población mayoritaria era inmigrante, entraba en un irreconciliable conflicto con la opinión sobre sí mismo, de ser un privilegiado caballero anglosajón, por lo que su racismo se galvanizó hasta el punto del miedo.

En 1926, Sonia y Lovecraft, todavía viviendo de forma separada, acordaron un divorcio amigable, donde Lovecraft alegó «las grandes divergencias entre ambos y los problemas económicos», aunque nunca se llevó a cabo. Debido al fracaso de su matrimonio, algunos biógrafos han especulado con la posibilidad de que Lovecraft fuera asexual, aunque Sonia dijera años más tarde de él que era un «adecuado y excelente amante».

De vuelta a Providence el 17 de abril de 1927, convivió con sus tías durante los años siguientes, en una «espaciosa y marrón casa de madera victoriana» en la calle Barnes n.º 10 (la dirección del Dr. Willett en "El caso de Charles Dexter Ward") hasta 1933. Allí es en donde se ve superado por la sensación de fracaso que lo invade, abandonándose a la soledad y la frustración. En esta época disfruta de paseos nocturnos, que repercuten en su hundimiento personal, y crean una esfera invisible de miedos que nunca le permitirán recuperarse si bien, paralelamente, contribuyen a su máximo esplendor literario. En estos fructíferos años escribió la gran mayoría de sus obras más conocidas, como "La llamada de Cthulhu" en 1926, "En las montañas de la locura" en 1931 o "El caso de Charles Dexter Ward", principalmente publicadas en la revista "Weird Tales".

En esos años visitó a varios anticuarios residentes en Quebec, Filadelfia y algunos lugares de Nueva Inglaterra, como Vermont y Massachusetts, y siguió manteniendo su enorme correspondencia. A sus viejos amigos añadió otros muchos escritores jóvenes, como D. W. Rimmel, R. H. Barlow o Robert Bloch, a los que aconsejaba en sus carreras y supervisaba trabajos. Mostró preocupación con las condiciones políticas y económicas del país. En la Gran Depresión, mostró su apoyo a Roosevelt y se convirtió en un socialista moderado, abandonando su rancio conservadurismo, mientras continuaba estudiando una gran variedad de temas, desde filosofía a literatura o historia de la arquitectura.

Los últimos dos o tres años de su vida fueron muy apurados económicamente. A pesar del duro trabajo y de sus esfuerzos como escritor, la pobreza en la que vivía aumentó. En 1932 su querida tía, la señora Clark, murió, y se vio obligado a mudarse a una pequeña y exigua habitación de alquiler con su otra tía, la señora Gamwell en 1933, situada en la calle College 66, detrás de la biblioteca John Hay (la dirección actual de esta casa es "65 Prospect Street"). Además, su íntimo amigo Robert E. Howard, al que nunca llegó a conocer en persona, se suicidó el 11 de junio de 1936, dejándolo desconcertado y profundamente apenado.

Sus últimas obras fueron incrementando en longitud y complejidad, lo que dificultaba la venta pues las revistas pulp rechazaban los textos largos, lo que llevó a Lovecraft a la necesidad de trabajar de revisor y corrector para otros autores, de escritor fantasma, como en "El diario de Alonzo Typer" (1938), "The Mound" (1940) y "Winged Death" (1940), y también en poesía y otros estilos literarios.

Sobre los problemas económicos que sufrió el escritor a lo largo de toda su vida, el novelista francés Michel Houellebecq escribió:

En sus últimos años, su naturaleza enfermiza y la desnutrición fueron minando su salud. Su anormal sensibilidad a cualquier temperatura inferior a los 20° se agudizó hasta el punto de que se sentía realmente enfermo a tales temperaturas. Durante el último año de su vida, sus cartas estaban llenas de alusiones a sus malestares y dolencias. A finales de febrero de 1937, cuando contaba con cuarenta y seis años, ingresó en el hospital Jane Brown Memorial, de Providence. Allí murió a primeras horas de la mañana del 15 de marzo de 1937, de cáncer intestinal complicado con la denominada enfermedad de Bright. Aunque actualmente este término no suele utilizarse se refiere a una serie de enfermedades inflamatorias de los riñones. Es decir, parece ser que Lovecraft tuvo una complicación de su enfermedad tumoral intestinal con una grave insuficiencia renal que provocó su fallecimiento. El diagnóstico de su enfermedad tuvo lugar apenas un mes antes de su muerte.

Fue enterrado tres días después en el panteón de su abuelo Phillips en el cementerio de Swan Point; aunque su nombre está inscrito en la columna central, ninguna lápida señala su tumba. Muchos años después de su muerte, en la lápida que le erigió un grupo de aficionados, puede leerse una línea tomada de una de las miles de cartas que escribió a sus corresponsales: «Yo soy Providence».

El nombre de Lovecraft es sinónimo de ficción de horror; sus escritos, particularmente los Mitos de Cthulhu, han influido desde los años 60 a los autores de ficción a lo largo y ancho del mundo, y se pueden encontrar elementos lovecraftianos en novelas, películas, música, videojuegos, cómics y dibujos animados. Por ejemplo, los villanos de Gotham City en "Batman" son encarcelados en el Asilo Arkham, en Arkham, una invención de Lovecraft. Muchos escritores modernos de terror, como Stephen King, Bentley Little o Joe R. Lansdale, por nombrar a unos pocos, han citado a Lovecraft como una de sus más importantes influencias.

Lovecraft fue un escritor casi desconocido en su propia época, aunque sus historias se habían hecho un lugar en publicaciones como "Weird Tales", solo los aficionados a este tipo de literatura conocían su nombre. De entre ellos, mantenía regularmente correspondencia con otros escritores contemporáneos, como Clark Ashton Smith y August Derleth, gente que se convirtió en buenos amigos suyos, incluso sin haberse nunca conocido en persona. Este nutrido grupo de escritores llegó a conocerse como el Círculo de Lovecraft, ya que tomaban prestados elementos de las historias de Lovecraft -libros misteriosos con nombres inquietantes, panteones de dioses extraterrestres, como Cthulhu y Azathoth, y lugares como Miskatonic y Arkham- para usarlos en sus propias historias, con la bendición y ánimo de Lovecraft; incluso en ocasiones con su ayuda, la cual solía extralimitarse de la función de un editor para re-elaborar los relatos. Fueron los esfuerzos del Círculo de Lovecraft —particularmente los de August Derleth— los que evitaron que el nombre y las historias de Lovecraft desaparecieran completamente en la oscuridad tras la muerte del autor.

Después de su fallecimiento, el Círculo de Lovecraft siguió contribuyendo a su leyenda. August Derleth fue, probablemente, el más prolífico de todos ellos, ya que amplió y extendió la visión de Lovecraft. Las contribuciones de Derleth han sido objeto de mucha controversia, ya que mientras Lovecraft nunca consideró a su panteón de dioses extraterrestres más que como parte de la trama argumental, Derleth creó una cosmología completa, con una guerra entre Los Antiguos o Dioses arquetípicos, como Hypnos o Ulthar, y los Dioses Primigenios, como Cthulhu y Nyarlathotep. Además, asoció a los Dioses Primigenios a los cuatro elementos. Algunos seguidores de Lovecraft no han visto con buenos ojos dichas modificaciones, puesto que parecen contradecir la visión de Lovecraft de un universo desordenado y sin plan, donde los seres menos malevolentes simplemente no se interesaban en la Humanidad. La pregunta que todo fan se hace es: ¿Habría aprobado Lovecraft las extensiones de Derleth? Se dice que Lovecraft era muy comprensivo sobre esta clase de adiciones y modificaciones, por lo que probablemente hubiera dado el visto bueno a Derleth, pero no lo hubiera adoptado para sus propias historias. Si había un Círculo de Lovecraft, entonces la versión de Derleth sería un añadido interesante, pero no formaría parte del Círculo.

El trabajo de Lovecraft ha sido agrupado en tres categorías por algunos críticos. Mientras que Lovecraft prefirió no referirse a estas categorías él mismo, sí escribió en alguna ocasión: «Existen mis obras poeanas y mis obras dunsanianas [pero] ¿dónde están mis obras lovecraftianas?».


Algunos críticos no ven la diferencia entre el Ciclo del Sueño y los Mitos de Cthulhu, a menudo señalando la recurrencia del "Necronomicón" y los subsiguientes "dioses". Una explicación frecuentemente argüida es el que el Ciclo del Sueño pertenece más a un género de fantasía en tanto que los Mitos de Cthulhu pertenecen a la ciencia ficción.

Las pesadillas que sufría Lovecraft le sirvieron de inspiración directa para su trabajo, y es quizás una visión directa de su inconsciente y su simbolismo explica su continuo revuelo y popularidad. Todos estos intereses le llevaron a apreciar de manera especial el trabajo de Edgar Allan Poe, quien influyó fuertemente en sus primeras historias, de atmósfera macabra y miedos ocultos que acechan en la oscuridad. El descubrimiento de Lovecraft de las historias de Edward Plunkett, Lord Dunsany, llevó su literatura a un nuevo nivel, resultando en una serie de fantasías que tomaban lugar en la tierra de los sueños. Fue probablemente la influencia de Arthur Machen, con sus bien construidos cuentos sobre la supervivencia del antiguo mal y de sus creencias místicas en misterios ocultos que yacían detrás de la realidad que lo que ayudó finalmente a inspirar a Lovecraft a encontrarse a sí mismo a partir de 1923.

Otra inspiración provino de una fuente insospechada: los avances científicos en áreas como la biología, astronomía, geología y física, que reducían al ser humano a algo insignificante, impotente y condenado en un universo mecánico y materialista, un pequeñísimo punto en la vastedad infinita del cosmos. Estas ideas contribuyeron de forma decisiva a un movimiento llamado cosmicismo, y que le dieron a Lovecraft razones de peso para su ateísmo.

Sobre este asunto, Rafael Llopis, probablemente el mejor conocedor de la figura y la obra de Lovecraft en el contexto de la lengua española, afirma en el prólogo a la antología fundamental "Los mitos de Cthulhu":
Llopis hace notar más adelante cómo recuerda el misticismo siniestro de los mitos lovecraftianos el «estilo bíblico, los nombres sonoros y exóticos, el irrealismo onírico, el fondo numinoso de religión arcaica» que impregna relatos poeanos como «Silencio» o «Sombra», o también los "Cuentos de un soñador", debidos a otro precursor de Lovecraft, Lord Dunsany.

Sobre este asunto, Llopis (también psiquiatra) afirma en su "Historia natural de los cuentos de miedo" (2013): «Así, pues, la obra de Lovecraft contiene el germen de una religión primitiva, bárbara y cruel, llena de horror primordial. Y ese horror deriva también del juego dialéctico entre la fascinación que en él ejercía el caos de la subconsciencia prehumana y su propio terror racionalista a la regresión de la mente, a la pérdida del control consciente de sus pensamientos y actos. Para su mente rígida y estrictamente lógica, el caos representaba un peligro mortal, pero a la vez era liberación de un superyó tiránico y entrega a un mundo íntimo y ancestral que le atraía como un abismo prohibido. Otra contradicción importante, íntimamente vinculada a la anterior, es la que surge en Lovecraft entre su amor y su horror al pasado».

Los Mitos de Cthulhu integran un panteón de deidades alienígenas extradimensionales y horrores que se alimentan de la humanidad y que tienen trazos de antiguos mitos y leyendas. El término "Mito de Cthulhu" fue acogido por el autor August Derleth después de la muerte de Lovecraft. El autor se refería a su mitología artificial como "Yog-Sothothería".

Sus historias crearon uno de los elementos de mayor influencia en el género del horror: el "Necronomicón", el escrito secreto del árabe Abdul Alhazred. El impacto y la fortaleza del concepto del mito ha llevado a algunos a concluir que Lovecraft basó su trabajo en mitos pre-existentes y en creencias ocultistas. Ediciones apócrifas del "Necronomicón" también han sido publicadas a través de los años.

Su prosa es anticuada, y frecuentemente usaba vocabulario arcaico u ortografía en desuso, así como adjetivos de uso poco habitual como (gibosa, ciclópeo o atávico), con frecuentes intentos de transcribir dialectos, que han sido calificados de imprecisos. Su trabajo, al ser Lovecraft un anglófilo, está plasmado en un inglés británico utilizando comúnmente escritura anacrónica.

Lovecraft fue un prolífico escritor de cartas. Durante su vida escribió miles de ellas, aunque no se conoce el número exacto. Una estimación de 100.000 parece ser acertada, como apunta L. Sprague de Camp. En algunas ocasiones las fechaba 200 años antes de la fecha en que habían sido escritas, lo que las databa en la época colonial, antes de la Guerra de Independencia de los Estados Unidos (una guerra que lo hería por su anglofilia). Explica que, según él, los siglos XVIII y XX habían sido los mejores; el primero siendo el siglo de nobleza y de gracia y el segundo de la ciencia, en tanto que el siglo XIX, en particular la Era Victoriana, habría sido un error.

Se suelen señalar en la evolución literaria de Lovecraft diversas etapas marcadas por el influjo de sus autores favoritos en esas épocas. Cada fase tuvo su periodo de apogeo, mas no es posible precisar una fecha exacta de inicio y término dado que las tres se superponen.




Otros autores distinguen, por el contrario, ciclos o proyectos narrativos más específicos:


En las historias de Lovecraft se repiten varios temas:

Los protagonistas de las historias de Lovecraft siempre son conducidos a la «unión de esos disociados conocimientos», y también así comienzan muchas de sus historias. Cuando tal cosa ocurre, la mente del protagonista o investigador, por lo general, queda destruida por la abismal enormidad de lo descubierto, al ser incapaz de asimilar semejante conocimiento. Aquellos que se cruzan con manifestaciones «vivas» de lo incomprensible, se vuelven locos.

Aquellos personajes que intentan hacer uso de este conocimiento están, invariablemente, condenados. Algunas veces su trabajo atrae la atención de seres malévolos; ocasionalmente, son aniquilados por monstruos de su propia creación.

Los seres de los Mitos de Lovecraft a menudo se sirven de humanos. Cthulhu, por ejemplo, es venerado bajo distintos nombres por diferentes cultos alrededor del mundo, como los esquimales de Groenlandia y los practicantes del vudú de Luisiana.
Los adoradores son utilizados por Lovecraft debido a motivos narrativos como ayuda en el hilo conductor de la historia. A veces intervienen de forma directa en la acción.
La mayoría de los seres de los Mitos son extremadamente poderosos para ser derrotados por humanos, y su conocimiento directo significa, normalmente, que la víctima se vuelva loca. Cuando se llega a un acuerdo con ellos, Lovecraft necesita una forma de proveer una estructura dramática para construir el hilo tensor sin llevar la historia a un final prematuro. Los adoradores le ofrecen la forma de revelar información sobre sus «dioses» en pequeñas dosis, y haciendo posible para los protagonistas ganar batallas temporales. Lovecraft, como sus contemporáneos, imaginó «salvajes» cercanos a la Tierra, es decir, en el caso de Lovecraft, cercanos a Cthulhu.

A propósito de esta temática, Jorge Luis Borges escribió el cuento "There are more things", incluido en el volumen "El libro de arena", como homenaje a Lovecraft.

Otro tema recurrente en las historias de Lovecraft es la idea de que los descendientes en una línea de sangre nunca pueden escapar de los crímenes cometidos por sus antepasados, si éstos han sido lo suficientemente atroces. Los descendientes pueden estar alejados en tiempo y en espacio (y, además, en culpabilidad) del acto en sí mismo, pero la sangre se lo revelará ("Las ratas en las paredes", "El horror oculto", "Arthur Jermyn", "El alquimista", "La sombra sobre Innsmouth" y "El caso de Charles Dexter Ward").

Un ejemplo de crimen que Lovecraft considera lo suficientemente atroz para que tenga esta clase de consecuencias es el canibalismo ("El grabado en la casa" y "Las ratas en las paredes").

A menudo, en las historias de Lovecraft, el protagonista es incapaz de controlar sus propias acciones, o encuentra imposible cambiar el curso de los acontecimientos. Muchos de estos personajes escaparían del peligro si simplemente corrieran en dirección opuesta, aunque esta posibilidad nunca surge o es de alguna forma sometida por una entidad externa, como en "El color que cayó del cielo". Con frecuencia estos sujetos se encuentran bajo la influencia de algún ser malévolo u otros seres. Con la misma inevitabilidad que el destino del ancestro, huir o suicidarse no proporciona la completa seguridad de escapar ("La cosa en el umbral", "El intruso", "El caso de Charles Dexter Ward", etc.) En algunos casos, este destino se manifiesta para toda la humanidad, y no existe escape posible ("En la noche de los tiempos", "La sombra sobre Innsmouth"). En relatos como "Los sueños en la casa de la bruja", la poética de Lovecraft apunta a la imposibilidad de triunfo de los saberes popular y científico (las leyendas y la ciencia) frente al horror de lo desconocido.

Lovecraft juega a menudo con la idea de la civilización que lucha penosamente contra elementos bárbaros y primitivos. En algunas historias esta lucha es a nivel individual; la mayoría de sus protagonistas poseen una cultura y unos estudios elevados, pero se ven gradualmente corrompidos por una influencia maligna.

En estas historias, la «maldición» es normalmente hereditaria, o por cruzarse con seres no humanos ("Hechos tocantes al difunto Arthur Jermyn y su familia" en 1920, "La sombra sobre Innsmouth" en 1931) o a través de cierta influencia mágica ("El caso de Charles Dexter Ward"). La degradación física y mental aparecen de forma conjunta. El tema de la «sangre corrompida» podría representar la preocupación de Lovecraft respecto la historia de su familia, particularmente la muerte de su padre debido a que Lovecraft sospechaba que fue a causa de un desorden sifilítico.

En otras historias, una sociedad al completo es amenazada por la barbarie. A veces, dicho barbarismo es representado por una amenaza externa, con una civilización destruida por la guerra ("Polaris"). De vez en cuando, un pequeño grupo de gente cae en decadencia y surge espontáneamente un atavismo ("El horror oculto"). Mucho más frecuentemente, tales historias involucran a una cultura civilizada que es gradualmente socavada por una clase baja marginal, sin educación ni derechos, que se halla influida por fuerzas inhumanas.

Un componente común en el trabajo inicial de Lovecraft es asociar la virtud, el intelecto, una clase elevada, civilización y racionalidad a la raza blanca, que a menudo contrapuso con el corrupto, intelectualmente inferior, incivilizado e irracional, que asoció con gente de clase baja, racialmente impura, y/o no de raza europea, de piel oscura, que frecuentemente eran los villanos en sus historias.

Algunas de sus opiniones racistas más cruentas pueden localizarse en sus primeras poesías escritas en su juventud, particularmente en "On the creation of Niggers" y "New England Fallen" (ambas de 1912). En "On the creation of Niggers", Lovecraft plasma de una forma muy cruda sus prejuicios, caracterizando explícitamente a la gente negra como subhumanos:

En "La llamada de Cthulhu", Lovecraft describe a un grupo mestizo de adoradores de Cthulhu:
Lovecraft también expresó en alguna ocasión creencias racistas y etnocéntricas en su cartas personales En una carta fechada el 23 de enero de 1920, Lovecraft escribió:
En "", Lovecraft describe a un varón afroamericano que acaba de fallecer:
En "El horror de Red Hook", un personaje es descrito como «un árabe con una odiosa boca negroide». En la obra "El lazo de Medusa", escrito para Zealia Bishop, la sorpresa final de la historia —tras revelar que el villano de la historia es una medusa vampírica— es que ella 

En "El caso de Charles Dexter Ward", se presenta de forma condescendiente a una pareja afroamericana: 
En un claro contraste con el propietario, al parecer extranjero::
Los narradores en "La calle", "", "Él", "La llamada de Cthulhu", "La sombra sobre Innsmouth", "El horror de Red Hook", y en muchos otras historias, expresan sentimientos que podrían ser considerados hostiles hacia los judíos. Se casó con una mujer ucraniana de ancestros judíos, Sonia Greene, quien más tarde comentó que tenía que recordarle constantemente sus raíces cuando realizaba algún comentario antisemita. «Siempre que nos encontrábamos en las calles de Nueva York, abarrotadas de personas de distintas nacionalidades y credos —escribió Greene después de su divorcio— Howard venía lívido de la rabia. Parecía que iba a perder la cabeza».

Hasta cierto punto, las ideas de Lovecraft referentes a la raza reflejaban actitudes comunes en esa época, y particularmente las leyes de segregación racial se hacían cumplir en la mayor parte del territorio estadounidense, y muchos estados promulgaban leyes eugenésicas y prohibiciones en contra del mestizaje, que también eran comunes en áreas no católicas en Europa. Un movimiento popular durante la década de 1920, dio como resultado en una drástica restricción en la inmigración hacia los Estados Unidos, culminando en la Ley de Inmigración de 1924, que ponía de manifiesto testimonios de expertos ante el Congreso de Estados Unidos sobre la amenaza hacia la sociedad americana en la asimilación de «personas de baja cultura» del este y del sur de Europa.

Lovecraft era en un principio un anglófilo confeso, y sostenía que la cultura inglesa era el pináculo comparativo de la civilización, y consideraba a los descendientes de los primeros ingleses en América como una rama de segunda clase, y todos los demás, por debajo de ellos (por ejemplo, su poema . Su amor por la historia y la cultura inglesa se ve a menudo reflejado en su trabajo (como la nostalgia del Rey Kuranes por Inglaterra en "La búsqueda onírica de la desconocida Kadath").

Las ideas de Lovecraft sobre la eugenesia se extendían a menudo sobre sus personajes de raza blanca. Mostró una mayor simpatía por la raza caucásica y los grupos culturales europeos. El narrador de "Aire frío" habla despectivamente de los pobres hispanoamericanos de su vecindario, pero respeta al rico y aristócrata Dr. Muñoz, por sus orígenes celtíberos, y porque es «un hombre de cuna, culto y de buen gusto». Los descendientes degenerados de los inmigrantes holandeses en las Montañas Catskill, «quienes corresponden exactamente con la basura blanca en el sur» ("Más allá del muro del sueño", 1919), son elementos comunes. En "El Templo", el narrador es un capitán de un U-Boot de la Primera Guerra Mundial cuya fe en su «inquebrantable voluntad germánica» y la superioridad de su patria lo llevan a ametrallar a los supervivientes que se encontraban en botes salvavidas; más tarde, asesina a su propia tripulación, mientras lo ciega la maldición que ha atraído sobre él. De hecho, según "Lovecraft: Una biografía", por L. Sprague de Camp, Lovecraft estaba horrorizado por los informes de violencia antisemita en Alemania (antes de la Segunda Guerra Mundial, que no viviría para ver), sugiriendo que el escritor a pesar de todo, se oponía al exterminio de aquellos que consideraba «inferiores».

El racismo de Lovecraft ha sido un foco continuado de interés académico e interpretativo. S. T. Joshi, uno de los primeros eruditos en Lovecraft, observa que «no hay ninguna negación del racismo en Lovecraft, ni puede ser interpretada simplemente como “típico de su época”, ya que parece que Lovecraft expresó sus opiniones más pronunciadamente (aunque generalmente no para su publicación) que muchos otros contemporáneos. Es también absurdo negar que el racismo entra en su ficción». Michel Houellebecq defiende que «el odio racial» proporcionaba la fuerza y la inspiración emocional para muchas de las mejores obras de Lovecraft.

El antagonismo racista de Lovecraft es un corolario de su noción nihilista del determinismo biológico: "En las montañas de la locura", donde los exploradores descubren pruebas de una raza totalmente extraterrestre (Antiguos) que creó seres humanos mediante bioingeniería, pero fue destruida finalmente por sus brutales esclavos, los Shoggoth. Incluso después de que varios miembros de la expedición mueran a manos de los Antiguos y los Shoggoth, se aprecia cierta simpatía por parte del narrador hacia estos seres: 

Estas líneas del pensamiento en la visión del mundo de Lovecraft - racismo y una romántica defensa reaccionaria del orden cultural frente a la degeneración del mundo moderno - han conducido a algunos estudiosos a establecer una afinidad especial con el aristocráta, antimodernista y tradicionalista Julius Evola:
Por otra parte, algunos autores consideran que el racismo de Lovecraft era más que nada de índole cultural e intelectual, pasivo e introvertido (como lo evidencía el hecho de que el poeta Samuel Loveman, uno de sus mejores amigos, quien era judío y homosexual, no se enteraría del antisemitismo y homofobia de Lovecraft hasta varios años después de la muerte de este a través de Sonia Greene), más que brutalmente biológico, proactivo y extrovertido -como el de los primeros nazis de esa época quienes ya promovían el odio y la agresión a otras razas en forma activa y despiadada- siendo que Lovecraft expresa en algunas de sus historias cierta admiración a personas de distintos orígenes que han asimilado las costumbres, buenos modales y artes anglosajonas y por el hecho de haberse casado con una judía a quien él mismo consideraba una mujer sumamente inteligente y "bien asimilada".

En sus últimos años la antipatía de Lovecraft por ciertas razas y culturas específicas se sublimó en un desprecio a la ignorancia, soberbia y egoísmo de la especie humana en general (incluyendo a los sajones) y la risible e irónica insignificancia de la humanidad y sus vicios ante la magnificencia y misterio del universo no conocido, evidente en el desarrollo y desenlace de la mayoría de sus últimas obras de horror cósmico.

Las mujeres en la obra de Lovecraft escasean, y no son compasivas, comprensivas ni amables. Los pocos personajes femeninos en sus historias, - como Asenath White (si bien de hecho era un perverso hechicero que se había apoderado del cuerpo de una inocente chica) en "La cosa en el umbral" y Lavinia Whateley en "El horror de Dunwich" - son, de forma invariable, sirvientas de las fuerzas del mal. El romance se encuentra casi ausente de sus historias; cuando aparece el amor, es normalmente de forma platónica ("El árbol, Cenizas"). Sus personajes viven en un mundo donde la sexualidad tiene connotaciones negativas - si es reproductiva, suele dar nacimientos de seres sub-humanos "El horror de Dunwich" -. En este contexto, puede ser de ayuda prestar atención a la escala del horror de Lovecraft, que es frecuentemente descrito por "horror cósmico". Operando a escalas cósmicas, tal y como operan estas historias, asignan a la humanidad un rol insignificante, por lo que no es a la sexualidad femenina a lo que estos relatos niegan su rol positivo y vital, es a la sexualidad humana en general.

Además, Lovecraft sostiene en una carta privada (enviada a una de sus amigas escritoras y poetisas) que la discriminación en contra de la mujer es una superstición oriental, de la cual los arios deberían liberarse. Dejando el racismo aparte, la carta parece excluir una misoginia consciente, como de hecho, parece estar descartada de su vida privada.

Al llegar el siglo XX, la dependencia y confianza del ser humano respecto la ciencia fue aumentando significativamente, abriendo nuevos mundos y proporcionando herramientas mediante las cuales se puede comprender mucho mejor el mundo en el que se vive. Lovecraft aprovechaba huecos, lagunas en el conocimiento del universo y las convertía en tenebrosas ciénagas del horror. En la obra "El color que cayó del cielo", se pone de manifiesto la incapacidad de la ciencia para comprender un extraño meteorito, lo que lleva a un paroxismo demencial.

En una carta dirigida a James F. Morton en 1923, Lovecraft define la Teoría de la Relatividad de Albert Einstein como un lanzamiento del mundo al caos y haciendo del cosmos una broma. En otra carta, escrita en 1929 y dirigida a Harris Woodburn, Lovecraft especula con la comodidad que proporciona la ciencia y el riesgo que supondría que se colapsara. Es más, en una época donde el ser humano veía la ciencia como algo tremendamente poderoso e ilimitado, Lovecraft se dio cuenta de su potencial alternativo y sus tenebrosos resultados.

El estilo de Lovecraft es muy característico e inconfundible, pero no era lo que se dice un "estilista"; se limitaba a conseguir un tono siempre serio y solemne. Comparado, por ejemplo, con otro maestro del género de terror, Montague R. James, carece de ironía, su cultura se muestra impostada y crea atmósferas desde el principio, no como M. R. James, quien las va levantando poco a poco acumulando contrastes y sutilezas hasta el desastre final. Sin embargo, y por el contrario, es el rey del tono; usa demasiados adjetivos y palabras polisílabas y un "tempo" narrativo lento y moroso que logra distanciar a un lector acostumbrado a lecturas más rápidas y directas, menos oscilantes y sinuosas, y lo instala en otra órbita en la que se siente perdido. Además, repite machaconamente ciertas palabras que van predisponiendo poco a poco la sensibilidad del lector en el nivel que le interesa ("atávico", "numinoso", "inmemorial", "arcano"...).

Como suele narrar desde el punto de vista de un erudito, usa un inglés arcaico y avejentado que le sirve para conferir una falsa autoridad polvorienta y la patina del tiempo a lo que narra, inventándose una bibliografía ficticia de grimorios en latín, árabe o hebreo (el "Necronomicón" de Abdul Alhazred, "De Vermis Mysteriis", el "Liber Ivonis" aportación de su discípulo Robert Bloch, el Cultes de Goules del Conde D'Erlette etc.). También le ayuda a desorientar y desenfocar el juicio del lector el empleo de la primera persona, que funde lector y protagonista, pero con la argucia de que este último suele ser un solitario sin vida ordinaria ni necesidades sociales ni placeres confesos, ensimismado y cercano al suicidio y la locura, haciendo que asimile su psicología atormentada y acrecentando su miedo. Describe todo con prolijidad... pero nunca, salvo al final de su carrera -y quizá por la reescritura de su testaferro August Derleth- al monstruo, al que deja obrando en un plano abstracto mucho más ominoso. Gusta de esparcir sensaciones vagas e indefinibles que propenden a crear ilusiones de inseguridad y trascendencia, desordenando la realidad espacio-temporal. Su escritura tiende a una especie de religiosidad ritual de ecos paganos pero arreligiosa, pues el autor era ateo: Lovecraft excluye conscientemente la religión, que podría ofrecer algún consuelo ante el horror inevitable.

A partir de los años 60, la obra de Lovecraft, aparte de gozar de adaptaciones más o menos fidedignas al cómic, inspiraría obras originales. Es el caso de "Lone Sloane" (1966) de la que su autor, Philippe Druillet, diría Otras muchas obras, como "Tales Of Peter Hypnos" (1975-76) de Josep María Beà, también se muestran deudoras de la obra del escritor de Providence.

Además de ser inspiración de trabajos literarios, el mundo de la música ha sido también muy influido por Lovecraft. Grupos de metal extremo (géneros como el "black metal", "death metal", etcétera) las letras de algunas de sus canciones abarcan pasajes de algunas obras del autor, así como abordan de igual manera la mitología lovecraftiana. Algunos grupos son: Morbid Angel, Arzachel, Shub Niggurath, Mercyful Fate, Metallica, Draconian, Cradle of Filth, Internal Suffering, Tiamat e Iron Maiden. El músico argentino Claudio Gabis compuso lo que en su discografía se conoce como "Trilogía Fantástica", las canciones "Más allá del valle del tiempo", "Fiebre de la ruta" y "El viaje de Lord Dunsany", basadas en la literatura de Lovecraft.

Lovecraft es considerado como uno de los autores de literatura fantástica más influyentes del siglo XX y un maestro del género de terror literario.









</doc>
<doc id="15369" url="https://es.wikipedia.org/wiki?curid=15369" title="Fisiología mamaria">
Fisiología mamaria

Durante la pubertad las mamas ven su crecimiento estimulado por la hormonas sexuales que culmina sobre los 20 años de edad. El desarrollo del tejido adiposo y conectivo aumenta bajo la influencia de otras hormonas como progesterona, prolactina, corticoides y hormona del crecimiento.

El aumento en los niveles de estrógenos y progesterona estimulan el desarrollo glandular.

La lactancia tiende a mantener los cambios ocurridos durante el embarazo. Al inicio de la misma y durante las primeras horas, los repetidos intentos de succión por parte del neonato acaban por provocar la salida de una secreción espesa y amarillenta, rica en colesterol, llamada calostro.

La producción de leche lactantes (tiene un contenido en colesterol elevado) que facilitaría la evacuación del meconio del intestino del recién nacido. Pocas horas después la mama deja de producir calostro para secretar la llamada leche de transición que luego modificará su composición para dar lugar a la leche normal o madura. 

La composición de la leche normal incluye proporciones elevadas de agua. Aunque podría parecer que esta circunstancia limita el aporte de nutrientes al bebé es importante considerar que una osmolaridad elevada no es fácil de equilibrar por parte del riñón del lactante que, en sus primeros meses, debe extraer el agua que necesite de la leche y sin aportes adicionales.

En la leche se encuentran numerosos nutrientes así como vitaminas y minerales y otras sustancias diversas, destacando las inmunoglobulinas. Estas moléculas actúan como anticuerpos que proporcionan al niño una protección importante ante potenciales infecciones. Las llamadas leches maternizadas, elaboradas a partir de leche de vaca, carecen de este componente. Esta es una de las razones por las que la OMS recomienda que las madres recurran a la lactancia materna durante, al menos, los primeros seis meses de vida. 

La lactancia materna natural parece reforzar de manera particular el vínculo emocional madre - hijo de una manera tan sólida como primaria, lo que proporciona una satisfacción particular a ambos. De hecho algunas madres prolongan la lactancia de su hijo durante dos años o más, aún a pesar de que el niño toma ya una alimentación muy variada y completa. En teoría, la prolongación de la lactancia tiene además otra consecuencia: durante la misma los niveles de prolactina en sangre se mantienen elevados, lo que impide que se produzca una secreción adecuada de hormona foliculoestimulante (FSH) y luteinizante (LH) con lo que en ocasiones no se produce la ovulación, pero la lactancia no es eficaz como método anticonceptivo natural, por lo que durante todo el periodo de lactancia debe usarse algún método anticonceptivo para evitar embarazos.

Debido a que la función fisiológica de la mama reconocida clásicamente es la producción de leche, con frecuencia se olvida que la misma desempeña un papel en la función sexual en muchas culturas humanas. 

En las sociedades occidentales tecnológicamente desarrolladas muchos varones se sienten atraídos, sobre todo, por los senos de gran tamaño. Otros, sin embargo, los prefieren de un tamaño limitado aunque turgentes y firmes. En realidad, el tamaño y la forma, así como la consistencia, no predicen en absoluto la capacidad de la mama para producir eficazmente leche. De hecho, gran parte de la mama es tejido adiposo, que, en parte, tiene funciones estructurales y de sostén y que contribuye a proporcionar atractivo sexual a la mujer, pero no se relaciona con la producción de leche.



</doc>
<doc id="15370" url="https://es.wikipedia.org/wiki?curid=15370" title="Janis Joplin">
Janis Joplin

Janis Lyn Joplin (Port Arthur, 19 de enero de 1943 - Los Ángeles, 4 de octubre de 1970) fue una cantante estadounidense de "rock and roll" y "blues" caracterizada por su poderosa voz y la gran intensidad de su interpretación.Fue una de las estrellas de rock más grandes de su época. Después de lanzar tres álbumes, murió de una sobredosis de heroína a la edad de 27 años. Un cuarto álbum, Pearl, fue lanzado en enero de 1971, poco más de tres meses después de su muerte. Este álbum alcanzó el número uno en las listas de Billboard.

En 1967, Joplin saltó a la fama durante una presentación en el Monterey Pop Festival, donde fue la cantante principal de la entonces poco conocida banda de rock psicodélico de San Francisco, Big Brother and The Holding Company. Después de lanzar dos álbumes con la banda, dejó Big Brother para continuar como solista con sus propios grupos de apoyo, primero Kozmic Blues Band y luego Full Tilt Boogie Band. Apareció en el festival de Woodstock y en el recorrido del tren Festival Express. Cinco singles de Joplin fueron a Billboard Hot 100, incluyendo una versión de la canción "Me and Bobby McGee", que alcanzó el número 1 en marzo de 1971. Sus canciones más populares incluyen sus versiones de "Piece of My Heart", "Cry Baby", "Down on Me", "Ball 'n' Chain" y "Summertime"; y su canción original "Mercedes Benz", su grabación final.

Janis fue un símbolo femenino de la contracultura de la década de 1960 y la primera mujer en ser considerada una gran estrella del "rock and roll". En 1995 entró en el Salón de la Fama del Rock y en 2004 la revista "Rolling Stone" la colocó en el lugar 46 de los 100 mejores artistas de todos los tiempos; mientras que en 2008 la ubicó en el puesto 28 de los mejores cantantes de todos los tiempos. En 2013 recibió una estrella en el Paseo de la Fama de Hollywood. En 1999, fue elegida como la tercera mejor artista femenina del "rock" en la lista 100 Greatest Women in Rock realizada por VH1. Fue admitida en el Salón de la Fama del Rock and Roll en 1995. Audiencias y críticos por igual se refirieron a su presencia escénica como "eléctrica".

Janis Joplin sigue siendo uno de los músicos más vendidos en los Estados Unidos, contando con certificaciones de la Asociación de la Industria de la Grabación de América por 15,5 millones de álbumes vendidos tan solo en los Estados Unidos.

Nació el 19 de enero de 1943 en Port Arthur, localidad industrial de Texas. Sus padres, Seth (1910-1987), que trabajaba en una refinería, y Dorothy (1913-1998), que había destacado cantando en su instituto, habrían querido que Janis fuera maestra. Tenía dos hermanos menores, Laura (1949) y Michael (1953).

Su familia solía asistir a la Iglesia de Cristo. Los Joplin sentían que Janis siempre necesitaba más atención que el resto de sus hijos. Su madre decía: "Ella era infeliz e insatisfecha. La relación no era la más adecuada". 

En su adolescencia se hizo amiga de un grupo de marginados a través de quienes tuvo acceso a discos de artistas de blues afroamericanos como Bessie Smith, Ma Rainey o Lead Belly, a quienes más tarde Joplin acreditó como influencia en su decisión de convertirse en cantante. Al comenzar a participar en un coro, fue conociendo otros cantantes de "blues" como Odetta, Billie Holiday y Big Mama Thornton. A los dieciséis años comenzó a manifestar su amor por la música, frecuentando los bares de Luisiana, donde escuchaba música afroamericana, de "blues" y "jazz".

Entre sus compañeros de clase estaban GW Bailey y Jimmy Johnson. Joplin se graduó de la secundaria en 1960 y asistió a Lamar State College of Technology en Beaumont, Texas, durante el verano, y más tarde, en la Universidad de Texas en Austin, aunque no completó sus estudios.( El periódico universitario, "The Daily Texan", publicó un perfil de ella en la edición del 27 de julio de 1962, titulado "Ella se atreve a ser diferente". El artículo comenzó, "Ella va descalza cuando se siente como ella misma, lleva Levi's a clase porque son más cómodos, y lleva su Autoharp con ella dondequiera que va por lo que, en caso de que tuviera el impulso de romper a cantar, le será muy útil. Se llama Janis Joplin".)

Cuando estudiaba Bellas Artes en la Universidad de Texas en Austin, comenzó a cantar de forma habitual en bares. Participaba frecuentemente con la banda Waller Creek Boys. Allí empezó a tener reputación de ser una fuerte bebedora. En 1963 se trasladó a la ciudad de San Francisco. Dejó Texas para ir a San Francisco "sólo para estar lejos de Texas, porque mi cabeza estaba en un lugar muy diferente", dijo en enero de 1963 viviendo en Playa Norte y más tarde Haight-Ashbury. 

Estando allí conoció a muchos músicos con los que más tarde se reencontraría, como su amante Ron "Pigpen" McKernan" (después, miembro de The Grateful Dead), grabando un disco casero con Jorma Kaukonen, futuro guitarrista de Jefferson Airplane y Margareta Kaukonen en la máquina de escribir, utilizada como instrumento de percusión. 

En 1964, Joplin y la futura guitarrista de Jefferson Airplane, Jorma Kaukonen registraron una serie de estándares de "blues", acompañado además por Margareta Kaukonen en la máquina de escribir (como instrumento de percusión).

Fue en este periodo cuando comenzó a consumir drogas y se sumió, lentamente, en un estado de abandono, llegando a pesar 35 kilos. En 1965 le anunció a su familia que retomaría sus estudios universitarios, y que se casaría con un hombre que había conocido en San Francisco, llamado Peter LeBlanc; sin embargo la pareja no funcionó y Peter LeBlanc la abandonó; esto marcaría aún más su inseguridad afectiva y su sentimiento de soledad.

Cansada de esperar a LeBlanc y de ser una "chica buena", se mudó a San Francisco junto a Chet Helms, un productor que conoció en Texas. Se unió a la banda Big Brother and the Holding Company el 4 de julio de 1966, logrando una combinación perfecta. 

Chet Helms le ofreció que se uniese a la banda de la que era su mánager, y con la que finalmente grabaría su primer álbum, "Big Brother and the Holding Company", que tuvo una importante repercusión. 

Joplin amaba la libertad creativa de la escena musical en San Francisco. Solía actuar junto con otros grupos psicodélicos como The Grateful Dead, Jefferson Airplane y Quicksilver Messenger Service en los famosos salones de baile Avalon Ballroom, Fillmore East y Fillmore West, o con festivales al aire libre en el Golden Gate Park y en Haight-Ashbury.

Actuó con su grupo en el Festival de Monterey de 1967 junto con algunos grandes artistas del momento como Jimi Hendrix, The Mamas and The Papas, Jefferson Airplane, Otis Redding y The Who, entre otros. Como la primera actuación de los Big Brother no había sido filmada, les pidieron que tocasen al día siguiente. Durante esa presentación, interpretaron "Combination Of The Two;" Janis dejó a la audiencia boquiabierta con una versión del emblemático blues de Big Mama Thornton, «Ball And Chain».

A partir de entonces fueron contratados por el productor de Bob Dylan, Albert Grossman. Joplin eclipsaba a los Big Brother. En la primavera de 1968, se trasladaron a Nueva York para grabar su primer disco. Aquella combinación de música repetitiva, de estilo psicodélico de los 60, con la imponente voz de Joplin, era prodigiosa y "Cheap Thrills" salió en agosto de 1968. Lanzando a Joplin al éxito, a los tres días se hizo disco de oro y en el primer mes se vendieron más de un millón de copias. En el 2003, "Cheap Thrills" se colocó en el lugar 338 de los 500 mejores álbumes de todos los tiempos.

Las críticas sobre ella fueron muy buenas, y la prensa empezó a centrarse más en ella que en el grupo, todos le decían que ella era demasiado buena para el grupo, había tensión entre ellos a causa del protagonismo de Janis y la fama, y ella quería hacer un estilo más blues y soul, como las cantantes que veneraba, como Bessie Smith, Billie Holiday o Aretha Franklin, así que después de mucha presión por parte de su mánager, Albert Grossman, se marchó de Big Brother and the Holding Company.

Juntos se pusieron a buscar los mejores músicos del país para crear el nuevo grupo. A principios de 1969 ya estaba creado, aunque los músicos variarían a lo largo del año. Se llevó con ella al guitarrista Sam Andrew de Big Brother and the Holding Company. 

Con su nueva banda, "Kozmic Blues Band", salió su segundo disco, "I Got Dem Ol' Kozmic Blues Again Mama!". El sonido era distinto a lo que sus oyentes estaban acostumbrados: era una mezcla de rock, soul y blues, y recibió malas críticas, la revista "Rolling Stone" la denominó la "Judy Garland del rock".

En abril, Janis y la Kozmic Blues Band fueron de gira por Europa, pasando por Frankfurt, Estocolmo, París, Londres, y algunos lugares más, donde el público la acogió muy calurosamente y ella regresó a EE. UU. muy contenta, diciendo que el mejor concierto que había dado en su vida fue en Londres, donde la audiencia se volvió loca.

En ese año, a causa de la presión se enganchó a la heroína y comenzó a prodigarse en entrevistas, en las que terminaba hablando de su vida y de sus sentimientos. Decía que "hacía el amor con 25 000 personas en el escenario y luego se volvía a casa sola...". Cada vez dependía más del alcohol y de la heroína. Sin embargo, se había convertido en un símbolo de fuerza y de rebeldía para muchas mujeres de su época.

El 16 de agosto de 1969 actuó con enorme éxito en el festival de Woodstock, dónde realizó dos repeticiones de «Ball and Chain» y «Piece of My Heart».

Los músicos de la banda eran sólo profesionales, y Joplin quería que su banda fuese como una familia, como en Big Brother. Con el único que acabó conectando fue con el saxofonista Cornelius "Snooky" Flowers. A finales de 1969 Janis estaba ya destrozada y demasiado enganchada a la heroína y al alcohol, así que decidió tomarse un descanso y 
abandonar la banda. A finales de ese año la banda se separó. Su último concierto fue en el Madison Square Garden en Nueva York en la noche del 19 y 20 de diciembre de 1969.

En febrero de 1970, se fue de viaje con una amiga a Río de Janeiro por carnaval, a desintoxicarse, por lo menos, de la heroína. Allí conoció a David Niehouse y se enamoraron, estuvieron unos meses por la selva de Brasil viajando como dos viejos "beatniks" en la carretera y al volver a San Francisco, David se instaló en casa de Janis.

Albert Grossman, le propuso a Janis una nueva banda, la Full Tilt Boogie Band, y Janis, ya desenganchada de la heroína, pero no del alcohol, aceptó. David Niehouse quería seguir viajando por el mundo y le ofreció que se marcharan juntos, pero ella prefirió quedarse con su audiencia y su música. Así, Joplin congenió muy bien con todos los miembros de la banda, ellos la querían y ella los quería.

En verano de ese año, Janis y su banda participaron en el Festival Express, junto con otros artistas importantes de la época cómo The Grateful Dead, Buddy Guy y The Band. 

En una fiesta de los Hell's Angels de San Francisco, ese mismo verano, conoció a Seth Morgan y se enamoró de él. En septiembre de 1970, se trasladó a Los Ángeles a grabar "Pearl". El 4 de octubre de 1970 había sido un buen día en el estudio, y para celebrarlo salió de copas con sus compañeros y se emborrachó. Según el estudio forense, murió a la 1:40 por sobredosis de heroína. Joplin ya había pasado por experiencias similares y había salido con vida, pero esta vez no había nadie para ayudarla. Su cuerpo fue descubierto unas 18 horas después. Todos quedaron sorprendidos, pues pensaron que Janis ya no consumía, y estaba en la mejor época de su vida. 

En 1971, seis semanas después de su muerte, salió el disco "Pearl"; fue un éxito y se mantuvo en el número uno de ventas durante 14 semanas. Como homenaje, se dejó el tema «Mercedes Benz» a capella, ya que fue la última canción que Janis grabó; también se incluyó la canción «Buried Alive in the Blues» sólo con música, sin la voz de Janis. 

El sencillo «Me and Bobby McGee», compuesto por Kris Kristofferson (con quien la cantante tuvo un romance) y Fred Foster, representó su mayor éxito, al ser la única canción de Janis Joplin en alcanzar el Nº 1 en el Billboard Hot 100, por una semana en marzo de 1971.

En 2003, "Pearl" se colocó en el lugar 122 de los 500 mejores álbumes de todos los tiempos.

Las circunstancias de la muerte de la cantante fueron confusas, y aún hoy en día despiertan diversas hipótesis; el sábado 3 de octubre de 1970, Joplin visitó el estudio de grabación Sunset Sound Recorders en Los Ángeles, para escuchar la parte instrumental de "Buried Alive in the Blues", antes de grabar su pista vocal programada para el día siguiente. En algún momento de ese mismo día, le comunicaron por teléfono que su prometido, Seth Morgan, estaba en su casa jugando al billar con otras mujeres que había conocido ese sábado. En el estudio expresó su enfado por la noticia, y porque la noche anterior no había cumplido con su promesa de ir a visitarla. A pesar de ello, manifestó alegría por el progreso de la grabación. 

Por la noche, junto con el miembro de la banda Ken Pearson, salieron del estudio hacia el bar Barney's Beanery. Después de la medianoche los llevó a su casa y luego se retiró a su habitación en el Landmark Motor Hotel.

Al día siguiente, el domingo 4 por la tarde, Joplin no apareció en el estudio según lo convenido, por lo que el productor Phil Rothchil comenzó a preocuparse. El administrador y representante de la banda Full Tilt Boogie, John Cooke, decidió visitarla y encontró su automóvil Porsche descapotable en el aparcamiento. Al entrar a la habitación, la encontraron muerta, tirada en el suelo a un lado de su cama. La causa oficial de su muerte fue una sobredosis de heroína, probablemente bajo los efectos del alcohol. Cooke cree que Joplin accidentalmente recibió heroína con una concentración más alta a la normal, debido a la sobredosis de otros adictos en esa semana. 

El episodio habría ocurrido alrededor de la 1:45 p.m. del día 4 de octubre. Se dice que esto le sucedió en otras ocasiones, pero esta vez no hubo nadie que la ayudara. Algunas circunstancias que rodearon su muerte nunca se explicaron, como la pureza extrema que tenía la droga que la mató y que las jeringas usadas no se encontraron; se especuló incluso que pudo haber una persona involucrada. 

Su amiga Peggy Caserta admitió que, al igual que Seth Morgan, había prometido visitar a Joplin la noche del viernes 2 de octubre, pero se había ido de fiesta con otros consumidores de drogas que estaban alojados en un hotel de Los Ángeles. De acuerdo con su libro "Going Down With Janis", Caserta escuchó del distribuidor que les vendió la heroína a ella y Joplin el sábado, que la artista le expresó su tristeza por dos amigos que la habían abandonado la noche anterior.

La canción "Buried Alive in the Blues" quedó inconclusa con la trágica muerte de la cantante, aunque fue finalmente incluida como un tema instrumental en "Pearl", a manera de un homenaje póstumo.

Joplin fue incinerada en la funeraria Pierce Brothers Westwood Village en Los Ángeles. Sus cenizas fueron esparcidas desde un avión en el océano Pacífico a lo largo de Stinson Beach. El único servicio fúnebre tuvo un carácter privado, ya que sólo asistieron los padres de Joplin y su tía materna.

En su testamento, Joplin dejó 2500 dólares para realizar una fiesta en su honor en caso de su desaparición. Alrededor de 200 personas recibieron invitaciones para la fiesta que decía: «Las bebidas son por Pearl», una referencia al apodo de la cantante. El evento, que tuvo lugar el 26 de octubre de 1970, fue en Lion's Share, localizado en San Anselmo, California. Contó con la presencia de su hermana Laura y amigos cercanos de Joplin, como el artista del tatuaje Lyle Tuttle, el prometido de Joplin, Seth Morgan, Bob Gordon, y su mánager de gira John Cooke. Se repartieron brownies mezclados con hachís entre los asistentes. 

Al morir a los veintisiete años, Janis Joplin fue incluida en el llamado Club de los 27.

La vida privada de Janis Joplin siempre fue objeto de polémicas y amplias controversias. Se conoce que desde su adolescencia tuvo serios problemas de personalidad y autoestima, relacionados con su aspecto físico.

Hay cierta tendencia generalizada a definirla como bisexual, a lo que se sumó su desenfrenado estilo de vida. Aunque, al parecer, tuvo más parejas femeninas que masculinas, Joplin nunca se describió a sí misma como lesbiana o bisexual, sino simplemente "sexual". Su vida sexual incluyó numerosos hombres y mujeres, en lo que se calificaban de "orgías animales". Estos aspectos hicieron que sus propios padres la rechazaran y rehusaran encontrarse con ella, en muchas ocasiones.

Quizás su pareja más estable y conocida fue Peggy Caserta, una amiga, relación que causó su ruptura con el empresario David Niehaus. Caserta afirmó en su libro de 1973, "Going Down With Janis", que ella y Joplin habían decidido separarse mutuamente en abril de 1970, para mantenerse alejadas cada una del uso de las drogas, algo que no consiguieron. Caserta era una ex-azafata de Delta Airlines y dueña de una boutique de ropa en Haight Ashbury. Ambas continuarían con su amistad, unidas por su fuerte adicción a la heroína, hasta la muerte de la cantante.

En sus últimos meses de vida, Janis Joplin estableció una fugaz relación con el estudiante de Berkeley Seth Morgan, joven de 21 años, traficante de heroína y futuro escritor de novelas. Ambos se conocieron en agosto de 1970 en una fiesta en el bar Hell's Angels de San Francisco. Para ese entonces, Joplin residía en el Landmark Motor Hotel en Hollywood Heights, Los Ángeles (lugar donde fue encontrada sin vida dos meses después), sitio en el cual se estableció previo a las sesiones de grabación de "Pearl" en el Sunset Sound Recorders.

Morgan y Joplin incluso anunciaron a inicios de septiembre de 1970 sus planes para casarse, e invitaron a la ceremonia a todos los músicos que participaban en el estudio.

Tras una vida problemática, el 17 de octubre de 1990, Morgan falleció en un accidente de tráfico cuando conducía su motocicleta en compañía de su novia (ambos bajo los efectos del alcohol y la cocaína).

En 1974, Leonard Cohen publicó el álbum "New Skin for the Old Ceremony" incluyendo la canción "Chelsea Hotel #2" donde describe su aventura con Janis Joplin en el Hotel Chelsea de Nueva York.

Big Brother and the Holding Company


Kozmic Blues Band


Full Tilt Boogie









</doc>
<doc id="15373" url="https://es.wikipedia.org/wiki?curid=15373" title="Biofísica">
Biofísica

La biofísica es la ciencia que estudia la biología con los principios y métodos de la física. Se discute si la biofísica es una rama de la física o de la biología. Desde un punto de vista puede concebirse que los conocimientos y enfoques acumulados en la física "pura" pueden aplicarse al estudio de sistemas biológicos. En ese caso la biofísica le aporta conocimientos a la biología, pero no a la física, sin embargo, le ofrece a la física evidencia experimental que permite corroborar teorías. Ejemplos en ese sentido son la física de la audición, la biomecánica, los motores moleculares, comunicación molecular, entre otros campos de la biología abordada por la física.

Otros estudios consideran que existen ramas de la física que deben desarrollarse a profundidad como problemas físicos específicamente relacionados con la materia viviente. Así, por ejemplo, los polímeros biológicos (como las proteínas) no son lo suficientemente grandes como para poderlos tratar como un sistema mecánico, a la vez que no son lo suficientemente pequeños como para tratarlos como moléculas simples en solución. Los cambios energéticos que ocurren durante una reacción química catalizada por una enzima, o fenómenos como el acoplamiento químico-osmótico parecen requerir más de un enfoque físico teórico profundo que de una evaluación biológica.

Entre esos dos extremos aparecen problemas como la generación y propagación del impulso nervioso donde se requiere un pensamiento biológico, más un pensamiento físico así como algo cualitativamente nuevo que aparece con la visión integradora del problema.

Una subdisciplina de la biofísica es la dinámica molecular, que intenta explicar las propiedades químicas de las biomoléculas a través de su estructura y sus propiedades dinámicas y de equilibrio.





</doc>
<doc id="15374" url="https://es.wikipedia.org/wiki?curid=15374" title="Licopeno">
Licopeno

El licopeno del neolatín "lycopersicum", la especie tomate, es un caroteno rojo brillante y pigmento carotenoide y fitoquímico que se encuentra en los tomates y otras frutas y verduras de color rojo, como las zanahorias rojas, el pimiento rojo, sandías, y papayas, aunque no en las fresas o cerezas. Aunque el licopeno es químicamente un caroteno, no tiene actividad de vitamina A. Los alimentos que no son de color rojo también pueden contener licopeno, como las habas cafés o el perejil.

En las plantas, algas y otros organismos fotosintéticos, el licopeno es un intermediario importante en la biosíntesis de muchos carotenoides, incluyendo el beta caroteno, que es responsable de la pigmentación amarilla, naranja, o roja, la fotosíntesis, y la foto-protección. Como todos los carotenoides, el licopeno es un hidrocarburo poliinsaturado, es decir, un alqueno no sustituido. Estructuralmente, el licopeno es un tetraterpeno y ensamblado a partir de ocho unidades de isopreno que se componen enteramente de carbono e hidrógeno. Es insoluble en agua. Los once dobles enlaces conjugados del licopeno le dan su color rojo intenso y su actividad antioxidante. Debido a su fuerte color y no toxicidad, el licopeno es un colorante alimentario útil (registrado como E160d) y está aprobado para el uso en los EE.UU., Australia y Nueva Zelanda (registrado como 160d) y la UE.

El licopeno no es un nutriente esencial para los humanos, pero que se encuentra comúnmente en la dieta principalmente de platos preparados a base de tomates. Cuando se absorbe por el intestino, el licopeno se transporta en la sangre por diversas lipoproteínas y se acumula principalmente en la sangre, tejido adiposo, piel, hígado y las glándulas suprarrenales, pero se puede encontrar en la mayoría de los tejidos.

La investigación preliminar ha demostrado que las personas que consumen tomates pueden tener un menor riesgo de cáncer, posiblemente debido a que el licopeno afecta los mecanismos del cáncer de próstata. Sin embargo, esta área de investigación y la relación entre el licopeno y el cáncer de próstata han sido consideradas insuficientes de evidencia para su aprobación de "declaración de propiedades saludables" por la FDA.

El licopeno es uno de los primeros carotenoides que aparecen en la síntesis de este tipo de compuestos, constituyendo la base molecular para la síntesis de los restantes carotenoides. El licopeno es un carotenoide de estructura sencilla con una cadena alifática formada por cuarenta átomos de carbono. El licopeno es un carotenoide altamente lipofílico que se caracteriza por carecer de anillos cíclicos y poseer un gran número de dobles enlaces conjugados. Su obtención por síntesis química aún no está totalmente establecida y, a diferencia de otros carotenoides como el β-caroteno producido a gran escala por síntesis, el licopeno se obtiene fundamentalmente a partir de fuentes naturales, hongos y especialmente de tomates. Sin embargo, los sistemas de extracción son costosos y el licopeno presenta una baja estabilidad, lo que ha limitado su utilización como colorante alimenticio.

En nuestra dieta obtenemos licopeno a partir de alimentos muy definidos, fundamentalmente a través del consumo de tomate y derivados (salsas, tomate frito, tomate triturado, ketchup, pizzas, zumos) y de sandía. En el tomate maduro, el carotenoide mayoritario es el licopeno que lo contiene en aproximadamente en un 83% y en porcentaje también importante, se encuentra el β-caroteno, entre un 3-7%, y otros como son el γ-caroteno, que al igual que el β-caroteno tienen actividad provitamínica A, fitoeno, fitoflueno, etc. El contenido en licopeno aumenta con la maduración de los tomates y puede presentar grandes variaciones según la variedad, condiciones del cultivo como el tipo de suelo y clima, tipo de almacenamiento, etc. La cantidad de licopeno en los tomates de ensalada está alrededor de 3000 µg/100g y en los de "tipo pera" es más de diez veces esa cifra. De forma general, el contenido de licopeno es menor en los tomates cultivados en invernadero, en cualquier estación, que en los tomates producidos al aire libre durante el verano, así como también el contenido de licopeno es menor en frutos que se recolectan verdes y maduran en almacén en comparación con los frutos madurados en la tomatera. 

Actualmente es posible obtener por ingeniería genética, tomates que contienen más de tres veces la cantidad de licopeno que el resto de los tomates. 

La facilidad con la que incorporamos el licopeno a nuestro organismo, es decir, su biodisponibilidad, es diferente según la forma en que lo consumamos, así por ejemplo cuando se toma con aceite se facilita su absorción. Las investigaciones confirman que la absorción intestinal del licopeno es mucho mejor (hasta 2,5 veces más) si se consume cuando se calienta como las salsas que como fruta natural o zumo, debido a que el licopeno se absorbe mejor a través de las grasas y aceites por su liposolubilidad y a que, con temperaturas altas, se rompen las paredes celulares del fruto, que son las que dificultan la absorción del licopeno.
El licopeno se encuentra presente en el organismo humano tanto en sangre en cantidad de 30 µg/dl como en tejidos, distribuyéndose de forma variable. El licopeno es el carotenoide predominante en la composición de los tejidos humanos, concentrándose especialmente en la próstata, lo que podría explicar su fuerte acción preventiva en la aparición de cáncer de próstata.

El licopeno posee propiedades antioxidantes, y actúa protegiendo a las células humanas del estrés oxidativo, producido por la acción de los radicales libres, que son uno de los principales responsables de las enfermedades cardiovasculares, del cáncer y del envejecimiento. Además, actúa modulando las moléculas responsables de la regulación del ciclo celular y produciendo una regresión de ciertas lesiones cancerosas y de próstata.
No se conocen exactamente las bases biológicas ni fisicoquímicas de estas propiedades, pero parecen directamente relacionadas con el elevado poder antioxidante del licopeno, mucho más que otros antioxidantes como la vitamina E o el β-caroteno. Un gran número de procesos cancerígenos y degenerativos están asociados a daños oxidativos sobre el genoma y los mecanismos genéticos de control de la proliferación y diferenciación celular. El licopeno actuaría como un potente neutralizador de radicales libres (óxido y peróxido) atenuando los daños oxidativos sobre los tejidos.

Cada vez existen más estudios epidemiológicos que sugieren que el consumo de licopeno tiene un efecto beneficioso sobre la salud humana, reduciendo notablemente la incidencia de las patologías cancerosas sobre todo, de pulmón, próstata y tracto digestivo, cardiovasculares y del envejecimiento. También existen evidencias científicas de que previene el síndrome de degeneración macular, principal causa de ceguera en la gente mayor de 65 años.

Un estudio realizado por investigadores de la Universidad de Harvard, reveló que el consumo de licopeno redujo en un 45% las posibilidades de desarrollar cáncer de próstata en una población de 48.000 sujetos que tenían en su dieta por lo menos 10 raciones semanales de tomate o subproductos de éste. La investigación duró seis años. Otras investigaciones descubrieron que el licopeno también reduce los niveles de colesterol en forma de lipoproteína de baja densidad (LDL), que produce aterosclerosis, por lo que la ingesta de tomates reduce la incidencia de enfermedades cardiovasculares.

Los primeros estudios se centraron en los beneficios que aportaban en la prevención de ciertos cánceres, mostraban que aquellas personas que lo consumían con frecuencia estaban menos expuestas a cánceres que afectaban al sistema digestivo y al reproductor tales como el de colon y de próstata.

Otros posteriores venían a demostrar las propiedades del antienvejecimiento del licopeno. Un ejemplo es el llevado a cabo con un grupo de 90 monjas, en el sur de Italia, con edades comprendidas entre los 77 y los 98 años. Aquellas con índices mayores de licopeno en la sangre tenían una mayor agilidad a la hora de realizar todo tipo de actividades.

Se estima que en España, a partir de frutas y hortalizas frescas, la cantidad de licopeno consumido es de aproximadamente 1,3 mg/persona/día. 

El que haya muchas pruebas que muestran que el licopeno contenido en nuestra dieta es beneficioso para nuestra salud, no quiere decir que si lo ingerimos de forma aislada en forma de pastillas o cápsulas vaya a mejorar nuestra salud o podamos evitar ciertas enfermedades. Todavía habría que realizar muchos estudios antes de poder hacer recomendaciones para consumirlo aisladamente como suplemento dietético. Pero lo que sí se puede recomendar es aumentar su ingesta a partir de las frutas y hortalizas.

No se han descrito problemas de toxicidad ante un aumento en la ingesta dietética de licopeno, salvo en la carotenodermia. Hay que ser un tanto escépticos ante las "prometedoras" perspectivas derivadas de los diferentes tipos de estudios epidemiológicos, ya que hay varios aspectos que necesitan más información, como son: 

Al ser tan común, el uso del licopeno ha sido permitido como colorante alimenticio. Debido a la insolubilidad del licopeno en el agua y a que se encuentra estrechamente ligado a la fibra vegetal, su disponibilidad ha aumentado con el uso de las comidas procesadas. Por ejemplo, el cocinar tomates para guisos o guisados (similar a las salsas de tomate enlatadas) y servirlos en platos ricos en aceites (como salsas para pastas o pizza) incrementa la asimilación del licopeno hacia el torrente sanguíneo.

El licopeno mancha instantáneamente cualquier superficie medianamente porosa, incluyendo la mayoría de los plásticos. Mientras que las manchas de tomate se pueden limpiar con facilidad de las telas (cuando las manchas aún están frescas), los plásticos manchados desafían todos los esfuerzos para quitar el licopeno con agua caliente, jabones o detergentes (aunque los productos blanqueadores lo destruyen). Los plásticos son especialmente susceptibles de ser manchados si son calentados, sufren arañazos, mojados en aceite, o atacados por ácidos (como los encontrados en los tomates).


</doc>
<doc id="15375" url="https://es.wikipedia.org/wiki?curid=15375" title="Historia de los sistemas operativos">
Historia de los sistemas operativos

Un sistema operativo es uno o varios programas que se usan para poder trabajar con los componentes de un equipo de cómputo. Los sistemas operativos proveen un conjunto de funciones necesarias y usadas por diversos programas de aplicaciones de una computadora, y los vínculos necesarios para controlar y sincronizar el hardware de la misma. En las primeras computadoras, que no tenían sistema operativo cada programa necesitaba la más detallada especificación del hardware para ejecutarse correctamente y desarrollar tareas estándares, y sus propios drivers para los dispositivos periféricos como impresoras y lectores de tarjetas perforadas. El incremento de la complejidad del hardware y los programas de aplicaciones eventualmente hicieron del sistema operativo una necesidad.

Los primeros sistemas operativos fueron desarrollados por cada usuario para el uso de su propia computadora central, y es en 1956 que la General Motors desarrolla lo que es hoy considerado el primer sistema, el GM-NAA I/O, para su IBM 704.

A finales de la década de 1940, con lo que se podría considerar la aparición de la primera generación de computadoras en el mundo, se accedía directamente a la consola de la computadora desde la cual se actuaba sobre una serie de micro interruptores que permitían introducir directamente el programa en la memoria de la computadora.

A principios de los años 50 con el objeto de facilitar la interacción entre persona y computadora, los sistemas operativos hacen una aparición discreta y bastante simple, con conceptos tales como el monitor residente, el proceso por lotes y el almacenamiento temporal.

Su funcionamiento era bastante simple, se limitaba a cargar programas a la memoria, leyéndolos de una cinta o de tarjetas perforadas, y ejecutarlos. El problema era encontrar una forma de optimizar el tiempo entre la retirada de un trabajo y el montaje del siguiente.

El primer Sistema Operativo de la historia fue creado en 1956 para un ordenador IBM 704, y básicamente lo único que hacía era comenzar la ejecución de un programa cuando el anterior terminaba.

Su objetivo era disminuir el tiempo de carga de los programas, haciendo simultánea la carga del programa o la salida de datos con la ejecución de la siguiente tarea. Para ello se utilizaban dos técnicas, el "buffering" y el "spooling".

En los años 60 se produjeron cambios notorios en varios campos de la informática, con la aparición del circuito integrado la mayoría orientados a seguir incrementando el potencial de los ordenadores. Para ello se utilizaban técnicas de lo más diversas.

En un sistema "multiprogramado" la memoria principal alberga a más de un programa de usuario. La CPU ejecuta instrucciones de un programa, cuando el que se encuentra en ejecución realiza una operación de E/S; en lugar de esperar a que termine la operación de E/S, se pasa a ejecutar otro programa. Si éste realiza, a su vez, otra operación de E/S, se mandan las órdenes oportunas al controlador, y pasa a ejecutarse otro. De esta forma es posible, teniendo almacenado un conjunto adecuado de tareas en cada momento, utilizar de manera óptima los recursos disponibles.

En este punto tenemos un sistema que hace buen uso de la electrónica disponible, pero adolece la falta de interactividad; para conseguirla debe convertirse en un sistema multiusuario, en el cual existen varios usuarios con un terminal en línea, utilizando el modo de operación de tiempo compartido. En estos sistemas igual que en la multiprogramación. Pero, a diferencia de ésta, cuando un programa lleva cierto tiempo ejecutándose el sistema operativo lo detiene para que se ejecute otra aplicación.

Estos sistemas se usan en entornos donde se deben aceptar y procesar en tiempos muy breves un gran número de sucesos, en su mayoría externos al ordenador. Si el sistema no respeta las restricciones de tiempo en las que las operaciones deben entregar su resultado se dice que ha fallado.
El tiempo de respuesta a su vez debe servir para resolver el problema o hecho planteado. El procesamiento de archivos se hace de una forma continua, pues se procesa el archivo antes de que entre el siguiente, sus primeros usos fueron y siguen siendo en telecomunicaciones.

Diseño que no se encuentran en ordenadores monoprocesador. Estos problemas derivan del hecho de que dos programas pueden ejecutarse simultáneamente y, potencialmente, pueden interferirse entre sí. Concretamente, en lo que se refiere a las lecturas y escrituras en memoria. Existen dos arquitecturas que resuelven estos problemas:

La arquitectura NUMA, donde cada procesador tiene acceso y control exclusivo a una parte de la memoria. 
La arquitectura SMP, donde todos los procesadores comparten toda la memoria. 
Esta última debe lidiar con el problema de la coherencia de caché. Cada microprocesador cuenta con su propia memoria caché local. De manera que cuando un microprocesador escribe en una dirección de memoria, lo hace únicamente sobre su copia local en caché. Si otro microprocesador tiene almacenada la misma dirección de memoria en su caché, resultará que trabaja con una copia obsoleta del dato almacenado.

Para que un multiprocesador opere correctamente necesita un sistema operativo especialmente diseñado para ello. La mayoría de los sistemas operativos actuales poseen esta capacidad.

Además del Atlas Supervisor y el OS/360, los años 1970 marcaron el inicio de UNIX, a mediados de los 60 aparece Multics, sistema operativo multiusuario - multitarea desarrollado por los laboratorios Bell de AT&T y Unix, convirtiéndolo en uno de los pocos SO escritos en un lenguaje de alto nivel. En el campo de la programación lógica se dio a luz la primera implementación de Prolog, y en la revolucionaria orientación a objetos, Smalltalk.

Se trataba de sistemas grandes, complejos y costosos, pues antes no se había construido nada similar y muchos de los proyectos desarrollados terminaron con costos muy por encima del presupuesto y mucho después de lo que se marcaba como fecha de la finalización. Además, aunque formaban una capa entre el hardware y el usuario, éste debía conocer un complejo lenguaje de control para realizar sus trabajos. 
Otro de los inconvenientes es el gran consumo de recursos que ocasionaban, debido a los grandes espacios de memoria principal y secundaria ocupados, así como el tiempo de procesador consumido. Es por esto que se intentó hacer hincapié en mejorar las técnicas ya existentes de multiprogramación y tiempo compartidos


Con la creación de los circuitos LSI (integración a gran escala), chips que contenían miles de transistores en un centímetro cuadrado de silicio, empezó el auge de los ordenadores personales. En éstos se dejó un poco de lado el rendimiento y se buscó más que el sistema operativo fuera amigable, surgiendo menús, e interfaces gráficas. Esto reducía la rapidez de las aplicaciones, pero se volvían más prácticos y simples para los usuarios. En esta época, siguieron utilizándose lenguajes ya existentes, como Smalltalk o C, y nacieron otros nuevos, de los cuales se podrían destacar: C++ y Eiffel dentro del paradigma de la orientación a objetos, y Haskell y Miranda en el campo de la programación declarativa.
Un avance importante que se estableció a mediados de la década de 1980 fue el desarrollo de redes de computadoras personales que corrían sistemas operativos en red y sistemas operativos distribuidos.
En esta escena, dos sistemas operativos eran los mayoritarios: MS-DOS (Micro Soft Disk Operating System), escrito por Microsoft para IBM PC y otras computadoras que utilizaban la CPU Intel 8088 y sus sucesores, y UNIX, que dominaba en los ordenadores personales que hacían uso del Motorola 68000.

SunOS fue la versión del sistema operativo derivado de Unix y BSD desarrollado por Sun Microsystems para sus estaciones de trabajo y servidores hasta el principio de los años 1990. Ésta estaba basada en los UNIX BSD con algunos añadidos de los System V UNIX en versiones posteriores.

SunOS 1.0 estaba basada básicamente en BSD 4.1 y se publicó en 1982. SunOS 2.0, que salió en 1985, usaba BSD 4.2 como una base e introducía una capa de sistema de ficheros virtual (VFS) y el protocolo NFS. SunOS 3.0 coincidía con el lanzamiento de la serie Sun-3 en 1986 e incorporaba varias utilidades de System V. SunOS 4.0, que salió en 1989, migró a la base de BSD 4.3, introdujo un nuevo sistema de memoria virtual, enlazamiento dinámico y una implementación de la arquitectura System V STREAMS I/O.

SunOS 5.0 y las versiones posteriores están basadas en UNIX System V Release 4.

En 1981 Microsoft compró un sistema operativo llamado QDOS que, tras realizar unas pocas modificaciones, se convirtió en la primera versión de MS-DOS (Micro Soft Disk Operating System). A partir de aquí se sucedieron una serie de cambios hasta llegar a la versión 7.1, versión 8 en Windows Milenium, a partir de la cual MS-DOS dejó de existir como un componente del Sistema Operativo.

En 1983, con la aparición de los ordenadores MSX, se realizó una adaptación para este sistema que utilizaba el procesador Z-80 llamada MSX-DOS. Era un cruce entre la versión MS-DOS 1.25 y CP/M. En 1988, una vez que Microsoft se desvinculó de proyecto, ASCII Corporation publicó la versión MSX-DOS 2.0 que añadió, entre otras cosas, soporte para el uso de directorios.

El lanzamiento oficial del ordenador Macintosh en enero de 1984, al precio de US $1,995 (después cambiado a $2,495 dólares). Incluía su sistema operativo Mac OS cuya características novedosas era una GUI (Graphic User Interface), Multitareas y Mouse. Provocó diferentes reacciones entre los usuarios acostumbrados a la línea de comandos y algunos tachando el uso del Mouse como "juguete".

AmigaOS es el nombre que recibe el conjunto de la familia de gestores de ventanas y ROMs que incluían por defecto los ordenadores personales Commodore Amiga como sistema operativo. Fue desarrollado originalmente por Commodore International, e inicialmente presentado en 1985 junto con el Amiga 1000.

OS/2 es un sistema operativo de IBM que intentó suceder a DOS como sistema operativo de las computadoras personales. Se desarrolló inicialmente de manera conjunta entre Microsoft e IBM, hasta que la primera decidió seguir su camino con su Windows e IBM se ocupó en solitario de OS/2.

OS/2 ya no es comercializado por IBM, y el soporte estándar de IBM para OS / 2 se suspendió el 31 de diciembre de 2006. Se ha mantenido desde entonces con relativamente pocas nuevas características bajo el nombre eComStation.

BeOS es un sistema operativo para PC desarrollado por Be Incorporated en 1990, orientado principalmente a proveer alto rendimiento en aplicaciones multimedia. A pesar de la creencia común fomentada por la inclusión de la interfaz de comandos Bash en el sistema operativo, el diseño de BeOS no estaba basado en UNIX.

Originalmente (1995-1996) el sistema operativo se corría sobre su propio hardware, conocido como BeBox. Más tarde (1997) fue extendido a la plataforma PowerPC y finalmente (1998) se añadió compatibilidad con procesadores x86.

Este sistema al parecer es una versión mejorada de Unix, basado en el estándar POSIX, un sistema que en principio trabajaba en modo comandos. Hoy en día dispone de Ventanas, gracias a un servidor gráfico y a gestores de ventanas como KDE, GNOME entre muchos. Recientemente GNU/Linux dispone de un aplicativo que convierte las ventanas en un entorno 3D como por ejemplo Beryl o Compiz. Lo que permite utilizar Linux de una forma visual atractiva.

Existen muchas distribuciones actuales de Gnu/Linux (Debian, Fedora, Ubuntu, Slackware, etc.) donde todas ellas tienen en común que ocupan el mismo núcleo Linux. Dentro de las cualidades de Gnu/Linux se puede caracterizar el hecho de que la navegación a través de la web es sin riegos de ser afectada por virus, esto debido al sistema de permisos implementado, el cual no deja correr ninguna aplicación sin los permisos necesarios, permisos que son otorgados por el usuario. A todo esto se suma que los virus que vienen en dispositivos desmontables tampoco afectan al sistema, debido al mismo sistema de permisos.

Solaris es un sistema operativo de tipo Unix desarrollado desde 1992 inicialmente por Sun Microsystems y actualmente por Oracle Corporation como sucesor de SunOS. Es un sistema certificado oficialmente como versión de Unix. Funciona en arquitecturas SPARC y x86 para servidores y estaciones de trabajo.

Windows NT es una familia de sistemas operativos producidos por Microsoft, de la cual la primera versión fue publicada en julio de 1993.

Previamente a la aparición del famoso Windows 95 la empresa Microsoft concibió una nueva línea de sistemas operativos orientados a estaciones de trabajo y servidor de red. Un sistema operativo con interfaz gráfica propia, estable y con características similares a los sistemas de red UNIX. Las letras NT provienen de la designación del producto como "Tecnología Nueva" ("New Technology").

Las versiones publicadas de este sistema son: 3.1, 3.5, 3.51 y 4.0. Además, Windows NT se distribuía en dos versiones, dependiendo de la utilidad que se le fuera a dar: Workstation para ser utilizado como estación de trabajo y Server para ser utilizado como servidor.

FreeBSD es un sistema operativo multiusuario, capaz de efectuar multitarea con apropiación y multiproceso en plataformas compatibles con múltiples procesadores; el funcionamiento de FreeBSD está inspirado en la variante 4.4 BSD-Lite de UNIX. Aunque FreeBSD no puede ser propiamente llamado UNIX, al no haber adquirido la debida licencia de The Open Group, FreeBSD sí está hecho para ser compatible con la norma POSIX, al igual que varios otros sistemas "clones de UNIX". 

El sistema FreeBSD incluye el núcleo, la estructura de ficheros del sistema, bibliotecas de la API de C, y algunas utilidades básicas. La versión 6.1 
trajo importantes mejoras como mayor apoyo para dispositivos Bluetooth y controladores para tarjetas de sonido y red.

La versión 7.0, lanzada el 27 de febrero de 2008, incluye compatibilidad con el sistema de archivos ZFS de Sun y a la arquitectura ARM, entre otras novedades.

La distribución más notable es PC-BSD.

Windows es el nombre de una familia de sistemas operativos desarrollados y vendidos por Microsoft basado en MS-DOS. Windows nunca fue realmente un Sistema Operativo con verdadero entorno gráfico hasta Windows 95. Hasta la versión 3.11 Windows fue un entorno de escritorio para MS-DOS. 

Windows 95 es un sistema operativo con interfaz gráfica de usuario híbrido de entre 16 y 32 bits. Fue lanzado al mercado el 24 de agosto de 1995 por la empresa de software Microsoft con notable éxito de ventas. Durante su desarrollo se conoció como Windows 4 o por el nombre clave Chicago. Esta serie de Windows terminó con Windows Me.

ReactOS (React Operating System) es un sistema operativo de código abierto destinado a lograr la compatibilidad binaria con aplicaciones de software y controladores de dispositivos hechos para Microsoft Windows NT versiones 5.x en adelante (Windows XP y sus sucesores).

En 1996 un grupo de programadores y desarrolladores de software libre comenzaron un proyecto llamado FreeWin95 el cual consistía en implementar un clon de Windows 95. El proyecto estuvo bajo discusión por el diseño del sistema ya habiendo desarrollado la capa compatible con MS-DOS, pero lamentablemente esta fue una situación que no se completó. Para 1997 el proyecto no había lanzado ninguna versión, por lo que los miembros de éste, coordinados por Jason Filby, pudieron revivirlo. Se decidió cambiar el núcleo del sistema compatible con MS-DOS y de ahora en adelante basarlo en uno compatible con Windows NT, y así el proyecto pudo seguir adelante con el nombre actual de ReactOS, que comenzó en febrero de 1998, desarrollando las bases del kernel y algunos drivers básicos.

FreeDOS es un proyecto que aspira a crear un sistema operativo libre que sea totalmente compatible con las aplicaciones y los controladores de MS-DOS.

El programa ya ha alcanzado un alto grado de madurez y tiene algunas características que no existían en MS-DOS. Algunos comandos de FreeDOS son idénticos o mejores que sus equivalentes de MS-DOS, pero aún faltan algunos del sistema operativo original.

El intérprete de línea de comandos usado por FreeDOS se llama FreeCOM.

SymbOS es un sistema operativo desarrollado originalmente en 2001 para los ordenadores Amstrad CPC. Se trata de un sistema operativo gráfico con una estética e interfaz similar a Windows 95. A pesar de la baja potencia que desarrollan estos ordenadores, alrededor de 4MHz, está minuciosamente optimizado para el hardware en el cuál funciona, por lo que el rendimiento es más que aceptable.

Debido a su cuidada programación modular, ha sido migrado posteriormente a los ordenadores MSX, Amstrad PCW y Enterprise 128 que, con versiones adaptadas y recompiladas en cada caso, son capaces de ejecutar las mismas aplicaciones sin modificación alguna.

Aunque parezca un sistema obsoleto, existe una extensa comunidad implicada en el proyecto. Los programadores originales continúan actualizando y dando soporte al sistema en la actualidad.

SymbOS es un claro ejemplo de software optimizado, de tal manera que con un mínimo hardware se obtienen prestaciones similares a otros grandes sistemas operativos actuales. Esto lo convierte en el antagonista de los modernos sistemas operativos, que derrochan la mayor parte de los recursos apoyándose en la alta potencia del hardware actual.

MorphOS es un sistema operativo, en parte propietario y en parte de código abierto, producido para ordenadores basados en los procesadores PowerPC (PPC). El sistema operativo en sí es propietario, pero muchas de sus bibliotecas y otros componentes son de código abierto, como Ambient (la interfaz del escritorio). La mariposa azul es el logo característico de este sistema operativo. Está basado en el Micronúcleo de Quark.

Darwin es el sistema que subyace en Mac OS X, cuya primera versión final salió en el año 2001 para funcionar en computadoras Macintosh. 

Integra el micronúcleo XNU y servicios de sistema operativo de tipo UNIX basados en BSD 4.4 (en particular FreeBSD) que proporcionan una estabilidad y un rendimiento mayor que el de versiones anteriores de Mac OS. Se trata de una evolución del sistema operativo NEXTSTEP (basado en Mach 2.5 y código BSD 4.3) desarrollado por NeXT en 1989 comprado por Apple Computer en diciembre de 1996.

Darwin proporciona al Mac OS X prestaciones modernas, como la memoria protegida, la multitarea por desalojo o expulsiva, la gestión avanzada de memoria y el multiproceso simétrico.

mac OS, antes llamado Mac OS X, es un sistema operativo basado en Unix, desarrollado, comercializado y vendido por Apple Inc. 

La primera versión del sistema fue Mac OS X Server 1.0 en 1999, y en cuanto al escritorio, fue Mac OS X v10.0 «Cheetah» (publicada el 24 de marzo de 2001).

La variante para servidores, Mac OS X Server, es arquitectónicamente idéntica a su contraparte para escritorio, además de incluir herramientas para administrar grupos de trabajo y proveer acceso a los servicios de red. Estas herramientas incluyen un servidor de correo, un servidor Samba, un servidor LDAP y un servidor de dominio entre otros.

Haiku es un sistema operativo de código abierto actualmente en desarrollo que se centra específicamente en la informática personal y multimedia. Inspirado por BeOS (Be Operating System), Haiku aspira a convertirse en un sistema rápido, eficiente, fácil de usar y fácil de aprender, sin descuidar su potencia para los usuarios de todos los niveles.

OpenSolaris fue un sistema operativo libre publicado en 2005 a partir de la versión privativa de Solaris de Sun Microsystems, ahora parte de Oracle Corporation. OpenSolaris es también el nombre de un proyecto iniciado en 2005 por Sun para construir y desarrollar una comunidad de usuarios alrededor de las tecnologías del sistema operativo del mismo nombre. Después de la adquisición de Sun Microsystems, en agosto de 2010, Oracle decidió interrumpir la publicación y distribución de OpenSolaris, así como su modelo de desarrollo, basado en la disponibilidad de versiones de desarrollo compiladas cada dos semanas y versiones estables cada seis meses. Sin embargo, los términos de su licencia libre no han sido modificados, por lo que el código fuente afectado por ella será publicado cuando Oracle publique nuevas versiones de Solaris.

Illumos es un proyecto de software libre derivado de OpenSolaris. Fue anunciado por conferencia web desde Nueva York el 3 de agosto de 2010. El nombre del proyecto es un neologismo procedente del latín "Illum" (la luz) y de "OS" (operating system, sistema operativo).

Se trata del código base a partir del cual cualquiera podrá crear su propia distribución de software basada en el sistema operativo OpenSolaris. Pero Illumos no es una distribución, ni una bifurcación (fork), al menos por el momento, en la medida que no pretende separarse del tronco principal, sino un derivado de la "consolidación" OS/Net (más conocida como ON), que consiste básicamente en el código fuente del kernel (SunOS), los drivers, los servicios de red, las bibliotecas del sistema y los comandos básicos del sistema operativo.

OpenIndiana es un sistema operativo tipo Unix liberado como software libre y de código abierto. Es una bifurcación de OpenSolaris concebida después de la compra de Sun Microsystems por parte de Oracle y tiene como objetivo continuar con el desarrollo y la distribución del código base de OpenSolaris. El proyecto opera bajo el patrocinio de la Illumos Foundation (Fundación Illumos). El objetivo declarado del proyecto es convertirse en la distribución de OpenSolaris de facto instalada en servidores de producción donde se requieren soluciones de seguridad y errores de forma gratuita.


</doc>
<doc id="15377" url="https://es.wikipedia.org/wiki?curid=15377" title="El Teniente Blueberry">
El Teniente Blueberry

El Teniente Blueberry (o simplemente Blueberry) es una serie francesa de historietas del oeste iniciada en 1963 por el guionista Jean-Michel Charlier y el dibujante Jean Giraud para la revista "Pilote" que narra las aventuras del Teniente de Caballería Mike Steve Donovan, alias ""Blueberry"". En 1981, los mismos autores crearon un segundo personaje cuyas aventuras transcurren en el lejano oeste estadounidense: "Jim Cutlass".

Jijé iba a ser el dibujante de la serie, pero propuso a Giraud, que era su alumno. Jijé hizo la portada de Fort Navajo (está firmada por él) y sustituyó a Giraud en Tormenta en el oeste un puñado de páginas, mientras Giraud viajaba a México para convertirse en Moebius. Suyas son desde el momento en que Blueberry escapa de los indios en el cañón hasta que vuelve a Fort Navajo y encuentra a Crowe en la muralla: toda la parte de los cactus, los mexicanos y Tucson. Luego volvió a sustituir a Gir en El jinete perdido, que es casi todo suyo.

En España, estas historietas también fueron publicadas en revistas como Bravo, Gran Pulgarcito o Mortadelo de Editorial Bruguera.

Fallecido Jean-Michel Charlier, Giraud se hizo cargo de la serie, aunque el primero de sus guiones, una mezcla de western y fantástico titulada "Blueberry 1900", fuera rechazada por el hijo del guionista belga.

En 1861 Mike Donovan, hijo de un hacendado sudista de Georgia, es acusado de asesinar al padre de su prometida, Harriet Tucker. Perseguido por el auténtico asesino, un esclavo huido le ayuda a pasar a las líneas nordistas en el preciso momento de estallar la Guerra de Secesión. Adopta el nombre de Mike S. Blueberry y pasa a ser corneta del regimiento de caballería. Pendenciero, aficionado al juego, al alcohol y a las mujeres, es un militar íntegro, audaz y con sentido de la estrategia que asciende hasta ser nombrado Teniente al final de la Guerra de Secesión.

Las aventuras del Teniente le llevan a conocer y salvar la vida del General nordista Dodge durante la guerra. Éste le devolverá el favor más tarde, intercediendo por Blueberry ante el presidente Ulisses S. Grant. Blueberry vivirá un tiempo entre los apaches donde se le conoce como Tsi-Na-Pah (Nariz Rota) y llegará a contar con la amistad del Gran Jefe Cochise y el amor de su hija, Chini. Así mismo, conoce y se enfrenta al mayor Chamán de Guerra apache, Gokhlayeh, más tarde conocido como Gerónimo, en una aventura que le lleva a Tombstone donde coincide con Wyatt Earp y Doc Holliday durante los acontecimientos del OK Corral.

Entre los personajes femeninos que aparecen en las aventuras de Blueberry, es una única mujer la que le obsesiona: la cabaretera conocida como Chihuahua Pearl (aunque también ha usado el nombre de Lilly Calloway).

Para el propio Jean Giraud, la serie ha sido muy importante, ya que, como él mismo afirma,

Hasta ahora las aventuras de Blueberry nos han sido contadas en tres series de álbumes:

El ejemplar de Apaches se marca como nº0 porque cronológicamente se sitúa entre la Juventud de Blueberry y el primer libro del Teniente Blueberry: Fort Navajo

En 2004 se realizó una adaptación de la historieta al cine ("Blueberry. La experiencia secreta") de la mano de Jan Kounen que cosechó poco éxito de critica y público y fue protagonizada por Vincent Cassel (Mike S. Blueberry), Juliette Lewis (Maria Sullivan) y Michael Madsen (Wallace Sebastian Blount). Colaboró Carlo de Boutiny.



</doc>
<doc id="15378" url="https://es.wikipedia.org/wiki?curid=15378" title="Economía de Andorra">
Economía de Andorra

El turismo es el principal componente de la economía de Andorra. Atractivo para los compradores de España y Francia por su condición de zona franca, el país ha desarrollado un importante complejo turístico muy activo en la temporada de invierno (gracias a los campos de esquí) y, en menor medida, en verano. En el año 2005, el país acogió a 11.049.490 visitantes. 

Andorra tiene un comercio muy activo en bienes de consumo, especialmente de productos manufacturados de importación, los cuales, al ser libres de impuestos ("duty-free") son más baratos en Andorra que en España o Francia. Como consecuencia, el contrabando es una práctica corriente. El estatus de zona franca de Andorra también ha creado una controversia con respecto a su relación con la Unión Europea. Las negociaciones sobre este tema empezaron en 1987, poco después de la incorporación de España a la UE. Un acuerdo de 1991 puso cuotas para el "duty-free" y puso límites en algunos productos (principalmente tabaco y bebidas alcohólicas). Aun así, a Andorra se le permite mantener diferencias de precio con los países de la UE, lo que es un atractivo para los visitantes.

El sector bancario, debido a la condición de paraíso fiscal del país, también contribuye sustancialmente a la economía de Andorra.

Aunque menos del 2% de la tierra es cultivable, la agricultura, conjuntamente con la ganadería, eran los principales soportes de la economía andorrana hasta el surgimiento del turismo. La ganadería ovina ha sido tradicionalmente la principal actividad económica, pero las plantaciones de tabaco son más lucrativas y es a lo que está destinada ahora la mayor parte de la superficie cultivada del país. La práctica totalidad de la comida de Andorra es importada.

Aparte de la artesanía, se fabrica cigarros, cigarrillos y muebles para mercados domésticos y de exportación. Una planta hidroeléctrica en Les Escaldes, con una capacidad de 15 megawattios, provee el 15% de la electricidad de Andorra; el resto de la electricidad consumida proviene de España y Francia.

Desde el 1 de enero de 2002 se utiliza el euro como moneda oficial. Los presupuestos se elaboraban en pesetas antes de la desaparición de la moneda española.

Los servicios representan el 80% del PIB de Andorra. En el año 2005, el país recibió a 11.049.490 visitantes, de los cuales 2.418.409 eran turistas y 8.631.081 excursionistas. El 57,2% de los visitantes eran españoles, el 39,8% eran franceses, y sólo un 3,0% venían de otros países.

Con unos 270 hoteles, 400 restaurantes y numerosos comercios, el turismo emplea a una gran porción de la fuerza laboral.


PIB (Producto Interior Bruto)

PIB "per capita"

Distribución del PIB por sectores

Crecimiento PIB estimado

Tasa de inflación

Importaciones

Exportaciones

Saldo (Exportaciones-Importaciones)

Población ocupada

Población ocupada por sectores

(Datos del gobierno andorrano del año 2000) 

Población bajo el umbral de la pobreza

Se presentan a continuación las mercancías de mayor peso en las importaciones de Andorra para el período 2010-2014. Las cifras están expresadas en dólares estadounidenses valor FOB.

Se presentan a continuación los principales socios comerciales de Andorra para el periodo 2010-2014.La mayoría de sus importadores están en América y Europa. Las cifras expresadas son en dólares estadounidenses valor FOB.


</doc>
<doc id="15380" url="https://es.wikipedia.org/wiki?curid=15380" title="El final de la etapa apostólica">
El final de la etapa apostólica

Hacia el año 62, el sumo sacerdote del judaísmo, Ananías, hizo apadrear al apóstol Santiago (llamado hermano de Jesús), que regía la iglesia de Jerusalén. Uno de sus hermanos, Simón, fue llamado a sucederle, pero la situación política y el nacionalismo judío llevaron pronto a Simón a la muerte, ante esta situación el consejo de ancianos (presbíteros) u obispos de la iglesia de Jerusalén trasladaron la iglesia a la ciudad de Pela, pero la situación política de Palestina se agravaba y los conflictos internos del hebraísmo eran cada día mayores. En el año 70 los romanos atacaron a Jerusalén y destruyeron el templo. Prontamente en manos de los romanos los grupos judíos de los saduceos, zelotes y esenios serían exterminados; de todos sólo el de los fariseos sobrevivió. Esa fue la razón de la división del judaísmo y el cristianismo. De los apóstoles vivía tan sólo Juan el evangelista, que se había trasladado a Éfeso, iglesia madre de muchas de Asia Menor y Gracia, donde se manifestaban brotes gnósticos. Durante los obispados de Lino y Anacleto en la iglesia de Roma, Roma fue ganando importancia en el cristianismo, por ser la capital del imperio y por ser el lugar de muerte de los apóstoles Pedro y Pablo. Para el obispado de Clemente, Roma se convirtió en la sede del cristianismo.

Con el emperador Vespasiano, el cristianismo siguió extendiéndose, hasta que, en el año 90, Domiciano inició una nueva persecución. Juan fue llevado primero a Roma y desterrado luego a la isla de Patmos, donde escribió el "Apocalipsis" y algunas de sus cartas. Bajo el imperio de Nerva, de quien dice su biógrafo Xifilino que "no permitió que se acusase a nadie por haber observado las ceremonias de la religión judaica o haber descuidado el culto de los dioses, pudo regresar Juan a Éfeso, y pocos años después falleció, a edad muy avanzada. Con su muerte concluye la etapa apostólica. 

Algunas características de esta etapa: 
Al concluir el siglo I, el cristianismo se ha extendido por la cuenca del Mediterráneo, cuenta con los libros religiosos básicos y las distintas comunidades urbanas se sienten unidas. Surge entonces el gnosticismo. Algunos autores han considerado fundador a Simón el Mago (a quien se refieren los Hechos de los Apóstoles. Doctrina filosófico-religiosa de los primeros siglos de la Iglesia, mezcla de la cristiana con creencias orientales y judaicas, que pretendía tener un conocimiento intuitivo y misterioso de las cosas divinas. Doctrina sincretista en su fondo, el gnosticismo advertía la oposición existente entre el mundo material (malo) y el espiritual (bueno). La materia era obra de un demiurgo (dios inferior o de los ángeles, y esto les llevó a considerar que el cuerpo de Jesucristo no podía ser materia (pues no podía ser malo). La salvación para el gnóstico dependía del conocimiento personal, era fruto de su ciencia. 

En el siglo II, ciertas ideas gnósticas, la trascendencia de las cuales queda implícita tras su simple enunciación, influyeron en varios sectores cristianos y tendieron a la racionalización de la fe. Apuntaba el peligro de las primeras creencias consideradas herejía, del mismo modo que habían empezado las persecuciones. 




</doc>
