<doc id="1217" url="https://es.wikipedia.org/wiki?curid=1217" title="Fisiología humana">
Fisiología humana

La fisiología (del griego "physis", naturaleza, y "logos", conocimiento, estudio) es la ciencia que estudia las funciones de los seres multicelulares (vivos). Es una de las ciencias más antiguas del mundo. Muchos de los aspectos de la fisiología humana están íntimamente relacionadas con la fisiología animal, en donde mucha de la información hoy disponible ha sido conseguida gracias a la experimentación animal, pero sobre todo gracias a las autopsias. La anatomía y fisiología son campos de estudio estrechamente relacionados en donde la primera hace hincapié en el conocimiento de la forma mientras que la segunda pone interés en el estudio de la función de cada parte del cuerpo, siendo ambas áreas de vital importancia en el conocimiento médico general

La homeostasia, (del griego "homoios" que significa "similar", y "stasis", en griego στάσις, "posición", "estabilidad") es un término que usan los fisiólogos para describir y explicar la persistencia de las condiciones estáticas o constantes en el medio interno. Esencialmente, todo órgano y tejido en el cuerpo llevan a cabo funciones que ayudan a mantener estas condiciones constantes. Desde los pulmones que captan el oxígeno, hasta los riñones que mantienen constantes las concentraciones de iones en el cuerpo, cada órgano y célula aporta una función que se suma a las funciones totales de los demás sistemas que permiten la vida del ser humano. La homeostasis también es un proceso para la regulación del ejercicio físico

El 65% del cuerpo humano está formado de líquido y la mayor parte de este líquido se encuentra dentro de las células ("líquido intracelular") aproximadamente 65% de la cantidad de agua; de cualquier modo, alrededor de un tercio (35% restante) se encuentra en los espacios por fuera de las células y compone lo que conocemos como "líquido extracelular". De este contamos con líquido intersticial (20% de la cantidad de agua) y líquido intravascular (15% restante o 5% del peso del cuerpo). También están los líquidos del tercer espacio que cuentan con menos del 1% (Líquidos pleural, cefalorraquídeo, intraarticular, pericardico, intraocular). A diferencia del primero, este líquido se encuentra siempre en movimiento en el organismo. Es mezclado rápidamente por la circulación de la sangre y por difusión entre la misma y los líquidos tisulares, y en el líquido extracelular se encuentran los iones y nutrientes que se requieren para que las células conserven su función. Prácticamente, todas las células viven rodeadas de líquido extracelular, por lo que a este líquido se le conoce como medio interno del cuerpo o "milieu intérieur" como le llamó el fisiólogo Claude Bernard.

Las células se desarrollan y llevan a cabo sus funciones, tanto más si estas son especializadas, mientras tengan a mano en el medio interno las concentraciones adecuadas de iones, oxígeno, glucosa, diversos aminoácidos y otras sustancias que le sirven como bloques de nutrición.

El cuerpo está formado por células, estas a su vez forman tejidos, los tejidos a su vez forman órganos, estos forman aparatos y, a su vez estos componen los sistemas que mantienen el cuerpo vivo.

Esta clasificación por sistemas es una forma arbitraria de clasificación. Muchas partes del cuerpo participan de manera interconectadas ( sobre todo el cerebro por su función hormonal a nivel del hipotálamo sobre el resto del organismo)), es por ello, que los sistemas pueden ser organizados según función, origen embriológico u otro tipo de característica particular. Dentro de estos casos, es el sistema neuroendocrino, el complejo que se encarga de la regulación fisiológica por medio de efectores a nivel periféricos en cada uno de los otros sistemas. Además, muchos aspectos de la fisiología clásica no se pueden incluir fácilmente dentro de esta clasificación tradicional.

El estudio de cómo ciertas enfermedades o situaciones extrafisiológicas afectan a la fisiología se denomina fisiopatología.

El cuerpo humano posee variados sistemas de control. Son estos mecanismos los que permiten la vida y poseen una gran importancia biomédica, en virtud de que si uno de los sistemas falla, el equilibrio homeostático se ve en riesgo y en ocasiones el fallo puede ser incompatible con la vida. Los más complejos son los sistemas de control genético dentro de la célula, pero existen otros que se hacen patentes desde el punto de vista de un órgano o sistema como un todo. Dentro de estos mecanismos de control, que son unos cientos, tenemos la regulación de concentraciones de oxígeno y dióxido de carbono, regulación de la presión arterial, la regulación de la temperatura corporal, regulación hormonal, entre otros.

Los sistemas de control del cuerpo humano actúan mediante un proceso de "retroalimentación negativa (negative feedback)". Si algún factor cualquiera alcanza concentraciones exageradas o excesivas o demasiado bajas, un sistema de control inicia una retroalimentación negativa que consiste de una serie de cambios que devuelven al factor antes mencionado hacia un valor medio determinado, con lo que se mantiene la homeostasis. Un buen ejemplo para ilustrar este proceso es la regulación de la concentración de dióxido de carbono en el organismo. Cuando existe una concentración incrementada de CO2 en el líquido extracelular, se aumenta la ventilación pulmonar, lo que al mismo tiempo hace disminuir la concentración del gas en el medio interno, ya que aumenta su expulsión en cada respiración. Esto es lo mismo que decir que la respuesta es negativa con respecto del estímulo inicial. Del modo contrario, si el CO2 disminuye de manera excesiva, se comienza el proceso del sistema de control para que los niveles del gas se incrementen a un nivel adecuado del mismo ya que es de vital importancia para el ser humano.

A la retroalimentación positiva también se le conoce como "círculo vicioso" y es regularmente fatal para el organismo que lo padece. Una retroalimentación positiva, al contrario de la retroalimentación negativa, no deriva en una estabilidad del sistema, si no en una inestabilidad peligrosa. Un ejemplo para ilustrar este concepto es: cuando un hombre sufre una hemorragia grave de dos litros de sangre provocando que el volumen de sangre sea tan bajo que el corazón no disponga del suficiente como para bombear con eficacia. Esto hace que la presión arterial caiga y el riego sanguíneo de las arterias coronarias del corazón al músculo cardíaco sea tan bajo que el órgano comienza a sufrir, por falta de oxígeno. Esto debilita al corazón y hace que el bombeo sea más débil y disminuido, lo que hace que el corazón se debilite más, continuando así hasta que el sistema se colapse por culpa del círculo vicioso generado.

En muchos casos el mismo organismo tratará de proveer una retroalimentación negativa para romper el círculo vicioso en el que se encuentran los factores. Si en el ejemplo de la hemorragia, a la persona en lugar de dos litros fuera solo un litro la pérdida de sangre, los mecanismos de control normales proporcionarían la retroalimentación negativa para controlar el gasto cardiaco y la presión arterial compensarán de manera eficaz la retroalimentación positiva y la persona se recuperará sin dificultades. Lo mismo sucede si hay una intervención de urgencia por el cuerpo de salud que pueden trasfundir plasma o sangre al paciente para evitar un shock.

Durante el parto ocurre un efecto beneficioso de la retroalimentación positiva con la hormona oxitocina.

Es un mecanismo de control especial del sistema nervioso. Permite adaptarse a una situación antes de que se alteren las variables, y siempre es mediado por el mismo sistema nervioso. Cuando el cerebro ordena hacer algo, recibe una señal retrospectiva sobre lo que ha hecho, y si fuera necesaria una corrección la hará la próxima vez que realice ese movimiento. Intervienen particularmente el cerebelo y los ganglios basales, y está relacionado con habilidades de aprendizaje motor y coordinativo.

Atendiendo a los diversos tipos de células, órganos y sistemas, podemos distinguir los siguientes:




</doc>
<doc id="1218" url="https://es.wikipedia.org/wiki?curid=1218" title="Flavio Josefo">
Flavio Josefo

Tito Flavio Josefo, también conocido por su nombre hebreo "José ben Matityahu" o "Josefo ben Matityahu" (n. 37-38 – Roma, 101), fue un historiador judío fariseo, descendiente de familia de sacerdotes. Hombre de acción, estadista y diplomático, fue uno de los caudillos de la rebelión de los judíos contra los romanos. Apresado y trasladado a Roma, llegó a ser favorito de la familia imperial "Flavia". En Roma escribió, en griego, sus obras más conocidas: "La guerra de los judíos", "Antigüedades judías" y "Contra Apión". Fue considerado como un traidor a la causa judía y odiado por los judíos. Su obra fue preservada por los romanos y los cristianos.

Flavio Josefo (en griego antiguo Ἰώσηπος, Iốsēpos, en hebreo יוסף בן מתתיהו) nació alrededor del año 37 en el seno de una familia sacerdotal de Judea ligada a la monarquía de los asmoneos. Su nombre originario era "Yosef ben Mattityahu" o "Yossef bar Mattityahu", es decir, "José hijo de Matías", aunque cuando el emperador Vespasiano hizo de él un ciudadano romano, lo latinizó asociándolo a la familia del bienhechor que lo liberó tras hacerle prisionero, como Tito Flavio Josefo ("Titus Flavius Iosephus"). En los siglos XVI y XVIII se impuso la modalidad ortográfica de «Josefo» para distinguirlo de los santos llamados José, aunque los ingleses lo citan por su nombre latino «Josephus».

Ya desde pequeño se caracterizó por su buena memoria y su facilidad de aprendizaje, lo que le permitió desarrollar sus dotes intelectuales. En el año 64 se trasladaría a Roma para conseguir de Nerón la liberación de algunos sacerdotes judíos amigos suyos capturados durante las revueltas judías contra los romanos, causa por la que es procesado y encarcelado. Sin embargo, pronto es liberado gracias al apoyo de Popea Sabina, esposa del emperador.

Tras su vuelta a Jerusalén, en el año 66 estalló la Gran Revuelta Judía. Fue designado por el Sanedrín de Jerusalén como comandante en jefe de Galilea, organizando su administración y defensa. Capituló en el verano del año 67, tras seis semanas defendiendo la casi inexpugnable fortaleza de Jotapata. La mayoría de sus compatriotas fueron asesinados y Josefo fue capturado y llevado ante la presencia del por entonces general Vespasiano. Ante él hizo muestras de su gran formación y predijo que pronto sería emperador, lo que le llevó a ganarse el perdón cuando se cumplió la predicción. Así, Josefo pasó a llamarse Flavio Josefo, siendo liberado en el año 69. 

Josefo se unió al séquito de Tito, hijo de Vespasiano, en el año 70 en su marcha hacia Judea, siendo testigo ocular de la destrucción de Jerusalén y del Segundo templo y participando como mediador entre ambas partes.

En el año 71 viaja a Roma y, por orden del emperador, se le otorga una pensión, la ciudadanía romana bajo el nombre de Tito Flavio y una casa que fue residencia del mismo Vespasiano. Será aquí donde desarrollará su trabajo literario e histórico. Murió durante el mandato de Trajano (probablemente en 101).

Flavio Josefo no busca la asimilación del mundo hebreo al grecorromano, sino el reconocimiento de su dignidad.

Sobre su método nos dice: «…yo creo que si lo que interesa es extraer la verdadera interpretación de los hechos a partir de los hechos mismos, y no seguir vanas opiniones, lo adecuado es todo lo contrario [no despreciar los testimonios de los pueblos no griegos]» ("Antigüedades judías", 6). El autor consideraba que la audacia es una fuerza fundamental en los acontecimientos históricos, por ejemplo: «… no consiguieron lo que habían planeado contra mí, pues yo les había salido al paso con una estratagema mejor» ("Autobiografía", LV). 

A pesar de creer en la potencia de la Fortuna, no es supersticioso: «y ridiculizaba lo absurdo de la acusación de brujería, señalando que si los romanos pudiesen vencer a sus enemigos mediante hechiceros, no mantendrían tantos miles de soldados» ("Autob.," XXI).

Escribió los siguientes libros en griego:


Su primera obra escrita en Roma fue un relato de la guerra judía, dirigida a ciertos "bárbaros superiores" -normalmente considerados como la comunidad judía de Mesopotamia- en su "lengua paterna" (Guerra I.3), posiblemente el idioma era arameo occidental. En el 78 d.C. terminó la obra en siete volúmenes en griego, conocida como "Guerra judía" (en latín "Bellum Judaicum" o "De Bello Judaico"). Comienza con los hechos del período de los Macabeos y concluye con los relatos de la caída de Jerusalén y la caída sucesiva de las fortalezas de Herodión, Maqueronte y Masada y las posteriores celebraciones romanas de victoria en Roma, las operaciones de limpieza, y el levantamiento contra el imperio en Cirene. Junto con el relato de algunos de esos mismos eventos en su autobiografía "Vida", también en ella proporciona al lector una visión general de la parte de Josefo en los acontecimientos desde su regreso a Jerusalén después de una breve visita a Roma a principios de los años 60 (Vida 13-17).

A raíz de la supresión de la revuelta judía, Josefo habría presenciado las marchas de las legiones triunfantes de Tito dirigiendo a sus cautivos judíos y llevando los tesoros del Templo despojado de Jerusalén. Fue en este contexto que Josefo escribió su Guerra, alegando estar en contra de las cuentas antijudías. Él discute la demanda de que los judíos sirvieran a un dios derrotado, y que eran naturalmente hostiles a la civilización romana. Más bien, culpa de la guerra judía a lo que él llama "fanáticos no representativos y excesivamente celosos" entre los judíos, que llevaron a las masas lejos de sus líderes aristocráticos tradicionales (como él), con resultados desastrosos. Josefo también culpa a algunos gobernadores romanos de Judea, representándolos como administradores atípicamente corruptos e incompetentes. Según Josefo, el judío tradicional era, debería ser, y puede ser, un ciudadano leal y amante de la paz. Los judíos pueden e históricamente han aceptado la hegemonía de Roma precisamente porque su fe declara que Dios mismo da a los imperios su poder.

El siguiente trabajo de Josefo en veintiún volúmenes fue "Antigüedades de los judíos", completado durante el último año del reinado del emperador Flavio Domiciano (entre 1.9.93 y 14.3.94, véase AJ X.267). Al exponer la historia, la ley y las costumbres de los judíos, estaba entrando en muchos debates filosóficos de actualidad en la Roma de esa época. Una vez más, ofrece una apología de la antigüedad y el significado universal del pueblo judío. Josefo afirma estar escribiendo esta historia porque "vio que otros pervirtieron la verdad de esas acciones en sus escritos", siendo esos escritos sobre la historia de los judíos. En cuanto a algunas de sus fuentes para el proyecto, Josefo dice que él dibujó e "interpretó de las Escrituras Hebreas" y que era un testigo ocular de la guerra entre los judíos y los romanos, que había contado anteriormente en las guerras judías.

Describe la historia judía comenzando con la Creación, tal como se transmite a través de la tradición histórica judía. Asegura que Abraham enseñó ciencia a los egipcios, quienes, a su vez, enseñaron a los griegos. Moisés estableció una aristocracia senatorial sacerdotal, que, como la de Roma, resistió a la monarquía. Presenta a las grandes figuras del Tanaj como filósofos ideales. E incluye un apéndice autobiográfico defendiendo su conducta al final de la guerra cuando cooperó con las fuerzas romanas.

Louis H. Feldman esboza la diferencia entre llamar a esta obra Antigüedades de los judíos en lugar de la Historia de los judíos. Aunque Josefo dice que describe los acontecimientos contenidos en las Antigüedades "en el orden del tiempo que les pertenece", Feldman argumenta que Josefo "tenía la intención de organizar [su] material sistemáticamente en lugar de cronológicamente" y tenía un alcance que " Politiza a las instituciones políticas, a la vida religiosa y a la vida privada".

"Contra Apión" es una defensa en dos volúmenes del judaísmo como religión clásica y filosófica, haciendo hincapié en su antigüedad, en contraposición a lo que Josefo afirmaba que era la tradición relativamente más reciente de los griegos. También se abordan algunas acusaciones antijudaicas atribuidas por Josefo al escritor griego Apion, y los mitos acreditados a Manetón.

Hacia el año 93, escribe "Antigüedades judías". En el libro XVIII consta una mención a Jesús de Nazaret que ha recibido el nombre de "Testimonio flaviano, "cuya veracidad sigue siendo motivo de controversia actualmente.

En el libro XX, escribe también acerca del «hermano del llamado Jesucristo, de nombre Santiago»:
En el mismo libro de "Antigüedades judías", menciona la muerte de Juan el Bautista por orden de Herodes Antipas "(Ant., XVIII, v, 2)".

En el libro sexto de "La guerra de los judíos" se encuentra una completa descripción del famoso Templo de Salomón, que junto con la de la Mishná y la Biblia ha servido de controversia a lo largo de la historia para debatir sobre el tamaño y la forma del edificio. Especialmente en el Renacimiento dividió a los estudiosos en dos tendencias:

Es muy probable que el Monasterio de El Escorial, la obra cumbre del católico Felipe II, esté basado en las descripciones de Josefo, dentro de la línea historicista del hebraísta Benito Arias Montano.

Durante la Edad Media, en toda Europa, Josefo fue un autor muy leído. Su obra reviste una importancia de primer orden para la historia del pueblo hebreo y aclara algunos hechos históricos importantes, como el asedio y destrucción de Masada en el año 74. También realiza descripciones de las sectas históricas del antiguo judaísmo: fariseos, saduceos y zelotes y la algo extravagante comunidad de los esenios (uno de cuyos asentamientos fue Qumram). Se encuentran asimismo algunas de las primeras noticias históricas referentes al cristianismo, como el martirio del hermano de Jesús, Santiago, o el sacrificio de Jesús en una cruz, en tiempos de Poncio Pilato, texto que se ha considerado muy deformado por la tradición de copia cristiana, pero que ha sido reconstruido en su forma original con ayuda de copias sirias.



Sobre Flavio Josefo



</doc>
<doc id="1219" url="https://es.wikipedia.org/wiki?curid=1219" title="Fósil">
Fósil

Los fósiles (del latín "fossilis", que significa ‘excavado’) son los restos o señales de la actividad de organismos pretéritos. Dichos restos, conservados en las rocas sedimentarias, pueden haber sufrido transformaciones en su composición (por diagénesis) o deformaciones (por metamorfismo dinámico) más o menos intensas. La ciencia que se ocupa del estudio de los fósiles es la paleontología. Dentro de la paleontología están la paleobiología, que estudia los organismos del pasado —entidades paleobiológicas, que conocemos solo por sus restos fósiles—, la biocronología, que estudia cuándo vivieron dichos organismos y la tafonomía, que se ocupa de los procesos de fosilización.

El vocablo fósil se deriva del verbo latino "fodere", excavar, a través del sustantivo "fossile", aquello que es excavado.
A lo largo de toda la historia, y antes, en la prehistoria, el hombre ha encontrado fósiles, restos de seres vivos petrificados por los minerales con los que se hallaban en contacto. Fueron esos minerales los que sustituyeron o preservaron su forma externa.

El hombre primitivo les atribuía un significado mágico. Los autores de la Antigüedad clásica los habían observado y, en general, interpretado correctamente. El término "fósil" lo empleaba ya Plinio en el siglo I, y su uso fue recuperado en el siglo XVI por Agricola, aludiendo a su carácter de cuerpo enterrado (como derivado de "fossa") e incluía tanto los restos orgánicos como los cuerpos minerales integrados en los materiales de la corteza terrestre. Esta situación se mantuvo hasta principios del siglo pasado, si bien es verdad que los auténticos fósiles solían diferenciarse como fósiles organizados.

El geólogo británico Lyell definió a los fósiles como restos de organismos que vivieron en otras épocas y que actualmente están integrados en el seno de las rocas sedimentarias. Esta definición conserva su validez, aunque actualmente el término tiene una mayor amplitud, ya que se incluyen en el mismo las manifestaciones de la actividad de organismos como excrementos (coprolitos), restos de construcciones orgánicas, huellas de pisadas, impresiones de partes del cuerpo, dentelladas (icnofósiles), etc.

Existen regiones de la Tierra que son conocidas por su particular riqueza en fósiles; por ejemplo, las pizarras de Burgess Shale en la Columbia Británica de Canadá, la caliza de Solnhofen o los estratos ricos en dinosaurios de la Patagonia.

En España, destacan Atapuerca y Las Hoyas. El primero es un rico yacimiento del Pleistoceno donde se han encontrado, entre otros, abundantes fósiles de homínidos. El segundo es conocido por la presencia de "Iberomesornis".

Los lugares que hacen posible una preservación excepcional (incluso a veces conservando señales de tejidos blandos) son conocidos como Lagerstätten (lugares de descanso o almacenamiento, en alemán).

Los fósiles más antiguos son los estromatolitos, que consisten en rocas formadas por la precipitación y fijación de carbonato cálcico, merced a la actividad bacteriana. Esto último se ha podido saber gracias al estudio de los estromatolitos actuales, producidos por tapetes microbianos. La formación Gunflint contiene abundantes microfósiles ampliamente aceptados como restos microbianos.

Hay muchas clases de fósiles. Los más comunes son restos de ammonoidea, caracoles o huesos transformados en piedra. Muchos de ellos muestran todos los detalles originales del caracol o del hueso, incluso examinados al microscopio. Los poros y otros espacios pequeños en su estructura se llenan de minerales.

Los minerales son compuestos químicos, como la calcita (carbonato de calcio), que estaban disueltos en el agua. El paso por la arena o el lodo que contenían los caracoles o los huesos y los minerales se depositaron en los espacios de su estructura. Por eso los fósiles son tan pesados.
Otros fósiles pueden haber perdido todas las marcas de su estructura original. Por ejemplo, una concha de caracol originalmente de calcita puede disolverse totalmente después de quedar enterrada. La impresión que queda en la roca puede llenarse con otro material y formar una réplica exacta de la concha. En otros casos, la concha se disuelve y tan solo queda el hueco en la piedra, una especie de molde que los paleontólogos pueden llenar con yeso para descubrir la forma del resto.

Desde un punto de vista práctico distinguimos:
Los fósiles por lo general solo muestran las partes duras del animal o planta: el tronco de un árbol, el caparazón de un caracol o los huesos de un dinosaurio o un pez. Algunos fósiles son más completos: registran una mayor cantidad de información paleobiológica. Si una planta o animal queda enterrado en un tipo especial de lodo que no contenga oxígeno, algunas de las partes blandas también pueden llegar a conservarse como fósiles.

Los más espectaculares de estos "fósiles perfectos" son mamuts lanudos completos hallados en suelos congelados. La carne estaba tan congelada, que aún se podía comer después de 20 000 años. Los fósiles más recientes, por convenio, son los referidos a organismos que vivieron a finales de la última glaciación cuaternaria, es decir, hace unos 13 000 años aproximadamente. Los restos posteriores (Neolítico, Edad de los Metales, etc.) suelen considerarse ordinariamente como subfósiles.

Finalmente deben considerarse también aquellas sustancias químicas incluidas en los sedimentos que denotan la existencia de determinados organismos que las poseían o las producían en exclusiva. Suponen el límite extremo de la noción de fósil (marcadores biológicos o fósiles químicos).

Los icnofósiles son restos de deposiciones, huellas, huevos, nidos, bioerosión o cualquier otro tipo de impresión. Son el objeto de estudio de la Paleoicnología.

Los icnofósiles presentan características propias que les hacen identificables y permiten su clasificación como parataxones: icnogéneros e icnoespecies. Los parataxones son clases de pistas fósiles agrupadas por sus propiedades comunes: geometría, estructura, tamaño, tipo de sustrato y funcionalidad. Aunque a veces diagnosticar la especie productora de un icnofósil puede resultar ambiguo, en general es posible inferir al menos el grupo biológico o el taxón superior al que pertenecía.

En los icnofósiles se pueden identificar varios tipos de comportamiento: filotaxia, fobotaxia, helicotaxia, homostrofia, reotaxia,tigmotaxia y agropecuaria

El término icnofacies hace referencia a la asociación característica de pistas fósiles, recurrente en el espacio y en el tiempo, que refleja directamente condiciones ambientales tales como la batimetría, la salinidad y el tipo de sustrato. Las pistas y huellas de invertebrados marinos son excelentes indicadores paleoecológicos, al ser el resultado de la actividad de determinados organismos, relacionada con ambientes específicos, caracterizados por la naturaleza del sustrato y condiciones del medio acuático, salinidad, temperatura y batimetría. Especialmente la profundidad del mar condiciona el género de vida de los organismos y, por tanto, no es de extrañar que se puedan distinguir toda una serie de icnofacies de acuerdo con la batimetría, cuya nomenclatura, debida a Seilacher, se refiere al tipo de pistas más frecuentes y más carcterísticas de cada una.

Un icnofósil puede tener varias interpretaciones:

"Microfósil" es un término descriptivo que se aplica al hablar de aquellos fósiles de plantas o animales cuyo tamaño es menor de aquel que puede llegar a ser analizado por el ojo humano. Normalmente se utilizan dos rasgos diagnósticos para diferenciar microfósiles de eucariotas y procariotas:

El ámbar (resina fósil) es un polímero natural encontrado en muchos tipos de estratos por todo el mundo, incluso en el Ártico. Se trata de la resina fosilizada de árboles hace millones de años. Se presenta en forma de piedras amarillentas.

En el ámbar pueden encontrarse fósiles de insectos y otros pequeños animales que, en su momento, quedaron atrapados por la resina.

Los pseudofósiles son patrones visuales en rocas, producidos por procesos geológicos, que se asemejan a formas propias de los seres vivos o sus fósiles; un ejemplo clásico son las dendritas de pirolusita (óxido de manganeso, MnO), que parecen restos vegetales. La interpretación errónea de los pseudofósiles ha generado ciertas controversias a lo largo de la historia de la Paleontología. En el año 2003, un grupo de geólogos españoles puso en entredicho el origen orgánico de los fósiles de Warrawoona que, según William Schopf, correspondían a cianobacterias que constituían el primer rasgo de vida sobre la Tierra hace 3.500 millones de años. La base de tal replanteamiento era que estructuras filamentosas, similares a estos supuestos microfósiles de Warrawoona, pueden ser producidos a temperatura y presión ambiente por la combinación, en un medio alcalino, de una sal de bario y un silicato. Un nuevo estudio publicado en 2015 por la revista "Proceedings of the National Academy of Sciences" resolvió finalmente la controversia. Los investigadores David Wacey y Martin Saunders utilizaron microscopía electrónica de transmisión para examinar rebanadas ultradelgadas de los candidatos a microfósiles y así construir mapas a escala nanométrica de su tamaño, forma, química y distribución de carbón mineral. Esto hizo evidente que la distribución de carbono era diferente a todo lo visto en microfósiles auténticos y revelando su origen mineral.

Un fósil viviente es un término informal usado para referirnos a cualquier especie viviente que guarde un gran parecido con una especie conocida por fósiles (se podría decir que es como si el fósil hubiera "cobrado vida").

Los braquiópodos son un ejemplo perfecto de "fósiles vivientes". "Lingula" es un braquiópodo actual del que se encuentran fósiles a través de todo el Cenozoico. Otro ejemplo es el celacanto. Fue una gran sorpresa encontrar este pez en las costas de África en 1938, cuando se pensaba que llevaban 70 millones de años extintos.

El registro fósil es el conjunto de fósiles existentes. Es una pequeña muestra de la vida del pasado distorsionada y sesgada. No se trata, además, de una muestra al azar. Cualquier investigación paleontológica debe tener en cuenta estos aspectos, para comprender qué se puede obtener a través del uso de los fósiles.

El número de especies totales (entre plantas y animales) descritas y clasificadas asciende a 1,5 millones. Este número sigue en aumento, pues se descubren aproximadamente diez mil insectos cada año (existe una gran diversidad de insectos, se conocen 850 000 especies). Se estima que solo falta un centenar de especies de aves por describir (existe una baja diversidad de aves, pues solo se conocen 8600 especies). Las estimaciones sobre las especies vivas posibles son de cinco millones. Se conocen unas 300 000 especies de fósiles, es decir, el 20 % del número de especies vivientes conocidas y menos del 6 % de las probables. El registro fósil abarca desde hace 3500 millones de años hasta la actualidad; sin embargo, el 99 % de sus representantes se encuentran desde hace 545 millones de años hasta ahora. Son comparaciones asombrosas si consideramos que el registro fósil incluye centenares de millones de años y que la fauna y la flora vivientes representan solo un instante de tiempo geológico. Si la conservación de los fósiles fuera aceptablemente buena, sería previsible que el número de especies extintas superara en mucho el número de las especies actuales.

Hay varias explicaciones posibles a la pobreza relativa en especies extintas:
Todo sugiere que la diversidad actual puede no ser apreciablemente más alta que la media en todo el tiempo que va desde el Cámbrico. Por lo tanto la baja cifra de especies extintas no puede explicarse satisfactoriamente por la idea de que la diversidad crece con el progreso evolutivo. Las especies se extinguen y son reemplazadas por otras durante el curso del tiempo geológico. Se ha sugerido el plazo de 12 millones de años para un reemplazo completo de todas las especies. La duración de los distintos biocrones está entre 0,5 y 5 millones de años (2,75 millones de años el biocrón medio). Finalmente, como conclusión, la cantidad de especies extintas estimadas es:
formula_1

Para que un resto corporal o una señal de un organismo merezca la consideración de fósil es necesario que se haya producido un proceso físico-químico que le afecte, conocido como fosilización. En este proceso se pueden producir transformaciones más o menos profundas que pueden afectar a su composición y estructura. Este proceso va en función del tiempo, por lo que debe haber transcurrido un determinado intervalo a partir del momento de producción del resto para que llegue a la consideración de fósil.
La fosilización es un fenómeno excepcionalmente raro, ya que la mayoría de los componentes de los seres vivos tienden a descomponerse rápidamente después de la muerte.

La permineralización ocurre después del enterramiento, cuando los espacios vacíos en un organismo (espacios que en vida estaban llenos de líquido o gas) se llenan con agua subterránea, y los minerales que esta contiene precipitan, llenando dichos espacios.

En muchos casos los restos originales del organismo han sido completamente disueltos o destruidos.

Son los principales responsables en el mundo. Su efecto es la rareza con que se conservan partes orgánicas blandas (0.01 % de los individuos en una comunidad marina solo tienen partes blandas). La presencia de partes blandas son indicativas de condiciones sedimentológicas y diagenéticas excepcionales.

Son los más rápidos y eficaces para la biodegradación. Por ello, las condiciones anóxicas son un requisito previo a la preservación de organismos ligeramente mineralizados y de partes blandas. La demanda de oxígeno para la descomposición en un medio aeróbico es muy alta (1 mol de Corg. requiere 106 moles de O). Una reacción estándar sería así:
formula_2

La descomposición es la principal fuente de pérdida de información en el registro fósil y la mineralización es la única vía de frenarla. Los tejidos pueden conservarse como permineralizaciones, residuos orgánicos alterados o, con el deterioro prolongado, como improntas. Si la descomposición supera a la mineralización, se destruyen los tejidos y solo se conservan refractarios como la quitina, la lignina o la celulosa.

La descomposición en el registro fósil puede caracterizarse a tres niveles:

La mayor parte se recicla (dando lugar a CO) dentro de la columna de agua, particularmente en la zona eufótica. Una proporción relativamente pequeña de la materia orgánica producida pasa a formar parte de los sedimentos adyacentes, y quedan afectadas por los modificadores del flujo orgánico (bioestratinómicos), que son la foto-oxidación, la actividad microbiana y los organismos detritívoros.

La materia orgánica incluye además de lípidos libres, biopolímeros como los hidratos de carbono, proteínas, quitina y lignina, algunos de los cuales serán utilizados para su consumo y modificación por organismos bentónicos y diversos microorganismos. El resto, no utilizado de esta manera, puede sufrir policondensación para formar geopolímeros, y pasa a formar parte del protoquerógeno, precursor del querógeno. Con el entierro del sedimento, la creciente condensación e insolubilización produce la lenta conversión diagenética a querógeno que constituye el volumen de la materia orgánica en antiguos sedimentos.

Las moléculas orgánicas (fósiles químicos) son abundantes en muchos sedimentos y rocas sedimentarias, y se denominan marcadores biológicos "biomarker". Su estudio e identificación requieren técnicas sofisticadas de toma de muestra y análisis. Conservan un registro muy detallado de la actividad biológica del pasado y están relacionados con moléculas orgánicas actuales. Las posibles fuentes de marcadores biológicos en muestras geológicas son tantas como moléculas se conocen en los organismos.

Una roca madre es un volumen rocoso que ha generado o ha estado generando y expeliendo hidrocarburos en cantidades suficientes para formar acumulaciones de petróleo y gas. La mayoría de las rocas madre potenciales contienen entre 0,8 y 2 % de carbono orgánico. Se acepta un límite aproximado del 0,4 % como el volumen más bajo de carbono orgánico para la generación de hidrocarburos, estando el óptimo por encima del 5-10 %. La naturaleza de los hidrocarburos generados depende fundamentalmente de la composición del querógeno, que puede estar constituido por dos tipos de materia orgánica:

La durabilidad de los esqueletos es la resistencia relativa de estos a la fractura y destrucción por agentes físicos, químicos y bióticos. Estos procesos destructivos pueden dividirse en cinco categorías que siguen un orden más o menos secuencial:
Los procesos destructivos de desarticulación, fragmentación y corrasión son muy evidentes en el registro fósil. Estos procesos afectan de manera diferente a los distintos tipos de esqueletos. La mayoría de los organismos marinos se puede asignar a una de las cinco categorías arquitectónicas de esqueleto: macizo, arborescente, univalvo, bivalvo o de elementos múltiples.
Cuando se toman en conjunto los distintos tipos de esqueletos y sus sensibilidades a los agentes destructivos, nos encontramos con unos excelentes indicadores de los procesos sedimentarios, lo que puede usarse para definir distintas tafofacies.

Si se considera como partículas sedimentarias los restos esqueléticos de los organismos, se podrá realizar estudios sobre su comportamiento hidrodinámico (conchas de braquiópodos, bivalvos, gasterópodos, cefalópodos, ostrácodos y crinoideos). En general se conoce poco del comportamiento hidrodinámico de estas partes duras, tan abundantes e importantes ecológicamente en ambientes de aguas poco profundas de medios modernos y del registro fósil. El comportamiento hidrodinámico de las conchas es complejo e imprevisible, principalmente debido a la gran diversidad de formas involucradas.

La comprensión de los procesos diagenéticos es fundamental para interpretar correctamente la mineralogía original, estructura de esqueletos y conchas, sus afinidades taxonómicas y su paleoecología. Un problema que se plantea muy frecuentemente es deducir cual ha sido la mineralogía original de grupos extintos (corales rugosos, arqueociátidos, estromatopóridos...). La transición hasta el estado de fósil depende mucho de la composición esquelética.

Después del enterramiento el carbonato se altera en mayor o menor magnitud durante la diagénesis temprana.

El aragonito normalmente se transforma en calcita mediante uno de estos procesos principalmente:

En general, los esqueletos fósiles que estaban constituidos por calcita mantienen frecuentemente esta composición original (a menos que se hayan silicificado o dolomitizado). El contenido en magnesio tiende a reducirse, de forma que puede haber alteración diagénica con alto o bajo contenido de calcita. Existen técnicas especiales como la catodoluminiscencia que permiten determinar su contenido original a partir de áreas relictas que han conservado su composición original.

La preservación de partes blandas está asociada en muchas ocasiones con la precipitación de carbonatos en forma de nódulos y estratificados, como es el caso de las calizas litográficas. Los nódulos carbonatados están constituidos por siderita o calcita y asociados a sedimentos arcillosos ricos en microorganismos. Contienen fósiles que a menudo se conservan en tres dimensiones incluyendo a veces partes blandas fosilizadas. Su tamaño varía entre 10 y 30 centímetros aunque se han encontrado de hasta 10 metros (incluyendo un plesiosaurio completo). El contenido en microorganismos y su descomposición son los factores primarios que controlan el grado de anoxia, Eh y pH. En presencia de oxígeno, la respiración microbiana produce CO que se acumula en el agua de los poros del sedimento, favoreciendo la disolución de los carbonatos

formula_3

En ausencia de oxígeno las bacterias del sedimento utilizan una serie de oxidantes alternativos en el proceso de la respiración (Mn, NO, Fe o SO) y cuando todos los oxidantes han desaparecido son las reacciones de fermentación las que dominan produciéndose metano. Las calizas litográficas se forman en medios lacustres y marinos, son de grano muy fino y finamente bandeadas. Un ejemplo son las famosas calizas de Solnhofen del Jurásico de Baviera que contienen los fósiles de "Archaeopteryx". El carbonato en estos depósitos se puede originar a partir de una fuente biogénica (como algas calcáreas) o como un precipitado químico.

La pirita sedimentaria se encuentra como un componente menor de sedimentos marinos clásticos tanto actuales como antiguos. Los estudios en sedimentos actuales han demostrado que la formación de pirita autigénica se suele dar en la diagénesis muy temprana a tan solo unos centímetros por debajo de la interfase agua-sedimento. Un aumento de la cantidad de microorganismos o la profundidad de enterramiento, impide la difusión de oxígeno en el sedimento y los microorganismos se ven obligados a respirar anaeróbicamente. La mineralización detiene la pérdida de información asociada a la descomposición de macroorganismos y la precipitación de pirita en la diagénesis temprana es un importante medio para la preservación de los fósiles. En los tejidos blandos como músculos y también quitina, durante la diagénesis temprana se puede producir la piritización. Cuando la descomposición es más avanzada y por lo tanto más tardía la formación de pirita, se destruirán tejidos blandos y solo los compuestos biológicos resistentes (denominados refractarios) como celulosa y lignina se conservan. Las partes biogénicas duras como las conchas (carbonato cálcico y magnesio) y los huesos (fosfato de calcio) son algunas de las estructuras biológicas más resistentes a la descomposición. De las dos, el carbonato de calcio es el más inestable y por consiguiente el que con más probabilidad puede ser reemplazado por pirita. La pirita sedimentaria presenta varias morfologías:

La formación de pirita está controlada por la concentración de carbono orgánico, sulfato y minerales detríticos férricos. En un ambiente marino normal los minerales férricos y los sulfatos están presentes en abundancia y la formación de pirita es controlada por el suministro de carbono orgánico. Sin embargo, en ambientes de agua dulce la formación de pirita está muy limitada por la baja concentración de sulfato.

El fósforo es un elemento fundamental en la vida. Se concentra en tejidos duros, como huesos o algunas cutículas, o más a menudo en partes blandas. Por consiguiente no sorprende que esté involucrado en la fosilización. El esqueleto de vertebrados está principalmente compuesto de hidroxiapatito (Ca(PO)(OH)). Algunos OH pueden ser reemplazados localmente, por iones de F, sobre todo en dientes, produciendo un hidroxi-fluorapatito menos soluble. Los caparazones fosfáticos de invertebrados tienen composiciones similares con alguna variación. La composición de los huesos fósiles contienen más flúor. El volumen medio del flúor de los huesos de peces marinos y de agua dulce es respectivamente 4300 ppm y 300 ppm, mientras que los fósiles contienen 22 100 ppm y 19 900 ppm de flúor.

Los esqueletos de carbonato de calcio pueden pasar a apatito sin cambio en la morfología externa. En ambientes naturales, esta alteración diagénica está asociada a depósitos de fosfato. La transformación bacteriana de organismos calcáreos en apatito se ha demostrado en laboratorio. Estas observaciones y experimentos hacen pensar en el siguiente posible mecanismo:

La fosfatización de sílice primaria también aparece en algunos esqueletos de radiolarios aunque este proceso todavía no es bien conocido.

El examen microscópico de muestras de fosforitas muestra que numerosos microorganismos sin caparazón mineralizado (algas, hongos, bacterias) mineralizan como apatito, aunque no tuvieran ningún precursor mineral. Un ejemplo bien conocido son los coprolitos fosfatizados donde la propia materia orgánica es reemplazada por apatito que conserva la forma exacta del objeto. Por ejemplo, las estrías de contracción de algunos coprolitos. La fosfatización de partes blandas también es frecuente; se conocen muchos ejemplos en artrópodos (copépodos, ostrácodos) que aparecen en nódulos calcáreos y fosfáticos dentro de calizas nodulares, o en coprolitos de grandes vertebrados.

Estudios en fosforitas y sobre la síntesis experimental del apatito han permitido realizar una estimación de las condiciones probables en la fosilización del apatito. Debido a sus requisitos de estabilidad, el apatito se forma preferentemente en un ambiente deficiente en oxígeno, a veces incluso en condiciones totalmente reductoras, como indica su frecuente asociación con pirita. Este ambiente se consigue fácilmente en medios con abundante materia orgánica, que es a su vez la principal fuente de fósforo.

La sílice puede reemplazar a la calcita y al aragonito de las conchas y permineralizar la madera. También puede formar nódulos o capas de sílex, reemplazando sedimentos carbonatados o precipitando directamente, envolviendo o rellenando fósiles o incluso restos de bacterias, microfósiles orgánicos y plantas que se preservan excepcionalmente, como en las Rhynie Chert (Escocia).

Hay tres modos comunes de reemplazo mineral de la concha:

Las plantas están compuestas por varias partes (tallo, ramas, raíces, hojas, polen, frutos, semillas) algunas de las cuales se separan durante la vida, mientras otras lo hacen después de la muerte. Una adecuada comprensión de los procesos de dispersión que afectan a estas partes es muy importante en la interpretación correcta de las asociaciones paleoflorísticas. Estudios sobre dispersión de hojas por el viento muestran que viene determinada por su peso y forma.

Los restos vegetales se pueden conservar de varias formas:

Recientemente ha podido constatarse la posibilidad de extraer restos de ADN de fósiles, y amplificarlos mediante PCR. La evolución de estos conocimientos ha sido muy rápida, ya que si a finales de los 90 existían reticencias sobre la veracidad de los restos fósiles de ADN, para el año 2000 ya existían publicaciones y se había establecido una metodología. Por aquel entonces ya se habían extraído secuencias cortas de fósiles de Neandertal y de mamut. Años después, también hay multitud de ejemplos en plantas e incluso bacterias. Así, Golenberg y su equipo obtuvieron una secuencia parcial de DNA de cloroplasto perteneciente a un fósil de "Magnolia latahensis". No obstante, se ha mantenido la controversia sobre la fiabilidad de los procedimientos utilizados. Este ADN fósil permitiría establecer relaciones filogenéticas entre distintos taxones, además de facilitar una visión global de las ramas evolutivas. Además, facilita la estimación en la tasa de mutación existente entre taxones relacionados. Los métodos propuestos son:


Los fósiles tienen una importancia considerable para otras disciplinas, como la Geología o la Biología evolutiva, son las aplicaciones prácticas de la Paleontología.

Basándose en la sucesión y evolución de las especies en el curso de los tiempos geológicos, la presencia de fósiles permite datar las capas del terreno (Bioestratigrafía y Biocronología), con mayor o menor precisión dependiendo del grupo taxonómico y grado de conservación. Así se han establecido la mayor parte de las divisiones y unidades de las escalas cronológicas que se usan en estratigrafía.

Aportan información de paleoambientes sedimentarios, paleobiogeográficas, paleoclimáticas, de la evolución diagenética de las rocas que los contienen, etc.

Los fósiles siguen revisándose, utilizando en cada ocasión técnicas más modernas. La aplicación de esas técnicas conlleva nuevas observaciones que modifican a veces planteamientos previos. Así, por ejemplo, tras una revisión realizada en 2006 con técnicas tomográficas de rayos X, se concluyó que la familia que contiene a los gusanos "Markuelia" tenía una gran afinidad con los gusanos priapúlidos, y es adyacente a la rama evolutiva de Priapulida, Nematoda y Arthropoda.





</doc>
<doc id="1220" url="https://es.wikipedia.org/wiki?curid=1220" title="Femenino">
Femenino

Femenino es un adjetivo que en español se utiliza con diferentes significados, según se utilice para definir una realidad biológica, sociológica o gramatical:





</doc>
<doc id="1221" url="https://es.wikipedia.org/wiki?curid=1221" title="Fractal">
Fractal

Un fractal es un objeto geométrico cuya estructura básica, fragmentada o aparentemente irregular, se repite a diferentes escalas. El término fue propuesto por el matemático Benoît Mandelbrot en 1975 y deriva del latín "fractus", que significa quebrado o fracturado. Muchas estructuras naturales son de tipo fractal. La propiedad matemática clave de un objeto genuinamente fractal es que su dimensión métrica fractal es un número no entero.

Si bien el término "fractal" es reciente, los objetos hoy denominados fractales eran bien conocidos en matemáticas desde principios del siglo XX. Las maneras más comunes de determinar lo que hoy denominamos dimensión fractal fueron establecidas a principios del siglo XX en el seno de la teoría de la medida.

La definición de fractal desarrollada en los años 1970 dio unidad a una serie de ejemplos, algunos de los cuales se remontaban a un siglo atrás. A un objeto geométrico fractal se le atribuyen las siguientes características:

Las copias son similares al todo: misma forma pero diferente tamaño. Ejemplos de autosimilaridad

No basta con una sola de estas características para definir un fractal. Por ejemplo, la recta real no se considera un fractal, pues a pesar de ser un objeto autosimilar carece del resto de características exigidas.

Un fractal natural es un elemento de la naturaleza que puede ser descrito mediante la geometría fractal. Las nubes, las montañas, el sistema circulatorio, las líneas costeras o los copos de nieve son fractales naturales. Esta representación es aproximada, pues las propiedades atribuidas a los objetos fractales ideales, como el detalle infinito, tienen límites en el mundo natural. 

Para encontrar los primeros ejemplos de fractales debemos remontarnos a finales del siglo XIX: en 1872 apareció la función de Weierstrass, cuyo grafo hoy en día consideraríamos fractal, como ejemplo de función continua pero no diferenciable en ningún punto. 
Posteriormente aparecieron ejemplos con propiedades similares pero una definición más geométrica. Dichos ejemplos podían construirse partiendo de una figura inicial (semilla), a la que se aplicaban una serie de construcciones geométricas sencillas. La serie de figuras obtenidas se aproximaba a una figura límite que correspondía a lo que hoy llamamos conjunto fractal. Así, en 1904, Helge von Koch definió una curva con propiedades similares a la de Weierstrass: el copo de nieve de Koch. En 1915, Waclaw Sierpinski construyó su triángulo y, un año después, su alfombra. 

Estos conjuntos mostraban las limitaciones del análisis clásico, pero eran vistos como objetos artificiales, una "galería de monstruos", como los denominó Poincaré. Pocos matemáticos vieron la necesidad de estudiar estos objetos en sí mismos. 

En 1919 surge una herramienta básica en la descripción y medida de estos conjuntos: la dimensión de Hausdorff-Besicovitch.

Estos conjuntos, fruto de los trabajos de Pierre Fatou y Gaston Julia en los años 1920, surgen como resultado de la aplicación reiterada de funciones holomorfas formula_1.

Analicemos el caso particular de funciones polinómicas de grado mayor que uno. Al aplicar sucesivas veces una función polinómica es muy posible que el resultado tienda a formula_2. Al conjunto de valores de formula_3 que no escapan al infinito mediante esta operación se le denomina conjunto de Julia relleno, y a su frontera, simplemente conjunto de Julia.

Estos conjuntos se representan mediante un algoritmo de tiempo de escape, en que cada pixel se colorea según el número de iteraciones necesarias para escapar. Suele usarse un color especial, a menudo el negro, para representar los puntos que no han escapado tras un número grande y prefijado de iteraciones.

"Ejemplos de conjuntos de Julia para formula_4"
La familia de conjuntos de Julia formula_5, asociadas a la reiteración de funciones de la forma formula_4 presenta conjuntos de una variedad sorprendente.

Dicha familia tendrá especial relevancia al quedar parametrizada en un mapa de fractales, popularizado en los años 1980, llamado conjunto de Mandelbrot. Este conjunto M representa un mapa en que cada pixel, correspondiente a un valor del parámetro formula_7, se colorea de modo que refleje una propiedad básica del conjunto de Julia asociado a formula_8. En concreto, formula_9 si el conjunto de Julia asociado a formula_8 es conexo.

Iterando funciones de forma alternativa se generan los fractales oscilantes.

A continuación se muestra una serie de fractales de las diferentes potencias de Z = Z + C , según el método de Mandelbrot. 
Todos los puntos del plano complejo C=(Cx,iCy) son iterados por adición a la función correspondiente. Todas las iteraciones parten de los puntos x=0 iy=0.
Cuando la iteración converge se colorea de amarillo pálido. La divergencia a infinito es coloreada mediante un patrón cromático desde el negro al azul. El fractal derivado de la función Z = Z + C se denomina conjunto de Mandelbrot. 

Ejemplos de fractales del tipo Mandelbrot Z = Z + C 

Ejemplos de fractales del tipo Mandelbrot Z = Z + 1/C 

A continuación se muestra una serie de fractales de las diferentes potencias de Z = Z + C, según el método de Julia, por el matemático francés Gaston Julia.

Todos los puntos del plano complejo Z=(x,iy) son iterados en la función correspondiente. A todas las iteraciones se le añade una constante arbitraria (Cx,iCy) de tal modo que la elección de la constante "semilla" determina de forma unívoca la forma y el color del fractal, una vez ha sido definido el patrón cromático. En los ejemplos mostrados a continuación se ha elegido una constante tal que solo produce divergencia, y se ha coloreado con el algoritmo de la velocidad de escape.

Ejemplos de fractales del tipo Julia Z = Z + C
Ejemplos de fractales de tipo Julia, de la función exponencial: Z = Z + C

Ejemplos de fractales del tipo Julia de funciones complejas.

El método de Newton intenta encontrar por iteración las raíces de la función F(Z)-1 = 0.

Se itera la función F(Z) con cada punto del plano complejo (x + iy), siendo Z=(x1 + iy1) hasta la convergencia de x1 i y1, según la siguiente fórmula: Z = Z - F(Z) / F’(Z), en donde F’(Z) es la derivada. Se ha coloreado con el algoritmo de la velocidad de convergencia, conceptualmente idéntico al de la velocidad de escape, y presenta similitudes con el método de Julia.

Ejemplos de fractales de tipo Newton, de algunas funciones de variable compleja:

Según B. Mandelbrot, un objeto es autosimilar o autosemejante si sus partes tienen la misma forma o estructura que el todo, aunque pueden presentarse a diferente escala y pueden estar ligeramente deformadas.

Los fractales pueden presentar tres tipos de autosimilitud:


Entre los fractales podemos encontrar ejemplos como curvas que llenan todo el plano. En ese caso, la dimensión topológica de la curva, que es uno, no nos informa sobre la forma en que esta ocupa el espacio ambiente. De modo general, podríamos preguntarnos cómo densamente un conjunto ocupa el espacio métrico que lo contiene. Los números que nos informan objetivamente de este tipo de cuestiones son:



Podemos destacar tres técnicas comunes para generar fractales:

El concepto de fractal no dispone en el año 2008 de una definición matemática precisa y de aceptación general. Intentos parciales de dar una definición fueron realizados por:

Puede definirse en términos del mínimo número formula_11 de bolas de radio formula_12 necesarias para recubrir el conjunto, como el límite:

O en función del recuento del número de cajas formula_14 de una cuadrícula de anchura formula_15 que intersecan al conjunto:

Se demuestra que ambas definiciones son equivalentes, y que son invariantes bajo isometrías.

De una definición más compleja, la dimensión de Hausdorff-Besicovitch nos proporciona un número formula_17, también invariante bajo isometrías, cuya relación con la dimensión fractal formula_18 es la siguiente:

Esto permite distinguir en algunos casos entre conjuntos con la misma dimensión fractal.

Un sistema iterativo de funciones (IFS) es un conjunto de funciones contractivas definidas sobre un subconjunto de formula_20. Cuando no hay solapamiento entre las imágenes de cada función, se demuestra que formula_21 y que ambas pueden calcularse como solución de la ecuación:

donde c designa el factor de contracción de cada aplicación contractiva del IFS.

Se han utilizado técnicas de fractales en la compresión de datos y en diversas disciplinas científicas.

Comprimir la imagen de un objeto autosemejante como el helecho de la figura no es difícil: haciendo uso del , debemos encontrar un IFS, conjunto de transformaciones que lleva la figura completa (en negro) en cada una de sus partes autosemejantes (rojo, azul celeste y azul marino). La información sobre la imagen quedará codificada en el IFS, y la aplicación reiterada de dichas transformaciones permite obtener la imagen procesada en cuestión. 

Pero el enfoque anterior plantea problemas con muchas imágenes reales: no esperamos, por ejemplo, que la imagen de un gato presente pequeños gatitos distorsionados sobre sí mismo. Para solventarlo, en 1989 Arnaud Jacquin creó el esquema de "sistemas de funciones iteradas particionadas": en él se subdivide la imagen mediante una partición y para cada región resultante se busca otra región similar a la primera bajo las transformaciones apropiadas.

El esquema resultante es un sistema de compresión con pérdidas, de tiempo asimétrico. Lamentablemente aún se tarda mucho en encontrar las transformaciones que definen la imagen. No obstante, una vez encontradas, la descodificación es muy rápida. La compresión, aunque dependa de muchos factores, suele ser equiparable a la compresión JPEG, con lo cual el factor tiempo resulta determinante para decantarse por uno u otro sistema.

Las formas fractales, las formas en la que las partes se asemejan al todo, están presentes en la materia biológica, junto con las simetrías (las formas básicas que solo necesitan la mitad de información genética) y las espirales (las formas de crecimiento y desarrollo de la forma básica hacia la ocupación de un mayor espacio), como las formas más sofisticadas en el desarrollo evolutivo de la materia biológica en cuanto que se presentan en procesos en los que se producen saltos cualitativos en las formas biológicas, es decir posibilitan catástrofes (hechos extraordinarios) que dan lugar a nuevas realidades más complejas, como las hojas que presentan una morfología similar a la pequeña rama de la que forman parte que, a su vez, presentan una forma similar a la rama, que a su vez es similar a la forma del árbol, y sin embargo cualitativamente no es lo mismo una hoja (forma biológica simple), que una rama o un árbol (forma biológica compleja).

Pero además las formas fractales no solo se presentan en las formas espaciales de los objetos sino que se observan en la propia dinámica evolutiva de los sistemas complejos (ver teoría del caos). Dinámica que consta de ciclos (en los que partiendo de una realidad establecida simple acaban en la creación de una nueva realidad más compleja) que a su vez forman parte de ciclos más complejos los cuales forman parte del desarrollo de la dinámica de otro gran ciclo. Las evoluciones dinámicas de todos estos ciclos presentan las similitudes propias de los sistemas caóticos.

La música puede contener formas fractales. Algunas obras clásicas de Beethoven, Bach y Mozart son ejemplos representativos según reveló un estudio. El método que siguieron estos compositores, ya sea de manera intencionada o no, para integrar fractales y matemáticas era mediante una analogía entre una dimensión fractal y el número y la disposición de las diferentes notas de una obra o pieza. 

Se usan tanto en la composición armónica y rítmica de una melodía como en la síntesis de sonidos. Esto se debe al uso de lo que en composición se llaman "micromodos", o pequeños grupos de tres notas, a partir de los cuales uno puede trabajarlos de manera horizontal (melódica), o vertical (armónica). A su vez, el ritmo puede ser trabajado en sucesiones temporales específicas, que son determinadas por sucesiones de fractales.

Por otra parte, las litografías del artista holandés Maurits Cornelis Escher (1898-1972) desarrollaron con frecuencia estructuras matemáticas complejas y avanzadas.

Con programas informáticos como Apophysis, Sterling o Ultra Fractal se pueden hacer imágenes con técnicas diversas; cambiando parámetros, geometría de triángulos o con transformaciones aleatorias.






</doc>
<doc id="1223" url="https://es.wikipedia.org/wiki?curid=1223" title="Familia de lenguas">
Familia de lenguas

Una familia de lenguas es un grupo de idiomas con un origen histórico común y emparentados filogenéticamente, es decir, parecen derivar de una lengua más antigua o protolengua (lengua madre).

Las familias se originan cuando una lengua, denominada «protolengua de la familia», da lugar a diferentes idiomas por un proceso de diversificación dialectal. Las lenguas de una familia usualmente son ininteligibles entre sí, aunque en la mayoría de los casos conservan parecidos fonéticos y gramaticales. Cuando las similitudes entre los idiomas son claras, es posible reconstruir su origen común, e incluso la protolengua de la que derivan, mediante los métodos de la lingüística histórica.

La comparación sistemática de las lenguas del mundo mediante los métodos de la lingüística histórica ha permitido probar que la mayoría de las lenguas no son lenguas aisladas filogenéticamente, sino que entre ellas forman grupos o familias. Frecuentemente dentro de una familia es posible reconstruir fidedignamente el origen común o «protolengua madre» de dicha familia. El estudio sistemático de muchas familias ha permitido reconstruir las diversas protolenguas o lenguas ancestrales que por diversificación habrían dado lugar a diversas familias. Dicha reconstrucción parte de las similitudes observadas entre las lenguas de una misma familia y trata de determinar qué palabras o características gramaticales son el resultado de la herencia del ancestro lingüístico común o protolengua.

El ancestro común a la mayoría de familias no es conocido o conocido solo de forma directa en pocas ocasiones, ya que el registro histórico de la mayoría de las lenguas es muy corto. Sin embargo, es posible recuperar muchas de las características del ancestro común de lenguas relacionadas aplicando el método comparativo —un procedimiento de reconstrucción desarrollado en el s. XIX por la escuela neogramática en la que destaca el lingüista August Schleicher—. Las familias de lenguas pueden ser subdivididas en unidades menores, normalmente denominadas “ramas” (la historia de una familia de lenguas se representa frecuentemente como un árbol filogenético).

El ancestro común de una familia (o una rama) se conoce como «protolengua». Por ejemplo, la protolengua reconstruida de la bien conocida familia indoeuropea es llamada protoindoeuropeo (de la que no se conservan restos escritos, puesto que fue usada antes de la invención de la escritura). A veces una protolengua puede ser identificada con una lengua conocida. Así, los dialectos provinciales del latín («latín vulgar») fueron origen de las lenguas romances modernas. Es decir, la lengua «protorromance» es más o menos idéntica al latín (aunque no idéntica al latín culto de los escritores clásicos). Los dialectos del antiguo nórdico son la protolengua del noruego, el sueco, el danés y el islandés. De ahí que dichas protolenguas resulten de una «reconstrucción» que los lingüistas intentan a partir de datos conocidos.

De manera tentativa, cuando no existen datos tan buenos sobre una lengua, se emplean preliminarmente varios sistemas de comparación lingüística basados especialmente en listas de palabras, mediante tratamiento estadístico. Entre estas técnicas están la glotocronología o más generalmente la lexicoestadística. En esta última línea se trabaja en el proyecto de comparación sistemática ASJP que puede sugerir vías de comparación sistemática entre lenguas poco documentadas, así como esclarecer la estructura interna de las familias de lenguas y que proporciona una aproximación del árbol filogenético global con más de 4000 lenguas.

Las lenguas que no pueden ser clasificadas con seguridad en ninguna familia son llamadas lenguas aisladas. Existen varios motivos por los que una lengua se clasifica como aislada:

Las estimaciones glotocronológicas han mostrado que la mayoría de las familias lingüísticas bien establecidas se han diversificado en los últimos 50 siglos. Se entiende que una familia está bien establecida cuando existe consenso en que dichas lenguas forman un grupo y se ha podido reconstruir razonablemente la protolengua originaria. Mientras que las familias peor establecidas, o incluso polémicas, y las macrofamilias parecen tener tiempos de diversificación más grandes. Eso refleja dos hechos:

La distribución geográfica de las familias es el reflejo del devenir histórico de sus hablantes. Así, la mayor parte de las grandes familias de lenguas parece haberse expandido gracias a «revoluciones» agrícolas o tecnológicas de algún otro tipo. La revolución neolítica provocó la expansión de las lenguas afroasiáticas en África y Oriente Medio, las lenguas sino-tibetanas en Extremo Oriente y, de acuerdo con la teoría de Renfrew, la expansión de las lenguas indoeuropeas en Eurasia occidental.

La mejora de las técnicas de navegación permitió a los hablantes de las lenguas austronesias expandirse desde la isla de Taiwán por toda Oceanía, llegando incluso a Madagascar, frente al continente africano. El imperialismo europeo llevó las lenguas indoeuropeas a América y a numerosas áreas de África, Oceanía y, en menor medida, Asia. Al parecer, el uso del hierro y otras tecnologías habría permitido a las lenguas Níger-Congo llegar a imponerse en África desplazando a los hablantes de otras familias ahora poco numerosas, como las lenguas nilo-saharianas o las lenguas joisanas.

En la actualidad, las dos mayores familias lingüísticas por número de hablantes, las lenguas indoeuropeas y las lenguas sino-tibetanas, juntas suman un número de hablantes equivalente al 75 % de la humanidad. Por otro lado, entre las lenguas indígenas de América, por ejemplo, muchas familias de lenguas apenas superan los pocos miles de hablantes.

La siguiente tabla resume las principales familias del mundo según el número de hablantes:

El número de lenguas sobre el que se basan las cifras anteriores es de 6533, entre las que se incluyen 310 lenguas extintas (sin hablantes actualmente), 71 "pidgins" y criollos que suman cerca de 2 millones de hablantes. Además se conocen unas 75 lenguas de señas que no son contabilizadas por no tratarse de lenguas orales adscritas a ninguna familia de la lista anterior.

Están agrupadas geográficamente sin tener en cuenta las relaciones entre familias. En la siguiente lista, cada uno de los puntos es una familia de lenguas conocida. Las denominaciones geográficas de los títulos son solamente para mantener un orden y facilitar la lectura. Las relaciones geográficas son convenientes para tal objetivo, pero no representan ningún tipo de intento de crear «superfamilias» filogenéticas.

Desde antiguo se reconoció que las lenguas semíticas del Oriente próximo y la península arábiga estaban genéticamente emperentadas, cosa que se explicaba en términos semi-míticos juzgando que los pueblos semitas eran descendientes comunes de Sem. La clasificación extensiva de las lenguas del África subsahariana empezó en el siglo XIX sobre la base de datos lingüísticos y datos etnográficos, dominados por una visión racista y supremacista de la variedad humana. El estudio plenamente científico y exento de prejuicios racistas empezó propiamente en el siglo XX. El trabajo de Joseph Greenberg, en la actualidad aceptado en líneas generales por la mayoría de los africanistas, agrupa a las lenguas del continente africano en cuatro grandes macrofamilias:


Subsisten discrepancias menores sobre las agrupaciones internas de estos grupos, y sobre la clasificación de algunas lenguas cordofanas. Se ha realizado un importante trabajo comparativo sobre la mayoría de las subfamilias dentro de las lenguas afroasiáticas y de las lenguas Níger-Congo. Se han propuesto varias reconstrucciones razonablemente completas del protoafroasiático, del protonilosahariano, aunque el sistema fonológico reconstruido por diversos autores puede llegar a diferir considerablemente, lo cual indica que todavía se necesita mayor clarificación sobre el parentesco y las características de dichas lenguas.

Durante la Edad Media europea se reconoció el parentesco evidente entre algunas lenguas (las lenguas románicas, las lenguas celtas, las lenguas germánicas, las lenguas eslavas, etc.). Sin embargo, no se sospechó de que todos estos grupos estaban en última instancia emparentados hasta mucho más tarde. Hacia finales del siglo XVIII el juez británico Williams Jones propuso seriamente la idea de que el latín, el griego, el germánico, el celta, el sánscrito y el persa estaban emparentados. Esta fue la primera identificación de la familia indoeuropea en una forma cercana a como la conocemos hoy en día. Durante el siglo XIX el desarrollo del método comparativo permitió identificar otras familias.

En la actualidad Europa es el continente menos diverso desde el punto de vista lingüístico. Esto se debe básicamente a las migraciones indoeuropeas durante el neolítico, y la posterior formación de imperios cuyos hablantes usaban lenguas indoeuropeas, que acabaron con la mayoría de las lenguas preindoeuropeas del continenente, con excepciones como el vasco, el finés, el húngaro y diversas lenguas del Cáucaso. El Cáucaso, por otra parte, es un región montañosa mucho más diversa que el resto de Europa. Por otro lado, Eurasia central es una región bastante más diversa que Europa (excepto el Cáucaso), con varias grandes familias de lenguas. Las familias generalmente aceptadas hoy en día incluyen:

En el Extremo Oriente se encuentra la segunda familia por número de hablantes (macrofamilia sino-tibetana) y la familia más amplia del mundo por número de lenguas (familia austronesia). Una lista de las familis generalmente aceptadas de la región es la siguiente:
Muchos autores presuponen que en última instancia todas las lenguas australianas podrían estar remotamente emparentadas dado el relativo aislamiento de Australia respecto a otras regiones. La investigación de las lenguas australianas reconoce entre 228 y 262 lenguas. La mayoría de ellas unas 160 pertenecen a una familia filogenética bien identificada (familia pama-ñung), el resto de lenguas pertenecen a más o menos una docena de pequeñas familias familias, de las cuales la mitad serían de hecho lenguas aisladas. No existen pruebas establecidas del parentesco de todas las lenguas australianas, ya que los métodos de la lingüística histórica solo funcionan bien para tiempos de diversificación de unos pocos milenios. Si en verdad todas las lenguas australianas están en último término emperentadas no se conoce con seguridad por más que algunos consideren razonable dicha conjetura. La clasificación básica de las lenguas australianas es por tanto:

Nueva Guinea es la región lingüísticamente más diversa del planeta, ya que, en su territorio, se hablan entre 750 y 900 lenguas. No existe un acuerdo completo sobre el número de familias diferentes existentes, y los trabajos comparativos revelan que el número de unidades filogenéticas válidas identificadas es enorme, por lo que no se puede considerar que las lenguas papúes constituyan una única familia. Y, aunque varios autores han sugerido que, en último término, todas las lenguas papúes están relacionadas, esto no se ha probado satisfactoriamente debido a la enorme diversidad de estas lenguas.

Si se atiende al número de familias incontrovertiblemente identificadas o bien establecidas, existirían más de 60 familias lingüísticas en Nueva Guinea (ver por ejemplo clasificación del WALS); de estas, cerca de una docena serían realmente lenguas aisladas y las otras 50 familias propiamente dichas. Es posible que el número de familias bien establecidas pueda reducirse a un número inferior, como sugieren las clasificaciones tentativas de Ross y Wurm, pero hoy por hoy esas clasificaciones son tentativas. Greenberg considera que las familias papúes constituyen un subgrupo genéticamente válido dentro de las lenguas indopacíficas, pero dicha clasificación es altamente especulativa y ha sido ampliamente criticada.

La clasificación de las lenguas de América es probablemente una de las áreas más controvertidas de la clasificación filogenética de las lenguas. Las propuestas van desde más de siete docenas de unidades filogenéticas, hasta solo tres unidades para todo el continente.

El primer trabajo suficientemente ambicioso de clasificación de las lenguas de Norteamérica fue el llevado a cabo por John Wesley Powell, que reconoció más de una cincuentena de grupos filogenéticos. Edward Sapir hizo algunas propuestas controvertidas tendentes a reducir el número de grupos, tratando de identificar relaciones entre los grupos de Powell. Algunas propuestas de Sapir han ganado aceptación, pero la mayoría han sido desechadas. Una clasificación «conservadora» al estilo de Powell basada en evidencia disponible actualmente reconoce los siguientes grupos:

El trabajo comparativo sobre estas lenguas podría llevar a reducir el número de grupos, aunque ese trabajo de buscar parentescos lejanos entre familias bien establecidas es complicado, porque los grupos anteriores solo parecen muy remotamente relacionados unos con otros, y los posibles parentescos resultan en general muy discutibles e inseguros.

En Sudamérica existen seis grandes familias por número de lenguas: familia macro-tupí (76 lenguas), la familia arawak (64 lenguas), la macrofamilia macro-gê (32 lenguas), la familia caribe (32 lenguas), la macrofamilia pano-tacana (33 lenguas), la familia chibcha (25 lenguas) y la familia tucana (22 lenguas). Por número de hablantes son importantes familias o macrolenguas formadas por un número reducido de lenguas que alcanzaron gran difusión: quechua, aimara, idioma guaraní y mapuche. Una lista más o menos completa del resto de pequeñas familias de lenguas es la siguiente:

Normalmente el nombre de familia lingüística se reserva para un grupo de lenguas cuyo parentesco histórico y origen común no resulta polémico. En general, cuando el trabajo lingüístico está avanzado hasta el punto de haber reconstruido algunos miles de términos de la protolengua originaria, se considera fuera de toda duda que las lenguas forman una familia. Comparaciones arqueológicas y especulaciones lingüísticas y estadísticas nos sugieren que los ancestros reconstruidos no se remontan más allá de 5000 o 7000 años. Para períodos de diferenciación mayores, el cambio lingüístico es tan profundo que difícilmente pueden encontrarse o demostrarse parentescos genéticos (de la misma manera que las pruebas de parentesco genético entre familias biológicas de personas solo pueden aplicarse a personas muy estrechamente relacionadas).

Sin embargo, más allá del nivel de familia, se encuentran algunas similitudes aisladas que permiten especular que muchas de las familias de lenguas identificadas podrían agruparse en macrofamilias o superfamilias tentativas, usando métodos menos exigentes que la reconstrucción de la protolengua. Diferentes lingüistas han propuesto algunas agrupaciones de familias lingüísticas en superfamilias. Muchas han sido propuestas en base al método de Morris Swadesh. Ninguna tiene una aceptación amplia como grupo filogenético de lenguas, pero algunas, como la familia amerindia, la papú, la australiana, la joisán y la paleosiberiana, resultan prácticas como agrupaciones geográficas de familias pequeñas con características comunes.


Una lengua aislada es una lengua natural para la que no se ha probado ningún parentesco con otra lengua viva o muerta. Presumiblemente, una lengua aislada es aquella que no pertenece a ninguna familia de lenguas propiamente dicha (es decir, ella es la única miembro de su familia). El ainu, el euskera, el buruchasqui o burushaski y el sumerio son ejemplos de lenguas clasificadas frecuentemente como aisladas. También en América existen lenguas aisladas, como el mapuche (América del sur), el purépecha (México) o el zuñi (Estados Unidos). 


Entre las lenguas de señas también pueden establecerse conexiones históricas claras, en muchos casos la historia está además documentada. Así, por ejemplo, la moderna lengua de señas francesa, la lengua de señas norteamericana y la lengua de señas mexicana han evolucionado a partir de variantes de la misma lengua: la antigua lengua de señas francesa (usada por la comunidad de sordos de París durante el siglo XVIII). En cambio, la lengua de señas británica no tiene parentesco con la lengua de señas norteamericana, aun cuando los británicos y los norteamericanos oyentes usan variantes del inglés. Es decir, un señante (usuario de lengua de señas) de lengua de señas norteamericana tendrá menos dificultad para comunicarse con un señante de lengua de señas francesa que con un señante de lengua de señas británica.

La siguiente lista incluye algunas familias conocidas de lenguas de señas:
Algunas lenguas de señas son lenguas aisladas:





</doc>
<doc id="1224" url="https://es.wikipedia.org/wiki?curid=1224" title="Fanzine">
Fanzine

Un fanzine (abreviatura en inglés de "fan's magazine", revista para fanáticos) es una publicación temática realizada por y para aficionados, es un tipo de Zine. El término fanzine fue acuñado en octubre de 1940 por Russ Chauvenet, para distinguir a los "fanzines" de los "prozines", las revistas profesionales del género.

Los editores pueden ser un grupo organizado de personas o una sola persona. Los creadores pueden ser aficionados o profesionales que se distinguen en su campo. El desarrollo de esta actividad no suele ir acompañado de remuneración económica, siendo los "fanzines" tradicionalmente gratuitos o con un coste mínimo para pagar los gastos de producción. Copias a menudo se ofrecen a cambio de publicaciones similares, o para las contribuciones de arte, artículos o cartas de comentario que se publican a continuación. Los "fanzines" se han convertido en publicaciones profesionales (a veces conocidos como "prozines"), y muchos escritores profesionales fueron publicados por primera vez en "fanzines"; algunos siguen contribuyendo en ellos después de ser reconocidos profesionalmente. Un fanzine en la mayoría de los casos se ocupa de cuestiones específicas, como la música, el cómic, la ciencia ficción, la literatura, la política, la pornografía o incluso combinaciones de estos. Los "fanzines" tienen sus raíces en el siglo XIX, con los panfletos que circularon para difundir principalmente ideas políticas. Su auge, sin embargo, se experimentó en las décadas de 1950 a 1960, cuando se convirtió en uno de los principales medios de expresión de la contracultura.

Los "fanzines" son publicaciones no profesionales producidas por seguidores de un fenómeno cultural particular (como puede ser un género literario, musical o historietístico) para el placer de otros que tienen los mismos intereses.

Su ventaja indiscutible es contar con especialistas en su materia, publicando de forma libre y directa sin ataduras ni intereses para con terceros. A esta ""ausencia de condicionantes editoriales (el editor suele dar libertad de expresión)"" hay que añadir otra ventaja para el autor novel: ""la posibilidad de darse a conocer a un público aficionado más o menos amplio y a algún que otro editor profesional que en un momento dado pueda darte esa oportunidad tan esperada"". Con ello, el "fanzine" se muestra ""a la vez un buen terreno de rodaje y una inmejorable plataforma de lanzamiento al ámbito profesional"".

Los problemas endémicos de los "fanzines" son su dependencia de las ganas desinteresadas de sus colaboradores en un trabajo no remunerado que debe obtenerse del tiempo libre y sus problemas para distribuirse llegando a su público potencial. Al depender del tiempo y el esfuerzo desinteresado de sus creadores no suelen durar mucho, ya que no reciben compensación monetaria.

Es posible que si el trabajo realizado es sobre un campo muy específico sobre el que no existen publicaciones comerciales, pueda mantenerse cubriendo un hueco e incluso profesionalizarse. Un "fanzine" que ha pasado a editarse con medios profesionales se denomina "prozine". Si hay un equipo detrás de su publicación profesionalizado y llega a obtener beneficios, hablamos ya de una revista como tal, aunque no haya un grupo editorial en ello, una distribución nacional o internacional o una correcta gestión para establecer su ISSN.

Los orígenes de publicaciones "fan" de aficionados no son muy claros, pero se pueden remontar a los grupos literarios del siglo XIX en los Estados Unidos que se formaron en asociaciones de prensa de aficionados a la publicación de colecciones de ficción, la poesía y el comentario, tales como H. P. de Lovecraft Estados Amateur. Estas publicaciones se produjeron por primera vez en las pequeñas prensas de impresión de sobremesa, a menudo por estudiantes. El desarrollo de los "fanzines" está ligado al de los medios de edición de bajo costo como la multicopista y la fotocopiadora (que también han sido y son soportes para toda clase de folletos, pasquines y octavillas revolucionarias y contraculturales). Grandes acontecimientos de la historia del "fanzine" y su espíritu, son la generación de autores norteamericanos de cómics underground de los años 1960 y 1970 y el texto disponible en la red en formato copyleft. Sin el concepto del "fanzine" estas revoluciones culturales no habrían sido posibles. En opinión del teórico Antonio Lara, los "fanzine"s han jugado "un papel fundamental en la evolución general de los medios, y, más concretamente, de las formas culturales marginadas por las instituciones oficiales", como pudieran ser "los cómics, carteles, cromos, animación, novelas populares, telefilmes y otras". Desde mediados de los años sesenta, otros países, como España, también han sido muy ricos en este tipo de publicaciones.

La calidad de los "fanzines" impresos es muy variable. Muchas veces se hace a mano, y simplemente son fotocopiados o incluso impresos con técnicas modernas. Las mismas personas que escriben, preparan los archivos de texto en el ordenador, y el diseño de la aparición de la revista. Hay casos en los que algunas partes de la revista son totalmente artesanales. En cuanto al color es totalmente negro, a veces solo con la portada a color, y finalmente algunos aparecen en dos o cuatro colores. La calidad de impresión afecta directamente el precio. Como avanzaba la tecnología de impresión profesional, también lo hizo la tecnología de los "fanzine"s. Concretamente, la calidad de los "fanzines" en su conjunto ha mejorado considerablemente desde el 2000, como los ordenadores se hicieron más asequible y el conocimiento de los programas de edición de imágenes digitales o formas gráficas de configuración más común. Muchos "fanzines" circulan en forma de CD u otro medio digital. Todavía hay formas de "fanzines" acompañados de CD. Actualmente, medios como Internet y la facilidad para maquetar en HTML han facilitado la distribución y el formato, por lo que la edición de "fanzines" se ha extendido a la red. Este tipo de "fanzines" electrónicos se denomina "ezine".

Fanzines de ciencia ficción: Fueron una de las primeras formas de fanzine, dentro de uno de los cuales se acuñó el término "fanzine", y al mismo tiempo constituyen el principal tipo de actividad fandomera la ciencia-ficción. El primer fanzine de ciencia ficción, el Comet, fue publicado en 1930 por el Club de Ciencia con correspondencia en Chicago. Tradicionalmente, los fanzines de ciencia ficción estuvieron (y son muchos todavía) disponible para "los de siempre", lo que significa que una edición de la muestra sería enviada por correo a petición: para recibir otras cuestiones, un lector envía una "carta de comentario" sobre el fanzine al editor. Desde 1955, cada año el Worldcon (Convención Mundial de Ciencia Ficción) ha otorgado los Premios Hugo al Mejor Fanzine; se añadieron premios por mejor escritor del ventilador y Mejor Artista del ventilador en 1967 y han continuado desde entonces.

Fanzines de medios: Los fanzines de medios fueron originalmente simplemente un subgénero de los fanzines de ciencia ficción, escrita por aficionados a la ciencia ficción que ya estaban familiarizados con apazines. El primer fanzine de los medios de comunicación fue una publicación fan de Star Trek llamada Spockanalia, publicado en septiembre de 1967 por miembros de Lunarians. A mediados de la década de 1970, había suficientes medios revistas que publicaban adzines que existían solo para anunciar todas las otras revistas disponibles. Otra popular franquicia de fanzines fue la saga "Star Wars".

Comic Fanzines: Los cómics se mencionaron y discutieron ya en la década de 1930 en los fanzines de fandom de la ciencia ficción. La primera versión de Superman (un villano calvo) apareció en el tercer número de Jerry Siegel y Joe Shuster 1933 fanzine de ciencia ficción. Los cómics fanzines a menudo incluyen obras de aficionados basadas en los personajes existentes y discusión de la historia del cómic.

Fanzines de películas de terror: Como con los cómic fanzines, los fanzines de películas de terror crecieron en interés desde las publicaciones de la ciencia ficción. Los Horrores de la Pantalla de Alex Soma, el diario de Frankenstein de Calvin T. Beck y las criaturas Gore de Gary Svehla fueron los primeros fanzines de terror creados como alternativas más serias a la popular revista de 1958 de Forrest J Ackerman, Famous Monsters of Filmland.

Fanzines de música Rock n Roll: A mediados de la década de 1960, varios aficionados activos en la ciencia ficción reconocen un interés común en la música rock, y así nació el fanzine de rock. Paul Williams y Greg Shaw eran dos SF-fans que se volvieron editores de fanzines de rock. 'Crawdaddy! (1966) de Williams y dos fanzines de Shaw con sede en California, “Mojo Navigator” (1966) y “Who Put the Bomp”, (1970) se encuentran entre los más importantes fanzines de rock. En la década de 1980, con el auge de las superestrellas de grandes escenarios, muchos fanzines de rock de la cantera surgieron. A finales de 1990, fanzines notorios y revistas electrónicas florecieron sobre la música electrónica y el post-rock. ‘Crème brûlée’ fanzine fue uno de los que documentó el género postrock y la música experimental.

Punk Fanzines: Un punk fanzine (o punkzine) es una revista relacionada con la subcultura punk y el género hardcore de la música punk. Cuentan con la literatura de punk, como comentario social, la poesía de punk, noticias, chismes, críticas y artículos de música sobre bandas de punk rock o escenas del punk regional. La estética de bricolaje de la subcultura punk creó una prensa clandestina próspera. Tales revistas de aficionados se inspiraron en los fanzines de rock de la década de 1970, que se inspiraron en revistas de la comunidad de fans de la ciencia ficción. Tal vez el más influyente de los fanzines al cruzar de la ciencia ficción fandom al rock y, más tarde, el punk rock y música new wave, fue “Who Put the Bomp” de Greg Shaw.

Fanzines de juegos de rol: Otro grupo importante de fanzines surgió en juego de rol fandom donde los fanzines permitieron a la gente publicar sus ideas y puntos de vista sobre los juegos específicos y sus campañas de rol. Los fanzines de rol permitieron a las personas comunicarse entre los años 1970 y 1980, con control editorial completo en las manos de los jugadores, a diferencia de los editores de juegos. Estos primeros fanzines fueron en general a máquina, en un formato A5 y por lo general se ilustraron con obras de arte abismal o indiferente.

Fanzines de videojuegos: Surgieron por primera vez durante el segundo período de generación cuando los boletines de noticias para los grupos de usuarios de ordenador y las tiendas no eran poco frecuentes, aunque no siempre bien conocidos. La publicación “Joystick Jolter” fue el primer fanzine real. Más tarde, como herramientas de autoedición se hicieron más accesibles, hubo un aumento en la producción de fanzine. Los fanzines de videojuegos disminuyeron en popularidad con el aumento de la web en todo el mundo, aunque algunas revistas, continuaron más allá de mediados de los años 90 (por ejemplo Classic Gamer Magazine and Video Game Collector). La era de los fanzines de videojuegos fue más grande en los EE.UU. y Canadá, pero había /hay revistas de otros países también.

Fanzines de juegos de guerra: Existen varios fanzines dentro de la afición de los juegos de guerra. Entre ellos se encuentra Charge!, un fanzine líder internacional en exclusiva para los entusiastas de los juegos de guerra en miniatura del período de la Guerra de Secesión. Otros fanzines apoyan Warhammer y otros conjuntos de reglas populares.

Fanzines de deportes: La primera asociación de fanzines de fútbol se considera , una publicación que se desarrolló entre 1972 y 1976. Fuera del mundo del fútbol había una serie de fanzines establecidos, por ejemplo, la Liga de Rugby tiene publicaciones notables como “Who The Hell Was St. George Anyway?“. Sin embargo, debido a la presión de la Internet, etc. estas publicaciones ya no existen en forma impresa. También hay un número de fanzines que se encuentran en Irlanda de los cuales Shelbourne Red Inc. es el de más larga duración. En los Estados Unidos, los fanzines deportivos son relativamente raros.

Con la creciente disponibilidad de Internet a finales del siglo XX y los principios del siglo XXI, la revista de papel tradicional ha comenzado a dar paso a la revista electrónica (o "e-zine") que es más fácil de producir y utiliza el potencial de Internet para ser cada vez más grande y con audiencia mundial. No obstante, fanzines impresos se siguen produciendo, ya sea de preferencia por el formato o para llegar a las personas que no tienen acceso a la Web. Además festivales de Zine se llevan a cabo cada año en ciudades estadounidenses como Los Ángeles, Chicago, y Brooklyn, , así como a nivel internacional en ciudades como Melbourne, Australia,y Glasgow, Reino Unido.




</doc>
<doc id="1230" url="https://es.wikipedia.org/wiki?curid=1230" title="Geografía">
Geografía

La geografía (del latín "geographĭa", y este del griego ["geōgraphía"], literalmente traducido como «descripción de la tierra») es la ciencia que trata de la descripción o de la representación gráfica de la Tierra. En sentido amplio es la ciencia que estudia la superficie terrestre, las sociedades que la habitan y los territorios, paisajes, lugares o regiones que la forman al relacionarse entre sí.

El primer autor en utilizar la palabra geografía fue Eratóstenes (276-194 a. C.) en una obra hoy en día perdida. Sin embargo, la fundación de la geografía se le atribuye al también considerado padre de la historia, Heródoto (484-420 a. C.). Para los griegos es la descripción racional de la Tierra y, particularmente para Estrabón, es el estudio de las distintas regiones humanas como base para la formación del político.

Existen cuatro tradiciones históricas en la investigación geográfica, las cuales son: el análisis espacial de fenómenos naturales y humanos, los estudios del territorio (del lugar a la región), el estudio de la relación entre el hombre y su entorno, y la investigación de las ciencias de la Tierra.

La geografía moderna es una disciplina cuyo objetivo primordial es la explicación de toda una serie de fenómenos naturales y sociales y no se refiere solo a la localización de esos fenómenos, sino que también estudia cómo son y cómo han cambiado para llegar a ser lo que son. 

La geografía se divide en dos grandes ramas: geografía regional y geografía general. 

La geografía regional estudia las diferentes subdivisiones del espacio terrestre en países, estados y regiones a distintas escalas de detalle, desde el análisis geográfico de un pequeño valle de montaña, hasta el estudio regional amplio de comarcas, países, naciones o estados, e incluso, espacios multinacionales. Mientras que la geografía general se divide en dos grandes ramas: geografía física y geografía humana:

Las cuatro tradiciones históricas en investigación geográfica son: análisis espacial de fenómenos naturales y humanos, estudios de área de lugares y regiones, estudios de relaciones entre humanos y tierras y las ciencias de la Tierra. La geografía ha sido llamada «la disciplina mundial» y «el puente entre las ciencias humanas y las ciencias físicas».

Los antiguos griegos fueron los primeros en acumular y sistematizar sus conocimientos, denominándolos con el título de «geográficos», fundando así una nueva disciplina. Estrabón, Eratóstenes y Claudio Ptolomeo, fueron quienes «clásicamente» acuñaron el término empezando a desarrollar teorías y prácticas de lo que en ese momento se entendía por geografía. Los romanos continuaron su labor añadiendo una nueva manera de pensarlo a base de recopilación de datos y técnicas, Pomponio Mela fue uno de ellos.
Durante lo que suele conocerse como la Edad Media en Europa no hubo un desarrollo significativo de la disciplina, eso si consideramos que modernamente la cartografía es una disciplina técnica por sí misma. No obstante, no hay que olvidar que la Geografía en Europa había estado asociada a lo que hoy entendemos como cartografía, base de la moderna Geomática, a través de la cual entendemos lo que la disciplina significaba para ellos en el siglo XVIII. Pues debido a los requerimientos propios a los procesos de la colonización europea de América y África, la Cartografía y la Geografía de la época eran prácticamente la misma disciplina. Sin embargo, en el mundo árabe la historia es distinta para la época, Al-Idrisi e Ibn Jaldún se apropiaron y profundizaron el conocimiento geográfico greco-romano consolidando una visión del mundo que no encaja con los estándares de lo que conocemos como Edad Media, sino que tuvieron su propia manera de producirlo y significarlo. Los chinos también desarrollaron para el interior de su territorio un conocimiento geográfico que les permitiría tener un férreo control del mismo.

En un sentido extremadamente amplio podríamos decir que el pensamiento geográfico árabe, cristiano y chino compartía el hecho de basarse en un pensamiento determinista, con una fuerte inclinación al estudio de la naturaleza, con la salvedad de que en el mundo árabe no había una rígida distinción entre sociedad y naturaleza. Compartían además el considerar al estudio del territorio sobre el que se llevaban a cabo actividades humanas como una unidad con lo que consideraban los ciclos de la naturaleza. Ese pensamiento estaba fuertemente determinado por las creencias e ideas teológicas de sus elaboradores, existían por ejemplo representaciones de la superficie de la tierra de forma circular, del mundo conocido por las culturas de ese momento (Europa, Asia y la parte norte del África). La Europa medieval no conoció desarrollos sino en la profundización de los cálculos más precisos, Cosmas Indicopleustes fue uno de los pocos geógrafos "medievales" relevantes —aunque cabe destacar que fue un desarrollo muy temprano de la Edad Media, en el siglo VI— a pesar de avalar la idea geocéntrica de Ptolomeo. Idea que no cambiaría sino hasta los acontecimientos ocurridos en Europa conocidos como revolución científica que empezaría con la teoría heliocéntrica de Nicolás Copérnico, el fenómeno de rotación terrestre y la idea de una Tierra de forma esférica de Galileo Galilei, coronado con lo que conocemos comunmente como ley de gravitación universal de Isaac Newton, momento del nacimiento de la física moderna y de la matematización de las ciencias que estudian a la naturaleza. Lo cual no habría sido posible sin los procesos de Conquista de las Américas y al tráfico de esclavos de África, y la posterior conquista de Oceanía. Dichos procesos de Colonización española de América, repercutieron profundamente en la Geografía, quien por su parte, experimentó profundos cambios, debido a que fue uno de los conocimientos más utilizados en la época para la exploración europea del mundo. La idea que se tenía de la disciplina entonces fue magistralmente expuesta por Johannes Vermeer en su pintura "El geógrafo", que además por esos mismos procesos de conquista se convertiría en la visión dominante de la disciplina hasta principios del siglo XX.

Cabe destacar sin embargo que a lo largo del siglo XIX, esta disciplina se consolidó como parte fundamental del desarrollo de los estados nacionales, logrando institucionalizarse en un gran número de universidades europeas, siendo reconocida incluso hasta finales del siglo XX, como una de las disciplinas más importantes para la educación básica de cualquier ciudadano. La razón de ello se debe al papel que tendría para la construcción de ideas como Frontera, País o nacionalidad. En cuanto a los geógrafos más reconocidos de la época, nos encontramos con Bernhardus Varenius, quien sería uno de los más importantes predecesores de la geografía moderna, al igual que Mikhail Lomonosov, o para algunos el naturalista y crítico de la geografía de su tiempo Alexander von Humboldt, así como el también pedagogo Karl Ritter. Entre los más destacados geógrafos del siglo XIX encontramos a Friedrich Ratzel, quien es más conocido por la influencia que tendría en las ideas de la Alemania nazi, al geógrafo anarquista Élisée Reclus, a William Morris Davis, uno de los precursores de la Geomorfología, al también edafólogo Vasily Dokuchaev o a Alfred Russel Wallace, uno de los precursores de la teorías de la evolución, al climatólogo Wladimir Peter Köppen, los destacados estrategas militares Halford John Mackinder, Karl Haushofer y a Paul Vidal de La Blache, quien sería uno de los precursores del Federalismo, e influiría en la construcción de una subdivisión interna en los territorios de las naciones para el reconocimiento y control de los recursos de cada País.

Por su parte, a mediados del siglo XX ocurriría una profunda ruptura con la geografía del siglo XIX, que aún se encuentra en disputa, pues ha ocurrido lo que en palabras de Immanuel Kant podríamos denominar un giro copernicano, poniendo de relieve la importancia del sujeto (sociedad o individuo) para el entendimiento del mundo en consideración al objeto (naturaleza o individuo), donde se tiene el reconocimiento empírico de que la sociedad es quien dirige dicho proceso, que sólo puede ser pensado a partir de la relación de las sociedades con la domesticación y transformación de la naturaleza para fines específicamente humanos. Ese cambio de perspectiva ha supuesto la base de lo que se conoce como el giro espacial de las Ciencias sociales, centrándose sobre todo en el desarrollo del Estudio de nombres geográficos (planteado por los estudios culturales emanados de las críticas al orientalismo), geografía crítica (para el mundo hispano) o radical (en el mundo anglosajón), o las geografías posmodernas. Además la geografía tiene ahora fuertes vínculos con disciplinas afines como la Sociología, la Economía o la Historia. Entre los geógrafos más destacados del Siglo XX encontramos a David Harvey, Neil Smith, Milton Santos, Yves Lacoste, Horacio Capel, Richard Hartshorne, Ellen Churchill Semple, Doreen Massey Walter Christaller, Torsten Hägerstrand, Carl Sauer, Peter Hall, Philippe Pinchemel, Brian Joe Lobley Berry, Yi-Fu Tuan o Maria Dolors García Ramón, todos ellos con posiciones y posturas muy distintas entre sí.

A comienzos del siglo XXI, la situación actual de la Geografía es algo ambivalente. Por un lado, parece evidente que la visibilidad de la Geografía como disciplina académica ha disminuido a nivel popular. Estos cambios están afectando a la concepción que se tiene de la disciplina. En la forma contemporánea de entender a la disciplina es la libertad humana (con fuerte influencia del Idealismo alemán). Actualmente se vive un profundo debate en la disciplina, entre los defensores de geografías regionales cuantitativas, dónde se defiende una Geografía más bien descriptiva, y los defensores de las las geografías radicales, humanísticas y pos modernas, que apelan por una disciplina más crítica frente a los hechos manifiestos por la crisis del capitalismo y, especialmente, por el derrumbe de los gobiernos socialistas a escala mundial. El desplazamiento que viven distintas instituciones educativas en el mundo de una Geografía más cercana a las Ciencias de la Tierra o a las Ciencias sociales, nos revela un lento pero progresivo cambio sistemático en la disciplina.

A partir de los años cincuenta del siglo XX se produjo un intenso debate en la disciplina, a consecuencia de los catastróficos acontecimientos de la Segunda Guerra Mundial, donde se puso en cuestión el papel de nuestra disciplina que por tradición había estado inclinada a los intereses del Estado desde sus orígenes al centrarse en la consigna de Estrabón debido a que su conocimiento estaba orientada a dicho fin.

Es el estudio sobre los orígenes y sentidos de los planteamientos teóricos de la disciplina.

Como toda Ciencia social comparte una serie de posicionamientos teóricos y posturas con otras disciplinas como la Sociología, la Historia o la Economía

La geografía durante la época clásica griega era una disciplina con un solo objetivo, la descripción y estudio de la la superficie terrestre. Se nutría con los relatos de los viajeros que gracias a la navegación y exploración llegaron a tener una idea bastante aproximada del ecúmene, es decir, del mundo conocido en aquellos tiempos y se encargaba de describir y catalogar o enumerar la ubicación de los accidentes naturales y de los distintos pueblos que se encontraban sobre la superficie terrestre. Pero el saber geográfico, al pasar de los tiempos, dio origen a la división de la geografía en dos ramas que forman la primera gran dicotomía de la ciencia, tal como señala Juan Vilá Valentí (). Estas dos ramas son Geografía general y Geografía especial también llamada esta última, en distintas épocas, geografía corológica, es decir, geografía de los lugares y geografía regional, que fue el término que finalmente se impuso y que abarcan ambas el doble objetivo de estudio de dicha ciencia. Siguiendo con los planteamientos de Vilá Valentí, estas dos ramas dieron paso a nuevas divisiones, como sucede con la geografía general, cuyo campo de estudio dio origen a una nueva dicotomía: geografía física y geografía humana. 
Así, a partir de lo que se pensaba en el siglo XIX, que las formas de pensar la relación entre la sociedad y la naturaleza exigían un enfoque separado y especializado , la geografía solía dividirse en dos grandes ramas: Geografía general y geografía regional. Es importante señalar que es fundamental ponerlo sobre la mesa pues es aún una de las principales formas de aproximarse a la disciplina, debido a que se trata de un saber del Estado tal como lo pone de relieve Yves Lacoste en su obra "La geografía, un arma para la Guerra", la cual sigue siendo utilizada por las instituciones nacionales de todo el mundo, a pesar de que en los círculos académicos especializados suele reconocerse como obsoleta. En la división clásica, la geografía general solía pensarse como analítica, ya que estudiaba los hechos físicos y humanos individualmente, mientras que la geografía regional se consideraba como sintética, ocupándose de los sistemas territoriales particulares sin distinción entre «físico» y «humano». Sin embargo, la articulación entre ambas ramas ha sido tradicionalmente un tema de debate dentro de la geografía que cambió dramáticamente con los debates ocurridos en la segunda mitad del siglo XX.

La geografía general presenta un conjunto de diversos tipos de subdisciplinas configuradas alrededor de su propio objeto, con fuertes vínculos con sus respectivas ciencias auxiliares y con grados variables de comunicación entre sí. Se trata de un estudio de multitud de ciencias específicas que se encuentran relacionadas entre sí por el objeto de estudio (nuestro planeta, en especial los conceptos y procesos que se presentan en la superficie terrestre). Por razones metodológicas que se derivan del campo de estudio tan amplio que desarrolla, se subdivide en dos grandes ramas: geografía humana y geografía física.

La geografía humana es la ciencia social centrada en el estudio de las sociedades y de sus territorios; también estudia al ser humano y sus reacciones con su entorno tanto en el aspecto estático de su organización, como en el dinámico de los cambios que experimentan . La geografía humana contiene varias divisiones:

Geografía de la población: estudia los patrones y procesos involucrados en el estudio de la población de los distintos espacios; su distribución, su dinamismo natural y los movimientos migratorios, así como los problemas demográficos (despoblación rural o éxodo rural, flujos migratorios internacionales, envejecimiento, entre otros.). Tiene como ciencia afín a la demografía. Y la diferencia entre las dos ciencias se centra en una distinción del punto de vista: la demografía estudia la población desde la perspectiva de la estadística, mientras que la geografía de la población la estudia teniendo en cuenta la distribución espacial de la población y de sus características.

Geografía rural: estudia el mundo rural y los espacios rurales, las actividades económicas que se llevan a cabo en estos (agricultura, ganadería, turismo), los tipos de asentamiento y los problemas de estas áreas (despoblación, problemas económicos, problemas ambientales, etc.). Como ciencias afines pueden citarse a la agronomía, la sociología rural y la economía.

Geografía urbana: estudia las ciudades y las regiones urbanas, su morfología (plano, estructura, edificación, sectores, procesos ecológicos), sus características socioeconómicas, sus cambios y problemas. Como ciencias afines están el urbanismo y la sociología urbana.

Geografía médica: estudia los efectos del medio ambiente en la salud de las personas y de la distribución geográfica de las enfermedades incluyendo también el estudio de los factores ambientales que influyen en su propagación (epidemias, pandemias, endemias). Su ciencia afín es la medicina.

Geografía del transporte: se ocupa de los sistemas de transporte como parte de la organización de los espacios geográficos. Sus temas principales de estudio son la configuración y características de las redes de transporte, los flujos que se dan sobre estas redes y los problemas relacionados con el transporte, como la congestión, la contaminación, su papel en el desarrollo socioeconómico de los espacios geográficos en que se integran, etc. Como disciplinas afines pueden citarse la historia del transporte y la economía del transporte.

Geografía económica: estudia las actividades económicas que se desarrollan en los distintos espacios, la localización de las actividades económicas y los problemas económicos (desarrollo geográfico desigual, globalización, deslocalización de las actividades, etc.). Para Krugman es la "rama de la economía" acerca de la "localización de la producción en el espacio". Tiene como disciplinas afines a la economía regional y la historia económica. Engloba subdisciplinas más especializadas como:



Geografía política: estudia la política en los diversos espacios, la organización y características de los estados (fronteras, capitalidad, estructura político-administrativa, sistema electoral, etc.) y las relaciones internacionales de conflicto o dominación. Como ciencias afines se presentan la ciencia política, la sociología y la historia política.

Geografía social: se centra en diversos aspectos sociales de los espacios estudiados como las divisiones sociales, la educación, la pobreza, las relaciones de género, la etnicidad, etc.

Geografía del envejecimiento o geografía gerontológica: analiza las implicaciones socioespaciales del envejecimiento de la población a partir de la comprensión de las relaciones entre el entorno físico-social y las personas mayores, a diferentes escalas, micro (vivienda), meso (barrio) y macro (ciudad, región, país), etc. La contribución de los geógrafos del envejecimiento, como Graham D. Rowles, están contribuyendo a la gerontología ambiental comprendiendo los aspectos ambientales de la gerontología en países desarrollados y en desarrollo.

Geografía cultural: estudia las diversas culturas, la difusión de elementos culturales, las representaciones culturales, los paisajes culturales así como las transformaciones que provocan las culturas en su ambiente. La ciencia afín por excelencia de la geografía cultural ha sido la antropología.

Geografía histórica: estudia las características y evolución de los espacios históricos, su morfología y organización territorial así como su configuración social. Tiene como ciencia afín a la historia.

La geografía física (conocida en un tiempo como fisiografía, término ahora escasamente usado) es la rama de la geografía que estudia en forma sistemática y espacial la superficie terrestre considerada en su conjunto y, específicamente, el espacio geográfico natural.

La geografía física se preocupa, según Strahler, de los procesos que son el resultado de dos grandes flujos de energía: el flujo de radiación solar que dirige las temperaturas de la superficie junto a los movimientos de los fluidos, y el flujo de calor desde el interior de la Tierra que se manifiesta en los materiales de los estratos superiores de la corteza terrestre. Estos flujos interactúan en la superficie terrestre que es el campo del geógrafo físico. Así, la geografía física es la rama de la geografía que estudia el medio físico. Los principales elementos que estructuran el medio físico corresponden al relieve, las aguas terrestres, el clima, la vegetación, la fauna y el suelo; y el estudio de cada uno de estos ha dado origen a diversas ciencias de la Tierra, entre las cuales se encuentran:









La geografía regional o corológica (del griego «χώρα», espacio, país, región y «λόγος», conocimiento, estudio) es la disciplina que estudia los sistemas o complejos geográficos. Sin embargo, no hay consenso a la hora de definir que es un complejo geográfico ni el papel de la geografía regional en el conjunto de la geografía.
Para algunos geógrafos, la geografía regional es una disciplina encargada del estudio sintético de los complejos geográficos (territorios, lugares, paisajes o regiones entre otras denominaciones). Sería por lo tanto una parte de la geografía en condición de igualdad con las múltiples disciplinas que conforman la geografía general o sistemática, las cuales estudian analíticamente diversos fenómenos en sus características y distribución (relieve, clima, vegetación, población, organización económica, organización política, comercio, transportes, etc.).

Para otros geógrafos, sin embargo, la denominación geografía regional es redundante pues toda la geografía es regional. Es decir, la geografía tiene por objeto estudiar los complejos geográficos a cualquier escala (localidades, comarcas, regiones, países, grandes regiones, etc.) tanto de forma sintética como temática. Las diversas disciplinas que conforman la geografía general serían por lo tanto, el acercamiento temático y comparativo al estudio de los complejos geográficos. Así, según Robert E. Dickinson, «La geografía es fundamentalmente la ciencia regional o corológica de la superficie terrestre» y para Manuel de Terán, «La primacía de la geografía regional no es discutible en la situación actual de la ciencia geográfica. La geografía moderna es fundamentalmente geografía regional, como en la Antigüedad fue corología y chorografía».

Como se ha observado con detenimiento en el análisis anterior el pensamiento geográfico dominante se enfoca en la proyección de características particulares de la sociedad para el análisis de datos estadísticos, con el objetivo de ser proyectados y analizados en circunstancias específicas. Actualmente se conoce con el título de Geoingeniería, suele ser desempeñada generalmente por geólogos biólogos y urbanistas más que por los propios geógrafos, por lo que hay un intenso debate en la disciplina que cuestiona si se debe o no considerar como parte de la disciplina.

 El Premio Vautrin Lud es el nombre por el que se conoce al Premio Internacional de Geografía Vautrin Lud, que es el máximo galardón en el campo de la geografía a nivel internacional. Es concedido desde 1991, considerado por algunos como el Premio Nobel de Geografía. Se otorga anualmente en el Festival Internacional de Geografía en Saint-Dié-des-Vosges, Francia (ciudad natal de Vautrin Lud). Es decidido por un jurado compuesto por cinco académicos.






</doc>
<doc id="1233" url="https://es.wikipedia.org/wiki?curid=1233" title="Guipúzcoa">
Guipúzcoa

Guipúzcoa (en euskera, y oficialmente Gipuzkoa) es una provincia española y territorio histórico de la comunidad autónoma del País Vasco. Su capital es San Sebastián. Limita con el departamento francés de Pirineos Atlánticos por el noreste, Navarra al este, Vizcaya al oeste, Álava al suroeste y el golfo de Vizcaya al norte. Se halla situada en el extremo este del mar Cantábrico, en el golfo de Vizcaya, entre los 42º 53' 10" y los 43º 23' 45" de latitud norte y entre 1º 43' 45" y 2º 36' 7" de longitud oeste de Greenwich. Posee 66 km de costa.

Su área de 1.997 km la hace la . La provincia cuenta con 88 municipios y una población de 707.298 habitantes (2015), de los cuales más de la mitad viven en el área metropolitana de San Sebastián. Aparte de la capital, otras ciudades importantes son Pasajes, Irún, Rentería, Éibar, Zarauz, Mondragón, Tolosa, Fuenterrabía, Beasain, Zumárraga y Oñate.

Su clima atlántico le da un color verde intenso a esta tierra con una mínima oscilación térmica, mientras que el mar Cantábrico pone el color azul a un paisaje atractivo para los turistas. Guipúzcoa es el territorio vasco donde más extendido se encuentra el euskera entre la población.

La principal zona turística del territorio es la costa (Costa Vasca), donde destacan los municipios de San Sebastián, Zarauz y Fuenterrabía. Además de sus playas, poseen un gran número de edificios de gran interés cultural e histórico. En el interior destacan poblaciones como Éibar, Beasain, Oñate, Mondragón, Azpeitia y Tolosa.

Actualmente el restaurante Mugaritz está considerado como el cuarto mejor del mundo. Se encuentra en Rentería, a 53,5 km del centro de Guipúzcoa.



La proposición de ley núm. 122/000039 presentada el 2 de julio de 2004 por el Grupo Parlamentario Vasco (Partido Nacionalista Vasco) en el Congreso de los Diputados de la VIII legislatura, que pretendía establecer como denominación oficial única la de "Gipuzkoa", fue retirada por ese mismo partido el 9 de mayo de 2006.
En 2011, el acuerdo presupuestario alcanzado por el PSOE y el PNV en el Congreso de los Diputados, incluyó el cambio de denominación actual, mediante el cual, la única denominación oficial del territorio guipuzcoano es "Gipuzkoa".

Las menciones más antiguas sobre el topónimo Guipúzcoa datan del siglo XI. El documento escrito conocido más antiguo que menciona este topónimo data del año de 1025. Se trata del documento de donación del Monasterio de San Salvador de Olazábal ("monasterium quo dicitur ollazabal"), junto con sus heredades y términos, al Monasterio de San Juan de la Peña de la actual Provincia de Huesca. Los donantes son el "senior Garsia Acenariz de Ipuscua" y su esposa "Gayla" o "Gaila". Se cree que Guipúzcoa era por aquel entonces una tenencia feudal del Reino de Pamplona, al frente del cual se encontraba el susodicho señor "Garsia Acenariz" o García Aznárez. El Reino de Pamplona alcanzaba por aquel momento su máxima extensión territorial histórica, abarcando desde el Condado de Ribagorza en el Alto Aragón hasta el río Pisuerga en la frontera entre León y Castilla.

En dicho documento de donación se describen los límites del término del susodicho monasterio de Olazábal, sobre cuyo solar se construyó siglos más tarde la actual iglesia de "Altzo-azpi" del municipio de Alzo. Las tierras pertenecientes al monasterio de Olazábal abarcaban una larga y estrecha franja de tierra que iba desde las cercanías de la costa guipuzcoana (el barrio de Elcano de Aya) hasta la sierra de Aralar. Se supone que este territorio, centrado en el valle del río Oria, constituía el corazón de la "Ipuscua" del siglo XI gobernada por García Aznárez.

Además de este primer documento, otros tres diplomas hallados en San Juan de la Peña mencionan a García Azenáriz y a su esposa Doña Gaila, así como a otros miembros de su familia: su hija Doña Belasquita y su yerno Sancho Fortuniones. En un documento de 1048 se menciona a "Doña Gaila de Ippucha" donando el Monasterio de Santiago de Luquedeng (de ubicación desconocida) al de San Juan de la Peña. Por entonces era rey de Pamplona García Sánchez el de Nájera.

En la segunda mitad del siglo XI aparece mencionado un segundo señor de Guipúzcoa, "Orbita Azenáriz", cuya primera mención escrita data de un documento de 1066, durante el reinado de Sancho Garcés IV de Pamplona.

En 1076 el reino de Pamplona sufrió una convulsión con el asesinato de Sancho Garcés IV, víctima de una intriga a manos de sus hermanos. Los nobles pamploneses prefirieron entregar el reino a uno de sus poderosos vecinos, Aragón o Castilla y León, que consentir que los infantes fratricidas se hicieran con el reino o que accediera al trono el heredero legítimo, Sancho de Pamplona, que era todavía un niño de corta edad. Los monarcas de León y Aragón pertenecían también a la familia real pamplonesa, ya que eran nietos del gran rey Sancho el Mayor y por tanto tenían cierta legitimidad para acceder al trono. Ambos candidatos, con apoyos locales, trataron de asentar su candidatura ocupando militarmente parte del territorio pamplonés. Finalmente los dos candidatos llegaron a un acuerdo y dividieron el reino en dos partes. El rey Alfonso VI de León se hizo con el control de la mitad occidental del reino, que incluía buena parte de La Rioja, Bureba y casi todo el actual País Vasco, y pasaba a ostentar entre sus títulos el de Rey de Nájera, mientras que Sancho Ramírez de Aragón obtenía el reconocimiento como rey de Pamplona y se quedaba el resto del reino.

En la división del reino de 1076 la parte más oriental de la actual provincia de Guipúzcoa, la comarca situada entre San Sebastián y el Río Bidasoa siguió vinculada al Reino de Pamplona. Este hecho parece confirmarse porque el rey Pedro I de Aragón confirmó unos años más tarde, en 1101, la antigua donación al Monasterio de Leire de la iglesia de San Sebastián, lo que probaría su jurisdicción sobre esta parte del territorio en aquel momento. Esta parte de la provincia es la que históricamente siempre ha estado más vinculada a Navarra, territorio del que ha sido la "salida natural al mar" a través del río Bidasoa y con la que comparte el mismo dialecto del euskera y un pasado étnico común vascón. Cabe pensar que la Guipúzcoa del siglo XI, la que habían regido como señores los Azenariz no incluía todavía esta parte de la provincia.

En cambio la mayor parte del territorio de la actual Guipúzcoa entró a formar parte por primera vez en su historia de la órbita política castellano-leonesa y se convierte en territorio fronterizo entre Castilla y Pamplona. "Orbita Azenariz" perdió el señorío sobre Guipúzcoa a raíz de este hecho, ya que en 1080 es mencionado en otro documento pero ya no como "senior" de Guipúzcoa. En su lugar el rey Alfonso VI entregó el gobierno de Guipúzcoa a Lope Íñiguez, señor de Vizcaya, que había sido su principal apoyo en la reclamación del trono pamplonés. Lope Iñiguez aparece mencionado en un documento del Monasterio de San Millán de la Cogolla de 1081 bajo el título de conde en Vizcaya, Álava y Guipúzcoa ("comite Lope Ennecones in Bizkaia et Alava et Ipuzcoa"). Posteriormente se le menciona en un documento del Monasterio de Irache de 1088 como "... comes Lupus dominans Alaua et Bizcaya et Ipuzcoa" y en otro manuscrito de San Millán de 1091 como "Comes Lope dominante Bizcahiam et Ipuzcoam".

En 1109, sabiéndose cerca de su muerte y sin herederos varones, Alfonso VI concertó la boda de su heredera Urraca I con el rey Alfonso I de Aragón. Alfonso I pasó a ser regente de Castilla, sin embargo el matrimonio entre el rey de Aragón y la reina de León no consolidó ni mucho menos la unión y la paz entre sus reinos, ya que los cónyuges acabaron unos pocos años enfrentados en una guerra civil que se prolongó entre 1111 y 1114. En el transcurso del enfrentamiento muchos territorios y plazas fronterizas que pertenecían a los reinos de su esposa cayeron en manos de Alfonso I. Entre ellos se encontraba buena parte del territorio que en la división de 1076 había caído en manos castellano-leonesas.

Tras la restauración del dominio pamplonés-aragonés en la década de 1110, aparece como nuevo tenente de Guipúzcoa Ladrón Íñiguez, que aparece también al frente de Vizcaya y Álava. En 1127 el Pacto de Támara entre Alfonso I de Aragón y Alfonso VII de Castilla consolidaba el dominio aragonés-pamplonés sobre Guipúzcoa, ya que los castellanos reconocieron la soberanía del Reino de Pamplona sobre Guipúzcoa. En 1130 o 1131 tiene lugar una expedición militar de Alfonso I Bayona. En esta expedición le acompañaron el padre del nuevo señor de Guipúzcoa, Iñigo Vélaz, y sus hijos. En 1134 se restaura la independencia del Reino de Pamplona bajo el reinado de García Ramírez tras separarse de nuevo de Aragón a la muerte de Alfonso I.
Los reyes castellanos tras incorporar Guipúzcoa en 1200 impulsaron la labor de urbanización y fundación de villas que habían iniciado los pamploneses unos años antes con la fundación de San Sebastián. Siguiendo el ejemplo de San Sebastián, el primer impulso se centró en la fundación de villas en la franja costera de la provincia. Castilla, igual que Navarra, estaba necesitada de puertos de mar, que sirvieran para dar salida comercial a sus productos, de base para una flota naval o para industrias económicas importantes como la pesca o la caza de la ballena. En Guipúzcoa ya existían por aquel entonces núcleos de población en la costa, lo que hicieron los reyes castellanos fue dotar a dichas poblaciones preexistentes de fueros y derechos que impulsaran su crecimiento y fortalecieran esos asentamientos. El rey Alfonso VIII de Castilla fundó en menos de una década desde la anexión 3 villas marineras siguiendo el modelo del fuero de San Sebastián. Las 4 villas marineras guipuzcoanas ocupaban de manera casi uniforme la costa guipuzcoana.

Unas décadas más tarde se completaría esta urbanización costera con la fundación de una quinta villa por el nieto de Alfonso VIII, el rey Fernando III

La segunda fase de la expansión urbana guipuzcoana se produce a mediados del siglo XIII, durante el reinado del "rey sabio" Alfonso X. Esta vez las fundaciones se realizan en dos ejes norte-sur que atraviesan la provincia, el valle del Río Oria y el valle del río Deva. Alfonso X fundó 5 nuevas villas y quizás una sexta:

Por el rey Sancho IV de Castilla:

Por el rey Fernando IV de Castilla:

Por el rey Alfonso XI de Castilla:

Por el rey Enrique II de Castilla:

Por el rey Juan II de Castilla:

Por el rey Juan I de Castilla:

En 1845 el territorio del Señorío de Oñate, tras ser abolidos los señoríos jurisdiccionales, se incorpora definitivamente a esta provincia.

·Astigarraga: (1382) Durante las Guerras banderizas de los siglos XIV y XV los Murguía fueron parte del bando oñacino. En este turbulento periodo los señores de Murguía lograron establecer una relación de cierto dominio señorial sobre los vecinos de Astigarraga. En 1382, siendo señora de Murguía Navarra Martínez de Oñaz, nieta de don Diego López de Salcedo; los vecinos de Astigarraga suscribieron un contrato con los señores de Murguía por el cual debían de prestar a los señores una serie de servicios y pagar una serie de tributos; a cambio de protección y una serie de derechos que les eran reconocidos por los segundos.

Por extensión, Guipúzcoa es la menor de las 50 provincias de España.
Guipúzcoa presenta una orografía muy accidentada al encontrarse en la unión de la Cordillera Cantábrica al oeste y los Pirineos al este. Es la segunda provincia más montañosa de España atendiendo al desnivel del terreno.

Los ríos guipuzcoanos son todos ellos de curso breve y de cuencas hidrográficas pequeñas. No obstante, sus caudales son relativamente cuantiosos y estables, debido al elevado índice pluviométrico y a la persistencia de las precipitaciones en esta zona.

De este a oeste, el primer río es el Bidasoa, que nace en Puerto Izpegui (Navarra) a 710 m. de altitud y entra en Guipúzcoa por Endarlaza, recorriendo por nueve kilómetros el territorio provincial sirviendo de frontera natural entre España y Francia, primero en un valle angosto y luego ensanchándose en una llanura costera sobre la que se asientan Irún y Fuenterrabía, desembocando finalmente en el mar Cantábrico junto al cabo Higuer.

El Oyarzun u Oarso es un pequeño río de 15 km de longitud que nace en las peñas de Aya, a 680 m. de altura, atraviesa Rentería y desemboca en la bahía de Pasajes. Es un río con frecuentes avenidas que debido a su pendiente (45,3 por mil) arrastra numerosos sedimentos detríticos que se depositan en la bahía.

El Urumea nace al nordeste de Leiza (Navarra) a 710 m. de altitud, tiene un cauce de 53 km y baña a Hernani donde recibe las aguas de su único afluente el río Añarbe, para finalmente desembocar entre los montes Ulía y Urgull en San Sebastián.

El río Oria es el mayor y más largo de los ríos guipuzcoanos, nace en el Puerto de San Adrián, a 660 m. de altitud. Al principio se le considera formado por los tres ramales que pasan por Idiazábal, Cegama y Zumárraga, y a partir de aquí sigue con un cauce único que alcanza cerca de 80 km de longitud donde recoge las aguas de sus afluentes los ríos Leizarán, Berástegui, Amézqueta, Araxes, Amundarain, Agaunza y Ursuarán, bañando a los municipios de Beasáin, Ordicia, Legorreta, Alegría de Oria, Tolosa, Villabona, Andoáin, Lasarte-Oria y Usúrbil, desembocando al mar en Orio formando en su desembocadura una peligrosa barra.

El río Urola nace cerca de Legazpia en la vertiente norte del Aitzgorri a 720 m. de altitud, tiene como afluentes a los ríos Urrestilla y Régil, y baña Legazpia, Zumárraga, Villarreal de Urrechu, Azcoitia, Azpeitia, Cestona, Aizarnazábal y desemboca en el mar en Zumaya.

El río Deva nace en el monte Eizmendi, en la sierra de Elgueta, a 825 m. de altitud. Presenta un cauce de 58 km de largo y tiene como afluentes a los ríos Ego, Aramayona y Aránzazu; atraviesa Salinas de Léniz, Arechavaleta, Escoriaza, Mondragón, Vergara, Placencia de las Armas, Elgóibar, Alzola y Mendaro, desembocando en Deva.

Además deben mencionarse los ríos que proceden de las zonas cársticas o torcales existentes en Arno, Lastur, Aizarna, Vidania, Aintzarga, Alotza, Iñurritza, Ubedí, Urbía, Escaraz, Guezaltza y Degüiza.

Factores determinantes del clima guipuzcoano son la situación de la provincia entre el Pirineo y la cordillera Cantábrica y entre el mar y el valle del Ebro, posición de la cual resulta un clima oceánico de matiz mediterráneo, caracterizado por su pequeña oscilación térmica anual, con veranos frescos e inviernos moderados y con lluvias abundantes a lo largo de todo el año pero predominantes en otoño y comienzos del invierno. La temperatura media es de 8,1 °C en invierno y 18,2 °C en verano.

Los vientos son muy frecuentes, predominando los del norte-noroeste y sur. Solo un 2% de los días son de calma. Las lluvias son abundantes (50% de días lluviosos) debidas al régimen de vientos y a la orografía de la provincia, con precipitaciones que oscilan entre 1.200 y 1.700 litros anuales por metro cuadrado. La nubosidad también es alta (solo 10% de días totalmente despejados), con una media de 1.830 horas anuales de insolación (equivalente a 5 por día). 

El clima es oceánico, con pocas oscilaciones térmicas, y su temperatura anual alcanza un promedio de 14 °C, con abundantes precipitaciones (1.400 mm al año) y en ocasiones violentas galernas. Las precipitaciones y el relieve condicionan una hidrografía definida por ríos de escasa longitud, aunque caudalosos y regulares; los principales son el Bidasoa, el Oyarzun, el Urumea, el Oria, el Urola y el Deva. Su utilidad agrícola, como consecuencia de las precipitaciones, es mínima, si bien han sido la base de una industria que ha terminado por contaminar sus aguas. La vegetación predominante, también condicionada por el clima, es el bosque boreal, con especies de hoja caduca que alternan con prados. Robles, fresnos, abedules, pinos, castaños y eucaliptos cubren las laderas de las montañas, donde habitan zorros, jabalíes, ardillas y corzos.

Guipúzcoa cuenta con 714.360 habitantes (2012), es la 4.ª provincia española (tras Madrid, Barcelona y Vizcaya) con mayor densidad de población con 374,21 hab/km².

Guipúzcoa también ha sido una de las regiones gracias a las cuales se repuebla la Castilla medieval, pues gente de estas tierras emigró en la Edad Media a tierras castellanas donde se asentaron; así pues, muchas de las gentes de Valladolid, Burgos, Toledo, Palencia etc., tienen antepasados guipuzcoanos, aunque no tengan apellidos vascos.

La provincia de Guipúzcoa es la 33.ª de España en que existe un mayor porcentaje de habitantes concentrados en su capital (26,12 %, frente a 31,96 % del conjunto de España).

En su calidad de provincia especial por constituir un territorio histórico dentro del País Vasco, Guipúzcoa cuenta con un cámara normativa formada por 51 representantes (denominados tradicionalmente en Guipúzcoa "junteros") elegidos por sufragio universal directo llamada Juntas Generales de Guipúzcoa. Las elecciones a las juntas generales se realizan cada cuatro años coincidiendo con las elecciones municipales y para ellas el territorio guipuzcoano se agrupa en cuatro circunscripciones: Deba-Urola, Oria, Donostialdea y Bidasoa-Oyarzun.
Las Juntas Generales se encargan de elegir al Diputado General, órgano ejecutivo unipersonal, que junto con el Consejo de Diputados por él elegidos forma la Diputación Foral de Guipúzcoa como órgano de gobierno provincial.
La Diputación es responsable políticamente frente a las Juntas y dirige la administración foral en el marco competencial definido por las Ley de Territorios Históricos, el Estatuto de Autonomía del País Vasco y la Ley de Bases de Régimen Local. 
En la actualidad el Diputado General de Guipúzcoa Markel Olano (PNV), elegido por las Juntas Generales tras las elecciones de 2015 por mayoría absoluta con los votos de los 18 junteros de su partido y los 9 junteros del PSE-EE.




</doc>
<doc id="1234" url="https://es.wikipedia.org/wiki?curid=1234" title="GNU General Public License">
GNU General Public License

La Licencia Pública General de GNU o más conocida por su nombre en inglés GNU General Public License (o simplemente sus siglas en inglés GNU GPL) es la licencia de derecho de autor más ampliamente usada en el mundo del software libre y código abierto, y garantiza a los usuarios finales (personas, organizaciones, compañías) la libertad de usar, estudiar, compartir (copiar) y modificar el software. Su propósito es doble: declarar que el software cubierto por esta licencia es libre, y protegerlo (mediante una práctica conocida como copyleft) de intentos de apropiación que restrinjan esas libertades a nuevos usuarios cada vez que la obra es distribuida, modificada o ampliada. Esta licencia fue creada originalmente por Richard Stallman fundador de la Free Software Foundation (FSF) para el proyecto GNU.

La Free Software Foundation pone la "GPL" a disposición de cualquiera que desee proteger los derechos de sus usuarios finales (usar, compartir, estudiar y modificar), y otorgar a los beneficiarios de un programa de ordenador u otro tipo de obra los derechos de la definición de software libre. La "GPL" se distingue del dominio público o de otras licencias de software libre conocidas como permisivas por hacer hincapié en el copyleft, o solo permitir que las copias y derivados de una obra bajo la "GPL" perpetúen la misma licencia.

La mayor parte del software GNU es copyleft, pero no todo; sin embargo, todo el software GNU debe ser software libre.

Parte del software GNU fue escrito por el equipo de la Free Software Foundation, pero la mayor parte proviene de algunos voluntarios. La Free Software Foundation es titular del copyright de parte de ese software, otra parte está bajo el copyright de sus autores.

David A. Wheeler sostiene que el copyleft proporcionado por la "GPL" fue crucial para el éxito de sistemas basados en Linux, dando a los programadores que han contribuido al kernel la seguridad de que de su trabajo se beneficiaría todo el mundo y seguirá siendo libre, en lugar de ser explotado por compañías de software que no tendrían que dar nada de nuevo a la comunidad.

Los usuarios o compañías que distribuyen sus trabajos bajo las "GPL", pueden cobrar o distribuirlas gratuitamente. Esto distingue las "GPL" de las licencias de software que prohíben su distribución comercial. La "FSF" argumenta que no se debe restringir la distribución comercial del software (incluyendo la redistribución), y en ese tenor la "GPL" establece explícitamente que las obras cubiertas por esta licencia se pueden vender a cualquier precio.

La GPL fue creada por Richard Stallman en 1989 para proteger los programas liberados como parte del proyecto GNU. La GPL original se basó en la unificación de licencias similares utilizadas en versiones anteriores de GNU Emacs, GNU Debugger y de GNU C Compiler. Estas licencias contenían disposiciones similares a las actuales GPL, pero eran específicas para cada programa, haciéndolos incompatibles, a pesar de ser la misma licencia. El objetivo de Stallman era producir una licencia que pudiera ser aplicada a cualquier proyecto, por lo que es posible utilizarlas en muchos proyectos para compartir código.

La segunda parte de esta licencia, versión 2, fue liberada en 1991. Durante los siguientes 15 años, los miembros de la comunidad FOSS comenzaron a preocuparse con los problemas en la GPLv2 que permitían explotar software GPL con intenciones contrarias a la licencia. Estos problemas incluían tivoización, que es la inclusión de software con GPL en hardware que rechazará ejecutar versiones modificadas de su software, problemas de compatibilidad como ocurre con la licencia Affero General Public License; y las disputas por patentes entre Microsoft y distribuidores de código libre y abierto, lo que se consideró como un intento de usar las patentes como arma contra la comunidad FOSS.

Históricamente, la familia de licencias de la "GPL" ha sido una de las licencias de software más populares en el software libre de dominio. La tercera versión de esta licencia (GNU GPLv3) fue desarrollada para tratar de resolver estos problemas y fue lanzada oficialmente el 25 de julio de 2007. Esta es la primera licencia "copyleft" para uso general, lo que significa que los trabajos derivados solo pueden ser distribuidos bajo los términos de la misma licencia.

La versión 1 de GNU GPL, fue presentada el 25 de febrero de 1989, impidió lo que eran las dos principales formas con las que los distribuidores de software restringían las libertades definidas por el software libre. El primer problema fue que los distribuidores publicaban únicamente los archivos binarios, funcionales y ejecutables, pero no entendibles o modificables por humanos. Para prevenir esto, la GPLv1 estableció que cualquier proveedor de software libre además de distribuir el archivo binario debía liberar a su vez código fuente entendible y que pudiera ser modificado por el ser humano, bajo la misma licencia (secciones 3a y 3b de la licencia).

El segundo problema era que los distribuidores podían añadir restricciones adicionales, ya fuera añadiendo restricciones a la licencia o mediante la combinación del software con otro que tuviera otras restricciones en su distribución. Si esto se hacía, entonces la unión de los dos conjuntos de restricciones sería aplicada al trabajo combinado entonces podrían añadirse restricciones inaceptables. Para prevenir esto, GPLv1 obligaba a que las versiones modificadas en su conjunto, tuvieran que ser distribuidas bajo los términos GPLv1 (secciones 2b y 4 de la licencia). Por lo tanto, el software distribuido bajo GPLv1 puede ser combinado con software bajo términos más permisivos y no con software con licencias más restrictivas, lo que entraría en conflicto con el requisito de que todo software tiene que ser distribuido bajo los términos de la GPLv1.

Según Richard Stallman, el mayor cambio en GPLv2 fue la cláusula “Liberty or Death” («libertad o muerte»), como la llama en la sección 7 de ese documento. Esta sección dice que si alguien impone restricciones que le prohíben distribuir código GPL de tal forma que influya en las libertades de los usuarios (por ejemplo, si una ley impone que esa persona únicamente pueda distribuir el software en binario), esa persona no puede distribuir software GPL. La esperanza es que esto hará que sea menos tentador para las empresas el recurrir a las amenazas de patentes para exigir una remuneración de los desarrolladores de software libre.

En 1990 se hizo evidente que una licencia menos restrictiva sería estratégicamente útil para la librería C y para las librerías de software que esencialmente hacían el trabajo que llevaban a cabo otras librerías comerciales ya existentes. Cuando la versión 2 de GPL fue liberada en junio de 1991, una segunda licencia Library General Public License fue introducida al mismo tiempo y numerada con la versión 2 para denotar que ambas son complementarias. Los números de versiones divergieron en 1999 cuando la versión 2.1 de LGPL fue liberada, esta fue renombrada como "GNU Lesser General Public License" para reflejar su lugar en esta filosofía.

A finales de 2005, la Free Software Foundation (FSF) anunció estar trabajando en la versión 3 de la GPL (GPLv3). El 16 de enero de 2006, el primer borrador de GPLv3 fue publicado, y se inició la consulta pública. La consulta pública se planeó originalmente para durar de nueve a quince meses, pero finalmente se extendió a dieciocho meses, durante los cuales se publicaron cuatro borradores. La GPLv3 oficial fue liberada por la FSF el 29 de junio de 2007. Fue escrita por Richard Stallman con el asesoramiento legal de Eben Moglen y el "Software Freedom Law Center".

Según Stallman los cambios más importantes se produjeron en el campo de las patentes de software, la compatibilidad de licencias de software libre, la definición de código fuente, y restricciones de hardware respecto a las modificaciones de hardware. Otros cambios están relacionados con la internacionalización, cómo son manejadas las violaciones de licencias, y cómo los permisos adicionales pueden ser concedidos por el titular de los derechos de autor. También añade disposiciones para quitar al DRM su valor legal, por es posible romper el DRM en el software de GPL sin romper leyes como la DMCA.

El proceso de consulta pública fue coordinado por la Free Software Foundation con asistencia de Software Freedom Law Center, Free Software Foundation Europe, y otros grupos de software libre. Los comentarios del público fueron recolectados a través del portal gplv3.fsf.org.

Durante el proceso de consulta pública, 962 comentarios fueron presentados para el primer borrador. Finalmente, al final del proceso se alcanzó la cifra de 2,636 comentarios.

El tercer borrador fue liberado el 28 de marzo de 2007. Este borrador incluye mecanismos destinados a evitar acuerdos relativos a las patentes, como el controvertido acuerdo entre Microsoft y Novell y restringe las cláusulas anti-tivoización a una definición legal de un "usuario" o "producto de consumo". También elimina la sección de "Limitaciones geográficas", cuyo probable borrado se había anunciado en el lanzamiento de la consulta pública.

El cuarto borrador, que fue el último, fue liberado el 31 de mayo de 2007. Introdujo la compatibilidad con las Licencias Apache, clarificó el rol de los contratistas externos, y hace una excepción para evitar los problemas provocados por el acuerdo Microsoft-Novell, estableciendo en el párrafo 6 de la Sección 11 lo siguiente:

El objetivo de esto es hacer este tipo de acuerdos ineficaces. La licencia está orientada a que Microsoft tenga que extender las licencias de patentes para garantizar a los clientes de Novell el uso de GPLv3, lo que es posible únicamente si Microsoft es distribuidor legal del software bajo GPLv3.

Algunos desarrolladores de alto nivel del kernel de Linux, comentaron e hicieron declaraciones públicas a los medios de comunicación sobre sus objeciones a los borradores 1 y 2.

Los términos y condiciones de GPL deben estar disponible para cualquiera que reciba una copia de la obra al cual ha sido aplicada esta licencia. Cualquier licencia que se le apliquen dichos términos da permiso a realizar modificaciones a una obra, realizar copias y distribuirla o distribuir cualquiera de sus versiones derivadas. Con esta licencia, está permitido cobrar por la distribución de cada copia, o no cobrar nada. Este último punto distingue las licencias GPL de las licencias de software que prohíben la distribución comercial. La FSF argumenta que en el software libre no debe haber cabida para las restricciones comerciales, y las obras bajo este tipo de licencias pueden ser vendidas a cualquier precio.

La GPL, además, establece que un distribuidor no puede imponer "restricciones sobre los derechos otorgados por la GPL". Esta prohíbe actividades como la distribución del software bajo un acuerdo de confidencialidad o contrato. Distribuidores bajo la GPL también conceder una licencia para cualquiera de sus patentes software, para ser utilizadas en software GPL.

La cuarta sección de la versión 2 de la licencia y la decimoséptima sección de la versión 3 requieren que los programas distribuidos como binarios precompilados estén acompañados de una copia del código fuente, una oferta por escrito para distribuir el código fuente a través del mismo mecanismo que el binario pre-compilado, o una oferta por escrito para obtener el código fuente del binario recibido bajo la GPL. La segunda sección de la versión 2 y la sección quinta de la versión 3 también apuntan que hay que suministrar "a todos los destinatarios una copia de esta Licencia junto con el Programa". La versión 3 de la licencia permite que el código fuente esté disponible en distintas plataformas en cumplimiento de la séptima sección. Estos incluyen la descarga de código fuente desde un servidor de red adyacente o la obtención del mismo a través de peer-to-peer, siempre que el código compilado esté disponible y que haya "instrucciones claras” sobre dónde encontrar el código fuente.

La FSF no permite la aplicación de derechos de copyright a una obra licenciada bajo GPL, al menos que el autor los aplique explícitamente (esto sucede raras veces en con excepción de los programas que forman parte del proyecto GNU). Sólo los titulares de los derechos individuales tienen la autoridad para demandar una violación de la licencia cuando se lleva a cabo.

Los derechos de distribución otorgados por la GPL para versiones modificadas de la obra no son incondicionales. Cuando alguien distribuye bajo GPL añadiendo a la obra sus propias modificaciones, los requisitos para la distribución de la totalidad de la obra no puede ser mayor que los requisitos que están en la GPL.

Este requisito se conoce como "copyleft". Que alcanza su verdadero potencial en el caso de los derechos de autor sobre el software. Si una obra GPL tiene derechos copyright, no se tendrá derecho a distribuir esta obra, realizar modificaciones (excepto para uso propio). Al aplicar una GPL a una obra, los derechos de la misma estarán protegidos por la ley de derechos de autor. Y si por el contrario, si se distribuye copias de la obra (licenciada bajo GPL) sin atenerse a los términos de la GPL (por ejemplo, al mantener en secreto el código fuente), puede ser demandado por el autor original de los derechos de autor.

"Copyleft" por lo tanto utiliza la ley de copyright para lograr lo opuesto de su propósito usual: en lugar de imponer restricciones, otorga derechos, de tal manera que garantice que los derechos no puedan ser posteriormente quitados o restringidos. También asegura que si los derechos ilimitados de redistribución no se conceden o se produce cualquier falla legal se encuentra bajo la protección de la ley.

Muchos distribuidores de programas bajo GPL empaquetan el código fuente con el ejecutable. Una alternativa que cumple las bases de "copyleft" es la de proporcionar una oferta por escrito para distribuir el código fuente en un medio físico (como por ejemplo un CD) bajo demanda. En la práctica muchos programas bajo la GPL se distribuyen por internet, y el código se encuentra alojado en servidores FTP, HTTP, etc.

"Copyleft" solo se aplica cuando se trata de redistribuir el programa. Según sus bases, está permitido hacer privadas las modificaciones realizadas, sin obligación de divulgar las modificaciones siempre y cuando este software sea de uso propio (no sea redistribuido).

Hubo un debate sobre si se trataba de una violación de la GPL de liberar el código fuente tanto en forma ofuscada, como en forma deliberadamente compleja a la comprensión. El consenso general fue que, si bien no ética, no se consideró una violación. El asunto fue aclarado cuando la licencia fue modificada para exigir que tuviera que estar disponible la versión «preferida» del código fuente.

GPL fue diseñado orientado más a una licencia que a un contrato. En algunas jurisdicciones, la distinción legal entre una licencia y un contrato es muy importante: los contratos son ejecutables por la ley de contratos, mientras que las licencias se aplican en virtud del derecho de autor. Sin embargo, esta distinción no es útil en las diversas jurisdicciones en que no existen diferencias entre los contratos y licencias, como los sistemas de derecho civil.

Aquellos que no aceptan los términos de la GPL y sus condiciones no tienen permiso, en virtud del derecho de autor, a copiar o distribuir software con la GPL o trabajos derivados. Sin embargo, si no redistribuyen el programa, pueden utilizar el software en su organización a su gusto, y estas obras (incluidos los programas) construidas bajo este uso no requieren estar bajo esta licencia.

El texto que compone la GPL es en sí está protegido bajo "copyright" y es propiedad de la FSF. Sin embargo, la FSF no es titular del derecho de autor de una obra publicada bajo la GPL, a menos que el autor asigne explícitamente los derechos de autor a la FSF (que rara vez sucede con excepción de los programas que forman parte del proyecto GNU). Sólo los titulares de los derechos individuales tienen la autoridad para demandar una violación de la licencia cuando se lleva a cabo.

La FSF permite al público crear nuevas licencias basadas en la GPL, siempre y cuando las licencias derivadas no utilicen GPL sin permiso. Esto no se recomienda, ya que tal licencia puede ser incompatible con la GPL.
Otras licencias creadas por el proyecto GNU incluyen la GNU Lesser General Public License y la GNU Free Documentation License.

Código licenciado bajo varias licencias puede ser combinado con programas con licencias GPL sin conflictos, siempre que la combinación de restricciones del trabajo en su conjunto no ponga ninguna restricción adicional más allá de lo permitido por la GPL. Además de los términos regulares de la GPL, hay restricciones y permisos adicionales que se pueden aplicar:


La FSF mantiene una lista de las licencias de software libre GPL-compatibles con muchas de las licencias de software libre más comunes, como la licencia original MIT/X la licencia BSD (en su forma actual de tres cláusulas) y la licencia Artistic 2.0.

David A. Wheeler ha abogado a los desarrolladores de software libre/abierto a que usen solo licencias GPL-compatibles, porque hacerlo de otra manera hace más difícil para los demás la participación y la contribución al código. Como ejemplo específico de incompatibilidad, ZFS de Sun Microsystems no puede ser incluido en la GPL del kernel Linux, porque este está bajo una GPL-incompatible CDDL. Además, ZFS está protegido por patentes, así que la distribución independiente desarrollada por una implementación GPL requeriría el permiso de Oracle.

Varias empresas usan licencias múltiples para distribuir una versión GPL y vender una propietaria a otras compañías que quieran combinar el paquete de código con código propietario, usando una vinculación dinámica o no. Ejemplos de estas compañías incluyen MySQL AB, Digia PLC (Qt framework, antes del 2011 de Nokia), Red Hat (Cygwin) y RiverBank Computing (PyQt). Otras compañías, como Mozilla Foundation (algunos de sus productos incluyen Mozilla Application Suite, Mozilla Thunderbird y Mozilla firefox), usan licencias múltiples para distribuir versiones bajo GPL y otras licencias de código abierto.

La GPL, al ser un documento que cede ciertos derechos al usuario, asume la forma de un contrato, por lo que usualmente se la denomina contrato de licencia o acuerdo de licencia. En los países de tradición anglosajona existe una distinción doctrinal entre licencias y contratos, pero esto no ocurre en los países de tradición civil o continental. Como contrato, la GPL debe cumplir los requisitos legales de formación contractual en cada jurisdicción.

La licencia ha sido reconocida, entre otros, por juzgados en Alemania, particularmente en el caso de una sentencia en un tribunal de Múnich, lo que indica positivamente su validez en jurisdicciones de derecho civil.

El software bajo la "GPL" puede ser aplicado bajo todos los propósitos, incluidos los propósitos comerciales e incluso como herramienta de creación de software propietario. En uso puramente privativo (o interno), sin ventas ni distribuciones implicadas, el software puede ser modificado sin liberar el código fuente pero, de lo contrario, el código fuente y cualquier cambio realizado en él debe estar disponible para los usuarios, ya que en este caso los derechos del usuario están protegidos por copyleft. De esta forma, las aplicaciones instaladas en sistemas operativos prominentes bajo la "GPL" como Linux y también el GNU Compiler Collection, no es necesario que estén licenciadas bajo la "GPL" o que estén distribuidas con su código fuente disponible ya que las licencias no dependen de la plataforma. Por ejemplo, si un programa está formado completamente por código original, o si está combinado con software que no cumple los requisitos de copyleft no es necesario que se licencie bajo la "GPL" o que se distribuya con su código fuente disponible. Sólo si un programa utiliza fragmentos de código "GPL" (y el programa es distribuido) el código fuente en su totalidad debe estar disponible, bajo la misma licencia. La otra licencia de GNU, LGPL (GNU Lesser General Public License) fue creada para tener derechos menos restrictivos que "GPL", por lo que en este caso en un programa que utiliza fragmentos de código LGPL, no es necesario liberar el código original. Algunos otros programas de software libre (como ejemplo prominente esta "MySQL") son de doble licencia bajo varias licencias, a menudo con uno de los certificados que son la "GPL".




</doc>
<doc id="1236" url="https://es.wikipedia.org/wiki?curid=1236" title="Proyecto GNU">
Proyecto GNU

El proyecto GNU es un proyecto colaborativo de software libre con el objetivo de crear un sistema operativo completamente libre: el sistema GNU. Fue anunciado por Richard Stallman en 1983.

GNU es un acrónimo recursivo que significa GNU No es Unix ("GNU is Not Unix"). Nótese que la "G" a su vez significa "GNU". Puesto que en inglés americano ""gnu"" se pronuncia parecido a ""new"", Richard Stallman recomienda pronunciarlo con una "g" no silenciosa para evitar sugerir que se trata de algo nuevo. En español, se recomienda pronunciarlo "ñu" como el antílope africano, o bien fonéticamente como en inglés.
En sus charlas Richard Stallman finalmente dice: «"Se puede pronunciar de cualquier forma, la única pronunciación errónea es llamarlo "Linux""».

En la década de 1970 UNIX era un sistema operativo no libre o privativo muy popular entre los reducidos usuarios académicos e industriales de la época. Su éxito es atribuido a su portabilidad, entonces descomunal; a su arquitectura relativamente simple que ha demostrado ser técnicamente estable; y a las viejas prácticas liberales de distribución de software aunadas a regulaciones anti-monopolio, que obligaron durante un tiempo a su propietario AT&T a ofrecer el código gratuitamente a diversas instituciones.

Mientras tanto Stallman venía de una tradición de programadores completamente distinta en los laboratorios del MIT, donde se usaban otros sistemas operativos autóctonos bajo el control de sus usuarios, como el Incompatible Timesharing System. Hacia principios de la década de 1980 la comunidad hacker del MIT se desmoronaba junto con sus sistemas. Muchos miembros partieron para desarrollar software privativo para compañías como Symbolics, y la nueva ola iba reemplazando el viejo software del MIT que quedaba atrapado en las arquitecturas de hardware. Habiéndose acostrumbrado a modificar y compartir tales programas en extinción; Stallman asegura que el desarrollo de un sistema operativo libre moderno y portátil (y con éste el lanzamiento del movimiento del software libre) fue una reacción contra lo que de otra manera le parecía un futuro desagradable rodeado de software privativo. Así el sistema GNU fue diseñado para ser totalmente compatible con UNIX; aprovechando tanto el diseño modular y portable como sus usuarios.

El 27 de septiembre de 1983 se anunció públicamente el proyecto por primera vez en el grupo de noticias net.unix-wizards. Al anuncio original siguieron otros ensayos escritos por Richard Stallman como el ""Manifiesto GNU"", que establecieron sus motivaciones para realizar el proyecto GNU, entre las que destaca "volver al espíritu de cooperación que prevaleció en los tiempos iniciales de la comunidad de usuarios de computadoras". La programación comenzó en 1984.

Stallman había experimentado decepción ofreciendo sus programas libres a Symbolics, que luego le eran negados tras ser mejorados. Dentro de sus anuncios del proyecto GNU, Stallman habla por primera ocasión de la idea de evitar ofrecer sus nuevos programas bajo el completo dominio público. Para asegurar que el software GNU permaneciera libre para todos sus usuarios independientemente de los distribuidores e intermediarios, el proyecto debía ser publicado bajo una licencia de derechos de autor diseñada para ofrecer las libertades, al mismo tiempo que prohibiera añadir restricciones posteriores. La idea se conoce como copyleft, y está representada en la Licencia General Pública de GNU (GNU GPL) entre otras.
En 1985, Stallman creó la Free Software Foundation (FSF o Fundación para el Software Libre) para proveer soportes logísticos, legales y financieros al proyecto GNU. La FSF también contrató programadores para contribuir a GNU, aunque una porción sustancial del desarrollo fue (y continúa siendo) producida por voluntarios. A medida que GNU ganaba renombre, negocios interesados comenzaron a contribuir al desarrollo o comercialización de productos GNU y el correspondiente soporte técnico. El más prominente y exitoso de ellos fue Cygnus Solutions, ahora parte de Red Hat.

El hecho de ser compatible con la arquitectura de UNIX implica que GNU esté compuesto de pequeñas piezas individuales, algunas de las cuales ya estaban disponibles libremente, como el sistema tipográfico TeX y el sistema gráfico X Window que pudieron ser adaptados y reutilizados. Muchos otros en cambio tuvieron que ser desarrollados desde cero para luego poder ser ofrecidos libremente. Para 1990 el proyecto GNU ya había completado la re-escritura del bien conocido editor de texto Emacs, la creación del compilador GCC, del intérprete de comandos o shell Bash, y la mayor parte de las bibliotecas y utilidades que componen un sistema operativo UNIX típico. Éstos gozaron de adopción y éxito inmediato, pero faltaba un componente clave: el núcleo (kernel en inglés).

En el manifiesto GNU, Stallman mencionó que "un núcleo inicial existe, pero se necesitan muchos otros programas para emular Unix". Él se refería a TRIX, que es un núcleo de llamadas remotas a procedimientos, desarrollado por el MIT y cuyos autores decidieron que fuera libremente distribuido; TRIX era totalmente compatible con UNIX versión 7. En diciembre de 1986 ya se había trabajado para modificar este núcleo. Sin embargo, los programadores decidieron que no era inicialmente utilizable, debido a que solamente funcionaba en "algunos equipos sumamente complicados y caros", razón por la cual debería ser portado a otras arquitecturas antes de que se pudiera utilizar. Finalmente, en 1988, se decidió utilizar como base el micronúcleo Mach desarrollado en la CMU. Inicialmente, el núcleo recibió el nombre de Alix (así se llamaba una novia de Stallman), pero por decisión del programador Michael Bushnell fue renombrado a Hurd. La programación finalmente dio inicio en 1990. Desafortunadamente, debido a razones técnicas y conflictos entre los programadores originales el desarrollo de Hurd se retrasó enormemente. Hurd no vio la luz de la usabilidad sino hasta mediados de la década de 2000. Afortunadamente la gente no tuvo que esperar hasta entonces por un sistema completo y funcional; otros núcleos ya habían acaparado la atención de los programadores y alcanzado mayor madurez.

Armado con las herramientas de GNU, en 1991 Linus Torvalds empezó a escribir el núcleo Linux inspirado en el libro de Minix de Andrew Tanenbaum. En sus primeros anuncios públicos Torvalds le atribuía su acción a la frustración de no poder usar Minix comercialmente, y a la ausencia de núcleos libres tipo Unix como GNU Hurd; o el de BSD, descendiente de Unix que para entonces se encontraba purgando el código privativo original de AT&T y defendiéndose legalmente del mismo. A pesar de sus desacuerdos suscitados a raíz de la publicación de Linux, tanto Torvalds como Tanenbaum pronosticaban que el superior núcleo de GNU eventualmente dejaría obsoletos a Linux y Minix. En 1992 Torvalds decidió cambiar la licencia no comercial de Linux a la GPL. Rápidamente, múltiples programadores se unieron en el desarrollo, colaborando a través de Internet y consiguiendo que paulatinamente Linux fuera más serio, potente y compatible con UNIX. Linux fue combinado con el resto del sistema GNU, resultando en un sistema operativo libre y completamente funcional que sigue usándose al día de hoy. La combinación es conocida como "GNU/Linux" o como una "distribución Linux" y existen diversas variantes. (Véase también: Controversia por la denominación GNU/Linux).

También es frecuente hallar componentes de GNU instalados en un sistema BSD o un UNIX no libre, en lugar de los programas originales para UNIX. Esto se debe a que muchos de los programas escritos por el proyecto GNU han demostrado ser de mayor calidad que sus versiones equivalentes de UNIX.
A menudo, estos componentes se conocen colectivamente como "herramientas GNU". Muchos de los programas GNU han sido también transportados a otros sistemas operativos como Microsoft Windows y Mac OS X.

Listado de algunos programas desarrollados por el proyecto GNU:


El proyecto GNU también ayuda con el desarrollo de otros paquetes, como:

La pocas variantes puramente GNU usan el núcleo Hurd, por ejemplo Debian GNU/Hurd, aunque no ha habido lanzamientos oficiales hasta el momento.

Linux es el núcleo más usado con GNU, aunque Linux en sí no es parte del proyecto GNU (Linux-libre sin embargo sí lo es). GNU también es utilizado con otros núcleos, como en Debian GNU/kFreeBSD, Debian GNU/NetBSD, Nexenta OS o GNU-Darwin.

Actualmente las distribuciones que la FSF recomienda son aquellas que traen el kernel Linux-libre y que usan exclusivamente software libre. Algunas de éstas son Trisquel GNU/Linux, Parabola GNU/Linux entre otras. La lista completa se puede ver en el sitio web de GNU.




</doc>
<doc id="1239" url="https://es.wikipedia.org/wiki?curid=1239" title="Geometría">
Geometría

La geometría (del latín "geometrĭa", y este del griego γεωμετρία de "γῆ" "gē", ‘tierra’, y μετρία "metría", ‘medida’) es una rama de la matemática que se ocupa del estudio de las propiedades de las figuras en el plano o el espacio, incluyendo: puntos, rectas, planos, politopos (que incluyen paralelas, perpendiculares, curvas, superficies, polígonos, poliedros, etc.).

Es la base teórica de la geometría descriptiva o del dibujo técnico. También da fundamento a instrumentos como el compás, el teodolito, el pantógrafo o el sistema de posicionamiento global (en especial cuando se la considera en combinación con el análisis matemático y sobre todo con las ecuaciones diferenciales).

Sus orígenes se remontan a la solución de problemas concretos relativos a medidas. Tiene su aplicación práctica en física aplicada, mecánica, arquitectura, geografía, cartografía, astronomía, náutica, topografía, balística etc. Y es útil en la preparación de diseños e incluso en la elaboración de artesanía.

La geometría es una de las ciencias más antiguas. Inicialmente está constituida en un cuerpo de conocimientos prácticos en relación con las longitudes, áreas y volúmenes. La civilización babilónica fue una de las primeras culturas en incorporar el estudio de la geometría. La invención de la rueda abrió el camino al estudio de la circunferencia y posteriormente al descubrimiento del número π (pi); También desarrollaron el sistema sexagesimal, al conocer que cada año cuenta con 360 días, además implementaron una fórmula para calcular el área del trapecio rectángulo. En el Antiguo Egipto estaba muy desarrollada, según los textos de Heródoto, Estrabón y Diodoro Sículo. Euclides, en el siglo III a. C. configuró la geometría en forma axiomática y constructiva, tratamiento que estableció una norma a seguir durante muchos siglos: la geometría euclidiana descrita en "Los Elementos".

El estudio de la astronomía y la cartografía, tratando de determinar las posiciones de estrellas y planetas en la esfera celeste, sirvió como importante fuente de resolución de problemas geométricos durante más de un milenio. René Descartes desarrolló simultáneamente el álgebra de ecuaciones y la geometría analítica, marcando una nueva etapa, donde las figuras geométricas, tales como las curvas planas, podrían ser representadas analíticamente, es decir, con funciones y ecuaciones. La geometría se enriquece con el estudio de la estructura intrínseca de los entes geométricos que analizan Euler y Gauss, que condujo a la creación de la topología y la geometría diferencial.

La geometría se propone ir más allá de lo alcanzado por la intuición. Por ello, es necesario un método riguroso, sin errores; para conseguirlo se han utilizado históricamente los sistemas axiomáticos. El primer sistema axiomático lo establece Euclides, aunque era incompleto. David Hilbert propuso a principios del siglo XX otro sistema axiomático, éste ya completo.
Como en todo sistema formal, las definiciones, no sólo pretenden describir las propiedades de los objetos, o sus relaciones. Cuando se axiomatiza algo, los objetos se convierten en entes abstractos ideales y sus relaciones se denominan modelos.

Esto significa que las palabras "punto", "recta" y "plano" deben perder todo significado material. Cualquier conjunto de objetos que verifique las definiciones y los axiomas cumplirá también todos los teoremas de la geometría en cuestión, y sus relaciones serán virtualmente idénticas al del modelo "tradicional".

En geometría euclidiana, los axiomas y postulados son proposiciones que relacionan conceptos, definidos en función del punto, la recta y el plano. Euclides planteó cinco postulados y fue el quinto (el postulado de paralelismo) el que siglos después —cuando muchos geómetras lo cuestionaron al analizarlo— originará nuevas geometrías: la elíptica (geometría de Riemann) o la hiperbólica de Nikolái Lobachevski.

En geometría analítica, los axiomas se definen en función de ecuaciones de puntos, basándose en el análisis matemático y el álgebra. Adquiere otro nuevo sentido hablar de puntos, rectas o planos. puede definir cualquier función, llámese recta, circunferencia, plano, etc.

El campo de la topología, que tuvo un gran desarrollo en el siglo XX, es en sentido técnico un tipo de geometría transformacional, en que las transformaciones que preservan las propiedades de las figuras son los homeomorfismos (por ejemplo, esto difiere de la geometría métrica, en que las transformaciones que no alteran las propiedades de las figuras son las isometrías). Esto ha sido frecuentemente expresado en la forma del dicho: "la topología es la geometría de la página de goma".

Desde los antiguos griegos, ha existido numerosas contribuciones a la geometría, particularmente a partir del siglo XVIII. Eso ha hecho que proliferen numerosas subramas de la geometría con enfoques muy diferentes. Para clasificar los diferentes desarrollos de la Geometría moderna se pueden recurrir a diferentes enfoques:

Los antiguos griegos manejaban un único tipo de geometría, a saber, la geometría euclídea, hábilmente codificada en los "Elementos de Euclides" por una escuela alejandrina encabezada por Euclides. Este tipo de geometría se basó en un estilo formal de deducciones a partir de cinco postulados básicos. Los cuatro primeros fueron ampliamente aceptados y Euclides los usó extensivamente, sin embargo, el quinto postulado fue menos usado y con posterioridad diversos autores trataron de demostrarlo a partir de los demás, la imposibilidad de dicha deducción llevó a constatar que junto con la geometría euclídea existían otros tipos de geometrías en que el quinto postulado de Euclídes no participaba. De acuerdo a las modificaciones introducidas en ese quinto postulado se llega a familias diferentes de geometrías o espacios geométricos diferentes entre ellos:
A partir del siglo XIX se llegó a la conclusión de que podían definirse geometrías no euclídeas entre ellas:

En el siglo XIX se constató que otra forma de enfocar los conceptos geométricos era estudiar la invarianza de ciertas propiedades bajo diferentes tipos de transformaciones matemáticas, así se clasificaron diversas propiedades geométricas en grupos y se plantearon subdisciplinas consistentes en ver cuales eran las propiedades invariantes bajo tipos particulares de transformaciones, así aparecieron los siguientes tipos de enfoques geométricos:

Si bien Euclides básicamente se restringió a conceptos geométricos representables mediante figuras (puntos, líneas, círculos, etc.) el desarrollo de otras ramas de las matemáticas no conectadas inicialmente con la geometría propiamente dicha, llevó a poder aplicar las herramientas de otras ramas a problemas propiamente geométricos así nacieron:

Además de las subramas propiamente dichas modernamente han surgido numerosas aplicaciones prácticas de la geometría entre ellas:

El aprendizaje de la geometría implica el desarrollo de habilidades visuales y de argumentación.
Para que el aprendizaje de la geometría no carezca de sentido, es importante que el grupo docente se preocupe por buscar un equilibrio entre la asociación de habilidades de visualización y argumentación, pues ambas habilidades son fundamentales dentro del proceso formativo del individuo. Es decir, no se trata sólo de enseñar contenidos como una “receta” o por cumplir con lo estipulado en el currículo sino que se pretende que con la enseñanza de la geometría el estudiantado aprenda a pensar lógicamente.
El ser humano, desde su infancia, crea representaciones del mundo físico que le rodea. Estas le generan una necesidad (teórica y práctica) para lograr el entendimiento de ese mundo. El hemisferio derecho del cerebro resulta ser el más beneficiado ante la presencia de estímulos visuales, a diferencia del hemisferio izquierdo, que tiene la responsabilidad de desarrollar las capacidades verbales. El estudio de la geometría contribuye significativamente al desarrollo de esas necesidades espaciales de visualización; sin embargo, hasta una época histórica reciente, que data a partir de la década de los años 50, es cuando educadores matemáticos se interesaron por el estudio de dicho campo, al vincular la capacidad matemática con la capacidad espacial.
Respecto a las dificultades que las estudiantes y los estudiantes presentan al estudiar geometría se encuentran: resolver un problema algebraicamente; calcular perímetros, áreas y volúmenes, debido a que no identifican cuál fórmula aplicar y dificultad para interpretar qué es lo que dice un problema. Al realizar el análisis por nivel, se puede observar que en el ciclo diversificado (décimo y undécimo año) la principal dificultad que presentan es interpretar lo que dice un problema. La principal dificultad de las alumnas y alumnos de séptimo, octavo y noveno año, es, respectivamente, comprender las fórmulas del perímetro, áreas y volúmenes y aprender las definiciones; resolver una situación problema algebraicamente y dificultad para extraer información de un dibujo geométrico.



</doc>
<doc id="1240" url="https://es.wikipedia.org/wiki?curid=1240" title="Gluon">
Gluon

El gluon o gluón (de la voz inglesa "glue" 'pegamento', derivada a su vez del latín "glūten" a través del francés "gluer" 'pegar') es el bosón portador de la interacción nuclear fuerte, una de las cuatro fuerzas fundamentales. No posee masa ni carga eléctrica, pero sí carga de color, por lo que además de transmitir la interacción fuerte también la sufre.

La teoría que postula la existencia de los gluones y describe su dinámica se denomina cromodinámica cuántica. El nombre hace alusión a "pegamento" ("glue"), ya que estas partículas son las que "unen" los quarks dentro de los nucleones.

Al igual que el fotón, el gluon es un bosón sin masa, con espín 1. Como los quarks, los gluones tienen carga de color, que depende del cambio de color de los quarks.

Los quarks cambian de color cuando se intercambian gluones, de tal forma que la carga de color total del sistema formado por el quark y el gluon, antes y después de la emisión o absorción es la misma.

Por ejemplo, si un quark rojo se vuelve azul al emitir un gluon, entonces es porque emite un gluon rojo-antiazul (la parte roja del gluon es el rojo que pierde el quark, y el antiazul es para anular el azul que el quark gana). El sistema tiene carga de color neta roja.

Existen asimismo 8 tipos de gluones, siendo cada uno de ellos una combinación color-anticolor.
Los quarks y los gluones forman partículas compuestas con carga de color total neutra (se suele decir que las partículas compuestas son blancas).

Los gluones forman también parte de los hadrones, y la energía del campo de color que crean es la responsable de la mayoría de la masa del mismo formula_1. En el caso del protón se puede ver que:

Por lo que gran parte de la masa del protón es atribuible a la energía del campo de color.

Al sufrir ellos mismos su propia interacción, los gluones que unen los quarks crean un campo de Yang-Mills de color que impide que los quarks se separen con una fuerza inmensa, para pequeñas distancias parece que el campo decae en intensidad pero para distancias del orden del tamaño de un nucleón la fuerza es mucho mayor que las fuerzas electrostáticas de repulsión entre protones. La formación de estas ligaduras por parte de los gluones limita el campo de acción de esta interacción a un orden de 10 metros (más o menos el tamaño de un núcleo atómico).

Al contrario que la fuerza eléctrica o la gravitatoria, si se intenta separar entre sí un par de quarks, el campo de color tira de ellos con mucha más fuerza; es como si los quarks estuvieran unidos por un "muelle gluónico", que intenta volver a su longitud inicial. Debido a esto, los quarks y los gluones son partículas muy difíciles de detectar y solo podemos ver las partículas que ellos forman, los hadrones.

Cuando se separan tanto dos quarks unidos mediante este muelle, se acumula tanta energía en el sistema que es más fácil para el mismo crear nuevos quarks para devolver el campo de color a un estado menos energético. Esto es resultado de convertir parte de la energía del campo de color en nueva materia formula_1.

A pesar de que los hadrones tienen carga de color neutra, los quarks de distintos hadrones pueden atraerse con mucha fuerza, en el caso de los nucleones incluso mayor que la electromagnética. A esta fuerza de naturaleza fuerte entre distintos hadrones se le llama residual, y es la responsable de que el núcleo atómico sea estable a pesar de la gran cantidad de cargas positivas que posee.

Esta fuerza residual puede describirse de manera aproximada mediante un campo de Yukawa que representa una interacción mediada por piones que son partículas masivas lo cual explicaría que la fuerza nuclear decae mucho más rápido que la ley de la inversa del cuadrado siendo la intensidad de esta fuerza virtualmente nula fuera del núcleo atómico.

La descripción matemática de la interacción de los gluones entre sí y con los quarks es descrita por la cromodinámica cuántica. En ese contexto los gluones son descritos como un campo gluónico que es un campo de Yang-Mills asociado a una simetría de gauge del tipo SU(3). El lagrangiano que describe la interacción de los gluones entre sí y con los quarks viene dado por:
- \frac{1}{4}G^a_{\mu \nu} G^{\mu \nu}_a</math>
Donde la intensidad del campo gluónico viene dada por el tensor antisimétrico o 2-forma formula_3, mientras que la distribución espacial de los quarks viene dada por el espinor multicomponente formula_4.




</doc>
<doc id="1243" url="https://es.wikipedia.org/wiki?curid=1243" title="Género literario">
Género literario

Los géneros literarios son los distintos grupos o categorías en que podemos clasificar las obras literarias atendiendo a su contenido y estructura. La retórica los ha clasificado en tres grupos importantes: épico o narrativo, lírico y dramático, a los que se añade con frecuencia el género didáctico, convirtiéndose en un punto de referencia para el análisis de la literatura.
Así mismo, y desde el punto de vista del autor, los géneros literarios son modelos de estructuración formal y temática que le permiten establecer un esquema previo a la creación de su obra. 

La clasificación de las obras literarias en géneros y subgéneros se atiene a criterios semánticos, sintácticos, fonológicos, discursivos, formales, contextuales, situacionales y afines. En la historia, ha habido varias clasificaciones de los géneros literarios, por lo que no se puede determinar una categorización de todas las obras siguiendo un criterio común.

La clasificación de los géneros literarios se inicia con Aristóteles, quien en su obra "La Poética" distingue los siguientes:




Cada uno de estos géneros vendría definido por un modo de expresión y un estilo propio que debía adecuarse a su finalidad estética. Cualquiera de ellos puede expresarse en verso o en prosa.

Los cuatro grandes géneros literarios bajo la visión moderna (narrativa, lírica, dramática y didáctica) comprenden cada uno de ellos una variedad de subgéneros, en algunos textos definidos como «formas literarias». Fundamentalmente son:








Son las distintas variedades del drama u obra de teatro, constituida por diálogos entre personajes y con un cierto orden.

Actualmente también se consideran formas literarias aquellas que son didácticas como:

En la actualidad es difícil hablar de género, especialmente con respecto a la producción de obras después del modernismo, debido a que no existen características formales para determinar qué obras pertenecen a determinado género. Por ejemplo, la novela, tras una cierta evolución a finales del siglo XIX que culmina en Gustave Flaubert, se ha convertido en el siglo XX y comienzos del XXI en la forma literaria por excelencia, a la que se acogen más propuestas diferentes de escritura. El término novela sirve ahora de nombre a un corpus de obras de cierta extensión, en las que se pueden alojar varios discursos y en las que no es necesaria ni la unidad ni la coherencia en la acción fijadas por el canon aristotélico. Entre estas obras, son frecuentes las que hacen uso de la polifonía, presentando distintas voces narrativas, y las que tratan distintas temáticas u ofrecen distintos bloques argumentales en la misma obra. Desde luego, ya no existe un elemento formal común que las agrupe.

El tratamiento de la novela como género escrito solo vino después de 1934, cuando Mijaíl Bajtín diferenció la novela de la prosa novelesca y la poesía lírica. Los antecedentes de esta discusión de los anteriores críticos es que ellos no habían encontrado en la novela la misma forma-estilística de la poesía y, por consiguiente, se le había negado cualquier significación artística, para solo tratarla como un documento. A partir de los años veinte, se había planteado estudiar la prosa novelesca y definirla por su especifidad. De acuerdo con Bajtín, fue un error de los críticos de los años veinte el de calcar los análisis de los géneros poéticos para ser un estudio monoestilístico. Rechazando así a la estilística el estatus de estudio de la novela por solo reducirse a las destrezas individuales y del artista, y dejando al lado las evidencias del habla de las ciudades, de los registros sociales, de las generaciones y las épocas (Francisco Abad, "Bajtín ante la lengua literaria").




</doc>
<doc id="1244" url="https://es.wikipedia.org/wiki?curid=1244" title="Gramo">
Gramo

El gramo (símbolo "g") es la unidad principal de masa del Sistema Cegesimal de Unidades, y la unidad de masa del sistema métrico decimal. Originalmente fue definida como la masa de un centímetro cúbico de agua a 3,98 °C, y actualmente se define como la milésima parte del kilogramo, la unidad básica de masa del Sistema Internacional de Unidades.

1 gramo es igual a:





</doc>
<doc id="1245" url="https://es.wikipedia.org/wiki?curid=1245" title="Gustave Flaubert">
Gustave Flaubert

Gustave Flaubert (Ruan, Alta Normandía; 12 de diciembre de 1821-Croisset, Baja Normandía; 8 de mayo de 1880) fue un escritor francés. Es considerado uno de los mejores novelistas occidentales y es conocido principalmente por su novela "Madame Bovary", y por su escrupulosa devoción a su arte y su estilo, cuyo mejor ejemplo fue su interminable búsqueda de "le mot juste" ("la palabra exacta").

Gustave Flaubert fue el segundo hijo de Achille Cléophas (1784-1846) y de Anne Justine, de soltera Fleuriot (1793-1872). Su padre, cirujano jefe del Hospital de Ruan, sirvió como modelo para el personaje del doctor Lariviēre en "Madame Bovary". Su madre estaba emparentada con algunas de las más antiguas familias de Normandía.

El 15 de mayo de 1832 ingresó en el Colegio Real de Ruan, donde cursó octavo grado. Siguió sus estudios en el colegio y el instituto de Ruan sin demasiado entusiasmo. En el colegio era considerado un irresponsable. Sin embargo, se inició en la literatura a la edad de once años. Durante el verano de 1836 conoció a Élisa Schlésinger en Trouville. Este encuentro lo marcó bastante, cosa que reflejó posteriormente en su novela "La educación sentimental".

Licenciado en 1839, en agosto de 1840 superó el examen de "baccalauréat" (bachillerato). En el sorteo para el servicio militar resultó exento, e inició entonces sin demasiada convicción los estudios de Derecho en París. En su juventud Flaubert estaba lleno de vigor y, a pesar de su timidez, poseía una cierta gracia, era muy entusiasta e individualista y aparentemente no tenía ninguna ambición. Conoció a Víctor Hugo y, a finales de 1840, viajó con él por los Pirineos y Córcega. De vuelta a París perdía el tiempo soñando despierto, viviendo de las rentas que le proporcionaba su patrimonio. En junio de 1844, Flaubert, que amaba el campo y detestaba la ciudad, dejó los estudios de Derecho con el pretexto de reponerse de un acceso de epilepsia, mal que siempre se esforzó en ocultar, y abandonó París para regresar a Croisset, cerca de Ruan, donde vivió con su madre y más tarde con su sobrina. Esta propiedad, una casa en una agradable parcela a orillas del Sena, fue el hogar de Flaubert hasta el final de sus días. Aquí es también donde comenzó sus primeras obras literarias, por ejemplo la primera versión de "La educación sentimental".

En 1846 murieron su padre y su hermana, dos meses después de que enfermaran. Flaubert se hizo cargo de su sobrina. Comenzó una tormentosa relación con la poeta Louise Colet que duró diez años y de la que resultó una importantísima correspondencia. Las cartas que le dirigió fueron preservadas y, según Emile Faguet, esta relación fue el único episodio sentimental de importancia en la vida de Flaubert, que nunca se casó.

En París asistió a la Revolución de 1848, que observa con una mirada muy crítica (como en "La educación sentimental"). Durante el Segundo Imperio Francés frecuentó los salones parisinos más influyentes y entre otros se relacionó con George Sand.

Entre el 24 de mayo de 1848 y el 12 de septiembre de 1849, escribió la primera versión de "La tentación de San Antonio". En esa época su mayor amigo fue Máxime du Camp (1822-1894), con el que recorrió la región de Bretaña en 1846 y realizó un largo viaje (1849-1851) en el que recorrió Italia, Grecia, Egipto, Jerusalén y Constantinopla. Este viaje causó una gran impresión en la imaginación de Flaubert. Desde entonces, y salvo ocasionales visitas a París, no volvió a abandonar Croisset.

De regreso de su viaje a Oriente, en 1851 empezó a escribir "Madame Bovary". Anteriormente había escrito la novela "La tentación de San Antonio", pero no quedó contento con el resultado. Necesitó 56 meses para escribir "Madame Bovary", que fue publicada por primera vez en formato de folletín en la "Revue de Paris", en 1857. Las autoridades iniciaron acciones legales contra la editorial y el autor, acusados de atentar contra la moralidad, pero fueron declarados inocentes, a diferencia de Baudelaire, a quien el mismo tribunal había condenado por las mismas razones por su obra "Las flores del mal", publicada también ese mismo año.

Cuando "Madame Bovary" apareció en formato de libro recibió una cálida acogida. Flaubert pudo costearse una visita a Cartago entre los meses de abril y junio de 1858, a fin de documentarse para su próxima novela, "Salambó", que no terminó hasta 1862, a pesar de su trabajo ininterrumpido.

Retomó entonces el estudio de las costumbres de su época y, utilizando muchos de sus recuerdos de su juventud e infancia, el 1 de septiembre de 1864 comenzó a escribir la segunda versión de "La educación sentimental", que fue publicada en 1869 por la editorial Michel Lévy. Durante la Guerra franco-prusiana en 1870, soldados prusianos ocuparon su casa. Flaubert comenzó entonces a padecer enfermedades nerviosas.

La muerte o la incomprensión lo alejaron de sus amistades. En 1872 perdió a su madre, y su hasta entonces buena situación económica empeoró. Su sobrina, Mme. Commonville, cuidaba de él. En ese momento, entabló una relación de íntima amistad con George Sand, con la que mantuvo una correspondencia de inmenso interés artístico, y de vez en cuando se veía con sus conocidos parisinos, Émile Zola, Alphonse Daudet, Turgenev, Edmond Rostand y Jules Goncourt; pero nada indicaba la proximidad de la muerte de Flaubert, sumido en la desolación y la melancolía. Sin embargo, no dejó de trabajar con la misma entrega de antaño. "La tentación de San Antonio", de la que en 1857 se publicaron algunos fragmentos, fue por fin concluida y publicada por la editorial Charpentier en 1874. En ese año recibió un gran desengaño a causa del fracaso de su obra de teatro "El candidato". En 1877 Flaubert publicó en la editorial Charpentier "Tres cuentos" («Un corazón sencillo», «La leyenda de San Julián el Hospitalario» y «Herodías»). Pasó el resto de sus días trabajando incansablemente en una sátira de la futilidad del conocimiento humano y la omnipresencia de la mediocridad, que había iniciado en el periodo 1872-1874, para luego dejarla abandonada y retomarla en 1877, pero que finalmente dejó inacabada. Se trata de su deprimente y desconcertante "Bouvard y Pécuchet", publicada póstumamente en marzo de 1881 por la editorial Lemerre y que Flaubert consideraba que iba a ser su obra maestra.

Flaubert envejeció rápidamente a partir de 1870, y parecía un anciano cuando falleció en 1880, a la edad de 58 años. Murió de una hemorragia cerebral en Croisset, pero fue enterrado en el panteón familiar del cementerio de Ruan. En 1890 se inauguró en el museo de Ruan un monumento de Henri Chapu dedicado a Flaubert.

El carácter de Flaubert ofrecía varias peculiaridades. Era tímido e incluso extremadamente sensible y arrogante, pasaba del silencio absoluto a una vergonzosa y ruidosa verborrea; oscilaba entre una desesperación poco menos que nihilista y una vitalidad y "joie de vivre" casi rabelesiana. Tenía una gran tendencia a la soledad y el retraimiento social. Las mismas incoherencias marcaban su físico; tenía una fisonomía robusta pero padeció epilepsia desde la infancia; asimismo era un neurótico obsesionado con la escritura, pretexto de sus depresiones y de sus entusiasmos, cuando comentaba algunas de las páginas más felices de los clásicos. Su odio antiburgués comenzó en su infancia y se convirtió en una especie de monomanía, especialmente visible en su última obra, el "Bouvard y Pécuchet". Despreciaba la vulgaridad, la mediocridad, el adocenamiento, el materialismo del burgués, y además sus hábitos, su falta de inteligencia y su desprecio a la belleza.

Flaubert fue contemporáneo de Baudelaire, y como él, ocupa una posición clave en la literatura del siglo XIX. En su época fue rechazado (por razones morales) y admirado (por su fuerza literaria) al mismo tiempo, en la actualidad es considerado como uno de los mayores novelistas de su siglo. Se sitúa entre la generación romántica, la generación realista de Stendhal y Balzac y la generación naturalista de Zola y Guy de Maupassant.

Su preocupación e interés por el realismo y la estética de sus obras justifica el largo trabajo de elaboración de cada una de sus obras (somete a prueba sus textos leyéndolos en voz alta, sometiéndolos a la famosa prueba del «gueuloir»).



</doc>
<doc id="1247" url="https://es.wikipedia.org/wiki?curid=1247" title="Grado">
Grado

El término grado puede hacer referencia a:

El grado como medida angular:
El grado como unidad de temperatura:

El grado como unidad de acidez: 

El grado de dureza del agua, que comprende varias escalas (grado hidrotimétrico).

El grado alcohólico, porcentaje de alcohol en volumen que contiene una bebida alcohólica.

El grado de la escala, que en música designa la posición de una nota dentro de la escala musical.

El grado de parentesco entre personas.

El grado en matemáticas, además de nombrar a distintas unidades de medida de ángulos nombra:



España 

Italia

La palabra grado en topónimos:



</doc>
<doc id="1249" url="https://es.wikipedia.org/wiki?curid=1249" title="George Orwell">
George Orwell

Eric Arthur Blair (Motihari, Raj Británico, 25 de junio de 1903-Londres, Reino Unido, 21 de enero de 1950), más conocido por el pseudónimo de George Orwell, fue un escritor y periodista británico, cuya obra lleva la marca de las experiencias personales vividas por el autor en tres etapas de su vida: su posición en contra del imperialismo británico que lo llevó al compromiso como representante de las fuerzas del orden colonial en Birmania durante su juventud; a favor del socialismo democrático, después de haber observado y sufrido las condiciones de vida de las clases sociales de los trabajadores de Londres y París; y en contra de los totalitarismos nazi y estalinista tras su participación en la Guerra Civil Española.

Además de cronista, crítico de literatura y novelista, Orwell es uno de los ensayistas en lengua inglesa más destacados de los años treinta y cuarenta del siglo XX. Sin embargo, es más conocido por sus dos novelas críticas con el totalitarismo y publicadas después de la Segunda Guerra Mundial, "Rebelión en la granja" (1945) y "1984" (1949), escrita en sus últimos años de vida y publicada poco antes de su fallecimiento, y en la que crea el concepto de «Gran Hermano», que desde entonces pasó al lenguaje común de la crítica de las técnicas modernas de vigilancia.

En 2008, figuraba en el puesto número dos del listado de los cincuenta escritores británicos de mayor relevancia desde 1945, elaborado por "The Times".

El adjetivo «orwelliano» es frecuentemente utilizado en referencia al distópico universo totalitarista imaginado por el escritor inglés.

Eric Arthur Blair nació en Motihari, una colonia británica de la India, el 25 de junio de 1903. Era hijo de Ida Mabel Limouzin Blair, nacida en Birmania, de ascendencia francesa, y de Richard Walmsley Blair, administrador del ministerio del opio del gobierno colonial de la India.

A los dos años se trasladó con su madre y con su hermana mayor Marjorie a Inglaterra y no volvería a ver a su padre hasta 1907, cuando este visitó Inglaterra durante tres meses, antes de partir de nuevo hacia la India. Además, Eric tenía una hermana menor llamada Avril.

En 1909 Blair fue enviado a una pequeña escuela parroquial anglicana en Henley, a la cual había asistido su hermana mayor con anterioridad. Nunca escribió sobre sus recuerdos de aquella época, pero debió de impresionar a sus profesores muy favorablemente, pues dos años más tarde fue recomendado al director de una de las escuelas preparatorias de mayor renombre en Inglaterra por aquellos tiempos, St. Cyprian, en Eastbourne, Sussex. El joven Eric asistió a esta escuela gracias a una beca que permitía a sus padres pagar solamente la mitad de las tasas habituales. Sin embargo, Eric no se sentía a gusto en la escuela St. Cyprian, al menos en lo que se refiere a los métodos de enseñanza y a los profesores. Pese a ello, fue ahí donde consiguió sendas becas para la escuela de Wellington y posteriormente la de Eton, en la cual dice, años más tarde, haber sido relativamente feliz, pues se permitía a los estudiantes una considerable independencia. En este establecimiento hizo amistad con varios futuros intelectuales británicos, como Cyril Connolly, editor de la revista "Horizon", en la cual se publicaron muchos de los ensayos de Orwell.

Tras culminar sus estudios en Eton, decidió unirse a la Policía Imperial India en Birmania, pues no tenía posibilidades de conseguir una beca universitaria y los medios de su familia no eran suficientes para costear su educación. Tras cinco años como oficial, abandona el cuerpo de policía y vuelve a Inglaterra en 1927 habiendo desarrollado un odio hacia el imperialismo que muestra en su primera novela, "Los días de Birmania" ("Burmese Days"), publicada en 1934, y en ensayos como «Un ahorcamiento» («A Hanging», 1931) o «Matar a un elefante» («Shooting an Elephant», 1936).

Posteriormente vive un tiempo en la indigencia, haciendo trabajos de todas clases, tal y como recuerda en "Sin blanca en París y Londres" ("Down and Out in Paris and London"), su primera obra importante. Consigue un trabajo como maestro de escuela pero pronto se ve forzado a abandonarlo por problemas de salud y comienza a trabajar en una tienda de libros de segunda mano en Hampstead, una experiencia que rememora parcialmente en la novela corta "Que no muera la aspidistra" ("Keep the Aspidistra Flying", 1936).

Se trasladó a París en la primavera de 1928, donde vivía su tía Nellie, con la esperanza de forjar su carrera como hombre de letras. Tras algunos intentos fallidos, Eric se vio obligado a trabajar de lavaplatos en el lujoso Hotel X, tal como hace mención en su primer libro, "Sin blanca en París y Londres" (1933). A fines de 1929, regresó a la casa de sus padres en Southwold, Suffolk, enfermo y sin dinero, y escribió "Los días de Birmania" (1934).

Blair adoptó el seudónimo de George Orwell en 1933. Mientras el autor escribía para el "New Adelphi", vivía en Hayes, Middlesex y trabajaba como profesor de escuela, adoptó el pseudónimo para no incomodar a sus padres con "Sin blanca en París y Londres". Llegó a considerar otros nombres literarios como «Kenneth Miles» o «H. Lewis Allways», antes de decidirse por un nombre que deja traslucir el afecto que siempre había sentido por la tradición y la campiña inglesa: Jorge es el santo patrón de Inglaterra (y Jorge V era el soberano en ese entonces), mientras que el río Orwell, en Suffolk, es uno de los lugares más emblemáticos para muchos ingleses. Blair también pensó que un apellido que empezara con la letra O le daría una mejor posición a sus libros en los estantes de las librerías.

Como escritor, George Orwell se sirvió de su experiencia como profesor y de la vida en Southwold para la novela "La hija del clérigo" (1935), escrita en 1934 en casa de sus padres tras la enfermedad que lo abatía y lo obligaba a ganarse la vida impartiendo clases. De 1934 a 1936 trabajó a media jornada en Booklover’s Corner, una librería de segunda mano en Hampstead. Tras llevar una vida solitaria, quiso rodearse de la compañía de jóvenes escritores. Hampstead era un pueblo intelectual que ofrecía establecimientos destinados al desarrollo de actividades culturales de diversa índole. Estas experiencias se trasladaron a la novela "Que no muera la aspidistra" (1936).

Orwell contrajo matrimonio con Eileen O'Shaughnessy en 1936, y adoptaron un niño, Richard Horatio Blair. Eileen murió nueve años más tarde, en 1945, durante una operación.

A comienzos de 1936, Victor Gollancz, fundador del Left Book Club, instó a Orwell a escribir sobre la pobreza de la clase obrera en el norte de Inglaterra. Su relato, "El camino a Wigan Pier" fue publicada en 1937. Orwell ejerció como reportero social, tuvo acceso a muchas viviendas modestas para experimentar en las condiciones ínfimas en las que vivía la gente, tomó nota de los ingresos salariales por hogar, y pasó días enteros consultando en la biblioteca por registros de salud pública e informes laborales en las minas. Sin embargo, el autor nunca formó parte activa de asociación o coalición partidista alguna, si bien en vida reconoció sentirse un hombre de izquierdas.

La primera mitad de "El camino a Wigan Pier" presenta un compendio de sus investigaciones sociológicas en Lancashire y Yorkshire. Comienza evocando el panorama de las minas de cobre. La segunda parte, en cambio, es un ensayo extenso de sus vivencias y del desarrollo de su conciencia política, incluyendo una denuncia a los elementos irresponsables de la izquierda. Como resultado, el editor Gollancz temió que la última parte pudiera resultar ofensiva para los lectores habituales del Left Book Club, por lo que, sin pedirle autorización, agregó un prefacio a la obra mientras Orwell se encontraba en España.

Orwell decidió combatir en España con la idea de «matar fascistas porque alguien debe hacerlo». Así se lo hizo saber a su amigo Henry Miller en París en las navidades de 1936, quien le intentó convencer de que era «una idiotez». Aun así, no consiguió hacerle cambiar de idea, ya que su decisión estaba basada en la lucha por unos ideales.

Llegó a Barcelona el 26 de diciembre de 1936 con una carta de presentación del Partido Laborista Independiente (no se afilió al partido hasta junio de 1938, tras volver a Inglaterra) y ese mismo día se alistó y fue asignado como miliciano al partido de orientación trotskista POUM. Más tarde escribiría que de haber comprendido mejor la situación política en España, se habría unido como miliciano a la CNT.

En enero y febrero de 1937 combatió en el frente de la sierra de Alcubierre (Huesca). Más tarde, estando de permiso en Barcelona, participó en las Jornadas de Mayo de 1937 y tras volver al frente, recibió un tiro en el cuello en las proximidades de Huesca, el 20 de mayo de 1937. Su experiencia le motivó para escribir "Homenaje a Cataluña", donde describe su admiración por lo que es identificado como ausencia de estructuras de clase en algunas áreas dominadas por revolucionarios de orientación anarquista. Pero también critica el control estalinista del Partido Comunista de España y las mentiras que se usaban como propaganda para la manipulación informativa. En 1937, durante la represión del gobierno de Negrín contra el POUM, Orwell relató que estuvo a punto de ser asesinado en Barcelona.

Su participación en la Guerra Civil Española le marcó para siempre su visión del mundo. En 1946 escribió «La guerra de España y otros acontecimientos ocurridos en 1936-1937 cambiaron las cosas, y desde entonces supe dónde me encontraba. Cada línea en serio que he escrito desde 1936 ha sido escrita, directa o indirectamente, contra el totalitarismo y a favor del socialismo democrático como yo lo entiendo».

Al volver a Inglaterra estuvo ingresado con tuberculosis en un sanatorio, tras la cual se fue a Marruecos para recuperarse.

Orwell opinaba que si bien se necesitaba un cambio radical en las sociedades occidentales, y por tanto en los países capitalistas, el estalinismo representaba una amenaza a los principios que lo sustentaban.

Orwell se sustentó escribiendo reseñas de libros para el "New English Weekly" hasta 1940. Durante la Segunda Guerra Mundial fue miembro de la Home Guard, en donde recibió la Medalla de la Defensa. Sus pensamientos de aquellos años han quedado grabados en su libro "Diario de guerra 1940-1942".

En 1941 comenzó a trabajar para el Servicio Oriental de la BBC, principalmente en programas para ganar el apoyo de la India y el este de Asia a los ejércitos aliados. Era consciente de que su trabajo en esta época era simple y propagandístico, por lo que describe sentirse como «una naranja que ha sido pisoteada por una bota muy sucia». A pesar de los buenos ingresos, renunció en 1943 para convertirse en columnista y editor literario del "Tribune", la revista semanal de tendencia izquierdista que entonces dirigían Aneurin Bevan y Jon Kimche.

Se ha revelado en 2005, mediante un informe de la inteligencia británica, que Orwell fue vigilado durante alrededor de 12 años por la policía de aquel país en vista de su aparente vinculación con movimientos de izquierdas.

En 1949 Orwell entregó una carta a una amiga, Celia Kirwan, que trabajaba para una sección del Foreign Office (el ministerio de asuntos exteriores británico), dedicada en esos días a organizar unas conferencias sobre el estalinismo. Kirwan se dirigió a Orwell solicitándole nombres susceptibles de aceptar. Orwell también incluyó una lista de treinta y ocho escritores y artistas que consideró en su momento con inclinaciones procomunistas y que no tendrían intención en participar en dichas conferencias. En la lista, que no fue publicada hasta el 2003, se incluyeron numerosos periodistas —entre ellos el editor del "New Statesman", Kingsley Martin— y también a los actores Michael Redgrave y Charlie Chaplin.

En octubre de 1949, poco antes de su muerte, se casó en segundas nupcias con Sonia Brownell. Orwell murió en Londres a la edad de 46 años, de tuberculosis, enfermedad que había contraído durante el periodo que describe en "Sin blanca en París y Londres". Pasó los últimos tres años de su vida entre hospitales. Poco antes de morir, pide ser enterrado de acuerdo al rito anglicano. Falleció el 21 de enero de 1950. Sus restos reposan en Sutton Courtenay, Oxfordshire.

Orwell decía que su estilo literario se aproximaba bastante al de Somerset Maugham. En sus ensayos literarios también alaba encarecidamente los trabajos de Jack London, especialmente su libro "La carretera" ("The Road"). El descenso de Orwell a la vida de los más desfavorecidos en "El camino a Wigan Pier" tiene un parecido razonable con "La gente del abismo" ("The People of the Abyss") de London. En otros ensayos Orwell manifiesta su admiración por Charles Dickens, Herman Melville o Jonathan Swift.

A lo largo de su carrera fue principalmente conocido por su trabajo como periodista, en especial en sus escritos como reportero; a esta faceta se pueden adscribir obras como "Homenaje a Cataluña" ("Homage to Catalonia"), sobre la Guerra Civil Española, o "El camino a Wigan Pier" ("The Road to Wigan Pier"), que describe las pobres condiciones de vida de los mineros en el norte de Inglaterra.
Sin embargo los lectores contemporáneos llegan primeramente a este autor a través de sus novelas, particularmente a través de títulos enormemente exitosos como "Rebelión en la granja" ("Animal Farm") o "1984". La primera es una alegoría de la corrupción de los ideales socialistas de la Revolución rusa por Stalin. "1984" es la visión profética de Orwell sobre una sociedad totalitarista situada supuestamente en un futuro cercano. Orwell había vuelto de Cataluña convertido en un antiestalinista con simpatía por los trotskistas, definiéndose como un "socialista demócrata".









</doc>
<doc id="1253" url="https://es.wikipedia.org/wiki?curid=1253" title="Grossulariaceae">
Grossulariaceae

Grossulariaceae es una familia de plantas del orden "saxifragales" que consta de dos géneros, siete subgéneros y unas 150 especies. 
Habita las regiones frías y húmedas del hemisferio boreal y Sudamérica.

Son arbustos de hoja caduca y espinosos o desarmado. Hojas alternas o fasciculadas, simples, palmeadas y lobuladas a menudo veteadas, estípulas ausentes o adnadas a los pecíolos. La flores se presentan solitarias o en racimos, son bisexuales o unisexuales por aborto. Tubo del cáliz adnado al ovario, lóbulos imbricados. Pétalos libres, más pequeños que los sépalos. Estambres tantos como los pétalos y alternando con ellos. Ovario ínfero, unilocular, muchos óvulos en 2 placentas parietales, estilos 2, casi unidas, estigmas indivisa. Fruto en forma de baya, coronada por el cáliz persistente.
La familia fue descrita por Augustin Pyrame de Candolle y publicado en "Flore Française. Troisième Édition" 4(2): 405. 1805. El género tipo es: "Grossularia" Mill. 


</doc>
<doc id="1255" url="https://es.wikipedia.org/wiki?curid=1255" title="Geraniales">
Geraniales

Las Geraniales es un pequeño orden de las Magnoliophytas, incluyéndose dentro del subgrupo rósidas de las dicotiledóneas. La familia más grande en el orden son las Geraniaceae con más de 800 spp. El orden incluye algunas familias, contribuyendo juntos con menos de 40 spp. Muchas Geraniales son herbáceas, pero hay arbustos y pequeños árboles. Flores pentámeras, actinomorfas o zigomorfas; androceo con 2 verticilos, a veces uno de ellos se transforma en estaminodios; presentan un disco nectarífero muy reducido, que llega a transformarse en glándulas internas; cuando queda algo del disco, a este se sueldan los estambres, recuerda a un hipanto corto, pero segrega néctar; gineceo súpero. Muchas familias, escasa representación en la península ibérica, y solo de alguna de ellas.

La importancia económica de las Geraniales es baja. Algunas spp. del género "Pelargonium" son cultivadas por su aceite aromática para la industria perfumera. Otras especies, mayormente de las Geraniaceae, tiene usos hortícolas y medicinales.

No existen registros paleobotánicos.

Las familias están en nuevas clasificaciones. En ellas, Hypseocharitaceae y Francoaceae con Greyiaceae son incluidas dentro de las Geraniaceae y de las Melianthaceae respectivamente, pero pueden ser tratadas separadamente. Las Ledocarpaceae pueden incluirse en las Vivianiaceae.

En el sistema Cronquist, las Geraniales tenían una diferente composición, comprendiendo las siguientes familias:


Las Vivianiaceae y las Ledocarpaceae eran incluidas en las Geraniaceae, y las Hypseocharitaceae en las Oxalidaceae, y ahora en el orden Oxalidales. Las Melianthaceae estaban en las Sapindales, Greyiaceae y Francoaceae en las Rosales, esta última subsumida en las Saxifragaceae.



</doc>
<doc id="1256" url="https://es.wikipedia.org/wiki?curid=1256" title="Geraniaceae">
Geraniaceae

La de las geraniáceas (Geraniaceae) es una familia de hierbas o subarbustos (subfruticosos en la base). Hojas simples desde algo lobuladas hasta muy divididas, a veces peltadas, opuestas o alternas, con o sin estípulas. Flores hermafroditas, actinomorfas con tendencia a la zigomorfía; cáliz con 5 sépalos libres; corola con 5 pétalos libres; androceo con 10 estambres en 2 verticilos, a veces algunos reducidos hasta estaminodios, a veces pueden abortar 3 estambres ("Pelargonium"); gineceo súpero pentacarpelar, estilos soldados con estigmas libres. Flores generalmente agrupadas en cimas o en umbelas. Fruto baya esquizocarpico, con un pico estilar común, que en la madurez se separan en 5 mericarpos monospermos, germinación hipogea. Unas 700 especies de países templados y subtropicales, sobre todo de África del sur y de la región mediterránea.

Hierbas anuales a perennes, muy ramificadas en la base, a veces acaules. Los tallos pueden ser desde postrados hasta erectos, pubescentes. Las hojas presentan estípulas, son simples (desde lobadas a pinnatipartidas) o pinnaticompuestas (raramente bipinnatisectas). Las inflorescencias están sostenidas por pedúnculos bifloros (en ocasiones unifloros), o cimas umbeliformes terminales o axilares hasta de diez flores. Las flores son actinomorfas y hermafroditas. El cáliz está compuesto por cinco sépalos imbricados, múticos o mucronados, desiguales: los tres mayores muy pubescentes y los otros dos glabrescentes, persistentes y
algo acrescentes en el fruto. La corola está compuesta por cinco pétalos, unguiculados y caedizos. Presentan cinco nectarios que se ubican alternando con los pétalos. El androceo está formado por diez estambres dispuestos en dos ciclos, todos fértiles o el ciclo externo transformado en estaminodios; los filamentos son anchos, raramente connados en la base; las anteras son versátiles. El gineceo es de ovario súpero, formado por cinco carpelos unidos entre sí que delimitan cinco lóculos. Dentro de cada lóculo se hallan dos óvulos anátropos y péndulos. Presentan cinco estilos unidos entre sí por el ápice, las ramas estigmáticas son filiformes. El fruto es esquizocárpico y se denomina regma. A la madurez se separa en cinco mericarpos cada uno con una semilla y adherido a los estilos que se arquean o enrollan. Las semillas son exendospermadas, el embrión curvo y los cotiledones son peciolados, foliáceos.Etimología: Del griego "géranos" (γέρανος), grulla, debido al parecido de los frutos de las plantas de esta familia, en especial los de las especies del género "Geranium", con la cabeza y el pico de esta ave.


La familia fue descrita por Antoine-Laurent de Jussieu y publicado en "Genera Plantarum" 268. 1789 El género tipo es: "Geranium" L.
Comprende 7 géneros aceptados y otros 22 pendientes de ser aceptados.





</doc>
<doc id="1257" url="https://es.wikipedia.org/wiki?curid=1257" title="Idioma griego">
Idioma griego

El griego (en griego, Ελληνική γλώσσα [eliniˈci ˈɣlosa] o ελληνικά [eliniˈka]) es una lengua originaria de Grecia, que pertenece a la rama griega de las lenguas indoeuropeas. Es la lengua indoeuropea con la mayor historia documentada, puesto que cuenta con más de 3400 años de evidencia escrita. El sistema de escritura que ha utilizado durante la mayor parte de su historia y hasta la actualidad es el alfabeto griego. Previamente utilizó otros sistemas, como el Lineal B o el silabario chipriota. El alfabeto griego deriva del fenicio, y a su vez dio lugar a los alfabetos latino, cirílico y copto, entre otros.

El griego ocupa un lugar importante dentro de la Historia de Europa, la llamada civilización occidental y la cristiandad. El canon de la literatura griega antigua incluye obras de importancia e influencia monumental para el futuro canon occidental, como los poemas épicos de la "Ilíada" y la "Odisea". También en griego se escribieron muchos de los textos fundacionales de la filosofía occidental, como los diálogos platónicos o las obras de Aristóteles. El Nuevo Testamento de la Biblia se escribió en griego ""koiné"", idioma en el que se sigue celebrando la liturgia de varias confesiones cristianas (especialmente la Iglesia Ortodoxa y el rito bizantino de la Iglesia Católica). Junto con los textos latinos y las tradiciones del mundo romano, profundamente influido por la antigua sociedad griega, conforma la disciplina de los estudios clásicos.

El griego moderno, tal y como se lo conoce hoy en día, deriva del griego antiguo a través griego medieval o bizantino y es el idioma oficial de Grecia y de Chipre, además de ser una de las lenguas oficiales de la Unión Europea. El estándar lingüístico actual se desarrolló tras la Guerra de Independencia de Grecia (1821-1831) y está basado en la lengua popular ("dimotikí"), aunque con considerable influencia de la lengua culta arcaizante desarrollada a lo largo de los siglos XIX y XX ("kazarévusa"), que fue la norma oficial hasta 1976. Existen minorías de hablantes de griego en el sur de Albania y de Italia, donde se habla el dialecto salentino y el grecocalabrés. En torno al mar Negro quedan todavía minorías de hablantes del dialecto póntico. Además, desde finales del siglo XIX existen comunidades grecoparlantes descendientes de emigrados en Francia, Alemania, Reino Unido, Estados Unidos, Canadá, Australia, Argentina, Brasil, Chile, México y Uruguay.

Las lenguas o dialectos griegos constituyen juntos la subfamilia helénica de la familia indoeuropea. Con un registro escrito de unos 3.400 años, el griego es una de las lenguas (propiamente un grupo de lenguas) cuyo desarrollo histórico puede seguirse durante un mayor período, siendo superada solo por los escritos en lenguas chinas, egipcias e hitita. La historia de la lengua griega se puede dividir en las siguientes etapas:





Es común enfatizar la continuidad histórica de las diversas etapas de la lengua griega. Aunque el griego ha desarrollado cambios morfológicos y fonológicos comparables a los de otros idiomas, no ha habido ningún momento a lo largo de su historia desde la antigüedad clásica en que su tradición cultural, literaria u ortográfica se haya visto interrumpida hasta el punto de que pueda determinarse fácilmente el surgimiento de un nuevo idioma. Incluso hoy en día los hablantes de griego suelen considerar las obras literarias en griego antiguo más como parte de su idioma que de un idioma extranjero. Además, se afirma con frecuencia que los cambios históricos han sido relativamente pequeños en comparación con otras lenguas. Según Margaret Alexíou, «el griego homérico es probablemente más cercano al demótico que el inglés del siglo XII al inglés oral actual». La percepción de continuidad histórica se ve también reforzada por el hecho de que el griego se ha dividido muy poco en varias lenguas hijas, como ocurrió con el latín. Junto con el griego moderno estándar (en sus dos registros Katharévousa y dimotikí), las otras variedades derivadas del griego son el griego póntico, el tsakonio del Peloponeso oriental, hoy altamente amenazado, y el griko (grecocalabrés y griko salentino) de Italia meridional.

El griego es el idioma oficial y lengua mayoritaria de Grecia y Chipre. Como lengua minoritaria está presente desde hace más de dos mil años en el sur de Albania y en el sur de Italia (Grecia Salentina). En Italia se encuentran al sur de Apulia, donde se habla el salentino, y también en Bovesia y Regio de Calabria, al sur de Calabria, donde se habla la lengua greka. Igualmente existen minorías griegas desde hace más de dos mil años en territorios hoy ocupados por Turquía, principalmente en la actual Estambul, Esmirna, otras zonas de la Tracia Oriental y las costas anatólicas del Mar Egeo y el Mar de Mármara. De modo semejante son antiquísimas las muy pequeñas comunidades grecoparlantes existentes en algunos sitios costeros de la república de Georgia (incluyendo Pitiys, en la costa de Abjasia), en Ucrania (particularmente en la península de Crimea y en la parte meridional de la región histórica de Zaporozhia), y en las costas de Bulgaria y Rumania.

Desde finales del siglo XIX existen algunas comunidades grecoparlantes descendientes de emigrados en Francia, Alemania, Inglaterra, Australia, Estados Unidos, Canadá, México, Argentina, Brasil, Chile, y Uruguay. Es, por tanto, una lengua con un gran área de dispersión y una gran importancia histórica y filológica, pues los idiomas europeos más importantes de la actualidad poseen millares de palabras de uso común con étimos griegos, lo que da una idea de la importancia del idioma dentro de la cultura global. Con todo, se considera que el griego era hablado usualmente por unos dieciséis millones de personas en el 2006.

El griego moderno, los dialectos greco-italianos, el póntico y el tsakonio, son ya los únicos representantes supervivientes de la rama griega de las lenguas indoeuropeas. Otros idiomas importantes pero ya desaparecidos de esta rama fueron el griego micénico, el griego ático y el griego helenístico, extendido gracias a las conquistas de Alejandro Magno y del que derivan todas las variedades actuales a excepción del tsaconio.

A lo largo de su historia, la estructura silábica del griego ha cambiado poco: el griego muestra una estructura silábica mixta, que permite ataques silábicos complejos, pero codas restringidas. Solo tiene vocales orales, y una serie considerablemente estable de contrastes consonánticos. Los principales cambios fonológicos tuvieron lugar durante el periodo helenístico e incluyeron:

El alfabeto utilizado por el griego moderno es prácticamente el mismo del griego clásico, solo se ha modificado el sonido de algunas letras. En cambio quedaron obsoletas algunas letras dialectales o arcaicas usadas hacia los siglos VII y VI a. C. tales como la doble gamma o digamma (valor fonético aproximado: ([w]), la qoppa ([k]), la sampi ([ss, ts]?) y la san (s). También cayó en desuso una forma de escribir la letra sigma usada en el koiné alejandrino y en el griego bizantino cuyo grafema era "C", letra que ha quedado como legado en el alfabeto cirílico con el valor fonético de s.

En todas sus etapas, la morfología griega muestra una gran variedad de afijaciones derivativas, un sistema limitado pero productivo de composición, y un rico sistema flexivo. Mientras que las categorías morfológicas han permanecido estables a lo largo del tiempo, los cambios morfológicos han sido notables, especialmente en los sistemas nominal y verbal. El principal cambio en la morfología nominal fue la pérdida del dativo, cuyas funciones fueron sustituidas sobre todo por el genitivo. En la morfología verbal el principal cambio fue la pérdida de los infinitivos, que conllevó un consecuente aumento de nuevas formas perifrásticas.

Los pronombres muestran marcas de persona (1ª, 2ª y 3ª), número (singular, dual y plural en griego antiguo; singular y plural en las etapas posteriores), y género (masculino, femenino y neutro); así como declinación con casos (de seis casos en las formas arcaicas a cuatro en griego moderno). Los sustantivos, artículos y adjetivos marcan todas estas distinciones excepto la de persona. Tanto los adjetivos atributivos como los predicativos concuerdan con el nombre.

Las categorías flexivas del verbo griego han permanecido relativamente estables a lo largo de la historia griega, aunque con cambios significativos en cuanto al número de distinciones de cada categoría y su expresión morfológica. Los verbos griegos tienen formas flexivas sintéticas para:

Muchos aspectos de la sintaxis griega han permanecido constantes: los verbos solo concuerdan con el sujeto, el uso de los casos restantes está casi intacto (nominativo para sujetos y atributos, acusativo para objetos directos y tras casi todas las preposiciones, genitivo para la posesión), el artículo precede al nombre, las aposiciones son generalmente preposicionales, las oraciones de relativo siguen al sustantivo al que modifican, los pronombres relativos se posicionan al inicio de su proposición, etc. Sin embargo, los cambios morfológicos también tuvieron sus equivalentes en la sintaxis, y hay por tanto diferencias significativas entre la sintaxis antigua y moderna. El griego antiguo usaba muy frecuentemente construcciones de participio y de infinitivo, mientras que el griego moderno carece de infinitivo y en su lugar utiliza una gran variedad de construcciones perifrásticas, utilizando los participios de manera más restringida. La pérdida del dativo conllevó un aumento de objetos indirectos marcados mediante preposición o con genitivo. El orden de palabras antiguo tendía a ser SOV, mientras que el moderno es SVO o VSO.

La mayor parte del léxico del griego antiguo es heredado, pero incluye un número de préstamos de las lenguas de las poblaciones que habitaban en Grecia antes de la llegada de los proto-griegos. Se han identificado palabras de origen no indoeuropeo ya en tiempos micénicos, destacando en número los topónimos. La mayor parte del léxico griego moderno, por otro lado, ha sido heredada directamente del griego antiguo, aunque con cambios semánticos en bastantes casos. Los préstamos se han tomado principalmente del latín, el veneciano y el turco. Generalmente, los préstamos tomados con anterioridad al siglo XX adoptaron la declinación griega, mientras que los préstamos posteriores, especialmente los tomados del francés y el inglés, son indeclinables.



</doc>
<doc id="1258" url="https://es.wikipedia.org/wiki?curid=1258" title="Geología">
Geología

La geología (del griego γῆ /"guê"/, ‘Tierra’, y -λογία /"-loguía"/, ‘tratado’) es la ciencia que estudia la composición y estructura tanto interna como superficial del planeta Tierra, y los procesos por los cuales ha ido evolucionando a lo largo del tiempo geológico.

La misma comprende un conjunto de geociencias, así conocidas actualmente desde el punto de vista de su pedagogía, desarrollo y aplicación profesional. Ofrece testimonios esenciales para comprender la tectónica de placas, la historia de la vida a través de la paleontología, y cómo fue la evolución de ésta, además de los climas del pasado. En la actualidad la geología tiene una importancia fundamental en la exploración de yacimientos minerales (minería) y de hidrocarburos (petróleo y gas natural), y la evaluación de recursos hídricos subterráneos (hidrogeología). También tiene importancia fundamental en la prevención y entendimiento de desastres naturales como remoción de masas en general, terremotos, tsunamis, erupciones volcánicas, entre otros. Aporta conocimientos clave en la solución de problemas de contaminación medioambiental, y provee información sobre los cambios climáticos del pasado. Juega también un rol importante en la geotecnia y la ingeniería civil. También se trata de una disciplina académica con importantes ramas de investigación. Por extensión, han surgido nuevas ramas del estudio del resto de los cuerpos y materia del sistema solar (astrogeología o geología planetaria).

El estudio de la materia física de la Tierra se remonta a la Grecia antigua, cuando Teofrasto (372-287 aC) escribió la obra "Peri lithon" ("Sobre las rocas"). En la época romana, Plinio el Viejo escribió en detalle de los muchos minerales y metales que se utilizan en la práctica, y señaló correctamente el origen del ámbar.

Algunos estudiosos modernos, como Fielding H. Garrison, son de la opinión de que la geología moderna comenzó en el mundo islámico medieval. Abu al-Rayhan al-Biruni (973-1048) fue uno de los primeros geólogos musulmanes, cuyos trabajos incluían los primeros escritos sobre la geología de la India, la hipótesis de que el subcontinente indio fue una vez un mar. El erudito islámico Avicena (981-1037) propuso una explicación detallada de la formación de montañas, el origen de los terremotos, y otros temas centrales de la geología moderna, que proporcionan una base esencial para el posterior desarrollo de esta ciencia. En China, el erudito Shen Kuo (1031-1095) formuló una hipótesis para el proceso de formación de la Tierra, basado en su observación de las conchas de los animales fósiles en un estrato geológico en una montaña a cientos de kilómetros del mar, logró inferir que la Tierra se formó por la erosión de las montañas y por la deposición de sedimentos.

Durante los primeros siglos de exploración europea se inició una etapa de conocimiento mucho más detallado de los continentes y océanos. Los exploradores españoles y portugueses acumularon, por ejemplo, un detallado conocimiento del campo magnético terrestre y en 1596, Abraham Ortelius vislumbra ya la hipótesis de la deriva continental, precursora de la teoría de la tectónica de placas, comparando las costas de Sudamérica y África.

A Nicolás Steno (1638-1686) se le atribuye el Principio de la superposición de estratos, el principio de la horizontalidad original, y el principio de la continuidad lateral: tres principios que definen la estratigrafía.

Richard de Bury (1287-1345), en un libro titulado "Philobiblon" (o "El amor a los libros"), utilizó por primera vez el término "geologia", o ciencia terrenal. Sin embargo, no parece que el término fuese usado para definir una ciencia cuyo objeto de estudio fuese la Tierra, sino más bien el término "ciencia terrenal" aparece por oposición al término "teología" u otros términos con connotaciones espirituales.

El naturalista italiano Ulisse Aldovrandi (1522-1605) usó por primera vez la palabra "geología", con un sentido próximo al que tiene actualmente, en un manuscrito encontrado después de su muerte. Consideró la geología como la ciencia que se ocupa del estudio de los "fósiles", pero hay que tener en cuenta que el término "fósil" incluía también en aquellos tiempos los minerales y las rocas. Posteriormente, en 1657 aparece un trabajo de Mickel Pederson Eschilt, escrito en danés, y titulado "Geologia Norwegica", en el que estudió un terremoto que afectó a la parte sur de Noruega. En 1661, Robert Lovell (1630-1690), escribió una "Universal History of Minerals" ("Historia Universal de los Minerales"), una de cuyas partes denominó con el nombre latinizado de "Geologia". Después esta palabra fue usada por Fabrizio Sessa en 1687, en su trabajo titulado "Geologia -nella quale se spiega che la Terre e non le Stelle influisca né suaoi corpi terrestre", afirmando que "la geología es verdaderamente la que habla de la Tierra y de sus influencias". Erasmus Warren, en 1690, publicó un libro titulado "Geologia or a Discourse concerning the Earth before the Deluge" ("Geología, o un discurso concerniente a la Tierra antes del diluvio"); no obstante, el término "Geología" aparece sólo en el título de la obra, no encontrándose después en el texto. La palabra "Geología" fue establecida definitivamente como un término de uso general por Jean-André Deluc en 1778 y Horace-Bénédict de Saussure en 1779.

William Smith (1769-1839) dibujó algunos de los primeros mapas geológicos y comenzó el proceso de ordenar cronológicamente los estratos rocosos mediante el estudio de los fósiles contenidos en ellos.

James Hutton es a menudo visto como el primer geólogo moderno. En 1785 presentó un documento titulado "Teoría de la Tierra" para la Sociedad Real de Edimburgo. En su ponencia, explicó su teoría de que la Tierra debía de ser mucho más antigua de lo que se suponía, con el fin de permitir el tiempo suficiente para que las montañas puedan haber sido erosionadas y para que los sedimentos logren formar nuevas rocas en el fondo del mar, y estos a su vez afloren a la superficie para poder convertirse en tierra seca. Hutton publicó una versión de dos volúmenes de sus ideas en 1795.

Los seguidores de Hutton fueron conocidos como "plutonistas" porque creían que algunas rocas se formaron por volcanismo, que es la deposición de lava de los volcanes, a diferencia de la "neptunistas", quienes creían que todas las rocas se habían formado en el interior de un gran océano cuyo nivel disminuyó gradualmente con el tiempo.

Charles Lyell publicó su famoso libro "Principios de geología" en 1830. El libro, que influyó en el pensamiento de Charles Darwin, promovió con éxito la doctrina del uniformismo. Esta teoría afirma que los procesos geológicos que han ocurrido a lo largo de la historia de la Tierra, aún se están produciendo en la actualidad. Por el contrario, el catastrofismo es la teoría que indica que las características de la Tierra se formaron en diferentes eventos individuales, catastróficos, y que la tierra se mantuvo sin cambios a partir de entonces. Aunque Hutton creyó en el uniformismo, la idea no fue ampliamente aceptada en el momento.

Gran parte de la geología del siglo XIX giró en torno a la cuestión de la edad exacta de la Tierra. Las estimaciones variaban enormemente de unos pocos cientos de miles, a miles de millones de años. En el siglo XX, la datación radiométrica permitió que la edad de la Tierra se estimase en aproximadamente dos mil millones de años. La conciencia de esta enorme cantidad de tiempo abrió la puerta a nuevas teorías sobre los procesos que dieron forma al planeta. Hoy en día se sabe que la Tierra tiene aproximadamente 4500 millones de años.

Los avances más importantes en la geología del siglo XX han sido el desarrollo de la teoría de la tectónica de placas en la década de 1960, y el refinamiento de las estimaciones de la edad del planeta. La teoría de la tectónica de placas surgió a partir de dos observaciones geológicas por separado: La expansión del fondo oceánico y la deriva continental. La teoría revolucionó completamente las ciencias de la Tierra.

La escala del tiempo geológico abarca toda la historia de la Tierra. Se encuentra enmarcada a lo largo de aproximadamente 4.567 millones de años, en que se dataron los primeros materiales acrecionados del sistema solar, dando la edad de la tierra en 4.54 Ga, al comienzo del Eon Hádico (no oficialmente reconocido). Al final de la escala, se toma el día presente incluido en el Cuaternario Holoceno.


Actualmente la Geología comprende distintas ciencias o disciplinas, que configuran los planes formativos educativos universitarios o profesionales. Estas pueden estructurarse en los siguientes:

La cristalografía es la ciencia geológica que se dedica al estudio científico de los cristales, definidos como ""sólidos con una estructura interna formada por átomos, iones o moléculas ordenados periódicamente"". Para ello, es necesario conocer, por un lado, la estructura que presentan las partículas constituyentes del cristal; y por otro lado, es importante determinar su composición química. Los estudios de la estructura se apoyan fuertemente en el análisis de los patrones de difracción que surgen de una muestra cristalina al irradiarla con un haz de rayos X, neutrones o electrones. La estructura cristalina también puede ser estudiada por medio de microscopía electrónica.

La espeleología, es una ciencia que estudia la morfología y formaciones geológicas (espeleotemas) de las cavidades naturales del subsuelo. En ella se investigan, cartografían y catalogan todo tipo de descubrimientos en cuevas. Forma parte de la Geomorfología y sirve de apoyo a la Hidrogeología (Geodinámica externa). Suele ser considerada actualmente más bien un deporte, como anunciaba Noel Llopis Lladó en 1954, que la auténtica espeleología peligraba ya que existía un "confusionismo" entre el deporte (Espeleismo) y la ciencia (Espeleología).

La estratigrafía es la rama de la geología que trata del estudio e interpretación de las rocas sedimentarias, metamórficas y volcánicas estratificadas, y de su identificación, descripción, secuencia, tanto vertical como horizontal; cartografía y correlación de las unidades estratificadas de las rocas.

En la geología del petróleo se combinan diversos métodos o técnicas exploratorias para seleccionar las mejores oportunidades o “plays” para encontrar hidrocarburos (petróleo y gas).

La geología económica se encarga del estudio de las rocas con el fin de encontrar depósitos minerales que puedan ser explotados por el hombre con un beneficio práctico o económico. La explotación de estos recursos es conocida como minería.

La geología estructural es la rama de la geología que se dedica a estudiar la corteza terrestre, sus estructuras y su relación en las rocas que las contienen. Estudia la geometría de las formaciones rocosas y la posición en que aparecen en superficie. Interpreta y entiende el comportamiento de la corteza terrestre ante los esfuerzos tectónicos y su relación espacial, determinando la deformación que se produce, y la geometría subsuperficial de estas estructuras.

La gemología es en sentido amplio una rama de la mineralogía que se dedica específicamente al estudio, identificación, análisis y evaluación de las piedras preciosas o gemas. Una tarea central de la gemología es poner a disposición métodos y procedimientos rigurosos que permitan distinguir las gemas naturales de sus imitaciones y versiones sintéticas. Entre estos procedimientos se cuentan las mediciones realizadas con distintos instrumentos y aparatos (por ejemplo, mediciones cristalográficas y fotométricas, microscopía, espectroscopía, análisis de difracción por rayos X, etc). Debido al valor de las piezas estudiadas, prescinde de aquellos métodos mineralógicos que requieren de la extracción de muestras y utiliza solo aquellos procedimientos que las conservan intactas.

La geología histórica es la rama de la geología que estudia las transformaciones que ha sufrido la Tierra desde su formación, hace unos 4.540 millones de años, hasta el presente. Para establecer un marco temporal absoluto, los geólogos han desarrollado una cronología a escala planetaria dividida en eones, eras, periodos, épocas y edades, vinculada a su vez con una escala relativa, dividida en eonotemas, eratemas, sistemas, series y pisos que se corresponden uno a uno con los anteriores. Estas escalas se basan en los grandes eventos biológicos y geológicos.

La astrogeología, también llamada geología planetaria o exogeología, es una disciplina científica que trata de la geología de los cuerpos celestes (planetas y sus satélites, asteroides, cometas y meteoritos).

La geología regional es una rama de las ciencias geológicas que se ocupa de la configuración geológica de cada continente, país, región o de zonas determinadas de la Tierra.

La Geomorfología tiene por objeto la descripción y la explicación del relieve terrestre, continental y marino, como resultado de la interferencia de los agentes morfodinámicos sobre la superficie terrestre. Se puede subdividir, a su vez, en tres vertientes: G. Estructural que trata de la caracterización y génesis de las “formas del relieve”, como unidades de estudio. La G. Dinámica, sobre la caracterización y explicación de los procesos de erosión y meteorización por los principales agentes (gravedad y agua). Y la G. Climática, sobre la influencia del clima sobre la morfogénesis (dominios morfoclimáticos).

La geoquímica es la rama de la geología que estudia la composición y el comportamiento químico de la Tierra, determinando la abundancia absoluta y relativa de los elementos químicos, distribución y migración de los elementos entre las diferentes partes que conforman la Tierra (hidrosfera, atmósfera, biosfera y litosfera) utilizando como principales muestras minerales y rocas componentes de la corteza terrestre, intentando determinar las leyes o principios en las cuales se basa tal distribución y migración.

En 1923 el químico V.W Goldschmidth clasificó los elementos químicos en función a su historia geológica de la siguiente forma: «atmósfilos» que forman la atmósfera como son los gases, «calcófilos» como son las arenas y cristales (silicatos y carbonatos), «litófilos» corteza son sencillos como sulfuros, y «siderófilos» que son metales que se conservan puros.

La geofísica estudia la Tierra desde el punto de vista de la física y su objeto de estudio está formado por todos los fenómenos relacionados con la estructura, condiciones físicas e historia evolutiva de la Tierra. Al ser una disciplina experimental, usa para su estudio métodos cuantitativos físicos como la física de reflexión y refracción, y una serie de métodos basados en la medida de la gravedad, de campos electromagnéticos, magnéticos o eléctricos y de fenómenos radiactivos. En algunos casos dichos métodos aprovechan campos o fenómenos naturales (gravedad, magnetismo terrestre, mareas, terremotos, tsunamis, etc.) y en otros son inducidos por el hombre (campos eléctricos y fenómenos sísmicos).

La hidrogeología es una rama de las ciencias geológicas que estudia las aguas subterráneas en lo relacionado con su origen, su circulación, sus condicionamientos geológicos, su interacción con los suelos, rocas y humedales (freatogénicos); su estado (líquido, sólido y gaseoso) y propiedades (físicas, químicas, bacteriológicas y radiactivas) y su captación.

La mineralogía es la rama de la geología que estudia la sistemática y las propiedades físicas y químicas de los minerales que se encuentran en el planeta en sus diferentes estados de agregación. Un mineral es un sólido inorgánico de origen natural, que presenta una composición química definida, además tiene una estructura cristalina. Una observación importante es el caso del mercurio que, debido a la disposición de sus átomos, es un mineraloide. Los minerales aportan al ser humano los elementos químicos imprescindibles para sus actividades industriales.

La Paleontología es la ciencia que estudia e interpreta el pasado de la vida sobre la Tierra a través de los fósiles. Parte de sus fundamentos y métodos son compartidos con la Biología. Se subdivide en Paleobiología, Tafonomía y Biocronología y aporta información necesaria a otras disciplinas (estudio de la evolución de los seres vivos, bioestratigrafía, paleogeografía o paleoclimatología, entre otras).

La petrología es la rama de la geología que consiste en el estudio de las propiedades físicas, químicas, minerológicas, espaciales y cronológicas de las asociaciones rocosas y de los procesos responsables de su formación. La petrografía, disciplina relacionada, trata de la descripción y las características de las rocas cristalinas determinadas por examen microscópico con luz polarizada.

La sedimentología es la rama de la geología que se encarga de estudiar los procesos de formación, transporte y depósito de materiales que se acumulan como sedimentos en ambientes continentales y marinos y que normalmente forman rocas sedimentarias. Trata de interpretar y reconstruir los ambientes sedimentarios del pasado. Se encuentra estrechamente ligada a la estratigrafía, si bien su propósito es el de interpretar los procesos y ambientes de formación de las rocas sedimentarias y no el de describirlas como en el caso de aquella.

La sismología es la rama de la geofísica que se encarga del estudio de terremotos y la propagación de las ondas elásticas (sísmicas), que estos generan, por el interior y la superficie de la Tierra. Un fenómeno que también es de interés es el proceso de ruptura de rocas, ya que este es causante de la liberación de ondas sísmicas. La sismología también incluye el estudio de las marejadas asociadas (maremotos o "tsunamis") y los movimientos sísmicos previos a erupciones volcánicas.

La tectónica de placas es el estudio geológico-estructural a escala regional, donde se analiza no solo la mecánica sino la dinámica de la litosfera para lograr dar una explicación a las deformaciones y formaciones estructurales como lo son las placas tectónicas. Estudia las megadeformaciones a niveles corticales en ambientes continentales y oceánicos para lograr entender la formación de la Tierra y como evoluciona constantemente. El estudio de la tectónica se diversifica en otras áreas de la ciencia como el paleomagnetismo, la sismología y la termodinámica interna de la Tierra.

La vulcanología es el estudio de los volcanes, la lava, el magma y otros fenómenos geológicos relacionados. El término vulcanología viene de la palabra latina Vulcānus, Vulcano, el dios romano del fuego. Un volcanólogo es un estudioso de este campo. Los volcanólogos visitan los volcanes, en especial los que están activos, para observar las erupciones volcánicas, recoger restos volcánicos como el tephra (ceniza o piedra pómez), rocas y muestras de lava. Una vía de investigación mayoritaria es la predicción de las erupciones; actualmente no hay manera de realizar dichas predicciones, pero prever los volcanes, al igual que prever los terremotos, puede llegar a salvar muchas vidas.

Debido a la gran diversidad de disciplinas o "ciencias" geológicas, estas se agrupan en distintas unidades de enseñanza independientes, donde se lleva a cabo una mejor organización modular de la propia enseñanza e investigación de la Geología sobre las distintas "ciencias" que comprende. Una de las estructuras generales en como se componen estos departamentos, es:

Un geólogo es una persona especialista y profesional en el estudio, observación o experimentación relacionados con la Tierra, su composición, estructura, dinámica, origen y evolución.

Un geólogo se destaca por poseer las siguientes competencias:




</doc>
<doc id="1259" url="https://es.wikipedia.org/wiki?curid=1259" title="Ginkgoaceae">
Ginkgoaceae

Las Ginkgoaceae —una familia de Ginkgoales— son gimnospermas arbóreas con un único representante vivo actual, del género "Ginkgo" y especie "Ginkgo biloba". 

A diferencia de las cícadas, y como casi todas las demás gimnospermas, son árboles leñosos altamente ramificados. Puede ser reconocido por el hecho de que tiene ramas cortas además de ramas largas. De hasta 30 m de altura, con una corona más o menos asimétrica y corteza gris y surcada. Sin canales de resina. Hojas simples, de disposición espiralada, y ampliamente espaciadas en largas ramas cerca de las puntas de las ramas, también ampliamente empaquetadas en ramas cortas en los árboles más viejos, con forma de abanico, bilobadas o enteras, deciduas y amarillas brillantes en el otoño, de venación dicotómica. Árboles dioicos, como las cícadas. Los estróbilos de polen del pie masculino crecen en tallos como aguijones, constan en un eje largo central con ramas laterales que llevan cada uno de ellos dos microsporangios y penden, a veces son llamados «conos» pero no poseen estructuras que parezcan esporófilos. Los microsporangios son de dehiscencia longitudinal, liberando los granos de polen. Polen no alado, y esperma móvil, carácter ancestral. Los pies femeninos no llevan «conos». Los óvulos se presentan de a 2, terminales en una larga rama desde los tallos como aguijones, las semillas frecuentemente 1 por rama (el otro óvulo sin madurar a semilla), de unos 2,5 cm de diámetro, con una cubierta externa jugosa (sarcotesta) de olor desagradable, y otra dura interna (sclerotesta). Dentro de esta última está el endosperma de color verde claro y que constituye la parte comestible del «fruto». Está rodeado por una fina envoltura más o menos traslúcida de color pardo-anaranjado; el embrión se sitúa en posición apical. Hay 2 o 3 cotiledones.

"Ginkgo" es una de las pocas plantas con cromosomas sexuales. Las plantas con óvulos llevan dos cromosomas X, mientras que los individuos estaminados llevan cromosomas XY.

Actualmente limitado a los remotos valles montanos de China, está en peligro de extinción en la naturaleza. Ahora, irónicamente, "Ginkgo" es un buen árbol de sombra en situaciones urbanas, y ha sido plantado en todo el mundo como un popular árbol en las veredas.

Poco se sabe sobre la ecología de esta especie.

La polinización ocurre por viento en la primavera, pero la fertilización se retrasa por 4-7 meses. El jugo y el olor de la semilla sugiere dispersión por animales, pero los taxones que la dispersan son desconocidos y podrían hoy en día estar extintos.

El grupo ha estado muy diversificado en el pasado, pero en la actualidad solo existe un género ("Ginkgo") con una especie ("Ginkgo biloba").

La clasificación, según Christenhusz et al. 2011, que también provee una secuencia lineal de las gimnospermas hasta género:


Las hojas amplias y deciduas de "Ginkgo" no son como aquellas de casi todas las demás gimnospermas. La movilidad del esperma, conocida en el resto de las espermatofitas sólo en las cícadas, es claramente un carácter primitivo, como lo es la falta de tubos polínicos. El grupo viviente más cercano de Ginkgoaceae es el de las cícadas (ver Clado cícadas + "Ginkgo").

La familia tiene un extenso registro fósil, pero hoy en día contiene una única especie viviente. Los primeros representantes de "Ginkgo" aparecen en el Triásico tardío, hace más de 200 millones de años, y las estructuras reproductivas han cambiado poco en su aspecto general en unos 120 millones de años. Durante el Jurásico temprano, los parientes extinguidos de "Ginkgo" tuvieron amplia distribución y fueron diversos, consistiendo quizás en 3 familias.

Ha sido plantado en todo el mundo como un popular árbol en las veredas de las urbes.





</doc>
<doc id="1263" url="https://es.wikipedia.org/wiki?curid=1263" title="Gomorresina">
Gomorresina

La gomorresina es una secreción vegetal protectora formada por una mezcla de goma y resina que se emulsiona al mezclarse con agua. Puede contener o no, además, un aceite esencial volátil (gomorresinas con o sin olor).

La gomorresina es blanca y espesa, de naturaleza lechosa que fluye de varias plantas naturalmente o tras practicarles una incisión. Se solidifica tras estar al aire una cantidad de tiempo variable, dependiendo de la planta. Se utiliza como adhesivo natural.


</doc>
<doc id="1264" url="https://es.wikipedia.org/wiki?curid=1264" title="Kelvin">
Kelvin

El kelvin (antes llamado "grado Kelvin"), simbolizado como K, es la unidad de temperatura de la escala creada por William Thomson Kelvin, en el año 1848, sobre la base del grado Celsius, estableciendo el punto cero en el cero absoluto (−273,15 °C) y conservando la misma dimensión. Kelvin, a sus 24 años introdujo la escala de temperatura termodinámica, y la unidad fue nombrada en su honor.

Es una de las unidades del Sistema Internacional de Unidades y corresponde a una fracción de 1/273,16 partes de la temperatura del punto triple del agua. Se representa con la letra K, y nunca "°K". Actualmente, su nombre no es el de "grados kelvin", sino simplemente "kelvin".

Coincidiendo el incremento en un grado Celsius con el de un kelvin, su importancia radica en el 0 de la escala: la temperatura de 0 K es denominada 'cero absoluto' y corresponde al punto en el que las moléculas y átomos de un sistema tienen la mínima energía térmica posible. Ningún sistema macroscópico puede tener una temperatura inferior. A la temperatura medida en kelvin se le llama "temperatura absoluta", y es la escala de temperaturas que se usa en ciencia, especialmente en trabajos de física o química.

También en iluminación de fotografía, vídeo y cine se utilizan los kelvin como referencia de la temperatura de color. Cuando un cuerpo negro es calentado, emite luz de diferente color según la temperatura a la que se encuentra. De este modo, cada color se puede asociar a la temperatura a la que debería estar un cuerpo negro para emitir en ese color. Es necesario recalcar que la temperatura de color asociada a un cuerpo no está relacionada con su temperatura real. Por ejemplo, 1600 K es la temperatura de color correspondiente a la salida o puesta del sol. La temperatura del color de una lámpara de filamento de wolframio, tungsteno, corriente es de 2800 K. La temperatura de la luz utilizada en fotografía y artes gráficas es 5500 K (para considerarla "luz de día" —lo que no impide que se usen otras partes de la escala para referirse a la luz de tungsteno o algunas lámparas led), y la del sol al mediodía con cielo despejado es de 5200 K. La luz de los días nublados es más azul y es 6000 K o más, llegando incluso a los 11 000 K.

A continuación una tabla de los múltiplos y submúltiplos del Sistema Internacional de Unidades.

La física estadística dice que en un sistema termodinámico la energía contenida por las partículas es proporcional a la temperatura absoluta, siendo la constante de proporcionalidad la constante de Boltzmann. Por eso es posible determinar la temperatura de unas partículas con una determinada energía, o calcular la energía de unas partículas a una determinada temperatura. Esto se hace a partir del denominado principio o teorema de equipartición. El principio de equipartición establece que la energía de un sistema termodinámico es:

donde:




</doc>
<doc id="1265" url="https://es.wikipedia.org/wiki?curid=1265" title="Graphidiales">
Graphidiales

Graphidiales son líquenes formados por la asociación de un ascomiceto con fitobionte. Los graphidiales presentan apotecios lirelinos. Existen dos familias: 




</doc>
<doc id="1266" url="https://es.wikipedia.org/wiki?curid=1266" title="Graphidiaceae">
Graphidiaceae

Graphidiaceae son líquenes formados por la asociación de un ascomiceto con un fitobionte, presentan apotecios lirelinos, con reborde propio o paratecio, córtex ausente o muy reducido. 




</doc>
<doc id="1267" url="https://es.wikipedia.org/wiki?curid=1267" title="Graphis">
Graphis

Graphis son Líquenes formados por la asociación de un ascomiceto con fitobionte, presentan apotecios lirelinos, con reborde propio o paratecio, situados en una desgarradura, paráfisis simples. Corteza ausente o muy reducida.


</doc>
<doc id="1269" url="https://es.wikipedia.org/wiki?curid=1269" title="Gymnodiniales">
Gymnodiniales

Los Gymnodiniales son organismos unicelulares del filo Dinoflagellata, clase "Dinophyceae" con dos flagelos heterocontos en el sulcus y el cíngulo, fundamentalmente formas atecadas, otros con placas tecales.


</doc>
<doc id="1270" url="https://es.wikipedia.org/wiki?curid=1270" title="Gymnodinium">
Gymnodinium

Gymnodinium es un género de protistas dinoflagelados sin teca de la clase Dinophyceae, orden Gymnodiniales. Con dos flagelos heterocontos en el sulcus y el cíngulo.



</doc>
<doc id="1271" url="https://es.wikipedia.org/wiki?curid=1271" title="GNOME">
GNOME

GNOME es un entorno de escritorio e infraestructura de desarrollo para sistemas operativos GNU/Linux, Unix y derivados Unix como BSD o Solaris; compuesto enteramente de software libre.

El proyecto fue iniciado por los programadores de software libre mexicanos Miguel de Icaza y Federico Mena y forma parte oficial del proyecto GNU. Nació como una alternativa a KDE bajo el nombre de "GNU Network Object Model Environment" (Entorno de Modelo de Objeto de Red GNU). Actualmente, incluyendo al español, se encuentra disponible en 166 idiomas.

GNOME es el entorno de escritorio predeterminado en las principales distribuciones de Linux, incluyendo Fedora, Debian, Ubuntu, Red Hat Linux, CentOS, Oracle Linux, Arch Linux y Gentoo.

GNOME provee un gestor de ventanas «intuitivo y atractivo» y una plataforma de desarrollo para crear aplicaciones que se integran con el escritorio. El Proyecto pone énfasis en la simplicidad, facilidad de uso y eficiencia. Tiene como objetivo la libertad para crear un entorno de escritorio que siempre tendrá el código fuente disponible para reutilizarse bajo una licencia de software libre.

Desde GNOME 2, el enfoque fue puesto en la productividad. Con este fin, se crearon las Pautas de Interfaz Humana de GNOME ("Human Interface Guidelines", HIG). Todos los programas de GNOME comparten un estilo coherente de interfaz gráfica de usuario (GUI), pero no están limitados a los mismos widgets de GUI. Por el contrario, el diseño de la GUI de GNOME está guiado por conceptos que se describen en GNOME HIG, que a su vez depende de la ergonomía cognitiva. Después de HIG, los desarrolladores pueden crear programas de GUI de alta calidad, consistentes y utilizables, ya que abordan todo, desde el diseño de la GUI hasta el diseño recomendado de widgets basado en píxeles.

GNOME Shell es la interfaz de usuario oficial del escritorio GNOME, desde su versión 3.0. Cuenta con una barra superior que sostiene (de izquierda a derecha) un botón de Actividades, un menú de aplicaciones, un reloj y un menú de estado del sistema integrado. El menú de la aplicación muestra el nombre de la aplicación en foco y proporciona acceso a funciones tales como el acceso a las preferencias de la aplicación, el cierre de la aplicación o la creación de una nueva ventana de aplicación. El menú de estado contiene varios indicadores de estado del sistema, accesos directos a la configuración del sistema y acciones de sesión que incluyen el cierre de sesión, el cambio de usuario, el bloqueo de la pantalla y la suspensión de la computadora.

A partir de GNOME 3.8, se mantiene además un modo clásico para aquellos que prefieren una experiencia de escritorio tradicional (similar a GNOME 2).

GNOME tiene como objetivo mantener el entorno de escritorio accesible para las personas con discapacidad. Para ello utiliza la interfaz de programación de aplicaciones Accessibility Toolkit (ATK), que permite mejorar la experiencia del usuario mediante el uso de métodos de entrada especiales y síntesis de voz y software de reconocimiento de voz. Las utilidades particulares se registran con ATK utilizando la Interfaz de Proveedor de Servicios de Tecnología Asistida (AT-SPI) y se utilizan globalmente en todo el escritorio. Varias tecnologías de asistencia, incluido el lector de pantalla Orca y el método de entrada Dasher, se desarrollaron específicamente para su uso con GNOME.


GNOME es desarrollado por "The GNOME Project" y proporciona el escritorio GNOME, una interfaz gráfica de usuario, un conjunto de aplicaciones centrales, y la plataforma de desarrollo GNOME, un entorno para crear aplicaciones que se integran con el escritorio.

Al igual que con la mayoría de los proyectos de software libre, el desarrollo de GNOME se maneja de manera flexible. La discusión se produce principalmente en una serie de listas de correo públicas. Los desarrolladores y usuarios de GNOME se reúnen en una reunión anual de GUADEC para analizar el estado actual y la dirección futura de GNOME. GNOME incorpora estándares y programas de freedesktop.org para interactuar mejor con otros escritorios.

GNOME está escrito principalmente en C, C++, Vala, Python y JavaScript. Varias combinaciones de idiomas están disponibles.

Cada uno de los productos de software componentes en el proyecto GNOME tiene su propio número de versión y programa de desarrollo. Sin embargo, los mantenedores de módulos individuales coordinan sus esfuerzos para crear una versión estable completa de GNOME en un cronograma de aproximadamente seis meses, junto con sus bibliotecas subyacentes, como GTK+ y GLib. Algunos proyectos experimentales están excluidos de estas versiones.

Conforme van saliendo nuevas versiones, el equipo del proyecto GNOME sube el código fuente al Servidor FTP que a su vez contiene el código fuente de todas las versiones anteriores. Un dato importante para destacar es que es posible configurar la compilación del código fuente mediante "scripts". La mayoría de los proyectos que utilizan GNOME, proporcionan versiones estables y probadas, facilitando la instalación o bien lo hacen por medio de paquetes binarios precompilados.

Una lista de las distribuciones de GNU/Linux que incluyen GNOME se mantiene en la web de GNOME. Existe una versión oficial de GNOME LiveCD y LiveUSB, que permite su utilización sin necesidad de instalación, para así poder probar el escritorio.

La biblioteca de utilidades y estructuras de datos GLib, GObject y el kit de herramientas GTK+, constituyen la parte central de la plataforma de desarrollo GNOME. Esta se amplía con el marco IPC D-Bus , la biblioteca de dibujo Cairo 2D basada en vectores, la biblioteca gráfica acelerada Clutter, la biblioteca internacional de interpretación de texto Pango, la API de audio de bajo nivel PulseAudio, el entorno multimedia GStreamer y varias bibliotecas especializadas, incluyendo NetworkManager, PackageKit , Telepathy (mensajería instantánea) y WebKit.
El entorno de escritorio GNOME no consiste únicamente en la biblioteca de elementos de control gráfico GTK+ y las aplicaciones principales que hacen uso de ella. Existen bastantes paquetes de software adicionales que conforman el entorno completo de GNOME.

GNOME se inició el 15 de agosto de 1997 por Miguel de Icaza y Federico Mena, como un proyecto de software libre para desarrollar un entorno de escritorio y aplicaciones. Fue fundado en parte porque K Desktop Environment, que estaba creciendo en popularidad, se basó en el kit de herramientas Qt widget que utilizaba una licencia de software propietaria hasta su versión 2.0 (junio de 1999). En lugar de Qt, el kit de herramientas GTK+ fue elegido como la base de GNOME. GTK+ usa la Licencia Pública General Reducida (LGPL) de GNU, una licencia de software libre que permite que el software que se vincule con ella utilice un conjunto mucho más amplio de licencias, incluidas licencias de software propietario. GNOME está autorizado bajo la LGPL para sus bibliotecas, y la Licencia Pública General de GNU (GPL) para sus aplicaciones.

GNOME 2 era muy similar a una interfaz de escritorio convencional, con un escritorio simple en el que los usuarios podían interactuar con objetos virtuales, como ventanas, iconos y archivos. GNOME 2 usó Metacity como su administrador de ventanas predeterminado. El manejo de ventanas, aplicaciones y archivos, es similar al de los sistemas operativos de escritorio contemporáneos. En la configuración predeterminada de GNOME 2, el escritorio tiene un menú iniciador para acceder rápidamente a los programas instalados y las ubicaciones de archivos; Se puede acceder a las ventanas abiertas mediante una barra de tareas en la parte inferior de la pantalla, y la esquina superior derecha muestra un área de notificación para que los programas muestren avisos mientras se ejecutan en segundo plano. Sin embargo, estas funciones se pueden mover a casi cualquier posición u orientación que el usuario desee, reemplazar con otras funciones o eliminar por completo.

La versión 3.0 de GNOME fue lanzada el 6 de abril de 2011. Fue anunciada en la conferencia GUADEC en Estambul en julio de 2008. El nombre código "ToPaZ" fue posteriormente introducido dentro del proyecto y varios bosquejos fueron creados como parte del proceso de elaboración de la nueva versión. Aunque la nueva versión trae muchos cambios, la principal novedad es la inclusión de GNOME Shell. La versión iba a ser lanzada en septiembre de 2010, pero en julio del mismo año el equipo desarrollador decidió posponer el lanzamiento para el mes de marzo, lanzando en su lugar la versión 2.32. En septiembre, la fecha fue nuevamente retrasada hasta abril de 2011.

En la actualidad GNOME se ejecuta en la mayoría de sistemas tipo Unix y fue adoptado por la desaparecida empresa Sun Microsystems como parte del escritorio Java, sustituyendo el antiguo escritorio común de su plataforma Solaris. En Ubuntu, fue entorno por defecto hasta la llegada de Unity en la versión 11.04. Sin embargo, es posible alternar en la misma distribución entre Unity y GNOME. En el año 2013 con la versión 13.04 de Ubuntu, fue presentado conjuntamente el derivado oficial llamado Ubuntu GNOME. El 5 de abril de 2017 Ubuntu anunció que GNOME Shell volvería a ser elegido como entorno por defecto.




</doc>
<doc id="1273" url="https://es.wikipedia.org/wiki?curid=1273" title="Gallina ciega">
Gallina ciega

La gallina ciega (en Argentina, gallito ciego) es un juego infantil en el que un jugador, con los ojos vendados, debe atrapar a alguno de los participantes y, en ciertas variantes, adivinar quién es.

Los otros jugadores le tapan los ojos, normalmente con un pañuelo o venda, a un jugador seleccionado. Entonces el resto de jugadores empiezan a darle vueltas hasta marear al que atrapa. Mientras todos corren y la gallina gira, se va cantando una canción así, o similar:

A partir de ese momento, el jugador nombrado «gallina ciega» intenta atrapar a alguno de los que juegan, guiándose por sus voces. Tocando, por supuesto, pero sin pegar. Cuando alguien es atrapado sustituye a la gallina. En algunas versiones avanzadas del juego hay que adivinar quién es el jugador pillado, palpándole. En otras, cuando atrapa al otro jugador, ese jugador queda fuera del juego. Cuando estén jugando, para poder ayudar a la gallina a conseguir sus presas, los jugadores normalmente le hablan o le dan pistas de dónde se encuentran (como por ejemplo: cantando o gritándole direcciones como izquierda o derecha).

Suele jugarse en un área espaciosa, libre de obstáculos para evitar que el jugador haciendo el papel de la "gallina" se lastime al tropezarse o golpearse con algo.

El pintor Francisco de Goya inmortalizó este juego en su cuadro del mismo nombre. En la edad moderna, fue un juego de salón común entre los adultos de la clase alta europea



</doc>
<doc id="1274" url="https://es.wikipedia.org/wiki?curid=1274" title="Gymnostoma">
Gymnostoma

Gymnostoma es un género de árbol de la familia Casuarinaceae que comprende una quincena de especies aceptadas de las casi 30 descritas.



</doc>
<doc id="1275" url="https://es.wikipedia.org/wiki?curid=1275" title="Gastridium">
Gastridium

Gastridium, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Canarias, Europa occidental, del Mediterráneo.
Son plantas anuales. Hojas con vaina de márgenes libres; lígula obtusa, dentada, nervada, membranosa; limbo plano. Inflorescencia en panícula generalmente densa. Espiguillas con 1 flor hermafrodita, articulada con la raquilla. Glumas más largas que la flor, desiguales, agudas o acuminadas, a veces falciformes, uninervadas, ventrudas, más o menos escábridas en el ápice. Raquilla ligeramente prolongada por encima de la flor, hirsuta. Lema con 5 nervios y 4 dientes o setas apicales, mútica o aristada, membranosa. Callo redondeado. Arista dorsal más o menos geniculada. Pálea tan larga como la lema, con 2 nervios, bidentada. Lodículas enteras. Ovario elipsoideo, glabro. Cariopsis surcada. Hilo puntiforme.
El género fue descrito por Ambroise Marie François Joseph Palisot de Beauvois y publicado en " Essai d'une Nouvelle Agrostographie" 21, 164. 1812. La especie tipo es: "Gastridium australe" P. Beauv. 
El nombre del género es un diminutivo del griego "gaster" = (panza), refiriéndose a las glumas basales hinchadas.
Número de la base del cromosoma, x = 7. 2n = 28. 2 ploid. Cromosomas "grandes".
A continuación se brinda un listado de las especies del género "Gastridium" aceptadas hasta julio de 2011, ordenadas alfabéticamente. Para cada una se indica el nombre binomial seguido del autor, abreviado según las convenciones y usos.



</doc>
<doc id="1276" url="https://es.wikipedia.org/wiki?curid=1276" title="Gaudinia">
Gaudinia

Gaudinia, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario del Mediterráneo y de las Azores.
Son planta anuales. Hojas con vaina de márgenes libres; lígula corta, truncada, membranosa; limbo plano. Inflorescencia espiciforme, generalmente laxa, dística, con raquis excavado, desarticulándose por encima de las espiguillas en la madurez. Espiguillas sentadas, generalmente solitarias, más largas que los artejos del raquis, con 2-8 flores hermafroditas y no articuladas con la raquilla. Glumas más cortas que las flores, con nervios bien marcados; la inferior con 1-5 nervios; la superior con 4-11 nervios. Raquilla glabra. Lema lanceolada, papirácea, con margen membranoso y 7-9 nervios, aguda o bidentada, mútica o con arista dorsal más o menos retorcida. Pálea más corta que la lema, con 2 quillas, bidentada. Lodículas biobadas. Ovario con ápice hirsuto. Cariopsis fusiforme, ligeramente surcada, apendiculada. Hilo puntiforme.
El género fue descrito por Ambroise Marie François Joseph Palisot de Beauvois y publicado en "Essai d'une Nouvelle Agrostographie" 95, 164. 1812. La especie tipo es: "Gaudinia fragilis"
El género fue nombrado en honor de Jean François Aimée Gottlieb Philippe Gaudin (1776–1833), sacerdote suizo y profesor honorario de botánica en Lausana.
Número de la base del cromosoma, x = 7. 2n = 14 (y 14 +1). 2 ploid. Cromosomas "grandes".



</doc>
<doc id="1277" url="https://es.wikipedia.org/wiki?curid=1277" title="Glyceria">
Glyceria

Glyceria, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Tiene una distribución cosmopolita.
Son plantas perennes, glabras, de lugares encharcados. Tallos enraizantes por los nudos. Hojas con vaina de márgenes soldados, al menos en la mitad inferior y limbo plano o plegado. Panícula laxa con raquis excavado. Espiguillas con flores numerosas. Glumas desiguales, más cortas que la flor inferior, membranosas, uninervadas. Lemas redondeadas, 7-nervadas. Pálea casi tan larga como la lema, con quilla alada. Androceo con 3 estambres. Cariopsis ovoidea.
El género fue descrito por Robert Brown y publicado en "Prodromus Florae Novae Hollandiae" 179. 1810. La especie tipo es: "Glyceria fluitans" (L.) R. Br.
El nombre del género deriva del griego "glykeros" (dulce), refiriéndose a las semillas de "G. fluitans" y tal vez a las hojas y las raíces de algunas otras especies.

Número de la base del cromosoma, x = 10. 2n = 20, 28, 40, 56 y 60. 2, 4, y 6 ploid (y, aneuploides). Cromosomas pequeñas y medianas.




</doc>
<doc id="1281" url="https://es.wikipedia.org/wiki?curid=1281" title="Gráficos (informática)">
Gráficos (informática)

Gráficos o gráficas, en informática, es el nombre dado a cualquier imagen generada por una computadora.

Originariamente se llamaba así a los histogramas, pero, por extensión, empezó a llamarse así a todas las representaciones visuales que el ordenador podía generar que no fueran texto. Con el tiempo, el término se ha generalizado, aplicándose a cualquier tipo de imagen de ordenador.

Los formatos gráficos se dividen principalmente en:

Actualmente los equipos caseros y las máquinas de ocio tienen circuitos integrados especiales dedicados a aumentar la velocidad de presentación de los gráficos. Estos se conocen como unidades de procesamiento gráfico, o "GPU".



</doc>
<doc id="1287" url="https://es.wikipedia.org/wiki?curid=1287" title="Garnotia">
Garnotia

Garnotia, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Asia, norte de Australia y Pacífico.
El nombre del género fue otorgado en honor de Prosper Garnot (1794-1838), cirujano de la marina francesa y naturalista.



</doc>
<doc id="1289" url="https://es.wikipedia.org/wiki?curid=1289" title="Gay">
Gay

La palabra gay (sustantivo o adjetivo; plural: gais) es una manera de designar a las personas homosexuales masculinas, es decir, a aquellos hombres a los que les atraen sexual y emocionalmente otros hombres.

La principal diferencia entre las denominaciones «hombre homosexual» y "gay" (que hasta la década de 1970 significaba «alegre» o «divertido» en inglés); es que este último es un término positivo, importado del inglés y elegido originalmente por la comunidad gay de San Francisco (California, Estados Unidos) para referirse a sí mismos.
Mientras que «homosexual» es un neologismo, que originalmente en inglés tenía connotaciones negativas relacionadas con una patología, enfermedad o tara. Fue acuñado en 1869 por el escritor austriaco Karl-Maria Kertbeny y popularizado más tarde por el psiquiatra alemán Krafft-Ebing.

En países hispanohablantes, "gay" se refiere casi exclusivamente al género masculino (por lo tanto, no se aplica a las mujeres lesbianas o transexuales), estén o no fuera del armario. El transformismo, el travestismo y la transexualidad son fenómenos independientes (entre sí y con los gais), que pueden estar relacionados o no; por ejemplo, un hombre transexual puede ser tanto "gay" como heterosexual y un hombre que no es "gay", puede ser transformista. Aunque también se usa en algunos países para designar o calificar al género femenino; para evitar confusiones se suele hablar de «gais y lesbianas», aunque para algunas interpretaciones esta expresión es redundante.

El término «gay» es un anglicismo o préstamo de origen occitano y no del idioma inglés, como popularmente se cree; ya que en realidad lo del derivado del inglés, hace alusión a la homosexualidad asumida. Este término fue incluido en la vigésimo segunda edición del "Diccionario de la Real Academia Española" (DRAE), edición del 2001. Proviene del vocablo provenzal "gai" (en castellano "gayo", como en "La gaya ciencia") y significa alegre o pícaro. Con tal sentido lo utiliza el poeta Antonio Machado en el poema «Retrato» que publicó en 1906 en el periódico "El Liberal" y que luego apareció en su libro "Campos de Castilla" , donde habla del «gay trinar» para indicar que él no era un ave de esas que canta alegremente.

En la Inglaterra victoriana, el término "gay" se aplicaba a los hombres que ejercían la prostitución homosexual, por el modo "alegre" en que vivían y la forma en que se vestían. Finalmente, el término "gay boy" (literalmente "chico alegre", "prostituto" o "Taxi boy") se convirtió en sinónimo de homosexual dentro de la lengua inglesa.

En España, y en lenguaje coloquial; se suele calificar a los prostitutos homosexuales de bajo estatus, con el término de «chapero» ("aquél que cobra en "chapas""; entendiéndose "chapas" como monedas sueltas o calderilla). En Argentina, en cambio se suele llamar al prostituto masculino como «puto» o «taxi boy».

En el cine, la primera película que usó este término, fue el film "Bringing Up Baby" de 1938, con Cary Grant.

Gran parte de las asociaciones gais hispanohablantes, se decantaron hace tiempo por el uso del término "gay", frente a homosexual, optando por difundir su uso e incluyéndolo en sus nombres, tal como hacen COGAM (colectivo de lesbianas, gais, transexuales y bisexuales de Madrid) y FELGTB (federación estatal de gais, transexuales y bisexuales) de España, reflejando así la predilección por este término de sus asociados. De manera similar, las páginas web y medios de comunicación especializados en el colectivo usan preferentemente "gay". Aunque hay otras asociaciones como la CHA (Comunidad Homosexual Argentina) de Argentina o el Movimiento de Liberación Homosexual MOVILH de Chile que optan por el otro término.





</doc>
<doc id="1290" url="https://es.wikipedia.org/wiki?curid=1290" title="Graphics Interchange Format">
Graphics Interchange Format

Graphics Interchange Format (GIF) (Compuserve GIF) (traducido al español como Formato de Intercambio de Gráficos), es un formato gráfico utilizado ampliamente en la World Wide Web, tanto para imágenes como para animaciones.

El formato fue creado por CompuServe en 1987 para dotar de un formato de imagen en color para sus áreas de descarga de archivos, sustituyendo su temprano formato RLE en blanco y negro. GIF llegó a ser muy popular porque podía usar el algoritmo de compresión LZW (Lempel Ziv Welch) para realizar la compresión de la imagen, que era más eficiente que el algoritmo Run-length encoding (RLE) usado por los formatos PCX y MacPaint. Por lo tanto, imágenes de gran tamaño podían ser descargadas en un razonable periodo de tiempo, incluso con módems muy lentos.

GIF es un formato sin pérdida de calidad para imágenes con hasta 256 colores, limitados por una paleta restringida a este número de colores. Por ese motivo, con imágenes con más de 256 colores (profundidad de color superior a 8), la imagen debe adaptarse reduciendo sus colores, produciendo la consecuente pérdida de calidad.

La imagen en movimiento, surge con los experimentos del fisiólogo francés Étienne-Jules Marey y del fotógrafo británico radicado en los Estados Unidos Eadweard Muybridge (que, por una llamativa coincidencia, nacen y mueren en los mismos años: 1830-1904), constituyen el primer cuestionamiento de los datos que entregan los sentidos, justamente a través de los sentidos.

En 1872, surge una incógnita alrededor de los experimentos de Muybridge: ¿existía algún punto, durante el galope de un caballo, en el cual sus cuatro cascos se hallaban levantados del suelo al mismo tiempo? Con esta cuestión, Muybrigde quiso mostrar al ojo lo que jamás había visto. Esto lo logró colocando doce cámaras Scoville con lentes rápidas de Dallmayer, separadas por intervalos regulares a lo largo de una pista; cada cámara se disparaba a través de un dispositivo electromagnético accionado por en caballo a medida que su paso cortaba los filamentos tendidos transversalmente sobre la pista. como si fueran fotogramas de una película, esas imágenes sucesivas permitían ver con una nitidez irrefutable la evolución del movimiento.

Por otro lado, Marey, dentro de su aspecto científico, perfecciona la escopeta fotográfica, la cual era capaz de tomar 12 exposiciones en 1 segundo. Él consideraba que, lejos de ser permanentes, las imágenes retinianas son fugitivas: persisten allí algunos instantes, prolongando la duración aparente del fenómeno que las ha hecho nacer. Afirmaba que esta propiedad de la retina permitía estudiar cómo una imagen fotográfica podía representar un movimiento.

A partir de estos acontecimientos, y de la necesidad de representar el movimiento de una manera mucho más realista, surgen distintas técnicas de variados artistas; como por ejemplo Passion (1981, Jean-Luc Godard), The Bow (Motion Study, Anton Giulio Bragaglia), Heliografía (1993, "Claudio Caldini").

GIF
Los GIFs se extendieron gracias al navegador Netscape que permitía que se vieran. Si Netscape no hubiera integrado los GIF, probablemente, hubieran muerto en 1998. Fue en ese año cuando CompuServe fue comprada por AOL y dejó expirar la patente sobre ellos, por lo que el formato quedó liberado para el público general.

En los años 2000, cuando apareció Flash, un software que permitía crear animaciones más atractivas, potentes, que incluían audio y podían ser interactivas los GIF quedaron en desuso. Paradójicamente, el software Flash está obsoleto ya que las tabletas y smartphone como los iPhone no lo reproducen. Si haces banners publicitarios en Flash y quieres que estén desde otros móviles y no se pueden ver, se deja de usar. Las razones técnicas no son las únicas que justifican el repunte actual del uso del GIF, la funcionalidad, la gran aceptación social y potencia viral que tienen sumado a que son fáciles de ver, de reproducir, de compartir y de crear los hacen una herramienta gráfica comunicativa muy completa.

En 2012, GIF se convirtió en la palabra del año al ser reconocida por el diccionario de Oxford. Según Katherine Martin, responsable del diccionario, “el GIF ya no es solamente un medio de expresión de la cultura pop: se ha convertido en una herramienta para la investigación y el periodismo, y su identidad léxica se transforma y se mantiene”. 

Un año después, en 2013, el creador del formato, Steve Wilhite, recogió el Webby Award a toda una vida y aprovechó el momento para hacer una importante revelación: en estos premios, el discurso no puede tener más de cinco palabras y Wilhite optó por proyectar las suyas en la pared: "Se pronuncia JIF, no GIF”. Además ese mismo año, Alex Chung y Hace Cooke fundaron la base de datos online Giphy, que permite a los usuarios compartir y buscar archivos de GIFs animados. Su idea surgió con la intención de transmitir información de forma rápida y más visual.

En 2015, Facebook añadió soporte para GIFs en su página y sus chats, aunque originalmente no dieran apoyo a este formato de comunicación.

Actualmente Whatsapp ha incluido los GIFs en su plataforma.

Una imagen GIF puede soportar transparencias y puede contener entre 2 y 256 colores (2, 4, 8, 16, 32, 64, 128 ó 256) entre 16,8 millones de su paleta. Por lo tanto, dado que la paleta tiene un número de colores limitado (no limitado en cuanto a colores diferentes), las imágenes que se obtenían con este formato por lo general eran muy pequeñas.

Sin embargo, dado que el algoritmo de compresión "LZW" estaba patentado, todos los editores de software que usaban imágenes GIF debían pagarle regalías a Unisys, la compañía propietaria de los derechos. Esta es una de las razones por las que el formato PNG se está volviendo cada vez más popular, en perjuicio del formato GIF.

El GIF soporta 8 bits por píxel en cada imagen y una característica esencial es el loop infinito.

El uso de los GIF es generalmente para la publicidad en tipo banners. Su principal utilidad hoy en día sigue siendo el despliegue de imágenes animadas para páginas web, al ser el único formato soportado por multitud de navegadores que permita dicho efecto. Cabe destacar que la animación de este tipo de imágenes solo se puede visualizar en cierto tipo de aplicaciones y programas como presentaciones power point o páginas web, pero en hojas de cálculo o documentos de texto las imágenes gif pierden su animación.

Actualmente, los medios de comunicación, así como el cine, las televisoras y las campañas publicitarias, han optado por usar el formato GIF como medio de transmisión de datos, información y productos, aprovechando la rapidez de propagación y el auge que desde el 2012 ha tenido.

Estamos viviendo tiempos característicos por la sobrecarga de estímulos e información, es por eso que los GIFs suponen un momento de sosiego entre el video y la imagen fija. La manera de observar la realidad está cambiando, ahora nos fijamos en lo infinitesimal.

La Oxford University Press afirma que el formato se ha convertido en una herramienta con aplicaciones serias y aplicada en campos de investigación y periodismo.
Unisys, propietario de la patente del algoritmo LZW que se utiliza en el formato GIF reclamó durante años el pago de regalías por su uso. Compuserve, al desarrollar el formato, no sabía que el algoritmo LZW estaba cubierto por una patente. Debido a esto, cualquier programa capaz de abrir o guardar archivos GIF comprimidos con LZW debía cumplir con sus exigencias. Es necesario recalcar que el formato GIF puede utilizar otros métodos de compresión no cubiertos por patentes, como el método Run-length encoding.

El 20 de junio de 2003 expiró en Estados Unidos la patente por el algoritmo LZW.

Las redes sociales como Google Plus que permiten las animaciones han hecho que el gif animado vuelva a ser un formato muy utilizado por su sencillez de edición y poco peso frente a los vídeos.

Recientemente, redes sociales como Telegram, Twitter y Facebook se han sumado y han incluido la posibilidad de usar imágenes GIF en sus servicios. Su popularidad también llega hasta webs dedicadas a este tipo de imágenes como GIPHY, que cosecha puestos privilegiados (322) en el ranking Alexa.

Plataformas como Tumblr y Giphy son famosas por permitir acceso a gifs de infinidad de temas, permitiendo a los usuarios cargar, descargar y hasta crear sus propios gifs.

Aunque tengamos la opción de transmitir la misma idea con un pequeño vídeo, o con una frase, un GIF presenta unas ventajas técnicas y a tener en cuenta: dinamiza la comunicación, tiene una reproducción inmediata, facilita la retención visual, y produce un impacto emocional.

La primera revista en atreverse a publicar una portada que incluía un gif animado, fue la norteamericana "TIME ," que tras la presentación por parte de Apple de sus nuevos modelos de iPhone y Apple Watch el 9 de septiembre de 2014, construyó una portada alrededor de un artículo que nos hablaba sobre como Apple está invadiendo nuestros cuerpos. La imagen que se escogió para ilustrar dicho artículo en sus versiones digitales fue la de una muñeca humana en la que parpadeaban gráficos y números: un GIF. Su versión en papel era igual pero sin movimiento. Unos días después de esta publicación, el 29 de septiembre de 2014, la revista "New Yorker" presentó una portada animada en su página web y su aplicación móvil. La imagen constaba simplemente de un taxi neoyorquino con el Empire State de fondo y unas gotas de lluvia que se deslizaban por la pantalla.

Hoy en día por ejemplo, lectores de todas las ediciones internacionales del Huffington Post están acostumbrados a las noticias que incluyen GIFS y a su aparición en la portada. Incluso medios de comunicación más tradicionales como podría ser "The New York Times" ha trabajado con ellos.



</doc>
<doc id="1291" url="https://es.wikipedia.org/wiki?curid=1291" title="Genética">
Genética

La genética (del griego antiguo: "γενετικός", "guennetikós", ‘genetivo’, y este de "γένεσις", "guénesis", ‘origen’) es el área de estudio de la biología que busca comprender y explicar cómo se transmite la herencia biológica de generación en generación. Se trata de una de las áreas fundamentales de la biología moderna, abarcando en su interior un gran número de disciplinas propias e interdisciplinarias que se relacionan directamente con la bioquímica y la biología celular.

El principal objeto de estudio de la genética son los genes, formados por segmentos de ADN y ARN, tras la transcripción de ARN mensajero, ARN ribosómico y ARN de transferencia, los cuales se sintetizan a partir de ADN. El ADN controla la estructura y el funcionamiento de cada célula, tiene la capacidad de crear copias exactas de sí mismo tras un proceso llamado replicación.

Gregor Johann Mendel (20 de julio de 1822-6 de enero de 1884) fue un monje agustino católico y naturalista nacido en Heinzendorf, Austria (actual Hynčice, distrito Nový Jičín, República Checa) que descubrió, por medio de la experimentación de mezclas de diferentes variedades de guisantes, chícharos o arvejas ("Pisum sativum"), las llamadas Leyes de Mendel que dieron origen a la herencia genética. 

En 1941 Edward Lawrie Tatum y George Wells Beadle demostraron que los genes ARN mensajero codifican proteínas; luego en 1953 James D. Watson y Francis Crick determinaron que la estructura del ADN es una doble hélice en direcciones antiparalelas, polimerizadas en dirección 5' a 3', para el año 1977 Fred Sanger, Walter Gilbert, y Allan Maxam secuencian ADN completo del genoma del bacteriófago y en 1990 se funda el Proyecto Genoma Humano.

Aunque la genética juega con un papel muy significativo en la apariencia y el comportamiento de los organismos, es la combinación de la genética, replicación, transcripción y procesamiento (maduración del ARN) con las experiencias del organismo la que determina el resultado final.

Los genes corresponden a regiones del ADN o ARN, dos moléculas compuestas de una cadena de cuatro tipos diferentes de bases nitrogenadas (adenina, timina, citosina y guanina en ADN), en las cuales tras la transcripción (síntesis de ARN) se cambia la timina por uracilo —la secuencia de estos nucleótidos es la información genética que heredan los organismos. El ADN existe naturalmente en forma bicatenaria, es decir, en dos cadenas en que los nucleótidos de una cadena complementan los de la otra.

La secuencia de nucleótidos de un gen es traducida por las células para producir una cadena de aminoácidos, creando proteínas —el orden de los aminoácidos en una proteína corresponde con el orden de los nucleótidos del gen. Esto recibe el nombre de código genético. Los aminoácidos de una proteína determinan cómo se pliega en una forma tridimensional y responsable del funcionamiento de la proteína. Las proteínas ejecutan casi todas las funciones que las células necesitan para vivir.

El genoma es la totalidad de la información genética que posee un organismo en particular. Por lo general, al hablar de genoma en los seres eucarióticos se refiere solo al ADN contenido en el núcleo, organizado en cromosomas, pero también la mitocondria contiene genes y es llamada genoma mitocondrial.

La genética se subdivide en varias ramas, como:


La ingeniería genética es la especialidad que utiliza tecnología de la manipulación y trasferencia del ADN de unos organismos a otros, permitiendo controlar algunas de sus propiedades genéticas. Mediante la ingeniería genética se pueden potenciar y eliminar cualidades de organismos en el laboratorio ("véase Organismo genéticamente modificado"). Por ejemplo, se pueden corregir defectos genéticos (terapia génica), fabricar antibióticos en las glándulas mamarias de vacas de granja o clonar animales como la oveja Dolly.

Algunas de las formas de controlar esto es mediante transfección (lisar células y usar material genético libre), conjugación (plásmidos) y transducción (uso de fagos o virus), entre otras formas. Además se puede ver la manera de regular esta expresión genética en los organismos.

Respecto a la terapia génica, antes mencionada, hay que decir que todavía no se ha conseguido llevar a cabo un tratamiento, con éxito, en humanos para curar alguna enfermedad. Todas las investigaciones se encuentran en la fase experimental. Debido a que aún no se ha descubierto la forma de que la terapia funcione (tal vez, aplicando distintos métodos para introducir el ADN), cada vez son menos los fondos dedicados a este tipo de investigaciones. Por otro lado, aunque este es un campo que puede generar muchos beneficios económicos, este tipo de terapias son muy costosas, por lo que, en cuanto se consiga mejorar la técnica y disminuir su coste, es de suponer que las inversiones subirán.




</doc>
<doc id="1292" url="https://es.wikipedia.org/wiki?curid=1292" title="Grado Celsius">
Grado Celsius

El grado Celsius (históricamente conocido como centígrado; símbolo ℃) es la unidad termométrica cuyo 0 se ubica 0,01 grados por debajo del punto triple del agua y su intensidad calórica equivale a la del kelvin.

El grado Celsius pertenece al Sistema Internacional de Unidades, con carácter de unidad accesoria, a diferencia del kelvin, que es la unidad básica de temperatura en dicho sistema, aunque es igual a la Celsius.

Anders Celsius definió su escala en 1742 considerando las temperaturas de ebullición y de congelación del agua, asignándoles originalmente los valores 0 ℃ y 100 ℃, respectivamente (de manera que "más caliente" resultaba tener una "temperatura menor"); más tarde Jean-Pierre Christin (1743) y Carlos Linneo (1745) invirtieron ambos puntos. El método propuesto, al igual que el utilizado en 1724 para el grado Fahrenheit y el Grado Rømer de 1701, tenía la ventaja de basarse en las propiedades físicas de los materiales. William Thomson (luego Lord Kelvin) definió en 1848 su escala absoluta de temperatura en términos del grado Celsius. En la actualidad el grado Celsius se define a partir del kelvin del siguiente modo:

Los "intervalos" de temperatura expresados en ℃ y en kelvin tienen el mismo valor.

La escala Celsius es muy utilizada para expresar las temperaturas de uso cotidiano, desde la temperatura del aire a la de un sinfín de dispositivos domésticos (hornos, freidoras, agua caliente, refrigeración, etc.). También se emplea en trabajos científicos y tecnológicos, aunque en muchos casos resulta obligado el uso de la escala de Kelvin.

Las temperaturas de fusión y ebullición del agua destilada a una atmósfera de presión, en las escalas Kelvin, Celsius, Fahrenheit y Réaumur, son las siguientes:
El punto triple del agua es a 273,16 K, es decir, 0,01 ℃.

La magnitud de un grado Celsius es equivalente a la magnitud de un Kelvin; en otras palabras, una "diferencia de temperaturas" tiene el mismo valor numérico expresada en grados Celsius que en Kelvin:

La conversión de grados Celsius a grados Fahrenheit se obtiene multiplicando la temperatura en Celsius por 1,8 y sumando 32:

Para convertir Fahrenheit a Celsius:

La escala Celsius es una escala de temperatura que asigna el valor cero (0 ℃) al agua en proceso de fusión, y el valor cien (100 ℃) al agua en proceso de ebullición.

De escala Fahrenheit a escala Kelvin:
De escala Kelvin a escala Fahrenheit:

El símbolo del grado Celsius es un circulito volado (y no la letra o) seguido de la letra C, que forman un bloque indivisible. La Real Academia Española admite escribir solo el circulito volado, sin la C, pero esta notación no es conforme con las normas internacionales, en las que el círculo está reservado al grado de ángulo plano. El nombre es "grado Celsius" y, aunque la Conferencia General de Pesas y Medidas rechazó en 1948 el de "grado centígrado" (pues esta denominación se reserva para la escala de medida de ángulos), este último sigue siendo de uso corriente. No debe confundirse "centígrado", es decir, basado en una escala que da 100 grados entre la temperatura de fusión y la de ebullición del agua, con "centigrado", que es un centésimo de grado. 

Como la mayoría de los símbolos de unidades, debe haber un espacio entre el valor y ℃. Así, se tiene que 25 ℃ es "correcto", 25 ° C es "incorrecto" y 25°C es también "incorrecto".

En Unicode existe el carácter ℃ (U+2103) que representa el grado Celsius.


</doc>
<doc id="1293" url="https://es.wikipedia.org/wiki?curid=1293" title="Gouinia">
Gouinia

Gouinia, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de México a Argentina.
El género fue descrito por E.Fourn. ex Benth. & Hook.f. y publicado en "Genera Plantarum" 3: 1178. 1883. La especie tipo es: " Gouinia polygama" E. Fourn.
Gouinia: nombre genérico 
Número de la base del cromosoma, x = 10. 2n = 40 (si está disponible, pero con n cuenta de 20, 32, 38 y 40). 
A continuación se brinda un listado de las especies del género "Gouinia" aceptadas hasta mayo de 2015, ordenadas alfabéticamente. Para cada una se indica el nombre binomial seguido del autor, abreviado según las convenciones y usos. 





</doc>
<doc id="1294" url="https://es.wikipedia.org/wiki?curid=1294" title="Gouldochloa curvifolia">
Gouldochloa curvifolia

Gouldochloa, es un género monotípico de plantas herbáceas perteneciente a la familia de las poáceas. Su única especie: Gouldochloa curvifolia Valdés-Reyna, Morden et S.L.Hatch, es originaria de México.

Algunos editores lo incluyen en el género "Chasmanthium".
El género fue nombrado en honor de Frank Walton Gould (agrostólogo estadounidense), y el término griego "chloa" (hierba).

Número de la base del cromosoma, x = 12. 2n = 24. 2 ploid. 



</doc>
<doc id="1295" url="https://es.wikipedia.org/wiki?curid=1295" title="Graphephorum">
Graphephorum

Graphephorum, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Norteamérica y el Caribe.

Algunos editores lo incluyen en el género "Trisetum".



</doc>
<doc id="1296" url="https://es.wikipedia.org/wiki?curid=1296" title="Guadua">
Guadua

Las cañazas o tacuaras ("Guadua" spp.) son un género de plantas de la subfamilia del bambú, de la familia de las poáceas.

En el año de 1806 fue descrita por Alexander von Humboldt y Amadeo Bonpland quienes vieron esta planta en Colombia y la llamaron "Bambusa guadua", luego en 1822 fue clasificada por Carl Sigismund Kunth como "Guadua angustifolia". Se considera como una de las plantas nativas más representativas de los bosques andinos.

Este recurso se utilizaba ya desde épocas remotas por parte de los primitivos pobladores de los Andes, y actualmente sigue siendo usada, especialmente en la región centro-occidental de Colombia. 

No se sabe a ciencia cierta el origen de la palabra guadua, aunque ciertos especialistas creen que podría ser venezolano. Estas versiones emergen de las variantes “guadúas”, “guafa” con las cuales se conoce esta planta en este país. Y también se suele emplar el término "guasdua" como nos recuerda la ciudad de Guasdualito, en Venezuela.

Desde las zonas tropicales de México hasta el sur en la Argentina, exceptuando Chile y las islas del Caribe, la guadua crece en todos los países de Iberoamérica y en buena parte de los países asiáticos. En Argentina el género "Guadua" se ve representado por "G. chacoensis", "G. trinii", "G. ramossisima" y "G. paraguayensis". El término tacuara se usa en el Río de la Plata para nombrar cañas de origen asiático, como "Phyllostachys aurea".

Su uso es tan antiguo que, según el libro ‘Nuevas técnicas de construcción en bambú’ (1978), en el Ecuador se han encontrado improntas de bambú en construcciones que se estima tienen 9500 años de antigüedad.

Puentes colgantes y atirantados de impresionante precisión de ingeniería, poderosas embarcaciones así como flautas, quenas y marimbas, fueron realizados por los incas con este recurso durante la época de preconquista, y después de ella durante la colonia, la especie fue la encargada de proteger a los indios y hasta pequeños pueblos del asedio de los españoles escondiéndolos tras sus espesuras.

Colombia, Ecuador y Panamá son los países de América que registran mayor tradición de uso, de hecho en estas zonas existieron las mayores extensiones de la especie en el continente.

En Colombia la guadua ha sido sometida a grandes presiones deforestadoras; de extensas áreas existentes ha pasado a pequeñas manchas boscosas ubicadas en las orillas de los ríos y en los bosques húmedos de las laderas de montaña, especialmente en los departamentos de Quindío, Risaralda, Caldas, Tolima, Valle del Cauca, Cundinamarca y Santander.La guadua es una planta de la familia del bambú, que aporta grandes beneficios a la tierra y a las personas, pues con ella se puede construir casi todos los elementos de una casa. Es de muy rápido desarrollo, toma de 4 a 6 años para madurar y comienza su proceso de descomposición aproximadamente a los 10 años.

En la conquista española y, mucho después, la colonización antioqueña al viejo Caldas, la guadua fue un importante material empleado en la construcción de sus casas, de los utensilios caseros, herramientas de caza, ganadería y agricultura y hasta los acueductos.

El aprovechamiento es una práctica silvicultural de mantenimiento y mejoramiento del guadual. Puede definirse como una práctica silvicultural que procura crear condiciones favorables en el guadual, lo que implica el mejoramiento de la regeneración natural y de la composición estructural, que aseguran el máximo rendimiento sostenible. El aprovechamiento no solo pretende obtener los máximos ingresos posibles del recurso. 

En los bosques de guadua, el proceso de sucesión, se puede considerar como progresivo cuando su manejo muestra el guadual en equilibrio biológico, contrario cuando se produce alguna alteración o deterioro en su estructura, producto de una intervención natural o artificial caso en el cual se considera que el guadual comienza a presentar una sucesión regresiva, lo cual puede ocasionar su completa desaparición. 

Para evitar lo anterior es necesario conocer y diferenciar todos y cada uno de los elementos que conforman el guadual. Su conocimiento permite aprovechamientos técnicos, además de conocer su dinámica dentro del proceso de productividad del guadual. 

Entre las causas que ocasionan la llamada sucesión regresiva del guadual está el no manejo, ya que si los guaduales no se aprovechan tienden a degradarse por exceso de individuos en determinado momento y/o por disminución de la actividad biológica o dinámica del guadual. 

Por lo expuesto anteriormente los guaduales deben intervenirse periódicamente para regular el espacio vital de sus individuos y para favorecer una mayor aparición de rebrotes o renuevos. En Colombia, se han realizado investigaciones sobre aprovechamientos técnicos debido a que la gran mayoría de bosques se encuentran muy densos por falta de manejo, o muy intervenidos por una explotación antitécnica. 

Es necesario determinar para cada sitio, el ciclo de corte o periodo de corte a transcurrir entre un aprovechamiento y otro, y la intensidad de corte, o sea la cantidad y clase de individuos a extraer en cada ocasión, siendo esto lo que constituye propiamente el Plan de manejo técnico de un guadual. 

Con el aprovechamiento técnico se busca obtener un equilibrio en el bosque, en el ambiente y que a través de él, se obtengan ingresos según el manejo sostenible del recurso. 

Los planes de manejo se basan casi exclusivamente en el número de guaduas adultas o “hechas” que reporte el inventario de existencia, es decir, la importancia del rodal se limita al número de guaduas aprovechables. 

Los aprovechamientos comerciales se basan principalmente en el sistema de entresaca determinando la cantidad de tallos en porcentajes de acuerdo al estado de cada guadual y la edad de corte, planteándose como la ideal, cuando la guadua cambia de color, pues se pasa de verde a amarillo, siendo invadida por líquenes que le dan la tonalidad ceniza, blancuzca o “rucia”, produciéndose esta coloración aproximadamente a los 5 o 6 años de edad del tallo. 

Para conocer el aprovechamiento, es necesario conocer una serie de conceptos técnicos que ayudaran a hacer aprovechamientos más racionales. 

Es el tiempo transcurrido desde la aparición del rebrote continuando con todas sus fases vegetativas hasta la inactividad total de la planta o fase de secamiento del tallo.

Es el tiempo transcurrido desde la aparición del rebrote hasta el momento en que es aprovechado como guadua. 

Es el tiempo que permanece la guadua en determinada fase vegetativa, antes de pasar a una fase inmediatamente superior. 

Los aprovechamientos técnicos se basan en la extracción de un porcentaje determinado de guaduas maduras o "hechas" únicamente, lo que implica conocer muy bien las fases de desarrollo de un guadual, fácilmente distinguibles a nivel de campo, a saber: 





Es el tiempo transcurrido entre dos aprovechamientos sucesivos sobre un mismo bosque. Este depende de la posibilidad del guadual. Lo primordial para el corte de una guadua es tener en cuenta los cambios de luna por eso es recomendable cortarla en luna menguante ya que esta ejerce presión sobre el agua llevándola hasta su raíz y así esta la guadua en mejor condición para su aprovechamiento. También debemos tener en cuenta las manchitas blancas que les aparecen desde arriba hasta abajo.

Es el volumen o número de guaduas que se pueden aprovechar en un periodo determinado buscándose asegurar el máximo rendimiento sostenible. La posibilidad depende del producto deseado, de la composición estructural, de la dinámica en la regeneración natural, del turno, del tiempo de pausa y del área a aprovechar. 

El plan de manejo técnico lo constituyen el ciclo de corte, la intensidad de corte y las técnicas de aprovechamiento.

Para la extracción de cualquier cantidad de tallos de un guadual, es indispensable obtener la licencia de aprovechamiento y tener en cuenta que los aprovechamientos deben estar supervisados por profesionales competentes. 

Una vez conocidas las fases de desarrollo del guadual se procede a realizar muestreos, donde se contabiliza el número de individuos (tallos) por cada fase de desarrollo. Esta labor se efectúa a través de parcelas de muestreo de 10 m x 10 m x 10 m en cuadro. 

El número de tallos a entresacar está sujeto a estudios técnicos que determinen la intensidad o índice de corte. 

El aprovechamiento de los tallos debe estar dirigido a los maduros, pero dentro de esta fase se deben seleccionar los más avanzados, analizando las características ya mencionadas.

Conociendo el número de guaduas maduras o "hechas" por hectárea, se puede extraer un porcentaje de este tipo de guaduas. El índice de aprovechamiento generalmente es del 35% de guaduas maduras. Aprovechamientos mayores implican desbalances fisiológicos del guadual y susceptibilidad a volcamientos de rebrotes y guaduas jóvenes ocasionados por borrascas, vientos fuertes, vendavales y tempestades. 

La entresaca debe hacerse uniformemente en toda el área del guadual y los cortes de los tallos deben realizarse a la altura del primer o segundo nudo y a ras. Se deben evitar los cortes que dejan una concavidad o "pocillo", la cual favorece depósitos de agua que ocasionan pudriciones de la planta. 

Se deben cortar todos los tallos enfermos, secos en pie o secos partidos. La copa con sus ramas y demás partes no utilizables de la guadua se deben repicar y esparcir uniformemente dentro del guadual, pues su descomposición genera materia orgánica. Cuando la intervención se hace cerca de corrientes o depósitos de agua, debe evitarse arrojar desechos que obstaculicen su libre curso. 

El corte de los tallos al amanecer entre las 3.00 y las 5.00, implica obtenerlos con menor contenido de humedad y menores concentraciones de carbohidratos, por lo tanto más resistentes a los ataques de insectos y hongos. Todos los tallos cortados, se deben dejar dentro del guadual en posición vertical aproximadamente de 20 a 30 días, luego se secan preferiblemente a la sombra. 

Los cortes de los tallos se deben hacer a ras del primero o segundo nudo evitando espacios huecos en el tocón que favorezcan depósitos de agua y consecuente pudrición del rizoma.

Desde hace siglos la guadua ha sido utilizada tradicionalmente como material de construcción, y ahora, debido a la corriente actual de búsqueda de materiales para el desarrollo sostenible, esta planta ha ganado un espacio en la construcción. Desde viviendas de zonas rurales rurales construidas con bahareque en las cuales la armazón se construye con cañas de guadua, hasta para exportación en proyectos desarrollados en países donde no está planta no existe. También se han construido casas con técnicas mixtas.





</doc>
<doc id="1297" url="https://es.wikipedia.org/wiki?curid=1297" title="Gymnopogon">
Gymnopogon

Gymnopogon, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de América.
Son plantas perennes o anuales, cespitosas o rizomatosas. Con tallos simples o esparcidamente ramificados. Hojas principalmente caulinares, conspicuamente dísticas; la lígula una membrana ciliolada; láminas linear-lanceoladas, aplanadas, sin nervadura media, generalmente rígidamente patentes, la base subcordata o truncada con un seudopecíolo corto. Inflorescencia una panícula de varios racimos espiciformes, delgados, erectos o patentes; raquis triquetro, las espiguillas subsésiles, unilaterales, alternando en 2 hileras sobre 2 lados del raquis y paralelas a este. Espiguillas comprimidas lateralmente, con 1 flósculo bisexual y 1(2) flósculos estériles, el último flósculo reducido a un cuerpo delgado en forma de arista; desarticulación arriba de las glumas; glumas más largas que el flósculo, angostas, acuminadas, 1-nervias, carinadas; lema 3-nervia, diminutamente 2-fida, generalmente aristada abajo de la punta; pálea tan larga como la lema, 2-carinada; raquilla generalmente con un rudimento terminal delgado; lodículas 2; estambres 3; estigmas 2. Fruto una cariopsis; embrión 1/4-1/3 la longitud de la cariopsis; hilo punteado.
El género fue descrito por P.Beauv. y publicado en "Essai d'une Nouvelle Agrostographie" 41, 164. 1812. La especie tipo es: "Gymnopogon ambiguus" 
El nombre del género deriva de las palabras griegas "gumnos" = (desnudo) y "pogon" = (barba), aludiendo a una extensión de raquilla desnudo. 
Número básico del cromosoma, x = 10.

A continuación se brinda un listado de las especies del género "Gymnopogon" aceptadas hasta mayo de 2015, ordenadas alfabéticamente. Para cada una se indica el nombre binomial seguido del autor, abreviado según las convenciones y usos. 




</doc>
<doc id="1299" url="https://es.wikipedia.org/wiki?curid=1299" title="Gynerium">
Gynerium

Gynerium, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de México y América subtropical.
El nombre del género deriva de las palabras griegas "gune" (hembra) y "erion" (lana), refiriéndose a la espiguillas pistiladas. 
Número de la base del cromosoma, 2n = 72 y 76. 



</doc>
<doc id="1300" url="https://es.wikipedia.org/wiki?curid=1300" title="Güímar">
Güímar

Güímar es un municipio perteneciente a la provincia de Santa Cruz de Tenerife, en la isla de Tenerife —Canarias, España—.

La capital municipal se ubica en la Ciudad de Güímar, situada a 278 msnm

El municipio toma su nombre de su capital, que a su vez lo hace del antiguo reino guanche. Algunos autores traducen el término por 'ángulo, esquina, rincón'.

El escudo fue aprobado por el Ministerio de Gobernación el 2 de febrero de 1928.

En su parte central, en franja oblicua, en fondo de plata, dos personajes entrelazan sus brazos simbolizando «la paz sin sangre». Uno de los brazos, desnudo, representa a Añaterve "el Bueno" y su reino, el otro armado y desprovisto de guantelete a Alonso Fernández de Lugo y los suyos. A ambos lados los atributos de uno y otro: la isla de Tenerife, con el Teide en erupción, emergiendo de las aguas marinas, y el castillo y el león rampante, atributos éstos de los reinos que llevaron a cabo la conquista. Rodea esta escena central una bordura de sinople con ocho rejas de arado que representan «el trabajo agrícola» y en la cúspide, presidiendo el timbre del escudo, la corona de los Reyes Católicos.

El municipio cuenta con pendón heráldico, aprobado por la Corporación Municipal en mayo de 1966. El pendón es de color blanco con el escudo al centro.

Se extiende por el sector este de la isla, limitando con los municipios de Arafo, La Orotava y Fasnia. El límite sur es el barranco de Herques, que sirve de frontera con el municipio de Fasnia; la divisoria con el municipio de Arafo, al norte, está constituida por la aproximación a la mediana de la corriente de lava producida por la erupción volcánica de 1706, una de las erupciones históricas de Tenerife, que discurre de la cumbre dorsal de la isla al mar, aunque en este caso la trayectoria no llegó al mismo, sino que finalizó a unos trescientos metros de la costa. El lado oeste del municipio lo constituye la cordillera dorsal de la isla, cuyo máxima elevación es Izaña, importante centro de astronomía, y uno de los más antiguos observatorios meteorológicos de España.

Güímar está situado en un valle o depresión que, de acuerdo con la mayoría de los geólogos, es producto de un derrumbe de material volcánico al mar.

El municipio tiene dos partes bien diferenciadas cuya separación física es la Ladera de Güímar, precisamente el límite del derrumbe marino; estas dos partes son el propio Valle de Güímar y la Comarca de Agache.

El Valle de Güímar es un valle creado por desplazamiento de una enorme masa de materia volcánica que cae el mar, sumergiéndose a profundidades de dos mil metros. Aunque esta teoría geológica tiene muchos detractores, la hipótesis supone que tras la construcción de un edificio volcánico desde las profundidades del océano (tres mil metros), el sistema colapsa y se produce un desprendimiento que forma un valle. Sería el mismo proceso que el alud de nieve producido en las altas montañas; el peso hace que el sistema se desmorone por uno de sus lados hacia terrenos de menor cota. Tras el desprendimiento, el valle comenzó a ser rellenado por el producto de la erosión de las cumbres formándose el mayor cono de deyección sedimentario de Canarias. En la zona costera del valle se distingue perfectamente la erupción volcánica que conforma el Malpaís de Güímar, una Reserva Natural Especial formada por un gran cono volcánico y el campo de lavas asociado, que discurre en forma de abanico hasta el mar. La formación se completa con una línea de arrastre de arenas procedentes de las playas del Socorro por efecto de los constantes vientos alisios. La vegetación del malpaís está adaptada a la escasez de precipitación y a una elevada insolación, estando presentes grandes extensiones de tabaiba y cardón.

La costa es muy escarpada, producto de la erosión del mar en las sucesivas corriente lávicas que han ido llegando al océano: esta tónica sólo se rompe en la desembocadura de los grandes barrancos, sitios en los que la costa está formada por el amontonamiento de los cantos rodados que el agua de los barrancos ha trasladado desde las cumbres de la isla; las costas pedregosas son los Callaos del Socorro y los de la Bajas. En menor medida existen callaos en la desembocadura del barranco de Herques y en otros barrancos menores. 
Güímar está surcada por profundos barrancos cuyos cauces penetran en la profundidad de la isla dejando ver sus tempranas formaciones geológicas; en su interior, a la vera de sus desfiladeros, se excavan galerías que nutren de agua a la población para su consumo y el de la agricultura. Los principales barrancos son el de Herques, el de El Escobonal, el de Badajoz o de Chamoco, el del Agua o del Río y el de la Fajana o la Hoya.

Cuando los castellanos conquistaron Tenerife en 1496, los más importantes barrancos de Güímar tenían agua en sus cauces; estas escorrentías duraron hasta el final del siglo , años en las que se secaron por efecto de las erupciones volcánicas. La última erupción de Güímar ocurrió en el año 1705. La lava se derramó siguiendo el barranco de Arafo, desde la caldera de Pedro Gil hasta las proximidades del mar.

Posee clima subtropical, templado y árido. Su clima depende mucho de la altitud, siendo más árido en la costa y más húmedo en torno a los 700 ó 900 metros.

El barranco de Badajoz alberga manifestaciones de pinar natural, así como algunos reductos de laurisilva; asimismo cuenta con una importante muestra de retamar en Izaña, en la parte alta, dentro del llamado preparque del Teide.

La costa se encuentra recorrida de sur a norte por una grieta volcánica subterránea que ha dado al litoral (al igual que el resto de la costa sur de la isla) una morfología constituida por erupciones volcánicas que han producido importantes edificios volcánicos por acumulación de lapilli (roca conocida en Canarias por picón). La alineación volcánica ha creado montañas como la de Abeñamo, Pino de don Tomás, Montaña Colorada, Montaña de las Dos Tetas, Montaña de los Guirres, Montaña de la Mar y la Montaña Grande o Montaña del Socorro, que se eleva trescientos metros sobre el terreno circundante y tiene en su interior un cráter inactivo.

Una capa de toba volcánica (zahorra y material puzolánico) procedente de la gran erupción del tipo nube ardiente de Granadilla, está presente en toda la franja costera, sobre todo en los obstáculos que la nube ardiente encontró en su camino hacia Anaga; esta nube ardiente es importante no sólo en sí misma por constituir un ejemplo muy escaso en el mundo, sino porque modela y retoca todo el paisaje del sur de Tenerife, hasta tal punto que el sesenta por ciento que se contempla desde el espacio está marcado por la puzolana, observándose como una amplia extensión blanquecina. De acuerdo con las dinámicas térmicas del interior de la nube ardiente, los materiales se depositan en el suelo a diferentes niveles o altitudes: los más ligeros, llamados zahorras, se depositan a grandes altitudes; en Güímar se encuentran en Sosa, en los Altos de El Escobonal y de Agache y en la orilla del Monte en el Valle; en la zona media hay puzolanas más sólidas (llamadas toscas o toscones) que en algunos casos los primeros habitantes usaron para levantar paredes por su relativa dureza y por la facilidad para trabajarlos; en la costa se encuentran las puzolanas plenamente compactadas, son los llamados bloques de cantera que se siguen usando en la construcción por su dureza media y sobre todo por su vistosidad y facilidad para el cincelado. En la cumbre de Izaña también existen importantes aglomeraciones de lapilli o picón que redondean el paisaje.

El municipio cuenta con varios espacios naturales protegidos que recogen los distintos hábitats, referidos a la alta montaña, las medianías y la zona costera. Así, posee superficie del parque nacional del Teide, del parque natural de la Corona Forestal, del paisaje protegido de Siete Lomas y del monumento natural del Barranco de Fasnia y Güímar. Íntegramente incluido en su término se encuentra la reserva natural especial del Malpaís de Güímar.

Todos estos espacios protegidos están además incluidos en la Red Natura 2000 como Zonas de Especial Conservación, mientras que las superficies del parque nacional y del parque natural son también Zona de Especial Protección para las Aves.

El municipio cuenta asimismo con los montes de utilidad pública denominados Agache y Escobonal y Cumbres de Güímar.
El Parque Natural de la Corona Forestal es el mayor espacio protegido del archipiélago canario, situado en el centro de la isla de Tenerife y entorno al Parque nacional del Teide. Entre la Corona Forestal y el Parque nacional se ha creado un área de preparque que afecta al municipio de Güímar. Los lugares geográficos correspondientes al municipio de Güímar en la Corona forestal son: Corral del Niño, Llano de los Infantes, Izaña, Montaña del Cobre, Peta Podón, Mal Abrigo, El Peñón, el Lomo del Caballo, Los Dornajos y Cho Marcial. El Parque de la Corona Forestal incluye numerosas cabeceras de barrancos, algunas muy encajadas en la isla como el Barranco de Badajoz.

La Corona Forestal incluye el llamado Pico de Cho Marcial, escarpe que configura el paisaje de la zona alta del valle de Güímar, a su lado se encuentra la Caldera de Pedro Gil, donde tuvo lugar la erupción histórica de 1705. En la zona baja de la Corona Forestal se encuentran numerosas galerías de las que se extrae agua del interior de la isla. También se encuentran fuentes como la de Mal Abrigo, cerca de Izaña y Los Dornajos en los altos de Las Dehesas. En la zona baja de la Corona Forestal se encuentran las dos zona vitivinícolas más importantes de Güímar, las Dehesas y Los Pelados. La Corona Forestal está recorrida por varias pistas forestales, la más importante nace en el Mirador de don Martín, en la carretera General del Sur, y tras ascender bordeando la Ladera de Güímar se divide en dos ramales en la llamada Montaña del Cobre, uno sigue la ascensión hasta el Lomo de Izaña y otro se dirige hacia el norte, prácticamente en horizontal, hasta la altura del Lomo de Benito, para luego ascender hasta Malabrigo y el Peñón. En la zona de Malabrigo, junto a la fuente, existe un refugio de montaña, construido en su día por el Ayuntamiento, se trata del archete de Cayetano, junto a la Fuente de mal Abrigo; al lado de esta fuente también podemos encontrar dos cuevas excavadas en picón. La vereda más importante de esta zona nace en Güímar de Arriba y tras ascender entre los barrancos de Badajoz y El Río llega al Rinconcito, parte baja de la Montaña del Cobre, desde allí se dirige a la Fuente de Mal Abrigo para continuar hacia el Valle de la Orotava, justo en el Peñón. En la zona del Peñón, y en la de Montaña del Cobre, hay un desarrollo importante de la apicultura durante el verano, por la gran cantidad de retama que hay en la zona. En la actualidad las más viejas familias de abejeros de Güímar siguen llevando sus colmenas al lugar todos los años. En la Corona Forestal hubo a principios y mediados del siglo una importante actividad pastoril.

El territorio que constituye el moderno término municipal se integraba en el reino o "menceyato" de Güímar.

Según las crónicas, en un comienzo la isla de Tenerife constituyó una sola unidad política o reino hasta que se dividió en nueve. De entre ellos, los más importantes eran el de Taoro, que aglutinaba los reinos del norte, y el de Güímar, que hacía lo mismo con los del sur y que tenía una extensión mayor de la que posee el término municipal.

La economía se basaba en la ganadería —cabras, ovejas, cerdos— y en la agricultura y explotación de recursos marinos y forestales.

La importancia que alcanzó el reino güimarero se refleja en los numerosos vestigios encontrados: barranco de Herques, cuevas de habitación naturales y artificiales, la cueva de Chinguaro donde estuvo la imagen de la Virgen de la Candelaria, la cueva de El Cañizo en el barranco de Badajoz, refugios pastoriles, concheros, etc.

De entre todos, el "menceyato" de Güímar fue el que había recibido una mayor actividad evangelizadora previa a la conquista. En este contexto hay que analizar la repercusión histórica del hallazgo por los guanches de la imagen de la Virgen de Candelaria en las costas de Chimisay. La imagen fue llevada a la cueva-palacio del "mencey" de Güímar, donde se la veneró durante cincuenta años, convirtiéndose así en el primer santuario mariano de la isla.

Tras 1496, finalizadas las operaciones militares de conquista de la isla, los guanches se fueron integrando en el nuevo tejido social. Fueron muy pocos los guanches que en Güímar obtuvieron la propiedad de algún trozo de tierra o data cuando el nuevo gobernador procedió al reparto de lo que fue su antiguo territorio, por eso muchos siguieron viviendo en cuevas en lugares como Guaza de tal forma que llegaron a mantener su identidad hasta el siglo debido a su aislamiento.
El primer núcleo de población de Güímar se originó en el siglo en el barrio de San Juan -también llamado Güímar de Arriba- en las proximidades de los manantiales de los barrancos del Agua y de Chamoco. Las primeras edificaciones estuvieron vinculadas al ingenio azucarero puesto en marcha por los hermanos Juan Felipe y Blasino Piombino o Romano.

La producción de la comarca se centraba en la ganadería, caña de azúcar, cultivo de cereales, viña, producción de miel, etc.

A través de un proceso progresivo de concentración de tierras, en el que desaparecen muchos de los primeros pobladores que reciben datas, la hacienda de las Vargas se va convirtiendo en una inmensa propiedad. A mediado del siglo , cuando es adquirida por Pedro Alarcón, tenía una extensión mayor que la del moderno municipio de Güímar y además del ingenio y los cañaverales, contaba con muchas huertas de viña, frutales, tierras de secano, casas, dependencias, etc.

El Valle de Güímar comenzará a desempeñar un papel abastecedor de productos de primera necesidad para otras zonas de la isla, entre las que irá destacándose, sobre todo en el siglo , una población en expansión como el Puerto de la Cruz. Pese a los estragos de la erupción volcánica de 1705, que arrasó un importante volumen de tierras dedicadas al cultivo de cereales, los agricultores de Güímar aunaron esfuerzos para salir juntos del problema creando nuevas modalidades de cultivo y favoreciendo un crecimiento económico y poblacional importante que desmarcará a Güímar del estancamiento.

En el siglo la crisis de la economía azucarera motivó a los grandes propietarios de las tierras de Güímar a ir cediendo tierras a los campesinos bajo diferentes fórmulas. De esta manera fue creciendo la población del núcleo original, desplazándose en dirección a la costa. Este desplazamiento viene marcado por la fundación de una pequeña ermita junto a un depósito de agua, conocida como San Pedro del Tanque, y que posteriormente dará lugar al templo moderno. Así, a lo largo de esta centuria se va consolidando el núcleo central de la villa, vertebrada en torno a la plaza de San Pedro y a las calles de San Pedro Arriba y San Pedro Abajo.

En el tiene lugar un significativo crecimiento demográfico del pueblo, que está relacionado con una época de expansión agrícola basada en la agricultura de autoconsumo o de mercado interno y en la producción del vino -falso Madeira- para la exportación. Es en estos años cuando se consolidan los barrios de San Pedro Arriba y San Pedro Abajo. Se produce también en este siglo la segregación de los pagos de Fasnia, que pasarán a formar parte de Arico. La población del área de Agache también evoluciona en este siglo de manera ascendente por lo que surge en 1745 la primitiva ermita de El Escobonal.

En el siglo la localidad de Güímar presentaba ya una estructura urbana consolidada, cuyo centro estaba compuesto por un eje que unía la plaza de San Pedro y el convento dominico. En 1838, tras la Desamortización de Mendizábal, este convento pasó a convertirse en el centro sociopolítico de la localidad, al ubicarse en él las dependencias del ayuntamiento, las escuelas públicas y el juzgado. En 1854 surgió la primera plaza pública de la localidad, frente a la ermita de San Pedro Abajo.

En 1858 se produjo el intento fallido de los pueblos de Agache de segregarse del municipio de Güímar para convertirse en municipio independiente. En 1911 la localidad de El Escobonal volvería a optar por la segregación, en esta ocasión apuntando a la unión con el municipio de Fasnia.

El hito que corona el crecimiento demográfico y urbanístico de la localidad es la concesión del título de Villa, que tuvo lugar el 28 de junio de 1900.

A comienzos del , el núcleo urbano de Güímar estaba conformado fundamentalmente por las calles: El Rincón, Plaza de San Pedro, Tafetana, Santo Domingo, Carretera Vieja, etc. En la primera mitad de este siglo se va configurando una nueva vía que adquirirá gran relevancia urbanística, la formada por las avenidas de Santa Cruz y de Pérez Cáceres, anteriormente Carretera General del Sur, en donde se construyeron fondas, cines, etc. También surge la plaza de las Flores.
En la segunda mitad del siglo Güímar comienza a crecer en dirección al pueblo vecino de Arafo. En las estériles tierras que asoló el volcán de las Arenas se va estableciendo, primero en cuevas de archete y luego en casas de autoconstrucción o urbanizaciones, el barrio más populoso del municipio: Fátima, que surge con vitalidad en 1945 cuando el alcalde Antonio Gómez Ramos reparte solares de trescientos metros cuadrados, con la intención de construir viviendas según los planos elaborados por el aparejador güimarero Felipe Padrón Sanabria. En 1981 el Ayuntamiento y su alcalde, Pedro Guerra Cabrera, atendiendo a los problemas que le surgían a los vecinos en cuanto a la propiedad de los terrenos, los cede definitivamente a estos.

El crecimiento urbanístico de Güímar, en la segunda mitad del siglo , encuentra su hito en la concesión en 1961 del título de Ciudad y el trato de "Excelentísima" a su Corporación, otorgado por el Gobierno estatal.

A partir de los años 70 destaca el surgimiento del Puertito de Güímar como núcleo de segunda residencia en lo que era una zona de pescadores y junto a unas barriadas y que hoy es un núcleo en importante expansión de primera residencia y dotándose poco a poco de los servicios necesarios.

El municipio de Güímar cuenta con dos notarías demarcadas (la segunda desde 2008) y un registro de la propiedad, que abarca también el municipio de Arafo (creado desde 2007 pero abierto físicamente en Güímar desde febrero de 2009). Cabeza de partido judicial desde 1989, Güímar posee un Palacio de Justicia con capacidad para cuatro juzgados, si bien sólo existen tres en activo.

A 1 de enero de 2013 Güímar tenía un total de 18.589 habitantes, ocupando el 13. puesto en número de habitantes de la isla de Tenerife y el 14º de la provincia de Santa Cruz de Tenerife. 

La población relativa era de 181,55 hab./km².

Por edades existía un 68% de personas entre 15 y 64 años, un 17% mayor de 65 años y un 15% de entre 0 y 14 años. Por sexos contaba con 9.217 hombres y 9.372 mujeres. En cuanto al lugar de nacimiento, el 86% de los habitantes del municipio eran nacidos en Canarias, de los cuales el 62% ha nacido en el mismo municipio, el 33% en otro municipio de la isla y el 5% en otra isla del Archipiélago. El resto de la población la componía un 10% de nacidos en el Extranjero y un 4% procedentes del resto de España. De los nacidos en el Extranjero, el 70% proceden de países americanos, mientras que un 25% es originario de Europa.

El municipio se encuentra regido por su Ayuntamiento, compuesto por 17 concejales.


</doc>
<doc id="1302" url="https://es.wikipedia.org/wiki?curid=1302" title="Gramática">
Gramática

La gramática es el estudio de las reglas y principios que gobiernan el uso de las lenguas y la organización de las palabras dentro de unas oraciones y otro tipo de constituyentes sintácticos. También se denomina así al conjunto de reglas y principios que gobiernan el uso de una lengua concreta determinada; así, cada lengua tiene su propia gramática.

La gramática es parte del estudio general del lenguaje denominado lingüística. Clásicamente, el estudio de la lengua se divide en cuatro niveles:

A veces se restringe el uso del término gramática a las reglas y principios que definen el segundo de estos niveles. Sin embargo, la separación de los niveles no es totalmente nítida porque ciertas reglas gramaticales se realizan en el nivel fonético-fonológico e igualmente existen parámetros o criterios semánticos que sirven para decidir cuándo una determinada construcción es gramatical.

El término "gramática" deriva del latín "grammatĭca", y este del vocablo griego γραμματικῆ [τέχνη] ("grammatikḗ tékhne"), donde "tékhne" significaba «arte» o «técnica» y "grammatikḗ", derivado de γράμμα ("grámma", «letra»), significaba «de las letras». Para los griegos antiguos, este «arte de las letras» abarcaba todos los aspectos del discurso: ortografía, sintaxis, interpretación de los textos e incluso la crítica literaria; es decir, englobaba buena parte de lo que hoy diferenciamos como filología, como gramática y como retórica.

Fue Dionisio de Tracia, en su "Tékhne Grammatiké" (siglo I a. C.), el que estableció una terminología que heredarían las gramáticas occidentales posteriores, a partir de las latinas. Los romanos antiguos, con Elio Donato a la cabeza, crearon el término "litteratura" (de "littera", «letra») que reservaron para la parte histórica e interpretativa, mientras que conservaron el helenismo "grammatica" para el conjunto de normas y reglas.

Entre los principales tipos de gramática o enfoques en el estudio de la gramática se encuentran los siguientes:

La teoría gramatical ha evolucionado a través del uso y la división de las poblaciones humanas y las reglas sobre el uso del lenguaje tendieron a aparecer con el advenimiento de la escritura. La gramática más antigua que se conoce es el "Astadhiaia", un estudio sobre el sánscrito, escrito por Pánini, en la Antigua India, hacia el año 480 a. C.
Aunque Sócrates, Aristóteles y otros sabios de la antigüedad disertaron sobre la gramática, el primer tratado completo de gramática griega fue el que compuso Crates de Malos (siglo II a. C.). Por otra parte la "Ars Grammatica" de Elio Donato (s. IV) dominó los estudios gramaticales durante la Edad Media.

Antonio de Nebrija en 1492 compuso la primera Gramática castellana, primera también entre las gramáticas románicas, a las que servirá de modelo. La Gramática fue redactada en la localidad extremeña de Zalamea de la Serena

La gramática formal es una codificación del uso desarrollada basándose en la observación. Al establecerse y desarrollarse las reglas, pudo aparecer el concepto prescriptivo, que a menudo creó una brecha entre el uso contemporáneo y lo aceptado como correcto. Los lingüistas consideran normalmente que la gramática prescriptiva no tiene justificación alguna más allá del gusto estético de sus autores. De cualquier forma, las prescripciones permiten a la sociolingüística explicar las razones por las que un determinado grupo social utiliza construcciones diferenciales.

El estudio formal de la gramática es una parte importante de la educación desde la edad temprana hasta el aprendizaje avanzado, aunque las reglas que se enseñan en las escuelas no constituyen una gramática en el sentido en que los lingüistas utilizan el término, ya que son prescriptivas antes que descriptivas.

Los lenguajes construidos son muy comunes en la actualidad. Muchos —como el esperanto— fueron diseñados para ayudar en la comunicación humana, o el lojban, altamente compatible con lenguajes artificiales. También se han creado lenguajes como parte de un mundo de ficción (como el klingon y el quenya), y cada uno de ellos tiene su propia gramática.




</doc>
<doc id="1310" url="https://es.wikipedia.org/wiki?curid=1310" title="Gules">
Gules

En heráldica, gules (usado siempre en plural) es la denominación del color rojo vivo. De entre los esmaltes heráldicos, pertenece al grupo de los colores, junto con el azur (azul), el sable (negro), el sinople (verde) y el púrpura.

Este esmalte también ha sido llamado gola, goles, güella, rosicler, color sangre, y sanguino o sanguíneo (por influencia del esmalte inglés "sanguine", de color rojo oscuro).

El término «gules» proviene del francés antiguo "goules", ‘cuello de piel [roja]’, plural de "gole", "guele", ‘garganta’, del latín "gula", ‘garganta’. El filólogo Joan Corominas atribuye el nombre de este esmalte heráldico a la costumbre de adornar los cuellos de los mantos con trozos de piel de la garganta de la marta, teñidos de rojo. Ciertamente algunas canciones de gesta medievales describen este tipo de prendas: el "Roman de Raoul de Cambrai" (siglo X), por ejemplo, habla de «gules de marta», y el "Aye d’Avignon", de gules de armiño; mientras que un texto en latín, al describir una prenda de armiño, reza "circa collem et circa manus rubris gulis præparatam" (‘preparada en torno del cuello y de las muñecas con tiras rojas de piel’).

Históricamente se propusieron otras etimologías. Una de ellas sugería que «gules» podía provenir del francés "gueules", ‘fauces’, debido al color rojo del interior de la boca de las fieras cuando devoran a su presa; otra proponía que se originaba en términos similares de diversas lenguas de Oriente Medio y de Asia (árabe, persa, turco, hebreo), como "gul", "ghiul" o "gulude", que designarían directa o indirectamente al color rojo.

La adopción del término «gules» en heráldica está ligada al desarrollo histórico de esta disciplina. El lenguaje del blasón, que permite describir armerías adecuadamente (blasonar), comenzó a desarrollarse en el siglo XII. De esa etapa formativa de la heráldica se conservan, en romances franceses, descripciones de escudos donde el gules es llamado simplemente "vermeil" (‘bermejo’) o "rouge" (‘rojo’).
Hacia mediados del siglo XIII, sin embargo, los armoriales comienzan a tipificar el lenguaje heráldico, y en ellos el color rojo es llamado «gules» con cierta consistencia, aunque el lenguaje del blasón se estandarizaría recién en el siglo XVI.

En los inicios de la heráldica, entre los siglos XII y XIII, el gules era el esmalte más empleado: el historiador Michel Pastoureau halló que aparecía en el 60 % de las armerías europeas.

La adopción del término «gules» por parte de la lengua castellana data de 1603. En el pasado también se utilizaron, en lugar de «gules», adjetivaciones de color como "roxo", "rojo" y "colorado".

El gules no se encuentra definido con exactitud. En consecuencia, el tono y el matiz de rojo a emplear para representarlo quedan a criterio del artista heráldico. Se recomienda, sin embargo, que el rojo sea intenso y fiel a su naturaleza; no debe inclinarse demasiado hacia el naranja, el violeta, el marrón ni el rosa.

Cuando no se dispone de colores, el gules puede representarse mediante un rayado muy fino de líneas verticales paralelas, según el método atribuido al jesuita Silvestre Pietra Santa. Este es el método de representación que se ve comúnmente en grabados a una tinta.

Siguen tres ejemplos antiguos y notables del uso del gules.

Los animales que se blasonan como «escorchados» se representan de gules. "Escorchado", en el caso de los cuadrúpedos, significa que el animal está desollado, y en el caso de las aves, que está desplumada.

Hacia el inicio del Renacimiento se desarrolló un sistema de correspondencias simbólicas para los colores heráldicos que hoy se encuentra en desuso.
Es de notar que hacia 1828 este sistema era considerado absurdo por el heraldista inglés William Berry, aunque el español Francisco Piferrer, en 1858, lo comenta como si todavía fuese válido.

Si bien Jean Courtois, Heraldo Sicilia del Reino de Aragón, menciona en su tratado "Le blason des couleurs" (1414) que cualquiera de estas asociaciones del gules puede usarse para blasonar, en la práctica es posible que solamente se hayan usado el sistema planetario y el sistema de piedras preciosas. Para Alberto y Arturo García Caraffa (1919), el blasonado con gemas correspondía a los títulos y el de planetas a los soberanos.
Arthur Fox-Davies cita un ejemplo de blasonado con piedras preciosas que data de 1458.

Debajo se dan algunas de las antiguas correspondencias simbólicas del gules, así como algunos de los nombres que se le atribuyeron.

Los metales heráldicos:

Los otros colores heráldicos principales:
Y además:


</doc>
<doc id="1311" url="https://es.wikipedia.org/wiki?curid=1311" title="Geografía general">
Geografía general

La geografía general o "geografía sistemática" es la parte de la geografía que estudia las variaciones de las distribuciones tanto espaciales como de la superficie terrestre, así como la relación entre el medio natural y el ser humano. Se diferencia, por lo tanto, de la descripción y estudio de las regiones de la superficie terrestre (lo que se denominó Geografía Especial o corológica).

Se divide en geografía física y geografía humana.

"Se ha dicho, con razón, que la geografía es una Ciencia con una breve historia y un largo pasado" (). Esta apreciación hace referencia a que las obras de una geografía explicativa, y no solo descriptiva, son relativamente recientes, de fines del siglo XIX, pero tienen antecedentes en la Grecia durante la Edad Antigua, hace unos 25 siglos. Los primeros libros de Geografía son los de Eratóstenes y Estrabón y se trataban de una visión descriptiva del mundo conocido, con los accidentes geográficos, su ubicación y sus pueblos y habitantes.

Posteriormente a la época clásica griega, encontramos representantes de la geografía descriptiva, cada vez más explicativa, con el empleo de algunos mapas más elaborados, en la obra de la cultura helenística, convirtiéndose la ciudad de Alejandría, con su famosa Biblioteca, que llegó a reunir un millón de obras, mientras que los aportes de Ptolomeo, sus mapas y su teoría geocéntrica del mundo lo convirtieron en el autor más importante del campo de la Geografía a partir del siglo II, en la Edad Antigua y mucho tiempo después. El Imperio Romano impulsó el conocimiento del amplio territorio en el que se extendía, con la creación de miles de km de carreteras, fundación de ciudades, extensión de los cultivos, del regadío, de puentes y acueductos, todo ello logrado a través de un gran desarrollo de la ingeniería y de la arquitectura. Se destacan durante la Edad Media, las descripciones de viajeros principalmente, romanos, árabes y europeos del sur, como los venecianos, bizantinos, mallorquines (con el desarrollo de las llamadas cartas portulanas, de la brújula, la carabela y otros desarrollos de la navegación y del comercio. Al desarrollo del comercio en las ciudades del Mediterráneo, se unió el de las ciudades de la Liga Hanseática, ya durante la Baja Edad Media y comienzos de la Edad Moderna, cuando se inició la época de los grandes avances de la navegación transoceánica.



</doc>
<doc id="1313" url="https://es.wikipedia.org/wiki?curid=1313" title="Guerra">
Guerra

La guerra, en su sentido estrictamente técnico, es aquel conflicto social en el que dos o más grupos humanos relativamente masivos —principalmente tribus, sociedades o naciones— se enfrentan de manera violenta, preferiblemente, mediante el uso de armas de toda índole, a menudo con resultado de muerte —individual o colectiva— y daños materiales de una entidad considerable.

La guerra es la forma de conflicto socio-político más grave entre dos o más grupos humanos. Es quizá la más antigua de las relaciones internacionales y ya en el comienzo de las civilizaciones se constata el enfrentamiento organizado de grupos humanos armados con el propósito de controlar recursos naturales o humanos (conflictos entre cazadores nómadas y recolectores sedentarios que desarrollaron el concepto de "propiedad"), exigir un desarme o imponer algún tipo de tributo, ideología o religión, sometiendo, despojando y, en su caso, destruyendo al enemigo, en lo que se podía llegar y se llegó frecuentemente al genocidio. Es más, este tipo de conducta gregaria es extensible a la mayor parte de los homínidos y se encuentra estrechamente relacionado con el concepto etológico de territorialidad.

Las guerras se producen por múltiples causas, entre las que suelen estar el mantenimiento o el cambio de relaciones de poder, dirimir disputas económicas, ideológicas, territoriales, etc. En Ciencia Política y Relaciones Internacionales, la guerra es un instrumento político, al servicio de un Estado u otra organización con fines eminentemente políticos, ya que en caso contrario constituiría una forma más desorganizada aunque igualmente violenta: el bandolerismo por tierra o la piratería por mar.

Según Richard Holmes, la guerra es una experiencia universal que comparten todos los países y todas las culturas. Según Sun Tzu, «La guerra es el mayor conflicto de Estado, la base de la vida y la muerte, el Tao de la supervivencia y la extinción. Por lo tanto, es imperativo estudiarla profundamente». Según Karl von Clausewitz, la guerra es «la continuación de la política por otros medios».

Las reglas de la guerra, y la existencia misma de reglas, han variado mucho a lo largo de la historia. El concepto de quiénes son los combatientes también varía con el grado de organización de las sociedades enfrentadas. Las dos posibilidades más frecuentes son civiles sacados de la población general, generalmente varones jóvenes, en caso de conflicto, o soldados profesionales formando ejércitos permanentes. También puede haber voluntarios y mercenarios. Las combinaciones de varios o de todos estos tipos de militares son asimismo frecuentes.

Las formas de hacer una guerra dependen de los propósitos de los combatientes. Por ejemplo, en las guerras romanas, cuyo objetivo era expandir el imperio, el objetivo militar principal eran los combatientes de la nación a conquistar, para incorporar el pueblo una vez conquistado al imperio.

En la actualidad, a veces se hace distinción entre conflictos armados y guerras. De acuerdo con este punto de vista, un conflicto solo sería una guerra si los beligerantes han hecho una declaración formal de la misma. En una concepción de la doctrina militar de EE.UU. no se hace distinción alguna, refiriéndose a los conflictos armados como guerras de cuarta generación.
Entre el final de la segunda guerra mundial y el año 2010 hubo 246 enfrentamientos armados en 151 lugares del mundo.

Aristóteles afirmó que la guerra sólo sería un medio en vista de la paz, como lo es el trabajo en vista del ocio y la acción en vista del pensamiento.

La guerra, dice el Marqués de Olivart, es el litigio entre las naciones que defienden sus derechos, en el cual es el juez la fuerza y sirve de sentencia la victoria. Hugo Grocio la definió como "status per vincertatium qua tales sunt". Por su parte, Alberico Gentilis afirmó que "Bellum est armorum publicorum ensta contentio". Funk - Bretano y Alberto Sorel escribieron: "La guerra es un acto político por el cual varios Estados, no pudiendo conciliar lo que creen son sus deberes, sus derechos o sus intereses, recurren a la fuerza armada para que esta decida cuál de entre ellos, siendo más fuerte, podrá en razón de la fuerza, imponer su voluntad a los demás.".

Joseph de Maistre (1821) dijo, en sus Soirees de Saint Petesburg: "La guerra es divina en la gloria misteriosa que le rodea y en el atractivo no menos explicable que nos lleva hacia ella. La guerra es divina por la manera como se produce independientemente de la voluntad de los que luchan. La guerra es divina en sus resultados que escapan absolutamente a la razón."

G.W.F Hegel escribió: "la guerra es bella, buena, santa y fecunda; crea la moralidad de los pueblos y es indispensable para el mantenimiento de su salud moral. Es en la guerra donde el Estado se acerca más a su ideal porque es entonces cuando la vida y los bienes de los ciudadanos están más estrechamente subordinados a la conservación de la entidad común".

El instituto de investigación de la paz internacional de Suecia, define la guerra como todo aquel conflicto armado que cumple dos requisitos: enfrentar al menos una fuerza militar, ya sea contra otro u otros ejércitos o contra una fuerza insurgente y haber muerto diez mil o más personas.

Johan Huizinga establece que la guerra obtiene un carácter lúdico cuando se cumple con la condición agonal; el elemento agonal empieza a actuar en el momento en el que los adverarios se consideran enemigos que luchan por una cosa a la que pretenden tener derecho.

Buscar una o varias causas a las guerras ha sido una constante para muchos historiadores y políticos con el fin de evitar posibles conflictos en el futuro o encontrar culpables. Así autores como Brian Hayes apuntan a que ciertas causas se tienen como ciertas.

Una de las causas de la guerra es que dos naciones tengan diferencias profundas en diversos temas, que solo pueden resolverse con la vía armada. Desde el punto de vista socio-filosófico, se han avanzado muchas teorías sobre el origen y causa de la guerra. La primera, más contundente, resumida, filosófica, "racional" (en cuanto a explicar el origen de un fenómeno) es la que propone Platón en La República (tras afirmar que una ciudad es feliz con lo necesario):
Además, parece posible tratar de clasificar, muy en general, las teorías en dos grandes divisiones: la que ve la guerra como producto racional de ciertas condiciones, primariamente condiciones políticas (Carl von Clausewitz argumentó que la guerra es la continuación de la política por otros medios) y otra "irracionalista", que ve la guerra como producto de una tendencia, últimamente irracional, de los seres humanos.

Las teorías irracionalistas pueden aproximarse desde dos puntos de vista:

1. Aquellas que ven el origen de la guerra en causas no atribuible a fundamento racional, por ejemplo, sentimientos religiosos o emociones. El extremo lógico de esta visión —que el hombre es un animal inherentemente agresivo sujeto a tendencias tanto de competición como cooperación que se observan en animales sociales, situación que demanda la expresión ocasional de tales tendencias— se encuentra en algunas explicaciones ya sea biológicas, psicológicas o de la psicología social del origen de conflictos (ver, por ejemplo: Experimento de Robber's Cave).

2. La visión alternativa dentro de esta posición ve la guerra como originándose, a menudo, en equivocaciones o percepciones erróneas. Así, por ejemplo, Lindley y Schildkraut argumentan, a partir de un análisis estadístico, que la cantidad de guerras que se podría aducir tuvieron un origen racional ha disminuido dramáticamente en tiempos recientes (Lindley y Schildkraut ofrecen como ejemplos de tales equivocaciones la Guerra de las Malvinas aunque se dice que la causa fue en verdad subir la popularidad de Margaret Thatcher de Inglaterra declarando ella la guerra ya que Argentina no había matado a nadie y ellos hundieron al Belgrano que estaba yendo al continente matando a la mitad de todos los Argentinos que murieron, y la Guerra de Iraq) que otros aluden al deseo de petróleo, riquezas y dominio a la causa.

La visión alternativa, de la guerra como actividad racional, se basa en dos percepciones. La original de von Clausewitz acerca de la guerra constituyendo la persecución de (objetivos de) la política por otros medios, y una percepción posterior (implícita en von Clausewitz) que indica que se recurriría a la guerra cuando se estima que las ganancias superan a las pérdidas potenciales (es decir, a través de un análisis de costo-beneficio). A su vez, se pueden distinguir dos posiciones:

1. La teoría de la primacía de las políticas domésticas: se encuentra, por ejemplo, en las obras de Eckart Kehr y Hans-Ulrich Wehler (op. cit). Para esta posición, la guerra es el producto de condiciones domésticas. Así, por ejemplo, la Primera Guerra Mundial no fue producto de disputas internacionales, tratados secretos o consideraciones estratégicas, sino el resultado de condiciones sociopolíticas, incluyendo económicas, que, a pesar de ser comunes a varias sociedades, hacían sentir tensiones a cada una de ellas en forma interna, tensiones que solo se pudieron resolver a través de la guerra.

2. La teoría de la primacía de la política internacional, que se encuentra, por ejemplo, en la concepción de Leopold von Ranke, de acuerdo a quien son las decisiones de estadistas motivados por consideraciones geopolíticas las que conducen a la guerra.

Este deseo de conocer las causas para poder predecir cuando estallará el próximo conflicto ha sido abordado en varias ocasiones. Uno de los investigadores del fenómeno bélico fue Lewis Fry Richardson. Este autor investigó todos los conflictos desde el siglo XIX hasta la década de los 1950; considerando conflicto aquel enfrentamiento donde han muerto personas por causa intencionada de otra persona; de este modo juntaba los conflictos bélicos con las muertes por asesinato y homicidio, la mezcla fue intencionada por sus experiencias en la Segunda Guerra Mundial por las cuales pudo comprobar el efecto de muchas de las órdenes que vio dar y la suerte corrida por muchos soldados, enviados a la muerte a causa de esas órdenes.

Richardson tuvo la idea de catalogar las guerras según el número de muertos de una forma similar a cómo se catalogan los terremotos: según su intensidad. Así, una guerra de magnitud 6 sería en la que morirían de 1 000 000 a 1 999 999 personas; pero por todas las dificultades que halló para saber el número de muertos en una contienda (llegó a decir que resultaba más fácil saber el número de estrellas de una galaxia o de neutrinos en el universo) Richardson aplicó un índice de error de 0,5 (más menos); con este índice de error una guerra de magnitud 3 sería aquella en la que perecieron entre 316 228 y 3 162 278.

Aunque Richardson no fue el primero en recopilar conflictos bélicos su trabajo es uno de los más exhaustivos, pues comenzó en 1940 y siguió hasta el año de su muerte en 1953. Según sus estudios entre 1820 y 1950 hubo 315 conflictos de magnitud 2,5 o superior (al menos 300 muertos).

Pese a reconocer que resulta muy difícil saber cuando comienza un conflicto y cuando termina, si es uno o varios al tiempo o el ya citado número de muertos; los resultados fueron decepcionantes en cierto modo:

La frecuencia con la que estallan las confrontaciones sigue la distribución de Poisson, lo que parece indicar que las guerras son un suceso aleatorio. Así pues el autor concluyó que la principal causa de la guerra es la casualidad.

En segundo lugar, colocó los conflictos cronológicamente y según su magnitud, para saber si algún tipo de conflicto se repetía o si un tipo de guerra iba en aumento o en detrimento respecto a las demás. Los resultados tampoco fueron concluyentes, volviendo a mostrar una distribución muy similar al suceso aleatorio. De esta forma la conclusión es que de las guerras no se aprende a evitarlas y que la probabilidad de que estalle un nuevo conflicto es la misma para cualquier día, no importa si antes ha sucedido otro ni el tamaño de este otro.
Profundizando en su trabajo realizó un estudio de países vecinos que entraban en guerra. Midiendo las fronteras llegó a la conclusión de que un país linda con otras 6 naciones por término medio; por lo que la probabilidad de que una nación entrara en guerra con un vecino era casi del 10%, si fuera un proceso aleatorio; sin embargo la estadística indicaba que la probabilidad era del 87,33% (de 94 guerras estudiadas sólo 12 no tenían frontera común). Por lo tanto, según el matemático, otra causa de la guerra es la vecindad.

Richardson también relacionó las guerras con otros factores comúnmente indicados por los historiadores, como crisis económica o religión, llegando a otras tantas decepcionantes conclusiones:

No obstante Richardson concluyó que ni siquiera la religión es una causa de gran importancia.

Se ha sugerido, desde un punto de vista moral o filosófico, sería posible hablar de una Guerra justa o lícita. Si ese es el caso, hay que distinguir:

A primera vista parece posible proponer que la guerra no es necesariamente "ilícita". Existe el derecho de autodefensa o de legítima defensa contra el enemigo exterior, cuando ese ataca injustamente a un pueblo. Si se niega este derecho de legítima defensa se robustece al agresor y se pone en peligro la paz de los pueblos. Sin embargo, se ha sugerido desde una perspectiva ética que, para que una guerra pueda tener una licitud ética, existen una serie de condicionantes adicionales:

La defensa del bien público prevalece sobre cualquier derecho del agresor e incluso sobre los riesgos que puedan tener los propios agredidos. Pero se considera ilícita la matanza injusta.

Desde ese mismo punto de vista filosófico, se considera que el movimiento a favor de la paz se hace acreedor del más alto reconocimiento. Dicho movimiento es difusor de un espíritu de entendimiento y comprensión entre los pueblos. Su fin ético y moral es conseguir la paz y los acuerdos sin derramamiento de sangre.

El general chino Sun Tzu, en su célebre obra "El arte de la guerra", afirmó que la guerra había que ganarla antes de declararla o de que existiera en sí misma. En este aspecto, el célebre general expondría en una sucinta frase su concepción sobre el carácter de la guerra: "La guerra, es el Tao del engaño"; así, pretendería establecer que el estratega virtuoso debía basar todas sus decisiones militares, buscando primeramente distraer la atención del enemigo en los elementos más sobresalientes de su posición, y de no tenerlos, inventarlos.

El pensamiento de Sun Tzu, dejaría una profunda impronta en el pensamiento militar moderno, no sólo en reconocidos pensadores, sino también en eximios estrategas como Napoleón Bonaparte, quien en su renombrada victoria en la Batalla de Austerlitz, aplicara aquellos preceptos del "engaño".

El concepto de "guerra justa" fue presentado sistemáticamente por Tomás de Aquino en "Summa Theologiae".

Erasmo de Rotterdam, el reconocido humanista renacentista, calificaba a la guerra con la frase ""Dulce bellum inexpertis est"", cuya traducción al castellano es ""La guerra es dulce para los inexpertos"".

El historiador árabe Ibn Jaldún descubrió por primera vez las causas materiales de la guerra.

Carl von Clausewitz, en su clásica obra "De la guerra", pensaba que la guerra moderna es "La continuación de la política por otros medios" y que el fin de la misma era "desarmar al enemigo", no exterminarlo; de aquí nació el concepto de desarme mutuo, que imposibilita toda guerra y da paso a la política. La guerra sería pues un "acto político" y esta manifestación ponía en juego lo que él consideraba el único elemento racional de la guerra.
Según la "Enciclopedia mundial de las relaciones internacionales y Naciones Unidas", en los últimos 5500 años se han producido 14513 guerras que han costado 1240 millones de vidas y no han dejado sino 292 años de paz. Y únicamente entre 1960 y 1982, dicha enciclopedia calcula 65 conflictos armados (solo los que hayan producido al menos mil muertos) en 49 países, con un total de 11 millones de víctimas.
El primer conflicto bélico del que se tiene constancia es el que enfrentó a las ciudades-estado sumerias de Lagash y Umma, hacia el año 2450 a.C. La disputa se produjo por unas tierras de regadío. El rey de Lagash, Eannatum, comandó el ejército, que resultó victorioso, y convirtió a Umma en un estado vasallo.

Los conflictos bélicos en la siguiente lista representan guerras por control de un estado, en las cuales un mínimo de 1.000 personas habrían perdido sus vidas en 2011 o 2012. Las estadísticas son del Programa de Datos sobre Conflictos de Upsala en Suecia. 

Según el Libro Guinness de los Récords los siguiente conflictos están cada uno en un extremo




Marina Mancini, "Stato di guerra e conflitto armato nel diritto internazionale", Torino, Giappichelli, 2009, ISBN 978-88-348-9597-9

Erasmo de Rotterdam, "Adagios del poder y de la guerra y Teoría del adagio" (Incluye el comentario completo de Erasmo al adagio Dulce bellum inexpertis), Edición y traducción de Ramón Puig de la Bellacasa, Madrid, Alianza Editorial, el Libro de bolsillo, Filosofía, 2008, 436 pág. ISBN 978-84-206-6255-8



</doc>
<doc id="1314" url="https://es.wikipedia.org/wiki?curid=1314" title="Gobierno">
Gobierno

El Gobierno (del griego: κυβερνέιν "kybernéin" 'pilotar un barco' también 'dirigir, gobernar') es el principal pilar del Estado, la autoridad que dirige, controla y administra sus instituciones, la cual consiste en la conducción política general o ejercicio del poder ejecutivo del Estado. En ese sentido, habitualmente se entiende por tal órgano (que puede estar formado por un presidente o primer ministro y un número variable de ministros) al que la Constitución o la norma fundamental de un Estado atribuye la función o poder ejecutivo, y que ejerce el poder político sobre una sociedad. También puede ser el órgano que dirige cualquier comunidad política. Más estrechamente "Gobierno" significa el conjunto de los ministros; es decir, es sinónimo de "gabinete". Son las definiciones formales de lo que tangiblemente es un Gobierno; pero sustancial e intangiblemente el gobierno de un Estado comprende el conjunto de intereses vitales que ejercita y defiende a través de los objetivos nacionales permanentes, estos son las pautas o normas de conducta inalterables en el arte de gobernar, como la vigencia de la integridad territorial, o la división del poder en tres ramas, para lo cual por periodos que varían entre cuatro y seis años generalmente, se identifican cuales objetivos nacionales actuales, conducen a la vigencia de los intereses vitales, cualquiera que sea la orientación ideológica y filosófica del gobernante de turno.

En términos amplios, el Gobierno es el conjunto de instituciones, estructuras administrativas y autoridades que ejercen las diversas actividades estatales, denominadas comúnmente poderes del Estado (funciones del Estado). El Gobierno, en sentido propio, tiende a identificarse con la actividad política y más en particular con el poder ejecutivo.

El Gobierno no es lo mismo que el Estado, está vinculado a este por el elemento poder. El Gobierno pasa, cambia y se transforma, mientras que el Estado permanece, aunque históricamente puede experimentar algunas transformaciones en algunos aspectos. En ese sentido, el Gobierno es el conjunto de los órganos directores de un Estado a través del cual se expresa el poder estatal, por medio del orden jurídico. Puede ser analizado desde tres puntos de vista: según sus actores, como un conjunto de funciones, o por sus instituciones.

Muchos autores consideran que el objetivo del Gobierno es crear un sistema de auto-protección social para y con todas las personas que viven en el Estado, que sea seguro al largo plazo, autofinanciable, de muy buena calidad y sin corrupción. Prioritariamente asegurar el futuro de la salud, educación, trabajo, sustento y vivienda.

A diferencias de las ONG, el Gobierno recauda aportes obligatorios de todos los miembros del Estado, usualmente monetarios y en ocasiones en forma de servicio personal obligado, para construir infraestructura y servicios públicos.

Los expertos en ciencias políticas clasifican las diferentes clases de Gobierno de diversas maneras. A este respecto, la "Encyclopædia Britannica" explica: “Existe la distinción clásica entre Gobiernos según la cantidad de gobernantes: el que es ejercido por un solo hombre (monarquía o tiranía), por una minoría (aristocracia u oligarquía), o por la mayoría (democracia)”.

A veces los Gobiernos se clasifican según sus instituciones más importantes (parlamentarismo, Gobierno de un gabinete), según sus principios básicos de autoridad política (tradicional, carismático), según su estructura económica, o según su uso o abuso del poder. “Aunque ninguno de estos principios de análisis abarca todo aspecto —comenta esta obra de referencia—, cada uno tiene cierta validez.”
Históricamente, los primeros Gobiernos surgieron en sociedades con economías más complejas en los que existían excedentes económicos para coordinar el pleno aprovechamiento de los recursos humanos, naturales, instalaciones y herramientas. En la mayor parte de sociedades los Gobiernos sostienen buscar el máximo de beneficio social, aunque en algunos estados oligárquicos explícitamente el Gobierno decía defender los intereses de algún grupo social. Dentro de las instuticiones de Gobierno, destaca el poder ejecutivo como coordinador principal del Gobierno (en ocasiones incluso se confunde el término Gobierno con el mismo "poder ejecutivo"). Junto a este poder, se considera que el poder legislativo también es parte del Gobierno como generador de leyes y el poder judicial como árbitro entre conflictos entre diferentes agentes, que trata de asegurar el cumplimiento de las leyes.

Suele aludirse que el Gobierno se divide en poderes, pero en realidad se divide en órganos con distintos tipos de funciones: 

Los criterios de clasificación actuales se atienen más al contenido que a la forma, se trata de separar los Gobiernos no por el número de gobernantes, sino por la forma cómo se ejerce el poder o según la distribución de las competencias entre el individuo y el Estado, según el modo como se toman en consideración los gobernantes los derechos individuales (libertad de opinión, de prensa, de reunión, de pensamiento, de creación, de partidos políticos, de enseñanza).
Lo más correcto es separar los Gobiernos en democráticos y totalitarios, según se reconozca la libertad de intervenir en el Gobierno a los individuos o no, según se admitan los derechos fundamentales.

Los sistemas democráticos incluyen la participación de la población general en la toma de decisiones. Esta participación puede ser más notoria como en la democracia directa o más remota como sucede en la democracia representativa. En los estados modernos con millones de personas, se dan formas básicamente formas de democracia representativa, con la posibilidad de "referenda" y plebiscitos sobre cuestiones particulares, que usualmente obligan al gobierno a decidir entre dos o más alternativas según el voto mayoritario de la población.

Históricamente las democracias han tenido mayor apoyo de la población que los regímenes no democráticos, por esa razón muchos sistemas autoritarios e incluso totalitarios han llegado a referirse a si mismos como democracias, democracias populares o democracias orgánicas, cuando en realidad dichos regímenes no serían considerados propiamente democráticos por muchos analistas.

Los sistemas de gobierno totalitarios se basan frecuentemente en el transpersonalismo; el Estado regula según el criterio exclusivo de la clase gobernante, con poco o ningún contrapeso de otras clases, ni limitaciones asociadas a ciertos derechos civiles. En esos sistemas el Estado y la clase que lo dirige puede imponer sus ideas, criterios y doctrinas sin contrapeso de otras instituciones o grupos sociales. En los sistemas totalitarios todas las competencias residen en el Estado; este orienta los individuos de tal manera que se hace necesario que sean suprimidos o minimizados los derechos individuales.

El Estado totalitario no se caracteriza porque en él no se votó o porque no se cuente con el apoyo de la mayoría; se caracteriza porque en él no hay auténtica libertad de opinión. 
Las libertades individuales son absorbidas por el Estado, y se ejercitan solo según el interés y el fin de la clase dirigente. Sin embargo, formalmente la organización gubernativa totalitaria frecuentemente es muy similar a la organización de los sistemas democráticos, aunque esa similaridad difiere en algo fundamental, los sistemas totalitarios excluyen contrapesos, participación o representación efectiva de la población general. Aun así los sistemas totalitarios modernos nominalmente se han basado en normas, leyes y reglas escritas, según la noción de un Estado de derecho, si bien la potestad de cambiar arbitrariamente las normas deja sin efecto las garantías que dicho estado de derecho proporciona en las democracias.

La vida política y la económica no tendrán la posibilidad de florecer fuera de las doctrinas y directivas que dominan en el Gobierno. El poder judicial estará sometido a una misma concepción y el juez tendrá un campo de acción mucho más amplio que en la Democracia, puesto que no hay derechos individuales que salvaguardar y la justicia debe ejercerse imponiendo concepciones vagas, en función de los fines del Estado, interpretada por el Gobierno o el partido gubernativo.

El totalitarismo está dirigido por un Gobierno abarca todo, su sistema ideológico menostiene las individualildades concetas así como sus creencias personales o religiosas. Por lo que el único modo aceptado de religión es la religión de Estado, es decir, concordatarias y cofuncionales al Estado.

De acuerdo con el reconocido filósofo catedrático Ismael Iván Santaella Solorio y en conjunto con catedráticos. La base es el reconocimiento a la eminente dignidad humana, basando la organización estatal en el objeto de fomentar las múltiples posibilidades que derivan de dicha persona. La forma de Gobierno se basa en el predominio de la mayoría, pero con respeto a las minorías. Lo que conduce al pluripartidismo. En cuanto al funcionamiento se señala:

El Gobierno directo es aquel en el cual el pueblo ejerce directamente las funciones de Gobierno, actúa realizando actos de Gobierno sin representantes. Este régimen no existe actualmente y puede afirmarse que nunca se realizó, en Estado alguno. Solo ha sido posible en pequeñas circunscripciones (Municipios, Cantones suizos.).

Se ha dicho que en Grecia se practicó Democracia directa; lo que no es exacto, pues si bien el pueblo se reunía en el Ágora para discutir y resolver las cuestiones de Gobierno, era en realidad una aristocracia ya que estaban excluidos los extranjeros, esclavos y mujeres.
En la época moderna todos los autores citan como ejemplo de Gobierno directo los cantones suizos. Pero en realidad esas reuniones eran esporádicas y en ellas se limitaban a votar por sí o por no a los proyectos sometidos a su consideración. El Gobierno directo es una forma teórica y actualmente imposible de practicar, por el aumento de población de los Estados y la complejidad de la tarea gubernativa, cada vez más técnica.

El Gobierno representativo es aquel en el cual las funciones de Gobierno son realizadas por los representantes del pueblo. Actualmente la casi totalidad de los regímenes de Gobierno son representativos. Los gobernantes son considerados “representantes” de la ciudadanía y son ungidos en su calidad de tales mediante el sufragio. Este es el único contrato del elegido con el elector; el pueblo solamente tiene derecho de elección, la relación de representación se desarrolla a través del partido político. El representante no puede ser revocado, porque sus electores no tienen ningún contrato después del voto, salvo a través del partido político. Teóricamente el votante se inclina por un partido político por adhesión al programa de Gobierno que este propugna y vota por los candidatos de ese partido. Por esa razón el representante debiera cumplir con el programa y las autoridades del partido controlar su actuación.
El régimen semi-representativo es aquel que participa de ambos sistemas; el Gobierno se realiza indirectamente por medio de representantes, pero el pueblo realiza directamente algunos actos de Gobierno, es decir que no limita su intervención al sufragio, sino que a veces utiliza formas de Gobierno directo: plebiscitos, referendos, iniciativa popular..

Diversas ideologías históricas han hecho una crítica radical de la existencia del Estado en sí mismo, o las formas de Gobierno elegidas para dirigir el Estado. Así diversas formas de anarquismo han pugnado por la abolición de ciertas instituciones del Estado, mientras que en general el comunismo no ha abogado por la desaparición inmediata del Estado, sino por la forma que obligatoriamente debe estar constituida el Gobierno y la desaparición de ciertos tipos de Gobierno y los objetivos que debe perseguir dicho Gobierno. Igualmente, otras ideologías como el socialismo, la socialdemocracia, la democracia cristiana, el liberalismo o el fascismo apoyan decididamente la existencia de un Gobierno, y no hacen afirmaciones muy concretas sobre quien debe constituirlo, y más bien tienden a propugnar cuales son los objetivos ideales de un Gobierno.

Más recientemente desde el libertarismo y el anarcocapitalismo, algunos de sus partidarios han criticado la existencia del Gobierno político, no supeditado a la lógica del mercado y han difundido argumentos sugiriendo que el Gobierno es siempre una institución de autoprotección social, poco segura al largo plazo, que tal vez no sea capaz de asegurar los servicios de protección social a futuro, cuando la especie alargue la esperanza de vida por encima de los 100 años.




</doc>
<doc id="1323" url="https://es.wikipedia.org/wiki?curid=1323" title="Duelo al sol">
Duelo al sol

Duelo al sol (1946) es un western estadounidense, basado en la novela de Niven Busch sobre el relato bíblico de Caín y Abel, dirigido por King Vidor -con la colaboración de Otto Brower, William Dieterle, Sidney Franklin, William Cameron Menzies, David O. Selznick y Josef von Sternberg- y protagonizado, en los papeles principales, por Jennifer Jones, Joseph Cotten, Gregory Peck, Lionel Barrymore, Walter Huston, Lillian Gish, Harry Carrey, Charles Bickford, Herbert Marshall y Otto Kruger. La película estuvo nominada a dos Oscar en 1947: uno a la Mejor actriz principal, Jennifer Jones, y otro a la Mejor actriz secundaria, Lilian Gish.

Pearl (Jennifer Jones) es una joven mestiza india que es enviada a vivir a casa del senador texano McCandless (Lionel Barrymore), donde llama la atención de los dos hijos de este: el correcto Jesse (Joseph Cotten) y el fiero Lewton (Gregory Peck), quienes no tardarán en rivalizar por el amor de la joven.
Selznick esperaba que "Duelo al sol" superaría el éxito de "Lo que el viento se llevó". Fue un film muy controvertido en su época por su fuerte erotismo y por el affair que Selznick y Jones mantenían en la vida real y que finiquitó sus matrimonios. El film fue un gran éxito de taquilla pero no superó a "Lo que el viento se llevó". Recaudó 11 300 000dólares solo en Norteamérica .



</doc>
<doc id="1325" url="https://es.wikipedia.org/wiki?curid=1325" title="El paciente inglés">
El paciente inglés

El paciente inglés (The English Patient) es una película británica de 1996 dirigida por Anthony Minghella, basada en la novela del mismo título de Michael Ondaatje, y ambientada durante la Segunda Guerra Mundial. Fue la película más premiada en la gala de los Premios Óscar de ese año, con un total de 9 estatuillas de 12 candidaturas, y un gran éxito de taquilla. Se filmó en Túnez e Italia.

La película está ambientada en la Segunda Guerra Mundial y cuenta la historia de un hombre gravemente quemado, a quien solo se conoce como «el paciente inglés», que está siendo atendido por Hana (Juliette Binoche), una enfermera franco-canadiense en un monasterio italiano abandonado. El paciente es reacio a revelar información personal y solo a través de una serie de "flashbacks" se puede acceder a su pasado. Poco a poco se revela que él es en realidad un cartógrafo húngaro, el conde László Almásy (Ralph Fiennes), que estaba realizando un mapa del desierto del Sáhara y cuyo romance con una mujer casada, Katharine Clifton (Kristin Scott Thomas), en última instancia le llevó a su situación actual. A medida que el paciente recuerda más, David Caravaggio (Willem Dafoe), un exoperativo del servicio de inteligencia canadiense y formado como ladrón, llega al monasterio. Caravaggio perdió sus pulgares mientras era interrogado por un oficial del ejército nazi y poco a poco se desvela que se trataba de las acciones del paciente las que habían acarreado su tortura. Además de la historia del paciente, la película dedica tiempo a Hana y a su romance con Kip (Naveen Andrews), un zapador indio de origen sij en el ejército británico. Debido a los diversos acontecimientos de su pasado, Hana cree que cualquiera que se acerca a ella es probable que muera, y la posición de Kip como desactivador de bombas, hace que su romance esté lleno de tensiónante.

En la primera fase, ambientada en la década de 1930, el conde húngaro de la baja nobleza Laszlo de Almásy es colíder de una expedición arqueológica y topográfica de la Real Sociedad de Geografía en Egipto y Libia. Él y su compañero inglés Madox son académicos de corazón y deben desarrollar sus labores en medio de las turbulencias políticas europeas. En el inicio de la película, el matrimonio de los Clifton, Geoffrey (Colin Firth) y Katherine se unen a la expedición proporcionando un generoso aporte económico y animando bastante el espíritu del grupo. El conde se queda prendado de la hermosa y refinada Katherine. Como Geoffrey está a menudo lejos del grupo en otros asuntos, surge una aventura entre ambos. Los últimos meses antes del comienzo de la guerra traerán un gran logro arqueológico: el descubrimiento hecho por el conde de la "Cueva de los Nadadores", una antigua cueva subsahariana decorada con "figuras de natación", pinturas que datan de tiempos prehistóricos. En esta parte de la película, el romance entre Katherine y el conde se desarrolla en toda su plenitud, pero luego se desvanece aparentemente. Katherine se siente culpable por su infidelidad, mientras que el conde muestra una racha de celos junto con un desequilibrio que luego le persigue.

El otoño de 1939 y la guerra llevan toda excavación en la cueva a su fin, y obligan a Madox y al conde a tomar caminos separados. Mientras tanto, Geoffrey Clifton ha descubierto la aventura de su esposa, y busca una venganza repentina y dramática: un accidente con su avión, con Katherine a bordo, en el campamento del conde en el desierto. El accidente mata a Geoffrey en el acto, hiere gravemente a Katherine, y a pesar de que intenta acabar con la vida del conde, no lo logra. Almasy se las arregla para llevar a Katherine al refugio de la Cueva de los Nadadores, la deja con comida, agua, una linterna y una hoguera, y luego comienza su abrasador viaje de tres días a pie a la ciudad más cercana en busca de ayuda. La ciudad está en manos del ejército británico y el conde, aturdido y deshidratado, con su nombre no inglés, no es capaz de explicar de forma coherente a los funcionarios el accidente de avión y la difícil situación de Katherine. En su lugar, pierde los estribos durante el interrogatorio, por lo que lo meten en la cárcel militar. Lo envían encadenado a un tren hacia el norte de Bengasi, se escapa, se encuentra detrás de las líneas de África Korps y rápidamente negocia intercambiar sus mapas del desierto con los alemanes por gasolina para la avioneta de Madox, un De Havilland Tiger Moth que había dejado cerca del lugar de su expedición arqueológica. En el momento en que regresa a la cueva, Katherine está muerta y el conde lo está del todo, menos en un sentido físico. Se las arregla para colocar el cuerpo de Katherine en el avión y despega. Confundiendo el Tiger Moth con un avión de reconocimiento de la RAF, un batería alemán antiaéreo dispara y derriba en el desierto el avión que Almasy pilota. Aunque horriblemente quemado, aún vive, y es rescatado por miembros de la tribu beduina. 

La segunda fase de la película se traslada a Italia y los últimos meses de la guerra. El conde ya es un paciente inválido, y totalmente dependiente en ese momento de la morfina y el cuidado de su enfermera franco-canadiense Hana, separada de su unidad médica y establecida en un monasterio italiano, maltratado pero hermoso. Ese lugar se convierte en el punto focal de los hilos argumentales, más algunos nuevos y algunos sin terminar de la fase del norte de África, con temática en torno al amor, el azar y el telón de fondo de la guerra. Hana ha visto a un novio y a una amiga enfermera morir en la campaña de Italia y se pregunta si su relación con un teniente británico-indio romperá su ciclo de amor y de dolor o si simplemente continuará. Un visitante de la villa, llamado Caravaggio está buscando al conde desfigurado que él cree que juega un papel en su maltrecha época en Egipto y Libia. Pero Caravaggio, sin darse cuenta, tropieza con los restos del triángulo amoroso conde-Katherine-Geoffrey, entre 1940-42. Ha perdido los dos pulgares en un interrogatorio horrible a manos de los nazis y desde entonces ha perseguido y matado a los que él considera responsables de su destino. Él cree que el conde era parte de una red de espionaje e intriga en el desierto y sabe que negoció mapas con los alemanes. Caravaggio se enfrenta al conde con la noticia del suicidio de Madox y postula que el conde mató a los Cliftons. Solo un completo relato en la villa sobre el accidente de los Cliftons y el trato del conde de los mapas con los alemanes para recuperar a Katherine lleva a Caravaggio a la comprensión y el perdón.

Hana también encuentra reconciliación al final de la película. Su lugarteniente sobrevive a un encuentro con la muerte en el último día de la guerra y la esperanza en el amor resurge. El conde pide una sobredosis de morfina, por la que muere a manos de Hana.

Una de las escenas más memorables sitúa a Hana iluminando mediante una antorcha unos frescos de una capilla. Este ciclo de frescos, "Leyenda de la cruz", se encuentran en la capilla Bacci de la Basílica de San Francisco, en Arezzo, Toscana, Italia, y fueron pintados por Piero della Francesca.



</doc>
<doc id="1328" url="https://es.wikipedia.org/wiki?curid=1328" title="Blade Runner">
Blade Runner

Blade Runner (en algunos países El cazador implacable) es una película neo-noir y de ciencia ficción estadounidense dirigida por Ridley Scott, estrenada en y basada parcialmente en la novela de Philip K. Dick "¿Sueñan los androides con ovejas eléctricas?" (1968). Se ha convertido en un clásico de la ciencia ficción y precursora del género "ciberpunk". Fue candidata a dos Óscar. La película transcurre en una versión distópica de la ciudad de Los Ángeles (cambiando el San Francisco original de la novela), EE. UU., durante el mes de noviembre de 2019. El guion, escrito por Hampton Fancher y David Webb Peoples, se inspira libremente en la novela de Philip K. Dick. El reparto se compone de Harrison Ford, Rutger Hauer, Sean Young, Edward James Olmos, M. Emmet Walsh, Daryl Hannah, William Sanderson, Brion James, Joe Turkel y Joanna Cassidy; el diseñador principal fue Syd Mead y la música original fue compuesta por Vangelis.

La película describe un futuro en el que, mediante la ingeniería genética, se fabrican humanos artificiales a los que se denomina «replicantes»; se les emplea en trabajos peligrosos y como esclavos en las «colonias exteriores» de la Tierra. Estos replicantes, fabricados por Tyrell Corporation para ser «más humanos que los humanos» —especialmente los modelos «Nexus-6»—, se asemejan físicamente a los humanos, aunque tienen una mayor agilidad y fuerza física, pero carecen de la misma respuesta emocional y de empatía. 

Los replicantes fueron declarados ilegales en el planeta Tierra tras un sangriento motín ocurrido en el planeta Marte, donde trabajaban como esclavos. Un cuerpo especial de la policía, "Blade Runners", se encarga de identificar, rastrear y matar —o «retirar», en términos de la propia policía— a los replicantes fugitivos que se encuentran en la Tierra. Con un grupo de replicantes suelto en Los Ángeles, Rick Deckard, el mejor agente que ha existido en lo que a detección y retiro de replicantes se refiere, es sacado de su semi-retiro para que use algo de «la vieja magia blade runner».

En principio, "Blade Runner" recibió críticas contradictorias de parte de la prensa especializada. Unos se mostraron confundidos y decepcionados de que no tuviese el ritmo narrativo que se esperaba de una película de acción, mientras otros apreciaban su complejidad temática. La película no obtuvo buenos resultados de taquilla en los cines norteamericanos, pero logró un gran éxito en el resto del mundo. La película se convirtió en la favorita de los cinéfilos y el mundo académico, y ganó rápidamente el título de película de culto. 

Fue tal su éxito como cinta de alquiler en los videoclubes —éxito debido parcialmente a que la película se enriquecía al verla más de una vez— que se la eligió como una de las primeras películas en ser estrenadas en formato DVD. "Blade Runner" ha sido ampliamente aclamada como un clásico moderno por la ambientación lograda con sus efectos especiales y por adelantarse en plantear temas y preocupaciones fundamentales para el siglo XXI. Se la ha elogiado como una de las películas más influyentes de todos los tiempos, debido a su ambientación detallada y original, que sirve como un hito visual postmoderno con su descripción realista de un futuro en decadencia. "Blade Runner" también permitió poner a Philip K. Dick en la mira de Hollywood y desde entonces muchas películas se han inspirado en su obra literaria.

Forma parte del AFI's 10 Top 10 del American Film Institute en la categoría de "Películas de ciencia ficción", y en la lista del mismo Instituto.

El 6 de octubre de 2017 fue estrenada su continuación con el título "Blade Runner 2049".

Philip K. Dick falleció antes del estreno de la película, pero pudo ver una cinta de prueba de cuarenta minutos. El guion, escrito por Hampton Fancher, atrajo al productor Michael Deeley (quien aseguró financiación para el proyecto con varias fuentes, que más tarde resultaron problemáticas cuando una de ellas retrasó el lanzamiento de la edición especial de la película) y éste, a su vez, convenció al director Ridley Scott de crear su primera película en los EE. UU.; Scott estaba disconforme con el guion y solicitó a David Webb Peoples reescribirlo.

El título de la película viene de la novela "The Bladerunner", de Alan E. Nourse, cuyo protagonista contrabandea instrumentos quirúrgicos en el mercado negro y de "Bladerunner, A Movie" (en algunas ediciones "Blade Runner"), un tratado de cine escrito por William S. Burroughs; pero más allá del título, ninguna de las obras antes mencionadas resulta relevante para la película. Fancher encontró casualmente una copia de "Bladerunner, A Movie" mientras Scott estaba buscando un título comercial para su película; a Scott le agradó el título, y obtuvo los derechos sobre él, pero no sobre la novela.

"Blade Runner" debe mucho a "Metrópolis" de Fritz Lang. Scott da crédito al cuadro "Nighthawks", de Edward Hopper, y a la historieta breve "The Long Tomorrow", escrita por Dan O'Bannon y dibujada por Moebius (alias de Jean Giraud), como fuentes estilísticas para la ambientación. Scott contrató a Syd Mead como artista conceptual, y ambos recibieron gran influencia de la revista francesa de ciencia ficción "Métal hurlant" ("Heavy Metal"), en la que Moebius contribuía. Moebius recibió la oferta de trabajar en la preproducción de "Blade Runner", a la cual declinó para poder trabajar con René Laloux en la película animada "Les Maîtres du temps", decisión de la que Moebius más tarde se arrepentiría. Lawrence G. Paull (diseñador de producción) y David Snyder (director de arte) hicieron realidad los bocetos de Scott y Mead. Jim Burns trabajó brevemente en el diseño de los vehículos spinner; Douglas Trumbull y Richard Yuricich supervisaron los efectos especiales de la película.

Antes de que se iniciara la filmación de la película, Paul M. Sammon recibió el encargo de la revista "Cinefantastique" de escribir un artículo acerca de "Blade Runner". Su detallada observación e investigación sirvieron para publicar, más tarde, el libro "Future Noir: The Making of Blade Runner", conocido también como "La Biblia de Blade Runner" por los fanáticos de la película. El libro no solo describe la evolución de "Blade Runner", sino también las políticas y dificultades en el plató; particularmente respecto a las expectativas de Scott con su equipo de los EE. UU. (considerando que Scott es británico). Junto con lo anterior, su estilo como director de actores creó fricciones con el reparto, y contribuyó al posterior mutismo de Harrison Ford sobre la película.

En la ciudad de Los Ángeles, en noviembre de 2019, Rick Deckard (Harrison Ford) es llamado de su retiro cuando un Blade Runner excesivamente confiado —Holden (Morgan Paull)— recibe un tiro mientras llevaba a cabo la prueba Voight-Kampff a Leon (Brion James), un replicante fugitivo en la Tierra.

Deckard, dubitativo, se encuentra con Bryant (M. Emmet Walsh), su antiguo jefe, quien le informa que la reciente fuga de replicantes Nexus-6 es la peor hasta el momento. Bryant informa a Deckard acerca de los replicantes: Roy Batty (Rutger Hauer) es un comando, Leon es soldado y obrero, Zhora (Joanna Cassidy) es una trabajadora sexual entrenada como asesina y Pris (Daryl Hannah) un 'modelo básico de placer'. Bryant también le explica que el modelo Nexus-6 tiene una vida limitada a cuatro años como salvaguarda contra su desarrollo emocional inestable. 

Deckard es acompañado por Gaff (Edward James Olmos) a la Tyrell Corporation para comprobar que la prueba Voight-Kampff funciona con los modelos Nexus-6. Ahí, Deckard descubre que Rachael (Sean Young), la joven secretaria de Tyrell (Joe Turkel) es una replicante experimental, con recuerdos implantados que le permiten contar con una base emocional.

Deckard y Gaff allanan el apartamento de Leon mientras él y Roy obligan a Chew (James Hong), un diseñador genético de ojos, a que les envíe con J.F. Sebastian (William Sanderson), pues él les puede permitir llegar a Tyrell. Más tarde, Rachael visita a Deckard en su apartamento para probarle que ella es humana, pero huye llorando al enterarse de que sus recuerdos son artificiales. Pris conoce a Sebastian y se aprovecha de su bondad para lograr entrar en su apartamento.

Las pistas encontradas en el apartamento de Leon llevan a Deckard al bar de Taffy Lewis (Hy Pyke), lugar en que la tatuada Zhora realiza su espectáculo con una serpiente. Zhora intenta desesperadamente huir de Deckard por las calles atestadas de gente, pero Deckard logra alcanzarla y la "retira". Tras el tiroteo, Gaff y Bryant aparecen e informan a Deckard que también hay que "retirar" a Rachael. Convenientemente, Deckard observa a Rachael a lo lejos pero, mientras la sigue, Leon lo desarma repentinamente, y Deckard recibe una paliza. Rachael dispara a Leon, salvando la vida de Deckard y ambos se dirigen al apartamento de Rick, donde discuten las opciones que tiene Rachael. En un tranquilo instante de intimidad musical, ambos se empiezan a enamorar.

Entretanto, Roy llega al apartamento de Sebastian y se vale del encanto de Pris para convencer a Sebastian de ayudarle a reunirse con Tyrell. Ya en la habitación de Tyrell, Roy demanda que prolongue su vida y pide perdón por sus pecados. Al no ver satisfecha ninguna de sus solicitudes, Roy asesina a Tyrell y a Sebastian.

Deckard es enviado al apartamento de Sebastian después de los asesinatos. Allí, Pris le prepara una emboscada, aunque Deckard consigue dispararle tras una lucha. Roy regresa, atrapando a Deckard en el apartamento, y comienza a perseguirlo a través del edificio Bradbury hasta llegar al tejado. Deckard intenta escapar saltando a otro edificio quedando colgado de una viga. Roy cruza con facilidad y mira fijamente a Deckard —en el momento en que este se desprende de la viga, Roy lo sujeta por la muñeca, salvándole la vida—.

Roy se está deteriorando muy rápidamente (sus cuatro años de vida se acaban), se sienta y relata con elocuencia los grandes momentos de su vida concluyendo: «Todos esos momentos se perderán en el tiempo como lágrimas en la lluvia. Es hora de morir». Roy muere dejando escapar una paloma que tiene en sus manos, mientras que Deckard lo mira en silencio. Gaff llega poco después, y marchándose, le grita a Deckard: «Lástima que ella no pueda vivir, pero ¿quién vive?».

Deckard regresa a su apartamento y entra con cuidado, cuando nota que la puerta está entreabierta. Allí encuentra a Rachael, viva. Mientras se van del lugar, Deckard encuentra un "origami" que ha dejado Gaff (señal de que se les ha permitido escapar). Finalmente, la pareja se dirige a un futuro incierto.

A pesar de tener el aspecto de una película de acción, "Blade Runner" contiene un número inusualmente amplio de niveles dramáticos. Como obra del género ciberpunk le debe mucho al cine negro, pues contiene y explora convenciones tales como la mujer fatal, la narración en primera persona a lo Raymond Chandler (narración que no se encuentra en versiones posteriores) y la cuestionable perspectiva moral del héroe —extendido aquí para incluir el lado humano del personaje, así como la cinematografía oscura y sombría.

Es una de las películas de ciencia ficción mejor escritas que combina ambos géneros —pues abarca temas como la filosofía de la religión y las implicaciones éticas que conlleva el dominio de la ingeniería genética, dentro del contexto del drama clásico griego y sus nociones del hibris.

El mundo de "Blade Runner" representa un futuro cuya distancia ficticia de la actual realidad se ha reducido, la acción tiene lugar en el año 2019. La obra penetra en las implicaciones futuras de la tecnología en el ambiente y la sociedad, acercándose al pasado con el uso de la literatura, el simbolismo religioso, los temas dramáticos clásicos y el cine negro. Esta tensión entre pasado, presente y futuro es evidente en el futuro adaptado de "Blade Runner", donde la alta tecnología resplandece en lugares, mientras que el resto es decadente y viejo.
En el filme se puede percibir un alto nivel de paranoia en la manifestación visual del poder de las transnacionales, la policía omnipresente, las luces de las sondas y en el poder sobre el individuo, representando particularmente por la programación genética de los replicantes. El control sobre el ambiente es observado a gran escala, pero también cuando los animales son creados como meros artículos. Este contexto opresivo clarifica por qué muchas personas se van a las colonias exteriores, un paralelismo con la migración al continente americano. Las predicciones populares de los años 80, donde Estados Unidos es sobrepasado económicamente por Japón, se reflejan en el dominio de la cultura y publicidad japonesa en la ciudad de Los Ángeles de 2019. También la película hace un uso intensivo de los ojos y las imágenes manipuladas, como llamadas de atención sobre la realidad y la capacidad de percibirla.

Todo esto proporciona una atmósfera de incertidumbre para el tema central de "Blade Runner": examinar lo humano. Para descubrir a los replicantes, se utiliza una prueba de empatía (Test Voight-Kampff), con preguntas centradas en el tratamiento a los animales; esto funciona como indicador esencial de la "humanidad" de alguien. Los replicantes son retratados como personajes apáticos, y mientras que los humanos muestran pasiones y preocupaciones por otros, la masa de la humanidad en las calles es fría e impersonal. La película va tan lejos como para poner en duda la naturaleza de Deckard y obligar a la audiencia a revaluar qué significa ser humano.

Según el sociólogo David Lyon: 
"Blade Runner" tuvo un número significativo de actores que, en aquel entonces, eran desconocidos:






Actores secundarios:








La banda sonora de "Blade Runner", compuesta por Vangelis, es una combinación melódica y oscura de la composición clásica y los sintetizadores futuristas que reflejan el futuro retro y de cine negro que Ridley Scott imaginó. Vangelis, recién galardonado con el Óscar por "Chariots of Fire", compuso y ejecutó la música con sus sintetizadores, a la cual solo se añade el saxo tenor del músico de jazz británico, Dick Morrissey, colaborador habitual de Vangelis. El paisaje musical de 2019 fue creado dentro del modo espacial de Vangelis en la música New Age, como en otros álbumes suyos.

A pesar de la buena acogida por parte del público y la crítica —nominada en 1983 al premio BAFTA y el Globo de Oro como mejor banda sonora original— y la promesa de un álbum con la banda sonora por parte de Polydor Records al final de los títulos de créditos, el lanzamiento de la grabación original se retrasó durante más de una década.

Hay dos publicaciones oficiales de la música de "Blade Runner". A consecuencia de la carencia de un lanzamiento del disco, la New American Orchestra grabó una adaptación orquestal en 1982, con poca semejanza a la original. Algunos cortes de la película saldrían en 1989 a partir del recopilatorio "Themes", pero no sería hasta la presentación del "Director's Cut" de 1992 cuando aparecerá una cantidad sustancial de la banda sonora.

Sin embargo, mientras la mayoría de las pistas del álbum eran de la película, había unas cuantas que Vangelis compuso, pero no fueron finalmente utilizadas y algunas nuevas piezas musicales. La mayoría no consideraban esto como una representación satisfactoria de la banda sonora.

Estos retrasos y las pobres reproducciones generaron una cantidad importante de bootlegs durante años. Una de esas cintas piratas apareció en 1982 en las convenciones de ciencia ficción y llegó a ser popular debido al retraso de la versión oficial. En 1993, Off World Music, Ltd. creó un CD pirata que resultaría más extenso que el disco oficial de Vangelis. Un disco de Gongo Records presentaba el mismo material, pero con una calidad de sonido algo mejor.

En 2003, otros dos bootlegs aparecieron, el "Esper Edition", precedido por "Los Ángeles — November 2019". El "Esper Edition" contenía dos discos combinando los temas oficiales, lo del disco de Gongo y los propios de la película. Finalmente, "2019" era una compilación, en un solo disco, que consistía en casi todos los sonidos ambientales de la película, junto algunos sonidos del juego de Westwood "Blade Runner".

"Blade Runner" se estrenó en 1290 salas de cine el 25 de junio de 1982. La fecha fue escogida por el productor Alan Ladd, Jr. porque sus anteriores grandes éxitos, "" y "Alien", tuvieron una fecha similar (el 25 de mayo) en 1977 y 1979 respectivamente. Sin embargo, la recaudación del primer fin de semana fue decepcionante, con solo 6,15 millones de dólares, al igual que en el resto del mundo. Un importante factor de esta mala acogida por el público fue la coincidencia con el estreno de otra película: "", estrenada el 11 de junio, dominando la taquilla en ese momento.

Los críticos de cine se dividieron entre los que opinaban que la historia estaba sustentada por los efectos especiales y que eso no era lo que el estudio había anunciado, mientras que otros aclamaron su complejidad.

Una crítica generalizada caía sobre su ritmo lento; hasta un crítico cinematográfico le cambió el título a "Blade Crawler" (crawler, que se arrastra). Roger Ebert elogió las representaciones visuales de "Blade Runner", pero encontró escasa la historia humana. Ebert pensaba que el personaje poco convincente de Tyrell y la aparente falta de medios de seguridad que permitió a Roy asesinar a su creador eran ciertos problemas de trama. También creyó que la relación entre Deckard y Rachael parecía "existir más para el argumento que para ellos mismos".

Otros críticos han apuntado sin embargo que los efectos visuales sirven para crear un mundo deshumanizado donde resaltan los elementos humanos. Además, la relación entre Deckard y Rachael sería esencial para reafirmar la humanidad de ambos. En un episodio posterior de su programa, Ebert y Gene Siskel admitieron que estaban equivocados en sus reseñas iniciales, y que ellos mismos consideran la película como un clásico moderno.

"Blade Runner" ha sido nominada y ha ganado premios en numerosas ocasiones:







Si bien en principio la audiencia norteamericana la evitó, "Blade Runner" llegó a ser popular internacionalmente y se la considera una película de culto. El renombre la ha convertido en una referencia popular en otros medios: programas televisivos como "Futurama" se han referido muchísimas veces a "Blade Runner" y otros programas como "Cutting It" y "Stargate SG-1" han utilizado citas de la película.

El actor William Sanderson, quien interpretó a Sebastian, puso la voz a un personaje similar en la serie de animación "". En la película de acción "El Sexto Día", un psicólogo virtual repite la frase que se utilizó durante la escena de la prueba Voight-Kampff a Leon. Es también notable que las primeras escenas de "Blade Runner" presenten un primerísimo plano de un ojo humano; unas tomas similares se ven posteriormente en las películas "Días extraños" y "Minority Report".

El oscuro estilo ciberpunk de la película y el diseño futurista han servido como patrón e inspiración para sucesivas obras cinematográficas y programas televisivos, entre los que podemos mencionar a "Batman", "RoboCop", "Johnny Mnemonic", "El quinto elemento", "Dark Angel" y "Matrix". También ha tenido gran influencia en el anime, siendo ejemplo de ello "Ghost in the Shell", "Armitage III", "Ergo Proxy", "Cowboy Bebop", "Akira" y "Bubblegum Crisis". Antes de comenzar a rodar "Batman Begins", el director Christopher Nolan realizó una exhibición privada de "Blade Runner" a su equipo de filmación y les dijo: "Así es como vamos a hacer Batman". Las precuelas de "Star Wars" también han homenajeado a "Blade Runner" en sus secuencias de efectos especiales. Por su parte, la banda estadounidense de "rock" My Chemical Romance creó para su álbum "" una temática ambientada en el mismo lugar y año que la película, y han señalado que "Blade Runner" fue «una gran inspiración» para el disco.

Se cree a menudo que "Blade Runner" inspiró la novela "Neuromante" de William Gibson. Gibson ha respondido en entrevistas que él ya había escrito la novela cuando "Blade Runner" fue estrenada, y que realmente fue inspirado por el trasfondo de la película Alien. La película marca la introducción del género ciberpunk en la cultura popular. "Blade Runner" continúa reflejando tendencias y preocupaciones, y un número creciente de público la considera como la mejor película de ciencia ficción de todos los tiempos. La película fue seleccionada para su conservación en el Registro Nacional de Películas de Estados Unidos en 1993 y es utilizada frecuentemente en conferencias universitarias. Sus frases y banda sonora le han convertido en la película más citada del siglo XX.

"Blade Runner" también ha servido para influir a los juegos de rol del género cyperpunk tales como "Cyberpunk" y "Shadowrun", el juego de ordenador System Shock y la serie de juegos Syndicate, aunque sin duda alguna su mejor referente es el sucesor del propio System Shock, la obra conocida como Deus Ex, en donde se observa un futuro negro caracterizado por el empleo de nanotecnología, terrorismo, o el también llamado miedo global empleado por los gobiernos mundiales.

El filme también ha llegado al ámbito musical en forma de homenaje, numerosos sencillos incorporan en sus letras referencias —más o menos explícitas— a "Blade Runner". Entre este grupo de canciones puede citarse como ejemplo la canción "Boig per tu" del grupo español en idioma catalán Sau, donde una de sus estrofas, "«Quan no hi siguis al matí / les llàgrimes es perdran / entre la pluja / que caurà avui»" («Cuando no estés en la mañana / las lágrimas se perderán / entre la lluvia / que caerá hoy») es un guiño a la frase pronunciada por el replicante Batty en la escena final de la película.

Otra muestra de su influencia en la música es la canción Time What is Time de Blind Guardian, en donde hace claras referencias como:
"The things she remembered
Had never been her own
Replicant or human
I know the way to show..." o "Look into my eyes
Feel the fear just for a while
I'm a replicant and I love to live"

Existen siete versiones de "Blade Runner", aunque solo tres son ampliamente conocidas y vistas:







En 1982 las versiones norteamericana y europea para las salas de cine se estrenaron incluyendo un "final feliz" (usando metraje de la película de Stanley Kubrick, "El resplandor") y una voz en off, añadida a petición de los ejecutivos del estudio durante postproducción tras realizar pruebas de audiencia que indicaban la dificultad de comprender la película. Aunque varias versiones diferentes del guion habían incluido una voz en off, tanto Ridley Scott como Harrison Ford se mostraban insatisfechos del resultado e intentaron no incluirla en la versión final. Se ha rumoreado que Ford intencionalmente hizo la voz en off de mala calidad con la esperanza de que no fuera usada, pero recientes entrevistas indican lo contrario.

En 1990, Warner Bros permitió brevemente reproducir en cines una copia de 70 mm de la película, anunciándola como un "Director's Cut" (montaje del director). Sin embargo, Ridley Scott negó públicamente que esa versión de la película fuera el definitivo "Director's Cut", argumentando que fue editada toscamente y carecía de la banda sonora de Vangelis para la película.

En respuesta al descontento de Scott, y en parte debido al resurgimiento de la popularidad de la película a principios de los años 1990, Warner Bros decidió editar un definitivo "Director's Cut" bajo la dirección de Scott que se presentaría en 1992.

Para esto contrataron al restaurador de películas Michael Arick, que fue uno de los que redescubrieron las ediciones originales de "Blade Runner" y que ya estaba realizando las consultas para la Warner, para encabezar el proyecto junto a Scott. Arick pasó varios meses en Londres con Les Healey, que había sido el editor asistente en "Blade Runner", procurando compilar una lista de los cambios que Scott había deseado hacer a la película. También consiguió una enumeración de sugerencias y direcciones del propio director.
Arick realizó varios cambios a la película, la mayoría de ellos eran modificaciones de edición menores. Sin embargo, tres cambios importantes se realizaron en la película dando un giro significativo al resultado final: la eliminación de la voz en off de Deckard, la reintroducción de la secuencia de un sueño con un unicornio galopando en un bosque y el corte del final feliz impuesto por el estudio, incluyendo algunos efectos visuales que originalmente salían en los créditos finales.

Las presiones en forma de dinero y tiempo y la obligación a Thelma & Louise mantuvieron a Scott apartado de la reedición de la película y, aunque finalmente estaba más contento por esta versión que las anteriores, él no se sentía cómodo con ella como definitivo "Director's Cut".

Como curiosidad técnico-cinematográfica, la revisión de secuencias de Roy Batty en el "final cut" supuso la eliminación del «dedo» de Tyrell del hombro de Roy cuando este está en la cabina junto con Leon; se trata de una imagen empleada en el montaje de una escena o toma posterior, pero para la primera del personaje en la película actuando; tal defecto que se reitera en las sucesivas versiones es eliminado con la aproximación del plano y la alteración infográfica del fondo de la imagen. Hay nuevas escenas en el "final cut" de las que habría que destacar las bailarinas enmascaradas tras el escaparate callejero.

En parte como resultado de esas quejas, Scott fue invitado de nuevo a mediados de 2000 para ayudar a realizar una versión definitiva y final de la película, que sería completada a mediados de 2001. Durante el proceso, se creó una nueva impresión digital desde los negativos originales, los efectos especiales fueron mejorados y limpiados, y el sonido remasterizado en Dolby Digital 5.1 Surround. A diferencia del Director's Cut de 1992, Scott supervisó personalmente el nuevo montaje mientras se creaba.

El DVD de la edición especial se presentaría para las navidades de 2001, y los rumores apuntaban a que sería un set de tres discos incluyendo el montaje completo de la versión internacional para cines, el montaje del Director's Cut de 1992, y la nueva versión mejorada añadiendo escenas eliminadas, entrevistas con el reparto y el equipo, y el documental "On the Edge of Blade Runner".

Sin embargo, Warner Bros retrasó indefinidamente el lanzamiento de la edición especial tras disputas legales que comenzaron con los garantes de la versión original (en especial, Jerry Perenchio), que habían obtenido la propiedad de la película cuando el presupuesto de filmación subió de USD 21,5 millones a 28 millones.

Tras varios años de disputas, en mayo de 2006 apareció la noticia de que Warner Bros estaba retocando varias versiones de la película para poder hacer un lanzamiento a finales del año, de acuerdo con la revista "Total Film" y el sitio web "The Digital Bits". No hubo un acuerdo sobre la fecha de lanzamiento, pero se señaló que una versión restaurada del Director's Cut de 1992 aparecería primero en dos discos, posiblemente entre septiembre y diciembre de 2006. Finalmente Warner confirmaría el lanzamiento de "Blade Runner: The Final Cut" con motivo del 25º aniversario del estreno, tratándose de un set en formato maletín incluyendo cinco discos que se pondría a la venta el 18 de diciembre de 2007, con las versiones anteriormente mencionadas y las versiones de estreno en Europa y Estados Unidos, así como en formato Blu-ray y HD DVD. Una nueva edición de coleccionista con cinco discos, así como un doble disco individual fueron puestos a la venta en España el 12 de febrero de 2008, así como las versiones correspondientes en Blu-ray y HD DVD. Este último formato, como es sabido, acabó por no imponerse a su competidor. Toshiba decidió cesar de fabricar más reproductores y continuar con las investigaciones para mejorar su formato, lo cual repercutió "a posteriori" en la edición correspondiente.

También, para coleccionistas, es la versión que en 2009 produjo Phaedra Studio, de España, con un montaje exclusivo con las 5 versiones de la película, y toda la música que Vangelis compuso para la misma. Un total de dos horas y 28 minutos con sonido 5.1 y menú de escenas.

La productora Alcon Entretainment, que adquirió los derechos de la cinta en marzo de 2011, confirmó el 17 de mayo de 2012 que la nueva entrega del clásico de ciencia ficción sería una secuela cuya acción tendría lugar varios años después del momento en el que transcurre "Blade Runner". Ridley Scott dirigiría el filme, que no se centraría en el personaje de Harrison Ford, y negoció con el guionista de la cinta de 1982, Hampton Fancher, para que desarrollara el argumento de la secuela.

El 9 de octubre de 2013, Harrison Ford confirmó que había mantenido las primeras conversaciones con Ridley Scott para retomar el personaje de Rick Deckard. Con antelación, el director dejó claro que le gustaría contar con Ford, pero sin que ello significara que la nueva "Blade Runner" fuera una continuación de las aventuras de Deckard, solo que sí le gustaría que apareciera en algún momento. Michael Green trabajó en el guion de la secuela de "Blade Runner" sobre una historia escrita por Hampton Fancher, guionista de la película original basada en la novela de Philip K. Dick "¿Sueñan los androides con ovejas eléctricas?".

El 25 de noviembre de 2014, Scott declaró que no dirigiría la segunda parte de "Blade Runner", anunciando que solo sería el productor ejecutivo y confirmando a Harrison Ford en el reparto. El 17 de abril de 2015 se informó que Ryan Gosling protagonizaría la secuela de "Blade Runner" junto a Harrison Ford, dirigiendo finalmente la película el canadiense Denis Villeneuve.

El 18 de febrero de 2016, Alcon Entertainment anunció la fecha de estreno para el 12 de enero de 2018. Sin embargo, el 20 de abril de 2016 Warner informó de su adelanto para el 6 de octubre de 2017, tres meses antes de lo que estaba programada.

El 6 de octubre de 2016, justo a un año del estreno, se desveló el título oficial de la secuela: "Blade Runner 2049" y el 19 de diciembre se hizo público el primer teaser tráiler de la película.

"On the Edge of Blade Runner" (55 min.), producido en 2000 por Nobles Gate Ltd. (para Channel 4), dirigido por Andrew Abbott y escrito por Mark Kermode, sería incluido en la Edición especial. Las entrevistas con el equipo incluyen a Ridley Scott dando detalles del proceso creativo y los problemas durante preproducción. Los relatos de Paul M. Sammon y Fancher proporcionan una visión de la idea original de Philip K. Dick y los orígenes de "¿Sueñan los androides con ovejas eléctricas?"

Se entremezclan entrevistas al reparto con las notables excepciones de Harrison Ford y Sean Young. A través de estas entrevistas conseguimos tener la impresión de cuan dificultosa y frustrante fue la realización del proyecto como resultado de un director exigente sin aliados y unas condiciones duras, húmedas y calurosas; todo ello añadido a la atmósfera presionante que todos sentían cada vez más mientras se sobrepasaba el presupuesto. Hay también un recorrido de algunas localizaciones, las más notables son el edificio Bradbury y el solar de la Warner Bros que era las calles de Los Ángeles de 2019, con un aspecto muy distinto a la versión de la película.

Tras esto, el documental detalla las pruebas de postproducción en pantalla y sus ediciones y cambios (la voz en off, el final feliz, la escena eliminada del hospital), los efectos especiales, la banda sonora de Vangelis, y la relación tensa entre el equipo de rodaje y los inversionistas que culminaría con el despido de Deeley y Scott, a pesar de lo cual, siguieron trabajando en la película. También aparece la cuestión sobre si Deckard era o no replicante. 

"Future Shocks" (27 min.), es un documental de 2003 para TVOntario (como parte de su serie Film 101). Contiene entrevistas con el productor ejecutivo Bud Yorkin, Syd Mead, miembros del reparto como Sean Young, pero, de nuevo, sin Harrison Ford. Hay un extenso comentario por el autor de ciencia ficción Robert J. Sawyer y críticos de cine acerca de los enfoques sobre los temas, el impacto visual y la influencia de la película. Olmos habla sobre la participación de Ford y las experiencias personales durante la filmación con Young, Walsh, Cassidy y Sanderson. También relata una anécdota cuando los miembros del equipo crearon camisetas con fotogramas de Ridley Scott. Las versiones de la película son criticadas y se discute cómo de aproximado está a la realidad el futuro predicho en "Blade Runner".

El guion original de Hampton Fancher estaba basado libremente en la novela de Philip K. Dick. Sin embargo, el guion de Fancher se enfocaba más en los problemas del entorno y menos sobre las cuestiones de humanidad y fe, que era la parte central de la novela. Cuando Ridley Scott se unió a la película deseaba realizar cambios al guion ya escrito y, finalmente, contrató a David Peoples para realizar los cambios después de que Fancher se negase.

El título de la película también cambió varias veces durante el proceso de escribir el guion. Se llamaba "Dangerous Days" ("Días peligrosos") en la última prueba de Fancher, pero se renombró a "Blade Runner", título prestado (con permiso) de una novela de ciencia ficción de William S. Burroughs, "Blade Runner: A Movie".

Como resultado de las diferencias del guion de Fancher con la novela, las numerosas reescrituras antes y durante el rodaje y que Ridley Scott no había leído completamente la obra de Dick, la película se apartaba perceptiblemente de su inspiración original. Los cambios han impulsado a muchos críticos y seguidores a considerar ambos como trabajos independientes, a pesar de que la novela fuera reimpresa con el título de "Blade Runner" para ayudar a aumentar las ganancias.

Algunos de los temas en la novela se han reducido al mínimo o han sido eliminados completamente, incluyendo la fertilidad/esterilidad de la población, la religión, los medios de comunicación, las mascotas reales y sintéticas y las emociones.

Los productores de la película acordaron una proyección de algunos fragmentos rodados para Philip K. Dick poco antes de su muerte a principios de 1982. A pesar del hecho de que la película difería significativamente de su libro y el bien conocido escepticismo de Dick sobre Hollywood, este se entusiasmó bastante con la película. Dick predijo que: «[Blade Runner] cambiará la manera de ver las películas».

Hay tres novelas oficiales y autorizadas de "Blade Runner", escritas por el amigo de Philip K. Dick, K. W. Jeter, que continúan la historia de Rick Deckard e intentan resolver las diferencias entre "Blade Runner" y "¿Sueñan los androides con ovejas eléctricas?". Sin embargo, la primera novela de la trilogía contiene numerosas inconsistencias con la película, incluyendo la resurrección de un personaje muerto y una completa modificación de la naturaleza de otro. El resultado final parece más un universo alternativo que una secuela directa.


David Peoples ha dicho que en el guion de "Soldier" (1998) intentó crear una "secuela indirecta" de "Blade Runner". Ambas películas toman lugar en el mismo universo, lo que es evidente por el hecho que los autos voladores de "Blade Runner" aparecen como parte de la escenografía de "Soldier". Sin embargo, "Soldier" es una secuela no oficial, ya que nunca ha sido formalmente aprobada por la sociedad que mantiene los derechos de "Blade Runner".

Aunque no hay una secuela oficial de "Blade Runner", muchos seguidores de la película han observado cierta semejanza con la serie de televisión "Total Recall 2070" (1999). Muchos la consideran como una secuela de "Blade Runner", o que al menos toma lugar en el mismo universo. La serie está inspirada en la novela que inspiró "Blade Runner" y el relato corto que inspiró "Desafío Total", ambos obra de Philip K. Dick.

Otra secuela es la producción de 2003, "Natural City", subtitulada como "A Korean Blade Runner". Ambientada en 2080, los clones humanos con inteligencia artificial reemplazan la mano de obra en Natural City. Los clones tienen fecha de caducidad pero algunos de ellos no quieren aceptar el hecho de ser reciclados. "R" un miembro de las fuerzas "MP" se enamora de Ria, una clon a punto de expirar... El argumento tiene algunas similitudes con Blade Runner, así como parte de los escenarios, con coches voladores como los spinners y un cierto ambiente e iluminación parecidos, incluso con lluvia permanente. El dirigible de Blade Runner aquí se presenta como una enorme nave anunciando un viaje al lúdico planeta Koyo. Evidentemente la parte oriental tan apreciada por Ridley Scott en esta ocasión está omnipresente sin más. La escena con Deckard pidiendo fideos en un puesto de comidas en la calle también aparece como un guiño a la película. La música, muy melancólica, no puede ser comparada con la obra de Vangelis, aunque se ajusta al clima que se pretende conseguir.

Hay dos juegos para ordenador basados en la película, uno para Commodore 64 y ZX Spectrum por CRL Group PLC (1985), y otro como aventura de acción por Westwood Studios (1997). Este último juego presenta nuevos personajes e historias alternativas basadas en el mundo de "Blade Runner", junto con algunas de las voces originales del reparto de la película. Un prototipo de juego de mesa también fue creado en California (1982), con reglas parecidas al Scotland Yard.

El juego de Konami, Snatcher tiene muchas influencias de "Blade Runner", que son recogidas con detalle en numerosas páginas web.

Archie Goodwin escribió el guion de la interpretación para cómic, "A Marvel Comic Super Special: Blade Runner", publicado en septiembre de 1982. Con cubierta de Jim Steranko, la adaptación de 45 páginas fue ilustrada por el equipo de Al Williamson, Carlos Garzon, Dan Green y Ralph Reese. Crazy Comics creó una parodia llamada "Blade Blummer".

La frase que pronuncia el replicante Roy Batty agonizando antes de morir ha sido considerablemente influyente en el mundo de la ciencia ficción:

Original

Traducción (doblaje en España)

Traducción (doblaje en Latinoamérica)


</doc>
<doc id="1331" url="https://es.wikipedia.org/wiki?curid=1331" title="American Beauty">
American Beauty

American Beauty (titulada Belleza americana en Hispanoamérica) es una película dramática de dirigida por Sam Mendes, escrita por Alan Ball y protagonizada por Kevin Spacey, Annette Bening, Thora Birch, Wes Bentley, Mena Suvari y Chris Cooper. La trama relata la vida de los Burnham, una familia disfuncional compuesta por Lester, su esposa Carolyn y su hija adolescente Jane, quienes se relacionan con otros personajes, incluidos sus vecinos, la familia Fitts. La película es descrita por los críticos como una sátira que abarca la satisfacción personal, el amor paternal, la sexualidad, la belleza, el materialismo, la autoliberación y la redención. Además, abarca temas como la importancia dada por las sociedades occidentales modernas a la apariencia y el éxito económico, y cómo estos menoscaban las relaciones interpersonales, deformándolas y generando en ocasiones una necesidad de escapar. Es en ese sentido en que se presenta la relación del protagonista con la amiga de Jane.

En un principio, Ball comenzó a escribir el guion con la intención de convertirlo en una obra teatral, en parte inspirada en el circo mediático que inició en torno al juicio contra Amy Fisher en 1992. Luego de darse cuenta que la historia no funcionaría en el escenario, decidió adaptar el guion con base en una película. Tras varios años como escritor de televisión intentó entrar a la industria cinematográfica con "American Beauty". Finalmente, el guion fue modificado y adaptado, esta vez con un toque cínico, más que nada influenciado por la experiencia del escritor en comedias de situación. Finalmente los productores Dan Jinks y Bruce Cohen lograron que el estudio DreamWorks comprara el guion por 250 000 USD, cifra que superó la oferta de otras productoras. DreamWorks financió la producción con 15 millones USD y se desempeñó como su distribuidor estadounidense. La película marcó el debut cinematográfico del cineasta Sam Mendes, que hasta entonces solo había dirigido telefilmes y musicales. Spacey fue la primera opción de Mendes para encarnar a Lester, a pesar de las insistencias de DreamWorks en contratar actores más conocidos; del mismo modo, el estudio sugirió varias actrices para hacer de Carolyn, hasta que el director ofreció el papel a Bening. La fotografía se llevó a cabo entre diciembre de 1998 y febrero de 1999. El set de rodaje estuvo ubicado en Burbank y en Los Ángeles. 

Se estrenó en Estados Unidos el 15 de septiembre de 1999, y fue recibida positivamente por la crítica y el público; fue la película estadounidense con mejores críticas del año y recaudó más de 356 millones USD a nivel mundial. Principalmente se elogió los aspectos de la producción, con especial énfasis en el director, Spacey y Ball; la crítica destacó en la familiaridad de los personajes y la escenografía. La cinta ganó cinco Premios Óscar, en la categoría Mejor película, Mejor director, Mejor actor, Mejor guion original y .

La película comienza con una imagen de una cámara de vídeo, donde aparece una adolescente recostada en la cama. Ella se queja de su padre, dice que es aburrido y se avergüenza de él. Una voz en "off" de un joven, seguramente el que maneja la cámara, pregunta: «¿Quieres que lo mate?». Ella lo piensa un momento y dice con una sonrisa satisfecha: «Sí... ¿Lo harías?».

La película retoma con Lester Burnham (Kevin Spacey), un ejecutivo de publicidad de Chicago y padre de familia de cuarenta y dos años. Lester comienza a hacer de narrador, pero el Lester que aparece en la pantalla no está hablando: «En menos de un año, estaré muerto. Por supuesto, todavía no lo sé. Y en cierta manera, ya estoy muerto». Pronto nos damos cuenta del por qué: su vida no es la mejor. Su esposa Carolyn (Annette Bening) es una ambiciosa vendedora inmobiliaria a la que solo le importa el éxito profesional («Mi compañía vende una imagen y es parte de mi trabajo vivir esta imagen»); su hija Jane (Thora Birch), de dieciséis años (la chica de la cámara del principio de la película), es una típica adolescente apática que se queja de su padre por su falta de apoyo y está pensando en hacerse una cirugía de pechos, para levantárselos y dejar ambos a la misma altura. Lester comenta de ella: «Jane es una típica adolescente: enfadada, insegura y confusa. Me gustaría decirle que se le pasará, pero no quiero mentirle». Jane y Lester no se han hablado durante meses. Lester se autodescribe como un perdedor, aburrido, alguien fácil de olvidar («He perdido algo, pero nunca es tarde para recuperarlo»).

Se puede ver un día típico en la vida de cada uno de los tres personajes. Lester inicia su día masturbándose en la ducha. Según dice, «Este va a ser el mejor momento del día. Todo irá cuesta abajo a partir de aquí». Más tarde se ve a Lester en su trabajo, donde su jefe, Brad Dupree, le pide que haga un informe describiendo su trabajo y sus tareas, detallando exactamente cuál es su contribución a la compañía. Dupree está tratando de identificar quiénes son los empleados de los cuales se puede prescindir para poder despedirlos y ahorrarle dinero a la compañía. Carolyn, por su parte, intenta vender una casa a varias parejas, pero solo encuentra rechazo tras rechazo. Lester encuentra la inspiración para transformarse a sí mismo al conocer a Angela Hayes (Mena Suvari), la mejor amiga y compañera de colegio de su hija Jane. Angela es una bella, confiada y supuestamente promiscua animadora que aspira a ser modelo, y que piensa que «no hay nada peor en la vida que ser vulgar». Angela cautiva a Lester desde el momento en que él la ve en una actuación rutinaria de baile en el colegio y desarrolla una obsesión hacia ella, para vergüenza de Jane. Esa misma noche, Jane ve a un joven que la graba con su cámara de video a través de la ventana de su habitación. Jane, que no está acostumbrada a recibir atención de este tipo, se siente halagada. Después, cuando Jane invita a Angela a quedarse a dormir en su casa, Lester escucha a Angela decirle a Jane que encuentra atractivo a su padre y que «le haría totalmente el amor», si él comenzara a ejercitarse un poco. Habiendo escuchado esto, Lester inmediatamente parte hacia su garaje, donde encuentra viejas pesas y comienza a levantarlas. Mientras tanto, una familia formada por el extremadamente homófobo y austero coronel Frank Fitts (Chris Cooper), miembro del Cuerpo de Marines de los Estados Unidos, un hombre sin emociones y posiblemente con depresión; su mujer Barbara (Allison Janney); y su curioso e introspectivo hijo Ricky (Wes Bentley), se mudan a la casa de al lado de los Burnham. Jane empieza a notar que Ricky, al que no conoce su padre, gana dinero como traficante de marihuana.

Tiempo después, Carolyn empieza una relación extramatrimonial con un vendedor inmobiliario rival, y también, inducida por él, decide empezar a aliviar su estrés en un campo de tiro. Lester deja su trabajo, chantajeando a su jefe con su indemnización y empieza a trabajar en un nuevo restaurante de comida rápida y Ricky le enseña a Jane un video en el que una bolsa de plástico está «bailando» en el aire, lo que Rick consideró la cosa más bonita que jamás había grabado. Más tarde, durante una discusión acalorada en la cena, Lester finalmente hace valer su dominio sobre Carolyn en el hogar. En su último día de vida, Lester enfrenta calmado a su mujer sobre su relación extramatrimonial, causando el final de su matrimonio. Carolyn escucha una cinta de autoayuda que la convence de «negarse a ser una víctima». Conduce amargamente hacia su casa con su pistola, con la intención de enfrentarse a su marido, creyendo que ha arruinado su vida. Lester llama a Ricky a su casa para conseguir marihuana, aumentando las sospechas del coronel Fitts, que está convencido que su hijo es homosexual y mantiene una relación con el propio Lester. Consecuentemente, lo obliga a irse de casa, tras golpearlo con violencia. Cuando Ricky y Jane planean escapar a Nueva York, Angela, que les está visitando, les acusa de ser «raros», a lo que Ricky le recrimina que ella es fea, que es ordinaria y lo sabe. Mientras Rick habla con su madre, diciéndole que no le queda más alternativa que marcharse, se despide de ella y le pide que cuide de su padre, Angela se echa a llorar en las escaleras y Lester acude a consolarla. Pero antes, mientras se encontraba haciendo ejercicios físicos, levanta el portón de su garaje a un quebrado emocionalmente coronel Fitts, que se presenta en su casa completamente mojado bajo la lluvia. El coronel lo abraza intensamente y luego pretende besarlo, revelando así su condición sexual y siendo rechazado por Lester. Una vez con ella, Lester y Angela entran en una aproximación sexual, que se desbarata cuando ella le revela que, de hecho, es su primera vez. Lester no puede tomar su virginidad y, paternalmente, en vez de ello le hace un sándwich en la cocina. Por primera vez en un tiempo, Lester se da cuenta de que es realmente feliz. Cuando Angela se va al baño, Lester contempla una vieja foto de su familia sonriente, inconsciente de que una pistola se apoya en su nuca, por la espalda. Se oye un disparo y la cámara, que enfoca la pared, muestra cómo se imprime en ella una súbita mancha de sangre.

La película termina con una descripción de la vida de Lester en imágenes delante de sus ojos, entremezclados con escenas de su familia y otros hasta el momento del disparo; las reacciones de Ricky, Angela y Jane al disparo (Ricky observa que Lester murió feliz), Carolyn llorando justo al entrar a casa arrepentida por haber deseado la muerte de su esposo y el coronel Fitts volviendo a la suya con la ropa completamente ensangrentada y un arma en la mano. Mirando hacia atrás estos eventos desde el punto de vista del narrador, Lester está contento:


Las rosas son el elemento liminar y esencial de la película. "American Beauty" es el nombre de una variedad de las mismas cultivada artificialmente, un híbrido que reúne características de perfección, creado en Francia por Henri Lédéchaux en 1875, con el nombre original de "Madame Ferdinand Jamin". Metafóricamente, en la película se representa la "falsa belleza", que es solo apariencia lograda de manera artificial.



La represión de lo que uno realmente quiere/necesita/desea y la creación de un exterior superficial para ocultar las propias inseguridades es uno de los temas predominantes de la película:


La belleza puede encontrarse en todos los rincones si uno sabe cómo encontrarla. Como dice Angela, "no hay nada peor que ser ordinaria", porque ella piensa que lo es, aunque Lester piense lo contrario. Lester, en cambio, piensa que él es un "perdedor", aunque Angela lo encuentre "sexy", Jane odia su aspecto y piensa que ella es "aburrida" y Ricky, sin embargo, la encuentra fascinante.

Por tanto, como Ricky dice en su narración, incluso una bolsa de plástico vulgar ondeando al viento tiene una cierta suma de belleza, solo depende de cómo la mires. De ahí que todos los personajes de la película sean bellos y queribles de alguna manera, incluso aunque ellos mismos no puedan ser conscientes de eso.

La música de "American Beauty" fue compuesta por Thomas Newman. La banda sonora de la película tiene canciones de artistas tan populares como The Who, The Guess Who, Bill Withers, Free, Eels, The Folk Implosion, Gómez y Bob Dylan, la versión de la canción de The Beatles "Because" interpretada por Elliott Smith.

La reacción de la crítica a "American Beauty" fue abrumadoramente positiva, empezando ya tres meses antes del estreno de la película, cuando el redactor del "New York Times" Bernard Wainraub escribió una columna entusiasta sobre la película describiéndola como «lo más hablado sobre el cine del momento». La columna, que salió el fin de semana del 4 de julio, dio pocos detalles de la película, pero denotó que la misma estaba generando un "tremendo ruido" en el estudio de Dreamworks —los detalles de cómo y cuándo se estrenaría el filme estaban todavía debatiéndose—. También informaron que Steven Spielberg (cofundador de DreamWorks) dijo que la película era una de las mejores que había visto en años y que Bening le había hecho llorar en una de las primeras visiones de la película.
La película se estrenó el 8 de septiembre de 1999 en Los Ángeles (California) y las críticas anticipadas se reafirmaron uniformemente elogiando tanto el reparto como el guion, la fotografía y la dirección de la primera película de Mendes. Escribiendo para el "San Francisco Chronicle", Edward Guthman dijo de ella que era «una historia deslumbrante de la soledad, el deseo y los vacíos de conformidad». Jay Carr para el "Boston Globe" dijo «un clásico del milenio», el "New York Post" dijo «una pieza maestra a todo gas». Entre los pocos críticos que expresaron opiniones negativas de la película estaban J. Hoberman del "Village Voice" y Wesley Morris del "San Francisco Examiner", que fueron críticos con el guion y la dirección, pero no de sus actuaciones.
El 11 de septiembre, se presentó al Festival de Toronto donde ganó el premio del público. Ayudada por las tremendas críticas positivas, la película recaudó $861,531 en su primera semana en cartelera en Estados Unidos, a pesar de proyectarse solo en 16 salas. En octubre, la película se estrenó para un público mayoritario y rápidamente sobrepasó el presupuesto estimado de la película de $15000000. Finalmente, la película ganó $356296601 en todo el mundo.

La película dominó los Premios Óscar de 1999, con un total de ocho nominaciones. También ganó otros 82 premios y fue nominada a 63 más en numerosas ceremonias de entrega de premios. 









En español:


En inglés:


</doc>
<doc id="1332" url="https://es.wikipedia.org/wiki?curid=1332" title="Rosemary's Baby (película)">
Rosemary's Baby (película)

Rosemary's Baby (en Hispanoamérica, El bebé de Rosemary; en España, La semilla del diablo) es una película estadounidense de terror-dramática de 1968 escrita y dirigida por Roman Polański y protagonizada por Mia Farrow, John Cassavetes, Ruth Gordon, Sidney Blackmer, Maurice Evans y Ralph Bellamy como actores principales. Está basada en la novela homónima de Ira Levin. La película obtuvo un (Ruth Gordon), y Polański obtuvo una candidatura al Óscar en la categoría de Mejor Guion Adaptado.

Rosemary Woodhouse (Mia Farrow) es una joven ama de casa que está casada con el actor de teatro Guy Woodhouse (John Cassavetes). La pareja se instala en un apartamento de la Casa Bramford, antiguo edificio de apartamentos en Manhattan, (Nueva York). El apartamento tiene una leyenda un tanto sórdida debido a las siniestras reputaciones de algunos antiguos residentes. 

Rosemary es una mujer joven y alegre, le gusta estar dedicada a su hogar, anhela tener un bebé con Guy, quien por su parte, egoistamente desea alcanzar el estrellato. Por circunstancias accidentadas, los Woodhouse traban amistad con Roman Castevet (Sidney Blackmer) y Minnie Castevet (Ruth Gordon), un matrimonio de edad avanzada que vive en la misma planta del edificio, y que se convierten en una especie de padres sustitutos del joven matrimonio. Rosemary se hace amiga de Terri Gionoffrio (Victoria Vetri), una joven vecina del lugar que lleva un collar con una especie de raíz que le regalaron los Castevet después de acogerla en su casa.

Guy y Rosemary, al volver a la casa una noche, se sorprenden de ver una gran conmoción de personas y a la policía. Al parecer, Terri ha saltado del apartamento de los Castevet y se ha suicidado. Minnie y Roman llegan muy asustados, pero Rosemary los consuela diciéndoles que Terri habló mucho de ellos antes de matarse. Roman y Minnie invitan a Rosemary y a Guy a cenar. Guy parece haber logrado entablar una gran amistad con la pareja, pero Rosemary no confía tanto en ellos. Los Castevet les dan el collar de Terri, diciéndoles que el olor viene de una raíz llamada "Tanis".

Al poco tiempo, Guy consigue un papel en una obra en la que anteriormente había sido rechazado, después de que el actor que iba a aparecer, misteriosa e inexplicablemente, se queda ciego. Guy y Rosemary acuerdan tener el hijo tan deseado, y planean la fecha ideal para que ella quede embarazada. Aquella noche, Rosemary tiene un horripilante y extraño sueño, en el que ella se encuentra en la habitación, rodeada por los inquilinos del edificio (los Castevet incluidos), todos desnudos diciendo extrañas palabras, y que una criatura, Satanás (Clay Tanner), la está violando fuertemente y lastimando. La escena continúa hasta tal punto que Rosemary empieza a gritar que no es un sueño, pero se desmaya mientras la criatura sigue violándola.

Cuando despierta, Guy se disculpa por haberle ""hecho el amor" mientras estaba inconsciente", y ella descubre que está embarazada. Su amiga Elise (Emmaline Henry) le recomienda al Dr. Hill, pero los Castevet intervienen y le recomiendan al Dr. Abraham Sapirstein (Ralph Bellamy), que le da de beber un jugo que dice ser mejor que las vitaminas habituales. Durante los primeros tres meses del embarazo, Rosemary sufre fuertes dolores abdominales, le toma el gusto a la carne cruda y el hígado de pollo, y pierde mucho peso. El médico le dice que los dolores desaparecerán y que siga consumiendo la bebida. Hutch (Maurice Evans), un amigo de Rosemary, ve que Minnie le agrega la extraña "raíz Tanis" al jugo de Rosemary, y le molesta mucho, por lo que decide investigar lo que ocurre.

Sin embargo, el mismo día que Hutch planea compartir con Rosemary sus hallazgos, misteriosamente, cae en coma unas horas antes de la reunión y fallece tres meses después. Sin embargo, pocos días antes de morir, Hutch recupera brevemente la conciencia y, aprovechando esto, le da instrucciones a otra amiga, Grace Cardiff, entregándole un libro de brujería y un mensaje que Grace le da a Rosemary en el funeral: "el nombre es un anagrama".

Con esto y con el libro, Rosemary descubre que Roman Castevet es en realidad Steven Marcato, el hijo de un anterior inquilino, Adrian Marcato, quien fue acusado de brujería y posteriormente asesinado. Ella deduce que planean usar a su bebé para un culto extraño y que Guy cooperó con ellos para que sabotearan al actor y su carrera despegara. Luego se entera de que el Dr. Sapirstein es parte de la conspiración, y que ellos asesinaron a Hutch para que no los delatara. Rosemary comparte sus problemas con el Dr. Hill, y este cree que delira, así que llama a Sapirstein y a Guy. Ellos le dicen a Rosemary que si coopera, ni ella ni el bebé se verán perjudicados. Los dos hombres se llevan a Rosemary al apartamento, donde entra en trabajo de parto. Al despertar, le dicen que el bebé ha muerto, pero se oyen llantos en el edificio.

Rosemary descubre una puerta secreta y entra en el apartamento de los Castevet, donde ellos se encuentran reunidos delante de un bebé (al cual no se le ve el rostro). Al ver esto, ella exige saber la causa de la deformidad, pero rápidamente descubre que el ente que la violó era en realidad Satanás, que no fue un sueño, y se horroriza. Roman la calma y le dice que le dé una madre al niño y que ni ella ni Guy se tienen que unir a la secta si no quieren. La película termina con Rosemary arropando al niño y meciendo la cuna lentamente.


En Rosemary's Baby: A Retrospective, una edición especial en DVD de la película, el guionista y director Roman Polanski y el productor ejecutivo de Paramount Pictures Robert Evans, junto con el diseñador de producción, Richard Sylbert, rememoran algunos detalles sobre la producción. En dicho DVD, Robert Evans recuerda que William Castle le trajo las primeras galeradas de la novela de Ira Levin y le pidió comprar los derechos para la adaptación cinematográfica aún antes de que Random House, la editorial del escritor, publicara la novela. Como los responsables de la Paramount habían reconocido el potencial comercial de una posible adaptación, pronto estuvieron de acuerdo en que William Castle, que tenía una excelente reputación como productor de películas de terror de bajo presupuesto, podría producir, aunque no dirigir, la adaptación de película.

Por aquel entonces Robert Evans, quien ya conocía y admiraba las películas europeas de Roman Polanski, confiaba en poder convencerlo para que se involucrara en el proyecto, y con ello debutar en su primera producción para el cine estadounidense. Pronto Roman Polanski recibió de manos de Robert Evans, una primera y rústica versión del guion de "Rosemary's Baby" y quedó fascinado. Tanto es así, que leyó la novela original en una sola noche. A la mañana siguiente llamó a Robert Evans y le dijo que aquel guion era un proyecto muy interesante para su debut como cineasta en Estados Unidos, y que no solo le gustaría dirigirlo, sino participar en la redacción del guion final.

En su lectura de la novela, Roman Polanski imaginó al personaje principal, Rosemary, como una chica robusta física y mentalmente, pero también normal y corriente, ni guapa ni fea. Para ello pensó que el papel lo podría interpretar en un principio la actriz Tuesday Weld. Pero Robert Evans tenía sus dudas al respecto, ya que el libro todavía no había alcanzado la posición de best seller, Evans no confiaba en que el título del film por sí mismo garantizase la atención del público, y pensaba que para ello se precisaba de otra actriz más conocida. Con papeles secundarios en películas como "Guns at Batasi" y la por aquel entonces aún no estrenada "A Dandy in Aspic" no parecía que Mia Farrow tuviera una gran filmografía, pero su papel de "Allison MacKenzie" en la serie de televisión "Peyton Place", así como su reciente matrimonio con Frank Sinatra la convertían en una actriz interesante para el papel, según Evans. A pesar de su apariencia endeble y alicaída, Polanski finalmente le hizo una prueba. Desgraciadamente, aceptar este papel supuso muchos problemas en el matrimonio de Mia Farrow. Frank Sinatra, quien le exigió a su mujer que abandonara su carrera cuando se casaron, fue el primero en protestar, y a la larga le pidió el divorcio a mitad del film y ante todo el equipo de rodaje. Mia Farrow, en un intento de salvar su matrimonio, le suplicó al productor Robert Evans que le rescindiera su contrato. Sin embargo, él la convenció para que siguiera en el proyecto cuando le mostró metraje del film todavía no montado. Tras verlo, Mia Farrow decidió continuar, porque Evans le aseguró que con esta película conseguiría la nominación al premio Óscar a la mejor actriz protagonista, cosa que nunca sucedió.

Para interpretar el papel de "Guy Housewood", el marido de "Rosemary", Robert Redford fue la primera opción, pero este, por alguna razón, rechazó el papel. Pronto se pensó en Jack Nicholson, pero finalmente se impuso el criterio de Polanski y se eligió a John Cassavetes.

El diseñador de producción, Richard Sylbert, fue quien propuso a Ruth Gordon para el papel de "Minnie Castevet", la entrometida vecina. Ahora solo faltaba ubicar a todos los personajes en el edificio donde tenía lugar la acción: el ficticio edificio Bramford. Sylbert creyó que usar el edificio Dakota sería una buena idea. Dicho edificio, situado en la parte alta del Westside, en Manhattan, Nueva York, era famoso por la cantidad de personas vinculadas al mundo del espectáculo que vivían en él. Pero el edificio ya se estaba ganando su mala fama como lugar problemático: los propietarios no dieron su permiso para que se filmara en su interior, y Polanski no estaba satisfecho con el grado de oscuridad y penumbra de sus vestíbulos y pasillos. A la sazón, el edificio solo fue usado para las tomas exteriores que reflejaban en la ficción la "Casa Bramford".

Por otro lado, Polanski quiso contratar a viejas estrellas de Hollywood para los miembros del aquelarre, pero no conocía a ninguna personalmente. Para el aquelarre dibujó bosquejos de cómo había previsto cada personaje, y fueron finalmente los propios actores elegidos quienes tuvieron que terminar de crear sus papeles. En cada caso, el actor elegido se parecía físicamente a los dibujos de Polanski; estos fueron Ralph Bellamy, Patsy Kelly, Elisha Cock Jr, Phil Leeds, y Hopes Summers. 

Mia Farrow tuvo que lucir una peluca en prácticamente la primera mitad del metraje, y no fue hasta después, cuando ya lucía su embarazo ficticio, que se la pudo ver con su auténtico peinado, el que ella misma anuncia como la última moda de Vidal Sassoon. Como contrapartida a esto, también la actriz estadounidense vivió momentos muy amargos durante el rodaje. Una de las escenas de la película más cargadas emocionalmente era aquella en la que, en medio de una fiesta celebrada en su apartamento, sus amigas echan de la cocina a Guy, su marido, mientras tratan de consolarla a causa del embarazo tan traumático de Rosemary. Dicha escena fue rodada en un solo día, pero justo después de filmar la primera toma de la escena, un mensajero irrumpió en el set de rodaje, trayendo consigo toda la documentación referente al divorcio de Mia Farrow enviada por Frank Sinatra. Cuando la actriz leyó los documentos rompió a llorar sobre el suelo de la cocina, tal y como el personaje de Rosemary hace al comunicar a sus amigas lo extrañamente mal que siente su embarazo. Alarmado, Polanski quiso suspender la filmación de aquella escena por aquel día y concentrarse en otras que no implicaran la presencia de la actriz. Pero Farrow, en un arranque de profesionalidad, le suplicó al director continuar con el plan de trabajo original, y la escena se pudo terminar sin más complicaciones.

Polanski no deseaba que en ningún momento apareciese el "bebé de Rosemary", pues de esa forma, y con razón, daría más miedo imaginárselo. Pero los demás lo convencieron de "siempre mostrar al monstruo", por lo que, muy a su pesar, Polanski agregó, al final de la cinta, la toma de unos ojos amarillos que miran a la cámara.

En 1976 se estrenó en los Estados Unidos una miniserie para la televisión titulada "Look What's Happened to Rosemary's Baby" en donde se retomaban algunos personajes de la novela original de Ira Levin. Aunque Mia Farrow no participó en la producción, su personaje fue interpretado por la actriz Patty Duke, y Ruth Gordon repitió el papel de la entrometida vecina, la excéntrica Minnie Castevet.



</doc>
<doc id="1333" url="https://es.wikipedia.org/wiki?curid=1333" title="Chinatown (película)">
Chinatown (película)

Chinatown (en español: "Barrio chino") es una película estadounidense de cine negro-dramática de 1974 dirigida por Roman Polanski y protagonizada por Jack Nicholson, Faye Dunaway y John Huston. La película ganó el Oscar al Mejor Guion Original y fue candidata a 10 premios más. Desde su estreno es considerada simultáneamente como un film clásico y de culto.

Forma parte del AFI's 10 Top 10 en la categoría de "Películas de misterio".

Los Ángeles, Años 30. El detective privado Jake Gittes (Jack Nicholson) recibe la visita de una mujer que dice ser la esposa del ingeniero de la compañía de agua de la ciudad, Hollis Mulwray (Darrel Zwerling), y que cree que le está siendo infiel; si bien, la verdadera esposa de Mulwray, Evelyn (Faye Dunaway) se presenta también en la oficina del detective en días posteriores, después de que Gittes hace el ridículo por haber sido ingenuamente engañado por la primera mujer, que luego se hace llamar Ida Sessions (Diane Ladd). Cuando Mulwray es asesinado, Gittes es contratado, dos veces, por dos diferentes clientes, para investigar el caso; y es entonces que empieza a descubrir que detrás de todo, como cabe esperar, está un enorme negocio inmobiliario, secretos familiares y mucha codicia.




</doc>
<doc id="1335" url="https://es.wikipedia.org/wiki?curid=1335" title="Roma, ciudad abierta">
Roma, ciudad abierta

Roma, ciudad abierta ("Roma, città aperta") es una película italiana dirigida por Roberto Rossellini en el año 1945. Junto con "Ladrón de bicicletas", es considerada la obra maestra del neorrealismo italiano.

La acción se desarrolla en Roma, en los últimos años de la ocupación nazi: 1943 y 1944. Se inspira en la historia verídica del sacerdote Luigi Morosini, torturado y muerto por los nazis por ayudar a la resistencia.

En la Roma de 1943 y 1944, se entretejen las historias de varias personas relacionadas con la Resistencia. Durante la ocupación, el padre Pietro protege a los partisanos y, entre otros, da asilo a un ingeniero comunista: Manfredi. Pina, una mujer de pueblo, está de novia con un tipógrafo que lucha en la resistencia. Cuando la policía lo arresta, Pina corre desesperadamente tras el camión que se lo lleva, pero cae asesinada por una ráfaga de ametralladora ante los ojos de su hijo. Poco después, también el padre Pietro y el ingeniero -éste traicionado por su ex amante drogadicta- son arrestados. Manfredi muere por las atroces torturas que le infligen los alemanes para que revele el nombre de sus compañeros de resistencia. El padre Pietro corre la misma suerte: lo fusilan en presencia de los niños de la parroquia, entre los cuales se encuentra el hijo huérfano de Pina.

Rossellini comenzó a trabajar en el guión en agosto de 1944, a solo dos meses de terminar la ocupación alemana, con la colaboración de Federico Fellini y de Sergio Amidei. Según sus propias palabras, estaba movido por una fuerte necesidad de narrar los acontecimientos recientes, y literalmente salió a la calle a buscar historias (el argumento está basado en parte en sucesos reales). Comenzó a rodarse en enero de 1945, tanto en estudios como en locaciones de la ciudad devastada, siendo esto último algo que caracterizaría al neorrealismo. También sería característico el empleo de actores extraprofesionales: de los actores de "Roma, ciudad abierta", solo eran de la profesión Anna Magnani y Aldo Fabrizi.


En su lanzamiento, la película fue víctima de la censura. En Estados Unidos se la recortó, reduciendo su duración en un cuarto de hora. En Argentina fue retirada de exhibición por una orden anónima del gobierno en 1947. En la Alemania Occidental fue prohibida desde 1951 hasta 1960.







</doc>
<doc id="1338" url="https://es.wikipedia.org/wiki?curid=1338" title="Capricho de mujer">
Capricho de mujer

Capricho de mujer es una película estadounidense de 1942, del género comedia, dirigida por Mitchell Leisen. Protagonizada por Marlene Dietrich y Fred MacMurray en los papeles principales. 

Existe una producción británica del mismo nombre "The Lady Is Willing" de 1934, con un argumento distinto.

Clasicismo y elegancia en una de las escasas comedias de Marlene Dietrich.

</doc>
<doc id="1339" url="https://es.wikipedia.org/wiki?curid=1339" title="Drácula, de Bram Stoker">
Drácula, de Bram Stoker

Drácula de Bram Stoker, es una película estadounidense de terror y romance estrenada en 1992. Dirigida por Francis Ford Coppola y producida por Columbia Pictures; el guion de la cinta fue escrito por James V. Hart basándose en la novela "Drácula" de Bram Stoker. La película fue protagonizada por Gary Oldman, Winona Ryder, Keanu Reeves y Antony Hopkins. La banda sonora corrió a cargo de Wojciech Kilar, excepto el tema final «Love Song for a Vampire», que fue compuesto por Annie Lennox. Tuvo un presupuesto de 40 millones de dólares, una cantidad extraordinaria para una película de terror (género que en aquellos momentos no estaba de moda y que se solía rodar con presupuestos muy modestos). La película tuvo una buena acogida por el público y consiguió 215, 862, 692 dólares en todo el mundo, hecho que significó el retorno al éxito de Francis Ford Coppola y de su productora cinematográfica American Zoetrope. En la de entrega de los Premios Óscar la película obtuvo tres premios en la categoría a para Eiko Ishioka, para Tom C. McCarthy y David E. Stone y por último a para Greg Cannom, Michèle Burke y Matthew W. Mungle. 
En 1897, a finales del siglo XIX, Jonathan Harker (Keanu Reeves), recientemente recibido como abogado, debe viajar hasta Transilvania para que el Conde Drácula (Gary Oldman) firme unos papeles referentes a unas propiedades que acaba de adquirir en Londres. El problema es que el conde no es quien dice ser: en realidad, es el mítico príncipe rumano Vlad Tepes, ferviente caballero de la Orden del Dragón, que se transformó en "vampiro humano" una vez que reveló toda su ira contra Dios, luego que el ejército turco con la falsa noticia de su muerte en batalla empujara al suicidio a su esposa la princesa Elizabetha, el gran amor de su vida, y se tiñeran de sangre y lágrimas las aguas del río Arges, a las que se arrojó. Extrañamente, la novia de Harker, Mina Murray (Winona Ryder), pasaría a ser la viva reencarnación de la princesa rumana cuatrocientos años después. Por esa razón, Drácula decide viajar hasta la capital británica para conquistarla. Mina, luego de conocerlo, accede a tener un romance furtivo con el misterioso príncipe rumano, para lo cual tendrá que luchar entre las fuerzas del bien y del mal, antes que el amor inmortal que existía entre ambos logre triunfar finalmente.


Se rumoreaba mucho acerca de que Coppola, además de dirigir la película, también sería el encargado de adaptar la novela a un guion cinematográfico. Pero finalmente, los productores le cedieron la tarea a James V. Hart, ya que llevaba bastante tiempo trabajando con una adaptación de la novela original.

Ha habido mucha controversia acerca de la lealtad del guion de Hart a la novela de Bram Stoker, y actualmente esta película es considerada la mejor adaptación a la obra de Stoker, ya que si bien aparecen en ella todos los personajes, sus personalidades son tergiversadas. Drácula en el castillo aparece con un aspecto decrépito y un peinado estrafalario, y cuando llega a Londres y rejuvenece se convierte en un petimetre. Las dos jóvenes, Lucy Westenra y Mina Murray, también son deformadas: de lo que en la novela son bellas, decentes, nobles, delicadas y refinadas, en la película son lo contrario: Lucy Westenra es una pelirroja coqueta que intenta ser seductora de manera grotesca, y Mina Harker le es infiel a su esposo Jonathan Harker, pues se enamora de Drácula y tiene un romance con él; este idilio no solo es una ofensa a la dignidad de Mina sino que además no existe en absoluto en la novela, pues Mina es decente y fiel.

El filme está dirigido por Francis Ford Coppola. Los productores habían pensado en otros directores de géneros de terror como William Friedkin o John Carpenter, pero finalmente optaron por Coppola. Muchos de los productores dudaban acerca de si Coppola cumpliría las expectativas, ya que últimamente este director sufría múltiples problemas financieros debido a desastres cinematográficos; había dirigido películas de gran costo, pero escasa recaudación, como "El Padrino III" o "Apocalypse Now". Coppola esta vez se fijó más en bienes creativos que económicos y puso todo su empeño en hacer innovaciones que nunca se habían hecho, y finalmente no solo cumplió los requisitos de la película, sino que hizo que fuese una de las películas más taquilleras del año. Hay que sumar también que fue una de las películas que salvaría al director de su crisis tanto económica como profesional, haciendo que Coppola recuperar su prestigio perdido en el mundo del cine.

La banda sonora original estaba compuesta por el compositor polaco Wojciech Kilar, que conocería a Coppola en uno de sus conciertos en Francia, y al que ofrecería un debut en los Estados Unidos componiendo la música de la película.

Su banda sonora estuvo a punto de ser seleccionada para una nominación a los Oscars, pero por determinaciones desconocidas de los productores, no querían que la música de Kilar fuera seleccionada.

El tema principal de la película "Love Song for a Vampire" ("Canción de amor para un vampiro") fue escrita por Annie Lennox, que juntándola con el trabajo de Kilar, saldría al mercado en un disco con la banda sonora y los temas interpretados por Lennox. Este disco cosechó un gran éxito en los Estados Unidos, y también en gran parte de Europa, especialmente en Polonia, con la razón de que era el debut de un compositor polaco en el cine estadounidense.

Debido a constantes críticas hacia la película por sus escenas violentas y en muchos casos desalentadoras, la producción no tuvo más remedio que cortar muchas de las escenas de la película hasta finalizarla con 120 minutos de duración, pero supuestamente, con las escenas recortadas, el filme debería haber durado 145 minutos. Muchos fanáticos de la novela se quejaron al respecto, ya que una desintegración de la película equivaldría a menor expresión creativa del libro. Poco después del estreno de la película, circularon estas escenas cortadas de la película por las incipientes webs. Finalmente, cuando salió a la venta la versión de la película en VHS y DVD, se incluirían tales escenas suprimidas, y mostrando así al público, una versión más extendida, en la que se incluían escenas bastante sarcásticas, incluso desnudos de Winona Ryder.

La película a pesar de todo tendría una buena aceptación por parte de los críticos. La calificaron como la mejor adaptación cinematográfica de la novela que se había hecho nunca, ya que actualmente hay innumerables adaptaciones de la obra de Stoker. La reacción de los críticos, en general, fue positiva, pero se cuestionó mucho la fidelidad al argumento de la novela. Además, Keanu Reeves recibió bastantes críticas del público por su interpretación de Jonathan Harker. Sin embargo, el film fue un notable éxito de taquilla, recaudando 82,522,790 $ en su país de origen y 133,339,902 $ en el resto del mundo, con una recaudación total de 215,862,692 $, convirtiéndose en la adaptación de la novela más exitosa comercialmente hasta la fecha. La representación de Drácula por parte de Gary Oldman fue alabada por muchos críticos y ganó el Premio Saturn al Mejor Actor.







</doc>
<doc id="1341" url="https://es.wikipedia.org/wiki?curid=1341" title="Coogan's Bluff">
Coogan's Bluff

Coogan's Bluff (en España, La jungla humana; en Hispanoamérica, Mi nombre es violencia) es una película estadounidense de 1968 del género policíaco. Fue dirigida por Don Siegel, y contó con Clint Eastwood, Susan Clark, Lee J. Cobb, Tisha Sterling, Don Stroud y Betty Field en los papeles principales.

En un desolado desierto de Arizona, el alguacil Walt Coogan ("Clint Eastwood") montado en su jeep, se dirige a una montaña donde se oculta un fugitivo de origen Navajo ("Rudy Díaz"). Ya habían pasado tres días de persecución y finalmente había encontrado al fugitivo. Este, oculto entre las rocas, ya lo tiene en la mira de su rifle, cuando repentinamente Coogan gira su vehículo varias veces dejando tras de sí una nube de polvo. El navajo espera que la nube desaparezca, y cuando lo hace, ve que Coogan ha desaparecido. A los pocos minutos siente a sus espaldas el sonido del amartillamiento de un arma. Es Coogan que lo ha capturado. El alguacil y su prisionero regresan a la ciudad, pero en el camino Coogan se desvía para visitar la casa de su amante Millie ("Melody Johnsson"). La despierta con un beso, pero ella le exige que tome un baño antes de dedicarse al amor. El sheriff del condado, McCrea (Tom Tully) y un ayudante pasan en su patrullera por las cercanías y avistan el jeep de Coogan, entran silenciosamente a la casa y lo sorprenden en la bañera. Luego de llamarle la atención por haber dejado al prisionero esposado al jeep, mientras él se dedicaba al amor, el sheriff le da una hora para que se presente en el cuartel. Ya en el cuartel, el sheriff le encomienda una nueva misión, esta vez en la ciudad de Nueva York. Allí deberá recoger a un asesino fugado, James Ringerman ("Don Stroud"), que ha sido capturado por la policía neoyorquina, y traerlo con él a Arizona para ser juzgado. 

Coogan emprende viaje, y desembarca finalmente en el helipuerto del edificio MetLife Building en Nueva York, llevando puestos su sombrero alón, su lazo bolo al cuello y sus botas puntudas. Se presenta en el cuartel de policía para recoger al delincuente buscado, y luego de aclarar varias veces que él viene de Arizona y no de Texas, se entrevista con el teniente detective McElroy ("Lee J. Cobb"), que le informa que Ringerman está internado en el Hospital Bellevue, recuperándose de una sobredosis de LSD, y que hay que esperar a que le den de alta. Además, el teniente le dice a Coogan que tiene que seguir el procedimiento judicial y obtener los papeles de extradición de Ringerman en la Corte Suprema del estado de Nueva York, antes de poder recoger al preso. El alguacil de Arizona, que no está dispuesto a que reglas burocráticas demoren su trabajo, decide buscar la forma de eludirlas. En el cuartel es testigo de como una atractiva funcionaria, Julie Roth ("Susan Clark") es manoseada frente a sus ojos por un joven, y decide intervenir dándole a él una bofetada. Extrañamente, ella se enoja por su acción y el golpeado joven aprovecha para abandonar rápidamente la habitación, luego ella le explica a Coogan que el joven es uno de los participantes del programa de rehabilitación que ella dirige y que su intervención ha causado que el joven abandone su programa. Coogan se disculpa y le ofrece salir a cenar como compensación. Como Julie lo rechaza, se muestra interesado en el programa de rehabilitación y tomándola del brazo abandonan el cuartel. Ya en el apartamento de ella, intenta seducirla, pero ella lo rechaza nuevamente. Frustrado, se va de allí.

Se dirige luego al Hospital Bellevue, donde muestra sus credenciales de policía de Arizona, y consigue engañar al personal del hospital, logrando que le entreguen a Ringerman para llevárselo. Ringerman, que estaba acompañado de una muchacha hippie, debe seguirlo. Muy ufano, parte con su prisionero hasta el helipuerto para tomar el primer vuelo a Arizona; pero no contaba con la muchacha que estaba acompañando a Ringerman en el hospital, que los había estado siguiendo sin que Coogan se diera cuenta. Acompañada de un matón llamado Pushie ("David Doyle"), sorprenden a Coogan, lo golpean, aturdiéndolo, y escapan llevándose a Ringerman con ellos. Ringerman aprovecha para robar el revólver de Coogan. Las cosas no habían salido tan fáciles como el alguacil las había planeado. 

Coogan averigua el domicilio de la madre de Ringerman, Ellen Ringerman ("Betty Field") buscando información sobre su hijo. Ella, que lo recibe llamándolo" Buffalo Bill", se niega a dar ninguna información y comienza mostrarle los regalos que había recibido de su hijo, para demostrarle al alguacil lo buen hijo que era.. En el recorrido por el apartamento Coogan nota una fotografía donde aparecen Ringerman y la muchacha del hospital. La madre inadvertidamente le dice que ella se llama Linny Raven ("Tisha Sterling"), el alguacil anota el nombre y se retira escuchando los insultos de la madre de Ringerman. Ya en la calle, es arrestado por el sargento de policía Wallace ("James Edwards"), acusado de hacerse pasar por policía de Nueva York en el Hospital de Bellevue. De regreso en el cuartel, nuevamente se encuentra con Julie Roth y se acerca a ella para ver si puede obtener información sobre Linny Raven, ya que ella podía ser una de las jóvenes descarriadas de su programa de rehabilitación. Coogan logra que ella lo invite a cenar, para hablar del programa. Ya en el apartamento, le pregunta si conocía a Linny Raven, lo que Julie le confirma, advirtiéndolo de no provocar más problemas. Él le dice que solo era curiosidad e intenta seducirla nuevamente, esta vez con más éxito. En un momento en que ella desaparece en la cocina para seguir preparando la cena, Coogan nota el archivo donde Julie tenía su programa de rehabilitación. Toma la decisión y lo abre, encontrando el archivo de Linny Raven. Lo lee rápidamente y abandona silenciosamente el apartamento. Julie sale de la cocina y no lo encuentra. 

Coogan, en tanto, busca a Linny Raven en una discoteca psicodélica a la cual ella solía acudir, según constaba en su reporte. Luego de recorrer el local en penumbras repleto de gente bailando, llega a una habitación donde estaba un grupo de fumadores de marihuana. Linny Raven sentada en una mesa con unos amigos ya drogados, lo ve y lo llama, Coogan se dirige a ella y le dice que quiere conversar con ella a solas, lo que molesta a uno de los acompañantes de la muchacha, llamado Wonderful Digby ("Albert Popwell") que intenta sacar disimuladamente un puñal escondido en su bota para atacarlo. Coogan de da cuenta, coge una botella que estrella en la mesa y coloca el afilado borde de vidrio frente a la cara de su atacante, exigiéndole que entregue el puñal. Este obedece, Coogan lo toma y lo clava firmemente en la mesa antes de tomar a Linny del brazo para luego salir del local. La muchacha lo invita a su departamento para conversar. Ya allí, Linny comienza a seducir a Coogan y él le sigue el juego, pero antes desea saber donde está oculto Ringerman. Ella le dice que se lo dirá después que hagan el amor. Terminado el acto amoroso, ambos salen en dirección a un salón de billar, donde según Linny, se encuentra Ringerman, pero en realidad lo lleva a una emboscada. Al poco de entrar en el oscuro salón, Linny se dirige a Pushie, el matón que la había ayudado en el rescate de Ringerman y dueño del salón, y le dice que Coogan está desarmado. Acto seguido, el resto de hombres que estaba en el salón se arrojan sobre Coogan para golpearlo, y se desencadena una pelea feroz. Coogan semiaturdido en el piso, escucha la sirena de una patrullera que llegaba al local, lo que hace que sus agresores huyan rápidamente y él decide hacer lo mismo. Antes de irse, el golpeado alguacil golpea violentamente a Pushie como despedida. Los policías entran en el local y se encuentran con un destrozo general y tres contendientes desmayados. El teniente McElroy hace su entrada y recorriendo el lugar encuentra el sombrero de Coogan en el piso. 

Ya avanzada la madrugada, el alguacil regresa maltrecho a su hotel y comienza a curar sus heridas frente a un espejo. Unos golpes urgentes en la puerta lo interrumpen, y cuando abre la puerta se encuentra con Julie, que le enrostra su comportamiento con Linny Raven, quien la ha llamado por teléfono y le ha contado con detalles su noche pasada con él. Una vez que Julie se va, Coogan regresa al departamento de Linny, y esta vez no hay amor, sino una agresión física y una amenaza de muerte del alguacil. Linny, asustada, le confiesa que Ringerman está oculto en el museo del parque Fort Tryon Park llamado "The Cloisters", y hacia allá parten los dos. 

Linny se adelanta para advertir a Ringerman de la presencia de Coogan. El fugitivo pierde el control cuando escucha la voz del alguacil que lo llama y comienza a disparar a su alrededor, con el revólver que le había robado anteriormente. Cuando se le acaban los tiros, arroja el arma y huye hasta donde tenía su motocicleta, abandonando a Linny. En la huida se estrella con otro motorista y el motor de su motocicleta se detiene. Coogan aparece corriendo tras él, pero Ringerman logra hacer partir su vehículo y continúa su huida. Coogan coge la motocicleta caída y comienza una persecución a alta velocidad por el parque. Finalmente Coogan consigue alcanzar a Ringerman y estrella su motocicleta contra la de él. La persecución continúa a pie. 

Unas patrulleras llegan al parque y los policías son testigos del último golpe de puño de Coogan en la cara de Ringerman, antes de recibirlo desfalleciente. El teniente McElroy baja del automóvil policial y ordena a los policías que regresen a Ringerman al Hospital Bellevue. Coogan, a sabiendas de que su acción persecutoria es ilegal, se justifica con el argumento de que ha hecho "un arresto ciudadano" y le pregunta cuando le van a entregar a Ringerman. El teniente le repite el procedimiento judicial que debe seguir. 

Coogan, acepta esta vez. En la última escena Coogan, esposado a Ringerman, se prepara para subir al helicóptero que los llevará al aeropuerto, cuando aparece el teniente McElroy para despedirse y regresarle el sombrero a Coogan. Tras el teniente aparece Julie, que también viene a despedirse y alcanza a decirle algunas palabras. El helicóptero se prepara para emprender vuelo mientras Coogan saca un cigarrillo, y ante la mirada ansiosa de Ringerman, le coloca uno en la boca y se lo enciende, para luego encender el suyo. El helicóptero se eleva y Julie se despide de Coogan lanzándole un beso y agitando su mano.

La película tiene varias características que le dan un carácter destacado: 



</doc>
<doc id="1342" url="https://es.wikipedia.org/wiki?curid=1342" title="Rosetta">
Rosetta

Rosetta hace referencia a varios artículos:







</doc>
<doc id="1344" url="https://es.wikipedia.org/wiki?curid=1344" title="La loba (película de 1941)">
La loba (película de 1941)

La loba (originalmente en inglés The Little Foxes) es una película dirigida por William Wyler en el año 1941, y protagonizada por Bette Davis. 

Está basada en la obra de teatro del mismo título de Lillian Hellman, que también escribió el guion. La mitad del reparto (Dan Duryea, Patricia Collinge, Richard Carlson, Charles Dingle) fueron los actores que habían interpretado el papel en la versión original de Broadway, estrenada en el año 1939.

El título original "The Little Foxes" hace referencia a la Biblia, que en el Cantar de los Cantares dice:

La acción u obra transcurre a finales del siglo XIX en una pequeña ciudad del sur de los Estados Unidos. Regina (Bette Davis), la esposa del banquero local, Horace Giddens (Herbert Marshall), junto a sus dos hermanos, Ben (Charles Dingle) y Oscar (Carl Benton Reid), individuos de pocos escrúpulos, deciden llevar a la práctica el sueño de toda su vida: levantar una gran fábrica de algodón llevada por mano de obra barata y con la que se harán aún más ricos. Ben y Oscar conspiran con su hermana Regina, para que consiga que su marido invierta en el negocio, ya que él es el auténtico dueño de su fortuna. Regina envía a su hija, Alexandra (Teresa Wright), a buscar a Horace, que está en Baltimore recuperándose de un ataque al corazón.

Horace rehúsa la oferta amparándose en su frágil estado de salud y Regina insiste y le excita, pero Horace se mantiene en sus trece. En realidad a Horace le preocupa el estado de su hija y procura apartarla del ambiente de esa familia. Ante esto y desesperados, Ben y Oscar persuaden a Leo (Dan Duryea), el sobrino de Horace, para que le robe a su tío, ya que trabaja en el banco de éste, y conoce el contenido de su caja de seguridad personal. Sospechando el robo, Regina intenta chantajear a sus hermanos para que le den su parte del negocio. Pero Horace se adelanta y desbarata el plan. Cuando vuelve a casa, Horace le comunica que ha cambiado el testamento y que ella no se llevará nada más que deudas. Horace sufre una crisis cardíaca y Regina le niega la medicina, provocándole así la muerte. Sin embargo, antes de morir usa sus últimas fuerzas en pedir a su hija que se aleje de su madre y que se case con David, un periodista al que Regina rechaza. Mientras Ben comenta con su hermana las circunstancias de la muerte de Horace, Alexandra les escucha, y descubre la maldad de su madre y finalmente encuentra las fuerzas para abandonar esa casa, y marcharse con David. Regina, abatida, la ve alejarse desde la ventana.



</doc>
<doc id="1348" url="https://es.wikipedia.org/wiki?curid=1348" title="Gloria">
Gloria

Gloria hace referencia a varios artículos:








En particular, en el cristianismo:



</doc>
<doc id="1349" url="https://es.wikipedia.org/wiki?curid=1349" title="Geometría diferencial">
Geometría diferencial

En matemáticas, la geometría diferencial es el estudio de la geometría usando las herramientas del análisis matemático y del álgebra multilineal. Los objetos de estudio de este campo son las variedades diferenciables (al igual que en la topología diferencial) así como nociones de geometría de Riemann, por ejemplo las de conexión y curvatura (que no se estudian en la topología diferencial). 

Las aplicaciones modernas de la geometría diferencial están muy relacionadas con la física, especialmente en el estudio de la Teoría de la Relatividad.






</doc>
<doc id="1350" url="https://es.wikipedia.org/wiki?curid=1350" title="Geografía económica">
Geografía económica

La geografía económica es la rama de la geografía humana que relaciona la actividad económica (consumo y producción) con el lugar del mundo en que se lleva a cabo. Los geógrafos se interesan no solo por dónde están las cosas sino por qué están situadas en donde se encuentran, y la naturaleza de los procesos que afectan a consumidores y un conjunto de establecimientos de producción dentro de algún espacio definido. Los consumidores (todas las personas) son móviles, mientras que los establecimientos son fijos. Los consumidores se desplazan para consumir bienes y servicios, aunque en ocasiones son los productos los que se mueven desde el lugar de producción hasta el consumidor (entrega a domicilio), pero lo normal es que el producto y el consumidor se muevan hasta un lugar de encuentro: el mercado.

Teóricamente, en una economía de libre mercado, la demanda y la oferta se reflejan en los precios. Pero si introducimos la variable espacial necesitamos, también, tener en cuenta el coste del desplazamiento tanto del producto como de los consumidores, que se mide tanto en dinero como en tiempo empleado en el traslado. El precio refleja la última unidad (marginal) de un artículo o servicio colocado en el mercado, mientras que el valor depende de lo necesario que sea para el consumidor. 

Todas las personas son consumidores. Las fábricas que producen artículos y servicios se clasifican en industrias. Una empresa es una unidad de propiedad de negocio. En realidad, el espacio económico es todo menos homogéneo, y no todos los consumidores piensan y se comportan de la misma manera, y cambian en el tiempo lo que complica mucho el análisis geográfico de los fenómenos económicos. Y para complicar las cosas los sistemas económicos que se desarrollan en las diferentes regiones no están aislados unos de otros, sino que se interfieren. De cómo, por qué, dónde, cuándo sucede esto trata la geografía económica.

Desde el principio de su existencia el hombre ha buscado satisfacer sus necesidades básicas: reproducción, alimentación, vestido y casa, aprovechando los recursos que el medio le proporciona.
Las formas de vida de los grupos humanos se fueron complicando conforme avanzaba la civilización, pasando por varias etapas: recolección, pastoreo, pesca, agricultura, ganadería, industria, etc.

El comercio es la actividad que más ha influido en el modo de vida de los grupos humanos, pues ya no producen para satisfacer únicamente sus necesidades, sino lo hacen con el fin de intercambiar sus productos con los de otros grupos dedicados a distintas actividades. De esta manera se inicia la división del trabajo y la regionalización de las actividades productivas.
Estos cambios en la forma de vida se aceleran con el desarrollo de las actividades industriales, comerciales, medios de transporte y comunicación, conformando las actuales formas económicas de la sociedad moderna.

Para comprender las diferentes formas de organización económica y explotación de los recursos naturales que se realizan en las diferentes regiones y países del mundo, además de los factores geográficos, deben conocerse otros aspectos tales como: la revolución tecnológica del siglo XX, que determinó una creciente automatización, la aplicación de tecnologías adecuadas, disponibilidad de capitales, existencia de mano de obra calificada, estabilidad de los gobiernos y políticas administrativas estimulantes. Por último, se debe tener en cuenta la organización económica del mundo, dividido en grandes bloques económicos que tienen una influencia muy significativa en sus respectivas áreas. 

Todos estos hechos son estudiados y analizados por la Geografía Económica, a partir de la localización, causalidad y relación de los fenómenos económicos, por lo que su importancia es evidente.

La geografía económica analiza la combinación de factores naturales y espaciales en el estudio de las actividades económicas de una región o un país.

Esta especialidad estudia la localización y naturaleza de las actividades económicas, los patrones de uso de la tierra, el valor de la misma en relación con las vías de transporte, la rentabilidad del suelo, la distribución espacial de las actividades productivas en las ciudades y el mundo.

La geografía económica estudia las relaciones oferta-demanda desde una perspectiva espacial, para ello analiza la localización y características de los lugares "productores" y su relación espacial y temporal con los lugares "consumidores". Estos procesos están relacionados con las leyes de mercado, comercio nacional e internacional, los procesos de mundialización de la economía y la situación económica propia de cada país.

Una manera de entender las relaciones entre las actividades económicas y el espacio es por medio del análisis de los sectores económicos, pues es el aumento de productos implica así mismo una gran diversidad en las formas de producirlos. La clasificación de los sectores económicos se ha establecido según criterios nacionales adoptados por los diferentes países. De este modo los sectores económicos se clasifican en:

Abarca todas las actividades económicas que se basan en la extracción de bienes y recursos naturales. Las principales actividades del sector primario son la agricultura, la pesca, la explotación forestal, la explotación minera, la producción de energía y la captación de agua, de manera que están fundamentalmente vinculadas al ámbito rural. Estas constituyen la oferta básica de recursos e insumos para las demás actividades.

Incluye las actividades de transformación de bienes y recursos extraídos del medio natural. Estos procesos se desarrollan fundamentalmente en ámbitos urbanos, aprovechando la existencia cercana de mano de obra y de potenciales consumidores. Comprende todas las actividades económicas de un país relacionadas con la transformación de industrias de alimentos y otros tipos de bienes o mercancías. Forma parte de la actividad económica. Los distintos procesos, son cada vez más automatizados.

Incluye aquellas actividades cuyos productos no son bienes tangibles, sino que son intangibles, pero son sujetos de transacción económica, como las actividades bancarias, el comercio, el transporte, y el turismo entre otras. Por ser de carácter inmaterial están menos vinculadas a espacios concretos, pero es en el espacio urbano donde mejor se despliegan.

El sector cuaternario es un sector económico que incluye los servicios altamente intelectuales tales como investigación, desarrollo, innovación (I+D, I+D+I). Tradicionalmente se le consideraba parte del sector terciario pero su importancia cada vez más creciente y diferenciada ha hecho que algunos autores aboguen por considerarlo como un sector separado.

Incluye la industria de alta tecnología, de tecnologías de la información y las telecomunicaciones y algunas formas de investigación científica, así como la educación, la consultoría y la industria de la información.
Permite identificar y analizar el proceso productivo de bienes y servicios destinados a la satisfacción de las necesidades humanas.



</doc>
<doc id="1353" url="https://es.wikipedia.org/wiki?curid=1353" title="Gameto">
Gameto

Los gametos (el griego upame"etḗ" 'esposa' o γαμέτης "gamétēs" 'marido') son las células sexuales haploides de los organismos pluricelulares originadas por meiosis o mitosis a partir de las células germinales (o meiocitos en el caso de células diploides).

Los gametos reciben nombres diferentes según el sexo del portador y el reino (animal, vegetal) al que pertenezcan. En los animales, los gametos proceden de una estirpe celular específica llamada línea germinal, diferenciada en etapas tempranas del desarrollo, y se llaman óvulo el femenino y espermatozoide el masculino; y una vez fusionados producen una célula denominada cigoto o huevo fecundado que contienen dos conjuntos de cromosomas, por lo que es diploide. En las plantas, el gameto femenino se llama oósfera, y el polen es el gametofito masculino, en el interior del cual se forman los gametos masculinos que fecundan a la oósfera.

Los gametos son células compuestas por un solo juego de cromosomas (tienen una versión única de la información genética que determinará las características físicas del individuo) que durante la fecundación se fusionarán con otro gameto del sexo opuesto para formar el cigoto. A la formación de gametos se le llama gametogénesis. Los órganos que producen los gametos se llaman gónadas en los animales, y gametangios en los organismos vegetales. 

La célula resultante de la fusión de los gametos reúne los cromosomas de ambos, así que los gametos suelen ser células haploides. En organismos diploides, como los animales, la formación de los gametos implica un proceso de meiosis, con su correspondiente reducción cromosómica. En organismos haplodiplontes, como las plantas, los gametos son producidos por la fase haploide (gametófito), mientras que es la fase diploide (esporófito), producida precisamente a partir de la fecundación, la que produce esporas por meiosis.

En algunos organismos protistas y en hongos los gametos son morfológica y fisiológicamente idénticos, aunque puede haber una diferencia genética definida. En la evolución, sin embargo, se aprecia una tendencia muy clara a que se distingan cada vez más un gameto femenino, generalmente grande e inmóvil, y un gameto masculino, pequeño y móvil.

En plantas y algas se distinguen tres casos que corresponden a otros tantos grados de manifestación de la tendencia indicada:




</doc>
<doc id="1355" url="https://es.wikipedia.org/wiki?curid=1355" title="Estado de Guerrero">
Estado de Guerrero

Guerrero es uno de los treinta y un estados que, junto con la Ciudad de México, forman los Estados Unidos Mexicanos. Su capital es Chilpancingo de los Bravo y su ciudad más poblada, Acapulco de Juárez. Está ubicado en la región suroeste del país, limitando al norte con el Estado de México, Morelos y Puebla, al sureste con Oaxaca, al suroeste con el océano Pacífico y al noroeste con el río Balsas que lo separa de Michoacán. Fue fundado el 27 de octubre de 1849.

La geomorfología del estado es una de las más accidentadas y complejas de México; su relieve es atravesado por la Sierra Madre del Sur y las Sierras del Norte. En términos cartográficos, se suele llamar Sierra al sector occidental y Montaña al oriental. Entre ambas formaciones se ubica la depresión del río Balsas. Las lagunas más importantes del estado son la laguna negra, la laguna de Coyuca y la laguna de Tres Palos.

Tiene una superficie territorial de 64.281 km² (aprox. 38.000 mi²), en la cual viven poco más de tres millones de personas, lo que hace que se clasifique como la ; la mayoría de la población se concentra en la Zona Metropolitana de Acapulco.

Las principales actividades económicas de Guerrero son la agricultura, en donde se producen importantes cantidades de maíz, ajonjolí, sorgo, soya, arroz, jitomates, limones, café, melones, toronjas, sandías, cacahuates y mangos; en el turismo destaca el denominado "Triángulo del Sol", conformado por tres ciudades: Acapulco de Juárez, Ixtapa-Zihuatanejo y Taxco de Alarcón.

La idea de crear el estado de Guerrero surgió desde los tiempos de la lucha por la Independencia de México. El general José María Morelos y Pavón elaboró un documento mediante el cual creaba en el sur de México la Provincia de Nuestra Señora de Guadalupe de Tecpan. El territorio que Morelos le asignó a esta provincia correspondía, en ese tiempo, a una parte de las intendencias de México, Puebla y Valladolid. La idea de Morelos no tuvo éxito en ese entonces. Por iniciativa del general Álvarez, el Presidente de la República de ese entonces, general José Joaquín de Herrera, declaró la creación del estado de Guerrero.
El nombre de la entidad rinde homenaje a Vicente Guerrero Saldaña (1782-1831), destacado insurgente y caudillo en la etapa de resistencia durante la guerra de Independencia y segundo Presidente de México. El nombre del estado le fue impuesto como tal, en su creación el 27 de octubre de 1849. Guerrero es el único estado del país nombrado en honor a un presidente mexicano, pues otros ostentan el nombre de otros personajes destacados de la historia de México. El estado de Hidalgo en honor a Miguel Hidalgo, iniciador de la Independencia de México; Morelos en honor a José María Morelos, también artífice de la guerra de independencia, y Quintana Roo, en homenaje a Andrés Quintana Roo. El nuevo estado se fundó con los territorios de Acapulco, Chilapa y Taxco que antes pertenecían al estado de México; el de Tlapa perteneciente a Puebla y el de Coyuca que era de Michoacán.

El Estado de Guerrero se encuentra situado en una región antiguamente llamada "Zihuatlán" ("Lugar junto a las mujeres" en náhuatl, Ñuu Ra en mixteco). El territorio que ocupa actualmente la entidad estuvo habitado por grupos nómadas que recorrían las distintas regiones en busca de alimento y refugio hace más de veinte mil años. Los vestigios más antiguos que se han localizado datan aproximadamente de hace 22 mil años y son los restos humanos hallados cerca de los límites de los estados de Guerrero y Morelos, en el lugar conocido como "Cueva Encantada".
En el actual territorio estatal, los antiguos habitantes alcanzaron un progreso notable, aunque su identidad es causa de polémica, ya que para algunos autores los mismos olmecas que habitaron la región del Golfo de México también se asentaron en algunas de sus regiones.

Guerrero formó, durante el Período preclásico mesoamericano (2500 a. C. -200), una de las ocho regiones en que se dividió este territorio, contando además con importante presencia olmeca que dejó gran influencia en la cultura del estado, como la característica del "Hombre Jaguar". Otro rasgo esencial de la influencia olmeca fue el agrupamiento de las aldeas dispersas, la construcción de templos ceremoniales y el establecimiento de una organización política, cultural y religiosa administrada por sacerdotes que fueron asumiendo funciones de gobierno.

La Religión jugó un papel importante como aliciente espiritual y como medio para la explicación de numerosos fenómenos naturales. Con base en una interpretación mágica. El establecimiento de aldeas fijas es un indicador importante de los cambios sufridos por los grupos humanos al sedentarizarse, y uno de los asentamientos de este tipo más remoto de los que se han localizado en el país, corresponde al hallado en Puerto Marqués, cerca de Acapulco, en donde se han encontrado objetos de cerámica con una antigüedad de aproximadamente cinco mil años. 

Otras culturas se asentaron en el estado, como la mezcala y los coixcas que llegó a los territorios del estado en el siglo VIII y que asimiló e incorporó a su estilo el modelo cultural teotihuacano en su cerámica; integró en algunos lugares el juego de pelota, que tenía un carácter ritual, e incorporó sus elementos artísticos a la escultura en piedra.

Para el siglo XIV, se encontraban ya asentados en el territorio de la entidad diversos pueblos con sus características culturales propias, conviviendo algunos de manera pacífica y otros en constantes conflictos bélicos. Entre los más importantes estaban los purépechas, cuitlaltecas, ocultecas y matlatzincos, en la Tierra Caliente; los chontales, mazatlecos y tlahuicas en la Sierra Norte; los coíxcas y tepuztecos en los Valles Centrales; los tlapanecos y los mixtecos en La Montaña; los Yopes, mixtecos y amuzgos en la Costa Chica, y los tolimecas, chubias, pantecas y cuitlaltecas en la Costa Grande.

En el estado de Guerrero habitaron Los Yopes, una tribu que nunca fue sometida por los aztecas, y fue conquistada hacia 1553 por los españoles. Cuando los yopes, desgastados por el asedio mexica, no pudieron hacer frente solos a los invasores por mucho tiempo, la conquista y sumisión del territorio fue rápida y completa, incluso en la mayoría de los casos los pueblos enviaron emisarios a visitar a Cortés para informarle de su sumisión voluntaria.
En 1521 Rodrigo de Castañeda penetró y tomó el sector minero de Taxco; Gonzalo de Sandoval dominó la región Chontal; la Sierra del Norte, el valle de Iguala y el Centro de Coixcatlalpan. Un año después, el mismo Gonzalo de Sandoval sujetó la Costa Chica donde se fundó el sexto ayuntamiento de la Nueva España, con cabecera en el poblado de San Luis Acatlán y dominó parte de La Montaña. En 1523, Juan Rodríguez de Villafuerte se apoderó de Cihuatlán y casi toda la Costa Grande; después de destruir el poblado indígena de Zacatula fundó sobre sus ruinas la Villa de la Concepción, donde se instaló poco después el octavo ayuntamiento de la Nueva España y el primer astillero, en el cual se construyeron dos carabelas y dos bergantines. Por encargo de Cortés construyó después en Zihuatanejo tres bergantines más y en ese mismo año llegó a Acapulco, al que denominó Villa Fuerte y cuya encomienda logró obtener tiempo después. Isidro Moreno dominó varios pueblos de la Sierra de Tlacotepec y la parte alta de la Costa Grande en la región denominada Atlatomahua. Sin embargo, al finalizar la primera década de la Conquista, los españoles habían reducido violentamente dos rebeliones indígenas, una en Costa Grande en los astilleros de Zacatula, provocada por las vejaciones y la explotación y otra en San Luis Acatlán en la Costa Chica, donde los yopis trataron de recuperar su independencia y destruyeron el pueblo matando a una gran cantidad de españoles.
Los yopes fueron exterminados casi totalmente; en fecha de 2004, sólo quedan algunas pequeñas congregaciones de yopes.

Una vez que Tenochtitlán fue destruida y los mexicas sometidos, el océano Pacífico atrajo la atención de los conquistadores, esencialmente por motivos económicos. En 1519 Hernán Cortés ordenó que se explorara la provincia de Zihuatlán o Zacatula, como la llamaron los conquistadores, para cerciorarse de la existencia del Mar del Sur y de las riquezas en oro y perlas; la expedición estuvo a cargo de Gonzalo de Umbría. A fines de 1520 el mismo Cortés mandó reconocer la región taxqueña, con el objeto de localizar metales para fundir piezas de artillería. De esta manera, la penetración armada fue formalizando la conquista del territorio sureño, que no opuso gran resistencia, debido al temor que había despertado la noticia de la caída de Tenochtitlán.

Al conformarse la primera división política de la Nueva España, en el segundo tercio del siglo XVI, se estableció la Real Audiencia y se dividió el territorio de la Nueva España en cinco provincias, dentro de las cuales se establecieron Corregimientos y Alcaldías Mayores que tenían por objeto vigilar el orden de los pueblos y regular las relaciones entre los españoles y las comunidades indígenas. De esta manera se establecieron en el territorio sureño las alcaldías mayores de Tlapa bajo la jurisdicción de la provincia de Puebla; Taxco, Iguala, Chilapa y Acapulco de la de México y Zacatula bajo provincia de Valladolid.

La evangelización se llevó a cabo principalmente por los frailes agustinos en la zona Centro (Guerrero), La Montaña (Guerrero) y Tierra Caliente y por los franciscanos en la zona Norte, la Costa Grande y Acapulco.

Durante el Siglo de Oro español, sobresalió en la literatura el guerrerense Juan Ruiz de Alarcón, nacido en Taxco a finales del siglo XVI. En la segunda mitad del siglo XVII el gobierno español transformó la organización política sustituyendo las audiencias por intendencias y las alcaldías por partidos.

Tras tres siglos de colonia se gestaron un ambiente prerrevolucionario y un sentimiento de independencia, que estalló con el movimiento insurgente. Se dieron diversas conspiraciones realizadas por criollos, la más significativa fue la de Valladolid (hoy Morelia) en 1809, en la que participó Don José María Izazaga, originario de la hacienda El Rosario, en el actual municipio de Coahuayutla.

Esta conspiración fue descubierta el 20 de diciembre, sin embargo los conspiradores fueron indultados de la pena capital por el virrey, arzobispo Francisco Javier de Lizana y Beaumont.

En 1810 fue organizada la conspiración de Querétaro, a cargo del cura Miguel Hidalgo, el corregidor Miguel Domínguez, su esposa Josefa Ortiz de Domínguez, los militares Ignacio Allende, Juan Aldama y Mariano Abasolo, que logró levantar el primer movimiento armado contra el poder realista español, con el Grito de Dolores, logrando iniciar así la lucha por la Independencia de México.

El 20 de octubre de 1810, Hidalgo comisionó a José María Morelos para levantar en armas al sur, consciente de la importancia que tenía para la causa el puerto de Acapulco. Morelos entró a tierras surianas siguiendo la ruta de la Costa Grande. Después de varios intentos fallidos para tomar el puerto Morelos dejó tendido un cerco y marchó a los valles centrales, donde se unieron a la causa: Vicente Guerrero a quien el nombre del estado rinde homenaje, Nicolás Bravo, otro caudillo que llegó a la presidencia en 1839, y que combatió bajo las órdenes de José María Morelos, junto con Hermenegildo Galeana y Leonardo Bravo, y en el segundo círculo de insurgentes se encontraba Juan N. Álvarez, quien años más tarde impulsaría, junto con Nicolás Bravo, la creación del estado, y sería su primer , así como el matrimonio Catalán en Chilpancingo.

En 1810 proveniente de Zacatulaen José María Izazaga, benefactor insurgente se integró con 130 hombres al ejército Insurgente en Petatlán, estado Guerrero.

El 6 de septiembre de 1813 fue inaugurado en el templo de Nuestra Señora de la Asunción en Chilpancingo, el Congreso de Anáhuac, una idea que Morelos había recibido de Miguel Hidalgo, en su encuentro con él el 20 de octubre de 1810, y que pretendía establecer bases legislativas para la organización de la lucha por la Independencia. El día que inauguró el Congreso, Morelos pronunció un famoso discurso conocido como Sentimientos de la Nación, documento que ha servido de inspiración para muchas generaciones de políticos.

El Congreso promulgó el 13 de septiembre el Acta Solemne de la Declaración de Independencia de la América Septentrional, declarando a México como nación independiente.

El 22 de octubre de 1814, fue expedida la Constitución de Apatzingán, primer documento en la historia del constitucionalismo mexicano.

A la muerte de Morelos, Vicente Guerrero tomó en sus manos la bandera de la insurrección en un periodo de resistencia, entre 1816 y 1820, cuando muchos insurgentes como Nicolás Bravo e Ignacio López Rayón, se acogieron a la política del indulto, instrumentada por el virrey Juan Ruiz de Apodaca, y sólo Guerrero y Guadalupe Victoria en Veracruz, se mantenían como insurgentes; por lo demás, el país estaba casi pacificado.

En 1820 Apodaca, en vista de que Guerrero no podía ser derrotado, comisionó al coronel Agustín de Iturbide (artífice de la caída de Morelos, y quien se encontraba retirado desde 1816 debido a un escándalo de corrupción) como comandante de las fuerzas realistas en el sur del país.

Pronto, Iturbide se dio cuenta de que las fuerzas de Guerrero conocían mucho mejor que los realistas la zona montañosa de Guerrero, y no podían derrotarlos; por su parte Guerrero estaba aislado del país y no podía seguir solo la lucha. Por los motivos antes enunciados, Guerrero e Iturbide crearon el Ejército Trigarante con el abrazo de Acatempan el 10 de enero de 1821.

Iturbide y Guerrero firmaron el 24 de febrero el Plan de Iguala o de las tres garantías (independencia, libertad y religión), que entre sus postulados estaban invitar a todos los habitantes de la Nueva España a olvidar sus divisiones y a unirse para alcanzar la independencia. México sería una nación independiente gobernada por el rey Fernando u otro príncipe conservador europeo; criollos y peninsulares tendrían los mismos derechos y privilegios; y la iglesia católica continuaría teniendo sus privilegios en México. Creado el ejército de las Tres Garantías, fue puesto bajo el comando de Iturbide para garantizar el Plan de Iguala. El plan satisfizo a liberales y conservadores: la meta de la independencia y la protección de la iglesia católica hicieron posible que todos se unieran al movimiento independentista.

En agosto, el virrey Apodaca fue depuesto y en su lugar llegó Juan O'Donojú, último virrey, quien firmó los Tratados de Córdoba, con los que se reconocía la independencia de México, y el Ejército Trigarante entró a la Ciudad de México el 27 de septiembre de 1821.

En noviembre de 1810 Morelos hizo conocer a sus tropas la intención de erigir una provincia en el sur del país, llamada "Nuestra Señora de Guadalupe de Tecpan" con territorios de las intendencias de Puebla, México y Valladolid, pero con el declive de la campaña de Morelos, el proyecto quedó en el olvido.

Fue hasta 1823, en el Segundo Congreso Constituyente que Nicolás Bravo y Vicente Guerrero recuperaron la idea de Morelos; la creación del Estado del Sur, que tendría el mismo territorio de la Capitanía General del Sur, pero el Congreso rechazó la propuesta, estableciéndose la Comandancia Militar del Sur, con centro de operaciones en Chilpancingo.

Al morir fusilado Vicente Guerrero en Cuilapan, Oaxaca, el 14 de febrero de 1831, varios diputados (entre ellos el futuro presidente Benito Juárez) solicitaron en 1833 la creación del estado de Guerrero, y el cambio de nombre de Cuilapan por Guerrerotitlán, con el apoyo del cacique Juan Álvarez y de Nicolás Bravo; pero la propuesta no fue aprobada.

El 15 de mayo de 1849 el presidente José Joaquín de Herrera envió al Congreso la iniciativa para crear el estado de Guerrero, con territorio de los Estados de Michoacán, Puebla y México. La iniciativa fue aprobada por la Cámara de Diputados el 20 de octubre y por el Senado el 26 de octubre.

El día 27 de octubre de 1849 en sesión solemne del Congreso de la Unión, fue declarado constituido legalmente el Estado Libre y Soberano de Guerrero, y se nombró al general Juan Álvarez como comandante general interino.

En enero de 1850 se celebraron elecciones para diputados a la Legislatura Constituyente del Estado, que una vez integrada el 30 de enero en Iguala ratificó el 31 de enero a Juan Álvarez como primer gobernador del estado, pero el 13 de junio Álvarez solicitó licencia para ausentarse del gobierno y fue designado por la legislatura el coronel Miguel García, quien estuvo en el cargo hasta el 15 de enero de 1851, y promulgó la Ley Orgánica Provisional, para la organización del estado, que designaba a Tixtla como capital del Estado.

El 26 de junio de 1851 fue publicada la Constitución Política del Estado Libre y Soberano de Guerrero.

Entre 1862 y 1867 el Estado participó activamente en la defensa de la soberanía nacional, que fue amenazada por la Intervención Francesa.

Fue entonces cuando se dio el inicio del esplendor cultural en Guerrero, con su máximo exponente Ignacio Manuel Altamirano, uno de los más conocidos literatos mexicanos, quien también fungió como político y militar, y era de raza indígena. Murió siendo cónsul en San Remo, Italia.

Tras la derrota del ejército francés en 1867 y la caída del emperador Maximiliano de Habsburgo, el estado volvió a su vida normal y el hijo de Juan Álvarez, Diego, asumió la gubernatura y promulgó una nueva constitución el 26 de junio de 1874.

Juárez murió el 18 de julio de 1872 y le sustituyó el presidente de la Suprema Corte de Justicia, Sebastián Lerdo de Tejada, quien indultó a los participantes en la revuelta de la Noria y convocó a elecciones para noviembre, en las que fue reelecto.

En 1876 hubo nuevamente elecciones presidenciales y competían Lerdo contra Díaz, el primero resultó triunfador y Díaz promulgó el Plan de Tuxtepec, que convocó nuevamente a una revuelta.

En el estado de Guerrero el movimiento fue secundado por Vicente Cuenca (Teniente Coronel de Benito Juárez) en Iguala fusliado por las fuerzas porfiristas y enterrdo en la iglesia de Iguala; José Sánchez en Soyatlán, Jesús Márquez en Chilapa y Enrique M. Sosa en Atlamajac. Nuevamente el general Diego Álvarez encabezó la defensa de la institucionalidad y logró ganar varias batallas en la zona centro; los porfiristas, reforzados por sus correlegionarios poblanos, vencieron definitivamente en Amojileca, en el municipio de Chilpancingo y en el Playón, a un costado de Xaltianquis en el municipio de Acapulco.

En Tlaxcala venció definitivamente Díaz a las fuerzas del gobierno y de esta manera asumió el poder que mantuvo durante casi 30 años.

Desde finales del siglo XIX se gestaron movimientos contra la dictadura de Porfirio Díaz, y en Guerrero el más famoso fue el de Canuto A. Neri, contra el gobernador Francisco O. Arce, en 1893, donde las fuerzas de Arce fueron derrotadas y Neri asumió provisionalmente la gubernatura.

En 1891 se desarrolló un movimiento dirigido por José Cuevas que llegó a reunir una gran cantidad de comunidades de los valles centrales y que pretendía la caída de la dictadura.

En 1901, surgió un nuevo levantamiento en Mochitlán y Quechultenango, al mando de Anselmo Bello y Gabino Gardeño, quienes proclamaron el Plan del Zapote. En él se desconocía al presidente Díaz, se exigía el respeto a las elecciones democráticas y el reparto de tierras. Al conocer la situación Díaz mandó al coronel Victoriano Huerta a sofocar la rebelión.

En 1909 el hacendado coahuilense Francisco I. Madero publicó el libro "La Sucesión Presidencial en 1910", y viajó por el país en una gira política sin precedentes, organizando el Partido Nacional Antirreeleccionista, que tuvo filiales en la mayoría de los estados de la república. En Huitzuco, con la orientación de Octavio Bertrana, se formó el "Círculo Antirreeleccionista Juan N. Álvarez", encabezado por los hermanos Ambrosio, Rómulo y Francisco Figueroa.

En febrero de 1911, los Figueroa libraron uno de los primeros combates en el sur, en Atenango del Río. Para julio, tras la caída de Díaz y durante el interinato de Francisco León de la Barra se libró el primer combate del ejército zapatista, comandado por Emiliano Zapata.

Cuando se celebró el Congreso Constituyente (entre diciembre de 1916 y enero de 1917) en Querétaro, asistieron tres diputados guerrerenses, quienes pugnaron principalmente por la inclusión de los derechos agrarios en la Carta Magna, hecho que se vio consagrado en el artículo 27.

El Estado apoyó el Plan de Agua Prieta y a Álvaro Obregón en su revuelta contra el presidente Venustiano Carranza, durante 1920. De hecho, Obregón escapó de la policía carrancista disfrazado de fogonero y consiguió llegar a Chilpancingo, donde inició su movimiento.

En la llamada "época del milagro mexicano" hubo un desarrollo turístico de Guerrero, principalmente de Acapulco, inspirado por Miguel Alemán Valdés, presidente entre 1946 y 1952. En 1950, la Costera de Acapulco fue nombrada en honor de alemán.

Durante la década de 1970 el estado de Guerrero fue escenario de varios movimientos opositores al régimen priísta del país. Empujados en cierta manera por la poca atención a sus demandas, un grupo de profesores —entre ellos Lucio Cabañas y Genaro Vázquez— optaron por la lucha armada. La Asociación Cívica Nacional Revolucionaria y la Brigada de Ajusticiamiento del Partido de los Pobres tuvieron un gran impacto en la opinión pública nacional. Este último grupo, comandado por Cabañas Barrientos, secuestró a Rubén Figueroa Figueroa (senador por Guerrero y futuro gobernador del estado) en 1974, lo que dio pie a una dura represión por parte del Ejército Mexicano. Como resultado, Cabañas Barrientos fue muerto en Técpan de Galeana, suerte que corrieron otros miembros de las guerrillas de la Sierra Madre del Sur. Otros fueron detenidos y desaparecidos. Estos hechos forman parte de la Guerra Sucia mexicana. Años más tarde, también en la región de la Costa Grande, la policía del estado asesinó a 17 campesinos en el vado de Aguas Blancas (Coyuca de Benítez) el 28 de junio de 1995. Al año siguiente se levantó en armas el Ejército Popular Revolucionario, al que se supone ligado a la guerrilla del Partido Revolucionario Obrero Clandestino Unión del Pueblo-Partido de los Pobres (PROCUP-PdlP).

Con la fundación del Partido Nacional Revolucionario (hoy Partido Revolucionario Institucional) en 1929 todos los gobernadores provinieron de este partido, hasta que en las elecciones del 6 de febrero de 2005, el perredista Zeferino Torreblanca, derrotó al candidato del PRI, Héctor Astudillo.

El Estado de Guerrero se localiza en la zona de coordenadas meridional de la República Mexicana, sobre el océano Pacífico y se ubica entre los 16º18´ y 18º48´ de latitud norte y los 98º03´ y 102º12´ de longitud oeste. Limita al norte con los estados de México (216 km) y Morelos (88 km), al noroeste con el estado de Michoacán (424 km), al noreste con el estado de Puebla (128 km), al este con el estado de Oaxaca (241 km) y al sur con el mar Mexicano (océano Pacífico) (500 km). Dentro de México pertenece a la Zona Pacífico Sur. El estado tiene una extensión de 63.794 km², es decir, el 3,2 % del total del territorio nacional. Ocupa el decimocuarto lugar en extensión territorial.

El estado de Guerrero es sumamente montañoso, tiene serranías, además de ser muy irregular por sus sierras madres. Es atravesado por la Sierra Madre del Sur. El Eje Volcánico Transversal origina las sierras de Sultepec y Taxco. Junto con Oaxaca, extiende su territorio por la llamada Depresión Austral, y es recorrido por la sección sureste de la Sierra Madre del Sur. El Eje Volcánico Transversal atraviesa parte de Guerrero, principalmente la Región Norte. Mientras que los bosques de coníferas del Estado, son de los más grandes del país, un 14,8 % está en Guerrero.

Guerrero es uno de los Estados con más caudales hidrológicos. Dentro de la República Mexicana, el estado de Guerrero ocupa el 12º sitio en cuanto a disponibilidad acuífera, su aprovechamiento es de 602,626 millones de m³. Su territorio es cruzado por uno de los ríos más importantes de México, el Balsas. El territorio del estado se encuentra sobre tres regiones hidrológicas. La región 18 del río Balsas, de la que Guerrero ocupa el 31 % de la superficie. Tiene como presas más importantes a la Valerio Trujano en Tepecoacuilco, que surte de energía eléctrica a gran parte de la Región Norte. La región 19 de la Costa Grande ocupa el 20 % del territorio estatal, y sus ríos más importantes son el Ixtapa, Tecpan, Coyuca, La Sabana, Coyuquilla y Petatlán, además del Atoyac. Por último, la región 20 de la Costa Chica, de la que el 26,4 % de la superficie pertenece a Guerrero. No tiene muchos ríos, pero destacan el Nexpa, Ometepec y Papagayo. Los lagos y lagunas más importantes son Potosí, Mitla, Nuxco, Coyuca, Tres Palos, San Marcos (Tecomate), Chautengo, Tila, Huamuxtitlán, Tuxpan, Tixtla, Tecomate.

Guerrero casi no posee recursos de subsuelo, los más importantes se remontan a unas pocas salinas en la Costa Grande, principalmente en el municipio de Atoyac. Por lo demás, el subsuelo, según informes de la SEMARNAT, está gravemente contaminado, principalmente en Acapulco.

La flora está compuesta principalmente por árboles de amate copal, cuagiote, organeras, huizache y palmeras. Entre los animales más característicos de la fauna guerrerense están las iguanas, las serpientes, las lagartijas, las liebres, los conejos y los coyotes. Los animales en peligro de extinción en el Estado de Guerrero son el venado, el jaguar, el águila, la tortuga y la iguana.

Más del 60 % de la superficie estatal disfruta de clima cálido subhúmedo con precipitaciones en verano. El segundo lugar lo ocupa el clima semicálido con lluvias en verano, en casi la quinta parte del territorio. El resto lo ocupan climas menores, entre los que destacan semicálidos y templados, todos con lluvias moderadas. Según datos del INEGI, la ciudad de Chilpancingo tiene una temperatura media anual de 21,9 °C. Por lo que respecta a precipitación total anual, el mes que mayor precipitación hay en el Estado es septiembre, y el lugar con más lluvias es Pueblo Hidalgo, San Luis Acatlan.

El estado colinda al norte con los estados de México (216 km) y Morelos (88 km), al noroeste con el estado de Michoacán (424 km), al noreste con el estado de Puebla (128 km), al este con el estado de Oaxaca (241 km) y al sur con el océano Pacífico (500 km).

La frontera con Michoacán ha sido designada por dos Decretos: uno de la Federación, publicado en el "Diario Oficial" del 14 de diciembre de 1906, y otro del Estado, marcado con el número 18 del 20 de noviembre de 1907, que confirma y ratifica el anterior.

Con el estado de México; por Decreto de 15 de mayo de 1849, expedido por el Congreso General (hoy Honorable Congreso de la Unión), el que procedió al Decreto de Erección del Estado, con el estado de Morelos por el convenio celebrado entre ambas Entidades el 8 de octubre de 1946. Con Puebla, los límites están en el mapa oficial, levantado en el año de 1845 por órdenes del Poder Ejecutivo Federal, y con Oaxaca, por laudo pronunciado por particular el 28 de abril de 1890, que acepta el dictamen de las comisiones de límites de ambos estados, con base en el cual se expidió el Decreto de la Legislatura del Estado de 27 de noviembre del mismo año de 1890.

El Estado Libre y Soberano de Guerrero es una de las 32 entidades federativas de los Estados Unidos Mexicanos. Sobre la base de la Constitución Federal de 1917, en su artículo 115, en la cual se señala que:

A nivel estatal los municipios del estado de Guerrero se rigen por la Ley Orgánica Municipal del Estado de Guerrero, la cual en su versión en vigor solo señala en su artículo 9, setenta y seis municipios, discrepando con los ochenta y uno que tiene registrados oficialmente el INEGI, ya que la diferencia corresponde a municipios de reciente creación que aún no integran de manera formal sus cuerpos de gobierno. considerando a la lista del INEGI como la más actualizada se listan a continuación los municipios con la denominación y cabeceras municipales que a continuación se especifican.

El estado de Guerrero se encuentra territorialmente dividido en ocho regiones, que distinguen rasgos económicos, sociales, culturales y geográficos.



La máxima ley del Estado es la Constitución Política del Estado Libre y Soberano de Guerrero, publicada el 14 de octubre de 1980. En ella se consagran las garantías individuales de la Constitución Federal y algunas normas rectoras de la vida política estatal.

El poder ejecutivo reside en un solo individuo, que se denomina Gobernador Constitucional del Estado que es elegido por seis años, entra a ejercer su encargo el 1 de abril y protesta ante el Congreso Estatal. Además sus facultades están enumeradas en el artículo 74, su elección el 67, y su suplencia en los artículos 67 a 73.

El poder legislativo de la entidad se deposita en el Congreso del Estado, conformado por una única cámara de diputados. Esta cámara la componen 46 diputados electos popularmente cada 3 años, de los que 28 son de mayoría relativa y hasta 18 de representación proporcional. No pueden ser reelegidos para el período legislativo inmediato. La Constitución habla del Congreso en su Título Quinto.

El poder judicial se inviste en un Tribunal Superior de Justicia del Estado de Guerrero integrado por 19 magistrados numerarios y 3 supernumerarios, que son designados por el Gobernador y ratificados por el Congreso. Duran en su encargo seis años, pudiendo ser ratificados. El Tribunal funciona en pleno, o en tres salas: penal, familiar y civil. También existen los tribunales inferiores que el Congreso establezca.

El municipio es la estructura básica de gobierno y administración de la república mexicana, siendo los más poblados de Guerrero los municipios de Acapulco de Juárez, Chilpancingo de los Bravo e Iguala de la Independencia. El municipio está gobernado por un presidente municipal (alcalde) y un número variable de regidores (legislativo) y un síndico procurador (judicial).

Guerrero es uno de los estados con la menor variación de población en su historia. Como casi no sufrió los estragos poblacionales de la guerra de Independencia y de la revolución mexicana (los dos movimientos sociales que han causado mayor pérdida humana en la historia de México, en el siglo XIX y en el siglo XX, respectivamente). Ha mantenido su población prácticamente estable, pero con algunos cambios, derivados principalmente de la migración, ya que Guerrero genera el 1,1 % de la migración total del país.
A partir de la década de 1970 la población comenzó a crecer, y registró la tasa de crecimiento más alta de su historia, 3,2.
Conforme a los resultados del "II Censo de Población y Vivienda" efectuado por el Instituto Nacional de Estadística y Geografía (INEGI) del 31 de mayo al 25 de junio de 2010, Guerrero tenía hasta entonces un total de 3.388.768 habitantes, por lo que ocupa el lugar decimosegundo a nivel nacional.

De su población total, 1.645.561 eran hombres y 1.743.207 eran mujeres. La tasa de crecimiento anual para la entidad durante el período 2005-2010 fue del 1,7 %.
El municipio más poblado es Acapulco de Juárez con 789.971 habitantes, y el menos habitado es Juchitán con un total de 7 166 habitantes.

<noinclude>

En esta es una lista se muestran los 10 municipios de Guerrero con mayor IDH según los Indicadores de Desarrollo Humano y Género en México 2000 - 2005 del Programa de las Naciones Unidas para el Desarrollo (PNUD) publicado en 2005. El estado comprende 8 municipios con IDH muy alto, 43 con IDH alto, 29 con IDH medio y solo un municipio con IDH bajo.

La pobreza en Guerrero ocupa el tercer lugar a nivel nacional, superado sólo por Chiapas y Oaxaca, aunque en este estado se localiza una de las zonas más pobres de México, la Región Montaña (alta y baja), donde se localiza el municipio más pobre de México, Cochoapa el Grande, cuyos niveles de vida son similares a los de algunas de las regiones más pobres de África. Junto a Coicóyan de las Flores, un municipio oaxaqueño vecino de Metlatónoc, estos municipios son los más pobres del país. En 2004, alrededor de 600.000 personas del estado estaban inscritos en las instituciones estatales, federales y privadas de seguridad social. En 2006, el 7,2 % de la población estatal era derechohabiente del IMSS.

De acuerdo con las cifras dadas a conocer por el Consejo Nacional de Población (CONAPO) en 2004, en el Estado de Guerrero, los usuarios de los servicios de salud son en un 48,3 % hombres y 51,7 % mujeres. A 2005 fueron diagnosticados 8.720 casos de sida, pero sólo 4.382 lograron atenderse.

En 1999, de acuerdo a una encuesta de ingresos económicos, había un total de 2.814.267 unidades económicas trabajando activamente en el Estado de Guerrero, siendo el comercio la actividad que más unidades utilizaba, con 1.443.676 negocios dedicados a esa actividad económica.

En 2004, el trabajo en el cual se percibían mejores remuneraciones, era el del comercio menor, con $1.493.590 pesos mexicanos de 3.005.157 unidades que entraron al estado ese año. En contraste, sólo 349 unidades estaban dedicadas a la dirección de empresas y corporativos.

En el estado de Guerrero, 456.774 personas de cinco años y más hablan lengua indígena, lo que representa menos del 15 % (INEGI 2010). La población indígena en Guerrero se encuentra esencialmente en la zona de la montaña, y en menor medida en la Costa Chica, las dos zonas más marginadas del estado.

La población indígena se distribuye en cuatro grupos:


La migración es un fenómeno muy común en el Estado de Guerrero, pues cada año 73.000 guerrenses emigran a Estados Unidos. Guerrero ocupa el primer lugar nacional en migración interna y el quinto en migración externa. Cerca de 128.000 jornaleros salen durante el verano al norte del país, es decir a estados como Sonora, Sinaloa, Chihuahua y Baja California, mientras que muchos emigran directamente a Estados Unidos, particularmente a estados como Oregón, California, Arizona, Mississippi, Florida, Nueva York, Virginia, y Carolina del Norte. Entre un 1/4 y 1/3 de la población guerrerense vive en Estados Unidos, aproximadamente 950.000 y más de 300.000 viven en Chicago (segunda ciudad con más guerrerenses después de Acapulco).

Una de las causas de la migración es el desempleo existente en el Estado, principalmente en los grupos indígenas, ya que no puede brindar empleo al 79 % sus habitantes. Principalmente en la zona de la Montaña Baja, existe gran cantidad de individuos dedicados al peonaje, la mayoría analfabetas, entre ellos muchos niños. Muchos de estos empleados no tienen derechos sindicales.

Entre 50 y 60 guerrerenses intentan cruzar la frontera al día. Tras la firma del TLCAN, por parte de México, el 30 de noviembre de 1993, los estadounidenses pusieron en práctica la Operación Guardián, con lo que los riesgos al cruzar el muro fronterizo aumentaron.

El tráfico de indocumentados es muy usual en Guerrero, "los coyotes"(en la jerga mexicana así se conoce a los traficantes de inmigrantes) piden alrededor de 2.000 dólares norteamericanos por persona para intentar pasar a los guerrerenses a Estados Unidos. También se generan redes de corrupción alrededor de los traficantes de indocumentados.

En Guerrero reside una de las mayores comunidades de descendencia negra cuyos ancestros provienen de África subsahariana. Fue en tiempos del periodo colonial español cuando se realizó la migración forzada o la diáspora africana más numerosa hacia la Nueva España. La compra de esclavos trajo consigo una influencia cultural muy fuerte que está inmersa en la cultura popular de los guerrerenses.

El occidente del estado, lo que se conoce como Tierra Caliente y Costa Grande, fue el destino final miles de ibéricos que ocuparon las tierras de los indígenas y se establecieron de manera definitiva formando haciendas, ranchos y pequeñas villas de españoles.

Otros grupos provenientes de Italia, China, Filipinas, Perú, Chile y Líbano se establecieron en Guerrero. Ya a finales del siglo XX fueron los estadounidenses, canadienses y centroamericanos los que han buscado como destino de residencia permanente este estado.

El Escudo del estado de Guerrero es un tocado con Penacho compuesto por 11 plumas de distintos colores, que vistas de derecha a izquierda por su orden, quedan así: amarilla, azul, amarilla, amarilla oro, roja, verde, azul, roja, verde, amarilla y azul.

En su conjunto el escudo simboliza lo siguiente: el penacho y la diadema. El poder. El Escudo propiamente dicho. Capa del señor con poder. El Caballero Jaguar. Exponente máximo de la jerarquía guerrera nahua (recuérdese que el Ejército Azteca se formaba principalmente de caballeros Águila, caballeros Jaguar y caballeros Puma). Los colores son símbolos: el amarillo de los adornos en los grandes señores que usaban mucho el metal de oro; el rojo de la sangre, valor precioso que se entrega; el verde de los vegetales, el azul del cielo y el agua. Las manchas de la piel del Tigre, son del cielo por la noche y simbólicas del señor de la noche que es Tezcaltlipoca.

La Bandera del estado de Guerrero no tiene reconocimiento oficial y por tanto vigencia como tal, aunque algunas veces es utilizada por el gobierno como emblema de la entidad. Está compuesta por un campo blanco con el Escudo de Guerrero justo en el centro. El estado ha tenido únicamente dos banderas de facto, es decir, no oficiales pero sí utilizadas en algunas ocasiones. La diferencia ente la primera y la segunda es tan sólo la actualización del escudo.

Coro:

Estrofa I:

Coro:

Guerrero es uno de los estados de la República con Producto Interno Bruto mediano, pues en 2011 registró 198.144.844 pesos, lo que lo situaba en el lugar número 22 a nivel nacional, con una contribución del 1,3 % al total nacional.
Con respecto a las actividades económicas desarrolladas por los guerrerenses en edad de trabajar (2.075.739 a 2000), el sector primario ocupa 14.276 personas y representa el 5,6 % de la población económicamente activa (PEA), el secundario ocupa a 47.471 personas y representa el 18,72 % por ciento de la PEA y el terciario ocupa 184.869 personas y representa el 72,92 % por ciento de la PEA; es en este último en el que se ocupa la mayor parte de la población debido a que el estado basa su economía en el turismo y el comercio.

La agricultura es una actividad económica en que destaca Tierra Caliente, la región que tiene el mayor número de exportaciones de productos agrícolas en el estado. Esta actividad predomina en la selva, principalmente en la zona costera, puesto que la fertilidad de la tierra, y el clima tropical caluroso y lluvioso permiten abundantes productos tropicales, y se han construido sistemas de riego, como las presas Vicente Guerrero, Valerio Trujano y Hermenegildo Galeana. El estado produce ajonjolí, café, plátano, cacao, papaya, mango, tabaco, limón y maíz. La explotación forestal también es variada. Se utilizan las maderas de pino, encino, cedro y caoba.

La ganadería se practica en el estado, ya que gran parte de su territorio posee pastos, necesarios para favorecer la cría extensiva de todas las especies de ganado. Se crían principalmente ganado caprino y porcino. La ganadería en Costa Chica y en la Montaña es de subsistencia.

El comercio es desarrollado en todo el Estado. Los productos agrícolas, principalmente los tropicales, van no sólo a los mercados nacionales, sino también al extranjero, principalmente a Estados Unidos. El comercio de artesanía es también muy apreciado en México y el mundo.

La industria tiene sus principales centros en Buenavista de Cuéllar y Leonardo Bravo. La variante artesanal de esta actividad económica se localiza en Olinalá, Zitlala, Xochistlahuaca y Tetipac. En Guerrero, se obtienen del subsuelo plata, zinc, petróleo, gas, hierro y mercurio. La industria de la transformación está levemente desarrollada, en las ramas de producción de azúcar y derivados lácteos, hilados y tejidos de algodón, fabricación de celulosa, papel y conservadores.

El servicio público se presenta con mayor intensidad en la capital del Estado, Chilpancingo.

Los municipios de las costas poseen una incipiente pesca, actividad que es principalmente de manutención en los litorales de la zona, que tiene puertos pesqueros como Zihuatanejo y Acapulco.

El turismo es la actividad económica que más recursos deja al estado, pues aporta gran parte del PIB total del estado y emplea a miles de personas.Durante 2016 11 millones 500 mil turistas visitaron Guerrero, además de la llegada de 39 cruceros. Los principales centros turísticos en el estado son Taxco, Zihuatanejo, Ixtapa Zihuatanejo y Acapulco. Los centros turísticos guerrerenses son muy visitados debido a su cercanía con la Ciudad de México.

En 1998, especialmente durante la época de la Semana Santa (del 5 al 12 de abril), la ocupación turística en Acapulco rebasó los 6 millones y generó 2.300.000 dólares a la industria hotelera estatal La ocupación hotelera presenta dos tendencias: de temporada (Acapulco e Ixtapa) y de fin de semana (otros sitios turísticos como Taxco). La estadía promedio en las zonas turísticas de Guerrero en Acapulco e Ixtapa es de cuatro noches, mientras que para Taxco es de una.

Es la zona turística en el estado de Guerrero la cual recorre la Sierra Madre del Sur. Esta zona turística está conformada por las ciudades de Acapulco, en el sur, el binomio de Ixtapa - Zihuatanejo, en el norte y Taxco, en el centro del estado. Estas ciudades son las que reciben más turistas en Guerrero, teniendo en su conjunto 24 635 habitaciones de hospedaje en el 2016.

Antes llamado Feria Internacional de Hoteles y Agencias Turísticas de Acapulco, es una feria donde se reúnen las principales empresas dedicadas a la industria, donde se promueven los diferentes destinos turísticos de México. El tianguis se lleva a cabo desde 1975, siendo Acapulco su sede principal, hasta el año 2011 cuando se alterno su cede a varias ciudades del país, quedando Acapulco como su cede cada 2 años.

Entre los atractivos naturales del estado destacan las grutas de Juxtlahuaca, Oxtotitlán y las Grutas de Cacahuamilpa. Son distinguibles en las dos primeras la presencia de manifestaciones artísticas primitivas, conocidas como pinturas rupestres, en ambas cavernas las pinturas representadas están vinculadas a la iconografía olmeca. Además en ella recae la importancia de ser una de las primeras demostraciones pictóricas rupestres de Mesoamérica conocidas actualmente.

En Guerrero se tenían registrados hasta mayo de 2006 un total de 1.705 yacimientos arqueológicos, de los cuales, sólo siete se encuentran abiertos al público. Entre ellos destacan La Organera-Xochipala en el municipio de Eduardo Neri, Palma Sola en Acapulco, Cuetlajuchitlán en el municipio de Huitzuco, Teopantecuanitlán en el municipio de Copalillo y Tehuacalco en el municipio de Chilpancingo. En todas estas zonas arqueológicas el acceso es gratuito.

Entre los monumentos arquitectónicos de importancia destaca el Templo de Santa Prisca en la ciudad de Taxco de Alarcón, cuya fachada de laja rosa y sus dos torres de estilo churrigueresco, han hecho que se le proponga ante la Unesco como Patrimonio de la Humanidad. Otras catedrales coloniales que se encuentran en sus respectivos municipios destacan por su líneas sobrias, como ejemplo tenemos la Catedral de Ciudad Altamirano, construida en 1554, además de otras iglesias de importancia como la de Tixtla, San José Poliutla y San Francisco. A la par existen otras edificaciones históricas como el Fuerte de San Diego (Museo Histórico de Acapulco), levantado en el siglo XVIII como defensa marítima en Acapulco y el edificio que alberga al Museo Regional de Guerrero en Chilpancingo.

Guerrero es una zona muy importante en cuanto a cultura prehispánica, sin embargo los gobiernos estatales poco han hecho por promover estos sitios arqueológicos, para aquellos visitantes de nuestro estado que aparte de la playa quieran visitar una zona arqueológica, Tehuacalco es sin duda una visita obligatoria.

En esta zona arqueológica podemos encontrar más de una decena de estructuras, sus primeras edificaciones datan del año 650 a.C. y su decadencia se calcula alrededor del año 1300 d.C. aunque siguió siendo habitado hasta el siglo XVI, es probable que hay sido habitado por los yopes o yopimes, grupo étnico del Yopitzingo, se dice que este grupo nunca llegó a ser conquistado por los aztecas.

Las estructuras en este sitio fungen un papel secundario, ya que este lugar fue edificado en relación a los cerros circundantes, los cuales eran considerados sagrados: La Compuerta, El Capulín, Tierra Colorada y el Gavilán.

Se conocen 19 estructuras, de las cuales se distinguen 5 complejos mayores: La Encinera o Templo Principal, El Palacio, El Templo del Espejo de Agua, el Juego de Pelota y la plataforma habitacional, también existen estructuras de menor tamaño con visibles características religiosas, entras que podemos mencionar El Bocote, El Templo Rojo y el Altar de la Roca.

Para llegar a este sitio es posible hacerlo desde la Autopista del Sol, saliéndose en la desviación a Tierra Colorada, y tomar hacia el norte hasta el crucero de La Haciendita, kilómetro 57; Si se viaja por la carretera libre México – Acapulco (carretera 95), el crucero mencionado se halla al sur de Carrizal de la vía o al norte de Tierra Colorada. De ahí se toma la desviación para bajar hasta un lecho de un río donde hay un puente de concreto, y seguir la carretera asfaltada que llega a la zona arqueológica.

También es posible tomar taxis desde El Ocotito o Tierra Colorada.

Para hacer esta visita se recomienda llevar abundante agua, comida preparada, zapatos ligeros y cómodos, bloqueador solar, así como gorras o sombreros para protegerse del sol en los recorridos. No olvidar la cámara fotográfica.

La entrada a este sitio no tiene costo y funciona de martes a domingo en un horario de 9 AM a 5 PM.

La educación en el Estado de Guerrero se ha caracterizado por estar entre los últimos lugares del desarrollo nacional educativo. De acuerdo al Informe de Actividades 2005 del Programa de la Organización de las Naciones Unidas para el Desarrollo, entre los estados de México Guerrero tiene el lugar número 30 en aprovechamiento educativo, con un índice de 0,7491, el tercer sitio más bajo del país, sólo superado por Oaxaca y Chiapas.
La alfabetización tiene rasgos muy desiguales, pues de la población mayor de 15 años en el estado, la mayor tasa la registró Acapulco con 90,5 % de población alfabetizada, y la más baja el municipio de Cochoapa el grande con 24,1 %

El sector salud en Guerrero posee 1.061 centros médicos, y 14.658 personas trabajando en estas unidades, de las que 4.008 son médicos y 10.650 paramédicos. En 2005 se registraron 8.349 consultas médicas.

Los niveles del Índice de Desarrollo Humano son casi iguales en materia de educación y salud, pues Guerrero tiene el lugar 30º de desarrollo humano.

A 2006, hay 8.099 alumnos en preescolar, 24.999 en primaria, 10.546 en el nivel secundaria, y la relación alumno-maestro es de 22 %.

En materia de cultura, Guerrero posee influencias purépechas (Costa Grande y Tierra Caliente), matlazinca (Tierra Caliente), Tlahuica (Norte y Montaña), tlapaneca (Montaña) y yope (Costa Chica). Las influencias culturales de olmecas, teotihuacanas, mayas, purépechas, toltecas y mexicas se manifiestan en sitios arqueológicos como Teopantecuanitlán, Tepolzis, Tixtla, Huamuxtitlán, Ixcateopan, La Organera, Xochipala, Cuetlajuchitlán y Palma Sola.

También es un estado rico en artesanías. Destacan la alfarería, textiles de lana y algodón, madera, talabartería, y metalistería en Costa Grande. Tierra Caliente posee alfarería y orfebrería. La Sierra del Norte textiles en lana y algodón, madera, talabartería y orfebrería. Costa Grande tiene talabartería y la Montaña textiles de lana y algodón, madera y talabartería. Por otra parte, existen grupos culturales como grupos de danza mestiza, así como compañías teatrales destacadas como la compañía "Azul Montaña", proveniente de la ciudad de Atoyac de Álvarez, Guerrero.

Algunos bienes muebles o inmuebles protegidos que son patrimonio de la Nación, y están declarados como tales en el Registro Público de Monumentos y Zonas Arqueológicos del Instituto Nacional de Antropología e Historia

El estado de Guerrero presenta gran variedad de comidas, esto se debe al sincretismo de las culturas indígenas, española y francesa. Entre los platos típicos se encuentran los jumiles, aporreado, chalupitas, relleno, pozoles, moles, salsas de chile, tortillas, frijoles que son consumidos de diversas maneras.

La bebida alcohólica típica es el mezcal. Entre las no alcohólicas encontramos una gran gama en la que destacan las infusiones de hojas secas, conocidas como té, el chilate, creado a base de cacao y especias; aguas de limón, naranja, guayaba, mango, piña, tamarindo y otras frutas.

Como artesanía, la alfarería en el estado de Guerrero es uno de los recursos culturales más comunes y utilizado en el diario vivir de los pobladores, como ollas, vasijas, jarros, candeleros. Pero no sólo se limita a la fabricación de utensilios y enseres, sino también a la producción de juguetes, adornos, esculturas. Todos estos elementos son decorados con dibujos de distintos colores, estos pueden incluir motivos florales, representaciones de animales o de la naturaleza.

Los materiales de construcción de la alfarería de Guerrero son barro y algodón desmenuzado. Las técnicas de decoración consiste en pulir la superficie y posteriormente pintarla con pinceles y distintos esmaltes de colores en algunos casos se puede recurrir a un procedimiento de barnizado.

Instituciones de nivel superior:

+ Universidad Tecnologica del Mar del Estado de Guerrero (Utmar)

El estado de Guerrero cuenta con un equipo en la Segunda División de fútbol, el Internacional, y con Cinco equipos en la Tercera División, Gallos Blancos de Zihuatanejo y los Lobos de Zihuatanejo. Actualmente está en desarrollo la construcción de un estadio en Acapulco, en la zona de Barra Vieja.


Entre las celebraciones más propias del estado se encuentra la Danza de los Tlacololeros, originaria de la población de Chichihualco, la cual se lleva a cabo anualmente en septiembre durante las festividades de San Miguel Arcángel: 29 de septiembre; 14 de septiembre, festividad del Xilocruz; segundo domingo de septiembre, tradicional pendón; 28 de septiembre, Teopancalaquis, y en Chilpancingo vísperas de feria, y 24 de diciembre, tradicional feria de San Mateo. La danza también se ejecuta en otros lugares del estado. También destacan las festividades de la población de Mochitlán, por cuyos callejones se pasean toros, y las danzas del 24 al 26 de julio, en honor a Santa Ana.

En el estado de Guerrero, la celebración del Día de Muertosguarda características particulares, ya que los habitantes montan sus ofrendas a partir del 31 de octubre, y el sacristán hace repicar las campanas al mediodía, con lo que se anuncia la llegada de todos los santos. En las ofrendas, la comida se sirve en platos, cazuelas y vasos de barro; algo distintivo es el pan conocido como "caja de Heas", elaborado con harina de arroz; entre las flores, predominan el cempaxúchitl, la nube y el terciopelo; también se acostumbran las fotografías de los difuntos, las calaveras de azúcar, las veladoras. Se prende copal para recibir a los difuntos con un olor agradable, además de poner un camino de cal hacia el altar.

A diferencia de la de otros lugares, la celebración del pueblo nahua, que es considerado el pueblo indígena más grande de la región, comienza un mes antes, es decir, en septiembre. En esta se hacen oraciones, y repican las campanas durante la noche en la iglesia central o en las capillas. Este pueblo recibe la visita de las almas de los infantes el 31 de octubre; el altar se adorna con figuras de ángeles. El 1 de noviembre, se reciben las almas de los difuntos adultos, y el 2 de noviembre se visitan los panteones, en donde se reza por el descanso de los difuntos. En el pueblo de Teleolapan, la celebración se complementa con la danza de los tecuanes, una danza acerca de dos caciques: Lucas y Moranchi, con una relación no muy buena; ambos tenían muchas vacas y bueyes; el ganado comienza a desaparecer, y tiempo después se dan cuenta de que el culpable era un tigre o "tecuan"; Moranchi visita a Lucas junto con su tribu, pero lo hace en una forma muy peculiar, danzando en modo de saludo.

Los orígenes de esta danza se remontan a la época colonial, como una manifestación de la evangelización de las misiones que querían inculcar a los indios los conceptos básicos de la religión cristiana, así como una nueva concepción de los valores del bien y del mal. En esta danza existen dos personajes principales: la muerte y lucífer. Además, aparecen cuando menos 6 parejas de diablos y 2 o 3 bufones, llamados “huesquistles”. En el baile, el diablo mayor está golpeando una quijada de burro, rítmicamente; al mismo tiempo, al frente de una fila aparece una diabla, quien lleva una tonadilla musical con una guitarra, que es la que sirve de acompañamiento a la danza. Otro diablo hace sonar rítmicamente una caja de madera. Esta danza se representa, principalmente en: Tixtla, Chilapa, Chilpancingo, etc.

Su origen se remonta a fines del siglo XVIII, y su contenido critica las costumbres de la clase social alta, a fin de que la clase baja pudiera descargar públicamente su rencor hacia la gente que la humillaba y explotaba. La vestimenta es la de aquellos tiempos, utilizando todo lo que parece adecuado a los fines de esta danza.

Esta danza se refiere a los españoles radicados en México. Los danzantes llevan en la mano un pañuelo grande, con cuyos movimientos lanzan golpes al aire frente a su rostro; con este abaniqueo indican los movimientos que hacían los gachupines para espantar los mosquitos. Su vestuario es: saco, pantalón y zapatos de color negro, gorra o cachucha; la máscara muestra rasgos semejantes a los de los españoles y un cigarrillo en la boca, con lo que se simula el puro que los españoles suelen fumar.

Esta danza enseña gráficamente a distinguir entre el bien y el mal, supuestamente trabados en eterna lucha. Participan en esta danza: el fraile, el jugador, el estudiante, la quinceañera, el enamorado y la muerte. Los danzantes establecen, entre sí, diálogos con relatos especiales y bailan por parejas el tema musical que se les destina. Esta danza se realiza en los municipios de Chilapa y de Tlapa, entre otros.

Se le da este nombre por sus participantes que llevan terciado, del hombro derecho hacia el lado izquierdo, una sarta de pescaditos de madera pintados de colores. Su objetivo es interpretar la actividad de los hombres que se dedican a la pesca; por su vestimenta, los danzantes tratan de representar a las personas nativas de las costas Grande y Chica del estado; su atuendo se compone de: pantalón largo, huaraches, camisa de manta, faldas sueltas, máscara negra (que simula el color moreno de los costeños) con señales de profundas cicatrices producidas por las comunes riñas, sombrero de palma de uso diario y machete de cinta, fabricado en la región.

Esta representa a un grupo de trabajadores campesinos dedicados al cuidado y a domar las bestias mulares, propiedad de los ricos españoles; por esta actividad, los trabajadores recibían el nombre de "machos". La característica principal por la que se identifica esta danza es porque los danzantes llevan consigo una pequeña cabeza y pescuezo de madera, que representa a la bestia mular. En esta danza sólo una persona se viste de mujer, con ropa de principios del siglo XX, tal como se vestía la mujer de pueblo: enaguas largas, blusa de tela corriente y floreada, rebozo enrollado a la cintura con las puntas echadas hacia atrás sobre los hombros terciado al pecho y sombrero de palma común. La máscara da el aspecto alegre y jovial de la mujer mestiza.

Es una remembranza de las sangrientas batallas entre moros y cristianos, cuando estos fueron auxiliados por los “cruzados” llegados de todas partes de Europa en el año 1212. Los cristianos van guiados por un danzante con apariencia del señor Santiago, montado en su caballo blanco. Moros y cristianos llevan machete largo que hacen chocar entre unos y otros, lo que da la idea de una batalla. Su vestuario consta de: chaqueta larga de gamuza sin mangas ni solapa, sombrero de madera ligera, pintado de negro y con adornos de flores de papel de distintos colores llevando en el filo abundante cabellera crespa; la máscara representa el tipo blanco, europeo, y simula espesas patillas y piocha hacia delante. Los lugares donde se lleva a cabo esta danza son la cabecera municipal de Cuautepec y Acapulco, etc.

Los dos personajes principales del grupo reciben el nombre de Maizo y Salvador, y representan a los grandes señores de importantes ciudades, amantes de la cacería. En esta danza, también participa un grupo de huesquixtles, todos varones; llevan en la espalda un petate viejo o cualquier otra cosa, para no recibir en seco los latigazos que constantemente les dan el Maizo y el Salvador durante el baile. Los huesquixtles representan a los hombres modestos de la región, donde se hace la cacería del tigre.

Su vestimenta es toda negra: levitas que simulan las alas y máscaras con las características de estas aves. El propósito de esta danza es representar un festín de estas aves de rapiña en torno a un animal muerto que uno de los huesquixtles lleva consigo.

Los tejoneros tienen por finalidad danzar en las fiestas de carnaval y en las de Corpus, y tienen un gran repertorio de juegos de danzas, entre las que se encuentran: las del tigre, guajolote, el coyote, etcétera. La finalidad de estas danzas es divertir con sus travesuras, que corresponden a la categoría de los demonios o anticristos que ellos se atribuyen.

Los danzantes son 23: un monarca, 6 capitanes, 14 palomos y 2 malinches, cada uno con sus sones y zapateados especiales. El personaje principal es el “monarca” que danza acompañado de las malinches o sólo y ejecuta pasos vistosos. Esta danza es originaria de San Miguel Totolapan, de Tierra Caliente.

La música popular está compuesta por conjuntos de violines, guitarras sextas y tamboritas en Tierra Caliente. Bandas de aliento y música indígena con flauta de carrizo, charasca, violín y tambor en la Montaña. Conjuntos de sones con arpa, vihuela y jarana, danzas de tlacololeros, tecuanes, del tigre, los apaches y gachupines en el centro y la costa.

Por otra parte la música folclórica es prodigiosa en la región, ejemplo de esto es la música calentana que proviene de la región de Tierra Caliente, esta música se destaca por ser uno de los géneros culturales más ricos de la tradición popular local, y que en la actualidad aún permanece vigente. La música calentana se considera alegre, y es muy frecuentes en bodas, bautizos, cumpleaños y cualquier otro tipo de fiestas, cada una con un distinto repertorio, por esta razón este estilo es interpretado incluso en velorios, en donde se presentan melodías que representen la tristeza de los presentes.

El estado de Guerrero cuenta con 3.079.649 habitantes, de los cuales 17,2 % son indígenas (529.780 personas). La población indígena en Guerrero se encuentra esencialmente en la zona de la Montaña y en menor medida en la Costa Chica, siendo éstas las zonas más marginadas del estado.

La población indígena se reparte en 4 grupos:


De acuerdo a cifras difundidas por la SEDESOL de Guerrero, éste es el panorama de la población indígena en Guerrero:



Guerrero cuenta con dos Oficina de Representación de la Dirección General de Atención a Migrantes en el Extranjero.



</doc>
<doc id="1356" url="https://es.wikipedia.org/wiki?curid=1356" title="Guerra civil española">
Guerra civil española

La guerra civil española, o guerra de España, fue un conflicto social, político y bélico —que más tarde repercutiría también en una crisis económica— que se desencadenó en España tras el fracaso parcial del golpe de Estado del 17 y 18 de julio de 1936 llevado a cabo por una parte del Ejército contra el gobierno de la Segunda República. Tras el bloqueo del Estrecho y el posterior puente aéreo que, gracias a la rápida colaboración de la Alemania nazi y la Italia fascista, trasladó las tropas rebeldes a la Península en las últimas semanas de julio, comenzó una guerra civil que concluiría el 1 de abril de 1939 con el último parte de guerra firmado por Francisco Franco, declarando su victoria y estableciendo una dictadura que duraría hasta su muerte el 20 de noviembre de 1975.

La guerra tuvo múltiples facetas, pues incluyó lucha de clases, guerra de religión, enfrentamiento de nacionalismos opuestos, lucha entre dictadura militar y democracia republicana, entre revolución y contrarrevolución, entre fascismo y comunismo.

A las partes del conflicto se las suele denominar bando republicano y bando sublevado:

Ambos bandos cometieron y se acusaron recíprocamente de la comisión de graves crímenes en el frente y en las retaguardias, como sacas de presos, "paseos", desapariciones de personas o "tribunales" extrajudiciales. La dictadura de Franco investigó y condenó severamente los hechos delictivos cometidos en la zona republicana, llegando incluso a instruir una Causa General, todo ello con escasas garantías procesales. Por su parte, los delitos de los vencedores nunca fueron investigados ni enjuiciados durante el franquismo, a pesar de que algunos historiadores y juristas sostienen que hubo un genocidio en el que, además de subvertir el orden institucional, se habría intentado exterminar a la oposición política.

Las consecuencias de la Guerra Civil han marcado en gran medida la historia posterior de España, por lo excepcionalmente dramáticas y duraderas: tanto las demográficas —mortandad y descenso de la natalidad que marcaron la pirámide de población durante generaciones— como las materiales —destrucción de las ciudades, la estructura económica, el patrimonio artístico—, intelectuales —fin de la denominada Edad de Plata de las letras y ciencias— y políticas —la represión en la retaguardia de ambas zonas, mantenida por los vencedores con mayor o menor intensidad durante todo el franquismo, y el exilio republicano—, y que se perpetuaron mucho más allá de la prolongada posguerra, incluyendo la excepcionalidad geopolítica del mantenimiento del régimen de Franco hasta 1975.

En enero de 1930 el general Miguel Primo de Rivera reconoce el fracaso de la Dictadura que había instaurado en septiembre de 1923 con el apoyo del rey y dimite. Alfonso XIII nombra entonces como presidente del gobierno al general Dámaso Berenguer, pero este no consigue devolver a la monarquía la "normalidad constitucional" (este período fue conocido como "Dictablanda") y es sustituido en febrero de 1931 por el almirante Juan Bautista Aznar, quien convoca elecciones municipales para el domingo 12 de abril. Las elecciones son ganadas en las ciudades por las candidaturas republicano-socialistas surgidas del Pacto de San Sebastián de agosto de 1930 y el martes 14 de abril el rey Alfonso XIII, ante las dudas de la Guardia Civil y del Ejército a utilizar la fuerza para frenar las multitudinarias manifestaciones prorrepublicanas que inundan las principales ciudades, abandona el país. En Madrid el "comité revolucionario" republicano-socialista proclama la República y asume el poder como Gobierno Provisional presidido por Niceto Alcalá-Zamora.

Durante el primer bienio de la Segunda República Española se aprueba la nueva Constitución republicana y el gobierno de coalición de republicanos de izquierda y de socialistas presidido por Manuel Azaña, formado el 15 de diciembre de 1931 tras rechazar el Partido Republicano Radical su participación en el mismo por estar en desacuerdo con la continuidad en el gobierno de los socialistas, profundiza las reformas iniciadas por el Gobierno Provisional cuyo propósito es modernizar la realidad económica, social, política y cultural españolas. El nuevo gobierno se formó tras la elección de Niceto Alcalá Zamora como presidente de la República, quien confirmó a Manuel Azaña como presidente del Gobierno.

No obstante, el amplio abanico de reformas que emprendió el gobierno "social-azañista" encontró gran resistencia entre los grupos sociales y corporativos a los que se intentaba "descabalgar" de sus posiciones adquiridas: los terratenientes, los grandes empresarios, financieros y patronos, la Iglesia católica, las órdenes religiosas, la opinión católica, la opinión monárquica o el militarismo “africanista”. Este último organizó un fracasado golpe de estado en agosto de 1932 encabezado por el general Sanjurjo. Pero también existió una resistencia al reformismo republicano de signo contrario: el del revolucionarismo a ultranza, que encabezaron las organizaciones anarquistas (la CNT y la FAI). Para ellos, la República representaba el "orden burgués" (sin demasiadas diferencias con los regímenes políticos anteriores, Dictadura y Monarquía) que había de ser destruido para alcanzar el "comunismo libertario". Así se produjeron una serie de levantamientos anarquistas (en enero y diciembre de 1933) reprimidos con dureza.

La coalición encabezada por Azaña se deshace y se convocan elecciones para noviembre de 1933, en las que votaron por primera vez las mujeres, que son ganadas por la derecha católica de la CEDA y por el centro-derecha republicano del Partido Republicano Radical de Alejandro Lerroux. Este forma gobierno con el objetivo de “rectificar” las reformas del primer bienio, no anularlas, para incorporar a la República a la derecha “accidentalista” (que no se proclamaba abiertamente monárquica, aunque sus simpatías estuvieran con la Monarquía, ni tampoco republicana) representada por la CEDA y el Partido Agrario, que le dan su apoyo parlamentario. Cuando la CEDA entra en el gobierno en octubre de 1934 se desencadena la Revolución de Octubre, una fracasada insurrección socialista que solo se consolidó en Asturias durante un par de semanas (el único lugar donde también participó la CNT), aunque finalmente también fue sofocada por la intervención del Ejército, que trajo del Protectorado español de Marruecos a las tropas coloniales de regulares y legionarios y, una vez finalizada, se produjo una fuerte represión. Lo mismo sucedió con la proclamación por el presidente de la Generalidad de Cataluña Lluís Companys del "Estado Catalán" dentro de la "República Federal Española" el 6 de octubre.

La Revolución de octubre de 1934 hizo aumentar en el gobierno radical-cedista los temores a que un próximo intento de una "revolución bolchevique" acabara triunfando. Esto acentuó la presión sobre el Partido Radical para llevar adelante una política más decididamente legisladora o contrarrevolucionaria. En última instancia, los sucesos de octubre de 1934 convencieron a la CEDA de que era necesario llegar a alcanzar la presidencia del gobierno para poder dar el "giro autoritario" que el régimen, según ellos, necesitaba. El líder de la CEDA, José María Gil Robles, encontró su oportunidad cuando estallaron el escándalo del estraperlo y el del asunto Nombela que hundieron a Lerroux y al Partido Republicano Radical, del que no se recuperaría. Pero el Presidente de la República Alcalá Zamora se negó a dar el poder a una fuerza “accidentalista” que no había proclamado su fidelidad a la República y encargó la formación de gobierno a un independiente de su confianza, Manuel Portela Valladares, quien forma el 15 de diciembre un gabinete republicano de centro-derecha que aguanta el poder Ejecutivo hasta que Alcalá Zamora convoca elecciones para el 16 de febrero de 1936.

El resultado de las elecciones de febrero de 1936 fue un reparto muy equilibrado de votos con una leve ventaja de las izquierdas (47.1%) sobre las derechas (45.6%), mientras el centro se limitó a un 5.3%. Pero como el sistema electoral primaba a los ganadores, esto se tradujo en una holgada mayoría para la coalición del Frente Popular.

El miércoles 19 de febrero, Manuel Azaña, el líder del Frente Popular, formaba un gobierno que, conforme a lo pactado con los socialistas, solo estaba integrado por ministros republicanos de izquierda (nueve de Izquierda Republicana y tres de Unión Republicana). Una de sus primeras decisiones fue alejar de los centros de poder a los generales más antirrepublicanos: el general Manuel Goded fue destinado a la Comandancia militar de Baleares; el general Francisco Franco, a la de Canarias; el general Emilio Mola al gobierno militar de Pamplona. Otros generales significados como Luis Orgaz, Rafael Villegas, Joaquín Fanjul y Andrés Saliquet quedaron en situación de disponibles.

La medida más urgente que hubo de tomar el nuevo gobierno fue la amnistía de los condenados por los sucesos de octubre de 1934, "legalizando" así el asalto a varias cárceles por la multitud, pero dando cumplimiento también al punto principal del programa electoral del Frente Popular. Otra de las medidas urgentes era reponer en sus puestos a los alcaldes y concejales elegidos en 1931 y sustituidos durante el bienio conservador. El 28 de febrero el gobierno decretaba no solo la readmisión de todos los trabajadores despedidos por motivos políticos y sindicales relacionados con los hechos de 1934, sino que, presionado por los sindicatos, ordenaba a las empresas que indemnizaran a estos trabajadores por los jornales no abonados. Asimismo, fue restablecido el gobierno de la Generalidad de Cataluña, cuyos miembros habían salido de la cárcel beneficiados también por la amnistía.

La “cuestión agraria” fue otro problema que el nuevo gobierno tuvo que abordar con urgencia a causa de la intensa movilización campesina que se estaba produciendo con el apoyo decidido de las autoridades locales repuestas y que amenazaba con provocar graves conflictos en el campo, especialmente en Extremadura. Así el 19 de abril el ministro de Agricultura, Mariano Ruiz Funes, presentaba varios proyectos de ley, entre ellos uno que derogaba la Ley de Reforma de la Reforma Agraria de agosto de 1935, que se convirtió en ley el 11 de junio, por lo que volvía estar en vigor plenamente la Ley de Reforma Agraria de 1932. Gracias a varios decretos y a esta ley entre marzo y julio de 1936 se asentaron unos 115000 campesinos, más que en los tres años anteriores. Sin embargo, continuó la alta conflictividad en el campo, debida sobre todo a la actitud de los propietarios y a la radicalización de las organizaciones campesinas, saldándose todo ello con incidentes violentos. El caso más grave se produjo en Yeste (Albacete), donde a finales de mayo de 1936 "la detención de unos campesinos que pretendían talar árboles en una finca particular condujo a un sangriento enfrentamiento entre la Guardia Civil y los jornaleros, en los que murieron un guardia y 17 campesinos, varios de ellos asesinados a sangre fría por los agentes".

La actividad del parlamento estuvo paralizada casi todo el mes de abril debido al proceso de destitución del presidente de la República Niceto Alcalá-Zamora, iniciado y aprobado por la izquierda, y su sustitución por Manuel Azaña, que fue investido en su nuevo cargo el 10 de mayo de 1936, siendo sustituido al frente del gobierno por su compañero del partido Izquierda Republicana, Santiago Casares Quiroga, quien asumiría a su vez la cartera de Guerra.

El nuevo gobierno de Casares Quiroga continuó con la política reformista que ya había iniciado el gobierno Azaña que consistía fundamentalmente en volver a poner en vigor los decretos que habían sido derogados o modificados durante el bienio radical-cedista, a los que se añadieron algunos otros.

Uno de los problemas a los que tuvo que hacer frente el gobierno fue la oleada de huelgas que se produjeron declaradas y sostenidas muchas veces por comités conjuntos de la CNT y la UGT, en las que en muchas de ellas se hablaba de revolución, pero ni UGT ni CNT preparaban ningún movimiento insurreccional después de los fracasos continuos de 1932, 1933 y 1934, y la única posibilidad de que se produjese alguno sería como respuesta a un intento de golpe militar.

Otro de los problemas del gobierno de Casares Quiroga fue la división interna del PSOE, el partido más importante del Frente Popular, que enfrentaba a los sectores "prietista" y "largocaballerista", ya que Francisco Largo Caballero, que dominaba UGT y el grupo parlamentario del PSOE, continuó oponiéndose a la entrada en el gobierno de los socialistas y defendiendo el entendimiento entre las “organizaciones obreras” para esperar el momento en que el fracaso de los “burgueses republicanos" facilitara la conquista del poder por la clase obrera. Otro problema fue que el sector de la CEDA liderado por Gil Robles se decantaba por realizar un boicot a las instituciones republicanas y por apoyar la posición defendida de la derecha monárquica del Bloque Nacional de José Calvo Sotelo, que propugnaba abiertamente por la ruptura violenta del orden constitucional mediante un golpe de estado militar en cuya preparación ya estaban colaborando (por su parte los monárquicos carlistas aceleraron la formación de sus milicias requetés con vistas al alzamiento militar con cuyos dirigentes mantenían contactos).

Los gobiernos del Frente Popular también tuvieron que hacer frente a un aumento de la violencia política provocada por el partido fascista Falange Española, que a principios de 1936 era una fuerza política marginal, pero que tras el triunfo del Frente Popular recibió una avalancha de afiliaciones de jóvenes de derechas dispuestos a la acción violenta, y por la respuesta que le dieron las organizaciones de izquierda. El primer atentado importante que cometieron los falangistas fue el perpetrado el 12 de marzo de 1936 contra el diputado socialista y “padre” de la Constitución de 1931 Luis Jiménez de Asúa, en el que este resultó ileso, pero su escolta, el policía Jesús Gisbert, murió. La respuesta del gobierno de Azaña fue prohibir el partido y detener el 14 de marzo a su máximo dirigente José Antonio Primo de Rivera, pero el paso a la clandestinidad no impidió que siguiera perpetrando atentados y participando en reyertas con jóvenes socialistas y comunistas.

Los incidentes de mayor trascendencia se produjeron los días 14 y 15 de abril. El día 14 tuvo lugar un desfile militar en el Paseo de la Castellana de Madrid en conmemoración del Quinto Aniversario de la República. Junto a la tribuna principal estalló un artefacto y se produjeron a continuación varios disparos que causaron la muerte a Anastasio de los Reyes, alférez de la Guardia Civil que estaba allí de paisano, e hirieron a varios espectadores. Derechistas e izquierdistas se acusaron mutuamente del atentado. Al día siguiente se celebró el entierro del alférez que se convirtió en una manifestación antirrepublicana a la que asistieron los diputados José María Gil Robles, líder de la CEDA, y José Calvo Sotelo, líder de la derecha monárquica, además de oficiales del ejército y falangistas armados. Desde diversos lugares se produjeron disparos contra la comitiva que fueron respondidos, produciéndose un saldo de seis muertos y de tres heridos. Uno de los muertos fue el estudiante Ángel Sáenz de Heredia, falangista y primo hermano de José Antonio Primo de Rivera. También resultó herido un joven tradicionalista (carlista), José Llaguno Acha, y una muchedumbre intentó linchar al teniente José del Castillo Sáenz de Tejada al que se le acusó de dispararle.

Entre abril y julio los atentados y las reyertas protagonizadas por falangistas causaron más de cincuenta víctimas entre las organizaciones de izquierda obrera, la mayoría de ellas en Madrid. Unos cuarenta miembros de Falange murieron en esos actos o en atentados de represalia de las organizaciones de izquierda. También fueron objeto de la violencia los edificios religiosos (un centenar de iglesias y conventos fueron asaltados e incendiados) aunque entre las víctimas de la violencia política de febrero a julio no hubo ningún miembro del clero.

El aumento de la violencia política y el crecimiento de las organizaciones juveniles paramilitares tanto entre la derecha (milicias falangistas, requetés carlistas) como entre la izquierda (milicias de las juventudes socialistas, comunistas y anarquistas), y entre los nacionalistas vascos y catalanes (milicias de Esquerra Republicana de Catalunya y del PNV), aunque no estaban armadas y su actividad principal era desfilar, provocó la percepción entre parte de la opinión pública, especialmente la conservadora, de que el gobierno del Frente Popular presidido por Santiago Casares Quiroga no era capaz de mantener el orden público, lo que servía de justificación para el «golpe de fuerza» militar que se estaba preparando. A esta percepción también contribuyó la prensa católica y de extrema derecha que incitaba a la rebelión frente al “desorden” que atribuía al «Gobierno tiránico del Frente Popular», «enemigo de Dios y de la Iglesia», aprovechando que la confrontación entre clericalismo y anticlericalismo volvió al primer plano tras las elecciones de febrero con continuas disputas sobre asuntos simbólicos, como el tañido de campanas o las manifestaciones del culto fuera de las iglesias, como procesiones o entierros católicos. Así mismo, en el parlamento, los diputados de la derecha, singularmente Calvo Sotelo y Gil Robles, acusaron al gobierno de haber perdido el control del orden público.

En la noche del domingo 12 de julio era asesinado en la calle de Fuencarral de Madrid el teniente de la Guardia de Asalto e instructor de las milicias socialistas José del Castillo Sáenz de Tejada, que se dirigía a su puesto de trabajo en el Cuartel de Pontejos, probablemente por pistoleros de extrema derecha pertenecientes a la Comunión Tradicionalista (o de Falange Española). El teniente Castillo era muy conocido por su activismo izquierdista y se le atribuía la frase «Yo no tiro sobre el pueblo» tras haberse negado a participar en la represión de la Revolución de Asturias, acto de rebeldía que le costaría un año de cárcel.

Como represalia, los compañeros policías del teniente Castillo, dirigidos por el capitán de la Guardia Civil Fernando Condés, secuestraron en su propio domicilio y asesinaron en la madrugada del día siguiente a José Calvo Sotelo, líder de los monárquicos "alfonsinos" (que no tuvo nada que ver con el asesinato del teniente Castillo), y abandonaron el cadáver en el depósito del cementerio de la Almudena. En el entierro de Calvo Sotelo, el dirigente monárquico Antonio Goicoechea juró solemnemente «consagrar nuestra vida a esta triple labor: imitar tu ejemplo, vengar tu muerte y salvar a España». Por su parte, el líder de la CEDA, José María Gil Robles en las Cortes les dijo a los diputados de la izquierda que «la sangre del señor Calvo Sotelo está sobre vosotros» y acusó al gobierno de tener la «responsabilidad moral» del crimen por «patrocinar la violencia».

Según el estudio más completo que se ha realizado sobre las víctimas mortales como resultado de la violencia política entre febrero y julio de 1936, antes de iniciarse el golpe de estado, hubo un total de 189 incidentes y 262 muertos, de ellos 112 causados por la intervención de las fuerzas de orden público. De las 262 víctimas, 148 serían militantes de la izquierda, 50 de la derecha, 19 de las fuerzas de orden público y 45 sin identificar. Además ese estudio constata que el número de víctimas mortales causadas por la violencia política fue disminuyendo en esos cinco meses.

La violencia política de los meses de gobierno en paz del Frente Popular, de febrero a julio de 1936, fue utilizada después por los vencedores en la Guerra Civil como justificación de su alzamiento. Hoy en día, el debate sigue abierto, aunque la mayoría de los historiadores opinan que en absoluto puede hablarse de una «primavera trágica» en la que el gobierno del Frente Popular hubiera perdido el control de la situación. Y la conclusión de la mayoría de ellos es clara: «La desestabilización política real en la primavera de 1936 no explica en modo alguno la sublevación militar [de julio de 1936] y menos aún la justifica». «La política y la sociedad españolas mostraban signos inequívocos de crisis, lo cual no significa necesariamente que la única salida fuera una guerra civil».

Durante los primeros meses de 1936 se produjo una polarización de la política española, en cuyos extremos se situaba la izquierda revolucionaria y la derecha fascista, y en medio una izquierda moderada y una derecha republicana junto con un centro anticlerical y una derecha de fuerte componente católico y monárquico (que representaba a muchos militares, terratenientes y a la jerarquía católica que veían peligrar su posición privilegiada y su concepto de la unidad de España). Una división que podía remontarse al siglo XIX cuando tuvo lugar el difícil proceso de cambio que se inició en 1808 para poner fin al absolutismo que lastraba al país, manteniendo fuertes diferencias económicas entre privilegiados y no privilegiados, y que el moderantismo decimonónico solo consiguió superar parte. El resultado fue una población rural dividida entre los jornaleros anarquistas y los pequeños propietarios aferrados a (y dominados por) los caciques y la Iglesia; unos burócratas conformistas y una clase obrera con salarios muy bajos y, por lo tanto, con tendencias revolucionarias propias del nuevo siglo, hacen que también entre las clases pobres la división fuese muy acusada. También provenía del siglo XIX la tradición de que los problemas no se arreglaban más que con los pronunciamientos. No es extraño, pues, que en una España marcada por la reciente dictadura de Primo de Rivera e intentonas fallidas, como las de José Sanjurjo, volviese a haber ruido de sables y se temiese un plan para derribar al nuevo Gobierno establecido. Los acontecimientos darían la razón a los pesimistas.

Nada más conocerse la victoria del Frente Popular en las elecciones, se produjo un primer intento de «golpe de fuerza» por parte de la derecha para intentar frenar la entrega del poder a los vencedores. Fue el propio Gil Robles el primero que intentó sin éxito que el presidente del gobierno en funciones Manuel Portela Valladares declarase el «estado de guerra» y anulara los comicios. Le siguió el general Franco, aún jefe del Estado Mayor del Ejército, que se adelantó a dar las órdenes pertinentes a los mandos militares para que declarasen el estado de guerra (lo que según la ley de Orden Público de 1933 suponía que el poder pasaba a las autoridades militares), pero fue desautorizado por el todavía jefe de gobierno Portela Valladares y por el ministro de la guerra el general Nicolás Molero.

El 8 de marzo de 1936 tuvo lugar en Madrid, en casa de un amigo de Gil Robles, una reunión de varios generales (Emilio Mola, Luis Orgaz Yoldi, Villegas, Joaquín Fanjul, Francisco Franco, Ángel Rodríguez del Barrio, Miguel García de la Herrán, Manuel González Carrasco, Andrés Saliquet y Miguel Ponte, junto con el coronel José Enrique Varela y el teniente coronel Valentín Galarza, como hombre de la UME), en la que acordaron organizar un «alzamiento militar» que derribara al gobierno del Frente Popular recién constituido y «restableciera el orden en el interior y el prestigio internacional de España». También se acordó que el gobierno lo desempeñaría una Junta Militar presidida por el general Sanjurjo, que en esos momentos se encontraba en el exilio en Portugal.

Desde finales de abril, fue el general Mola quien tomó la dirección de la trama golpista (desplazándose así el centro de la conspiración de Madrid a Pamplona), adoptando el nombre clave de “El Director”. Este continuó con el proyecto de constituir una Junta Militar presidida por el general Sanjurjo, y comenzó a redactar y difundir una serie de circulares o “Instrucciones reservadas” en las que fue perfilando la compleja trama que llevaría adelante el golpe de Estado. La primera de las cinco “instrucciones reservadas” la dictó el 25 de mayo y en ella ya apareció la idea de que el golpe tendría que ir acompañado de una violenta represión.

Mola consiguió comprometer en el golpe a numerosas guarniciones, gracias también a la trama clandestina de la UME pero tenía dudas sobre el triunfo del golpe en el lugar fundamental, Madrid, y también sobre Cataluña, Andalucía y Valencia. Así pues, el problema de los militares implicados era que, a diferencia del golpe de estado de 1923, ahora no contaban con la totalidad del Ejército (ni de la Guardia Civil ni las otras fuerzas de seguridad) para respaldarlo. Una segunda diferencia respecto de 1923 era que la actitud de las organizaciones obreras y campesinas no sería de pasividad ante el golpe militar sino que como habían anunciado desencadenarían una revolución. Por estas razones se fue retrasando una y otra vez la fecha del golpe militar, y por eso, además, el general Mola, "el Director", buscó el apoyo de las milicias de los partidos antirrepublicanos (requetés y falangistas) y el respaldo financiero de los partidos de la derecha. Al gobierno de Casares Quiroga le llegaron por diversas fuentes noticias de lo que se estaba tramando pero no actuó con contundencia contra los conspiradores.

A principios de julio de 1936 la preparación del golpe militar estaba casi terminada, aunque el general Mola reconocía que «el entusiasmo por la causa no ha llegado todavía al grado de exaltación necesario» y acusaba a los carlistas de seguir poniendo dificultades al continuar pidiendo «concesiones inadmisibles». El plan del general Emilio Mola era un levantamiento coordinado de todas las guarniciones comprometidas, que implantarían el estado de guerra en sus demarcaciones, comenzando por el Ejército de África, que entre los días 5 y 12 de julio realizó unas maniobras en el Llano Amarillo donde se terminaron de perfilar los detalles de la sublevación en el Protectorado de Marruecos. Como se preveía que en Madrid era difícil que el golpe triunfase por sí solo (la sublevación en la capital estaría al mando del general Fanjul), estaba previsto que desde el norte una columna dirigida por el propio Mola se dirigiera hacia Madrid para apoyar el levantamiento de la guarnición de la capital. Y por si todo eso fallaba también estaba planeado que el general Franco, después de sublevar las islas Canarias, se dirigiría desde allí al Protectorado de Marruecos a bordo del avión Dragon Rapide, fletado en Londres el 6 de julio por el corresponsal del diario "ABC" Luis Bolín gracias al dinero aportado por el financiero Juan March, para ponerse al frente de las tropas coloniales, cruzar el estrecho de Gibraltar y avanzar sobre Madrid. Una vez depuesto el gobierno de la República, se instauraría una dictadura militar siguiendo el modelo de la Dictadura de Primo de Rivera, al frente de la cual se situaría el exiliado general Sanjurjo. «Los sublevados llevaron a cabo su acción pretendiendo que se alzaban contra una revolución absolutamente inexistente en la época en que actúan, inventan documentos falsos que compuso Tomás Borrás y que hablaban de un gobierno soviético que se preparaba, y de hecho lo que representaban era la defensa de las posiciones de las viejas clases dominantes, la lucha contra las reformas sociales, más o menos profundas, que el Frente Popular pone de nuevo en marcha».

El asesinato de José Calvo Sotelo en la madrugada del 13 de julio aceleró el compromiso con la sublevación de los carlistas y también de la CEDA, y acabó de convencer a los militares que tenían dudas, entre ellos, según Paul Preston, el general Franco. Además, Mola decidió aprovechar la conmoción que había causado en el país el doble crimen, y el día 14 adelantó la fecha de la sublevación que quedó fijada para los días 18 y 19 de julio de 1936.

El 17 de julio por la mañana en Melilla, los dos coroneles y otros oficiales que estaban al tanto del alzamiento militar se reúnen en el departamento cartográfico y trazan los planes para ocupar el 18 los edificios públicos, planes que comunican a los dirigentes falangistas. Uno de los dirigentes locales de la Falange informa al dirigente local de Unión Republicana, llegando esta información al General Romerales, Comandante Militar de Melilla, que a su vez informa a Casares Quiroga. Romerales envía por la tarde una patrulla de soldados y guardias de asalto a registrar el departamento cartográfico. El coronel al mando del mismo retrasa el registro y llama al cuartel de la Legión, desde donde le envían un grupo de legionarios. Ante estos, la patrulla se rinde y los sublevados proceden a arrestar a Romerales (que fue fusilado junto con el delegado del gobierno y el alcalde de Melilla que se habían resistido a la rebelión), proclaman el estado de guerra e inician anticipadamente el levantamiento, informando a sus compañeros del protectorado de Marruecos que habían sido descubiertos. Esto hizo que se adelantase en Marruecos la fecha prevista. En los tres días siguientes el golpe se extendió a las guarniciones de la península, Canarias y Baleares.
Los militares sublevados no consiguieron alcanzar su objetivo principal de apoderarse del punto neurálgico del poder, Madrid, ni de las grandes ciudades, como Barcelona, Valencia, Bilbao, Málaga o Murcia (aunque sí controlaban Sevilla, Valladolid, Zaragoza y Córdoba), pero dominaban cerca de la mitad del territorio español, ya que controlaban prácticamente el tercio norte peninsular (Galicia, León, Castilla la Vieja, Álava, Navarra, gran parte de la provincia de Cáceres, incluida la capital, y la mitad occidental de Aragón, incluyendo las tres capitales provinciales), menos la franja cantábrica formada por Asturias, Santander, Vizcaya y Guipúzcoa, que quedó aislada del resto de la zona republicana, y Cataluña. Además dominaban las ciudades andaluzas de Sevilla (donde el general Gonzalo Queipo de Llano se hace con inusitada determinación con el mando de la 2.ª División Orgánica), Córdoba y Cádiz conectadas entre sí por una estrecha franja (así como la ciudad de Granada, pero aislada del resto), más todo el Protectorado de Marruecos y los dos archipiélagos, Canarias (menos la isla de La Palma) y Baleares (excepto Menorca). Fuera de esta área controlaban determinados lugares y puntos de resistencia aislados dentro de la zona republicana como la ciudad de Oviedo (que soportó un asedio por parte de los republicanos durante 90 días, hasta la entrada de las tropas franquistas el 17 de octubre), el cuartel de Simancas en Gijón, el Alcázar de Toledo o el santuario de la Virgen de la Cabeza en Andújar. Esta España controlada por los sublevados era en general "la España interior, rural, de formas sociales más retardatarias, de grandes y medianos propietarios agrarios, y con extenso proletariado agrario también".

De los lugares donde ha triunfado la sublevación parten las ofensivas de las tropas rebeldes, a hacer lo que la propaganda "nacional" llamó la «Reconquista», para tomar las ciudades en manos de la República o a liberar los lugares en manos de los rebeldes asediados por las tropas gubernamentales, como son los casos del sitio de Oviedo y del Alcázar toledano.

En la zona sublevada la muerte en accidente de aviación del que iba ser el jefe de la rebelión, el general Sanjurjo, provocó que los generales sublevados decidieron crear el jueves 23 de julio una Junta de Defensa Nacional, que quedaría constituida al día siguiente en Burgos, y que estaría integrada por los generales Miguel Cabanellas, que fue nombrado presidente de la Junta por ser el general más antiguo entre los sublevados, Andrés Saliquet, Miguel Ponte, Emilio Mola y Fidel Dávila, además del coronel Federico Montaner y el coronel Moreno Calderón. En el Decreto nº 1 que publicó la Junta se establecía que esta asumía "todos los poderes del Estado" y que representaría al país ante los poderes extranjeros, aunque en las semanas siguientes ningún país la reconoció y siguió considerando como gobierno legítimo de España al de Madrid presidido por el republicano de izquierda José Giral. El 27 de julio de 1936 llegó a España el primer escuadrón de aviones italianos enviado por Benito Mussolini.

Las fuerzas republicanas, por su parte, consiguen sofocar el alzamiento en más de la mitad de España, incluyendo todas las zonas industrializadas, gracias en parte a la participación de las milicias recién armadas de socialistas, comunistas y anarquistas, así como a la lealtad de la mayor parte de la Guardia de Asalto y, en el caso de Barcelona, de la Guardia Civil. El gobernador militar de Cartagena, Toribio Martínez Cabrera, era simpatizante del Frente Popular y la marinería también era contraria al golpe militar, lo que unido a los tumultos populares de los días 19 y 20 hicieron fracasar el movimiento golpista en la base naval de Cartagena y el resto de la provincia de Murcia.

La zona fiel a la República ocupa "grosso modo" la mitad este de la Península: la parte oriental de Aragón (menos las tres capitales), Cataluña, Valencia, Murcia, Andalucía oriental (menos la ciudad de Granada), Madrid, Castilla la Nueva y La Mancha. En el oeste controlaba las provincias de Badajoz y de Huelva. Aislada de esta zona quedaba la franja cantábrica formada por Asturias (menos Oviedo y Gijón), Santander, Vizcaya y Guipúzcoa. El territorio leal era superior en extensión al rebelde y se trataba, por lo general, de las zonas de España "socialmente más evolucionadas, con importante población urbana, más industrializadas y con núcleos de obrerismo modernos organizados".

Así pues, el resultado del levantamiento era incierto pues tuvo éxito en unos sitios y fracasó en otros, por lo que España quedó dividida en dos zonas: una controlada por los militares que se habían alzado contra la República (la zona sublevada) y otra que permaneció fiel al gobierno (la zona republicana). Aproximadamente un tercio del territorio español había pasado a manos rebeldes, con lo que ninguno de los dos bandos tenía absoluta supremacía sobre el otro. La intentona de derrocar de un golpe a la República había fracasado estrepitosamente. Ambos bandos se prepararon para lo inevitable: un enfrentamiento que iba a desangrar España durante tres largos años. La guerra civil española acababa de empezar.

Aunque se trata de un tema muy controvertido, la mayoría de los historiadores calculan que un 70% de los 15000 jefes y oficiales en activo en 1936 combatieron en el bando sublevado (1236 fueron fusilados o encarcelados por ser desafectos al bando vencedor en cada lugar), mientras que, por el contrario, la mayor parte de los 100 generales no se sublevaron. De los 210000 soldados de tropa y suboficiales que teóricamente formaban el ejército regular en 1936, unos 120000 quedaron en la zona sublevada, pero lo más decisivo fue que entre ellos se encontraban los 47000 que formaban el Ejército de África que constituían las mejores tropas del ejército español. La Guardia Civil, por su parte, quedó muy dividida entre los leales y los rebeldes a la República.

Así pues, el bando sublevado no tuvo que construir su ejército sino que contó desde el primer momento con las unidades militares (y las fuerzas de orden público) sublevadas durante el golpe ya organizadas y dirigidas por sus mandos, entre las que destacaba el ejército del Protectorado de Marruecos, el llamado Ejército de África, compuesto por la Legión Extranjera y los Regulares (tropas indígenas moras mandadas por oficiales españoles) que constituía la fuerza militar más experimentada de todo el ejército español. Por otro lado las milicias carlistas (requetés) y las milicias falangistas que apoyaron a los sublevados fueron integradas en el ejército del que se consideraban aliadas y no enemigas (al contrario de lo que sucedió en el bando republicano donde las milicias obreras, especialmente las milicias confederales anarquistas, siempre desconfiaron de la institución militar, con la excepción de las milicias comunistas).

En el bando sublevado el ejército alcanzó rápidamente la unidad de mando y dominó completamente la vida civil de la zona sublevada, que ellos llamaban "zona nacional". La muerte en un accidente de aviación en los primeros días del golpe del general Sanjurjo, que era el militar elegido por sus compañeros para encabezar la sublevación, hizo que el mando en la zona sublevada quedara entonces repartido entre los generales Emilio Mola y Francisco Franco, pero solo dos meses después, el 1 de octubre, el general Franco asumió el mando único militar y político (el general Mola murió en otro accidente de avión al año siguiente, el 3 de junio de 1937).

«El fenómeno de la centralización militar del esfuerzo de guerra en la zona sublevada hizo que no se permitiese nada que se asemejase a la desunión política, al rencor entre grupos políticos y a la falta de confianza en los mandos y jefes de la campaña, todo lo cual se manifestó especialmente en la retaguardia republicana del norte, en Aragón y en Cataluña, que es donde se perdió realmente la guerra. (...) A medida que la República iba perdiendo la guerra, aumentaban el hambre y las privaciones en la retaguardia, creándose una situación infernal, con refugiados, bombardeos, escasez y frío».

En cuanto a la ayuda extranjera, el bando sublevado recibió armas de todo tipo y aviones prácticamente desde el primer día por parte de la Alemania nazi y la Italia Fascista a la que pronto se añadieron unidades militares completas (la Legión Cóndor alemana y el CTV italiano) en un flujo continuo que nunca se detuvo a largo de la guerra.

Por su parte el bando republicano no pudo contar con prácticamente ninguna unidad militar completa organizada y disciplinada con todos sus mandos y suboficiales y durante los primeros meses la fuerza militar que se opuso al ejército sublevado, tras la decisión del gobierno de José Giral de licenciar a las tropas para evitar que la sublevación se extendiera, estuvo constituida por columnas improvisadas integradas por unidades sueltas y por las milicias de las organizaciones obreras, que cuando estaban mandadas por oficiales de carrera estos a menudo suscitaban sospechas de traición entre los combatientes. Fue a partir de la formación del gobierno de Largo Caballero el 5 de septiembre de 1936 cuando se inició el proceso de construcción de un verdadero ejército, con la militarización de las milicias y su integración en las Brigadas Mixtas, primer paso para la creación del Ejército Popular que solo se logró tras la superación de la crisis de los "sucesos de mayo de 1937" y la formación a continuación del gobierno de Juan Negrín. Pero el ejército republicano siempre tuvo un problema estructural de difícil solución: la falta de mandos profesionales (según los cálculos de Michael Alpert, solo un 14% de los militares que figuraban en el "Anuario Militar" de 1936 servían todavía en 1938 en el ejército de la República). Un problema que fue especialmente acuciante en el caso de la Armada. Algo que reconoció el general republicano Vicente Rojo, que escribió:
Además en el bando republicano la unidad de mando solo se logró (y nunca fue completa) a mediados de 1937 cuando el Ejército Popular estuvo completamente estructurado y, por otro lado, solo a partir de ese momento las necesidades militares se impusieron sobre las de la vida civil (marcada por la Revolución Social de 1936). Y también, a diferencia del bando sublevado, era el gobierno quien tomaba las decisiones pero siguiendo casi siempre las recomendaciones del Jefe del Estado Mayor, el coronel y luego general Vicente Rojo, y de otros militares leales.

En cuanto a la ayuda extranjera la República, a causa de que Francia y Gran Bretaña no acudieron en su ayuda y además impulsaron el pacto que dio nacimiento al Comité de No Intervención (cuya prohibición de suministrar armas a alguno de los bandos contendientes no fue cumplida ni por Alemania ni por Italia, a pesar de haber firmado el acuerdo) la República tuvo que adquirir el material bélico donde pudo, a menudo recurriendo a los traficantes de armas que en ocasiones les vendieron material anticuado o en muy mal estado a precios astronómicos. Esto le hizo depender de los suministros que le proporcionó la Unión Soviética, después de que Stalin superara sus dudas sobre la ayuda a los republicanos españoles, cuyo material bélico (armas automáticas, tanques y aviones) acompañado de instructores y consejeros militares soviéticos, junto con las Brigadas Internacionales reclutadas por la Internacional Comunista o Komintern, no comenzó a llegar hasta octubre de 1936 y luego las sucesivas entregas se interrumpieron en varias ocasiones en función de la coyuntura internacional europea (que determinaron, por ejemplo, que el gobierno francés abriera o cerrara la frontera) y del creciente bloqueo impuesto por la Armada sublevada en los puertos republicanos.
Nada más conocerse el 17 de julio por la tarde que la sublevación militar había triunfado en el Protectorado de Marruecos, el ministro de Marina José Giral (que dos días después acabaría presidiendo el gobierno de la República tras la dimisión de Santiago Casares Quiroga y del gobierno "relámpago" de Diego Martínez Barrio) ordenó que varios barcos de guerra de la Marina se dirigieran al estrecho de Gibraltar para que bloquearan las plazas de Ceuta, Larache y Melilla y evitar así el paso a la península de las tropas coloniales. De la base de Cartagena salieron los destructores "Almirante Valdés", "Lepanto" y "Sánchez Barcáiztegui", con orden de navegar a máxima potencia hasta el estrecho. Gracias a que las dotaciones de esos barcos se rebelaron contra sus oficiales, que estaban comprometidos en el golpe, los sublevados no pudieron disponer inicialmente del Ejército de África, compuesto por la Legión Extranjera y los regulares (tropas formadas por marroquíes mandados por oficiales españoles).

El mismo día 19 de julio en que fue sofocada la rebelión en Madrid, salieron de la capital hacia la sierra de Guadarrama varias columnas compuestas por milicianos y por tropas de las unidades militares que habían sido disueltas por orden del gobierno para evitar que se pudieran sumar a la sublevación. Allí consiguieron impedir que las columnas de los sublevados enviadas por el general Mola desde Castilla y León y desde Navarra consiguieran atravesar los puertos de montaña de la sierra madrileña y llegar a la capital. El frente norte de Madrid quedó así estabilizado hasta el final de la guerra. Esta primera campaña de la Guerra Civil fue conocida con el nombre de batalla de Guadarrama.

Desde Barcelona, también una vez sofocada la rebelión, salieron varias columnas formadas rápidamente por las organizaciones obreras y los partidos de izquierda para dirigirse a Aragón. Junto con las columnas del POUM y del PSUC (y una de Esquerra Republicana de Catalunya que salió desde Tarragona), el contingente más importante lo aportaron las milicias confederales de las organizaciones anarquistas (CNT, FAI, Juventudes Libertarias). La primera y más numerosa fue la columna Durruti, así llamada porque estaba encabezada por el líder de la FAI Buenaventura Durruti, que salió de Barcelona el día 24 en dirección a Zaragoza. Las también anarquistas columna Ascaso y columna Los Aguiluchos de la FAI salieron en dirección a Huesca. pero ninguna de ellas consiguió alcanzar sus objetivos de liberar las tres capitales aragonesas (desde Valencia había salido hacia Teruel la columna de Hierro), y el frente de Aragón quedó estabilizado, aunque los anarquistas llevaron la revolución a la mitad oriental de Aragón donde crearon el Consejo Regional de Defensa de Aragón.

También desde la ciudad condal se organizó una expedición a las islas Baleares, de las que solo Menorca continuaba republicana. La operación iniciada el 8 de agosto al mando del capitán Bayo tuvo un éxito inicial al conseguir ocupar una franja de la costa de Mallorca, pero el desembarco de Mallorca acabó en un completo fracaso. Otro fracaso fue la ofensiva de Córdoba, «donde la situación estaba indecisa, lo que constituyó una de las pocas iniciativas estratégicas republicanas». Fue organizada desde Albacete por el general Miaja, cuyo jefe de Estado Mayor era el teniente coronel José Asensio Torrado, pero el avance se detuvo pronto (el general Miaja situó su cuartel general en Montoro) y los republicanos no pudieron reconquistar la Andalucía occidental, en manos de los sublevados especialmente después de la llegada de los primeras unidades procedentes del Protectorado de Marruecos.

La situación de bloqueo en que se encontraba el Ejército de África (la principal fuerza de combate con que contaban los sublevados para tomar Madrid, una vez detenidas las columnas del general Mola en la sierra de Guadarrama) se pudo superar gracias a la rápida ayuda que recibieron los sublevados de la Alemania nazi y de la Italia fascista. El 26 de julio llegaron a Marruecos los primeros veinte aviones de transporte alemanes Junker, que se podían convertir fácilmente en bombarderos, acompañados por cazas, y, cuatro días después, el 30 de julio, los primeros nueve cazabombarderos italianos. Con estos medios aéreos el general Franco, jefe de las fuerzas sublevadas de Marruecos, pudo organizar un puente aéreo con la península para transportar a los legionarios y a los regulares, y además conseguir la superioridad aérea en el estrecho. Así pues, el 5 de agosto pudo cruzarlo con una pequeña flota llamada por la propaganda de los sublevados "Convoy de la Victoria". Sin embargo, el desbloqueo completo del paso del estrecho no se produciría hasta más tarde, cuando el gobierno republicano decidió transferir la mayoría de sus barcos de guerra al Cantábrico, lo que según el historiador Michael Alpert constituyó "quizá el mayor error de la Guerra Civil". Esta decisión estuvo motivada, entre otras razones, por la negativa de Gran Bretaña, que contaba con la flota naval de guerra más importante del Mediterráneo, a que el gobierno republicano detuviera el tráfico neutral dirigido al territorio enemigo, por lo que los buques de guerra republicanos no podrían impedir que los barcos mercantes alemanes e italianos desembarcaran material de guerra en los puertos de Ceuta, Melilla, Cádiz, Algeciras o Sevilla, controlados por los sublevados.

El 1 de agosto el general Franco da la orden de que las columnas de legionarios, moros regulares y voluntarios avancen en dirección norte desde Sevilla para dirigirse a Madrid a través de Extremadura, teniendo el flanco izquierdo protegido por la frontera de Portugal, cuyo régimen salazarista apoyaba a los sublevados. Siguiendo esta ruta para llegar a la capital se unirían las dos zonas controladas por los sublevados. Se inicia así la Campaña de Extremadura. La llamada "columna de la muerte" a causa de la brutal represión que aplicó en las localidades extremeñas que fue ocupando, y cuyo hecho más destacado fue la matanza de Badajoz, avanzó rápidamente a un promedio de 24 kilómetros por día. El 10 de agosto tomó Mérida y el 15 Badajoz, estableciendo a continuación contacto con las fuerzas sublevadas del norte. El avance se volvió entonces en dirección noreste para alcanzar el valle del Tajo y el 2 de septiembre caía Talavera de la Reina, ya en la provincia de Toledo. El rápido avance de los sublevados hacia Madrid, unido a la noticia de la inminente caída de Irún (con lo que el norte quedaría completamente aislado del resto de la zona republicana), provocaron que el presidente José Giral, sintiéndose falto de apoyos y de autoridad, presentara la dimisión al presidente de la República Manuel Azaña. El 5 de septiembre se formaba un nuevo gobierno de "unidad antifascista" presidido por el socialista Francisco Largo Caballero, que asumió personalmente la cartera de Guerra, con el objetivo prioritario de organizar un ejército que pudiera detener el avance de los sublevados y ganar la guerra.

La rapidez con que cayeron una tras otra las poblaciones en el avance por Extremadura y el Tajo se debió fundamentalmente a que el Ejército de África estaba integrado por las tropas mejor entrenadas y curtidas en combate (legionarios y regulares), quizá las únicas verdaderamente profesionales en los primeros caóticos meses de guerra. En cambio las fuerzas republicanas estaban integradas en su mayoría por milicianos a los que les faltaba adiestramiento militar. "Eran indisciplinadas y tendían a huir, presas del pánico, abandonando las armas, las cuales constituían fusiles y piezas sueltas de artillería, dado que el desbarajuste originado en la capital por la sublevación no permitía una adecuada planificación militar. En julio y agosto se perdió mucho material militar. En contraste, los sublevados se armaban cada vez más con material extranjero, aparte del que tomaban al enemigo". Además los milicianos, cuya inmensa mayoría procedía de las organizaciones obreras y los partidos de izquierda, desconfiaban de los militares profesionales que pretendían mandarlos y por motivos ideológicos rechazaban la disciplina y la organización militares, a excepción de los comunistas que propugnaban la completa militarización de las milicias y la creación de un Ejército Popular siguiendo el modelo del Quinto Regimiento organizado por ellos.

El 21 de septiembre el Ejército de África tomaba el pueblo de Maqueda, a menos de 100 kilómetros de Madrid. Ese mismo día se reunían los generales sublevados en una finca de los alrededores de Salamanca para nombrar al general Franco como mando único y supremo de las fuerzas sublevadas. Una semana después volverían a reunirse para dilucidar el mando político. En ese intervalo de tiempo, el general Franco decidió desviar hacia Toledo las columnas que avanzaban hacia Madrid para levantar el asedio del Alcázar de Toledo, donde guardias civiles y algunos pocos cadetes de la Academia de Infantería al mando de su director, el coronel José Moscardó, llevaban dos meses resistiendo los ataques republicanos. Esta decisión, que según algunos historiadores hizo perder a los sublevados la posibilidad de tomar Madrid antes de que se organizase su defensa, ha suscitado un debate entre los historiadores. Para una buena parte de ellos fue una decisión más política que militar, pues afianzó el prestigio del general Franco ante sus compañeros cuando se estaba discutiendo ya el mando único político. "El Alcázar encerraba un tesoro de legitimidad simbólica: academia militar, los sitiados resistían en medio de las ruinas, con los muros de la poderosa fábrica medio destruidos, refugiados en los sótanos. Con su liberación, Franco recibió un enorme capital político: el Alcázar era el símbolo de la salvación de España que, como una mártir, resucitaba del sepulcro al que la habían conducido sus enemigos". Además tuvo un enorme valor propagandístico para la causa de los sublevados. «Del Alcázar se hizo posteriormente un mito por los franquistas, cuyos principales extremos —el episodio de los diálogos de Moscardó y su hijo en manos de los asediadores, por ejemplo— están hoy absolutamente desacreditados». Sin embargo algunos historiadores afirman que también tuvo una motivación militar. «Parece convincente la explicación usual: el compañerismo militar y el valor propagandístico de rescatar a los asediados en el Alcázar imponían levantar el asedio cuanto antes. Es posible que hubiera motivos políticos, no separados de la ambición de Franco de ser generalísimo y jefe civil, que impusieran ese gesto heroico. Ahora bien, el hecho de tomar primero Toledo podía justificarse militarmente: asegurar esta ciudad permitiría atacar Madrid desde el sur y el este, protegiendo los flancos por el Tajo y contando con dos carreteras de primera categoría en lugar de una». El mismo día que era levantado el asedio, el 28 de septiembre, el general Franco era nombrado por sus compañeros de sublevación no solo «generalísimo de las fuerzas nacionales de tierra, mar y aire», sino también «jefe del Gobierno del Estado Español, mientras dure la guerra».

El día 8 de octubre, el Ejército de África alcanzó San Martín de Valdeiglesias, a unos cuarenta kilómetros de Madrid, donde tomó contacto con las fuerzas sublevadas del norte al mando del general Emilio Mola, que acababa de finalizar la campaña de Guipúzcoa tras tomar Irún, el 5 de septiembre y San Sebastián el 13 de septiembre, quedando el norte republicano rodeado por tierra por los "nacionalistas". Así pues, a principios de octubre, las fuerzas sublevadas se habían desplegado en un semicírculo alrededor de Madrid que partía de Toledo al sur y alcanzaba el noroeste a unos diez kilómetros al norte de El Escorial, y que se encontraba entre 40 y 55 kilómetros de la capital. Aunque las fuerzas republicanas opusieron mayor resistencia gracias a la reorganización militar emprendida por el gobierno Largo Caballero (con la formación de las Brigadas Mixtas al mando en su mayoría de militares de carrera y en las que fueron encuadradas las milicias, una militarización acompañada de la creación de la figura de los comisarios políticos), las fuerzas "nacionales" fueron estrechando el semicírculo que atenazaba la capital (mientras que en el norte el 17 de octubre rompían el cerco de Oviedo) y a principios de noviembre llegaron a los barrios del sur de Madrid. "El ataque a Madrid marcó el final del primer periodo de la guerra".

El 6 de noviembre cuando parecía que el ejército sublevado estaba a punto de entrar en Madrid, el gobierno de Largo Caballero decidió trasladarse a Valencia, encomendando la defensa de la ciudad al general Miaja que debería formar una Junta de Defensa de Madrid. «Una salida precipitada, mantenida en sigilo, sobre la que no se dio explicación pública alguna». «Quienes se quedaron en Madrid no pudieron interpretar estos hechos sino como una vergonzosa huida... sobre todo porque los madrileños fueron capaces de organizar su defensa». Dos días después comenzó la batalla de Madrid.

Dado que las fuerzas de los nacionales no eran superiores a las fuerzas republicanas que defendían Madrid (unos 23000 soldados), la penetración en la capital tendría que ser rápida y en un frente muy estrecho. Una columna atravesaría el río Manzanares al norte del puente de los Franceses y avanzaría por la Ciudad Universitaria de Madrid para luego bajar por el paseo de la Castellana. Otra columna cruzaría el parque del Oeste para seguir por los bulevares y llegar a la plaza de Colón. Y una tercera cruzaría el barrio de Rosales para alcanzar la plaza de España y la calle Princesa. Para apoyar este avance se consideraba fundamental tomar el cerro de Garabitas en la Casa de Campo donde se podía situar la artillería y desde allí bombardear la ciudad. El éxito de la operación dependía de que los republicanos creyeran que el ataque se produciría por el sur y concentraran allí sus fuerzas, pero en la noche de 7 al 8 de noviembre, precisamente en el momento que iba comenzar la batalla de Madrid, el teniente coronel Vicente Rojo, jefe del Estado Mayor de la defensa de Madrid, conoció los planes de los atacantes gracias a los papeles encontrados en el cadáver de un oficial muerto del ejército sublevado.

Entre los días 8 y 11 de noviembre se produjeron violentos combates en la Casa de Campo. El día 13 los nacionales ocupaban el cerro de Garabitas y dos días después lograban cruzar el río Manzanares adentrándose en la Ciudad Universitaria. Pero de allí no pudieron pasar gracias a la resistencia que presentaron las fuerzas republicanas, reforzadas por la llegada de las primeras Brigadas Internacionales, de unidades de tanques soviéticos T-26 (cuya primera intervención se había producido en la batalla de Seseña) y de 132 aviones rusos "Moscas" y "Chatos" que disputaron la superioridad aérea a los 117 aviones de la Legión Cóndor alemana. El 23 de noviembre el general Franco desistió de continuar el infructuoso ataque frontal a la capital y el frente quedó ese día estabilizado.

"La resistencia de Madrid cambió el signo de la guerra. Ya no sería un conflicto de rápidos movimientos envolventes, sino de batallas a gran escala, de maniobras tácticas para alcanzar objetivos estratégicos, en las que unos cuantos centenares de metros de terreno tendrían significado y cuyo modelo sería la Primera Guerra Mundial, más que las campañas coloniales, única forma de guerra que los españoles conocían de modo directo".

Al fracasar el ataque frontal los nacionales decidieron envolver Madrid por el noroeste concentrando sus fuerzas para cortar la carretera de La Coruña e intentar penetrar por allí en Madrid. En el primer intento que tuvo lugar a finales de noviembre (primera batalla de la carretera de La Coruña) solo consiguieron avanzar tres de los siete kilómetros previstos, quedando detenido el ataque. El segundo intento tuvo lugar en diciembre (segunda batalla de la carretera de La Coruña) y también resultó un fracaso. El tercer y último intento (la conocida como tercera batalla de la carretera de La Coruña) tuvo lugar a principios de enero de 1937 y constituyó la "primera batalla importante de la Guerra Civil en campo abierto". Los nacionales organizaron un importante ejército, llamado División Reforzada de Madrid, que contaba con tanques italianos, baterías antitanque para contrarrestar los T-26 soviéticos y artillería pesada. Frente a ella los republicanos desplegaron un ejército compuesto de cinco divisiones, cada una con tres brigadas, aunque algunas no estaban completas y muy pocas estaban mandadas por oficiales de infantería de carrera (para mandar las cinco divisiones se tuvo que recurrir a dos oficiales retirados por la ley Azaña de 1931, a dos oficiales provenientes de las fuerzas de seguridad, y a un miliciano, el comunista Juan Modesto). Entre los días 6 y 9 de enero la División Reforzada atacó hacia el norte y luego giró al este al llegar a la carretera de La Coruña, pero las fuerzas republicanas resistieron y los "nacionales" tuvieron que desistir en su avance.

Fracasado el intento de envolver Madrid por el noroeste, los nacionales lo intentan por el sureste avanzando hacia el río Jarama para cortar la vital carretera de Valencia, por donde llegaban a Madrid la mayoría de sus suministros. La batalla del Jarama se inició el 4 de febrero con el ataque por unidades de la Legión Española y fuerzas regulares marroquíes, apoyadas por carros de combate, a las posiciones republicanas. El 11 de febrero tomaban el puente de Pindoque defendido por la compañía "André Marty" de la XII Brigada Internacional que tuvo 86 muertos. Los nacionales prosiguieron su avance pero las fuerzas republicanas apoyadas por unidades de tanques soviéticos dirigidos por el general "Pablo" (el general Rodímtsev) y el dominio del aire de la aviación republicana gracias a los "Chatos" les obligó a detenerse y renunciar a alcanzar la línea Arganda-Morata de Tajuña. Sin embargo los republicanos no pudieron recuperar el terreno perdido y el frente quedó estabilizado el 23 de febrero de 1937. Fue el final de la batalla del Jarama.

Mientras se iniciaba la batalla del Jarama, se producía la toma de Málaga por los nacionales el 8 de febrero de 1937, gracias especialmente a la intervención de las unidades motorizadas de la división de milicias fascistas italianas ("legionari" del CTV, Corpo di Truppe Volontarie) que había comenzado a llegar a España dos meses antes enviada por Mussolini, imbuido de la idea de que el soldado fascista era muy superior al combatiente "rojo". El ataque había comenzado el 14 de enero de 1937 avanzando desde Ronda por el norte, siguiendo la carretera costera avanzando hacia Marbella por el oeste (con el apoyo de los dos modernos cruceros Baleares y Canarias que bombardeaban desde el mar y contra los que poco podían hacer los destructores y los más viejos y peor armados cruceros republicanos) y desde Granada hasta Alhama por el noreste. Aunque las milicias republicanas consiguieron contener el ataque tierra adentro, el día 5 de febrero convergieron varias columnas sobre Málaga encabezadas por las fuerzas italianas. Esto obligó a retirarse a las milicias a la capital pero allí faltas de mandos, de fortificaciones para la defensa y del apoyo de la flota republicana no tuvieron más remedio que emprender la huida hacia el este por la carretera costera de Málaga y Almería acompañadas de miles de civiles mientras eran ametrallados y bombardeados por la aviación italiana y los barcos de guerra de los sublevados. A los pocos días los nacionales llegaban a Motril haciendo numerosos prisioneros y obteniendo grandes cantidades de material. "Para el Gobierno republicano, la derrota demostró una profunda ineficacia y una falta de energía moral y señaló el comienzo de la decepción de los comunistas con respecto a la actuación de Largo Caballero como Jefe de Gobierno y ministro de la Guerra. Las salpicaduras llegaron a los mandos que Largo había nombrado, los cuales fueron procesados como resultado de las investigaciones llevadas a cabo después del desastre".

El tercer y último intento de envolver Madrid fue una iniciativa del Corpo di Truppe Volontarie (CTV) fascista italiano, a la que accedió el generalísimo Franco, y que dio lugar a la batalla de Guadalajara. La idea italiana de la ofensiva era atacar Madrid desde el noreste dirigiéndose a Guadalajara y una vez tomada esta ciudad cortar la carretera de Valencia y entrar en la capital. Para esta operación, en la que se seguiría la táctica de lo que los generales italianos llamaban "guerra relámpago" (las previsiones eran que en una semana, entre el 8 y el 15 de marzo de 1937, Madrid sería conquistada), se desplegaron buena parte de los de los 48000 soldados con que contaba entonces el CTV (integrados en cuatro divisiones con 4000 vehículos, 542 cañones y 248 aviones).

El día 8 de marzo comenzó el ataque y en la noche del 9 al 10 de marzo la 3.ª División italiana tomaba Brihuega y el día 11 Trijueque encontrando una fuerte resistencia de las fuerzas republicanas, entre las que se encontraban la XI y la XII Brigadas Internacionales (de las que formaba parte el batallón Garibaldi integrado por italianos antifascistas), apoyadas por las unidades de tanques soviéticos y por la aviación, y ayudadas por el mal tiempo (los suelos embarrados por la lluvia dificultaba el avance de los vehículos e impedía el despegue de los aviones de los campos encharcados, mientras que los aviones republicanos sí disponían de campos de aviación utilizables). El 12 de marzo las tropas republicanas lanzaron una contraofensiva que hizo huir desmoralizada a la 3.ª División italiana y permitió recuperar en los días siguientes Trijueque y Brihuega, apoderándose de material abandonado por los italianos. El día 19 de marzo las fuerzas republicanas detuvieron su avance y organizaron líneas de defensa. El 23 de marzo terminó la batalla de Guadalajara que la prensa internacional liberal y de izquierdas llamó la "primera victoria contra el fascismo", destacando el hecho de que muchos "legionari" del CTV habían sido capturados por los "garibaldini" de las Brigadas Internacionales.

"Con la ayuda rusa la República había podido responder a la amenaza que suponía la llegada de armamento desde Italia y Alemania para el bando nacional. El Ejército Popular ya no consistía en bandas sueltas de milicianos con improvisados mandos. Había demostrado saber retirarse a fortificaciones preparadas, resistiendo con pequeñas retaguardias a la espera de refuerzos. Responder a esta técnica iba a exigir otras capacidades de las que poseía el CTV".

La batalla de Guadalajara fue el último intento del bando sublevado de tomar Madrid y solo una semana después de su final se inició la Campaña del Norte, el ataque de las fuerzas sublevadas contra la franja cantábrica que permanecía fiel a la República pero que estaba aislada por tierra del resto de la zona republicana. El objetivo de los "nacionales" era controlar sus importantes recursos mineros e industriales (especialmente las siderurgias y las fábricas de armas), además de que su conquista permitiría trasladar la flota sublevada al Mediterráneo para intentar detener el tráfico marítimo que se dirigía a los puertos republicanos. La ofensiva de las fuerzas sublevadas al mando del general Mola (unos 28 000 efectivos, incluidos los de las unidades del Corpo Truppe Volontarie italiano, apoyados por 140 aviones italianos y alemanes de la Legión Cóndor) se inició el 31 de marzo de 1937 desde las posiciones alcanzadas en octubre de 1936 en la campaña de Guipúzcoa, que se situaban a unos 35 kilómetros al oeste de San Sebastián, sobre las defensas de Vizcaya que había organizado el gobierno vasco presidido por José Antonio Aguirre desde octubre de 1936 tras haber aprobado las Cortes republicanas el Estatuto de Autonomía del País Vasco. El Ejército Vasco reclutado por Aguirre rechazaba la autoridad del general Francisco Llano de la Encomienda que era el jefe del Ejército del Norte, que teóricamente agrupaba a todas las fuerzas de Vizcaya, Santander y Asturias, y actuaba de forma independiente (en él no existía la figura del comisario político y tenía pocos mandos profesionales).
En la primera ofensiva de la campaña de Vizcaya las fuerzas "nacionales", aunque contaban con la superioridad naval y aérea (el grueso de la flota republicana se encontraba en el Mediterráneo y solo había un pequeño número de cazas soviéticos), avanzaron relativamente poco debido a la fuerte resistencia que encontraron y a las malas condiciones meteorológicas. La segunda ofensiva iniciada el 20 de abril tuvo más éxito alcanzando cinco días después la línea Guernica-Durango. El día 26 de abril, tras haber bombardeado Jaén y Durango los días anteriores, se produjo el bombardeo de Guernica por aviones alemanes de la Legión Cóndor y aviones italianos del CTV causando muchas víctimas civiles y una enorme destrucción porque además de las bombas convencionales utilizaron bombas incendiarias. Tres días después las fuerzas "nacionales" ocupaban la ciudad y el día 30 de abril llegaban a Bermeo.

Entonces ambos ejércitos se reorganizaron (el "lehendakari" Aguirre en persona asumió el mando supremo del ejército vasco) para atacar y defender respectivamente el conjunto de las fortificaciones alrededor de Bilbao, el llamado "Cinturón de Hierro", que sin embargo había perdido gran parte de su utilidad porque el ingeniero que las había diseñado, Alejandro Goicoechea, se había pasado al bando sublevado con los planos de las mismas. Gracias a ellos, los "nacionales" pudieron penetrar por sus puntos débiles mientras la ciudad de Bilbao era bombardeada por la artillería pesada y por la aviación. Finalmente Bilbao cayó el 16 de junio, sin que el gobierno de Valencia, presidido desde el 17 de mayo por el socialista Juan Negrín tras superar la crisis republicana de los "sucesos de mayo de 1937" hubiera podido organizar algún ataque en otros frentes que hubiera dificultado la gran concentración de medios terrestres y aéreos desplegada por los "nacionales" en la Campaña de Vizcaya.

Por fin a principios de julio las fuerzas republicanas lanzaron una ofensiva en el frente de Madrid para aliviar la presión del ejército "nacionalista" en el norte. Así el 6 de julio comienza la batalla de Brunete llamada así porque la lucha por la conquista de ese pueblo situado al oeste de Madrid por los republicanos (que pretendía seguir después en dirección sureste para encontrarse con las otras fuerzas gubernamentales que avanzarían desde el sur de la capital, lo que de tener éxito obligaría a los "nacionales" a ordenar un repliegue general de sus fuerzas si no querían verse cercados) se convirtió en el elemento central de los combates. El ataque hacia Brunete fue lanzado por el reorganizado V Cuerpo de Ejército republicano al mando del comandante de milicias Juan Modesto apoyado por unidades de tanques T-26 soviéticos que ocupó la localidad casi sin resistencia, pero el general Franco reaccionó rápidamente y envió unidades de la Legión y de Regulares más las brigadas de Navarra y unos 150 aviones italianos y alemanes retirados del frente del norte, deteniéndose así el ataque hacia Santander. Esto permitió a las fuerzas nacionales realizar el contraataque. «Empezó así una batalla de desgaste bajo el tremendo sol veraniego, sin sombra ni agua, que terminó arrojando un saldo de 40 000 bajas. La dura batalla concluyó el 26 de julio, por puro agotamiento. El Ejército Popular Republicano había retenido importantes sectores del territorio que había conquistado... aunque perdió Brunete. (...) [La batalla de] Brunete coincidía con el aniversario del principio de la guerra. A partir de unas cuantas columnas sublevadas que luchaban contra milicias improvisadas se habían formado dos ejércitos con un considerable apoyo de artillería y aviación».

Terminada la batalla de Brunete las fuerzas "nacionales" se reorganizaron y reanudaron la Campaña del Norte atacando Santander desde el sur por el puerto de montaña de Reinosa y desde el este siguiendo la costa. La batalla de Santander comenzó el 14 de agosto con el ataque a Reinosa que fue ocupada solo dos días después y cuya fábrica de armamento no fue destruida por los republicanos en su retirada en desbandada. La resistencia republicana en la costa también se desplomó rápidamente ante el avance de las unidades del CTV italiano gracias especialmente a la superioridad aérea (los republicanos no pudieron enviar aviación a aquella zona debido a la lejanía de las bases) cuyos continuos bombardeos destrozaron y desmoralizaron a las fuerzas republicanas mandadas por el general Mariano Gamir Ulibarri nombrado el 6 de agosto. El 24 de agosto, solo diez días después de iniciada la ofensiva, la ciudad de Santander (donde escaseaban los víveres y el combustible debido al bloqueo naval de la armada sublevada) fue ocupada después de que las fuerzas de orden público, una vez evacuados los mandos, izaron bandera blanca. «La historia de la campaña de Santander es la de un continuo avance, con ocasionales y breves resistencias. Fueron muchos los prisioneros y los que se "pasaron", lo que daba fe del estado de desmoralización de las filas republicanas».

La segunda ofensiva republicana para aliviar la presión de los "nacionales" en el Norte llegó tarde pues comenzó el mismo día de la caída de Santander. Esta vez se desarrolló en el frente de Aragón, que se mantenía prácticamente inalterado desde el inicio de la guerra cuando las columnas de milicias confederales anarquistas y del POUM salieron de Cataluña y ocuparon la mitad oriental de Aragón (donde crearon un ente casi independiente llamado Consejo de Aragón) aunque no consiguieron su objetivo de conquistar Zaragoza, y que tras los "sucesos de mayo de 1937" habían sido incorporadas a las unidades regulares del Ejército del Este. El 24 de agosto comenzó la ofensiva de Zaragoza cuyo propósito era romper el frente y alcanzar la capital aragonesa, lo que obligaría al general Franco a suspender su ofensiva del Norte. Al norte del Ebro combatían las divisiones anarquistas y al sur las comunistas dirigidas por Enrique Líster y los dos generales internacionales Walter y Kleber. Después de la toma de los pueblos de Codo y Quinto cercaron Belchite el día 26, dando inicio a la batalla de Belchite el hecho bélico más destacado de la campaña. Los "nacionales" que defendían el pueblo resistieron encarnizadamente hasta el 3 de septiembre. Cuatro días antes los "nacionales" habían iniciado la contraofensiva que al norte del Ebro hizo retroceder a las divisiones anarquistas y al sur en Fuentes de Ebro, un pueblo situado a 26 kilómetros de Zaragoza, consiguió derrotar a las unidades de tanques soviéticos BT5 y a la XV Brigada Internacional.

Aunque Belchite permaneció en manos de los republicanos los dos objetivos de la ofensiva de Zaragoza no se consiguieron: ni se tomó la capital aragonesa ni se detuvo el avance "nacionalista" en el frente norte. Tras la ocupación de Santander se inició el 1 de septiembre la ofensiva de Asturias por la costa y por el interior para poner fin al último territorio de la franja norte republicana. Unos días antes se había formado en Gijón (Oviedo continuaba ocupada por los "nacionalistas" desde el inicio de la guerra) el Consejo Soberano de Asturias y León bajo la presidencia del socialista Belarmino Tomás, uno de los antiguos dirigentes de la Revolución de Asturias de octubre de 1934, que intentó organizar la defensa, pero su situación eran tan difícil como la de Santander. Los asturianos no tenían apoyo naval (solo disponían del destructor "Císcar") ni apoyo aéreo (los pocos aviones con que contaban eran muy inferiores a los de los atacantes) y estaban sometidos al bloqueo naval de la armada sublevada lo que había provocado problemas de abastecimientos civiles y militares agravados por la presencia de unos 300000 refugiados procedentes de otras zonas ocupadas por las tropas "nacionales". Así pues la resistencia al avance "nacionalista" fue muy difícil de mantener por la carencia de material y alimentos y por el abandono de la zona desde aire y mar y la desmoralización de las tropas dio lugar a retiradas desordenadas a causa del pánico. Sin embargo hasta el 20 de octubre no fue tomado Gijón, el último reducto de la Asturias republicana y de todo el norte. La mayoría de los prisioneros del Frente Norte fueron recluidos en el campo de Miranda de Ebro.

Las consecuencias de la victoria "nacionalista" en la Campaña del Norte fueron muy importantes para el curso de la guerra. «Franco pudo concentrar todas sus fuerzas en el centro de España y en el Mediterráneo, y obtuvo el beneficio de una industria no destruida. La victoria restableció el orgullo de Mussolini [perdido por la derrota de la batalla de Guadalajara, que en adelante cooperaría de buena gana con Franco. La opinión internacional juzgaba que, una vez perdido el norte, la victoria era cuestión de tiempo».

En noviembre de 1937 el gobierno republicano de Juan Negrín decidió trasladarse de Valencia a Barcelona (donde desde noviembre de 1936 ya se encontraba el presidente de la República Manuel Azaña) para «poner en pleno rendimiento la industria de guerra» catalana, que en los meses siguientes quedó bajo la autoridad directa del gobierno de la República, para que supliera la pérdida de las importantes fábricas de armamento de Vizcaya, Cantabria y Asturias, y también para «asentar definitivamente la autoridad del gobierno en Cataluña», lo que relegó al gobierno de la Generalidad de Lluís Companys a un papel secundario.

El 12 de diciembre de 1937, la 11 División republicana al mando del jefe miliciano comunista Enrique Líster corta las de vías de comunicación de la ciudad de Teruel con la retaguardia "nacional". Así da comienzo la batalla de Teruel, cuya estrategia ha sido diseñada por el Jefe del Estado Mayor republicano, el coronel Vicente Rojo. El objetivo es conquistar este saliente que en las líneas enemigas representaba Teruel además de impedir el ataque de los "nacionales" contra Madrid previsto para el día 18 de diciembre y alcanzar un éxito militar como era tomar una capital de provincia en manos de los sublevados desde el inicio de la guerra para fortalecer la confianza interior y exterior en la causa republicana tras la derrota de la Campaña del Norte en un momento en que la llegada de material bélico de la Unión Soviética estaba reduciéndose a causa de las dificultades que estaba encontrando para pasar la frontera francesa por la caída el gobierno del socialista Leon Blum. El general Franco reaccionó inmediatamente para romper el cerco de Teruel pero como no pudo conseguirlo en el primer intento tuvo que enviar más fuerzas y suspender el ataque previsto sobre Madrid (con lo que uno de los objetivos estratégicos republicanos de la ofensiva sobre Teruel se había conseguido). Las bajas temperaturas y las nevadas dificultaron las acciones de los dos ejércitos e impidieron que los "nacionales" rompieran el cerco, a pesar de gozar de superioridad aérea y artillera, por lo que el coronel Domingo Rey d'Harcourt decidió rendirse el 8 de enero y las fuerzas republicanas (la 46.ª División al mando del miliciano Valentín González "El Campesino") ocuparon la ciudad. A partir de entonces las fuerzas "nacionales" redoblaron sus ataques para reconquistar Teruel lanzando varias ofensivas que fueron minando las defensas y la moral de las fuerzas republicanas. El 7 de febrero de 1938 alcanzaron la línea del río Alfambra y el 21 de febrero la ciudad estaba cercada. La División 46 mandada por "El Campesino" escapó o huyó, según las diferentes versiones, y la ciudad fue reconquistada por los "nacionales". "El valor de unos soldados bisoños mal conducidos, armados y vestidos y enfrentados por rencores políticos [anarquistas frente a comunistas] poco podía hacer contra tropas experimentadas y bien equipadas y, sobre todo, contra los bombardeos". El coronel Vicente Rojo le escribió al ministro de Defensa de la República Indalecio Prieto sobre la retirada de Teruel de la División 46:
La batalla de Teruel mostró las debilidades del ejército republicano lo que indujo a Franco a posponer definitivamente el ataque a Madrid para en su lugar lanzar la ofensiva de Aragón contra Cataluña y Valencia. El ataque, que iba a extenderse por todo el frente de Aragón, comenzó al sur del río Ebro el 9 de marzo donde el frente se derrumbó ante la gran concentración de fuego artillero y de aviación. El día 14 el CTV tomaba Alcañiz y el 17 los "nacionales" tomaban Caspe, después de haber "reconquistado" Belchite. Lo mismo sucedió al norte del Ebro donde tomaron Fraga el 27 de marzo y a principios de abril llegaron a Lérida (donde la 101.ª Brigada Mixta mandada por el jefe miliciano Pedro Mateo Merino impidió que cruzaran el río Segre por allí). Al norte de Lérida avanzaron hasta el Noguera Pallaresa y establecieron cabezas de puente en Balaguer y Tremp. Una vez alcanzadas esas posiciones Franco descartó dirigirse hacia Barcelona y optó por avanzar hacia el Mediterráneo al sur de la desembocadura del Ebro, objetivo que alcanzaron el 15 de abril al llegar a Vinaroz, con lo que la zona republicana quedó dividida en dos.

El fracaso de la batalla de Teruel y el derrumbe del frente de Aragón provocaron la crisis de marzo de 1938 en el bando republicano cuando el presidente del gobierno Juan Negrín intentó que Indalecio Prieto cambiara de ministerio y dejara el de Defensa ya que, como el presidente de la República Manuel Azaña, Prieto consideraba que lo que había sucedido mostraba que el ejército republicano nunca podría ganar la guerra y que había que negociar una rendición con apoyo franco-británico. Pero al no conseguirlo Negrín le pidió a Prieto que abandonara al gobierno, recomponiendo a continuación su gabinete el 6 de abril y asumiendo Negrín personalmente el Ministerio de Defensa, con el coronel comunista Antonio Cordón como subsecretario de Guerra, que procedió a la reorganización de las fuerzas republicanas agrupadas en dos grandes grupos de ejércitos, en consonancia con la división de la zona republicana provocada por la llegada de los "nacionales" al Mediterráneo: el GERC (Grupo de Ejércitos de la Región Centro-Sur) y el GERO (Grupo de Ejércitos de la Región Oriental). Las posiciones del nuevo gobierno de Negrín con vistas a unas posibles negociaciones de paz quedaron fijadas en su ""Declaración de los 13 puntos"", hecha pública en la significativa fecha del 1º de mayo de 1938.

Una vez alcanzado el Mediterráneo, Franco decidió dirigir sus tropas contra Valencia en lugar de contra Barcelona, sede del gobierno republicano, no porque temiera, según el historiador Michael Alpert, que "Cataluña fuera un bocado difícil" sino porque "la presencia de fuerzas alemanas e italianas en España hacía que un posible acercamiento de Franco a la frontera francesa pudiera suscitar tensiones internacionales". Se inicia así la ofensiva del Levante cuyo plan consistía en converger sobre Sagunto (a unos 20 kilómetros al norte de Valencia) avanzado por la costa desde Vinaroz y por el interior desde Teruel, para desde allí tomar Valencia. La resistencia republicana fue dura especialmente cuando las fuerzas "nacionales" tras conquistar Castellón de la Plana el 13 de junio alcanzaron la línea de fortificaciones llamada línea XYZ que se extendía desde Almenara, unos kilómetros al norte de Sagunto, en la costa hasta el río Turia en el interior. Allí las tropas "nacionales" tuvieron que detener su avance.

El 25 de julio de 1938 el republicano Ejército del Ebro, uno de los dos grandes cuerpos del ejército de que se componía el recién creado GERO, cruza en barcazas por sorpresa el río Ebro entre Mequinenza y Amposta con el objetivo de atacar desde el norte al ejército "nacional" que se acercaba a Valencia. Fue el inicio de la batalla del Ebro que se convirtió para ambos bandos en una dura lucha de desgaste. Aunque el paso del Ebro por Amposta en la costa fue pronto liquidado por las fuerzas "nacionales" el grueso del Ejército republicano llegó a las puertas de Gandesa en el interior pero no logró tomar esta localidad debido a la fuerte resistencia que opusieron las unidades de regulares y de legionarios que la defendían y sobre todo porque inexplicablemente la aviación republicana no protegió el avance y la Legión Cóndor enviada rápidamente por el general Franco dominó los aires y bombardeó y ametralló constantemente las posiciones republicanas. Así que hacia el 2 o el 3 de agosto la maniobra republicana había fracasado ya que no se iba a producir ninguna irrupción de unidades republicanas en el territorio dominado por los sublevados. A partir de ese momento las operaciones se centraron en la bolsa de territorio ganado por los republicanos al sur del Ebro, que estos defendieron a toda costa mientras que los "nacionales" intentaban desalojarlos de allí (a pesar de que algunos de los colaboradores del general Franco le aconsejaron que abandonara el frente del Ebro una vez detenido el avance republicano y reemprendiera la campaña contra Valencia, pero Franco pensó, sin embargo, "que con la ayuda constante que recibía desde Alemania e Italia en aviación y artillería pesada, con su mayor flexibilidad logística (frente a un enemigo que no podía llevar refuerzos a sus tropas por estar cerrada la frontera francesa) y con el virtual bloqueo marítimo de las costas, podría destruir lentamente lo mejor de las fuerzas de la República"). Después de tres meses de duros combates, que causaron más de 60 000 bajas por cada bando, los republicanos tuvieron que retirarse y volver a cruzar el Ebro en sentido contrario. El 16 de noviembre lo hacían las últimas unidades poniendo fin así a la batalla del Ebro, la más larga de la guerra y que supuso una nueva victoria para el bando sublevado.

Mientras se desarrollaba la batalla del Ebro estalló la crisis de los Sudetes de Checoslovaquia que podía conducir a la guerra en Europa. Negrín decidió entonces retirar las Brigadas Internacionales para conseguir una actitud favorable hacia la República de las potencias democráticas Francia y Gran Bretaña y lo mismo hizo el general Franco al reducir la presencia de tropas italianas (aunque conservando lo que realmente le interesaba de la ayuda fascista italiana: la artillería, la aviación y los carros de combate) y garantizar a Gran Bretaña y Francia que se mantendría neutral si estallara la guerra en Europa. Sin embargo el cierre de la crisis con los acuerdos de Múnich del 29 de septiembre de 1938, según los cuales Checoslovaquia debería entregar los Sudetes a Hitler, supuso una nueva derrota para la República en el plano internacional porque el acuerdo significaba que las potencias democráticas, Francia y Gran Bretaña, continuaban con su política de "apaciguamiento" respecto de la Alemania nazi, y si no intervenían para defender a Checoslovaquia menos lo harían para ayudar a la República española.

Los dos ejércitos salieron muy quebrantados de la batalla del Ebro, pero los "nacionales" lograron rehacerse rápidamente, estando, a principios de diciembre de 1938, preparados para comenzar la ofensiva de Cataluña, "que sería la última significativa de la guerra", en un momento en que tras los acuerdos de Múnich atacar Cataluña ya no implicaba el peligro de una reacción francesa ("Francia y Gran Bretaña habían aceptado, al menos tácitamente, la continuación de la presencia italiana en España, y solo deseaban el fin del conflicto. Por su parte, Franco había garantizado su neutralidad en caso de una guerra general").

El ataque a Cataluña se retrasó a causa del mal tiempo y finalmente comenzó el 23 de diciembre, avanzando desde el sur y desde el oeste, encontrando una fuerte resistencia durante las dos primeras semanas. Sobre el día 6 de enero, los restos del Ejército del Ebro habían quedado casi completamente diezmados, mientras que el otro grupo de ejércitos del GERO, el Ejército del Este, se batía en retirada. El jefe del Estado Mayor republicano, el general Vicente Rojo, proyectó una maniobra de diversión en la zona centro-sur para aliviar la presión sobre Cataluña, pero fracasó (hubo que desistir del desembarco en Motril por la debilidad de la flota republicana, "minada por la desidia, la indisciplina y la falta de una clara dirección político-estratégica"; la ofensiva en el frente de Extremadura tuvo escaso éxito dada la baja moral y la falta de material y de medios de transporte que padecían los ejércitos de la zona centro-sur (GERC) al mando del general Miaja).

Así pues, a partir de la primera semana de enero de 1939 el avance de las tropas "nacionales" fue prácticamente imparable (gracias de nuevo a la mejor preparación de sus mandos intermedios —comandantes, tenientes-coroneles y coroneles—, a su superioridad artillera y aérea por la presencia permanente de la Legión Cóndor y de la aviación italiana y a que la flota sublevada bombardeó los puertos impidiendo la llegada de material para las fuerzas republicanas). Los "nacionales" en su avance hacían cada vez mayor número de prisioneros, lo que «siempre constituye un indicio de la descomposición de un ejército». Artesa de Segre fue tomada el 4 de enero, Tárrega el 15, el 21 Villafranca del Panadés, el 22 Igualada y el 24 alcanzaron el río Llobregat. Los destrozados ejércitos republicanos se retiraron hacia la frontera francesa acompañados por una inmensa muchedumbre de civiles y de funcionarios y de autoridades que colapsaba las carreteras. El 26 de enero los "nacionales" sin encontrar apenas resistencia entraban en Barcelona, abandonada por el gobierno y las autoridades militares que cruzaron la frontera francesa el 5 de febrero después de celebrar la última reunión de lo que quedaba de las Cortes republicanas en el castillo de Figueras. Un día antes, el 4 de febrero, los "nacionales" habían ocupado Gerona. El general Vicente Rojo Lluch comparó un año después desde el exilio lo que había sucedido en Madrid en noviembre de 1936 y lo que había pasado en Barcelona en enero de 1939:

Entre el 5 y el 11 de febrero los últimos restos de los dos ejércitos republicanos del GERO cruzaron ordenadamente la frontera deponiendo sus armas y siendo internados a continuación en campamentos improvisados situados en las playas francesas a la intemperie.

Mientras las tropas republicanas cruzaban la frontera francesa, se producía la ocupación de Menorca por los "nacionales" gracias a la intervención británica, la única que se produjo en la Guerra de España. Para impedir que la estratégica isla de Menorca, que durante toda la guerra había permanecido bajo soberanía republicana, pudiera caer bajo dominio italiano o alemán, el gobierno británico aceptó la propuesta del jefe franquista de la Región Aérea de las Baleares, Fernando Sartorius, conde de San Luis, para que un barco de la Royal Navy lo trasladara a Mahón y negociar allí la rendición de la isla a cambio de que las autoridades civiles y militares republicanas pudieran abandonarla bajo protección británica. El gobierno británico puso en marcha la operación sin informar al embajador republicano en Londres, Pablo de Azcárate (que cuando más tarde se enteró presentó una protesta formal por haber prestado un buque británico a un «emisario de las autoridades rebeldes españolas»). Así pues, en la mañana del 7 de febrero arribaba al puerto de Mahón el crucero "Devonshire" con el conde de San Luis a bordo, donde se entrevistó con el gobernador republicano el capitán de navío Luis González de Ubieta, quien tras intentar infructuosamente contactar con Negrín, aceptó las condiciones de la rendición al día siguiente. A las 5 de la madrugada del 9 de febrero el "Devonshire" partía de Mahón rumbo a Marsella con 452 refugiados a bordo. Inmediatamente Menorca fue ocupada por los "nacionales" sin que participara ningún contingente ni italiano ni alemán. La intervención británica dio lugar a un acalorado debate en la Cámara de los Comunes el 13 de febrero durante el cual la oposición laborista acusó al gobierno conservador de Neville Chamberlain de haber comprometido al Reino Unido en favor de Franco. Al día siguiente el representante oficioso del general Franco en Londres, el duque de Alba, hizo llegar al secretario del Foreign Office lord Halifax «la gratitud del generalísmo y del gobierno nacional» por colaborar en «reconquistar Menorca».

El día 9 de febrero cruzó la frontera francesa el presidente del gobierno, Juan Negrín, pero en Toulouse cogió un avión para regresar a Alicante al día siguiente acompañado de algunos ministros con la intención de reactivar la guerra en la zona centro-sur, el último reducto de la zona republicana. Allí se desató una última batalla entre los que consideraban inútil seguir combatiendo y los que todavía pensaban que "resistir es vencer" (esperando que las tensiones en Europa acabaran estallando y Gran Bretaña y Francia, por fin, acudirían en ayuda de la República española, o que al menos impondrían a Franco una paz sin represalias), pero el cansancio de la guerra y el hambre y la crisis de subsistencias que asolaba la zona republicana estaban minando la capacidad de resistencia de la población. El problema para Negrín, que instaló su cuartel general en una finca cercana a la localidad alicantina de Elda (cuyo nombre en clave era "Posición Yuste") era cómo terminar la guerra sin combatir de manera distinta a la de entrega sin condiciones. Su posición fue prácticamente insostenible cuando el 27 de febrero, Francia y Gran Bretaña reconocieron al gobierno de Franco en Burgos como el gobierno legítimo de España, y al día siguiente el presidente de la República Manuel Azaña que se encontraba en la embajada española en París renunció a su cargo.

El día 24 de febrero, Negrín abandonó Madrid tras celebrar un consejo de ministros e instaló su cuartel general en una finca cercana a la localidad alicantina de Elda (la "Posición Yuste", que era su nombre en clave). Tres días después, el 27 de febrero, Francia y Gran Bretaña reconocían al gobierno de Franco en Burgos como el gobierno legítimo de España, y el día 28 de febrero, ante este reconocimiento internacional, se hacía oficial la renuncia a la Presidencia de la República de Manuel Azaña y su sustitución provisional por el presidente de las Cortes, Diego Martínez Barrio (ambos se encontraban en Francia). Después de todos estos hechos la posición de Negrín era insostenible.

Mientas tanto estaba muy avanzada la conspiración militar y política contra el gobierno Negrín dirigida por el jefe del Ejército del Centro, el coronel Segismundo Casado, convencido de que ""sería más fácil liquidar la guerra a través de un entendimiento entre militares"" por lo que había entrado en contacto a través de la "quinta columna" con el Cuartel General del "Generalísimo" Franco para una rendición del ejército republicano "sin represalias" al modo del "abrazo de Vergara" de 1839 que puso fin a la primera guerra carlista (con la conservación de los empleos y cargos militares, incluida). Algo a lo que los emisarios del general Franco nunca se comprometieron. Casado consiguió el apoyo de varios jefes militares, entre los que destacaba el anarquista Cipriano Mera, jefe del IV Cuerpo de Ejército, y de algunos políticos importantes, como el socialista Julián Besteiro, que también había mantenido contacto con los "quintacolumnistas" de Madrid. Todos ellos criticaban la estrategia de resistencia de Negrín y su "dependencia" de la Unión Soviética y del PCE, que eran los únicos que apoyaban ya la política de Negrín.

Probablemente en conexión con la conjura casadista, el 4 de marzo se produjo la sublevación de la base naval de Cartagena encabezada por militares profranquistas alentados por la quinta columna que había desplegado una intensa actividad en la base y en la ciudad. Durante el día 4 y el 5 tienen lugar combates entre los sublevados y los resistentes republicanos. Y en medio de ellos, el almirante Miguel Buiza ordena a la flota republicana que abandone el puerto y la dirige a la base naval de Bizerta en el protectorado francés de Túnez, a pesar de que la sublevación había sido dominada en Cartagena por las fuerzas republicanas el día 7 de marzo.

El 5 de marzo, al día siguiente del inicio de la sublevación de Cartagena, comenzó el golpe de Casado apoderándose sus partidarios de los puntos neurálgicos de Madrid y anunciando a continuación la formación de un Consejo Nacional de Defensa presidido por el general Miaja. El Consejo emitió un manifiesto por radio dirigido a la "España antifascista" en el que se deponía al gobierno de Negrín, pero no hablaba para nada de las negociaciones de paz. Las unidades militares controladas por los comunistas opusieron resistencia en Madrid y sus alrededores pero fueron derrotados (hubo cerca de 2000 muertos). Al día siguiente Negrín y su gobierno, junto con los principales dirigentes comunistas, abandonaron España en avión para evitar ser apresados por los "casadistas".

Consumado el golpe de Casado, el general Franco se negó a aceptar un nuevo "abrazo de Vergara", como Mola también lo había rechazado en el primer día del golpe de 1936, y no concedió a Casado "ninguna de las garantías imploradas casi de rodillas por sus emisarios [que solo se entrevistaron con miembros de baja graduación del Cuartel General], y contestó a británicos y franceses, deseosos de actuar como intermediarios en la rendición de la República para así contener la influencia alemana e italiana sobre el nuevo régimen, que no los necesitaba y que el "espíritu de generosidad" de los vencedores constituía la mejor garantía para los vencidos".

Franco únicamente aceptaba una "rendición sin condiciones" por lo que solo restaba preparar la evacuación de Casado y el Consejo Nacional de Defensa. Estos embarcaron con sus familias el 29 de marzo en el destructor británico que los trasladó a Marsella (el socialista Julián Besteiro decidió quedarse). Un día antes las tropas "nacionales" hicieron su entrada en Madrid y rápidamente los sublevados en su ofensiva final ocuparon prácticamente sin lucha toda la zona centro-sur que había permanecido bajo la autoridad de la República durante toda la guerra (el 29 de marzo Cuenca, Albacete, Ciudad Real, Jaén, Almería y Murcia; el 30 de marzo Valencia y Alicante, y el 31 de marzo la ciudad de Cartagena). En Alicante desde el día 29 de marzo unas 15000 personas, entre jefes militares, políticos republicanos, combatientes y población civil que habían huido de Madrid y de otros lugares se apiñaban en el puerto a la espera de embarcar en algún barco británico o francés, pero la mayoría no lo lograron y fueron apresados por las tropas italianas de la División Littorio, al mando del general Gastone Gambara. Muchos de los capturados fueron ejecutados allí mismo.

El 1 de abril de 1939 la radio del bando rebelde (Radio Nacional de España) difundía el último parte de la guerra civil española, que decía lo siguiente:

En la guerra civil española predominaron las acciones terrestres sobre las marítimas, y las marinas de ambos bandos evitaron las grandes acciones de guerra por motivos políticos y estratégicos. Así, después de los combates por el control del estrecho de Gibraltar de 1936, las dos flotas no tuvieron «encuentros decisivos en el mar» y «sus estrategias se movieron en contextos muy conservadores, tendentes sobre todo a la conservación de sus efectivos». El historiador Michael Alpert, en su estudio titulado "La guerra civil española en el mar", afirma que las «dos marinas de guerra españolas tuvieron que rehacerse», pero que la «gubernamental no consiguió estar a la altura del momento y, a pesar de contar con la mayoría de las unidades de la flota, desempeñó un papel defensivo durante la mayor parte de la contienda». En cambio «la Marina de los sublevados aprovechó al máximo sus exiguos recursos y la ayuda que recibió del extranjero».

Desde principios del siglo XX, la función primordial de la marina de guerra ya no era destruir los barcos del enemigo, sino bloquear sus rutas marítimas y sus puertos e impedir sus movimientos en la costa. Esto es lo que realizó cada vez con más éxito la marina del bando sublevado, mientras que la marina que permaneció fiel al gobierno abandonó ese objetivo después de las primeras semanas y adoptó una posición defensiva cuyo objetivo era proteger las comunicaciones marítimas propias, mientras los "nacionales" se esforzaban en interferirlas.

Al principio de la Guerra Civil, la marina republicana era muy superior a la que quedó en manos de los sublevados, pues estaba integrada por la práctica totalidad de la Armada española de aquel entonces: el acorazado "Jaime I" (botado en 1914); los cruceros ligeros "Libertad" (botado en 1925), "Miguel de Cervantes" (botado en 1928) y "Méndez Núñez" (botado en 1923); dieciséis destructores en servicio o a punto de entregar; siete torpederos; doce submarinos (del submarino "Isaac Peral" (C-1) al submarino C-6 y del submarino B-1 al submarino B-6); un cañonero; cuatro guardacostas y la casi totalidad de la Aeronáutica Naval.

A pesar de contar con una flota tan importante, el problema residió en que a lo largo de la guerra no se consiguieron superar los efectos de la represión que tuvo lugar en el momento del golpe de estado de julio de 1936 cuando la marinería y los suboficiales se rebelaron para impedir que los barcos se sumaran a la sublevación, ya que la inmensa mayoría de la oficialidad era partidaria del golpe. En una fecha tan avanzada como mayo de 1938, un informe presentado al presidente Juan Negrín sobre la situación de la flota señalaba la ausencia de eficacia y de disciplina. «En general la moral ofensiva de los mandos es pequeña y la moral de combate de las dotaciones es baja». Además, apuntaba la presencia de la quinta columna franquista tanto en la Flota como en la base naval de Cartagena («Moral derrotista. Mucho fascista con entera libertad de acción», se decía). Informes posteriores indicaban que la situación no había mejorado.

A diferencia de lo que ocurrió con el bando sublevado, que fue apoyado por las armadas italiana y alemana, la República solo recibió de la URSS cuatro lanchas torpederas de clase G-5, además de unos pocos mandos y especialistas en submarinos que, según un informe «reservado y confidencial» presentado al presidente Negrín, eran «considerados —dentro de la Flota— como huéspedes molestos a los que hay soportar con amabilidad. Lo mismo ocurre en la base naval de Cartagena». Por su parte, Francia y Gran Bretaña solo participaron en alguna ocasión puntual para evitar el apresamiento de buques propios por la flota "nacional".

Así pues, por encima de alguna victoria ocasional, como el hundimiento del "Baleares" a principios de marzo de 1938 en la batalla del cabo de Palos, «la realidad era que la marina republicana se había centrado en el servicio de protección del tráfico mercante, en el mantenimiento de un canal suministrador de pertrechos de guerra y de alimentos». Pero ni siquiera esa función de escolta la desempeñó con pleno éxito, como se señalaba en un informe del servicio secreto republicano (SIM) de enero de 1939 en el que después de afirmar la "notoria inferioridad" de la marina de guerra republicana respecto de la Marina de los "nacionales" se decía:
La flota republicana y la base naval de Cartagena fueron aumentando su importancia estratégica para la causa del bando republicano a media que aumentaban las dificultades para el abastecimiento procedente del exterior por vía terrestre, como consecuencia de los cierres frecuentes de la frontera francesa, por lo que el mantenimiento del "cordón umbilical" marítimo con la Unión Soviética era vital para los republicanos. También cobraron cada vez más importancia a medida que las derrotas republicanas se fueron acumulando y el territorio de la zona republicana se redujo porque, especialmente tras la caída de Cataluña a principios de febrero de 1939, "para los combatientes republicanos la Base y la Flota eran una especie de salvaguarda para el caso de una evacuación organizada o de última hora".

Al principio de la Guerra Civil, la marina del bando sublevado era muy inferior a la marina gubernamental pues solo contaba con el acorazado "España" (botado en 1913 y que en julio de 1936 se encontraba en dique seco); los cruceros ligeros "República", rebautizado como "Navarra", (botado en 1920 pero que se encontraba en reparaciones y no entró en servicio hasta muy avanzada la guerra, en agosto de 1938), y el "Almirante Cervera" (botado en 1928); el destructor Velasco (botado en 1923); cinco torpederos; tres cañoneras y cinco guardacostas. Pero esta inferioridad se vio compensada muy pronto gracias al control de los sublevados del principal astillero de la marina en Ferrol donde estaba prácticamente terminado el crucero pesado "Canarias" —que entró en servicio en septiembre de 1936— y otro, el "Baleares", a punto de ser entregado (entró en servicio en diciembre de 1936), junto con los dos únicos dragaminas de España (el dragaminas Júpiter, que entró en servicio a principios de 1937, y el dragaminas Vulcano, que entró en servicio a finales de ese mismo año).

La inferioridad inicial de los sublevados se vio compensada también con el apoyo con que contaron prácticamente desde el inicio de la guerra de la Armada Italiana, que participó con cruceros auxiliares y submarinos en el bloqueo de los envíos de armamento de la Unión Soviética, y de la alemana. El escándalo producido al hundir un submarino italiano por error un destructor británico, hizo que la Italia Fascista dejara de participar directamente en acciones de guerra navales, cediendo cuatro «submarinos legionarios» a los "nacionales" y vendiéndoles cuatro destructores y dos submarinos.

Por su parte la Alemania nazi envió al Mediterráneo dos submarinos en la llamada Operación Úrsula, hundiendo un U 34 alemán el submarino republicano C3 frente a Málaga. Los alemanes aportaron cruceros, pero estos no intervinieron, salvo en el bombardeo de Almería por el "Admiral Scheer" el 31 de mayo de 1937, efectuado en represalia por el ataque aéreo que había sufrido el 28 de mayo de 1937 el acorazado de bolsillo "Deutschland" en Ibiza. Este llamado incidente del Deutschland fue efectuado probablemente por tripulaciones rusas, sin conocimiento por parte del mando republicano. Pero el escándalo internacional que provocó hizo que la República dijese que era un error y que se trataba de aviones republicanos que creían atacar al crucero pesado "Canarias". El bombardeo de Almería, que se había producido abiertamente (exhibiendo el pabellón alemán), llegó a ser considerado como un posible motivo para que la República declarara la guerra a Alemania (posición defendida por el coronel Rojo e Indalecio Prieto, en búsqueda de la generalización del conflicto a toda Europa), pero finalmente se impuso la postura contraria de Negrín y Azaña.

Un informe del servicio secreto republicano (SIM) de enero de 1939 señalaba la desventaja de la marina republicana respecto de la «marina de guerra facciosa», que contaba con «un total de cerca de 100 unidades —contando entre ellas un gran número de cruceros auxiliares perfectamente artillados—».

La principal novedad en el campo de la guerra aérea de la contienda española de 1936 a 1939 fue que «por primera vez en la historia la aviación fue utilizada intensamente en misiones de bombardeo sobre la retaguardia». Así «a partir de la guerra civil española las víctimas podían estar a centenares de kilómetros de los lugares del enfrentamiento bélico y ser sencillamente población civil indefensa». Dado que la aviación militar española en julio de 1936 estaba obsoleta esto solo fue posible porque ambos bandos recibieron ayuda de potencias extranjeras que aportaron sus modernos bombarderos: el bando sublevado los Savoia-Marchetti S.M.81 y los Savoia-Marchetti S.M.79 de la Aviación Legionaria de la Italia fascista y los Junkers Ju 52 y Heinkel He 111 de la Legión Cóndor de la Alemania nazi; el bando republicano los Katiuskas de la Unión Soviética.

El bando sublevado utilizó en repetidas ocasiones el «bombardeo de terror», como lo llaman Solé i Sabaté y Villarroya, cuyo único objetivo era la población civil para desmoralizarla y empujarla a la rendición. Esta estrategia la inició en Madrid cuando en noviembre de 1936 fracasó el ataque frontal contra la ciudad y la continuó con el bombardeo de Durango, el bombardeo de Guernica, el bombardeo de Lérida, los bombardeos aéreos de Barcelona en enero de 1938, los bombardeos aéreos de Barcelona en marzo de 1938, el bombardeo del mercado central de Alicante, el bombardeo de Granollers y los bombardeos sobre diversas poblaciones catalanas en los meses finales de la guerra, especialmente los de Figueras, y cuyas víctimas principales fueron mujeres y niños en un momento en que el ejército republicano ya no existía en Cataluña. El único posible caso de "bombardeo de terror" por parte del bando republicano fue el de Cabra en noviembre de 1938, pero todo parece indicar que se trató de un terrible error cometido por los pilotos que confundieron el mercadillo de la ciudad con un campamento de tiendas de campaña de una unidad italiana que, según la orden que habían recibido, había que buscar y destruir.

Así en cuanto a las ciudades más devastadas por los bombardeos la lista la encabezan las tres principales ciudades republicanas, Barcelona, Madrid y Valencia, seguidas por Tarragona, Reus, Lérida, Badalona, Granollers, Gerona, San Feliu de Guíxols, Palamós, Figueras, Colera, Portbou y Perelló en Cataluña; Alicante, Sagunto, Gandía, Denia y Cartagena en la costa de Valencia y Murcia; y en Vizcaya Durango y Guernica, esta última convertida en el símbolo de las atrocidades de los bombardeos del bando sublevado, y que tuvo un enorme impacto a nivel internacional. En cuanto al número de víctimas también existe una enorme diferencia entre las causadas por los bombardeos republicanos, unas 1100, y las causadas por los bombardeos del bando franquista, alrededor de 9000 (Barcelona 2500 muertos; Madrid, 2000; Valencia, cerca de 1000; Alicante cerca de 500; Durango, Guernica, Lérida, Tarragona, Granollers, Figueras y Cartagena más de doscientos muertos cada una; Bilbao, Reus, Badalona y Alcañiz cerca de 200; Játiva más de 100 muertos; y pequeños pueblos cuyos muertos fueron inferiores a este número).

Así fue como "la aviación se convirtió en un arma decisiva y la actuación de la aviación italiana y alemana fue determinante en la victoria del ejército franquista".

Otros hitos de la guerra aérea durante la guerra civil española son que durante la misma probablemente se efectuó el primer puente aéreo de la historia; que en los aviones de caza empezó a primar el techo y la velocidad lo que supuso el fin de los biplanos y además se demostró su importancia para el dominio del aire y evitar así los bombardeos enemigos (incluso por la noche); que se realizaron ataques aéreos a unidades navales, en puerto y en el mar; que se emplearon aviones de bombardeo en picado para lanzar víveres y mensajes de ánimo a posiciones sitiadas, como el Alcázar de Toledo o el Santuario de Santa María de la Cabeza, y para los "bombardeos ideológicos", mediante el lanzamiento de octavillas y soflamas a las ciudades que estaban en la retaguardia, como el "bombardeo del pan" sobre Alicante.

Tras la etapa de cierta provisionalidad que representó la Junta de Defensa Nacional formada tras la muerte en accidente de aviación del general Sanjurjo, quien debía encabezar el Directorio militar que gobernaría el país tras derribar al gobierno del Frente Popular, los generales y jefes sublevados decidieron nombrar un mando único militar y político. Desde el 1 de octubre de 1936 el general Franco fue el "Generalísimo" de las fuerzas sublevadas y el "Jefe del Gobierno del Estado". Después del fracaso de la toma de Madrid (entre noviembre de 1936 y marzo de 1937) y con la perspectiva de que la guerra iba a ser larga, el "Generalísmo" Franco, con la ayuda de su cuñado, Ramón Serrano Suñer, comenzó a configurar la organización política del "Nuevo Estado". El primer paso fue el Decreto de Unificación de abril de 1937 por el que todas las fuerzas políticas que apoyaban el "alzamiento nacional", y singularmente los falangistas y los carlistas, que eran quienes con sus milicias más habían contribuido a la guerra y fueron integradas bajo un único partido denominado Falange Española Tradicionalista y de las JONS. El paso siguiente fue la organización del "Nuevo Estado" que fue la tarea encomendada por el "Generalísmo" a su primer gobierno nombrado el 30 de enero de 1938 (y que sustituyó a la Junta Técnica del Estado).

La construcción del "Nuevo Estado" fue acompañada de la destrucción de todo lo que tuviera que ver con la República. Así en la zona sublevada, al contrario de lo que estaba sucediendo en la otra zona (en la que se había desencadenado la revolución), se procedió a una "contrarrevolución", llevándose a cabo "una sistemática represión de las personas, las organizaciones y las instituciones que en alguna forma, real o, incluso, imaginaria, pudieran entenderse ligadas a esa República revolucionaria, o en manos de revolucionarios, a la que se decía combatir".

La muerte el 20 de julio del general Sanjurjo, exiliado en Estoril, a causa del accidente que tuvo nada más despegar el avión en el que tenía que dirigirse desde Lisboa hacia Pamplona para ponerse al frente de la sublevación, dejó a los generales sublevados sin el jefe que iba a encabezar el levantamiento. Para suplir en parte la carencia de un mando único los generales y jefes sublevados constituyeron en Burgos el 24 de julio una Junta de Defensa Nacional presidida por el general de más graduación y más antiguo, Miguel Cabanellas. Su Decreto número 1 establecía que asumía ""todos los poderes del Estado"" y en sucesivos decretos extendió el estado de guerra que los sublevados habían proclamado en cada sitio a toda España (lo que sirvió de base para someter a consejos de guerra sumarísimos a todos los que se opusieran a la rebelión militar), ilegalizó los partidos y sindicatos del Frente Popular y prohibió todas las actuaciones políticas y sindicales obreras y patronales ""mientras duren las actuales circunstancias"" (Decreto del 25 de septiembre).

Pero lo más urgente era lograr la unidad de mando militar. Así el 21 de septiembre de 1936 tuvo lugar en una finca de los alrededores de Salamanca la primera reunión a la que asistieron los generales de la Junta de Defensa Nacional, con el añadido de los generales Orgaz, Gil Yuste y Kindelán. Allí los reunidos discutieron sobre la necesidad del mando único de las fuerzas sublevadas y nombraron para el cargo al general Franco pues era quien mandaba el ejército que estaba a punto de conseguir la entrada en Madrid (el Ejército de África estaba cerca de Maqueda a solo 100 kilómetros de la capital) y el que había obtenido la ayuda de la Alemania nazi y de la Italia fascista, y que venía tratando con ellos. Pero una vez decidido el mando único en el terreno militar aún quedaba por dilucidar el mando político.

Entonces el general Franco realizó una "jugada maestra": ordenar que las columnas que avanzaban hacia Madrid se desviaran hacia Toledo para liberar el Alcázar y así levantar el cerco de dos meses al que llevaban sometidos un millar de guardias civiles y falangistas además de algunos cadetes de la Academia de Infantería al mando de su director, el coronel Moscardó, y que tenían retenidos "como rehenes a mujeres y niños de conocidos militantes de izquierda". "La toma del Alcázar agrandó la leyenda del general Franco. La famosa frase de Moscardó "sin novedad en el Alcázar", repetida ante Franco y numerosos periodistas dos días después de su liberación, fue adecuadamente propagada. Franco era el salvador de los héroes sitiados, el símbolo de un ejército dispuesto a ganar la guerra a cualquier precio".

El 28 de septiembre de 1936, el mismo día en que el Alcázar de Toledo fue liberado, se celebró la segunda reunión de los generales en Salamanca para decidir quién ostentaría el mando político. El elegido fue el general Franco al que sus compañeros de sublevación nombraban no solo “"Generalísimo de las fuerzas nacionales de tierra, mar y aire"", sino también ""Jefe del Gobierno del Estado español, mientras dure la guerra"". Pero cuando fue publicado al día siguiente el de la Junta de Defensa Nacional con su nombramiento se había introducido un importante cambio en el texto: se había suprimido la coletilla ""mientras dure la guerra"", y al nombramiento del general Franco como ""Jefe del Gobierno del Estado Español"" se le añadía ""quien asumirá todos los poderes del nuevo Estado"". Este decreto de 29 de septiembre de 1936 sería el fundamento de la legitimidad del poder del "Generalísimo" durante los siguientes 39 años.

El 1 de octubre de 1936, en el salón del trono de la Capitanía General de Burgos, Francisco Franco tomaba posesión de su nuevo cargo, como "Generalísimo" del ejército sublevado y "Jefe del Gobierno del Estado".

Un día antes el obispo de Salamanca Enrique Pla y Deniel había hecho pública una pastoral en la que presentaba la guerra como «una cruzada por la religión, la patria y la civilización», dando una nueva legitimidad a la causa de los sublevados: la religiosa. Así el generalísmo, no era solo el «jefe y salvador de la Patria», sino también el «caudillo» de una nueva «cruzada» en defensa de la fe católica y del orden social.

La primera ley que promulgó el generalísimo Franco fue la que creaba la Junta Técnica del Estado (en sustitución de la Junta de Defensa Nacional), presidida por el general Dávila (que en el verano de 1937 sería sustituido por el general monárquico Francisco Gómez-Jordana, mucho más eficiente que su antecesor) y que contaba con una Secretaría General del jefe del Estado, cargo que desempeñó Nicolás Franco, el hermano mayor del generalísmo. Su ocupación fue «rectificar toda la legislación republicana volviendo las cosas a su punto anterior».

La sede de la Junta Técnica del Estado se estableció en Burgos aunque la capital política de la España nacional era Salamanca donde residía el poder militar, pues allí se encontraba el Cuartel General de Franco.

El siguiente paso en el afianzamiento del poder del nuevo «caudillo» se produjo cuando tras el fracaso de la toma de Madrid (entre noviembre de 1936 y marzo de 1937) se planteó la necesidad de crear un "partido único", siguiendo el modelo de la Dictadura de Primo de Rivera, a partir de la fusión de los carlistas y falangistas.

Desde el Cuartel General del Generalísimo el nuevo asesor de Franco Ramón Serrano Súñer (cuñado del «caudillo» y antiguo diputado de la CEDA que había llegado a Salamanca evadido de la "zona roja") propició un acercamiento entre la Comunión Tradicionalista y Falange Española y de las JONS con vistas a su fusión, pero las diferencias ideológicas y políticas que les separaban eran casi insalvables (pues eran las que separaban el tradicionalismo del fascismo), y además había otro obstáculo que era innegociable: que al frente del "partido único" se situara el propio general Franco. Es decir, que ambas partes tenían que aceptar que la nueva formación política quedaría supeditada al poder personal del "Generalísmo", vértice del poder militar y político. Para apoyar esta idea se difundió desde el Cuartel General de Salamanca el lema "Una patria, un Estado, un caudillo", copia del lema nazi "Ein Volk, ein Reich, ein Führer" ('un pueblo, un Estado, un caudillo').

Se produjeron contactos entre falangistas y carlistas pero no fructificaron y todo el proceso no dejó de crear tensiones en el seno de ambos partidos que se tradujeron en el caso de los falangistas en los "sucesos de Salamanca" de abril de 1937, durante los cuales varios falangistas murieron en los enfrentamientos entre los partidarios de la fusión y de la supeditación al poder militar (encabezados por Sancho Dávila y Agustín Aznar) y los contrarios a ella (encabezados por Manuel Hedilla).

Finalmente, el Cuartel General de Franco decidió actuar, y el mismo día en que los falangistas contrarios a la fusión celebraron un Consejo Nacional en el que eligieron a Manuel Hedilla como "jefe nacional", el domingo 18 de abril, el propio general Franco anunció que se iba a promulgar al día siguiente un Decreto de Unificación de Falange y la Comunión Tradicionalista, que pasaban a estar ahora bajo su jefatura directa como "jefe nacional" del mismo.

Franco una semana después mandó detener a Manuel Hedilla (junto con otros falangistas disidentes) cuando se negó a integrarse en la Junta Política del nuevo partido como simple vocal y además comunicó a sus jefes provinciales que obedecieran únicamente sus propias órdenes. «Para que no quedara duda sobre la ubicación del poder en lo que ya comenzaba a llamarse Nuevo Estado, Hedilla fue juzgado y condenado a muerte por su "manifiesta actuación de indisciplina y de subversión frente al Mando y el Poder únicos e indiscutibles de la España nacional". A todos debía quedar claro que la unidad de mando militar sería en el futuro unidad de mando político». Pero Franco siguió los consejos de la hermana del "Ausente" Pilar Primo de Rivera (líder del sector "puro" de Falange), de Serrano Suñer y del embajador alemán e indultó a Hedilla, aunque este pasó cuatro años en la cárcel y cuando salió de ella quedó apartado de la vida política.

En los estatutos del "partido único", publicados el 4 de agosto, se estableció que el "caudillo" solo sería "responsable ante Dios y ante la Historia", y ante nadie más.

Dos meses antes, el 3 de junio, en plena Campaña del Norte el general Mola, el "director" de la conspiración militar que había dado el golpe de estado de julio de 1936 con el que comenzó la Guerra Civil, moría cuando el avión en el que viajaba se estrelló en una colina del pueblo de Alcocero, cerca de Burgos. Mola solía emplear el avión con frecuencia en sus desplazamientos y no existen pruebas de que hubiera sabotaje, aunque la muerte favorecía claramente a Franco al eliminar al "director" como rival. El embajador alemán escribió poco después: ""Sin duda Franco se siente aliviado por la muerte del general Mola"".

En octubre de 1937 fueron nombrados por el "Generalísmo" Franco los 50 miembros del Consejo Nacional de FET y de las JONS, pero no pasó de ser un órgano meramente consultivo. Lo mismo se podía decir de la FET y de las JONS, cuya única actividad quedaba reducida en la práctica a efectuar propaganda. Sin embargo, los dirigentes de Falange ocuparon muchos de los puestos más importantes en la administración del "Nuevo Estado" y en el partido.

En enero de 1938, mientras tenía lugar la batalla de Teruel, se da el primer paso para la configuración definitiva del "Nuevo Estado" con la promulgación por el "Generalísmo" de la Ley de la Administración Central del Estado por la que se creaba una estructura administrativa que adoptaba la forma ministerial, y con el nombramiento el 30 de enero de su primer gobierno en el que el propio Franco asume la Presidencia, mientras que Francisco Gómez-Jordana (hasta entonces presidente de la Junta Técnica del Estado) era el Vicepresidente y Ministro de Asuntos Exteriores. Sin embargo, el personaje más destacado del gabinete era Ramón Serrano Súñer, ministro de Gobernación y el "cuñadísimo" de Franco. En este gobierno se prefiguró ya la amalgama ideológica que sería siempre en el futuro el "franquismo": "su conservadurismo "tradicional", y su derechismo reaccionario".

Será este gobierno el que inicie el proceso de institucionalización del "Nuevo Estado", con la promulgación del "Fuero del Trabajo", basado en la "Carta del lavoro" del fascismo italiano, y que constituyó la primera de las siete Leyes Fundamentales de la Dictadura Franquista que funcionaron a modo de "constitución" del nuevo régimen; la derogación del Estatuto de Autonomía de Cataluña de 1932 y la promulgación de una serie de órdenes y decretos que prohibían el uso del catalán en los documentos públicos y en la conversación privada; la Ley de Prensa que sometía a los periódicos a la censura previa y atribuía al gobierno el nombramiento de los directores de periódicos; la reintroducción de la pena de muerte que había abolido la República; la aprobación de una Ley de Enseñanza Media que garantizaba a la Iglesia católica una absoluta autonomía en la educación secundaria.

Según Julián Casanova el fascismo y el catolicismo fueron las dos ideologías sobre cuya amalgama se construyó el "Nuevo Estado". El proceso de fascistización era evidente por la exaltación del líder, el "Caudillo", como el Führer o el Duce; el saludo brazo en alto establecido como "saludo nacional"; los uniformes y la simbología falangista; etc. Y al mismo tiempo proliferaban los ritos y manifestaciones religiosas católicas como las procesiones, las misas de campaña o las ceremonias político-religiosas que imitaban supuestas formas medievales.

El 19 de abril de 1939, diecinueve días después del "último parte" en el que Franco declaraba «la guerra ha terminado», se celebró en Madrid el desfile de la Victoria presidido por el «caudillo». Antes de empezar la parada militar el general Varela le impuso «en nombre de la Patria» a Franco la Gran Cruz Laureada de San Fernando, «que tanto había ambicionado desde sus campañas africanas y que tuvo que acabar autootorgándosela» en un decreto firmado por él mismo y que fue leído por el general conde de Jordana al inicio del acto. Al día siguiente el diario "ABC" de Madrid titulaba su crónica: «España, en el gran desfile militar ante el Caudillo, muestra al mundo el poderío de las armas forjadoras del nuevo Estado». Un mes después el general Franco ofrendaba su espada de caudillo victorioso a Dios en una ceremonia celebrada el 20 de mayo en la iglesia madrileña de Santa Bárbara y presidida por el cardenal primado de Toledo Isidro Gomá.

En la tarde del viernes 17 de julio se conocía en Madrid que en el Protectorado de Marruecos se había iniciado una sublevación militar. Al día siguiente la sublevación se extendió a la península y las organizaciones obreras (CNT y UGT) reclamaron «armas para el pueblo» para acabar con ella, a lo que el gobierno de Santiago Casares Quiroga se negó.

Por la noche de ese sábado 18 de julio Casares Quiroga presentó su dimisión al presidente de la República Manuel Azaña y este encargó a Diego Martínez Barrio, presidente de las Cortes y líder de Unión Republicana, que formara un gobierno que consiguiera "detener la rebelión" sin recurrir al apoyo armado de las organizaciones obreras. Martínez Barrio incluyó en su gabinete a políticos moderados y dispuestos a llegar a algún tipo de acuerdo con los militares sublevados y en la madrugada del sábado 18 al domingo 19 de julio, habló por teléfono con el general Emilio Mola, "El Director" de la sublevación, pero este se negó rotundamente a cualquier tipo de transacción. Así el "gobierno de conciliación" de Martínez Barrio dimitió y Azaña nombró el mismo domingo 19 de julio nuevo presidente del gobierno a un hombre de su partido José Giral, que formó un gobierno únicamente integrado por republicanos de izquierda, aunque con el apoyo explícito de los socialistas, que tomó la decisión de entregar armas a las organizaciones obreras, algo a lo que también se había negado Martínez Barrio porque, al igual que Casares Quiroga, consideraba que ese hecho traspasaba el umbral de la defensa constitucional y "legal" de la República.

A causa de esta decisión de «entregar armas al pueblo» el Estado republicano perdió el monopolio de la coerción, por lo que no pudo impedir que se iniciara una revolución social, ya que las organizaciones obreras no salieron a la calle «exactamente para defender la República... sino para hacer la revolución. (...) Un golpe de estado contrarrevolucionario, que intentaba frenar la revolución, acabó finalmente desencadenándola».

La entrega de armas a los partidos y organizaciones obreras hizo que estas constituyeran rápidamente "milicias armadas para hacer frente a la rebelión en el terreno militar y para proceder a una profunda revolución social (desentendiéndose de las autoridades republicanas, a las que no derribaron): incautaron y colectivizaron explotaciones agrarias y empresas industriales y mercantiles para asegurar la continuidad de la producción y distribución de bienes, y se hicieron cargo del mantenimiento de las principales funciones competencia del Estado. La producción, el abastecimiento de la población, la vigilancia, la represión, las comunicaciones y el transporte, la sanidad, quedaron en manos de comités sindicales, que en no pocas localidades suprimieron la moneda para sustituirla por vales. Ante el hundimiento de los mecanismos del poder público ["un gobierno que reparte armas es un gobierno que se ha quedado sin instrumentos para garantizar el orden público e imponer su autoridad"], surgió en el verano de 1936 un nuevo poder obrero, que era a la vez militar, político, social, económico”. "En el País Vasco, sin embargo, donde el PNV había rechazado la coalición con la CEDA en las elecciones de febrero de 1936 y apoyado a la izquierda en la tramitación del Estatuto de Autonomía, finalmente aprobado el 1 de octubre de 1936, no hubo revolución social y un partido católico y nacionalista se mantuvo hasta junio de 1937 al frente de un gobierno autónomo con poder sobre poco más que el territorio de Vizcaya".

Los comités que surgieron por todas partes eran autónomos y no reconocían límites a sus actuaciones, pero la paradoja fue que al mismo tiempo la revolución no acabó con el Estado republicano, sino que simplemente lo ignoró y lo redujo a la inoperancia. En Cataluña se constituyó el Comité Central de Milicias Antifascistas, pero el gobierno de la Generalidad no fue destituido y continuó en su puesto. En Valencia apareció el Comité Ejecutivo Popular. En Málaga y Lérida surgieron sendos Comités de Salud Pública. En Cantabria, Gijón y Jaén, comités provinciales del Frente Popular (Comité de Guerra de Gijón, Comité Popular de Sama de Langreo, etc). En Vizcaya, una Junta de Defensa. En Madrid se constituyó un Comité Nacional del Frente Popular, que organizaba milicias y la vida de la ciudad, pero junto a él seguía existiendo el gobierno de José Giral formado solo por republicanos de izquierda.

Pero el gobierno Giral, a pesar de que el poder real no estaba en sus manos, no dejó de actuar, especialmente en el plano internacional. Fue este gobierno el que pidió la venta de armas al gobierno del Frente Popular de Francia, y al no conseguirla, luego a la Unión Soviética, para lo cual dispuso de las reservas del oro del Banco de España. En el plano interior destituyó a los funcionarios sospechosos de apoyar la sublevación y dictó las primeras medidas para intentar controlar las "ejecuciones" indiscriminadas, arbitrarias y extrajudiciales de "fascistas" que llevaban a cabo decenas de "tribunales revolucionarios", también conocidos como "checas", montadas por las organizaciones y partidos obreros que habían impuesto el "terror rojo" en Madrid y en otros lugares. Así el gobierno Giral creó los tribunales especiales "para juzgar los delitos de rebelión y sedición y los cometidos contra la seguridad del Estado". Sin embargo estos "tribunales populares" no acabaron con las actividades de las "checas" que siguieron asesinando "fascistas" mediante los "paseos" (detenciones ilegales que acababan con el asesinato del detenido y cuyo cadáver eran arrojado en una cuneta o junto a la tapia de un cementerio) o las "sacas" (excarcelaciones de presos que supuestamente iban a ser puestos en libertad pero que en realidad eran llevados al paredón).

Cuando el 3 de septiembre de 1936 el Ejército de África sublevado tomó Talavera de la Reina (ya en la provincia de Toledo, después de haber ocupado Extremadura), y además también caía Irún en manos de los sublevados (con lo que el norte quedaba aislado del resto de la zona republicana), José Giral presentó la dimisión al presidente de la República Manuel Azaña.

Tras la dimisión de Giral, el presidente de la República Manuel Azaña encargó la formación de un "gobierno de coalición" a Francisco Largo Caballero, el líder socialista de UGT, una de las dos centrales sindicales que estaban protagonizando la revolución. Largo Caballero, que además de la presidencia asumió el ministerio clave de Guerra, entendió este gobierno como una gran "alianza antifascista", y así dio entrada en el gabinete al mayor número posible de representaciones de los partidos y sindicatos que luchaban contra la rebelión "fascista" (como llamaban las organizaciones obreras a la sublevación militar de julio). Pero el gobierno no se completó realmente hasta dos meses después, cuando el 4 de noviembre (en el momento en que las tropas sublevadas ya estaban a las afueras de Madrid) se integraron en él cuatro ministros de la CNT, entre ellos la primera mujer que fue ministra en España, Federica Montseny.

El nuevo gobierno de Largo Caballero, autoproclamado "gobierno de la victoria", enseguida concluyó que había que dar prioridad a la guerra, y de ahí el programa político que puso en marcha inmediatamente, cuya principal medida fue la creación de un nuevo ejército y la unificación de la dirección de la guerra (que incluía la incorporación de las milicias a las Brigadas Mixtas y la creación del cuerpo de comisarios). Así pues, los dirigentes sindicales de UGT y CNT al aceptar e impulsar este programa "estuvieron de acuerdo en que la implantación del comunismo libertario, a que aspiraba la CNT, o de la sociedad socialista, que pretendía la UGT, debía esperar al triunfo militar".

Pero todas estas medidas no consiguieron paralizar el avance hacia Madrid del Ejército de África y el 6 de noviembre ya estaba a punto de entrar en la capital. Ese día el gobierno decidió abandonar Madrid y trasladarse a Valencia, encomendando la defensa de la ciudad al general Miaja que debería formar una Junta de Defensa de Madrid. "Una salida precipitada, mantenida en sigilo, sobre la que no se dio explicación pública alguna". "Quienes se quedaron en Madrid no pudieron interpretar estos hechos sino como una vergonzosa huida... sobre todo porque los madrileños fueron capaces de organizar su defensa. Madrid resistió el primer embate y rechazó los siguientes, deteniendo así el avance del ejército rebelde".

El segundo gran objetivo del gobierno de Largo Caballero fue restablecer la autoridad del gobierno y de los poderes del Estado. Pero no se resolvieron las tensiones con los gobiernos de las "regiones autónomas" de Cataluña y el País Vasco, ni con los consejos regionales que habían surgido en otros sitios. En Cataluña, el gobierno de la Generalidad, que el 26 de septiembre incorporó a varios consejeros de la CNT y del POUM por lo que el Comité de Milicias Antifascistas quedó disuelto, organizó su propio ejército y el 24 de octubre aprobó el decreto de colectividades, cuestiones ambas que excedían el ámbito de sus competencias. En cuanto al País Vasco, el 1 de octubre las Cortes aprobaban el Estatuto de Autonomía de Euskadi y el nacionalista vasco José Antonio Aguirre fue investido "lehendakari" del gobierno vasco, entre cuyos miembros no incluyó a ningún representante de la CNT (en el País Vasco no había habido revolución social ni apenas violencia anticlerical y las iglesias continuaron abiertas). Aguirre construyó un Estado "cuasi soberano" sobre el territorio vasco que todavía no había sido ocupado por el bando sublevado y que prácticamente se reducía a Vizcaya. Además de una policía vasca, la Ertzaina, creó un ejército propio y no aceptó el mando del general que envió el gobierno de Madrid para ponerse al frente del Ejército del Norte. En cuanto al Consejo de Aragón, dominado por los anarquistas, el gobierno de Largo Caballero no tuvo más remedio que legalizarlo.

En la primavera de 1937, tras la decisión de Franco de poner fin por el momento a la toma de Madrid después de la victoria republicana en la batalla de Guadalajara, se abría la perspectiva de una guerra larga y pronto estalló la crisis entre las fuerzas políticas que apoyaban a la República. El conflicto fundamental fue el que enfrentó a los anarquistas de la CNT, que defendían la compatibilidad de la revolución con la guerra, y a los comunistas del Partido Comunista de España (PCE) y del PSUC en Cataluña, que entendían que la mejor forma de frenar la sublevación militar era restablecer el Estado republicano y aglutinar a todas las fuerzas de la izquierda política, incluidos los partidos de la pequeña y mediana burguesía, por lo que debía paralizarse la revolución social y dar prioridad a la guerra. Sin embargo, Santos Juliá afirma, en contra de la opinión de otros historiadores, que en la primavera de 1937 entre las fuerzas que apoyaban al gobierno de Largo Caballero "la divisora no corría entre guerra y revolución sino entre partidos y sindicatos" porque la prioridad dada a la guerra ya se había decidido el 4 de septiembre cuando se formó el gobierno de Largo Caballero, al que dos meses después se sumaron los cuatro ministros anarquistas.

La crisis estalló por los enfrentamientos iniciados en Barcelona el lunes 3 de mayo de 1937 cuando un destacamento de la Guardia de Asalto por orden de la Generalidad intentó recuperar el control sobre el edificio de la Telefónica en la plaza de Cataluña, en poder de la CNT desde las jornadas "gloriosas" de julio de 1936. Varios grupos anarquistas respondieron con las armas y el POUM se sumó a la lucha. En el otro bando, la Generalidad y los comunistas y socialistas unificados en Cataluña bajo un mismo partido (el PSUC) hicieron frente a la rebelión, que ellos mismos habían provocado, y la lucha se prolongó varios días. El viernes 7 de mayo la situación pudo ser controlada por las fuerzas de orden público enviadas por el gobierno de Largo Caballero desde Valencia, ayudadas por militantes del PSUC, aunque la Generalidad pagó el precio de que le fueron retiradas sus competencias sobre orden público. El enfrentamiento en las calles de Barcelona fue relatado por el británico George Orwell en su "Homenaje a Cataluña".

Los sucesos de mayo de 1937 en Barcelona tuvieron una repercusión inmediata en el gobierno de Largo Caballero. La crisis la provocaron el día 13 de mayo los dos ministros comunistas que amenazaron con dimitir si Largo Caballero no dejaba el Ministerio de la Guerra (el PCE especialmente desde la caída de Málaga el 8 de febrero le hacía responsable de las continuas derrotas republicanas), y que disolviera el POUM. En este ataque a Largo Caballero contaban con el apoyo de la fracción socialista de Indalecio Prieto, que controlaba la dirección del PSOE, que como los comunistas querían eliminar del gobierno a las organizaciones sindicales, UGT y CNT, y reconstruir el Frente Popular. Largo Caballero se negó a aceptar las dos condiciones de los comunistas y al no encontrar los apoyos suficientes para su gobierno dimitió el 17 de mayo. El presidente Manuel Azaña, que también estaba en desacuerdo con la presencia de las dos centrales sindicales en el gobierno, nombró a un socialista “prietista”, Juan Negrín, nuevo jefe de gobierno. Al día siguiente el órgano de la CNT "Solidaridad Obrera" declaraba en su editorial: «Se ha constituido un gobierno contrarrevolucionario».

El nuevo gobierno que formó el socialista Juan Negrín en mayo de 1937 respondió al modelo de las coaliciones de Frente Popular: tres ministros socialistas ocupando las posiciones fundamentales (el propio Negrín, que mantuvo la cartera de Hacienda que ya había ostentado en el gobierno de Largo Caballero, Indalecio Prieto, sobre el que recayó toda la responsabilidad en la conducción de la guerra, al ser nombrado al frente del nuevo Ministerio de Defensa, y Julián Zugazagoitia en Gobernación), dos republicanos de izquierda, dos comunistas, uno del PNV y otro de Esquerra Republicana de Catalunya. Según Santos Juliá, detrás de este gobierno estaba Manuel Azaña, que pretendía «un gobierno capaz de defenderse en el interior y de no perder la guerra en el exterior. (...) Con Prieto a cargo de un Ministerio de Defensa unificado, sería posible defenderse; con Negrín en la presidencia, se podían abrigar esperanzas de no perder la guerra en el exterior».

La política del nuevo gobierno tuvo cinco ejes fundamentales, algunos ya iniciados por Largo Caballero: la culminación de la formación del Ejército Popular y el desarrollo de la industria de guerra (lo que llevó al gobierno a trasladarse de Valencia a Barcelona en noviembre de 1937 para, entre otras razones, ""poner en pleno rendimiento la industria de guerra"" catalana); la continuación de la recuperación por el gobierno central de todos los poderes, con la justificación de que la dirección de la guerra así lo reclamaba (fue disuelto el Consejo de Aragón, último baluarte de la CNT; el traslado del gobierno de Valencia a Barcelona para ""asentar definitivamente la autoridad del gobierno en Cataluña"" relegó al gobierno de la Generalidad de Lluís Companys a un papel secundario). mantenimiento del orden público y la seguridad jurídica (con Zugazagoitia en Gobernación e Irujo en Justicia, se redujeron las ejecuciones "extrajudiciales" y las actividades de las "checas", pero en la "desaparición" del líder del POUM el gobierno dejó hacer a los comunistas y a los agentes soviéticos del NKVD); se dieron garantías a la pequeña y mediana propiedad; se intentó cambiar la política de "no-intervención" de Gran Bretaña y Francia por la de mediación en el conflicto, para que presionaran a Alemania e Italia y cesaran en su apoyo a los sublevados, con el objetivo final de alcanzar una "paz negociada", pero no se consiguió nada. El gran derrotado de esta línea política fue el sindicalismo, tanto el de la UGT y como el de la CNT. Por el contrario, los que resultaron más reforzados fueron los comunistas, de ahí la acusación lanzada contra Negrín de ser un "criptocomunista".

Las derrotas de la República en la batalla de Teruel y en la ofensiva de Aragón provocaron la crisis de marzo de 1938. Azaña y Prieto consideraron que lo que había sucedido mostraba que el ejército republicano nunca podría ganar la guerra y que había que negociar una rendición con apoyo franco-británico. Frente a ellos Negrín y los comunistas eran firmes partidarios de continuar resistiendo. La crisis se abrió al intentar Negrín que Prieto cambiara de ministerio (habiendo declarado su convicción de que la guerra estaba perdida, Prieto era el peor de los ministros de Defensa posible), pero Azaña respaldó a Prieto, así como el resto de los republicanos de izquierda y los nacionalistas de Esquerra y del PNV. Sin embargo, estos no consiguieron articular ninguna alternativa a Negrín, y este acabó saliendo reforzado de la crisis, con la consiguiente salida de Prieto del gobierno.

Negrín recompuso el gobierno el 6 de abril y asumió personalmente el Ministerio de Defensa e incorporó al gabinete a los dos sindicatos, UGT y CNT. Además José Giral fue sustituido en el ministerio de Estado por el socialista Julio Álvarez del Vayo. Las posiciones del nuevo gobierno con vistas a unas posibles negociaciones de paz quedaron fijadas en su "Declaración de los 13 puntos", hecha pública en la significativa fecha del 1º de mayo. En ella, "el gobierno anunciaba que sus fines de guerra consistían en asegurar la independencia de España y establecer una República democrática cuya estructuración jurídica y social sería aprobada en referéndum; afirmaba su respeto a la propiedad legítimamente adquirida, la necesidad de una reforma agraria y de una legislación social avanzada, y anunciaba una amplia amnistía para todos los españoles que quieran cooperar a la inmensa labor de reconstrucción y engrandecimiento de España. En su intento de aparecer ante las potencias extranjeras con la situación interior controlada, Negrín inició gestiones infructuosas con el Vaticano para restablecer relaciones diplomáticas y abrir las iglesias al culto".

Negrín era consciente de que la supervivencia de la República no solo dependía del fortalecimiento del Ejército Popular y de que se mantuviera la voluntad de resistencia de la población civil en la retaguardia, sino también de que Francia y Gran Bretaña pusieran fin a la política de "no intervención" o de que al menos presionaran a las potencias fascistas para que estas a su vez convencieran al "Generalísimo" Franco para que aceptara un final negociado. Negrín pensaba que su política era la única posible. Como dijo en privado ""no se puede hacer otra cosa"". Así pues, su idea era resistir para negociar un armisticio que evitara el ""reinado de terror y de venganzas sangrientas"" (las represalias y fusilamientos por parte de los vencedores sobre los vencidos) que Negrín sabía que Franco iba a imponer, como efectivamente acabó sucediendo.

Además Negrín, el general Vicente Rojo Lluch, jefe del Estado Mayor, y los comunistas, creían posible que el ejército republicano aún era capaz de una última ofensiva, que se inició el 24 de julio de 1938, dando comienzo así a la batalla del Ebro, la más larga y decisiva de la Guerra Civil. Pero después de tres meses de duros combates, se produjo una nueva derrota del ejército republicano que tuvo que volver a sus posiciones iniciales, "con decenas de miles de bajas y una pérdida considerable de material de guerra que ya no podría utilizarse para defender Cataluña frente a la decisiva ofensiva franquista".

Poco antes de que finalizara la batalla del Ebro se produjo otro hecho que también fue determinante para la derrota de la República, esta vez procedente del exterior. El 29 de septiembre de 1938 se firmaba el acuerdo de Múnich entre Gran Bretaña y Francia, por un lado, y Alemania e Italia, por otro, que cerraba toda posibilidad de intervención de las potencias democráticas a favor de la República. De las misma forma que ese acuerdo supuso la entrega de Checoslovaquia a Hitler, también supuso abandonar a la República Española a los aliados de nazis y fascistas. De nada sirvió que en un último intento desesperado de obtener la mediación extranjera Negrín anunciara ante la Sociedad de Naciones el 21 de septiembre, una semana antes de que se firmara el acuerdo de Múnich, la retirada unilateral de los combatientes extranjeros que luchaban en la España republicana, aceptando (sin esperar a que los "nacionales" hicieran lo propio) la resolución del Comité de No Intervención que proponía un Plan de retirada de voluntarios extranjeros de la Guerra de España. El 15 de noviembre de 1938, el día de antes del fin de la batalla del Ebro, las Brigadas Internacionales desfilaban como despedida por la avenida Diagonal de Barcelona. En el campo rebelde, por su parte, en octubre de 1938, seguros ya de su superioridad militar y de que la victoria estaba cerca, decidieron reducir en un cuarto las fuerzas italianas.

La última operación militar de la guerra fue la campaña de Cataluña, que acabó en un nuevo desastre para la República. El 26 de enero de 1939 las tropas de Franco entraban en Barcelona prácticamente sin lucha. El 5 de febrero ocupaban Gerona. Cuatro días antes, "el día 1 de febrero de 1939, en las sesiones celebradas por lo que quedaba del Congreso en el castillo de Figueras, [Negrín] redujo los 13 puntos a las tres garantías que su gobierno presentaba a las potencias democráticas como condiciones de paz: independencia de España, que el pueblo español señalara cuál habría de ser su régimen y su destino y que cesara toda persecución y represalia en nombre de "una labor patriótica de reconciliación". Pocos días después, hizo saber a los embajadores francés y británico que estaba dispuesto a ordenar un cese inmediato de las hostilidades si su gobierno obtenía garantías de que no habría represalias. Pero no las recibió".

El día 6 de febrero, las principales autoridades republicanas, encabezadas por el Presidente Azaña, cruzaban la frontera seguidos de un inmenso éxodo de civiles y militares republicanos que marchaban al exilio. El día 9 de febrero hacía lo mismo el presidente del gobierno, Juan Negrín, pero en Toulouse cogió un avión para regresar a Alicante el día 10 de febrero acompañado de algunos ministros con la intención de reactivar la guerra en la zona centro-sur. El único apoyo con el que contaba ya Negrín, además de una parte de su propio partido (el PSOE quedó dividido entre "negrinistas" y "antinegrinistas") eran los comunistas.

La "guerra de España" (como la llamó la prensa internacional) tuvo una repercusión inmediata en las complicadas relaciones internacionales de la segunda mitad de la década de los años treinta. En Europa existía una pugna política, diplomática, ideológica y estratégica a tres bandas entre las potencias democráticas, Gran Bretaña y Francia; las potencias fascistas, la Alemania de Hitler y la Italia de Mussolini; y la Unión Soviética de Stalin; y el "asunto español" fue enfocado por cada Estado europeo desde sus intereses concretos.

Los regímenes fascistas europeos (Alemania e Italia) y el Portugal "salazarista" apoyaron desde el principio a los militares sublevados, mientras que la República, tras negarle su ayuda Francia y Gran Bretaña que optaron por la política de No Intervención, obtuvo el apoyo de la URSS y de las Brigadas Internacionales a partir de octubre de 1936 (también recibió el apoyo casi simbólico de México). Este "apoyo internacional a los dos bandos fue vital para combatir y continuar la guerra en los primeros meses. La ayuda italo-germana permitió a los militares sublevados trasladar el Ejército de África a la península a finales de julio de 1936 y la ayuda soviética contribuyó de modo decisivo a la defensa republicana de Madrid en noviembre de 1936".

Hay un aspecto humanitario de la dimensión internacional de la Guerra Civil que no hay que olvidar: que la mayoría de las embajadas y legaciones extranjeras de Madrid y algunos consulados de capitales de provincia dieron asilo político a miles de españoles de ambos bandos que se encontraban en peligro de muerte.

Gran Bretaña y Francia veían que la "guerra de España" podía complicar aún más el difícil juego estratégico que se desarrollaba a escala europea. Por ello, la primera orientación de la diplomacia de esas potencias fue la de procurar el "aislamiento" del conflicto español. A esa estrategia se debió la política sobre la "No-Intervención" al que se sumaron 27 países de Europa y que dio nacimiento al Comité de No Intervención con sede en Londres.

La "no intervención" estuvo determinada por la política británica de "apaciguamiento" ("appeasement policy") de la Alemania nazi, a la que se vio arrastrado el gobierno del Frente Popular de Francia, que solo contaba con los británicos ante una posible agresión alemana. Además las simpatías del gobierno conservador británico se fueron decantando hacia el bando sublevado, ante en el temor de que España cayera ""en el caos de alguna forma de bolchevismo"" (en palabras del cónsul británico en Barcelona) si ganaba la guerra el bando republicano.

La idea partió del gobierno francés consciente de que ya que no podían ayudar a la República (porque ello supondría abrir un gran conflicto interno en la sociedad francesa y además enturbiaría las relaciones con su aliado "vital", Gran Bretaña), al menos podrían impedir la ayuda a los sublevados. El gobierno británico se sumó enseguida al proyecto, aunque el mismo "ponía en el mismo plano a un Gobierno legal y a un grupo de militares rebeldes".

Pero en la práctica la política de "no intervención" se convirtió en una "farsa", como la calificaron algunos contemporáneos, porque Alemania, Italia y Portugal no suspendieron en absoluto sus envíos de armas y municiones a los sublevados. La República, que a partir de octubre de 1936 comenzó a recibir la ayuda soviética, denunció ante la Sociedad de Naciones la intervención de las potencias fascistas en favor de los sublevados, aunque estas nunca fueron amonestadas.

Ante el fracaso del golpe de estado de julio de 1936 (en cuanto a la toma inmediata del poder), los militares sublevados obtuvieron ayuda rápidamente de la Italia fascista y de la Alemania nazi. Las ayudas en hombres al bando sublevado se materializaron en la Legión Cóndor alemana (unos 6000 hombres) y el Corpo di Truppe Volontarie italiano (un máximo de 40 000), más un contingente de combatientes portugueses denominados Viriatos. Para que no hubiera duda de su compromiso con la causa del bando sublevado, el 18 de noviembre de 1936 (en plena batalla de Madrid), Italia y Alemania reconocieron oficialmente al "Generalísimo" Franco y a su Junta Técnica del Estado como el gobierno legítimo de España. En cuanto a armamento, según Julio Aróstegui, los sublevados recibieron de Italia y de Alemania 1359 aviones, 260 carros de combate, 1730 cañones, fusiles, y municiones para todo ello.

Los combatientes alemanes, italianos y portugueses eran soldados regulares a los que se les proporcionaba una paga en su país de origen, aunque la propaganda de los sublevados siempre los presentó como "voluntarios". Los voluntarios genuinos fueron unos mil o mil quinientos hombres, entre los que destacaron la Brigada Irlandesa del general Eoin O'Duffy, integrada por unos 500-900 efectivos que habían venido a combatir a España para «librar la batalla de la cristiandad contra el comunismo» (aunque solo participaron en la batalla del Jarama y unos meses después volvieron a Irlanda), y 300-500 franceses de la organización ultraderechista Croix-de-feu (luego convertida en el Partido Social Francés) que constituyeron el batallón Jeanne d'Arc. También hay que contar entre los extranjeros que participaron en el bando sublevado a los miles de marroquíes del Protectorado español de Marruecos que fueron enrolados de forma intensiva en las tropas de Regulares del Ejército de África a cambio de una paga.

La razón principal de la ayuda de la Alemania nazi a Franco fue que Hitler consideró que en la "inevitable" guerra europea que iba a estallar en los próximos años sería mejor contar en España con un gobierno favorable encabezado por militares anticomunistas que por uno republicano que reforzaría sus vínculos con Francia (y con su aliada Gran Bretaña) y con la Unión Soviética. En la decisión de Hitler también contaron otros dos factores, uno ideológico (según la propaganda nazi la guerra de España era una confrontación entre "fascistas" y "marxistas", responsabilizando a la Unión Soviética y al "comunismo internacional" de haberla causado) y otro militar (experimentar nuevas armas y nuevas tácticas, lo que se concretó en el despliegue en la zona sublevada de una unidad aérea completa, apoyada por tanques y cañones antiaéreos, denominada la "Legión Cóndor"). Se probaron los cazas Messerschmitt Bf 109 y Junkers Ju 87 A/B y los bombarderos Junkers Ju 52 y Heinkel He 111. Asimismo estrenó en España sus tácticas de bombardeo sobre ciudades. Aunque no fue el único, el más famoso fue el bombardeo de Guernica representado por Picasso en su cuadro "Guernica", expuesto en el pabellón español de la Exposición Universal de París de 1937.
La razón principal de la ayuda de la Italia fascista era ganar un aliado para el proyecto de Mussolini de construir un imperio en el Mediterráneo, y de esa forma debilitar la posición militar de Francia y de Gran Bretaña. También como los nazis utilizó el anticomunismo en su propaganda para justificar la intervención en la guerra civil española.

Aunque menos aireada, la ayuda a los sublevados por parte de la dictadura de Oliveira Salazar de Portugal también fue importante, sobre todo en los primeros meses de la guerra porque dejó que los militares rebeldes utilizaran sus carreteras, ferrocarriles y puertos para comunicar la zona norte con Andalucía, y además devolvió a la zona sublevada a los republicanos que huían de la represión. Después Portugal constituyó una base de operaciones para la compra de armas y además fue un firme aliado de los sublevados en la "farsa" de la "no intervención", a quienes siempre defendió ante el Comité de No Intervención y en la Sociedad de Naciones.

Stalin respondió positivamente a la petición de ayuda formulada por el gobierno republicano, no inmediatamente sino cuando se convenció de que si la República española era derrotada aumentaría el poder de las potencias fascistas en Europa, lo que supondría una amenaza para la Unión Soviética (igual que para Francia, una posible aliada). Así fue como en septiembre de 1936 Stalin decidió enviar material bélico a la República española y ordenó además al Komintern que organizara el envío de voluntarios, que formarían las Brigadas Internacionales. Por las Brigadas pasaron un total aproximado de 40 000 hombres y el material de guerra soviético que la República recibió, cuyos primeros envíos llegaron al puerto de Cartagena a principios de octubre de 1936, fueron 1100 aviones, 300 carros de combate y 1500 cañones (a los que habría que añadir algunas pequeñas partidas francesas, de artillería y aviones, y fusiles y munición mexicanos). Otros autores precisan más las cifras y afirman que la URSS envió 680 aviones (cazas "Chato" y "Mosca" y bombarderos "Katiuska"), 331 carros de combate, 1699 piezas de artillería, 60 coches blindados, 450 000 fusiles Mosin-Nagant, 20 486 ametralladoras y ametralladoras ligeras DP y 30 000 toneladas de munición. Este material de guerra fue acompañado de unos 2000 técnicos, pilotos y asesores militares (y también agentes del NKVD, la policía secreta estalinista, bajo el mando de Alexander Orlov). Asimismo envió combustible, ropa y alimentos, parte de ellos sufragados con donaciones populares. Los soviéticos, como los alemanes y los italianos, probaron armas y tácticas de combate.

Del reclutamiento y de los aspectos organizativos de las Brigadas Internacionales se encargaron dirigentes del Partido Comunista Francés, encabezados por André Marty, y el centro de reclutamiento se estableció en París. La inmensa mayoría de los que se alistaron fueron verdaderamente "voluntarios de la libertad" (como decía la propaganda republicana) llegados desde los países dominados por dictaduras y por el fascismo, como Alemania, Italia o Polonia, pero también de los países democráticos como Francia (que aportó el mayor número de brigadistas, unos 9000), Gran Bretaña y Estados Unidos (con el famoso batallón Lincoln). Por tanto las Brigadas Internacionales no fueron el "Ejército de la Komintern" como aseguraba la propaganda del bando sublevado, instrumento de la política de Stalin. El centro de entrenamiento en España se situó en Albacete y allí se organizaron las cinco brigadas numeradas de la XI a la XV, cuya entrada en combate se produjo en la batalla de Madrid.

México apoyó la causa republicana de forma militar, diplomática y moral: proveyendo a las fuerzas leales de 20 000 rifles, municiones (se habla de un aproximado de 28 millones de cartuchos), 8 baterías, algunos aviones y comida, así como creando asilos para cerca de 25 000 españoles republicanos, dando protección, techo y comida a miles de intelectuales, familias y niños que llegaron al puerto de Veracruz y otros puertos del Golfo de México. Argentina cooperó en la evacuación de asilados hacia Francia con dos buques de la Armada Argentina, el ARA 25 de mayo y el ARA Tucumán.

La República financió la guerra con las reservas de oro del Banco de España que envió a la Unión Soviética (lo que la propaganda franquista llamó el "oro de Moscú"), menos una cuarta parte que fue vendida a Francia. El "oro de Moscú" estaba destinado "al pago del armamento adquirido a Rusia y otros países que hubo de abonarse siempre, mientras que las entregas alemanas e italianas [a los sublevados] eran gratis o con pago diferido en mercancías. Se evalúa el oro salido [hacia Moscú] en 510 toneladas, con un valor de 530 millones de dólares de la época. Hoy sabemos que no hay más "oro de Moscú" que ese, que fue invertido en su totalidad en la compra de armas".

La oportunidad y el acierto de la decisión del gobierno de Largo Caballero de depositar en Moscú la mayor parte de las reservas de oro del Banco de España (a donde llegaron a principios de noviembre de 1936) ha sido objeto de polémica entre los historiadores. Unos afirman, siguiendo fundamentalmente las investigaciones de Ángel Viñas, que el gobierno republicano no tenía otra opción, debido a la hostilidad que habían mostrado hacia la República los bancos de Gran Bretaña y Francia, por lo que la Unión Soviética era la única que garantizaba armamento y alimento a cambio de oro. Por el contrario Pablo Martín-Aceña, un investigador especializado en la financiación de la Guerra Civil, cree que el gobierno de la República decidió con precipitación antes de haber explorado otras opciones, como Francia e incluso Estados Unidos.

La propaganda franquista dijo que el oro del Banco de España (al que llamó el "oro de Moscú") había sido robado por la República y entregado a Stalin sin contrapartidas, pero las investigaciones de Ángel Viñas han demostrado que el "oro de Moscú" se gastó en su totalidad en compras de material bélico. Por su parte el Banco de Francia adquirió 174 toneladas de oro, una cuarta parte del total de las reservas, por las que pagó a la Hacienda republicana 195 millones de dólares. En total, entre el "oro de Moscú" (tres cuartas partes de las reservas del Banco de España) y el "oro de París" (una cuarta parte, del que la propaganda franquista nunca habló) las autoridades republicanas obtuvieron 714 millones de dólares que fue el coste financiero de la Guerra Civil para la República. En Rusia no quedó nada del oro español y las reservas estaban prácticamente agotadas en el verano de 1938. El problema fue que debido a la política de "no intervención" en muchas ocasiones los emisarios de la República fueron estafados por los traficantes de armas que les vendieron equipos obsoletos a precios mucho mayores del coste real. Los gobiernos republicanos también fueron estafados por la propia Unión Soviética, como ha señalado Gerald Howson, o por Polonia y otros países que abusaron de la precaria situación republicana para venderles "chatarra bélica".

Por su parte el bando sublevado, como no contaba con oro, sufragó la mayor parte del coste de la guerra (unos 700 millones de dólares, una cantidad similar a la gastada por la República) mediante créditos obtenidos de Italia y de Alemania. La Alemania nazi se cobró una parte del material de guerra que suministró "en especie" (un sistema ideado por Hermann Goering) con alimentos, materias y primas y minerales españoles que llegaban a Alemania a través de dos compañías creadas con tal fin. Algo parecido ocurrió con Italia, por lo que las dos potencias fascistas sustituyeron a Francia y Gran Bretaña como los primeros clientes comerciales de España. Asimismo los sublevados también obtuvieron ayuda económica y financiera de empresas y hombres de negocios de Gran Bretaña, Francia y Estados Unidos, especialmente de aquellos que más simpatizaban con la "causa nacional" (por ejemplo, las empresas norteamericanas y británicas Texaco y Shell les vendieron a crédito petróleo durante toda la guerra). El bando sublevado también recibió ayuda financiera de españoles ricos como Juan March, que aportó 15 millones de libras esterlinas, o del exrey Alfonso XIII, que donó 10 millones de dólares.

Aunque la motivación religiosa no aparece en ninguno de los bandos de pronunciamiento del golpe de estado en España de julio de 1936, la conversión del golpe de estado en una “cruzada” o “guerra santa” en defensa de la religión, se produjo rápidamente, lo que resultó muy oportuno para legitimar el golpe militar. Esta sacralización de la guerra se acentuó sobre todo cuando comenzaron a llegar a la zona sublevada las primeras noticias de la salvaje persecución religiosa que se había desencadenado en la zona republicana, donde el alzamiento militar había fracasado. José María Pemán, uno de los principales ideólogos del bando sublevado escribió: “"el humo del incienso y el humo del cañón, que sube hasta las plantas de Dios, son una misma voluntad vertical de afirmar una fe y sobre ella salvar un mundo y restaurar una civilización"”.

La mayoría de los obispos españoles esperaron a que el Vaticano se pronunciara antes de hacer pública su visión de la guerra, pero esto no ocurrió hasta el 14 de septiembre de 1936 cuando el papa Pío XI pronunció el discurso “"La vostra presenza"” en su residencia veraniega de Castelgandolfo en una audiencia pública a un grupo de unos 500 católicos españoles que habían conseguido huir de la zona republicana, muchos de ellos gracias a la ayuda de las autoridades republicanas, especialmente de la Generalidad de Cataluña. Pero en el discurso el Papa no utilizó el término de “cruzada” para referirse al conflicto bélico en España sino el de “Guerra Civil” “"entre los hijos del mismo pueblo, de la misma madre patria"” e hizo una exhortación final a amar a los enemigos. De hecho en la zona sublevada del discurso solo se publicaron aquellos párrafos que parecían ratificar la condición de cruzada de la guerra civil y se suprimió toda la segunda parte en que se exhortaba a amar a los enemigos. Los obispos españoles, que al principio solo conocieron el discurso de Pío XI en esta versión propagandística, hicieron públicas inmediatamente encendidas pastorales a favor de los sublevados, entre las que destacó la del obispo de Salamanca Enrique Pla y Deniel publicada el 30 de septiembre de 1936, solo un día antes de que el general Franco fuera proclamado “Generalísmo” y “Jefe del Gobierno del Estado”, bajo el título “Las dos ciudades” y en la que declaraba la guerra como una “cruzada por la religión, la patria y la civilización” (cuando Pla y Deniel conoció la versión completa no se retractó en absoluto de su pastoral, como tampoco lo hicieron el resto de obispos). De esta forma "Franco contó con el apoyo y bendición de la Iglesia católica". En el mismo sentido se expresó el cardenal Isidro Gomá, arzobispo de Toledo y primado de España:
Se planteó un grave problema para la idea de "cruzada" defendida por el bando sublevado cuando el Partido Nacionalista Vasco (PNV), un partido católico, permaneció fiel a la República (por lo que en el País Vasco republicano, que comprendía Vizcaya y Guipúzcoa, no hubo persecución religiosa, ninguna iglesia fue incendiada ni clausurada y el culto católico se desarrolló con normalidad), lo que echaba por tierra la concepción de la Guerra Civil como una "cruzada". Por eso el 6 de agosto de 1936, solo tres semanas después del golpe de julio, el obispo de Vitoria (cuya diócesis abarcaba entonces también Vizcaya y Guipúzcoa, además de Álava) Mateo Múgica y el obispo de Pamplona Marcelino Olaechea, publicaron conjuntamente una "Instrucción Pastoral" (que en realidad había sido escrita por el cardenal primado de Toledo Isidro Gomá) en la que instaban a los nacionalistas vascos a que pusieran fin a su colaboración con la República. En la "instrucción pastoral", y en otros escritos posteriores del cardenal Gomá sobre la "cuestión vasca", se hace referencia a los sacerdotes asesinados en las primeras semanas de la guerra por los "nacionales", y no por los "rojos", y cuya muerte en cierta forma justifica por ser "separatistas". El asesinato de estos sacerdotes motivó las protestas del obispo de Vitoria Mateo Múgica Urrestarazu que fue respondida por la Junta de Defensa Nacional con la exigencia al Vaticano de que fuera destituido de su obispado y abandonara España, a pesar de haber apoyado el "alzamiento" (el 14 de octubre de 1936 el obispo Múgica salió camino del exilio). Esta "cuestión vasca" reapareció cuando el País Vasco republicano fue ocupado por los "nacionales" en junio de 1937, a causa de que la represión también incluyó a numerosos sacerdotes vascos "separatistas" que fueron encarcelados por el delito de "rebelión".

Dos meses después se hizo pública la Carta colectiva de los obispos españoles con motivo de la guerra en España que fue redactada por el cardenal primado de Toledo Isidro Gomá a instancias del "Generalísimo" Francisco Franco que le pidió el 10 de mayo de 1937 que, dado que el episcopado español le apoyaba, publicara «un escrito que, dirigido al episcopado de todo el mundo, con ruego de que procure su reproducción en la prensa católica, pueda llegar a poner la verdad en su punto». La "verdad" que pretendía el general Franco que se difundiera en este documento estaba destinada a contrarrestar la condena hecha por amplios sectores del catolicismo europeo y americano más avanzado de los asesinatos cometidos por los "nacionales" de catorce sacerdotes en el País Vasco y de miles de obreros y campesinos en toda la zona sublevada, además de su rechazo a considerar a la guerra civil española como una cruzada o guerra santa.

El objetivo que perseguía Franco con la carta colectiva de ganarse a la opinión católica mundial en favor de la causa del bando sublevado lo logró plenamente porque prácticamente los obispos de todo el mundo adoptaron a partir de entonces el punto de vista sobre la guerra civil española que manifestaba la carta colectiva, sobre todo por la descripción que se hacía en ella de la persecución religiosa que se había desencadenado en la zona republicana. Sin embargo, cinco obispos no la suscribieron. Entre ellos se encontraba el obispo exiliado de Vitoria Mateo Múgica Urrestarazu que «no podía firmar un documento en el que, respondiendo a la acusación de que en la zona franquista también había una dura represión, se elogiaban los principios de justicia y el modo de aplicarla de los tribunales militares». Tampoco la firmó el cardenal Vidal y Barraquer, que era sin duda el caso más significativo de los cinco porque se trataba tal vez de la figura más destacada de aquel momento de la Iglesia Católica en España. La negativa a firmar la carta se basó en que él "creía que en aquella guerra fratricida la Iglesia no debía identificarse con ninguno de los dos bandos, sino más bien hacer obra de pacificación".

El Vaticano anunció que iba a reconocer plenamente al bando sublevado, en medio del derrumbe del frente de Aragón de la primavera de 1938, cuando comunicó que iba nombrar un nuncio que sustituiría al "delegado papal" Ildebrando Antoniutti, que desde julio de 1937 había detentado la representación pontificia ante el generalísimo Franco. El designado por el papa Pío XI fue monseñor Gaetano Cicognani. Presentó sus cartas credenciales a Franco el 24 de mayo, y un mes después, el 30 de junio, hacía lo mismo "en solemnes audiencia" ante Pío XI el embajador de la "España nacional" ante el Vaticano, José Yanguas Messía.

Cuando se produjo el triunfo de los "nacionales" en la guerra, la «Iglesia española, que se había adherido masivamente al alzamiento, se volcó con entusiasmo en las fiestas de la victoria sobre la otra media. Y la misma Santa Sede, que durante la mayor parte del conflicto se había mostrado tan reticiente, al final se sumó también a las celebraciones». El 1 de abril de 1939, el mismo día en que Franco emitió el famoso «último parte» en el que proclamaba «la guerra ha terminado», el papa Pío XII (el cardenal Pacelli que el día 2 de marzo había sido nombrado papa tras la muerte de Pío XI) felicitaba telegráficamente a Franco por su «victoria católica»: Dos semanas después, el 16 de abril de 1939, Radio Vaticano difundió un mensaje leído por el propio papa Pío XII que decía:
El 20 de mayo de 1939, un mes después del "desfile de la Victoria" presidido en Madrid por Franco, tuvo lugar en la Iglesia de Santa Bárbara de Madrid) una ceremonia político-religiosa "medievalizante que quería representar en forma de drama sacro la ideología de la guerra santa que acababa de concluir" en la que el general Franco con uniforme de capitán general, camisa azul (de Falange) y boina roja (de los requetés) acompañado de su esposa entró bajo palio en el templo (mientras el órgano hacía sonar el himno nacional) donde ofrendó la espada de la victoria a Dios. A continuación el cardenal Gomá, que presidía la ceremonia acompañado de diecinueve obispos (y en presencia del nuncio del Vaticano monseñor Cicognani), bendijo al «caudillo» hincado de rodillas ante él:
Sobre todo durante los primeros meses de la guerra en la zona republicana se desató una salvaje persecución religiosa con asesinatos, incendios y saqueos cuyos autores fueron "los extremistas, los incontrolados y los delincuentes comunes salidos de las cárceles que se les sumaron", todo ello inmerso en la ola de violencia desatada contra las personas y las instituciones que representaban el "orden burgués" que quería destruir la revolución social española de 1936 que se produjo en la zona donde el alzamiento militar fracasó. "Durante varios meses bastaba que alguien fuera identificado como sacerdote, religioso o simplemente cristiano militante, miembro de alguna organización apostólica o piadosa para que fuera ejecutado sin proceso".

En cuanto al número de víctimas un folleto de propaganda franquista editado en París en 1937 cifró el número en 16750 sacerdotes y el 80% de los miembros de las órdenes religiosas. Estas cifras se mantuvieron como las oficiales durante las dos primeras décadas de la dictadura franquista hasta que en 1961 el sacerdote Antonio Montero Moreno (que después sería obispo de Badajoz) publicó el único estudio sistemático y serio que se ha realizado hasta ahora, citando por sus nombres a las víctimas. Según ese estudio titulado "Historia de la persecución religiosa en España 1936-1939" fueron asesinados en la zona republicana 12 obispos, 4184 sacerdotes seculares, 2365 religiosos y 263 monjas. Queda pendiente conocer el número de los seglares católicos que fueron asesinados no por lo que supuestamente hubieran hecho individualmente sino por pertenecer a una asociación confesional católica o meramente por ser católicos practicantes.

Lo que las investigaciones posteriores a la de Montero Moreno han aclarado es que el mayor número de asesinatos se produjo entre julio y septiembre de 1936 cuando los miembros del clero eran apresados y ejecutados sin ningún tipo de juicio. A partir de la última fecha comenzaron a funcionar los tribunales populares bajo el impulso del nuevo gobierno de Largo Caballero que dieron unas mínimas garantías jurídicas a los detenidos y las condenas solían acabar con penas de prisión y no con la muerte. Tras los sucesos de mayo de 1937 y la formación del gobierno de Juan Negrín en el que el ministerio de justicia fue ocupado por el católico del PNV Manuel de Irujo cesaron completamente los asesinatos y la mayoría de los sacerdotes que estaban en prisión fueron puestos en libertad. Sin embargo, la prohibición del culto público católico continuó así como otras medidas revolucionarias. solo al final de la guerra con la desbandada del ejército republicano hacia la frontera francesa volvieron a producirse nuevas víctimas entre los miembros del clero, entre las que destaca el obispo de Teruel Anselmo Polanco Fontecha. Así pues, según el historiador y monje benedictino Hilari Raguer, "no se puede negar la trágica realidad de las matanzas del verano del 36, pero es confusionario pretender que el terror hubiera durado hasta el final de la guerra".

Las autoridades republicanas (especialmente los gobiernos autónomos de Cataluña y del País Vasco) intentaron evitar los asesinatos de sacerdotes y religiosos, y en general de las personas de derechas y de militares. En el País Vasco el gobierno de José Antonio Aguirre consiguió dominar la situación y allí no hubo persecución religiosa. En Cataluña, a pesar de que el poder efectivo lo tenían los cientos de comités revolucionarios fundamentalmente anarquistas que habían surgido tras la derrota de la sublevación del 19 de julio, la Generalidad presidida por Lluís Companys consiguió poner a salvo a miles de personas de derechas amenazadas, y entre ellas numerosos sacerdotes (empezando por la cabeza de la Iglesia en Cataluña, el arzobispo de Tarragona cardenal Vidal y Barraquer que había sido detenido por un grupo de milicianos) y religiosos (entre ellos 2142 monjas), concediéndoles pasaportes y fletando barcos franceses e italianos para que pudieran huir al extranjero, aunque no pudo evitar que cientos de ellos fueran ejecutados por ser católicos.

Sin embargo, a pesar de todas estas iniciativas, la Iglesia y el culto católico en la zona republicana, excepto en el País Vasco, habían desaparecido. En un informe interno presentado ante el Consejo de Ministros el 7 de enero de 1937 el ministro católico sin cartera del PNV Manuel Irujo denunció que en el «territorio leal» «todas las iglesias se han cerrado al culto, el cual ha quedado total y absolutamente suspendido». Asimismo, afirmaba Irujo, «todos los conventos han sido desalojados y suspendida la vida religiosa en los mismos» y «sus edificios, objetos de culto y bienes de todas clases fueron incendiados, saqueados, ocupados o derruidos». «Sacerdotes y religiosos han sido detenidos, sometidos a prisión y fusilados sin formación de causa por miles, hechos que, si bien amenguados, continúan aún». Acabado su informe Irujo pidió al resto de miembros del gobierno de Largo Caballero que aprobaran el restablecimiento de la libertad de conciencia y de la libertad de cultos reconocida en la vigente Constitución de 1931, pero su propuesta fue rechazada por unanimidad por entender que la opinión pública lo desaprobaría debido al alineamiento de la Iglesia católica con el bando sublevado, además de aducir el viejo (y falso) argumento, pero muy extendido, de que desde los templos se había disparado contra las fuerzas leales y contra "el pueblo".

La excepción la constituyó el País Vasco republicano pues allí no hubo persecución religiosa y el culto católico se desarrolló con normalidad. La razón fue que el Partido Nacionalista Vasco (PNV), un partido católico, permaneció fiel a la República.

En el gobierno que formó el socialista Juan Negrín tras los sucesos de mayo de 1937 el católico y nacionalista vasco Manuel Irujo ocupó el ministerio de Justicia que era el departamento que tradicionalmente en España se ocupaba de los asuntos religiosos. El encargo que recibió Irujo de Negrín fue que intentara normalizar la vida religiosa en la zona republicana. El primer fruto de la nueva política fue la tolerancia al culto doméstico por lo que las misas celebradas en casas particulares ya no fueron perseguidas ni, con algunas pocas excepciones, daban lugar a detenciones, a pesar de que en ocasiones se convertían en reuniones favorables a los sublevados.

En cuanto al restablecimiento del culto público el gobierno se encontró con la rotunda oposición de los anarquistas, por un lado, y, por otro, por la de algunos católicos republicanos y de las autoridades eclesiásticas que pensaban que las iglesias no se podían reabrir sin más olvidando los asesinatos y los incendios de los primeros meses de la guerra, además de que todo ello se podría convertir en un instrumento de la propaganda republicana. El gobierno llegó a enviar en secreto a Roma a un eclesiástico para que hiciera saber al Vaticano su propósito de normalizar la vida eclesiástica y reconciliarse con la Iglesia. Pero la respuesta del Vaticano fue evasiva sin comprometerse en nada.

Un nuevo gesto de reconciliación con la Iglesia se produjo el 17 de octubre de 1938 cuando cuatro ministros del gobierno presidieron el entierro católico del oficial vasco capitán Vicente Eguía Sagarduy muerto en combate, al que se le dio gran publicidad en la prensa y que tuvo gran impacto a nivel internacional. El paso siguiente fue la creación el 8 de diciembre de 1938 del Comisariado de Cultos de la República encargado de proteger la libertad religiosa y de cultos, al frente del cual Negrín nombró a un colega católico y amigo suyo Jesús María Bellido Golferichs, que aceptó el cargo "cumpliendo un deber de católico". Pero el culto público no tuvo tiempo para ser restablecido a causa de la ofensiva de Cataluña que lanzó el "Generalísimo Franco" el 23 de diciembre de 1938 y que en solo mes y medio ocupó toda Cataluña. Así pues, la reapertura de los templos católicos en Cataluña no fue obra de la República sino que la trajeron las tropas de Franco (cuando ya se habían hecho los preparativos para reabrir al culto una de las capillas de la catedral de Tarragona, los "nacionales" entraron en la ciudad el 15 de enero).

Durante los primeros días, unas 50000 personas que quedaron atrapadas en el bando contrario fueron ejecutadas mediante los llamados "paseos". Estos eran realizados por grupos armados que iban a buscar a la gente a sus casas o las cárceles donde se hallaban presos y bajo el eufemismo de "vamos a dar un paseo" los llevaban a cualquier carretera o a las tapias del cementerio y los ejecutaban.

Posiblemente el más divulgado de tales ajusticiamientos entre los llevados a cabo por el bando sublevado, debido a la relevancia del protagonista, sea el del poeta y dramaturgo Federico García Lorca en el barranco de Víznar en Granada. También adquirió gran relevancia la masacre de Badajoz, perpetrada por las tropas sublevadas tras la toma de la ciudad.

Por parte del bando republicano la mayor serie de asesinatos masivos fueron las Matanzas de Paracuellos entre el 7 de noviembre y el 4 de diciembre de 1936, sacas de los presos de las cárceles de Madrid (entre los que se encontraba el dramaturgo Pedro Muñoz Seca junto otras personas, intelectuales, religiosos, políticos y militares) y asesinados, la mayoría, en la localidad de Paracuellos de Jarama.

En el contexto de la guerra fueron muchos los que se aprovecharon para realizar tan macabros actos, a veces por venganza sin relación con la propia contienda, y cuando una zona caía en manos de uno u otro bando, no tardaban en llegar los "paseos". Especialmente cruel para la población fue el caso de las localidades que fueron intermitentemente ocupadas por ambos bandos, con las consiguientes y repetidas ejecuciones y venganzas.

En la zona bajo control de la República, los enfrentamientos entre milicias y facciones opuestas también sirvieron de coartada a episodios de represión sangrientos, como en el caso de las jornadas de mayo de 1937 en Barcelona, narradas por el escritor inglés George Orwell en su obra "Homenaje a Cataluña", basada en su experiencia de primera mano.

El militar Ramón Salas Larrazábal estudió las cifras de víctimas que pudieron morir en estas retaguardias. Consideró, según sus estudios que todas las víctimas fueron inscritas en los Registros Civiles, haciendo un cálculo aproximado de las muertes de la Guerra. En el , se puede ver un resumen de sus conclusiones. Sin embargo en estudios posteriores, y por ejemplo, en Navarra que el consideraba lugar "testigo", se ha podido comprobar que las víctimas de la represión eran muy superiores a las cifras que él había calculado.

Terminada la guerra, el bando republicano fue acusado por el bando sublevado de la comisión de crímenes desde los primeros días de la guerra. Las principales acusaciones se refieren a la persecución religiosa contra los católicos, la creación de centros de detención semiclandestinos (checas) donde se torturaba y asesinaba a los sospechosos de simpatizar con el bando contrario y la realización de asesinatos masivos como las matanzas de la Cárcel Modelo de Madrid y de Paracuellos. El régimen franquista promovió una extensa investigación sobre estos hechos conocida como Causa General que, pese a haber sido realizada con parcialidad y sin las suficientes garantías procesales, contó con abundantes pruebas documentales y testificales.

Por su parte, los delitos de los vencedores nunca fueron investigados ni enjuiciados. Numerosas voces del ámbito jurídico como Baltasar Garzón (exmagistrado español de la Audiencia Nacional), Carlos Jiménez Villarejo (fundador de la asociación Justicia Democrática), Raúl Zaffaroni (penalista y magistrado de la Corte Suprema de Argentina), así como diversas asociaciones de víctimas del franquismo y otros, sostienen que el bando sublevado cometió actos de genocidio y crímenes contra la humanidad, ya que en la documentación ahora disponible, como los archivos militares de la época, se demostraría que sus planes incluyeron el exterminio y persecución sistemática de la oposición política, la violación de las mujeres de la zona republicana, la imposición de tests físicos y psicológicos a presos para vincular su ideología con enfermedades mentales o el robo sistemático de niños a padres republicanos para eliminar la "contaminación" ideológica, a los que todavía se oculta su verdadera identidad.

Por considerar que dichos actos, por su naturaleza de crímenes contra la humanidad no pueden prescribir ni ser absueltos, el magistrado-juez Baltasar Garzón inició un proceso para investigar los hechos, basándose en el que ya había impulsado infructuosamente contra el exdictador chileno Augusto Pinochet, afirmando que no se buscaba «hacer una revisión en sede judicial de la Guerra Civil». Entre otras consideraciones, argumentó la acusación de genocidio de acuerdo con el derecho español, citando al auto 211/2008 del Juzgado Central de Instrucción número dos (caso SS-Totenkopf o Genocidio nazi), mediante el cual se consideraba delitos de genocidio y lesa humanidad los cometidos contra los españoles recluidos en los campos de concentración nazis con motivaciones políticas o ideológicas. La Audiencia Nacional decidió por mayoría de votos y sin hacer ninguna valoración acerca del carácter delictivo de los hechos denunciados, que el Juzgado Central de Instrucción número cinco dirigido por Garzón carecía de competencia objetiva para investigarlos, al considerar extinguida la posible responsabilidad penal de a causa de su fallecimiento. Los magistrados discrepantes consideraron que el juzgado sí era competente al ser los hechos investigados «delitos de lesa humanidad y genocidio», por constituir una «sistemática y masiva eliminación de adversarios políticos» tras la contienda.

El pago del gasto de la guerra por ambos bandos fue muy elevado. El haber usado el gobierno republicano las reservas de oro para comprar armamento acabó con las reservas monetarias de la zona republicana. El bando sublevado tuvo que abonar mucho dinero tras finalizar el conflicto, en gran parte dejando que Alemania explotara las reservas mineras de la península y del África Española del momento, por lo que hasta el estallido de la Segunda Guerra Mundial casi no tuvieron posibilidad alguna de obtener ingresos. España había quedado devastada en algunas zonas, con pueblos totalmente asolados. La economía española tardaría décadas en recuperarse.

El número de víctimas civiles aún se discute. Algunos afirman exageradamente que la cifra se situaría entre 500 000 y 1 000 000 de personas. Muchas de estas muertes no fueron debidas a los combates, sino a la represión en forma de ejecuciones sumarias y "paseos". Esta se llevó a cabo en el bando sublevado de manera sistemática y por orden de sus superiores, mientras en el bando republicano se produjo de manera descontrolada en momentos en que el gobierno perdió el control de las masas armadas. Los abusos se centraron en todos aquellos sospechosos de simpatizar con el bando contrario. En el bando sublevado se persiguió principalmente a sindicalistas y políticos republicanos (tanto de izquierdas como de derechas), mientras en el bando republicano esta represión se dirigió hacia simpatizantes de la reacción o sospechosos de serlo y sacerdotes de la Iglesia católica, llegando a quemar conventos e iglesias y asesinando a obispos, sacerdotes, religiosos y religiosas. Es incalculable la pérdida en el patrimonio histórico y artístico de la Iglesia católica, pues se destruyeron unos 20 000 edificios —entre ellos varias catedrales— incluyendo su ornamentación (retablos e imágenes) y archivos.

El número de muertos en la guerra civil española solo puede ser estimado de manera aproximada. El bando sublevado estableció una cifra de 500 000, incluyendo además de los muertos en combate, a las víctimas de bombardeos, ejecuciones y asesinatos. Estimaciones recientes arrojan esa misma cifra de 500 000 muertos o algo menos, sin incluir a quienes murieron de malnutrición, hambre y enfermedades engendradas por la guerra. La cifra de un millón de muertos, a veces citada, procede de una novela de Gironella, que la justifica entre los 500000 reconocidos y otros tantos cuya vida resultó irremediablemente destrozada.

Tras la guerra, la represión franquista inició un proceso represivo contra el bando perdedor, iniciándose una limpieza de la que fue llamada "La España Roja" y contra cualquier elemento relacionado con la República, lo que condujo a muchos al exilio o la muerte, produciéndose el robo de bebés de padres republicanos, que aún a día de hoy desconocen, en muchos casos, su identidad. Durante ese tiempo, hablar de democracia, república o marxismo era ilegal y perseguible.

El exilio forzoso de muchos represaliados antes, durante y después de la guerra es difícil de cuantificar. Según su situación geográfica y sus preferencias políticas se optó entre salir por mar, cruzando el océano para pasar a países sudamericanos en su mayoría o el mar los más pudientes para ir a Inglaterra o Francia. O por tierra cruzando los Pirineos al lado galo, país que muchos eligieron por su cercanía con España y su creencia de buena acogida, demostrándose su error con hechos como los campos de concentración de Bram.

El exilio republicano se produjo en tres momentos. El primero fue la campaña del Norte (marzo a noviembre de 1937). El segundo, la caída de Cataluña (enero a febrero de 1939), durante la cual pasaron a Francia alrededor de 400 000 personas (una cantidad tan importante que desbordó a las autoridades francesas, que tuvieron que improvisar diversos campos de concentración, incluso en las playas, donde los recluidos padecieron unas duras condiciones de vida; aunque casi la mitad de ellas acabarían retornando a España. La tercera y última oleada se produjo al final de la guerra, en los últimos días de marzo de 1939, cuando miles de republicanos se dirigieron a los puertos de Levante para conseguir un barco que los llevara al exilio, pero muy pocos lo consiguieron. Se calcula que en el mes de marzo de 1939 solo pudieron abandonar España entre 7000 y 7500 personas, incluidos los marinos de la dotación de la Flota que huyó a Bizerta.

Entre los exiliados se encontraba una parte significativa de las élites intelectuales españolas que buscaron acomodo en otros países, especialmente en México, lo que supuso una enorme pérdida de capital humano para España. Así por ejemplo, "en febrero de 1942 el consulado general de México en Vichy censó a 13 400 españoles de formación superior que deseaban salir de la Francia ocupada; entre ellos 1743 médicos, 1224 abogados, 431 ingenieros y 163 profesores de los 430 que poseía España en 1936".

Las repercusiones políticas y emocionales de la guerra trascendieron de lo que es un conflicto nacional, ya que, por muchos otros países, la Guerra Civil española fue vista como parte de un conflicto internacional que se libraba entre la religión y el ateísmo, la revolución y el fascismo. Para la URSS, Alemania e Italia, España fue terreno de prueba de nuevos métodos de guerra aérea y de carros de combate. Para Gran Bretaña y Francia, el conflicto representó una nueva amenaza al equilibrio internacional que trataban dificultosamente de preservar, el cual se derrumbó en 1939 (pocos meses después del fin de la guerra española) con la Segunda Guerra Mundial. El pacto de Alemania con la Unión Soviética supuso el fin del interés de esta en mantener su presión revolucionaria en el sur de Europa.

En cuanto a la política exterior, la GCE supuso el aislamiento de España y la retirada de embajadores de casi todo el mundo. Solo unos pocos países mantuvieron relaciones diplomáticas con España desde el final de la II Guerra Mundial hasta el inicio de la Guerra Fría. A partir de los años 50, las relaciones internacionales españolas, con el apoyo de EE. UU., pasan a ser casi normales, salvo con los países del Bloque Soviético.

Durante la guerra civil española de 1936 a 1939, muchos pueblos y ciudades resultaron total o parcialmente destruidos. Una vez finalizada la guerra, se constituyó la Dirección General de Regiones Devastadas que asumió la función de reconstruirlos.

Entre muchas poblaciones devastadas, se encontraron las siguientes:

En 2007 el gobierno español aprobó la Ley de Memoria Histórica, que intenta restaurar la memoria y dignidad de los represaliados. Esta incluye renombrar vías públicas con nombres franquistas, eliminación de símbolos falangistas de monumentos, mapas de fosas comunes y exhumación de cadáveres, etc.

Igualmente, otras administraciones económicas han actuado en la misma línea, llegando a pronunciarse a favor la ONU.

El tema de la Guerra Civil es el de mayor producción literaria de toda la historiografía española, así como el más polémico y generador de debate social y político (véase memoria histórica). Aunque hay un acuerdo casi unánime en las fechas, los denominados "revisionistas" próximos al franquismo, proponen la revolución de 1934 como inicio de la guerra. La propia declaración del "estado de guerra" fue divergente en ambos bandos: el gobierno republicano no declaró el estado de guerra hasta casi su final (para mantener el control civil de todas las instituciones), mientras que el gobierno de Franco no levantó la declaración hasta varios años después de terminada (para garantizar su control militar).

"Véase "

Realizadas durante la propia guerra, aunque también hubo películas de ficción (las republicanas "Aurora de esperanza" —Antonio Sau, Barcelona, 1937—, "Barrios bajos" —Pedro Puche, Barcelona, 1937— y "Nuestro culpable" —Fernando Mignoni, 1938— y cinco películas "nacionales" de Benito Perojo y Florián Rey rodadas en los estudios alemanes de la UFA, de género folclórico —ambiente reconstruido en "La niña de tus ojos", Fernando Trueba, 1998—), fueron fundamentalmente de género documental:

Bando republicano:
Bando sublevado:
Durante el franquismo (hasta 1975):
Desde 1975:
Ficción:
Documental:

Muchos de los cuentos basados en la Guerra Civil española son, según Ignacio Martínez de Pisón, «relatos concebidos desde el compromiso explícito con uno u otro bando»... los autores de algunos de esos relatos colaboraron muy activamente en labores de propaganda: Arturo Barea y María Teresa León para la España republicana; Edgar Neville, José María Pemán o Agustín de Foxá para la nacional. Sin duda, en el fragor de la contienda fueron muchos los escritores que se adaptaron a la situación de emergencia y alteraron su sistema de prioridades: contribuir a la victoria bélica, aunque fuera con algo tan modesto como una narración o un poema, estaría siempre por encima de cualquier otra consideración».

A pesar de lo comprometido del tema, hay tratamiento del mismo en la literatura infantil y juvenil.

Bando sublevado:
Algunas obras teatrales eran radiadas, como "Miaja defiende la Villa y rinde culto a Zorrilla" (Joaquín Pérez Madrigal, por Radio Nacional desde Salamanca).

La obra en Árabe 'Yusuf Melik Ispaniya' يوسف ملك إسبانيا(Yusuf Rey de España) (de Alí Al Tuma علي عدنان آل طعمة - Sharjah/Emiratos Árabes, 2015) trata de las aventuras de un Regular durante el conflicto español. Engañado por sus hermanos, Yusuf emprende escapar del ejército y de España. Es herido durante una batalla, se implica en una relación prohibida con una española, encarcelado, rehabilitado y llega a ser sargento en la policía militar y vengarse la injusticia a la que le sometieron sus hermanos. La obra trata de temas de religión, propaganda de guerra, el orden colonial y relaciones interculturales. Ganó el 'Premio de Sharjah por la Creatividad Árabe' del año 2015.

Bando republicano:

Posteriores a 1975:

Bando sublevado
Bando republicano

Bando republicano

Bando sublevado
Bando republicano

Bando sublevado

Bando republicano

En la democracia

La Exposición Internacional de París de 1937 alojó un "Pabellón de España" gestionado por el gobierno de la República en que, entre otros testimonios de la guerra, se presentó el "Guernica" de Pablo Picasso, la "Fuente de Mercurio" de Alexander Calder, "La Montserrat" de Julio González, "El campesino catalán en rebeldía" de Joan Miró, "Descubierta" y "Fusilados" de Modesto Ciruelos, "Aviones Negros" de Horacio Ferrer o "El pueblo español tiene un destino que conduce a una estrella" de Alberto Sánchez Pérez.

Bando sublevado:
Bando republicano


Algunos videojuegos cubren combates de la guerra civil española:

<div class="listaref references-small" style="-moz-column-count:2"></div class>





</doc>
<doc id="1366" url="https://es.wikipedia.org/wiki?curid=1366" title="HTML">
HTML

El lenguaje HTML basa su filosofía de desarrollo en la diferenciación. Para añadir un elemento externo a la página (imagen, vídeo, "script", entre otros.), este no se incrusta directamente en el código de la página, sino que se hace una referencia a la ubicación de dicho elemento mediante texto. De este modo, la página web contiene solamente texto mientras que recae en el navegador web (interpretador del código) la tarea de unir todos los elementos y visualizar la página final. Al ser un estándar, HTML busca ser un lenguaje que permita que cualquier página web escrita en una determinada versión, pueda ser interpretada de la misma forma (estándar) por cualquier navegador web actualizado.

Sin embargo, a lo largo de sus diferentes versiones, se han incorporado y suprimido diversas características, con el fin de hacerlo más eficiente y facilitar el desarrollo de páginas web compatibles con distintos navegadores y plataformas (PC de escritorio, portátiles, teléfonos inteligentes, tabletas, vipers etc.) No obstante, para interpretar correctamente una nueva versión de HTML, los desarrolladores de navegadores web deben incorporar estos cambios y el usuario debe ser capaz de usar la nueva versión del navegador con los cambios incorporados. Normalmente los cambios son aplicados mediante parches de actualización automática (Firefox, Chrome) u ofreciendo una nueva versión del navegador con todos los cambios incorporados, en un sitio web de descarga oficial (Internet Explorer). Por lo que un navegador desactualizado no será capaz de interpretar correctamente una página web escrita en una versión de HTML superior a la que pueda interpretar, lo que obliga muchas veces a los desarrolladores a aplicar técnicas y cambios que permitan corregir problemas de visualización e incluso de interpretación de código HTML. Así mismo, las páginas escritas en una versión anterior de HTML deberían ser actualizadas o reescritas, lo que no siempre se cumple. Es por ello que ciertos navegadores todavía mantienen la capacidad de interpretar páginas web de versiones HTML anteriores. Por estas razones, todavía existen diferencias entre distintos navegadores y versiones al interpretar una misma página web.

Tim Berners-Lee (TBL) en 1991 describe 18 elementos que incluyen el diseño inicial y relativamente simple de HTML. Trece de estos elementos todavía existen en HTML 4.

Berners-Lee consideraba el HTML una ampliación de SGML, pero no fue formalmente reconocida como tal hasta la publicación a mediados de 1993, por la IETF (en español: Grupo de Trabajo de Ingeniería de Internet), de una primera proposición para una especificación del HTML: el borrador del "Hypertext Markup Language" de Berners-Lee y Dan Connolly, que incluía una Definición de Tipo de Documento SGML para definir la gramática. El borrador expiró a los seis meses, pero fue notable por su reconocimiento de la etiqueta propia del navegador Mosaic usada para insertar imágenes sin cambio de línea, que reflejaba la filosofía del IETF de basar estándares en prototipos con éxito.

De la misma manera, el borrador competidor de Dave Raggett "HTML+ (Hypertext Markup Format)" (Formato de Marcaje de Hipertexto), de finales de 1993, sugería estandarizar características ya implementadas, como las tablas.

El HTML se escribe en forma de «etiquetas», rodeadas por corchetes angulares (<,>,/). El HTML también puede describir, hasta un cierto punto, la apariencia de un documento, y puede incluir o hacer referencia a un tipo de programa llamado "script", el cual puede afectar el comportamiento de navegadores web y otros procesadores de HTML.

HTML también sirve para codice_1referirse al contenido del tipo de MIME text/html o todavía más ampliamente como un término genérico para el HTML, ya sea en forma descendida del XML (como XHTML 1.0 y posteriores) o en forma descendida directamente de SGML (como HTML 4.01 y anteriores).

HTML consta de varios componentes vitales, entre ellos los "elementos" y sus "atributos", "tipos de data" y la "declaración de tipo de documento".

Los elementos son la estructura básica de HTML. Los elementos tienen dos propiedades básicas: atributos y contenido. Cada atributo y contenido tiene ciertas restricciones para que se considere válido al documento HTML. Un elemento generalmente tiene una etiqueta de inicio (por ejemplo, codice_2) y una etiqueta de cierre (por ejemplo, codice_3). Los atributos del elemento están contenidos en la etiqueta de inicio y el contenido está ubicado entre las dos etiquetas (por ejemplo, codice_4). Algunos elementos, tales como codice_5, no tienen contenido ni llevan una etiqueta de cierre. Debajo se listan varios tipos de elementos de marcado usados en HTML.

El marcado "estructural" describe el propósito del texto. Por ejemplo, codice_6 establece «Golf» como un encabezamiento de segundo nivel, el cual se mostraría en un navegador de una manera similar al título «Marcado HTML» al principio de esta sección. El marcado estructural no define cómo se verá el elemento, pero la mayoría de los navegadores web han estandarizado el formato de los elementos. Puede aplicarse un formato específico al texto por medio de hojas de estilo en cascada.

El marcado "presentacional" describe la apariencia del texto, sin importar su función. Por ejemplo, codice_7 indica que los navegadores web visuales deben mostrar el texto en negrita, pero no indica qué deben hacer los navegadores web que muestran el contenido de otra manera (por ejemplo, los que leen el texto en voz alta). En el caso de codice_7 e codice_9, existen elementos que se ven de la misma manera pero tienen una naturaleza más semántica: codice_10 y codice_11. Es fácil ver cómo un lector de pantalla debería interpretar estos dos elementos. Sin embargo, son equivalentes a sus correspondientes elementos presentacionales: un lector de pantalla no debería decir más fuerte el nombre de un libro, aunque el nombre resalte en "itálicas" en una pantalla. La mayoría del marcado presentacional ha sido desechada con HTML 4.0, en favor de hojas de estilo en cascada.

El marcado "hipertextual" se utiliza para enlazar partes del documento con otros documentos o con otras partes del mismo documento. Para crear un enlace es necesario utilizar la etiqueta de ancla codice_1 junto con el atributo codice_13, que establecerá la dirección URL a la que apunta el enlace. Por ejemplo, un enlace que muestre el texto de la dirección y vaya hacia nuestra Wikipedia podría ser de la forma codice_14. También se pueden crear enlaces sobre otros objetos, tales como imágenes codice_15.

En su mayoría de los atributos de un elemento son pares nombre-valor, separados por un signo de igual «=» y escritos en la etiqueta de comienzo de un elemento, después del nombre del elemento. El valor puede estar rodeado por comillas dobles o simples, aunque ciertos tipos de valores pueden estar sin comillas en HTML (pero no en XHTML). De todas maneras, dejar los valores sin comillas es considerado poco seguro. En contraste con los pares nombre-elemento, hay algunos atributos que afectan al elemento simplemente por su presencia (tal como el atributo codice_16 para el elemento codice_17).


Hay muchas formas de ponerle color a una página web con el lenguaje HTML, una de ellas es poner el siguiente atributo a un elemento: style="background-color: green" y el fondo se hará de color verde, aunque no se recomienda. La mejor solución es usar hojas de estilo . Otro caso sería añadir estilos a la letra, veamos un ejemplo:
Texto de prueba y así la letra se pondrá de color verde.

El lenguaje HTML puede ser creado y editado con cualquier editor de textos básico, como puede ser Gedit en GNU/Linux, el Bloc de notas de Windows, o cualquier otro editor que admita texto sin formato como GNU Emacs, Microsoft Wordpad, TextPad, Vim, Notepad++, entre otros.

Existen, además, otros editores para la realización de sitios web con características WYSIWYG ("What You See Is What You Get", o en español: «lo que ves es lo que obtienes»). Estos editores permiten ver el resultado de lo que se está editando en tiempo real, a medida que se va desarrollando el documento. Ahora bien, esto no significa una manera distinta de realizar sitios web, sino que una forma un tanto más simple, ya que estos programas, además de tener la opción de trabajar con la vista preliminar, tiene su propia sección HTML, la cual va generando todo el código a medida que se va trabajando. Algunos ejemplos de editores WYSIWYG son KompoZer, Microsoft FrontPage o Adobe Dreamweaver.

Combinar estos dos métodos resulta muy interesante, ya que de alguna manera se ayudan entre sí. Por ejemplo, si se edita todo en HTML y el desarrollador olvida algún código o etiqueta, basta con dirigirse al editor visual o WYSIWYG y se continúa ahí la edición o viceversa, ya que hay casos en que resulta más rápido y fácil escribir directamente el código de alguna característica que el usuario desea adherir al sitio que buscar la opción en el programa mismo.

Existe otro tipo de editores HTML llamados WYSIWYM que dan más importancia al contenido y al significado que a la apariencia visual. Entre los objetivos que tienen estos editores es la separación del contenido y la presentación, fundamental en el diseño web.

HTML utiliza etiquetas o marcas, que consisten en breves instrucciones de comienzo y final, mediante las cuales se determina la forma en la que debe aparecer en su navegador el texto, así como también las imágenes y los demás elementos, en la pantalla del ordenador.

Toda etiqueta se identifica porque está encerrada entre los signos menor que y mayor que (<nowiki><></nowiki>), y algunas tienen atributos que pueden tomar algún valor. En general las etiquetas se aplicarán de dos formas especiales:

Seleccionando la opción «ver código fuente» en el navegador, se puede ver realmente la información que está recibiendo el navegador web y cómo la está interpretando.

Por ejemplo: en Internet Explorer o en Firefox, simplemente hay que desplegar el menú «ver» y luego elegir «código fuente», mientras que en Chrome presionar . De esta forma, se abrirá el editor de texto configurado como predeterminado en el sistema con el código fuente de la página que se esté viendo en ese momento en el explorador. Otra forma más rápida consiste en hacer clic con el botón derecho del ratón en cualquier punto del área donde el navegador muestra la página web y elegir «ver código fuente».

Aparte de poder ver el código fuente HTML de una página web con las opciones antes descritas, Internet Explorer, Firefox y Google Chrome incorporan también unas herramientas conocidas como inspectores de página que se puede activar con .

Con estas herramientas es posible visualizar una página web y seleccionar dentro de ella un elemento concreto del cuál queremos conocer cuál es el código HTML con el que está hecho señalando el elemento en cuestión simplemente con el ratón. Al hacer esto, el código se mostrará en un área especial dentro del navegador en el que el usuario podrá ver el código HTML en cuestión (ver imagen), además, de las reglas CSS que aplican a ese código HTML en concreto. Este tipo de análisis resulta sumamente instructivo para aprender a desarrollar en HTML.

Para el navegador Firefox, además, existe como alternativa a la herramienta nativa el plugin Firebug, muy similar a la herramienta que Firefox incorpora por defecto.

En 1989 existían dos técnicas que permitían vincular documentos electrónicos, por un lado los hipervínculos o enlaces ("hiperlinks" o "links") y por otro lado un poderoso lenguaje de etiquetas denominado SGML. Por entonces, Tim Berners-Lee, quien trabajaba en el Centro Europeo de Investigaciones Nucleares CERN da a conocer a la prensa que estaba trabajando en un sistema que va a permitir acceder a ficheros en línea que funcionaba sobre redes de computadoras o máquinas electrónicas basadas en el protocolo TCP/IP. Inicialmente fue desarrollado para que se pudiera compartir fácilmente información entre científicos de distintas universidades e institutos de investigación de todo el mundo.

A principios de 1990, define por fin el HTML como un subconjunto del conocido SGML y crea algo más valioso incluso, el World Wide Web.

Tim Berners-Lee creó el proyecto World Wide Web (Tejido o Telaraña Mundial), así como un sistema que facilitaba la lectura de información, mediante un programa de navegación. Sería el primer navegador web, llamado WorldWideWeb, y desarrollado durante la segunda mitad del año 1990; siendo tiempo después rebautizado como Nexus, para evitar confusiones por su nombre que era igual al de la tecnología que representaba. Le siguieron otros dos navegadores: el Line Mode Browser y el ViolaWWW. Este último, desarrollado en 1992, fue el primer navegador en popularizarse entre los primeros usuarios de la World Wide Web.

Pei-Yuan Wei presentó el ViolaWWW, que funcionaría en modo texto y sobre un sistema operativo UNIX.

Los trabajos para crear un sucesor del HTML, denominado HTML +, comenzaron a finales de 1993. HTML+ se diseñó originalmente para ser un superconjunto del HTML que permitiera evolucionar gradualmente desde el formato HTML anterior. A la primera especificación formal de HTML+ se le dio, por lo tanto, el número de versión 2 para distinguirla de las propuestas no oficiales previas. Los trabajos sobre HTML+ continuaron, pero nunca se convirtió en un estándar, a pesar de ser la base formalmente más parecida al aspecto compositivo de las especificaciones actuales.

El borrador del estándar HTML 3.0 fue propuesto por el recién formado W3C en marzo de 1995. Con él se introdujeron muchas nuevas capacidades; por ejemplo, facilidades para crear tablas, hacer que el texto fluyese alrededor de las figuras y mostrar elementos matemáticos complejos. Aunque se diseñó para ser compatible con HTML 2.0, era demasiado complejo para ser implementado con la tecnología de la época, y cuando el borrador del estándar expiró en septiembre de 1995, se abandonó debido a la carencia de apoyos de los fabricantes de navegadores web. El HTML 3.1 nunca llegó a ser propuesto oficialmente, y el estándar siguiente fue el HTML 3.2, que abandonaba la mayoría de las nuevas características del HTML 3.0 y, a cambio, adoptaba muchos elementos desarrollados inicialmente por los navegadores web Netscape y Mosaic. La posibilidad de trabajar con fórmulas matemáticas que se había propuesto en el HTML 3.0 pasó a quedar integrada en un estándar distinto llamado MathML.

En 1997, HTML 4.0 se publicó como una recomendación del W3C. HTML 4.0 adoptó muchos elementos específicos desarrollados inicialmente para un navegador web concreto, pero al mismo tiempo comenzó a limpiar el HTML señalando algunos de ellos como «desaprobados» ("deprecated", en inglés).

HTML 4.0 implementa características como XForms 1.0 que no necesitan implementar motores de navegación que eran incompatibles con algunas páginas web HTML. En 2004 la W3C reabrió el debate de la evolución del HTML, y se dieron a conocer las bases para la versión HTML5. No obstante, este trabajo fue rechazado por los miembros del W3C y se daría preferencia al desarrollo del XML.

Apple, Mozilla y Opera anunciaron su interés en seguir trabajando en el proyecto bajo el nombre de WHATWG, que se basa en la compatibilidad con tecnologías anteriores.

En 2006, el W3C se interesó en el desarrollo de HTML5, y en 2007 se unió al grupo de trabajo del WHATWG para unificar el proyecto.

El diseño en HTML, aparte de cumplir con las especificaciones propias del lenguaje, debe respetar ciertos criterios de accesibilidad web, siguiendo unas pautas o las normativas y leyes vigentes en los países donde se regule dicho concepto. Se encuentra disponible y desarrollado por el W3C a través de las Pautas de Accesibilidad al Contenido Web 1.0 WCAG (actualizadas recientemente con la especificación 2.0), aunque muchos países tienen especificaciones propias, como es el caso de España con la Norma UNE 139803.

Los caracteres especiales como signo de puntuación, letras con tilde o diéresis o símbolos de escritura del lenguaje se deben convertir en entidad HTML para mostrarse en un navegador. La siguiente es una lista de caracteres españoles y su correspondiente entidad HTML:





</doc>
<doc id="1367" url="https://es.wikipedia.org/wiki?curid=1367" title="Hipertexto">
Hipertexto

El hipertexto es una herramienta con estructura no secuencial que permite crear, agregar, enlazar y compartir información de diversas fuentes por medio de enlaces asociativos.

La forma más habitual de hipertexto en informática es la de hipervínculos o referencias cruzadas automáticas que van a otros documentos (lexías). Si el usuario selecciona un hipervínculo, el programa muestra el documento enlazado. Otra forma de hipertexto es el stretchtext que consiste en dos indicadores o aceleradores y una pantalla. El primer indicador permite que lo escrito pueda moverse de arriba hacia abajo en la pantalla.

Es importante mencionar que el hipertexto no está limitado a datos textuales, podemos encontrar dibujos del elemento especificado o especializado, sonido o vídeo referido al tema. El programa que se usa para leer los documentos de hipertexto se llama navegador, "browser", visualizador o cliente, y cuando seguimos un enlace decimos que estamos navegando por la web. El hipertexto es una de las formas de la hipermedia, enfocada en diseñar, escribir y redactar texto en una media.

El concepto de hipertexto fue creado por Vannevar Bush, un estadounidense que con la invención de Memex, un dispositivo que sirve como base de datos y que posteriormente da la posibilidad de interactuar con los usuarios, permitió mecanizar y conectar la información con el fin de aumentar el desarrollo en aquella época. Toda esta explicación aparece recogida en el artículo "As We May Think", publicado en el número de julio de 1945 de la revista The Atlantic Monthly, de Boston.

Ted Nelson, en 1965, fue el primero en acuñar la palabra “hypertext”, su propuesta es Xanadu, un sistema que permite que un mismo documento aparezca en múltiples contextos sin tener que haber sido duplicado.

El primer sistema de hipertexto llevado a cabo fue creado por Andries Van Dam y construido en la Universidad Brown en el año 1967. Se llamaba HES (Hypertext Editing System).

Douglas Engelbart en 1968 diseña el NLS (on line system), origen del sistema Augment, un medio basado en una interfaz que permite la manipulación directa con el uso del dispositivo “ratón”. Engelbart se asocia con Ted Nelson para desarrollar un programa de computador en el que se puede implementar las nociones de hipermedia e hipertexto.
Aspen Movie Map fue el primer sistema hipermedia, llevado a cabo por Lippman en 1978, en el que se creó un mapa virtual de la ciudad de Aspen con el que el usuario podía moverse por las calles con el manejo de un joystick .
El concepto de anclas vino de la mano de Intermedia, en la Universidad Brown. Intermedia fue un sistema multiusuario que daba la facilidad de recuperar información. Solo se podía utilizar en Apple bajo Unix. Debido a la falta de fondos desparece.
Guide fue el primer sistema de hipertexto comercial, lo desarrolló Unix y más tarde llevado a la plataforma Apple Macintosh.
El verdadero punto de inflexión para el concepto de hipertexto ocurrió en 1987 con la introducción de HyperCard en las computadores de Apple. En ese mismo año se da una conferencia en la Universidad de North Caroline dedicada a la investigación hipertextual.
En 1991 se lleva a cabo el proyecto para llevar la tecnología hipermedial a la World Wide Web. Dos años más tarde, NCSA (National Center for Supercomputing Applications) crea Mosaic el navegador gráfico para la WWW.

En la historia se ha intentado crear novelas o cuentos impresos que se relacionan con la idea del proceso hipertextual como en "El jardín de senderos que se bifurcan", sin embargo, nunca se logró este proceso ya que era imposible salir del mismo medio en donde se estaba planteando la novela o el escrito.

El hombre es capaz de relacionar conceptos de la misma manera que se logra en un hipertexto, no lo hace necesariamente de manera lineal, por lo tanto, podemos decir que el pensamiento humano como tal se logra de una manera hipertextual.

Lo complicado radica en plasmar esta hipertextualidad en un formato lineal como lo es un libro, ya que este formato no permite jugar con la espacialidad de la información, la mente es como este gran hipertexto en el cual la información se encuentra en varios nodos y por medio de búsquedas relacionadas y vínculos se llega a la información que se busca.

Ejemplos de novelas hipertextuales:

"Rayuela", "Kenney Adam", "The museum", "Moulthrop", "Victory Garden".

El hipertexto permite almacenar grandes cantidades de información en poco espacio aparente, ya que la información se muestra al usuario de manera fragmentada. Puede incluir imágenes, gráficos, sonidos, animaciones, además de texto y se puede aplicar en entornos de programación, aplicaciones educativas y formación asistida por ordenador. Pero principalmente se utiliza cuando la información está organizada en muchos fragmentos relacionados entre ellos y el usuario necesita solo una pequeña parte de toda esa información.

En la práctica, el hipertexto se utiliza principalmente con:

Aun así, es el autor el que debe identificar los intereses de los lectores y orientar el texto hacia ellos, por lo que las utilidades pueden quedar abiertas.
Para realizar la estructura de hipertexto hay que tener en cuenta los usuarios potenciales a los que se dirige, el contexto de uso y el tema o materia que trata. El diseño del hipertexto configura la usabilidad buena o mala del sitio web. Aunque la información contenida y la estructura sean complejas, se debe mostrar al usuario como algo sencillo y ordenado.
El hipertexto configura una nueva forma de escribir y de entender el texto. Los lectores escanean la pantalla sin leer todo lo que contiene, buscando elementos que destaquen y llamen la atención. A su vez, quien escribe debe tener presentes cuestiones como el modo en que interactuará el usuario con el texto y con la estructura hipertextual, cómo navegará por ella o cómo asimilará la información. El hipertexto facilita la lectura y ofrece la oportunidad de crear una ruta propia. La experiencia con el hipertexto le da al usuario un mejor manejo estratégico del mismo y le vuelve más crítico con el contenido de Internet. En ambientes educativos, el hipertexto ayuda a desarrollar actividades como asociar, relacionar, fragmentar o esquematizar.

Un modelo es un marco general y teórico que formaliza todas las características y funciones, esenciales y deseables, que se puedan incluir en cualquier aplicación de este tipo. Evidentemente el modelo será más completo, en la medida que cuente y exprese más características. Según Tompa, (1989), un modelo en el contexto de sistemas hipermediales, tiene que representar tanto la estructura estática como el funcionamiento dinámico de sus componentes. Se debe agregar al modelo los aspectos relacionados con el intercambio de información entre el sistema y los usuarios, siendo estos el autor y el lector del hipermedia, con la finalidad de describir aquellos elementos de interfaz que facilitan la observación del documento en un computador.
Los sistemas hipertexto están basados en un modelo básico que sigue siendo utilizado y asumido por una variedad de investigadores. El modelo básico está dividido en: submodelo de datos y submodelo de procesos.

Submodelo de datos:

Submodelo de procesos:

En la literatura se encuentra una amplia gama de descripciones de hipertextos, en su mayoría utilizan como submodelo de datos derivaciones y extensiones de grafos, modelos expresados en lenguaje formal y modelos basados en el paradigma orientado a objetos. Los más utilizados son:




</doc>
<doc id="1369" url="https://es.wikipedia.org/wiki?curid=1369" title="GNU/Hurd">
GNU/Hurd

GNU Hurd es un conjunto de programas servidores que simulan un sistema operativo Unix, que establece la base de la distribución GNU. El Proyecto GNU lo ha estado desarrollando desde 1990 como software libre, distribuyéndolo bajo la licencia GPL.

Hurd intenta superar a los sistema operativos tipo Unix en cuanto a funcionalidad, seguridad y estabilidad, aún manteniéndose compatible con ellos. Esto se logra gracias a que Hurd implementa la especificación POSIX (entre otras), pero eliminando las restricciones arbitrarias a los usuarios.

Aunque el Proyecto GNU se refiere a Hurd como núcleo, en sentido estricto esto no es correcto, dado que parte importante de Hurd reside en espacio de usuario, interactuando con un micronúcleo (GNU Mach). De hecho, Hurd es un sistema operativo, como el núcleo Linux (como el mismo indica, el Proyecto GNU se refiere a GNU y GNU/Linux usando el término sistema operativo como equivalente de distribución).

El desarrollo de Hurd empezó en el año 1990. Aunque Richard Stallman, fundador del proyecto GNU, había anunciado que esperaba el lanzamiento oficial del sistema operativo GNU (también conocido como GNU/Hurd) antes de finales de 2002, esto no fue conseguido, en parte porque se comenzó a utilizar el núcleo Linux.

La palabra Hurd es un acrónimo recursivo. Hurd es el acrónimo de «Hird of Unix-Replacing Daemons» (en español: «Hird» de demonios que reemplazan a Unix). A su vez el término «Hird» significa «Hurd of Interfaces Representing Depth» («Hurd» de interfaces que representan profundidad). Tanto «Hurd» como «Hird» en inglés americano se pronuncian como /hɜːrd/ «herd» (en español: manada), por lo que GNU Hurd se podría traducir como «manada de ñúes», referente a su arquitectura de un conjunto de servidores corriendo.

A diferencia de la mayoría de núcleos tipo Unix, Hurd se erige encima de un micronúcleo (actualmente sólo está soportado Mach, aunque existió un proyecto ahora discontinuado para poder ejecutar Hurd en el micronúcleo de segunda generación L4), responsable de facilitarle los servicios de un núcleo más básicos: coordinar el acceso al hardware (a la CPU —mediante multiproceso—, a la memoria RAM —mediante gestión de memoria—, y a otros dispositivos de sonido, gráficos, almacenamiento, etc).

Hay otros sistemas tipo Unix que se ejecutan encima del micronúcleo Mach, como OSF/1, NEXTSTEP, Mac OS X, Lites y MkLinux. Todos ellos están implementados como un único "servidor". Por lo tanto, sustituyen el núcleo monolítico de los sistemas Unix tradicionales con dos elementos, el micronúcleo y el servidor Unix.

En cambio, Hurd consiste en múltiples servidores ejecutándose simultáneamente. En lugar de un solo programa enorme que controle desde el reloj hasta el manejo de la red, en Hurd cada una de estas tareas es gestionada por un servidor independiente. Esto hace que (teóricamente, al menos) el desarrollo de Hurd sea mucho más fácil, ya que es menos probable que el hacer cambios en un servidor tenga efectos indeseados en otros servidores.

En el diseño original de Mach una de las principales metas fue este tipo de «conjunto de servidores», pero parece que Hurd es el primero en implementar este diseño sobre un micronúcleo Mach (aunque QNX es similar, pero basado en su propio micronúcleo). No está claro por qué no hubo ninguna implementación de múltiples servidores anteriormente, aunque parece que los grupos que trabajaban en Mach estaban demasiado ocupados en éste para dedicarse al sistema operativo en su totalidad. Hurd intenta, además, ser portable entre micronúcleos.

En Hurd un buen número de conceptos tradicionales de Unix cambian o se potencian:

Bajo Unix, cada programa que se ejecuta tiene asociada una identidad de usuario, que normalmente se corresponde con el usuario que inició el proceso. Esta identidad determina en gran medida qué acciones se le permite realizar al programa. Ningún proceso externo puede cambiar la identidad de un programa que se esté ejecutando. Un proceso de Hurd, por otra parte, se ejecuta asociado a un conjunto de identidades de usuario, que puede contener múltiples identidades, una, o ninguna. Un proceso con los suficientes privilegios puede añadir o eliminar identidades de otro proceso. Por ejemplo, existe un servidor de contraseñas que otorga identidades en respuesta a una contraseña de usuario correcta.

En lo que respecta al sistema de archivos, se puede establecer un programa adecuado como "traductor" para un solo archivo o una jerarquía de directorios entera. Cada acceso al archivo traducido, o a los archivos en la jerarquía en el segundo caso, son de hecho manejados por este programa. Por ejemplo, un traductor de archivos puede simplemente redirigir las operaciones de lectura y escritura hacia otro archivo, no como un enlace simbólico de Unix. El "montaje" de Unix, en Hurd se consigue configurando un traductor de sistema de archivos (usando el mandato codice_1). Los traductores también se pueden usar para proporcionar servicios al usuario. Por ejemplo, el traductor ftpfs permite a un usuario encapsular un sitio FTP remoto en un directorio. Con esto, se pueden usar programas estándar como codice_2, codice_3 o codice_4 para manipular archivos en el sitio remoto. Hay traductores incluso más potentes, como UnionFS, que permite a un usuario unificar varios directorios en uno solo, de tal manera que al listar este directorio se muestra el contenido de todos los directorios unificados (una característica ausente en la mayoría de Unices, aunque presente en FreeBSD).

Quizás la característica más potente de Hurd es la posibilidad de que cualquier usuario ejecute sus propios servicios de sistema. Un usuario puede asignar cualquier traductor al sistema de archivos para su uso personal. Incluso puede reemplazar servidores del sistema, como el servidor de autenticación, con otros servidores de su elección. Todo esto se puede hacer sin afectar a los otros usuarios, gracias a que los ámbitos de efecto están bien definidos. De hecho, incluso es posible para un usuario ejecutar Hurd dentro de sí mismo, lo que se conoce como sub-Hurd.

Según la documentación de Debian son los siguientes:


También incluye varios sistemas de ficheros:


Entre todos ellos implementan la interfaz de programación de aplicaciones o API Single Unix Specification que es un superset de POSIX. En realidad, es la biblioteca libc la que implementa la API POSIX, igual que en Linux, y Hurd da una interfaz cercana pero de más bajo nivel.

La forma en que los programas llaman a Hurd es a través del sistema de archivos. Funcionan como un sistema de archivos especial, parecido al /proc de linux. Por ejemplo, si queremos hablar con el servidor auth miraremos en el directorio donde esté montado (/servers/auth) y haremos llamadas read/write sobre él.

De alguna forma, por tanto, el servidor del sistema de archivos es el que hace de interfaz del API y también sabe a cuál de los otros servidores de bajo nivel mandar las llamadas. A bajo nivel, cuando se hace un open de uno de estos archivos, el programa recibe los distintos dispositivos de hardware que vayan compilados dentro del micronúcleo. Por tanto Hurd no necesita llevar él mismo la gestión de bajo nivel de las interrupciones; en cambio sí necesita traducir las señales hardware a señales del sistema operativo.

Necesita un gestor de arranque que siga el protocolo multiboot como GRUB. La configuración se realiza mediante los siguientes pasos (o se configura el gestor de arranque para que lo haga automáticamente):

Con esto, el micronúcleo cargará los servidores del hurd y les pasará el control.

Actualmente, hay al menos cinco distribuciones de GNU/Hurd en preparación (Debian GNU/Hurd, Gentoo, Arch Hurd, Bee y A.T.L.D. GNU/Hurd), aunque ninguna ha publicado versiones oficiales.

Se está intentando crear una nueva versión del Hurd llamada NgHurd, este proyecto comenzó con un intento de portar el micronúcleo L4 a Hurd lo cual lo hubiera dotado de una mayor velocidad entre otras características. Dicho proyecto fue abandonado, por lo cual se están discutiendo las características para esta nueva versión desde cero, incluyendo el micronúcleo a utilizar.




</doc>
<doc id="1370" url="https://es.wikipedia.org/wiki?curid=1370" title="Historia">
Historia

La historia es la ciencia que tiene como objeto el estudio de sucesos del pasado, tradicionalmente de la humanidad, y como método el propio de las Ciencias Sociales/Humanas, así como el de las Ciencias Naturales en un marco de interdisciplinariedad. Siendo la disciplina que estudia y narra cronológicamente los acontecimientos pasados. Se denomina también «historia» al periodo que transcurre desde la aparición de la escritura hasta la actualidad, aunque es un convencionalismo ampliamente superado en la actualidad, considerando a la prehistoria también como parte intrínseca de la historia. 

Más allá de las acepciones propias de la "Ciencia Histórica", "Ciencias Históricas" o "Ciencias de la Historia", «historia», en el lenguaje usual, es la narración de cualquier suceso, incluso de sucesos imaginarios y de mentiras; sea su propósito el engaño, el placer estético o cualquier otro (ficción histórica). Por el contrario, el propósito de la ciencia histórica es averiguar los hechos y procesos que ocurrieron y se desarrollaron en el pasado e interpretarlos ateniéndose a criterios de objetividad; aunque la posibilidad de cumplimiento de tales propósitos y el grado en que sean posibles son en sí mismos objetos de estudio de la Historiología o Teoría de la Historia, como epistemología o conocimiento científico de la historia. 

A su vez, llamamos «historia» al pasado mismo, e, incluso, puede hablarse de una «Historia Natural» en que la humanidad no estaba presente (término clásico ya en desuso, que se utilizaba en oposición a la historia social, para referirse no solo a la geología y la paleontología sino también a muchas otras Ciencias Naturales —las fronteras entre el campo al que se refiere tradicionalmente este término y el de la prehistoria y la arqueología son imprecisas, a través de la paleoantropología—, y que se pretende complementar con la Historia ambiental o ecohistoria, y actualizarse con la denominada «Gran Historia»: campo académico interdisciplinar que se define como "el intento de comprender de manera unificada, la historia del Cosmos o Universo, la Tierra, la Vida y la Humanidad", cubriendo la historia desde el Big Bang hasta la Historia del mundo actual).

Ese uso del término «historia» lo hace equivalente a «cambio en el tiempo». En ese sentido se contrapone al concepto de filosófico equivalente a esencia o permanencia (lo que permite hablar de una filosofía natural en textos clásicos y en la actualidad, sobre todo en medios académicos anglosajones, como equivalente a la física). Para cualquier campo del conocimiento, se puede tener una perspectiva histórica —el cambio— o bien filosófica —su esencia—. De hecho, puede hacerse eso para la historia misma (véase tiempo histórico) y para el tiempo mismo (véase "Historia del tiempo" de Stephen Hawking, libro de divulgación sobre cosmología). En este sentido, todo pasado en relación al presente hace alusión al tiempo y a su cronología, y por lo tanto tener historia. 

En medicina se utiliza el concepto de historia clínica para el registro de datos sanitarios significativos de un paciente, que se remontan hasta su nacimiento o incluso hacer lo propio con respecto a su herencia genética.

El "historiador" o la "historiadora" es la persona encargada del estudio de la historia. Al historiador profesional se le concibe como el especialista en la disciplina de la Historia, y al historiador no profesional se le tiende a denominar como cronista.

Dentro de la popular división entre "ciencias" y "letras" o "humanidades", se tiende a clasificar a la historia entre las disciplinas humanísticas junto con otras ciencias sociales (también denominadas ciencias humanas); o incluso se la llega a considerar como un puente entre ambos campos, al incorporar la metodología de estas a aquellas. La ambigüedad de esa división del conocimiento humano, y el cuestionamiento de su conveniencia, ha llevado al llamado "debate de las dos culturas".

No todos los historiadores aceptan la identificación de la historia con una ciencia social, al considerarla una reducción en sus métodos y objetivos, comparables con los del arte si se basan en la imaginación (postura adoptada en mayor o menor medida por Hugh Trevor-Roper, John Lukacs, Donald Creighton, Gertrude Himmelfarb o Gerhard Ritter). Los partidarios de su condición científica son la mayor parte de los historiadores de la segunda mitad del siglo XX y del siglo XXI (incluyendo, de entre los muchos que han explicitado sus preocupaciones metodológicas, a Fernand Braudel, E. H. Carr, Fritz Fischer, Emmanuel Le Roy Ladurie, Hans-Ulrich Wehler, Bruce Trigger, Marc Bloch, Karl Dietrich Bracher, Peter Gay, Robert Fogel, Lucien Febvre, Lawrence Stone, E. P. Thompson, Eric Hobsbawm, Carlo Cipolla, Jaume Vicens Vives, Manuel Tuñón de Lara o Julio Caro Baroja). Buena parte de ellos, desde una perspectiva multidisciplinar (Braudel combinaba historia con geografía, Bracher con ciencia política, Fogel con economía, Gay con psicología, Trigger con arqueología), mientras los demás citados lo hacían a su vez con las anteriores y con otras, como la sociología y la antropología. Esto no quiere decir que entre ellos hayan alcanzado una posición común sobre las consecuencias metodológicas de la aspiración de la historia al rigor científico, ni mucho menos que propongan un determinismo que (al menos desde la revolución einsteniana de comienzos del siglo XX) no proponen ni las llamadas "ciencias duras". Por su parte, los historiadores menos proclives a considerar científica su actividad tampoco defienden un relativismo estricto que imposibilitaría de forma total el conocimiento de la historia y su transmisión; y de hecho de un modo general aceptan y se someten a los mecanismos institucionales, académicos y de práctica científica existentes en historia y comparables a los de otras ciencias (ética de la investigación, publicación científica, revisión por pares, debate y consenso científico, etc.).

La utilización que hace la historia de otras disciplinas como instrumentos para obtener, procesar e interpretar datos del pasado permite hablar de ciencias auxiliares de la historia de metodología muy diferente, cuya subordinación o autonomía depende de los fines a los que estas mismas se apliquen.

El registro de anales y crónicas fue en muchas civilizaciones un oficio ligado a un cargo institucional público, controlado por el estado. Sima Qian (denominado "padre de la Historia" en la cultura china) inauguró en esa civilización los registros históricos oficiales burocratizados (). La crítica del musulmán Ibn Jaldún ("Muqaddima" —"Prolegómenos a la Historia Universal—", 1377) a la manera tradicional de hacer historia no tuvo consecuencias inmediatas, siendo considerado un precedente de la renovación de la metodología de la historia y de la filosofía de la historia que no se inició hasta el siglo XIX, fruto de la evolución de la historiografía en Europa Occidental. Entre tanto, los cronistas oficiales castellanos y de Indias dieron paso en la España ilustrada del siglo XVIII a la fundación de la Real Academia de la Historia; instituciones similares existen en otros países.
La docencia de la historia en la enseñanza obligatoria fue una de las bases de la construcción nacional desde el siglo XIX, proceso simultáneo a la proliferación de las cátedras de historia en las universidades (inicialmente en las facultades de letras o "Filosofía y Letras", y con el tiempo, en facultades propias o de Geografía e Historia —disciplinas cuya proximidad científica y metodológica es una característica de la tradición académica francesa y española—) y la creación de todo tipo de instituciones públicas y privadas (clubes históricos o sociedades históricas, muy habitualmente "medievalistas", respondiendo al historicismo propio del gusto romántico, empeñado en la búsqueda de elementos de identificación nacional); así como publicaciones dedicadas a la historia.
En la enseñanza media de la mayor parte de los países, los programas de historia se diseñaron como parte esencial del currículo. En especial la agregación de historia presente en los "lycées" franceses desde 1830 adquirió con el tiempo un prestigio social incomparable con los cargos similares en otros sistemas educativos y que caracterizó el "elitismo" de la escuela laica republicana hasta finales del siglo XX.

A ese proceso de institucionalización, siguió la especialización y subdivisión de la disciplina con diferentes sesgos temporales (de cuestionable aplicación fuera de la civilización occidental: historia antigua, medieval, moderna, contemporánea —estas dos últimas, habituales en la historiografía francesa o española, no suelen subdividirse en la historiografía anglosajona: "—"), espaciales (historia nacional, regional, local, continental —de África, de Asia, de América, de Europa, de Oceanía—), temáticos (historia política, militar, de las instituciones, económica y social, de los movimientos sociales y de los movimientos políticos, de las civilizaciones, de las mujeres, de la vida cotidiana, de las mentalidades, de las ideas, cultural), historias sectoriales ligadas a otras disciplinas (historia del arte, de la música, natural, de las religiones, del derecho, de la ciencia, de la medicina, de la economía, de la ciencia política, de las doctrinas políticas, de la tecnología), o centrada en cualquier tipo de cuestión particular (historia de la electricidad, de la democracia, de la Iglesia, de los sindicatos, de los sistemas operativos, de las formas —literarias de la Biblia—, etc). Ante la atomización del campo de estudio, también se han realizado distintas propuestas que consideran la necesidad de superar esas subdivisiones con la búsqueda de una perspectiva holística (historia de las civilizaciones, historia total o historia universal) o su enfoque inverso (microhistoria); sin olvidar el nuevo campo académico e interdisciplinar de la Gran Historia como "el intento de comprender de manera unificada, la Historia del Cosmos o Universo, la Tierra, la Vida y la Humanidad", cubriendo la historia desde el Big Bang hasta la Historia del mundo actual. Examina los tiempos de larga duración utilizando un enfoque multidisciplinar basado en la combinación de numerosas disciplinas de la ciencia y las humanidades que estudian el pasado, las "Ciencias-Históricas", y explora la existencia humana en el contexto de un panorama más amplio, que en relación al presente hace alusión al tiempo y la cronología, enseñándose en universidades y escuelas.

El Premio Nacional de Historia (de Chile —bianual, a una personalidad— y de España —a una obra publicada cada año—) y el Premio Príncipe de Asturias de Ciencias Sociales (a una personalidad del ámbito de la historia, la geografía u otras ciencias sociales) son los más altos reconocimientos de la investigación histórica en el ámbito hispanohablante, mientras que en el ámbito anglosajón existe una de las versiones del Premio Pulitzer. El Premio Nobel de Literatura, que puede recaer en historiadores, solo lo hizo en dos ocasiones (Theodor Mommsen, en 1902, y Winston Churchill, en 1953). Desde una perspectiva más propia de la consideración actual de la historia como una ciencia social, el Premio Nobel de economía fue concedido a Robert Fogel y Douglass North en 1993. Por otra parte, el de la History of Science Society se estableció en 1958. El premio consiste en una medalla y una cantidad en metálico. Este premio se otorga en reconocimiento a un libro extraordinario sobre la historia de la ciencia. Cada año, un centenar de autores compiten por este premio, que es considerado el más importante para libros de historia de la ciencia.

El Premio Internacional de Ciencias Históricas, es el premio internacional más prestigioso de Historia otorgado por el Comité Internacional de Ciencias Históricas ("International International Committee of Historical Sciences" / "Comité international des sciences historiques"), la asociación internacional de "Ciencias Históricas" fundada en Ginebra el 14 de mayo de 1926, que concede desde 2015 el Premio Internacional de Historia del CICH, Jaeger-LeCoultre, al "historiador que se ha distinguido en el campo de la Historia por sus obras, publicaciones o docencia, y haya contribuido significativamente al desarrollo del conocimiento histórico". Considerado el "Premio Nobel" en Ciencias Históricas, el jurado del Consejo del CISH, que cuenta con 12 miembros de diferentes países, selecciona al ganador dentro de un grupo de candidatos excelentes y altamente calificados. Solo los miembros colectivos del CISH (sus comités nacionales o sus organizaciones afiliadas internacionales) pueden presentar candidatos.

La identificación del concepto de "historia" con la narración escrita del pasado produce, por un lado, su confusión con el término historiografía ("historia" se llama a la vez al objeto estudiado, a la ciencia que lo estudia y al documento resultado de ese estudio); y por otro justifica el empleo del término prehistoria para el período anterior a la aparición de la escritura, reservándose el nombre "historia" para el periodo posterior.

Según ese uso restrictivo, la mayor parte de la humanidad queda "fuera de la historia", no tanto porque no accede personalmente a la lectura y la escritura (el analfabetismo fue la condición común de la inmensa mayoría de la población, incluso para las clases dominantes, hasta la imprenta), sino porque los reflejados en el discurso histórico han sido siempre muy pocos, y grupos enteros quedan "invisibilizados" (las clases bajas, las mujeres, los discrepantes que no pueden acceder al registro escrito), con lo que ha sido objeto de preocupación de algunos historiadores la reconstrucción de la "visión de los vencidos" y la "historia desde abajo".

Lo mismo ocurre con gran número de pueblos y culturas (las consideradas como culturas primitivas, en una terminología ya desfasada de la antropología clásica) que "no tienen historia". El tópico los idealiza al considerar que son "pueblos felices". Entran en ella cuando se produce su contacto, habitualmente destructivo (aculturación), con civilizaciones (sociedades complejas, con escritura). Incluso en ese momento no son propiamente objeto de la "historia" sino de la protohistoria (historia realizada a partir de las fuentes escritas producidas por los que generalmente son sus pueblos colonizadores por oposición a los pueblos indígenas). No obstante, independientemente de que los historiadores y los antropólogos ideológicamente tengan una tendencia "etnocentrista" ("eurocentrista", "sinocentrista" o "indigenista") o, de forma opuesta, "multiculturalista" o "relativista cultural", existe la posibilidad de obtener o reconstruir un relato fiable de los acontecimientos que afectan a un grupo humano utilizando otras metodologías: fuentes arqueológicas (cultura material) o historia oral. En buena parte, esta diferencia es artificial, y no necesariamente novedosa: el mismo Heródoto no puede sino usar ese tipo de fuentes documentales cuando redacta la que se considera la primera "Historia", o al menos acuña el término, en la Grecia del siglo V a. C. "para que el tiempo no abata el recuerdo de las acciones de los hombres y que las grandes empresas acometidas, ya sea por los griegos, ya por los bárbaros, no caigan en olvido; da también razón del conflicto que puso a estos dos pueblos en la lid". Así comienza su obra titulada "Ἱστορίαι" (léase "históriai", literalmente «investigaciones», «exploraciones», latinizado "Historiae" —«"Historias»", en plural—), seminal para la ciencia histórica, y que suele denominarse en castellano "Los nueve libros de historia". La lid citada son las guerras médicas y los bárbaros, persas.

La palabra "historia" deriva del griego ἱστορία (léase "historia", traducible por «investigación» o «información», conocimiento adquirido por investigación), del verbo ἱστορεῖν («investigar»). De allí pasó al latín "historia", que en castellano antiguo evolucionó a "estoria" (como atestigua el título de la "Estoria de España" de Alfonso X el Sabio, 1260-1284) y se reintrodujo posteriormente en el castellano como un cultismo en su forma latina original.

La etimología remota procede del protoindoeuropeo "*wid-tor-" (de la raíz "*weid-", «saber, ver» —construcción hipotética—) presente también en las palabras latinas "idea" o "visión", en las germánicas "wit", "wise" o "wisdom", la sánscrita "veda", y las eslavas "videti" o "vedati", y en otras lenguas de la familia indoeuropea.

La palabra antigua griega ἱστορία fue usada por Aristóteles en su Περὶ τὰ ζῷα ἱστορίαι (léase "Peri ta zoa jistória", latinizado "Historia animalium", traducible por "Historia de los animales" [el título griego es plural y el latino es singular]). El término se derivaba de ἵστωρ (léase "jístōr", traducible por «hombre sabio», «testigo» o «juez»). Se pueden encontrar usos de ἵστωρ en los himnos homéricos, Heráclito, el juramento de los efebos atenienses y en las inscripciones beocias (en un sentido legal, con un significado similar a «juez» o «testigo»). El rasgo aspirado es problemático, y no se presenta en la palabra cognata griega εἴδομαι («aparecer»). La forma ἱστορεῖν («inquirir»), es una derivación jónica, que se expandió primero en la Grecia clásica y más tarde en la civilización helenística.

En el estudio de la historia conviene diferenciar tres conceptos a veces usados laxamente y que pueden llegar a ser confundidos entre sí:


Es imposible ignorar la polisemia y la superposición de estos tres términos, pero simplificando al máximo: la historia son los hechos del pasado; la historiografía es la ciencia de la historia; y la historiología es la epistemología o teoría de la historia.

La filosofía de la historia no debe confundirse ni con la historiología, ni con la historiografía, de los que se separa claramente. La filosofía de la historia es la rama de la filosofía que concierne al significado de la historia humana, si es que lo tiene. En su origen especuló si era posible un fin teleológico de su desarrollo, o sea, se pregunta si hay un diseño, propósito, principio director o finalidad en el proceso de la historia humana. En la actualidad se discute más sobre la función del conocimiento histórico dentro del conocimiento y las implicaciones del mismo. También se ha discutido sobre si el objeto de la historia debe ser una verdad histórica, el deber ser, o si la historia es en algún sentido es cíclica o lineal y el devenir histórico se aparta indefinidamente del punto de partida. También se ha discutido si es posible hablar de la idea de progreso positivo en ella.

Tampoco deben confundirse los supuestos fines teleológicos del hombre en la historia con los "fines de la historia" es decir, la justificación de la propia historia como memoria de la humanidad. Si la historia es una ciencia social y humana, no puede abstraerse del porqué se encarga de estudiar los procesos sociales: explicar los hechos y eventos del pasado, sea por el conocimiento mismo, sea por que nos ayudan a comprender el presente: Cicerón bautizó a la historia como "maestra de la vida", y como él Cervantes, que también la llamó "madre de la verdad". Benedetto Croce remarcó la fuerte implicación del pasado en el presente con su "toda historia es historia contemporáea". La historia, al estudiar los hechos y procesos del pasado humano, es un útil para la comprensión del presente y plantear posibilidades para el futuro. Salustio llegó a decir que "entre las distintas ocupaciones que se ejercitan con el ingenio, el recuerdo de los hechos del pasado ocupa un lugar destacado por su gran utilidad". Un tópico muy difundido (atribuido a Jorge Santayana) advierte que "los pueblos que no conocen su historia están condenados a repetirla", aunque otro tópico (atribuido a Carlos Marx) indique a su vez que cuando se repite lo hace "una vez como tragedia y la segunda como farsa".

La radical importancia de ello se basa en que la historia, como la medicina, es una de las ciencias en que el sujeto investigador coincide con el objeto a estudiar. De ahí la gran responsabilidad del historiador: la historia tiene una proyección al futuro por su potencia transformadora como herramienta de cambio social; y a los profesionales que la manejan, los historiadores, les es aplicable lo que Marx dijo de los filósofos ("hasta ahora se han encargado de interpretar el mundo y de lo que se trata es de transformarlo"). No obstante, desde otra perspectiva se pretende una "investigación desinteresada" para la objetividad en la ciencia histórica. Aunque "llegar a conocer los hechos tal como fueron", como pretendía Leopold Ranke, es imposible, sí es un imperativo de la investigación histórica acercarse al máximo a ese objetivo, y además hacerlo con una perspectiva tal que sitúe los hechos en su contexto, de modo que al conocimiento factual se añada el entendimiento de "lo que realmente pasó"; y aunque sea inevitable que sesgos de todo tipo alteren la forma en que tal entendimiento se produce, al menos ser conscientes de cuáles pueden ser y en qué grado actúan.

No hay un acuerdo universal sobre la periodización de la historia, aunque sí un consenso académico sobre los periodos de la historia de la civilización occidental, basado en los términos acuñados inicialmente por Cristóbal Celarius (Edades Antigua, Media y Moderna), que ponía al mundo clásico grecorromano y su Renacimiento como los hechos determinantes para la división; y que actualmente es de aplicación general. La acusación de eurocentrismo que se hace a tal periodización no impide que sea la más utilizada, por ser la que responde precisamente al desarrollo de los procesos históricos que produjeron el mundo contemporáneo.

En cuanto a la división del tiempo prehistórico en Edad de la Piedra y Edad de los Metales, fue propuesta en 1836 por el arqueólogo danés Christian Jürgensen Thomsen.

La evolución tecnológica presenta dos grandes cesuras en el pasado de la humanidad: la revolución neolítica y la revolución industrial, lo que permite hablar de tres grandes periodos: el caracterizado por la exclusividad de sociedades cazadoras-recolectoras, el preindustrial y el industrial (a veces se emplea el adjetivo postindustrial para el periodo de la historia más reciente).

El problema de cualquier periodización es hacerla coherente en términos sincrónicos y diacrónicos, es decir: que sea válida tanto para "el transcurso del tiempo" en un único lugar, como para lo que ocurre "al mismo tiempo" en distintos ámbitos espaciales. Cumplir ambos requisitos resulta difícil cuando los fenómenos que originan el comienzo de un periodo en un lugar (especialmente el Próximo Oriente, Asia central o China) tardan en difundirse o surgir endógenamente en otros lugares, que a su vez pueden estar más o menos próximos y conectados (como Europa Occidental o el África subsahariana), o más o menos lejanos y desconectados (como América u Oceanía). Para responder a todo ello, los modelos de periodización incluyen términos intermedios y periodos de solapamiento (yuxtaposición de características distintas) o transición (aparición paulatina de las novedades o características mixtas entre el periodo que empieza y el que termina). La didáctica de la historia se ayuda frecuentemente de diferentes tipos de representación gráfica de la sucesión de hechos y procesos en el tiempo y en el espacio.






</doc>
<doc id="1372" url="https://es.wikipedia.org/wiki?curid=1372" title="Hadrón">
Hadrón

Un hadrón (del griego ἁδρός, "hadrós", "denso") es una partícula subatómica formada por quarks que permanecen unidos debido a la interacción nuclear fuerte entre ellos. Antes de la postulación del modelo de quarks se definía a los hadrones como aquellas partículas que eran sensibles a la interacción fuerte.

Como todas las partículas subatómicas, los hadrones tienen números cuánticos correspondientes a las representaciones del grupo de Poincaré: codice_1, donde codice_2 es el espín, codice_3 la paridad, codice_4 la paridad C, y codice_5 la masa. Además, pueden llevar números cuánticos de sabor como el isoespín, extrañeza, etc.

Tanto el modelo de quarks, como la evidencia empírica sugieren que los hadrones son partículas compuestas por quarks y/o antiquarks. Hay dos tipos de hadrones (sin contar los casos "exóticos"):
Estas partículas tienen un número bariónico (codice_6) diferente de cero, que es igual a +1 para los nucleones e igual a -1 para sus antipartículas.

La mayor parte de los hadrones se han podido clasificar adecuadamente por el modelo de quarks, que postula que todos los números cuánticos de los bariones se derivan de aquellos de los "quarks de valencia". Para un barión estos son tres quarks, y para un mesón estos son un par quark-antiquark.

Cada quark es entonces un fermión con codice_6 = 1/3. Los estados excitados bariónicos o mesónicos son conocidos como resonancias. Cada estado fundamental hadrónico puede tener muchos estados excitados, y cientos han sido observados en experimentos con partículas. Las resonancias decaen extremadamente rápido (aproximadamente en 10 s) por las interacciones fuertes.

Los mesones que se encuentran fuera de la clasificación según el modelo de quarks se denominan mesones exóticos. Estos incluyen bolas de gluones, mesones híbridos y tetraquarks. Los únicos bariones que están fuera del modelo de quarks a la fecha son los pentaquarks, pero la evidencia de su existencia no ha sido esclarecida aún. Recientemente se ha demostrado la existencia del hadrón Z(4430), con un nivel de confianza de sigma 13.9.

Las resonancias son partículas masivas de muy corta existencia, se desintegran muy rápidamente en partículas más ligeras. Desde la aparición del modelo de quarks se las interpreta como estados excitados con una energía superior a la del estado fundamental, de sistemas ligados de quarks. Por tanto las resonancias no serían estrictamente estructuras diferentes, aunque inicialmente fueron interpretadas así por tener una masa diferente a la del estado fundamental (la discrepancia de masa tiene que ver con la relación "E" = "mc").

Todos los hadrones son sistemas de quarks ligados mediante interacción fuerte, la teoría estándar que da cuenta de esta interacción fuerte es la cromodinámica cuántica (en inglés "quantum chromodynamics" o QCD). Esta teoría postula diversos tipos de quarks que interaccionan entre sí mediante un campo gluónico. Dicho campo está formado por bosones denominados gluones. Debido a una propiedad importante de la teoría llamada confinamiento, los quarks con energías por debajo de la escala QCD experimentan este confinamiento, que impiden observar quarks libres a bajas energías, por lo que usualmente aparecen en forma de hadrones. Otra propiedad interesante de la teoría es que estos sistemas ligados de quarks o hadrones que son compuestos, y no llevan carga de color: si están formados por 3 quarks uno es "rojo", otro es "verde" y otro "azul" (de tal manera que se dicen que son "blancos"). En los mesones si el quark es de un "color" y anti-quark tienen el "anticolor" correspondiente. Así que globalmente no predomina ningún "color" que es una de las consecuencias del confinamiento.

En otras fases de materia QCD los hadrones pueden desaparecer. Por ejemplo, a temperatura y presión muy altas, a menos que haya suficiente cantidad de sabores muy masivos de quarks, la teoría QCD predice que los quarks y gluones van a interactuar débilmente y ya no estarán confinados. Esta propiedad, que se conoce como libertad asintótica, ha sido experimentalmente confirmada a las escalas de energía de entre un GeV y un TeV. Pero esta teoría pronto se pondrá a prueba ya que el 10 de septiembre de 2008 se puso en funcionamiento un acelerador de partículas o hadrones (el LHC, gran colisionador de hadrones, por sus iniciales en inglés), que mide 27 km de circunferencia, situado en el límite entre Francia y Suiza, cerca de la ciudad de Ginebra, y ha costado 3.700 millones de Euros (unos 6.000 millones de dólares según algunas fuentes).



</doc>
<doc id="1373" url="https://es.wikipedia.org/wiki?curid=1373" title="Hora">
Hora

La hora es una unidad de tiempo que se corresponde con la vigésimo-cuarta parte de un día solar medio.

Se utiliza para el tiempo civil y comprende 60 minutos o 3600 segundos, aunque pequeñas irregularidades en la rotación de la Tierra hacen que sean necesarios ajustes. Dado que desde 1967 el segundo se mide a partir de propiedades atómicas muy precisas, para mantener los estándares de tiempo cercanos al día solar medio se utilizan segundos intercalares.

En castellano el término "hora" no tiene abreviatura, pero si se utiliza como indicación del momento en que sucede o se hace una cosa en relación con cada una de las veinticuatro partes en que se divide el día y se escribe con cifras, opcionalmente puede emplearse el símbolo h, y en ese caso debe escribirse sin punto y es invariable en plural. No obstante, en países americanos que tienen al castellano como su idioma principal, es común la abreviatura "hs." aunque se use para señalar un singular.

Se llama hora a la doceava parte del tiempo que transcurre desde la salida del Sol hasta su puesta. que durante el invierno. Los egipcios dividían el día en veinticuatro horas, doce con luz solar y doce nocturnas, sería este sistema el que adoptaron los griegos y los romanos. Estos últimos, primero aplicaron el sistema de doce horas diurnas y más tarde al cómputo de la noche, tiempo transcurrido desde la puesta del Sol hasta su salida, también fue dividida en doce horas. Este tipo de horas se medía mediante un reloj de sol o mediante una Clepsidra. Cuando un reloj mecánico utiliza estas horas, su rapidez debe ser cambiada cada mañana y tarde, por ejemplo cambiando el largo de su péndulo. La hora según esta definición está regulada según el Sistema Horario Temporario.

El tiempo, a su vez, puede ser medido a través del uso de un reloj. El propósito de establecer un horario, por ejemplo, consiste en indicar el momento preciso en que tendrá lugar un hecho futuro para que las personas puedan organizar su rutina.

Posteriormente fue definida como la veinticuatrena parte del día solar aparente, lapso entre un mediodía y el siguiente, o entre una puesta de sol y la próxima. En esta definición las horas varían un poco, puesto que la duración del día solar aparente varía a lo largo del año. Cuando un reloj utiliza estas horas, debe ser ajustado unas pocas veces durante el mes. Según se tome como origen el paso del Sol por el Ocaso o el Orto se denominará Sistema Horario Itálico o Sistema Horario Babilónico respectivamente.

La hora es también una medida angular: como la Tierra da una vuelta sobre sí misma en aproximadamente 24 horas, una hora equivale a 15° (o sea, la veinticuatroava parte de la circunferencia). En todo meridiano terrestre el paso del Sol se produce al mediodía; una hora después pasará por otro meridiano situado a 15° al oeste del primero y así sucesivamente hasta medianoche, en cuyo momento preciso se hallará en el antemeridiano del meridiano de origen. A partir de entonces, el Sol se acerca a éste por levante, hasta volver al punto inicial 24 horas después.

Ahora bien, dada la forma esferoide del globo terrestre, la superficie limitada por dos meridianos separados por la distancia angular de 15° tiene la forma de un huso. Por convención universalmente adoptada, todos los relojes situados en el interior de un mismo huso horario indican la misma hora, aunque esa regla forzosamente tiene ciertas excepciones. Así, cuando una parte relativamente pequeña de un país se halla fuera del huso, se considera (para uniformar la hora nacional) que todo el territorio está en el huso principal. En los países muy extensos de este a oeste, como la Federación Rusa, Canadá o Estados Unidos, no existe "una" hora nacional, sino tantas horas como husos atraviesan el territorio. o en otros casos una parte de un país se puede sujetar a un horario, como por ejemplo el estado mexicano de Sonora que no cambia nunca su horario y mantiene la misma hora que su vecino estado fronterizo de Arizona.

Ciertos países, aprovechando que el Sol se oculta más tarde en verano, instituyen unos meses al año la llamada "hora de verano", es decir, adelantan todos los relojes de una hora, lo cual equivale a adoptar la hora del huso contiguo situado al este. Del mismo modo, en invierno se vuelve al huso horario original para aprovechar al máximo posible la luminosidad del Sol. En la Unión Europea este cambio tiene lugar en el mismo día para todos los Estados Miembros.

En otros casos, razones geopolíticas incitan a un país a adoptar de modo permanente la hora correspondiente al huso vecino: España, ubicada en el huso 0 cambió a la hora del huso 1 (hora CET), con objeto de facilitar las relaciones con la parte Occidental y Central de la Unión Europea.

El conocimiento de la hora tiene muchas repercusiones, tiene mucha importancia en astronomía y en otros campos de la actividad humana. Por esa razón, existen servicios internacionales y nacionales encargados de conservar una hora exacta y de difundirla a los usuarios. Durante largo tiempo, la tarea de determinar la hora estuvo a cargo de astrónomos que se fundaban en los movimientos de los astros. En la actualidad, se utilizan relojes atómicos que indican la hora con una enorme precisión.

La hora exacta y oficial de España, se mantiene según el reloj atómico del Real Instituto y Observatorio de la Armada (ROA) de San Fernando (Cádiz).

En México la hora oficial la determina el Centro Nacional de Metrología (CENAM), dependiente de la Secretaría de Economía.

En Chile la hora oficial la determina el Servicio Hidrográfico y Oceanográfico de la Armada de Chile (SHOA).

En Colombia la hora oficial la determina el Instituto Nacional de Metrología de Colombia.

En Costa Rica la hora oficial la determina el Instituto Meteorológico Nacional de Costa Rica. (IMN)






</doc>
<doc id="1375" url="https://es.wikipedia.org/wiki?curid=1375" title="Hypericaceae">
Hypericaceae

Hypericaceae es una familia cosmopolita del orden "Malpighiales", aceptada por la APG II (2003), con alrededor de 560 especies repartidas en 9 géneros. Se extiende desde las regiones templadas hasta los trópicos.

Plantas leñosas o herbáceas (árboles y lianas en los trópicos), glandulíferas (glándulas pedunculadas o sentadas aspecto en las hojas translúcido). Rica en aceites y resinas de color amarillo intenso, usadas como colorantes (gutagamba). Hojas opuestas o verticiladas, simples y enteras. Flores reunidas en inflorescencias terminales, en panículos, umbelas y cimas, generalmente hermafroditas, regulares, dispuestas en cimas dicasiales o solitarias (raramente); corola y cáliz con 4 - 5 piezas libres, pétalos amarillos; androceo con numerosos estambres unidos y agrupados solo por la base en 4 - 5 haces; gineceo súpero, sincárpico, con 3 - 5 carpelos, estilos libres. Frutos en cápsulas septicidas, bacciformes o drupáceos.

Lista de géneros y sinónimos relacionados alfabéticamente según APWeb:



</doc>
<doc id="1379" url="https://es.wikipedia.org/wiki?curid=1379" title="Historia del constitucionalismo español">
Historia del constitucionalismo español

La historia del constitucionalismo español es reflejo directo de las convulsiones políticas españolas de los siglos XIX y XX, mostrando las tensiones sociales y políticas que existieron en el país.

El constitucionalismo español, se podría definir como el proceso a través del cual el Estado español se ha dotado desde 1808 de una serie de normas magnas 

La crisis del Antiguo Régimen absolutista se agudizó en 1808, produciéndose el Motín de Aranjuez contra Godoy y el propio Rey Carlos IV de España. Este abdica en favor de su hijo Fernando VII de España, pero antes de consolidarse en el poder, Napoleón les hace ir a Bayona con el pretexto de arbitrar sus querellas familiares. Napoleón hace abdicar a padre e hijo en favor de su hermano José Bonaparte. Evitando aparecer un usurpador, Napoleón convocó en Bayona una asamblea de diputados, a los que presentó un texto de Constitución, promulgado el 8 de julio de 1808.

La asamblea de Bayona debería estar formada por cincuenta nobles, cincuenta eclesiásticos y cincuenta representantes del pueblo, pero solo acudieron sesenta y cinco personas, la mayoría nobles, a la que se añadieron algunos españoles residentes en Francia. La asamblea fue presidida por Miguel José de Azanza, discutió varios problemas y aprobó el proyecto de Constitución presentado por Napoleón el 7 de julio de 1807. Había sido redactado por M. Esmenard, un francés residente en España, y fue revisado por el general Joaquín Murat y el mismo emperador.

Organizaba España como una monarquía hereditaria en la cual, el monarca ocupaba el centro del poder político, pero con la obligación de respetar los derechos de los ciudadanos proclamados en su texto.

Nació en un contexto complejo, dictado fuera del territorio nacional y con un marcado carácter afrancesado, apadrinado por los liberales moderados. Debido a que no fue elaborada por los representantes de la Nación, por su origen y proceso no puede considerarse una Constitución, sino una Carta otorgada.

Se abre con la definición confesional del Estado, para tratar después todo lo referente a la Corona y, en títulos posteriores, aborda el entramado institucional, finalizando con un desordenado reconocimiento de determinados derechos y libertades. Pese a establecerse un conjunto de instituciones, no puede hablarse de división de poderes: las atribuciones del monarca eran amplísimas, las Cortes se estructuraban en la representación estamental y las facultades del Senado y de las propias Cortes carecían de fuerza para obligar. Aun así, debido al contexto histórico, este diseño no pudo desarrollarse.

El estatuto de Bayona contiene los elementos de una reforma política y social, tendentes a desarrollar el comercio, disminuir las bases del poder de la nobleza y potenciar a la burguesía. Se pueden destacar:

Respecto de los derechos y libertades, cabe destacar el carácter confesional que se le atribuye a España:

El artículo 1 señalaba que “"La religión Católica, Apostólica y Romana, en España y en todas las posesiones españolas, será la religión del Rey y de la Nación y no se permitirá ninguna otra".”

En un último título se contempla (disposiciones generales) una serie de derechos y libertades. La influencia de la Revolución francesa fue importante: se regulaban derechos de los inicios del liberalismo burgués, lo que suponía un avance respecto de la situación existente.

El Estatuto preveía un papel predominante del monarca, aunque su estatuto personal y prerrogativas no venían claramente enunciados. No obstante, del ámbito funcional de las instituciones, se revelan los amplios poderes del Rey. La importancia se observa en su ubicación (tras la religión) y que le dedica 4 de los 13 títulos.

Tampoco tuvieron vida efectiva. Se estructuraba en 3 estamentos (alto clero, nobleza y pueblo), donde se advertía una clara influencia del Antiguo Régimen, así como contradicción con los principios inspiradores de la Revolución. No se les confería de modo expreso la función legislativa, aunque sí de forma tácita en algunos preceptos.

Desconocía la institución del Gobierno. Contemplaba un título a los ministerios en el que establece un número (7-9) y su denominación. Los ministros eran responsables de la ejecución de las leyes y órdenes del rey. También regula la Administración de Hacienda, que aboga por la supresión de aduanas interiores, separa el Tesoro público del de la Corona y se configura un Tribunal de Contaduría para el examen y aprobación de las cuentas.

Órgano que agrupaba funciones diseminadas del Antiguo Régimen y acaba con la polisinodía en la que se confundían funciones de orden normativo con otras ejecutivas y judiciales. Tenía la facultad de examinar y extender los proyectos de leyes civiles y criminales y los reglamentos generales de la Administración. No deben confundirse sus funciones con las del actual Consejo de Estado, meramente consultivo.

Tenía importancia crucial. Se configuraba como independiente, aunque el Rey nombraba a todos los jueces. Se articulaba en distintas instancias a las que los ciudadanos podían acudir, se establecía la publicidad del proceso criminal y se emplazaba a la creación de un único código de leyes civiles y criminales y otro de comercio para España y las Indias, para poder racionalizar el caótico sistema normativo de entonces.

La marcha de Fernando VII y la presencia invasora francesa provocó un vacío de poder en 1808. La guerra había empezado y las capitulaciones de los monarcas ante Napoleón acrecentaron la sensación de vacuidad. Frente al derrumbamiento de la Administración, la resistencia se estructura a través de juntas provinciales y locales que representan un auténtico poder paralelo, hecho que conllevaría a que la legitimidad monárquica diera paso a la popularidad.

Frente a esta pluralidad de centros de poder, se crea la Junta Central que procederá a la convocatoria de Cortes (no estamentales) que devendrán constituyentes: el 24 de septiembre de 1810 se constituían las Cortes de Cádiz y el mismo día se aprueba un Decreto en el que aparecen los principios básicos del futuro texto constitucional: la soberanía nacional y la división de poderes.

Estaban formadas por una amalgama de intereses: pese al marcado sello liberal de las Cortes, existía presencia de corrientes absolutistas y reaccionarias junto a diputados reformistas o radicales. Incluso parte de los diputados conservadores acabarían promulgando un manifiesto en el que pedían a Fernando VII que suprimiera a su retorno la Constitución (Manifiesto de los Persas). Aun así, la Constitución tendrá un carácter de compromiso entre las opciones liberales y absolutistas. Fue promulgada por las Cortes Generales españolas reunidas extraordinariamente en Cádiz el 19 de marzo de 1812.

Por Decreto de 4 de mayo de 1814, Fernando VII derogó la Constitución de 1812 y todas las disposiciones dictadas en su desarrollo, y a partir de esa fecha fueron restableciéndose las del Antiguo Régimen Absolutista (si bien, como afirma algún autor, bajo la promesa de redactar una nueva Constitución). Posteriormente se volvió a aplicar desde el 8 de marzo de 1820, cuando en Madrid (España), Fernando VII es obligado a jurar la Constitución española de 1812, estando vigente durante el Trienio Liberal (1820-1823).


La Constitución carece de un título específico, pero a lo largo del texto se recogen de forma diseminada distintos derechos.

Por un lado, el artículo 12 ("la religión de la nación española es y será perpetuamente la Católica Apostólica Romana, y la nación la protege por leyes sabias y justas y prohíbe el ejercicio de cualquier otra") es confesional y cerradamente confesional, al imponer una religión y prohibir el resto. Es pues, a "sensu contrario", la negación de la libertad religiosa.

Los derechos reconocidos y diseminados por el texto reproducían los derechos individuales burgueses importados de la Revolución francesa, así, el artículo 4 habla de la libertad civil, la propiedad y los demás derechos legítimos (cláusula abierta).

La igualdad parece enunciada de forma menos enfática que en la Declaración de los Derechos del Hombre y del Ciudadano de 1789, se formulaba la existencia de un solo fuero para toda clase de personas en causas civiles y criminales y se reconocía el sufragio activo. Existía libertad de expresión (excepto en los escritos religiosos).

Se articulaban garantías en las detenciones y procesos judiciales: prohibición del tormento, inviolabilidad personal y domiciliaria, el habeas corpus, a ser informado de las causas, entre otras. Se dedicaba un título específico a la instrucción pública, dando importancia a la enseñanza y reconociendo una instrucción pública para todos los ciudadanos.

Era unicameral para evitar intermediaciones entre los representantes de la soberanía y el Rey, evitando así una segunda cámara de aristócratas elegidos por el Rey. El proceso de elección se regulaba con todo detalle, mediante sufragio indirecto en cuatro grados: la primera elección era casi universal (varones mayores de edad) para luego ir restringiéndose conforme avanza hacia un sufragio censitario pasivo.

La legislatura era de dos años y regía el principio de automaticidad de la convocatoria, ya que no dependía de la voluntad real, se reunían cada año durante tres meses y se preveían sesiones extraordinarias. Además, había una Diputación Permanente que velaba por los poderes de la Cámara cuando ésta no estaba reunida.

Las sesiones, salvo que dispusieran lo contrario, eran públicas. Tenían potestad para crear su Reglamento de organización y funcionamiento interno, y se establecía la inviolabilidad de los diputados en sus opiniones y en el ejercicio de sus funciones, y la inmunidad en causas criminales contra ellos, que debían ser juzgadas por un Tribunal de las Cortes.

Ejercía la potestad legislativa junto con el Rey, ya que la iniciativa se atribuía a éste y al diputado individual. También tenía una potestad financiera en cuanto fijaba los gastos de la Administración y aprobaba el reparto de las contribuciones.

La figura del Rey se regulaba como un órgano constitucional que tenía poderes limitados (poder constituido) en la medida que compartía el poder político con otras instituciones (sobre todo, las Cortes). El Art. 172 pone de relieve un amplio número de materias en las que no podía intervenir. De sus funciones, cabe destacar la legislativa a través de 2 instrumentos: 1) iniciativa legislativa y 2) la sanción y promulgación de las leyes, así como la posibilidad de interponer un veto suspensivo de carácter temporal en determinadas condiciones.

El poder ejecutivo recae en el Rey, al tener la competencia sobre la dirección de la política interior y exterior, ejercicio de la función ejecutiva y potestad reglamentaria (en lo no atribuido a las Cortes) y la defensa. En esencia, parecidas a las ejercidas hoy en día por el Gobierno. La figura del Rey era inviolable y no sujeta a responsabilidad, articulándose en el texto constitucional la figura del referendo.

Se preveía la existencia de un Consejo de Estado, cuyos miembros eran nombrados por el Rey a propuesta de las Cortes, que asesoraban al Rey y no tenían función jurisdiccional (diferencia del Estatuto de Bayona). Sus dictámenes no eran vinculantes.

El Rey tenía la potestad vigente de crear normas espaciales por el desarrollo público del estado de vinculación directa parlamentaria.

Nombrados y separados por el Rey, estableciéndose un cargo incompatible con el de diputado (separación rígida de poderes). La Constitución no contemplaba al Gobierno como órgano colegiado. No obstante, la práctica condujo a la existencia del órgano de Gobierno (reunión de los Secretarios) presidido por el Rey y, mediante Decreto de 1824, por el Presidente del Consejo de Ministros en ausencia de este. Se configuraba este Presidente como un primus inter pares que dirigía las sesiones cuando no estuviera presente la figura del Rey.

Se reconocía la integración del Estado en comarcas y provincias con cierta descentralización incipiente de carácter administrativo. El gobierno se articulaba a través de Diputaciones y Ayuntamientos y se preveía la figura del Jefe Superior, nombrado por el Rey, al que se le confería el gobierno político de las provincias y presidencia de los Ayuntamientos (donde hubiere). Es una excepción al principio electivo, interferencia del poder central en las instituciones locales y un precedente de la institución del Gobernador civil.

Una vez producida la muerte de Fernando VII en 1833, la maquinaria del Estado estaba en manos de los liberales. El testamento otorgaba como sucesora a Isabel II y nombraba Reina Gobernadora a María Cristina, esposa del Rey. Durante la enfermedad del monarca y ante las pretensiones carlistas, la Corona se alía con los liberales concediendo una amplia amnistía e inicia un reformismo moderado que topa con la oposición carlista (en parte por motivos socioeconómicos y la cuestión foral).

La pretensión de abrir el sistema político a la participación de los liberales moderados se hará mediante la elaboración de una norma (Estatuto) con vocación transitoria. Fracasada la reforma de Cea Bermúdez, la Regente (en 1834) encarga la formación del Gobierno a Martínez de la Rosa quien, junto a Garelly y Javier de Burgos, será autor del Estatuto Real (que será sancionado el 10 de abril de ese mismo año).



Son bicamerales (no volverán a ser unicamerales hasta 1931) formadas por: Estamento de Próceres (cámara alta) y Estamento de Procuradores (cámara baja). Tiene reminiscencias del Antiguo Régimen: los Próceres son aristócratas sociales divididos entres los Grandes de España y los elegidos por el Rey. Eran cargos vitalicios, de número indeterminado, garantizándose con ello las mayorías suficientes a la monarquía. Los Procuradores, se basaba en el principio electivo de sus miembros pero se exigía una renta alta (sufragio censitario).

El Estatuto no contemplaba el sistema electoral y se remitía a leyes posteriores de diverso signo: la primera (1834) era de sufragio indirecto y censitario y la segunda (1836) sistema de elección directa y sufragio censitario y capacitario. Estaban a medio camino entre una asamblea consultiva y una legislativa. No tenían capacidad auto normativa, pues el Reglamento de ambas Cámaras debía ser aprobado por la Reina Gobernadora previo dictamen del Consejo de Gobierno y de Ministros. Además, se preveían constantes interferencias del Rey en el funcionamiento de las Cortes, lo que impide el principio de autonomía parlamentaria, quedando éstas reducidas a un organismo de colaboración y consulta del monarca.

Las leyes requerían la aprobación de las 2 cámaras y la subsiguiente sanción real, reconociéndose implícitamente la capacidad de veto absoluto del Rey. No disponían de automaticidad de convocatoria, pues era el Rey quien las convocaba, suspendía o disolvía.

Se le concedía un conjunto desorbitado de facultades:

Sin duda, es importante la "constitucionalización" de la figura del Presidente del Consejo de Ministros en varios pasajes. Aunque solo hable ocasionalmente de Gobierno, el resto de referencias van dirigidas al Consejo de Ministros. También recoge la denominación de Ministro frente a la de Secretario de Estado y del Despacho (heredada de la época de Felipe V). Aparece un incipiente proto-sistema de parlamentarismo al necesitar la doble confianza (Rey y Cortes) para gobernar y la aparición de la llamada "cuestión de gabinete" o "cuestión de confianza".

El sistema del Estatuto Real se mantuvo vigente hasta 1836, cuando la Guardia Real de la Granja impuso a la Reina Regente el restablecimiento de la Constitución de 1812 y la convocatoria de unas Cortes constituyentes. Sin embargo, ante la evidente imposibilidad política de restablecer la Constitución de 1812, los progresistas decidieron reformarla en un nuevo texto que fuese asimilable tanto para los progresistas como para los moderados, siendo el primer intento serio del constitucionalismo español en establecer una Constitución consensuada, en un momento álgido de la guerra civil para así mostrar, tanto interna como externamente -muchos países no olvidaban el caos europeo que supuso el restablecimiento de la norma gaditana- un frente liberal unido frente al carlismo.

Por ello, los progresistas hicieron concesiones importantes con el fin de que los moderados respaldasen la nueva norma:

No obstante, también se incluyeron ciertos credos progresistas como la elección popular de los Ayuntamientos y las Diputaciones Provinciales, y el restablecimiento de la Milicia Nacional.

Tras las tumultuosas regencias de la Reina Regente y del general Espartero, se disuelve el Senado, se proclama la mayoría de edad de la Reina Isabel II, y se convocan nuevas elecciones a Cortes, con victoria de los moderados liderados por el general Narváez, quienes deciden reformar la vigente Constitución por otra más acorde a sus ideas -a pesar de la oposición progresista y de algunos sectores moderados, que defendían la norma de 1837 porque había sido fruto del consenso político y que les serviría para alternarse en el poder sin tener que cambiar la Constitución cada vez que se cambiase el Gobierno-.

Por tanto, el texto resultante no fue una simple reforma del anterior -aunque fue la única Constitución española surgida del procedimiento de reforma estipulado en la anterior Constitución-, sino que establecieron cambios muy importantes:

Durante la Década Moderada (1844-1854) transcurrió la Revolución de 1848, se suspendieron las garantías constitucionales con el fin de evitar la propagación de la ola revolucionaria europea en España. Aprovechando este contexto y tras lograr firmar un nuevo concordato, en 1852 el moderado ultramontano Juan Bravo Murillo, el entonces primer ministro español elaboró un proyecto constitucional en 1852 cuyo objetivo era volver a una normativa más acorde al Antiguo Régimen o a un sistema basado en una Carta otorgada similar al derogado Estatuto Real de 1834, con la intención de atraerse a los sectores más proclives al carlismo.

Sin embargo, la oposición al nuevo proyecto constitucional fue de tal naturaleza, tanto entre los moderados como en los demás partidos, que no podía prosperar de ninguna manera.

Esta constitución non nata surgía como producto del Bienio progresista iniciado en 1854, que acabó con la Década moderada.

Su contenido reafirmaba de forma absoluta el principio de la soberanía nacional, de modo que nada se da por preconstituido y todas las instituciones, incluida la Corona, encontrarían su fundamento en la voluntad nacional. También se reconocía ampliamente los derechos políticos e instalaba, por primera vez en España, un régimen de tolerancia religiosa. Se continuó manteniendo el sufragio directo censitario, aunque el Senado volvería a ser electivo. Se restablecía además, al igual que lo hacía la Constitución de 1812, la Diputación permanente de las Cortes, cuya función era velar por la observancia de la Constitución cuando las Cortes estuviesen cerradas. Se trata de una constitución un tanto rígida; ya que establece un procedimiento difícil de reforma; procedimiento que en parte fue seguido por el resto de constituciones que se promulgaron con posterioridad.

No obstante, este proyecto constitucional no terminó siendo promulgado tras la contrarrevolución de 1856, liderada por el general O'Donnell.

Después de que la Corte huyera a Francia, el poder supremo se confió al general Serrano, que convocó Cortes constituyentes que elaboraron un nuevo texto constitucional.

Esta fue una constitución democrática que estuvo vigente hasta el año 1873. La soberanía era nacional y el poder estaba dividido: el poder legislativo lo tenían las cortes, el poder ejecutivo residía en el rey y el poder judicial en los tribunales. Se continuó con la religión católica como religión oficial del estado aunque el texto garantizaba el ejercicio de cualquier otra, en público o en privado, en su artículo 21. Sufragio universal masculino.

Elaborada durante la I República que no llegó a promulgarse, que definía España como una República Federal, integrada por diecisiete Estados, que se daban su propia Constitución y que poseerían órganos legislativos, ejecutivos y judiciales, según un sistema de división de competencias entre la Federación y los Estados miembros. Sin embargo, la imposibilidad de llegar a un acuerdo para articular el funcionamiento de los Estados dentro de la federación, impidió que llegara a buen fin el proyecto.

Tras el golpe de Estado del general Pavía en enero de 1874, no se consiguió que ningún grupo político ofreciera una fórmula estable de gobierno. Ante esta situación, el futuro Alfonso XII, desde Inglaterra, se dirigió a los españoles ofreciéndose para gobernar bajo la fórmula de monarquía liberal. El general Martínez Campos llevó a cabo el Pronunciamiento de Sagunto de diciembre de 1874, que pondría fin a la I República y que daría lugar a la Constitución de 1876.

La nueva Carta Magna propondría a Alfonso de Borbón, hijo de la destronada Isabel II de España como Jefe de Estado con ciertas prerrogativas —por ejemplo, la soberanía compartida o el veto real—. Aunque inicialmente era partidaria del sufragio censitario, la Constitución de 1876 se reforma en 1890 para traer el sufragio universal masculino. La Constitución de 1876 fue suspendida en 1923, tras el golpe de Estado del capitán general Miguel Primo de Rivera, lo que la hace la constitución más longeva de la historia de España (47 años).

El proyecto de Constitución de 1929, llamada Estatuto Fundamental de la Monarquía, fue un proyecto de constitución —o mejor de carta otorgada— elaborado por la Sección Primera de la Asamblea Nacional Consultiva designada por la Dictadura de Primo de Rivera en octubre de 1927. Pretendía ser la nueva ley fundamental de la Monarquía de Alfonso XIII en sustitución de la Constitución liberal de 1876, suspendida desde el triunfo del golpe de Estado de Primo de Rivera en septiembre de 1923. Quería instaurar en España un régimen autoritario, antiliberal y antidemocrático, ya que en su articulado se limitaba drásticamente el ejercicio de los derechos y libertades, no se establecía la división de poderes ni se reconocía la soberanía nacional, sólo la mitad de las Cortes unicamerales era elegida por sufragio universal, mientras que la otra mitad era designada por las "corporaciones" y por el rey, y sus poderes y atribuciones habían sido muy mermados en favor de la Corona y del Consejo del Reino, una nueva institución con rasgos del Antiguo Régimen —antecedente del organismo del mismo nombre de la Dictadura franquista—. El proyecto rompía con toda la historia del constitucionalismo español y no satisfizo a nadie, ni siquiera al dictador, debido a los amplios poderes que concedía al rey en detrimento del jefe del gobierno, por lo que no llegó a discutirse en el Pleno de la Asamblea Nacional Consultiva y nunca entró en vigor.

La constitución republicana de 1931, nacida de unas elecciones municipales y de la posterior renuncia al trono por parte de Alfonso XIII introduce por primera vez algunas innovaciones del constitucionalismo contemporáneo, como son la renuncia a la guerra como forma de resolución de conflictos internacionales, o la inclusión, a partir de las teorías de Kelsen, de un Tribunal Constitucional, llamado Tribunal de Garantías Constitucionales. Introduce también, por primera vez, la descentralización del Estado, por medio de las Regiones Autónomas, anticipo de la organización territorial de la constitución de 1978.

Las profundas contradicciones de la sociedad española de los años veinte y treinta desembocarán en la Guerra Civil Española, tras la cual se instaurará la dictadura del General Francisco Franco, que supondrá la derogación de esta constitución y su sustitución por las Leyes Fundamentales del Reino, vigentes hasta la aprobación de la última constitución democrática de 1978.

Por tales se conoce el conjunto de leyes que establecían el entramado político-institucional del modelo de Estado instaurado por el general Francisco Franco tras la Guerra Civil Española.

La primera fue el Fuero del Trabajo que regulaba la vida laboral y económica. La Ley Constitutiva de las Cortes de 1942 establecía las Cortes como instrumento colaborador. En el Fuero de los Españoles de 1945 se fijaron los derechos y deberes de los españoles. La Ley del Referéndum Nacional de 1945 regulaba el referéndum. Por la Ley de Sucesión en la Jefatura del Estado de 1947 España se configura como un reino. La Ley de Principios del Movimiento Nacional de 1958 señala los principios rectores del ordenamiento jurídico y la Ley Orgánica del Estado de 1967, reforma todas las anteriores y fija los poderes del jefe del Estado.

Finalmente, la Ley para la Reforma Política de 1977 fue el instrumento jurídico que permitió articular la Transición española.

Nacida de la reforma legal realizada por las Cortes Españolas que condujo a la Ley para la reforma política, y fruto de la negociación entre los diversos partidos políticos surgidos tras las elecciones generales de España de 1977; consensuándose así una carta magna en donde participaron políticos que representaban a la inmensa pluralidad de las diferentes ideologías políticas, tanto del espectro derecha-izquierda como de los diversos posicionamientos sobre la vertebración territorial, social y económica de España. Esta constitución acoge la monarquía parlamentaria como forma política del Estado; asume la asunción de los valores democráticos, sociales y del Estado de Derecho, así como la recuperación de la organización territorial de la constitución republicana de 1931. La constitución de 1978 es la única refrendada y aprobada por el pueblo español mediante referéndum.

La cronología utilizada es la de su fecha de promulgación, que difiere de los períodos de vigencia y así:






</doc>
<doc id="1381" url="https://es.wikipedia.org/wiki?curid=1381" title="Haloragaceae">
Haloragaceae

Las Haloragaceae son una familia del orden Saxifragales.

Son plantas herbáceas o sufrutescentes, perennes, acuáticas o terrestres; tallos rizomatosos o erectos; plantas hermafroditas o monoicas. Hojas alternas, opuestas o verticiladas, simples o pectinadas, estipuladas o con las estípulas como escamas. Flores solitarias y axilares o en espigas, racimos o panículas terminales; flores unisexuales o raramente perfectas, epíginas; perianto ausente, uniseriado o biseriado; sépalos ausentes o 2–4; pétalos ausentes o 2–4, deciduos, libres, más grandes que los sépalos; estambres ausentes o 4 u 8, libres, frecuentemente en 2 verticilos y entonces los exteriores opuestos a los pétalos, anteras basifijas, 2-loculares, con dehiscencia longitudinal; carpelos 4, unidos, lóculos 1–4, óvulos 1 por lóculo, anátropos, estigmas frecuentemente plumosos. Frutos nuececillas o drupas, anguladas, sulcadas o aladas; semilla con testa membranácea, embrión recto, cilíndrico u obcordiforme, endosperma abundante, carnoso.
Fórmula floral:
formula_1 or formula_2

Frutos nuciformes o esquizocárpicos. Unas 180 especies.

Bastante cosmopolita, en el Hemisferio Sur, y la mayoría australianas. "Haloragis" no está en Europa

La familia fue descrita por Robert Brown y publicado en "A Voyage to Terra Australis" 2: 549. 1814. El género tipo es: "Haloragis"
Nueve Gros., 145 spp.:

El taxón de la más tempranas familia Cercodiaceae y Myriophyllaceae están ahora incluidas en la familia Haloragaceae. Antes, el género "Gunnera" estaba en esta familia.



</doc>
<doc id="1383" url="https://es.wikipedia.org/wiki?curid=1383" title="Hippocastanaceae">
Hippocastanaceae

Las Hippocastanaceae es una pequeña familia de árboles y arbustos integrada por tres géneros y unas 25 especies de América del Norte, Asia y la península balcánica.

Hojas opuestas, palmadas o imparipinnadas. Flores hermafroditas o unisexuales, ligeramente zigomorfas, pentámeras y de ovario súpero, dispuestas en inflorescencias paniculiformes. Fruto en cápsula loculícida.

Los miembros de esta familia están estrechamente emparentados con la familia Sapindaceae, mayoritariamente tropical. Los sistemas de clasificación actuales incluyen a los miembros de las Hippocastanaceae junto con los de Aceraceae, entre otros, en las Sapindaceae "sensu lato".

Recientes estudios moleculareshan demostrado que mientras las Aceraceae y Hippocastanaceae son monofilético en sí mismos, su separación de las Sapindaceae "sensu lato", Juss. "nom. cons." dejaría las Sapindaceae "sensu stricto" como un grupo parafilético. Por lo tanto, es ahora considerada como un simple sinónimo de la subfamilia Hippocastanoideae, Dumortier de las Sapindaceae "sensu lato", las Sapindaceae "sensu stricto" quedándose también como mera subfamilia Sapindoideae Burnett.

Su interés económico es escaso y se reduce al cultivo de algunas especies, como ornamentales y de sombra, a su madera, que es de escasa calidad y al empleo medicinal del castaño de indias.



</doc>
<doc id="1385" url="https://es.wikipedia.org/wiki?curid=1385" title="La bestia en la cueva">
La bestia en la cueva

La bestia en la cueva (título original en inglés: "The Beast in the Cave") es uno de los primeros cuentos de H. P. Lovecraft, escrito cuando contaba tan solo quince años de edad. Se reduce a un mero ejercicio de recreación o imitación de los cuentos de terror gótico, casi rayando el plagio. No obstante, es curioso poder constatar la tradición gótica en un temprano Lovecraft.



</doc>
<doc id="1386" url="https://es.wikipedia.org/wiki?curid=1386" title="Himno Europeo">
Himno Europeo

El himno de la Unión Europea, oficialmente Himno Europeo, es uno de los cuatro símbolos oficiales de la Unión Europea. El himno tiene su origen en la "Oda a la Alegría" ("An die Freude" en alemán), escrita por Friedrich von Schiller en 1785 y la composición realizada por Ludwig van Beethoven para su novena sinfonía. Fue adoptado oficialmente en 1985.

Este himno, según la Unión Europea, no sustituye a los himnos nacionales de los países de la UE, sino que "celebra los valores que todos ellos comparten".

En 1793, a la edad de 23 años, Ludwig van Beethoven conoció la obra del escritor alemán, y desde ese momento manifestó su inspiración y deseo de ponerle música. El 7 de mayo de 1824, diez años después de la Octava Sinfonía, Beethoven presenta en el Teatro de la Corte Imperial de Viena su Novena Sinfonía en RE Menor, Op. 125 -posteriormente conocida como “Coral”- cuyo cuarto y último movimiento concibió para ser interpretado por un coro y solistas basándose en la "Oda a la Alegría".

En 1971, la Asamblea Parlamentaria del Consejo de Europa (no confundir con el Consejo de la Unión Europea) decidió proponer la adopción de la antesala de la "Oda a la Alegría" de la Novena Sinfonía de Beethoven como himno, tomando la sugerencia hecha por el conde austriaco Richard Nikolaus Graf von Coudenhove-Kalergi en 1955. Beethoven fue visto generalmente como la mejor elección para un himno de Europa. El 19 de enero de 1972, el Consejo de Europa anunció finalmente la elección de la "Oda a la Alegría" como himno europeo. 

Herbert von Karajan, uno de los más grandes directores contemporáneos, accedió a una petición del Consejo de la Unión Europea de escribir tres arreglos instrumentales para solo de piano, viento y orquesta sinfónica, con los que se hizo oficial en 1985 como Himno de la Unión Europea tras la aprobación de los jefes de Estado y de Gobierno de la UE, siendo interpretado por primera vez de manera oficial el 29 de mayo de ese mismo año.

El Consejo de Europa es una institución diferente al Consejo de la Unión Europea y agrupa a países miembros de la Unión, pero también a países que no lo son, es por ello que el himno es el mismo para el Consejo de Europa y para la UE.

En marzo de 2004, el Consejo de Europa lanzó un CD con varias versiones del himno europeo, entre ellas la primera versión rap.

Debido al gran número de idiomas utilizados en la Unión Europea, el himno es puramente instrumental, y la letra en alemán de Friedrich Schiller no tiene carácter oficial. A pesar de esto, las letras alemanas suelen ser cantadas por los coros y la gente común cuando el himno toca en algunos actos oficiales, como ya ocurrió en la ampliación de la UE en 2004, en la frontera entre Alemania y Polonia.

A pesar de esto, se ha intentado en varias ocasiones dotarle de letra al himno. Recientemente, el latín, como antigua lengua de mucho países europeos, fue el lenguaje propuesto por el compositor austriaco Peter Roland. El compositor ofreció una copia de su versión a Romano Prodi, entonces presidente de la Comisión Europea durante una reunión en Viena en febrero de 2004.

En Francia, varias adaptaciones de la Oda eran conocidas mucho antes de la aparición de la Unión Europea. Se publicó una versión de Maurice Bouchor (1855-1929) titulada "Himno a la humanidad universal" ("Hymne à l'humanité universelle"), que añadía varios versos a otro texto anterior de Jean Ruault. Esta versión y otra por Maurice Bouchor y Julien Thiersot bajo el título "Himno de los tiempos futuros" ("Hymne des temps Futurs") que fue publicada en un libro de música está muy extendida entre las escuelas básicas, donde se suele tocar de forma no oficial durante los eventos europeos. También se conoce otra versión por el escritor católico Folliet Joseph (1903-1972).

Existe también un proyecto de la Comisión Europea (CE) para dotarlo de un texto que represente los ideales de la Unión. Peter Roland ha preparado tres estrofas en latín relacionadas con la paz y la Europa unida en la diversidad, haciendo eco al lema de la UE: "Unida en la Diversidad".

Existe también una versión de Miguel Ríos escrita en 1970.

Aún más reciente es la propuesta del partido Unión Europea de Esperanto (EEU) que ofrece un texto en esperanto, escrito por el expresidente de la EEU Umberto Broccatelli. En la página web de EEU se pueden encontrar traducciones de este texto en 37 idiomas, incluyendo los idiomas oficiales de la UE. Como parte de una iniciativa ciudadana europea, el 1 de abril de 2012 la EEU presentó como propuesta a la Comisión Europea que "la Unión Europea recomiende cantar el himno europeo en el idioma neutral esperanto, como propone Umberto Broccatelli, cuando los representantes de los Estados miembros quieran expresar conjuntamente su pertenencia a una Europa común y de iguales derechos".




</doc>
<doc id="1387" url="https://es.wikipedia.org/wiki?curid=1387" title="Hélice alfa">
Hélice alfa

Son estructuras secundarias de las proteínas, esta hélice mantiene su forma por la presencia de los puentes de hidrógeno que se forman entre los átomos de oxígeno del grupo carbonilo de un aminoácido y el átomo de hidrógeno del grupo amino de otro aminoácido situado a cuatro aminoácidos de distancia en la cadena. Los grupos R se extienden hacia afuera desde la hélice. 
Es una estructura anfipática porque posee una parte hidrofílica y una parte hidrófoba, lo que produce el enrollamiento de esta estructura, de manera que la parte hidrófoba no interactúe con el agua. 

En las proteínas, la hélice α es el principal motivo de estructura secundaria. Fue postulada primero por Linus Pauling, Robert Corey, y Herman Branson en 1951 basándose en las estructuras cristalográficas entonces conocidas de aminoácidos y péptidos y en la predicción de Pauling de la forma planar de los enlaces peptídicos.

Los aminoácidos en una hélice α están dispuestos en una estructura helicoidal dextrógira, con unos 3,6 aminoácidos por vuelta. Cada aminoácido supone un giro de unos 100° en la hélice, y los Cα de dos aminoácidos contiguos están separados por 1,5Å. La hélice está estrechamente empaquetada; de forma que no hay casi espacio libre dentro de la hélice. Todas las cadenas laterales de los aminoácidos están dispuestas hacia el exterior de la hélice. 

El grupo N-H del aminoácido (n) puede establecer un enlace de hidrógeno con el grupo C=O del aminoácido (n+4). De esta forma, cada aminoácido (n) de la hélice forma dos puentes de hidrógeno con su enlace peptídico y el enlace peptídico del aminoácido en (n+4) y en (n-4). En total son 7 enlaces de hidrógeno por vuelta. Esto estabiliza enormemente la hélice. Está dentro de los niveles de organización de la proteína.

Los cuatro primeros aminoácidos de la hélice, tal conocida como alfa, y los cuatro últimos solo podrán formar un enlace de hidrógeno en vez de dos, por lo tanto la hélice α suele ser más estable en la zona central que en los extremos. Para compensar esta pérdida, los aminoácidos de los extremos suelen ser polares y forman puentes de H con sus cadenas laterales y la cadena lateral de otros aminoácidos de la hélice. Cuando dos hélices alfa se aproximan entre si tienden a interaccionar con ángulos de -30 y 60o.

En la hélice los momentos dipolares de todos los aminoácidos están perfectamente alineados, con lo que se forma un dipolo total con una carga parcial positiva en el extremo N-terminal y una carga parcial negativa en el extremo C-terminal. 

En una hélice α, las cadenas laterales de los aminoácidos en posición (n) y en posición (n+4) quedan alineados. De forma que si en esas posiciones ponemos dos aminoácidos con carga de igual signo o muy voluminosos se desestabiliza la hélice.

Algunos aminoácidos, llamados "disruptores de hélices", pueden desestabilizar la estructura helicoidal. Uno de ellos es la prolina, que al ser un iminoácido (aunque algunos autores cuestionan que la prolina no es en rigor un iminoacido), el N de su enlace peptídico no tiene unido un H para formar un enlace de hidrógeno con el aminoácido en (n+4). Además el metileno unido al N del enlace peptídico también provoca impedimentos estéricos que hacen que la hélice tienda a romperse en el punto donde esté la prolina, aunque no lo hará si esta es suficientemente larga y estable. La glicina al tener una gran flexibilidad puesto que su cadena lateral es solo un H, suele estar en los acodamientos al final de la hélice.

Al primer aminoácido de una hélice en el extremo N-terminal se le llama N-cap y al último aminoácido de la hélice, en el extremo C-terminal se le llama C-cap. 
En posición N-cap, suelen aparecer aminoácidos polares no cargados, como la asparagina, o cargados negativamente, como el ácido glutámico, de forma que se compense la pérdida de un enlace peptídico en los extremos de la hélice que ya hemos comentado y en el caso del glutámico, la carga negativa de su cadena lateral interacciona con la carga parcial positiva del extremo N-terminal de la hélice.

En el C-cap son frecuentes la glicina y la prolina, que como ya hemos comentado rompen la estructura de la hélice, y también aminoácidos cargados positivamente, como la lisina, cuya carga positiva interacciona con la carga parcial negativa del extremo C-terminal de la hélice.

Los polipéptidos cortos habitualmente no son capaces de adoptar la estructura de hélice alfa, ya que el coste entrópico asociado con el plegamiento de la cadena polipeptídica es demasiado alto.

Las hélices α además de ser el tipo de estructura secundaria más frecuente en las proteínas, son de gran importancia en los motivos estructurales de unión al DNA, como los motivos hélice-giro-hélice y los dedos de zinc. Esto se debe que el diámetro de 12Å de la hélice α coincide con la anchura de la hendidura mayor del DNA en forma B o B-DNA.

Existen otros tipos de estructuras helicoidales similares a la hélice α en las proteínas, pero mucho menos comunes:



Julian Voss-Andreae es un escultor alemán con grados académicos en física experimental y escultura. Desde el año 2001 Voss-Andreae crea "esculturas de proteínas" inspiradas en la estructura proteica, siendo la hélice α uno de sus objetos preferidos. Este artista ha fabricado esculturas de hélice α a partir de diversos materiales, como bambú y otros árboles. En el año 2004 realizó un monumento en memoria de Linus Pauling, descubridor de la hélice alfa, diseñado a partir de una gran viga de acero reordenada según la forma de la estructura de la hélice alfa. La escultura de color rojo brillante y 3 metros de altura se ubica frente a la casa de infancia de Pauling en Portland, Oregón.




</doc>
<doc id="1388" url="https://es.wikipedia.org/wiki?curid=1388" title="Hélice de colágeno">
Hélice de colágeno

La hélice de colágeno es un tipo de estructura secundaria de las proteínas que solamente la presenta el colágeno, que está formado por unas unidades denominadas tropocolágeno, y son estas las que presentan la hélice colágena.

Este tipo de estructura está constituida por tres cadenas polipeptídicas que se enrollan de forma levógira. Esta hélice es lo que constituye la hélice triple de colágeno.

No están tan enrolladas como las hélices alfa. La hélice del colágeno contiene tres aminoácidos por vuelta, mientras que la hélice alfa contiene 3,6.

Una característica de estas estructuras es la composición en cuanto a aminoácidos, que sigue el mismo patrón Gly-X-Y-Gly-X-Y etc. y es para todas las cadenas. X e Y son cualquier aminoácido, aunque existen preferencias por la prolina, hidroxiprolina y en menor proporción por la lisina. La glicina es el aminoácido más pequeño y el único capaz de colocarse dentro de la hélice, los demás siempre hacia afuera. La hélice la favorecen los más pequeños.

La estabilidad se mantiene por los enlaces de hidrógeno entre el grupo amino de los enlaces peptídicos en los que participa la glicina y el carbonilo de cualquier enlace peptídico. Los enlaces se establecen tanto en cada hebra como entre hebras, por lo tanto son enlaces intermoleculares intercatenarios.

También contribuyen a la estabilidad las fuerzas de van der Waals, estas interacciones son de tipo físico (por atracción entre aminoácidos).

También se pueden formar enlaces covalentes entre restos de aminoácidos (lys). Estos suelen ser entre cadenas, se forma de manera espontánea y se puede destruir con el calor.


</doc>
<doc id="1389" url="https://es.wikipedia.org/wiki?curid=1389" title="Proteína conjugada">
Proteína conjugada

Las proteínas conjugadas o heteroproteínas son moléculas que presentan una parte proteica (apoproteína) y otra no proteica menor (grupo prostético). Esto las diferencia de las proteínas simples u holoproteínas. Todas son globulares, y se clasifican en función del grupo prostético.



</doc>
<doc id="1390" url="https://es.wikipedia.org/wiki?curid=1390" title="Holoproteína">
Holoproteína

Una holoproteína es una proteína que está conformada exclusivamente por una secuencia de aminoácidos. Es sinónimo de proteína simple. 

Las holoproteínas se clasifican en:

Estas proteínas son solubles en agua, se encuentran en todas las células del cuerpo y también en el torrente sanguíneo. Algunos ejemplos de albúminas son las lacto albúminas que se encuentran en la leche y las seroalbúminas que se encuentran en la sangre.
Estas proteínas son insolubles en agua pero son solubles en soluciones salinas diluidas con fuertes ácidos y sus bases. Los ejemplos de globulinas son la lactoglobulina de la leche y la ovoglobulina.

Estas proteínas son solubles en ácidos diluidos y en álcalis. La proteína de glutelina de trigo es un buen ejemplo de glutelinas. Éstas, sólo se producen en el material vegetal.

Estas proteínas son solubles en un 70 u 80% de alcohol. Entre ellas podemos destacar el fliadin de trigo y la zeína del maíz. Se encuentran únicamente en los materiales vegetales.

Los albuminoides o las selenoproteinas son insolubles en todos los disolventes neutros, en los álcalis diluidos y en los ácidos. Se encuentran en los tejidos conectivos, en el cabello y en las uñas. Algunos ejemplos son la queratina, que se encuentra en las capas queratinizadas de la piel y en la corteza o córtex del cabello y de las uñas y el colágeno que se encuentra en las fibras blancas del tejido areolar.

Éstas son proteínas solubles en agua en la que los ácidos básicos aminados son predominantes. Son ricos en arginina o en lisina. Las eucariotas del ADN de los cromosomas se asocian con las histonas en la formación de las nucleoproteínas.

Estas proteínas son solubles en agua y en polipéptidos básicos de bajo peso molecular (aproximadamente de unos 4.000 daltons). Son muy ricos en aminoácidos argininos. La cadena polipeptídica consiste en 28 residuos de aminoácidos, entre los que se incluyen 19 argininas y 8 o 9 aminoácidos no básicos. Las protaminas se encuentran unidas al ADN de los espermatozoides de algunos peces. Algunos ejemplos de protaminas son la salmina (del salmón) y la esturina (de los esturiones).


</doc>
<doc id="1392" url="https://es.wikipedia.org/wiki?curid=1392" title="Hipoglucemia">
Hipoglucemia

La hipoglucemia, también conocido como hipoglicemia (no debe confundirse con su antónimo, hiperglucemia), es un estado definido por una concentración de glucosa en la sangre anormalmente baja, inferior a 50-60 mg / 100 ml. Se suele denominar shock insulínico, por la frecuencia con que se presenta en pacientes con diabetes mellitus en tratamiento con insulina. Generalmente se asocia con alteraciones o pérdida del conocimiento.

La hipoglucemia muy a menudo es resultado del tratamiento para la diabetes mellitus. A continuación se listan otros factores que deben considerarse en cualquier paciente con hipoglucemia:

1. Fármacos: antidiabéticos orales (sobre todo clorpropamida, repaglinida, nateglinida), alcohol, dosis altas de saliciatos, sulfonamidas, pentamidina, quinina,quinolonas. 

2. Enfermedad grave: insuficiencia hepática, renal o cardiaca; septicemia, inanición prolongada.

3. Deficiencias hormonales: insuficiencia suprarrenal, hipopituitarismo.

4. Insulinoma: tumor de células B pancreáticas, hiperplasia de células B (conocida como nesidioblastosis, ya sea congénita, o posterior a cirugía gástrica o bariátrica)

5. Otras etiologías raras: tumores de células no B (tumores mesenquiomatosos grandes o epiteliales que producen factor de crecimiento similar a insulina ll, otros tumores no pancreáticos), insulina o anticuerpos contra el receptor para insulina, defectos enzimáticos hereditarios.

La hipoglucemia puede deberse a diversas causas. En personas sanas suele ser consecuencia de un ayuno muy prolongado debido a que el organismo sigue utilizando glucosa, una vez que ya no queda glucógeno en el hígado para producirla.
Un ejercicio intenso acompañado de poca ingesta previa puede provocar hipoglucemia.
En personas que padecen diabetes mellitus es muy habitual. En este caso, suele deberse a un fallo en la administración de insulina exógena o de medicamento oral antiadiabético. Si se administra cuando no se ha comido lo suficiente, los niveles de glucosa pueden bajar hasta producir una hipoglucemia severa. En este tipo de pacientes también se puede producir por un exceso de ejercicio unido a una escasa ingesta de alimentos ya que la actividad física promueve la utilización de glucosa por los tejidos.

Hay que vigilarla especialmente en niños menores de 6 años, ya que puede perjudicar al desarrollo cerebral.

También puede causar hipoglucemia el consumo de alcohol debido a los efectos inhibidores de la neo glucogénesis hepática. Para que esto ocurra el glucógeno hepático debe haberse consumido. Esto se da en el ejercicio intenso y en el ayuno prologado.

En términos generales, la hipoglucemia es el resultado de dos factores: 

Cuando el cuerpo produce glucagón y adrenalina, logra corregir cualquier exceso de insulina (que haga bajar demasiado los niveles glucémicos) y logra avisarnos de que no hay suficiente glucosa circulando para permitir la función normal del cuerpo. Pero el proceso de corrección es imperfecto o ausente en la mayoría de las personas con DM. Por este defecto, el azúcar en sangre baja a niveles hipoglucémicos cuando la insulina esté activa y presente en una cantidad excesiva para la cantidad de carbohidrato presente en la sangre. Si se administra insulina cuando los niveles de glucosa en sangre son normales, puede haber un episodio de hipoglucemia. Si la cantidad de actividad física es mayor a la prevista, la cantidad de insulina o medicamento oral presente en el cuerpo puede resultar excesiva, lo cual podría iniciar un episodio de hipoglucemia. También se puede dar un episodio de hipoglucemia si a la persona con DM1 ó DM2 se le administra insulina o el medicamento oral y luego decide no comer en las siguientes horas. La manera más confiable de saber si se tiene, o se está cerca de tener, un episodio de hipoglucemia es utilizando el medidor casero de glucosa.

Se producen sensaciones muy variadas como:
Un síntoma que identifica esta condición temporal es un dolor en el centro del pecho, lo mejor es tomar un refresco o un dulce para elevar los niveles de glucosa en la sangre.

Si no se ingieren hidratos de carbono, se puede sufrir de convulsiones, pérdida de conciencia, coma, daño cerebral y muerte.



Para evitar recaídas se recomienda que se cambien los hábitos alimenticios del paciente para que haya glucosa disponible en sangre a lo largo de todo el día. Están aconsejadas comidas reducidas y con mayor frecuencia (5 o 6 veces al día), que incluyan hidratos de carbono de digestión y absorción lenta. En lo posible habría que evitar el consumo de alcohol y los azúcares de rápida absorción.






</doc>
<doc id="1393" url="https://es.wikipedia.org/wiki?curid=1393" title="Hidrocarburo">
Hidrocarburo

Los hidrocarburos son compuestos orgánicos formados únicamente por átomos de carbono e hidrógeno. Los hidrocarburos son los compuestos básicos que estudia la química orgánica. Las cadenas de átomos de carbono pueden ser lineales o ramificadas, y abiertas o cerradas. Los que tienen en su molécula otros elementos químicos (heteroátomos) se llaman hidrocarburos sustituidos.

La mayoría de los hidrocarburos que se encuentran en nuestro planeta ocurren naturalmente en el petróleo crudo, donde la materia orgánica descompuesta proporcionó una abundancia de carbono e hidrógeno, los que pudieron catenarse para formar cadenas aparentemente ilimitadas. Los hidrocarburos pueden encontrarse también en algunos planetas sin necesidad de que haya habido vida para generar petróleo, como en Júpiter, Saturno, Titán y Neptuno, compuestos parcialmente por hidrocarburos como el metano o el etano.

Los hidrocarburos se pueden clasificar en dos tipos: alifáticos y aromáticos. Los alifáticos, a su vez se pueden clasificar en alcanos, alquenos y alquinos según los tipos de enlace que unen entre sí los átomos de carbono. Las fórmulas generales de los alcanos, alquenos y alquinos son CH, CH y CH, respectivamente.

Hidrocarburos saturados o alcanos: Son compuestos formados por carbono e hidrógeno, presentan enlaces sencillos (SP3). Presenta una fórmula general (CnH2n+2), donde n es el número de carbonos del compuesto y el sufijo o y su terminación es ano.

CH4→ Metano

C2H6→Etano

C3H8→Propano

C4H10→Butano

C5H12→Pentano

C6H14→ Hexano

C7H16→Heptano

C8H18→Octano

C9H20→Nonano

C10H22→Decano.
De acuerdo al tipo de estructuras que pueden formar, los hidrocarburos se pueden clasificar en:

Los sistemas policíclicos se pueden clasificar por su complejidad en: 




Según los enlaces entre los átomos de carbono, los hidrocarburos se clasifican en:

Los hidrocarburos extraídos directamente de formaciones geológicas en estado líquido se conocen comúnmente con el nombre de petróleo, mientras que los que se encuentran en estado gaseoso se les conoce como gas natural.

La explotación comercial de los hidrocarburos constituye una actividad económica de primera importancia, pues forman parte de los principales combustibles fósiles (petróleo y gas natural), así como de todo tipo de plásticos, ceras y lubricantes.

Según los grados API, se clasifican en:

formula_1

Si es:

Los hidrocarburos sustituidos son compuestos que tienen la misma estructura que un hidrocarburo, pero que contienen átomos de otros elementos distintos al hidrógeno y el carbono en lugar de una parte del hidrocarburo. La parte de la molécula que tiene un ordenamiento específico de átomos, que es el responsable del comportamiento químico de la molécula base, recibe el nombre de grupo funcional.

Por ejemplo:

Los compuestos halogenados tienen como grupo funcional los átomos de halógenos. Tienen una alta densidad. Se utilizan en refrigerantes, disolventes, pesticidas, repelentes de polillas, en algunos plásticos y en funciones biológicas: hormonas tiroideas. Por ejemplo: cloroformo, diclorometano, tiroxina, Freón, DDT, PCBs, PVC.
La estructura de los compuestos halogenados es: "R-X", en donde X es flúor (F), cloro (Cl), bromo (Br) y yodo (I), y R es un radical de hidrocarburo.

Las intoxicaciones por hidrocarburos tienden a causar cuadros respiratorios relativamente severos. La gasolina, el queroseno y los aceites y/o barnices para el tratamiento de muebles, que contienen hidrocarburos, son los agentes más comúnmente implicados en las intoxicaciones. El tratamiento a menudo requiere intubación y ventilación mecánica. Inducir el vómito en estos sujetos está contraindicado porque puede causar más daño esofágico.

Los microorganismos se consideran como seres capaces de adaptarse y adaptar su metabolismo en función de las condiciones ambientales en las que se desarrollen y los parámetros físico-químicos que presenten, lo que les permite también desarrollarse en lugares donde están presentes los hidrocarburos. 

Existen alrededor de 160 géneros de microorganismos que degradan los hidrocarburos, entre los principales se encuentran:



</doc>
<doc id="1394" url="https://es.wikipedia.org/wiki?curid=1394" title="Hercio">
Hercio

El hercio o hertz (símbolo Hz) es la unidad de frecuencia del Sistema Internacional de Unidades.

Nombrado en honor al físico alemán Heinrich Rudolf Hertz (1857-1894), que descubrió la propagación de las ondas electromagnéticas. El nombre fue establecido por la Comisión Electrotécnica Internacional (IEC por sus siglas en inglés) en 1930. Este fue adoptado en 1960 por la CGPM (Conférence Générale des Poids et Mesures: Conferencia General de Pesos y Medidas), reemplazando el nombre anterior de "cps" ("ciclos por segundo"), así como sus múltiplos relacionados:
El término "ciclo por segundo" fue completamente reemplazado por "hercio" en la década de 1970. Es además usado en las curvas senoides, que representan ondas sonoras.

Un hercio representa un ciclo por cada segundo, entendiendo "ciclo" como la repetición de un suceso. Por ejemplo, el hercio se aplica en física a la medición de la cantidad de veces por un segundo que se repite una onda (ya sea sonora o electromagnética) o puede aplicarse también, entre otros usos, a las olas de mar que llegan a la playa por segundo o a las vibraciones de un sólido. La magnitud que mide el hercio se denomina frecuencia y es, en este sentido, la inversa del período. Un hercio es la frecuencia de una oscilación que sufre una partícula en un período de un segundo.

La conversión entre una frecuencia formula_1 medida en hercios y una velocidad angular formula_2 medida en radianes por segundo es
A continuación una tabla de los múltiplos y submúltiplos del SI (Sistema Internacional de Unidades).



</doc>
<doc id="1395" url="https://es.wikipedia.org/wiki?curid=1395" title="Edad Antigua">
Edad Antigua

La Edad Antigua es la época histórica que coincide con el surgimiento y desarrollo de las primeras civilizaciones o civilizaciones antiguas. Tradicionalmente, se ha considerado la invención de la escritura como el punto de partida de la historia antigua. El concepto más tradicional de la historia antigua presta atención a la invención de la escritura, que convencionalmente la historiografía la ha considerado el hito que permite marcar el final de la prehistoria y el comienzo de la historia, dada la primacía que otorga a las fuentes escritas frente a la cultura material, que estudia con su propio método la arqueología. Otras orientaciones procuran atender al sistema social o al nivel técnico. Por último, los estudios de genética de poblaciones basados en distintas técnicas de análisis comparativo de ADN y los estudios de antropología lingüística están llegando a reconstruir de un modo cada vez más preciso las migraciones antiguas y su herencia en las poblaciones actuales.

Sea cual fuera el criterio empleado, coincidiendo en tiempo y lugar, unos y otros procesos cristalizaron en el inicio de la vida urbana (ciudades muy superiores en tamaño, y diferentes en función, a las aldeas neolíticas); en la aparición del poder político (palacios, reyes) y de las religiones organizadas (templos, sacerdotes); en una compleja estratificación social; en grandes esfuerzos colectivos que exigen la prestación de trabajo obligatorio; en el establecimiento de impuestos y el comercio de larga distancia (todo lo que se ha venido en llamar «revolución urbana»). Este nivel de desarrollo social, que por primera vez se alcanzó en la Sumeria del IV milenio a. C. (espacio propicio para la constitución de las primeras ciudades-estado competitivas a partir del sustrato neolítico), llevaba ya cuatro milenios desarrollándose en el Creciente Fértil. A partir de ellas, y de sucesivos contactos (tanto pacíficos como violentos) de pueblos vecinos (culturas sedentario-agrícolas o nómada-ganaderas que se nombran tradicionalmente con términos de validez cuestionable, más propios de familias lingüísticas que de razas humanas: semitas, camitas, indoeuropeos, etc.), se fueron conformando los primeros estados de gran extensión territorial, hasta alcanzar el tamaño de imperios multinacionales.
Procesos similares tuvieron lugar en diversos momentos según el área geográfica (sucesivamente Mesopotamia, el valle del Nilo, el subcontinente indio, China, la cuenca del Mediterráneo, la América precolombina y el resto de Europa, Asia y África); en algunas zonas especialmente aisladas, algunos pueblos cazadores-recolectores actuales aun no habrían abandonado la prehistoria mientras que otros entraron violentamente en la edad moderna o la contemporánea de la mano de las colonizaciones de los siglos XVI al XIX.

Los pueblos cronológicamente contemporáneos a la Historia escrita del Mediterráneo Oriental pueden ser objeto de la protohistoria, pues las fuentes escritas por romanos, griegos, fenicios, hebreos o egipcios, además de las fuentes arqueológicas, permiten hacerlo.

La Antigüedad clásica se localiza en el momento de plenitud de la civilización grecorromana (siglo V a. C. al II d. C.) o, en sentido amplio, en toda su duración (siglo VIII a. C. al V d. C.). Se caracterizó por la definición de innovadores conceptos sociopolíticos —los de ciudadanía y de libertad personal, no para todos, sino para una minoría sostenida por el trabajo esclavo—, a diferencia de los imperios fluviales del antiguo Egipto, Babilonia, India o China, para los que se definió la imprecisa categoría de «modo de producción asiático», caracterizados por la existencia de un poder omnímodo en la cúspide del imperio y el pago de tributos por las comunidades campesinas sujetas a él, pero de condición social libre (pues aunque exista la esclavitud, no representa la fuerza de trabajo principal). El papel de las mujeres en esta época fue olvidado.

El final de la Edad Antigua en la civilización occidental coincide con la caída del Imperio romano de Occidente, en el año 476 (el Imperio romano de Oriente sobrevivió toda la Edad Media hasta 1453 como Imperio bizantino), aunque tal discontinuidad no se observa en otras civilizaciones. Por tanto, las divisiones posteriores (Edad Media y Edad Moderna) pueden considerarse válidas solo para aquella, mientras que la mayor parte de Asia y África, y con mucha más claridad América, son objeto en su historia de una periodización propia.
Algunos autores culturalistas hacen llegar la Antigüedad tardía europea hasta los siglos VI y VII, mientras que la escuela «mutacionista» francesa la extiende hasta algún momento entre los siglos IX y XI. Distintas interpretaciones de la historia hacen hincapié en cuestiones económicas (transición del modo de producción esclavista al modo de producción feudal, desde la crisis del siglo III), políticas o ideológicas (desaparición del imperio e instalación de los reinos germánicos desde el siglo V), religiosas (sustitución del paganismo politeísta por los monoteísmos teocéntricos: el cristianismo —siglo IV— y posteriormente el islam —siglo VII—), filosóficas (filosofía antigua por la medieval) y artísticas (evolución desde el arte antiguo —clásico— hacia el arte medieval —paleocristiano y prerrománico—).

Las civilizaciones de la Antigüedad son agrupadas geográficamente por la historiografía y la arqueología en zonas en que distintos pueblos y culturas estuvieron especialmente vinculados entre sí; aunque las áreas de influencia de cada una de ellas llegaron en muchas ocasiones a interpenetrarse e ir mucho más lejos, formando imperios de dimensiones multicontinentales (el Imperio persa, el de Alejandro Magno y el Imperio romano), talasocracias («gobierno de los mares») o rutas comerciales y de intercambio de productos e ideas a larga distancia; aunque siempre limitadas por el relativo aislamiento entre ellas (obstáculos de los desiertos y océanos), que llega a ser radical en algunos casos (entre el Viejo Mundo y el Nuevo Mundo). La navegación antigua, especialmente la naturaleza y extensión de las expediciones que necesariamente tuvieron que emprender las culturas primitivas de Polinesia (al menos hasta la Isla de Pascua), es un asunto aún polémico. En algunas ocasiones se ha recurrido a la arqueología experimental para probar la posibilidad de contactos con América desde el Pacífico. Otros conceptos de aplicación discutida son la prioridad del difusionismo o del desarrollo endógeno para determinados fenómenos culturales (agricultura, metalurgia, escritura, alfabeto, moneda, etc.) y la aplicación del evolucionismo en contextos arqueológicos y antropológicos.

El Antiguo Oriente Próximo o Antiguo Oriente es el término utilizado para denominar las zonas de Asia occidental y noreste de África donde surgieron las civilizaciones anteriores a la civilización clásica grecorromana, y que actualmente se denomina Oriente Próximo u Oriente Medio. Para la misma región, Vere Gordon Childe acuñó la denominación Creciente Fértil, al definirla como la zona donde surgió primero la Revolución neolítica (VIII milenio a. C.) y posteriormente la Revolución urbana (IV milenio a. C.). Son los actuales países de Irak, parte de Irán, parte de Turquía, Siria, Líbano, Israel, los Territorios palestinos, Jordania, Arabia y Egipto. Cronológicamente, se entiende como un periodo que va desde el inicio de las civilizaciones históricas en torno al IV milenio a. C. (en esta zona la aparición de la escritura, las ciudades y los templos es simultánea a la Edad del Bronce) hasta la expansión del Imperio aqueménida en el siglo VI a. C.

La desembocadura del Tigris y el Éufrates en la Baja Mesopotamia dio origen a la acumulación de depósitos aluviales en la zona de marismas que va ganando paulatinamente terreno al mar frente a la costa en retroceso del golfo Pérsico (actualmente a más de cien kilómetros del lugar que ocupaba en el IVmilenioa.C., y con los dos ríos confluyentes —Shatt al-Arab—). La zona fue propicia (con la condición de mantener una gran capacidad de organización social para el trabajo colectivo en la construcción de obras hidráulicas como canalizaciones, regadío y drenajes) para el desarrollo de las ciudades-estado sumerias (Ur, Uruk, Eridú, Lagash). Estas, en competencia entre sí y con los pueblos nómadas de estepas y desiertos circundantes (los del sur y oeste englobados por la historiografía en el amplio concepto étnico de semitas y los del este en la zona irania donde se fue formando la civilización elamita), así como con los núcleos que se fueron formando más al norte (Babilonia) y más al norte aún en la Alta Mesopotamia (Nínive); fueron desarrollando las características constitutivas de la civilización (sociedad compleja) y el estado (superestructura político-ideológica): templo, clase sacerdotal y religión organizada, frontera, guerra territorial, ejército, propaganda, impuestos, burocracia, monarquía, construcciones como murallas y zigurats; y el rasgo que marca el inicio de la historia: el registro de la memoria en la escritura.
La dinámica del crecimiento territorial llevó a la formación de imperios, que en su pretensión de monopolizar el poder, se describían a sí mismos como un continuo espacial «entre el mar pequeño y el mar grande» (el golfo Pérsico y el Mediterráneo), en enumeraciones más o menos fiables de pueblos anexionados, destruidos, dispersados, rechazados, sometidos, tributarios, o simplemente socios comerciales, aliados o contactos diplomáticos.

Cordilleras, mesetas, estepas y desiertos caracterizan un difícil medio físico entre el río Tigris al oeste, el golfo Pérsico al sur, el río Indo al este y los montes Elburz, el Mar Caspio y el río Oxus al norte. No obstante, también son la vía terrestre que conecta el Oriente Próximo con el Asia Central y el Asia Meridional (más difícilmente, siendo más usada la conexión marítima); y a través de esas zonas, en última instancia, con el Extremo Oriente. La extensa región persa o irania cumpliría un papel clave en la teoría indoeuropea, de debatida validez, que suponía la existencia de un grupo ancestral de pueblos de las estepas portadores de rasgos comunes (lingüísticos, étnicos, culturales e incluso de estructura de pensamiento), esencialmente ganaderos (otorgaban un gran valor a vacas, caballos y perros), de estructura social patriarcal, jerarquizada y triádica (visible incluso en su panteón de dioses), que protagonizaron una gigantesca expansión que incluiría la conquista de India por los arios; la de Europa por los predecesores de griegos, latinos, celtas, germanos y eslavos; y la de Mesopotamia, Anatolia, Levante y Egipto por medos y persas.

La península de Anatolia, vía terrestre entre Asia y Europa, de la que la separa el estrecho del Bósforo y las numerosas islas del Egeo, con las que siempre mantuvo un continuo cultural (del que son muestra los aqueos y troyanos del mito homérico), estuvo en el corazón de las innovaciones de la Revolución Neolítica y la Revolución Urbana, desarrollando estados poderosos que entraron en relación y competencia con los mesopotámicos e incluso con Egipto. Hacia el norte, la costa del Mar Negro (el Ponto para griegos y romanos), acogía mitos como el del vellocino de oro que se hallaba en la Cólquide. La cordillera del Cáucaso la pone en contacto con las lejanas llanuras eurasiáticas.

La zona costera más oriental del Mediterráneo, por su ubicación entre África y Asia y sus favorables condiciones físicas, actuó como un «pasillo» entre el mar y el desierto, muy compartimentado, aunque con valles fluviales de dirección norte-sur (los del Jordán y el Orontes), que posibilitó las comunicaciones terrestres entre África, Asia y Europa. Ese papel se había cumplido desde el Paleolítico y el Neolítico (Jericó), y se acentuó con las primeras civilizaciones. Los grandes imperios de Egipto, Mesopotamia y Anatolia tuvieron en esta zona su zona de contacto geoestratégico. El contexto crítico de finales del II milenio a. C. permitió que se desarrollaran potentes civilizaciones locales de fuerte personalidad e influencia en el desarrollo histórico posterior (rasgos como el alfabeto o el monoteísmo), con una proyección muy superior a su extensión geográfica o población.

Entre el Tigris y la cordillera del Líbano comienza una vasta zona desértica que se extiende hacia el sur hasta la península arábiga. Supone un obstáculo insalvable para el desarrollo de la agricultura más allá de pequeñas zonas de oasis muy dispersos, excepto en la zona del Yemen (Arabia Felix —‘Arabia feliz’—). Las actividades económicas que se desarrollaron y permitieron la formación de una peculiar civilización fueron, por tanto, la ganadería nómada y las lucrativas rutas caravaneras del comercio a larga distancia que conectaban todas las partes del mundo antiguo a través de los puertos del Mar Rojo, el golfo de Adén y el golfo Pérsico (abiertos al océano Índico —navegación hasta la India e Indonesia—, al este de África —donde la relación con Eritrea y Etiopía fue muy estrecha— y a la costa oriental de Egipto —Berenice—), y ciudades del interior como Alepo, Damasco, Apamea, Petra o Palmira (que conectaban con el Levante mediterráneo).

«Egipto es un don del Nilo» (Heródoto), pues pocas civilizaciones tuvieron una relación tan determinante con un río. Su crecida anual permite la fertilidad y altísima densidad de población de una estrecha franja que recorre el despoblado desierto norteafricano («desertizado» en el periodo postglacial) desde las cataratas del sur hasta el delta del norte. La dualidad entre el Alto Egipto y el Bajo Egipto forjó, sobre una sociedad campesina extraordinariamente estable y vinculada por el trabajo colectivo en las obras hidráulicas, unas instituciones y una cultura caracterizadas por la sacralización de la figura del faraón, la fortaleza de los templos, una eficaz burocracia y una compleja religión del más allá. Dentro de una gran continuidad a lo largo de milenios (que a veces se ha interpretado como homogeneidad o incluso estereotipación, con escasísimas excepciones —el periodo de Amarna—), se mantuvo una repetida dialéctica entre la unidad y la disgregación en el devenir cíclico de las fases de la historia egipcia, con periodos de esplendor y de crisis.


Hélade es el concepto geográfico y cultural que abarcaba en la Antigüedad clásica el territorio habitado por los griegos o helenos, más amplio que la actual Grecia, y que comprendería el territorio continental europeo que va desde el Peloponeso al sur hasta una difusa separación con Macedonia, Tracia y Epiro al norte; además de las islas del mar Egeo y del Mar Jónico y la costa occidental de la actual Turquía (Jonia) hasta el Helesponto. También se asimilaban al concepto de Hélade las colonias griegas establecidas por todo el Mediterráneo; y también podían entenderse próximos a él los extensos territorios de las monarquías helenísticas de Egipto y el Próximo Oriente, que en mayor o menor medida habían sido helenizados.

Muchos mitos griegos se situaban en costas o islas situadas en un indefinido «extremo Occidente» (Vulcano —Hefaistos—, Trabajos de Hércules —Heracles, Columnas de Hércules, Gerión, Atlas—, Atlántida, Jardín de las Hespérides, Odisea —Cíclopes, Lestrigones, Sirenas, Escila y Caribdis, Ogigia, Lotófagos—); otros se situaban en dirección menos clara, o más bien en el Mediterráneo oriental (hacia el Mar Negro —la Cólquide de los viajes de Jasón, los Argonautas y el Vellocino de Oro—, el sur del Egeo —la Creta de Minos, Dédalo, Ícaro, y el Minotauro vencido por el ateniense Teseo; o del rapto de Europa— o el Chipre del nacimiento de Afrodita).



El Imperio romano tuvo un impacto muy superior a su propia extensión espacial (casi 6 millones de kilómetros cuadrados, ya de por sí una de las mayores entre los imperios de todos los tiempos) y a su duración temporal (del 27a.C. al 476d.C. en Occidente y al 1453 en Oriente); por ser la institución política y la formación económico social decisiva para la conformación de la civilización occidental, que en buena medida puede considerarse una pervivencia suya. A través de ella pervivieron sus conceptos jurídicos e institucionales (derecho romano, municipio romano, provincia romana, senado romano...), artísticos y culturales (arte y cultura clásica, urbanismo romano, vía romana, teatro romano, termas, acueductos...) y el propio idioma (el latín). La romanización fue un proceso que tuvo mucho de sincrético, puesto que incorporaba rasgos culturales de los pueblos conquistados. Muy especialmente se identificó con la civilización griega, a la que Roma reconocía como superior a la suya propia, excepto en cuestiones políticas y militares "(Ex Oriente Lux, Ex Occidente Dux)".
En su periodo final, la aportación judeocristiana fue decisiva.


Las estepas del Asia Central tuvieron históricamente una estrecha relación (dialéctica de pueblos nómadas y sedentarios) con la llanura del Indostán, y esta con la Península del Decán. La conexión por tierra con el Oriente Medio a través de los desiertos de Irán fue, en cambio, más comprometida, mientras que la navegación por el Mar Arábigo permitió rutas más fluidas. No obstante, todas ellas fueron experimentadas, a veces en el transcurso de la misma expedición, como fue el caso de la de Alejandro Magno (326).

El aislamiento geográfico de esta zona está marcado por las más altas cordilleras del mundo: el Himalaya, el Altái, el Hindu Kush, el Tian Shan, el Pamir y el Karakorum; y algunos de los más extensos y secos desiertos: el Taklamakán y el Gobi. Incluso las comunicaciones marítimas entre India y China son dificultosas (exposición a los monzones, prolongada navegación por la interposición de la península de Indochina y la península de Malaca que obliga a cruzar por zonas como el estrecho de la Sonda o el estrecho de Malaca). Aun así, existieron contactos, como testimonia la continuidad de rutas comerciales y la difusión de tecnologías, alfabetos y religiones (el hinduismo al Sureste asiático y el budismo a Tíbet, China y Japón). No obstante, la dificultad de ese contacto se percibía como resultado de un viaje de dimensiones míticas ("Viaje a Occidente").

El desierto del Sahara y las dificultades del curso superior del Nilo supusieron dos formidables barreras geográficas que provocaron una discontinuidad cultural muy importante entre el Norte de África y el África Subsahariana. No obstante, fueron lo suficientemente permeables como para permitir el contacto mediante rutas caravaneras con la zona del río Níger y el golfo de Guinea, y el contacto a través del Mar Rojo con Eritrea y Etiopía, zonas fuertemente vinculadas a la Península arábiga. El caso especial de Madagascar es consecuencia de la procedencia de la población malgache, relacionada a través del Océano Índico con otras poblaciones malayo-polinesias.
En la América precolombina, surgieron dos centros civilizatorios distintos: la región andina hacia el IV milenio a. C. y Mesoamérica hacia el II milenio a. C.





En fondo blanco, los periodos considerados prehistóricos (sin presencia de escritura -la existencia de proto-escritura en algunas culturas es una cuestión polémica-), en fondo ligeramente sombreado los periodos históricos (con presencia de escritura -las primeras escrituras y alfabetos, en letras de color rosa-), en fondo de distintos colores, los distintos imperios (entidades políticas de gran extensión, que alcanza al menos una de las zonas consideradas en este esquema).

Mediterráneo Occidental (hegemonía romana tras las guerras púnicas): 

Mediterráneo Oriental:

-Grecia:

-Egipto:

-Asia menor y Mar Negro:
-Levante, Mesopotamia y Asia Central:

William Shakespeare compuso varias obras teatrales con ambientación en la Antigüedad:
"Julio César (Shakespeare), Antonio y Cleopatra, Coriolano, Titus Andrónicus", etc.
Cervantes hizo lo propio en "El cerco de Numancia"; pero fue más usual en el teatro clásico francés: Pierre Corneille ("Horacio", "Cinna", etc.) y Jean Racine ("La Tebaida", "Andrómaca", "Fedra", etc.), a partir del cual —y basándose en modelos clásicos y en textos antiguos de Terencio y Plauto— se fijaron las convenciones académicas que fijaron el modelo del teatro neoclásico del siglo XVIII.

La novela histórica surgida en el romanticismo tuvo en la Edad Media su principal escenario (véase medievalismo), pero también se buscó la ambientación en distintas civilizaciones de la Edad Antigua.

Muchas de las novelas se adaptaron al cine o la televisión:

El éxito editorial de los temas históricos ha multiplicado la aparición de "best sellers" del género, sobre todo los relacionados con la historia militar de Roma.


La adaptación de mitos de la edad antigua ha dado origen a un género cinematográfico especial: "Troya", "Furia de titanes", "Jasón y los argonautas", etc., así como el cine bíblico: "Los diez mandamientos" (de Cecil B. DeMille, 1923 y 1956), "Salomón y la reina de Saba", "Sansón y Dalila", etc.

Véase .

También distintas adaptaciones de los evangelios: "La historia más grande jamás contada, La túnica sagrada, El Evangelio según San Mateo, La Pasión de Cristo", etc. Véase .

Con el nombre de "peplum" (por la vestidura denominada en castellano peplo) se designa a un subgénero cinematográfico en que la ambientación en la Antigüedad es una simple excusa para una película de aventuras de bajo presupuesto en la que los anacronismos y otras inadecuaciones a la historia son abundantes ("Hércules", de 1958, y "Hércules, Sansón, Maciste y Ursus", de 1964). Las características del género ha propiciado la realización de numerosas secuelas y parodias.
Tanto estas como las de mayor nivel popularmente recibieron el nombre de «películas de romanos» (aunque fueran ambientadas en la época griega o cualquier otra época antigua), y su visionado en los «cines de barrio» de sesión continua y doble programa, o en los cines de verano tuvo un notable papel en la educación sentimental de la juventud desde finales de los años cincuenta hasta los setenta, reflejado en obras como las de Terenci Moix (egiptómano y mitómano en concreto de Elizabeth Taylor, actriz que representó a Cleopatra). Joaquín Sabina tiene una canción titulada "Una de romanos", caracterizada por la nostalgia de la juventud pasada.







</doc>
<doc id="1398" url="https://es.wikipedia.org/wiki?curid=1398" title="Historia de México (Época Independiente)">
Historia de México (Época Independiente)

 
Tras las revueltas independentistas iniciadas a principios del siglo XIX hasta culminar en el año de 1821, la Nueva España se separó del control de España para pasar el control administrativo y material a los "criollos" (españoles nacidos en la Nueva España), evento que se logró a partir de la guerra independentista de 1810 hasta 1821, movimiento que fue iniciado por Miguel Hidalgo y Costilla y continuado por otros insurgentes. Durante el transcurso del siglo XIX el país fue sujeto de constantes revueltas y levantamientos destinados a obtener el control y el poder administrativo. Facciones que disputaban intereses eclesiásticos, conflictos territoriales, nuevas formas de gobierno, e invasiones de países extranjeros dejaron agotados los recursos con los que contaba el país haciendo que la nueva nación emergente tardara en perfilarse. 

Después de que se empezó a querer una independencia a principios del siglo XIX, la Nueva España se separó del dominio de España para que todas las tierras y poder económico pasara a los criollos. La Independencia empieza el 15 de septiembre en la noche (pero se celebra el 16 desde el principio de sus años independientes que durante el régimen Porfirista se consolida porque él también cumplía años ese día) de 1810 con el grito de "Dolores" por Miguel Hidalgo y Costilla. Con otros Insurgentes pelearon durante 11 años hasta ganar la guerra de independencia en 1821. Con esto se cambió el nombre a Estados Unidos Mexicanos.

La forma en que Bustamante llegó al poder y el asesinato de Guerrero motivaron un clima de descontento que alentó el regreso de personajes como Antonio López de Santa Anna, a la sazón Héroe nacional, por haber derrotado a las fuerzas españolas de reconquista de Isidro Barradas.

Durante estos años Antonio López de Santa Anna se transformó en la persona más importante de la nación, cambiando sus lealtades de acuerdo con que bando tenía más poder en ese momento.

El costo de esta inestabilidad fue la pérdida de la mitad del país; pérdida que favoreció a los Estados Unidos. Texas se declara independiente en 1836, y California, Nevada, Utah, la región occidental de Colorado (la oriental era del Territorio de la Luisiana), Arizona, Nuevo México y las pequeñas zonas fronterizas de Wyoming, Kansas y Oklahoma que pertenecian a México se pierden al finalizar la guerra México-Estados Unidos(1846-1848).

Las bases fundamentales de la invasión de Estados Unidos a México se dieron en lo que se conoce como el "Destino Manifiesto". Esta política era un recurso que elaboraban los norteamericanos para extender en la medida de lo posible a otros países su ideología, ya fuera por la dominación cultural o bien con la expansión militar. El segundo recurso siempre era más utilizado.
Los pobladores de Estados Unidos querían seguir expandiéndose, decidieron invadir el territorio mexicano, el gobierno mexicano los dejó con tres condiciones; que hablaran español, que se convirtieran a la religión católica y que no tuvieran esclavos. Los estadounidenses aceptaron en principio, pero al poco tiempo dejaron de cumplir su promesa y la guerra por el territorio mexicano empezó (Guerra México-Estados Unidos). Sus ansias de expandirse hacia el sur fueron inevitables, lo que provocó una guerra a todas luces desigual.
En ese momento el presidente de la unión americana era James Polk Knox, quien habría advertido al congreso de su país de sus deseos de intervención a su débil vecino del sur, y fue el mismo congreso quien lo motivó a realizar esta invasión, es decir, casi de forma unánime se pronunciaron por esta, salvo pocas voces que estaban en desacuerdo, entre ellas la de Abraham Lincoln, representante de Illinois.

El recuerdo de la gran revolución de Ayutla, nos da ocasión para significar la limpia trayectoria de la vida de Juan N. Álvarez, ciudadano ejemplar, revolucionario puro que entrega a la Patria medio siglo de su existencia, amalgamada con la causa misma de la libertad y agigantada por la fuerza política y moral y el profundo contenido social de nuestras revoluciones. 

Inicia Morelos apenas sus operaciones en el Sur, cuando el 17 de noviembre de 1810, en el pueblo de Coyuca, hoy de Benítez, se incorpora a su escolta el joven Juan N. Álvarez, quien ha de asistir al lado de Morelos, mientras este vive y después, al lado de Don Vicente Guerrero, a la mayor parte de las acciones de armas de los 11 años de la Guerra de Independencia, hasta verla coronada por el éxito en el memorable Abrazo de Acatempan, el Plan de Ayutla y la entrada a México del Ejército Trigarante. 

No disipada todavía la lucha, defiende el federalismo (Constitución del 4 de octubre de 1824), con el conocimiento pleno de que representaba la única forma de asegurar el pleno goce de las libertades, que el centralismo pretendía ahogar, continuando el sistema virreinal a base de concentrar el poder y la autoridad en unas cuantas manos. 

Esta convicción le mantuvo activo hasta 1854. En el período que va de la consumación de la Independencia Política a la Gran Revolución de Ayutla, solo mantiene en paz a su provincia, cuando surgen los gobiernos liberales que dan vigencia a la Constitución de 1824, con una sola excepción que lo honra. Siendo presidente Santa Anna y manteniéndose los sureños en rebeldía, acaece la invasión estadounidense; el sur depone su actitud y al mando de Juan N. Álvarez presta su contingente, para mantener la integridad Nacional. 

El 1º de marzo de 1854 se proclama el Plan de Ayutla y es la figura de aquel joven soldado que se unió a Morelos en 1810, que maduro en convicciones a través del penoso evolucionar de su pueblo, el que ha de prestarle eje y alma a la gran Revolución de Ayutla. 

Jesús Romero Flores, escribe “Tres etapas grandiosas ha tenido la Revolución Mexicana: La lucha por la Independencia Política, 1810; la lucha por la libertad espiritual, 1854 y la lucha por la autonomía económica 1910. Hidalgo, Álvarez y Madero, acaso sin proponérselo conscientemente, iniciaron cada una de esas etapas que fueron felizmente continuadas por otros muchos paladines“.

Pero la figura de Juan N. Álvarez se actualiza, cobra importancia, a través de la política presente, porque no solo funde su vida al calor que producen las luchas libertarias, sino que es entonces y se prolonga ahora como una eterna y hermosa lección de civismo. 

El hombre que ha dado su juventud a la Patria, viejo ya, abraza una vez más su vieja causa con estas ejemplares palabras: 

“Mi edad bastante avanzada y mis notorias enfermedades, me exigen retirarme al descanso de la vida privada; más al llamado de mis conciudadanos he alejado de mí el bienestar particular y vengo a sacrificarlo todo a la causa sagrada que desde tiempos muy atrás sirvo con lealtad, porque ella es la de mi Patria“.

Y cuando triunfante la Revolución de Ayutla estima necesario nuevamente el sacrificio nos hereda estas preciosas palabras. 

“Pobre entré a la Presidencia y pobre salgo de ella, pero con la satisfacción que no pesa sobre mí la censura pública, porque dedicado desde mi más tierna edad al trabajo personal, se manejar el arado para sostener a mi familia, sin necesidad de los puestos públicos donde otros se enriquecen con ultraje de la orfandad y la miseria“

La Guerra de Reforma duró de diciembre de 1857 a enero de 1861. Con el transcurso de los años, la guerra se hizo más sangrienta y polarizó a la gente en la nación. Muchos de los moderados se unieron a los liberales, convencidos de que era necesario disminuir y controlar el gran poder de la iglesia.

"Artículos principales: Segunda Intervención Francesa en México y Segundo Imperio Mexicano

La presidencia de Benito Juárez(1858-71) fue interrumpida por el segundo imperio de México (1864-67). Conservadores trataron de instituir una monarquía cuando ayudaron a traer a México el archiduque de la casa real de Austria, conocido como Maximiliano de Habsburgo (cuya esposa era la princesa belga Carlota Amalia) con la ayuda militar de Francia, que estaba interesada en la explotación de las minas del noroeste del país.

Aunque el ejército francés, entonces considerado uno de los más eficientes del mundo, sufrió una derrota inicial en la Batalla de Puebla el 5 de mayo de 1862, eventualmente derrotaron a las fuerzas del gobierno mexicano dirigido por el general Ignacio Zaragoza, y pusieron a Maximiliano como el emperador de México. Maximiliano de Habsburgo favorecía el establecimiento de una monarquía limitada que compartiría el poder con un congreso electo democráticamente

La República fue restaurada en 1867, cuando los franceses salieron de México. Benito Juárez se dedicó a reconstruir el país y a cumplir con los mandatos de la constitución de 1857. La sociedad se secularizó, y el gobierno intenta atraer a la inversión extranjera con la pacificación del país y con proyectos que actualizaban la infraestructura de transportes.

Durante estos años, Benito Juárez consolidó su poder, y fue reelegido en dos ocasiones. Porfirio Díaz, héroe de la batalla de Puebla, se levantó en armas en contra de Juárez en 1872, pero la nación responde con desdén a su llamado a las armas. Benito Juárez muere en 1872, y Sebastián Lerdo de Tejada asume la presidencia. 

En 1876, Lerdo de Tejada busca la reelección, y Díaz vuelve a levantarse en armas. En esta ocasión, Díaz es victorioso y derrota a Lerdo de Tejada, que termina huyendo del país.

Porfírio Díaz llegó a la presidencia en 1876. Durante los más de treinta años de su presidencia (1876-1911) gerontocratica, la infraestructura del país se fortaleció gracias a la inversión extranjera aun así el quería buscar de nuevo la reelección. Este periodo de relativa prosperidad y paz es conocido como el porfiriato. Pero la gente no estaba conforme con el gobierno durante el porfiriato. México atraía a inversionistas porque Díaz les daba muchas preferencias y la paga a los trabajadores era muy baja. El resultado fue que una minoría de inversionistas, nacionales y extranjeros, se enriquecieron, y la mayor parte de la población vivía en la miseria. La democracia fue suprimida completamente, y la disidencia era reprimida, generalmente con brutalidad.

En 1910, Díaz, ya de ochenta años, decidió convocar elecciones para reelegirse como presidente. Creyó que para entonces había eliminado toda oposición seria en México. Sin embargo, Francisco I. Madero, un hombre de disposición académica proveniente de familia adinerada, decidió lanzarse como candidato en contra de Díaz, y pronto obtuvo el apoyo del pueblo.

Cuando los resultados oficiales de la elección fueron anunciados, se declaró que Díaz había ganado la reelección con el casi unánime voto de la nación; Madero recibió unos cuantos cientos de votos. El fraude fue tan obvio, que la gente se amotinó. Madero preparó un documento llamado el Plan de San Luis Potosí, en el cual llamó a los mexicanos a la armas para luchar en contra del gobierno de Porfirio Díaz el 20 de noviembre de 1910.

Este plan inició la revolución mexicana. Madero fue encarcelado en San Antonio, Texas, pero el plan continuó su curso, aun con Madero tras las rejas. El ejército federal fue derrotado por las fuerzas revolucionarias, lideradas por Emiliano Zapata en el sur, Pancho Villa y Pascual Orozco en el norte, y Venustiano Carranza. Porfirio Díaz renunció en 1911, por “el bien de la nación”, y salió a su exilio en Francia, donde murió en 1915.

Los generales revolucionarios tenían objetivos diferentes. Las figuras revolucionarias variaban de los liberales, como Madero, a los radicales como Emiliano Zapata y Pancho Villa. Como consecuencia, fue difícil llegar a un acuerdo de cómo organizar el gobierno de las fuerzas triunfantes de la revolución. El resultado fue una lucha por el control del gobierno de México que duró más de veinte años. Este periodo es considerado parte de la revolución mexicana, pero también se puede considerar como una guerra civil. Durante este tiempo muchos de los líderes más destacados de la revolución, Madero(1911), Venustiano Carranza(1920), Emiliano Zapata(1919) y Pancho Villa(1923), fueron asesinados.

Después de la renuncia de Díaz, Madero fue electo presidente en 1911. En 1913 sufrió un golpe de estado y fue asesinado por órdenes de Victoriano Huerta. Venustiano Carranza, general revolucionario encabezó el movimiento en contra de Huerta. Carranza, uno de los muchos presidentes que México tuvo durante este periodo turbulento, también promulgó una nueva constitución el 5 de febrero de 1917, la cual todavía rige México.

En 1920, Álvaro Obregón Salido asumió la presidencia. Él le dio lugar en el nuevo gobierno a todos los elementos de la sociedad mexicana excepto por los hacendados y religiosos más reaccionarios, y catalizó con éxito el movimiento liberal, particularmente en contenimiento del rol de la iglesia católica, mejorando la educación y tomando pasos hacia la institución de derechos a la mujer.

Aunque la revolución Mexicana y la guerra civil habían terminado para 1920, los conflictos armados no cesaron hasta el final de esa década. El conflicto más grande de esta era fue entre aquellos que favorecían una sociedad secular con separación de la religión y el gobierno, y aquellos que favorecían la supremacía de la Iglesia católica. Este conflicto terminó en un alzamiento armado de parte de aquellos que apoyaban a la iglesia, y la guerra se llamó “la guerra cristera”-

Porfirio Díaz había apoyado el Plan de Ayutla bajo las órdenes de Juárez durante la guerra de la reforma y contra Maximiliano. Por diferencias con Juárez proclamó el Plan de la Noria, y tuvo que exiliarse. Más tarde, lanzó el Plan de Tuxtepec contra Lerdo de Tejada ocupó la capital y el gobierno en 1876, y gobernó hasta 1911 con pocas interrupciones ningún hombre había conservado tanto tiempo el poder después de la conquista. Manejo el país durante 30 años, directamente unas veces y otras por medio de otro presidente. El porfiriato le dio a México dos cosas que le eran muy necesarias: inversión de capitales, paz y orden interno que había vuelto a conocer desde tiempos de la colonia.
Durante el porfiriato se creó la Secretaria de Educación Pública y Bellas Artes, y en 1910 se reorganizó la universidad de acuerdo con las normas actuales de la enseñanza superior.

Hasta la instauración del régimen del General Porfirio Díaz a finales del siglo XIX y principios del siglo XX el país fue impulsado de manera importante ante la nueva Revolución industrial; las costumbres y la fisonomía de las ciudades, los transportes y la producción de bienes materiales cambiaban para dar paso a la nueva modernidad. Esto marcó grandes distancias entre las sociedades creando un ambiente de inestabilidad que desató la Revolución mexicana en el año de 1910, periodo caracterizado por nuevas revueltas e insurrecciones en múltiples regiones del país hasta que grupos revolucionarios obtuvieron el control y de inmediato se pasó a promulgar la nueva Constitución moderna que desplazó a las anteriores.
El expresidente Álvaro Obregón quiso retornar al poder y logró que se reformaran las leyes que prohibían la reelección. Ganó las elecciones presidenciales de 1928. Pero antes de tomar posesión, durante una comida en que se celebraba su victoria, fue asesinado.

Como consecuencia del asesinato del presidente electo, el Congreso designó como presidente provisional a Emilio Portes Gil. Para fortalecer el gobierno, Calles les propuso a los jefes políticos y militares la creación de un partido político que serviría para resolver sus diferencias y fomentar la unidad. Así nació, en 1929, el Partido Nacional revolucionario (PNR).
En las nuevas elecciones ganó el candidato del PNR, Pascual Ortiz Rubio; fue una votación muy discutida contra José Vasconcelos, que era candidato independiente. Sin embargo, el verdadero poder lo tuvo Plutarco Elías Calles, llamado Jefe Máximo de la revolución.

De 1928 a 1934 hubo tres presidentes: Emilio Portes Gil, Pascual Ortiz Rubio y Abelardo L. Rodríguez. Ninguno de ellos cubrió un periodo completo. A este periodo se le conoce como el Maximato, porque durante ese tiempo el poder se concentró en el Jefe Máximo. La influencia de Calles terminó cuando el siguiente presidente de la República, el general Lázaro Cárdenas, lo expulsó del país, exiliándolo a Francia.

Durante el siglo XX, México continuó su trayecto integrándose a los nuevos adelantos de la sociedad mundial. El Partido Revolucionario Institucional) mantuvo la supremacía en la administración del país desde la época de la Revolución mexicana y con grandes altibajos fue superado por una importante oposición pacífica al ya convertido régimen a principios del siglo XXI.

Al terminar el periodo presidencial de Lázaro Cárdenas, una parte importante de las clases medias y altas se encontraba alienada por sus medidas izquierdistas, por lo que éste, para mantener la frágil estabilidad que había alcanzado el país, decidió escoger como sucesor a Manuel Ávila Camacho de una tendencia más conservadora.

Entre las acciones que realizó Manuel Ávila Camacho se encuentran la creación del IMSS; la eliminación del sector militar del PNR (el cual tomó, desde ese momento, su nombre actual, PRI; y la sustitución del líder de la CTM, Vicente Lombardo Toledano, por Fidel Velázquez, quien presidiría dicha organización hasta su muerte en 1997.
En general, el gobierno de Manuel Ávila Camacho se caracterizó por la búsqueda de lo que se llamó en ese entonces "unidad nacional", es decir, la reconciliación de las diferencias que había provocado el cardenismo, aunque en algunos casos esto significara un retroceso en las políticas sociales adoptadas por Cárdenas.

En materia de política exterior, el gobierno de Ávila Camacho tuvo que enfrentar la entrada de México a la Segunda Guerra Mundial del lado de los aliados, luego de que un submarino alemán hundiera el buque petrolero mexicano "Potrero del Llano" frente a las costas de Florida. Lo anterior comprometió a México en la Guerra.

En el año 2000 Vicente Fox Quesada postulado por el Partido Acción Nacional ganó las elecciones presidenciales y por primera vez en 71 años el partido oficial emanado de los postulados de la revolución cesó en su predominancia.

Pero en las elecciones federales de 2003 el Partido Revolucionario Institucional mantuvo la mayoría de los curules en la cámara de senadores y ganó las elecciones en la mayoría de los estados de la república, manteniendo su liderazgo

En el año 2006, por segunda ocasión en la historia, el Partido Acción Nacional se impuso en las elecciones a la presidencia de la república con su candidato Felipe Calderón Hinojosa, en una dudosa contienda al lado de Andrés Manuel López Obrador.
Tras comenzar su gobierno el presidente Calderón le declara una guerra violenta y con pocos resultados (aparte de la inseguridad y matanzas) para el país y para colmo sobrevino una crisis económica del 2008-2009 que causó una ola de desempleo y violencia aparte de la corrupción en incremento.

Así con una economía que volvía a crecer y una fuerte inseguridad se celebraron elecciones en 2012 y resultó ganador el licenciado Enrique Peña Nieto por el PRI aunque al principio las cosas no fueron mal a mediados del 2013 la inseguridad y violencia se incrementaron y para finales del 2014 la popularidad del presidente Peña Nieto bajaba drásticamente gracias a los 43 estudiantes desaparecidos en Ayotzinapa , a comienzos del 2015 el crecimiento económico se ha hecho más lento y la popularidad presidencial en su más bajo nivel a pesar de las reformas implementadas por el presidente Peña Nieto.


</doc>
<doc id="1401" url="https://es.wikipedia.org/wiki?curid=1401" title="Horizonte de sucesos">
Horizonte de sucesos

En relatividad general, el horizonte de sucesos —también llamado horizonte de eventos— se refiere a una hipersuperficie frontera del espacio-tiempo, tal que los eventos a un lado de ella no pueden afectar a un observador situado al otro lado. Obsérvese que esta relación no tiene por qué ser simétrica o biyectiva, es decir, si A y B son las dos regiones del espacio tiempo en que el horizonte de eventos divide el espacio, A puede no ser afectada por los eventos dentro de B, pero los eventos de B generalmente sí son afectados por los eventos en A. Por dar un ejemplo concreto, la luz emitida desde dentro del horizonte de eventos jamás podría alcanzar a un observador situado fuera, pero un observador dentro podría observar los sucesos del exterior.

Existen diversos tipos de horizontes de eventos, y estos pueden aparecer en diversas circunstancias. Una de ellas particularmente importante sucede en presencia de agujeros negros, aunque este no es el único tipo de horizonte de eventos posibles, existiendo además horizontes de Cauchy, horizontes de Killing, horizontes de partícula u horizontes cosmológicos.

El horizonte de sucesos es una superficie imaginaria de forma esférica que rodea a un agujero negro, en la cual la velocidad de escape necesaria para alejarse del mismo coincide con la velocidad de la luz. Por ello, ninguna cosa dentro de él, incluyendo los fotones, puede escapar debido a la atracción de un campo gravitatorio extremadamente intenso.

Las partículas del exterior que "caen" dentro de esta región nunca vuelven a salir, ya que para hacerlo necesitarían una velocidad de escape superior a la de la luz y, hasta el momento, la teoría indica que nada puede alcanzarla.

Por tanto, no existe modo de observar el interior del horizonte de sucesos, ni de transmitir información hacia el exterior. Esta es la razón por la cual los agujeros negros no tienen características externas visibles de ningún tipo, que permitan determinar su estructura interior o su contenido, siendo imposible establecer en qué estado se encuentra la materia desde que rebasa el horizonte de sucesos hasta que colapsa en el centro del agujero negro.

Si cayéramos en un agujero negro, en el momento de atravesar el horizonte de sucesos no notaríamos ningún cambio, ya que no se trata de una superficie material, sino de una frontera imaginaria, alejada de la zona central donde se concentra la masa. La característica peculiar de esta frontera es que representa el punto de no retorno, a partir del cual no puede existir otro suceso más que caer hacia el interior, dando así origen al nombre de esta superficie.

Al incluir efectos cuánticos en el horizonte de sucesos, se hace posible la emisión de radiación por parte del agujero negro debido a las fluctuaciones del vacío que dan origen a la llamada radiación de Hawking.

Otro tipo de horizonte diferente es el que ve un observador uniformemente acelerado. Para caracterizar este tipo de horizonte necesitamos introducir las coordenadas de Rindler para el espacio-tiempo de Minkowski. Partiendo de las coordenadas cartesianas la métrica de dicho espacio-tiempo:

Consideremos ahora la región conocida como "cuña de Rindler", dada por el conjunto de puntos que verifican:

Y definamos sobre ella un cambio de coordenadas dado por:

Cuya transformación inversa viene dada por:

Usando estas coordenadas la cuña de Rindler del espacio de Minkowski tiene una métrica expresada en las nuevas coordenadas dada por la expresión:

Esta métrica tiene una singularidad aparente en formula_1, donde el tensor expresado en las coordenas de Rindler tiene un determinante que se anula. Esto sucede porque en formula_2 la aceleración asociada al observador se hace infinita. En estas coordenadas el horizonte de Rindler es precisamente la frontera de la cuña de Rindler. Es interesante que puede demostrarse que este horizonte es análogo en muchos aspectos al horizonte de eventos de un agujero negro.

El límite del universo observable es una hipersuperficie que constituye la barrera de lo que puede ser observado en cada instante de tiempo, más allá existirían partículas cuya luz todavía no ha tenido tiempo de alcanzarnos, debido a que la edad del universo es finita (ver Big Bang). Todo suceso actual o pasado situado tras el horizonte de eventos, no forma parte del universo observable actual (aunque puede ser visible en el futuro cuando las señales luminosas procedentes de ellos alcancen nuestra posición futura).

La forma en que este horizonte del universo observable cambia según la naturaleza de la expansión del universo. Si la expansión tiene ciertas características, que no serán nunca observables, por ejemplo, sin importar cuanto tiempo transcurra (eso pasa en cierto tipo de expansión acelerada, por ejemplo). La frontera pasada de los eventos que nunca podrán ser observados es propiamente un horizonte de sucesos llamado horizonte de sucesos de partícula.

El criterio para determinar si el horizonte de sucesos del universo es diferente del vacío es el siguiente, defínase una distancia comóvil formula_3 mediante la expresión:

En esta ecuación, "a"("t") es el factor de escala, "c" es la velocidad de la luz y "t" es la edad actual del universo. Si formula_4, es decir, los puntos arbitrariamente lejanos pueden ser observados, entonces el horizonte de sucesos es vacío. Si formula_5 entonces existirá un horizonte de sucesos.

Ejemplos de modelos cosmológicos sin horizonte de sucesos son los modelos de universos dominados por materia o por radiación. Un ejemplo de modelo cosmológico con horizonte de sucesos es un universo dominado por la constante cosmológica, como por ejemplo un Universo de De Sitter.

El estudio de la causalidad en relatividad general se lleva a cabo siguiendo un enfoque topológico, así un horizonte de eventos futuro o pasado puede caracterizarse como el conjunto de puntos de la clausura topológica del dominio de dependencia de una hipersuperficie lumínica situada en el "infinito" que no pertenecen al pasado o futuro cronológico de dicho dominio. Conviene aclarar que cuando se dice que una hipersuperficie está ubicada en el "infinito" se quiere decir que está situada sobre los puntos del diagrama conforme de Penrose que representa el espacio-tiempo, en signos los horizontes de eventos pasado formula_6 y futuro formula_7 de una hipersuperficie lumínica formula_8vienen dados por:

Donde la definición de los signos que aparecen es la misma usada en .



</doc>
<doc id="1403" url="https://es.wikipedia.org/wiki?curid=1403" title="Hydrocharitaceae">
Hydrocharitaceae

Las hidrocaritáceas (nombre científico Hydrocharitaceae) son una familia de hierbas acuáticas perennes, sumergidas o flotantes, distribuidas en todo el mundo, la mayoría son de agua dulce aunque también hay géneros marinos. La familia es reconocida por sistemas de clasificación modernos como el sistema de clasificación APG III (2009) y el APWeb (2001 en adelante). Anteriormente era la única familia del orden Hydrocharitales, pero en los sistemas de clasificación mencionados está incluida en el orden Alismatales. Sus hojas son a veces pecioladas pero usualmente indiferenciadas. La inflorescencia muchas veces tiene dos brácteas fusionadas (a veces libres) en la base. El ovario es ínfero, muchas veces con placentación parietal laminar o más o menos fuertemente intrusa. Los lóbulos del estigma son bífidos. La familia es muy heterogénea morfológicamente, siendo subdividida en 4 subfamilias: Hydrocharitoideae, Stratiotoideae, Anacharidoideae e Hydrilloideae. Los mecanismos de polinización también varían mucho dentro de la familia.

Hierbas acuáticas, completamente sumergidas a emergentes en parte, y enraizadas en el sustrato o flotantes y sin fijación, en hábitats marinos o de agua dulce, muchas veces rizomatosas, tejidos más o menos aerenquimatosos.

Pelos unicelulares, de pared gruesa, con extensiones de la epidermis en estructuras puntiagudas de tipo aguja ("prickle") a lo largo de márgenes o venas.

Hojas alternas y espirales, opuestas, o verticiladas, a lo largo del tallo o en una roseta basal, simples, enteras o serradas, a veces con una lámina bien desarrollada, con venación paralela o palmada, o evidente solo en la vena media, envainadoras en la base. Sin estípulas. Pequeñas escamas presentes en el nodo dentro de la vaina de la hoja.

Inflorescencias determinadas, a veces reducidas a una flor solitaria, axilar, por debajo de ella 2 brácteas muchas veces conadas.

Flores bisexuales o unisexuales (plantas entonces monoicas o dioicas), usualmente radiales, con perianto diferenciado en cáliz y corola.

3 sépalos, separados, valvados.

3 pétalos, separados, usualmente blancos, imbricados, a veces faltantes.

Estambres 1, 2, 3 o numerosos, filamentos separados a conados. Polen usualmente sin aperturas, en "Thalassia" y "Halophila" unidos en cadenas como hilos.

Carpelos usualmente 3-6, conados, ovario ínfero, con óvulos esparcidos en la superficie de los lóculos, la placenta muchas veces más o menos profundamente intrusa, estilos muchas veces divididos, pareciendo el doble del número de carpelos, estigmas elongados y papilosos.

Óvulos numerosos (o solitarios y basales).

Néctar muchas veces secretado de estaminodios.

Fruto carnoso, puede ser una baya o una cápsula que se abre irregularmente o valvadamente. Embrión a veces curvado. Sin endosperma.

Ampliamente distribuidas, pero más comunes en regiones tropicales y subtropicales, en hábitats de agua dulce (la mayoría de los géneros) o marinos ("Enhalus, Halophila, Thalassia").

La familia posee una variedad interesante de mecanismos de polinización. Muchas especies en "Egeria, Limnobium, Stratiotes", y "Blyxa" tienen flores vistosas que están por encima de la superficie del agua y son polinizadas por variados insectos usualmente recolectores de néctar. En "Vallisneria, Enhalus" y "Lagarosiphon", las flores masculinas se desprenden y flotan en la superficie del agua, mientras que entran en contacto con las flores femeninas. En "Elodea", las anteras de las flores masculinas pueden explotar, desparramando granos de polen en la superficie del agua, las mismas flores masculinas son a veces desprendidas de la planta y flotan en la superficie del agua hasta el estigma. En "Hydrilla" el transporte del polen puede ocurrir por viento o agua. Finalmente, en "Thalassia" y "Halophila" la polinización ocurre bajo el agua.

Puede ocurrir polinización cruzada o autopolinización.

Los frutos carnosos maduran debajo del agua.

Los frutos o las semillas son dispersadas por el agua o los animales.

La reproducción vegetativa por fragmentación de los rizomas es común.

Hydrocharitacae, si bien monofilética (Dahlgren y Rasmussen 1983, Les "et al." 2006) es morfológicamente heterogénea, y ha sido dividida en 3 a 5 subfamilias (Dahlgren "et al." 1985).

"Najas" tiene flores reducidas con un óvulo basal y erecto, pero su ubicación dentro de Hydrocharitaceae está sostenida por la anatomía del tegumento de la semilla y los análisis de secuencias de ADN (Les 1993, Les y Haynes 1995, Les "et al." 2006).

"Zannichellia" (Zannichelliaceae) probablemente también pertenece aquí (Les "et al." 1997a).

La familia fue reconocida por el APG III (2009), el Linear APG III (2009) le asignó el número de familia 31. La familia ya había sido reconocida por el APG II (2003).

La familia fue descrita por Antoine-Laurent de Jussieu y publicado en "Genera Plantarum¡" 67. 1789. El género tipo es: "Hydrocharis" L.

Los géneros más representados son "Ottelia" (40 especies), "Najas" (40 especies), y "Elodea" (15 especies).

Los géneros son, según Angiosperm Phylogeny Website: (visitado en abril de 2015):

Sinónimos, según el APWeb: Enhalaceae Nakai, Halophilaceae J. Agardh, Hydrillaceae Prantl, Najadaceae Jussieu, "nom. cons.", Thalassiaceae Nakai, Vallisneriaceae Link.

Muchos géneros, como "Hydrilla, Egeria, Elodea, Vallisneria", y "Limnobium", son utilizados como plantas de acuario.

Especies de "Elodea, Hydrilla, "y" Lagarosiphon" son malezas acuáticas perniciosas.

Más descripciones


</doc>
<doc id="1404" url="https://es.wikipedia.org/wiki?curid=1404" title="Hidrógeno">
Hidrógeno

El hidrógeno (en griego, de ὕδωρ "hýdōr", genitivo ὑδρός "hydrós", y γένος "génos" «que genera o produce agua») es el elemento químico de número atómico 1, representado por el símbolo H. Con una masa atómica de 1,00794 (7) u, es el más ligero de la tabla de los elementos. Por lo general, se presenta en su forma molecular, formando el gas diatómico H en condiciones normales. Este gas es inflamable, incoloro, inodoro, no metálico e insoluble en agua.

Debido a sus distintas propiedades, el hidrógeno no se puede encuadrar claramente en ningún grupo de la tabla periódica, aunque muchas veces se sitúa en el grupo 1 (o familia 1A) por poseer un solo electrón en la capa de valencia o capa superior.

El hidrógeno es el elemento químico más abundante, al constituir aproximadamente el 75% de la materia visible del universo. En su secuencia principal, las estrellas están compuestas principalmente por hidrógeno en estado de plasma. El hidrógeno elemental es relativamente raro en la Tierra y es producido industrialmente a partir de hidrocarburos como, por ejemplo, el metano. La mayor parte del hidrógeno elemental se obtiene "in situ", es decir, en el lugar y en el momento en que se necesita. Los mayores mercados del mundo disfrutan de la utilización del hidrógeno para el mejoramiento de combustibles fósiles (en el proceso de hidrocraqueo) y en la producción de amoníaco (principalmente para el mercado de fertilizantes). El hidrógeno puede obtenerse a partir del agua por un proceso de electrólisis, pero resulta un método mucho más caro que la obtención a partir del gas natural.

El isótopo del hidrógeno más común es el protio, cuyo núcleo está formado por un único protón y ningún neutrón. En los compuestos iónicos, puede tener una carga positiva (convirtiéndose en un catión llamado hidrón, H, compuesto únicamente por un protón, a veces en presencia de 1 o 2 neutrones); o carga negativa (convirtiéndose en un anión conocido como hidruro, H). También se pueden formar otros isótopos, como el deuterio, con un neutrón, y el tritio, con dos neutrones. En 2001, fue creado en laboratorio el isótopo H y, a partir de 2003, se sintetizaron los isótopos H hasta H. El hidrógeno forma compuestos con la mayoría de los elementos y está presente en el agua y en la mayoría de los compuestos orgánicos. Tiene un papel particularmente importante en la química ácido-base, en la que muchas reacciones implican el intercambio de protones (iones hidrógeno, H) entre moléculas solubles. Puesto que es el único átomo neutro para el que se puede resolver analíticamente la ecuación de Schrödinger, el estudio de la energía y del enlace del átomo de hidrógeno ha sido fundamental hasta el punto de haber desempeñado un papel principal en el desarrollo de la mecánica cuántica.

Las características de este elemento y su solubilidad en diversos metales son muy importantes en la metalurgia, puesto que muchos metales pueden sufrir fragilidad en su presencia, y en el desarrollo de formas seguras de almacenarlo para su uso como combustible. Es altamente soluble en diversos compuestos que poseen tierras raras y metales de transición, y puede ser disuelto tanto en metales cristalinos como amorfos. La solubilidad del hidrógeno en los metales está influenciada por las distorsiones locales o impurezas en la estructura cristalina del metal.

El término "hidrógeno" proviene del latín "hydrogenium", y este del griego antiguo "ὕδωρ" ("hydro"): ‘agua’ y "γένος-ου"("genos"): ‘generador’; es decir, "productor de agua". Fue ése el nombre con el que lo bautizó Antoine Lavoisier. La palabra puede referirse tanto al átomo de hidrógeno (descrito en este artículo), como a la molécula diatómica (H), que se encuentra a nivel de trazas en la atmósfera terrestre. Los químicos tienden a referirse a esta molécula como dihidrógeno, molécula de hidrógeno, o hidrógeno diatómico, para distinguirla del átomo del elemento, que no existe de forma aislada en las condiciones ordinarias.

El hidrógeno diatómico gaseoso, H, fue el primero producido artificialmente y formalmente descrito por T. von Hohenheim (más conocido como Paracelso), que lo obtuvo artificialmente mezclando metales con ácidos fuertes. Paracelso no era consciente de que el gas inflamable generado en estas reacciones químicas estaba compuesto por un nuevo elemento químico. En 1671, Robert Boyle redescubrió y describió la reacción que se producía entre limaduras de hierro y ácidos diluidos, lo que resulta en la producción de gas hidrógeno. En 1766, Henry Cavendish fue el primero en reconocer el hidrógeno gaseoso como una sustancia discreta, identificando el gas producido en la reacción metal-ácido como "aire inflamable" y descubriendo más profundamente, en 1781, que el gas produce agua cuando se quema. Generalmente, se le da el crédito por su descubrimiento como un elemento químico. En 1783, Antoine Lavoisier dio al elemento el nombre de "hidrógeno" (del griego "υδρώ" (hydro), agua y "γένος-ου" (genes) generar, es decir, "productor de agua") cuando él y Laplace reprodujeron el descubrimiento de Cavendish, donde se produce agua cuando se quema hidrógeno.

Lavoisier produjo hidrógeno para sus experimentos sobre conservación de la masa haciendo reaccionar un flujo de vapor con hierro metálico a través de un tubo de hierro incandescente calentado al fuego. La oxidación anaerobia de hierro por los protones del agua a alta temperatura puede ser representada esquemáticamente por el conjunto de las siguientes reacciones:

Muchos metales, tales como circonio, se someten a una reacción similar con agua, lo que conduce a la producción de hidrógeno.

El hidrógeno fue licuado por primera vez por James Dewar en 1898 al usar refrigeración regenerativa, y su invención se aproxima mucho a lo que conocemos hoy en día como termo. Produjo hidrógeno sólido al año siguiente. El deuterio fue descubierto en diciembre de 1931 por Harold Urey, y el tritio fue preparado en 1934 por Ernest Rutherford, Marcus Oliphant, y Paul Harteck. El agua pesada, que tiene deuterio en lugar de hidrógeno regular en la molécula de agua, fue descubierta por el equipo de Urey en 1932.

François Isaac de Rivaz construyó el primer dispositivo de combustión interna propulsado por una mezcla de hidrógeno y oxígeno en 1806. Edward Daniel Clarke inventó el rebufo de gas de hidrógeno en 1819. La lámpara de Döbereiner y la Luminaria Drummond fueron inventadas en 1823.

El llenado del primer globo con gas hidrógeno fue documentado por Jacques Charles en 1783. El hidrógeno proveía el ascenso a la primera manera confiable de viajes aéreos después de la invención del primer dirigible de hidrógeno retirado en 1852 por Henri Giffard. El conde alemán Ferdinand von Zeppelin promovió la idea de utilizar el hidrógeno en dirigibles rígidos, que más tarde fueron llamados zepelines, el primero de los cuales tuvo su vuelo inaugural en 1900. Los vuelos normales comenzaron en 1910, y para el inicio de la Primera Guerra Mundial, en agosto de 1914, se había trasladado a 35 000 pasajeros sin ningún incidente grave. Los dirigibles elevados con hidrógeno se utilizan como plataformas de observación y bombarderos durante la guerra.

La primera travesía transatlántica sin escalas fue hecha por el dirigible británico "R34" en 1919. A partir de 1928, con el Graf Zeppelin LZ 127, el servicio regular de pasajeros prosiguió hasta mediados de la década de 1930 sin ningún incidente. Con el descubrimiento de las reservas de otro tipo de gas ligero en los Estados Unidos, este proyecto debió ser modificado, ya que el otro elemento prometió más seguridad, pero el Gobierno de Estados Unidos se negó a vender el gas a tal efecto. Por lo tanto, el H fue utilizado en el dirigible "Hindenburg", que resultó destruido en un incidente en vuelo sobre Nueva Jersey el 6 de mayo de 1937. El incidente fue transmitido en vivo por radio y filmado. El encendido de una fuga de hidrógeno se atribuyó como la causa del incidente, pero las investigaciones posteriores señalaron a la ignición del revestimiento de tejido aluminizado por la electricidad estática.

Gracias a su estructura atómica relativamente simple, consistente en un solo protón y un solo electrón para el isótopo más abundante (protio), el átomo de hidrógeno posee un espectro de absorción que pudo ser explicado cuantitativamente, lo que supuso el punto central del modelo atómico de Bohr, que constituyó un hito en el desarrollo la teoría de la estructura atómica. Además, la consiguiente simplicidad de la molécula de hidrógeno diatómico y el correspondiente catión dihidrógeno, H, permitió una comprensión más completa de la naturaleza del enlace químico, que continuó poco después con el tratamiento mecano-cuántico del átomo de hidrógeno, que había sido desarrollado a mediados de la década de 1920 por Erwin Schrödinger y Werner Heisenberg.

Uno de los primeros efectos cuánticos que fue explícitamente advertido (pero no entendido en ese momento) fue una observación de Maxwell en la que estaba involucrado el hidrógeno, medio siglo antes de que se estableciera completamente la teoría mecano-cuántica. Maxwell observó que el calor específico del H, inexplicablemente, se desviaba del correspondiente a un gas diatómico por debajo de la temperatura ambiente y comenzaba a parecerse cada vez más al correspondiente a un gas monoatómico a temperaturas muy bajas. De acuerdo con la teoría cuántica, este comportamiento resulta del espaciamiento de los niveles energéticos rotacionales (cuantizados), que se encuentran particularmente separados en el H debido a su pequeña masa. Estos niveles tan separados impiden el reparto equitativo de la energía calorífica para generar movimiento rotacional en el hidrógeno a bajas temperaturas. Los gases diatómicos compuestos de átomos pesados no poseen niveles energéticos rotacionales tan separados y, por tanto, no presentan el mismo efecto que el hidrógeno.

El hidrógeno es el elemento químico más abundante del universo, suponiendo más del 75% en materia normal por masa y más del 90 % en número de átomos. Este elemento se encuentra en abundancia en las estrellas y los planetas gaseosos gigantes. Las nubes moleculares de H están asociadas a la formación de las estrellas. El hidrógeno también juega un papel fundamental como combustible de las estrellas por medio de las reacciones de fusión nuclear entre núcleos de hidrógeno.

En el universo, el hidrógeno se encuentra principalmente en su forma atómica y en estado de plasma, cuyas propiedades son bastante diferentes a las del hidrógeno molecular. Como plasma, el electrón y el protón del hidrógeno no se encuentran ligados, por lo que presenta una alta conductividad eléctrica y una gran emisividad (origen de la luz emitida por el Sol y otras estrellas). Las partículas cargadas están fuertemente influenciadas por los campos eléctricos y magnéticos. Por ejemplo, en los vientos solares las partículas interaccionan con la magnetosfera terrestre generando corrientes de Birkeland y el fenómeno de las auroras.

Bajo condiciones normales de presión y temperatura, el hidrógeno existe como gas diatómico, H. Sin embargo, el hidrógeno gaseoso es extremadamente poco abundante en la atmósfera de la Tierra (1 ppm en volumen), debido a su pequeña masa que le permite escapar al influjo de la gravedad terrestre más fácilmente que otros gases más pesados. Aunque los átomos de hidrógeno y las moléculas diatómicas de hidrógeno abundan en el espacio interestelar, son difíciles de generar, concentrar y purificar en la Tierra. El hidrógeno es el decimoquinto elemento más abundante en la superficie terrestre La mayor parte del hidrógeno terrestre se encuentra formando parte de compuestos químicos tales como los hidrocarburos o el agua. El hidrógeno gaseoso es producido por algunas bacterias y algas, y es un componente natural de las flatulencias.

El gas hidrógeno (dihidrógeno) es altamente inflamable y se quema en concentraciones de 4% o más H en el aire. La entalpía de combustión de hidrógeno es −286 kJ/mol; se quema de acuerdo con la siguiente ecuación balanceada.
Cuando se mezcla con oxígeno en una variedad de proporciones, de hidrógeno explota por ignición. El hidrógeno se quema violentamente en el aire; se produce la ignición automáticamente a una temperatura de 560 °C. Llamas de hidrógeno-oxígeno puros se queman en la gama del color ultravioleta y son casi invisibles a simple vista, como lo demuestra la debilidad de la llama de las turbinas principales del transbordador espacial (a diferencia de las llamas fácilmente visibles del cohete acelerador del sólido). Así que se necesita un detector de llama para detectar si una fuga de hidrógeno está ardiendo. La explosión del dirigible Hindenburg fue un caso infame de combustión de hidrógeno. La causa fue debatida, pero los materiales combustibles en la cubierta de la aeronave fueron los responsables del color de las llamas. Otra característica de los fuegos de hidrógeno es que las llamas tienden a ascender rápidamente con el gas en el aire, como ilustraron las llamas del "Hindenburg", causando menos daño que los fuegos de hidrocarburos. Dos terceras partes de los pasajeros del "Hindenburg" sobrevivieron al incendio, y muchas de las muertes que se produjeron fueron por caída o fuego del combustible diésel.

H reacciona directamente con otros elementos oxidantes. Una reacción espontánea y violenta puede ocurrir a temperatura ambiente con cloro y flúor, formando los haluros de hidrógeno correspondientes: cloruro de hidrógeno y fluoruro de hidrógeno.

A diferencia la de los hidrocarburos, la combustión del hidrógeno no genera óxidos de carbono (monóxido y dióxido) sino simplemente agua en forma de vapor, por lo que se considera un combustible amigable con el medio ambiente y ayuda a mitigar el calentamiento global.

El nivel energético del estado fundamental electrónico de un átomo de hidrógeno es –13,6 eV, que equivale a un fotón ultravioleta de, aproximadamente, 92nm de longitud de onda.

Los niveles energéticos del hidrógeno pueden calcularse con bastante precisión empleando el modelo atómico de Bohr, que considera que el electrón orbita alrededor del protón de forma análoga a la órbita terrestre alrededor del Sol. Sin embargo, la fuerza electromagnética hace que el protón y el electrón se atraigan, de igual modo que los planetas y otros cuerpos celestes se atraen por la fuerza gravitatoria. Debido al carácter discreto (cuantizado) del momento angular postulado en los inicios de la mecánica cuántica por Bohr, el electrón en el modelo de Bohr solo puede orbitar a ciertas distancias permitidas alrededor del protón y, por extensión, con ciertos valores de energía permitidos. Una descripción más precisa del átomo de hidrógeno viene dada mediante un tratamiento puramente mecano-cuántico que emplea la ecuación de onda de Schrödinger o la formulación equivalente de las integrales de camino de Feynman para calcular la densidad de probabilidad del electrón cerca del protón. El tratamiento del electrón a través de la hipótesis de De Broglie (dualidad onda - partícula) reproduce resultados químicos (tales como la configuración del átomo de hidrógeno) de manera más natural que el modelo de partículas de Bohr, aunque la energía y los resultados espectrales son los mismos. Si en la construcción del modelo se emplea la masa reducida del núcleo y del electrón (como se haría en el problema de dos cuerpos en Mecánica Clásica), se obtiene una mejor formulación para los espectros del hidrógeno, y los desplazamientos espectrales correctos para el deuterio y el tritio. Pequeños ajustes en los niveles energéticos del átomo de hidrógeno, que corresponden a efectos espectrales reales, pueden determinarse usando la teoría mecano-cuántica completa, que corrige los efectos de la relatividad especial (ver ecuación de Dirac), y computando los efectos cuánticos originados por la producción de partículas virtuales en el vacío y como resultado de los campos eléctricos (ver Electrodinámica Cuántica).

En el hidrógeno gaseoso, el nivel energético del estado electrónico fundamental está dividido a su vez en otros niveles de estructura hiperfina, originados por el efecto de las interacciones magnéticas producidas entre los espines del electrón y del protón. La energía del átomo cuando los espines del protón y del electrón están alineados es mayor que cuando los espines no lo están. La transición entre esos dos estados puede tener lugar mediante la emisión de un fotón a través de una transición de dipolo magnético. Los radiotelescopios pueden detectar la radiación producida en este proceso, lo que sirve para crear mapas de distribución del hidrógeno en la galaxia.

Existen dos tipos distintos de moléculas diatómicas de hidrógeno que difieren en la relación entre los espines de sus núcleos: En la forma de ortohidrógeno, los espines de los dos protones son paralelas y forman un estado triplete, en forma de para-hidrógeno, los spins son antiparalelas y forman un singular. En condiciones normales de presión y temperatura el hidrógeno gaseoso contiene aproximadamente un 25% de la forma "para" y un 75% de la forma "orto", también conocida como "forma normal". La relación del equilibrio entre ortohidrógeno y parahidrógeno depende de la temperatura, pero puesto que la forma orto es un estado excitado, y por tanto posee una energía superior, es inestable y no puede ser purificada. A temperaturas muy bajas, el estado de equilibrio está compuesto casi exclusivamente por la forma "para". Las propiedades físicas del para-hidrógeno puro difieren ligeramente de las de la forma normal ("orto"). La distinción entre formas "orto"/"para" también se presenta en otras moléculas o grupos funcionales que contienen hidrógeno, tales como el agua o el metileno.

La interconversión no catalizada entre el parahidrógeno y el ortohidrógeno se incrementa al aumentar la temperatura; por esta razón, el H condensado rápidamente contiene grandes cantidades de la forma "orto" que pasa a la forma "para" lentamente. La relación "orto"/"para" en el H condensado es algo importante a tener en cuenta para la preparación y el almacenamiento del hidrógeno líquido: la conversión de la forma "orto" a la forma "para" es exotérmica y produce el calor suficiente para evaporar el hidrógeno líquido, provocando la pérdida del material licuado. Catalizadores para la interconversión "orto"/"para", tales como compuestos de hierro, son usados en procesos de refrigeración con hidrógeno.

Una forma molecular llamada hidrógeno molecular protonado, H, se encuentra en el medio interestelar, donde se genera por la ionización del hidrógeno molecular provocada por los rayos cósmicos. También se ha observado en las capas superiores de la atmósfera de Júpiter. Esta molécula es relativamente estable en el medio del espacio exterior debido a las bajas temperaturas y a la bajísima densidad. El H es uno de los iones más abundantes del universo, y juega un papel notable en la química del medio interestelar.

Si bien se suele catalogar al hidrógeno como no metal, a altas temperaturas y presiones puede comportarse como metal. En marzo de 1996, un grupo de científicos del Laboratorio Nacional Lawrence Livermore informó de que habían producido casualmente, durante un microsegundo y a temperaturas de miles de kelvins y presiones de más de un millón de atmósferas (> 100 GPa), el primer hidrógeno metálico identificable.

A pesar de que el H no es muy reactivo en condiciones normales, forma multitud de compuestos con la mayoría de los elementos químicos. Se conocen millones de hidrocarburos, pero no se generan por la reacción directa del hidrógeno elemental con el carbono (aunque la producción del gas de síntesis seguida del proceso Fischer - Tropsch para sintetizar hidrocarburos parece ser una excepción pues comienza con carbón e hidrógeno elemental generado in situ). El hidrógeno puede formar compuestos con elementos más electronegativos, tales como los halógenos (flúor, cloro, bromo, yodo) o los calcógenos (oxígeno, azufre, selenio); en estos compuestos, el hidrógeno adquiere carga parcial positiva debido a la polaridad del enlace covalente. Cuando se encuentra unido al flúor, al oxígeno o al nitrógeno, el hidrógeno puede participar en una modalidad de enlace no covalente llamado "enlace de hidrógeno" o "puente de hidrógeno", que es fundamental para la estabilidad de muchas moléculas biológicas. El hidrógeno puede también formar compuestos con elementos menos electronegativos, tales como metales o semimetales, en los cuales adquiere carga parcial negativa. Estos compuestos se conocen como hidruros.

El hidrógeno forma una enorme variedad de compuestos con el carbono. Debido a su presencia en los seres vivos, estos compuestos se denominan compuestos orgánicos; el estudio de sus propiedades es la finalidad de la Química Orgánica, y el estudio en el contexto de los organismos vivos se conoce como Bioquímica. Atendiendo a algunas definiciones, los compuestos "orgánicos" requieren la presencia de carbono para ser denominados así (ahí tenemos el clásico ejemplo de la urea) pero no todos los compuestos de carbono se consideran orgánicos (es el caso del monóxido de carbono, o los carbonatos metálicos. La mayoría de los compuestos orgánicos también contienen hidrógeno y, puesto que es el enlace carbono-hidrógeno el que proporciona a estos compuestos muchas de sus principales características, se hace necesario mencionar el enlace carbono-hidrógeno en algunas definiciones de la palabra "orgánica" en Química. (Estas recientes definiciones no son perfectas, sin embargo, ya que un compuesto indudablemente orgánico como la urea no podría ser catalogado como tal atendiendo a ellas).

En la Química Inorgánica, los hidruros pueden servir también como ligandos puente que unen dos centros metálicos en un complejo de coordinación. Esta función es particularmente común en los elementos del grupo 13, especialmente en los boranos (hidruros de boro) y en los complejos de aluminio, así como en los clústers de carborano.

Algunos ejemplos de compuestos covalentes importantes que contienen hidrógeno son: amoniaco (NH), hidracina (NH), agua (HO), peróxido de hidrógeno (HO), sulfuro de hidrógeno (HS), etc.

A menudo los compuestos del hidrógeno se denominan hidruros, un término usado con bastante inexactitud. Para los químicos, el término "hidruro" generalmente implica que el átomo de hidrógeno ha adquirido carga parcial negativa o carácter aniónico (denotado como H). La existencia del anión hidruro, propuesta por G. N. Lewis en 1916 para los hidruros iónicos del grupo 1 (I) y 2 (II), fue demostrada por Moers en 1920 con la electrolisis del hidruro de litio (LiH) fundido, que producía una cantidad estequiométrica de hidrógeno en el ánodo. Para los hidruros de metales de otros grupos, el término es bastante erróneo, considerando la baja electronegatividad del hidrógeno. Una excepción en los hidruros del grupo II es el BeH, que es polimérico. En el tetrahidruroaluminato (III) de litio, el anión AlH posee sus centros hidrúricos firmemente unidos al aluminio (III).

Aunque los hidruros pueden formarse con casi todos los elementos del grupo principal, el número y combinación de posibles compuestos varía mucho; por ejemplo, existen más de 100 hidruros binarios de boro conocidos, pero solamente uno de aluminio. El hidruro binario de indio no ha sido identificado aún, aunque existen complejos mayores.

La oxidación del H formalmente origina el protón, H. Esta especie es fundamental para explicar las propiedades de los ácidos, aunque el término «protón» se usa imprecisamente para referirse al hidrógeno catiónico o ion hidrógeno, denotado H. Un protón aislado H no puede existir en disolución debido a su fuerte tendencia a unirse a átomos o moléculas con electrones mediante un enlace coordinado o enlace dativo. Para evitar la cómoda, aunque incierta, idea del protón aislado solvatado en disolución, en las disoluciones ácidas acuosas se considera la presencia del ion hidronio (HO) organizado en clústers para formar la especie HO. Otros iones oxonio están presentes cuando el agua forma disoluciones con otros disolventes.

Aunque exótico en la Tierra, uno de los iones más comunes en el universo es el H, conocido como hidrógeno molecular protonado o catión hidrógeno triatómico.

El isótopo más común de hidrógeno no posee neutrones, existiendo otros dos, el deuterio (D) con uno y el tritio (T), radiactivo con dos. El deuterio tiene una abundancia natural comprendida entre 0,0184 y 0,0082% (IUPAC). El hidrógeno es el único elemento químico que tiene nombres y símbolos químicos distintos para sus diferentes isótopos.

El hidrógeno también posee otros isótopos altamente inestables (del H al H), que fueron sintetizados en el laboratorio, pero nunca observados en la naturaleza.

El hidrógeno es el único elemento que posee diferentes nombres comunes para cada uno de sus isótopos (naturales). Durante los inicios de los estudios sobre la radiactividad, a algunos isótopos radiactivos pesados les fueron asignados nombres, pero ninguno de ellos se sigue usando. Los símbolos D y T (en lugar de ²H y ³H) se usan a veces para referirse al deuterio y al tritio, pero el símbolo P corresponde al fósforo y, por tanto, no puede usarse para representar al protio. La IUPAC declara que aunque el uso de estos símbolos sea común, no es lo aconsejado.

H es un producto de algunos tipos de metabolismo anaeróbico y es producido por diversos microorganismos, por lo general a través de reacciones catalizadas por enzimas que contienen hierro o níquel llamadas hidrogenasas. Estas enzimas catalizan la reacción redox reversible entre H y sus componentes, dos protones y dos electrones. La creación de gas de hidrógeno ocurre en la transferencia de reducir equivalentes producidos durante la fermentación del piruvato al agua.

La separación del agua, en la que el agua se descompone en sus componentes, protones, electrones y oxígeno ocurre durante la fase clara en todos los organismos fotosintéticos. Algunos organismos —incluyendo el alga "Chlamydomonas reinhardtii" y cianobacteria— evolucionaron un paso más en la fase oscura en el que los protones y los electrones se reducen para formar gas de H por hidrogenasas especializadas en el cloroplasto. Se realizaron esfuerzos para modificar genéticamente las hidrogenasas de cianobacterias para sintetizar de manera eficiente el gas H incluso en la presencia de oxígeno. También se realizaron esfuerzos con algas modificadas genéticamente en un biorreactor.

El gas H es producido en los laboratorios de química y biología, muchas veces como un subproducto de la deshidrogenación de sustratos insaturados; y en la naturaleza como medio de expulsar equivalentes reductores en reacciones bioquímicas.

En el laboratorio, el gas H es normalmente preparado por la reacción de ácidos con metales tales como el zinc, por medio del aparato de Kipp.

Zn + 2 H → Zn + H

El aluminio también puede producir H después del tratamiento con bases:

2 Al + 6 HO + 2 OH → 2 Al(OH) + 3 H

La electrólisis del agua es un método simple de producir hidrógeno. Una corriente eléctrica de bajo voltaje fluye a través del agua, y el oxígeno gaseoso se forma en el ánodo, mientras que el gas hidrógeno se forma en el cátodo. Típicamente, el cátodo está hecho de platino u otro metal inerte (generalmente platino o grafito), cuando se produce hidrógeno para el almacenamiento. Si, sin embargo, el gas se destinara a ser quemado en el lugar, es deseable que haya oxígeno para asistir a la combustión, y entonces, ambos electrodos pueden estar hechos de metales inertes (se deben evitar los electrodos de hierro, ya que consumen oxígeno al sufrir oxidación). La eficiencia máxima teórica (electricidad utilizada "vs" valor energético de hidrógeno producido) es entre 80 y 94%.

2HO → 2H(g) + O

En 2007, se descubrió que una aleación de aluminio y galio en forma de gránulos añadida al agua podía utilizarse para generar hidrógeno. El proceso también produce alúmina, pero se puede reutilizar el galio, que previene la formación de una película de óxido en los gránulos. Esto tiene importantes implicaciones para la potenciales economía basada en el hidrógeno, ya que se puede producir en el lugar y no tiene que ser transportado.

El hidrógeno puede ser preparado por medio de varios procesos pero hoy día el más importante consiste en la extracción de hidrógeno a partir de hidrocarburos. La mayor parte del hidrógeno comercial se produce mediante el reformado catalítico de gas natural o de hidrocarburos líquidos. A altas temperaturas (700-1100 °C), se hace reaccionar vapor de agua con metano para producir monóxido de carbono y H:

Esta reacción es favorecida termodinámicamente por un exceso de vapor y por bajas presiones pero normalmente se practica a altas presiones (20 atm) por motivos económicos. La mezcla producida se conoce como "gas de síntesis", ya que muchas veces se utiliza directamente para la síntesis de metanol y otras sustancias químicas. Se pueden usar otros hidrocarburos, además de metano, para producir gas de síntesis con proporciones variables de los productos. 

Si el producto que se desea es solo hidrógeno, se hace reaccionar el monóxido de carbono a través de la reacción de desplazamiento del vapor de agua, por ejemplo con un catalizador de óxido de hierro. Esta reacción es también una fuente industrial común de dióxido de carbono:

Otras opciones para producir hidrógeno a partir de metano son la pirólisis, que resulta en la formación de carbono sólido:

O la oxidación parcial, la cual se aplica también a combustibles como el carbón:

Otro proceso que produce hidrógeno como producto secundario es la electrólisis de salmuera para producir cloro.

Existen más de 200 ciclos termoquímicos que pueden ser utilizados para la separación del agua, alrededor de una docena de estos ciclos, tales como el ciclo de óxido de hierro, ciclo del óxido cerio (III)-óxido cerio(IV), ciclo de óxido zinc-zinc, ciclo del azufre-yodo, ciclo del cobre-cloro, ciclo híbrido del azufre están bajo investigación y en fase de prueba para producir hidrógeno y oxígeno a partir de agua y calor sin utilizar electricidad. Un número de laboratorios (incluyendo Francia, Alemania, Grecia, Japón y Estados Unidos) están desarrollando métodos termoquímicos para producir hidrógeno a partir de energía solar y agua.

En condiciones anaeróbicas, las aleaciones de hierro y acero se oxidan lentamente por los protones de agua concomitante reducidos en hidrógeno molecular (H). La corrosión anaeróbica de hierro conduce primero a la formación de hidróxido ferroso (óxido verde) y se puede describir mediante la siguiente reacción:

A su vez, bajo condiciones anaeróbicas, el hidróxido ferroso (Fe(OH) ) puede ser oxidado por los protones de agua para formar magnetita e hidrógeno molecular. Este proceso se describe por la reacción de Schikorr:

La magnetita así cristalizada (FeO) es termodinámicamente más estable que el hidróxido ferroso (Fe(OH) ).

Este proceso ocurre durante la corrosión anaeróbica de hierro y acero en aguas subterráneas sin oxígeno y en suelos reducidos por debajo del nivel freático.

En ausencia de oxígeno atmosférico (O), en condiciones geológicas profundas que prevalezcan lejos de atmósfera de la Tierra, el hidrógeno (H) se produce durante el proceso del serpentinización por la oxidación anaeróbica de protones del agua (H) del silicato ferroso (Fe) presente en la red cristalina de la fayalita (FeSiO, el hierro olivino). La reacción correspondiente que conduce a la formación de magnetita (FeO), cuarzo SiO) e hidrógeno (H) es la siguiente:

Esta reacción se parece mucho a la reacción de Schikorr observada en la oxidación anaeróbica del hidróxido ferroso en contacto con el agua.

De todos los gases de fallo formados en transformadores eléctricos, el hidrógeno es el más común y se genera bajo la mayoría de condiciones de fallo, por lo que, la formación de hidrógeno es un primer indicio de problemas graves en el ciclo de vida del transformador.

Se necesitan grandes cantidades de H en las industrias del petróleo y química. Una aplicación adicional de H es de tratamiento ("mejoramiento") de combustibles fósiles, y en la producción de amoníaco. Los principales consumidores de H en una planta petroquímica incluyen hidrodesalquilación, hidrodesulfuración, y de hidrocraqueo. El H se utiliza como un agente hidrogenizante, particularmente en el aumento del nivel de saturación de las grasas y aceites insaturados (que se encuentran en artículos como la margarina) y en la producción de metanol. Del mismo modo es la fuente de hidrógeno en la fabricación de ácido clorhídrico. El H también se utiliza como agente reductor de minerales metálicos.

Además de su uso como un reactivo, H tiene amplias aplicaciones en la física y la ingeniería. Se utiliza como gas de protección en los métodos de soldadura tales como la soldadura de hidrógeno atómico. H se utiliza como un enfriador de generadores en centrales eléctricas, porque tiene la mayor conductividad térmica de todos los gases. H líquido se utiliza en la investigaciones criogénicas, incluyendo estudios de superconductividad. Dado que el H es más ligero que el aire, teniendo un poco más de 1/15 de la densidad del aire, fue ampliamente utilizado en el pasado como gas de elevación en globos aerostáticos y dirigibles.

En aplicaciones más recientes, se utiliza hidrógeno puro o mezclado con nitrógeno (a veces llamado "forming gas") como gas indicador para detectar fugas. Las aplicaciones pueden ser encontradas en las industrias automotriz, química, de generación de energía, aeroespacial y de telecomunicaciones. El hidrógeno es un aditivo alimentario autorizado (E 949) que permite la prueba de fugas de paquetes, entre otras propiedades antioxidantes.

Los isótopos más raros de hidrógeno también poseen aplicaciones específicas para cada uno. El deuterio (hidrógeno-2) se utiliza en aplicaciones de la fisión nuclear como un moderador para neutrones lentos, y en las reacciones de fusión nuclear. Los compuestos de deuterio tienen aplicaciones en la química y biología en los estudios de los efectos isotópicos. El Tritio (hidrógeno-3), producido en los reactores nucleares, se utiliza en la producción de bombas de hidrógeno, como un marcador isotópico en las ciencias biológicas, como una fuente de radiación en pinturas luminosas.

La temperatura de equilibrio del punto triple de hidrógeno es un punto fijo definido en la escala de temperatura ITS-90 a 13,8033 Kelvin.

El hidrógeno no es una fuente de energía, excepto en el contexto hipotético de las centrales nucleares de fusión comerciales que utilizan deuterio o tritio, una tecnología actualmente lejos de desarrollo. La energía del sol proviene de la fusión nuclear del hidrógeno, pero este proceso es difícil de lograr de forma controlable en la Tierra. El hidrógeno elemental de fuentes solares, biológicas, o eléctricas requieren más energía para crear lo que es obtenido al quemarlo, por lo que, en estos casos, sirve el hidrógeno como portador de energía, como una batería. Se puede obtener a partir de fuentes fósiles (tales como metano), pero estas fuentes son insustentables.

La densidad de energía por unidad de volumen tanto del hidrógeno líquido como del gas de hidrógeno comprimido en cualquier presión posible es significativamente menor que aquella de fuentes de combustible tradicionales, aunque la densidad de energía por unidad de "masa" de combustible sea más alta. Sin embargo, el hidrógeno elemental ha sido ampliamente discutido en el contexto de la energía, como un posible "portador" de energía futura a gran escala de la economía. Por ejemplo, el secuestro de CO seguido de captura y almacenamiento de carbono podría realizarse al punto de producción de H a partir de combustibles fósiles. El hidrógeno utilizado en el transporte se quemaría relativamente limpio, con algunas emisiones de NOx, pero sin emisiones de carbono. Sin embargo, los costos de infraestructura asociados con la conversión total a una economía del hidrógeno podría ser sustancial.

El hidrógeno es empleado para saturar enlaces rotos de silicio amorfo y carbono amorfo que ayuda a la estabilización de las propiedades del material. Es también un potencial donante de electrones en diferentes materiales óxidos, incluyendo ZnO, SnO, CdO, MgO, ZrO, HfO, LaO, YO, TiO, SrTiO, LaAlO, SiO, AlO, ZrSiO, HfSiO, y SrZrO.

El hidrógeno genera diversos riesgos para la seguridad humana, de potenciales detonaciones e incendios cuando se mezcla con el aire al ser un asfixiante en su forma pura, libre de oxígeno. Además, el hidrógeno líquido es un criogénico y presenta peligros (tales como congelación) asociados con líquidos muy fríos. El elemento se disuelve en algunos metales y, además de fuga, pueden tener efectos adversos sobre ellos, tales como fragilización por hidrógeno. La fuga de gas de hidrógeno en el aire externo puede inflamarse espontáneamente. Por otra parte, el fuego de hidrógeno, siendo extremadamente caliente, es casi invisible, y por lo tanto puede dar lugar a quemaduras accidentales.

Aunque incluso interpretar los datos de hidrógeno (incluyendo los datos para la seguridad) es confundido por diversos fenómenos. Muchas de las propiedades físicas y químicas del hidrógeno, dependen de la tasa de parahidrógeno/ortohidrógeno (por lo general llevar a días o semanas a una temperatura determinada para llegar a la tasa de equilibrio por el cual los resultados suelen aparecer. los parámetros de detonación de hidrógeno, como la presión y temperatura crítica de fundición, dependen en gran medida de la geometría del recipiente.




</doc>
<doc id="1412" url="https://es.wikipedia.org/wiki?curid=1412" title="Herpetología">
Herpetología

La herpetología (del griego «ἑρπετόν», "herpeton" "animal reptante, que se arrastra", y «-λογία» "-logía", tratado, estudio, ciencia) es la rama de la zoología que estudia a los reptiles y anfibios. 

El estudio de los anfibios beneficia al conocimiento del estado del ambiente, porque son muy sensibles a las perturbaciones de los ecosistemas, especialmente la contaminación, en parte porque su primer desarrollo se produce en ambientes acuáticos frecuentemente poco extensos o temporales. 

Algunos venenos y toxinas producidas por los reptiles y los anfibios son útiles en la medicina humana; por ejemplo, el estudio de los venenos de ciertas serpientes se investiga en busca de fármacos anticoagulantes.


</doc>
<doc id="1414" url="https://es.wikipedia.org/wiki?curid=1414" title="Helictotrichon">
Helictotrichon

Helictotrichon, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario Europa, África, Sudeste Asiático, Norte y Sur de América.
Son plantas perennes, cespitosas o cortamente estoloníferas, con innovaciones intra y extravaginales. Hojas con vaina de márgenes ligeramente soldados en la base; lígula corta, truncada, ciliada, membranosa; limbo rígido, con haz surcado y envés liso. Inflorescencia en panícula laxa y ramificada con ramas escábridas. Espiguillas comprimidas lateralmente, con 2-4 flores hermafroditas y articuladas con la raquilla. Glumas 2, desiguales; la inferior con 1-3 nervios, la superior con 3-5 nervios. Lema con dorso redondeado y con 5-7 nervios y ápice bidentado; arista inserta hacia la parte media dorsal de la lema, geniculada, con columna retorcida en hélice y de sección redondeada. Pálea con 2 quillas ciliadas. Lodículas enteras. Ovario con ápice hirsuto. Cariopsis oblongo-elíptica, surcada ventralmente, con ápice peloso. Hilo linear.
Es importante la especie forrajera nativas "H. milanjianum" en Kenia.
El género fue descrito por Besser ex Roem. & Schult. y publicado en "Mantissa" 3: 526, in obs. 1827. La especie tipo es: "Helictotrichon sempervirens" (Vill.) Pilg.
El nombre del género deriva de las palabras griegas "helictos" (espiral) y "trichon", probablemente refiriéndose a la arista. 

El número cromosómico básico del género es x = 7, con números cromosómicos somáticos de 2n = 14, 28, 42, 70, 81, 98, 112, 126, 133 y 147, ya que hay especies diploides y una serie poliploide. Cromosomas relativamente «grandes».




</doc>
<doc id="1415" url="https://es.wikipedia.org/wiki?curid=1415" title="Hemarthria">
Hemarthria

Hemarthria, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario África tropical, Madagascar, Asia Oriental, región Indomalaya y Australia.

Son plantas perennes. Tallo generalmente ramificado. Hojas con lígula representadas por una fila de pelos; las más superiores espatiformes. Inflorescencias axilares o terminales, espiciformes, con raquis marcadamente excavado, con 2 espiguillas por nudo, una sentada (inferior) y alojada en la excavación del raquis, la otra pedunculada (superior) con pedúnculo soldado con la parte externa de uno de los márgenes de la concavidad. Espiguillas no articuladas, comprimidas dorsiventralmente, con 2 flores, la inferior reducida a una lema membranosa, la superior hermafrodita. Glumas 2, la superior de la espiguilla inferior de cada nudo, semimembranosa, soldada parcialmente con la concavidad del raquis, la inferior de la espiguilla inferior y las 2 de la espiguilla superior de cada nudo, coriáceas y con numerosos nervios. Lemas y páleas membranosas, hialinas. Lodículas glabras. Androceo con 3 estambres. Cariopsis con embrión de más de 1/2 de su longitud.
El género fue descrito por Robert Brown y publicado en "Prodromus Florae Novae Hollandiae" 207. 1810. La especie tipo es: "Hemarthria compressa" R.Br. 
El nombre del género deriva de las palabras griegas "hemi" (la mitad) y "arthron" (conjunta), refiriéndose a las articulaciones de la inflorescencia (entrenudos), que son ahuecados. 
Número de la base del cromosoma,x = 9, o 10. 2n = 18 ó 20 (18 +2 B), o 36, o 54. 2, 4, y 6, ploid (y aneuploides). Cromosomas "pequeños". 



</doc>
<doc id="1416" url="https://es.wikipedia.org/wiki?curid=1416" title="Heteropogon">
Heteropogon

Heteropogon, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Tiene una distribución cosmopolita en las regiones tropicales.

El nombre del género deriva de las palabras griegas "heteros" (diferentes) y "pogon" (barba), refiriéndose a las espiguillas fértiles, con barbas las femeninas y sin barbas las masculinas. 
Son matas erectas de gramíneas que se encuentran en las regiones tropicales de todo el mundo, y algunas especies que crecen en zonas templadas y cálidas. Las inflorescencias aparecerán en forma de espiguillas. 
Número de la base del cromosoma, x = 10 y 11. 2n = 20, 22, 40, 44, 50, 60 y 80. 2, 4, 6 y 8, ploid. 



</doc>
<doc id="1417" url="https://es.wikipedia.org/wiki?curid=1417" title="Holcus">
Holcus

Holcus es un género de plantas de la familia de las poáceas, conocidos genéricamente como "pastos dulces" o "pastos miel" por el contenido en glucosa de la hoja (aunque no deben confundirse con el "Paspalum dilatatum", al que también se conoce por ese nombre). 
Son nativos de Eurasia, y prefieren los climas frescos y templados.
Los tallos son cortos, rodeados de hojas lisas de color verde grisáceo. Las inflorescencias son de color blanco o violáceo, y miden entre 2 y 6 cm de largo. 

Son plantas anuales o perennes. Hojas con vaina de márgenes libres; lígula dentada, membranosa; limbo plano o ligeramente convoluto. Inflorescencia en panícula laxa. Espiguillas ligeramente comprimidas lateralmente, con 2 (-3) flores articuladas con la raquilla. Raquilla prolongada por encima de la última flor, generalmente pelosa. Glumas más largas que las flores, ligeramente desiguales, aquilladas; la inferior uninervada; la superior trinervada. Lema elíptica, con 5 nervios, truncada; la de la flor inferior mútica o aristada; la de la flor superior generalmente aristada; arista dorsal o subterminal, geniculada o curvada. Callo obtuso y corto. Pálea más corta que la lema, con 2 quillas escábrida. Lodículas generalmente con 1 diente lateral. Ovario glabro. Cariopsis oblongo-elíptica, ligeramente surcada. Hilo elíptico.
El género fue descrito por Carlos Linneo y publicado en "Species Plantarum" 2: 1047. 1753. La especie tipo es: "Holcus lanatus" L.



</doc>
<doc id="1418" url="https://es.wikipedia.org/wiki?curid=1418" title="Hordelymus">
Hordelymus

Hordelymus, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Eurasia.




</doc>
<doc id="1419" url="https://es.wikipedia.org/wiki?curid=1419" title="Hordeum">
Hordeum

Hordeum, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Norteamérica y del norte de Asia.
Es un género de plantas perteneciente a la familia Gramíneas o Poáceas, pueden ser anuales o perennes, menores de 1,6 m de altura.
Morfológicamente se puede distinguir una vaina con dos apéndices auriculiformes en la zona ligular, lígula corta y láminas planas, excepcionalmente setáceas.
Poseen una flor hermafrodita con 3 estambres, fruto cariopse oblongo, deprimido con surco ventral y ápice pubescente, adherido a las glumelas o separándose de ellas por efecto de la trilla.
La inflorescencia es en espigas, las cuales pueden ser dísticas o comprimidas, con un raquis frágil o tenaz. Espiguillas unifloras dispuestas de a 3 en cada soporte del raquis, con el dorso de la lemma hacia afuera; la espiguilla central es siempre hermafrodita, las laterales pueden ser hermafroditas o estériles; raquilla articulada arriba de las glumas y prolongaciones en apéndice filiforme, piloso o glabro.
Glumas 2, lanceoladas o lineares.

Lemma lanceolada, 5-nervada, aristada, trifurcada o mútica.

Existen aproximadamente unas 25 a 30 especies en las regiones templadas de todo el mundo, 4 de las cuales son domésticas:
"Hordeum vulgare; Hordeum distichum; Hordeum intermedium; Hordeum deficens". En general prefieren un suelo fértil bien drenado a pleno sol.
El género fue descrito por Carlos Linneo y publicado en "Species Plantarum" 1: 84–85. 1753. 1753. La especie tipo es: " Hordeum vulgare" L
Hordeum: nombre antiguo latino para la cebada.
El número de cromosomas es de: x = 7. 2n = 14, 28, y 42





</doc>
<doc id="1420" url="https://es.wikipedia.org/wiki?curid=1420" title="Hyparrhenia">
Hyparrhenia

Hyparrhenia, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de África.

La mayoría son nativas de África tropical, algunas se pueden encontrar en zonas cálidas templadas en Eurasia. Son gramíneas anuales y perennes. La inflorescencia surge como dobles espigas de espiguillas en parejas.

Son plantas perennes, cespitosas. Hojas con lígula membranosa, obtusa o truncada, denticulada, glabra. Inflorescencia en panícula, compuesta por varios pares de racimos, parcialmente envueltos por vainas espatiformes. Espiguillas geminadas, articuladas por debajo de las glumas, ligeramente comprimidas dorsiventralmente, desiguales; la inferior de cada pareja sentada, con 1 flor inferior reducida a la lema y otra superior hermafrodita; la superior pedunculada, con 1 flor inferior reducida a la lema y otra superior masculina. Glumas más largas que las flores, subiguales; la inferior con 7-11 nervios y 2 quillas; la superior trinervada. Lema de las flores hermafroditas con arista terminal 1-2 veces geniculada; la de las flores masculinas mútica. Pálea muy reducida o ausente. Lodículas glabras. Androceo con 3 estambres. Cariopsis con embrión de c. 1/3 de su longitud.
El género fue descrito por Andersson ex E.Fourn. y publicado en "Mexicanas Plantas" 2: 51, 67. 1886. La especie tipo es: "Hyparrhenia foliosa" (Kunth) Andersson ex E. Fourn. 
Hyparrhenia: nombre genérico que deriva del griego "hipo" = (bajo) y "arrhen" = (masculino), en alusión a que las espiguillas masculinas solo se encuentran en las bases del racimo.
El número de cromosomas es de : x = 10 y 15. 2n = 20, 30, 40, 44, 45, y 60. 2, 4, y 6 ploides. Nucleolos persistentes.



</doc>
<doc id="1421" url="https://es.wikipedia.org/wiki?curid=1421" title="Helada (desambiguación)">
Helada (desambiguación)

La palabra helada puede referirse a:


</doc>
<doc id="1424" url="https://es.wikipedia.org/wiki?curid=1424" title="Hombre (desambiguación)">
Hombre (desambiguación)

Hombre hace referencia a varios artículos:









</doc>
<doc id="1426" url="https://es.wikipedia.org/wiki?curid=1426" title="Homo sapiens">
Homo sapiens

Homo sapiens (del latín, "homo" ‘hombre’ y "sapiens" ‘sabio’) es una especie del orden de los primates perteneciente a la familia de los homínidos. También son conocidos bajo la denominación genérica de «hombres», aunque ese término es ambiguo y se usa también para referirse a los individuos de sexo masculino y, en particular, a los varones adultos. Los seres humanos poseen capacidades mentales que les permiten inventar, aprender y utilizar estructuras lingüísticas complejas, lógicas, matemáticas, escritura, música, ciencia, y tecnología. Los humanos son animales sociales, capaces de concebir, transmitir y aprender conceptos totalmente abstractos.

Se consideran "Homo sapiens" de forma indiscutible a los que poseen tanto las características anatómica de las poblaciones humanas actuales como lo que se define como «comportamiento moderno». Los restos más antiguos de "Homo sapiens" se encuentran en Marruecos con 315 000 años. La evidencia más antigua de comportamiento moderno son las de Pinnacle Point (Sudáfrica) con 165 000 años.

Pertenece al género "Homo" que fue más diversificado y, durante el último millón y medio de años incluía otras especies ya extintas. Desde la extinción del "Homo neanderthalensis", hace 28 000 años, y del "Homo floresiensis" hace 12 000 años (debatible), el "Homo sapiens" es la única especie conocida del género "Homo" que aún perdura.

Hasta hace poco, la biología utilizaba un nombre trinomial —"Homo sapiens sapiens"— para esta especie, pero más recientemente se ha descartado el nexo filogenético entre el neandertal y la actual humanidad, por lo que se usa exclusivamente el nombre binomial. "Homo sapiens" pertenece a una estirpe de primates, los hominoideos. Aunque el descubrimiento de "Homo sapiens idaltu" en 2003 haría necesario volver al sistema trinomial, la posición taxonómica de este último es aún incierta. Evolutivamente se diferenció en África y de ese ancestro surgió la familia de la que forman parte los homínidos.
Filosóficamente, el ser humano se ha definido y redefinido a sí mismo de numerosas maneras a través de la historia, otorgándose de esta manera un propósito positivo o negativo respecto de su propia existencia. Existen diversos sistemas religiosos e ideales filosóficos que, de acuerdo a una diversa gama de culturas e ideales individuales, tienen como propósito y función responder algunas de esas interrogantes existenciales. Los seres humanos tienen la capacidad de ser conscientes de sí mismos, así como de su pasado; saben que tienen el poder de planear, transformar y realizar proyectos de diversos tipos. En función a esta capacidad, han creado diversos códigos morales y dogmas orientados directamente al manejo de estas capacidades. Además, pueden ser conscientes de responsabilidades y peligros provenientes de la naturaleza, así como de otros seres humanos.

El nombre científico, es el asignado por el naturalista sueco Carlos Linneo (1707-1778) en 1758, alude al rasgo biológico más característico: "sapiens" significa «sabio» o «capaz de conocer», y se refiere a la consideración del ser humano como «animal racional», al contrario que todas las otras especies. Es precisamente la capacidad del ser humano de realizar operaciones conceptuales y simbólicas muy complejas —que incluyen, por ejemplo, el uso de sistemas lingüísticos muy sofisticados, el razonamiento abstracto y las capacidades de introspección y especulación— uno de sus rasgos más destacados. Posiblemente esta complejidad, fundada neurológicamente en un aumento del tamaño del cerebro y, sobre todo, en el desarrollo del lóbulo frontal, sea también una de las causas, a la vez que producto, de las muy complejas estructuras sociales que el ser humano ha desarrollado, y que forman una de las bases de la cultura, entendida biológicamente como la capacidad para transmitir información y hábitos por imitación e instrucción, en vez de por herencia genética. Esta propiedad no es exclusiva de esta especie y es importante también en otros primates.

Linneo clasificó al hombre y a los monos en un grupo que llamó antropomorfos, como subconjunto del grupo cuadrúpedos, pues entonces no reconocía signos orgánicos que le permitieran ubicar al ser humano en un lugar privilegiado de la escala de los vivientes. Años más tarde, en el prefacio de "Fauna suecica", manifestó que había clasificado al hombre como cuadrúpedo porque no era planta ni piedra, sino un animal, tanto por su género de vida como por su locomoción y porque además, no había podido encontrar un solo carácter distintivo por el cual el hombre se diferenciara del mono; en otro contexto afirmó sin embargo que considera al hombre como el fin último de la creación. A partir de la décima edición de "Systema naturae" reemplazó a los cuadrúpedos por los mamíferos y como primer orden de estos, puso a los primates, entre los cuales colocó al hombre. Linneo tuvo el mérito de dar origen a un nuevo e inmenso campo epistemológico, el de la antropología, si bien se limitó a enunciarlo y no lo cultivó. A él tendrán que remitirse todos los científicos posteriores, tanto para retomar sus definiciones como para criticarlas. En 1758 se definió al "Homo sapiens" linneano como una especie diurna que cambiaba por la educación y el clima. 

Linneo no designó un holotipo para "Homo sapiens", pero en 1959 William Stearn propuso al propio Linneo, padre de la moderna taxonomía, como lectotipo para la especie. Con posterioridad se difundió la idea de que había sido sustituido por Edward Cope, pero esta propuesta no llegó a formalizarse, así que siguen siendo los restos de Linneo enterrados en Uppsala el tipo nomenclatural -que debe considerarse simbólico- para la especie "Homo sapiens". 

En la actualidad existen defensores de incluir al ser humano, chimpancé ("Pan troglodytes") y bonobo ("Pan paniscus") en el mismo género, dada la cercanía filogenética, que es más estrecha que la que se encuentra entre otras especies animales que sí están agrupadas genéricamente.

El ser humano es un ser vivo, y como tal está compuesto por sustancias químicas llamadas biomoléculas, por células y realiza las tres funciones vitales: nutrición, relación y reproducción.

Además, el cuerpo es un organismo pluricelular, es decir, está formado por muchas células, entre las cuales existen diferencias de estructuras y de función.

Por otra parte, el ser humano es un animal, pues tiene células eucariotas, es decir, presenta orgánulos celulares especializados en una función determinada y su material genético se encuentra protegido por una envoltura; y presenta nutrición heterótrofa, es decir, que para obtener su propia materia orgánica se alimenta de otros seres vivos.

En cuanto a su locomoción y movimiento, es uno de los más plásticos del reino animal, pues existe una amplia gama de movimientos posibles, lo que le capacita para actividades como el arte escénico y la danza, el deporte y un sinnúmero de actividades cotidianas. Asimismo destaca la habilidad de manipulación, gracias a los pulgares oponibles, que le facilitan la fabricación y uso de instrumentos.

La especie humana posee un notorio dimorfismo sexual en el nivel anatómico, por ejemplo, la talla media actual entre los varones caucásicos (si crecen bien nutridos y con poco estrés) hacia los 21 años es de 1.75 m, la talla media de las mujeres caucásicas en iguales condiciones es de 1.62 m, y los pesos promedios respectivos son de 75 kg y 61 kg respectivamente; aunque sí se ha notado una «tendencia secular» al aumento de las tallas (especialmente durante el siglo XX).

La mente se refiere colectivamente a aspectos del entendimiento y conciencia que son combinaciones de capacidades como el raciocinio, la percepción, la emoción, la memoria, la imaginación y la voluntad. La mente, para los materialistas, es un resultado de la actividad del cerebro.

El término pensamiento define todos los productos que la mente puede generar incluyendo las actividades racionales del intelecto o las abstracciones de la imaginación; todo aquello que sea de naturaleza mental es considerado pensamiento, bien sean estos abstractos, racionales, creativos, artísticos, etc. Junto con los cetáceos superiores (delfines y ballenas), los homininos de los géneros "Gorilla" y "Pan" y los elefantes, alcanza el mayor desarrollo en la escala evolutiva y aún muchas de sus interacciones nos son desconocidas.

El ser humano es un animal omnívoro.  En las primeras especies del género "Homo", el paso de una alimentación eminentemente vegetariana a la inclusión de la carne en la dieta no se debió a cuestiones culturales, sino a los desajustes metabólicos provocados por un mayor desarrollo cerebral. Sin embargo, en el humano, una dieta demasiado rica en proteínas necesita el complemento de carbohidratos y grasas, de lo contrario pueden aparecer carencias nutricionales importantes que pueden incluso provocar la muerte. Por ello, la alimentación del ser humano se basa en la combinación de materia vegetal con carne, aunque hay humanos que optan debido a voluntad propia o razones médicas a consumir dietas vegetarianas.

La especie humana es entre los seres vivos pluricelulares actuales una de las más longevas; se tienen documentados casos de longevidad que sobrepasan los cien años. Tal longevidad es un carácter genotípico que, sin embargo, debe ser coadyuvado por condiciones vivenciales favorables. En el Imperio romano, hacia el año 1 d. C., la esperanza de vida rondaba sólo los veinticinco años, debido en gran parte a la elevada mortalidad infantil. La edad de la pubertad es aproximadamente a los once años en las niñas y a los trece años en los niños, aunque las edades varían según la persona.
Entre otras implicaciones, la importancia del lenguaje simbólico en el "Homo sapiens", hace que los significantes sean los soportes del pensar o los pensamientos. En nuestra especie, el pensar humano, a partir de los tres años y medio de edad se hace prevalentemente simbólico.

Asociado con lo anterior (y esto lo explica el psicoanálisis), debe notarse que la especie humana es prácticamente la única que se mantiene en celo sexual continuo: es realmente destacable que en la especie humana no exista un estro propiamente dicho. En las mujeres existe un ciclo de actividad ovárica en virtud del cual existen cambios fisiológicos en todo su sistema reproductivo y del cual derivan ciertos cambios de conducta. Sin embargo, como en las mujeres la aceptación sexual no se circunscribe a una parte del ciclo reproductivo, no se debería usar el término ""estro"" o ""celo"" en el ser humano, dado que la aceptación sexual es independiente de su ciclo reproductivo. Ya entre chimpancés y, sobre todo, bonobos, se nota una conducta próxima.

Ahora bien; dada la dificultad de vivir "solamente" practicando relaciones sexuales, un "mecanismo" evolutivo compensatorio habría sido el de la sublimación –la cual se considera asociada a la existencia de un lenguaje y un pensar simbólicos–, si se da una sublimación esto parece significar que, también se da una "represión" (en el sentido freudiano) que origina a lo inconsciente. El "Homo sapiens" es, en este sentido, un "animal pulsional". Según la reflexología de Pavlov el "Homo sapiens" "no" se restringe a un "primer sistema de señales" (el de estímulo/respuesta y respuesta a un estímulo substitutivo), sino que el ser humano se encuentra en un nivel de "segundo sistema de señales". Este segundo sistema es, principalmente el del lenguaje simbólico que permite una heurística, que es la capacidad para realizar de forma inmediata innovaciones positivas para sus fines.

Por otra parte, la especie humana es de las pocas, junto con el bonobo ("Pan paniscus") en el reino animal que copula cara a cara, lo cual tiene implicaciones emocionales de gran relevancia para la especie.

Cabe anotar que con el surgimiento de la teoría de la inteligencia emocional, desde la psicología sistémica, el ser humano no debe reducirse a sus pulsiones, las cuales sublima o reprime, sino que se entiende como un ser sexuado, que vive esta dimensión en relación con la formación recibida en la familia y la sociedad. La sexualidad se forma entonces desde los primeros años y se va entendiendo como una vivencia procesual acorde a su ciclo vital y su contexto socio-cultural.

A diferencia de lo que ocurre en la mayor parte de las otras especies sexuadas, la mujer sigue viviendo mucho tiempo tras la menopausia. En las otras especies la hembra suele fenecer al poco tiempo de llegada la misma.

Por la indicada prematuración, la madurez sexo-genital es –en relación a otras especies– muy tardía entre los individuos de la especie humana, actualmente en muchas zonas la menarquia está ocurriendo a los once años, esto significa que, aunque la madurez sexo-genital es siempre lenta en la especie humana, existe un adelantamiento de la misma respecto a épocas pasadas (del mismo modo suele darse una menopausia cada vez más tardía). Pero si la madurez sexo-genital es tardía en la especie humana, aún más suele serlo la madurez intelectual y, en especial la "madurez emotiva".

A lo largo de la historia se han ido desarrollando distintas concepciones míticas, religiosas, filosóficas y científicas respecto del ser humano, cada una con su propia explicación sobre el origen del hombre, trascendencia y misión en la vida.

Evolutivamente, en cuanto perteneciente al infraorden Catarrhini, "Homo sapiens" parece tener su ancestro, junto con todos los primates catarrinos, en un período que va de los 50 a 33 millones de años antes del presente (AP), uno de los primeros catarrinos, quizás el primero, es "Propliopithecus", incluyendo a "Aegyptopithecus", en este sentido, el ser humano actual, al igual que primates del "Viejo Mundo" con características más primitivas, probablemente descienda de esa antigua especie.

En cuanto a la bipedestación, ésta se observa en ciertos primates a partir del Mioceno. Ya se encuentran ejemplos de bipedación en "Oreopithecus bambolii" y la bipedestación parece haber sido común en "Orrorin" y "Ardipithecus". Las mutaciones que llevaron a la bipedación fueron exitosas porque dejaba libre las manos para coger objetos y, particularmente, porque en la marcha un homínido ahorra mucha más energía andando sobre dos piernas que sobre cuatro patas, puede acarrear objetos durante la marcha y otear más lejos. Sin embargo, de remontarse la bipedestación a quizás a unos 6 millones de años aP, la andadura o forma de marcha típica del humano se consolida aproximadamente hace al menos unos 4 millones de años con "Australopithecus", previo a éstos los primates antropoides apoyaban toda la planta del pie haciendo una flexión y descargando el peso en el calcáneo, en cambio "Australopithecus" logra una marcha bípeda eficiente, pues se notan claramente los cambios anatómicos a nivel del pie, en especial del dedo gordo; también ajustando el ángulo del fémur con el cuerpo para el equilibrio, la cadera o pelvis cambia a más robusta, corta y cóncava (forma de cuenco); la columna pasó de ser un arco en forma de C a una forma de S y el agujero de la base del cráneo que conecta con la columna se desplazó hacia adelante como dirigiéndose al centro de gravedad de la cabeza.

Hace 1.5 millones de años con "Homo erectus" o con "Homo ergaster", la andadura moderna implica la existencia de un pequeño ángulo entre el dedo gordo y el eje del pie, así como la presencia del arco longitudinal de la planta y una distribución medial del peso (notar que en las mujeres la andadura distribuye el peso más hacia las partes internas del pie debido a la mayor anchura de la pelvis).

Todos los cambios reseñados han sucedido en un periodo relativamente breve (aunque se mida en millones de años), esto explica la susceptibilidad de nuestra especie a afecciones en la columna vertebral y en la circulación sanguínea y linfática (por ejemplo, el corazón recibe -relativamente- "poca" sangre).

Lo que denominamos propiamente «humano», es una referencia a la aparición de la capacidad de fabricar herramientas de piedra en un homínido bípedo: "Homo habilis", considerado por la mayoría como la especie humana más primitiva, mostrando además incremento en la capacidad craneana con respecto a "Australopithecus". Es así como se establece que hace unos 2.5 millones de años, con la aparición del género "Homo", se toma como punto de inicio para el Paleolítico o Edad de Piedra. Mayor éxito evolutivo tendrá "Homo erectus", quien logrará expandirse por todo Eurasia.
Probablemente cuando los ancestros de "Homo sapiens" vivían en selvas comiendo frutos, bayas y hojas, abundantes en vitamina C, pudieron perder la capacidad metabólica, que tiene la mayoría de los animales, de sintetizar en su propio organismo tal vitamina; ya antes parecen haber perdido la capacidad de digerir la celulosa. Tales pérdidas durante la evolución han implicado sutiles pero importantes determinaciones: cuando las selvas originales se redujeron o, por crecimiento demográfico, resultaron superpobladas, los primitivos homínidos (y luego los humanos) se vieron forzados a recorrer importantes distancias, migrar, para obtener nuevas fuentes de nutrientes, la pérdida de la capacidad de metabolizar ciertos nutrientes como la vitamina C habría sido compensada por una mutación favorable que permite a "Homo sapiens" una metabolización óptima (ausente en primates) del almidón y así una rápida y "barata" obtención de energía, particularmente útil para el cerebro. "Homo sapiens" parece ser una criatura bastante indefensa y como respuesta satisfactoria la única solución evolutiva que ha tenido es su complejísimo sistema nervioso central. Espoleado principalmente por la busca de nuevas fuentes de alimentación. Se ha sugerido la hipótesis de que la cefalización aumentó paralelamente al incremento de consumo de carne, aunque dicha hipótesis no concuerda con el grado de cefalización desarrollada por los animales carnívoros. La habilidad humana para digerir alimentos con alto contenido de almidón podría explicar el éxito del homo sapiens en el planeta, sugiere un estudio genético.

Se denomina «humanos arcaicos», «"Homo sapiens" arcaico» o también «pre-sapiens», a un cierto número de especies de "Homo" que aún no son considerados anatómicamente modernos. Poseen hasta 600 000 años de antigüedad y tienen un tamaño cerebral cercano al de los humanos modernos. El antropólogo Robin Dunbar opina que es en esta etapa en la cual aparece el lenguaje humano. La filiación de estos individuos dentro de nuestro género resulta aún controvertida.

Entre los humanos arcaicos están considerados "Homo heidelbergensis", "Homo rhodesiensis", "Homo neanderthalensis" y a veces "Homo antecessor"; en 2010 se ha añadido a éstos el denominado «hombre de Denísova», y en 2012 el denominado «hombre del ciervo rojo» en China. Ya que no son "sapiens", algunos especialistas prefieren llamarlos simplemente "arcaicos" antes que "H. sapiens" arcaico.

Se denominan propiamente Homo sapiens o anatómicamente modernos a individuos con una apariencia similar a la de los humanos modernos. Estos humanos pueden clasificarse como premodernos, pues en ellos no se observa todavía el conjunto de características de un cráneo moderno, casi esférico, con la bóveda alta y la frente vertical. La similitud se aprecia a nivel del esqueleto del cuerpo y cavidad craneana, pero esta similitud no es total pues el rostro aún mantiene características arcaicas como los arcos superciliares (grandes cejas) y prognatismo maxilar (proyección bucal), aunque menos desarrollados que en los neandertales.

Se consideran dentro de este grupo a los restos de Florisbad en Sudáfrica (260 000 años), los de Herto en Etiopía, que corresponde a "Homo sapiens idaltu" (160 000 años), los de Jebel Irhoud en Marruecos (315 000 años) y los de Skhul/Qafzeh al Norte de Israel (100 000 años). También se consideran anatómicamente modernos a los hombres de Kibish, sin embargo estos se enmarcan mejor dentro de los humanos modernos.

Se consideran Homo sapiens sapiens de forma indiscutible a los que poseen las características principales que definen a los humanos modernos: primero la equiparación anatómica con las poblaciones humanas actuales y luego lo que se define como "comportamiento moderno".

Actualmente, gracias a los análisis científicos, se sabe que en la genealogía de la evolución humana habría existido un antepasado común masculino y uno femenino; a los cuales se les nombró como sus símiles religiosos.

Los restos más antiguos son los de Omo I, llamados Hombres de Kibish, encontrados en Etiopía con 195 000 años, y restos en cuevas del río Klasies en Sudáfrica con 125 000 años y con indicios de una conducta más moderna.

Esta antigüedad coincide con lo estimado para la Eva mitocondrial, la cual está considerada la antecesora de todos los seres humanos actuales y de la que se cree que vivió en el África Oriental (probablemente Tanzania) hace unos 200 000 años.

Por otra parte, la línea patrilineal nos lleva hasta el Adán cromosómico, quien nos confirma un origen para los humanos modernos en el África subsahariana y se le calcula unos 140 000 años de antigüedad.

Es casi seguro que la Eva mitocondrial y el Adán, los primeros "Homo sapiens" eran melanodérmicos, esto es, de tez oscura. Esto se debe a que la piel oscura es una excelente adaptación a la exposición solar alta de las zonas intertropicales del planeta Tierra; la tez oscura (por la melanina) protege de las radiaciones UV (ultravioletas) y obtiene de ellas por metabolismo un nutriente llamado folato, indispensable para el desarrollo del embrión y del feto; pero, a medida que las poblaciones humanas migraron a latitudes más allá de los 45º (tanto Norte como Sur) la melanina paulatinamente fue menos necesaria, más aún, en las cercanías de las latitudes de los 50º la casi total falta de este pigmento en la dermis, cabello y ojos ha sido una adaptación para captar más radiaciones U.V. —relativamente escasas en tales latitudes, salvo que se produzcan huecos de ozono—; en tales latitudes la tez muy clara posibilita una mayor metabolización de vitamina D a partir de las radiaciones UV.

La aparición del comportamiento humano moderno significó el más importante cambio en la evolución de la mente humana, dando lugar a que el ingenio creativo humano le llevaría a dominar su entorno paulatinamente. Una revolución humana que nos hizo como somos hoy.

Las innovaciones que fueron apareciendo consisten en una gran diversidad de herramientas de piedra, en el uso de hueso, asta y marfil, en entierros con bienes funerarios y rituales, construcción de viviendas, diseño de las fogatas, evidencia de pesca, cacería compleja, aparición del arte figurativo y el uso de adornos personales.

Las evidencias más antiguas se encuentran en África; herramientas elaboradas hace 165 000 años se encontraron en la cueva de Pinnacle Point (Sudáfrica). Restos de puntas de flechas y herramientas de hueso para pescar se encontraron en el Congo y tienen 90 000 años. Igualmente antiguos son unos símbolos sombreados con ocre rojo en costas al sur de África.
Según la teoría fuera de África, hubo una gran migración de África hacia Eurasia hace 70 000 años que produjo la paulatina dispersión por todos los continentes. Según los estudios genéticos y los descubrimientos paleontológicos, se estima que hace 60 000 años hubo una migración costera por el Sur de Asia, de pocos miles de años, que posibilitó la colonización posterior de Australia, Extremo Oriente y Europa.

En Occidente hubo un centro de expansión en el Medio Oriente que está relacionado con el hombre de Cromañón y la población temprana de Europa; probable causa de la extinción del hombre de Neandertal.

Según algunos estudios genéticos, en Europa hubo tres migraciones: la primera, proveniente del Asia Central hace 40 000 años que colonizó la Europa del Este. Una segunda oleada hace 22 000 años, proveniente del Oriente Medio, que se instaló en la Europa del sur y del oeste. El 80 % de los europeos actuales son descendientes de estas dos migraciones, que durante el transcurso del máximo glaciar de hace 20 000 años, se refugiaron en la Península Ibérica y en los Balcanes, para volver a expandirse por el resto de Europa cuando llegó el clima favorable. La tercera migración se habría producido hace 9000 años, proveniente del Oriente Medio, durante el transcurso del Neolítico y sólo el 20 % de los europeos actuales llevan marcadores genéticos correspondientes a esos emigrantes.

Sin embargo otros estudios dicen lo contrario, afirmando que en Europa el componente neolítico desde el Cercano Oriente es el más importante. Lo cierto por ahora es que el acervo genético europeo prehistórico proviene mayoritariamente del Cercano Oriente, y una menor parte proviene de África, Asia Central y Siberia.

En Oriente la población es igualmente antigua. El pliegue epicántico de los párpados existente en gran parte de las poblaciones del Asia y de América, el pliegue que hace 'bridados' en su aspecto externo a los ojos, ha sido una especialización de poblaciones que durante las glaciaciones debieron pervivir en lugares con abundancia de nieve; los ojos vulgarmente llamados «rasgados» entonces fueron el modo de adaptación para que los ojos no padecieran un excesivo reflejo de la luz solar reflejada por la nieve.
El lenguaje designa todas las comunicaciones basadas en la interpretación, incluyendo el lenguaje humano, pero la mayoría de las veces el término se refiere a lo que los humanos utilizan para comunicarse, es decir, a las lenguas naturales. El lenguaje es universal y es usado por naturaleza en las personas y en los animales. Sin embargo, filósofos como Martin Heidegger consideran que el lenguaje propiamente tal es sólo privativo del hombre. Es famosa la tesis de Heidegger según la cual el lenguaje es la casa del ser (Haus des Seins) y la morada de la esencia humana. Este criterio es similar al de Ernst Cassirer quien ha definido al "Homo sapiens" como el "animal simbólico por excelencia"; tan es así que es casi imposible suponer un pensamiento humano sin la ayuda de los símbolos, particularmente de los significantes que subyacen como fundamentos elementales para todo pensar complejo y que transcienda a lo instintivo.

Actualmente la especie humana muestra esta faceta hablando en torno a 6000 idiomas diferentes, si bien más del 50 % de los 7000 millones de personas que actualmente conforma la colectividad humana, sabe hablar al menos una de las siguientes ocho lenguas: chino mandarín, español, inglés, árabe, hindi, portugués, bengalí o ruso.

En muchas civilizaciones los seres humanos se han visto a sí mismos como diferentes de los demás animales, y en ciertos ámbitos culturales (como las religiones del Libro o buena parte de la metafísica del Occidente) la diferencia se asigna a una entidad inmaterial llamada alma, en la que residirían la mente y la personalidad, y que algunos creen que puede existir con independencia del cuerpo.
Posiblemente, la manifestación más clara de humanidad es el arte —en el sentido amplio del término—, que produce la cultura. Por ejemplo, los individuos de una determinada especie de ave fabrican un nido, o emiten un canto, cuyas características son específicas, comunes a todos los individuos de esa especie. En cambio, cada hombre puede imprimir a sus acciones los rasgos propios de su individualidad; por eso, cuando se analiza un cuadro, una forma de escribir, una manera de fabricar herramientas, etc., se puede deducir quién es su autor, su artífice, su artista.

En año 2011, en la revista "Science", se publicó un trabajo de Francesco d'Errico, de la Universidad de Burdeos en Francia, donde afirman haber encontrado uno de los rastros más antiguos de un taller de pintura, en la cueva Blombos en Cape Coast, 300 km al este de Ciudad del Cabo, este hecho muestra un modo sistemático para obtener pigmentos, pues reunir todos los elementos necesarios para una preparación de este tipo, es indicativo de un elevado nivel de pensamiento, que se puede llamar pensamiento simbólico. "La capacidad de tener estos pensamientos es considerado un gran paso en la evolución humanas precisamente lo que nos diferenció del mundo animal".

Paralelamente, también somos la única especie que dedica su tiempo y energía a algo aparentemente inútil desde el punto de vista puramente práctico. El arte es una de las manifestaciones de la creatividad humana, pero una manifestación vacía y negativa desde el punto de vista de la supervivencia. Si bien, esta actividad en principio dañina, en realidad es la herramienta con la cual desarrollamos nuestra cultura, nuestra unión, y nuestra fuerza como pueblo. Nos divide y separa de unos pueblos; y nos hermana con otros. En esta telaraña que envuelve a nuestras sociedades, a nuestro planeta.

Una sociedad humana es aquella que se considera a sí misma, a los habitantes y a su entorno; todo ello interrelacionado con un proyecto común, que les da una identidad de pertenencia. Asimismo, el término connota un grupo con lazos económicos, ideológicos y políticos. Tal sociedad supera al concepto de nación-estado, planteando a la sociedad occidental como una sociedad de naciones, etc.

En relación con la capacidad para realizar grandes modificaciones ambientales, cabe decir que "Homo sapiens" es actualmente un poderoso agente geomorfológico; es en este y otros sentidos en que el ser humano es actualmente el mayor superpredador y la especie más poderosa del planeta, en comparación con los demás especies. Sin embargo, sigue siendo frágil ante posibles eventos cataclísmicos que pudieran afectar su hábitat, como las glaciaciones.

"Homo sapiens", por ser un animal muy vulnerable en estado de naturaleza, es muy dependiente de la tecnología (ergo: es dependiente de la ciencia por primitiva que esta sea), así es que se dice de "Homo sapiens" que es "homo faber".

Quizás, dado que todo sistema retroalimentado de forma natural llega a su fin, el fin de un ecosistema llega cuando la vida ha logrado evolucionar hasta lograr seres con un grado de conciencia capaz de programarse en función de la educación recibida y no según lo termodinámicamente sostenible. La educación es, por tanto, la demostración evidente de si somos parte de un sistema aún mayor o intentamos independizarnos de todo, estableciendo nuestras formas de obtener nuestros recursos, sin tener en cuenta los ya establecidos por la propia naturaleza.

Por ejemplo, la naturaleza le dota de capacidades físicas para buscar alimentos en el medio que les rodea de una manera termodinámicamente eficaz. Los humanos establecen que lo mejor es racionalizar los medios que la naturaleza les da y replicarlos de forma industrial, aplicando procesos que no se dan de forma natural, aumentando el consumo energético por redundar algo que ya existe y ampliándolo a algo totalmente termodinámicamente innecesario, como es el hecho de que se le entregue alimento en casa, de intervenir los códigos genéticos de los alimentos para hacerlos resistentes a enfermedades, de influir en qué alimentos contendrán semillas y cuáles no y un largo etcétera, que a día de hoy nos hace la vida más cómoda, pero que ignoran cómo les afectan esos cambios en su estructura genética y, por lo tanto, si su descendencia portará características fundamentales para sobrevivir a un medio natural o, por el contrario, nacerán y dependerán tan íntimamente del medio artificial que cualquier modificación a ese medio le incapacite de tal manera que provoque su extinción.




</doc>
<doc id="1427" url="https://es.wikipedia.org/wiki?curid=1427" title="Humana Inc.">
Humana Inc.

Humana Inc. (), fundada el año 1961 en Louisville, Kentucky, es una corporación empresarial que comercializa y administra seguros de salud. Con un conjunto de 11,5 millones de clientes en Estados Unidos, la compañía es la mayor en términos de beneficio del estado de Kentucky e integrante de la lista Fortune 100. Asimismo tiene una capitalización bursátil de más de 13 mil millones de dólares, beneficios por valor de 25,2 mil millones y posee 26.000 empleados en todo Norteamérica. Humana comercializa sus seguros de salud en los 50 estados de EE.UU., Washington D.C y Puerto Rico, poseyendo además intereses económicos en Europa Occidental.

La compañía fue fundada por David A. Jones, Sr. y Wendell Cherry como empresa propietaria de residencias de la tercera edad en 1961. Entonces llamada Extendicare, llegó a ser la mayor empresa de este tipo en los Estados Unidos, para dejar esta actividad de lado y centrarse en la compra de hospitales en 1972. Llegó a ser la mayor compañía hospitalaria del mundo en la década de los ochenta. 

El nombre de la compañía cambió a Humana Inc. en 1974. Humana sufrió un tremendo crecimiento en los años venideros, en parte como consecuencia de la toma de control de American Medicorp Inc. en el año 1978, que tuvo como consecuencia que la empresa doblara su tamaño. Durante la segunda mitad de los años setenta, la empresa volcó sus esfuerzos en una estrategia de construcción y apertura rápida de hospitales en un mes. Durante este boom de la construcción, Humana desarrolló el modelo de doble pasillo para la construcción de hospitales. Este diseño altamente eficaz redujo la distancia entre pacientes y enfermeros localizando el servicio sanitario en el interior del edificio con las habitaciones de los pacientes rodeando el perímetro.

Humana trajo la investigación pionera del corazón artificial de la mano de los doctores Robert Jarvik y William DeVries, inventor y cirujano del primer corazón de este tipo que se implantó en la Universidad de Utah en 1982, para crear el Humana Heart Institute en Louisville en 1985.

Durante la última década del siglo XX Humana separó sus hospitales de sus operaciones relativas a la aseguración médica.

Durante el desarrollo del sistema sanitario de EE.UU. en la década de los ochenta, Humana creó y comenzó a comercializar seguros de salud. Por otro lado en 1998, el grupo United Healthcare intentó adquirir la compañía, sin embargo el esfuerzo fracasó cuando se dio a conocer las pérdidas trimestraes de United por valor de casi mil millones de dólares.

En el año 2001, Humana se unió en colaboración con Navigy, Inc. (subsidiaria de la también empresa aseguradora Blue Cross and Blue Shield Association of Florida, Inc.) para lanzar Availity, un serivicio que facilita los trámites entre profesionales médicos de Florida, usuarios de los planes de salud y aseguradoras.

En 2005, la compañía pactó un acuerdo empresarial con el grupo Virgin, ofreciendo incentivos financieros a los asegurados para obtener un estilo de vida saludable en estos.

El Business Health Care Group of Southeast Wisconsin (en español, Grupo de Sanitario del Sureste de Wisconsin) escogió a Humana como socio administrativo para ayudar a reducir los costes sanitarios.

Humana lanzó en 2006 el servicio RightSource, una farmacia por correo a domicilio que opera en todo EE.UU.
La siguiente lista representa algunas de las mayores adquisiciones realizadas por Humana desde 1990 en EE.UU.




</doc>
<doc id="1428" url="https://es.wikipedia.org/wiki?curid=1428" title="Historia de la inteligencia artificial">
Historia de la inteligencia artificial

La Inteligencia Artificial surge definitivamente a partir de algunos trabajos publicados en la década de 1940 que no tuvieron gran repercusión, pero a partir del influyente trabajo en 1950 de Alan Turing, matemático británico, se abre una nueva disciplina de las ciencias de la información. 

Si bien las ideas fundamentales se remontan a la lógica y algoritmos de los griegos, y a las matemáticas de los árabes, varios siglos antes de Cristo, el concepto de obtener razonamiento artificial aparece en el siglo XIV. A finales del siglo XIX se obtienen lógicas formales suficientemente poderosas y a mediados del siglo XX, se obtienen máquinas capaces de hacer uso de tales lógicas y algoritmos de solución.

En su histórico artículo de 1950, Turing propuso que la pregunta «¿puede pensar una máquina?» era demasiado filosófica para tener valor y, para hacerlo más concreto, propuso un «juego de imitación». En la prueba de Turing intervienen dos personas y una computadora. Una persona, el interrogador, se sienta en una sala y teclea preguntas en la terminal de una computadora. Cuando aparecen las respuestas en la terminal, el interrogador intenta determinar si fueron hechas por otra persona o por una computadora. Si actúa de manera inteligente, según Turing es inteligente. Turing, señaló que una máquina podría fracasar y aún ser inteligente. Aun así creía que las máquinas podrían superar la prueba a finales del siglo XX.

De todas maneras esta prueba no tuvo el valor práctico que se esperaba, aunque sus repercusiones teóricas son fundamentales. El enfoque de Turing de ver a la inteligencia artificial como una imitación del comportamiento humano no fue tan práctico a lo largo del tiempo y el enfoque dominante ha sido el del comportamiento racional, de manera similar, en el campo de la aeronáutica se dejó de lado el enfoque de tratar de imitar a los pájaros y se tomó el enfoque de comprender las reglas de aerodinámica. Aunque desde luego, el enfoque del comportamiento humano y el del pensamiento humano siguen siendo estudiados por las ciencias cognitivas y continúan aportando interesantes resultados a la Inteligencia Artificial, y viceversa.

La ciencia no se define, sino que se reconoce. Para la evolución de la Inteligencia Artificial las dos fuerzas más importantes fueron la lógica matemática, la cual se desarrolla rápidamente a finales del siglo XIX, y las nuevas ideas acerca de computación y los avances en electrónica que permitieron la construcción de los primeros computadores en 1940.
También son fuente de la inteligencia artificial: la filosofía, la neurociencia y la lingüística. La lógica matemática ha continuado siendo un área muy activa en la inteligencia artificial. Incluso antes de la existencia de los ordenadores con los sistemas lógicos deductivos.

Los juegos matemáticos antiguos, como el de las Torres de Hanói (hacia el 3000 a. C.), muestran el interés por la búsqueda de un modo resolutor, capaz de ganar con los mínimos movimientos posibles.

Cerca de 300 a. C., Aristóteles fue el primero en describir de manera estructurada un conjunto de reglas, silogismos, que describen una parte del funcionamiento de la mente humana y que, al seguirlas paso a paso, producen conclusiones racionales a partir de premisas dadas.

En 250 a. C. Ctesibio de Alejandría construyó la primera máquina autocontrolada, un regulardor del flujo de agua que actuaba modificando su comportamiento "racionalmente" (correctamente) pero claramente sin razonamiento.

En 1315, Ramon Llull tuvo la idea de que el razonamiento podía ser efectuado de maneral artificial.

En 1847 George Boole estableció la lógica proposicional (booleana), mucho más completa que los silogismos de Aristóteles, pero aún algo poco potente.

En 1879 Gottlob Frege extiende la lógica booleana y obtiene la Lógica de Primer Orden la cual cuenta con un mayor poder de expresión y es utilizada universalmente en la actualidad.

En 1903 Lee De Forest inventa el triodo, también llamado bulbo o válvula de vacío.

En 1936 Alan Turing publicó un artículo de bastante repercusión sobre los "Números Calculables", un artículo que estableció las bases teóricas para todas las ciencias de computación, y que puede considerarse el origen oficial de la informática teórica. En este artículo introdujo el concepto de Máquina de Turing, una entidad matemática abstracta que formalizó el concepto de algoritmo y resultó ser la precursora de las computadoras digitales. Podía conceptualmente leer instrucciones de una cinta de papel perforada y ejecutar todas las operaciones críticas de un computador. El artículo fijó los límites de las ciencias de la computación porque demostró que no es posible resolver problemas con ningún tipo de computador. Con ayuda de su máquina, Turing pudo demostrar que existen problemas irresolubles, de los que ningún ordenador será capaz de obtener su solución, por lo que se le considera el padre de la teoría de la computabilidad. 

En 1940 Alan Turing y su equipo construyeron el primer computador electromecánico y en 1941 Konrad Zuse creó la primera computadora programable y el primer lenguaje de programación de alto nivel Plankalkül. Las siguientes máquinas más potentes, aunque con igual concepto, fueron la ABC y ENIAC.

En 1943 Warren McCulloch y Walter Pitts presentaron su modelo de neuronas artificiales, el cual se considera el primer trabajo del campo de inteligencia artificial, aun cuando todavía no existía el término.

En 1950 Turing consolidó el campo de la inteligencia artificial con su artículo "Computing Machinery and Intelligence", en el que propuso una prueba concreta para determinar si una máquina era inteligente o no, su famosa Prueba de Turing por lo que se le considera el padre de la Inteligencia Artificial. Años después Turing se convirtió en el adalid que quienes defendían la posibilidad de emular el pensamiento humano a través de la computación y fue coautor del primer programa para jugar ajedrez.

En 1951 William Shockley inventa el transistor de unión. El invento hizo posible una nueva generación de computadoras mucho más rápidas y pequeñas.

En 1956 se dio el término "inteligencia artificial" en Dartmouth durante una conferencia convocada por McCarthy, a la cual asistieron, entre otros, Minsky, Newell y Simon. En esta conferencia se hicieron previsiones triunfalistas a diez años que jamás se cumplieron, lo que provocó el abandono casi total de las investigaciones durante quince años.

En 1980 la historia se repitió con el desafío japonés de la quinta generación, que dio lugar al auge de los sistemas expertos pero que no alcanzó muchos de sus objetivos, por lo que este campo sufrió una nueva interrupción en los años noventa.

En 1987 Martin Fischles y Oscar Firschein describieron los atributos de un agente inteligente. Al intentar describir con un mayor ámbito (no solo la comunicación) los atributos de un agente inteligente, la IA se ha expandido a muchas áreas que han creado ramas de investigación enormes y diferenciadas. Dichos atributos del agente inteligente son: 


Podemos entonces decir que la IA posee características humanas tales como el aprendizaje, la adaptación, el razonamiento, la autocorrección, el mejoramiento implícito, y la percepción modular del mundo. Así, podemos hablar ya no solo de un objetivo, sino de muchos, dependiendo del punto de vista o utilidad que pueda encontrarse a la IA.

En los 90 surgen los agentes inteligentes al paso de los años eso fue evolucionando

El programa Artificial Linguistic Internet Computer Entity (A.L.I.C.E.) ganó el premio Loebner al Chatbot más humano en 2000, 2001 y 2004, y en 2007 el programa Ultra Hal Assistant ganó el premio.

Muchos de los investigadores sobre IA sostienen que «la inteligencia es un programa capaz de ser ejecutado independientemente de la máquina que lo ejecute, computador o cerebro»:

2010: El programa Suzette ganó el premio Loebner. Algunos programas de inteligencia artificial gratuitos son Dr. Abuse, Alice, Paula SG, Virtual woman millenium.

2011: Un ordenador de IBM gana el concurso de preguntas y respuestas 'Jeopardy!': El ordenador de IBM Watson ha salido victorioso de su duelo contra el cerebro humano. La máquina ha ganado el concurso de preguntas y respuestas Jeopardy!, que emite la cadena de televisión estadounidense ABC, al imponerse a los dos mejores concursantes de la historia del programa. Watson les ha vencido en la tercera ronda, contestando preguntas que le obligaban a pensar como una persona.

2014: Un ordenador ha logrado superar con éxito el test de turing: Un ordenador ha logrado superar con éxito el test de Turing haciendo creer a un interrogador que es una persona quien responde sus preguntas- en un certamen organizado en Londres por la Universidad de Reading (Reino Unido). El ordenador, con el programa Eugene desarrollado en San Petersburgo (Rusia), se ha hecho pasar por un chico de 13 años, y los responsables de la competición consideran que es un “hito histórico de la inteligencia artificial”.

2016: Un ordenador de Google vence al campeón mundial de un juego milenario “Go”: Un programa informático desarrollado por la compañía británica Google DeepMind había conseguido vencer, por primera vez, a un campeón profesional de un milenario juego de origen oriental llamado Go. El reto era enorme para una máquina, ya que la prueba de estrategia encierra una gran complejidad.




</doc>
<doc id="1429" url="https://es.wikipedia.org/wiki?curid=1429" title="Heráclito">
Heráclito

Heráclito de Éfeso (en griego: Ἡράκλειτος ὁ Ἐφέσιος "Herákleitos ho Ephésios"), conocido también como «El Oscuro de Éfeso», fue un filósofo griego. Nació hacia el año 540  a. C. y falleció hacia el 480 a. C.

Era natural de Éfeso, ciudad de la Jonia, en la costa occidental del Asia Menor (actual Turquía). Como de los demás filósofos griegos anteriores a Platón, no quedan más que fragmentos de sus obras, y en gran parte se conocen sus aportes gracias a testimonios posteriores.

La obra de Heráclito es completamente aforística. Su estilo remite a las sentencias del oráculo de Delfos y reproduce la realidad ambigua y confusa que explica, usando el oxímoron y la antítesis para dar idea de la misma. Diógenes Laercio (en "Vidas"..., IX 1–3, 6–7, 16) le atribuye un libro titulado "Sobre la naturaleza" ("περὶ φύσεως"), que estaba dividido en tres secciones: «Cosmológica», «Política» y «Teológica». No se posee mayor certeza sobre este libro. El primer estudioso en proponer un ordenamiento de los fragmentos fue P. Schuster (1873), poniendo a la cabeza de todos el que posteriormente fue dispuesto como B56 (Diels-Kranz) y que refiere la adivinanza que unos niños plantearon a Homero, y que este, "el más sabio de todos los griegos", como lo pinta Heráclito (véase más abajo), no supo resolver. Ingram Bywater en 1877 hizo un reacomodo de los fragmentos conforme a la indicación de Laercio, traducido al español por José Gaos. Es curioso que Bywater no considera importante el fragmento que Schuster pone a la cabeza de todos, y no lo incluye en su propia ordenación. Agustín García Calvo reconstruye la posible estructura del libro en su edición de los fragmentos del mismo, titulada "Razón común". Distingue tres apartados: «Razón general», «Razón política» y «Razón teológica».

Heráclito afirma que el fundamento de todo está en el cambio incesante. El ente deviene y todo se transforma en un proceso de continuo nacimiento y destrucción al que nada escapa.

Es común incluir a Heráclito entre los primeros filósofos físicos ("φυσικοί", como los llamó Aristóteles), que pensaban que el mundo procedía de un principio natural (como el agua para Tales de Mileto, el aire para Anaxímenes y el ápeiron para Anaximandro), y este error de clasificación se debe a que, para Heráclito, este principio es el fuego, lo cual no debe leerse en un sentido literal, pues es una metáfora como, a su vez, lo eran para Tales y Anaxímenes. El principio del fuego refiere al movimiento y cambio constante en el que se encuentra el mundo. Esta permanente movilidad se fundamenta en una estructura de contrarios. La contradicción está en el origen de todas las cosas.

Todo este fluir está regido por una ley que él denomina "Λόγος" (Logos). Este "Logos" no solo rige el devenir del mundo, sino que le "habla" ("indica", "da signos", fragmento B93DK) al hombre, aunque la mayoría de las personas «"no sabe escuchar ni hablar"» (fragmento B73DK). El orden real coincide con el orden de la razón, una «"armonía invisible, mejor que la visible"» (B54DK), aunque Heráclito se lamenta de que la mayoría de las personas viva relegada a su propio mundo, incapaces de ver el real. Si bien Heráclito no desprecia el uso de los sentidos (como Platón) y los cree indispensables para comprender la realidad, sostiene que con ellos no basta y que es igualmente necesario el uso de la inteligencia, como afirma en el siguiente e importante fragmento:

Al uso de los sentidos y de la inteligencia, hay que agregarle una actitud crítica e indagadora. La mera acumulación de saberes no forma al verdadero sabio, porque para Heráclito lo sabio es «"uno y una sola cosa"», esto es, la teoría de los opuestos. El fragmento quizás más conocido de su obra dice:

El fragmento (citado con frecuencia erróneamente como "no se puede entrar dos veces en el mismo río", siguiendo la versión que da Platón en el "Crátilo") ejemplifica la doctrina heraclítea del cambio: el río —que no deja de ser el mismo río— ha cambiado sin embargo casi por completo, así como el bañista. Si bien una parte del río fluye y cambia, hay otra (el "cauce", que también debe interpretarse y no tomarse en un sentido literal) que es relativamente permanente y que es la que guía el movimiento del agua. Algunos autores ven en el cauce del río el logos que «todo rige», la medida universal que ordena el cosmos, y en el agua del río, el fuego. A primera vista esto puede parecer contradictorio, pero debe recordarse que Heráclito sostiene que los opuestos no se contradicen sino que forman una unidad armónica (pero no estática). Es razonable, entonces, que la otra cara del agua sea el fuego, como él mismo lo adelanta en sus fragmentos.

A pesar que existen ciertas similitudes entre Heráclito y Parménides de Elea, las doctrinas de ambos siempre han sido contrapuestas (con cierto margen de error), ya que la del primero suele ser llamada «del devenir» o (con cierto equívoco) «del todo fluye», mientras que el ser parmenídeo es presentado como una esfera estática e inmóvil.

Era conocido como «el Oscuro», por su expresión lapidaria y enigmática. Ha pasado a la historia como el modelo de la afirmación del devenir. Su filosofía se basa en la tesis del flujo universal de los seres: «"Panta rei"» (πάντα ρεῖ), todo fluye. El devenir está animado por el conflicto: «"La guerra ("pólemos") es el padre de todas las cosas"», una contienda que es al mismo tiempo armonía, no en el sentido de una mera relación numérica, como en los pitagóricos, sino en el de un ajuste de fuerzas contrapuestas, como las que mantienen tensa la cuerda de un arco. Para Heráclito el arjé es el fuego, en el que hay que ver la mejor expresión simbólica de los dos pilares de la filosofía de Heráclito: el devenir perpetuo y la lucha de opuestos, pues el fuego solo se mantiene consumiendo y destruyendo, y constantemente cambia de materia. Ahora bien, el devenir no es irracional, ya que el logos, la razón universal, lo rige: «"Todo surge conforme a medida y conforme a medida se extingue"». El hombre puede descubrir este logos en su propio interior, pues el logos es común e inmanente al hombre y a las cosas (la doctrina de Heráclito fue interpretada, olvidando esta afirmación del logos, en la filosofía inmediatamente posterior —sobre todo, en Platón— como una negación de la posibilidad del conocimiento: si nada es estable, se niega la posibilidad de un saber definitivo). De Heráclito es también la doctrina cosmológica del eterno retorno: la transformación universal tiene dos etapas que se suceden cíclicamente: una descendente por contracción o condensación, y otra ascendente por dilatación.

He aquí algunas frases de Heráclito:











</doc>
<doc id="1431" url="https://es.wikipedia.org/wiki?curid=1431" title="Híbrido">
Híbrido

El término híbrido, palabra proveniente del Latín "hybrida" ("mestizo"), que posee características de distintas naturalezas. puede hacer referencia:



</doc>
<doc id="1434" url="https://es.wikipedia.org/wiki?curid=1434" title="Hierochloë">
Hierochloë

Hierochloe, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de las regiones templadas y frías del mundo. Comprende 92 especies descritas y de estas, solo 35 aceptadas.

Probablemente se puede incluir en el género "Anthoxanthum" 
Son plantas perennes, cespitosas o rizomatosas, comúnmente con olor a cumarina. Lígula una membrana; láminas lineares, aplanadas a convolutas. Inflorescencia una panícula espiciforme o laxa, terminal. Espiguillas comprimidas lateralmente, subsésiles o cortamente pediceladas; flósculos 3, caedizos como una unidad; desarticulación solamente arriba de las glumas; glumas alargadas, subiguales, membranáceas, carinadas, la inferior 1-nervia, la superior 3-nervia; flósculos inferiores 2, estériles o estaminados, pardos, ciliados, vacíos y sin una pálea o con 2-3 estambres y una pálea, las lemas subiguales, 3-5-nervias, la primera lema con una arista corta recta, la segunda lema con una arista geniculada torcida insertada dorsalmente en el 1/2 inferior; flósculo terminal mucho más corto que los estériles, bisexual o pistilado, la lema papirácea, sin arista, 3-5-nervia, la pálea 1-2-carinada, las lodículas 2, con 2 estambres, el ovario glabro, los estilos 2, separados, exertos apicalmente. Fruto una cariopsis, no adherido a la pálea; hilo cortamente linear. 
El género fue descrito por Robert Brown R.Br. y publicado en "Prodromus Florae Novae Hollandiae" 208. 1810. La especie tipo es: "Hierochloe odorata" 
Hierochloe nombre genérico que deriva del griego "hieros" (sagrada) y "chloë" (hierba), aludiendo a "("H. odorata") que se sembraba delante de las puertas de las iglesias en los días festivos ".

El número cromosómico básico es x = 7, con números cromosómicos somáticos de 2n = 14, 28, 42, 56, 64, 66, 68, 71, and 72, or 74–78. Hay especies diploides y una serie poliploide. Cromosomas relativamente «grandes».





</doc>
<doc id="1435" url="https://es.wikipedia.org/wiki?curid=1435" title="Hilaria">
Hilaria

Hilaria, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario del suroeste de EE. UU. y México a Venezuela.
Son plantas perennes, estoloníferas o rizomatosas. Con vainas redondeadas; la lígula una membrana ciliada o erosa; láminas lineares. Inflorescencia una espiga; espiguillas dimorfas, en fascículos sésiles o subsésiles, los fascículos desarticulándose como una unidad consistente de 1 espiguilla central y 2 laterales; callo obtuso. Espiguillas centrales sésiles, lateralmente comprimidas, casi ocultas por las espiguillas laterales; glumas 1-7-nervias, más cortas que los flósculos, papiráceas a coriáceas, asimétricas, basalmente connatas o libres, 2-lobadas a truncadas o agudas, con 0-2 aristas desde el seno y a veces desde el dorso; flósculos 1(2), el inferior bisexual o pistilado, el superior estaminado o estéril cuando presente; lema membranácea, a veces atenuándose en un cuello largo y angosto, 2-fida o 2-lobada, aristada o sin aristas; pálea casi tan larga como la lema, 2-nervia; lodículas 2, rudimentarias; estambres 3; estigmas 2, plumosos, exertos terminalmente; fruto una cariopsis, el embrión 9/ 10 la longitud de la cariopsis, el hilo punteado. Espiguillas laterales subsésiles, comprimidas lateralmente; glumas más cortas a más largas que los flósculos, asimétricas, flabeladas, papiráceas o coriáceas y connatas en la base, 3-7-nervias, la punta aguda o lobada, con 0-6 aristas desde el seno o el dorso; flósculos 1-5, estaminados o estériles; lema membranácea, aguda a 2-lobada, 3-nervia; pálea casi tan larga como la lema, membranácea; lodículas 2; estambres 3.
El género fue descrito por Carl Sigismund Kunth y publicado en "Nova Genera et Species Plantarum (quarto ed.)" 1: 116–117, pl. 37. 1815[1816]. La especie tipo es: "Hilaria cenchroides" 
El género fue nombrado en honor de Augustin Saint-Hilaire. 
El número cromosómico básico es x = 9, con números cromosómicos somáticos de 2n = 36, 72, 86, 90 y 120. Hay especies diploides y una serie poliploide. Nucléolos persistentes. 





</doc>
<doc id="1438" url="https://es.wikipedia.org/wiki?curid=1438" title="Hefesto">
Hefesto

En la mitología griega, Hefesto (en griego Ἥφαιστος "Hêphaistos", quizá de φαίνω "phainô", ‘brillar’) es el dios del fuego y la forja, así como de los herreros, los artesanos, los escultores, los metales y la metalurgia. Era adorado en todos los centros industriales y manufactureros de Grecia, especialmente en Atenas. Su equivalente aproximado en la mitología romana era Vulcano, en la japonesa Kagutsuchi, en la egipcia Ptah y en la hindú Agni.

Hefesto era bastante feo, y estaba lisiado y cojo. Incluso el mito dice que, al nacer, Hera lo vio tan feo que lo tiró del Olimpo y le provocó una cojera. Tanto es así, que caminaba con la ayuda de un palo y, en algunas vasijas pintadas, sus pies aparecen a veces del revés. En el arte, se le representa cojo, sudoroso, con la barba desaliñada y el pecho descubierto, inclinado sobre su yunque, a menudo trabajando en su fragua. La apariencia física de Hefesto indica arsenicosis, es decir, envenenamiento crónico por arsénico que provoca cojera y cáncer de piel. El arsénico se añadía al bronce para endurecerlo y la mayoría de los herreros de la Edad de Bronce habrían padecido esta enfermedad. 
Hefesto era hijo de Hera, junto a Zeus. En la "Teogonía" de Hesíodo, Hera lo concibió sola, celosa porque Zeus había dado a luz a Atenea, que le había brotado de la cabeza. En la "Ilíada", se afirma que Zeus fue padre de Hefesto.

La tensión entre ambas versiones era tal que aunque en una y en otra se narra que Atenea terminó naciendo de Zeus, en la que Hefesto era anterior se decía que había sido él quien había abierto la cabeza del padre para liberar a la hermana, mientras que en la otra versión se sostenía que había sido Prometeo.

De cualquier forma, en el pensamiento griego los destinos de Atenea, diosa de la sabiduría y la guerra, y Hefesto, dios de la forja que fabricaba las armas de la guerra, estaban relacionados. Hefesto y Atenea Ergane (como patrona de los artesanos) se honraban en una fiesta llamada Calqueas en el trigésimo día del mes Pianepsio. Hefesto también fabricó muchos de los pertrechos de Atenea.
Hera, mortificada por haber parido tan grotesca descendencia, no tardó en arrojarlo del Olimpo. Hefesto cayó durante nueve días y nueve noches hasta el mar, donde, como cuenta su mismo personaje en la "Ilíada", dos diosas del mar, la nereida Tetis (madre de Aquiles) y la oceánide Eurínome, lo recogieron y lo cuidaron en la isla de Lemnos, y allí creció hasta convertirse en un maestro artesano.

Otras versiones afirman que fue su padre Zeus quien lo arrojó a causa de una conspiración de Hera y Hefesto para derrocarlo, y en la "Ilíada" se narra que fue porque liberó a su madre, que estaba presa con una cadena de oro entre la tierra y el cielo tras una pelea con Zeus. Hefesto cayó en la isla de Lemnos, y quedó lisiado con cojera.

Tras haber fabricado tronos de oro para Zeus y otros dioses, Hefesto se vengó elaborando uno mágico de oro que envió como regalo a Hera. Cuando esta se sentó en él, quedó atrapada, incapaz de levantarse. Los demás dioses rogaron a Hefesto que volviese al Olimpo y la liberase, pero él se negó, enfadado aún por haber sido expulsado. Intervino entonces Dioniso, quien emborrachó a Hefesto y lo llevó de vuelta al Olimpo a lomos de una mula. Hefesto, contrariado por la treta y dueño de la situación, impuso severas condiciones para liberar a Hera, una de las cuales fue contraer matrimonio con Afrodita.

En el panteón olímpico, Hefesto estaba formalmente emparejado con Afrodita, a quien nadie podía poseer. Hefesto estaba contentísimo de haberse casado con la diosa de la hermosura y forjó para ella magnífica joyería, entre ella un cinturón que la hacía más irresistible aún para los hombres. Afrodita fue entregada a Hefesto por su padre Zeus como agradecimiento por haberlo ayudado en el nacimiento de Atenea, puesto que Zeus tenía un fuerte dolor de cabeza por haberse tragado a la oceánida Metis y Hefesto lo ayudó a extraerla. También, hay recordar que muchas versiones mitológicas indican a Zeus como padre de Afrodita.

Sin embargo, Afrodita se entregaba en secreto a Ares, el dios de la guerra, según se narra en la "Odisea". Cuando Hefesto tuvo noticia de estos amores por medio de Helios, el sol, que todo lo ve, tejió una red de oro irrompible casi invisible con la que atrapó en la cama a los amantes en uno de sus encuentros. Hesíodo cuenta que el suceso fue motivo de gran algarabía en el Olimpo, pues Hefesto llamó a todos los demás dioses olímpicos para que se burlaran de la pareja de amantes. Hermes, el Argifonte, el mensajero de los dioses comentó que no le habría importado sentir tal vergüenza. Hefesto no quiso liberarlos hasta que prometieran terminar su romance, y así lo hicieron, pero escaparon ambos tan pronto como levantó la red Hefesto, y no mantuvieron su promesa.

Según algunos autores, su desgraciado matrimonio con Afrodita fue lo que le impulsó a asaltar a Atenea cuando esta acudió a él por nuevas armas.

Prometeo había creado al ser humano a semejanza de los dioses, pero tardó tanto que no le quedó con qué protegerlo. Apiadándose de su indefensa creación, robó el fuego del Olimpo para que la humanidad pudiera calentarse. Según algunas versiones, Prometeo robó el fuego del carro de Helios (en la mitología posterior, de Apolo) o de la forja de Hefesto. En otras (notablemente, el "Protágoras" de Platón), Prometeo robaba las artes de Hefesto y Atenea, llevándose también el fuego porque sin él no servían para nada. Obtuvo así el hombre los medios con los que ganarse la vida.

Para aplacar la furia de Zeus, Prometeo dijo a los humanos que quemasen ofrendas a los dioses, pero entonces le engañó de nuevo dándole los huesos y tendones del sacrificio en lugar de la carne. Para vengarse, Zeus ordenó a Hefesto que hiciese una mujer de arcilla, a la que llamó Pandora. Zeus le infundió vida y la envió a Prometeo, junto al ánfora que contenía todas las desgracias con las que quería castigar a la humanidad. Prometeo sospechó y no quiso tener nada que ver con Pandora, por lo que fue enviada con Epimeteo, quien la desposó. Pandora terminaría abriendo la caja a pesar de las advertencias de su marido.

Zeus se enfureció al ver cómo Prometeo se libraba de Pandora, e hizo que lo llevaran al monte Cáucaso, donde fue encadenado por Hefesto con la ayuda de Bía y Cratos. Envió entonces un águila para que se comiera el hígado de Prometeo. Al ser inmortal, el hígado volvía a regenerarse cada día, y el águila volvía a comérselo cada noche.

Este castigo había de durar para siempre, pero Heracles pasó por el lugar de cautiverio de Prometeo de camino al jardín de las Hespérides y lo liberó disparando una flecha al águila. Prometeo fue así liberado, aunque debía llevar con él un anillo unido a un trozo de la roca a la que fue encadenado.

Según la "Ilíada", la forja de Hefesto estaba en el monte Olimpo. Pero lo habitual era situarla en el corazón volcánico de la isla egea de Lemnos. Hefesto era identificado por los griegos con los dioses-volcanes del sur de Italia Adranos y Vulcano. Escritores clásicos posteriores siguieron esta idea describiendo una forja del dios en las islas volcánicas de Lipari, cerca de Sicilia. Los colonizadores griegos de esta isla terminarían asociando la fragua de Hefesto con el Etna.

Hefesto fabricó muchos de los accesorios que lucían los dioses, y se le atribuye la forja de casi todos los objetos metálicos con poderes finamente trabajados que aparecen en la mitología griega: el casco y las sandalias aladas de Hermes, la égida de Zeus, el famoso cinturón de Afrodita, la armadura de Aquiles, las castañuelas de bronce de Heracles, el carro de Helios, el hombro de Pélope, el arco y las flechas de Eros, el casco de invisibilidad de Hades, el collar que regaló a Harmonía y el cetro de Agamenón. Asimismo era el forjador de los rayos de Zeus.

Hefesto también creó diversas criaturas:


Hefesto trabajaba ayudado por:


A pesar de estar casado con Afrodita, Hefesto no tuvo descendencia con ella, salvo que Virgilio hablase en serio cuando afirmaba que Eros era su hijo.

En la "Ilíada", la consorte de Hefesto es llamada Caris. Hesíodo afirmaba que era la más joven de las tres Cárites: Aglaya, ‘la gloriosa’. Según la tradición órfica, fueron padres de:


Según Apolodoro, Hefesto intentó violar a Atenea pero no lo logró. Su semen cayó al suelo, y así Gea engendró a Erictonio, uno de los reyes de Atenas. Atenea crio entonces al bebé como una madre adoptiva. Alternativamente, el semen cayó en la pierna de Atenea, y esta lo limpió con un trozo de lana que tiró al suelo, surgiendo entonces Erictonio de la tierra y la lana. Aún otra versión dice que Hefesto quería que Atenea se casase con él, pero que desapareció en el lecho nupcial, y Hefesto terminó eyaculando en el suelo.

Higino propuso una etimología, según la cual "Erictonio" procede del ‘conflicto’ ("Eri-") entre Atenea y Hefesto, y ‘de la Tierra’ ("-ctonio"). Algunos autores sugieren que una Atenea más antigua y menos virginal se oculta tras esta retorcida reelaboración del mito.

En cualquier caso, hay un Templo de Hefesto (llamado «Hefesteo» o también «Teseo») situado a los pies de la Acrópolis, cerca del ágora de la ciudad.

Se decía que Erictonio creó los carros para ocultar la deformidad de las piernas de Hefesto.

A veces se consideraba a Hefesto padre con Etna de los Palicos, los daimones ctónicos de los géiseres y los manantiales de aguas termales de la región de Palacia (Sicilia).

Hefesto estaba de algún modo conectado con la arcaica religión mistérica frigia y tracia de los Cabiros, que eran llamados los "Hephaistoi" (‘hombres de Hefesto’) en Lemnos. Estos, hijos de Hefesto con la ninfa Cabiro, eran daimones que moraban en la isla de Samotracia (mar Egeo) junto con sus hermanas, las ninfas Cabírides.

También se cuenta entre su descendencia a Talía, la ninfa siciliana a la que amó Zeus.

Hefesto fue también padre de los siguientes mortales:


Higino nombra también a Filoto ("Philottus") y Espínter ("Spinther") entre los hijos de Hefesto, sin dar más detalles.









</doc>
