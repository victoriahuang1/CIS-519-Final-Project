<doc id="1976" url="https://de.wikipedia.org/wiki?curid=1976" title="Geschichte Berlins">
Geschichte Berlins

Die Geschichte Berlins beginnt nicht erst mit der ersten urkundlichen Erwähnung im Jahr 1237, sondern bereits mit der Vor- und Frühgeschichte des Berliner Raumes. Zeugnisse dieser frühen Phase der Besiedlung sind vor allem im Museum für Vor- und Frühgeschichte sowie als lebensechte Nachbildung im Museumsdorf Düppel zu sehen.

Der Name "Berlin" leitet sich vermutlich von dem slawischen Begriff "br’lo" bzw. "berlo" mit der Bedeutung "Sumpf, Morast, feuchte Stelle" oder ‚trockene Stelle in einem Feuchtgebiet‘ sowie dem in slawischen Ortsnamen häufigen Suffix "-in" ab. Dafür spricht vor allem, dass der Name in Urkunden immer wieder mit Artikel auftaucht („der Berlin“).

Der Stadtname ist weder auf den angeblichen Gründer der Stadt, Albrecht den Bären, gestorben bereits 1170, noch auf das Berliner Wappentier zurückzuführen. Hierbei handelt es sich um ein redendes Wappen, mit dem versucht wird, den Stadtnamen in deutscher Interpretation bildlich darzustellen (Berlin = ‚Bär‘). Das Wappentier leitet sich demnach vom Stadtnamen ab, nicht umgekehrt.

Funde von Feuersteinen und bearbeiteten Knochen lassen auf eine Besiedlung des Berliner Raums seit etwa 60.000 v. Chr. schließen. Zu dieser Zeit waren weite Teile Nord- und Ostdeutschlands von den Vergletscherungen der letzten Eiszeit bedeckt, die ungefähr von 110.000 bis 8.000 v. Chr. dauerte. Im Baruther Urstromtal, rund 75 Kilometer südlich Berlins, erreichte das Inlandeis vor rund 20.000 Jahren seine maximale südliche Ausdehnung. Seit rund 19.000 Jahren ist der Berliner Raum, dessen Niederung zum Jungmoränenland der Weichsel-Kaltzeit zählt, wieder eisfrei. Vor rund 18.000 Jahren bildeten die abfließenden Schmelzwasser das Berliner Urstromtal als Teil der "Frankfurter Staffel" aus, das wie alle Urstromtäler im Untergrund aus mächtigen Schmelzwassersanden besteht. Die Spree nutzte das Urstromtal für ihren Lauf, im unteren Spreetal bildete sich stellenweise eine Tundra heraus. Westlich dominierten feuchte Niederungen und Moorgebiete das Erscheinungsbild des Tals.

Die Plateaus Barnim und Teltow bildeten sich parallel zum späteren Lauf der Spree. Mit dem Rückgang des Eises wurde Standwild wie Rehe, Hirsche, Elche und Wildschweine sesshaft und verdrängte die Rentiere. In der Folge begannen die Menschen, die von der Jagd lebten, feste Siedlungen zu errichten. Im 9. Jahrtausend v. Chr. siedelten an der Spree, Dahme und Bäke Jäger und Fischer, die Pfeilspitzen, Schaber und Feuersteinbeile hinterließen. Aus dem 7. Jahrtausend v. Chr. stammt eine Maske, die wahrscheinlich als Jagdzauber diente.

Im 4. Jahrtausend v. Chr. bildeten sich Kulturen mit Ackerbau und Viehzucht, die handgefertigte Keramiken und Vorratsspeicher benutzten. Drei Bestattungen auf dem Gebiet von Schmöckwitz aus dieser Zeit bilden die ältesten Menschenfunde auf Berliner Boden. Ein Dorf der Trichterbecherkultur konnte 1932 bis 1934 auf dem Gebiet der Britzer Hufeisensiedlung ausgegraben werden.

Die meisten jungsteinzeitlichen Funde stammen von der Kugelamphorenkultur um 2000 v. Chr. Rund 200 bronzezeitliche Fundstellen bezeugen eine immer dichter werdende Besiedlung an der Havel und Spree. Schätzungsweise 1000 Menschen sollen sich zu dieser Zeit auf etwa 50 Siedlungen verteilt haben, die überwiegend der Lausitzer Kultur und der Nordischen Bronzezeit zugerechnet werden. Ein 1955 in Lichterfelde entdecktes bronzezeitliches Dorf bestand aus sieben oder acht rechteckigen Häusern, die sich um einen Dorfplatz herum gruppierten. Die Pfostenhäuser waren mit lehmverkleideten Wänden sowie schilf- oder strohgedeckten Dächern ausgestattet. Ein weiteres Dorf mit fast 100 Bauten konnte beim Bau des Klinikums in Berlin-Buch freigelegt werden.

Mit Beginn der Eisenzeit um 600 v. Chr. wurde die Lausitzer von der Jastorf-Kultur abgelöst. Seit ungefähr 500 v. Chr. drangen die nachfolgenden Germanen ins Berliner Gebiet vor und siedelten sich auf den waldreichen Höhen des Barnim und des Teltow an. Germanische Siedlungen wurden vor allem in Rudow, Lübars, Marzahn und Kaulsdorf ausgegraben. In der Zeit nach Christi Geburt tauchten die elbgermanischen Semnonen, ein Volksstamm der Sweben, auf. Ein Teil der semnonischen Bevölkerung wanderte 200 n. Chr. nach Südwesten ab. Ihnen folgten ostgermanische Burgunden.

Im 4. und 5. Jahrhundert n. Chr. verließen große Teile der germanischen Stämme das Gebiet um Havel und Spree und wanderten Richtung Oberrhein nach Schwaben. Im Berliner Raum nahm daher die Besiedlungsdichte ab, er blieb aber von germanischen Restgruppen besiedelt.

Ab dem 6. Jahrhundert kamen Slawenstämme in die Lausitzer Gegend und Ende des 7. Jahrhunderts auch in das weitgehend entvölkerte Spree-Havel-Gebiet. Sie ließen sich in bisher unbesiedelten Landstrichen nieder. Im späteren Berliner Stadtkern gibt es keine slawischen Spuren. Sie finden sich erst auf den Hochflächen von Teltow und Barnim sowie an den Ufern von Spree und Nebengewässern.

Auf dem Gebiet von Berlin siedelten die Stämme der Heveller (Havelslawen) und der Sprewanen, die zum Stammesverband der Lutizen gehörten. Die Heveller bevölkerten das Havelland hinauf bis zum Rhinluch und zum Tegeler See und hatten ihren Hauptsitz auf der Brennaburg auf der heutigen Dominsel der Stadt Brandenburg. Zur Sicherung ihres Gebietes nach Osten errichteten die Heveller um 750 etwas südlich der Spreemündung (Burgwallinsel) in die Havel einen weiteren slawischen Burgwall, um den sich herum dank günstiger Verkehrslage eine Kaufmannssiedlung entwickelte. Weiter im Osten und durch einen breiten Waldgürtel getrennt befand sich das Siedlungsgebiet der Sprewanen, deren Zentrum die Köpenicker Schlossinsel am Zusammenfluss von Spree und Dahme bildete. Hier bestand im 9. Jahrhundert ebenfalls ein slawischer Burgwall. Spandau und Köpenick waren durch eine wichtige Handelsstraße verbunden, die südlich der Spree verlief, um 1170 aber auf das Nordufer verlegt wurde.

Die Sprewanen gründeten weitere Siedlungen auf den Gebieten von Mahlsdorf, Kaulsdorf, Pankow und Treptow. Der durch zahlreiche Münzfunde bezeugte Sprewanenfürst Jaxa von Köpenick, der auf der Köpenicker Burg vermutlich seinen Hauptsitz hatte, wurde 1157 vom Askanier Albrecht dem Bären (1134–1170) bei der Eroberung der Brennaburg entscheidend geschlagen und vertrieben. Albrecht, der bereits 1134 von Lothar III. mit der Nordmark belehnt wurde, gründete daraufhin die Mark Brandenburg und ernannte sich zu ihrem ersten Markgrafen. Der während des 12. Jahrhunderts aufgegebene Spandauer Burgwall wurde als Frühstadt von den Askaniern weiter nördlich auf das Gebiet der heutigen Zitadelle Spandau verlegt, und es entwickelte sich ein neuer Stadtkern gegenüber der Spreemündung.

Die Gründung der ersten Dörfer im Bereich des heutigen Berlin fiel in den anschließenden Landesausbau der askanischen Markgrafen im Teltow, der durch eine geschickte Siedlungspolitik und eine kluge Einbeziehung der international agierenden geistlichen Orden der Zisterzienser (Kloster Lehnin) und der Tempelritter (Komturhof Tempelhof) gekennzeichnet war.

Ende des 12. Jahrhunderts legten Fernkaufleute, die, wahrscheinlich aus dem niederrheinisch-westfälischen Raum kommend, durch das Gebiet reisten, an der Spreeniederung mit der Cöllner Spreeinsel eine erste Siedlung an. An dieser Stelle zwischen den Hochflächen des Teltow und des Barnim verengte sich das sumpfige Urstromtal auf vier bis fünf Kilometer. Auf der rechten, nördlichen Uferseite entstand Alt-Berlin, auf der Spreeinsel direkt gegenüber Cölln.

Neuere Grabungen haben gezeigt, dass erste Siedlungsaktivitäten für Berlin/Cölln wohl schon im letzten Viertel des 12. Jahrhunderts begannen. Archäologische Untersuchungen 1997–1999 stießen in der Breiten Straße 28 (Alt-Cölln) auf einen um 1200 wiederverwendeten Balken, der mit Hilfe der Baumringanalyse auf „um/nach 1171“ datiert werden konnte. Im Jahre 2007 wurde bei Ausgrabungen auf dem Cöllner Petrikirchplatz in einem Erdkeller ein Eichenbalken gefunden, dessen Analyse ergab, dass der Baum um das Jahr 1212 gefällt worden war. 1997 und 2008 wurden im Bereich des Schlossplatzes unter den Fundamenten des 1747 abgerissenen Dominikanerklosters Siedlungsreste gefunden. Das jüngste Datum hat ein Holzrest von 1198 (Waldkante); der gesamte Befund trägt Brandspuren. Dieser Siedlungsteil ist also offenbar nach 1198 nach einer Brandzerstörung aufgegeben worden, denn er wurde spätestens zu Beginn der zweiten Hälfte des 13. Jahrhunderts von der ersten Cöllner Stadtmauer überbaut. Die seit der politischen Wende 1990 ermittelten Dendrodaten können aber nur unterschiedlich wissenschaftlich verwendet werden. Das älteste „belastbare“ Dendrodatum für Berlin/Cölln ist 1198 (Waldkante).

Nach wie vor ist ungeklärt, wer älter ist: Berlin oder Cölln, und wer der jeweilige Gründer war: eine Genossenschaft von Fernkaufleuten (die Berliner Nikolaikirche hat das Patrozinium der Fernkaufleute) oder der Markgraf (Cölln hat den brandenburgischen Adler im Wappen). Ungeklärt ist auch die Frage, ob Cölln als Vorgänger eine Niederlassung der Erzbischöfe von Magdeburg hatte (Rolf Barthels "Magdeburg-Hypothese").

Berlin und Cölln entstanden als Gründungsstädte. Im Gegensatz zu den slawischen Gründungen Spandau und Köpenick (1197 bzw. 1209/1210 erstmals urkundlich erwähnt) am westlichen und östlichen Ausgang des Spreetales, die eher eine strategische Bedeutung hatten, waren Berlin und Cölln von Anfang an als Handelsplätze geplant, um die Handelsvorteile (Zoll, Niederlage) von Spandau und Köpenick abzuziehen.

Die Urkunden mit den frühesten Erwähnungen Cöllns vom 28. Oktober 1237 und Berlins vom 26. Januar 1244 befinden sich im Domstiftsarchiv in Brandenburg an der Havel. Zu beachten ist dabei, dass der Brandenburger Vertrag vom 28. Oktober 1237, der u. a. einen "Symeon plebanus de Colonia" („Symeon, Pfarrer von Cölln“) bezeugt, nur in einer zu Merseburg am 28. Februar 1238 ausgestellten Urkunde überliefert ist. 1244 erscheint derselbe Symeon in einer anderen Urkunde dann als Propst von Berlin, d. h. zu dieser Zeit war Berlin bereits Mittelpunkt eines Archidiakonats. Als Stadt "(civitas)" wird Berlin erstmals 1251 urkundlich erwähnt, Cölln erst zehn Jahre später.

Die Entwicklung und die gezielte Privilegierung des Ausbaus der Doppelstadt durch die beiden Markgrafen seit den 1230er Jahren hing eng mit der Aufsiedlung der Hochflächen Teltow und Barnim zusammen, ausführlich geschildert in der Märkischen Fürstenchronik. Die askanischen Siedlungen auf dem nordwestlichen Teltow waren durch die sperrriegelartig gegründeten Templerdörfer um den Komturhof Tempelhof strategisch gegen die Wettinische Herrschaft auf dem Teltow mit Mittenwalde und Köpenick sowie dem sehr wahrscheinlich geplanten wettinischen Aufbau einer Herrschaft um Hönow (u. a. mit Hellersdorf) gesichert. Die Grenze zwischen der askanischen Mark und den wettinischen Besitzungen verlief zu dieser Zeit in Nord-Süd-Richtung mitten durch das heutige Berliner Stadtgebiet. Die Behauptung eines dazwischen liegenden Streifens der Erzbischöfe von Magdeburg wird überwiegend bestritten. Die Spannungen mit den Wettinern entschieden sich im Teltow-Krieg zwischen 1239 und 1245 zugunsten der Askanier, der ihnen endgültig den gesamten Teltow und Barnim (abgesehen von Rüdersdorf) und damit das gesamte heutige Stadtgebiet einbrachte.


Einen großen Teil seines Aufstiegs von einem kleinen Brückenort zu einem bedeutenden Spreeübergang verdankt Berlin-Cölln den Askaniern, die den alten Fernhandelsweg von Magdeburg nach Posen, der auch über Spandau und Köpenick führte, durch die Stadt leiteten. Wirtschaftlich konnte sie sich insbesondere durch das von den gemeinsam regierenden Markgrafen Otto III. und Johann I. ausgestellte Niederlags- oder Stapelrecht gegenüber den Städten Spandau und Köpenick durchsetzen. Dieses verpflichtete durchreisende Kaufleute ihre Waren einige Tage in der Stadt anzubieten. Hinzu kamen Zollfreiheiten, die den Zwischenhandel und die Ausfuhr landwirtschaftlicher Erzeugnisse begünstigten. Die Handelsverbindungen reichten von Osteuropa bis Hamburg, Flandern und England sowie zur Ostseeküste und nach Süddeutschland "(Via Imperii)". Die Stadt erstreckte sich zu dieser Zeit auf einer Fläche von 70 Hektar und umfasste die Handelsniederlassung am Molkenmarkt und rund um die Nikolaikirche sowie die Gegend des Neuen Marktes und der Marienkirche. Die wichtigste Verbindung zwischen Berlin und Cölln war der Mühlendamm, der die Spree anstaute und auf dem sich mehrere Mühlen befanden.

Obwohl Berlin und Cölln viele gemeinsame Einrichtungen besaßen, wurden beide Städte von getrennten Verwaltungen geführt. In den aus zwölf bzw. sechs Mitgliedern bestehenden Räten saßen Großkaufleute und Fernhändler, die das Patriziat der Stadt bildeten. An der Spitze beider Verwaltungen stand der Schultheiß, der in Berlin und Cölln als Vertreter des Markgrafen amtierte. Als erster bekannter Schulze wird Marsilius de Berlin 1247 erwähnt, nachdem spätestens 1240 das Stadtrecht verliehen wurde; der neueste Forschungsstand (Fritze 2000) geht von einem Zusammenhang mit dem Zehntvertrag von 1237 aus, ebenso die Aufwertung der Nikolaikirche zur Propsteikirche und die Anlage des Marienviertels.

Die mittlere Schicht bildeten Kaufleute, Handwerksmeister und Ackerbürger, die sich in Zünften organisierten. Als ältestes Dokument des Zunftwesens gilt die Bestätigung einer Bäckergilde aus dem Jahr 1272. Von 1284 ist ein erster Innungsbrief für die Schuster überliefert, die Tuchmacher erhielten 1289 verschiedene Rechte und die Fleischerinnung wurde 1311 gegründet. Diese vier Stände waren am angesehensten und bildeten das Viergewerk.

An religiösen Einrichtungen existierten zu der Zeit eine Propstei, mit der Marienkirche, der Nikolaikirche und der Petrikirche (Cölln) drei Pfarrkirchen, das Graue Kloster des Franziskaner Ordens und das Dominikanerkloster in Cölln sowie die zugehörigen Klosterkirchen. Um das Heilig-Geist-Spital entstand ein eigenes Stadtviertel, das Georgenhospital befand sich im Osten von Berlin vor dem Oderberger Tor bzw. Georgentor. Das 1406 gegründete Gertraudenhospital lag südöstlich von Cölln. In der Klosterstraße befand sich das Hohe Haus, in dem zeitweise die Kurfürsten residierten.

Im Jahr 1307 schlossen sich Berlin und Cölln zu einer Union zusammen, um eine gemeinsame Bündnis- und Verteidigungspolitik zu verfolgen. Für den gemeinsamen Rat wurde ein drittes Rathaus auf der Langen Brücke errichtet.

Nach dem Aussterben der märkischen Askanier 1320 übertrug der Wittelsbacher Kaiser Ludwig IV., ein Onkel des letzten Askaniers Heinrichs II., 1323 die Mark Brandenburg seinem ältesten Sohn Ludwig dem Brandenburger. Von Anfang an war die wittelsbachische Regierung über Brandenburg von starken Spannungen geprägt. 1325 erschlugen und verbrannten die Berliner und Cöllner Bürger Propst Nikolaus von Bernau, der als Parteigänger des Papstes Johannes XXII. aus Frankreich gegen den Kaiser auftrat, daraufhin verhängte der Papst über Berlin das Interdikt.

Auch in der Folge kam es zu weiteren Spannungen mit der Wittelsbacher Herrschaft. 1349 huldigten im Streit um die Mark 36 brandenburgische Städte dem „Falschen Woldemar“ in der Spandauer Zitadelle.

Ende 1351 ging Brandenburg an Ludwigs Halbbruder Ludwig den Römer. Dieser gewann 1356 die Kurwürde für die Mark Brandenburg und schloss aus Hass gegen seine bayrischen Brüder, mit denen er wegen der Kur und der bayerischen Erbfolge nach dem Tode seines Neffen Meinhard in Streit geraten war, 1363 eine Erbverbrüderung mit Kaiser Karl IV. Diese sollte nach seinem und seines Bruders Ottos kinderlosem Tode die Mark Brandenburg Karls Sohn Wenzel zusichern. Ludwig ließ daraufhin die Stände dem Kaiser huldigen. Als Ludwig dann starb, ohne Kinder hinterlassen zu haben, wurde zunächst sein Bruder Otto sein Nachfolger. Ludwig wurde wie seine erste Frau Kunigunde im Grauen Kloster in Berlin beigesetzt. 1373 fiel Berlin dann mit der Mark Brandenburg an die Luxemburger. Im 14. Jahrhundert waren Berlin und Cölln Mitglied in der Hanse. Im Jahr 1378 gab es einen Großbrand in Cölln und im 1380 auch einen in Berlin. Dabei wurden unter anderem das Rathaus und fast alle Kirchen zerstört, wie auch der überwiegende Teil der Stadturkunden und Dokumente der Städte.

Friedrich I. wurde im Jahr 1415 Kurfürst der Mark Brandenburg und blieb dies bis 1440. Mitglieder der Familie Hohenzollern regierten bis 1918 in Berlin, erst als Markgrafen und Kurfürsten von Brandenburg, dann als Könige in und von Preußen und schließlich als Deutsche Kaiser. Die Einwohner Berlins haben diese Veränderung nicht immer begrüßt. 1448 revoltierten sie im „Berliner Unwillen“ gegen den Schlossneubau des Kurfürsten Friedrich II. Eisenzahn. Dieser Protest war jedoch nicht von Erfolg gekrönt und die Bevölkerung büßte viele ihrer politischen und ökonomischen Freiheiten ein.

Berlin-Cölln wurde nach 1448 zunehmend als Residenzstadt der brandenburgischen Markgrafen und Kurfürsten betrachtet. 1451 bezog Friedrich II. seine neue Residenz in Cölln. Als Berlin-Cölln Wohnsitz der Hohenzollern wurde, musste es seinen Status als Hansestadt aufgeben. Die ökonomischen Aktivitäten verlagerten sich vom Handel auf die Produktion von Luxuswaren für den Hofadel. Die Bevölkerungszahl stieg im 16. Jahrhundert auf über zehntausend an.

Im Jahr 1510 wurden 100 Juden beschuldigt, Hostien gestohlen und entweiht zu haben. 38 von ihnen wurden verbrannt, zwei wurden – nachdem sie zum Christentum konvertiert waren – geköpft, alle anderen Berliner Juden wurden ausgewiesen. Nachdem ihre Unschuld nach 30 Jahren nachgewiesen werden konnte, durften Juden – nach Zahlung einer Gebühr – wieder nach Berlin siedeln, wurden jedoch 1573 erneut, diesmal für hundert Jahre, vertrieben.

Westlich von Berlin wurde 1527 der Tiergarten als Jagdrevier für die Kurfürsten angelegt und 1573 als Verbindung zum Schloss ein Reitweg gebaut, aus dem später die Straße Unter den Linden wurde. Dadurch begann die Ausrichtung der Stadtentwicklung Richtung Westen.

Joachim II., Kurfürst von Brandenburg und Herzog von Preußen, führte 1539 die Reformation in Brandenburg ein und beschlagnahmte im Rahmen der Säkularisation Besitzungen der Kirche. Das so erworbene Geld benutzte er für seine Großprojekte wie den Bau der Zitadelle Spandau und des Kurfürstendamms als Verbindungsstraße zwischen seinem Jagdschloss im Grunewald und seiner Residenz im Berliner Stadtschloss. 1539 ging die erste Druckerei in Berlin in Betrieb. 1567 entwickelte sich aus einem geplanten Schauspiel der dreitägige „Knüppelkrieg“ zwischen Berlin und Spandau, bei dem sich die Spandauer nicht mit der Niederlage im Schauspiel abfinden wollten und letztendlich die Berliner verprügelten. Die Uhrmacherinnung wurde 1552 gegründet. Kurfürst Johann Sigismund trat 1613 vom lutherischen zum reformierten Bekenntnis über.

In der ersten Hälfte des 17. Jahrhunderts hatte der Dreißigjährige Krieg für Berlin schlimme Folgen: Ein Drittel der Häuser wurde beschädigt, die Bevölkerung halbierte sich. Friedrich Wilhelm, bekannt als der "Große Kurfürst", übernahm 1640 die Regierungsgeschäfte von seinem Vater. Er startete eine Politik der Immigration und der religiösen Toleranz. Die Verbindung von Oder und Spree durch den Friedrich-Wilhelm-Kanal ab 1668 brachte für Berlin wirtschaftliche Vorteile wegen geringerer Frachtkosten. (Siehe auch: Wirtschaftsgeschichte Brandenburg-Preußens)

In der Folge des Dreißigjährigen Krieges begann 1658 unter der Leitung von Johann Gregor Memhardt der Bau einer Festungsanlage um die Stadt, die etwa 1683 fertiggestellt war. Die 1662 neu gegründete Stadt Friedrichswerder sowie die Vorstadt Neukölln am Wasser lagen innerhalb dieser Fortifikation. Der alte Reitweg zum Tiergarten wurde ab 1647 zur Allee ausgebaut und mit Linden bepflanzt. Nördlich davon wurde ab 1674 die zweite Stadterweiterung Dorotheenstadt angelegt. Die dritte Neustadt war die Friedrichstadt, die ab 1691 entstand. Vor den Toren der Festung befanden sich im Norden die Spandauer Vorstadt, im Osten die Stralauer Vorstadt und dazwischen die Georgenvorstadt, im Süden lag die Köpenicker Vorstadt und südwestlich die Leipziger Vorstadt.

Im Jahr 1671 wurde 50 aus Österreich vertriebenen jüdischen Familien ein Zuhause gegeben. Mit dem Edikt von Potsdam 1685 lud Friedrich Wilhelm die französischen Hugenotten nach Brandenburg ein. Über 15.000 Franzosen kamen, von denen sich 6.000 in Berlin niederließen. Um 1700 waren 20 Prozent der Berliner Einwohner Franzosen, und ihr kultureller Einfluss war groß. Viele Einwanderer kamen außerdem aus Böhmen, Polen und Salzburg. Friedrich Wilhelm baute außerdem eine Berufsarmee auf.

Zur Annäherung der beiden protestantischen Konfessionen in Brandenburg fand 1662–1663 das Berliner Religionsgespräch statt. Der erste Kirchenneubau für die Anhänger der reformierten Kirche war die 1695 erbaute Parochialkirche. Die Berliner Hugenottengemeinde ließ die Französische Friedrichstadtkirche errichten (1705 eingeweiht).

Die angestrebte Standeserhöhung zum preußischen König erreichte Kurfürst Friedrich III. 1701, Berlin wurde zur Hauptstadt des preußischen Staates. Am 17. Januar 1709 wurde das Edikt zur Bildung der "Königlichen Residenz Berlin" durch Zusammenlegung der Städte Berlin, Cölln, Friedrichswerder, Dorotheenstadt und Friedrichstadt erlassen. Nach einigen dazu nötigen Verwaltungsänderungen erfolgte die Vereinigung zum 1. Januar 1710. Die Einwohner der Berliner und Cöllner Vorstädte erhielten 1701 die Bürgerrechte und waren damit den Stadtbewohnern gleichgestellt.

Das ab 1696 für die Kurfürstin Sophie Charlotte westlich von Berlin gebaute Schloss Lützenburg wurde nach deren Tod 1705 in Schloss Charlottenburg umbenannt, die benachbarte Siedlung bekam den Namen Charlottenburg und erhielt das Stadtrecht.

Mit dem Baubeginn des Zeughaus 1695 begann der repräsentative Ausbau der späteren Straße Unter den Linden. Andreas Schlüter gestaltete das Berliner Schloss um. Nicht die alte Berliner Hauptstraße, die Königsstraße, sondern Unter den Linden wurde zur „via triumphalis“ Preußens, die Stadtentwicklung verlagerte von nun an den Schwerpunkt hin zu den Neustädten im Westen.

Um die Residenzstadt zum Mittelpunkt der Künste und der Wissenschaften zu machen, gründete Kurfürst Friedrich III. 1696 die Academie der Mahler-, Bildhauer- und Architectur-Kunst, sowie 1700 die Kurfürstlich-Brandenburgische Societät der Wissenschaften, ihr erster Präsident wurde Gottfried Wilhelm Leibniz. Beide Einrichtungen bezogen das obere Stockwerk des königlichen Stalles (Marstall zwischen Unter den Linden und Dorotheenstraße, heute Grundstück der Staatsbibliothek). Dort wurde 1711 die Berliner Sternwarte eingeweiht. Als oberste Gesundheitsbehörde wurde 1685 das Collegium medicum eingerichtet. Außerhalb der Stadtmauer entstand 1710 ein „Lazareth“ für Pest­kranke, das 1727 zum Bürgerhospital unter dem Namen Charité umgewandelt wurde. Bereits 1661 war die Churfürstliche Bibliothek angelegt worden. Die erste Zeitung Berlins erschien 1617 und hatte unter wechselndem Namen bis Mitte des 18. Jahrhunderts ein Monopol, seit 1751 wurde diese inoffiziell "Vossische Zeitung" genannt. Das „“ wurde 1702 in der Stralauer Vorstadt gegründet.

Friedrichs Sohn, Friedrich Wilhelm I., König in Preußen, ab 1713 an der Macht, war ein sparsamer Mann, der das Stehende Heer vergrößerte und Preußen zu einer bedeutenden Militärmacht aufbaute. 1709 hatte Berlin 55.000 Einwohner, von denen 5.000 in der Armee dienten, 1755 waren es bereits 100.000 Einwohner bei 26.000 Soldaten. Außerdem ließ Friedrich Wilhelm die Akzisemauer um die Stadt errichten, eine hölzerne Mauer mit 14 Toren, an denen die Verbrauchssteuern auf eingeführte Waren sowie Schutzzölle erhoben wurden. Weiterhin hatte die Mauer Kontrollfunktionen und sollte die Flucht von Soldaten verhindern. Neue Exerzierplätze und militärische Gebäude entstanden in Berlin und Umgebung. In der Breiten Straße fanden oft Bestrafungen durch Spießrutenlaufen statt.

Nordwestlich von Berlin ließ Friedrich Wilhelm I. von 1717 bis 1719 die Königliche Pulverfabrik errichten und siedelte französische Einwanderer an, Moabit entstand. Der Unternehmer und hohe Beamte Johann Andreas Kraut beteiligte sich an der Gründung des Königlichen Lagerhauses, Berlins größter Manufaktur. Ein bedeutendes Großunternehmen war das Bank- und Handelshaus Splitgerber & Daum. Die erste Börsensitzung der bereits 1685 gegründeten Börse fand 1739 im Neues Lusthaus im Lustgarten statt. Eine der ersten Versicherungen in Deutschland wurde 1718 mit der Feuersozietät gegründet. Das seit 1468 bestehende Kammergericht bezog 1735 den Neubau des Kollegienhauses in der Lindenstraße, dem ersten großen Verwaltungsgebäude während der Regierungszeit Friedrich Wilhelm I.

Unter dem Oberbaudirektor Philipp Gerlach wurden in 1730er Jahren die Torplätze Quarree, Octogon und Rondell angelegt. Der Gendarmenmarkt entstand 1688 nach Plänen von Johann Arnold Nering. Die Neustädte waren durch ein geordnetes Straßenraster geprägt mit geraden Straßen, die weite Perspektiven boten. Die Bürger der königlichen Stadterweiterungen waren verpflichtet in ihren Häusern Soldaten mit deren Familien einzuquartieren. Französische Einwanderer siedelten ab etwa 1716 am südlichen Rand des Tiergartens, dem späteren Tiergartenviertel. Vor dem Vorgängerbau des heutigen Brandenburger Tors befand sich seit 1730 ein Exerzierplatz aus dem später der Königsplatz, der heutige Platz der Republik (Berlin), hervorging.

Im Jahr 1740 kam Friedrich II., bekannt als "Friedrich der Große", an die Macht. Friedrich II. wurde auch der "Philosoph auf dem Thron" genannt, da er unter anderem mit Voltaire korrespondierte. Unter ihm wurde die Stadt zum Zentrum der Aufklärung. Der bekannteste Berliner Philosoph der Zeit war Moses Mendelssohn. Mittelpunkte der Berliner Aufklärung waren der literarische Freundeskreis um den Verleger und Literaten Friedrich Nicolai in dessen Haus in der Brüderstraße und der Montagsklub. Die Berliner Mittwochsgesellschaft gab die Zeitschrift "Berlinische Monatsschrift" heraus. Mehrere Vereinigungen der Freimaurer entstanden, und Vereine, wie die Gesellschaft der Freunde oder die Gesellschaft Naturforschender Freunde wurden gegründet.

Der Bau des Forum Fridericianum begann 1741 mit der Grundsteinlegung für das Opernhaus unter Knobelsdorff. Nach Plänen von Georg Christian Unger entstand die Königliche Bibliothek. Die Königliche Porzellan-Manufaktur wurde 1763 gegründet. Zuckersiedereien entstanden. Johann Georg Wegely gründete 1723 eine Wollzeugmanufaktur auf der Speicherinsel, heute ein Teil der Fischerinsel. Der Bankier und Händler Veitel Heine Ephraim ließ das als Ephraim-Palais bekannt gewordene Haus errichten. (Siehe auch: "Merkantilismus") Zur Versorgung der Kriegsopfer wurde das Invalidenhaus 1748 eröffnet. Während der Regierungszeit Friedrich II. entstanden neue Kasernen, in denen Militärangehörige mit ihren Familien einquartiert wurden.

Für den Warenhandel bedeutsame Gebäude wurden an der Spree errichtet, wie der Alte und Neue Packhof oder der Aktienspeicher und das Mehlhaus. Güter und Baustoffe wurden vor allem mit den Kaffenkähnen transportiert.

Die inzwischen militärisch veraltete Festungsanlage wurde ab 1734 abgerissen. Der damit beauftragte Stadtkommandant Graf von Hacke ließ 1750 beim Abbruch des Spandauer Tors einen Platz anlegen, der bald zum Hackeschen Markt wurde. Die Spandauer Vorstadt erhielt 1712 eine eigene Kirche in der Sophienstraße. Während des Siebenjährigen Krieges wurde die preußische Hauptstadt zweimal kurzzeitig von Feinden Preußens besetzt: 1757 von den Österreichern und 1760 von den Russen.

Der Regierungsantritt König Friedrich Wilhelms II. im Jahr 1786 bedeutete für Berlin eine kulturelle Umbruchphase. Nachdem König Friedrich II. hauptsächlich von Potsdam aus regiert und residiert hatte, wurden Hof und Regierung unter Friedrich Wilhelm II. nun wieder nach Berlin verlegt. Die Stadt wurde wieder zur unbestrittenen Hauptstadt Preußens, was Künstler, Gewerbetreibende und Unternehmer anzog.

Trotz der neuen kulturellen und wirtschaftlichen Impulse des Hofes unterschied sich Berlin mit seinem Mauerring noch wesentlich von einer modernen Großstadt, in der sich der Siedlungskern nicht mehr vom Umland und den Vorstädten abgrenzen lässt. Im Jahr 1793 umschloss eine 17 Kilometer lange und vier Meter hohe Akzisemauer das nur 13 Quadratkilometer große Berlin. In vier Stunden ließ sich die gesamte Großstadt entlang der Mauer umwandern. Lediglich die von Handwerkern bewohnte Rosenthaler Vorstadt, einige bürgerliche Sommerhäuser und Ausflugslokale befanden sich außerhalb der Stadtmauer. Friedrich Wilhelm II. ließ die Holzpalisaden des Mauerrings durch feuersicheres Ziegelmauerwerk ersetzen. Bis 1802, also innerhalb von 15 Jahren, war der Bau abgeschlossen.

Auch die seit 1735 nicht mehr instandgesetzten Berliner Stadttore mussten erneuert werden. Schon unter Friedrich II. hatten 1786 die ersten Vorarbeiten begonnen, doch der Großteil konnte erst unter Friedrich Wilhelm II. fertiggestellt werden. Die Stadttore waren weiterhin notwendig, um einerseits den Reiseverkehr und den auf Waren zu entrichtenden Zoll zu kontrollieren und andererseits Soldaten die Desertion bzw. Flucht zu erschweren. Berlin konnte durch insgesamt 14 Stadttore betreten werden; dem Brandenburger Tor im Westen, dem Hamburger Tor im Nordwesten, dem Oranienburger Tor im Norden, dem Rosenthaler Tor im Norden, dem Schönhauser Tor im Nordosten, dem Frankfurter Tor im Osten, dem Schlesischen Tor im Osten, dem Königstor, dem Halleschen Tor im Südosten, dem Stralauer Tor im Süden, dem Kottbusser Tor im Südwesten und dem Potsdamer Tor im Südwesten.

Im April 1788 gab Friedrich Wilhelm II. mit dem Neubau des Brandenburger Tors das heutige Wahrzeichen der Stadt in Auftrag. Der Vorgängerbau- ein bescheidenes, einspuriges Barocktor- entsprach nicht mehr dem königlichen Repräsentationsbedürfnis. Dies lag auch an der bedeutenden Lage. Das Brandenburger Tor stand in Sichtweite des Berliner Stadtschlosses und grenzte an den Tiergarten an, einem wichtigen Ausflugsziel der königlichen Familie. Der Bau des Brandenburger Tors geschah aber vor allem als Erinnerungsdenkmal an den siegreichen Preußischen Einmarsch in Holland und der daraus hervorgehenden Allianz zwischen Preußen, Großbritannien und der Republik der Sieben Vereinigten Provinzen. Der König forderte, dass das Brandenburger Tor sich an den Propyläen des Perikles bzw. an dem Torbau der Akropolis in Athen orientieren sollte. Damit unterstrich er seinen Anspruch wie Athen im Attischen Seebund Führungsmacht der neuen Allianz zu sein und auf dieser Grundlage ein „goldenes Zeitalter“ des Friedens etabliert zu haben.

Am Ende des 18. Jahrhunderts gehörte Berlin zu den Zentren der europäischen Aufklärung. Professoren, Lehrer, Künstler und Beamte entwickelten ein vom Hof zunehmend unabhängigeres Denken. In der Folge wurden Salons, Lese- und Theatergesellschaften zu Treffpunkten für kulturelle und politische Debatten. Das Interesse an Literatur, die gemeinsam gelesen und besprochen wurde, ließ Angehörige aller Stände in den Berliner Salons zusammenkommen. Auch Frauen und Juden gewannen „Freiräume“, die sie außerhalb der Salons nicht besaßen. Vor allem die Salons der Schriftstellerinnen Henriette Herz oder Rahel Varnhagen ragen hierbei heraus.

In dem aufgeklärten Milieu Berlins fand die 1789 ausgebrochene Französische Revolution große Aufmerksamkeit. Vor allem die großen Berliner Zeitungen – die "Vossische Zeitung" und die "Spenersche Zeitung" – lieferten detaillierte und zuverlässige Informationen über die Pariser Ereignisse, selbst über die Hinrichtung Ludwigs XVI. Die Französische Revolution wurde in der Berliner Presse trotz des Zensurediktes von 1788 als „Sieg der Vernunft über aristokratische Anmaßung und königliche Misswirtschaft gefeiert“. Gleichwohl befand sich Berlin in keinem revolutionären Vorstadium. Die Leserschaft der Stadt- hauptsächlich Angehörige des Bildungsbürgertums und der Bürokratie- waren finanziell von Staat und Hof abhängig. Mit dem Terror unter dem Jakobinerregime begann die positive Resonanz der Französischen Revolution in Berlin endgültig an Einfluss zu verlieren. Friedrich Wilhelm II. reagierte auf die Veröffentlichungen dennoch mit Ablehnung. Einem Minister schrieb er noch vor Ausbruch der Französischen Revolution über die in Berlin bestehende Praxis der „Preßfrechheit“.

Hatte sich Berlin unter Friedrich II. zur größten Stadt auf dem Gebiet des heutigen Deutschland entwickelt, wurde die Stadt unter Friedrich Wilhelm II. zu einem der führenden Zentren der Klassik. Auf Augenhöhe mit Wien und Weimar wetteiferte die preußische Hauptstadt nun um Künstler, Architekten und Gelehrte. Friedrich II. hatte zwar französische Dichter und italienische Komponisten nach Berlin berufen, aber deutsche Kulturgrößen wie Herder, Goethe, Mozart und Beethoven ignoriert. Auch war das Theater- und Opernwesen in den letzten Regierungsjahren Friedrichs II. weder architektonisch noch inhaltlich dem Zeitgeschmack angepasst worden. Der Zuschauerraum des Königlichen Opernhauses Unter den Linden musste daher 1787 von dem Oberbaudirektor Carl Gotthard Langhans, dem Architekten des Brandenburgers Tors, umgebaut werden. Auch das Schlosstheater in Charlottenburg wurde unter Friedrich Wilhelm II. erbaut. Das ehemals Französische Komödienhaus am Gendarmenmarkt wurde in das Deutsche Nationaltheater umbenannt, in dem die Stücke erstmals in deutscher Sprache aufgeführt wurden. Eine weitere kulturelle Revolution bestand darin, dass anders als unter Friedrich II. moderne Stücke wie Schillers "Don Carlos", Shakespeares "Kaufmann von Venedig" und Goethes "Iphigenie auf Tauris" im Nationaltheater gespielt werden durften.

Die Professionalisierung des Berliner Kunstgewerbes dieser Zeit geht entscheidend auf die Reform der Königlichen Akademie der bildenden Künste und mechanischen Wissenschaften durch Friedrich Anton von Heynitz zurück. Als Kurator formte er die Akademie in ein leistungsfähiges Ausbildungsinstitut für Maler, Architekten und Kunsthandwerker um. Durch organisierte Kunstausstellungen der Akademie bildete sich in Berlin zudem erstmals eine künstlerisch interessierte Öffentlichkeit heraus, der der König zum Teil auch seine Kunstsammlung zugänglich machte. Mit Friedrich Wilhelm II. wurde der Baustil des Rokoko, an dem Friedrich der Große Zeit seines Lebens festgehalten hatte, durch den sich außerhalb Preußens längst etablierten Klassizismus abgelöst. Bedeutende Künstler, wie der Grafiker und Illustrator Daniel Chodowiecki oder die Bildhauer Johann Gottfried Schadow und Christian Daniel Rauch oder die Architekten Carl Gotthard Langhans, Friedrich Wilhelm von Erdmannsdorf, Carl von Gontard und David Gilly wirkten in Berlin.

Es entstanden zahlreiche prächtige Hofpaläste. Das Schloss Bellevue wurde 1786 fertiggestellt.

Die Infrastruktur Berlins steckte unter Friedrich Wilhelm II. noch in den Kinderschuhen. Erst 1789 wurde damit begonnen, die Prachtstraße Unter den Linden zu pflastern. Hier konzentrierte sich der städtische Hauptverkehr, da die angrenzenden Gassen und Straßen wegen der Mist-, Sperrmüll- und Schutthaufen kaum passierbar waren. Private Abortgruben und die Viehhaltung innerhalb des Mauerrings trugen zum Gestank bei. Sandige Straßenböden wurden häufig von der Menschenmenge aufgewirbelt, sodass in zeitgenössischen Berichten immer wieder von „Staubwolken“ die Rede war. Der Schriftsteller Marie-Henri Beyle klagte darüber, wie bloß jemand, „auf die Idee gekommen sei, mitten in all dem Sand eine Stadt zu gründen“. Friedrich von Coelln notierte sogar, dass Berlin „in den Sandwüsten Arabiens“ liegen könnte. Wegen der fehlenden Kanalisation schütteten die Berliner Abfälle und Fäkalien in die Gosse und entleerten ihre Nachttöpfe in die Rinnsteine. Die städtische Reinigung kam den Mengen an Fäkalien, Abfällen und Unrat kaum hinterher. Nur die wenigsten Stadtviertel wurden von Öllaternen beleuchtet. Aus Sparsamkeitsgründen reichte die Ölmenge nur dafür aus, die Lichter bis Mitternacht brennen zu lassen.

Nennenswerte Fortschritte gelangen vor allem im Ausbau und der Ausbesserung der Chausseen. Diese bestanden zuvor nur aus einer „Packlage unbehauender Steine“, über die loser Kies aufgetragen wurde. Am 18. April 1792 ordnete Friedrich Wilhelm II. an, einen gepflasterte Hauptverkehrsweg zwischen den Residenzstädten Berlin und Potsdam anzulegen, die spätere Berlin-Potsdamer Chaussee. Der Bauunterhalt der Anlage gestaltete sich jedoch schwierig, da die Benutzungsgebühren weit geringer ausfielen, als von der Regierung erwartet.

In den 1790er Jahren kam es im Textilgewerbe europaweit zu einer Krise, von der Berlin besonders schwer betroffen war, da der Textilsekor mit 25.000 Personen den größten Berufszweig der Stadt bildete. Die billigere Produktion durch Kinder und Frauen einerseits und die Verlagerung der Webarbeit auf das Land andererseits drückten die Löhne in der Stadt. In der Folge organisierten die Gilde- und Zunftgenossen der Weber 1793 einen Streik, in dessen Folge gewaltsame Zusammenstöße mit dem Militär nicht ausblieben. Nur ein Bruchteil der etwa 13.000 Beschäftigungslosen fand eine Unterkunft in den Waiserhäusern und Hospitälern.

Im Jahr 1806 bekam Berlin die Folgen der seit 1795 verfolgten preußischen Neutralitätspolitik zu spüren. Die königliche Regierung hatte sich militärisch und bündnispolitisch nahezu unvorbereitet in den Vierten Koalitionskrieg begeben. Nach der vernichtenden Niederlage gegen den französischen Kaiser Napoleon I. in der Doppelschlacht bei Jena und Auerstedt am 14. Oktober 1806, war eine erfolgreiche Verteidigung Berlins ausgeschlossen. Die unbefestigte Zollmauer war ungeeignet, um einen Angriff abzuwehren. Auch waren nicht mehr genügend Truppen in Berlin stationiert. Nachdem kurzzeitig Gerüchte eines preußischen Sieges in Berlin eingetroffen waren und gefeiert wurden, wurde in der Nacht vom 16. zum 17. Oktober 1806 das volle Ausmaß der preußischen Niederlage bekannt. Dem stellvertretenden Gouverneur von Berlin, Graf Friedrich Wilhelm von der Schulenburg-Kehnert, war bewusst, dass die französische Einnahme nur eine Frage der Zeit war. Aus diesem Grund versuchte er die soziale Ordnung damit aufrecht zu erhalten, indem er dem Patriotismus der Berliner entgegenwirkte. So lehnte er das Gesuch ab, eine freiwillige Berliner Bürgermiliz aufzubauen, die im märkischen Umland die französische Armee bekämpfen wollte. In einem berühmt gewordenen Aufruf ließ er am 17. Oktober 1806 an Mauern verkünden:

Trotz der verordneten Ruhe herrschte in Berlin eine unübersichtliche Betriebsamkeit. Um an Neuigkeiten zu gelangen, versammelten sich viele Berliner auf den Straßen. Die Stimmung war durchaus gemischt. Zum Teil bekundeten die Bewohner ihre Loyalität für die königliche Familie, andere spotteten über die Flucht der Prinzen, Regierung und Beamten, während andere offen ihre Wut über die politisch Verantwortlichen äußerten. Sogar Sympathiebekundungen für Napoleon sollen zuhören gewesen sein. Das Durcheinander in der Stadt führte dazu, dass im Zeughaus lagernde Munition und Waffen nicht weggeschafft wurden. Mit zeitlicher Verzögerung folgten wohlhabende Bürgerfamilien dem Beispiel der Obrigkeit und reisten nach Ostpreußen ab. Sie hofften, dass ihre verlassenen Berliner Wohnungen weniger attraktiv für die Einquartierung französischer Soldaten sein würden.

Zwischen dem 18. Oktober 1806 und dem 23. Dezember 1809 hatte Berlin de facto seine Funktion als Sitz der preußischen Krone, Staatsbehörden und des Hofes eingebüßt. Memel und Königsberg rückten in dieser Zeit an die Stelle Berlins, das in Reichweite der französischen Armeen lag. Bälle, Ausstellungen, Feste, Theater- und Opernaufführungen gingen in Berlin ohne Förderung der Regierung zurück. Trotzdem zeigten die Berliner anfangs nicht nur Ablehnung gegenüber der napoleonischen Besetzung. Nachdem am 23. Oktober 1806 die ersten zwei französischen Divisionen durch das Kottbusser und Hallesche Tor eingedrungen waren, inszenierte Napoleon sich am 27. Oktober 1806 während seines Einzug durch das Brandenburger Tor als siegreicher Feldherr: Die zwischen dem Großen Stern und dem Brandenburger Tor auf beiden Seiten Spalier stehenden französischen Kürassiere, empfingen Napoleon mit „vive l’empereur“-Rufen (: „Es lebe der Kaiser“), denen sich zumindest einige Berliner anschlossen. Der französische Militärkommandant ordnete an, dass zu Ehren Napoleons alle Glocken Berlins zu läuten waren und an den Fenstern Frauen weiße Tücher zu schwenken hätten. Vor dem Brandenburger Tor überreichte der Berliner Magistrat Napoleon die Schlüssel der Stadt.

In Berlin verfolgte Napoleon zwei Ziele: Erstens musste er durch Kontributionen, Einquartierungen, Armeelieferungen und Kunstraub die Finanzierung seiner Expansionspolitik sicherstellen. Auch um das französische Gewerbe und den Handel anzukurbeln, war er darauf angewiesen, das besiegte Preußen wirtschaftlich auszupressen. Zweitens musste ein möglicher Aufstand der Berliner verhindert werden, der sonst zu viele französische Truppen gebunden hätte, vor allem da sich der Krieg in Ostpreußen noch fortsetzte. Da staatliche Behörden, die Abgaben und Zahlungen hätten eintreiben können, jedoch größtenteils aus Berlin geflohen waren, musste Napoleon den Aufbau einer neuen, ihm loyalen Administration gewährleisten. Zu diesem Zweck ließ Napoleon am 27. Oktober 1806 den Berliner Stadtmagistrat und den Zivilgouverneur in sein Quartier, das Berliner Stadtschloss, zitieren. Der Magistrat sollte 2000 wohlhabende Bürger nennen, die dann aus ihrer Mitte 60 Personen wählten, die die provisorische Generalverwaltung leiten sollten. Die Generalverwaltung hatte wiederum ein sieben Köpfe umfassendes „Comite administrativ“ zu bestimmen. Es sollte den Stadtmagistrat ersetzen. Zusätzlich befahl Napoleon am 3. November 1806 die Bildung einer unter französischen Kommando stehenden 1200 Mann starken Bürgergarde, die die öffentliche Ordnung aufrechterhalten sollte. 

Zwischen 1806 und Dezember 1808 waren in Berlin nie weniger als 12.000 Soldaten stationiert, darunter auch Truppen der mit Napoleon verbündeten Rheinbundstaaten. Die noch aus der Zeit Friedrichs des Großen stammenden Kasernen Berlins reichten nicht aus, um die zeitweise 30.000 Mann unterzubringen, weshalb sie größtenteils in private Wohnungen einquartiert werden mussten. Um ihre Versorgung möglichst lange zu sichern, versuchte die französische Militärführung durch strenge Strafen Exzesse zu verhindern. Dennoch kam es vereinzelt zu Plünderungen, Erpressungen und gewalttätigen Eskalationen zwischen Hausbewohnern und Soldaten. Im Umgang mit den Wohnungsbesitzern ermahnte der französische General Pierre Augustin Hullin seine Soldaten „die gewöhnliche Mahlzeit (…) zu teilen und unter keinerlei Vorwand mehr zu verlangen“. Fleisch, Wein und Brot sollten aus militärischen Vorratslagern bezogen werden, um die Zivilisten zu entlasten. Bürger, die den Soldaten kein Quartier geben konnten, mussten Quartiergeld zahlen. In den zwei Jahren verschlang die zweijährige Verpflegung der Soldaten 8,6 Millionen Taler. Handel und Produktion gingen in der Folge deutlich zurück. Die Besatzer strukturierten die Verwaltung nach französischem Vorbild um, zogen staatliches Eigentum und persönlichen Besitz der Adligen ein. Erst nach der Ratifikation eines Abkommens mit Frankreich zur Umsetzung des Tilsiter Friedens zogen die Franzosen im Dezember 1808 aus Berlin ab.

Wie schon bei seinen vorhergegangenen Feldzügen betrieb Napoleon keine willkürliche Plünderung von Schlössern und Sammlungen. Er ließ Kunstwerke aus besetzten Ländern systematisch nach Paris transportieren. Dabei ging ihm der Generaldirektor des Musee Napoleon, Dominique-Vivant Denon, zur Hand. Denon wählte die bedeutendsten Kunstwerke aus, indem er sämtliche königliche Sammlungen in Potsdam, Charlottenburg und Berlin besichtigte sowie deren Inventarlisten begutachtete. Die akribisch durchgeführte Aufzeichnung ermöglichte nach der Niederlage Napoleons deren Rückführung nach Berlin. Denon wählte 116 Gemälde, 204 Statuen, Büsten und Reliefs, tausende Münzen, 25 Gegenstände aus Elfenbein und 23 aus Bernstein aus. Zwei Schiffe wurden benötigt, um die in Kisten verpackte Fracht in die französische Hauptstadt zu schaffen. Bereits am 11. November 1806 benachrichtigte Denon den Künstler Johann Gottfried Schadow in seinem Atelier, dass Napoleon persönlich angeordnet habe, sein Werk, die Quadriga des Brandenburger Tors, abzubauen. Sie sollte auf einem zu diesem Zeitpunkt noch nicht näher bestimmten Pariser Triumphbogen wieder aufgestellt werden. Die Klage Schadows und anderer Künstler, die diese in einem Brief an Napoleon äußerten, die Kupferarbeit könne bei dem Transport beschädigt werden, sollte den Kaiser nie erreichen. Vom 2. bis 8. Dezember 1806 wurde die Quadriga schließlich von dem Potsdamer Kupferschmied Emmanuel Ernst Jury abmontiert und am 21. Dezember 1806 auf ein Schiff verladen. An die Quadriga erinnerte bis 1814 nur noch eine eiserne Befestigungsstange, die zum städtebaulich sichtbaren Symbol der preußischen Niederlage von 1806 avancierte. Napoleon wurde von den Berlinern deshalb fortan als „Pferdedieb“ verspottet.

Die Reaktion auf den offensichtlichen Zusammenbruch des altpreußischen Staats waren Preußischen Reformen, die mit dem Oktoberedikt von 1807 beginnend, das Ende der Ständeordnung und die Bauernbefreiung herbeiführten. Reformer wie der Freiherr vom und zum Stein, der Philosoph Johann Gottlieb Fichte oder der Theologe Friedrich Schleiermacher setzten sich nun für die Berliner Belange ein: Unter Stein wurde am 19. November 1808 die neue Berliner Städteordnung beschlossen und in einem Festakt am 6. Juli 1809 in der Nikolaikirche proklamiert, was zur ersten frei gewählten Stadtverordnetenversammlung führte. Wahlberechtigt waren aber nur Hauseigentümer und Personen mit einem Jahreseinkommen über 200 Taler, das waren dazumal rund sieben Prozent der Einwohner. An die Spitze der neuen Verwaltung wurde ein Oberbürgermeister gewählt, der erste in diesem Amt war Carl Friedrich Leopold von Gerlach, der es bis zu seinem Tod 1813 blieb. Die Vereidigung der neuen Stadtverwaltung, nun ‚Magistrat‘ genannt, erfolgte am 8. Juli 1809 im Berliner Rathaus.

Weitere Reformen wie die Einführung einer Gewerbesteuer, das unter Staatskanzler Carl August von Hardenberg verabschiedete Gewerbe-Polizeigesetz (mit der Abschaffung der Zunftordnung und Einführung der Gewerbefreiheit), die bürgerliche Gleichstellung der Juden und die Erneuerung des Heereswesens führten zu einem neuen Wachstumsschub in Berlin. Vor allem legten sie in Verbindung mit der Bauernbefreiung die Grundlage für die spätere Industrieentwicklung in der Stadt. Der König kehrte Ende 1809 mit seinem gesamten Hofstaat nach Berlin zurück. Als die napoleonischen Truppen im Zuge ihres Russlandfeldzuges 1812 wieder in Berlin einrückten, herrschte zeitweilig Stillstand. Diese erneute Besatzung war nach der vernichtenden Niederlage Napoleons 1813 beendet, bis dahin hatten sich sogar viele Berliner als Freiwillige in die Russische Armee gemeldet. Als Napoleon geschlagen war, sorgte General Blücher auch für die sofortige Rückgabe der Quadriga an Berlin (siehe auch → hier). Sie erhielt erneut ihren Platz auf dem Brandenburger Tor, dabei wurde dem Stab der Siegesgöttin nach einem Entwurf von Karl Friedrich Schinkel nun ein Eisernes Kreuz und ein preußischer Adler hinzugefügt. Viele Berliner verbanden den Sieg über Frankreich mit der Hoffnung, dass ein neuer Weg in eine demokratische Zukunft beschritten werden könne.

An der Potsdamer Straße entstand ab 1809 der Botanische Garten, der Ende des 19. Jahrhunderts nach Dahlem verlegt wurde.

Die bestehenden zahlreichen Schulen und kleinen wissenschaftlichen Einrichtungen (wie die Akademie der Künste, Bauakademie, Lehrinstitut für Bergwerk und Hüttenwesen, Schulen zur Ausbildung von Militär oder Ärzten) mussten zwecks besserer Wirksamkeit reformiert werden. Unter der Leitung von Wilhelm von Humboldt wurde das Bildungswesen neu geordnet. Die Gründung der Berliner Universität erfolgte 1810. Hier wurde die notwendige Einheit von Lehre und Forschung praktiziert. 52 Professoren begannen ihre Vorlesungen vor 256 eingeschriebenen Hörern im Palais des Prinzen Heinrich. Zu den ersten Professoren gehörten August Boeckh, Albrecht Daniel Thaer, Friedrich Carl von Savigny, Christoph Wilhelm Hufeland. Erster Rektor wurde der Philosoph Johann Gottlieb Fichte. Die neue Universität entwickelte sich rasch zum geistigen Mittelpunkt von Berlin und wurde bald weit über die preußische Residenzstadt hinaus berühmt. Hier lehrte beispielsweise ab 1818 der Philosoph Georg Wilhelm Friedrich Hegel. Mit Berlin verbunden war Alexander von Humboldt. In den folgenden Jahrzehnten wirkten viele bedeutende Wissenschaftler in der Stadt, wie der Historiker Leopold von Ranke der Geodät Johann Jacob Baeyer, der Biologe Johannes Peter Müller, der Geograph Carl Ritter, der Mathematiker Karl Weierstraß, der Astronom Wilhelm Foerster oder der Arzt Albrecht von Graefe. Heinrich Gustav Magnus baute ab 1840 eines der ersten physikalischen Institute Deutschlands in Berlin auf.

Zwischen 1810 und 1811 erschien Berlins erste Tageszeitung, die von Heinrich von Kleist herausgegebenen "Berliner Abendblätter". Das in der Straße An der Stechbahn gelegene "Volpische Kaffeehaus", später "Café Josty", wurde zu einem beliebten öffentlichen Treffpunkt des Bürgertums genauso wie auch das Weinlokal "Lutter & Wegner" am Gendarmenmarkt. Friedrich Ludwig Jahn begann 1811 mit den Turnveranstaltungen in der Hasenheide. Seit 1812 galt für die Juden eine Berufsfreiheit. Die Niederlage der Franzosen 1814 bedeutete auch ein Ende weiterer Reformen.

Der Komponist Carl Friedrich Zelter, ein Bewohner von Berlin, schrieb 1817 an seinen Freund Wolfgang Maximilian von Goethe: Heinrich Heine äußerte 1826 in seinen Reisebildern: „Berlin ist gar keine Stadt, sondern Berlin gibt bloß den Ort dazu her, wo sich eine Menge Menschen, und zwar darunter viele Menschen von Geist, versammeln, denen der Ort ganz gleichgültig ist.“

Karl Friedrich Schinkel legte 1822 Pläne für die Neugestaltung der nördlichen Spreeinsel vor, dort wurde 1825 mit dem Bau des Alten Museums begonnen. Das Schauspielhaus am Gendarmenmarkt eröffnete 1821.

Mit dem Ende der Napoleonischen Kriege begann für Preußen und seine Hauptstadt eine jahrzehntelange Friedensperiode. Ohne eine kriegerische Beeinträchtigung von außen wurde die soziale und politische Entwicklung innerhalb Berlins beschleunigt. Ein wesentlicher Faktor hierfür war das rapide Wachstum der Bevölkerung. Während 1816 nur etwa 200 000 Menschen in der Stadt lebten, waren es im Jahr 1840 bereits 330.000 und im Jahr 1846 sogar 408.000 Einwohner. Berlin war um 1850 nach London, Paris und Wien zur viertgrößten Stadt Europas herangewachsen. Die Verdopplung der Berliner Einwohnerzahl im Vormärz kann zum einen durch eine jährliche Geburtenrate von 30 Prozent (d. h. 300 Lebendgeburten auf 1000 Einwohner) und zum anderen durch eine hohe Zuwanderung erklärt werden. Mit der Bauernbefreiung von 1807 (siehe dazu das Oktoberedikt) konnte die Landbevölkerung erstmals nach Berlin einwandern. Als Großstadt mit karitativen Organisationen, vielfältigen Arbeitsmöglichkeiten und Freizeitangeboten übte Berlin eine große Anziehungskraft auf ihr Umfeld aus. Die Neu-Berliner stammten noch überwiegend aus den agrarisch geprägten preußischen Provinzen Brandenburg und Schlesien. Da sie nicht an den wirtschaftlichen Wettbewerb der Stadt gewöhnt waren, glitten die meisten Zuwanderer in Armut ab. Sie gingen der Tätigkeit als Tagelöhner, Kutscher oder Hausknecht nach.

Das seit den späten 1830er Jahren wachsende preußische Eisenbahnnetz legte die Grundlagen für den Beginn der industriellen Revolution, der neben dem Bevölkerungswachstum zweiten wichtigen Entwicklung im Vormärz-Berlin. Existierten in Preußen im Jahr 1840 nur 185 Kilometer Eisenbahnstrecke, waren es im Jahr 1843 bereits 815 und im Jahr 1847 schon 1424 Kilometer. Der Norden Berlins entwickelte sich dank diesem entstehenden Verkehrsnetz zu einem wichtigen Maschinenbaustandort. Die Industriestadt Berlin war das erste, das ein Reisender zu Gesicht bekam, wenn er sich der Stadt näherte. Einen guten Eindruck von den Verhältnissen vermittelt ein Bericht der "Spenerschen Zeitung" aus dem Jahr 1840:
Anfang der 1830er Jahre regte sich insbesondere in der preußischen Regierung und Bürokratie noch Widerstand gegen den Bau eines Berliner Eisenbahnnetzes. Dies lag daran, dass der Fokus der preußischen Regierung noch primär auf dem Ausbau von Chausseen beruhte. Der neuen Technologie dagegen wurde misstraut, zumal bei der Verlegung von Gleisen staatliche Ländereien betroffen waren. Noch 1834 lehnte das preußische Innenministerium den Bau einer Bahnstrecke zwischen Berlin und Leipzig ab. Eine Wende trat erst durch die Bemühungen des Berliner Rechtsanwaltes J. C. Robert ein, der König Friedrich Wilhelm III. einen Plan vorlegte, der die Eisenbahnstrecke von Berlin nach Potsdam reduzierte. Der König leitete daraufhin eine Untersuchung des Planes durch das Staatsministerium an, das dem Unterfangen einen wirtschaftlichen Nutzen bescheinigte. In einer Kabinettsorder vom 16. Januar 1836 bestätigte der preußische König die Genehmigung für den Schienenbau. Schließlich gelang es, einer Reihe von Privataktionären 1837 die Berlin-Potsdamer Eisenbahngesellschaft zu gründen, die mit einem Startkapital von 700.000 Talern die Finanzierung stemmen sollte. Innerhalb von 14 Monaten wurde eine eingleisige Strecke vom Platz vor dem Potsdamer Tor über Zehlendorf nach Potsdam errichtet. Bis auf Schienenschrauben und Wagenkästen, die in Berlin hergestellt wurden, kamen bei dem Vorhaben alle technischen Anfertigungen wie Lokomotiven und Gleise aus England. Am 22. September 1838 wurde die Strecke als erste preußische Eisenbahnlinie in Betrieb genommen.

Noch in den 1840ern war die Eisenbahn in Berlin zu einem wichtigen Verkehrsmittel geworden: In den Jahren 1847 und 1848 erreichten oder verließen die Stadt 1,5 Millionen Reisende über das Schienennetz. Die 1841 vollendete Strecke nach Anhalt verband Berlin fortan mit dem Königreich Sachsen. Die Strecke nach Potsdam wurde bis 1844 nach Magdeburg erweitert. Bis 1846 erhielt Berlin über Frankfurt an der Oder eine Verbindung nach Breslau. Im selben Jahr folgte der Anschluss nach Hamburg. Schon ab dem Jahr 1844 verbanden die Eisenbahnstrecken Berlin mit allen vier Himmelsrichtungen. Dies führte zu einer Beschleunigung des Nachrichtenwesens, des Handels, der Industrie und der Personenmobilität. Die am Stadtrand gelegenen Bahnhöfe wurden durch Pferdeomnibusse untereinander und mit der Stadt verbunden. Um 1840 waren etwa 1000 Droschken und andere Fuhrwerke im Einsatz. Sie wurden in der Regel noch von privaten Unternehmen geführt, die aber langfristig nicht genügend Kapital aufbringen konnten und in den nächsten Jahrzehnten verschwinden sollten. 

Die erste von Borsig gebaute Lokomotive fuhr 1841 vom neuen Anhalter Bahnhof. Der Stettiner Bahnhof nahm 1842 den Betrieb auf. Im selben Jahr wurde auch der Frankfurter Bahnhof eröffnet, der als einziger innerhalb der Zollmauer lag. Der fünfte Kopfbahnhof wurde 1846 als Hamburger Bahnhof eingeweiht. Die Straßen, die vom Stadtzentrum zu den Bahnhöfen verliefen, entwickelten sich zu Hauptverkehrsadern. Die Leipziger Straße wandelte sich in den folgenden Jahrzehnten von einer Wohnstraße zur Geschäftsstraße, an der sich die großen Warenhäuser befanden.

Die mit dem Bevölkerungswachstum und der Industriellen Revolution verbundenen sozialen Probleme und die Wohnungsnot führten zu einem gewaltigen Bauboom. Zunächst wurden die Freiflächen innerhalb des Mauerrings bebaut. Allerdings siedelten sich die meisten Industrieunternehmen aus Platzgründen an der Stadtperipherie an, wohin ihnen die Arbeitersiedlungen folgten. Vor allem im Bereich der Oranienburger und Rosenthaler Vorstadt wuchs Berlin deutlich über ihre Mauern hinaus. In den Berliner Vorstädten entwickelten sich die ersten sogenannten ‚Mietskasernen‘. In diesen Wohnungen kam es vor, dass sich mehrere Familien einen Raum teilen mussten, der nur durch Kreidestriche oder eine Schnur symbolisch getrennt wurde. Aus einem zeitgenössischen Polizeibericht geht hervor, dass allein vor dem Hamburger Tor 2500 Menschen in nur 400 Zimmern untergebracht waren. Zur gängigen Praxis gehörte auch die Aufnahme sogenannter „Schlafburschen“, die gegen Bezahlung für einige Stunden in die Wohnung aufgenommen wurden. Durch diese Art der Weitervermietung ließen sich die eigenen Mietkosten senken.

Unter Leitung von Peter Beuth wurde ein umfassendes Programm der Gewerbeförderung durchgeführt und 1821 zur Verbesserung der Gewerbeausbildung das Gewerbeinstitut eingerichtet. Vor dem Oranienburger Tor begann 1804 die Königlich Preußische Eisengießerei ihre Arbeit. Weitere Unternehmen folgten, wie 1837 die Maschinenbauanstalt von August Borsig. Das Industriegebiet in der Oranienburger Vorstadt erhielt bald den Namen "Feuerland". Neue Maschinenbaufabriken, wie die Werke von Louis Schwartzkopff, Julius Pintsch oder Heinrich Ferdinand Eckert entstanden, im Apparatebau führend wurde die Firma von Carl Justus Heckmann.

Der preußische Staat benötigte für die Verwaltung und Kontrolle der von der Hauptstadt weit entfernten Rheinprovinzen schnellere Kommunikationsmittel. Ausgehend von der Berliner Sternwarte in der Dorotheenstraße wurde bis Ende 1832 eine optische Telegrafenlinie über Potsdam bis Magdeburg fertiggestellt, deren Verlängerung später bis Koblenz erfolgte.

Ab 1825 wurde die zentrale Gasversorgung aufgebaut, vor allem auch für die Straßenbeleuchtung. Das erste private Gaswerk der englischen Imperial Continental Gas Association vor dem Halleschen Tor ging 1826 in Betrieb. Zwei städtische Gaswerke, aus denen später die GASAG entstand, wurden Mitte der 1840er Jahre am Stralauer Platz und in der Gitschiner Straße (Böcklerpark) gebaut.

Die Berliner Münze bezog 1800 ihr neues Gebäude am Werderschen Markt. Nicht weit entfernt in der Jägerstraße befand sich die 1765 gegründete Königliche Hauptbank (ab 1847 Preußische Bank, aus der 1876 die Reichsbank hervorging). Seit 1815 hatte das Bankhaus Mendelssohn seinen Sitz in der Jägerstraße. In der Nachbarschaft war das Gebäude der staatlichen Seehandlungsgesellschaft, die in der Finanzierung des Eisenbahnbaus aktiv war.

Die Choleraepidemie erreichte Berlin 1831, während der etwa 2000 Einwohner erkrankten. Kinderarbeit in der Industrie mit hohen täglichen Arbeitszeiten war üblich. Die durchschnittliche Lebenserwartung in Berlin Mitte des Jahrhunderts lag für höhere Berufe bei 54 Jahren, für Industriearbeiter bei 42 Jahren.

König Friedrich Wilhelm IV. verlegte das Hofjagdgebiet der Hohenzollern, das sich seit dem 16. Jahrhundert im Großen Tiergarten befunden hatte, in den Wildpark bei Potsdam. Das frei gewordene Gelände mit der dortigen Fasanerie sowie die 850 Tiere der königlichen Menagerie, die sich auf der Pfaueninsel befand, schenkte er der Berliner Bevölkerung. Auf dieser Grundlage entstand im Jahr 1844 mit dem Zoologischen Garten der älteste Tierpark Deutschlands.

Bereits in den 1820er Jahren bildete sich die Friedrich-Wilhelm-Stadt als eigener Stadtteil. Bis 1841 wurden die Stadtgrenzen über die Zollmauer hinaus erweitert, die Oranienburger und Rosenthaler Vorstadt kamen hinzu, ebenso die äußere Luisenstadt, das äußere Stralauer Viertel und das äußere Königsviertel sowie die Friedrichsvorstadt. Peter Joseph Lenné übernahm ab 1840 die städtebaulichen Planungen. Aufbauend u. a. auf Ideen von Schinkel legte er 1840 die „Projectirten Schmuck- und Grenzzüge von Berlin mit nächster Umgebung“ vor, worin der Ausbau des Landwehrkanals (1850 eingeweiht) vorgeschlagen wurde.

Im Vormärz grenzte sich der königliche Hof noch deutlich von der Industrie- und Bürgerstadt Berlin ab. Zum einen lag dies an der fehlenden gesellschaftlichen Durchlässigkeit zwischen den Ständen. Noch immer bildete das Berliner Schloss das Zentrum einer „militärisch-aristokratischen Exklusivität“. Nur den jeweils höchsten Spitzen des Berliner Wirtschafts- und Bildungsbürgertums wurde Zutritt zum Hofleben gewährt. Der Großteil der Akademiker, Künstler und Schriftsteller blieb jedoch davon gänzlich ausgeschlossen. Da noch kein voll entwickeltes Kommunikations- und Verkehrsnetz sowie kein parlamentarisches Mitspracherecht bestand, übte der Hof bis 1848 nur wenig Einfluss auf die öffentliche Meinung aus. Hinzu kam, dass insbesondere König Friedrich Wilhelm IV. und sein Hofstaat in Berlin keine ständige Präsenz zeigten. Im Frühling hielt sich der Hof mit Vorliebe im Potsdamer Stadtschloss auf, der Frühsommer wurde häufig in Sanssouci verbracht, im August und September zog sich der König nach Rügen und ins schlesische Erdmannsdorf zurück, reiste im Herbst für Truppenmanöver nach Potsdam und verbrachte die Weihnachtszeit in Schloss Charlottenburg. Das Erscheinungsbild Berlins als Residenzstadt trat aufgrund des enormen Wachstums des Stadtgebietes zunehmend in den Hintergrund. Der Zeitgenosse Friedrich Saß kommentierte dies 1846 mit den Zeilen:
Die Spannungen zwischen Regierung und Hauptstadt verschärften sich nach 1815 auch politisch: An die Stelle der preußischen Reformer traten nun konservative Berater des Königs, die auf eine vorrevolutionäre Staats- und Gesellschaftsordnung hinarbeiteten. Obwohl der Protest in Berlin gegen die Restaurationspolitik eher gering ausfiel, sanktionierte die Regierung die national und liberal gesinnte Turn- und Studentenbewegung. 1819 wurde die Schließung des Turnplatzes an der Hasenheide und ein generelles Turnverbot veranlasst. Insbesondere Berliner Studenten und Professoren waren im Zuge der sogenannten „Demagogenverfolgung“ von willkürlichen Verhaftungen, Hausdurchsuchungen, Spionage und öffentlicher Denunziation betroffen. Zahlreiche Theaterstücke und Publikationen wurden zensiert oder ganz verboten, Professoren wie Wilhelm Martin Leberecht de Wette verloren ihren Lehrstuhl und Theologen wie Friedrich Schleiermacher wurden strafversetzt. Aus der Verfolgungshysterie resultierte schließlich eine schleichende Entfremdung zwischen Dynastie und Hauptstadt.

Ausdruck der politischen und sozialen Unzufriedenheit im Vormärz waren Unruhen wie die Schneiderrevolution 1830, die Feuerwerksrevolution 1835 und die Kartoffelrevolution 1847. Als Folge der Missernte von 1846 und sogenannten Kartoffelfäule kam es in Berlin zu einer krisenhaften Verknappung von Lebensmitteln. Im Januar 1847 stiegen die Kartoffelpreise um das Drei- bis Vierfache an. Selbst die Außerkraftsetzung aller Einfuhrzölle für Mehl und Getreide konnte die Preisexplosionen nicht mehr stoppen. Am 21. April 1847 brachen auf dem Gendarmenmarkt Tumulte aus, die mit der Plünderung von Kartoffelständen begannen. Schnell weitete sich die Unruhe auf große Teile der Stadt aus. Bäcker- und Fleischerläden wurden angegriffen. Der Umstand, dass nicht nur Lebensmittel gestohlen wurden, sondern auch Fensterscheiben und Türen eingeschlagen, Geräte und Mobiliar beschädigt oder mitgenommen und Ladenschilder als Brennholz verwendet wurde, zeigt, dass es sich bei dem Protest sowohl um eine „Strafaktion“ als auch Hungerrevolte handelte. Erst mithilfe von Militärkräften gelang es am 23. April 1847 die Situation wieder unter Kontrolle zu bringen.

Nur in kleinsten Kreisen befasste man sich mit möglichen Entwicklungen, es entstanden zahlreiche „Debattierklubs“.

→ siehe Hauptartikel zur Märzrevolution 1848 in Berlin 

Die politischen Spannungen waren bei allen Fortschritten nicht ausgeräumt. Der Tod von König Friedrich Wilhelm III. und der Regierungsantritt von Friedrich Wilhelm IV. änderten an den bestehenden Zuständen kaum etwas. Die erstarkenden Handwerksbetriebe schlossen sich im Jahr 1844 zum Berliner Handwerker-Verein zusammen und nahmen damit auch auf die politische Bildung des Mittelstandes Einfluss. Außerdem wurde der Bund der Gerechten gegründet. Die sozialen Probleme in Berlin wurden durch die Kunde über den Schlesischen Weberaufstand besonders deutlich beleuchtet. Eine Missernte und die zunehmende Verfolgung Andersdenkender führten zu ersten Unruhen in der Stadt.

Am 18. März 1848 kam es zu einer großen Kundgebung, an der sich rund 10.000 Berliner beteiligten. Die königstreuen Truppen waren dagegen aufmarschiert und es begannen nächtliche Barrikadenkämpfe. Bis zur Beendigung dieser Märzrevolution am 21. März waren 192 Personen umgekommen. Allerdings kam es auch danach weiterhin zu Unruhen. So wurde am 14. Juni 1848 das Zeughaus gestürmt und geplündert.

Im Ergebnis des Aufstands machte der König mit seiner Proklamation „An meine lieben Berliner“ jedoch zahlreiche Zugeständnisse; vor allem wurde die Presse- und Versammlungsfreiheit eingeführt, und ihrem Gefolge entstanden erste politische Vereinigungen als Vorläufer späterer Parteien. Ende 1848 wurde ein neuer Magistrat gewählt. Die Wirtschaft war in den vorangegangenen Jahrzehnten rückläufig, sodass es nun eine große Anzahl Erwerbsloser gab. Man führte Notstandsarbeiten ein, die zum schnellen Ausbau des Berliner Wasserstraßensystems führten. Diese kleinen Verbesserungen waren jedoch nicht von langer Dauer, im Spätherbst 1848 setzte der König ein neues Kabinett ein, am 10. November rückten wieder preußische Truppen in Berlin ein, am 12. November wurde der "Belagerungszustand" ausgerufen. Viele Errungenschaften der Revolution waren damit zunichte geworden.

Die Einführung der elektrischen Telegrafie ermöglichte 1849 die Gründung der Nachrichtenagentur Wolffs Telegraphisches Bureau.Das Kaufhaus Gerson eröffnete 1849 als erstes Warenhaus Berlins am Werderschen Markt.

Nach einer kurzen Pause wurde im März 1850 eine neue Stadtverfassung und Gemeindeordnung beschlossen, wonach die Presse- und Versammlungsfreiheit wieder aufgehoben, ein neues Dreiklassenwahlrecht eingeführt und die Befugnisse der Stadtverordneten stark eingeschränkt wurden. Die Rechte des Polizeipräsidenten Carl Ludwig Friedrich von Hinckeldey wurden dagegen gestärkt. In seiner Amtszeit bis 1856 sorgte er allerdings auch für den Aufbau der städtischen Infrastruktur (vor allem Stadtreinigung, Wasserwerke, Wasserleitungen, Errichtung von Bade- und Waschanlagen).

Preußen wurde 1850 eine konstitutionelle Monarchie. Die zwei Kammern des Preußischen Landtags, Herrenhaus und Abgeordnetenhaus, hatten ihren Sitz in Berlin.

Die Bauordnung von 1853 begünstigte in den folgenden Jahrzehnten die Entstehung der Mietskasernen. Eine bedeutende Stadterweiterung erfolgte 1861. Wedding mit Gesundbrunnen, Moabit, die Tempelhofer und Schöneberger Vorstädte sowie die äußere Dorotheenstadt kamen hinzu. Mit dem 1852 fertiggestellten Luisenstädtischen Kanal sollte der neue Stadtteil Friedrich-Wilhelm-Stadt einen attraktiven Freiraum erhalten. Weitere Pläne von Lenné für den Berliner Norden folgten 1853.

Bedeutsam bei der Finanzierung der Industrie wurde die 1856 gegründete Berliner Handels-Gesellschaft, die zwischen Französischer Straße und Behrenstraße ihren Sitz hatte. Die 1851 gegründete Disconto-Gesellschaft, lange Zeit eine der größten deutschen Bankgesellschaften, bezog ein Gebäude Unter den Linden. In den folgenden Jahrzehnten entwickelte sich die Gegend zum führenden Zentrum der Finanzwirtschaft in Deutschland.

Im Jahr 1861 wurde Wilhelm I. neuer König. Zu Beginn seiner Regentschaft gab es Hoffnung auf eine Liberalisierung. 1861 wurde das Stadtgebiet durch die Eingemeindung von Wedding und Moabit sowie Tempelhofer und Schöneberger Vorstadt erweitert.

Das weiterhin rapide Bevölkerungswachstum der Stadt führte in dieser Zeit zu großen Problemen. Das Verkehrswesen musste erneuert werden, der Bau der Berliner Ringbahn führte zur besseren Verbindung der Berliner Kopfbahnhöfe. In der Verantwortung der Königlichen Eisenbahndirektion Berlin lag der weitere Ausbau der Vorortbahnen und damit wesentlich die Gestaltung des zukünftigen Wachstums der Großstadtregion. 1862 trat der Hobrecht-Plan in Kraft, der die Bebauung von Berlin und seines Umlandes in geordnete Bahnen lenken sollte. Der Bau von Wasserversorgung und Kanalisation unter maßgeblicher Beteiligung von Rudolf Virchow schuf wesentliche Voraussetzungen für die moderne Stadt. Das erste kommunale Krankenhaus entstand im Volkspark Friedrichshain. Der Neubau des Roten Rathauses wurde 1869 fertiggestellt.

Mit der Eröffnung der ersten Strecke der Pferdebahn begann 1865 die Geschichte der Straßenbahn in Berlin. Die ABOAG, der größte Betreiber von Pferdeomnibussen in Berlin, wurde 1868 gegründet (bereits seit 1825 gab es Pferdeomnibusse).

Die ersten Postbezirke für Berlin wurden 1862 festgelegt. Das Haupttelegraphenamt zwischen Französischer und Jägerstraße entstand ab 1863. Das Rohrpostsystems ging 1865 in Betrieb. Von 1910 bis 1916 wurde das neue Haupttelegraphenamt in der Oranienburger Straße gebaut, in unmittelbarer Nähe liegt das 1881 fertiggestellte Postfuhramt. Für das Hofpostamt wurde bis 1882 ein Neubau errichtet.

Seit 1862 waren Steinplatten aus Lausitzer Granit – die sogenannten „Schweinebäuche“ oder „Charlottenburger Platten“ – als Belag der Bürgersteige vorgeschrieben und seit 1873 deren Rahmung mit Mosaikpflaster.

Die ersten Plakatsäulen von Ernst Litfaß wurden 1855 aufgestellt.

Vor allem im Nordosten der Stadt entstanden mehrere große Brauereien, wie das Unternehmen von Julius Bötzow, die Schultheiss-Brauerei von Richard Roesicke, die Aktienbrauerei Friedrichshöhe von Georg Patzenhofer und Friedrich Goldschmidt, das Böhmische Brauhaus von Armand Knoblauch und weitere.

Das Baumaterial für die Expansion zur Metropole bezog Berlin überwiegend aus der Mark Brandenburg. Über die Wasserwege wurden Rüdersdorfer Kalkstein, Ziegel aus Glindow und Zehdenick oder Kachelöfen aus Velten angeliefert.

Die politische Bedeutung Berlins als Hauptstadt Preußens wuchs 1867 an, als der Norddeutsche Bund gegründet wurde, dessen Bundeskanzler der preußische Ministerpräsident Otto von Bismarck wurde, sodass Berlin nun erstmals auch für nichtpreußische Gebiete Hauptstadtfunktionen innehatte.

Unter der Führung Preußens kam es nach Ende des Deutsch-Französischen Kriegs zur Kleindeutschen Lösung; 1871 wurde das Deutsche Reich gegründet, Wilhelm I. wurde Kaiser und Berlin zur Hauptstadt des Reichs.

Berlin war inzwischen zu einer Industriestadt mit 800.000 Einwohnern angewachsen. Mit diesem Wachstum konnte die Infrastruktur jedoch nicht mithalten. 1873 begann man endlich mit dem Bau einer Kanalisation, der 1893 abgeschlossen war. Auf den ökonomischen Boom der Gründerzeit folgte der Gründerkrach, eine Wirtschaftskrise in der zweiten Hälfte der 1870er Jahre. Die Stadtentwicklung blieb nach wie vor ein strittiges Thema. Am 1. Januar 1876 erhielt die Stadt Berlin per Vertrag vom Staat die Brücken und Straßen. 1882 beschränkte das sogenannte "Kreuzbergerkenntnis" die Baupolizei auf das Abwenden von Gefahren, untersagte ihr jedoch die Einflussnahme in ästhetischen Aspekten.

Die weiter rasant wachsende Industrie Berlins brachte auch eine starke Arbeiterbewegung hervor. Spätestens nach dem Ende des Sozialistengesetzes 1890 zählte sie zu den bestorganisierten der Welt. Dazu gehörten die SPD, aber auch zahlreiche Gewerkschaften. Eine Vielzahl von Streiks, Demonstrationen und Protesten gingen von ihr aus, wie etwa die Moabiter Unruhen oder die Wahlrechtskämpfe.

Nach der Reichsgründung von 1871 bestand in der Hauptstadt Berlin ein Bedarf an repräsentativen Regierungsgebäuden. Der Reichstag bezog zunächst seinen provisorischen Sitz in der Leipziger Straße. Der Bau des neuen Reichstagsgebäudes begann 1884 am Königsplatz. Nach der Fertigstellung 1894 wurde am alten Standort zwischen Leipziger Straße und heutiger Niederkirchnerstraße ein Gebäudekomplex für das Preußische Herrenhaus und den Preußischen Landtag (1892–1904) errichtet.

Max von Forckenbeck wurde 1878 zum Oberbürgermeister gewählt und übte das Amt bis 1892 aus. In die Dienstzeit von Hermann Blankenstein als Berliner Stadtbaurat fällt der Bau des Zentralvieh- und Schlachthofes von 1876 bis 1883 sowie der Zentralmarkthalle (1883–1886). Das Wasserwerk Friedrichshagen ging 1893 in Betrieb. Gustav Meyer wurde 1870 zum Gartendirektor von Berlin ernannt (bis 1877) und plante mehrere Parks in Berlin, wie den Volkspark Friedrichshain, den Volkspark Humboldthain, den Treptower Park oder den Kleinen Tiergarten.

Ludwig Hoffmann wurde 1896 Stadtbaurat in Berlin (bis 1924), er entwarf u. a. das Alte Stadthaus und die Volksbäder in der Oderberger und Baerwaldstraße sowie viele Schulbauten und Feuerwachen. Zur besseren Versorgung der Großstadtbevölkerung mit Grünanlagen wurden u. a. der Körnerpark und der Brixplatz angelegt. Während dieser Zeit baute die Stadt beispielsweise die Heilanstalten in Buch, das Rudolf-Virchow-Krankenhaus und den Osthafen. Die wachsenden Müllmengen wurden zu größeren Teilen über den Wasserweg zur ersten städtischen Deponie nach Spreenhagen verbracht.

Bereits in 1860er Jahren begann die öffentliche Hand mit dem Ankauf von Grundstücken im historischen Stadtkern. Durch die Neubebauung mit Gebäuden für kommunale Einrichtungen wurde die Berliner Altstadt zu einem modernen Stadtzentrum umgeformt. Der Bau des Berliner Rathauses erfolgte zwischen 1860 und 1869. Die Gerichtslaube, eines der ältesten Bauwerke der Stadt, wurde 1871 abgerissen. Durch das schnelle Stadtwachstum war das Rote Rathaus bald zu klein, und es wurde ein „zweites Rathaus“ benötigt. Von 1902 bis 1911 entstand darum das Alte Stadthaus. In der Dirksenstraße wurde 1886 bis 1890 das Polizeipräsidium gebaut. Das bei seiner Fertigstellung zweitgrößte Gebäude Berlins war das Land- und Amtsgericht in der Neuen Friedrichstraße (heute Littenstraße), gebaut zwischen 1896 und 1905. Ebenfalls in der Neuen Friedrichstraße bezogen die städtischen Gaswerke ein neues Geschäftshaus. Am Rande des zu dieser Zeit entstandenen Zeitungsviertels in der südlichen Friedrichstadt wurde 1879 an der Oranienstraße im heutigen Kreuzberg die Reichsdruckerei mit dem Ziel gegründet, hoheitlichen Wertdruck – beispielsweise Banknoten und Briefmarken – zentral für das Deutsche Kaiserreich herzustellen.

Die Berliner Packetfahrt Gesellschaft verkehrte von 1884 bis 1900. Um den Alexanderplatz für Straßenverkehr besser mit der Friedrichstadt zu verbinden, erfolgte 1891 der Durchbruch der "Kaiser-Wilhelm-Straße" durch die Berliner Altstadt (Idee bereits 1873 in Orths Bebauungsplan). Die Berliner Stadtbahn wurde ab 1883 gebaut und folgt teilweise dem Verlauf des alten Festungsgrabens. Zur Bewältigung des stark angewachsenen Verkehrs begann 1896 die Konstruktion der U-Bahn und der Vorortstrecken der Eisenbahn.

An der Leipziger Straße entstand zwischen 1896 und 1906 nach Plänen des Architekten Alfred Messel ein Wertheim-Warenhaus, 1907 wurde am Wittenbergplatz das Kaufhaus des Westens (KaDeWe) eröffnet, beide zählten zu den größten Warenhäusern Europas. Das Gebiet um den Kurfürstendamm entwickelte sich zur zweiten Berliner City. Weitere City-Bereiche waren das Regierungsviertel Wilhelmstraße, das Bankenviertel, das Zeitungsviertel und das Konfektionsviertel. Im Exportviertel Ritterstraße konzentrierten sich Unternehmen der Luxuswarenherstellung. Die bedeutendsten Geschäftsstraßen waren Friedrichstraße, Leipziger Straße und Unter den Linden. Das Zentrum des Fremdenverkehrs war die Kreuzung Friedrichstraße/Unter den Linden mit dem "Café Bauer" und der Konditorei "Kranzler". Die renommiertesten Hotels waren das "Kaiserhof", das "Bristol", das "Adlon" und das "Esplanade". Beliebter Treffpunkt von Berliner Künstlern des deutschen Impressionismus, wie Max Liebermann oder Paul Lincke, war das "Café des Westens". 1906 wurde die Jahrhundertausstellung deutscher Kunst gezeigt, eine sehr umfangreiche Ausstellung, insbesondere der Kunst des gerade vergangenen 19. Jahrhunderts.

Mit dem Bau des ersten Blockkraftwerks in der Schadowstraße begann in den 1880er Jahren die Elektrifizierung der Berliner Innenstadt. Die "Städtischen Electricitäts-Werke" (später: BEWAG) wurden 1884 gegründet, und das erste öffentliche Kraftwerk ging 1885 in der Markgrafenstraße in Betrieb. Emil Rathenau gründete 1883 die "Deutsche Edison-Gesellschaft für angewandte Elektricität", die sich unter dem Namen AEG innerhalb weniger Jahrzehnte zum größten deutschen Industrieunternehmen entwickelte. Bereits 1847 hatte Werner von Siemens die "Telegraphen Bau-Anstalt von Siemens & Halske" gegründet und 1866 den ersten elektrischen Generator entwickelt. Zusammen mit der 1879 entstandenen Technischen Hochschule, dem im selben Jahr gegründeten "Elektrotechnischen Verein Berlin" und den Berliner Banken als Finanziers entwickelte sich bald die "Elektropolis Berlin". Für die AEG entwarf Peter Behrens moderne Industriebauten, wie die AEG-Turbinenfabrik von 1909 in Moabit oder die Werke im Wedding. Zwischen Charlottenburg und Spandau entstand mit der Siemensstadt ein ganzer Stadtteil, der von der Elektroindustrie geprägt wurde. Bedeutende Bauten der Industriearchitektur, wie die Dynamohalle oder in den 1920er Jahren von Hans Hertlein das Schaltwerk wurden dort errichtet. Das Gegenstück dazu bildete das Fabrikquartier Oberschöneweide im Südosten, u. a. mit dem Kabelwerk Oberspree. Die flächendeckende Elektrifizierung erfolgte wesentlich in den 1920er und 1930er Jahren. Das 1927 fertiggestellte Kraftwerk Klingenberg versorgte zusammen mit dem 1931 in Betrieb genommenen Kraftwerk West die wachsende Metropole mit elektrischer Energie. Siemens stellte 1881 in Lichterfelde die erste elektrisch betriebene Straßenbahn vor. Die erste U-Bahnstrecke vom Stralauer Tor zum Potsdamer Platz wurde 1902 eröffnet.

Ein weiterer neuer Industriezweig war die chemische Industrie. Ernst Schering gründete 1864 im Wedding eine chemische Fabrik, und aus den Zusammenschluss der Unternehmen von Paul Mendelssohn Bartholdy, Carl Alexander von Martius und Max August Jordan entstand 1873 die "Actien-Gesellschaft für Anilin-Fabrikation" (Agfa).

Die Physikalisch-Technische Reichsanstalt nahm ihre Arbeit 1887 auf. Ihr erster Präsident war der Physiker Hermann von Helmholtz. Die 1911 gegründete Kaiser-Wilhelm-Gesellschaft als Trägerin der in der Grundlagenforschung führenden Kaiser-Wilhelm-Institute nahm ihren Sitz in Berlin. Mehrere Kaiser-Wilhelm-Institute entstanden in Dahlem. Das Kaiserliche Patentamt begann 1877 seine Arbeit in Berlin. Nobelpreise wurden an den in Berlin lebenden Historiker Theodor Mommsen, den Mediziner und Mikrobiologen Robert Koch, den Chemiker Emil Fischer oder den Physiker Max Planck vergeben. Als erste der königlich preußischen Versuchsanstalten entstand 1871 die Mechanisch-Technische Versuchsanstalt. Die Urania-Gesellschaft, eine neuartige Bildungseinrichtung, wurde 1888 gegründet.

Ein Beispiel für die typische "Berliner Mischung" von Wohnen und Arbeiten in der Innenstadt sind die Hackeschen Höfe.

Außerhalb der 1860 abgerissenen Akzisemauer begann in den vom Hobrecht-Plan vorgesehenen Bereichen (heute: Kreuzberg, Prenzlauer Berg, Friedrichshain und Wedding) im sogenannten „Wilhelminischen Ring“ der Bau von Mietskasernen, um billigen Wohnraum für Arbeiter zu schaffen. Diese überbelegten Wohngebiete waren durch dichte Bebauung, lichtarme Höfe, Kellerwohnungen und mangelnde sanitäre Ausstattung geprägt, Industriebetriebe verursachten Luftverschmutzung und Lärm. Im Südwesten der Stadt entstanden ab 1850 großzügige und weit ausgedehnte Villenkolonien für das wohlhabende Bürgertum, beispielsweise in Lichterfelde, weitere Villenviertel folgten im Westen gegen Ende des 19. Jahrhunderts, zum Beispiel Grunewald oder Westend. Diese Gebiete wurden hauptsächlich durch die "Terraingesellschaften" (Immobilienunternehmen) geplant und gebaut. Eine führende Rolle bei dieser privat finanzierten Stadtplanung hatte der Unternehmer Johann Anton Wilhelm von Carstenn. Entlang der damals neuen Kaiserstraße, die Lichterfelde mit Charlottenburg verband, entstanden zunächst als Gartenvororte Friedenau und Wilmersdorf (siehe: Carstenn-Figur), die sich später zu dichter bebauten bürgerlichen Wohnvierteln entwickelten. Die Gesellschaft von Salomon und Georg Haberland baute das Viertel um den Viktoria-Luise-Platz, das Bayerische Viertel und das Rheinische Viertel um den Rüdesheimer Platz. Mit dem Reichsgenossenschaftsgesetz von 1889 wurde die Gründung von Wohnungsbaugenossenschaften möglich. In den folgenden Jahren wurden eine Reihe gemeinnütziger Wohnanlagen, zum Beispiel nach Entwürfen von Paul Mebes oder Alfred Messel errichtet. Ab der Jahrhundertwende entstanden vor der Stadt einige Gartenstädte, wie die Baugenossenschaft „Freie Scholle“ in Tegel, die Waldsiedlung Hakenfelde, die Gartenstadt Staaken oder die Gartenstadt Falkenberg.

Ab 1888 traf sich der Friedrichshagener Dichterkreis. Zu einem der Zentren der Lebensreform wurde Berlin mit der Neuen Gemeinschaft. Die reformerischen Ideen fanden ihren Ausdruck in der Anlage neuer Grünräume wie dem Schillerpark. Im Stil der neuen Gartenstädte wurde der Vorort Frohnau geschaffen. Zu den Reformbestrebungen dieser Zeit gehörten die Wandervogel-Bewegung, die 1896 in Steglitz gegründet wurde, mehrere Einküchenhäuser entstanden und die Berliner Arbeitergärten wurden angelegt.

Zwischen 1904 und 1908 beschäftigte sich die 51-teilige Buchreihe "Großstadt-Dokumente" ausführlich mit Berlin. Eines der Hauptthemen des aufwendigsten Stadtforschungsprojektes im deutschsprachigen Raum dieser Zeit war der Vergleich des häufig als „moderne Retortenstadt“ betrachteten Berlins mit dem als traditions- und kulturreicher geltenden Wien.

In seiner 1910 veröffentlichten Schrift "Berlin – ein Stadtschicksal" schrieb Karl Scheffler, Berlin sei „"dazu verdammt: immerfort zu werden und niemals zu sein."“

Otto Lilienthal führte seine Versuchsflüge durch, und in Johannisthal eröffnete 1909 der erste Motorflugplatz Deutschlands. Nach sechsjähriger Bauzeit wurde 1906 der Teltowkanal für den Schiffsverkehr freigegeben. Die Berliner Gewerbeausstellung fand 1896 in Treptow statt. Der "Lunapark" in Halensee zählte zu den größten Vergnügungsparks Europas. Auf dem Tempelhofer Feld fanden die Spiele von neu gegründeten Fußballvereinen statt, die sich Anfang der 1890er Jahre in ersten Verbänden organisierten, wie dem Bund Deutscher Fußballspieler oder dem Deutschen Fußball- und Cricket Bund. Seit 1911 fanden im Sportpalast die Sechstagerennen statt.

Der „Wettbewerb Groß-Berlin“ von 1910 prägte die weitere Entwicklung der Stadt im 20. Jahrhundert maßgeblich. Zur Koordinierung infrastruktureller Maßnahmen im rasant wachsenden Berliner Raum bildete sich 1911 der Zweckverband Groß-Berlin, aus dem 1920 der Zusammenschluss zu Groß-Berlin hervorging; bleibende Leistung des Verbandes ist der Abschluss des Dauerwaldvertrags.

Der Erste Weltkrieg führte zu Hunger in Berlin. Im Winter 1916/1917 waren 150.000 Menschen auf Hungerhilfe angewiesen, und Streiks brachen aus. Als 1918 der Krieg endete, dankte Wilhelm II. ab. Der Sozialdemokrat Philipp Scheidemann und der Kommunist Karl Liebknecht riefen beide nach der Novemberrevolution die Republik aus. In den nächsten Monaten fanden in Berlin zahlreiche Straßenkämpfe zwischen den unterschiedlichen Fraktionen statt.

In den ersten Jahren der Weimarer Republik war Berlin Schauplatz gewaltsamer innenpolitischer Auseinandersetzungen. Zur Jahreswende 1918/1919 wurde die Kommunistische Partei Deutschlands (KPD) in Berlin gegründet. Im Januar 1919 versuchte sie im Spartakusaufstand, die Macht an sich zu reißen. Die Revolte scheiterte, und am 15. Januar 1919 töteten rechtsgerichtete Truppen Rosa Luxemburg und Karl Liebknecht. Im März 1919 kam es in Berlin zu einem politischen Generalstreik, der das gesamte Wirtschaftsleben und den Verkehr lahmlegte. Rund eine Million Beteiligte forderten eine Verankerung der Räte in der zu dieser Zeit verhandelten Weimarer Reichsverfassung sowie weitere Reformen. Am 13. Januar 1920, während die Nationalversammlung im Reichstagsgebäude über das Betriebsrätegesetz verhandelte, fand vor dem Haus eine Demonstration gegen den Gesetzesvorschlag statt. Dazu hatten die linken Oppositionsparteien USPD und KPD aufgerufen, die dann aber die Demonstration der rund 100.000 Menschen dem Selbstlauf überließen. Als die Menge das Gebäude zu stürmen drohte, eröffnete die Polizei das Feuer und tötete mindestens zwanzig Menschen, über 100 wurden verletzt. Damit handelte es sich um die blutigste Demonstration der deutschen Geschichte. Im März 1920 versuchte Wolfgang Kapp an der Spitze von Freikorpsformationen im "Kapp-Putsch" die sozialdemokratische Regierung zu stürzen und eine Militärherrschaft zu errichten. Die Berliner Reichswehrtruppen sympathisierten mit den Putschisten, verhielten sich jedoch weitgehend "neutral". Während die Regierung Berlin verlassen hatte, brach der Putsch infolge eines reichsweiten Generalstreiks nach fünf Tagen zusammen.

Am 1. Oktober 1920 wurde Groß-Berlin durch das "Gesetz über die Bildung einer neuen Stadtgemeinde" gegründet. Dabei wurde Berlin mit sieben weiteren Städten, nämlich Charlottenburg, Köpenick, Lichtenberg, Neukölln, Schöneberg, Spandau und Wilmersdorf, 59 Landgemeinden und 27 Gutsbezirken zu einer Gemeinde unter dem Namen "Berlin" verschmolzen. Groß-Berlin hatte damals 3.804.048 Einwohner. Berlin wurde damit hinter New York, London, Tokio und Paris zur fünftgrößten Stadt der Welt und zur größten Industriestadt Europas. Neuer Oberbürgermeister wurde Gustav Böß, der das Amt bis 1929 ausübte. Seit der Wahl zur Berliner Stadtverordnetenversammlung von 1919 galt das Frauenwahlrecht, das Wahlalter wurde von 25 auf 20 Jahre herabgesetzt und das Dreiklassenwahlrecht abgeschafft.

Im Jahr 1922 wurde Außenminister Walther Rathenau in Berlin ermordet. Die Stadt war schockiert: eine halbe Million Menschen kamen zu seiner Beerdigung.

Die ersten Jahre der jungen Republik waren von wirtschaftlichen Problemen geprägt. Die Arbeitslosigkeit war hoch. Die Geldentwertung verschärfte sich und erreichte im Herbst 1923 ihren Höhepunkt (Deutsche Inflation 1914 bis 1923). Das Geldvermögen von großen Teilen des Mittelstandes und der Rentner wurde vernichtet. Deutschland hatte durch den Friedensvertrag von Versailles hohe Reparationen zu zahlen. Ab 1924 besserte sich die Situation durch neue Vereinbarungen mit den Alliierten, amerikanische Hilfe (Dawes-Plan) und eine bessere Finanzpolitik. Die Hochzeit Berlins, die „Goldenen Zwanziger Jahre“ begannen. Personen wie der Architekt Walter Gropius, der Physiker Albert Einstein, der Maler George Grosz, Schriftsteller wie Arnold Zweig, Bertolt Brecht und Kurt Tucholsky, die Schauspielerin Marlene Dietrich und Regisseure wie Friedrich Wilhelm Murnau, Fritz Lang und Max Reinhardt machten Berlin zum kulturellen Zentrum Europas. Das Nachtleben dieser Zeit hat seinen bekanntesten Niederschlag in dem Film "Cabaret" gefunden, nach der Vorlage des Buches "Goodbye To Berlin" von Christopher Isherwood.

Die Gegend zwischen Lützowplatz und Potsdamer Platz war Wohnort für viele Künstler, und Kunsthändler wie Alfred Flechtheim hatten hier ihre Galerien. Zum bevorzugten Treffpunkt für Künstler wurde das "Romanische Café" am Kurfürstendamm. Ein kulturelles Zentrum im Berliner Westen war das Viertel um den Prager Platz, wo viele Künstler, Schauspieler und Schriftsteller lebten.

Im Jahr 1924 eröffnete der Flughafen Tempelhof. Im gleichen Jahr fand auch die erste Funkausstellung auf dem Messegelände statt, die erste "Grüne Woche" folgte 1926. Berlin war der zweitgrößte Binnenhafen des Landes (siehe: Westhafen). Die ab 1924 nach und nach elektrifizierten Berliner Stadt-, Ring- und Vorortbahnen wurden 1930 unter dem Namen "S-Bahn" zusammengefasst. Diese Infrastruktur wurde zur Versorgung der über vier Millionen Berliner benötigt. Mit der Ausstrahlung der ersten Unterhaltungssendung begann 1923 im Vox-Haus die Geschichte des deutschen Rundfunks. 1926 wurde zum Auftakt der dritten Funkausstellung der Funkturm eingeweiht. Das von Hans Poelzig entworfene Haus des Rundfunks, wurde 1931 eingeweiht. Die autobahnähnliche Renn- und Versuchsstrecke AVUS wurde 1921 eröffnet. Zwischen 1930 und 1933 führte der "Verein für Raumschiffahrt", zu dem auch der spätere Ingenieur Wernher von Braun gehörte, auf dem Raketenflugplatz Berlin in Tegel erste Versuche mit Flüssigkeitsraketen durch.

Grüne Stadträume schuf Erwin Barth mit der Neugestaltung des Klausenerplatzes oder den neuen Anlagen von Lietzenseepark, Volkspark Jungfernheide und Volkspark Rehberge. Um die dicht bebaute Innenstadt entstand ein grüner Parkring. Das neue Strandbad Wannsee wurde 1930 eingeweiht und das Poststadion gebaut. Zur Linderung der Wohnungsnot begann unter dem Stadtbaurat Martin Wagner nach Einführung der Hauszinssteuer der Bau von Großsiedlungen durch gemeinnützige Wohnungsunternehmen, wie beispielsweise die Hufeisensiedlung und Onkel Toms Hütte oder Wohnanlagen wie der Sonnenhof. Durch dieses Wohnungsbauprogramm entstanden 140.000 neue Wohnungen in Berlin. Der Alexanderplatz wurde ab Ende der 1920er Jahre umgestaltet, das Berolina- und das Alexanderhaus nach Plänen von Peter Behrens entstanden. Den U-Bahnhof unter dem Platz entwarf Alfred Grenander. Bekannte Architekten für die neuartigen Gewerkschaftshäuser waren Max Taut und Erich Mendelsohn.

Die kurze Zeit des Aufschwungs endete im Jahr 1929 mit der Weltwirtschaftskrise. Im November dieses Jahres gewann die NSDAP ihre ersten Sitze in der Stadtverordnetenversammlung (5,8 % der Stimmen, 13 Mandate). Die NSDAP schnitt bei Wahlen in Berlin bis 1933 allerdings signifikant schlechter ab als im Reichsdurchschnitt. Wählerhochburgen der Partei waren die Stadtbezirke mit eher bürgerlicher Wohnbevölkerung, in den ausgesprochenen Arbeiterbezirken erzielte sie dagegen bis zuletzt weit unterdurchschnittliche Ergebnisse. Bei der Reichstagswahl im Juli 1932 erhielt die NSDAP in Steglitz 42,1 % und in Zehlendorf 36,3 %, im Wedding aber nur 19,3 % und in Friedrichshain 21,6 % der Stimmen. Am 20. Juli 1932 wurde die preußische Regierung unter Otto Braun in Berlin durch einen Staatsstreich der rechtskonservativen Reichsregierung, den sogenannten „Preußenschlag“, abgesetzt. Am 30. Januar 1933 wurde Hitler, der seit 1931 im Hotel Kaiserhof logierte, zum Reichskanzler ernannt. Schon in der Nacht zum 31. Januar gab es mehrere Tote und Verletzte, als SA-Leute in die als KPD-Hochburg geltende Wallstraße (heute: Zillestraße) in Charlottenburg eindrangen und um sich schossen (das Ereignis steht im Mittelpunkt des Romans "Unsere Straße" von Jan Petersen).

In den Jahren der Weimarer Republik war das bei der politischen Rechten verhasste „rote Berlin“ eine Wähler- und Mitgliederhochburg von KPD (bei der Reichstagswahl im November 1932 mit 860.837 Stimmen stärkste Partei im Stadtgebiet) und SPD gewesen. Bis 1933 waren alle Versuche des 1926 ernannten NSDAP-Gauleiters Joseph Goebbels, die strukturelle Dominanz der Linksparteien zu brechen, erfolglos geblieben. Das gelang erst durch die im Anschluss an den Reichstagsbrand ausgelöste Terrorwelle, die im Juni 1933 mit der „Köpenicker Blutwoche“ einen lokalen Höhepunkt erreichte. Der seit 1931 amtierende Oberbürgermeister Heinrich Sahm trieb 1933 zusammen mit Julius Lippert, dem zum Staatskommissar ernannten NSDAP-Fraktionschef in der Stadtverordnetenversammlung, die „Säuberung“ der städtischen Körperschaften und Behörden voran und trat noch 1933 in die NSDAP ein. Geschätzt wird, dass in Berlin bis Ende 1933 rund 30.000 Menschen aus politischen Gründen inhaftiert, viele in den über 100 SA-Lokalen und „wilden“ Konzentrationslagern misshandelt, nicht wenige auch getötet wurden. Trotz der massiven Repressivmaßnahmen soll die illegale Berliner Parteiorganisation der KPD aber noch Ende 1934 rund 5.000 aktive Mitglieder gehabt haben. Die Stadt blieb bis 1945 ein Zentrum des – in seiner politischen Reichweite freilich sehr limitierten – organisierten Widerstands gegen die NS-Diktatur.

Die bereits vor der „Machtergreifung“ 1933 an die Stadt vergebenen Olympischen Sommerspiele fanden 1936 in Berlin statt und wurden von der NS-Propaganda für ihre Zwecke instrumentalisiert. Um in der internationalen Öffentlichkeit die Selbstinszenierung als normaler Staat nicht zu gefährden, wurde die sonst offen sichtbare Judenfeindlichkeit und Diskriminierung der jüdischen Bevölkerung reduziert. So entfernte man zum Beispiel die Schilder mit der Aufschrift „Für Juden verboten“. Im Rahmen der 700-Jahr-Feiern Berlins folgten dann 1937 weitere NS-Propagandaveranstaltungen.

In diese Zeit fallen auch die Planungen der Nationalsozialisten, Berlin zur „Welthauptstadt Germania“ auszubauen. Die Pläne des „Generalbauinspektors“ Albert Speer sahen gigantische Zentralachsen in Berlin vor, an denen Monumentalbauten stehen sollten. Geplant wurde für eine Einwohnerzahl von acht bis zehn Millionen Menschen, die Stadtgrenze sollte bis zum neuen Autobahnring erweitert werden. Während die meisten Projekte nicht verwirklicht wurden, sind in Berlin noch heute Reste dieser Architektur zu finden.

Der amerikanische Schriftsteller Ernest Hemingway weilte in den 1930er Jahren mehrfach in Berlin und veröffentlichte im Februar 1939 in der Zeitschrift "Das Wort" folgende bemerkenswerte Einschätzung: 

Um 1933 lebten etwa 160.000 Juden in Berlin: ein Drittel aller deutschen Juden, vier Prozent der Bevölkerung der Stadt. Ein Drittel davon waren arme Immigranten aus Osteuropa, die hauptsächlich im Scheunenviertel nahe dem Alexanderplatz lebten. Die Juden wurden von Anfang an vom NS-Regime verfolgt. Im März mussten alle jüdischen Ärzte das Krankenhaus Charité verlassen. In der ersten Aprilwoche inszenierten die Nazimachthaber den sogenannten „Judenboykott“, bei dem die übrige Bevölkerung vom Einkaufen in jüdischen Läden abgehalten werden sollte.

Vom 9. bis 10. November 1938 brannten infolge des reichsweit organisierten Pogroms gegen die Juden die Synagogen. Jüdische Geschäfte und Wohnungen wurden demoliert, viele als Juden denunzierte Deutsche wurden „zu ihrem Schutz“ verhaftet. Die Zwangsauswanderung in Verbindung mit Arisierungen (versteckter Form von Enteignung) wurde erneut vorangetrieben. Um 1939 lebten noch rund 75.000 Juden in Berlin.

Am 18. Oktober 1941 ging vom Bahnhof Grunewald der erste von insgesamt 63 Transporten mit Juden ins damalige Litzmannstadt ab. Der Holocaust begann. 50.000 Juden wurden in die Konzentrationslager verschleppt, wo die meisten ermordet wurden.

Von historischer Bedeutung über Berlin hinaus ist in diesem Zusammenhang auch die 1942 im Ortsteil Wannsee abgehaltene Wannseekonferenz, auf der unter Leitung des Chefs des Reichssicherheitshauptamts Reinhard Heydrich die von den Nazis „Endlösung“ genannte Judenverfolgung zwischen den staatlichen Stellen koordiniert wurde. Nur rund 1.200 Juden überlebten in Berlin die Kriegsphase, indem sie sich – auch mit Hilfe von Judenrettern – versteckten oder untertauchten.

Rund 30 Kilometer nordwestlich von Berlin befand sich bei Oranienburg das Konzentrationslager Sachsenhausen, wo hauptsächlich politische Gegner und sowjetische Kriegsgefangene inhaftiert waren. Zehntausende starben dort. Das KZ Sachsenhausen hatte Nebenlager in der Nähe von Industriebetrieben, in denen die Gefangenen arbeiten mussten. Viele dieser Lager befanden sich in Berlin. Experten des Holocaust Memorial Museum ermittelten für Berlin insgesamt rund 3000 NS-Lager und als „Judenhäuser“ bezeichnete Wohnhäuser zur Vorbereitung von Deportationen.

Am 1. September 1939 begann der Zweite Weltkrieg, von dem Berlin anfangs wenig betroffen war. Erste alliierte Luftangriffe auf das Stadtgebiet führte bereits Ende August 1940 das britische RAF Bomber Command durch. Da sich Berlin an der Grenze der Reichweite der damals noch in der Mehrzahl eingesetzten zweimotorigen Flugzeuge (u. a. Whitley und Hampden) befand, konnten diese nur wenig Bombenlast tragen und die Schäden waren daher noch gering. Auch die mehrmals stattfindenden Angriffe der sowjetischen Luftstreitkräfte verursachten nur geringe Zerstörungen. Durch den verstärkten Einsatz von schweren viermotorigen Halifax- und Lancaster-Bomber bei der RAF wurden die Schäden erheblich größer.

Mit dem offiziellen Eintritt der Vereinigten Staaten in den Zweiten Weltkrieg nach der Kriegserklärung Deutschlands an die USA wurde im Laufe des Jahres 1942 in Großbritannien die 8. Luftflotte der USAAF stationiert. Während die Briten nachts die Städte ansteuerten, flogen die USAAF tagsüber, sodass quasi rund um die Uhr mit Fliegeralarm zu rechnen war. In den letzten drei Monaten vor Kriegsende flogen die USAAF am 3. und 26. Februar sowie am 18. März 1945 die drei schwersten Angriffe auf Berlin, an denen teils über 1200 Maschinen beteiligt waren. Bei den insgesamt gezählten 363 Luftangriffen kamen schätzungsweise 20.000 Berliner ums Leben und mehr als 1,5 Millionen Menschen wurden obdachlos. Während Teile der Innenstadt komplett zerstört wurden, erlitten die Außenbezirke nur geringere Beschädigungen. Im Schnitt waren ein Fünftel (50 Prozent in der Innenstadt) der Berliner Gebäude zerstört.

Zerstörung von Berliner Gebäuden im Zweiten Weltkrieg:

Auch die Verkehrsinfrastruktur war größtenteils zerstört; die Versorgungslage war bis nach dem Ende des Krieges katastrophal. Insgesamt fielen 450.000 Tonnen Bomben auf Berlin.

Nach dem Beginn der Schlacht um Berlin eroberten sowjetische und polnische Verbände ab dem 21. April 1945 die ersten Vororte der Reichshauptstadt. Am 30. April 1945 nahm sich Hitler im Führerbunker hinter der Neuen Reichskanzlei das Leben. Am Morgen des 2. Mai kapitulierte der letzte Berliner Kampfkommandant Weidling und das Regierungsviertel rund um die Wilhelmstraße wurde von der Roten Armee besetzt. Trotzdem unternahmen dort und an anderen Stellen eingekesselte Einheiten von Wehrmacht, Waffen-SS und Hitlerjugend noch verzweifelte Ausbruchsversuche, gaben diese aber in den Abendstunden auf. In den nächsten Wochen übte der sowjetische Generaloberst Bersarin als Stadtkommandant die Macht in Berlin aus.

Nach dem Kriegsende lag Berlin in Schutt und Asche: 28,5 Quadratkilometer des Stadtgebietes lagen in Trümmern, 600.000 Wohnungen waren total zerstört, 100.000 beschädigt, jedes zweite Kaufhaus war eine Ruine. Seit Kriegsbeginn 1939 hatte die Stadt über 1,5 Millionen Einwohner verloren; neben Kriegstoten, -gefangenen, ermordeten und vertriebenen NS-Opfern sind als größte Gruppe die nicht aus der luftkriegsbedingten Evakuierung zurückgekehrten Berliner zu nennen.

Der Dichter Günter Weisenborn schrieb folgende Eindrücke von 1945 auf: 

Gegenwärtig wird zunehmend Kritik an der historischen Aufarbeitung des Kriegsende-Geschehens geäußert.

Auf der Konferenz von Jalta vom 2. bis 11. Februar 1945 beschlossen die Alliierten, Deutschland in vier Besatzungszonen und Berlin in vier Sektoren aufzuteilen, von denen jeder von einem der Alliierten, Großbritannien, Frankreich, den USA und der Sowjetunion, kontrolliert wurde. Dazu zogen sich die sowjetischen Streitkräfte im Sommer 1945 aus den Westsektoren zurück, die sie nach der Schlacht um Berlin bis dahin besetzt hatten. Noch im Mai hatte die sowjetische Stadtkommandantur einen ersten Magistrat unter Arthur Werner und eine auf KPD-Mitglieder gestützte Stadtverwaltung eingesetzt. In der Zeit vom 1. bis 4. Juli 1945 trafen die amerikanischen und britischen Besatzungstruppen sowie eine Vorausabteilung des französischen Kontingents in den ihnen zugewiesenen Sektoren ein. Trotz der Sektorenaufteilung wurde Berlin weiter von einer gemeinsamen alliierten Kommandantur verwaltet. Schon bald gab es sich verschärfende politische Konflikte zwischen den Westalliierten und der Sowjetunion.

Am 20. Oktober 1946 fand die erste Wahl zur "Stadtverordnetenversammlung von Groß-Berlin" in allen vier Besatzungssektoren gemeinsam statt und endete mit einem deutlichen Sieg der SPD vor CDU und SED. Es folgten zunehmende Auseinandersetzungen in der Verwaltung und in der Stadtverordnetenversammlung. Gemäß der Einschätzung von Wolfgang Leonhard hatte sich Stalin ursprünglich mit einem vereinten Deutschland mit einem Mehrparteiensystem abgefunden, in dem er einen möglichst hohen Einfluss wahren wollte, anstatt einem kommunistischen Ostdeutschland.

Am 5. Dezember 1948 sollte eine erneute gemeinsame Wahl zur Stadtverordnetenversammlung von Groß-Berlin stattfinden, die jedoch nur in West-Berlin durchgeführt werden konnte, weil die sowjetische Besatzungsmacht sie in ihrem Sektor verboten hatten. Vielmehr hatte die SED-Fraktion am 30. November 1948 eine „Stadtverordnetenversammlung“ unter Teilnahme von hunderten angeblicher Abordnungen der Ost-Berliner Betriebe durchgeführt, auf der der rechtmäßig gewählte Magistrat für abgesetzt erklärt wurde und Friedrich Ebert (der Sohn des ehemaligen Reichspräsidenten) zum Oberbürgermeister „gewählt“ wurde.

Im Juni 1948 blockierten sowjetische Truppen nach der Einführung der D-Mark sämtliche Straßen- und Schienenverbindungen durch die sowjetische Zone Richtung West-Berlin, in der Hoffnung, wieder die wirtschaftliche Kontrolle über die gesamte Stadt zu erlangen. Der in Ost-Berlin residierende Magistrat von Groß-Berlin verteilte an alle West-Berliner Lebensmittelkarten, die jedoch zumeist nicht in Anspruch genommen wurden. Die Blockade war mehr symbolischer Art und behinderte ausschließlich den Gütertransport aus Westdeutschland. Die West-Berliner jedoch fühlten sich in Anbetracht der politischen Verhältnisse um sie herum stärker dem westdeutschen Wirtschaftsraum zugehörig und verzichteten auf den Warenverkehr mit den östlichen Stadtbezirken und dem Umland.

Die Regierung der Vereinigten Staaten reagierte, indem sie die Luftbrücke einrichtete, bei der Nahrung, Heizstoffe und andere Versorgungsgüter in die Stadt eingeflogen wurden. Die Luftbrücke blieb bis September 1949 bestehen, obwohl die Blockade am 12. Mai 1949 aufgehoben wurde. Als Teil des Projektes erweiterten Ingenieure der US-Armee den Flughafen Tempelhof. Da die Piloten gelegentlich Süßigkeiten für Kinder bei der Landung aus dem Fenster warfen, wurden die Flugzeuge von den Berlinern "Rosinenbomber" genannt. Pakete mit Süßigkeiten wurden auch über Ost-Berlin abgeworfen.

Das Ziel der Sowjetunion, West-Berlin wirtschaftlich mit seinem Umland zu verzahnen und eine dauerhafte wirtschaftliche Loslösung zu verhindern, misslang gründlich. Mehr noch: Die West-Berliner Bevölkerung fühlte sich nach der Blockade politisch und wirtschaftlich noch stärker mit Westdeutschland verbunden als jemals zuvor. Nach der wirtschaftlichen Teilung war die politische Teilung somit nicht mehr aufzuhalten.

Als am 23. Mai 1949 die Bundesrepublik Deutschland in den drei westlichen Besatzungszonen gegründet wurde, listete Artikel 23 des Grundgesetzes auch Groß-Berlin als Bundesland mit auf. Ähnlich verhielt es sich mit der am 7. Oktober 1949 gegründeten DDR. Die damalige Fassung der Verfassung der DDR beschreibt Deutschland als „unteilbare Republik“ in der es nur eine deutsche Staatsangehörigkeit gäbe und deren Hauptstadt Berlin sei. Gemeint war zweifellos das gesamte Groß-Berlin, das nach DDR-Sichtweise auf dem Gebiet der sowjetischen Besatzungszone lag und deren westliche Sektoren nur von den Westalliierten verwaltet wurden. Somit beanspruchten beide neu gegründeten Staaten das gesamte Groß-Berlin, ohne jedoch vor dem 3. Oktober 1990 jemals Verfügungsgewalt über ganz Berlin gehabt zu haben.

Im Jahr 1950 trat in West-Berlin die Verfassung von Berlin (VvB) in Kraft. Nach Art. 2 Abs. 1 VvB war Berlin ein Land der Bundesrepublik Deutschland; dieser Artikel konnte jedoch keine Wirkung entfalten, da er von den in Berlin maßgeblichen Alliierten gemäß Genehmigungsschreiben vom 29. August 1950 zurückgestellt war. Die Bindung West-Berlins an die Bundesrepublik wurde jedoch durch „Übergangsregelungen“, die in Art. 87 VvB für die Zeit der alliierten Einschränkungen getroffen wurden, weitgehend gewährleistet, insbesondere durch regelmäßige Übernahme der Bundesgesetze durch das Berliner Abgeordnetenhaus. Am 3. Dezember 1950 folgte die erste Wahl zum Abgeordnetenhaus von Berlin, das seinerseits den Senat von Berlin wählte. Erster Regierende Bürgermeister von Berlin wurde Ernst Reuter. Bis 1961 folgten ihm Walther Schreiber (CDU), Otto Suhr (SPD) und Willy Brandt (SPD).

"Vgl. Beschreibung unter Geschichte Ost-Berlins bis 1990 sowie den Hauptartikel Berliner Mauer"

Als am 13. August 1961 die ersten Steinblöcke in den frühen Morgenstunden am Potsdamer Platz gelegt wurden, standen amerikanische Truppen mit scharfer Munition bereit, schauten dem Bau der Mauer jedoch nur zu. Zwar wurden die Westalliierten durch Gewährsleute über die Planung „drastischer Maßnahmen“ zur Abriegelung von West-Berlin informiert, vom konkreten Zeitpunkt und Ausmaß der Absperrung gaben sie sich öffentlich überrascht. Da ihre Zugangsrechte nach West-Berlin nicht beschnitten wurden, griffen sie nicht militärisch ein.

US-Präsident Kennedy besuchte am 26. Juni 1963 Berlin. Vor dem Rathaus Schöneberg hielt er eine Rede über die Mauer, in der er die historischen Worte sprach: „Ich bin ein Berliner“. Dies bedeutete den West-Berlinern auf ihrer demokratischen Insel inmitten der DDR viel, war jedoch in Anbetracht der amerikanischen Akzeptanz beim Bau der Mauer teilweise Symbolik. Für die Westalliierten und die DDR bedeutete der Mauerbau eine politische und militärische Stabilisierung, der Status quo von West-Berlin wurde im wahrsten Sinne des Wortes zementiert – die Sowjetunion gab ihre im Chruschtschow-Ultimatum noch 1958 formulierte Forderung nach einer entmilitarisierten, „freien“ Stadt West-Berlin auf.

Im Jahr 1971 sicherte das Viermächteabkommen über Berlin die Erreichbarkeit West-Berlins und beendete die wirtschaftliche und politische Bedrohung, die mit einer Schließung der Zufahrtsrouten möglich gewesen wäre. Ferner bekräftigten alle vier Mächte die gemeinsame Verantwortung für ganz Berlin und stellten klar, dass West-Berlin kein Bestandteil der Bundesrepublik sei und nicht von ihr regiert werden dürfe. Während die Sowjetunion den Vier-Mächte-Status nur auf West-Berlin bezog, unterstrichen die Westalliierten 1975 in einer Note an die Vereinten Nationen ihre Auffassung vom Viermächte-Status über Gesamt-Berlin.

Der Westteil der Stadt wurde von der Bundesrepublik massiv subventioniert, auch um mit dem „Schaufenster des Westens“ propagandistische Wirkung in der DDR zu entfalten. Unternehmen erhielten massive Investitionszuschüsse. Die Berlinzulage (genannt: „Zitterprämie“), ein achtprozentiger Lohnaufschlag, sollte den fortgesetzten Arbeitskräftemangel lindern. Sowohl für Berliner Ehepaare als auch für die Zuzügler wurde ein zinsloses Familiengründungsdarlehen in Höhe von 3000 DM eingeführt, das „abgekindert“ werden konnte. Trotzdem blieb die Bevölkerungsentwicklung West-Berlins von Abwanderung und Überalterung geprägt (siehe auch hier).

Nach Willy Brandt (bis 1966) amtierten als Regierende Bürgermeister Heinrich Albertz, Klaus Schütz, Dietrich Stobbe, Hans-Jochen Vogel (alle SPD). Ab der Wahl zum Abgeordnetenhaus von Berlin 1981 regierten mit Richard von Weizsäcker und Eberhard Diepgen Politiker der CDU. Ab der Abgeordnetenhauswahl 1989 war in dem von Walter Momper (SPD) geleiteten Senat Momper erstmals die Alternative Liste an der Landesregierung beteiligt.

Ab 1967 wurde West-Berlin Zentrum der Studentenrevolten, die von der Freien Universität ausging, und die ihr Zentrum in Charlottenburg hatte. Ein weiterer Brennpunkt war die Zentrale der Springer-Verlage in der damaligen Kreuzberger Kochstraße (heute: Rudi-Dutschke-Straße). Es ging hier um einen gesellschaftlichen Konflikt, der die Bevölkerung spaltete. Studenten und Polizei standen sich oft gewalttätig gegenüber.

Die Erschießung des Studenten Benno Ohnesorg bei der Demonstration am 2. Juni 1967 in West-Berlin gegen den Besuch des Schahs von Persien durch den Polizeibeamten Karl-Heinz Kurras war ein entscheidender Anstoß für die Verbreitung der Studentenbewegung.

Ab Anfang der 1970er Jahre entwickelte sich in West-Berlin eine Terroristenszene. Neben Personen aus der Rote Armee Fraktion war in West-Berlin auch die Bewegung 2. Juni aktiv, die sich nach dem Todesdatum von Benno Ohnesorg benannt hatte. Am 10. November 1974 wurde der Kammergerichtspräsident Günter von Drenkmann ermordet und 1975, kurz vor der Wahl zum Abgeordnetenhaus von Berlin 1975, der Vorsitzende der Berliner CDU, Peter Lorenz, von Terroristen entführt.

Als Reaktion auf den Wohnungsmangel bei gleichzeitigem spekulationsbedingtem Leerstand entwickelte sich im östlichen Teil Kreuzbergs, dem alten Postbezirk SO 36, Ende der 1970er Jahre eine vergleichsweise große und aktive Hausbesetzer<nowiki>bewegung</nowiki>. Im Juli 1981 erreichte die Anzahl der besetzten Häuser in Berlin mit 165 ihren Höhepunkt. Von diesen Besetzungen wurden 78 bis zum November 1984 durch den Abschluss von Miet-, Kauf- oder Pachtverträgen legalisiert, die Restlichen wurden geräumt. Bereits im Dezember 1980 war es infolge einer versuchten Besetzung zu schweren Zusammenstößen zwischen Hausbesetzern und der Polizei gekommen. (siehe: "Schlacht am Fraenkelufer") Bei einer Demonstration gegen die Räumung von acht besetzten Häusern starb in der Potsdamer Straße der Demonstrant und Hausbesetzer Klaus-Jürgen Rattay, der infolge eines Polizeieinsatzes unter einen Bus der BVG geraten war.

Bereits im Sommer 1945 konnte am Kurfürstendamm wieder eine Kunstgalerie eröffnet werden, die Galerie Gerd Rosen, wo u. a. der Maler Werner Heldt die Bilderserie "Berlin am Meer" vorstellte.

Das Gebiet um den Kurfürstendamm im Westen wurde als neues repräsentatives Zentrum ausgebaut. Von Paul Schwebes entworfen wurde das Bauensemble "Zentrum am Zoo". Das internationale Filmfestival Berlinale fand 1951 erstmals statt. Seit 1957 war der Zoo Palast zentrales Wettbewerbskino.

Weitere bedeutende Bauprojekte waren unter anderem das Europa-Center-Berlin und der Neubau der Kaiser-Wilhelm-Gedächtniskirche am Breitscheidplatz, das neue Gebäude der Deutschen Oper, die Kongresshalle, die anlässlich der Internationalen Bauausstellung "Interbau" 1957 entstandene Mustersiedlung "Südliches Hansaviertel", das nach seinem Architekten benannte Corbusierhaus oder die Stadtautobahn. Für das geplante Kulturforum entstanden an der Potsdamer Straße die Berliner Philharmonie und die Staatsbibliothek Preußischer Kulturbesitz nach Plänen des Architekten Hans Scharoun sowie die von Ludwig Mies van der Rohe stammende Neue Nationalgalerie. Mit der Freien Universität Berlin wurde 1948 eine eigene Universität gegründet, das Studentendorf Schlachtensee errichtet und das Museumszentrum Berlin-Dahlem gebaut.

In den 1970er Jahren entstanden unter anderem der Flughafen Tegel, das ICC und der Bierpinsel am U-Bahnhof Schloßstraße im Zusammenhang mit der Verlängerung der U-Bahn Linie 9 bis Rathaus Steglitz. Zahlreiche neue U-Bahnstationen wurden von Rainer G. Rümmler gestaltet, wie am Fehrbelliner Platz bei der Verlängerung der Linie U7.

Zu politischen Krisen und Regierungswechseln führten mehrere Bauskandale („Berliner Sumpf“, „Berliner Filz“), wie die Garski-Affäre, die Affäre um den Bau des Steglitzer Kreisels und der Antes-Skandal.

Der Standortnachteil West-Berlins (Insellage) führte zu Entwicklungsrückständen in der Wirtschaftsstruktur gegenüber den westdeutschen Großstädten. Um die Defizite im hochwertigen Dienstleistungssektor auszugleichen, siedelte der Staat zentrale Verwaltungen in Berlin an, wie die 1953 eröffnete Bundesversicherungsanstalt für Angestellte, das 1956 errichtete Bundesversicherungsamt, das 1958 gegründete Bundeskartellamt, das 1952 gegründete Bundesgesundheitsamt sowie das 1974 geschaffene Umweltbundesamt. Das Bundesverwaltungsgericht nahm 1952 seine Arbeit in Berlin auf, ansässig war hier auch der 5. Strafsenat des Bundesgerichtshofes. Großforschungseinrichtungen wie das Hahn-Meitner-Institut mit dem Berliner Experimentier-Reaktor und BESSY wurden geschaffen. Das Wissenschaftszentrum Berlin für Sozialforschung wurde 1969 gegründet.

Ein wichtiger Arbeitgeber in West-Berlin waren die Einrichtungen der Alliierten.

In den alten AEG-Fabriken im Wedding nahm 1983 mit dem Berliner Innovations- und Gründerzentrum (BIG) das erste Gründerzentrum Deutschlands seine Arbeit auf.

Beispiele für frühe Wohnungsbauprojekte der Nachkriegszeit in West-Berlin sind die 1953/1954 errichtete Ernst-Reuter-Siedlung im Wedding, die Otto-Suhr-Siedlung in der Luisenstadt (ab 1956) und die Ruhwaldparksiedlung. Als Gegenstück zur Stalinallee in Ost-Berlin (s. u.) begann ab 1956 im Rahmen der Interbau (IBA 57) die Errichtung des neuen Hansaviertels (ca. 1.300 Wohnungen).

Die erste neue Großsiedlung am Stadtrand entstand ab 1960 auf dem Falkenhagener Feld in Spandau (ca. 8.000 Wohnungen). In Berlin-Buckow-Rudow wurde von 1960 bis 1975 die Gropiusstadt errichtet (rund 17.000 Wohnungen). Der Bau des Märkischen Viertels in Reinickendorf begann 1963 und endete 1974 (ca. 16.000 Wohnungen). Weitere Beispiele waren die Thermometersiedlung in Lichterfelde-Süd oder die Wohnsiedlung Charlottenburg-Nord (1968–1974).

Mit dem Beschluss des ersten "Stadterneuerungsprogramms" 1963 setzte im Westteil Berlins ein großflächiger Abriss zehntausender Wohnungen der innerstädtischen Quartiere aus dem späten 19. Jahrhundert ein („Mietskasernen“). Diese Gebiete wurden nach Vorstellungen modernen Städtebaus völlig umgestaltet und neu bebaut. Das Viertel um die Brunnenstraße im Wedding wurde zum größten zusammenhängenden Sanierungsgebiet Deutschlands mit rund 17.000 Wohnungen. Das erste Stadterneuerungsprogramm war für einen Zeitraum von 10 bis 15 Jahren angelegt. Diese Praxis des Umgangs mit der Stadt wurde zunehmend kritisiert. Eine Wende brachte das Europäische Jahr des Denkmalschutzes 1975, erstmals gelang es dem Architekten Hardt-Waltherr Hämer am Klausenerplatz in Charlottenburg einen Mietskasernenblock mit innerer Bebauung überwiegend zu erhalten. Das vormals schlechte Ansehen der Arbeiterquartiere der Gründerzeit änderte sich langsam. Josef Paul Kleihues entwarf für den Vinetaplatz im Sanierungsgebiet Wedding-Brunnenstraße den ersten Baublock West-Berlins, der wieder an die Traditionen der Stadt des 19. Jahrhunderts anknüpfte (von 1975 bis 1977 errichtet).

Mitte der 1970er Jahre hatten sich die politischen und ökonomischen Rahmenbedingungen geändert. Das Vier-Mächte-Abkommen von 1971 bestätigte die Teilung Berlins, Planungen die sich noch auf die ganze Stadt bezogen wurden aufgegeben. Die Ölkrise von 1973 leitete u. a. die langsame Abkehr von der autogerechten Stadt ein, sodass 1976 der Aufbau eines umfassenden Stadtautobahnsystems aufgegeben wurde. 1974 endete der Bau von Großsiedlungen am Stadtrand. Im selben Jahr wurde noch ein zweites Stadterneuerungsprogramm gestartet, das einen höheren Anteil modernisierter Altbauwohnungen vorsah. Beispielsweise sollten bei der Sanierung des Bereiches um den Chamissoplatz in Kreuzberg Platz, Straßen und Teile der alten Höfe erhalten bleiben. Allerdings wurden weiterhin tausende Wohnungen aus der Gründerzeit abgerissen und durch städtebauliche Großformen ersetzt, wie beispielsweise das "Neue Kreuzberger Zentrum" am Kottbusser Tor (1969–1974), die "Autobahnüberbauung Schlangenbader Straße" in Wilmersdorf (1976–1980) oder das "Pallasseum" in Schöneberg (1977). Der gesellschaftliche Protest gegen die „Kahlschlagsanierungen“ durch Hausbesetzungen erreichte zwischen 1979 und 1982 seinen Höhepunkt. Hauptkritikpunkte waren vor allem die Zerstörung sozialer Gefüge und die Vernichtung von billigem Wohnraum. Die städtebauliche Wende hin zur Wiedergewinnung der Innenstadt als Wohnort leitete 1978 der Beschluss zur Durchführung einer Internationalen Bauausstellung, der IBA 1984–1987 ein. Der „Kahlschlagpolitik“ des Neubaus und dem modernen Städtebau wurden die Leitbilder der „behutsamen Stadterneuerung“ und der „kritischen Rekonstruktion“ gegenübergestellt. 1982 entstanden die 12 Grundsätze der Stadterneuerung, die nach 1990 auch im Anwendung fanden und bis heute die Stadterneuerungsprozesse in Berlin prägen. Der Schwerpunkt der IBA lag in Kreuzberg, die „kritische Rekonstruktion“ der historischen Stadträume in der südlichen Friedrichstadt wurde nach 1990 in der nördlichen Friedrichstadt im Bezirk Mitte fortgesetzt. Die Themen der IBA waren u. a. ökologisches Bauen, Bürgerbeteiligung, neue Wohnformen, Umnutzung von Gebäuden, Mischung von Wohnen und Arbeiten oder die fußgängerfreundliche Umgestaltung von Straßen.

Zwischen 1982 und 1986 wurden in Vorbereitung auf die umfangreichen 750-Jahr-Feiern von 1987 in beiden Teilen der Stadt zahlreiche Verschönerungen vorgenommen. Beispielsweise wurden in West-Berlin der Breitscheidplatz und der Rathenauplatz neu gestaltet. Historische Gebäude sind aufwendig restauriert worden, so beispielsweise der Martin-Gropius-Bau oder der Hamburger Bahnhof. Als Ersatz für die teilungsbedingt nicht mehr erreichbaren Naherholungsgebiete im Südosten eröffnete zur Bundesgartenschau 1985 mit dem Britzer Garten die erste größere Parkanlage seit den 1920er Jahren.

Zu Pfingsten fand vom 6. bis 8. Juni 1987 an drei aufeinanderfolgenden Tagen das Concert for Berlin statt. Das Konzertgelände lag beim Reichstag nahe der Mauer und es kam auf deren Ostseite zu Zusammenstößen zwischen jugendlichen Zuhörern der DDR und Volkspolizei. Zu Ausschreitungen kam es am Ersten Mai in Kreuzberg.

Die Tour de France startete zu Ehren des Jubiläums mit einer Einzelzeitfahretappe auf dem Kurfürstendamm.

Die Jubiläumsfeier wurde durch Briefmarkenausgaben (Deutsche Bundespost Berlin), aber auch im Osten (siehe unten) gewürdigt. Im Westen erschien ein Block mit vier Marken sowie eine Einzelmarke.

Umfangreiche Aufräumarbeiten der zerstörten Innenstadtbereiche waren erforderlich. Dazu setzten Baubetriebe Trümmerbahnen ein, Frauen und Männer mussten tatkräftig mit anpacken. Der Lehrbetrieb der Humboldt-Universität wurde wieder aufgenommen, Straßenbahn-, S-Bahn- und U-Bahn-Netze und Wagen instandgesetzt. Ebenfalls kam die Wasser- und Energieversorgung vor allem durch Reparaturen des Leitungsnetzes und der vorhandenen Technik wieder in Gang. Durch die Lagerung des Trümmerschutts entstanden im Stadtbild künstliche Erhebungen wie der "Mont Klamott" im Volkspark Friedrichshain oder die "Biesdorfer Höhe".

Im Ortsteil Karlshorst des Bezirks Lichtenberg quartierte sich gleich ab Mai 1945 die sowjetische Stadtverwaltung ein, wofür Bewohner des auserkorenen Bereichs östlich der Treskowallee kurzfristig ausquartiert wurden. Das Sowjetische Ehrenmal im Treptower Park wurde angelegt.

Die Lebensmittelversorgung erfolgte mit Lebensmittelkarten, ebenfalls gab es "Kohlenkarten". Für dringende Neuanschaffungen von Kleidung wurden von den Bezirksämtern "Bezugsscheine" ausgegeben. Dort, wo bereits große Flächen freigeräumt waren, wurden mit den wiedergewonnenen Materialien neue Wohnhäuser errichtet, die bedeutendste Baustelle war die in Stalinallee umbenannte vormalige Große Frankfurter Straße.

Am 17. Juni 1953 begann eine Demonstration von anfänglich 60 Bauarbeitern, die später als Volksaufstand bekannt wurde. Am Beginn war es nur Protest über eine kürzlich von der DDR-Regierung beschlossene Arbeitsnormerhöhung. Ihren Ausgang nahm die Demonstration an der im Bau befindlichen Stalinallee (heute: Karl-Marx-Allee). Als insbesondere der RIAS von der Demonstration berichtete, solidarisierten sich viele Ost-Berliner mit dem Protestzug und reihten sich ein. Unterstützung erhielten die Ost-Berliner, die zum Potsdamer Platz zogen, auch von Berlinern aus den Westbezirken. Auch in zahlreichen Städten der DDR kam es infolge der Aufstände in Ost-Berlin zu Arbeitsniederlegungen und Demonstrationen.

Als der Aufstand außer Kontrolle zu geraten drohte, rief die Regierung der DDR sowjetische Truppen zu Hilfe. In der Folge kam es zu Straßenkämpfen, bei denen auf kaum bewaffnete Arbeiter scharf geschossen wurde. Während der Niederschlagung des Aufstandes wurden mindestens 153 Personen getötet. Die Beteiligung von West-Berliner Arbeitern, die Berichterstattung des RIAS, Angriffe auf Volkspolizisten und das Niederbrennen des Columbushauses nutzte die DDR-Regierung, um diesen Aufstand als konterrevolutionär und von West-Berlin gesteuert zu bezeichnen. Die unbeliebten Normerhöhungen wurden aber dennoch zurückgenommen und Kampfgruppen aus politisch besonders linientreuen Bürgern gegründet, um zukünftige Aufstände ohne sowjetische Soldaten niederschlagen zu können.

Am 13. August 1961 begann die ostdeutsche Regierung mit dem Bau der Berliner Mauer, die die Trennung Berlins endgültig festigte. Der Plan zum Bau der Mauer in Berlin war ein Staatsgeheimnis der DDR-Regierung. Die Mauer sollte die Emigration der ostdeutschen Bevölkerung in den Westen verhindern, da die DDR wirtschaftlich und personell auszubluten drohte (sogenannte „Abstimmung mit den Füßen“).

Ost-Berlin war politisches, kulturelles und wirtschaftliches Zentrum der DDR und Sitz mehrerer Kombinate. In Ost-Berlin wurden rund 50 Prozent des städtischen Haushalts aus der Staatskasse der DDR finanziert.

In der Nachkriegszeit wurden die Gebäude im östlichen Teil der Straße Unter den Linden überwiegend wiederaufgebaut, während das Stadtschloss gesprengt wurde. Der Tierpark in Friedrichsfelde wurde 1955 eingeweiht, der Palast der Republik 1976 eröffnet. Im Osten begann in den 1970er Jahren ein groß angelegtes Wohnungsbauprogramm, in dem ganze Stadtteile neu angelegt wurden, nachdem schon in den 1960er Jahren insbesondere am Alexanderplatz repräsentative Neubauten errichtet worden waren (Kongresshalle, Haus des Lehrers, Berliner Fernsehturm).

Ein wichtiges Infrastrukturprojekt bildete der Ausbau des Flughafens Schönefeld sowie der Bau des Berliner Außenrings.

Nach Kriegsende waren (Gesamtberliner Zahlen) von den rund 1,5 Millionen Wohnungen der Vorkriegszeit über ein Drittel zerstört und nicht mehr verfügbar. Hatte die Beseitigung der enormen Trümmermengen und die Herrichtung nur schwach beschädigter Gebäude anfangs Vorrang, konnten 1949–1950 die ersten neuen Wohnhäuser gebaut werden. Nach einem Konzept von Hans Scharoun entstanden an der Karl-Marx-Allee zwei Laubenganghäuser ergänzt um fünf benachbarte Wohnzeilen. Weitere Beispiele für ersten Wohnungsneubau der Nachkriegszeit sind das Hochhaus an der Weberwiese (1952), die Wohnblocks am Ostseeplatz sowie die Bebauung an der Kniprodestraße. Der Straßenzug des Prestigeprojektes Stalinallee wurde zwischen 1952 und 1956 fertiggestellt (ca. 2.500 Wohnungen).

Um 1955 wurde das DDR-Bauwesen nach überwiegend ökonomischen Kriterien neu ausgerichtet, der industrielle, typisierte Wohnungsbau begann. Größere Baustellen waren der Wohnkomplex Friedrichshain ab 1956, der ab 1958 (ca. 4.500 Wohnungen) oder das Wohngebiet Fennpfuhl ab 1961. In der Luisenstadt begann 1958 der Bau des Neanderviertels (ab 1966 Heinrich-Heine-Viertel) mit Q3A-Typenbauten.

Mit dem Regierungswechsel 1971 in der DDR wurde auf dem VIII. Parteitag der SED die Ausrichtung der künftigen Wirtschaftspolitik festgelegt (Einheit von Wirtschafts- und Sozialpolitik) und ein langfristiges Wohnungsbauprogramm eingeleitet. Das Politbüro des ZK der SED beschloss 1976 den Neubau von rund 200.000 Wohnungen bis 1990 in Ost-Berlin. Das Ziel sollte durch die Errichtung von Großsiedlungen am Stadtrand, Baulückenschluss in der Innenstadt und Stadterneuerungsmaßnahmen erreicht werden. Bereits 1973 war mit der Sanierung der historischen Bausubstanz am Arnimplatz begonnen worden, die auch für die West-Berliner Entwicklungen bedeutsam war. Ebenfalls im Prenzlauer Berg wurden die Häuser um den Arkonaplatz von Mitte der 1970er bis Mitte der 1980er Jahre restauriert. Diese beispielhaften Projekte führten auch in Ost-Berlin zur Anerkennung des Wertes der historischen Bausubstanz, das 1979 erlassene Abrissverbot wurde in der Praxis allerdings häufig umgangen. Diese aufwendigen Stadterneuerungsmaßnahmen blieben Einzelfälle, der Altbaubestand verfiel meistenteils weiter. Die Investitionen flossen überwiegend in die großen Neubaugebiete. Von 1975 bis 1987 wurden in Marzahn rund 62.000 Wohnungen errichtet und ein neuer Stadtbezirk gegründet. Marzahn war das größte Wohnungsbauprojekt der DDR. Ab 1979 folgte der Aufbau von Hohenschönhausen, wo bis 1989 über 40.000 Wohnungen entstanden. In Hellersdorf wurden zwischen 1981 und Ende 1989 rund 34.000 Wohnungen gebaut. In der ersten Hälfte der 1980er Jahre entstand am Stadtrand in Köpenick das Salvador-Allende-Viertel II, eine weitere Großsiedlung in Altglienicke (Treptow) war Mitte der 1980er Jahre in Planung.

Vor der 750-Jahr-Feier sollten zusätzlich 20.000 Neubauwohnungen entstehen und 10.000 Wohnungen modernisiert werden. Bekanntere Beispiele sind die Restaurierungen der Husemannstraße oder der Sophienstraße sowie von Teilen der Spandauer Vorstadt (dort wurden historisierende Plattenbauten errichtet). Der Bau des Nikolaiviertels als „neue“ Altstadt kann als Variante der „kritischen Rekonstruktion“ der historischen Stadt gesehen werden. Von 1983 bis 1986 entstand im Prenzlauer Berg das Prestigeprojekt Ernst-Thälmann-Park mit ca. 1.300 Wohnungen. Im Innenstadtbereich wurden S- und U-Bahnhöfe saniert und teils aufwendig künstlerisch ausgestaltet wie der U-Bahnhof Klosterstraße als „erfahrbares Museum“. In Vorbereitung auf die 750-Jahr-Feier begann die Rekonstruktion des Gendarmenmarkts. 1984 wurde Schinkels Schauspielhaus als Konzerthaus Berlin völlig renoviert wieder eröffnet. Ost-Berlin reagierte auf die West-Berliner BUGA von 1985 mit der Berliner Gartenschau als Gegenstück. Die Jubiläumsfeier wurde auch im Osten Berlins durch die Briefmarkenserie 750 Jahre Berlin der Deutschen Post gewürdigt.

Zentren der Oppositionsbewegung im Ostteil Berlins während der 1980er Jahre waren beispielsweise Gethsemanekirche, Samariterkirche und Zionskirche. Am 17. Januar 1988 protestierten Bürgerrechtler auf der offiziellen Liebknecht-Luxemburg-Demonstration. Im Herbst 1989 kam es zur Wende und friedlichen Revolution in der DDR. Am 4. November 1989 fand mit der Alexanderplatz-Demonstration die größte nicht staatlich gelenkte Demonstration in der Geschichte der DDR statt.

Bei den Feierlichkeiten zum 40. Jahrestag der DDR in Ost-Berlin im Oktober 1989 hielt Ehrengast Michail Gorbatschow eine Rede, in der er andeutete, dass er eine restriktive Politik der DDR-Regierung in Bezug auf die Flüchtlinge, die zu diesem Zeitpunkt über die Grenzen von Ungarn und der Tschechoslowakei flüchteten, nicht zulassen würde.

Am 9. November ließen die Grenztruppen zunächst am Übergang Bornholmer Straße, später auch an anderen Grenzübergängen nach einer missverstandenen Äußerung des Politbüromitgliedes Günter Schabowski auf einer Pressekonferenz die dort wartende Menge passieren. Viele Ost-Berliner fuhren noch in der Nacht nach West-Berlin. Am Brandenburger Tor erklommen Menschen die Mauer, es herrschte Volksfeststimmung. Die Reisefreiheit wurde nicht mehr zurückgenommen und die Mauer wurde in der Folgezeit abgerissen, wobei viele Berliner als sogenannte „Mauerspechte“ mit Hammer und Meißel Teile der Mauer als Souvenirs abschlugen.

Der Ost-Berliner Oberbürgermeister Tino Schwierzina und der West-Berliner Regierende Bürgermeister Walter Momper arbeiteten fortan in enger Absprache, um die große Menge an Aufgaben, die die bevorstehende Wiedervereinigung der Stadthälften aufwarf, in Angriff zu nehmen. Das Bürgermeistergespann wurde scherzhaft in den Medien als „Schwierzomper“ oder „Mompzina“ verballhornt, die beiden Stadtregierungen Senat (West) und Magistrat (Ost) wurden von Walter Momper bald als „Magi-Senat“ tituliert. Die Ost-Berliner Bevölkerung stand nun vor der Herausforderung, den Systemübergang und die damit verbundenen grundlegenden Veränderungen der gesellschaftlichen und wirtschaftlichen Ordnung zu bewältigen.

Der Einigungsvertrag erklärte Berlin mit der Wiedervereinigung am 3. Oktober 1990 zur Hauptstadt Deutschlands. Mit der Zustimmung zum Einigungsvertrag verzichteten die Alliierten auf ihre Kontrolle über Berlin, wodurch der umstrittene rechtliche Status Berlins geklärt und damit die Berlin-Frage gelöst war. Am 2. Dezember 1990 fanden die ersten Wahlen zum Abgeordnetenhaus des wiedervereinigten Berlins statt. Der Sitz von Bundestag und Bundesregierung blieb allerdings zunächst noch in Bonn. Erst nach einer kontroversen – auch von der Öffentlichkeit geführten – Debatte beschloss der Bundestag am 20. Juni 1991, dass die Hauptstadt Berlin auch Parlaments- und Regierungssitz sein solle (siehe: Hauptstadtbeschluss).

Eine mit dem West-Berliner Vorbild vergleichbare Hausbesetzerbewegung entwickelte sich erst im Rahmen der politischen Wende 1989 in den Ost-Berliner Stadtteilen Friedrichshain und Prenzlauer Berg. Diese war insbesondere durch das passive Verhalten der Ost-Berliner Volkspolizei begünstigt. Dies änderte sich allerdings nachdem im Juli 1990 der Ost-Berliner Magistrat unter den Einfluss des Senats von West-Berlin geraten war. In der Folge kam es zu den schweren Straßenschlachten bei der Räumung der Mainzer Straße. Viele der Besetzungen wurden ähnlich wie bei der ersten Besetzungswelle legalisiert. Die letzten besetzen Häuser, die im Rahmen der „Berliner Linie“ toleriert worden waren, ließ der Berliner Innensenator Jörg Schönbohm zwischen 1996 und 1998 räumen.

Nach dem Mauerfall stand Berlin vor der Herausforderung die beiden eigenständigen Teilstädte wieder zu einer Gesamtstadt zusammenzuführen und den wirtschaftlichen Strukturwandel zu bewältigen. Ein Drittel aller Erwerbstätigen in Ost-Berlin waren im Staatssektor beschäftigt, in West-Berlin arbeiteten ein Viertel aller Erwerbstätigen im öffentlichen Dienst, während dagegen die Dienstleistungen des Wirtschaftssektors nur schwach entwickelt waren. Berlin war 1990 gemessen an der Zahl der Beschäftigten die größte Industriestadt Deutschlands. In Ost-Berlin hatte die Industriebeschäftigung einen Anteil von 25 %. Die krisenhafte Deindustrialisierung der Region in den folgenden Jahren und der Abbau der Staatsbeschäftigung führte zu einem drastischen Anstieg der Arbeitslosigkeit. Der Dienstleistungssektor entwickelte sich langsamer als erhofft, der Aufbau neuer High-Tech-Industrien, wie in Adlershof, konnte nur mit langfristiger Perspektive begonnen werden. Anfänglich optimistische Annahmen über das Wachstum Berlins sowie steuerliche Anreize für Immobilieninvestitionen befeuerten einen Bauboom bei Bürogebäuden und im Wohnungsbau. Mitte der 1990er Jahre wurden jährlich 20.000 Wohnungen fertiggestellt. Der Senat plante in einem neuen Wohnungsbauprogramm mehrere Großprojekte am Stadtrand, wie Karow-Nord, Französisch-Buchholz, Altglienicke, Rudower Felder, Staaken. Für den Bezirk Hellersdorf wurde mit der „Hellen Mitte“ ein neues Stadtteilzentrum errichtet. Weitere wichtige Bauvorhaben waren die Entwicklungsgebiete Altes Schlachthofgelände, die Wasserstädte Rummelsburger Bucht und Oberhavel sowie Biesdorf-Süd. Die Infrastruktur Ost-Berlins musste zu großen Teilen erneuert und mit West-Berlin zusammengefügt werden. Die Züge der S-Bahn können seit 2002 wieder auf der geschlossenen Ringbahn fahren. Der Schienenverkehr wurde nach dem Pilzkonzept neu geordnet, und im Jahr 2006 wurde der neue Hauptbahnhof eröffnet. Als Bewerberstadt für die Olympischen Spiele im Jahr 2000 hat Berlin als Vorleistung die Sportstätten Velodrom und Max-Schmeling-Halle neu errichtet.

Aufgegebene Flächen von ehemaligen Bahnanlagen, Flugplätzen, Schlachthöfen, Rieselfeldern, Industrieanlagen sowie der Bereich der Berliner Mauer ermöglichten die Anlage neuer Freiräume, wie dem Mauerpark, dem Natur-Park Südgelände, dem Landschaftspark Johannisthal/Adlershof, dem Landschaftspark Wartenberger Feldmark, dem Park auf dem Nordbahnhof oder dem Park am Gleisdreieck.

Im Zuge der Wiedervereinigung wurde im Einigungsvertrag der Grundsatz „Rückgabe vor Entschädigung“ festgelegt, was zu einer Neuaufteilung des Grund und Bodens in der Berliner Mitte führte. Haupteigentümer waren die Treuhandanstalt und die Oberfinanzdirektion Berlin aber nur zu geringen Teilen die Stadt Berlin selbst.
Die wichtigen Entscheidungen zur weiteren Entwicklung der Innenstadt wurden in geheimen Sitzungen zwischen Februar 1991 und September 1993 vom "Koordinierungsausschuß für innerstädtische Investitionen" (KOAI) getroffen. Nach den Vorstellungen der Politik sollte Berlin zu einer „Global City“ aufsteigen und die Konzernzentralen der Global Player in der Stadt angesiedelt werden. Ein Leuchtturmprojekt in dieser Hinsicht war der Potsdamer Platz, die damals größte Baustelle Deutschlands. Auf Initiative von Stadtentwicklungssenator Volker Hassemer wurde ab 1991 das Stadtforum durchgeführt. Bausenator Wolfgang Nagel berief 1991 Hans Stimmann zum Senatsbaudirektor. Um die Neubebauung der Berliner Innenstadt entzündete sich der „Berliner Architekturstreit“. Zahlreiche städtebauliche Maßnahmen, wie der Wiederaufbau des Pariser Platzes oder die Schaffung des neuen Parlaments- und Regierungsviertels, wurden begonnen. Im Sommer 1995 wurde das Reichstagsgebäude verhüllt.

Als erstes Verfassungsorgan verlegte zum 1. Januar 1994 der damalige Bundespräsident Richard von Weizsäcker seinen Dienstsitz nach Berlin. Am 7. September 1999 nahm der Bundestag und am 29. September 2000 der Bundesrat ihre Arbeiten in Berlin auf.

Die Fusion der Bundesländer Berlin und Brandenburg scheiterte 1996 in einer Volksabstimmung am Veto der brandenburgischen Wähler.

Mitte der 1990er Jahre begann ein Jahrzehnt der Stagnation geprägt durch Bevölkerungsverluste mit Abwanderung ins Umland und Rückgang der Wirtschaftsleistung.

Die Loveparade entwickelte sich während der 1990er Jahre zu einer Massenveranstaltung der Technokultur.

Der Entfall der meisten staatlichen Subventionen infolge der Deutschen Teilung und seit 1997 zusätzlich der Berliner Bankenskandal brachten das Land Berlin in enorme finanzielle und fiskalische Schwierigkeiten, die dessen Handlungsfähigkeit einschränken. Der Bankenskandal führte 2001 zu einem Misstrauensvotum gegen den Regierenden Bürgermeister Eberhard Diepgen. Nachfolger Klaus Wowereit regierte Berlin anschließend über 13 Jahre lang in unterschiedlichen Koalitionen.

Eine Phase drastischer Kürzungen bei den öffentlichen Ausgaben wurde unter der Parole "" eingeleitet. Kommunales Eigentum wurde privatisiert, so die städtischen Wohnungsunternehmen GEHAG seit 1998 und GSW 2004 mit ihrem Bestand an mehreren zehntausend Wohnungen. Die Mehrheitsanteile am Energieversorger Bewag wurden 1997 verkauft, wie auch 1999 die Hälfte der Anteile an den Berliner Wasserbetrieben, wogegen 2011 ein erfolgreicher Volksentscheid durchgeführt wurde.

Berlin klagte 2003 beim Bundesverfassungsgericht wegen einer „extremen Haushaltsnotlage“, um eine Bundesergänzungszuweisung von 35 Milliarden Euro zum Schuldenabbau zu erhalten. Diese Klage wurde 2006 zurückgewiesen. Die defizitäre Lage Berlins (Zitat Klaus Wowereit: ) konnte durch Wachstum der Wirtschaft, besonders des Tourismus, und der Bevölkerung in der Folgezeit abgemildert werden; seit 2013 macht Berlin keine neuen Schulden mehr.

Seit der Abgeordnetenhauswahl 2016 regiert eine rot-rot-grüne Koalition aus SPD, Linken und Grünen, die von Michael Müller geführt wird.

Am 19. Dezember 2016 ereignete sich der Anschlag auf den Berliner Weihnachtsmarkt an der Gedächtniskirche.


Gesamtgeschichte

Stadtgründung

Mittelalter

19. Jahrhundert

20. Jahrhundert
Periodika



</doc>
<doc id="1977" url="https://de.wikipedia.org/wiki?curid=1977" title="Großer Lauschangriff">
Großer Lauschangriff

Als Großer Lauschangriff werden in Deutschland, Österreich und der Schweiz umgangssprachlich akustische und optische Überwachungsmaßnahmen der Strafverfolgungsbehörden und Nachrichtendienste bezeichnet.

Die Grundlagen für den „Großen Lauschangriff“ wurden am 16. Januar 1998 vom Bundestag und am 6. März 1998 vom Bundesrat durch Einfügung der Absätze 3 bis 6 des Grundgesetz (GG), wodurch die sogenannte "akustische Wohnraumüberwachung" zu Zwecken der Strafverfolgung ermöglicht wurde (Abs. 3), gelegt.
Die Ausführungsbestimmungen zu dem Gesetz mussten nach einer Entscheidung des Bundesverfassungsgerichts am 3. März 2004 geändert werden. Zwar erklärte das Gericht die Grundgesetzänderung für grundsätzlich verfassungskonform, die Ausführungsbestimmungen wurden jedoch als verfassungswidrig eingestuft. Mit dem „Gesetz zur Umsetzung des Urteils des Bundesverfassungsgerichts zur akustischen Wohnraumüberwachung“, das der Bundestag am 12. Mai 2005 mit den Stimmen der SPD und der Grünen verabschiedete, erhielt der Große Lauschangriff seine bis heute gültige Form.

Die Gesetzesänderung war in Politik und Öffentlichkeit sehr umstritten. Eine von Journalisten initiierte Kampagne gegen die geplante Überwachung ihrer Berufsgruppe führte zu einem plötzlichen Umschwung in der Medienberichterstattung, sodass kurz vor Verabschiedung des Gesetzes diese Berufsgruppe einfach gesetzlich wieder in den Kreis der vom „Großen Lauschangriff“ ausgenommenen Gruppen aufgenommen wurde.

Vor allem Juristen ging der Eingriff in das Grundrecht auf Unverletzlichkeit der Wohnung zu weit. Von Kritikern wurde die Befürchtung geäußert, die Grundgesetzänderung sei der Beginn der Einrichtung eines Überwachungsstaates. 

Schon vor 1998 hatte die Bundesregierung versucht, den „Großen Lauschangriff“ einzuführen. Meist scheiterte dies an der damaligen Bundesjustizministerin Sabine Leutheusser-Schnarrenberger (FDP). 1995 führte die FDP dazu eine Urabstimmung durch, bei der sich eine Mehrheit von 63,6 % für den „Großen Lauschangriff“ aussprach. Als Reaktion darauf trat Sabine Leutheusser-Schnarrenberger von ihrem Amt als Bundesministerin zurück.

Im Rahmen des „Großen Lauschangriffs“ sind Polizei und Staatsanwaltschaft befugt, auch Wohnungen zu überwachen. Dies ist jedoch nur möglich, wenn zuvor auf Antrag der Staatsanwaltschaft diese Überwachung durch die Staatsschutzkammer, in Fällen des Vorliegens von Gefahr im Verzug auch durch den Vorsitzenden der Staatsschutzkammer, angeordnet wird ( i. V. m. Abs. 2 StPO).

Vom „Großen Lauschangriff“ ist der „Kleine Lauschangriff“ zu unterscheiden. Der „Kleine Lauschangriff“ bezieht sich nur auf Gespräche außerhalb von Wohnungen, also an öffentlichen Örtlichkeiten sowie auch in allgemein zugänglichen Büro- und Geschäftsräumen ( StPO). Wohnungen in diesem Sinne sind die Bereiche, die der Berechtigte der allgemeinen Zugänglichkeit entzogen und zur Stätte seines Lebens und Wirkens gemacht hat.

Der Begriff „Lauschangriff“ taucht erstmals 1968 in der von Erika Fuchs übersetzten Donald-Duck-Geschichte „Irrungen und Wirrungen mit einem Werwolf“ (DD 117) auf. Er verbreitete sich nicht etwa über Kritiker solcher Maßnahmen, sondern über das nachrichtendienstliche und ministerielle Umfeld, als diese Maßnahme in den 70er Jahren erstmals genutzt wurde. (→ Lauschaffäre Traube). Gleichwohl kann gleichbedeutend der Terminus „akustische Wohnraumüberwachung“ verwendet werden.

Die Gesetzesänderung ermöglicht den Einsatz der akustischen Wohnraumüberwachung für den Bereich der Strafverfolgung; außerdem wurde die bereits in der alten Fassung des GG enthaltene Möglichkeit der Wohnraumüberwachung zu Zwecken der Gefahrenabwehr modifiziert (Absätze 4 bis 6). Die einfachgesetzlichen Umsetzung erfolgte durch das "Gesetz zur Verbesserung der Bekämpfung der Organisierten Kriminalität", durch das die maßgeblichen §§ 100c, 100d, 101f sowie 101 StPO eingefügt bzw. geändert wurden.

Die Voraussetzungen der akustischen Wohnraumüberwachung sind in Abs. 1 StPO geregelt. Zusätzliche Voraussetzungen gelten nach Abs. 3 der Vorschrift, wenn die Überwachung in Räumen Dritter durchgeführt werden soll.

Nach der Rechtsprechung des Bundesverfassungsgerichts muss die Überwachung in Situationen unterbleiben, in denen Anhaltspunkte bestehen, dass die Menschenwürde ( GG) durch die Maßnahme verletzt wird. Demzufolge bestimmt Abs. 2 StPO, dass Äußerungen, die dem Kernbereich privater Lebensgestaltung zuzurechnen sind, nicht erfasst werden dürfen. Im Rahmen einer sogenannten „negativen Kernbereichsprognose“ ist dies vor Anordnung der Maßnahme schon vom zuständigen Gericht zu prüfen. Führt dennoch die Überwachung unerwartet zur Erhebung von absolut geschützten Informationen, muss sie abgebrochen werden und die Aufzeichnungen sind unverzüglich zu löschen ( Abs. 4 StPO). Erkenntnisse über solche Äußerungen dürfen nicht verwendet werden ( Abs. 2 StPO). Das Risiko, solche Daten zu erfassen, besteht typischerweise beim Abhören von Gesprächen mit engsten Familienangehörigen, sonstigen engsten Vertrauten und Personen, zu denen ein besonderes Vertrauensverhältnis besteht. Bei diesem Personenkreis dürfen laut Bundesverfassungsgericht Überwachungsmaßnahmen nur ergriffen werden, wenn konkrete Anhaltspunkte dafür bestehen, dass die Gesprächsinhalte zwischen dem Beschuldigten und diesen Personen keinen absoluten Schutz erfordern, so bei einer Tatbeteiligung der das Gespräch führenden Personen. 

Ein im Juli 2004 vom Bundesjustizministerium vorgelegter Referentenentwurf zur Änderung des Gesetzes sah vor, dass diese Ausnahmeregelungen auf Strafverteidiger und Rechtsanwälte beschränkt werden sollten. Daneben sollte der „Große Lauschangriff“, den Maßgaben des Bundesverfassungsgerichts folgend, nur noch bei schweren Straftaten wie Mord und Totschlag Anwendung finden. 

Gegen diesen Entwurf wurde von Interessenvertretern der vom Schutzentzug bedrohten Berufsgruppen, von nahezu allen deutschen Datenschutzbeauftragten, von Teilen der Presse und von den Grünen massive Kritik geäußert, da der Entwurf wesentliche Aspekte des Urteils des Bundesverfassungsgerichts (s. weiter unten) ignorierte oder gar ins Gegenteil verkehrte. Bundesjustizministerin Brigitte Zypries zog den Entwurf daraufhin bereits nach wenigen Tagen wieder zurück.

Im Mai 2005 verabschiedeten SPD und Grüne im Bundestag schließlich das „Gesetz zur Umsetzung des Urteils des Bundesverfassungsgerichts zur akustischen Wohnraumüberwachung“. Das Gesetz enthält kein absolutes Überwachungsverbot für Gespräche im privaten Bereich, sondern statuiert vielmehr eine allgemeine Eingriffsbefugnis und nennt die Bedingungen, wann abgehört werden darf. Nicht übernommen wurde das in der Entscheidung des Bundesverfassungsgerichts vom 3. März 2004 (siehe weiter unten) aufgestellte Erfordernis, dass die Verwendung einer Aufnahme einer gerichtlichen Überprüfung bedarf.

Am 3. März 2004 entschied das Bundesverfassungsgericht auf die Verfassungsbeschwerde unter anderem von Sabine Leutheusser-Schnarrenberger, Gerhart Baum und Burkhard Hirsch hin, dass große Teile des "Gesetzes zur Bekämpfung der organisierten Kriminalität" gegen die Menschenwürde verstoßen und deshalb verfassungswidrig sind. 
Während die Änderung von GG durch das Gericht nicht beanstandet wurde, erklärten die Richter zahlreiche Ausführungsbestimmungen der Strafprozessordnung für nicht verfassungskonform. Insbesondere dürfe die Überwachung nur noch bei dem Verdacht auf besonders schwere Straftaten angeordnet werden. Von der besonderen Schwere einer Straftat im Sinne des Abs. 3 GG ist nur auszugehen, wenn sie der Gesetzgeber mit einer höheren Höchststrafe als fünf Jahre Freiheitsstrafe bewehrt hat. 

Gespräche zwischen engen Angehörigen dürfen nur abgehört werden, wenn alle Beteiligten verdächtig sind und das Gespräch strafrechtlich relevanten Inhalt hat. Sind diese Voraussetzungen nicht erfüllt, sind entsprechende Aufzeichnungen nicht nur als Beweismittel wertlos, sondern dürfen gar nicht erst vorgenommen werden. Durch diese Norm wird die bisherige Praxis automatisierter Mitschnitte als nicht verfassungsgemäß verworfen. Um Verfassungsmäßigkeit im Vollzug der Überwachung herzustellen, muss nunmehr die Überwachung aktiv durch einen Beamten verfolgt werden, der erforderlichenfalls die Überwachung abbricht, sobald die vom Gericht genannten Voraussetzungen nicht mehr vorliegen.

Die Beibehaltung des geänderten GG impliziert, dass der Große Lauschangriff als äußerstes Mittel der Strafverfolgung als verfassungskonform anzusehen ist. Konsequenterweise billigt das Gericht, entgegen der ursprünglichen Intention des GG, dem Bürger keinen vor staatlichem Zugriff geschützten Raum zu. Stattdessen begrenzt das Urteil das Zugriffsrecht des Staates auf die Privatsphäre auf solche Situationen, aus denen für die Gemeinschaft erhebliche Gefahren erwachsen können. Die absolute Norm der geschützten Privatsphäre wird somit durch einen relativierenden Schutz persönlicher Gesprächsinhalte ersetzt. Diese sind jedoch auch nur dann geschützt, wenn sie keinen (nach Meinung der Polizei) „strafrechtlich relevanten Inhalt“ haben. Der Schutz der innersten Privatsphäre wird damit letztendlich ins Ermessen der Polizei verlegt.

Das Urteil musste bis zum 30. Juni 2005 in einem neuen Gesetz umgesetzt worden sein. Solange der Gesetzgeber nicht gehandelt hat, muss die Polizei das Urteil des Bundesverfassungsgerichts umsetzen.

Zur Urteilsbegründung heißt es:
„Zur Unantastbarkeit der Menschenwürde gehört die Anerkennung eines absolut geschützten Kernbereichs privater Lebensgestaltung. Jede Erhebung von Informationen aus diesem Bereich muss abgebrochen werden. Jede Verwertung ist ausgeschlossen. (Urteil zum Großen Lauschangriff vom 3. März 2004)“

Den Richterinnen Renate Jaeger und Christine Hohmann-Dennhardt ging das Urteil nicht weit genug. Über die entsprechenden Regelungen der Strafprozessordnung hinaus sei auch die Grundgesetzänderung verfassungswidrig, heißt es in ihrem abweichenden Votum vom 3. März 2004. Sie berufen sich dabei auf die sogenannte „Ewigkeitsklausel“ des Grundgesetzes, wonach Änderungen an den Verfassungsgrundsätzen der und GG mit dem Ziel von deren Einschränkung grundsätzlich unzulässig sind. Insbesondere wurde an der Grundgesetzänderung kritisiert, dass sie zwar eine Reihe von materiell- und verfahrensrechtlichen Hürden gegen das Belauschen von Privatwohnungen aufstellt, jedoch keine, die das Belauschen von „Gesprächssituationen höchstpersönlicher Art“ zwingend verböte. Die Mehrheit der Richter begegnete diesem Einwand mit dem Argument, im Wege einer verfassungskonformen Auslegung – insbesondere unter Beachtung des Abs. 1 GG und des Grundsatzes der Verhältnismäßigkeit – erlaube GG nur solche einfachgesetzlichen Regelungen und darauf gestützte Maßnahmen, die Abs. 3 GG i. V. m. Abs. 1 GG unangetastet ließen. Die Funktion des eigentlich sachlich einschlägigen Schrankengebäudes des Abs. 3 GG wird dadurch freilich implizit in Frage gestellt.

Daneben argumentieren die Richterinnen, dass angesichts der inzwischen technisch möglichen Totalüberwachung dem in GG formulierten Schutz der Privatsphäre ein viel größerer Stellenwert beizumessen sei, als es sich die Väter des Grundgesetzes einst überhaupt haben vorstellen können.

In der Presse wurde die Entscheidung überwiegend als eine seit Langem überfällige Rückbesinnung auf die Kernelemente des Rechtsstaats begrüßt. Nach einer langen Reihe immer weiter gehender Aushöhlungen des Rechtsstaates durch die Politik unter dem Vorwand der Verbrechensbekämpfung sei durch die Richter deutlich gemacht worden, dass es definitive Grenzen der Relativierung der Grundrechte durch Strafgesetze gebe. Die erheblichen Erschwernisse, die das Gericht dem Vollzug der Überwachung auferlegt, werden als eine De-facto-Aushebelung des Großen Lauschangriffs betrachtet.

Die Würdigung der tatsächlichen Durchführung des Großen Lauschangriffs liefert Gegnern wie Befürwortern der Regelung gleichermaßen Argumente: Die Tatsache, dass in fünf Jahren 119 Überwachungsmaßnahmen durchgeführt wurden, wird von den Befürwortern der Regelung als Beweis dafür angesehen, dass von einer flächendeckenden Bespitzelung keine Rede sein könne; umgekehrt argumentieren die Kritiker, die relativ niedrige Zahl der Überwachungen zeige, dass der Nutzen der Regelung weit geringer sei als von den Befürwortern behauptet und von ihrer grundrechtlichen Fragwürdigkeit bei Weitem überwogen werde.

Im Vorfeld der Entscheidung des Bundesverfassungsgerichts waren im Lager der Unionsparteien bereits Überlegungen angestellt worden, die akustische Wohnraumüberwachung durch eine optische Wohnraumüberwachung („Spähangriff“) zu ergänzen. Dazu stehen für das BSI, das BKA und den Verfassungsschutz zur Erprobung Terahertz/Millimeterwellensysteme von Thyssen Krupp bereit. Zu Evaluationszwecken wurden nach dem Ground-Range-Radar-Prinzip Entfernungen bis zu 850 km realisiert. Diese Technologie wird zurzeit per Klage verboten, dennoch ist der BMI nicht bereit, auf einen Einsatz zu verzichten. Nach übereinstimmender Meinung der Presse wird diesen Überlegungen nach Bekanntgabe der Entscheidung zum "Großen Lauschangriff" keine Chance auf Umsetzung mehr eingeräumt.

Aus dieser weitgehenden Übereinstimmung über den Geist des Richterspruchs erklärt sich das große öffentliche Echo, auf das die Vorlage des Referentenentwurfs im Juli 2004 stieß: Zahlreiche der im Entwurf vorgesehenen Änderungen waren dem Geist des Richterspruchs diametral entgegengesetzt und verschärfen die vom Gericht kritisierten Punkte sogar noch. Allgemein herrscht in der Presse die Einschätzung, dass auf dem Entwurf zwar „Zypries draufstehe“, aber „Schily drin“ sei, wobei auch gerne auf die Zeit verwiesen wird, die Brigitte Zypries als Staatssekretärin Otto Schilys im Bundesinnenministerium verbracht hat.


2005 ordneten Gerichte in sieben Verfahren eine akustische Wohnraumüberwachung an, 2006 in drei Fällen, 2007 in zehn Fällen und 2008 in sieben Fällen. Vor 2005 lag die Zahl bei rund 30 Genehmigungen pro Jahr. Den Rückgang hat größtenteils das oben erwähnte Urteil des Bundesverfassungsgerichts zur Eingrenzung des Großen Lauschangriffs verursacht.

In Österreich steht Lauschangriff für die „optische und akustische Überwachung von Personen unter Verwendung technischer Mittel“. Diese neue Form der Beweisgewinnung ist in Österreich seit 1997 in StPO geregelt. Überwacht werden nichtöffentliches Verhalten bzw. Äußerungen von Personen in Form von Bild- und Tonübertragung und -aufzeichnung. Im Normalfall muss die Ratskammer (ein aus drei Richtern bestehender Senat) zustimmen. Kontrolliert und geprüft wird die Anordnung und Durchführung des Lauschangriffes durch die unabhängigen Rechtsschutzbeauftragten. Anfangs wurde der Lauschangriff nur unter Probe eingeführt, da es erhebliche Bedenken gegen Eingriffe in die Privatsphäre gab. Doch mittlerweile ist diese Form der Überwachung zur Verbrechensbekämpfung bei allen großen politischen Parteien in Österreich unumstritten.

Erstmals angewandt wurde er im Mai 1999 im Zuge der „Operation Spring“. Lauschangriffe werden in Österreich in der Regel von der Sondereinheit für Observation durchgeführt. Der Große Lauschangriff gewann wieder an Aufmerksamkeit im Wiener Neustädter Tierschützerprozess, bei dem das Schicksal 13 unschuldiger Tierrechtler verhandelt wurde. Im Ermittlungsverfahren kam der Große Lauschangriff zum Einsatz ohne das Vorliegen einer Straftat und ist somit sehr umstritten.




</doc>
<doc id="1978" url="https://de.wikipedia.org/wiki?curid=1978" title="Gur-Sprachen">
Gur-Sprachen

Die Gur-Sprachen oder voltaischen Sprachen bilden eine Untereinheit des Nord-Volta-Kongo-Zweigs der Niger-Kongo-Sprachen. 

Die etwa 75 Gur-Sprachen werden in einem zusammenhängenden Territorium, das vom Südosten Malis über die nördliche Elfenbeinküste, Ghana, Togo und Benin bis nach Burkina Faso und Nigeria reicht, von insgesamt etwa 15 Millionen Menschen gesprochen.

Der Name „Gur“ wurde 1895 von Gottlob Krause vorgeschlagen, da einige Sprachen dieser Gruppe die erste Silbe "Gur-" aufweisen (z.B. Gurma, Gurunsi, Gurenne). Die Bezeichnung „Voltaisch“ nimmt Bezug auf den Volta-Fluss, sie wird vor allem in der französischen Fachliteratur verwendet ("langues voltaïques").

Die mit Abstand bedeutendste Gur-Sprache ist das Mòoré, die Sprache der Mossi (mit 7 Mio. Sprechern einschließlich der Zweitsprecher). Sie ist die Hauptverkehrssprache von Burkina Faso und wird auch in Mali, Togo, Benin und der Elfenbeinküste gesprochen. Andere bedeutende Gur-Sprachen mit mindestens 500.000 Sprechern sind Dagaari, Frafra, Dagbani, Kusaal, Gurma, Konkomba, Tem (Verkehrssprache in Togo), Kabiyé, Lobiri und Bariba. Die größeren Sprachen sind in der folgenden Klassifikation aufgeführt.

Die genetische Einheit der Kerngruppe „Zentral-Gur“ ist seit langem unbestritten, die Zugehörigkeit einzelner Sprachen außerhalb dieses Kerns nach wie vor ungeklärt. Früher wurden auch das Dogon und die Senufo-Sprachen zu den Gur-Sprache gerechnet (z.B. Bendor-Samuel 1971, De Wolf 1981), Dogon wird heute eher als isolierter Primärzweig des Niger-Kongo, Senufo als ein Parallelzweig des Gur innerhalb des Nord-Volta-Kongo angesehen. Die genetische Nähe der Gur-Sprachen zu den Kwa - und Benue-Kongo-Sprachen gab den Anlass, innerhalb des Niger-Kongo die Einheit Volta-Kongo einzuführen.

"Klassifikation der Gur-Sprachen (nach Manesssy 1975)"


Folgende kleinere Einzelsprachen werden mit Vorbehalt auch dem Gur zugerechnet: Teen-Loma, Tiefo, Tusia, Viemo, Wara-Natioro.

Fast alle Gur-Sprachen haben ein Nominalklassensystem, die meisten zeigen Konkordanz. Durchschnittlich gibt es 11 Nominalklassen, die durch Suffixe markiert werden, einige Sprachen (z.B. Tem) besitzen noch Klassenpräfixe bei häufig vorkommenden Substantiven. Die Wortstellung im Satz ist SVO, in der Regel werden Postpositionen verwendet, nur „mit“ ist in vielen Gur-Sprachen eine Präposition. Genitivattribute und Possessivpronomina stehen vor dem Nomen, das sie näher bestimmen, Adjektivattribute, Demonstrativa und Numerale folgen ihrem Nomen, wobei nicht immer Konkordanz herrscht. Einige Adjektive haben unabhängige Klassenpräfixe für Singular und Plural, die nicht in Konkordanz mit dem Nomen stehen. Die meisten Gur-Sprachen sind Tonsprachen mit zwei bis drei Tonhöhen, das Bariba besitzt sogar 6 differenzierte bedeutungsrelevante Tonvarianten. Ein Beispiel für eine Gur-Sprache ohne bedeutungsunterscheidende Tonhöhen ist Koromfe.




</doc>
<doc id="1979" url="https://de.wikipedia.org/wiki?curid=1979" title="Gelber Zwerg">
Gelber Zwerg

Ein Gelber Zwerg oder auch Hauptreihenstern der Spektralklasse G ist ein Stern der Spektralklasse G und der Leuchtkraftklasse V. Ein Beispiel für einen gelben Zwerg stellt die Sonne dar.
Die gelben Zwerge befinden sich ungefähr in der Mitte des Hertzsprung-Russell-Diagramms. Der Name Gelber Zwerg leitet sich ab von der relativ geringen Größe dieser Sterne (im Vergleich z. B. zu Roten Riesen) und der gelblichen Farbe.

Gelbe Zwerge weisen mit Massen von 0,8 bis 1,1 Sonnenmassen Oberflächentemperaturen von etwa 5300 K bis 6000 K auf. Die meisten der Gelben Zwergsterne gehören der Sternpopulation I an.
In jeder Sekunde fusioniert die Sonne ungefähr 600 Mio. Tonnen Wasserstoff zu Helium, wobei in etwa 4 Mio. Tonnen Materie in Energie umgewandelt werden.

Der revidierte Yerkes Atlas (Johnson & Morgan 1953) listet 11 gelbe Zwergsterne als Standard, wobei im Laufe der Zeit einige auf der Liste entfernt wurden.
Die Anker des MK-Systems bilden folgende Sterne:
Andere fügen dieser Liste "HD 115043 (G1V)" und "16 Cygni B (G3V)" hinzu. Die Wahl von G4V, G6V, G7V und G9V Standardsternen ist weniger eindeutig.

Ein gelber Zwerg verweilt während seiner Existenz ca. 10 Mrd. Jahre in der Hauptreihe. Es wird angenommen, dass sich alle Gelben Zwerge im weiteren Verlauf ihrer Existenz zu einem Roten Riesen entwickeln, wobei es nicht zu einer Supernova kommt. Schließlich kollabiert der Rote Riese zu einem Weißen Zwerg.



</doc>
<doc id="1980" url="https://de.wikipedia.org/wiki?curid=1980" title="Gemini-Programm">
Gemini-Programm

Das Gemini-Programm war nach dem Mercury-Programm das zweite bemannte Raumfahrtprogramm der Vereinigten Staaten. Ziel des Gemini-Programms war das Entwickeln von Verfahrensweisen und Technologien für das Apollo-Programm. In seinem Rahmen fanden 1965 und 1966 zehn bemannte Raumflüge statt, bei denen Astronauten unter anderem die ersten amerikanischen Weltraumausstiege durchführten.

Gemini wurde aus der Not geboren, wobei es der NASA möglich war, hieraus eine Tugend zu machen. Nach Einstellung der Mercury-Flüge würde, das war relativ früh klar, eine zeitliche Lücke von drei oder gar vier Jahren bis zum Beginn der Apollo-Missionen klaffen – wertvolle Jahre, die man dringend benötigte, um die erforderlichen Technologien, z. B. Kopplungsmechanismen, Lebenserhaltungssystem, EVA-Anzüge etc., zu erproben. Aus diesem Grund war ursprünglich geplant, das bestehende Mercury-System zu einem zwei Mann fassenden Raumschiff, genannt Mercury Mark II, zu erweitern. Der Vorteil hätte darin gelegen, durch Rückgriff auf vorhandene Technik Entwicklungskosten zu sparen und die Zeit bis zum Beginn des bemannten Apollo-Flugprogramms sinnvoll überbrücken zu können. Die wesentlichen Veränderungen hätten im Einbau eines zweiten Sitzes, der Montage einer leistungsfähigen Manövriereinheit und dem Einsatz einer bereits existierenden Oberstufe als Docking-Attrappe bestanden. Zur Vereinfachung der Handhabung plante man außerdem eine modularisierte Inneneinrichtung, die einen Austausch oder das Hinzufügen von Komponenten vereinfacht und Mercury Mark II zu einer leistungsfähigen Plattform für bemannte Raumflüge gemacht hätte.

"Gemini" steht im Lateinischen für das Sternbild Zwillinge, womit der Name auf das zweisitzige Raumschiff und die Rendezvous-Manöver Bezug nimmt. Außerdem sind die mythologischen Zwillinge Castor und Pollux die Götter der Reisenden. Offiziell erhielt das Programm seinen Namen am 3. Januar 1962, nachdem im Dezember 1961 um Vorschläge gebeten worden war. Der Name "Gemini" wurde von zwei Personen vorgeschlagen.

Zur Unterstützung der bereits ausgebildeten Mercury-Astronauten entschloss sich die NASA am 18. April 1962, fünf bis zehn neue Astronauten zu rekrutieren, worauf 253 Bewerbungen eingingen.

Am 17. September 1962 wurde die Gruppe 2, bestehend aus neun Astronauten, der Öffentlichkeit vorgestellt. Dies waren Neil Armstrong, Frank Borman, Charles Conrad, James Lovell, James McDivitt, Elliott See, Thomas Stafford, Edward White und John Young.

Die Auswahl der dritten Astronautengruppe begann am 5. Juni 1963 mit einer weiteren Ausschreibung. Die NASA stellte die 14 erfolgreichen Bewerber am 18. Oktober 1963 vor: Edwin Aldrin, William Anders, Charles Bassett, Alan Bean, Eugene Cernan, Roger Chaffee, Michael Collins, Walter Cunningham, Donn Eisele, Theodore Freeman, Richard Gordon, Russell L. Schweickart, David Scott und Clifton Williams.

Damit stieg die Zahl der aktiven Astronauten für die Programme Gemini und Apollo auf 27, da die Mercury-Astronauten Glenn, Carpenter und Slayton aus verschiedenen Gründen für das Gemini-Programm nicht zur Verfügung standen.

Theodore Freeman starb am 31. Oktober 1964 bei einem Flugzeugunglück. Elliot See und Charles Bassett, die als Besatzung für Gemini 9 vorgesehen waren, kamen am 28. Februar 1966 ebenfalls bei einem Flugzeugabsturz ums Leben. Virgil Grissom, Edward White und Roger Chaffee starben am 27. Januar 1967 bei der Apollo-1-Katastrophe, Clifton Williams verunglückte am 5. Oktober 1967.

Mit der Landung von Gemini 12 am 15. November 1966 und der offiziellen Schließung des Gemini-Büros am 1. Februar 1967 endete das Gemini-Programm.

Die Landekapsel des Gemini-Raumschiffs war 5,8 Meter lang und hatte einen Durchmesser von drei Metern. Die Luken konnten während des Aufenthalts im Weltraum geöffnet und geschlossen werden, so dass Aktivitäten außerhalb des Raumschiffs möglich waren. Ein spezielles Kopplungsmodul war für die Andockmanöver vorgesehen. Die Masse der Landekapsel betrug ca. 3.800 kg. Erstmals wurde bei einem Raumschiff eine Polymerelektrolytbrennstoffzelle als primäre Energieversorgung eingesetzt. Nicht wiederaufladbare Batterien waren nur für den Wiedereintritt und für Notfälle vorgesehen. Erstmals wurde auch ein Bordcomputer, der Gemini Digital Computer, zur Unterstützung der Besatzung bei Berechnungen eingesetzt. Der Computer aus 5 Platinen mit 510 Modulen hatte einen Speicher von nur 4096 Befehlsworten von jeweils 39 Bit Länge. Da sich dieser als zu klein erwies, wurde er ab Gemini 8 durch ein Magnetbandlaufwerk ergänzt, welches die Speicherkapazität versiebenfachte.

Wie die Mercury-Redstone- und Mercury-Atlas-Raketen vor ihnen wurden auch die Gemini-Titan-Raketen von der NASA über die United States Air Force geordert und waren eigentlich Raketen, die für militärische Einsätze gedacht waren. Die Air Force war für den Startkomplex 19 auf der Cape Canaveral Air Force Station verantwortlich und bereitete alle Gemini-Starts vor und führte sie aus. Daher trugen die erste und zweite Stufe auch Seriennummern der US-Air Force. Sie waren auf jeweils gegenüberliegenden Seiten am unteren Ende der Stufe angebracht. Da die Raketen im Jahr 1962 bestellt worden waren, sollte eine Seriennummer eigentlich der Vorlage "62-12XXX" folgen. Auf den Stufen der Titan II war aber nur "12XXX" vermerkt.


siehe Gemini-Raumanzug und Astronaut Maneuvering Unit

Nach dem Mercury-Programm, welches nach den ersten Erfolgen der Sowjetunion die prinzipielle Möglichkeit bemannter Weltraumflüge ebenfalls demonstrierte, wurde mit Gemini ein großer Fortschritt erzielt, auch um die für einen erfolgreichen Mondflug nötigen Manöver zu testen: Rendezvous und Kopplung von Raumschiffen, Außenbordeinsätze, Bahnänderungen, sowie die Zusammenarbeit der Bodenstation mit den Piloten. Konzepte, die die NASA allesamt vorher im Weltall so noch nicht erprobt hatte.

Gemini war somit ein überaus erfolgreiches Programm, welches auch bewies, dass es möglich war, schwere Havarien wie im Fall von Gemini 8 zu beherrschen. Es wurde ein Grundstein für die Apollo-Mondmissionen gelegt. Im Jahr 1967 gab es dann aber zu Beginn des Apollo-Programms mit dem Verlust dreier Menschenleben bei Apollo 1 einen schweren Rückschlag. Eine ähnlich schwere Katastrophe ereignete sich im selben Jahr beim sowjetischen Sojus-Programm mit Sojus 1.

Die Erfahrungen aus dem Gemini-Programm haben aber letztendlich maßgeblich zur ersten erfolgreichen bemannten Mondlandung von Apollo 11 beigetragen.








</doc>
<doc id="1981" url="https://de.wikipedia.org/wiki?curid=1981" title="Gewürzvanille">
Gewürzvanille

Die Gewürzvanille – Aussprache: []; schweizerisch und süddeutsch [] – ("Vanilla planifolia") oder Echte Vanille ist eine Orchideenpflanze. Der Name stammt über das französische "vanille" vom spanischen "vainilla" (‚kleine Hülse oder Schote‘, zu lat. "vagina"). Gewürzvanille wird im Handel unter den Herkunftsbezeichnungen Bourbon-Vanille (von den Inseln Madagaskar und Reunion [ehemals Bourbon]), mexikanische Vanille und Vanille aus Tahiti angeboten (vergleiche Tahiti-Vanille). Die Pflanze besitzt grün-gelbliche Blüten und bringt Samenkapseln hervor, aus denen das Gewürz Vanille hergestellt wird.

Die Gewürzvanille ist eine immergrüne Kletterpflanze, der spärlich verzweigte Spross erreicht Längen von 10–15 m. Die dunkelgrüne Sprossachse ist im Querschnitt rund und meist etwa 1, seltener bis 2 cm dick. Die Länge der Internodien ist recht variabel und beträgt 4–10 cm, gelegentlich mehr. Die nicht oder nur sehr kurz gestielten Blätter sind länglich oder länglich-oval geformt, an der Basis abgerundet, am Ende spitz oder mit lang ausgezogener Spitze. Die Blattlänge beträgt 8–25 cm, die Breite 2–8 cm. Jedem Blatt gegenüber entspringt eine Luftwurzel, die zuerst im Querschnitt rund ist, sich bei Kontakt jedoch flach und fest an eine Unterlage heften kann. Die Luftwurzel verfügen - wie bei vielen anderen epiphytischen Orchideen - über ein Velamen radicum, mit dem sie Wasser und darin gelöste Nährstoffe aufnehmen, speichern und in tiefer gelegen Schichten weiterleiten können.

Der Blütenstand entspringt den Blattachseln im oberen Bereich der Pflanze, sehr selten sitzt er endständig am Trieb. Die Blütenstandsachse ist im Querschnitt leicht kantig und misst 0,4–1 cm im Durchmesser. Sie wird 5–8 cm lang, ist leicht gebogen und trägt 6–15, gelegentlich auch 20–30 Blüten. Jede Blüte steht in der Achsel eines kleinen länglichen bis ovalen Tragblattes. Die Tragblätter werden 0,5–1,5 cm lang und 0,7 cm breit. Die duftenden, gelblich-grünen Blüten sind von wachsartigem Aussehen. Innerhalb eines Blütenstandes blühen sie nacheinander auf, wobei eine einzelne Blüte nur etwa acht Stunden geöffnet ist, bevor sie verwelkt. Der Fruchtknoten ist etwas gebogen, 4–7 cm lang bei 0,3 bis 0,5 cm Durchmesser; im Querschnitt ist er fast rund. Die äußeren Blütenblätter (Sepalen) weisen auch bei geöffneter Blüte nach vorne, sie sind länglich bis leicht spatelförmig, die Enden sind stumpf und nach außen gebogen, die Länge beträgt 4–7 cm bei 1–1,5 cm Breite. Die seitlichen Petalen gleichen den Sepalen, sie sind etwas kleiner und nicht so dick. Auf ihrer Außenseite zeichnet sich die Mittelrippe als erhabener Kiel ab. Die Lippe wird 4–5 cm lang und 1,5–3 cm breit. Besonders im vorderen Bereich ist sie dunkler und klarer gelb als die übrigen Blütenblätter. An der Basis ist sie für ein Stück mit der Säule verwachsen, auch weiter vorn sind die Seiten der Lippe nach oben geschlagen und umhüllen die Säule, die Spitze ist ausgebreitet oder nach unten umgeschlagen. Der vordere Rand der Lippe ist leicht gewellt. Längs der Lippe laufen mehrere Reihen warziger Papillen, die in der Mitte am längsten sind. Ob es sich diese Papillen ein Futtergewebe darstellen oder nur zur Verstärkung der Schauwirkung dienen, ist bisher unklar. Mittig auf der Lippe sitzt ein nach hinten gerichtetes Haarbüschel. Die Säule wird 3–5 cm lang, nach vorne leicht keulenförmig verdickt, auf der Unterseite behaart. Die Kapselfrucht (umgangssprachlich „Vanilleschote“ genannt) wird 10–25 cm lang bei 0,8–1,5 cm Durchmesser, sie ist nicht gebogen. Bei der Reife springt sie entlang zweier Schlitze auf und setzt zahlreiche glänzende, dunkelbraune bis schwarze Samen frei.

Die Chromosomenzahl beträgt 2n = 25, 26, 28 oder 30-32. 

Die Frucht der Gewürzvanille ist nur bei ständigem Umgang schwach giftig, wirkt aber hautreizend und allergen.

Hauptwirkstoffe:
1,5–3 % Vanillin (Bourbonvanille 3,2–3,7 %), Vanillinsäure, Vanillylalkohol, Protocatechualdehyd, Protocatechusäure. Das Vanillearoma beruht neben dem Vanillingehalt auf dem Vorkommen zahlreicher Begleitstoffe.

Pharmakologische Wirkung:
Bei Arbeitern, die mit dem Sortieren und Verpacken von Vanille beschäftigt sind, treten Hautausschläge, Kopfschmerzen und Schlaflosigkeit auf. Allergische und irritative Kontaktdermatiden sind im Englischen unter der Bezeichnung „vanillism“ bekannt. Sie treten in der Regel berufsbedingt, d. h. bei jenen Personen auf, die Vanillefrüchte zu ernten und zu verpacken haben. 

Der Genuss von vanillehaltigen Speisen (auch Vanille-Eis) führt bei Allergikern gelegentlich zu urtikariellen Erscheinungen und Gesichtsschwellungen. Die für die Vanille-Allergie verantwortlichen Kontaktallergene sind bis heute unbekannt. Allem Anschein nach sind weder Vanillin noch von diesem abgeleitete oder mit diesem nah verwandte Verbindungen wie zum Beispiel Vanillylalkohol, Ethylvanillin, Zimtsäure, Isoeugenol die Ursache.

Ursprung der Gewürzvanille ist Mexiko und Mittelamerika. Vor allem wegen des aromatischen Inhaltsstoffes Vanillin in den nach der Fermentation schwarzen Kapseln war sie schon bei den Ureinwohnern Mexikos, den Azteken, unter dem nahuatl-aztekischen Namen "tlilxochitl" (= schwarze Blume) als Gewürz bekannt. Die spanischen Eroberer brachten die Vanille nach Europa. Da sie nur in Mexiko wuchs, hatten die Spanier lange Zeit das Monopol auf Vanille. Heute wird sie in tropischen Gebieten rund um die Erde angebaut, wobei vor allem Madagaskar und Réunion als wichtigste Anbauregionen zu nennen sind.

Der kommerzielle Anbau der Vanille erfolgt fast ausschließlich zur Gewinnung des Gewürzes Vanille.
Versuche, die Vanille außerhalb Mexikos anzupflanzen und zu züchten, scheiterten lange Zeit, da sie nur durch ganz bestimmte, ausschließlich in Mexiko und Zentralamerika vorkommende, Bienen- und Kolibriarten bestäubt werden kann. In anderen Ländern, wo diese natürlichen Pollenüberträger nicht vorkommen, muss der Mensch deren Funktion übernehmen. In Plantagen wird immer händisch bestäubt, da hierdurch der prozentuale Anteil an den entstehenden Vanilleschoten erhöht werden kann.

Erst 1837 gelang es dem belgischen Botaniker Charles Morren, den Fortpflanzungsmechanismus der Vanille aufzuklären und eine künstliche Bestäubung in einem Gewächshaus durchzuführen. Fast zur gleichen Zeit, im Jahr 1841, glückte dem Plantagensklaven Edmond Albius ebenfalls eine künstliche Bestäubung, als Lohn soll er später seine Freiheit zurückerhalten haben. Bei der arbeitsaufwändigen künstlichen Bestäubung mit z. B. einem Stachel pflanzlicher Herkunft (Kaktus, Organenbaum, Bambus, etc.) schafft ein geübter Plantagenarbeiter am Tag etwa 1000 bis 1500 Blüten.

Die Insel Madagaskar liefert 80 % des weltweiten Bedarfs. Bis zu 2000 Tonnen Schoten der Gewürzvanille werden hier pro Jahr geerntet. Die Ernte und die Verarbeitung sind aufwendig. Die Früchte müssen blanchiert werden, wochenlang in der Sonne trocknen und anschließend in Kisten ausreifen, bevor sie ihr charakteristisches Aroma bekommen. 

Die Bourbon-Vanille hat ihren Namen vom langjährigen Hauptlieferanten von Vanille, der Insel Réunion im Indischen Ozean, die bis zur Französischen Revolution und danach wieder von 1810 bis zur Februarrevolution 1848 "Île Bourbon" hieß. Heute sind die Hauptanbaugebiete Madagaskar (der Norden Madagaskars liefert über 50 % der Weltproduktion), die Komoren und an dritter Stelle Réunion; Mexiko liefert nur noch etwa 10 % der Vanilleproduktion. Weitere Anbaugebiete sind Mauritius, Indonesien (Java), die Seychellen, Tahiti und Sansibar. Die Anteile an der Weltproduktion schwanken klimabedingt (Zyklone in Madagaskar) sowie durch Qualitäts- und Preisschwankungen teilweise stark.

Zu den weltgrößten Abnehmern zählen Coca-Cola und Pepsi-Cola, die jeweils etwa 40 Tonnen abnehmen.

Der Marktpreis von Vanille unterliegt seit Jahrzehnten starken Schwankungen. Er stieg drastisch Ende der 70er Jahre infolge eines Taifuns. Mitte der 80er Jahre löste sich das seit 1930 bestehende Kartell auf, das die Vanillepreise und -verteilung steuerte. Der Marktpreis sank auf fast 20 US-Dollar pro Kilogramm. Der Taifun Hudah verwüstete im Jahr 2000 die Anbaugebiete. Im Zusammenhang mit politischen Instabilitäten stieg der Vanillepreis bis zum Jahre 2004 stark an, um dann 2005 erneut auf etwa 40 US-Dollar pro Kilogramm zu sinken.




</doc>
<doc id="1985" url="https://de.wikipedia.org/wiki?curid=1985" title="Gravitation">
Gravitation

Die Gravitation (von für „Schwere“), auch Massenanziehung oder Gravitationskraft, ist eine der vier Grundkräfte der Physik. Sie äußert sich in der gegenseitigen Anziehung von Massen. Sie nimmt mit zunehmender Entfernung der Massen ab, besitzt aber unbegrenzte Reichweite. Im Gegensatz zu elektrischen oder magnetischen Kräften lässt sie sich nicht abschirmen.

Auf der Erde bewirkt die Gravitation, dass alle Körper nach „unten“, d. h. in Richtung Erdmittelpunkt fallen, sofern sie nicht durch andere Kräfte daran gehindert werden. Im Sonnensystem bestimmt die Gravitation die Bahnen der Planeten, Monde, Satelliten und Kometen und im Kosmos die Bildung von Sternen und Galaxien sowie dessen Entwicklung im Großen.

Gravitation wird oft mit Schwerkraft gleichgesetzt. Das Gewicht eines Körpers wird allerdings vom lokal herrschenden Schwerefeld bestimmt, welches nicht nur die "Gravitationskraft" umfasst, sondern auch auf den Körper wirkende Trägheitswirkungen (insbesondere durch die Rotation des Bezugssystems).

Im Rahmen der klassischen Physik wird die Gravitation mit dem newtonschen Gravitationsgesetz beschrieben, d. h. als eine instantan durch den leeren Raum wirkende Fernwirkungskraft. Ein grundlegend anderes Verständnis der Gravitation ergibt sich aus der allgemeinen Relativitätstheorie nach Albert Einstein. Hierbei wirkt die Gravitation nicht in Form einer Kraft auf die Körper, sondern durch eine Krümmung der vierdimensionalen Raumzeit, wobei die Bahnen der Körper, auf die keine weiteren Kräfte wirken, einer kürzesten Linie (im gekrümmten Raum), d. h. einer Geodäte, entsprechen.

Der griechische Philosoph Aristoteles beschrieb in der Antike im Rahmen seiner Kosmologie die Schwere als diejenige Eigenschaft der sublunaren Elemente (Erde, Wasser, Luft, Feuer), die alle aus diesen Elementen bestehenden Körper zum Mittelpunkt der Welt streben lässt. Diese Vorstellung war lange das physikalische Hauptargument für das geozentrische Weltbild.

Altindische Autoren führten den freien Fall auf eine Kraft zurück, die proportional zur Masse eines Objektes ist und in Richtung des Erdmittelpunkts wirkt. Der persische Astronom Muhammad ibn Musa erklärte im 9. Jahrhundert die Bewegungen der Himmelskörper durch eine Anziehungskraft. Al-Biruni übersetzte im 11. Jahrhundert die Werke der indischen Autoren ins Arabische und ins Persische. Sein Zeitgenosse Alhazen formulierte eine Theorie der Massenanziehung. Der Perser Al-Khazini stellte im 12. Jahrhundert die Vermutung auf, dass die Stärke der Erdanziehung abhängig vom Abstand zum Erdmittelpunkt ist, und unterschied zwischen Masse, Gewicht und Kraft.

Ein bedeutender Kritiker der peripatetischen (aristotelischen) Physik und Vorbereiter des kopernikanischen Weltbildes ist der Spätscholastiker Nikolaus von Oresme. Er hielt im 14. Jahrhundert die Erdrotation für wahrscheinlich und beschrieb die Möglichkeit vieler Welten sowie vieler gravitativer Zentren – im Gegensatz zu einer ruhenden, im Mittelpunkt des Universums liegenden und alles Schwere anziehenden Erde.

Nikolaus Kopernikus ging 1543 in "De revolutionibus orbium coelestium" davon aus, dass außer der Erde auch alle anderen Himmelskörper Gravitation ausüben:
Johannes Kepler veröffentlichte 1609 in seiner "Astronomia nova" folgende Axiome:

Ebenfalls Anfang des 17. Jahrhunderts beschrieb Galileo Galilei den freien Fall eines Körpers als gleichmäßig beschleunigte Bewegung, die unabhängig von seiner Masse oder sonstigen Beschaffenheit ist.

René Descartes erklärte die Schwerkraft als Folge seiner „Wirbeltheorie“. 1644 veröffentlichte er die "Principia Philosophiae", welche großen Einfluss hatten – auch auf die Kritik durch Isaac Newton – denn die Kometen konnten offensichtlich nicht mit Descartes’ Modell erklärt werden. Dass Kometen die Sphären, bzw. die Bahnen der Planeten durchdringen, bzw. kreuzen, war seit Tycho Brahe und dem Kometen von 1577 die vorherrschende Meinung.

Der englische Gelehrte Robert Hooke erklärte um 1670 die Wirkung der Gravitation mit Hilfe von „Gravitationstrichtern“ und erklärte, dass die Gravitation eine Eigenschaft aller massebehafteten Körper sei und umso größer, je näher sich zwei Körper zueinander befänden. Die Theorie, dass die Schwerkraft umgekehrt proportional zum Quadrat des Abstands vom Massezentrum ist, taucht 1680 in einem Brief Hookes an seinen Landsmann Newton erstmals auf.

Isaac Newton beschrieb in seiner "Principia" als erster die Gravitation mithilfe einer mathematischen Formel. Dieses von ihm formulierte Gravitationsgesetz ist eine der Grundgleichungen der klassischen Mechanik, der ersten "physikalischen" Theorie, die sich auch in der Astronomie anwenden ließ. Danach ist die Gravitation eine Kraft zwischen je zwei Körpern, die diese zu ihrem gemeinsamen Schwerpunkt hin beschleunigt, wobei ihre Stärke proportional zum Quadrat des Abstandes der Körper abnimmt. Die Newtonsche Theorie, vollendet um 1800 von Pierre-Simon Laplace, liefert ein grundlegendes Verständnis der Dynamik des Sonnensystems mit der Möglichkeit präziser Vorhersagen der Bewegung von Planeten, Monden und Kometen. Sie bestätigt die keplerschen Gesetze der Planetenbewegung für einzelne Planeten, lässt aber darüber hinaus den störenden Einfluss der anderen Planeten und Monde ermitteln. Die danach berechneten Werte stimmten lange Zeit mit den entsprechenden astronomischen und irdischen Beobachtungen und Experimenten vollkommen überein. Die erste so nicht erklärbare Diskrepanz wurde Mitte des 19. Jahrhunderts an der Periheldrehung der Bahn des Merkur entdeckt.

Zur Erklärung der Gravitation im Sinne eines Prozessgeschehens wurden weiterhin bis zur Entwicklung der allgemeinen Relativitätstheorie im frühen 20. Jahrhundert eine Reihe mechanischer, respektive kinetischer Erklärungen vorgeschlagen (siehe Mechanische Erklärungen der Gravitation). Eine der bekanntesten ist die von Fatio und Le Sage entwickelte Theorie der Le-Sage-Gravitation. Diese argumentiert, dass die Gravitationsanziehung zweier Körper auf der Abschirmung des aus Richtung des jeweils anderen wirkenden Drucks beruht. Im Zusammenhang hiermit stehen die Theorien eines Äthers als Vermittler von Wechselwirkungen (anstelle einer Fernwirkung), zu diesen Wechselwirkungen gehört auch der Elektromagnetismus. Eine der letzten dieser Theorien war die um 1900 entstandene Lorentzsche Äthertheorie, die schließlich von dem neuartigen Ansatz der einsteinschen Relativitätstheorie verdrängt wurde.

In der 1916 von Albert Einstein aufgestellten allgemeinen Relativitätstheorie (ART) wird die Gravitation auf eine geometrische Eigenschaft der Raumzeit zurückgeführt. Er nimmt an, dass die Raumzeit durch die Anwesenheit von Masse und jeder Form von Energie gekrümmt wird. Das ermöglicht, die Gravitation grundsätzlich anders zu interpretieren als die anderen Kräfte, nämlich als Trägheitskraft. Nach dem Äquivalenzprinzip kann die Wirkung der Gravitation nicht von der Auswirkung einer Beschleunigung des Bezugssystems unterschieden werden; insbesondere heben sich in einem frei fallenden Bezugssystem die Wirkungen von Gravitation und Beschleunigung exakt auf. Man sagt, die Gravitation sei durch den Übergang zu den neuen Koordinaten „wegtransformiert“. Allerdings gilt dies jeweils nur für einen Ort, weil jedes reale Gravitationsfeld für benachbarte Orte verschiedene Beschleunigungen bewirkt. In der allgemeinen Relativitätstheorie wird zu jedem Punkt im Raum das entsprechende "Lokale Inertialsystem" ermittelt, worin es keine Gravitation gibt und die spezielle Relativitätstheorie mit ihrer vierdimensionalen Raumzeit in euklidischer Geometrie gilt. Die Wirkung der Gravitation tritt dann bei der Rücktransformation in das Bezugssystem des Beobachters zutage. Analog dazu, dass nach Galilei kräftefreie Bewegungen geradlinig und gleichförmig verlaufen, bewegen sich in der allgemeinen Relativitätstheorie Körper ohne nichtgravitative Kräfte auf Geodäten in einem „gekrümmten“ Raum mit riemannscher Geometrie. Zur Bestimmung der an einem Punkt herrschenden Krümmung der Raumzeit dienen die einsteinschen Feldgleichungen. Sie wurden so formuliert, dass im Grenzfall schwacher Gravitation die nach ihnen berechneten Ergebnisse mit denen übereinstimmen, die nach der newtonschen Gleichung berechnet werden. Die allgemeine Relativitätstheorie behandelt die Gravitation also als Trägheitskraft und stellt sie mit Zentrifugalkraft, Corioliskraft oder der Kraft, die man in einem Fahrzeug beim Anfahren oder Abbremsen spürt, auf eine Stufe.

Innerhalb des Sonnensystems, wo es sich um schwache Felder bzw. geringe Krümmung der Raumzeit handelt, ergeben sich nur geringe Abweichungen von den Vorhersagen des newtonschen Gravitationsgesetzes. Das erste erfolgreiche Anwendungsbeispiel der allgemeinen Relativitätstheorie war die Erklärung der kleinen Abweichung zwischen der beobachteten Periheldrehung der Bahn des Merkur und dem Wert, der nach der newtonschen Theorie aufgrund der Bahnstörungen durch die anderen Planeten vorhergesagt wird. Bei starker Krümmung, wie sie durch starke Konzentration großer Masse auf kleinem Raum hervorgerufen wird, werden völlig neue Phänomene wie z. B. Schwarze Löcher vorhergesagt.

Als Quelle wie auch als Angriffspunkt der Gravitation gilt in der newtonschen Mechanik allein die Masse, die, von dem ursprünglich ungenauen Begriff einer gegebenen Materiemenge ausgehend, hier ihre erste präzise physikalische Definition erfuhr. In der allgemeinen Relativitätstheorie ist die Gravitation Ausdruck der Krümmung der Raumzeit, die ihrerseits nicht nur von der Anwesenheit von Materie, sondern auch von Energie in jeder Form, auch der Gravitationsenergie selbst, und darüber hinaus von Massen- und Energieströmen beeinflusst ist. Alle der Beobachtung zugänglichen Vorhersagen der allgemeinen Relativitätstheorie wurden durch Messungen bestätigt.

In der Newtonschen Gravitation ging man noch von einer instantanen oder augenblicklichen Ausbreitung der Gravitationswirkung aus, das heißt, dass die Wirkung auch über große Entfernungen sofort erfolgt. Innerhalb der einsteinschen Sichtweise gilt jedoch, dass sich keine Wirkung, also auch nicht die Gravitationswirkung, schneller als mit Lichtgeschwindigkeit ausbreitet. Durch eine schnelle Veränderung der Position von Massen, wie zum Beispiel bei schnell kreisenden Doppelsternen oder beim Kollaps eines Sternes werden dann Gravitationswellen erzeugt, die sich mit Lichtgeschwindigkeit ausbreiten.

Experimentell nicht zugänglich sind extrem hohe Konzentrationen von Masse bzw. Energie auf engstem Raum, für deren Beschreibung neben der Gravitation auch Quanteneffekte berücksichtigt werden müssten. Versuche einer Quantenfeldtheorie der Gravitation gibt es in Ansätzen. Es mangelt allerdings an Vorhersagen, die sowohl berechenbar als auch beobachtbar wären. Das Grundproblem dabei ist, dass sich bei solchen Konzentrationen schnell schwarze Löcher bilden, und sich die Quanteneffekte in deren Innerem abspielen, so dass sie nicht beobachtet werden können.

Das Phänomen „Dunkle Materie“ steht für die Differenz zwischen den beobachteten und nach den Modellen von Kepler, Newton und Einstein zu erwartenden Massen beim Rotationsverhalten von Galaxien und Galaxienhaufen. Statt zusätzlicher, nicht sichtbarer Masse schlug Mordehai Milgrom 1983 vor, dass eine Änderung der Newtonschen Bewegungsgesetze die Ursache für die beobachteten Rotationskurven sein könnte. Gemäß der „MOND-Hypothese“ hat die Änderung nur bei sehr kleinen Beschleunigungen, wie sie im astronomischen Maßstab auftreten, einen relevanten Einfluss auf die Bewegungen.

Befürworter der „Modifizierten Newtonschen Dynamik“ führen an, dass die Newtonsche Gravitationstheorie von 1686 bereits drei Modifikationen erfahren hat. Bei sehr kleinen Abständen verwenden Physiker ausschließlich die Quantenmechanik, bei sehr großen Geschwindigkeiten Einsteins spezielle Relativitätstheorie und nahe sehr großer Massen seine allgemeine Relativitätstheorie.

In der klassischen Mechanik ist die Gravitation oder "allgemeine Massenanziehung" eine Eigenschaft aller Materie, die nur von deren Masse abhängt, nicht aber von deren Art oder Bewegung. Die Gravitation drückt sich in der Gravitationskraft oder dem Gravitationsfeld aus, das von jeder Masse erzeugt wird, auf jede andere Masse anziehend wirkt und (in der klassischen Mechanik) unendliche Ausbreitungsgeschwindigkeit und Reichweite besitzt. Das newtonsche Gravitationsgesetz gibt die momentane Kraft formula_1 an, mit der zwei punktförmig gedachte Körper mit den Massen formula_2 und formula_3 im Abstand formula_4 einander anziehen (formula_5 ist die universelle Gravitationskonstante):

Diese Kraft ist für beide Körper gleich groß, jedoch entgegengesetzt gerichtet. Wenn keine weiteren Kräfte wirken, erfährt jeder der beiden Körper eine Beschleunigung zum anderen hin. Diese Momentanbeschleunigung formula_7 kann mithilfe des zweiten newtonschen Gesetzes formula_8 berechnet werden. Es ergibt sich beispielsweise für den Körper 1:

Die Momentanbeschleunigung des Körpers 1 hängt also nicht von seiner Masse formula_2 ab, sondern von der Masse formula_3 des anderen Körpers. Der Körper 2 erteilt somit in einem bestimmten Abstand jedem anderen Körper, unabhängig von dessen Masse, die gleiche Beschleunigung. Umgekehrt gilt das Gleiche für die Beschleunigung, die Körper 1 jedem anderen Körper im Abstand formula_4 erteilt:

Die Beschleunigungen sind daher indirekt proportional zu den beschleunigten Massen: formula_14. Nimmt man für den Körper 2 die Erde und für den Körper 1 einen beliebigen Gegenstand des täglichen Lebens, so bedeutet dies, dass die Erde aufgrund ihrer viel größeren Masse nur eine unmessbar kleine Beschleunigung durch Körper 1 erfährt. Sie kann deshalb als ruhend angenommen werden. Körper 1 erfährt von ihr jedoch eine Beschleunigung, die zwar vom Abstand vom Erdmittelpunkt abhängt, nicht jedoch von der Masse formula_2. Dies erklärt die von Galileo Galilei zuerst ausgesprochene Tatsache, dass (im leeren Raum, also ungehindert durch andere Kräfte oder Widerstände) alle Körper unabhängig von ihrer Masse die gleiche "Fallbeschleunigung" erfahren. Die Gleichheit der Fallbeschleunigung wird auch als das Prinzip der Äquivalenz von träger und schwerer Masse (in seiner schwachen Formulierung) bezeichnet.

Sind die Massen der beiden Körper nicht so stark voneinander verschieden wie in dem vorangehenden Beispiel, so führen "beide" Körper beschleunigte Bewegungen aus, wobei der Gesamtschwerpunkt zwischen den beiden Massen als ruhender Bezugspunkt gewählt werden kann (siehe Schwerpunktsatz). Wenn beide Körper aus der Ruhe starten, so stürzen sie auf gerader Strecke aufeinander zu, bis sie sich treffen. (In der Abstraktion als Punktmassen würde dies im Gesamtschwerpunkt geschehen.)

Wenn sie jedoch jeweils eine Anfangsgeschwindigkeit im Schwerpunktsystem haben, so führen sie Bewegungen aus, deren Bahnkurven in einer gemeinsamen Ebene liegen; das verlangt der Drehimpulserhaltungssatz. Welche Form diese Bahnkurven haben, hängt von den Geschwindigkeiten der beiden Körper ab (siehe Zweikörperproblem). Eine mögliche Lösung sind Ellipsenbahnen, wobei der Schwerpunkt jeweils einen Brennpunkt der beiden Ellipsen bildet. Ein Beispiel dafür ist das System Erde-Mond, bei dem die Masse der Erde so groß ist, dass der gemeinsame Schwerpunkt sogar im Inneren der Erde liegt.

Systeme, die aus drei oder mehr Körpern bestehen, die sich gegenseitig anziehen, verhalten sich oft chaotisch und sind mit analytischen Methoden nicht berechenbar (siehe Drei-Körper-Problem). Es gibt jedoch hilfreiche Näherungen. Im Sonnensystem beispielsweise ist die Masse der Planeten im Vergleich zur Sonnenmasse sehr gering. Wenn man davon ausgeht, dass die Sonne deshalb von den Planeten nicht beeinflusst wird und dass die Planeten untereinander nicht wechselwirken, dann ergeben Berechnungen mit dem Newtonschen Gravitationsgesetz die Keplerschen Bahnellipsen der Planeten.

Die klassische Beschreibung der Gravitation ist also für viele Anwendungsfälle hinreichend genau. Abweichungen treten allerdings im Zusammenhang mit präzisesten Messungen auf, z. B. bei der Periheldrehung des Merkur. Die klassische Beschreibung versagt völlig bei extremen Bedingungen, die z. B. bei Schwarzen Löchern vorliegen.

Die Gewichtskraft eines Körpers auf der Erdoberfläche wird maßgeblich durch die Gravitation bestimmt. Weiter tragen Trägheitskräfte zur Gewichtskraft bei; z. B. wirkt die Fliehkraft, die sich aus der Erdrotation ergibt, der Gravitation ein wenig entgegen. Gravitation und Trägheitskräfte zusammen bilden das Schwerefeld.

Die Gravitationskonstante formula_5 ist eine Fundamentalkonstante der Physik. Ihre genaue Bestimmung ist sehr schwierig, denn zwischen zwei Körpern, deren Masse durch direkte Wägung bestimmt werden kann, ist die Gravitationskraft äußerst gering. Ihr Wert ist daher nur auf vier Dezimalstellen bekannt, im Unterschied zu den mindestens acht Dezimalstellen anderer Fundamentalkonstanten.

Die erste Bestimmung gelang 1798 Henry Cavendish. Das in seinem Labor durchgeführte, von John Michell erdachte, Experiment (Gravitationswaage) hat historische Bedeutung für die Entwicklung der experimentellen und theoretischen Grundlagen der Gravitation.

In der allgemeinen Relativitätstheorie (ART) wird die Gravitation nicht wie eine Kraft im Sinne der klassischen Physik behandelt. Im Unterschied zu den gewöhnlichen klassischen Feldtheorien, in denen die Koordinaten für Ort und Zeit in einer festen Struktur vorgegeben werden, betrachtet die ART diese Struktur selber als veränderlich. Als Grundlage nutzt sie die aus der speziellen Relativitätstheorie bekannte Raumzeit, in der Orts- und Zeitkoordinaten in einer vierdimensionalen pseudo-riemannschen Mannigfaltigkeit zusammengefasst sind. Diese Raumzeit ist in der ART aber nicht mehr „flach“ wie in der Euklidischen Geometrie, sondern wird durch das Auftreten von Masse oder Energie „gekrümmt“. Die Krümmung ergibt sich an jedem Punkt der Raumzeit aus der Metrik, die festlegt, wie der vierdimensionale Abstand zwischen zwei Punkten der Raumzeit, also zwischen zwei Ereignissen, zu ermitteln ist. Dabei wird der zeitliche Abstand mit positivem, der räumliche Abstand aber mit negativem Vorzeichen gewertet. Weiter wird festgelegt, dass ein Körper, auf den außer der Gravitation keine Kräfte wirken, sich zwischen zwei Ereignissen (z. B. Abfahrt und Ankunft) stets entlang derjenigen Verbindungslinie bewegt, die nach dieser raumzeitlichen Metrik die "längste" ist (Geodäte), was wegen der erwähnten Vorzeichenwahl die räumlich "kürzeste" Strecke bedeutet. Dort wo die Raumzeit flach ist, ist die Geodäte die gerade Verbindungslinie der beiden Punkte. Umgerechnet in die üblichen Koordinaten für Ort und Zeit gibt sie eine gleichförmige Bewegung auf dem räumlich kürzesten Weg, also längs der räumlichen Verbindungsgeraden. Das entspricht dem Trägheitsgesetz der klassischen Mechanik für den völlig kräftefreien Körper. Bei einer gekrümmten Raumzeit entspricht eine Geodäte im Allgemeinen einer beschleunigten Bewegung längs einer räumlich gekrümmten Bahn. Die durch die Anwesenheit von Masse oder Energie verursachte Krümmung der Raumzeit wird durch die einsteinschen Feldgleichungen gerade so festgelegt, dass die Geodäte eine Bewegung wiedergibt, die genau der Bewegung des ansonsten kräftefreien Körpers im herrschenden Gravitationsfeld entspricht (also freier Fall, Wurfparabel, Planetenbahn etc.). Da die Masse des betrachteten Körpers dabei gar nicht einfließt, gilt für Körper mit verschiedener Masse dieselbe Geodäte, d. h., sie bewegen sich in einem gegebenen Gravitationsfeld gleich. Damit ist auch das Äquivalenzprinzip erklärt, das in der klassischen Physik die Gleichheit von schwerer und träger Masse feststellt. Die Gravitation tritt demnach nicht wie in der klassischen Physik als eine bestimmte Kraft auf, die auf den Körper wirkt und eine Beschleunigung verursacht, sondern als eine Eigenschaft der Raumzeit, in der der Körper sich kräftefrei bewegt. Gravitation wird auf diese Weise als ein rein geometrisches Phänomen gedeutet.

In diesem Sinne reduziert die allgemeine Relativitätstheorie die Gravitationskraft auf den Status einer Scheinkraft: Wenn man auf einem Stuhl sitzend fühlt, wie man durch eine „Gravitationskraft“ zur Erde hin gezogen wird, deutet die ART dies so, dass man von der Stuhlfläche fortwährend daran gehindert wird, der Geodäte durch die von der Erdmasse gekrümmten Raumzeit zu folgen, was der freie Fall wäre. Dabei ist die Kraft, mit der die Stuhlfläche auf die Sitzfläche des Beobachters einwirkt, keineswegs eine Scheinkraft. Sie geht letztlich zurück auf die elektrostatische Abstoßung bei der Berührung der Atome der Stuhlfläche durch die Atome des Beobachters. Nach der Sichtweise der allgemeinen Relativitätstheorie verschiebt sich also die Interpretation der Ereignisse. Während nach der klassischen Mechanik die Erde ein Inertialsystem darstellt, in dem die nach unten gerichtete Schwerkraft auf den Beobachter durch die nach oben gerichtete Stützkraft des Stuhls ausgeglichen wird, so dass der Beobachter in Ruhe bleiben kann, stürzt das nach der allgemeinen Relativitätstheorie richtige Inertialsystem mit Erdbeschleunigung formula_17 nach unten. Doch in diesem Inertialsystem übt der Stuhl eine Kraft auf den Beobachter aus, die ihn konstant mit formula_18 nach oben beschleunigt.

Senkrecht frei fallende Körper hingegen, aber auch Satelliten, Planeten, Kometen oder Parabelflüge folgen einer Geodäte durch die Raumzeit. Ihre Bewegungen werden in der allgemeinen Relativitätstheorie als (netto) kräftefrei angesehen, da die Erdmasse (oder Sonnenmasse) durch die Raumzeitkrümmung die Definition davon beeinflusst, was im Sinne der Trägheit von Körpern „geradeaus“ bedeutet. Direkter tritt die Raumzeitkrümmung z. B. in astronomischen Beobachtungen in Erscheinung, in denen nachgewiesen werden konnte (s. Abb.), dass große Massen die Krümmung von Lichtstrahlen bewirken.

Aufgrund des Relativitätsprinzips und der daraus folgenden Invarianz gegenüber Lorentztransformationen trägt nicht nur Masse, sondern auch jede Form von Energie zur Krümmung der Raumzeit bei. Dies gilt einschließlich der mit der Gravitation selber verbundenen Energie. Daher sind die einsteinschen Feldgleichungen nichtlinear. Sie lassen sich im Bereich schwacher Krümmung durch lineare Gleichungen annähern, in denen sich das newtonsche Gravitationsgesetz wiederfinden lässt. Gegenüber den nach dem newtonschen Gesetz berechneten Phänomenen ergeben sich aber kleine Korrekturen, die durch genaue Beobachtungen sämtlich bestätigt werden konnten (siehe Tests der allgemeinen Relativitätstheorie). Völlig neue Phänomene jedoch ergeben sich bei starker Krümmung der Raumzeit, hier insbesondere die schwarzen Löcher.

Im Rahmen einer Quantenfeldtheorie wird die Gravitation in linearer Näherung durch den Austausch eines als Graviton bezeichneten masselosen Teilchens beschrieben, das den Spin 2 hat. Darüber hinaus führt schon die Formulierung einer Quantentheorie der Gravitation zu prinzipiellen Problemen, die bisher ungelöst sind. Auch die supersymmetrische Erweiterung führte bisher nicht zu einer konsistenten Theorie. Als derzeit aussichtsreichste Kandidaten gelten die Stringtheorie und die Schleifenquantengravitation. Ein wesentliches Ziel ist dabei, die Gravitation mit den übrigen Wechselwirkungen zu einer „Großen Vereinheitlichten Theorie“ (GUT) zu vereinen, um somit eine Theorie zu formulieren, die alle Naturkräfte auf einmal beschreiben kann. Das bedeutet, dass die Gravitation, welche die Effekte der Quantenfeldtheorie nicht berücksichtigt, um diese erweitert würde. Im Rahmen der vereinigten Superstringtheorien, der M-Theorie, wird das Universum als elfdimensionale Mannigfaltigkeit beschrieben. Dabei stellt der Teil des Universums, in welchem wir existieren, eine höherdimensionale Membran (p-Brane) dar, die selbst in eine noch höherdimensionalere Mannigfaltigkeit eingebettet ist, in der noch weitere Branen schwingen könnten und somit parallele Raumzeiten innerhalb desselben Universums darstellen. In der M-Theorie werden die Gravitonen als geschlossene Strings dargestellt, die nicht an die Grenzen einer Brane gebunden sind. Daher sind sie in der Lage, sich durch alle zusätzlichen Raumdimensionen auszubreiten und auch in andere Branen zu gelangen. Auf diese Weise wird die Stärke der Gravitation hinreichend abgeschwächt, so dass sie im Rahmen unserer vierdimensionalen Erfahrungswelt als die schwächste der vier Wechselwirkungen erscheint.

Die Wirkung des Gravitationspotentials auf die quantenmechanische Phase der Wellenfunktion wurde 1975 durch ein Interferenzexperiment an freien Neutronen nachgewiesen. Die Wellenfunktion und Energie von Neutronen, die einen im Gravitationsfeld gebundenen Zustand besetzen, konnte 2012 ausgemessen werden. In beiden Fällen bestätigen die Messergebnisse die aufgrund der Quantenmechanik berechneten Voraussagen.

Die Erde hat eine Masse von 5,974·10 kg. Ihr Radius beträgt an den Polen 6356 km bzw. wegen der Erdabplattung 6378 km am Äquator. Daraus ergibt sich mithilfe des Gravitationsgesetzes von Newton, dass die Gravitationsbeschleunigung zwischen formula_19 (am Äquator) und formula_20 (an den Polen) beträgt. Die tatsächlich wirksame Fallbeschleunigung weicht jedoch von dem auf diese Weise berechneten Wert ab, man spricht deshalb auch vom Ortsfaktor. Diese Ortsabhängigkeit, die auch die Richtung der Fallbeschleunigung betrifft, hängt mit der Zentrifugalwirkung, die durch die Erdrotation hervorgerufen wird, mit der Höhe des Standorts und mit lokalen Schwereanomalien zusammen. Dementsprechend ist die Gewichtskraft im Schwerefeld der Erde nicht nur eine reine "Gravitationskraft" im Sinne des Gravitationsgesetzes.

Wenn von „Schwerelosigkeit“ gesprochen wird, ist oft nicht die Abwesenheit von Gravitation gemeint, sondern lediglich die Abwesenheit einer der Gewichtskraft entgegengerichteten Haltekraft. Ein Körper, auf den lediglich die Gravitationskraft wirkt, befindet sich in einem Zustand des freien Falls. In diesem Sinne befindet sich auch eine Raumstation im Erdorbit im freien Fall, wobei wegen genügend großer horizontaler Bahngeschwindigkeit die Flugbahn nicht an der Erdoberfläche endet, sondern um die Erde herum führt. In einem frei fallenden Bezugsystem sind keine Gravitationswirkungen bemerkbar. Folglich wird dieser Zustand als Schwerelosigkeit bezeichnet. Dies gilt unter der Bedingung, dass das Gravitationsfeld zumindest lokal näherungsweise homogen ist. Geringe Abweichungen davon führen zu Phänomenen der Mikrogravitation.

In einem System aus zwei umeinander kreisenden Himmelskörpern (z. B. Erde und Sonne) gibt es konstant mitrotierende Punkte, an denen weitere Himmelskörper eine Bahn haben könnten, auf der sich alle Kräfte aufheben – die sogenannten Lagrange-Punkte. Dort heben sich die Gravitationskräfte der Himmelskörper und die Zentrifugalkraft der Bahnbewegung gegenseitig auf. Eine entsprechende Bahn, die einen Lagrange-Punkt verfolgt, kann stabil oder instabil sein – ein leichtes Abweichen vom Lagrange-Punkt kann eine korrigierende Kraft zurück zu dem Punkt bewirken (stabil) oder zum Ausbrechen führen (instabil). Das Planck-Weltraumteleskop ist in einem Lagrange-Punkt stationiert.

Nahe Massen haben mehr Einfluss auf die Gravitationsbeschleunigung als ferne Massen. Daher sind auch um relativ kleine Körper im Schwerefeld großer Körper Satellitenbahnen möglich. Der Raumbereich, in dem dies der Fall ist, ist die "Gravisphäre" des jeweiligen Himmelskörpers. Aus dem gleichen Grund ist die Gravitationsbeschleunigung eines unregelmäßig geformten Körpers nicht an allen Raumpunkten auf sein Baryzentrum ausgerichtet.

Im Bereich der Science-Fiction und Grenzwissenschaften gibt es zahlreiche Konzepte einer gravitativen Abschirmung oder einer Antigravitation. Relative Bekanntheit haben Experimente von Quirino Majorana, der um 1920 eine abschirmende Wirkung durch schwere Elemente gefunden haben will (entkräftet u. a. durch Henry Norris Russell), und von Jewgeni Podkletnow, der 1995 bei rotierenden Supraleitern eine Abnahme der Gewichtskraft behauptete, was allerdings ebenfalls nicht bestätigt werden konnte.




</doc>
<doc id="1987" url="https://de.wikipedia.org/wiki?curid=1987" title="Galen">
Galen

Galen ist der Name folgender Personen:

Galen ist der Name des westfälischen Adelsgeschlechts Galen (Adelsgeschlecht):

Galen bezeichnet:
Siehe auch: 


</doc>
<doc id="1988" url="https://de.wikipedia.org/wiki?curid=1988" title="Galenos">
Galenos

Galenos von Pergamon, auch Aelius Galenus (, in mittelalterlichen Handschriften und frühneuzeitlichen Drucken auch "Galienus"; * 129 oder 131 in Pergamon; † um 205 oder 215 in Rom), war ein vorwiegend in Rom tätiger griechischer Arzt und Anatom. Der ihm in der Renaissance verliehene Vorname bzw. Gentilname "Claudius" beruht auf einer Fehldeutung der Abkürzung "Cl." – für "Clarissimus". Galen gilt nach Hippokrates als der bedeutendste Arzt des Altertums.

An Galens Geburtsort Pergamon befand sich das um die Mitte des 2. Jahrhunderts berühmteste Heiligtum des Asklepios. Sein Vater, der Architekt und Mathematiker Nikon, unterrichtete Galen zunächst in aristotelischer Philosophie, Mathematik und Naturlehre. Ab etwa 146 beschäftigte sich Galen vornehmlich mit der Medizin. Er studierte in der Nähe von Smyrna. Im Alter von 19 Jahren reiste er nach Alexandria, das zu jener Zeit Zentrum der Heilkunst und der einzige Ort war, an dem Humansektionen und Untersuchungen an Leichen durchgeführt werden durften. Die reichhaltige Bibliothek von Alexandria besaß auch viele Schriften mit detaillierten Zeichnungen, die seine wissenschaftliche Ausbildung unterstützten. Heilkuren und Pflege fanden zu der Zeit in einem Asklepieion statt, in dem sowohl Priester als auch Heilkundler tätig waren. 158 kehrte Galen nach Pergamon zurück. Dort betreute er als Sport- und Wundarzt Gladiatoren und unterhielt gleichzeitig eine eigene ärztliche Praxis. Während der Olympischen Spiele leistete er den Athleten medizinische Hilfe. Dabei versorgte er deren frische Verletzungen, die er so auch wissenschaftlich beschreiben konnte.

Ab 161 war Galen in Rom. Die Heilung des geachteten Philosophen Eudemos von Pergamon ermöglichte ihm eine Tätigkeit als Arzt der römischen Aristokratie. Um 166 verließ er Rom, wahrscheinlich wegen einer dort ausgebrochenen Pestepidemie ("Antoninische Pest"). Zurück in Pergamon nahm er seine Arbeit als Gladiatorenarzt wieder auf. 168 reiste er auf Bitte des römischen Kaisers Marcus Aurelius nach Aquileia, wo angeblich die „Pest“ unter den römischen Soldaten ausgebrochen war. Seine präzise Beschreibung der vorgefundenen Krankheitssymptome lässt aber vermuten, dass es sich eher um eine Pockenepidemie gehandelt hatte. Seinem Wunsch entsprechend wurde er ab 169 in Rom Leibarzt des Kaisersohnes Commodus, später vermutlich auch des Kaisers P. Septimius Severus.

Galen starb in Rom, der genaue Zeitpunkt ist unbekannt. Ging die frühere Forschung noch vom Sterbejahr 199 aus, wird mittlerweile sein Tod um das Jahr 216, in jedem Fall erst nach 204, datiert.

Galens medizinisches Hauptwerk ist der "Methodus medendi", es besteht aus 14 Büchern. Der Leitgedanke darin ist, dass alle Erscheinungen in der Natur und beim Menschen einen bestimmten Zweck erfüllen. Galen begriff den Menschen als eine Leib-Seele-Einheit, die von zwei Seiten beeinflusst wird, vom Spirituellen und von der Materie.

Er nahm die in der Philosophie entwickelte "Vier-Elemente-Lehre" auf, wonach Feuer, Erde, Luft und Wasser in unterschiedlicher Zusammensetzung die Grundelemente allen Seins darstellen. Ebenso knüpfte er an die in der hippokratischen Medizin bereits in Ansätzen entwickelte "Viersäftelehre" an, welche den vier Körperssäften Blut, Schleim, gelbe Galle und schwarze Galle jeweils die "vier Qualitäten" (Primärqualitäten) warm und feucht, kalt und feucht, warm und trocken und kalt und trocken zuordnete. Die von Galen postulierten "vier Geschmacksqualitäten" (Sekundärqualitäten) sind: Blut – süß, Schleim – salzig, gelbe Galle – bitter, schwarze Galle – sauer und scharf. Darüber hinaus verknüpfte er die vier Säfte auch mit den vier Lebensphasen des Menschen. Krankheit war für ihn eine Dyskrasie, eine fehlerhafte Mischung der Säfte. Galen legte bei der Diagnose von Krankheiten besonderen Wert auf die Untersuchung von Puls und Harn.

Diesem Ansatz folgend entwickelte Galen ein eigenständiges pharmakotherapeutisches System, das er in einigen seiner Schriften darlegte. Unter diesen der Medikamentenherstellung gewidmeten Schriften sind insbesondere sein "De compositione medicamentorum" in 17 und sein "De simplicium medicamentorum temperamentis et facultatibus" in 11 Büchern zu nennen. Ziel war eine aus Erfahrung abgeleitete, auf Erkenntnis ursächlicher Zusammenhänge und Vernunft basierende Pharmakologie, die mittels des geschriebenen Wortes weitergegeben, überprüft und weiterentwickelt werden konnte. Denn „die Vernunft lehrt uns das allgemeine Ziel der Heilung bei jedem Leiden, die Erfahrung die Kräfte des Stoffes.“ Entsprechend stellte der erste Teil seines "De compositione medicamentorum" die theoretischen Grundlagen seiner Arzneimittellehre dar, während im zweiten Teil die speziellen Rezepte im Einzelnen folgten. Bei ihnen legte Galen Wert darauf, dass sie erprobt seien, auf Erfahrung beruhten und ihr Wert von den anerkanntesten Pharmakologen bestätigt würden.

Die von ihm angewandten Medikamente unterteilte er in "elementare", die nur eine der vier elementaren Qualitäten besaßen, "kombinierte" – sie wiesen zwei Qualitäten, eine Haupt- und eine Nebenwirkung auf – sowie "spezifische" für besondere Fälle, etwa Abführ-, Brech- oder Entwässerungsmittel. Während die "simplicia" genannten elementaren Medikamente zum Teil auf die "materia medica" des im 1. Jahrhundert wirkenden Arztes Pedanios Dioskurides zurückgingen, hatte Galen viele seiner "composita" durch empirische Untersuchungen entwickelt. Jede Krankheit verlangte nach einem eigenen Medikament, für dessen Auswahl und Dosierung man das "temperamentum", das heißt die "angemessene Mischung der Säfte" des Kranken selbst, und des erkrankten Körperteils im Speziellen, sowie den Wirkungsgrad des Medikamentes beachten müsse. Er stellte damit die Therapie und Pharmakologie auf eine systematische Basis.

Die Wirkungsgrade seiner Stoffe unterschied er folgendermaßen:

Krankhaften Veränderungen der "ausgewogenen Mischung der Säfte", die sich durch Erhitzen, Anfeuchten, Erkälten oder Austrocknen der betroffenen Körperteile zeigten, müsse mit entgegengesetzt wirkenden Medikamenten begegnet werden. Hierbei sei die "Anziehungskraft" eines Körperteils auf bestimmte Medikamente, die durch die "ähnliche Beschaffenheit auf elementarer Ebene" hervorgerufen werden könne, zu berücksichtigen.

An den komplizierten Rezepturen Galens orientierte sich die Pharmakologie des islamischen und des abendländischen Kulturraums bis ins Spätmittelalter. Erst unter dem Einfluss der medizinischen Lehre des Paracelsus verlor diese, Galenik genannte, Lehre von Herstellung und Zubereitung der Medikamente im Verlauf der frühen Neuzeit an Bedeutung, der Begriff blieb erhalten.

In seinem Werk vereinigte Galen zwei über Jahrhunderte hinweg im Widerstreit stehende medizinische Herangehensweisen.

Diese methodische Synthese begründete Galens maßgeblichen Einfluss auf die mittelalterliche Medizin bis hin zur Renaissance. Er führte umfangreiche Sektionen und Vivisektionen an Tieren durch und verfasste nahezu 400 Schriften, die nach seinem Tod durch Oribasius (326–403) in 70 Büchern zusammengefasst wurden. Knapp ein Viertel davon ist im griechischen Original oder in lateinischen, arabischen oder syrischen Übersetzungen erhalten. Bis ins 17. Jahrhundert und darüber hinaus dienten sie als medizinische Lehrgrundlage an den Universitäten.

Viele von Galens Ansichten über die menschliche Anatomie waren jedoch falsch, da er die anhand seiner Sektionen von Schweinen, Affen und Hunden gewonnenen Erkenntnisse einfach auf den Menschen übertragen hatte. Seine Werke dienten als Grundlage anatomischer Vorlesungen und wurden als so vollständig angesehen, dass man lange Zeit keinen Anlass zur Überprüfung sah. Es war nicht üblich und häufig sogar verboten, menschliche Körper zu sezieren. Stellten Ärzte zufällig bei einer Leiche Abweichungen von Galens Lehre fest, hielten sie das untersuchte Organ für eine Missbildung. Vesalius war in den 1530er Jahren der Erste, der erkannte, dass Galen wohl nie einen Menschen seziert hatte. Er beklagte, man hätte bei einem Metzger mehr über Anatomie lernen können, als bei anatomischen Vorlesungen. Vesalius’ eigene Leichensektionen in den 1540er Jahren, die er dank guter Beziehungen zur Obrigkeit hatte durchführen können, belebten die anatomische Forschung.

Bis heute gültig sind die von Celsus beschriebenen, und später von Galen ergänzten, Kardinalzeichen der Entzündung:


Sind sämtliche Körperbestandteile – darunter versteht Galen die Säfte, das Pneuma und die "res naturales" (die „konstitutionellen Bedingtheiten“ des individuellen Lebens) – in ausreichender Qualität und Quantität vorhanden und diese körperlichen Funktionen im Sinne einer Zweckmäßigkeit (Teleologie) im freien Fluss, resultiert Gesundheit, "sanitas".

Für Galen gibt es fließende Übergänge zwischen dem Zustand der Gesundheit, "sanitas", des Krankseins, "aegritudo", und einem Zwischenzustand, "neutralitas". Dieses Gleich- oder Ungleichgewicht wird durch Größen der "res naturales", "res non naturales" (die nicht-konstitutionellen und damit „konditional-physiologischen Bedingtheiten bzw. prozessualen Abläufe“ im individuellen Organismus) und "res praeter naturales" geregelt.
Die Einflussfaktoren jener drei Gruppierungen bestimmen den Umgang hinsichtlich einer Prophylaxe, "praeservatio", Gesunderhaltung, "conservatio sanitatis", oder Therapie, "curatio".
Als „res naturales“ betrachtet Galen:

Hingegen sind die sogenannten "sex res non naturales" (die Bezeichnung stammt nicht direkt von Galen) jene sechs fundamentalen Bedingungen menschlicher Gesundheit, welche die "richtige Mischung der Körpersäfte" beeinflussen:

Galens systematisch ausgebautes Werk, das im frühen Mittelalter von Hunain ibn Ishāq (808–873) auch ins Syrische und Arabische übersetzt wurde, war in seinem Umfang und in seinem wissenschaftlichen Niveau für die Nachwelt von solcher Autorität, dass es 1400 Jahre brauchte, bis es durch neuere Forschungen langsam überwunden wurde. Seine falsche Hypothese der Blutströmung vom Zentrum zur Peripherie des Körpers wurde erst im 17. Jahrhundert durch William Harvey und Marcello Malpighi gegen erhebliche Widerstände revidiert.

Galens Auffassung der Humoralpathologie hatte als Krankheitskonzept Bestand bis ins 19. Jahrhundert. Seine Lehren wurden, vor allem im Mittelalter, anderen gegenüber zu Recht bevorzugt und waren bis zum 19. Jahrhundert Grundlage des medizinischen Wissens an europäischen Universitäten.



Moderne Gesamtausgaben

Ausgaben der Renaissance

Einzelausgaben

Übersetzungen

Bibliographische Hilfsmittel




</doc>
<doc id="1989" url="https://de.wikipedia.org/wiki?curid=1989" title="Geometrie">
Geometrie

Die Geometrie ( "geometria (ionisch geometriē)" ‚Erdmaß‘, ‚Erdmessung‘, ‚Landmessung‘) ist ein Teilgebiet der Mathematik.

Einerseits versteht man unter "Geometrie" die zwei- und dreidimensionale euklidische Geometrie, die Elementargeometrie, die auch im Schulunterricht – früher unter dem Begriff "Raumlehre" – gelehrt wird und die sich mit Punkten, Geraden, Ebenen, Abständen, Winkeln usw. beschäftigt, sowie diejenigen Begriffsbildungen und Methoden, die im Zuge einer systematischen und mathematischen Behandlung dieses Themas entwickelt wurden.

Andererseits umfasst der Begriff "Geometrie" eine Reihe von großen Teilgebieten der Mathematik, deren Bezug zur Elementargeometrie für Laien nur mehr schwer erkennbar ist. Dies gilt insbesondere für den modernen Begriff der Geometrie, der im Allgemeinen die Untersuchung invarianter Größen bezeichnet.

Die älteste erhaltene Geometrieabhandlung in deutscher Sprache stammt vom Beginn des 15. Jahrhunderts. Es handelt sich dabei um die sogenannte "Geometria Culmensis", welche im Auftrag des Deutschorden-Hochmeisters Konrad von Jungingen im Raum Culm verfasst worden ist und neben dem, im Wesentlichen auf der "Practica geometriae" des Dominicus de Calvasio beruhenden, lateinischen Text auch dessen deutsche Übersetzung enthält. Als erstes gedrucktes und eigenständiges Geometriebuch in deutscher Sprache gilt Albrecht Dürers "Underweysung der messung mit dem zirckel und richtscheyt in Linien ebnen unnd gantzen corporen" aus dem Jahre 1525.

Die Verwendung des Plurals weist darauf hin, dass der Begriff Geometrie in einem ganz bestimmten Sinn gebraucht wird, nämlich Geometrie als mathematische Struktur, deren Elemente traditionellerweise Punkte, Geraden, Ebenen … heißen und deren Beziehungen untereinander durch Axiome geregelt sind. Dieser Standpunkt geht zurück auf Euklid, der versucht hat, die Sätze der ebenen euklidischen Elementargeometrie auf einige wenige Postulate (d. h. Axiome) zurückzuführen. Die folgende Liste soll einen Überblick über verschiedene Typen von Geometrien, die in dieses Schema passen, geben:





In jeder Geometrie interessiert man sich für diejenigen Transformationen, die bestimmte Eigenschaften nicht zerstören (also ihre Automorphismen): Zum Beispiel ändern weder eine Parallelverschiebung noch eine Drehung oder Spiegelung in einer zweidimensionalen euklidischen Geometrie die Abstände von Punkten. Umgekehrt ist jede Transformation, die die Abstände von Punkten nicht ändert, eine Zusammensetzung von Parallelverschiebungen, Drehungen und Spiegelungen. Man sagt, dass diese Abbildungen die Transformationsgruppe bilden, die zu einer ebenen euklidischen Geometrie gehört, und dass der Abstand zweier Punkte eine euklidische Invariante darstellt. Felix Klein hat in seinem Erlanger Programm Geometrie allgemein als die Theorie der Transformationsgruppen und ihrer Invarianten definiert (vgl. Abbildungsgeometrie); jedoch ist das keineswegs die einzig mögliche Definition. Im Folgenden sind Geometrien und prominente Invarianten aufgezählt:






Die folgende Liste umfasst sehr große und weitreichende Gebiete mathematischer Forschung:

Üblicherweise werden im Geometrieunterricht Geräte wie Zirkel, Lineal und Geodreieck, aber auch der Computer (siehe auch: Dynamische Geometrie) verwendet. Die Anfangsgründe des Geometrieunterrichts befassen sich etwa mit geometrischen Transformationen oder dem Messen von geometrischen Größen wie Länge, Winkel, Fläche, Volumen, Verhältnisse usw. Auch komplexere Objekte wie spezielle Kurven oder Kegelschnitte kommen vor. Darstellende Geometrie ist die zeichnerische Darstellung der dreidimensionalen euklidischen Geometrie in der (zweidimensionalen) Ebene.

Die Aussagen werden in Sätzen formuliert.

Grundlegende Sätze:





</doc>
<doc id="1990" url="https://de.wikipedia.org/wiki?curid=1990" title="Gogo">
Gogo

Gogo steht für:




"Siehe auch:" Goggo


</doc>
<doc id="1991" url="https://de.wikipedia.org/wiki?curid=1991" title="Geschichte Deutschlands">
Geschichte Deutschlands

Die Geschichte Deutschlands beginnt nach herkömmlicher Auffassung mit der Entstehung des römisch-deutschen Königtums im 10./11. Jahrhundert, wenngleich sich damit noch lange kein „Staat der Deutschen“ entwickelte. Die deutsche Sprache ist seit dem 8. Jahrhundert als eigenständige, in eine Vielzahl von Dialekten unterteilte und sich weiterentwickelnde Sprache fassbar. Die Bewohner des Reiches waren vor allem Nachfahren von Germanen und Kelten, im Westen jedoch auch von römischen Siedlern und im Osten von westslawischen Stämmen, den sogenannten Wenden oder Elbslawen.

Das römisch-deutsche Reich entwickelte sich im Frühmittelalter aus dem Ostfrankenreich, das wiederum infolge der Krise des fränkischen Reichs im 9. Jahrhundert entstanden war. Das Herrschergeschlecht der Ottonen konnte im 10. Jahrhundert die westliche („römische“) Kaiserwürde erlangen und legte die Grundlage für das seit dem späten 13. Jahrhundert so genannte Heilige Römische Reich. Ottonen sowie die nachfolgenden Salier und Staufer stützten sich in unterschiedlicher Ausprägung auf die Reichskirche. Die mittelalterlichen römisch-deutschen Kaiser sahen sich in der Tradition des antiken Römischen Reichs (Reichsidee), wobei es wiederholt zu Spannungen zwischen den Universalmächten Kaisertum und Papsttum kam. Bereits gegen Ende der staufischen Dynastie (12./13. Jahrhundert) verlor das Königtum an Macht. Die römisch-deutschen Könige waren aber ohnehin nie absolute Herrscher, vielmehr wurde der Aspekt konsensualer Herrschaft des Königtums im Verbund mit den Großen betont. Im Gegensatz zu den westeuropäischen Monarchien England und Frankreich entwickelte sich im römisch-deutschen Reich nie eine zentralisierte Reichsherrschaft. Die Macht der vielen Landesherren nahm im Spätmittelalter weiter zu, die Goldene Bulle Karls IV. legte eine kurfürstliche Wahlmonarchie fest. Diese Form einer dezentralisierten Herrschaft, die durchaus auch Vorteile hatte, begründete letztlich die Tradition des deutschen Föderalismus. Im Spätmittelalter kam es außerdem zum Aufstieg des Städtewesens.

Der frühneuzeitliche Staatsbildungsprozess spielte sich insbesondere auf der Ebene der einzelnen Territorien und nur bedingt auf der Ebene des Reiches ab. Reformation, Gegenreformation und Dreißigjähriger Krieg im 16. und 17. Jahrhundert führten über Deutschland hinaus zu veränderten Voraussetzungen im Glauben und Denken, zu demographischen Verschiebungen und zu veränderten politischen Konstellationen. Neben den Habsburgern mit Österreich, die seit dem 15. Jahrhundert fast durchgängig den Kaiser stellten, stiegen die Hohenzollern mit Preußen zur zweiten deutschen Großmacht auf.

Als Folge der Koalitionskriege gegen die Französische Revolution ging das Heilige Römische Reich Deutscher Nation 1806 unter. Nach der in die Befreiungskriege mündenden Vorherrschaft Napoleons I. über den europäischen Kontinent ergab sich im Zuge restaurativer Bemühungen eine politische Neuordnung in Form des Deutschen Bundes unter gemeinsamer österreichischer und preußischer Führung. Die dagegen gerichteten freiheitlichen Bestrebungen in der Revolution von 1848/49 wurden niedergeschlagen, der auf nationale Einheit Deutschlands gerichtete Impuls dann aber durch das preußische Militär in Kriegen sowohl gegen Österreich als auch gegen Frankreich in die Gründung des Deutschen Kaiserreichs überführt. Sozialgeschichtlich war das 19. und frühe 20. Jahrhundert geprägt von industrieller Revolution und Hochindustrialisierung, einem hohen Bevölkerungswachstum und einem Prozess der Urbanisierung.

Deutsche Weltmachtambitionen im Zeichen des Wilhelminismus trugen im Zeitalter des Imperialismus zur Entstehung des Ersten Weltkriegs bei, der in einer als schmachvoll empfundenen deutschen Niederlage endete. Die Revolution 1918/19 brachte mit der Weimarer Republik erstmals ein demokratisch verfasstes deutsches Gemeinwesen hervor, das allerdings dauerhafte politische Stabilität nicht erlangte, sondern 1933 von der nationalsozialistischen Diktatur abgelöst wurde. Die damit von Anbeginn einhergehende gewalttätige Unterdrückung aller Regimegegner im Inneren und planvoll betriebene Expansionspolitik nach außen – verbunden mit der Entfesselung des Zweiten Weltkriegs sowie mit der systematischen Verfolgung und Vernichtung der europäischen Juden – haben die NS-Zeit bis 1945 zum katastrophalen Tiefpunkt der deutschen Geschichte werden lassen.

Nach der Kapitulation der Wehrmacht vollzogen die vier Siegermächte die Aufteilung Deutschlands und Berlins: Eine östliche und drei westliche Besatzungszonen wurden gebildet, die Ostgebiete des Deutschen Reiches fremder Verwaltung unterstellt. Aus den drei Westzonen entstand 1949 die Bundesrepublik Deutschland, aus der sowjetischen Zone die Deutsche Demokratische Republik (DDR). Die Teilung Deutschlands wurde 1961 mit dem Bau der Berliner Mauer und durch die seitens der DDR militärisch gesicherte und streng bewachte innerdeutsche Grenze zementiert.

Nach der friedlichen Revolution in der DDR, die 1989 das Ende der SED-Diktatur herbeiführte und bei den ersten freien Wahlen zur Volkskammer im März 1990 eine weit überwiegende Mehrheit der Einheitsbefürworter zur Folge hatte, war der Weg frei für Verhandlungen über die deutsche Wiedervereinigung. Die Zustimmung der vier vormaligen Siegermächte zum Vollzug der deutschen Einheit war wesentlich mitbestimmt von der Einbindung der alten Bundesrepublik in den 1951 begonnenen europäischen Integrationsprozess und von der Erwartung, dass die Zusagen bezüglich einer Fortsetzung dieses Kurses auch nach der Erweiterung um die fünf neuen Bundesländer durch das vereinte Deutschland eingehalten würden. Die Bestätigung wurde bei der Einführung des Euro wie auch bei der EU-Osterweiterung von deutscher Seite erbracht.

Der älteste Nachweis von Vertretern der Gattung "Homo" auf dem Gebiet der heutigen Bundesrepublik ist der zwischen 500.000 und 600.000 Jahre alte Unterkiefer von Mauer, des Typusexemplars von "Homo heidelbergensis". Etwas jüngere Funde stammen vom Fundplatz Bilzingsleben sowie von "Homo steinheimensis"; bekannte Funde sind schließlich auch die Schöninger Speere. Aus "Homo heidelbergensis" ging vor 130.000 Jahren der Neandertaler ("Homo neanderthalensis") hervor, der – sofern die klimatischen Bedingungen es zuließen – nahezu 100.000 Jahre lang auch in Deutschland lebte. Da Deutschland während der letzten Phase der Eiszeit zur Kältesteppe (Tundra) wurde und die polare Vereisung bis ins nördliche Niedersachsen vordrang, dürfte Deutschland während des mittleren Aurignacien bis weit in das Mittelpaläolithikum hinein so gut wie unbewohnt gewesen sein, Spuren menschlicher Besiedlung fehlen für sehr lange Zeit.

Spuren des zugewanderten modernen Menschen ("Homo sapiens" der Cro-Magnon-Epoche) wurden in den Höhlen der Schwäbischen Alb gefunden, etwa die 35.000 bis 40.000 Jahre alte Venus vom Hohlefels, die weltweit älteste gesicherte Darstellung eines Menschen (neben der etwa gleich alten Venus vom Galgenberg). Die ältesten Überreste des Homo sapiens fanden 1914 Steinbrucharbeiter im Rheinland: das etwa 14.000 Jahre alte Doppelgrab von Oberkassel.

Jäger und Sammler stellten um 5800/5600 v. Chr. bereits Keramikgefäße her, bevor sie zwischen etwa 5500 und 5000 v. Chr. durch bäuerliche Kulturen abgelöst wurden. In dieser, als Jungsteinzeit bezeichneten Epoche, entwickelten sich Ackerbau, Viehhaltung und feste Siedlungsplätze sowie eine andere Art der Keramik. Das Gebiet des heutigen Deutschland wurde nach- und nebeneinander von der bandkeramischen, der schnurkeramischen und der Glockenbecherkultur besiedelt, die Benennung erfolgte anhand des archäologischen Fundgutes. Die Verwendung von Metallen revolutionierte die technischen Möglichkeiten. Aus der Bronzezeit sind einige Funde erhalten, wie etwa die in Sachsen-Anhalt gefundene Himmelsscheibe von Nebra, eine Metallplatte mit Goldapplikationen, die als älteste Himmelsdarstellung gilt (ihr Alter wird auf 3700–4100 Jahre geschätzt).

In der Bronze- und Eisenzeit bildeten sich in diesen Regionen verschiedene indoeuropäisch sprechende Volksgruppen und Stämme. Diese entstanden aus eingewanderten indoeuropäischen Stämmen bzw. deren Nachfahren, die sich mit den seit Ende der letzten Eiszeit ansässigen „Ureinwohnern“ und auch später fortwährend mit durchziehenden Völkern bzw. Siedlern vermischten. Diese dynamische Entwicklung wird als Ethnogenese bezeichnet und ist vor allem ein sozialer Prozess. Die Nachfahren der in Nordeuropa und Norddeutschland auf dem Gebiet der Nordischen Bronzekultur siedelnden Gruppen wurden in der Antike von griechischen Geschichtsschreibern als Kelten im Westen oder Skythen im Osten beschrieben. Erst unter römischen Autoren etablierte sich der Begriff Germanen. Die südlichen Teile Deutschlands wurden dagegen von Kulturgruppen besiedelt, die seit der Eisenzeit als Kelten bezeichnet werden können. 

Das erste Mal werden die Germanen bei antiken griechischen und römischen Autoren erwähnt, beginnend wohl mit Poseidonios im 1. Jahrhundert v. Chr. Die Germanen selbst waren jedoch eine uneinheitliche Gruppe von verschiedenen Stämmen, die auch kein übergeordnetes Gemeinschaftsgefühl verband. Bereits der Begriff „Germanen“ (lateinisch "Germani") ist ein ethnographischer, wenig präziser Sammelbegriff antiker Autoren, die damit auch ein „Barbarenbild“ verbanden. „Germanen“ darf aus methodischen Gründen daher nicht als Begriff für ein einheitliches Volk missverstanden werden.

Während der Ausbreitung des Römischen Reiches bis in die Spätantike siedelten dazu Römer im Raum des heutigen Süd- und Westdeutschland, deren Truppen den Süden und Westen Germaniens entlang der Donau und des Rheins bis etwa ins 5. Jahrhundert besetzten. Die Legionäre stammten aus sehr unterschiedlichen Regionen des Römischen Reiches, wie z. B. Hispanien, Illyrien, Syrien, Gallien, Afrika. In der zivilen Bevölkerung der römischen Provinzen ist eine starke keltische Komponente erkennbar, etwa auf Steindenkmälern und den dadurch erschließbaren Namen. Dies wird bestätigt durch eine Notiz in der (wichtigen, aber auch problematischen) ethnographischen Schrift "Germania" des Tacitus, der berichtet, dass sich im Dekumatland Leute aus Gallien niederließen.

Die historisch erfassten germanischen Stämme der frühen römischen Kaiserzeit des ersten Jahrhunderts gliedern sich in drei Kulturgruppen auf: die sogenannten Rhein-Weser-Germanen, die Nordseegermanen und die Elbgermanen. Durch die makropolitischen Einflüsse des andauernden Konflikts mit dem Römischen Reich sowie innergermanische politische, soziale und wirtschaftliche Veränderungen kam es ab dem 2. Jahrhundert aus diesen Kulturgruppen heraus zur (nicht biologisch, sondern als historisch-sozialer Prozess verstandenen) „Entstehungsprozess“ von neuen und größeren Stammesverbänden. Diese Stammesverbände, vor allem die Alamannen oder auch "Alemannen", die Bajuwaren, die Franken und die Sachsen wirkten konstituierend für die mittelalterliche Bildung Deutschlands und nominell bis in die Neuzeit als sogenannte „deutsche Volksstämme“, beziehungsweise ihnen wird eine solche Bedeutung beigemessen.

Seit der Reichskrise des 3. Jahrhunderts verstärkte sich der Druck, den die großen germanischen Stammesverbände der Alamannen und der Franken, die sich in der Germania Magna neu gebildet hatten, auf die Grenzen des Römischen Reiches ausübten. In den Provinzen an Rhein und Donau setzte eine Germanisierung ein, die besonders das römische Heer betraf. Teilweise wurde diese unterstützt durch Ansiedlung germanischer Foederaten auf dem Gebiet des "Imperium Romanum".

Während der Völkerwanderung blieben auch Angehörige weiterer Volksgruppen, wie etwa der Sarmaten oder Hunnen, im Gebiet des heutigen Deutschland zurück. Nach der Abwanderung fast aller Germanen aus den Gebieten östlich der Elbe wurden diese von Slawen besiedelt, deren Land erst durch die Ostkolonisation deutscher Zuwanderer vom 11. bis zum 14. Jahrhundert sowie später im Rahmen der Eingliederung ins römisch-deutsche Reich wieder Bestandteil der deutschen Geschichte wurde.

Um 500 v. Chr. war der Raum des heutigen Süddeutschland keltisch und derjenige des heutigen Norddeutschland germanisch besiedelt. Erste Erwähnung finden einige keltische und germanische Stämme bei den Griechen und Römern, beginnend wohl mit Poseidonios im 1. Jahrhundert v. Chr., in der folgenden Zeit unter anderem bei Caesar und Tacitus. Die Germanen selbst waren jedoch eine uneinheitliche Gruppe von verschiedenen Stämmen, die auch kein übergeordnetes Gemeinschaftsgefühl verband. Bereits der Begriff „Germanen“ (lateinisch "Germani") ist ein ethnographischer, wenig präziser Sammelbegriff antiker Autoren, die damit auch ein „Barbarenbild“ verbanden. „Germanen“ darf aus methodischen Gründen daher nicht als Begriff für ein einheitliches Volk missverstanden werden.

Die Germanen wanderten im Laufe der Jahrhunderte südwärts, sodass um Christi Geburt die Donau die ungefähre Siedlungsgrenze zwischen Kelten und Germanen war. Hierdurch gelangten keltische Orts- und Gewässernamen sowie keltische Lehnwörter in den germanischen Wortschatz. Nach der Eroberung Galliens durch Caesar im Gallischen Krieg wurden in der Regierungszeit des ersten römischen Kaisers Augustus Feldzüge im rechtsrheinischen Raum durchgeführt, wenngleich die Römer nach der Varusschlacht im Jahr 9 n. Chr. ihre Truppen schließlich wieder an den Rhein zurückverlegten und es seit Tiberius bei einzelnen Militäroperationen beließen. Von etwa 50 v. Chr. bis ins frühe 5. Jahrhundert n. Chr. gehörten die Gebiete westlich des Rheins und südlich der Donau zum Römischen Reich, von etwa 80 bis 260 n. Chr. auch ein Teil Hessens (Wetterau) sowie der größte Teil des heutigen Baden-Württemberg südlich des Limes. Die römischen Gebiete im heutigen Deutschland verteilten sich auf die Provinzen "Germania superior", "Germania inferior" und "Raetia". Auf die Römer gehen Städte wie Trier, Köln, Bonn, Worms und Augsburg zurück, die zu den ältesten Städten Deutschlands zählen. Die Römer führten Neuerungen in Hausbau und Handwerk ein. Zur Sicherung der Grenzen siedelten die Römer befreundete germanische Stämme in den Provinzen an. Auch Siedler aus allen Teilen des Römischen Reiches, insbesondere aus Italien, wanderten ein und wurden westlich des Rheins und südlich der Donau sesshaft. Eine erste Geschichte Gesamtgermaniens lieferte im Jahr 98 der römische Geschichtsschreiber Tacitus.

Nachdem bereits Mark Aurel im 2. Jahrhundert im Verlauf der Markomannenkriege schwere Abwehrkämpfe gegen Germanen zu bestehen hatte, nahm zur Zeit der Reichskrise des 3. Jahrhunderts der germanische Druck auf die römische Nordgrenze beträchtlich zu, während gleichzeitig im Osten das neupersische Sassanidenreich die römische Ostgrenze bedrohte. Die neuformierten tribalen Großverbände der Alamannen und Goten unternahmen immer wieder Einfälle in das Imperium, das um die Mitte des 3. Jahrhunderts den Höhepunkt der Krise durchlief. Zwar errangen römische Truppen wohl 235 in einem Feldzug des Maximinus Thrax im Harzgebiet noch einen Sieg, doch 259/60 mussten die rechtsrheinischen Gebiete aufgegeben werden (Limesfall). Ende des 3. Jahrhunderts hatte sich die Lage für das Imperium wieder stabilisiert, vor allem aufgrund der Reformen Diokletians und Konstantins, die außerdem erfolgreich die Grenzen sicherten. Dennoch kam es im Verlauf der Spätantike immer wieder zu militärischen Auseinandersetzungen zwischen Römern und Germanen.

Nach dem um 375 erfolgten Einfall der Hunnen nach Ostmitteleuropa änderte sich die Lage grundlegend. Die sogenannte Völkerwanderung, die im 5. Jahrhundert ihren Höhe- und im späten 6. Jahrhundert ihren Schlusspunkt fand, brachte die Völkerschaften im Osten, insbesondere die Germanen, in Bewegung und spätestens nach dem Rheinübergang von 406 das weströmische Reich in erhebliche Bedrängnis. Germanen stießen auf weströmisches Territorium vor und ergriffen schließlich von weiten Teilen des Westreiches (meistens mit Gewalt, teilweise aber auch durch Verträge) Besitz. Das Westreich war im Jahr 476, als der letzte Kaiser im Westen, Romulus Augustulus, abgesetzt wurde, faktisch auf Italien zusammengeschmolzen. Allerdings sind mehrere Aspekte der Völkerwanderung in der modernen Forschung umstritten. Die auf römisches Gebiet eingewanderten germanischen Stämme (die ethnisch oft recht heterogen zusammengesetzt waren) zogen bis nach Nordafrika und errichteten eigene Reiche. Das Vandalenreich in Nordafrika, das Burgundenreich in Südostgallien und das Ostgotenreich in Italien gingen bereits im 6. Jahrhundert unter, während das Westgotenreich in Hispanien und das Reich der Langobarden in Italien (wo diese 568 eingefallen waren) bis ins 8. Jahrhundert bestehen blieben. Am dauerhaftesten und bedeutendsten sollte sich das um 500 errichtete Frankenreich der Merowinger erweisen. Daneben existierten teilweise bis ins 6. Jahrhundert zahlreiche kleinere Herrschaftsgebilde, wie die der Heruler, Rugier und Gepiden, während die um die Mitte des 5. Jahrhunderts in Britannien eingedrungenen Angelsachsen mehrere Kleinreiche gründeten, bevor sich dort im 7. Jahrhundert eine dauerhaftere Herrschaftsordnung etablierte (Heptarchie).

In der historischen Forschung ist bis heute umstritten, ab wann von Deutschland und ab wann vom deutschen Volk gesprochen werden kann. In der älteren, stark national geprägten Forschung wurde die Gleichsetzung von Germanen mit den Deutschen im mittelalterlichen Reich postuliert. Dieser Ansatz ist sehr problematisch und wird in der neueren Forschung abgelehnt, denn es wird dabei auch eine bewusste Eigenidentität vorausgesetzt. In der modernen Forschung wird Ethnogenese hingegen nicht als biologischer und vielmehr als sozialer Prozess verstanden, in dessen Verlauf sich eine Identität im Rahmen eines komplexen Entwicklungsprozess erst langsam herausbildet. Hinzu kommt, dass eine Sprachgemeinschaft nicht einfach mit einer ethnischen Gemeinschaft gleichgesetzt werden kann. Die Auswertung der zeitgenössischen Quellen ergibt denn auch nicht das Bild von „deutschen Stämmen“, die sich im 9. Jahrhundert bewusst in einem eigenen Reich (dem Ostfrankenreich) zusammengeschlossen haben. Als Orientierungspunkt diente vielmehr bis weit ins 11. Jahrhundert hinein das Frankenreich.

Erst im 11. Jahrhundert taucht der Begriff "rex Teutonicorum" („König der Deutschen“) für den ostfränkischen/römisch-deutschen Herrscher auf, allerdings als Fremdbezeichnung durch anti-kaiserliche Kreise, denn die römisch-deutschen Herrscher haben sich selbst nie so bezeichnet. Für die mittelalterlichen römisch-deutschen Herrscher waren die deutschsprachigen Gebiete ein wichtiger Teil des Reiches, das aber daneben auch Reichsitalien und das Königreich Burgund umfasste. Aufgrund der Reichsidee, die die Anknüpfung an das antike Römerreich und eine heilsgeschichte Komponente beinhaltete, war der damit einhergehende Herrschaftsanspruch nicht national, sondern (zumindest theoretisch) universal ausgerichtet. 

In der folgenden Zeit diente als loser politischer Rahmen das Reich, als verbindende kulturelle Komponente die deutsche Sprache. Eine „deutsche Identität“ – die Idee, zu einer spezifischen, abgegrenzten Gemeinschaft zu gehören – entwickelte sich im breiten öffentlichen Bewusstsein lange Zeit nicht. Während in England und Frankreich mit ihren zentral organisierten Königsherrschaften die Tendenz zu „nationalen Königreichen“ neigte (wobei der Begriff Nation problematisch ist und Benedict Anderson zufolge nur als konstruierte „vorgestellte Gemeinschaft“ zu betrachten ist), dominierte im von partikularen Grundstrukturen geprägten römisch-deutschen Reich die universale Reichsidee, wenngleich Begriffe wie "deutsche Lande" in späteren Quellen durchaus belegt sind. Erst im Spätmittelalter begannen deutsche Gelehrte wie z. B. Alexander von Roes und Lupold von Bebenburg sich Gedanken über die Rolle „der Deutschen“ im Gefüge Europas und einer politischen Identität (biologische Kategorien spielten hier keine Rolle) zu machen, was aus einer Position politischer Schwäche des Reiches geschah, wobei die Überlegungen weiterhin stark mit der Reichsidee verknüpft blieben. Nun erst setzte der Prozess einer langsamen politischen Identitätsbildung im eigentlichen Sinne ein.

In die ehemaligen Siedlungsgebiete germanischer Stämme, die von diesen im Verlauf der Völkerwanderung verlassen worden waren, wanderten im 7. Jahrhundert bis zur Elbe-Saale-Linie slawische Gruppen ein. Fast im gesamten Raum östlich der Elbe wurde daher vom Frühmittelalter bis ins hohe Mittelalter slawisch gesprochen "(Germania Slavica)", in der Lausitz leben bis heute die slawischen Sorben.

Ein beträchtlicher Teil West- (im Wesentlichen das ehemals römische Gallien) und Teile des westlichen Mitteleuropas wurden ab dem frühen 6. Jahrhundert vom Frankenreich eingenommen, das heutige nordwestliche Deutschland wurde von den Sachsen beherrscht. Das Frankenreich war von den Merowingern gegründet worden und sollte sich als das bedeutendste germanisch-romanische Nachfolgereich des untergegangenen Weströmischen Reichs erweisen. Childerich I. hatte dafür die Grundlage gelegt, an die sein Sohn Chlodwig I. anknüpfte. Versuche der Merowinger, ihren Herrschaftsbereich östlich des Rheins weiter auszudehnen, hatten einigen Erfolg: Alamannen und Thüringer gerieten bereits im 6. Jahrhundert unter fränkische Vorherrschaft. Interne Machtkämpfe und die zunehmende Macht der Hausmeier verhinderten jedoch, dass sich im Merowingerreich ein starkes zentrales Königtum entwickelte. Dagobert I. konnte das Königtum noch einmal stärken, bevor die Merowinger im späten 7. Jahrhundert (so zumindest die traditionelle Lehrmeinung, allerdings beruhend auf spätere und parteiische Quellen) faktisch von den Karolingern entmachtet wurden, die seit 751 auch die fränkische Königswürde bekleideten.

Pippin der Jüngere bestieg 751 als erster Karolinger den fränkischen Königsthron. Der bedeutendste Karolinger war Pippins Sohn Karl der Große, der von 768 (allein seit 771) bis 814 regierte und seit 800 sogar die römische Kaiserwürde im Westen erneuern konnte. Karl führte Feldzüge gegen die Sachsen (die erst nach sehr harten und wechselhaft verlaufenden Kämpfen in den Sachsenkriegen besiegt werden konnten), gegen die Langobarden in Italien, die Awaren an der Südostgrenze und gegen die Mauren in Nordspanien, womit er die Grenzen des Frankenreiches erheblich ausdehnte. Kulturell erlebte das Reich ebenfalls einen lebhaften Aufschwung, der als karolingische Bildungsreform (oft auch eher unpräzise als "karolingische Renaissance") bezeichnet wird. Das Karlsreich, für das vor allem die Merowinger die Grundlage gelegt hatten, einte das Gebiet des kontinentalen Europa zwischen Atlantik, Pyrenäen, Ostsee und Alpensüdrand. Nach Karls Tod 814 wurde es 843 im Vertrag von Verdun unter seinen Enkeln dreigeteilt. Das Westfrankenreich sollte die Grundlage vor allem für die Entwicklung des Königreichs Frankreich bilden. Das Ostfränkische Reich ist eng mit der Geschichte des (erst im Spätmittelalter so genannten) Heiligen Römischen Reiches verknüpft und stellt faktisch die Keimzelle des späteren Deutschlands dar, ohne aber dass sich in dieser Zeit bereits eine deutsche Identität entwickelt hatte.

Mit der Teilung des Frankenreichs 843 begann sein Zerfall. Der Sohn Karls des Großen, Ludwig der Fromme, konnte dessen Einheit noch wahren. Als Nachfolger bestimmte er seinen ältesten Sohn Lothar I. Dieser bekam das Mittelreich und die Kaiserwürde, Karl der Kahle den Westteil und Ludwig der Deutsche den Ostteil. Nach dem Tod der Söhne Lothars I. wurde das einstige Mittelreich aufgeteilt unter Karl dem Kahlen und Ludwig dem Deutschen. Nach Ludwigs Tod 876 wurde dann das Ostfränkische Reich unter seinen drei Söhnen Karlmann, Ludwig dem Jüngeren und Karl dem Dicken ebenfalls aufgeteilt. 880 wurde die Grenze zum Westfränkischen Reich festgelegt, die das gesamte Mittelalter beinahe unverändert das Deutsche Reich von Frankreich scheiden sollte. Der ostfränkische König Karl der Dicke konnte nach dem Tod seiner Brüder und des westfränkischen Königs das Fränkische Reich nochmals kurze Zeit vereinigen, wurde aber nach kraftloser Herrschaft im Osten von seinem Neffen Arnulf von Kärnten, einem Sohn Karlmanns, 887 verdrängt. Mit Arnulfs Sohn Ludwig dem Kind starb 911 der letzte ostfränkische Karolinger. Um ihre eigene Macht nicht zu gefährden, wählten die Herzöge den vermeintlich schwachen Frankenherzog Konrad I. zu ihrem König (911–918).

Auf Konrad I. (911–918), der die karolingische Tradition nicht bewahren konnte, folgte der Sachsenherzog Heinrich I. aus dem Geschlecht der Liudolfinger („Ottonen“). Das Reich blieb bis zum Ende des Mittelalters geprägt vom Wahlkönigtum und dem Einfluss der Großen. In der neueren Forschung wird zwar die Bedeutung der Ottonenzeit für die Ausformung Ostfrankens betont, sie gilt aber nicht mehr als Beginn der eigentlichen „deutschen“ Geschichte. Der damit verbundene komplexe Prozess zog sich vielmehr mindestens bis ins 11. Jahrhundert hin.

Heinrich I. verteidigte das Reich gegen Einfälle von Ungarn und Slawen. Neben dem fränkischen Erbe trat nun immer mehr eine eigene gemeinsame Identität hervor. Zum Nachfolger bestimmte Heinrich I. seinen Sohn Otto I. Dieser versuchte zuerst, die neu entstandenen Stammesherzogtümer seiner Macht zu unterstellen. Zur Sicherung seiner Macht stütze er sich immer mehr auf die Kirche (Reichskirchensystem). 955 besiegte Otto die Ungarn in der Schlacht auf dem Lechfeld. 950 wurde Böhmen und ab 963 Polen zeitweise lehnsabhängig vom römisch-deutschen Herrscher. Otto erweiterte sein Herrschaftsgebiet um Teile Italiens. Nach der Heirat mit Adelheid von Burgund nannte er sich eine kurze Zeit König der Langobarden. 962 erreichte Otto endgültig seine Anerkennung als König von Italien und danach die Kaiserkrönung durch den Papst. In Süditalien geriet er in Konflikt mit dem byzantinischen Kaiser. Sein Sohn Otto II. heiratete schließlich die Kaisernichte Theophanu, Süditalien verblieb jedoch bei Byzanz. Otto II. erlitt 982 gegen die Sarazenen eine vernichtende Niederlage. Die Gebiete östlich der Elbe (Billunger Mark und die Nordmark) gingen im großen Slawenaufstand größtenteils für etwa 200 Jahre wieder verloren. Sein Sohn Otto III. starb, bevor er seinen Plan verwirklichen konnte, die Machtbasis nach Rom zu verlegen. Auf dem Kongress von Gnesen im Jahre 1000 erkannte er den polnischen Herrscher Boleslaw I. Chrobry als Mitregenten im Reich an. Der letzte Ottonenkönig Heinrich II. hatte sich in mehreren Kriegen gegen Polen (König Boleslaw I. Chrobry) und Ungarn (König Stephan I.) zu behaupten. Unter ihm wurde das Reichskirchensystem weiter ausgebaut.

1024 wählten die deutschen Fürsten den Salier Konrad II. zum König. Er erwarb 1032 das Königreich Burgund und stabilisierte die Königsmacht. Sein Nachfolger Heinrich III. setzte auf der Synode von Sutri drei rivalisierende Päpste ab, ernannte den Reformer Clemens II. zum Papst und ließ sich von ihm 1046 zum Kaiser krönen. Kurz darauf erließ er ein Verbot der Simonie. Gegen Heinrichs selbstbewusste Herrschaftsausübung entstand aber auch eine Opposition im Reich, was der Beginn einer Krise der salischen Monarchie war. Während der Regierungszeit Heinrichs IV. eskalierte der sogenannte Investiturstreit, in dem die Kirchenreformer dem Kaiser Simonie vorwarfen. Heinrich erklärte Papst Gregor VII. für abgesetzt, gleichzeitig formierte sich im deutschen Reichsteil eine Opposition. Nun bannte der Papst den König. Um den Kirchenbann zu lösen, unternahm Heinrich IV. den Gang nach Canossa. 1084 setzte er Papst Gregor wiederum ab und ließ sich in Rom von Gegenpapst Clemens III. zum Kaiser krönen. Sein Sohn Heinrich V. verbündete sich schließlich mit den Fürsten gegen ihn und setzte ihn ab. Ein längerer Krieg wurde durch den Tod des Vaters 1106 verhindert. Unter Heinrich V. kam es 1122 im Wormser Konkordat zum Ausgleich mit der Kirche. Die Machtstellung der salischen Monarchie hatte aber nicht unerheblich gelitten.

Im 11. Jahrhundert etablierte sich "regnum teutonicum" („Deutsches Königreich“) als Begriff und erhielt im Investiturstreit politische Konturen. Der Begriff wurde jedoch weniger von den römisch-deutschen Königen, die vielmehr stets den universalen Charakter des Reichs betonten, sondern vor allem von dessen politischen Gegenspielern (wie dem Papsttum) eher abwertend benutzt.

Mit Heinrichs Tod endet die Salierzeit und die Fürsten wählten Lothar III. von Supplinburg zum König. Nach dem Tod Lothars 1138 wurde der Staufer Konrad III. König. Dieser erkannte Lothars Schwiegersohn, dem Welfen Heinrich dem Stolzen, dessen Herzogtümer ab. Konrads Nachfolger Friedrich I. („Barbarossa“) versuchte den Ausgleich, indem er den Welfen Heinrich den Löwen 1156 mit den Herzogtümern seines Vaters, Sachsen und Bayern, belehnte. Heinrich der Löwe unterwarf als neuer Lehnsherr von 1147 bis 1164 die Slawen in Mecklenburg und Pommern.

Im Vertrag von Konstanz 1153 erreichte Friedrich I. die Kaiserkrönung, die 1155 erfolgte. Er besiegte anfangs die nach mehr Selbständigkeit strebenden lombardischen Städte, konnte sich aber nicht dauerhaft gegen sie durchsetzen. Als Alexander III. Papst wurde, begann der Kampf zwischen Kaiser und Papst erneut. Nach der Niederlage bei Legnano musste Friedrich Alexander als Papst und den Lombardenbund anerkennen. 1180 entzog Friedrich Heinrich dem Löwen, der seine Italienpolitik nicht mehr unterstützte, dessen Herzogtümer. Am Ende musste Friedrich, der den "honor Imperii" betonte, politisch mehrere Zugeständnisse an die Großen des Reichs machen. Ab 1187 übernahm Friedrich I. die Führung der Kreuzfahrer. 1190 starb er in Syrien.

Friedrichs Sohn Heinrich VI. wurde dank der Heirat mit der normannischen Prinzessin Konstanze 1194 König von Sizilien. Als Heinrich VI. 1197 starb, kam es zu einer Doppelwahl des Staufers Philipp von Schwaben, des Bruders von Heinrich VI., und des Welfen Otto IV., eines Sohns Heinrichs des Löwen. Nach der Ermordung Philipps 1208 wurde Otto IV. König. Der Papst unterstützte aber wegen Ottos Italienzug den Staufer Friedrich II., den Sohn Heinrichs VI., der 1212 zum Gegenkönig gewählt wurde. 1214 brachte die Schlacht bei Bouvines die Entscheidung für Friedrich, der 1220 die Kaiserkrone erlangte. Friedrich regierte sein Reich von seiner Heimat Sizilien aus, wo er auch über wesentlich mehr politische Macht verfügte als dies im deutschen Reichsteil der Fall war. Die Regierung in Deutschland überließ er seinem Sohn Heinrich. 1235 setzte er statt Heinrich dessen Bruder Konrad IV. ein. Es kam aufgrund der Italienpolitik Friedrichs und des politischen Machtanspruchs beider Seiten zum Machtkampf mit Papst Gregor IX., der den Kaiser 1227 bannte. Dennoch erreichte Friedrich im Heiligen Land die Übergabe Jerusalems. Der Konflikt setzte sich auch fort, als Innozenz IV. Gregors Nachfolge antrat. Innozenz erklärte den Kaiser 1245 gar für abgesetzt. Friedrich II. starb im Dezember 1250. Nach seinem Tod tobte der Kampf des Papstes gegen die Staufer weiter. Konrad IV. konnte sich im Königreich Sizilien behaupten, starb aber 1254. 1268 wurde der letzte Staufer, der sechzehnjährige Sohn Konrads IV., Konradin, im Kampf um sein sizilianisches Erbe gegen Karl von Anjou in Neapel öffentlich hingerichtet.

Das Spätmittelalter (circa 1250 bis 1500) wird in der neueren Forschung im Gegensatz zur älteren Lehrmeinung nicht mehr als Niedergangszeit begriffen. Die Zeit bis ins späte 14. Jahrhundert war stark vom Wahlkönigtum geprägt: Drei große Familien, die Habsburger, die Luxemburger und die Wittelsbacher, verfügten über den größten Einfluss im Reich und über die größte Hausmacht. Es kam zwar zu Krisen wie Hungersnöten aufgrund von Überbevölkerung (siehe auch Spätmittelalterliche Agrarkrise), Pestausbrüchen (Schwarze Tod), dem rund ein Drittel der Bevölkerung zum Opfer fiel, anti-jüdischen Pogromen und zum abendländischen Schisma. Aber im Spätmittelalter florierten auch die Städte und der Handel mit der expandierenden Hanse, es kam zu grundlegenden politischen Strukturierungen und es begann der Übergang in die Renaissance.

Nach dem Ende der Staufer verfiel die Königsmacht. Das Königtum stützte sich nur noch auf ein geringes Reichsgut, das vor allem während des 14. Jahrhunderts durch Reichspfandschaften weitgehend verloren ging. Der König musste nun versuchen, seine Hausmacht zu erweitern und damit Politik zu machen. Als neuer Machtfaktor erwiesen sich inzwischen die Reichsstädte. Eine Gruppe mächtiger Reichsfürsten (die späteren Kurfürsten) wählten in einer verfassungsrechtlich bemerkenswerten Doppelwahl sowohl Richard von Cornwall aus England als auch Alfons von Kastilien zum König. Dies verschaffte den Wählenden die Möglichkeit, ihre eigene Macht weiter auszubauen, wenngleich die Forschung betont, dass die Kurfürsten gegenüber den Reichsinteressen keineswegs desinteressiert waren. Beide Gewählten waren aber zu schwach, sich im Reich durchzusetzen, und strebten eher nach der Kaiserkrone. Richard war ganz selten im Reich, Alfons hat es nie betreten. Zeitgenossen sprachen schon damals vom „Interregnum“, der königslosen Zeit, doch wird dieser Zeitraum in der neueren Forschung differenzierter beurteilt, zumal es zu keinem Zusammenbruch des Reiches kam.

Das Interregnum wurde 1273 durch die Wahl Rudolfs von Habsburg beendet. Seit dieser Zeit waren die Kurfürsten das exklusive Wahlgremium und beanspruchten auch Mitwirkungsrechte. Rudolf ebnete dem Haus Habsburg den Weg, auf dem es zu einer der mächtigsten Dynastien im Reich wurde. Er konnte die Königsmacht wieder konsolidieren und effektiv Handlungsspielräume nutzen, doch gelang es ihm nicht, Kaiser zu werden. Seine beiden Nachfolger, Adolf von Nassau und Albrecht I., standen im Konflikt mit den Kurfürsten aufgrund ihrer expansiven Hausmachtpolitik. 1308 wurde der Luxemburger Heinrich VII. zum König gewählt. Dieser konnte 1310 seine Hausmacht um Böhmen erweitern, das Haus Luxemburg stieg zur zweiten großen spätmittelalterlichen Dynastie neben den Habsburgern auf. Er betrieb in Anlehnung an die Staufer wieder eine Italienpolitik und wurde im Juni 1312 in Rom zum Kaiser gekrönt. Er starb im August 1313 in Italien.

Nach dem Tod Heinrichs setzte sich nach einer Doppelwahl 1314 der Wittelsbacher Ludwig der Bayer gegen die Habsburger durch. 1327 zog Ludwig nach Italien und wurde im darauffolgenden Jahr in Rom zum Kaiser gekrönt, allerdings ohne Mitwirkung des Papstes, der Ludwig die päpstliche Approbation verweigerte. Im Kampf des Kaisers gegen das Papsttum, dem letzten Kampf der beiden Universalgewalten des Mittelalters, bestätigten die Kurfürsten im Kurverein von Rhense 1338, dass ein von ihnen gewählter König nicht vom Papst bestätigt werden müsse. Eine von den Luxemburgern geführte Opposition gegen Ludwigs Hausmachtpolitik formierte sich 1346. Der Luxemburger Karl IV. wurde von seinen Anhängern mit Unterstützung des Papstes zum Gegenkönig gewählt.

Der Tod Ludwigs 1347 verhinderte einen längeren Krieg. Karl IV. verlegte seinen Herrschaftsschwerpunkt nach Böhmen. Er gewann unter anderem die Mark Brandenburg zu seinem Hausmachtkomplex hinzu. Im Vertrag von Namslau 1348 erkannte Kasimir der Große von Polen die Zugehörigkeit Schlesiens zu Böhmen – und damit zum Heiligen Römischen Reich – an, versuchte später jedoch beim Papst, diesen anzufechten. 1348 wurde in Prag die erste deutschsprachige Universität gegründet. 1355 wurde Karl zum Kaiser gekrönt. Er verzichtete auf eine Weiterführung der Italienpolitik und gab auch im Westen teils Reichsrechte auf; das Reichsgut verpfändete er weitgehend, so dass die nachfolgenden Könige sich endgültig nur noch auf ihr Hausgut stützen konnten. Die Goldene Bulle von 1356 stellte bis zum Ende des Heiligen Römischen Reichs eine Art Grundgesetz dar und regelte die Wahlmodalitäten (einschließlich Mehrheitsprinzip). Ihr Hauptziel war die Verhinderung von Gegenkönigen und Thronkämpfen. Karl glaubte, die Machtstellung des Hauses Luxemburg zementiert zu haben, vor allem aufgrund seiner starken Hausmacht, doch gelang es den nachfolgenden Luxemburger Königen nicht mehr, effektiv darüber zu verfügen.

Unter dem Nachfolger Karls verfiel die Königsmacht endgültig. Wenzel, der ältere Sohn Karls IV., wurde 1400 von den vier rheinischen Kurfürsten wegen Untätigkeit abgesetzt. Nach dem Tod des Nachfolgers Ruprecht von der Pfalz aus dem Hause Wittelsbach 1410 wurde mit Wenzels Bruder Sigismund, der bereits König von Ungarn war, wieder ein Luxemburger gewählt. Sigismund war ein gebildeter und intelligenter Herrscher, doch verfügte er über keine ausreichende Machtbasis im Reich. Er erreichte zwar 1433 die Kaiserkrönung, war jedoch nicht in der Lage, das Königtum zu stabilisieren. Eine Reichsreform scheiterte an Eigeninteressen der Landesherrscher. Durch die Einberufung des Konzils von Konstanz konnte er allerdings das Abendländische Schisma beenden.

Mit dem Tod Sigismunds erlosch das Haus Luxemburg in männlicher Linie. Die Habsburger traten 1438 mit Albrecht die Nachfolge an. Von 1438 bis 1740 und von 1745 bis zum Ende des Reiches 1806 sollte das Haus Habsburg nun den römischen König stellen. Unter der langen Regierung von Friedrich III. (1440–1493) wurde der Grundstein für die spätere habsburgische Weltmachtpolitik gelegt. Gleichzeitig durchlief das Reich einen Struktur- und Verfassungswandel, wobei in einem Prozess „gestalteter Verdichtung“ (Peter Moraw) die Beziehungen zwischen den Reichsgliedern und dem Königtum enger wurden.

Maximilian I. erwarb durch Heirat die Besitzungen des Hauses Burgund, zu denen unter anderem die reichen Niederen Lande gehörten, für sein Haus und behauptete große Teile davon im Krieg gegen Frankreich (Frieden von Arras). 1495 beschloss der Wormser Reichstag eine Reichsreform. Maximilians Sohn Philipp der Schöne wurde 1496 mit der Erbin Spaniens vermählt. Maximilian nahm 1508 ohne päpstliche Krönung den Kaisertitel an. Er beendete faktisch die Züge der römisch-deutschen Könige zur Kaiserkrönung nach Rom (sein Neffe Karl V. wurde aber noch vom Papst in Bologna gekrönt). Grund waren verschiedene schwelende Konflikte mit Frankreich und Venedig, dessen Truppen viele Alpenpässe versperrt hatten. Durch seine Heiratspolitik kamen neben der spanischen Krone auch Böhmen und Ungarn von den Jagiellonen zum Herrschaftsbereich der Habsburger.

Mit der Publikation seiner 95 Thesen gegen den Ablasshandel durch Martin Luther setzte 1517 die Reformation ein.

1519 wurde der Habsburger Karl V. zum König gewählt und nannte sich nach seiner Krönung im Jahre 1520 „erwählter Kaiser“; erst zehn Jahre später wurde er im Rahmen einer Aussöhnung als letzter deutscher Herrscher vom Papst gekrönt, diesmal nicht in Rom, sondern in Bologna. Unter Karl stieg Habsburg zur Weltmacht auf. Außenpolitisch war er in ständige Kriege zur Abwehr der Osmanen sowie gegen Frankreich und den Papst verwickelt. Dadurch war seine Stellung im Reich selbst schwach und er konnte die Ausbreitung der Reformation nicht verhindern.

In den Jahren 1522 bis 1526 wurde in etlichen Ländern und Städten des Reichs die Lehre Luthers eingeführt. Die Reformation erfolgte durch Landesherren, die auch zum Landesbischof wurden. Der Bruder des Kaisers, Ferdinand, wollte die Duldung der Lutheraner aufheben. Dagegen protestierten die evangelischen Landesfürsten. Daher leitet sich die Bezeichnung Protestanten für Anhänger der evangelischen Glaubensrichtung ab.

Die schlechte Lage der Bauern hatte schon im 15. Jahrhundert zu regionalen Aufständen geführt, während der Reformationszeit kam es 1524 bis 1526 zu einem Bauernkrieg. 1525 wurde ein Bauernheer unter Führung von Thomas Müntzer bei Frankenhausen vernichtet.

Im Schmalkaldischen Krieg von 1546/1547 kam es erstmals zum Kampf der Katholiken unter Führung des Kaisers gegen die Protestanten. Der Kaiser gewann den Krieg, konnte aber das Augsburger Interim nicht durchsetzen.

Als sich die Fürsten über die Religionsgrenzen hinweg gegen ihn erhoben, verzichtete Karl V. 1556 zugunsten seines Sohnes Philipp II. auf Spanien und machte seinen Bruder Ferdinand zu seinem Nachfolger im Reich. Der neue König hatte bereits 1555 den Augsburger Religionsfrieden ausgehandelt.

Unter dem Eindruck der Reformation begann die katholische Kirche eine innere Reform. Zudem setzte die Gegenreformation ein. Diese bestand zum einen in der Verfolgung von Zweiflern an der offiziellen päpstlichen Lehre durch die Inquisition, zum anderen entstanden neue Orden, von denen die Jesuiten eine führende Rolle bei der Rekatholisierung spielten.

Dennoch war die Religionspolitik von Ferdinands Sohn und Nachfolger Maximilian II. vergleichsweise tolerant, während in Frankreich zur selben Zeit Religionskriege wüteten. Die dezentralisierte Herrschaft im Reich erwies sich hierbei als vorteilhaft, da es in den jeweiligen Landesherrschaften unterschiedliche Konfessionen geben konnten, aber daraus wenigstens zunächst kein scharfer Gegensatz zum Kaisertum entstand, während in Frankreich das Königtum bestrebt war, ausschließlich die katholische Konfession durchzusetzen. Maximilians Sohn Rudolf II. zog sich dagegen in seiner Residenz Prag immer mehr aus der Wirklichkeit zurück, während die religiösen Konflikte sich zuspitzten. Es kam zum Kölner Krieg, als der dortige Erzbischof zum Protestantismus übergetreten war, und in den zum Reich gehörenden Niederlanden verschärfte sich der Widerstand gegen das streng katholische Regiment der spanischen Habsburger.

Die protestantischen Fürsten schlossen sich 1608 unter Führung Friedrichs von der Pfalz zur Union zusammen. Entsprechend schlossen sich die katholischen Fürsten 1609 unter Führung des Bayernherzogs Maximilian I. zur Liga zusammen.

Nachdem Kaiser Rudolf II. die Regierungsgeschäfte an seinen Bruder Matthias abgetreten hatte, schränkte dieser die den Protestanten gewährten Rechte wieder ein. 1618 kam es deshalb zum Prager Fenstersturz, bei dem zwei kaiserliche Räte von böhmischen Standesvertretern in der Prager Burg zum Fenster hinausgeworfen wurden.

Nach dem Tod des Kaisers wurde der Führer der Union, Friedrich von der Pfalz, 1619 zum König von Böhmen erklärt. Der neue Kaiser Ferdinand II. zog mit dem Heer der katholischen Liga nach Böhmen. In der Schlacht am Weißen Berge 1620 wurde das böhmische Heer besiegt. Nach der Flucht Friedrichs besetzte Tilly die Pfalz und die Oberpfalz. Der Bayernherzog Maximilian I. bekam die Pfälzer Kurfürstenwürde.

Der Dänenkönig Christian IV. rückte 1625 mit seinem Heer in Norddeutschland ein. Er wurde aber vom kaiserlichen Heer unter Tilly und dem böhmischen Adligen Wallenstein besiegt. Pommern, Jütland und Mecklenburg wurden vom katholischen Heer besetzt.

Nach dem Ende des Dänisch-Niedersächsischen Krieges erließ der Kaiser 1629 das Restitutionsedikt. Besorgt wegen seiner erheblich gestiegenen Machtfülle erreichten die Reichsstände auf dem Regensburger Kurfürstentag 1630 die Absetzung seines Feldherrn Wallenstein.

Nun griff der Schwedenkönig Gustav II. Adolf ins Kriegsgeschehen ein. Bei Rain fiel 1632 Tilly. Der Kaiser setzte daraufhin Wallenstein wieder ein. Bei der Schlacht von Lützen 1632 fiel der Schwedenkönig.

Wallenstein wurde 1634 erneut abgesetzt und bald darauf ermordet. Um die Schweden vom deutschen Boden zu vertreiben, schloss der Kaiser mit dem protestantischen sächsischen Kurfürsten 1635 einen Sonderfrieden, den Frieden von Prag.

Das katholische Frankreich griff 1635 auf schwedischer Seite ein, jedoch konnte keine der beiden Seiten den Krieg für sich entscheiden. Große Teile des Reiches wurden verwüstet. Die Vorkriegs-Einwohnerzahl wurde erst wieder um 1750 erreicht. Der neue Kaiser Ferdinand III. bemühte sich seit 1637 verstärkt um Friedensverhandlungen, aber Deutschland war längst zum Spielball fremder Mächte geworden, wodurch sich das Leid der Bevölkerung weiter verlängerte. Die seit 1642 laufenden Verhandlungen führten am 24. Oktober 1648 zum Westfälischen Frieden.

Der Friedensschluss beinhaltete eine Abtretung von Teilen Lothringens und des Elsass an Frankreich. Die Niederlande und die Schweiz schieden offiziell aus dem Reich aus. Die Stellung der Reichsstände und der Territorien wurde gestärkt und der Augsburger Religionsfriede bestätigt. Bei einem Konfessionswechsel des Landesherrn wurde nicht mehr von der Bevölkerung dasselbe verlangt. Die Macht des Kaisers wurde noch weiter eingeschränkt, seine Durchsetzungskraft beruhte in der Zukunft nur noch auf der Stellung seiner Dynastie.

Das Heilige Römische Reich zerfiel in 382 souveräne und halbsouveräne Territorien. Dieses Reichsgebilde wurde vom zeitgenössischen Staatsrechtler Samuel Pufendorf als „Monstrum“ oder „durch göttliche Fügung bewahrtes Unding“ bezeichnet. Pufendorf verwendete aber auch als einer der ersten die Bezeichnung „Deutschland“.

Die Zerstörungen und Bevölkerungsverluste des Dreißigjährigen Kriegs förderten die Entwicklung staatlich gelenkter Wirtschafts- und Sozialpolitik. Verbunden mit der merkantilistischen Wirtschaftsform war das Entstehen der absolutistischen Herrschaftsform nach Vorbild des französischen Königs Ludwig XIV.

Unter Kurfürst Friedrich Wilhelm begann seit 1640 der Aufstieg Brandenburg-Preußens. Der nachfolgende Kurfürst Friedrich III. ließ sich 1701 zum König Friedrich I. "in Preußen" krönen. Die Standeserhebung war möglich, weil er als Herzog in Preußen ein souveräner Herrscher außerhalb des Heiligen Römischen Reiches war. Gegen eine Zahlung von zwei Millionen Talern und die Entsendung eines Truppenkontingentes für die Reichsarmee erkannte der habsburgische Kaiser Leopold I. ihn innerhalb und außerhalb des Reiches als König an. Der Aufstieg des nun entstehenden brandenburg-preußischen Staates, später einfach nur "Preußen" genannt, führte zum Dualismus mit Österreich, der Deutschlands Innenpolitik bis 1866 bestimmen sollte.

Unter dem Habsburger Kaiser Leopold I. war das Reich der zweifachen Bedrohung durch die Osmanen und den Expansionsdrang Frankreichs unter Ludwig XIV. ausgesetzt. 1683 konnte der Kaiser mit Unterstützung einiger deutscher Fürsten und des Polenkönigs Jan III Sobieski, der die Schlacht am Kahlenberg bei Wien gegen Kara Mustafa gewann, die Türken vor Wien schlagen und aus Ungarn vertreiben.

Dadurch wurde ein Krieg gegen Frankreich verhindert, zu dem schon gerufen werden sollte. Frankreich hatte sich – die außenpolitische Gelegenheit nutzend – unter Ausschluss der verfassungsgemäßen Gegebenheiten die freie Reichsstadt Straßburg und andere elsässische Gebiete in sein Territorium einverleibt, obwohl diese Gebiete Reichsstände waren.

Durch die Wahl des sächsischen Kurfürsten Friedrich August I. 1697 zum König von Polen kam es bis 1763 zu einer Personalunion von Sachsen und Polen, die durch den Großen Nordischen Krieg und den Polnischen Thronfolgekrieg unterbrochen wurde. Ebenso gab es von 1714 bis 1837 eine Personalunion von Hannover und England.

Das Aussterben der spanischen Habsburger löste 1701 den Spanischen Erbfolgekrieg aus, der mit dem Tod von Joseph I. eine für Habsburg ungünstige Wende nahm, allerdings auch die Kräfte Frankreichs erschütterte. Das österreichische Haus Habsburg war unter Leopold I. und Joseph I. dennoch zur europäischen Großmacht geworden.

Das Aussterben der österreichischen Habsburger im Mannesstamm mit Kaiser Karl VI. führte 1740 zum Österreichischen Erbfolgekrieg. Der Wittelsbacher Karl VII. wurde zum neuen Kaiser gewählt, Friedrich II. fiel im habsburgischen Kronland Schlesien ein.

Karls VI. Tochter Maria Theresia konnte die Kaiserkrone für ihren Gemahl Franz I. zwar mit britischer Hilfe schließlich gegen preußische Hegemonialansprüche verteidigen, sie verlor aber im Siebenjährigen Krieg 1763 Schlesien endgültig an Preußen.

Schweden verlor durch seine Niederlage im Großen Nordischen Krieg (1700–1721) gegen Russland, Dänemark, Sachsen-Polen und Preußen fast alle Besitzungen im Reich. Durch die drei Teilungen Polens 1772, 1793 und 1795 kamen Österreich und Preußen zu erheblichen Gebietsgewinnen.

Die Aufklärung hielt Einzug in Preußen unter Friedrich dem Großen (der "Alte Fritz"), der nach den Prinzipien des aufgeklärten Absolutismus herrschte. Auch in Österreich unter Kaiser Joseph II. hielt die Aufklärung Einzug. Sie führte jedoch nicht zu Reformen, die die feudalen Machtverhältnisse erschütterten. Josephs Bruder und Nachfolger Leopold II. musste einen Teil der Reformen in den österreichischen Erblanden wieder zurücknehmen.

Als historische Epoche hat das 19. Jahrhundert Überlänge, indem es jeweils mit umwälzenden Ereignissen auch für die Geschichte Deutschlands schon 1789 anfängt und erst 1914 endet. Den Auftakt bilden die Französische Revolution und Napoleon Bonapartes zeitweilige Vorherrschaft über Europa; das Ende markiert der Ausbruch des Ersten Weltkriegs, mit dem nach einem Wort des damaligen britischen Außenministers Edward Grey in Europa die Lichter ausgingen. Für Deutschland war dieses lange Jahrhundert jene Epoche, in der Freiheit und Einheit der Nation als Bürgerforderungen den deutschen Fürsten präsentiert wurden und in der Revolution 1848/49 vorerst scheiterten, in der die industrielle Revolution neue wirtschaftliche, soziale und politische Strukturen hervorbrachte und in der mit Hilfe des preußischen Militärs unter Bismarcks politischer Leitung das Deutsche Kaiserreich zustande kam.

In der mit Freiheitspathos, allgemeinen Menschenrechten und gewaltenteilender Verfassung verbundenen Frühphase der Französischen Revolution wurden diese Errungenschaften auch in Deutschland teils enthusiastisch begrüßt. Man kannte und schätzte in gebildeten Kreisen französische Aufklärer wie Voltaire, Montesquieu und Rousseau. Die Radikalisierung des Revolutionsgeschehens in Frankreich bis hin zum Dauereinsatz der Guillotine gegen „Feinde des Volkes“ und Verdächtige führte außerhalb jedoch schnell zu weit überwiegender Ablehnung dieser Entwicklung. Die aus dem revolutionären Frankreich geflohenen adligen Emigranten schürten die gegenrevolutionäre Stimmung an den Höfen im Ausland. In der Pillnitzer Deklaration drohten Kaiser Leopold II. und König Friedrich Wilhelm II. von Preußen bereits mit militärischer Intervention zugunsten des französischen Königs Ludwigs XVI. In den nachfolgenden Koalitionskriegen gegen das französische Revolutionsheer gab es aber keinen durchschlagenden Erfolg. Vielmehr gelang es dem aus dessen Reihen hervorgegangenen General Napoleon Bonaparte, durch militärische Erfolge und politisches Geschick die Führung der Republik an sich zu reißen, sich alsbald zum Kaiser der Franzosen zu krönen und auch die politischen Verhältnisse in Deutschland in seinem Sinne neu zu ordnen.

Während die Franzosen als Nation in einem Staat geeint waren, bot das Heilige Römische Reich deutscher Nation eher ein Bild staatlicher Zersplitterung in die Territorien unterschiedlichster Größe der mehr als 300 Reichsstände. Als Kulturnation durch Sprache, Literatur und Geistesleben geeint, waren die Deutschen weit davon entfernt, eine Staatsnation zu bilden. Für Goethe war Deutschland nicht recht dingfest zu machen: „Wo das gelehrte beginnt, hört das politische auf.“

Mit dem Frieden von Lunéville 1801, der das ganze linksrheinische Gebiet Frankreich angliederte und Kompensationsansprüche deutscher Reichsstände zur Folge hatte, wurde Napoleon zum „Schiedsrichter über Deutschland“. Seinem politischen Gestaltungsanspruch unterlag folglich auch der Reichsdeputationshauptschluss 1803, durch den die katholischen Fürsten in Deutschland im Zuge der Säkularisation und Mediatisierung fast alle ihre Besitzungen verloren. Gebietszuwächse erlangten dabei vor allem Preußen, Bayern, Württemberg und Baden. Kurz nachdem Napoleon sich 1804 zum Kaiser der Franzosen gemacht hatte, erklärte sich Franz II. zum erblichen Kaiser von Österreich, da er als römisch-deutscher Kaiser bedeutungslos geworden war.

Mit dem Sieg Napoleons in der Dreikaiserschlacht bei Austerlitz 1805, der Gründung des Rheinbunds unter französischem Protektorat 1806 und der Niederwerfung Preußens durch Napoleon in der Schlacht bei Jena und Auerstedt sowie seinem anschließenden Einzug in Berlin nahm die Franzosenzeit in Deutschland forciert ihren Lauf. Die Sonderformation der Rheinbundstaaten setzte den Schlusspunkt unter die Auflösung des Alten Reiches, da Franz II. als römisch-deutscher Kaiser nun auch formal abdankte. Der Rheinbund, über den Napoleon militärisch wie außenpolitisch gebot, vollzog teilweise innere Reformen nach französischem Vorbild, wurde aber je länger desto deutlicher zu einem Instrument französischer Hegemonie im Dienste Napoleons. Preußen verlor im Frieden von Tilsit die Besitzungen westlich der Elbe und fast alle Gebietszuwächse aus den Teilungen Polens: Es wurde nahezu halbiert. Die auch durch die französische Besatzung sinnfällige Bedrohung seiner staatlichen Existenz bereitete aber auch den Boden für die Preußischen Reformen unter Stein und Hardenberg, die zumal für das Militär (Scharnhorst und Gneisenau), für die Wirtschaft sowie für das Bildungwesen (Wilhelm von Humboldt) neue Kräfte wecken und neue Ressourcen erschließen sollten.

Weil Napoleon Deutschland hauptsächlich als imperiale Rekrutierungsbasis der Grande Armée behandelte und zum Objekt finanzieller und wirtschaftlicher Ausbeutung machte, schlugen anfängliche Bewunderung für den Korsen oder relative Gleichgültigkeit um in Abneigung, Verbitterung und Hass auf die französische Okkupationsmacht. Die Verhängung der Kontinentalsperre gegen England durch Napoleon, die ein ausgedehntes Schmuggelwesen erzeugte, gegen das wiederum mit militärischen Mitteln repressiv vorgegangen wurde, ließ den allgemeinen Unmut weiter ansteigen. Man war ständig Kontrollen und Schikanen ausgesetzt, litt unter Teuerung und Versorgungsengpässen.

Erst Napoleons gescheiterter Russlandfeldzug ließ 1813 eine Lage entstehen, in der durch eine Koalition der anderen europäischen Mächte die Napoleon verbliebenen Truppen geschlagen und die französische Vorherrschaft in Deutschland wie in Europa beendet werden konnte. Das Signal für den Beginn der Befreiungskriege setzte der preußische General Yorck von Wartenburg, indem er am 30. Dezember 1812 ohne die Order seines noch mehrere Wochen zögerlichen Königs die Konvention von Tauroggen abschloss. Offiziell wurde die preußisch-russische Allianz Ende Februar 1813. Österreich trat erst im August 1813 in den Krieg gegen Napoleon ein, trug aber zu dessen Niederlage in der Völkerschlacht bei Leipzig wesentlich bei. Nun sagten sich auch die Rheinbundstaaten von Napoleon los, und bis zum Jahresende war ganz Deutschland befreit.

Als die europäischen Mächte auf dem Wiener Kongress darangingen, die Hinterlassenschaft der Ära Napoleons auch in Deutschland neu zu ordnen, suchte man die Balance zu halten zwischen einer Zersplitterung, die als Machtvakuum Begehrlichkeiten der westlichen wie der östlichen Nachbarmächte Frankreich und Russland hätte wecken können, und einer national geeinten deutschen Großmacht, die ihrerseits auf Expansionskurs hätte gehen können. Als für alle akzeptable Neuschöpfung entstand so der Deutsche Bund, kein Bundesstaat, sondern ein Staatenbund aus 41 souveränen Mitgliedern mit einem in Frankfurt am Main tagenden ständigen Gesandtenkongress, dem Bundestag, als einzigem gemeinsamen Organ. Mit den Königen von England, den Niederlanden und Dänemark waren einerseits auch ausländische Fürsten mit Territorialbesitz im Deutschen Bund vertreten; die Herrscher Österreichs und Preußens andererseits geboten zusätzlich über Gebiete außerhalb des Bundes.

Der betont restaurative Charakter der Beschlüsse des Wiener Kongresses zeigte sich besonders in der von Zar Alexander I. initiierten Heiligen Allianz, in der die europäischen Herrscher einander Verbundenheit und wechselseitigen Beistand bezeugten und darin übereinstimmten, ihre Völker in väterlichem Sinne christlich und friedlich zu regieren. „Die Heilige Allianz ist kein Instrument realer Politik der europäischen Mächte, aber sie wird ein Symbol der konservativen, der antirevolutionären Restauration und Stabilisierungspolitik.“ In der politischen Praxis gingen die beiden Großmächte innerhalb des Deutschen Bundes, Österreich mit Metternich an der Spitze und Preußen, besonders entschieden auf Restaurationskurs. So löste Friedrich Wilhelm III. von Preußen zur allgemeinen Enttäuschung aller Reformanhänger sein wiederholtes Versprechen nicht ein, Preußen zu einem Staat mit Verfassung zu machen, während in Süddeutschland eine ganze Reihe von Verfassungsstaaten entstanden. Das hatten sich viele der Freiwilligen anders vorgestellt, die für Freiheit und Einheit des Vaterlands in die Befreiungskriege gezogen waren.

Die Proteststimmung konzentrierte sich in den studentischen Burschenschaften und kam in öffentlichen Manifestationen zum Ausdruck, so beim Wartburgfest 1817, wo neben den Forderungen nach nationaler Einheit und konstitutioneller Freiheit auch solche gegen den Polizeistaat und die feudale Gesellschaft geäußert wurden. Die Ermordung des Schriftstellers August von Kotzebue, der die Burschenschaften verspottet und die russische Regierung mit Berichten über jakobinische Tendenzen an deutschen Universitäten versorgt hatte, durch den Theologiestudenten Karl Ludwig Sand sowie ein weiteres Attentat mit burschenschaftlich-radikalem Hintergrund wurden zum Anlass für die von Metternich betriebenen Karlsbader Beschlüsse 1819. Diese führten zum Verbot der Burschenschaften, zur Überwachung der Universitäten auch hinsichtlich staatsfeindlicher Lehre, zu ausgedehnter Zensur von Druckerzeugnissen und zur „Exekutionskompetenz gegen widerspenstige oder revolutionäre Gliedstaaten“ des Deutschen Bundes. „Indem jede freie Bewegung abgewürgt und unterdrückt wurde, konnte sich kein politisches Leben, Öffentlichkeit und Verantwortung bilden, keine großen Ziele und keine konkreten Aufgaben, kein freies Wechselspiel der verschiedenen Kräfte.“

Das deutsche Leben wurde ins Innerliche abgedrängt, in Kunstverehrung, Wissenschaft oder Geschichte, in eine weitgehende Entpolitisierung jedenfalls. Bürger, die ihre politische Protesthaltung nicht im Untergrund hochhalten oder theoretisch vertiefen wollten, widmeten sich verstärkt dem Privatleben in Haus und Familie. Kleinheit, Überschaubarkeit und Gemütlichkeit gehörten zum Biedermeier-Ambiente und prägten das Zusammenleben. Der gemeinsame Sonntagsspaziergang der Familie wurde im bürgerlichen Milieu nun ebenso üblich wie der Weihnachtsbaum, das Weihnachtsliedersingen und die Hausmusik im kleinen Kreis.

Die Julirevolution von 1830 in Frankreich hatte auch weiter östlich Auswirkungen. So kam es zu einem vergeblichen Aufstand in Polen gegen Russlands Vorherrschaft und zu einem polnischen Emigrantenstrom nach Westen. In Deutschland löste sich die zwischenzeitliche Erstarrung des politischen Lebens. Eine deutliche Manifestation wiedererwachten öffentlichen Eintretens für Freiheit und Einheit war das Hambacher Fest 1832, wo im Zeichen schwarz-rot-goldener Fahnen unter dem Jubel der Menge Bekenntnisse zu einem geeinten, demokratisch-republikanischen Deutschland abgelegt wurden. Zwar blieben repressive Reaktionen nicht aus, aber es zeigte sich darin wie auch im Professoren-Widerstand der Göttinger Sieben 1837, dass das fortbestehende Regime der Karlsbader Beschlüsse nicht überall durchschlug.

In der Rheinkrise 1840, ausgelöst durch französische Ambitionen auf linksrheinische deutsche Territorien, fanden Bürger und Regierende in nationalem Selbstbehauptungsstreben zusammen. Das Kölner Dombaufest 1842 inszenierte Friedrich Wilhelm IV. von Preußen „als Bekenntnis zu deutscher Größe und zur Versöhnung der Konfessionen im Zeichen eines gemeinsamen kulturellen Erbes“, jedoch ohne die Bereitschaft, sein verfassungsloses „väterliches Regiment“ in Frage stellen zu lassen. Neben uneingelösten politischen Forderungen im Bürgertum waren für die Destabilisierung der Ordnung des Deutschen Bundes im Vormärz auch soziale Missstände ursächlich. Dem Bevölkerungswachstum zwischen 1815 und 1848 von 22 auf 35 Millionen Menschen (+59 Prozent) stand keine auch nur annähernd proportionale Steigerung der landwirtschaftlichen Produktion gegenüber, mit der Folge einer desolaten Versorgungslage. Pauperismus steht als Begriff und Zustandsbeschreibung für das Elend dieser Zeit. Kartoffelfäule und Getreidemissernten verschlechterten die Lage ab 1845 zusätzlich.

Als die Februarrevolution 1848, wiederum von Paris ausgehend, in Europa Wellen schlug, gab es deshalb eine breit gestreute Unzufriedenheit und Auflehnungsbereitschaft gegen die bestehenden Verhältnisse. In Wien wurde am 13. März Metternichs Rücktritt erzwungen, während der Kaiserhof seinen Sitz vorübergehend nach Innsbruck verlegte. In Berlin reagierte Friedrich Wilhelm IV. auf Barrikadenkämpfe und Revolutionstote in der Märzrevolution mit einem Aufruf, der Volksvertretungen auf ständischer Grundlage befürwortete, der mit der Formel schloss: „Preußen geht fortan in Deutschland auf.“ Die Regierungen in Deutschland ernannten liberale „Märzregierungen“, die wiederum entsprechend neue Gesandte in den Bundestag schickten. 500 Liberale und Demokraten aus ganz Deutschland bildeten am 31. März in Frankfurt am Main ein Vorparlament, das den erneuerten Bundestag beriet.

Der Bundestag ließ ein gesamtdeutsches Parlament wählen, die Deutsche Nationalversammlung in Frankfurt. Sie sollte einen Verfassungsentwurf für einen deutschen Bundesstaat erarbeiten, doch setzte schon im Juni 1848 eine vorläufige Reichsregierung ein, die Provisorische Zentralgewalt, die auch von den Staaten anerkannt wurde. Außerdem erließ die Nationalversammlung Reichsgesetze und gab den Bau der ersten gesamtdeutschen Flotte in Auftrag. Mittlerweile befand Deutschland sich nämlich in einem Krieg mit Dänemark um Schleswig-Holstein.

Der deutsche Bundesstaat sollte ursprünglich die Grenzen des Deutschen Bundes haben, zuzüglich der preußischen Ostprovinzen und Schleswigs. Das hätte eine großdeutsche Lösung bedeutet, weil große Teile Österreichs zum Bundesgebiet gehört hatten. Diese weithin begrüßte Lösung erwies sich aber als unmöglich, als die österreichische Monarchie im Herbst 1848 wieder erstarkte. Im März 1849 war überdeutlich, dass das zentralistische Österreich es nicht erlauben würde, dass nur Teile sich einem deutschen Bundesstaat anschlossen. Außerdem gab der preußische König Friedrich Wilhelm IV. nur undeutliche Signale, ob er eine deutsche Kaiserkrone eines Kleindeutschland annehmen würde. Innerlich lehnte er sie sowieso ab, weil er lieber von den übrigen Fürsten zum Kaiser ausgerufen werden wollte.

Trotzdem wählte die Nationalversammlung den preußischen König zum Kaiser. Im Laufe des April 1849 erfolgte erst eine vorläufige, dann eine endgültige Ablehnung. Der König verbot daraufhin, wie auch andere Fürsten, seinen Untertanen rechtswidrig die Mitgliedschaft in der Nationalversammlung. Ein Teil der Abgeordneten machte dennoch weiter; viele von ihnen sind dafür verfolgt worden. Die im Zusammenhang mit einer Reichsverfassungskampagne stehenden Maiaufstände in Dresden, in der Rheinpfalz und in Baden wurden allerdings niedergeschlagen; die letzten Revolutionäre ergaben sich am 23. Juli in Rastatt.

Der verbleibende Ertrag und wesentliche Rezeptionsaspekte der gescheiterten Revolution von 1848/49 lagen vornehmlich auf der Verfassungsebene: Zum einen kam nun auch in Preußen der Konstitutionalisierungsprozess in Gang. Zum anderen wurden mit der am 28. März 1849 kurzzeitig in Kraft getretenen Paulskirchenverfassung etwa bezüglich der Grundrechte und der Bundesstaatlichkeit erstmals für Deutschland Normen gesetzt, die später in der Weimarer Verfassung von 1919 und im Grundgesetz für die Bundesrepublik Deutschland von 1949 verwirklicht wurden.

Ob die Niederlage des deutschen Liberalismus 1848/49 in einen deutschen Sonderweg mündete, der Deutschland weg von freiheitlichen Traditionen des Westens und letztlich in den Zivilisationsbruch der NS-Zeit führte, wird in der Geschichtswissenschaft kontrovers diskutiert.

Mit dem doppelten Scheitern der Frankfurter Nationalversammlung erst an der österreichischen, dann auch an der preußischen Reaktion waren nun auch die von der Revolution inspirierten liberalen Verfassungen hinfällig und wurden durch obrigkeitsgefälligere Modelle abgelöst. Zu einem Dauerkonflikt für anderthalb Jahrzehnte wurde die Rivalität der beiden Großmächte um die Führungsrolle in Deutschland. Wirtschaftspolitische Voraussetzungen und Entwicklungsprozesse spielten dabei eine wichtige, die preußischen Ambitionen letztlich begünstigende Rolle.

Ab der Mitte des 19. Jahrhunderts kam die Industrielle Revolution in Deutschland verstärkt zum Zuge. Mit dem Deutschen Zollverein von 1834 waren über Preußen hinausgehend elementare Voraussetzungen zur Herstellung eines einheitlichen Wirtschaftsraumes geschaffen, in dem sich künftig auch politische Interessen bündeln ließen. Zur Förderung industriellen Wachstums waren neben weiträumigen Märkten auch verbesserte Transportwege und Nachrichtenkommunikation sowie ein mobiler Kapitalmarkt günstig. Maßgeblichen Anteil an dem sich beschleunigenden Industrialisierungsprozess hatte das energisch vorangetriebene Eisenbahnwesen, sei es beim Auf- und Ausbau des Schienennetzes oder bei der Herstellung von Lokomotiven, wie z. B. in den Borsigwerken. Im Ergebnis wurden die Transportkosten um bis zu 80 Prozent gesenkt und die allgemeine Mobilität gestärkt. Für Bodenschätze, Ernteerträge und Massenwaren konnten nun größere Märkte erschlossen werden. Ab der Jahrhundertmitte wurden Aktienbanken für die Finanzierung von Industrie und Handel typisch.

Der durch die Industrialisierung angestoßene Strukturwandel verlief in Preußen in mehrerer Hinsicht dynamischer als in Österreich. Neben ein höheres Bevölkerungswachstum auf preußischer Seite trat eine beschleunigt veränderte Beschäftigungssituation: Während in Österreich erst am Ende des 19. Jahrhunderts weniger als 60 Prozent der Bevölkerung in der Landwirtschaft tätig waren, bestand dieses Verhältnis in den außerösterreichischen Gebieten des Deutschen Bundes mehr als ein halbes Jahrhundert früher. „Die Standortnachteile bei Kohle und Eisen, das Fehlen verkohlbarer Kohle, die ungünstigen Verkehrsverhältnisse und vor allem die wesentlich geringere durchschnittliche Produktivität und Kaufkraft schon im Bereich des Agrarsektors – 40 Gulden pro Kopf und Jahr in der Monarchie, 78 Gulden im Zollverein (1852) – hatte ein unaufhaltsames Zurückfallen der österreichischen Wirtschaft zur Folge.“

Bis in die erste Hälfte der 1860er Jahre blieb aber die österreichische Diplomatie darin erfolgreich, die preußischen Ambitionen auf eine mindestens gleichrangige Führungsrolle in Deutschland abzuwehren. Während Preußen unmittelbar nach der gescheiterten Revolution mit der Bildung einer kleindeutschen Union unter preußischer Führung durchzudringen suchte, setzte Österreich auf Wiederherstellung des Deutschen Bundes und hatte dabei Russlands Unterstützung. Mit der Olmützer Punktation nahm Preußen von einer militärischen Auseinandersetzung Abstand und kehrte in den Deutschen Bund mit Österreich als "Präsidialmacht" zurück. Das österreichische Streben nach Schaffung eines mitteleuropäischen Wirtschaftsraums durch Beteiligung an Preußens Zollverein scheiterte jedoch am preußischen Widerstand und daran, dass die deutschen Mittelstaaten sich politisch zwar eher an Österreich hielten, wirtschaftlich aber vom Verbund mit Preußen profitierten.

Dass das Präsidieren im Deutschen Bund der äußeren Machtstellung Österreichs nichts nützte, wenn Preußen sich verweigerte, zeigte sich sowohl im Krimkrieg als auch im Zweiten Italienischen Unabhängigkeitskrieg, der für Österreich mit dem Verlust der Lombardei endete. Auch die vorübergehende Schwächung Preußens durch den inneren Konflikt um Heeresreform und Verfassung konnte Österreich gegen den Widerstand des nunmehr zum preußischen Ministerpräsidenten berufenen Otto von Bismarck nicht zur Festigung des Führungsanspruchs im Deutschen Bund nutzen. Bismarck formulierte ein kampfbetontes Programm: „Preußens Grenzen nach den Wiener Verträgen sind zu einem gesunden Staatsleben nicht günstig; nicht durch Reden und Majoritätsbeschlüsse werden die großen Fragen der Zeit entschieden – das ist der große Fehler von 1848 und 1849 gewesen –, sondern durch Blut und Eisen.“

Den Krieg gegen Dänemark um Schleswig führten beide Mächte 1864 gemeinsam und einigten sich danach auch in der Folgenregelung: Nach zunächst gemeinsamer Zuständigkeit für beide Herzogtümer kam Holstein 1865 unter österreichische, Schleswig unter preußische Verwaltung. Seit Anfang 1866 betrieb Bismarck in der Holstein-Frage eine auf Konfliktschürung angelegte Politik, die Preußens Führung in Deutschland zum Ziel hatte. Durch eine Allianz mit Italien und die Erlangung der Neutralität Napoleons III. konnte Bismarck auch Wilhelm I. für den Waffengang gegen Österreich gewinnen, das von den übrigen deutschen Staaten keine durchschlagende militärische Unterstützung erhielt. In dem knapp sechswöchigen Deutschen Krieg besiegte das preußische Lager zunächst die Österreich verbundenen deutschen Mittelmächte und in der Schlacht bei Königgrätz dann auch das österreichische Heer selbst. Um ein französisches Eingreifen zu vermeiden, begnügte sich Preußen im anschließenden Friedensschluss mit Österreichs Verzicht auf Mitwirkung in den deutschen Angelegenheiten, mit der endgültigen Auflösung des Deutschen Bundes sowie mit der Gründung eines Norddeutschen Bundes unter Führung Preußens nördlich der Mainlinie. Die süddeutschen Staaten erhielten die Möglichkeit, sich zu einem Südbund zusammenzuschließen, der allerdings nicht verwirklicht wurde.

Die Verfassung des Norddeutschen Bundes wie auch die unter preußischer Führung betriebene Wirtschafts- und Infrastrukturpolitik nahmen das nachfolgende Kaiserreich in mancher Beziehung voraus bzw. zielten darauf hin. Wie in der nachmaligen Verfassung des Kaiserreichs gab es einen Bundesrat mit starkem preußischen Übergewicht, einen Kanzler Bismarck, der in Personalunion die Funktionen des preußischen Ministerpräsidenten und des Außenministers vereinte, sowie einen Reichstag als Entscheidungsorgan über Gesetzgebung und Staatshaushalt. Die Anbindung der süddeutschen Staaten an den Weltmarkt war wesentlich auf die Nutzung preußischer Eisenbahnen und Wasserwege angewiesen. Durch Zollverein und zentralisierte Gesetzgebung wurde der wirtschaftliche und rechtliche Rahmen in den Mitgliedsstaaten des Norddeutschen Bundes vereinheitlicht.

Zum Frankreich Napoleons III., der für seine Neutralität im Preußisch-Österreichischen Krieg und für die Hinnahme von Preußens Machtzuwachs wenigstens mit Luxemburg hatte abgefunden werden wollen – was vor allem an England scheiterte –, bestanden zunehmend Spannungen, die hinsichtlich der spanischen Thronfolge eskalierten, als ein Kandidat aus dem Hause Hohenzollern, Leopold von Hohenzollern-Sigmaringen, dafür im Gespräch war. Die von Bismarck redigierte Emser Depesche provozierte Frankreichs Kriegserklärung. Auch im Deutsch-Französischen Krieg von 1870/71 behielt das preußische Militär die Oberhand (Schlacht bei Sedan) und schuf damit die Voraussetzungen zur Gründung des Deutschen Kaiserreiches, die mit der Krönung Wilhelms I. zum Deutschen Kaiser im Spiegelsaal von Schloss Versailles am 18. Januar 1871 vollzogen wurde. Nicht nur das mussten die Franzosen hinnehmen, sondern im Frieden von Frankfurt am Main als Kriegsverlierer zudem die Abtretung von Elsass und Lothringen sowie eine Kriegsentschädigung des Siegers in Höhe von fünf Milliarden Goldfranken.

Vor allem die süddeutschen Staaten Württemberg und Bayern ließen sich ihre Einbeziehung in das Kaiserreich mit Reservatrechten abgelten. Diese betrafen unter anderem Bier- und Branntweinsteuern sowie die Post- und Eisenbahnverwaltungen. Das deutsche Volk kam mit der Reichstagswahl vom 3. März 1871 erst ins Spiel, als die Weichen bereits gestellt waren. Die politische Orientierung und Interessenartikulation der Bürger vermittelten die Parteien, die in Deutschland von weltanschaulichen Grundsätzen geprägt waren und seit der Revolution 1848/49 ein Fünfparteiensystem aus Konservativen, rechten und linken Liberalen, Katholizismus und Sozialisten bildeten.

Als erste organisiert hervorgetreten waren im 19. Jahrhundert die Liberalen, die Freiheit und Einheit der Nation in einer Gesellschaft rechtsgleicher Bürger anstrebten: einen Nationalstaat mit liberaler Verfassung. An der Haltung gegenüber Bismarcks antiparlamentarischem Kurs bei der Budgetierung des preußischen Militärs schieden sich die Nationalliberalen von der älteren Fortschrittspartei. Die Konservativen traten im Rahmen der neuen Verfassungsordnung für die Vorrechte von Monarch, Regierung und ländlichem Grundbesitz ein, für Kirche, Militär und Adel. Die Interessen der anwachsenden Industriearbeiterschaft richteten sich seit der Gründung des Allgemeinen Deutschen Arbeitervereins (ADAV) durch Ferdinand Lassalle auf die Durchsetzung des allgemeinen Wahlrechts und die Verbesserung der Lebens-, Arbeits- und Lohnverhältnisse durch Machtzuwachs im staatlichen Institutionengefüge. Seit dem Gothaer Vereinigungsparteitag 1875 mit der SDAP bildeten die Sozialdemokraten eine geschlossene und weiter wachsende politische Bewegung. Die Existenz einer katholischen Volkspartei, des Zentrums, lässt sich mit der Minderheitslage der Katholiken in einer vornehmlich protestantisch und teils säkular geprägten Gesellschaft erklären, in der Katholiken – außer in Bayern – einem nichtkatholischen „Regierungsestablishment“ gegenüberstanden.

Bismarcks Stellung im politischen System war durch das Vertrauen Wilhelms I. gefestigt, aber auch seine Fähigkeit, mit den Fraktionen des Reichstags umzugehen. Das verschaffte ihm großen politischen Gestaltungsspielraum, den er mit wechselnden Partnern unter den Parteien zu nutzen wusste. Dabei ging es ihm um die Stabilisierung und Modernisierung des Reiches ebenso wie um die Konservierung politischer und gesellschaftlicher Hierarchien. Bei der Modernisierung handelte es sich unter anderem um Vereinheitlichung und Liberalisierung der Wirtschaftsordnung, um reichsweite Gewerbe- und Niederlassungsfreiheit, um die Vereinheitlichung des Rechtswesens, um Verwaltungsreformen und die Einführung der Verwaltungsgerichtsbarkeit, lauter Anliegen, für die Bismarck von den Liberalen unterstützt wurde. Das galt auch für sein Vorgehen im Kulturkampf gegen die Machtposition des katholischen Klerus, dessen Einfluss auf mehreren Ebenen durch die Reichsgesetzgebung zurückgedrängt wurde, speziell durch das Verbot politischer Aufwiegelung von der Kirchenkanzel herab, durch Beseitigung der geistlichen Schulaufsicht, Einführung der obligatorischen Zivilehe und Streichung von staatlichen Leistungen an den Klerus („Brotkorbgesetz“).

Als die französischen Kriegsentschädigungen, die ihren Teil zur wirtschaftlichen Blüte des Gründerbooms bis 1873 beigetragen hatten, aufgebraucht waren und es um eine Reform der Reichsfinanzverfassung, bald darauf zudem um die Einführung von Schutzzöllen ging, verschob sich die Bismarcks Gesetzesvorlagen mittragende Reichstagsmehrheit stärker auf die konservative Seite. Und als es Bismarck nach Attentaten auf Kaiser Wilhelm I. 1878 darum ging, die geeinte und als Systembedrohung angesehene Sozialdemokratie durch die Sozialistengesetze niederzuhalten, fand er dafür eine Reichstagsmehrheit aus Konservativen und Liberalen. Diesem bis 1890 bestehenden Repressionsinstrument stellte Bismarck in der Folge eine Sozialgesetzgebung mit Krankenversicherung (1883), Unfallversicherung (1884) und Rentenversicherung (1889) entgegen, die Lebensrisiken und Unmut in der Arbeiterschaft vermindern und zukunftsweisende Bedeutung haben sollte.

Außenpolitisch setzte Reichskanzler Bismarck nach der Krieg-in-Sicht-Krise 1875, in der Frankreich, Großbritannien und Russland gegen Deutschland zusammenwirkten, auf ein Defensivbündnis mit Österreich-Ungarn, das Russland möglichst nicht verprellen sollte (Rückversicherungsvertrag 1887) und damit die prekäre deutsche Mittellage in Anbetracht der sicheren Gegnerschaft Frankreichs durch eine elastische Friedenspolitik zu stabilisieren versuchte: „In jeder europäischen Krise, so stellte sich die Lage in der späten Bismarckzeit dar, spielte Berlin die Hinterhand, konnte bremsen, beruhigen, abwarten und sich nach Möglichkeit heraushalten.“ Die 1884 einsetzende deutsche Kolonialpolitik in Afrika und Ozeanien, wo sich Briten und Franzosen mit ihren Einflussgebieten bereits gegenüberstanden, führte in West-, Südwest- und Ostafrika sowie in der Südsee zwar nominell zu Landnahmen, die die Fläche des Reichsgebiets mehrfach überstiegen, stellte sich aber weder wirtschaftlich noch außenpolitisch als Gewinn dar und spielte in Bismarcks Politik alsbald kaum noch eine Rolle. Im Ernstfall waren die deutschen Kolonien nicht verteidigungsfähig, drohten aber, das Kaiserreich in unübersehbare Konflikte zu verwickeln.

Nachdem das Dreikaiserjahr 1888 nicht nur den Tod Wilhelms I., sondern auch den seines den Thron nur 99 Tage innehabenden Sohnes Friedrichs III. gebracht hatte, der liberalen politischen Vorstellungen nahestand, wurde dessen Sohn Wilhelm II. 29-jährig Deutscher Kaiser, der unverhohlen von der Vorstellung des „persönlichen Regiments“ geleitet war. Meinungsverschiedenheiten über die Beibehaltung des Sozialistengesetzes, wofür Bismarck stand, wurden zu einem Hauptgrund seiner Entlassung 1890. Seit der Berufung zum preußischen Ministerpräsidenten 1862 war Bismarck damit länger im Amt gewesen, als es seine vier Nachfolger bis zum Ersten Weltkrieg in der Summe sein würden (Leo von Caprivi (1890–1894); Fürst Chlodwig zu Hohenlohe-Schillingsfürst (1894–1900); Bernhard von Bülow (1900–1909) und Theobald von Bethmann Hollweg (1909–1917)).

Die dem „Gründerkrach“ folgende wirtschaftliche Depression hatte gesellschaftliche Rückwirkungen, die sich im vermehrten Auftreten von Interessenverbänden wie auch in innergesellschaftlichen Ab- und Ausgrenzungstendenzen zeigten. Politisch und gesellschaftlich diskriminiert waren nicht allein die Sozialdemokraten, sondern verstärkt auch wieder Juden, die nun oft als Semiten bezeichnet wurden. Das führte 1879 zur Gründung einer Antisemitenliga. Ebenfalls zu dieser Zeit erklärte Hofprediger Adolf Stoecker die Juden zu „einer Gefahr für das deutsche Volksleben“. Eugen Dühring publizierte im Jahr darauf ein Buch zur „Judenfrage“ als Rassen-, Sitten und Kulturfrage, beklagte darin das „Übel der Verjudung und Judenherrschaft für die modernen Völker“ und erwog Möglichkeiten der „Entjudung“.

Spätestens 1890 ging die deutsche Wirtschaftsentwicklung wieder in eine so ausgeprägte Wachstumsphase über, dass sogar von einem „ersten deutschen Wirtschaftswunder“ die Rede ist, zu dessen Leitsektoren Großchemie, Elektrotechnik und Maschinenbau gehörten. Beim Anteil an der Weltindustrieproduktion lag Deutschland 1913 an zweiter Stelle hinter den USA, im Welthandel ebenfalls auf dem zweiten Platz hinter Großbritannien. Für die Mehrzahl in der arbeitenden Bevölkerung verbesserte der Wirtschaftsaufschwung auch die Lebensverhältnisse um die Jahrhundertwende. Dies galt nicht zuletzt für die wachsende Industriearbeiterschaft, die ihre Interessen auch zunehmend gewerkschaftlich organisierte und vertreten ließ. Dagegen gab es in häuslicher Arbeit und traditionellem Handwerk kaum noch ein Auskommen.

Das wirtschaftlich prosperierende Kaiserreich dieser Zeit schien somit vielen gesellschaftlich einflussreichen Köpfen prädestiniert, sich auch weltpolitisch im Kampf um Märkte und Rohstoffe einen „Platz an der Sonne“ zu sichern. In Kombination mit der Neigung Wilhelms II. zum Auftrumpfen und zur Prestigesteigerung wurde daraus eine hyperaktive, unstete und wenig substantielle äußere Politik, die mit vielen Forderungen und Drohgesten vor allem Unruhe stiftete. Ein besonders markanter, an Bedeutung stetig zunehmender und letztlich fataler Aspekt deutscher Weltmachtpolitik war die Flottenrüstung, die Alfred von Tirpitz mit Unterstützung unter anderen des „Flottenkaisers“ und des Alldeutschen Verbandes vorantrieb. Dabei war "Navalismus" als Vorstellung, dass Weltmacht sich auf Seemacht gründete, seinerzeit international durchaus verbreitet. Dass aber das Kaiserreich in seiner prekären Mittellage zwischen den Mächten Frankreich und Russland, die untereinander einen Interessenausgleich herbeigeführt hatten und ein Bündnis eingegangen waren, mit seinem unverkennbar gegen England gerichteten, herausfordernden Flottenrüstungsprogramm sich diese etablierte Weltmacht auch noch zum Gegner machte, ist unter rationalen Gesichtspunkten kaum zu erklären.

Außer Österreich-Ungarn stand im Wesentlichen nur Italien noch für ein Bündnis zur Verfügung. Nach den Marokkokrisen, der Bosnienkrise und während der Balkankriegen bildete sich im Kaiserreich zunehmend die Vorstellung aus, eingekreist zu sein. Dies zeigte sich auf höchster Ebene im Kriegsrat vom 8. Dezember 1912, wo der Chef des Generalstabes von Moltke davon sprach, den für unvermeidlich gehaltenen Krieg je eher desto besser zu führen. Wilhelm II. sprach sich in erster Konsequenz bezüglich Marine und Heer für intensivierte Kriegsvorbereitungen aus, während der nicht anwesende Reichskanzler Bethmann-Hollweg einstweilen auf diplomatische Entschärfung der Lage setzte.

Während das durch den Aufstieg des Bürgertums, durch die Industrialisierung und die Rivalität der imperialistischen Mächte geprägte Zeitalter auch in Deutschland das erste Jahrzehnt des 20. Jahrhunderts überdauerte, endete die nachfolgende Epoche der verschärften globalen Konflikte des 20. Jahrhunderts, an denen Deutschland wesentlichen Anteil hatte, bereits am Ende der 1980er Jahre.

Die Bündniskonstellationen zwischen den europäischen Mächten und die Verwicklung des österreichisch-ungarischen Vielvölkerstaats in die seit längerem instabilen Verhältnisse auf dem Balkan (Balkankrise, Balkankriege) wirkten zusammen, als nach der Ermordung des österreichischen Thronfolgers Franz Ferdinand am 28. Juni 1914 in Sarajevo die k.u.k-Monarchie am 23. Juli Serbien vorsätzlich ein kaum annehmbares Ultimatum stellte. Dieses Vorgehen wurde begünstigt durch den „Blankoscheck“, den Wilhelm II. mit der deutschen Regierung dazu erteilt hatte. Am 28. Juli erklärte Österreich-Ungarn Serbien den Krieg; Deutschland folgte am 1. August mit der Kriegserklärung gegen Russland und am 3. August mit der gegen Frankreich. Der völkerrechtswidrige Einmarsch deutscher Truppen nach Belgien war der Anlass für die Kriegserklärung Großbritanniens an Deutschland am 4. August 1914. Somit entwickelte sich innerhalb weniger Tage aus einem Lokalkrieg der Erste Weltkrieg, die „Ur-Katastrophe des 20. Jahrhunderts“ (George Kennan). Angesichts der durch den Kaiser verkündeten Burgfriedenspolitik und der allgemeinen Mobilmachung zu Kriegsbeginn zerstoben zunächst alle Aktivitäten der Friedensbewegung in einer Welle der Kriegsbegeisterung großer Teile der bürgerlich-akademischen Schichten.

Die Kriegsschuldfrage ist bis heute umstritten; völkerrechtlich gilt nach wie vor die Setzung des Versailler Vertrages, wonach „Deutschland und seine Verbündeten als Urheber für alle Verluste und Schäden verantwortlich sind“. Nach einer Phase der gegenseitigen Schuldzuweisungen in den 1920er Jahren näherte man sich später auf internationaler Ebene der Deutung, dass Europa 1914 in den Krieg „hineingeschlittert“ sei ("„Europe slithered over the brink into the boiling cauldron of war“", so David Lloyd George im Jahre 1933). Infolge der Fischer-Kontroverse kam es seit den 1960er Jahren zu der Auffassung, dass zwar eine längerfristige Planung des Krieges seitens Deutschlands nicht nachweisbar, die unverantwortliche Politik der deutschen Regierung in der Julikrise aber ausschlaggebend für die Auslösung des Weltkriegs gewesen sei. Zum 100. Jahrestag des Kriegsbeginns sind andererseits eine Reihe von Veröffentlichungen erschienen, welche die Teilverantwortung Russlands, Serbiens und Frankreichs sowie der Gesamtheit der beteiligten Staaten wieder mehr in den Blickpunkt rücken und den Sinn einer Schuldzuweisung generell bezweifeln.

Als nach ersten militärischen Erfolgen des deutschen Heeres im Osten der mit dem Schlieffen-Plan verbundene Vorstoß im Westen ab September 1914 im Stellungs- und Grabenkrieg zum Erliegen kam, als die Materialschlachten zu hohen Verlusten an der Front führten und die Kriegswirtschaft zu Versorgungsengpässen und -notlagen in der heimischen Zivilbevölkerung, bröckelte die anfänglich geschlossene Unterstützung für die von der Obersten Heeresleitung (OHL) unter Paul von Hindenburg und Erich Ludendorff seit August 1916 zunehmend dominierte Reichsregierung. Zwar konnte 1917 im Friedensvertrag von Brest-Litowsk mit der aus der Oktoberrevolution in Russland hervorgegangenen Sowjetregierung ein aus Sicht der OHL vorteilhafter Frieden geschlossen werden; dennoch wurde mit dem Kriegseintritt der USA die Lage des deutschen Heeres im Westen entgegen der noch im Sommer 1918 optimistisch ausgerichteten Kriegspropaganda zunehmend unhaltbar.

Ende September 1918 überraschte die OHL die deutsche Öffentlichkeit mit der Forderung, die politisch Verantwortlichen müssten nunmehr umgehend Waffenstillstandsverhandlungen aufnehmen. Diese Wendung führte zur Oktoberreform, auf deren Grundlage erstmals eine parlamentarische Regierung gebildet wurde, die nun aber auch für den Ausgang des Krieges würde einstehen sollen. Kurzzeitig und einmalig in seiner Geschichte war Deutschland vom 28. Oktober bis zum 9. November 1918 eine parlamentarische Monarchie. Noch während der laufenden Bemühungen um einen Waffenstillstand erteilte die Seekriegsleitung den Befehl an die Flotte, zu einer auf den ehrenvollen Untergang angelegten letzten Schlacht gegen die Royal Navy auszulaufen. Diesem Befehl verweigerten die Schiffsbesatzungen in Wilhelmshaven und Kiel den Gehorsam, und der daraus sich entwickelnde Kieler Matrosenaufstand weitete sich aus zur Novemberrevolution der Arbeiter und Soldaten, die die Monarchie in Deutschland beseitigte und im Ergebnis der politischen Richtungskämpfe zur Ausbildung einer parlamentarischen Republik führte.

Inmitten der revolutionären Unruhen erfolgte am 9. November 1918 eine zweifache Ausrufung der Republik: durch Philipp Scheidemann mit parlamentarischer Zielsetzung, durch Karl Liebknecht mit sozialistischer Ausrichtung. Unter dem Druck der revolutionären Arbeiter- und Soldatenräte kam es zu einer Übergangsregierung bestehend aus je drei „Volksbeauftragten“ der Mehrheits- und der Unabhängigen Sozialdemokratie. Ein Reichsrätekongress im Dezember 1918 in Berlin machte aber mit großer Mehrheit den Weg frei für Wahlen zu einer Verfassunggebenden Nationalversammlung, erstmals mit Einschluss des Frauenwahlrechts. Da die Unruhen aber anhielten – im Januar 1919 wurde der Spartakusaufstand durch Freikorps-Truppen niedergeschlagen und dessen führende Köpfe Rosa Luxemburg und Karl Liebknecht ermordet –, verlegte man den Tagungsort der Nationalversammlung nach Weimar. Auch in dieser Hinsicht war die Weimarer Republik das Ergebnis anfänglicher Improvisationen.

Die Nationalversammlung hatte die Aufgabe, dem Deutschen Reich eine neue politische Ordnung zu geben, was in Form der am 14. August 1919 in Kraft getretenen Weimarer Verfassung geschah, und sie fungierte gleichzeitig als Parlament, stimmte über Gesetze und Haushaltsfragen ab, wählte ein neues Staatsoberhaupt (Reichspräsident Friedrich Ebert) und bildete eine breite Regierungskoalition, die sog. Weimarer Koalition, aus der am 13. Februar 1919 das Kabinett Scheidemann hervorging. Unter den sowohl innen- wie außenpolitisch äußerst schwierigen Nachkriegsbedingungen strebte es eine soziale Befriedung und die Umstellung der Kriegs- auf eine Friedenswirtschaft an. Umstritten waren bei dieser Neuordnung Sozialisierungsmaßnahmen in bestimmten Wirtschaftsbereichen wie auch Möglichkeiten und Ausmaß einer personellen Erneuerung in den Bereichen Verwaltung, Justiz und Militär, um mit den gesellschaftspolitischen Strukturen des Kaiserreichs zu brechen. Diesbezüglich wird mitunter von einer „unvollendeten Revolution“ gesprochen. Vorerst unumstritten waren hingegen die Einführung des Achtstundentags, die Anerkennung der Gewerkschaften und das Betriebsrätegesetz.

Zur inneren Zerreißprobe und dauerhaften Belastung der Weimarer Republik wurde die Auseinandersetzung um die Unterzeichnung der von den Siegermächten des Ersten Weltkriegs Deutschland auferlegten Bedingungen des Versailler Vertrags. Mit Gebietsabtretungen, Reparationsforderungen und Abrüstungsauflagen war zugleich das Eingeständnis gefordert, dass Deutschland und seine Verbündete „Urheber aller Verluste und aller Schäden“ seien, was als offizielles Schuldeingeständnis interpretiert wurde und in Deutschland ganz überwiegend als „Kriegsschuldlüge“ aufgefasst wurde. Um die deutsche Position in den Friedensverhandlungen nicht zusätzlich zu schwächen, blieben Dokumente, die die kaiserzeitliche politische Führung belasteten, mit sozialdemokratischer Unterstützung unter Verschluss. Als die Nationalversammlung unter ultimativem Druck der Siegermächte dem Vertrag schließlich doch zustimmte, trat Scheidemann als Regierungschef zurück.

Anhaltende politische Instabilität und republikfeindliche Tendenzen blieben Merkmale der Weimarer Republik in ihrer Frühphase: 1920 trieb der von oppositionellen Militärs initiierte Kapp-Putsch die Berliner Regierung zunächst in die Flucht, scheiterte jedoch am entschlossenen Widerstand und Generalstreik breiter Bevölkerungskreise. Die Ermordung Matthias Erzbergers 1921 und die Walther Rathenaus 1922 richteten sich nicht zuletzt gegen „Erfüllungspolitiker“ im Hinblick auf den Versailler Vertrag. Ebenfalls mit diesem hing die mehrseitig bedrohliche Existenzkrise der Weimarer Republik 1923 zusammen: Neben der durch Kriegsfinanzierung, Reparationspflichten und finanzpolitische Weichenstellungen bedingten Großen Inflation des Jahres 1923, in der das sparfreudige Bürgertum alle verbliebenen Geldreserven verlor, kam es in dem vom Ruhrkampf geschwächten Rheinland zu separatistischen Aktivitäten, im Hamburger Aufstand zu kommunistischen Machtkämpfen einerseits und zu kommunistischen Regierungsbeteiligungen in Sachsen und Thüringen andererseits. In München, das 1919 kurzzeitig von einer Räterepublik regiert worden war, fand am 9. November 1923 der Hitlerputsch statt.

Die Beendigung von Ruhrkampf und Großer Inflation gelang im Herbst 1923 durch eine Währungsreform unter dem kurzzeitigen Reichskanzler Gustav Stresemann, der im Zusammenwirken mit Reichspräsident Ebert auch die anderen Krisenherde unter Kontrolle brachte. Mit Hilfe des Dawes-Plans wurde ab 1924 eine relative Stabilisierung der Weimarer Republik erreicht. Dabei kam es in verbesserter Finanzlage unter anderem zum Infrastrukturausbau, zu Wohnungsbauprogrammen und 1927 zur Einführung der Arbeitslosenversicherung. Die Rede von den „goldenen zwanziger Jahren“ hat aber nicht in politisch oder wirtschaftlich glanzvollen Zeiten ihren Ursprung, sondern bezieht sich auf „die stürmische Entfaltung eines neuen Lebensgefühls und die eruptive Freisetzung schöpferischer geistiger Kräfte in einem kurzen Jahrzehnt denkbar weitgehender Freiheit und großer Vielfalt des geistig-künstlerischen Schaffens.“ Den diesen Aufbruch tragenden Kräften standen aber breite, konservative Strömungen gegenüber, die sich kulturpessimistisch und zivilisationskritisch zu der das kulturelle Klima der Weimarer Republik weitgehend bestimmenden künstlerischen und intellektuellen Avantgarde etwa in der Malerei, in Literatur und Theater oder in der Architektur verhielten.

Mit der Neuregelung der Reparationsbedingungen im Dawes-Plan, dem ein Zustrom amerikanischer Kredite und Investitionen nach Deutschland folgte, ging auch die außenpolitische Isolierung des Landes nach dem Ersten Weltkrieg zu Ende. In den Locarno-Verträgen sicherte das Deutsche Reich die Anerkennung der Westgrenzen gemäß Versailler Vertrag zu und wurde 1926 in den Völkerbund aufgenommen. Die diesen Verständigungsprozess gestaltenden Außenminister Frankreichs und Deutschlands, Briand und Stresemann erhielten dafür gemeinschaftlich den Friedensnobelpreis.

Ausdruck einer zunehmenden Rechtsverschiebung des politischen Spektrums in der Republik war nach dem Tod Friedrich Eberts die Reichspräsidentenwahl 1925, aus der Paul von Hindenburg als Sieger hervorging, jener nun bereits 77-Jährige, der die Dolchstoßlegende populär gemacht hatte. Andererseits kam es nach der Reichstagswahl 1928 zur Bildung einer großen Koalition der Parteien SPD, DDP, des Zentrums, der BVP und der DVP unter Führung des sozialdemokratischen Reichskanzlers Hermann Müller. Sie zerbrach im März 1930 im Streit um die Finanzierung der 1927 eingeführten Arbeitslosenversicherung, die seit Frühjahr 1929 unterfinanziert war. Hinzu kamen der Youngplan, der zwar die jährlichen Reparationszahlungen senkte, die Verantwortung für deren Transfer aber Deutschland selbst übertrug, und die durch den New Yorker Börsenkrach im Oktober 1929 ausgelöste Weltwirtschaftskrise, die den Zustrom amerikanischer Kredite nach Deutschland beendete. Ob der Bruch der Großen Koalition auf die divergierenden sozialpolitischen Positionen ihrer Flügelparteien SPD und DVP oder auf die erklärte Absicht von Reichspräsident und Reichwehrführung zurückzuführen ist, die SPD aus der Regierung zu drängen, ist seit 1957 umstritten.

Hindenburg ernannte den als Finanzpolitiker profilierten Zentrumsmann Heinrich Brüning zum Reichskanzler und unterstützte ihn in den Jahren 1930 bis 1932 mit allen Befugnissen, die ihm laut Weimarer Verfassung zu Gebote standen: Das Notverordnungsrecht nach Artikel 48 der Verfassung, die Möglichkeit der Reichstagsauflösung nach Artikel 25 mit nachfolgenden Neuwahlen und die Ernennung des Reichskanzlers ohne Wahl durch den Reichstag nach Artikel 53. Nachdem der Reichstag erstmals eine Notverordnung Brünings mit Mehrheit abgelehnt und dadurch aufgehoben hatte, wurde er aufgelöst, während Brüning blieb und in der Zeit bis zu den Neuwahlen wiederum per Notverordnung weiterregierte. Als die rechtsextreme Nationalsozialistische Deutsche Arbeiterpartei (NSDAP) bei den Septemberwahlen 1930 sprunghaft zu einer bedeutenden politischen Kraft im Reichstag anwuchs, entschloss sich die SPD bis auf Weiteres zur Tolerierung von Brünings Notverordnungsregime, während die oppositionellen Kräfte der äußersten Rechten sich in der Harzburger Front sammelten. Mit harten Sparprogrammen, Steuererhöhungen und Leistungskürzungen war Brüning um die Vermeidung einer neuerlichen Inflation und um Zugeständnisse des Auslands bei den Reparationen bemüht, verschärfte im Zuge der Bankenkrise damit aber noch die wirtschaftliche Rezession. Frankreich und Großbritannien irritierte er mit Plänen für eine Deutsch-österreichische Zollunion.

Nach der Reichspräsidentenwahl 1932 entzog ihm Hindenburg Ende Mai seine Unterstützung und berief statt seiner Franz von Papen zum Reichskanzler, der die antiparlamentarische Stoßrichtung des Präsidialregimes mit seinem „Kabinett der Barone“ noch verstärkte. Sein autoritärer Kurs gipfelte in dem Preußenschlag vom 20. Juli 1932, mit dem er die geschäftsführende Regierung unter sozialdemokratischer Führung absetzte und in Abstimmung mit Hindenburg selbst als Reichskommissar für Preußen an ihre Stelle einnahm. Im Reichstag hatte Papen kaum Unterstützer; seine Notverordnungen wurden, sofern der Reichstag nicht gerade aufgelöst war, mit drastischen Mehrheiten zurückgewiesen. Unter dem Eindruck der immer weiter massenhaft sich ausbreitenden Arbeitslosigkeit und sozialen Not in der Weltwirtschaftskrise radikalisierte sich das Wählerverhalten noch zunehmend. Die beiden 1932 vorgenommenen Reichstagsauflösungen führten in den Reichstagswahlen sowohl des Julis als auch des Novembers jeweils dazu, dass die NSDAP stärkste Kraft im Reichstag wurde und eine negative Mehrheit der Demokratiegegner mit den Kommunisten bildete, sodass republikanische Regierungsmehrheiten in weite Ferne rückten.

Da Papen auch nach der Novemberwahl im Reichstag auf brüske Ablehnung stieß, machte Hindenburg, indem er Adolf Hitler das Amt zunächst noch verweigerte, den Reichswehrgeneral Kurt von Schleicher zum Reichskanzler. Als aber dessen „Querfront“ scheiterte, mit der er Teile der NSDAP abspalten und für eine übergreifende Gewerkschaftsinitiative gewinnen wollte, fand sich Hindenburg unter dem Einfluss seiner Berater bereit, den von Papen und Hugenberg vermeintlich „eingerahmten“ Hitler am 30. Januar 1933 zum Reichskanzler zu ernennen.

Mit Hitlers Reichskanzlerschaft begann am 30. Januar 1933 der Weg in die nationalsozialistische Diktatur. Die zu diesem Ziel führenden Schritte waren in den Grundzügen bei Hitlers Amtsantritt bereits vorgesehen und wurden bei sich bietenden Gelegenheiten noch beschleunigt, sodass der Prozess der „Machtergreifung“ durch die Ausschaltung sowohl der politischen Gegner als auch der anfänglichen Regierungspartner unter Beseitigung hinderlicher Verfassungsbestimmungen binnen weniger Monate durchschlug. Einer erneuten Reichstagsauflösung durch Hindenburg am 31. Januar folgte als Reaktion auf KPD-Streikaufrufe schon am 4. Februar 1933 eine auf Einschränkung der Meinungs-, Presse- und Versammlungsfreiheit gerichtete Notverordnung. Der Reichstagsbrand am 27./28. Februar, für den die NS-Führung sogleich die Kommunisten als Brandstifter verantwortlich machte, bot vor der für den 5. März angesetzten Reichstagsneuwahl für eine noch viel umfassendere Notverordnung Anlass, die praktisch jeden Schutz politischer Grundrechte auf Dauer außer Kraft setzte, wie sich zeigen sollte. Mittels vorbereiteter Listen kam es umgehend zu einer Verhaftungswelle gegen profilierte NS-Gegner im linken Spektrum. Die unter diesen Umständen abgehaltene Reichstagswahl verschaffte zwar dem „Kabinett der nationalen Erhebung“ eine parlamentarische Mehrheit, nicht aber der NSDAP allein. Mit dem bei der Regierungsbildung verabredeten Ermächtigungsgesetz vom 24. März 1933, das nach Streichung der kommunistischen Mandate und der überwiegenden Zustimmung des Zentrums die nötige Zweidrittelmehrheit erhielt, wurde die Regierung und wurde insbesondere Reichskanzler Hitler von jeglicher parlamentarischen Zustimmung unabhängig, sogar hinsichtlich verfassungsändernder Gesetze. Auf dieser Grundlage setzte ein beschleunigter Gleichschaltungsprozess ein, der sich unter anderem auf die Länder, auf die Verwaltungsbehörden, die Gewerkschaften wie auf die politischen Parteien erstreckte. Am 14. Juli 1933, nach dem Verbot bzw. der Selbstauflösung sämtlicher Parteien außer der NSDAP, wurde diese zur gesetzlich einzig zugelassenen Partei in Deutschland. Die schon seit Februar 1933 in großer Zahl willkürlich festgenommenen NS-Widersacher wurden großteils in Konzentrationslagern inhaftiert.

Als attraktives Gegenbild zur Bekämpfung und Vernichtung ihrer tatsächlichen Gegner und vermeintlichen Feinde propagierten die Nationalsozialisten eine geschlossene Volksgemeinschaft, in der sich jeder nach Kräften nützlich machen und vorankommen sollte. Mit ihr und durch sie sollte der „Schandfrieden“ von Versailles getilgt werden und das Deutsche Reich zu neuer Kraft und Größe aufsteigen. Gesellschaftliche Standesunterschiede galt es zu beseitigen, die Gleichwertigkeit körperlicher und geistiger Arbeit anzuerkennen, die „Volksgenossen“ unterschiedlicher Herkünfte bei Gemeinschaftsaufgaben zusammenzuführen. Dazu dienten teilnahmepflichtige Organisationen wie Hitlerjugend, Bund Deutscher Mädel, Reichsarbeitsdienst, Wehrdienst und eine Vielzahl weiterer Einrichtungen, unter denen sich die Freizeit- und Reiseorganisation Kraft durch Freude (KdF) besonderer Beliebtheit erfreute. Für die Verbreitung und Durchsetzung der NS-Weltanschauung in allen Gliederungen von Staat und Volk war als Hauptinstrument das Reichsministerium für Volksaufklärung und Propaganda unter Joseph Goebbels zuständig, dem auch die Zensur der veröffentlichten Meinung in Schrift und Bild unterlag. Am 10. Mai 1933 war er der Hauptredner bei der Bücherverbrennung auf dem Opernplatz, die von Studenten der Friedrich-Wilhelms-Universität „wider den undeutschen Geist“ veranstaltet wurde. Gerade unter den Nachwuchsakademikern waren die NSDAP-Anhänger bereits zu Zeiten der Weimarer Republik besonders stark vertreten, stand die Partei in ihren Augen doch für die Überwindung verkrusteter Strukturen, für Modernität, Mobilität und Egalität: „Den hochgespannten Erwartungen, an dem großen Projekt einer Modernisierung Deutschlands unter den Auspizien eines dynamisierten Nationalismus selber teilnehmen zu können, entsprach offenbar glaubwürdig die messianische Vision eines – im Vergleich mit allen anderen Parteipolitikern – ganz ungewöhnlichen charismatischen «Führers» mit einer extraordinären «Willenspotenz» und der rhetorischen Fähigkeit, das Erreichen großartiger Ziele zu einer unumstößlichen Gewißheit zu erheben.“ Seit Anfang April 1933 gab es ein "Hauptamt für Presse und Propaganda der Vereinigten Deutschen Studentenschaften", das in einem Rundschreiben jeden Studenten aufforderte, seine und die Bibliotheken seiner Bekannten zu „säubern“ und dafür zu sorgen, dass „ausschließlich volksbewusstes Schrifttum darin heimisch ist.“

Wer dagegen von den Nationalsozialisten nicht zur Volksgemeinschaft gezählt wurde, ihnen unnütz erschien, abweichende Ansichten vertrat oder sich ihnen in den Weg stellte, wurde diskriminiert und verfolgt. Das galt, wie die politischen Morde im Zusammenhang mit dem angeblichen Röhm-Putsch zeigten, mit denen die SA zugunsten der Wehrmacht und zum Vorteil der SS entmachtet wurde, sogar für eine mögliche Opposition innerhalb der NSDAP gegen den Kurs Hitlers. Die christlichen Kirchen der Katholiken und der Protestanten ließ man gewähren, nachdem die Zentrumspartei als politischer Akteur verschwunden war und sofern nicht vereinzelt opponiert wurde. Mit dem Vatikan wurde ein Konkordat geschlossen, das unter anderem die Bekenntnisschulen und den katholischen Religionsunterricht zusicherte. Gegen Juden aber, die von den Nationalsozialisten als Schädlinge am „Volkskörper“ angesehen und ausgesondert wurden, kam es bereits im April 1933 zu einer organisierten Boykott-Aktion. 1935 wurden sie durch die Nürnberger Gesetze ausgebürgert, 1938 in und nach der Reichspogromnacht, in der randalierende uniformierte SA- und SS-Leute mehr als 1.400 Synagogen in Deutschland zerstörten, vielfach schwer und teils mit tödlichem Ausgang misshandelt und ihrer wirtschaftlichen Existenz beraubt. Zu Opfern der nationalsozialistischen „Rassenhygiene“ wurden außerdem Sinti und Roma sowie Deutsche mit Geisteskrankheiten oder angeborenen Behinderungen, denen das Gesetz zur Verhütung erbkranken Nachwuchses galt. Die NS-Propaganda bezeichnete solche Menschen als „lebensunwertes Leben“. Im Rahmen von „Euthanasie“-Maßnahmen wurden sie ab 1939 massenhaft umgebracht.

Begünstigt von der einsetzenden wirtschaftlichen Erholung und rückläufigen Arbeitslosigkeit – auch ungeachtet der spezifisch nationalsozialistischen Beschäftigungsprogramme, unter denen der Autobahnausbau das bekannteste ist – fanden die NS-Diktatur und ihr „Führer“ rasch wachsende Zustimmung, die Hitler auch durch markiges außenpolitisches Auftreten förderte und sich in Volksabstimmungen bestätigen ließ. Als bedeutende Schritte auf dem Weg zu neuer deutscher Größe wurden die Rückgliederung des Saarlands 1935, der Einmarsch deutscher Truppen in das gemäß Versailler Vertrag entmilitarisierte Rheinland 1936 und der Anschluss Österreichs im März 1938 angesehen und propagandistisch gefeiert. Gemäß seinem in „Mein Kampf“ niedergelegten Programm ging es Hitler aber darüber hinaus um die Eroberung von „Lebensraum“ für das Deutsche Volk im Osten durch die Unterwerfung der Sowjetunion. Bereits 1936 gab er einen geheimen Vierjahresplan aus mit der Vorgabe, binnen vier Jahren die Wehrmacht einsatzfähig und die deutsche Wirtschaft kriegsfähig zu machen. Die dafür nötige militärische Aufrüstung wurde durch verdeckte Staatsschulden finanziert, die nur aus Kriegsgewinnen hätten getilgt werden können. Schon im Herbst 1938 legte es Hitler in der Auseinandersetzung um das Sudetenland auf eine militärische Intervention mit weiter reichenden Optionen an, musste sich dann aber mit dem Münchner Abkommen begnügen. Mit dem Einmarsch deutscher Truppen in die „Rest-Tschechei“ und in das Memelland im März 1939 endeten die Appeasement-Politik und ungehinderte Expansion des NS-Staates. Für den Fall eines deutschen Angriffs auf Polen gaben Großbritannien und Frankreich eine Beistandsgarantie.

Mit dem überraschenden, die Vermeidung eines Zweifrontenkriegs begünstigenden Hitler-Stalin-Pakt erschien dem NS-Diktator der Überfall auf Polen als ein überschaubares Risiko. Am 1. September 1939 begann mit dem Polenfeldzug des Deutschen Reiches der Zweite Weltkrieg. Die Blitzkriegsmaschinerie war von Polen über Norwegen und im Westfeldzug so erfolgreich, dass Hitler trotz des am energischen Widerstand unter Winston Churchill gescheiterten Versuchs der Unterwerfung Englands für den 22. Juni 1941 den Angriff auf die Sowjetunion befahl. Der deutsche Vormarsch wurde von der weit unterschätzten Roten Armee mit Einbruch des Winters erst kurz vor Moskau gestoppt. Doch auch den gerade mit Japan in den Krieg eingetretenen USA erklärte der deutsche Diktator am 11. Dezember 1941 deutscherseits den Krieg. Die auf „Lebensraum“-Eroberung gerichtete militärische Ostexpansion des nationalsozialistischen Deutschland sah auch für die einheimische Zivilbevölkerung keinerlei Schonung vor. Vielmehr ging es – unter anderem durch Zwangsarbeit und Aushungern – um eine radikale Dezimierung der slawischen „Untermenschen“, an deren Stelle arische „Herrenmenschen“ als Kolonisten die Organisation der Nahrungsmittel- und Rohstoffversorgung für das künftige „Großgermanische Reich“ übernehmen sollten. Im Generalplan Ost war die „Verschrottung“ von 31 Millionen Slawen vorgesehen, im Protokoll der Wannseekonferenz die Vernichtung von 11 Millionen Juden. Zwischen 1941 und 1944 stieg die Zahl der nach Deutschland verschleppten Zwangsarbeiter von drei auf acht Millionen. Das dem Vernichtungslager Auschwitz-Birkenau angeschlossene Zwangsarbeiterlager Auschwitz-Monowitz gehörte zum oberschlesischen Chemie-Komplex, der Dimensionen annahm, die denen des Ruhrgebiets kaum nachstanden. Den Juden in Europa hatte Hitler bereits Anfang 1939 die Vernichtung angedroht. Seit September 1941 waren sie gezwungen, den Judenstern zu tragen. Auf der Wannseekonferenz im Januar 1942 wurden Zuständigkeiten und Organisation bezüglich der „Endlösung der Judenfrage“ beschlossen, nachdem der Holocaust mit den Morden der Einsatzgruppen der Sicherheitspolizei und des SD bereits im Juli 1941 begonnen hatte. Nach der Deportation in Ghettos wie Theresienstadt oder das Warschauer Ghetto wurde die Ermordung der Juden im besetzten Osten Europas seit Herbst 1941 mit Gaskammern und Verbrennungseinrichtungen auch industriell betrieben. Neben Auschwitz-Birkenau gehörten im Rahmen der „Aktion Reinhardt“ zu den großen Vernichtungslagern Belzec, Sobibor und Treblinka. Bis zum Kriegsende wurden etwa sechs Millionen europäische Juden ermordet, darunter über drei Millionen polnische Juden.

Nachdem die militärische Front des NS-Reiches und seiner Verbündeten 1942 ihre größte Ausdehnung im Osten erreicht hatte, setzte mit der verlorenen Schlacht um Stalingrad der Umschwung ein, der auf deutscher Seite in einen noch mehr als zwei Jahre währenden Krieg der erzwungenen Rückzüge, Zwischenoffensiven, Kapitulationsverbote und Durchhalteparolen mündete; und zwar nicht nur im Osten, sondern auch in Nordafrika und im Italien des verbündeten Faschistenführers Benito Mussolini; nach der angloamerikanischen Invasion in der Normandie im Juni 1944 schließlich auch im Westen. Seit 1943 tauchten lange nach jenen Luftangriffen, mit denen deutsche Bomber im Spanischen Bürgerkrieg zunächst Gernika, im Zuge der Luftschlacht um England dann vor allem London und Coventry verwüstet hatten, die alliierten Luftstreitkräfte vermehrt über deutschen Großstädten auf und richteten mit Spreng- und Brandbomben verheerende Schäden an. Das bis zuletzt verschonte Dresden wurde noch im Februar 1945 in Schutt und Asche gelegt.

Der Widerstand gegen das NS-Regime blieb auch angesichts der sich anbahnenden Kriegsniederlage begrenzt und durch den Terror-Apparat (Reichssicherheitshauptamt, Gestapo) beherrschbar, zumal die Propaganda bis zuletzt auf den „Endsieg“ einschwor. Im zeitgenössischen Umfeld praktisch wirkungslos blieben auch die heute berühmten Flugblattaktionen der Weißen Rose oder das von Mitgliedern des Kreisauer Kreises inspirierte Attentat vom 20. Juli 1944, das Claus Schenk Graf von Stauffenberg erfolglos auf Hitler verübte. Einige Wirkung zeigte immerhin der öffentliche Einsatz des Münsteraner Bischofs von Galen gegen die Morde im Rahmen des Euthanasie-Programms. Im Regelfall wurden aktiv Widerständige als Hoch- und Landesverräter behandelt und hingerichtet, teils auch ohne Aburteilung durch den Volksgerichtshof.

In den letzten Kriegsmonaten kam es mit dem Vorrücken der Roten Armee an die Reichsgrenzen zu Flucht und Vertreibung der deutschen Bevölkerung im Osten, mitbedingt durch die sowjetischerseits betriebene Westverschiebung Polens. Betroffen waren mehr als 12 Millionen Deutsche, von denen über zwei Millionen dabei umkamen. Während der Schlacht um Berlin erschoss sich Hitler am 30. April 1945. Die deutsche Kapitulation wird auf den 8. Mai 1945 datiert. Die Verhaftung der letzten Reichsregierung unter Karl Dönitz in Flensburg-Mürwik erfolgte erst am 23. Mai 1945.

Die mit der Kapitulation besiegelte Niederlage des „Dritten Reiches“ war als historische Zäsur noch durchdringender als der Weltkriegsausgang 1918. Für Deutschland führte sie nicht nur zum faktischen Verlust aller Gebiete jenseits von Oder und Neiße, die seit der mittelalterlichen Ostsiedlung unter deutsche Hoheit gelangt waren, sondern auch zur Aufteilung des verbleibenden Territoriums in Besatzungszonen der vier Siegermächte, die die Gesamtverantwortung für „Deutschland als Ganzes“ zunächst im Rahmen des Alliierten Kontrollrats gemeinsam ausübten. Das in den Kalten Krieg übergehende, durch systembedingte politische und wirtschaftliche Interessenkonflikte verursachte Zerwürfnis zwischen den drei westlichen Mächten und der Sowjetunion bewirkte einen viereinhalb Jahrzehnte andauernden Teilungsprozess bezüglich der politischen Systeme und bei der Entwicklung staatsbürgerlicher Identitäten in beiden deutschen Staaten. Zwar bestand ein Bewusstsein für Zusammengehörigkeit der Deutschen bei vielen DDR-Bewohnern fort, wie sich 1989/90 zeigen sollte; die unterschiedlichen Sozialisations- und Lebensbedingungen in Ost und West wirken aber auch nach erfolgter Wiedervereinigung in vielen Bereichen des individuellen und gesellschaftlichen Lebens nach, wie es grob vereinfachend in dem Bild von der „Mauer in den Köpfen“ zwischen „Ossis“ und „Wessis“ zum Ausdruck kommt. Auch darin zeigen sich Spätfolgen jener von den Siegermächten auferlegten Neuordnung der Verhältnisse in Deutschland, die dem bitteren Ende des „totalen Krieges“ nationalsozialistischer Prägung folgte.

Das Ende von Krieg und NS-Herrschaft wurde zur Befreiung für die Vielzahl der vom Regime Verfolgten, in Lagern Internierten und tödlich Bedrohten, darunter neben Juden auch deportierte Zwangsarbeiter hauptsächlich östlicher Herkunft und Kriegsgefangene sowie die unterschiedlich motivierten Widerständler und inneren Emigranten. Auch für die übrige deutsche Bevölkerung ging nun die Schreckenszeit der nächtlichen Luftangriffe und der schließlich sogar nach innen gerichteten Zerstörungswut Hitlers und seiner Gefolgsleute zu Ende, die weder Industrieanlagen noch Elektrizitätswerke oder überhaupt eine überlebenswichtige Einrichtung unzerstört den Alliierten überlassen wollten und die den „Verbrannte-Erde-Befehl“ ihres Führers möglichst gründlich umzusetzen trachteten. Mancher Empfänger widersinniger Befehle und Durchhalteparolen verweigerte nun die Selbstaufopferung und suchte die eigene Haut zu retten. Für die Mehrheit der Deutschen, darunter Vertriebene, Ausgebombte, Hungernde und vergewaltigte Frauen mit ihren Familien, überwog das Erlebnis des Zusammenbruchs und des damit einhergehenden Elends.

Die von den Hauptsiegermächten auf der Potsdamer Konferenz getroffenen Vereinbarungen sahen für Deutschland eine grundlegende Abkehr von den NS-Strukturen in verschiedener Hinsicht vor: Demokratisierung, politische Dezentralisierung und strikte Entmilitarisierung, verbunden mit einer wirtschaftlichen Dekartellierung und einem Demontageprogramm. Die Demontagen industrieller Anlagen sollten die Kriegsschäden der Anti-Hitler-Koalition zum Teil ausgleichen, was insbesondere die Sowjetunion in ihrer Besatzungszone, der SBZ, in die Tat umsetzte. Alle deutschen Patente und Industriegeheimnisse wurden 1945–1947 von den USA beschlagnahmt, nach John Gimbel eine durchgreifende Beraubung des deutschen technischen Wissens, Wert fast 10 Milliarden US-Dollar. Ende 1950 wurden die Demontagen in der Bundesrepublik eingestellt. Frankreich forderte basierend auf den Plänen Jean Monnets (1946–50), das Saar- und Ruhrgebiet von Deutschland abzutrennen. Die Ruhrbehörde wurde aber 1952 durch die Montanunion abgelöst; und nach der gemäß den Pariser Verträgen durchgeführten Volksabstimmung wurde das Saarland am 1. Januar 1957 der damaligen Bundesrepublik angegliedert. Ebenfalls beschlossen wurden Maßnahmen zur Entnazifizierung der deutschen Gesellschaft. Haupt- und Mitverantwortliche in NSDAP, Staatsapparat und Wirtschaft sollten je nach ihrer Belastung zur Rechenschaft gezogen, aus ihren Positionen entfernt und bestraft werden. Die überlebenden Hauptverantwortlichen wurden in den Nürnberger Prozessen der Kriegsverbrechen und der Verbrechen gegen die Menschlichkeit angeklagt und je nach Beweislage und Größe der Schuld zu Freiheitsstrafen oder zum Tode verurteilt, einige freigesprochen. Für die breite Bevölkerung in den Westzonen wurde ein Entnazifizierungsverfahren entwickelt, das mit umfangreichen Fragebögen und Spruchkammern zur Ermittlung der mehr oder minder Belasteten, der Mitläufer und der Entlasteten führen sollte. Der Anteil der auf diese Weise als belastet eingestuften Personen war gering. In der SBZ gab es keine Fragebogenaktion, aber einen intensiv und anhaltend propagierten Antifaschismus sowie mehr als eine halbe Million Entlassungen früherer Nationalsozialisten bis 1948. Dennoch waren beispielsweise mehr als die Hälfte aller Schuldirektoren in der DDR Anfang der 1950er Jahre ehemalige NSDAP-Parteigenossen.

Viele deutsche Zwangsarbeiter in der Sowjetunion waren inhaftierte Soldaten des Ostheeres. Zusätzlich dazu überließen die US-Amerikaner den Sowjets einen Teil ihrer Gefangenen. Von den wenigen, die den Mangel und die Knochenarbeit überlebten, kehrten die letzten 1955 heim.

Politisch und wirtschaftlich stellten die Besatzungsmächte die Weichen in ihren Zonen jeweils im Sinne der eigenen Zielvorstellungen und Systemlogik. Während in der sowjetisch besetzten Zone schon 1945 eine Bodenreform zur Enteignung von Großgrundbesitzern und zur Schaffung kleinbäuerlicher Existenzen durchgeführt wurde, unterblieb Derartiges im Westen. Dafür intervenierte die amerikanische Besatzungsmacht gegen eine in der hessischen Landesverfassung vorgesehene Option zur Sozialisierung hauptsächlich von Grundstoffindustrien.

Je deutlicher der Ost-West-Gegensatz sich im weltpolitischen Maßstab ausbildete, desto klarer schlug er sich auch in der Deutschlandpolitik der Großmächte nieder. Während die sowjetische Besatzungsmacht die Zwangsvereinigung von SPD und KPD in ihrer Zone durchsetzte und freie Wahlen nach ersten SED-Misserfolgen für die Zukunft ausschloss, unterstützten die Westmächte die Ausbildung konkurrierender Parteien im Rahmen eines demokratischen Pluralismus. Die Gründung diverser Parteien auch in der SBZ hatte dagegen nur scheinbar eine demokratische Funktion. Es galt von vornherein das aus Moskau von der Gruppe Ulbricht für den ostdeutschen Wiederaufbau mitgebrachte Motto: „es muß demokratisch aussehen, aber wir müssen alles in der Hand haben.“

In der Truman-Doktrin boten die USA 1947 allen vom „Totalitarismus“ bedrohten Ländern ihre Hilfe an: Westdeutschland wurde mit dem Marshallplan wirtschaftlich in die Lage versetzt, bald wieder eine wichtige Rolle unter den marktwirtschaftlichen Ökonomien der westlichen Welt zu spielen. Darauf bereitete 1947 auch der Zusammenschluss der amerikanischen und britischen Besatzungszone zur Bizone vor, die mit französischer Beteiligung im April 1949 zur Trizone erweitert wurde. Mit der Londoner Sechsmächtekonferenz im März 1948 wurden von westlicher Seite die Weichen für die Gründung eines von der SBZ separierten deutschen Teilstaats gestellt, was den Protest der Sowjetunion hervorrief und ihren Auszug aus dem Alliierten Kontrollrat zur Folge hatte. Die Währungsreform in den Westzonen und in den Westsektoren Berlins im Juni 1948 beantwortete die sowjetische Besatzungsmacht mit einer Währungsreform in der SBZ und in Ost-Berlin sowie mit der Blockade der Zugänge nach West-Berlin, sodass die Bewohner von jeglicher Versorgung abgeschnitten zu werden drohten. Oberbürgermeister Ernst Reuter gelang es, den amerikanischen Militärgouverneur Lucius D. Clay vom Freiheitswillen und von der engen Bindung der West-Berliner an die Westalliierten zu überzeugen und für die Errichtung der Berliner Luftbrücke gemeinsam mit der britischen Royal Air Force zu gewinnen.

In den an die Ministerpräsidenten der westdeutschen Länder am 1. Juli 1948 übergebenen Frankfurter Dokumenten formulierten die Westmächte ihre Forderungen und Bedingungen bezüglich der Gründung eines westdeutschen Staates. In zwei Konferenzen bis zum Monatsende (Rittersturz-Konferenz und Niederwaldkonferenz) gaben die an einem Fortbestehen der Einheit Deutschlands orientierten westdeutschen Länderverantwortlichen dieser Aufforderung unter der Bedingung nach, dass der zu errichtende Weststaat als ein Provisorium anzulegen sei und das Ziel einer späteren Wiedervereinigung aller Deutschen in einem Staat ausdrücklich erhalten bliebe. Mit der Ausarbeitung eines Grundgesetzes statt einer Verfassung beauftragt wurde deshalb nach Vorarbeiten durch den Verfassungskonvent auf Herrenchiemsee anstelle einer Verfassunggebenden Versammlung ein Parlamentarischer Rat, der in Bonn zusammentrat. Das von den westdeutschen Ländern bis auf Bayern ratifizierte und von den Militärgouverneuren der Westmächte genehmigte Grundgesetz für die Bundesrepublik Deutschland wurde am 23. Mai 1949 verkündet.

In Reaktion auf diese Vorgänge und parallel dazu fanden auch in der SBZ Vorbereitungen für die Gründung eines separaten Staates nach sowjetischen Leitlinien statt: Aus der Volkskongressbewegung ging ein von SED-Mitgliedern dominierter Deutscher Volksrat hervor, der einen SED-nahen Verfassungsentwurf präsentierte und beschloss, den wiederum der Dritte Deutsche Volkskongress verabschiedete. Damit war der Weg in die staatliche Teilung Deutschlands festgelegt.

Bei den Wahlen zum ersten Deutschen Bundestag am 14. August 1949 erlangten die neu formierten Parteien von CDU/CSU, FDP und DP Stimmanteile, die dazu ausreichten, den bereits im Parlamentarischen Rat zum Präsidenten gewählten CDU-Vorsitzenden Konrad Adenauer mit einer Stimme Mehrheit (seiner eigenen) zum Bundeskanzler zu wählen. Die SPD um Kurt Schumacher und Carlo Schmid war danach für gut anderthalb Jahrzehnte die führende Oppositionspartei. Erster Bundespräsident wurde der FDP-Vorsitzende Theodor Heuß.

Die Gründungsphase der Bundesrepublik Deutschland stand anhaltend im Zeichen der Kriegsfolgenbewältigung und des wirtschaftlichen Wiederaufbaus. Nachdem die Trümmerfrauen den Schutt abgetragen hatten, die allgemeine Versorgungslage sich stabilisiert hatte und Lebensmittelmarken wie Schwarzmarktbeschaffungen nicht mehr gebraucht wurden, ging es in Politik und Alltag um die Beseitigung von Wohnraumnot und um die Herstellung einer funktionierenden sozialen Marktwirtschaft. Deren Motor und leitender Verfechter war bereits seit seiner Zeit als Wirtschaftsdirektor der Bizone Ludwig Erhard, nun Wirtschaftsminister im Kabinett Adenauer und später dessen Nachfolger als Bundeskanzler. Erhards Weichenstellung mit der Freigabe der Preise wurde bis 1950 auf eine harte Probe gestellt, als die Arbeitslosenzahlen von 1948 (400.000) auf über zwei Millionen anstiegen. Erst als der Preisauftrieb der Korea-Krise in einen Korea-Boom überging, der die unausgelasteten Produktionskapazitäten der westdeutschen Industrie ins Spiel brachte, die Exportwirtschaft ankurbelte und den Durchbruch zu anhaltendem Wirtschaftswachstum brachte, kam das Wirtschaftswunder in Gang. Vollbeschäftigung, wachsender Wohlstand und der Durchbruch zur Konsumgesellschaft waren die Folge.

Aus dem wirtschaftlichen Boom entstanden Verteilungsspielräume, die sich auch sozialpolitisch niederschlugen. Nicht nur höhere Löhne und Einkommenssteigerungen, sondern auch die Beteiligung der Rentner an den Zuwächsen durch Einführung der dynamischen Rente 1957 sorgten dafür, dass Arbeiterschaft, Gewerkschaften und Sozialdemokratie nun nicht mehr auf Zerschlagung, sondern auf Ergänzung der Marktwirtschaft durch Ausbau des Sozialstaats setzten. Ein starker Impuls in Richtung auf eine ausgleichende Sozialpolitik in der deutschen Nachkriegsgesellschaft war aber mit der nötigen Integration der Millionen von Vertriebenen aus dem osteuropäischen Raum gesetzt. Speziell darauf zielte das Lastenausgleichsgesetz von 1952, das durch langzeitlich verteilte, mäßige Vermögensabgaben der Nichtgeschädigten die mittellos Hinzugekommenen u. a. mit Eingliederungshilfen, Hausratentschädigung und Aufbaudarlehen unterstützte.

Außenpolitisches Hauptziel der Regierung Adenauer nach dem Petersberger Abkommen war in den Anfangsjahren der Bundesrepublik die Wiederherstellung der vollen staatlichen Souveränität gegenüber den westlichen Siegermächten. Dies kam in einer von wechselseitigen Interessen bestimmten starken Westbindung der Bundesrepublik zum Tragen, die 1951 zur Schaffung der Europäischen Gemeinschaft für Kohle und Stahl führte und damit den Grundstein für die Europäische Union legte. Mit dem Inkrafttreten der Pariser Verträge 1955 wurde die angestrebte Souveränität erlangt und im Zuge dessen durch den Deutschlandvertrag das Besatzungsstatut beendet. Die Rechte der Alliierten wurden durch – erheblich eingeschränkte – Vorbehaltsrechte abgelöst. Zur Wiederbewaffnung des westdeutschen Staates hatte bereits der Koreakrieg auch gegen erheblichen inneren Widerstand (Ohne mich-Bewegung) Anlass gegeben. 1955 wurde die Bundesrepublik Mitglied des westlichen Verteidigungsbündnisses NATO. Die vormaligen Besatzungsmächte behielten als Schutzmächte eigene militärische Standorte und Einrichtungen im Bundesgebiet. Zudem entstanden die Kasernen und Übungsplätze der neu gegründeten Bundeswehr. In der Deutschlandpolitik verfolgte Adenauer strikt einen Alleinvertretungsanspruch der Bundesrepublik für alle Deutschen und die staatliche Nichtanerkennung der DDR. Mit der Hallstein-Doktrin sollte auch deren Anerkennung durch andere Staaten verhindert werden. Gegenüber der Sowjetunion zeigte sich Adenauer flexibel, um bei seinen Moskauer Verhandlungen 1955 die Rückkehr der restlichen deutschen Kriegsgefangenen aus sowjetischen Arbeitslagern zu erreichen.

Einen neuen, wirksamen Anstoß zur Auseinandersetzung mit der NS-Vergangenheit erhielt die deutsche Öffentlichkeit seit Anfang der 1960er Jahre mit dem Eichmann-Prozess in Jerusalem und den vor deutschen Gerichten stattfindenden Prozessen gegen die Verantwortlichen in den deutschen Vernichtungslagern der SS, so z. B. die Auschwitzprozesse. Der Deutsche Bundestag debattierte und beschloss 1965 die Verlängerung der Verjährungsfrist für Mord und Beihilfe zum Mord in der NS-Zeit. In Teilen der bundesdeutschen Gesellschaft (insbesondere unter Studenten und Akademikern) setzte zeitlich parallel ein Bewusstseins- und Wertewandel ein. Amerikanisch geprägte Kulturmuster traten an die Stelle der im nationalen Rahmen herkömmlichen. Gegenüber „neuen“ Werten wie Emanzipation, insbesondere der Frauen gegenüber Männern, Partizipation und Lebensqualität traten die im industriegesellschaftlichen Rahmen funktionalen Werte wie Disziplin, Zuverlässigkeit und Unterordnungsbereitschaft zurück.

Das Bildungswesen war seit der von Georg Picht ausgerufenen Bildungskatastrophe in Gärung begriffen. Geballter Studentischer Protest, der gegen die Ordinarienuniversität mit Parolen wie: „Unter den Talaren – Muff von 1000 Jahren“ aufbegehrte, weitete sich zur umfassenden Gesellschaftskritik aus, die sich gegen die unaufgearbeitete NS-Vergangenheit der Vätergeneration und gegen die Verabschiedung der Notstandsgesetze, gegen die amerikanische Kriegführung in Vietnam, gegen das kapitalistische System und die Ausbeutung der Dritte-Welt-Länder durch die westlichen Industriestaaten richtete. Wichtigster Träger der Protestbewegung war die sogenannte 68er-Generation. Einschneidende, die Proteste radikalisierende Ereignisse waren der Tod des Studenten Benno Ohnesorg durch die Kugel des Polizisten Karl-Heinz Kurras 1967 und das Attentat 1968 auf Rudi Dutschke, den wichtigsten Theoretiker der Studentenbewegung.

Auch auf der Regierungsebene kam Mitte der 1960er Jahre ein Wandel in Gang: In der Großen Koalition unter Bundeskanzler Kurt Georg Kiesinger gelangte die SPD erstmals zur Regierungsbeteiligung; in der sozialliberalen Koalition unter Willy Brandt wurde sie zur führenden politischen Kraft. „Mehr Demokratie wagen“, hieß es in der Regierungserklärung als Motto für einen nun einsetzenden Prozess gesellschaftspolitischer Reformen, darunter die Ausweitung von Bildungschancen durch Einführung des BAföG, die Senkung des Wahlalters, eine Reform des Strafrechts, die Neuregelung von Schwangerschaftsabbrüchen (§ 218 StGB) sowie ein Betriebsverfassungsgesetz zwecks Mitbestimmung von Arbeitnehmervertretern. Die 68er-Bewegung spaltete sich zeitlich parallel in unterschiedliche politische Richtungen auf, teils, indem diverse kommunistische inspirierte Untergruppierungen gebildet wurden, deren Mitgliedern alsbald „Berufsverbote“ drohten, teils in Gestalt reformorientierter Verfechter der Systemveränderung, die den „Marsch durch die Institutionen“ antraten. Randliche Splittergruppen hielten eine Gewalteskalation für das geeignete Mittel zur Herstellung einer revolutionären Situation. Daraus entwickelte sich der Terrorismus der RAF, der zu einer ernsten Herausforderung für die Regierung von Bundeskanzler Helmut Schmidt wurde. Wirksames Krisenmanagement wurde Schmidt auch wirtschaftspolitisch abverlangt, vor allem hinsichtlich der Folgenbewältigung des Ölpreisschocks, der Ende 1973 die von nahöstlichen Ölimporten abhängigen westlichen Industrieländer traf. Nach Jahren üppigen Wirtschaftswachstums geriet die Bundesrepublik bei steigenden Arbeitslosenzahlen 1975 in eine Rezession.

Zu einem Regierungswechsel kam es jedoch erst 1982 wieder, als die Gemeinsamkeiten der sozialliberalen Koalition in der Sozial- und Wirtschaftspolitik aufgebraucht waren und die FDP unter der Führung Hans-Dietrich Genschers im Rahmen eines konstruktiven Misstrauensvotums die Wahl des Oppositionsführers Helmut Kohl zum Bundeskanzler unterstützte. Die im März 1983 folgenden Neuwahlen brachten nicht nur die Bestätigung für die neue christlich-liberale Koalition, sondern auch den erstmaligen Einzug der Grünen in den Bundestag. Sie stellten ein Sammelbecken dar für die Neue Linke, für die Frauenbewegung, für Friedensbewegte angesichts der Nachrüstungsdebatte wie für ökologisch Interessierte, Umweltschützer, und Atomkraftgegner, zumal unter dem Eindruck der Reaktorkatastrophe von Tschernobyl 1986. Mit diesen Themen, unangepassten Formen des Auftretens und einer akzentuierten Gleichstellungspolitik von Frauen und Männern wurden sie für die Altparteien im parlamentarischen Alltag zur Herausforderung. Die mit der Einrichtung einer Bundesstelle für Umweltangelegenheiten bereits in der Regierung Brandt begonnene Umweltschutzpolitik fand in der Schaffung des Bundesumweltministeriums durch die Regierung Kohl 1986 ihre Fortsetzung.

Doch vor allem in der Außenpolitik ist über alle Regierungswechsel zu Zeiten der Bundesrepublik hinweg die Kontinuität gewahrt worden. Die Westanbindung blieb das feste Fundament auch nach dem Bau der Berliner Mauer 1961 und trotz des danach einsetzenden Bemühens, zu einem Modus vivendi mit den östlichen Machthabern zu gelangen. Die von der Regierung Brandt-Scheel initiierte neue Ostpolitik, die zur vertraglichen Anerkennung des Status quo u. a. gegenüber der Sowjetunion, der Volksrepublik Polen und der DDR führte und im Gegenzug Erleichterungen des innerdeutschen Reise- und Besucherverkehrs sowie einen vertraglich abgesicherten Status für West-Berlin erbrachte, wurde auch von der Regierung Kohl-Genscher bruchlos fortgesetzt. Dies zeigte sich auch beim Besuch Erich Honeckers 1987 in der Bundesrepublik, dem ersten und einzigen eines DDR-Staatsoberhaupts.

Auf die mit dem Mauerfall am 9. November 1989 in Gang kommende Dynamik reagierte der mit dem Ziel der deutschen Wiedervereinigung stets eng verbundene Kanzler Kohl situationsangepasst flexibel. Dem am 28. November im Deutschen Bundestag vorgetragenen 10-Punkte-Programm zur Überwindung der Teilung Deutschlands und Europas folgte am 19. Dezember 1989 ein Treffen mit dem neuen DDR-Ministerpräsidenten Hans Modrow in Dresden und am Nachmittag eine Massenkundgebung, die für Kohl den dringlichen Einheitswunsch der Ostdeutschen unterstrich. Er verließ Dresden „mit der Überzeugung, daß das Regime der DDR vor dem Zusammenbruch stand und es keine Alternative mehr gab zu einer Wiedervereinigung in möglichst naher Zukunft.“

Von der aus dem Deutschen Volksrat hervorgegangenen „provisorischen Volkskammer“ wurden am 11. Oktober 1949 Wilhelm Pieck zum Staatspräsidenten und Otto Grotewohl zum Ministerpräsidenten der DDR-Regierung gewählt (Wahlen zur Volkskammer fanden erstmals am 15. Oktober 1950 statt, und zwar nach dem Einheitslistenprinzip). Tatsächliches politisches Machtzentrum aber war das SED-Politbüro, das sich die Kontrolle über alle wichtigen Initiativen und Beschlüsse von Volkskammer und Regierung vorbehielt. Den größten persönlichen Einfluss auf die Ausgestaltung der Herrschaftsverhältnisse in den Anfangsjahren der DDR übte der im Juli 1950 zum Generalsekretär der SED gewählte Walter Ulbricht aus. Nach dem Prinzip des Demokratischen Zentralismus’ wurden nicht nur die wichtigen Weichenstellungen innerhalb des engsten SED-Führungszirkels getroffen, sondern auch für die nachgeordneten Organisationen von Partei und Staat mit bindender Wirkung durchgesetzt. Auf dieser Linie wurden dann auch die politisch einflusslosen Länder in der DDR im Juli 1952 aufgelöst und durch 14 Bezirke ersetzt, die ihrerseits von den zugehörigen SED-Gliederungen dominiert wurden, ebenso wie die den Bezirken untergeordneten 217 Kreise. Wichtigster Hebel zur Durchsetzung der Parteilinie in der Praxis war die Kaderpolitik der SED, mittels derer alle wichtigen Positionen in Staat und Gesellschaft durch Personen besetzt wurden, die den spezifischen Eignungskriterien laut SED-Vorgaben entsprachen.

Ebenfalls dem sowjetischen Muster folgend, wurde die Wirtschaft mit dem ersten Fünfjahresplan 1951 zentralistisch ausgerichtet; im Folgejahr wurden die ersten Volkseigenen Betriebe (VEB) und die erste Landwirtschaftliche Produktionsgenossenschaft (LPG) gebildet. Zugleich erhöhte die SED den Druck auf alle von den Parteivorgaben Abweichenden innerhalb und außerhalb der SED durch Kriminalisierung und gerichtliche Aburteilung der Widersacher. Ausspähung und Bereitstellung belastenden Materials wurde dabei hauptsächlich von den Mitarbeitern des 1950 gegründeten Ministeriums für Staatssicherheit (kurz: MfS oder „Stasi“) übernommen, dem „Schild und Schwert“ der Partei bis zum Ende der DDR.

Tatsächlich gab es Widerstand während der gesamten vier Jahrzehnte, in denen die DDR existierte. Eine breite Volkserhebung gegen das SED-Regime gab es vor 1989 jedoch nur einmal, und zwar in der Frühphase aus Protest gegen verstärkten Leistungsdruck am Arbeitsplatz. Durch Erhöhung der Arbeitsnormen sollten vor allem die hohen Rüstungskosten gedeckt werden, die im Zuge der beiderseitigen deutschen Wiederbewaffnung als Folge des Koreakriegs und der Verhärtung im Ost-West-Konflikt anfielen. Nachdem der Volksaufstand vom 17. Juni 1953 mit Hilfe sowjetischer Militärs und Panzer niedergeschlagen war, kam es bis zum Bau der Berliner Mauer 1961 zu Flüchtlingszahlen in Größenordnungen, die die wirtschaftliche Existenz der DDR gefährdeten. Als die Fluchtmöglichkeit entfiel, bot sich dem SED-Regime einerseits die Möglichkeit, den Ausbau der sozialistischen Gesellschaft zu forcieren; für das Gros der DDR-Bewohner andererseits galt es nun, sich in den bestehenden Verhältnissen einzurichten und mit dem System zu arrangieren.

In der nach innen gerichteten Kulturpolitik schwankte die SED-Führung je nach aktuellen politischen Opportunitäten zwischen Phasen einer verhaltenen Liberalisierung – auch in Bezug auf westliche Einflüsse – und solchen rigider ideologischer Verhärtung. Die mit dem Prager Frühling 1968 aufkeimenden Hoffnungen auf einen mit mehr Freiheiten verbundenen Reformsozialismus wurden mit der Niederschlagung durch die Staaten des Warschauer Pakts unter Mitwirkung der DDR zerstört. Als im Mai 1971 Erich Honecker mit sowjetischer Unterstützung seinen politischen Ziehvater Ulbricht in der DDR-Staatsführung ablöste, war die soziale Revolution in der DDR bereits im Wesentlichen durchgeführt, und die visionär-utopischen Erwartungen verblassten. Vielmehr wurde nun die „Gestaltung der entwickelten sozialistischen Gesellschaft“ im Rahmen des „realen Sozialismus’“ propagiert.

Als gestaltende Kraft setzte man dabei auf die „sozialistische Persönlichkeit“, die definitionsgemäß über „umfassende politische, fachliche und allgemeinwissenschaftliche Kenntnisse verfügt, einen festen, von der marxistisch-leninistischen Weltanschauung geprägten Klassenstandpunkt besitzt, sich durch hohe geistige, physische und moralische Qualitäten auszeichnet, vom kollektiven Denken und Handeln durchdrungen ist und aktiv, bewusst und schöpferisch den Sozialismus mitgestaltet.“ Der Heranbildung solcher Persönlichkeiten diente das gesamte Erziehungs- und Bildungswesen in der DDR, nicht nur in den Schulen, sondern auch in den parteinahen Jugendorganisationen: zum einen die Pionierorganisation „Ernst Thälmann“ mit den 6- bis 10-jährigen Jungpionieren und den 10- bis 14-jährigen Thälmannpionieren; zum anderen die Freie Deutsche Jugend (FDJ) für die 14- bis 25-Jährigen, die während der Ära Honecker zwei Drittel bis vier Fünftel der Jugendlichen und jungen Erwachsenen einschloss. Neben Flaggenappellen, ideologischen Unterweisungen, dem Liedersingen, Schießübungen und Zeltlagern wurde auch zum Mitmachen bei sogenannten Jugendobjekten angehalten. Das waren Arbeitseinsätze vielfältiger Art, die sich 1974 auf 68.370 Objekte richteten und 854.912 Jugendliche beschäftigten. Mit der an den schulischen Rahmen angebundenen Jugendweihe, die – bis auf wenige mit meist starker kirchlicher Bindung – die Jugendlichen in der DDR auf ein sozialistisches Gelöbnis verpflichtete, prägte sich in der DDR ein nachhaltig wirksames eigenes Brauchtum aus. Die von Honecker betonte Bedeutung der Landesverteidigung und Grenzsicherung für alle Bereiche der Gesellschaft war ein weiteres Sondermerkmal der DDR, in der ab 1978 an allen Schulen ein obligatorischer Wehrunterricht erteilt wurde.

Für die Förderung der Berufstätigkeit von Frauen gab es in der DDR nicht nur das Postulat der Geschlechtergleichberechtigung, sondern auch eine von der verbliebenen männlichen Bevölkerung nicht zu füllende Arbeitskräftelücke. Zur Förderung eines hohen Beschäftigungsgrades der Frauen trugen verschiedene Maßnahmen bei, insbesondere der Aufbau eines umfassenden Kinderbetreuungssystems mit Krippen, Kindergärten und Betreuungsangeboten nach Schulschluss. Kindergelderhöhungen, erweiterter Mutterschaftsurlaub und Arbeitsplatzgarantien wirkten ebenfalls daran mit, dass die Geburtenfreudigkeit von 1973 bis 1980 um ein Drittel anstieg. Am Arbeitsplatz waren Frauen wie Männer zu Kollektiven zusammengefasst, die im sozialistischen Wettbewerb, typischerweise als Brigaden, durch eine hohe Produktivität Prämien erlangen konnten. Der Zusammenhalt solcher Kollektive erstreckte sich aber auch auf außerbetriebliche Aktivitäten wie gemeinsame Geburtstagsfeiern, Ausflüge, Ausstellungs- und Theaterbesuche sowie auf ein Sich-Kümmern um Probleme und Sorgen einzelner Mitglieder. Im Zuge des vom Staat dergestalt organisierten Arbeits- und gesellschaftlichen Lebens „schrieb sich das Kollektiv als Team, als Schule der Kommunikation und ihrer Grenzen, als Hort arbeiterlicher Gemeinschaftserfahrung und sozialer Kontrolle in die Alltagserfahrung der DDR ein.“

Doch auch in Fragen des Urlaubs, der Mobilität und der Versorgung mit Konsumgütern war man davon abhängig, was die staatliche Planung vorsah und was produziert und angeboten wurde. Trotz subventionsbedingt niedriger Preise etwa bei Grundnahrungsmitteln, öffentlichen Verkehrsmitteln, Mieten und Büchern wurde die DDR oft als fehlgesteuerte Mangelwirtschaft erlebt: Weil es vieles oft nicht gab, stellte man sich in die Schlange, um auf Vorrat zu kaufen, was man vielleicht aktuell gar nicht brauchte. Wer aber Zugang zu westlichen Devisen hatte, war besser dran als der Rest. Denn er konnte zum Beispiel im Intershop bekommen, was anderen versagt blieb. Zum Teil lange Wartezeiten fielen an bei der Verteilung nachgefragter Urlaubsplätze durch den Feriendienst des FDGB, bei der bedarfsgerechten Wohnraumvergabe und bei der Auslieferung von Kraftfahrzeugen. Die reguläre Wartefrist auf den mit 13.000 Mark der DDR noch erschwinglichsten, etwa ein durchschnittliches Jahreseinkommen kostenden Kleinwagen Trabant betrug in der DDR-Spätphase 14 Jahre.

Das „Weltniveau“ in der Produktion zu erreichen und mitzubestimmen, lautete die von der DDR-Führung ausgegebene Parole im Streben um innere und äußere Anerkennung. Hinsichtlich letzterer wurden in der ersten Hälfte der 1970er Jahre wichtige Fortschritte erzielt, als man im Verhältnis zur Bundesrepublik Deutschland den Grundlagenvertrag, die beiderseitige Einrichtung Ständiger Vertretungen in Bonn und Ost-Berlin sowie ein devisenträchtiges Transitabkommen aushandelte. Mit der Aufnahme beider deutscher Staaten in die Vereinten Nationen erlangte die DDR international einen gleichberechtigten Status, der durch die Mitunterzeichnung der KSZE-Schlussakte 1975 noch unterstrichen wurde. Durch gezielte Förderung sportlicher Nachwuchstalente und ein staatliches Zwangsdopingsystem im DDR-Leistungssport erzielte die DDR in manchen Bereichen international herausragende Erfolge, etwa bei Olympischen Spielen.

Dass die innergesellschaftliche Akzeptanz des SED-Regimes gleichwohl prekär blieb, zeigte die Ausbürgerung des Liedermachers Wolf Biermann 1976, die zu einer breiten Protestwelle führte und vielfach resignative Tendenzen hinsichtlich der Reformierbarkeit des Herrschaftssystems bestärkte. Mit Berufung auf die Menschenrechtsgarantien der KSZE-Schlussakte stellten immer mehr Bürger einen Antrag auf legale Ausreise aus der DDR. Waren es 1984 rund 32.000 Antragsteller, die neben z. T. jahrelangen Wartezeiten auch eine drastische gesellschaftliche Ausgrenzung in Kauf nahmen, so wuchs die Anzahl 1988 auf über 110.000 an. Die Situation war aber noch in anderer Hinsicht instabil. Denn der im Vergleich zu allen anderen Ostblockstaaten am höchsten entwickelte Lebensstandard der DDR-Bevölkerung beruhte auf einer zunehmend dramatischen Staatsverschuldung, die ausweglose Züge annahm, weil die SED-Führung unter Honecker an den vielfältigen Subventionen keine Abstriche machen wollte, um nicht zusätzliche Unzufriedenheit in der Bevölkerung zu schüren. Nach der drastischen Kürzung sowjetischer Öllieferungen 1981 nahm die Krise der DDR-Staatsfinanzen immer dramatischere Züge an, die auch durch westdeutsche Devisenzuflüsse aus Handel und Verträgen sowie durch wiederholte Milliardenkredite nur kurzfristig überbrückt werden konnten: „Allein Improvisationskunst und der westliche Devisentropf vermochten die marode Planwirtschaft noch halbwegs am Laufen zu halten.“ Trotzdem verschlechterte sich die Versorgungslage der Bevölkerung merklich, selbst bei Waren des täglichen Bedarfs; und die notwendigen Investitionen zur Substanzerhaltung bei Wohnungsbauten und Industrieanlagen blieben aus, was der Volksmund bitter kommentierte: „Ruinen schaffen ohne Waffen!“

In der nach dem Mauerbau erwachsen gewordenen Generation bildeten sich Protestgruppen aus, die neue Themen und Positionen besetzten, sich mit Rüstungseskalation und Umweltzerstörung, mit den Ursachen von Verelendung in der Dritten Welt und mit den Perspektiven eines Europas ohne Grenzen befassten, eine international orientierte Friedensbewegung, die sich in Kleingruppen lokal organisierte und als Kern einer vielfach unter kirchlichem Schutz und Zuspruch sich entwickelnden Bürgerrechtsbewegung bereitstand, als Michail Gorbatschow mit Glasnost und Perestroika die Vorzeichen sowjetischer Politik änderte und die sozialistischen „Bruderstaaten“ zu eigenverantwortlicher Zukunftsgestaltung anhielt. Indem die DDR-Führung daraufhin jede Kursänderung ablehnte und daranging, sogar sowjetische Medien zu zensieren und deren Abonnenten zu düpieren, geriet sie zunehmend in die Isolation.

Dem Problemandrang – aus finanzwirtschaftlichen Problemen, sich verschlechternder Versorgungslage der Bevölkerung, einer wachsenden Protestbewegung gegen die Kommunalwahlfälschungen vom Mai 1989 und den über die seit Juni offene ungarische Grenze massenhaft abströmenden DDR-Bewohnern – hatte die nun auch mit Desillusionierten und Unzufriedenen in den Reihen der SED konfrontierte Staatsführung außer örtlichen Gewaltübergriffen, Internierungen und Gewaltandrohung nichts mehr entgegenzusetzen. Nach dem Triumph der Leipziger Montagsdemonstranten am 9. Oktober und dem Fall der Berliner Mauer infolge des Massenansturms vom 9. November 1989 war die SED-Herrschaft am Ende. Die nach den Machtwechseln von Honecker über Egon Krenz und Hans Modrow zu Lothar de Maizière neu ausgerichtete und nun von Bürgerrechtlern mitgestaltete DDR selbst ging binnen eines Jahres im wiedervereinigten Deutschland auf.

Die Ostdeutschen bewirkten mit ihrer friedlichen Revolution nicht nur den Zusammenbruch der SED-Diktatur, sondern nahmen nach der Grenzöffnung mit einer Akzentverschiebung ihrer zentralen Parole bei den fortgesetzten Montagsdemonstrationen mehrheitlich auch deutlich Kurs auf ein wiedervereinigtes Deutschland. Hatte man die DDR-Obrigkeit vordem mit dem Ruf „Wir sind das Volk!“ in die Schranken gewiesen, so demonstrierte man nun vorwiegend mit der Wendung „Wir sind ein Volk!“ für die deutsche Einheit. Artikel 23 des Grundgesetzes der alten Bundesrepublik garantierte die Möglichkeit eines geschlossenen Beitritts der DDR zur Bundesrepublik Deutschland. Wer es als Ostdeutscher besonders eilig hatte, in der Bundesrepublik anzukommen, konnte das aber auch durch Übersiedlung unverzüglich in die Tat umsetzen. Anfang 1990 schwoll die Zahl der diese Möglichkeit Nutzenden in einer für beide Staaten auf unterschiedliche Weise problematischen Größenordnung an. Die ohnehin auf Vereinigungskurs ausgerichtete Regierung Kohl arbeitete ihrerseits energisch auf die Herstellung der Einheit Deutschlands hin und wurde durch den Ausgang der Volkskammerwahl vom März 1990 darin bestärkt, in der die Allianz für Deutschland mit dem künftigen CDU-Ministerpräsidenten Lothar de Maizière triumphierte. Schon zum 1. Juli wurde eine Währungs-, Wirtschafts- und Sozialunion vereinbart und durchgeführt. Der mit den vier Siegermächten des Zweiten Weltkrieges ausgehandelte Zwei-plus-Vier-Vertrag bildete den äußeren Grundstein der Einheit Deutschlands; der von Volkskammer, Bundestag und Bundesrat ratifizierte Einigungsvertrag schuf die inneren Voraussetzungen dafür, dass es am 3. Oktober 1990 zur deutschen Wiedervereinigung kam.

In der ersten gesamtdeutschen Bundestagswahl im Dezember 1990 und nochmals 1994 wurde die christlich-liberale Koalition unter Bundeskanzler Helmut Kohl bestätigt, die den Vereinigungsprozess wesentlich gestaltet hatte. Mit knapper Mehrheit (338 zu 320 Stimmen) beschloss der Bundestag am 20. Juni 1991, Bonn als Regierungssitz aufzugeben und Regierung und Parlament nach Berlin zu verlegen. Seit 1999 tagt der Deutsche Bundestag im von Grund auf renovierten Reichstagsgebäude in Berlin. Seit September 1999 ist auch die Bundesregierung endgültig in Berlin angesiedelt.

Innenpolitisch absolut vorrangig – und wie der gesamte Vereinigungsprozess mit enormen Kosten verbunden – war während der 1990er Jahre der Aufbau Ost. In den neuen Bundesländern wurde die verkehrliche Infrastruktur modern ausgebaut und die Sanierung von Bausubstanz und Industriebetrieben, wo nicht abrissreif, vorangetrieben. Der Umbau hin zu marktwirtschaftlichen Strukturen mit Hilfe der Treuhandanstalt wurde in hohem Tempo und unter Abwicklung der unverkäuflichen bzw. als unrentabel geltenden Betriebe durchgeführt; und die in DDR-Zeiten durch industrielle Schadstoffeinträge aus veralteten Produktionsanlagen ökologisch besonders belasteten Gewässer und Regionen wurden den Erfordernissen des Umweltschutzes angepasst. Der „Vereinigungsboom“ kam wesentlich den Unternehmen in der alten Bundesrepublik zugute, während die angestammten Produktangebote aus DDR-Zeiten nun kaum noch Abnehmer fanden. Der wirtschaftliche Restrukturierungsprozess in den neuen Bundesländern brauchte Zeit und verlief regional unterschiedlich erfolgreich. Die Arbeitslosenquoten in ostdeutschen Bundesländern lagen mitunter doppelt so hoch wie in den alten Ländern, die durch Partnerschaften und Aushilfe mit qualifiziertem Verwaltungspersonal die Anpassung der neuen Länder an die administrativen, juristischen, wirtschaftlichen und politischen Standards der Bundesrepublik unterstützten.

Die konzentrierten Anstrengungen und finanziellen Transferleistungen, die zur Angleichung der Lebensverhältnisse im Osten Deutschlands aufgewendet wurden, rückten mit dem Abklingen des vereinigungsbedingten Wirtschaftsaufschwungs einen unterdessen eingetretenen Reformstau ins Bewusstsein. Mehrere Reformvorhaben der Bundesregierung scheiterten an der rot-grünen Mehrheit im Bundesrat (sogenannte „Blockade“). Der lange Zeit vielerorts unergiebige ostdeutsche Arbeitsmarkt hatte auch eine fortgesetzte Abwanderung gerade junger Menschen zur Folge, die im Westen Beschäftigung suchten – ein anhaltendes demographisches Problem in den strukturschwachen Regionen Ostdeutschlands. Teils gibt es dort auch verstärkt rechtsextremistische Tendenzen. Andererseits ist die sozial benachteiligte Lage vieler Ostdeutscher ein wichtiger Grund für die vergleichsweise starke Stellung der in Die Linke aufgegangenen „Partei des Demokratischen Sozialismus“ (vormals SED) in den neuen Bundesländern.

Das wiedervereinigte Deutschland ist ein souveräner Staat. Die Truppen der "Vier Mächte" sind zum größten Teil abgezogen, die noch verbliebenen Militäreinheiten der Westalliierten haben keinerlei Hoheitsbefugnisse mehr und unterliegen dem NATO-Truppenstatut. Die Zustimmung der vormaligen Siegermächte zur deutschen Wiedervereinigung war an Zusagen der deutschen Bundesregierung geknüpft, den Prozess der europäischen Integration weiterhin nachhaltig zu fördern, nachdem die Bundesrepublik diesen bereits seit den 1950er Jahren entscheidend mitgestaltet hatte. Diese Ausrichtung wurde auch in die veränderte Präambel des Grundgesetzes eingetragen. Mit der Unterzeichnung des Vertrages von Maastricht 1992 wurde die Europäische Gemeinschaft (EG) in die mit erweiterten Kompetenzen ausgestattete Europäische Union (EU) überführt. Der Vertrag stellte auch die Weichen für die Einführung einer gemeinsamen europäischen Währung, des Euro. Mit klarer Unterstützung der Bundesregierung wurde zudem die EU-Osterweiterung beschlossen, die 2004 in Kraft trat.

Aus der Lösung der deutschen Frage 1990 sind neue Erwartungen und Ansprüche an eine verantwortlich mitgestaltende Rolle Deutschlands bei der Aufrechterhaltung des Weltfriedens, bei der militärischen Umsetzung von UN-Resolutionen wie auch hinsichtlich der Beteiligung an Militäreinsätzen der NATO erwachsen. Nach der Wiedervereinigung beteiligte sich die Bundeswehr erstmals an Auslandseinsätzen, so zum Beispiel nach den Terroranschlägen in den USA vom 11. September 2001 am Krieg in Afghanistan. Eine Beteiligung am Irakkrieg lehnte die Regierung Schröder/Fischer dagegen ab. Mit der in den letzten Jahren deutscherseits erhobenen Forderung nach einem ständigen Sitz im UN-Sicherheitsrat, die gleichfalls mit der gewachsenen internationalen Rolle und Verantwortungsbereitschaft Deutschlands begründet wird, ist die Bundesregierung einstweilen nicht durchgedrungen.

Bei der Bundestagswahl 1998 wurde die CDU/CSU-FDP-Koalition unter Kohl abgelöst. Die neue Bundesregierung aus SPD und Bündnis 90/Die Grünen (rot-grüne Koalition) ging unter Bundeskanzler Gerhard Schröder eine Reihe umstrittener Reformen an. Allgemein wurde das Thema Ökologie stärker gewichtet, beispielsweise mit dem Beginn des Atomausstiegs oder mit Gesetzesinitiativen zur Reduzierung von Treibhausgasen. Die Regierung setzte auch erste Ansätze für richtungsweisende Veränderungen in der Sozial-, Renten- und Gesundheitspolitik (siehe Agenda 2010) durch. Mittels der Einnahmen aus der Ökosteuer gelang es, die Lohnnebenkosten (Rentenversicherungsbeiträge) zu reduzieren. Im Zuge der schon in den 1990er Jahren für die Volkswirtschaften weiter gewachsenen Bedeutung des Weltmarkts, der sogenannten Globalisierung, verlagerten aber vor allem größere Unternehmen Produktionskapazitäten in sogenannte Billiglohnländer, sodass die Arbeitslosenquote zunächst weiterhin hoch blieb. Mit dem auf wirtschaftliche Wettbewerbsfähigkeit zielenden Hartz-Konzept zur Neuordnung von Arbeitslosen- und Sozialhilfe konnte die rot-grüne Koalition aber nur Teile der eigenen Wählerschaft überzeugen.

Seit der vorzeitig Bundestagswahl 2005 bekleidet mit der in der DDR aufgewachsenen Angela Merkel erstmals eine Frau das Amt des Bundeskanzlers. Dem rot-grünen Kabinett Schröder II folgte eine Große Koalition (Kabinett Merkel I). Im Jahr 2008 geriet Deutschland in den Sog einer weltweiten Finanz- und Wirtschaftskrise, die im Wesentlichen durch eine zu sorglose Kreditgewährung insbesondere im Bereich der Immobilienbankgeschäfte in den USA ausgelöst wurde. Im Zusammenhang mit den dadurch bedingten Turbulenzen an den globalen Finanzmärkten steht auch die Staatsschuldenkrise im Euroraum, die eine anhaltende Herausforderung auch für die deutsche Finanz- und Europa-Politik darstellt.

2009 wurde die Große Koalition durch eine schwarz-gelbe Koalition aus Union und der FDP ersetzt. Merkel behielt ihr Amt als Bundeskanzlerin. Bei den Bundestagswahlen 2013 hat die FDP den Einzug in den Bundestag verpasst, es kam erneut zu einer großen Koalition unter Merkel als Bundeskanzlerin.

Am 31. Dezember 2015 hielten sich in Deutschland 211.052 anerkannte Flüchtlinge und 447.336 Asylbewerber auf, hauptsächlich aus dem Nahen Osten und Afrika; im Jahr 2015 hatten insgesamt 476.649 Personen Asylanträge in Deutschland gestellt. Dies bedeutete einen Zuwachs von 135,0 % gegenüber dem Jahr 2014 und war der höchste Jahreswert seit Bestehen des Bundesamtes. Die ursprünglichen Prognosen für das Jahr von zunächst 450.000 und dann 800.000 wurden signifikant übertroffen. Angela Merkel hat für ihre Politik der "offenen Grenzen" Zustimmung, aber auch harsche Kritik geerntet. Die Flüchtlingskrise wird von einigen Politikern und Organisationen als größte Herausforderung des Landes seit der Wiedervereinigung gesehen.


Eine bis Ende 2015 reichende bibliographische Onlinedatenbank bieten unter anderem die "Jahresberichte für deutsche Geschichte".









</doc>
<doc id="1999" url="https://de.wikipedia.org/wiki?curid=1999" title="Gläubiger">
Gläubiger

Der Rechtsbegriff des Gläubigers ist eine Lehnübersetzung des italienischen "creditore", das auf "credere" ‚glauben‘ zurückgeht. Ein Gläubiger glaubt demnach seinem Schuldner, dass dieser die Schuld (geschuldete Leistung) erbringen wird.

Im Schuldrecht wird als Gläubiger bezeichnet, wer von einem anderen, dem Schuldner, eine Leistung fordern kann ( Abs. 1 Satz 1 BGB). Die Rechtsbeziehung zwischen Gläubiger und Schuldner wird als Schuldverhältnis bezeichnet. Die Gesamtheit derjenigen, die Forderungen gegenüber dem Schuldner haben, wird als Gruppe der Gläubiger bezeichnet. Zur Durchsetzung machen diese einen Anspruch geltend.

In der Zwangsvollstreckung ist (Vollstreckungs-)Gläubiger derjenige, der aus einem vollstreckbaren Titel vollstreckt. (Vollstreckungs-)Schuldner ist, gegen wen aus dem vollstreckbaren Titel vollstreckt wird.

Im schweizerischen Sprachgebrauch hat der Begriff „Gläubiger“ in einer Betreibung lediglich die Bedeutung ‚Betreibender‘. Mit anderen Worten ist Gläubiger „diejenige Person, deren Forderung vollstreckt, zu deren Gunsten also das Schuldbetreibungsverfahren durchgeführt werden soll“.

Im Insolvenzverfahren vertreten die Gläubiger ihre Interessen gemeinschaftlich. Hauptorgan ist die so genannte Gläubigerversammlung, InsO. Die Gläubigerversammlung trifft die wesentlichen Entscheidungen im Insolvenzverfahren. Daneben kann von der Gläubigerversammlung noch ein Gläubigerausschuss eingesetzt werden, der den Insolvenzverwalter bei der Durchführung seiner Aufgaben unterstützen und überwachen soll, InsO.

Der Gläubiger wird häufig mit dem wirtschaftlich Berechtigten gleichgesetzt. Obwohl die Gläubigereigenschaft und die wirtschaftliche Berechtigung häufig in einer Person zusammenfallen können, ist ein Auseinanderfallen beider Eigenschaften durchaus möglich.

Es gibt mehrere Gläubigermehrheiten:




</doc>
<doc id="2006" url="https://de.wikipedia.org/wiki?curid=2006" title="Grand-Bassam">
Grand-Bassam

Grand-Bassam (auf Deutsch auch: Groß-Bassam) ist eine Hafenstadt der Elfenbeinküste an der Atlantikküste (Golf von Guinea), etwa 40 Kilometer östlich von Abidjan. Die Stadt mit ihren heute knapp 84.000 Einwohnern war zu französischen Kolonialzeiten die wichtigste Stadt der Kolonie Elfenbeinküste. Wegen ihrer gut erhaltenen Architektur aus dieser Zeit trägt sie seit 2012 den Titel des UNESCO-Welterbes und ist auch wegen ihrer Strände beliebt bei Touristen und Bewohnern des nahen Abidjan.

Grand-Bassam liegt im Südosten der Elfenbeinküste am Ufer des Atlantischen Ozeans im Departement Grand-Bassam, das zur Region Sud-Comoé des Distrikts Comoé gehört. Es grenzt im Norden an die Gemeinden Bingerville (im Autonomen Distrikt Abidjan) und Alépé (in der Region La Mé), im Osten an die Gemeinde Bonoua, im Süden an den Atlantik und im Westen wieder an den Autonomen Distrikt Abidjan (mit der Gemeinde Port-Bouët).

Die Fläche der Gemeinde, die identisch mit der der gleichnamigen Unterpräfektur ist, beträgt 11.300 ha, auf denen laut Zensus von 2014 84.028 Menschen leben.

Die Ébrié-Lagune teilt die Stadt in zwei Teile:


Der Boden ist flach und sandig, von einigen mehr oder weniger sumpfigen Untiefen abgesehen ist die Vegetation der Gemeinde eine mit Bäumen durchsetzte Savanne. Entlang der Küste bestehen Kokospalmenpflanzungen.

Die Unterpräfektur Grand-Bassam wird durch den Atlantischen Ozean und drei weitere Wasserläufe bestimmt: die Ébrié-Lagune, deren Seitenarm, die Ouladine-Lagune, an welcher der Leuchtturm gelegen ist und den Fluss Comoé, der seine Quelle in Banfora in Burkina Faso hat.

Das Klima ist regenreich. Man unterscheidet vier Jahreszeiten:

Über den Ursprung des Namens von Bassam gibt es mehrere Theorien. Nach Professor Niangoran Bouah, Ethno-Soziologe, war Bassam keine Ortsbezeichnung. Einerseits könnte es vom N'Zima-Wort "Bazouam" abstammen, was ein Hilferuf ist. Eine N'Zima-Frau hätte ihn einem Europäer zugerufen und dieser gedacht, es sei der Name des Ortes. Die zweite These geht auf die Sprache der Abouré zurück. Aus dem Wort "Alsam" (Abouré für: Abenddämmerung) entwickelte sich durch linguistische Bequemlichkeit "Abassam" und später "Bassam". Niangoran Bouah tendiert dazu, der zweiten These höhere Wahrscheinlichkeit zuzugestehen.

Ab 1470 knüpften die Europäer ersten Kontakt mit den Bevölkerungen des Litorals der Elfenbeinküste. 1469 landete Soeiro da Costa, ein portugiesischer Seefahrer, als erster bekannter Europäer im Gebiet von Grand-Bassam, bevor er in Richtung Elmina an der Goldküste (heute Ghana) weiterreiste. Zwischen 1470 und 1471 legten João de Santarém und Pêro Escobar zum ersten Mal an der Elfenbeinküste an. Ivorische Städtenamen wie Sassandra, San-Pédro oder Fresco erinnern noch heute daran.

Die Menschenjagden im Rahmen des Sklavenhandels in der Goldküste führten im 17. Jahrhundert zu einer Migrationsbewegung ins Gebiet der Elfenbeinküste. Abouré siedelten sich in der Umgebung des Flusses Bia und bis zur Aby-Lagune an. Dabei gründeten sie die Dörfer Dibi, Aboisso, Wessebo und Ahakro, die erste Hauptstadt des Königreichs, das König "Aka Ahoba", der Führer der Abouré-Migration, begründet hatte.

Die Agni-Brafé, Gründer des Königreichs Sanwi, eroberten im 18. Jahrhundert das Gebiet der Abouré. Diese zogen sich von der Bia zurück in ihren derzeitigen Lebensraum im Südosten des Küstengebietes. Dort teilen sie sich in drei Gruppen auf: die Ehe des Dorfes Moossou, die Ehive der Bonoua-Dörfer und die Odjowo und Ossouen (oder Eblapoue) des Dorfes Ebrah. Gemäß allen Quellen stammen die Abouré, eine Untergruppe der Aschanti, ursprünglich aus der Goldküste.

Später, um 1840, stießen, ebenfalls aus dem heutigen Ghana, die N'Zima zu ihnen. Aus der gleichen Ursprungsregion stammen, knüpften sie Eheallianzen. Die N'Zima (oder Appolien) besiedelten die Gebiete der heutigen Stadtquartiere "Petit Paris", "France" und "Azuretti". Auch heute noch besteht die einheimische Bevölkerung Grand-Bassams aus Abouré und N'Zima. Sie hatten als erste Kontakt zu den Europäern.

Einige Jahre später siedelten Ehotilé auf der Insel von Vitré und teilten sich in zwei Gruppen, welche die Dörfer "Vitré 1" und "Vitré 2" besiedelten.

Das Gebiet von Grand-Bassam wurde gemäß einigen Quellen vom französischen Forscher Marcel Treich-Laplène entdeckt. Andere schreiben, Treich-Laplène sei erst 1893 hierher gekommen, als das Fort Nemours bereits seit Jahrzehnten bestanden hat und bereits seit 13 Jahren unter dem Kommando von Arthur Verdier stand.

Nachdem am 9. Februar 1842 zwischen einem einflussreichen Abouré namens Attekebele, genannt "König Peter" und Leutnant de Vaisseau Kerhallet ein Vertrag abgeschlossen worden war, konnte durch Admiral Méquet die Stadt Grand-Bassam für die Franzosen gegründet werden. Sie wurde 1893 Hauptstadt der Kolonie Elfenbeinküste mit Louis-Gustave Binger als erstem Gouverneur. Es handelt sich um die erste Präfektur der französischen Kolonie. Als 1896 eine Gelbfieber-Epidemie ausbrach, veranlasste Binger die Verlegung der Kolonialverwaltung weiter westlich ins heutige Bingerville.

Die Landungsbrücke ("le wharf") von Grand-Bassam war die erste Hafenanlage der Elfenbeinküste. Mit ihrem Bau wurde 1897 begonnen. Die rund zweihundert Meter lange Brücke überwand die Brandung und erlaubte es den Schiffen, sicher anzulegen. Als 1923 eine zweite Landungsbrücke dem Verkehr übergeben werden konnte, geschah dies gerade zur rechten Zeit, denn die alte versank in einem Sturm in den Wellen. Ein Jahr zuvor waren 76.000 Tonnen Waren umgeladen worden. Auch in den kommenden zehn Jahren blieb dies der einzige Tiefseehafen der Kolonie, welcher seine Kapazitätsgrenze im Jahre 1929 mit 172.000 Tonnen Umschlag erreichte. Die Kapazität wurde durch die im gleichen Jahre erbaute, aber erst 1931 in Betrieb genommene Landungsbrücke in Port Bouët schließlich verdoppelt. Grand-Bassam blieb jedoch eine wichtige Hafenstadt, bevor 1950 der Tiefseehafen von Abidjan eröffnet wurde. Überreste der Landungsbrücke von 1923 gelten heute noch als Sehenswürdigkeit.

Der Leuchtturm der Stadt wurde 1915 erbaut, andere Quellen nennen ein Jahr früher als Baujahr. Er weist eine Höhe von vierundzwanzig Metern auf und besteht aus mit Kalk verputztem und weiß gestrichenem Blockmauerwerk, das von einer Galerie und der Laterne abgeschlossen wird. Offensichtlich ist der Verputz zwischenzeitlich an den meisten Stellen abgefallen. Letzte Nachweise über den Betrieb stammen aus dem Zweiten Weltkrieg. Danach war das Leuchtfeuer anscheinend von den 1950er-Jahren bis zu den 1970er-Jahren außer Betrieb. Der Turm steht auf einem Landstreifen zwischen dem Atlantischen Ozean und der Ouladine-Lagune. Die Fokalfläche beträgt 32 Meter und das Licht leuchtet alle fünf Sekunden auf. Der Standort des Turmes ist zugänglich, der Turm selbst jedoch nicht.

Heute ist die Stadt ein Touristenort und Sitz des Bischofs von Grand-Bassam, einer der beiden Suffragandiözesen des Erzbistums Abidjan mit der "Cathédrale Sacré-Cœur de Grand-Bassam" von 1910.

Bei Anschlägen am 13. März 2016 erschossen Terroristen der al-Qaida im Maghreb am Strand und in Strandnähe 14 Touristen.

Die historische Altstadt von Grand-Bassam wurde 2012 in die UNESCO-Welterbeliste aufgenommen als herausragendes Beispiel einer Kolonialstadt des späten 19. und frühen 20. Jahrhunderts mit für spezielle Belange geplanten Stadtvierteln, so etwa für Handel, Verwaltung und getrennten Wohnvierteln für Afrikaner und Europäer, basierend auf Prinzipien des Funktionalismus und der Hygiene unter Berücksichtigung der klimatischen Gegebenheiten. Die Gebäude sind in teils schlechtem Zustand und von weiterem Verfall bedroht. Zum Bereich des Welterbes gehört das Fischerdorf N’zima.

Zu den herausragenden Gebäuden zählen die Offiziersmesse, der Gouverneurspalast, der Justizpalast von 1911, das "Hôtel des Postes et Douane", der bauliche Komplex der Katholischen Kirche und das "Maison Ganamet".

Der Verein Moossou FC spielt zur Saison 2015/16 in der höchsten ivorischen Spielklasse, ein weiterer Verein ist USC Bassam. Beide Vereine tragen ihre Spiele im 3000 Zuschauer fassenden "stade municipal de Bassam" aus.



</doc>
<doc id="2007" url="https://de.wikipedia.org/wiki?curid=2007" title="Geschichte Kretas">
Geschichte Kretas

Die Geschichte Kretas lässt sich in die "vorgeschichtliche" und die "historische Zeit" unterteilen. Die Minoische Kultur (ca. 3000 v. Chr.–ca. 1050 v. Chr.) wird teilweise zur vorgeschichtlichen, teils zur historischen Epoche gerechnet.

Zu der fossil erhaltenen, ausgestorbenen endemischen Fauna Kretas gehörten Zwergflusspferde, Zwergelefanten, Zwerghirsche "(Praemegaceros cretensis)", außerdem große Nagetiere und Insektenfresser und Raubtiere wie Dachse, Marder und eine landlebende Otterart. Große Fleischfresser fehlten dagegen völlig.

Der genaue Zeitpunkt der ersten Besiedlung Kretas ist nicht bekannt. Spuren möglicher früher Hominiden reichen bis 5,7 Millionen Jahre zurück, der Zeit der Messinischen Salinitätskrise. Eine 2002 entdeckte und 2017 von Forschern bei Trachilos, nahe dem Hafen von Kissamos, untersuchte versteinerte Fußspur von etwa 50 Abdrücken wäre eines der ältesten Zeugnisse menschlicher Vorfahren überhaupt (Koordinaten der Fundstelle: ). Die Abdrücke stammen von einem aufrecht gehenden Lebewesen, unterscheiden sich jedoch von denen gewöhnlicher Tiere, wie Bären oder Affen. Neben einem Fußballen weisen fünf Zehen, darunter ein großer Zeh, nach vorn, was auf einen Homininen weist.

Paläolithische Funde von Steinwerkzeugen werden auf ein Alter von mindestens 130.000 Jahren zurückgeführt, sind indes nicht zuverlässig datiert. Die neun Fundstellen liegen an der Südküste bei Plakias (Kotsifou, Schinaria, Timeos Stavros, Gianniou) und am Unterlauf des Megalopotamos (Preveli), alle in der Gemeinde Agios Vasilios. Curtis Runnels, Steinwerkzeug-Fachmann und Expeditionsteilnehmer in Südkreta, hält nach stilistischen Merkmalen der gefundenen Schaber und Faustkeile ein Alter von 130.000 bis 700.000 Jahren für möglich. Damit stammten sie nicht vom modernen Menschen "(Homo sapiens)", sondern einer vorzeitlichen Menschenart, entweder dem Heidelbergmenschen "(Homo heidelbergensis)" oder dem Neandertaler "(Homo neanderthalensis)".

Ebenfalls an der Südküste Kretas in der Gemeinde Agios Vasilios wurden an zwanzig Stellen etwa 1600 mesolithische (mittelsteinzeitliche) Steinobjekte entdeckt, beispielsweise Projektilspitzen, Stichel und Schaber. Diese sind bis zu 11.000 Jahre alt. Die Fundstellen befinden sich bei Damnoni, Ammoudi, Schinaria, Timeos Stavros, Preveli und Agios Pavlos. Die archäologische Expedition von 2008/09 unter Leitung von Thomas Strasser hatte das Ziel, Belege für eine vor dem Neolithikum (Jungsteinzeit) erfolgte Besiedlung Kretas zu finden und damit die bis dahin fraglichen mesolithischen Funde aus der Samaria-Schlucht, die hauptsächlich durch Begehung entstanden sein sollten, beweiskräftig zu ersetzen.

In den neolithischen Siedlungen wurden bisher keine Knochen der endemischen Inselfauna gefunden, sie starb vor Ankunft der ersten bäuerlichen Siedler aus, wie dies auch von anderen Mittelmeerinseln (Zypern, Sardinien, Mallorca) bekannt ist. Erste eindeutige anthropomorphe Zeugnisse stammen aus dem frühen Neolithikum und werden auf etwa 6000 v. Chr. datiert. Hier sind die akeramischen Schichten von Knossos bedeutsam. In dieser Periode betrieb man bereits Ackerbau. Erst seit etwa 5500 v. Chr. wurde Keramik hergestellt.

→ "Hauptartikel:" Minoische Kultur

Die Minoische Zeit beginnt etwa 3000 v. Chr. und steht einerseits in der Tradition der einheimischen neolithischen Vorgängerkultur, wurde andererseits aber auch durch starke Einflüsse und eventuelle Einwanderung aus Kleinasien befruchtet. Auch die Metallverarbeitung wurde wahrscheinlich aus Kleinasien übernommen. Dies bewirkte einen kulturellen und wirtschaftlichen Aufschwung, der sich im Entstehen der „Minoischen“ Kultur niederschlug. Die Minoische Kultur endete im 13. Jahrhundert v. Chr., als sich auf Kreta die Mykenische Kultur vom griechischen Festland durchsetzte.

Nach dem Untergang der minoischen Kultur wurde Kreta von den mykenischen Griechen beherrscht, ihnen folgten seit dem 11. Jahrhundert v. Chr. weitere Eroberer vom griechischen Festland. Auf der Insel bildeten sich eine Anzahl selbstständiger Poleis heraus. Auf die Geschehnisse des griechischen Festlands nahmen diese keinen Einfluss und umgekehrt versuchten die Hauptmächte des antiken Griechenlands – allen voran Sparta und Athen – niemals, Kreta zu erobern. Gering war das Interesse der griechischen Historiker an den Geschehnissen auf der Insel und es gibt daher eher wenige schriftliche Zeugnisse über die Geschichte Kretas.
Über das archaische Zeitalter lässt sich aber mit Sicherheit aussagen:
In der Zeit vom 6. bis zum 4. Jahrhundert währte auf der Insel Kreta eine relative Friedensperiode, durch umfassende herrschaftspolitische Maßnahmen (u. a. Gesetze, vgl. das Stadtrecht von Gortys) war oberflächlich ein Ausgleich zwischen den dominierenden aristokratischen Kräften ersichtlich. Erst in der zweiten Hälfte des 4. Jahrhunderts ging die alte aristokratische Ordnung, die stark an den Machterhalt einiger weniger Familien orientiert war, durch Machtkämpfe zwischen diesen zu Grunde.

Die Gesellschaft des archaischen Kretas kann man als recht eigentümlich auffassen. In vielen Merkmalen ähnelte sie der Spartas. Der Adel betrieb Herrschaftspolitik durch Einflussnahme auf die jungen Männer in Form von Päderastie und gemeinsam lebende Jungmannschaften, also Sport- und Kampfgruppen unter einem Paidonomos. Diese Jungmannschaften gingen nach der Volljährigkeit in die Mahlgemeinschaften über, in denen die Bürgerschaft organisiert waren. Bürger konnte man nur sein, sofern man an den gemeinsamen Mählern, die überwiegend von den wohlhabenden Kretern finanziert wurden, teilnahm. „Regiert“ wurde Kreta durch Kosmen, deren Anzahl pro Stadt differierte. Jenes Amt wurde nach dem Rotationsprinzip an die einflussreichsten Familien vergeben – freilich um Machtkämpfe zu vermeiden. Wohl einen großen Stellenwert im archaischen Kreta hatte die Familie – ihr Schutz und Erhalt wurde von vielerlei Gesetzen (vgl. das Erbschafts-, Schuld- und Familienrecht der "Großen Inschrift" von Gortys) gewährleistet.
Das wirtschaftliche Potential der Insel wurde durch fortwährende Kriege zwischen den verschiedenen Poleis geschwächt.

Der Spartanerkönig Agis III. setzte, als Alexander der Große in Kleinasien stand und einen ersten Sieg gegen das Perserreich errungen hatte, 333 v. Chr. noch immer auf die persische Karte. Durch seinen Bruder und Mitregenten Agesilaos ließ er Kreta besetzen. Im Frühjahr 332 v. Chr. begannen die makedonischen Nauarchen Hegelochos und Amphoteros die Inseln zu besetzen – von Tenedos und Chios bis nach Kos und schließlich Lesbos. Amphoteros unterwarf schließlich die kretischen Stützpunkte.

Zwischen 267 und 261 v. Chr. intervenierten die ägyptischen Ptolemäer auf Kreta, aber sie konnten die Insel, zwischen deren Städten der Krieg zum Dauerzustand geworden war, nicht befrieden. 220 folgte eine Intervention Philipps V. von Makedonien, der mit der kretischen Stadt Gortyn verbündet war. Er konnte die Verhältnisse auf Kreta stabilisieren, zog aber die Kreter in seinen Konflikt mit der römischen Republik hinein. In den Makedonischen Kriegen zwischen 214 und 196 war Kreta mit Philipp verbündet, ohne dass sich die Niederlagen des Königs auf die Insel auswirkten. Der römische Sieg führte nur zur erneuten Unabhängigkeit der kretischen Städte und die alten Rivalitäten zwischen Knossos, Cydonia und Gortyna flammten unverzüglich wieder auf. Der römische Senat schickte mehrfach (184, 180 und 174 v. Chr.) Gesandte als Vermittler, ohne dass diese etwas bewirkten. Die Instabilität Kretas bot den besten Nährboden für Piraten und Sklavenhändler, die auf der Insel leicht Unterschlupf fanden und mit dieser oder jener Stadt paktierten. Die Rhodier, als wichtigste griechische Handelsmacht jener Zeit, versuchten die Situation zu ordnen und unternahmen 154 v. Chr. einen Kriegszug nach Kreta. Sie wurden jedoch vernichtend geschlagen. Nur eine römische Intervention verhinderte die totale Niederlage.

Im ersten Jahrhundert v. Chr. begannen die Römer ernsthafter gegen die Piraten in der Ägäis vorzugehen. 74 v. Chr. ordnete der Senat deshalb die Eroberung Kretas an. Der erste Versuch unter dem Befehl des Marcus Antonius war schlecht vorbereitet und es standen zu wenig Schiffe und Truppen zur Verfügung. Antonius erlitt eine herbe Niederlage und viele Römer gerieten in Gefangenschaft. Unterdessen verhinderte der Krieg gegen Mithridates von Pontus und der Aufstand des Spartacus für einige Jahre einen neuen römischen Eroberungsversuch.
69 v. Chr. wurde der Konsul Quintus Caecilius Metellus vom Senat mit der Eroberung Kretas beauftragt. Mit Erfolg nahm er eine kretische Stadt nach der anderen ein, während Pompeius die Piraten zur See bekämpfte. Die geschlagenen Kreter wollten sich nur Pompeius unterwerfen und dieser nahm diese Unterwerfung an, obwohl Quintus Caecilius Metellus der eigentliche Eroberer war und Kreta zur römischen Provinz machte. Nicht nur dieser selbst, sondern die ganze "gens" der Meteller haben das Pompeius sehr verübelt. In Rom feierte er einen Triumph und nahm das Cognomen "Creticus" an.

Einmal befriedet fanden sich die Kreter ohne Widerstand mit der römischen Herrschaft ab. Die Insel war eine der ruhigsten Provinzen des ganzen Imperiums. Unter Kaiser Augustus wurde sie mit Gebieten in Libyen zur Provinz "Creta et Cyrenaica" vereinigt. Kaiser Diocletian trennte beide Gebiete 298 n. Chr. und bildete eine eigene Provinz Kreta. Im 3. und 4. Jahrhundert verbreitete sich das Christentum auf der Insel.

Im Jahr 365 wurde Kreta von einem sehr starken Erdbeben erschüttert. Dieses Erdbeben vor Kreta 365 richtete nicht nur in Kreta, sondern in den meisten Anrainerstaaten des östlichen Mittelmeeres Verwüstungen an.

In den Zeiten der Völkerwanderung blieb Kreta von Eroberungsversuchen germanischer und slawischer Völkerschaften verschont, sieht man von einem Zug slawischer Seefahrer im Jahr 623 ab, die möglicherweise in der Absicht kamen, dort zu siedeln.

674 erfolgte ein erster arabischer Angriff, 692 ein weiterer.
Unter ihrem Führer Abu Hafs al-Balluti (später al-Ikritishi, der Kreter genannt, die Griechen nannten ihn Apohapsis) wurden im Jahr 816 Muladí als Rebellen aus dem islamischen Spanien vertrieben. Diese 10 bis 15.000 Menschen gelangten auf Umwegen nach Ägypten, wo sie Alexandria einnehmen konnten. Nach einer schweren Niederlage gegen die Truppen des Kalifen wandten sich die Andalusier gegen Kreta, das sie möglicherweise bereits zuvor mit Raubzügen heimgesucht hatten. Ob sie es ab etwa 824 tatsächlich ganz eroberten, ist nicht sicher, und auch ihre Rolle beim Niedergang der Städte auf der Insel ist aus den wenigen Quellen nicht ablesbar. Sicher ist nur, dass sie Kreta als Basis für Kaperfahrten gegen Byzanz benutzten, dass sie es Al-Khandaq nannten, und dass das spätere Iraklion ihre Hauptstadt war.

→ "Siehe auch:" Emirat von Kreta

Byzanz versuchte mehrfach, die Insel zurückzuerobern. So scheiterten Versuche in den Jahren 826 und 828 trotz erheblicher Erfolge auch 843-844, dann erneut 865.

961 fiel die Insel wieder an das Byzantinische Reich, dessen Feldherr und späterer Kaiser Nikephoros Phokas die Insel eroberte.

→ "Siehe auch:" Venezianische Kolonien#Candia (Kreta)

Nach dem Vierten Kreuzzug erwarb die Republik Venedig 1204 Kreta von Bonifaz von Montferrat für den offiziellen Preis von 1.000 Silbermark. Noch wichtiger als das Geld war aber die Garantie des Dogen, dass Bonifatius im Gegenzug Gebiete des gleichen Werts in Griechenland bekam. Damit begann die Periode der venezianischen Herrschaft, auch "Venetokratie" (Βενετοκρατία) genannt. Die Insel wurde zur wichtigsten venezianischen Kolonie. In sechs Provinzen, deren Namen den Stadtsechsteln (sestieri) der Mutterstadt entsprachen, siedelten rund 4000 Venezianer auf die Insel über und nahmen Feudalgüter in Besitz (unter anderen die Familie der Falier, aus welcher der venezianisch-kretische Dichter Marinos Phalieros stammte). Doch die Kreter wehrten sich in etwa zehn Aufständen, die das ganze 13. Jahrhundert durchzogen – letztlich ohne Erfolg. Der größte Aufstand dauerte unter der Führung von Alexios Kalergis von 1283 bis 1299. Zwischen katholischen Venezianern und orthodoxen Griechen herrschte ein strenges Heiratsverbot.

Zugleich unternahmen Genua und Byzanz (bzw. Nikaia) mehrere Versuche, die Insel zurückzuerobern. Die Einwohnerzahl wuchs von rund 50.000 auf 200.000 an. Die Hauptstadt Candia wurde zu einem der wichtigsten Handelsrelais im östlichen Mittelmeer. 1363–1366 rebellierten die venezianischen Siedler selbst gegen die harte Fiskal- und Handelspolitik der Mutterstadt – ebenso erfolglos wie zuvor die griechischen Kreter.

Nach dem Fall Konstantinopels im Jahr 1453 flohen viele Festlandsgriechen nach Kreta; ab der Eroberung Zyperns durch die Osmanen 1570/71 war Kreta das größte verbliebene griechische Siedlungsgebiet außerhalb des Osmanischen Reiches. Die kulturelle Tradition von Byzanz wurde auf Kreta, gemischt mit italienischen Einflüssen, noch 200 Jahre nach dem Fall Konstantinopels fortgeführt. Man spricht von der "Byzantinischen Renaissance". Eine der bekanntesten Persönlichkeiten dieser Periode war der Maler Domínikos Theotokópoulos, der in Spanien als El Greco (der Grieche) berühmt wurde, jedoch auf Kreta als Ikonenmaler begonnen hatte.

Von 1645 bis 1669 eroberte das Osmanische Reich im 6. Venezianischen Türkenkrieg als eine der letzten venezianischen Bastionen auch Kreta und leitete damit die Periode der Osmanischen Herrschaft, auch "Turkokratie" (Τουρκοκρατία) genannt, auf der Insel ein. Zuletzt fiel Candia nach mehr als zwanzigjähriger Belagerung.

Unter der Herrschaft der Osmanen konvertierten einige Kreter zum Islam. In den Städten bildeten Moslems bald 70 % der Bevölkerung und die Christen waren in der Minderheit. Auf dem Land waren hingegen nur ein Viertel bis ein Drittel der Bevölkerung Moslems.
Widerständler gegen die osmanische Herrschaft zogen sich in unwegsame Gebiete wie die Sfakia zurück. Dort begann der erste kretische Aufstand gegen die türkischen Besatzer unter Daskalogiannis im Jahre 1770, er wurde jedoch blutig niedergeschlagen.

Nach dem Ausbruch der griechischen Freiheitskämpfe auf dem Festland 1821 erhoben sich die Kreter erneut, wurden jedoch 1824 von ägyptischen Truppen geschlagen. Weitere Aufstände wie die Einnahme der Festungsinsel Imeri Gramvousa (1825–1828) und die Tragödie vom Arkadi 1866 zeigten den Freiheitswillen der Kreter. 1866 wurden sie durch das italienisch-bulgarische "Garibaldi-Bataillon" unterstützt. Im Jahr 1896 rebellierte die griechisch-orthodoxe Bevölkerung wieder gegen die osmanische Herrschaft. Ein Eingreifen Griechenlands führte zum Türkisch-Griechischen Krieg, der 1897 mit einer Niederlage Griechenlands endete. Im Friedensvertrag vom 4. Dezember 1897 erhielt Kreta auf Druck der europäischen Großmächte den Status eines internationalen Protektorats.

Seit 1898 war Kreta de facto ein unabhängiger Staat unter der nominellen Oberhoheit des Sultans.

→ "Hauptartikel: Kretischer Staat"

1913 wurde die Insel infolge des Ersten Balkankriegs mit Griechenland vereinigt. Nach dem griechisch-türkischen Krieg (1919–1922) und dem Vertrag von Lausanne wurde die muslimische Bevölkerung Kretas zwangsumgesiedelt. Auswahlkriterium bei dieser Vertreibung war primär die Religionszugehörigkeit, nicht die ethnische Zugehörigkeit, d. h. auch griechischstämmige muslimische Familien wurden ausgewiesen.

Während des Zweiten Weltkrieges standen 1941 griechische, britische, australische und neuseeländische Truppen auf Kreta. Sie sollten die Insel gegen die Deutschen und Italiener halten, um die britische Schifffahrt im Mittelmeer zu sichern. Das gelang nicht, ab dem 20. Mai 1941 war Kreta Schauplatz des ersten großangelegten Luftlandeangriffs im Zweiten Weltkrieg, mit dem Ergebnis, dass die Insel von deutschen und italienischen Truppen erobert wurde. Der anschließende Partisanenkampf, dem sich große Bevölkerungsteile anschlossen, führte zu eskalierenden Kriegsverbrechen. So wurden auf Befehl von Generaloberst Kurt Student am 2. Juni 1941 die meisten männlichen Bewohner des Ortes Kondomari erschossen und die Stadt Kandanos zerstört. In der Gemeinde Viannos wurden am 14. September 1943 500 Bewohner, zumeist Frauen und Kinder erschossen. Am 20. Mai 1944 umstellten Einheiten unter dem Befehl des deutschen Kommandanten der "„Festung Kreta“" General Bruno Bräuer das jüdische Viertel (278 Mitglieder) der Stadt Chania. Flüchtende Einwohner wurden erschossen, alle anderen per Schiff nach Iraklio gebracht und zwei Wochen später nach Griechenland deportiert. Der ehemals griechische Frachter "Tanais" ("Danae"), der die überlebenden Mitglieder der jüdischen Gemeinde zusammen mit Hunderten griechischer Geiseln und einigen italienischen Kriegsgefangenen nach Athen bringen sollte, wurde am 9. Juni 1944 von dem britischen U-Boot "Vivid" torpediert und sank. Nur vier der jüdischen Einwohner Chanias sollen überlebt haben.
Bis zum Herbst 1944 blieb die gesamte Insel unter deutscher Besatzung. (Ostkreta war bis zum Ausscheiden Italiens aus dem Achsenbündnis 1943 von italienischen Truppen besetzt.) Die letzten Soldaten des deutschen Küstenjägerregiments wurden erst einen Monat nach Kriegsende von den Alliierten in Chania entwaffnet. Während der Besetzung kamen etwa 8.000 Kreter bei Kämpfen oder bei Massakern zu Tode. Bruno Bräuer wurde nach Kriegsende an Griechenland überstellt und zum Tode verurteilt. Mit dem ebenfalls wegen Kriegsverbrechen auf Kreta verurteilten General Friedrich-Wilhelm Müller wurde er am 20. Mai 1947 um 5 Uhr hingerichtet. Als bemerkenswert gilt ferner auch die Entführung des deutschen Generals Heinrich Kreipe am 26. April 1944 von Kreta nach Ägypten durch den britischen Special Operations Executive in Zusammenarbeit mit Kretern.




</doc>
<doc id="2010" url="https://de.wikipedia.org/wiki?curid=2010" title="Große Seen">
Große Seen

Die Großen Seen () sind eine Gruppe fünf zusammenhängender Süßwasserseen in Nordamerika.

Zu den Großen Seen gehören:

Hydrologisch gesehen bilden Huron- und Michigansee zusammen nur einen See mit einer schmalen Stelle, der Mackinacstraße. Der maximale Höhenunterschied zwischen den einzelnen Seen liegt bei circa 150 Meter, den größten Teil davon bilden die Niagarafälle zwischen dem Erie- und dem Ontariosee. Aufgrund ihrer Größe sind auf den Großen Seen die Gezeiten bemerkbar, die Auswirkungen sind allerdings gering und werden von meteorologischen Effekten überdeckt.
Der Michigansee liegt als einziger der Großen Seen vollständig in den USA, die anderen vier liegen entlang der kanadisch-US-amerikanischen Grenze. Durch den Sankt-Lorenz-Strom werden sie in den Atlantik entwässert.

Über 35.000 Binneninseln beziehungsweise Binnen-Inselgruppen befinden sich im Gebiet der Großen Seen. Im kanadischen Teil des Huronsees liegt beispielsweise Manitoulin Island, die mit 2.766 Quadratkilometern flächenmäßig größte Binnenseeinsel der Erde.

Im Winter erzeugt die Wasseroberfläche der Großen Seen den Lake effect snow. Der dadurch entstehende Snow Belt erstreckt sich über fünf Bundesstaaten.

Die Umgebung der Großen Seen und das Tiefland des Sankt-Lorenz-Stromes sowie seine sich noch weithin im Schelf untermeerisch fortsetzende Trichtermündung stellen geologisch eine Einheit dar.

Glaziale Ausräumung, Auflagerung von Moränenschutt und Krustenbewegungen bestimmen die Gestalt des Seengebietes, dessen Hohlformen allerdings schon durch großräumige tektonische Einmuldungen im Tertiär und zu Beginn des Pleistozäns angelegt wurden.

Eine mächtige paläozoische Schichtenfolge, die aus verschiedenen widerstandsfähigen Sandsteinen und Kalken bestehende Onondaga-Formation, umrahmt die Seen im Süden. Zwischen Ontario- und Eriesee und nördlich des Michigansees erstreckt sich die aus hartem Dolomitgestein und weichem Schiefer bestehende Niagara-Schichtstufe. Am Nordrand der Großen Seen tritt der Kanadische Schild an die Oberfläche.

Die Großen Seen sind ein wichtiges Reservoir für die Wasserversorgung der USA und Kanadas. Mit etwa 245.000 Quadratkilometern bilden sie die größte Süßwasserfläche der Erde, wobei der Baikalsee aufgrund seiner großen Tiefe die Großen Seen im Süßwasservolumen knapp übertrifft.

Durch die starke Besiedlung und Industrialisierung des Gebiets kam es jedoch zu einer immer höheren Schadstoffbelastung und zur Massenvermehrung von eingeschleppten Tier- und Pflanzenarten, wie etwa dem Meerneunauge, der Schwarzmund-Grundel und der Dreikantmuschel. Ein Wasserschutzabkommen wurde 1978 zwischen den USA und Kanada vereinbart.

Über den Illinois Waterway besteht eine Schifffahrtsverbindung zum Mississippi River, über den Sankt-Lorenz-Seeweg zum Sankt-Lorenz-Strom und damit dem Atlantik. Aufgrund der besonderen Verhältnisse auf den Seen hat sich ein eigener Typ Massengutschiff herausgebildet, das Große-Seen-Schiff.

Die Interlake Steamship Company besteht seit 1987.




</doc>
<doc id="2011" url="https://de.wikipedia.org/wiki?curid=2011" title="Genyornis">
Genyornis

Genyornis ist eine im Pleistozän ausgestorbene Gattung der Donnervögel (Dromornithidae), die in Australien lebte und vor etwa 47.000 Jahren plötzlich ausstarb. Die einzig bislang bekannte Art "Genyornis newtoni" wurde nach dem englischen Zoologen und Ornithologen Alfred Newton benannt. "Genyornis" ist die einzige noch im Pleistozän lebende Donnervogelgattung. Fossilien der Gattung wurden in allen australischen Bundesstaaten gefunden. "Genyornis" ist auch die einzige Donnervogelgattung, von der ein im anatomischen Zusammenhang gefundenes Skelett vorhanden ist.

"Genyornis" wurde 2,0 bis 2,15 Meter hoch, etwa 290 kg schwer und war damit ein mittelgroßer Donnervogel, kleiner als "Bullockornis planei" und "Dromornis stirtoni" aber größer als "Ilbandornis woodburnei". Der Schädel von "Genyornis" war konisch, der Schnabel war weniger hoch und weniger seitlich abgeflacht als der von "Bullockornis" und "Dromornis". Wahrscheinlich nahm der Vogel Gastrolithen zur Zerkleinerung der vor allem aus Blättern bestehenden Nahrung auf, die mit einigen Skeletten gefunden wurden.

Untersuchungen von verbrannten Eierschalen von "Genyornis", gefunden an mehr als 200 Orten in ganz Australien, zeigen, dass die Population plötzlich vor etwa 47.000 Jahren zusammenbrach. Wahrscheinlich ist "Genyornis" ausgestorben, weil Aborigines ihre Eier gesammelt, in Feuern gebraten und gegessen haben.




</doc>
<doc id="2012" url="https://de.wikipedia.org/wiki?curid=2012" title="Genua">
Genua

Genua ( , im Ligurischen "Zena") ist die Hauptstadt der italienischen Region Ligurien. Das im Nordwesten des Landes am Ligurischen Meer gelegene ehemalige Zentrum der im Mittelalter bedeutenden Republik Genua ist heute Verwaltungssitz einer gleichnamigen Metropolitanstadt.

Die Stadt ist mit circa 590.000 Einwohnern die sechstgrößte Italiens. In der Agglomeration hat Genua rund 800.000 Einwohner und 1,5 Millionen in der Metropolregion.

Die Prachtstraßen "Le Strade Nuove" mit den Renaissance- und Barockbauten der "Palazzi dei Rolli" im Zentrum der Altstadt wurden im Jahre 2006 von der UNESCO zum Welterbe erklärt.

In der Bucht von Genua steigt das Gebirge des Apennin landeinwärts steil an und legt damit die gesamte Charakteristik der Stadt fest. Genua ist aufgrund seiner Lage eine fast ausschließlich dem Meer zugewandte Stadt. Deutlich wird dies beispielsweise bei einer Zugfahrt von Mailand nach Genua: Nach minutenlangen Fahrten durch stockdunkle Tunnel erscheinen unvermittelt das Mittelmeer und die Stadt.

In Genua wird die Trennung zwischen dem extrem dicht besiedelten, oft planlos verbauten Küstenstreifen und dem dörflich geprägten, von zunehmender Abwanderung betroffenen, strukturarmen Hinterland, die ganz Ligurien prägt, besonders deutlich. Noch heute können aufgrund dieser Gegensätze die Berührungspunkte der Genuesen mit weit entfernten Hafenstädten im gesamten Mittelmeerraum größer sein als mit einem geographisch zwar nur wenige Kilometer entfernten, nach Tradition und Mentalität aber Welten entfernten Bergdörfchen im Apennin.

Geographisch gesehen bildet Genua genau die Mitte der italienischen Region Ligurien. Die sich etwa 35 km an der Mittelmeerküste entlangziehende Stadt geht in südöstlicher Richtung in die sogenannte Riviera di Levante (bis La Spezia), in südwestlicher Richtung in die Riviera di Ponente (bis Ventimiglia) über.

In Genua ist es üblich, regionale Ortsangaben hauptsächlich mit den Richtungen "Levante" (also südöstlich von Genua) beziehungsweise mit "Ponente" (westlich von Genua) anzugeben.

Genua bekam in der italienischen Sprache oft den Zusatz "la superba" oder "la dominante".

Das Klima Genuas ist ein maritim gemäßigtes, mit Übergängen zum mediterranen Klima, und wird oft von den Atlantikwinden der Westwindzone beeinflusst. Ausläufer des Mistralwindes begünstigen in der Region Genuas die Bildung von Tiefdruckwirbeln.

Die Tagestemperaturunterschiede sind das Jahr über relativ gering und konstant bei circa 6 °C. Die Jahresdurchschnittstemperatur liegt bei +15,6 °C; mit dem Januar als kältestem Monat mit +8,0 °C und dem Juli als wärmsten mit +23,9 °C im Mittel. Die Luftfeuchtigkeit ist das Jahr über relativ hoch, insbesondere im Sommer und den gemäßigten Jahreszeiten. Der Jahresniederschlag liegt bei 1072 mm, mit Niederschlägen im ganzen Jahr, die jedoch zwischen September und November ihren Höchststand und im Juli ihren niedrigsten Stand erreichen. Der (stets präsente) Wind bläst im Winter zumeist aus nördlicher Richtung und im Frühling und in der ersten Herbsthälfte aus dem Süden.

Aufgrund der Besonderheiten des städtischen Territoriums hat jedoch jeder einzelne Stadtteil, innerhalb dieses makroskopischen Klimabildes, sein eigenes Mikroklima, das sich von dem der anderen Stadtteile in Temperatur, Luftfeuchtigkeit, Niederschlag und Sonnenexposition unterscheidet.

Die dem Küstenverlauf folgende Stadtfläche wird an ihren beiden Ausläufern von zwei Flüssen durchquert. Im "Levante" (östlicher Ausläufer) der Bisagno, mit seiner Mündung im Stadtteil Foce, und im "Ponente" (westlicher Ausläufer) von dem Fluss Polcevera, der die Stadtteile Sampierdarena und Cornigliano trennt. In dieser Weise lassen sich fünf große Zonen abgrenzen: das Zentrum, Valpolcevera, Valbisagno, Ponente und Levante. Politisch ist Genua seit dem 24. März 1997 in neun Munizipien unterteilt:

Die Munizipien setzen sich aus insgesamt 31 Stadtteilen zusammen.

Während des Faschismus wurde das Territorium der Stadt Genua um ein Vielfaches vergrößert. Dazu wurden 1926 zahlreiche Gemeinden in die Stadt eingegliedert. Im Westen erreichte die Stadtgrenze dadurch Voltri, im Osten Nervi und im Norden Pontedecimo und Molassana. Diese Stadterweiterung schuf das sogenannte "Groß-Genua". Die ehemals eigenständigen Stadtteile Genuas haben jedoch ihre Struktur als Kleinstadt in der Regel beibehalten, mit eigenen Zentren, Peripherien, eigener Kultur und eigenen Traditionen.

Während des ökonomischen Aufschwungs wurden in den 1960er Jahren neue Stadtteile, wie beispielsweise Ca' Nuova und Biscione, gegründet.

Nach einem mäßigen Wachstum in der zweiten Hälfte des 19. Jahrhunderts, das durch eine hohe Abwanderungsrate nach Amerika bestimmt war, kam es im 20. Jahrhundert zu einer regelrechten Bevölkerungsexplosion, begünstigt durch die positive Entwicklung des Hafens und der Schwerindustrie. In einer ersten Phase zogen hauptsächlich Bewohner des ligurischen Hinterlandes und von Piemont nach Genua. Nach dem Ersten Weltkrieg wurde dieser Zuzug von Venezianern und Friaulern konstant gehalten.

In dem Zeitraum der 1960er bis 1970er Jahre zogen hauptsächlich Süditaliener (Sizilianer und Sarden) nach Genua. Der anhaltende Zustrom von Einwanderern brachte auch logistische und urbane Probleme mit sich. So mussten, um genug Siedlungsfläche zu bieten, zwei Hügel abgetragen und ein Flussbett zugeschüttet werden.

In den 1980er Jahren kam das Bevölkerungswachstum schließlich ins Stocken, um sich in den folgenden Jahren in eine „Bevölkerungsimplosion“ zu verwandeln. Von 816.000 Einwohnern 1971 sank die Population auf 610.000 im Jahre 2001 (das bedeutet eine Bevölkerungsminderung von 25 % innerhalb von 30 Jahren). Begünstigt wurde diese Entwicklung durch das sehr hohe Durchschnittsalter, das eine höhere Sterberate im Vergleich zur Geburtenrate mit sich brachte (2006: 4680 Geburten bei 8158 Sterbefällen). Das Durchschnittsalter der Genueser liegt bei 47,0 Jahren, mit einem Höchstwert von 48,5 Jahren im Stadtgebiet des "Medio Levante". Der Altenquotient (Verhältnis von den "über 65-Jährigen" zu den "unter 15-Jährigen") liegt bei 242,0. Im März 2007 lebten 288.616 (47 %) Männer und 325.525 (53 %) Frauen in Genua.

Bei der Stadtverwaltung von Genua sind 299.165 Familien („nucleo familiare“), bestehend aus durchschnittlich 2,04 Personen, gemeldet (Stand: Dezember 2006). Von den gemeldeten Familien bestehen 41,4 % aus nur einer Person, 28,2 % aus zwei, 18,4 % aus drei, 9,9 % aus vier und 2,1 % aus fünf oder mehr Personen.

Die größte nicht-italienische Bevölkerungsgruppe stellten 2006 Ecuadorianer mit 12.734 gemeldeten Einwohnern, gefolgt von Albanern, Marokkanern, Peruanern, Nigerianern, Chinesen und Rumänen. Die Einwanderungsrate liegt seit 2003 über der Auswanderungsrate.

Der Name der Stadt ist vom lateinischen "" ‚das Knie‘ abgeleitet.

Da Genua einen Naturhafen ersten Ranges hat, muss es als Seehafen benutzt worden sein, sobald begonnen wurde, im Tyrrhenischen Meer Schifffahrt zu betreiben. Aus antiken Schriftquellen ist nichts über einen Aufenthalt oder eine Besiedelung durch Griechen bekannt, die Entdeckung eines griechischen Friedhofs aus dem 4. Jahrhundert v. Chr. deutet aber darauf hin. Beim Bau der "Via XX. Settembre" wurden 85 Gräber gefunden, von denen der Großteil auf das Ende des 5. und das 4. Jahrhundert v. Chr. datiert. Die Leichen waren in allen Fällen verbrannt und in kleinen Schachtgräbern beerdigt worden, wobei das Grab selbst durch eine Platte aus Kalkstein bedeckt wurde. Die Urnen entsprechen dem letzten rotfigurigen Stil und wurden hauptsächlich aus Griechenland oder "Magna Graecia" importiert, während die Bronzeobjekte aus Etrurien und die Broschen aus Gallien kamen. Dies veranschaulicht die frühe Bedeutung Genuas als Handelshafen und das Eindringen griechischer Sitten, denn die übliche Praxis der Ligurier war die Erdbestattung. Man nimmt an, dass sich der Name Genua aus der Form seiner Küstenlinie ableitet, die an ein Knie ("") erinnert.

Vom Auftauchen der Römer wird erstmals 216 v. Chr. berichtet, von der Zerstörung durch die Karthager und dem unmittelbaren Wiederaufbau durch die Römer 209 v. Chr. Die Römer machten Genua und Placentia zu ihrem Hauptquartier gegen die Ligurier. Von Rom aus kam man dorthin über die "Via Aurelia" entlang der Nordwestküste und ihre Verlängerung, die später den Namen "Via Aemilia" (Scauri) bekam. Letztere wurde erst 109 v. Chr. gebaut; es muss aber schon lange vorher eine Küstenstraße gegeben haben, mindestens ab 148 v. Chr., als die "Via Postumia" von Genua durch Libarna (heute Serravalle Scrivia, wo Überreste eines Amphitheaters und Inschriften gefunden worden sind), Dertona, Iria, Placentia, Cremona und von da ostwärts gebaut wurde. Es gibt eine Inschrift von 117 v. Chr. (im "Palazzo Municipale" in Genua erhalten) mit der Entscheidung der "patroni" Q. und M. Minucius aus Genua, in Übereinstimmung mit einem Erlass des römischen Senats in einer Kontroverse zwischen dem Volk Genuas und den Langenses (auch Viturii genannt), den Einwohnern einer benachbarten Hügelstadt, die in das Genueser Territorium aufgenommen wurde. Aber keine der anderen in Genua gefundenen Inschriften, die praktisch allesamt Grabesinschriften sind, kann definitiv der antiken Stadt zugeordnet werden; man kann gleichermaßen annehmen, dass sie von anderen Orten über See dorthin gebracht wurden. Nur aus Inschriften an anderen Orten wissen wir, dass Genua Stadtrechte hatte, aber es ist unbekannt, ab welchem Zeitpunkt. Klassische Autoren berichten wenig von der Stadt.

Die Geschichte Genuas während der langobardischen und karolingischen Perioden ist lediglich die Wiederholung der allgemeinen Geschichte der italienischen Kommunen, denen es gelang, von wettstreitenden Fürsten und Baronen die ersten Urkunden ihrer Freiheit zu erlangen. Der patriotische Geist und die Tüchtigkeit der Genuesen auf See, die sie in ihren Verteidigungskriegen gegen die Sarazenen entwickelten, führte zur Gründung einer bürgerlichen Verfassung und zum raschen Wachstum einer wirksamen Marine. Aus der Notwendigkeit eines Bündnisses gegen den gemeinsamen sarazenischen Feind schloss sich Genua Anfang des 11. Jahrhunderts mit Pisa zusammen, um die Muslime von der Insel Sardinien zu vertreiben und zur mittelalterlichen Kolonialmacht aufzusteigen.

Bereits 1162 errichteten Genueser in Salé, zwischen Tanger und Casablanca gelegen, einen Stützpunkt an der afrikanischen Atlantikküste, zu dem 1253 das südwestlich von Casablanca gelegene Safi kam. 1277 eröffneten sie die ersten Seeverbindungen von Spanien mit Flandern und England. Ab 1251 genossen sie in Sevilla steuerliche Privilegien. Genueser Kaufleute haben schon vor dem Ende der Reconquista den Handel mit Olivenöl, Wein, Thunfisch, Leder, Seife und Quecksilber auf der iberischen Halbinsel in Cádiz, Granada, Lissabon, Málaga und Sanlucar zu ihrer Domäne gemacht. Die Eroberungen Gran Canarias, Las Palmas und Teneriffas wurden durch genuesisches Handels- und Kreditkapital finanziert unter aktiver Teilnahme spanischer und portugiesischer Unternehmer, wie z. B. der Tuchfabrikanten. Auch in Valencia, Toledo und Cuenca hatten Genueser großen Anteil am kastilischen Handel. Zu den "alberghi ligures", den Genueser Familien, die in Andalusien dauerhaft ansässig wurden, zählen die "Boccanegra", "Cataño", "Centurión", "Espinola", "Grimaldo", "Pinelo", "Rey", "Riberol", "Sopranis", "Zaccaría" u. a. Anders als die Venezianer verfügten die Genueser nicht über eine große Kriegsmarine. Genuesisch-pisanischer Technologietransfer verhalf den iberischen Monarchien Portugal, Kastilien-León und Aragón-Katalonien nach und nach zu eigenen, leistungsfähigen Flotten, die von den eroberten Häfen entlang der Straße von Gibraltar die maurische Seesperre mit der Zeit durchbrachen.

Das so erworbene sardische Gebiet lieferte bald Gelegenheit zu Eifersüchteleien zwischen den Verbündeten Genua und Pisa. Zwischen den beiden Republiken begannen lange Seekriege, die schließlich katastrophal für Pisa ausgingen. Mit nicht weniger Gewandtheit als Venedig nahm Genua all die Gelegenheiten des umfangreichen Speditionsverkehrs zwischen Westeuropa und dem Nahen Osten wahr, die sich durch die Kreuzzüge ergaben. Die den Sarazenen in der gleichen Periode entrissenen Seehäfen entlang der spanischen Küste und die vor Smyrna (Izmir) gelegene ägäische Insel Chios wurden Genueser Kolonien, während in der Levante, an den Küsten des Schwarzen Meeres und entlang den Ufern des Euphrat starke Genueser Festungen errichtet wurden. Es ist nicht verwunderlich, dass diese Eroberungen bei Venezianern und Pisanern erneuten Neid hervorriefen und neue Kriege provozierten. Aber der Kampf zwischen Genua und Pisa fand in der Seeschlacht bei Meloria 1284 sein für Pisa verheerendes Ende.

Der Erfolg Genuas in Handel und Seefahrt während des Mittelalters ist umso bemerkenswerter, als es im Gegensatz zu den rivalisierenden Venezianern ständig von inneren Uneinigkeiten geplagt wurde. Das einfache Volk und der Adel kämpften gegeneinander, rivalisierende Parteien unter den Adligen strebten danach, die Vormacht im Staat zu erlangen. Adelige und Volk gleichermaßen wandten sich zur Schlichtung und Herrschaft an ausländische "capitani del popolo", als einziges Mittel, um einen vorübergehenden Waffenstillstand zu erreichen. Aus diesen Kämpfen zwischen rivalisierenden Adligen, in denen die Namen "Spinola" und "Doria" herausragen, wurde Genua bald in den Strudel der guelfischen und ghibellinischen Parteien hineingezogen; aber seine Anerkennung ausländischer Autoritäten – nacheinander Deutsche, Neapolitaner und Mailänder – machte 1339 den Weg zu einem unabhängigeren Staat frei. Die Regierung nahm nun eine bleibendere Form an mit der Ernennung des ersten Dogen (eines Amts auf Lebenszeit) Simone Boccanegra. Abwechselnde Siege und Niederlagen der Venezianer und Genuesen – unter den Niederlagen die schlimmste die Niederlage gegen Venedig bei Chioggia 1380 – endeten in der Feststellung der signifikanten Unterlegenheit der Genueser Herrscher, die mal unter die Macht Frankreichs, mal der Visconti aus Mailand fielen.

Der "Banco di San Giorgio" mit seinen großen Besitzungen hauptsächlich auf Korsika bildete während dieser Phase das stabilste Element im Staat, bis 1528 der Nationalgeist seine alte Kraft wiedergewann, als Andrea Doria die französische Vorherrschaft abschütteln und die alte Form der Regierung wiederherstellen konnte. In diesem Zeitraum – dem Ende des 15. und Anfang des 16. Jahrhunderts – entdeckte der Genueser Seefahrer Christoph Kolumbus im Auftrage Spaniens die Neue Welt. Die Regierung, wie sie von Andrea Doria wiedereingesetzt worden war, mit bestimmten Änderungen, die ihr einen konservativeren Charakter verliehen, blieb bis zum Ausbruch der Französischen Revolution und der Bildung der Ligurischen Republik unverändert. Während dieses langen Zeitraums von fast drei Jahrhunderten, in dem der dramatischste Vorfall die „Verschwörung der Fieschi“ war, entdeckten die Genueser den Ausgleich für den verlorenen Osthandel in den enormen Gewinnen, die sie als Bankiers der spanischen Krone und Ausrüster der spanischen Armeen und Flotten sowohl in der Alten als auch in der Neuen Welt machten. Anders als viele andere italienische Städte war Genua vergleichsweise immun gegen fremde Vorherrschaft.

Gegen Ende des 17. Jahrhunderts wurde die Stadt von den Franzosen beschossen und 1746, nach der Niederlage von Piacenza, an die Österreicher übergeben, die jedoch schnell verjagt wurden. Eine 1729 begonnene Revolte in Korsika wurde mit Hilfe der Franzosen unterdrückt, die 1768 selbst die Insel in Besitz nahmen (siehe Korsika).

Die kurzlebige Ligurische Republik, gegründet 1797 und völlig von Frankreich abhängig, wurde schon 1805 vom französischen Kaiserreich einverleibt. 1804 erhob sich Genua gegen die Franzosen, auf die Zusicherung von Lord William Bentinck hin, dass die Alliierten der Republik wieder ihre Unabhängigkeit zurückgeben würden. Durch eine Geheimklausel im Vertrag von Paris war jedoch festgelegt worden, dass Genua mit dem Herrschaftsgebiet des Königs von Sardinien vereinigt werden sollte; diese Vorkehrung wurde vom Wiener Kongress bestätigt. Zweifellos hat die durch diese Klausel hervorgerufene Unzufriedenheit dazu beigetragen, dass in Genua der republikanische Geist am Leben blieb und durch den Einfluss des jungen Genuesen Giuseppe Mazzini nicht nur für die sardische Monarchie, sondern für alle Regierungen der Halbinsel eine ständige Bedrohung blieb. Selbst der materielle Nutzen aus der Vereinigung mit Sardinien und die konstitutionelle Freiheit, die König Karl Albert all seinen Untertanen gewährte, konnten nicht die republikanischen Unruhen von 1848 verhindern. Nach einem kurzen und scharfen Kampf wurde die vorübergehend von den Republikanern besetzte Stadt von General Alfonso La Marmora wieder zurückgewonnen. Im späten 19. und frühen 20. Jahrhundert konnte Genua seine Rolle als bedeutender Seehafen und ein wichtiger Stahl- und Schiffbauzentrum ausbauen.

Im Zweiten Weltkrieg kam die Stadt nach dem Kriegseintritt Italiens auf alliierter Seite 1944 unter deutsche Besatzung und wurde zur Festung erklärt. Die Ausführung des Befehls zur Sprengung des Hafens und der Altstadt (heute Weltkulturerbe) nach dem Näherrücken der Front im März 1945 wurde vom deutschen Stadtkommandanten General Günther Meinhold verweigert. Als einzige der von den Deutschen besetzten Städte wurde Genua nicht den Alliierten, sondern am 25. April 1945 kampflos den Partisanen übergeben. Meinhold wurde umgehend von dem Marinekommandanten Kapitän zur See Max Berninghaus zum Tode verurteilt, und diese Tatsache nach Berlin gemeldet. Hitler bestätigte das Urteil, das es jedem Soldaten ermöglichte, Meinhold zu erschiessen. Meinhold überlebte dank seiner Beliebtheit bei der Truppe. In der Villa Migone ist eine Gedenkstätte eingerichtet und heute zu besichtigen.

In den Nachkriegsjahren spielte Genua eine entscheidende Rolle im italienischen Wirtschaftswunder ("miracolo economico"). Es bildete das sogenannte "Industrie-Dreieck" in Norditalien, das auch Mailand und Turin mit einschloss. Seit 1962 hat sich die "Genoa International Boat Show" als eine der größten jährlich wiederkehrenden Ereignisse in Genua entwickelt. Mit dem wirtschaftlichen Strukturwandel und der Deindustrialisierung in den 1980er Jahren ergaben sich für Genua große Probleme, Arbeitsplätze gingen verloren und die Einwohnerzahl sank. Die Kriminalität stieg stark an, die Altstadt Genuas war im Niedergang begriffen. Die Explosion des Ölfrachters Haven verschmutzte 1991 die Küste um Genua und in Südfrankreich.

Für die Kolumbusfeiern von 1992 zum 500-jährigen Jubiläum der Entdeckung Amerikas wurde der „Alte Hafen“ zur Tourismusattraktion ausgebaut. Im Juli 2001 fand der 27. G8-Gipfel in Genua statt. Überschattet wurde die Konferenz von gewaltsamen Auseinandersetzungen mehrerer hunderttausend Globalisierungskritiker und der italienischen Polizei. Neben hunderten Verletzten wurde der 23-jährige Carlo Giuliani durch einen Schuss eines Polizisten getötet.

Im Jahr 2004 hat die Europäische Union Genua – zusammen mit der französischen Stadt Lille – als Kulturhauptstadt Europas ausgezeichnet. Als Teile der Altstadt 2006 von der UNESCO zum Weltkulturerbe erklärt wurden, änderte sich die Situation für Genua in vielen Belangen zum Positiven.

Beschreibung: in Silber ein rotes durchgehendes gemeines Kreuz, über dem Schild eine goldene siebentürmige Mauerkrone und am Schildfuß ein Spruchband mit der Devise „LIBERTAS“ in silbernen Majuskeln. Zwei goldene schwarzgezungte Greife stehen auf einer Arabeske und halten den Schild.

Im 16. bis 18. Jahrhundert machte die Genueser Schule in der Malerei von sich reden.

Genua verdankt seine kulturelle Wiederbelebung zu einem großen Teil seinen Umweltprojekten im Hinterland (z. B. die Gründung verschiedener Naturparks, wie dem Naturpark Beigua und dem Naturpark Aveto), aber vor allem den strukturellen Maßnahmen im Stadtzentrum selbst. Hier wurde im Zusammenhang mit der Feier zum Kolumbusjahrestag 1992 und der Expo 92 das größte Aquarium Europas errichtet. Der Komplex des Aquariums ("Acquario di Genova") befindet sich auf dem Areal des 1992 komplett umstrukturierten Touristenhafens ("Porto Antico"), der Anlegeplätze für hunderte Boote und Yachten bietet.

In den 1980er und 1990er Jahren wurden viele, bisher vernachlässigte Bauwerke, hauptsächlich Kirchen und Palazzi restauriert und rekonstruiert. Darunter beispielsweise auch die Renaissance-Basilika "Santa Maria Assunta", die auf Grund ihrer Lage auf dem Stadthügel von Carignano, nahezu von jedem Punkt der Stadt sichtbar ist.

Die vollständige Restauration des prächtigen "Palazzo Ducale", einst Machtzentrum der Dogen und Senatoren und heute Austragungsort zahlreicher Kulturveranstaltungen und des Opernhauses "Carlo Felice", das im Zweiten Weltkrieg bis auf die neoklassizistische Vorhalle zerstört worden war, brachten der Stadt eine kulturelle Aufwertung. Beide Gebäude sind an der "Piazza De Ferrari" gelegen, die den Mittelpunkt der Stadt darstellt.

Ein weiteres bedeutendes Monument Genuas ist der Friedhof von Staglieno. Hier ruhen die sterblichen Überreste einiger bekannter Persönlichkeiten, unter ihnen Giuseppe Mazzini, Fabrizio De André und die Frau Oscar Wildes.

Wehrhafte Befestigungsanlagen zeugen von der wechselvollen Geschichte der früheren Seerepublik. Einst war Genua von einer kilometerlangen, durchgehenden Mauer auf den Bergrücken oberhalb der Stadt umgeben. Ganze Abschnitte sowie ein Großteil der Forts sind noch heute zu besichtigen.

Genuas Altstadt ist eine der größten Europas. In den Jahren nach dem Zweiten Weltkrieg wurde sie zunehmend dem Verfall preisgegeben. Aufgrund gravierenderer wirtschaftlicher Probleme wie des Niedergangs des Hafens und der Werften, der Arbeitslosigkeit und der Abwanderung fehlte einerseits das Geld zur Erhaltung. Andererseits wollten auch immer weniger Genuesen in dem historischen Viertel wohnen.

Erst im Vorfeld des Kulturstadtjahres 2004 tat sich einiges. Der alte Hafen westlich der Altstadt wurde in den 1990er Jahren von Renzo Piano, dem Stararchitekten der Stadt, grundlegend umgestaltet. So wurde ein Übergang von der Altstadt zum alten Hafen geschaffen. Die Hauptachse der Altstadt, die "Via di San Lorenzo", wurde verbreitert. Unzählige Palazzi wurden restauriert. In der Nähe der Porta Soprana, des ehemaligen Stadttores und damit der Grenzmarkierung der Altstadt, liegt das mutmaßliche Geburtshaus des Christoph Kolumbus.

Einen kontrastreichen Gegensatz zur mittelalterlichen Altstadt bilden die Patrizierhäuser und prunkvollen Paläste in den beiden "Strade Nuove" aus dem 16. Jahrhundert. In der "Via Garibaldi" und der "Via Balbi" mit ihren Palästen, Innenhöfen und Gärten wird der ganze Reichtum vergangener Zeiten als See- und Finanzmacht Europas deutlich. Allen voran ist der "Palazzo Ducale" aus dem 13. Jahrhundert zu erwähnen, der sich am östlichen Ende der "Via di San Lorenzo" befindet. In der "Via Garibaldi" befinden sich auch die wichtigsten Kunstmuseen der Stadt, der "Palazzo Rosso" und der "Palazzo Bianco", in der "Via Balbi" das Hauptgebäude der Universität von Genua.

Rund um den Hafen von Genua wird bis zum heutigen Tag die Tradition des Trallalero, eines mehrstimmigen Gesangs ohne Instrumente, gepflegt.

Neben der "Fontana di Piazza de Ferrari" ist der Leuchtturm, oder "La Lanterna", das Wahrzeichen der Stadt Genua. Er befindet sich auf einem Hügelvorsprung in der Nähe vom Stadtteil Sampierdarena im westlichen Bezirk der Stadt. Das Bauwerk erreicht eine Höhe von 77 m (117 m insgesamt mit Fundament) und besteht aus zwei übereinandergesetzten Türmen mit quadratischen Grundrissen.

Der 1128 erbaute Leuchtturm wurde 1514 bei der Belagerung des französischen Forts "Briglia", das um den Turm herum errichtet worden war, durch Kanonenbeschuss schwer beschädigt und erst 1543 wiederaufgebaut. Heute ist der Leuchtturm über einen Spazierweg, der beim Fährenterminal, westlich des "Porto Antico" beginnt, zu erreichen. Sein Leuchtfeuer ist, bei guten Sichtverhältnissen, noch aus einer Entfernung von bis zu 36 Seemeilen (ca. 55 km) auszumachen.

In Genua befindet sich die "Università degli Studi di Genova" mit weiteren Lehranstalten in Imperia, Savona, Chiavari und La Spezia. Sie umfasst nahezu alle Fakultäten, mit Schwerpunkt auf Schiffbau.

Wichtige Akademien in Genua sind das "Conservatorio „Niccolò Paganini“", die "Accademia Ligustica di Belle Arti" und die "Akademie der Italienischen Handelsschifffahrt".

In den letzten Jahrzehnten hat die Wirtschaft Genuas eine Schwerpunktverschiebung von der Schwerindustrie (vorwiegend an den Hafen angebunden) hin zum Dienstleistungssektor (hauptsächlich Tourismus, Handel, etc.) erfahren. In diesem Zusammenhang wurden viele heruntergekommene Stadtteile ("Val Bisagno", "Valpolcevera" und "Centro storico") saniert. In Genua findet auch die größte Messe Europas im Bereich Yachten und Segelschiffe statt, der "Salone nautico". Nach wie vor ist der Hafen Genuas der wichtigste Italiens und von seiner Umschlagskapazität der zweitwichtigste des Mittelmeers nach Marseille. Behindert in seiner Expansion wird er allein durch seine mangelhafte Anbindung an weiterführende Transportstrukturen (Schienennetz), was allerdings durch die geplante Schienenverbindung Genua-Rotterdam verbessert werden soll.

Ein weiterer neuer Wirtschaftsbereich hat in Genua mit der Einrichtung des "Italienischen Instituts für Technologie" (IIT), mit Schwerpunkt in Nanobiotechnologie, Robotik und Neurowissenschaft, einen Aufschwung erfahren. Neben schon vorhandenen Forschungseinrichtungen (pädiatrisches Krankenhaus Giannina Gaslini) ist die Schaffung eines High-Tech-Stadtteils vorgesehen.

Der Hafen von Genua ist hinsichtlich seines Containerumschlags einer der größten am Mittelmeer. Seine Bedeutung erhält er vor allem durch sein großes Hinterland, das die Industriegebiete von Mailand und Turin umfasst und bis in die Schweiz reicht, für das Genua den nächstgelegenen Seehafen darstellt. Der Ölhafen ist Ausgangspunkt der Anfang des Jahres 1997 stillgelegten Central European Line, die über die Alpen bis nach Ingolstadt (Bayern) führt. Im Hafen befindet sich der alte Schwimmkran „Langer Heinrich“ der ehemaligen Kriegsmarinewerft Wilhelmshaven.

Die ausschließlich dem Meer zugewandte Stadt erstreckt sich über einen relativ steil abfallenden Küstenstreifen und ist vom Hinterland des Apennin-Gebirges – abgesehen von zwei tief eingeschnittenen, nach Norden verlaufenden Tälern – vollkommen abgetrennt. Bedingt durch diese Topographie ist das Straßennetz der Stadt durch verschiedene fast horizontal den Höhenlinien folgende Hauptstraßenachsen gegliedert. Darüber hinaus werden die Hanglehnen in den tieferen Teilen der Stadt durch innerstädtische Tunnel durchschnitten. Ca. 5 km hinter der Küstenlinie verläuft in etwa 200 m Seehöhe die Autobahn A12, die das hier durch tief eingeschnittene Täler gegliederte Gelände (z. B. bei Staglieno) mit Tunneln durchschneidet und im Val Polcevera auf die Autobahn A7 nach Mailand trifft. Von Sampierdarena schließlich führt eine weitere Autobahn, die A10, in westlicher Richtung über Savona, Imperia, San Remo und Monaco bis ins französische Nizza. Entlang des Hafens zieht sich die Stadtautobahn, die sogenannte "Sopraelevata Aldo Moro", auf einem durchgehenden Viadukt, was dem Stadtbild zwar eher abträglich ist, die Altstadt und das Gelände des Porto Antico jedoch von einem Großteil des Ost-West-Verkehrs spürbar entlastet.

Im Stadtgebiet von Genua befinden sich zwei größere Bahnhöfe, die beide von der Hauptstrecke Ventimiglia-La Spezia passiert werden. Letztere unterteilt sich in die Bahnstrecke Pisa–La Spezia–Genua in südliche Richtung und in die Bahnstrecke Ventimiglia–Genua in Richtung Westen. Im Besonderen ist der Bahnhof Genova Piazza Principe durch seine räumliche Konzeption beeindruckend, da er zwischen zwei Tunnelausgängen eingeschachtet ist und über einen beeindruckenden gründerzeitlichen Aufgang in die Stadt verfügt. Von hier aus verkehren alle überregionalen Züge, besonders in nördlicher Richtung (Mailand, Turin). Vom zweiten großen Bahnhof, der "Genova Brignole", verkehren vor allem die vielen regionalen Züge entlang der ligurischen Küste und ins Hinterland. Isoliert im östlichen Teil der Altstadt befindet sich in unmittelbarer Nähe des eklektizistischen "Castello Mackenzie" auf ca. 80 Meter Seehöhe der Kopfbahnhof der meterspurigen Lokalbahn nach Casella ("siehe": Bahnstrecke Genua-Casella). Das kleine Örtchen liegt ca. 20 Kilometer nördlich von Genua und ist vor allem für Wochenendausflügler ein beliebter Ausgangspunkt für Wanderungen ins nahezu menschenleere Hinterland der Hafenstadt.

An den europäischen Flugverkehr angeschlossen ist Genua seit dem 17. Juli 1985 durch den Flughafen "Cristoforo Colombo", der wegen Platzmangels auf einer künstlich aufgeschütteten Halbinsel im Mittelmeer errichtet wurde. Der Flughafen liegt im Stadtteil Sestri Ponente, 6 km entfernt vom Zentrum Genuas. Er verfügt über eine 2915 m lange Asphaltpiste.

Bedeutung erlangt der Flughafen durch seine Verbindung zum Hafen von Genua. Das Passagieraufkommen im Jahr 2010 belief sich auf 1.272.048 Personen.

Der innerstädtische Personennahverkehr wird durch das städtische Verkehrsunternehmen AMT betrieben. Neben einem ausgedehnten Busnetz, einer O-Buslinie und einer U-Bahn befinden sich im Stadtgebiet mehrere Bergbahnen. Die größte davon ist die Standseilbahn auf den Righi, die nun schon seit mehr als 100 Jahren teilweise unterirdisch verlaufend die oberen Stadtviertel erschließt. Daneben existiert noch eine kleinere Standseilbahn sowie eine Zahnradbahn in den Villenort Granarolo. Die U-Bahn verfügt lediglich über eine einzige Linie mit sieben Stationen. Sie verläuft großteils unter dem engen, verwinkelten Altstadtzentrum. Bis zum Jahr 1966 verfügte Genua über ein eigenes Straßenbahn-Netz. Der Straßenbahntunnel nach Brin wird heute wieder genutzt.

Eine Besonderheit stellen die zahlreichen Lifte ("Ascensori") dar, die teilweise in Privathäusern enden bzw. unterwegs mit Schlüsselschalter private Gebäude erschließen, dabei aber vom Verkehrsunternehmen der Stadt betrieben werden. Nahe dem Bahnhof Piazza Principe befindet sich einer der größten, der durch einen etwa 200 Meter langen Fußgängertunnel ins Bergesinnere erreicht werden kann und den man einige Stockwerke höher in einer der höhenlinienparallelen Straßen verlässt. Das schönste Panorama über die Altstadt und den Hafen bietet die Aussichtspromenade Belvedere Luigi Montaldo/Castelletto. Von der Piazza Portello fährt der architektonisch überaus gelungene Aufzug "Ascensore della Spianata Castelletto" nach oben. Wie alle Aufzüge und Lifte von Genua benutzt man ihn mit einfachen Busfahrscheinen vom Kiosk. Daneben gibt es auch noch Kuriositäten, wie z. B. einen Fußgängertunnel, der einen Straßentunnel mit Ampelschaltung kreuzt.

Seit 1810 besteht die Libreria Bozzi als älteste Buchhandlung Italiens. Genua ist Sitz der lokal erscheinenden Tageszeitung Il Secolo XIX.

Genua beheimatet zwei Fußballvereine, die in der Saison 2016/17 beide in der ersten Liga (Serie A) spielen. Die Heimspiele werden von beiden Vereinen im Stadio Luigi Ferraris ausgetragen, das auch als "Marassi" bekannt ist - so heißt auch das Viertel, in dem das Stadion steht. Das „Derby della lanterna“ gehört zu den vier wichtigsten Fußballderbys in Italien und ist vor allem für die farbenfrohen Choreografien der Fans bekannt.

Der Genoa Cricket and Football Club (auch einfach "Genoa" oder "Genoa CFC") wurde 1893 von Engländern als Cricket- und Leichtathletikverein gegründet und bekam unter James Richardson Spensley 1897 eine eigene Fußballsparte. Damit ist Genoa der älteste, noch aktive Fußballklub Italiens. Mit seinen neun Meisterschaftstiteln zählt der Verein zu den erfolgreichsten Mannschaften im italienischen Fußball. 2005 wurde der Verein in die dritte Liga ("Serie C1") abgestuft, nachdem sich herausgestellt hatte, dass mindestens ein Spiel manipuliert worden war. In der Folge kam es zu Ausschreitungen, bei denen zwölf Polizisten bei Auseinandersetzungen mit circa 3000 aufgebrachten Fans verletzt wurden. Seit Juni 2007 spielt Genoa wieder in der Serie A.

Die U.C. Sampdoria ist der zweite wichtige Fußballverein Genuas. Er entstand 1946 durch eine Fusion von SG Sampierdarenese und SG Andrea Doria, aus deren Namen sich auch der Vereinsname "„Sampdoria“" ableitet, und spielte zeit seines Bestehens hauptsächlich in der Serie A. Der größte Erfolg des Vereins war der Gewinn des Europapokals der Pokalsieger 1989/90. 2010 spielte Sampdoria noch die Champions-League-Qualifikation und verlor gegen Werder Bremen. 2011 stieg Sampdoria Genua als 18. von 20 Mannschaften in die zweithöchste Spielklasse Serie B ab, im Jahr darauf glückte aber der sofortige Wiederaufstieg.

Bekannte Persönlichkeiten der Stadt sind in der "Liste von Persönlichkeiten der Stadt Genua" aufgeführt.

Genua listet zu folgenden acht Städten eine Gemeindepartnerschaft auf: 
Die Stadt Genua hat mit ihrem Namen zum Teil auf Umwegen Pate gestanden, unter anderem für die Bezeichnung Jeans. Deren Ursprung waren Stoffe aus Baumwolle, die aus der Gegend um Genua in die USA kamen. Aus der französischen Form des Städtenamens „Gênes“ machte die amerikanische Umgangssprache den Begriff „Jeans“. Auch die Anhänger des argentinischen Fußballclubs CA Boca Juniors, genannt "Xeneizes", verdanken ihren Namen Genua, da der Club von ausgewanderten Genuesen gegründet wurde.





</doc>
<doc id="2013" url="https://de.wikipedia.org/wiki?curid=2013" title="Gesellschaft">
Gesellschaft

Gesellschaft steht für:

Siehe auch:


</doc>
<doc id="2014" url="https://de.wikipedia.org/wiki?curid=2014" title="Galvanische Zelle">
Galvanische Zelle

Eine galvanische Zelle [], galvanisches Element oder galvanische Kette ist eine Vorrichtung zur spontanen Umwandlung von chemischer in elektrische Energie. Jede Kombination von zwei verschiedenen Elektroden und einem Elektrolyten bezeichnet man als galvanisches Element, und sie dienen als Gleichspannungsquellen. Der charakteristische Wert ist die eingeprägte Spannung. Unter der Kapazität eines galvanischen Elements versteht man das Produkt aus Entladungsstromstärke mal Zeit.

Der Name geht auf den italienischen Arzt Luigi Galvani zurück. Er entdeckte, dass ein mit Instrumenten aus verschiedenartigen Metallen berührter Froschschenkel-Nerv Muskelzuckungen auslöst, da das so gebildete Redox-System als galvanisches Element Spannung aufbaut, so dass Strom fließt.

Galvanische Zellen werden systematisch in drei Gruppen unterteilt:


Die Funktion der galvanischen Zellen beruht auf einer Redoxreaktion. Reduktion und Oxidation laufen räumlich getrennt in je einer Halbzelle (Halbelement) ab. Durch Verbinden der beiden Halbzellen mit einem Elektronenleiter und einem Ionenleiter wird der Stromkreis geschlossen. Die Spannung des elektrischen Stroms lässt sich durch die Nernst-Gleichung berechnen. Sie hängt von der Art des Metalls (elektrochemische Spannungsreihe), der Konzentration in der Lösung der jeweiligen Halbzelle sowie der Temperatur ab. Im Gegensatz zur Elektrolyse, beispielsweise in der Galvanotechnik, kann in der galvanischen Zelle elektrische Energie gewonnen werden, während die Elektrolyse elektrische Energie benötigt.

Beim Entladen von galvanischen Zellen ist der Minuspol immer die Anode (= Pol, an dem die Oxidation stattfindet), der Pluspol immer die Kathode (= Pol, an dem die Reduktion stattfindet). Eine Eselsbrücke hierfür lautet galvanische OMA (Oxidation, Minuspol und Anode).
Während des Ladevorgangs von Sekundärzellen sind die chemischen Reaktion an den Polen vertauscht: Die Oxidation findet am Pluspol statt, weswegen er dann abweichend als Anode fungiert - ebenso ist dann der Minuspol der Ort der Reduktion und damit die Kathode. Die Eselsbrücke für die Reaktion beim Ladevorgang lautet dementsprechend: OPA (Oxidation, Pluspol und Anode).

Eine galvanische Zelle liefert so lange eine Spannung, bis das elektrochemische Gleichgewicht erreicht wird.

Immer, wenn sich zwei unterschiedliche Metalle in einer Elektrolytlösung befinden, entsteht eine Spannung (galvanische Zelle). Dies ist auf die jeweilige Tendenz der Metalle, in Lösung zu gehen und dabei Ionen zu bilden, die so genannte Lösungstension, zurückzuführen.
Neben dem Daniell-Element (Kupfer/Zink) kann so beispielsweise auch aus Kupfer- und Silberelektroden ein galvanisches Element erzeugt werden: Die
Kupferelektrode taucht in eine Kupfersulfat-Lösung, die Silberelektrode in Silbernitratlösung, und verbunden werden diese durch einen Draht (Elektronenleiter) mit Voltmeter und einen Ionenleiter.

Wenn jedoch beide Elektroden über einen elektrischen Leiter miteinander verbunden werden, sorgt die unterschiedliche Lösungstension der Elektroden dafür, dass die Reaktion weiterlaufen kann. Da das Redoxpotential von Kupfer (Reduktionsmittel) niedriger ist als das von Silber (Oxidationsmittel), gehen an der Kupferelektrode mehr Ionen in Lösung als an der Silberelektrode. Daher ist die negative Ladung in der Kupferelektrode höher als die in der Silberelektrode, es entsteht also eine Spannung, bei der die Elektronen zur Silberelektrode hin „gedrückt“ werden. Das führt dazu, dass die Lösung der Silberatome gestoppt wird, stattdessen reagieren die überschüssigen Elektronen mit den Ag-Ionen der Silbernitratlösung und sorgen dafür, dass sich diese als normale Silberatome an der Silberelektrode festsetzen.

An der Silberelektrode werden also Silberionen zu elementarem Silber reduziert:

Die Silberelektrode ist damit die Kathode (Elektrode, an der die Reduktion stattfindet) und der Pluspol der galvanischen Zelle (da hier ein Elektronenmangel entsteht).

An der Kupferelektrode findet hingegen folgende Oxidation statt:

Die Kupferelektrode ist die Anode (Elektrode, an der die Oxidation stattfindet) und der Minuspol der galvanischen Zelle (da hier ein Elektronenüberschuss entsteht).

In der galvanischen Zelle läuft also eine Redoxreaktion ab, deren Reaktionsteile jedoch räumlich voneinander getrennt sind.

Werden die zwei Elektroden nun also elektrisch leitend verbunden, so entsteht zwar eine Spannung, aber es fließt noch kein Strom. Der Grund dafür ist, dass in der Kupfersulfatlösung ein Überschuss an Cu-Ionen entsteht und die Lösung sich stark positiv auflädt, was verhindert, dass sich weitere Kupferatome lösen können.

Ähnliches passiert mit der Silbernitratlösung, welche sich negativ auflädt, da vom neutralen Silbernitrat nur die negativ geladenen Nitrat-Ionen übrig bleiben (während sich die positiven Silberionen an die Silberelektrode anlagern, indem sie dort jeweils ein Elektron aufnehmen).

Silbernitratlösung: c[NO ] » c[Ag ]

Kupfersulfatlösung: c[SO ] « c[Cu ]

Deswegen sind die Elektrodenräume über eine Ionenbrücke (Salzbrücke) miteinander verbunden, welche notwendig ist, um den Stromkreis zu schließen. Die Ionenbrücke ist häufig ein U-Rohr, das mit einem Elektrolyten gefüllt ist und dessen Enden mit einer Membran oder einem Diaphragma versehen sind. Über die Salzbrücke erfolgt der Ionenaustausch, um so der Aufladung der einzelnen Zellen entgegenzuwirken. Eine andere Möglichkeit, die Elektrodenräume voneinander zu trennen, besteht in einer selektivpermeablen (ausgewählt durchlässigen) Membran, welche ebenfalls einen Ladungsausgleich ermöglicht. Über die Ionenbrücke wandern also die Salzionen (in diesem Fall Nitrationen) von der Kathode zur Anode, also von der Silberhalbzelle zur Kupferhalbzelle.

Es gibt auch galvanische Zellen mit zwei gleichen Halbzellen, die sich in ihrer Konzentration unterscheiden, diese nennt man Konzentrationselement.

Der Deflagrator ist ebenfalls eine Galvanische Zelle.

Eine galvanische Zelle wird auch manchmal in verkürzter Schreibweise beschrieben. Das oben grafisch dargestellte Daniell-Element sähe in dieser Schreibweise folgendermaßen aus:

Beide Halbzellen werden in einer galvanischen Zelle durch ein Diaphragma, also eine dünne, halbdurchlässige Membran (semipermeable Membran) getrennt. Durch diese Membran werden fast ausschließlich die negativ geladenen Anionen hindurchgelassen. Im Falle des Daniell-Elements sind das SO-Ionen (Sulfationen), welche in den Salzlösungen beider Halbzellen vorhanden sind.

Dieses Diaphragma wird in der verkürzten Schreibweise durch den doppelten senkrechten Strich (||) dargestellt. Rechts und links von diesem doppelten Strich werden die beiden Halbzellen der galvanischen Zelle und die darin stattfindenden Reaktionen verkürzt dargestellt. Zudem wird die Konzentration der Metallsalzlösung, also die Konzentration der gelösten Metalle in beiden Halbzellen angegeben. Die Anodenhalbzelle steht üblicherweise links.



</doc>
<doc id="2016" url="https://de.wikipedia.org/wiki?curid=2016" title="GmbH &amp; Co. KG">
GmbH &amp; Co. KG

Die Gesellschaft mit beschränkter Haftung & Compagnie Kommanditgesellschaft (GmbH & Co. KG) ist im deutschen und österreichischen Recht eine Sonderform der Kommanditgesellschaft (KG) und somit eine Personengesellschaft. In der Schweiz ist diese Rechtsform bisher nicht möglich.

Anders als bei einer typischen Kommanditgesellschaft ist der persönlich und unbegrenzt haftende Gesellschafter (Komplementär) keine natürliche Person, sondern eine Gesellschaft mit beschränkter Haftung (GmbH). Ziel dieser gesellschaftsrechtlichen Konstruktion ist es, Haftungsrisiken für die hinter der Gesellschaft stehenden Personen auszuschließen oder zu begrenzen.

Die Firma ist der Name, unter dem die GmbH & Co. KG ihre Geschäfte betreibt. Sie muss „zur Kennzeichnung des Kaufmanns geeignet sein und Unterscheidungskraft besitzen“ ( Abs. 1 HGB). Sie muss gem. Abs. 1 Nr. 3 HGB (neue Fassung) die Bezeichnung „Kommanditgesellschaft“ bzw. eine „allgemein verständliche Abkürzung“ dieses Begriffs (KG) im Namen tragen. Abs. 2 schreibt ferner eine Bezeichnung vor, die die Haftungsbeschränkung kennzeichnet.

Hieraus ergibt sich folgende korrekte Firmierung: "Name" GmbH & Co. KG.

Früher teilweise verwendete Formen wie "Name" GmbH & Comp. oder "Name" GmbH & Cie. sind nicht mehr zulässig. Nicht korrekte Firmierungen, da irreführend, sind: "Name" KG-GmbH & Cie. oder "Name" & Co. GmbH & Co. KG. Für nach alter Fassung des HGB angemeldete Gesellschaften gilt die frühere, dazu ergangene Rechtsprechung weiterhin, z. B. "Name" & Co. oder "Name" & Cie., auch "Name" & Comp.

Eine Kommanditgesellschaft darf nach Abs. 1 HGB zum Zwecke eines Handelsgewerbes oder nach § 161 Abs. 2 i. V. m. Abs. 2 HGB zur Verwaltung eigenen Vermögens errichtet werden. Angehörige der freien Berufe können grundsätzlich nicht in der Rechtsform einer KG beruflich tätig sein; Besonderheiten gelten hierbei aufgrund ihrer Berufsgesetze für Steuerberater und Wirtschaftsprüfer für Treuhandtätigkeiten ( StBerG; Abs. 2 WPO).

Die Beziehungen und Rechte der Gesellschafter untereinander regelt der Gesellschaftsvertrag. Die diesbezüglichen Vorgaben für die KG aus dem Handelsgesetzbuch ( HGB) sind weitestgehend dispositiv, d. h., sie können durch vertragliche Vereinbarungen abgeändert werden. So sieht z. B. Abs. 1 i. V. m. Abs. 2 HGB vor, dass Beschlüsse der Gesellschafter einstimmig zu fassen sind. Diese Regelung kann im Gesellschaftsvertrag durch eine Vereinbarung ersetzt werden, die Mehrheitsbeschlüsse ermöglicht. Auch die Berechnung dieser Mehrheit sollte hier definiert werden, andernfalls gilt nach § 119 Abs. 2 HGB die Kopfzahl der Gesellschafter.

Die Komplementär-GmbH kann sich mit ihrem gesamten Vermögen oder mit einem Teil ihres Vermögens an der KG beteiligen. Bei Leistung einer Sacheinlage ist zur Errichtung der KG – im Gegensatz zur GmbH – kein Sachgründungsbericht erforderlich. Im Falle einer Umwandlung von einer bestehenden GmbH zu einer GmbH & Co. KG empfiehlt es sich u. U., nur das Umlaufvermögen der GmbH in die KG einzubringen und das Anlagevermögen bei der GmbH zu belassen. Alternativ kann von der Einlage der GmbH auch abgesehen werden. Die „Leistung“ der GmbH für die KG beschränkt sich in diesem Fall auf die Übernahme der Geschäftsführung und auf die persönliche Haftung.

Auf Seite der Kommanditisten bezeichnet die "Pflichteinlage" den Betrag, den ein Kommanditist in die Gesellschaft einzuzahlen hat. Unabhängig hiervon besagt die im Handelsregister eingetragene "Haftsumme" (veraltet: "Hafteinlage"), mit welchem Betrag der jeweilige Kommanditist persönlich haftet. Wird im Gesellschaftsvertrag keine Pflichteinlage vereinbart, dann kann unterstellt werden, dass diese mit der Haftsumme identisch ist. Mit Leistung der Pflichteinlage erlischt die persönliche Haftung des Kommanditisten in Höhe des eingezahlten Betrages (Regelung in Deutschland s. Abs. 1 HGB, in Österreich s. § 171 Abs. 1 Unternehmensgesetzbuch).

Die GmbH & Co. KG wird durch die GmbH (Komplementärin) vertreten, die typischerweise auch die alleinige Geschäftsführungsbefugnis besitzt ( HGB). Der Kommanditist ist im Regelfall von der Geschäftsführung ausgeschlossen; er kann lediglich bei außergewöhnlichen Geschäften sein Widerspruchsrecht ausüben (§ 164 Satz 1 HGB). Somit ist, sofern nichts anderes im Gesellschaftsvertrag vereinbart ist, der Geschäftsführer der GmbH mittelbar auch Geschäftsführer der KG. Im Übrigen sind die Rechtsgrundlagen dieselben wie bei der KG.

Haftungsbeschränkung

Die GmbH als Komplementärin haftet selbst unbeschränkt mit ihrem gesamten Vermögen; die Gesellschafter der GmbH haften in Höhe ihrer Stammeinlagen.

Nachfolgeregelung

Da nach dem Tod einer natürlichen Person als Komplementär die Erben an dessen Stelle treten, entsteht für die Erben ein Haftungsrisiko. Diese Folge tritt nicht ein, wenn mindestens eine Kapitalgesellschaft Komplementärin ist.

Geschäftsführung

Als Geschäftsführer der Komplementär-GmbH können Nichtgesellschafter beschäftigt werden (Fremdorganschaft).

Kapitalbeschaffung

Die GmbH & Co. KG ist weniger kreditwürdig, da keine natürliche Person unbeschränkt haftet.

Kosten

Die Verwaltungskosten sind höher, da sowohl für die GmbH & Co. KG als auch die Komplementär-GmbH Buchführungspflicht besteht, Jahresabschlüsse erstellt und veröffentlicht werden müssen und Steuererklärungen abgegeben werden müssen.

Veröffentlichungen

Die GmbH & Co. KG unterliegt gemäß HGB der Publizitätspflicht und muss ihre Jahresabschlüsse wie eine Kapitalgesellschaft offenlegen. Sie ist damit transparenter als eine KG.

Ausgangspunkt für die Einordnung des Vermögens der Gesellschaft sind die Regelungen des BGB über die Gesellschaft bürgerlichen Rechts. Danach unterliegt das Vermögen dinglich einer gesamthänderischen Bindung. Keinem Gesellschafter steht ein Vermögensgegenstand der Gesellschaft oder ein Bruchteil des Vermögens der Gesellschaft zu. Allen Gesellschaftern steht das Vermögen der Gesellschaft gleichzeitig zur gesamten Hand zu. Eine typische Ausgestaltung der Gesellschaft besteht darin, dass der GmbH als Komplementär keine Vermögensbeteiligung eingeräumt wird. Das gesamte Vermögen steht regelmäßig den Kommanditisten zu. Trotzdem ist auch die GmbH dinglich gesamthänderisch am gesamten Vermögen der Gesellschaft beteiligt. Die vereinbarte Beteiligung am Vermögen kommt im Fall des Ausscheidens des Gesellschafters oder der Liquidation der Gesellschaft zum Tragen. Wird auf die erwähnte typische Ausgestaltung zurückgegriffen, erhält die GmbH im Fall des Ausscheidens oder Liquidation keinen Anteil ausbezahlt.

Wie jede andere KG ist die GmbH & Co. KG "Kaufmann" im Sinne des Handelsgesetzbuches (HGB) und hat deshalb Bücher zu führen und Jahresabschlüsse anzufertigen ( HGB). Da in der typischen GmbH & Co. KG jedoch keine natürliche Person Komplementär (Vollhafter) ist, unterliegt sie nach HGB wie Kapitalgesellschaften höheren Anforderungen an die Aufstellung des Jahresabschlusses und hat diesen auch im elektronischen Bundesanzeiger zu veröffentlichen.

Zuerst werden die Komplementärgehälter ausgezahlt. Von dem Rest des Gewinns bekommt jeder Gesellschafter 4 % auf seine Einlage. Das übrig Gebliebene wird nun anteilsmäßig verteilt. Dies geschieht gem. Abs. 2 HGB in einem angemessenen Verhältnis, sofern nichts anderes beschlossen wurde, z. B. entsprechend der Einlage des jeweiligen Gesellschafters.

Die Gesellschafter der GmbH & Co. KG können ihre Mitgliedschaft gemäß Abs. 2 i. V. m. HGB formlos zum Ende des jeweiligen Geschäftsjahres, unter Wahrung einer Frist von sechs Monaten, kündigen.

Als Personengesellschaft ist die GmbH & Co. KG selbst weder körperschaft- noch einkommensteuerpflichtig. Der Gewinnanteil der Komplementär-GmbH unterliegt der Körperschaftsteuer. Die Gewinnanteile der Kommanditisten unterliegen – soweit sie natürliche Personen sind – der Einkommensteuer.

In Deutschland unterliegt jeder stehende Gewerbebetrieb gemäß Abs. 1 Satz 1 GewStG der Gewerbesteuer. Als gewerblich tätige Personengesellschaft ist die GmbH & Co. KG grundsätzlich gewerbesteuerpflichtig, allerdings erst ab dem Zeitpunkt der Aufnahme ihrer gewerblichen Tätigkeit. Vorbereitungshandlungen zur Gründung einer GmbH & Co. KG bzw. Abwicklungsmaßnahmen zur Auflösung der Firma werden nicht gewerbesteuerlich erfasst. Für die "gewerblich geprägte" GmbH & Co. KG gilt das Gegenteil: hier beginnt die Gewerbesteuerpflicht schon mit der Aufnahme jeglicher, auf den Erwerb von Einkommen abzielender Tätigkeit. Seit 2002 ist die Veräußerung von Anteilen an Personengesellschaften unter bestimmten Voraussetzungen steuerpflichtig ( Satz 2 GewStG). Dies gilt, soweit an der veräußerten Personengesellschaft nicht eine natürliche Person unmittelbar beteiligt ist. Steuerpflichtig ist die Personengesellschaft selbst, nicht deren Gesellschafter. Bei doppelstöckiger Personengesellschaft gilt: die Obergesellschaft ist Gesellschafterin (Mitunternehmerin) der Untergesellschaft. Da sie keine natürliche Person ist, ist der Gewinn aus der Veräußerung der Tochter in voller Höhe steuerpflichtig. Soweit an der Obergesellschaft eine natürliche Person beteiligt ist, wird die Gewerbesteuer aus der Veräußerung nach EStG angerechnet. Durch die zivilrechtliche Abtretung eines Mitunternehmeranteils wird die Steuerpflicht der bisherigen Personengesellschaft nur beendet, wenn sämtliche Gesellschafter dadurch ausscheiden. Bei einem lediglich partiellen Gesellschafterwechsel besteht die Steuerpflicht der Personengesellschaft fort.

Wie jede andere Personengesellschaft, handelt auch die GmbH & Co. KG als "selbstständiger Rechtsträger": Immer dann, wenn die KG ein Grundstück erwirbt oder veräußert, fällt Grunderwerbsteuer an, auch wenn das Grundstücksgeschäft mit einem oder mehreren Gesellschaftern abgeschlossen wird. Steuerschuldner ist die KG, jedoch haften die Gesellschafter gesamtschuldnerisch ( Abs. 4 AO).

Die "steuerliche Transparenz" der Personengesellschaft macht sich auch im Grunderwerbsteuerrecht bemerkbar: Bei Grundbesitzübereignungen zwischen Gesellschaftern und Gesellschaft (und umgekehrt) gewähren die , und GrEstG personenbezogene Vergünstigungen. § 5 und § 6 GrEStG befreien die Übertragung so weit, wie ein Grundeigentümer mit dem gleichen ideellen Anteil am Grundstück beteiligt bleibt. Eine fünfjährige Sperrfrist soll Missbräuche verhindern: Innerhalb dieser Zeitspanne nach einem steuerlich befreiten Grundstücksgeschäft können sich Änderungen der Gesellschaftsstruktur steuerlich nachteilig auswirken.

Die Einbringung eines Grundstücks in eine Familien-KG ist in der Regel in voller Höhe grunderwerbsteuerfrei. Der Wechsel von Gesellschaftern einer KG mit Grundbesitz kann dagegen unter bestimmten Umständen grunderwerbsteuerpflichtig sein.

Eine rein vermögensverwaltende, nicht gewerblich tätige und nicht gewerblich geprägte GmbH & Co. KG wird erbschaftsteuerrechtlich (siehe Erbschaftsteuer- und Schenkungsteuergesetz) wie Privatvermögen behandelt; im Falle einer gewerblich tätigen bzw. gewerblich geprägten GmbH & Co. KG handelt es sich um Betriebsvermögen, das gegenüber Privatvermögen steuerlich begünstigt wird. Bei der Übertragung einer vermögensverwaltenden GmbH & Co. KG wird nicht die Beteiligung an einer gewerblichen Personengesellschaft im Sinne einer Mitgliedschaft vererbt oder verschenkt, sondern lediglich der Anteil an Wirtschaftsgütern. Anteilige Schulden werden nicht saldiert, sondern im Sinne einer „gemischten Schenkung“ behandelt. Bei der Übertragung einer gewerblich tätigen oder gewerblich geprägten GmbH & Co. KG sind die Bilanzwerte steuerlich relevant. Hierbei müssen stille Reserven nicht versteuert werden. Ausgenommen sind Grundstücke (Ansatz des Bedarfswerts) und Beteiligungen (Ansatz nach Kurswert) an Kapitalgesellschaften, deren Wertansatz unabhängig von der Prägung bzw. Tätigkeit der GmbH & Co. KG erfolgt.



Bei der typischen (auch personengleichen) GmbH & Co. KG sind die Gesellschafter der Komplementär-GmbH zugleich die Kommanditisten der GmbH & Co. KG.

Bei der Einheits-GmbH & Co. KG hält die KG alle Anteile der Komplementär-GmbH. Dadurch wird die Unternehmensführung in "einer" Gesellschaft, der KG, vereint. Hierbei muss der Gefahr der "verdeckten Einlagenrückzahlung" durch entsprechende Vereinbarungen im Gesellschaftsvertrag entgegengewirkt werden, um den berechtigten Anspruch der Gläubiger auf Erhalt des haftenden Kapitals zu erfüllen.

In der Einmann-GmbH & Co. KG hält "ein" Eigentümer alle Kommandit- und GmbH-Anteile.

In einer beteiligungsidentischen GmbH & Co. KG sind alle Eigentümer gleichmäßig im gleichen Verhältnis untereinander als Kommanditisten an der KG und als Gesellschafter an der Komplementär-GmbH beteiligt. Um die Beteiligungsidentität auch im Falle des Ausscheidens eines Gesellschafters zu wahren, empfiehlt sich die Aufnahme eines Passus im Gesellschaftsvertrag, mit der die Kündigung der Mitgliedschaft der Komplementär-GmbH gleichzeitig die Kündigung der KG fingiert.

Die Publikumsgesellschaft (auch „Massen-“ oder „Kapitalanlagegesellschaft“) ist auf die Aufnahme eines nahezu unbegrenzten Personenkreises als Kommanditisten ausgelegt. Die Kommanditisten stehen zueinander in keiner persönlichen Beziehung und wirken an der Formulierung des Gesellschaftsvertrags nicht mit, sondern treten der bestehenden Gesellschaft lediglich bei. 

Klassischer Anwendungsbereich der Publikums-KG sind die sog. geschlossenen Fonds. Diese unterscheiden sich von den sog. offenen Fonds (z. B. klassische Aktien- und Rentenfonds) durch ihre gesellschaftsrechtliche Konstruktion und vor allem dadurch, dass man die Anteile nicht offiziell an zugelassenen Börsen handeln kann, sondern ein Ausstieg (= Kündigungsmöglichkeit) der Kommanditisten prinzipiell während der geplanten Laufzeit der Gesellschaft ausgeschlossen ist. 

Bei der Publikums-KG ist eine juristische Besonderheit zu beachten: Wegen ihrer wirtschaftlichen Ähnlichkeit zur Aktiengesellschaft sind statt der §§ 161 ff HGB (wie sie eigentlich auf eine Kommanditgesellschaft anzuwenden wären) weitestgehend die Vorschriften des Aktiengesetzes anzuwenden. 

An der doppelstöckigen (bzw. „mehrstufigen“) GmbH & Co. KG ist als einziger Komplementär und/oder Kommanditist eine weitere GmbH & Co. KG beteiligt. Für ein derartiges Konstrukt sprechen ggf. mitbestimmungsrechtliche oder umwandlungsrechtliche Gründe; dagegen spricht der hohe administrative Aufwand mit mehrfacher Buchführung und Bilanzierung.

Ist eine GmbH gleichzeitig Vollhafter in mehreren Kommanditgesellschaften, so spricht man von einer „sternförmigen Beteiligung“ der Komplementär-GmbH. Konkurrieren die sternförmig gebundenen KGen in der gleichen Branche, sollte in den Gesellschaftsverträgen das Wettbewerbsverbot aus Abs. 1 HGB abbedungen werden.

Komplementär kann auch eine Unternehmergesellschaft (haftungsbeschränkt) sein ("UG (haftungsbeschränkt) & Co. KG"). Ebenso sind ausländische Kapitalgesellschaften als Komplementär möglich, z. B. die Limited & Co. KG.

Da nach schweizerischem Recht nur natürliche Personen Komplementäre einer Kommanditgesellschaft sein können ( Abs. 2 OR), ist eine GmbH & Co. KG nicht möglich. Politische Bemühungen, dies zu ändern, waren bis jetzt nicht erfolgreich.




</doc>
<doc id="2018" url="https://de.wikipedia.org/wiki?curid=2018" title="Gefangener">
Gefangener

Ein Gefangener bzw. eine Gefangene ist eine Person, die in ihren Freiheitsrechten legal beschränkt oder ihrer illegal beraubt ist, sich also unfreiwillig in Gefangenschaft – hoheitlichem Gewahrsam oder in der Gewalt von Kriminellen – befindet.


Man unterscheidet im Rechtswesen als legitime Gefangennahmen

Häftlinge, die aus politischen Gründen inhaftiert sind, bezeichnet man als politische Gefangene. Eine weitere Sonderform ist die Verwahrung psychisch kranker Straftäter in (meist geschlossenen) Heil- und Pflegeanstalten, etwa fürsorgerischer Freiheitsentzug in der Schweiz, Unterbringung in Österreich.

Für den Gefangenen hat der Freiheitsentzug erheblichen Einfluss auf seine bürgerlichen Grundrechte; aus der Gefangennahme erfolgt eine Einschränkung derselben. Tangierte Einschränkungen der Grundrechte sind unter anderem:
Weitere Aspekte sind die Kleiderordnung (Tragen der Privatkleidung oder einheitliche Anstaltskleidung), Freizeitgestaltung und anderes.

Internationale Regelungen, die Rechte, Pflichten und sonstige Lebensumstände von Gefangenen regeln:

Auch ein Arrestant (Jugendstrafe) ist ein Strafgefangener, jedoch nur für kurze Zeit.





</doc>
<doc id="2020" url="https://de.wikipedia.org/wiki?curid=2020" title="Goldene Zahl (Kalender)">
Goldene Zahl (Kalender)

Die Goldene Zahl (lat.: "Numerus aureus") kennzeichnet die Position eines Kalenderjahres der christlichen Ära innerhalb des 19-jährigen Mondzirkels. Dieser Position, von der das Osterdatum abhängt, sind die Goldenen Zahlen 1 bis 19 fortlaufend zugeordnet (vgl. Tabelle).

Die am häufigsten angegebene Formel zur Bestimmung der Goldenen Zahl formula_1 für das Jahr mit der Jahreszahl formula_2 lautet: 

mit
Das Ergebnis  0 ist in 19 umzuwandeln, wonach die Ergebnisreihe lautet:

Das Jahr 2009 hat die Goldene Zahl (2009 + 1) mod 19 = 15.
Im Jahr 2013 ist die Umwandlungsregel (0 → 19) anzuwenden:
Das Jahr 2013 hat die Goldene Zahl (2013 + 1) mod 19 = 0, also 19.

Die folgende Formel führt zum gleichen Ergebnis (außer für das Jahr 1 v. Chr., für das allerdings auch die erste Formel kein korrektes Ergebnis liefert), ohne in Ausnahmejahren die Umwandlungsregel anwenden zu müssen:

Wegen ihrer Bedeutung bei der Berechnung des Osterfestes (Computus (Osterrechnung)) – des im Christentum wichtigsten Festes – wurde diese Hilfsgröße in spätmittelalterlichen Jahreskalendern oft mit goldener Farbe geschrieben, wodurch die Bezeichnung Goldene Zahl entstanden sein soll. Möglich ist auch, dass sie bereits wegen ihrer hervorragenden Bedeutung zu diesem Namen kam.



</doc>
<doc id="2021" url="https://de.wikipedia.org/wiki?curid=2021" title="Größter gemeinsamer Teiler">
Größter gemeinsamer Teiler

Der größte gemeinsame Teiler (ggT) ist ein mathematischer Begriff. Sein Pendant ist das "kleinste gemeinsame Vielfache (kgV)". Beide spielen unter anderem in der Bruchrechnung und der Zahlentheorie eine Rolle.

Er ist die größte natürliche Zahl, durch die sich zwei ganze Zahlen ohne Rest teilen lassen.

Der formula_1 zweier ganzer Zahlen formula_2 und formula_3 ist eine ganze Zahl formula_4 mit der Eigenschaft, dass sie Teiler sowohl von formula_2 als auch von formula_3 ist und dass jede ganze Zahl, die ebenfalls die Zahlen formula_2 und formula_3 teilt, ihrerseits Teiler von formula_4 ist. Beim Ring formula_10 der ganzen Zahlen (der eine Totalordnung > besitzt) normiert man den formula_1 auf die größte ganze solche Zahl formula_12.

Der Begriff „groß“ in formula_1 korreliert hochgradig mit der üblichen Ordnungsrelation > der ganzen Zahlen. Es gibt allerdings eine wichtige Ausnahme: Da die formula_14 Vielfaches einer jeden ganzen Zahl formula_4 ist, ist formula_14 in Teilbarkeitsfragen an „Größe“ nicht zu überbieten. Diese Auffassung ist in Einklang mit der Verbandsvorstellung (und der Idealtheorie) und vereinfacht einige der unten aufgeführten Rechenregeln.

Die englische Bezeichnung gcd ("greatest common divisor") für formula_1 ist in mathematischen Texten ebenfalls verbreitet.

Oft wird auch formula_18 als Kurzschreibweise für formula_19 verwendet.


GgT und kgV kann man über die Primfaktorzerlegung der beiden gegebenen Zahlen bestimmen. Beispiel:


Für den ggT nimmt man die Primfaktoren, die in beiden Zerlegungen vorkommen, und als zugehörigen Exponenten den jeweils kleineren der Ausgangsexponenten:


Die Berechnung der Primfaktorzerlegung großer Zahlen und damit auch die Bestimmung des größten gemeinsamen Teilers nach obiger Methode ist sehr aufwändig. Mit dem euklidischen Algorithmus existiert jedoch ein effizientes Verfahren, um den größten gemeinsamen Teiler zweier Zahlen zu berechnen. Dieses Verfahren wurde durch den steinschen Algorithmus noch weiter variiert. Ob dies eine Verbesserung ist, hängt von der jeweiligen Bewertungsfunktion und „Maschinerie“ ab, die den jeweiligen Algorithmus ausführt.

Beim euklidischen Algorithmus wird in aufeinanderfolgenden Schritten jeweils eine Division mit Rest durchgeführt, wobei der Rest im nächsten Schritt zum neuen Divisor wird. Der Divisor, bei dem sich Rest 0 ergibt, ist der größte gemeinsame Teiler der Ausgangszahlen. Beispiel:

formula_24

Somit ist 252 der größte gemeinsame Teiler von 3780 und 3528.

Der Euklidische-Algorithmus lautet in C entsprechend wie folgt:

Man verwendet alle Primfaktoren, die in jeder der Zahlen vorkommen, mit der jeweils kleinsten vorkommenden Potenz, zum Beispiel:

also:

Man könnte auch zunächst formula_29 berechnen und danach formula_30 denn als eine zweistellige Verknüpfung auf den natürlichen Zahlen ist der ggT assoziativ:

Dies rechtfertigt die Schreibweise formula_32.

Seien formula_2, formula_3, formula_35 und formula_4 ganze Zahlen. Dann gilt:

Dabei bezeichnet formula_38 den Betrag von formula_2.

Aus der genannten Rechenregel formula_40 ergibt sich speziell formula_41. Dies ergibt sich auch daraus, dass jede ganze Zahl formula_4 (sogar die 0 selbst) wegen formula_43 Teiler der 0 ist, während umgekehrt 0 keine von 0 verschiedene Zahl teilt.

Ist formula_44 ein gemeinsamer Teiler von formula_2 und formula_3, dann gilt:

Ist formula_50   (formula_2 und formula_3 sind kongruent modulo formula_4), dann gilt:

Hält man eines der beiden Argumente fest, dann ist ggT eine multiplikative Funktion, denn für teilerfremde Zahlen formula_2 und formula_3 gilt

Nach dem Lemma von Bézout lässt sich der größte gemeinsame Teiler zweier ganzer Zahlen formula_4 und formula_59 als Linearkombination von formula_4 und formula_59 mit ganzzahligen Koeffizienten darstellen:

Beispielsweise besitzt der größte gemeinsame Teiler von formula_64 und formula_65 die folgende Darstellung:

Die Koeffizienten formula_67 und formula_68 können mit dem erweiterten euklidischen Algorithmus berechnet werden.

Beim Kürzen wird ein gemeinsamer Faktor von Zähler und Nenner eines Bruches entfernt, wobei sich der Wert des Bruches nicht ändert, z. B. formula_69. Kürzt man mit dem größten gemeinsamen Teiler von Zähler und Nenner, entsteht ein Bruch, der nicht weiter kürzbar ist. Zum Beispiel ist formula_70, also

Ein Bruch, der nicht weiter kürzbar ist, wird "gekürzter Bruch" oder auch "vollständig" und "maximal gekürzter Bruch" genannt.

→ "siehe Kleinstes gemeinsames Vielfaches#Zusammenhang zwischen kgV und dem größten gemeinsamen Teiler"

Der Begriff des ggT baut auf dem Begriff der Teilbarkeit auf, wie er in Ringen definiert ist. Man beschränkt sich bei der Diskussion des ggT auf nullteilerfreie Ringe, im kommutativen Fall sind das die Integritätsringe.

Ein Integritätsring, in dem je zwei Elemente einen ggT besitzen, heißt "ggT-Ring" oder "ggT-Bereich". (In einem ggT-Ring haben je zwei Elemente auch ein kgV.)

In Allgemeinen besitzen solche Ringe keine Halbordnung, die antisymmetrisch ist, wie die ganzen oder die natürlichen Zahlen eine haben. Häufig ist die Teilbarkeitsrelation, die eine Quasiordnung ist, die einzige Ordnungsrelation. Deshalb lässt sich der ggT ggfls. nicht mehr eindeutig als nicht-negativ normieren, sondern nur bis auf Assoziiertheit bestimmen. Zwei Elemente formula_2 und formula_3 sind assoziiert, in Zeichen formula_74, wenn es eine Einheit formula_75 mit formula_76 gibt.

Wir erweitern den Begriff des ggT auf die Menge aller größten gemeinsamen Teiler der Elemente einer Teilmenge formula_77 eines Ringes formula_78, formal:
In Worten: Die Teiler von formula_80 sind genau die Elemente aus formula_78, die alle Elemente aus formula_77 teilen.
Die ggT sind untereinander assoziiert.

Man kann den ggT z. B. auch für Polynome bilden. Statt der Primfaktorzerlegung nimmt man hier die Zerlegung in irreduzible Faktoren:

Dann ist

Der Polynomring formula_85 in einer Variablen formula_86 ist euklidisch. Dort gibt es zur Berechnung des formula_1 eine Division mit Rest.

Im gaußschen Zahlenring formula_88 ist der größte gemeinsame Teiler von formula_89 und formula_90 gerade formula_91, denn formula_92 und formula_93. Genau genommen ist formula_91 nur "ein" größter gemeinsamer Teiler, da alle zu dieser Zahl assoziierten Zahlen ebenfalls größte gemeinsame Teiler sind. (Die Einheiten sind formula_95.)

Im Integritätsring formula_96 haben die Elemente

keinen ggT: Die Elemente formula_98 und formula_89 sind zwei "maximale gemeinsame Teiler", denn beide haben den gleichen Betrag, aber diese zwei Elemente sind nicht zueinander assoziiert. Also gibt es keinen ggT von formula_2 und formula_3.

Die genannten Elemente formula_102 und formula_89 haben aber ihrerseits einen ggT, nämlich formula_104. Dagegen haben sie kein kgV, denn wenn formula_105 ein kgV wäre, dann folgt aus der „ggT-kgV-Gleichung“, dass formula_105 assoziiert zu formula_107 sein muss. Das gemeinsame Vielfache formula_108 ist jedoch kein Vielfaches von formula_109, also ist formula_109 kein kgV und die beiden Elemente haben gar kein kgV.

Ist formula_78 ein Integritätsring und haben die Elemente formula_2 und formula_3 ein kgV, dann haben sie auch einen ggT, und es gilt die Gleichung

Ein euklidischer Ring ist ein Hauptidealring, der ein faktorieller Ring ist, der schließlich ein ggT-Ring ist. Ebenso ist jeder Hauptidealring ein Bézoutring, der wiederum stets ein ggT-Ring ist.

Ein Beispiel für einen nicht-kommutativen ggT-Ring sind die Hurwitzquaternionen.

In der elementaren Zahlentheorie gehört der größte gemeinsame Teiler formula_115 von zwei ganzen Zahlen formula_116 zu den wichtigsten Grundkonzepten. Man schreibt dort regelmäßig formula_117 und meint damit dann den "positiven" ggT, geht also von formula_118 aus.

In der analytischen Zahlentheorie kann die ggT-Funktion formula_119 in "einer" Variablen für festes formula_120 analytisch zu einer ganzen Funktion fortgesetzt werden. → Siehe Ramanujansumme.




</doc>
<doc id="2022" url="https://de.wikipedia.org/wiki?curid=2022" title="GGT">
GGT

GGT steht für:



</doc>
<doc id="2026" url="https://de.wikipedia.org/wiki?curid=2026" title="Gebrauchsmuster">
Gebrauchsmuster

Das Gebrauchsmuster ist der „kleine Bruder“ des Patents und ein Schutzrecht des Gewerblichen Rechtsschutzes. Die Unterschiede zum Patent sind mit den letzten Änderungen des Gebrauchsmustergesetzes (GebrMG) geringer geworden. 

Infolge der zunehmenden Industrialisierung und des gesteigerten Warenverkehrs, vor allem aber im Zuge zunehmender wirtschaftlicher Interessenwahrnehmung auf nationalstaatlicher Ebene, entstand nach der Reichsgründung, ähnlich wie schon ein Gesetz zum Geschmacksmusterschutz (1876) auch die Dekretierung eines Gebrauchsmusterschutzes. Ein Reichsgesetz vom 1. Juni 1891 schuf für das Deutsche Kaiserreich die rechtlichen Voraussetzungen, sodass das Kaiserliche Patentamt am 1. Oktober 1891 das „Deutsche Reichs-Gebrauchsmuster“ einführte. Zahlreiche Produkte wurden so zwischen 1891 und etwa 1945 mit der Kennzeichnung „D.R.G.M.“ versehen, oft unter Hinzufügung der Musternummer, die es heute erlaubt, die Entstehungszeit mancher materiell überlieferter historischer Geräte auf ein bestimmtes Jahrzehnt einzugrenzen. Auch einige Jahre nach dem Zweiten Weltkrieg war diese Kennzeichnung in Westdeutschland gelegentlich noch üblich, die Abkürzung lautete dann nach Gründung der Bundesrepublik Deutschland entsprechend "D.B.G.M." (Deutsches Bundes-Gebrauchsmuster).

Die Schutzvoraussetzungen für das Gebrauchsmuster sind denen für das Patent ähnlich. Durch ein Gebrauchsmuster können in Deutschland und Österreich gewerblich anwendbare Erfindungen geschützt werden, die neu sind und auf einem erfinderischen Schritt beruhen (DE: § 1 Abs. 1 GebrMG; AT: § 1 Abs. 1 GMG). Die Schweiz kennt keinen Gebrauchsmusterschutz. In den übrigen europäischen Staaten sind dem Gebrauchsmuster entsprechende Institute vor allem in Spanien von Bedeutung, aber in zahlreichen anderen Ländern vorgesehen, zum Teil mit Anforderungen wie beim Patent (Frankreich, Belgien, Ungarn), zum Teil mehr oder weniger stark abweichend. In den Niederlanden läuft das sog. Sechs-Jahre-Patent aus, weil es für die Antragsteller zu wenig Rechtssicherheit bietet.

Bei der Anforderung der „Neuheit“ zeigen sich Unterschiede zum Patent:
Eine Erfindung ist neu im Sinne des GebrMG, wenn sie – zum Zeitpunkt der Anmeldung des Gebrauchsmusters – aus dem Stand der Technik noch nicht bekannt ist. Im Gegensatz zum PatG in diesem Sinne ist jedoch nur das bekannt, was "schriftlich" vorbeschrieben ist oder bereits "im Inland" vorbenutzt wurde (DE: § 3 Abs. 1 GebrMG; abweichend AT: § 3 Abs. 1 GMG: auch mündliche Beschreibungen, keine Beschränkung auf das Inland). 

Darüber hinaus bleiben auch Veröffentlichungen bei der Prüfung der Neuheit unberücksichtigt, die durch den Erfinder oder seinen Rechtsnachfolger bis zu 6 Monaten vor der Anmeldung erfolgt sind (Neuheitsschonfrist; DE: § 3 Abs. 1 Satz 3 GebrMG; AT: § 3 Abs. 4 Nr. 1 GMG). Außerdem kann in Deutschland für eine Anmeldung innerhalb von sechs Monaten nach einer Ausstellung auf einer anerkannten Messe (im Bundesgesetzblatt veröffentlicht) eine „Ausstellungspriorität“ in Anspruch genommen werden, so dass bei der Beurteilung der Schutzfähigkeit des Gebrauchsmusters alle Veröffentlichungen, die am Tag der Ausstellungspriorität oder danach erfolgten, außer Betracht bleiben.

Der erfinderische Schritt ist, ähnlich wie die erfinderische Tätigkeit im Patentrecht, jeweils im Einzelfall zu prüfen. Die frühere Ansicht, dass der Maßstab an die Erfindungshöhe, also der erfinderische Schritt beim Gebrauchsmuster, im Allgemeinen geringer sei als die erfinderische Tätigkeit beim Patent, kann in Deutschland durch die Entscheidung „Demonstrationsschrank“ des BGH (veröffentlicht u. a. in BGHZ 168, 142 und in Gewerblicher Rechtsschutz und Urheberrecht (GRUR) 2006, 842) als überholt angesehen werden. Es kann daher nicht generell gesagt werden, dass eine Erfindung, die nicht ganz „patentwürdig“ ist, gebrauchsmusterfähig ist. 

In Österreich wurde dies zunächst noch anders gesehen (so der Oberste Gerichtshof (OGH) in seinen Entscheidungen „Wurfpfeilautomat“ aus dem Jahr 1996, „Gleitschichtkühler“ aus dem Jahr 2003 und „Holzabdeckung“ vom 12. Juli 2006 (in ÖBl. 2007, 76, 78 f.) sowie der Oberste Patent- und Markensenat in Patentblatt 2007, 88 „Gong“; kritisch hierzu Beetz: "Zur Erfindungsqualität im Gebrauchsmusterrecht", ÖBl. 2007, 148). In der Entscheidung „Teleskopausleger“ hat sich der Oberste Patent- und Markensenat der Entscheidung des BGH in „Demonstrationsschrank“ aber angeschlossen, so dass es auch in Österreich keinen Unterschied zwischen dem „erfinderischen Schritt“ und der „erfinderischen Tätigkeit“ gibt.

Wie auch bei Patenten ist die gewerbliche Anwendbarkeit bei Gebrauchsmustern in der Regel gegeben. Die Voraussetzungen an die gewerbliche Anwendbarkeit sind denen des Patents gleich und in Europa weitestgehend vereinheitlicht. Lediglich bei medizinischen Heilverfahren ist gewerbliche Anwendbarkeit oft nicht gegeben, da das Handeln des Arztes während seiner Berufsausübung als nicht gewerblich angesehen wird. Daneben ist auch die private bzw. höchstpersönliche Anwendung eines Verfahrens nicht gewerblich anwendbar. Das betrifft beispielsweise die Religionsausübung und Ähnliches.

Im Gegensatz zum Patentrecht können in Deutschland (anders in Österreich) Verfahren nicht durch Gebrauchsmuster geschützt werden. Die Rechtsprechung der letzten Jahre hat den Begriff des Verfahrens aber einengend gesehen. Daneben sind in Deutschland nunmehr biotechnologische Erfindungen ganz vom Schutz ausgeschlossen, in Österreich lediglich der Schutz von Pflanzen, Tieren und biologischem Material sowie Verfahren zu deren Züchtung und Verfahren zur chirurgischen oder therapeutischen Behandlung von Menschen und Diagnostizierverfahren an Menschen ().

Die Schutzdauer von Gebrauchsmustern beträgt zunächst drei Jahre. In den meisten Ländern ist es maximal verlängerbar auf zehn Jahre.

Das Patent- und Markenamt prüft bei einem Gebrauchsmuster in Deutschland nicht die sachlichen Voraussetzungen. Liegen die formellen Kriterien vor, so wird das Gebrauchsmuster in der Regel in das Gebrauchsmusterregister eingetragen (§ 8 GebrMG). Lediglich bei offensichtlich nicht dem Gebrauchsmusterschutz zugänglichen Gegenständen, z. B. Verfahren, erfolgt keine Eintragung. Dadurch wird ein schnelles Eintragungsverfahren erreicht, so dass der Inhaber aus dem Gebrauchsmuster sehr schnell Rechte geltend machen kann, ohne ein evtl. langwieriges Patenterteilungsverfahren abwarten zu müssen. 

In Österreich gibt es die Möglichkeit der beschleunigten Registrierung (§ 27 GMG), welche bei Vorliegen der formellen Kriterien für die Erteilung eine sofortige Veröffentlichung im Gebrauchsmusterblatt und eine sofortige Eintragung in das Gebrauchsmusterregister ermöglicht. Daneben wird ein Recherchenbericht erstellt und dem Anmelder die Möglichkeit gegeben, bestimmte Verfahrensschritte freiwillig zu setzen (Teilung, Änderung). Daneben ist auch die einmalige Umwandlung einer Gebrauchsmusteranmeldung in eine Patentanmeldung sowie die Umwandlung einer Patentanmeldung in eine Gebrauchsmusteranmeldung möglich. 

Eine professionell, d. h. von einem Patentanwalt eingereichte Gebrauchsmusteranmeldung ist in der Regel innerhalb von etwa drei Monaten in das Gebrauchsmusterregister eingetragen. Im Vergleich dazu erstellt das DPMA bei einer Patentanmeldung nach etwa acht Monaten einen ersten, sachlichen Bescheid, so dass bis zur Erteilung in der Regel mindestens 18 Monate vergehen.
In Österreich liegen die Schriftstücke (Vorbescheide) der Fachabteilungen im Schnitt einen Monat, bevor sie freigegeben und per Post ausgesendet werden.

Die sachlichen Kriterien werden erst bei einem Verletzungsverfahren durch das Zivilgericht oder im Löschungsverfahren vom Deutschen Patent- und Markenamt bzw. Bundespatentgericht geprüft.

Das Verletzungsverfahren findet vor den zuständigen Kammern an den Landgerichten (Patentstreitkammern) statt. Im Gegensatz zum Verletzungsprozess in Patentsachen kann die Verletzungsbeklagte hier einwenden, dass das Gebrauchsmuster nicht rechtsbeständig ist, ihm es mithin an Neuheit oder am erfinderischen Schritt fehlt.
Das Risiko, dass sich das Gebrauchsmuster im Streitfall mit einem Verletzer als nicht rechtsbeständig erweist, ist (wegen der fehlenden Prüfung durch das Amt vor der Eintragung) höher als beim Patent und muss vom Gebrauchsmusterinhaber getragen werden. Nimmt ein Gebrauchsmusterinhaber einen Verletzer in Anspruch, so kann sich daher auch eine Schadenersatzpflicht des Gebrauchsmusterinhabers ergeben, wenn sich das Gebrauchsmuster als nicht rechtsbeständig erweist. Ein Gebrauchsmusterinhaber sollte daher unbedingt eine professionelle Recherche zur Prüfung der Rechtsbeständigkeit veranlassen, bevor er einen Verletzer in Anspruch nimmt.

Das Löschungsverfahren kann in Deutschland von jedermann durch einen Antrag auf Löschung eines Gebrauchsmusters beim Deutschen Patent- und Markenamt (DPMA) in Gang gesetzt werden. Somit besteht im Gegensatz zum Patent eine zweifache Verteidigungsmöglichkeit gegen ein Gebrauchsmuster (Zivilgerichte einerseits, DPMA und Bundespatentgericht andererseits).
In Österreich findet auch gegen Gebrauchsmuster das Nichtigkeitsverfahren vor der Nichtigkeitsabteilung des Österreichischen Patentamts mit Berufung zum Oberlandesgericht (OLG) Wien statt.

Die Schutzwirkung ist im Wesentlichen die gleiche wie beim Patent. 

In einigen Fällen werden bestimmte Schutzwirkungen jedoch versagt, da Gebrauchsmuster im Gegensatz zu Patenten nicht geprüft sind. Im österreichischen Zollverfahren können Waren eines Verletzers nur dann angehalten werden, wenn ein Patent erteilt ist, nicht jedoch, wenn ein Gebrauchsmuster registriert ist. 

In Österreich ist es seit 1994 möglich, Programmlogik als Gebrauchsmuster anzumelden, wobei für Gebrauchsmuster nur eine formale Prüfung durchgeführt wird. Dadurch soll gemäß den amtlichen Erläuterungen ein Schutz der Lösungsidee möglich sein, die durch die Programmlogik manifestiert wird.



außerdem die Kommentare zum Patentgesetz von Georg Benkard, 11. Aufl. 2015, Busse/Keukenschrijver, 8. Aufl. 2016 und Mes, 4. Aufl. 2015, mit Kommentierung des Gebrauchsmustergesetzes



</doc>
<doc id="2027" url="https://de.wikipedia.org/wiki?curid=2027" title="Zählrohr">
Zählrohr

Zählrohre dienen zum Nachweis und zur Messung ionisierender Strahlung, gehören also zu den Strahlungs- und Teilchendetektoren.

Je nach Bauart und Betriebsspannung arbeitet das Zählrohr
Der häufig anzutreffende Begriff Geigerzähler bezeichnet fachsprachlich das Geiger-Müller-Zählrohr. Umgangssprachlich kann damit jedoch auch ein komplettes Strahlungsmessgerät gemeint sein, etwa ein Kontaminationsnachweisgerät oder ein Dosisleistungsmessgerät. Der Detektor in solchen Geräten ist oft, aber nicht immer, ein Geiger-Müller-Zählrohr.

Im Prinzip ist mit ein und demselben Zählrohr jede der drei genannten Betriebsarten möglich. Die meisten Zählrohre werden aber für eine bestimmte dieser Anwendungen optimiert gebaut. 

Die einfachsten Zählrohre bestehen aus einem an beiden Seiten verschlossenen zylindrischen Metallrohr, das die Kathode darstellt. Die Anode, ein Draht von z. B. 0,1 mm Durchmesser, befindet sich in der Achse des Zylinders und wird an einem Ende durch einen Isolator (Glas) aus dem Zählrohr herausgeführt. Der Rohrdurchmesser beträgt einige Zentimeter.

Solche Zählrohre sind zur Detektion von Gammastrahlung geeignet, da diese das Metallrohr durchdringt. Wenn auch Alpha- und Betastrahlung detektiert werden sollen, darf das Zählrohr an einem Ende nur mit einer massearmen Folie (z. B. Glimmer oder biaxial orientierter PET-Folie) verschlossen sein ("Fensterzählrohr"). Die Folie muss dem Druckunterschied zur Außenluft standhalten, aber die Teilchen in das Zählrohr gelangen lassen.

Das Rohr ist mit einem Gas ("Zählgas") gefüllt, wie unten ausführlicher beschrieben.

Zwischen Anode und Kathode wird eine Gleichspannung angelegt. Wenn ionisierende Strahlung einfällt, erzeugt sie in der Gasfüllung freie Elektronen, die im elektrischen Feld zur Anode wandern. Im Fall geladener Teilchenstrahlung ist die Zahl der Elektronen proportional der vom einfallenden Teilchen im Gas abgegebenen Energie.

Der weitere Vorgang hängt wesentlich von der Spannung zwischen Anode und Kathode ab, wie die abgebildete Kurve ("Charakteristik") zeigt. Bei geringer Spannung rekombiniert ein Teil der Elektronen auf dem Weg zur Anode wieder mit den Ionen. Der im Stromkreis auftretende Stromimpuls entspricht nur den Elektronen, die die Anode erreicht haben; dieser Anteil ist je nach dem Ort der Ionisation im Rohr verschieden groß und ergibt daher keine Aussage über die vom detektierten Teilchen abgegebene Energie. Dieser Bereich der angelegten Spannung heißt Rekombinationsbereich.

Bei höherer Spannung – Größenordnung 100 Volt – erreichen alle freigesetzten Elektronen die Anode. Der im Stromkreis messbare Impuls ist damit proportional der Energie, die die Strahlung im Zählrohr abgegeben hat. Das Zählrohr arbeitet jetzt als Ionisationskammer.

Soll die gesamte Energie eines Strahlungsteilchens erfasst werden, muss die Teilchenbahn im Gas enden, die Reichweite der Strahlung im Gas also kürzer als die Abmessung des Zählrohrs in Strahlenrichtung sein. Dementsprechend werden hierfür relativ große Zählrohre (bis zu etwa 1 m lang) und Gasfüllungen bis zu einigen Bar Überdruck verwendet.

Bei weiterer Erhöhung der Spannung werden die durch die Strahlung freigesetzten Elektronen aufgrund der hohen elektrischen Feldstärke dicht am Anodendraht so stark beschleunigt, dass sie durch Stöße mit den Gasatomen weitere Elektronen auslösen können. Es entstehen Elektronenlawinen mit je "n" Elektronen ("n" kann bis zu 1 Million betragen); dies wird auch "Gasverstärkung" genannt. Da die Lawinen nur in einem sehr kleinen Raumbereich nahe der Anode auftreten, ist die Größe des gemessenen Stromimpulses unabhängig vom Ort der ursprünglichen Ionisierung und nach wie vor proportional der Energie der einfallenden Strahlung. Deshalb heißt dieser Bereich der Betriebsspannung "Proportionalbereich". Der Impuls ist im Vergleich zum Ionisationskammerbetrieb "n"-mal größer und daher leichter messbar.

Für Abmessungen und Gasdruck gilt das Gleiche wie bei Ionisationskammern. Da der Proportionalbereich in einem steilen Teil der Charakteristik liegt, muss die Betriebsspannung sehr genau konstant sein. Während eine Ionisationskammer z. B. auch parallele Plattenelektroden haben kann, ist beim Proportionalzählrohr die Feldgeometrie mit dem dünnen Anodendraht wesentlich. Die Zylinderform der Kathode ist dagegen nicht entscheidend; Proportionalzähler können je nach geometrischen Erfordernissen auch andere Formen haben und auch mehrere parallele Anodendrähte enthalten.

Proportionalzählrohre bieten nicht nur die Möglichkeit, Teilchenenergien zu messen, sondern werden z. B. im Strahlenschutz wegen der guten Unterscheidungsmöglichkeit zwischen Alpha- und Betastrahlung verwendet. Auch die Hand-Fuß-Monitore für die Routinekontrolle beim Verlassen von Kontrollbereichen enthalten deshalb Proportionalzähler.

Aus der physikalischen Forschung ist z. B. das Homestake-Neutrinoexperiment zu nennen, wo Proportionalzähler eingesetzt wurden, um sehr seltene Beta-Zerfälle einer gasförmigen Probe sicher von anderer Strahlung unterscheiden zu können. In weiterentwickelter Form wird der Proportionalzähler als Vieldraht-Proportionalkammer und als Straw-Detektor auch in der Hochenergiephysik genutzt.

Auch Neutronenstrahlung kann mit Proportionalzählrohren gemessen werden. Zur Energiemessung an schnellen Neutronen (etwa 0,1 bis 6 MeV) wird als Zählgas Wasserstoff oder Methan von einigen Bar Überdruck verwendet. Aus dem damit gemessenen Energiespektrum der Rückstoßprotonen aus der elastischen Streuung lässt sich auf das Neutronenspektrum schließen.

Für langsame, insbesondere für thermische Neutronen eignet sich das Gas Bortrifluorid (BF). Die beiden in der exothermen Kernreaktion B(n,formula_1)Li gleichzeitig entstehenden Ionen, das Alphateilchen und der Lithium-Atomkern, führen zur Ionisation. Zwecks höherer Nachweiswahrscheinlichkeit wird oft BF mit an B-10 angereichertem Bor benutzt. 

Statt der BF-Gasfüllung kann auch eine borhaltige Schicht auf der Innenseite des Zählrohrs verwendet werden. Dies hat den Vorteil, dass als Zählgas z. B. Argon genutzt werden kann, das kürzere Impulse ergibt. Nachteilig ist dagegen, dass die Kernreaktion weniger Ionisationsenergie im Gas hinterlässt, denn aus kinematischen Gründen wird immer nur eines der beiden Ionen ins Rohrinnere emittiert; die Unterscheidung von Gammaimpulsen wird dadurch schwieriger.

Das seltene Heliumisotop Helium-3 kann ebenfalls als Neutronen-Zählgas dienen. Die auch hier exotherme Reaktion ist He(n,p)H. He-3 ist teurer als Bortrifluorid, ergibt aber eine höhere Nachweiswahrscheinlichkeit, denn es enthält keine anderen Atomkerne, der Wirkungsquerschnitt der Reaktion ist größer und es kann ein höherer Fülldruck verwendet werden. He-3-Zählrohre können bei höheren Temperaturen betrieben werden, bei denen BF sich zersetzen würde.

Auch die Bor- und Helium-3-Zählrohre werden im Proportional- und nicht im Geiger-Müller-Bereich (siehe unten) betrieben, um beispielsweise Gammastrahlung von Neutronenstrahlung unterscheiden zu können. Eine wichtige Anwendung (meist mit BF-Zählrohr) ist der Long Counter.

Ab einer bestimmten noch höheren Spannung bewirkt jedes einfallende ionisierende Teilchen eine "selbständige" Gasentladung, das heißt, auch jedes sekundär freigesetzte Elektron löst, bevor es die Anode erreicht, seinerseits mindestens ein neues Elektron aus. Auch wird Ultraviolettstrahlung erzeugt, die an entfernten Stellen ionisiert, sodass die Entladung sich über das ganze Zählrohr ausbreitet. Die einmal eingeleitete ("gezündete") Gasentladung „brennt“ unabhängig von Art und Energie der auslösenden Strahlung (daher die Bezeichnung „Auslösezählrohr“) und erlischt erst, wenn die langsam radial nach außen wandernde Ionenwolke durch Abschirmung die Feldstärke genügend verringert hat. Ein erneutes Zünden der Gasentladung beim Aufprall der Ionen auf die Rohrwand wird durch Zusatz eines "Löschgases" zum Füllgas verhindert (siehe unter Gasfüllung).

Die Stromimpulse sind also von einheitlicher Größe und so groß, dass sie u. U. ohne Verstärkung direkt in einem Lautsprecher als Knackgeräusche hörbar gemacht werden können. Zur Auslösung genügt schon ein einziges freigesetztes Elektron, der Detektor hat also die bestmögliche Empfindlichkeit. Dieser Bereich der Arbeitsspannung heißt "Plateau" oder "Geiger-Müller-Bereich".

Verglichen mit anderen Detektoren hat das Geiger-Müller-Zählrohr wegen des Gasentladungsvorgangs eine relativ lange Totzeit der Größenordnung 100 Mikrosekunden. Daran schließt sich noch eine ähnlich lange "Erholungszeit" an, während der ein neuer Impuls nicht die volle Höhe erreicht. Noch länger wird die Totzeit, wenn durch einen sehr hohen Widerstand, etwa 100 Kiloohm, in der Hochspannungszuleitung das erneute Zünden nach dem Impuls unterbunden werden soll; deshalb hat sich als besseres Verfahren der Löschgaszusatz allgemein durchgesetzt.

Verwendet werden Geiger-Müller-Zählrohre beispielsweise zur Prüfung auf Kontamination und für allgemeine Strahlenschutzzwecke. Information über Strahlenart und -energie lässt sich mit ihnen nur grob gewinnen, indem man Vergleichsmessungen mit verschiedenen zwischen Strahlenquelle und Zählrohr gebrachten Abschirmungen vornimmt.

Als Zählrohrfüllung können viele verschiedene Gase, sogar Luft, dienen. Edelgase wie z. B. Argon sind vorteilhaft zum Erzielen möglichst kurzer Impulse, weil sie keine negativen Ionen bilden, die viel langsamer als die Elektronen zur Anode wandern. Zur Detektion von Gammastrahlung wird Argon mit mehreren Bar Überdruck oder, wegen seiner hohen Ordnungszahl, Xenon verwendet. Bei Ionisationskammern und Proportionalzählern wird oft ein Anteil einer gasförmigen Verbindung beigemischt, etwa Methan oder Kohlendioxid. Dieser Zusatz verringert durch unelastische Stöße die Temperatur der Elektronen und bewirkt so eine weitere Verkürzung des Stromimpulses, macht also den Detektor „schneller“. Er unterdrückt auch Ultraviolettstrahlung, die zu überzähligen Impulsen führen könnte.

Für den Geiger-Müller-Betrieb wird dem Gas Ethanoldampf oder ein Halogengas (Chlor oder Brom) beigemischt. Dieses "Löschgas" sorgt dafür, dass nach dem Erlöschen der Gasentladung keine neue Zündung durch auf die Wand auftreffende Ionen erfolgt, indem seine Moleküle Energie durch Dissoziation statt durch Ionisation aufzehren.

Ortsfest betriebene Zählrohre sind in manchen Fällen nicht dicht verschlossen, sondern werden als "Durchflusszähler" mit langsam durchströmendem Gas betrieben. Dies vermeidet Probleme mit Verunreinigungen, chemischen Reaktionen des Gases oder kleinen Undichtigkeiten. Bei Geiger-Müller-Zählern kann so der Ethanolzusatz, der sich im Zählrohrbetrieb sonst verbrauchen würde, konstant gehalten werden.

Ein Vorläufer der Zählrohre wurde erstmals 1913 von Hans Geiger beschrieben. Das Geiger-Müller-Zählrohr geht auf Geigers Entwicklungsarbeiten zusammen mit seinem Mitarbeiter Walther Müller zurück, deren Ergebnisse ab 1928 veröffentlicht wurden. Es war der erste bekannte und allgemein genutzte Detektortyp, der auf Teilchen oder Strahlungsquanten mit einem elektrischen Impuls reagierte. Die praktische Nutzung des Proportionalbereiches ist in elektronischer Hinsicht – Verstärkung der Impulse, Stabilität der Hochspannung – anspruchsvoller und wurde erst ab der Mitte des 20. Jahrhunderts zu einer Routinemethode.

Da die Impulse des Geiger-Müller-Zählrohrs für alle Teilchen gleich sind, eignet es sich vor allem zum "Zählen" der einfallenden Teilchen/Quanten. Die Bezeichnung „Geigerzähler“ oder „Geiger-Zählrohr“ erscheint daher natürlich. Diese Bezeichnung hat sich auf die später entwickelten Detektoren wie „Proportionalzähler“, „Szintillationszähler“ usw. übertragen, obwohl diese nicht nur zum Zählen, sondern auch zur Energiemessung und zur Unterscheidung von Strahlenarten dienen.




</doc>
<doc id="2030" url="https://de.wikipedia.org/wiki?curid=2030" title="Ginkgo">
Ginkgo

Der Ginkgo oder Ginko ("Ginkgo biloba") ist eine in China heimische, heute weltweit angepflanzte Baumart. Er ist der einzige lebende Vertreter der Ginkgoales, einer ansonsten ausgestorbenen Gruppe von Samenpflanzen. Natürliche Populationen sind nur aus der Stadt Chongqing und der Provinz Guizhou im Südwesten Chinas bekannt.

In Ostasien wird der Baum wegen seiner essbaren Samen oder als Tempelbaum kultiviert. Er wurde von holländischen Seefahrern aus Japan nach Europa gebracht und wird hier seit etwa 1730 als Zierbaum gepflanzt.

Zum Jahrtausendwechsel erklärte das deutsche „Kuratorium Baum des Jahres“ "Ginkgo biloba" zum Mahnmal für Umweltschutz und Frieden und zum Baum des Jahrtausends. Der Ginko ist ein „lebendes Fossil“.

Der Ginkgo ist ein sommergrüner Baum, das heißt, er wirft im Herbst seine Blätter ab. Er kann 1000 Jahre und älter werden und Wuchshöhen von bis zu 40 Metern und einen Brusthöhendurchmesser (BHD) von 1 bis 4 Meter erreichen. Ein Exemplar aus Korea besitzt eine Höhe von 64 Meter und einen BHD von 4,45 Metern. Der junge Baum wächst meistens schlank und auffallend gerade in die Höhe. Sein Umriss ist pyramidenförmig und er ist nur spärlich beastet. Dies ändert sich zunehmend beim älteren Baum ab 25 Jahren, dessen Äste sich immer mehr in die Waagerechte bewegen und so eine ausladende, mächtige Baumkrone bilden können. Meistens besitzt der Ginkgo zwei Haupttriebe, von denen einer schwächer ausgebildet ist. Bäume, die unter Stress stehen, können in Bodennähe oder darunter Sekundärstämme bilden, die aus wurzelartig wachsenden Trieben entstehen.

Das harzfreie, weiche und leichte Holz des Ginkgos weist eine feine Textur auf und ähnelt dem der entwicklungsgeschichtlich jüngeren Koniferen. Das hellbraune Kernholz lässt sich nur schwer vom hellgelben Splintholz unterscheiden. An Stammkrümmungen oder Ästen entsteht häufig Druckholz, das unabhängig von der Kontrolle des Hauptsprosses wächst. Der Zellulose-Gehalt liegt zwischen 40 und 42 Prozent und der Lignin-Gehalt bei 30 bis 34 Prozent. Die Rohdichte liegt mit 12 bis 15 Prozent Holzfeuchtigkeit bei ca. 430 kg/m³. Im Gegensatz zu Nadelhölzern sind bei dieser Art Tracheiden in verschiedenen Größen vorzufinden. Bei den Radialwänden der Tracheiden können ein bis zwei, manchmal auch drei Reihen von Hoftüpfeln festgestellt werden. Darüber hinaus lagern sich in den Tracheiden viele Calciumoxalat-Kristalle an. Das Holz eignet sich gut für Schnitzerarbeiten und findet als Paneel Verwendung. Es werden kaum Bestände zur reinen Holzgewinnung angebaut.

Die Borke von ausgewachsenen Bäumen ist dunkelgrau, rau, tief gefurcht und schwer entflammbar; dies macht die Bäume mäßig feuerresistent. Bei jüngeren Stämmen ist sie graubraun und weist hellbraune Risse auf. Die Rinde einjähriger Zweige ist hellgrau und geht bei zweijährigen Zweigen ins Hellbraune über.

Während bei Altbäumen die Seitenwurzeln dominieren, bilden Jungbäume eine bis zu einen Meter lange Pfahlwurzel aus. Anders als in vielen Literaturberichten dargestellt, bildet der Ginkgo keine Wurzelbrut aus. Der Baum hat relativ dicke Feinwurzeln von über 0,5 Millimeter, die von sehr vielen Wurzelhaaren bedeckt sind.

Ginkgo besitzt die Fähigkeit, bei schlechten Umweltbedingungen über dem Boden „aereal chichi“ und unter dem Boden „basal chichi“ zu bilden. „Aereal chichi“ sind einem Tropfstein ähnelnde (stalaktitenartige) verholzte, über einen Meter lange Anschwellungen, die bei sehr alten Ginkgobäumen an den Ästen oder am Stamm in Asthöhe aus überwallten Sprossknospen entstehen. Berühren diese verholzten Anschwellungen den Boden, entstehen unter günstigen Bedingungen zahlreiche vegetative Sprosse, die sich zu einer eigenständigen Pflanze entwickeln können. „Basal chichi“ sind verholzte, rhizomähnliche Anschwellungen, aus denen meist Sekundärstämme und Adventivwurzeln hervorgehen. Die Entwicklung der „basal chichi“ ist meistens auf wurzelartige, zur Schwerkraft (positiv geotrop) wachsende Triebe (auch Lignotuber genannt) zurückzuführen. Stimuliert durch traumatische Reize treibt eine dieser Knospen in den Achseln der beiden Kotyledonen aus, und die entsprechenden Triebe wachsen vom Spross in Richtung Schwerkraft. Auch hier kann eine eigenständige Pflanze entstehen, die aber meist mit der Mutterpflanze verbunden bleibt.

Sehr auffällig sind die Terminalknospen. Sie sind lohfarbig (hellbraun), haben einen Durchmesser von 2 bis 5 mm und sind von kleinen Blättern ohne Achselknospen umgeben, wobei sich die Tegmente schuppenartig anordnen.

Eine Besonderheit in der Pflanzenwelt stellen die sehr charakteristischen fächerförmigen, breiten Laubblätter dar. Sie sind in der Mitte mehr oder weniger stark eingekerbt und die Blattform variiert je nach der Stellung am Trieb und der Wuchskraft des Baumes, weshalb kaum ein Ginkgo-Blatt dem anderen gleicht. Blätter von jungen Bäumen sind deutlich anders geformt als die von alten Bäumen (Altersdimorphismus). An Kurztrieben und an der Basis von Langtrieben erreichen die Blätter eine Breite von vier bis acht Zentimeter und sind entweder ungeteilt oder durch Einschnitt zweilappig. Die Blätter an den Spitzen von Langtrieben besitzen deutlich tiefere Ausbuchtungen, welche die Blätter in zwei oder mehr Lappen teilen. An den Langtrieben werden die Blätter zwischen sechs und zehn Zentimeter breit. Der Blattstiel wird zwischen vier und zehn Zentimeter lang. Alle Blätter sind gabelnervig (dichotom), evolutionär betrachtet ein sehr ursprüngliches Merkmal. Sie sind zu Beginn ihres Wachstums im Frühjahr hellgrün und dunkeln über den Sommer nach, im Herbst färben sie sich auffallend hellgelb bis goldgelb und fallen schließlich etwa Anfang November ab.
Nach einer weit verbreiteten Meinung haben die Fächerblätter ihre charakteristische Gestalt aus zusammengewachsenen Nadeln während ihrer Entwicklungsgeschichte geerbt. Das ist aber unwissenschaftlich und weder anatomisch, noch entwicklungsbiologisch oder evolutionär belegbar.

Die Äste bilden Langtriebe und Kurztriebe aus. Die Langtriebe können je nach Bedingungen zwischen 20 und 100 Zentimeter im Jahr wachsen. Aus den Langtrieben wachsen versetzte (wechselständige) Blätter, aus deren Blattstielansätzen wiederum achselständige Knospen wachsen. Kurztriebe sind sehr langlebig – sie werden bis 60 Jahre alt und wachsen häufig nur ein paar Millimeter im Jahr, weshalb sie kaum eine Länge von 20 Zentimeter erreichen. Kurztriebe können sich ganz unerwartet zu Langtrieben entwickeln.

Die Blätter, die als einzige Teile der Pflanze pharmazeutisch genutzt werden, enthalten rund 0,5 bis 1,8 Prozent Flavonoide: es sind dies Flavon- und Flavonolglykoside, acylierte Flavonolglykoside, Biflavonoide, Flavan-3-ole und Proanthocyanidine. Bei den beiden erstgenannten Gruppen treten als Aglykone vor allem Kaempferol, Quercetin und Isorhamnetin auf, in geringerem Ausmaß Apigenin und Luteolin.

Terpene sind zu 0,03 bis 0,25 Prozent vorhanden, vor allem als Terpenlactone. An Diterpenen sind die Ginkgolide A, B, C, J und M zu nennen. Das Sesquiterpen Bilobalid ist ein Abbauprodukt der Ginkgolide. Weitere Terpene sind Polyprenole und Steroide.

Des Weiteren kommen langkettige Kohlenwasserstoffe und deren Derivate vor: Alkohole, Aldehyde, Ketone und Säuren.

Weitere Inhaltsstoffe sind alicyclische Säuren (Shikimisäure, Chinasäure, Ascorbinsäure, Ginkgolsäure und Hydroxyginkgolsäure), Cyclite = cyclische Polyole (Pinit, Sequoyit), sowie Saccharose.

Der Ginkgo ist ein Windbestäuber und blüht im März, er ist zweihäusig getrenntgeschlechtig (diözisch), es existieren also männliche und weibliche Pflanzen. Gelegentlich treten einhäusig getrenntgeschlechtige (monözische) Bäume auf. Die Bäume unterschiedlichen Geschlechts sind bis zur Geschlechtsreife, die erst im Alter zwischen 20 und 35 Jahren erfolgt, äußerlich kaum voneinander zu unterscheiden. Weibliche und männliche Blüten wachsen an den Achseln von Laub- und Niederblättern aus mehrjährigen Kurztrieben heran.

Männliche Blüten haben das Aussehen von 2 bis 3 cm langen Kätzchen. Sie bestehen aus vielen an einer gestreckten Achse schraubig angeordneten Staubblättern (Mikrosporophyllen). Die Mikrosporophylle bestehen aus einem dünnen Stiel (Staubfaden) mit zwei (manchmal bis zu vier) an der Spitze (einer kurzen runden Apikalerweiterung) hängenden Mikrosporangien (Pollensäcken), in denen die Pollen gebildet werden. Die Blüten treiben vor den eigentlichen Blättern aus und fallen nach dem Bestäuben je nach Temperatur von Anfang April bis Ende Mai wieder ab. Der kahnförmige Pollen hat eine Größe von 30 µm × 10 μm.

Die 2 bis 3 mm großen Samenanlagen (weibliche Blüten) stehen zu zweit an einem sich apikal gabelnden 1 bis 1,5 cm langen Stiel. Gelegentlich ist nur eine, in manchen Fällen sind mehr als zwei zusätzliche Samenanlagen pro Stiel vorzufinden, von denen meist nur eine ausreift. Sie bestehen aus einem äußeren Integument mit einer als Mikropyle bezeichneten Öffnung im oberen Bereich. Im Inneren der Samenanlagen befindet sich das vom Integument umhüllte Megasporangium (Nucellus), in dessen Innerem sich wiederum die funktionsfähige Megaspore befindet.

Der nach der Befruchtung aus der Samenanlage entstandene Ginkgosamen ähnelt äußerlich den Mirabellen und hat eine Größe von 20 bis 30 mm × 16 bis 24 mm. Er besteht aus einem inneren Embryo, eingebettet in das Nährgewebe (primäres Endosperm) des weiblichen Gametophyten, das von drei Schichten umgeben ist: der dünnhäutigen Innenschicht (Endotesta), einer harten verholzten Mittelschicht (Sklerotesta) und einer dicken Samenschale (Sarkotesta), die früher einmal das Integument der Samenanlage war. Die sich entwickelnde Samenschale ist bis zur Reife im Herbst grün, bei Kälteeinbruch wird sie gelb, bis der Samen schließlich abfällt. Die Samenschale entwickelt im ausgereiften Zustand einen unangenehmen Geruch nach ranziger Butter. Verantwortlich dafür sind die in der Samenschale enthaltenen Fettsäuren Buttersäure und Capronsäure. Die ebenfalls enthaltenen Phenole können durch Austreten des Saftes zu Hautreizungen und Allergien führen. Der Ginkgosamen ohne Samenschale (der Kern) hat eine Größe von 19 bis 30 mm × 11 bis 14 mm und ein Tausendkorngewicht von 1500 Gramm.

Das diploide Genom des Ginkgo umfasst 2n=24 Chromosomen. Weibliche und männliche Bäume weisen in der Art ihrer Chromosomen erkennbare Unterschiede auf. Diese Unterschiede können mikroskopisch durch Wurzelspitzenpräparate nachgewiesen werden. Das kann sehr hilfreich sein, um recht junge Pflanzen meist neuer Zuchtsorten dem weiblichen oder männlichen Geschlecht zuordnen zu können. Weibliche Exemplare weisen ein heteromorphes (griechisch "verschieden geformtes") Chromosomenpaar mit nur einem kleinen Satelliten auf, männliche Bäume dagegen haben nur automorphe Chromosomen.

Der Befruchtungszeitpunkt liegt je nach Zeitpunkt der Bestäubung zwischen Ende August und Ende September. Im Generationswechsel entspricht der Ginkgobaum dem Sporophyt der Farne und Moose. Allerdings werden die Sporen der weiblichen Bäume nicht mehr in der Luft freigesetzt, sie sind vielmehr im Sporangium sesshaft geworden und relativ groß (genannt Megasporen; Megasporen gibt es auch bei diversen Algen).

Die weiblichen Blüten (Samenanlagen) entwickeln im Inneren der Megaspore (= Embryosackmutterzelle) einen extrem stark reduzierten Megagametophyten (= befruchtungsfähiger Embryosack), der über sein Megagametangium (Synergiden) einen Megagameten (Eizelle) erzeugt. Die Megasporen erhalten so viel Nahrung zugeteilt, dass sie später ohne selbstständige Ernährung Geschlechtszellen (Eizellen) entwickeln können. Der weibliche Gametophyt entsteht zunächst durch freie Kernteilungen, gefolgt von Zellwandbildung. Am Ende besteht der Gametophyt aus mehreren hundert Zellen und bildet meist zwei – selten auch drei – Archegonien. Der Gametophyt ist durch den Besitz von Chlorophyll grün gefärbt.

Die Sporen der männlichen Bäume (genannt Mikrosporen oder Pollen) erfahren noch im „Mikrosporangium“ ihre ersten mitotischen Teilungen. In der ersten Zellteilung entstehen durch zwei inäquale Teilungen der Pollenzelle zwei Prothalliumzellen und eine Antheridienzelle. Aus dieser entstehen durch erneute Teilung die Pollenschlauchzelle und die generative Zelle. In diesem Stadium wird das Pollenkorn aus dem Sporangium entlassen und als solches als stark reduzierter Mikrogametophyt (mehrzelliges Pollenkorn) vom Wind zum Megagametophyten geweht.

Im empfangsbereiten Stadium sondert das Integument an der Spitze (Mikropyle) eine für die Fortbewegung der männlichen Geschlechtszellen nötige schleimige Flüssigkeit (Pollinationströpfchen) ab. Sie entsteht durch Auflösung der Zellen unter der Mikropyle, wodurch auch eine Pollenkammer entsteht. Wenn das Pollenkorn das Pollinationströpfchen erreicht, absorbiert es Wasser und andere Substanzen aus der Flüssigkeit; auf diese Weise wird es schwerer, wodurch es zum Ende der Empfangsbereitschaft mit der Pollinationsflüssigkeit in der Mikropyle eintrocknet und sich in die Pollenkammer zurückzieht. Durch das Eintrocknen wird auch die Mikropyle verschlossen.

In der Pollenkammer keimt das Pollenkorn aus und bildet einen kurzen Pollenschlauch, der an seiner Spitze eine stark verzweigte, interzellular wachsende Struktur entwickelt, die das weibliche Gewebe (Nucellus) über mehrere Monate durchdringt, als eine Art Haftorgan (Haustorium) dient und Nährstoffe aufnimmt, wodurch sich das Nucellusgewebe zwischen Pollenkammer und Archegonienkammer auflöst. Während dessen werden im Pollenschlauch die Spermien gebildet: die generative Zelle teilt sich in eine Stielzelle und in die spermatogene Zelle. Der männliche Gametophyt ist jetzt fünfzellig, bestehend aus zwei Prothalliumzellen, Pollenschlauchzelle, Stielzelle und spermatogener Zelle. Letztere teilt sich und bildet zwei Spermienzellen (Spermatozoide). Der Pollenschlauch ist nichts anderes als das Rudiment eines einstmals selbstständig wachsenden Gametophyten. Vier Monate nach Auskeimen des Pollenkorns schwillt das basale Ende des Pollenschlauches so weit an, bis es die Form eines sackartigen Gebildes annimmt, das in unmittelbarer Nähe zum Archegonium in der mit Flüssigkeit gefüllten Archegonienkammer zerplatzt und zwei vielgeißlige, schwimmfähige, sich selbstständig bewegende Geschlechtszellen (Spermatozoiden) freisetzt. Der Ginkgo ist neben Palmfarnen die einzige rezente Samenpflanze mit Spermatozoiden. Die Spermien haben eine Größe von etwa 70-90 Mikrometer und wurden erstmals im Jahr 1895 bis 1898 von Sakugoro Hirase beschrieben. Nach Freilassung schwimmen die beiden Spermatozoiden auf die Archegonien zu. Ein Spermatozoid durchdringt die Archegonie und verschmilzt mit der Eizelle. Das ist eine für Pflanzen sehr ursprüngliche Entwicklung. Meistens erfolgt die eigentliche Verschmelzung der Spermatozoiden mit der Eizelle erst Wochen nach dem Abfallen der Samenanlagen.

Nach der Befruchtung teilt sich der Kern der Zygote rasch und bildet über 1000 freie Zellkerne. Danach bilden sich die Zellwände und aus dem Gewebe entwickelt sich schrittweise eine Wurzel, eine kleine stammartige Struktur von Zellen und zwei Keimblätter (Kotyledonen), deren Oberseiten nah zueinander platziert sind.

Als ursprüngliches Verbreitungsgebiet werden die mesophytischen Mischwälder, die einst das Hügelland entlang des Jangtsekiang bedeckten, genannt. In Dokumenten aus dem 11. Jahrhundert wird als Ursprungsgebiet eine Region südlich des Jangtsekiang genannt, die dem heutigen Ningguo-Distrikt in der Provinz Anhui entspricht. Natürliche Populationen sind nur aus dem Südwesten Chinas bekannt. Die Populationen an den Südhängen des Jinfo-Gebirges in der Stadt Chongqing weisen im Vergleich mit anderen Populationen in China eine ausgeprägte genetische Diversität auf und gelten daher als natürlich. In den angrenzenden Gebieten der Provinz Guizhou sind zahlreiche kleine Populationen vorhanden, die ebenfalls als natürliche Vorkommen des Ginkgos angesehen werden. Die lange Zeit als natürliches Vorkommen geltende Population auf dem Westgipfel des Tianmu Shan im Nordwesten der Provinz Zhejiang ist aller Wahrscheinlichkeit nach auf Anpflanzungen durch buddhistische Mönche zurückzuführen.

Wie die meisten Bäume geht auch der Ginkgo eine Symbiose mit verschiedenen Mykorrhiza-Pilzen ein, unter anderem mit "Glomus epigaeum". Er ist sehr unempfindlich gegenüber Luftschadstoffen und eignet sich deshalb sehr gut als Straßen- und Parkbaum. Des Weiteren ist er weitgehend resistent gegen Insektenfraß sowie von Pilzen, Bakterien und Viren ausgelöste Krankheiten, erträgt Temperaturen von bis zu −30 °C und wächst sowohl auf sauren wie alkalischen Böden, wobei bei ersteren meist ein schlechteres Wachstum zu erkennen ist. Sehr nasse aber auch übermäßig trockene Böden werden dagegen nicht toleriert.

In den USA zeigten angepflanzte Ginkgobäume ein gutes Wachstum bei reichhaltigen, über das ganze Jahr verteilten Niederschlägen. Bei kalten Winden, subtropischen und sehr hohen Temperaturen während der Vegetationsperiode war dagegen schlechtes Wachstum zu erkennen.

Der Ginkgo weist eine hohe Resistenz gegenüber Krankheiten und Herbivoren auf, keine Einzelspezies wird für sich allein als Bedrohung erachtet. Krankheitserreger wie Pilze, Bakterien oder Viren sind nur im Keimlingsstadium oder bei sehr geschwächten Pflanzen zu beobachten. In Bezug auf Insekten ist der Ginkgo einer der am wenigsten anfälligen Bäume überhaupt. Es konnte weder im ursprünglichen Lebensraum (Ostasien) noch in Nordamerika oder Europa eine natürliche Räuberfauna entdeckt werden.

Die Resistenz des Ginkgo gegenüber Pilzen lässt sich zum Teil durch einen wachsartigen Stoff in der Kutikula der Blätter erklären, der die Sporenkeimung und das Wachstum des Keimschlauches einiger Pilze verringert und somit ein Eindringen der Pilze in die Kutikula verhindert. Des Weiteren enthalten die Blätter 2-Hexenal, der fungizidische Eigenschaften aufweist. 2-Hexenal ist in niedriger Konzentration vorhanden und vom Wasserdampfdestillat der Blätter getrennt. In seltenen Fällen konnten "Fusarium sp." und "Macrophomina phaseoli" entdeckt werden, bei der es zur Wurzel- und Stammfäule kommt.

Die hohe Immunität gegen Bakterien- und Virusattacken wird zum einen durch den Säuregrad der Blätter erklärt, der ihn resistent gegen Bakterien wie "Pseudomonas phaseolicola", "Escherichia coli", "Bacillus pumilus" und "Xanthomonas phaseoli" macht. Zum anderen konnte durch Studien festgestellt werden, dass das Wachstum des Tabakmosaik- und Bohnenmosaikvirus durch Wirkstoffe aus den Wurzeln erheblich inhibiert wird.

Blätter, Holz und Wurzeln sind für fast alle Insekten mehr oder weniger toxisch. So werden in Japan und China Blätter des Ginkgobaums als Lesezeichen verwendet, um Bücher vor Silberfischen und Insektenlarven zu schützen. Z. B. sterben Japankäfer eher an Unterernährung als frische Ginkgoblätter zu fressen. Die säurehaltigen Blätter bilden bei Beschädigungen verstärkt 2-Hexenale, die zusammen mit Substanzen wie Ginkgolid A, Bilobalid und Ginkgolsäure als aktivste Bestandteile der Blätter gegenüber Insekten ermittelt wurden. Vereinzelt konnten bei jungen, alten und stark geschädigten Pflanzen einige Schädlinge identifiziert werden. Selten vorkommende Insekten sind "Cacoecimorpha pronubana" und die Larve des Maiszünslers ("Pyrausta mubilalis"), die sich von den Blättern ernähren, sowie "Brachytrupes portentosus", "Agrotis ypsilon" und "Gulcula panterinaria", die sich in vereinzelten Fällen von den Setzlingen ernähren.

Tiere wie Schnecken, Nacktschnecken, Mäuse, Kaninchen, Hasen oder Hirsche gehören bei Jungpflanzen zu den bedeutendsten Fraßfeinden. Sie fressen die Blätter, Wurzeln oder die Rinde im unteren Bereich des Baums ab, was oft zum Absterben der Pflanze führt. Bei Sämlingen besteht zudem die Gefahr der Zerstörung durch Vögel.

 Der Name Ginkgo leitet sich vom chinesischen "Yínxìng" () her, dessen sinojapanische Aussprache "Ginkyō" (jap. phonographisch ) ist. Es handelt sich um eine Kombination der Schriftzeichen „gin = Silber“ und „kyō = Aprikose“, ein Hinweis auf die silbrig schimmernden Samenanlagen. Der Name ist für das Jahr 1578 erstmals bezeugt. Nach Europa gelangte er durch den deutschen Arzt und Japanforscher Engelbert Kaempfer, der, angeregt durch Andreas Cleyer und andere Gelehrte, in Batavia während seines zweijährigen Aufenthalts in Japan (1690 bis 1691) umfangreiche Untersuchungen zur Pflanzenwelt des Archipels durchführte. Einen großen Teil seiner Forschungsergebnisse publizierte er unter dem Titel „Flora Japonica“ in seinem Werk "Amoenitatum Exoticarum" (Lemgo, 1712). Nahezu alle Pflanzen hatte er in Japan zeichnerisch festgehalten. Da er Wert auf die Wiedergabe der einheimischen Namen legte, ließ er sich diese von Japanern im bebilderten Wörterbuch "Kinmōzui" () anzeigen. Die chinesischen Schriftzeichen wurden für den Druck aus diesem Buch kopiert, bei der Wiedergabe der Lesung "Ginkyō" in lateinischer Schrift jedoch unterlief Kaempfer ein Schreibfehler. Gewöhnlich notierte er die heute als „kyo“ transliterierte Silbe in der Form „kjo“, doch hier schrieb er aus ungeklärten Gründen in völlig atypischer Weise „kgo“. Diese Form wurde 1771 von Carl von Linné bei der Erstveröffentlichung der Gattung übernommen und ist damit unveränderbarer Bestandteil der Nomenklatur. Das von ihm für die Art gewählte Artepitheton "biloba" weist auf die Zweilappigkeit des Blattes hin. Als Trivialname ist seit der Rechtschreibreform neben „Ginkgo“ auch die Schreibweise „Ginko“ zulässig.

Ein Synonym von "Ginkgo biloba" L. ist "Salisburia adiantifolia" Sm. Der englische Botaniker James Edward Smith schlug 1797 den Gattungsnamen "Salisburia" vor und wollte damit den Botaniker Richard A. Salisbury ehren. 1824 kam noch der Name "Salisburia biloba" Hoffmanns hinzu. Der Name konnte sich aber nicht gegen den international anerkannten Namen "Ginkgo biloba" durchsetzen, so dass "Salisburia" ein Synonym blieb. Weitere Synonyme sind: "Pterophyllus ginkgo" K.Koch und "Pterophyllus salisburiensis" (L.) J.Nelson.

In der heutigen japanischen Sprache nennt man den Baum gewöhnlich "Ichō", die Samen "Ginnan", ebenfalls geschrieben. Wegen der chaotischen Verhältnisse bei der Übernahme chinesischer Bezeichnungen vor und während der Edo-Periode notieren botanische Texte in Japan den Namen meist nur phonographisch geschrieben. Hier und dort findet man die Lesung jedoch auch für die Schriftzeichen . Dies ist linguistisch eigentlich falsch, denn "Ichō" stammt von dem alternativen chinesischen Namen "Yājiǎoshù" (), der auf die Form der Blätter anspielt. In chinesischen Texten findet man auch die Bezeichnungen "Báiguǒ" () und „Großvater-Enkel-Baum“ ("Gōngsūnshù", ). Letztere bezieht sich auf die lange Zeit, die verstreicht, bis ein neu gesetzter Baum die ersten Samen trägt. Weitere ins Deutsche übersetzte Namen waren Elefantenohrbaum, Entenfußbaum, Mädchenhaarbaum, Fächerblattbaum (eine Anspielung auf die Blätter), Chinesischer Tempelbaum (wegen der häufigen Pflanzungen in buddhistischen Tempeln) und Beseeltes Ei, Mandelfrucht, Weißnuss, Nuss-Aprikose, was auf das Aussehen oder die Form der Samen zurückgeht.

Der Ginkgo fand ab etwa 1000 n. Chr. in ganz Ostasien als Tempelbaum Verbreitung und gelangte dabei auf die Koreanische Halbinsel sowie nach Japan.

Von Japan aus gelangten die ersten Ginkgo-Pflanzen um 1730 nach Europa und wurden im botanischen Garten der Universität Utrecht in den Niederlanden aufgezogen. 1754 gelangten Exemplare von Utrecht nach Kew Gardens in England. In die Vereinigten Staaten (Philadelphia) wurden die ersten Exemplare 1784 gebracht. Heute stellt der Ginkgo in den meisten gemäßigten Zonen eine wichtige und gute Alternative zu anderen Straßen- und Parkbäumen dar und wird auch sehr gern angepflanzt.

Der möglicherweise älteste Ginkgo-Baum Deutschlands, der Ginkgo in Rödelheim, wurde angeblich um das Jahr 1750 gepflanzt und steht im Frankfurter Stadtteil Rödelheim. Der Schlosspark Harbke (Sachsen-Anhalt) hat in seinem umfangreichen Baumbestand ebenfalls einen der ältesten deutschen Ginkgos, der um das Jahr 1758 gepflanzt worden sei. Im Bergpark Wilhelmshöhe in Kassel befinden sich weitere alte Ginkgos, die angeblich um das Jahr 1780 gepflanzt wurden. Auch in Mannheim und Dresden gibt es sehr alte Ginkgos ohne weitere Jahresdaten. Im Botanischen Garten Jena wächst am Fürstengraben neben dem Alten Inspektorenhaus ein angeblich Ende des 18. Jahrhunderts angepflanzter Ginkgo, dessen Pflanzung angeblich auf Johann Wolfgang von Goethe zurückgeht. Innerhalb des Gartens steht am sogenannten „Mittelberg“ neben einem männlichen Ginkgo ein weibliches Exemplar. In Leipzig steht ein ohne weitere Jahresdaten von Willmar Schwabe gepflanzter weiblicher Baum. In Weimar befindet sich in der Puschkinstrasse hinter dem Fürstenhaus Weimar der „Goethe-Ginkgo“, den Goethe um das Jahr 1815 vom Hofgärtner Sckell pflanzen ließ.
Aufgrund seiner Resistenz gegen Schädlingsbefall und seiner Anspruchslosigkeit wird der Ginkgo inzwischen weltweit als Stadtbaum angepflanzt. In Berlin hat langjährige Kultur als Straßenbaum gezeigt, dass er resistent gegen Autoabgase und Streusalz ist, in jungen Jahren allerdings auch empfindlich gegen Frost.

Der unangenehme Geruch der Samen nach Buttersäure führt dazu, dass in Europa vornehmlich männliche Ginkgobäume aus Stecklingen angepflanzt werden, während man in China und Japan – genau umgekehrt – vorwiegend weibliche Bäume (siehe Nutzung als Nahrungsmittel) als Allee- und Straßenbäume pflanzt und dabei, um eine Befruchtung zu erleichtern, männliche und weibliche Bäume nebeneinander setzt.

Die Vermehrung des Ginkgo erfordert von einem Gärtner viel Geduld: Ginkgosamen keimen zwar ohne Probleme selbst auf einer Fensterbank, bis zu ihrer Keimung aber können mehr als zwei Jahre vergehen, und auch nur etwa 30 Prozent aller Stecklinge gehen, nach ebenfalls sehr langer Zeit, an, wobei sie außerdem meist schwachwüchsiger sind als Sämlingspflanzen. Hinzu kommt, dass der Ginkgo empfindlich auf Verpflanzungen reagiert.

Für die Aussaat bestimmte Samen sammelt man im Spätherbst unter weiblichen Bäumen, die, um die Befruchtung der Samen zu gewährleisten, in weniger als 100 Metern Entfernung von einem männlichen Baum stehen. Anschließend muss zunächst die äußere, fleischige Samenhülle (Sarkotesta) sorgfältig entfernt werden, wobei der Saft der Sarkotesta zu Hautreizungen und Allergien führen kann. Die so gereinigten Samen werden anschließend gegebenenfalls noch einmal durch Stratifikation für die darauffolgende Aussaat vorbereitet.

Damit der Ginkgo den Anforderungen als Samenlieferant, der Verwendung in der Medizin und den immer stärker steigenden Anforderungen als Straßen- und Zierbaum gerecht werden kann, werden immer mehr Zuchtsorten (Cultivare) selektiert. In China selektierte man allein 28 Sorten wegen ihrer überlegenen Samengröße, Samenform sowie des überlegenen Samenertrags. Eine weit verbreitete Vermehrungsart der Zuchtsorten stellt die Pfropfung dar, bei der die Pflanzen bereits mit fünf Jahren Samen tragen (Fruktifizieren). Ein häufig verwendeter Cultivar ist ‚Dafushon‘, der bereits mit 15 Jahren Jahreserträge von 5 bis 10 kg und mit 50 Jahren zwischen 50 und 100 kg erzielt. Ein weiterer oft genutzter Cultivar ist ‚King of Dongling‘ mit einem Tausendkorngewicht von etwa 2800 g.

Nach den fast nur in Asien angebauten Frucht-Cultivaren werden seit 1980 in den USA und Frankreich im großen Umfang Cultivare zur reinen Blätter-Gewinnung angebaut. Verwendet werden dabei Inhaltsstoffe wie Ginkgolide und Bilobalide, die aus den Blättern gewonnen werden und in der Humanmedizin Verwendung finden (siehe Medizinische Nutzung). Die entsprechenden Bäume werden direkt nach dem Ernten der Blätter kurz über dem Boden zurückgeschnitten, um eine Höhe von über drei Metern zu vermeiden. Im Normalfall erreichen die Bäume dann bis zum nächsten Jahr wieder eine Höhe von einem Meter, die so von Jahr zu Jahr konstant gehalten werden kann.

Da der Bedarf an Ginkgoholz relativ gering ist und nur selten Ginkgos zur reinen Holzgewinnung angebaut werden, wurden noch keine Cultivare zur reinen Holzgewinnung selektiert.

Neben der Selektierung von neuen Ginkgo-Sorten für medizinische Zwecke und zur reinen Samen-Gewinnung wurden die meisten Cultivare für die Nutzung als Zier- und Straßenbaum selektiert.

In Asien wurden mehrere Zuchtreihen des Ginkgobaumes mit verschiedenen Qualitäten als Nahrungspflanze gezüchtet. Genutzt wird der Kern des Samens, dieser muss jedoch gegart werden. In Japan dienen die geschälten (daher von Sarkotesta und Sklerotesta befreiten) Ginkgosamen (in kleinen Mengen) als Beilage zu verschiedenen Gerichten. Sie werden teilweise im Reis mitgekocht, als Einlage in einem Eierstich-Gericht verwendet oder geröstet und gesalzen als Knabberei verzehrt. Dazu werden die Samen von ihrer harten Schale befreit, nur der gelbe Innenkern wird verwendet. In Europa sind Ginkgosamen meist nur als Konserven erhältlich. Geröstete und gehackte Kerne dienen als Gewürz in der asiatischen Küche. Die Samen enthalten 37,8 % Kohlenhydrate, 4,3 % Proteine und 1,7 % Fett. Ein Übermaß an Ginkgosamen kann zu Vergiftungserscheinungen führen, da diese den Vitamin-B6-Antagonisten 4-Methoxypyridoxin enthalten. Im 11. Jahrhundert n. Chr. sollen diese „Nüsse“ so geschätzt worden sein, dass der Kaiser von China die Samen als Tributzahlung von den südöstlichen Provinzen forderte.

Verwendung finden Spezialextrakte aus den Ginkgoblättern. Diese sind an den erwünschten Wirkstoffen (Ginkgolide, Terpenlactone) angereichert, an den unerwünschten Stoffen (besonders Ginkgolsäure) abgereichert. Die Kommission E kennzeichnet den Trockenextrakt aus Ginkgoblättern mit einem Droge-Extrakt-Verhältnis von 35:1 bis 67:1; einem Gehalt von 22 bis 27 % Flavonglykosiden und 5 bis 7 % Terpenlactonen; und unter 5 ppm Ginkgolsäure. Die Definition von Ginkgotrockenextrakt "(Ginkgo extractum siccum raffinatum et quantificatum)" nach dem Europäischen Arzneibuch ist sehr ähnlich. Für die Behandlung von Demenz sind in Deutschland nur derartige Extrakte verkehrsfähig. Die meisten pharmakologischen Untersuchungen wurden mit den Extrakten EGb 761 und LI 1370 durchgeführt. Bei Ginkgo-basierten Nahrungsergänzungsmitteln, etwa aus Supermärkten oder aus Drogerien, ist die gewünschte Wirksamkeit unklar, da deren Qualität oft fragwürdig ist und wissenschaftliche Studien fehlen.

Ginkgospezialextrakte werden nach der ATC-Klassifikation der WHO zu den Antidementiva gezählt. Nach der Kommission E und der European Scientific Cooperative on Phytotherapy (ESCOP) werden Ginkgospezialextrakte bei folgenden Indikationen angewendet:

Der Schwerpunkt liegt heute bei der Behandlung der Demenz. Ginkgo-Arzneimittel können ähnlich wie Acetylcholinesterase-Hemmer beziehungsweise Cholinesterasehemmer, die eine Zunahme der Konzentration von Acetylcholin bewirken, für einen gewissen Zeitraum kognitive Parameter verbessern, also die geistige Leistungsfähigkeit steigern und das Zurechtkommen im Alltag erleichtern, wodurch auch die Belastung der Angehörigen reduziert wird. CHE-Hemmer sind von der Arzneimittelkommission der deutschen Ärzteschaft als Mittel erster Wahl definiert. In der aktuellsten internationalen Leitlinie der "World Federation of Societas of Biological Diseases" werden Ginkgo-Arzneimittel als gleichwertig effektiv zu CHE-Hemmern und Memantin und verträglicher beurteilt. Laut einer 2014 publizierten französischen Studie scheinen auch Patienten, welche an der Alzheimer-Krankheit leiden, von der parallelen Einnahme von Ginkgo-Arzneimitteln neben den klassischen Cholinesterase-Hemmern zu profitieren. Insgesamt gilt die medikamentöse Therapie von Demenz-Kranken heute noch als "sehr bescheiden".

Eine weitere Indikation sind leichte kognitive Beeinträchtigungen (MCI, "mild cognitive impairment"), die überwiegend auf normalen Alterungsprozessen beruhen und bei einem Teil der Patienten (10 bis 20 Prozent) zu einer Demenz voranschreiten.

Insgesamt gibt es über 40 klinische Studien zu Ginkgopräparaten (u. a. die verschreibungspflichtigen "Rezirkane", "Symfona", "Tebokan" und das apothekenpflichtige "Tebonin"), wobei nur wenige die strengen Richtlinien für hochwertige klinische Prüfungen erfüllen. Einige dieser Studien fanden signifikante Vorteile der Ginkgo-Therapie, andere keinen. Eine Metaanalyse von 2010 etwa ergab, dass ein Ginkgo-Arzneimittel zwar wirksamer sei als ein Schein-Medikament, der Effekt jedoch wie bei allen anderen Demenz-Präparaten moderat ausfalle und die klinische Bedeutung dieses Effektes wie generell bei Antidementiva schwer zu bestimmen sei.

Das Institut für Qualität und Wirtschaftlichkeit im Gesundheitswesen untersuchte 2008 im Rahmen einer Arzneimittelbewertung Studien und Unterlagen zum Präparat EGb 761. Auf Grundlage der sieben bewerteten Studien kam es zu dem Schluss, dass es bei der Behandlung der Alzheimer-Krankheit einen "Beleg" für einen Nutzen beim Therapieziel „Aktivitäten des täglichen Lebens“ gebe, sofern 240 mg Extrakt täglich eingenommen werden. Für die Therapieziele „kognitive Fähigkeiten“ und „allgemeine psychopathologische Symptome“ sowie für das angehörigenrelevante Therapieziel „Lebensqualität der (betreuenden) Angehörigen“ (gemessen am emotionalen Stress der Angehörigen) gebe es bei derselben Dosierung dagegen nur einen "Hinweis" auf einen Nutzen. Die Neutralität der untersuchten Studien ist jedoch umstritten.

Die S3-Leitlinie "Chronischer Tinnitus" der Arbeitsgemeinschaft der Wissenschaftlichen Medizinischen Fachgesellschaften von 2015 kommt zu dem Schluss, dass es keine Evidenz für die Wirksamkeit von Ginkgo-Präparaten bei Tinnitus gibt, und spricht deswegen keine Empfehlung aus.

Ginkgospezialextrakte haben folgende Hauptwirkungen:

Neue Arbeiten untersuchen vorwiegend die Wirkung von Ginkgoextrakten auf das Zentralnervensystem. Ältere Arbeiten untersuchten eher die durchblutungsfördernde Wirkung.

Die Ginkgoextrakte haben zum einen Radikalfängereigenschaften, diese Wirkung gegen reaktive Sauerstoffspezies wird vor allem durch die Flavonoide vermittelt; zum anderen hemmen sie den plättchenaktivierenden Faktor (PAF) im Blut, der eine Rolle etwa bei Entzündungen spielt. Mit diesen zwei Mechanismen können jedoch viele der beobachteten Wirkungen nicht erklärt werden. Zudem besitzt die Reinsubstanz mit der stärksten neuroprotektiven Wirkung, das Bilobalid, keine dieser beiden Eigenschaften.

Eine wesentliche Rolle dürften daher auch die Effekte der Inhaltsstoffe auf die Genexpression haben. Der Extrakt EGb 761 verändert die Expression von mindestens 155 Genen in Microarray-Studien. Darunter befinden sich Transkriptionsfaktoren, Gene für antioxidative Enzyme, Mitochondrienproteine und Proteine der DNA-Synthese und -Reparatur. Als weiterer Mechanismus wird ein Einfluss der Terpenlactone auf verschiedene Rezeptoren diskutiert.

Die Interaktion von Ginkgoextrakten mit dem plättchenaktivierenden Faktor (PAF) wird mit einer Reihe von Effekten auf Erkrankungen des Herz-Kreislaufsystems, der Nieren und des zentralen Nervensystems in Verbindung gebracht. Der Inhaltsstoff Ginkgolid B scheint am stärksten für diese Wirkung verantwortlich zu sein.

In Versuchen zeichnen sich Extrakte aus Ginko biloba durch östrogene als auch anti-östrogene Wirkung über eine Interaktion mit dem Östrogenrezeptor aus.

An unerwünschten Wirkungen werden als sehr selten auftretend Magen-Darm-Beschwerden, Kopfschmerzen und allergische Hautreaktionen beschrieben. Einzelne Blutungen bei Langzeitbehandlungen konnten nicht in ursächlichen Zusammenhang mit Ginkgoextrakten gebracht werden. Ginkgo-Extrakt selbst hat keinen Einfluss auf die Blutgerinnung.

Allerdings besteht laut Arzneimittelkommission der Deutschen Ärzteschaft, ausgehend von mehreren Fallberichten ihrer Datenbank, bei Kombination mit Gerinnungshemmern (wie orale Antikoagulanzien oder Thrombozytenfunktionshemmer) eine erhöhte Blutungsgefahr, ebenso bei einer vererbten oder erworbenen Gerinnungsstörung. Die einzelnen Berichte über Blutungen belegen jedoch nicht zweifelsfrei, dass es hier einen kausalen Zusammenhang gab, da meist andere, gerinnungshemmende Medikamente eingenommen wurden.

In vielen Ginkgo-haltigen Arzneimitteln und Tees ist in nennbaren Mengen der Störstoff Ginkgolsäure enthalten. Da die Konzentration von Ginkgolsäure in Teeprodukten im Gegensatz zu Arzneimitteln bisher keiner Kontrolle unterliegt, werden Ginkgo-haltige Tees als potentiell gesundheitsgefährdend diskutiert. Ginkgolsäure kann schwere Allergien und Magenschleimhautentzündungen hervorrufen. Auch cytotoxische, neurotoxische und mutagene Wirkungen wurden nachgewiesen.

In einer Studie des National Toxicology Programs der National Institutes of Health wurde 2013 im Tierversuch eine erhöhte Rate an Leber- und Schilddrüsenkrebs beobachtet, wobei diese Versuche mit sehr hohen Dosen von bis zu 2000 mg/kg Körpergewicht durchgeführt wurden, die beim Menschen gewöhnlich bei weitem nicht erreicht werden.

Im Gegensatz zur wissenschaftlich-pharmakologischen Nutzung werden in der Traditionellen Chinesischen Medizin nicht nur die Blätter, sondern auch die Samen und Wurzeln des Baumes genutzt.

Die Samen werden bei Husten, Blaseninfektionen, Asthma, Tuberkulose, Alkoholvergiftungen, Blähungen, Gonorrhöe sowie bei häufigem und schmerzhaften Wasserlassen angewendet.

Eingenommen wird hierbei eine Abkochung der von Sarkotesta und Sklerotesta befreiten Ginkgosamen, die nach dem Kochen ohne Samen eingenommen wird.
Gegen starke asthmoide Atemnot, Schleimbildung und Husten können die Samen in gerösteter oder gekochter Form auch pur angewendet werden, wobei bei regelmäßiger Einnahme aufgrund von geringen Anteilen des Vitamin-B6-Antagonisten 4-Methoxypyridoxin 6–10 g/Tag nicht überschritten werden sollten.

Die Wurzeln werden bei nächtlichen Samenergüssen und Menstruationsstörungen angewendet.
Sie helfen bei Blähungen und stärken den Magen, wirken anregend und zusammenziehend.

Eingenommen wird hierbei eine Abkochung, die nach dem Kochen ohne Wurzeln vor dem Essen eingenommen wird. Eine Überdosierung der Wurzel wie bei den Samen ist nicht möglich.

Die Ginkgogewächse gehören weder zu den Nadel- noch zu den Laubbäumen, sondern bilden eine eigene Gruppe. Obwohl der Ginkgo auf den ersten Blick Ähnlichkeit mit Laubbäumen (Bedecktsamer) hat, ist er mit den Nadelbäumen näher verwandt und wird deshalb wie sie zu den Nacktsamern gezählt. Der Ginkgo wird in eine eigene Klasse eingeordnet, in die Klasse Ginkgoopsida (oder Ginkgophyta). Von der Klasse Coniferopsida unterscheidet er sich durch die abweichenden Strukturen der generativen Organe, insbesondere der begeißelten Spermatozoiden. Von der Klasse der Palmfarne (Cycadopsida) unterscheiden sie sich vor allem durch die Anatomie der vegetativen Organe. Die Ginkgoopsida enthalten wiederum eine einzige Ordnung, die Ginkgoartigen (Ginkgoales), deren einzige Familie die Ginkgogewächse (Ginkgoaceae) mit nur einer lebenden Gattung der Ginkgo sind.

Zum Bekanntheitsgrad und zur Verbreitung des Ginkgos in Deutschland hat das Gedicht mit dem Titel Gingo biloba wesentlich beigetragen, das der 66 Jahre alte Goethe im September 1815 schrieb und 1819 in seiner Sammlung "West-östlicher Diwan" veröffentlichte. Das Gedicht ist Goethes später Liebe, Marianne von Willemer, gewidmet und stellt das Ginkgoblatt aufgrund seiner Form als Sinnbild der Freundschaft dar. Der Brief mit dem Gedicht, dem Goethe zwei Ginkgo-Blätter beilegte, ist heute im Goethe-Museum Düsseldorf zu sehen, in dessen unmittelbarer Umgebung zahlreiche Ginkgobäume stehen.

Der Grund für die bis heute große Bedeutung des Ginkgo für Kunst, Kultur und Heilkunde liegt vor allem in der Chinesischen Philosophie und der ansprechenden Morphologie des Baumes und seiner Blätter.
Der Ginkgo wird seit langem als kraftspendend und lebensverlängernd verehrt. Die Chinesen und Japaner verehren den Ginkgo seit Jahrhunderten wegen seiner Lebenskraft und Wunderverheißungen als heilig und erbeten unter ihm ihre Wünsche. Frauen erbitten unter ihm Milch zum Stillen ihrer Kinder und Bauern erflehen Regen für eine reichhaltige Ernte, Ginkgos sind auf diese und andere Art und Weise in Mythen, Volkserzählungen und Geschichten wieder zu finden. Der Ginkgo steht in Japan unter Naturschutz. So mancher Baumriese überragt ganze Ortschaften und gilt als Wahrzeichen für seine Anwohner. Aus dem 18. Jahrhundert gibt es in dem Kloster Tanzhe-si eine weit verbreitete Legende. Demzufolge gab es dort ein Ehrentor, das zu einem Ginkgobaum führte. Dieser Baum wurde durch ein kaiserliches Etikett geschützt. Der dortige Glaube der Chinesen besagte, dass bei jedem Thronwechsel innerhalb der Mandschu-Dynastie der Hauptstamm ein neues Reis in den Baum einsetzte, das sich dann zu einem prächtigen Ast entwickeln sollte. Bäume mit einem Alter von 1000 bis 2000 Jahren sind keine Seltenheit. Man findet sie in Tempeln in der Nachbarschaft auf Anhöhen und auch in Friedhöfen neben Gräbern. In Japan werden die geschälten (von Sarkotesta und Sklerotesta befreiten) Ginkgosamen beim Hochzeitsmahl als Glückssymbol verzehrt. Ein 3000 Jahre alter und 26 Meter hoher Ginkgo in der Provinz Shandong hat bei günstiger Witterung Samen von insgesamt einer Tonne geliefert. In vielen Geschichten und Erzählungen wird der Baum als Wohnort von Geistern beschrieben und deshalb hoch geschätzt und gleichermaßen gefürchtet.

Zudem wurde das in der Pflanzenwelt einzigartige zweigeteilte Blatt und seine Zweihäusigkeit schon früh eng mit dem Symbol des Yin-Yang in Verbindung gebracht. Zur modernen Mythenbildung hat auch wesentlich die Geschichte des Tempelbaumes in Hiroshima beigetragen, der bei der Atombombenexplosion 1945 in Flammen aufging, aber im selben Jahr wieder austrieb und weiterlebte.

Das Ginkgo-Blatt ist das Logo der Universität Tokio und der südkoreanischen Sungkyunkwan-Universität.





</doc>
<doc id="2033" url="https://de.wikipedia.org/wiki?curid=2033" title="Glucagon">
Glucagon

Glucagon (auch "Glukagon") ist ein Peptidhormon, dessen Hauptwirkung die Erhöhung des Blutzuckerspiegels durch Anregung der Bildung von energiereicher Glucose aus Glykogen in der Leber ist. Es wird aus den Präkursoren Präglucagon und Präproglucagon in den Langerhans-Inseln der Bauchspeicheldrüse (α-Inselzellen) gebildet. Bei Blutzuckerabfall, aber auch nach einer proteinreichen Mahlzeit wird Glucagon von der Bauchspeicheldrüse in die Blutbahn abgegeben und dort frei transportiert. Dieses Hormon ist in seiner Wirkung auf den Glucose-, Protein- und Fettsäurestoffwechsel ein Gegenspieler des Insulins. Glucagon wird von der Leber aufgenommen und durch Spaltung inaktiviert.

Die Existenz des Pankreashormons Glucagon als hyperglykämischem Faktor wurde 1923 zum ersten Mal von John Raymund Murlin postuliert. Doch erst im Jahre 1953 konnte Anne-Marie Staub die Reinsubstanz gewinnen und isolieren. Die unten aufgezeichnete Sequenzierung erschloss 1956 William Wallis Bromer. Positive Effekte auf die Herzleistung wurden 1960 von Ronald Ralph Tuttle und Alfed Emil Farah erforscht sowie belegt. In der Vergangenheit wurde das Glucagon v. a. bei einem kardiogenen Schock angewendet.

Die Primärstruktur des humanen Glucagons besteht aus 29 Aminosäuren mit einer Molekülmasse von 3483 Da. Die Primärstruktur lautet: His-Ser-Gln-Gly-Thr-Phe-Thr-Ser-Asp-Tyr-Ser-Lys-Tyr-Leu-Asp-Ser-Arg-Arg-Ala-Gln-Asp-Phe-Val-Gln-Trp-Leu-Met-Asn-Thr.

Bei normaler Ernährung bleibt die Sekretion von Glucagon im Vergleich zu der von Insulin relativ konstant. Die Stimuli für eine erhöhte Ausschüttung sind hauptsächlich Hypoglykämie (zu niedriger Blutzuckerspiegel), proteinreiche Mahlzeiten, Infusion von Aminosäuren (z. B. Arginin, Alanin), länger dauernde starke körperliche Arbeit und Stress.
Bei Hypoglykämie kann die Glucagonsekretion auf das bis zu Vierfache gesteigert werden.
Stimulation erfolgt durch β-Adrenorezeptoren.
Seine Freisetzung wird von Insulin, Somatostatin und GLP-1 gehemmt.

Glucagon ist der Gegenspieler zu Insulin. Während Insulin die Glykogensynthese fördert, resultiert die Freisetzung von Glucagon in einem Abbau von Glykogen. Die Wirkung von Glucagon beruht auf der Bindung an einen G-Protein-gekoppelten Rezeptor. Das dadurch aktivierte G-Protein stimuliert die Adenylatcyclase (). Durch cAMP werden die Enzyme für den Glucose- und Fettstoffwechsel aktiviert. Als vorrangiger Effekt wird die Glykogenphosphorylase () phosphoryliert, die den Glykogenabbau stimuliert und die Glykogensynthese hemmt.

Glucagon stimuliert nicht nur die Glykogenolyse, sondern auch die Neusynthese von Glucose (Gluconeogenese) aus Aminosäuren. Glucagon hat also eine proteinkatabole Wirkung, was zum Anstieg von Harnstoff im Blut führt. Außerdem werden über cAMP fettverdauende Enzyme (Lipasen) aktiviert, woraus eine Erhöhung der Fettsäuren im Blut resultiert.

Glucagon wird zur Ruhigstellung des Darmes eingesetzt und wird in dieser Funktion auch als intravenös zu verabreichendes Medikament verwendet. Als Gegenmittel bei Vergiftungen mit Betablockern und Calciumkanalblockern wird der Wirkstoff ebenfalls angewendet. Es wird auch beim Magenröntgen verwendet, um die Schleimhaut besser beurteilen zu können.

Am Herzen bewirkt Glucagon neben einer Herzfrequenzsteigerung auch eine kurzfristige Zunahme der Kontraktionskraft des Herzmuskels.

Außerdem besitzen viele insulinpflichtige Diabetiker ein Notfall-Set mit Glucagon und einem Lösungsmittel, das bei einer schweren Hypoglykämie mit Bewusstlosigkeit nach Auflösung der Pulversubstanz von einem eingewiesenen Helfer subkutan oder intramuskulär gespritzt wird und über den oben beschriebenen Wirkungsmechanismus eine Erhöhung des Blutzuckerspiegels erreichen soll. Glucagon wird vom Hersteller Novo Nordisk unter dem Handelsnamen GlucaGen vertrieben.

Für eine im Jahr 2010 durchgeführte Studie wurde eine Insulinpumpe entwickelt, die neben der Insulinampulle eine Glucagonampulle beinhaltete. Durch eine beständige Glucose-Messung in einem Closed-Loop-System (Blutglukosemessung und Dosisabgabe erfolgen automatisch) wurde bei Unterzuckerungsgefahr Glucagon über die Pumpe abgegeben. Dadurch traten weniger und kürzer andauernde Hypoglykämien auf.

Es gibt einen Glucagontest, der im medizinischen Alltag allerdings nur selten verwendet wird. Er dient der Prüfung der Stimulierbarkeit der β-Zellen des Pankreas (Funktionsreserve) zur Unterscheidung von Diabetes Typ I und Typ II.






</doc>
<doc id="2035" url="https://de.wikipedia.org/wiki?curid=2035" title="Grafikkarte">
Grafikkarte

Eine Grafikkarte steuert in einem Computer die Grafikausgabe. Bei Ausführung eines Programms berechnet der Prozessor die Daten, leitet diese an die Grafikkarte weiter und die Grafikkarte wandelt die Daten so um, dass der Monitor oder Projektor ("Beamer") alles als Bild wiedergeben kann. Grafikkarten werden entweder als PC-Erweiterungskarten (über die Bussysteme PCI, AGP oder PCI Express, früher auch ISA oder VLB) mit der Hauptplatine verbunden oder sind im Chipsatz auf der Hauptplatine enthalten. Mittlerweile ist die Integration so weit vorangeschritten, dass bereits in Hauptprozessoren Bestandteile für die Grafikausgabe vorhanden sind (bei Intel seit Core iX-Generation, bei AMD im Fusion-Programm).

Die wichtigsten Komponenten moderner Grafikkarten sind: GPU, Video-RAM, RAMDAC sowie die Anschlüsse für externe Geräte (z. B. für den Monitor oder Grafiktablett).

Das Grafikkarten-Prinzip wurde in Serienproduktion erstmals beim Mikrocomputer Apple II verwendet, dessen auf der Hauptplatine integrierte Grafikfähigkeiten durch zusätzlich zu erwerbende Steckkarten verbessert werden konnten. („PAL-Farbkarte“, „80-Zeichen-Karte“).
Dieser kam 1977 auf den Markt.

Der erste IBM-PC kam 1981 mit einer Karte auf den Markt, die lediglich die einfarbige Darstellung von Text ermöglichte (MDA = Monochrome Display Adapter). Die Firma Hercules bot 1982 eine sehr viel bessere Karte an, die Hercules Graphics Card.

Bis 1989 setzten sich die Farb-Grafikkartentypen als Standard durch, die IBM neu auf den Markt brachte:

Auch heute noch ist der VGA-Modus (640 × 480 Punkte in 16 Farben) der „Notfall-Modus“ bei allen PCs; nur bis zu diesem Modus kann die Hardware aller heutigen PC-Grafikkarten von der Software auf einheitliche Weise angesprochen werden.

VGA war allerdings nicht der letzte Grafikkartenstandard. Die Video Electronics Standards Association (VESA) stellte einen Standard für Videomodi bis zu einer Auflösung von 1280 × 1024 Punkten in 16 Bit Farbtiefe auf, die heute jede PC-Grafikkarte beherrscht.

Die weiteren Bezeichnungen SVGA, XGA usw. sind keine Grafikkartenstandards mehr, sondern Kurzbezeichnungen für Bildschirmauflösungen, zum Beispiel XGA mit 1024 × 768 Punkten.

Bis etwa 1990 beschränkten sich die Grafikkarten darauf, den Inhalt des Video-RAM über einen sogenannten RAMDAC-Baustein in Ausgangssignale für den Monitor umzuwandeln. Der Programmierer konnte im Wesentlichen nur den Textmodus nutzen sowie im Grafikmodus einzelne Pixel auf eine bestimmte Farbe setzen. Das war die erste Generation der Grafikkarten. Es folgten zwei weitere:

Ab 1991 wurden die Grafikkarten zu eigenständigen kleinen Recheneinheiten mit eigener GPU (Graphics Processing Unit) weiterentwickelt, einer sogenannten "Graphics-" oder "Pixel Engine" oder dt. Grafikprozessor, bei dem man nicht nur einzelne Pixel setzen konnte, sondern dem man Befehle zum Zeichnen von Linien und Füllen von Flächen schicken konnte (Windows-Beschleuniger). Diese Funktionen beschleunigten vor allem das Verschieben der Fenster (Windows) der grafischen Benutzeroberfläche. Das Konzept der Zusatzfunktionalität wurde mit der Zeit immer weitergeführt, so wurden z. B. seit 1995 auch Funktionen zur Beschleunigung der Videowiedergabe (z. B. im AVI-Format) und Dekodierung von komprimierten Videodaten (z. B. MPEG) eingeführt ("Videobeschleunigung"). Diese Funktionen wurden vorher auf separaten Steckkarten angeboten.

Nachdem Mitte der 1990er Jahre mit Doom der große Boom der 3D-Spiele begonnen hatte, kam bald von 3dfx der erste brauchbare 3D-Beschleuniger, der Voodoo Graphics-Chipsatz. Einem 3D-Beschleuniger kann ein Programm in einem dreidimensionalen Raum die geometrischen Figuren in Form von Polygonen und die Texturen angeben, mit denen die Flächen der Polygone gefüllt werden sollen (Rendern). Diese recht simple, aber rechenintensive Aufgabe hatte in den frühen 3D-Spielen noch die CPU übernehmen müssen; nun konnte sie an die Grafikkarte delegiert werden, was zu einer massiven Leistungssteigerung von 3D-Spielen führte (bessere Bildauflösung, wesentlich realistischere Bilder).

Waren die 3D-Beschleuniger der ersten Generation noch auf eigenen Steckkarten verbaut, durch die das Grafiksignal der im System verbauten 2D-Grafikkarte durchgeschleift wurde, setzten sich bald Lösungen durch, die 2D- und 3D-Funktionalität auf derselben Karte vereinten.

Um noch mehr 3D-Leistung anzubieten, werden heute mit der Multi-GPU-Technik (siehe auch SLI und AMD CrossFireX) zwei oder mehr 3D-Grafikkarten bzw. -prozessoren parallel geschaltet, um noch mehr Grafikelemente je Zeitspanne berechnen zu können. Da diese Technik aber recht hohe Kosten und einen erhöhten Energiebedarf mit sich bringt, hat sie bisher nur geringen Einfluss auf den Grafikkartenmarkt.

Die bekanntesten Hardwareschnittstellen für Grafikkarten sind PCI, AGP und PCI Express, früher waren auch ISA oder VESA Local Bus gängig. Diese Schnittstellen sind entweder Bussysteme oder Direktverbindungen (AGP, PCI Express), die den Buscontroller mit der Grafikkarte verbinden. Da die Spezifikation der Schnittstellen zumeist durch Interessenverbände vorgenommen wird, in denen sowohl die Controller- als auch die Grafikkarten- bzw. Grafikchiphersteller Mitglied sind, funktionieren (im Idealfall) alle konformen Grafikkarten mit allen konformen Controllern. Es gab in der Vergangenheit aber verschiedene Probleme mit einigen Schnittstellen, die die Interoperabilität einschränkten, beispielsweise „AGP Fast Writes“ bei AGP (auf Intel-Plattformen konnte es die Leistung erhöhen, auf AMD-Plattformen für Instabilität sorgen) oder IRQ-Probleme bei PCI (mögliche Abstürze, Einfrieren oder Leistungseinbrüche, Ursache meist schlechte oder fehlerhafte Implementierung der Schnittstelle).

Bei anderen Plattformen als den IBM-kompatiblen Rechnern gab es entsprechend den dort üblichen Stecksystemen Grafikkarten für die Apple-II-Steckplätze, später bei den ersten Macs für nuBus (später PCI und Nachfolger wie bei PC), für Amigas für deren Zorro-Bus und auch Europakarten für Systeme, die auf letzteren aufbauen.

Der Grafikspeicher dient zur Ablage der im Grafikprozessor (GPU) verarbeiteten Daten sowie als Bildspeicher („Framebuffer“): Das sind digitale Bilder, die später auf dem Computer-Bildschirm oder mit dem Projektor ausgegeben werden.

Die Größe des Grafikspeichers bestimmte die maximale Farbtiefe und Bildauflösung. Dabei ließ sich der benötigte Speicher für eine gewünschte Auflösung und Farbtiefe vom Anwender leicht errechnen: Wenn beispielsweise die Auflösung 1600 × 1200 mit einer Farbtiefe von 24 Bit (True Color) erwünscht ist, berechnet man zunächst die Anzahl der Bildpunkte (Pixel) dieser Auflösung (1600 horizontal × 1200 vertikal = 1.920.000 Pixel insgesamt). Die Farbtiefe „24 Bit“ bedeutet, dass für jedes dieser Pixel 24 Bit Farb-Informationen vorliegen. Somit multipliziert man die Pixelanzahl mit der Farbtiefe (1.920.000 × 24 Bit = 46.080.000 Bit). Nunmehr ist nur noch die Umrechnung in Byte erforderlich. Da ein Byte aus 8 Bit besteht, wird die Zahl durch 8 geteilt (46.080.000 Bit / 8 = 5.760.000 Byte). Da früher Grafikkarten in der Regel mit 4 oder 8 Megabyte Grafikspeicher ausgeliefert wurden, hätte man für die gewünschte Einstellung eine Grafikkarte mit mindestens 8 Megabyte Grafikspeicher benötigt.

Heute werden ausschließlich Grafikkarten mit sehr viel mehr Speicher gebaut als zur reinen Bildspeicherung notwendig wäre. Beim Rendern dreidimensionaler Grafiken werden hier zusätzlich zum Framebuffer die Daten der Objekte, beispielsweise Größe, Form und Position, sowie die Texturen, die auf die Oberfläche der Objekte gelegt werden, gespeichert. Besonders die immer höher auflösenden Texturen haben für einen starken Anstieg der Speichergröße bei aktuellen Grafikkarten gesorgt. So liegt die Speichergröße aktueller Grafikkarten bereits im drei- bis fünfstelligen Megabytebereich (512 MB, 1024 MB, 2048 MB, 3072 MB, 4096 MB, 6144 MB, 8192 MB, 12288 MB), 512 MB und weniger sind selten geworden. Bei Spielegrafikkarten ist die Obergrenze Anfang 2016 bei 12 GB, wohingegen professionelle Grafikkarten schon mit bis zu 24 GB Grafikspeicher ausgestattet werden können.

Bei Onboard-Lösungen wird meist der Hauptspeicher des Systems als Grafikspeicher genutzt, das wird als Shared Memory bezeichnet. Der Zugriff erfolgt über das jeweilige Bussystem und ist deshalb langsamer als direkt angebundener Speicher.

Der Grafikprozessor dient zur Berechnung der Bildschirmausgabe. Mitte der 1990er Jahre kamen die ersten 3D-Beschleuniger auf den Markt. Diese Grafikprozessoren waren in der Lage, einige Effekte und dreiecksbasierte Algorithmen (wie u. a. Z-Puffern, Texture Mapping) und Antialiasing selbstständig durchzuführen. Besonders dem Bereich Computerspiele verhalfen solche, zusätzlich zu installierenden Steckkarten (z. B. 3dfx Voodoo Graphics), zu einem Entwicklungsschub.

Heute sind GPUs wegen ihrer Spezialisierung auf Grafikberechnungen den CPUs in ihrer Rechenleistung überlegen.
Als Vergleich dienen die Transistoranzahl des Grafikprozessors von Nvidia (Geforce 8800GTS 512, 754 Millionen) mit der eines Modells von Intel (Core 2 Extreme QX9650, 820 Millionen). Der Unterschied wird deutlich, wenn man bedenkt, dass über die Hälfte der CPU-Chipfläche für die 2×6 MB Cache verbraucht werden. Die Entwicklung der Integrationsdichte der Grafikprozessoren hat mit einem jährlichen Faktor von 2,4 sogar das Mooresche Gesetz übertroffen.

Wie bei den Hauptprozessoren der Rechner, in die die Grafikkarten eingebaut werden, sind auch die GPUs auf den Grafikkarten oft Gegenstand von Übertaktungsmodifikationen zur Leistungssteigerung.

Die Rechenkapazität, die auf solchen Grafikkarten zur Verfügung steht (siehe unter GPGPU), hat schon dazu geführt, dass allein zum Erzielen maximaler Rechenleistung mehrere Grafikkarten in einen Rechner eingebaut werden. Solche Systeme werden teilweise in großen Anzahlen zu Supercomputern zusammengestellt.

Aufgrund der hohen thermischen Verlustleistung durch die zunehmende Komplexität von Grafikprozessoren bzw. teilweise auch des Grafikspeichers sind ähnlich aufwendige Kühllösungen wie bei Prozessorkühlern notwendig. Grafikkarten verbrauchen mit einem Grafikprozessor (GeForce GTX 680) bis zu 195 Watt (TDP) Leistung, die vollständig als Wärmeenergie abgeführt werden muss. Dazu existieren mehrere Ansätze:

Besonders die Konstruktionen der Luftkühlungen sind durch die benötigte Oberfläche des Kühlkörpers oft wesentlich größer als es die Spezifikationen des Steckplatzes zulassen (vgl. Abb. rechts). Aus diesem Grund können auf dem Mainboard oft die angrenzenden Steckplätze nicht verwendet werden.

Der RAMDAC (Random Access Memory Digital/Analog Converter) ist ein Chip, der für die Umwandlung von digitalen (Videospeicher) in analoge Bildsignale (Monitor) verantwortlich ist. Von ihm werden die Signalausgänge angesteuert.
Er kann auch im Grafikprozessor integriert sein.



Zusätzliche Signalausgänge und auch -eingänge sind je nach Karte unterschiedlich realisiert. Teilweise sind entsprechende Buchsen (Cinch, S-Video, LFH60) direkt auf dem Slotblech vorhanden. Vor allem aus Platzgründen sehen Hersteller aber auch einen mittelbaren Anschluss über Adapterkabel oder Kabelpeitschen vor. Dann findet sich direkt auf der Grafikkarte eine Buchse, z. B. aus der Mini-DIN-Familie, deren Beschaltung nicht standardisiert ist und die oft die allgemeine Bezeichnung VIVO (für Video-In-Video-Out) hat. Hier wird eine herstellerspezifische Kabelpeitsche angeschlossen, die dann weitere Anschlussmöglichkeiten zur Verfügung stellt.


Grundsätzlich werden vier Typen von Grafiklösungen unterschieden:

Bei diesen Integrated Graphics Processor, kurz IGP genannten Lösungen wird die Funktionalität der Grafikkarte in den Chipsatz der Hauptplatine oder in den Prozessor (z. B. Intel i5) integriert. IGPs bieten alle 2D-Funktionen, aber meistens nur langsame oder veraltete 3D-Funktionalität und werden daher vornehmlich in Bereichen mit geringeren Grafikanforderungen eingesetzt. Mittlerweile sind die Grafiklösungen von AMD und Intel jedoch bereits leistungsfähig genug, um aktuelle Spiele auf zumindest geringen Details zu spielen. Auch bei den unterstützten Features hat sich viel getan. Derzeit unterstützen beide Hersteller DirectX in Version 11 sowie aktuelle Standards wie OpenCL oder OpenGL. Wegen ihres niedrigen Stromverbrauchs werden sie auch häufig in Notebooks eingesetzt. Der niedrige Stromverbrauch ist auch ein Motiv zum Einsatz in Embedded-PCs; bei besonders kritischen Anwendungen wie beispielsweise in der Medizin kommt der Vorteil hinzu, dass die Ausfallquelle der Steckkontakte zwischen Hauptplatine und Grafikkarte entfällt. Bei besonders kompakten oder preiswerten Geräten wird auf einen eigenen Grafikspeicher verzichtet und stattdessen der Hauptspeicher des Rechners mitverwendet (siehe Unified Memory Architecture, Shared Memory), was sich jedoch negativ auf die Leistungsfähigkeit auswirkt.

Anbieter von IGPs:

Neueste Notebooks mit PCIe-Schnittstelle können einen austauschbaren Grafikchip besitzen (siehe Mobile PCI Express Module), was sich jedoch (noch) nicht als Standard durchgesetzt hat.

Das sind vollwertige Grafikkarten, bei denen wenig Augenmerk auf die 3D-Funktionen gelegt wird, sondern die vor allem ein scharfes und kontrastreiches Bild liefern sollen. Es gibt auch Varianten mit 3D-Zusatzfunktionen, vor allem für CAD-Anwendungen.

Diese Grafikkarten gibt es in verschiedenen Preisklassen von rund 25 € bis zu 1100 €, wobei die teuren Karten das technisch Machbare im Bereich 3D-Darstellung widerspiegeln. Bei Spielekarten konkurrieren hauptsächlich AMD (AMD-Radeon-Serie) und Nvidia (Geforce-Reihe) miteinander, deren Chips von einer Vielzahl von Herstellern auf deren Grafikkarten verwendet werden. Daneben gibt es noch Anbieter wie S3 Graphics, Matrox (gehörte zu den Pionieren der 3D-Spielegrafikkarten, wurde aber von der mächtigen Konkurrenz in den professionellen Markt zurückgedrängt) und XGI Technology, die aber nur eine untergeordnete Rolle spielen und meist in Büro-PCs Verwendung finden.

Da die meisten Spiele für Microsofts Direct3D-Schnittstelle (ein Teil der Windows-Systemkomponente DirectX) entwickelt werden, sind Spielegrafikkarten auf Höchstleistung mit diesem System optimiert. Grafikkarten, die volle Hardwareunterstützung für die aktuelle DirectX-Version bieten, können praktisch alle technisch realisierbaren 3D-Rendering-Funktionen in Echtzeit berechnen. Manche Spielehersteller setzen aber auf OpenGL, allen voran id Software.

Seit 2006 befindet sich die Version 10 von DirectX auf dem Markt, die allerdings nur in Verbindung mit den Microsoft-Betriebssystemen Windows Vista und Windows 7 funktioniert. DirectX 10 wird seitens Nvidia von der Nvidia-GeForce-8-Serie und aufwärts unterstützt, seitens AMD von den Karten der ATI-Radeon-HD-2000-Serie und aufwärts. Karten ab der ATI-Radeon-HD-3000-Serie unterstützen sogar bereits die Nachfolgerversion DirectX 10.1, die mit dem Service Pack 1 für Windows Vista ausgeliefert wird und nur geringe Neuerungen bringt (Verwendung in nur wenigen Spielen, etwa dem Luftkampfspiel H.A.W.X. oder ). DirectX 10 erhöht viele Beschränkungen in der Shaderprogrammierung und soll einen geringeren Overhead als DirectX 9 aufweisen, wodurch das Ausführen von Direct3D-Befehlen schneller vonstattengehen soll. Der Nachteil ist, dass seit der Einführung von DirectX 10 nur wenige Spiele für DirectX 10 optimiert werden (prominentestes Beispiel: Crysis), da der kommerzielle Verkauf von Windows Vista erst am 30. Januar 2007 begann und die Nutzung der neuen Effekte von DirectX 10 eine enorme Rechenleistung benötigen und folglich nur auf High-End-Grafikkarten zufriedenstellend funktionieren. Viele neue Spiele unterstützen oftmals immer noch nur DirectX 9 und manchmal parallel DirectX 11, DirectX 10 hat daher nur noch eine geringe Bedeutung.

Seit Ende 2009 gibt es DirectX in Version 11. Diese Version wird bei den Karten von ATI (bzw. AMD) ab der „HD5000“-Reihe und ab der „GTX-400“-Serie von Nvidia unterstützt. Der Start von DirectX 11 lief besser als der von DirectX 10, da es bei Einführung von Windows 7 und damit DirectX 11 bereits ein Spiel mit DirectX 11 gab (BattleForge) und weitere schnell folgten. Die Spiele unterstützen jedoch alle noch DirectX 9, was sie auch auf Windows XP lauffähig macht.

Neben Direct3D gibt es als weiteres Grafik-API OpenGL in der aktuellen Version 4.2, das mit einem etwas größeren Funktionsumfang als Direct3D 11 aufwartet.

Im Jahr 2013 stellte AMD zudem die API AMD Mantle vor, die bislang nur mit AMD-Grafikkarten ab der ATI-Radeon-HD-7000-Serie verwendet werden kann. Mantle bietet sowohl eine bessere Leistungsausnutzung bei Mehrkernprozessoren als auch einen geringeren Entwicklungsaufwand als Direct3D. Die Unterstützung für Mantle beschränkt sich derzeit noch auf wenige Spiele. Die Frostbite-3-Engine (siehe Frostbite-Engine) unterstützt Mantle voll, somit sind Spiele wie Battlefield 4, oder mit Mantle spielbar. In Zukunft ist eine Unterstützung von Nvidia-Grafikkarten und Linux-Betriebssystemen durchaus denkbar, aber noch nicht von AMD angekündigt.

2016 erschien vom OpenGL-Entwickler Khronos Group die API Vulkan, die OpenGL ablösen soll.

Die aktuellen Spitzenmodelle stellen mit Stand 2018 Nvidia mit der "Geforce GTX 1080 Ti" auf Basis des in 16nm gefertigten ""GP102"" Chip der ""Pascal"" Architektur. 
Im Dezember 2017 wurde die ""Titan XP"", der Vollausbau des ""GP102"" mit 12GB VRAM ("1080 Ti" nur 11GB VRAM), durch die ""Titan V"" auf Basis des in 12nm gefertigten ""GV100"" der aktuellen ""Volta"" Architektur ersetzt. Diese zieht eine radikale Änderung des VRAMs mit sich, da Nvidia bei der ""Titan V"" auf 12GB ""HBM2"" setzt und somit nicht mehr ""GDDR5"" oder ""GDDR5X"" nutzt.
Nvidia stellte im Mai 2016 die in 16 nm gefertigten Modelle "Geforce GTX 1080" und "Geforce GTX 1070" mit der „Pascal“-Architektur vor. Die Nutzung der neuen Speichervariante GDDR5X soll den Karten eine höhere Bandbreite verschaffen.

AMD konkurriert dagegen mit der "Radeon R9 Fury X" mit dem Fiji-XT-Chip, die ebenfalls im 28-nm-Fertigungsprozess hergestellt wird. Die Fury X ist dabei mit 4 Gbyte VRAM ausgestattet, allerdings nutzt sie im Gegensatz zum GDDR5-VRAM der Nvidia-Karten sogenannten High Bandwidth Memory, welcher durch das Stapeln der Speicherbausteine und das Anbinden jedes Stapels über zwei 128-Bit-Kanäle über eine deutlich größere Bandbreite angebunden ist als gewöhnlicher GDDR5-Speicher.

Am 29. Juni 2016 hat AMD die Mittelklassen Grafikkarte Radeon RX 480 mit dem Codenamen "Polaris" veröffentlicht. Die GPU hat einen Boosttakt von 1266 MHz und einen Speichertakt von 4000 MHz (effektiv 8000 MHz). Die Radeon RX 480 besitzt einen 8 GB GDDR5 Grafikspeicher. Der direkte Konkurrent der RX 480 ist die GeForce GTX 1060.

In den Spielen mit 4K-Auflösung schnitt die Radeon R9 Fury X in ersten Benchmarks besser als die GeForce-Karten ab. Allerdings produzierte der serienmäßige Wasserkühler der Fury X in der ersten Serie häufig störende Geräusche, wodurch es zu zahlreichen Reklamationen kam. AMD versprach eine neue Revision der Karte und lieferte eine verbesserte Version des Wasserkühlers.

Das sind vor allem Grafikkarten für CAD- und GIS-Anwendungen. Die Karten bieten spezielle für CAD/GIS notwendige Funktionen, die auf „normalen“ Grafikkarten nur emuliert und dadurch sehr viel langsamer genutzt werden können. Seit der letzte Spezialchip-Anbieter 3DLabs 2006 das Geschäft eingestellt hat, bieten nur noch AMD (unter dem Markennamen ATI) und Nvidia Lösungen für das OpenGL-Workstation-Segment an. Die beiden Firmen nutzen dabei Derivate ihrer Spielegrafikkarten-Chips. Diese werden dann mit einem modifizierten ROM und Treiber auf die 2D-Darstellung von OpenGL und nicht mehr auf die 3D-Darstellung von DirectX und OpenGL optimiert. Dabei unterstützen die Treiber dieser Grafikkarten das Zeichnen mehrerer Millionen geglätteter Linien und User-Clip-Planes. Obwohl sich die Hardware zwischen Spiele-3D-Chips und OpenGL-Chips nur minimal unterscheidet, kosten Profi-Karten erheblich mehr. Grund dafür ist das Optimieren der Treiber, der umfangreiche Kundendienst, der Workstation-Kunden geboten werden muss, und das sehr teure SRAM, mit dem manche Grafikkarten ausgestattet sind. Weiterhin sind oft zusätzliche Fähigkeiten vorhanden wie DisplayPort-Anschlüsse zur Nutzung eines höheren Farbumfangs oder die Projektion einer großen Fläche mit mehreren Bildquellen. Die Produktlinien heißen bei AMD ATI FireGL bzw. inzwischen AMD FirePro und bei Nvidia Quadro.

Außer den oben beschriebenen DirectX-Grafikkarten gibt es spezielle Karten, die nur OpenGL unterstützen. Diese werden häufig im Animationsbereich eingesetzt und sind heute für Spieler völlig uninteressant, da die meisten PC-Spiele nur noch DirectX unterstützen (anders jedoch auf der Macintosh-Plattform). Standardmäßig beherrscht jede heutige DirectX-Grafikkarte auch OpenGL, umgekehrt ist das jedoch nicht der Fall.

Seit den Anfängen der programmierbaren Grafikpipeline im Jahr 2000 besteht die Möglichkeit, die Rechenleistung der Grafikprozessoren zur Berechnung von parallelisierbaren Rechenoperationen, wie sie z. B. bei technischen und wirtschaftlichen Simulationen vorkommen, zu nutzen. Diese Anwendung wird als GPGPU (General Purpose Computation on Graphics Processing Unit) bezeichnet, siehe auch bei CUDA.

Um Grafikkarten benutzen zu können, ohne Hardware und Software für jede einzeln zu entwickeln, existieren verschiedene Software-Grafikschnittstellen.

Vor allem auf grundlegender Funktionsebene interessant ist das BIOS, das wichtige Text- und Grafikausgabefunktionen bereitstellt, die u. a. von Textkonsolen unter DOS oder Linux genutzt werden. Diese Funktionen sind relativ langsam, funktionieren aber zuverlässig auf jeder Grafikkarte.

In den meisten heutigen Betriebssystemen liegt eine Abstraktionsschicht zwischen Programmen und Hardware, die sogenannten Gerätetreiber. Ohne diese müssten Programme die Hardware direkt ansprechen, was aber aufgrund der Unterschiede zwischen Grafikkarten zu einer hohen Spezialisierung und damit hohem Programmieraufwand für die Unterstützung vieler Grafikkarten führen würde. Da aber Grafikkartentreiber ebenfalls sehr unterschiedliche Funktionen anbieten können, wurden im Laufe der Zeit verschiedene Grafik-APIs entwickelt, die den Zugang zu diesen Funktionen erleichtern sollen. Die bekanntesten darunter sind OpenGL, DirectX (genauer: DirectDraw, Direct3D) und Quartz, die es dem Programmierer ermöglichen, einfach und unabhängig von der Grafikkarte 2D- und 3D-Grafik anzuzeigen. Für DirectX und Quartz setzen die Schnittstellen nicht unbedingt Hardware-3D-Funktionen der Grafikkarte voraus, nutzen diese aber, falls sie vorhanden sind. Ältere 3D-Anwendungen können im Prinzip auch auf Computern mit integrierter Grafik oder einer einfachen 3D-Karte laufen, jedoch relativ langsam oder optisch weniger ansprechend.

Für das Betriebssystem EComstation wurde der universelle Panorama-Treiber entwickelt, der alle gängigen Grafikkarten bedient.

Da viele Grafikkarten heutzutage das flüssige Anschauen von Videos mittels des Rechners durch Hardwarebeschleunigung erlauben und ebenfalls viele Grafikkarten einen TV-Out-Anschluss haben, ist es naheliegend, den Rechner an einen Fernseher oder einen Videorekorder anzuschließen. Jedoch unterbinden es einige Hersteller durch den Grafikkartentreiber oder die "Grafikkarte" selbst, beide Fähigkeiten miteinander zu verbinden. So kommt es vor, dass beim Abspielen von Videos zwar die gesamte Benutzeroberfläche sichtbar ist, das Video selbst jedoch nicht. Unter Linux funktioniert dann beispielsweise die XVideo-Implementation nur bei der primären Anzeige (also dem Computer-Monitor), nicht jedoch beim TV-Out-Anschluss. Dieses Problem kann man meist umgehen, indem man die Hardwarebeschleunigung für das Dekodieren von Videos ausschaltet, jedoch ist das Video dann oft nicht mehr flüssig.

Es wird vermutet, dass solche Beschränkungen eingebaut werden, um den Nutzer an der Aufzeichnung des Videos durch einen Videorekorder zu hindern. Jedenfalls ist in einigen mitgelieferten Handbüchern nachzulesen, dass Produkte von Macrovision (einer Firma, die für ein Kopierschutzverfahren bekannt ist) in die "Grafikkarte" integriert wurden.

Ein konkreter Fall ist der fglrx-Treiber von AMD, der (derzeit) nicht das hardwareunterstützte Abspielen von Videos am TV-Ausgang unterstützt.

Ein weiteres Problem war und ist die Verwendung mehrerer VGA-kompatibler Grafikkarten, wie es in PCI-Systemen der Fall sein kann. Dabei unterstützt das Betriebssystem nicht jede freie Kombination, nicht einmal von Grafikkarten desselben Herstellers. Durch eine Aktualisierung des ROMs auf der Karte kann hier jedoch manchmal Abhilfe geschaffen werden.

Hersteller von Grafikchips:
3dfx, 3DLabs, AMD, Alliance Semiconductor, ARK Logic, ArtX, ATI Technologies, Avance Logic, Bitboys Oy, Chips & Technologies, Cirrus Logic, Intel, Matrox, NeoMagic, Number Nine, Nvidia, Oak Technology, Rendition, S3 Graphics, S3 Inc., SiS, Trident, Tseng Labs, Western Digital, XGI.

Hersteller von Grafikkarten:
ABIT, Albatron, AOpen, Asus, ATI Technologies, AXLE3D, Club 3D, Connect3D, Creative Labs/3DLabs, DFI, Diamond Multimedia, ELSA Technology, EVGA, Elitegroup, Gainward, Galaxy Microsystems Ltd., KFA2, GeCube, Genoa, Gigabyte, Hercules Graphics, HIS, Inno3D, Leadtek, Matrox, MSI, miro, Number Nine, Orchid Technologies, Palit Microsystems Ltd., Paradise Systems, PixelView, PNY, PowerColor, Quantum3D, Sapphire, Sigma, Sparkle, SPEA, STB Systems, TerraTec, VideoLogic, Video Seven, XFX, XpertVision, Zotac.

Heute sind nur noch AMD / ATI Technologies, Nvidia, Matrox und S3 Graphics als Grafikchiphersteller auf dem Markt, sowie AMD, Intel, Nvidia, SiS und VIA Technologies als Hersteller von integrierten Grafiklösungen.




</doc>
<doc id="2036" url="https://de.wikipedia.org/wiki?curid=2036" title="Gentechnik">
Gentechnik

Als Gentechnik bezeichnet man Methoden und Verfahren der Biotechnologie, die auf den Kenntnissen der Molekularbiologie und Genetik aufbauen und gezielte Eingriffe in das Erbgut (Genom) und damit in die biochemischen Steuerungsvorgänge von Lebewesen bzw. viraler Genome ermöglichen. Als Produkt entsteht zunächst rekombinante DNA, mit der wiederum gentechnisch veränderte Organismen (GVO) hergestellt werden können.
Der Begriff Gentechnik umfasst die Veränderung und Neuzusammensetzung von DNA-Sequenzen in vitro (z. B. im Reagenzglas) oder in vivo (in lebenden Organismen). Dazu gehört auch das gezielte Einbringen von DNA in lebende Organismen.

Gentechnik wird sowohl zur Herstellung neu kombinierter DNA innerhalb einer Art, als auch über Art-Grenzen hinweg verwendet. Dies ist möglich, weil alle Lebewesen denselben genetischen Code benutzen, von dem nur in wenigen Ausnahmefällen leicht abgewichen wird (siehe codon usage). Ziele gentechnischer Anwendungen sind beispielsweise die Veränderung von Kulturpflanzen, die Herstellung von Medikamenten oder die Gentherapie.

Obwohl es große Gemeinsamkeiten bei den verwendeten Methoden gibt, wird häufig nach Anwendungsbereich differenziert:

Transgene Nutzpflanzen haben seit ihrer Erstzulassung im Jahr 1996 weltweit an Bedeutung gewonnen und wurden 2015 in 28 Ländern auf 179 Millionen Hektar (das entspricht knapp ca. 12 % der globalen Landwirtschaftsfläche von 1,5 Mrd. Hektar) angebaut. Dabei handelt es sich insbesondere um Pflanzen, die aufgrund von gentechnischen Veränderungen tolerant gegenüber Pflanzenschutzmitteln oder giftig für bestimmte Schadinsekten sind. Durch den Einsatz haben sich für Landwirte, insbesondere in Entwicklungsländern, trotz höherer Ausgaben für Saatgut teilweise Ertrags-, Einkommens- und Gesundheitsvorteile oder Arbeitserleichterungen sowie geringere Umweltbelastungen ergeben. Zugelassenen Sorten wird von wissenschaftlicher Seite Unbedenklichkeit für Umwelt und Gesundheit attestiert. Umweltverbände, Anbieter ökologisch erzeugter Produkte sowie einige politische Parteien lehnen die grüne Gentechnik ab.

Transgene Tiere werden vor allem in der Forschung als Versuchstiere eingesetzt. Transgene Tiere zum menschlichen Verzehr sowie zur Eindämmung von Infektionskrankheiten sind noch nicht zugelassen.

Etliche Produkte, die für den Menschen interessant sind (zum Beispiel Insulin, Vitamine), werden mit Hilfe gentechnisch veränderter Bakterien hergestellt.
Auch für die Medizin hat die Gentechnik Bedeutung erlangt, die Zahl der gentechnisch hergestellten Medikamente auf dem Markt nimmt stetig zu. Anfang 2015 waren in Deutschland 175 Arzneimittel mit 133 verschiedenen gentechnisch erzeugten Wirkstoffen zugelassen. Sie werden bei zahlreichen Krankheiten eingesetzt, etwa Zuckerkrankheit, Blutarmut, Herzinfarkt, Wachstumsstörungen bei Kindern, verschiedenen Krebsarten und der Bluterkrankheit. Weltweit befinden sich über 350 Gentech-Substanzen in klinischen Prüfungen mit Patienten.

Insulin ist das bekannteste Hormon, das mit Hilfe der Gentechnik gewonnen wurde. Das früher verwendete Insulin stammte von Rindern und Schweinen und war nicht hundertprozentig baugleich mit dem des Menschen. Mittels Gentechnik wurde es nun ersetzt und löste u. a. die Probleme von Diabetikern mit einer Unverträglichkeit gegenüber Tierinsulin.

Auch in der Krebstherapie sind gentechnisch hergestellte Medikamente heute etabliert. Nach Meinung einiger Krebsexperten könnten durch den Einsatz von Interferon und blutbildenden Wachstumsfaktoren die Krebstherapien bei bestimmten Tumorarten verbessert, Krankenhausaufenthalte verkürzt oder gar vermieden sowie Lebensqualität gewonnen werden.

Ansätze zur gentechnischen Veränderung von Zellen im menschlichen Körper zu Heilzwecken werden im Artikel Gentherapie beschrieben.

Vor etwa 8000 Jahren wurde im heutigen Mexiko durch Züchtung das Erbgut von Teosinte-Getreide durch die Kombination von natürlich vorkommenden Mutationen so verändert, dass die Vorläufer der heutigen Mais-Sorten entstanden. Dadurch wurde nicht nur der Ertrag erhöht, sondern auch eine Pilzresistenz erzeugt.

Künstliche Mutationen für Züchtungszwecke wurden innerhalb der konventionellen Landwirtschaft erzeugt, indem Keime stark ionisierender Strahlung oder anderen genverändernden Einflüssen (Mutagenen) ausgesetzt wurden, um Mutationen im Erbgut häufiger als unter natürlichen Bedingungen hervorzurufen. Samen wurden ausgesät und jene Pflanzen, die die gewünschten Eigenschaften besaßen, wurden weiter gezüchtet. Ob dabei auch noch andere, unerwünschte, Eigenschaften entstanden, wurde nicht systematisch überprüft. Diese Technik wurde bei fast allen Nutzpflanzen und auch bei einigen Tierarten angewendet, jedoch lag der Erfolg der Mutationszüchtung bei Pflanzen nur zwischen 0,5 bis 1 % an züchterisch brauchbaren Mutanten, bei Tieren ist diese Methode überhaupt nicht zu gebrauchen.

Bei diesen Vorläufern der Gentechnik enthielt der veränderte Organismus jedoch keine rekombinante DNA.
Die eigentliche Geschichte der Gentechnik begann, als es Ray Wu und Ellen Taylor 1971 gelang, mit Hilfe von 1970 entdeckten Restriktionsenzymen eine Sequenz von 12 Basenpaaren vom Ende des Genoms eines Lambdavirus abzutrennen. Zwei Jahre später erzeugte man das erste genetisch veränderte rekombinante Bakterium, indem ein Plasmid mit vereinter viraler und bakterieller DNA in das Darmbakterium "Escherichia coli" eingeschleust wurde.
Angesichts dieser Fortschritte fand im Februar 1975 die Asilomar-Konferenz in Pacific Grove, Kalifornien, statt. Auf der Konferenz diskutierten 140 Molekularbiologen aus 16 Ländern Sicherheitsauflagen, unter denen die Forschung weiter stattfinden sollte. Die Ergebnisse waren Grundlage für staatliche Regelungen in den Vereinigten Staaten und später in vielen anderen Staaten.
1977 gelang erstmals die gentechnische Herstellung eines menschlichen Proteins in einem Bakterium. Im selben Jahr entwickelten Walter Gilbert, Allan Maxam und Frederick Sanger unabhängig voneinander Methoden zur effizienten DNA-Sequenzierung, für die sie 1980 mit dem Nobelpreis für Chemie ausgezeichnet wurden. Ende der 1970er Jahre entdeckten die Belgier Marc Van Montagu und Jeff Schell die Möglichkeit, mittels "Agrobacterium tumefaciens" Gene in Pflanzen einzuschleusen und legten damit den Grundstein für die Grüne Gentechnik.

1980 beantragte Ananda Chakrabarty in den USA das erste Patent auf einen GVO, dessen Zulassungsverfahren bis vor den Supreme Court getragen wurde. Dieser entschied 1981, dass der Fakt, dass Mikro-Organismen lebendig sind, keine gesetzliche Bedeutung für den Zweck des Patent-Rechtes habe und machte damit den Weg für die Patentierung von Lebewesen frei. 1982 kam in den Vereinigten Staaten mit Insulin das erste gentechnisch hergestellte Medikament auf den Markt.
1982 wurde mit dem Bakteriophagen Lambda das erste Virus in seiner vollständigen DNA-Sequenz veröffentlicht. Im Jahr 1983 entwickelte Kary Mullis die Polymerase-Kettenreaktion, mit der DNA-Sequenzen vervielfältigt werden können und erhielt dafür 1993 den Chemie-Nobelpreis.
1985 wurden genetisch manipulierte Pflanzen in den USA patentierbar und es erfolgte die erste Freisetzung genetisch manipulierter Bakterien (ice minus bacteria). 1988 wurde das erste Patent für ein gentechnisch verändertes Säugetier, die sogenannte Krebsmaus, vergeben.

Ab Herbst 1990 wurde im Humangenomprojekt damit begonnen, das gesamte Genom des Menschen zu sequenzieren. Am 14. September 1990 wurde die weltweit erste Gentherapie an einem vierjährigen Mädchen durchgeführt. Im Jahr 1994 kamen im Vereinigten Königreich und den Vereinigten Staaten gentechnisch veränderte Flavr-Savr-Tomaten, auf den Markt.

Im Jahr 1996 wurden erstmals transgene Sojabohnen in den USA angebaut. Der Import dieser Sojabohnen nach Deutschland führte dort zu ersten öffentlichen Kontroversen über die Verwendung von Gentechnologie in der Landwirtschaft. Greenpeace führte im Herbst 1996 mehrfach illegale Protestaktionen durch, wie Behinderung der Löschung und Beschriften von Frachtern.

Die Firma Celera und International Genetics & Health Collaboratory behaupteten 2001, das menschliche Genom, parallel zum Humangenomprojekt, vollständig entschlüsselt zu haben. Jedoch war die Sequenzierung nicht vollständig. Ein Jahr später wurde der erste in seiner Keimbahn gentechnisch veränderte Primat geboren.

Die Erzeugung gentechnisch veränderter Organismen besteht meistens aus zwei Methoden. Durch eine Klonierung wird die rekombinante DNA erzeugt, je nach verwendetem Vektor ist anschließend noch eine Methode zum Einschleusen der DNA erforderlich, z. B. durch eine Transfektion oder Transformation. Das Genome Editing verwendet zusätzlich sequenzspezifische Endonukleasen. Hier eine Übersicht der wichtigsten Techniken:


Da die Funktion der meisten Gene in Pflanzen unbekannt ist, muss man, um sie zu erkennen, die Steuerung des Gens modifizieren. Dabei werden Effekte von Genen normalerweise durch einen Vergleich dreier Pflanzenpopulationen aufzuklären versucht (Wildtyp, Überexpressoren und „Knockout“-Population). Hierfür gibt es verschiedene Techniken, wie etwa RNAi. Allen Techniken ist gemein, dass sie doppelsträngige RNA produzieren, die der Pflanze den „Befehl“ gibt, „normale“ Ribonukleinsäure des zu untersuchenden Gens abzubauen.

Außerdem gehören auch deskriptive Techniken zur Standardausrüstung der gentechnischen Pflanzenforschung. Dabei werden Gene kloniert, dann bestimmt man die Häufigkeiten von Transkripten (Bauanleitungen für Proteine) oder mittels so genannter DNA-Chips gleich die meisten Gene einer Pflanze in ihrer Ablesehäufigkeit.

Der Agrobakterium-vermittelte Gentransfer ist ebenfalls eine wichtige Technik. Bei dieser gentechnischen Methode werden einzelne Erbfaktoren von Zellen eines Organismus in Zellen eines anderen Lebewesens übertragen.

Die somatische Hybridisierung wiederum erlaubt es, gewünschte Merkmale verschiedener Elternpflanzen zu kombinieren. Im Vergleich zum Agrobakterium-vermittelten Gentransfer müssen hierbei keine spezifischen Gene identifiziert und isoliert werden. Außerdem wird damit die Einschränkung der Transformation (Gentransfer) überwunden, nur wenige Gene in ein vorgegebenes Erbgut einführen zu können. Auch kann bei der Zellfusion die Chromosomenzahl der Zellen multipliziert werden, also die Anzahl der Chromosomensätze (Ploidiegrad) erhöht werden. Dies kann die Ertragsfähigkeit von Pflanzen steigern (Heterosiseffekt). Molekulare Marker oder biochemische Analysen werden genutzt, um aus der somatischen Hybridisierung hervorgegangene Pflanzen zu charakterisieren und zu selektieren.

Eine gentechnische Methode der roten Biotechnologie ist die Gentherapie. Hier wird versucht, Krankheiten, die durch defekte Gene verursacht werden, durch Austausch dieser Gene zu heilen.


Biotechnologische Medikamente werden durch transgene Organismen (Mikroorganismen, Nutztiere oder Pharmapflanzen) hergestellt. Dabei wird iterativ so lange verändert, bis ein Wirkstoff entsteht, der die Krankheit heilen kann.

Durch gelenkte Evolution werden hier Stämme von Mikroorganismen erzeugt und aufgrund ihrer Erträge der gewünschten Produkte, die durch ein Screening festgestellt wurden, selektiert. Dieser Vorgang wird in iterativen Zyklen wiederholt, bis die angestrebten Veränderungen erreicht sind. Zur Identifizierung von nicht kultivierbaren Organismen untersucht man Metagenome, d. h. die Gesamtheit der Genome eines Lebensraums, Biotops oder einer Lebensgemeinschaft (Biozönose). In Metagenomen können beispielsweise Biokatalysatoren aufgefunden werden, die bisher noch nicht bekannte biochemische Reaktionen katalysieren und neue, interessante Stoffwechselprodukte bilden.

Zum Einschleusen von Plasmid-DNA in das Bakterium wird u. a. die Eigenschaft von Calciumchlorid genutzt, Zellmembranen durchlässig zu machen.

Seit dem 18. April 2004 besteht innerhalb der EU eine Kennzeichnungspflicht für gentechnisch veränderte Produkte. Sie schließt ein, dass alle Produkte, die eine genetische Veränderung besitzen, gekennzeichnet werden müssen, auch dann, wenn die Veränderung im Endprodukt nicht mehr nachweisbar ist. Ausgenommen von der Kennzeichnungspflicht sind Fleisch, Eier und Milchprodukte von Tieren, die mit gentechnisch veränderten Pflanzen gefüttert wurden sowie Produktzusätze, die mithilfe genetisch veränderter Bakterien hergestellt wurden, ebenso Enzyme, Zusatzstoffe und Aromen, da sie im rechtlichen Sinne nicht als Lebensmittel gelten.

Kritiker von gentechnisch veränderten Lebensmitteln verweisen in diesem Zusammenhang darauf, dass derzeit (Stand: 2005) etwa 80 Prozent der angebauten gentechnisch veränderten Pflanzen in die Futtermittelindustrie einfließen. Sie fordern deshalb die Kennzeichnungspflicht auch für diese tierischen Produkte. Auch wenn die Erbsubstanz gentechnisch veränderter Futtermittel im Magen von Tieren aufgelöst wird, kann sie im Endprodukt nachweisbar sein, zumindest als Fragmente.

Eine Kennzeichnung muss weiterhin nicht erfolgen, wenn die Verunreinigung mit genetisch verändertem Material unter 0,9 % (Stand: 2008) Gewichtsprozent liegt und zufällig oder technisch unvermeidbar ist. Dabei ist jede Einzelzutat eines Lebens- oder Futtermittels getrennt zu betrachten. 2007 wurde eine neue EU-Öko-Verordnung (Nr. 834/2007) verabschiedet, die ab 2009 Gültigkeit erlangt. Mit ihr wird die Möglichkeit geschaffen, dass Zusatzstoffe für Lebens- oder Futtermittel, die A) grundsätzlich im Ökolandbau zugelassen sind und B) nachweislich nicht in GVO-freier Qualität verfügbar sind, auch dann eingesetzt werden dürfen, wenn sie durch gentechnisch veränderte Mikroorganismen hergestellt wurden. Die Interpretation der neuen Regel steht noch aus. Derzeit ist nach der neuen Regel kein Stoff zugelassen.

Gesetzlich werden Haftung, Strafvorschriften und Definitionen in Bezug auf die Gentechnik durch das 1990 erlassene deutsche Gentechnikgesetz geregelt. Der zweite Teil dieses Gesetzes definiert die Sicherheitsstufen und -maßnahmen an Arbeitsplätze für gentechnische Arbeiten. Die Einstufung erfolgt dabei nach Risiko für die menschliche Gesundheit und Umwelt in 4 Sicherheitsstufen:

Bei der Zuordnung wird nach Anhörung einer Kommission im Zweifel die höhere Sicherheitsstufe gewählt.

Den genauen Umgang mit gentechnisch veränderten Organismen regelt die Gentechnik-Sicherheitsverordnung. Ein Gesetz zur Neuordnung des Gentechnikrechts wurde im Juni 2004 erlassen, um die EU-Richtlinie zur Freisetzung von GVOs umzusetzen.

In Österreich wurde im April 1997 das "Gentechnik-Volksbegehren" angenommen. Bei einer Wahlbeteiligung von über 21 % wurden damit ein gesetzlich verankertes Verbot der Produktion, des Imports und des Verkaufs gentechnisch veränderter Lebensmittel, ein ebensolches Verbot der Freisetzungen genetisch veränderter Pflanzen, Tiere und Mikroorganismen sowie ein Verbot der Patentierung von Lebewesen gefordert. Der Beschluss wurde am 16. April 1998 nach 3. Lesung angenommen.

Das Schweizer Volk stimmte im Rahmen einer Volksinitiative vom 27. November 2005 bei einer Stimmbeteiligung von über 42 % mehrheitlich für ein Moratorium bezüglich der Nutzung von Gentechnik in der Landwirtschaft. Für zunächst fünf Jahre wurde damit der Anbau von Pflanzen oder die Haltung von Tieren verboten, die gentechnisch verändert wurden. Ausnahmen gibt es nur für der Forschung (vor allem Risikoforschung) dienende kleine Anbauflächen, die den Vorschriften der "Freisetzungs-Verordnung" unterstehen. Importe von gentechnisch veränderten Produkten sind teils – unter strengen Auflagen – zugelassen. Nach intensiver politischer Diskussion wurde das Moratorium von Bundes-, Stände- und Nationalrat bis 2013 verlängert. Danach sollen Ergebnisse eines nationalen Forschungsprogramms, das bis 2012 lief, für eine neue Entscheidungsfindung berücksichtigt werden.
Mit denselben Argumenten wurde das Moratorium im Dezember 2012 bis Ende 2017 verlängert. Trotz der Verlängerung will der Bundesrat es den Bauern erlauben, ab 2018 in gewissen Zonen gentechnisch veränderte Pflanzen anzubauen. Diese Pläne stoßen allerdings im Parlament auf heftigen Widerstand.

Die Regulierung der Gentechnik ist außerhalb der deutschsprachigen Länder und der EU allgemein häufig weniger strikt. In den USA und Kanada ist Kennzeichnung z. B. freiwillig.




</doc>
<doc id="2038" url="https://de.wikipedia.org/wiki?curid=2038" title="Design (Schutzrecht)">
Design (Schutzrecht)

Ein Design oder Geschmacksmuster ist ein gewerbliches Schutzrecht, das seinem Inhaber für bestimmte Waren ein Ausschließlichkeitsrecht zur Benutzung einer ästhetischen Erscheinungsform (Gestalt, Farbe, Form) verleiht. Die Begriffe "Design" oder "Geschmacksmuster" bezeichnen keinen Unterschied, sondern sind nur verschiedene Bezeichnungen für dieselbe Schutzrechtsart. Nachfolgend wird der Begriff "Design" verwendet.

Designschutz ist gegeben, wenn das Design bei der zuständigen Behörde für gewerbliche Schutzrechte, meist das jeweilige Patentamt, registriert bzw. eingetragen ist. Es handelt sich dann um ein "eingetragenes Design". Daneben gibt es in der EU auch ein "nicht eingetragenes Gemeinschaftsgeschmacksmuster", dessen Schutz alleine durch die erstmalige Benutzung entsteht. Internationaler Designschutz ist über das Haager Abkommen über die internationale Hinterlegung gewerblicher Muster und Modelle möglich.

Ästhetische Gestaltungen sollen so gegen Nachahmung geschützt werden. Vom Patent- oder Gebrauchsmusterschutz wären sie hingegen ausgenommen. Der Designschutz erfasst die zwei- oder dreidimensionale Erscheinungsform eines ganzen Erzeugnisses oder eines Teils davon.

Bedingungen für die Rechtswirksamkeit eines Designsrechtes sind im Wesentlichen:



Ein Designrecht ist ein ungeprüftes Schutzrecht. Im Eintragungsverfahren werden die Voraussetzungen der Neuheit und Eigenart nicht geprüft, sondern nur formale Voraussetzungen für die Registrierung. Macht der Inhaber eines Designrechtes Ansprüche aus dem Design gegen einen vermeintlichen oder mutmaßlichen Verletzer geltend, so kann der Verletzer überprüfen lassen, ob dem Design zum Zeitpunkt der Anmeldung bzw. am Prioritätstag die Neuheit oder Eigenart fehlte. Je nach prozessualer Situation kann er eine Widerklage auf Feststellung oder Erklärung der Nichtigkeit bei dem Gericht erheben, vor dem er wegen Verletzung verklagt wurde, oder (bei eingetragenen Designs) einen Nichtigkeitsantrag beim zuständigen Amt stellen, bei dem das Design registriert wurde.

Der Schutz entsteht mit der Eintragung in das Register. Die Schutzdauer des eingetragenen Designs beträgt in den meisten Jurisdiktionen 25 Jahre, gerechnet ab dem Anmeldetag. Hierfür sind Aufrechterhaltungsgebühren zu zahlen. Unterbleibt dies, erlischt der Schutz früher.

Die Verordnung (EG) Nr. 6/2002 des Rates vom 12. Dezember 2001 über das Gemeinschaftsgeschmacksmuster (GGV) etablierte ein EU-weit geltendes Gemeinschaftsgeschmacksmuster. Es hat gleichermaßen in allen EU-Staaten Wirkung. Zuständig für die Eintragung von Gemeinschaftsgeschmacksmustern ist das Amt der Europäischen Union für Geistiges Eigentum (EUIPO). Neben dem sog. eingetragenen Gemeinschaftsgeschmacksmuster gibt es auch das bereits erwähnte "nicht eingetragene Gemeinschaftsgeschmacksmuster". Dieses nichtregistrierte Designrecht entsteht automatisch mit der öffentlichen Zugänglichmachung des Designs in der EU und bietet Schutz für drei Jahre (Art. 11 Abs. 2 GGV setzt dem bestimmte Arten der außergemeinschaftlichen Zugänglichmachung gleich).

Daneben sind in der EU national gültige Designrechte möglich. In Deutschland ist die für Eintragung und Nichtigkeitsanträge zuständige Behörde das Deutsche Patent- und Markenamt (DPMA); die entsprechenden Bestimmungen finden sich im Designgesetz.

Die Aufrechterhaltungsgebühren sind für Gemeinschaftsgeschmacksmuster und nationale deutsche Designs ab dem 6. Schutzjahr jeweils für einen Fünf-Jahres-Zeitraum zu zahlen.

Das Designrecht ermächtigt den Inhaber, Dritten etwas zu untersagen. Betroffen ist insbesondere das Herstellen, Anbieten, Inverkehrbringen, die Ein- oder Ausfuhr oder der Gebrauch eines Erzeugnisses, welches das Design beinhaltet oder bei dem es verwendet wird. Dabei wird auf die gesamte Erscheinungsform eines Designs, die bei eingetragenen Designs in der Anmeldung sichtbar wiedergegeben ist abgestellt, Abs. 1 DesignG. Auf Identität kommt es nicht an. Maßgeblich ist die Frage, ob bei einem „informierten Benutzer“ derselbe Gesamteindruck hervorgerufen wird Abs. 2 DesignG. 

Untersagt werden kann grundsätzlich jede der genannten Handlungen, sofern sie nicht durch den Rechtsinhaber gestattet wurden, Designgesetz (DesignG), oder das Recht des Inhabers bereits erschöpft ist. Letzteres ist dann der Fall, wenn die Ware ursprünglich vom Schutzrechtsinhaber oder mit dessen Genehmigung in Verkehr gebracht wurde. Ausnahmen von Designschutz gewährt die Rechtslage insbesondere für im privaten Bereich zu nicht-gewerblichen Zwecken vorgenommene Handlungen, für Handlungen zu Versuchszwecken und für Wiedergaben zum Zwecke der Zitierung oder der Lehre mit Angabe der Quelle und in einem fairen, nicht beeinträchtigenden Umfang.

Dem Schutzrechtsinhaber wird in Deutschland ein Recht an der gewerblichen Nutzung des Abbilds der geschützten Gegenstände zugesprochen. Infolge Art. 13 der EU-Geschmacksmusterrichtlinie 98/71 EG formuliert GeschmMG die Begrenzung dieses Ausschließlichkeitsrechtes; erlaubt sind: "Wiedergaben zum Zwecke der Zitierung oder der Lehre, vorausgesetzt, solche Wiedergaben sind mit den Gepflogenheiten des redlichen Geschäftsverkehrs vereinbar, beeinträchtigen die normale Verwertung des Geschmacksmusters nicht über Gebühr und geben die Quelle an". 

Daraus wird von Gesetzeskommentaren im Umkehrschluss gefolgert, dass alle anderen Wiedergaben von Erzeugnissen dem Rechtsinhaber vorbehalten seien: "Als Benutzungshandlung ist Wiedergabe jede Art und jede Form der Erzeugnisabbildung. Dem VerbietungsR(echt) unterliegt z. B. die Wiedergabe von mustergemäßen Erzeugnissen in Bildbänden". Abbildungen als Schmuck oder Dekoration würden nicht unter die Ausnahmebestimmung fallen. 
Da eine "erläuternde Befassung" nötig sei, würde etwa der kommerzielle Vertrieb von Postkarten dem Verbotsrecht des Rechtsinhabers unterfallen. Als Quellenangabe komme die "Information über die gestalterische und betriebliche Herkunft des Gegenstands der Wiedergabe" in Betracht. 

Die Abbildung eines geschützten Designs wie z. B. des ICE wurde in einem richtungsweisenden Präzedenzfall 2011 vom Bundesgerichtshof dahingehend entschieden, dass die Abbildung eines Geschmacksmusters nicht den „Zwecke der Zitierung“ nach Nr. 3 DesignG erfüllt und damit unzulässig ist, wenn sie ausschließlich Werbezwecken dient. Zu Grunde lag ein Fall, in dem ein Forschungsinstitut der Fraunhofer-Gesellschaft, das sich mit Schienenfahrzeugtechnik befasste und für die Deutsche Bahn eine Radsatzprüfanlage für den Zugtyp ICE 1 entwickelt hatte, im Ausstellerkatalog einer Fachmesse für seine Leistungen mit einer Abbildung des Triebwagens des ICE 3 geworben hatte. Diese Abbildung diene laut BGH reinen Werbezwecken, und sei nicht mehr vom Geschmacksmustergesetz freigestellt.

Grundsätzlich steht das Recht aus Designschutz eigenständig neben urheberrechtlichen Ansprüchen. Rechtsprechung zur Frage, welche der Schrankenbestimmungen des Urheberrechts analog gültig sind, liegt noch nicht vor. Gefordert wird z. T. eine Abwägung zwischen den Interessen des Rechtsinhabers und den Interessen desjenigen, der das Muster abbilden möchte. 




</doc>
<doc id="2039" url="https://de.wikipedia.org/wiki?curid=2039" title="Gewerblicher Rechtsschutz">
Gewerblicher Rechtsschutz

Der gewerbliche Rechtsschutz umfasst im deutschen Recht die gewerblichen Schutzrechte der einzelnen Gewerbetreibenden an immateriellen Gütern wie beispielsweise einer technischen Erfindung oder einer Marke. 

Insbesondere das Patent-, Marken- und Designrecht, aber auch das Halbleiterschutzgesetz oder das Sortenschutzgesetz regeln Voraussetzung, Inhalt und Schranken der dem Rechteinhaber zustehenden Ausschließlichkeitsrechte. 

Zum gewerblichen Rechtsschutz wird auch das Lauterkeitsrecht insoweit gezählt, als es im Gesetz gegen den unlauteren Wettbewerb (UWG) die gewerbliche Tätigkeit schützt, obwohl es den Gewerbetreibenden kein Immaterialgüterrecht gewährt (wettbewerbsrechtlicher Leistungsschutz). Das so entstandene Gebiet wird als "Grüner Bereich" (nach der Fachzeitschrift GRUR, die einen grünen Einband hat) bezeichnet.

Das Urheberrecht wird nicht zu den gewerblichen Schutzrechten gezählt, da es den Schutz persönlicher geistiger Schöpfungen betrifft, die mehr dem künstlerischen als dem gewerblichen Bereich entstammen.

Gewerbliche Schutzrechte und das Urheberrecht werden unter dem Begriff des "geistigen Eigentums" zusammengefasst.


</doc>
<doc id="2041" url="https://de.wikipedia.org/wiki?curid=2041" title="Gräser (Begriffsklärung)">
Gräser (Begriffsklärung)

Gräser steht für:

Gräser oder Graeser ist der Familienname folgender Personen:

Siehe auch:


</doc>
<doc id="2043" url="https://de.wikipedia.org/wiki?curid=2043" title="Gesellschaftsrecht (Deutschland)">
Gesellschaftsrecht (Deutschland)

In der deutschen Rechtswissenschaft wird mit Gesellschaftsrecht das Rechtsgebiet bezeichnet, das sich mit den privatrechtlichen Personenvereinigungen, die zur Erreichung eines bestimmten Zweckes durch Rechtsgeschäft begründet werden, beschäftigt.

Daneben hat das gemeinsame Gesellschaftsrecht der EU-Mitgliedstaaten in Deutschland Geltung.

Die Geschichte des Gesellschaftsrechts behandelt die historische Entwicklung der Normen über privatrechtliche Personenvereinigungen. Erstmals kodifiziert wurden Regelungen zum Gesellschaftsrecht im Preußischen Allgemeinen Landrecht von 1794. Darin enthalten waren Regelungen zur vermögensmäßigen "societas" (der Vorläuferin der GbR), der "moralischen Personen" sowie zur OHG und zur Stillen Gesellschaft. Die weltweit erste gesetzliche Ausgestaltung der Aktiengesellschaft "(société anonyme)" geht auf den französischen "Code de commerce" von 1807 zurück. In Deutschland fand das Gesellschaftsrecht seine erste gesamtdeutsche Regelung durch das Allgemeine Deutsche Handelsgesetzbuch (ADHGB) von 1861; für die Aktiengesellschaft enthielt dieses noch ein Konzessionssystem, das allerdings schon 1870 wieder aufgehoben wurde. Juristisches Neuland betrat die deutsche Gesetzgebung 1892, als die international unbekannte Form der GmbH im GmbH-Gesetz von 1892 zum Entstehen kam. Die Systematik des deutschen Gesellschaftsrechtes geht in seiner heutigen Form auf das BGB von 1896 (in Kraft seit 1900) und das Handelsgesetzbuch (HGB) von 1897 zurück. 1937 wurde aus diesem das Recht der Aktiengesellschaften ausgegliedert. Seit dem letzten Drittel des 20. Jahrhunderts finden wichtige Entwicklungen besonders im Gesellschaftsrecht der Europäischen Union statt.

Einfachrechtliche Rechtsquellen des Gesellschaftsrechtes sind:


Daneben sind in verfassungsrechtlicher Hinsicht die und Grundgesetz (GG) von besonderer Relevanz.

Nach BGB liegt eine Gesellschaft unter drei Voraussetzungen vor:


Durch diese Merkmale wird die "Gesellschaft im weiteren Sinne" definiert. Innerhalb dieser unterscheidet man zwischen "Gesellschaft im engeren Sinne" (Personengesellschaften, beispielsweise die GbR, die OHG und die KG) und Körperschaften (beispielsweise Vereine bürgerlichen Rechts, die Aktiengesellschaft (AG) und die GmbH). Die Personengesellschaft unterscheidet sich vom Verein durch die Abhängigkeit ihres rechtlichen Bestandes von den Gesellschaftern und ihre Organisationsstruktur. Grundform der Personengesellschaften ist nach herrschender Meinung und Systematik des Gesetzes die Gesellschaft bürgerlichen Rechts, Grundform der Vereine der Verein bürgerlichen Rechts.

Personengesellschaften sind keine juristischen Personen und besitzen deshalb nach dem Gesetz keine eigene Rechtspersönlichkeit, wenngleich sie in der Praxis – mit Ausnahme der Stillen Gesellschaft – von ihrem Mitgliederbestand unabhängige Träger von Rechten und Pflichten sind.


Der eingetragene Verein (e. V.) und die rechtsfähige Stiftung sind ebenfalls eigenständige juristische Personen, jedoch keine Kapitalgesellschaften. Der Verein hat Mitglieder, aber nicht notwendigerweise ein Vermögen. Die rechtsfähige Stiftung hat ein dauerhaft dem Stiftungszweck gewidmetes Vermögen, aber keine Mitglieder, Gesellschafter oder Eigentümer.

Bei den Kapitalgesellschaften handelt es sich um juristische Personen.


Darüber hinaus gibt es Mischformen, die aus mehreren Gesellschaften (Kapital- und Personengesellschaften) zusammengesetzt sind. Dabei tritt eine Kapitalgesellschaft oder Stiftung als persönlich haftende Gesellschafterin einer Personengesellschaft oder KGaA auf.


Im deutschen Gesellschaftsrecht gibt es drei Formen der Haftung, und zwar die gesellschaftsrechtliche Haftung, die Zurechnung (hier insbesondere bei der Organhaftung) und die Durchgriffshaftung. Bei der letzteren geht es darum, die Rechtsfolgen der Haftung auf einen hinter dem eigentlichen Normadressaten stehenden Dritten zu erstrecken. Im Konzernrecht kennt man zudem die Konzernhaftung.

Das internationale Gesellschaftsrecht (Kollisionsrecht) ist ein Teil des internationalen Privatrechts. Bislang gibt es in Deutschland keine geschriebenen Regelungen dazu.

In der deutschen Rechtspraxis war bislang die "Sitztheorie" vorherrschend. Danach ist das Recht des Landes maßgeblich, in dem die Gesellschaft ihren tatsächlichen Verwaltungssitz hat. Das Gegenmodell zur Sitztheorie ist die "Gründungstheorie". Danach ist das Recht des Staates anwendbar, in dem die Gesellschaft gegründet und registriert wurde, und zwar auch dann, wenn die Gesellschaft ihren Verwaltungssitz in ein anderes Land verlegt. Probleme ergeben sich hier allerdings bei den Briefkastengesellschaften; und es ist ein "Race to the bottom" möglich, also ein Zulauf in die Länder, die geringere Anforderungen an die Gründung haben (siehe auch Delaware-Effekt). In der Europäischen Union gilt seit den EuGH-Urteilen "Daily Mail", "Centros", "Überseering" und "Inspire Art" wegen der gebotenen Freizügigkeit auch für juristische Personen die Gründungstheorie – allerdings beschränkt auf Gesellschaften, die in einem Mitgliedstaat der Europäischen Union oder einem Staat der Europäischen Freihandelsassoziation (mit Ausnahme der Schweiz, die das EWR-Abkommen nicht ratifiziert hat) gegründet wurden. Dies hat in Deutschland auch zu einer starken Zunahme von Limiteds geführt.

In jüngerer Zeit gibt es – vor allem im Zuge der neueren höchstrichterlichen Rechtsprechung, wonach in der EU gegründete Gesellschaften aufgrund der europarechtlichen Niederlassungsfreiheit in anderen EU-Mitgliedstaaten auch dann anerkannt werden müssen, wenn diese Gesellschaften ihren effektiven Verwaltungssitz in ein anderes EU-Land verlegen – zunehmend auch Mischformen mit ausländischen Gesellschaftsformen (z. B. Limited & Co. KG).


Gesetzessammlungen

Lehrbücher

Fallbücher

Kommentare

Zeitschriften/Aufsätze



</doc>
<doc id="2047" url="https://de.wikipedia.org/wiki?curid=2047" title="Gaia (Mythologie)">
Gaia (Mythologie)

Gaia oder Ge ( oder , dorisch ), deutsch auch "Gäa", ist in der griechischen Mythologie die personifizierte Erde und eine der ersten Gottheiten. Ihr Name ist indogermanischen Ursprungs und bedeutet möglicherweise "die Gebärerin". Ihre Entsprechung in der römischen Mythologie ist Tellus.

In Hesiods "Theogonie" entsteht Gaia als eine der ersten Gottheiten aus dem Chaos. Ihre Geschwister sind Tartaros, Eros, Erebos und Nyx.
Für die Orphiker ist Hydros (Wasser) die Urgottheit, aus der nach ihrer Vorstellung Gaia als einzige Gottheit ohne Befruchtung hervorgegangen ist. Der Mythograph Hyginus nennt als Eltern der Gaia Aither und Hemera.

Bei Hesiod gebiert Gaia von Uranos die Titanen, die einäugigen Kyklopen und schließlich die hundertarmigen Hekatoncheiren. Dem Vater sind seine Kinder verhasst, darum hält er sie in Gaia (in der Höhlung der Erde) versteckt und freut sich seiner Tat. Gaia sinnt auf eine List, sie bringt das unzerbrechliche graue Adamant hervor und macht daraus eine gezähnte Sichel. Dann fordert sie ihre Kinder auf, sich gegen den Vater aufzulehnen. Der Titan Kronos folgt ihr als einziger. Als Uranos sich voll Verlangen Gaia nähert, schneidet Kronos ihm mit der Sichel das Geschlechtsteil ab und wirft es fort. Das aus der Wunde des Uranos fließende Blut befruchtet Gaia und sie gebiert die Giganten, die Erinnyen und die melischen Nymphen.

In der "Bibliotheke des Apollodor" überredet Gaia aus Ärger darüber, dass Uranus die Hekatoncheiren und die Kyklopen in den Tartaros verbannt hat, die Titanen dazu, über ihren Vater herzufallen. Kronos gibt ihnen die Sichel, und alle Titanen außer Okeanos wenden sich gegen Uranos. Kronos entmannt ihn, und Gaia gebiert aus seinem Blut die Giganten und die Erinnyen. Die Titanen befreien ihre Geschwister aus dem Tartaros und ernennen Kronos zum höchsten Herrscher.

In der "Theogonie" sagen Uranos und Gaia dem Kronos voraus, dass einer seiner Nachkommen ihn stürzen würde, so wie er seinen Vater entmachtet hat. Kronos verschlingt daraufhin jedes Kind, sobald es von seiner Gemahlin Rhea geboren worden ist. Als Rhea aber den Zeus erwartet, bittet sie Gaia, ihn vor Kronos zu verstecken. Anstatt des Kindes bringt Rhea diesem einen gewindelten Stein, den dieser verschlingt, und Gaia zieht Zeus heimlich in Kreta auf. Als Zeus herangewachsen ist, überredet er die Okeanide Metis, dem Kronos ein Brechmittel in seinen Trank zu geben, sodass er die Kinder mitsamt dem Stein erbricht. Diese geben Zeus zum Dank den Donner, den Zündkeil und den Blitz, die Gaia in sich verborgen hatte. Zeus und seine Geschwister führen daraufhin zehn Jahre Krieg gegen die Titanen, bis Gaia ihnen den Ort zeigt, an dem die Kyklopen und Hekatoncheiren gefangen gehalten werden. Zeus befreit sie und gemeinsam besiegen sie die Titanen und verbannen sie in den Tartaros, wo sie von den Hekatoncheiren bewacht werden. Auf Gaias Rat wird Zeus von den anderen Göttern zu ihrem Obersten gemacht. Auch laut der "Bibliotheke" kann Zeus mit Hilfe der aus dem Tartaros befreiten Hekatoncheiren und Kyklopen die Titanen besiegen.

Der Titan Prometheus beklagt sich in "Der gefesselte Prometheus" des Aischylos darüber, dass er vergeblich seine Geschwister gewarnt habe, diese hätten nicht auf die Prophezeiung von Uranos und Gaia hören wollen.

Die Gigantomachie wird erstmals in der "Bibliotheke" ausführlich beschrieben. Gaia zeugt mit Tartaros aus Ärger über die Gefangennahme ihrer Kinder, der Titanen, die Giganten, die von ihr aufgestachelt werden, den Olymp zu stürmen. Da die Giganten, wie die Olympier vom Orakel erfahren, nicht von der Hand eines Gottes getötet werden können, holen diese Zeus' Sohn Herakles an ihre Seite. Doch Gaia macht sich auf die Suche nach einer Pflanze, die die Giganten dennoch unbesiegbar machen soll. Zeus aber bittet Eos, Selene und Helios darum, kein Licht mehr zu spenden, und findet in der Nacht selbst das Kraut. Die Götter besiegen mit Herakles' Hilfe die Giganten und Gaia zeugt, erzürnt über die Niederlage, mit Tartaros den Typhoeos.

In der "Dionysiaka" des Nonnos bittet Hera sie darum, etwas gegen die Taten des Zeus und des Dionysos zu unternehmen, der das erdgeborene Volk der Inder in seinem Feldzug bekämpft hat. Gaia ist darüber so erzürnt, dass sie ihre Kinder, die Titanen und Giganten, aussendet um Dionysos zu bekämpfen und lebend oder tot zu ihr zu bringen.

In der "Theogonie" gebiert Gaia ohne Befruchtung Uranos, Ourea und Pontos.
Mit Uranos zeugt sie daraufhin die Titanen Okeanos, Koios, Kreios, Iapetos, Hyperion, Theia, Rhea, Mnemosyne, Themis, Phoibe, Tethys und Kronos, die Kyklopen Brontes, Steropes und Arges sowie die Hekatoncheiren Briareos, Gyges und Kottos.
Aus Uranos’ Blut, das nach der Entmannung von Uranos auf Gaia fällt, wachsen die Giganten, die Erinnyen und die melischen Nymphen, die alle nicht näher benannt werden.
Von Pontos bekommt sie die Kinder Nereus, Keto, Phorkys, Thaumas und Eurybia. Als Zeus später den Kronos stürzt und mit den Titanen kämpft, zeugt Gaia mit Tartaros den Typhoeos und sendet diesen gegen die olympischen Götter aus. Sie muss sich aber fügen und die Oberherrschaft des Zeus anerkennen.
Nach anderen Hesiod zugeschriebenen Texten zeugt sie mit Poseidon den Laistrygon, und bringt den Skorpios hervor
Mit Epaphos ist sie zudem Erzeugerin zahlreicher menschlicher Völker, namentlich der Hemikunoi, Libyes, Aithiopes, Katoudaioi, Pygmaioi, Melanokhrotoi, Skythes, Laistrygones und Hyperboreoi.

In Homers "Odyssee" bringt sie den Tityos hervor und in der "Ilias" zeugt sie mit Hephaistos den Erichthonios. Der Epiker Eumelos nennt als Nachkommen der Gaia mit Uranos die Kyklopen und die Hekatoncheiren In den Texten der Orphiker zeugt sie mit Hydros, aus dem sie selbst hervorging, den Kronos und die Ananke.

In der archaischen Lyrik werden ebenfalls Nachkommen der Gaia genannt. Bei Alkaios stammen die Phaiaken von ihr ab, bei Simonides der Ätna und bei Bakchylides wird Aristaios genannt. In einem anonymen Fragment werden die Kabiren, Dysaules, Pelasgos, Alalkomeneos und Jarbas genannt.

Der Tragödiendichter Aischylos nennt als Nachkommen der Gaia in seinem Stück "Der gefesselte Prometheus" den Riesen Argos, den Titanen Prometheus., sowie die Titanen Okeanos, Kronos und Tethys Zephir wird in "Agamemnon" genannt und Themis und Phoibe in den "Eumeniden". In dem Stück "Die Schutzflehenden" nennt er noch Palaichthon.

Nach Apollonios gebiert Gaia den Drachen Cholkykos, nach Kallimachos ist sie mit Hephaistos die Mutter des Erichthonios und bei Strabon werden die Korybanten als Kinder genannt. Nach Diodor zeugt sie mit Uranus die Titanen, deren Namen die aus der "Theogonie" sind, sowie die nicht namentlich genannten Kyklopen und Hekatoncheiren und sie gebiert die Korybanten.

Stammbaum nach Hesiods Theogonie

Vergil nennt in seinem Epos "Aeneis" Enkelados und Koios, sowie Pheme und Tityos als Nachkommen. Nach Ovids "Metamorphosen" gebiert sie den Python und von einem Regenguss befruchtet die Korybanten. Nach den "Fasti" gebiert sie den Ophiotaurus und wird von einem Ochsenfell befruchtet, das mit dem Urin von Zeus, Poseidon und Hermes vollgesogen ist und bringt daraus den Orion hervor.
Im "Thebais" von Statius ist Gaia die Mutter des Drachen Nemeios

In der "Bibliotheke des Apollodor" zeugt sie mit Uranos die Titanen, Kyklopen und Hekatoncheiren, die auch dieselben Namen tragen, wie bei Hesiod. Als weiterer Titan wird Dione genannt. Wie bei Hesiod wachsen aus ihr die Erinyen und die Giganten aus dem Blut des Uranos hervor, erhalten hier jedoch Namen. Die Erinyen heißen Tisiphone, Megaira und Alekto und die Giganten sind Alkyoneus, Porphyrion, Enkelados, Ephialtes, Eurytos, Klytios, Mimas, Pallas, Polybotes, Hippolytos, Agrios und Thoon. Von Okeanos bekommt sie den Triptolemos, von Tartaros den Typhon und die Echidna, von Poseidon den Antaios und von Hephaistos bekommt sie den Erichthonios. Aus sich selbst bringt sie den Orion und den Argos hervor.

Nach Hyginus "Praefatio" zeugt sie mit Aither den Pontos und den Tartaros sowie die Titanen und die Erinnyen. Die Erinnyen heißen bei ihm Briareos, Gyes und Steropes, von den Titanen nennt er Okeanos, Themis, Hyperion, Koios, Kronos, Rhea, Mnemosyne, Dione, Atlas und Polos.
Mit Tartaros zeugt sie die Giganten Enkelados, Koios, Astraios, Peloros, Pallas, Emphytos, Rhoikos, Agrios, Ephialtes, Eurytos, Theomises, Theodamas, Otos, Typhon, Polybotes und Iapetos.
Als weitere Kinder Gaias mit Aither nennt er Dolor, Dolus, Ira, Luctus, Mendacium, Justiurandum, Ultio, Intermperantia, Altercatio, Oblivio, Socordia, Timor, Superbia, Incestum und Pugna. Nach Hyginus "Fabulae" zeugt sie mit Poseidon den Antaios und gebiert den Kekrops. Zudem wird sie wie bei Ovid von einem Ochsenfell befruchtet und bringt den Orion zur Welt. Nach Hyginus "Astronomica" bringt Gaia den Skorpios zur Welt.

In Pausanias "Reisen in Griechenland" wird sie als Mutter des Anax und des Hyllos sowie des Areion genannt.
Bei Antoninus Liberalis ist sie die Mutter des Kekrops und bei Flavius Philostratos mit Poseidon die des Antaios. Bei Athenaios ist sie Mutter des Sykeus

In der "Dionysiaka" des spätantiken Epikers Nonnos werden als Nachkommen Silenos, Tityos und Argos sowie die Korybanten und die Daktylen genannt. Als Mutter der Giganten erscheint sie im Zusammenhang mit den Giganten Alpus und Damasen.
Mit Zeus zeugt sie die Zyprischen Kentauren. und den Orion, wie bei Ovid und Hyginus befruchtet von einem Ochsenfell

Stammbaum nach Pseudo-Apollodors Bibliotheke

Gaias Bedeutung in der Mythologie wie im Kult liegt hauptsächlich in der Vorstellung der Griechen über die Erde begründet. Aus dieser Vorstellung leitet sich sowohl Gaias Hauptbedeutung als Muttergottheit ab, die alles Lebende hervorbringt und ernährt, als auch die einer Todesgottheit, die den Menschen nach dessen Tod in ihren Schoß aufnimmt. Sie wurde aber auch als Rachegottheit und Orakelgottheit aufgefasst.

Als segenspendende Erdgöttin wird Gaia bereits in einer der Homerischen Hymnen besungen und auch entsprechend kultisch verehrt. In den Mythen und ihren Darstellungen ist dieser Aspekt der bedeutendste.
Gaia ist seit Hesiod die Urgöttin in der theogonischen Dichtung. Von ihr stammen die Beherrscher der Welt ab, die Titanen und aus denen die Olympischen Götter, sowie deren Herausforderer die Giganten und Typhon. Dazu ist sie die Mutter des personifizierten Himmels Uranos und des Meeres Pontos und damit die Ahnin eines großen Teils der griechischen Götterwelt.
Ihre bereits im Alten Orient angelegte Funktion als Muttergöttin behält sie im Grunde die ganze Antike über bei, wenn auch Abwandlungen stattfanden. So werden ihr und ihrer Göttergeneration in den Theogonien der Orphiker frühere Wesen vorgeschaltet oder seit dem Derveni-Papyrus Nyx stärker betont. Die Darstellung der Gaia ist bei Hesiod ausgeprägt anthropomorph, spätere Dichter stellen sie, besonders bei der Verbindung von ihr mit Uranos, als Naturallegorie dar.

Als Todesgöttin ist sie in Attika nachweisbar. In "Die Perser" von Aischylos bittet der Chor die Königin, Spenden in die Erde zu gießen während König Xerxes die chthonischen Götter Gaia, Hermes und Hades anfleht, den Schatten seines Vaters Dareios wieder hinaufzusenden. Im Kult und in Darstellungen zeigt sich diese Bedeutung etwa in Fruchtopfern nach Begräbnissen, in Reliefs auf Sarkophagen oder Idolen in attischen Gräbern.

Als rächende Gottheit erscheint sie, wenn Eide auf ihren Namen abgelegt werden, da dies nur bei Göttern geschah, von denen bei Eidbruch Rache zu erwarten war. In der griechischen Religion werden die Schatten der Verstorbenen unter der Erde gerichtet, weshalb Eide besonders auf Gottheiten mit Bezug zur Erde geleistet wurden. In Aischylos' "Choephoren" werden Hermes, alle chthonischen Götter und schließlich Gaia von Elektra angefleht, Rache an Aigisthos für den Tod ihres Vaters zu üben.
Nach Pausanias befand sich eine Gaia-Statue am Areopag, an der ihr die Freigesprochenen ein Opfer darbrachten.

Als wahrsagende Gottheit erscheint Gaia bereits in Hesiods "Theogonie", als sie dem Kronos sein Schicksal voraussagt. Sie galt als ursprüngliche Inhaberin der meisten chthonischen Orakel, da davon ausgegangen wurde, dass aus der Erde aufsteigende Dämpfe die Priesterinnen erst zu ihren Orakelsprüchen befähigt haben.

Die ältesten gesicherten Darstellungen der Gaia finden sich auf attisch-schwarzfigurigen Vasen aus der zweiten Hälfte des 6. Jahrhunderts v. Chr. Sie zeigen sie in voller Figur als flehende Mutter in Darstellungen der Gigantomachie und in Darstellungen des Kampfes zwischen Apollon und Tityos.

In Darstellungen der Gigantomachie wird sie nur abgebildet, wenn auch ein Großteil der Olympischen Götter gezeigt wird. Auf Fragmenten schwarzfiguriger Vasen sind Teildarstellungen von ihr erhalten, aus denen sich ihre Gesamtdarstellung erschließen lässt. Auf zwei Fragmenten sind ihre Füße zu sehen, auf einem ihre Arme und Hände und auf dem letzten das Gesicht. Sie trägt einen Peplos und befindet sich in einer zentralen Gruppe olympischer Götter um Zeus, der den Streitwagen besteigt. Die Gruppe bewegt sich nach rechts, Gaia steht links neben dem Wagen, beugt sich zu Zeus vor und berührt von unten dessen Bart.

In Darstellungen des Kampfes von Apollon und Tityos gilt sie in drei Fällen als gesichert abgebildet und in fünf weiteren Darstellungen ist ihre Zuschreibung unsicher. Einmal ist sie namentlich genannt, sie steht zwischen Apollon und Artemis auf der einen und Tityos auf der anderen Seite und greift durch Heben ihres Arms in den Kampf ein. In den beiden anderen als gesichert geltenden Abbildungen ist auf Tityos Seite noch Leto zu sehen, Gaia steht zwischen den Kontrahenten. Sie hält ihren Schleier Apollon zugewandt in der Weise, wie eine Braut ihrem Bräutigam gegenübertritt. Der mythologische Hintergrund der Szene ist unklar. Auf den beiden als unsicher geltenden Darstellungen aus dem 6. Jahrhundert kann es sich bei der neben Tityos stehenden Frauengestalt auch um Leto anstatt Gaia handeln. Gegen die Zuordnung Gaias zu den drei rotfigurigen Darstellungen spricht in erster Linie die Darstellung als volle Figur, die nicht der Darstellungskonvention Gaias im 5. Jahrhundert entspricht, auch hier wird die Darstellung Letos vermutet.
Im 5. Jahrhundert wird Gaia nicht mehr als volle Figur abgebildet, sondern als Torso, der aus dem Boden aufsteigt. Die ersten bekannten derartigen Darstellungen zeigen sie im Zusammenhang mit der für die athenische Aitiologie bedeutenden Geburt des Erichthonios. Gaia steigt aus dem Boden, um Athena den Erichthonios zu übergeben, meist in Gegenwart Kekrops und weiteren Personen, manchmal in Gegenwart von Hephaistos. Auf der ältesten dieser Vasen ist sie ab der Taille abgebildet und reicht der auf sie zuschreitenden Athena das Kind, daneben stehen Kekrops und Hephaistos. Sechs der neun weiteren attischen Vasen sind rotfigurig, die Darstellung wird jeweils nur leicht variiert. Zwei Darstellungen variieren nur die Anwesenden, zwei zeigen sie schon weiter aufgestiegen ab den Knien beziehungsweise der Hüfte und bei einer ist die Übergabe des Kindes bereits vollzogen. Bis auf die letzte Darstellung ist sie immer frontal abgebildet. Von drei schwarzfigurigen Loutrophoroi sind Fragmente mit diesem Motiv erhalten. Die Darstellung auf diesen Kultgefäßen, die zu Hochzeiten und Begräbnissen genutzt wurden, steht wahrscheinlich in Bezug zu Gaias Heiligtum auf der Akropolis, bei dem ihr Voropfer dargebracht wurden.

Neben attischen Vasen findet sich das Motiv auf einem Kantharos aus dem Osten Griechenlands, auf drei Steinreliefs und einem melischen Relief sowie auf einem Stater von Kyzikos. Die Steinreliefs stammen aus der römischen Epoche, es wird jedoch angenommen, dass es sich bei ihnen um Reproduktionen des um 420 v. Chr. errichteten Frieses am Fuß der Kultstatuen handelt, die sich im Hephaisteion befanden. Auf dem melischen Relief ist Gaia von den Schultern aufwärts zu sehen und zeigt die Szene gegenüber anderen Darstellungen spiegelverkehrt, woraus geschlossen wird, dass es mithilfe eines Abgusses angefertigt wurde. Gefunden wurde das Relief in einem athenischen Grab. Auf dem Stater ist sie mit Erechthonios von den Hüften an aufwärts zu sehen. Das Motiv der aus dem Boden aufsteigenden Gestalt wurde in der Klassik losgelöst von Gaia im Kontext der Geburten Aphrodites, Pandoras und Persephones verwendet.

Das Motiv wird in der Klassik auch zur Darstellungen Gaias in der Gigantomachie übernommen. Auf einer Schale ist sie am Rand einer Schlachtenszene mit leicht erhobenen Armen ab den Oberschenkeln zu sehen und auf einem Krater, auf dem wegen der ausführlichen Darstellung der Schlacht vermutlich die Bemalung des Parthenos-Schildes wiedergegeben ist, erscheint sie am Rand mit voll erhobenen Armen. Die Giganten befinden sich durchgängig auf einer niederen Ebene als die Götter, die vom Himmel herab kämpfen.
Im Hellenismus erscheint Gaia meist in groß angelegten Darstellungen der Gigantomachie. Auf dem Ostfries des Pergamonaltars ist sie als Torso dargestellt, der sich jedoch nicht am Rand des Kampfes befindet, sondern ähnlich wie in den frühesten Darstellungen inmitten einer Kampfszene. Das Gleiche ist für das Fries aus dem Athenaheiligtum in Priene festzustellen. Auf einer etruskischen Relief-Urne steht sie schützend hinter einem am Boden liegenden Giganten. Da der Körper des Giganten ihren unteren Teil bedeckt, ist unklar ob sie als ganze Figur oder als aufsteigender Torso gedacht wurde.

In der römischen Kunst erscheint sie auf den oben genannten Reproduktionen des Hephaisteion-Frieses und in wenigen anderen Darstellungen, auf denen sie namentlich genannt wird. In weiteren Darstellungen des Gaia-Motives, bei denen die namentliche Zuordnung nicht möglich ist, wird die Darstellung von Tellus angenommen.

Eine kultische Verehrung der Gaia gab es in erster Linie in Athen, wo sie auch als Kurotrophos verehrt wurde. Ein ständiger Kult ist von Athen abgesehen in der Regel nur an entlegenen Orten oder an Orakelstätten zu finden. Verehrt wurde sie meist in ihrer segenspendenden Bedeutung als Muttergottheit, aber auch als Todesgottheit und als rächende Gottheit.
Der vermutlich älteste Kultort ist das Temenos der Ge Olympia in Athen. Es befand sich im Peribolos des Hieron des Zeus Olympios neben einem Tempel des Kronos und der Rhea. In dem Temenos befand sich ein Erdspalt, in den sich die Deukalionische Flut verlaufen haben soll und in diesen wurde jährlich ein Opferbrei aus Honig und Weizenmehl geworfen.
Als Kurotrophos hatte sie einen Altar im Pandroseion, dem Heiligtum des Pandrosos auf der Akropolis. Mit Pandrosos und Athena Polias bildete Ge Kurotrophos dort eine Trias, der von den athenischen Amtsträgern geopfert wurde. Wahrscheinlich wurden für sie und Pandrosos dort an den Panathenäen je ein Stuhl aufgestellt, um sie an den Feierlichkeiten teilhaben zu lassen. Einen Tempel hatte sie neben dem Tempel der Demeter Chloe unterhalb des Niketempels.

Gaia Kurotrophos wurde in Athen als Ernährerin der Kinder verehrt, von denen sie deshalb durch Tänze gefeiert wurde. König Erichthonios soll eingeführt haben, dass ihr deshalb vor jedem Opfer ein Voropfer gebracht wird, das vermutlich auch aus Getreide und Honig bestand.
Weitere Opfer wurden der mütterlichen Gaia zu Hochzeiten und Festen dargebracht. Der rächenden Göttin wurden von Freigesprochenen an ihrer Statue am Areopag geopfert und der Todesgöttin bei Begräbnissen, geopfert wurden ihr hierbei Früchte. Ebenfalls Früchte wurden ihr an dem chthonischen Fest Genesia geopfert und ein Getreideopfer wurde ihr zur Procharisteria dargebracht. Zu den Thesmophorien wurde sie als Kurotrophos angerufen.
In Delphi galt Gaia als erste Inhaberin des Orakels, bis sie es an Themis, der Inhaberin vor Apollon, abtreten musste. Es wurde davon ausgegangen, dass die Pythia durch aus der Erde aufsteigender Dämpfe inspiriert sei, womit Gaia als erste Inhaberin zu erklären ist. Einen Tempel hatte sie der Nähe des Apollonheiligtums, wo sie den Beinamen Eurusternos trug.

Die Priesterin des noch in später Zeit besuchten Orakels bei Aigai sollen, um Gaia um Rat zu fragen, Ochsenblut getrunken und in eine Höhle hinabgestiegen sein. Hier hatte sie einen Tempel, in dem ein altes Xoanon stand. Die Priesterin des Tempels durfte nur mit einem Mann verkehrt haben und musste danach zölibatär leben.

In Olympia befand sich ein Aschenaltar neben einem Altar der Themis, der nach Pausanias zuvor ein Orakel gewesen war. Sie soll auch neben Zeus im Orakel von Dodona verehrt worden sein und möglicherweise ist ihr noch der frühere Besitz des Trophoniosorakels von Lebadeia zuzurechnen.

In der historischen Zeit ist Gaia als Orakelgottheit außer im Orakel von Aigai von Zeus und Apollon verdrängt worden. Möglich ist auch, dass manche Orakelorte durch ihre Bezugnahme auf Gaia ihren Anspruch auf Alter und Authentizität ausdrücken wollen, ohne dass Gaia dort tatsächlich ein Orakel geweiht gewesen war.

Im attischen Demos Phlya, wo sie mit Beinamen Megale als Naturgottheit verehrt wurde, hatte Gaia einen Altar. Auch wurden hier Orgien für sie gefeiert, die älter als die Mysterien von Eleusis gewesen sein sollen. In einem Heiligtum in Patrai wurde sie sitzend dargestellt, während die Fruchtbarkeitsgöttinnen Demeter und Kora neben ihr standen. Ein weiteres Heiligtum befand sich auf der Agora von Lakedaimon und ein weiterer Altar in Tegea neben einem Tempel der Geburtsgöttin Eileithyia.

Da sie vor allem in ihrer Bedeutung als Muttergöttin verehrt wurde, bestanden die ihr dargebrachten Opfer in der Regel aus Getreide, Früchten oder Honig und vereinzelt aus Tieropfern. Als Rachegöttin wird ihr allein in der "Ilias" vor dem Kampf zwischen Paris und Menelaos ein schwarzes Lamm geopfert. In Attika wurde ihr zu Hochzeiten und zu Begräbnissen geopfert und bei Trockenheit wurde sie nach einer Inschrift auf der Akropolis anstatt der Vegetationsgöttin Demeter als Gaia Karpophoros als Vermittlerin zu Zeus angerufen. Die Einführung des Opfers bei Begräbnissen wird von Cicero dem Kekrops zugeschrieben. In der attischen Tetrapolis wurden ihr im Monat Poseideon eine trächtige Kuh, im Gamelion ein Schaf und am 10. Elaphebolion ein schwarzer Bock geopfert.
Aus Mykonos ist überliefert, dass dort jährlich am 12. des Monats Lenaion (Januar–Februar) Opfer an Dionysos Lenaios, Zeus Chthonios und Ge Chthonia gebracht wurden. Fremde durften an diesem Opfer nicht teilnehmen.

Als Kultnamen der Gaia sind überliefert:

Bis zur Moderne haben bildende Künstler sich mit Gaia beschäftigt und versucht, ihr eine Form zu geben.
In Anlehnung an die griechische Mythologie nannten die Wissenschaftler Lynn Margulis und James Lovelock ihren Denkansatz, die Erde mit einem Organismus gleichzusetzen, Gaia-Hypothese. Diese Wahl hat sicherlich zur großen Popularität der Hypothese beigetragen, führte jedoch auch zu esoterischen Auslegungen, von denen sich die Autoren distanziert haben.




</doc>
<doc id="2049" url="https://de.wikipedia.org/wiki?curid=2049" title="Nordische Mythologie">
Nordische Mythologie

Als nordische Mythologie bezeichnet man die Gesamtheit der Mythen, die in den Quellen der vorchristlichen Zeit Skandinaviens belegt sind.

Die nordischen Mythen sind zum Teil den kontinentalgermanischen Mythen sehr ähnlich. Man geht heute allgemein davon aus, dass die Göttergesellschaft ursprünglich dieselbe war. Gleichwohl haben sich Kulte, Namen und Mythen in den verschiedenen Räumen im Laufe der Zeit auseinanderentwickelt.

Die nordische Mythologie basierte nie auf einer religiösen Gesellschaft oder auf einem zusammenhängenden religiösen System. Sie war also nie so etwas wie eine Religion im modernen Sinn. Es gab auch keine Instanz, die die Glaubensinhalte festlegte. Die Mythen waren eher ein theoretischer Überbau für bestimmte Kultformen und hatten wenig mit Glauben in unserem Sinne zu tun. Gleichwohl finden sich immer wieder Versuche in der Forschung, zu ermitteln, was der „ursprüngliche“ und „echte“ Glaubensinhalt gewesen ist. Ein solches Qualitätsurteil lässt sich kaum treffen, zumal eine Religion immer als „echt“ von dem erlebt wird, der sie ausübt.

Es gibt nur sehr wenige schriftliche Zeugnisse aus der Zeit der mythischen Kulte. Es handelt sich dabei um die in Metall oder Stein geritzten Runen. Die meisten Quellen stammen hingegen aus römischen und christlichen Schriften. Diese stammen weder aus erster Hand, noch sind sie neutral. Die zusammenhängende Darstellung und der enzyklopädische Charakter der Völuspá werden nicht der vorangegangenen oralen Tradition zugerechnet. Man muss auch berücksichtigen, dass die skandinavischen Dichter Elemente der christlichen Religion verwendet haben, ohne deren Inhalt zu übernehmen.

 Andeutungen über religiöse Vorstellungen der Vorzeit lassen sich auch aus bronzezeitlichen Artefakten ablesen. Bekannt sind schalenförmige Eintiefungen in Felsen, die mit Opfern in Verbindung gebracht werden. Felsritzungen lassen auf schamanistisch-magische Praktiken schließen. Ob die Mythen inhaltlich irgendetwas mit dem zu tun haben, was auf uns überkommen ist, lässt sich nicht feststellen. Das Rad mit vier Speichen als Felsritzung lässt manche auf einen Sonnenkult in der Bronzezeit schließen, für den eine mythische Grundlage aber nicht überliefert ist. Das Gleiche gilt für Miniaturäxte, die mit dem Blitz in Verbindung gebracht werden. Der Sonnenwagen von Trundholm, ein 1902 auf Sjælland in Dänemark gefundenes 57 cm langes Bronzemodell eines von Pferden gezogenen Wagens, der in die Zeit von 1500 bis 1300 v. Chr. datiert wird, belegt jedenfalls keinen Sonnenkult.

Es ist aus religionsphänomenologischer Sicht nicht völlig sicher, dass mit den steinzeitlichen Religionen bereits Götter als lebende Wesen verbunden waren. Es ist auch gut möglich, dass Naturelemente wie Blitz, Bäume, Steine, Erde und Wasser selbst als lebendig betrachtet wurden. Götter als Personen sind in der Bronzezeit durch Felszeichnungen und Bronzefiguren belegt. Nun werden in großer Zahl kleine Boote aus Gold und andere Gegenstände angetroffen, die auf Opfer schließen lassen. Opfergefäße auf Wagen deuten auf Fruchtbarkeitskulte hin, die mythologisch bereits mit der nach Tacitus pangermanischen Gottheit Nerthus in Verbindung gebracht werden.

Die Feuerbestattung, die in der zweiten Hälfte des 2. Jahrtausends v. Chr. üblich wurde, wird als Mittel der Befreiung der Seele vom Körper für ein jenseitiges Leben gedeutet.

Ab dem 4. Jahrhundert n. Chr. finden sich Schiffsbestattungen in verschiedensten Formen. Menschen werden in voller Kleidung und mit reichen Beigaben bestattet. Man findet Münzen wohl analog zum Obolus aus der griechischen Mythologie im Mund des Toten, mit dessen Hilfe er die Überfahrt der Seele ins Totenreich bezahlen soll. Dass das gleiche sehr spezielle Motiv zu dieser Zeit unabhängig vom kontinentalen Kulturkreis entstanden sein sollte, darf als unwahrscheinlich gelten, so dass von einer Motivwanderung von Süden nach Norden ausgegangen werden kann.

Weitere Quellen sind die skandinavischen Brakteaten mit Götterdarstellungen und Runeninschriften sowie Votivgaben aller Art.

Alle diese archäologischen Zeugnisse bedürfen für ihre konkrete Deutung der Schriftquellen. Als Snorri Sturluson sein Skaldenlehrbuch um 1225 schrieb, war der geschilderte mythologische Stoff von Skandinavien bis Bayern bekannt. Er schildert zum Beispiel die Midgardschlange als ein Tier, das um alle Lande herum im Meer liegt und sich selbst in den Schwanz beißt. Dieser Text deutet die Darstellung der sich in den Schwanz beißenden ringförmigen Schlange auf dem Goldmedaillon von Lyngby aus dem 5. Jahrhundert, auf dem englischen Steinkreuzfragment von Brigham aus dem 8. Jahrhundert, auch den Ring in einem Pfeilerdienst der Neuwerkkirche in Goslar aus dem 12. Jahrhundert und auf dem spätromanischen Taufbecken von Fullösa in Schonen. Seine Überlieferung ist der wichtigste Schlüssel zur germanischen Ikonografie der Mythen. Bildliche Darstellungen, die keiner textlichen Überlieferung zugeordnet werden können, wie dies für die Felsritzungen der Bronzezeit gilt, sind über den konkreten Gegenstand der Darstellung hinaus nicht zu interpretieren.

Die ältesten Quellen über Mythen nördlich der Alpen stammen aus dem 1. Jh. n. Chr. und wurden von Tacitus überliefert. Andere Quellen sind Votivsteine germanischer Soldaten in römischen Diensten. Sie sind häufig schwer verständlich, weil sie sehr kurz sind und die Kenntnis über mythische Zusammenhänge bereits voraussetzen. Außerdem bezeichnen sie die germanischen Götter in der Regel mit den lateinischen Namen der entsprechenden römischen Gottheiten. Als weitere Quellen kommen Verfasser wie Prokop, Jordanes, Gregor von Tours, Paulus Diaconus und Beda Venerabilis hinzu und Beschlüsse von Kirchensynoden und Gesetze, insbesondere von Burchard von Worms, päpstliche Rundschreiben und Predigten. Sie lassen Rückschlüsse auf die religiöse Praxis des einfachen Volkes auf dem germanischen Kontinent zu, an die sich dann Nachrichten über spätere Zeiten anschließen.

Außerordentlich selten sind Quellen in einer germanischen Sprache, wie die "Merseburger Zaubersprüche", der Text auf der Nordendorfer Spange, die angelsächsischen Stammtafeln, Glossen mit Personen und Ortsnamen und die Andeutungen in den Heldensagen. Alle diese Quellen betreffen aber Mythen und religiöse Praktiken der kontinentalen Germanen, und die Schlüsse daraus lassen sich trotz der Verwandtschaft nicht ohne weiteres auf Skandinavien übertragen.

Skandinavien ist mit schriftlichen Quellen reicher gesegnet, in aller Regel in altisländischer Sprache. Allen voran steht die "Lieder-Edda", die "Prosa-Edda" des Skalden Snorri Sturluson, wobei bei seinen Texten immer beachtet werden muss, dass sie in einer bereits christlich geprägten Kultur verfasst worden waren. Aber auch andere Skalden- und Prosatexte sowie lateinische Berichte wie die des Adam von Bremen, des Thietmar von Merseburg, des Saxo Grammaticus, die "Vita Ansgarii" des Rimbert. Sogar in der samischen und in der finno-ugrischen Mythologie finden sich Gestalten, die nordgermanische Entsprechungen haben: Hora-galles entspricht dem Thor, Väralden olmai (isl. veraldar guð, Frey), Biegga-galles (Windgott, Sturmgott, Njörd oder Odin). Der schamanistische Odin und die Art wie er seine besondere Sehergabe erhält, ist höchstwahrscheinlich finno-ugrischen Ursprungs.

Es ist umstritten, ob das, was die gelehrten norwegischen und isländischen Quellen über die nordische Mythologie berichten, auf Einflüsse der griechischen Mythologie und des christlichen Gedankengutes zurückzuführen ist. Es hat sicherlich nicht zum Glauben im Volke gehört. Einiges kann auch auf Missverständnissen christlicher Verfasser über mythische Vorstellungen und Zusammenhänge beruhen. Sørensen meint, dass die Lieder–Edda genuin heidnische Tradition wiedergibt: Zum einen enthalte die Darstellung der Götter keinen Bezug zum Christentum, auch nicht zu christlicher Moral. Zum anderen betont Snorri selbst den scharfen Unterschied zwischen dem, was er niederschreibt und dem Christentum: Snorri verstand also seine Überlieferung als echt heidnisch und für Christen nicht ungefährlich. Ein Einfluss lässt sich insbesondere für die Einrichtung von „Tempeln“ vermuten, die in lateinischen Texten erwähnt werden. Denn es gibt kein entsprechendes Wort für das lateinische Wort "templum" in norrön, und es sind auch nicht die leisesten archäologischen Spuren heidnischer Gotteshäuser gefunden worden. Daher lässt sich nicht mit Sicherheit sagen, welchen Gegenstand die Verfasser mit dem Ausdruck "templum" belegt haben.

Alles spricht für einen Opferkult unter freiem Himmel mit Gelage im Wohnhaus des Goden. Allerdings sind für das Festgelage auch große Hallen nachgewiesen (z. B. Borg auf den Lofoten mit 74 m Länge, Gudme auf Fünen und Lejre auf Seeland mit 47 m). Auch die Ortsnamen auf -hov deuten auf solche zentralen Kultstätten hin. Nach allem, was man weiß, dürfte der Gebäude-Tempel in Uppåkra eine Ausnahme gewesen sein. Der Glaube im Volk über die Seelen der Verstorbenen und die Naturereignisse entspricht im Wesentlichen dem, was in ganz Europa geglaubt wurde, was auch durch den übereinstimmenden Volksglauben in jüngerer Zeit und auch die ähnliche Nomenklatur für Alben, Zwerge, Nachtmare, Wichtel und Nöck bestätigt wird. Nachrichten über solche Gemeinsamkeiten im Glauben der frühen germanischen Zeit finden sich in dem gemeinsamen Zug, über Bäume und Flüsse hinaus auch die Sonne, den Mond und das Feuer zu verehren. Eine systematische Mythologie, die dem Volksglauben zu Grunde liegt, lässt sich aus den Quellen aber nicht entwickeln. Die Traditionen waren auch nicht einheitlich. So schreibt Snorri z. B. in Gylfaginning über Odin: und kurz darauf: Hier hat Snorri also zwei unterschiedliche Traditionen über die Eltern von Jörð unverbunden nebeneinander gestellt. Auch stehen ein vertikales Weltbild mit Göttern im Himmel und ein horizontales Weltbild mit dem Wohnsitz der Götter im Mittelpunkt der Erdscheibe nebeneinander. Baldur wohnt in Breiðablik, Njörd in Noatún und Freya in Folkwang, alle im Himmel lokalisiert. Andererseits heißt es, dass die Asen eine Burg Asgard mitten in der Welt bauten und dort wohnten. Es wird sowohl vertreten, dass beides unterschiedliche heidnische Traditionen seien, als auch, dass das vertikale Weltbild einen christlichen Einfluss widerspiegle.

Die neuere Forschung sieht den Einfluss des Christentums weniger in einem Eindringen christlicher Motive in die heidnischen Mythen als vielmehr in der Darstellungsweise. Snorri Sturluson war in mitteleuropäischem Denken mit genauen Definitionen und Kategorien geschult. Das hat auf die Darstellung des Stoffes abgefärbt. Hennig Kure hat dies an einem Beispiel aufgezeigt: Snorri beruft sich in Grímnismál auf die ältere Gylfaginning. Dort heißt es in den Strophen 25 und 26:

Snorri paraphrasiert diese Quelle nun in Gylfaginning folgendermaßen:

Die Unbestimmtheit des Mythos wird bei Snorri eindeutig gemacht. Das Wort „á“ in der zweiten Zeile, das „auf, neben, nahe bei“ bedeuten kann, wird bei Snorri zu „uppi“ – „obendrauf“. Der nicht näher identifizierte „Lærað“ wird als Baum definiert. Gylfaginning sagt nicht, was die Ziege von den Zweigen frisst, Snorri legt es fest: Es sind Blätter. Auch woraus der Met rinnt, klärt erst Snorri. Der Met geht bei Gylfaginning nie aus. Snorri ergänzt, dass die Einherjer volltrunken werden. In Gylfaginning hat alles Wasser seinen Lauf von den Tropfen aus dem Hirschgeweih. Snorri zählt alle Flüsse auf. Nichts bleibt in mythischer Schwebe, alles wird genau festgelegt. Darin sieht Kure und die von ihm zitierte Forschung den Haupteinfluss christlicher Bildung auf die Darstellung der heidnischen Mythen und weist darauf hin, dass auch die gegenwärtige Forschung auf diese Mythen durch die Brille Snorris blickt.

Als weitere schriftliche Quellen können Inschriften gesehen werden. Sie sind auf Brakteaten, Weihe-, Votiv- und Bildsteinen zu finden.

In Skandinavien wurde bei den Göttern Frey, Freya, Njörd und den Asen, vor allem bei Thor geschworen. So rief Egil Skallagrimsson in der "Egils saga" 934 einen Fluch von Odin, Frey und Njörd herab, und in "Skírnismál" werden Flüche im Namen Odins, Thors und Freys beschworen. Für Trondheim sind für das 10. Jh. Trinksprüche beim Opfer für Odin, Njörd und Frey überliefert. Die "Flateyjarbók" nennt ebenfalls Odin, Frey und die Asen. Auch Adam von Bremen nennt Wodan, Frey und Thor als Götter im Zusammenhang mit dem Opferfest von Uppsala. Thor wird auch im Tempel von Håkon Jarl in Lade erwähnt.

Aus der Überführung römischer Wochentage in eine germanische Nomenklatur lässt sich entnehmen, welche germanischen Götter als Entsprechung zu den römischen gesehen wurden. "Dies mercurii" wurde zu "onsdag" (Mittwoch), dem Tag des Wodan/Odin, denn beide führten die Toten zu ihrer neuen Wohnstatt. "Dies Jovis" wurde zu "Thorsdag" (Donnerstag), was eine Entsprechung von Jupiter und Thor beinhaltet. Thor konnte auch mit Herkules identifiziert werden. Was dem einen die Keule war, war dem anderen der Hammer. "Dies Martis" wurde in "Tisdag" (Dienstag) verwandelt, womit Mars und Tyr, ein sehr alter Kriegsgott, in Entsprechung gesetzt wurden.

Nach Tacitus verehrten gewisse germanische Völker die Göttin "Nerthus", der im Norden der Gott Njörd entspricht. Es ist denkbar, dass die Göttin der Fruchtbarkeit bei den Sueben in der Nachbarschaft, die Tacitus als "Isis" bezeichnet, mit dieser Nertus identisch ist. Es ist auch unsicher, ob Frey, Freya und Ull in den Quellen überhaupt Eigennamen sind oder nicht vielmehr Bezeichnungen für Götter mit anderem Namen, wie dies bei "des Landes Gott" oder "Ásabraqr" für Thor bekannt ist („Þórr heißt Atli und Àsabragr“ heißt es in der "Prosa-Edda"). Es sieht nämlich so aus, als ob es urgermanisch eine Dreiheit von Hauptgöttern gegeben habe, einen Himmelsgott (erst "Tyr", später "Thor"), einen männlichen/weiblichen für die Erde, zu der auch das Meer gehörte, und der Fruchtbarkeit ("Nertus, Njörd, Frey, Freya") und einen unterirdischen Gott des Totenreiches ("Wodan, Odin"), die man in Krieg und Gefahr anrief.

Prokop berichtete im 6. Jh., dass die Einwohner Thules (Norwegen) eine große Zahl von Göttern und Geistern im Himmel, in der Luft, auf der Erde im Meer und in Quellen und Flüssen verehrten. Man opfere ihnen allen, aber dass "Ares" (Mars) – also Tyr – ihr höchster Gott sei, dem sie Menschen opferten. Das "sächsische Taufgelöbnis", das in einer Fuldaer Handschrift des 8. Jahrhunderts überliefert ist, ermöglicht, die Namen der für die Sachsen wohl wichtigsten Götter kennenzulernen. Es lautet: „Ich widersage allen Werken und Worten des Teufels, Thor, Wodan und Saxnot und allen Unholden, die ihre Gefährten sind“.

In den Merseburger Zaubersprüchen werden die Götter "Phol" (Balder), "Uuodan" (Wodan), "Sinhtgunt" (umstritten, aber wahrscheinlich der Mond), "Sunna" (Sonne), "Friia" (isl. Frigg auch Freya) und ihre Schwester "Uolla" (isl. Fulla) genannt.

Gewisse Götternamen treten oft gemeinsam auf, "Njörd, Tyr" und "Thor", oder "Freya, Ull" und "Thor". Nach der "Völuspá" ist die Welt von "Burrs" Söhnen "Odin, Vile" und "Ve" geschaffen, und die Menschen erhielten ihr Leben von "Oden, Höner" und "Lodur".

Auch die Ortsnamenforschung fördert alte Götternamen zu Tage: "Thor", "Njord", "Ull", "Frey", "Odin", "Tyr", "Frigg", "Freya", mit den schwedischen Beinamen "Härn" und "Vrind", möglicherweise auch "Vidar, Balder, Höder" und "Skade". Von den Namen der Göttergeschlechter kommen "gud, as, dis", wahrscheinlich auch "van" vor.

Man kann anhand der Votivtexte von einem ausgeglichenen und zuversichtlichen Verhältnis zu den schicksalbestimmenden Mächten bei der bäuerlichen Bevölkerung ausgehen. Ganz anders ist die von den Skalden überlieferte Mythologie, wie sie in den Edda-Liedern vorgetragen wurde. Hier herrscht ein tiefer Pessimismus vor.

Die Götterwelt der Germanen begründet sich auf drei Geschlechter, die alle aus dem Urchaos Ginnungagap und dem Urrind Audhumbla hervorgingen: Das Geschlecht der Riesen und Ungeheuer, zu denen praktisch alle bösen Wesen gehörten, die auch für Naturkatastrophen verantwortlich gemacht wurden, kam als erstes auf die Welt. Dieses Geschlecht hat die Macht, die Welt zu vernichten. Damit dies nicht passiert, wurden Wanen und Asen geschaffen. Sie halten alles im Gleichgewicht, bis sich das Schicksal der Götter in einem finalen Kampf erfüllt, infolgedessen es zu einem Krieg zwischen Riesen und dem Asen-Wanen-Bund kommt, dem sich die gefallenen Menschenkrieger anschließen und in dem die ganze Welt vernichtet wird, um wiedergeboren zu werden.

Die Wanen, das zweitälteste Geschlecht, wurden als äußerst geschickt, erdgebunden und weise verehrt und lebten ewig, sofern sie nicht erschlagen wurden. Die Asen, das jüngste Geschlecht, galten als äußerst mutig und stark, aber nicht sehr klug, was man auch in der Edda nachlesen kann. Ihr Ewiges Leben verdanken sie einem Trunk, der sie gewissermaßen abhängig von den Wanen machte.

Hauptgott der Asen war Odin, ursprünglich vielleicht Tyr. Hauptgott der Wanen war der Meeresgott Njörd bzw. dessen Zwillingskinder Freyr und Freya. Asen und Wanen fochten einen großen Krieg aus, bei dem die Asen als Sieger hervorgingen, wobei die Wanen weiterhin eine geachtete Stellung innehatten. Beide Geschlechter lebten versöhnt und nebeneinander, bis die Christianisierung der Germanen einsetzte. Daraus ergeben sich auch verschiedene Schöpfungsmythen: so ist sowohl Tyr als auch Odin Schöpfer der ersten Menschen. Odin war ursprünglich der Hauptgott der Westgermanen, wobei er sich nordwärts über ganz Europa verbreitete. Für die Nordgermanen spielte ursprünglich Nerthus eine große Rolle, doch schon früh verschmolz ihr Kriegsgott Wodan mit dem Kriegsgott Odin und wurde so zum Hauptgott. Auch die Ostgermanen übernahmen Odin schließlich als Hauptgott. Daher wird in der Nordgermanischen Religion Odin immer als oberster Gott angesehen.

Odin war der Gott über allen anderen Göttern. Odin war zuvorderst Kriegs- und Todesgott, und erst in zweiter Linie ein Weiser. Der Name „Odin“ leitet sich vom altnordischen Wort „óðr“ her, das „wild, rasend“ bedeutet. Daher war er der Gott der Ekstase und des rasenden Kampfes. Er war nicht ein nordischer, sondern ein gemeingermanischer Gott. Er war auch Hauptgott der Angeln, der Sachsen, die ihn Wodan nannten, was Inschriften bekräftigen. Die Sage um Odin reicht auch weit zurück, denn bereits die Römer wussten, dass die Germanen einen Gott verehrten, der ihrem Mercurius ähnelte. Odin hatte nur ein Auge, das andere hatte er dem Jöten Mimir verpfändet, der über den Brunnen der Weisheit am Lebensbaum Yggdrasil gebot, wofür er aus dem Brunnen trinken durfte – er opferte also sein körperliches Auge für ein geistiges, mit dem er Dinge sehen konnte, die anderen verborgen waren. Auch die Magie der Runen hatte er von Mimir gelernt. Nach der Völuspá hatte Odin einst den ersten Krieg verursacht: „In die Feinde schleuderte Odin den Speer. Das war der erste Kampf der Völker.“

Als Ekstatiker und Magier war Odin in der Lage, seine Gestalt zu wechseln. Woher dieser schamanistische Zug in Odin kommt, ist nicht bekannt, möglicherweise aus dem Osten, wo der Schamanismus verbreitet war.

Thor war vor allem der Gott der Bauern. Seine wichtigste Eigenschaft war seine gewaltige Kraft. Darüber hinaus hatte Thor seinen Hammer Mjölnir. Thor beschützte sowohl Götter als auch Menschen gegen die Jöten, die feindlichen Mächte in der Welt. Thors Kampf mit der Midgardschlange ist der Mythen liebstes Thema. Diese war ein eiterspeiender Wurm draußen im Ozean, der so lang war, dass er den Erdkreis umfasste.

Odin und Thor gehörten zu den Asen. Zu dieser Göttergruppe zählten auch Balder, Heimdall, Bragi und Ullr. Frigg, Odins Frau, Siv, die Frau Thors, und Idun waren Wanen. Daneben gab es noch Nornen, Folgegeister und Walküren. Sie alle hatten ihre Aufgabe und Rolle in der sozialen Weltordnung wie auch bei der Beschreibung von Naturereignissen. Die Nornen Urd, Verdandi und Skuld spinnen den Lebensfaden eines jeden Menschen. Die Folgegeister sind Geister, die die Menschen begleiten, die Walküren Odins Sendboten. Hinzu kommen weitere Wesen in der Natur: Zwerge, Elfen und Geister. Die Jöten waren die Hauptwidersacher der Asen. Sie symbolisierten die unbeherrschbaren Naturkräfte. Ihr Stammvater war der Urriese Ýmir, der der Urgrund der geschaffenen Welt war. Als Odin Ýmir tötete, entstanden aus seinem Blut Bäche, Flüsse und das Meer, aus seinen Knochen wurden die Steine, sein Fleisch die Erde und seine Haare das Gras und der Wald. Sein Schädel ist das Himmelsgewölbe. Die ersten Menschen, Ask und Embla, wurden allerdings von Odin erschaffen. Ein anderes Göttergeschlecht waren die Wanen. Zu ihnen gehörten Freyr und Freya sowie deren Vater Njörðr, der in Vanaheimr aufgewachsen war. Die Wanen waren Fruchtbarkeitsgötter. Zwischen Wanen und Asen gab es Krieg, der aber mit einem Bündnis endete. Es gibt Spekulationen über einen historischen Hintergrund, nämlich dass asengläubige Krieger wanengläubige Bauern unterworfen hätten oder einfach nur der Wanenkult von einem Asenkult abgelöst worden sei oder auch, dass hier verschiedene Lebensentwürfe gegeneinander gestellt werden sollten.

Der Kampf der Asen gegen die Jöten, der Kampf Gut gegen Böse, ist ein Gemeingut vieler Religionen. Aber im Unterschied zum Christentum siegt bei den Nordleuten nicht das Gute. Vielmehr sind der Untergang und der Tod der Götter (Ragnarök) vorbestimmt. Dass die Edda nach dem Untergang der Welt eine neue Welt erstehen lässt, ist möglicherweise auf christlichen Einfluss zurückzuführen. Im nordischen Heidentum der gebildeten Oberschicht gab es keine christliche Hoffnung; der Pessimismus dominierte.
Das Weltbild der Bewohner Skandinaviens war stark von ihren Mythen und Sagen geprägt, wobei unklar ist, wieweit deren Vorstellungen in der Bevölkerung verbreitet war. Die überlieferten Mythen beschreiben, was in der königlichen Hofgesellschaft, einer Kriegerkaste, vorgetragen wurde. Im Knotenpunkt der Welt lag Asgard, hier waren die kriegerischen Götter, die Asen, und die Wanen ansässig. Jeder von Ihnen hatte ein eigenes Domizil und so herrschte: Odin in Hlidskjálf, Balder auf Breiðablik, Freyja in Fólkvangr, Freyr in Álfheimr, Njörd in Nóatún, Thor in Thrúdheimr und Heimdall auf der Burg Himinbjörg. Das Reich der Götter und die Welt der Sterblichen wurde durch Bifröst, eine regenbogenartige Brücke, miteinander verbunden. In Midgard waren die Menschen heimisch. Ein riesiges Meer, welches eine gigantische Schlangenbestie, die einfach als Midgardschlange bezeichnet wurde, beherbergte, umgab sie. Weit in der Ferne lag die Außenwelt Utgard. Hier wohnten allerlei Ungeheuer und Riesen, die den Göttern und Menschen feindlich gesinnt waren und nur darauf warteten, am Tag des Ragnarök zuzuschlagen. Tief unter der kalten Erde wurde das Totenreich von der Göttin Hel bewacht. Hel war eine Gottheit, deren eine Körperhälfte eine betörende junge Frau widerspiegelte, während die andere Seite ein altes Skelett zeigte, welches als Symbol für alles Vergängliche stand. In Asgard wuchs auch der Weltenbaum, der als Yggdrasil bezeichnet wurde. Dieser überaus gigantische Baum war durch seine Wurzeln mit Midgard, Utgard und Helheim verbunden und hielt das Gefüge der Welt und ihre Ordnung zusammen. Vor der Weltenesche lag auch die Wasserquelle der Schicksalsgöttin. Der Weltenbaum war immensen Strapazen ausgesetzt: vier Hirsche zerrten an seinen Knospen, der Lindwurm Nidhöggr nagte an den Wurzeln und an einer Seite fraß sich schon die Fäulnis in den Baum des Lebens.

In der "Snorra-Edda" und in der "Ynglinga saga" hat Snorri Sturluson die in der älteren isländischen Poesie, besonders der "Lieder-Edda" vorgefundenen Mythischen Berichte ausgewertet. Es kann durchaus sein, dass er dabei nicht immer die heidnische Auffassung richtig wiedergegeben hat.
Es gibt noch weitere Mythen in der eddischen Dichtung.

"Genealogische Ursprungsmythen" sind Geschichtsmythen, die in der Regel die Herrschaft einer Königssippe zu legitimieren hatten.

Sæmundur fróði, Vater der isländischen Geschichtsschreibung (1056–1133), hat für die dänischen Könige einen Stammbaum von 30 Generationen konstruiert, die er auf die Skjöldungen und Ragnar Lodbrok zurückführte. Ihm folgte Ari fróði für Harald Schönhaar mit einer Ahnenreihe von 20 Generationen auf die mythischen Könige Schwedens, die von dem Gott Yngvi/Freyr, einem Hauptgott Uppsalas, abstammen sollten. Diese Mythenbildung hielt sich noch lange, indem die späteren Könige sich entweder auf König Harald oder auf König Olav den Heiligen zurückzuführen trachteten, obgleich sie genetisch sicher nicht von ihnen abstammten.

Das Gleiche ist in England zu beobachten. Frühe Genealogien gingen auf Wodan (Odin) und Frealaf zurück. Westsächsische Genealogien führen im "Life of King Alfred" (ca. 893/94) die westsächsischen Könige vor Alfred erstmals über Beaw, Scyldwa, Heremod, Itermon, Haðra, Hwala, Bedwig und Sceaf(ing) schließlich auf Adam zurück. Dies steht auch für den westsächsischen König Æthelwulf in der "Angelsächsischen Chronik", die im Jahre 892 begonnen wurde. Durch Angleichung der Genealogie an den "Beowulf" konstruierte die altenglische Geschichtsschreibung einen gemeinsamen Ursprung für Dänen und Angelsachsen. Im 12. Jh. erfolgte dann die mythische Anbindung an Troja und den König Aeneas. Vorher hatten bereits die Franken mit der mythischen Abstammung von den Trojanern ihre Rechtsnachfolge nach den Römern begründet.

Es gibt eine Gruppe von Geschichtsmythen, deren gesellschaftliche Funktion in der Identitätsstiftung eines Volkes besteht. Diese Mythen sind innerhalb des geschichtlichen Zeithorizonts auf Glaubwürdigkeit angewiesen, weshalb sie historische Personen mit mythischen Ereignissen in Verbindung bringen. Ein typisches Beispiel dafür ist die "Färingersaga". Aber auch das "Landnámabók" wird heute nicht mehr als historisch zutreffender Bericht über die Besiedlung Islands angesehen.

Man kann dazu auch die euhemeristische Umwandlung von Göttermythen in Geschichtsmythen für Völker rechnen wie die Ynglinga saga der Heimskringla.

Nach dem Prolog der "Heimskringla" von Snorri Sturluson war Odin kein Gott, sondern ein König. Nach ihm hat "König Odin" Saxland seinen drei Söhnen unterstellt: Ost-Saxland erhielt sein Sohn "Vegdeg", Westphalen erhielt "Beldeg" und Franken der Sohn "Sigi". Vegdegs Sohn sei "Vitrgils" gewesen. Dessen beiden Söhne seien "Vitta", der Vater von "Heingest" und "Sigarr", der Vater des "Svebdeg" gewesen. In angelsächsischen Quellen ist der erste Urkönig und Wodan-Nachkomme ebenfalls "Swæfdeg". Dort sind die ersten Glieder der Wodannachfahren mit "Wägdäg, Sigegar, Swæfdäg" und "Sigegat" wiedergegeben. Auch Tacitus geht von der ursprünglichen Aufteilung des nordalpinen Raums unter drei Söhnen des "Mannus" aus. Wenn auch die Namen und Gebiete anders sind, so ist die Grundstruktur doch ähnlich.

Beim "aitiologischen Mythos" handelt es sich um Mythen, die Naturereignisse oder Kulte begründen sollen. Der bekannteste Mythos ist der von Mjölnir, mit dem Thor den Blitz erzeugt. Aber es gibt auch andere Mythen, die in diese Gruppe einzuordnen sind.

So hatte der Name "Helgi" in den drei Heldenliedern der Edda "Helgakviða Hundingsbana I", "Helgakviða Hundingsbana II" und "Helgakviða Hjörvarðssonar" ursprünglich einen sakralen Sinn und bezeichnete einen Geheiligten, Geweihten. "Beowulf" gibt den Namen mit "Hálga" wieder. "Helgi" erhielt seinen Namen nach der "Helgakviða Hjörvarðssonar" von der mythischen Walküre "Sváfa". Helgi wurde von Odins Speer im Fesselhain getötet, wurde aber wiedergeboren. Linguistische Untersuchungen legen nahe, dass es sich dabei um das Opfer im Semnonenhain handelt, ein Kult der Sueben, als diese noch in Brandenburg siedelten und von dem Tacitus berichtet.

Der Mythos um "Balder", der durch eine Mistel getötet wurde und wieder aufersteht, gehört zu den Naturmythen, die Frühling und Wachstum unterlegt werden.

Zum Odinskult wurde der Odins-Speer verwendet, um das Opfer damit zu töten. Um dieses Ritual gab es mehrere Mythen, nicht nur das "Helgilied". Odin warf seinen Speer Gungnir über die Wanen und löste so die erste Schlacht aus. Der Speer stammte von den Zwergen und war ihm von Loki gegeben worden.

Über das Alter der nordischen Mythen lassen sich keine sicheren Aussagen machen. Zunächst ist die Frage zu beantworten, wonach genau man fragt. Je weiter man zurückgeht, desto spärlicher werden die Bausteine sein, die sich in der Schlussfassung der Eddalieder finden. Selbst wenn man die Lieder in ihrer bunten Vielfalt der Phantasie einer höfisch intellektuellen Dichtung zuschreibt, die von den Skalden im Gefolge Olavs des Heiligen ausformuliert wurde, besagt dies nichts über den Entstehungszeitpunkt der Motive, die der Skalde zusammengefügt hat, und seine eigenen Umgestaltungen. Diese müssen als Gedankengut einige hundert Jahre älter sein, um sich in ganz Nordeuropa so verbreiten zu können, dass sie bei jedem Hörer der Skaldendichtung und seiner Kenningar präsent waren. Die wohl älteste bekannte Darstellung der Mitgardschlange auf dem Medaillon von Lyngby aus dem 5. Jahrhundert dürfte bereits eine längere Tradition hinter sich gehabt haben. Andererseits darf sowohl aus sprachlichen Gründen (Synkope) als auch aus soziologischen Gründen ein großer Teil des wesentlichen Gehalts der Götterlieder nicht aus einer Zeit vor dem 9. Jahrhundert angesetzt werden. Denn es handelt sich weithin um die Dichtung eines Kriegerstandes. Die Vorstellung von Walhall als einem Ort, wo die im Kampf gefallenen Krieger sich mit Kampfspielen vergnügen, ist dafür typisch. Frauen haben keine Chance nach Walhall zu kommen. Als Håkon der Gute im Jahre 961 fällt, wird nach seinem Tode Hákonarmál auf ihn gedichtet. Håkon war Christ, gleichwohl lässt ihn der Dichter nach Walhall einziehen, was auf ein hohes Alter der Walhall-Vorstellung schließen lässt. Die Kriegerkaste hat sich aber erst im 9. Jh. so etabliert, dass sie auch einen eigenen Mythos bilden konnte. Keine der kontinentalen und angelsächsischen Quellen lässt auch nur andeutungsweise erkennen, dass die Wikinger einem heldenhaften Tod mit Aussicht auf den Einzug in Walhall gelassen ins Auge sahen. Vielmehr mieden sie die erkannte Gefahr und retteten sich ohne weiteres durch Flucht oder Loskauf. Aber von diesem Mythenbildungsprozess ist die Entstehung der in den Mythen agierenden Gestalten, ihre Wesenszüge und ihre Bedeutung im Pantheon zu unterscheiden. Diese Elemente können ein wesentlich höheres Alter haben und sogar früheisenzeitliches Gemeingut gewesen sein, aus dem sich die Dichter dann bedient haben.

Ein anderes Beispiel ist der einäugige Odin, der 9 Tage und 9 Nächte an einem Baum hängt. Dass dieses Element sehr alt ist, zeigt schon die Beschreibung Adams von Bremen von dem Opferfest in Uppsala, wo Tiere und Menschen an Bäumen aufgehängt wurden.

Einäugigkeit und Baumheiligtümer sind sehr alte Elemente, die sicher schon zu Zeiten Adams von Bremen viele Generationen hinter sich hatten, und Odin gilt als Hauptgott für Uppsala. Damit wird aber nichts über das Alter der Ätiologie gesagt. Das Streben nach Weisheit als Grund für dieses Bild ist sicherlich nicht so alt wie dieses Bild und gehört in einen gesellschaftlichen Zusammenhang mit ausgeprägten intellektuellen Ansprüchen, sei es in Norwegen, sei es vom Kontinent importiert. Auch der Gewinn der Runen durch Odin einerseits und die These, dass die Runen in Anlehnung an die römische "Capitalis monumentalis" entwickelt worden seien, andererseits führt dazu, dass dieser Teil des Odinsmythos erst nach der Berührung mit der "Capitalis monumentalis" und der darauf folgenden Entwicklung der Runen entstanden sein kann.

Ein weiteres Beispiel ist die "Helgakveða Hundingsbana II" (ein Heldenlied aus der älteren Edda), das altertümlichste Helgilied, in welchem ein Fesselhain erwähnt wird, der mit dem semnonisch-suebischen Fesselwald, über den Tacitus berichtet, für identisch gehalten wird. Obgleich Helgi seinen Beinamen von seinem Feind "Hunding" erhielt, spielt Hunding im Helgilied keine Rolle. Das bedeutet, dass im Laufe der Tradition die Geschichte starken Veränderungen unterworfen war. Hier lässt sich im Übrigen der Namenstransport belegen: In der Geschichte von Helgi treten drei Personen mit Namen Helgi auf: "Helgi Hjörvarðsson", "Helgi Hundingsbani" und "Helgi Haddingjaskati". Die walkürisch-dämonische Geliebte des ersten Helgi heißt "Sváva", ein unskandinavischer Name, der aus Süddeutschland kommt, "Sigrún" ist die Geliebte des zweiten Helgi und "Kára" die des dritten. Es handelt sich jeweils um die Wiedergeburt des vorangegangenen Paares. Es zeigt sich hier wie auch sonst, dass sich die Namen über wesentlich längere Zeiträume erhalten, als Motive und Begebenheiten.

Bei einem solchen hochkomplexen Entstehungsprozess ist daher bereits die Frage nach dem Alter sehr problematisch, da der Begriff des Alters einen Nullpunkt voraussetzt, der für jedes Motivelement anders anzusetzen ist.

Man wird daher einen "vorwikingischen" Zeitraum, einen "wikingischen" Zeitraum und einen "mittelalterlichen" Zeitraum zu unterscheiden haben. Überlagert wird diese Periodisierung von den Einflüssen erst der heidnisch-römischen, dann der römisch-christlichen Kultur. Wenn man beispielsweise davon ausgeht, dass die Runen auf römische Einflüsse zurückgehen, dann kann dies nicht bei dem Mythos über Odin als dem, der das Geheimnis der Runen erwarb, außer Betracht bleiben.

Nachdem sehr früh die Ahistorizität des Mythos entdeckt war, begann man darüber nachzudenken, wie solche „Fabeleien“ zustande gekommen seien. Diese Art der Sagakritik führte zu einem neuen Typ des Mythos.

Wie schon in Griechenland Euhemeros die Göttermythen glaubte dadurch erklären zu können, dass es sich bei den Göttern um Könige der Vorzeit handele, die dann später mythisch vergöttlicht worden seien, so hat auch Snorri Sturluson in seiner "Heimskringla" Odin zu einem Urkönig in Saxland gemacht. So wurde aus dem Weltentstehungsmythos ein Geschichtsmythos, nämlich ein Ursprungsmythos. Ob Snorri von der Erklärung des Euhemeros erfahren hat, lässt sich nicht mehr feststellen. Möglich wäre es, denn die isländischen Antikensagas wurden in diesem Zeitraum (Ende des 12. bis Mitte des 13. Jh.) verfasst, denen die im Mittelalter weit verbreiteten Werke "De exidio Troiae Historia" des Dares Phrygius, die "Historia Regum Britanniae" des Geoffrey von Monmouth und die "Alexandreis" des Walter von Châtillon und andere Überlieferungen zu Grunde lagen. Eine aufklärerische Tendenz war damals schon zu bemerken, indem z. B. Homers "Ilias" als Lügenmärchen recht unbeachtet blieb und stattdessen die Version des Dares Phrygius bevorzugt wurde.

Man hat in der Vergangenheit den durchschlagenden Erfolg der Christianisierung auf eine Schwäche und den Niedergang der Überzeugungskraft der Mythologie zurückgeführt. Der dänische Kirchenhistoriker Jørgensen sah den Sieg des Christentums in der Barbarei des vorangegangenen heidnischen Glaubens begründet. Mit dem Christentum sei Kultur in das barbarische nordische Volk gekommen. Demgegenüber ist für die Mythologie festzustellen, dass sie im Gegensatz zur religiösen Praxis die Christianisierung fast unbeschadet überstanden hat. Das zeigt sich schon an Snorri Sturluson. Er sah klar, dass die nordische Dichtkunst ohne die Mythologie aufhören würde. Denn sie war auf mythologische Umschreibungen, den Kenningar, angewiesen. Daher musste die Mythologie sowohl den Verfassern als auch den Hörern bekannt sein. Aus diesem Grunde wurde die Mythologie von den skandinavischen Kirchen nicht bekämpft. An den alten Kirchen finden sich Schnitzereien mit Anspielungen auf die heidnische Mythologie.

Die vielen heidnischen Wesen erlitten im christlichen Kontext ein unterschiedliches Schicksal, je nachdem, wie sie in das Christentum integriert werden konnten. Das Gleiche gilt für kultische Handlungen.

Viele heidnische Götter wurden unter dem Christentum zu Teufeln oder zauberkundigen Menschen umgedeutet. Das Bild des nordischen Götterhimmels stand im Widerspruch zu den Beschreibungen der christlichen Bibel oder der Himmlischen Hierarchie und ließ sich daher nicht problemlos in die mittelalterliche Weltanschauung integrieren. Man kann die Wahrnehmung der mythischen Wesen des vorchristlichen Heidentums folgerichtig in zwei Gruppen einteilen: Die eine Gruppe wurde als teuflisch erklärt und bekämpft. Die andere wurde in das Christentum integriert.

Diese Integration ist bei der Behandlung der Fylgja deutlich zu erkennen. Sie hatten als Bindeglied zwischen den Lebenden und Toten eines Geschlechts eine wichtige Funktion. Deshalb musste man sie auf irgendeine Weise in den christlichen Kult integrieren. Ansätze dazu kann man in der "Flateyjarbók" und in der "Gísla saga Súrssonar" erkennen. In der "Flateyjarbók" ist die Þáttr Þiðranda ok Þórhalls überliefert. Dort wird geschildert, wie der Sohn eines Großbauern aus dem Haus tritt, weil er ein Klopfen an der Tür vernommen habe. Am Morgen wird er sterbend gefunden. Er berichtet noch, dass er vor der Tür von neun schwarz gekleideten Frauen, die gegen ihn anritten, angegriffen worden sei. Etwas später seien neun weiß gekleidete Frauen gekommen, die ihm hätten helfen wollen, doch zu spät gekommen seien. Dieser Traum wird so gedeutet, dass die schwarzen Frauen die alten heidnischen Fylgjen seines Geschlechts gewesen seien, die weißen Frauen die neuen christlichen. Diese hätten ihm aber nicht helfen können, weil er kein Christ gewesen sei. In der Gíslasaga hat Gísli zwei Traumfrauen. Die eine sei böse, aber von der guten berichtet Gísli, dass sie ihm geraten habe, in der kurzen Zeit, die ihm noch zu leben bleibe, den alten Glauben abzulegen und sich nicht mehr mit Zauberei abzugeben, sondern gut zu den Tauben, Lahmen und Armen sein solle. Hier ist ein deutlicher Anklang zu dem christlichen Schutzengel zu erkennen. Doch in der Sagaliteratur des 13. Jahrhunderts ist die Fylgja immer noch Fylgja und kein Engel und stellt ein heidnisches Überbleibsel Seite an Seite mit christlichen Vorstellungen dar. Aber der christliche Skald Bjǫrn Arngeirsson hítdœlakappi († um 1024) schreibt in seinem "Lausavisur" Strophe 22 von einem Traum kurz vor seinem Tod, dass eine helmbewehrte Frau ihn heimholen wollte. Die helmbewehrte Frau im Traum ist klar als Walküre erkennbar. „Heim“ war für den Christen aber das Himmelreich. Ob die Strophe echt ist, also von dem Skalden im 11. Jahrhundert gedichtet wurde, ist zwar zweifelhaft. Aber wenn das Gedicht erst im 13. Jahrhundert vom Sagaverfasser gedichtet worden sein sollte, so ist doch bemerkenswert, dass eine Walküre Odins oder Freyas 200–300 Jahre nach der Christianisierung einen Christen heimholen konnte.

Die Aufspaltung mythischer Wesen in vom Christentum akzeptierte und vom Christentum verurteilte Wesen lässt sich wahrscheinlich auch bei Snorris Gylfaginning erkennen. Dort teilt er die ursprünglich mythischen Alben in Schwarzalben und Weißalben ein. Allerdings ist mit dieser Aufteilung keine Auf- oder Abwertung verbunden, sondern sie beschreibt Zuständigkeitsbereiche dieser Wesen.

Die Vorstellung über Zwerge lebte im Christentum weiter, allerdings nicht als mythische Wesen. Sie gingen ohne weiteres in den Volksglauben ein. Sie hatten zwar eine Funktion in der heidnischen Vorstellungswelt, stellten aber keine Bedrohung für den christlichen Glauben dar. Auch die Vorstellungen über die Nornen und das Schicksal lebten ebenfalls weiter, allerdings nicht so unproblematisch. Hallfrøðr vandræðaskáld (um 965 – um 1007) erteilt in der Strophe 10 seines Lausarvisur Odin und den Nornen eine Absage und hält sie für Blendwerk. Allerdings war die Auffassung zu den Nornen in Norwegen und Island unterschiedlich. In Island wurde die Norne nach kurzer Zeit zur Hexe. Als böse Gestalt lebte sie im Volksglauben fort, wurde aber im religiösen Zusammenhang ungefährlich. In Norwegen lebte die Vorstellung weiter, dass die Nornen das Schicksal bestimmten. In der Stabkirche Borgund ist eine Runenschrift mit dem Text zu sehen: „Ich ritt hier vorbei am St. Olavstag. Die Nornen taten mir viel Böses, als ich vorbeiritt.“.

Ein weiteres Problem sind die Jöten, zu denen auch die Midgardschlange zu rechnen ist. Sie waren die Gegner der Götter, die im Christentum dämonisiert wurden. Die meisten Religionshistoriker sind der Auffassung, dass die Jöten nicht angebetet wurden und dadurch kultisch von den Göttern unterschieden seien. Aber es wird auch die Auffassung vertreten, dass einige Jöten ebenfalls Gegenstand eines Kultes waren. Jedenfalls werden die Jöten hin und wieder mit „illi Óðinn“ (der böse Odin) bezeichnet, was wiederum eine Bezeichnung des Teufels ist. Aber eine der wichtigsten Eigenschaften der Jöten war ihre Klugheit, so dass sie nicht nur dämonisiert wurden. Vielmehr wurden sie auch teilweise „entmythologisiert“ zu einfachen Trollen im Volks- und Aberglauben.
Schlangen und Drachen waren nicht so mit der Midgardschlange verknüpft, wie der Thorshammer mit Thor. Sie hatten einen unterschiedlichen Symbolgehalt im jeweiligen Kontext. Davon hing auch ihr Schicksal nach der Christianisierung ab. Drachen und Schlangen gibt es auch im Christentum und werden mit dem Teufel gleichgesetzt. Die Schlange tritt in der Bibel als Verführerin auf. In der norrönen Literatur finden sich Beispiele für Schlangen als Symbol des Bösen. Als der Bischof Guðmundur Arason in die Bucht von Hjørungavåg einfahren wollte, versperrte ihm der Legende nach eine gewaltige Seeschlange den Weg. Er bespritzte sie mit Weihwasser. Da musste die Schlange weichen. Am nächsten Tag fand man den Wurm in zwölf Teile zerstückelt am Strand. Der mit Schwert durchbohrte Drache symbolisiert den Sieg des Guten über das Böse. Dass Sigurðr fáfnisbani in "Fáfnismál" den Drachen Fafnir tötet – ein weit verbreitetes Motiv in der Eddadichtung – ist zwar in der heidnischen Zeit angesiedelt, aber erst im 13. Jahrhundert gedichtet und wird als Parallelmotiv zu ähnlichen Motiven des Alten Testaments und vorausweisend auf das Christentum und Sigurðr als Vorläufer christlicher Helden gesehen, denen ähnliches zugeschrieben wurde. Während die rechte Portalsäule der Hyllestad-Kirche Sigurðr zeigt, ist auf der linken Säule Samson abgebildet, der den Löwen erwürgt.

Aber in den nordischen Mythen wird die Schlange nicht nur negativ gesehen. Die Midgardschlange, die um das Weltenrund liegt, hält diese zusammen und verhindert so das Auseinanderfallen der Welt in das Chaos. Der Drache hatte einerseits einen aggressiven Symbolgehalt. Auf dem „stál“, dem obersten Stück des Stevens eines Kriegsschiffes, saß bei den Kampfschiffen der Drachenkopf. Nach allen Quellentypen, den literarischen, den archäologischen und dem Bildmaterial zu urteilen waren die Drachenköpfe auf den Schiffen relativ selten. Nach dem Landnámabók war es verboten, mit dem Drachenkopf am Steven den Heimathafen anzusegeln. Die Schutzgeister des Landes könnten aufgebracht oder vertrieben werden. Auf Feindfahrt sollte er die Schutzgeister des Feindes vertreiben. Wer die Schutzgeister des angegriffenen Landes vertrieb und das Land unterwarf, war der neue örtliche Herrscher. Deshalb werden in den Quellen die Schiffe mit Drachenköpfen regelmäßig den Führungspersönlichkeiten der Unternehmungen zugeschrieben. Der Drache konnte andererseits mit Schutz in Verbindung stehen. Der Drache liegt auf dem Schatz oder windet sich um ihn. Das ist seine Wächterfunktion. In der Forschung werden Drachenfiguren oft als reine Dekoration angesehen, insbesondere an Stabkirchen, aber auch an Schmuckstücken und Armreifen. Aber Mundal vermutet in ihnen eine apotropäische Funktion. Bei Kirchen sollten sie das Heidnische fernhalten. Während Drachen neben anderen Fratzen auch Kirchen auf dem Kontinent zierten, ist doch auffällig, welches Übergewicht die Drachenköpfe an den norwegischen Stabkirchen haben, ja sogar an Reliquienschreinen. Das kann daran liegen, dass die Drachen in der profanen Kunst in der vorchristlichen Zeit einen allen bekannten Symbolgehalt hatten, der sie auch in der Kirchenkunst tragbar machte. Sie können gedeutet werden als das Fernhalten des Bösen, aber auch als Allgegenwart des Bösen, sogar innerhalb des Kirchenraums.

Im älteren Frostathingslov und im Gulathingslov wird das Blót an heidnische Mächte, an heidnischen Grabhügeln und Altären verboten. Noch in den späteren Christenrechten von 1260, wie dem Neueren Gulathings Christenrecht, und auch in einer Predigt in der Hauksbók aus dem ersten Drittel des 14. Jahrhunderts werden noch die Verwerflichkeit, an die Schutzgeister des Landes zu glauben oder sie zu verehren, erwähnt. Die Sitte dürfte trotzdem noch mehrere hundert Jahre fortbestanden haben. Ein Grund für das lange Fortbestehen der Bräuche für die Schutzgeister des Landes könnte sein, dass sie als weniger gefährlich für das Christentum angesehen wurden, als der Glaube an die Götter.

Das Gleiche gilt für den Ahnenkult. Ihm begegnete das Christentum mit Misstrauen. So wird in § 29 des Älteren Gulathingslov verboten, an den Grabhügeln zu opfern. Doch der Ahnenkult lebte unter dem Christentum fort. Das kann daran liegen, dass die Ahnenverehrung in einer Clangesellschaft ein wichtiges religiöses Element darstellt und das Christentum darin immerhin den Glauben an ein Leben nach dem Tode sah. Und man grenzte dann die Ahnenverehrung und die Ahnenanbetung voneinander ab.





</doc>
<doc id="2052" url="https://de.wikipedia.org/wiki?curid=2052" title="Gefäßsporenpflanzen">
Gefäßsporenpflanzen

Die Gefäßsporenpflanzen (Pteridophyta) oder Farnartigen Pflanzen waren lange Zeit eine systematische Großgruppe der Gefäßpflanzen. Sie umfasste die sporenbildenden Gefäßpflanzen (im Gegensatz zu den samenbildenden): Bärlapppflanzen und Farne. Die beiden Gruppen sind jedoch nicht näher verwandt, die Farne sind mit den Samenpflanzen näher verwandt als mit den Bärlapppflanzen. Daher werden die Gefäßsporenpflanzen heute nicht mehr als taxonomische Gruppe betrachtet. 

Farnpflanzen sind primär an das Landleben angepasst, und zwar noch wesentlich stärker als die Moose. In ihrem Generationswechsel dominiert der Sporophyt, also die diploide Generation. 

Der Gametophyt, die haploide, sexuelle Generation, wird hier Prothallium genannt. Er ist meist kurzlebig und wird nur wenige Wochen alt. Kommt es zu keiner Befruchtung, kann er auch einige Jahre überdauern. Er wird maximal wenige Zentimeter groß, ist thallös und ähnelt einem thallösen Lebermoos. Es gibt mannigfache Abweichungen, der typische Aufbau ist folgender: Das Prothallium ist ein einfacher, grüner Thallus, der an der Unterseite Rhizoide besitzt, mit denen er am Boden befestigt ist. Am Prothallium entstehen zahlreiche Geschlechtsorgane, Antheridien und Archegonien. Die Befruchtung erfolgt ausschließlich im Wasser.

Im Gegensatz zu den Moosen ist der Sporophyt eine selbständige, grüne Pflanze, die nicht auf die Versorgung durch den Gametophyten angewiesen ist. Bei den Bärlapppflanzen, den Schachtelhalmen und den echten Farnen ist der Sporophyt in Achse, Blätter und Wurzel gegliedert. Die ausgestorbenen Urfarne hatten nur blattlose Gabeltriebe, ihnen fehlten auch wie den rezenten Gabelblattgewächsen die Wurzeln. Der Sporopyht ist also ein echter Kormus.

Der Embryo bildet bei den rezenten Vertretern kurz nach den ersten Zellteilungen der Zygote ein Haustorium (Fuß) sowie einen Wurzelscheitel, einen Stammscheitel und einen Blattscheitel. Aus diesen entwickelt sich die erste Wurzel, der Stamm und das erste Blatt (Kotyledone). Die Wurzel entwickelt sich nicht wie bei den Samenpflanzen, sondern entsteht endogen aus dem Spross. Die Gefäßsporenpflanzen besitzen also eine primäre Homorhizie.

Die drei Grundorgane wachsen bei den meisten Vertretern mit Scheitelzellen, nicht mit Meristemen. Die Verzweigung erfolgt gabelig oder seitlich, nie jedoch aus den Blattachseln. Die Wurzeln besitzen eine Wurzelhaube. Die Seitenwurzeln entstehen nicht wie bei den Samenpflanzen im Perizykel, sondern in der innersten Rindenschicht. Die Blätter ähneln denen der Samenpflanzen: Sie besitzen eine Cuticula und Spaltöffnungen, allerdings besitzen die Epidermiszellen meist Chloroplasten. Die Leitbündel sind wohldifferenziert. Das Xylem besteht aus Tracheiden, selten (etwa bei "Pteridium") sind auch Tracheen vorhanden. Vorherrschend sind konzentrische Leitbündel mit Innenxylem. Die Zellwände sind mit Lignin verstärkt. 

Sekundäres Dickenwachstum mittels Kambium kommt bei rezenten Gruppen nur selten und schwach ausgeprägt vor. Bei manchen fossilen Gruppen war es verbreitet.

Die Sporangien werden meist an Blättern gebildet, nur bei den ursprünglichsten Gruppen direkt an Sprossachsen. Die Sporangien selbst sind sehr vielgestaltig. Die sporangientragenden Blätter heißen Sporophylle und sind oft einfacher gebaut als die rein assimilierenden Blätter (Trophophylle). 

Die Sporangien umschließen das Archespor (das sporogene Gewebe). Die Zellen des Archespor runden sich ab und werden zu (meist 16) Sporenmutterzellen. Durch Meiose entstehen aus jeder dieser Sporenmutterzellen vier haploide Meiosporen, die häufig tetraedrisch angeordnet sind. Das sporogene Gewebe ist oft von einer Nährschicht umgeben, dem Tapetum. 

Die Sporen sind meist gelblich bis bräunlich und in der Regel chlorophyllfrei. Die Wand gliedert sich in ein inneres Endospor und ein widerstandfähiges äußeres Exospor, auf dem noch ein Perispor (Perine) aufgelagert ist. 

Bei den meisten Gruppen sind die Sporen gleichartig (isospor), aus ihnen entwickeln sich zwittrige Prothallien. Mehrfach haben sich unabhängig zweihäusige Gruppen entwickelt, bei denen die Prothallien rein männlich oder weiblich sind. Bei manchen Gruppen hat dies auch zu zwei Sporenformen geführt (Heterosporie): großen, nährstoffreichen weiblichen Megasporen und kleinen, männlichen Mikrosporen. Diese werden getrennt in Mega- beziehungsweise Mikrosporangien gebildet.

Die Gefäßsporenpflanzen sind eine paraphyletische Gruppe, das heißt, sie umfasst nicht alle Nachkommen ihres letzten gemeinsamen Vorfahren.

Zu den Gefäßsporenpflanzen zählten folgende Gruppen:


Die letzten vier Klassen werden heute vielfach als eigene Gruppe Farne (Monilophyten) zusammengefasst, da sie eindeutig monophyletisch sind. Sie sind die Schwestergruppe der Samenpflanzen, mit denen sie in der Gruppe der Euphyllophyten zusammengefasst werden. Deren Schwestergruppe sind die Bärlapppflanzen.




</doc>
<doc id="2060" url="https://de.wikipedia.org/wiki?curid=2060" title="Glossar">
Glossar

Ein Glossar (, [']; zu ['] oder ['] wörtlich für „Zunge“ oder „Sprache“) ist eine Liste von Wörtern mit beigefügten Erklärungen oder Übersetzungen. Das lateinische Wort "glossarium" bezeichnet dabei als Objekt ein „Buch“, das (ver)alte(te) oder fremde Wörter erläutert. Im erweiterten Sinn wird ein "Glossar" auch Begriffserklärung"' genannt. Zudem, insbesondere wenn es um die Erklärung oder Beschreibung einzelner Begriffe geht, werden diese auch als [Begriffs-]Abgrenzung oder "Definition" bezeichnet.

Glossare wurden in der Antike und im Mittelalter von sogenannten "Glossographen" („Glossenschreibern“) als Sammlungen erklärungsbedürftiger Wörter (Archaismen, Dialekt­wörter, Fremdwörter, siehe Glosse) für das Grammatik­studium und als Hilfsmittel für die Erklärung von Texten (wie Homers und der Bibel) erstellt. Seit spätantiker Zeit entstanden außerdem zweisprachige, griechisch-lateinische und lateinisch-griechische Glossare, die der Vermittlung der jeweils fremden Sprache dienten, und im lateinischen Mittelalter dann den Anknüpfungspunkt für die Entstehung lateinisch-volkssprachlicher Glossare bildeten (Abrogans, Affatim-Glossar). 

Als lexikographisches Genre bilden die ein- und zweisprachigen Glossare eine Vorstufe für die auf vollständige Erfassung eines Wortschatzes angelegten Wörterbücher, von denen noch im 18. Jahrhundert das bis heute grundlegende Lexikon des Vulgär- und Mittellateinischen von Charles Du Cange als "Glossarium ad scriptores mediae et infimae latinitatis" (1. Ausgabe Paris 1678) betitelt wurde. Die Glossare der Antike und Spätantike bedienten sich bereits häufig des Verfahrens der Etymologie, die ein Wort oder dessen Bestandteile aus ähnlich klingenden Wörtern abzuleiten sucht, um derart nicht nur die Herkunft des Wortes, sondern auch die wesentlichen Eigenschaften der bezeichneten Sache aufzudecken. Sie boten darum neben primär sprachlichen vielfach auch einen hohen Anteil an sachlichen Erklärungen, durch den sie zu einer Vorstufe der Enzyklopädien wurden. So ist die für das Mittelalter wirkungsmächtigste Enzyklopädie, die "Etymologiae" von Isidor von Sevilla, unter anderem auch aus spätantiken Glossaren kompiliert.

In der Neuzeit ist ein Glossar im Bereich der Philologie und Editions­technik meist eine Liste von Wörtern mit sprachlichen Erklärungen, die den Wortschatz eines edierten Textes erschließt, und in der Regel im Anhang zu diesem Text abgedruckt wird. Ein fachsprachliches oder technisches Glossar listet die Terminologie einer Fachsprache oder eines technischen Sachgebietes mit begrifflich-sachlichen Definitionen auf, die den richtigen Gebrauch dieser Fachausdrücke und deren eindeutiges Verständnis sichern sollen.



</doc>
<doc id="2061" url="https://de.wikipedia.org/wiki?curid=2061" title="Global System for Mobile Communications">
Global System for Mobile Communications

Das Global System for Mobile Communications (früher "Groupe Spécial Mobile", GSM) ist ein Mobilfunkstandard für volldigitale Mobilfunknetze, der hauptsächlich für Telefonie, aber auch für leitungsvermittelte und paketvermittelte Datenübertragung sowie Kurzmitteilungen (Short Messages) genutzt wird. Es ist der erste Standard der sogenannten zweiten Generation („2G“) als Nachfolger der analogen Systeme der ersten Generation (in Deutschland: A-Netz, B-Netz und C-Netz) und ist der weltweit am meisten verbreitete Mobilfunk-Standard.

GSM wurde mit dem Ziel geschaffen, ein mobiles Telefonsystem anzubieten, das Teilnehmern eine europaweite Mobilität erlaubte und mit ISDN oder herkömmlichen analogen Telefonnetzen kompatible Sprachdienste anbot.

In Deutschland ist GSM die technische Grundlage der D- und E-Netze. Hier wurde GSM 1992 eingeführt, was zur raschen Verbreitung von Mobiltelefonen in den 1990er-Jahren führte. Der Standard wird heute in 670 GSM-Mobilfunknetzen in rund 200 Ländern und Gebieten der Welt als Mobilfunkstandard genutzt; dies entspricht einem Anteil von etwa 78 Prozent aller Mobilfunkkunden. Es existieren später hinzugekommene Erweiterungen des Standards wie HSCSD, GPRS und EDGE zur schnelleren Datenübertragung.

Im März 2006 nutzten weltweit 1,7 Milliarden Menschen GSM und täglich kommen eine Million neue Kunden dazu – hauptsächlich aus den Wachstumsmärkten Afrika, Indien, Lateinamerika und Asien. Rechnet man alle Mobilfunkstandards zusammen, so sind weltweit ca. 2 Milliarden Menschen mobiltelefonisch erreichbar. Das gaben die GSM Association und die GSA im Oktober 2005 bekannt. Im Jahr 2003 wurden (nach Angaben der Deutschen Bank) 277 Milliarden US-Dollar mit GSM-Technik umgesetzt.

Ende der 1950er Jahre nahmen die ersten analogen Mobilfunknetze in Europa ihren Betrieb auf; in Deutschland war dies das A-Netz. Ihre Bedienung war jedoch kompliziert, und sie verfügten nur über Kapazitäten für wenige tausend Teilnehmer. Zudem gab es innerhalb Europas nebeneinander mehrere verschiedene Systeme, die zwar teilweise auf dem gleichen Standard beruhten, sich aber in gewissen Details unterschieden. Bei der nachfolgenden Generation der digitalen Netze sollte eine ähnliche Situation vermieden werden.

Im Unterschied zum Festnetz gibt es bei einem Mobilfunknetz diverse zusätzliche Anforderungen:
Die Standardisierung von GSM wurde bei CEPT begonnen, von ETSI (Europäisches Institut für Telekommunikationsnormen) weitergeführt und später an 3GPP (3rd Generation Partnership Project) übergeben. Dort wird GSM unter dem Begriff GERAN (GSM EDGE Radio Access Network) weiter standardisiert. 3GPP ist somit für UMTS und GERAN verantwortlich.

Die mit GSM erzielbaren Reichweiten schwanken stark, je nach Geländeprofil und Bebauung. Im Freien sind bei Sichtkontakt teilweise bis zu 35 km erreichbar. Bei größeren Entfernungen verhindert die Signallaufzeit der Funksignale eine Kommunikation zwischen Basis- und Mobilstation. Es ist allerdings mit Hilfe spezieller Tricks möglich, die Zellengröße zu vergrößern, teilweise auf Kosten der Kapazität. Anwendung findet dies in Küstenregionen.
In Städten beträgt die Reichweite aufgrund von Dämpfungen durch Gebäude und durch die niedrigere Antennenhöhe oft nur wenige hundert Meter, dort stehen die Basisstationen allerdings aus Kapazitätsgründen auch dichter beieinander.

Grundsätzlich gilt jedoch, dass mit GSM 900 aufgrund der geringeren Funkfelddämpfung und der größeren Ausgangsleistung der Endgeräte größere Reichweiten erzielbar sind als mit DCS 1800.

Entsprechend der Reichweite wird die Zellengröße festgelegt. Dabei wird auch die prognostizierte Nutzung berücksichtigt, um Überlastungen zu vermeiden.

Die digitalen Daten werden mit einer Mischung aus Frequenz- und Zeitmultiplexing übertragen, wobei Sende- und Empfangsrichtung durch Frequenzmultiplexing getrennt werden und die Daten durch Zeitmultiplexing. Das GSM-Frequenzband wird in mehrere Kanäle unterteilt, die einen Abstand von 200 kHz haben. Bei GSM 900 sind im Bereich von 890–915 MHz 124 Kanäle für die Aufwärtsrichtung "(Uplink)" zur Basisstation und im Bereich von 935–960 MHz 124 Kanäle für die Abwärtsrichtung "(Downlink)" vorgesehen. Die TDMA-Rahmendauer beträgt exakt 120/26 ms (ca. 4,615 ms) und entspricht der Dauer von exakt 1250 Symbolen. Jeder der acht Zeitschlitze pro Rahmen dauert somit ca. 0,577 ms, entsprechend der Dauer von 156,25 Symbolen. In diesen Zeitschlitzen können Bursts verschiedener Typen gesendet und empfangen werden. Die Dauer eines normalen Bursts beträgt ca. 0,546 ms, in denen 148 Symbole übertragen werden.

Da die Mobilstation jeweils nur in einem Zeitschlitz des Rahmens sendet, ergibt sich eine Pulsrate von 217 Hz.

Das Modulationsverfahren ist "Gaussian Minimum Shift Keying" (GMSK, dt.: Gauß'sche Minimalphasenlagenmodulation), eine digitale Phasenmodulation bei der die Amplitude konstant bleibt. Mit EDGE wurde dann 8-PSK eingeführt. Während bei GMSK pro Symbol nur 1 bit übertragen wird, sind dies bei 8-PSK 3 bit, jedoch wird für die Funkverbindung ein besseres Signal-Rauschleistungsverhältnis benötigt.

Da bei einer Entfernung von mehreren Kilometern das Funksignal durch die beschränkte Ausbreitungsgeschwindigkeit (die sogenannte Gruppengeschwindigkeit) soweit verzögert werden kann, dass der Burst des Mobiltelefons nicht mehr innerhalb des vorgegebenen Zeitschlitzes bei der Basisstation ankommt, ermittelt diese die Signallaufzeit und fordert das Mobiltelefon auf, den Burst etwas früher auszusenden. Dazu teilt sie dem mobilen Gerät den Parameter "Timing Advance" (TA) mit, der den Sendevorlauf in 3,7-μs-Schritten vorgibt. Dies entspricht jeweils der Zeitdauer eines Bit, wobei die Bitrate 270,833 kbits/s beträgt (siehe unten). Der "Timing Advance" hat einen Wertebereich von 0 bis 63. Die Dauer eines Bits entspricht bei gegebener Gruppengeschwindigkeit einer Wegstrecke von ca. 1,106 km, und da für die Laufzeit Hin- und Rückrichtung zusammen betrachtet werden müssen, entspricht eine Änderung des "Timing Advance" um eins einer Entfernungsänderung von etwas mehr als 553 m. Somit ergibt sich eine maximale Reichweite von ca. 35,4 km, die jedoch mit technischen Tricks erweitert werden kann.

Nach dem Empfangsburst schaltet das Mobiltelefon auf die um 45 MHz versetzte Sendefrequenz, und sendet dort den Burst des Rückkanals an die Basisstation. Da "Downlink" und "Uplink" um drei Zeitschlitze versetzt auftreten, genügt eine Antenne für beide Richtungen. Zur Erhöhung der Störfestigkeit kann auch das Frequenzpaar periodisch gewechselt werden (frequency hopping), so entsteht eine Frequenzsprungrate von 217 Sprüngen pro Sekunde.

Bei einer Bruttodatenübertragungsrate von ca. 270,833 kbit/s pro Kanal (156,25 Bits in jedem Burst zu 15/26 ms) bleiben je Zeitschlitz noch 33,85 kbit/s brutto übrig. Von dieser Datenrate sind 9,2 kbit/s für die Synchronisation des Rahmenaufbaus reserviert, so dass 24,7 kbit/s netto für den Nutzkanal übrig bleiben. Durch die Übertragung per Funk liegen in diesem Bitstrom noch viele Bitfehler vor.

Die Datenrate pro Zeitschlitz von 24,7 kbit/s wird in 22,8 kbit/s für die kodierten und verschlüsselten Nutzdaten des Verkehrskanals (Traffic Channel) und 1,9 kbit/s für die teilnehmerspezifischen Steuerkanäle (Control Channel) aufgeteilt. Die Kanalkodierung beinhaltet eine Reihe von Fehlerschutzmechanismen, so dass für die eigentlichen Nutzdaten noch 13 kbit/s übrig bleiben (im Fall von Sprachdaten). Eine später eingeführte alternative Kanalkodierung erlaubt die Verringerung des Fehlerschutzes zugunsten der Anwendungsdaten, da bei Datenübertragungsprotokollen im Gegensatz zur Sprachübertragung bei Bitfehlern eine Neuanforderung des Datenblocks möglich ist.

Die Sendeleistung der Mobilstation bei GSM 900 beträgt max. 2 Watt und 1 Watt bei GSM 1800. Die Sendeleistungen der Basisstationen für GSM 900/1800 betragen 20-50/10-20 Watt. Die Sendeleistungen von Mobil- und Basisstationen werden nach Verbindungsaufbau je auf das notwendige Mindestmaß reduziert. Die Basisstationen sendet, je nach Bedarf, in den einzelnen Zeitschlitzen eines Rahmens mit unterschiedlicher Leistung. Sie sendet nur in aktiven Zeitschlitzen. Die Leistungsregelung erfolgt im Abstand von Sekunden. Daneben kann das Handy, wenn nicht gesprochen wird, die Abstrahlungen unterbrechen. Der technische Grund für beide Maßnahmen ist, den Stromverbrauch zu senken und Funkstörungen in Nachbarzellen gleicher Frequenz zu reduzieren.

GSM-Netze sind in fünf Teilsysteme unterteilt (siehe Bild von links nach rechts):


"Die blauen Buchstaben im Bild bezeichnen die Datenübertragungswege zwischen den Komponenten."

In einem GSM-Netz werden folgende Nummern zur Adressierung der Teilnehmer verwendet: Die MSISDN (Mobile Subscriber ISDN Number) ist die eigentliche Telefonnummer, unter der ein Teilnehmer weltweit zu erreichen ist.
Die IMSI (International Mobile Subscriber Identity) ist dementsprechend die interne Teilnehmerkennung, die auf der SIM gespeichert wird und zur Identifizierung eines Teilnehmers innerhalb eines Funknetzes verwendet wird. Aus Datenschutzgründen wird die IMSI nur bei der initialen Authentifizierung der mobilen Station über das Funknetz gesendet, in weiteren Authentifizierungen wird stattdessen eine temporär gültige TMSI (Temporary Mobile Subscriber Identity) verwendet. Für das Roaming, also das Routing des Telefonats innerhalb des Mobilfunknetzes, wird die MSRN (Mobile Station Roaming Number) verwendet.

Eine der wichtigsten Grundfunktionen in zellularen Mobilfunknetzen ist der vom Netz angestoßene Zellwechsel während eines laufenden Gesprächs. Dieser kann aus verschiedenen Gründen notwendig werden. Ausschlaggebend ist u. a. die Qualität der Funkverbindung, aber auch die Verkehrslast der Zelle. Es kann zum Beispiel ein Gespräch an eine weiter entfernte Zelle übergeben werden, um eine Überlastung zu vermeiden.

Hier wird zum Beispiel aufgrund der Kanalqualität der MS ein neuer Kanal innerhalb einer Zelle zugewiesen.

Mehrere Prozeduren im GSM-Netz behandeln die Bewegung (Mobility) der Teilnehmer im Netz. Damit ein mobiler Teilnehmer, der sich irgendwo im Netzgebiet befindet, angerufen oder ihm eine Kurznachricht zugestellt werden kann, muss ständig die Voraussetzung dafür bestehen, dass der Teilnehmer eine Suchanfrage (genannt Paging) empfangen kann. Hierzu muss sein aktueller Aufenthaltsort in gewisser Granularität ständig nachgeführt werden.

Zur Verringerung des Aufwands im Kernnetz und zur Verlängerung der Akku-Laufzeit wird zentral nur die Location Area erfasst, in der sich ein eingebuchtes Mobiltelefon befindet. Wo es sich innerhalb dieses Gebietes befindet, ist nicht bekannt. Um Energie und Übertragungskapazität zu sparen, meldet sich das Mobiltelefon im Standby-Betrieb (idle-mode) in vom Netz vorgegebenen Abständen (zwischen 6 Minuten und 25,5 Stunden) oder beim Wechsel der Location Area beim Netz. Sobald das Netz mit dem Mobiltelefon eine Verbindung aufbauen möchte, wird dieses über alle Basisstationen der Location Area gerufen und bei Meldung die Verbindung über die Basisstation, an der das Endgerät sich meldet, aufgebaut.

Dem Mobiltelefon dagegen ist genau bekannt, in welcher Funkzelle es sich befindet. Im Standby-Betrieb scannt es die Nachbarzellen, deren Trägerfrequenzen es von der Basisstation auf speziellen Informationskanälen mitgeteilt bekommt. Wird das Signal einer der Nachbarzellen besser als das der aktuellen Zelle, dann wechselt das Mobiltelefon dorthin. Bemerkt es dabei eine Änderung der Location Area, dann muss es dem Netz seinen neuen Aufenthaltsort mitteilen.

Für das Mobilitätsmanagement sind das VLR (Visitor Location Register) und das HLR (Home Location Register) von sehr großer Bedeutung. Die beiden sind eigentlich als Datenbanken zu verstehen. Jede MS ist genau einmal in einem HLR registriert. Dort sind alle Teilnehmerdaten gespeichert. Im HLR ist stets das VLR eingetragen, in dessen Bereich sich eine MS zuletzt gemeldet hat. Im VLR sind jeweils alle sich im Einzugsgebiet eines MSC befindlichen MS eingetragen.

Da viele Mobilfunkbetreiber aus verschiedenen Ländern Roamingabkommen getroffen haben, ist es möglich, das Mobiltelefon auch in anderen Ländern zu nutzen und weiterhin unter der eigenen Nummer erreichbar zu sein und Gespräche zu führen.

In diesem Abschnitt werden die Sicherheitsfunktionen aufgeführt. Defizite dieser Funktionen sind im Abschnitt Sicherheitsdefizite aufgeführt.

Jedem Teilnehmer wird bei der Aufnahme in das Netz eines Mobilfunkbetreibers ein 128 Bit langer "Subscriber Authentication Key" K zugeteilt. Der Schlüssel wird auf Teilnehmerseite in der SIM-Karte, netzseitig entweder im HLR oder im AuC gespeichert.
Zur Authentifizierung wird der MS vom Netz eine 128 Bit lange Zufallszahl RAND geschickt. Aus dieser Zufallszahl und K wird mit dem A3-Algorithmus der Authentifizierungsschlüssel SRES' (Signed Response, 32 Bit) berechnet. Diese Berechnung findet in der SIM-Karte statt. Der Authentifizierungsschlüssel SRES wird vom Netz im AuC und von der MS getrennt berechnet und das Ergebnis vom VLR verglichen. Stimmen SRES und SRES' überein, ist die MS authentifiziert.

Der A3-Algorithmus ist elementarer Bestandteil der Sicherheit im GSM-Netz. Er kann von jedem Netzbetreiber selbst ausgewählt werden, Details der jeweiligen Implementierung werden geheim gehalten.

Zur Verschlüsselung wird aus der zur Authentifizierung benötigten Zufallszahl RAND und dem Benutzerschlüssel K mit dem Algorithmus A8 ein 64 Bit langer Codeschlüssel (engl.: "Ciphering Key") K bestimmt. Dieser Codeschlüssel wird vom Algorithmus A5 zur symmetrischen Verschlüsselung der übertragenen Daten verwendet.

Schon angesichts der geringen Schlüssellänge kann davon ausgegangen werden, dass die Verschlüsselung keine nennenswerte Sicherheit gegen ernsthafte Angriffe bietet. Außerdem wurde bereits durch mehrere Angriffe 2009 und 2010 auf den verwendeten Algorithmus A5/1 gezeigt, dass dieser prinzipiell unsicher ist. Allerdings verhindert die Verschlüsselung ein einfaches Abhören, wie es beim analogen Polizeifunk möglich ist.

Die Verschlüsselung mit dem unsicheren A5/1-Algorithmus ist in Deutschland normalerweise eingeschaltet. In Ländern wie z. B. Indien darf das Handynetz nicht verschlüsselt werden. Prinzipiell sieht der GSM-Standard vor, dass Mobiltelefone bei unverschlüsselten Verbindungen eine Warnung anzeigen.

Um eine gewisse Anonymität zu gewährleisten, wird die eindeutige Teilnehmerkennung IMSI, über die ein Teilnehmer weltweit eindeutig zu identifizieren ist, auf der Luftschnittstelle verborgen. Stattdessen wird vom VLR eine temporäre TMSI generiert, die bei jedem Location Update neu vergeben wird und nur verschlüsselt übertragen wird.
Der Benutzer muss sich gegenüber der SIM-Karte (und damit gegenüber dem Mobilfunknetz) als berechtigter Nutzer authentisieren. Dies geschieht mittels einer PIN. Es ist auf der SIM-Karte festgelegt, ob die PIN-Abfrage deaktiviert werden kann. Wurde die PIN dreimal in Folge falsch eingegeben, wird die SIM-Karte automatisch gesperrt. Um sie wieder zu entsperren, ist der PUK (Personal Unblocking Key) erforderlich. Der PUK kann zehnmal in Folge falsch eingegeben werden bevor die SIM-Karte endgültig gesperrt wird. Das Mobilfunknetz muss sich nicht gegenüber dem Benutzer authentisieren.

Festnetzseitig basiert der GSM-Standard auf dem ISDN-Standard und stellt deshalb ähnliche vermittlungstechnische Leistungsmerkmale bereit. Mit der Möglichkeit, Kurznachrichten (SMS, kurz für Short Message Service) zu senden und zu empfangen, wurde ein neuer Dienst geschaffen, der begeistert angenommen worden ist und mittlerweile eine wichtige Einnahmequelle für die Netzbetreiber geworden ist.

Für die Sprachübertragung bei GSM wurden im Laufe der Jahre mehrere Codecs standardisiert. Die üblichen Sprachcodecs, welche typischerweise mit einer Datenrate von weniger als 20 kbit/s auskommen, führen eine der menschlichen Sprache angepasste Merkmalsextraktion durch, wodurch sie nur für die Übertragung von Sprache brauchbar sind. Musik oder andere Geräusche können sie daher nur mit geringerer Qualität übertragen. Im Folgenden werden die im GSM-Netz verwendeten Sprachcodecs kurz zusammengefasst:

Der erste GSM-Sprachcodec war der Full-Rate-Codec (FR). Für ihn steht nur eine Netto-Datenrate von 13 kbit/s zur Verfügung (im Unterschied zu G.711 64 kbit/s bei ISDN). Die Audiosignale müssen deshalb stark komprimiert werden, aber trotzdem eine akzeptable Sprachqualität erreichen. Beim FR-Codec wird eine Mischung aus Langzeit- und Kurzzeit-Prädiktion verwendet, die eine effektive Komprimierung ermöglicht (RPE/LTP-LPC Sprachkompression: "Linear Predictive Coding", "Long Term Prediction", "Regular Pulse Excitation").
Technisch werden jeweils 20 ms Sprache gesampelt und gepuffert, anschließend dem Sprachcodec unterworfen (13 kbit/s). Zur Vorwärtsfehlerkorrektur (Forward Error Correction, FEC) werden die 260 Bits eines solchen Blocks in drei Klassen eingeteilt, dementsprechend, wie stark sich ein Bitfehler auf das Sprachsignal auswirken würde. 50 Bits des Blocks werden in Klasse Ia eingeteilt. Sie sind am stärksten zu schützen und erhalten eine CRC-Prüfsumme von 3 Bits für Fehlererkennung und Fehlerverdeckung "(error concealment)". Zusammen mit 132 Bits der Klasse Ib, die etwas weniger zu schützen sind, werden sie einem Faltungs-Code unterworfen, der aus den 185 Eingangsbits 378 Ausgangsbits generiert. Die restlichen 78 Bits werden ungeschützt übertragen. So werden aus 260 Bits Nutzdaten 456 Bits fehlergeschützte Daten, wodurch die erforderliche Bitrate auf 22,8 kbit/s steigt.
Die 456 Bits werden durch Interleaving auf acht Halbbursts zu je 57 Bits aufgeteilt. Nach dem Deinterleaving im Empfänger wirken sich kurzzeitige Störungen (zum Beispiel ein Burst lang) durch die Fehlerspreizung nur noch gering aus. Durch die Kombination der unterschiedlichen Fehlerschutzverfahren im GSM, wird, obwohl der Funkkanal äußerst fehleranfällig ist, oft eine gute Sprachqualität erreicht.

Mit der Einführung des Half-Rate-Codecs wurde es möglich, auf einem Zeitschlitz der Luftschnittstelle nicht nur ein, sondern zwei Gespräche gleichzeitig abzuwickeln. Wie der Name sagt, steht für HR nur die halbe Datenrate zur Verfügung wie für den FR-Codec. Um trotzdem eine brauchbare Sprachqualität zu erreichen, wird anstelle der im FR-Codec verwendeten skalaren Quantisierung eine Vektorquantisierung verwendet. Dadurch ist für die Kodierung ungefähr die drei- bis vierfache Rechenleistung erforderlich wie beim FR-Codec. Weil die Sprachqualität trotzdem eher mäßig ist, wird HR von den Mobilfunknetzbetreibern nur dann eingesetzt, wenn eine Funkzelle überlastet ist.

EFR arbeitet mit einer ähnlichen Datenrate wie der Full Rate Codec, nämlich 12,2 kbit/s. Durch einen leistungsfähigeren Algorithmus (CELP) wurde, gegenüber dem Full-Rate-Codec, eine bessere Sprachqualität erreicht, welche bei einem guten Funkkanal annähernd dem Niveau von ISDN-Telefongesprächen (G.711a) entspricht.

Bei AMR handelt es sich um einen parametrierbaren Codec mit unterschiedlichen Datenraten zwischen 4,75 und 12,2 kbit/s.
In der 12,2-kbit/s-Einstellung entspricht er vom Algorithmus wie auch in der Audioqualität her weitgehend dem GSM-EFR-Codec.
Je geringer die Datenrate der Sprachdaten ist, umso mehr Bits stehen für die Kanalkodierung und damit zur Fehlerkorrektur zur Verfügung. Somit wird der 4,75-kbit/s-Codec als der robusteste bezeichnet, weil trotz hoher Bitfehlerhäufigkeit bei der Funkübertragung noch ein verständliches Gespräch möglich ist. Während eines Gespräches misst das Mobilfunknetz die Bitfehlerhäufigkeit und wählt den dafür geeignetsten Codec aus einer Liste, dem Active Codec Set (ACS) aus. Die verwendete Coderate wird somit fortlaufend an die Kanalqualität adaptiert.

Bei diesem Codec handelt es sich um eine Erweiterung und Optimierung des schon verfügbaren AMR-Codecsets. Wie das „WB“ (wide band) schon vermuten lässt, wird der übertragbare Frequenzbereich von derzeit ca. 3,4 kHz auf etwa 6,4 kHz beziehungsweise 7 kHz angehoben, ohne mehr Funkressourcen zu belegen. Die Entwicklung dieses Codecs ist seit einiger Zeit abgeschlossen, und er wurde von der ITU (G.722.2) und 3GPP (TS 26.171) standardisiert. Der Codec soll durch die größere Bandbreite Sprach- und Umgebungsgeräusche besser gemeinsam übertragen können, was in lauter Umgebung eine bessere Sprachqualität ermöglicht. Ericsson hat im T-Mobile-UMTS-Netz in Deutschland im Sommer 2006 mit ausgewählten Kunden in den Städten Köln und Hamburg einen AMR-WB-Betriebstest durchgeführt. Ende 2008 wurden alle Ericsson-BSC des Telekom-Netzes für AMR-WB vorbereitet. Seit Ende 2011 können alle Endkunden der Telekom AMR-WB nutzen. AMR-WB wird in Deutschland als "HD-Voice" vermarktet.

Wird ein GSM-Kanal für Datenübertragung genutzt, erhält man nach den Dekodierschritten eine nutzbare Datenrate von 9,6 kbit/s. Diese Übertragungsart wird Circuit Switched Data (CSD) genannt. Eine fortschrittliche Kanalkodierung ermöglicht auch 14,4 kbit/s, bewirkt bei schlechten Funkverhältnissen aber viele Blockfehler, so dass die „Downloadrate“ tatsächlich niedriger ausfallen kann als mit erhöhter Sicherung auf dem Funkweg. Deshalb wird in Abhängigkeit von der Bitfehlerhäufigkeit zwischen 9,6 und 14,4 kbit/s netzgesteuert umgeschaltet (=Automatic Link Adaptation, ALA).

Beides ist jedoch für viele Internet- und Multimediaanwendungen zu wenig, so dass Erweiterungen unter dem Namen HSCSD und GPRS geschaffen wurden, die eine höhere Datenrate ermöglichen, indem mehr Bursts pro Zeiteinheit für die Übertragung genutzt werden können. HSCSD nutzt eine feste Zuordnung mehrerer Kanalschlitze, GPRS nutzt Funkschlitze dynamisch für die aufgeschalteten logischen Verbindungen (besser für den Internetzugang). Eine Weiterentwicklung von GPRS ist E-GPRS. Dies ist die Nutzung von EDGE für Paketdatenübertragung.

Die Position eines Mobiltelefons ist für den Mobilfunkbetreiber durch die permanente Anmeldung am Netz in gewissen Genauigkeitsgrenzen bekannt. Im Standby-Betrieb ist sie zumindest durch die Zuordnung zur aktuell verwendeten Location Area gegeben. Diese Information wird bei Bewegung der Mobilstation regelmäßig aktualisiert.

GSM-Ortung stellt je nach Anwendungsfall eine Alternative zum GPS dar und wird für verschiedene Dienste genutzt, unter anderem für Location Based Services, Routenplaner, Flottenmanagement für Transportunternehmen oder eine Hilfe zum Wiederauffinden eines Mobiltelefons.

Die Verwendung für Rettungsdienste ermöglicht das schnelle Auffinden von Unfallopfern. Ebenso wird GSM-Ortung in der Strafverfolgung als Hilfsmittel der Polizei eingesetzt.

GSM wurde ursprünglich hauptsächlich für Telefongespräche, Faxe und Datensendungen mit konstanter Datenrate konzipiert. Burstartige Datensendungen mit stark schwankender Datenrate, wie es beim Internet üblich ist, wurden nicht eingeplant.

Mit dem Erfolg des Internet begann daher die sogenannte „Evolution von GSM“, bei der das GSM-Netz komplett abwärtskompatibel mit Möglichkeiten zur paketorientierten Datenübertragung erweitert wurde. Außerdem sollten nur minimale Kosten durch den Austausch von vielfach verwendeten Komponenten entstehen.

Geschwindigkeiten bis zu 14,4 kBit/s werden mit Circuit Switched Data erreicht.

Durch die Kopplung von mehreren Kanälen erreicht HSCSD insgesamt eine höhere Datenrate, maximal 115,2 kbit/s. Um HSCSD nutzen zu können, braucht man ein kompatibles Mobiltelefon, auf Seiten des Netzbetreibers sind Hardware- und Softwareänderungen bei Komponenten innerhalb der Basisstationen und des Kernnetzes erforderlich. In Deutschland unterstützen nur Vodafone und E-Plus HSCSD.

GPRS erlaubte erstmals eine paketvermittelte Datenübertragung. Der tatsächliche Datendurchsatz hängt unter anderem von der Netzlast ab und liegt bei maximal 171,2 kbit/s. Bei geringer Last kann ein Nutzer mehrere Zeitschlitze parallel verwenden, während bei hoher Netzlast jeder GPRS-Zeitschlitz auch von mehreren Benutzern verwendet werden kann. GPRS erfordert beim Netzbetreiber allerdings innerhalb des Kernnetzes zusätzliche Komponenten (den GPRS Packet Core).

Mit EDGE wurde durch eine neue Modulation (8PSK) eine Erhöhung der Datenrate ermöglicht. Sie beträgt maximal 384 kbit/s. Mit EDGE werden GPRS zu E-GPRS (Enhanced GPRS) und HSCSD zu ECSD (Enhanced Circuit Switched Data) erweitert.

Streaming services erfordern eine minimale garantierte Datenrate. Dies ist in GPRS ursprünglich nicht vorgesehen. Inzwischen (d. h. ab 3GPP release 99) wurden durch Einführung entsprechender Quality-of-service-Parameter und einige andere Eigenschaften die Voraussetzungen dafür geschaffen, echtes Streaming über GPRS zu ermöglichen.

Seit Mitte 2004 wird in den Standardisierungsgremien an einer Methode gearbeitet, die es Mobilgeräten erlauben soll, GSM-Dienste statt über die GSM-Luftschnittstelle auch über jede Art von anderen (IP-)Übertragungssystemen zu nutzen. Dafür sollen die Sendestationen von WLAN, Bluetooth etc. über sogenannte Generic Access Controller an das GSM core network angeschlossen werden. Die GSM-Nutzdaten sowie die Signalisierungsdaten werden dann durch das IP-Netz hindurchgetunnelt.

Cell Broadcast oder Cell Broadcasting (kurz CB) ist ein Mobilfunkdienst zum netzseitigen Versenden von Kurzmitteilungen an alle in einer bestimmten Basisstation eingebuchten MS.

BOS-GSM (je nach Anbieter auch BOS@GSM, GSM-BOS) ist eine Technik zur digitalen Funkkommunikation von Anwendern mit besonderen Sicherheitsanforderungen wie Behörden und Organisationen mit Sicherheitsaufgaben (BOS: Polizei, Feuerwehr, Rettungsdienste).

Im französischen Sprachgebrauch wird vor allem in Belgien häufig die Abkürzung „GSM“ für das deutsche Wort „Mobiltelefon“ benutzt. Auch in der bulgarischen Sprache, die seit über 200 Jahren viele Wörter aus dem Französischen entlehnt, wird „GSM“ synonym für „Mobiltelefon“ gebraucht.

GSM hat einige Defizite in puncto Sicherheit aufzuweisen. Dazu zählen unter anderem:


Das Protokoll von GSM ist gegen Man-in-the-middle-Angriffe (MITM) nicht gewappnet. Ein Beispiel für den möglichen Einsatz ist ein IMSI-Catcher. Das Gerät erzwingt die Ausschaltung der Verschlüsselung.

2003 präsentierten Elad Barkan, Eli Biham und Nathan Keller einen alternativen Man-in-the-middle-Angriff gegen GSM, der es ermöglicht, den A5/3-Verschlüsselungsalgorithmus zu umgehen. Dieser Angriff ist ein Angriff gegen das GSM-Protokoll und kein Angriff gegen die Chiffre KASUMI selbst. Eine längere Version des Papers wurde im Jahr 2006 veröffentlicht. Der Angreifer positioniert sich mit einer eigenen Basisstation zwischen den mobilen Teilnehmer und der richtigen Basisstation (Betreiber-Netzwerk). Die Challenge RAND wird an den mobilen Teilnehmer weitergereicht. Die Antwort SRES wird jedoch vom Angreifer zwischengespeichert. Das Mobiltelefon wird nun vom Angreifer aufgefordert eine A5/2-Verschlüsselung zu beginnen. Nach Zustandekommen der Verschlüsselung bricht der Angreifer innerhalb einer Sekunde den Geheimtext und extrahiert den Schlüssel K. Der Angreifer schickt nun das zwischengespeicherte SRES an das Betreiber-Netzwerk. Der Angreifer ist gegenüber dem Netzwerk authentifiziert. Das Netzwerk fordert den Angreifer nun auf, eine Verschlüsselung A5/1 oder A5/3 zu nutzen. Der Angreifer benutzt den vorher extrahierten K und es kommt eine verschlüsselte Kommunikation zustande. Der Angreifer kann anschließend Gespräche abhören, sie in Echtzeit dekodieren oder zwischenspeichern. Das Umleiten und die Übernahme von Gesprächen, das Verändern von SMS und das Führen von Gesprächen auf Kosten Anderer ist ebenfalls möglich.

Im Rahmen des USENIX-Security Symposiums 2013 wurde gezeigt, dass mit Hilfe einer geschwindigkeitsoptimierten OsmocomBB-Firmware – auf wenigen Geräten installiert – ein GSM-Netz zum Denial of Service gebracht werden kann, indem die präparierten Handys alle Paging-Requests beantworten (mit etwa 65 Antworten pro Sekunde), bevor der berechtigte Empfänger reagieren kann.
GSM sieht daraufhin von weiteren Anfragen ab, eine Authentifizierung folgt erst im nächsten Schritt. Die Hälfte aller Netze (global) prüft in weniger als einem von zehn Fällen die Legitimation des Endgerätes.

Die Algorithmen A5/1 und A5/2 können in Echtzeit gebrochen werden. Der A5/3-Algorithmus mit einem 64 Bit-Schlüssel basiert auf der KASUMI-Chiffre. Die KASUMI-Chiffre gilt seit 2010 als theoretisch gebrochen. Ein erfolgreicher praktischer Angriff gegen A5/3 ist nicht bekannt. Als sicher gilt der A5/4-Algorithmus mit einem 128 Bit-Schlüssel.

Der Sicherheitsforscher Karsten Nohl fordert "kurzfristig" den Einsatz von SIM-Karten mit zusätzlicher Verifikationsfunktion. Ein kleines Java-Programm auf der Karte könnte den Netzbetreiber gegenüber dem Mobilfunkteilnehmer verifizieren. Damit würde die jetzige einseitige durch eine gegenseitige Authentifizierung ersetzt. Dieses Vorgehen verhindert MITM-Angriffe und hilft auch gegen DoS-Paging-Angriffe. Des Weiteren müssen Netzbetreiber und Mobilfunkgeräte den Verschlüsselungsalgorithmus A5/3 benutzen und auf Kombinationen mit A5/1 oder A5/2 verzichten.

"Langfristig" fordert der Experte den Einsatz von A5/4 und die Nutzung von USIM-Karten.

Im Abschnitt Weblinks findet sich mit der "GSM Security Map" eine visuelle Übersicht der GSM-Sicherheit in verschiedenen Ländern.

Im Oktober 2013 berichteten mehrere Medien über das Abhören von Angela Merkels Parteihandy durch die US-amerikanische National Security Agency (NSA). Laut FAZ besaß Merkel zu diesem Zeitpunkt einen Mobilfunkvertrag mit Vodafone. Es bestand der Verdacht, dass das GSM-basierte Funknetz des Providers durch die NSA angezapft wurde.

GSM arbeitet mit unterschiedlichen Frequenzen für den Uplink (vom Mobiltelefon zum Netz) und den Downlink (vom Netz zum Mobiltelefon). Die folgenden Frequenzbänder können vom Mobilfunkanbieter verwendet werden:


Aus Kostengründen erfolgte der Bau von neuen Mobilfunknetzen (z. B. Australien/Telstra) oder Mobilfunknetz-Erweiterungen (z. B. Schweiz/Swisscom) nur mit der neueren Mobilfunktechnologie UMTS. Neue Mobilfunkstationen senden immer öfter nur ein UMTS- und LTE-Signal aus.

In Deutschland fand GSM-Mobilfunk bis zum Jahr 2005 nur im P-GSM- und DCS-1800-Bereich statt. Ende 2005 öffnete die Bundesnetzagentur den gesamten E-GSM-Frequenzbereich für den GSM-Mobilfunk.

Daraufhin begannen E-Plus und O2 ab April 2006 zum Teil in den E-GSM-Bereich umzuziehen (E-Plus: 880,2 – 885,0 MHz / 925,2 – 930,0 MHz und O2: 885,2 – 890,0 MHz / 930,2 – 935,0 MHz). Diese Bereiche nutzen die beiden Anbieter von nun an zum Ausbau ihrer Netze in dünn besiedelten Regionen. Somit verfügen alle vier deutschen Mobilfunkanbieter über Spektren in beiden Bereichen.

Die alten Zuweisungen im DCS-1800-Bereich mussten sie zum Teil als Ausgleich im Januar 2007 abgeben. Sie wurden bei der Frequenzauktion im Jahr 2010 neu vergeben:


Die aktuellen GSM-Lizenzen laufen 2016 aus und werden dann durch die Bundesnetzagentur voraussichtlich wieder neu versteigert.

Die Kanäle (ARFCN) der einzelnen Bänder sind wie folgt auf die fünf deutschen Betreiber verteilt:

Das obere Bandende des GSM1800-Bereiches (ab ARFCN 864) wurde bis zur Frequenzauktion 2015 freigehalten, um störende Beeinflussungen bei DECT-Schnurlostelephonen zu vermeiden (sog. DECT-Schutzband 1875.5 - 1880.0 MHz). Außerdem wurde dieser Bereich bis Ende 2015 für temporäre und dauerhafte Test- und Versuchsanlagen durch die Bundesnetzagentur an Firmen wie auch Privatpersonen vergeben.

R-GSM, E-GSM (GSM 900), E-UTRA Band 8

Die DB betreibt entlang der Eisenbahnstrecken ein nicht öffentliches GSM-R-Mobilfunknetz.

DCS 1800 (GSM 1800) E-UTRA Band 3

Sch = Schutzabstand zum benachbarten DECT-Band

Ende Juni 2013 hatte die Bundesnetzagentur bekannt gegeben, dass die zum 31. Dezember 2016 ablaufenden Nutzungsrechte an den Mobilfunkfrequenzen erneut in einer Auktion versteigert werden sollen. Neben den Frequenzen im 900-MHz- und 1800-MHz-Bereich, sollen ebenfalls Frequenzblöcke im Bereich von 700 MHz und 1,5 GHz im Rahmen der Auktion vergeben werden. Den bisherigen vier Mobilfunknetzbetreibern soll je ein Frequenzblock im 900-MHz-Bereich außerhalb der Auktion zugeteilt werden, um die Grundversorgung zu sichern .

Die ab 1. Januar 2017 gültigen Bundesnetzagentur-Konzessionen erlauben die Nutzung der Mobilfunkfrequenzen durch die deutschen Mobilfunkanbieter wie nachfolgend abgebildet. Das von der Bundesnetzagentur zugewiesene Frequenzband kann vom Mobilfunkanbieter in Deutschland für GSM, UMTS oder LTE genutzt werden. Üblich ist die Nutzung des zugewiesenen Frequenzband für unterschiedliche Techniken (zum Beispiel: E-UTRA Band 8: GSM und UMTS).

R-GSM, E-GSM (GSM 900), E-UTRA Band 8

Die DB betreibt entlang der Eisenbahnstrecken ein nicht öffentliches GSM-R-Mobilfunknetz. Die Angaben für E-UTRA Band 8 entsprechen der Zuteilung ab 2017!

DCS 1800 (GSM 1800) E-UTRA Band 3

Die Kanäle (ARFCN) der einzelnen Bänder sind wie folgt auf die vier deutschen Betreiber verteilt:

Die bis Ende 2034 gültigen RTR-Konzessionen erlauben die Nutzung der Mobilfunkfrequenzen durch die österreichischen Mobilfunkanbieter wie nachfolgend abgebildet. Das vom RTR zugewiesene Frequenzband kann vom Mobilfunkanbieter in Österreich für GSM, UMTS oder LTE genutzt werden. Üblich ist die Nutzung des zugewiesenen Frequenzbandes für unterschiedliche Technologien (zum Beispiel: E-UTRA Band 8: GSM und UMTS).

R-GSM, E-GSM (GSM 900), E-UTRA Band 8

Die ÖBB betreibt entlang der Eisenbahnstrecken ein nicht öffentliches GSM-R-Mobilfunknetz. Die Angaben für E-UTRA Band 8 entsprechen der Zuteilung ab 2018! Bis 1. Januar 2018 werden in mehreren Schritten die Mobilfunkfrequenzen auf dem E-UTRA Band 8 neu zugeteilt (Refarming).

DCS 1800 (GSM 1800) E-UTRA Band 3

Die Angaben für E-UTRA Band 3 entsprechen der Zuteilung ab 2020! Bis 1. Januar 2020 werden in mehreren Schritten die Mobilfunkfrequenzen auf dem E-UTRA Band 3 neu zugeteilt (Refarming).

Siehe Mobilfunkfrequenzen in der Schweiz.

Alle öffentlichen Schweizer Mobilfunkanbietern haben die Abschaltung ihres GSM-Mobilfunknetzes bekannt gegeben:


Bereits heute kann der Einsatz eines nur 2G/GSM-tauglichen Mobiltelefons zu Mobilfunkempfangsproblemen führen.

Es wird erwartet, dass GSM langfristig durch Nachfolgestandards ersetzt wird. Während in Australien und Singapur die Abschaltung im Jahr 2017 bereits beschlossen wurde, steht z. B. für Deutschland und Österreich noch kein Abschalt-Termin fest, jedoch wird in der Schweiz wahrscheinlich ab 2021 kein öffentliches GSM-Mobilfunknetz mehr zur Verfügung stehen.





</doc>
<doc id="2062" url="https://de.wikipedia.org/wiki?curid=2062" title="General Packet Radio Service">
General Packet Radio Service

General Packet Radio Service, abgekürzt GPRS (deutsch: „Allgemeiner paketorientierter Funkdienst“) ist die Bezeichnung für den paketorientierten Dienst zur Datenübertragung in GSM-Netzen.

Im Gegensatz zum leitungsvermittelten (englisch "circuit switched") Datendienst "CSD" ist GPRS paketorientiert. Das heißt, die Daten werden beim Sender in einzelne Pakete umgewandelt, als solche übertragen und beim Empfänger wieder zusammengesetzt.

Wenn GPRS aktiviert ist, besteht nur virtuell eine dauerhafte Verbindung zur Gegenstelle (sog. "-Betrieb"). Erst wenn wirklich Daten übertragen werden, wird der Funkraum besetzt, ansonsten ist er für andere Benutzer frei. Deshalb braucht kein Funkkanal dauerhaft (wie bei CSD) für einen Benutzer reserviert zu werden. Deshalb werden die Kosten für GPRS-Verbindungen üblicherweise nach übertragener Datenmenge berechnet, und nicht nach der Verbindungsdauer. Maßgeblich sind natürlich die individuellen Vertragskonditionen.

Die GPRS-Technik ermöglicht bei der Bündelung aller acht GSM-Zeitschlitze eines Kanals theoretisch eine Datenübertragungsrate von 171,2 Kilobit pro Sekunde. Im praktischen Betrieb ist die Anzahl der nutzbaren Zeitschlitze innerhalb eines Rahmens jedoch durch die Fähigkeit der Mobilstation (englisch "multislot capability") und der Netze begrenzt. Am Markt befinden sich (Stand 2008) Geräte der Multislot Class 12 mit maximal je vier Zeitschlitzen im Downlink und im Uplink (jedoch gleichzeitig maximal 5 Zeitschlitze). Die damit erreichbare Datenübertragungsrate beträgt – abhängig vom verwendeten Kodierungsschema (hängt ab vom Signal und Rauschverhältnis) und der von der Netzauslastung abhängigen Anzahl der zugeteilten Zeitschlitze (Timeslots) – bis zu 53,6 kbps (bei 4 Zeitschlitzen und CS-2). Das entspricht in etwa der Geschwindigkeit eines V.90-Telefonmodems.

Es existieren 3 verschiedene Endgeräteklassen, die die grundsätzlichen Fähigkeiten eines Endgeräts angeben. Die Endgeräteklasse wird mit einem Buchstaben angegeben:
GPRS-fähige Mobiltelefone gehören zumeist zur Geräte-Klasse B. (Stand 2008/2009) Einige Nokia-Geräte, wie das N900, unterstützen Klasse A.

Ungefähr seit dem Jahr 2000 unterstützen viele Mobiltelefone GPRS, etwa für die Betrachtung von WAP-Seiten. Der Multimedia Messaging Service (MMS) basiert ebenfalls auf GPRS. Oft kann auch ein Computer oder Handheld mit einem GPRS-fähigen Mobiltelefon verbunden werden, um diesem einen vollwertigen, wenn auch schmalbandigen Internetzugang zu gewähren. Das Mobiltelefon fungiert dann als Modem. Bekannt sind auch kleine GPRS-Modems als Steckkarten für Notebooks. Besonders geeignet ist GPRS auch für Fernwirkaufgaben. In der Regel wird hier nur eine geringe Bandbreite benötigt, die Übertragungsgeschwindigkeit spielt eine untergeordnete Rolle. Größte Vorteile von GPRS im Bereich Fernwirken sind die Netzabdeckung und die Verfügbarkeit von GSM, sowie die geringeren Investitionen im Vergleich zu anderen Übertragungstechniken. Ein weiterer Anwendungsfall ist die Ortung von Fahrzeugen und Objekten, bei der GPRS zur Übertragung von Positions- und Telemetriedaten benutzt wird. Weiterhin wird das GPRS-Datennetz für den Mobilfunkdienst Push-to-talk genutzt.

Der paketvermittelnde Dienst GPRS baut auf dem GSM-Mobilfunknetz auf, benötigt aber zusätzliche Netzelemente: Die PCU, den SGSN und den GGSN.

"Siehe Hauptartikel: GPRS Support Node, Packet Control Unit"

Die GSM-Richtlinien wie auch WPP3G (der GSM-Nachfolger für UMTS) definieren Schnittstellen zwischen den verschiedenen Netzelementen. Die folgende Liste führt die gebräuchlichsten Schnittstellen (Signalisierung) und Verbindungen (Signalisierung und Nutzdaten) auf. Die weitgehend englischen Begriffe sind dem Regelwerk "GSM Recommendations" entnommen. Eine Übersetzung ist nicht immer sinnstiftend.


Die BSC koppeln die GPRS-Paketdaten aus und leiten diese über Frame-Relay- oder IP-Verbindungen an den zuständigen Serving GPRS Support Node (SGSN) weiter. Jeder SGSN verwaltet den GPRS-Datenverkehr für eine größere Anzahl von BSCen. Sofern die Gb-Schnittstelle über IP statt Frame Relay geleitet wird, kann eine BSC mit einer Gruppe von SGSN kommunizieren. Man spricht dann von „SGSN in Pool“ oder „Gb flex“. Damit wird das Netz ausfallsicherer, und die Last kann besser zwischen den SGSN verteilt werden.

Ein SGSN hat für GPRS-Datenkommunikation eine ähnliche Funktion wie ein MSC für Sprachkommunikation. Der SGSN organisiert das Einbuchen von Teilnehmern für GPRS-Dienste, den Wechsel von Funkzellen und SGSN-Bereichen (GPRS-Routing Area Update bzw. GPRS-Cell Reselection) und das Routing von GPRS-Daten. Ein SGSN nutzt hierfür folgende Schnittstellen:

Die GGSN (Gateway GPRS Support Node) stellen die GPRS-Datenverbindungen zu netzinternen Diensteplattformen oder zu Datennetzen her. Ein GGSN hat folgende Schnittstellen, welche alle auf IP basieren:

Der Zugang zum GPRS-Netz erfolgt über einen Zugangspunkt, der Access Point Name (APN) genannt wird. Die Zuordnung von APN zu einem Teilnehmer erfolgt über die Teilnehmerdaten, die im HLR gespeichert werden. Ein Teilnehmer kann dabei mehrere APN nutzen.





</doc>
<doc id="2065" url="https://de.wikipedia.org/wiki?curid=2065" title="Garantie">
Garantie

Um eine Garantie handelt es sich allgemein, wenn ein Rechtssubjekt ein bestimmtes Handeln oder Unterlassen bereits vor Eintritt eines bestimmten Ereignisses rechtsverbindlich zusagt. 

Die „Sicherheit, Gewähr“ () ist eine Ableitung aus dem Wort „Bürge“ (). Beide Worte entstammen dem altfranzösischen Verb „für etwas haften“ () und wurden in der französischen Diplomatensprache verwandt. Als Lehnwort gelangte es im Jahre 1661 in gleicher Schreibweise nach Preußen. 

In der Umgangssprache wird unter Garantie vornehmlich die Zusicherung der Funktionsfähigkeit von Gütern – insbesondere technischer Konsumgüter – für einen bestimmten Zeitraum bezeichnet. Bei Funktionsmängeln während dieses Zeitraums verpflichtet sich der Hersteller oder Verkäufer, der die Garantie abgegeben hat, die Funktionsfähigkeit kostenlos wiederherzustellen. Die Bedingungen der Garantie sind in einem Garantieschein festgehalten. Der Sprachgebrauch macht häufig keinen Unterschied zwischen der gesetzlichen Gewährleistungspflicht und einer zusätzlichen freiwillig angebotenen vertraglichen Garantie, während es sich juristisch um unterschiedliche Rechte bzw. Verpflichtungen handelt.

Im Wirtschaftsleben gibt es einerseits Garantien, die eine bereits bestehende eigene Verpflichtung des Garanten (Eigengarantie) verstärken oder begründen (z. B. Beschaffenheits-/Haltbarkeitsgarantie; Garantie der Werthaltigkeit von Aktiven im Rahmen eines Unternehmenskaufs etc.), und andererseits Garantien, die ein Garant für einen Auftraggeber einem begünstigten Auftragnehmer gegenüber abgibt, um sicherzustellen, dass die Verpflichtung auch bei Unwillen oder Unvermögen des Auftraggebers erfüllt wird. Banken (Avalkredit) und Versicherungen (Kautionsversicherung) bieten solche Garantien gegen Entgelt an; Muttergesellschaften oder natürliche Personen (Verwandte, Freunde) stehen allenfalls unentgeltlich für Verpflichtungen nahestehender natürlicher oder juristischer Personen ein, wobei in diesem Fall oft die Form der Bürgschaft gewählt wird.

Im Handel ist die Garantie eine zusätzlich zur gesetzlichen Gewährleistungspflicht übernommene freiwillige und frei gestaltbare Dienstleistung eines Händlers oder Herstellers gegenüber dem Kunden. Wird eine solche Beschaffenheits- oder Haltbarkeitsgarantie abgegeben, so ist Abs. 2 Bürgerliches Gesetzbuch (BGB) anwendbar. Die Garantiezusage bezieht sich häufig auf die Funktionsfähigkeit bestimmter Teile (oder des gesamten Geräts) über einen bestimmten Zeitraum. Bei einer Garantie spielt der Zustand der Ware zum Zeitpunkt der Übergabe an den Kunden keine Rolle, da ja die Funktionsfähigkeit für den Zeitraum „garantiert“ wird. Die Garantie ist jedoch üblicherweise ausgeschlossen, wenn die Ursache des Defekts beim Kunden liegt oder der Kunde versucht hat, selbst eine Reparatur durchzuführen. Für Form und Inhalt der Garantieerklärung gelten beim Verbrauchsgüterkauf besondere Bestimmungen.

Häufig wird Garantie jedoch mit Gewährleistung verwechselt. Diese beiden Begriffe unterscheiden sich wie folgt:
Im juristischen Sinn definiert eine Garantie die vertraglich vereinbarte Verpflichtung eines Garanten, während die Gewährleistung direkt aus dem Gesetz abzuleiten ist. 
Die gesetzliche Gewährleistung bezieht sich auf die Mangelfreiheit des Kaufgegenstandes zum
Zeitpunkt der Übergabe an den Käufer. Genaueres siehe Gewährleistung. Sie beträgt nach BGB allgemein 24 Monate und kann bei Gebrauchtwaren per AGB oder einzelvertraglich auch gegenüber Verbrauchern auf zwölf Monate verkürzt werden. Der Kunde kann daher seine Rechte bei Lieferung eines mangelbehafteten Gegenstandes nunmehr zwei Jahre lang (bzw. ein Jahr bei gebrauchten Waren, sofern kaufvertraglich vereinbart) geltend machen. Zu Gunsten des privaten Käufers gegenüber dem gewerblichen Verkäufer wird beim Verbrauchsgüterkauf in den ersten sechs Monaten nach Übergabe vermutet, dass die Ware schon zum Lieferzeitpunkt defekt war, es sei denn, der Verkäufer kann nachweisen, dass der Mangel zum Zeitpunkt der Lieferung noch nicht bestand (Beweislastumkehr). Reklamiert der Kunde später als sechs Monate nach dem Kauf, so kehrt die Beweislast zum rechtlichen Grundsatz zurück, dass grundsätzlich jede Partei die Beweislast für die tatsächlichen Voraussetzungen der ihr günstigen Rechtsnorm trägt, d. h., er muss beweisen, dass der Gegenstand schon bei der Übergabe einen Mangel aufwies. 

Für den Kunden ist zu beachten, dass durch eine Garantiezusage die gesetzliche Gewährleistung in keinem Fall ersetzt oder gar – im Umfang oder der Zeitdauer – verringert werden kann, sondern immer nur neben der bzw. zusätzlich zur gesetzlichen Gewährleistung Anwendung findet.

Garantien müssen auf Wunsch des Konsumenten schriftlich oder auf dauerhaftem Datenträger übermittelt werden. Sie müssen den Hinweis enthalten, dass daneben und unberührt von der Garantie Gewährleistungsansprüche bestehen können. Garantien müssen immer mehr Rechte, als die gesetzliche Gewährleistung bereits beinhaltet, enthalten.

Während bei der Qualitätsgarantie in der Regel der Hersteller oder Händler nur selbst eine Zusicherung für eine eigene Verpflichtung gibt, besteht im Wirtschaftsleben national und insbesondere international das Bedürfnis, dass eine dritte Partei mit unbestrittener Bonität die Verpflichtungen des Hauptschuldners zusätzlich absichert (garantiert).
Sie deckt im internationalen Handels- und Wirtschaftsverkehr Erfüllungsrisiken ab. 
Die Garantie dokumentiert, dass der Begünstigte eine vertraglich vereinbarte Leistung (z. B. Zahlung, Lieferung, Dienstleistung) von einem Dritten erhält. Bei Nichterfüllung ist der festgelegte Betrag der Garantie in Anspruch zu nehmen. 

Eine natürliche oder juristische Person, die aus einem Rechtsgeschäft eine Verpflichtung zu erfüllen hat (Auftraggeber), beauftragt eine dritte Partei (Garant) eine Garantie zugunsten eines Dritten (Begünstigter) auszustellen. 

Garant ist meist eine Bank, es kann jedoch auch eine Versicherungsgesellschaft, eine Muttergesellschaft oder eine staatliche Institution (Bundesgarantie, Landesgarantie) der Garant sein.

Bankgarantien (Avale) können direkt durch die Bank des Verpflichteten an den Begünstigten abgegeben werden (direkte Garantie) oder indirekt über eine Korrespondenzbank (indirekte Garantie). Bei dieser Konstruktion spricht man auch von einer Rückgarantie.

Die Garantie im Bankgeschäft stellt ein wichtiges Sicherungsmittel dar, welches insbesondere im internationalen Kreditverkehr die Bürgschaft ersetzt. Entweder nehmen Kreditinstitute diese Gewährleistung als Kreditsicherheit herein oder stellen Bankgarantien aus, die bestimmte Geschäfte absichern.

Dabei verpflichtet sich der Garant einseitig im formfreien Garantievertrag, entweder für einen künftigen Schaden/Verlust ohne Rücksicht auf Verschulden einzustehen oder die Haftung für einen bestimmten wirtschaftlichen Erfolg zu übernehmen. Der garantierte Erfolg kann auch darin bestehen, dass die Bank als Gläubigerin einer Kreditforderung den Kreditbetrag vom Schuldner zurückerhält. Es handelt sich um eine abstrakte Haftung, die selbständig neben der Hauptschuld übernommen wird, selbst wenn letztere aus Rechtsgründen nicht (mehr) besteht. Der Garant hat im Falle der Gewährleistung den Gläubiger so zu stellen, als ob der garantierte Erfolg eingetreten oder der Schaden nicht entstanden wäre.

Diese Form der Gewährleistung ist international üblich, aber im BGB nicht geregelt. Die Bestimmungen über die Bürgschaft können nicht analog angewandt werden.

Eine Unterform ist die Garantie „"auf erstes Anfordern"“. Sie hat den Zweck, rechtliche oder tatsächliche Streitfragen aus dem Verhältnis Gläubiger-Hauptschuldner (sog. Valutaverhältnis) – deren Beantwortung sich nicht von selbst ergibt („liquide Beweise“) – aus dem Garantieversprechen herauszuhalten und nach vollzogener Inanspruchnahme einem Rückforderungsprozess zwischen Gläubiger und Hauptschuldner vorzubehalten. Das der Stellung der Bankgarantie zugrunde liegende Rechtsverhältnis zwischen dem Garantieauftraggeber und dem Begünstigten hat für die Rechtsbeziehungen des Begünstigten zur Bank daher nur dann Bedeutung, wenn sich dies aus dem Inhalt des Garantievertrages ergibt oder wenn eine missbräuchliche Inanspruchnahme der Garantie offensichtlich oder liquide beweisbar ist. Bei Bankgarantien auf erstes Anfordern wird sich nur in Ausnahmefällen aus dem Garantievertrag ableiten lassen, dass im Falle des Vorliegens der formellen Voraussetzungen für die Inanspruchnahme der Garantie (formeller Garantiefall) der Anspruch des Begünstigten gegen die Bank zusätzlich noch davon abhängig sein soll, dass ihm auch im Valutaverhältnis zum Garantieauftraggeber ein Anspruch zusteht (materieller Garantiefall).

Eine "Rück- oder Gegengarantie" auf erstes Anfordern liegt vor, wenn im Rahmen eines mehrstufigen (indirekten) Garantieverhältnisses die vom Garantieauftraggeber eingeschaltete (Erst-)Bank die Garantie gegenüber dem (Letzt-)Begünstigten nicht selbst erteilt, sondern damit eine weitere Bank (Zweitbank) beauftragt und dieser die Erstattung der aus deren Garantieübernahme entstehenden Aufwendungen „auf erstes Anfordern“ verspricht. Im Verhältnis der beteiligten Banken zueinander handelt es sich um eine selbständige direkte Garantie zur Sicherung und Ergänzung des vertraglichen Aufwendungsersatzanspruchs der Zweitbank gegen die Erstbank. Diese für Direktgarantien auf erstes Anfordern entwickelten Regeln gelten grundsätzlich auch für eine Rückgarantie auf erstes Anfordern. Beim Missbrauchseinwand muss jedoch den Besonderheiten der Rückgarantie Rechnung getragen werden. Der zu begleichende Anspruch aus der Rückgarantie ist vom tatsächlichen Eintritt der Zahlungsvoraussetzungen der Garantie der Zweitbank gegenüber dem Letztbegünstigten grundsätzlich unabhängig. Ebenso wenig setzt er voraus, dass die Zweitbank die Zahlung an den Letztbegünstigten für erforderlich (§ 670 BGB) halten durfte; diese Frage ist vielmehr erst in einem Rückforderungsprozess zwischen Erst- und Zweitbank zu klären.

Die Abstraktheit ist kein juristischer Ausdruck, sondern sie wird in der Wirtschaftspraxis als Gegensatz zur Akzessorietät (der Bürgschaft) verwendet. Die Garantie ist so verstanden in zweifacher Weise abstrakt. Einerseits begründet sie eine vom Grundgeschäft unabhängige Leistungsverpflichtung des Garanten ("äußere Abstraktheit"), andererseits bleibt die Wirksamkeit einer Verfügung dadurch unbeeinträchtigt, dass die Vereinbarung über ihren Zweck nicht in ihr enthalten ist ("inhaltliche Abstraktheit"). Das der Bankgarantie zugrunde liegende Rechtsverhältnis zwischen dem Hauptschuldner und dem Garantie-Begünstigten (sog. "Valutaverhältnis") hat für die Rechtsbeziehungen des Begünstigten zum Garanten daher nur ausnahmsweise Bedeutung. Die auf das Grundgeschäft bezogenen Einreden/Einwendungen des Hauptschuldners gegenüber dem Begünstigten werden daher für den Garanten ausgeschlossen.

Im Gegensatz zum abstrakten Sicherungsinstrument Garantie ist die Bürgschaft akzessorisch, so dass die auf das Grundgeschäft bezogenen Einreden/Einwendungen des Hauptschuldners gegenüber dem Begünstigten auch dem Bürgen zustehen und die Bürgschaft mit dem Bestand der Forderung aus dem Grundgeschäft sehr eng zusammenhängt.

Um die Rechtssicherheit in internationalen Geschäften zu verbessern und zu verhindern, dass Auftraggeber oder Auftragnehmer aufgrund ihrer wirtschaftlichen Stärke einseitige und unbillige Konditionen durchsetzen, haben internationale Finanzierungsinstitute Kreditbedingungen erarbeitet, die für Aufträge verbindlich sind, die durch diese Institutionen finanziert werden. So hat z. B. Weltbank ein Regelwerk für die Vergabe von Projektaufträgen herausgegeben, das auch verbindliche Texte für diverse Garantien vorschreibt.


Garantien dienen meist als Kreditsicherheit bei Kreditinstituten. Diese gewähren Kredite an dritte Kreditnehmer auf der Grundlage der Kreditwürdigkeit des Garanten. Voraussetzung ist die so genannte Bürgensubstitution, bei der das schlechtere Risikogewicht des Kreditnehmers durch das bessere Risikogewicht des Garanten ersetzt wird.

Kreditsicherheiten gelten seit Januar 2014 bankenaufsichtsrechtlich als Kreditrisikominderungstechniken. Werden Kreditsicherheiten durch die in allen EU-Mitgliedstaaten geltenden Capital Requirements Regulation (CRR) als Kreditrisikominderungstechniken anerkannt, führen sie bei Kreditinstituten zu einer geringeren Unterlegung durch Eigenkapital als bei Blankokrediten. Das hat zur Folge, dass besicherte Kredite mit einem günstigeren Kreditzins gewährt werden können.

Art. 194 CRR stellt Grundsätze für die aufsichtsrechtliche Anerkennung von Kreditrisikominderungstechniken auf, wonach Kreditsicherheiten insbesondere in allen Rechtsordnungen rechtswirksam () und durchsetzbar () sein müssen, ausreichend liquide, im Zeitablauf wertstabil und bei einem Kreditereignis zeitnah verwertbar sein müssen. Die positive Korrelation zwischen den Sicherheiten und der Kreditnehmerbonität darf nicht sehr hoch sein (Art. 194 Abs. 4 CRR). Unterschieden wird zwischen Kreditrisikominderungstechniken „mit Sicherheitsleistung“ (Realsicherheiten; Art. 4 Abs. 1 Nr. 58 CRR) und „ohne Sicherheitsleistung“ (Personalsicherheiten; Art. 203 CRR). 

Demnach gehören Garantien (und Bürgschaften) als Gewährleistungen zu den Personalsicherheiten. Zwecks Anerkennung haben Garantien bestimmte Bedingungen zu erfüllen. Art. 213 CRR verlangt unmittelbare Garantien, nach Art. 214 Abs. 1 CRR sind bestimmte Rückgarantien anerkannt. Bei Rückgarantien von Staaten und anderen öffentlichen Stellen dürfen die besicherten Kredite wie Forderungen an den Staat behandelt werden. Art. 215 CRR schreibt vor, dass bei Ausfall des Kreditnehmers der Sicherungsgeber (Garant) uneingeschränkt in Anspruch genommen werden kann und kein Vorbehalt vorhanden sein darf, nach dem das Institut den geschuldeten Betrag zunächst beim Kreditnehmer einfordern muss. Dieses Kriterium ist bei Garantien auf erste Anforderung erfüllt. Gemäß Art. 183 Abs. 1c CRR muss sie schriftlich erteilt sein, darf vom Sicherungsgeber nicht widerrufen werden können und Vermögenswerte des Sicherungsgebers müssen durch ein vollstreckbares Urteil pfändbar sein. Für anerkannte Sicherungsgeber gelten nach Art. 183 Abs. 1b CRR dieselben Regeln wie für Schuldner (Art. 171, 172 und 173 CRR), so dass deshalb die wirtschaftlichen Verhältnisse des haftenden Sicherungsgebers im Rahmen einer Kreditwürdigkeitsprüfung genauso zu prüfen sind wie die des Kreditnehmers. Zur Vermeidung positiver Korrelationen dürfen Sicherungsgeber weder konzernmäßig mit dem Kreditnehmer () noch mit dem Kreditinstitut verbunden sein. Nach Art. 233 Abs. 1 (CRR) ist bei der Sicherheitenbewertung der Betrag als Kreditsicherheit anzusetzen, zu dessen Zahlung sich der Sicherungsgeber im Falle des Kreditereignisses verpflichtet hat.


Wenn die Einhaltung von Verträgen zwischen Staaten (international oder bilateral) durch weitere nicht die direkt beteiligte Staaten (meist Großmächte) garantiert wird, so liegt eine völkerrechtliche Garantie vor. Wird eine solche Garantie durch mehrere Garantiemächte abgegeben, so kann es sich um eine Mehrzahl von Einzelgarantien handeln, d. h., jede Schutzmacht kann unabhängig von den anderen Maßnahmen zur Sicherung der Vertragseinhaltung einleiten. Es gibt jedoch auch die Form der Kollektivgarantie, die eine Abstimmung der Garantiemächte untereinander voraussetzt.
Neben der Garantie für die Einhaltung von Verträgen gibt es auch Garantien für die Erhaltung eines Zustandes oder die Wahrung von Rechten, z. B. Garantie der territorialen Integrität oder der Neutralität eines Staates.

Im Staatsrecht bezeichnet man die Festschreibung von Grundrechten in den Verfassungen als Garantie der Menschenrechte oder Grundrechte.
Neben der Garantie von individuellen Rechten enthalten Verfassungen meist auch konstitutionelle oder institutionelle Garantien (z. B. kommunale Selbstverwaltung aus Abs. 2 GG) Durch die Erhebung eines politischen Organisationsprinzips in den Verfassungsrang, wird es der beliebigen Änderung durch einfache Mehrheiten entzogen und damit besonders geschützt.







</doc>
<doc id="2066" url="https://de.wikipedia.org/wiki?curid=2066" title="GPL (Begriffsklärung)">
GPL (Begriffsklärung)

GPL steht als Abkürzung für:

.gpl („GIMP-Palette“) ist die Dateinamenserweiterung für:



</doc>
<doc id="2068" url="https://de.wikipedia.org/wiki?curid=2068" title="Gemüse">
Gemüse

Gemüse (mhd. "gemüese", ursprüngliche Bedeutung: Mus aus Nutzpflanzen) ist heute ein Sammelbegriff für essbare Pflanzenteile wild wachsender oder in Kultur genommener Pflanzen. Meist handelt es sich um Blätter, Knollen, Stängel oder Wurzeln von ein- oder zweijährigen krautigen Pflanzen, die roh, gekocht oder konserviert genossen werden. Im Gegensatz zu Pflanzen oder Pflanzenteilen, die vor allem wegen ihrer Reservestoffe (Kohlenhydrate, Eiweiß und Fette) genutzt werden und deshalb die Grundkost in der Ernährung des Menschen darstellen, wird Gemüse vor allem wegen seines Gehalts an Vitaminen, Mineralstoffen und sekundären Pflanzenstoffen als Beikost verzehrt. Gemüse ist geschmacksgebend und kalorienarm. Zudem hat Gemüse aufgrund seines hohen Gehalts an Ballaststoffen eine wichtige Funktion für die Verdauung.

Trockene Samen wie Erbsen oder Linsen und Getreidekörner zählen "nicht" zum Gemüse. Pflanzenteile, die als Gemüse "und" Gewürz genutzt werden, wie Paprika oder Zwiebeln, gelten nur dann als Gemüse, wenn sie eine erkennbare Hauptkomponente der Mahlzeit bilden.

Die Unterscheidung von Obst und Gemüse ist nicht eindeutig, sie ist kulturell bedingt.

In Deutschland gibt es verschiedene Definitionen, die einander zum Teil widersprechen:

"Feldgemüse" ist ein Sammelbegriff für Gemüse, das unter freiem Himmel angebaut wird. Diese Anbauart steht im Gegensatz zum gärtnerischen Gemüsebau, bei dem in Glashäusern, Folientunneln oder ähnlichen geschützten Bereichen gearbeitet wird. Zum Feldgemüse zählt man: Kohlgewächse, Salate, Zwiebeln, Gurken, Gemüsespargel, Karotten, Petersilie, Rote Rüben u. v. a.

Nach den Erntezeiten unterscheidet man "Frühgemüse, Sommergemüse, Herbstgemüse, Wintergemüse" und "Dauergemüse." Früher war diese Einteilung sehr wichtig für Anbauplanung und Ernährung. Durch den Anbau von Gemüsen in Gewächshäusern und den internationalen ganzjährigen Handel hat ihre Bedeutung stark abgenommen.

Nach Fruchtreife und dem Verzehr unterscheidet man "Frischgemüse" und "Lagergemüse". Auch diese Unterscheidung hat durch Weiterverarbeitung und Lebensmittelkonservierung an Bedeutung verloren. Zum Beispiel kann verderbliches Gemüse durch Tiefkühlen oder in Konservendosen frisch gehalten werden.

In der Europäischen Union teilt man zudem das Gemüse in zwei Gruppen ein, um es hinsichtlich Preis und Erzeugung möglichst vergleichbar zu machen:

Um eine gleichbleibende Qualität bei Gemüse im Handel zu gewährleisten, unterliegt es bestimmten Vermarktungsnormen und muss entsprechend gekennzeichnet werden.

Neben speziellen Normen für Gemüsepaprika, Salate, krause Endivie, Eskariol und Tomaten müssen alle Gemüsearten folgende Mindesteigenschaften der allgemeinen Vermarktungsnorm erfüllen:


Über die Mindestanforderungen hinaus unterscheidet man vier Qualitätsunterteilungen:


Gemüse wird als Frischgemüse (nicht behandeltes, nicht verarbeitetes Gemüse), Tiefkühlgemüse, Dosengemüse, Glaswarengemüse, in Öllaken oder Essig oder vergorenes eingelegtes Gemüse und Trockengemüse vermarktet. Es wird mitunter zwischen Frischgemüse und „erntefrischem Gemüse“ unterschieden, wobei die „Frische“ in Deutschland und in der EU nicht definiert ist.

Seit 1957 gibt es in Deutschland tiefgekühltes Gemüse zu kaufen. Ermöglicht wurde dies durch die Entwicklung der Kühltechnik. Ohne den Zusatz von Konservierungsstoffen kann seitdem frisches Gemüse über einen langen Zeitraum haltbar gemacht werden. Das erste TK-Gemüse auf Deutschlands Einzelhandelsmarkt war der Spinat. Heute ist das Angebot weitaus vielseitiger und reicht von einfachen Erbsen bis hin zu asiatischen Gemüsemischungen. Der Vorteil ist, dass die Nährstoffe bzw. Vitamine über einen langen Zeitraum hinweg durch die Kälte konserviert werden und nur wenig abnehmen, weitaus weniger als zum Beispiel ein über drei Tage im Gemüsefach des Kühlschranks gelagertes Gemüse. 

In einer Studie von Ökotrophologen der Universität Hamburg wurde Frischgemüse und Tiefkühl-Gemüse in unterschiedlichen Verarbeitungs-, Lagerungs- und Zubereitungsstufen auf ihren Nährwert und ihre Sensorik hin untersucht. Die Ernährungswissenschaftler fanden heraus, dass viele wichtige Nährstoffe wie Vitamin C durch die Tiefkühlung auch nach vier Monaten in hohem Maße erhalten waren, während sie bei gewissen Gemüsearten bei Lagerung sowohl bei 4 °C als auch bei 20 °C rasch abnahmen.





</doc>
<doc id="2069" url="https://de.wikipedia.org/wiki?curid=2069" title="GNU-Projekt">
GNU-Projekt

Das GNU-Projekt (Aussprache: []) wurde von Richard Stallman mit dem Ziel gegründet, ein offenes, unixähnliches Betriebssystem zu schaffen, das sicherstellt, dass die Endbenutzer die Freiheiten haben, es verwenden, untersuchen, verbreiten (kopieren) und ändern zu dürfen. Software, deren Lizenz diese Freiheiten garantiert, wird Freie Software (Free Software) genannt, GNU ist in diesem Sinne "frei". 

Bekanntheit erlangte das Projekt vor allem auch durch die von ihm eingeführte GNU General Public License (GPL), unter der viele weitere Softwareprojekte veröffentlicht werden, sowie zahlreiche GNU-Programme, wie die GNU Compiler Collection, den GNU Debugger sowie Werkzeuge der GNU coreutils, den Editor Emacs und andere.

Die Entstehung des GNU-Projekts geht auf Richard Stallman zurück, der von 1971 bis 1984 am Massachusetts Institute of Technology (MIT) arbeitete. In der Anfangszeit seiner Arbeit erfuhr er den Umgang mit Software als einen regen und offenen Austausch zwischen Entwicklern und Nutzern. Damals war es üblich, Programme, auch in Form des Quelltextes, zu tauschen und bei Bedarf anzupassen.
Die Situation änderte sich Ende der 1970er und Anfang der 1980er, als Unternehmen damit begannen, Software unter stark beschränkenden Lizenzen zu veröffentlichen und den Quelltext geheim zu halten. Stallman stand daraufhin am Scheideweg, sich entweder dem Modell der proprietären Software anzupassen oder aber einen anderen Weg zu gehen. Er entschied sich dafür, ein Modell freier Software zu entwickeln, das die Offenheit der Software und die Möglichkeit des Tauschens gewährleisten sollte. Der erste Schritt auf diesem Weg sollte ein freies Betriebssystem in der Art von Unix sein. Da es in der Zeit am MIT üblich war, für Programme, die anderen Programmen ähneln, rekursive Akronyme zu nutzen, wählte Stallman den Namen "GNU" für „GNU’s not Unix“.

Die Entscheidung, GNU Unix-kompatibel zu machen, hatte mehrere Gründe. Zum einen war Stallman sicher, dass die meisten Unternehmen ein grundlegend neues Betriebssystem ablehnen würden, wenn die Programme, die sie benutzten, darauf nicht laufen würden. Andererseits ermöglichte die Unix-Architektur eine schnelle, einfache und verteilte Entwicklung, da Unix aus vielen kleinen Programmen besteht, die größtenteils unabhängig voneinander entwickelt werden können. Auch waren viele Bestandteile eines Unix-Systems frei für jeden erhältlich und konnten so direkt in GNU integriert werden, beispielsweise das Textsatzsystem TeX oder das Fenstersystem X Window. Die fehlenden Teile wurden von Grund auf neu geschrieben.

Das GNU-Projekt wurde am 27. September 1983 in den Newsgroups net.unix-wizards und net.usoft angekündigt. Die Arbeit daran begann am 5. Januar 1984, nachdem Stallman seine Stelle am MIT gekündigt hatte, um sich ganz dem GNU-Projekt widmen zu können und gleichzeitig zu verhindern, dass das MIT aufgrund des Arbeitsverhältnisses Rechte an dem von ihm geschriebenen Code besitzt. Stallman erklärte wenig später im „GNU Manifest“ und in anderen Essays seine Motive. So sah er einen Hauptzweck des Projekts darin, „den Geist der Kooperation, der in den frühen Jahren der Computergemeinschaft vorgeherrscht hatte, wiederzubeleben“. Damit stellte das GNU-Projekt, obwohl größtenteils technischer Natur, auch eine soziale und politische Initiative dar. Es hat seit seiner Gründung nicht nur Software hervorgebracht, sondern auch eigene Lizenzmodelle und eine große Zahl theoretischer Schriften, die meist von Stallman verfasst wurden.

Das GNU-Projekt steht im engen Zusammenhang mit der Entwicklung von Linux bzw. GNU/Linux.

Die vom GNU-Projekt veröffentlichte Software wurde damals unter jeweils eigenen Lizenzen gestellt, welche die entsprechenden Freiheiten gewährten. Für das Prinzip einer Lizenz, welche die Pflicht zur Offenheit explizit einbaut, nutzte Stallman den Begriff Copyleft, den Don Hopkins Mitte der 1980er ihm gegenüber in einem Brief erwähnte. Später entschloss sich Stallman, eine einheitliche Lizenz zu schaffen, unter der alle Software veröffentlicht werden konnte. Er entwarf daher mit Hilfe von Jerry Cohen die GNU General Public License, welche im Kern vier Freiheiten umfasst: das Programm für jeden Zweck zu nutzen, Kopien weiterzuverteilen, die Arbeitsweise des Programms zu studieren und das Programm eigenen Bedürfnissen anzupassen.

Um dem GNU-Projekt einen logistischen, juristischen und finanziellen Rahmen zu geben, gründete Stallman 1985 die gemeinnützige Free Software Foundation (FSF). Die FSF beschäftigt auch Programmierer, um an GNU zu arbeiten, obwohl der wesentliche Teil der Arbeit von Freiwilligen geleistet wird. Als GNU bekannter wurde, begannen Unternehmen daran mitzuarbeiten. Sie entwickelten Programme, die sie unter der GPL veröffentlichten, begannen CDs mit Software zu verkaufen und Dienstleistungen rund um das System anzubieten. Eines der bekanntesten Unternehmen der früheren Zeit des Projekts war Cygnus Solutions. Viele dieser Unternehmen unterstützen die Free Software Foundation mit Geld oder anderen Spenden. Dazu gehören unter anderem IBM, Google Inc. und HP.

Die Richtlinien für freie Systemdistributionen (GNU FSDG) sollen als Orientierungshilfe für Distributionssysteme dienen, was es bedeutet sich als Freie Software zu qualifizieren. So soll die Distribution vollständig sein und alle Informationen als Quellcode und unter freier Lizenz bereitgestellt werden. Weiter soll die Distribution keine unfreie Firmware enthalten und die Dokumentation unter freier Lizenz stehen. Eine freie GNU/Linux-Distribution ist z. B. Trisquel und eine freie GNU-fremde Systemdistribution ist Replicant

Das Logo des GNU-Projekts ist eine Zeichnung eines Gnus, einer afrikanischen Antilope. Es wurde ursprünglich von Etienne Suvasa entworfen und seitdem in verschiedenen abgewandelten Formen wiedergegeben.




</doc>
<doc id="2071" url="https://de.wikipedia.org/wiki?curid=2071" title="GNU General Public License">
GNU General Public License

Die ' (kurz ' oder ; aus dem Englischen wörtlich für "allgemeine Veröffentlichungserlaubnis" oder "-genehmigung") ist die am weitesten verbreitete Softwarelizenz, die einem gewährt, die Software auszuführen, zu studieren, zu ändern und zu verbreiten (kopieren). Software, die diese Freiheitsrechte gewährt, wird Freie Software genannt; und wenn die Software einem Copyleft unterliegt, so müssen diese Rechte bei Weitergabe (mit oder ohne Software-Änderung, -Erweiterung, oder Softwareteile-Wiederverwendung) beibehalten werden. Bei der GPL ist beides der Fall.

Die ursprüngliche Lizenz hat Richard Stallman von der Free Software Foundation (FSF) für das GNU-Projekt geschrieben. Die FSF empfiehlt die aktuelle, 2007 veröffentlichte dritte Version (GNU GPLv3).

Die GPL kann von jedem als Lizenz verwendet werden, um mit dieser die Freiheitsrechte der Endnutzer sicherzustellen. Sie ist die erste Copyleft-Lizenz für den allgemeinen Gebrauch. Copyleft bedeutet, dass Änderungen oder Ableitungen von GPL-lizenzierten Werken nur unter den gleichen Lizenzbedingungen (also eben GPL) vertrieben werden dürfen. Damit gewährt die GPL den Empfängern eines Computerprogramms die Freiheitsrechte Freier Software und nutzt Copyleft, um sicherzustellen, dass diese Freiheiten bei Weiterverbreitung erhalten bleiben, auch wenn die Software verändert oder erweitert wird. Freizügige Lizenzen wie die BSD-Lizenz hingegen fordern nicht das Copyleft.

Unter GPL lizenzierte Software darf für alle Zwecke ausgeführt werden (auch kommerzielle Zwecke, und GPL-lizenzierte Compiler und Editoren dürfen auch als Werkzeuge für die Erstellung von proprietärer Software genutzt werden); sie darf bei rein privater (oder interner) Verwendung – ohne Vertrieb, ohne Weitergabe – modifiziert werden, ohne dass der Quellcode offengelegt werden muss (nur bei Vertrieb oder Weitergabe müssen der Quellcode und etwaige Code-Änderungen den Endnutzern zugänglich gemacht werden – dann kommt nämlich Copyleft zur Anwendung, um sicherzustellen, dass die Endnutzer-Freiheiten erhalten bleiben). Jedoch muss Software, welche als Anwendungsprogramm unter einem GPL-lizenzierten Betriebssystem wie GNU/Linux läuft, nicht zwangsweise unter GPL oder quelloffen vertrieben werden – die Lizenzierung ist nur von den verwendeten Bibliotheken und Software-Teilen abhängig (nicht von der unterliegenden Plattform): wenn z. B. ein Anwendungsprogramm nur eigene Software enthält, oder mit quelloffenen Software-Teilen kombiniert wird, welche keinem strengen Copyleft unterliegen (also somit auch keine GPL-Teile), dann müssen die eigenentwickelten Software-Teile nicht unter GPL oder quelloffen gelegt werden (selbst wenn das eingesetzte Betriebssystem unter GPL lizenziert ist). Nur bei der Realisierung von Software, welche neue (eigene) Quellcode-Teile mit GPL-Teilen verbindet (und wenn diese Software verbreitet oder vertrieben wird), so muss der Quellcode den Nutzern (unter den gleichen Lizenzbedingungen: GPL) zugänglich gemacht werden. Die GNU "Lesser" General Public License (LGPL) wurde entwickelt, um ein schwächeres Copyleft als GPL zu haben: LGPL erfordert nicht, dass eigene entwickelte Code-Teile (welche LGPL-Teile nutzen, aber von ihnen unabhängig sind: z. B. lediglich Library-Aufruf) unter den gleichen Lizenzbedingungen zur Verfügung gestellt werden müssen.

Nutzer und Firmen dürfen für den Vertrieb von GPL-lizenzierten Werken Geld verlangen (kommerzieller Vertrieb), oder sie kostenlos vertreiben. Dies unterscheidet GPL von Software-Lizenzen, welche den kommerziellen Vertrieb verbieten. Die FSF erklärt, dass freiheitsrespektierende Software auch den kommerziellen und gewerblichen Nutzen und Vertrieb (inklusive Weitervertrieb) nicht einschränken darf: die GPL besagt ausdrücklich, dass GPL-Werke (z. B. Freie Software) zu jedem Preis verkauft oder weitervertrieben werden können.

Die GNU GPL wurde im Januar 1989 von Richard Stallman, dem Gründer des GNU-Projekts, geschrieben.

Sie basierte auf einer Vereinheitlichung gleichartiger Lizenzen, die bei früheren Versionen von GNU Emacs, dem GNU Debugger und der GNU Compiler Collection Anwendung fanden. Diese Lizenzen waren auf jedes Programm speziell zugeschnitten, enthielten aber die gleichen Vorschriften wie die aktuelle GNU GPL. Das Ziel von Stallman war, eine Lizenz zu entwickeln, die man bei jedem Projekt verwenden kann. So entstand die erste Version der GNU General Public License, die im Januar 1989 veröffentlicht wurde.

Im Juni 1991 veröffentlichte die Free Software Foundation (FSF) die zweite Version der GNU GPL (GPLv2). Die wichtigste Änderung dabei war die sogenannte „Liberty or Death“-Klausel (übersetzt: „Freiheit oder Tod“) in Paragraph 7. Diese besagt, wenn es nicht möglich ist, einige Bedingungen der GNU GPL einzuhalten – beispielsweise wegen eines Gerichtsurteils – es untersagt ist, diese Lizenz nur bestmöglich zu erfüllen. In diesem Fall ist es also überhaupt nicht mehr möglich, die Software zu verbreiten. Auch kam der Paragraph 8 hinzu: Dieser erlaubt es einem Autor, die Gültigkeit der Lizenz geographisch einzuschränken, um Länder auszuschließen, in denen die Verwertung des Werks durch Patente oder durch urheberrechtlich geschützte Schnittstellen eingeschränkt ist. Des Weiteren ist die zweite Version besser mit nicht-US-amerikanischen Rechtssystemen kompatibel, da sie sich auf die Berner Übereinkunft stützt.

Zeitgleich wurde am 2. Juni 1991 eine neue Lizenz mit dem Namen GNU Library General Public License (GNU LGPL) mit der Versionsnummer 2.0 (GNU LGPL v2.0) veröffentlicht, bei der es sich um eine von der GNU GPL abgeleitete, gelockerte Version der GNU GPL handelt. Sie wurde eingeführt, nachdem seit 1990 deutlich wurde, dass die GNU GPL in manchen Fällen (meist für Programmbibliotheken) zu restriktiv (einschränkend) war. Die GNU LGPLv2 (Juni 1991) wurde ursprünglich für einige bestimmte Bibliotheken entworfen. Die Lizenz verwirklicht das Modell eines schwachen Copylefts, wobei zwar darunter stehende Programmbibliotheken nicht mehr zur Folge haben, dass die sie verwendenden Programme ebenfalls unter gleichen Bedingungen lizenziert werden müssen, jedoch unterliegen Weiterentwicklungen der Bibliotheken selbst nach wie vor der GNU LGPL. Mit der im Februar 1999 erschienenen Version 2.1 wurde die Lizenz in "GNU Lesser General Public License" umbenannt, der neue Name war ein Vorschlag von Georg Greve.

Seit ihrer Einführung ist die GPL die am weitesten verbreitete freie Softwarelizenz. Die meisten Programme im GNU-Projekt sind unter der GPL und der LGPL lizenziert, darunter auch die Compilersammlung GCC, der Texteditor GNU Emacs und der Gnome Desktop. Auch viele weitere Programme von anderen Autoren, die nicht Bestandteil des GNU-Projekts sind, sind unter der GPL lizenziert. Außerdem sind alle LGPL-lizenzierten Produkte auch unter der GPL lizenziert.

Der erste Entwurf der dritten Version der GPL wurde am 16. Januar 2006 der Öffentlichkeit zur Diskussion vorgestellt. Es folgten drei weitere Entwürfe. Am 29. Juni 2007 wurde schließlich die finale Version der GPL 3 publiziert.

Richard Stallman kündigte bei der Veröffentlichung der GPLv3 2007 an, für eine nächste GPL Version ("GPLv4") diesmal nicht so lange zu warten, sondern eine solche innerhalb der nächsten 10 Jahre in Angriff zu nehmen; über konkrete Planung ist jedoch nichts bekannt.

Am 29. Juni 2007, 16 Jahre nach dem Erscheinen der Version 2 im Jahre 1991, erfolgte eine Revision der Lizenz mit der Version 3. Einige der größten und wichtigsten Änderungen sind:


Die FSF als Halter der GPL unter der Leitung von Richard Stallman koordinierte die Überarbeitung, beraten wurde sie dabei von Eben Moglen. Durch die angestrebte Universalität der GPL 3 ergaben sich zwangsläufig konkurrierende Interessenlagen. Am 16. Januar 2006 wurde ein erster vorläufiger Entwurf veröffentlicht und zur Diskussion gestellt, um ein möglichst optimales Ergebnis für die zukünftige Publikation zu erreichen.
Die GPLv3 wurde seit der Veröffentlichung des ersten Entwurfs kontrovers diskutiert. Kontrovers diskutiert wurde u. a. in der Entwurfsphase der Aspekt der Tivoisierung, der in der vorherigen Version v2 nicht bedacht worden war. Der FSF-Vorschlag soll Tivoisierung zukünftig verhindern, Linuxkernelinitiator Linus Torvalds kritisierte jedoch dieses Vorgehen und vertrat den Standpunkt, dass Tivoisierung erlaubt bleiben solle. Torvalds kritisierte insbesondere die ersten zwei Entwürfe äußerst scharf und sieht weiterhin keinen Grund, den Linux-Kernel unter diese Version der Lizenz zu stellen. Starke Kritik gab es auch von Seiten der Firmen Linspire, Novell, MySQL und anderen. Einige Firmen – insbesondere MySQL – änderten daraufhin die Lizenzformulierung ihrer Produkte von „GPLv2 or later“ zu „GPLv2 only“. Neben dem Linux-Kernel entschieden sich einige weitere FOSS-Projekte, nicht auf die GPLv3 zu wechseln: BusyBox, AdvFS, Blender, und der VLC media player.

Ein weiterer Diskussionsaspekt war, ob die GPLv3 Affero-artige Anforderungen erlauben sollte, was die sogenannte "ASP-Lücke in der GPL" (englisch Originalterm: ""ASP loophole in the GPL"") geschlossen hätte. Nachdem jedoch einige Bedenken wegen des zusätzlichen administrativen Aufwandes geäußert worden waren, wurde entschieden, die Affero-Lizenz als eigenständige Lizenz von der GPL getrennt zu behalten.

Auch gab es Kontroversen über die Mischbarkeit von GPLv2-Software mit GPLv3-Software, welche nur unter der optionalen ""or later""-Klausel der GPL möglich ist. Diese Klausel wurde jedoch von einigen Entwicklern als reine Notfalloption (englisch "safeboat clause") betrachtet, nicht jedoch als reguläre Möglichkeit die Lizenz signifikant zu ändern. Auch sind die vorhandenen Projekte, welche ihre Software ohne die optionale ""or later"" Klausel lizenziert haben, am bekanntesten der Linux-Kernel, damit inkompatibel mit GPLv3-Software und können keinen Quelltext mit dieser austauschen. Ein Beispiel ist die Bibliothek "GNU LibreDWG", die nun nicht mehr von LibreCAD und FreeCAD verwendet werden kann.

Nach drei weiteren Entwürfen wurde die endgültige Fassung am 29. Juni 2007 publiziert. Als Nebeneffekt der Überarbeitung sind mehrere zusätzliche Lizenzen GPL-kompatibel geworden.

Die signifikant erweiterte GPLv3 wird als essentiell inkompatibel zur GPLv2 bewertet, Kompatibilität zwischen beiden Lizenzen ist nur über die optionale Klausel "this version or later" gegeben, welche jedoch von einigen Projekten nicht verwendet wird, beispielsweise dem Linux-Kernel. 2011, vier Jahre nach der GPLv3 Veröffentlichung, sind laut den Daten von Black Duck Software nur 6,5 % aller Open-Source-Projekte unter GPLv3, während 42,5 % der GPLv2 unterliegen. 2013, sechs Jahre nach der Veröffentlichung der GPLv3, ist laut Black Duck Daten die GPLv2 weiterhin die mit Abstand häufigst verwendete Lizenz. Andere Autoren machten 2011 im Zusammenhang mit dieser Spaltung eine vermehrte Bewegung in Richtung von freizügigen Lizenzen aus, weg von Copyleft-Lizenzen.

Einige Journalisten und Entwickler schließen aus der geringen Migration der Projekte von der alten GPLv2 auf die neuere GPLv3, dass eine Spaltung der Gemeinschaft entlang der Grenzen der beiden Lizenzversionen entstehe.

Alle abgeleiteten Programme eines unter der GPL stehenden Werkes dürfen von Lizenznehmern nur dann verbreitet werden, wenn sie von diesen ebenfalls zu den Bedingungen der GPL lizenziert werden. Dies betrifft nur Lizenznehmer, nicht die Inhaber der Rechte. (Der Halter des Copyrights – das ist der Autor oder jemand, dem der Autor seine Rechte abgetreten hat – kann das Werk auch unter beliebigen anderen Lizenzen weitergeben.) Dieses Schutzverfahren benannte Richard Stallman „Copyleft“ – als Anspielung auf das Wort Copyright. Ziel ist, die Freiheit eines Programmes auch in der Weiterentwicklung von anderen sicherzustellen.

Dieses Prinzip findet sich auch in anderen Lizenzen – unter anderem in den GNU-Lizenzen (LGPL, AGPL und GFDL) sowie als „Share Alike“ bezeichnet in einigen der Creative-Commons-Lizenzen.

Da die GPL bestimmte Freiheiten gewährleistet und verlangt, dass selbige Freiheiten für die Software-Empfänger aufrechterhalten werden (auch bei anschließender Weitergabe an weiterefolgende Empfänger, oder bei Code-Änderung oder Codeteile-Wiederverwendung: Copyleft); kann man GPL-lizenzierte Software-Teile nicht mit Code-Teilen kombinieren, dessen Lizenzen verlangen, dass Empfänger auf gewisse Freiheiten verzichten müssen, oder verlangen, dass anschließend-weiterefolgenden Empfängern Freiheiten wieder entzogen werden müssen. Solche Lizenzen sind mit der GNU GPL inkompatibel (da der Grund für die GPL und dessen Copyleft, eben ein gesamtheitliches Schützen dieser Freiheiten für alle Empfänger ist).

Das GNU Projekt verwaltet eine Liste von Lizenzen welcher mit der GNU GPL kompatibel sind. Darunter gibt es auch bestimmte freizügige Freie Lizenzen (aber nicht alle), die mit der GNU GPL kompatibel sind. Freizügige Lizenzen erlauben zwar "für sich" genommen, dass Entwickler und Distributoren wahlweise den Empfängern bei Weitergabe bestimmte Freiheiten entziehen könnten (daher "freizügig"); jedenfalls ist solch ein Entziehen aber nicht zwingend erforderlich: bei einer Kombination mit GPL-lizenzierten Software-Code-Teilen ist solch ein Entziehen nicht erlaubt, wenn es die durch die GPL-gewährten Freiheiten einschränken würde: GPL-lizenzierte Software-Code-Teile dürfen nur verändert, erweitert oder mit anderen Software-Teilen zusammengefügt werden, wenn das kombinierte Resultat nach wie vor, allen Empfängern die Freiheiten der GPL gewährt (das Copyleft der GPL muss erhalten bleiben).

Die FSF hält Copyleft bei Programmbibliotheken zwar ebenfalls für prinzipiell gerechtfertigt, erteilt jedoch für Programme, für die sie die Rechte besitzt, manchmal aus strategischen Gründen Ausnahmen, beispielsweise um die Akzeptanz einer Bibliothek zu erhöhen. In diesen Fällen wird die Lesser General Public License (LGPL) von der FSF empfohlen, die explizit diese Nutzung erlaubt, ohne Copyleft-Forderungen an das aufrufende Programm zu stellen.

Die GPL enthält einen Anhang, der beschreibt, wie man die Lizenz auf ein neues Programm anwenden kann. Der Anhang enthält eine Standardvorlage, in die noch der Name des Programms, eine kurze Beschreibung dessen, was es tut, das Jahr der Erstellung und der Name des Autors einzufügen ist. Die Vorlage enthält einen Haftungshinweis, der warnt, dass das Programm ohne jegliche Garantie kommt. Sie lizenziert das Programm unter der jeweiligen GPL-Version, mit dem Zusatz „or (at your option) any later version“, der das Programm auch für die Bedingungen zukünftig herausgegebener Fassungen der GPL öffnet. Damit steht das Programm automatisch auch unter einer neuen GPL-Version, sobald die Free Software Foundation eine solche herausgibt. Dadurch werden der Lizenzwechsel auf eine neue Version der GPL ermöglicht und Kompatibilitätsprobleme zwischen unterschiedlichen Versionen vermieden. Einige Projekte verwenden die Vorlage auch für die GPL-Version 2 ohne den Zusatz, da sie mit der GPLv3 nicht einverstanden sind. Die Vorlage enthält noch einen Hinweis, wo man eine Kopie der GPL finden kann, wenn dem Programm keine Kopie beiliegt.

Eine zentrale Registrierungsstelle für GPL-lizenzierte Programme existiert nicht, die FSF betreibt aber zusammen mit der UNESCO ein Verzeichnis ohne Anspruch auf Vollständigkeit.

Mit einer von 2000 bis 2002 erarbeiteten Modernisierung des deutschen Urheberrechts sollte gesetzlich verankert werden, dass ein Urheber auf eine angemessene Vergütung in keinem Fall verzichten kann. Theoretisch hätte das für Händler, die freie Software verkaufen, eine Rechtsunsicherheit zur Folge gehabt, da Programmierer möglicherweise im Nachhinein einen Anteil des Erlöses hätten verlangen können, was Möglichkeiten des Missbrauchs eröffnet hätte. Mit der Ergänzung des Gesetzentwurfs um die sogenannte Linux-Klausel wurde die GPL (und ähnliche Lizenzen, die „unentgeltlich ein einfaches Nutzungsrecht für jedermann einräumen“, vgl. § 32 Abs. 3 Satz 3 UrhG) jedoch auf eine sichere rechtliche Basis gestellt.

Das Landgericht München I bestätigte in einer schriftlichen Urteilsbegründung vom 19. Mai 2004 (Az. ) eine einstweilige Verfügung, mit der einer Firma untersagt worden war, Netfilter ohne Einhaltung der GPL weiterzuverbreiten. Dies war das erste Mal, dass die GPL eine signifikante Rolle in einem deutschen Gerichtsverfahren spielte. Das Gericht bewertete die Tätigkeiten des Beklagten als Missachtung einiger Bedingungen der GPL und somit als Urheberrechtsverletzung. Dies entsprach genau den Prognosen, die Eben Moglen von der FSF für solche Fälle zuvor gemacht hatte. Grundlage der Entscheidung war die deutsche Übersetzung der GPL, die vom Gericht ansatzweise auf die Gültigkeit als AGB geprüft wurde. Bei manchen Klauseln waren komplizierte rechtliche Konstruktionen bzw. Auslegungen nötig, um die Zulässigkeit nach deutschem Recht zu erreichen. Die gegnerische Partei hatte die Zulässigkeit der Bedingungen der GPL nicht angegriffen, sondern nur bestritten, überhaupt der richtige Beklagte zu sein.

Am 6. September 2006 war die GPL am Landgericht Frankfurt am Main erfolgreich Bestandteil eines Verfahrens gegen D-Link (Az.: ).

Am 4. Oktober 2006 wurde die Gültigkeit der GPL in einem weiteren Urteil bestätigt. Ein Bevollmächtigter der Programmierer von drei GPL-lizenzierten Hilfsprogrammen zum Start eines Betriebssystemkerns, zog nach einer Abmahnung gegen ein Unternehmen vor Gericht, das die Programme in seiner Firmware verwendet hatte, ohne ihren Quellcode offengelegt und die GPL beigelegt zu haben. Die Ansprüche in der Unterlassungsaufforderung wurden teilweise nicht erfüllt, so dass das Gericht entschied, dass das Unternehmen das Urheberrecht des Klägers verletzt habe und somit Herkunft und die Abnehmer der Firmware nennen sowie die Gerichts- und Abmahnungskosten und die Kosten für den Aufwand zur Feststellung der Rechtsverletzung tragen müsse. Die Beklagten hatten dabei versucht, sich mit einer ganzen Bandbreite von üblichen Argumenten zu wehren, einschließlich Ungültigkeit der GPL wegen Wettbewerbswidrigkeit, Beweisverwertungsverbot wegen Urheberrechtsverletzung bei der Feststellung des Verstoßes (d. h. unerlaubte Dekompilierung der Firmware – der Kläger hatte jedoch nur den Bootvorgang beobachtet), Erschöpfungsgrundsatz und fehlendes Recht zur Klage, da im Rahmen der Open-Source-Entwicklung lediglich von einer Miturheberschaft ausgegangen werden könne und für die Klage die Zustimmung der anderen Urheber nötig sei. Das Gericht lehnte diese Argumente jedoch alle ab.

Am 21. März 2006 scheiterte der US-Amerikaner Daniel Wallace mit einer Klage am Bezirksgericht im US-Bundesstaat Indiana gegen die FSF. Er hatte den Standpunkt vertreten, dass die GPL unwirksam sei. Sie erzwinge durch die Verfügbarkeit kostenloser Softwarekopien eine Preisabsprache zwischen den verschiedenen Anbietern, was einen Verstoß gegen den Sherman Antitrust Act darstelle. Der Richter John Daniel Tinder folgte dieser Auffassung nicht und bemerkte, dass eine Kartellrechtsverletzung schwerlich festgestellt werden könne, wenn die Interessen des Klägers von denen der Konsumenten divergieren. Klagen gegen Red Hat, Novell und IBM wurden ebenfalls abgewiesen.

Um die Rechte von GPL-Autoren zu schützen und gegen Verstöße vorgehen zu können, gründete Harald Welte im Jahr 2004 das Projekt gpl-violations.org. Gpl-violations.org ist bereits mehrmals im Auftrag von Programmierern erfolgreich vor Gericht gezogen. In etlichen weiteren Fällen konnte eine außergerichtliche Einigung erzielt werden.

Das Copyright des Lizenztextes selbst liegt bei der Free Software Foundation (FSF). Diese erlaubt im Kopf der Lizenz das Kopieren und Verbreiten der Lizenz, verbietet jedoch die Modifikation des Lizenztextes. Damit wird sichergestellt, dass die Rechte und Pflichten, welche durch die GPL garantiert werden, nicht abgeändert werden können, indem der Lizenztext abgeändert wird. Auch wird dadurch verhindert, dass unterschiedliche inkompatible Versionen der GPL entstehen. Die FSF erlaubt die Schaffung neuer Lizenzen auf Basis der GPL, solange diese einen eigenen neuen Namen haben, die Präambel der GPL nicht enthalten und sich nicht auf das GNU-Projekt beziehen. Dies geschah ursprünglich beispielsweise bei der GNU Affero General Public License, bevor diese von der FSF übernommen wurde.

Die GPL bestreitet die Copyright-Gesetze des betroffenen Staates nicht, sondern akzeptiert diese und nutzt sie, um die beschriebenen Rechte und Pflichten durchzusetzen. Ein unter GPL lizenziertes Werk steht nicht in der Public Domain. Der Autor behält – falls nicht ausdrücklich anders festgelegt – das Urheberrecht am Werk und ist im Fall der Nichteinhaltung der Lizenzbedingungen in der Lage, dagegen gerichtlich vorzugehen.

Auf dem Open-Source-Hoster SourceForge waren im Juli 2006 etwa 70 % der Software unter der GPL lizenziert, im Mai 2016 nur noch etwa 59 % (87.692 Projekte mit GPLv2-Lizenz, 14.880 Projekte mit GPLv3-Lizenz, insgesamt 175.081 Projekte).

Im Jahr 2008 standen von den 3489 Projekten auf der Entwicklerplattform von BerliOS 67 % (2334 Projekte) unter der GPL. Die Entwicklerplattform wurde 2014 stillgelegt.

Das von Black Duck Software verwaltete "Open Source Resource Center" gab 2012 die Verbreitung der GPLv2 unter Open-Source-Projekten mit 32,65 % und die der GPLv3 mit 11,62 % an. Nach einer undatierten Liste der meistgenutzten Open-Source-Lizenzen liegen aktuellere Werte nur noch bei 20 % für die GPLv2 und bei 8 % für die GPLv3.

Die Firma Palamida betreibt eine GPL3-Watchlist, laut derer von den 10.086 registrierten Projekten etwa 2946 unter der GPLv3 registriert sind, jedoch ist die Auswahl der Projekte nicht repräsentativ. Die Zahlen des Open Source License Resource Center lassen eher darauf schließen, dass im Juli 2008 etwa drei bis vier Prozent der GPL-Projekte die dritte Version verwendeten. Nicht berücksichtigt ist dabei, dass der Standardtext der Free Software Foundation für die Freigabe eines Programms unter der GPL vorsieht, dass die Nutzung auch unter jeder späteren Version der GPL erlaubt ist. Damit sind unter der GPL 2 lizenzierte Programme, die den Standardtext verwenden, auch unter der GPLv3 und zukünftigen Versionen nutzbar.

Für 2015 meldet GitHub, dass nur rund 20 % der dort registrierten Projekte eine Lizenzangabe enthalten. Von diesen wiederum nutzen knapp 13 % die GPLv2, fast 9 % die GPLv3 und gut 1 % die AGPLv3.

Kritik an der GPL besteht hauptsächlich aus Kritik am starken Copyleft und Kritik am Prinzip der freien Software. Zum Beispiel bezeichnete Microsofts ehemaliger CEO Steve Ballmer 2001 Linux wegen der Auswirkungen der GPL als "Krebsgeschwür".
2001 beschrieb Craig Mundie, Microsoft Senior Vice President, die GPL öffentlich als "viral". Stephen Davidson von der Weltorganisation für geistiges Eigentum verwendete in einem Leitfaden über das Open-Source-Modell (in dem er allgemein eher zurückhaltende Schlüsse zieht) die Bezeichnung "viral" für die Copyleft-Eigenschaften der GPL. Später kritisierten andere die viralen Eigenschaften der GPL ebenfalls.

Auch von Befürwortern freier Software wird die GPL für die begrenzte Kompatibilität mit anderen Lizenzen (und zwischen den GPL-Varianten) sowie ihren komplexen Lizenztext kritisiert.




</doc>
<doc id="2073" url="https://de.wikipedia.org/wiki?curid=2073" title="Geschichte der römisch-katholischen Kirche">
Geschichte der römisch-katholischen Kirche

Die römisch-katholische Kirche versteht sich gemeinsam mit den orthodoxen Kirchen als die Kirche Jesu Christi in ungebrochener geschichtlicher Kontinuität seit dem 50. Tag nach der Auferstehung (Pfingsttag), an dem gemäß dem Neuen Testament der Heilige Geist über die Apostel kam (Apg 2,1ff.). 

Ihr Bischofsamt führt sie, ebenso wie die orthodoxe, anglikanische und altkatholische Kirche über eine ununterbrochene „Reihe der Handauflegungen“ – Apostolische Sukzession – auf den Apostel Petrus zurück. Dieser wurde nach dem Neuen Testament von Christus selbst zur Leitung der Kirche bestimmt: „Du bist Petrus, und auf diesen Felsen werde ich meine Kirche bauen und die Mächte der Unterwelt werden sie nicht überwältigen.“ 

Die frühesten bekannten Gemeinden waren in Jerusalem (Jerusalemer Urgemeinde) und Antiochia sowie diejenigen, an die die Briefe des Apostels Paulus gerichtet waren (z. B. Rom, Korinth, Thessaloniki). In diesen Gemeinden, die jedenfalls teilweise untereinander in brieflicher Verbindung standen, bildeten sich etwa ab dem Ende des 1. Jahrhunderts und der ersten Hälfte des 2. Jahrhunderts Ämter heraus, aus denen sich schließlich im Verlauf des zweiten Jahrhunderts eine Dreigliederung ergab: Bischof ("Episkopos" = Aufseher), Priester ("Presbyter" = Älterer) und Diakon ("Diakonos" = Diener oder Bote). Diese Herausbildung von Anfängen einer Hierarchie kann vor allem durch Spaltungen und Streit innerhalb der frühen Gemeinden erklärt werden, bei denen es sowohl um persönliche Auseinandersetzungen als auch um unterschiedliche Lehrmeinungen ging. Schon der 1. Korintherbrief des Apostels Paulus wusste von vier unterschiedlichen Parteien in der Gemeinde von Korinth.

Die Auseinandersetzung mit unterschiedlichen Lehrmeinungen führte zur Notwendigkeit, ein Leitungs- und Lehramt zu schaffen. Allmählich (noch im 2. Jahrhundert wurden "Episkopos" und "Presbyter" synonym verwendet) bildete sich eine ausdifferenzierte kirchliche Hierarchie heraus und der Kanon biblischer Schriften wurde festgelegt, dessen Grundbestand gegen Ende des 2. Jahrhunderts feststand. Vor allem in der Auseinandersetzung mit der religiös-philosophischen Gnosis entstanden gleichzeitig erste Ansätze zu einem Glaubensbekenntnis. 

Waren die ersten Anhänger Jesu Christi noch Juden, genannt Judenchristen, so bildete sich mit der Mission vor allem des Apostels Paulus unter den Heiden einerseits und der Zerstörung Jerusalems und des Jerusalemer Tempels (70 n. Chr.) andererseits das Heidenchristentum als dominierende Richtung heraus. Ab dem Ende des Bar-Kochba-Aufstands 132/133 n. Chr. verschwand das Judenchristentum nach und nach bzw. ging in heterodoxen jüdischen Gemeinden auf.
Das in den ersten drei Jahrhunderten n. Chr. den Mittelmeerraum dominierende Römische Reich war grundsätzlich religiös tolerant. Die bereits ab dem ersten Kaiser Augustus auftauchenden Tendenzen zu einer Vergöttlichung des Kaisers mussten jedoch früher oder später zu einem Konflikt zwischen der staatlichen verordneten Göttlichkeit des Herrschers einerseits und dem strengen, aus dem Judentum übernommenen Monotheismus des Christentums führen. Die erste staatliche Christenverfolgung fand in Rom unter Kaiser Nero nach dem Stadtbrand des Jahres 64 statt. Bei dieser Verfolgung stand noch nicht der religiöse Aspekt im Vordergrund. Den Christen wurde vielmehr Brandstiftung vorgeworfen. Im Verlauf der neronianischen Verfolgung wurden zahlreiche Christen, vielleicht auch die Apostel Petrus und Paulus, hingerichtet. Zur unerlaubten Religion ("religio illicita") wurde das Christentum erst unter Domitian (81–96).

Dies führte jedoch keineswegs zu flächendeckenden Christenverfolgungen im Römischen Reich. Das Christentum war zunächst eine Unterschichtreligion von Sklaven und kleinen Leuten. Gelegentliche Nachrichten von Christen aus der Oberschicht waren in den ersten 150 Jahren die Ausnahme, und die religiösen Anschauungen der Unterschicht rückten erst in das Blickfeld der Behörden, wenn sie die öffentliche Ordnung (oder die in der Person des Kaisers verkörperte Reichseinheit) zu bedrohen schienen. Dennoch kam es immer wieder zu zunehmend systematischen staatlichen Verfolgungen (z. B. unter Kaiser Decius um die Mitte des 3. Jahrhunderts und unter Kaiser Diokletian zu Beginn des 4. Jahrhunderts), die aber immer wieder durch längere Perioden relativen Friedens unterbrochen wurden.

Die Verfolgungen hatten gravierende Auswirkungen auf die Gemeinden: Zwar gab es einerseits Märtyrer, die freudig in der Erwartung des Paradieses in den Tod gingen, andererseits schworen Gläubige – auch Diakone, Priester und Bischöfe – ihrem Christentum ab, lieferten heilige Bücher oder Gerätschaften aus oder besorgten sich auch nur durch Bestechung eine Bescheinigung, dass sie ihrer Opferpflicht vor dem Altar des Kaisers genügt hätten. Nach dem Abklingen der Verfolgung stellte sich jeweils die Frage, wie mit diesen „Gefallenen“ ("lapsi") zu verfahren sei. Mehrheitlich setzte sich schließlich die pragmatische Linie durch, dass die "lapsi" nach gehöriger und langjähriger Buße wieder in die Kirchengemeinschaft aufzunehmen seien. Allerdings führte dies zu jahrzehntelanger Spaltung in der Kirche. Die nach einem ihrer Exponenten, dem Schriftsteller und zweiten Gegenpapst (der erste war zu Anfang des 3. Jahrhunderts Hippolyt gewesen) Novatian, „Novatianer“ genannte härtere Gruppe verweigerte den Gefallenen die volle Wiederaufnahme in die Kirche und ließ sie nur zu lebenslanger Buße zu. Aus dieser Richtung entwickelte sich im Osten des Reiches die Gruppe der "Katharoi" („die Reinen“), von deren Selbstbezeichnung der Begriff des Ketzers abgeleitet ist. Selbst im Westen verschwand die rigoristische Gruppe erst etwa im 5. Jahrhundert, im Osten hielt sie sich weit länger.
Nach dem Abklingen der Verfolgungen vor allem unter den Kaisern Decius (249–251) und Valerian (253–260) kehrte eine Periode der Duldung des Christentums ein, die erst durch die diokletianische Verfolgung (ab 303) endete. In dieser Zeit bildeten sich Strukturen heraus, die für die weitere Kirchengeschichte grundlegend wurden. So wissen wir von Konzilien, an denen in Afrika bis zu 70 Bischöfe teilnahmen. Liturgie und Taufritus begannen sich zu vereinheitlichen. Auch die ersten Auseinandersetzungen um die Bedeutung des Ehrenvorrangs des Bischofs von Rom fanden sich im späten 2. und im 3. Jahrhundert (Auseinandersetzungen um den Ostertermin zur Zeit Viktors I. (189–199); Unstimmigkeiten zwischen den Päpsten Kalixt I. (217–222) bzw. Stephan I. (254–257) und den afrikanischen Bischöfen, im sogenannten Ketzertaufstreit vertreten vor allem durch Cyprian von Karthago). Ab dem Ende des 2. Jahrhunderts drang das Christentum auch zunehmend in die römische Oberschicht ein: Wir wissen von Konsuln und Beamten des Kaiserhofs, die der Kirche angehörten.

David Sloan Wilson sieht die über Jahrhunderte stabilen hohen Wachstumsraten der ersten Gemeinden begründet in – jeweils im Vergleich zum Rest des Römischen Reiches – der besseren Stellung der Frau im frühen Christentum, der besseren Kooperation (z. B. bei der Pflege Kranker) innerhalb der Gemeinden, einer weniger reproduktionsfeindlichen Lebenseinstellung sowie der geschickt umgesetzten Strategie, sich als Gruppe von Außenseitern abzugrenzen, taufwillige Heiden jedoch (beispielsweise im Gegensatz zum Judentum) relativ einfach aufzunehmen.

Einen Wendepunkt stellte das Jahr 313 dar, als der weströmische Kaiser Konstantin der Große nach seinem Sieg an der Milvischen Brücke mit der Mailänder Vereinbarung, das Christentum zu einer erlaubten Religion erklärte. Vorausgegangen sein soll der Legende nach das "Wunder an der Milvischen Brücke", wobei dem Kaiser ein am Himmel erschienen Kreuzeszeichen den Sieg über seinen Rivalen Maxentius angekündigt haben soll. Die Toleranzpolitik Konstantins und seine zunehmende Annäherung an das Christentum bis hin zu seiner Taufe kurz vor seinem Tod, leitete den Aufstieg des Christentums zur Staatsreligion im Römischen Reich ein. Offiziell wurde das Christentum im Jahr 380 mit dem sogenannten Dreikaiseredikt zur Staatsreligion erklärt.

Als Beginn des Mittelalters wird in der Kirchengeschichte oft das Jahr 529 angesehen (vgl. Josef Pieper, Scholastik). In diesem Jahr schloss Kaiser Justinian I. die Platonische Akademie, und selbiges Jahr gilt als Gründungsjahr des ersten westlichen Klosters Montecassino durch Benedikt von Nursia. Doch auch andere Daten können als Ausdruck der Wendung zum Mittelalter angesehen werden, vom Toleranzedikt Kaiser Konstantins des Großen 313 bis zum Tod des Kaisers Justinian I., dessen Reich kurz darauf zerfiel.
Drei Wendepunkte sind an dieser Stelle genannt, die letzten Endes entschieden, wie sich die kommende Zeit entwickeln würde. Das Toleranzedikt ebnete den Weg des Christentums weg von einer Entscheidungsreligion zu einer die gesamte Bevölkerung umfassenden Volksreligion. Die Schließung der Akademie bei gleichzeitiger Gründung von Montecassino markierte die Verlagerung der Intellektualität und Bildung auf die Klöster, und der Zerfall des römischen Reiches nach Justinian führte zu einer fast völligen Auflösung bisheriger Gesellschaftsstrukturen und staatlicher Ordnung.

Und so ist auch die Zeit vom 6. bis zum 10. Jahrhundert die am schlechtesten dokumentierte Zeit der Kirchengeschichte. Die Alphabetisierung nahm in dieser Zeit rapide ab, damit einher ging das theologische Wissen zurück. 

In der Folge wurde das Reich der germanischen Franken politische Stütze der Katholischen Kirche nach deren Abwendung vom Arianismus unter Chlodwig. Pippin II. und Fabianus der Große begründeten und sicherten den Kirchenstaat, wodurch der Papst zugleich weltlicher Herrscher wurde. 

Die zunehmende theologische, politische und kulturelle Entfremdung zwischen der römischen und den östlichen Kirchen führte zu Schismen im 9. und 11. Jahrhundert, woraus dann infolge der Plünderung von Konstantinopel definitiv das morgenländische Schisma wurde.

Das Mittelalter war gekennzeichnet vom Streben nach einer religiös-politischen Einheitskultur. Die nach dem Zusammenbruch des Römerreichs neu entstandenen germanischen Staatenbildungen verstanden sich als christliche Reiche. Kreuzzüge gegen den vorgedrungenen Islam und Inquisition gegen abweichende Glaubensrichtungen, von Königen teilweise leidenschaftlicher betrieben als von Bischöfen, galten der Sicherung dieser gesuchten Einheit. Auch die katholischen Herrscher Spaniens waren religiös motiviert, als sie in der Reconquista die Eroberung der iberischen Halbinsel durch die Mauren rückgängig machten.

Entscheidend für die Entwicklung des Westens war die Bipolarität von Papst und Kaiser, die das Entstehen von Staatskirchen verhinderte. Beim Investiturstreit des 12. Jahrhunderts zwischen Kaiser und Papst ging es vordergründig um die Vollmacht zur Ernennung von Bischöfen (Investitur), letztlich um den Vorrang und die Grenzen von geistlicher und weltlicher Macht. 

Die Scholastik holte den verlorenen Geisteshorizont der Antike – teils vermittelt durch islamische Tradenten – unter christlicher Perspektive wieder ein. Die anfangs nur formale und oberflächliche Christianisierung der Bevölkerung wurde vertieft und fand ihren Ausdruck in Architektur, Kunst, Dichtung und Musik, in religiösen Bewegungen und Ordensgründungen, in zahlreichen karitativen Einrichtungen und Initiativen sowie im Fest- und Alltagsleben der Menschen.

Durch die Reformation verlor die Katholische Kirche weite Gebiete Nord- und Mitteleuropas. Parallel dazu vollzog sich die politisch motivierte Abspaltung der Anglikanischen Kirche, die sich in der Folge in moderater Weise der Reformation anschloss.

Die frühe Neuzeit ist geprägt durch den Konformismus. Der teilweise religiös motivierte Dreißigjährige Krieg verheerte Deutschland und schwächte seinen politischen Zusammenhalt im Kaisertum. Der Absolutismus in den katholischen Ländern Europas führte zum Staatskirchentum, das eine weitere Schwächung des Papsttums zur Folge hatte. 

Nach der Entdeckung Amerikas folgten den spanischen und portugiesischen Eroberern katholische Missionare. In Lateinamerika – wie auch in Teilen Afrikas – entstanden starke katholische Ortskirchen, die jedoch bis heute ihre Verflechtung in koloniale Strukturen nicht restlos ablegen konnten. Rom konnte damit seinen Machtverlust in Europa durch geographische Expansion weitgehend kompensieren. Die Ostasien-Mission blieb allerdings weitgehend erfolglos. 

Die Aufklärung und die Französische Revolution veränderten die geistige Situation und die kirchliche Ordnung Europas grundlegend. Die Zeit der geistlichen Fürstentümer in Deutschland endete.

Im 19. Jahrhundert stand die Katholische Kirche auf der Seite der politischen und gesellschaftlichen Restauration sowie des Antimodernismus und Antiliberalismus. Sie kämpfte – vergeblich – um von alters her angestammte Domänen wie Einflussnahme im Bildungswesen. Diese Positionierung gipfelte einerseits im Ersten Vatikanischen Konzil mit der Dogmatisierung der Unfehlbarkeit des Papstes in Glaubensfragen, deren Ablehnung u. a. zur Abspaltung der Altkatholischen Kirche führte. Andererseits führte gerade der Antimodernismus die Katholische Kirche zur Kritik an der menschenverachtenden Ausbeutung der Arbeiterschaft in der beginnenden Industrialisierung und zur Formulierung der katholischen Soziallehre durch Papst Leo XIII.

Das 20. Jahrhundert ist gekennzeichnet durch die Auseinandersetzung der Kirche mit den totalitären Herrschaftssystemen des Nationalsozialismus und des Stalinismus sowie mit der „Moderne“ in ihren weltanschaulichen, moralischen, sozialen und politischen Dimensionen. Diese Auseinandersetzung wurde teils mit Kompromissen, teils in strikter Abgrenzung bis zum Martyrium geführt. In der Sowjetunion wurde die katholische Kirche verfolgt. Zur Dokumentation der Religionsfreiheitsverletzungen gab man die Chronik der Litauischen Katholischen Kirche heraus.

Im Ersten Weltkrieg versuchte Benedikt XV. neutral zu bleiben. Das Friedensangebot der Mittelmächte vom 12. Dezember 1916 unterstützte er nicht. Dafür sandte er am 1. August 1917 eine eigene Friedensnote an die Staatsoberhäupter der kriegführenden Länder. Die darin enthaltenen Vorschläge waren für Deutschland nicht ungünstig, und scheiterten hauptsächlich an der Ablehnung durch die Entente. Aber auch innerhalb Deutschlands stand man ihnen teilweise misstrauisch gegenüber. Zu den Friedensverhandlungen wurde der Papst nicht hinzugezogen. Er setzte sich später gegen eine Fortsetzung der Hungerblockade gegen die Mittelmächte und für die Heimkehr der Kriegsgefangenen ein. Der deutsche Katholizismus war enttäuscht, dass von Seiten des Vatikans kein Protest gegen den Versailler Vertrag erfolgte. In der päpstlichen Presse erschienen allerdings juristische Gutachten, die sich gegen eine Auslieferung des deutschen Kaisers und der deutschen Heeresführung (Ludendorff, Paul von Hindenburg) aussprachen. Zur Klärung der Kriegsschuldfrage forderte Benedikt die Öffnung aller Archive der beteiligten Staaten. Es ist nicht unbegründet, von einem Versagen des Papsttums im Ersten Weltkrieg zu sprechen. Dabei müssen aber auch die immensen Schwierigkeiten gesehen werden, die einem Eingreifen der Kurie in die Politik der kriegführenden Mächte entgegenstanden.
Im Vorfeld des Zweiten Weltkrieges schloss Pius XI. 1933 das Reichskonkordat mit den Nationalsozialisten in Deutschland.

Das Zweite Vatikanische Konzil markiert eine Periode der Öffnung und Modernisierung. Das lange Pontifikat Johannes Pauls II. (1978–2005) ist durch das von ihm mitbewirkte Zusammenbrechen des Kommunismus und ein starkes politisches Engagement für Entwicklung und Frieden (z. B. im Irak-Krieg 2003), aber auch durch innerkirchliche Restaurationstendenzen geprägt. 1990 weiht er im Rahmen einer apostolischen Afrika-Reise in Yamoussoukro der Heiligen Gottesmutter Maria das größte Kirchengebäude der Christenheit.

In den 1990er und 2000er Jahren wurden in einer Vielzahl von Ländern Fälle von sexuellem Kindesmissbrauch in der römisch-katholischen Kirche publik und riefen ein großes Medienecho hervor. Neben den Taten an sich wurde vor allem die Vertuschung der Fälle innerhalb der kirchlichen Hierarchie kritisiert. Im weiteren Verlauf kam es zur Verschärfung der innerkirchlichen Leitlinien zum Umgang mit Missbrauchsfällen.




</doc>
<doc id="2075" url="https://de.wikipedia.org/wiki?curid=2075" title="Gewürzpflanze">
Gewürzpflanze

Als Gewürzpflanze bezeichnet man eine Pflanzenart, von der bestimmte Teile (Blüten, Früchte, Samen, Rinde, Wurzeln, Rhizome und andere Teile) als Gewürze verwendet werden.

Gewürzpflanzen zählen zu den Nutzpflanzen. Viele sind zugleich Heilpflanzen:



</doc>
<doc id="2076" url="https://de.wikipedia.org/wiki?curid=2076" title="Godzilla">
Godzilla

Godzilla (jap. , "Gojira") (ausgesprochen englisch [], japanisch []) ist ein japanisches Filmmonster. Das 50–118,5 Meter hohe Monster ist bisher in 30 japanischen und zwei amerikanischen Filmen aufgetreten und hat andere Monsterfilmreihen wie Mothra und Gamera inspiriert, die sich bei Fans des Genres ebenfalls großer Beliebtheit erfreuen, welche ihn auch als König der Monster bezeichnen.

Die Grundidee zum Film stammt vom Produzenten Tomoyuki Tanaka. Als Inspiration gilt hierbei der Vorfall des japanischen Fischerbootes "Glücklicher Drache V" (jap. 第五福竜丸, Dai-go Fukuryū-maru). Dieses Boot geriet am 1. März 1954 in den Einflussbereich von Castle Bravo, einem amerikanischen Nuklearwaffentest, bei dem die US Army am Tag zuvor ihre stärkste nukleare Waffe auf dem Bikini-Atoll zündete. Durch die unerwartete Stärke der Bombe und die ungünstigen Witterungsbedingungen wurden Boot und Mannschaft schwer verstrahlt. Der Funker Aikichi Kuboyama verstarb am 23. September 1954 daran. Die anderen Besatzungsmitglieder überlebten zunächst. Sechs von ihnen erkrankten später an Leberkrebs. Während der Vorfall in den Vereinigten Staaten kaum wahrgenommen wurde, sorgte er für enorme Empörung in der japanischen Bevölkerung und zerstörte beinahe die Versöhnungsanstrengungen beider Staaten, die sich im Zweiten Weltkrieg gegenüber gestanden hatten.

Der erste Godzilla-Film von 1954 "(Gojira)" ist in der japanischen Originalversion ein nicht nur tricktechnisch beeindruckendes, sondern auch hinsichtlich der Handlung und Dramatik durchdachtes Werk, das sich als eine Allegorie auf das japanische Trauma der Atombombenabwürfe über Hiroshima und Nagasaki oder aber als direkte Reaktion auf das Atomunglück von Dai-go Fukuryū-maru deuten lässt. Es existiert neben der japanischen Originalversion von Regisseur Ishirō Honda eine umgeschnittene internationale Fassung, für die Terry O. Morse einige zusätzliche Szenen mit Raymond Burr als Reporter drehte. Honda ließ sich bei diesem ersten Film von dem erfolgreichen amerikanischen Monsterfilm "Panik in New York" ("The Beast From 20000 Fathoms," 1953), mit Trickaufnahmen von Ray Harryhausen, inspirieren.

Der erste Godzilla-Film kann als Verarbeitung des von Japan verlorenen Zweiten Weltkrieges, der Atombombenabwürfe auf Hiroshima und Nagasaki und der zahlreichen Atomtests der Amerikaner im Pazifik während des Kalten Krieges interpretiert werden. Ist in diesem Film Godzilla als Symbol der Bombe ein böses Monster, änderte sich das im Laufe der Serie. Vor allem versuchte man, Elemente aus ausländischen Produktionen oder dem Weltgeschehen einzubinden. In Filmen wie "Befehl aus dem Dunkel" (1965) wird Godzilla zum Beschützer Japans (bzw. der ganzen Erde, wie in "Final Wars") vor außerirdischen Invasoren. Er wird – so Georg Seeßlen – „vom großen Zerstörer zum großen Freund“. Mit dem Erfolg von TV-Serien wie Raumschiff Enterprise und dem breiteren Interesse für den Wettlauf ins All sowie der Mondlandung der Apollo 11 wurden Science-Fiction-Elemente bis 1975 verstärkt eingesetzt. Der Erfolg der Zurück in die Zukunft-Trilogie inspirierte die Macher des 1991 erschienenen Godzilla – Duell der Megasaurier zur Einbindung des Themas „Zeitreisen“. In den Serien der 1980er/90er und 2000er Jahre wurde Godzilla wieder zu einem bösen Monster, konnte sich aber nie von der Rolle des Anti-Helden distanzieren. Anfang der 1970er Jahre wurde mit Godzilla auch auf die anhaltende Umweltverschmutzung aufmerksam gemacht. Hierbei kämpfte er beispielsweise gegen ein Monster, welches aus der Umweltverschmutzung seine Energie bezieht. Dieses Thema wurde in späteren Filmen der Reihe erneut aufgefasst und zum zentralen Punkt einzelner Geschichten. Ähnliche Anspielungen gibt es auch auf die Gentechnologie.

In Deutschland kamen die Godzilla-Filme in den 1970er Jahren mit teilweise sinnentstellender Synchronisation ins Kino, die die marktschreierischen Verleihtitel in die Handlung zu integrieren suchten. Dabei wurden oftmals Frankenstein und King Kong in die Verleihtitel integriert, obwohl die entsprechenden Monster in der Regel nicht in den Filmen mitspielten. Während King Kong schlicht das zu dieser Zeit wohl bekannteste Synonym für amoklaufende Riesenmonster war – jedenfalls bekannter als Godzilla -, bezieht sich Frankenstein nur indirekt auf Mary Shelleys Romanfigur. "Frankenstein – Der Schrecken mit dem Affengesicht", in dem ein 50 Meter hohes, atomar verstrahltes Frankenstein-Monster gegen ein weiteres Urzeitungeheuer kämpfen durfte, war im Sommer 1967 so erfolgreich an den deutschen Kinokassen, dass nahezu alle folgenden Filme, die die japanischen Riesenmonster zum Thema hatten, entsprechend eingedeutscht wurden, um an diesen Erfolg anzuknüpfen; sogar unter Verwendung des gleichen „Frankenstein“-Schriftzugs. Doch auch mit Godzilla selbst wurden Filme mit irreführenden Titeln belegt. So ist der koreanische Film "Yongary" in Deutschland unter dem Titel "Godzillas Todespranke" erhältlich. Auch der zweite Film der Gamera-Reihe, der in Deutschland "Dragon Wars" heißt, wurde mit Godzilla auf dem Cover beworben, obwohl dieser gar nicht erst auftaucht. Nur das gegnerische Monster wird Godzilla genannt, während Gamera den leicht abgewandelten Namen seines Gegners (Barugon) erhielt.

Tricktechnisch wurde in den Godzilla-Filmen mit Suitmation gearbeitet, was bedeutet, dass ein Schauspieler die Rolle des Monsters in einem oft zentnerschweren Gummikostüm spielt. Die für die Filme charakteristischen Zerstörungsszenen von Städten wurden in detailliert ausgestatteten Modellen gedreht. Da mit der Suitmation eine eigene Ästhetik erreicht wird, die allerdings von westlichen, an amerikanische Tricktechnik gewohnte Zuschauer oft als „billig“ verstanden wird, findet diese auch in den neueren japanischen Godzilla-Produktionen der 1990er Jahre immer noch Anwendung, zusätzlich ergänzt durch zahlreiche Computereffekte. Ursprünglich wollte man wie in einigen amerikanischen Produktionen die Stop-Motion-Technik von Ray Harryhausen nutzen, doch der Aufwand und die Kosten waren für Toho der Grund für die Suitmation-Entscheidung. Man experimentierte jedoch weiterhin mit Computereffekten. Ab 1984 wurde Godzillas charakteristischer Hitzestrahl, der vorher nur ins Filmmaterial eingemalt worden war, im Computer erstellt. 1999 und 2000, in den Filmen und Godzilla vs. Megaguirus wurde das Monster in Unterwasserszenen ganz im Computer animiert, was die Fans jedoch nicht akzeptierten.

Der Godzilla aus der ersten amerikanische Verfilmung wurde unter anderem 2004 im japanischen Godzilla-Film, "", parodiert. In einem Kampf zwischen dem echten und dem amerikanischen Godzilla, der in diesem Film "Zilla" genannt wird, schleudert der echte Godzilla Zilla mit dem Schwanz in das Opernhaus von Sydney und vernichtet ihn anschließend mit seinem radioaktiven Strahl. Das Ganze wird, wie auch schon der Anfang des Trailers, von "We’re all to blame" (dt. „Wir haben alle [daran] Schuld“) von der Band Sum 41 untermalt.

Aufgrund des finanziellen Erfolges des zweiten amerikanischen Godzilla-Films entschied sich Toho, nach zwölf Jahren einen neuen Godzilla-Streifen zu drehen. Dieser kam unter dem Titel "Shin Godzilla" (‚neuer Godzilla‘, internationaler Titel: "Godzilla: Resurgence") am 29. Juli 2016 in die japanischen Kinos. Für den deutschsprachigen Markt sicherte sich bereits Splendid Entertainment die Vertriebsrechte. Dieser entstand unter der Regie von Hideaki Anno und Shinji Higuchi, die beide durch die Anime-Serie "Neon Genesis Evangelion" bekannt wurden, wobei das Drehbuch ebenfalls von Anno stammt, die Spezialeffekte von Higuchi. Nach dem Erfolg von Shin Godzilla wurde erstmals eine Adaption als Anime-Filme in Auftrag gegeben, die als Trilogie beginnend mit "" ab November 2017 in den japanischen Kinos angelaufen ist.

Die insgesamt 30 japanischen Godzilla-Filme unterteilen sich in fünf lose zusammenhängende Serien mit jeweils weitgehend voneinander unabhängiger Chronologie: die "Showa-Reihe" von 1954 bis 1975 (15 Filme), die "Heisei-Reihe" von 1984 bis 1995 (7 Filme) und die "Millennium-Reihe" von 1999 bis 2004 (6 Filme). Eine vierte Reihe, die mit dem 2016 erschienenen "Shin Godzilla" begann, ist derzeit namenlos. Mit dem Anime-Film erscheint seit 2017 eine Anime-Film-Reihe, die unabhängig der vierten Film-Reihe ist.

Bereits 1978 erschien in den Vereinigten Staaten unter dem Titel Godzilla – Der Retter der Erde eine Zeichentrickserie von Godzilla, welche sich in seiner Präsentation stark an ein sehr junges Publikum orientierte. Godzilla sowie sein Sohn wurden als Beschützer der Menschen inszeniert. Die 26 Episoden starke Serie lief von 1978 bis 1979 und wurde anschließend nicht weitergeführt.

1998 kam ein amerikanischer Godzilla-Film des deutschen Regisseurs Roland Emmerich mit visuellen Effekten von Volker Engel ins Kino, der eine völlig neue und andere Version der Riesenechse präsentierte. Die Handlung wurde von Tokio nach New York City verlegt. Der Film war zwar ein kommerzieller Erfolg, wird aber von Fans des japanischen Godzillas nicht als Teil der Reihe akzeptiert. So ist unter Fans für das Emmerich-Monster die Kurzform "GINO" gebräuchlich: “Godzilla In Name Only” "(Godzilla nur dem Namen nach)". Nach Veröffentlichung dieses Films ließ die verantwortliche Produktionsgesellschaft Toho verlautbaren, dass es für mindestens zehn Jahre keinen weiteren Godzilla-Film geben werde. Trotzdem erschien noch 1998 eine weitere US-amerikanische Zeichentrickserie unter dem Titel Godzilla – Die Serie, welche thematisch den Kinofilm von Emmerich fortsetzte. Diese Serie wurde nach zwei Jahren und 40 Episoden ebenfalls nicht mehr fortgeführt.

Im Mai 2014 wurde der zweite amerikanische Godzilla-Film in 2D und 3D veröffentlicht. Produziert und vertrieben wurde der Film neben der Toho Company von Warner Bros., Legendary Pictures und Disruption Entertainment. Regie übernahm hier Gareth Edwards. Dieser Film wurde im Gegensatz zum Werk von Roland Emmerich deutlich wohlwollender aufgenommen. 

Für Juni 2018 kündigten Warner Bros. und Legendary Pictures eine Fortsetzung an, in der ebenfalls Gareth Edwards die Regie übernehmen sollte. Dieser stieg aber nach der Fertigstellung seines Star Wars-Ablegers wieder aus. Ein Ersatz ist derzeit nicht bekannt, Legendary verschoben den Start daher um 12 Monate. Des Weiteren wurde für 2020 ein Film angekündigt, in dem Godzilla auf den Riesenaffen King Kong treffen soll, ein Duell, das schon 1962 verfilmt wurde. Diesbezüglich wurde ein Aufeinandertreffen bereits in einer Post-Credit-Szene des Films angedeutet.

Der japanische Name (jap. , "Gojira") ist ein Kunstwort, bestehend aus den japanischen Wörtern für Gorilla (jap. , "Gorira") und Wal (jap. , "Kujira"). Der Name wurde gewählt, weil Godzilla in einer Planungsphase als eine Kreuzung zwischen einem Wal und einem Gorilla beschrieben wurde. Dies ist auch eine Anspielung auf seine Größe, Leistung und seinen Lebensraum, das Meer. Diese These der Herkunft des Namens wurde nie offiziell bestätigt, ist aber am wahrscheinlichsten. Es besteht auch die Theorie, dass der Name von einem damaligen übergewichtigen Mitarbeiter von Toho stammt, der 1954 in der Marketing-Abteilung arbeitete. Aufgrund seiner Statur besaß er den Spitznamen "Gojira".

Godzilla gilt auch als Namenspatron des Mozilla-Projekts und diverser Nebenprodukte wie Bugzilla, Chatzilla oder auch Jira. Diese Nebenprodukte wurden von Toho, die alle Rechte am Namen und Charakter Godzilla hält, äußerst argwöhnisch betrachtet.

Das charakteristische Brüllen Godzillas entstand nach unbefriedigenden Tonexperimenten mit verschiedenen Tierstimmen. Akira Ifukube, der Komponist der Filmmusik des ersten Godzilla-Films aus dem Jahr 1954, schlug schließlich vor, für die Stimme ein Musikinstrument zu verwenden. Das Brüllen wurde mit einem Kontrabass erzeugt, über dessen Saiten ein mit Kiefernharz bestrichener Lederhandschuh der Länge nach gestrichen wurde.

Hier eine Auflistung einiger weiterer Monster, die in den Godzilla-Filmen der Toho-Studios auftraten:






Die US-amerikanische Rockband Blue Öyster Cult verarbeitete den Godzilla-Stoff in dem gleichnamigen Song, erschienen 1977 auf dem Album "Spectres". Die spätere Live-Version auf "Extraterrestrial Live" (1982) wurde um ein Intro erweitert, worin die Godzilla-Story hörspielartig nacherzählt wird. Der Song zählt zu den Klassikern der Band.

Der Song "Simon Says" von Pharoahe Monch ist ein Hip-Hop Remix eines Godzilla Soundtracks.

Die 1984 gegründete brasilianische Metal Band Sepultura, veröffentlichte im September 1993 auf Ihrem Album "Chaos A.D." einen Song namens "Biotech is Godzilla"

Die Britische Band Lostprophets veröffentlichte den Song "We Are Godzilla, You Are Japan" in ihrem zweiten Album "Start Something".

Die 1996 gegründete französische Band Gojira hieß ursprünglich "Godzilla", benannte sich später aber nach dem japanischen Originalnamen um.

Die US-amerikanische Punk Band, Groovie Ghoulies veröffentlichte 2002 einen Song namens "Hats Off To You (Godzilla)" als Reverenz an Godzilla.

Der US-amerikanische Künstler Doctor Steel veröffentlichte ebenfalls im Jahr 2002 den Song "Atomic Superstar" über Godzilla in seinem Album "People of Earth".

2003 erschien im Album "Hai" der Band The Creatures ein japanischer Song den sie Godzilla widmeten, der Name des Songs war "Godzilla!"

Es existieren mindestens 4 Original Film-Soundtracks zu den Godzilla-Filmen:
"The Best Of Godzilla Vol.1" (1954–1975), GNP Crescendo Records, GNPD 8055 (1998)
"The Best Of Godzilla Vol.2" (1984–1995), GNP Crescendo Records, GNPD 8056 (1998)
"The Best of Godzilla – Then" (1954–1975), Silva Screen Records, FILMCD 201 (1998)
"The Best of Godzilla – Now" (1984–1995), Silva Screen Records, FILMCD 202 (1998)




</doc>
<doc id="2077" url="https://de.wikipedia.org/wiki?curid=2077" title="Gregory Chaitin">
Gregory Chaitin

Gregory J. Chaitin (* 1947 in Chicago) ist ein US-amerikanischer Mathematiker und Philosoph. Sein Hauptarbeitsgebiet ist die Berechenbarkeitstheorie. Er steht damit in der Tradition von Kurt Gödel und Alan Turing, deren Theoreme (Unvollständigkeitssatz, Turing-Berechenbarkeit) er zur Algorithmischen Informationstheorie verallgemeinerte, die der Kolmogorow-Komplexität ähnlich ist.

Chaitin wurde als Kind argentinischer Einwanderer aus Buenos Aires geboren. Die Familie zog aber schon früh nach New York, wo er bereits in jungen Jahren durch das Buch "Gödel's Proof" von Ernest Nagel und James R. Newman über Gödels Unvollständigkeitssatz zur Berechenbarkeitstheorie hingezogen wurde. (Chaitin geht diese jedoch von Seiten der Informationstheorie Shannons an.) Er besuchte ab 1962 die Bronx High School of Science und ab 1965 die City University of New York (CUNY). 1966 ging er mit der Familie zurück nach Buenos Aires, wo er bei IBM als Programmierer anfing und Kurse in LISP-Programmierung und Metamathematik an der University of Buenos Aires hielt. Anfang der 1970er entstand seine Arbeit "Information theoretic limits of formal systems" (erweitert publiziert im ACM Journal 1974), die ihm eine Einladung ans Thomas J. Watson Research Center der IBM einbrachte, wo er bis heute tätig ist. Von 1976 bis 1985 arbeitete er dort als Software- und Hardwareingenieur an IBM´s RISC Projekt. Zurzeit ist er auch Gastprofessor im Computer Science Department der University of Auckland in Neuseeland.

Seine Ergebnisse betreffen die Struktur mathematischer Theorien. Chaitin sucht Aussagen zur prinzipiellen Berechenbarkeit und zur prinzipiellen Entscheidbarkeit mathematischer Sätze.

Er beschäftigte sich mit Beispielen für prinzipiell unentscheidbare Sätze. Bei solchen Sätzen sei es komplett "zufällig", ob sie wahr oder falsch seien. Der englische Begriff "random" kann allerdings auch "wahllos" oder "regellos" heißen; gemeint ist hier, dass diese Sätze nicht "begründet" werden können, sondern "dass es eben so ist". 

Laut Chaitin hat er bewiesen, dass es bis auf endlich viele Ausnahmen unentscheidbar ist, ob eine Zahl Kolmogorow-reduzibel ist, d. h. ob es ein kleineres Programm gibt, das diese Zahl erzeugt. Es existiert also kein allgemeines Verfahren, mit dem die Kolmogorow-Komplexität gemessen werden könnte.

Die Interpretation von Chaitins Ergebnissen ist unter einigen Mathematikern umstritten.
Von ihm stammt die Chaitinsche Konstante.

Chaitin hat auch viel zur Philosophie der Mathematik geschrieben, insbesondere in Zusammenhang mit den Unvollständigkeitssätzen Gödels und Komplexitätsfragen.

1995 wurde er Ehrendoktor der University of Maine und erhielt 2002 eine Ehren-Professur in Buenos Aires.





</doc>
<doc id="2078" url="https://de.wikipedia.org/wiki?curid=2078" title="Gurkenkraut">
Gurkenkraut

Gurkenkraut ist die Bezeichnung für folgende Nutzpflanzen:


</doc>
<doc id="2080" url="https://de.wikipedia.org/wiki?curid=2080" title="Grad">
Grad

Grad (aus lat. "" ‚Schritt, Stufe‘) steht für:

Maßeinheiten:

in der Mathematik und Physik:

Grad ist der Name von:

Personen:

Orte:

-grad steht für:

Siehe auch:



</doc>
<doc id="2081" url="https://de.wikipedia.org/wiki?curid=2081" title="Ganze Zahl">
Ganze Zahl

Die ganzen Zahlen (auch "Ganzzahlen", lat. "numeri integri") sind eine Erweiterung der natürlichen Zahlen.

Die ganzen Zahlen umfassen alle Zahlen

und enthalten damit alle natürlichen Zahlen sowie deren additive Inverse. Die Menge der ganzen Zahlen wird meist mit dem Buchstaben mit Doppelstrich formula_1 bezeichnet (das „Z“ steht für das deutsche Wort „Zahlen“). Das alternative Symbol formula_2 ist mittlerweile weniger verbreitet; ein Nachteil dieses Fettdruck-Symbols ist die schwierige handschriftliche Darstellbarkeit. Der Unicode des Zeichens lautet U+2124 und hat die Gestalt ℤ.

Die obige Aufzählung der ganzen Zahlen gibt auch gleichzeitig in aufsteigender Folge deren natürliche Anordnung wieder. Die Zahlentheorie ist der Zweig der Mathematik, der sich mit Eigenschaften der ganzen Zahlen beschäftigt. 

Die Repräsentation ganzer Zahlen im Computer erfolgt üblicherweise durch den Datentyp Integer.

Die ganzen Zahlen werden im Mathematikunterricht üblicherweise in der fünften bis siebten Klasse eingeführt.

Die ganzen Zahlen bilden einen Ring bezüglich der Addition und der Multiplikation, d. h., sie können ohne Einschränkung addiert, subtrahiert und multipliziert werden. Dabei gelten Rechenregeln wie das Kommutativgesetz und das Assoziativgesetz für Addition und Multiplikation, außerdem gelten die Distributivgesetze.

Durch die Existenz der Subtraktion können lineare Gleichungen der Form
mit natürlichen Zahlen formula_4 und formula_5 stets gelöst werden: formula_6. Beschränkt man formula_7 auf die Menge der natürlichen Zahlen, dann ist nicht jede solche Gleichung lösbar.

Abstrakt ausgedrückt heißt das, die ganzen Zahlen bilden einen "kommutativen unitären Ring". Das neutrale Element der Addition ist 0, das additiv inverse Element von formula_8 ist formula_9, das neutrale Element der Multiplikation ist 1.

Die Menge der ganzen Zahlen ist total geordnet, in der Reihenfolge
D. h., man kann je zwei ganze Zahlen vergleichen. Man spricht von "positiven" formula_11, "nichtnegativen" formula_12, "negativen" formula_13 und "nichtpositiven" formula_14 ganzen Zahlen. Die Zahl 0 selbst ist weder positiv noch negativ. Diese Ordnung ist "verträglich" mit den Rechenoperationen, d. h.:

Mithilfe der Anordnung lassen sich die Vorzeichenfunktion
und die Betragsfunktion 
definieren. Sie hängen wie folgt
zusammen.

Wie die Menge der natürlichen Zahlen ist auch die Menge der ganzen Zahlen abzählbar.

Die ganzen Zahlen bilden keinen Körper, denn z. B. ist die Gleichung formula_24 nicht in formula_1 lösbar. Der kleinste Körper, der formula_1 enthält, sind die rationalen Zahlen formula_27.

Eine wichtige Eigenschaft der ganzen Zahlen ist die Existenz einer Division mit Rest. Aufgrund dieser Eigenschaft gibt es für zwei ganze Zahlen stets einen größten gemeinsamen Teiler, den man mit dem Euklidischen Algorithmus bestimmen kann. In der Mathematik wird formula_1 als "euklidischer Ring" bezeichnet. Hieraus folgt auch der Satz von der eindeutigen Primfaktorzerlegung in formula_1.

Ist die Menge der natürlichen Zahlen gegeben, dann lassen sich die ganzen Zahlen daraus als Zahlbereichserweiterung konstruieren:

Auf der Menge formula_30 aller Paare natürlicher Zahlen wird folgende Äquivalenzrelation definiert:
Die Addition und Multiplikation auf formula_30 wird definiert durch:

formula_35 ist nun die Menge aller Äquivalenzklassen.

Die Addition und Multiplikation der Paare induzieren nun wohldefinierte Verknüpfungen auf formula_1, mit denen formula_1 zu einem Ring wird.

Die übliche Ordnung der ganzen Zahlen ist definiert als

Jede Äquivalenzklasse formula_40 hat im Fall formula_41 einen eindeutigen Repräsentanten der Form formula_42, wobei formula_43, und im Fall formula_44, wobei formula_45.

Die natürlichen Zahlen lassen sich in den Ring der ganzen Zahlen einbetten, indem die natürliche Zahl formula_8 auf die durch formula_42 repräsentierte Äquivalenzklasse abgebildet wird. Üblicherweise werden die natürlichen Zahlen mit ihren Bildern formula_42 identifiziert und die durch formula_49 repräsentierte Äquivalenzklasse wird mit formula_9 bezeichnet.

Ist formula_8 eine von formula_52 verschiedene natürliche Zahl, so wird die durch formula_42 repräsentierte Äquivalenzklasse als "positive" ganze Zahl und die durch formula_49 repräsentierte Äquivalenzklasse als "negative" ganze Zahl bezeichnet.

Diese Konstruktion der ganzen Zahlen aus den natürlichen Zahlen funktioniert auch dann, wenn formula_55 ohne formula_52 definiert wird. Dann müsste die natürliche Zahl formula_8 mit der durch formula_58 repräsentierten Äquivalenzklasse identifiziert werden.





</doc>
<doc id="2083" url="https://de.wikipedia.org/wiki?curid=2083" title="Gerade (Begriffsklärung)">
Gerade (Begriffsklärung)

Eine Gerade ist:


gerade bezeichnet:


Siehe auch:


</doc>
<doc id="2085" url="https://de.wikipedia.org/wiki?curid=2085" title="Gestein">
Gestein

Als Gestein bezeichnet man eine feste, natürlich auftretende, in der Regel mikroskopisch heterogene Vereinigung von Mineralen, Gesteinsbruchstücken, Gläsern oder Rückständen von Organismen. Das Mischungsverhältnis dieser Bestandteile zueinander ist weitgehend konstant, sodass ein Gestein trotz seiner detaillierten Zusammensetzung bei freiäugiger Betrachtung einheitlich wirkt.

Die Untersuchung der Lithogenese ( "lithos" = Stein, Fels, Gestein), Petrogenese ( "petros" = Stein) oder Gesteinsbildung ist zentrales Gebiet der Petrologie und Geologie, aber auch der Geophysik und Geochemie.

Die meisten Gesteine der Erdkruste (und auch der terrestrischen Planeten) sind Silikatgesteine (Hauptbestandteile Feldspäte und Quarz), nur ein kleiner Prozentsatz sind Karbonate.

Ein größeres Volumen eines bestimmten Gesteines, das sich in der Erdkruste befindet oder im Gelände zu Tage tritt, wird gemeinhin als Gesteinsformation bezeichnet (nicht gleichzusetzen mit dem zwar ähnlichen, aber wesentlich exakter definierten Formationsbegriff in der Lithostratigraphie).

Der geologische Gesteinsbegriff ist weiter gefasst als der umgangssprachliche und bezieht auch natürlich auftretende Metall-Legierungen, vulkanisches Glas, Eis, lockeren Sand oder Kohle ein. Die Lehre von den Gesteinen, die Petrologie, ist ein Teilgebiet der Geowissenschaften. Beispiele für verschiedene Gesteinsarten sind in der Liste der Gesteine zu finden.

Die Erde und die inneren Planeten des Sonnensystems bauen sich aus sehr großen, räumlich zusammenhängenden Massen von Gesteinen auf. Jedoch sind diese nur an der Oberfläche der Erdkruste sichtbar und zugänglich, insbesondere in Gebirgen, die durch tektonische Vorgänge der Gebirgsbildung entstehen.

Die Lehre von der Be- und Verarbeitung von Gesteinen und Erden, deren Charakter nichtmetallisch ist, nennt man Gesteinshüttenkunde.

Gesteine bestehen im Wesentlichen aus Mineralen, von denen aber nur etwa dreißig einen bedeutenden Anteil an der Gesteinsbildung haben, die darum ‚gesteinsbildende Minerale‘ genannt werden. Vor allem sind dies Silikate, wie Feldspäte, Quarz, Glimmer, Amphibole oder Olivin, aber auch Karbonate, wie Calcit oder Dolomit sind wichtige Bestandteile von Gesteinen. Neben diesen "Hauptgemengteilen" (die mineralischen Komponenten, die mehr als 10 % der Gesamtmasse ausmachen) enthalten die meisten Gesteine noch so genannte "Nebengemengteile" (Komponenten die zwischen 10 und 1 % ausmachen) oder "Akzessorien" (Komponenten, die nur zu <1 % enthalten sind). Häufig sind die Akzessorien für ein Gestein namensgebend. Des Weiteren ist durchweg ein gewisser Anteil Wasser vorhanden, als Kristallwasser oder Porenwasser.

Als Gefüge eines Gesteins bezeichnet man vor allem seine Textur – die räumliche Lage und Verteilung der Minerale in einem Gestein, die sich aus den Eigenschaften und dem Verhältnis der gesteinsbildenden Minerale zueinander ergibt – und die Struktur, die sich auf die geometrischen Eigenschaften der einzelnen Gesteinsbestandteile bezieht. Dazu gehören relative und absolute Größe, die Form der Kristalle oder Mineralkörner und die Art des Kornverbandes.

Gesteine lassen sich entsprechend ihrer Entstehung grob in drei Klassen unterteilen: magmatische Gesteine, Sedimentgesteine, und metamorphe Gesteine. Innerhalb dieser Klassen wird weiter untergliedert. Die gesamte Geschichte eines Gesteins, von seiner ursprünglichen Bildung bis zu seinem heutigen Zustand, wird als 'Petrogenese' bezeichnet.

In der Geotechnik und zahlreichen verwandten Wissenschaften wie der Bodenkunde unterscheidet man Gesteine anhand ihrer mechanischen Eigenschaften grundsätzlich in zwei Gruppen, die Festgesteine und die Lockergesteine. Bei den Festgesteinen werden insbesondere unter dem Aspekt der Bearbeitbarkeit und Verwendbarkeit Hartgesteine von Weichgesteinen unterschieden.

Magmatische Gesteine (Magmatite, Erstarrungsgesteine) entstehen durch das Erkalten und Auskristallisieren des geschmolzenen Materials aus dem Erdinneren, des so genannten Magmas. Die Nomenklatur von magmatischen Gesteinen nach ihrem Mineralbestand findet sich im Streckeisendiagramm.

Findet das Erkalten unterirdisch (tiefer als 5 km) statt, spricht man von Plutoniten oder Intrusivgesteinen (Tiefengestein). Durch die verhältnismäßig gute Wärmeisolation der aufliegenden Gesteine kühlt sich die Magmaschmelze nur langsam ab, so dass große Mineralkristalle entstehen können. Beispiele für plutonische Gesteine sind Granit, Granodiorit, Syenit, Diorit oder Gabbro. Das Magma kann riesige Gesteinsmassen bilden, die so genannten Plutone, die oft mehrere Tausend Kubikkilometer Gestein umfassen.

Magma kann jedoch auch in flüssigem Zustand zu Tage treten. An der Erdoberfläche im Kontakt mit Luft oder Wasser erkaltet es schnell und bildet dann die so genannten Vulkanite oder Effusivgesteine (Ergussgesteine). Durch die rasche Abkühlung kommt es nur zur Bildung sehr kleiner Kristalle wie etwa beim Basalt oder Andesit. Weitere Beispiele sind Rhyolith und Trachyt. Bei sehr schneller Abschreckung entsteht sogar überhaupt keine kristalline Ordnung, sondern vulkanisches Glas wie beispielsweise Obsidian.

Ganggesteine bilden die Zwischenglieder von Plutoniten und Vulkaniten. Sie dringen in Spalten zwischen Magmakammer und Erdoberfläche ein und erkalten dort als Gänge. Beispiele für Ganggesteine sind Granitporphyr, Dolerit und Lamprophyr.

Metamorphe Gesteine (Umwandlungsgesteine) entstehen aus älteren Gesteinen beliebigen Typs durch Metamorphose, das heißt durch Umwandlung unter hohem Druck beziehungsweise hoher Temperatur. Bei der Umwandlung ändert sich in der Regel die Mineralzusammensetzung des Gesteins, weil neue Minerale und Mineralaggregate gebildet werden; der Gesteinschemismus bleibt aber weitgehend gleich. Daneben kann auch das Gesteinsgefüge transformiert werden. Beispielsweise entsteht aus Quarzsandsteinen durch Anwachsen von Quarz­säumen an die Sedimentkörner und die daraus resultierende enge Verzahnung der Körner miteinander das metamorphe Gestein Quarzit, aus Kalksteinen entsteht, durch Rekristallisation, der auf Bruchflächen typisch „zuckerkörnige“ Marmor (beides sind Beispiele für weitgehend monomineralische Gesteine, bei denen während der Metamorphose keine oder keine nennenswerten Änderungen im Mineralbestand erfolgen).

Weiträumige Metamorphose von Gesteinen findet meist in großer Tiefe statt, lokale Transformationen können aber auch nahe der Erdoberfläche auftreten, meist im Zusammenhang mit Vulkanismus. Auch Meteoriteneinschläge führen zu Gesteinsmetamorphosen (sogenannte Impaktmetamorphose).



Sedimentgesteine (Sedimentite, Ablagerungsgesteine) entstehen
So werden Sedimentgesteine nach Art ihrer Bildung in "klastische, chemische" und "organogene (biogene) Ablagerungsgesteine" unterschieden.

Werden die Ablagerungen durch Sedimentation weiteren Materials bedeckt, verdichten sie sich durch Druck, Bindemittelzufuhr und erhöhte Temperatur unter zunehmendem Wasserverlust immer mehr, bis aus dem weichen Sediment ein hartes, sprödes Sedimentgestein entstanden ist. Diese Veränderungen nach der primären Sedimentation bezeichnet man als Diagenese.

Beispiele für Sedimentgesteine sind Sandstein, Kalkstein und Steinsalz.

Sedimente lagern sich meist kumulativ in einer Abfolge horizontaler Schichten ab; durch die Reihenfolge der Ablagerung sind von Ausnahmefällen abgesehen höherliegende Schichten jünger als tieferliegende, eine Erkenntnis, die als "Superpositionsprinzip" oder "Lagerungsgesetz" auf den dänischen Arzt und Geologen Nicolaus Steno zurückgeht. Nach ihrer Entstehung können Sedimentgesteine starken Kräften unterliegen, infolge derer die ehemals flachen Schichten gefaltet und gekippt werden, so dass die Lage des Gesteins im Raum so stark verändert sein kann, dass die ursprüngliche Schichtfolge lokal umgekehrt ist.

Sedimente lassen sich grob in "terrestrische" Land- und "marine" Meeressedimente unterteilen. Zu terrestrischen zählt man auch Ablagerungen in Süßwasserseen oder Flüssen, die aus Sand oder Schlamm entstanden sind, sowie die organischen Pflanzenreste, aus denen Kohle hervorgegangen ist. Auch Wüsten­sedimente sowie Ablagerungen von Gletschern werden dieser Gruppe zugeteilt. Ein Grenzfall zwischen Vulkaniten und Sedimenten sind vulkanische Aschen und Tuffe.

Meeressedimente können durch Ablagerung von Erosionsmaterial anderer Gesteine auf dem Meeresgrund, durch von biochemischen Vorgängen verursachte Ausfällung, zum Beispiel von Karbonaten, und durch Ablagerung anorganischer Skelette von Mikroorganismen wie Foraminiferen, Coccolithophoriden (Haptophyta), Strahlentierchen (Radiolaria) und Kieselalgen (Bacillariophyta) entstehen.

Einen Sonderfall unter den Gesteinen bilden die Meteoriten, Gesteinskörper aus dem Weltraum. Meteoriten sind Zeugnisse der Frühgeschichte des Sonnensystems und enthalten zahlreiche Minerale, die sich nicht in anderen Gesteinen irdischen Ursprungs finden lassen. Sie lassen sich nach ihrem Mineralgehalt einteilen in Steinmeteoriten, die in erster Linie aus Silikaten wie Olivin oder Pyroxen bestehen, Eisenmeteoriten, die sich häufig aus den Eisen-Nickel-Mineralen Kamacit und Taenit zusammensetzen und Stein-Eisen-Meteoriten, die einen Mischtyp darstellen. Die Größe von Meteoriten liegt zwischen der von Mikrometeoriten und riesigen, tonnenschweren Gesteinskörpern. Fast alle der Wissenschaft bekannten Meteoriten gingen, in geologischen Zeitmaßstäben betrachtet, vor sehr kurzer Zeit auf der Erde nieder. Nur ein sehr geringer Teil liegt als sogenannte „fossile Meteoriten“ vor. Derartige Stücke sind in Schweden in mehrere hundert Millionen Jahre alten Sedimentgesteinen nachgewiesen worden.

Irdischen Ursprungs, aber durch Meteoriteneinschläge gebildet sind die Tektite, zentimetergroße Glasobjekte, die durch einschlagbedingtes Schmelzen irdischen Gesteins und darauf folgendes schnelles Abkühlen an der Luft entstehen, und die Impaktite, die durch die starken mechanischen und thermischen Einwirkungen bei einem Meteoriteneinschlag aus den am Einschlagsort vorhandenen Gesteinen entstehen, wie etwa Suevit.

Magmatische, metamorphe und Sedimentgesteine werden durch geodynamische Prozesse wie Erosion, Gesteinsmetamorphose oder Sedimentation ineinander umgewandelt.

So unterliegen durch Erosion des Deckgesteins freigelegte metamorphe und magmatische Intrusivgesteine ebenso wie die an der Oberfläche gebildeten Sediment- und magmatischen Extrusivgesteine der Verwitterung und Erosion. In erster Linie durch wind- oder wasserbedingten Transport lagern sich die Verwitterungsbestandteile als Sedimente ab und bilden durch Verdichtung schließlich Sedimentgesteine. Diese wandeln sich wie auch magmatische Intrusivgesteine in großer Tiefe unter hohem Druck und hoher Temperatur in metamorphe Gesteine um. Der Kreislauf schließt sich, wenn diese entweder wieder an die Oberfläche gelangen oder durch weitere Absenkung ins Erdinnere aufgeschmolzen werden und damit das Rohmaterial für die Entstehung magmatischer Gesteine bilden.

Das älteste bisher sicher datierte Gestein stammt aus der Acasta-Gneis-Formation des Slave-Kratons im Nordwesten Kanadas mit 4,031 ± 0,003 Milliarden Jahren (datiert 1999). Forscher der McGill-Universität in Kanada behaupteten 2008, im Nuvvuagittuq-Grünsteingürtel an der Hudson Bay im nördlichen Kanada ein noch älteres Gestein mit 4,28 Milliarden Jahren gefunden zu haben. Diese Datierung ist umstritten, das Alter dieser Gesteine ist weiterhin Gegenstand der Forschung.

Körner aus Mineralen, die besonders widerstandsfähig gegen Verwitterung sind, beispielsweise Quarz, können mehrfach zumindest den exogenen Teil des Gesteinskreislaufs durchlaufen. Körner aus Mineralen, die zudem einen besonders hohen Schmelzpunkt haben, können sogar komplette Zyklen durchlaufen. Ein solches Mineral ist Zirkon, und die ältesten Zeugnisse einer festen Kruste auf der Erde sind Zirkonkörner. Diese entstammen Metasedimenten in den Jack Hills (West-Australien), die vor 3 Milliarden Jahren abgelagert wurden. Einige der Zirkone darin waren jedoch schon vor 4,4 Milliarden Jahren aus einem Magma auskristallisiert.

Gesteine dienten in der Menschheitsgeschichte als erster Werkstoff zur Herstellung von Werkzeug, den Steingeräten, und sind somit auch der Namensgeber für die älteste kulturhistorische Erdepoche, die Steinzeit. Archäologische Funde aus jener Zeit sind meist Steinartefakte. Steine bilden das älteste feste Baumaterial der menschlichen Kultur und die ältesten bekannten überlieferten Schriftträger menschlicher Schrift­kultur.

Die Kunst, Steine zu bearbeiten, nennt man Lithurgik.

In früheren Zeitepochen wurden aus Gesteinen gesamte Bauwerke erstellt. Heute sind sie ein wesentlicher Bestand im Innenausbau (Bodenbelag, Treppe, Fensterbank, Waschtisch und Küchenarbeitsplatte) und im Außenbau (Fassaden­bekleidung oder Pflasterstein). Des Weiteren sind sie Grundlage bildlicher Darstellungen in der Kunst, besonders in der Lithografie und als Ausgangsmaterial der Bildhauerei. Schmucksteine, Edelsteine und Halbedelsteine sind als Schmuck beliebt. Lesesteinhaufen und Trockensteinmauern dienten früher als Markierung von Äckern und sind heute wertvolle Biotope. Ein Grenzstein wird zur Abgrenzung von Gebieten verwendet. Fossilien in Form von Versteinerungen zeugen von Lebewesen früherer Äonen, Epochen und Perioden und spielen eine große Rolle für das Studium vergangener Lebensformen, der Evolutionsgeschichte sowie für die Datierung von Gesteinsschichten.





</doc>
<doc id="2086" url="https://de.wikipedia.org/wiki?curid=2086" title="Gottlob Frege">
Gottlob Frege

Friedrich Ludwig Gottlob Frege (* 8. November 1848 in Wismar; † 26. Juli 1925 in Bad Kleinen) war ein deutscher Logiker, Mathematiker und Philosoph.

Seine herausragende Leistung auf dem Gebiet der Logik besteht darin, als erster eine formale Sprache und, damit zusammenhängend, formale Beweise entwickelt zu haben. Er schuf dadurch eine wesentliche Grundlage für die heutige Computertechnik und Informatik sowie für formale Methoden in der linguistischen Semantik.

Im Bereich der Philosophie waren seine sprachphilosophischen Betrachtungen außerordentlich einflussreich. Unmittelbar beeinflusst hat er u. a. Rudolf Carnap, der bei ihm studierte, Bertrand Russell und Ludwig Wittgenstein. Frege gilt als einer der hauptsächlichen Wegbereiter der analytischen Philosophie, einer der wichtigsten Strömungen der Philosophie des 20. Jahrhunderts.

Gottlob Freges Eltern waren Karl Alexander Frege (* 1809 in Hamburg; † 1866) und Auguste Wilhelmine Sophia Bialloblotzky (* 1815 in Pattensen; † 1898). Die Heirat fand 1846 statt. Freges Vater war Lehrer und Direktor des Wismarer Lyzeums, einer privaten höheren Schule für Mädchen, die er selbst gegründet hatte. Dort wurde insbesondere (neben Unterricht in Religion, Französisch, Geschichte, Naturkunde, Geographie und Rechnen) elementarer Unterricht in Neuhochdeutsch für die von Haus aus Plattdeutsch sprechenden Töchter gegeben (Eintrittsalter war acht Jahre). Karl Alexander Frege veröffentlichte 1862 auch eine neuhochdeutsche Grammatik. Freges Mutter Auguste war dort ab 1843 Lehrerin gewesen und leitete später nach dem Tod ihres Mannes 1866 noch zehn Jahre erfolgreich die von ihrem Mann gegründete Mädchenschule. Ihr Vater war Heinrich Sigmund Bialloblotsky (1757–1828), der Superintendent in Pattensen und ab 1822 in Wunstorf war. Die Familie Bialloblotzky entstammte dem im 17. Jahrhundert aus Glaubensgründen von Polen nach Deutschland (Seehausen bei Wittenberg) ausgewanderten polnischen Adelsgeschlecht Ogonceyk. Freges Großmutter mütterlicherseits war die Tochter des Superintendenten Ludwig Wilhelm Ballhorn, die ihre Linie bis zu Philipp Melanchthon zurückverfolgte. Weitere Vorfahren Freges waren sein Onkel mütterlicherseits der Forschungsreisende in Afrika, Schulleiter, Pastor und Missionar Christoph Heinrich Friedrich Bialloblotsky (1799–1869) und sein Großvater väterlicherseits, der Kaufmann und sächsische Konsul in Hamburg Christian Gottlob Frege (1779–1811), der mit der Tochter eines Maklers Printz verheiratet war. Er stammte aus einer bekannten Leipziger Bankiersfamilie (siehe Christian Gottlob Frege)

Frege hatte noch einen Bruder Arnold Frege (* 1852). Im Todesjahr Freges 1925 wird er als Schriftsteller in Neudamm bei Stettin erwähnt.

Das Geburtshaus in der Böttcherstr. 2 in Wismar, das der Vater 1846 erwarb, wurde im Zweiten Weltkrieg zerstört. Dort war auch die Schule.

Frege besuchte das Gymnasium Große Stadtschule Wismar. Einer seiner Lehrer, Leo Sachse, hatte anscheinend einen großen Einfluss auf ihn. Der Name „Leo Sachse“ wird später in Freges Schriften in Beispielen verwendet. Nachdem im Jahre 1866 sein Vater gestorben war, begann Frege 1869 sein Studium auf Sachses Rat hin an der Universität Jena. Hier lehrten unter anderem Ernst Abbe, der Frege in seiner wissenschaftlichen Karriere unterstützte, und der Philosoph Kuno Fischer, mit dessen Ideen Frege sich intensiv auseinandersetzte.

Im Jahre 1871 wechselte Frege an die Universität Göttingen, wo er 1873 seine Doktorarbeit "Über eine geometrische Darstellung der imaginären Gebilde in der Ebene" vorlegte. Frege kehrte nach Jena zurück, wo er sich 1874 bei Abbe über das Thema "Rechnungsmethoden, die sich auf eine Erweiterung des Größenbegriffes gründen" habilitierte. Er lehrte als Privatdozent. 1879 wurde er zum außerordentlichen Professor ernannt.

Im Jahre 1887 heiratete Frege Margarete Lieseberg, Tochter des Kaufmanns Heinrich Lieseberg aus Grevesmühlen. Die Ehe blieb kinderlos (nach anderen Quellen hatten sie mindestens zwei Kinder, die jung starben), und das Ehepaar Frege adoptierte einen Jungen, Paul Otto Alfred Frege (vormals Paul Otto Alfred Fuchs).

Im Jahr 1895 wurde Frege zum Mitglied der Leopoldina gewählt. 1896 wurde Frege in Jena zum ordentlichen Honorarprofessor berufen und lehrte dort – wenig beachtet von Studenten und Kollegen – durchgehend bis zu seiner Emeritierung im Jahre 1917. Freges einziger Student von Bedeutung war Rudolf Carnap, der sein Werk später in mancherlei Hinsicht weiterführte und bekannt machte. Immerhin hatte Frege wissenschaftlichen Kontakt zu den Literaturnobelpreis-Trägern Rudolf Eucken und Bertrand Russell.

Freges wissenschaftliche Arbeit wurde durch die Entdeckung der Russellschen Paradoxie im Jahre 1902 in eine schwere Krise gestürzt (siehe auch den Abschnitt "Mathematik"). 1903 gestand Frege im Nachwort seiner "Grundgesetze der Arithmetik" ein, dass durch Russell die „Grundlagen seines Baues erschüttert“ worden seien.

Im Jahre 1904 starb Freges Frau Margarete.

In den Folgejahren verfiel Frege in eine Depression, die sich unter anderem darin äußerte, dass er keine größeren Arbeiten mehr publizierte. Erst nach seiner Emeritierung erschienen wieder eine Reihe von drei zusammenhängenden logischen Untersuchungen: "Der Gedanke" (1918), "Die Verneinung" (1918) und "Gedankengefüge" (1923). Er hatte seine Lebenskrise zumindest teilweise überwunden. In seinem 1994 aus dem Nachlass publizierten Teil seines Tagebuchs (für 1924) finden sich anti-demokratische, anti-katholische, anti-französische und antisemitische Bemerkungen; öffentlich ist Frege aber wohl nie politisch in Erscheinung getreten. Seinen Lebensabend verbrachte Frege in Bad Kleinen, in der Nähe seiner Geburtsstadt Wismar.

Im Jahre 2001 wurde der Asteroid (21665) Frege nach ihm benannt.

Freges Nachlass kam auf Initiative von Heinrich Scholz 1935 nach Münster, wo er bei einem Bombenangriff im März 1945 zu einem großen Teil zerstört wurde.

Nachdem die durch Aristoteles begründete nichtformale Syllogistik mehr als 2.000 Jahre lang als die exakteste Form logischen Schließens gegolten hatte, begann mit Freges revolutionärer „Begriffsschrift“ aus dem Jahre 1879 eine neue Ära in der Geschichte der Logik. In dieser Publikation entwickelte er eine neue Logik in axiomatischer Form, die bereits den Kernbestand der modernen formalen Logik umfasste, nämlich eine Prädikatenlogik zweiter Stufe mit Identitätsbegriff.

Frege war neben George Boole und Ernst Schröder einer derjenigen Logiker des 19. Jahrhunderts, die durch die Verbesserung der Logik den Grundstein für die Erforschung der Grundlagen der Mathematik legten. Nach Wilhelm Ackermann und David Hilbert, die in ihren Arbeiten häufig Bezug auf seine Schriften nahmen, ist Freges wichtigster Beitrag die „Erfüllung des Bedürfnisses der Mathematik nach exakter Grundlegung und strenger axiomatischer Behandlung.“

In der Philosophie der Mathematik trat Frege als scharfer Kritiker vorgefundener Ansätze hervor: In den "Grundlagen der Arithmetik" findet sich eine umfangreiche und einflussreiche Analyse v. a. der Theorien Immanuel Kants, der arithmetische Sätze als synthetische Urteile a priori auffasst, und John Stuart Mills, für den arithmetische Sätze durch Erfahrung bestätigte allgemeine Naturgesetze sind.

Daneben war Frege der Begründer eines neuen mathematikphilosophischen Programms, des Logizismus, dem zufolge die Sätze der Arithmetik sich auf logische Wahrheiten zurückführen lassen. Dieses Programm wird in den "Grundlagen der Arithmetik" informell skizziert und in den späteren "Grundgesetzen der Arithmetik" streng formal durchgeführt.

Das System des Logizismus enthielt jedoch einen Widerspruch (die sogenannte Russellsche Antinomie), wie Frege in einem berühmt gewordenen Brief von Bertrand Russell aus dem Jahr 1902 erfahren musste. Frege sah sein Lebenswerk gescheitert und zog sich resigniert von der Logik zurück. Nichtsdestoweniger hatte er durch seine Arbeit die wesentlichen Grundlagen geschaffen, auf denen andere, insbesondere Russell, aufbauen und das logizistische Programm vollenden konnten.

Im Bereich der Sprachphilosophie unterscheidet Frege zwischen einem "Sinn" und einer "Bedeutung", die jedem sprachlichen Zeichen zukommen. Freges Terminologie ist abweichend vom üblichen Sprachgebrauch und deshalb etwas irreführend, denn mit "Bedeutung" meint er den Bezug bzw. die Referenz eines Ausdrucks, während sein "Sinn" dem nahekommt, was für gewöhnlich als Bedeutung bezeichnet wird. Frege kennt grundsätzlich drei verschiedene Arten von sprachlichen Ausdrücken: Eigennamen, Sätze und Begriffsausdrücke. Für jeden dieser Typen kann zwischen Sinn und Bedeutung unterschieden werden:






</doc>
<doc id="2087" url="https://de.wikipedia.org/wiki?curid=2087" title="George Boole">
George Boole

George Boole [] (* 2. November 1815 in Lincoln, England; † 8. Dezember 1864 in Ballintemple, in der Grafschaft Cork, Irland) war ein englischer Mathematiker (Autodidakt), Logiker und Philosoph.

George Boole wurde in Lincolnshire geboren. Er hatte außer der Grundschulbildung keine weiterführenden Schulen besucht. Er brachte sich autodidaktisch Altgriechisch, Französisch und Deutsch bei. Mit 16 Jahren wurde er Hilfslehrer, um seine Familie finanziell zu unterstützen. Im Alter von 19 Jahren gründete Boole seine eigene Schule. Auf Grund seiner wissenschaftlichen Arbeiten wurde er 1848 Mathematikprofessor am Queens College in Cork (Irland), obwohl er selbst keine Universität besucht hatte. Dort lernte er Mary Everest kennen, seine spätere Frau. Sie war mathematisch interessiert, arbeitete als Bibliothekarin und setzte sich mit der Didaktik der Mathematik auseinander. Ihr Onkel George Everest war Namensgeber des höchsten Bergs der Welt. George und Mary hatten fünf Töchter, darunter die Autorin und Musikerin Ethel Lilian Voynich (1864–1960) und Alicia Boole Stott (1860–1940), der es als Mathematikerin ohne formale akademische Bildung gelang, die regulären Polyeder in vier Dimensionen zu klassifizieren.
Von der Royal Society wurde Boole 1844 mit der Royal Medal ausgezeichnet. 1847 publizierte er sein epochemachendes Logikwerk "The Mathematical Analysis of Logic" und 1854 sein ausführlicheres Buch "An Investigation of the Laws of Thought". 1857 wurde er zum Mitglied („Fellow“) der Royal Society gewählt.

George Boole starb am 8. Dezember 1864 mit nur 49 Jahren an einer fiebrigen Erkältung. Auf seinem Fußweg ging er zwei Meilen weit im strömenden Regen zur Universität, wo er anschließend seine Vorlesung in durchnässten Kleidern hielt. Er erkältete sich, bekam hohes Fieber und erholte sich davon später nicht mehr. Seine Frau war Anhängerin der damaligen Naturheilkunde, die „Gleiches mit Gleichem“ zu behandeln pflegte. Sie soll den an der Fiebererkältung erkrankten Gatten im Bett eimerweise mit kaltem Wasser übergossen haben. Als seine Todesursache wurde Pleuraerguss angegeben.

Boole schuf in seiner Schrift "The Mathematical Analysis of Logic" von 1847 den ersten algebraischen Logikkalkül und begründete damit die moderne mathematische Logik, die sich von der bis dato üblichen Logik durch eine konsequente Formalisierung abhebt. Er formalisierte die klassische Logik und Aussagenlogik und entwickelte ein Entscheidungsverfahren für die wahren Formeln über eine disjunktive Normalform. Boole nahm damit – da aus der Entscheidbarkeit der klassischen Logik ihre Vollständigkeit und Widerspruchsfreiheit folgt – schon gut 70 Jahre vor Hilberts Programm für ein zentrales Logikgebiet die Lösung der von David Hilbert gestellten Probleme vorweg. Als Verallgemeinerungen von Booles Logikkalkül wurden später die sogenannte boolesche Algebra und der boolesche Ring nach ihm benannt.

Boole benutzte die gewöhnliche Algebra, die heute als Potenzreihen-Ring über dem Körper der reellen Zahlen präzisiert wird. In sie bettete er die klassische Logik ein, indem er die Konjunktion UND als Multiplikation und die Negation als Differenz zur formula_1 definierte und für logische Terme die Idempotenz forderte, das heißt: 
Es handelt sich dabei um eine Einbettung, in der nicht alle Terme einen logischen Sinn haben; beispielsweise ist wegen formula_2 die Summe formula_3 logisch sinnlos, weshalb Boole formula_4 uninterpretierbar nannte. Die Addition ist also im logischen Bereich nur eine partielle Operation, weshalb er bei den logischen Termen und Operatoren von elective symbols, elective functions, elective equations sprach. Dieser Sachverhalt wurde von seinen Nachfolgern kritisiert. Seine Methode ist aber völlig korrekt. Denn der logische Bereich ist operativ abgeschlossen: Es ist die von idempotenten Unbestimmten, der 1, der Multiplikation und der Negation erzeugte Struktur, da formula_1 idempotent ist und mit formula_6 und formula_7 auch formula_8 und formula_9 idempotent sind, wie man leicht nachrechnet. Damit wirken auch alle definitorisch ableitbaren logischen Operatoren in diesem Bereich, insbesondere die einschließende und die ausschließende Disjunktion:
Beide Definitionen gehören zum logischen Bereich:

Seine ODER-Definition liefert offenbar alle Axiome der späteren booleschen Algebra und seine ENTWEDER-ODER-Definition alle Axiome des späteren booleschen Rings, wobei die Additionen formula_12 und formula_13 strikt zu unterscheiden sind. 

Boole entwarf seinen Kalkül primär als Begriffs- oder Klassenlogik, in dem formula_1 das Universum (die Allklasse) ist und die Unbestimmten formula_15 Klassen (Begriffe) repräsentieren. Innerhalb dieses Kalküls stellte er dann die scholastische Syllogistik mit Gleichungssystemen dar. Ihre grundlegenden Prädikate repräsentierte er durch Gleichungen:

Sekundär gebrauchte Boole seinen Kalkül auch als Aussagenlogik, in dem die Unbestimmten formula_15 Aussagen repräsentieren und formula_1 und formula_23 die Wahrheitswerte: 
Sein logisches Entscheidungsverfahren über eine Normalform ergänzte er durch ein gleichwertiges semantisches Entscheidungsverfahren mit Wahrheitswert-Einsetzungen in boolesche Funktionen, die jedem belegten logischen Term einen Wahrheitswert zuordnen. Dieses Verfahren entspricht dem Entscheidungsverfahren mit Wahrheitstafeln, das zur Ermittlung von Tautologien dient.

Unter der booleschen Algebra wird heute nicht Booles originale Algebra verstanden, sondern der boolesche Verband, den Boole-Nachfolger entwickelten. 1864 entfernte William Stanley Jevons bei Boole die logisch sinnlosen mathematischen Terme und gab der Addition einen logischen Sinn als inklusives ODER mit der Regel formula_28. Boole, der mit ihm korrespondierte, war nicht einig mit dieser Uminterpretation der Addition, weil die Regeln der üblichen Algebra verletzt sind, denn formula_28 impliziert in ihr formula_30. Dennoch setzte sich diese Modifikation von Booles Kalkül durch, maßgeblich beeinflusst durch Ernst Schröder, der dazu 1877 das erste vollständige Axiomensystem formulierte, das Giuseppe Peano 1888 in die moderne nicht-additive Form brachte.

Booles Kalkül lässt sich auch so modifizieren, dass keine logisch sinnlosen Terme mehr vorkommen und die üblichen Rechenregeln für die Addition gewahrt bleiben. Dazu muss die Addition im logischen Bereich abgeschlossen sein und die Idempotenz erfüllen; dann gilt speziell formula_31, was formula_32 impliziert, so dass auch formula_33 gilt und selbstinverse Terme vorliegen. Hierdurch erhält die Addition den Sinn des exklusiven ENTWEDER-ODER. Diese Kalkülvariante gab Iwan Iwanowitsch Schegalkin 1927 erstmals an zusammen mit einer vollständigen Axiomatisierung. Dabei entsteht ein sogenannter boolescher Ring, dem Marshall Harvey Stone 1936 den Namen gab. Boolesche Ringe sind rechnerisch elegant, weil hier die schulbekannten Rechenregeln gelten. Die zur Entscheidbarkeit einer Formel notwendige Normalform entsteht hier einfach durch distributives Ausmultiplizieren und Streichen doppelter Faktoren und Summanden mit der Idempotenz formula_34 und der Zusatzregel formula_32.

Beide Kalkülvarianten sind in Booles Originalkalkül implizit enthalten, da man mit seinen Definitionen beide Axiomensysteme ableiten kann.






</doc>
<doc id="2088" url="https://de.wikipedia.org/wiki?curid=2088" title="Granit">
Granit

Granite (von lat. "granum" „Korn“) sind massige und relativ grobkristalline magmatische Tiefengesteine (Plutonite), die reich an Quarz und Feldspaten sind, aber auch dunkle (mafische) Minerale, vor allem Glimmer, enthalten. Der Merkspruch „Feldspat, Quarz und Glimmer, die drei vergess ich nimmer“ gibt die Zusammensetzung von Granit vereinfacht wieder. Granit entspricht in seiner chemischen und mineralogischen Zusammensetzung dem vulkanischen Rhyolith. Granit tritt gewöhnlich massig auf und kann durch horizontal und vertikal verlaufende Klüfte (dreidimensionales Kluftnetz) in quaderförmige Blöcke zerlegt sein. Seltener ist Granit im Dachbereich der Intrusion plattig ausgebildet.

In der Umgangssprache wird das Wort "Granit" häufig als Überbegriff für verschiedene plutonische Gesteine verwendet, die hinsichtlich ihrer Farbe, Textur, Körnung, ihrer chemischen Zusammensetzung und ihrem Mineralbestand den eigentlichen Graniten (einschließlich der Alkalifeldspatgranite) mehr oder weniger ähneln. Dabei handelt es sich um Granodiorite und Tonalite sowie um Monzonite und Diorite. Diese Gesteine werden, sofern sie einen Quarzanteil von mehr als 20 % besitzen, petrographisch unter den Oberbegriffen Granitoide oder "granitische Gesteine" zusammengefasst. Monzonite und Diorite haben weniger als 20 % Quarz und sollten daher weder als „Granit“ noch als „Granitoid“ bezeichnet werden.

Zudem werden des Öfteren dunkle Naturwerksteine magmatischen Ursprunges als „schwarze Granite“ bezeichnet (z. B. der „svart granit“ von Älmhult in Südschweden). Diese Gesteine weisen in aller Regel weniger als 20 % Quarzanteil auf und sind petrographisch meist als Mikrogabbros (Dolerite), Basalte oder Basanite einzuordnen (vgl. → melanokrates Gestein). Granite im petrographischen Sinn sind nie schwarz – sie zählen zu den hellen (leukokraten) Gesteinen.

Im Valle Maggia und im gesamten Tessin werden sehr häufig „Granit“ genannte Gesteine für Hausdächer, Pergolen, Straßenbegrenzungen, Tische und Bänke verwendet, die im petrographischen Sinne kein Granit sind. Es handelt sich um plattige Paragneise.

Weiterhin taucht der Begriff "Granit" mehrmals in Redewendungen auf. Es wird dabei vor allem auf seine Härte und Widerstandsfähigkeit verwiesen:

Granite entstehen durch die Kristallisation von Gesteinsschmelzen (Magma) innerhalb der Erdkruste, meistens in einer Tiefe von mehr als zwei Kilometern unter der Erdoberfläche. Im Gegensatz dazu stehen die vulkanischen Gesteine, bei denen das Magma bis an die Erdoberfläche dringt. Granit ist deshalb ein Tiefengestein (Fachausdruck: Plutonit). Gesteine, die sehr nahe der Erdoberfläche (weniger als zwei Kilometer) erstarren, nennt man hingegen Subvulkanite, Übergangsmagmatit oder Ganggestein, werden aber oft auch unter dem Begriff "Vulkanit" subsumiert. Die Schmelztemperatur von granitischen Magmen unter Atmosphärendruck liegt bei 960 °C, bei fluidreichen Magmen verringert sich die Schmelztemperatur auf bis zu 650 °C.

Granite entstehen in den meisten Fällen nicht aus Material des Erdmantels, sondern aus aufgeschmolzenem Material der unteren Erdkruste. Für die Entstehung von Magmakammern muss mit Zeiträumen von 10 bis 15 Millionen Jahren gerechnet werden.

Klassisch werden drei Granit-Typen nach Chapell und White (1974) unterschieden:
Okrusch und Matthes (2009) fügen noch einen vierten sog. M-Typ-Granit ("mantle source") hinzu. Es handelt sich hierbei um relativ selten vorkommende Restdifferentiate von Mantelschmelzen; diese können sowohl an ozeanischen Inselbögen als auch an Hotspots entstehen. Noch neuere Literatur führt auch noch einen C-Typ-Granit an ("charnockitic source").
Durch Isotopenverhältnisse in erster Linie von Strontium ist heute weitgehend die Herkunft und die Anteile der jeweiligen Stammmagmen aus Kruste und Mantel geklärt.

Tektonische Verwerfungen, die durch Bewegungen der Erdkruste entstehen, dienen den Magmen als leichte Aufstiegswege von der unteren in die obere Kruste. Man bezeichnet den Aufstieg bzw. die Platznahme derartiger Magmamassen nach oben als Intrusion. Dabei bilden sich in der Erdkruste große, oft riesige Magmenkörper. Sie erreichen beträchtliche Ausmaße von mehreren Kilometern bis hin zu mehreren 100 Kilometern Länge und Breite. Diese Körper nennt man Pluton, wenn sie, wie im Fall von Granit, sich relativ tief im Erdinneren ausbilden.

Durch tektonische Prozesse kann es zu einer Abschnürung der Magmenaufstiegswege kommen. Es entsteht dann eine isolierte Magmenkammer. Häufig bleiben aber auch die Aufstiegswege in Verbindung mit dem Intrusionskörper. Daneben tritt aber auch der Fall auf, dass Magmen beim Aufstieg aufgehalten werden, da sie durch die teilweise Aufschmelzung des umgebenden Gesteins Wärme abgeben. Häufig enthalten sie dann unaufgeschmolzene Mineralkörner oder Gesteinsfragmente aus dem Nebengestein.

Wie alle Plutonite erstarrt auch Granit sehr langsam in größeren Tiefen von mehreren Kilometern. Dabei kristallisieren die dunklen Minerale, die auch meistens eine hohe Dichte haben, wegen ihres höheren Schmelzpunktes zuerst. Diese schweren, frühen Kristallisate, wie Hornblende oder Pyroxen, sinken in der noch flüssigen Restschmelze ab und sammeln sich im unteren Bereich der auskühlenden Magmakammer. Quarz oder Kalifeldspat hingegen kristallisieren erst später aus oder sammeln sich wegen ihrer geringeren Dichte im oberen Bereich (Dachbereich) der Magmenkammer an. Diesen Prozess nennt man magmatische Differentiation.

Der Kontakt mit dem Nebengestein führte in den Randbereichen des Magmas zu „Verunreinigungen“ und zu einem rascheren Erkalten des Magmas. Häufig entstehen dabei besonders ausgefallene Gesteinsvarietäten und Minerale. Dieses trifft zum Beispiel auf den bläulichen "Kösseine-Granit" aus dem Fichtelgebirge zu, bei dem es durch Vermischung der Schmelze mit tonigem Nebengestein zur Bildung von feinen Mikroklin­kristallen kam, welche die bläuliche Einfärbung verursachen.

Weiterhin wird auch das Nebengestein durch die hohe Temperatur und durch die Materialzufuhr aus dem heißen Magma deutlich verändert und in ein metamorphes Gestein umgewandelt. Bekanntestes Beispiel sind die Hornfelse.

Durch weitere Bewegungen der Erdkruste und Abtragung des darüber befindlichen Gesteins gelangt dann der erstarrte Granit an die Erdoberfläche. Dabei kann sich der Granit durch tektonische oder hydrothermale Prozesse deutlich verändern. Mit dem Erreichen der Erdoberfläche setzt außerdem die Verwitterung und Abtragung des Granits selbst ein. Bei genügend langer Zeitdauer und warm-feuchtem Klima kann die Verwitterung mehr als 100 m in die Tiefe reichen. Dieser Prozess vollzieht sich in Zeiträumen von Zehntausenden von Jahren.

Im Allgemeinen ist Granit mittel- bis grobkörnig. Er besitzt eine homogene Mineralverteilung mit oft richtungsloser Textur und die daraus resultierende relativ gleichmäßige Optik. Die Struktur von Granit ist durch unmittelbaren Kornverband gekennzeichnet, die Größe der Kristalle schwankt meistens zwischen einem und mehreren Millimetern. Man kann für gewöhnlich alle Kristalle mit bloßem Auge erkennen. Neben gleichkörnigen Graniten, bei denen nahezu alle Kristalle dieselbe Größenklasse besitzen, gibt es auch sehr häufig ungleichkörnige oder porphyrische Granite. Dort sind einzelne Kristalle, meistens handelt es sich um Feldspäte, um ein mehrfaches größer als die Kristalle der Matrix. Ein bekannter porphyrischer Granittyp ist der Rapakiwi. 

Das Farbspektrum reicht bei Graniten von hellem Grau bis bläulich, rot und gelblich. Dabei spielen die Art der Erstarrung (Kristallisation) und Umwelteinflüsse, denen das Gestein ausgesetzt war, ebenso eine Rolle wie der Mineralgehalt. Die gelbe Farbe angewitterter Granite kommt von Eisenhydroxidverbindungen (Limonit), die infolge von Verwitterungseinflüssen aus primär im Granit enthaltenen Eisen führenden Mineralen entstanden sind.

Farbtabelle für Granite:
Granite bestehen hauptsächlich aus Quarz, Feldspäten und zu etwa 20–40 Massen-% aus dunklen, mafischen Mineralen. Bei den mafischen Mineralen handelt es sich vorwiegend um Biotit (Dunkelglimmer), seltener um Amphibole, Pyroxene oder andere. Bei den Feldspäten überwiegen die Alkalifeldspäte gegenüber den Plagioklasen. Zu den wesentlichen hellen Gesteinsbestandteilen des Granits zählt auch der Hellglimmer Muskovit. Als Akzessorien (Nebenbestandteile) führen Granite Zirkon, Apatit, Titanit, auch Magnetit, Rutil, Ilmenit oder andere Erzminerale, die zum Teil aus überprägten Zonen stammen können.

Mit dem Granit eng verwandt und in Plutonen oft mit diesem vergesellschaftet sind andere magmatische Tiefengesteine, die eine leicht abweichende chemische Zusammensetzung haben und zusammen mit dem Granit als Granitoide bezeichnet werden. Dazu gehören der Alkalifeldspatgranit (Plagioklas fehlt weitgehend bis vollständig), Granodiorit (Plagioklas überwiegt über Kalifeldspat) und der Diorit (Kalifeldspat fehlt weitgehend). Ebenfalls chemisch den Graniten sehr ähnlich und im Gefolge selbiger auftretend sind Pegmatite, die sich in erster Linie durch ihr riesenkörnige Gefüge von Granit unterscheiden und, da sie aus Restschmelzen hervorgehen, stark mit sogenannten inkompatiblen Elementen wie Lithium angereichert sind. Lange bei den Graniten eingeordnet wurde Charnockit, der sich durch einen relativ hohen Anteil an Orthopyroxenen auszeichnet. Jedoch sind zumindest ein Teil der Charnockite nicht magmatischen, sondern metamorphen Ursprunges.

Darüber hinaus ist Granit das entsprechende Tiefengestein zu den vulkanischen Gesteinen Rhyolith und Obsidian. Alle drei sind saure Gesteine, das heißt, sie besitzen einen hohen SiO-Gehalt. Sie unterscheiden sich nur durch ihre Kristallisationsgeschwindigkeit sowie, damit verbunden, das Gesteinsgefüge bzw. die chemische Struktur.

Granite gehören zu den häufigsten Gesteinen innerhalb der kontinentalen Erdkruste. Sie finden sich auf allen Kontinenten. Sie entstehen im Rahmen der Plattentektonik primär in Gebirgen oder an Subduktions­zonen: Die abtauchende (ozeanische) Platte führt auch sedimentäres Material mit sich, das nicht subduziert werden kann und den sogenannten Akkretionskeil bildet. Hier kann durch den hohen Wassergehalt granitisches Magma entstehen, das bei der Abkühlung im Erdinneren Granit bildet.


Granite findet man auch sehr häufig als eiszeitliches Geschiebe in den pleistozänen Tiefländern Mittel-, Nord- und Osteuropas.

Auf Grund ihres hohen Quarz- und Feldspatanteils sowie ihrer klimatisch eher ungünstigen Lage in den Mittelgebirgen, entstehen in Mitteleuropa aus Graniten im Allgemeinen nährstoffarme Böden, die außerdem zur Versauerung neigen. Je nach Wasserangebot und Entwicklungstiefe des Bodens findet man meistens Ranker oder Braunerden, seltener Podsole. Meistens werden diese Böden forstwirtschaftlich genutzt.

Bei der Verwitterung von Granit entsteht ein sandartiges Material, welches "Granitgrus" (auch "Granitgruß") genannt wird. Dieser eignet sich auch als Wegebaumaterial, Zuschlagsstoff für Kalkmörtel und kann im Erd- und Grundbau auch als Dichtung eingesetzt werden. Granitgrus gewann man beispielsweise lange Zeit aus den Vorkommen des Bergener Massivs im Vogtland und verwendete ihn in der Region als Wege-, Bau- und Scheuersand. Die Vergrusung tritt dort in einer Mächtigkeit von bis zu mehreren Metern auf.

Granite haben wegen ihrer hohen Widerstandskraft, Härte und Wetterfestigkeit und wegen ihrer guten Schleif- und Polierbarkeit eine große wirtschaftliche Bedeutung im Bauwesen, werden aber auch in speziellen Bereichen des Maschinenbaus, des Werkzeugbaus und für Messeinrichtungen eingesetzt. Sie finden sich:


Verwendet wird Granit seit alters her auch in der Steinbildhauerei. Da es sich im arbeitstechnischen Sinne um ein Hartgestein handelt und bei der Ausformung händische Techniken verwendet werden, die einen hohen körperlichen und technischen Aufwand fordern, sind Granit-Skulpturen seltener als solche aus Weichgestein.

Nachfolgend ist ein typisches Anforderungsprofil technischer Werte mit europäischen Prüfungnormen für belastete Bereiche aufgeführt:

Grobkörnige Granite haben schlechtere Druck- und Biegezugwerte als die fein- bis mittelkörnigen. Eingelagerte Minerale können zu Verfärbungen führen.

In den gelb gefärbten Graniten hat sich Hämatit zu Limonit verwandelt. Dieser Prozess hat sich in der Natur über Zehntausende von Jahren oberflächennah vollzogen und kann sich bei falschem Mörteleinsatz innerhalb kurzer Zeiträume vollziehen. Es kann durchaus sein, dass sich zudem die Gelbfärbung der Granite durch eine Umwandlung des Feldspats und Biotits punktuell vollzogen hat.

Granit wird in vielen Natursteinsorten vertrieben, darunter

Im Zuge der magmatischen Differenziation erfolgt in der Schmelze eine Anreicherung mit radioaktiven Elementen, insbesondere mit Uran und Thorium. Daher weisen saure Magmatite wie Granit und Rhyolith einen generell höheren Anteil solcher Elemente auf als basische Magmatite. Uran und Thorium sind hierbei vor allem in akzessorischen schwach radioaktiven Mineralen wie Zirkon, Titanit und Apatit enthalten. Zudem besitzen Granitoide einen höheren Anteil an Kaliumfeldspäten (Orthoklas, Mikroklin) als mafische Magmatite, und ein geringer Anteil des Kaliums in diesen Feldspäten liegt in Form des radioaktiven Isotops Kalium-40 vor. Auch der in Graniten üblicherweise enthaltene Hellglimmer Muskovit enthält viel Kalium. Durch den relativ hohen Uran-, Thorium-, und Kaliumgehalt gehören Granitoide zu den am stärksten strahlenden Gesteinen überhaupt.

Die Gesundheitsgefährdung durch die Strahlenbelastung, welche von Granitplatten im Haushalt beziehungsweise dem aus diesen entweichenden Zerfallsprodukt Radon ausgeht, ist gegenüber der natürlichen Hintergrundstrahlung oder anderen Strahlenquellen, beispielsweise Röntgentechnik, vernachlässigbar. David J. Brenner, Direktor des Zentrum für Radiologie Forschung an der Columbia University in New York, schätzt, dass die Gefahr einer Krebserkrankung aufgrund der Strahlenbelastung durch Granitplatten im Haushalt (selbst wenn diese sehr stark angereichert sind) im Bereich eins zu einer Million liegt.

Besonderheiten sind auch die „polsterartige“ Verwitterung (Wollsackverwitterung) und die dabei unter begünstigenden Bedingungen auftretende moosüberwachsene Oberfläche, der beim weiteren Zerfall bodenbildende Grus (kleinkörnige Zerfallsprodukte des Gesteins), die Entstehung von Blockheiden und Hochmooren.

Landschaftsformen dieser Art sind mitunter Gegenstand einer touristischen Vermarktung in „mystischen Projekten“ und Seminaren, frühere Hexen­geschichten und viele Wackelsteine, an denen man seine Kräfte messen kann. Aus verwittertem Granit entstehen neben anderen Gesteinen Kaolin und Quarzgrus. Am Monte Kaolino in der Oberpfalz ist der „Restquarz“ zu einem Eventhügel aufgetürmt. Andere Verwitterungsprodukte sind unter anderem Tonminerale.




</doc>
<doc id="2090" url="https://de.wikipedia.org/wiki?curid=2090" title="Globalisierungskritik">
Globalisierungskritik

Globalisierungskritik bezeichnet die kritische Auseinandersetzung mit den ökonomischen, sozialen, kulturellen und ökologischen Auswirkungen der Globalisierung. 

Träger der Globalisierungskritik sind eine Vielzahl unterschiedlicher Nichtregierungsorganisationen (NGOs) wie beispielsweise das Netzwerk attac, freie Träger aller Art und Einzelpersonen wie Arundhati Roy, Jean Ziegler oder Naomi Klein. Die Positionen, die Globalisierung vollständig ablehnen und die globale Verflechtung reduzieren wollen, werden als Globalisierungsgegner bezeichnet. Davon zu unterscheiden ist eine Globalisierungskritik im engeren Sinn, die sich beispielsweise gegen den Neoliberalismus richtet und für eine "andere Globalisierung" eintritt (daher auch französisch altermondialisation und englisch "alter-globalization" von "alter" = anders). Im allgemeinen Sprachgebrauch und auch in den Medien werden die Globalisierungskritiker teilweise unzutreffend als Globalisierungsgegner bezeichnet.

Im Zentrum der Kritik stehen die Deregulierung und der damit verbundene Abbau sozialer Rechte sowie die allumfassende Kommerzialisierung und Vermarktung (Kommodifizierung) durch „Privatisierung öffentlicher Unternehmen, Umbau der Sozialhilfe oder ‚Inwertsetzung’ von menschlicher und außermenschlicher Natur“. Ein Schwerpunkt der Kritik solle sich damit gegen eine Wirtschaftsordnung richten, die mit dem mehrdeutigen Kampfbegriff „neoliberal“ bezeichnet wird und die von Organisationen wie Weltbank und Welthandelsorganisation weltweit gefördert werde.

Die Globalisierungskritik wurzelt in älteren Strömungen wie Kapitalismuskritik und Befreiungstheologie; sie übernimmt und entwickelt deren Gedankengut weiter; sie ist eine aktuelle Ausprägung von diesen.

Gegen Ende der 1990er Jahre hat sich die Globalisierungskritik in verschiedenen Bewegungen entwickelt. In vielen ehemaligen Kolonien betrachten verschiedene soziale Bewegungen die Kämpfe gegen die globalen Abkommen und Institutionen als Fortsetzung der Kämpfe gegen die Kolonialherren (vgl. Neokolonialismus).

In Lateinamerika bezog sich der Aufstand der Zapatistas im Januar 1994 direkt auf das Inkrafttreten des Nordamerikanischen Freihandelsabkommens (NAFTA). Die Zapatistas organisierten mit den sogenannten intergalaktischen Encuentros (Zusammenkünften) auch die ersten globalen Vernetzungstreffen. Es kam zu einem Aufstand in Chiapas, der schnell weite Gebiete des Bundesstaats erfasste. Der Versuch, den Kampf gegen den „Neoliberalismus“ zu popularisieren, blieb zu diesem Zeitpunkt weitgehend auf eine kleine Gruppe politischer Weggefährten aus dem europäischen und US-amerikanischen Studentenmilieu beschränkt.

Erst mit dem Entwurf des Multilateralen Investitionsschutzabkommens (MAI) im Jahr 1997, das weitgehende Rechte für transnationale Konzerne vorsah, weitete sich der Protest auf eine breitere internationale Öffentlichkeit aus. Nichtregierungsorganisationen in Kanada, den USA, Frankreich und einigen asiatischen Ländern kritisierten den Entwurf heftig. Vor allem die französische Kulturindustrie fühlte sich vom „MAI“ bedroht, da sie der freie Marktzugang der Konkurrenz von Hollywoodproduktionen ausgesetzt hätte. Mit dem Ausstieg der französischen Regierung unter Ministerpräsident Lionel Jospin war dieses Projekt gescheitert.

Die OECD-Staaten und führende Vertreter der Wirtschaft kündigten bald nach dem Scheitern an, dass sie einen neuen institutionellen Rahmen für das Investitionsabkommen finden wollten, um für transnationale Konzerne und Auslandsinvestitionen eine größtmögliche Rechtssicherheit garantieren zu können. Diese Ankündigung und die ab Juli 1997 aufkommende Asienkrise schärften die kritische Wahrnehmung der „neoliberalen Weltwirtschaft“ nochmals. So publizierte u. a. der Chefredakteur von "Le Monde diplomatique", Ignacio Ramonet, im Dezember 1997 den Leitartikel „Désarmer les marchés“ – die Märkte entwaffnen, der die Bewegung "Attac" ins Leben rief.

Ein einschneidendes Ereignis in der globalisierungskritischen Bewegung stellte der Abbruch der 3. WTO-Konferenz in Seattle im Dezember 1999 dar, nach dem es zu gewalttätigen Auseinandersetzungen zwischen Globalisierungskritikern und der Polizei kam. Nach Seattle entwickelte sich die globalisierungskritische Bewegung auch in den Metropolen und erfuhr eine weltweite Verbreitung.

Auf dem Europäischen Kontinent waren die Proteste gegen die Sitzung von Weltbank und internationalem Währungsfonds am 26. September 2000 in Prag wichtig für die weitere Mobilisierung. Die ca. 15.000 Globalisierungskritiker zogen in drei farbig gekennzeichneten Demonstrationen in Richtung Tagungsgebäude: ein gelber Zug (Tute Bianche u. a.), ein blauer Zug (Autonome u. a.), und Pink & Silver (Rhythms of Resistance u. a.).

Beim EU-Gipfel in Göteborg 2001 demonstrierten am 14. Juni 2001 mehr als 20.000 Globalisierungskritiker unter dem Motto „Bush not welcome“. Es kam zur Eskalation von Gewalt. Ein Polizist gab mehrere Schüsse auf Demonstranten ab, neben zwei Beintreffern wurde eine Person durch einen Bauchschuss lebensgefährlich verletzt.

Wenige Wochen später, beim G8-Gipfel in Genua 2001 kam es zu schweren Auseinandersetzungen zwischen der italienischen Polizei und Demonstranten. Die italienische Regierung hatte für die Zeit des Gipfels das Schengener Abkommen außer Kraft gesetzt und ließ sämtliche Grenzen lückenlos überwachen. In Genua selbst wurden 20.000 Polizisten und Carabinieri zusammengezogen. Medien und einige Politiker warnten vor „"bürgerkriegsähnlichen Zuständen"“. Es kam zu schweren Übergriffen und Menschenrechtsverletzungen der Exekutive gegen Demonstranten. Hunderte Demonstranten wurden verletzt. Als der italienische Aktivist Carlo Giuliani mit anderen ein Polizeifahrzeug attackierte, wurde er von einem der Polizisten erschossen und mit dem Geländewagen zweimal überrollt. Nach Schätzungen nahmen zwischen 70.000 und 250.000 Globalisierungskritiker an den Protesten teil.

In Europa und Nordamerika lässt sich die globalisierungskritische Bewegung auf verschiedene Teile der Neuen Sozialen Bewegungen, insbesondere der Dritte-Welt-/Eine-Welt-Bewegung, und der Gewerkschaften zurückführen. Aufmerksamkeit erzielten die Proteste durch neue Aktionsformen, die von Gruppen wie Reclaim the Streets in Großbritannien und das Direct Action Network in Seattle inspiriert wurden. In den Niederlanden formte sich Ende der 1960er Jahre eine „Antiglobalisierungsbewegung“ u. a. gegen den Vertrag von Amsterdam. Dazu entstand 1967 das Kollektiv Eurodusnie, das bis heute besteht.

NGOs spielen eine tragende Rolle in der globalisierungskritischen Bewegung. Sie organisieren regelmäßig Gegen- und Alternativkongresse und nutzen die modernen Kommunikationstechnologien, um ihre Publikationen einer kritischen Öffentlichkeit zuzuführen. NGOs arbeiten in zahlreichen Netzwerken zu unterschiedlichen Schwerpunkten. Viele NGOs favorisieren die UNO als Institution für ihre Konzepte von „Global Governance“. In Europa setzen sie auf die Europäische Union. Kritiker werfen den NGOs vor, sie konzentrierten sich primär auf Lobbyismus. Je größer die finanzielle Abhängigkeit von supranationalen Institutionen, Regierungen oder Konzernen, so die vielgeäußerte Kritik des radikalen Flügels der Bewegung, umso lauter propagierten die NGOs die Reformierbarkeit der kapitalistischen Weltwirtschaftsordnung.

In Gebieten mit indigenen Völkern schließen diese sich häufig den Kampagnen der NGOs an, sofern sie nicht selbst dazu in der Lage sind. Die indigene Kritik an der westlichen Zivilisation, Kolonialisierung und Globalisierung ist seit Jahrhunderten aktuell.

Seit den Ereignissen von Seattle mobilisieren zunehmend auch die Gewerkschaften gegen Treffen internationaler Institutionen. In Europa beteiligten sie sich erstmals im großen Stil an den Protesten gegen die EU-Regierungsgipfel in Nizza und Brüssel. Dort organisierten die Gewerkschaften jeweils eigenständige Demonstrationen. In beiden Fällen ging die große Beteiligung auf die Mobilisierungsfähigkeit der französischen "CGT" zurück.

International sind es vor allem einige Gewerkschaftsverbände aus Schwellenländern, die sich an die Seite der neuen Bewegung stellen. Dazu gehört die brasilianische "CUT" und die südkoreanische "KCTU", die erst im Jahre 1999 legalisiert worden ist. In Europa waren unabhängige und linksgewerkschaftliche Organisationen die treibenden Kräfte, wie zum Beispiel die italienischen "SinCobas" und die französischen "SUD"-Gewerkschaften, die seit den Europäischen Märschen gegen Erwerbslosigkeit 1997 anlässlich des EU-Gipfels in Amsterdam eine offensive Politik über den nationalstaatlichen Rahmen hinaus praktizieren.

In dem vom Gründungskongress 2006 angenommenen Programm des Internationalen Gewerkschaftsbundes (IGB) enthält der erste Abschnitt unter der Überschrift "Die Globalisierung verändern" die Kritik und Alternativvorstellungen des IGB. Der 2. IGB-Weltkongress (2010) verabschiedete eine umfassendere Entschließung zu diesem Thema.

Neben Gewerkschaften und NGOs haben sich innerhalb der globalisierungskritischen Bewegung verschiedene internationale Netzwerke herausgebildet. Das in Europa bekannteste ist Attac. Die von Ignacio Ramonet in seinem Leitartikel in "Le Monde Diplomatique" lancierte Idee war, auf weltweiter Ebene eine NGO ins Leben zu rufen, die Druck auf die Regierungen machen sollte, um eine internationale „Solidaritätssteuer“, genannt „Tobin-Steuer“, einzuführen. Gemeint war damit die durch den US-amerikanischen Ökonomen James Tobin Ende der 70er Jahre vorgeschlagene Steuer in Höhe von 0,1 % auf internationale Kapitalflüsse. Der von Ramonet gleichzeitig vorgeschlagene Name dieser Organisation „Attac“ sollte, aufgrund seiner sprachlichen Nähe zum französischen Wort "attaque", zugleich den Übergang zur „Gegenattacke“ signalisieren, nach Jahren der Anpassung an die Globalisierung.

In Frankreich fiel dieser Appell der in fortschrittlichen Kreisen einflussreichen Zeitung auf fruchtbaren Boden. Schon die große Streikwelle Mitte der 1990er Jahre hatte das kritische Bewusstsein vieler Franzosen gegenüber dem Neoliberalismus geschärft, dessen internationale Dimension durch die Asienkrise Ende 1997 nochmals verdeutlicht wurde.

Die Aktivitäten von Attac weiteten sich schnell über den Bereich der Tobinsteuer und die „demokratische Kontrolle der Finanzmärkte“ hinaus aus. Mittlerweile umfasst der Tätigkeitsbereich von Attac auch die Handelspolitik der WTO, die Verschuldung der Dritten Welt und die Privatisierung der staatlichen Sozialversicherungen und öffentlichen Dienste. Die Organisation ist inzwischen in einer Reihe von afrikanischen, europäischen und lateinamerikanischen Ländern präsent.

In Deutschland hatten im Jahre 2000 mehrere NGOs, darunter Weltwirtschaft, Ökologie und Entwicklung (WEED), die Initiative für "Attac-Deutschland" ergriffen.

Attac ist in mehr als 30 Ländern aktiv und hatte Ende 2016 rund 90.000 Mitglieder – davon 29.000 in Deutschland.

Ein zweites weltweites Netzwerk neben Attac ist Peoples Global Action (PGA). Bei PGA arbeiten in Europa vor allem Gruppen mit, die sich am Politikverständnis der mexikanischen Zapatisten orientieren. Das im Februar 1998 in Genf gegründete Netzwerk lehnt jede Art von Lobbyarbeit ab und veranstaltet stattdessen regelmäßig globale „action days“. Die größte ihr zugehörige Organisation ist die indische Bauernorganisation "KRRS", der nach eigenen Angaben etwa zehn Millionen Mitglieder angehören. Das Netzwerk macht v. a. durch originelle Aktionen auf sich aufmerksam. Es setzt auf die Prinzipien der Spontanität, Selbstverwaltung und Konfrontation. Im Gegensatz zu Attac gibt es keine formelle Mitgliedschaft von Einzelpersonen. Jeder Kontinent muss allerdings eine verantwortliche Gruppe stellen, die für die internationale Koordinierung der Aktionstage delegiert ist und die internationalen Konferenzen mit vorbereitet.

Der internationale Bauernverband Via Campesina spielt vor allem in den Ländern des Südens eine tragende Rolle. In Europa ist der Franzose José Bové mit seinen Aktionen gegen Freihandel und McDonald’s bekannt geworden. Aus Lateinamerika genießt vor allem die brasilianische Landlosenbewegung MST durch ihre spektakulären Landbesetzungen einen gewissen Bekanntheitsgrad. Via Campesina konzentriert sich auf Agrarpolitik, grüne Gentechnologie und Patentrecht.
In seinem Blickfeld steht v. a. die Politik der WTO. Die Bauernorganisation tritt für Ernährungssouveränität ein, also gegen eine Exportorientierung in der Landwirtschaft und für die Ernährungssicherheit der Regionen. Das bedeutet, dass jede Region der Welt in der Lage sein sollte, die dort lebende Bevölkerung mit heimischen Agrarprodukten zu ernähren.

In Deutschland sind das Dissent!-Netzwerk, die Interventionistische Linke und die Bundeskoordination Internationalismus (BUKO) zu erwähnen.

Diese unterschiedlichen Netzwerke und Organisationen trafen im Januar 2001 erstmals zum Weltsozialforum in Porto Alegre (Brasilien) zusammen – zeitgleich zu dem seit 1971 stattfindenden Weltwirtschaftsforum von Konzernmanagern und Wirtschaftspolitikern in Davos. Insgesamt waren in Porto Alegre 117 Länder vertreten, mit mehr als 10.000 Teilnehmenden. Neben zahlreichen NGOs und Basisbewegungen waren auch 400 Parlamentarier anwesend. Porto Alegre galt als Modellprojekt für das Motto der Konferenz: „Eine andere Welt ist möglich“, da die brasilianische Arbeiterpartei ("PT") dort den „Beteiligungshaushalt“ eingeführt hatte, der für mindestens 20 % des Budgets der Stadt plebiszitäre Elemente vorsah.

Als Folge dieses Gegengipfels entstanden weitere Sozialforen, zunächst auf kontinentaler Ebene (Europäisches Sozialforum), später auch auf regionaler und lokaler Ebene. Die Bewegung gilt als inhaltlich vielfältig. Die Schwerpunkte liegen auf einer "sozial gerechten Globalisierung" sowie bei "Menschenrechten" (insbes. „Frauenrechten“) und ökologischen Themen.

Eng verknüpft mit den kirchlichen Akteuren in den Sozialforen ist auch der Ökumenische Rat der Kirchen (ÖRK), der auf seinen Vollversammlungen ebenfalls Kapitalismuskritik äußert.

Der Politikwissenschaftler Claus Leggewie unterscheidet fünf Typen der Globalisierungskritik:

Kritiker der Globalisierung sehen in der Aufspaltung des Finanzkapitals durch attac in „gutes“ (produktives) und „schlechtes“ (unproduktives) Kapital eine Methode, den Kapitalismus in einer Ausprägung zu kritisieren, ohne ihn an und für sich zu verwerfen. Nicht der Kapitalismus sei der Auswuchs, sondern der Neoliberalismus.

Gegen die Fokussierung der Globalisierungskritik auf die ökonomische Dimension spricht sich unter anderem der deutsche Soziologe Ulrich Beck aus, der diese Betrachtungsweise als „Globalismus“ bezeichnet und kritisiert.

Marchart kritisiert die Globalisierungskritiker, dass sie nicht weit genug gehen, sondern im ökonomischen Denken stecken bleiben. Er begründet dies damit, dass die Globalisierungskritiker keinen neuen Anfang im Sinne von Hannah Arendt machen. Sie beruft sich dabei auf Augustinus: „Damit ein Anfang sei, wurde der Mensch geschaffen, vor dem es niemand gab.“ (Marchart, S. 31) Wenn Globalisierungskritik in einem Raum der Alternativlosigkeit stattfindet wie die neoliberale Margaret Thatcher es in ihrem Ausspruch – „There is no alternative“ – klar ausdrückt, „dann könnte es nur um Fragen der entweder effizienteren oder etwas gerechteren "Verwaltung" gehen – letztlich um ein besseres Globalisierungsmanagement.“ (S. 95) Damit befindet man sich in einem Diskurs der sich im alten, vergangenen Rahmen bewegt, der jedoch völlig apolitisch im Sinne von Arendt ist. Politik muss nicht nur den vermeintlichen Notwendigkeiten folgen, sondern kreativ im „Reich der Freiheit“ (siehe Ethik Immanuel Kants) denken, das auf einem neuen und damit völlig unbekannten "Anfang" beruht.








</doc>
<doc id="2092" url="https://de.wikipedia.org/wiki?curid=2092" title="Granatgruppe">
Granatgruppe

Die Granatgruppe (kurz Granate) ist eine wichtige Gruppe gesteinsbildender Minerale aus der Abteilung der Inselsilikate (Nesosilikate).

Die allgemeine Granatformel lautet: XY[ZO] oder auch AB[RO], wobei 'X', 'Y' und 'Z' bzw. 'A', 'B' und 'R' allerdings keine chemischen Elemente vertreten, sondern definierte Plätze im Kristallgitter darstellen. Die jeweiligen Gitterplätze können dabei von verschiedenen Ionen besetzt werden:


Innerhalb der Granatobergruppe, zu der alle Minerale gezählt werden, die mit der Granatstruktur kristallisieren, auch solche aus anderen Mineralklassen (z. B. Halogenide, Hydroxide), fasst die Granatgruppe alle Minerale mit 12 positiven Ladungen pro Formeleinheit auf der Z-Position zusammen. Aktuell (2013) sind das nur Silikate.

Die Granat-Minerale kristallisieren meist im kubischen Kristallsystem und bilden überwiegend isometrische Kristalle mit den charakteristischen Formen des Rhombendodekaeders (veraltet auch "Granatoeder"), Ikositetraeders sowie deren Kombinationen.

Granate sind im Allgemeinen durchsichtig bis durchscheinend, bei vielen Fremdbeimengungen und in derben Mineral-Aggregaten auch undurchsichtig. Unverletzte bzw. unverwitterte Kristallflächen weisen einen glas- bis fettähnlichen Glanz auf. Die Farbe der Granate ist sehr variabel, auch wenn rötliche Farbvarietäten überwiegen. Die Palette reicht von einem hellen Grün über Gelbgrün bis Dunkelgrün, Hellgelb über Gelborange und Orangerot sowie von einem hellen Rosa bis zu einem fast schwarz wirkenden Dunkelrot. Seltener finden sich farblose und braune Varietäten und sehr selten auch farbwechselnde (Changierende) und blaue Granate. Die Strichfarbe ist allerdings immer weiß.

Ihre relativ hohe Dichte (3,5 bis 4,5 g/cm), Mohshärte (6,5 bis 7,5) und Lichtbrechung (n = 1,61 (Katoit) bis n = 1,96 (Calderit)) machen sie sowohl als Schmuckstein als auch für industrielle Anwendungen interessant.

Die Bezeichnung Granat wurde erst im Mittelalter geprägt, hat aber ihren Ursprung im lateinischen Wort "granum" für Korn oder Kern bzw. "granatus" für körnig oder kernreich und bezieht sich einerseits auf das Vorkommen des Minerals in Körnern, welche Ähnlichkeit mit den Kernen des Granatapfels ("Punica granatum") haben, andererseits aber auch auf die orangerote bis rotviolette Farbe von Blüte, Frucht und Kernen des Granatapfels.

Schon in der Antike wurden Granate als Schmucksteine genutzt. Im Mittelalter waren sie zusammen mit Rubinen und Spinellen unter der Bezeichnung "Karfunkel" (auch "Karfunkelstein") bekannt – die meisten stammten damals aus Indien. Besonders populär waren sie aber im 19. Jahrhundert, als böhmische Pyrope so begehrt waren, dass sie bis nach Amerika verschifft wurden.

In der mittlerweile veralteten, aber noch gebräuchlichen 8. Auflage der Mineralsystematik nach Strunz gehörte die Granatgruppe zur allgemeinen Abteilung der „Inselsilikate (Nesosilikate)“, trägt die System-Nr. "VIII/A.08" und bestand aus den Mitgliedern Almandin, Andradit, Calderit, Goldmanit, Grossular, Henritermierit, Hibschit, Holtstamit, "Hydrougrandit" (diskreditiert 1967 als unnötiger Gruppenname), Katoit, Kimzeyit, Knorringit, Majorit, Morimotoit, Pyrop, Schorlomit, Spessartin, Uwarowit, Wadalit und "Yamatoit" (diskreditiert, da identisch mit Momoiit).

Die seit 2001 gültige 9. Auflage der Strunz’schen Mineralsystematik ordnet die Granatgruppe ebenfalls in die Abteilung der „Inselsilikate“ ein. Diese ist allerdings weiter unterteilt nach der möglichen Anwesenheit weiterer Anionen und der Koordination der beteiligten Kationen, so dass die Granatgruppe mit der System-Nr. "9.AD.25" entsprechend der Zusammensetzung der Mitglieder Almandin, Andradit, Blythit, Calderit, Goldmanit, Grossular, Henritermierit, Hibschit, Holtstamit, Hydroandradit, Katoit, Kimzeyit, Knorringit, Majorit, Momoiit ("IMA 2009-026"), Morimotoit, Pyrop, Schorlomit, Spessartin, Skiagit, Uwarowit und Wadalit in der Unterabteilung „Inselsilikate ohne weitere Anionen; Kationen in oktahedraler [6] und gewöhnlich größerer Koordination“ zu finden ist.

Auch die vorwiegend im englischen Sprachraum gebräuchliche Systematik der Minerale nach Dana ordnet die Granatgruppe in die Abteilung der „Inselsilikatminerale“ ein. Hier ist sie allerdings unterteilt in die Untergruppen „Pyralspit-Reihe“ (System-Nr. "51.04.03a"), „Ugrandit-Reihe“ (System-Nr. "51.04.03b"), „Schorlomit-Kimzeyit-Reihe“ (System-Nr. "51.04.03c"), „Hydrogranate“ (System-Nr. "51.04.03d") und „Tetragonale Hydrogranate“ (System-Nr. "51.04.04") innerhalb der Unterabteilung „“ zu finden.

Die zuvor aufgeführten, klassischen Klassifikationen, legen die die Obergruppen (Klassen) anhand der Zusammensetzung fest und unterteilen diese nach strukturellen Kriterien.

Die aktuelle Klassifikation der Granate, die von der International Mineralogical Association (IMA) 2013 erarbeitet wurde, geht umgekehrt vor. Sie definiert die Granatobergruppe anhand des Strukturtyps und unterteilt diese nach chemischen Gesichtspunkten, der Kationenladung auf der tetraedrisch koordinierten Z-Position, in 5 Gruppen und 3 Einzelminerale.

Die Klassifikation der IMA nimmt keine weitere Aufgliederung der Granate in Untergruppen vor. In älterer Literatur findet sich eine Unterteilung anhand von verbreiteten Mischkristallreihen in zwei wesentliche Gruppen/Reihen:

Pyralspit-Gruppe:

Ugrandit-Gruppe:

Weitere Namen von Mischkristallzusammensetzungen, hypothetischen Zusammensetzungen oder synthetischen Verbindungen:


Granate kommen in massiver Form oder körnig, häufig aber auch als makroskopische Kristalle vor, die bis zu 700 kg schwer werden können.

Besonders häufig findet man Granate in metamorphen Gesteinen wie Gneis, Glimmerschiefer oder Eklogit; daneben treten sie auch in magmatischen Gesteinen und sedimentär in Schwermineralseifen (Strandsedimente, Flusssedimenten) auf. Die meisten natürlich gefundenen Schmuckstein-Granate stammen heute aus den USA, aus Südafrika und Sri Lanka.

Die genaue chemische Zusammensetzung steht immer mit jener des umgebenden Gesteins im Zusammenhang: So kommt beispielsweise der magnesiumreiche Pyrop häufig in Peridotiten und Serpentiniten vor, während grüner Uwarowit vor allem in chromhaltigem Serpentinitgestein auftritt.

Bei der Metamorphose von silikatischen Peliten bilden sich almandinreiche Granate ab ca. 450 °C bei der Reaktion von Chloritoid + Biotit + HO zu Granat + Chlorit. Bei niedrigen Temperaturen sind die Granatmischkristalle reich an Spessartin und werden bei steigenden Temperaturen zunehmend almandinhaltiger. Ab ca. 600 °C bildet sich Granat beim Abbau von Staurolith. Bei weiter steigenden Temperaturen werden die Granate zunehmend reicher an Pyrop und selbst bei beginnender Gesteinsschmelze können Granate noch neu gebildet werden z. B. bei der Reaktion von Biotit + Sillimanit + Plagioklas + Quarz zu Granat + Kalifeldspat + Schmelze. Erst ab Temperaturen von 900 °C baut sich Granat ab zu Spinell + Quarz oder bei hohen Drucken zu Orthopyroxen + Sillimanit.

In der Suite der Metabasite (z. B. metamorphe Basalte) tritt Granat gesteinsbildend in Eklogiten auf und die Granatmischkristalle sind reich an Pyrop und Grossular.

Mit steigenden Druck bildet sich Granat beim Übergang von der Granulit-Fazies zur Eklogit-Fazies ab ca. 10kBar, 900 °C bei der Reaktion von Orthopyroxen und Plagioklas zu Granat, Klinopyroxen und Quarz.
In Blauschiefern bilden sich zunächst Fe-reiche Granate, die auf dem Weg zur Eklogit-Fazies zunehmend Pyrop- und Grossular-reicher werden.

Granate erleiden unter bestimmten lithofaziellen Umständen innerhalb von metamorphen Gesteinen eine Umwandlung bzw. Zersetzung. Das Ergebnis dieser Prozesse nennt man Kelyphit. Dabei entstehen zahlreiche neue Mineralien.

Granate kristallisieren im Allgemeinen mit kubischer Symmetrie in der . Die Elementarzelle enthält 8 Formeleinheiten und hat je nach Zusammensetzung eine Kantenlänge von 1.146 nm (Pyrop) bis 1.256 nm (Katoit).

O-Anion

Die Sauerstoffanionen besetzen die allgemeine Gitterposition 96h mit der Punktsymmetrie . Jedes O-Anion ist dort von 4 Kationen umgeben:


Die Sauerstoffionen bilden nicht, wie bei anderen Oxidstrukturen mit hoher Dichte, eine dichteste Kugelpackung. Große 8-fach koordinierte Ionen würden in einer kubisch oder hexagonal dichtesten Sauerstoff-Kugelpackung keinen Platz finden. Aufgrund der komplexen Verknüpfung aller Koordinationspolyeder über gemeinsame Ecken und vor allem viele gemeinsame Kanten erreicht die Granatstruktur dennoch eine hohe Dichte.

Die Kationen besetzten je nach Größe und Ladung drei verschiedene, spezielle Gitterpositionen, wo sie von 4, 6 oder 8 Sauerstoffionen umgeben sind.
ZO-Tetraeder

Die Z-Kationen (Si) sitzen auf der Gitterposition 24d mit der Punktsymmetrie , wo sie von 4 Sauerstoffionen umgeben sind, die an den Ecken eines Tetraeders liegen.

Die ermittelten Z-O-Bindungslängen liegen zwischen 0,163 nm (Pyrop, Almandin) und 0,165 nm (Goldmanit). Die ZO- Koordinationstetraeder haben zwei Paare unterschiedlich langer Kanten:

YO-Oktaeder

Die Y-Kationen sitzen auf der Gitterposition 16a mit der Punktsymmetrie , wo sie von 6 Sauerstoffionen umgeben sind, die an den Ecken eines Oktaeders liegen.
Die ermittelten Y-O- Bindungslängen liegen zwischen 0,19 nm (Pyrop) und 0,20 nm (Andradit). Der GO-Koordinationspolyeder hat zwei verschiedene Kanten:

XO-Dodekaeder

Die X-Kationen sitzen auf der Gitterposition 24c mit der Punktsymmetrie 222, wo sie von 8 Sauerstoffionen umgeben sind, die an den Ecken eines Dodekaeders (Trigondodekaeder) liegen.
Die ermittelten X-O- Bindungslängen liegen zwischen 0,22 nm (Pyrop) und 0,25 nm (Andradit, Glodmanit). Der XO-Koordinationspolyeder hat 4 verschiedene Kanten:

Verknüpfung der Koordinationspolyeder
Die ZO-Tetraeder und YO-Oktaeder sind über gemeinsame Sauerstoffatome an ihren Ecken zu einem Gerüst aus alternierenden Tetraedern und Oktaedern verbunden. Granate sind Inselsilikate und ihre ZO-Tetraeder sind untereinander nicht direkt verbunden.

Die XO-Dodekaeder sind über gemeinsame Kanten zu 3er-Ringen verknüpft, deren Ebene senkrecht zur Raumdiagonale der Elementarzelle liegt. Diese XO-Dodekaederringe sind untereinander so zu einem Gerüst verknüpft, dass jeder Dodekaeder zu zwei solchen Ringen gehört. Über weitere Kannten sind die Dodekaeder mit den Tetraedern und Oktaedern des ZO-YO-Gerüstes verbunden, dessen Zwischenräume es ausfüllt.

Insbesondere Grossular-Andradit-Mischkristalle sind schwach doppelbrechend und optisch zweiachsig. Auch bei Almandin wurde optische Anisotropie beobachtet. Die optischen Eigenschaften sind sehr sensible Indikatoren für Abweichungen von der idealen, kubischen Struktur. Bei Röntgenstrukturuntersuchungen von Granaten konnten sie hingegen nur selten nachgewiesen werden. Einige Arbeiten ergeben für solche Granate trikline (Raumgruppe ) oder ortorhombische (Raumgruppe ), aber auch tetragonale (Raumgruppe ) oder monokline (Raumgruppe ) Symmetrie. Als Ursachen dieser Symmetrieerniedrigung werden zahlreiche Ursachen angeführt:


Granat wird wegen seiner Härte auch als Schleifmittel beim Sandstrahlen und Wasserstrahlschneiden eingesetzt.

Insbesondere künstlich erzeugte Kristalle mit Granatstruktur werden in feinmechanischen und optischen Instrumenten eingesetzt. Im Gegensatz zu den natürlichen Mineralien werden hier auf dem Tetraeder-Platz statt Silicium oftmals andere Elemente eingebaut. Yttrium-Aluminium-Granat (YAG, YAl[Al O]), bei dem etwa ein Prozent der Yttrium-Ionen durch Neodym-Ionen ersetzt wird, ist ein häufig eingesetzter Laserkristall (). Der gelbe Lumineszenzkonverter der weißen LEDs ist zu Beginn der Entwicklung ein Cer-dotierter YAG gewesen. Yttrium-Eisen-Granat (YIG) und Verwandte werden als Mikrowellenferrit, Resonator oder als YIG-Filter in der Hochfrequenztechnik eingesetzt.

Granate finden in verschiedenen Varianten als Schmucksteine Verwendung. Man unterscheidet unter anderem den dunkelroten Pyrop, der auch Kaprubin genannt wird, den rotschwarzen Almandin, den smaragdgrünen Uwarowit, den gelbgrünen Andradit, den schwarzen Schorlomit und Melanit, den transparent-grünlichen Demantoid und den orangeroten Spessartin. Daneben gibt es noch Grossular. Außerdem gibt es seit einigen Jahren eine neue Variante, den orangefarbenen Mandaringranat.
Granate werden auch als Edelsteine des kleinen Mannes bezeichnet.


Monographien

In Kompendien

Wissenschaftliche Fachartikel



</doc>
<doc id="2093" url="https://de.wikipedia.org/wiki?curid=2093" title="Gammastrahlung">
Gammastrahlung

<onlyinclude>
Gammastrahlung – auch ​ɣ-Strahlung geschrieben – im "engeren" Sinne ist eine besonders durchdringende elektromagnetische Strahlung, die bei spontanen Umwandlungen („Zerfall“) der Atomkerne vieler natürlich vorkommender oder künstlich erzeugter radioaktiver Nuklide entsteht.

Der Name stammt von der Einteilung der ionisierenden Strahlen aus radioaktivem Zerfall in Alphastrahlung, Betastrahlung und Gammastrahlung mit deren steigender Fähigkeit, Materie zu durchdringen. Alpha- und Betastrahlung bestehen aus geladenen Teilchen und wechselwirken daher deutlich stärker mit Materie als die ungeladenen Photonen oder Quanten der Gammastrahlung. Entsprechend haben letztere ein deutlich höheres Durchdringungsvermögen.

Im "weiteren" Sinne wird mit Gammastrahlung jede elektromagnetische Strahlung mit Quantenenergien über etwa 200 keV bezeichnet, unabhängig von der Art ihrer Entstehung.</onlyinclude> Dies entspricht Wellenlängen kürzer als 0,005 nm (5 pm). In diesem allgemeinen Sinn wird die Bezeichnung insbesondere dann verwendet, wenn der Entstehungsprozess der Strahlung nicht bekannt ist (beispielsweise in der Astronomie) oder für die konkrete Aufgabenstellung gleichgültig ist (beispielsweise im Strahlenschutz), jedoch ausgedrückt werden soll, dass höhere Energien als bei Röntgenstrahlung (rund 100 eV bis 300 keV) vorliegen.

Der kleine griechische Buchstabe formula_1 (Gamma) wird allgemein als Formelsymbol für ein Photon beliebiger Energie und Entstehungsart benutzt.

Gammastrahlung im ursprünglichen Wortsinn entsteht dann, wenn sich nach einem radioaktiven Alpha- oder Betazerfall der zurückbleibende Kern (Tochterkern) in einem angeregten Zustand befindet; das gilt für viele, aber nicht für alle Alpha- und Beta-Zerfälle. Der angeregte Kern schwingt oder rotiert – anschaulich gesagt – eine geraume Zeit lang. Beim Übergang in einen weniger hoch angeregten Zustand oder den Grundzustand gibt er die frei werdende Energie in Form von Gammastrahlung ab (siehe Zerfallsschema). Diese Zustandsänderung des Kerns wird als Gammaübergang oder auch „Gammazerfall“ bezeichnet, obwohl der Kern dabei keineswegs „in seine Bestandteile zerfällt“, denn die Anzahl seiner Neutronen und Protonen bleibt konstant.

Der angeregte Zustand kann auch auf andere Weise, wie Neutroneneinfang oder andere Kernreaktionen oder die vorherige Absorption eines energiereicheren formula_1-Quants, entstanden sein.

Die Wellenlängen oder Energien der Gammastrahlen sind diskret und sind charakteristisch für das jeweilige Radionuklid, vergleichbar etwa dem optischen Linienspektrum chemischer Elemente. Die Messung des Gammaspektrums einer unbekannten Substanz (Gammaspektroskopie) ist daher geeignet, Aufschluss über Arten und Mengenanteile der darin enthaltenen Radionuklide zu geben.

Die scharfen Energien der Gamma-Spektrallinien erklären sich daraus, dass die Lebensdauern von Gammaübergängen kernphysikalisch gesehen vergleichsweise lang sind. Der angeregte Kern – den man sich etwa wie einen pulsierenden Rugbyball vorstellen kann – baut ein oszillierendes elektromagnetisches Quadrupolfeld auf. Ein Gamma-Quant kann aber nur Dipolschwingungen aufnehmen; seine Emission ist daher relativ unwahrscheinlich. Gemäß der Energie-Zeit-Unschärferelation ist die Lebensdauer formula_3 eines Übergangs umgekehrt proportional seiner Energieunschärfe oder Linienbreite formula_4:

Die Lebensdauern angeregter Kernzustände sind stets größer als etwa 10 Sekunden und führen daher zu diskreten Photonenenergien mit Halbwertsbreiten unter 0,3 eV.

Die durchschnittliche Verzögerungs- oder Halbwertszeit zwischen dem Alpha- oder Betazerfall und dem Gammaübergang hängt vom Nuklid und dem jeweiligen angeregten Zustand ab. Sie ist, wenngleich im kernphysikalischen Sinne „lang“, vom praktischen Standpunkt gesehen meist sehr kurz (Sekundenbruchteile). Will man Gammastrahlung für Forschungs-, medizinische oder technische Zwecke nutzen – beispielsweise die vom 2,5-MeV-Zustand des Nuklids Ni ausgesandte "Kaskade" zweier Photonen von 1,17 und 1,33 MeV – braucht man daher ein Präparat des Betastrahlers Co. Dieses Nuklid zerfällt mit 5,26 Jahren Halbwertszeit zum gewünschten Ni-Zustand.

Aus diesem praktischen Grund werden Gammastrahlen (nicht nur beim Ni, sondern ganz allgemein, auch in wissenschaftlich-technischen Unterlagen, Tabellen, Nuklidkarten usw.) immer dem "Mutter"nuklid des vorangehenden Alpha- oder Betazerfalls, im Beispiel dem Co, zugeordnet: Man spricht von Cobalt-60-Strahlung, Kobaltkanone usw., auch wenn es nur um die Gammastrahlung geht, die vom Tochterkern Ni emittiert wird.

Die seltenen Fälle von angeregten Atomkernen, deren Gammaübergänge Halbwertszeiten von Sekunden, Minuten oder noch länger haben, werden als "metastabil" oder als Kernisomere bezeichnet. Nur in diesen Fällen wird als Bezeichnung das eigentliche gammastrahlende Nuklid genannt. Ein Beispiel ist das Technetium-Isotop Tc, das in der medizinischen Diagnostik (siehe Szintigrafie) verwendet wird.

Bei der Paarvernichtung, der Reaktion eines Teilchens mit dem zugehörigen Antiteilchen, entstehen (allein oder neben anderen möglichen Reaktionsprodukten) auch Photonen, die ebenfalls Gammastrahlung genannt werden. Diese Gammaquanten tragen zusammen die Energie, die der Masse der vernichteten Teilchen entspricht, abzüglich der eventuellen Bindungsenergie, falls die beiden Teilchen bereits aneinander gebunden waren bzw. einander „umkreisten“, und zuzüglich eventuell vorher vorhandener Bewegungsenergie.

Gammablitze (englisch Gamma Ray Bursts) – auch Gammastrahlen-Explosionen genannt – stellen eines der energiereichsten Phänomene im Weltall dar. Ihr Entstehungsmechanismus ist nur ansatzweise geklärt. Das Spektrum ist kontinuierlich mit Photonenenergien von etwa 1 keV bis in den MeV-Bereich. Es enthält unter anderem Röntgenstrahlung. Es handelt sich nicht um Gammastrahlung im engeren, kernphysikalischen Sinne (siehe Einleitung).

Die Energiebereiche natürlicher Gamma- und Röntgenstrahlung überlappen sich, was eine gewisse Unschärfe dieser Begriffe zur Folge hat. Mancher Autor verwendet die Begriffe weiterhin im klassischen Sinne, um die Herkunft der Strahlung (Gammastrahlung aus Kernprozessen, Röntgenstrahlung aus hochenergetischen Prozessen mit Elektronen) zu kennzeichnen. Andere Autoren unterscheiden hingegen nach der Quantenenergie, wobei die Trennlinie dann bei ca. 100 bis 250 Kiloelektronenvolt liegt. Eine genaue Festlegung gibt es hierfür aber nicht. Zur Vermeidung von Missverständnissen ist es daher immer sinnvoll, Quantenenergie und Entstehungsprozess explizit anzugeben. Andererseits führen genau diese exakten Angaben in populärwissenschaftlicher Literatur regelmäßig zu Verständnisschwierigkeiten, weil viele Leser mit keV-Angaben oder Begriffen wie Bremsstrahlung oder Synchrotronstrahlung überfordert sind, während die Begriffe Gamma- und Röntgenstrahlung allgemein bekannt sind. Daher müssen Autoren zwischen Verständlichkeit und Unschärfe ihrer Formulierungen abwägen.

Im Gegensatz zur Bragg-Kurve bei geladenen Teilchenstrahlungen nimmt die Intensität (und damit der Energieeintrag) der Gammastrahlung exponentiell mit der Eindringtiefe ab. Das heißt, die Anzahl der Gammastrahlen wird nach jeweils einer Halbwertsdicke halbiert. Die Halbwertsdicke hängt von der Wellenlänge der Gammastrahlung und von der Ordnungszahl des abschirmenden Materials ab: Blei ist deshalb das gängigste zum Strahlenschutz gegen Gammastrahlung verwendete Material. Seine Halbwertsdicke für Gammastrahlung der Energie 2 MeV beträgt 14 mm. Hieraus wird die im Vergleich zu geladenen Teilchenstrahlungen viel durchdringendere Wirkung gut ersichtlich.

Die wichtigsten Wechselwirkungsprozesse beim Durchgang von Gammastrahlung durch Materie sind Photoionisation, Compton-Streuung und Paarbildung.

Wird Gammastrahlung in menschlichem, tierischem oder pflanzlichem Gewebe absorbiert, wird ihre Energie in Ionisations- und anderen Vorgängen wirksam. Dabei treten im Gewebe "Sekundärstrahlungen" wie freigesetzte Elektronen und Röntgenstrahlung auf. Insgesamt ergeben sich – für den Organismus meist schädliche – Wirkungen durch das Aufbrechen chemischer Bindungen. Das Ausmaß der Gesamtwirkung wird durch die Äquivalentdosis beschrieben. Die Folgen können am bestrahlten Organismus selbst ("somatische" Schäden) oder, durch Schädigung des Erbguts, an seinen Nachkommen als "genetische" Schäden auftreten.

Die Funktionsfähigkeit der Zellen bleibt auch bei hohen Strahlendosen zunächst meist erhalten. Sobald sich die Zelle aber teilt oder Proteine produziert, können Veränderungen am Erbgut und Schäden an Zellorganellen zum Absterben der Zelle führen. Die Strahlenkrankheit wirkt deswegen erst nach einiger Zeit tödlich, wenn bestimmte, lebenswichtige Zelltypen, die auch beim gesunden Menschen regelmäßig absterben und neu gebildet werden, nicht mehr in ausreichender Zahl vorhanden sind. Besonders betroffen sind hiervon Blutzellen. Alternativ kann es dazu kommen, dass durch die Strahlung verursachte Mutationen zu unkontrollierter Zellteilung führen, wobei die sich teilenden Zellen meistens ihre ursprüngliche biologische Funktion verlieren. Es entstehen Tumore, die darüber hinaus Metastasen bilden können (Krebs).

Gammastrahlung aus radioaktiven Quellen wird in der Strahlentherapie verwendet. Die Strahlenenergie in der Teletherapie muss möglichst hoch sein; verwendet wird z. B. Co, das Gammaquanten mit den Energien 1,17 und 1,33 MeV abstrahlt. Aufgrund des Bedarfs an möglichst hochenergetischen Photonen und der mit radioaktiven Strahlern verbundenen Sicherheitsprobleme wird in der Teletherapie jedoch inzwischen meist Bremsstrahlung aus Linearbeschleunigern für Elektronen eingesetzt. Auch in der Brachytherapie mittels kleiner, in den Körper eingeführter Präparate werden Gammastrahlen angewendet (meist Ir).

In der Szintigrafie und der Single-Photon-Emissionscomputertomographie werden kurzlebige Gammastrahler wie Tc, I, I, Xe oder In für diagnostische Zwecke verwendet.

Gammastrahlung kann Materie durchdringen, ohne reflektiert oder gebrochen zu werden. Ein Teil der Strahlung wird beim Durchgang absorbiert, abhängig von der Dichte und der Dicke des Mediums. Bei der Füllstandsmessung mit Gammastrahlung nutzt man diesen Umstand, denn die gemessene Strahlungsintensität hängt davon ab, ob sich in dem betrachteten Gefäß ein Medium befindet oder nicht.

Eine weitere Anwendung von Gammastrahlen findet man bei der Durchstrahlungsprüfung, mit deren Hilfe man Ablagerungen, Korrosionsschäden oder Erosionsschäden an der Innenseite von Apparaten und Rohrleitungen nachweisen kann.

Im Grenzschutz werden Radionuclide Identifying Devices eingesetzt, die über die Gammastrahlung Rückschlüsse auf die transportierten radioaktiven Stoffe zulassen.

In der Technik eingesetzte Gammastrahler sind hauptsächlich Co, Se, Yb und Ir. Ein Nachteil von Gammastrahlen ist, dass die Strahlenquellen nicht abgeschaltet werden können. Bei der Verwendung von Gammastrahlung im Betrieb müssen wegen ihrer Gefährlichkeit umfangreiche Strahlenschutzmaßnahmen ergriffen werden.

Zur Strahlensterilisation und zur Vernetzung von Polymer-Kunststoffen werden "Gammabestrahlungsanlagen" verwendet. Sie arbeiten fast ausschließlich mit Co, das aus Co in Kernreaktoren durch Neutroneneinfang hergestellt wird. Die Strahlensicherheit bei den Anlagen wird durch die Versenkbarkeit der Strahlenquellen in ein tiefes Wasserbecken oder einen tiefen, schachtförmigen Betonbunker erreicht.

Die Gammasterilisation medizinischer Produkte, z. B. eingeschweißter Notfallbestecke, hat vor anderen Verfahren den Vorteil, dass sie in der Verkaufsverpackung erfolgen kann.

Auf dem Gebiet der Lebensmittelbestrahlung ist vor allem die Zwiebelbestrahlung zu nennen, die in der Deutschen Demokratischen Republik in der Zeit von 1986 bis 1990 durchgeführt worden ist. Eine hierauf spezialisierte Gammabestrahlungsanlage gab es bei der Landwirtschaftlichen Produktionsgenossenschaft Queis in Spickendorf. In der DDR wurden auch viele andere Lebensmittel bestrahlt (Geflügel, Gewürze, Volleipulver etc.); eine Kennzeichnung der Produkte war nicht vorgesehen. Mit dem Beitritt zur Bundesrepublik Deutschland erloschen alle diese Zulassungen.

Großbestrahlungsanlagen gibt es z. B. in den Niederlanden und in Südafrika.

Der Rückstoß, den der Atomkern bei der Emission des Gammaquants normalerweise erhält, kann unter Umständen von dem gesamten Kristallgitter übernommen werden, in das dieser eingebettet ist. Dadurch wird der Energieanteil, der dem Photon durch Rückstoß verloren geht, vernachlässigbar klein. Ist zudem die Halbwertszeit des angeregten Zustands hoch, entstehen Gammastrahlen mit einer extrem scharfen Energie. Darauf beruht die in der chemischen Analytik wichtige Mößbauer-Spektroskopie.

Gammastrahlung kann durch ihre Wechselwirkung mit Materie nachgewiesen werden, z. B. mit Teilchendetektoren wie der Ionisationskammer oder dem Geiger-Müller-Zählrohr, Szintillationszählern, Halbleiterdetektoren oder Tscherenkow-Zählern.

1900 fand Paul Villard eine Komponente in der vier Jahre zuvor von Antoine Henri Becquerel entdeckten radioaktiven Strahlung, die sich nicht durch Magnetfelder ablenken ließ und ein sehr hohes Durchdringungsvermögen von Materie zeigte. Da es die dritte gefundene Strahlkomponente war, prägte Ernest Rutherford den Begriff "Gammastrahlung".

Durch Beugung von Gammastrahlung an Kristallen gelang es Rutherford und Edward Andrade 1914, zu zeigen, dass es sich um eine Form von elektromagnetischer Strahlung handelt. Die gefundenen Wellenlängen waren sehr kurz und mit der von Röntgenstrahlung vergleichbar.




</doc>
<doc id="2095" url="https://de.wikipedia.org/wiki?curid=2095" title="Gorillas">
Gorillas

Die Gorillas ("Gorilla") sind eine Primatengattung aus der Familie der Menschenaffen (Hominidae). Sie sind die größten lebenden Primaten und die ausgeprägtesten Blätterfresser unter den Menschenaffen. Sie sind durch ihr schwarzgraues Fell und den stämmigen Körperbau charakterisiert und leben in den mittleren Teilen Afrikas. Wurden früher alle Tiere zu einer Art zusammengefasst, so unterscheiden jüngere Systematiken zwei Arten mit jeweils zwei Unterarten: den Westlichen Gorilla ("G. gorilla"), der in den Westlichen Flachlandgorilla ("G. g. gorilla") und den Cross-River-Gorilla ("G. g. diehli") aufgeteilt wird, und den Östlichen Gorilla ("G. beringei"), bei dem zwischen dem Östlichen Flachlandgorilla ("G. b. graueri") und dem Berggorilla ("G. b. beringei") unterschieden wird.

Gorillas weisen einen robusten, stämmigen Körperbau auf. Sie sind stehend etwa 1,25 bis 1,75 Meter hoch, wobei sie meist die Knie etwas gebeugt halten. Wie alle Menschenaffen sind sie schwanzlos. Beim Gewicht weisen sie einen deutlichen Geschlechtsdimorphismus auf: Während Weibchen 70 bis 90 Kilogramm schwer werden, erreichen Männchen bis zu 200 Kilogramm. Trotz anderslautender Berichte (manche Quellen geben bis zu 275 Kilogramm an) gelten Tiere mit über 200 Kilogramm in freier Natur als Seltenheit. Wohlgenährte Tiere in menschlicher Obhut können dagegen deutlich schwerer werden und bis zu 350 Kilogramm wiegen. Östliche Gorillas sind generell etwas größer und schwerer als Westliche Gorillas, sie haben eine breitere Brust und wirken stämmiger.

Wie bei allen Menschenaffen mit Ausnahme des Menschen sind die Arme deutlich länger als die Beine, die Spannweite der ausgestreckten Arme beträgt 2 bis 2,75 Meter. Gorillas haben sehr breite Hände mit großem Daumen. Auch die Füße sind breit, die Großzehe ist wie bei den meisten Primaten opponierbar. Beim Berggorilla – der am stärksten bodenbewohnenden Unterart – allerdings ist diese weniger abgespreizt und mit den übrigen Zehen bindegewebig verbunden. Wie der Mensch (und auch andere Primaten) hat jeder Gorilla einen unverwechselbaren Fingerabdruck. Wissenschaftler identifizieren die Tiere jedoch vornehmlich anhand von Fotos oder Zeichnungen ihres ebenso einzigartigen „Nasenabdrucks“, das heißt durch die Form der Nase und die Anordnung der Falten darauf.

Die Fellfarbe der Gorillas ist dunkel. Während die Östlichen Gorillas schwarz gefärbt sind, sind die Westlichen Gorillas eher graubraun; bei dieser Art kann die Oberseite des Kopfes auffallend braun gefärbt sein. Das Gesicht, die Ohren, die Handflächen und Fußsohlen sowie bei älteren Männchen die Brust sind unbehaart. Dafür entwickelt sich bei älteren Männchen ein silbergraues Rückenfell, weswegen sie auch als Silberrücken bezeichnet werden. Während bei den Östlichen Gorillas diese Graufärbung auf den Rücken beschränkt bleibt, kann sie sich bei Westlichen Gorillas auch auf die Hüften und die Oberschenkel erstrecken. Bei Berggorillas ist das Fell länger und seidiger als bei den übrigen Populationen, insbesondere an den Armen.

Der Kopf des Gorillas ist durch die verglichen mit anderen Primaten kurze Schnauze charakterisiert; die Nasenlöcher sind groß, die Augen und Ohren hingegen klein. Auffallend sind die ausgeprägten Überaugenwülste, die Schädel der Männchen sind überdies mit einem Scheitelkamm und einem Nuchalkamm (einer Knochenleiste am Nacken) ausgestattet, die als Muskelansatzstellen dienen.

Wie alle Altweltaffen haben Gorillas 32 Zähne, die Zahnformel lautet I2-C1-P2-M3. Die Schneidezähne sind wie bei vielen blätterfressenden Säugetieren relativ klein, die Eckzähne groß und hauerartig und bei Männchen deutlich größer als bei Weibchen. Die Molaren haben höhere Höcker und schärfere Scherkanten als bei den übrigen Menschenaffen, was ebenfalls eine Anpassung an die Blätternahrung darstellt.

Die Augenfarbe ist einheitlich braun, die Iris weist an ihrem Rand einen schwarzen Ring auf.

Gorillas leben im mittleren Afrika, die Verbreitungsgebiete der zwei Arten liegen jedoch rund 1000 Kilometer voneinander entfernt. Westliche Gorillas leben nahe dem Golf von Guinea, wobei der Cross-River-Gorilla nur ein kleines Gebiet in der Grenzregion zwischen Nigeria und Kamerun bewohnt. Westliche Flachlandgorillas sind vom südlichen Kamerun und dem Westen der Zentralafrikanischen Republik über Äquatorialguinea, Gabun und die Republik Kongo bis in die angolanische Exklave Cabinda verbreitet. Die Population im äußersten Westen der Demokratischen Republik Kongo dürfte ausgestorben sein.

Östliche Gorillas bewohnen die östlichen Regionen der Demokratischen Republik Kongo (Östliche Flachlandgorillas) sowie die Regionen der Virunga-Vulkane und des Bwindi-Waldes im Grenzgebiet zwischen Uganda, Ruanda und der Demokratischen Republik Kongo (Berggorilla).

Gorillas sind ausgesprochene Waldbewohner. Westliche Flachlandgorillas bevorzugen tiefergelegene Regenwälder und Sumpfgebiete, Cross-River- und Östliche Flachlandgorillas hingegen sind eher in hügeligem Terrain zu finden. Die Berggorillas sind die ausgeprägtesten Bewohner des Berglandes und kommen in Regionen bis in 4000 Metern Seehöhe vor. Verschiedene Populationen bewohnen verschiedene Waldtypen – auch innerhalb der Unterarten, generell sind Östliche Gorillas häufiger in Sekundärwäldern zu finden.

Gorillas können sowohl auf dem Boden als auch in den Bäumen nach Nahrung suchen. Am Boden bewegen sie sich wie die Schimpansen in einem vierfüßigen Knöchelgang fort, das heißt, sie stützen sich auf die zweiten und dritten Fingerglieder. Selten gehen sie auch allein auf den Beinen, dabei legen sie jedoch nur kurze Distanzen zurück. Gorillas sind aber auch relativ gute Kletterer und erklimmen Bäume bis in 40 Meter Höhe. Im Geäst nehmen sie aber im Gegensatz zu Schimpansen und Orang-Utans sehr selten eine suspensorische (an den Armen hängende) Haltung ein. Die Berggorillas hingegen sind mit Ausnahme des Menschen die ausgeprägtesten Bodenbewohner aller Menschenaffen und klettern nur selten auf Bäume.

Obwohl Gorillas nicht schwimmen können, kommen sie im Gamba-Naturschutzgebiet in Gabun häufig an den Strand und wurden auch schon beim Baden im Meer beobachtet. Die sogenannten "Bai-Gorillas" im Kongo waten auf der Suche nach Nahrung gewohnheitsmäßig durch die Sümpfe der von ihnen besuchten Waldlichtungen und zeigen keine besondere Scheu vor Wasser. Jedoch durchqueren Gorillas keine Gewässer, insbesondere Flüsse, in denen sie nicht aufrecht stehen können.

Wie alle Menschenaffen sind Gorillas tagaktiv, nahezu ihre gesamte Aktivität ist auf die Zeit zwischen 6:00 und 18:00 Uhr beschränkt. Nach der morgendlichen Nahrungsaufnahme legen sie zwischen 10:00 und 14:00 eine Rast ein, um sich dann erneut auf Nahrungssuche zu begeben und einen Schlafplatz vorzubereiten. Die Schlafplätze bestehen aus selbst angefertigten Nestern aus Ästen und Blättern, die entweder am Boden oder im Geäst liegen können. Die Anfertigung der Nester dauert nicht länger als fünf Minuten, und normalerweise wird ein Nest nur für eine Nacht verwendet.

Gorillas leben in Gruppen zusammen, die zwei bis 40 Tiere umfassen können. Die Gruppengröße der Westlichen Gorillas ist mit durchschnittlich vier bis acht Tieren deutlich kleiner als die der Berggorillas mit zehn bis 20 Individuen. Gemeinhin ist in jeder Gruppe nur ein ausgewachsenes Silberrücken-Männchen vorhanden, seltener auch zwei oder drei. In diesem Fall übernimmt ein Männchen die dominante Rolle und ist das einzige, das sich fortpflanzt. Mehrere Weibchen samt ihrem Nachwuchs, und meist auch ein oder mehrere subadulte Männchen („Schwarzrücken“), ergänzen die Gruppe.

Manchmal lässt sich ein „Fission-Fusion-Modell“ („Trennen und Zusammengehen“) beobachten, das heißt, dass sich die Gruppe immer wieder in kleinere Untergruppen aufteilt – etwa zur Nahrungssuche – und dann wieder zusammenkommt. Die Beobachtungen zum Gruppenverhalten sind nicht einheitlich, insgesamt dürften aber die Gruppen stabil sein und der Zusammenhalt enger als etwa bei Schimpansen.

Im Gegensatz zu vielen anderen Primaten verlassen bei den Gorillas nicht nur die Männchen, sondern auch die Weibchen ihre Geburtsgruppe beim Erwachsenwerden. Dadurch sind die Weibchen einer Gruppe meist nicht miteinander verwandt und interagieren auch nur in sehr geringem Ausmaß untereinander. Eine soziale Organisation um eine „Kerngruppe“ nah verwandter Weibchen, wie sie bei vielen anderen Primaten zu beobachten ist, fehlt bei den Gorillas. Männchen, die ihre Geburtsgruppe verlassen haben, wandern meist einige Jahre allein umher und versuchen dann, entweder eine eigene Gruppe zu gründen, indem sie einige Weibchen um sich scharen, oder die Führungsrolle in einer etablierten Gruppe zu übernehmen. Gelingt ihnen das, kommt es oft zum Infantizid, das heißt, das Männchen tötet die von seinem „Vorgänger“ gezeugten Jungtiere. Der Nutzen dieses Verhaltens kann in der Tatsache gesehen werden, dass säugende Weibchen nicht schwanger werden, nach dem Tod des Jungtieres jedoch schnell wieder empfängnisbereit sind.

Im Gegensatz zu den Männchen bleiben die Weibchen nach dem Verlassen ihrer Geburtsgruppe nicht lang allein, sondern versuchen sich rasch einer bestehenden Gruppe oder einem jungen Männchen anzuschließen. Es kann aber vorkommen, dass die Weibchen einer etablierten Gruppe sich zusammenschließen, um ein neu hinzugekommenes Weibchen wieder zu vertreiben.

Die Größe der Streifgebiete ist variabel, bei Flachlandgorillas sind sie jedoch mit 500 bis 3200 Hektar größer als bei den Berggorillas mit 400 bis 800 Hektar. Das Revierverhalten ist wenig entwickelt, die Streifgebiete überlappen sich häufig. Möglicherweise haben die Gruppen aber Kernreviere, die von anderen Gruppen nicht betreten werden.

Oft suchen mehrere Gruppen an den gleichen Stellen nach Nahrung, jedoch nicht gleichzeitig. Meist vermeiden die Gruppen den direkten Kontakt miteinander und gehen sich aus dem Weg; anderen Beobachtungen zufolge kann es bei der Begegnung zweier Gruppen auch zum zeitweiligen Zusammenschluss oder zu Feindseligkeit kommen. Diese wird durch Gebrüll, durch Gestik oder durch Kraftdemonstrationen ausgetragen, handgreifliche Auseinandersetzungen vermeiden Gorillas allerdings in der Regel.

Gorillas kommunizieren miteinander durch Laute, Gesichtsausdrücke, Körperhaltungen und Kraftdemonstrationen.

Sie kennen eine Reihe von Lauten, die zur Lokation von Gruppenmitgliedern und fremden Gruppen sowie als Ausdruck der Aggression verwendet werden. Dazu zählen Rülpslaute, die der Kontaktaufnahme mit anderen Gruppenmitgliedern dienen, laute, über einen Kilometer weit hörbare „U!“-Rufe "(„hoots“)", die die Dominanz des Männchens ausdrücken oder den Kontakt zwischen einzelnen Gruppen ermöglichen, sowie Grunz- und Knurrlaute, die Aggression ausdrücken. Diese Stimmung kann beispielsweise auch mit geöffnetem Mund und gefletschten Zähnen signalisiert werden. Hingegen zeugt ein gedämpftes, langgezogenes Grunzen (einem menschlichen Räuspern nicht unähnlich) von Entspannung und Wohlbehagen, das von Rangern und Touristen zur Signalisierung ihrer friedlichen Absichten gern imitiert wird.

Bekanntestes kommunikatives Verhalten der Gorillas ist das Trommeln auf die Brust. Früher hielt man es für ein rein männliches Verhalten, das dem Imponiergehabe dient und andere Männchen einschüchtern sollte. Dieses Verhalten wird aber von Tieren beiderlei Geschlechts und aller Altersklassen praktiziert und dient vermutlich verschiedenen Funktionen, wie etwa der Angabe des Standorts oder als Begrüßungsritual.

Verhaltensmuster, die der Einschüchterung dienen, umfassen neben lautem Gebrüll auch das Laufen auf zwei Beinen, das Schütteln von Ästen, das Ausreißen und Wegschleudern von Pflanzen (meist in Richtung des vermeintlichen Gegners) und das Schlagen auf den Boden.

Bis vor kurzem war kein Werkzeuggebrauch bei freilebenden Gorillas bekannt. Im Jahr 2005 wurden allerdings erstmals Tiere fotografiert, die mit Hilfe eines Stockes die Tiefe eines Gewässers ausloteten, bevor sie es durchquerten, und die ein Holzstück als Brücke auf sumpfiges Gelände legten, um es leichter passieren zu können. In unmittelbarem Zusammenhang mit dem Nahrungserwerb ist aber weiterhin kein Werkzeuggebrauch bei Gorillas bekannt. Ihre große Kraft, mit der sie auch dicke Äste abbrechen können, und ihre hauptsächlich auf Blättern und Früchten basierende Ernährung dürften solche Methoden, wie sie bei anderen Menschenaffen zu beobachten sind, unnötig machen.

Gorillas benutzen ebenso wie Schimpansen stachelige, gerbstoffhaltige Blätter, um sich von lästigen Darmparasiten zu befreien. Sie fressen eine größere Zahl dieser Blätter unzerkaut, so dass diese die Parasiten von den Darmwänden abschaben.

Erwachsene Gorillas haben keine natürlichen Feinde; Jungtiere fallen gelegentlich Leoparden zum Opfer. Teile ihres Verbreitungsgebietes können sich mit dem des Gemeinen Schimpansen überlappen (Sympatrie). Ähnliche Lebensweisen und Ernährungsmuster könnten zu einer Nahrungskonkurrenz führen, Beobachtungen dazu gibt es aber nicht. Die größte Bedrohung für die Gorillas geht vom Menschen aufgrund der Lebensraumzerstörung und der Bejagung aus (siehe Bedrohung).

Von allen Menschenaffen sind Gorillas die ausgeprägtesten Pflanzenfresser. Ihre Hauptnahrung sind Blätter, je nach Art und Jahreszeit nehmen sie in unterschiedlichem Ausmaß auch Früchte zu sich. Aufgrund ihrer Körpergröße und des geringen Brennwerts ihrer Nahrung müssen Gorillas viel Zeit ihrer aktiven Perioden fressend verbringen.

Berggorillas ernähren sich zum Großteil von Blättern und Mark; Früchte werden hingegen kaum verzehrt. Die beiden Flachlandgorilla-Populationen hingegen ergänzen ihren Speiseplan mit Früchten, je nach Jahreszeit können diese bis zu 50 % der Nahrung ausmachen. Aus diesem Grund klettern Flachlandgorillas auch öfter auf Bäume, während Berggorillas ausgeprägte Bodenbewohner sind.

Unklar ist, in welchem Ausmaß Insekten und andere Kleintiere verzehrt werden. In freier Natur wurde das Fressen von Fleisch nur selten beobachtet, es gibt aber Berichte, wonach Westliche Flachlandgorillas Termitenhügel aufbrachen und die Insekten verzehrten. Möglicherweise nehmen Gorillas auch unbeabsichtigt Kleintiere zu sich, wenn diese sich auf den von ihnen verzehrten Blättern befinden.

Gorillas trinken nur selten Wasser. Sie stillen ihren Bedarf an Flüssigkeit allein durch das Verzehren großer Mengen pflanzlicher Nahrung – bei erwachsenen Männchen durchschnittlich 25 Kilogramm pro Tag.

Die täglichen Streifzüge, die die Gorillas bei der Nahrungssuche zurücklegen, sind verglichen mit denen anderer Primaten kurz. Am kürzesten sind diese bei Berggorillas mit durchschnittlich 0,4 Kilometern, was zum einen am meist üppigen Angebot an Blättern und zum anderen am geringen Nährwert dieser Nahrung liegt, was die Tiere mit langen Ruhephasen wettmachen. Die täglichen Streifzüge der Flachlandgorillas sind mit 0,5 bis 1,2 Kilometern aufgrund der abwechslungsreicheren Nahrung deutlich länger.

Das Paarungsverhalten der Gorillas ist vom Ansatz her polygyn, d. h. nur das dominante Männchen pflanzt sich mit den Weibchen der Gruppe fort. Allerdings kommt es aus verschiedenen Gründen immer wieder zu Ausnahmen von dieser Regel (siehe Paarungsverhalten). Die Paarung ist saisonal nicht eingeschränkt, kann also das ganze Jahr über erfolgen. Die Länge des Sexualzyklus des Weibchens beträgt 27 bis 28 Tage. Die Tragzeit beträgt etwa 8½ bis 9 Monate und ist somit zusammen mit der des Menschen die längste aller Primaten.

Meist kommt ein einzelnes Jungtier zur Welt, Zwillinge sind selten. Neugeborene wiegen rund 2 Kilogramm, mit drei Monaten können sie krabbeln und reiten danach mehrere Jahre auf dem Rücken der Mutter. Nach drei bis vier Jahren werden sie entwöhnt. Das Geburtsintervall liegt dementsprechend bei 3,5 bis 4,5 Jahren – außer wenn das Jungtier früher stirbt. Beobachtungen zufolge liegt die Sterblichkeitsrate bei Jungtieren bei 42 %, insbesondere im ersten Lebensjahr ist sie hoch. Im Laufe seines Lebens bringt das Weibchen durchschnittlich zwei bis drei überlebende Jungtiere zur Welt.

Weibchen erreichen die Geschlechtsreife mit sechs bis acht und Männchen mit zehn Jahren. Aufgrund der Sozialstruktur erfolgt die erste Paarung jedoch meist erst einige Jahre später: bei Weibchen mit neun bis zehn und bei Männchen mit 15 Jahren.

Die Lebenserwartung der Tiere liegt bei 35 bis 40 Jahren, in menschlicher Obhut können Gorillas jedoch älter als 50 werden. "Massa" († 1984) im Zoo von Philadelphia war mit 54 Jahren lange der älteste bekannte Gorilla weltweit, danach "Jenny" († 2008) im Zoo von Dallas mit 55 Jahren. Bis Januar 2017 galt "Colo" (* 22. Dezember 1956; † 17. Januar 2017) im Zoo von Columbus als das älteste noch lebende Tier. Sie war zudem der erste jemals in Gefangenschaft geborene Gorilla.

Der karthagische Seefahrer Hanno († 440 v. Chr.) brachte von seiner Afrikareise die Felle von drei „wilden Frauen“ mit, die von den afrikanischen Dolmetschern als "" bezeichnet wurden. Es ist aber unklar, wo Hanno die Wesen genau erlegte und ob es sich dabei wirklich um Gorillas handelte, oder um Schimpansen oder gar Angehörige eines Pygmäenvolks.

Abgesehen von einem Bericht des englischen Seefahrers Andrew Battell aus dem 16. Jahrhundert erhielt die westliche Welt erst im 19. Jahrhundert Kenntnis von diesen Tieren. Der Name „Gorilla“ wurde diesen Tieren zuerst von dem US-amerikanischen Missionar, Arzt und Naturforscher Thomas Staughton Savage (1804–1880) in Anlehnung an den Bericht Hannos zugeteilt, unter Mitwirkung des amerikanischen Naturwissenschaftlers und Anatomen Jeffries Wyman (1814–1874). Savage, der in Gabun einige erlegte Exemplare des westlichen Flachlandgorillas erhalten hatte, beschrieb 1847 zusammen mit Wyman diese großen Affen als neue Art; als erste wissenschaftliche Artbezeichnung wurde "Troglodytes gorilla" eingeführt ("Troglodytes" war damals die Gattungsbezeichnung der Schimpansen). Isidore Geoffroy Saint-Hilaire prägte dann 1852 den bis heutige gültigen Gattungsnamen "Gorilla".

Der Afrikaforscher Paul Belloni Du Chaillu (1835–1903) bewirkte durch seine Unternehmungen und seine Publikationen, dass gegen Ende des 19. Jahrhunderts das Interesse an Gorillas in den USA und auch in Europa rasant zunahm. Der erste in Europa eingehend wissenschaftlich untersuchte, lebende Gorilla, genannt M'Pungu, wurde 1876/77 im Berliner Aquarium Unter den Linden zur Schau gestellt. Eines der bekanntesten Motive ist die Filmfigur „King Kong“, ein riesenhafter Gorilla, die seit dem ersten Film "King Kong und die weiße Frau" 1933 in zahlreichen Adaptionen und Remakes in der Film- und Fernsehgeschichte wiederkehrt. Nicht nur von den Ausmaßen, sondern auch vom Verhalten hat diese Figur, wie auch viele andere Gorillafiguren aus Büchern, Comics oder Filmen mit den realen Gorillas allerdings kaum etwas gemein. Das lag daran, dass die Lebensweise und das Sozialverhalten dieser Tiere lange Zeit kaum bekannt war.

Zunächst standen – wie bei vielen Säugetieren – morphologische Studien im Vordergrund. Paul Matschie vermutete 1903, dass es sich bei einem auf den Virunga-Vulkanen erlegten Tier um eine eigene Art (Berggorilla) handeln könnte. Er beschrieb aber noch einige weitere Arten, durch die Arbeiten von Ernst Schwarz und Harold Coolidge in den 1930er Jahren wurde die bis zum Ende des 20. Jahrhunderts gültige Systematik mit einer einzigen Art und mehreren Unterarten festgelegt. Erst zu Beginn des 21. Jahrhunderts setzte sich anhand morphologischer und auch molekularer Studien die Ansicht durch, dass es zwei Arten von Gorillas gibt. (Siehe dazu Innere Systematik.)

Die Lebensweise der Gorillas rückte erst nach dem Zweiten Weltkrieg in den Blickpunkt der Forschung. Der US-Amerikaner George Schaller (* 1933) war der erste Forscher, der freilebende Gorillas ab 1959 ausführlich untersuchte. 1967 begann die jahrzehntelange Forschungsarbeit von Dian Fossey (1932–1985) – unterstützt durch Louis Leakey – bei den Berggorillas auf den Virunga-Vulkanen. Ihr Leben und ihre Ermordung wurden durch die Verfilmung "Gorillas im Nebel" einer breiteren Öffentlichkeit bekannt. Feldstudien bei Westlichen Flachlandgorillas begannen erst in den 1980er Jahren; bekanntestes Projekt ist die Tätigkeit von Caroline Tutin und Michael Fernandez im Lopé-Nationalpark in Gabun.

Wie bei anderen Menschenaffen wird auch bei Gorillas versucht, ihre Kommunikationsfähigkeit und Intelligenz in Laborversuchen zu erforschen. Zu den bekanntesten dieser Untersuchungen zählen die Versuche, dem Weibchen Koko die amerikanische Gebärdensprache beizubringen.

Beide Gorillaarten sind bedroht, wenn auch in unterschiedlichem Ausmaß. Ein Grund für die Gefährdung liegt in der Zerstörung ihres Lebensraumes durch die Rodung der Wälder. Hinzu kommen bürgerkriegsähnliche Zustände in Teilen ihres Verbreitungsgebietes, welche die nötigen Schutzmaßnahmen erschweren und eine effiziente Überwachung von Schutzgebieten nahezu unmöglich machen. Ein weiterer Grund stellt die Bejagung wegen ihres Fleisches („Bushmeat“) dar, die immer noch durchgeführt wird. Auch Krankheiten ziehen die bereits angegriffenen Populationen weiter in Mitleidenschaft, insbesondere Ebola. Die Gesamtpopulation der Gorillas wird auf rund 100.000 Tiere geschätzt, die sich allerdings sehr unterschiedlich auf die einzelnen Populationen verteilen.

Diese Population des Westlichen Flachlandgorillas bewohnt ein großes, vergleichsweise dünn besiedeltes Gebiet, in welchem auch einige Nationalparks eingerichtet wurden. Darüber hinaus sind nahezu alle in Zoos gehaltenen Gorillas Westliche Flachlandgorillas, wo nach jahrzehntelangen Schwierigkeiten heute auch die Nachzucht regelmäßig gelingt.




Gorillas sind seit 1975 im Washingtoner Artenschutzübereinkommen im Anhang I gelistet. Somit ist der internationale kommerzielle Handel mit den Tieren oder ihren Teilen verboten. 2008 trat das Abkommen zur Erhaltung der Gorillas und ihrer Lebensräume in Kraft. Das Abkommen wurde bislang von der Zentralafrikanischen Republik, der Republik Kongo, Nigeria, der Demokratischen Republik Kongo, Ruanda und Gabun unterzeichnet.

Gorillas bilden zusammen mit Orang-Utans, Schimpansen (Gemeiner Schimpanse und Bonobo) sowie dem Menschen die Familie der Menschenaffen (Hominidae). Zwar haben Gorillas eine Reihe von morphologischen Gemeinsamkeiten mit den Schimpansen, dabei dürfte es sich aber um Synapomorphien (gemeinsame abgeleitete Merkmale) aller afrikanischen Menschenaffen handeln, die beim Menschen verloren gegangen sind. Genetische Studien deuten darauf hin, dass Schimpansen enger mit den Menschen als mit den Gorillas verwandt sind. Das kommt im Kladogramm (s. Abb.) zum Ausdruck.

Der um das Jahr 2000 von einigen Forschern formulierte Vorschlag, die Gorillas und die Schimpansen aufgrund der nur geringfügigen genetischen Unterschiede zwischen diesen und den Menschen der Gattung "Homo" zuzuordnen, fand in den folgenden Jahren keinen Eingang in die international angesehenen systematischen Werke.

Wann die zu den Gorillas führende Entwicklungslinie sich von der zu den Schimpansen und Menschen führenden Linie trennte, ist bislang nicht eindeutig geklärt: Der mutmaßliche Gorilla-Vorfahr "Chororapithecus" wurde zwar auf rund 8 Millionen Jahre datiert, anhand von DNA-Analysen wurde die Auftrennung allerdings in die Zeit vor 6,5 Millionen Jahren datiert. Die Abtrennung von Westlichem Gorilla und Östlichem Gorilla ereignete sich vor rund 1,6 bis 0,9 Millionen Jahren, die Abtrennung des Westlichen Flachlandgorillas vom Cross-River-Gorilla vor rund 17.800 Jahren.

Nach der Sequenzierung des Gorilla-Genoms wurde 2012 in der Fachzeitschrift "Nature" ein mittlerer Unterschied („mean nucleotid divergences“) von 1,81 % für Gorilla/Schimpanse und von 1,75 % für Gorilla/Mensch ausgewiesen, der Unterschied für Mensch/Schimpanse ergab 1,37 %. Demnach ist der Mensch näher mit dem Schimpansen verwandt als mit dem Gorilla, doch der Gorilla etwas näher mit dem Menschen als mit dem Schimpansen. Für die Trennung der Entwicklungslinien der Gorillas einerseits von den Schimpansen und Menschen andererseits wurde ein Schätzwert von 6 bis 10 Millionen Jahre vor heute veröffentlicht.

Traditionell wurden alle Gorillas zu einer Art zusammengefasst und drei Unterarten unterschieden, der Westliche Flachlandgorilla, der Östliche Flachlandgorilla und der Berggorilla.

Aufgrund von Unterschieden im Körperbau und in der Lebensweise geht man heute von zwei Arten mit je zwei Unterarten aus:

Die Population des Bwindi-Waldes („Bwindigorillas“), die traditionell dem Berggorilla zugerechnet wird, könnte allerdings eine eigene, bislang nicht wissenschaftlich beschriebene Unterart des Östlichen Gorillas darstellen.




</doc>
<doc id="2097" url="https://de.wikipedia.org/wiki?curid=2097" title="Genussmittel">
Genussmittel

Genussmittel im engeren Sinne sind Lebensmittel, die nicht in erster Linie wegen ihres Nährwertes und zur Sättigung konsumiert werden, sondern aufgrund ihres Geschmacks und ihrer anregenden oder berauschenden Wirkung.

Oft werden auch andere psychoaktive Substanzen, die (mangels Nährwerts) keine Lebensmittel darstellen (beispielsweise Tabakwaren) zu den Genussmitteln gerechnet. In der Fachliteratur wird der Begriff darüber hinaus gelegentlich für Zucker und andere Gewürze verwendet. Im Deutschen Wörterbuch der Brüder Grimm werden Genussmittel definiert als Lebensmittel, deren Verzehr weniger der Ernährung als vielmehr dem Genuss dient. Die Unterscheidung zwischen Nahrungs- und Genussmitteln ist wissenschaftlich und insbesondere juristisch nicht definiert. Einzig für den Verkauf von Alkohol und Tabak gibt es gesetzliche Bestimmungen.

Sozioökonomisch betrachtet gehörten Genussmittel bis in die Neuzeit zu den Luxusgütern und waren Statussymbole. Die französischen Begriffe verweisen auf die pharmakologische Wirkung einiger Genussmittel wie Alkohol, Kaffee und Tee. 

Die allermeisten Genussmittel besitzen eine angenommene oder tatsächlich anregende oder beruhigende Wirkung. Diese basiert überwiegend auf Alkaloiden, welche von den Ausgangspflanzen zur Abwehr von Fressfeinden gebildet werden. Einige Genussmittel können zu Abhängigkeiten führen. Sie haben oft eine erhebliche soziale Bedeutung, insbesondere wenn sie gemeinsam mit anderen Menschen konsumiert werden.



</doc>
<doc id="2098" url="https://de.wikipedia.org/wiki?curid=2098" title="Getränk">
Getränk

Getränk (Kollektivum zu "Trank"; veraltet Trunk) ist ein Sammelbegriff für zum Trinken zubereitete Flüssigkeiten. Getränke werden entweder zum Stillen von Durst und damit zur Wasseraufnahme des Körpers, als Nahrungsmittel oder auch als reine Genussmittel aufgenommen. Die englische Entsprechung Drink wird im deutschen Sprachgebrauch auch als Oberbegriff für Cocktails sowie für Einzelportionen von Spirituosen verwendet. Mit "Mixgetränk" sind ebenfalls oft Cocktails gemeint, "Mischgetränk" deutet auf die Zubereitung aus verschiedenen Einzelflüssigkeiten wie bei Milchshakes oder Biermischgetränken.

Getränke lassen sich in verschiedene Kategorien einteilen. So unterscheidet man:


und


und


Die Übergänge zwischen den verschiedenen Gruppen sind fließend; so können einige Getränke sowohl kalt, als auch heiß getrunken werden.

Milch wird je nach Definition zu den Getränken gezählt oder auch nicht. Milch gilt als Nährflüssigkeit. Dagegen werden Mischgetränke mit Milch immer zu den Getränken gezählt.

Zur Aufbewahrung und Lagerung sowie zum Transport und Verkauf werden Getränke üblicherweise in Flaschen, Fässer, Getränkekartons, Getränkedosen oder ähnlichem abgefüllt. Konsumiert werden Getränke meist aus Gläsern, Tassen, Bechern, Trinkschalen oder direkt aus der Verpackung (Dosen, Flasche; etc.), teilweise auch unter Benutzung eines Trinkhalms.

Zu den alkoholfreien Getränken gehören Milch und das Wasser selbst, welches bekanntermaßen für alle Lebewesen lebensnotwendig ist. Weiterhin zählen dazu auch "alkoholfreie Erfrischungsgetränke", die meist aus Wasser oder Milch, Früchten und Gemüsen sowie teilweise sonstigen zugesetzten Geschmacks- und Aromastoffen hergestellt werden. Als "alkoholfrei" bezeichnete Erzeugnisse dürfen maximal 0,5 Volumenprozent Alkoholgehalt aufweisen (Traubensaft bis zu einem Volumenprozent). Eine Besonderheit sind "alkoholreduzierte" Getränke, die bis zu vier Volumenprozent Alkohol enthalten dürfen.

Alkoholische Getränke oder alkoholhaltige Getränke, auch "Alkoholika" oder (vor allem in Bezug auf Spirituosen) "geistige Getränke" genannt, enthalten Trinkalkohol (Ethanol). In Lebensmitteln wird dieser meist nur als "Alkohol" bezeichnet. 

Im chemischen Sinn bilden Alkohole jedoch eine ganze Stoffklasse. Alkoholische Getränke werden aus kohlenhydrathaltigen Flüssigkeiten durch alkoholische Gärung erzeugt. Nach geltendem Lebensmittelrecht kommen als Rohstoffe für den Alkohol nur landwirtschaftliche Produkte in Frage. Alkoholische Getränke dürfen also weder Alkohol synthetischen Ursprungs noch anderen Alkohol nicht landwirtschaftlichen Ursprungs enthalten.

Zu den alkoholischen Getränken gehören sowohl Getränke, deren Alkohol lediglich durch alkoholische Gärung entstanden ist, zum Beispiel Bier und Wein, als auch Destillate aus solchen Getränken oder aus vergorenen Maischen sowie deren Mischprodukte. Getränke, deren Alkoholgehalt direkt oder indirekt auf Destillation zurückgeht und mindestens 15 % vol. beträgt, werden in der EU als Spirituose bezeichnet.

Aufgrund der giftigen Wirkung des Ethanols auf das zentrale und periphere Nervensystem, die Leber und andere Organe sind alkoholische Getränke ab einer gewissen Dosis gesundheitsschädlich. Regelmäßiger und hoher Alkoholkonsum kann zur Alkoholkrankheit und zu ernsthaften Folgekrankheiten führen; seine Wirkung ist daher eindeutig negativ. Vor allem bei Männern, aber auch bei Frauen, wird durch regelmäßigen Alkoholkonsum von mehr als 36 Gramm täglich der Gedächtnisverlust um fast sechs Jahre beschleunigt.<ref name="DOI10.1212/WNL.0000000000000063">S. Sabia, A. Elbaz, A. Britton, S. Bell, A. Dugravot, M. Shipley, M. Kivimaki, A. Singh-Manoux: "Alcohol consumption and cognitive decline in early old age." In: "Neurology." .</ref> Auch die exekutiven Funktionen des Gehirns leiden unter dem Alkoholkonsum.

Da einige alkoholische Getränke wie Rotwein Antioxidantien enthalten, wird durch einige Studien bei einem moderaten Konsum von 0,2 Liter Wein am Tag für einen Erwachsenen eine gefäß- und herzschützende Wirkung prognostiziert. Viele vordergründig positive Wirkungen werden jedoch durch andere aufgehoben, etwa durch die stark erhöhte Krebsgefahr beim regelmäßigen Konsum selbst geringer Mengen, die durch wissenschaftliche Studien bestätigt wurde, z. B. durch eine britische Studie aus dem Jahr 2006. Die meisten positiven Wirkungen gehen auch nicht vom Alkohol selbst aus, sondern von anderen Pflanzenstoffen, die in Getränken wie Rotwein enthalten sind. Mediziner warnen davor, einzelne Wirkungen aus dem Gesamtzusammenhang zu reißen.

Viele Studien wurden von der ' der Stiftung ' finanziert, deren Mitglieder die Konzerne Moët & Chandon, Allied Domecq, Brasseries Kronenbourg, Heineken und Diageo sind. In Deutschland wurden viele Studien von der Deutschen Weinakademie (DWA) in Auftrag gegeben, die von den Weinerzeugern finanziert wird. Alleine für die Pressearbeit im Inland wurden 160.000 Euro ausgegeben. Die französische Sopexa gab 800.000 Euro für deutsche Medien aus. Einige der Studien wurden gefälscht.

Da Alkohol desinfizierend wirkt, wurde Alkoholkonsum früher mit der Vorbeugung gegen durch unsauberes Wasser übertragene Krankheiten gerechtfertigt. Die desinfizierende Wirkung von Ethanol-Wasser-Mischungen ist jedoch nur bei einem Alkoholgehalt zwischen 50 und 80 % signifikant; bei unter 20 % Ethanolgehalt fehlt sie völlig.

In alkoholischen Getränken sind neben Ethanol und Wasser auch die bei der Gärung entstehenden Nebenprodukte enthalten, etwa Aldehyde, die Alkohole Glycerin, Methanol und 1-Propanol sowie auch höhere einwertige Alkohole. Zusätzlich finden sich aliphatische Carbonsäuren, Milch- und Bernsteinsäure sowie Carbonsäureester darin. Diese Stoffe beeinflussen das Aroma der Getränke. Beim Brennen alkoholhaltiger Flüssigkeiten oder von Maische entstehen Spirituosen mit einem Alkoholgehalt ab 15 % – mit Ausnahme von Eierlikör, der mindestens 14 Volumenprozent haben muss.

Ethanolgehalte verschiedener alkoholischer Getränke, Angabe in Volumenprozent:





</doc>
<doc id="2099" url="https://de.wikipedia.org/wiki?curid=2099" title="Geochronologie">
Geochronologie

Geochronologie (von altgriechisch: "γῆ (ge)" „Erde“ und "χρὁνος" (chronos) „Zeit, Zeitdauer“ und -logie) ist die Wissenschaftsdisziplin, die Ereignisse der Erdgeschichte und sekundär die Entstehungszeit von Gesteinen und Sedimenten (siehe Chronostratigraphie) absolut-zeitlich datiert. Unter anderem erstellt sie aus den ermittelten Daten die geologische Zeitskala, in der Zeitintervalle identifiziert, als geochronologische Einheiten benannt und zeitlich datiert dargestellt sind.

Häufig korrespondieren geochronologische Einheiten mit der Bildungszeit chronostratigraphischer Einheiten, also physisch existenter Gesteinskörper. Die Geochronologie ist ihrem Wesen nach dagegen immateriell und ist daher nicht im eigentlichen Sinne eine stratigraphische (gesteinsdatierende) Disziplin. Die Beziehungen zwischen konkreten geochronologischen Einheiten werden immer in einer älter/jünger-Beziehung ausgedrückt.

Die Datierung von Gesteinen kann absolut oder relativ erfolgen.

Lange gab es keine direkten Methoden zur absoluten Altersbestimmung von Gesteinen. Schätzungen basierten auf Erosionsraten der Gebirge sowie Sedimentationsraten in Seen und Ozeanen. Anfang des 20. Jahrhunderts begründete der schwedische Geologe Gerard Jakob De Geer die Warvenchronologie, also das Auszählen von jährlichen Schichten ("Warven"). Jährliche Schichten sind auch in Eisbohrkernen erkennbar.

Die Aufstellung lokaler relativer Schichtfolgen und deren regionale und globale Zuordnung ist Thema der Stratigraphie.

Hier werden Erkenntnisse zu chronometrischen Fragestellungen aus der Isotopengeologie zur Altersbestimmung genutzt.
Mit der Entdeckung der Radioaktivität wurden verschiedene Messmethoden entwickelt, die auf der Untersuchung des Mengenverhältnisses natürlicher Radioisotope beruht. Die Isotopenverhältnisse ändern sich aufgrund unterschiedlicher Zerfallszeiten (Halbwertszeit) oder natürlicher Bestrahlung (Radioaktivität der Erde oder extraterrestrische Strahlung).

Heute werden auch Methoden eingesetzt, die auf der quantitativen Bestimmung künstlich erzeugter Radioisotope beruhen, z. B. die Tritiummethode zur Bestimmung des Alters oberflächennaher Grundwässer. Nach einem Eintrag eines solchen Isotops in das Wasser nimmt der Gehalt des Isotops durch Zerfall und ggf. Verdünnung ab.

Die erste auf der Uran-Blei-Zerfallsreihe beruhende Altersbestimmung wurde 1913 von Arthur Holmes veröffentlicht und war seinerzeit sehr umstritten. Friedrich Georg Houtermans publizierte 1953, basierend auf von Clair Cameron Patterson durchgeführten Uran-Blei-Isotopenmessungen an Meteoriten, das heute akzeptierte Erdalter von ca. 4,5 Milliarden Jahren. Heute werden unterschiedliche radioaktive Isotope sowie ihre Zerfallsprodukte benutzt, um das Alter von Gesteinen zu bestimmen. Das Alter eines Gesteins ist je nach Untersuchungsmethode unterschiedlich zu interpretieren. Bei magmatischen Gesteinen können sowohl das Alter der Kristallisation (der Platznahme in der Erdkruste) und je nach untersuchtem Mineral auch mehrere Abkühlalter bestimmt werden. Ebenso kann in metamorphen Gesteinen der Zeitraum eines Metamorphose-Ereignisses festgestellt werden. In manchen Sedimenten bilden sich während der Ablagerung bestimmte Minerale (zum Beispiel Glaukonit in vielen marinen (Grün-)Sandsteinen), deren Entstehungsalter durch Messung radioaktiver Isotope bestimmt werden kann. Dieses Alter wird dann als Sedimentationsalter interpretiert.

Rubidium Rb zerfällt mit einer Halbwertszeit von 47 Mrd. Jahren in Sr. Die Radiometrische Datierung eignet sich für sehr alte Gesteine. Da neben Sr auch das stabile Sr vorkommt, erhält man über die Isochronenmethode recht genaue Daten für beispielsweise Feldspäte, Hornblende oder Glimmer in der Größenordnung von 1000 Mio. Jahren mit einem Fehler von mehreren 10 Mio. Jahren.

Die Uran-Blei-Methode nutzt zwei Zerfallsreihen:

Das Alter uranhaltiger Minerale kann nun über das Verhältnis der Tochterisotope zum verbliebenen Anteil des Mutterisotops (hier: U) unter Kenntnis der Halbwertszeit des Mutterisotops bestimmt werden. Dabei muss ggf. der vor dem radioaktiven Zerfall bestehende Gehalt an den Bleiisotopen Pb und Pb berücksichtigt werden; dies geschieht durch die Messung des Gehalts an nicht durch radioaktiven Zerfall entstandenem, das heißt bereits vorhandenem Pb: Die unveränderten Verhältnisse Pb/Pb und Pb/Pb sind aus der Messung von Meteoritenmaterial bekannt, daher kann aus dem Pb-Gehalt auch der ursprüngliche Gehalt an Pb bzw. Pb berechnet werden; dieser muss von dem gemessenen Gehalt abgezogen werden – der Rest ist dann durch radioaktiven Zerfall entstanden.

Ein großer Vorteil der Uran-Blei-Methode ist, dass man meist beide Zerfallsreihen benutzen und damit sein Ergebnis absichern kann. Wegen der hohen Halbwertszeiten ist die Methode am besten geeignet, Alter ab 1 Millionen Jahre zu bestimmen.

Die Kalium-Argon-Methode nutzt die Zerfallsprodukte des Kaliums. Kalium selbst kommt in der Natur in Form von drei Isotopen vor: K (93,26 %), K (0,012 %), K (6,73 %).

Das radioaktive K zerfällt mit einer Halbwertszeit von 1,277 · 10 Jahren zu Ar und Ca. Das selten auftretende Ar wird für die Altersbestimmung verwendet. Ca kommt als Isotop des Calciums sehr häufig vor, so dass die Entstehung von zusätzlichem Ca aus dem Zerfall von Kalium kaum messbar ist und sich daher für Altersbestimmungen nicht eignet.

Zur Bestimmung des Ar-Gehaltes eines Gesteins muss das Gestein geschmolzen werden. In dem dabei austretenden Gas wird das Edelgas Ar bestimmt. Wenn auch der K-Gehalt des Gesteins bestimmt ist, lässt sich aus der Veränderung des Verhältnisses von K zu Ar zwischen der Zeit der Gesteinentstehung bzw. –erstarrung und dem Zeitpunkt der Bestimmung des Verhältnisses im Labor das Alter des Gesteins berechnen.

Durch die relativ lange Halbwertszeit von 1,28 · 10 Jahren eignet sich diese Methoden für Gesteine, die älter als ca. 100 000 Jahre sind.

Die Ar/Ar-Methode nutzt die Entstehung von Ar aus K durch Neutronenbeschuss einer Gesteinsprobe in einem Reaktor. Nach dem Beschuss wird das Verhältnis der beim folgenden Schmelzen einer Gesteinsprobe austretenden Isotope Ar und Ar bestimmt.

Wie bei der Kalium-Argon-Methode ist Ar das Tochterisotop. Da die Isotopenverhältnisse des K bekannt sind, kann Ar, das bei dem Zerfall von K durch Neutronenbeschuss entsteht, als Ersatz für das K-Mutterisotop verwendet werden.

So ist lediglich das Verhältnis von Ar zu Ar im austretenden Gas zu bestimmen. Analysen anderer Isotope durch weitere Analysemethoden sind nicht erforderlich.

Die besonders zur Altersbestimmung organischen Materials erdgeschichtlich jüngeren Materials geeignete Radiokohlenstoffmethode nutzt den Zerfall des durch kosmische Strahlung in der höheren Atmosphäre entstandenen C (Halbwertszeit: 5730 Jahre). Sie ist für geologische Zwecke nur dann geeignet, wenn kohlenstoffhaltige Objekte datiert werden sollen, die weniger als ca. 50.000 Jahre alt sind. Damit ist sie auf das Quartär begrenzt.

Die Hauptanwendungsgebiete der Radiokarbonmethode sind die Archäologie, die archäologische Stratigraphie sowie die Historische Klimatologie.

Die Altersbestimmung mit Hilfe der Oberflächenexpositionsdatierung über das Aluminiumisotop Al und das Berylliumisotop Be im Mineral Quarz (SiO) basiert auf dem (bekannten) Verhältnis von Al und Be, die beide durch kosmische Strahlung (Neutronen-Spallation, Myonen-Einfang) an der Oberfläche von Steinen/Mineralen entstehen. Das Verhältnis ist abhängig u. a. von der Höhenlage, der geomagnetischen Breite, der Strahlungsgeometrie und einer möglichen Schwächung der Strahlung durch Abschirmungen (Verbringung, Bedeckung). Die spezifischen Strahlungsbedingungen und damit das Verhältnis von Al zu Be müssen vor der Altersbestimmung festgelegt bzw. abgeschätzt werden können.

Ab dem Zeitpunkt, zu dem das in Frage kommende Material vor der kosmischen Strahlung abgeschirmt wurde (z. B. durch Einlagern in eine Höhle), nimmt der Anteil der beiden Radionuklide durch radioaktiven Zerfall unterschiedlich schnell ab, sodass sich aus dem Verhältnis dieser Radionuklide zum Zeitpunkt der Untersuchung und dem angenommenen (bekannten) Gleichgewichtsverhältnis unter Bestrahlung und Kenntnis der jeweiligen Halbwertszeiten (siehe auch Nuklidkarte) das Alter abschätzen lässt.

Diese Methode wurde auch zur Bestimmung des Alters von fossilen Hominiden-Knochen genutzt. Allerdings können die Knochen nicht direkt untersucht werden, sondern es werden die sie umgebenden Quarz enthaltenden Sedimente herangezogen.

Samarium 146 wandelt sich über Alphazerfall in Neodym 142 um. Die lange Halbwertszeit des Samarium erlaubt Altersbestimmungen geologischer Zeiträume. Vor 2012 vermutete man eine Halbwertszeit des Samarium von 103 Mio Jahren. Vermutlich ist sie mit 68 Mio Jahren deutlich kürzer. Aus dem gemessenen Verhältnis zum stabilen Isotop Sm144 von 0,007 und einem Ausgangsverhältnis von 0,0094 folgt ein Alter für die Erde von 4,57 Mrd. Jahren.

Tritium (H) ist ein natürliches Isotop des Wasserstoffs und zerfällt mit einer Halbwertzeit 12,32 Jahren. Durch die atmosphärischen Kernwaffentests in den 1950er und zu Beginn der 1960er Jahre wurden große Mengen Tritium in der Atmosphäre freigesetzt.

Durch Niederschlag gelangte dann Tritium in Oberflächengewässer und oberflächennahes Grundwasser. Die Abnahme der Tritiumkonzentration durch Verdünnung und radiologischem Zerfall ermöglicht die Bestimmung des Alters eines Wasser, d. h. dessen Eintrags über den Niederschlag bzw. dessen Verweilzeit im Grundwasserleiter sofern mögliche Verdünnung durch vorhandenes Wasser oder andere Zuströme abgeschätzt werden können.

Mit der Tritiummethode ist die Bestimmung der Verweilzeiten des Grundwasser von einigen Jahren bis zu mehreren Jahrzehnten möglich. Voraussetzung ist, dass dieser Eintrag nicht vor den atmosphärischen Kernwaffentests stattfand.






</doc>
<doc id="2101" url="https://de.wikipedia.org/wiki?curid=2101" title="Gerhard Schröder (CDU)">
Gerhard Schröder (CDU)

Gerhard Schröder (* 11. September 1910 in Saarbrücken; † 31. Dezember 1989 in Kampen auf Sylt) war ein deutscher Politiker (CDU). Der Jurist war von 1953 bis 1961 Bundesminister des Innern, von 1961 bis 1966 Bundesminister des Auswärtigen und von 1966 bis 1969 Bundesminister der Verteidigung.

Schröder galt als dynamisch und kompetent, aber distanziert. Als Außenminister prägte er insbesondere die Ostpolitik und die Partnerschaft der Bundesrepublik Deutschland zu den USA und Großbritannien (Westintegration). Bei der Wahl des deutschen Bundespräsidenten 1969 unterlag er mit dem bisher knappsten Ergebnis einer Bundesversammlung dem SPD-Kandidaten Gustav Heinemann.

Gerhard Schröder wurde 1910 als ältestes von drei Kindern des aus Ostfriesland stammenden Eisenbahnbeamten Jan Schröder und der Antina Schröder, geborener Duit, in Saarbrücken geboren. Er besuchte humanistische Gymnasien (das Ludwigsgymnasium in Saarbrücken, ein Gymnasium in Friedberg, das Landgraf-Ludwigs-Gymnasium Gießen) und absolvierte das Abitur am heutigen Max-Planck-Gymnasium in Trier im Jahr 1929.

Schröder nahm nach seinem Abitur das Studium der Rechtswissenschaft an der Albertus-Universität Königsberg auf, da er fern seines Heimatortes neue Erfahrungen sammeln wollte.
Später studierte er zwei Semester an der University of Edinburgh, wo ihn die britische Lebensart beeindruckte, der er sich zeitlebens verbunden fühlte.
Ab Sommer 1931 war er Student in Berlin, wo er die teilweise blutigen Auseinandersetzungen der politischen Kontrahenten in der Endphase der Weimarer Republik erlebte, und wechselte bald darauf an die Universität Bonn. In dieser Zeit engagierte er sich hochschulpolitisch und war Mitglied der Hochschulgruppe der DVP. Für diese zog er auch in den AStA der Universität ein.

In Bonn schloss Schröder das Jurastudium 1932 mit dem ersten und 1936 mit dem zweiten juristischen Staatsexamen ab.

1934 wurde er zum Dr. jur. promoviert. Seine Dissertation mit dem Titel "Die außerordentliche Auflösung von Tarifverträgen" war vor der Machtergreifung der Nationalsozialisten verfasst worden, so dass sie nach der neuen, von den Nationalsozialisten erlassenen Gesetzgebung überholt und nur noch Makulatur war. Die Universität befreite ihn daher von der Verpflichtung, die Doktorarbeit drucken zu lassen.

Ab 1933 war er zunächst Assistent an der Juristischen Fakultät der Universität Bonn. Von Oktober 1934 bis 1936 war er Referent am Kaiser-Wilhelm-Institut für ausländisches und internationales Privatrecht in Berlin. 1935 musste er das Referendarlager "Hanns Kerrl" bei Berlin für drei Monate besuchen, wo ihm nach eigenem Bekunden die politische Indoktrinierung missfiel. 1936 dann wurde er Anwaltsassessor in einer großen Kanzlei, deren Mitarbeiter überwiegend Juden waren. Sein Kanzleichef und späterer Partner, Walter Schmidt, bescheinigte ihm im Entnazifizierungsverfahren, dass er damals jüdischen und anderen verfolgten Mandanten zur Seite gestanden habe, so dass er des Öfteren mit dem Nationalsozialistischen Rechtswahrerbund, dem er unter der Mitgliedsnummer 013115 angehörte, Probleme gehabt habe. 1939 wurde er Rechtsanwalt mit der Spezialisierung auf Steuerrecht.

Im September 1939 wurde er zur Wehrmacht eingezogen und in der Nähe von Berlin zum Funker ausgebildet. Von September 1940 bis Mai 1941 erhielt er eine Freistellung von der Wehrmacht und war während dieser Zeit in seiner Kanzlei in Berlin tätig. Daraufhin wurde er ins besetzte Dänemark nach Silkeborg und auf die Insel Fanø kommandiert. Im Russlandfeldzug geriet er in den Kessel von Cholm und wurde dort durch einen Granatsplitter im rechten Unterschenkel verletzt, so dass er bis 1943 kriegsuntauglich war. Nach seiner Genesung wurde er als Funklehrer (zuletzt im Dienstgrad Unteroffizier) in der Nähe von Berlin eingesetzt und ergab sich den US-amerikanischen Truppen 1945 bei Calbe. Er wurde in einem britischen Kriegsgefangenenlager bei Bad Segeberg interniert und war dort Übersetzer. Bereits im Juni 1945 wurde er aus der Kriegsgefangenschaft entlassen.

Seine Ehefrau Brigitte Schröder, deren Bruder ein Freund und Studienkollege Schröders war, galt nach den Nürnberger Gesetzen aufgrund ihrer teilweise jüdischen Herkunft als „Mischling“. Die Hochzeit war daher nur mit einer Ausnahmegenehmigung der Wehrmacht möglich. Schröder musste schriftlich auf eine militärische Karriere verzichten, so dass er in der Wehrmacht lediglich den Rang eines Obergefreiten bekleidete. Die Hochzeit fand im Mai 1941 als Ferntrauung statt.
Gerhard und Brigitte Schröder hatten drei Kinder:

Nach seiner Entlassung aus der Kriegsgefangenschaft traf er seine Frau, die mit den gemeinsamen Kindern vom Rittergut ihrer Eltern in Schlesien vor der Roten Armee geflohen war, in Hamburg wieder. Dort lebten sie zunächst bei seinen Eltern. Sein Vater Jan starb am 24. November 1945.

Noch 1945 bewarb sich Schröder beim Oberpräsidenten der Rheinprovinz, Hans Fuchs, in Düsseldorf und erhielt eine Anstellung als Oberregierungsrat. Diese behielt er auch, nachdem die britische Besatzungsmacht Fuchs durch Robert Lehr ersetzt hatte. In dieser Zeit knüpfte er auch Kontakte zu Konrad Adenauer und Kurt Schumacher.

Zum Jahreswechsel 1945 auf 1946 wurde er Leiter des deutschen Wahlrechtsausschusses in der britischen Besatzungszone. Dieser Ausschuss hatte die Aufgabe, der britischen Besatzungsmacht Vorschläge zum Ablauf der ersten Kommunalwahlen zu unterbreiten.

Mit der Gründung des Landes Nordrhein-Westfalen wurde er ins Innenministerium versetzt und war dort auch für Wahlfragen auf Landesebene zuständig. Mit dem damaligen SPD-Minister Walter Menzel kam es zu keiner konstruktiven Zusammenarbeit, was maßgeblich an dessen Festhalten am Verhältniswahlrecht lag, während Schröder ein Mehrheitswahlrecht favorisierte. Als ein ehemaliges Mitglied der SS namens Hans-Walter Zech-Nenntwich, der unter seinem neuen Namen "Nansen" als britischer Agent tätig war, Berater des Innenministers wurde, sorgte Schröder für dessen Entlassung, quittierte aber selbst daraufhin den Dienst, da das Vertrauensverhältnis zu seinem Dienstherren nicht mehr gegeben war. Zech-Nenntwich wurde später wegen Kriegsverbrechen rechtskräftig verurteilt.

Ab 1947 arbeitete er bis 1953 als Rechtsanwalt und als Abteilungsleiter bei der „North German Iron and Steel Control“ (NGISC). Er war der Berater von Heinrich Dinkelbach, dem Chef der NGISC. Er war in dieser Zeit auch Mitglied der Aufsichtsräte zweier Stahlunternehmen geworden, des Hüttenwerkes Haspe AG in Hagen und der Duisburger Ruhrort-Meiderich AG. Aus dieser Zeit stammte auch seine Ablehnung gegenüber der KPD, die in beiden Aufsichtsräten stark vertreten war.

1948 wurde Elisabeth Nuphaus seine engste Mitarbeiterin, die bei ihm bis 1980 tätig gewesen ist.

Am 1. April 1933 trat Schröder unter der Mitgliedsnummer 2177050 in Bonn in die NSDAP ein. Auf Drängen des Präsidenten des Oberlandesgerichts wurde er gemeinsam mit allen anderen Referendaren auch Mitglied der SA. Beim Wechsel nach Berlin 1934 erneuerte er seine Mitgliedschaft jedoch nicht. Am 1. Mai 1941 trat Schröder aus der NSDAP aus.

1945 gehörte Schröder zu den Mitbegründern der CDU. In der Zeit bis 1949 galt er als führender Wahlrechtsexperte in seiner Partei und leitete daher 1948 den "Arithmetischen Ausschuss", der der CDU das Eintreten für ein Mehrheitswahlrecht empfahl.

Von 1950 bis 1979 gehörte er dem geschäftsführenden Vorstand der Rheinischen CDU an.

Von 1967 bis 1973 war er Stellvertretender Bundesvorsitzender seiner Partei. Er wurde auf dem Bundesparteitag in Braunschweig mit 405 von 562 Stimmen gewählt, es war das beste Ergebnis der fünf gewählten Stellvertreter Kiesingers. Im November 1970 wurde er in diesem Amt bestätigt, aber mit dem schlechtesten Ergebnis der gewählten Kandidaten.

Auf dem Bundesparteitag in Saarbrücken 1971 hatte er mit Helmut Kohl abgesprochen, dass er dessen Kandidatur zum Parteivorsitz aktiv unterstützen wolle und im Gegenzug der Kanzlerkandidat der Union bei der nächsten Bundestagswahl zu werden. Hauptkonkurrent war Rainer Barzel, der gleich nach beiden Posten strebte, um diese mit seinem Fraktionsvorsitz zu vereinigen. Im entscheidenden Augenblick zögerte Schröder mit seiner Unterstützung für Kohl und wurde in der Folge auch nicht der nächste Kanzlerkandidat.

Bei der Bundestagswahl 1972 gehörte Schröder neben Franz Josef Strauß und Hans Katzer zur Kernmannschaft des CDU-Kanzlerkandidaten Rainer Barzel und vertrat die Bereiche Außen- und Sicherheitspolitik.

Im Mai 1952 wurde in Siegen der Evangelische Arbeitskreis von CDU und CSU gegründet, um die katholisch dominierte Union interkonfessionell zu öffnen. Nachdem die beiden ersten Sprecher des EAK, Hermann Ehlers und Robert Tillmanns, 1954 respektive 1955 im Amt verstorben waren, wählten am 2. Dezember 1955 die Delegierten einstimmig Gerhard Schröder in Abwesenheit zu ihrem neuen Sprecher. Schröder besaß innerhalb der CDU zuvor keine eigene "Hausmacht", so dass er sich durch dieses Amt weiter im innersten Zirkel der Parteispitze festsetzen konnte. Seit dieser Zeit fiel sein Name auch öfters spekulativ in den Medien als ein möglicher Kanzlerkandidat der Union. Schröder war einer der wichtigsten Repräsentanten des protestantischen Teils der Union und von 1955 bis 1978 durchgehend Sprecher des EAK. Sein Nachfolger wurde der spätere Bundespräsident Roman Herzog.

Da Theodor Heuss für eine dritte Amtszeit als Bundespräsident, die einer Verfassungsänderung bedurft hätte, nicht zur Verfügung stand, musste von der Union ein neuer Kandidat gefunden werden. Schröder wurde im Januar 1959 zu sondierenden Gesprächen zu Ludwig Erhard geschickt, ob dieser nicht für das höchste Staatsamt bereitstehen würde. Erhard winkte aber ab. Daraufhin gehörte Schröder dem 16-köpfigen Auswahlgremium der beiden Unionsparteien an, das am 24. Februar 1959 Erhard als Kandidaten für das Amt des Bundespräsidenten vorschlug. Dieser lehnte jedoch erneut ab.

Als Kanzler Adenauer dann sich selbst als Kandidaten für das Bundespräsidentenamt ins Spiel brachte, war Schröder sofort für diese Option. Als sich aber herausstellte, dass sich Ludwig Erhard gestützt auf die Bundestagsfraktion und die öffentliche Meinung als Kanzlerkandidat sah, verwarf Adenauer seine eigene Kandidatur auch zum Leidwesen Schröders wieder. Es deutete sich bereits der aufziehende Kampf zwischen Erhard und Adenauer um Adenauers Nachfolge an, da Letzterer mit allen zur Verfügung stehenden Mitteln Erhard als Bundeskanzler verhindern wollte. Schröder verhielt sich bei aller Sympathie zu Erhard in dieser Zeit immer auch loyal zu Adenauer, der in dieser Parteikrise sehr viel von seiner Reputation einbüßte. Eine Umfrage des Emnid-Meinungsforschungsinstituts ergab zu diesem Zeitpunkt bei der Kanzlerfrage eine Mehrheit für Ludwig Erhard von 51 Prozent zu 32 Prozent für Konrad Adenauer.

Da Adenauer nun nach Alternativen zu Erhard suchte, rückte Schröder das erste Mal in seinen Fokus, als er ihn einigen Parteifreunden neben Kai-Uwe von Hassel und Heinrich Krone als möglichen Herausforderer Erhards ankündigte.

Von 1949 bis 1980 war Schröder Mitglied des Deutschen Bundestages.

Durch seine vorherige Arbeit bei der Stahltreuhandverwaltung geprägt, setzte sich Schröder innerhalb der CDU-Bundestagsfraktion für das Betriebsverfassungsgesetz ein, das am 14. November 1952 beschlossen wurde.

1952 gehörte Schröder zu einer Gruppe von 34 Abgeordneten der CDU/CSU-Fraktion, die einen Gesetzentwurf zur Einführung des relativen Mehrheitswahlrechts in den Bundestag einbrachten, womit sie allerdings die Stabilität der Koalition gefährdeten, da die kleineren Parteien ein Mehrheitswahlrecht nicht unterstützten. Schröder brachte daraufhin einen Antrag ein, der eine Sperrklausel bei Bundestagswahlen vorsah. Das heute gültige Wahlrecht zum Bundestag basiert auf seinem Antrag.

Vom 24. Juni 1952 bis zum 20. Oktober 1953 war er stellvertretender Fraktionsvorsitzender der CDU/CSU-Bundestagsfraktion. Dieses Amt gab er auf, als er Bundesinnenminister wurde.

Von März bis Mitte April 1953 folgte er mit einigen jungen Politikern der Regierungskoalition einer Einladung des State Departments in die USA. Diversen Besuchen bei dortigen Regierungsbehörden und auch militärischen Einrichtungen folgte eine kurze Audienz beim damaligen Präsidenten der Vereinigten Staaten, Dwight D. Eisenhower.

Von 1969 bis 1980 war er Vorsitzender des Auswärtigen Ausschusses. In dieser Eigenschaft war er der erste bundesdeutsche Spitzenpolitiker, der eine Einladung in die Volksrepublik China erhielt. Dort verhandelte er vom 13. bis 29. Juli 1972 mit dem chinesischen Premierminister Zhou Enlai über die später erfolgte Aufnahme von diplomatischen Beziehungen.

Ebenso reiste er in dieser Eigenschaft im Januar 1971 das erste Mal in die UdSSR nach Moskau. Trotz des Besuches übte Schröder im Bundestag scharfe Kritik an den Ostverträgen.

Ebenso traf er 1971 mit dem neuen US-Präsidenten Richard Nixon zusammen, um über die Entspannungspolitik zu diskutieren. Nixon und Schröder kannten sich noch aus ihrer Zeit als US-Vizepräsident bzw. Bundesinnenminister.

Am 27. April 1972, als die CDU/CSU-Fraktion das erste konstruktive Misstrauensvotum in den Deutschen Bundestag einbrachte, antwortete er dem damaligen Bundesaußenminister Walter Scheel auf dessen Rede zur Außenpolitik der sozialliberalen Koalition und begründete damit außenpolitisch den Antrag der CDU/CSU-Fraktion auf Abwahl der Regierung Brandt und Wahl Rainer Barzels.

Ein umstrittenes Treffen hatte er Ende 1974 als Vorsitzender des Auswärtigen Ausschusses mit Jassir Arafat, das in der sozialliberalen Regierungskoalition, aber auch innerparteilich umstritten war.

Bei der Debatte um die Ostverträge war Schröder ein Warner vor zu großer Euphorie in der Entspannungspolitik; obwohl er sie befürwortete, sah er in ihr nicht den Schlüssel zur Deutschen Einheit.
Nachdem Rainer Barzel den Fraktions- und Parteivorsitz am 9. Mai 1973 niedergelegt hatte, was Schröder sehr bedauerte, kandidierte Schröder am 17. Mai 1973 gegen seinen ehemaligen Staatssekretär Karl Carstens um dieses Amt und wieder gegen Richard von Weizsäcker. Er unterlag aber deutlich mit 28 Stimmen bei 58 Stimmen für Weizsäcker und 131 für Carstens, den Helmut Kohl favorisierte. Diese Niederlage war das Ende seines Spitzenpolitikerdaseins, denn er wurde nie mehr für wichtige Ämter in Erwägung gezogen und rutschte ab in den Status des "Elder statesman".

Schröder gehörte neben Ludwig Erhard, Hermann Götz (beide CDU), Richard Jaeger, Franz Josef Strauß, Richard Stücklen (alle CSU), Erich Mende (FDP, später CDU), Erwin Lange, R. Martin Schmidt und Herbert Wehner (alle SPD) zu den zehn Abgeordneten, die seit der Bundestagswahl 1949 dem Parlament 25 Jahre ununterbrochen angehörten.

Schröder ist der Vorsitzende des Auswärtigen Ausschusses, der mit elf Jahren die längste Amtszeit innehatte, sein Nachfolger wurde sein ehemaliger Weggefährte Rainer Barzel.

Gerhard Schröder ist zuletzt über die Landesliste Nordrhein-Westfalen (1969, 1972 und 1976) und davor stets als direkt gewählter Abgeordneter des Wahlkreises Düsseldorf-Mettmann bzw. Düsseldorf-Mettmann II (1965) in den Bundestag eingezogen. Diesen Wahlkreis sollte ursprünglich der ehemalige Zentrumspolitiker Richard Muckermann erhalten, aber die Delegierten wählten mit großer Mehrheit Schröder, da der katholische Muckermann in dem stark evangelisch geprägten Wahlkreis vermutlich chancenlos gewesen wäre. Bei der ersten Wahl (1949) hatte Schröder noch keine Listenabsicherung.

In seinem ersten Bundestagswahlkampf 1949 war sein Wahlkampfslogan "Für Gesundheit-Arbeit-Frieden". Er gewann den Wahlkreis mit 34,1 % der Stimmen und einem Vorsprung von 2,7 Prozentpunkten vor seinem sozialdemokratischen Kontrahenten.

Bei der Wahl zum 2. Deutschen Bundestag erhielt er als Wahlkreiskandidat 52 Prozent der Erststimmen und somit rund vier Prozentpunkte mehr als die CDU an Zweitstimmen, 1957 erreichte er sein bestes Ergebnis an Erststimmen mit 54,2 Prozent und damit auch das beste Ergebnis, das je ein Kandidat in diesem Wahlkreis erzielen konnte. 1961 erhielt er 44,9 Prozent der Erststimmen (zum Vergleich: die Union erhielt 45,3 % der Zweitstimmen). 
In diesem Wahlkampf trat er als Vertreter Adenauers in der Fernsehsendung "Unter uns gesagt" von Kurt Wessel auf. Ludwig Erhard war verstimmt, das nicht er als Vizekanzler in die Sendung eingeladen wurde.

Bei der Bundestagswahl 1965 gelang es Schröder ein letztes Mal, seinen Wahlkreis mit 48,6 Prozent der Erststimmen klar zu behaupten. Bei der Bundestagswahl 1969 konnte Schröder, bei deutlichen Stimmengewinnen der SPD, das erste Mal seinen Wahlkreis nicht verteidigen. Er zog trotzdem in den Bundestag ein, da er auf der Landesliste Nordrhein-Westfalens den ersten Platz erhalten hatte.

Bei den Bundestagswahlen 1972 und 1976 kandidierte er nur noch auf der Landesliste. 1972 war er auf dem zweiten Listenplatz hinter Kanzlerkandidat Barzel und 1976 auf dem sechsten Platz.

1980 wollte Schröder erneut über einen Platz auf der Landesliste in den Bundestag einziehen. Er wurde aber aus drei Gründen nicht nominiert: durch die verlorene Landtagswahl in Nordrhein-Westfalen 1980 hatte die CDU NRW einen Kandidatenüberschuss; der Kanzlerkandidat der Union, Franz Josef Strauß, wollte seinen unionsinternen Intimfeind nicht im 9. Bundestag sehen und der CDU-Vorsitzende Helmut Kohl war nur mäßig an Schröder im Bundestag interessiert. So wurde Schröder mit relativ ruppigen Mitteln von der Landesliste getilgt und mit Ablauf der Legislaturperiode endete seine Zeit im Bundestag.

Am 20. Oktober 1953 wurde Schröder von Bundeskanzler Konrad Adenauer in das Amt des Bundesministers des Innern berufen. Ausschlaggebend dafür waren Schröders erfolgreiches Ergebnis in seinem Wahlkreis bei der zweiten Bundestagswahl, die zunehmenden Alterserscheinungen seines Vorgängers, seine relative Jugend und seine juristische Ausbildung. Zudem war Schröder Protestant und in den ersten Jahren wurde die Position des Bundesinnenministers ausschließlich an protestantische Politiker vergeben, um eine gewisse Parität zwischen den Konfessionen im Kabinett zu wahren. Damit wurde er Nachfolger seines ehemaligen Vorgesetzten Robert Lehr.

Am 17. Juli 1954 trat die zweite Bundesversammlung in West-Berlin zur Wiederwahl von Bundespräsident Theodor Heuss zusammen. Am 20. Juli gab es zum 10. Jahrestag des Attentats auf Adolf Hitler eine Gedenkstunde in Berlin. Schröder war aus terminlichen Gründen schon vorab nach Bonn gereist, um die siegreiche deutsche Fußballnationalmannschaft nach dem Wunder von Bern als zuständiger Bundesminister für den Sport zu empfangen. Der Präsident des Bundesamts für Verfassungsschutz Otto John war als ehemaliger Widerstandskämpfer anwesend und reiste in der Nacht in die DDR. Schröder vertrat lange den Standpunkt, John müsse entführt worden sein, und lobte eine Belohnung in Höhe von 500.000 DM für Hinweise aus. Die meisten Bonner Politiker waren jedoch schon früh der Ansicht, dass John freiwillig in die damalige SBZ geflohen sei. Der Bundestagsausschuss zum Schutz der Verfassung, der von Schröders ehemaligen Vorgesetzten Walter Menzel geleitet wurde, mit dem Schröder eine enge Feindschaft verband, stellt mit der SPD-Bundestagsfraktion einen Missbilligungsantrag gegen Schröder und forderte einen Untersuchungsausschuss. Die FDP war sich zu dieser Zeit nicht sicher, ob sie Schröder stützen wollte. Das zeitgleiche Scheitern der Europäischen Verteidigungsgemeinschaft nötigte sie jedoch dazu, die Koalition zu halten und folglich Schröder zu unterstützen, so dass der Missbilligungsantrag keine Mehrheit fand und der Untersuchungsausschuss zwei Jahre später kein Fehlverhalten Schröder attestieren konnte. Nach Johns Rückkehr in die Bundesrepublik im Dezember 1955 und seiner Verurteilung wegen Landesverrats setzte sich Schröder bei Theodor Heuss für seine – 1958 erfolgte – Begnadigung ein. Durch die Ereignisse um John sensibilisiert, war Sicherheit Schröders oberste Prämisse. Er erwarb sich bald den Ruf eines Law-and-Order-Politikers.

Zu Beginn von Schröders Amtszeit bestand als einzige bewaffnete Kraft im Staat, die der Bundesregierung unterstand, nur der Bundesgrenzschutz. Durch die Ereignisse des Aufstandes in der DDR wurde der Bundesgrenzschutz von 10.000 Mann auf das Doppelte aufgestockt. Mit Gründung der Bundeswehr wurde der personelle Bestand dieser Truppe von großen Teilen des BGS freiwillig gestellt. Schröder erreichte in den Verhandlungen dazu, dass der BGS nicht vollständig in der Bundeswehr aufging und die Sollstärke der Truppe bald wieder erreicht wurde.

Schröder setzte einen Verbotsantrag gegen die KPD durch. Bereits sein Amtsvorgänger hatte schon ein Verbotsverfahren gegen die Sozialistische Reichspartei erfolgreich durchgesetzt und damals zeitgleich einen Antrag zum Verbot der KPD eingebracht, der jedoch erst unter Schröders Ägide positiv entschieden wurde. Ein Amnestiegesetz für KPD-Funktionäre wurde von Schröder erfolgreich parlamentarisch bekämpft, obwohl SPD und FDP diesen Gesetzesentwurf stützten, da Herbert Wehner in der Debatte Schröder mit Andrei Wyschinski, dem sowjetischen Ankläger der stalinistischen Schauprozesse, verglich. Dieser Vorgang wurde von der CDU im Bundestagswahlkampf 1957 erfolgreich ausgeschlachtet.

Schröder legte besonderen Wert auf den Zivil-, Luft- und Bevölkerungsschutz. In der damaligen Zeit des Kalten Krieges mussten Einrichtungen für die Zivilbevölkerung geschaffen werden, um sie im Kriegsfalle möglichst abzusichern. Schröder unternahm deshalb 1957 eine ausgedehnte USA-Reise, um sich mit den dortigen Sicherheitsmaßnahmen vertraut zu machen. So wurden Katastrophenkrankenhäuser gebaut und in Materiallagern von BGS und Bund sich auf verschiedene Katastrophenzustände vorbereitet, um die Leiden der Zivilbevölkerung möglichst rasch zu lindern.

Als Ende der 50er Jahre der Bundestag durch die absolute Mehrheit der CDU- und CSU-Fraktion eine mögliche Bewaffnung der Bundeswehr mit Atomwaffen im Kriegsfall beschloss, formierte sich eine breite Front von SPD, GVP, DGB und FDP, um gegen dieses Gesetz unter dem Motto "Kampf dem Atomtod" mit einer Volksbefragung vorzugehen. Schröder war ein notorischer Gegner von plebeszitären Elementen in der Bundesrepublik, da er sie aus der Weimarer Zeit kannte und überzeugt war, dass extreme Parteien, wie die NSDAP und KPD, dieses verfassungsmäßige Mittel zum Kampf gegen die demokratische Republik genutzt hatten. Am 30. Juli 1958 gab das Bundesverfassungsgericht der Regierung recht und erkannte damit Volksbefragungen als nicht verfassungsmäßig an. Später entschied der NATO-Rat, dass nur die USA im Krisenfall über solch eine Maßnahme zu entscheiden hätten, wodurch das Gesetz bedeutungslos wurde.

Der Deutschlandvertrag zwischen der Bundesrepublik und den drei westalliierten Mächten sah ein Vorbehaltsrecht in Artikel 5 Absatz 2 vor, das den Alliierten die Möglichkeit gab, im Notfall die Kommandogewalt in Deutschland zu übernehmen. Schröders Ministerium erarbeitete auf Weisung von Bundeskanzler Adenauer schon 1958 erste Gesetzentwürfe, die der SPD frühzeitig bekannt gegeben wurden, da man zu dieser Grundgesetzänderung die Stimmen der SPD-Fraktion des Bundestages und die der SPD-geführten Bundesländer brauchte. Durch die Berlin-Krise bedingt wurde die Gesetzesinitiative gehemmt. Schlussendlich kam es nicht zur Abstimmung über die Notstandsgesetze, da die SPD nicht dafür stimmen wollte. Aus einem vertraulichen Brief eines SPD-Funktionärs erfuhr er, dass die Führung der SPD nie ernsthaft vorhatte, seinen Gesetzentwurf zu unterstützen, und deswegen hinhaltend verhandelt hatte, um das Ergebnis der Bundestagswahl 1961 mit ihrem frischen und verhältnismäßig jungen Kanzlerkandidaten Willy Brandt abzuwarten.

Bundeskanzler Adenauer sah sich und seine CDU bei der Kontrolle der ARD ins Hintertreffen geraten. Die Kontrolle übten nur die Bundesländer über ihre eigenen Rundfunkanstalten aus. Die Exekutive des Bundes hatte nahezu keine Eingriffsmöglichkeiten. Adenauer ließ daher am 25. Juli 1960 in privatrechtlicher Rechtsform die Deutschland-Fernsehen-GmbH mit Sitz in Köln gründen. Die SPD-geführten Bundesländer Hamburg, Bremen, Niedersachsen und Hessen riefen das Bundesverfassungsgericht an, das mit dem 1. Rundfunk-Urteil vom 28. Februar 1961 Adenauers Pläne blockierte. In der Folge wurde dann das ZDF 1962 gegründet. Schröder galt als Verfechter des Adenauer-Fernsehens, da er als „Zentralist“ die Macht der Bundesländer gerne beschnitten hätte.

Schröder scheiterte vor Gericht mit dem Versuch, die Vereinigung der Verfolgten des Naziregimes zu verbieten. Ebenso scheiterte seine Absicht, eine Bündelung der Landtagswahlen festzusetzen, am Widerstand der Landesregierungen.

Schröders Initiative, im Bundestag ein Ein- und Ausreisegesetz zur DDR zu verabschieden, gelang nicht, wobei die DDR 1961 mit dem Mauerbau dafür sorgte, dass der Gesetzentwurf obsolet wurde.

Gerhard Schröder ist bis heute immer noch der Bundesinnenminister mit der längsten Amtszeit, sowohl in direkter Folge als auch insgesamt.

Nach der Bundestagswahl 1961 brauchte die Union einen Koalitionspartner, um regieren zu können. Bundeskanzler Adenauer wurde mit der FDP schnell einig, wobei der neue Koalitionspartner unbedingten Wert darauf legte, dass Heinrich von Brentano als Bundesaußenminister abzulösen sei. Die FDP favorisierte für dieses Amt den damaligen Baden-Württembergischen Ministerpräsidenten Kiesinger, Adenauer hingegen seinen langjährigen Innenminister Schröder oder auch Walter Hallstein. Gleichzeitig mobilisierte die Berliner CDU alle Kräfte, um Schröder zu verhindern, da dieser in der Berlin-Krise und beim Mauerbau die schlechte strategische Position Berlins gerügt und sich für eine Totalaufgabe der Stadt ausgesprochen hatte, um einen eventuell aufziehenden Krieg zu verhindern, so dass von Berliner Seite wenig bis kein Vertrauen zu Schröder als Person und erst recht im Amt des Bundesaußenministers bestand. Ebenso war Bundespräsident Lübke nicht bereit, Schröder zum Außenminister zu ernennen. Der Einwand des damaligen Staatssekretärs im Auswärtigen Amt, Karl Carstens, dass es dem Bundespräsidenten nicht zustehe, einzelne Minister abzulehnen, sorgte für die Aufgabe von Lübkes Widerstand. Lübke war über Schröders Aussagen zur Berlin-Frage und zum Mauerbau gegen ihn eingenommen.

Trotzdem versuchte eine kleine katholische Gruppe in der Unionsfraktion um Karl Theodor zu Guttenberg, Bruno Heck und Heinrich Krone Heinrich von Brentano an seinem Rückzug vom Amt zu hindern, den Kanzler umzustimmen und einer große Koalition mit der Sozialdemokratie den Weg zu ebnen. Adenauer blieb bei seinen Entschlüssen und Schröder wurde am 14. November 1961 neuer Bundesaußenminister, wobei Bundespräsident Lübke Schröders Ernennungsurkunde demonstrativ als letzte unterzeichnete.

Schröder galt als Gewinner der neuen Regierungsbildung, da er das wichtigste Amt neben dem Bundeskanzler erhielt und sich dadurch positiv für seine weitere Karriere in Szene setzen konnte.

Schröder hatte mit Karl Carstens und Rolf Lahr zwei Staatssekretäre im Amt, mit denen er schnell harmonierte und deren Meinungen bei ihm großes Gewicht hatten. Diese Harmonie wurde wohl auch dadurch begünstigt, dass alle drei Norddeutsche und Protestanten waren.

Der Führungsstil im Ministerium änderte sich mit Schröders Amtsübernahme erheblich. So wurden in die Entscheidungen auch untere Fachkräfte mit Amtsrang eingebunden und die außenpolitischen Entscheidungen von Schröders engstem Stab mitunter auch seinen Sekretärinnen mitgeteilt, damit diese anderen Ministerien bei Nachfragen kompetent antworten konnten. Zudem fand jeden Tag eine Morgensitzung der Referatsleiter, meist unter dem Vorsitz der Staatssekretäre, statt, um die aktuellen außenpolitischen Ereignisse zu bewerten.

Schröder betrieb eine offene Personalpolitik, die sich an Leistung und Kompetenz orientierte und nicht am Parteibuch des Bewerbers. So konnten untere Ränge auch kritische Denkschriften an ihn richten und brauchten nicht fürchten, dadurch ihrer Amtskarriere zu schaden. Schröders kühle Unnahbarkeit schreckte viele Beamte ab, die sie oft fälschlicherweise für Arroganz hielten und viele Diskussionen mit ihm endeten bei der Durchsetzung Schröders Meinung, da er die Sachthemen oft besser beherrschte als die Fachbeamten. Um die Flexibilität der Entscheidungen des Auswärtigen Amts zu verbessern führte er dort als erster Minister einen Planungsstab ein.

Im Zuge der Berlin-Krise und des Mauerbaus führte Schröders erste Dienstreise als Außenminister ihn als Begleiter Adenauers nach Washington. Anders als Adenauer schenkte er der US-amerikanischen Taktik des Verhandelns mit der Sowjetunion und deren Satellitenstaaten mehr Vertrauen als der Bundeskanzler. Mit seinem US-amerikanischen Amtskollegen Dean Rusk verband ihn sehr schnell eine gute Freundschaft, die auf gegenseitigem Respekt beruhte.

Diese Tatsache, verbunden mit ersten Verhandlungsangeboten der USA an Moskau, veranlassten Adenauer, Gerhard Schröder und seine beiden Staatssekretären sowie Adenauers Intimus Hans Globke nach Cadenabbia zu zitieren, wo er traditionell Sommerurlaub machte. Dort musste Schröder sein erstes diplomatisches Entgegenkommen zur amerikanischen Seite zurücknehmen und sich der Richtlinienkompetenz des damals 85-jährigen Bundeskanzlers beugen.

Trotzdem erhoffte sich Schröder weiter im Laufe der damaligen Zeit mehr Mitbestimmung der Bundesrepublik auf die Verteidigungspolitik der NATO, gerade im Hinblick auf die europäischen Alliierten und deren damalige Zwistigkeiten mit den USA. Vor allem hoffte er, dass die Bundesrepublik auch Einfluss auf nukleare Verteidigungsmaßnahmen des Bündnisses bekam, denn Westdeutschland verfügte zwar über keine nuklearen Waffen, war aber gemessen an der Sollstärke seines Heeres das stärkste NATO-Mitglied in Europa.

Bei den Verhandlungen zum Teststoppabkommen schloss sich Schröder wieder der Meinung der Kennedy-Administration an und setzte auf den Verhandlungsweg. Adenauer brachte fast das ganze Bundeskabinett hinter sich, versuchte eine Ratifizierung des Abkommens auch durch die DDR zu verhindern, lehnte sich eng an Frankreich an, das dieses Abkommen bis heute nicht ratifiziert hat. Am Ende war der Riss zwischen Bundeskanzler und Außenminister kaum noch zu kitten und der Gegensatz zwischen den "Atlantikern" und "Gaullisten" in der CDU nahm besorgniserregende Formen an. Schröder setzte sich auch mit Unterstützung der SPD und FDP daraufhin erfolgreich für den Beitritt Deutschlands zum Abkommen ein.

Mit seinem französischen Amtskollegen Maurice Couve de Murville verband ihn keine Freundschaft und auch zum französischen Staatspräsidenten Charles de Gaulle kam es nie zu einem freundschaftlichen Ton. Schröder hielt die damalige französische Politik für die Bundesrepublik und die EWG für negativ, da er keine Integrationselemente in ihr fand. Schröder verstand die europäische Einigung und auch die deutsch-französische Aussöhnung als eine komplementäre Politik zur Bündnispolitik im Rahmen der NATO und Führung der USA. Aus diesem Grunde plädierte er auch im Bundeskabinett für die Aufnahme Großbritanniens in die EWG, um auch ein Gegengewicht zu Frankreich bereitzuhalten. Diese Politik rief bei Adenauer Protest hervor und er ließ ihm über Globke einen Brief zukommen, der Schröder an die Richtlinienkompetenz des Bundeskanzlers fesseln sollte. Der indirekte Versuch, Schröder damit zu einem Rücktritt zu provozieren, schlug jedoch fehl.

Großbritannien bewegte sich zu dieser Zeit wieder näher auf die USA zu, da man auf US-amerikanische Hilfe für Trägersysteme atomarer Sprengköpfe angewiesen war, nachdem die USA die Herstellung der zugesicherten AGM-48 Skybolt ohne Konsultation Londons eingestellt hatten. Diese Hinwendung Großbritanniens provozierte de Gaulle so sehr, dass er Adenauer einen bilateralen Vertrag vorschlug. Adenauer ergriff diese Möglichkeit, die am 23. Januar 1963 in den Élysée-Vertrag gipfelte, den Schröder auch mit unterzeichnen musste. Nach erfolgter Unterzeichnung erhielt Adenauer von de Gaulle eine Umarmung mit Kuss, beides verweigerte de Gaulle Schröder.

Die daraus resultierende französische Ablehnung eines Beitritts Großbritanniens zur EWG und damit auch Deutschlands Votum im Sinne Frankreichs, bestürzte die US-Administration, die fest mit einem baldigen Beitritts Großbritanniens gerechnet hatte, um zur NATO ebenso durch die EWG ein festes politisches und wirtschaftliches Bündnis in Westeuropa mit Großbritannien zu schaffen und somit der Sowjetunion einen zweiten Machtblock an deren Westgrenze zu präsentieren. Schröder schickte daraufhin Staatssekretär Carstens als "Troubleshooter" nach Washington, um die dortigen Gemüter zu beruhigen.

1955 hatte die junge Bundesrepublik diplomatische Beziehungen zur UdSSR aufgenommen. Schröder lernte 1966 in Genf auch den sowjetischen Außenminister Andrei Andrejewitsch Gromyko kennen, mit dem ihn wenig Menschliches verband. Es gelang es ihm aber schon beim ersten Treffen, Gromyko seine Idee für bessere Handelsbeziehungen aufzuzeigen, obwohl die UdSSR sich zu dieser Zeit durch eine mögliche nukleare Bestückung der Bundeswehr bedroht fühlte. Er betonte dabei aber auch die bundesdeutsche Leitlinie der Außenpolitik, dass das erste Ziel die Verwirklichung der deutschen Einheit in Frieden sei.

Kurze Zeit darauf wurde das Außenministerium mit Indiskretionen des deutschen Botschafters in Moskau, Hans Kroll, konfrontiert. Dieser hatte den Globke-Plan gegenüber Pressevertretern ausgeplaudert. Schröder musste bei Adenauer mit seinem eigenen Rücktritt drohen, bis dieser schließlich Krolls Abberufung aus Moskau zustimmte. Dabei spielte möglicherweise auch eine Rolle, dass Kroll in Bonn über hochrangige Freunde verfügte, wie Heinrich Krone, Franz Josef Strauß, Erich Mende oder Erich Ollenhauer.

Schröder war einer der wenigen westdeutschen Politiker, der den Mauerbau emotionslos sah und nur als Ausdruck der Hilflosigkeit der DDR-Führung, ihre Bevölkerung im eigenen Land zu behalten.

Schröder versammelte Ende Mai 1962 einen kleinen Kreis von Mitarbeitern zu einer Strategietagung in der Abtei Maria Laach, um mit ihnen neue Wege in der Ostpolitik zu besprechen. Ohne die DDR anzuerkennen, so war man sich einig, sollten Handelsbeziehungen zu den Staaten des Warschauer Pakts aufgenommen werden. Der Handel sollte zu einer Annäherung und zu größerer Verständigung führen. Im Juni 1962 stellte er seine Thesen dem 11. Bundesparteitag der CDU in Dortmund vor. In der CDU war sein Programm sehr umstritten, gerade bei seinen stärksten Kritikern um von Guttenberg und Krone; FDP und SPD hingegen begrüßten diese neuen Akzente der bundesdeutschen Außenpolitik. So wurde Schröder, der von der Opposition und dem Koalitionspartner als Innenminister immer gemieden wurde, im Amt des Außenministers vertrauensvoller Kooperationspartner. Die erste Handelsniederlassung wurde am 7. März 1963 in Warschau nach erfolgreichem Vertragsabschluss eröffnet. Ende 1964 hatte man schon in fast allen Ostblockstaaten mit Ausnahme der DDR Handelsvertretungen eröffnen können.

Auf Druck der FDP musste Adenauer den Bundeskanzlerposten im Laufe der 4. Legislaturperiode (1961 bis 1965) an einen Nachfolger aus den Reihen der Union abgeben. Im Ringen um seine Nachfolge versuchte Adenauer, seinen Stellvertreter Ludwig Erhard mit allen Mittel zu verhindern. Es spielten sich dabei sehr unschöne Szenen seitens des Patriarchen ab, die die CDU in zwei Lager spaltete. Aus diesem Grunde kristallisierten sich Anfang der Legislaturperiode mehrere potentielle Gegenkandidaten zu Erhard heraus, darunter Franz Josef Strauß, Eugen Gerstenmeier, Heinrich von Brentano, Heinrich Krone und Gerhard Schröder. Im Verlauf des internen Machtkampfes erklärten Krone und Brentano sich einer Kandidatur gegenüber Erhard nicht mehr bereit, Gerstenmeier war nur als Kanzler einer großen Koalition zu haben, so dass nur noch Strauß und Schröder übrig blieben. Der Gegensatz der beiden Unionspolitiker zueinander verschärfte sich zusehends bis hin zur Spiegel-Affäre, die Strauß’ Anwartschaft auf eine etwaige Kanzlerkandidatur stoppte. Schröder, der mit der Spiegel-Affäre fast nichts zu tun hatte, distanzierte sich schnell vom damaligen Verteidigungsminister Strauß und war somit der einzige wirkliche Konkurrent einer Kanzlerkandidatur Erhards.

Der CDU-Abgeordnete Will Rasner versuchte alsbald, Schröder in der Unionsfraktion als Gegenkandidaten zu Erhard aufzubauen. Am 22. März 1963 tagte die Fraktion und Heinrich von Brentano eröffnete die Sitzung mit einem Referat, dass die Partei an Ludwig Erhard nicht vorbeikomme. Adenauer, der Erhard verhindern wollte, nutzte die Gelegenheit nicht, um Schröder als Kandidaten ins Spiel zu bringen. Vielleicht lag das auch daran, dass Schröder nicht offensiv genug gegen den Vizekanzler und dessen Kanzlerambitionen vorgegangen war, so dass Adenauer zu wenig Vertrauen in Schröder hatte. Erhard wurde schließlich unspektakulär ohne Gegenkandidat zum neuen Kanzlerkandidaten der Unionsfraktion gekürt.

Schröder sah (wie auch Strauß) in Erhard zu diesem Zeitpunkt nur einen Übergangskanzler, der die Bundestagswahl 1965 als "Wahlkampflokomotive" der Union gewinnen sollte und dessen Nachfolger baldmöglichst darauf zu küren sei, so dass beide ihre Ambitionen auf das Bundeskanzleramt vorerst zurücksteckten.

Schröder vermied es ebenso wie etwa Heinrich Krone oder Ernst Lemmer, der Nachwelt seine Sicht auf den Nachfolgestreit und die innerparteilichen Auseinandersetzung zu hinterlassen.

Adenauer und Schröder gingen in den letzten Monaten Adenauers im Amt stärker denn je getrennte Wege. Die Teststoppdebatte war der Höhepunkt der Entzweiung. Schröder nahm es Adenauer übel, dass dieser sich nicht für ihn bei der Kanzlernachfolgedebatte eingesetzt hatte, und Adenauer nahm es Schröder übel, dass dieser weiterhin einen pro-amerikanischen Kurs verfolgte und des Kanzlers Lieblingsbündnis mit Frankreich nicht mit dem Leben erfüllte, wie Adenauer es sich gewünscht hatte. Schriftliche Ermahnungen Adenauers wies Schröder in den letzten Kanzlertagen kurz und teilweise lapidar ab.

Dass sein Verhalten ihm selbst später von Schaden sein könnte, ahnte Schröder nicht. Adenauer blieb bis März 1966 Parteivorsitzender und bis zu seinem Tod im April 1967 die graue Eminenz der Union.

Mit der Amtsübernahme Ludwig Erhards als Bundeskanzler änderte sich für Schröder erst einmal wenig, da Erhard ihm in keiner Weise böse war, dass er zwischendrin ebenso als Kanzlerkandidat gehandelt worden war. Schröder war es auch, der Erhard zur Mäßigung anhielt, wenn dieser immer stärker den Kanzlerwechsel forderte. Politisch war Erhard ebenso wie Schröder ein Atlantiker und unterstützte die außenpolitischen Bemühungen seines Außenministers in dieser Richtung nach Kräften. Einzig Konrad Adenauer versuchte Heinrich von Brentano wieder als Außenminister zu installieren, fand jedoch in Partei, Fraktion, Koalitionspartner und beim neuen Bundeskanzler kein Gehör. Das Bundeskabinett wurde von Erhard nun fast vollständig übernommen bis auf Rainer Barzel als Bundesminister für gesamtdeutsche Fragen, der seinen Ministersessel für den FDP-Parteivorsitzenden und Vizekanzler Erich Mende hat räumen müssen und dafür in die Unionsfraktionsführung wechselte.

Kurz nach dem Kanzlerwechsel wurde der US-amerikanische Präsident Kennedy bei einem Attentat in Dallas getötet. Sein Nachfolger wurde Vizepräsident Lyndon B. Johnson. Nach Abschluss der Trauerfeierlichkeiten Kennedys lud Johnson Bundeskanzler Erhard und Außenminister Schröder auf seine Ranch nach Texas ein. Menschlich standen sich die Partner Johnson/Rusk und Erhard/Schröder sofort nahe und beide Seiten bekräftigten, dass sie wieder enger in den politischen Fragen zusammenrücken würden, jedenfalls mehr als es unter Adenauer der Fall war.

Nachdem sich aber zeigte, dass der deutscherseits geförderte Plan zu Aufstellung einer Multilateral Force (zu deutsch: Multilaterale (Atom-)Streitmacht) nach dem Wahlsieg der britischen Labour Party 1964 mit ihrem Premierminister Harold Wilson nicht durchzusetzen war, mussten Außenminister Schröder und Kanzler Erhard sich gegen erhöhten Druck in der eigenen Fraktion wappnen, denn die Gaullisten in der CDU-Fraktion warfen ihnen außenpolitisches Versagen vor. Versagt hatte aber vor allem der US-amerikanische Präsident Lyndon B. Johnson, der die eigentlich treibende Kraft hinter der der MLF war und der die Interessen seiner NATO-Partner nicht hatte bündeln können, denn sein Rückzieher vor dem Hintergrund innenpolitischer Probleme ließ die Bemühungen Gerhard Schröders im Sande verlaufen. Es war zu diesem Zeitpunkt nur der kommenden Bundestagswahl 1965 geschuldet und dem Einsatz des Unionsfraktionschefs Rainer Barzel zu verdanken, dass die Fraktion sich hinter der Regierung in dieser Frage sammelte, obwohl die Meinungen stark divergierten.

Der Devisenausgleich für die Stationierung US-amerikanischer Truppen in Deutschland lief vertraglich 1967 aus, die Kosten hatten den Bundeshaushalt in Schieflage gebracht, da zwei Milliarden Mark zur Bezahlung fehlten. Bundeskanzler Erhard unternahm daher im September 1966 eine Reise in die USA, um einen Aufschub der Zahlung zu erreichen, begleitet wurde er von Außen- und Verteidigungsminister. Die Verhandlungen mit US-Präsident Johnson verliefen sehr negativ, da dieser selbst unter innenpolitischem Druck stand, da das US-amerikanische Engagement in Vietnam nicht den gewünschten Erfolg brachte. Johnson verhandelte extrem hart und ließ der deutsche Regierungsdelegation kein Entgegenkommen zu.

Das Verhältnis zu Frankreich erhielt mit dem neuen Kanzler keinen neuen Schwung, wie etwa das zu den USA. Eher im Gegenteil trafen nun französische Interessen auf einen anglophilen Kanzler, der durch seinen Außenminister darin bestärkt wurde. Erhard und Schröder hatten Angst davor, dass Frankreich durch die wirtschaftliche Macht Deutschlands im Hintergrund nach einer politischen Hegemonie in Europa strebte. Das zeigte sich recht schnell bei den Verhandlungen zum EWG-Agrarmarkt und beim GATT-Abkommen, in denen die französische Regierung die deutsche Agrarpreispolitik vollständig zu ihren Gunsten brechen wollte. Als Schröder darin nicht nachgeben wollte, verweigerte Frankreich seinen Beitritt beim wirtschaftlich für Deutschland wichtigen GATT-Vertrag. Beides konnte zwar durch Nachverhandlungen geregelt werden, hinterließ aber bei beiden Regierungen einen üblen Beigeschmack.

Zur weiteren Verstimmung führte die Entführung von Antoine Argoud aus München nach Paris. Das Mitglied der OAS wurde höchstwahrscheinlich im Auftrage der französischen Regierung entführt, ohne dass die Bundesrepublik konsultiert oder auch nur informiert wurde. Schröder als ehemaligem Bundesinnenminister ging dieser Eingriff in die Souveränität der Bundesrepublik zu weit und er schrieb eine Protestnote an Frankreich. Gleichzeitig war Frankreich dabei, die Volksrepublik China anzuerkennen, wiederum ohne die Bundesrepublik zu konsultieren, wie es der Deutsch-Französische-Vertrag eigentlich forderte.

Schröders harte Haltung bei diesen Punkten wurde ihm von der Unionsfraktion negativ ausgelegt. Nicht nur der Kreis der "Gaullisten" um Adenauer, Guttenberg, Brentano und Krone versuchte, Schröder in Misskredit zu bringen, sondern auch Franz Josef Strauß nahestehende Kreise in der CSU. Einzig die französische Blockadehaltung der Politik des "leeren Stuhles" bei den EWG-Agrarverhandlungen brachte Schröder und seiner politischen Grundhaltung innerhalb der CDU wieder Auftrieb, da auch Gaullisten über diese Art der fast erpresserischen Politik enttäuscht waren.

Persönlich erschwerend kam für Schröder hinzu, dass die Pariser Administration ihn auf seiner Visite am 9. Dezember 1964 überaus herablassend behandelte. Offiziell musste sein Flugzeug eine Parkposition abseits des Empfangshauses auf dem Flughafen Orly einnehmen, da der Luftverkehr zu diesem Zeitpunkt es nicht zuließ, dort zu parken, so dass man vor einem Acker halt macht. Schröders spontane Reaktion darauf war: "„Wir sind doch nicht hierhergekommen, um Kartoffeln auszubuddeln.“" Daraufhin erschien ein klappriger Air France-Bus, woraufhin sich Schröder weigerte, den Flieger zu verlassen. Erst das Eintreffen einer Limousine und das Zureden der Stewardessen überzeugte ihn, das Fahrzeug zu besteigen. Für den Besuch des Außenministers einer eng befreundeten Nation war dieser Vorfall im schlimmsten Grade peinlich.

Einen weiteren Dämpfer erhielt das deutsch-französische Verhältnis durch de Gaulles einseitige Ankündigung eines Teilaustritts aus der NATO vom 21. Februar 1966. Frankreich wollte seine Streitkräfte im Ernstfall nicht mehr dem Oberbefehlshaber der NATO für Westeuropa unterstellen. Hintergrund dürfte die französische Angst gewesen sein, in den Vietnamkrieg hineingezogen zu werden. Diese einseitige Aktion wog umso schwerer, da bei ausführlichen Regierungsgesprächen, die Kanzler Erhard und Schröder wenige Wochen zuvor in Paris geführt hatten, die Bundesrepublik vertragswidrig nicht über den politischen Schritt informiert worden war. Schröder nahm daraufhin eine aggressive Verhandlungshaltung ein und stritt mit den Franzosen und dem eigenen Kabinett um den Verbleib der französischen Truppen in Deutschland. Seines Erachtens besaßen diese durch den Teilaustritt aus dem Verteidigungsbündnis mindere Rechte gegenüber den anderen NATO-Truppen auf deutschem Boden. Allerdings blieb Schröder unter dem Druck der eigenen Partei und des Kabinetts nicht lange hart und nahm bald eine versöhnlichere Haltung ein.

Der Historiker Henning Köhler urteilt: „Zu keinem Zeitpunkt ist die Außenpolitik der Bundesrepublik so kurzsichtig und einseitig betrieben worden wie unter Erhard und Schröder.“ "Gaullisten" und "Atlantiker" seien inhaltlich gar keine alternativen Positionen gewesen, sondern nur polemische Etikettierungen. In Wahrheit sei es darum gegangen, in selbstverständlicher Anerkennung der USA als Garantiemacht der bundesdeutschen Sicherheit die im Élysée-Vertrag begonnene Kooperation mit Frankreich zu vertiefen und weiter auszubauen. An dieser Aufgabe sei Schröder gescheitert.

Schon früh unter der Kanzlerschaft Erhards nahm der damals regierende Bürgermeister von Berlin, Willy Brandt, über seinen Intimus Egon Bahr Kontakt zur ostdeutschen Führung auf, um ein Passierscheinabkommen für die Weihnachtszeit 1963 für die West-Berliner Bevölkerung auszuhandeln. Solche außenpolitischen Eigenmächtigkeiten, die an eine Anerkennung der DDR grenzten, führten zu ersten Zerwürfnissen mit dem alten und zukünftigen Kanzlerkandidaten der SPD, denn der "Wandel durch Annäherung" wurde von Schröder nicht vertreten, er hoffte durch den Handel langsam die östlichen Diktaturen aufzuweichen.

Eine weitere Annäherung an den Ostblock bahnte sich 1964 an, als der Schwiegersohn und engste Berater Nikita Chruschtschows, Alexei Iwanowitsch Adschubei, bei einem inoffiziellen Besuch der Bundesrepublik einen Staatsbesuch Chruschtschows noch im selben Jahr vereinbarte, der allerdings wegen dessen Sturz nicht mehr zu Stande kam. Ironischerweise ist Chruschtschows politischer Niedergang mit der Annäherungspolitik an die Bundesrepublik verknüpft, die er ohne Rücksprache mit seinem Politbüro eigenmächtig eingeleitet hatte.

Diese politische Ausrichtung Schröders auf eine Annäherung mit Entspannung, wie sie der US-amerikanischen Linie entsprach, verschärfte den innerparteilichen Gegensatz zwischen Gaullisten und Atlantikern erheblich. Verschärft wurde diese Tatsache erheblich durch die Unterstützung dieser Politik durch die FDP und erst recht durch die SPD. Daher hofften viele CDU-Gaullisten, Schröder nach der Bundestagswahl 1965 durch einen der ihren ersetzen zu können.

Nach der gewonnenen Bundestagswahl 1965 konnte Schröder im Amt des Außenministers verbleiben. Er ließ bei den bundesdeutschen Diplomaten eine Umfrage zur Ost- und Entspannungspolitik durchführen. Einheitlicher Tenor der Diplomaten war, dass eine Entspannungspolitik zum Osten nur möglich sei durch Aufgabe der Hallstein-Doktrin, denn gerade Länder der Dritten Welt waren mehr als nur bereit, den zweiten deutschen Staat diplomatisch anzuerkennen. Gerade Wilhelm Grewe, der die Hallstein-Doktrin mit entwickelt hatte, setzte sich für eine Lockerung seines eigenen Werks ein. 1966 war es dann soweit, dass die Bundesregierung eine Friedensnote an alle Länder der Welt versendete mit Ausnahme der DDR. Das erste Mal wurde Adenauers „Politik der Stärke“ fallengelassen, um den Ostblock-Staaten ein Gesprächsangebot und Friedenssignal zu senden. Diese Annäherung war zwar aus heutiger Sicht zaghaft, im damaligen politischen Geschehen der Bundesrepublik eine Sensation.

Sein Amtsnachfolger Brandt ging in seinen Bemühungen der Entspannungspolitik weiter als Schröder, nutzte aber die von Schröder eingeleiteten Maßnahmen als Fundament seiner Ostpolitik. Schröder verfolgte diesen Weg mit erheblicher Verbitterung, da diese Schritte ihm von der eigenen Partei noch verwehrt wurden, jedoch in der großen Koalition sein Nachfolger die Erlaubnis dazu erhielt und Schröders Bemühungen mit der Zeit an Glanz verloren.

Unter Adenauer begann die bundesdeutsche Diplomatie mit zarten Schritten auf den Staat Israel zuzugehen. Erster Punkt, der aus moralischer Notwendigkeit geboren wurde, war die Wiedergutmachung, die auch dem israelischen Staat pekuniäre Zuwendungen zukommen ließ. Mit weiterer Eingliederung der Bundesrepublik in die NATO und damit über die USA in strategischer Partnerschaft mit Israel wurden deutsche Rüstungsgüter zum Teil unter Herstellungspreis an Israel geliefert. Darunter die vom US-Verteidigungsminister Robert McNamara geforderten 150 Kampfpanzer (statt vorher 15, wie ursprünglich vereinbart) des Typs M48 aus bundesdeutscher Lizenzproduktion. Der Rüstungsdeal sollte unter allen Umständen geheim gehalten werden, um die arabischen Staaten, darunter gerade Ägypten nicht abzuschrecken oder gar zu provozieren. Trotz Schröders Veto, der dem israelischen Rüstungsgeschäft von vornherein sehr kritisch gegenüberstand, wurde das Panzergeschäft abgewickelt und kam über Indiskretionen an die Presse und damit an die Öffentlichkeit.

Fast zeitgleich empfing der ägyptische Staatschef Nasser den DDR-Staatschef Walter Ulbricht wie einen Staatsgast in Kairo und Alexandria, was einer faktischen Anerkennung der DDR gleichkam sowie somit einem Bruch der Hallstein-Doktrin. Obwohl Israel im Vergleich zu seinen arabischen Nachbarn wenig wirtschaftlichen Kontakt zur Bundesrepublik unterhielt, entschied Bundeskanzler Erhard sich für Aufnahme von diplomatischen Beziehung zu Israel entgegen dem Ratschlag Schröders und seines Ministeriums. Schröder hatte die Befürchtung, dass dieser Schritt den Abbruch vieler diplomatischer Beziehungen mit der arabischen Welt zur Folge haben würde und somit diese Staaten sich der DDR als deutsche Alternative zuwenden würden; das hätte bedeutet, dass die DDR unweigerlich international an Reputation und Einfluss gewonnen hätte. Schröder hielt daher weiterhin an einer Nichtanerkennung der DDR fest, denn er erwartete von diesem Schritt der Anerkennung das Fallenlassen einer möglichen Wiedervereinigung Deutschlands.

Gerhard Schröders Gesundheit war in den Jahren zuvor nie ernstlich bedroht gewesen, jedoch stellte schon seine Schwester Marie-Renate, eine Humanmedizinerin, Anfang der sechziger Jahre eine sich verschlechternde, erhebliche und nicht beeinflussbare Herzarrhythmie bei ihrem Bruder fest. Anfang Oktober 1964 unterzog sich Schröder daher einer Operation zur Einpflanzung eines Herzschrittmachers. Er fiel durch den Genesungsprozess bedingt fünf Wochen aus, ließ sich jedoch weiter über den politischen Verlauf informieren. Diese Zeit verbrachte er zum größten Teil auf der Bühlerhöhe.

Im April 1965 musste Schröder sich wieder einer Kur zwecks seiner Herzprobleme unterziehen, er wählte hierfür die Idylle am Tegernsee in Bayern. Die Zeit nutzte er ebenso, um die mit Bundeskanzler Erhard entstandenen Differenzen über die Israelpolitik der Regierung in privaten Gesprächen zu bereinigen, denn Erhard lebte privat am Tegernsee.

Trotz des überragenden Sieges der Union, die knapp die absolute Parlamentsmehrheit verfehlte, war die Regierungsbildung sehr zäh, denn die FDP hatte bei der Wahl spürbare Verluste hinnehmen müssen, die CSU und ihre Politik war mit über 55 Prozent der bayrischen Wählerstimmen enorm bestätigt worden und gerade das Tauziehen um die Besetzung des Außenministeriums lähmte die Verhandlungen. Schröder wollte unbedingt weiterhin Außenminister der Bundesrepublik bleiben und setzte sich schon im frühen Verhandlungsstadium offensiv in Szene. Nachdem der Bundeskanzler an ihm festhalten wollte, setzten die gaullistischen Kreise um Adenauer, Krone, zu Guttenberg und Strauß alles daran, Schröder in Misskredit zu bringen. Man scheute sich nicht davor, den Bundespräsidenten Lübke, mit Fingerzeig auf Schröders Privatleben und seiner Affäre in Paris als ungeeignet, für die eigene Sache einzuspannen. Letztendlich waren alle diese Versuche vergeblich, da Schröder durch den EAK, das Vertrauen des Bundeskanzlers und sein Erststimmenergebnis im Wahlkreis zu gut abgesichert war. Wiederum musste der Bundespräsident widerwillig einen Außenminister Schröder ernennen.

Durch den Verhandlungsmisserfolg über die Stationierungskosten der US-amerikanischen Truppen war Bundeskanzler Erhard gezwungen, den Bundeshaushalt über Steuererhöhungen zu sanieren. Die Bundesminister der FDP reichten daraufhin ihren Rücktritt ein, so dass Erhard keine Mehrheit mehr im Bundestag hatte. Das rechtlich nicht bindende "Vertrauensfrage-Ersuchen" der SPD-Fraktion vom 8. November 1966, das mit den Stimmen der FDP beschlossen worden war, nötigte den Parteivorstand auf seiner Sitzung am selben Tag, Erhard den Rücktritt nahezulegen. Schröder verhielt sich, anders als manche Kabinettskollegen der CDU, bis zum Schluss loyal gegenüber Ludwig Erhard.

Auf der Parteivorstandssitzung vom 8. November 1966 schlug der Ministerpräsident von Rheinland-Pfalz Helmut Kohl mehrere Mitglieder dieses Gremiums zu Kandidaten der fraktionsinternen Abstimmung über den Kanzlerkandidaten vor. Es waren Eugen Gerstenmeier, Kurt Georg Kiesinger, Rainer Barzel und Gerhard Schröder. Alle bis auf Gerstenmeier erklärten ihre Bereitschaft sich der Abstimmung zu stellen, Gerstenmeier wollte nicht gegen Kiesinger kandidieren und empfahl diesen zu wählen.

Schröder war in der internen Abstimmung der CDU/CSU-Fraktion über ihren Kanzlerkandidaten im dritten Wahlgang Kiesinger mit 81 zu 137 Stimmen (bei 26 Stimmen für Rainer Barzel) unterlegen. Der Atlantiker-Gaullisten-Streit hatte in der Union starke Spannungen ergeben, die für seine Niederlage in der Kanzlerkandidatenabstimmung der Unionsfraktion mitverantwortlich waren. Franz Josef Strauß versagte dem Protestanten Schröder gegenüber die Unterstützung der entscheidenden Stimmen der CSU in der gemeinsamen Fraktion. Ebenso negativ für ihn war, dass Rainer Barzel auch aus dem nordrhein-westfälischen Landesverband kam und so Schröder auch Stimmen entzog. Trotzdem war Schröder ohne die CSU-Stimmen intern in der CDU-Fraktion der Kandidat mit den meisten Stimmen, so dass Kiesinger bei der Regierungsbildung Schröder einen Ministerposten anbieten musste. Schröder war im Kabinett nun der dienstälteste Minister der amtierenden Bundesregierung.

Als bei der Bildung der Großen Koalition die SPD das Amt des Außenministers für ihren Vorsitzenden Willy Brandt beanspruchte, wurde Schröder am 1. Dezember 1966 im Kabinett Kiesinger Bundesminister der Verteidigung. Kiesinger hätte gerne auf Schröder am Kabinettstisch verzichtet, musste ihn aber mit einem weiteren Amt bedenken, da Schröders Stellung in der CDU immer noch sehr stark war. Schröder selbst sah dies als einen Abstieg gegenüber dem Außenministerium an.

Schröder nahm ins Bundesverteidigungsministerium ein paar loyale Mitarbeiter mit, allen voran seine Sekretärin Frau Naphus und seinen Staatssekretär Carstens. Den Generalinspekteur der Bundeswehr Ulrich de Maizière beließ er im Amt und harmonierte schnell mit ihm. Schwerer wog für ihn der relativ schnelle Abgang von Carstens zu Kiesinger als dessen Kanzleramtschef. Carstens' Nachfolger wurde der ehemalige Bundespressesprecher und aktive Reserveoffizier Karl-Günther von Hase.

In seiner Amtszeit wurden einige wichtige verteidigungspolitische Entscheidungen getroffen, so konnte unter anderem die hohe Absturzquote der Starfighterflotte drastisch herabgesetzt werden, was vor allem Johannes Steinhoff als Inspekteur der Luftwaffe zu verdanken ist. Ferner wurde in Absprache mit dem britischen Amtskollegen Denis Healy von Schröder der Grundstein für ein europäisches Kampfflugzeugprojekt gelegt, aus dem später der Tornado hervorgehen sollte. Ebenso war Schröder als Verteidigungsminister darauf bedacht, dass das Projekt einer gemeinsamen Koordinierung der Atomwaffen des NATO-Bündnisses wieder aufgenommen wurde, nachdem die Multilateral Force gescheitert war. Daher unterstützte er die Gründung der Nuklearen Planungsgruppe.

Schröder betrachtete sich in der damaligen Situation als "Reservekanzler" der CDU bei einem Scheitern der großen Koalition, der er wenig Chancen auf Erfolg gab. Kiesingers reservierte Haltung gegenüber Schröder zeigte sich auch daran, dass der Kanzler in seinen Urlaubsort Kressbronn am Bodensee sehr oft die Entscheidungsträger der Koalition einlud, um zwischen den Gruppierungen besser vermitteln zu können, Schröder aber nur einmal eingeladen war und damit weniger als jeder andere Bundesminister.

Beim Haushaltsentwurf des neuen Finanzministers Strauß hätte die Bundeswehr die größten pekuniären Einschnitte hinnehmen müssen, wogegen sich Schröder offen wehrte. Kiesinger reagierte durch Konsultationen mit den pensionierten Generälen Speidel und Heusinger, die an Schröder wie an seinem Generalinspekteur Kritik übten und die Kürzungen des Finanzministeriums akzeptierten.

Zu einem Eklat kam es, als der Parlamentarische Staatssekretär im Kanzleramt zu Guttenberg den Inspekteur des Heeres Josef Moll zum Vortrag beim Kanzler lud, ohne Schröder als Minister zu informieren. Daraufhin drohte Schröder mit seinem Rücktritt. Letztlich wurde beschlossen, dass solche Konsultationen des Regierungschefs nur unter Hinzuziehung des Ministers stattfinden sollten.

Bei der Einführung der Notstandsgesetze war Schröder das einzige Kabinettsmitglied, das dagegen votierte, denn die Regierungsentwürfe gingen ihm nicht weit genug, er hielt an seinen Entwürfen als Bundesinnenminister fest.

Am 29. August 1967 stürzte er aufgrund von Herzrhythmusstörungen und Bewusstseinstrübung auf der Treppe seines Ferienhauses "Atterdag" auf Sylt und wurde per Rettungshubschrauber ins Universitätsklinikum Hamburg-Eppendorf geflogen. Schröder erholte sich nie ganz davon, sein Gedächtnis verließ ihn des Öfteren, seine Stimme blieb seitdem schleppend. Ferner wurde sein Gesundheitszustand zusehends zu einem Politikum, wenn er für höhere Ämter vorgeschlagen wurde und seine Gegner auf seine schwache Gesundheit verwiesen.

Im Vorfeld der Bundespräsidentenwahl 1969 wurde Schröder früh als geeigneter Kandidat der Unionsparteien angesehen. In der CDU regte sich allerdings Widerstand von Seiten Kiesingers und weiterer Schröder-Gegner, die auch über Helmut Kohl den damals noch ziemlich unbekannten Richard von Weizsäcker ins Spiel brachten. In der entscheidenden parteiinternen Abstimmung setzte sich Schröder mit 65 zu 20 Stimmen klar gegen seinen Konkurrenten durch. Die SPD nominierte seinen Kabinetts-Kollegen im Justizministerium Gustav Heinemann. Das bewirkte eine gewisse Polarisierung, standen sich doch ein ehemaliges Mitglied der Bekennenden Kirche, somit ein ausgewiesener Gegner der NS-Diktatur, und, was wieder in den Fokus der Öffentlichkeit gerückt wurde, ein früheres Mitglied der NSDAP und der SA einander gegenüber.

In den nun folgenden Monaten vor der Wahl versuchten sowohl Heinemann als auch Schröder die damals auf Bundesebene in Opposition stehende FDP, auf deren Stimmen es höchstwahrscheinlich ankommen würde, für sich zu gewinnen. Am Morgen des Wahltages informierte der FDP-Vorsitzende Walter Scheel Schröder darüber, dass die FDP mehrheitlich Heinemann wählen werde.

Bei der Wahl selbst unterlag Schröder Heinemann im dritten Wahlgang mit 506 zu 512 Stimmen. Gewählt wurde er wohl auch von 22 Mitgliedern der Bundesversammlung, die von der NPD entsandt worden waren, einige Stimmen für ihn dürften auch von der FDP abgegeben worden sein. Mit diesem Ergebnis zeichneten sich der Machtverlust für die seit 1949 regierenden Unionsparteien und eine neue Mehrheit für eine sozialliberale Koalition bereits ab.


Schröder unterhielt in den Jahren nach seiner aktiven politischen Tätigkeit einen privaten Diskussionskreis von ehemaligen Politikern, Diplomaten und Wirtschaftsfunktionären, die über die globalen Probleme der neuen Zeit philosophierten, jedoch politisch nicht mehr ins Tagesgeschäft eingriffen. Er hielt in diesem Kreis die Politik der Reagan-Administration für gut, da seiner Meinung nach im Westen wieder Stärke bewiesen wurde, und befürwortete das SDI-Programm.

Sein letzter Auftritt im Bundestag war am 17. Juni 1984, als er die Festrede der Gedenkveranstaltung zum 17. Juni 1953 hielt.

Schröder starb am 31. Dezember 1989 in seinem Haus auf Sylt. Nach seinem Tode ehrte ihn der Deutsche Bundestag am 12. Januar 1990 mit einem Staatsakt im Plenarsaal. Gerhard Schröder wurde auf dem Friedhof der Inselkirche St. Severin in Keitum auf Sylt beigesetzt.

Schröder hatte eine preußische Erziehung und hielt zu den meisten Menschen einen unterkühlten Abstand. Bis zu seinem Ausscheiden aus dem Bundestag 1980 duzte er sich mit keinem Mitglied der CDU/CSU-Bundestagsfraktion.

1960 baute sich Schröder auf der Nordseeinsel Sylt im Ort Kampen in der Südwestheide ein Ferienhaus, das er "Atterdag" nannte. Atterdag ist Dänisch und bedeutet „neuer Tag“, war aber auch der Beiname des dänischen Königs Waldemar IV. Hier unterhielt er zu damals einflussreichen Personen der Gesellschaft und Wirtschaft enge Beziehungen, wie etwa zu Berthold Beitz. Auf Sylt lernte Schröder auch den Maler Albert Aereboe kennen, der dort lebte und arbeitete und von dem er sich porträtieren ließ. Durch Aereboe wurde sein Interesse an moderner Kunst geweckt.

Schröder war ehrenamtlicher Präsident der Deutschen Gesellschaft für Photographie.

Das anfangs gute Verhältnis zum Verleger Rudolf Augstein wurde durch einen negativen Artikel im Spiegel über Schröder als Innenminister hoffnungslos zerrüttet, obwohl Augstein in den ersten Jahren Schröder als potentiellen Kanzlerkandidaten sah. Zum Chef des Springer-Verlages Axel Springer konnte er nie ein gutes Verhältnis entwickeln, zeitweise wurde er in dessen Bild-Zeitung hart angegriffen, wie etwa am 23. März 1965 mit der Schlagzeile "Minister Schröder – der Versager des Jahres". Man geht heute davon aus, dass Springer ein Gegner von Schröders "Berlin-Politik" war, den gaullistischen Kräften in der CDU/CSU näher stand und ebenso mit Schröders Israelpolitik nicht einverstanden war, denn die Freundschaft zu Israel gehörte zum Kern der Ausrichtung des Springer-Verlages.


Von Schröder:
Über Schröder:

Am 10. Oktober 1987 sollte es auf WDR 2 ein Interview mit dem damaligen SPD-Oppositionsführer des niedersächsischen Landtages, Gerhard Schröder, über die geplatzte rot-grüne Koalition in Hessen geben. Durch einen Fehler hatten die Moderatoren nicht den SPD-Politiker per Telefon zugeschaltet bekommen, sondern Gerhard Schröder von der CDU, der aber ebenso irritiert war wie die Moderatoren. Die Sendung konnte trotzdem gerettet werden, da Gerhard Schröder auch zu diesem Thema seine Sicht der Dinge vortragen konnte.










</doc>
<doc id="2104" url="https://de.wikipedia.org/wiki?curid=2104" title="Harmonie">
Harmonie

Die Harmonie ( "harmonía" „Ebenmaß“, „Harmonie“, Silbe "ar" oder "har": indogerman. Herk. = Vereinigung von Entgegengesetztem zu einem Ganzen) bezeichnet:

Der Begriff „Harmonie“ wird besonders dort verwendet, wo man neben einer bestimmten Regelmäßigkeit in der Anordnung einzelner Objekte bzw. ihrer Teile noch einen Sinn, eine Wertbezogenheit anzumerken glaubt.

Bei der Herausbildung des Begriffs in der Antike bezog sich „Harmonie“ auf Erscheinungen der Symmetrie. Der Harmoniebegriff wurde zunächst von den Pythagoreern in den Mittelpunkt philosophischer Betrachtungen gestellt. Man sah die Harmonie in der schönen Proportion als Einheit von Maß und Wert. Diese These, zunächst mit mathematischen Erkenntnissen und mit der Harmonie der Töne gestützt, wurde ins Mystische extrapoliert.

So wurde behauptet, die Bewegung der Himmelskörper folge bestimmten harmonischen Zahlenverhältnissen und bewirke eine (unhörbare) „Sphärenmusik“. Heraklit versuchte, den Begriff „Harmonie“ dialektisch als Einheit der Gegensätze zu fassen: „Das Widerstrebende vereinige sich, aus den entgegengesetzten (Tönen) entstehe die schönste Harmonie, und alles Geschehen erfolge auf dem Wege des Streites.“
Auch Platon stützte sich auf den Harmoniebegriff als Beleg seiner Ideenlehre. So entwickelte er Gedanken von den „Atomen“, die aus Dreiecken bestehen, von der Harmonie des Kosmos, der Töne u. a. und übertrug sie auch in die Staatslehre.

Besonders die antike Medizin knüpfte an diese naturphilosophische Harmonie an. Sie leitete aus dem harmonischen Mischungsverhältnis von Körpersäften Gesundheit und aus einer Unausgewogenheit Krankheit ab. Die galenische Temperamentenlehre übertrug diese Theorie außerdem auf den menschlichen Charakter.

Die Harmonielehre "der Antike" hat zwei Quellen:


Zahlen, die in einer harmonischen Proportion stehen, müssen die Gleichung (a − b) : (b − c) = a : c erfüllen. (Siehe auch Goldener Schnitt)

Boethius stellte die einflussreiche Theorie von den drei verschiedenen Arten von „Musik“ auf („Musik“: der Inbegriff der Gesamtheit harmonischer Maßverhältnisse):


Boethius weist der "musica mundana" die dominierende Rolle zu. Der Mensch hat die Pflicht, diese zu erkennen und selbst ein geregeltes Leben zu führen. Die mittelalterliche Astronomie bemühte sich, mit dem Modell von harmonisch aufeinander abgestimmten Sphärenbewegungen eine Erklärung der Himmelsbewegungen zu geben.

In der Lehre des Thomas von Aquin (* um 1225–1274) wird die Seele nach dem Tod vom Leib getrennt und besteht weiter ("Anima forma corporis").

Johannes Kepler (1561–1630) legte seinen astronomischen Forschungen die Vorstellung der Existenz einer „Sphärenharmonie“ zugrunde. Eines seiner Hauptwerke trägt den Titel „"Harmonice mundi"“ (1619). Als überzeugter Kopernicaner geht Kepler der Frage nach, welche Zusammenhänge zwischen den Planetenbewegungen und den harmonischen Verhältnissen bestehen, wie sie aus der Musik und Geometrie geläufig sind.

Marin Mersenne gab in seiner Schrift „Harmonie universelle“ (1636) eine physikalische Begründung des musikalischen Tonsystems. Die Harmonie bis Leibniz basierte auf der Forderung der Existenz eines Systems, das aus miteinander nicht wechselwirkenden Elementen besteht. Mit der Entwicklung eines neuen Systembegriffs, vor allem des der Newtonschen Physik, wurde die materielle Wechselwirkung Voraussetzung für die Existenz von Systemen. Damit büßte die Harmonie ihren ursprünglichen bedeutenden Einfluss auf die Naturauffassung ein. In Gestalt der Lehre von den „Wahlverwandtschaften“ als Basis der chemischen Verbindungen blieb sie jedoch noch bis ins 19. Jahrhundert hinein von Einfluss.

In Leibniz' (1646–1716) Lehre von der „universellen Harmonie“ kommt die Auffassung von der durchgängigen Gesetzlichkeit der Welt zum Ausdruck. Zur Lösung des spezifischen Problems der Bestimmung des Verhältnisses von Leib und Seele führte Leibniz den Begriff der „prästabilierten Harmonie“ von Leib und Seele ein: Leib und Seele sollen wie zwei voneinander unabhängig gehende Uhren miteinander harmonieren.

Georg Wilhelm Friedrich Hegel (1770–1831) bezeichnete mit Harmonie eine bestimmte Phase des dialektischen Widerspruchs, und zwar jene, in dem sich das qualitativ Verschiedene nicht nur als Gegensatz und Widerspruch darstellt, sondern „eine zusammenstimmende Einheit“ bildet. Innerhalb seiner Lehre von den Maßverhältnissen definierte Hegel die in den musikalischen und chemischen Verhältnissen auftretenden Harmonien als „ausschließende Wahlverwandtschaften, deren qualitative Eigentümlichkeit sich aber ebenso sehr wieder in die Äußerlichkeit bloß quantitativen Fortgehens auflöst“ (in: Wissenschaft der Logik). Doch auch hier wird das Harmoniekonzept schließlich von der Analyse der konkreten chemischen Wechselwirkungen verdrängt.


Eine große Rolle spielte und spielt der Harmoniebegriff schließlich in den Bemühungen der Biologie bzw. Taxonomie, ein geschlossenes System von Arten, Gattungen u. a. der Lebewesen in der Botanik und Zoologie zu begründen. Besonders für die Verfasser der „Verwandtschaftstafeln“ von Lebewesen sowie für die Anhänger von „natürlichen Systemen“ in der Taxonomie ist der Harmoniegedanke ein Leitprinzip.

In den Naturwissenschaften wurde der Begriff durch Begriffe wie Symmetrie, Ganzheit, System, Strukturgesetz u. a. ersetzt. Eine Bedeutung hat der Begriff der Harmonie als heuristisches Prinzip, wenn damit die Aufforderung verstanden wird, in der Vielfalt von objektiven Merkmalen und Beziehungen nach Strukturgesetzen zu suchen.

Neben dieser methodologischen Funktion des Begriffs der Harmonie und seiner nahezu theoretischen Unbrauchbarkeit in den Naturwissenschaften kommt ihm jedoch in jenen Wissenschaften eine positive theoretische Funktion zu, in denen die Subjekt-Objekt-Dialektik selbst Gegenstand der Wissenschaft ist, in denen Werte und Normen als Faktoren der vom Menschen gestalteten oder zu gestaltenden Objekte untersucht werden.

Harmonie bedeutet dann vor allem, "Gestalt und Funktion aller Teile eines Ganzen so abzustimmen, daß die Funktion der jeweils anderen Teile und vor allem die Funktion des Ganzen maximal befruchtet werden."

Heute hat der Begriff der Harmonie seine Relevanz in der Ästhetik, den Kunstwissenschaften (Musik, Baukunst, Malerei), in der Pädagogik ("die allseitig entwickelte Persönlichkeit") u. a.




</doc>
<doc id="2105" url="https://de.wikipedia.org/wiki?curid=2105" title="Hilfe">
Hilfe

Hilfe im Sinne der "Hilfsbereitschaft" ist ein Teil der Kooperation in den zwischenmenschlichen Beziehungen. Sie dient dazu, einen erkannten Mangel oder eine änderungswürdige Situation oder einer Notlage zu verbessern. Der Hilfe geht entweder eine Bitte des Hilfebedürftigen oder eine von ihm unabhängige Entscheidung durch Hilfsbereite voraus.

Die Feststellung über das Ausmaß der Hilfebedürftigkeit und der geeigneten Hilfsmittel kann zwischen den betroffenen Parteien kaum bis stark differieren. Dabei kann die Situation sowohl über- als auch unterschätzt werden. Ursachen sind meistens in der Kompetenz des Helfenden, aber auch in der Urteilskraft des Hilfebedürftigen zu suchen. So kann etwa die Urteilskraft eines schwer kranken Menschen ebenso stark geschwächt sein wie sein Allgemeinzustand. Im Gegenzug kann der Helfende der Situation nicht oder nicht ausreichend gewachsen sein.

Hieraus wird deutlich, dass ein „Anspruch auf Hilfe“, wie er in den meisten Gesellschaften als ein selbstredendes „ungeschriebenes Gesetz“ betrachtet wird, nicht gleichbedeutend mit „Anspruch auf Besserung“ ist. Schließlich gibt es zu viele subjektive Störfaktoren, die einer effektiven Hilfe im Wege stehen können. In den traditionellen und erfahrenen helfenden Berufen (Heilberufe, Gesundheitsberufe) hat sich daher die „Hilfe zur Selbsthilfe“ als ein effektives und realistisches Konzept durchgesetzt.

Viele Menschen betrachten Hilfe nicht nur als natürliche Pflicht, sondern als eine aus ihrem Glauben folgende Aufgabe. Hier folgt das Gewissen eher einer gesellschaftsunabhängigen Instanz. Nicht wenige Hilfsangebote werden von religiösen Institutionen oder besonderen weltanschaulichen Splittergruppen getragen. Einige von ihnen verbieten ihren Anhängern aber gesellschaftlich vereinbarte und tradierte Hilfsangebote.

Hilfe ist besonders dann eine gewollte Kooperation, wenn sie das Fortbestehen eines Systems fördert. Diese als Symbiose bekannte Kooperation (Koexistenz) gleicht durch Wechselwirkung einen „allein nicht überwindbaren“ Mangel aus, ohne dabei direkt Bedingungen an dieses Handeln zu knüpfen. Hier besteht eine unmittelbare Abhängigkeit, die man als „Hilfe zum Selbsterhalt“ bezeichnen kann, denn sie entspringt weder einer Konvention noch einem Gewissen. Allerdings ist auch hier die gegenseitige Hilfe keine Garantie zum Fortbestand. Sowohl veränderte äußere Umstände als auch immanente Wandlungen können das System zwingen, sich aufzulösen.

Bei mehreren Systemen untereinander wird diese Problematik etwas entschärft. Es liegt in der Natur der Systeme, dass sie benötigte Hilfsmittel (Aktivitäten, Ressourcen, Energie usw.) bereitstellt. Das helfende System transferiert also in das betroffene System. Daraus folgt, dass im Hilfe-System ein Ausgleich geschaffen werden muss für die abgegebenen Leistungen. Sonst würde sich dieses durch weitere derartige Kooperation aufzehren. Damit ist diese besondere (unbalancierte) Situation auch für das Hilfe-System belastend. Unter Umständen bedarf es sogar in der Folge selbst der Hilfe (siehe auch: Helfersyndrom). Je nach dem Grad der Notsituation ist somit eine daran ausgerichtete Vernetzung oder Verkettung von vielen sich jeweils sichernden und ergänzenden Hilfestellen notwendig. Umgekehrt kann man jedes (vernetzte) System auch als sich in gegenseitiger Hilfe befindliche Instanzen sehen, die das Fortbestehen des Ganzen garantieren.

Mit "Art" ist gemeint, welchen Zweck die Hilfe verfolgt. Die Form (in Klammern) sagt aus, wer oder was die Hilfe leistet, bzw. woraus sie besteht. Die häufigsten Formen sind Geld, Nahrung und Kleidung. Sie werden nicht mehr extra erwähnt.



</doc>
<doc id="2107" url="https://de.wikipedia.org/wiki?curid=2107" title="Hybrid">
Hybrid

Das Substantiv Hybrid (neutrum: das Hybrid) und das Adjektiv hybrid beziehen sich auf etwas Gebündeltes, Gekreuztes oder Vermischtes. Diese griechischstämmigen Begriffe (abgeleitet von ὕβρις "hýbris", "Übermut" oder "Anmaßung") haben über das Lateinische "(hybrida", "Bastard, Mischling" oder "Frevelkind") ihren Weg u. a. in die englische und deutsche Sprache gefunden.

Jüngeren etymologischen Studien zufolge sind die weitläufig mit dem Begriff der Hybridität verbundenen negativen Konnotationen des griechischen Wortstammes ὕβρις nicht den homerischen Epen entlehnbar, sondern erfuhren ihren Bedeutungswandel erst später in der sprachlichen Entwicklung des Altgriechischen: stattdessen legt die dortige Verwendung des Wortes eine wertneutrale Bedeutung im Sinn von "Kraft" nahe, 

Allgemein versteht man in der Technik unter Hybrid ein System, bei welchem zwei Technologien miteinander kombiniert werden.

Die vorangestellte Bezeichnung "Hybrid-" betont ein aus unterschiedlichen Arten oder Prozessen zusammengesetztes Ganzes. Die Besonderheit liegt darin, dass die zusammengebrachten Elemente für sich schon Lösungen darstellen, durch das Zusammenbringen aber neue erwünschte Eigenschaften entstehen können.

Auch wenn das Zusammenbringen verschiedener Subsysteme geradezu ein Prinzip von Systemen ist, meiden Systeme eher solche Hybrid-Lösungen. Denn das Hybridartige bedeutet, dass Doppel- oder Mehrfachlösungen für die gleiche Funktion eingesetzt werden, die einen jeweils unterschiedlichen inneren Aufbau besitzen.

Systeme sichern ihr Fortbestehen jedoch eher aus 1. der Mehrfachverwendung gleicher Teile für die gleiche Funktion (Redundanz) oder 2. das Zusammenfügen unterschiedlicher Subsysteme zu unterschiedlichen Zwecken.

In Kraftfahrzeugen werden Stoßfänger aus einer Kombination von Kunststoff (glasfaserverstärktes Polyamid) und Metallen (Stahl oder Aluminium) hergestellt. Die Hybridbauweise ermöglicht einerseits die rationelle Fertigung komplexer hochbelastbarer geometrischer Strukturen, andererseits eine Gewichtsersparnis, im Fall von Stoßfängern ein besseres Fahrverhalten durch optimierte Gewichtsverteilung des Fahrzeugs. Die unterschiedlichen Werkstoffe werden beispielsweise durch Hybridfügen, der Kombination mehrerer Fügeverfahren (Beispiel: Punktschweißkleben) gefügt.

Hybride Antriebssysteme bestehen aus einer Kombination von mindestens zwei verschiedenen und getrennten Energiespeicher- und Antriebssystemen.












</doc>
<doc id="2108" url="https://de.wikipedia.org/wiki?curid=2108" title="Historische Jahrestage">
Historische Jahrestage

Diese Liste zeigt eine tabellarische Anordnung der Wikipedia bekannten historischen Jahrestage.

Historische Jahrestage bezeichnen Tage mit historischer Bedeutung,- oder Bezug. Ein historisches Ereignis ist eine Begebenheit, die eine geschichtliche Veränderung verursacht hat. Jeder Tag im Jahr hat den Status eines historischen Jahrestages. Der Kalender der historischen Jahrestage hilft bei der Suche nach bestimmten Gedenktagen, Geburtstagen und historischen Ereignissen.





</doc>
<doc id="2126" url="https://de.wikipedia.org/wiki?curid=2126" title="Heidentum">
Heidentum

Heidentum oder Paganismus (von lateinisch "paganus" ‚heidnisch‘; lateinisch "pagus" ‚Dorf‘) bezeichnet religionsgeschichtlich aus christlicher Sicht den Zustand, nicht zu einer der monotheistischen Religionen zu gehören. In Anlehnung an historische Texte aus Antike und Mittelalter werden diese in Europa und Vorderasien von Christen, Muslimen, Juden, Zoroastriern und Manichäern "(den abrahamitischen Religionen)" abgegrenzt. In der Primärliteratur dieser Epochen ist die Verwendung aufgrund des religiösen Exklusivitätsanspruches häufig abwertend (pejorativ). In der neueren Forschungsliteratur wird "Heidentum/heidnisch" und "Pagane/pagane Kulte" – bezogen auf die Antike und das Mittelalter – wertneutral benutzt, um damit die Anhänger verschiedener Götterkulte von Christen, Juden, Zoroastriern und Manichäern zu unterscheiden.

Die negative Konnotation des Begriffs "Heidentum" hat allerdings aufgrund weiterhin wirksamer religiöser Prägungen kaum abgeschwächt in den heutigen Sprachgebrauch überdauert. In der Moderne findet der Begriff "Heide" meist keine Anwendung mehr für Atheisten, Agnostiker oder Minderheitsreligionen. Als Selbstbezeichnung von Anhängern neopaganistischer Bewegungen wird er jedoch wieder verwendet. 

Auf Atlaskarten des 19. Jahrhunderts ist eine Verwendung als Synonym für „Stammesreligionen“ zu entnehmen.

Zu Zeiten des frühen Christentums, das sich aus einer innerjüdischen Sekte, dem Judenchristentum, in das Heidenchristentum differenzierte, galten die Abweichler und Anhänger der paulinischen Theologie und Mission, vergleichbar selbst als eine Art "Heiden". Später, innerhalb des frühmittelalterlichen Christentums, diente der Begriff dann zunächst als einfaches Unterscheidungsmerkmal der aus dem Judentum bekehrten Judenchristen von den nicht-jüdischen Heidenchristen. Seit dem europäischen Mittelalter wurde er vornehmlich aus der Sicht monotheistischer, missionierender Religionen häufig abwertend für religiöse Gegner außerhalb der eigenen Tradition gebraucht.

Vor allem das Christentum verwendete den Begriff als Bezeichnung für alle Ungläubigen. Von manchen wurde in Abweichungen vom gängigen Sprachgebrauch auch die jüdische Religion als heidnisch bezeichnet.

In der konkreten christlich-missionarischen Auseinandersetzung und Gewalt ist der Begriff vor allem in den nordischen Kulturen bereits sehr früh als abgrenzende Selbstbezeichnung nachweisbar (siehe Etymologie).

Heidentum kann als Selbst- und Fremdbezeichnung auch die Wiederbelebung alter Religionen in der Gegenwart bedeuten. In diesem Fall wird der Begriff synonym zum präziseren Neopaganismus (Neuheidentum) verwendet.

Die jüdische Tradition hat vergleichbar den abgrenzenden, nicht abwertenden hebräischen Begriff "goj" (‚aus den Völkern‘), was etwa Nichtjude bzw. Ausländer bedeutet. Die islamische Tradition hat vergleichbar den abgrenzenden arabisch-islamischen Rechtsbegriff Kāfir, der Ungläubige oder „Gottesleugner“ bezeichnet.

Es gibt verschiedene Theorien über die Etymologie des Wortes "Heide". Die Bildungen "heiþna, haiþina" werden als sehr alte Bildungen eingestuft. Früher wurde das Wort als Lehnübersetzung zu "paganus" betrachtet. Dieses Wort ist aber erst in der zweiten Hälfte des 4. Jahrhunderts aufgekommen, als das Suffix -ina nicht mehr verwendet wurde, und geht auf das lateinische Wort "pagus" zurück, das einfach nur das Landvolk oder die Dorfbewohner bezeichnete. Auch zur Entstehung des Wortes "Heiðinn" als „Heide“ gibt es verschiedene Interpretationen. So wurden die Wörter "Hellene" und "gentiles" im ähnlichen Sinne wie das spätlateinische Wort paganus für „Heiden“ verwendet. Der Indogermanist Wilhelm Schulze knüpfte an das armenische Wort "hethanos" (Lehnwort aus dem Griechischen: ἔθνος (éthnos)) an, das über komplizierte Veränderungen im Gotischen ans Germanische weitergegeben worden sei. Jost Trier hat die „Heide“ als Allmende identifiziert und etymologisch mit "heimr" ‚Welt, Heimat‘ verbunden. So kommt er zur Bedeutung von „heiðinn“ als „zur eigenen heimischen Kultgemeinde gehörend“.

Zunächst war „heiðinn“ eine durchaus von Christen übernommene, aber nicht pejorative Bezeichnung nordgermanischer Nichtchristen. Der Skalde Eyvindr Skáldaspillir (um 920–990) dichtete (zur Aussprache siehe Isländische Aussprache):

Erst die vordringende christliche Missionierung, auch Zwangsmissionierung, führte zu einer gewissen Abwertung im Sinne von „primitiv“, die bis heute vorsticht.

In der christlichen Tradition dient der Begriff "Heide" als Sammelbezeichnung für die jeweils anderen, also diejenigen, die außerhalb der eigenen christlich-trinitarischen Traditionen stehen. Der Begriff diente ursprünglich als polemische Kategorie zur Abwertung des "anderen", dem die Zugehörigkeit zu einer Religion abgesprochen wird. Eng verknüpft ist damit die Vorstellung der "falschen Religion". Je nach Kontext kann deshalb "Heide" und "Heidentum" unterschiedliche Bedeutung annehmen. Zeitweise wurden als Heiden alle "anderen" außerhalb des Christentums benannt, im Zuge der Reformation und der Konfessionalisierung auch die jeweils andere Konfession als heidnisch bezeichnet. Der semantische Gehalt des germanischen Wortes "Heide" überlappt sich dabei mit der Bedeutung des lateinischen "paganus", des Landbewohners, der im begrifflichen Gegensatz zum Stadtbewohner steht.

In jüdischen Schriften wird einerseits zwischen dem Volk Israel und den "Gojim" (Einzahl "Goj") unterschieden, was in der Septuaginta mit ΕΘΝΟΣ ("ethnos" = ‚Volk‘), in der Vulgata mit "gentes" (= ‚Stämme, Völker‘) übersetzt wurde, andererseits werden aber beide Ausdrücke auch häufig (z. B. Genesis 35,11) als Selbstbezeichnung verwendet. Diese Ambivalenz in der Verwendung findet sich auch noch im Neuen Testament, mehrheitlich sind aber die Anhänger des griechischen und römischen Polytheismus gemeint, in einigen Fällen auch die zum Christentum bekehrten Nichtjuden. Es wird unterschieden zwischen "Judenchristen" (zum Christentum bekehrten Juden) und "Heidenchristen" (zum Christentum bekehrten Anhängern anderer Religionen). Paulus bezeichnete sich selbst als Apostel der Heiden (Nationen), weil er sich beauftragt sah, Nichtisraeliten zu lehren und zu verkündigen.

Traditionell wurden die Paganen (Heiden) von den Anhängern monotheistischer Religionen pauschal als "Ungläubige" betrachtet und behandelt.

Die jüdische, christliche und islamische Ablehnung des Heidentums richtete sich zunächst vor allem gegen den griechischen und römischen Polytheismus, im Zuge der Mission unter anderem auch gegen das germanische, keltische, slawische, baltische und indianische Heidentum.

Als Ende des klassischen Heidentums kann daher jeweils die Entwicklung beziehungsweise die Einführung des Christentums oder des Islam als Volks- oder Staatsreligion angesehen werden, unbeschadet der in den regionalen Übergangszeiten entstandenen Formen des Synkretismus, also der Mischung von religiös-kultischer Tradition und akkommodierten christlichen Inhalten, Riten und Kulten.

Obwohl das Christentum im späten 4. Jahrhundert (also nach der konstantinischen Wende im frühen 4. Jahrhundert) zur Staatsreligion des Römischen Reiches wurde und in der Folgezeit versucht wurde, viele "heidnische" Bräuche zu unterdrücken oder zu christianisieren, lassen sich noch die ganze Spätantike hindurch heidnische oder zumindest synkretistische Überzeugungen und Praktiken finden. Um 400 nahm aber die Zahl der Anhänger paganer Kulte spürbar ab, zumal auch Christen die kulturellen Traditionen (so die klassische Bildung) betonten.

Später wurde im Christentum das Heidentum außerhalb der eigenen Kultur lokalisiert, häufig als Aberglaube abgetan oder als Ziel der Missionierung gesehen, wenngleich die zwangsweise Christianisierung offiziell und auch von verschiedenen christlichen Gelehrten im Mittelalter abgelehnt wurde.

Der Islam unterschied ebenfalls von Beginn an zwischen den Leuten des Buches (Christen und Juden) und den Ungläubigen, die missioniert werden sollen. Anhänger polytheistischer Religionen besitzen nach der Scharia bis heute keinen Rechtsstatus und genießen keinen Schutz. Reste des arabischen Heidentums fanden sich noch Anfang des 20. Jahrhunderts, zum Beispiel in Form der Verehrung von Dhū l-Chalasa.

Dagegen konzentrierte sich innerhalb des Christentums der Begriff "Heide" während der Kreuzzüge fast ausschließlich auf die muslimischen Sarazenen. Erst im Zuge der Mission auf den wieder bzw. neu entdeckten Kontinenten Afrika, Amerika und Asien wurde er im Sinne der "Neuland-, Pionier- bzw. Heidenmission" wieder breiter gefasst. Heute wird der Begriff im Kontext der Evangelisierung und Inkulturation der meisten christlichen Konfessionen kaum mehr verwendet; vielmehr bezeichnen sich heute die Angehörigen der neu aufkeimenden polytheistischen Strömungen selbst als Heiden, ohne darin eine Form der Geringschätzung zu sehen.

Die Bezeichnung „Heide“ ist aufgrund der christlichen Tradition im deutschen Sprachraum gemeinhin negativ belegt. Demgegenüber steht die positive Verwendung durch das "Neuheidentum" (Neopaganismus): Obwohl diese esoterisch-neureligiöse Bewegung eine Vielzahl unterschiedlicher und eigenständiger – oft polytheistischer – Richtungen aufweist, bezeichnen sich deren Anhänger häufig bewusst als "Heiden", um damit ihre gemeinsame, religiöse Gruppen-Identität als Gegenpol zur christlich-jüdischen Tradition bzw. auch zu allen Weltreligionen und dem „überzeugten Unglauben“ hervorzuheben.

Die neuheidnische Bewegung hat seit der umweltpolitischen Gesellschaftskritik in den 1970er Jahren erheblichen Zulauf. Überall spielen Ökologie, Ganzheitlichkeit und Spiritualität eine zentrale Rolle. Zumeist im Wege individueller „Bewusstseinserweiterungen“ möchte man zu einer Lebensweise- oder zumindest einer Weltanschauung „im Einklang mit der Natur“ gelangen.

Da es nahezu keine historischen Aufzeichnungen aus der Zeit des vorchristlichen Europas gibt, beziehen sich Neuheiden unter anderem auf nordische und keltische Märchen und Sagen sowie auf Traditionen und exotische Rituale der sogenannten „Naturreligionen“. Besonders asiatische, indianische und keltische Elemente werden aufgegriffen und – ohne Rücksicht auf den historischen oder geographischen Kontext – den eigenen Vorstellungen angepasst. Die Flut an Veröffentlichungen und Kursen ermöglicht es den dafür aufgeschlossenen Menschen, eine Vielzahl von neuheidnischen Ideen zu konsumieren, ganz individuell zusammenzustellen und zu verändern. In der Szene finden sich auch etliche Vertreter indigener Gruppen, die ihr „archaisches Wissen“ gewinnbringend an neue Heiden verkaufen. Viele dieser Neoschamanen werden in ihrer Heimat nicht als religiöse Autoritäten anerkannt und beispielsweise in Nordamerika abwertend als Plastikschamanen betitelt. Darüber hinaus sind auch ihre Kenntnisse der eigenen Überlieferungen im Zuge der häufig zwangsweisen christlichen Missionierung unvollständig, so dass sie vielfach auf jüngere Entwicklungen (siehe Peyote-Religion) aufbauen, die jedoch ihrerseits schon synkretistische Mischreligionen aus verschiedenen ethnischen und christlichen Elementen sind.

Die Zahl der Anhänger neuheidnischer Weltanschauungen ist statistisch schwer zu ermitteln, da diese häufig nicht in großen Organisationen zusammengefasst sind. Die Schätzungen gehen von mehreren Millionen weltweit aus. Wicca und verwandte Bewegungen sind nach unterschiedlichen Schätzungen von mehreren 1.000 mit bis zu 100.000 Anhängern in Deutschland die größte neuheidnische Richtung. Um das Jahr 1990 wurde die Zahl der Wicca-Anhänger auf mehr als 200.000 in den USA, 30.000 in Großbritannien und weltweit auf 800.000 geschätzt.


Siehe auch die diversen Aufsätze in Aufstieg und Niedergang der römischen Welt oder der Cambridge Ancient History und der New Cambridge Medieval History.



</doc>
<doc id="2128" url="https://de.wikipedia.org/wiki?curid=2128" title="Hollywood">
Hollywood

Hollywood () [] ( für "Stechpalmenwald") ist ein Stadtteil von Los Angeles im US-Staat Kalifornien mit 210.824 Einwohnern (Volkszählung 2000). Weltbekannt wurde Hollywood als Zentrum der US-amerikanischen Filmindustrie, weshalb sein Name oft auch stellvertretend für die gesamte amerikanische Filmbranche steht, deren Mythos zur Entstehung gebräuchlicher Synonyme wie "Traumfabrik" (englisch: "dream factory") oder "Tinseltown" (von englisch "tinsel" für "Glitzerschmuck") führte.

Im Jahr 1853 stand in dem Gebiet, das heute Hollywood umfasst, nur eine Adobehütte. Um 1870 hatte sich in der Gegend eine blühende Landgemeinde entwickelt, in der unterschiedliche Gewächse einheimischer und exotischer Herkunft angebaut wurden. Ihre Bewohner nannten sie "Cahuenga Valley", nach dem nahegelegen "Cahuenga Pass". Daran erinnert heute noch der Straßenname "Cahuenga Boulevard".

Seinen heutigen Namen erhielt Hollywood im Jahr 1886 von der Familie Whitley. Zu jener Zeit begann der aus Oklahoma zugewanderte Harvey J. Whitley, sich hier als Immobilienmakler zu engagieren. Um 1900 hatte die Gemeinde ein Postamt, eine Zeitung, ein Hotel, zwei Märkte sowie 500 Einwohner. Am 14. November 1903 wurde Hollywood nach dem zustimmenden Votum seiner Wähler als eigenständige Gemeinde anerkannt. Nur sieben Jahre später, im Jahr 1910, stimmten die Einwohner Hollywoods in einer Volksabstimmung der Eingemeindung nach Los Angeles zu. Der Grund hierfür war vor allem der Zugang zur Wasserversorgung der benachbarten Großstadt. Im Auftrag der Wasserverwaltung von Los Angeles wurde seit 1908 an dem "Los Angeles Aqueduct" gebaut, der in großen Mengen preiswertes Trinkwasser aus dem Owens Valley ins trockene Südkalifornien transportieren sollte. Mit Hilfe dieses Wassers war die Großstadt Los Angeles so in der Lage, eine Vielzahl von Nachbargemeinden einzugemeinden. Andere Gemeinden mit eigener Wasserversorgung wie z. B. Burbank sind aus dem gleichen Grund noch heute unabhängig.

Noch in demselben Jahr 1910 besuchte der Filmregisseur D. W. Griffith aus New York mit seiner Schauspielertruppe Hollywood, um dort Aufnahmen für den ersten in Hollywood produzierten Film "In Old California" zu drehen. Der Film wurde am 10. März 1910 uraufgeführt. Griffith und seine Mitarbeiter blieben mehrere Monate und stellten eine Reihe von Filmen fertig, bevor sie nach New York zurückkehrten. Der eigentliche Aufstieg Hollywoods begann im Jahr darauf, als David Horsleys Nestor Company hier das erste Filmstudio eröffnete. Noch im gleichen Jahr siedelten 15 weitere, "Independents" (Unabhängige) genannte Unternehmen von New York, dem damaligen Zentrum der Filmindustrie, nach Hollywood über. Zu den Pionieren der ersten Stunde gehörte auch Carl Laemmle aus Laupheim in Württemberg, Gründer der "Independent Moving Pictures Company". In den folgenden Jahren siedelten immer mehr Filmstudios nach Hollywood und einigen umliegenden Orten (z. B. Burbank) um, um dem in New York vorherrschenden Monopol der Motion Picture Patents Company (MPPC) zu entkommen. Um 1915 wurde bereits die Mehrheit aller amerikanischen Filme in der Region von Los Angeles produziert.

Es gab viele Gründe für diesen Umzug. Neben ökonomischen waren es das geeignetere Klima und die gleichmäßigere Tageslänge (zu dieser Zeit hatte man noch kein adäquates Kunstlicht, man drehte also entweder im Freien oder in einem Studio mit Glasdach oder ähnlichem). Mitentscheidend war zweifelsohne auch die große Entfernung zu New York, von wo aus die mächtige MPPC alle ihr nicht angeschlossenen Unternehmen mit hohen Strafen und Lizenzgebühren bedrohte.

In den 1920er Jahren war Hollywood zur Welthauptstadt der Filmindustrie avanciert. Diese begann sich in dieser Zeit in wachsendem Umfang durch prunkvolle oder exotische Kinopaläste zu feiern, wie z. B. das Grauman’s Chinese Theatre oder das Egyptian.

Zur Filmindustrie kamen nach dem Zweiten Weltkrieg das Fernsehen und die Musikindustrie hinzu: Am 22. Januar 1947 begann "KTLA", der erste Fernsehsender der Stadt, mit dem Sendebetrieb. 1952 wurde an der Kreuzung von Beverly Boulevard und Fairfax Avenue die "CBS Television City" eröffnet, zu jener Zeit eines der größten Fernsehstudios. Noch heute werden in den von den Architekten Pereira & Luckman errichteten Gebäuden Fernsehsendungen wie z. B. "Dancing with the Stars" oder "The Late Night Show" produziert.

Zu den modernen architektonischen Sehenswürdigkeiten Hollywoods kam wenige Jahre später das von "Welton Becket" geplante "Capitol Records Building" (1956) in der "Vine Street" hinzu: Das Gebäude hat deutliche Ähnlichkeit mit einem Stapel 45-Schallplatten mit einer Nadel auf der Spitze, sodass für jeden Passanten die Nutzung als Hauptquartier des Plattenlabels Capitol Records erkennbar ist.

Nachdem der architektonische Reichtum Hollywoods jahrzehntelang von Vernachlässigung und Abriss bedroht war, werden die erhaltenen Bauwerke seit den 1980er Jahren immer mehr geachtet. So hat etwa der Hollywood Boulevard seit 1985 einen Eintrag im National Register of Historic Places. Gleichzeitig werden viele Gegenden in Hollywood, insbesondere rund um den Hollywood Boulevard, immer stärker gentrifiziert. Dazu trug auch die 1999 eröffnete "Red Line" bei, eine U-Bahn-Linie der Metro Los Angeles, die seitdem den zentralen Geschäftsbezirk Hollywoods mit Downtown Los Angeles verbindet.

Im Jahr 2002 versuchten Bürger aus Hollywood und San Fernando Valley, in einem Volksbegehren die Unabhängigkeit von Los Angeles durchzusetzen. Beide Begehren verfehlten die jeweils erforderlichen Stimmenzahlen jedoch bei Weitem.

Seit der Fertigstellung der "Red Line"-U-Bahn der Metro Los Angeles von der Union Station über Downtown nach North Hollywood ist das Viertel für US-Verhältnisse überdurchschnittlich gut an den Öffentlichen Personenverkehr angebunden. In der Folge entschied sich die Stadtplanung, am Sunset Boulevard, am Hollywood Boulevard und an der "Vine Street" eine stark verdichtete Bebauung mit Hochhäusern vorzusehen und so die Transportmöglichkeiten der U-Bahn auszunutzen. Bis 2030 ist gegenüber 2010 dadurch ein Anstieg der Bevölkerung von 25 % im Viertel, konzentriert im Umfeld der U-Bahn-Stationen, geplant. Die Planungen sind umstritten, weil sie den Charakter Hollywoods verändern würden.

In den Hollywood Hills über der Stadt befindet sich das bekannte Hollywood Sign, große Buchstaben, die 1923 als „Hollywoodland“ errichtet wurden, um für den Verkauf von Grundstücken zu werben. Als die Buchstaben mehr und mehr verfielen, wurde 1978 durch die Handelskammer von Hollywood mit Unterstützung einiger Prominenter zum 91. Geburtstag der Stadt ein neuer Schriftzug aufgestellt.

Zu den größten Filmstudios in Hollywood zählen derzeit die Universal Studios und Warner Bros. Die Geschichte des „Hollywoodkinos“ lässt sich in mehrere Phasen gliedern, unter anderem die "Klassische Periode" und das New Hollywood von 1967 bis 1976.

Zu den weltbekannten Sehenswürdigkeiten in Hollywood gehört der Walk of Fame. Auf dem Gehweg sind über 2.500 Platten mit Sternen für Stars eingelassen, die in fünf Kategorien mit jeweils einem entsprechenden Symbol eingeteilt sind. Mit den Sternen werden lebende wie auch verstorbene Prominente geehrt, die eine wichtige Rolle vor allem in der amerikanischen Unterhaltungsindustrie spielten oder noch spielen. Darüber hinaus wird aber auch an fiktive Personen erinnert oder in Einzelfällen an Organisationen und Einrichtungen wie z. B. das "LAPD (Los Angeles Police Department)".

Die Stadträte Goldberg und Koretz legten am 16. Februar 2005 einen Gesetzentwurf vor, der die Grenzen für den Bereich Hollywood festlegte. Nach der einmütigen Unterstützung durch die "Chamber of Commerce" und den "LA City Council" wurde der Entwurf am 28. August 2006 vom damaligen Gouverneur Arnold Schwarzenegger als "Assembly Bill 588" genehmigt; seitdem hat Hollywood offizielle Bezirksgrenzen.

Das Planungsgebiet Hollywood umfasst nun offiziell den Bereich östlich von Beverly Hills und West Hollywood und südlich von Burbank. Vom restlichen Stadtgebiet von LA wird es abgegrenzt (im Uhrzeigersinn) durch Crescent Drive, Wonderland Avenue, Lookout Mountain Avenue, Laurel Canyon Boulevard, Mulholland Drive, Cahuenga Boulevard, Barham Boulevard, Golden State Freeway, Glendale Boulevard, Rowena Avenue, Hyperion Avenue, Fountain Avenue, Sunset Boulevard, Santa Monica Boulevard, Hoover Street, Melrose Avenue, June Street und Rosewood Avenue.

Im Projekt "Mapping L.A." der Los Angeles Times werden die Grenzen deutlich enger gefasst, da bspw. Hollywood Hills, Los Feliz und Griffith Park als eigene Stadtteile gezählt werden.





</doc>
