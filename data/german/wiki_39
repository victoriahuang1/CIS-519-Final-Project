<doc id="4350" url="https://de.wikipedia.org/wiki?curid=4350" title="Reduktion (Chemie)">
Reduktion (Chemie)

Eine Reduktion ist eine chemische Teilreaktion, bei der Elektronen von einem Teilchen (Atom, Ion oder einem Molekül) aufgenommen werden. Die Oxidationszahl des Teilchens wird dabei kleiner. Sie tritt immer zusammen mit einer Oxidation auf. Beide Phänomene zusammen werden als Redoxreaktion bezeichnet. 

Historisch wurde die Reduktion als ein Entzug von Sauerstoff aus einem Oxid betrachtet. Reduktion (von lat. "" für „Zurückführung“) war damit eine Reaktion, bei der eine Oxidation rückgängig gemacht wurde. Oxidation wurde als Vereinigung einer Verbindung oder eines Elements mit Sauerstoff definiert und beruhte auf den Erkenntnissen von Antoine Laurent de Lavoisier. 

Oxide edler Metalle, wie Silber(I)-oxid, zerfallen beim bloßen Erhitzen. Aus Silber(I)-oxid bildet sich Sauerstoff und elementares Silber. 

Wird Kupfer(II)-oxid im Wasserstoffstrom erhitzt, so entsteht metallisches Kupfer und Wasser. Wasserstoff wirkt hier als Reduktionsmittel und entzieht dem Kupfer(II)-oxid Sauerstoff.

Heute gilt eine breitere Sichtweise, die nicht auf Reaktionen von sauerstoffhaltigen Verbindungen begrenzt ist und die klassische Betrachtung integriert hat.

Reduktion ist eine Reaktion bei der ein ein- oder mehratomiges Teilchen Ox ein oder mehrere Elektronen aufnimmt. Dabei bildet sich das Teilchen Red:

Ox reagiert als Elektronenakzeptor, Ox und Red bilden ein sogenanntes Redox-Paar. Die Elektronen stammen von einem zweiten Redox-Paar bei dem eine Oxidation erfolgt. Während im Bereich der Elektrochemie, wie bei einer Elektrolyse oder einer Galvanischen Zelle, der Elektronentransfer zwischen den zwei Redox-Paaren eine messbare Größe ist, lässt sich in anderen Fällen die Reduktion nur über die damit verbundene Erniedrigung der Oxidationszahl von Ox erkennen.

Betrachtet man eine Reduktion als Gleichgewichtsreaktion, ist die Rückreaktion eine Oxidation. Solche Gleichgewichte liegen beispielsweise in einem nicht genutzten Akkumulator vor. Während beim Entladen die Teilreaktion in die eine Richtung verläuft, führt das Laden zu einer Umkehrung der Reaktionsrichtung.

Obwohl eine Reduktion nie ohne Oxidation erfolgt und daher eine Redoxreaktion vorliegt, wird oft eine Reaktion aus der Perspektive des gewünschten Produkts betrachtet. So wird von Reduktion von Eisenerz zum elementaren Eisen oder einer kathodischen Reduktion von Aluminiumoxid zu Aluminium gesprochen.

Wird ein Eisennagel in eine wässrige Kupfer(II)-sulfatlösung gestellt, bildet sich ein rotbrauner Belag von metallischem Kupfer auf dem Nagel. Das Kupfer wird dabei reduziert, das Eisen zu Fe-Ionen oxidiert.

Das Eisen, das während der Redoxreaktion selbst oxidiert wird, nennt man in diesem Zusammenhang auch Reduktionsmittel, weil seine Anwesenheit die Reduktion des Kupfers erst ermöglicht. Reduktion bedeutet dabei immer ein Absinken der Oxidationszahl durch Aufnahme von Elektronen. Oxidation bedeutet dagegen die Abgabe von Elektronen und somit eine Erhöhung der Oxidationszahl. In diesem Fall entsprechen die Ladungen der Teilchen ihrer Oxidationszahl. 

Die thermische Zersetzung von Silber(I)-oxid mit den Oxidationsstufen formula_4 ist auch eine Reaktion, bei der Elektronen übertragen werden. 

Bei der Umsetzung von Kupferoxid mit Wasserstoff wird Kupfer reduziert. Als Reduktionsmittel agiert hier Wasserstoff. Die Oxidationsstufe der Sauerstoffatome bleibt in der Reaktion unverändert, die Atome wechseln jedoch ihren Bindungspartner. Die formal entstehenden H-Ionen kombinieren mit den formal unverändert vorhandenen O-Ionen zum Reaktionsprodukt Wasser mit den Oxidationsstufen formula_5.

Eine Aufnahme von Wasserstoff durch organische Verbindungen führt zu einer Verringerung der Oxidationszahl eines oder mehrerer Kohlenstoffatome. Die katalytischen Hydrierung von 2-Buten führt zu "n"-Butan: 

Die Oxidationszahlen der ehemals durch Doppelbindung verknüpfte Kohlenstoffatome ändern sich von −1 auf −2. Formal haben diese Atome je ein Elektron und je ein Proton aufgenommen. Das 2. Redox-Paar mit dem Reduktionsmittel H kann so formuliert werden: 

In dieser Reaktion wird Wasserstoff formal oxidiert und die Elektronen formal freigesetzt. Die Gesamtreaktion ist eine Redoxreaktion, aus der Perspektive des Edukts 2-Buten erfolgt eine Reduktion der Verbindung zu "n"-Butan. Oft wird diese Reaktion als Additionsreaktion betrachtet. Aus diesem Blickwinkel sind die Änderungen von Oxidationsstufen irrelevant. 

Häufiger wird im Zusammenhang mit sauerstoffhaltigen, organischen Verbindungen von Reduktion gesprochen, wie beispielsweise der Umsetzung von Ketonen oder Aldehyden zu Alkoholen. Nimmt Acetaldehyd Wasserstoff auf, so entsteht Ethanol. Dabei ändert sich die Oxidationsstufe der Carbonylgruppe von +1 nach −1:

Reduktionen sind in der Biochemie wichtig. In vielen Stoffwechselwegen einer Zelle findet eine Reduktion durch Übertragung von Wasserstoff statt. Coenzyme wie NADH, NADPH oder FADH sind befähigt, formal ein Hydridion oder Wasserstoff auf eine andere Verbindung zu übertragen.



</doc>
<doc id="4351" url="https://de.wikipedia.org/wiki?curid=4351" title="Redoxreaktion">
Redoxreaktion

Eine Redoxreaktion (eigentlich: Reduktions-Oxidations-Reaktion) ist eine chemische Reaktion, bei der ein Reaktionspartner Elektronen auf einen anderen überträgt. Hierbei findet also eine Elektronenabgabe (Oxidation) durch einen Stoff (ein sog. Reduktionsmittel, beispielsweise Wasserstoff) sowie eine Elektronenaufnahme (Reduktion) durch einen anderen Stoff (ein sog. Oxidationsmittel, beispielsweise Sauerstoff) statt. Redoxreaktionen sind von grundlegender Bedeutung in der Chemie: Viele Stoffwechsel- und Verbrennungsvorgänge, technische Produktionsprozesse und Nachweisreaktionen basieren auf solchen Elektronenübertragungsreaktionen.

In einer Redoxreaktion reagiert ein Stoff A, der Elektronen abgibt (Reduktionsmittel, Donator genannt) mit einem Stoff B, der diese Elektronen aufnimmt (Oxidationsmittel, Akzeptor). Die allgemeinen Reaktionsschemata lauten:

Um zu bestimmen, welcher Stoff in einer Reaktion oxidiert und welcher reduziert wird, können die Oxidationszahlen herangezogen werden.

Bei einer "Komproportionierung" (oder auch: Synproportionierung) reagieren Verbindungen, die ein Element in "niedriger" Oxidationsstufe (Reduktionsmittel) enthalten, zusammen mit Verbindungen, in denen das betreffende Element in "höherer" Oxidationsstufe (Oxidationsmittel) vorliegt, zu einer Verbindung mit "mittlerer" Oxidationsstufe.

Man spricht von einer "Disproportionierung", wenn bei einer chemischen Reaktion Elemente mit mittlerer Oxidationsstufe in solche mit einer niedrigen und einer höheren übergehen. Diese Reaktionen verlaufen häufig unter dem Einfluss eines Katalysators (Stoff, der eine chemische Reaktion beschleunigt, ohne sich dabei zu verändern) ab.

Die Reaktion von Wasserstoff mit Sauerstoff (Knallgas), bei der Wasser (HO) entsteht, wird Knallgasreaktion genannt. Jede Verbrennung stellt eine Redoxreaktion dar. So auch das Verbrennen von Benzin, Diesel und Kerosin in Kraftfahrzeugen, Schiffen und Flugzeugen. Kraftstoffe, die viel Energie freisetzen, können als Raketentreibstoff verwendet werden. In der Pyrotechnik wird ebenfalls auf Oxidations- und Reduktionsmittel für verschiedene Feuerwerkseffekte gesetzt. Bei Explosivstoffen kommt es zu einer schlagartig exothermen Redoxreaktion, bei der Gas frei wird, sich temperaturbedingt stark ausdehnt und somit die Sprengkraft bewirkt.

Reagiert ein Metallatom mit einem Sauerstoffatom, so kann man die Oxidation des Metalls anhand folgender Reaktionsgleichungen nachvollziehen:

Sauerstoff hat in diesem Fall das Bestreben, durch Aufnahme von zwei Elektronen eine stabile Valenzelektronenschale mit insgesamt acht Elektronen aufzubauen (Oktettregel). Das Metall wiederum kann durch Abgabe der Elektronen teilbesetzte Schalen auflösen und so die nächstniedrigere stabile Elektronenkonfiguration erreichen. Wird Eisen oxidiert, so entsteht der aus dem Alltag bekannte Rost. Beim aktiven kathodischen Korrosionsschutz werden wiederum Redoxreaktionen ausgenutzt.

Die Verbrennung von fossilen Energieträgern wie Kohle, Erdöl, Erdgas wird in Wärmekraftwerken genutzt, um elektrische Energie zu erzeugen.
Zahlreiche Reaktionen aus dem Themenbereich der Metallurgie sind klassische Beispiele für technisch bedeutsame Redoxreaktionen in der Industrie.

Beim Hochofenprozess wird Eisen mit Koks reduziert. Als Nebenreaktion entsteht unter anderem das starke Reduktionsmittel Kohlenmonoxid, welches bei Sauerstoffmangel im Hochofen nicht sofort zu Kohlenstoffdioxid weiter reagiert.

Zur Herstellung von zahlreichen Metallen aus ihren Oxiden kann Aluminium als Reduktionsmittel verwendet werden, wenn die Metalle edler als Aluminium sind. Das Verfahren, bei dem Aluminiumpulver oder -späne eingesetzt werden, heißt aluminothermisches Verfahren. Eine Mischung aus Eisenoxid und Aluminium wird Thermit genannt und wird beispielsweise zum Zusammenschweißen von Eisenbahnschienen und für Brandbomben verwendet.

Bei der Herstellung von Margarine werden Pflanzenöle katalytisch hydriert (Fetthärtung).

Die Umrötung von Fleisch durch Pökelsalze ist ebenfalls eine Redoxreaktion. Es kommt zur Ausbildung stabiler Komplexe leuchtend roter Farbe (Nitrosylmyoglobin und Nitrosylmetmyoglobin).

Fetthaltigen Lebensmitteln werden Antioxidantien zugesetzt, um Oxidationsschäden am Produkt (und damit ein Ranzigwerden) zu verhindern. Stattdessen werden die zugesetzten Antioxidantien oxidativ angegriffen.

Zahlreiche Analysemethoden basieren auf Redoxprozessen. Klassische Nachweisreaktionen oder Trennungsgänge basieren zum Teil auf Redoxreaktionen. Ebenso moderne elektrochemische Analysemethoden und die quantitative Redoxtitration.

Im Haber-Bosch-Verfahren wird Ammoniak aus den Elementen Stickstoff und Wasserstoff hergestellt. Dies ist unter anderem ein wichtiges Vorläuferprodukt für die Gewinnung von Stickstoffdünger und somit für die Landwirtschaft von enormer Bedeutung.

Viele zellbiologische Prozesse beinhalten Redox-Reaktionen. Häufig beteiligt sind die Coenzyme NAD, NADP und FAD, die Reduktionsmittel in Form von Hydridionen übertragen. Diese Reduktionsäquivalente dienen oft dazu, Energie durch Substratkettenphosphorylierung oder oxidative Phosphorylierung in Form von GTP bzw. ATP umzuwandeln.

Bei der Zellatmung wird Glucose (Traubenzucker) zu Kohlenstoffdioxid oxidiert und Sauerstoff zu Wasser reduziert. Die vereinfachte Summenformel lautet:

Die Umkehrreaktion ist die Photosynthese, bei der grüne Pflanzen aus Kohlenstoffdioxid und Wasser – durch Energiezufuhr (Licht) – Traubenzucker (Glucose) aufbauen und Sauerstoff freisetzen. Die Brutto-Reaktionsgleichung lautet:

Organismen wie die Bäckerhefe können während der alkoholischen Gärung Zucker zu Trinkalkohol ("Ethanol") und Kohlenstoffdioxid umwandeln um daraus Energie zu gewinnen.

Archaeen aus der Gruppe der Methanbildner können unter Sauerstoffabschluss Methan aus Kohlenstoffdioxid herstellen. Der Vorgang wird Methanogenese genannt.

Die "Elektrochemie" ist das Teilgebiet der physikalischen Chemie, welches sich mit dem Zusammenhang zwischen elektrischen und chemischen Vorgängen befasst. Wenn daher eine Redoxreaktion durch einen elektrischen Strom erzwungen wird oder einen solchen liefert, so ist dies ein elektrochemischer Vorgang.
Die für die Elektrochemie entscheidenden Vorgänge laufen dabei an der Phasengrenze ab. Die Elektrochemie ist also die Wissenschaft der Vorgänge zwischen einem Elektronenleiter (Elektrode) und einem Ionenleiter (Elektrolyt).
Von zentraler Bedeutung ist die Nernst-Gleichung, welche die Konzentrationsabhängigkeit des Elektrodenpotentials beschreibt. Dies lässt sich mithilfe der Redox-Titration analytisch nutzen um Ionen in Lösung zu bestimmen. Theoretisch wird die Übertragung von Außenelektronen in Lösung durch die Marcus-Theorie beschrieben.

Wird die Redoxreaktion durch eine von außen angelegte elektrische Spannung erzwungen, nennt man diesen Vorgang Elektrolyse – wird durch die chemische Reaktion geeigneter Substanzen eine messbare Spannung hervorgerufen, so liegt ein galvanisches Element vor. Diese Spannungen (Redoxpotentiale) sind charakteristisch für die jeweiligen Reaktionen und auf einer Skala dokumentiert, der elektrochemischen Spannungsreihe. Hier wird die "Stärke" eines Oxidations- oder Reduktionsmittels "messbar".

Elektrochemische Redoxreaktionen laufen in einer galvanischen Zelle ab:




</doc>
<doc id="4352" url="https://de.wikipedia.org/wiki?curid=4352" title="ROT13">
ROT13

ROT13 (, zu Deutsch in etwa „rotiere um 13 Stellen“) ist eine Caesar-Verschlüsselung (auch Verschiebechiffre genannt), mit der auf einfache Weise Texte verschlüsselt werden können. Dies geschieht durch Ersetzung von Buchstaben – bei ROT13 im Speziellen wird jeder Buchstabe des lateinischen Alphabets durch den im Alphabet um 13 Stellen davor bzw. dahinter liegenden Buchstaben ersetzt.

Der Name "ROT13" stammt aus dem Usenet in den frühen 1980er Jahren. ROT13 ist nicht zur sicheren Verschlüsselung gedacht, es wird im Gegensatz dazu sogar oft als Beispiel für eine schwache, unsichere Verschlüsselung genannt. Vielmehr dient ROT13 dazu, einen Text unlesbar zu machen, also zu verschleiern, so dass eine Handlung des Lesers erforderlich ist, um den ursprünglichen Text lesen zu können. ROT13 lässt sich daher mit Lösungen von Rätseln in Zeitschriften vergleichen, die kopfüber gedruckt werden, damit sie nicht sofort versehentlich gelesen werden können.

ROT13 selbst benutzt nur die 26 Buchstaben des lateinischen Alphabets, aber es gibt erweiterte Methoden, die auch Zahlen und Sonderzeichen beachten.

Der Name ROT13 für den relativ trivialen Algorithmus trat Vermutungen zufolge ursprünglich in der Newsgroup "net.jokes" auf. Es gab dort Versuche, die Leser vor möglicherweise anstößigen Witzen besonders zu bewahren, jedoch wurde eine einzelne Kategorie abgelehnt, da kein spezieller Platz für diese eher abgelehnten Beiträge geschaffen werden sollte. Somit wurde das einfache Verfahren ROT13 benutzt, um Leser vor dieser Art von Witzen direkt zu schützen. Es wurden auch die Pointen der Witze verschlüsselt, so dass sie nicht unabsichtlich zu früh gelesen werden konnten.

Das Verfahren wurde seitdem in verschiedenen Bereichen zum Schutz der Leserschaft verwandt, so dass die Leser nicht unbeabsichtigt etwas lesen, was sie nicht lesen wollen; abgesehen vom oben genannten Versuch eines "freiwilligen Jugendschutzes" beispielsweise zum Schutz vor Spoilern (etwa inhaltliche Beschreibung eines Films). Einige E-Mail-Programme, Texteditoren und viele Newsreader bieten eine ROT13-Funktion an.

ROT13 hat gegenüber anderen Verschiebechiffren (ROT-formula_1, also gegenüber einer Verschiebung um "n" ≠ 13 Stellen des Alphabets) den Vorteil, dass die Ver- und Entschlüsselung identisch abläuft, also mathematisch eine Involution vorliegt. Wird ein bereits einmal verschlüsselter Text erneut verschlüsselt, so wird er also entschlüsselt. Verbreitet ist deshalb auch der Witz von „doppelt ROT13-verschlüsselten“ Inhalten (manchmal auch ROT-26 genannt).

Aufgrund der Einfachheit des Algorithmus lassen sich verschlüsselte Texte sowohl manuell – beispielsweise anhand einer Tabelle – als auch durch simple Programme relativ einfach und schnell entschlüsseln. Bei UNIX-Systemen existiert ein Kommandozeilenprogramm namens codice_1 (für engl. "transliterate"), die zur Ver- und Entschlüsselung benutzt werden kann:
Eine Methode für automatische Entschlüsselung wurde in zahlreiche Newsreader eingebaut. Da ROT13 Buchstaben des Alphabets jeweils nur wieder mit Buchstaben ersetzt, verursachte dieses Verfahren bei Newsreadern keine Fehler wie andere einfache Verschlüsselungen, bei denen die Buchstaben auch durch Sonderzeichen ersetzt wurden, mit denen die Software nicht zurechtkam.

Zur Ver- und Entschlüsselung lässt sich folgende Tabelle benutzen:
Es wird jeweils der oben stehende Buchstabe durch den darunter stehenden ersetzt – sowohl für Verschlüsselung als auch für Entschlüsselung.

Als Beispiel dient hier die teilweise Verschlüsselung eines Witzes, so dass Anfang des Witzes und Pointe getrennt bleiben:

Durch Anwendung von ROT13 auf die zweite Zeile wird die Pointe offengelegt:

ROT13 ist ein Sonderfall der historischen Verschlüsselungsmethode, die der römische Feldherr Gaius Iulius Caesar vor mehr als 2000 Jahren benutzte und die unter dem Namen "Caesar-Verschlüsselung" bekannt ist. ROT13 ist eine feste Caesar-Verschiebung um 13 Buchstaben (entspricht dem Schlüssel M) und ist daher keinesfalls als sichere Verschlüsselung geeignet. Mit einfachsten kryptoanalytischen Methoden wie der Untersuchung der Buchstabenhäufigkeit oder der Analyse bezüglich häufiger Buchstabenkombinationen kann diese Methode sehr schnell entlarvt und gebrochen werden.

Der einzige Zweck von ROT13 ist also der, dass der Empfänger einer Nachricht die "bewusste" Entscheidung treffen muss, den verschlüsselten Abschnitt zu lesen. Da ROT13 eine offenkundig unsichere Verschlüsselungsmethode ist, wurde diese Bezeichnung zum Schlagwort für unsichere Verschlüsselungen.

Ironischerweise besitzt die (heute veraltete) DES-Verschlüsselung eine Ähnlichkeit mit ROT13. Bei ihr existieren nämlich vier sogenannte schwache Schlüssel, welche ihre sonst recht hohe Sicherheit völlig aushebeln. Genauso wie bei ROT13 erzeugt die "Verschlüsselung" eines Geheimtexts wiederum den Klartext, falls Ver- und Entschlüsselung mit demselben schwachen Schlüssel geschehen.

Da es in einigen Fällen auch sinnvoll ist, dass Zahlen und/oder Sonderzeichen wie @, - oder ? nicht auf den ersten Blick erkannt werden können, wurde zudem ein Verfahren namens ROT18 entwickelt, welches bei den Großbuchstaben die Ziffern von 0 bis 9 einbezieht, bei den Kleinbuchstaben aber mit ROT13 identisch ist. ROT18 wird allerdings von keinem gängigen E-Mail-Programm oder Newsreader unterstützt. Alternativ gibt es das Verfahren ROT5, das die Zahlen extra behandelt und sie um fünf Stellen weiterschiebt. Der noch weniger verbreitete ROT47-Algorithmus wiederum wendet das von ROT13 bekannte Verfahren auf alle ASCII-Zeichen, die keine Leer- und Steuerzeichen sind, d. h. Zeichen zwischen 33 („!“) und 126 („~“), an.





</doc>
<doc id="4353" url="https://de.wikipedia.org/wiki?curid=4353" title="Rechtsform">
Rechtsform

Die Rechtsform ist der durch Gesetze zwingend vorgeschriebene, rechtliche Rahmen von Gesellschaften, mit dem einige gesetzlich vorgegebene Strukturmerkmale verbunden sind und mit dem Gesellschaften am Wirtschaftsleben teilnehmen.

Der Begriff "Rechtsform" wird im Gesetz zwar gebraucht ( Handelsgesetzbuch (HGB), sehr häufig im Umwandlungsgesetz UmwG), eine Legaldefinition gibt es indes nicht. Mit einer Rechtsform verbindet das Gesetz national wie international unterschiedliche Grundstrukturen hinsichtlich bestimmter Mitgliedschafts- und Haftungsformen. Es steht ein geschlossener Katalog von Rechtsformen zur Verfügung (Typenzwang), der nicht beliebig erweitert werden kann. Es ist daher nicht möglich, eine neue Rechtsform zu konstruieren und mit dieser am Markt aufzutreten. Allerdings bietet das Gesetz Spielraum für eine individuelle Gestaltung der gesetzlich vorgegebenen Grundstrukturen. Dieser Spielraum erlaubt Mischformen (wie die GmbH & Co. KG oder die AG & Co. KGaA). Bereits im Januar 1986 hatte der Europäische Gerichtshof (EuGH) die Möglichkeit eingeräumt, die geeignete Rechtsform für die Ausübung der Tätigkeiten in einem anderen Mitgliedstaat frei zu wählen. Im September 2003 entschied der EuGH schließlich, dass die in einem EU-Mitgliedstaat gegründete Rechtsform in einem anderen EU-Staat anerkannt werden muss, wenn sie dorthin ihren Sitz verlegt. So gelangen ausländische Rechtsformen nur über den Weg der Sitzverlegung auch nach Deutschland und umgekehrt.

Der Mindestinhalt des Gesellschaftsvertrages erfasst nicht die Einigung über die Rechtsform als OHG, KG oder BGB-Gesellschaft. Das folgt aus dem Rechtsformzwang bei Personengesellschaften nach Abs. 1 und Abs. 1 HGB. Bei Kapitalgesellschaften ist hingegen die Rechtsform bereits Teil des Mindestinhalts ( Abs. 3 AktG, ).

Wer ein Unternehmen gründet, muss sich zunächst für eine Rechtsform entscheiden. Die Rechtsformwahl ist ein typisch betriebswirtschaftliches Entscheidungsproblem, weil sich aus den unterschiedlichen Merkmalsausprägungen einzelner Rechtsformen weitreichende betriebswirtschaftliche Konsequenzen ergeben können. Die Wahl der Rechtsform wirkt sich auf mitgliedschafts- und haftungsrechtliche sowie steuerliche Überlegungen aus. Hierzu gehören die Haftung der Gesellschafter und deren Recht zur Geschäftsführung, Betriebsgröße, Kapitalbedarf, Börsenfähigkeit, Aufnahme neuer Mitgesellschafter, Rechnungslegung, Publizitätspflichten, Mitbestimmungs- (ausgeschlossen bei OHG und KG), Konzern- (AG und SE als europaweite Holding) oder gewerberechtliche Fragen als Entscheidungskriterien. Während bei Personengesellschaften mindestens ein Gesellschafter auch mit seinem gesamten privaten Vermögen für die Verbindlichkeiten der Gesellschaft haftet (Ausnahme: GmbH & Co. KG), ist die Haftung bei Kapitalgesellschaften begrenzt (z. B. auf die jeweiligen Einlagen der Gesellschafter). Wird eine natürliche Person unternehmerisch tätig, so haftet sie mit ihrem Gesamtvermögen. Es können jedoch auch Ein-Personen-GmbHs gegründet werden, in denen ein Gesellschafter alle Anteile besitzt.

In den einzelnen Staaten gibt es aus Gründen der Rechtssicherheit und des Gläubigerschutzes einen geschlossenen Katalog von möglichen Rechtsformen, unter denen der Gründer sich für eine entscheiden kann. Die gesetzlich vorgesehenen Rechtsformen besitzen einen Rechtsrahmen, an den sich ein Gründer bei der Errichtung des Gesellschaftsvertrages orientieren muss (Rechtsformzwang).

Diese Rechtsformwahl ist bei bestimmten Geschäftstätigkeiten allerdings gesetzlich eingeschränkt. Eine bestimmte Rechtsform ist vorgeschrieben bei Versicherungsgesellschaften (nur in der Rechtsform der AG, VvAG, SE oder Anstalten des öffentlichen Rechts und Körperschaften des öffentlichen Rechts; Abs. 2 VAG), für private Bausparkassen (AG; Abs. 1 BauSparkG); bei Pfandbriefbanken hielt man die bisher einschränkende Vorgabe einer zulässigen Rechtsform (AG und KGaA für Hypothekenbanken) für nicht mehr erforderlich. Kapitalanlagegesellschaften dürfen nur in der Rechtsform geführt werden, die das Kapitalanlagegesetzbuch zulässt (z. B. KAGB). Nach Abs. 1 KWG ist für Kreditinstitute im Sinne des Abs. 1 KWG lediglich die Rechtsform des Einzelkaufmannes ausgeschlossen, alle übrigen Rechtsformen sind zulässig (OHG und KG nennen sich „Privatbankiers“, AG und KGaA „Aktienbanken“). Nach HGB müssen jedoch alle Kreditinstitute, auch wenn sie nicht in der Rechtsform einer AG betrieben werden, ihren Jahresabschluss nach den Vorschriften für große Kapitalgesellschaften aufstellen.

In Deutschland sind 14 Rechtsformen (ohne Mischformen) zulässig. Jeder Zusammenschluss von natürlichen Personen zu einer Gesellschaft löst eine Entscheidung auch über deren Rechtsform aus. In Deutschland und international wird generell zwischen Rechtsformen des Privatrechts (') und öffentlichen Rechtsformen (') unterschieden. 

Die einmal gewählte Rechtsform muss nicht auf Dauer beibehalten werden. Man unterscheidet den Rechtsformwechsel kraft Gesetzes und die Umwandlung. 

Auch die Rechtsordnungen anderer Staaten kennen Rechtsformen, in denen die dort ansässigen Unternehmen geführt werden können. Teilweise sind ausländische Rechtsformen den deutschen ähnlich, allerdings gibt es auch erhebliche Abweichungen. In Österreich und der Schweiz sind die Rechtsformen den deutschen sehr ähnlich. Die häufigste Rechtsform in Großbritannien ist die Limited, von der es als Unterarten die der GmbH sehr ähnlichen ' und die der AG ähnelnden ' gibt. Einzelunternehmen heißen ', OHGs heißen '. In den USA ist die häufigste Rechtsform die dem Einzelunternehmen entsprechende ', gefolgt von der ' und der ' als Pendant zur GmbH und die ' als AG.
Auf Ebene der Europäischen Union sind folgende Rechtsformen geregelt, die in allen Ländern der EU genutzt werden können:


Im Jahre 2012 lag dem Statistischen Bundesamt zufolge der Anteil der Kapitalgesellschaften an allen Rechtsformen bei 16,4 % (davon 96 % GmbH, 1,5 % AG), Personengesellschaften bei 13,0 % (davon 48,2 % BGB-Gesellschaft, 30,9 % GmbH & Co. KG).

In Deutschland gibt es folgende Rechtsformen, die sich nach ihren Vorschriften zur Gründung und Leitung teilweise stark unterscheiden:






Eine Sonderform von juristischen Personen nehmen Gewerkschaften und Politische Parteien ein, sofern sie keine eingetragenen Vereine sind. Sie gelten dennoch als rechtsfähig.

Als noch im 20. Jahrhundert tätige (heute übergeleitete) Rechtsformen sind noch zu nennen:


In Österreich gibt es folgende Rechtsformen:





Diese Gebilde können als Körperschaftsteuersubjekte in Betracht kommen.

In Frankreich gibt es folgende Rechtsformen:




In Litauen gibt es folgende Rechtsformen:



In Großbritannien gibt es folgende Rechtsformen:



In Russland gibt es folgende Rechtsformen: Zum 1. September 2014 wurden die OAO und SAO abgeschafft.
In der Schweiz gibt es im Privatrecht folgende Rechtsformen:





In China gibt es, wie in Deutschland, eine generelle Trennung zwischen Personengesellschaften wie zum Beispiel dem Gewöhnlichen Partnerschaftsunternehmen und Kapitalgesellschaften. Seit über 20 Jahren ist Equity Joint Venture der am weitesten verbreitete Typ ausländischer Investments in China. Equity Joint Ventures sind Kapitalgesellschaften, die der Rechtsform nach einer deutschen GmbH gleichen. Mindestens ein chinesischer und ein ausländischer Partner bringen finanzielle, materielle oder immaterielle Mittel in das Gemeinschaftsunternehmen ein. Die Gesellschaft muss zudem ein festgelegtes, behördlicherseits zu genehmigendes gemeinsames Unternehmensziel verfolgen. Im Gegensatz zu der mit deutlich weniger Kapitaleinsatz verbundenen Representative-Office-Variante hat ein Equity Joint Venture mehr Rechte. So darf das Unternehmen Landnutzungsrechte kaufen, unabhängig chinesisches Personal anstellen, Gebäude bauen usw.

In Japan existiert neben der Kabushiki kaisha (Aktiengesellschaft), der Gōdō kaisha (Hybridgesellschaft), der Yūgen Sekinin Jigyō Kumiai (japanische Version einer Limited Liability Partnership) und der Gōshi-gaisha (Kommanditgesellschaft) noch die Sōgo-gaisha (Gesellschaft auf Gegenseitigkeit) für Versicherungsunternehmen. Die "Yūgen-gaisha", die 1940 nach dem Vorbild der deutschen GmbH geschaffen wurde, können seit 2006 nicht mehr gegründet werden. Auf bestehende GmbHs werden die Regelungen bezüglich Aktiengesellschaften angewendet.

Der "Companies Act" von 1973 sieht in Südafrika die "Share Capital"-Rechtsformen der "Public Company" (Ltd.) und der "Private Company (PTY) Ltd." (mit bis zu 50 Aktionären), bei denen nur das Gesellschaftsvermögen haftet, und alle übrigen Gesellschaftsformen mit vollhaftenden Gesellschaftern ("Close Corporation", CC), "Partnership" und "Trust" vor.

In Namibia gibt es im Unternehmensrecht ( von 1973, 2004 und 2007) grundsätzlich die Unterscheidung nach öffentlichen ("public") und privaten ("private") Unternehmen:

Anderen Rechtsgebieten unterliegen die folgenden Unternehmungen:

siehe Gesellschaftsrecht der Vereinigten Staaten

Wichtige deutsche Rechtsformen der OHG, KG, GmbH und AG lassen sich in ihren Grundstrukturen mit internationalen Rechtsformen vergleichen.




</doc>
<doc id="4355" url="https://de.wikipedia.org/wiki?curid=4355" title="Rahm (Begriffsklärung)">
Rahm (Begriffsklärung)

Rahm steht für:


Familienname:


Vorname:

Orte:
Siehe auch:


</doc>
<doc id="4357" url="https://de.wikipedia.org/wiki?curid=4357" title="Reproduktion">
Reproduktion

Als Reproduktion wird ein Vorgang bezeichnet, bei dem etwas vervielfältigt wird, sowie häufig auch die im Ergebnis dessen entstandene Kopie. Insbesondere im Zusammenhang mit sozialen Systemen wird unter Reproduktion neben der Neuerstellung auch die Aufrechterhaltung eines Zustandes verstanden.

Kann ein System mehr als eine Nachbildung (Kopie, Replikat) seiner selbst erzeugen, ist Wachstum bzw. Vermehrung möglich. Deren Geschwindigkeit wird auch als Reproduktionsrate gemessen. Setzt sich das Wachstum bzw. die Vermehrung ungehindert fort, kommt es zu exponentiellem Wachstum.

Unter 'Reproduktion' versteht man in der Soziologie im Zusammenhang mit sozialen Systemen (soziale Reproduktion) neben der Neuerstellung auch die Aufrechterhaltung eines Zustandes ("Reproduktion des Status quo" in im Prinzip dynamischen Systemen).

Bei Lebewesen spricht man von Vermehrung, von vegetativer Vermehrung oder von generativer Vermehrung, geschlechtlicher Fortpflanzung und Fortpflanzung. 

In der landwirtschaftlichen und gärtnerischen Produktion wird grundsätzlich der Begriff "Vermehrung" für alle Fälle der Reproduktion verwendet. Dabei wird unterschieden:






</doc>
<doc id="4358" url="https://de.wikipedia.org/wiki?curid=4358" title="Raytracing">
Raytracing

Raytracing (dt. Strahlverfolgung oder Strahlenverfolgung, in englischer Schreibweise meist "ray tracing") ist ein auf der Aussendung von Strahlen basierender Algorithmus zur Verdeckungsberechnung, also zur Ermittlung der Sichtbarkeit von dreidimensionalen Objekten von einem bestimmten Punkt im Raum aus. Ebenfalls mit Raytracing bezeichnet man mehrere Erweiterungen dieses grundlegenden Verfahrens, die den weiteren Weg von Strahlen nach dem Auftreffen auf Oberflächen berechnen.

Prominenteste Verwendung findet Raytracing in der 3D-Computergrafik. Hier ist der grundlegende Raytracing-Algorithmus eine Möglichkeit zur Darstellung einer 3D-Szene. Erweiterungen, die den Weg von Lichtstrahlen durch die Szene simulieren, dienen, ebenso wie das Radiosity-Verfahren, der Berechnung der Lichtverteilung.

Weitere Anwendungsgebiete von Raytracing sind die Auralisation und Hochfrequenztechnik.
Vor der Entwicklung von Raytracing bestand das junge Gebiet der 3D-Computergrafik im Wesentlichen aus einer Reihe von „Programmiertricks“, die versuchten, die Schattierung von beleuchteten Objekten nachzuahmen. Raytracing war der erste Algorithmus auf diesem Gebiet, der einen gewissen physikalischen Sinn ergab.

Das erste mit Raytracing berechnete Bild wurde 1963 an der University of Maryland auf einem oszilloskopartigen Bildschirm ausgegeben. Als Entwickler des Raytracing-Algorithmus gelten oft Arthur Appel, Robert Goldstein und Roger Nagel, die den Algorithmus Ende der 1960er Jahre veröffentlichten. Weitere Forscher, die sich zu dieser Zeit mit Raytracing-Techniken beschäftigten, waren Herb Steinberg, Marty Cohen und Eugene Troubetskoy. Raytracing basiert auf der geometrischen Optik, bei der das Licht als eine Gruppe von Strahlen verstanden wird. Die beim Raytracing verwendeten Techniken wurden bereits wesentlich früher, unter anderem von Linsenherstellern, verwendet. Heute verwenden viele Renderer (Computerprogramme zur Erzeugung von Bildern aus einer 3D-Szene) Raytracing, eventuell in Kombination mit weiteren Verfahren.

Einfache Formen des Raytracings berechnen nur die direkte Beleuchtung, also das direkt von den Lichtquellen eintreffende Licht. Raytracing wurde seit seiner ersten Verwendung in der Computergrafik jedoch mehrmals wesentlich erweitert. Höher entwickelte Formen berücksichtigen auch das indirekte Licht, das von anderen Objekten reflektiert wird; man spricht dann von einem globalen Beleuchtungsverfahren.

Der Begriff "Raycasting" bezeichnet meist eine vereinfachte Form des Raytracings, wird teilweise aber auch synonym dazu gebraucht.

Die Erzeugung eines Rasterbildes aus einer 3D-Szene wird "Rendern" oder "Bildsynthese" genannt. Voraus geht die Erstellung einer solchen Szene vom Benutzer mit Hilfe eines 3D-Modellierungswerkzeugs.

In der Szenenbeschreibung werden zumindest folgende Daten angegeben:


Daneben wird beim Raytracing auch die Position eines "Augpunktes" sowie einer "Bildebene" angegeben, die zusammen die Perspektive angeben, aus der die Szene betrachtet wird. Der Augpunkt ist ein Punkt im Raum, der der Position einer virtuellen Kamera oder eines allgemeinen Beobachters entspricht. Die Bildebene ist ein virtuelles Rechteck, das sich in einiger Entfernung zum Augpunkt befindet. Sie ist die dreidimensionale Entsprechung des zu rendernden Rasterbildes im Raum. Rasterförmig verteilte Punkte auf der Bildebene entsprechen den Pixeln des zu erzeugenden Rasterbildes.

Raytracing ist in erster Linie ein Verfahren zur Verdeckungsberechnung, also zur Ermittlung der Sichtbarkeit von Objekten ab dem Augpunkt. Das Grundprinzip ist recht einfach.

Raytracing arbeitet mit einer Datenstruktur, "Strahl" genannt, die den Anfangspunkt und die Richtung einer Halbgeraden im Raum angibt. Es wird für jedes Pixel die Richtung des Strahls berechnet, der vom Augpunkt aus zum entsprechenden Pixel der Bildebene weist. Für jedes Primitiv der Szene wird nun mittels geometrischer Verfahren der eventuelle Schnittpunkt, bei dem der Strahl auf das Primitiv trifft, ermittelt. Dabei wird gegebenenfalls die Entfernung vom Augpunkt zum Schnittpunkt berechnet. Der „Gewinner“, also das vom Augpunkt aus sichtbare Primitiv, ist dasjenige mit der geringsten Distanz.

Das Prinzip der Aussendung der Strahlen vom Augpunkt aus ähnelt dem Aufbau einer Lochkamera, bei der ein Objekt auf einem Film abgebildet wird. Beim Raytracing sind allerdings „Film“ (Bildebene) und „Loch“ (Augpunkt) vertauscht. Ähnlich wie bei der Lochkamera bestimmt der Abstand zwischen Bildebene und Augpunkt die „Brennweite“ und damit das Sichtfeld.

Da die Strahlen nicht wie in der Natur von den Lichtquellen, sondern vom Augpunkt ausgehen, spricht man auch von "Backward Ray Tracing". Raytracing beschäftigt sich mit der Frage, "woher" das Licht kommt. Einige Veröffentlichungen nennen das Verfahren allerdings "Forward Ray Tracing" oder "Eye Ray Tracing."

Der oben erwähnte Test auf einen eventuellen Schnittpunkt von Strahl und Primitive ist das Herzstück des Raytracings. Solche Tests lassen sich für eine Vielzahl von Primitiventypen formulieren. Neben Dreiecken und Kugeln sind unter anderem Zylinder, Quadriken, Punktwolken oder gar Fraktale möglich.

Bei Kugeln ist der Schnittpunkttest eine relativ kurze und einfache Prozedur, was die Popularität dieser Objekte auf Raytracing-Testbildern erklärt. Viele Renderprogramme lassen jedoch aus Gründen der Einfachheit nur Dreiecke als Primitiven zu, aus denen sich jedes beliebige Objekt näherungsweise zusammensetzen lässt.

Seit Kurzem werden auch komplexere Geometrien für den Schnittpunkttest wie etwa NURBS verwendet. Vorteilhaft dabei ist ein Maximum an Präzision, da die Fläche nicht wie sonst üblich in Dreiecke unterteilt wird. Der Nachteil ist eine erhöhte Renderzeit, da der Schnittpunkttest mit komplexen Freiformflächen sehr viel aufwändiger als mit einfachen Dreiecken ist. Eine hinreichende Annäherung an die Genauigkeit von NURBS ist zwar auch mit Dreiecken möglich, in diesem Fall muss aber eine sehr große Anzahl gewählt werden.

Bei der Ermittlung des nächsten Primitivs wird nicht nur der Schnittpunkt und seine Distanz zum Augpunkt, sondern auch die Normale des Primitivs am Schnittpunkt berechnet. Damit sind alle Informationen vorhanden, um die zum Augpunkt reflektierte „Lichtstärke“ und somit die Farbe zu ermitteln. Dabei werden auch die Beschreibungen der Lichtquellen der Szene genutzt. Den Berechnungen liegen lokale Beleuchtungsmodelle zugrunde, die die Materialbeschaffenheit eines Objekts simulieren. Diesen Teil des Renderers, der für die Ermittlung der Farbe zuständig ist, nennt man "Shader".

Die Programmierung eines einfachen "Raytracers" erfordert wenig Aufwand. In Pseudocode lässt sich das Prinzip folgendermaßen darstellen:

Jeder Raytracer, unabhängig von der verwendeten Raytracing-Variante, folgt einer ähnlichen Struktur, die noch einen Schnittpunkttest ("Teste_Primitiv") und einen Shader ("Farbe_am_Schnittpunkt") enthält.

Bei der Bestimmung des ersten Primitivs, auf das ein Strahl trifft, kann, wie im weiter oben aufgeführten Beispielcode, jedes Primitiv der Szene gegen den Strahl getestet werden. Dies ist jedoch nicht grundsätzlich erforderlich, wenn bekannt ist, dass gewisse Primitive sowieso nicht in der Nähe des Strahls liegen und daher nicht getroffen werden können. Da Schnittpunkttests die größte Laufzeit beim Raytracing beanspruchen, ist es wichtig, so wenig Primitive wie möglich gegen den Strahl zu testen, um die Gesamtlaufzeit gering zu halten.

Bei den Beschleunigungsverfahren wird die Szene meist in irgendeiner Form automatisch aufgeteilt und die Primitiven diesen Unterteilungen zugewiesen. Wenn ein Strahl durch die Szene wandert, so wird er nicht gegen die Primitiven, sondern zunächst gegen die Unterteilungen getestet. Dadurch muss der Strahl nur noch gegen die Primitive derjenigen Unterteilung getestet werden, die der Strahl kreuzt.

Es wurde eine Vielzahl derartiger Beschleunigungstechniken für Raytracing entwickelt. Beispiele für Unterteilungsschemas sind Voxelgitter, BSP-Bäume sowie Bounding Volumes, die die Primitiven umschließen und eine Hierarchie bilden. Mischformen dieser Techniken sind ebenfalls populär. Auch für Animationen gibt es spezielle Beschleunigungstechniken. Die Komplexität dieser Techniken lassen einen Raytracer schnell zu einem größeren Projekt anwachsen.

Keine Technik ist generell optimal; die Effizienz ist szenenabhängig. Dennoch reduziert jedes Beschleunigungsverfahren die Laufzeit enorm und macht Raytracing erst zu einem praktikablen Algorithmus. Auf Kd-Bäumen basierende Unterteilungen sind für die meisten nicht-animierten Szenen die effizienteste oder nahezu effizienteste Technik, da sie sich mittels Heuristiken optimieren lassen. Mehrfach festgestellt wurde, dass die asymptotische Laufzeit von Raytracing in Abhängigkeit von der Anzahl der Primitiven logarithmisch ist.

Es wurde gezeigt, dass auf modernen Rechnern nicht die Prozessorleistung, sondern Speicherzugriffe die Geschwindigkeit des Raytracings begrenzen. Durch sorgfältige Nutzung von Caching durch den Algorithmus ist es möglich, die Laufzeit wesentlich zu verringern. Ebenfalls möglich ist die Nutzung der SIMD-Fähigkeit moderner Prozessoren, die parallele Berechnungen ermöglicht, sowie speziell darauf optimierter Unterteilungsschemata. Damit ist das gleichzeitige Verfolgen mehrerer, in „Paketen“ zusammengefasster, Strahlen möglich. Grund dafür ist, dass die vom Augpunkt ausgesendeten Strahlen meist sehr ähnlich sind, also meist die gleichen Objekte schneiden. Mit dem Befehlssatz SSE etwa können vier Strahlen gleichzeitig auf einen Schnittpunkt mit einem Primitiv getestet werden, was diese Berechnung um ein Vielfaches beschleunigt. Auf entsprechenden Hardwareimplementationen – zum Beispiel auf FPGAs – können auch größere Pakete mit über 1000 Strahlen verfolgt werden. Allerdings büßen Caching- und SIMD-Optimierungen bei erweiterten Formen des Raytracings viel von ihrem Geschwindigkeitsvorteil ein.

Weiterhin ist es möglich, den gesamten Raytracing-Vorgang zu parallelisieren. Dies lässt sich etwa dadurch trivial bewerkstelligen, dass verschiedene Prozessoren bzw. Maschinen unterschiedliche Ausschnitte des Bildes rendern. Lediglich gewisse Beschleunigungstechniken oder Erweiterungen müssen angepasst werden, um parallelisierungstauglich zu sein.

Das grundlegende Raytracing-Verfahren benötigt kaum Speicher. Jedoch belegt die Szene selbst, die sich heutzutage bei komplexen Szenen oft aus mehreren Millionen Primitiven zusammensetzt, sehr viel Speicher und kann mehrere Gigabyte umfassen. Hinzu kommt der mehr oder weniger hohe zusätzliche Speicherbedarf der Beschleunigungstechniken. Da solch große Szenen nicht vollständig in den Arbeitsspeicher des Rechners passen, wird häufig Swapping nötig.

Bei größeren Objekten, die mehrmals in der Szene vorhanden sind und sich nur durch ihre Position und Größe unterscheiden (etwa bei einem Wald voller Bäume), muss nicht die gesamte Geometrie neu gespeichert werden. Durch diese "Instancing" genannte Technik lässt sich bei bestimmten Szenen erheblich Platz einsparen.

Einer der Gründe für den Erfolg des Raytracing-Verfahrens liegt in seiner natürlichen Erweiterbarkeit. Das oben beschriebene primitive Verfahren ist für die heutigen Anforderungen der Bildsynthese unzureichend. Mit steigender Rechenleistung und zunehmender Inspiration aus der Physik – vor allem der Optik und der Radiometrie – kamen mehrere Erweiterungen und Varianten auf, von denen einige hier kurz vorgestellt werden sollen.

Grundsätzlich gilt, dass mit jeder Erweiterung die erreichbare Qualität der gerenderten Bilder sowie der relative Zeitbedarf stark anstieg und mit Path Tracing das Maximum erreichte. Erst nachfolgende Entwicklungen zielten darauf ab, den Zeitaufwand von Path Tracing zu verringern, ohne an Qualität einzubüßen.

Aufgrund der Flexibilität des Raytracing-Algorithmus ist es möglich, Lichtstrahlen nicht nur vom Augpunkt, sondern auch von beliebigen anderen Punkten des Raums auszusenden. Wie Arthur Appel bereits 1968 demonstrierte, kann dies dazu benutzt werden, Schatten zu simulieren.

Ein beliebiger Punkt einer Oberfläche befindet sich genau dann im Schatten, wenn sich zwischen ihm und der Lichtquelle ein Objekt befindet. Indem vom Schnittpunkt an der Oberfläche ein "Schattenstrahl" in Richtung der Lichtquelle ausgesendet wird, lässt sich bestimmen, ob ein Objekt dessen Weg kreuzt. Ist dies der Fall, so befindet sich der Schnittpunkt im Schatten, und es wird als Helligkeit des Strahls 0 zurückgegeben. Im anderen Fall findet normales Shading statt.

Raytracing lässt sich nicht nur auf einfache lichtundurchlässige, sondern auch auf durchsichtige und spiegelnde, reflektierende Objekte anwenden. Dabei werden weitere Lichtstrahlen von den Schnittpunkten ausgesendet. Bei spiegelnden Flächen etwa muss dabei lediglich die Richtung des von der Fläche ausgehenden Strahls gemäß dem Reflexionsgesetz (Einfallswinkel ist gleich Reflexionswinkel) berücksichtigt und ein entsprechender "Reflexionsstrahl" errechnet werden.

Bei lichtdurchlässigen Objekten wird ein Strahl gemäß dem Snelliusschen Brechungsgesetz ausgesendet, diesmal ins Innere des betreffenden Objektes. Generell reflektieren transparente Objekte auch einen Teil des Lichts. Die relativen Farbanteile des reflektierten und des gebrochenen Strahls lassen sich mit den Fresnelschen Formeln berechnen. Diese Strahlen werden auch "Sekundärstrahlen" genannt.

Da die Sekundärstrahlen auf weitere Objekte fallen können, wird der Algorithmus rekursiv aufgerufen, um mehrfache Spiegelungen und Lichtbrechungen zu ermöglichen. Die hierarchische Gesamtheit der Aufrufe wird auch "Renderbaum" genannt.

"Rekursives Raytracing" wurde um 1980 von Kay und Whitted entwickelt.

In Pseudocode sieht der Shader beim rekursiven Raytracing in etwa wie folgt aus:

Der Rest des Programms kann wie beim einfachen Raytracing bleiben. Die hier aufgerufene Funktion "Farbe_aus_Richtung" kann wiederum "Farbe_am_Schnittpunkt" aufrufen, woraus der rekursive Charakter des Verfahrens deutlich wird.

Rekursives Raytracing ermöglicht neben Lichtbrechung und -reflexion die Simulation von harten Schatten. In Wirklichkeit haben Lichtquellen jedoch eine bestimmte Größe, was dazu führt, dass Schatten weich und verschwommen wirken.

Dieser Effekt, sowie Antialiasing, glänzende Reflexion und mehr, lassen sich mit "diffusem Raytracing" (auch "stochastisches Raytracing" oder "distributed ray tracing" genannt) simulieren, das 1984 von Cook u. a. veröffentlicht wurde. Die Idee ist, in verschiedenen Situationen statt eines Strahls mehrere Strahlen auszusenden und aus den errechneten Farben den Mittelwert zu bilden. Beispielsweise lassen sich weiche Schatten mit Kern- und Halbschatten erzeugen, indem die Richtungen der Schattenstrahlen zufällig verteilt die Oberfläche der Lichtquelle abtasten. Der Nachteil ist, dass dabei Bildrauschen entsteht, wenn zu wenig Strahlen verwendet werden. Es gibt jedoch Möglichkeiten wie Importance Sampling, die das Rauschen reduzieren.

Obwohl diffuses Raytracing zahlreiche Effekte ermöglicht, ist es immer noch nicht in der Lage, die globale Beleuchtung mit Effekten wie diffuser Interreflexion und Kaustiken (durch Bündelung von Licht erzeugte helle Lichtflecken) zu simulieren. Dies liegt daran, dass zwar bei spiegelnden Reflexionen, nicht jedoch bei diffusen Oberflächen Sekundärstrahlen ausgesendet werden.

In seiner 1986 veröffentlichten Publikation beschrieb James Kajiya die Rendergleichung, die die mathematische Basis für alle Methoden der globalen Beleuchtung bildet. Die von einem Strahl beigetragene „Helligkeit“ wird dabei radiometrisch korrekt als Strahldichte interpretiert. Kajiya zeigte, dass zur globalen Beleuchtung Sekundärstrahlen von allen Oberflächen ausgesendet werden müssen. Daneben wies er auch darauf hin, dass ein Renderbaum den Nachteil hat, dass zu viel Arbeit für die Berechnungen in großer Hierarchietiefe verschwendet wird und es besser ist, jeweils einen einzigen Strahl auszusenden. Diese Methode ist heute als "Path Tracing" bekannt, da ein Strahl sich vom Augpunkt aus seinen „Weg“ durch die Szene sucht. Path Tracing hat eine rigorose mathematische und physikalische Basis.

Falls beim Path Tracing der von einer diffusen Oberfläche ausgesandte Sekundärstrahl eine Lichtquelle direkt trifft, so wird dieser Helligkeitsanteil üblicherweise ignoriert. Der Anteil der direkten Beleuchtung wird stattdessen weiterhin per Schattenstrahl berechnet. Alternativ kann die direkte Beleuchtung berechnet werden, indem nur ein Sekundärstrahl gemäß dem lokalen Beleuchtungsmodell ausgesendet wird und, falls dieser eine Lichtquelle direkt trifft, deren Strahldichte zurückgegeben wird. Welche dieser beiden Methoden effizienter ist, hängt vom lokalen Beleuchtungsmodell der Oberfläche sowie vom von der Oberfläche betrachteten Raumwinkel der Lichtquelle ab. Die konzeptuell einfachere Variante des Path Tracing, bei der keine Schattenstrahlen ausgesandt werden, ist als "Adjoint Photon Tracing" bekannt.

Obwohl Path Tracing die globale Beleuchtung simulieren kann, nimmt die Effizienz des Verfahrens bei kleinen Lichtquellen ab. Insbesondere Kaustiken und deren Reflexionen sind mit Path Tracing sehr verrauscht, sofern nicht sehr viele Strahlen ausgesendet werden. Deshalb werden meist andere, auf Path Tracing basierende Verfahren oder Erweiterungen verwendet.

"Light Ray Tracing" ist eine seltene Variante, bei der die Lichtstrahlen nicht vom Augpunkt, sondern von den Lichtquellen ausgesendet werden. Die Pixel, die vom Strahl auf der Bildebene getroffen werden, werden eingefärbt. Dadurch lassen sich bestimmte Effekte wie Kaustiken gut, andere Effekte jedoch nur sehr ineffizient simulieren, da viele Strahlen die Bildebene verfehlen.

Da sich einige Effekte nur vom Augpunkt, andere nur von den Lichtquellen aus gut simulieren lassen, wurden Algorithmen entwickelt, die beide Methoden kombinieren. Das Ziel ist es, Szenen mit beliebig komplexer Lichtverteilung und -reflexion effizient rendern zu können.


Die angeführten gängigen Varianten des Raytracings lassen sich erweitern, um zusätzliche Effekte zu ermöglichen. Einige Beispiele:


Raytracing-Berechnungen gelten als sehr zeitintensiv. Raytracing wird daher vornehmlich bei der Erzeugung von Darstellungen eingesetzt, bei denen eher die Qualität als die Berechnungszeit im Vordergrund steht. Ein Bild mit Raytracing zu berechnen, kann abhängig von der verwendeten Technik, der Szenenkomplexität, der verwendeten Hardware und der gewünschten Qualität beliebig lange – in der Praxis oft mehrere Stunden, in Einzelfällen sogar mehrere Tage – dauern. In Bereichen wie der Virtuellen Realität, in der räumliche Darstellungen in Echtzeit berechnet werden müssen, konnte sich Raytracing daher bisher nicht durchsetzen. Computeranimationsfilme werden überwiegend mit dem REYES-System erzeugt, bei dem Raytracing-Berechnungen so weit wie möglich vermieden werden. Gelegentlich wurde Raytracing von der Demoszene genutzt.

Gegenüber üblichen Echtzeitrenderern auf Z-Buffer-Basis hat Raytracing jedoch mehrere Vorteile: eine einfache Implementierung mit überschaubarer Komplexität, eine im Gegensatz zur Grafikpipeline hohe Flexibilität sowie die leichtere Austauschbarkeit der Shader und dadurch eine erleichterte Implementierung neuer Shader. Die Geschwindigkeit von Raytracing muss daher in Relation zur erreichten Bildqualität gesetzt werden. Für die anspruchsvollen Qualitätsanforderungen der realistischen Bildsynthese gibt es, insbesondere bei komplizierten Szenen mit beliebigen Materialien, keine Alternative zu Raytracing.

Es existieren Bestrebungen, echtzeitfähige Raytracer für komplexe Szenen zu implementieren, was bereits unter bestimmten Voraussetzungen mit prozessor- und speicheroptimierten Softwarelösungen gelungen ist. Auf Hardware optimierte Implementierungen von Raytracing zeigen, dass die künftige breite Nutzung von Raytracing im Echtzeitbereich denkbar ist. Mit diesen Anwendungen beschäftigen sich Projekte wie die OpenRT-Programmierschnittstelle und diverse Implementierungen für programmierbare Grafikprozessoren (GPGPU). Außerdem wurden spezielle Architekturen für hardwarebeschleunigtes Raytracing entwickelt.

Das Raytracing-Prinzip kann auf beliebige Anwendungsbereiche ausgeweitet werden, bei denen die Ausbreitung von Wellen in einer Szene simuliert werden soll. Strahlen repräsentieren dabei stets die Normalenvektoren zu einer Wellenfront. In der Auralisation und Hochfrequenztechnik versucht man, die Auswirkungen einer Szene auf die Akustik beziehungsweise auf ein elektromagnetisches Feld zu simulieren. Das Ziel ist es, für bestimmte Frequenzen den Energieanteil zu berechnen, der von einem Sender zu einem Empfänger über die verschiedenen möglichen Wege durch die Szene übertragen wird.

In der Akustik ist Raytracing neben der Spiegelschallquellenmethode und der Diffusschallberechnung eine Möglichkeit zur Lösung dieses Problems. Zur Simulation müssen die Materialeigenschaften der verschiedenen Körper sowie die Dämpfung des Schalls durch die Luft berücksichtigt werden.

Eine Möglichkeit zum Auffinden der Übertragungswege besteht darin, Strahlen von einer Quelle isotrop (in alle Richtungen) auszusenden, eventuell mit Energieverlust an den Gegenständen zu reflektieren und die Gesamtenergie der auf den Empfänger auftreffenden Strahlen zu ermitteln. Diese Methode wird Ray launching genannt. Strahlen können auch eine bestimmte „Form“ – etwa die einer Röhre – haben, um punktförmige Empfänger simulieren zu können. Der Nachteil dieser Methode ist ihre Langsamkeit, da viele Strahlen nie den Empfänger erreichen und für präzise Statistiken eine hohe Anzahl vonnöten ist.
Ein weiteres Problem ergibt sich dadurch, dass die Wellenlänge oft nicht gegenüber den Abmessungen der Körper innerhalb einer Szene vernachlässigbar ist. Sofern die Beugung von Strahlen nicht berücksichtigt wird, kann es daher zu merklichen Fehlern in der Simulation kommen.




</doc>
<doc id="4359" url="https://de.wikipedia.org/wiki?curid=4359" title="Richard Wagner">
Richard Wagner

Wilhelm Richard Wagner (* 22. Mai 1813 in Leipzig; † 13. Februar 1883 in Venedig) war ein deutscher Komponist, Dramatiker, Dichter, Schriftsteller, Theaterregisseur und Dirigent. Mit seinen Musikdramen gilt er als einer der bedeutendsten Erneuerer der europäischen Musik im 19. Jahrhundert. Er veränderte die Ausdrucksfähigkeit romantischer Musik und die theoretischen und praktischen Grundlagen der Oper, indem er dramatische Handlungen als Gesamtkunstwerk gestaltete und dazu die Libretti, Musik und Regieanweisungen schrieb. Er gründete die ausschließlich der Aufführung eigener Werke gewidmeten Festspiele in dem von ihm geplanten Bayreuther Festspielhaus. Seine Neuerungen in der Harmonik beeinflussten die Entwicklung der Musik bis in die Moderne. Mit seiner Schrift "Das Judenthum in der Musik" gehört er geistesgeschichtlich zu den obsessiven Verfechtern des Antisemitismus.

Richard Wagner wurde als neuntes Kind des Polizeiaktuarius Carl Friedrich Wagner (1770–1813) und der Bäckerstochter Johanna Rosine Wagner, geb. Pätz (1774–1848) in Leipzig (im Gasthof "Zum roten und weißen Löwen") geboren und am 16. August in der Thomaskirche auf den Namen Wilhelm Richard Wagner evangelisch getauft. Am 23. November 1813, sechs Monate nach Richards Geburt, starb sein Vater an Typhus. Am 28. August 1814 heiratete Wagners Mutter den Maler, Schauspieler und Dichter Ludwig Geyer (1779–1821), der von Carl Friedrich Wagner sehr geschätzt worden war und sich nach dessen Tod der Familie angenommen hatte. Spekulationen, wonach Geyer der leibliche Vater Richard Wagners gewesen sei, sind heute klar widerlegt. Nirgendwo in Wagners schriftlichen und mündlichen Äußerungen gibt es Belege dafür, dass Richard selbst an seiner Abstammung von Carl Friedrich Wilhelm Wagner gezweifelt habe. In ihrem Tagebuch notierte Richard Wagners zweite Ehefrau Cosima am 26. Dezember 1878: „Dann sagt Richard, (Sohn) Fidi, dem er seine Kappe immer zur Aufbewahrung zugeworfen, habe prachtvoll ausgesehen, seinem Vater Geyer ähnlich gesehen. Ich: ‚Vater Geyer ist gewiß dein Vater gewesen.‘ Richard: ‚Das glaube ich nicht.‘ ‚Woher dann die Ähnlichkeit?‘ Richard: ‚Meine Mutter hat ihn damals geliebt, Wahlverwandtschaften.‘“ Wie Fotografien eindeutig belegen, weist der Bruder Albert, Carl Friedrich Wilhelm Wagners ältester Sohn, eine geradezu frappierende Ähnlichkeit mit Richard auf.
Noch 1814 übersiedelte die Familie nach Dresden. Am 26. Februar 1815 wurde Richards Halbschwester Cäcilie geboren. Seine älteren Geschwister hießen Albert, Gustav, Rosalie, Julius, Luise, Klara, Theresia und Ottilie. Im Jahr 1817 wurde Richard – unter dem Namen Richard Geyer – eingeschult. Zwei Jahre später erkrankte der Stiefvater Ludwig Geyer und starb am 30. September 1821 in Dresden. Danach nahmen mehrere Verwandte das Kind in Betreuung. So kam Richard im Oktober 1821 zum Bruder seines Stiefvaters Karl nach Eisleben, wo auch schon sein Bruder Julius aufgenommen worden war, und lebte dort für ein Jahr unter dem Namen Richard Geyer. Ab dem 2. Dezember 1822 besuchte er die Kreuzschule in Dresden. Im Jahr 1826 übersiedelte die Familie nach Prag, weil Richards Schwester Rosalie dort ein Engagement als Theaterschauspielerin erhielt. Richard blieb in Dresden und war bei der Familie Dr. Böhme untergebracht; er besuchte seine Familie aber mehrmals in Prag. Ab Weihnachten 1827 war er wieder mit seiner zurückgekehrten Familie in Leipzig. Hier besuchte er von 1828 bis 1830, jetzt unter dem Namen Richard Wagner, die Nikolaischule sowie die Thomasschule zu Leipzig. Der vaterlose Knabe fand in dieser Zeit ein Vorbild in seinem Onkel Adolph Wagner, einem Philologen, der sich als Übersetzer der Werke von Sophokles einen Namen gemacht hatte und mit Goethe korrespondierte. Richard las in dessen umfangreicher Bibliothek Shakespeare und die Romantiker, zum Beispiel E. T. A. Hoffmann, und schrieb schon als Schüler sein erstes dramatisches Werk, "Leubald" (1826–1828), ein großes Trauerspiel in fünf Akten im Stile Shakespeares.

Mit 16 Jahren erlebte Wagner in Leipzig erstmals Beethovens Oper "Fidelio" mit Wilhelmine Schröder-Devrient in der Titelrolle. Von nun an stand für ihn fest, dass er Musiker werden wollte. Er verfasste kurz darauf erste Sonaten und ein Streichquartett (1829) sowie mehrere Ouvertüren (1830).

Ab 1831 studierte Wagner an der Universität Leipzig Musik, außerdem nahm er Kompositionsunterricht beim Thomaskantor Christian Theodor Weinlig, dem er seine Klaviersonate in B-Dur widmete. Dieses Werk erschien bereits ein Jahr später gedruckt durch den Verlag Breitkopf & Härtel. Davon und auch vom Erfolg der ersten Aufführung seiner Konzertouvertüre in d-Moll im Jahr 1832 in Leipzig angespornt, komponierte Wagner weitere Konzertstücke, unter anderem die C-Dur-Symphonie, die noch im selben Jahr im Prager Konservatorium uraufgeführt wurde.

Angeregt durch die Spätromantik, insbesondere von E. T. A. Hoffmann und einem Stoff aus Ritterzeit und Ritterwesen, hatte er den Plan zu seiner ersten Oper unter dem Titel "Die Hochzeit" verfasst. Er dichtete den Text und begann mit der Komposition der ersten Nummern dieses „Nachtstücks von schwärzester Farbe“ (R. W.), dessen übertriebene Schauerromantik bei seiner Schwester Rosalie jedoch wenig ankam. Daraufhin vernichtete Wagner den Textentwurf, von der Partitur blieben Teile erhalten (WWV 31).

Wagner war beim Corps Saxonia Leipzig aktiv, allerdings nicht lange. Wagner selbst schrieb, dass er freiwillig das Corps verlassen habe, vor allem aus Enttäuschung über die apolitische Haltung der Leipziger Landsmannschafter (= Corpsstudenten) zum Aufstand der Polen. Die „schmerzliche Trauer“ Wagners über die polnische Niederlage bei Ostrolenka hätten die Landsmannschafter nicht geteilt. Im Zuge der Polenschwärmerei herrschten unter den damaligen Studenten große Sympathien zum Nachbarvolk. Der Schriftsteller und Publizist Heinrich Laube beeindruckte Wagner 1833 mit den Ideen des Jungen Deutschlands, einer revolutionär orientierten literarischen Bewegung des Vormärz.

Mit dem Plan, den in Leipzig nach einer italienischen Vorlage verfassten Text seiner Oper "Die Feen" zu vertonen verließ Wagner im Januar 1833 Leipzig und reiste über Hof und Bamberg nach Würzburg, wo sein ältester Bruder Albert lebte und von Oktober 1830 bis Mai 1841 am Theater als Tenor angestellt war. Am 13. Februar 1833 wurde Richard Wagner als „studiosus musicae aus Leipzig“ im polizeilichen Melderegister der Stadt Würzburg eingetragen. Seine erste Unterkunft in Würzburg nahm er für einige Wochen in der Wohnung seines Bruders in der Unteren Wöllergasse (heute Kolpingstraße). Später wohnte er vermutlich in der Hinteren Kapuzinergasse (heute der Huebergasse 5 entsprechend).

In Würzburg begann er am 20. Februar 1833 mit der Komposition der Oper "Die Feen", nachdem er dank seines Bruders sein erstes Engagement als Chordirektor und Chorrepetitor für ein halbes Jahr vom Würzburger Theater, das er anlässlich einer Aufführung von "Der Freischütz" (mit seinem Bruder als "Max") am 18. Februar erstmals besucht hatte, erhalten hatte. Zusätzlich zu seiner Haupttätigkeit als Chorrepetitor musste Wagner am Theater auch Schauspieler- und Statistenrollen übernehmen und war als Theaterkomponist tätig. Im Herbst 1833 begann die neue Spielzeit des Theaters und Wagner bezog, ohne seine Tätigkeit als Chordirektor wieder aufzunehmen, am 17. Oktober eine Wohnung in der Lochgasse 34 (das Haus am Ort der heutigen Spiegelstraße 19 wurde 1856 abgebrochen). Für seinen Unterhalt sorgte in dieser Zeit, wie schon in den Theaterferien von Anfang Mai bis Ende September, wiederum seine Schwester Rosalie. Nachdem er am 6. Januar die „Feen“ fertiggestellt hat, verließ er Würzburg am 15. Januar 1834 wieder und kehrte nach Leipzig zurück. Zugleich hatte er auch seine weniger oder mehr intensiven Liebesbeziehungen zu der Choristin Therese Ringelmann und der ebenfalls am Theater tätigen Friederike Galvagni beendet.

In Laubes "Zeitung für die elegante Welt" erschien bald darauf (1834) sein Aufsatz "Die Deutsche Oper". Als musikalischer Leiter der Sommersaison in Bad Lauchstädt und des Theaters in Magdeburg lernte er die Schauspielerin Minna Planer kennen und verliebte sich leidenschaftlich in sie. Wagners erste selbstständige musikalische Einstudierung betraf nach seiner Aussage Adolf Müller seniors Musik zu Johann Nestroys Posse "Lumpazivagabundus" (1833).
Wagner arbeitete 1835 an der Oper "Das Liebesverbot" und leitete die zweite Magdeburger Spielzeit. Am 29. März 1836 fand unter desolaten Bedingungen die Uraufführung der Oper "Das Liebesverbot oder Die Novize von Palermo" in Magdeburg statt. Über Berlin reiste Wagner nach Königsberg. Am 24. November heiratete er Minna Planer, die dort als Schauspielerin engagiert war, in der Tragheimer Kirche. Am 1. April 1837 wurde er Musikdirektor in Königsberg. Der Theaterbetrieb brach allerdings kurz darauf wegen Bankrotts der Direktion zusammen. Wagner war gewohnt, über seine Verhältnisse zu leben und ansässige Bürger um Darlehen zu bitten, die er nicht zurückzahlen konnte. Im Juni 1837 erlangte er eine Kapellmeisterstelle in Riga, wo er sich zunächst vor seinen preußischen Gläubigern in Sicherheit brachte. Im Juli verließ ihn seine Frau Minna mit einem Kaufmann namens Dietrich; sie kehrte im Oktober aber reumütig wieder zu ihm nach Riga zurück. Hier entstanden der Text und der Beginn der Partitur seiner ersten Erfolgsoper "Rienzi". Wagner lernte hier auch Wilhelm Hauffs Märchen vom "Gespensterschiff" mit dem Holländer-Stoff kennen. Mit dem Theaterdirektor Karl von Holtei plante er ein Singspiel unter dem Titel "Die glückliche Bärenfamilie", sperrte sich aber bald gegen den Theaterbetrieb. In dieser Zeit ging die Epoche der Wanderbühnen zu Ende, die zunehmend Stadttheatern mit festem Personal weichen mussten.

Bereits 1839 verlor Wagner seine Stellung in Riga wieder. Aus Furcht vor seinen Gläubigern überschritten seine Frau und er heimlich die russisch-ostpreußische Grenze und fuhren auf dem kleinen Segelschiff "Thetis" nach London. Die stürmisch verlaufende, mehrfach in norwegischen Häfen unterbrochene und schließlich über vier Wochen dauernde Seefahrt, bei der das Schiff beinahe kenterte, brachte Inspirationen für den "Fliegenden Holländer". Nach kurzem Aufenthalt in London reiste das Paar über Boulogne-sur-Mer, wo Wagner den führenden Pariser Opernkomponisten Giacomo Meyerbeer persönlich kennenlernte, weiter nach Paris.

Wagner verbrachte mit Minna die Jahre 1840 und 1841 bis April 1842 unter ärmlichen wirtschaftlichen Bedingungen in Paris. Er vollendete dort "Rienzi" (1840) und schrieb und komponierte den "Fliegenden Holländer" (1841). Meyerbeer erkannte seine Begabung und förderte ihn, doch war er von Wagners „Pumpgenie“ (Thomas Mann) weniger begeistert. In Paris befanden sich die führenden Theater der Welt. Gelehrig nahm Wagner Anregungen der Grand opéra oder des Melodrams auf. Um sich und seine Frau ernähren zu können, verfasste er Artikel für diverse Journale und erledigte musikalische Lohnarbeiten. Er lernte Heinrich Heine und Franz Liszt kennen. Aus Geldnot musste er sogar den Prosaentwurf zum "Fliegenden Holländer" unter dem Titel "Le vaisseau fantôme" für 500 Francs an die Pariser Oper verkaufen, die den Kompositionsauftrag an ihren Hauskomponisten Pierre-Louis Dietsch vergab – was Wagner indes nicht davon abhielt, seine Idee selbst auszuführen und in Musik zu setzen.

In Paris setzte er sich mehr und mehr mit den politischen Vorgängen in Frankreich auseinander. Während ihn in jungen Jahren die Gräuel der Französischen Revolution „mit aufrichtigem Abscheu gegen ihre Helden“ erfüllt hatten, wie er in "Mein Leben" schrieb, reagierte er ganz anders, als Lafayette die liberale Opposition in Paris anführte. „Die geschichtliche Welt begann für mich von diesem Tage an; und natürlich nahm ich volle Partei für die Revolution, die sich mir nun unter der Form eines mutigen und siegreichen Volkskampfes, frei von allen den Flecken der schrecklichen Auswüchse der ersten französischen Revolution darstellte.“

In diese Zeit fiel auch die Beschäftigung mit Ludwig Feuerbachs religionskritischer Philosophie und den Theorien des französischen Frühsozialisten und frühen Theoretikers des modernen Anarchismus Pierre-Joseph Proudhon. Vor allem die Formulierung Proudhons zur Frage: „Was ist Eigentum?“ beschäftigte Wagner zeitlebens: „Solange Eigentum Privilegien birgt, solange bedeutet privilegiertes – also erpresserisches – Eigentum Diebstahl.“ Diese Einstellung wurde vor allem in seinem Nibelungendrama ein roter Faden.

Im Frühjahr 1842 erhielt Wagner von der Dresdner Hofoper die Nachricht, dass man seine neue Oper "Rienzi" aufführen wolle. Nachdem es ihm in Paris nicht gelungen war, künstlerische Pläne voranzubringen und dort Erfolg zu haben, verließ er die Stadt im April 1842 und zog nach Dresden um. Den Juni verbrachte er in Teplitz-Schönau, wo er schon 1834 und 1836 gewesen war. Auf dem Schreckenstein entstand der erste "Tannhäuser"-Entwurf. Die Uraufführung des "Rienzi" fand am 20. Oktober in Dresden statt. Sie war ein großer Erfolg und bedeutete den künstlerischen Durchbruch des jungen Wagner. Etwa zur gleichen Zeit wurde Franz Liszt Hofkapellmeister in Weimar.

Wagner konnte in Dresden am 2. Januar 1843 seine Oper "Der fliegende Holländer" zur Uraufführung bringen. Am 2. Februar wurde er zum Königlich-Sächsischen Kapellmeister an der Dresdner Hofoper ernannt. Wenig später übernahm er zusätzlich die Leitung der Dresdner Liedertafel, in deren Auftrag er das monumentale Chorwerk "Das Liebesmahl der Apostel" komponierte; die Uraufführung am 6. Juli 1843 in der Frauenkirche im Rahmen des Zweiten Allgemeinen Dresdner Männergesangsfestes war durch und durch ein Erfolg. Wagner distanzierte sich aber in der Folge davon, weitere oratorische Werke zu komponieren, und führte das Werk nicht mehr auf. Kurz darauf überredete er seinen Freund Ferdinand Hiller, die Leitung der Dresdner Liedertafel zu übernehmen.

Es entstanden Freundschaften mit Anton Pusinelli und August Röckel, mit dem er vor allem Gespräche über Politik führte. Wagner arbeitete 1844 weiter an der Oper "Tannhäuser und der Sängerkrieg auf (der) Wartburg". Im Juli 1845 hielt er sich in Marienbad auf und entwarf dort in einer ersten Inhaltsskizze die Handlung zu den "Meistersingern von Nürnberg". Er beschäftigte sich intensiv mit den deutschen Sagen, vor allem dem Nibelungen- und dem Gral-Mythos, und begann mit der Konzeption seiner Oper "Lohengrin". In Dresden leitete er am 19. Oktober die Uraufführung seines "Tannhäuser". Wagner dirigierte 1846 Beethovens 9. Symphonie – wobei er u. a. den jungen Hans von Bülow tief beeindruckte, und begann im Sommer, während eines dreimonatigen Urlaubs in Graupa nahe Dresden, mit der Komposition des "Lohengrin". Am 9. Januar 1848 verstarb Wagners Mutter in Leipzig. Im Frühjahr 1848 besuchte Franz Liszt Wagner erstmals in Dresden, wenig später kam es zu einem Gegenbesuch bei Liszt in Weimar, womit eine lange Freundschaft begann.
Um sich Anregungen für eine Theaterreform zu holen, reiste Wagner im Sommer 1848 nach Wien. Anschließend schloss er sich in Dresden den im Zuge der Märzrevolution verstärkten republikanischen Reformbestrebungen in Sachsen an und lernte dabei auch den russischen Anarchisten Michail Bakunin kennen. Wagner bemühte sich um eine Theaterreform am Hoftheater und entwickelte seine Idealvorstellungen über den Stellenwert der Kunst in der Gesellschaft. Er veröffentlichte einige Beiträge in den "Volksblättern" seines Freundes August Röckel, u. a. die Schrift "Die Revolution". Zur gleichen Zeit entstand seine Abhandlung "Die Wibelungen", "Weltgeschichte aus der Sage", eine Vorstufe zu seinem Hauptwerk "Der Ring des Nibelungen", dessen Konzeption mit dem "Siegfried" gleichzeitig entstand, ebenso wie die Konzeption eines Musikdramas "Jesus von Nazareth", wobei er Jesus vor allem als Sozialrevolutionär sah.

Im Frühjahr 1849 beteiligte er sich aktiv am Dresdner Maiaufstand. Nach der Niederschlagung der Volksunruhen wurde er wie auch seine Freunde Gottfried Semper und August Röckel von der Polizei steckbrieflich gesucht und sah sich gezwungen, zu fliehen. Im Freundes- und Mitarbeiterkreis spielte er seine Beteiligung am Dresdner Aufstand herunter. Sein späterer Mitarbeiter Hermann Zumpe (tätig in Bayreuth von 1873 bis 1875) zitiert die folgende Beschreibung von Wagners Rolle: „Aus seinem (Wagners) Munde bei einem Gartenfest in Wahnfried: Semper auf dem Balkon in einer Rede begriffen, Wagner erschrocken unter dem Volk, springt hinauf, um Semper vom Balkon zu reissen – da erblickt man ihn und –: Mit gefangen etc.“

Wagner floh mit falschem Pass zunächst in die Schweiz und blieb nach einem kurzen Aufenthalt in Paris bis 1858 dauerhaft in Zürich im Exil. Dort entstanden in den Folgejahren die "Zürcher Kunstschriften", unter anderen "Die Kunst und die Revolution, Das Kunstwerk der Zukunft" und seine große musiktheoretische Schrift "Oper und Drama".

In einem regen Briefaustausch mit seinen Freunden Franz Liszt, August Röckel und Theodor Uhlig entwickelte und erklärte er seine zukünftigen künstlerischen Ambitionen. Mit seinem neuen Opernentwurf "Wieland der Schmied" versuchte Wagner in Paris erneut sein Glück, allerdings vergeblich. Er lernte die junge Jessie Laussot kennen, die in unglücklicher Ehe gebunden war, und folgte ihr nach Bordeaux, in der Absicht, sein bisheriges Leben hinter sich zu lassen und mit ihr nach Griechenland zu fliehen. Nach einigen Wochen beendete er die Affäre und kehrte zu seiner Frau nach Zürich zurück. In Weimar fand am 28. August 1850 in Abwesenheit Wagners die Uraufführung von "Lohengrin" unter der Leitung von Franz Liszt statt.
Wagner lernte 1852 Otto und Mathilde Wesendonck kennen und begann nach einer Kur in der Wasserheilanstalt Albisbrunn, südlich von Zürich gelegen, mit der Dichtung zum "Ring des Nibelungen". Er lernte Georg Herwegh kennen, einen Weggenossen von Karl Marx, der ein reger Diskussionspartner und Wanderfreund wurde. Wagner unternahm ausgedehnte Bergtouren, unter anderem eine mehrwöchige Fußwanderung nach Italien. In der Einsamkeit der Hochgebirgslandschaften und erhabenen Gletscher sah er die idealen Szenenbilder für seinen "Ring". Am 16. Februar 1853 las Wagner erstmals öffentlich seine komplette Ring-Dichtung an vier Abenden im Hotel Baur au Lac in Zürich.

Im Mai 1853 gab Wagner enthusiastisch aufgenommene Konzerte mit Ausschnitten aus eigenen Werken in Zürich. Im Juli besuchte ihn Liszt; bei dieser Gelegenheit kam es zum Bruderschaftstrunk mit Liszt und Herwegh. Wagner reiste im September erneut nach Italien, wo ihm in einem Hotel in La Spezia im Halbschlaf die Ur-Idee zum musikalischen Beginn des "Rings des Nibelungen" kam, und konzipierte das "Rheingold"-Vorspiel. Am 10. Oktober war Wagner bei Liszt in Paris und sah zum ersten Mal dessen Tochter Cosima, die zu diesem Zeitpunkt 15 Jahre alt war. Im Herbst 1854 vollendete Wagner die "Rheingold"-Komposition, an der er seit Oktober 1851 mit zahlreichen Unterbrechungen gearbeitet hatte.

Richard Wagner las 1854 auf Empfehlung von Herwegh Schopenhauers Hauptwerk "Die Welt als Wille und Vorstellung". Im selben Jahr begann er mit der Konzeption von "Tristan und Isolde". Die Oper wurde grundlegend von der Philosophie Schopenhauers beeinflusst. 1855 gab Wagner mehrere Konzerte in London, 1856 richtete er ein Gnadengesuch an den sächsischen König. Zwischenzeitlich lebte er auf dem sogenannten „Grünen Hügel“ neben der Villa Wesendonck in Zürich, arbeitete an "Siegfried" und später an "Tristan und Isolde" und vertonte – als musikalische Studien zum "Tristan" – fünf Gedichte von Mathilde Wesendonck ("Wesendonck-Lieder"). Am 18. August 1857 wurden Hans von Bülow und Cosima in Berlin getraut und unternahmen ihre Hochzeitsreise zu Wagner nach Zürich. Wagners Affäre mit Mathilde Wesendonck spitzte sich 1858 zu: Nachdem Minna die Beziehung ihres Mannes zur verheirateten Mathilde Wesendonck aufgedeckt und einen Eklat provoziert hatte, trennte sich Wagner von seiner Frau. Er reiste nach Venedig, wo er den zweiten Akt des "Tristan" komponierte. Seine Frau übersiedelte nach Dresden.

Im Frühjahr 1859 musste Wagner aus politischen Gründen das damals unter österreichischer Verwaltung stehende Venedig verlassen. Er begab sich nach Luzern und vollendete im Hotel Schweizerhof den "Tristan". Danach ging er wieder nach Paris, wohin Minna ihm nachfolgte. In Fürstin Pauline von Metternich und Marie von Kalergis (später Fürstin Muchanoff) fand er neue Mäzene, die ihm Konzerte in Paris und Brüssel ermöglichten. Im August 1860 konnte Wagner nach einer Teilamnestie durch den sächsischen König wieder deutschen Boden betreten.

Wagner studierte 1861 an der Opéra Garnier in Paris eine neue, französische Fassung seines "Tannhäuser" ein, für die er die erste Szene neu komponiert und ein Ballett eingefügt hatte. Trotzdem entsprach das Ergebnis nicht den vorgefassten Erwartungen einiger Pariser Publikumsclubs, so dass es zum Tannhäuser-Skandal kam. Auch hatte der Dirigent der Aufführung, Pierre-Louis Dietsch, nach Wagners Meinung die Produktion sabotiert. Nach der dritten durch Zwischenrufe gestörten Aufführung zog Wagner sein Werk zurück. Er verließ Paris und hielt sich in Karlsruhe, Venedig und Wien auf, kehrte dann einige Wochen später wieder nach Paris zurück, um im Auftrag des Musikverlegers Franz Schott aus Mainz mit seiner neuen Arbeit "Die Meistersinger von Nürnberg" zu beginnen. Anfang 1862 siedelte er nach Biebrich um, um die Musik zu den "Meistersingern" zu komponieren.

Ein neues Zusammentreffen mit Minna Anfang 1862 in Biebrich führte zur endgültigen Trennung des Ehepaars. Im gleichen Jahr erließ der König von Sachsen eine vollständige Amnestie, worauf Wagners Freund und Gönner Wendelin Weißheimer ihm erstmals wieder ein Konzert in Leipzig, seiner Heimatstadt, ermöglichte. In Weimar sah Wagner Franz Liszt wieder. Im Juli traf er sich mit den Bülows, danach blieb er in Wien und wohnte einige Monate in Penzing, um die geplante Uraufführung seines "Tristan" zu begleiten, zu der es aber wegen zahlreicher Schwierigkeiten nicht kam. Im Wiener Musikverein gab er im Beisein der Kaiserin Elisabeth einige umjubelte Konzerte, erstmals mit Ausschnitten aus seinem "Ring". Im Jahr 1863 gab Wagner Konzerte in Sankt Petersburg, Moskau, Budapest, Prag und Karlsruhe, die künstlerisch erfolgreich waren, jedoch nicht die erwarteten Einnahmen brachten. Am 28. November bekannten sich Wagner und Cosima in Berlin gegenseitig ihre Liebe. Im Frühjahr 1864 flüchtete Wagner vor Steuerfahndung und Gläubigern aus Wien und besuchte Eliza Wille in Mariafeld bei Zürich.
Letzte Rettung aus größter finanzieller Not und persönlicher Verzweiflung ergab sich für Wagner indirekt dadurch, dass er am 4. Mai 1864 von König Ludwig II. in München empfangen wurde, der wenige Wochen zuvor im Alter von 18 Jahren die Regentschaft vom verstorbenen Vater Maximilian übernommen hatte. Wagner war nicht nur der Lieblingskomponist des Königs, sondern wurde auch sein „väterlicher“ Freund und Berater. Der König blieb bis zum Tode Wagners dessen Mäzen. In dieser exponierten Stellung nahm Wagner Einfluss auf politische Entscheidungen des jungen Königs und verfasste verschiedene politische Schriften. Im Juni und Juli des gleichen Jahres weilte Cosima bei Wagner im Haus Pellet am Starnberger See, wo sie ihre Liebesbeziehung besiegelten. Der König stellte ihm in der Brienner Straße in München als Wohnsitz ein Haus zur Verfügung. Am 10. April 1865 wurde in München Isolde geboren, das erste gemeinsame Kind von Cosima (noch eine verheiratete "von Bülow") und Richard Wagner. Am 10. Juni fand die Uraufführung von "Tristan und Isolde" in München statt. Am 17. Juli begann Wagner seine Autobiographie "Mein Leben" zu diktieren. Wegen heftiger Proteste der Bevölkerung und der Regierung, die Wagner und Ludwig II. Verschwendungssucht vorhielten, verließ Wagner Bayern im Dezember in Richtung Schweiz. Er mietete vorübergehend ein Landhaus bei Genf, begann sich dort einzurichten und die Komposition des ersten Akts der "Meistersinger" fortzusetzen. Auf der Suche nach einem dauerhaften Wohnsitz reiste er Anfang 1866 nach Toulon, Lyon und Marseille.

Inzwischen war seine Frau Minna am 25. Januar 1866 in Dresden gestorben. Ende März mietete Wagner das bei Luzern gelegene Landhaus Tribschen und zog am 15. April dort ein. Die unterbrochene Kompositionsarbeit an den "Meistersingern" wurde wieder aufgenommen.

Am 22. Mai erhielt er überraschenden Besuch von König Ludwig und Paul von Thurn und Taxis. Ludwig wollte als König abdanken und bei Richard Wagner bleiben, der den jungen König jedoch überzeugen konnte, nach München zurückzukehren. Wenige Monate später zog Cosima von Bülow mit ihren beiden Bülow-Kindern Daniela und Blandine und der Wagner-Tochter Isolde bei ihm ein. Richards und Cosimas gemeinsames zweites Kind Eva wurde dort am 17. Februar 1867 geboren. Die Uraufführung der "Meistersinger von Nürnberg" fand am 21. Juni 1868 in München am Hoftheater statt. Am 8. November kam es in Leipzig zur ersten Begegnung mit Nietzsche. Ab dem 16. November lebte Cosima endgültig bei Wagner und begann am 1. Januar 1869 ihr Tagebuch zu schreiben. Friedrich Nietzsche, seit kurzem Professor in Basel, kam nun regelmäßig (insgesamt 23 mal) als Gast nach Tribschen und war auch zugegen, als am 6. Juni 1869 Siegfried, Cosimas und Richards drittes Kind, geboren wurde. Am 22. September fand auf Veranlassung König Ludwigs, jedoch gegen den Willen Wagners, in München die Uraufführung von "Das Rheingold" statt. Auch die Uraufführung der "Walküre" erfolgte ohne Wagners Zustimmung, der den "Ring" nur vollständig aufführen wollte, am 26. Juni 1870 in München.

Am 18. Juli 1870 wurde die Ehe Cosimas und Hans von Bülows geschieden, am 25. August wurden Cosima und Richard Wagner in der protestantischen Kirche von Luzern getraut. Am 25. Dezember 1870 fand die Uraufführung des "Siegfried-Idylls" als Geburtstagsgeschenk für Cosima auf der Treppe in Wagners Haus in Tribschen statt. Wagner wählte 1871 Bayreuth als Festspielort und kündigte erstmals Festspiele zur Aufführung des Ring des Nibelungen an. Im April reiste er mit Cosima über Bayreuth nach Berlin, wo sie von Otto von Bismarck empfangen wurden. Eine finanzielle Unterstützung der geplanten Festspiele durch das Deutsche Kaiserreich konnte Wagner nicht erreichen. Zur Finanzierung der Festspiele wurden ab 1872 Wagnervereine gegründet und Patronatsscheine verkauft; eine wesentliche Rolle spielte dabei Marie Gräfin Schleinitz, die Wagner 1863 kennengelernt hatte und ihn zeitlebens enthusiastisch förderte.

Wagner verließ im Frühjahr 1872 mit Cosima und den Kindern Tribschen, um nach Bayreuth zu ziehen, zunächst ins Hotel Fantaisie neben dem gleichnamigen Schloss in Donndorf, etwa sieben Kilometer westlich von Bayreuth, dann in eine Stadtwohnung. Am 22. Mai konnte er den Grundstein für sein Festspielhaus legen. Er war 1873 oft auf Konzertreisen, um Geld für seine Festspielstiftung einzuspielen. Bruckner und Nietzsche waren zu Besuch in Bayreuth. Am 2. August 1873 fand das Richtfest des Festspielhauses statt. In diesem Jahr hatte Friedrich Nietzsche seine ersten schweren Krankheitsanfälle. Auch Wagner war von den vielfältigen Belastungen seiner Arbeit zunehmend angegriffen und hatte in den letzten zehn Lebensjahren unter regelmäßigen Herzanfällen zu leiden.

Im Dezember 1873 wurde ihm der Königliche Maximiliansorden für Kunst und Wissenschaft verliehen, der ihm bereits 1864 zugedacht war und den er damals aus politisch-persönlichen Überlegungen nicht angenommen hatte.

Am 28. April 1874 bezogen Cosima und Richard Wagner das Haus Wahnfried. Die Partitur des "Ring des Nibelungen" wurde am 21. November 1874 beendet und König Ludwig gewidmet, der – nach längerem Zögern – mit einer zusätzlichen finanziellen Unterstützung das Festspielunternehmen rettete, als Wagners eigene Mittel und eingehende Spenden zu versiegen drohten.

Das Festspielhaus war 1875 so weit fertiggestellt, dass bereits die Proben beginnen konnten. Im Bayreuther Festspielhaus hatte Wagner ein „unsichtbares Orchester“ anlegen lassen, indem der Orchestergraben mit einer Abdeckung zum Publikum hin abgeschirmt wurde („mystischer Abgrund“). Dadurch konnte die Konzentration der Zuschauer einzig auf die dramatische Handlung und die akustische Wahrnehmung der Musik gerichtet werden, ohne dass deren Tonerzeugung sichtbar wurde. Wie sich zeigte, war durch diese Einrichtung aber auch eine besondere Klangqualität erreicht worden. Die einzigartige Akustik des Hauses beruht außerdem darauf, dass der Raum ein Holzbau ist und der Zuschauerraum keine Logen an den Seiten hat. Die Sitze sind ungepolstert, so dass weniger Schall geschluckt wird. Die Idee zu dieser Anlage des Festspielhauses geht zurück auf das Theater in Riga, wo Wagner in einer Art Scheune dirigieren musste, die durch eine Bretterwand unterteilt war, von deren Akustik er jedoch begeistert war.

In Anwesenheit Kaiser Wilhelms I. begannen am 13. August 1876 die ersten Bayreuther Festspiele mit der vollständigen Aufführung des "Ring des Nibelungen". Im September reiste Wagner nach Italien und hatte eine letzte Begegnung mit Nietzsche in Sorrent. In den Jahren 1877 bis 1879 arbeitete Wagner in seinem Haus Wahnfried am "Parsifal". Während eines London-Aufenthalts wurde er von Königin Victoria von Großbritannien empfangen. Am 31. Dezember 1879 verreiste Wagner erneut nach Italien und hielt sich im Folgejahr überwiegend in Neapel, Ravello, Siena und Venedig auf. Dort entstanden auch seine sogenannten „Regenerationsschriften“ ("Religion und Kunst"), die in den von Hans von Wolzogen herausgegebenen "Bayreuther Blättern" veröffentlicht wurden.

Nachdem er mit seiner Ring-Aufführung bei den ersten Festspielen 1876 ein finanzielles Desaster erlebt hatte, trug sich Wagner eine Zeitlang mit Plänen, in die Vereinigten Staaten auszuwandern, was er mit unrealistischen wirtschaftlichen Erwartungen verband. Sein aus Amerika stammender Zahnarzt Newell Sill Jenkins, der zwischen 1866 und 1909 in Dresden praktizierte und mit Wagner befreundet war, hatte ihm von den Verhältnissen in den Staaten erzählt. Wagner hatte vor, den Amerikanern den "Parsifal" als Dankesgabe für den in seiner Vorstellung sicher erfolgreichen Neuanfang zu schenken: „Ich halte es nicht für unmöglich, dass ich mich noch entschließe, mit meiner ganzen Familie und meinem letzten Werke für immer nach Amerika auszuwandern.“ Er besprach seine Pläne mit Jenkins, der ihn auch in Italien besuchte, und formulierte in einem dreiseitigen Brief wirtschaftliche Bedingungen, die seine Existenz jenseits des Ozeans absichern sollten. Jenkins bemühte sich jedoch, ihm diese Pläne im Verbund mit anderen Bekannten und Familienangehörigen auszureden.

Letztlich setzte Wagner seine Auswanderungspläne mit Rücksicht auf sein Alter und möglicherweise auch seine Kinder, die an Bayreuth hingen, nicht um. Im November 1881 reiste er, gesundheitlich angeschlagen, wegen des günstigeren Klimas mit seiner Familie nach Sizilien und vollendete am 13. Januar 1882 in Palermo den "Parsifal", der bei den zweiten Bayreuther Festspielen am 26. Juli 1882 in Bayreuth uraufgeführt wurde. Zuvor gab es in München eine Privataufführung des Parsifal-Vorspiels für König Ludwig; es war ihre letzte Begegnung.

Am 16. September 1882 reiste Wagner mit seiner Familie abermals nach Venedig, wo er auch mehrere Wochen mit Franz Liszt zusammen war. Am 25. Dezember gab er als Geburtstagsgeschenk für Cosima letztmals ein gemeinsames Konzert im Teatro La Fenice; er dirigierte seine Jugendsymphonie in C-Dur.

Am 13. Februar 1883 hielt er sich in dem von ihm und seiner Familie bewohnten Seitenflügel des Palazzo Vendramin-Calergi auf. Gegen 15 Uhr wartete die Familie bei Tisch auf Wagner, der trotz Herzkrämpfen in seinem Arbeitszimmer an einem Aufsatz "Über das Weibliche im Menschlichen" schrieb. Das Hausmädchen fand ihn zusammengesunken an seinem Schreibtisch über den Worten „Gleichwohl geht der Prozeß der Emanzipation des Weibes nur unter ekstatischen Zuckungen vor sich. Liebe – Tragik“. Er sagte noch: „Meine Frau und der Doktor“, bevor er in Bewusstlosigkeit fiel und gegen 15:30 Uhr in Cosimas Armen starb.

Der Bildhauer Augusto Benvenuti nahm am 14. Februar die Totenmaske ab. Am 16. Februar wurde Wagners einbalsamierter Leichnam, begleitet von seiner Familie und einigen Freunden, in zwei Sonderwagen, die dem Zug aus Venedig angehängt waren, über München nach Bayreuth überführt. Nach der Ankunft am Sonntag, dem 18. Februar, in Bayreuth wurde der Sarg unter den Klängen des Trauermarsches aus "Götterdämmerung" unter der Anteilnahme der Bayreuther Bevölkerung vom Bahnhof zur Villa Wahnfried geleitet und in der vorbereiteten Gruft im Garten beigesetzt.

Wagner wollte die aus seiner Sicht „dekadenten“ Theater reformieren, mit Hilfe seiner Kunst zu einer besseren Volkserziehung beitragen und somit die Welt verbessern. Bereits in jungen Jahren war er von der Idee beherrscht, Musik und Drama zu verknüpfen ("Das Kunstwerk der Zukunft", "Oper und Drama") und in Anlehnung an die Tradition der griechischen Tragödien eine neue Kunstrichtung zu begründen. In seinen Schriften hat er immer wieder beschrieben, wie mittels Musik dramatische Handlungen zu „Botschaften“ werden können und die Musik (das weiblich „gebärende Element“) der Dichtung (der männlich „zeugende Samen“) zusätzliche Ausdruckskraft verleiht.

Seine Konzeption vertrat er mit Vehemenz und arbeitete zielstrebig darauf hin, seine Kunstidealvorstellung (in Form von Festspielen an einem Ort der Muße) zu verwirklichen. In König Ludwig II. fand er einen Gleichgesinnten, so dass beide ihre Kunstideale (Festspielhaus, Musikschule, Kunsterziehung) in München realisieren wollten. Dieses Vorhaben scheiterte jedoch und konnte erst später in Bayreuth verwirklicht werden. Dort entwickelte sich Wagners Festspielkonzept vor allem mit seinem Bühnenweihfestspiel "Parsifal" zu einem „Religionsersatz“ durch die Kunst ("Religion und Kunst").

Wagners Werke sind ein Höhepunkt der romantischen Musik und beeinflussten viele Zeitgenossen und spätere Komponisten erheblich. Vor allem der "Tristan" brachte die Musiksprache des 19. Jahrhunderts weit voran und gilt vielen als Ausgangspunkt der Modernen Musik.

Das betrifft vor allem die Harmonik. Mit dem "Tristan", dessen erster Akt 1857 komponiert wurde, führte Wagner sie weit über den Stand hinaus, auf dem Brahms noch 1892 in seinen späten Klavierstücken op. 117 bis 119 blieb. Sie ist das Gebiet, auf dem Wagners Phantasie sich entfaltet, einen charakteristischen Personalstil entwickelt und durch die jeweilige dramatische Situation des Geschehens in Grenzen gehalten wird, sich also nicht im Unendlichen verliert. Wagners Einfluss auf die Musikgeschichte zeigt sich zum Beispiel darin, dass mehr als 100 Jahre nach der Komposition des Werkes die komplexen harmonischen Verläufe des Tristan-Akkords analysiert und unterschiedlich interpretiert wurden und von der Krise der modernen Harmonielehre die Rede war. Das sahen auch viele zeitgenössische Komponisten so. Ein besonderer Verehrer Wagners war z. B. Anton Bruckner, der durch Wagners Tod zum Trauersatz seiner siebten Sinfonie inspiriert wurde. Von Wagner übernahm er allerdings nur die Harmonik und die extreme Länge seiner Kompositionen, während seine Formen durch ihre klaren Kanten in großem Gegensatz zu den fließenden Übergängen Wagners stehen. Hier brachte erst das neue Jahrhundert mit der Zwölftontechnik Arnold Schönbergs eine echte Weiterentwicklung.

Dieser Bewertung wird gelegentlich entgegengehalten, dass schon Komponisten vor Wagner bedeutende harmonische Neuerungen in die Musik eingeführt hatten. Dies gilt etwa für Frédéric Chopin, dessen gewagte Chromatik bzw. Harmonik – etwa in einigen Préludes und Nocturnes – seine Zeitgenossen überraschte.

Bei Wagners Einfluss, dem sich viele zu entziehen versuchten, kann zudem nicht von einer kontinuierlichen, gleichförmigen Entwicklung gesprochen werden. Komponisten wie etwa Pjotr Iljitsch Tschaikowski und Antonín Dvořák bewegten sich noch in „traditionellen“ harmonischen Bahnen, während Richard Strauss und Gustav Mahler die wagnersche Tonsprache übernahmen.

Gattungsgeschichtlich liegt Wagners Bedeutung in der Weiterentwicklung der sogenannten Nummernoper zum Musikdrama. Während etwa Webers "Freischütz" eine Abfolge einzelner Nummern (Arien, Duette, Chöre etc.) ist, die durch gesprochene Rezitative miteinander verbunden werden, herrscht bei Wagner – vor allem in seinen reifen Werken – die sogenannte „unendliche Melodie“. Das Orchester beginnt am Anfang eines Aktes zu spielen und hört am Aktende auf; gesprochen wird nicht. Es gibt keine Arien mehr, sondern – gesungene – Erzählungen bzw. Monologe, Dialoge etc. Sie stehen aber nicht isoliert neben- bzw. nacheinander, sondern werden miteinander durch die Orchestermusik verwoben. Dabei bedient sich Wagner der Leitmotivtechnik, d. h. er ordnet einer bestimmten Person, einem Gegenstand oder einem Gefühl (Liebe, Sehnsucht, Wut) ein bestimmtes musikalisches Motiv zu, das immer dann zu hören ist, wenn die Person, der Gegenstand oder das Gefühl auftaucht.

Wagner wollte „Gedachtes“ und „Gefühltes“ musikalisch ausdrücken und bewirkte mit einer solchen „absichtsvollen Musik“ eine bis dahin nicht gekannte „psychologische Wirkung“ beim Zuhörer. Mit der Leitmotivtechnik im "Ring des Nibelungen" und bei "Tristan und Isolde" ist ihm dies eindrucksvoll gelungen.

In zwei Fällen soll Wagners Musik Emotionen ausgelöst haben, die zum Tode führten – 1911 beim Tod von Felix Mottl während des 2. Aktes des "Tristan" und 1968 beim Herztod des Dirigenten Josef Keilberth, ebenfalls im 2. Akt des "Tristan".

Wagner prägte nachhaltig den Dirigierstil. Er dirigierte auswendig und unterstrich die Emotionalität der Musik durch Mimik und Gestik, was bis dahin nicht üblich war. Von großer Wirkung war die Aufführung der 9. Symphonie von Beethoven, die er am Palmsonntag 1846 in Dresden nach vielen Proben dirigierte. Zum besseren Verständnis der Musik hatte Wagner für dieses Konzert ein Programm mit Stellen aus Goethes "Faust" drucken lassen. Wie in Dresden waren es auch später in Zürich oder London Wagners Interpretationen beethovenscher Symphonien, die ihn als Experten für Beethoven-Dirigate auswiesen. Der Bildhauer Gustav Adolph Kietz, jüngerer Bruder des Porträtmalers und Wagner-Freundes Ernst Benedikt Kietz, berichtet in seinen Erinnerungen:
Wagner war schon früh davon überzeugt, ein Genie zu sein. „In fünfzig Jahren werde ich der Beherrscher der musikalischen Welt sein“, prophezeite er. Er war mit einem Körpermaß von 1,66 Metern nicht groß (Anm.: Seinerzeit war dies jedoch eine Durchschnittsgröße in Sachsen), hatte aber eine starke Ausstrahlung, wie selbst einer seiner größten Kritiker, der Wiener Rezensent Eduard Hanslick, konstatieren musste:

Wagner hatte „sein Herz auf der Zunge“ und gewann viele Freunde, die sich für ihn und seine Kunst einsetzten, zum Beispiel Franz Liszt, Otto von Wesendonck und Julie Ritter. Er konnte charmant sein und beanspruchte für sich und seine Kunst, von der „Gesellschaft“ unterstützt zu werden (es gab damals noch keine Tantiemen für Wiederaufführungen von Kunstwerken). Seine finanziellen Probleme sah er als „lächerliche Schulden“, denen man in der Zukunft erheblich größere „Aktiva“ gegenüberstellen könne. Erst durch König Ludwig II. konnte dieser „Anspruch“ erfüllt werden, wobei Wagner es immer als Priorität ansah, seine Festspielidee verwirklichen zu können.

Cosima Wagner verstand es, ihr Idol und ihren späteren Ehemann „ins rechte Licht“ zu setzen, beispielsweise durch den „Hausbiographen“ Carl Friedrich Glasenapp, der noch zu Wagners Lebzeiten eine mehrbändige Biographie zu schreiben begann. Seine Autobiographie diktierte Wagner seiner Frau Cosima und schenkte den ersten Privatdruck seinem „Freund“ König Ludwig II. Erst im Jahre 1911 wurde die Autobiographie veröffentlicht. Wagner wurde von verschiedenen Malern porträtiert, darunter Franz von Lenbach und Pierre-Auguste Renoir (1882).

Wie kaum ein anderer Künstler hat Wagner polarisiert, und bis in die Gegenwart beschäftigen sich Interpreten unterschiedlicher Disziplinen mit seinem vielschichtigen Werk. Neben Komponisten, die Wagner ablehnten, wie Brahms und Tschaikowski, gab es Kritiker wie Nietzsche – und später Adorno –, die nicht nur auf die Gefahren des „sinnbetörenden Rausches“ hinwiesen, sondern sich mit den Wirkungen Wagners auf die Musik der Zukunft, ja der gesamten Kultur auseinandersetzten.
Zunächst hatte Friedrich Nietzsche in seiner frühen Schrift "Die Geburt der Tragödie aus dem Geiste der Musik" Wagner noch als Erneuerer deutscher Kultur gefeiert und ihm in seinen "Unzeitgemäßen Betrachtungen" einen eigenen Essay "Richard Wagner in Bayreuth" gewidmet. Nachdem er sich in "Menschliches, Allzumenschliches" (1878–1880) von seinem früheren Abgott schrittweise gelöst hatte, publizierte er später etliche kritische, ja hämische Schriften, in denen er Wagner vor allem nach dessen "Parsifal" zudem der Dekadenz, des „undeutschen“ Wesens und der Sinnbenebelung bezichtigte und über das geistige Niveau der sogenannten Wagnerianer in Bayreuth spottete. Nietzsche gab allerdings halb ironisch zu, dass man schon aus psychologischen Gründen auf Wagner nicht verzichten könne, wenngleich Georges Bizets helle, südliche und diesseitige Welt der schweren und schwülen Atmosphäre Wagners vorzuziehen sei.

Nietzsches Kritik an Wagner ist vielschichtig, und obwohl sie sich vor allem am Spätwerk (dem "Parsifal") entzündete, bezog er sie nun auch auf frühere Werke und den "Ring", den er in den "Unzeitgemäßen Betrachtungen" noch gefeiert hatte. Als ehemaliger „Schüler“ Schopenhauers ("Schopenhauer als Erzieher"), der sich später gegen den Pessimismus seines Lehrers stellte, analysierte Nietzsche dessen Einfluss auf Wagner. Habe Wagner als revolutionärer Denker zunächst in Verträgen, Gesetzen, Institutionen das Übel der Welt erblickt – das Vertragsmotiv im "Ring" –, änderte sich später sein Weltbild, und das christliche Motiv der Erlösung trat in den Mittelpunkt. Viele Figuren Wagners sollten fortan „erlöst“ werden. Wagners „Schiff“ sei nach der „Götterdämmerung der alten Moral“ lange Zeit „lustig auf dieser Bahn“ (des Optimismus) gelaufen, bis es auf das „Riff“ der schopenhauerschen Philosophie gefahren sei. Er habe dann den "Ring" ins Schopenhauersche übersetzt: Alles auf der Welt laufe schief, und alles gehe zugrunde. So sei nur das Nichts, die Auslöschung, die „Götterdämmerung“ die Erlösung – und dieses Nichts werde von Wagner nun unaufhörlich gefeiert.

Kurz vor seinem Zusammenbruch im Januar 1889 zog Nietzsche in seinen Spätwerken "Ecce homo", "Götzen-Dämmerung" und "Der Fall Wagner" eine brennglasartige Bilanz seines Denkens. In seinem letzten Werk, "Nietzsche contra Wagner", das er zu Weihnachten 1888 veröffentlichte, setzte er sich schonungslos mit Wagner, den Deutschen und deren "décadence" auseinander.

Das Verhältnis zwischen Franz Liszt und Wagner war nicht ohne Spannungen. Mit „Altersweisheit“ fanden sie wieder zueinander. Nach Wagners plötzlichem Tod schrieb Liszt an Olga von Meyendorff:

Thomas Mann beschäftigte sich in Essays, Vorträgen und seinem epischen Werk immer wieder mit Wagner. Einerseits konnte er sich dem Klangrausch seiner Musik nicht entziehen, andererseits analysierte er in vielen Abhandlungen und Briefen immer wieder die Schwächen Wagners:

In seinem später als Essay erschienenen Vortrag "Leiden und Größe Richard Wagners", den er 1933 zum 50. Todestag Wagners in München hielt, analysierte er das wagnersche Lebenswerk und setzte sich derart kritisch mit der Persönlichkeit und der Musik Wagners auseinander, dass es zu einem inszenierten Protest gegen den Schriftsteller kam. Dieser „Protest der Richard-Wagner-Stadt München“, der am 16./17. April 1933 in den "Münchener Neuesten Nachrichten" erschien und u. a. von Hans Knappertsbusch, Richard Strauss und Hans Pfitzner unterzeichnet war, bestärkte Thomas Mann in dem Entschluss, nicht nach Deutschland zurückzukehren. Die Verfasser warfen Thomas Mann vor, von den Idealen der "Betrachtungen eines Unpolitischen" abgerückt zu sein, mit „ästhetisierendem Snobismus“ das „tiefste deutsche Gefühl“ zu beleidigen und den „großen deutschen Meister“ zu verunglimpfen.

Thomas Mann sagte im Vortrag "Richard Wagner und der Ring des Nibelungen" 1938 in der Aula der Universität Zürich:
Theodor W. Adorno, der Sozialphilosoph und Musiktheoretiker der Zweiten Wiener Schule, beschäftigte sich u. a. in seinem Buch "Versuch über Wagner" mit dem Werk des Komponisten:
Marcel Prawy, der Wiener Dramaturg, Theater- und Musikkritiker, resümiert in seiner Wagner-Hommage:


Die Bewertung von Richard Wagners Antisemitismus ist bis heute von der Frage geprägt, inwieweit seine judenfeindlichen Äußerungen und Werke das eigene ambivalente Verhältnis zum Judentum, zur Religion im Allgemeinen und zur politischen Landschaft seiner Zeit widerspiegeln oder von Anstößen aus seiner Umgebung hervorgerufen wurden. Wagner griff antijudaistische und frühantisemitische Stereotype und Reflexe auf, die er vorfand. Sie werden auch auf Martin Luthers Judenschriften zurückgeführt. Antisemitismus gehörte in Wagners Umfeld zum „guten Ton“, vor allem während der Zeit mit Cosima, die eine extreme antisemitische Einstellung hatte. Wagner gab antisemitische Stereotype allerdings nicht nur wieder, sondern vertrat sie offensiv und entwickelte sie in Schriften wie "Das Judenthum in der Musik" aktiv weiter.

Wagners Weltbild, in dem sich künstlerische und politisch-agitatorische Ambitionen vermischten, war geprägt von einer pauschalen Sehnsucht nach Aufbruch, Umsturz und Revolution, nach einer meist nicht näher definierten neuen Kunst und Gesellschaft, die aus dem Untergang des Bestehenden erstehen sollte (siehe: "Die Kunst und die Revolution"). Seine Motivation war eine sich stets wandelnde Mischung aus humanistisch-aufklärerischem Pathos der Revolution gegen die Aristokratie, romantischen Aspekten wie der Sehnsucht nach einer Rückkehr zur Natur und der Ablehnung der Industrialisierung sowie nationalistischen Wunschträumen von der totalen Identifikation und Einheit einer Rasse oder eines Volkes.

Ressentiments gegen deutsche Juden waren für Wagner ein willkommenes Ventil für einen ausgeprägten Minderwertigkeitskomplex, wie einige Biographen meinen, beispielsweise der Tiefenpsychologe Josef Rattner, der in einem „Psychogramm“ Wagners Antisemitismus wie folgt erklärt:

Rattner führt weiter aus, dass Wagners Antisemitismus – auch der von Cosima Wagner – eine Beihilfe zur Integration in die „vornehme Welt“ gewesen sei. Mit dem dauernden Sichaufreizen am Judentum „vollzog das Ehepaar Wagner ein Ritual“. Beide hätten sich dabei gegenseitig ihr „Wohlgeborensein“, ihre „Deutschheit“ und zumindest ihre „rassische Aristokratie“ versichert. Zwei ehrgeizige, auf Perfektionismus bedachte Charaktere hätten sich im Antisemitismus zur wechselseitigen und absoluten Selbstbestätigung vereinigt.

Richard Wagners von Freunden und Bekannten häufig beschriebene Ruhmsucht, sein Hang zu Luxus, Verschwendung und Blendwerk waren ausgerechnet die Eigenschaften, die er häufig den Juden vorwarf. Wie seine Geschwister gehörte Richard Wagner zum Theatermilieu, das sich damals vom fahrenden Volk zu emanzipieren und bürgerliche Anerkennung zu erwerben suchte. Die vom zeitgenössischen Liberalismus grundsätzlich begrüßte jüdische Emanzipation, die mit der Gewerbefreiheit und Aufhebung der Berufsverbote und Zünfte einherging, wurde von anderen Unterprivilegierten oft als bedrohliche Konkurrenz angesehen.

Blieben finanzieller Erfolg und Anerkennung aus, so wähnte Wagner sich nicht selten als Opfer angeblicher jüdischer Gegner und Machenschaften. Seine missgünstige Geringschätzung und Diffamierung jüdischer Komponisten wie Giacomo Meyerbeer und Felix Mendelssohn Bartholdy versuchte er mit Schriften wie "Das Judenthum in der Musik" und dem darauf aufbauenden "Brief an Gräfin Muchanow" durch allgemeinere Theorien zu begründen, um – wie Kritiker vermuten – die dahinter stehenden persönlichen Motive zu verdecken.

In diesem Zusammenhang wird auch der musikalische Einfluss Mendelssohns auf Wagner diskutiert. So waren einige Frühwerke Wagners, wie etwa die "Columbus-Ouvertüre", teilweise von Kompositionen Mendelssohns angeregt. Trotz der persönlichen Vorbehalte rühmte Wagner Mendelssohns Musik durchaus und bezeichnete dessen "Hebriden-Ouvertüre" noch 1879 in den "Bayreuther Blättern" als „eines der schönsten Musikwerke, die wir besitzen“.

Wagners Schriften und Äußerungen über und gegen Juden umfassen ein weites Spektrum. Dieses reicht von niedersten, affektiven Tiraden über ausgeklügelte Theorien bis hin zu beinahe versöhnlichen Tönen und – wie einige Historiker und Musikkritiker meinen – zur Identifizierung Wagners mit der Außenseiterrolle der Juden, da er auch sich selbst oft als Außenseiter empfand.

In seiner Broschüre "Das Judenthum in der Musik" (1869) schrieb Richard Wagner ohne wirklichen musiktheoretischen Bezug vom „natürlichen Widerwillen gegen jüdisches Wesen“ und meinte: „Der Jude ist nach dem gegenwärtigen Stande der Dinge dieser Welt wirklich bereits mehr als emanzipiert: er herrscht, und wird solange herrschen, als das Geld die Macht bleibt, vor welcher alles unser Thun und Treiben seine Kraft verliert“. An die Juden gerichtet, schloss er mit den Worten: „Aber bedenkt, dass nur Eines eure Erlösung von dem auf euch lastenden Fluche sein kann: die Erlösung Ahasvers, – der U n t e r g a n g ! “ (Sperrung im Original).

Richard Wagner hatte diesen Text bereits 1850 in der "Neuen Zeitschrift für Musik" unter dem Pseudonym „K. Freigedank“ publiziert. Er trat damit 1869 wieder an die Öffentlichkeit, diesmal unter eigenem Namen und ergänzt durch einen Anhang (S. 31–57), der den ursprünglichen Aufsatz an Gehässigkeit und Demagogie noch übertrifft. Darin findet sich gegen Ende der scheinbar resignierende Aufruf: „Ob der Verfall unserer Cultur durch eine gewaltsame Auswerfung des zersetzenden fremden Elementes aufgehalten werden könne, vermag ich nicht zu beurtheilen, weil hierzu Kräfte gehören müssten, deren Vorhandensein mir unbekannt ist.“ Dies kann als Appell zur tätigen Judenbekämpfung aufgefasst werden.

Als sich im Gefolge des Berliner Antisemitismusstreits 1880/81 in ganz Deutschland rasant eine aggressive, antijüdische Stimmung ausbreitete, deren Kerngedanke die Vorstellung war, Juden seien ein in Deutschland nicht integrierbarer Fremdkörper und besäßen nach ihrer Emanzipation einen unverhältnismäßigen und zerstörerischen Einfluss auf die deutsche Kultur, stellte sich Wagner kurz vor seinem Tod noch einmal klar auf die Seite der antisemitischen Agitateure und schrieb am 22. November 1881 in einem Brief an König Ludwig II., er halte:
Auch das auf die Juden gemünzte kulturpessimistische Begriffspaar vom „Dämon“, der den „Verfall“ der Kultur betreibt, taucht in dieser Zeit in einer Spätschrift Wagners auf ("Erkenne dich selbst", 1881). Es wurde 1923 von dem nationalsozialistischen Theoretiker Alfred Rosenberg in einer antisemitischen Schrift aufgegriffen.

Selbst in Wagners Einsatz für den Tierschutz am Ende seines Lebens lassen sich antisemitische Anklänge finden. Angelehnt an Schopenhauer hielt er Schächtung und Vivisektion für „zwei Seiten einer Medaille“ und betrachtete sie als Ausdruck einer „Jüdischen Medizin“.

Persönlich pflegte Wagner Freundschaften zu jüdischen Landsleuten wie seinem Helfer Carl Tausig, Joseph Rubinstein, Angelo Neumann und der berühmten Sängerin Lilli Lehmann. Bemerkenswert ist auch, dass er am Ende seines Lebens die "Parsifal"-Uraufführung Hermann Levi anvertraute, dem Sohn eines Rabbiners, der zu Wagners Freundeskreis zählte und zu dem er ein ambivalentes Verhältnis besaß. Von Wagners Anhängerkreis wurde Levi später als Jude abgelehnt und antisemitisch angefeindet.

Uneinigkeit besteht in Wissenschaft und Kritik darüber, ob und inwieweit Wagners antisemitische Einstellungen Eingang in seine musikdramatischen Werke gefunden haben. Während der Musikkritiker Joachim Kaiser verschiedentlich bekräftigte, in Wagners Werken ließen sich antisemitische Äußerungen nicht nachweisen, war unter anderem Theodor W. Adorno überzeugt, die von Wagner negativ gezeichneten Figuren wie Mime oder Alberich aus dem "Ring" seien Judenkarikaturen. In Westdeutschland wurde die Debatte um antisemitische Themen und Figuren in Wagners Opern seit den 1970er Jahren durch mehrere Schriften von Hartmut Zelinsky vorangetrieben, der Richard Wagner als Protonationalsozialisten zeichnete und dem viele Wagnerianer vehement widersprachen. In der DDR war der Leipziger Literaturwissenschaftler Bernd Leistner 1989 mit Adorno der Ansicht, auch der Beckmesser sei als antijüdische Karikatur angelegt. Obwohl er Zelinskys Thesen ablehnte, vertrat auch der Wagner-Biograf Barry Millington 1992 diese Ansicht in seiner Antwort auf die Frage, ob "Die Meistersinger" ein antisemitisches Thema enthalten. Ihm wurde unter anderem von Hans Rudolf Vaget und Dieter Borchmeyer widersprochen. Auf breiten Widerspruch stieß auch die 1995 von dem amerikanischen Antisemitismusforscher Paul Lawrence Rose vertretene These, bereits im "Fliegenden Holländer" würden antisemitische Ideen transportiert. An einer Einbettung der Ringfiguren in Wagners judenfeindliche Denkweise und auch am Beckmesser als Träger antijüdischer Stereotypen halten Sprachwissenschaftler wie Ludger Hoffmann oder Theatermacher wie Barrie Kosky aber fest. Saul Friedländer nahm 1999 eine vermittelnde Position ein, sieht aber ebenfalls antijüdische Tendenzen in Wagners Musikdramen.

Ein Kongress mit dem Ziel einer wissenschaftlichen Aufarbeitung des Themas "Wagner und die Juden" fand erstmals im Festspielsommer 1998 in Bayreuth unter Beteiligung von Wagnerforschern aus Deutschland, Israel und den USA statt; die Beiträge und z. T. sehr kontroversen Diskussionen wurden unter der Herausgeberschaft von Dieter Borchmeyer u. a. publiziert.

An Wagners Antisemitismus knüpfte der „Bayreuther Kreis“ um Cosima Wagner an, der in der Villa Wahnfried tagte. Zu diesem gehörten sowohl Rassentheoretiker wie Arthur de Gobineau und Houston Stewart Chamberlain als auch Künstler und rechte Aktivisten. So waren im Umfeld des Kreises etwa der Maler Hans Thoma oder der Schriftsteller Julius Langbehn aktiv. Durch denunziatorische Anfeindungen jüdischer Künstler wie Hermann Levi, Alexander Kipnis oder Ottilie Metzger-Lattermann trug der Bayreuther Kreis dazu bei, antisemitische Ressentiments unter Intellektuellen zu verbreiten. Durch das Engagement der Wahnfried-Zirkel wurde im Kaiserreich eine Art Wagner-Bewegung ausgelöst, die sich in der Gründung zahlreicher Kulturvereine zeigte. Hier wurde Wagner-Begeisterung mit Judenfeindlichkeit und Nationalismus verbunden. Unter dem Einfluss des Hofpredigers Adolf Stoecker sowie Philipp zu Eulenburgs, Cosima Wagners und Chamberlains wurde auch Kaiser Wilhelm II. für die Unterstützung der Wagner-Bewegung gewonnen.

Wagner hatte großen Einfluss auf den englisch-deutschen Schriftsteller Houston Stewart Chamberlain, Verfasser der "Grundlagen des neunzehnten Jahrhunderts" (1899), eines Werks, dessen schwärmerischer Germanenkult von antisemitischem und rassistischem Gedankengut durchzogen ist. Er verfasste es direkt im Anschluss an seine Wagner-Biographie (1895), in der er die tieferen Beweggründe und politisch-philosophischen Vorstellungen des von ihm verehrten Richard Wagner zu erschließen versucht. Chamberlain gehörte seit Ende der 1880er Jahre zum Wahnfried-Kreis um Wagners Frau Cosima und heiratete 1908 Wagners zweite Tochter Eva, nachdem andere Wagner-Töchter seine Avancen abgewiesen hatten. Seit 1909 lebte er dauerhaft in Bayreuth. Er gilt als wichtiger ideologischer Vordenker der Theorie des Rassenkampfes und Wegbereiter des Rassenantisemitismus nationalsozialistischer Prägung und sah sich selbst und sein Verständnis der Rassenfrage in Kontinuität mit Wagner stehend und mit Wagner im Ansatz übereinstimmend.

In der tradierten Wagner-Rezeption wurde häufig beschwichtigend angemerkt, dass Wagners publizistischer Antisemitismus vermutlich eine bloße Randnotiz geblieben wäre, hätte ihn das nationalsozialistische Regime unter Adolf Hitler nicht für sich vereinnahmt. Der Nationalsozialismus stilisierte Wagner zum deutschen Komponisten par excellence und missbrauchte Wagners Musiktheater propagandistisch selbst noch für Untergangsszenarien gegen Ende des Zweiten Weltkriegs im Sinne eines menschenverachtenden Todes- und Endzeitkults.

Während seiner Wiener Zeit ging Hitler regelmäßig in die Oper und beschäftigte sich intensiv mit Wagner. Als Vorbild eigener Lebensvisionen war Wagner für ihn ein vergöttertes Idol. Wie Joachim Fest beschreibt, machte die eingebildete Nachfolge die „Verführung durch den romantischen Geniebegriff deutlich“, welcher in Wagner seine Erfüllung und Entgleisung gefunden habe. Die eskapistischen Träume des scheiternden, im Männerheim lebenden Künstlers Hitler entzündeten sich am Genie Wagners. Hitler erklärte später, mit Ausnahme Wagners keine Vorläufer gehabt zu haben, und bezeichnete Wagner als „größte Prophetengestalt, die das deutsche Volk besessen“ habe.

In einem Aufsatz über Hitler und Wagner hat der Historiker Saul Friedländer 2000 auf das Faktum aufmerksam gemacht, dass es keine einzige schriftliche oder verbürgte mündliche Mitteilung Hitlers gibt, in der er sich auf Wagners Antisemitismus beruft. Ob Hitler Wagners Schrift "Das Judenthum in der Musik", in der dieser den „Untergang“ des Judentums prophezeit, gekannt hat, ist deshalb fraglich. Jedenfalls hat sich der gescheiterte Künstler Hitler, der dem „Massenerschütterer und Großmeister des Musiktheaters“ (Thomas Mann) verfallen war, zum „Vollstrecker seines Propheten“ gemacht (Joachim Köhler).

Hitler wurde dem „Bayreuther Kreis“ 1919 durch den Musikkritiker Dietrich Eckart bekannt. Dank ihm lernte Hitler im Jahre 1923 in Bayreuth Cosima und Winifred Wagner sowie Houston Stewart Chamberlain persönlich kennen und nahm später als „Führer“ per Verfügung Einfluss auf die Festspiele hinsichtlich des Programms und der Regie, z. B. bei "Parsifal". Es verschaffte Hitler persönliche Genugtuung und das Gefühl der Anerkennung beim deutschen Bürgertum, dass er als ehemaliger Postkartenmaler Ideen zum Bühnenbild eines der höchstrangigen Musikfestivals in Deutschland beisteuern durfte.

Das Thema Wagner und Hitler wird seit Jahrzehnten publizistisch behandelt, beispielsweise von Hartmut Zelinsky und Joachim Köhler. Dieser versuchte in seinem Buch "Wagners Hitler", den Einfluss der wagnerschen Gedankenwelt auf Hitler und dessen Handeln nachzuweisen. Auch Thomas Mann beschäftigte sich immer wieder mit der Thematik: „Es ist viel Hitler in Wagner.“

Im Jahr 2012 wurde die Wanderausstellung „Verstummte Stimmen. Die Bayreuther Festspiele und die Juden 1876 bis 1945“ im Bayreuther Rathaus und im Park vor dem Festspielhaus in Bayreuth neben der Wagner-Büste aufgestellt. Durch die Ausstellung wird an frühere jüdische Mitwirkende bei Wagner-Festspielen erinnert, die von Nationalsozialisten vertrieben oder ermordet wurden.

In Israel ist Wagner heftig umstritten. Die öffentliche Aufführung von Wagners Werken ist noch immer praktisch nicht möglich. Im Juli 2001 verursachte das von Daniel Barenboim mit der Berliner Staatskapelle auf dem Israel-Festival in Jerusalem als Zugabe aufgeführte Vorspiel aus "Tristan und Isolde" einen Eklat und zog die Kritik des damaligen Jerusalemer Bürgermeisters Ehud Olmert und einen Boykottaufruf des Simon-Wiesenthal-Zentrums nach sich, obwohl sich die Mehrheit des Publikums spontan für die Aufführung ausgesprochen hatte. Bereits früher hatten Proteste von Holocaust-Überlebenden Wagner-Aufführungen verhindert. Für die häufig angeführte Begründung, Wagnermusik sei den Häftlingen in nationalsozialistischen Vernichtungslagern über Lautsprecher vorgespielt worden, gibt es nach Aussage des israelischen Rechtsanwalts Jonathan Livny, der am 14. November 2010 die erste Wagner-Gesellschaft in Israel gegründet hat, allerdings keinen tragfähigen historischen Beleg.

In der Stadthalle der Wagner-Festspielstadt Bayreuth spielte das Israel Chamber Orchestra unter der Leitung des Wiener Dirigenten Roberto Paternostro im Juli 2011 das "Siegfried-Idyll". Auch hier rief der Tabubruch, dass ein israelisches Orchester Wagners Musik spielt, geteilte Reaktionen hervor. Einen für den 18. Juni 2012 an der Universität Tel Aviv geplanten Konzertabend mit Werken Wagners sagte die Universität im Vorfeld ab, da die Veranstaltung „eine rote Linie“ überschreite und die „Gefühle der israelischen Öffentlichkeit im Allgemeinen und der Holocaust-Überlebenden im Besonderen verletzen“ könnte.

Insgesamt sind nach dem Wagner-Werk-Verzeichnis (WWV) einschließlich aller Gelegenheitskompositionen und Widmungsblätter, jedoch ohne die Schriften Wagners, 113 Werke verzeichnet.


Nur die folgenden zehn Werke wählte Wagner für Aufführungen im Festspielhaus auf dem Grünen Hügel in Bayreuth aus:

Wagner hat neben den Inhaltsentwürfen, Textfassungen und Analysen seiner Musikdramen zahlreiche musiktheoretische, philosophische, politische und belletristische Schriften verfasst und sie mit seinen Musikdramen ab 1871 in seiner Sammlung "Sämtliche Schriften und Dichtungen" herausgegeben, die – einschließlich der Autobiographie "Mein Leben" – 16 Bände umfasst. Wagner war schriftstellerisch produktiver als die meisten anderen Komponisten, und in seinem schriftstellerischen Œuvre verarbeitete er Ideen und Eindrücke aus seiner breit gefächerten Lektüre. Seine Schriftzeugnisse belegen, „dass Wagner ein Durchlauferhitzer mit dem Ziel der kreativen Anverwandlung und rücksichtslosen Vereinnahmung war“. Zudem hat er tausende Briefe geschrieben.

Die meisten seiner Schriften gelten als stilistisch verunglückt und zeichnen sich nicht durch stringente Gedankenführung aus. Neben trocken deduzierendem Stil und Kanzleiprosa finden sich hymnische Episoden und Gedankenblitze. Gregor-Dellin urteilt in seiner Wagner-Biographie, die Schriften seien mit „Reisszwecken gespickt, ein unverdaulicher Brei, Kanzleiprosa“, und Ludwig Reiners griff für Beispiele schlechter Prosa immer wieder auf Texte Wagners zurück. Für den ebenso kritischen wie begeisterten Verehrer Thomas Mann enthalten die Schriften „sehr Wahres und Falsches ineinander geschlungen“ und „höchste Sachkunde neben peinlicher Mitrederei“. Man könne aus Wagners Schriften nicht viel über den Verfasser lernen. „Wagners siegreiches Werk beweist nicht seine Theorie, sondern nur sich selbst.“

Wie auch immer man die Schriften beurteilt, so können sie doch als Nährboden betrachtet werden, aus dem seine musikdramatischen Werke hervorgegangen sind. Zugleich machen sie deren geistigen Hintergrund verständlich.

Als seine wichtigsten Schriften gelten:

Wagners Autobiographie "Mein Leben", die zu seinen Lebzeiten nur im Privatdruck in etwa 25 Exemplaren für enge Freunde erschien, gilt als kulturhistorisches Dokument des 19. Jahrhunderts, ebenso wie die Tagebuchaufzeichnungen Cosima Wagners, die sie von 1869 bis zum Tod ihres Gatten führte. Darin ist viel Privates, „Nebensächliches“ mitgeteilt, aber auch zahlreiche Aussprüche und Gespräche Wagners bis hin zu seinen Träumen.

Zum 200. Geburtstag Richard Wagners wurden 2013 eine 10-Euro-Gedenkmünze und eine Briefmarke zu 58 Eurocent jeweils mit seinem Bildnis herausgegeben.

Zahlreiche Orte würdigen Wagner durch die Benennung einer Straße nach ihm, siehe dazu Richard-Wagner-Straße und Richard-Wagner-Platz.












</doc>
<doc id="4361" url="https://de.wikipedia.org/wiki?curid=4361" title="Ring (Algebra)">
Ring (Algebra)

Ein Ring ist eine algebraische Struktur, in der, ähnlich wie in den ganzen Zahlen formula_1, Addition und Multiplikation definiert und miteinander bezüglich Klammersetzung verträglich sind. Die Ringtheorie ist ein Teilgebiet der Algebra, das sich mit den Eigenschaften von Ringen beschäftigt.

Der Name "Ring" bezieht sich nicht auf etwas anschaulich Ringförmiges, sondern auf einen organisierten Zusammenschluss von Elementen zu einem Ganzen. Diese Wortbedeutung ist in der deutschen Sprache ansonsten weitgehend verloren gegangen. Einige ältere Vereinsbezeichnungen (wie z. B. Deutscher Ring, Weißer Ring, Maschinenring) oder Ausdrücke wie „Verbrecherring“, „Tauschring“ oder auch „Ringvorlesung“ weisen noch auf diese Bedeutung hin. Das Konzept des Ringes geht auf Richard Dedekind zurück; die Bezeichnung "Ring" wurde allerdings von David Hilbert eingeführt. In speziellen Situationen ist neben der Bezeichnung "Ring" auch die Bezeichnung "Bereich" geläufig. So findet man in der Literatur eher den Begriff "Integritätsbereich" statt "Integritätsring".

Je nach Teilgebiet und Lehrbuch (und zum Teil je nach Kapitel) wird unter einem Ring etwas Unterschiedliches verstanden. Ebenfalls leicht abweichend sind dann die Definitionen von Morphismen sowie Unter- und Oberstrukturen. Mathematisch ausgedrückt handelt es sich bei diesen unterschiedlichen Ringbegriffen um unterschiedliche Kategorien.

Ein "Ring" formula_2 ist eine Menge formula_3 mit zwei zweistelligen Operationen formula_4 und formula_5, sodass

Das neutrale Element formula_11 von formula_12 heißt "Nullelement" des Rings formula_3.

Ein Ring heißt "kommutativ", falls er bezüglich der Multiplikation kommutativ ist, ansonsten spricht man von einem nicht-kommutativen Ring.

Hat die Halbgruppe formula_14 ein (beidseitiges) neutrales Element formula_15, ist also ein Monoid, dann nennt man formula_2 einen "Ring mit Eins" oder "unitären Ring". Ringe mit nur links- oder nur rechtsneutralem Element gelten in der Ringtheorie nicht als unitär.

Manche Autoren verstehen unter einem Ring grundsätzlich einen (kommutativen) Ring mit Eins, und sprechen andernfalls von einem "Pseudo-Ring", englisch auch "rng" (sic!) oder "non-unital ring".In der Kategorie der Ringe mit Eins muss die Eins auch bei Ringhomomorphismen erhalten bleiben.

Jeder Ring lässt sich in einen unitären Ring einbetten.
In der kommutativen Algebra werden Ringe als "kommutative Ringe mit Eins" definiert.






Eine Untermenge formula_25 eines Ringes formula_3 heißt "Unterring" (oder "Teilring") von formula_3, wenn formula_25 zusammen mit den beiden auf formula_25 eingeschränkten Verknüpfungen von formula_3 wieder ein Ring ist. formula_25 ist genau dann ein Unterring von formula_3, wenn formula_25 eine Untergruppe bezüglich der Addition ist und formula_25 abgeschlossen bzgl. der Multiplikation ist, d. h.

Auch wenn formula_3 ein Ring mit Eins ist, so muss die Eins nicht notwendigerweise in formula_25 enthalten sein. formula_25 kann auch ein Ring ohne Eins sein – etwa formula_41 – oder eine andere Eins haben. In der Kategorie der Ringe mit Eins wird von einem Unterring verlangt, dass er dasselbe Einselement enthält (dafür ist es zwar notwendig, aber nicht immer hinreichend, dass der Unterring ein auf diesen bezogen multiplikativ neutrales Element enthält).

Der Durchschnitt von Unterringen ist wieder ein Unterring, und der von formula_42 "erzeugte Unterring" wird definiert als der Durchschnitt aller formula_43 umfassenden Unterringe von formula_3.

Ein Ring formula_45 heißt "Oberring" oder "Erweiterung" eines Ringes formula_3, wenn formula_3 ein Unterring von formula_45 ist. Es ist auch üblich von einer "Ringerweiterung" zu sprechen, wenn man einen Ring mit einem Oberring betrachtet. Dies ist analog zum Begriff der Körpererweiterung.


Jeder Ring kann in einen Ring mit Einselement eingebettet werden.

Folgende Ringerweiterung findet sich in E. Sernesi "Deformations of algebraic schemes":
Sei formula_3 ein kommutativer Ring, formula_50 ein formula_3-Modul und formula_52 die direkte Summe der abelschen Gruppen. Eine Multiplikation auf formula_45 sei definiert durch
(Die Identifikation von formula_55 mit formula_56 mit einem formula_57, für das formula_58 ist, und Ausrechnen von formula_59 ergibt die genannte Formel.) formula_45 erweist sich als Ring. Man hat die exakte Sequenz
mit der Projektion formula_62. Somit ist formula_45 eine Erweiterung von formula_3 um formula_50. Eine andere bemerkenswerte Eigenschaft dieser Konstruktion ist, dass der Modul formula_50 zum Ideal eines neuen Ringes formula_45 wird. Nagata nennt diesen Vorgang "Prinzip der Idealisierung".

Zu einem Ring formula_3 heißt eine Teilmenge formula_69 von formula_3 "Linksideal" (bzw. "Rechtsideal"), wenn gilt:
Ist formula_69 sowohl Links- als auch Rechtsideal, so heißt formula_69 "zweiseitiges Ideal" oder auch nur "Ideal."

Enthält in einem Ring mit Eins ein (Links-, Rechts-)Ideal die Eins, so umfasst es ganz formula_3. Da formula_3 auch ein Ideal ist, ist formula_3 das einzige (Links-, Rechts-)Ideal, das die Eins enthält. formula_3 und formula_83 sind die sogenannten "trivialen Ideale."

Jedes Ideal formula_69 von formula_3 ist auch ein Unterring von formula_3, ggf. ohne Eins. In der Kategorie der Ringe mit 1 gilt formula_69 dann nicht als Unterring.

Ist formula_69 ein Ideal in einem Ring formula_3, dann kann man die Menge der Nebenklassen
bilden. Die Verknüpfung formula_4 lässt sich wegen ihrer Kommutativität immer auf formula_92 fortsetzen; die Verknüpfung formula_5 jedoch nur, wenn formula_69 ein "zweiseitiges" Ideal in formula_3 ist. Ist dies der Fall, dann ist formula_92 mit den induzierten Verknüpfungen ein Ring. Er wird "Faktorring" formula_92 genannt – gesprochen: formula_3 modulo formula_69.

Der Ringhomomorphismus
der einem Element formula_101 seine Nebenklasse formula_102 zuordnet, hat formula_69 zum Kern.

In einem Ring formula_3 mit Eins wird der von formula_15 erzeugte Unterring als der "Grundring" bezeichnet. Hat dieser endliche Mächtigkeit formula_106 so ist formula_107 die Charakteristik von formula_108 abgekürzt: formula_109 und man sagt, formula_3 habe "positive" Charakteristik. Andernfalls wird formula_111 gesetzt. Damit ist im endlichen wie unendlichen Fall der unitäre Ringhomomorphismus
injektiv.
Der Grundring ist das Bild formula_113 und jedes seiner Elemente ist mit jedem Ringelement vertauschbar. Außerdem ist für jedes Ringelement formula_114
das additive Inverse von formula_116

Ist formula_3 ein kommutativer Ring mit Eins, so kann der Polynomring formula_118 gebildet werden. Dieser besteht aus Polynomen mit Koeffizienten aus formula_3 und der Variablen formula_120 zusammen mit der üblichen Addition und Multiplikation für Polynome. Eigenschaften von formula_3 übertragen sich zum Teil auf den Polynomring. Ist formula_3 nullteilerfrei, faktoriell oder noethersch, so trifft dies auch auf formula_118 zu.

Ist formula_3 ein Ring mit Eins, so kann zu gegebenem formula_125 der Matrizenring formula_126 gebildet werden. Dieser besteht aus den quadratischen Matrizen mit Einträgen aus formula_3 mit der üblichen Addition und Multiplikation für Matrizen. Der Matrizenring ist wiederum ein Ring mit Eins. Jedoch ist der Matrizenring für formula_128 weder kommutativ noch nullteilerfrei, selbst wenn formula_3 diese Eigenschaften hat.

Sind formula_3 und formula_45 Ringe, dann kann das Mengenprodukt formula_132 auf natürliche Weise mit einer Ringstruktur ausgestattet werden:
Denn die Gültigkeit des Distributivgesetzes in jeder Komponente überträgt sich unmittelbar auf das Mengenprodukt.

Sind beide Ringe formula_3 und formula_45 unitär, dann ist auch formula_132 unitär mit formula_138 als dem Einselement.

Dieselbe Konstruktion ist möglich mit einer beliebigen Familie von Ringen: Sind formula_139 Ringe über einer Indexmenge formula_140, dann ist formula_141 ein Ring, genannt das direkte Produkt der formula_142 Ein Unterring des direkten Produkts ist die direkte Summe, bei der nur endlich viele Komponenten von 0 verschieden sind.

Für zwei Ringe formula_3 und formula_45 heißt eine Abbildung
"Ringhomomorphismus" (kurz "Homomorphismus"), falls für alle formula_146 gilt:

Der Kern formula_149 des Ringhomomorphismus formula_150 ist ein zweiseitiges Ideal in formula_3.

Ein Morphismus formula_150 von "Ringen mit Eins" muss außerdem noch die Bedingung erfüllen, dass das Einselement auf das Einselement abgebildet wird:

Ein Isomorphismus ist ein bijektiver Homomorphismus.
Die Ringe formula_3 und formula_45 heißen "isomorph", wenn es einen Isomorphismus von formula_3 nach formula_45 gibt. In diesem Fall ist auch die Umkehrabbildung ein Isomorphismus; die Ringe haben dann dieselbe Struktur.

Ausgestattet mit der komponentenweisen Addition und Multiplikation ist das direkte Produkt formula_158 ein Ring. Dann ist mit formula_159 die Abbildung
ein Homomorphismus von Ringen; ein Homomorphismus von "Ringen mit Eins" aber nur, wenn formula_161

Von zwei Elementen formula_162 heißt formula_163 "linker Teiler" (Linksteiler) von formula_164, falls ein formula_165 mit formula_166 existiert. Dann ist auch formula_167 "rechtes Vielfaches" von formula_163. Entsprechend definiert man "rechten Teiler" (Rechtsteiler) und "linkes Vielfaches".

In kommutativen Ringen ist ein linker Teiler auch ein rechter und umgekehrt. Man schreibt hier auch formula_169, falls formula_163 ein Teiler von formula_167 ist.

Alle Elemente von formula_3 sind (Rechts- bzw. Links-) Teiler der Null. Der Begriff des (Rechts- bzw. Links-) Nullteilers hat eine andere Definition. Wenn formula_11 nach dieser als Nullteiler zählt, gilt der Satz: Ein Element ist genau dann (Rechts- bzw. Links-) Nullteiler, wenn es nicht (rechts- bzw. links-) kürzbar ist.

Existiert in einem Ring formula_3 mit Eins zu einem Element formula_175 ein Element formula_101, so dass formula_177 (bzw. formula_178) gilt, so nennt man formula_101 ein "Linksinverses" (bzw. "Rechtsinverses") von formula_175. Besitzt formula_175 sowohl Links- als auch Rechtsinverses, so nennt man formula_175 "invertierbar" oder "Einheit" des Ringes. Die Menge der Einheiten eines Ringes formula_3 mit Eins wird gewöhnlich mit formula_184 oder formula_185 bezeichnet. formula_184 bildet bezüglich der Ringmultiplikation eine Gruppe – die "Einheitengruppe" des Ringes. Ist formula_187, so ist formula_3 ein Schiefkörper, ist formula_3 darüber hinaus kommutativ, so ist formula_3 ein Körper.

In kommutativen Ringen mit Eins (insbesondere Integritätsringen) definiert man alternativ die Einheiten auch als diejenigen Elemente, die die Eins teilen. Dass formula_175 die Eins teilt, heißt nämlich dass es formula_101 gibt mit formula_193.

Zwei Elemente formula_163 und formula_167 sind genau dann "rechts assoziiert", wenn es eine Rechtseinheit formula_175 gibt, sodass formula_197. "Links assoziiert" bei formula_198 mit einer Linkseinheit formula_175.

Wenn in einem kommutativen Ring mit Eins die Elemente formula_200 in der Beziehung formula_169 und formula_202 stehen, dann sind formula_163 und formula_167 zueinander "assoziiert". Die Seitigkeit (links, rechts) kann also weggelassen werden.

Assoziiertheit ist eine Äquivalenzrelation.

Ein von 0 verschiedenes Element formula_205 heißt "irreduzibel", wenn es weder Linkseinheit noch Rechtseinheit ist und es keine Nicht-Linkseinheit formula_163 und keine Nicht-Rechtseinheit formula_167 mit formula_208 gibt, wenn also aus der Gleichung folgt, dass formula_163 Linkseinheit oder formula_167 Rechtseinheit ist.

In einem kommutativen Ring genügt es zu fordern, dass formula_205 von 0 verschieden ist, keine Einheit ist und aus formula_208 folgt, dass formula_163 oder formula_167 eine Einheit ist.

Für kommutative unitäre Ringe definiert man: Ein Element formula_62 heißt "prim" oder "Primelement", wenn es keine Einheit und ungleich 0 ist und aus formula_216 folgt formula_217 oder formula_218 (siehe auch "Hauptartikel:" Primelement).

In einem nullteilerfreien Ring ist jedes Primelement irreduzibel. In einem faktoriellen Ring ist umgekehrt auch jedes irreduzible Element ein Primelement.







</doc>
<doc id="4364" url="https://de.wikipedia.org/wiki?curid=4364" title="Religionswissenschaft">
Religionswissenschaft

Die Religionswissenschaft ist eine Geisteswissenschaft oder auch Kulturwissenschaft, die Religion empirisch, historisch und systematisch erforscht. Dabei befasst sie sich mit allen konkreten Religionen, religiösen Gemeinschaften, Weltanschauungen und Ideologien sowie religiös konnotierten Narrativen der Vergangenheit und Gegenwart.

Zu ihren Subdisziplinen zählen beispielsweise der Religionsvergleich bzw. -komparatistik, die Religionsgeschichte, Religionsphänomenologie, Religionssoziologie, Religionspsychologie, Religionsethnologie, Religionsökonomie, Religionsgeographie u. a. Zur universitären Theologie bestehen Berührungspunkte in allen theologischen Bereichen: kirchengeschichtlichen, exegetischen, systematischen und praktischen. Untersuchungsgegenstand der Religionswissenschaft sind darüber hinaus die Binnensystematiken verschiedener Religionen. Neue Ansätze sind beispielsweise die sogenannte „Angewandte“ (Wolfgang Gantke) beziehungsweise „Praktische Religionswissenschaft“ (Udo Tworuschka).

Was genau „Religion“ ist oder etwas als „religiös“ bestimmt, konnte bisher nur vorläufig bestimmt werden (siehe Religionsdefinition). Die Religionswissenschaft arbeitet in der Regel mit auf ihre jeweiligen Fragestellungen zugeschnittenen Arbeitsdefinitionen (Heuristik).

Im deutschsprachigen Raum wird das Fach oftmals durch Attribute wie „allgemein“ oder „vergleichend“ näher bestimmt und häufig mit der Disziplin der Religionsgeschichte assoziiert. Zum Beispiel nannte sich der Dachverband der Religionswissenschaft in Deutschland 50 Jahre lang „Deutsche Vereinigung für Religionsgeschichte“ und wurde 2005 in Deutsche Vereinigung für Religionswissenschaft (DVRW) umbenannt.

Eine Untersuchung von Glaubensinhalten auf der Sachebene, beispielsweise die Suche nach transzendenter Wahrheit, nimmt die Religionswissenschaft nicht vor. Sie ordnet, klassifiziert, vergleicht und analysiert die Erscheinungsformen und Elemente verschiedener Religionen oder religiöser Narrative. Die religionsgeschichtliche Arbeit sowie qualitative und quantitative Methoden (z. B. durch Feldforschung) sind hierfür wesentliche Grundlagen. Anschließende Vergleiche und Analysen werden z. B. mit interdisziplinären Methoden durchgeführt; dazu gehören kulturtheoretische, religionssoziologische, religionspsychologische Zugänge zum Material.

Dagegen sind Religionsphilosophie und Religionstheologie ausdrücklich nicht Teil der Religionswissenschaft, da sie normative Elemente enthalten. Eine große Rolle spielen die Philologien von Sprachen, in denen religiöse Schriften abgefasst sind oder in denen religiöses Leben stattfindet; beispielsweise Gräzistik, Latinistik, Semitistik, Arabistik, Sinologie, Keilschriftforschung, Indologie. Außerdem sind Fächer von Bedeutung, die sich auf eine einzelne Religion oder einen bestimmten Kulturkreis spezialisieren (oft identisch mit den entsprechenden Philologien): Keltologie, Judaistik, Buddhismuskunde, Islamwissenschaft, Afrikanistik, Orientalistik, Tibetologie.

Weitere Fächer, die mit der Religionswissenschaft im interdisziplinären Austausch stehen, sind Geschichte, Archäologie, Volkskunde, Ethnologie/Völkerkunde, Anthropologie und andere Kulturwissenschaften. Vor dem Hintergrund von religiösen Konflikten bestehen auch Beziehungen zur Politikwissenschaft und Fragestellungen der Friedens- und Konfliktforschung. Seit den 1990ern spielen auch Disziplinen der Neurowissenschaften eine Rolle.

Religiöse Binnensystematiken sind grundsätzlich Teil des Gegenstandes, nicht der Methode der Religionswissenschaft. Im Rahmen von innerhalb des Faches umstrittenen Ansätzen wie Praktischer bzw. Angewandter oder Interkultureller Religionswissenschaft spielen religiöse Akteure auch als Dialogpartner eine Rolle. Gleichzeitig bedienen sich die christlichen Theologien – wie auch viele andere Disziplinen – religionswissenschaftlicher Methoden, soweit es die Erforschung ihrer historischen Grundlagen betrifft. Soweit Religionswissenschaft an theologischen Fakultäten angesiedelt ist, wird sie oft im Sinne von Missionswissenschaft, (vergleichende) Religionsgeschichte oder im Dienste einer Universaltheologie als Hilfsdisziplin betrachtet.

Die Religionsforschung im religionswissenschaftlichen Sinne entstand während der neuzeitlichen Aufklärung, insbesondere in England, den Niederlanden, Deutschland und Skandinavien. Erst ab dem Anfang des 20. Jahrhunderts etablierte sie sich als eigenständiges Fach an den Universitäten; in Deutschland erstmals 1912 mit der Gründung des Religionswissenschaftlichen Instituts Leipzig. Zunächst wurde sie an theologischen Fakultäten gelehrt und betrieben. Dies ging auf die Rektoratsrede Adolfs von Harnack von 1901 zurück. Erster Lehrstuhlinhaber war der spätere Erzbischof von Schweden und Friedensnobelpreisträger Nathan Söderblom.

Die Krise des Historismus nach dem Ersten Weltkrieg resultierte in einer Aufwertung der Religionsgeschichte als Zugang zu "universalen" Grundeigenschaften des Menschen. Diese wurden durch Ansätze der Religionsphänomenologie gesucht (siehe bspw. Rudolph Otto, Mircea Eliade), die heute jedoch innerhalb der religionswissenschaftlichen Diskussion als dekonstruiert gelten. Aus der Problematisierung des klassischen Religionsvergleichs und dem damit einhergehenden Universalismus der Religionsdefinition ist die bis heute andauernde Aushandlung der religionswissenschaftlichen Theorie und Methodik erwachsen. In den meisten Universitäten wird sie daher als von den Theologien unabhängige Wissenschaft gelehrt, was einen Einzug in die philosophischen und kulturwissenschaftlichen Fakultäten zur Folge hatte.

Im Allgemeinen lassen sich innerhalb der bestehenden Religionswissenschaft mehrere Traditionslinien ausmachen. Nach Hamid Reza Yousefi lassen sie sich in zwei Linien unterteilen, die grundsätzlich verschiedene Antworten auf die Frage geben, was Religionswissenschaft ist bzw. nicht ist, eine phänomenologische und eine philologische Richtung. Während Religionsphänomenologen die Kategorie des Heiligen nicht preisgeben und faktisch eine Religionswissenschaft des Verstehens betreiben, distanzieren sich philologisch ausgerichtete Religionswissenschaftler von dieser methodischen Tätigkeitsform und halten an der Religionswissenschaft als einer ‚reinen’ Wissenschaft fest. Um diese Linien miteinander zu versöhnen, entwickelt Yousefi das Konzept einer interkulturellen Religionswissenschaft. Ihm geht es „um den gesellschaftlichen Auftrag der Religionswissenschaft“ und die Beantwortung der Frage, „wozu überhaupt Religionswissenschaft.“ Er schlägt eine pluralistische Methodenkombination vor, in der hermeneutische und empirische Ausrichtungen ineinander greifen und aufeinander aufbauen.

Auch ein diskurstheoretischer bzw. genealogischer Zugang nach Michael Bergunder ist möglich. Aufbauend auf Diskussionen der Semiotik und Poststrukturalismus (siehe Michel Foucault, Ernesto Laclau) wird der Name "Religion" im Zuge einer globalen Verflechtungsgeschichte untersucht und ein besonderes Augenmerk auf die kritische Reflexion von Fragen des Orientalismus, Postkolonialismus und angenommenen Eurozentrismus von "Religion" gelegt.

In den letzten Jahren entstanden mehrere Zentren für interdisziplinäre Religionsforschung in Deutschland. Derzeitig kann Religionswissenschaft als eigenständige Disziplin u. a. an den Universitäten Bayreuth, Berlin (Freie Universität), Bochum, Bremen, Erfurt, Frankfurt, Göttingen, Hamburg, Hannover, Heidelberg, Jena, Leipzig, Marburg, Münster, München, Potsdam und Tübingen studiert werden. Hierbei gibt es folgende Abschlüsse des Faches:

In der deutschen Hochschulpolitik ist die Religionswissenschaft als Kleines Fach eingestuft.

In Österreich kann Religionswissenschaft in Wien, Graz, Salzburg und Linz studiert werden.
In Graz ist es seit dem Wintersemester 2006/07 möglich, ein Masterstudium (Master of Arts) der Religionswissenschaften zu absolvieren, in Salzburg seit dem Wintersemester 2016/17. In Wien bietet dies die Katholisch-Theologische Fakultät der Universität in Zusammenarbeit mit der Evangelisch-Theologischen Fakultät und anderen Fakultäten seit dem Wintersemester 2008/09 an. Das seit Wintersemester 2015/16 existierende Masterstudium Religion in Kultur und Gesellschaft an der Katholischen Privatuniversität Linz beschäftigt sich auch schwerpunktmässig mit religionswissenschaftlichen Inhalten. 

Zurzeit wird die Religionswissenschaft an den Schweizer Universitäten deutlich ausgebaut. Religionswissenschaft mit deutschem oder französischsprachigem Bachelor- oder Masterabschluss kann studiert werden in Basel (dt.), Bern (dt.), Freiburg (dt./frz.), Genf (frz.), Lausanne (frz.), Luzern (dt.) und Zürich (dt.).


Einführungen

Nachschlagewerke


"Organisationen"

"Zeitschriften"


</doc>
<doc id="4365" url="https://de.wikipedia.org/wiki?curid=4365" title="Ribonukleinsäure">
Ribonukleinsäure

Ribonukleinsäure (Ri|bo|nu|kle|in|säu|re; kurz RNS; englisch RNA für "ribonucleic acid") (lat.-fr.-gr. Kunstwort) ist eine Nukleinsäure, die sich als Polynukleotid aus einer Kette von vielen Nukleotiden zusammensetzt. Das Biomolekül ist bei bestimmten Virentypen (RNA-Viren, Retroviren) sowie den hypothetischen urzeitlichen Ribozyten Träger der Erbinformation, also die materielle Basis der Gene. Das Wort setzt sich zusammen aus Ribose und Nukleinsäure.

Eine wesentliche Funktion der RNA in der biologischen Zelle ist die Umsetzung von genetischer Information in Proteine (siehe Proteinbiosynthese, Transkription und Translation), in Form der mRNA fungiert sie hierbei als Informationsüberträger. Daneben erfüllen spezielle RNA-Typen weitere Aufgaben; bei RNA-Viren macht sie sogar das Genom selbst aus. Weiterhin bestehen auch Teile der für die Umsetzung dieser Information verantwortlichen Zellbestandteile aus RNA: Bei der Reifung der mRNA sind snRNA und snoRNA beteiligt, die katalytischen Bestandteile der Ribosomen bildet die rRNA, und die tRNA transportiert die Bausteine für die Proteine. Ferner sind spezielle RNAs an der Genregulation beteiligt.

Vom Aufbau her ist die RNA der DNA ähnlich. RNA-Moleküle sind – im Gegensatz zur doppelsträngigen DNA – in der Regel einzelsträngig, können allerdings in kurzen Strecken mit komplementären Basensequenzen (A-U, G-C) charakteristische Rückfaltungen ausbilden, die intramolekular den Eindruck einer Doppelstrang-Helix erwecken. Beide sind Polynukleotide, bei denen die Nukleobasen an Zuckern über Phosphorsäurediester miteinander verknüpft sind. Die Einzelsträngigkeit erhöht die Zahl der Möglichkeiten für dreidimensionale Strukturen der RNA und erlaubt ihr chemische Reaktionen, die der DNA nicht möglich sind. Jedes Nukleotid besteht bei der RNA aus einer Ribose (d. h. einer Pentose: einem Zucker mit fünf C-Atomen), einem Phosphatrest und einer organischen Base. Die Ribose der RNA ist mit derjenigen der DNA identisch, bis auf eine Hydroxygruppe statt eines Wasserstoff-Atoms an der 2'-Position im Pentose-Ring (daher auch Desoxyribonukleinsäure, DNA). Dieser Unterschied macht die RNA weniger stabil im Vergleich zur DNA, da er eine Hydrolyse durch Basen ermöglicht: Die OH-Gruppe an der 2'-Position des Zuckers wird durch ein negativ geladenes Hydroxidion einer Base ihres Protons beraubt und der dann zurückgebliebene Sauerstoff geht eine Ringbindung mit dem Phosphor ein, wodurch die Bindung zum nächsten Nukleotid gelöst wird. Die RNA wird so in ihre Nukleotide zerlegt.

In der RNA kommen die folgenden organischen Basen vor: Adenin, Guanin, Cytosin und Uracil. Die ersten drei Basen kommen auch in der DNA vor. Uracil dagegen ersetzt Thymin als komplementäre Base zu Adenin. Vermutlich nutzt RNA Uracil, da dieses energetisch weniger aufwändig herzustellen ist (keine Methyl-Substituierung).

Als Sekundärstrukturen sind bei der RNA vor allem Hairpin-, Stemloop- und Loop-Strukturen bekannt, eine Helix-Konformation ist aber ebenfalls möglich, wobei Hairpin- und Stemloop-Strukturen sowohl Einzelstrang- als auch Doppelstrangbereiche aufweisen. Die Loop-Strukturen bezeichnen einzelsträngige Schlaufenstrukturen innerhalb eines Moleküls.

RNA kann wie DNA ebenfalls als doppelsträngiges Molekül vorliegen. Sie weist dabei die typischen Merkmale einer Watson-Crick-Helix auf: antiparallele Anordnung der RNA-Stränge und rechtsgewundene Helix. Sie nimmt dabei die Form einer A- oder A´-Helix an (Vgl. DNA). Die A-RNA wird auch als RNA-11 bezeichnet, homolog zur A´-RNA, die als RNA-12 bezeichnet wird. Hierbei gibt die Zahl nach dem Spiegelstrich die Anzahl der Basenpaare je Helixwindung wieder. A´-RNA kommt häufig bei hohen Salzkonzentrationen vor (über 20 %).

A-RNA: 11 Basenpaare pro Helixwindung, Ganghöhe 2,7 nm bis 2,8 nm, Neigungswinkel zur Helixachse ca. 14°
A´-RNA: 12 Basenpaare pro Helixwindung, Ganghöhe 3 nm, Neigungswinkel zur Helixachse 16° bis 19°

Das in Lebewesen vorkommende Enantiomer der RNA ist die -RNA. Sie ist aus -Ribonukleotiden aufgebaut. Die Chiralitätszentren liegen in der -Ribose. Durch Verwendung von -Ribose, bzw. -Ribonukleotiden lässt sich -RNA synthetisieren. Diese ist vergleichsweise stabiler gegenüber dem enzymatischen Abbau durch RNasen.

Das Enzym RNA-Polymerase katalysiert an der DNA durch den Prozess der Transkription aus Nukleosidtriphosphat (NTP) die RNA. Dafür setzt sich die RNA-Polymerase an eine Promotor genannte Nukleotid-Sequenz der DNA (Transkriptionsinitiation). Dann trennt sie die DNA-Doppelhelix durch Lösen der Wasserstoffbrücken in einem kurzen Bereich in zwei DNA-Einzelstränge auf. Am codogenen Strang der DNA lagern sich durch Basenpaarung komplementäre Ribonukleotide an. Sie werden unter Eliminierung eines Pyrophosphat durch eine esterartige Bindung zwischen Phosphorsäure und Ribose miteinander verknüpft. Die Ableserichtung der DNA verläuft vom 3'-Ende zum 5'-Ende, die Synthese der komplementären RNA dementsprechend 5'→3'. Die Öffnung der DNA-Doppelhelix erfolgt nur in einem kurzen Bereich, so dass der bereits synthetisierte Teil der RNA aus dieser Öffnung heraushängt und zwar mit dem 5'-Ende der RNA voran. Die Synthese der RNA wird an einem Terminator genannten DNA-Abschnitt beendet. Danach wird das RNA-Transkript entlassen und die RNA-Polymerase löst sich von der DNA.

RNA kann per Phosphoramidit-Synthese künstlich erzeugt werden.

RNA-Moleküle können unterschiedliche Funktionen ausüben. Die RNA kann genetische Information übertragen. Andere RNA-Moleküle tragen zur Übersetzung dieser Information in Proteine bei, sowie bei der Regulation der Gene. Darüber hinaus kann RNA auch katalytische Funktionen ähnlich einem Enzym innehaben. RNA wird daher – je nach ihrer Funktion – auch verschieden benannt. Vorangestellte Kleinbuchstaben kennzeichnen die unterschiedlichen RNA-Typen:

Die folgenden RNA-Klassen werden allgemein als nichtcodierende Ribonukleinsäuren bezeichnet.

In der Mehrzahl der Lebewesen spielt die RNA als Informationsträger eine der DNA untergeordnete Rolle:
Die DNA ist hier das permanente Speichermedium für die genetische Information, die RNA dient als Zwischenspeicher.
Nur RNA-Viren (die Mehrzahl aller Viren) nutzen RNA anstelle der DNA als permanentes Speichermedium. Zur Taxonomie von Viren unterscheidet man folgende RNA-Typen:
Darüber hinaus nutzen einige Viren RNA als Replikationsintermediat (z. B. Retroviren und Hepadnaviren).

Da ständig neue RNA gebildet wird und da zu unterschiedlichen Zeitpunkten verschiedene Transkripte benötigt werden (differentielle Genexpression), darf die RNA in der Zelle nicht zu stabil sein, sondern muss auch einem Abbau unterliegen. Dies geschieht mit Hilfe von RNasen, Enzymen, die die Verbindungen des Zucker-Gerüstes der RNA trennen und somit die Monomere (bzw. Oligomere) bilden, welche wieder zur Bildung neuer RNA verwendet werden können. Wann eine RNA abgebaut werden soll, wird dabei vor allem (aber nicht ausschließlich) durch die Länge des Poly-A-Schwanzes bestimmt, der mit zunehmender Verweildauer der RNA im Cytoplasma sukzessive verkürzt wird. Sinkt die Länge dieses Schwanzes unter einen kritischen Wert wird die RNA schnell degradiert. Zusätzlich können die RNAs stabilisierende oder destabilisierende Elemente enthalten, die eine weitere Regulation ermöglichen.

Zumindest bei der mRNA von Eukaryoten findet der RNA-Abbau nicht irgendwo im Cytoplasma statt, sondern in den so genannten „P-Bodies“ (Processing Bodies), die sehr reich an RNasen und anderen, am RNA-turnover (-Abbau)-beteiligten Enzymen sind. Zusammen mit „Stress-Granules“ dienen diese Körper weiterhin der kurzzeitigen Lagerung von mRNA und demonstrieren so wiederum die enge Verknüpfung des RNA-Metabolismus (hier Translation und RNA-Abbau).

Die RNA-Welt-Hypothese besagt, dass RNA-Moleküle bei der chemischen Evolution vermutlich Vorläufer der Organismen waren. Die Hypothese lässt sich ableiten aus der Fähigkeit der RNA zur Speicherung, Übertragung und Vervielfältigung genetischer Informationen, sowie aus ihrer Fähigkeit, als Ribozyme Reaktionen zu katalysieren. In einer Evolutionsumgebung würden diejenigen RNA-Moleküle gehäuft vorkommen, die sich selbst bevorzugt vermehren.

Für die Forschung an RNA sind bereits mehrere Nobelpreise verliehen worden:

RNA kann durch eine RNA-Reinigung, z. B. per RNA-Extraktion, von anderen Biomolekülen getrennt werden. Die Menge und Reinheit der isolierten RNA erfolgt durch photometrische Messung bei einer Wellenlänge von 260 und 280 nm. Weitere Hinweise auf die Qualität der RNA erhält man durch Agarose-Gelelektrophorese gefolgt mit einer Anfärbung durch Farbstoffe wie SYBR Green II, Methylenblau, Stains-All oder durch eine Silberfärbung. Der qualitative Nachweis von RNA (ob eine bestimmte RNA vorliegt) erfolgt meistens durch eine RT-PCR, teilweise mit einer anschließenden DNA-Sequenzierung, oder durch einen Northern Blot. Der quantitative Nachweis (wie viel von einer bestimmten RNA vorliegt) erfolgt meistens durch eine qRT-PCR, bei gereinigten Proben mit nur einer RNA-Sequenz kann die Konzentration auch durch Photometrie bestimmt werden. Durch "Molecular Combing" kann die RNA gestreckt und ausgerichtet werden. Mittels "In situ"-Hybridisierung lassen sich spezifische RNAs in Zellen und Geweben ohne vorhergehende Isolierung nachweisen.




</doc>
<doc id="4366" url="https://de.wikipedia.org/wiki?curid=4366" title="Regulärer Ausdruck">
Regulärer Ausdruck

Ein regulärer Ausdruck (, Abkürzung oder ) ist in der theoretischen Informatik eine Zeichenkette, die der Beschreibung von Mengen von Zeichenketten mit Hilfe bestimmter syntaktischer Regeln dient. Reguläre Ausdrücke finden vor allem in der Softwareentwicklung Verwendung. Neben Implementierungen in vielen Programmiersprachen verarbeiten auch viele Texteditoren reguläre Ausdrücke in der Funktion „Suchen und Ersetzen“. Ein einfacher Anwendungsfall von regulären Ausdrücken sind Wildcards.

Reguläre Ausdrücke können als Filterkriterien in der Textsuche verwendet werden, indem der Text mit dem Muster des regulären Ausdrucks abgeglichen wird. Dieser Vorgang wird auch Pattern Matching genannt. So ist es beispielsweise möglich, alle Wörter aus einer Wortliste herauszusuchen, die mit "S" beginnen und auf "D" enden, ohne die dazwischen liegenden Buchstaben oder deren Anzahl explizit vorgeben zu müssen.

Der Begriff des regulären Ausdrucks geht im Wesentlichen auf den Mathematiker Stephen Kleene zurück. Dieser benutzte eine fast identische Bezeichnung, die er reguläre Mengen nannte.

Reguläre Ausdrücke beschreiben eine Familie von formalen Sprachen und gehören damit zur theoretischen Informatik. Diese Sprachen, die regulären Sprachen, befinden sich auf der untersten und somit ausdrucksschwächsten Stufe der Chomsky-Hierarchie (Typ 3). Sie werden erzeugt durch reguläre Grammatiken.

Zu jedem regulären Ausdruck existiert ein endlicher Automat, der die vom Ausdruck spezifizierte Sprache akzeptiert. Ein entsprechender (nichtdeterministischer) endlicher Automat kann mit der "Thompson-Konstruktion" aus einem regulären Ausdruck konstruiert werden. Daraus folgt die relativ einfache Implementierbarkeit regulärer Ausdrücke. Umgekehrt existiert zu jedem endlichen Automaten ein regulärer Ausdruck, der die vom Automaten akzeptierte Sprache beschreibt. Ein entsprechender regulärer Ausdruck kann mit "Kleenes Algorithmus" aus einem nichtdeterministischen endlichen Automaten konstruiert werden. Kleenes Algorithmus erzeugt meist sehr lange reguläre Ausdrücke. Die "Zustands-Elimination" (deutsch eigentlich: „Zustands-Eliminierung“) liefert in der Praxis meist kürzere reguläre Ausdrücke. Im Höchstfall (engl. "worst case") liefern jedoch beide Algorithmen reguläre Ausdrücke der Länge formula_1, wobei formula_2 die Anzahl der Zeichen des zugrundeliegenden Alphabets und formula_3 die Anzahl der Zustände im Automaten bezeichnen.

Die Syntax definiert genau, wie reguläre Ausdrücke aussehen.

Reguläre Ausdrücke sind immer über einem vorgegebenen Zeichenvorrat formula_4 definiert, dem sogenannten Alphabet. Reguläre Ausdrücke basieren auf genau drei Operationen: Alternative, Verkettung und Wiederholung. Die formale Definition sieht folgendermaßen aus:

Für Alternative wird statt formula_13 auch das Symbol formula_14 verwendet. Man schreibt dann formula_15. Für die Verkettung (Konkatenation) gibt es alternativ auch ein Operatorsymbol; man schreibt dann formula_16.

Man kann auch zusätzliche Konstanten und Operationen erlauben, sofern sich ihre Wirkung auch mit den oben genannten Grundregeln beschreiben ließe. So findet man in der Literatur unter anderem auch formula_17 als regulären Ausdruck oder die positive Kleenesche Hülle formula_18, die als Abkürzung von formula_19 betrachtet werden kann.

Gibt man eine Rangfolge der Operatoren an, kann man auf einige Klammern verzichten. Die Rangfolge ist üblicherweise "Kleene-Stern" vor "Konkatenation" vor "Alternative". Statt formula_20 genügt dann die Schreibweise formula_21.

Die Anzahl der verschachtelten *-Operatoren wird als Sternhöhe bezeichnet.

Die Semantik regulärer Ausdrücke definiert genau, welche formale Bedeutung die Syntax regulärer Ausdrücke hat.

Ein regulärer Ausdruck beschreibt eine formale Sprache, also eine Menge von Wörtern (Zeichenketten). Die Definition der Semantik lässt sich analog zur Syntaxdefinition beschreiben. Dabei bezeichnet formula_22 die formale Sprache, die durch den regulären Ausdruck formula_23 spezifiziert wird.

Enthält die Syntaxdefinition regulärer Ausdrücke auch die Konstante formula_17, so ist deren Bedeutung definiert als formula_34, also die Sprache, die nur das leere Wort formula_35 enthält.

Das leere Wort ist ein Wort einer formalen Sprache (formula_36) und somit kein regulärer Ausdruck. Die Sprache, die nur das leere Wort enthält, lässt sich aber auch ohne die Konstante formula_17 durch einen regulären Ausdruck beschreiben, zum Beispiel: formula_38. Es wird jedoch nicht immer optisch zwischen einem regulären Ausdruck und der zugehörigen Sprache unterschieden, sodass man statt formula_39 auch formula_40 als regulären Ausdruck für die Sprache formula_41 verwendet, ebenso kann die Unterscheidung zwischen formula_5 und formula_43 sowie zwischen formula_17 und formula_35 entfallen.

Wenn das Alphabet aus den Buchstaben formula_40, formula_47 und formula_48 besteht, also formula_49, dann lassen sich die folgenden Sprachen mit den entsprechenden regulären Ausdrücken beschreiben:

Ken Thompson nutzte diese Notation in den 1960er Jahren, um "qed" (eine Vorgängerversion des Unix-Editors "ed") zu bauen und später das Werkzeug grep zu schreiben. Seither implementieren sehr viele Programme und Bibliotheken von Programmiersprachen Funktionen, um "reguläre Ausdrücke" zum Suchen und Ersetzen von Zeichenketten zu nutzen. Beispiele dafür sind die Programme sed, grep, emacs, die Programmiersprachen Perl und Tcl und Standardbibliotheken der Programmiersprachen C, C++, Java, JavaScript, Python, PHP, Ruby und das .NET-Framework. Auch die Textverarbeitung und die Tabellenkalkulation des Office-Paketes OpenOffice.org bieten die Möglichkeit, mit regulären Ausdrücken im Text zu suchen.

Zwischen verschiedenen Regexp-Implementierungen gibt es Unterschiede in Funktionsumfang und Syntax. In Programmiersprachen haben sich überwiegend die "Perl Compatible Regular Expressions" (PCRE) durchgesetzt, die sich an der Umsetzung in Perl 5.0 orientieren. Daneben wird bei POSIX.2 zwischen „grundlegenden“ regulären Ausdrücken "(basic regular expressions)" und „erweiterten“ regulären Ausdrücken "(extended regular expressions)" unterschieden.

Einige Programme, zum Beispiel der Texteditor Vim, bieten die Möglichkeit, zwischen verschiedenen Regexp-Syntaxen hin- und herzuschalten.

Reguläre Ausdrücke spielen eine wichtige Rolle bei der lexikalischen Analyse von Quelltexten, beispielsweise in Compilern oder zur Syntaxhervorhebung in Editoren. Ein lexikalischer Scanner zerlegt den Quelltext mithilfe von regulären Ausdrücken in sogenannte "Tokens" (Schlüsselwörter, Operatoren, …). Da es sich bei den meisten Programmiersprachen um kontextfreie Sprachen handelt, sind reguläre Ausdrücke nicht mächtig genug, um deren Syntax zu beschreiben. Daher wird die bei Compilern folgende syntaktische Analyse in der Regel von einem separaten Programm, dem Parser, erledigt.

Reguläre Ausdrücke spielen auch in der Bioinformatik eine Rolle. Sie kommen in Proteindatenbanken zum Einsatz, um Proteinmotive zu beschreiben. Der reguläre Ausdruck

codice_1

beschreibt zum Beispiel eine Proteindomäne in PROSITE. Der obige reguläre Ausdruck besagt Folgendes: Am Anfang wähle die Aminosäure Tryptophan (Einbuchstabencode W), dann wähle 9 bis 11 Aminosäuren frei aus, dann wähle entweder V, F oder Y, dann wähle entweder F, Y oder W, dann wieder 6 bis 7 Aminosäuren frei, dann entweder G, S, T, N oder E, dann entweder G, S, T, Q, C oder R, dann F, Y oder W, dann R dann S dann A dann P.

Die meisten heutigen Implementierungen unterstützen Erweiterungen wie zum Beispiel Rückwärtsreferenzen "(backreferences)." Hierbei handelt es sich nicht mehr um reguläre Ausdrücke im Sinne der theoretischen Informatik, denn die so erweiterten Ausdrücke beschreiben nicht mehr notwendigerweise Sprachen vom Typ 3 der Chomsky-Hierarchie.

Die folgenden Syntaxbeschreibungen beziehen sich auf die Syntax der gängigen Implementierungen mit Erweiterungen, sie entsprechen also nur teilweise der obigen Definition aus der theoretischen Informatik.

Eine häufige Anwendung regulärer Ausdrücke besteht darin, spezielle Zeichenketten in einer Menge von Zeichenketten zu finden. Die im Folgenden angegebene Beschreibung ist eine (oft benutzte) Konvention, um Konzepte wie "Zeichenklasse", "Quantifizierung", "Verknüpfung" und "Zusammenfassen" konkret zu realisieren. Hierbei wird ein regulärer Ausdruck aus den Zeichen des zugrunde liegenden Alphabets in Kombination mit den Metazeichen codice_2 (teilweise kontextabhängig) gebildet, bei manchen Implementierungen auch codice_3. Die Meta-Eigenschaft eines Zeichens kann durch einen vorangestellten Rückwärtsstrich (Backslash) aufgehoben werden. Alle übrigen Zeichen des Alphabets stehen für sich selbst.

Diejenigen Zeichen, die direkt (wörtlich, literal) übereinstimmen müssen, werden auch direkt notiert. Je nach System gibt es auch Möglichkeiten, das Zeichen durch den Oktal- oder Hexadezimalcode (codice_4 bzw. codice_5) oder die hexadezimale Unicode-Position (codice_6) anzugeben.

Mit eckigen Klammern lässt sich eine "Zeichenauswahl" definieren (codice_7 und codice_8). Der Ausdruck in eckigen Klammern steht dann für "genau ein" Zeichen aus dieser Auswahl. Innerhalb dieser Zeichenklassendefinitionen haben einige Symbole andere Bedeutungen als im normalen Kontext. Teilweise ist die Bedeutung eines Symbols vom Kontext abhängig, in dem es innerhalb der Klammern auftritt.

Beispielsweise bedeutet ein Zirkumflex codice_9 am Anfang einer Zeichenklassendefinition, dass die Zeichenklasse negiert bzw. invertiert wird (im Sinne der Komplementbildung). Steht ein Zirkumflex jedoch irgendwo sonst in der Definition, ist es wörtlich ("literally") zu verstehen. Ebenfalls kontextabhängig ist die Bedeutung des Bindestrich-Zeichens (codice_10). Zudem unterscheiden sich hier die Regexp-Auswerter ("regex engines") (zum Beispiel POSIX und PCRE) in einigen Punkten voneinander. Steht ein Bindestrich codice_10 zwischen zwei Zeichen in der Klassendefinition, zum Beispiel codice_12, so ist er als Bis-Strich zu verstehen, das heißt als Beschreibung eines Zeichenintervalls oder Zeichenbereichs bezüglich der ASCII-Tabelle. Das genannte Beispiel wäre äquivalent zu codice_13. Am Anfang oder Ende einer Zeichenklasse stehende Bindestriche werden als das Zeichen selbst interpretiert.

Es gibt vordefinierte Zeichenklassen, die allerdings nicht von allen Implementierungen in gleicher Weise unterstützt werden, da sie lediglich Kurzformen sind und auch durch eine "Zeichenauswahl" beschrieben werden können. Wichtige Zeichenklassen sind:
Ein Punkt (codice_14) bedeutet, dass an seinem Platz ein (fast) beliebiges Zeichen stehen kann. Die meisten RegExp-Implementierungen sehen standardmäßig Zeilenumbrüche nicht als beliebiges Zeichen an, jedoch kann dieses in einigen Programmen mittels des sogenannten "Single-Line"-Modifiers codice_15 (zum Beispiel in codice_16) erreicht werden.

In vielen neueren Implementierungen können innerhalb der eckigen Klammern nach POSIX auch Klassen angegeben werden, die selbst wiederum eckige Klammern enthalten. Sie lauten beispielsweise:

Quantoren (englisch "quantifier", auch "Quantifizierer" oder "Wiederholungsfaktoren") erlauben es, den vorherigen Ausdruck in verschiedener Vielfachheit in der Zeichenkette zuzulassen.
Die Quantoren beziehen sich dabei auf den vorhergehenden regulären Ausdruck, jedoch nicht zwangsläufig auf die durch ihn gefundene Übereinstimmung. So wird zwar zum Beispiel durch codice_17 ein „a“ oder auch „aaaa“ vertreten, jedoch entspricht codice_18 nicht nur sich wiederholenden "gleichen" Ziffern, sondern auch Folgen gemischter Ziffern, beispielsweise „072345“.

Weitere Beispiele sind:

Soll eine Zeichenkette "nur" aus dem gesuchten Muster bestehen (und es nicht nur enthalten), so muss in den meisten Implementierungen explizit definiert werden, dass das Muster vom Anfang (codice_21 oder codice_9) bis zum Ende der Zeichenkette (codice_23, codice_24 oder codice_25) reichen soll. Andernfalls erkennt zum Beispiel codice_20 auch bei der Zeichenkette „1234507“ die Teilzeichenkette „12345“. Aus dem gleichen Grund ergäbe beispielsweise codice_27 immer einen Treffer, da jede Zeichenfolge – selbst das leere Wort „“ – mindestens 0-mal das Zeichen „a“ enthält.

Quantoren sind standardmäßig „gierig“ (englisch "greedy") implementiert. Das heißt, ein regulärer Ausdruck wird zur größtmöglichen Übereinstimmung aufgelöst. Da dieses Verhalten jedoch nicht immer so gewollt ist, lassen sich bei vielen neueren Implementierungen Quantoren als „genügsam“ oder „zurückhaltend“ (englisch "non-greedy", "reluctant") deklarieren. Zum Beispiel wird in Perl oder tcl hierfür dem Quantor ein Fragezeichen codice_28 nachgestellt. Die Implementierung von genügsamen Quantoren ist vergleichsweise aufwendig und während des Suchvorgangs langsam (erfordert Backtracking), weshalb manche Implementierungen diese ausdrücklich vermeiden z. B. sed.


Eine Variante des oben beschriebenen gierigen Verhaltens ist das "possessive matching". Da hierbei jedoch das Backtracking verhindert wird, werden einmal übereinstimmende Zeichen nicht wieder freigegeben. Daher finden sich in der Literatur auch die synonymen Bezeichnungen "atomic grouping", "independent subexpression" oder "non-backtracking subpattern". Die Syntax für diese Konstrukte variiert bei den verschiedenen Programmiersprachen. Ursprünglich wurden solche Teilausdrücke (engl. "subpattern") in Perl durch codice_33 formuliert. Daneben existieren seit Perl 5.10 die äquivalenten, in Java bereits üblichen possessiven Quantoren codice_34, codice_35, codice_36 und codice_37.


Ausdrücke lassen sich mit runden Klammern codice_40 und codice_41 "zusammenfassen":
Etwa erlaubt codice_42 ein „abc“ oder ein „abcabc“ etc.

Einige Implementierungen speichern die gefundenen Übereinstimmungen von Gruppierungen ab und ermöglichen deren Wiederverwendung im regulären Ausdruck oder bei der Textersetzung. Diese werden "Rückwärtsreferenzen" (englisch "back references") genannt. Häufig wird dazu die Schreibweise codice_43 oder codice_44 verwendet, wobei "n" die Übereinstimmung der "n"-ten Gruppierung entspricht. Eine Sonderstellung stellt dabei "n"=0 dar, das meist für die Übereinstimmung des gesamten regulären Ausdrucks steht.


Interpreter von regulären Ausdrücken, die Rückwärtsreferenzen zulassen, entsprechen nicht mehr dem Typ 3 der Chomsky-Hierarchie. Mit dem Pumping-Lemma lässt sich zeigen, dass ein regulärer Ausdruck, der feststellt, ob in einer Zeichenkette vor und nach der codice_47 die gleiche Anzahl von codice_48 steht, keine reguläre Sprache ist.
Daneben gibt es auch noch Gruppierungen, die keine Rückwärtsreferenz erzeugen (englisch "non-capturing"). Die Syntax dafür lautet in den meisten Implementierungen codice_49…codice_41. Regexp-Dokumentationen weisen darauf hin, dass die Erzeugung von Rückwärtsreferenzen stets vermieden werden soll, wenn kein späterer Zugriff auf sie erfolge. Denn die Erzeugung der Referenzen kostet Ausführungszeit und belegt Platz zur Speicherung der gefundenen Übereinstimmung. Zudem lassen die Implementationen nur eine begrenzte Anzahl an Rückwärtsreferenzen zu (häufig nur maximal 9).

Mit dem regulären Ausdruck codice_51 können Folgen von durch Bindestriche getrennten Zahlenfolgen gefunden werden, ohne dabei die letzte durch einen Bindestrich getrennte Zahlenfolge als Rückreferenz zu erhalten.

Ein Datum im Format codice_52 soll in das Format codice_53 überführt werden.


Man kann alternative Ausdrücke mit dem codice_56-Symbol zulassen.


Um die oft auf Zeichenketten bezogenen Anwendungen auf dem Computer zu unterstützen, werden in der Regel zusätzlich zu den bereits genannten die folgenden Zeichen definiert:

Perl Version 5 führte zusätzlich zu den üblichen regulären Ausdrücken auch "look-ahead" und "look-behind assertions" (etwa „vorausschauende“ bzw. „nach hinten schauende“ Annahmen oder Behauptungen) ein, was unter dem Begriff "look-around assertions" zusammengefasst wird. Diese Konstrukte erweitern die regulären Ausdrücke um die Möglichkeit, kontextabhängige (engl.: "context sensitive") Bedingungen zu formulieren, ohne den Kontext selbst als passend zu finden. Das heißt, möchte man alle Zeichenfolgen „Sport“ finden, denen die Zeichenfolge „verein“ folgt, ohne dass jedoch die gefundene Zeichenfolge die Zeichenfolge „verein“ selbst enthält, wäre dies mit einer "look-ahead assertion" möglich: codice_59. Im Beispielsatz „Ein Sportler betreibt Sport im Sportverein.“ würde jener reguläre Ausdruck also zum letzten Vorkommen von „Sport“ passen, da nur diesem die Zeichenfolge „verein“ folgt; er würde jedoch nicht zur Teilzeichenkette „Sportverein“ passen.

Aufgrund der Eigenschaft, dass der angegebene Kontext (im Beispiel „verein“) zwar angegeben wird, jedoch kein expliziter Bestandteil der passenden Zeichenkette (hier „Sport“) ist, wird im Zusammenhang mit "assertions" meist das Attribut "zero-width" mitgenannt. Die vollständigen Bezeichnungen lauten somit – je nachdem, ob ein bestimmter Kontext gefordert (positiv) oder verboten (negativ) ist – "zero-width positive/negative look-ahead/behind assertions." Die Bezeichnungen der Richtungen rühren daher, dass Regexp-Parser eine Zeichenkette immer von links nach rechts abarbeiten.
Look-arounds werden nicht nur von Perl und PCRE, sondern unter anderem auch von Java, .NET und Python unterstützt. JavaScript interpretiert ab Version 1.5 positive und negative Look-Aheads.


Relativ wenig verbreitet sind "bedingte Ausdrücke." Diese sind unter anderem in Perl, PCRE und dem .NET-Framework einsetzbar. Python bietet für solche Ausdrücke im Zusammenhang mit "look-around assertions" nur eingeschränkte Funktionalität.
Beispiel

Reguläre Ausdrücke

Reguläre Ausdrücke und natürliche Sprachen

Reguläre Ausdrücke und Automatentheorie

Forschungsliteratur




</doc>
<doc id="4367" url="https://de.wikipedia.org/wiki?curid=4367" title="Rotes Meer">
Rotes Meer

Das Rote Meer ( "al-Bahr al-ahmar"; "Arabischer Golf"; "Yam Suf"; Tigrinya ቀይሕ ባሕሪ "QeyH baHri"; , "Erythrà Thálassa" (übersetzt Erythräisches Meer, in der römischen Antike unter diesem Namen bekannt)) ist ein schmales, 2240 km langes, im zentralen "Suakin-Trog" bis 3040 m tiefes Nebenmeer des Indischen Ozeans zwischen Nordost-Afrika und der Arabischen Halbinsel. Der Rauminhalt des Meeres beträgt etwa 200.000 km³, die Oberfläche etwa 438.000 km² bei einer durchschnittlichen Wassertiefe von 538 m.

Zum Roten Meer gehören:

Das Rote Meer markiert eine geologisch hochaktive Spreizungszone mit aufquellendem Magma (analog dem Mittelatlantischen Rücken) und bewirkt dadurch das Auseinanderdriften der Afrikanischen und der Arabischen Platte seit 130 Millionen Jahren. Die Ausbildung einer Senke verdeutlichte sich „erst“ vor 38 Millionen Jahren im Oligozän, setzt sich im Ostafrikanischen Graben fort und wird in vielen Millionen Jahren zu einem neuen Ozean führen. Zurzeit wird das Meer jedes Jahr im Norden um 0,8 cm, im Süden um 1,6 cm breiter. Nach mehrfacher Isolierung vom Indischen Ozean, vorübergehender Verbindung mit dem Mittelmeer und sogar Austrocknung erreichte das Rote Meer seinen jetzigen Zustand erst vor knapp 5000 Jahren.

Zum Indischen Ozean, genauer gesagt zum Golf von Aden, verengt sich das ansonsten bis 360 km breite Meer bei Bab al-Mandab ("arab.:" „Tor der Tränen“) auf nur noch 29 km und ist mit dem Arabischen Meer verbunden, das ein Teil des Indischen Ozeans ist. Zudem liegt an dieser Enge der Meeresboden nur 130 m unter dem Wasserspiegel. Diese Schwelle behindert den Wasseraustausch enorm, was zur Folge hat, dass das Rote Meer einen ungewöhnlich hohen Salzgehalt von 4,2 %, also 42 g/l, (normal ~ 3,5 %; in der Nordsee bei Sylt 3,0 % bis 3,2 %) und relativ wenige Nährstoffe sowie einen Tidenhub von lediglich einem halben bis einem Meter aufweist. Dadurch kommt es wiederum zu vermindertem Planktonwachstum, was Taucher wegen der oft ausgezeichneten Sichtweite zu schätzen wissen, auch wegen über 2000 km Korallenriffen. Neben Korallengärten und -wänden ziehen einige berühmte Wracks die Unterwasserfreunde an.
Von gelegentlich auftretenden Wasserzuflüssen durch intermittierende Zuflüsse wie Wadis abgesehen ist es das einzige Meer, in das keine perennierende Flüsse münden. Dies erklärt zudem die gute Sicht unter Wasser, da sich im Wasser wenige Schwebstoffe befinden. 
An der Schwelle bei Bab al-Mandab steigt 16 °C kühles Tiefenwasser aus dem Golf von Aden auf, was eine biologische Barriere für manche Arten darstellt. Dies ist eine Erklärung, warum es im ganzen Roten Meer keine Seeschlangen gibt.

Bereits in der Antike gab es verschiedene Kanalprojekte, welche das Mittelmeer mit dem Roten Meer verbanden. Der im 19. Jahrhundert fertiggestellte Sueskanal ist die aktuelle künstliche Verbindung zwischen dem Roten Meer und dem Mittelmeer. 

Der Red Sea Dam ist ein spekulativer Makro-Engineering-Vorschlag zur Absperrung und Absenkung des Roten Meers mittels eines Staudamms aus den 1960er Jahren, der 2007 von der Universität Utrecht aufgegriffen und ausgebaut wurde.

Die Namensgebung stammt wahrscheinlich aus dem althergebrachten System der Bezeichnung von Himmelsrichtungen durch Farben. Erstmals ist der Name zur Zeit der persischen Achaimeniden bezeugt: Für jenes iranische Volk lag dieses Meer im Süden, der durch die Farbe Rot symbolisiert wurde. Also bedeutete rotes Meer „Südsee“ (und analog das Schwarze Meer „Nordsee“).
Herodot nannte dieses Meer im Zusammenhang mit dem Kanalbau des Necho II. auch den „arabischen Meerbusen“: Für die spätere Kanalerweiterung, die in mehreren Windungen vom Isthmus bei Ismailia bis zum Ende des schmalen Meerstreifens bei Sues in den „arabischen Busen“ führte, gab er als Distanz 1.000 Stadien an und fügte hinzu, „dass der arabische Busen das ist, was man auch das rote Meer nennt“.

Strabon referiert in seiner Geographica die Ansichten des Agatharchides zu diesem Namen:

Gelegentlich wird zur Namenserklärung die Blaualge "Trichodesmium erythraeum" mit ihrer rötlich-orangen Chlorophyll-Variante herangezogen: Während periodisch auftretender Algenblüten kann sie ganze Teppiche an der Wasseroberfläche ausbilden. In Reisehandbüchern wird des Öfteren über den rötlichen Schimmer von Meer und Bergketten bei Sonnenaufgang erzählt.
Möglich auch, dass die Bezeichnung „Rotes Meer“ von einer Übersetzung aus dem Altgriechischen stammt. Die alten Griechen bezeichneten die Gebiete südlich von Oberägypten „Erythraia“ ("erythros" altgr. „rot“), wohl wegen der Rotfärbung der dortigen Erde und des dort häufig vorkommenden roten Sandsteins. Das Erythräa vorgelagerte Meer wurde demnach das „Erythräische Meer“ genannt, ein Name, der später auf das heutige „Rote Meer“ ausgedehnt wurde. Die Römer übersetzten die Bezeichnung „erythros“ wortwörtlich mit „rot“. Das heutige Land Eritrea wurde nach der italienischen Schreibung dieses Wortes benannt.

Eine weitere Erklärung geht auf das Volk der Himyaren zurück, das in der Antike im südwest-arabischen Raum herrschte. Der Name „Himjar“ ist auf das Wort „chumr“ zurückzuführen, das mit „rot“ oder „die Roten“ übersetzt werden kann. Dementsprechend wurde aus dem „Meer der Himjaren“ das „Meer der Roten“. Im Laufe der Zeit wurde daraus „Das Rote Meer“.

Im frühen 16. Jahrhundert war es üblich, das Rote Meer auf Seekarten rot einzufärben.

Vorherrschend sind Saumriffe nur wenige dutzend bis hunderte Meter vor der Küste oder in Inselnähe. An einigen wenigen flachen Stellen erheben sich Fleckriffe, wie im Nordosten von Hurghada, vor Safaga, südlich von Ras Ghalib (auch Marsa Ghalib, Port Ghalib) – wie das Elphinstone-Riff – und südlich von Marsa Alam. Ferner gibt es drei Riffgruppen weit vor der Küste, die von tiefem Wasser umgeben sind: nordöstlich von Al-Qusair (auch El Quseir) die Brother Islands (Al-Akhawein), südöstlich von Marsa Alam das Daedalus Riff (Abu el-Kizan) und an der Grenze zum Sudan, auf der Höhe von Al Shalaten, St. Johannes-Insel (Geziret Zabargad) und Rocky Island.

Auf Grund der topographischen Verbreitungsbarrieren und besonderen ökologischen Situation mit stark wechselnden Bedingungen entwickelte sich eine Spielwiese der Evolution und viele Arten kommen endemisch vor. Aber es finden sich auch fast alle Arten aus dem gesamten Indopazifik, wenngleich die Faunenzusammensetzung ungewöhnlich stark differiert. Man findet Schildkröten, seltener den Weißspitzen-Hochseehai, Weißspitzen-Riffhai, Grauen Riffhai und Manta. Die raren Walhaie kommen meist nur in relativ kleinen Exemplaren von max. 5–6 m vor, die kaum noch zählbare Population der Gabelschwanzseekühe scheint vor dem Zusammenbruch zu stehen. Nicht vergessen sollte man in der Aufzählung Napoleon-Lippfische, Büffelkopf-Papageifische (beide werden zuweilen verwechselt), Doktor-, Kaiser-, Rotfeuer-, Kugel- und Igelfische, Blaupunktstachelrochen, Kraken und viele mehr. Muränen, teils außerordentlich große Exemplare, sieht man vor allem Ende August bis Anfang September (vermutlich die Laichzeit) ungewöhnlicherweise auch tagsüber in freiem Wasser dahinschlängeln. Auffallend ist insgesamt die geringere Artenvielfalt im Vergleich zu tropischen Gebieten. Häufig trifft man bei Bootsfahrten, in seltenen Glücksfällen beim Schnorcheln und Tauchen auf den Großen Tümmler und den Spinner-Delfin.

Die Artenvielfalt der Vögel ist naturgemäß gering, von einigen Kulturfolgern abgesehen. Trotzdem finden sich einige ornithologisch interessante Vertreter. So lassen sich Palm- ("Streptopelia senegalensis", engl. Laughing Dove) und Türkentauben ("Streptopelia decaocto", engl. Collared Dove), die Große Raubseeschwalbe ("Sterna caspia", engl. Caspian Tern) und die Rußseeschwalbe ("Sterna fuscata", engl. Sooty Tern) sehen. Der Küstenreiher ("Egretta gularis", engl. Western Reef Heron, bis 55 cm) präsentiert sich in einer schwarzen, einer weißen und einer Mischversion, ferner sind Strandläufer (engl. sandpiper) und Sperber ("Accipiter nisus", engl. Sparrowhawk) zu beobachten. Vor allem im nördlichen Bereich des Roten Meeres können die ebenfalls raren Eisvögel ("Alcedinidae", engl. kingfisher) an der Meeresküste beim Sturzfischen gesichtet werden, während der Afrikanische Schwarzstorch ("Ciconia nigra", engl. Black Stork) sich eher im südlichen Teil sehen lässt. Eine Besonderheit ist die endemische Weißaugenmöwe. Mit Glück sind Fischadler ("Pandion haliaetus", bis 50 cm; rüttelt manchmal wie ein Bussard über dem Riff) mit auffallend weißer Unterseite bei der Jagd über dem Riff zu beobachten.
Wer Anfang bis Mitte Oktober in dieser Gegend weilt, kann den Flug von unzähligen Zugvögeln nach Süden beobachten – ein atemberaubendes Schauspiel. Über Nacht sind dann oft sämtliche Bäume der Umgebung besetzt. Retour geht es wieder Mitte bis Ende März.

Vor Hurghada haben zum einen der Massentourismus, der sich rasant nach Süden ausbreitet, zum anderen das Einleiten ungeklärter Abwässer, wildes Ankern und die Korallenbleiche viele Korallen irreversibel stark beschädigt oder ganz vernichtet. Es wird davon ausgegangen, dass die Zerstörung selbst in den südlichsten Teilen, an der Grenze zum Sudan, rasch voranschreiten wird. Massenhafte Tauchsafaris haben dabei einen erheblichen Anteil. Das illegale Fischen an geschützten Korallenriffen ist üblich, selbst Fleisch von Meereskühen und Haifischen wird gelegentlich in Hurghada angeboten. So hat es noch vor wenigen Jahren am Elphinstone Dutzende von Weißspitzen-Hochseehaien gegeben, während hier jetzt höchstens zwei oder drei zu sehen sind, an anderen Stellen gar keine mehr. Die Population der Gabelschwanzseekühe scheint vor dem Zusammenbruch zu stehen.

Die HEPCA (Hurghada Environmental Protection and Conservation Association) ist eine 1992 gegründete Nichtregierungsorganisation, die sich des Schutzes des ägyptischen Meeresteils mit sämtlichen Tieren über und unter Wasser angenommen hat. Dazu gehören u. a. die Installation von über 1000 Mooring-Bojen, um Schäden durch wildes Ankern zu vermeiden.

Am Dolphin House hat die Beschränkung der Boote und die Einrichtung von Schutzzonen einiges bewirkt.

Einige Tauchunternehmen vor Ort fordern, die Anzahl der Tauchboote am selben Ankerplatz zu begrenzen, um die Störung der angestammten Tiere durch Taucher zu reduzieren und zu vermeiden, dass durch mehrere miteinander vertäute Schiffe bei Seegang Korallenblöcke herausgerissen werden.

Am 19. Juni 2010 wurde bekannt, dass durch ein Leck an einer Ölplattform nahe Hurghada eine bisher unbestimmte Menge Öl ausgelaufen ist (offizielle Stellen sprechen von 20–40 Barrel, Umweltschützer gehen von einer weit höheren Verschmutzung aus), das nach Auskunft des verantwortlichen Ölkonzerns das Küstengebiet auf einer Länge von 160 km verschmutzte. Ein nach offiziellen Angaben ca. 20 Meilen langer Ölteppich trieb vor Hurghadas Küste. Am 25. Juni 2010 verlautbarte das ägyptische Erdölministerium, dass der Ölteppich vermutlich nicht von einem Leck an einer Bohrinsel verursacht wurde, sondern von einem Öltanker, der bei der Reinigung auf hoher See Ölrückstände verlor.





</doc>
<doc id="4370" url="https://de.wikipedia.org/wiki?curid=4370" title="Rosengewächse">
Rosengewächse

Die Rosengewächse (Rosaceae) sind eine Pflanzenfamilie der Kerneudikotyledonen. Die Familie ist weltweit verbreitet, mit Schwerpunkt auf der Nordhalbkugel. Die Vertreter sind krautige Pflanzen, Sträucher oder Bäume und haben meist auffällige, zwittrige Blüten mit doppelter Blütenhülle und einem deutlich ausgeprägten Blütenbecher. Zur Familie gehören neben den namensgebenden, als Zierpflanzen genutzten Rosen ("Rosa") auch viele bekannte Obstarten wie Apfel, Birne, Brombeeren, Erdbeeren und Himbeere sowie das Steinobst mit Kirschen, Zwetschge, Pflaume, Mandel und anderen.

Die Vertreter der Rosengewächse sind Bäume, Sträucher oder krautige Pflanzen, wobei die strauchige Wuchsform als die ursprüngliche innerhalb der Familie angesehen wird. Große Bäume mit Wuchshöhen von 25 bis 30 Meter sind selten und treten nur in wenigen Gattungen (wie "Eriobotrya, Sorbus, Prunus") auf. Holzige Pflanzen können immergrün oder laubwerfend sein. Manche Sippen besitzen Sprossdornen. Stacheln sind in manchen Gattungen häufig, besonders bei "Rosa" und "Rubus". Krautige Vertreter sind meist ausdauernd und bilden unterirdische, vertikale Rhizome oder horizontale Wurzelstöcke als Überdauerungsorgane.

Die Laubblätter sind meist wechselständig. Bei der Blattform gilt das einfache Blatt als die in der Familie ursprüngliche Form, zusammengesetzte Blätter gelten als abgeleitet. Zusammengesetzte Blätter sind meist paarig oder unpaarig gefiederte Blätter und kommen in rund 30 Gattungen vor. Gegenständige Blätter kommen nur in den Gattungen "Coleogyne, Rhodotypos" und "Lyonothamnus" vor. Das Vorhandensein von Nebenblättern gilt als ursprüngliches Merkmal. Bei den Spiraeoideae kam es in mehreren Entwicklungslinien unabhängig voneinander zum Verlust der Nebenblätter. Die Nebenblätter sind häufig am Grund mit dem Blattstiel verwachsen. Am apikalen Ende des Blattstiels sitzen meist zwei Drüsen. Der Blattrand ist häufig gesägt, selten ganzrandig. Bei einigen Gattungen wurden Wasserspalten beziehungsweise Guttation beobachtet. Im Holz besteht das Grundgewebe vorwiegend aus Fasertracheiden, seltener auch aus Libriformfasern.

Die Blüten stehen vorwiegend in traubigen oder rispigen Blütenständen, Ähren, Köpfchen, einzeln stehende Blüten sind selten.

Die Blüten sind radiärsymmetrisch und meist zwittrig, nur selten durch Reduktion eingeschlechtlich. Ein Blütenbecher (Hypanthium) ist stets vorhanden und unterschiedlich stark ausgeprägt. In der Regel ist eine doppelte Blütenhülle vorhanden, Kelch und Krone sind meist fünfzählig. Die Kelchblätter sitzen am Rand des Blütenbechers und sind eher klein. Manchmal wird auch ein Außenkelch gebildet. Die Kronblätter sind meist auffällig, die vorwiegende Farbe ist weiß, in einigen Gruppen auch gelb. Das Fehlen der Kronblätter wie beispielsweise bei der Gattung "Sanguisorba" ist ein abgeleitetes Merkmal und tritt meist bei windbestäubten Gruppen auf.

Bei den Staubblättern gilt eine Zahl von über 10 bis viele als ursprünglich (sekundäre Polyandrie), sekundär gibt es auch weniger. Häufig sind es rund 20. Sie sind stets frei und nicht miteinander verwachsen. Von den Fruchtblättern sind sie meist durch einen Nektar absondernden Diskus getrennt. Die Pollenkörner sind bei der Freisetzung zweizellig und treten einzeln als Monaden aus. Sie sind eher kugelig, im Allgemeinen tricolporat (weisen drei Keimfurchen/-poren auf) und mit langen Furchen.

Bei den Fruchtblättern gilt die Zahl von eins bis fünf als ursprünglich, es können auch viele sein. Die Fruchtblätter sind frei (apokarp) oder unecht verwachsen. Sie sitzen dem Blütenboden auf (etwa Erdbeeren) oder sie sind vom vertieften Blütenbecher umgeben (etwa Rosen) oder mit diesem verwachsen (etwa Äpfel). Es gibt alle Übergänge von oberständigem zu unterständigem Fruchtknoten. Pro Fruchtblatt gibt es meist zwei anatrope Samenanlagen, die ein oder zwei Integumente besitzen, seltener - bei ursprünglichen Sippen, auch mehrere Samenanlagen. Der Embryosack entwickelt sich nach dem Polygonum-Typ, der Embryo nach dem Asterad-Typ. Die Griffel sind mit Ausnahme einiger Vertreter der Tribus Pyreae frei.

Die für die meisten Arten zutreffende Blütenformel lautet somit: formula_1

Die Früchte der Rosengewächse sind sehr vielgestaltig. In der Vergangenheit wurden die Früchte und die mit ihnen zusammenhängende Blütenmorphologie als Hauptmerkmal zur systematischen Gliederung der Familie verwendet, während neuere molekulargenetischen Untersuchungen die Gruppenbildung anhand der genetischen Übereinstimmungen zwischen den Arten vornehmen.

In der Bestimmungsliteratur finden sich dementsprechend die vier Unterfamilien Spiraeoideae, Rosoideae, Maloideae und Prunoideae, während neue Fachliteraturen zur Genetik oder zum Sekundärstoffwechsel der Rosaceae parallel zu dieser klassischen Systematik die aktualisierten Zuordnungen verwenden.

Nach der klassischen Sichtweise können die Rosaceae anhand ihrer Früchte in die vier folgenden Unterfamilien bzw. morphologischen Gruppen eingeteilt werden:

Die Samen besitzt häufig eine feste, teilweise dickwandige Samenschale. Sie wird aus den sog. Integumenten der Samenanlage gebildet. Die Samenschale schützt den Embryo, der hauptsächlich aus den beiden flachen bis dicken Keimblättern besteht. In den reifen Samen der Rosaceae ist nur manchmal ein zusätzliches Nährgewebe (Endosperm) erhalten bzw. nur mehr eine dünne Schicht.

Die Chromosomengrundzahlen der Rosaceae betragen x = 7, 8, 9, 15, und 17. Als ursprünglich werden 7 oder 9 angesehen. Die Grundzahl 8 hat sich bei den Rosoideae einmal und bei den Spiraeoideae mehrfach entwickelt, die Grundzahl 17 einmal bei den Pyreae.

Die Rosaceae sind reich an Gerbstoffen, die diffus im Gewebe verteilt sind oder in Gerbstoff-Idioblasten vorkommen. Es sind überwiegend kondensierte Gerbstoffe (Proanthocyanidine), in der Unterfamilie Rosoideae kommen auch in größerem Ausmaß Gallo- und Ellagitannine vor. Die monomeren Vorstufen der Gerbstoffe wie Catechine und Flavonolglykoside des Kaempferols und Quercetins kommen ebenfalls vor. Ellagsäure kommt nur bei den Rosoideae vor.

In den Cuticularwachsen sind pentazyklische Triterpene wie Oleanolsäure und Ursolsäure weit verbreitet. In der Rinde finden sich häufig Triterpenalkohole (wie Lupeol, Betulin). Als Pseudosaponine werden Triterpensäuren, die über die Carboxygruppe mit Zuckern verestert sind, bezeichnet. Ein Beispiel ist Tormentol. Echte Saponine kommen ebenfalls vor. Die Samen sind meist stärkefrei und speichern dafür Proteine und fettes Öl.

Weit verbreitet innerhalb der Familie sind cyanogene Glykoside wie Amygdalin oder Prunasin.

Sorbitol wird in den Blättern und Früchten vieler Vertreter als Kohlenhydrat-Reservestoff gespeichert, fehlt allerdings bei vielen Vertretern der Rosoideae. Sorbitol ist auch vielfach das im Phloem transportierte Kohlenhydrat.

Bei den Kernobstgewächsen sind die Wände der Samenschalen-Epidermis häufig stark verschleimt, besonders bei der Quitte ("Cydonia oblonga"). In den Früchten sind Fruchtsäuren in teils hohen Konzentrationen vertreten, besonders Äpfel- und Zitronensäure, teils auch Bernsteinsäure, sowie auch Ascorbinsäure (Vitamin C).

Der Großteil der Rosengewächse besitzt Scheiben- und Schalenblumen, bei denen die einzelne Blüte relativ groß ist und als Bestäubungseinheit fungiert. Seltener sind Pinselblumen vertreten, hier sind die Einzelblüten relativ klein und stehen in köpfchen- oder ährenartigen Blütenständen zusammen. Dieser Blumentyp kommt vor allem bei den Sanguisorbeae vor. Als Bestäuber fungieren vor allem Fliegen und kurzzungige Bienen. Weniger Bedeutung als Bestäuber haben langzungige Bienen, Käfer und Schmetterlinge. Einige Gattungen der Sanguisorbeae sind windbestäubt.

Fremdbestäubung wird in vielen Arten durch eine mehr oder weniger ausgeprägte Vorweiblichkeit (Protogynie) erreicht, die meisten sexuell reproduzierenden Arten sind zudem selbstinkompatibel.

In rund einem Drittel der Gattungen gibt es Polyploidie. Häufig kommt Polyploidie in den artenreichen Gattungen vor. Beispiele sind "Alchemilla" (1000 Arten, bis 28-ploid), "Potentilla" (bis 16-ploid), "Rosa" und "Rubus".

In einigen Gattungen hat sich Apomixis entwickelt, sie ist meist mit Polyploidie gekoppelt. Die häufigste Form der Apomixis ist die Aposporie, bei der sich der Embryosack aus einer unreduzierten vegetativen Zelle entwickelt. Selten tritt auch Diplosporie auf, bei der sich der Embryosack aus einer unreduzierten generativen Zelle, die von der Embryosackmutterzelle abstammt, entwickelt. Für den Samenansatz sind dennoch meist eine Bestäubung und eine Befruchtung des Endosperms nötig. Von daher ist es im Prinzip auch möglich, dass die unreduzierte Eizelle befruchtet wird und so eine Erhöhung der Chromosomenzahl stattfindet.

Ein großer Teil der polyploiden Rosengewächse ist im Gegensatz zu den übrigen Vertretern der Familie selbstkompatibel, eine Pflanze kann sich also selbst bestäuben.

Hybridisierung tritt bei den Rosengewächsen häufig auf, bei den Pyreae sogar über Gattungsgrenzen hinweg. Die mit der Hybridbildung häufig einhergehende Apomixis führte dazu, dass sich in manchen Gattungen diploid-triploid-tetraploide Netzwerke von Arten bildeten. Hybride wurden durch Polyploidisierung fruchtbar, bzw. triploide Sippen können sich apomiktisch fortpflanzen.

Es gibt bei den Rosengewächsen vier Hauptarten der Ausbreitung der Diasporen, die in engem Zusammenhang mit den Fruchttypen stehen: Fleischige Früchte werden von Tieren gefressen, die Samen wieder ausgeschieden (Endozoochorie). Bei Bäumen sind dies meist Vögel, Fledermäuse oder andere Säugetiere, bei Erdbeeren dürften es Schnecken sein, bei "Aremonia" wird aufgrund des Vorhandenseins von Elaiosomen Ameisenausbreitung (Myrmekochorie) vermutet. Epizoochorie kommt bei Arten vor, die an Hypanthium oder Griffel Haken ausgebildet haben. Es gibt auch Samenausschleuderer und selten Anemochorie (etwa "Dryas" und "Geum").

Vesikulär-arbuskuläre Mykorrhiza kommt bei den Rosengewächse etwa gleich häufig vor wie bei allen Rosopsida, während Ektomykorrhiza nur bei wenigen verholzten Arten der Dryadoideae, Pyreae, bei "Prunus" und "Rosa" nachgewiesen wurde. Die Dryadoideae gehen mit den stickstofffixierenden Bakterien der Gattung "Frankia" eine Symbiose ein.

Die Vertreter der Rosaceae sind weltweit verbreitet. Von den Gattungen sind lediglich drei kosmopolitisch, nämlich "Prunus, Alchemilla" und "Rubus", wobei allerdings nur bei "Prunus" gesichert ist, dass sie natürlicherweise, ohne menschlichen Einfluss auf allen Kontinenten vorkommt. 16 Gattungen sind über die ganze temperate Zone der nördlichen Hemisphäre verbreitet, wovon die meisten auch in die mediterranen oder sogar tropischen Klimate, hier meist in der montanen Höhenstufe weiter südlich reichen. "Geum" und "Agrimonia" reichen auch auf die Südhalbkugel. Lediglich zwei Gattungen kommen nur auf der Südhalbkugel vor, "Acaena" und "Oncostylis". Die meisten endemischen Gattungen gibt es mit 20 in Asien und 17 in Nordamerika, nur wenige in Südamerika (3), Afrika (5) und Europa (1).

Rosengewächse wachsen an einer Vielzahl von Standorten, von Halbwüsten bis zu Tiefland-Regenwäldern und offener, alpiner Vegetation. Eine große Anzahl von Arten ist auf bewaldeten Berghängen mittlerer Seehöhe und gemäßigter Breite zu finden.

Die Familie beherbergt viele Zier- und Nutzpflanzen. Als Obst genutzte Arten sind besonders: Quitte ("Cydonia oblonga"), Japanische Wollmispel ("Eriobotrya japonica"), Garten-Erdbeere ("Fragaria" ×"ananassa"), Wald-Erdbeere ("Fragaria vesca"), Kultur-Apfel ("Malus domestica"), Mispel ("Mespilus germanicus"), Aprikose bzw. Marille ("Prunus armeniaca"), Süß-Kirsche ("Prunus avium"), Sauer-Kirsche ("Prunus cerasus"), Zwetschge, Pflaume und Mirabelle (Unterarten von "Prunus domestica"), Schlehdorn ("Prunus spinosa"), Birne ("Pyrus communis"), Moltebeere ("Rubus chamaemorus"), Brombeeren ("Rubus fruticosus" agg.), Himbeere ("Rubus idaeus") und Süße Eberesche ("Sorbus aucuparia" var. "edulis").
Etliche Arten werden auch zu Heilzwecken verwendet. Hier herrschen Gerbstoffdrogen vor: Rhizom von "Potentilla erecta", Blätter von Brombeere, Frauenmantel und Odermennig.

Die Rosaceae sind innerhalb der Ordnung der Rosenartigen (Rosales) die Schwestergruppe aller anderen Familien der Rosales.

In die Familie Rosaceae werden rund 90 Gattungen mit insgesamt etwa 3000 Arten gestellt. In der Vergangenheit dienten vor allem die Früchte als Hauptmerkmal zur systematischen Gliederung der Familie, während man heute versucht, auch molekulargenetische Übereinstimmungen zwischen den Gattungen in der Systematik zu berücksichtigen. Als Folge der Neuerung wurden die alten Unterfamilien-Bezeichnungen "Prunoideae" und "Maloideae" in der entsprechenden Fachliteratur teilweise ausrangiert; die zugeordneten Pflanzen wurden in die Triben Pyrinae (Kernobstgewächse, Spiraeoideae) und Prunus (Steinobstgewächse, Spiraeoideae) verschoben. Damit bilden die Stein- und Kernobstgewächse nach der neueren Sichtweise keine eigenen Unterfamilien mehr.

Auf Laien kann diese Gleichzeitigkeit zwei verschiedener Systematiken verwirrend wirken; sie verfolgen jedoch eine jeweils eigene Zielsetzung und können daher nicht als richtig oder falsch bewertet werden, sondern nur nach ihrem praktischen Nutzen im Hinblick auf eine Aufgabenstellung: Die morphologische Systematik dient vorrangig der Orientierung über die Anatomie der Pflanzen und der Pflanzenbestimmung, während man sich von der molekularen Sichtweise validere Erkenntnisse über die phylogenetischen Verwandtschaftsverhältnisse der Rosaceae erhofft.

Die hier aufgeführten Gruppen folgen den molekulargenetischen Verwandtschaftsverhältnissen und sind jeweils natürliche Verwandtschaftsgruppen (monophyletisch). Trotzdem sind die genaueren Verwandtschaftsbeziehungen zwischen den Unterfamilien und besonders zwischen den Triben der Spiraeoideae noch nicht ausreichend bekannt.

Die traditionelle Untergliederung in die vier Unterfamilien Prunoideae, Pyrinae, Spiraeoideae und Rosoideae geht auf Wilhelm Olbers Focke 1888 zurück. Die Gliederung in Triben stammt in weiten Teilen von Maximowicz für Spiraeoideae (1879), Focke für Rosoideae (1888) und Koehne für Maloideae (heute:Pyrinae)(1890), die Prunoideae wurden nie in Triben unterteilt. Eine Gliederung der Familie von Hutchinson (1964) in 20 Triben ohne Unterfamilien konnte sich nicht durchsetzen. Die Revision der Familie 2007 mit der Eingliederung der bisherigen Unterfamilien Prunoideae und Pyrinae in die Spiraeoideae, sowie der Aufstellung einer neuen Unterfamilie Dryadoideae hatte die Bildung monophyletischer Taxa zum Ziel.

Die Rosaceae sind seit dem Eozän durch zahlreiche Fossilien aus Nordamerika und Europa gut belegt. Ab dem Neogen gibt es auch Funde aus Asien, der Arktis, Nordafrika und einigen Gondwana-Gebieten. Gut untersuchte Funde stammen aus den Okanagan Highlands (Rocky Mountains) aus dem frühen bis mittleren Eozän. Hier gibt es rezente Gattungen, die bereits im Eozän voll entwickelt sind, Arten, die rezenten Gattungen ähneln und ausgestorbene Gattungen, die in ihren Merkmalen höheren Taxa ähneln. Beispiele für letztere sind "Paleorosa" und "Stonebergia". Auch die Gattung "Prunus" ist reichlich vertreten mit Fossilien, die heutigen Vertretern bereits sehr ähneln.

Von "Paleorosa" ist der älteste in situ Rosaceen-Pollen bekannt. Die morphologischen Merkmale der Gattung stehen zwischen den klassischen Unterfamilien Pyrinae und Spiraeoideae. Die Früchte von "Quintacava" ähneln den Kernobstgewächsen. Heute weitverbreitete Gattungen, die ebenfalls seit dem Eozän belegt sind, sind beispielsweise "Rubus", "Crataegus" und "Sorbus".

Im Neogen sind die Rosengewächse in Europa ein wichtiges Florenelement. Weit verbreitete Gattungen sind hier "Rosa", "Crataegus", "Rubus", "Mespilus", "Sorbus" und "Prunus".




</doc>
<doc id="4372" url="https://de.wikipedia.org/wiki?curid=4372" title="Bayreuther Festspiele">
Bayreuther Festspiele

Die Bayreuther Festspiele oder Richard-Wagner-Festspiele sind ein Musiktheaterfestival, das den zehn letzten Opern Richard Wagners (1813–1883) gewidmet ist. Das Festival findet seit 1876 mit Unterbrechungen, seit 1951 alljährlich im eigens dafür vom Komponisten gemeinsam mit dem Architekten Otto Brückwald (1841–1917) geschaffenen Festspielhaus auf dem Grünen Hügel in Bayreuth statt. Die Festspiele dauern in der Regel vom 25. Juli bis 28. August.

Leiterin ist Katharina Wagner, als Musikdirektor fungiert Christian Thielemann.


Richard Wagner wünschte sich ein Theater, an dem er als Komponist, Textdichter, Dramaturg und Intendant seine Vorstellungen vom Gesamtkunstwerk verwirklichen konnte. Dieses sollte sich abseits der Metropolen – ohne Ablenkung und ohne die Kompromisse eines Repertoirebetriebs – voll und ganz der Darbietung seiner Werke widmen können. 1871 entschied er sich für Bayreuth als Standort. Zur Finanzierung der von ihm auf 300.000 Taler geschätzten Kosten für den Bau eines Festspielhauses und die erste Saison gründete er einen "Patronatsverein", der unter der Leitung von Marie Gräfin von Schleinitz, einer Freundin von Wagners Frau Cosima Wagner, Anteilsscheine für jeweils 300 Taler ausgab. Der Käufer erhielt einen Sitzplatz für drei zyklische Aufführungen des "Rings". Dies gilt als Erfindung des Fundraisings. Weitere Vereine gründeten sich in verschiedenen deutschen Städten. Jedoch konnten bis Frühjahr 1873 nur 340 Patronatsscheine abgegeben werden. Das Richtfest des Festspielhauses fand im Oktober 1873 statt, noch bevor die Finanzierung gesichert war. Anfang 1874 drohte die Einstellung des Baus wegen fehlender Finanzmittel, woraufhin König Ludwig II. von Bayern aus freundschaftlicher Verbundenheit mit Wagner ein Darlehen über 100.000 Taler aus seinem Privatvermögen zur Verfügung stellte.

Die Auswertung der Archive ergab, dass, wie auch in anderen Opernhäusern Juden im laufenden Theaterbetrieb diskriminiert wurden. „Aber der erbittert judenfeindliche ideologische Rahmen, den Wagner selbst, seine Frau Cosima oder ihr Schwiegersohn Houston Stewart Chamberlain lieferten, den gab es woanders nicht. Dieses klare jüdische Feindbild gab es nur in Bayreuth,“ fasste Hannes Heer 2012 seine Forschung zusammen. Dennoch traten viele bedeutende jüdische Künstler regelmäßig bei den Bayreuther Festspielen auf, etwa der Münchner Hofkapellmeister Hermann Levi als Dirigent der "Parsifal"-Uraufführung 1882, auf dem sowohl Wagner wie König Ludwig II. gegen Anfeindungen von anderer Seite bestanden, oder der österreichisch-amerikanische Bassbariton Friedrich Schorr. Schorr war von 1925 bis 1931 als Wotan, Hans Sachs und Holländer engagiert. Eine enge künstlerische Zusammenarbeit verband Richard Wagner zudem mit dem deutsch-jüdischen Opernimpresario Angelo Neumann, der Wagners "Ring"-Inszenierung von 1876 in den Originalkulissen der Bayreuther Festspiele auf Theatertourneen durch ganz Europa bekannt machte. Die Inszenierungen hielten sich bis zum Zweiten Weltkrieg weitgehend an die Regieanweisungen im Originaltext und prägten eine Aufführungspraxis, die auch auf andere Opernhäuser stilbildend wirkte.

Die ersten Festspiele begannen am 13. August 1876; sie boten die Uraufführung des kompletten "Rings des Nibelungen" an drei Tagen und einem Vorabend. Zu den Gästen gehörten Franz Liszt, Anton Bruckner, Karl Klindworth, Camille Saint-Saëns, Peter Tschaikowski, Edvard Grieg, Lew Tolstoi, Paul Lindau, Friedrich Nietzsche und Gottfried Semper, ferner Kaiser Wilhelm I., Kaiser Pedro II. von Brasilien und König Karl von Württemberg. König Ludwig II. hatte vom 6. bis zum 9. August die Generalproben besucht und kam zum dritten und letzten Aufführungszyklus nochmals nach Bayreuth, wobei er sich allen öffentlichen Huldigungen entzog.

Der künstlerische Erfolg der Aufführungen wurde durch einige bühnentechnische Pannen beeinträchtigt. Wegen des finanziellen Misserfolgs – es verblieben Schulden in Höhe von 148.000 Mark – konnten die nächsten Festspiele erst 1882 (mit der Uraufführung des "Parsifal") ausgerichtet werden. Wie er in einem Brief an Ludwig II. schrieb, beabsichtigte Wagner, im Festspielhaus auch seine anderen Werke nach und nach „in der Weise aufzuführen, dass diese Aufführungen als Muster der Korrektheit meiner nächsten Nachwelt überliefert werden können“. Wenige Monate darauf starb der Komponist. Bis kurz vor seinem Tod trug er sich mit dem Gedanken, seinen "Tannhäuser" sowie den "Fliegenden Holländer" umzuarbeiten, um sie „bayreuthwürdig“ zu machen. Eine Aufführung seiner Frühwerke ("Das Liebesverbot", "Die Feen", "Rienzi") untersagte er zwar nicht, bekundete aber auch kein Interesse daran. Bis heute ist es in Bayreuth üblich, nur die zehn Hauptwerke vom "Fliegenden Holländer" bis zum "Parsifal" zu spielen.

Wagner hat selbst keinen Nachfolger für die Leitung der Festspiele bestimmt. Nach seinem überraschenden Tod wurden sie von seiner Witwe Cosima fortgeführt und fanden zunächst unregelmäßig statt. Immer wieder musste aus wirtschaftlichen Gründen – der Festspielbetrieb war ein reines Privatunternehmen der Familie Wagner – pausiert werden, um finanzielle Engpässe zu überwinden. Auch war die Publikumsnachfrage nicht immer ausreichend, teilweise wurde vor nur mäßig gefülltem Haus gespielt. Nach Wagners Tod 1883 hatte Adolf von Groß, ein Freund der Familie Wagner, die Finanzverwaltung übernommen und eine „strikte Ausgabendisziplin“ eingeführt. So konnten die Festspiele allmählich finanziell gesichert werden. Die Kredite aus dem Privatvermögen des bayerischen Königshauses wurden von der Familie Wagner noch bis 1906 zurückgezahlt.

Die Festspiele selbst entwickelten sich im Wechsel zwischen künstlerischer Stagnation und Innovation. Cosima Wagner, die ab 1886 selbst Regie führte, hatte eine strenge Vorstellung von Werktreue. 1908 übergab sie auf dringenden Rat ihrer Ärzte die Leitung der Festspiele ihrem Sohn Siegfried Wagner, der schrittweise eine Modernisierung der Aufführungen ermöglichte. Der Erste Weltkrieg erzwang 1914 einen Abbruch der laufenden Saison; die Rückerstattung gelöster Karten verursachte ein hohes Defizit, so dass erst 1924 wieder Festspiele durchgeführt werden konnten. 1921 nahm eine neue "Deutsche Festspiel-Stiftung" mehr als fünf Millionen Mark aus dem Verkauf von Patronatsscheinen ein. Die Inflation der Jahre 1921/22 entwertete dieses Vermögen jedoch, so dass erst nach zehnjähriger Pause, am 22. Juli 1924, die Festspiele unter Leitung von Siegfried Wagner wieder eröffnet werden konnten. Die "Meistersinger"-Premiere geriet zu einer unverhohlen nationalistischen Veranstaltung; unter den Gästen waren Erich Ludendorff und Heinrich Claß. Der Schlussapplaus nach dem III. Akt mündete in das vom Publikum stehend gesungene Deutschlandlied. Die Festspielleitung sah sich dadurch zu einem Aufruf genötigt, dass solche Bekundungen zu unterbleiben hätten.

In seinem Testament von 1929 legte Siegfried Wagner fest, dass die Festspiele dauerhaft in der Verantwortung der Familie Wagner liegen sollen und dort nur die Werke seines Vaters in Bayreuth aufgeführt werden dürfen: „Das Festspielhaus darf nicht veräußert werden. Es soll stets den Zwecken, für die es sein Erbauer bestimmt hat, dienstbar gemacht werden, einzig also der festlichen Aufführung der Werke Richard Wagners.“ Würden diese Auflagen nicht erfüllt, so sollte das Festspielhaus an die Stadt Bayreuth fallen, die ihrerseits an die letztgenannte Auflage gebunden wäre. Ob die Verfügung bezüglich des Ausschlusses anderer Werke noch bindend ist, wurde wiederholt – auch von Familienmitgliedern – diskutiert.

Problematisch waren die Festspiele zu Anfang der 1930er Jahre: 1930 starb Siegfried Wagner erst 61-jährig an einem während der Probenzeit erlittenen Herzinfarkt. Die Festspiele wurden nun von seiner Witwe Winifred Wagner übernommen. Unterdessen kam es zwischen dem neu verpflichteten Dirigenten Arturo Toscanini und den beiden anderen Dirigenten der Jahre 1930 und 1931, Karl Muck und Wilhelm Furtwängler, immer wieder zu Spannungen und Eifersüchteleien. Toscanini widerrief kurz vor Beginn der Proben für die Festspiele des Jahres 1933 seine Zusage, da nach der Machtübernahme der Nationalsozialisten in Deutschland eine ausländer- und vor allem judenfeindliche Stimmung herrschte.

Die Nähe Winifred Wagners zu Reichskanzler Adolf Hitler stellte sicher, dass die Festspiele ab 1933 staatlich finanziert und aller Sorgen enthoben waren. Sie trug aber auch wesentlich dazu bei, dass Wagner (laut dem Literaturwissenschaftler Hans Mayer) im Jahr 1945 „an der Kulturbörse unter Null gehandelt“ wurde. Thomas Mann bezeichnete Bayreuth als Hitlers Hoftheater. 

Hitler hatte Bayreuth zuletzt 1940 besucht. Ab diesem Zeitpunkt wurden auf Anordnung Hitlers sogenannte „Kriegsfestspiele“ durchgeführt. Die NS-Organisation "Kraft durch Freude" mit ihrer Abteilung „Urlaub und Reisen“ übernahm den Kartenverkauf. Leiter dieser Abteilung war Bodo Lafferentz, der 1943 durch seine Heirat mit Verena Wagner Winifreds Schwiegersohn wurde. Lafferentz übernahm die Zuteilung der Karten, die vor allem verwundete Soldaten mit ihrem Pflegepersonal sowie Rüstungsarbeiter erhielten. Ab 1941 wurden die Festspiele immer stärker durch den Krieg beeinflusst. Da in der ersten Festspielwoche 1941 bereits ab etwa 21 Uhr totale Verdunkelung angeordnet war, begannen die Aufführungen schon kurz nach Mittag. 1944 standen nur noch die "Meistersinger von Nürnberg" auf dem Programm. Die letzte der zwölf Aufführungen des Jahres fand am 9. August statt. Es war die vorletzte Opernaufführung überhaupt im Dritten Reich, die letzte war die öffentliche Generalprobe der "Liebe der Danae" von Richard Strauss im Salzburger Festspielhaus am 16. August 1944.

Im Rahmen der Entnazifizierung konzentrierte sich das Verfahren vor der Spruchkammer Bayreuth ausschließlich auf die Person Winifred Wagners, anstatt die Verstrickungen des gesamten Festspielbetriebs zu untersuchen. Winifred wurde in der Berufungsinstanz als „Mitläuferin“ eingestuft, und nachdem sie rechtsverbindlich zugunsten ihrer Söhne Wieland und Wolfgang Wagner auf die Leitung der Festspiele verzichtet hatte, nur mit geringen Auflagen belegt, die für sie keine größeren und für die Neugründung der Festspiele durch ihre beiden Söhne Wieland und Wolfgang keinerlei Einschränkungen darstellten. So war der Weg frei für die Wiederaufnahme der Festspiele.

1949 wurde die Gesellschaft der Freunde von Bayreuth gegründet, die sich zum Ziel setzte, Geldspenden zur Durchführung der Festspiele einzuwerben. Bereits an Pfingsten 1950 standen 400.000 DM bereit. Bis heute hat die Gesellschaft der Freunde von Bayreuth Spenden in Höhe von 60 Millionen Euro zugunsten der Bayreuther Festspiele geleistet. 

Bei diesem Neuanfang lag die gemeinsame künstlerische und organisatorische Leitung den Enkeln des Festspielgründers, Wieland und Wolfgang Wagner. Ihnen gelang es, jährliche Festspiele – mit meist einer Neuinszenierung pro Saison – zu etablieren. Die ersten Nachkriegsfestspiele begannen am 30. Juli 1951 mit einer vielbeachteten Inszenierung des "Parsifal" durch Wieland Wagner.

Auf dem Spielplan steht seither traditionell eine wechselnde Auswahl aus den Hauptwerken Richard Wagners: "Der fliegende Holländer", "Tannhäuser", "Lohengrin", "Der Ring des Nibelungen" (mit den vier Teilen "Das Rheingold", "Die Walküre", "Siegfried", "Götterdämmerung"), "Tristan und Isolde", "Die Meistersinger von Nürnberg" und "Parsifal".

Gelegentlich wurde auch Beethovens neunte Sinfonie im Festspielhaus aufgeführt. Richard Wagner selbst hatte dieses Werk am 22. Mai 1872 im Markgräflichen Opernhaus dirigiert, aus Anlass der Grundsteinlegung für das Festspielhaus. Im Rahmen der Festspiele erklang die neunte Sinfonie unter Leitung von Richard Strauss (1933), Wilhelm Furtwängler (1951, 1954), Paul Hindemith (1953), Karl Böhm (1963) und Christian Thielemann (2001). Zum 100. Todestag von Richard Wagners Schwiegervater Franz Liszt wurde 1986 dessen Faust-Sinfonie aufgeführt.

Verschiedentlich gingen neue Impulse für Oper und Musiktheater von Bayreuth aus, so ab 1951 durch die Inszenierungen von Wieland Wagner, der mit seiner radikalen „Entrümpelung“ der Bühne einen ästhetischen Neuanfang wagte, der stilbildend bis in die 1970er Jahre wirkte. 1976 ereignete sich in der "Ring"-Inszenierung von Patrice Chéreau zum 100-jährigen Jubiläum der Festspiele (sogenannter "Jahrhundertring") erneut eine umfassende stilistische Veränderung und Erneuerung, die zunächst auch heftige Verstörung und Proteste hervorrief, später aber als richtungweisend und künstlerisch überragend anerkannt wurde.

Musikalisch gelten die Festspielaufführungen – insbesondere bezogen auf Chor und Orchester – als weltweit außerordentlich, was auch mit der architektonischen und akustischen Besonderheit des Gebäudes (s. a. mystischer Abgrund) zu tun hat. Die Solisten werden für die jeweilige Saison eingeladen, wobei in den Anfangsjahren die Ehre der Einladung und die darauf folgenden Aufträge die Tatsache kompensierten, dass die Künstler in der Regel weit unterhalb ihrer Normalverdienste bezahlt wurden. Astrid Varnay wird zitiert mit den Worten: „In Bayreuth wird gearbeitet, das Geld verdienen wir woanders.“ Dieser Grundsatz geht auf Richard Wagner selbst zurück, der erklärte: „Die Sänger und Musiker erhalten von mir nur Entschädigungen, keine Bezahlung. Wer nicht aus Ehre und Enthusiasmus zu mir kommt, den lasse ich wo er ist.“ Dieser Grundsatz wurde in den folgenden Jahrzehnten aufgeweicht, so dass „kein Künstler alleine Neubayreuth zuliebe auf eine gerechte Entlohnung verzichtet“ (Michael Karbaum). Machten Anfang der 1950er Jahre die Personalkosten noch knapp unter 50 % des Gesamtetats aus, wurden in den 1970er Jahren 78–80 % für Gehälter und Gagen ausgegeben, was den Maßstäben anderer großer Bühnen oder Festspiele entspricht.

Jährlich finden 30 Aufführungen im Bayreuther Festspielhaus statt. Die Vorstellungen beginnen, wie zur Zeit Richard Wagners, bereits am Nachmittag, zwischen den Aufzügen gibt es einstündige Pausen, die wegen der Dauer und Komplexität von Wagners Werken durchaus angemessen erscheinen und inzwischen auch an anderen Theatern für Wagner-Aufführungen eingeführt wurden.

Über Jahrzehnte waren die 30 Vorstellungen lange im Voraus ausverkauft. Sie können von ca. 58.000 Zuschauern gesehen werden. Dieser Zahl gegenüber stand in manchen Jahren eine Nachfrage von bis zu 500.000 Kartenbestellungen, so dass mit Wartezeiten von zehn und mehr Jahren gerechnet werden musste. In der Folge entwickelte sich ein Schwarzmarkt mit Festspieltickets, dem wiederum durch personalisierte Eintrittskarten und Kontrollen begegnet werden sollte. Für die "Meistersinger von Nürnberg" des Jahres 1996 ist der Zorn Wolfgang Wagners über einen Kartenverkauf zum Zehnfachen des Normalpreises überliefert. Diese intransparente Entwicklung war das Resultat der Kartenvergabepraxis der Wagner-Familie, zumindest bis zum Ende der Ära Wolfgang Wagner: Niemand wusste, wie viele reguläre Karten in den freien Verkauf gingen und wie viele Günstlinge, Sponsoren und Freundeskreise auf der Zuteilungsliste der Festspielleitung standen. Unklar blieb damit auch, wer wirklich die Aufführungen besuchte oder die zugeteilten Karten gewinnbringend weiterverkaufte.

2011 wurde bekannt, dass nur rund 40 % der Karten in den freien Verkauf kamen, die Mehrheit war in Form von Kontingenten besonderen Zielgruppen zum Kauf angeboten worden. Der größte Empfänger war mit 14.000 Karten jährlich die Mäzenatenvereinigung Gesellschaft der Freunde von Bayreuth, von der die Festspiele jedes Jahr mit Spenden in Höhe von bis zu drei Millionen Euro unterstützt wurden. Weitere Kontingente von Kaufkarten wurden Firmensponsoren, der Stadt Bayreuth, dem Bezirk Oberfranken und der Bayerischen Staatskanzlei zur Verfügung gestellt. Wagner-Freundeskreise und Musikerorganisationen wurden genauso berücksichtigt wie Journalisten (1000 kostenlose Pressekarten zuzüglich eines gesonderten Kontingents für den Bayerischen Rundfunk). Reiseveranstalter erhielten ebenfalls Kartenzuteilungen, die sie zu Paketen mit Unterkunft und Gastronomie bündelten. Der Bundesrechnungshof kam 2011 zum Ergebnis, dass die Vergabe dieser Kontingente „mit den Förderzielen des Bundes unvereinbar“ sei.

Als Reaktion auf die Kritik beendeten die Festspiele 2012 zunächst die Tradition, ursprünglich zwei, ab 2010 eine Vorstellung exklusiv für Mitglieder des DGB Bayern vergünstigt anzubieten, um dessen Verdienste für die Neubegründung der Festspiele nach dem Zweiten Weltkrieg zu würdigen. Die Karten für diese Vorstellungen waren laut Medienberichten in der Vergangenheit in besonders hohem Maß auf dem Schwarzmarkt angeboten worden, so dass die eigentliche Zielgruppe nur bedingt erreicht wurde. 2012 wurde die Kartenvergabe vollkommen neu geregelt: Ab 2012 kamen ca. 65 % der Karten in den freien Verkauf, weshalb der Richard-Wagner-Verband wie auch alle 138 Wagner-Verbände keine Kontingente mehr erhielt. Auch Reisebüros bekamen keine Eintrittskarten mehr. Weiterhin bevorzugt behandelt wird aber die Mäzenatenvereinigung Gesellschaft der Freunde von Bayreuth. Folge dieser Veränderungen war jedoch, dass inzwischen die Nachfrage nach Karten für die Bayreuther Festspiele stark zurückgegangen ist. 2016 waren selbst am Tag vor der Premiere noch nicht alle Vorstellungen ausverkauft. Leere Plätze bei einigen Vorstellungen waren bereits in den Jahren zuvor verschiedentlich aufgefallen.

Der reguläre Eintrittskartenpreis liegt im Jahr 2016 zwischen 30 und 320 Euro (Plätze mit Sichteinschränkung für 25 und 10 Euro). Im Verhältnis zur allgemein hohen künstlerischen Qualität gelten die Preise, auch verglichen mit anderen Festivals, als äußerst maßvoll. Lange Zeit galt die Mitgliedschaft bei den Freunden von Bayreuth, die mit weiteren Kosten (hoher Mitgliedsbeitrag und erwünschte Spenden) verbunden war, als sichere Möglichkeit, um überhaupt regelmäßigen Zugang zu Eintrittskarten zu bekommen. Auf dem Schwarzmarkt wurden Aufschläge von bis zu 700 % auf den regulären Eintrittspreis bezahlt. Ab der Saison 2017 werden für die Premierenvorstellungen der jeweiligen Neuproduktion 25 % des Kartenkategorienpreises auf den zu zahlenden Kartenpreis aufgeschlagen, bei den restlichen Vorstellungen der Neuproduktion werden 15 % des Kartenkategorienpreises auf den finalen Kartenpreis aufgeschlagen. Für die Wiederaufnahmen gelten die alten Preiskategorien.

Inzwischen werden für einen Teil der Vorstellungen auch online Eintrittskarten verkauft, in der Saison 2013 zunächst für eine Vorstellung, die in wenigen Minuten ausverkauft war. Seit 2014 werden Kartenkontingente online verkauft, die zunächst nach kürzester Zeit vergriffen waren. Der Richard-Wagner-Verband vergibt jährlich Stipendien, vornehmlich um Studierenden einen unentgeltlichen Besuch der Aufführungen zu ermöglichen. Auch damit wird versucht, der Idealvorstellung Richard Wagners, jedem ernsthaft Interessierten ungeachtet seiner finanziellen Möglichkeiten den Besuch der Festspiele zu ermöglichen, gerecht zu werden.

Träger des Bayreuther Festspielhauses ist seit 1973 die Richard-Wagner-Stiftung Bayreuth. Stiftungsmitglieder sind die Bundesrepublik Deutschland, der Freistaat Bayern, die Stadt Bayreuth, die Gesellschaft der Freunde von Bayreuth, die Bayerische Landesstiftung, die Oberfrankenstiftung, der Bezirk Oberfranken und Mitglieder der Familie Wagner. Geschäftsführer des Stiftungsrates ist der Oberbürgermeister der Stadt Bayreuth (derzeit Brigitte Merk-Erbe). Die Festspiele werden seit 1986 von der "Bayreuther Festspiele GmbH" durchgeführt. Der Etat der Festspiele beträgt 16 Millionen Euro pro Jahr (Stand: 2012). Der Bund, das Land Bayern und die Stadt Bayreuth bezuschussen den Festspielbetrieb jährlich mit sieben Millionen Euro, der Anteil der Stadt wurde 2016 von 1 Million auf 1,11 Millionen Euro heraufgesetzt.

Künstlerischer Leiter der Festspiele war seit der Wiedereröffnung 1951 (bis 1966 gemeinsam mit seinem Bruder Wieland) Wolfgang Wagner. In den 1990er und 2000er Jahren mehrten sich die Stimmen, die (auch über die Medien) den Rücktritt des Festspielleiters zugunsten verschiedener möglicher Nachfolger (darunter Nike Wagner, Eva Wagner-Pasquier und Wieland Lafferentz oder auch Gudrun Wagner und Katharina Wagner) forderten. 2001 fiel die Entscheidung des Stiftungsrats entgegen dem Willen Wolfgang Wagners zugunsten von Eva Wagner-Pasquier, die jedoch kurze Zeit nach der Wahl auf das Amt verzichtete, da sich Wolfgang Wagner auf seinen Vertrag auf Lebenszeit berief und seinen Posten nicht freiwillig aufgeben wollte. Nach dem plötzlichen Tod von Gudrun Wagner – der Ehefrau und persönlichen Mitarbeiterin Wolfgang Wagners – und angesichts des hohen Alters des Festspielleiters wurde die Nachfolgefrage im November 2007 wieder aktuell. Im April 2008 brachte dann Wolfgang Wagner selbst eine Nachfolgelösung, bestehend aus seinen beiden Töchtern, ins Gespräch und kündigte seinen Rücktritt an, falls der Stiftungsrat sich für die Halbschwestern Eva und Katharina als gemeinsames Leitungsteam der Bayreuther Festspiele aussprechen würde.

Nachdem sowohl Katharina Wagner als auch Eva Wagner-Pasquier ihre Bereitschaft zur Kooperation signalisiert hatten, erklärte Wagner in einem Brief an den Stiftungsrat, zum 31. August 2008 sein Amt als Festspielleiter niederzulegen. Eine Woche vor Ablauf der Bewerbungsfrist und dem Zusammentreten des Stiftungsrates zur Neubesetzung am 1. September 2008 bewarb sich auch Nike Wagner, die Leitung der Festspiele gemeinsam mit dem renommierten Kulturmanager Gerard Mortier zu übernehmen. Der Stiftungsrat wählte in dieser Sitzung die beiden Töchter Wolfgang Wagners, Katharina Wagner und Eva Wagner-Pasquier, zu neuen Leiterinnen der Bayreuther Festspiele.

Nach dem Auslaufen ihres Vertrags von 2008 ist Eva Wagner-Pasquier mit Ende der Saison 2015 aus der Leitung ausgeschieden. Seitdem führt Katharina Wagner die Festspiele allein. Ihr zur Seite stand bis Ende 2015 Heinz-Dieter Sense als Geschäftsführer der Festspiele GmbH, seit 2016 Holger von Berg in gleicher Funktion. Am 29. Juni 2015 wurde bekannt, dass Christian Thielemann bereits am 15. März 2015 und mit Wirkung bis zum Jahre 2020 zum Musikdirektor der Bayreuther Festspiele berufen wurde, eine Position, die es bislang noch nicht gab. Bereits seit 2010 war Thielemann musikalischer Berater der Festspielleitung und soll in dieser neuen Position seine Erfahrungen weitergeben und sich grundsätzlich mit allen musikalischen Belangen des Hauses befassen. Bei einer Pressekonferenz der Festspiele am 25. Juli 2015 wurde bekannt, dass hierbei Thielemanns Aufgaben seien, das Klangbild der Bayreuther Festspiele mit zu prägen, die Orchesterbesetzung auszuwählen und einen Stamm von Assistenten aufzubauen. Zudem soll er in dieser Funktion die Künstlerische Geschäftsleitung beraten und international Solisten besorgen.

Farbig markiert sind die Wirkungszeiten der jeweiligen Festspielleiter, bezogen auf das Jahr der Premiere.

Als „Blaue Mädchen“ wurden die Türsteherinnen des Festspielhauses in Bayreuth bezeichnet. Der Name entstand aus der bis 2008 traditionell blauen Farbe ihrer Uniform. Seit dem Festspielsommer 2009 sind sie jedoch einheitlich grau gekleidet.

In früher Zeit waren es vorzugsweise unverheiratete junge Damen aus der näheren Umgebung von Bayreuth, heute dominieren Studentinnen der theater- und operbezogenen Studiengänge aus Bayreuth, Deutschland, Europa und der Welt. Sie haben die Möglichkeit, sich in ihrem Dienst annähernd alle 30 Aufführungen einer Festspielsaison der Richard-Wagner-Festspiele anzuschauen und anzuhören. Ab der Saison 2015 ist auch männliches Einlasspersonal im Einsatz.

Von 1952 bis 1987 nahm Siegfried Lauterwasser als Bühnenfotograf die Inszenierungen der Bayreuther Festspiele auf. Seit 2009 ist Enrico Nawrath als Bühnenfotograf verantwortlich. 

Am 18. August 1931 übertrug die Deutsche Stunde in Bayern erstmals eine Aufführung live aus dem Festspielhaus: "Tristan und Isolde", dirigiert von Wilhelm Furtwängler. Angeschlossen waren über 200 europäische, amerikanische und afrikanische Sender; es war die „erste Weltsendung in der Geschichte des Rundfunks“.

Von einigen Bayreuther Inszenierungen gibt es Filmaufzeichnungen, u. a.:

2008 fand als Live-Übertragung aus dem Festspielhaus das erste Public Viewing einer Aufführung der Bayreuther Festspiele statt. Bei den Bayreuther Festspielen 2010 war das erste Public Viewing für Kinder am Vormittag mit der Filmaufführung der Kinderoper "Tannhäuser und der Sängerkrieg auf Wartburg" sowie dem interaktiven Wagner-Erlebnisparcours und Rahmenprogramm für Kinder im Anschluss. Die Aufführungen konnten auch als Livestream im Internet verfolgt werden.

Nachdem sich der Sponsor Siemens zurückzog, gab es 2012 kein "Public Viewing" auf dem Volksfestplatz. Stattdessen wurde am 11. August eine Vorstellung des Parsifal live in über hundert Kinos gezeigt. Das Pausenprogramm mit Einblicken hinter die Kulissen und Interviews wurde moderiert von Katharina Wagner, Klaus Florian Vogt und Axel Brüggemann. 2013 wurde in ähnlicher Weise eine Aufführung des Fliegenden Holländers, 2014 eine des Tannhäusers, 2015 eine des Tristans in der Inszenierung von Katharina Wagner und 2016 eine des Parsifals unter dem Dirigat von Hartmut Haenchen im Kino übertragen. 2017 ist eine Übertragung der Meistersinger-Produktion von Barrie Kosky in Kinosälen, auf Sky Arts sowie in einem Livestream auf der Internetpräsenz von BR-Klassik aufgeführt worden.
Seit Wiederaufnahme der Festspiele nach dem Zweiten Weltkrieg im Jahr 1951 gibt es an den Aufführungstagen jeweils Einführungsvorträge zu den an den gleichen Tagen stattfindenden Vorstellungen. Als Referenten dieser von Wieland Wagner vorgeschlagenen Veranstaltungsreihe wirkten zunächst Erich Rappl und ab 1998 Stefan Mickisch. Seit einigen Jahren finden zwei Einführungsvorträge zu jeder Vorstellung statt, Referenten sind bzw. waren Stefan Mickisch und Detlev Eisinger (in dieser Funktion von 2002 bis einschl. 2008). Oft werden mehr als 10.000 Zuhörer pro Saison gezählt. An einzelnen Tagen werden auch Vorträge in englischer und französischer Sprache angeboten. Ab dem Jahr 2009 wird einer der Einführungsvorträge im Haus Wahnfried vom Leiter des Museums gehalten. Zusätzlich gibt es inszenierungsbezogene Einführungsvorträge im Festspielhaus, die aber für Personen reserviert sind, die eine Eintrittskarte für die jeweilige Aufführung besitzen.
Seit 2013 werde auch allgemein zugängliche Einführungsvorträge jeweils zwei Stunden vor Vorstellungsbeginn in der Walhall-Lounge direkt auf dem Festspielgelände angeboten.

2009 wurde auf der Probebühne IV des Festspielhauses eine etwa einstündige, für Kinder von sechs bis zehn Jahren konzipierte Bearbeitung des "Fliegenden Holländers" gespielt (Textfassung: Alexander Busche; Einrichtung für 19 Musiker / musikalische Leitung: Christoph Ulrich Meier; Regie: Alvaro Schoeck, Bühnenbild: Merle Vierck; Kooperationspartner: Hochschule für Musik „Hanns Eisler“ Berlin).

2010 wurde eine "Tannhäuser"-Bearbeitung gespielt, 2011 ein Ring für Kinder, 2012 eine kindgerechte Fassung der Meistersinger von Nürnberg (Regie: Eva-Maria Weiss; musikalische Leitung: Hartmut Keil), 2013 (Regie: Michael Höppner; musikalische Leitung: Boris Schäfer) eine von Tristan und Isolde, 2014 ein Lohengrin (Regie: Maria-Magdalena Kwaschik; musikalische Leitung: Boris Schäfer), 2015 Parsifal in einer Fassung von Katharina Wagner (Regie: Tristan Braun; musikalische Leitung: Boris Schäfer). und 2016 eine kindergerechte Fassung des Fliegenden Holländers. 2017 ist eine neue Tannhäuser-Produktion aufgeführt worden und somit ist der gesamte Bayreuther Werkekanon auch in den Kinderopern in seiner zweiten Serie. Die 10 Aufführungen finden in den ersten zwei Festspielwochen statt (25. Juli – 10. August) und werden seit 2009 auf der Probebühne IV gezeigt. Das Kinderfestspielorchester ist das Brandenburgische Staatsorchester Frankfurt (Oder). Eine Besonderheit ist die Mitwirkung von Kindern in der Produktion durch Kostümwettbewerbe oder als Statisten auf der Bühne.





</doc>
<doc id="4373" url="https://de.wikipedia.org/wiki?curid=4373" title="Radom">
Radom

Radom [] ist eine kreisfreie Großstadt der Woiwodschaft Masowien im zentralen, leicht südöstlichen Teil Polens – rund 100 Kilometer südlich der Landeshauptstadt Warschau zwischen der Weichsel und dem Fuß des Heiligkreuzgebirges. Radom hat sieben Hochschulen und ist bedeutender Verkehrsknotenpunkt der Linien Warschau–Krakau sowie Łódź–Lublin.

Radom wurde 1155 zum ersten Mal urkundlich erwähnt. Die Blütezeit der Stadt lag am Ende des 15. Jahrhunderts, als der polnische König Kasimir IV. die Stadt zu seiner Residenz machte.

Mit der Dritten Teilung Polens 1795 wurde Radom Österreich zugeschlagen. 1809 bis 1815 gehörte es zum Herzogtum Warschau und danach zum Kongresspolen, das unter russischer Herrschaft stand.
Im September 1939 fand im Raum Radom eine Kesselschlacht statt, in der technisch unterlegene polnische Truppen von deutschen Panzerverbänden aufgerieben wurden. 

Während der deutschen Besatzung betrieben die Deutschen hier ein Außenlager des KZ Majdanek (an der Szkolnastr.) und das Ghetto Radom mit 30.000 Bewohnern. Zu den verantwortlichen Offizieren gehörten neben anderen Karl Oberg, Erich Kapke, Fritz Katzmann, Wilhelm Bluhm, Hermann Weinrich und Herbert Böttcher, die später als Kriegsverbrecher verurteilt wurden. Im Umfeld von Radom errichtete die Wehrmacht 1940 den Truppenübungsplatz Mitte. Hierfür wurden etliche Dörfer der Umgebung „abgesiedelt“. Zivilverwalter der Stadt war der Nationalsozialist Fritz Schwitzgebel aus Saarbrücken.

Von 1939 bis 1945 war Radom Sitz des Distrikts Radom im Generalgouvernement. Ende 1943 übernahm die DAW Deutsche Ausrüstungswerke polnische Häftlinge im Generalgouvernement sowie die Industriebetriebe in Radom.

Am 16. Januar 1945 wurde Radom von der Roten Armee eingenommen. Die an ihrem Wohnort gebliebenen Deutschen wurden teilweise vertrieben oder ermordet. 
Die Arbeitsfähigen mussten in den Industriewerken in Radom oder auch in der Landwirtschaft Zwangsarbeit verrichten. Im Frühjahr 1945 wurden die arbeitsfähigen deutschen Männer zu Trupps zusammengestellt und zur Zwangsarbeit in sowjetische Lager verbracht.

1976 kam es in Radom zu Arbeiterunruhen, die von Sicherheitskräften niedergeschlagen wurden.

Zu Beginn des 19. Jahrhunderts siedelten sich in und um Radom evangelische Deutsche an. So gründeten sie um 1815 die pommerschen Dörfer Pelagiów und Soltyków. Später folgten noch nachstehende Kolonien: Błonie und Zabierzów 1838, Małe Studnie und Bobrowniki 1839, Józefów bei Radom und Bartodzieje 1842, Polesie, Pająków und Leokadiów nach 1870. Bis zum Jahr 1826 hatten die Evangelischen in und um Radom weder Kirche, Pfarrhaus noch einen eigenen Pastor. Zur Befriedigung ihrer religiösen Bedürfnisse suchten sie entweder die lutherische Kirche in Wengrow auf oder die dortigen Pastoren Goburek bzw. Haupt kamen nach Radom zu Hauptgottesdiensten oder zur Verrichtung von Amtshandlungen. Aber infolge der weiten Entfernung und schlechten Wege war dieser Zustand auf Dauer untragbar. Und so wünschten hier die Evangelischen die Bildung eines neuen Kirchspiels. Die evangelisch-augsburgische Gemeinde entstand am 30. September 1826. 1827 kaufte die Gemeinde eine ehemalige Benediktinerkirche, die damals ein Theater war. Das Gebäude wurde zu einer evangelischen Kirche umgebaut. Am 15. August 1828 wurde die Kirche eingeweiht.
1827 wohnten in der Stadt 1442 Lutheraner und 21 Reformierte. Pastor Julius Krauze eröffnete in Radom eine evangelische Schule, die am 8. Januar 1843 in eine Elementarschule umgewandelt wurde. 1834 wurde der evangelische Friedhof gegründet. 1887 schenkte Frau Pastor Wüstehube der Gemeinde eine Orgel. In der Zeit 1893 bis 1895 wurde die Kirche um- und ausgebaut. Die Ausgaben wurden größtenteils durch freiwillige Gaben bestritten. Leokadiów, das größte Kantorat der Gemeinde, besaß einen geräumigen Betsaal mit einem Glockenturm. 1938 wurde der Betsaal niedergebrannt.

Im Ersten Weltkrieg wurden die Eingepfarrten fast alle nach Russland verschleppt. 1918–1920 kehrten die meisten von ihnen wieder zurück. Im Zweiten Weltkrieg wurde die Kreishauptmannschaft, im ganzen mehr als 4000 evangelische Deutsche, unter Leitung des Kreishauptmanns Dr. Rubehn nach Deutschland evakuiert.

Trotz des Zweiten Weltkrieges und seiner Folgen besteht die Gemeinde bis heute. Am 23. September 2001 konnte das 175-jährige Jubiläum der Gemeindegründung gefeiert werden.

Sehenswert sind aus der älteren Zeit das Kloster der Bernhardiner, gestiftet vom polnischen König Kasimir IV. Jagiello im 15. Jahrhundert, die spätmittelalterliche Johannes-Pfarrkirche mit Kapelle der Familie Kochanowski sowie die barocke Dreifaltigkeitskirche. Die älteste Kirche der Stadt, die Wenceslaus-Kirche aus dem 13. Jahrhundert, wurde erst in den letzten Jahren saniert, wobei das Innere modern ausgestattet wurde. Sehr wichtig für die polnische Baukunst des 19. Jahrhunderts sind das Gebäude der ehemaligen Woiwodschaftsverwaltung nach Plänen von Antonio Corazzi, ein Prachtwerk des Spätklassizismus, und das Rathaus im Stile der italienischen Neorenaissance, erbaut nach Plänen von Marconi. In ungeraden Jahren, Ende August bzw. Anfang September, findet in Radom eine internationale Flugschau (Air-Show) statt.

Sendeanlage für Langwellenfunkdienste (nicht Rundfunk) im Westen der Stadt.

Die metallverarbeitende Industrie, die bis 1989 das wirtschaftliche Bild Radoms bestimmte, existiert in dieser Form nicht mehr, so dass Radom als Industriestadt von relativ hoher Arbeitslosigkeit betroffen ist.





</doc>
<doc id="4374" url="https://de.wikipedia.org/wiki?curid=4374" title="Rhea (Mythologie)">
Rhea (Mythologie)

Rhea () ist eine Gestalt aus der griechischen Mythologie und eine der Titaninnen.

Rhea ist die Tochter der Gaia und des Uranos sowie die Gemahlin ihres Bruders Kronos, mit dem sie gemeinsam den ewigen Fluss der Zeit und der Generationen bestimmt. Nach einer Prophezeiung wurde vorhergesagt, dass Kronos dereinst durch eines seiner Kinder abgesetzt werde. Aus diesem Grunde verschlang er alle Kinder, die Rhea ihm gebar. Als Rhea wiederum schwanger war, versuchte sie Zeus, ihren neugeborenen Sohn, vor Kronos zu verbergen. Sie versteckte ihn in einer Höhle auf Kreta und ließ ihn von den Kureten bewachen. Da Kronos von der Geburt wusste, präsentierte sie ihm statt des Kindes einen in Windeln gewickelten Stein, den dieser sofort gierig verschlang.

Gemeinsam mit Kronos zeugte sie zuvor die Gottheiten Hestia, Demeter, Hera, Hades und Poseidon, die alle von ihrem Vater verschlungen wurden. Als Zeus herangewachsen war, stürzte er seinen Vater Kronos und wurde selbst zum Herrscher des nächsten Göttergeschlechtes.

Gaia stellt in der Mythologie die Große Erdmutter, die Urmutter aller Götter, dar. Sowohl Gaia als auch Rhea sowie deren Tochter Hera schenken Söhnen das Leben, die ihre Väter entmachten oder zumindest einen Versuch unternehmen, sie zu stürzen. Bei den Römern wurde die Gottheit als Kybele bezeichnet. Rhea wird daher manchmal mit dieser oder mit Demeter gleichgesetzt, quasi wie eine Reinkarnation der personifizierten Muttergöttin oder der Erde, da Rhea wiederum als Mutter der Götter und Menschen gilt.

Es spricht einiges dafür, dass es sich um immer dieselbe Göttin in anderer Gestalt handelt oder dasselbe Ritual mit Personen in gleichen Funktionen. Insofern können Gaia, Rhea und Demeter/Hera als Vertreterinnen und Verkörperungen der Großen Göttin angesehen werden und die scheinbaren Inzeste und Bluttaten als Andeutungen matriarchalischer Rituale. Für diese These spricht auch, dass Rhea – wie die Große Göttin/Erdmutter in anderen Mythologien auch – in einer dreifachen Gestalt auftritt, bzw. vertreten wird: als Amaltheia, die Amme des Zeus, als Io, seine Geliebte, und als Rachegöttin Adrasteia, auch Nemesis genannt.

Den Orphikern zufolge soll Rhea mit ihrem Gatten Kronos auf der Insel der Seligen herrschen, wo das Goldene Zeitalter anhält.

Der Analytischen Psychologie in der Tradition Carl Gustav Jungs gilt Rheia als besonders deutliche Ausprägung des sog. Mutterarchetyps.

Nach der Göttin sind der Mond Rhea des Saturn und der paläozoische Rhea-Ozean benannt.

Rhea wird meist mit anderen Göttern kombiniert, wie mit Demeter. Oft ist sie als Göttermutter dargestellt, dann meist sitzend auf einem Omphalos. Einige Darstellungen beschäftigen sich auch mit der Gigantomachie; hier findet man Rhea auf Seiten der Götter.



</doc>
<doc id="4389" url="https://de.wikipedia.org/wiki?curid=4389" title="Rohrkolben">
Rohrkolben

Die Rohrkolben ("Typha"), regional auch als Kanonenputzer, Lampenputzer oder Schlotfeger auch "Schmackedutsche", "Bumskeule", "Pompesel", "Bullerbesen" etc. bezeichnet, sind eine der beiden Gattungen der Familie der Rohrkolbengewächse (Typhaceae) innerhalb der Ordnung der Süßgrasartigen (Poales).

Sie sind Wasser- und Sumpfpflanzen, welche in Feuchtgebieten dichte Bestände entwickeln können. Besonderes Kennzeichen der Rohrkolben ist der auffallend zweiteilige Blütenstand aus einem rein weiblichblütigen und darüber befindlichem rein männlichblütigen Kolben.

Rohrkolben-Arten sind sommergrüne, ausdauernde krautige Pflanzen. Es sind Wasser- und Sumpfpflanzen (Hydrophyten, Helophyten) mit kräftigen unterirdisch kriechenden Rhizomen. Sie sind in der Lage, dichte Bestände zu entwickeln (Polykormone).

An den stets unbehaarten Stängeln sind die Blätter wechselständig und streng zweizeilig (distich) angeordnet. Die ungestielten, einfachen Laubblätter wachsen steif aufrecht, können eine Länge von bis zu 4 Meter erreichen, sind linealisch grasartig und bestehen aus einem schwammartig-zusammendrückbaren Schwimmgewebe. Die parallelnervigen Blattspreiten sind nach außen gewölbt und innen flach, so dass sich im Querschnitt ein Halbkreis ergibt – im Gegensatz zu den Igelkolben mit dreieckigem Blattquerschnitt. Die Blattscheiden sind stets offen. An den Scheidenmündungen im Übergang zur Spreite sind keine Blatthäutchen (Ligulae) entwickelt.

Rohrkolben-Arten sind einhäusig getrenntgeschlechtig (monözisch). Der Gesamtblütenstand (Infloreszenz) der Rohrkolben besteht aus einem dickeren, rein weiblichblütigen und einem darüber befindlichen, durch einen artspezifisch langen Sprossabschnitt getrennten, dünneren rein männlichblütigen Teilblütenstand. Diese sind als walzenförmige oder kugelige Kolben ausgebildet, in denen die Einzelblüten dicht gedrängt stehen. Der Blütenstand ist nie von Hochblättern (Brakteen) durchsetzt – im Gegensatz zu den Arten der Igelkolbengewächse. Die eingeschlechtigen, dreizähligen Einzelblüten sind spelzenlos. Die weibliche Blüte besteht aus der Blütenhülle (a) (Perigon), die ist zu einem dichten Haarkranz reduziert und einem gestielten Fruchtknoten (c) mit spatelförmiger Narbe (d). Die auf einem Stiel sitzenden zwei bis fünf Staubblätter (b) der einzelnen männlichen Blüten sind von wenigen Hüllborsten (a) umgeben.
Die Blütezeit der Rohrkolben erstreckt sich von Mai bis August.

Die Verbreitungseinheit (Diaspore) wird aus der Achäne, eine einsamige Nussfrucht und den Perigonhaaren gebildet.

Die "Typha"-Arten werden durch den Wind bestäubt (Anemogamie).

Die Ausbreitung der Diasporen erfolgt durch den Wind (Anemochorie) und durch Wasser (Hydrochorie). Dabei dienen die feinen Perigonhaare als Flug- oder Schwimmorgane. Bei den meisten Arten verlassen die Samen die Fruchthülle bei längerem Kontakt mit dem Wasser, sinken ab und keimen unter Wasser (anaerob). Bei einigen Arten verbleiben sie in der Fruchthülle und keimen an der Luft unter aeroben Bedingungen.

Die vegetative Ausbreitung erfolgt über Rhizome. Die "Typha"-Arten können an geeigneten Standorten dichte artenarme Bestände, sogenannte Röhrichte entwickeln. Die "Typha"-Arten sind an feuchte bis nasse, zum Teil brackige und zeitweise überflutete Lebensräume angepasst. Sie besiedeln Gewässerufer, Sümpfe und Moore.

"Typha"-Arten sind weltweit von den gemäßigten Zonen bis in die Tropen verbreitet (kosmopolitisch) und häufig. Die "Typha"-Arten sind unterschiedlich verbreitet. Eine weite Verbreitung hat beispielsweise der Breitblättrige Rohrkolben ("Typha latifolia"). Er kommt in den gemäßigten Zonen der Nordhalbkugel bis nach Südamerika sowie in Teilen Afrikas vor. Andere "Typha"-Arten besiedeln nur ein eingeschränktes Areal. "T. capensis" beschränkt sich ausschließlich auf ein Gebiet von Uganda bis Südafrika oder "Typha davidiana" nur auf China.

Der Gattungsname "Typha" leitet sich vom Griechischen Wort "týphos" für Rauch ab. Es wird damit auf die braune rauchähnliche Farbe der Fruchtkolben Bezug genommen.

Die genaue Platzierung der Gattung innerhalb der Ordnung Poales war lange umstritten. So wurde von einigen Autoren die Gattung Igelkolben in die Familie der Rohrkolbengewächse aufgrund ihrer morphologischen Ähnlichkeit mit aufgenommen, von anderen Autoren wurde die Beibehaltung eigenständiger, monogenerischer Familien (Typhaceae und Sparganiaceae) vorgezogen. Nach der strikt phylogenetisch orientierten APG III sind die Igelkolben jedoch Teil der Rohrkolbengewächse.

Die Gattung "Typha" umfasst je nach Autor 16 bis 27 Arten:


Dazu kommen noch als Hybride:

Bereits seit der Altsteinzeit verwenden Menschen Rohrkolben zur Feuererzeugung, da nitrierte Rohrkolbenwatte leicht entzündlich ist. 

Alle Pflanzenteile sind essbar. Besonders die stärkereichen Rhizome können wie Gemüse gekocht werden.
Lange bevor andere Getreidearten von den Menschen nutzbar gemacht wurden, wurden offenbar schon vor 30.000 Jahren die stärkehaltigen Wurzelstöcke zu Mehl verarbeitet. Aus den Erträgen eines Hektars Sumpfland können bis zu 8 Tonnen Mehl gewonnen werden.

Rohrkolben werden zur Reinigung von Abwässern in Kläranlagen eingesetzt und zur Entgiftung von Böden und Schlämmen. Diese naturnahen Verfahren werden unter dem Fachbegriff „Phytosanierung“ zusammengefasst, bei denen die komplexen Fähigkeiten von Pflanzen und der mit ihnen im Wurzelraum vergesellschafteten Mikroorganismen genutzt werden. Rohrkolben qualifizierten sich wegen ihrer hohen Primärproduktion zur Kultivierung. Sie gewinnen an Bedeutung als nachwachsender Rohstoff zum Beispiel für Dämmmaterial, als Torfersatz oder Bau- und Heizmaterial.

Rohrkolben-Arten werden als dekorative Bepflanzung von Teichen in Parks und Gärten eingesetzt. Die getrockneten Blütenstände werden in der Floristik verwendet.

Die Bastfasern einiger Arten können zu Spinnfasern verarbeitet werden.

Aus dem Stroh können Flechtwaren z. B. Strohhüte hergestellt werden.

In den 2000er Jahren entwickelte der Architekt "Wolfgang Theuerkorn" aus "Typha angustifolia" einen Dämmstoff, indem er Streifen der Blätter mit Magnesit zu Platten verklebte und zunächst bei der Sanierung eines historischen Fachwerkhauses in Nürnberg einsetzte. Inzwischen wurden etliche weitere Gebäude mit den 2 bis 12 Zentimeter starken, diffusionsoffenen, kapillaraktiven, schalldämmenden und aufgrund enthaltener Gerbstoffe schimmelresistenten Platten gedämmt, die in einer kleinen Fabrik im bayerischen Schönau (Rottal) hergestellt werden. Das Fraunhofer-Institut für Bauphysik in Holzkirchen (Oberbayern) errichtete zum Langzeittest eine Hütte.



</doc>
<doc id="4390" url="https://de.wikipedia.org/wiki?curid=4390" title="Rhein-Main-Gebiet">
Rhein-Main-Gebiet

Das Rhein-Main-Gebiet, auch Metropolregion Frankfurt/Rhein-Main, ist eine der elf von der deutschen Ministerkonferenz für Raumordnung definierten Metropolregionen in Deutschland. Es ist benannt nach den beiden Flüssen Main und Rhein und liegt im Süden Hessens sowie Teilen der angrenzenden Länder Rheinland-Pfalz "(Rheinhessen)" und Bayern "(Unterfranken)". Kern der Metropolregion ist der städtische Ballungsraum Frankfurt/Rhein-Main. Insgesamt hat das Rhein-Main-Gebiet ungefähr 5,7 Millionen Einwohner, von denen etwa 2,2 Millionen im Ballungsraum Frankfurt/Rhein-Main leben.

Das Rhein-Main-Gebiet ist die verkehrsgeographische Mitte Deutschlands und Europas.

Die Region stellt ein polyzentrisches Verdichtungsgebiet dar, dessen wirtschaftlich und politisch wichtigste Städte Frankfurt am Main, Wiesbaden, Mainz und Darmstadt sind. Funktionaler und geografischer Mittelpunkt ist die Stadt Frankfurt am Main.

Andere städtische Zentren der Region sind Rüsselsheim am Main, Groß-Gerau, Bad Homburg vor der Höhe, Offenbach am Main, Hanau, Aschaffenburg, Gießen, Limburg an der Lahn und Fulda.

Der Bereich der Industrie- und Handelskammern, die Mitglied des "IHK-Forums Rhein-Main" sind, umfasst die ganze Wirtschaftsregion. Damit erhält man folgende großzügige, der Metropolregion Frankfurt/Rhein-Main entsprechende, Abgrenzung:

Der Lahn-Dill-Kreis ist hier nicht enthalten, da er nicht Teil der europäischen Metropolregion Frankfurt/Rhein-Main ist, obwohl er historisch zum Rhein-Main-Gebiet gehört.

Der Kreis Bergstraße und die Stadt Worms liegen im Überschneidungsbereich zur benachbarten Metropolregion Rhein-Neckar.

Die Abteilung „Rhein-Mainische Forschung“ (1925–2005 an den Geografischen Instituten der Universität Frankfurt beheimatet) grenzt die Region auf der Basis von Pendlerverflechtungen ähnlich ab – Kernstädte der Region sind hier Frankfurt, Wiesbaden, Offenbach, Darmstadt und Hanau in Hessen sowie Aschaffenburg in Bayern und Mainz in Rheinland-Pfalz. Mit insgesamt etwa 4,9 Millionen Einwohner auf ungefähr 11.000 km² Fläche umfasst die Region nach dieser Abgrenzung auch den Regierungsbezirk Darmstadt, den Landkreis Limburg-Weilburg (Regierungsbezirk Gießen) sowie den Landkreis Aschaffenburg und den Landkreis Miltenberg aus Bayern sowie den Landkreis Mainz-Bingen, die Stadt Worms und den Landkreis Alzey-Worms aus Rheinland-Pfalz. Die Erweiterung des IHK-Forums im Norden um die IHK-Bezirke Gießen-Friedberg ist aus Sicht der Wissenschaftler wenig sinnvoll, da sich aus diesen Landkreisen nur wenige Verflechtungen mit dem Kern der Region nachweisen lassen.

Eurostat, das statistische Amt der Europäischen Union, verwendet das harmonisierte Konzept der Stadtregion ("Functional Urban Area", bis 2013 "Larger Urban Zone"). Die Stadtregion "DE005C Frankfurt am Main" wird seit 2004 im Rahmen des Urban Audit für statistische Erhebungen genutzt. Zur Stadtregion Frankfurt gehören gemäß dieser Definition folgende Verwaltungseinheiten:


In der so abgegrenzten Region mit zusammen 4305 Quadratkilometern leben 2.574.812 Einwohner (2012)

Zur Metropolregion gehören auch die Stadtregionen DE020C Wiesbaden mit 462.098 Einwohnern, DE025C Darmstadt mit 439.084 Einwohnern und DE037C Mainz mit 403.849 Einwohnern.

Das "Gesetz über die Metropolregion Frankfurt/Rhein-Main" des Hessischen Landtags vom 11. März 2011 definiert den engeren Ballungsraum Frankfurt am Main folgendermaßen:


Dieses Gebiet zählt etwa 2,2 Millionen Einwohner auf 2.500 km² Fläche.

Der Ballungsraum, der in etwa der Ausdehnung des S-Bahn-Netzes entspricht, reicht von der Gegend um Wiesbaden und Mainz im Westen bis Aschaffenburg im Osten sowie von Friedberg und Bad Nauheim im Norden bis Darmstadt im Süden. Dieses Gebiet zählt 3,4 Millionen Einwohner auf 5500 km² Fläche.

Der Einzugsbereich des Rhein-Main-Gebiets ist sehr groß. Etwa 350.000 Pendler kommen jeden Tag in den Frankfurter Raum, die zum Teil weit mehr als 100 Kilometer von ihrem Arbeitsplatz entfernt wohnen. Der Pendler-Einzugsbereich umfasst den ganzen Odenwald, die Südpfalz, die Rhön, den Taunus, den Westerwald, die Region Marburg/Gießen/Wetzlar und die Kurpfalz. Der Rhein-Main-Verkehrsverbund (RMV) ist deshalb nicht zufällig der drittgrößte deutsche Verkehrsverbund.

Zur Metropolregion Frankfurt/Rhein-Main gehören folgende Städte ab 30.000 Einwohnern (Stand 31. Dezember 2015; in den letzten beiden Spalten ist die Zugehörigkeit zu dem engeren Verband "Regionalverband Frankfurt/Rhein-Main" (BAFRM) und dem ehemaligen Verband "Region Starkenburg" (RGSTARK) angegeben):

Die zentrale und verkehrsgünstige Lage in Südwestdeutschland förderte schon Mitte des 19. Jahrhunderts die Industrialisierung der Region. Unternehmen aus vielen Branchen haben hier ihren Sitz und beschäftigen in der Region etwa 1,8 Millionen Arbeitnehmer. In der Frankfurter Innenstadt überwiegen Banken und Investmentgesellschaften. Im weiteren Umfeld haben sich weitere Dienstleistungen etabliert, wobei die Automobilindustrie eine Schlüsselrolle einnimmt. Viele davon haben eine Europa- oder Deutschlandzentrale, oft mit Forschungs- und Designzentren. Auch die Bau- und Immobilien-Wirtschaft zählt mit einem Anteil von 18 Prozent an der regionalen Bruttowertschöpfung zu den wirtschaftlichen Schwergewichten der Region. Als Wissenschaftsstädte, mit Sitz von Bundesbehörden und Versicherungsunternehmen, haben sich Darmstadt und Wiesbaden etabliert.

Der Logistikbereich ist besonders durch den Flughafen Frankfurt am Main und die zentrale Anbindung an das Autobahn- und Eisenbahnnetz stark begünstigt. Das Frankfurter Kreuz und der Frankfurter Hauptbahnhof sind jeweils die verkehrsreichsten in Europa. In wenigen Stunden Fahrt sind München, Hamburg, die Benelux-Staaten, Paris, die Schweiz, Österreich, Tschechien, Polen und Berlin zu erreichen. Weitere wichtige Bahnhöfe im Fernverkehr sind Mainz Hbf, Frankfurt Süd und Frankfurt Flughafen Fernbahnhof. Über den Frankfurter Flughafen sind viele Flugziele weltweit als Direktflug erreichbar. Die Infrastruktur im Rhein-Main-Gebiet gilt als sehr gut ausgebaut.

Die landschaftliche Attraktivität der Region ergibt sich aus dem Gegensatz zwischen den Ebenen der beiden namensgebenden Flüsse und den die Region begrenzenden Mittelgebirgen.

Die Untermainebene ist der nördliche Ausläufer der Oberrheinischen Tiefebene, die etwa von Basel bis Frankfurt reicht. Der Mittelrhein durchbricht in einem engen, teilweise schluchtartigen Tal das Rheinische Schiefergebirge. Außer den beiden genannten Strömen sind Nidda, Kinzig und Nahe wichtige Flüsse der Region, an ihrem Nordrand außerdem die Lahn.

Fünf Mittelgebirge begrenzen die Region: Taunus, Vogelsberg, Spessart, Odenwald und Hunsrück. Der Südhang des Taunus (Rheingau) und der Westhang des Odenwalds (Bergstraße) gehören klimatisch zu den mildesten Gegenden in Deutschland.

Der Rheingau, das linksrheinische Gebiet Rheinhessen, die hessische Bergstraße sowie das unterfränkische Maintal sind Weinbaugebiete. Die Landwirtschaft in der Wetterau im Norden der Region verfügt über Böden, die zu den ertragsreichsten in Deutschland zählen. Im dicht besiedelten Kernraum der Region um Frankfurt dienen die Freiflächen mehr der Naherholung als der Landwirtschaft. Typisch für das dortige Landschaftsbild sind Streuobstwiesen, deren Erträge meist zur Produktion des Frankfurter Apfelweins dienen.

Im hessischen Ried direkt am Rhein befindet sich das große Naturschutzgebiet Kühkopf.

Eine bis heute gültige Besonderheit der Region ist, dass es niemals in der Geschichte eine territoriale Einheit des Rhein-Main-Gebiets gab. Der tausendjährigen Kleinstaaterei verdankt die Region ihre kulturelle Vielfalt, aber auch die im Gegensatz zu konkurrierenden Metropolregionen fehlende Kooperation und Koordination.

In römischer Zeit lag die Region an der Grenze des Imperiums. Mainz war unter dem Namen "Mogontiacum" Hauptstadt der Provinz Obergermanien, der Limes schützte die Reichsgrenze und verlief über den Kamm des Taunus und quer durch die Wetterau. Außer Mainz gab es zahlreiche römische Kastelle in der Region (Hofheim, Höchst, Frankfurt, Kleiner Feldberg, Saalburg, u. a.) sowie die Stadt Nida (bei Frankfurt-Heddernheim). Wiesbaden war schon damals ein wichtiger Badeort "(Aquae Mattiacorum)".

Bereits in der spätrömischen Antike (seit 343) wurde Mainz zu einem Bischofssitz, der im frühen Mittelalter einer der wichtigsten des fränkischen, später Deutschen Reichs wurde. Fränkische Könige (Merowinger, später Karolinger) errichteten Königshöfe, u. a. in Frankfurt und Ingelheim. Das Kloster Lorsch wurde durch Landschenkungen eines der mächtigsten in Deutschland. Durch die günstige Verkehrslage konnte die Region Handelsverkehr an sich ziehen, wichtige Straßen entstanden, so die Via Regia.

Im späten Mittelalter löste Frankfurt Mainz als wichtigste Stadt der Region ab. Frankfurt, Friedberg (Hessen), Wetzlar und Gelnhausen (Letzteres mit Kaiserpfalz der Staufer) waren Freie Reichsstädte. Die Erzbischöfe von Mainz waren Erzkanzler des Reichs und einer der sieben Kurfürsten. Frankfurt verdankte seinen Aufstieg der Rolle als bedeutende Messestadt und als Ort der Wahl, später auch der Krönung der römisch-deutschen Könige und Kaiser.

Das Erzbistum Mainz umfasste große Gebiete im Westen und Osten (um Aschaffenburg) des Rhein-Main-Gebietes, bis es 1803 aufgelöst wurde. Nach dem Wiener Kongress verteilte sich ab 1816 die Region auf folgende Territorien:



Nach dem Preußisch-Deutschen Krieg 1866 annektierte Preußen alle genannten Territorien außer dem Großherzogtum Hessen und dem Königreich Bayern, die kleinere Gebietsteile abtreten mussten. Die territoriale Zersplitterung bestand allerdings weiter, da das Großherzogtum Hessen durch das Stadtgebiet Frankfurt und den anschließenden Kreis Hanau in zwei Teile geteilt blieb.

Die eigentliche Geschichte der „Region Rhein-Main“ oder des „Rhein-Main-Gebietes“ im Wortsinn beginnt gegen Ende des 19. Jahrhunderts, als zum ersten Mal über einen regionalen Zusammenhang debattiert und der Begriff "Rhein-Main-Gebiet" geprägt wurde. Damals wie heute blieb die Region als solche jedoch in ihren Grenzen unbestimmt. In den 1920er Jahren gab es erste Versuche, einer regionalen Kooperation den Weg zu ebnen und Funktionen in der Region zu verteilen – Zeugnis dieses Versuches ist der Plan eines „Rhein-Mainischen Städtekranzes“, der vom damaligen Frankfurter Oberbürgermeister Ludwig Landmann direkt nach seinem Amtsantritt 1924 vorgestellt wurde. Landmann sah das Rhein-Main-Gebiet mit Frankfurt im Zentrum eines südwestdeutschen Einzugsgebietes, für das im Rahmen der Diskussionen um die sogenannte Reichsreform sogar Frankfurter Planungen für ein eigenes neues Reichsland „Rheinfranken“ lanciert wurden. Die Bedeutung, die der Region in den späten 1920er Jahren beigemessen wurde, zeigt auch die Gründung einer eigenen Forschungsabteilung „Rhein-Mainische Forschung“ am Geografischen Institut der Universität Frankfurt. Mit dem „Rhein-Mainischen Atlas“ legte diese 1929 nicht nur den ersten deutschen Regionalatlas überhaupt vor, sondern definierte erstmals Grenzen der Region: Diese reichte von Kassel im Norden und Aschaffenburg im Osten bis nach Koblenz im Westen und Saarbrücken im Süden.

In der Zeit des Nationalsozialismus wurde die Region kurzzeitig politisch im NS-Gau Hessen-Nassau zusammengefasst – dieser hatte nur kurz Bestand, ist aber die erste politische Institutionalisierung des Rhein-Main-Gebietes. 1945 wurde die Grenze zur später auf Kosten der britischen und amerikanischen Zone eingerichteten Französische Besatzungszone von den Alliierten willkürlich im Rhein festgelegt. Die Besatzungsmächte gründeten in der Folge die noch heute bestehenden Bundesländer jeweils auf ihrem Territorium. Durch die (französische) Gründung des neuen Landes Rheinland-Pfalz wurde Rheinhessen von Hessen abgetrennt, die Region (und sogar das Stadtgebiet von Mainz) wurde erneut administrativ geteilt.

Mit Aufkommen der Regionalplanung in Deutschland begann auch im Rhein-Main-Gebiet, vor allem in der engeren Stadtregion Frankfurt, eine Phase der Institutionalisierung. Durch starke Suburbanisierung wurde eine Lösung der anstehenden Probleme im regionalen Maßstab immer dringender. Während der 1960er Jahre wurde lange um Stadtkreis- und Regionalstadtmodelle gerungen, die stets den Wegfall administrativer Ebenen mit sich gebracht hätten. 1975 wurde als Kompromiss der Umlandverband Frankfurt (UVF) per Landesgesetz ins Leben gerufen – dieser war ein sogenannter Mehrzweckpflichtverband und sollte zahlreiche Aufgaben übernehmen: Zum einen sollte er für die 43 Mitgliedskommunen die Flächennutzungsplanung im Rahmen eines gemeinsamen Flächennutzungsplans übernehmen. Dazu kamen zahlreiche Trägerschaftsaufgaben, z. B. der Wasserver- und Abwasserentsorgung, der Abfallentsorgung, regionaler Freizeiteinrichtungen u. a. Der UVF konnte seinen Aufgaben allerdings nicht überall nachkommen, da ihm zahlreiche Einrichtungen nicht wie vorgesehen überlassen wurden.

Der Umlandverband geriet schnell in die Kritik. Diese gipfelte 1995 im sogenannten „Jordan-Papier“ des SPD-Bezirks Hessen-Süd, mit dem eine Neuordnung des Regierungsbezirk Darmstadt durch Regionalkreise vorgeschlagen wurde.

1999 griff die neu gewählte CDU/FDP-Landesregierung unter Roland Koch die Kritik am Umlandverband auf und schuf im Jahr 2000 mit dem Ballungsraumgesetz eine neue Regionalstruktur: Der Umlandverband Frankfurt wurde durch den Planungsverband Ballungsraum Frankfurt/Rhein-Main abgelöst, das Aufgabenspektrum auf die Planung reduziert und das Verbandsgebiet (Ballungsraum) von 43 auf 75 Kommunen erweitert. Sämtliche Trägerschaftsaufgaben des UVF sollten sich freiwillig in der Region organisieren und von einem „Rat der Region“, gebildet aus Oberbürgermeistern und Landräten, gelenkt werden. Auf eine demokratische Legitimation dieses Konstruktes wurde verzichtet, das Parlament des Umlandverbandes wurde durch die Verbandskammer des Planungsverbandes ersetzt. Im Vergleich zu anderen Regionalisierungen bleibt die Abgrenzung des Ballungsraumes jedoch deutlich hinter den tatsächlichen wirtschaftlichen Verflechtungen der Kernstädte mit ihrem Umland zurück. Mittlerweile hat die Landesregierung von ihrem Recht, regionale Kooperation zu verordnen zweimal Gebrauch gemacht: Zum einen wurde so die Wirtschaftsförderung Region FrankfurtRheinMain als Gemeinschaftsunternehmen einiger Kernstädte sowie einiger Landkreise gegründet (2005). Diese soll sich um die einheitliche Vermarktung bzw. Präsentation der Region bemühen. Derzeit läuft noch die von der Landesregierung festgelegte Frist zur Bildung eines Kulturzweckverbands – da jedoch einige Kommunen eine Umverteilung von Geldern zu Gunsten der Kernstadt Frankfurt und ihres kulturellen Angebots vermuten, lehnen zahlreiche betroffene Kommunen diesen Verband strikt ab. Die Städte Hanau und Offenbach haben Klagen vor dem hessischen Verwaltungsgerichtshof eingereicht.

Das Ballungsraumgesetz wurde von Beginn an heftig kritisiert, z. B. aufgrund eines Eingriffsrechts der Landesregierung, mit dem diese regionale Kooperation per Erlass initiieren kann und wegen der fehlenden demokratischen Legitimation. In der Folge wurden zahlreiche Initiativen gestartet, die eine Neuordnung der Region versuchten: So wurde von der Frankfurter Oberbürgermeisterin Petra Roth ein „Stadtkreismodell“ vorgelegt, das den Zusammenschluss von Frankfurt mit seinen Nachbargemeinden in einem Kreis vorsah. Die SPD Hessen legte ein Konzept vor, mit dem Hessen insgesamt in vier Regionalkreise unterteilt werden sollte. Keines der Konzepte konnte sich jedoch bislang durchsetzen, so dass die Region Rhein-Main nach wie vor politisch fragmentiert ist.

Das Ziel einer „vereinten“ Region verfolgen auch zahlreiche Initiativen in der Region: Dazu gehörte z. B. die "Metropolitana", hervorgegangen aus einer Artikelserie der Frankfurt Rundschau (2000–2001), die sich als Verein formierte und später mit der Wirtschaftsinitiative FrankfurtRheinMain fusionierte. Auch mit Hilfe einer Bauausstellung – vergleichbar der "IBA Emscher Park" im Ruhrgebiet – sollte das Regionalbewusstsein in der Region mehrfach befördert werden. Eine IBA wurde bereits in Zusammenhang mit der Metropolitana diskutiert, im Jahr 2004 wurde die Idee aufgegriffen und ein Frankfurter Architektur- und Planungsbüro mit einer Machbarkeitsstudie beauftragt, die 2005 vorgelegt werden sollte. Zu den Initiativen, die sich um eine (politische) Stärkung der Region bemühen, ist auch das IHK Forum Rhein-Main zu zählen. 

Als Bürgerinitiative formierte sich Anfang 2004 die Regionalwerkstatt Rhein-Main. Unter Führung der Wirtschaftsinitiative FrankfurtRheinMain wurden im Rahmen eines Workshops Ideen zu Zukunft der Region gesammelt. Obwohl die Resonanz anfangs groß war, gelang es den Organisatoren nicht, die Begeisterung für die Idee einer Region Rhein-Main weiter zu tragen, so dass die Initiative im Sand verlief.

Auf Initiative und Einladung des Frankfurter Oberbürgermeisters Peter Feldmann fand am 17. April 2015 in der Paulskirche ein „Tag der Metropolregion“ statt. Mehrere hundert Vertreter aus Kommunen und Wirtschaft waren eingeladen, der damalige Präsident des europäischen Parlaments Martin Schulz hielt eine Rede. In einer Erklärung wird die Verabschiedung eines Staatsvertrags zwischen Hessen, Rheinland-Pfalz und Bayern gefordert.

Am 18. Januar 2018 hat sich das "Strategieforum FrankfurtRheinMain" erstmals getroffen. Unter dem Vorsitz des Chefs der hessischen Staatskanzlei Axel Wintermeyer versammelt es Vertreter der Landesregierungen von Hessen, Rheinland-Pfalz, Bayern und Baden-Württemberg, Kommunalvertreter sowie Vertreter von Industrie- und Handelskammern. Als informelles Gremium will es Empfehlungen erarbeiten, hat jedoch keine Entscheidungsbefugnisse.

Mit Ausnahme des bayerischen Gebietsanteils und des Frankfurter Stadtteils Bergen-Enkheim und des Main-Kinzig-Kreises gehört das Rhein-Main-Gebiet zur Evangelischen Kirche in Hessen und Nassau. Main-Kinzig und Bergen-Enkheim gehören zur Evangelischen Kirche von Kurhessen-Waldeck. Aschaffenburg und Miltenberg gehören zur Evangelisch-Lutherischen Kirche in Bayern.

Bei der katholischen Kirche haben vier Diözesen Anteil an der Region, nämlich Mainz an den früher zu Hessen-Darmstadt gehörenden Gebieten, Limburg an den früher zu Nassau, Frankfurt und Hessen-Homburg gehörenden Gemeinden und Fulda an den früher kurhessischen Orten. In dieser Hinsicht ist die Stadt Frankfurt dreigeteilt. Die beiden bayerischen Landkreise um Aschaffenburg gehören zum Bistum Würzburg.


In der Kulturregion Frankfurt/Rhein-Main haben sich 46 Städte und Landkreise des Rhein-Main-Gebiets sowie der Regionalverband zusammengeschlossen. Die gemeinnützige Gesellschaft fördert seit 2005 die Zusammenarbeit zwischen den Kommunen und informiert über Kulturangebote und Ereignisse in der Region. In der Route der Industriekultur werden 1000 Industriebauwerke auf den 160 Kilometern zwischen Miltenberg und Bingen am Rhein zu einer Erlebnisroute über das Industriezeitalter verknüpft. 

Der Kulturfonds Frankfurt/Rhein-Main koordiniert und fördert seit 2007 kulturelle Projekte in der Region. Zum Fonds tragen hessische Städte und Landkreise der Region sowie das Land Hessen bei. 





</doc>
<doc id="4391" url="https://de.wikipedia.org/wiki?curid=4391" title="Remittende">
Remittende

Als Remittenden (lat. "" „zurückschicken“) werden meist Bücher, seltener auch andere Waren bezeichnet, die der Handel an den Verlag zurückschickt. 
Gründe dafür können Mängel an einzelnen Büchern sein, die Aufhebung des gebundenen Ladenpreises durch den Verlag oder vereinbarte Konditionen der Buchhandlung mit dem Verlag, die die Rücksendung und Erstattung eines Prozentsatzes des Jahresbezugs erlauben.
Auch Barsortimente erlauben in der Konditionsgestaltung mit den Buchhandlungen die Remission eines Prozentsatzes des Jahresbezugs.

Bei remittierten Büchern, die "lieferbar und neuwertig" sind, bleibt die Buchpreisbindung erhalten.

Sind die Remittenden beschädigt, spricht man von Mängelexemplaren, die zu reduzierten Preisen verkauft werden dürfen. Scheinmängelexemplare umgehen die Preisbindung, indem Bücher ohne tatsächlichen Mangel als Mängelexemplare klassifiziert und verkauft werden.

In der Wirtschaft werden wegen Mängeln oder bei Nichtgefallen zurückgesendete Waren ebenfalls als Remittenden bezeichnet.


</doc>
<doc id="4394" url="https://de.wikipedia.org/wiki?curid=4394" title="Links und rechts">
Links und rechts

Links und rechts ist eine Zuordnungsbeschreibung der zwei durch die Vertikale getrennten Seiten aus der Perspektive des Betrachters. Damit verbunden sind zwei gleichnamige einander entgegengesetzte Richtungsangaben. In der Konnotation abweichend meint die Bezeichnung bei der Oberfläche von Stoffen die Außen- (rechts) und die Innenseite (links) (siehe Bekleidung, Textilien, Lochung).

In einer aufrechten Position mit Blickrichtung Norden befindet sich links der Westen und rechts der Osten.

Die rechte und linke Hand sind nicht identisch, auch wenn sie gleich groß sind. Sie unterscheiden sich in ihrer Händigkeit, sie sind "chiral".

Die Gesetze der Physik sind weitgehend, aber nicht vollständig symmetrisch, was links und rechts angeht. Man kann ein physikalisches Experiment durchführen, bei dem Unterschiede zwischen beiden Richtungen bei der Messung zur Festlegung von links und rechts dienen können. Diese Spiegelsymmetrie wird als Paritätsverletzung bezeichnet. Sie tritt nur im Zusammenhang mit der schwachen Wechselwirkung auf.

Für Objekte kann eine linke und rechte Seite definiert werden, dabei stellt sich häufig die Frage, ob dies vom Standpunkt des Betrachters oder einem anderen Standpunkt aus gesehen wird.

Linke und rechte Körperhälfte sowie rechte und linke Körperteile werden anatomisch aus der Sicht des Individuums beschrieben. Die Unterscheidung von rechts und links muss im Kindesalter gelernt werden. Fachlich spricht man von „egozentrischer“ Sicht. Die Übertragung dieser Sichtweise auf die Körper anderer Personen erfordert einen weiteren Lernschritt.

Bei den Schnecken gibt es, meist artspezifisch, links- und rechtsgewundene Schneckenhäuser. Die Windung des Gehäuses wird von der Spitze (Apex) aus betrachtet: eine Drehrichtung gegen den Uhrzeigersinn – dann liegt die dem Betrachter zugewandte Gehäusemündung links – ist linksgewunden (sinistral), eine Drehrichtung im Uhrzeigersinn ist rechtsgewunden (dextral). Das Gehäuse der weitaus meisten Schneckenarten ist rechtsgewunden. Ein so genannter Schneckenkönig ist eine einzelne Schnecke, deren Gehäuse in die spiegelbildliche, artuntypische Richtung gewunden ist. Die Gefleckte Weinbergschnecke beispielsweise ist rechtsgewunden, ein „Schneckenkönig“ tritt bei dieser Art mit einer Häufigkeit von 1:20.000 auf.

Die weitaus meisten Tiere gehören zu den Bilateria (Zweiseitentiere) mit einer linken und einer rechten Körperhälfte, die zueinander weitgehend spiegelsymmetrisch sind. Diese Bilateralsymmetrie ist jedoch nicht vollkommen – so gibt es Asymmetrien in der Anordnung unpaarer (einfach ausgebildeter) innerer Organe wie Herz und Leber, jeweils geringfügige Abweichungen bezüglich Lage, Form und Größe der Augen, Ohren, Gliedmaßen usw. zueinander oder in der Geometrie von Schneckenhäusern.

Die talwärtige Blickrichtung, also flussabwärts, in Fließrichtung von der Quelle zur Mündung, legt das linke und das rechte Ufer eines Flusses fest.

Bei Schriftstücken, Bildern und Karten definiert der Standpunkt des Betrachters die linke und rechte Seite. So werden Personen oder Gegenstände auf Bildern im deutschen Sprachraum meistens „von links nach rechts“ (v. l. n. r.) benannt.

In vielen Sprachen schreibt man wie im Deutschen von links nach rechts. In anderen Sprachen, zum Beispiel im Hebräischen und im Arabischen, wird von rechts nach links geschrieben. Die Indischen Ziffern schreibt man in Schriften beiderlei Schreibrichtung jeweils mit der Einerstelle rechts und jeder weiteren Stelle links davon.

Auf einer Landkarte befindet sich meistens oben Norden, unten Süden, links Westen und rechts Osten. Karten der Nordpolregion oder der Antarktis werden so orientiert, dass der vom mittigen Pol ausgehende Nullmeridian 
senkrecht nach unten bzw. – vom Südpol – nach oben weist. Damit liegt auf jeder dieser Pol-Karten die West-Hemisphäre links und die östliche rechts. 
Grundrisse von Gebäuden werden meist so gezeichnet, dass die Längsseiten parallel zum Papier gezeichnet sind. Die nördliche Himmelsrichtung wird dann mit einem passend ausgerichteten Nordpfeil eingezeichnet.

Orientierungspläne auf Tafeln etwa von Gebäudegängen, Messegeländen, Einkaufszentren, Wohnsiedlungen werden als vertikale Tafel günstig so orientiert, dass rechts am Plan beim parallelen Blick über die oder neben der Tafel vorbei auch rechts in der Natur entspricht – ein Nordpfeil am Plan weist dann im Allgemeinen nicht nach oben.

Bei medizinischer Behandlung am menschlichen Körper darf mit hoher Sicherheit keine Verwechslung der Seiten vorkommen. So wird grundsätzlich auf jedem Röntgenbild markiert, welche Körperseite, oder Extremitäten welcher Seite abgebildet werden. Durch die Chiralität der Anfangsbuchstaben L und R – im Deutschen – eignen sich diese grafisch optimal zur Anzeige sowohl der Körper(teil)seite als auch der korrekten Betrachtungsrichtung des Röntgenbilds, das auf beidseitig beschichtetem Film vorliegt. Der Röntgenstrahlenkegel läuft etwa von oben durch eine Hand oder einen Lungenflügel hindurch auf eine (lichtdichte) Röntgenfilmkassette, auf diese wird dazu der Markierungsbuchstabe ("Bleizeichen," aus Messing oder NiRo) für die entsprechende Körperseite gelegt. Dieser Buchstabe ist dann aus Betrachtungsrichtung (wie Belichtungsrichtung von oben) grafisch seitenrichtig lesbar. Bei Durchleuchtung der Lunge des stehenden Menschen also Bestrahlung von hinten und gleichzeitiger Betrachtung am Fluoreszenzschirm von vorne wird das Bild jedoch aus der Gegenrichtung betrachtet. Wird ein Röntgenbild in dieser Projektionsart angefertigt, ist der Buchstabe umzudrehen, oder ein Aufsteckbuchstabe in Spiegelschrift zu verwenden, damit er bei üblicher Betrachtung „gegen den Röntgenstrahl“ seitenrichtig erscheint.

Kleinbildfilm wird durch das Objektiv auf der Schichtseite belichtet und als Diapositiv oder negativ genau im umgekehrten Strahlengang auf Leinwand oder Papierbild projiziert („vergrößert“). Links und rechts, genauso wie oben und unten sind in Natur und auf Film, bzw. Film und Leinwand (Bild) vertauscht, jeweils aus Sicht des Fotografen hinter der Kamera oder des Projektorbedieners. Diese Abbildung entspricht jeweils einer Drehung um 180° in der optischen Achse. Kleinbildflme sind mitunter an den Randstreifen so mit Aufnahmenummern versehen, dass sie mit dem Negativ seitenrichtig zu lesen sind, wenn nicht wie bei Rollei 35 die Filmeinlegerichtung unüblich orientiert ist.

Bei Fahrzeugen definiert die hauptsächliche Fahrtrichtung die linke und rechte Seite, beispielsweise fährt man in Kontinentaleuropa und vielen anderen Teilen der Welt auf der in Fahrtrichtung rechten Seite der Fahrbahn (Rechtsfahrgebot), es befindet sich das Lenkrad von Kraftfahrzeugen auf der linken Seite (um den Gegenverkehr besser beurteilen zu können; nur LKW des mittleren 20. Jahrhunderts hatten auch in rechts fahrenden Ländern das Lenkrad rechts, um sich am rechten Straßenrand zu orientieren), es gilt der Vorrang rechts vor links.

Bei Wasserfahrzeugen bezeichnet man rechts als "Steuerbord" (weil das Steuerruder der Galeere ursprünglich rechts war, mittig am Heck ist eine neuere Erfindung) und links als "Backbord," entsprechend gilt allerdings nur für motorisierte Wasserfahrzeuge untereinander eine Vorfahrtsregel Steuerbord vor Backbord.

Bei Personen definiert der Standpunkt der beschriebenen Person die linke und die rechte Seite. Somit ist das linke Auge das linke Auge in Blickrichtung der beschriebenen Person, obwohl dies für einen gegenüberstehenden Betrachter rechts liegt. Dies gilt auch für alle anderen Organe; 
z. B. befindet sich die Leber des Menschen auf der rechten Seite, obwohl diese in anatomischen Darstellungen auf der linken Seite eingezeichnet ist.

In der Medizin werden dafür die lateinischen Bezeichnungen "dexter" (rechts) und "sinister" (links) verwendet.

Sehe ich mich selbst im Spiegel, sehe ich meine rechte Gesichtsseite auch im virtuellen Spiegelbild rechts. Dieses Spiegelbild ist seitenvertauscht zur Direktansicht, das andere Personen von mir gewinnen, die mir ins Gesicht sehen. Das macht Kommunikation missverständlich, wenn man das Gegenüber mit Fingerzeig oder Worten dezent darauf hinweisen will: „Du hast auf deiner rechten Wange einen Gulaschspritzer.“

Erst 2 Spiegel, die sich einem von einer senkrechten Achse um 90° öffnen, bilden das eigene Gesicht (und auch andere Personen neben einem) durch doppelte Spiegelung seitenrichtig ab. Die Trennfuge der Spiegelkanten läuft mitten durch das Gesicht, wenn nicht der Winkel der Spiegel zueinander etwas in Richtung spitzer verkleinert wird, wodurch man umso mehr Teile seines Gesichts zweimal sehen kann, je breiter die Spiegel sind. Ein mehrflächiges Pentaprisma am Kopf einer Spiegelreflexkamera macht nichts anderes, da das Bild am waagrechten Bildschirm durch den Umlenkspiegel gegenüber dem von hinten gesehenen Bild in der Filmebene schon oben-unten vertauscht erscheint.

Betrachtet man bei Videochat oder -telefonie über eine Kamera – meist am oberen Bildschirmrand platziert – sein eigens Bild am Bildschirm, so erwartet man sein eigenes Spiegelbild, weshalb Hard- oder Software dem Empfänger das aufgenommene Bild übermitteln, jedoch beim Absender gespiegelt darstellen. Rücke ich also vor dem Bildschirm nach rechts, rückt auch mein Bild hin zur rechten Bildschirmseite. So verhalten sich auch (und nur die) bildschirmseitigen Frontkameras von Smartphones und Tablets, sowie die zusätzlichen Frontbildschirme, die manche Digitalkameras für Selbstporträts auf ihrer Objektivseite aufweisen.

Im Gegensatz zu Bildern definiert in der Heraldik der Standpunkt des Schildträgers die linke und rechte Seite eines Wappens. Es ist also beispielsweise bei in Büchern abgebildeten Wappen diejenige Wappenseite die linke, welche sich vom Betrachter der Buchseite aus gesehen rechts der Wappenmitte befindet.

Der Ausdruck gehört zur Fachsprache der Blasonierung (Wappenbeschreibung).

Bei Schrank- und Durchgangstüren, sowie Fenstern definiert in Deutschland vereinbarungsgemäß die Bandseite ihre Seitigkeit, und zwar von dem Raum aus gesehen, nach dem sich die Türe hin öffnet. Die Band- oder auch Anschlagsseite einer Tür ist diejenige, an der sich ihre Bänder (auch Angeln oder Scharniere genannt) befinden, die also der sich öffnenden Kante mit Griff und Schloss gegenüberliegt. Ausgehend von dieser Betrachtung werden auch die jeweils zugehörigen unsymmetrischen Türbeschläge (Bänder, Schlösser, Griffe [Türdrücker, Oliven, Schließer] etc.) als rechts- oder linksseitig bezeichnet.
Bei Durchgangstüren unterscheiden sich die schweizerische Norm des VSSM und die europäische DIN-Norm:
Nach der europäischen DIN-Norm wird ein Schloss, das zu einer links gebandeten Türe passt, als linkes Schloss bezeichnet. In der schweizerischen Norm des VSSM wird dasselbe Schloss allerdings als rechtes Schloss bezeichnet.
Das ergibt folgende Situation:
DIN: linkes Band, linkes Schloss, linke Tür;
jedoch VSSM: linkes Band, rechtes Schloss, linke Tür.
Die an Zimmertüren häufig verwendeten Einschraubbänder sind jedoch ohnedies symmetrisch, Einstemmschlösser durch Wenden der Schließfalle (der schräg federnd herausragende Teil) um ihre waagrechte Achse trotz chiralem Innenleben vor dem Einbau auf rechts oder links einstellbar und so arretierbar.

Bei Kleidungsstücken bezeichnet rechts die nach außen sichtbare Oberfläche, während links die Innenseite, auch Abseite, bezeichnet. Von Bedeutung sind rechts und links auch beim Stricken, bei vielen – etwa einseitig bedruckten oder behandelten, mustergewebten, Samt-Stoffen, geknüpften Teppichen, auch geprägtem und nicht gratfrei gestanztem Lochblech oder Holzfaserplatte, kalandrierter Kunststofffolie, Papier, als Zwilling gewalzter Alufolie.

Am Theater werden links und rechts stets als vom Zuschauer aus gesehen definiert und als Bühnenlinks bzw. Bühnenrechts bezeichnet. Für den Darsteller bedeutet das eine Umkehrung der Richtungen: das Bühnenlinks wird vom Zuschauer als links gelegen gesehen und darum auch für den Darsteller als links bezeichnet. Diese den Darsteller betreffende Umkehrung der Richtungen unter Verwendung der Bezeichnungen links und rechts findet allerdings keine Anwendung, da immer wieder Missverständnisse aufgetreten sind, wenn während der Proben vom Regiepult im Zuschauerraum Spielanweisungen gegeben wurden und auch während Vorstellungen sichergestellt werden musste, Irrtümer der Darsteller hinsichtlich des szenisch „richtigen“ Auftritts auszuschließen. Aus diesem Grunde gibt es an Opernhäusern bzgl. der Bühnenseiten die Bezeichnungen links und rechts nicht mehr. An der Staatsoper Unter den Linden Berlin heißen sie „Berlin“ und „Charlottenburg“, am Richard-Wagner-Festspielhaus Bayreuth „West“ und „Ost“, am Staatstheater am Gärtnerplatz München „Klenzestraße“ und „Reichenbachstraße“ und am Teatro Real Madrid „Calle Felipe V“ und „Calle Carlos III“, um nur einige zu nennen.

Bei Eisenbahnstrecken sind Bahnlinks und Bahnrechts in Blickrichtung der aufsteigenden Kilometrierung definiert. Üblich sind auch die Begriffe „links der Bahn“ sowie „rechts der Bahn“.
In Österreich ist für betriebliche Zwecke die Richtung vom Anfangspunkt zum Endpunkt einer Strecke maßgeblich für „links der Bahn“ und „rechts der Bahn“. Diese Definition muss nicht mit der aufsteigenden Kilometrierung übereinstimmen. Für technische Beschreibungen (linke Schiene / rechte Schiene etc.) wird im Regelfall die aufsteigende Kilometrierung als Referenz genommen.

Das indogermanische "reg" als sprachgeschichtliche Wurzel stand eigentlich für "geradeaus," "aufrichten," "recken," "geraderichten" und wurde auch für das Gute, Wahre und Vollkommene angewandt. Die Verwendung derselben Wortwurzel für die Richtung „rechts“, "richtig" und das Recht ( vs. ) existiert unter anderem auch im Englischen (), im Französischen (), im Spanischen (), in den slawischen Sprachen (, , ) und im Persischen ("rast").

Das neuhochdeutsche "link(s)" geht zurück auf ; die ursprüngliche Bedeutung war „ungeschickt“ (vgl. „linkisch“). "Jemanden linken," "eine Linke drehen" heißt ugs. "betrügen". Andere Ausdrücke sind im Lauf der Jahrhunderte ungebräuchlich geworden oder nur mundartlich erhalten geblieben (mittelhochdeutsch ).

Einige Menschen haben Schwierigkeiten, sich egozentrisch (d. h. nach der Rechts-Links-Strategie) zu orientieren. Bei der egozentrischen Orientierung handelt es sich um eine kulturelle Konvention. Verhaltensbiologische Experimente an Menschenaffen, Kindern und Erwachsenen von Naturvölkern und aus dem westlichen Kulturkreis haben gezeigt, dass der Mensch ursprünglich eine allozentrische Prägung hat, sich also an der Umgebung und den Himmelsrichtungen orientiert. Diese evolutionär sehr alte Umgebungs-Strategie wird erst von einer Prägung durch Sprache und Kultur überlagert. Die natürliche Verhaltensweise, den Ort eines Gegenstandes im Verhältnis zur Umgebung zu erfassen, wird also im Laufe der Kindheit durch die erlernte Fähigkeit überdeckt, die Position eines Objektes in Relation zum eigenen Körper zu beschreiben. Das bereitet etwa 20 bis 30 % der Menschen Schwierigkeiten, wobei zwischen den Geschlechtern keine großen Unterschiede gefunden wurden. Rund 120 Mal im Jahr werden Patienten in deutschen Krankenhäusern auf der falschen Seite operiert (2010).




</doc>
<doc id="4395" url="https://de.wikipedia.org/wiki?curid=4395" title="Reflexiv">
Reflexiv

Reflexiv (lateinisch „rückbezüglich“) bezeichnet:

Siehe auch: 


</doc>
<doc id="4396" url="https://de.wikipedia.org/wiki?curid=4396" title="Relation">
Relation

Als Relation ( ‚das Zurücktragen‘), Beziehung, wird im Allgemeinen ein Verhältnis zwischen einem Seienden oder Ereignis zu einem oder mehreren anderen bezeichnet. „Im einzelnen gibt es einseitige und wechselseitige Beziehungen.“

Der Begriff der Relation steht im engen Zusammenhang mit den Begriffen Struktur und System. In der Systemtheorie versteht man unter der Struktur eines Systems die Menge aller Relationen zwischen den einzelnen Elementen des Systems.

Beim Begriff Relation muss man zwischen konstruierten Beziehungen "(relatio rationis)" und realen Beziehungen "(relatio in natura)" unterscheiden. Von realen Beziehungen spricht man, wenn Objekte sich in irgendeiner Form tatsächlich aufeinander beziehen. Von konstruierten (gedachten) Beziehungen spricht man, wenn Objekte in Beziehung gesetzt werden, etwa hinsichtlich ihrer Größe, Lage, Existenzdauer oder anderer Daten.

In der Logik wird die Bezeichnung Relation oft synonym zum Begriff mehr-, insbesondere zweistelliges Prädikat verwendet.

Relationen werden in der Regel nach den Merkmalen der Reflexivität, Symmetrie (auch Antisymmetrie und Asymmetrie) und Transitivität eingeteilt. Für die wissenschaftliche Forschung ist es darüber hinaus bedeutsam, partikuläre oder vollständige, punktuale, ein- oder mehrdimensionale sowie stellenmäßig bestimmte oder unbestimmte Relationen zu unterscheiden.

Von besonderer Bedeutung ist die Unterscheidung in "äußere" und "innere" Relationen: von "inneren Relationen" spricht man dann, wenn alle zueinander in Relation stehenden Objekte zueinander in demselben Referenzsystem definiert sind und eine Änderung des Referenzsystems die Relation zwischen den Objekten nicht verändert. Innere Relationen sind also invariant gegenüber Transformationen des Referenzsystems.



</doc>
<doc id="4398" url="https://de.wikipedia.org/wiki?curid=4398" title="Brasilianischer Pfefferbaum">
Brasilianischer Pfefferbaum

Der Brasilianische Pfefferbaum ("Schinus terebinthifolia"), auch Weihnachtsbeere genannt, gehört zur Familie der Sumachgewächse (Anacardiaceae). 

Der Brasilianische Pfefferbaum wächst als Strauch oder kleiner Baum und erreicht Wuchshöhen von bis zu 9 Metern. Er hat eine rundliche Krone und grünlich-bronzefarbene, gefiederte Blätter. Die winzigen, gelblich-weißen Blüten sind in Rispen angeordnet und werden im Sommer gebildet. Aus ihnen entwickeln sich später kleine grüne Beeren, die sich während der Reife zu den auffälligen, roten, lange haltbaren Früchten entwickeln und in dichten Rispen beisammenstehen. Das glänzende Laub verströmt einen pfeffrigen Geruch, wenn man es reibt oder bricht.

Die Chromosomenzahl beträgt 2n = 28.

"Schinus terebinthifolia" enthält 3,3 bis 5,2 % ätherisches Öl. Dieses besteht vor allem aus den Monoterpenen α- und β-Phellandren, Limonen, p-Cymol, Silvestren, Myrcen, α-Pinen, trans-Terpin, Perillaaldehyd, 3-Caren und Carvacrol. Außerdem enthalten die Früchte Cardanole, ihre Konzentration schwankt zwischen 0,03 % (in Réunion) und 0,05 % (in Florida). Einige Zeit nach dem Verzehr können Schleimhautreizungen auftreten. Hauttests mit Cardanol erwiesen starke hautreizende Wirkung mit langer Latenzzeit. Vermutlich können von den Früchten ausgehende Dämpfe Kopfschmerzen, Schwellungen der Augenlider und Atmungsdepressionen hervorrufen. Obwohl nach Schwenker & Skopp nach Selbstversuchen und Verwendung als Gewürz keine Reizwirkung von der Pflanze ausging, sollte sie als giftig betrachtet werden.

Die Früchte dieser brasilianischen Gewürzpflanze werden unter der Bezeichnung „Rosa Pfeffer“, „Rosé Pfeffer“ oder „Rosa Beeren“ als Gewürz verwendet, sie sind jedoch kein echter Pfeffer, sondern werden buntem Pfeffer (schwarz, weiß und grün) aus optischen Gründen anstelle des verderblichen roten Pfeffers beigemischt. Sie sind von mild aromatischem Geschmack. Die Früchte werden gerne als Weihnachtsschmuck verwendet, darauf beruht auch der Zweitname „Weihnachtsbeere“.

Der Brasilianische Pfefferbaum ist in Mittel- und Südamerika beheimatet.
In den USA ist die 1840 als Zierpflanze nach Florida importierte Art heute unerwünscht, da sie verwildert und natürliche Biotope überwuchert. Große Gebiete der Everglades sind heute reine Pfefferbaum-Bestände und es wird mit Millionen-Dollar-Einsatz versucht, Bereiche wieder von dieser Pflanze zu befreien. Der Besitz oder die Pflanzung ist in Florida strafbar.
Die Bäume sind frostempfindlich und benötigen eine Mindesttemperatur von 5 °C.




</doc>
<doc id="4402" url="https://de.wikipedia.org/wiki?curid=4402" title="REXX">
REXX

REXX ("Restructured Extended Executor") ist eine von Mike Cowlishaw bei IBM entwickelte Skriptsprache.

REXX stammt aus dem Großrechnerbereich. Mike Cowlishaw hatte es in den 1980er Jahren als Nachfolger der Skriptsprache EXEC 2 unter VM zuerst implementiert (der Unterschied zwischen dem relativ simplen und nicht sehr mächtigen EXEC-2 und REXX ist ähnlich groß wie der zwischen der MS-DOS Batch-Sprache und BASIC). REXX steht dabei für „Restructured EXtended eXecutor“ (Language). REXX wurde auf TSO und andere Umgebungen wie OS/2 portiert. Eine angepasste Version – genannt ARexx – erfreut sich seit 1987 auch auf dem Amiga großer Beliebtheit, da beinahe jedes wichtige Programm damit „fernsteuerbar“ ist. Mittlerweile sind auch Interpreter für fast alle Umgebungen bis hin zum Palm OS erhältlich. 1996 wurde REXX zum ANSI-Standard (ANSI X3.274-1996 „Information Technology – Programming Language REXX“).

REXX kann besonders leicht erweitert werden, indem dynamische Programmbibliotheken zum eigentlichen Interpreter hinzugeladen werden. Insbesondere unter OS/2 ist eine Vielfalt solcher Bibliotheken mit mathematischen, Datenbank-, Socket- und System-Funktionen verfügbar, die wie normale REXX-Funktionen angesprochen werden können.
REXX ist in der Regel eine interpretierte Sprache, aber für Linux und für IBM-Großrechner-Betriebssysteme sind auch REXX-Compiler verfügbar.

In "klassischem Rexx" (im Unterschied zum hier nicht behandelten, jedoch kompatiblen Objektorientierten Rexx) ist jeder Wert ein String – auch Zahlen. Es ist also ohne weiteres möglich, Zahlenwerte mit String-Manipulationen zu ändern und das Ergebnis sofort wieder als Zahl zu verwenden:

a = 2
a = a || '00'
say a / 2
Durch Anhängen zweier Nullen wird codice_1 mit 100 „multipliziert“; das Ergebnis, die Zeichenkette codice_2, kann sofort wieder als Zahl verwendet werden. Ausgegeben wird codice_3.

Folgerichtig ist die Arbeit mit Strings in Rexx sehr einfach.

Die obige Verkettungsoperation kann auch als
a = a'00'
geschrieben werden. Ein oder mehrere Leerzeichen zwischen codice_1 und codice_5 führen hingegen dazu, dass bei der impliziten Verkettung ein Leerzeichen eingefügt wird, was unerwünscht ist, wenn das Ergebnis eine Zahl sein soll.

Wenn eine Zahl benötigt wird, weil der verwendete Operator mit Zahlen arbeitet, versucht Rexx, den vorliegenden Wert als Zahl zu interpretieren:
say ' 1' + 2

gibt codice_6 aus.

Im Normalfall rechnet Rexx auf neun Dezimalstellen genau; durch Angabe einer höheren Anzahl kann jedoch fast beliebig genau gerechnet werden.
Diese wenig hardwarenahe Methode von Rexx führt dazu, dass arithmetische Operationen vergleichsweise langsam ausgeführt werden.

Rexx wurde unter anderem entwickelt, um auf einfache Weise Kommandos an eine Umgebung absetzen zu können. Dies wird unterstützt durch die folgende Strategie bei der Auswertung einer Anweisung, welche Rexx-Programme unempfindlich gegenüber neu eingeführten Schlüsselwörtern macht und die ein Alleinstellungsmerkmal der Sprache darstellt:

1. Wenn das zweite Token mit einem Gleichheitszeichen beginnt, handelt es sich um eine Wertzuweisung

Hieraus folgt, dass z. B.

if = 1

eine gültige Anweisung ist, die der Variablen "IF" den Wert "1" zuweist!

Hingegen wäre

if == 1

zwar ein gültiger logischer Ausdruck, der prüft, ob die Variable if exakt den Wert 1 hat; als eigenständige Anweisung ergibt sie jedoch einen Syntaxfehler, weil der zuzuweisende Wert "= 1" eben "kein" gültiger Ausdruck ist.

2. Ist das zweite Token ein Doppelpunkt, handelt es sich um eine Marke

Marken werden benötigt, um Prozeduren und Funktionen zu realisieren; diese notiert man in Rexx "nach" dem „ausführbaren Teil“ des Programms. Beispiel:

say: funk('dir x')
exit
funk: return Arg(1)
Man könnte erwarten, dass codice_7 zur Standardausgabe ausgegeben wird. Das Schlüsselwort codice_8 fungiert hier jedoch nur als Marke; der Ausdruck codice_9 bildet
schon die nächste Anweisung.
Gemäß Regel 4 (siehe unten) wird also codice_10 aufgerufen und codice_7 zur Ausführung an die Umgebung übergeben. (Es ginge natürlich auch ohne die Funktion codice_10; dies nur als sehr einfaches Beispiel für einen Funktionsaufruf)

Es ist auch möglich, mit codice_13 eine bestimmte Marke anzusteuern; dies ist eher unüblich und nur in bestimmten Fällen sinnvoll, z. B. als Alternative zu sehr großen codice_14-Anweisungen.

3. Wenn das erste Token ein Schlüsselwort ist, erfolgt die Auswertung entsprechend dieser Schlüsselwortanweisung

Solche Schlüsselwörter sind z. B. codice_15, codice_16, codice_8. Die späte Auswertung der Schlüsselwörter begünstigt Erweiterungen. Zukünftige Versionen der Sprache können so neue Schlüsselwörter einführen, ohne dass existierende Programme überarbeitet werden müssen: sowohl Variablen als auch Marken können ihren Namen behalten.

4. In jedem anderen Fall wird die Anweisung als Ausdruck ausgewertet und das Ergebnis an die Umgebung übergeben

Dies bedeutet, dass die folgende Rexx-Anweisung (unter DOS, Windows, OS/2, …) den Inhalt des aktuellen Verzeichnisses ausgibt:

dir

oder auch:

'dir'

Im ersten Fall ist codice_18 eine Variable; wurde ihr kein Wert zugewiesen, so ist ihr Wert codice_19 (ihr Name in Großbuchstaben), und es wird codice_19 an die Umgebung übergeben und ausgeführt. Im zweiten Fall wird garantiert codice_18 übergeben und ausgeführt.

Es könnte natürlich sein, dass eine zukünftige Rexx-Version ein Schlüsselwort codice_18 einführt. Um sicherzugehen, dass das Programm auch dann noch funktioniert, kann z. B. durch

"dir

erzwungen werden, dass die Anweisung als Ausdruck (Verkettung der Variablen mit dem Leerstring) erkannt wird;
oder man verwendet einfach die Variante, das Kommando als Stringkonstante zu übergeben.




</doc>
<doc id="4403" url="https://de.wikipedia.org/wiki?curid=4403" title="Rekursion">
Rekursion

Als Rekursion ( ‚zurücklaufen‘) bezeichnet man den abstrakten Vorgang, dass Regeln auf ein Produkt, das sie hervorgebracht haben, von neuem angewandt werden. Hierdurch entstehen potenziell unendliche Schleifen. Regeln bzw. Regelsysteme heißen "rekursiv," wenn sie die Eigenschaft haben, Rekursion im Prinzip zuzulassen.

Rekursion ist ein zentraler Begriff in Mathematik, Logik und Informatik und hat vielfältige Anwendungen darüber hinaus; diese reichen bis in die Kunst, wo das Phänomen auch als "mise en abyme" bezeichnet worden ist.

Rekursion ist auch eine Problemlösungsstrategie. Komplexe Sachverhalte können oft mit rekursiv formulierten Regeln sehr elegant erfasst werden. Das Grundprinzip ist dabei dann das Zurückführen einer allgemeinen Aufgabe auf eine einfachere Aufgabe derselben Klasse. Beispielsweise ist die rekursive Programmierung Bestandteil vieler Programmiersprachen. Prozeduren oder Funktionen können sich dabei selbst aufrufen. Rekursion und Iteration sind im Wesentlichen gleichmächtige Sprachmittel.

In Mathematik, Logik und Informatik erscheint Rekursion spezieller in der Form, dass eine Funktion in ihrer Definition selbst nochmals aufgerufen wird "(rekursive Definition)". Wenn man mehrere Funktionen durch wechselseitige Verwendung voneinander definiert, spricht man von "wechselseitiger Rekursion". Nicht jede rekursive Definition ist eine Definition im eigentlichen Sinn, denn die zu definierende Funktion braucht nicht wohldefiniert zu sein. Jeder Aufruf der rekursiven Funktion muss sich durch Entfalten der rekursiven Definition in endlich vielen Schritten auflösen lassen. Ist dies nicht erfüllt, so spricht man von einem infiniten Regress (in der Informatik auch als Endlosschleife bezeichnet).

Unter anderem können auch Punktmengen rekursiv definiert werden (dies ergibt die sogenannten Fraktale). Deren graphische Darstellung liefert ästhetisch ansprechende, "natürlich" aussehende Gebilde. Ein Beispiel ist der Pythagoras-Baum.
Der dazugehörige Algorithmus sieht folgendermaßen aus; der dritte Teil enthält die Rekursion:

Der Algorithmus wird dann bis zu einer vorgegebenen "Rekursionstiefe" entfaltet. Bei Rekursionstiefe eins entsteht ein Dreieck mit je einem Quadrat über den drei Seiten. Das sieht wie die Illustration zum Satz des Pythagoras aus – daher der Name. Je höher die Rekursionstiefe, desto mehr ähnelt das Gebilde einem Baum.

Die Grammatik natürlicher Sprachen wird in der Linguistik u.a. mit Hilfe von sogenannten Phrasenstrukturregeln beschrieben. Nach Ansicht der meisten Linguisten zeigen dabei alle menschlichen Sprachen die Eigenschaft, rekursiv aufgebaut zu sein (im Gegensatz zu Signalsystemen im Tierreich). Dies ergibt sich, weil in der Zerlegung einer grammatischen Einheit, die mit einer Kategorie etikettiert wird, dieselbe Kategorie erneut auftauchen kann. Ein Beispiel ist das Phänomen der Nebensätze, das hier mit folgender stark vereinfachter Produktionsregel beschrieben ist:


Diese Grammatik lässt die Wahl, ob die Ausbuchstabierung von „VP“ mit Regel 2 oder 3 erfolgen soll. Für den Fall, dass die Schritte 1 und dann 3 aufgerufen werden, ergibt sich eine Rekursion: Als Produkt von Regel 3 erscheint das Symbol S, das wiederum den Start für Regel 1 darstellt.

• Siehe auch: Produktionsregel

Die Funktion formula_1 soll zu jeder Zahl formula_2 die Summe der natürlichen Zahlen bis einschließlich formula_2 berechnen. Sie ist folgendermaßen "definiert":

Gleichwertig zu dieser Darstellung ist das Verfahren, eine rekursive Definition der Summenfunktion zu geben. Hierzu bestimmen wir zunächst den einfachen Fall, den "Rekursionsanfang". Im Beispiel handelt es sich um den Funktionswert für formula_5.

Übrig bleibt der schwierige Fall, also hier der Funktionswert für beliebige formula_7. Den schwierigen Fall führen wir auf einen einfacheren Fall zurück, nämlich auf den Fall formula_8. Dieser einfachere Fall wird unser rekursiver Aufruf. Die entsprechende Vorschrift heißt "Rekursionsschritt". Beispielsweise lässt sich die Summe der natürlichen Zahlen bis einschließlich formula_2 berechnen, indem man die Summe der natürlichen Zahlen bis einschließlich formula_8 berechnet und dazu die Zahl formula_2 addiert:

Diese beiden Gleichungen lassen sich zu einer rekursiven Definition der Summenfunktion zusammenfassen:

Es handelt sich hierbei um eine lineare Rekursion, denn in jedem der beiden Fälle (Rekursionsanfang und Rekursionsschritt) gibt es höchstens einen sum-Aufruf. Es ist sogar eine primitive Rekursion. Bei der dargestellten Definition handelt es sich um keine Endrekursion, denn nach dem rekursiven Aufruf formula_14 muss noch formula_2 addiert werden.

Die Summe der Zahlen von formula_5 bis formula_17 berechnet sich dann wie folgt:
Die Aufrufkette dazu sieht so aus:
Es gibt auch eine Charakterisierung der Summenfunktion ohne Rekursion: die Gaußsche Summenformel besagt, dass

Ein anderes klassisches Beispiel für eine rekursive Funktion ist die Fibonacci-Folge
Die Fibonacci-Funktion formula_22, die jedem formula_2 die formula_2-te Fibonacci-Zahl zuordnet, hat die einfachen Fälle formula_25 und formula_26 und genügt der Rekursionsgleichung
Es ergibt sich die rekursive Definition:

Diese rekursive Definition ist kaskadenförmig. Die dritte Fibonacci-Zahl wird folgendermaßen berechnet:
Die Berechnung für formula_31 wird hier mehrfach durchgeführt. Das deutet an, dass es Potential für Optimierungen gibt. Auch für die Fibonacci-Funktion gibt es einen gleichwertigen geschlossenen Ausdruck.

Das Grundprinzip der rekursiven Definition einer Funktion "f" ist: Der Funktionswert "f"("n"+1) einer Funktion "f" : N → N ergibt sich durch Verknüpfung bereits berechneter Werte "f"("n"), "f"("n"-1), …
Falls die Funktionswerte von "f" für hinreichend viele Startargumente bekannt sind, kann jeder Funktionswert von "f" berechnet werden. Bei einer rekursiven Definition einer Funktion "f" ruft sich die Funktion so oft selbst auf, bis eine durch den Aufruf der Funktion veränderte Variable einen vorgegebenen Zielwert erreicht oder Grenzwert überschritten hat (Terminierung, Abbruchbedingung).

Die Definition von rekursiv festgelegten Funktionen ist eine grundsätzliche Vorgehensweise in der funktionalen Programmierung. Ausgehend von einigen gegebenen Funktionen (wie z. B. der Summenfunktion) werden neue Funktionen definiert. Mit diesen können weitere Funktionen definiert werden.

Ein Spezialfall der Rekursion ist die primitive Rekursion, die stets durch eine Iteration ersetzt werden kann. Bei einer solchen Rekursion enthält der Aufrufbaum keine Verzweigungen, das heißt, er ist eine Aufrufkette: das ist immer dann der Fall, wenn eine rekursive Funktion sich selbst jeweils nur einmal aufruft. Der Aufruf kann dabei am Anfang ("Head Recursion", siehe Infiniter Regress) oder am Ende ("Tail Recursion" oder Endrekursion) der Funktion erfolgen. Umgekehrt kann jede Iteration durch eine primitive Rekursion ersetzt werden, ohne dass sich dabei die Komplexität des Algorithmus ändert.

Die häufigste Rekursionsform ist die "lineare Rekursion", bei der in jedem Fall der rekursiven Definition höchstens ein rekursiver Aufruf vorkommen darf. Die Berechnung verläuft dann entlang einer Kette von Aufrufen.

Die primitive Rekursion ist ein Spezialfall der linearen Rekursion. Hier definiert man Funktionen auf den natürlichen Zahlen, wobei in jedem rekursiven Aufruf dessen erster Parameter um Eins ab- oder zunimmt. Jede primitiv-rekursive Definition kann unter Zuhilfenahme eines Stapels durch eine Schleife (Programmierung) (z. B. For-Schleife oder While-Schleife) ersetzt werden.

Die "endständige" oder "repetitive" Rekursion ("Tail Recursion" oder Endrekursion) bezeichnet den Spezialfall der linearen Rekursion, bei der jeder rekursive Aufruf die letzte Aktion des rekursiven Aufrufs ist. Endrekursionen lassen sich unmittelbar durch While-Schleifen ersetzen und umgekehrt.

Unter "verschachtelter" Rekursion versteht man eine Rekursion, bei welcher rekursive Aufrufe in Parameterausdrücken rekursiver Aufrufe vorkommen. Diese Rekursionsform gilt als außerordentlich schwer zu durchschauen.

"Kaskadenförmige" Rekursion bezeichnet den Fall, in dem mehrere rekursive Aufrufe nebeneinander stehen. Die rekursiven Aufrufe bilden dann einen Baum. Kaskadenförmige Rekursion gilt als elegant, kann aber ohne weitere Maßnahmen einen exponentiellen Berechnungsaufwand nach sich ziehen. Sie wird gerne als Ausgangspunkt für die Ableitung einer anderen effizienteren Formulierung gebraucht.

Die "wechselseitige" Rekursion bezeichnet die Definition mehrerer Funktionen durch wechselseitige Verwendung voneinander. Sie lässt sich auf die gewöhnliche Rekursion einer tupelwertigen Funktion zurückführen.

Im Fall von primitiv-rekursiven Funktionen steht es dem Programmierer frei, eine iterative oder eine rekursive Implementierung zu wählen. Dabei ist die rekursive Umsetzung meist eleganter, während die iterative Umsetzung effizienter ist (insbesondere weil der Stack weniger beansprucht wird und der Overhead für den wiederholten Funktionsaufruf fehlt); siehe auch das Programmierbeispiel unten.

Manche Programmiersprachen (zum Beispiel in der Funktionalen Programmierung) erlauben keine Iteration, sodass immer die rekursive Umsetzung gewählt werden muss. Solche Sprachen setzen häufig zur Optimierung primitive Rekursionen intern als Iterationen um (einige Interpreter für LISP und Scheme verfahren so).

Es ist zu beachten, dass eine naive Implementierung bei manchen Funktionen (z. B. den Fibonacci-Zahlen) bedingt, dass Teillösungen mehrfach berechnet werden. Abhilfe schafft in diesem Beispiel die Memoisation, die auf der Wiederverwendung bereits berechneter Zwischenlösungen beruht. Die Rekursion ist ein wesentlicher Bestandteil einiger Entwurfsstrategien für effiziente Algorithmen, insbesondere der Teile-und-herrsche-Strategie ("Divide and Conquer"). Andere Ansätze (zum Beispiel sogenannte Greedy-Algorithmen) verlangen ein iteratives Vorgehen. Rekursion und primitiv-rekursive Funktionen spielen eine große Rolle in der theoretischen Informatik, insbesondere in der Komplexitätstheorie und Berechenbarkeitstheorie ("siehe" Lambda-Kalkül und Ackermannfunktion).

Im Compilerbau ist der rekursive Abstieg ("Recursive Descent") eine Technik, bei der eine Sprache rekursiv "geparst" wird.

Im folgenden Beispiel wird eine Zeichenkette von Offset 0 bis Offset n "implementativ iterativ" durchlaufen. Die Abbruchbedingung ist erfüllt, wenn der Iterator auf den Nullterminator der Zeichenkette stößt.

Jedoch lässt sich die Iteration einer Zeichenkette auch "implementativ rekursiv" darstellen, auch wenn die Aufgabenstellung nicht implizit "rechnerisch rekursiv" ist.

Das Beispiel zeigt eine beliebte und einfache Implementierung der Fakultätsberechnung mittels Pseudocode. Der rekursiven Variante wird hier zur Verdeutlichung eine iterative Variante gegenübergestellt. Dabei ist formula_2 die Zahl, deren Fakultät berechnet werden soll.

codice_1

Die Rekursion kommt in der vorletzten Zeile zum Ausdruck, wo die Funktion sich selbst mit einem um 1 verringerten Argument aufruft. Im nächsten Beispiel wird die Funktion nur einmal aufgerufen und arbeitet dann linear den gegebenen Algorithmus ab:

codice_2

Beim Lösen einer Rekursion sucht man zum einen den Laufzeitaufwand, zum anderen die explizite Form der Rekursion.

Der Aufwand kann als asymptotische Θ- bzw. Ο-Schranke mittels Mastertheorem bzw. Substitutionsmethode bestimmt werden. Auch das "geschickte Raten" mit anschließender Induktion bietet eine Möglichkeit, eine Oberschranke der Laufzeit zu ermitteln.

Die explizite Form (oder auch geschlossene Form genannt) der Rekursionsgleichung lässt sich beispielsweise durch die Erzeugende-Funktion finden. Eine zweite Möglichkeit bietet das "Ableiten" durch Differenzenbildung aufeinanderfolgender Funktionswerte der Rekurrenz.



</doc>
<doc id="4404" url="https://de.wikipedia.org/wiki?curid=4404" title="Rekursives Akronym">
Rekursives Akronym

Als Rekursives Akronym bezeichnet man eine Abkürzung, die in der Erklärung ihrer Bedeutung rekursiv auf sich selbst verweist, d. h. paradoxerweise ihre eigene Abkürzung als Teil des ausgeschriebenen Begriffs enthält (siehe Konstruktionsmethoden). Rekursive Akronyme sind normalerweise Initialwörter. Der Begriff wird auch für Abkürzungen gebraucht, die eigentlich keine Akronyme sind. Die meisten rekursiven Akronyme treten in Projekten der freien Software auf.

Echte rekursive Akronyme lassen sich mit einer einfachen Methode konstruieren:


Rekursive Akronyme sind nicht zu verwechseln mit einem Apronym oder Backronym.

Beispiel eines rekursiven Akronyms in Palindromgestalt, dessen Selbstreferenzierung auch seine sich selbst genügende Bedeutung umfasst:

Einige eng verwandte Phänomene sind streng genommen keine rekursiven Akronyme. Meist kommt die Abkürzung zwar im ausgeschriebenen Begriff als Wort vor. Sie ist allerdings nicht sich selbst gemeint, sondern ein echtes Wort mit gleicher Schreibweise. Bei anderen wird die Rekursion durch eine nachträglich von Dritten gefundene alternative Deutung der Buchstaben erzeugt.


</doc>
<doc id="4405" url="https://de.wikipedia.org/wiki?curid=4405" title="Rüsseltiere">
Rüsseltiere

Die Ordnung der Rüsseltiere (Proboscidea) wurde nach dem auffälligsten Merkmal, dem Rüssel (lat. "proboscis"), benannt. Ihre einzigen heute noch lebenden Vertreter sind die Elefanten.

Die Rüsseltiere unterscheiden sich nicht nur durch den überaus langen Rüssel, sondern auch durch ihren Körperbau und ihre charakteristische Bezahnung (Stoßzähne bzw. große Mahlzähne) von allen anderen Landsäugern. Besonders markant ist die Rüsselbildung, welche anfänglich kaum vorhanden war. Später entwickelte sich der Rüssel, der bei heutigen Tieren aus bis zu 150.000 längs, zirkular oder schräg verlaufenden Muskelfasern einer Vielzahl verschiedener Muskeln besteht, zu einem feinfühligen Greiforgan, welches das Erreichen der Blätter auf höheren Bäumen ebenso ermöglichte wie das Abreißen von Grasbüscheln in den Steppen.

Besondere skelettanatomische Merkmale sind die säulenförmigen Gliedmaßen, die senkrecht unter dem Körper stehen, wobei die oberen und unteren Partien der Extremitäten einen Winkel von 180° bilden. Dies unterscheidet die Rüsseltiere von zahlreichen anderen Säugetieren, deren Beine in einem leichten Winkel angeordnet sind. Die deutlich vertikale Stellung, die möglicherweise schon im Eozän vollständig ausgebildet war, unterstützte dabei die enorme Gewichtszunahme der frühen Vertreter dieser Ordnung. Weiterhin besitzen die Langknochen keine Knochenmarkhöhle, sondern der Raum ist mit Spongiosa gefüllt, was den Beinen eine größere Festigkeit gibt. Die Blutbildung findet dabei in den Zwischenräumen statt. Als weitere Besonderheit an den Füßen besitzen Rüsseltiere einen sechsten „Zeh“, der jeweils hinter dem Daumen bzw. dem großen Zeh ansetzt (Die Ansatzstelle befindet sich jeweils am oberen (proximalen), nach hinten innen zeigenden Gelenkende des Metacarpus I (Daumen) beziehungsweise des Metatarsus I (großer Zeh) und aus Knorpelmaterial besteht, das teilweise verknöchert ist. Er dient zur Unterstützung der anderen Zehen bei der Stabilisierung des hohen Körpergewichtes. Er ist schon bei den Deinotherien nachweisbar und geht so bis ins frühe Miozän zurück. Die Entwicklung dieser anatomischen Besonderheit hängt mit der enormen Körpergrößenzunahme der Rüsseltiere in jener Zeit zusammen, die verbunden ist mit der Abkehr von der eher amphibischen Lebensweise der frühen Probodscidea-Vertreter hin zu einer rein terrestrischen.

Eine andere Besonderheit weist der sehr große Kopf der Rüsseltiere auf, dessen Schädeldach aus luftgefüllten Hohlräumen besteht. Diese bienenwabenartig geformten Hohlräume, die durch dünne Knochenplättchen voneinander getrennt sind, verringern nicht nur das Gewicht des gesamten Schädels, sondern ermöglichten gleichzeitig auch einen enormen Zuwachs an Volumen der Schädeloberfläche. Dieser Volumenzuwachs war notwendig, um einerseits über die mächtige Nackenmuskulatur den Halt des Kopfes inklusive der evolutiv immer größer werdenden Stoßzähne zu gewährleisten, andererseits aber auch um der kräftigen Kaumuskulatur für den massiven Unterkiefer als Ansatzfläche zu dienen. Die Entwicklung eines derartigen luftgefüllten Schädels begann stammesgeschichtlich schon sehr früh bei den Rüsseltieren und ist bei einigen Vertretern schon im Oligozän, möglicherweise auch schon im späten Eozän nachgewiesen.

Das ursprüngliche permanente Rüsseltiergebiss besaß noch die vollständige Bezahnung der relativ altertümlichen tertiären Säugetiere mit drei Schneidezähnen, einem Eckzahn, vier Prämolaren und drei Molaren je Kieferast. Im Laufe der stammesgeschichtlichen Evolution reduzierte sich die Zahnanzahl kontinuierlich bis zu den heutigen Elefanten, die nur einen Schneidezahn im Oberkiefer (Stoßzahn) und drei Molaren je Kieferbogen aufweisen, wovon aber nur jeweils ein Molar im Ober- und im Unterkiefer in jeder Kieferhälfte zur Verfügung steht. Diese werden beim Kauen der Pflanzennahrung stark abgenutzt, können jedoch bei den heutigen Elefanten fünf Mal nachgeschoben werden, umfassen also sechs Generationen. Diese sechs Generationen beinhalten drei Milchprämolaren und drei Dauermolaren. Die Milchprämolaren werden von einigen Experten aufgrund der starken Ähnlichkeit zu den Molaren auch als Milchmolaren angesprochen, sind aber aus ontogenetischer Sicht Prämolaren. Zusätzlich wiesen noch einige ältere Vertreter der Kronengruppe der Rüsseltiere ("Loxodonta", "Elephas" und "Mammuthus") noch zwei dauerhafte Prämolaren auf. Der Verlust der Dauerprämolaren erfolgte in den jeweiligen Linien unabhängig voneinander. Der Zahnwechsel erfolgt dabei horizontal, indem sich ein neuer Zahn erst von hinten herausschiebt, wenn der vordere weitgehend abgekaut ist. Dieser horizontale Zahnwechsel, der sich von dem vertikalen der meisten andern Säugetiere deutlich unterscheidet, entstand durch die Verkürzung des Kiefers in der Rüsseltierevolution, so dass nicht mehr alle Zähne gleichzeitig Platz fanden. Erstmals aufgetreten ist dieses Merkmal im mittleren Oligozän. Auch die Stoßzähne des Oberkiefers fallen bei den jungen Elefanten nach dem ersten Jahr aus, werden dann aber durch ständig wachsende ersetzt.

Zur systematischen Einteilung der Rüsseltiere wird hauptsächlich der Aufbau der Molaren herangezogen. Die Kaufläche dieser Mahlzähne ist sehr vielgestaltig und der jeweiligen Lebensweise der Tiere angepasst. Sie kann höckerige Strukturen (bunodont) aufweisen, wie bei einigen sehr frühen Rüsseltieren, oder aus einzelnen Querleisten aufgebaut sein (lophodont bis zygodont), die teilweise durch verschieden starke Abnutzung härterer und weicherer Stellen eine dachartige Struktur ausbilden wie bei den Stegodonten bzw. lamellenartig geformt sein wie bei den Mammuts und den heutigen Elefanten.

Markantestes Skelettelement sind die Stoßzähne, die gerade, gedrillt, nach oben oder unten gebogen, schaufelförmig, dem Ober- oder Unterkiefer oder beiden entspringend, weit auseinander oder eng zusammenstehend, und in den verschiedensten Längen (bis zu 4 m) und Stärken vorhanden waren. Die Stoßzähne sind eine Bildung der Schneidezähne, die anfänglich noch recht klein und weitgehend senkrecht im Kiefer standen, später in Verbindung mit der allgemeinen Reduktion der Zahnanzahl im Gebiss der Rüsseltiere aber einen übergroßen Wuchs erreichten. Dabei entstanden die Stoßzähne des Oberkiefers aus den zweiten Schneidezähnen (I2) des jeweiligen Kieferastes, während der Ursprung der Unterkieferstoßzähne unter Experten lange diskutiert, mittlerweile aber der erste Schneidezahn (I1) des Kieferastes identifiziert wurde. Heute leben nur noch die Elefanten mit ihren beiden Stoßzähnen im Oberkiefer.

Die Anpassungen der Stoß- und besonders der Backenzähne ermöglichten den Rüsseltieren die Erschließung verschiedener pflanzlicher Nahrungsquellen, von den Sumpfpflanzen, die dem frühen "Moeritherium" als Nahrung dienten, über Blätter und Zweige, die mit den Rüsseln abgerissen wurden, oder Rinden, die wie bei den Deinotherien mit den Stoßzähnen abgeschält werden konnten, bis zu den Gräsern der Savannen und Steppen, welche u. a. die Mammuts bevorzugten und die besonders intensiv gekaut werden müssen.

Ein zotteliges Haarkleid schützte einige nördliche Arten der Mammutiden („Echte Mastodonten“) und Mammuts vor der Kälte der Eiszeit. Die beiden riesigen gebogenen Stoßzähne des Mammuts scheinen auch als Schneepflug zur Nahrungssuche unter der Schneedecke wertvolle Dienste geleistet zu haben. Zwergbildungen bei Stegodonten und Elefanten (siehe: Zwergelefant) ermöglichten über lange Zeiträume hinweg das Überleben auch auf kleineren Inseln des Mittelmeerraums und in Indonesien.

Daneben haben Rüsseltiere auch Einfluss auf ihr unmittelbares Biotop. Durch das Entrinden von Bäumen, Fressen von Blättern, Abknicken von Zweigen und Ästen, das Herausreißen von Büschen und kleinen Bäumen oder das Spalten größerer wirken sie zusammen mit anderen Megaherbivoren stark auf die Landschaft ein. Das gilt nicht nur für die heutigen Elefanten in den Savannen Ost- und Südafrikas, sondern sicher auch für die Mammuts der Mammutsteppe. Dabei ist dies offensichtlich ein Verhalten, das schon sehr früh im Rüsseltier-Stammbaum auftrat und bis ins frühe Miozän oder gar Oligozän zurückreicht, als u. a. mit den Deinotherien die ersten größeren Rüsseltiere mit sehr großen Stoßzähnen auftraten, deren überlieferten Abnutzungsspuren und Beschädigungen auf solche Handlungsweisen schließen lassen.

Die Rüsseltiere entstanden zweifellos in Afrika. Dies geschah zu einer Zeit, als dieser Kontinent noch nicht über Landbrücken mit anderen Erdteilen verbunden war. Solche Landbrücken entstanden erst im unteren Miozän vor mehr als 20 Millionen Jahren, als sich der nördlich gelegene Tethys-Ozean schloss und so eine Verbindung zum heutigen Eurasien entstand. Zu den ersten Auswanderern gehörten die Mammutiden und die Gomphotherien, die erstmals eurasischen Boden betraten. Einige Vertreter, wie z. B. "Zygolophodon" oder "Gomphotherium", erreichten über Nordasien sogar den nordamerikanischen Kontinent und bildeten eigenständige Entwicklungslinien. Den ersten Auswanderern folgten die Deinotherien, allerdings verbreiteten sie sich nicht so weit, wie die Mastodonten und Gomphotherien, sondern blieben auf Eurasien beschränkt. Die erste Auswanderungswelle erfolgte dabei vor rund 20 bis 22 Millionen Jahren. Das Auftreten der Rüsseltiere außerhalb Afrikas wird als "Proboscidean datum event" bezeichnet, wobei dieses ursprünglich als singulär angesehene Ereignis nach neueren Untersuchungen aus mindestens sechs einzelnen Phasen bestand. Im Zuge der Bildung des Isthmus von Panama und der Entstehung einer geschlossenen amerikanischen Landmasse im Pliozän vor 3 Millionen Jahren kam es zum Großen Amerikanischen Faunenaustausch, wobei letztendlich einige Vertreter der Gomphotherien auch Südamerika besiedelten.

Die Rüsseltiere besiedelten somit einen Großteil der Alten und Neuen Welt, lediglich den Australischen Kontinent und die meisten weit vom Festland entfernten Inseln, wie Madagaskar und Neuguinea haben sie niemals erreicht. Dabei umfasste ihr Lebensraum sowohl tropische als auch arktische Lebensräume, wobei sie meistens Tiefländer, einige Arten wie "Cuvieronius" aber auch gebirgige Hochländer erschlossen. Noch bis ins späte Pleistozän waren sie mit vier Familien über Amerika, Eurasien und Afrika verbreitet. Heute findet man sie nur noch in Afrika und Südasien in Form der Elefanten.

Rüsseltiere sind eine relativ alte Ordnung der Säugetiere, erste Vertreter traten bereits im Paläozän vor mehr als 60 Millionen Jahren auf. Dabei kann die stammesgeschichtliche Entwicklung grob in drei Stufen eingeteilt werden, verbunden mit einer jeweiligen Auffächerung in zahlreiche Gattungen und Arten sowie Anpassung an unterschiedliche ökologische Nischen (adaptive Radiation). Generelle Trends in der Evolution der Rüsseltiere sind eine markante Größenzunahme – die ältesten Formen waren weniger als einen Meter groß, während spätere Formen bis zu mehr als 4 Meter Schulterhöhe erreichten –, Vergrößerung des Schädels, vor allem des Schädeldaches als Ansatzstelle für eine mächtige Nacken- und Kaumuskulatur, verbunden mit der Verkürzung des Kieferbereiches, Verkürzung des Halsbereiches, Ausbildung eines Rüssels, Hypertrophie der jeweils zweiten bzw. ersten Schneidezähne mit Ausbildung großer Stoßzähne ebenso wie die Tendenz zur Bildung großer Molaren bei gleichzeitigem Verlust der vorderen Prämolaren und weitgehend auch des vorderen Gebisses sowie die Änderung des Zahnaustausches vom für Säugetiere typischen vertikalen hin zum horizontalen Wechsel. Weiterhin bedeutend ist, dass frühere Rüsseltiere eher Blattfresser ("browser") waren, während die späteren Formen stärker auf Grasnahrung ("grazer") spezialisiert waren.

Die erste Radiation erfolgte vor 61 bis etwa 24 Millionen Jahren. Die Vertreter dieser urtümlichsten Rüsseltiere hatten noch deutlich bunodont aufgebaute Zähne mit maximal vier Querleisten am dritten Molaren, die jeweils einen hohen Zahnschmelzhöcker an den Enden aufwiesen. Einige Formen besaßen auch noch einen Eckzahn je Kieferast. Charakteristisch ist der hier noch vorkommende vertikale Zahnwechsel, so dass alle Zähne gleichzeitig in Gebrauch waren.

Als ältestes Rüsseltier gilt derzeit "Eritherium", das 2009 erstmals beschrieben wurde. Es war ein nur 3 bis 8 kg schweres Tier mit drei Leisten auf dem letzten Molar und lebte im nördlichen Afrika. "Phosphatherium", das 1996 in Marokko ausgegraben wurde, lebte vor etwa 55 Millionen Jahren und war kaum größer als ein Fuchs. Es hatte rein äußerlich wenig mit späteren Rüsseltieren gemeinsam, sein Zahnbau, der dem von "Eritherium" ähnelte aber stärker ausgebildete Leisten zwischen den Zahnhöckern besaß und so eine Tendenz zur Lophodontie aufweist, verrät jedoch die enge Verwandtschaft. Eine noch stärkere Tendenz zu diesen Zahnformen zeigen u. a. "Numidotherium" und "Daouitherium", welche etwa gleich alt sind. "Moeritherium" aus dem Eozän Nordafrikas war ein weiteres frühes Mitglied der Rüsseltiere. Es war etwa so groß wie ein Tapir (etwa 110 cm), und besaß einen schweineähnlichen Kopf mit einer verlängerten Nasen-Oberlippe sowie leicht verlängerten Schneidezähnen im Ober- und Unterkiefer. Neben Elefantenmerkmalen trug der Schädel auch gemeinsame Merkmale mit dem der Seekühe. Des Weiteren zeichnete sich die Gattung durch einen sehr langen Körper aus. Mit "Barytherium" fand die erste enorme Körpergrößenzunahme innerhalb der Rüsseltier-Linie statt. Die Tiere erreichten eine Schulterhöhe von 2,5 bis 3 Meter und besaßen insgesamt acht Stoßzähne, je zwei pro Kieferast.

Ebenfalls in die erste Radiationsphase gehören die Deinotherien (Deinotheriidae), die erstmals im mittleren Oligozän erschienen und eine frühe Abspaltung darstellen. Charakteristisch für diese Rüssseltiergruppe sind die Stoßzähne, die sich nur im Unterkiefer befanden und abwärts gebogen waren. Sie dienten als Werkzeuge zum Abschaben von Baumrinde. Die frühen Formen, wie "Chilgatherium" und "Prodeinotherium" waren noch relativ klein, während "Deinotherium" im Pliozän und Pleistozän teilweise bis zu 4 Meter Schulterhöhe erreichte. Sie stellten eine der ersten erfolgreichen Rüsseltiergruppen dar und starben in Europa im Mittleren Pliozän (Piacenzium), in Afrika im Unteren Pleistozän, vor rund einer Million Jahren aus. Einige Autoren stellen die Zugehörigkeit der Deinotherien zu den Rüsseltieren aufgrund der Zahn- und Gebissmorphologie in Frage und möchten sie eher in näherer Verwandtschaft zu den Seekühen stellen, diese Auffassung wird aber nur wenig geteilt.

"Palaeomastodon" und "Phiomia" waren weitere sehr frühe Rüsseltiergattungen aus dem Eozän und Oligozän Nordafrikas. Sie gehören ebenfalls noch zu Vertretern der ersten Radiation, sind aber mit den späteren Rüsseltierarten schon deutlich näher verwandt als mit den früheren. Es bereitet derzeit noch Probleme, die frühen Formen mit diesen beiden Gattungen zu verbinden, da offensichtlich noch Zwischenglieder fehlen. Wahrscheinlich umfasst "Phiomia" die Schwesterlinie zu den späteren "Gomphotherien" (Gomphotheriidae), während "Palaeomastodon" jene der Mammutiden (Mammutidae) darstellt.

Die Mammutidae stellen die letzte Gruppe innerhalb der ersten Radiation dar. Ihre Entwicklungslinie begann laut molekulargenetischen Untersuchungen bereits vor wenigstens 26 Millionen Jahren. Die Molaren sind zygodont mit maximal vier Schmelzleisten auf dem letzten Zahn. Der spezielle Aufbau der Backenzähne kennzeichnet sie als weitgehende Blattfresser. Weiterhin waren diese Rüsseltiere durch zwei Stoßzähne im Oberkiefer charakterisiert, während ältere Formen ebenfalls zwei kleinere Stoßzähne im Unterkiefer hatten, die im Laufe der weiteren Evolution erst reduziert und später verloren gingen. Die älteste Gattung stellt "Losodokodon" aus dem Oberen Oligozän dar, die aber nur anhand einiger Backenzähne aus Kenia überliefert ist. Über einen häufigeren Nachweis verfügt "Eozygodon", während die bekannteste Gattung "Mammut" ist, zu der u. a. auch das Amerikanische Mastodon ("Mammut americanum") gehört, das zeitgleich mit den Vertretern der späteren Gattung "Mammuthus" lebte und gegen Ende der letzten Eiszeit im oberen Pleistozän ausstarb. Der Gattungsname "Mammut" führt häufig zur Verwirrung, da dessen Vertreter mit den eigentlichen Mammuts, deren Gattungsname "Mammuthus" lautet, nicht näher verwandt sind.

Die zweite Radiationsphase erfolgte im Miozän. Bei den Vertretern dieser Gruppe ist erstmals der horizontale Zahnwechsel nachweisbar, der durch die Verkürzung der Kieferknochen entstand. Bemerkenswert ist, dass die Mammutiden zwar in die erste Radiationsphase gehören, die späteren Vertreter wie "Mammut" das Merkmal des horizontalen Zahnwechsels aber ebenfalls besaßen. Weitere Merkmale in dieser Radiationsphase sind die deutlich hochkronigeren Backenzähne und die Entwicklung von bunodonten über lophodonte zu zygodonten Molaren mit einer teils deutlich dachartigen Struktur der einzelnen Zahnleisten, wobei sich die Zahl dieser Leisten des hintersten Molars auf sechs erhöhte. Möglicherweise an der Basis der zweiten Radiation stand "Eritreum" aus dem späten Oligozän Nordostafrikas, das in seiner Zahnmorphologie noch zwischen "Phiomia" bzw. "Palaeomastodon" und den späteren Rüsseltieren vermittelte, aber schon den horizontalen Zahnwechsel aufwies. Die wichtigsten Gruppen der zweiten Radiationsphase sind die Gomphotherien (Gomphotheriidae) und die Stegodonten (Stegodontidae), zwei Rüsseltierfamilien, die ursprünglich zusammen mit den Mammutiden zur Überfamilie der Mastodonten (Mastodontoidea) zusammengefasst wurden. Der Begriff Mastodon wird aber heute nur noch als Bestandteil eines Gattungsnamen oder umgangssprachlich für das Amerikanische Mastodon gebraucht.

Die bedeutendste Rüsseltierlinie stellten die Gomphotherien (Gomphotheriidae) dar, die zuerst in Afrika nachweisbar sind, später sich aber über Eurasien bis auf den amerikanischen Doppelkontinent verbreiteten. Diese waren eine sehr erfolgreiche Gruppe der Rüsseltiere, da sie sich aufgrund der starken Ausbreitung offener Landschaften im Miozän und der Umstellung auf Grasnahrung in zahlreiche Gruppen aufspalteten. So stellen sie heute fast die Hälfte aller bekannten Taxa, die sich in mehrere Unterfamilien aufteilen. Allgemein handelte es sich bei den Gomphotherien um Rüsseltiere mit vier Stoßzähnen, je zwei im Ober- und im Unterkiefer. Ein weiteres Merkmal sind ein bunodonter bis lophodonter Zahnbau der Molaren, wobei die Milchzähne und die ersten beiden Dauermolaren drei Schmelzleisten besaßen – weswegen sie ursprünglich auch als trilophodonte Gomphotherien bezeichnet wurden –, während der letzte Backenzahn vier, fünf und mehr Rippen hatte. Zur Unterteilung der Gomphotherien werden teilweise auch die Stoßzähne herangezogen. So wiesen die Gomphotheriinae mit "Gomphotherium" im Oberkiefer zwei deutlich nach unten gerichtete Stoßzähne auf, während jene des Unterkiefers langgestreckt und abgeflacht waren. Die Choerolophodontinae hatten dagegen kurze, deutlich reduzierte Unterkieferstoßzähne während die Rhynchotheriinae der ersten Gruppe ähnelten, aber seitlich abgeflachte Unterkieferstoßzähne aufwiesen. Diese wurden im späteren Verlauf, wie "Stegomastodon" und "Cuvieronius" zeigen, zusätzlich noch deutlich reduziert. Bemerkenswert sind die Amebelodontinae wie "Platybelodon" aus Asien und "Amebelodon" aus Nordamerika, die mit stark verlängerten und verbreiterten, schaufelartig umgebildeten Unterkieferstoßzähnen ausgestattet waren, während die Oberkieferstoßzähne nur eine geringe Größe aufwiesen. Einige der zu den Gomphotherien gezählten Arten überlebten bis ins späte Pleistozän.

Deutlich weiter entwickelt als die Gomphotherien waren "Tetralophodon" und "Anancus", die im mittleren bzw. im späten Miozän erstmals in Afrika und Eurasien auftraten. Ursprünglich wurden sie als tetralophodonte Gomphotherien bezeichnet, da ihre Milchzähne und die vorderen Dauermolaren je vier Schmelzleisten besaßen. Gegenwärtig werden sie aber aufgrund modernerer Schädelmerkmale in die nähere Verwandtschaft zu den Stegodonten (Stegodontidae) und Elefanten (Elephantidae) gestellt und der Überfamilie Elephantoidea zugewiesen. Beide Gattungen wiesen stark reduzierte Unterkieferstoßzähne auf, die teils nur noch im Milchgebiss ausgeprägt waren. Unabhängig von dieser altweltlichen Entwicklungslinie entstanden in Amerika offensichtlich auch Gomphotherien-artige Formen mit einer höheren Anzahl an Schmelzleisten wie das spätmiozäne "Pediolophodon" aus Nebraska, welches allerdings nur auf dem zweiten Mahlzahn vier Schmelzfalten aufwies, auf dem ersten dagegen drei.

Die zweite große Gruppe innerhalb der zweiten Radiationsphase umfasste die Stegodonten, die sich im mittleren Miozän vor etwa 15 Millionen Jahren in Nordasien aus Gomphotherien mit bunodonten Molaren entwickelten. Die älteste Form ist "Stegolophodon". Aus dieser entstanden dann die späteren Gattungen, wie "Stegodon", die typische gerippte und häufig sehr hochkronige Molaren besaßen. In der Regel hatten die Stegodonten nur obere Stoßzähne, während die unteren in den verkürzten Unterkiefern weitgehend reduziert oder nicht mehr ausgebildet waren. Diese Rüsseltiergruppe war über einen Großteil Eurasiens verbreitet, im späten Miozän und frühen Pliozän kam sie auch in Afrika vor während sie Amerika aber nicht erreichte.

Die dritte Radiationsphase begann im späten Miozän vor 7 Millionen Jahren und umfasste die Gruppe der Elefanten (Elephantidae), die einzige Rüsseltierfamilie, die bis heute überlebt hat. In dieser Phase wurde der Schädel weiter verkürzt und die Stirn erhöht. Die Molaren wurden weiter verlängert und waren nun deutlich lamellenartig aufgebaut, wobei die Anzahl der Lamellen von acht bis 30 variierte. Dabei waren die Lamellen deutlich flach ausgebildet und nicht mehr so prominent erhöht wie bei den vorhergehenden Rüsseltiergruppen. Außerdem kam es zu einem Rückgang der Zahnschmelzdicke je Lamelle. Alle diese Merkmale zeigen, dass diese Rüsseltiere sehr gut an Grasnahrung angepasst waren.

Die älteste Form war "Primelephas", welcher sich vor etwas mehr als 7 Millionen Jahren in Afrika aus "Stegodon" entwickelte. Aus ihm gingen die heutigen Gattungen "Loxodonta" und "Elephas" hervor. Die Trennung der beiden Gruppen fand schon sehr früh in der Entwicklung von "Primelephas" statt und sollte nach Genanalysen bereits vor 7,6 Millionen Jahren abgeschlossen sein. Nur wenig später, vor 6,7 Millionen Jahren, spalteten sich "Elephas" und "Mammuthus" ab. Während "Loxodonta" weitgehend auf dem afrikanischen Kontinent beschränkt blieb, erreichten "Elephas" und "Mammuthus" vor rund 3 Millionen Jahren auch Eurasien, während einige Vertreter von "Mammuthus" als einzige Elefanten vor knapp 2 Millionen Jahren auch erstmals Amerika betraten. Aufgrund der Verbreitung und Anpassung an das kühlere bis kalte Klima des nördlichen Eurasiens während des Pleistozäns zeichneten sich beide Gattungen durch eine recht hohe Radiation mit zahlreichen Arten aus. Während alle Elefanten eine sehr große Körpergröße aufwiesen, brachte "Mammuthus" mit dem Steppenmammut ("Mammuthus trogontherii") die vermutlich größte bisher bekannt Rüsseltierart hervor, deren Schulterhöhe bei teilweise über 4,5 Meter lag.

Im Neogen, besonders im Pleistozän, fand eine weltweite Verbreitung der Rüsseltiere auf alle Kontinente, außer Australien und Antarktika, mit zahlreichen Arten statt. Diese Verbreitung kann nur durch die Annahme ausgedehnter Wanderungen über Landbrücken, die sich vor ca. 20 Millionen Jahren zwischen Afrika und Eurasien gebildet haben, stattgefunden haben. Am Ende des Pleistozän, also bis vor etwa 12.000 Jahren lebten noch 7 Gattungen von Rüsseltieren: "Stegodon", "Stegomastodon" (inkl. "Haplomastodon"), "Cuvieronius", "Mammut", "Mammuthus", "Elephas" und "Loxodonta". Nur die letzten beiden überlebten bis heute. Dabei ging mit dem Aussterben der meisten Rüsseltiergattungen, aber auch anderer großer Säugetiere bis zum Beginn des Holozäns, möglicherweise die Ausbreitung des modernen Menschen ("Homo sapiens") einher. Allerdings können neben dem Menschen auch die starken Klimaschwankungen der Warm- und Kaltzeiten als Ursache angesehen werden. Über die Gründe der sogenannten Quartären Aussterbewelle wird stark diskutiert.

Heute gibt es nur noch drei Arten der Rüsseltiere, die zwei Gattungen angehören. Dabei umfasst "Loxodonta" den Afrikanischen Elefanten ("Loxodonta africana") und den Waldelefanten ("Loxodonta cyclotis"), während "Elephas" den Asiatischen Elefanten ("Elephas maximus") einschließt.

Die nächsten lebenden Verwandten der Rüsseltiere sind die Seekühe. Diese bilden zusammen mit den ausgestorbenen Desmostylia und Embrithopoda das Taxon der Tethytheria. Ebenfalls relativ nahe verwandt sind die Schliefer, die die Außengruppe der Tethytheria bilden und mit diesen gemeinsam das Taxon der Paenungulata formen.

Man fasst diese Tiere heute mit einigen anderen Säugetierordnungen, die ebenfalls afrikanischen Ursprungs sind zur Überordnung der Afrotheria zusammen. Dazu gehören neben den oben erwähnten folgende noch lebende Ordnungen:


Es sind heute ca. 160 Arten der Rüsseltiere bekannt, davon mehr als 130 aus Afrika, Asien und Europa, die sich auf rund 40 Gattungen und mehr als 10 Familien verteilen. Allerdings sind heute alle bis auf die Elefanten ausgestorben. Einige Arten wurden erst in der Zeit nach dem Jahr 2000 entdeckt, darunter vor allem Vertreter der ältesten Rüsseltiere, wie das "Eritherium" oder das "Daouitherium". Generell lassen sich zwei große Formengruppen (Unterordnungen) unterscheiden: Plesielephantiformes und Elephantiformes, die anhand der Zahnmorphologie unterschieden werden. So besitzen Plesielephantiformes nur zwei Leisten (bilophodont) auf den ersten beiden Dauermolaren, während Elephantiformes drei, vier (tri- und tetralophodont) oder mehr besitzen. Dabei ist die Stellung der Deinotherien innerhalb der Plesielephantiformes problematisch, da sein zweiter Molar zwar biliphodont ist, dies aber möglicherweise kein ursprüngliches, sondern ein abgeleitetes Merkmal darstellt. Aus diesem Grund werden die Plesielephantiformes von einigen Wissenschaftlern als paraphyletisch eingestuft. Innerhalb der Elephantiformes gibt es noch die Teilordnung Elephantimorpha, deren Hauptmerkmal der horizontale Zahnwechsel ist. Vor allem stammesgeschichtlich ältere Gattungen sind teilweise in ihrer Stellung unsicher, ebenso einige fortgeschrittenere, wie "Eritreum", das wohl am Übergang zu den Elephantimorpha steht. Aber auch bei stammesgeschichtlich jüngeren Formen, vor allem der Gomphotherioidea gibt es noch taxonomische Unklarheiten. So wurden ursprünglich "Anancus" und "Tetralophodon" den Gomphotherien zugeordnet, in jüngere Zeit revidierte man diese Zuweisung wieder und stellte beide zu den moderneren Elephantoidea. Die Gliederung basiert auf den Bearbeitungen von Jeheskel Shoshani und Pascal Tassy 2005 unter Berücksichtigung neuer Ergebnisse. In einer Studie aus dem Jahr 2012 erfolgte eine erneute Revision der Gomphotherien, insbesondere der südamerikanischen Vertreter, die einige Unklarheiten aus vorangegangenen Bearbeitungen beseitigte.





</doc>
<doc id="4409" url="https://de.wikipedia.org/wiki?curid=4409" title="Regenerativ">
Regenerativ

regenerativ (von lat. "regeneratio" = "Neuentstehung" und "regenerare" = „wieder (er)zeugen“) bezeichnet



</doc>
<doc id="4411" url="https://de.wikipedia.org/wiki?curid=4411" title="Schweden">
Schweden

Das Königreich Schweden ( oder einfach Sverige ) ist eine parlamentarische Monarchie in Nordeuropa. Das Staatsgebiet umfasst den östlichen Teil der Skandinavischen Halbinsel und die Inseln Gotland und Öland. Schweden ist Mitglied des Nordischen Rates und seit 1995 der Europäischen Union. Anders als Norwegen und Dänemark ist es jedoch nicht Mitglied der NATO und militärisch bündnisfrei.

Schweden grenzt an das Kattegat, die Staaten Norwegen und Finnland sowie die Ostsee, seit der Inbetriebnahme der Öresundbrücke im Jahr 2000 besteht zudem eine direkte Landverbindung zu Dänemark. Zu Schweden gehören etwa 221.800 Inseln, Gotland (2994 km²) und Öland (1347 km², beide in der Ostsee) sowie Orust (346 km², nördlich von Göteborg) sind die drei größten. Die längste Ausdehnung von Norden nach Süden beträgt 1572 km, von Osten nach Westen 499 km. Die Landgrenze zu Norwegen ist 1619 km lang, die zu Finnland 586 km.

Während weite Teile des Landes flach bis hügelig sind, steigen entlang der norwegischen Grenze die Gebirgsmassive der Skanden bis auf über 2000 m Höhe an. Der höchste Gipfel ist der Kebnekaise mit 2111 m. Über das Land verteilt gibt es 28 Nationalparks. Die flächenmäßig größten befinden sich im Nordwesten des Landes.

Süd- und Mittelschweden (Götaland und Svealand), das nur zwei Fünftel von Schweden umfasst, ist von Süden nach Norden in drei Großlandschaften aufgeteilt, Nordschweden (Norrland), welches die restlichen drei Fünftel umfasst, ist von Westen nach Osten in drei Landschaften geteilt.

Die längsten Flüsse Schwedens sind Klarälven, Torne älv, Dalälven, Ume älv und Ångermanälven. Die größten Seen sind Vänern, Vättern, Mälaren und Hjälmaren.

Der südlichste Teil, die historische "Provinz Schonen" (Skåne), ist eine Fortsetzung der Tiefebene Norddeutschlands und Dänemarks. In Schonen liegt der tiefste Punkt Schwedens (ausgenommen Gewässer) mit 2,4 Metern unter dem Meeresspiegel und der südlichste Punkt Schwedens, Smygehuk. Nördlich davon erstreckt sich das "Südschwedische Hochland", eine Hochebene umgeben von einer Hügellandschaft mit einer großen Anzahl von langgestreckten Seen, die durch eiszeitliche Erosion entstanden sind. Die dritte Großlandschaft ist die "Mittelschwedische Senke", eine flache, zerklüftete Landschaft mit großen Ebenen, Horsten, Tafelbergen, Fjorden und einer Reihe von Seen.


Der Westen "Nordschwedens" ist durch das Skandinavische Gebirge geprägt, das die Grenze zu Norwegen bildet. Die Gebirgskette weist Höhen zwischen 1.000 und 2.000 Metern über dem Meeresspiegel auf. Im Skandinavischen Gebirge liegt auch Schwedens höchster Berg, der 2.104 m hohe Kebnekaise. Im Dreiländereck Norwegen/Schweden/Finnland befindet sich mit Treriksröset Schwedens nördlichster Punkt.

Nach Osten hin schließt sich das "Vorland" an, Schwedens ausgedehnteste Großlandschaft. Entlang des Gebirges erstrecken sich große Hochlandebenen auf einer Höhe von 600 bis 700 Metern über dem Meeresspiegel, die in ein welliges Hügelland übergehen, das nach Osten abfällt. In dieser Landschaft befinden sich auch die großen Erzvorkommen (Eisen, Kupfer, Zink, Blei) Schwedens. Die großen Flüsse Schwedens, die ihren Ursprung im Skandinavischen Gebirge haben, fließen beinahe parallel in tiefen Talgängen in Richtung Ostsee.

Entlang der Ostseeküste erstreckt sich die ebene Küstenlandschaft, die zwischen Härnösand und Örnsköldsvik von einem bis an die Ostseeküste reichenden Ausläufer des Vorlandes (Höga Kusten, Nationalpark) unterbrochen wird.

Große Teile Schwedens bestehen aus Urgestein, wie Gneis und Granit. In Jämtland und Teilen von Mittel- und Südschweden (so auch auf den Inseln Öland und Gotland) findet man stellenweise umfangreiche Schichten aus dem Silur.

Die skandinavische Halbinsel war während der Eiszeiten zeitweise vollständig von Eis bedeckt. Der Druck und die Bewegung der Eismassen hat die Landschaft in vielen Teilen wesentlich mitgestaltet. Durch den großen skandinavischen Gletscher der letzten Eiszeit (Weichseleiszeit) ist die heutige Landschaft Schwedens mit den zahlreichen Seen, Flüssen (siehe auch Liste der Flüsse in Schweden) und Wasserfällen (siehe auch Liste der Wasserfälle in Schweden) entstanden. Die damit einhergehende Abschleifung und Aushöhlung hat neben den Moränen die charakteristischen Ablagerungen aus Kieseln und runden Steinen hinterlassen, die in Schweden "åsar" (dt. Os) genannt werden.

Ein auch heute noch wichtiger Faktor ist die postglaziale Landhebung. Das Abschmelzen der Eismassen, die die Erdkruste niedergedrückt hatten, hat seit der letzten Eiszeit (ungefähr 10.000 v. Chr.) zu einer Landhebung von 800 m geführt. Heutzutage beträgt die Landhebung bis zu 10–11 mm jährlich im Höga Kusten, in der Stockholmer Gegend sind es jährlich etwa 6 mm.

Schwedens Klima ist für seine geographische Lage ziemlich mild. Es wird vor allem durch die Nähe zum Atlantik mit dem warmen Golfstrom bestimmt. Große Teile Schwedens haben daher ein feuchtes Klima mit reichlich Niederschlag und relativ geringen Temperaturunterschieden zwischen Sommer und Winter. Kontinental beeinflusstes Klima mit geringeren Niederschlägen und höheren Temperaturunterschieden findet man im Inneren des Südschwedischen Hochlandes und in einigen Teilen des Vorlandes des Skandinavischen Gebirges. Polares Klima kommt nur im nördlichen Hochgebirge vor. Die Durchschnittstemperatur für den Januar beträgt 0 °C bis −2 °C im Süden und −12 °C bis −14 °C im Norden (ausgenommen das Hochgebirge), die Durchschnittstemperatur für den Juli beträgt 16 °C bis 18 °C im Süden und 12 °C bis 14 °C im Norden. Kälterekorde wurden am 2. Februar 1966 in Vuoggatjålme, Gemeinde Arjeplog mit −52,6 °C, beziehungsweise am 13. Dezember 1941 in Malgovik, Gemeinde Vilhelmina mit −53 °C gemessen.

Da sich Schweden zwischen dem 55. und 69. Breitengrad erstreckt und ein Teil nördlich des Polarkreises liegt, ist der Unterschied zwischen dem langen Tageslicht im Sommer und der langen Dunkelheit im Winter beträchtlich.

In Nordschweden prägen die ausgedehnten borealen Nadelwälder das Bild. Je südlicher man kommt, desto häufiger gibt es Mischwälder. Als markanter Grenzraum für Flora und Fauna gilt der so genannte "limes norrlandicus". In Südschweden mussten die Laubwälder dem Ackerbau Platz machen oder wurden wegen des schnelleren Wachstums durch Nadelwälder ersetzt.

Auf den Inseln Gotland und Öland findet man, bedingt durch das Klima und die geologischen Voraussetzungen, eine beeindruckende und vielfältige Flora vor. Hier gibt es eine einzigartige Mischung, unter anderem Pflanzen, die sonst in Europa nur im Balkanraum vorkommen. Besonders erwähnenswert sind die zahlreichen Orchideenarten.
Das Wildschwein ist im südlichen Schweden inzwischen wieder stark verbreitet, obwohl es im 18. Jahrhundert vollständig ausgerottet worden war. Es konnte sich jedoch nach Ausbrüchen von Wildschweinen aus in den 1940er Jahren angelegten Wildgehegen in den 1970er Jahren wieder eine lebensfähige wilde Population entwickeln, die heute rund 80.000 – 100.000 Tiere umfasst. Die Population wuchs seit den 1990er Jahren um jährlich 13 % an und nimmt auch heute noch zu. Zudem findet nach wie vor eine Ausbreitung in Richtung Norden statt, und so kommt das Wildschwein heute bis nach Dalarna und Hälsingland vor. Inzwischen werden in Schweden jährlich rund 25.000 Wildschweine erlegt.

Wie das Wildschwein ist auch der Rothirsch in Schweden vornehmlich in der südlichen Landeshälfte verbreitet. Er kommt vor allem in Götaland vor, isolierte Populationen gibt es aber auch in Dalarna, Jämtland und sogar Västerbotten. Die meisten Bestände beruhen auf gezielten Aussetzungen, nur in Schonen gibt es noch einen ursprünglichen Bestand. Das Reh ist im Vergleich zum Rothirsch etwas weiter verbreitet und kommt nordwärts bis Dalarna flächendeckend und zahlreich vor. Gebiete weiter nördlich sind nur äußerst spärlich vom Reh besiedelt.
Besonders bekannt ist Schweden für die größte Zahl an Elchen in Europa. Sie stellen eine recht große Gefahr im Straßenverkehr dar – 2006 wurden 4.957 Verkehrsunfälle mit Elchen gezählt. Die Elche richten auch großen Schaden in Waldpflanzungen an. In der Jagdsaison im Herbst wird bis zu einem Viertel des Elchbestands erlegt. Der Bestand ist durch die hohe Reproduktionsrate nicht gefährdet.

Raubtiere wie Braunbären, Wölfe und Luchse sind in den letzten Jahren dank strenger Umweltbestimmungen wieder auf dem Vormarsch. Die vielen Seen und langen Küsten bieten viel Lebensraum für Wassertiere: Süß- und Salzwasserfische gibt es reichlich, und auch Biber und Robben sind häufig anzutreffen.

Schweden richtete 1909 als erstes Land in Europa Nationalparks ein. Mittlerweile sind 11 % des Landes durch Naturschutzgebiete oder -reservate sowie 29 Nationalparks geschützt. Sollte die Einrichtung von zwölf neuen Nationalparks und die Erweiterung von sieben bereits bestehenden beschlossen werden, würde der Anteil der geschützten Fläche auf 11,5 % steigen.
Schweden hatte nach den Angaben des statistischen Zentralamtes SCB des Landes Ende November 2016 9,982 Millionen Einwohner. Im Januar 2017 wurde die Marke von 10 Millionen Einwohnern erstmals überschritten. Die Bevölkerung wuchs jährlich um knapp 0,8 Prozent.

Die Geburtenrate von 1,88 Kindern pro Frau (2016) liegt einerseits unter der Reproduktionsschwelle von 2,1 Kindern pro Frau, andererseits weit über dem EU25-Durchschnitt, der im selben Jahr bei 1,58 Kindern pro Frau lag. Die Lebenserwartung betrug im Zeitraum von 2010 bis 2015 81,9 Jahre (Frauen: 83,7, Männer: 80,0 Jahre). Das Durchschnittsalter betrug 2016 41,2 Jahre.

Die Mehrheit der Einwohner sind ethnische Schweden. Es gibt eine größere Minderheit von Schwedenfinnen im Land. Zum einen lebten Finnen über mehrere Jahrhunderte in Teilen des heutigen Schwedens, zum anderen gibt es eine größere Anzahl von Finnen aufgrund von Migration nach dem Zweiten Weltkrieg. Schwedenfinnen bilden in Tornedalen eine große Gruppe. Es gibt heute insgesamt etwa 450.000 Einwohner mit finnischen Wurzeln.

Eine andere Minderheit sind die heute etwa 20.000 schwedischen Samen. Viele leben in den Gemeinden Gällivare und Kiruna. Die traditionelle Rentierzucht spielt bis heute eine Rolle. Es gibt 51 samische lokale Gemeinschaften, genannt "samebyar" (schwedisch; wörtlich „Samendörfer“), in denen die Zucht betrieben wird. Die samischen Sprachen wurden im Jahr 2000 zu anerkannten Minderheitensprachen.

In Schweden leben Einwanderer aus fast allen Ländern der Welt. Im Jahr 2016 war der Bevölkerungsanteil der im Ausland geborenen Einwohner bei knapp 18 Prozent (1,78 Millionen Einwohner). Schweden hat seit Jahrzehnten ein verhältnismäßig liberales Einwanderungsrecht. Erste große Einwanderungswellen gab es ab den 1960er Jahren: primär aus anderen europäischen Ländern, wie aus Deutschland, Italien, Jugoslawien sowie auch der Türkei. In den 1980er Jahren gab es einen Anstieg von Asylbewerbern, aus dem Irak, Iran, Libanon, Eritrea und zum Teil auch aus Südamerika. Ab den 2000ern gab es eine vermehrte Einwanderung von Menschen aus anderen Regionen, wie Afrika sowie Vorder- und Zentralasien. Herkunftsländer waren Irak, Afghanistan oder auch Somalia. Aufgrund der Flüchtlingskrise in Europa ab 2015 und der zahlreichen Aufnahme von Flüchtlingen und Migranten, stieg die Zahl der Personen mit Migrationshintergrund stark an.
Die größte im Ausland geborene Personengruppe war 2016 mit 153.620, die der Finnen. Weitere große Gruppen stellen Personen aus Syrien (149.418), aus dem Irak (135.129), aus Polen (88.704), aus dem Iran (70.637), dem ehemaligen Jugoslawien (66.539) sowie aus Somalia (63.853).

Der Bevölkerungsanteil von Ausländern und Menschen mit Migrationshintergrund ist regional sehr unterschiedlich, wobei die höchsten Anteile in den Großstädten Stockholm, Malmö und Göteborg erreicht werden. In den ländlichen Gebieten des Landes leben verhältnismäßig wenig Migranten.

Die Schwedische Sprache ist seit dem 1. Juli 2009 nicht nur de facto, sondern auch gesetzliche Amtssprache. In Schweden haben Finnisch, Tornedalfinnisch, Jiddisch, Romani, Samisch und die schwedische Gebärdensprache "Svenskt teckenspråk" den Status anerkannter Minderheitensprachen. Entlang der schwedisch-finnischen Grenze, in Tornedalen, wird von ungefähr der Hälfte der Bevölkerung Tornedalfinnisch "(Meänkieli)" gesprochen. Die Samische Sprache wird von einigen Tausend Menschen als Hauptsprache verwendet, zusätzlich zur Schwedischen Sprache.

Fast 80 % der schwedischen Bevölkerung sprechen Englisch als Fremdsprache, da Englisch zum einen die erste Fremdsprache an den Schulen darstellt und zum anderen im Fernsehen sehr stark vertreten ist (fremdsprachige Spielfilme werden üblicherweise nicht synchronisiert, sondern untertitelt). Als zweite Fremdsprache wählt die Mehrheit (ca. 45 %) der Schüler Spanisch. Auch Deutsch (rund 25 %) und Französisch (rund 20 %) werden als zweite Fremdsprache angeboten; Deutsch war wie auch im restlichen Skandinavien bis etwa 1945 die erste Fremdsprache. Die norwegische Sprache wird aufgrund starker Ähnlichkeiten zum Schwedischen zumeist verstanden; für das Dänische trifft das in geringerem Maße zu, insbesondere außerhalb der ehemals dänischen Landesteile Halland, Blekinge und Schonen.

2016 gehörten 61,7 % der schwedischen Bevölkerung der evangelisch-lutherischen Schwedischen Kirche an, die von 1527 bis 1999 Staatskirche war. Seit 2000 ist die Mitgliederzahl deutlich rückläufig. Zwischen 2005 und 2015 haben etwa 740.000 Mitglieder (11 %) die Kirche verlassen.
Die zweitgrößte Religionsgemeinschaft, die der Muslime, lässt sich zahlenmäßig nur schwer einschätzen. Ihre Mitgliederzahl liegt 2014 bei ungefähr 500.000 (5,1 %).

Nach einem Verbot im Verlauf der Reformation ist es Katholiken seit 1781 wieder erlaubt, ihre Religion öffentlich zu praktizieren. 1783 wurde das erste apostolische Vikariat für Schweden mit Abt Nikolaus Oster eingerichtet. Die römisch-katholische Kirche in Schweden hatte 2016 etwa 113.000 Mitglieder (1,1 % der Bevölkerung).

Die orthodoxen und orientalisch-orthodoxen Kirchen haben etwa 120.000 (1,2 %) Gläubige.

Evangelische Freikirchen sind vor allem im Raum Jönköping, in Bohuslän und in Västerbotten stärker vertreten und haben zusammen gut 250.000 Mitglieder, davon knapp die Hälfte in der Equmeniakyrkan.

Die neo-charismatische Bewegung Livets Ord hat ihren Hauptsitz in Uppsala. Daneben gibt es in Schweden etwa 23.000 Zeugen Jehovas (0,25 %), und etwa 10.000 Menschen gehören einer jüdischen Gemeinde (0,1 %) an. Daneben existiert in Stockholm eine mandäische Gemeinde mit eigenem Gotteshaus.

Das schwedische Bildungssystem umfasst vier Teilbereiche: Vorschule, Schule, Hochschulen und Universitäten sowie Erwachsenenbildung. Die Schulpflicht beträgt neun Jahre (7. bis 16. Lebensjahr), an die sich ein freiwilliger dreijähriger Gymnasiumsbesuch anschließt. Etwa 30 Prozent eines Jahrganges beginnen innerhalb von fünf Jahren nach dem Abschluss des Gymnasiums ein Studium.

Im PISA-Ranking von 2015 erreichen Schwedens Schüler Platz 23 von 72 Ländern in Mathematik, Platz 28 in Naturwissenschaften und Platz 17 beim Leseverständnis. Die Leistung Schwedischer Schüler lag damit in allen drei Kategorien leicht über den OECD-Durchschnitt. 

In der Nähe von Kiruna in Esrange wird ein Raketenstartplatz für den Start von Höhenforschungsraketen betrieben.

Die skandinavische Halbinsel wird erstmals in der "Naturalis historia" Plinius’ des Älteren aus dem Jahr 79 erwähnt. Er schreibt über "Scatinavia", eine große Insel, auf der das Volk der Hillevionen lebt. Manche sehen darin die erste Erwähnung der Schweden. Im Jahr 98 findet sich in Tacitus’ "Germania" eine Erwähnung der Suionen (Absatz 44), die angeblich „im Ozean selbst“ leben und eine mächtige Flotte haben. Auf der Weltkarte des Ptolemäus um 120 ist Skandinavien erstmals kartographisch erfasst. Im fünften Jahrhundert beschrieb Prokop die Insel Thule im Norden, die zehnmal größer als Britannien sei und auf der im Winter 40 Tage lang keine Sonne scheine.

Während des frühen Mittelalters (um 800 bis 1000) beherrschten Wikinger die europäischen Meere und Küstengegenden. Schwedische Wikinger, auch Waräger genannt, orientierten sich vor allem Richtung Osten, nach Russland. Ab dem neunten Jahrhundert wirkten die auch Rus genannten Schweden am Aufbau der Kiewer Rus mit. Der erste Kontakt mit dem Christentum entstand durch die Missionstätigkeiten des heiligen Ansgars, des Erzbischofs von Hamburg und Bremen. Er unternahm um 830 und 853 zwei Missionsreisen nach Birka, dem wichtigsten Handelsplatz der Wikinger im Mälaren, die allerdings keinen Erfolg hatten. Im Jahr 1008 ließ Olof Skötkonung, König von Schweden, sich jedoch taufen. Doch bis ins 12. Jahrhundert waren weite Teile der Bevölkerung heidnisch. So wurde 1160 König Erik IX. von anti-christlichen Adligen nach dem Besuch der Messe ermordet.

Im Jahr 1397 bildete die dänische Königin Margarethe I. die Kalmarer Union. Durch Erbschaft und Heirat hatte sie zuvor die norwegische und schwedische Krone erlangt. Diese Vereinigung dreier Reiche unter dänischen Unionskönigen blieb bis 1523 bestehen, auch wenn die Durchsetzung der Zentralmacht letztlich nicht gelang. Die Kalmarer Union wurde immer mehr von inneren Kämpfen, besonders zwischen königlicher Zentralmacht und Hochadel, geprägt. Zu gewissen Zeiten waren die Unionskönige auch in Schweden anerkannt, aber dazwischen regierten der schwedische König Karl Knutsson (1448–57, 1464–65 und 1467–70) beziehungsweise schwedische Reichsverweser. Der Konflikt kulminierte unter dem Reichsverweser Sten Sture dem Jüngeren. Der dänische Unionskönig Christian II. besiegte seine schwedischen Widersacher 1520 und ließ im November desselben Jahres etwa hundert Oppositionelle im sogenannten Stockholmer Blutbad hinrichten. Dies führte zum Aufruhr des Gustav Wasa, der 1521 zum Reichsverweser ernannt wurde, und dem endgültigen Zusammenbruch der Kalmarer Union. Im Jahr 1523 wurde Gustav I. Wasa zum König gewählt. Nach dem Volksaufstand litt das schwedische Reich unter hohen Schulden und Gustav I. sah sich nach Möglichkeiten zur Verbesserung der finanziellen Lage um. Dafür vergab er unter anderem ein Fischereimonopol an die Gävlefischer. Die Brüder Olavus und Laurentius Petri hatten in Deutschland Bekanntschaft mit Martin Luther gemacht. Die Opposition des Luthertums zu Klöstern schuf eine Gelegenheit zur Auffrischung der finanziellen Situation. Aus diesem Grund unterstützte der König die Gebrüder Petri. Da die Bevölkerung zunächst nicht in Kontakt mit dem protestantischen Gedankengut kam, wurde die Reformation schrittweise eingeführt. Viele Traditionen, die im deutschen Protestantismus aufgehoben werden sollten, wurden beibehalten. 1544 wurde Schweden zum evangelischen Reich erklärt.

Vor allem das 17. Jahrhundert der schwedischen Geschichte ist geprägt von Versuchen seitens des Königshauses, eine Hegemonialstellung in Europa zu erlangen. Durch den Bürgerkrieg in Russland konnte Schweden die Kontrolle über Estland erlangen. Von 1611 bis 1613 fochten Dänemark und Schweden den Kalmarkrieg aus, der zu einem Sieg der Dänen und der Abgabe der Finnmark an das unter dänischer Herrschaft stehende Norwegen führt. Später schaltete sich Gustav II. Adolf aktiv in den Dreißigjährigen Krieg ein und eroberte weite Teile Norddeutschlands, darunter Vorpommern, das Erzbistum Bremen und das Bistum Verden. 1632 fiel er allerdings in der Schlacht bei Lützen. 1648 erlangte Schweden im Westfälischen Frieden große Küstengebiete auf dem Boden des Heiligen Römischen Reichs. Nach einem Krieg gegen Dänemark kam 1658 im Frieden von Roskilde das heutige Südschweden einschließlich des wichtigen Schonen hinzu. Ein jähes Ende fanden die Großmachtträume unter Karl XII., der im Großen Nordischen Krieg von den Russen und den Dänen geschlagen wurde. Schweden musste daraufhin seine Besitzungen im Baltikum abgeben. In diese Zeit fallen auch verschiedene Kolonialisierungsbestrebungen außerhalb Europas. Diese umfassten die Gründung von schwedischen Niederlassungen und Kolonien in Nordamerika (1638–1655) und Westafrika (1650–1659), scheiterten letztlich aber.

Erst nach dem Verlust Finnlands an das russische Zarenreich 1809 und den Napoleonischen Kriegen, in deren Folge Schweden von Dänemark das Königreich Norwegen abgetreten bekam, endete die schwedische Verwicklung in Kriege und größere Kampfhandlungen. Die so oft beschworene schwedische Neutralitätspolitik nahm ihren Anfang. Sie war bis ins 20. Jahrhundert hinein jedoch nie eine offizielle politische Doktrin, sondern mehr Ausdruck pragmatischer Politik. So war man durchaus versucht (und hatte jeweils auch bereits mobilisiert), in der Schleswig-Holsteinischen Erhebung (1848–1851) und im Deutsch-Dänischen Krieg (1864) um das Herzogtum Schleswig und Südjütland auf Seiten Dänemarks einzugreifen sowie Norwegens Unabhängigkeitserklärung von Schweden 1905 militärisch zu verhindern. Weitere Krisensituationen ergaben sich für Schweden insbesondere im Zweiten Weltkrieg, als man im sogenannten Winterkrieg zwischen Finnland und der Sowjetunion 1939/40 Finnland mit Freiwilligen und Hilfsgütern unterstützte, sowie nach dem Unternehmen Weserübung.

Schweden ist eine parlamentarisch-demokratische Monarchie. Staatsoberhaupt ist seit 1973 König Carl XVI. Gustaf. Die Aufgaben des Staatsoberhauptes sind rein repräsentativ und zeremoniell; der König hat keine politischen Machtbefugnisse und nimmt nicht am politischen Leben teil.

Das Einkammer-Parlament, der Reichstag (schwed. "Riksdag") hat 349 Abgeordnete und wird alle vier Jahre neu gewählt. Die acht im Reichstag vertretenen Parteien sind die konservative Moderate Sammlungspartei "(Moderata samlingspartiet, M)," die Liberale Partei "(Liberalerna, L)," die Zentrumspartei "(Centerpartiet, C)," die Christdemokraten "(Kristdemokraterna, KD)," die Grünen "(Miljöpartiet de Gröna, MP)," die Sozialdemokratische Arbeiterpartei Schwedens "(Sveriges socialdemokratiska arbetareparti, S)," die Linkspartei "(Vänsterpartiet, V)" und die Schwedendemokraten "(Sverigedemokraterna, SD)".

Der Ministerpräsident "(statsminister)" wird vom Reichstag ernannt, der seinerseits die weiteren Minister (schwed. "statsråd") seiner Regierung ernennt.

Schweden ist in 21 Provinzen (schwed. "län") gegliedert. Die staatlichen Verwaltungsaufgaben auf regionaler Ebene werden von einem Regierungspräsidenten (schwed. "landshövding") und einer Provinzialregierung (schwed. "länsstyrelse") wahrgenommen.

Die Ursprünge des schwedischen politischen Systems liegen in den Verwaltungsreformen des Axel Oxenstierna von 1618. Im Gegensatz zu den meisten Demokratien dürfen die Minister, also die Regierung, die ausführenden Organe nicht direkt steuern (Ostnordische Verwaltungsform, auch in Finnland gebraucht). Vielmehr sind es die unabhängig agierenden Zentralämter (schwed. "ämbetsverk") (beispielsweise Trafikverket, Skolverket – es gibt ungefähr 200 in unterschiedlicher Größe), welche die Aufgaben erfüllen, die in anderen Ländern von Ministerien oder Landesverwaltungen realisiert werden. Demgegenüber haben die Ministerien die Aufgabe, Gesetzesvorlagen auszuarbeiten und im besten Fall die Möglichkeit, die Arbeit der Zentralämter durch Verordnungen zu beeinflussen.

Die kommunale Selbstverwaltung geschieht auf zwei Ebenen: den (seit 2003) 290 Gemeinden (schwed. "kommun") und den Provinziallandtagen (schwed. "landsting"), welche eine Art Kommunenverbund darstellen (nicht zu verwechseln mit den staatlichen "länsstyrelse"). Die Gemeinden nehmen die kommunalen Aufgaben, wie unter anderem das Schulwesen, soziale Dienstleistungen, Kinder- und Altenbetreuung sowie die kommunale Infrastruktur wahr, jedoch werden die Rahmenbedingungen von den zentralen Behörden, beispielsweise Skolverket, bestimmt. Die Provinziallandtage hingegen sind für diejenigen Bereiche der kommunalen Selbstverwaltung zuständig, die die Kraft einzelner Gemeinden übersteigen, wie unter anderem das Gesundheitswesen und die Krankenpflege, den Regionalverkehr und die Verkehrsplanung. Die Gemeinden und die Provinziallandtage finanzieren ihre Tätigkeit durch die Erhebung von Einkommenssteuern, mit Abgaben und staatlichen Zuschüssen.

In Schweden gilt das Öffentlichkeitsprinzip, das heißt, dass behördliche Schriftstücke mit geringen Ausnahmen der Presse und allen Privatpersonen zugänglich sind. Niemand muss angeben, warum er ein Schriftstück einsehen möchte, noch muss man sich ausweisen. Es ist seit 1766 verfassungsrechtlich garantiert und ist damit die weltweit älteste Verfassungsregelung zur Informationsfreiheit. Auch auf dem Gebiet des Datenschutzes, des Gegenstücks zur Informationsfreiheit, gehört Schweden zu den Vorreitern: Während das weltweit erste Datenschutzgesetz 1970 in Hessen verkündet wurde, trat das weltweit erste "nationale" Datenschutzgesetz 1973 in Schweden in Kraft.

Eine weitere skandinavische Besonderheit ist das System der Ombudsmänner (schwed. "ombudsman"). Sie sollen die Rechte des Einzelnen beim Kontakt mit den Behörden schützen und die Befolgung wichtiger Gesetze sicherstellen. Bürger, die meinen, ungerecht behandelt worden zu sein, können sich an die Ombudsmänner wenden, die den Fall untersuchen und eventuell als Sonderankläger vor Gericht bringen. Gleichzeitig sollen sie in Zusammenarbeit mit den Behörden die Lage in ihren jeweiligen Bereichen erfassen, Aufklärungsarbeit betreiben und Vorschläge für Gesetzesänderungen machen. Neben den Justizombudsmännern gibt es einen Verbraucherombudsmann, einen Kinderombudsmann und einen Diskriminierungsombudsmann.

Schweden galt lange Zeit als sozialdemokratisches Musterland; es wurde von vielen europäischen Linken als gelungenes Beispiel für einen "dritten Weg" zwischen Sozialismus und Marktwirtschaft gesehen. Das hat sich spätestens seit den Reformen in den 1990er Jahren geändert.

Am 14. September 2003 wurde in Schweden über die Einführung des Euro als Landeswährung abgestimmt. Die Einführung war im Vorfeld kontrovers diskutiert worden, und letztlich setzten sich die Euro-Skeptiker durch (Wahlbeteiligung: 81,2 %, Wahlausgang: 56,1 % dagegen, 41,8 % dafür, 2,1 % Enthaltungen, 0,1 % ungültig). Die Skeptiker sahen in der Euro-Einführung eine Bevormundung der schwedischen Währungspolitik durch die Europäische Zentralbank (EZB). Vor 2013 soll es nach der Ankündigung der schwedischen Regierung kein weiteres Referendum zur Einführung des Euro geben. Die Abstimmung wurde durch die Ermordung der schwedischen Außenministerin Anna Lindh schwer überschattet.

Die Reichstagswahlen 2014 gewann keine der beiden großen Blöcke. Eine am 2. Oktober 2014 stattfindende Vertrauensabstimmung im Parlament gewann Stefan Löfven "(Sveriges socialdemokratiska arbetareparti)" und trat damit die Nachfolge von Fredrik Reinfeldt als Staatsminister (Ministerpräsident) an. Obgleich die rot-grüne Regierung Löfven über keine Mehrheit verfügt, wurde die Wahl möglich, weil sich sowohl die bürgerliche Opposition als auch die sozialistische Linkspartei der Stimme enthielt. Nachdem der Haushaltsentwurf der Regierung am 3. Dezember 2014 gescheitert war, weil die Oppositionsparteien gegen diesen Entwurf mehr Stimmen als die Regierung erreichten, kündigte Löfven Neuwahlen zum 22. März 2015 an. Auf einer Pressekonferenz gab Löfven am 27. Dezember 2014 bekannt, dass in einem „Dezemberabkommen“ der rot-grünen Minderheitsregierung mit den vier Oppositionsparteien der Bürgerlichen Allianz vereinbart wurde, dass diese bei der nächsten Abstimmung über das Budget 2015 den Vorschlag der Regierung nicht ablehnen werden. Die bereits angekündigten, aber offiziell erst am 29. Dezember 2014, also drei Monate nach der letzten Parlamentswahl auszurufenden Neuwahlen fanden daher nicht statt.

Schweden wurde 2006 von "Human Rights Watch" aufgrund seines Mitwirken an der Überstellung des asylsuchenden Mohammed al-Zari nach Ägypten, der Missachtung des absoluten Folterverbots bezichtigt.

Bei der Europawahl 2004 errang die Junilistan aus dem Stand 14,5 % der Stimmen und entsendet erstmals drei von 19 schwedischen Abgeordneten ins Europaparlament.

Bei der Europawahl 2009 errang die schwedische Piratpartiet (eine Piratenpartei) aus dem Stand 7,1 % der Stimmen und entsendet erstmals einen der 18 schwedischen Abgeordneten ins Europaparlament. Die PP wurde damit fünftstärkste Partei, nach den Parteien Arbetarepartiet-Socialdemokraterna (24,6 %), Moderata samlingspartiet (18,8 %), Folkpartiet liberalerna (damaliger Parteiname der Liberalerna) (13,6 %) und Miljöpartiet de gröna (10,8 %). Das bemerkenswert hohe Ergebnis der Piratenpartei, deren Hauptforderung „ein reformiertes Urheberrecht“ ist, wird auf die hohe Aufmerksamkeit der schwedischen Bevölkerung auf die Verurteilung von vier Verantwortlichen des Torrent-Portals The Pirate Bay zu Haftstrafen Mitte April 2009 zurückgeführt.

Bei der Europawahl 2014 errang die schwedische Feministiskt initiativ aus dem Stand 5,3 % der Stimmen und entsendet erstmals einen der 20 schwedischen Abgeordneten ins Europaparlament.

Der Demokratieindex der Zeitschrift The Economist weist Schweden nach Norwegen als das zweitdemokratischste Land der Welt aus.

Die staatliche Verwaltung Schwedens ist derzeit (Stand 2016) in 21 Provinzen "(län)" unterteilt. Diese lehnen sich teilweise an die historischen Provinzen "(landskap)" an, in die das Reich bis 1634 eingeteilt war, was sich in der Namensgebung vieler Provinzen spiegelt. Mehr oder weniger deckungsgleich mit den historischen Provinzen sind Gotland, Skåne, Blekinge, Östergötland, Värmland und Dalarna; in anderen Fällen sind die historischen Provinzen in mehrere heutige Provinzen aufgeteilt (z. B. die alten Lappland und Småland) oder aber mehrere historische Landschaften in einer einzigen Provinz zusammengefasst (z. B. im Fall der heutigen Jämtlands län und Västra Götalands län). Die Provinzgrenzen folgen insgesamt grob den früheren Landskapsgrenzen, es gibt jedoch viele kleinflächige Abweichungen.

Eine Reform des gegenwärtigen Systems mit dem Ziel der Einteilung des Landes in acht bis zehn Großprovinzen war insbesondere ab den 1990er-Jahren im Gespräch. Mit der Umsetzung dieser Pläne wurde 1997/1998 mit der Schaffung von Skåne län und Västra Götalands län aus zwei beziehungsweise drei früheren Provinzen begonnen. Diese Entwicklung sollte ursprünglich bis 2014 abgeschlossen sein, aber bis heute kam es zu keinen weiteren Änderungen.

Die heutigen Provinzen sind:
"Anmerkung:" anfängliche Sortierung der Tabelle in der in schwedischen Statistiken üblichen Reihenfolge der Provinzen, ab Stockholms län grob im Uhrzeigersinn

Die kommunale Selbstorganisation findet auf der Ebene der Provinziallandtage und der Gemeinden statt; dabei sind die Provinziallandtage derzeit für das Gesundheitswesen, die Kulturpflege und gemeinsam mit den Gemeinden für den öffentlichen Nahverkehr zuständig.

Derzeit decken sich die Gebiete der Provinziallandtage/Regionen mit den zugehörigen Provinzen; jede Provinz hat einen Provinziallandtag. In den Provinzen, in denen es zu einer Zusammenschlagung der Provinziallandtage zu Regionen gekommen ist (Västra Götaland, Skåne) hat man auch die Provinzen entsprechend zusammengefasst. Ebenfalls Regionen gebildet haben 2010 Halland und Gotland. Diese Regionen werden wohl permanent verbleiben; die Zusammenfassung der Provinziallandtage im Übrigen ist jedoch ein Prozess, der sich fortsetzen wird; welche Provinziallandtage zu welchen Regionen zusammengefasst werden ist jedoch vor allem in Mittelschweden noch unklar; ein Beschluss dazu wird 2014 erwartet. Ab 2015 soll dann die neue Gliederung in Kraft treten; dabei darf eine Provinz ein oder mehrere Provinziallandtage/Regionen enthalten, eine Provinzgrenze wird jedoch nicht quer durch einen Provinziallandtag verlaufen.

Die Gemeinden stellen die Verwaltungseinheit unter den Provinziallandtagen dar. In Schweden gibt es 290 Gemeinden.

Mit Abstand größter Ballungsraum Schwedens ist die Hauptstadt Stockholm, gefolgt von Göteborg und Malmö. Weitere Großstädte sind Uppsala, Västerås, Örebro, Linköping und Helsingborg.

Das „schwedische Modell“, ein Begriff vor allem der 1970er-Jahre, bezieht sich auf den Wohlfahrtsstaat, ein umfassendes System sozialer Sicherheit und sozialer Fürsorge, das das Ergebnis einer einhundertjährigen Entwicklung ist. Zwischen 1890 und 1930 wurden teilweise die Grundlagen für ein Sozialsystem geschaffen, aber erst ab den 1930er-Jahren, insbesondere nach der Regierungsübernahme der Sozialdemokratischen Arbeiterpartei 1932, wurde der Aufbau des Wohlfahrtsstaates als politisches Projekt vorangetrieben. Das schwedische Sozialsystem erfasste schließlich alle, vom Kleinkind (über die kommunale Kinderfürsorge) bis zum Rentner (über die kommunale Altenfürsorge). Erst im letzten Jahrzehnt kam es zu einschneidenden Veränderungen. Eine schwere Wirtschaftskrise zu Beginn der 1990er-Jahre führte zu einer Kürzung von Sozialleistungen und die erwartete demographische Entwicklung führte zu einem radikalen Umbau des Rentensystems, das nun an die wirtschaftliche Entwicklung gekoppelt ist.

Der Staatshaushalt umfasste 2016 Ausgaben von umgerechnet 250,8 Milliarden US-Dollar, dem standen Einnahmen von umgerechnet 248,3 Mrd. US-Dollar gegenüber. Daraus ergibt sich ein Haushaltsdefizit in Höhe von 0,3 % des BIP.
Die Staatsverschuldung betrug 2016 215,8 Mrd. US-Dollar oder 41,6 % des BIP.

2006 betrug der Anteil der Staatsausgaben (in % des BIP) folgender Bereiche:

Die schwedische Polizei "(Polisen)" verfügt über ca. 26.000 Mitarbeiter, davon mehr als 18.000 Polizisten.

Die schwedische Sicherheitspolizei "(Säkerhetspolisen)" ist ein Nachrichtendienst mit polizeilichen Befugnissen.

Die schwedischen Streitkräfte (schwedisch "Försvarsmakten") bestehen aus den vier Teilstreitkräften
Die schwedische Armee ist formell als Verwaltungsbehörde organisiert. Als solche untersteht sie direkt der schwedischen Regierung und nicht, wie in vielen anderen Staaten, dem Verteidigungsminister. Den Oberbefehl sowohl in Friedens- als auch in Kriegszeiten führt ein Vier-Sterne-General mit dem Titel "Överbefälhavaren".

Die elf- bis siebzehnmonatige Wehrpflicht wurde am 1. Juli 2010 ausgesetzt, nachdem seit Ende des Kalten Krieges bereits immer weniger Soldaten eingezogen wurden (45.000 Wehrdienstleistende im Jahr 1975 gegenüber 15.000 Wehrdienstleistenden im Jahr 2003). In Krisenzeiten kann die Regierung die allgemeine Wehrpflicht, aus Gründen der Gleichstellung auch für Frauen, per Beschluss wieder einführen. Tatsächlich kündigte das Verteidigungsministerium im September 2016 an, dass die Wehrpflicht im Jahr 2018 wieder eingeführt wird, dann auch für Frauen geltend.

Der Verteidigungshaushalt beträgt umgerechnet etwa 4,2 Milliarden Euro (40 Mrd. SEK, Stand: 2010), worin alle laufenden Aufwendungen für die Streitkräfte und Ausgaben für Forschung und Entwicklung sowie die Materialbeschaffung enthalten sind.

Aufgrund des Kalten Krieges sah Schweden einen Beitritt zu den Europäischen Gemeinschaften vor 1989 als unvereinbar mit seiner Neutralitätspolitik an. 1995 trat Schweden in der vierten Erweiterungsrunde der EU bei. Die schwedische Regierung setzt sich für eine EU ein, die transparent arbeitet, Gleichberechtigung fördert und eine friedliche Globalisierung als Priorität versteht. Das Land sprach sich für die Erweiterung um die Länder Mittel- und Osteuropas, darunter auch die baltischen Staaten aus. Ferner gehört Schweden zu den stärksten Befürwortern eines EU-Beitritts der Türkei. Vom 1. Juli bis zum 31. Dezember 2009 hatte Schweden die Präsidentschaft des Europäischen Rates inne.

Noch in der ersten Hälfte des 19. Jahrhunderts war Schweden ein ausgeprägter Agrarstaat, in dem 90 % der Bevölkerung von der Landwirtschaft lebte. Erst in der zweiten Hälfte des 19. Jahrhunderts setzte eine umfassende Industrialisierung ein, die bis zur Weltwirtschaftskrise von 1929 die Grundlagen für eine moderne Industriegesellschaft legte. Die Industrialisierung basierte anfänglich auf gutem Zugang zu Rohstoffen und der Verarbeitung dieser Ressourcen an Ort und Stelle (beispielsweise Eisenerz mit Hütten in Svealand, unendliche Wälder im Norden, einer Vielzahl an Sägewerken entlang der norrländischen Küste). Erst in den 1890er-Jahren bildete sich eine sehr fortschrittliche Werkstattindustrie, vor allem in Mittelschweden, heraus (beispielsweise Nobel AB, ASEA (heute ABB), Bahco, LM Ericsson, Alfa Laval, SKF). Nach dem Zweiten Weltkrieg wurde Schweden zu einer der führenden Industrienationen der Welt. Die Entwicklung erreichte in der Mitte der 1960er-Jahre ihren Höhepunkt, seit den 1970er-Jahren geht die Anzahl der Beschäftigten in der Industrie zurück, während der Dienstleistungsbereich wächst. 2000 betrug der Anteil der Landwirtschaft am Bruttoinlandsprodukt (BIP) nur noch 2 % und der des sekundären Sektors 28 %, während 70 % des BIP durch den tertiären Sektor erwirtschaftet wurden.

Schweden hat in den zurückliegenden Jahren die weltweite Wirtschafts- und Finanzkrise vergleichsweise gut gemeistert. 2014 betrug der Anstieg des BIP 2,3 % (2013: 1,5 %). Für das Jahr 2015 werden von der schwedischen Regierung 2,8 % Wirtschaftswachstum erwartet. Im Vergleich mit dem BIP der EU ausgedrückt in Kaufkraftstandards erreichte Schweden 2015 einen Indexwert von 123 (EU-28:100) und damit etwa 98 % des deutschen Wertes. Schweden belegte im Global Competitiveness Index 2017–2018 Rang 7 und war laut den Korruptionswahrnehmungsindex 2016 eines der am wenigsten korrupten Länder der Welt. Im Index der Wirtschaftlichen Freiheit belegt das Land 2017 Platz 19 von 180 Ländern.

Im Jahr 2014 betrug die offizielle Arbeitslosenquote 8 %.

Die schwedische Landwirtschaft ist durch die geologischen Voraussetzungen und das Klima geprägt. 10 % der Staatsfläche werden landwirtschaftlich genutzt. 90 % der Anbaufläche befinden sich in Süd- und Mittelschweden. Ein Großteil der Landwirtschaftsbetriebe ist in Familienbesitz. Angebaut werden vor allem Getreide, Kartoffeln und Ölpflanzen. Mehr als die Hälfte der landwirtschaftlichen Einnahmen (58 %) wird aber durch die Tierhaltung erwirtschaftet, hier vor allem durch die Milchproduktion. Die Landwirtschaftssubventionen der EU belaufen sich auf 24 % der Einnahmen. Drei Viertel der landwirtschaftlichen Betriebe verfügen auch über Wald und verbinden Landwirtschaft mit Forstwirtschaft. Die Forstwirtschaft ist von einiger Bedeutung, da Schweden eines der waldreichsten Länder der Erde ist; 56 % der Staatsfläche ist von Wald bedeckt.

Schweden ist reich an Bodenschätzen, die schon ab dem Mittelalter abgebaut wurden. Eisenerz wird, nach der Eisen- und Stahlkrise der 1970er-Jahre, nur noch in Norrland (Kiruna, Gällivare-Malmberget) abgebaut und exportiert. Kupfer, Blei und Zink übersteigen den Eigenbedarf um das Mehrfache und werden ebenfalls exportiert, während Silber zu 60 % und Gold zu 80 % den Eigenbedarf decken. Größere Erzreserven sind vorhanden, deren Abbau ist aber zurzeit unwirtschaftlich.

Was die schwedische Industrie auszeichnet, ist der verhältnismäßig hohe Anteil von Großunternehmen. Nach einer Krise am Beginn der 1990er-Jahre (mit einem Produktionsrückgang von 10 % innerhalb von zwei Jahren) hat sich die Industrie wieder erholt. Die größten Industriezweige sind Fahrzeugbau (1996: 13 % der industriellen Wertschöpfung) mit Unternehmen wie Volvo, Scania, Saab AB (Flugzeuge und Raumfahrttechnik) und andere, die Holz- und Papierindustrie (ebenfalls 13 % der industriellen Wertschöpfung) mit vier Großunternehmen, der Maschinenbau (12 % der industriellen Wertschöpfung) mit Unternehmen wie Electrolux, SKF, Tetra-Pak und Alfa Laval und die Elektro- und Elektronikindustrie (10 % der industriellen Wertschöpfung) mit den dominierenden Unternehmen Ericsson und ABB.

Seit 2006 finden in ganz Schweden mit Schwerpunkt auf dem hohen Norden verstärkte Anstrengungen bei der Suche nach Erzen statt. Die Samen befürchten dabei erhebliche negative Auswirkungen des Bergbaus auf die Rentierwirtschaft und die empfindliche Natur.


Elektrische Energie wird in Schweden vor allem durch erneuerbare Energien und Kernenergie produziert: im Jahr 2015 stammten 57 % der Stromproduktion von erneuerbaren Energien, wobei gerade Wasserkraftwerke an den großen Flüssen (Luleälv, Indalsälv, Umeälv und Ångermanälv) im Norden des Landes, der Rest aus Kernkraftwerken. Auch am Primärenergieverbrauch hat die Wasserkraft einen erheblich Anteil: 2011 lieferte sie rund 15 %. Unter den Mitgliedstaaten der Europäischen Union trägt Schwedens Wasserkraft am meisten zur Versorgung aus erneuerbaren Energiequellen bei: Im Jahre 2011 wurden 66 TWh erzeugt – das entspricht mehr als 20 % der insgesamt in den EU-Ländern erzeugten Energie aus Wasserkraft.

2015 gab die Regierung bekannt, in allen Verbrauchssektoren, d. h. Strom, Wärme und Verkehr, vollständig aus der Nutzung fossiler Energieträger aussteigen zu wollen, um die Energiewende sowie den Klimaschutz voranzubringen. Zugleich sollen erneuerbare Energien, Energieeffizienzmaßnahmen, Speicher und nachhaltige Verkehrslösungen stärker gefördert werden. Bis 2040 soll die gesamte Energieversorgung Schwedens zu 100 % auf erneuerbaren Energien basieren. Hierfür soll vor allem die Windenergie an Land ausgebaut werden, wobei die schwankende Energieabgabe der Windkraftanlagen durch die vorhandenen Wasserkraftwerke sowie stärkere Vernetzung mit Nachbarstaaten zum überregionalen Stromaustausch ausgeglichen werden soll. 2017 setzte sich das Land zudem in einem Klimaschutzgesetz das Ziel, bis 2045 vollständig treibhausgasneutral zu sein. Der Beschluss kam mit 254 zu 41 Stimmen angenommen, wobei alle Parteien außer den weit rechts im Parteienspektrum stehenden Schwedendemokraten den Beschluss unterstützten.


Nach der partiellen Kernschmelze in Three Mile Island in den USA (1979) wurde in Schweden eine Volksabstimmung gegen Kernenergie erfolgreich durchgeführt. Das hatte zur Folge, dass das Parlament 1980 entschied, keine weiteren Kernkraftwerke mehr zu bauen und die zwölf vorhandenen bis 2010 abzuschalten.

Dieser Ausstiegsplan wurde nur teilweise vollzogen. 1997 nahm der Schwedische Reichstag die Vorlage über „eine nachhaltige Energieversorgung“ an. Diese bestimmte unter anderem, einen der Reaktoren am Standort Barsebäck vor dem 1. Juli 1998 und den zweiten vor dem 1. Juli 2001 stillzulegen, allerdings unter der Voraussetzung, dass deren Stromproduktion kompensiert werden kann. Der frühere Beschluss, alle Reaktoren bis 2010 stillzulegen, wurde aufgehoben. Barsebäck Block 1 wurde schließlich am 30. November 1999 stillgelegt, Barsebäck Block 2 am 1. Juni 2005.

Der Verzicht auf die Nutzung der Kernenergie wird in Schweden kontrovers diskutiert. Die Industrie befürchtet den Verlust einer preiswerten Stromerzeugung und damit eine Beeinträchtigung ihrer internationalen Wettbewerbsfähigkeit. Zudem betonen Kritiker, dass ein Verzicht auf die Kernenergienutzung ohne über ausreichende andere und verlässliche Stromerzeugungstechniken zu verfügen erhebliche negative Folgen für die schwedische Volkswirtschaft haben könne.

Die Leistung der drei noch in Betrieb befindlichen Kernkraftwerke ist in den letzten Jahren erheblich gesteigert worden. Diese Steigerung ermöglichte die Kompensation des 2005 abgeschalteten Kernkraftwerks Barsebäck. Eine Ausnutzung von vorhandenen weiteren großen Wasserkraftpotenzialen ist nicht möglich. Der Schwedische Reichstag beschloss 1998, aus Naturschutzgründen keine weiteren Ausbauten von Gewässern zuzulassen. Per Gesetz geschützt sind die Flüsse Kalixälv, Piteälv, Torneälv und Vindelälv.

Die Betreiber von Kernkraftwerken gehen von einer Nutzungszeit der bestehenden Anlagen etwa bis zum Jahr 2050 aus. Diesbezüglich gab es 2004 einen Beschluss des Parlaments, dass ein Ausstieg „in den nächsten 30 bis 40 Jahren“ anzustreben sei. Im Januar 2008 sprach sich Jan Björklund, der Vorsitzende der liberalen Partei Schwedens, für einen Neubau von vier weiteren Reaktoren aus. Eine Umfrage im Juni 2008 ergab, dass 40 % der Schweden diesen Plänen zustimmten, wohingegen 42 % nur den Betrieb der derzeitigen Anlagen befürworteten, nicht aber einen Neubau weiterer Anlagen. Am 5. Februar 2009 beschloss der Schwedische Reichstag den Neubau von zehn Reaktoren in den drei bestehenden Kraftwerken.

November 2014 erklärte der Direktor des Staatskonzerns Vattenfall, Magnus Hall, alle Pläne zum Ausbau der Atomenergie in Schweden auf Eis gelegt zu haben – einer Übereinkunft der rot-grünen Regierung folgend. 2015 soll eine parlamentarische Energiekommission auf Initiative von Energieminister Ibrahim Baylan ein neues Zukunftskonzept zur Versorgung Schwedens mit nachhaltiger Energie erarbeiten. Mittelfristig sollen 3 Kernkraftwerksblöcke geschlossen werden. Vattenfall kündigte an, zwei Blöcke im Kernkraftwerk Ringhals 2018 bzw. 2020 zu schließen, während EON einen Betrieb von Oskarshamn 2 gegen 2020 aufgrund wirtschaftlicher Probleme einstellen will, da sich eine notwendige Modernisierung nicht lohne.


Im Jahr 2006 erklärte die schwedische Regierung, bis 2020 vollständig auf erneuerbare Energien umsteigen zu wollen, um sich von der Abhängigkeit von fossilen Rohstoffen zu befreien. Im selben Jahr richtete der sozialdemokratische Ministerpräsident Göran Persson für diesen Zweck ein Komitee für Öl-Unabhängigkeit ("Komiteeen för att bryta oljeberoendet i Sverige till år 2020") ein, das konkrete Pläne erarbeitete. Der Bericht empfiehlt bis zum Jahr 2020 folgende Ziele zu verwirklichen:

Um die Ziele zu erreichen sollen bis zum Jahr 2020 mindestens 75 Prozent aller neuen Gebäude in Niedrigenergiebauweise errichtet werden. Bestehende Häuser sollen modernisiert und auf Fern- bzw. Nahwärme, Biokraftstoffe oder Wärmepumpenheizungen umgerüstet werden. Im Jahr 2013 war Schweden das Land, in dem die Energiewende weltweit am weitesten vorangeschritten war.

Der Dienstleistungsbereich erwirtschaftet heute 70 % des BIP, was sich vor allem darauf zurückführen lässt, dass der öffentliche Sektor in den letzten Jahrzehnten so stark gewachsen ist. Dennoch steht der private Dienstleistungsbereich für mehr als zwei Drittel der Produktion.

Der Fremdenverkehr trägt mit etwa 3 % (3,3 Mrd. Euro, 2000) zu Schwedens BIP bei. Vier Fünftel der Touristen sind Inländer und nur ein Fünftel kommt aus dem Ausland. Von den Auslandstouristen kamen 1998 23 % aus Deutschland, 19 % aus Dänemark, 10 % aus Norwegen und je 9 % aus Großbritannien und den Niederlanden.

Schwedens Wirtschaft ist stark vom internationalen Handel abhängig. Die wichtigsten Exportländer sind Deutschland (10,2 % des Exportes im Jahr 2016), Norwegen (10,1 %), Vereinigte Staaten (7,0 %), Dänemark (7,0 %) und Finnland (6,7 %). Die wichtigsten Exportprodukte sind Maschinen (14,2 % des Exportes 2016), Elektro- und Elektronikprodukte (14,9 %) und KFZ und KFZ-Bestandteile (12,6 %). Die wichtigsten Importländer sind Deutschland (18,8 % des Importes im Jahr 2016), Niederlande (8,3 %) und Norwegen (8,2 %). Die wichtigsten Importprodukte sind Elektro- und Elektronikprodukte (15,3 % des Importes 2016), KFZ und KFZ-Bestandteile (12,1 %) und Nahrungsmittel (9,7 %)

Vergleichsweise hoch ist der Anteil ausländischer Direktinvestitionen in Schweden. Das kann darauf zurückgeführt werden, dass die schwedische Wirtschaft von einer kleinen Anzahl international tätiger Konzerne dominiert wird. Etwa 50 Konzerne kommen für zwei Drittel des schwedischen Exportes auf.

Schweden ist der zehntgrößte Rüstungsexporteur der Welt.


Schweden besitzt ein gut ausgebautes Eisenbahnnetz, das vor allem im dichter besiedelten Süden die wichtigsten Städte miteinander verbindet. Größter Anbieter sind die Statens Järnvägar (SJ). Daneben existieren mehrere kleinere Eisenbahngesellschaften mit lokaler Bedeutung. In den letzten Jahren ist das Eisenbahnnetz aus ökonomischen Gründen verkleinert worden. Das betraf beispielsweise die Inlandsbahn nach Nordschweden. Von Bedeutung ist der Hochgeschwindigkeitsverkehr mit dem modernen SJ X2, der Stockholm, Göteborg, Malmö/Kopenhagen und mehrere kleinere Städte miteinander verbindet. Schweden ist mit Dänemark zwischen Malmö und Kopenhagen über die Öresundverbindung verbunden. Größter Logistikanbieter im Schienengüterverkehr ist die Green Cargo AB.

Schweden besitzt ein sehr gut ausgebautes Straßennetz mit einer guten Infrastruktur an Raststätten, das auf stärker frequentierten Strecken autobahnartig ausgebaut wird. Autobahnen "(motorväg)" verbinden hauptsächlich die drei Ballungsregionen um Stockholm, Göteborg und Malmö. Über die Öresundbrücke verläuft eine mautpflichtige Autobahn.

Weit verbreitet sind bei Fernstraßen wechselseitig dreispurige Straßen, wobei die mittlere Spur als Überholspur jeweils einer Richtung benutzt wird. Landstraßen und kleinere Wege sind in ganz Schweden oft unbefestigt. Bis 1967 herrschte in Schweden Linksverkehr. ("Siehe Hauptartikel Dagen H", ‚Tag H‘, H für – ‚Rechtsverkehrumstellung‘)

Überlandbusse stellen ein beliebtes Verkehrsmittel dar, weil sie preisgünstig sind und ein engmaschiges Netz anbieten.

Von großer Bedeutung bei den längeren Inlandsverbindungen beispielsweise nach Nordschweden ist der Flugverkehr. Fast jede Mittel- und Großstadt verfügt über einen Verkehrsflughafen. Die größten Flughäfen sind die Flughäfen Stockholm/Arlanda, Göteborg/Landvetter, Stockholm-Skavsta sowie der Flughafen Malmö.

Als Land mit einer langen Küstenlinie und vielen natürlichen Seehäfen hat Schweden traditionell eine weit entwickelte Schifffahrt. Insbesondere die Küstenschifffahrt und die Fährverbindungen besitzen eine hohe Bedeutung. Wichtige Häfen befinden sich in Göteborg, in Malmö, in Helsingborg, in Trelleborg, in Karlshamn, in Karlskrona und im Raum Stockholm.

Marktführer der Personen- und Fahrzeugbeförderung mit Fähren ist die Stena Line.

Am 6. Januar wird "Trettondedag jul" (dreizehnter Weihnachtstag, auch "Trettondag jul") begangen. Dieser Tag entspricht dem deutschen Dreikönigstag und ist im hauptsächlich protestantischen Schweden ein staatlicher Feiertag.

Am "Tjugondedag jul" (zwanzigster Weihnachtstag, auch "Tjugondag jul") oder "Tjugondag Knut" (13. Januar) ist die Weihnachtszeit vorbei. Es finden gelegentlich Abschlussfeste mit Weihnachtsbaumplünderung statt. Die Kerzen und der Schmuck werden entfernt und der Baum hinausbefördert.

"Påsk" (Ostern) wird im ganzen Land gefeiert – bis in die 1970er Jahre hinein war der Karfreitag ein stiller Tag mit geschlossenen Geschäften und Trauermusik im Radio, heute ist das außer in strikt religiösen Kreisen Vergangenheit. Am Karsamstag laufen die Kinder als "Osterhexen (påskhäxor)" verkleidet herum, um Süßigkeiten oder Geld einzusammeln. Karfreitag und Ostermontag sind gesetzliche Feiertage.

Der "Valborgsmässoafton" wird am 30. April gefeiert und entspricht der deutschen Walpurgisnacht. Das Volk versammelt sich um große Lagerfeuer. Es werden Reden über den Frühling gehalten und Frühlingslieder gesungen. Vor allem in den beiden alten Universitätsstädten Lund und Uppsala ist "Valborg" oder "Siste april" am Abend vor dem 1. Mai ein wichtiges Studentenfest. In Uppsala beginnt das Fest nach einem Sektfrühstück bereits um 10 Uhr, wenn selbstgebaute fantasievolle Boote beim Wettrennen durch den "Fyrisån" gesteuert werden. Im Anschluss an das feierliche Mützenaufsetzen um 15 Uhr zieht man im "champagne-galopp" den Carolinahügel hinunter bis in die überfüllten Studentenkneipen, wo ausgelassene Trinkgelage beginnen. Die Studenten feiern den beginnenden Frühling oft bis in die frühen Morgenstunden in den Parks und Straßen der Stadt mit Spielen, Picknick und übermäßigem Alkoholgenuss.

Der 6. Juni, "Svenska flaggans dag", ist der offizielle Nationalfeiertag Schwedens. Ursprünglich 1916 als „Flaggentag“ ins Leben gerufen, ist der 6. Juni seit 1983 „Nationaltag“ und erst seit 2005 auch gesetzlicher Feiertag. Dieser Nationaltag wird jedoch nicht richtig gefeiert und unter der Bevölkerung weithin als unbedeutend empfunden.

Das "Midsommarfest" wird in der ersten Nacht zum Samstag nach dem 21. Juni gefeiert. Die Heftigkeit des Feierns dieses Wochenendes ist nur mit Weihnachten vergleichbar. Wenn am Johannisabend Ende Juni das Sonnenlicht im Norden 24 Stunden lang zu sehen ist und im Süden nur wenige Stunden lang in blauen Dämmerschein übergeht, ist Schweden am schönsten. Der Feiertag ist eine uralte Tradition und wurzelt in den vorgeschichtlichen Sommersonnenwendfeiern. Um den mit Birkenreisig und Blumen geschmückten Maibaum, das vielleicht bekannteste schwedische Nationalsymbol, wird überall in Schweden getanzt und gesungen. Im ganzen Land herrscht ausgelassene Feststimmung.

Im August kamen früher die ersten frischen Krebse auf den Markt. Das dazugehörige Fest wird "Kräftskiva" genannt und kann zu beliebiger Zeit stattfinden. Man isst, so viel man schafft, von den in einem kräftigen Dillsud gekochten Krebsen und trinkt dazu Schnäpse. Als Schmuck dienen Girlanden und lustige Hüte.

In Nordschweden gibt es zum Ende des Sommers noch das "Surströmmingsskiva". Der Verzehr der in einer Dose vorgegorenen Heringe mit Kartoffeln oder tunnbröd (Dünnbrot – eine Vorstufe des Knäckebrots aus Norrland) erfordert aber unempfindliche Geruchsnerven.
Das "Luciafest" beginnt am Morgen des 13. Dezember und ist in Schweden der Tag der Lichterkönigin. Die älteste Tochter erscheint als Luciabraut in einem weißen Kleid und einem Kranz aus Preiselbeerzweigen und brennenden Kerzen auf dem Kopf. Die „Lussebrud“ weckt die Familie und serviert das Frühstück am Bett. Im ganzen Land werden Schulen und Arbeitsstätten in den frühen Morgenstunden von magisch schimmernden Luciazügen besucht. Junge Mädchen in fußlangen weißen Gewändern mit Kerzen auf dem Kopf und in den Händen werden von weißgekleideten jungen Männern begleitet, den „Sternjungen“, die bei dieser Gelegenheit einen langen, spitzen, mit einem Stern gekrönten Hut tragen. Zusammen singen sie die traditionellen Gesänge, die zur Vorweihnachtszeit und zu Weihnachten gehören. Von diesem Tag an und über die gesamte Weihnachtszeit hinweg isst man ein besonderes, mit Safran gewürztes und gefärbtes, Hefegebäck "(Lussekatter)".

Bei der Rangliste der Pressefreiheit 2017, welche von Reporter ohne Grenzen herausgegeben wird, belegte Schweden Platz 2 von 180 Ländern. Das Land hatte damit, hinter dem Nachbarland Norwegen, die freieste Presse der Welt.
Die öffentlich-rechtliche Fernsehgesellschaft Sveriges Television AB (SVT) sowie Sveriges Radio haben ihren Sitz in Stockholm. Dort befindet sich auch seit Anfang der 90er Jahre das private TV4, während das Ende der 1980er-Jahre gegründete private TV3 in London ihren Sitz fand, um das damalige Monopol von SVT zu umgehen.

Nachdem in den 80er Jahren Kabelfernsehen eingeführt wurde und somit auch ausländische Privatsender in Schweden zu sehen waren, wurden ab 1990 auch schwedische Anbieter für privates Radio und Fernsehen zugelassen.

Überregionale Tageszeitungen sind die in Stockholm erscheinenden Dagens Nyheter, Svenska Dagbladet und Dagens Industri. Zu weiteren Printmedien siehe auch die Liste von Zeitungen.

Im Jahr 2016 nutzte 93,1 % der Bevölkerung das Internet.

Unter „schwedischer Literatur“ versteht man die in schwedischer Sprache geschriebene Literatur, also neben der Literatur aus Schweden – einschließlich der von Einwanderern in Schwedisch geschriebenen – auch die Literatur von den Åland-Inseln und die von Finnlandschweden geschriebene Literatur. Die schwedische Literatur ist ein Teil der skandinavischen Literatur.

Seit ABBA gilt schwedische Popmusik als Exportschlager. Infolge des Erfolgs von ABBA schafften in den 80er und 90er Jahren weitere schwedische Popbands wie Roxette, Rednex und Ace of Base den internationalen Durchbruch. Aber auch im Bereich des Rock und Metal erlangten zahlreiche schwedische Bands seit den 80er Jahren weltweiten Erfolg - die Bandbreite international bekannter schwedischer Rockbands reicht von Glam-Rock (Europe) über Rock 'n Roll (Backyard Babies), Indie-/Alternative Rock (The Cardigans, Peter Bjorn and John, Shout Out Louds) und Punkrock (Refused, The Hives) bis hin zu Heavy Metal (In Flames, Evergrey, Hammerfall). Im Bereich des Metal wurde allem die Göteborger Metal-Szene der 90er Jahre international bekannt und einflussreich, als Bands wie At The Gates, In Flames, Dark Tranquillity und Soilwork dazu beitrugen, einen Stil zu entwickeln, der heute als Melodic Death Metal bekannt ist. Ein weltbekannter schwedischer DJ ist Avicii. Max Martin ist der erfolgreichste schwedische Musikproduzent und Songschreiber - er wurde in den 90er Jahren durch seine Arbeit für Rednex und Ace of Base bekannt und schrieb und produzierte ab den späten 90ern unter anderem für Britney Spears, Katy Perry, *NSYNC, die Backstreet Boys und Bon Jovi. Heute gilt Schweden deshalb neben den USA, Großbritannien, Kanada und Australien als eine der wichtigsten Musikexport-Nationen der Welt.

Auch Chormusik aus Schweden – die von traditioneller Folklore über die beliebten Trinklieder bis zu klassischer Chorliteratur eine große Bandbreite bietet – hat in Deutschland eine Anhängerschaft, die zur Gründung einiger speziell darauf ausgerichteter Chöre geführt hat: Unter anderem „De tokiga trollen“ aus Leverkusen, „Schwedischer Chor München“, „Swensk Ton“ in Frankfurt oder „Der Schwedische Chor in Stuttgart“.

Zu den ältesten Volksmelodien dürften die Weisen der schwedischen Kuhhirtinnen gehören "(vallåt)". Die Melodien sind Signalrufe für andere Kuhhüterinnen, die verschiedene Bedeutungen haben können (verlorenes Tier, wiedergefundenes Tier usw.) oder direkte Anweisungen an die Herde (Rast, Schlaflieder, Weidelieder usw.). Ob die Melodiefolgen durch Musikinstrumente (Kuhhörner, Luren) geprägt sind oder von Anfang an gesungen wurden, kann nicht mit Sicherheit bestimmt werden.

Viele Hirtenweisen sind in die Tanzmusik übergegangen oder dienten als Quelle für die nationalromantische klassische Musik (Alfvén, Atterberg). In der Tanzmusik, die sich wohl vor allem im Barock entwickelte, dominieren die Geige (Spielmannsmusik), die sich seit Ende des 17. Jahrhunderts in Schweden verbreitete, und die Tanzformen der Polka (ursprünglich aus Böhmen), des Menuetts und der Polska. Dabei ist man sich nicht einig, inwieweit die Tanzform der Polska teilweise bereits als Bauerntanz vor polnischen Einflüssen im 16. und 17. Jahrhundert existierte. Vor dem allgemeinen Gebrauch der Geige waren die Schlüsselfidel (schwedisch "nyckelharpa", seit dem Spätmittelalter gebräuchlich) und die Sackpfeife übliche Volksinstrumente. Die nyckelharpa konnte sich als Instrument bis in die Gegenwart halten. Nach technischen Weiterentwicklungen (chromatische Nyckelharpa) erlebt sie heute einen neuen Aufschwung auch außerhalb der Volksmusik, beispielsweise in der Musik der Mittelalterszene.

Die schwedische Volksmusik geriet durch die pietistischen und frömmlerischen Bewegungen auf dem Lande im Laufe des 19. Jahrhunderts in starke Bedrängnis. Instrumente der Volksmusik galten als Troll- und Teufelszeug. Entscheidend zum Überleben der Volksmusik beigetragen hat der Maler Anders Zorn, der unterhalb des Gesundaberges am Siljanssee nahe seinem Heimatort Mora in Dalarna seit 1906 Volksmusikwettbewerbe durchführte. Auf diese Weise gelang es ihm, die alten Melodien und Instrumente wieder populär zu machen. Eine ähnliche Gefährdung erlebten die samische Volksmusik, der Joik und die Samentrommel, die während der Zeit der Missionierung im 17. und 18. Jahrhundert als Teufelsmusik verpönt waren. Die Trommeln wurden systematisch eingesammelt. Der Joik ist ein Lied, das im Text und lautmalerisch in der Melodie die Natur, Tiere, Menschen, freudvolle oder traurige Ereignisse beschreibt. Die Trommeln wurden im Rahmen von schamanistischen Bräuchen verwendet (Wahrsagen, Opfer, Voraussagen usw.).

Bekannte zeitgenössische Volksmusiker und Sänger sind z. B. Ulrika Bodén, Emma Härdelin, Lena Willemark, Anders Norudde und Benny Andersson.

Johan Helmich Roman (1694–1758) gilt als eigentlicher Vater der schwedischen Kunstmusik. Roman orientierte sich an Georg Friedrich Händel, schrieb Tafelmusik "(Drottningholmsmusiken)," aber auch die erste schwedischsprachige Messe "(Then svenska messan)". Unter Gustav III. erlebte die Oper eine erste Blütezeit (damals entstanden auch Werke mit betont nationalen Inhalten wie etwa Johann Gottlieb Naumanns „Gustav Vasa“).

Franz Berwald (1796–1868) und Adolf Fredrik Lindblad (1801–1878) gehören zu den ersten bedeutenden Sinfonikern, die an die deutsche Klassik und Romantik anknüpfen. Für beide ist Beethoven das große Vorbild. Berwald erlangte mit seinen Sinfonien auch internationale Anerkennung und schrieb erste Tondichtungen (Älvalek). Lindblad erlangte vor allem wegen seiner Chorwerke und Lieder große Beliebtheit. Ludvig Norman (1831–1855) dominierte als Sinfoniker die Mitte des 19. Jahrhunderts. Seine Symphonien schließen an die romantische Musik Niels Wilhelm Gades an und stehen der deutschen Romantik Schumanns und Mendelssohns nahe. Ivar Hallström folgte mit seinen Opern (Den Bergtagna) und Balletten französischen Vorbildern. Dagegen schloss sich Andreas Hallén der neudeutschen Schule an mit seinen Tondichtungen „Die Toteninsel“ oder seiner Oper „Harald Viking“, in der Anklänge an Wagners Werk unverkennbar sind.

Die Volksmusik und ihr reicher Melodienschatz wurde von August Söderman „wiederentdeckt“. Mit seinen Tanzsuiten, seiner Schauspielmusik und Chorwerken versucht er eine nationale schwedische Musiksprache zu finden. Seine Versuche wurden zur Inspirationsquelle der Spätromantiker. Die Musik der Jahrhundertwende wurde von mehreren großen Persönlichkeiten geprägt, denen es gelang, eine nationale schwedische aber auch sehr persönliche Musiksprache zu schaffen: Wilhelm Stenhammar, Hugo Alfvén und Wilhelm Peterson-Berger. Wilhelm Stenhammar ist von den dreien der „klassischste“ und der überlegene Beherrscher der musikalischen Großformen (Sinfonien, Klavierkonzerte, Kantaten). Brahms und Wagner sind für seine Musiksprache Vorbilder. Hugo Alfvén schuf mit seinen Rhapsodien (Midsommarvaka, Uppsala rapsodi, Dalarapsodi), die schwedische Volksmusik als Motive verwenden, eine nationale schwedische Musiksprache. Wilhelm Peterson-Berger schuf bedeutende Sinfonien, Opern (Arnljot) und Klavierwerke (Frösöblomster, I Somras), in denen er großartige Naturstimmungen in Klang und Melodie umsetzt. Auch er steht Wagner nahe, aber auch Edvard Grieg und klingt zuweilen überraschend modern und erinnert in seinen Klängen an den Impressionismus Debussys, den er eigentlich ablehnte.

Die Spätromantik ist intensiv und dauert bis um 1950 an. Dominante Musikerpersönlichkeit dieser Zeit ist Kurt Atterberg mit seinen Sinfonien, deren Musiksprache sich an Richard Strauss orientiert. Auch Atterberg gelingen ungewöhnliche Klangfarben zur Schilderung von Naturstimmungen, die zum Teil sein Vorbild Strauss an Raffinesse noch übertreffen. In den 1930er-Jahren beginnt eine Gruppe von Komponisten, die sogenannten „30-talisterna“, an neuere Musikströmungen anzuknüpfen mit neoklassizistischen Werken (Lars-Erik Larsson, Gunnar de Frumerie, Dag Wirén). Hilding Rosenberg wird mit seinen gewaltigen Sinfonien, die sich inhaltlich mit komplexen geistigen Zusammenhängen auseinandersetzen (Johannesapokalypse), zum großen Neuerer der Sinfonik. Karl-Birger Blomdahl setzt mit seiner Weltraumoper „Aniara“ (1959) neue Maßstäbe für die Entwicklung der modernen Musik in Schweden, in dem er auch elektronische Klänge (Tonband) einführt, obwohl die Musik sich zu einem großen Teil noch sehr konservativ an der neoklassizistischen Tonsprache der 1940er-Jahre orientiert. Heute ist Schweden international für seine Popmusik bekannt. Bands wie ABBA, Roxette, Ace of Base und Army of Lovers sind weltbekannt.

Schweden hat eine Reihe von Opern- und Theaterhäusern, die meisten davon befinden sich in Stockholm, wie die Königliche Oper, das Schlosstheater Drottningholm, das Königliche Dramatische Theater, das Chinateatern, das Regina Theater und das Jüdische Theater Stockholm. Weitere Häuser befinden sich unter anderem in Malmö (Musiktheater Malmö), in Umeå (NorrlandsOperan), in Kristianstad (Theater Kristianstad), in Karlstad (Wermland Opera) und in Göteborg (GöteborgsOperan).

Um 1910 begann man mit der regelmäßigen Produktion von Spielfilmen. Der schwedische Film erreichte bald eine Qualität, die ihn international bekannt machte. Die Regisseure Victor Sjöström und Mauritz Stiller sowie die Schauspielerin Greta Garbo erlangten Weltruhm. Aber mit der Einführung des Tonfilmes und der damit verbundenen Begrenzung auf den kleinen, schwedischsprachigen Markt sank der Film auf ein provinzielles Niveau ohne künstlerischen Anspruch ab. Mit Ingrid Bergman hatte Schweden allerdings bereits den zweiten großen Hollywoodstar. Erst nach dem Zweiten Weltkrieg erlebte der schwedische Film selbst einen neuerlichen künstlerischen Aufschwung, zuerst im Dokumentarfilm, beispielsweise Arne Sucksdorffs 1948 mit dem Oscar ausgezeichneten Film „Menschen in der Stadt“, und danach als Autorenfilm mit Ingmar Bergman, Jan Troell und Bo Widerberg als herausragende Persönlichkeiten. Bergman erreichte mit Filmen wie Wilde Erdbeeren, Szenen einer Ehe, Das siebente Siegel, Herbstsonate und Fanny und Alexander einen weltweit legendären Status. Auch schwedische Kinder- und Jugendfilme, zumeist von Olle Hellbom nach einer Vorlage von Astrid Lindgren verfilmt, erlangten internationale Aufmerksamkeit. Die Schaffung des Schwedischen Filminstitutes in den 1960er-Jahren trug zu einer Qualitätssicherung bei, die bis heute andauert.

Zum „Welterbe in Schweden“ gehören (Stand 2017) fünfzehn UNESCO-Welterbestätten, darunter dreizehn Stätten des Weltkulturerbes, eine Stätte des Weltnaturerbes und eine gemischte Kultur- und Naturerbestätte. Zwei dieser Stätten sind grenzüberschreitend oder transnational. Die erste Welterbestätte wurde 1991 in die Welterbeliste aufgenommen, die bislang letzte Welterbestätte wurde 2012 eingetragen.
"Idrott" (Leibesübungen) haben in Schweden eine lange Tradition. Schon in den Höhlenzeichnungen wurden Skiläufer und Schwimmer abgebildet. Olaus Magnus beschreibt Leibesübungen als Teil der nationalen Identität im 15. Jahrhundert. Bei den Olympischen Spielen 1912 (in Stockholm) war Schweden zusammen mit den USA das mit Abstand erfolgreichste Land. Um vor allem gegenüber den Nachbarn Dänemark, Norwegen und Finnland zu glänzen sowie die Überlegenheit der Schwedischen Gymnastik gegenüber dem Sport zu demonstrieren, gab es erhebliche Investitionen in die Förderung des Spitzensports. Durch das Einmischen des amerikanischen Präsidenten Theodore Roosevelt in die Olympischen Spiele 1908 waren zudem die Spiele so politisiert, dass es wichtig wurde zu gewinnen. Schweden umging die Amateurbedingungen der Zeit, indem es die Männermannschaft (sofern die Männer interessiert waren) zu sechs Monaten Wehrdienst einzog und insofern den Staatsamateur erfand.
In Schweden erfreuen sich heute Mannschaftssportarten wie Eishockey, Handball, Innebandy, Bandy oder Fußball großer Beliebtheit, da sich hiermit die nationale Identität besser darstellen lässt als durch Individualsportarten - zumal das Herausstellen des Individuums nicht dem schwedischen Nationalcharakter entspricht. Daneben sind insbesondere Wintersportarten (speziell Langlauf) populär.

Das Eishockeyteam Schwedens gehört zu den besten der Welt. Unter anderem spielen Spieler wie Peter Forsberg, Markus Naslund, Mats Sundin, Henrik Zetterberg, Nicklas Lidström, Daniel Alfredsson für das „Tre Kronor“-Team. Bei den Olympischen Winterspielen 2006 in Turin holten sie die Goldmedaille im Finale gegen den Erzrivalen Finnland. Das bedeutete zugleich den achten Weltmeistertitel für das schwedische Team.
Die Damenauswahl konnte bei diesen Olympischen Spielen mit einem Sieg gegen die USA zum ersten Mal ein rein nordamerikanisches Finale verhindern. Im Endspiel scheiterte das Team aber an Kanada.

Die erfolgreichsten schwedischen alpinen Skiläufer sind Ingemar Stenmark, Pernilla Wiberg und Anja Pärson. Die bekanntesten Schweden im nordischen Skisport sind die Langläufer Gunde Svan, Thomas Wassberg und Torgny Mogren sowie der Skispringer Jan Boklöv, der als Erfinder des sogenannten V-Stils gilt. Magdalena Forsberg ist die erfolgreichste Biathletin in der Geschichte des Weltcups.

Schweden dominierte vor dem Zweiten Weltkrieg gemeinsam mit Österreich die Herrenkonkurrenz im Eiskunstlauf. Ulrich Salchow ist mit zehn Weltmeisterschaftstiteln bis heute unangefochten der erfolgreichste Eiskunstläufer bei Weltmeisterschaften. Gillis Grafström ist mit drei Olympiasiegen und einer Silbermedaille der erfolgreichste Eiskunstläufer bei Olympischen Spielen.
Im Fußball stand Schweden 1958 bei der Fußball-Weltmeisterschaft im eigenen Land im Finale gegen Brasilien. 1950 und 1994 erreichte die Mannschaft Platz 3. Zuletzt spielten für das Nationalteam viele internationale Stars wie Henrik Larsson, Fredrik Ljungberg oder Olof Mellberg, derzeit noch Zlatan Ibrahimović. An der Weltmeisterschaft 2006 in Deutschland nahmen sie ebenfalls teil, schieden aber im Achtelfinale nach einer Niederlage gegen Deutschland aus. Für die Weltmeisterschaft 2010 konnte sich Schweden aber nicht qualifizieren. Die Frauen-Nationalmannschaft gehört zu den besten der Welt und die schwedische Damallsvenskan gilt neben der deutschen Bundesliga als stärkste Liga Europas.
1954, 1958, 1990 und 1999 war die schwedische Männer-Handballnationalmannschaft Weltmeister. Europameister wurden das Land 1994, 2000 und 2002. 1992, 1996 und 2000 belegte das schwedische Handballteam jeweils den zweiten Platz bei den Olympischen Spielen. Aktuelle schwedische Nationalspieler sind unter anderem Stefan Lövgren, Marcus Ahlm, Pelle Linders, Kim Andersson, Mattias Andersson und Henrik Lundström. Der Schwede Magnus Wislander wurde zum Welt-Jahrhundert-Spieler gekürt.

Im Tennis hat Schweden einige der weltbesten Spieler hervorgebracht. Dazu gehören der fünfmalige Wimbledonsieger Björn Borg (elf Grand Slam Titel), sowie Mats Wilander (sieben Grand Slam Titel) und Stefan Edberg (sechs Grand Slam Titel).

Auch im Tischtennis kamen einige Weltklassespieler aus Schweden, so u. a. Jan-Ove Waldner (zweifacher Weltmeister) und Mikael Appelgren. Die Nationalmannschaft gehörte seit den 1980er Jahren zu den besten der Welt, konnte u. a. 1989, 1991 und 1993 dreimal in Folge die Weltmeisterschaft gewinnen und ist mit 14 Titeln Rekordeuropameister. Die letzten großen internationalen Erfolge (Weltmeister 2000, Europameister 2002) liegen jedoch inzwischen schon längere Zeit zurück.

In der Mannschaftssportart Unihockey "(innebandy)" gewann das schwedische Herrenteam sechs der bisher sieben ausgetragenen Weltmeisterschaften; die schwedischen Damen gewannen zweimal den Weltmeistertitel. Neben Finnland und der Schweiz gehört Schweden zu den Gründungsvätern des Unihockey-Weltverbandes IFF.

Auch im Motorsport gab es einige erfolgreiche Schweden wie z. B. die beiden Rallye-Weltmeister Björn Waldegard und Stig Blomqvist sowie in der Formel 1 den zweimaligen Vizeweltmeister Ronnie Peterson. Im Speedway gewannen Tony Rickardsson, Ove Fundin, Per Jonsson, Anders Michanek und Björn Knutsson insgesamt 14 Goldmedaillen für Schweden in der Speedway-Einzelweltmeisterschaft. Tony Rickardsson ist mit sechs WM-Titeln der erfolgreichste Speedwayfahrer aller Zeiten. Erik Stenlund und Per-Olof Serenius wurden jeweils Eisspeedway-Weltmeister. Anders Michanek gewann 1977 zudem noch die Langbahn-Weltmeisterschaft.




</doc>
<doc id="4417" url="https://de.wikipedia.org/wiki?curid=4417" title="Spezialeffekt">
Spezialeffekt

Als Spezialeffekt (), auch (von englisch lautmalerisch „ef-eks“) bzw. kurz SPFX oder SFX (doppeldeutig mit SFX – sound effects), wird eine mechanische oder chemische Technik bezeichnet, um bestimmte außergewöhnliche Erscheinungen, wie etwa Explosionen, in Theater oder Film zu erzeugen. Im Gegensatz zu den Visuellen Effekten (VFX) werden Spezialeffekte direkt am Drehort erzeugt und gefilmt. Damit ist das gewünschte Ergebnis sofort überprüfbar.

Die Spezialeffekte sind eng verbunden mit anderen Institutionen wie zum Beispiel Stunttechnik und Maske. Der Übergang ist oft fließend.

Bei vielen Spezialeffekten werden die gewünschten Ereignisse durch ähnlich wirkende Effekte simuliert, zum Beispiel zerbrechendes Glas (Filmglas), Blut (Filmblut), Schnee. Oft werden die gewünschten Ereignisse auch künstlich nachgestellt oder wirklich durchgeführt, zum Beispiel Regen, Feuer, Explosionen, einstürzende Gebäude oder Brücken.

Bei der Körperbemalung ("bodypainting") bezeichnet man Spezialeffekte als die Kunstform, bei der dem Körper außer Farbe durch Pinsel, Schwamm und/oder Airbrush aufgetragen zusätzliche „Anbauten“ wie Latex-Masken, Perücken oder Ähnliches als Erweiterung zum Gesamtkunstwerk dienen.

Weitere Beispiele:

Grundsätzlich erhöhen alle Effekte die sinnlichen Realitätseindrücke (vor allem optisch und auditiv), allerdings können sie auch zu deren parodistischer Überzeichnung eingesetzt werden. So zielen Spezialeffekte nicht nur auf die Steigerung der Erlebnisintensität des Zuschauers ab, sondern können durch Verweis auf sein Fiktionsbewusstsein den Zuschauer auch auf Distanz halten. In Genres wie z. B. Horror- oder Science-Fiction-Film werden Spezialeffekte zur Erzeugung von Schockbildern verwendet. Sie ziehen die Aufmerksamkeit der Zuschauer auf sich, indem sie das Besondere des Schreckens zeigen.




</doc>
<doc id="4427" url="https://de.wikipedia.org/wiki?curid=4427" title="Liste der Städte in Deutschland">
Liste der Städte in Deutschland

Die Liste der Städte in Deutschland enthält eine vollständige Auflistung aller 2060 Städte in Deutschland in alphabetischer Reihenfolge (Stand: 1. Januar 2018).

Es sind nur die (verwaltungsrechtlich selbstständigen) Gemeinden (Kommunen) aufgeführt, die das Stadtrecht besitzen.

Auf die einzelnen Länder entfallen folgende Anzahlen:




</doc>
<doc id="4432" url="https://de.wikipedia.org/wiki?curid=4432" title="Sergei Michailowitsch Eisenstein">
Sergei Michailowitsch Eisenstein

Sergei Michailowitsch Eisenstein (, wiss. Transliteration "Sergej Michajlovič Ėjzenštejn"; *  in Riga, Russisches Kaiserreich; † 11. Februar 1948 in Moskau, Sowjetunion) war ein sowjetischer Regisseur. Seine berühmtesten Werke sind die Revolutionsfilme "Panzerkreuzer Potemkin" und "Oktober".

Seine Mutter war die Russin Julia Konezkaja, sein Vater war der Rigaer Stadtarchitekt und Staatsrat Michail Eisenstein, der im Zentrum Rigas Jugendstilbauten errichtete, deutsch-schwedischer Abstammung war und vom Judentum zum russisch-orthodoxen Glauben konvertierte.

Der in großbürgerlichen Verhältnissen aufgewachsene Sergei Eisenstein studierte am Petrograder Institut für Zivilingenieure. Doch er merkte schnell, dass das Theater seine große Leidenschaft war. 1918 wurde er zur Roten Armee einberufen und wirkte bei einem Agitpropzug als Karikaturenzeichner. 1920 wechselte er in das Armeetheater, doch noch im selben Jahr wurde er zum Studium der japanischen Sprache nach Moskau delegiert. Dies brach er ab und stieg als Bühnenbildner im Proletkult-Theater ein. Dort nahm er an Regiekursen des extremen Theatererneuerers Wsewolod Meyerhold teil. Er setzte seine künstlerische Laufbahn fort und sammelte Filmerfahrungen, die er in der Bühnenarbeit einsetzte (erstmals verwendete Eisenstein filmische Sequenzen auf der Bühne 1923 in einer Inszenierung von Ostrowskis "Eine Dummheit macht auch der Gescheiteste"). Mit dem Konzept der Attraktionsmontage begründete er zuerst theoretisch, dann in seinen Filmen den Versuch einer eigenständigen, revolutionär geprägten Kunstform. 1929 ging er das Studium der neuen Filmtechnik an, und um Geld zu verdienen, drehte er zwei Filme im Ausland (Frauennot–Frauenglück, La Romance sentimentale). Danach bestritt er die Teilnahme an diesen Filmen. Auf Einladung der Paramount ging er nach Hollywood und hielt Vorlesungen an den größten Universitäten Europas und der USA. Später unterrichtete er an der Moskauer Filmhochschule und schrieb einige Bücher.

Seinen internationalen Durchbruch als Regisseur hatte er mit dem Revolutionsfilm "Panzerkreuzer Potemkin", der heute genauso zu den wegweisenden Klassikern der Filmgeschichte gezählt wird wie seine Filme "Oktober" und "Iwan der Schreckliche". Seine späteren Filme wurden teilweise Opfer der sowjetischen Zensur. Ab 1934 war Eisenstein mit der Journalistin und Filmkritikerin Pera Ataschewa (1900–1965) verheiratet. Während der Stalinschen Säuberungen 1937/38 bereitete die Geheimpolizei NKWD einen Schauprozess mit ihm als Angeklagten vor, doch kam es nicht zu dem Verfahren. Die Akten darüber wurden in den 1990er Jahren entdeckt.

Eisenstein arbeitete mit dem russischen Komponisten Sergei Prokofjew für zwei seiner Filme zusammen: "Alexander Newski" und "Iwan der Schreckliche" (Teil I und Teil II). Letzterer war als Dreiteiler geplant, jedoch konnte Eisenstein nur die ersten beiden Teile fertigstellen. Während der erste Teil von "Iwan der Schreckliche" 1945 noch mit dem Stalinpreis ausgezeichnet wurde, unterlag der zweite Teil wegen der nicht ausreichend linientreuen Umsetzung sowjetischer Geschichtsbilder einem Aufführungsverbot. Stalin persönlich verlangte eine „Nachbearbeitung“. Gemeinsam mit Premierminister Wjatscheslaw Molotow gab Stalin Eisenstein dafür konkrete Anweisungen. So bemängelte er, dass Eisenstein den Zaren als unentschlossenen Herrscher so wie Hamlet dargestellt habe. Überdies sei die Opritschnina nicht als „fortschrittliche Kraft“ gezeigt.

Zudem arbeitete Eisenstein seit seinem Film "Streik" mit dem Kameramann Eduard Tisse zusammen; und die Musik für "Oktober" schrieb Edmund Meisel, eine spätere Musikbegleitung wurde zusammengestellt aus Sinfonien von Dmitri Schostakowitsch.

Am 11. Februar 1948 erlag Sergei Eisenstein einem Herzinfarkt, während er an einem Text zur Geschichte des sowjetischen Films arbeitete. Seine zahlreichen filmtheoretischen Schriften wurden erst ab den 1960er Jahren und nur in Teilen veröffentlicht, ebenso wie seine Memoiren. Eisenstein setzte sich kritisch mit der Ausdruckskunde Ludwig Klages’ auseinander.

Eisenstein gilt, obwohl unter schwierigen Umständen tätig, theoretisch wie handwerklich (insbesondere durch seine innovative Montagetechnik) als einer der größten Regisseure und Visionäre der Filmgeschichte. Seine Werke hinterließen bleibenden Eindruck und werden bis heute oft zitiert. Für seine Verdienste erhielt Eisenstein 1941 und 1946 den Stalinpreis.



Das staatliche russische Filmarchiv Gosfilmofond Russlands wollte im Jahr 2015 die Unterstützung für das Projekt von Peter Greenaway einstellen, wenn er nicht die Hinweise auf die Homosexualität Eisensteins aus dem Skript streiche.





</doc>
<doc id="4433" url="https://de.wikipedia.org/wiki?curid=4433" title="Steven Soderbergh">
Steven Soderbergh

Steven Andrew Soderbergh (* 14. Januar 1963 in Atlanta, Georgia) ist ein US-amerikanischer Filmregisseur, Filmproduzent, Drehbuchautor, Kameramann und Filmeditor.

Unter dem Pseudonym "Peter Andrews" arbeitet er auch als Kameramann, hauptsächlich in seinen eigenen Filmen, auch taucht er öfter im Abspann für den Schnitt als "Mary Ann Bernard" auf. Sein Film "Sex, Lügen und Video" erhielt 1989 bei den Internationalen Filmfestspielen von Cannes die Goldene Palme. Damit war Soderbergh der jüngste Filmemacher, der diesen wichtigen Preis verliehen bekam. Ebenso erhielt er für "Traffic – Macht des Kartells" 2001 den Oscar.

Nach Videoproduktionen drehte er Independentfilme "(Sex, Lügen und Video", 1989; "Kafka", 1991). Das Spiel mit Zeit- und Handlungsebenen wurde zu einem Markenzeichen seiner späteren Filme "(Out of Sight", 1998, "Traffic – Macht des Kartells", 2000; "Ocean’s Eleven", 2001).

Steven Soderbergh wurde als fünftes von sechs Kindern in Atlanta (Georgia) im Osten der Vereinigten Staaten geboren. Sein Vater, Peter Andrew Soderbergh, war Professor für Erziehungswissenschaft, seine Mutter, Mary Ann Soderbergh, arbeitete früher als Psychologin. Sein Großvater väterlicherseits war ein schwedischer Immigrant aus Stockholm. Drei Monate nach seiner Geburt siedelte die Familie nach Austin (Texas), 1967 nach Pittsburgh (Pennsylvania) und 1973 nach Charlottesville (Louisiana) um. 1977 erfolgte schließlich der Umzug nach Baton Rouge, Louisiana. Soderberghs Vater wurde Dekan des Fachbereichs Erziehungswissenschaft an der "Louisiana State University". 1979 trennten sich seine Eltern. Steven Soderbergh war ein begabter Baseballspieler, entdeckte dann aber seine Liebe zum Film. Während der Schulzeit schrieb er sich in die Animationsfilmklasse ein und begann bereits im Alter von 13 Jahren, erste Kurzfilme mit einer Super-8-Kamera, die er an der Universität ausgeliehen hatte, zu drehen. In seiner Jugend sah er den Film "Der weiße Hai" von Steven Spielberg 28-mal und "American Graffiti" von George Lucas 14-mal. Die Einstellungen und Schnitte der Filme lernte er praktisch auswendig. Nach seinem Schulabschluss verdingte sich der damals 18-Jährige als Editor in Los Angeles bei der Fernsehserie "Games People Play". Er kehrte jedoch schon bald unzufrieden nach Baton Rouge zurück, wo er Drehbücher schrieb und weitere kleine Eigenproduktionen drehte.

Über einen Freund wurde er auf die Rockband Yes aufmerksam, die nach einem Regisseur Ausschau hielt, der ihre Tournee auf Film festhalten könnte. Soderbergh bekam den Job und filmte die Gruppe bei ihren Auftritten. Das Ergebnis gefiel der Band so gut, dass sie ihn bat, einen weiteren Film über sie zu drehen. Soderbergh willigte ein und es entstand der Konzertfilm "". 1986 wurde der Film für die Grammy Awards als Bestes Musik-Langvideo nominiert. 1988 heiratete Soderbergh die Schauspielerin Betsy Brantley, 1994 erfolgte die Scheidung. Es gibt eine gemeinsame Tochter.
1989 folgte der Independentfilm "Sex, Lügen und Video", zu dem er in gerade mal acht Tagen das Drehbuch verfasst hatte. Der Film wurde 1989 mit Beifall und Lob auf den Internationalen Filmfestspielen von Cannes vorgeführt und gewann die Goldene Palme. Danach folgten finanziell wenig erfolgreiche Filme wie "Kafka" (1991) und "König der Murmelspieler" (1993).

Den kommerziellen Durchbruch brachte ihm 1998 die Gaunerkomödie "Out of Sight", die nach einer Vorlage von Elmore Leonard entstand. Für "Traffic – Macht des Kartells" (2000) erhielt Soderbergh den Oscar für die beste Regie. Seitdem drehte er einige künstlerisch anspruchsvolle Filme, die er mit Top-Stars wie Brad Pitt, George Clooney und Julia Roberts besetzen konnte, was auch seinen kommerziellen Erfolg steigerte.

Im Jahr 2000 gründeten Soderbergh und George Clooney zusammen die Produktionsfirma Section Eight Productions, mit der sie fortan Filme produzierten. 2006 verließ Clooney die Firma.

Mit der Gaunerkomödie "Ocean’s Eleven" (2001) gelang Soderbergh sein größter kommerzieller Erfolg. Der Film spielte weltweit 451 Millionen US-Dollar ein. Bei den Fortsetzungen "Ocean’s 12" (2004) und "Ocean’s 13" (2006) führte er ebenfalls Regie.

Daneben entstanden auch immer wieder eher anspruchsvolle Filme wie "The Good German – In den Ruinen von Berlin" (2006) oder "Che – Revolución"/"Che – Guerrilla" (2008), die trotz Kritikerlob an den Kinokassen floppten.

Soderbergh dreht seit 2008 seine Filme mit digitalen Kinokameras.

Nach den Box-Office-Erfolgen "Contagion" (2011) und "Magic Mike" (2012), entstand 2013 mit "Side Effects" Soderberghs nächster Kinofilm. Bereits vor Erscheinen kündigte der Regisseur an, sich danach auf unbestimmte Zeit aus dem Filmgeschäft zurückziehen zu wollen. Soderbergh begründete dies unter anderem mit immer komplizierteren Arbeitsbedingungen in Hollywood sowie zu starker Beanspruchung durch seine Arbeit. Ende April 2013 hielt Soderbergh als Gastredner beim San Francisco International Film Festival eine vielbeachtete Rede zur „Lage des Films“, in der er neben der immer stärkeren Fokussierung der Studios auf die Produktion von Tentpole-Releases mit möglichst leichtverständlicher Handlung auch die massiv gestiegenen Marketingkosten und die zunehmende Diskrepanz zwischen Filmemachern und Filmproduzenten kritisierte.

Nachdem mehrere Filmstudios die Produktion abgelehnt hatten, drehte Soderbergh die Biografie des Entertainers Liberace als Fernsehfilm "Liberace – Zu viel des Guten ist wundervoll" für den Pay-TV-Sender HBO mit Michael Douglas und Matt Damon in den Hauptrollen. Der Film wurde mit 11 Emmys ausgezeichnet (u. a. als "Beste Miniserie oder Fernsehfilm" und "Bester Hauptdarsteller in einer Miniserie oder einem Fernsehfilm") und kam in Europa ins Kino. 2014 und 2015 inszenierte er die Fernsehserie "The Knick". An "Magic Mike XXL" aus dem Jahr 2015 ist er als Kameramann und Filmeditor sowie Ausführender Produzent beteiligt.









</doc>
<doc id="4435" url="https://de.wikipedia.org/wiki?curid=4435" title="Stanley Kubrick">
Stanley Kubrick

Stanley Kubrick ([]; * 26. Juli 1928 in New York; † 7. März 1999 in Childwickbury Manor bei London) war ein US-amerikanischer Regisseur, Produzent und Drehbuchautor. Seine Filme werden vor allem für ihre tiefe intellektuelle Symbolik und ihre technische Perfektion gelobt. Kubrick versuchte, das Medium selbst zu erforschen, indem er jedes Genre analytisch zerlegte, um seine Bestandteile zu etwas Neuem zusammenzusetzen. Der Regisseur war aber auch berüchtigt dafür, jede Szene bis ins kleinste Detail zu perfektionieren und dabei die Schauspieler bis an ihre psychischen und physischen Grenzen zu führen. Seine Filme oszillieren zwischen Ordnung und Chaos und ergeben so eine filmische Conditio humana.

Ihre Hauptthemen sind die Unnahbarkeit der Realität und das Scheitern der Menschlichkeit, ausgedrückt durch einfaches Akzeptieren, Ignorieren oder das Ringen der Protagonisten mit ihren dunklen, inneren Kräften oder Trieben. Authentizität, Kälte, Ehrlichkeit, Realität, Traum, Triebe sind die wohl wichtigsten Schlagwörter im Zusammenhang mit Kubricks Werken. Filmschaffende und -kritiker zählen ihn zu den bedeutendsten Filmemachern aller Zeiten, obwohl er nie einen Oscar als bester Regisseur erhalten hat.

Stanley Kubrick wurde am 26. Juli 1928 in Bronx, New York, geboren und war das erste von zwei Kindern. Seine Eltern Jacques, ein Chirurg, und Gertrude, geborene Perveler, stammten aus jüdischen Familien, alle Großeltern waren aus dem österreichisch-ungarischen Galizien eingewandert. 1934 kam Kubricks jüngere Schwester Barbara zur Welt.

Seine frühe Leidenschaft waren exzessive Lektüre, das Kino und das Schachspiel. Ab 1941 besuchte er die Taft High School, wo er Fotograf der Schülerzeitung war. Nach dem Schulabschluss begann er seine Karriere als Fotograf. Nachdem er zunächst Amateurfotos an das New Yorker Magazin "Look" verkauft hatte, bekam er mit 18 Jahren dort schließlich eine Festanstellung. Eine Fotogeschichte über einen Boxer, die er verfasste, führte ihn tiefer in die behandelte Materie ein.

Als Fotograf war er mit investigativer Berichterstattung vertraut; dementsprechend inszenierte er 1950 seinen ersten Dokumentarfilm "Day of the Fight", eine, obwohl nur 16 Minuten lange, damals aufsehenerregende Studie über individuelle Leistungen im Boxring. Motiviert durch den Erfolg und die Anerkennung, die ihm durch das Erstwerk zugekommen waren, drehte er anschließend den Dokumentarfilm "Flying Padre" und den Gewerkschafts-Werbefilm "The Seafarers".

Seine ersten, überwiegend mit geliehenem Geld finanzierten Spielfilme "Fear and Desire" (1953), ein allegorisches, zeitlich und geographisch unbestimmtes Kriegsdrama, und "Der Tiger von New York (Killer’s Kiss)" (1955), den er an United Artist verkaufte, zogen hingegen bereits die Aufmerksamkeit Hollywoods auf sich. "Der Tiger von New York" ist Kubricks letzter Film mit Happyend. Filmkennern wurde er mit dem klassischen Film noir "Die Rechnung ging nicht auf (The Killing)" ein Begriff, bevor ihm mit "Wege zum Ruhm" (mit Kirk Douglas in der Hauptrolle) der endgültige Durchbruch gelang. Der während des Ersten Weltkriegs spielende Film "Wege zum Ruhm" (Originaltitel: "Paths of Glory") thematisiert die Grausamkeit und die Sinnlosigkeit des Krieges nur am Rande. Er ist durchaus ein antimilitaristischer Film, vor allem aber eine bitterböse Parabel auf Herrschaftsstrukturen und ein Bekenntnis gegen die Todesstrafe.
In diesen Filmen finden sich bereits fast alle wesentlichen Stilelemente Kubricks: die zwischen Distanz und Involviertsein wechselnde Kamera, die sich für Handlungsabläufe mehr zu interessieren scheint als für die Motive der Handelnden; die Reduktion der Charaktere auf Spielfiguren auf einem symbolischen Schachbrett; die emotionale und moralische Gleichmütigkeit der Erzählung. Der passionierte Schachspieler Kubrick plante nach eigenen Angaben viele Filme und die handelnden Figuren analog zu den Konflikten und Bewegungen auf einem Schachbrett.
Kirk Douglas, Hauptdarsteller und ausführender Produzent des Monumentalfilms "Spartacus," engagierte Kubrick als Regisseur, nachdem der ursprüngliche Regisseur Anthony Mann nach wenigen Drehtagen gefeuert worden war. Der Film wurde zu einem Kassenerfolg, der Kubrick die finanziellen Mittel für seine folgenden Filme lieferte. Er selbst war jedoch aufgrund seines geringen Einflusses auf Drehbuch und Produktionsbedingungen sehr unzufrieden, weswegen er "Spartacus" als ein „notwendiges Übel“ bezeichnete. Kubrick nahm sich vor, nie wieder einen Film zu drehen, bei dem er nicht von der Drehbucherstellung bis zum Schnitt volle Kontrolle über die Produktion haben würde. Er verließ das Hollywood-System und blieb für die Protagonisten dort bis zum Ende seines Lebens ein öffentlichkeitsscheuer Außenseiter.

In den Jahren 1948 bis 1951 war Kubrick mit seiner Jugendliebe Toba Metz verheiratet und anschließend von 1954 bis 1957 mit der österreichischen Balletttänzerin Ruth Sobotka. Bei den Dreharbeiten zu "Wege zum Ruhm" lernte er Christiane Harlan kennen, die er 1957 heiratete. Zusammen mit ihr, den beiden gemeinsamen Töchtern Anya (1959–2009) und Vivian (* 1960) sowie seiner Stieftochter Katharina (* 1953) zog er in den frühen 1960ern nach England. Dort ließ er sich zunächst in der Nähe der Elstree-Studios bei London nieder; später kaufte er das Anwesen Childwickbury Manor im District St. Albans, wo er in den ehemaligen Stallungen Studio- und Schnitträume einrichtete. Für die Presse und in Hollywood galt er als jemand, der extrem zurückgezogen lebte; Bekannte erzählten allerdings, dass er den größten Teil seiner Zeit in der Umgebung von Familie, Freunden und Bekannten verbrachte.

Sein erster in England gedrehter Film war "Lolita" (1962). Kubrick arbeitete eng mit dem Autor des Romans, Vladimir Nabokov, zusammen. Das mehrere hundert Seiten umfassende Drehbuch, das Nabokov selbst schrieb, veränderte Kubrick entscheidend, so dass die als Skandalbuch rezipierte Handlung verfilmt werden konnte, ohne dass der Film weltweit auf dem Index landete. Bei den Arbeiten zu "Lolita" entdeckte der Regisseur den Schauspieler Peter Sellers. Sellers verkleidet sich, um Humbert zu täuschen, bereits in „Lolita“ in seiner Rolle als Quilty als Schulpsychologe Dr. Zemph.

Kubrick fragte an, ob Sellers in seinem nächsten Film "" gleich vier Rollen übernehmen könne. Dieser sagte zu, spielte anschließend jedoch „nur“ drei Figuren in dem Film. Die vierte, den Kommandanten des Bombers, übernahm Slim Pickens. Sellers wollte sie nicht spielen und brach sich bei einem Versuch prompt ein Bein.
Das große Risiko bei "Dr. Seltsam oder: Wie ich lernte, die Bombe zu lieben," die Konfrontation zu Zeiten des Kalten Kriegs als Schwarze Komödie aufzuführen, zahlte sich aus. Der Film kann auch als intelligente Antwort auf die James-Bond-Filme gesehen werden. Ebenso berühmt wurden seine nächsten beiden Filme, "" (1968) und "Uhrwerk Orange" (1971). Alle drei Filme provozierten durch eine ironische Theatralisierung bei ihrem Erscheinen heftige öffentliche Kontroversen und werden in der Filmwissenschaft immer noch diskutiert, sowohl in Bezug auf Themen und Handlung als auch der in ihnen enthaltenen Symbolik.

Der Film "Barry Lyndon" (1975), nach dem Roman von William Makepeace Thackeray (1844), hingegen war ein kommerzieller Misserfolg. Die Schönheit barocker Malerei und Musik filmisch erlebbar zu machen und das Leben jener Zeit anhand einer fiktiven Biographie von Barry Lyndon authentisch wiederzugeben, durch natürliches Kerzenlicht in allen Innenaufnahmen, brachte keinen Erfolg an der Kinokasse. Allerdings beeinflusste der Film andere Regisseure, die sich später diesem Thema widmeten.

Nach "Barry Lyndon" nahm Kubricks Produktionstempo ab. In den letzten 25 Jahren seines Lebens produzierte er nur noch drei weitere Filme. Allerdings waren sein Ruhm und das ihn umgebende „Mysterium“ derart groß, dass jede Veröffentlichung weltweit mit großen Erwartungen aufgenommen wurde. Wichtiger für Kubrick und wohl einmalig in der Geschichte Hollywoods war, dass er bei jedem Film von den großen Studios weitgehend freie Hand und ein beinahe unbeschränktes Zeitbudget bekam.

Mit Jack Nicholson drehte Kubrick den Film "Shining" (1980), eine Adaption des Buches von Stephen King. Insbesondere King-Fans waren unzufrieden mit dem Film, obgleich Kubrick buchstäblich Fluten von Blut entfesselte, da er sich die Handlung des Buches betreffend große Freiheiten herausnahm. Im Zentrum des Films steht der Entwurf eines luxuriösen Raumes der Moderne. In dem Film wird Geschichte zur ewigen Wiederkehr des Gleichen: der Gewalt, der keine Ordnung widerstehen kann. King selbst bezeichnete Kubricks "Shining" als schlechteste Verfilmung eines seiner Bücher. Obwohl nicht so enthusiastisch von der zeitgenössischen Kritik rezipiert wie frühere Werke, gilt "Shining" mittlerweile als Klassiker des Mystery-Thrillers.

Der im Vietnamkrieg spielende Film "Full Metal Jacket" (1987) war Kubricks einziger Film, der aus seiner Sicht zu spät kam. Trotz strengster Geheimhaltung wurde kurz vor Fertigstellung des Films das Thema in der Öffentlichkeit bekannt. Daraufhin stellte Oliver Stone seinen Film "Platoon" schneller als geplant fertig und brachte ihn wenige Wochen vor "Full Metal Jacket" in die Kinos. In Deutschland war die Kinopremiere von "Full Metal Jacket" ein halbes Jahr nach der von "Platoon".

Nachdem Kubrick "Full Metal Jacket" fertiggestellt hatte, arbeitete er unter dem Arbeitstitel "Aryan Papers" an einer Verfilmung des Romans "Lügen in Zeiten des Krieges" von Louis Begley und der Science-Fiction-Geschichte "A.I." Als Steven Spielberg 1993 "Schindlers Liste" veröffentlichte, verwarf Kubrick sein Projekt "Aryan Papers," um nicht in eine ähnliche Situation zu kommen, wie sie sich bei "Full Metal Jacket" ergeben hatte. Dabei war das Projekt schon weit gediehen, man stand kurz vor Drehbeginn. Er ging davon aus, dass das Publikum auf absehbare Zeit vermutlich keinen weiteren Film zum Thema Holocaust würde sehen wollen. Er arbeitete zunächst weiter an "A.I." und begann parallel dazu mit den Arbeiten für eine Verfilmung der "Traumnovelle" von Arthur Schnitzler, die er schon seit Ende der 1960er Jahre geplant hatte. Da er schließlich befürchtete, dass die Geschichte eines Roboters, der ein echter Mensch werden möchte, in seinen Händen zu philosophisch werden könnte, übertrug er das Projekt Steven Spielberg und widmete von da an seine volle Aufmerksamkeit der Bearbeitung der "Traumnovelle". Nach zwei Jahren Drehzeit legte Kubrick am 5. März 1999 die fertig geschnittene Fassung der Verfilmung unter dem Titel "Eyes Wide Shut" (1999) vor. In dieser Zeit gab sich ein Hochstapler namens Alan Conway als Kubrick aus, während der echte Kubrick mit den Dreharbeiten beschäftigt war. Diese Geschichte wurde 2006 unter dem Titel "Colour Me Kubrick" mit John Malkovich verfilmt.

Am 7. März 1999 starb Stanley Kubrick in seinem Haus an den Folgen eines Herzinfarkts.

Kubrick war dafür berühmt und berüchtigt, jede Szene so oft wiederholen zu lassen, bis sie in seinen Augen perfekt war. Als berühmtes Beispiel gilt eine Szene aus seinem Film "Shining," in der Shelley Duvall einen Stapel von über dreihundert Blatt Papier findet, auf denen immer wieder derselbe Satz steht: "All work and no play makes Jack a dull boy". Kubrick weigerte sich, für die einzelnen Seiten Kopien zu verwenden, selbst bei Seiten, die man unmöglich genau sehen konnte. Mehrere Schreiber waren damit beschäftigt, jede Seite im Original zu tippen. Im Making-of zum Film "Shining" wird die Härte gegenüber der jungen Shelley Duvall sichtbar, die Kubrick gezielt einsetzt, damit sie sich besser in ihre Rolle hineinversetzen kann.

Sein Drang zum Perfektionismus wird Kubrick nicht nur als Stärke, sondern teilweise auch als Schwäche zugeschrieben. So sagte seine Frau über ihn, dass er zwar hervorragende Arbeit ablieferte, jedoch oft sehr langsam arbeitete. Neben einigen nicht realisierten Projekten kam Kubrick dadurch wirtschaftlich mit "Full Metal Jacket" in Bedrängnis; der Film konnte erst nach "Platoon" veröffentlicht werden.













</doc>
<doc id="4436" url="https://de.wikipedia.org/wiki?curid=4436" title="Soziologie">
Soziologie

Soziologie ( ‚Gefährte‘ und -logie) ist eine Wissenschaft, die sich mit der empirischen und theoretischen Erforschung des sozialen Verhaltens befasst, also die Voraussetzungen, Abläufe und Folgen des Zusammenlebens von Menschen untersucht. Als systematisch-kritische Wissenschaft des Sozialen ging die Soziologie aus dem Zeitalter der Aufklärung hervor und nimmt als Sozialwissenschaft eine Mittelstellung zwischen Natur- und Geisteswissenschaften ein. Ihren Namen erhielt sie von Auguste Comte, bevor sie sich in der zweiten Hälfte des 19. Jahrhunderts als eigenständige universitäre Disziplin durchsetzte. Ferdinand Tönnies, Georg Simmel und Max Weber gelten als Begründer der deutschsprachigen Soziologie.

Die Soziologie bildet den aus den Geisteswissenschaften entstandenen Kern der Sozialwissenschaften. Während andere sozialwissenschaftliche Disziplinen wie die Politikwissenschaft oder die Wirtschaftswissenschaften bestimmte Bereiche des Sozialen unter spezifischen Aspekten (Politik: legitime Machtausübung; Wirtschaft: Knappheit) untersuchen, erforscht die Soziologie alle Aspekte des sozialen Zusammenlebens der Menschen in Gemeinschaften und Gesellschaften. Sie fragt nach Sinn und Strukturen des sozialen Handelns (Handlungstheorie) sowie nach den die Handlungen regulierenden Werten und Normen. Ihre Untersuchungsobjekte sind die Gesellschaft als Ganzes ebenso wie ihre Teilbereiche: soziale Systeme, Institutionen, Organisationen und Gruppen. Überdies befasst sich die Soziologie mit der gesellschaftlichen Integration und Desintegration, mit sozialer Ungleichheit, sozialen Konflikten und sozialem Wandel.

Weitere Themen, mit denen sich die Soziologie beschäftigt, sind Sozialstrukturen, Arbeit, Geschlechter, soziale Netzwerke, Gruppen, Kommunikationsmittel (Massenmedien), Migration, Alltag, Technik und Lebenswelt. Für viele dieser Themen haben sich spezielle Soziologien etabliert (siehe unten), andere – wie etwa die allgemeine Frage nach den Wechselwirkungen von Handeln und Struktur – sind Thema der allgemeinen Soziologie. Fragestellungen der Soziologie überschneiden sich häufig mit solchen der Sozialpsychologie und anderer Sozial- und Geisteswissenschaften, teilweise auch mit denen von Naturwissenschaften wie zum Beispiel der Neurobiologie.

Eine facheinheitliche Definition von "Soziologie" existiert nicht. Eine verbreitete Definition stammt von Max Weber, fokussiert auf das „soziale Handeln“.

Als eigenständige Wissenschaft wurde die Soziologie erst seit Ende des 19. Jahrhunderts anerkannt. Sie löste sich in dieser Zeit als Einzelwissenschaft von der Philosophie, Wirtschaftswissenschaft, Staatslehre und Völkerkunde. Ihre Entstehungsgeschichte ist eng mit der Entwicklung der Bürgerlichen Gesellschaft im Europa des 19. Jahrhunderts sowie mit der fortschreitenden Industrialisierung verbunden.

Vorläufer der Soziologie sind in der Geschichtswissenschaft, der Nationalökonomie, aber auch im Journalismus und in den Policeywissenschaften zu sehen. Denker am Anfang und in der Mitte des 19. Jahrhunderts wie Henri de Saint-Simon, Karl Marx und Herbert Spencer werden heute auch als soziologische Klassiker betrachtet.

Der Namensgeber der Soziologie war Auguste Comte mit seinem 1851–1854 erschienen vierbändigen Werk "Système de politique positive, ou Traité de sociologie, instituant la religion de l’humanité". Seitdem versucht sie, teils in Fortentwicklung, teils im Gegensatz zu älteren Autoren, die sich ebenfalls mit den sozialen Wechselwirkungen beschäftigten – wie etwa schon in der Antike Xenophon im 4. Jahrhundert v. Chr., Polybios zwei Jahrhunderte später, Ibn Chaldun im 14. Jahrhundert, Giambattista Vico am Anfang und Adolph Freiherr Knigge am Ende des 18. Jahrhunderts – ihren Anspruch nach einem „ihr eigenen Erkenntnisgegenstand“ zu formulieren.

Für Comte ist dieser Gegenstand die „soziale Physik“ ("physique sociale"), die er nach Gesetzen der sozialen Statik und sozialen Dynamik unterscheidet. Für Émile Durkheim ist es der „Soziale Tatbestand“ ("fait social") bzw. – in der Übersetzung René Königs – „soziologische Tatbestand“, der außerhalb des individuellen Bewusstseins existiert und von zwingendem Charakter ist. Für Ferdinand Tönnies bilden die „sozialen Wesenheiten“, das heißt die auf dem „Willen zur sozialen Bejahung“ beruhenden sozialen Verbindungen, den spezifischen soziologischen Gegenstand. Für Max Weber ist es das „soziale Handeln“ (siehe oben).

In der Soziologie als Wissenschaft des Sozialen sind Theorie und Erfahrung aufeinander bezogen. Empirisch gehaltvoll sowie den Regeln der Logik folgend, zielt sie darauf, das Beobachtete zu verstehen und dafür Erklärungen mit Hilfe allgemeiner Sätze (Axiome) zu entwickeln. Dem entspricht die Dualität der Untersuchungsansätze: hermeneutisch interpretierende einerseits und kausalanalytische Verfahren andererseits, wobei erstere die Teilnehmerperspektive, letztere die Beobachterperspektive einnehmen.

Soziologische Theorien folgten dabei nie „demselben“ Paradigma, d. h., sie bezogen sich in ihrem wissenschaftlichen Ansatz nicht auf nur eine bestimmte Denkweise. Dies liegt an ihrem theoretischen Schwierigkeitsgrad – ihr Gegenstand ist hochkomplex.

Hinzu kommt: Bereits methodologisch, aber auch häufig aus moralischen Gründen verbietet sich meist das – oft klärende – Experiment; die stattdessen mögliche Befragung impliziert konzeptionelle und Interpretations­probleme: Beispielsweise bringen Interviewer subjektive Aspekte ein, werden angeschwindelt, in Einzelfällen fälschen sie sogar die Aussagen. Die Soziologie bleibt also immer auch auf Beobachtungen angewiesen. Auch erscheinen je nach den konkreten Fragen die Paradigmata unterschiedlich erfolgversprechend, wenn die Ergebnisse darstellungslogisch ‚einfach‘ und sachlich, finanzierungsbedingt schnell oder kostensparend sein sollen.

Zwei erkenntnistheoretische Hauptansätze sind zu unterscheiden, wobei völlig wertungsfreie von weltanschaulichen Motiven unabhängige Forschungsergebnisse nicht erreicht, aber angestrebt werden können:


Diese beiden Hauptkonzepte und ihre Überschneidungen sind die Grundlagen für die große Anzahl unterschiedlicher soziologischer Theorien ("siehe unten" die Beispiele unter "Makrosoziologie" und "Mikrosoziologie"). Hinzu kommt, dass „bei eingeschränkten Fragestellungen“ im soziologischen Alltag Forscher verschiedener wissenschaftstheoretischer Ausrichtung – dank eines in der Soziologie entwickelten umfangreichen mathematischen bis sozialhistorischen Methodenbaukastens – ähnliche bis gleiche, sowohl verlässliche, als auch gültige Befunde erheben.

In der Praxis verzichten viele Soziologen häufig darauf, einen einzigen epistemologischen Standpunkt einzunehmen und arbeiten je nach Fragestellung und Ressourcen mit verschiedenen Theorien und Methoden.

Der Begriff "Gesellschaft" bezieht sich auf eine Summe von Beziehungen und Verhältnissen zwischen den einzelnen Menschen. Nicht gemeint ist die bloße räumliche und mengenmäßige Anzahl von Individuen, sondern deren Sozialität. Damit sind Strukturen aus relativ stabilen Verhaltensmustern bezeichnet, die ihren Ursprung im interaktiven menschlichen Handeln haben und in diesem Bereich ihre Wirkung erzielen. Als allgemeinster Begriff von Gesellschaft wird „das jeweilig umfassendste System des menschlichen Zusammenlebens“ bezeichnet. Über spezifischere Merkmale für eine Gesellschaft besteht in der Soziologie keine Einigung.

Der Prozess, der aus Individuen Gesellschaftsmitglieder macht, wird „Vergesellschaftung“ genannt.

Institutionen wie der Staat, die Familie, das Recht oder die Erziehung werden heute als Unterkategorien (auch: Subsysteme) der Gesellschaft begriffen. Die Unterscheidung zwischen Staat und Gesellschaft begründete den Beginn der Soziologie.

Die Begriffe „das Soziale“ bzw. „Sozialität“ meinen den Forschungsgegenstand der Soziologie und entsprechen in ihrer Bedeutung dem Begriff der „Gesellschaft“.

Der Begriff Handeln bedeutet in der Soziologie nach Max Weber ein „Handeln“, das für den Handelnden mit „Sinn“ verbunden ist. Laut Max Weber definiert sich „soziales Handeln“ dadurch, dass es auf Andere bezogen, sinnhaft am Verhalten Anderer orientiert ist.

Ein „sozialer Tatbestand“ ("fait social") ist nach Émile Durkheim „jede mehr oder minder festgelegte Art des Handelns, die die Fähigkeit besitzt, auf den Einzelnen einen äußeren Zwang auszuüben; oder auch, die im Bereiche einer gegebenen Gesellschaft allgemein auftritt, wobei sie ein von ihren individuellen Äußerungen unabhängiges Eigenleben besitzt.“

Seit Auguste Comte wird in der Soziologie gefragt: Was trennt, was verbindet die Menschen, was sorgt für Fortschritt und zugleich Ordnung? Dieses Thema wurde vor allem im Strukturfunktionalismus – so von Talcott Parsons – behandelt. Gegenwärtig [2008] wird unter anderem die Desintegrationstheorie von Wilhelm Heitmeyer stark rezipiert.

Mit dem sozialen Wandel als der umfassenden Veränderung von relativ stabilen Sozialstrukturen befasst sich die Soziologie seit ihrer Entstehungszeit; er spielt bereits im Denken Henri de Saint-Simons und Marx’ eine bedeutsame Rolle. Seine konzeptionelle Fassung erhielt er durch Ogburns Schrift "Social Change" (1922). In neuerer Zeit steht der soziale Wandel im Fokus von Modernisierungstheorien.

Soziale Normen sind Verhaltenserwartungen an Individuen und Gruppen in spezifischen sozialen Situationen mit unterschiedlich starken Verbindlichkeiten, die durch positive und negative Sanktionen durchgesetzt werden (siehe auch Soziale Erwünschtheit).
Die Normgebundenheit sozialen Verhaltens ist ein frühes Thema der Soziologie. Mit ihr haben sich insbesondere Émile Durkheim und Talcott Parsons, in der deutschen Nachkriegssoziologie Ralf Dahrendorf und Heinrich Popitz beschäftigt.

Eine häufig vorzufindende Unterteilung der Soziologie unterscheidet zwischen

Unzufrieden mit dieser wissenschaftstheoretisch strengen Alternative sind Vertreter eines als „Mesosoziologie“ bezeichneten Blicks auf intermediäre Ebenen (Betonung des „Hin und Her“) und eines neuerdings als „Makro-Mikro-Soziologie“ bezeichneten Ansatzes, der prozessanalytisch Einseitigkeiten ausschließlicher Makro- und Mikro-Betrachtung zu überwinden beansprucht (Betonung des „Weder-noch“).


Diese Theorie mittlerer Reichweite (vgl. Robert K. Merton) umschreibt z. B. die Soziologie der Institutionen, Rituale und Organisationen, Soziale Gruppen bzw. die Verbindung zwischen Mikro- und Makrosoziologie.


Hier wird für den Ansatz von Norbert Elias, die Figurationssoziologie (auch Prozesssoziologie), eine über die Akteuranalyse hinausgehende strömungsstrukturelle (figurative) Grundlegung beansprucht, die jedoch makrosoziologische Reifizierungen der Gesamtgesellschaft ablehnt. Ein zweiter Ansatz ist die Sozialisationstheorie von Klaus Hurrelmann, die Persönlichkeitsentwicklung als einen permanenten produktiven Prozess der Verarbeitung von innerer Realität (Körper, Psyche) und äußerer Realität (soziale und physische Umwelt) konzipiert.

Ferner lassen sich Themenbereiche der Soziologie auch danach unterscheiden, ob sie der „allgemeinen“ Soziologie zuzurechnen sind, also generelle Gültigkeit beanspruchen, oder ob es sich dabei um Themen einer „speziellen“ Soziologie handelt. Theoretisch gehören die soziologischen „Methoden“ zur allgemeinen Theorie, in der Hochschulpraxis werden sie aber oft gesondert betrieben.

Zur „Allgemeinen Soziologie“ zählen die Kategorien und Hypothesen, mit denen soziales Verhalten in den verschiedenen Lebensbereichen erklärt wird. Dazu gehören Sachgebiete wie das Verhältnis von Akteur und Gesellschaft oder Person und sozialem System, sowie die Struktur und der Wandel von Gesellschaften bzw. sozialen Systemen. Auch die Methoden der empirischen Forschung lassen sich hier einordnen.

Hauptthemen der Allgemeinen Soziologie sind beispielsweise: Devianz, Eliten, Funktionale Differenzierung, Gruppen, Herrschaft, Kommunikation, Macht, Sozialisation, Soziales Handeln, soziale Interaktion, Klassen, soziale Mobilität, soziale Rollen, sozialer Tausch, soziale Ungleichheit, sozialer Wandel, Sozialstruktur, Technik.

„Spezielle Soziologien“ – informell auch „Bindestrichsoziologien“ genannt – befassen sich mit den Strukturen und Prozessen gesellschaftlicher Teilsysteme oder institutioneller Bereiche der Gesellschaft.

Zu den wichtigsten speziellen Soziologien gehören Arbeitssoziologie, Wirtschaftssoziologie, Familiensoziologie und Politiksoziologie. Durch die zunehmende Differenzierung auch der Soziologie selbst bilden sich laufend weitere spezielle Soziologien.

Um eine der Soziologie angemessene Methodik der empirischen Erforschung sozialer Tatbestände wurde seit den Anfängen der Disziplin im sogenannten Methodenstreit gerungen.

Das umfangreiche methodische Instrumentarium der empirischen Soziologie lässt sich wie folgt untergliedern:

Weiterhin existieren Kombinationen der verschiedenen Ansätze, die "mixed methods" genannt werden. Die sogenannte Objektive Hermeneutik beansprucht dagegen, eine umfassende Forschungsmethodologie der Sozialwissenschaften zu formulieren, die gleichermaßen für quantifizierende Daten wie für natürlich protokollierte Ausdrucksgestalten der konkreten Lebenspraxis (wobei Protokolle per se schon „historisch“ sind) Anwendung findet. Die oben genannte Methodenunterscheidung wird von dieser Methodologie kritisiert und abgelehnt.

Obwohl der Unterschied zwischen einer reinen Theorie und ihrer Anwendung in vielen Wissenschaften gemacht wird und in den Bereich alltäglicher Vorverständnisse auch der Soziologie gehört, gibt es hier einen strengen und einen weniger festgelegten Gebrauch.

Im strengen Sinne hat Ferdinand Tönnies zwischen einer axiomatisch abgestützten und begrifflich entfalteten „Reinen Soziologie“ und einer von dorther ausgehenden „Angewandten Soziologie“ unterschieden, bei der diese Begriffe deduktiv an historische soziale Prozesse angelegt werden. Im ersten Fall bewegt man sich demnach im „Reich der Ideen“, im zweiten im „Reich der Wirklichkeit“.

Im weniger strengen Sinne versteht man unter angewandter Soziologie die Handhabung theoretischer Grundlagen zur Bearbeitung von Forschungsaufträgen. Der Erfolg einer soziologischen Theorierichtung ist dabei nicht nur von der intellektuellen Tüchtigkeit und wissenschaftlichen Bedeutung ihrer Begründer abhängig, sondern – wissenschaftssoziologisch gesehen – durchaus auch von der Nachfrage nach soziologischer Beratung durch den Markt beziehungsweise durch soziale Verbände oder die Politik, selten aber nachhaltiger auch durch soziale Bewegungen.

Markt- und Wahlforschung bieten die lukrativsten Aufträge für Soziologen, was die Entwicklung der quantitativen Methoden (Statistik) und der an die Naturwissenschaften angelehnten Theorieansätze relativ begünstigt. Denn die Fragen sind meist eingeschränkt und auf die allernächste Zukunft bezogen. Viele "ceteris paribus"-Bedingungen können also vorausgesetzt werden, ohne die Ergebnisse stark zu beeinträchtigen. Hier kam es, zuerst in den USA (seit den späten 1940er Jahren auch in Deutschland) zur Gründung von Umfragefirmen und Meinungsforschungsinstituten.

Einige spezielle Teilgebiete (Militär-, Medizin-, Sport- und Katastrophensoziologie) fragen soziologische Beratung nach, nicht aber die Industriesoziologie, seit das Fach in Deutschland in den 1970er Jahren aus den wirtschafts- und sozialwissenschaftlichen Fakultäten (Fachbereichen) in die philosophischen umgezogen ist; die Organisationssoziologie wird nun vor allem in den USA fortgeführt. Eine beratende Funktion hat oftmals auch die Rechtssoziologie, die u. a. im Vorfeld geplanter Gesetze Wirkungs- und Evaluationsforschung betreibt; sie kann auch in Bereichen mit „weichen“ Rechtsverhältnissen (Arbitragen, Treu und Glauben, „nach billigem Ermessen“) für eine Strukturierung sorgen. Sozialräumliche Strukturen werden zu Planungszwecken von der Gemeinde- bzw. Stadtsoziologie untersucht.

Brotlose Künste sind hingegen zahlreiche spezielle Soziologien, die sich schlecht vermarkten lassen und quantitativen Methoden wenig zugänglich sind, etwa die Kunst-, Literatur- oder Religionssoziologie. Also ist deren Forschungsfortschritt stark von der Forschungsfreiheit der Universitätssoziologie, von den Motiven der Wissenschaftler selbst und von den relativ geringen Drittmittelzuschüssen gemeinnützig denkender Förderer (Mäzene) abhängig.

Diktaturen lehnen eine – vor allem die Mentalität der Bevölkerung berücksichtigende und darüber Auskunft gebende – Soziologie ab; bei besonderem (dann oft geheimem) Beratungsbedarf erlauben auch sie vorübergehend soziologische Fragestellungen (beispielsweise in der DDR der 1980er Jahre im Bereich der angewandten Stadt- und Jugendsoziologie).

Einige besonders bedeutsame soziologische Denker seit ihrem Begründer Auguste Comte seien hier aufgeführt. Eine solche Liste ist selbstverständlich anfechtbar.

Hier kann nur eine Auswahl angesprochen werden.


Ferner gibt es:







Institutionen

Studentische Diskurse


</doc>
<doc id="4438" url="https://de.wikipedia.org/wiki?curid=4438" title="Sanktion">
Sanktion

Eine Sanktion (; aus neulateinisch ‚Heilung, Anerkennung, Bestätigung, Billigung, Strafandrohung‘ zu ‚heiligen, durch Weihe unverbrüchlich festsetzen, gesetzlich bekräftigen, bei Strafe verbieten‘) dient dazu, Verbindlichkeit herzustellen. Der Begriff hat in verschiedenen Wissenschaften unterschiedliche Bedeutung.

Im Rechtssystem der Monarchie war die Sanktion vor allem die Genehmigung eines Gesetzesbeschlusses des Parlaments durch den Monarchen (Erteilung der Gesetzeskraft). Der Monarch hatte das Recht, die Sanktion zu verweigern; ohne sie konnte der Parlamentsbeschluss amtlich nicht publiziert werden und nicht in Kraft treten.

Zum Beispiel wurde im altösterreichischen Reichsgesetzblatt die erteilte kaiserliche Sanktion mit folgenden Worten beurkundet:
(De facto unterschrieb der Monarch als letzter.) 

Ansonsten sind mit Sanktionen in der Regel durch Gesetze angedrohte Strafmaßnahmen gemeint, die darauf ausgerichtet sind, konkretes Fehlverhalten zu unterbinden und damit Rechtsnormen durchzusetzen. Sanktionen gibt es sowohl im weltlichen als auch im kirchlichen Recht (Kirchenstrafen).

Im Strafrecht dienen Sanktionen gemäß den Strafzwecktheorien dazu, den durch das missbilligte Verhalten gestörten Rechtsfrieden wiederherzustellen. Zusätzlich sollen potentielle Straftäter hierdurch mittels Abschreckung von eigener Delinquenz abgehalten werden. Sanktionen dienen hier also auch der Kriminalprävention.

Im Privatrecht dienen beispielsweise Vertragsstrafen diesem Zweck.

Im Sozialrecht existieren Sanktionen in Form von Leistungskürzungen (z. B. Sperrzeit im Arbeitslosengeld, Sanktionen im Arbeitslosengeld II). 

Im Völkerrecht bedient sich der UN-Sichheitsrat z. B. Wirtschaftssanktionen, um andere Staaten zur Einhaltung seiner Beschlüsse zu bewegen.

Der Wortbedeutung nach, wie auch im soziologischen Verständnis, können Sanktionen grundsätzlich positiver oder negativer Art sein: Eine positive Sanktion ist eine – nicht zwangsläufig materielle – „Belohnung“; eine negative Sanktion eine „Bestrafung“.
In der Soziologie werden Formen der Organisation von sozialen Prozessen damit bezeichnet, siehe Soziale Sanktion.

Hierbei unterteilt man die Sanktionen beispielsweise in sechs Schweregrade:

Durch die Sanktionierung werden wissenschaftliche Namen von Pilzen gegenüber älteren, gleichlautenden Homonymen und konkurrierenden (anderslautenden) Synonymen geschützt. Dazu muss der Name in einem der drei im Internationalen Code der botanischen Nomenklatur genannten Werken vom jeweiligen Autor akzeptiert worden sein. Wurde der Name eines Rost- (Uredinales), Brand- (Ustilaginales) oder Bauchpilzes (Gasteromycetes) in C.H. Persoons akzeptiert, so gilt dieser Name als sanktioniert. Für alle anderen Pilze sind die beiden Werke und von E.M. Fries maßgeblich.




</doc>
<doc id="4439" url="https://de.wikipedia.org/wiki?curid=4439" title="Scanner (Datenerfassung)">
Scanner (Datenerfassung)

Ein Scanner (engl. "to scan" ‚abtasten‘) oder Abtaster ist ein Datenerfassungsgerät, das ein Objekt auf eine systematische, regelmäßige Weise abtastet oder vermisst. Das Scannen ist ein optomechanischer Vorgang. 

Die Hauptidee ist, mit relativ begrenzten Messinstrumenten durch eine Vielzahl von Einzelmessungen ein Gesamtbild des Objekts zu erzeugen. 

Der Scanner nimmt die analogen Daten der physikalischen Vorlage mit Hilfe von Sensoren auf und übersetzt diese anschließend mit A/D-Wandlern in digitale Form. So können sie z. B. mit Computern verarbeitet, analysiert oder visualisiert werden. 

Russell Kirsch von NBS hatte schon 1957 den Digital-Scanner entwickelt. Das allererste derart gescannte Bild war ein Babyfoto seines neugeborenen Sohns Walden, 176 × 176 Pixel.

Dreidimensionale Vorlagen lassen sich nur mit einem 3D-Scanner einlesen. Man verwendet solche Geräte meistens zum Katalogisieren oder Archivieren von Objekten. Der Nachteil ist, dass die Abtasteinrichtung oft fest montiert sein muss bzw. bei Handscannern Referenzpunkte auf dem Objekt aufgeklebt werden müssen.

Ein Buchscanner wird primär zum Einlesen gebundener Schriftdokumente benutzt. Spezielle Ausführungen erlauben auch das Scannen von losen Dokumenten, Urkunden und Landkarten.

Der Scannertyp wird im professionellen und semiprofessionellen Bereich verwendet und wird in zwei Ausführungen angeboten: zum einen als reiner Filmscanner, bei dem mittels spezieller Vorrichtungen die Diapositive und Negative in den Scanner geführt werden, zum anderen als Hybridgerät, bei dem ein Flachbettscanner einen besonderen Durchlichtaufsatz erhält. Für beide Ausführungen gibt es sowohl einfache als auch hochwertige Geräte, die sich neben der Pixeldichte auch im Dichteumfang stark unterscheiden. Die optische Auflösung hochwertiger Geräte beträgt ca. 3000 ppi bis 4000 ppi. Außerdem arbeiten diese auch mit einem speziellen Ausleuchtungsverfahren, um die sonst üblichen Streu- und Nebeneffekte beim Einscannen der stark reflektierenden Vorlagen zu eliminieren. Siehe auch bei Dia-Scan.

Für die Erfassung größerer Mengen von Schriftgut werden Flachbettscanner mit ADF (Automatic Document Feeder), Einzugsscanner oder spezielle Hochgeschwindigkeitsscanstraßen als Dokumentenscanner eingesetzt.

Durchlichtscanner werden für transparente Vorlagen wie Filme, Dias, Röntgenbilder verwendet. Es gibt Geräte mit im Deckel integrierter oder auch externer Lichtquelle.

Jedes Faxgerät besitzt für seine Senderichtung einen Einzugsscanner. Dabei ist eine Zeile aus lichtempfindlichen CCD-Sensoren (oder Sensoren anderer Technologie) fest im Gerät eingebaut. Die Vorlage wird daran entlanggeführt. Beim Fax wird reiner Schwarzweißbetrieb verwendet, also weder Farbe noch Graustufen erkannt.

Der Einzugsscanner ist genau so aufgebaut wie ein Faxgerät (siehe oben), allerdings heutzutage zusätzlich mit Graustufen und Farberkennung. Der offensichtliche Nachteil der Einzugsscanner ist die ausschließliche Verarbeitung von Einzeldokumenten bzw. Stapeln davon. Bücher lassen sich nicht einscannen. Außerdem kann es beim Einzug glatter Vorlagen, wie z. B. Fotos, zu unangenehmen Randverzerrungen kommen. Sie kommen hauptsächlich im Enterprise-Bereich als Dokumentenscanner zum Einsatz. 

Zum Lesen meist kleinerer Dokumente (Beispiel: von Hand durch Ankreuzen ausgefüllte Formulare), sonst in der Technik wie Dokumentenscanner oder Einzugsscanner.

Im Gegensatz zu Durchlicht-Flachbettscannern kommt ein Filmscanner bei der Filmabtastung von photographischem Material wie Film-Negativen, Dias sowie Kinofilmen für Fernseh- und Kinozwecke zur Anwendung. Siehe hierzu auch Filmabtaster.

Der Flachbettscanner, das heute gebräuchlichste Bilderfassungsgerät, arbeitet nach dem gleichen Prinzip wie ein Kopiergerät. Die Vorlage wird auf eine Glasscheibe gelegt, sie bleibt immer am gleichen Platz, die lichtempfindlichen Sensoren werden während des Abtastens unter der Glasscheibe entlanggeführt. Diese Methode erlaubt es, neben Fotos und Bildern auch sperrige Vorlagen wie Bücher abzutasten. Um ein scharfes Bild zu erreichen, muss die Vorlage ganz flach auf der Glasplatte aufliegen. Das bereitet aber bei manchen Vorlagen Probleme. Kostengünstige Flachbettscanner können Vorlagen bis zu DIN A4 abtasten.

Bei Vorlagengrößen von mehr als A2 spricht man von Großformatscannern, die als Durchzug-, Flachbett- oder Trommelscanner angeboten werden. Bei Durchzugscannern gibt es zwei konkurrierende Systeme, CCD und CIS. CCD arbeitet mit mehreren kleinen Kamerasensoren (daher der Name). Vergleichbar mit Panoramabildern wird das Bild der Kameras zu einem Gesamtbild verrechnet. Das von der Vorlage reflektierte Licht wird dabei über Spiegel und Linsen auf dem Sensor gebündelt. CIS (Contact Image Sensor) arbeitet mit Sensorstreifen, auf die das von der Vorlage reflektierte Licht direkt auftrifft. Da in der CIS-Technik mehrere Sensorstreifen die gesamte Scanbreite abdecken, ist eine Bündelung des Lichts durch Linsen nicht nötig und es treten weniger Fehler auf (kein Versatz zwischen den Kameras, geringe Verzerrungen und keine Farbsäume). Dafür ist die CIS-Technik bei Unebenheiten der Scanvorlage anfällig für Unschärfen.

Wie es der Name sagt, muss man den Handscanner von Hand über die Vorlage ziehen. Man darf den Scanner nicht zu schnell über die Vorlage ziehen (weil ein bestimmter Grenzwert für die übertragene Datenmenge nicht überschritten werden kann) und sollte dabei auch keine seitlichen Abweichungen von der Geraden ausführen, was durch parallel zur (eindimensionalen bzw. linearen) Abtastzeile gelagerte Walzen unterstützt wird.

Geräte der ersten Generation waren günstige Alternativen zu herkömmlichen Scannern. Um eine A4-Seite einzuscannen, muss man mehrmals scannen und per Software zusammensetzen, da die Geräte zu schmal sind. Die Rolle erfasste in Zusammenhang mit einem Impulsgeber auch den zurückgelegten Weg über der Vorlage und damit die zweite Dimension. Handscanner waren Anfang bis Mitte der 1990er Jahre populär, sind aber wegen ihrer Nachteile und der stark gefallenen Preise für Flachbettscanner längst vom Markt verschwunden.

Heutige Geräte erlauben das Erfassen von ganzen DIN A4 Seiten mit einer Scanbewegung. Die mögliche Geschwindigkeit hat sich wesentlich gesteigert auf je nach Farbeinstellung bis zu 2 bis 4 Sekunden pro Seite. Sie sind batteriebetrieben und speichern auf microSD oder schicken die Daten gleich über Bluetooth oder WLAN an das gewünschte Gerät. Man spricht auch von "mobilen (Dokumenten-)Scannern", worunter aber auch kleine, mobile Einzugsscanner zu verstehen sind; oder gegenüber diesen als Unterscheidungsmerkmal von "Buchscannern", da man nicht nur einzelne Blätter bearbeiten kann. Sie sind heute meist Zusatzgeräte um unterwegs damit zu arbeiten.

Zwischendurch wurden in der Hand zu haltende Scanner entwickelt, die einzelne Zeilen einscannen konnten und eine OCR-Software integriert hatten. Sie werden auch "digitale Textmarker" genannt und sind noch erhältlich. Es gibt ähnliche Geräte mit eingebauter Übersetzungs-Software.

Auch die rotierende, horizontal stark bündelnde Antenne eines Rundsichtradars wird gelegentlich als Scanner bezeichnet. Zusammen mit der Darstellung auf vektororientierten Bildschirmen gehört Radar ebenfalls zu den bildgebenden Verfahren.

Scanner für Anwendungen in der Photogrammetrie wie Réseauscanner

In der Medizin gibt es verschiedene Scanner, wie z. B. 

Dies ist einer der ältesten Scannertypen, der aber auch heute noch die exaktesten Ergebnisse liefert. Auflösung (ca. 12.000 ppi), Tempo und Qualität bleiben von anderen Gerätearten unerreicht. Die Trommelscanner des früheren Weltmarktführers Heidelberger Druckmaschinen sind mit der Spezial-Software SilverFast weiterhin an modernen Computer-Systemen einsetzbar. Beim Trommelscanner wird die Vorlage auf einer rotierenden Trommel befestigt, an der sich das Beleuchtungs- und Abtastungssystem linear vorbeibewegt, so dass die Vorlage schraubenförmig abgetastet wird. Da die Lichtquelle und das Abtastungssystem immer in der gleichen Lage zum Papier sind, kann mit einfachen Mitteln eine hervorragende Qualität erreicht werden. Zusätzlich haben Trommelscanner anstelle der normalen CCD-Sensoren hochempfindliche Photomultiplier zum Einlesen der Daten. Nachteilig ist, dass sie viel kosten und sehr groß sind. Eine frühe Anwendung von Trommelscannern war die Bildtelegrafie.

Scanner arbeiten in der Regel nach folgendem Prinzip: Die Bildvorlage wird beleuchtet, und das reflektierte Licht wird über eine Stablinse, welche das reflektierte Licht bündeln und das Streulicht eliminieren soll, an einen optoelektronischen Zeilensensor geleitet (schneller Scan, englisch: "fast scan"). Die analogen Lichtsignale werden pixelweise durch Analog-Digital-Wandlung in Digitalsignale umgewandelt, während gleichzeitig entweder die Vorlage oder die Sensoroptik schrittweise senkrecht zur Sensorausdehnung bewegt wird (langsamer Scan, englisch: "slow scan").

Bei der Abtastung mit einem Flächensensor kann die gesamte Vorlage oder flächenhafte Teile der Vorlage gleichzeitig gescannt werden.

Durch erneuten Scanvorgang nach Verschiebung der Sensoren im Subpixelbereich kann die Bildauflösung und unter Umständen auch die fotografische Auflösung erhöht werden.

Bestimmte Farbwerte werden durch getrenntes Abtasten der Grundfarben (meist Rot, Grün und Blau) mittels Vorschalten von Farbfiltern und gegebenenfalls durch softwaremäßige, additive Farbmischung ermittelt. Dieses Filterverfahren benötigt für jede Primärfarbe einen Scandurchlauf, wenn alle Sensorelemente für den Scan eingesetzt werden. Alternativ werden auch Bayer-Sensoren oder andere Farbsensoren eingesetzt, bei denen alle Sensorelemente mit jeweils einem festen Farbfilter in einer bestimmten Farbreihenfolge versehen werden. Dadurch kann der Scan in einem Durchlauf durchgeführt werden (siehe auch CCD).

Beim Einsatz von mehreren farbigen und schaltbaren Lichtquellen wird nur ein Scandurchlauf benötigt, da die Farbtrennung durch die Lichtquellen selbst gegeben ist. Die Sensoren messen während einer Messung zum Beispiel mit der Beleuchtung durch preisgünstige Leuchtdioden nur das Licht einer bestimmten Wellenlänge (siehe auch CIS). Alternativ können auch farbige Lichtquellen mit kontinuierlichem Lichtspektrum eingesetzt werden.

Im Prismenverfahren wird die Vorlage mit weißem Licht beleuchtet. Das reflektierte Licht wird durch ein Prisma geführt, das die Farbanteile aufspaltet. Diese werden von nebeneinanderliegenden optischen Sensoren erfasst. Auch bei dieser Technik ist nur ein Scanvorgang erforderlich.

Die Qualität eines Scanners ist je nach Einsatzzweck abhängig von:

Einfache Scanner mit Einzelblatteinzug verarbeiten ca. zehn Seiten pro Minute. Hochleistungsscanner mit einer Mechanik zum Umblättern erfassen pro Minute 40 Seiten eines Buches.

Die Qualität von Scannern kann häufig mittels eines sogenannten Hohlraum-Effekts (englisch "cavity effect") abgeschätzt werden. Dabei werden Würfel aus schwarzer Pappe mit ca. zehn Zentimetern Kantenlänge und einem Loch von ca. fünf Millimetern Durchmesser auf der Lochseite gescannt. Die Lochseite kann dadurch modifiziert werden, dass sie außen aus weißer Pappe besteht. Das Loch stellt näherungsweise einen Hohlraumstrahler dar, der praktisch kein sichtbares Licht aussendet. Im Scan dürfte daher an der Stelle des Loches kein Signal vorhanden sein. 

In der Praxis treten jedoch dennoch Signale auf, die im Wesentlichen zwei Ursachen haben: 

Letzteres kommt dadurch zustande, dass Licht aus der Umgebung des Loches in den Bildwandler des Scanners gestreut wird und stellt den "Hohlraum-Effekt" dar. Das Rauschen ist im Wesentlichen ortsunabhängig und hat daher einen konstanten Pegel.

Die folgenden acht Beispielbilder illustrieren diese Effekte. Die ersten vier stellen Originalmessungen dar, wohingegen die nächsten vier Bilder mit einer Gammakorrektur versehen sind formula_1. Auf der linken Seite ist jeweils ein guter Scan und auf der rechten Seite ein schlechter Scan dargestellt. Die oberen Bilder zeigen einen gelochten Würfel vollständig aus schwarzer Pappe und die unteren einen mit einer weißen gelochten Außenfläche.

In den unteren beiden rechten Bildern sind deutliche Bildfehler zu erkennen. Im oberen rechten Bild, das mit schwarzer Pappe gescannt worden ist, ist im Loch deutlich das Bildrauschen zu erkennen. Im unteren rechten Bild ist dieses Rauschen in der Bildmitte noch erkennbar, wird aber durch Falschlicht überstrahlt, das zur Lochmitte hin schwächer wird.



</doc>
<doc id="4440" url="https://de.wikipedia.org/wiki?curid=4440" title="Selbstorganisation">
Selbstorganisation

Als Selbstorganisation wird in der Systemtheorie hauptsächlich eine Form der Systementwicklung bezeichnet, bei der die formgebenden, gestaltenden und beschränkenden Einflüsse von den Elementen des sich organisierenden Systems selbst ausgehen. In Prozessen der Selbstorganisation werden höhere strukturelle Ordnungen erreicht, ohne dass erkennbare äußere steuernde Elemente vorliegen.

Im politischen Gebrauch bezeichnet Selbstorganisation die Gestaltung der Lebensverhältnisse nach flexiblen, selbstbestimmten Vereinbarungen und ähnelt dem Autonomiebegriff.

Konkret eingesetzt wird der Begriff bei sich selbst organisierenden Karten, einer Variante der künstlichen neuronalen Netze.

Bei Selbstorganisation kann man zwischen autogener (aus eigenen Kräften heraus) und autonomer (selbstbestimmt) Selbstorganisation unterscheiden:

Autogene Selbstorganisation

Autonome Selbstorganisation

Der Begriff der Selbstorganisation wurde in den 1950er-Jahren von Wesley A. Clark und Belmont G. Farley geprägt:
In sozialen Systemen lässt sich beobachten, wie Ordnung – unabhängig von den Handlungen eines Organisators – aus dem System selbst heraus entsteht. Diese Erscheinung wird als Selbstorganisation bezeichnet. Die Selbstorganisation ist ein nicht nur in der Systemtheorie populärer Begriff. Ihm kommt sowohl in sozialen als auch in natürlichen, physikalischen, biologischen, chemischen oder ökonomischen Systemen Bedeutung zu. Auch geht das Konzept der Rätedemokratie und ihrer sozio-politischen Ansätze davon aus, dass die zur Selbstorganisation erforderlichen Handlungsspielräume gegen bestehende Formen der Fremdbestimmung erkämpft werden müssen. Diesem Ansatz zufolge können die Menschen nur dann ihr Leben selbst in die Hand nehmen, wenn sie auch die Produktionsmittel kontrollieren und nicht hierarchischen Organisationen unterworfen sind.

Die Vor- oder Urgeschichte der Selbstorganisation umfasst den Zeitraum vom griechisch-römischen Altertum bis etwa zur Mitte des zwanzigsten Jahrhunderts. Schon im alten Griechenland spekulierten Philosophen über Chaos und Turbulenz als Ursache von Ordnung. In der Philosophie des Aristoteles könnte man Selbstorganisation auch als Entelechie bezeichnen. Die platonisch orientierte Naturphilosophie Isaac Newtons (, 1687) nimmt schon im Ersten Bewegungsgesetz an, dass die Materie absolut passiv ist. Sie ist deshalb auch zu keiner Selbstbewegung und Selbstorganisation fähig. Aktive Ursachen materieller Veränderungen sind hier die immateriellen „Kräfte der Natur“. In den Naturwissenschaften des achtzehnten, neunzehnten und frühen zwanzigsten Jahrhunderts dominierten dagegen materialistisch-mechanistische Denkweisen, die sich unter anderem auch in Darwins Evolutionstheorie widerspiegeln. Die eigentliche Entstehungsgeschichte der Selbstorganisation beginnt jedoch erst in der zweiten Hälfte des 20. Jahrhunderts. Der relativ späte Zeitpunkt hat mehrere Ursachen, zunächst verhinderte das vorherrschende mechanistische Paradigma das notwendige Umdenken, außerdem wurden mit Selbstorganisation in Verbindung stehende Phänomene ignoriert. Gegenwärtig kann noch nicht von einer Theorie selbstorganisierender sozialer Systeme oder von empirisch getesteten Hypothesen gesprochen werden.

Der universellen Anwendbarkeit verdankt der Begriff der Selbstorganisation seine breite Resonanz.

Immanuel Kant führte den Begriff der Selbstorganisation in seiner "Kritik der Urteilskraft" von 1790 ein, um die belebte Sphäre zu charakterisieren: „Man sagt von der Natur und ihrem Vermögen in organisierten Produkten bei weitem zu wenig, wenn man dieses ein "Analogon der Kunst" nennt; denn da denkt man sich den Künstler (ein vernünftiges Wesen) außer ihr. Sie organisiert sich vielmehr selbst, und in jeder Species ihrer organisierten Produkte, zwar nach einerlei Exemplar im Ganzen, aber doch auch mit schicklichen Abweichungen, die die Selbsterhaltung nach den Umständen erfordert.“ Dies führte ihn zu der Erkenntnis, dass die mechanistische Physik Erklärungsgrenzen hat. Der Begründer der „dynamistischen Naturphilosophie“ und einer der Exponenten des Deutschen Idealismus Friedrich Wilhelm Joseph Schelling griff Kants Überlegungen auf und erweiterte dessen Konzept der Selbstorganisation zu einer allgemeinen, auch die anorganische Sphäre umfassenden Naturphilosophie. Dabei erkannte er, dass es nicht ausreicht, nur die Selbsterhaltung von Systemen zu thematisieren. Diese müssten vielmehr in ihrem „ersten Ursprung“ erkannt werden. Eine Theorie der ursprünglichen Selbstorganisation, die für ihn insbesondere mit dem ersten Ursprung des Lebens und mit der ursprünglichen Entstehung von Arten und Gattungen verbunden war, darf die Zirkularität von Prozessen wie bei der bloßen Selbstreproduktion nicht voraussetzen. Auch das „dynamische Gleichgewicht“ ist bloßes Produkt eines tiefergehenden Prozesses der "natura naturans". Schellings Naturphilosophie, die an die Kosmogonie von Platons "Timaios" anknüpft, ist daher im Kern eine Theorie der Emergenz. Heuser-Keßler zeigte, dass Kants Selbstorganisationsbegriff Ähnlichkeiten mit dem der "Autopoiesis" hat, während Schellings Lehre Berührungspunkte mit den physikalischen Selbstorganisationstheorien der Moderne aufweist. Zudem zeigte sie, dass Schellings Konzept der Selbstorganisation in philosophischer Hinsicht tiefer begründet ist und daher nicht nur historisch, sondern auch aktuell von systematischer Relevanz ist. Sie wurde daher von naturwissenschaftlichen Vertretern der Selbstorganisationstheorien wie z. B. Manfred Eigen, Hermann Haken oder Ilya Prigogine vielfach eingeladen, um dies zu erläutern. Auch wirkte ihre Arbeit auf die Schelling-Forschung in den USA, Kanada und Australien ein. Um ihre Thesen weiter auszubauen, erforschte sie die Mathematikgeschichte des 19. Jahrhunderts und erkannte, dass Schellings Lehre vom sich selbst organisierenden Prinzip Wirkungen auf die Entstehung der modernen Mathematik in Deutschland hatte.

Selbstorganisation ist das spontane Auftreten neuer, stabiler, effizient erscheinender Strukturen und Verhaltensweisen (Musterbildung) in offenen Systemen. Das sind Systeme, die sich fern vom thermodynamischen Gleichgewicht befinden, die also Energie, Stoffe oder Informationen mit der Außenwelt austauschen. Die Selbstorganisation ist jedoch auch bei exothermen Prozessen und Prozessen im thermischen Gleichgewicht allgegenwärtig, in der Welt der Elementarteilchen, der Physik und der Chemie, im Weltall bei der Entstehung der Sterne und Planeten, in der Evolution, der Biologie bis hin zu den anfangs genannten sozialen Systemen. Emergente Systeme entstehen von selbst aus ihren Elementen durch die Wechselwirkungen zwischen ihnen. In Physik und Chemie sind dies unmittelbar die Kräfte der Naturgesetze. Die Systeme haben zusätzlich zu ihren komplexen Strukturen auch neue Eigenschaften und Fähigkeiten, die die Elemente nicht haben. Ein selbstorganisiertes System verändert seine grundlegende Struktur abhängig von seinem Entwicklungsprozess und seiner Umwelt. Die interagierenden Teilnehmer (Elemente, Systemkomponenten, Agenten) handeln nach einfachen Regeln und erschaffen dabei aus Chaos Ordnung, ohne eine Vision von der gesamten Entwicklung haben zu müssen.

Ein einfacher Fall von (physikalischer) Selbstorganisation ist z. B. das Auftreten von Konvektionszellen beim Erhitzen von Flüssigkeiten (Bénard-Experiment).

Das Konzept der Selbstorganisation findet man in verschiedenen Wissenschaftsbereichen wie z. B. Chemie, Biologie (Gerichtete Faltung und Assoziation von Proteinen, Helix-Bildung der DNA, …), Soziologie usw.

Um von Selbstorganisation sprechen zu können, müssen folgende (nicht voneinander unabhängige) Kriterien erfüllt sein:

Selbstorganisation im unternehmerischen Handeln verlagert einen Teil der hierarchischen Funktionen in die unterlagerten Organisationseinheiten. Solches Vorgehen erfordert einen Paradigmenwechsel, der alle Beteiligten neu herausfordert.

Im Zuge der Schülerorientierung wurden seit den 1970er Jahren Unterrichtskonzepte entwickelt, die Selbstorganisation in der Lernergruppe fördern. Hier ist das Konzept kooperatives Lernen zu nennen. Ferner wird in der Methode Lernen durch Lehren die Klasse als „neuronales Netz“ behandelt. Dabei sollen – in Analogie zu neuronalen Ensembles – durch intensive und langfristige Interaktionen zwischen den Lernenden stabile Verbindungen entstehen, die Gruppe lernt also. Darüber hinaus sollen diese „neuronalen Netze“ kollektiv Wissen konstruieren.

Prozesse jugendlicher Selbstorganisation, wie sie sich zum Beispiel in selbstverwalteten Jugendhäusern und Jugendräumen zeigen, stellen eine zentrale Form offener Kinder- und Jugendarbeit dar, in der pädagogische Fachkräfte entweder keine Rolle spielen oder doch nur die Funktion von Begleitern, Beratern oder Moderatoren (z. B. bei Konflikten Jugendlicher mit ihrer Umwelt, etwa den Nachbarn des selbstorganisierten Jugendraumes) wahrnehmen.

Das emergente Verhalten eines selbstorganisierenden Systems zeigt oft sehr gute Eigenschaften bezüglich der Skalierbarkeit und der Robustheit gegenüber Störeinflüssen oder Parameteränderungen, weshalb sich selbstorganisierende Systeme gut als Paradigma für zukünftige komplexe technische Systeme eignen. Allerdings gibt es keinen einfachen Algorithmus, um die notwendigen lokalen Regeln für ein erwünschtes globales Verhalten zu erzeugen. Bisherige Ansätze bauen zum Beispiel auf manuellem Versuch und Irrtum auf und erwarten ein grundsätzliches Systemverständnis durch den Ingenieur. Als andere Alternative werden oft existierende Systeme in der Natur kopiert, was jedoch das Vorhandensein eines geeigneten Beispiels voraussetzt. Ein naturinspiriertes Beispiel ist die Ausnutzung eines Effekts, der in der Natur bei sogenannten Rippelmarken in Dünen auftritt. Dieser Effekt wird beim Schichtwachstum ausgenutzt. Quantenpunkte wachsen so.

Aktuelle Forschung zielt auf die Anwendung von evolutionären Algorithmen zum Entwurf eines selbstorganisierenden Systems.
In den letzten Jahren wird der Begriff der Selbstorganisation vermehrt auch für Technologien zur Herstellung und Modifizierung von MEMS und NEMS verwendet, besser bekannt als Bottom-up-Verfahren. Hier findet Selbstorganisation auf molekularer oder nanokristalliner Ebene statt und kann biologisch, chemisch oder physikalisch erfolgen.






</doc>
<doc id="4441" url="https://de.wikipedia.org/wiki?curid=4441" title="Selbstregulation">
Selbstregulation

Der Begriff Selbstregulation bezeichnet allgemein Prozesse, bei welchen ein System seine Funktion selbst anpasst. Dies kann geschehen, um eine Funktion aufrechtzuerhalten oder das System an neue Bedingungen anzupassen. 

Im Gegensatz zur "Steuerung" beschreibt der Begriff "Regulierung" lernfähige Systeme, die sich durch Rückkopplung (Feedback) an veränderte Rahmenbedingungen anpassen und trotz sogenannter "Störungen" (Soll-Ist-Abweichungen) ihr (selbst gesetztes) Ziel erreichen können.

Der Grundgedanke der Selbstregulation stammt aus der Biologie und gilt als ein grundlegendes Funktionsprinzip lebender Organismen. Sie findet beispielsweise in der Physiologie des menschlichen und des tierischen Körpers fortlaufend statt, meist bei Veränderung statischer Zustände und von uns unbemerkt. Beispiele sind:


Oft spricht man in der Medizin auch von Autoregulation. Diese betrifft meist lokalere Feedbackmechanismen. Insbesondere die Durchblutung von Organen ist oft stark von selbstregulierenden Prozessen abhängig.

Selbstregulation ist ein Begriff, der in der Pädagogik der 1970er Jahre eine zentrale Rolle spielte. Das Konzept beinhaltete, dass Kinder sich ohne bedeutende Einwirkungen durch Erziehende zu gesellschaftsfähigen Individuen entwickeln. Erziehende sind nur noch zuständig, wenn es um den Schutz des Kindes geht. Autorität dagegen, die die Erziehung in die Hand nimmt, ist nicht mehr von Bedeutung oder unerwünscht, da sich Kinder frei und selbständig zum Individuum entwickeln bzw. selbst herausfinden, wie sie sich in der Welt zurechtfinden. Auch soziale Regeln werden in Gruppenprozessen und ohne Einwirkung des Erziehenden formuliert. Der Erziehende sollte oder darf nicht mehr als derjenige auftreten, der Erziehungsprozesse steuert und die Ziele vorgibt.

Beispiele für diese Form der Erziehung waren manche „Kinderläden“. Kinderläden waren Einrichtungen, in denen Kinder manchmal schon vom Säuglingsalter ab und bis nach der Einschulung betreut wurden. Sie waren häufig von Eltern organisiert, die die Erziehungskonzepte zusammen mit den angestellten Erziehern entwickelten und auch regelmäßig mitarbeiteten.




</doc>
<doc id="4442" url="https://de.wikipedia.org/wiki?curid=4442" title="Signal">
Signal

Ein Signal ( ‚dazu bestimmt‘, ‚ein Zeichen‘) ist ein Zeichen mit einer bestimmten Bedeutung, die das Signal durch Verabredung oder durch Vorschrift erhält. Eine Information kann durch ein Signal transportiert werden. Dazu benötigt man einen Sender und einen Empfänger (vgl. das Funksignal in der Nachrichtentechnik). Ohne technische Hilfsmittel kommt man bei der direkten menschlichen Kommunikation aus, dort können (oft nonverbale) Signale verschiedene Aufforderungen bedeuten.

Ein Signal enthält im Allgemeinen eine Bedeutung und kann zur Übertragung einer Nachricht genutzt werden. Es ist nur dann von Nutzen, wenn der Empfänger einen definierten Sinn darin erkennt, über einen geeigneten Sensor verfügt und den Informationsgehalt entsprechend auswerten kann. Ein Gerät oder Gegenstand zur Signalerzeugung ist ein "Signalgerät" (Signalmittel).

Wird ein Signal zur Auswertung von Information genutzt, nennt man es "Nutzsignal". Behindert es die Übertragung nützlicher Information, so heißt es "Störsignal": In diesem Fall enthält es selbst keine verwertbare Information.

Die Abgrenzung von "technischen" und "nicht-technischen" Signalen ist nicht in jedem Fall vollkommen eindeutig herzustellen. Ein nicht-technisches Signal aus dem Bereich Verkehrswesen ist ein Polizist, der mit Handzeichen den Verkehr regelt. Und ein technisches Signal aus dem Bereich Kommunikation ist das Signal in der Telefonleitung. "Lichtsignal" und "Tonsignal" lassen sich nach den verschiedenen Quellen eindeutig voneinander unterscheiden. Bekannte Quelle für ein Lichtsignal ist die Beleuchtung für Notausgänge (Piktogramm).

Allgemein ist ein Signal im technisch-physikalischen Zusammenhang eine Wirkung, welche von einem physikalischen Objekt ausgeht und sich mathematisch als eine Funktion beschreiben lässt (beispielsweise ein elektrischer Spannungsverlauf über der Zeit).

Ein Fachgebiet, das sich mit dem Begriff "Signal" besonders auseinandersetzt, ist die Nachrichtentechnik, ein Bereich der Elektrotechnik. Von einem Signal spricht man, wenn man einer messbaren physikalischen Größe wie z. B. einer elektrischen Spannung, einem Schalldruck oder einer Feldstärke eine Information zuordnet. Diese Information kann aus der Messung eines physikalischen Prozesses stammen, wie zum Beispiel der Messung einer Temperatur. Die Information kann einem Signal auch durch ein technisches Modulationsverfahren aufgeprägt werden, um durch ein Signal beliebige Informationen an eine geeignete Empfangseinrichtung zu übertragen. Im Allgemeinen ändern Signale ihren Betrag als Funktion der Zeit und einer weiteren informationstragenden Größe. Weiterhin sind Signale in allgemeiner Darstellung dimensionslos, haben also keine bestimmte Maßeinheit. Die Zuordnung der Information zu einem Signal ist zunächst willkürlich, sodass die Information im Allgemeinen nur sinnvoll ausgewertet werden kann, wenn die Eigenschaften der Quelle des Signals bekannt sind.

Eine analoge Informationsübertragung kann durch Modulation einer hochfrequenten Trägerwelle erfolgen, sodass das Signal durch Veränderung der Amplitude oder der Frequenz der Trägerwelle entsteht; man spricht dann von Amplitudenmodulation bzw. Frequenzmodulation.

Signale, die keinen kontinuierlichen Zeitverlauf besitzen, nennt man "zeitdiskret". Falls in physikalischen Systemen die Zeit kontinuierlich abläuft, sind nur die von einem Messsystem beobachteten Zustandsgrößen (Werte des Signales zu bestimmten Zeitpunkten) zeitdiskret. Kann die messbare Größe nur endlich viele Werte annehmen, im Extremfall nur zwei wie {an, aus}, {hell, dunkel} oder {0, 1}, so spricht man von einem "wertdiskreten" oder n-nären (im Falle von zwei Werten binären) Signal. Ein gleichzeitig zeitdiskretes und wertdiskretes Signal wird als Digitalsignal bezeichnet. Im Gegensatz dazu bezeichnet man als Analogsignal ein Signal, dessen informationstragende Größe stetig veränderliche Werte annehmen kann.

Beispiele für Signale in der Nachrichtentechnik sind das Zeitsignal oder in der Fernseh- und Videotechnik das Fernsehsignal. 

Als Signal bezeichnet man außerdem elektrische Wechselspannungen die aus Signalgeneratoren stammen. Sie weisen einen charakteristischen Zeitverlauf auf und können außer zu Modulations- auch zu Steuerungs- Test- und Messzwecken eingesetzt werden.

Das Modell eines Signals ist die reelle Funktion, die jedem Punkt der reellen Achse als Zeitstrahl einen reellen Wert zuweist. Möchte man auch räumliche Aspekte oder Variationen in weiteren Parametern in den Signalbegriff einbeziehen, wie es in der digitalen Bildbearbeitung geschieht, so modelliert man das Signal als Funktion mit dem linearen Raum ℝ oder einer Teilmenge davon als Definitionsbereich. Den Fall "d" = 1 assoziiert man mit zeitabhängigen Signalen, den Fall "d" = 2 mit ortsabhängigen Signalen.

Die Zielmenge muss ebenfalls nicht auf eine Dimension eingeschränkt zu bleiben. Verfolgt man die Entwicklung mehrerer Größen gleichzeitig, so bildet das "N"-Tupel der Messwerte einen Punkt in einem linearen Raum ℝ.

Ist der Definitionsbereich diskret, besteht er also aus isolierten Punkten, so nennt man das Signal ebenfalls "diskret". Für die Signaltheorie relevant sind dabei endliche Mengen und reguläre Gitter im ℝ, wie z. B. die Menge ℤ oder skalierte Varianten davon. (Jedes reguläre Gitter im ℝ ist gegeben durch einen Aufpunkt O, meist der Nullpunkt, und eine Basis, meist eine skalierte Instanz der kanonischen Basis.)

Ist zusätzlich zum diskreten Definitionsbereich der Wertevorrat eine endliche Menge, z. B. eine endliche Teilmenge des ℝ, so nennt man das Signal "digital", denn die endlich vielen Elemente können durch Bitfolgen aus {0,1} für ein genügend großes "M "aufgezählt werden. Ein "elementares" digitales Signal ist eine Funktion auf einem Gitter, die in die Menge {0,1} bzw. die der Wahrheitswerte {wahr, falsch} oder die der Zustände {an, aus} abbildet. Über Tupel, d. h. Bitfolgen, von "elementaren digitalen Signalen" kann jede Form von digitalen Daten kodiert werden.

Im Verkehrswesen ist das Signal ein für den Verkehrsteilnehmer an der Strecke aufgestelltes Zeichen, das Regeln für die Benutzung des Verkehrsweges definiert, also z. B. Aussagen über Befahrbarkeit und Höchstgeschwindigkeit eines bestimmten Streckenabschnitts trifft. Man unterscheidet folgende Signale:

Für die Übertragung eines (elektrischen) Tonsignals im Sinne der Tontechnik hat der Lautsprecher weltweite Verbreitung gefunden. Mehrere Tonsignale lassen sich ggf. als Akkord (unterschiedliche Signale gleichzeitig) oder als Melodie (Abfolge von Signalen) wahrnehmen. Quellen für Tonsignale sind: Mikrofon mit Verstärker, Musikinstrument, Tonwiedergabegeräte (z. B. CD-Spieler, Plattenspieler etc.), Synthesizer (z. B. Soundkarte).

Als Messsignal bezeichnet man eine physikalische Größe, die der zu messenden Größe eindeutig zugeordnet ist. Das Messsignal ist in der Regel zeitlich veränderlich. Im Zusammenhang mit einer Messeinrichtung unterscheidet zwischen deren Eingangs- und Ausgangssignal. Das Ausgangssignal kann eine Anzeige sein oder ein vorzugsweise elektrisches Signal in Form eines Analog- oder Digitalsignals.

Beispiel: Wenn die Frequenz einer akustischen Schwingung zu messen ist, wird das Messsignal eine elektrische Wechselspannung sein.

In der Informationstechnik bezeichnet man zwei unterschiedliche Dinge als "Signal":

Im Militärwesen verwendet man Signale, um freundlichen oder feindlichen Truppen Informationen zukommen zu lassen; siehe auch: Erkennungssignal, Signalmittel, Flaggensignal, Schamade.

An Flughäfen werden sogenannte Marshaller (Einwinker) eingesetzt, um Flugzeuge zu ihren gekennzeichneten Parkpositionen () zu lotsen. Eine verbale Kommunikation zwischen Marshaller und Pilot ist dagegen gewöhnlich nicht möglich. Daher muss die Verständigung mit den Piloten durch standardisierte Handzeichen (Leuchtstäbe) erfolgen.

Im frühen 19. Jahrhundert wurde optisch telegrafiert, d. h. die Information wurde durch die Stellung von Telegrafenarmen übertragen.

Als Notsignal oder Warnsignal werden im Gebirge oder auf See Signalraketen verwendet, aber auch der Morse-Code für SOS ""kurz-kurz-kurz lang-lang-lang kurz-kurz-kurz"".

"Signalwesten" werden in verschiedenen Berufsbereichen getragen, um Fußgänger in besonderen Situationen deutlich sichtbar zu machen: am Flughafen oder am Hafen, in Baustellen oder bei einer Panne am Fahrzeug.

Signale für die Wahrnehmung durch den Menschen sind so beschaffen, dass einer der Sinne des Menschen diese wahrnehmen kann, beispielsweise als Signalfarbe oder Klingelton. Sie können einen bestimmten Zweck haben, z. B. als Warnsignal oder eine Information enthalten wie z. B. über die "freie Fahrt" an einer grün leuchtenden Verkehrsampel.

In diesem Sinne werden in der Schweiz die Verkehrszeichen als Strassensignale bezeichnet.

Signale für die Wahrnehmung durch den Menschen können im Ursprung elektrotechnisch, chemischen oder körpersprachliche generiert sein. z. B. bei einer Geste.

Auch im Umgang zwischen Mensch und Tier sind Signale üblich (vgl. Dressur), so zum Beispiel bei Hund oder Pferd. Hierbei müssen die Schritte des Signalerkennens, der Signalauswertung und einer entsprechend antrainierten Reaktion vorher geübt werden.

Ein "politisches Signal" ist eine Handlung, von deren Vorbild- und anderer Wirkung oder deren kulturell implizierten Bedeutungen eine Beeinflussung der Akteure eines politischen Systems erwartet wird.

In Lebewesen findet die Signalübertragung hauptsächlich durch Botenstoffe und elektrische Ladungen (Nervenzellen) statt.


</doc>
<doc id="4443" url="https://de.wikipedia.org/wiki?curid=4443" title="Speicher">
Speicher

Ein Speicher (von ‚Getreidespeicher‘, aus "spica" ‚Ähre‘), je nach Zusammenhang auch Lager, Depot, Ablage, Puffer, Vorrat oder Reserve genannt, ist ein Ort oder eine Einrichtung zum Speichern von materiellen oder immateriellen (Datenspeicher) Objekten.


Speicher können natürlichen Ursprungs sein oder vom Menschen künstlich geschaffen werden.

Zumeist erfolgt eine Speicherung vom Menschen zeitlich befristet mit der Absicht oder zumindest der Option, das Eingelagerte zu einem späteren Zeitpunkt wieder für den Gebrauch zu entnehmen. Solche oft auch "Zwischen"speicher, Puffer oder Vorrat bezeichneten Speicher dienen zum Ausgleich von zeitlichen Unterschieden zwischen Zufluss/Angebot und Abfluss/Nachfrage. 

Seltener erfolgt eine Speicherung unbefristet oder endgültig. Für solche Speicher ist im Sprachgebrauch der Begriff (End-)Lager oder Ablage üblicher.

Die gespeicherte Menge und somit der Füllstand des Speichers, ergibt sich mathematisch als zeitliches Integral über die Differenz aus Zuflussrate und Abflussrate im Zeitintervall formula_1 

Wird die Speicherkapazität (d. h. der maximal mögliche Füllstand) überschritten, kommt es ggf. zu einem Überlauf. 

Ein Speicher ist ein wichtiges Element in der Regelungstechnik. Es kann zur Glättung verwendet werden. Bei einem System mit mehreren Speichern gleicher Art kann es zu Schwingungen kommen.





</doc>
<doc id="4445" url="https://de.wikipedia.org/wiki?curid=4445" title="Stau (Wasserstraßen)">
Stau (Wasserstraßen)

Ein Stau (griechisch: στάσις = stasis für stehen, Station) bezeichnet die Störung eines Verkehrs- oder Transportflusses über einen Transportweg, zum Beispiel Kanal. Mögliche Störungen sind z. B. Engstellen oder sonstige Verkehrsbehinderungen; von Stau spricht man allgemein, sobald der Fluss erheblich behindert ist oder vollständig zum Erliegen kommt. Die Eigenschaften des Transportweges beziehungsweise Kanals wie Kapazität und die Verkehrslenkung einerseits und die Eigenschaften des Transportgutes andererseits sind dabei von großer Bedeutung.

Der Transport ist normalerweise gekennzeichnet durch eine fortgesetzte Belegung und gleichzeitige Freigabe von (Kanal-)Ressourcen. Dieser Vorgang ist bei einem Stau gestört. Folge ist eine fortgesetzte weitere Belegung, aber ohne entsprechende Freigabe. Der Stau ist daher ein selbstverstärkender Vorgang, der durch plötzliches Entstehen z. B. auf Wasserwegen seine Gefährlichkeit ausmacht.

Ein Stau kann gewollt oder ungewollt sein. Beispiele für einen gewollten Stau ist der Wasserstau an einer Staustufe oder einer Stauanlage: größtenteils zur Stromerzeugung, gelegentlich auch zur Bewässerung.

In der Mehrheit ist der Stau eine ungewollte Erscheinung und kann folgende Ursachen haben:


Weitere Engstellen sind Schleusen und Schiffshebewerke. Ebenso kann der Kreuzungsverkehr mehrerer Verkehrsarten (Fluss zu Schiene/Straße) an beweglichen Brücken durch Blockabfertigung einen Schiffsstau verursachen.

Man unterscheidet zwischen Wasserstau und Schiffsstau. Ein Wasserstau kann, wie oben beschrieben, gewollt oder durch Treibgut oder Umweltverschmutzung fahrlässig verursacht sein.

Ein Schiffsstau ist immer von dem Verhalten der Verkehrsteilnehmer bzw. vom Einsatz der Schiffe durch die Reedereien abhängig. Auch Havarien tragen zur Störung im Verkehrsfluss der Schiffe bei. Flüsse sind meistens nicht durchgängig barrierefrei, sodass Schiffe geschleust werden müssen. Hier entstehen wegen der begrenzten Aufnahmemöglichkeit in der Schiffsschleuse Rückstaus wartender Schiffe, die sich auch nachteilig auf den Verkehrsfluss auswirken. Ein Schiffsstau kommt wegen der großen zur Verfügung stehenden Verkehrsfläche sehr selten vor, außerdem besteht auf den Binnenwasserstraßen ein effektives Verkehrslenkungssystem, das die Schiffsführer frühzeitig auf Behinderungen aufmerksam macht.

Möglichkeiten zur Verhinderung von Verkehrsstaus auf Wasserstraßen sind:


</doc>
<doc id="4447" url="https://de.wikipedia.org/wiki?curid=4447" title="Symbiose">
Symbiose

Symbiose (von sowie ) bezeichnet in Europa die Vergesellschaftung von Individuen zweier unterschiedlicher Arten, die für beide Partner vorteilhaft ist.

Ausgehend von seinen Arbeiten an Flechten schlug Anton de Bary 1878 auf der 51. "Versammlung Deutscher Naturforscher und Ärzte" in Kassel vor, die Bezeichnung "Symbiose" für jegliches Zusammenleben von artverschiedenen Organismen, also auch für den Parasitismus, in die Biologie einzuführen. In diesem weitgefassten Sinn wird die Bezeichnung "Symbiose" (englisch "symbiosis") noch immer in der US-amerikanischen Literatur für sämtliche Formen des koevolutionär entstandenen Zusammenlebens, vom Mutualismus über den Kommensalismus, den Neutralismus bis hin zum Parasitismus verwendet. In Europa wird die Bezeichnung "Symbiose" dagegen im eingangs definierten engeren Sinn verwendet.

Bei Symbiosen zwischen Lebewesen, die sich durch ihre Größe erheblich unterscheiden, bezeichnet man den größeren Partner oft als "Wirt", den kleineren als "Symbiont".

Der größte Teil der Biomasse auf der Erde besteht aus symbiotischen Systemen, da ein großer Teil der Bäume und Sträucher auf Bestäubung durch andere Spezies angewiesen ist. Hinzu kommen die Flechten, eine symbiotische Lebensgemeinschaft zwischen einem Pilz und Grünalgen oder Cyanobakterien. Viele im flachen Wasser lebende sessile wirbellose Meerestiere wie Feuerkorallen, die meisten Blumentiere sowie die Riesenmuscheln leben mit Fotosynthese betreibenden Zooxanthellen zusammen. Ein weiteres Beispiel sind die Magen- und Darmbakterien der Tiere, die etwa bei Wiederkäuern den Aufschluss zellulosereicher Pflanzennahrung ermöglichen.

Eine Unterscheidungsmöglichkeit verschiedener Symbiosenformen ergibt sich aus dem Grad der wechselseitigen Abhängigkeit der beteiligten Arten:


Eine Unterscheidung verschiedener Symbioseformen ergibt sich aus der räumlichen oder körperlichen Beziehung der beiden beteiligten Arten:


Eine Unterscheidung von Symbioseformen ergibt sich aufgrund der Art des erzielten Nutzens für die beiden beteiligten Arten.



Die Endosymbiontentheorie besagt, dass die Mitochondrien und Chloroplasten, Zellorganellen in Eukaryoten (Pflanzen, Tiere und Pilze), zu einem frühen Zeitpunkt der Evolution aus endosymbiotisch lebenden Prokaryoten (aerobe, chemotrophe Bakterien bzw. Cyanobakterien) entstanden sind. Hierfür sprechen die Übereinstimmungen im strukturellen Aufbau und in den von den Wirtszellen abweichenden, aber mit den Prokaryoten übereinstimmenden, biochemischen Merkmale (z. B. Aufbau der Ribosomen und, soweit vorhanden, der DNA). Des Weiteren vermehren diese Zellorganellen sich durch Teilung, genau wie Bakterien es tun.

Die Aufnahme von Endosymbionten ist ein Beispiel dafür, dass symbiotische Lebensgemeinschaften im Laufe der Evolution so eng werden können, dass es sinnvoll ist, diese als neu gebildete biologische Arten zu betrachten. Dieses Entstehen einer neuen Art durch Verschmelzung von Symbionten wird als Symbiogenese bezeichnet. Die Bedeutung der Symbiogenese wurde in neuerer Zeit durch die US-amerikanische Evolutionsbiologin Lynn Margulis stark betont. Nach ihrer (stark umstrittenen) Theorie gehört Symbiogenese zu den wichtigsten artbildenden Mechanismen überhaupt.

Zur wissenschaftlichen Beschreibung und Modellierung symbiotischer Systeme kommen in der Biologie Systeme gewöhnlicher Differentialgleichungen, gelegentlich aber auch kompliziertere mathematische Strukturen zum Einsatz.

Beispielsweise werden, unter Zuhilfenahme einiger idealisierender Vereinfachungen Symbiosen zweier Spezies auf Ebene der Populationsdynamiken beschrieben durch: 

falls ein Effekt der Symbiose in einer Veränderung der intrinsischen Wachstumsrate der beteiligten Populationen besteht

und 

falls der primäre Effekt in einer Anpassung der Kapazitäten liegt. 

(Bezeichnungen: X,Y Abundanzen der Spezies; a,b intrinsische Wachstumsraten der Spezies, K1,K2 Kapazitäten, c.d ökologische Interaktionsparameter) 

Mischformen dieser beiden simplifizierenden Grenzfälle sind selbstverständlich möglich und dürfen in der Natur regelhaft vermutet werden.



Johann Brandstetter und Josef H. Reichholf (Hrsg.): "Symbiosen. Das erstaunliche Miteinander in der Natur." Matthes und Seitz, Berlin 2017, ISBN 978-3-95757-366-7


</doc>
<doc id="4448" url="https://de.wikipedia.org/wiki?curid=4448" title="System">
System

Als System (altgr. σύστημα ', ‚aus mehreren Einzelteilen zusammengesetztes Ganzes‘) wird allgemein eine Gesamtheit von Elementen bezeichnet, die miteinander verbunden sind und dadurch als eine aufgaben-, sinn- oder zweckgebundene Einheit angesehen werden können, als strukturierte systematische"' Ganzheit. In unterschiedlichen Fachgebieten werden darüber hinaus spezifischere Begriffsverwendungen vorgeschlagen, diskutiert und angewendet.
Begriffsgeschichtlich tritt neben die Verwendung der Bezeichnung „System“ für funktionale Gebilde wie Sonnensysteme oder Tonsysteme die Verwendung für (Grimm’sches Wörterbuch). Ein hierzu ähnlicher Begriff ist "Konstrukt" (vgl. auch die Theorie des "Sozialkonstruktivismus").

Die griechischen Ausdrücke σύστημα, σύσταμα, σύστεμα fanden Gebrauch als „Oberbegriff für alle verbandlichen Organisationen, die öffentlichen Gemeinwesen mit eingeschlossen“.

Darüber hinaus wird σύστημα gebraucht

An den musiktheoretischen Gebrauch knüpft Platon in seinem späten Dialog "Philebos" an. Er spricht von den vielen „Verbindungen“, welche aus den „Zwischenräumen“ der Töne entstehen und von ebenfalls in Zahlen messbaren „ähnlichen Verhältnissen“ in den Bewegungen des Leibes; zugleich müsse man dabei bedenken, was darin „Eines und Vieles“ ist; durch dieseart Überlegung gelange man zur „Einsicht“, die wegen der Unendlichkeit jedes Begriffs und Dinges aber nie abschließbar sei.

Der pseudo-platonische Dialog "Epinomis" bezieht den Terminus „σύστημα“ auf die Zahlen, mit welchen die Gesetze der Sternbahnen erfassbar sind.

Seit dem 16. Jahrhundert wird der Systembegriff in verschiedenen Zusammenhängen verwendet, so z. B. bezogen auf die Sphäre der Politik zuerst durch Thomas Hobbes im Sinne einer "political entity".

Als "Systemtheorie" werden Forschungsrichtungen diverser Fachrichtungen zusammenfassend bezeichnet, die komplexe Zusammenhänge durch allgemeine Theorien zum Funktionieren von Systemen überhaupt beschreiben. Als erster definierte um 1950 Ludwig von Bertalanffy (1901–1972) Systeme als Interaktionszusammenhänge, die sich von ihrer Umwelt abgrenzen, die wiederum aus anderen Interaktionszusammenhängen besteht. Gemäß in diesem Kontext verbreiteter Grundideen lassen sich Systeme als sich selbst organisierende Funktionseinheiten verstehen, die ihr Weiterfunktionieren selbst produzieren (vgl. Autopoiesis) und sich in spezifischer Weise von ihrer Umwelt differenzieren, etwa durch Ausprägung spezifischer Unterscheidungsweisen. 
Ein Beispiel: Seefahrer setzten bestimmte Tiere auf einer Insel aus, um sie später dort jagen zu können. Dadurch gerät das bis dahin auf der Insel bestehende System aus Tieren und Pflanzen „durcheinander“; ein neues System entsteht. Manchmal entstehen Endemiten (= Pflanzen oder Tiere, die nur in einer bestimmten, räumlich klar abgegrenzten Umgebung vorkommen).

Der strukturalen Linguistik (→ Strukturalismus) liegt die Auffassung zugrunde, dass sprachliche Einzelelemente nicht jeweils durch sich selbst in ihrer Bedeutung begründet sind, sondern durch ihre Relationen zu anderen Elementen – wobei deren Ganzheit als "System" mit unter anderem dieser allgemeinen Eigenschaft beschrieben wird.

Für Leittechnik definiert IEC 60050-351 ein System als 





</doc>
<doc id="4449" url="https://de.wikipedia.org/wiki?curid=4449" title="Sergio Leone">
Sergio Leone

Sergio Leone (* 3. Januar 1929 in Rom, Italien; † 30. April 1989 ebenda) war ein italienischer Filmregisseur. Besondere Bekanntheit erlangte er durch seine Arbeiten im Bereich der Italo-Western. Mit den epischen Westernfilmen "Zwei glorreiche Halunken" und "Spiel mir das Lied vom Tod" konnte er in den späten 1960er Jahren seine größten Erfolge verbuchen.

Sergio Leone wurde am 3. Januar 1929 als Sohn des Filmpioniers Vincenzo Leone („Roberto Roberti“) und der Schauspielerin Edvige Valcarenghi („Bice Walerian“) geboren. Sein Vater war seit 1911 im Filmgeschäft tätig und wurde in Italien vor allem durch seine Zusammenarbeit mit dem Stummfilmstar Francesca Bertini bekannt. Er sympathisierte mit den Kommunisten und zog sich unter dem Eindruck des Faschismus weitgehend von der Außenwelt zurück.

Leone selbst wurde in seiner Jugend nicht nur durch die Herrschaft des Duce, sondern auch durch die Besetzung Roms sowie die letzten Kriegsjahre geprägt. In diese Zeit fällt auch sein erster Kontakt mit der US-amerikanischen Populärkultur, für die er sich begeisterte. Besonders das Kino Hollywoods faszinierte den jungen Leone: 

Leones Vater begann ab 1939 damit, wieder Filme zu drehen. Da Vincenzo Leone den kleinen Sergio regelmäßig zu seiner Arbeit mitnahm, war dieser bereits von Kindesbeinen an mit allen Aspekten der Filmherstellung vertraut.

Ab Mitte der 1940er Jahre arbeitete Leone in den unterschiedlichsten Positionen im italienischen Studiosystem. Als Statist, Regieassistent, Regisseur des zweiten Kamerateams oder Autor von Drehbüchern wirkte Leone bei einer Vielzahl von italienischen Filmen mit. Meist handelte es sich um künstlerisch eher anspruchslose Filme im Stile des damals sehr populären Peplum.

Allerdings war Leone als Komparse und Regieassistent auch an dem Filmklassiker "Fahrraddiebe" (1948) beteiligt. Bei dem amerikanischen Monumentalfilm "Quo Vadis" (1951), der in Rom gedreht wurde, fungierte er als einer der Regisseure des zweiten Aufnahmeteams. Dieselbe Funktion hatte er 1959 auch bei "Ben Hur" inne, dem aufwändigsten Filmprojekt der 1950er Jahre. Auch dieses Hollywood-Epos wurde in Italien gedreht. Als Regisseur war Leone später stark vom amerikanischen Kino beeinflusst und vor allem an epischen, publikumswirksamen Filmen interessiert.

1959 war Sergio Leone als (ungenannter) Co-Regisseur bei "Die letzten Tage von Pompeji" tätig, einem von Mario Bonnard inszenierten, zeittypischen Sandalenfilm. Streifen dieser Art wurden damals in Italien in großer Zahl produziert. Leone hatte bei "Die letzten Tage von Pompeji" bemerkenswerterweise mehrere Mitarbeiter, die später zu den führenden Regisseuren des Italo-Western wurden: Duccio Tessari war Regieassistent, Sergio Corbucci und Enzo Barboni agierten als Regisseur bzw. Kameramann des zweiten Kamerateams. Auch wenn "Die letzten Tage von Pompeji" eine Billig-Produktion war, lernte Leone bei der Herstellung des Films viel über die Filmfinanzierung.

1961 absolvierte der 32-jährige Sergio Leone mit "Der Koloß von Rhodos", einem weiteren Sandalenfilm italienischer Prägung, sein eigentliches Regiedebüt. Verglichen mit den späteren Werken des Regisseurs ist dieser Film nach allgemeinem Tenor von geringer Bedeutung. Leone selbst räumte ein, er habe den Film nur gedreht, um seine Hochzeitsreise zu finanzieren. Dies führte dazu, dass dieser Film in Gesamtdarstellungen von Sergio Leones Werk nur rudimentär behandelt oder sogar ausgelassen wird. Dennoch lassen sich bereits einige Charakteristika seines späteren Schaffens erkennen.

Während in den frühen 1960er Jahren die Nachfrage nach Sandalenfilmen langsam verebbte, war Leone schon mit der Vorbereitung seines nächsten Filmes befasst. Er orientierte sich diesmal in einer völlig anderen Richtung und bereitete die Produktion eines Western vor. Leone war von diesem Genre begeistert und glaubte daran, dass auch europäische Westernfilme erfolgreich sein konnten, obwohl bis dato alle bedeutenden Western aus den USA gekommen waren. Seit 1962 liefen im deutschsprachigen Raum allerdings mit großem Erfolg die Filme der Karl-May-Reihe.

In Italien waren bereits vor Leone Western produziert worden (ungefähr 25), doch blieben diese in kommerzieller wie künstlerischer Hinsicht bedeutungslos. Es war Leone, der mit "Für eine Handvoll Dollar" (1964) das Genre des Italo-Western in der heute bekannten Form begründete. Bei der Ausarbeitung des Drehbuchs orientierten sich er und seine Co-Autoren an Akira Kurosawas Film "Yojimbo – Der Leibwächter" (1961). Die Hauptfigur von Kurosawas Film, einen Samurai-Krieger, transformierte Leone in einen Westernhelden. Kurosawa und sein Co-Autor strengten einen Copyright-Prozess an und erhielten unter anderem 15 % der weltweiten Einnahmen des Leone-Films.

Da Sergio Leone nur ein geringes Budget zur Verfügung stand (200.000 Dollar), konnte er keinen etablierten amerikanischen Star wie Henry Fonda oder James Coburn für die Hauptrolle von "Für eine Handvoll Dollar" engagieren. Auf der Suche nach einem bezahlbaren US-Schauspieler stieß Leone auf den relativ unbekannten TV-Darsteller Clint Eastwood, der schließlich für 15.000 Dollar verpflichtet wurde. Der 34-jährige Eastwood trat in der Rolle eines mysteriösen Revolvermannes auf, der in einem abgelegenen Dorf in New Mexico zwei verfeindete Clans gegeneinander ausspielt und sich dabei durch seine phänomenalen Schießkünste auszeichnet.

"Für eine Handvoll Dollar" galt zunächst als obskur und wurde von den Kritikern entweder verrissen oder überhaupt nicht beachtet. Der Film entwickelte sich jedoch zu einem sensationellen Kassenerfolg. In der Rolle des zynischen „Fremden ohne Namen“ (tatsächlich trug er den Rollennamen „Joe“), der seinen Gegnern in einem Poncho mit aufreizender Lässigkeit gegenübertritt, wurde Clint Eastwood zu einem internationalen Star. Unzählige Westerndarsteller orientierten sich in den Folgejahren an dem von Eastwood und Leone geschaffenen Charaktertypus. Leone selbst hielt nicht allzu viel von den schauspielerischen Fähigkeiten seines Hauptdarstellers: „Er hat zwei Gesichtsausdrücke: einen mit und einen ohne Hut.“

Um den Eindruck zu erzeugen, "Für eine Handvoll Dollar" sei ein amerikanischer Film, hatten sich Leone und seine Mitarbeiter englische Pseudonyme zugelegt (Leone agierte beispielsweise als „Bob Robertson“ – eine Hommage an seinen Vater, der als Roberto Roberti bekannt gewesen war). Bei "Für ein paar Dollar mehr" (1965) wurden im Vorspann dagegen die richtigen Namen der Filmemacher genannt. Für diesen zweiten Film seiner – später so genannten – „Dollar-Trilogie“ stand Leone ein sehr viel höheres Budget (600.000 Dollar) zur Verfügung. Lee Marvin, Charles Bronson oder Henry Fonda sollten die zweite Hauptrolle neben Clint Eastwood spielen, konnten aber nicht verpflichtet werden, weshalb Leone den 40-jährigen Lee van Cleef engagierte, der bis dahin in zahlreichen Hollywood-Western (Zwölf Uhr mittags) in kleineren Nebenrollen aufgetreten war.

Eastwood trat erneut als unrasierter Revolvermann in Erscheinung und spielte einen Kopfgeldjäger, der mit seinem „Kollegen“ (Van Cleef) eine Gaunerbande zur Strecke bringt. Wie schon der Vorgängerfilm wurde auch "Für ein paar Dollar mehr" hauptsächlich in der Gegend von Almeria in Spanien gedreht, und wie "Für eine Handvoll Dollar" wurde er zu einem großen Kassenerfolg.

Leone war als Regisseur nun so etabliert, dass ihm für den letzten Teil der „Dollar-Trilogie“ ein Budget von 1,2 Millionen Dollar bewilligt wurde, was die Produktion eines epischen Westernfilms mit aufwändigen Szenenaufbauten und einer großen Zahl an Statisten ermöglichte. (Alle Filme, die Leone ab da an drehte, hatten eine Überlänge von mindestens 2 ½ Stunden.) In "Zwei glorreiche Halunken" (1966) war Clint Eastwood erneut als Kopfgeldjäger im Poncho zu sehen und jagte neben Lee van Cleef (als sadistischem Bösewicht) und Eli Wallach (als mexikanischem Banditen) hinter einem Goldschatz her, der in den Wirren des Bürgerkriegs verlorenging. Leones dritter Western wurde zu einem riesigen Kassenerfolg und avancierte im Lauf der Jahrzehnte zu einem beliebten Kultfilm. In der Internet Movie Database rangiert er auf der Liste der besten Filme auf Platz 9 und gilt dort als bester Western aller Zeiten (Februar 2016).

Der enorme finanzielle Erfolg der relativ günstig produzierten „Dollar“-Filme löste die Italowestern-Welle aus, die in der zweiten Hälfte der 1960er Jahre ihren Höhepunkt hatte und hunderte von Filmen unterschiedlichster Qualität hervorbrachte. Fast alle Italowestern waren Billigproduktionen, die sich an den Werken Leones orientierten, welcher das Genre stilistisch und thematisch nachhaltig prägte.

Typischerweise traten in den Italowestern zynische, unrasierte Revolvermänner in Erscheinung, die im amerikanisch/mexikanischen Grenzgebiet gegen sadistische Schurken kämpften. Explizite Gewaltdarstellungen und Folterszenen prägten das Genre, die Protagonisten wurden häufig (auch bei Leone) schwer misshandelt. Die gängigen Themen der amerikanischen Western (Landbesiedelung, Krieg gegen die Indianer etc.) wurden in den Italowestern kaum behandelt. Zahlreiche Filme waren, korrespondierend mit dem Zeitgeist der späten 1960er Jahre, als „Revolutions-Western“ konzipiert und zeigten den Kampf der mexikanischen Landbevölkerung gegen ihre Unterdrücker. Da viele der Filme in Spanien gedreht wurden, konnten die südländisch aussehenden spanischen Statisten leicht als Mexikaner ausgegeben werden.

Anfang der 1970er Jahre wurde durch die enorm erfolgreichen Klamauk-Western mit Bud Spencer und Terence Hill, in denen die Klischees dieses Sub-Genres persifliert wurden, das Ende des Italowesterns eingeläutet. Bis Mitte der 1970er Jahre entstanden noch einige ernsthafte Filme wie zum Beispiel Keoma – Das Lied des Todes (1976) mit Franco Nero, dem wohl profiliertesten italienischen Star dieses Genres. Obwohl sich Regisseure wie Sergio Corbucci (Django) oder Duccio Tessari (Eine Pistole für Ringo) ebenfalls im Italowestern profilieren konnten, blieb Sergio Leone in kommerzieller wie künstlerischer Hinsicht die bestimmende Figur.

Die ersten drei Western von Sergio Leone revolutionierten den Inszenierungsstil des gesamten Genres und wirkten stilbildend nicht nur für den Italowestern. Der amerikanische Westernfilm, der Mitte der 1960er Jahre in seinen Konventionen erstarrt war, orientierte sich ab der zweiten Hälfte der 1960er Jahre deutlich an den viel zeitgemäßeren italienischen Western. Filme wie Die gefürchteten Vier (1966), Hängt ihn höher (1968), Das Wiegenlied vom Totschlag (1970) oder Chatos Land (1971 – dies war eine englische Produktion) orientierten sich am harten, zynischen Grundton des Italowesterns.

Sergio Leone arbeitete ab Mitte der 1960er Jahre mit einem festen Mitarbeiterstab, der an den meisten seiner Filme beteiligt war. Kameramann Tonino Delli Colli (1922–2005) sorgte für den speziellen Look der Leone-Filme, der unter anderem durch den Wechsel zwischen opulenten Landschaftspanoramen und ungewöhnlichen Großaufnahmen der Darstellergesichter geprägt war. Delli Colli und Leone waren auch darauf spezialisiert, aufwändige Kamerabewegungen zu arrangieren (Kamerafahrt über das Dach des Bahnhofsgebäudes in "Spiel mir das Lied vom Tod").

Der Filmeditor bei allen Leone-Filmen ab "Zwei glorreiche Halunken" war Nino Baragli (1925–2013), der zusammen mit Leone für die komplexen Szenenmontagen verantwortlich zeichnete („Triello“ am Schluss von "Zwei glorreiche Halunken"). Als Produktionsdesigner und Kostümbildner war Carlo Simi (1924–2000) für die Ausstattung der Leone-Filme zuständig, die meist durch eine besondere Opulenz geprägt war.

Von elementarer Bedeutung für Sergio Leones Filme war die Musik von Ennio Morricone (* 1928), einem Klassenkameraden des Regisseurs aus Kindertagen. Nachdem sich Leone und Morricone – der als Trompeter, Arrangeur, Komponist und Dirigent tätig war – jahrelang aus den Augen verloren hatten, trafen sie sich wieder, als Leone einen geeigneten Komponisten für "Für eine Handvoll Dollar" suchte. Morricone, der seit 1961 als Filmkomponist arbeitete, schuf für Leone Soundtracks, die sich fundamental von den traditionellen symphonischen Westernsoundtracks unterschieden und durch den Einsatz unkonventioneller Instrumente (Maultrommel) und Soundeffekte (Kojotengeheul) auffielen. Morricone stellte seine Musik in der Regel bereits vor den Dreharbeiten fertig, was Leone die Möglichkeit gab, Szenen oder Kamerabewegungen genau auf sie abzustimmen. Als Komponist zeichnete er ab 1964 für jeden Leone-Film für die Musik verantwortlich.

Ennio Morricone stieg zu einem der bekanntesten und international gefragtesten Filmkomponisten auf und schuf Melodien, die über das Kino hinaus zu einem Teil der Populärkultur wurden ("Lied vom Tod", "Nobody-Thema"). Er zeichnet bis heute (Stand 2012) für mehr als 500 Soundtracks verantwortlich; seine Musik wurde so populär, dass er sie seit Jahren mit großer Orchesterbegleitung live aufführt. Zahlreiche Komponisten wie zum Beispiel Bruno Nicolai orientierten sich bei ihren Italo-Western-Soundtracks an Morricones Arbeiten.

Sergio Leone, der stark vom amerikanischen Kino geprägt war, verpflichtete für seine Filme vor allem US-Schauspieler. Eine Ausnahme war der Italiener Gian Maria Volonté (1933–1994), der in den ersten beiden Dollar-Filmen als Schurke auftrat. Hauptdarsteller der Dollar-Trilogie war Clint Eastwood (* 1930), der als Zigarillo rauchender Revolvermann zu einer Ikone der Popkultur wurde und es vom TV-Cowboy ("Rawhide") zum internationalen Filmstar brachte. Als Darsteller, Regisseur und Produzent zählt Eastwood seit Jahrzehnten zu den führenden Hollywood-Persönlichkeiten. Lee van Cleef (1925–1989) avancierte durch die Leone-Filme zu einem der populärsten Stars des Italo-Westerns und spielte häufig abgeklärte Kopfgeldjäger und ähnliche Figuren. Charles Bronson (1921–2003) wurde 1968 durch "Spiel mir das Lied vom Tod" zum internationalen Action-Star.

Nachdem sich Sergio Leone mit seinen ersten Filmerfolgen einen guten Ruf erworben hatte und seine Budgets größer geworden waren, konnte er auch renommierte amerikanische Charakterdarsteller wie Eli Wallach (1915–2014), Henry Fonda (1905–1982), Jason Robards (1922–2000) oder Rod Steiger (1925–2002) verpflichten. In den 1980er Jahren arbeitete er mit Robert De Niro (* 1943) zusammen.

Nachdem "Zwei glorreiche Halunken" zu einem großen Erfolg geworden war, avancierte Leone endgültig zu einem internationalen Star-Regisseur und erhielt die Chance, in Hollywood zu arbeiten. Er wollte jedoch zunächst keine Western mehr drehen, sondern plante die Produktion eines epischen Gangsterfilms. Da die Studios dieses Genre für nicht mehr zeitgemäß hielten, erklärte sich Leone dazu bereit, einen weiteren Western zu inszenieren.

Mit seinen Drehbuchautoren Bernardo Bertolucci, Dario Argento (beide wurden später selbst als Regisseure bekannt) und Sergio Donati erarbeitete er die epische, opernhafte Geschichte von "Spiel mir das Lied vom Tod" ("C’era una volta il West"/"Once Upon A Time In The West") (1968), einer Prestigeproduktion, für die ihm ein Budget von fünf Millionen Dollar bewilligt wurde. Es war die erste von nur zwei US-Produktionen Leones.

"Spiel mir das Lied vom Tod" entstand in Amerika, Spanien und Italien und war mit amerikanischen Darstellern wie Henry Fonda, Charles Bronson und Jason Robards besetzt. Die italienische Star-Schauspielerin Claudia Cardinale komplettierte das Hauptdarsteller-Quartett. Da der Film von der amerikanischen Gesellschaft Paramount produziert wurde und drei amerikanische Stars in den Hauptrollen zu sehen waren, kann dieser Film genau genommen kaum noch als Italo-Western bezeichnet werden. Allerdings waren alle kreativen Schlüsselpositionen (Drehbuch, Kamera, Ausstattung, Musik, Schnitt) mit Leones italienischem Team besetzt.

"Spiel mir das Lied vom Tod" zeigte Charles Bronson in der Rolle eines mundharmonikaspielenden Revolvermannes, der einen sadistischen Schurken (Henry Fonda) zur Strecke bringt, wurde zu einem riesigen Erfolg und ging als Klassiker und Kultfilm in die Filmgeschichte ein. In den USA lief der Film in einer stark gekürzten Fassung, durch die die künstlerische Vision Leones erheblich beeinträchtigt wurde, und fiel an den Kinokassen durch. (Auch mit seinen nächsten Filmen konnte sich Leone in den USA nicht mehr durchsetzen.)

Vor allem in Europa konnte der Regisseur mit "Spiel mir das Lied vom Tod" dagegen große Erfolge feiern, in Deutschland avancierte der Western mit 13 Millionen Zuschauern zu einem der erfolgreichsten Kinofilme und lief teils jahrelang in den Kinos. Ennio Morricone schrieb für "Spiel mir das Lied vom Tod" einen der wohl bekanntesten Soundtracks der Kinogeschichte.

Mit "Spiel mir das Lied vom Tod" hatte Sergio Leone seinen Karrierehöhepunkt erreicht. Bis zu seinem Tod im Jahr 1989 inszenierte er nur noch zwei Filme, die beide an den Kinokassen ohne große Resonanz blieben. Bei seinem Projekt "Todesmelodie" ("Giù La Testa"; Arbeitstitel des Drehbuchs war "Es war einmal … die Revolution") (1971) wollte Leone zunächst nur als Produzent im Hintergrund agieren; als Regisseur vorgesehen waren Peter Bogdanovich oder Sam Peckinpah. Nachdem die Regie schließlich von seinem ehemaligen Assistenten Gian Carlo Santi übernommen worden war, kam es bei den Dreharbeiten zu Differenzen mit den Darstellern, weshalb Leone selbst auf den Regiestuhl wechselte.

"Todesmelodie" stand in der Tradition zahlreicher „Revolutions-Western“, die in den späten 1960er Jahren entstanden waren. Rod Steiger (als mexikanischer Bandit) und James Coburn (als irischer Sprengstoffspezialist) führen hier einen Banküberfall durch und werden unfreiwillig zu Helden der mexikanischen Revolution. Verglichen mit den anderen Western Leones war dieser Film – der zweite Teil der sogenannten „Amerika-Trilogie“ – kommerziell nicht erfolgreich und geriet bald in Vergessenheit.

Nach "Todesmelodie" war Leone jahrelang nur noch als Filmproduzent tätig, so auch 1973 bei der Westernkomödie "Mein Name ist Nobody", bei dem er außerdem als Ideenlieferant und Co-Autor fungierte. Terence Hill in der Titelrolle des Nobody spielte hier eine ganz ähnliche Figur wie in seinen erfolgreichen Spaß-Western mit Bud Spencer – den sympathischen Abenteurer, der schneller zieht als andere. Ihm zur Seite stand Henry Fonda in der Rolle von Jack Beauregard, einem legendären Revolvermann fortgeschrittenen Alters, den der namenlose Nobody als Fan bewundert. Obwohl Leones früherer Regie-Assistent Toninio Valerii offiziell als Regisseur des Films angegeben war, wurden offenbar zahlreiche Szenen von Sergio Leone inszeniert. Als Soundtrack-Komponist fungierte wie immer Ennio Morricone, der mit der Titelmelodie eines seiner wohl bekanntesten Musikstücke schuf.

Ab 1972 bereitete Sergio Leone sein Gangster-Epos "Es war einmal in Amerika" vor, das auf Harry Greys Buch "The Hoods" basierte und den dritten Teil seiner Amerika-Trilogie darstellte. Nach aufwändigen Vorbereitungsarbeiten kam die fast vierstündige Gangster-Saga 1984 schließlich ins Kino. Der Film erzählt auf drei Zeitebenen (1922/1932/1968) das Leben des jüdischen Gangsters Noodles (Robert De Niro), der während der Prohibitionszeit an der Seite seines Freundes Max (James Woods) Karriere macht, diesen dann aber an die Polizei verrät. Das hochbudgetierte Epos (30 Millionen Dollar) fand mit seiner komplexen Erzählstruktur im Kino kein Publikum und wurde erfolglos umgeschnitten und gekürzt.

Der Film wurde von der Kritik allerdings rehabilitiert und gilt seit langem als einer der großen Klassiker der 1980er Jahre. Sergio Leone konnte jedoch nie die von ihm geplante Schnittfassung des Films erstellen. Unter Leitung von Martin Scorsese wurde der Film restauriert und 2012, bei den Filmfestspielen von Cannes, in einer um 25 Minuten verlängerten Fassung präsentiert.

Sergio Leone starb 1989 im Alter von 60 Jahren an einem Herzinfarkt, als er gerade an einem Film über die Belagerung Leningrads im Zweiten Weltkrieg arbeitete. Der stark übergewichtige Regisseur hatte bereits zuvor Herzinfarkte erlitten.

Noch heute beschreiben viele Regisseure Leone als ihr großes Idol. In einem Interview sagte James Woods, dass die Arbeit mit Sergio Leone der Höhepunkt seiner Filmkarriere gewesen sei. Quentin Tarantino ist bekennender Liebhaber seiner Filme und lässt auch viele für Sergio Leone typische Kameraeinstellungen in seine eigenen Filme einfließen. Clint Eastwood widmete Leone seinen Oscar für die beste Regie von "Erbarmungslos" ("Unforgiven", 1992), obwohl er einige Streitigkeiten mit ihm gehabt hatte.


<nowiki>*</nowiki> Produktionen unter fremder Regie, Teilsequenzen unter Regie Leones





</doc>
<doc id="4450" url="https://de.wikipedia.org/wiki?curid=4450" title="Systemtheorie">
Systemtheorie

Systemtheorie ist eine interdisziplinäre Betrachtungsweise, in der grundlegende Aspekte und Prinzipien von Systemen zur Beschreibung und Erklärung unterschiedlich komplexer Phänomene herangezogen werden.

So vielfältige Gegenstandsbereiche und Modelle wie das Sonnensystem, biologische Zellen, der Mensch, eine Familie, eine Organisation, ein Staat, aber auch Maschinen und Computernetzwerke können als Systeme aufgefasst und systemtheoretisch beschrieben werden. Kognitive Prozesse des Erkennens und Problemlösens, die auf Konzepte der Systemtheorie Bezug nehmen, werden oft unter dem Begriff Systemdenken zusammengefasst.

Die Analyse von Strukturen, Dynamiken und Funktionen soll eine umfassendere Sicht ermöglichen und realistischere Vorhersagen über das Systemverhalten erlauben. Systemtheoretische Begriffe werden in den verschiedensten wissenschaftlichen Disziplinen angewandt. „Die Systemtheorie hat von Anfang an das Ziel verfolgt, der Zersplitterung des Wissens in den wissenschaftlichen Disziplinen entgegenzuwirken.“

Die Systemtheorie ist sowohl eine allgemeine und eigenständige Disziplin als auch ein weitverzweigter und heterogener Rahmen für einen interdisziplinären Diskurs, der den Begriff "System" als Grundkonzept führt. Es gibt folglich sowohl eine allgemeine „Systemtheorie“ als auch eine Vielzahl unterschiedlicher, zum Teil widersprüchlicher und konkurrierender Systemdefinitionen und -begriffe. Es hat sich heute jedoch eine relativ stabile Reihe an Begriffen und Theoremen herausgebildet, auf die sich der systemtheoretische Diskurs bezieht.

Der Begriff "Allgemeine Systemtheorie" geht auf den Biologen Ludwig von Bertalanffy zurück. Seine Arbeiten bilden zusammen mit der Kybernetik (Norbert Wiener, W. Ross Ashby) die grundlegenden Überlegungen dieses Wissenschaftsansatzes. Weitere wichtige Theorien stammen von Humberto Maturana und Francisco Varela (Autopoiesis), Stuart Kauffman (Selbstorganisation) und Alfred Radcliffe-Brown (Strukturfunktionalismus) sowie Talcott Parsons (Strukturfunktionalismus oder Systemfunktionalismus) und Niklas Luhmann (soziologische Systemtheorie).

Kulturgeschichtlich geht der Systembegriff bis auf Johann Heinrich Lambert zurück und wurde unter anderem von Johann Gottfried Herder übernommen und ausgearbeitet. Dies vollzieht sich vor allem an der Frage, wie man lebende Organismen und deren Selbsterhaltung und -organisation verstehen kann.

Die moderne Systemtheorie beruht auf unabhängig voneinander entwickelten Ansätzen, die später synthetisiert und erweitert wurden: Der Begriff Systemtheorie bzw. Systemlehre stammt von Ludwig von Bertalanffy (vgl. '). Von Bertalanffy spricht von offenen Systemen und entwickelt den Begriff der organisierten Komplexität, der den dynamischen Austausch mit der Umwelt beschreiben soll. Erst mit der Ausformulierung des Informations­begriffes ließ sich dieses Konzept jedoch weiter generalisieren. Bereits 1948 hatte Norbert Wiener mit ' (Kybernetik) einen ebenfalls zentralen Ausdruck geprägt, der heute mit dem Systembegriff eng verbunden ist. Ein weiteres verwandtes Konzept ist die Tektologie Alexander Bogdanows.

Die Kybernetik behandelt operationell geschlossene Mechanismen. Sie wurde als Regelungs- und Kommunikationstheorie konzipiert. Der Fokus der Kybernetik liegt auf Regelung und Steuerung. Deshalb kommen in der Kybernetik als Systeme in erster Linie geregelte Mechanismen in Betracht. Die Regelung beruht immer auf Prozessen, die mit der mathematischen Systemtheorie der Technik beschrieben werden können. Bertalanffy hat sich gegen die Vermischung seiner Systemlehre und der Kybernetik ausgesprochen, weil er das mechanistische Denken der Kybernetik für die Beschreibung von Leben als nicht adäquat erachtete.

Als Systemtheorie 2. Ordnung bezeichnet man Systemtheorien, die in folgendem Sinne selbstbezüglich sind: Mit der jeweiligen Systemtheorie wird der Systemtheoretiker, der die Theorie macht, beschrieben. Der Kernbegriff ist deshalb „die Beobachtung des Beobachters“.

Als Autopoiesis bezeichnet Humberto Maturana sowohl seine Systemtheorie wie auch den wesentlichen Prozess, den er mit seiner Theorie beschreibt, nämlich das Leben. Maturana beschreibt, grob gesehen, das Gleiche wie von Bertalanffy in seiner Systemlehre, er argumentiert aber kybernetisch: er spricht von lebenden (autopoietischen) Maschinen, die operationell geschlossen sind.

Als Selbstorganisation bezeichnet man Prozesse, die wie die Autopoiese zu höheren strukturellen Ordnungen führen, ohne dass ein steuerndes Element erkennbar ist. Ein Beispiel ist der Laserstrahl, anhand dessen die Theorie von Hermann Haken auch entwickelt wurde.

Der Radikale Konstruktivismus wurde von Ernst von Glasersfeld entwickelt. Er hat dabei auf die Arbeiten von Jean Piaget zurückgegriffen. Die Denkweise von Piaget war konstruktivistisch und epistemologisch. Ernst von Glasersfeld argumentiert insbesondere auch mit der operationellen Geschlossenheit von Systemen.

Als ' bezeichnet man die Modellierung mit Regelkreisen. Bekannt gemacht hat das Verfahren Jay Wright Forrester durch das Weltmodell World3, anhand dessen in der -Publikation ' ("Die Grenzen des Wachstums", Dennis L. Meadows 1972) der globale Rohstoffverbrauch prognostiziert wurde.

Die soziologische Systemtheorie versteht sich als eine Universaltheorie im Sinne eines umfassenden und kohärenten Theoriegebäudes für alle Formen von Sozialität. Der soziologische Systembegriff geht auf Talcott Parsons zurück. Parsons betrachtet dabei Handlungen als konstitutive Elemente sozialer Systeme. Er prägte den Begriff der strukturell-funktionalen Systemtheorie.

Niklas Luhmann erweitert die Theorie Parsons und verwendet nicht mehr den Handlungsbegriff, sondern den sehr viel allgemeineren Begriff der Operation – siehe Systemtheorie (Luhmann).

Die neueste Strömung ist die Theorie komplexer Systeme. Ein komplexes System ist dabei ein System, dessen Eigenschaften sich nicht vollständig aus den Eigenschaften der Komponenten des Systems erklären lassen. Komplexe Systeme bestehen aus einer Vielzahl von miteinander verbundenen und interagierenden Teilen, Entitäten oder Agenten.

Komplexe Systeme sind von der Welt der Elementarteilchen bis hinauf zur menschlichen Gesellschaft weit verbreitet, ja geradezu dominant. Sie entstehen überwiegend durch Prozesse der spontanen Selbstorganisation und sind meist einer Theorie auf der Basis bekannter mathematischer Funktionen nicht zugänglich. Beispiele sind die Bildung der Atomkerne, der Atome, die Umwandlung von Stoffen von einem Aggregatzustand in einen anderen, die Kristallisation, chemische Reaktionen, die Evolution, die geistigen Prozesse im Gehirn, die Entwicklung der Sozialsysteme usw. In der belebten Natur sind offene Systeme dominant, die die Zufuhr von Energie benötigen, in der unbelebten Natur bilden sich komplexe Systeme meist spontan unter Abgabe von Energie oder auch im thermischen Gleichgewicht.

Die Theorie der Komplexen adaptiven Systeme beruht vorwiegend auf den Arbeiten des Santa Fe Institute. Diese neue Komplexitätstheorie, die Emergenz, Anpassung und Selbstorganisation beschreibt, basiert auf Agenten und Computersimulationen, die Multiagentensysteme (MAS) einschließen, die zu einem wichtigen Instrument bei der Erforschung von sozialen und komplexen Systemen wurden.

Diese vier Hauptrichtungen haben Vorläufer, Unterabteilungen, Entwicklungen, Anwendungen in den Fachdisziplinen.

Die Chaosforschung beschäftigt sich mit bestimmten nichtlinearen dynamischen Systemen, die eine Reihe von Phänomenen aufweisen, die man Chaos (genauer: "chaotisches Verhalten") nennt. Eines dieser Phänomene ist der Schmetterlingseffekt, der beinhaltet, dass beliebig kleine Änderungen unvorhersehbar große Effekte haben können. Chaotische Systeme sind zum Beispiel Wetter, Klima, Plattentektonik, turbulente Strömungen, Wirtschaftskreisläufe, Internet und das Bevölkerungswachstum.

Die Katastrophentheorie ist ein Zweig der Mathematik, der sich mit den Verzweigungen von dynamischen Systemen beschäftigt und beschreibt plötzliche Veränderungen, die sich aus kleinen Veränderungen von Umständen ergeben.

Der Konnektionismus versteht ein System als Wechselwirkungen vieler vernetzter einfacher Einheiten. Die meisten konnektionistischen Modelle beschreiben die Informationsverarbeitung in Neuronen­netzen. Sie bilden eine Brücke zwischen biologischer Forschung und technischer Anwendung.

Um Systeme in Modellen beschreiben zu können, spielen Bereiche aus Mathematik und Informatik eine Rolle. Wenn ein System quantitativ beschrieben werden kann und weitere Voraussetzungen erfüllt sind (insbesondere die Differenzierbarkeit der beschreibenden Funktionen), dann werden häufig Differentialgleichungs­systeme für die mathematische Modellierung herangezogen. Fehlen diese Voraussetzungen, dann muss die Beschreibung auf einer abstrakteren Ebene erfolgen. Für eine formale Beschreibung mit begrifflichen Mitteln dient in der Mathematik die formale Begriffsanalyse, ein Teilgebiet der Ordnungstheorie. Auf Seite der Informatik beschäftigt sich die Ontologie damit, Systeme formal mit begrifflichen Mitteln zu beschreiben. Grundlagen dazu liegen auch in der philosophischen Ontologie.








</doc>
<doc id="4451" url="https://de.wikipedia.org/wiki?curid=4451" title="Soziologische Systemtheorie">
Soziologische Systemtheorie

Als soziologische Systemtheorie wird eine auf systemtheoretischen Diskursen und Begriffen basierende Theorie der Sozialität als Teil einer allgemeinen Soziologie bezeichnet. Die soziologische Systemtheorie hat dabei den Anspruch, eine Universaltheorie im Sinne eines umfassenden und kohärenten Theoriegebäudes für alle Formen von Sozialität (z. B. Zweierbeziehungen, Familien, Organisationen, Funktionssysteme, Gesellschaft) zu sein. Damit umfasst sie auch sich selbst als Gegenstand ihrer Theorie, operiert also selbstbezüglich (selbstreferentiell).

Als wichtigste Vertreter gelten Talcott Parsons (strukturfunktionalistische Theorie des Handlungssystems) und Niklas Luhmann (funktionalstrukturalistische Theorie sozialer Kommunikationssysteme, siehe Systemtheorie (Luhmann)).

Die Ursprünge der Systemtheorie liegen in den USA. 1954 wurde die Society for General Systems Research (heute: International Society for the Systems Sciences) gegründet, in deren Jahrbuch "General Systems" die ersten grundlegenden Arbeiten zu einer Allgemeinen Systemtheorie publiziert wurden. Es gab zwei Hauptströmungen: den Struktur- oder Bestandsfunktionalismus und die Theorie Parsons, für die sich die Bezeichnung Systemfunktionalismus nicht durchgesetzt hat. Parsons wird häufig unter Strukturfunktionalismus subsumiert, was er jedoch selbst (wie auch sein Student Niklas Luhmann) zurückweist. Tatsächlich unterscheidet sich seine Theorie auch fundamental vom Strukturfunktionalismus.

Ausgehend von ethnologischen und anthropologischen Fragestellungen untersuchte der Strukturfunktionalismus (Alfred R. Radcliffe-Brown, Bronisław Malinowski,
Edward E. Evans-Pritchard) die Frage, wie Strukturen das Verhalten von Individuen innerhalb einer Gesellschaft determinieren. Dabei wurden alle gesellschaftlichen Strukturen auf ihre Funktion hin befragt. Als Struktur wird dabei die Gesamtheit der sozialen Beziehungen und Interaktionen im sozialen Netzwerk einer Gesellschaft verstanden. Diese Strukturen einer Gesellschaft werden als äußerst stabil und als nur durch externe Faktoren wandelbar angesehen. In diesem Sinne suchte der Strukturfunktionalismus nach den Bestandsvoraussetzungen sozialer Systeme und gesellschaftlicher Strukturen. Die Ergebnisse waren im Wesentlichen Listen mit Bestandsvoraussetzungen und Variablen. Die Limitierung auf segmentäre Gesellschaften, wie etwa Stämme, wurde damit begründet, dass man einen isolierbaren begrenzbaren Forschungsgegenstand brauchte, um überhaupt Aussagen treffen zu können.

Der soziologische Systembegriff geht auf Talcott Parsons zurück. Die von Parsons entwickelte Systemtheorie "will die Gemeinschaft als Zusammenhang ('System') begreifen, nämlich als zwischenmenschliches Verhaltensgefüge ('Struktur'), dessen Teile in wechselseitiger Abhängigkeit ('Interdependenz') zueinander stehen. Ein solches Verhaltenssystem bildet sich dadurch, daß Menschen ihre Handlungen nach bestimmten Verhaltenserwartungen ... aufeinander einstellen. An den mehr oder minder stabilen Verhaltensgefügen sind die Einzelnen in bestimmten 'Rollen' beteiligt". Aus dieser Sicht hat die normative, insbesondere die rechtliche Lenkbarkeit des Verhaltens eine zentrale Funktion für die Bildung einer Gemeinschaft. 
Parsons betrachtet dabei Handlungen als konstitutive Elemente sozialer Systeme. Er prägte den Begriff der strukturell-funktionalen Systemtheorie. Der Begriff "Struktur" bezieht sich dabei auf diejenigen Systemelemente, die von kurzfristigen Schwankungen im System-Umwelt-Verhältnis unabhängig sind. "Funktion" dagegen bezeichnet den dynamischen Aspekt eines sozialen Systems, also diejenigen sozialen Prozesse, die die Stabilität der Systemstrukturen in einer sich ändernden Umwelt gewährleisten sollen. Die strukturell-funktionale Theorie beschreibt also den Rahmen, der Handlungsprozesse steuert. Ist die Struktur eines Systems bekannt, kann in funktionalen Analysen angegeben werden, welche Handlungen für die Systemstabilisierung funktional oder dysfunktional sind. Handlungen werden also nicht isoliert betrachtet, sondern im Kontext der strukturellen und funktionalen Aspekte des jeweiligen Sozialsystems.

Zur strukturellen und funktionalen Analyse sozialer Systeme entwickelte Parsons das AGIL-Schema, das die "für die Strukturerhaltung notwendigen Funktionen" systematisiert. Demnach müssen alle Systeme vier elementare Funktionen erfüllen:

Einzelne Handlungen werden also nicht isoliert, sondern im Rahmen eines strukturellen und funktionalen Systemzusammenhanges betrachtet. Handlungen sind dabei Resultate eben jenes Systemzusammenhanges, der durch diese Handlungen gestiftet wird (handlungstheoretische Systemtheorie). Parsons beschreibt den Zusammenhang zwischen System und Systemelementen also als rekursiv und berücksichtigt damit wechselseitige Ermöglichungs-, Verstärkungs- und Rückkopplungsbedingungen.

Niklas Luhmann erweitert die Theorie Parsons und verwendet nicht mehr den Handlungsbegriff, sondern den sehr viel allgemeineren Begriff der "Operation". Systeme entstehen, wenn Operationen aneinander anschließen. Die Operation, in der soziale Systeme entstehen, ist Kommunikation. Wenn eine Kommunikation an eine Kommunikation anschließt (sich auf diese zurückbezieht und sie zugleich weiter führt), entsteht ein sich selbst beobachtendes soziales System. Kommunikation wird durch Sprache und durch symbolisch generalisierte Kommunikationsmedien (Geld, Wahrheit, Macht, Liebe) wahrscheinlich gemacht.

Die Besonderheit in der Sichtweise Luhmanns besteht darin, dass Kommunikation – als die Operation sozialer Systeme – nicht als Handeln gesehen wird, das durch einzelne Menschen vollzogen wird. Im Besonderen geht es nicht um Einwirkungen von Mensch zu Mensch, die ein Beobachter als Kausalität (Monokausalität, Multikausalität oder Kausalkette) feststellen kann. Ebenso wenig geht es um Informationsübertragung, die als Metapher aufgefasst werden kann. Der Begriff "Kommunikation" beschreibt eine Operation, in der "soziale Systeme" entstehen. Kommunikation kann nur an Kommunikation anschließen, und auf diese Weise verlaufen diese Operationen simultan und parallel zu den Operationen anderer Systeme (z. B. den Gedanken als Operationen psychischer Systeme, synonym Bewusstseinssysteme). Auch Personen bestehen nicht als Handelnde, sondern als von der Kommunikation konstruierte Einheiten („Identifikationspunkte“).

Luhmann unterscheidet drei Typen sozialer Systeme:


Gesellschaft ist das umfassende System, das sich in Funktionssysteme ausdifferenziert. Auf diese Weise entstehen unter anderem das Recht, die Wirtschaft, die Wissenschaft, die Politik, die Religion als funktional ausdifferenzierte Systeme. Diese Systeme – nicht die Menschen – beobachten unter Verwendung spezifischer Unterscheidungen (Recht/Unrecht im Rechtssystem, wahr/falsch im Wissenschaftssystem, Allokation/Nichtallokation im Wirtschaftssystem, Immanenz/Transzendenz im Religionssystem oder Regierung/Opposition im politischen System). Diese Unterscheidungen oder Codes bilden den Rahmen, innerhalb dessen das Teilsystem Formen ausbilden kann. Der Code sorgt für die operative Schließung des Systems. Für die Offenheit des Systems sorgen Programme, nach denen für die eine oder andere Seite einer Entscheidung optiert wird. Als Beispiel für ein Systemprogramm können etwa Theorien in der Wissenschaft genannt werden, die über eine Zuordnung zu einer der beiden Seiten wahr/falsch entscheiden.







</doc>
<doc id="4453" url="https://de.wikipedia.org/wiki?curid=4453" title="Systemdenken (Systemtheorie)">
Systemdenken (Systemtheorie)

Systemdenken in der Systemtheorie fasst die typischen Sichtweisen eines Systemikers zusammen: 

Klassische und fachliche Sichtweisen können als Mittel zur Reduktion von Komplexität in größeren Systemen angesehen werden; dazu gehören: einfache Mechanik, einfache Regeln, lineares und kategorisches Denken
(die durchaus für Teillösungen in sehr kleinen Bereichen verwendet und ggf. auch auf andere Systeme übertragen werden). In vielen Fällen ist jedoch eine vielgestaltigere, dynamischere Sichtweise angebracht, ohne dabei jedoch Effektivitätsprinzipien zu vernachlässigen. 




</doc>
<doc id="4458" url="https://de.wikipedia.org/wiki?curid=4458" title="Gakuryū Ishii">
Gakuryū Ishii

Gakuryū Ishii (; * 15. Januar 1957 in Präfektur Fukuoka) bis 2012 Sōgo Ishii () ist ein japanischer Filmregisseur. Im Vor- und Abspann wird er manchmal als "Sohgo Ishii" oder "Toshihiro Ishii" aufgelistet.

Ishii gilt stilistisch als Außenseiter im japanischen Film, der in seinen Filmen zahlreiche Genres miteinander vermischt und bewusst mit Konventionen bricht. Er gilt als einer der bedeutendsten japanischen Filmregisseure der Gegenwart.

1986 drehte er mit den Einstürzenden Neubauten den Kurzfilm "½ Mensch". Typische Stilmittel Ishiis sind Kameraführungen à la Shinya Tsukamoto (sehr experimentelle hektische Kameraführung und schnelle Schnitte).

Durch sein großes Interesse an Musik widmet sich Ishii nicht nur der Spielfilmkunst, sondern hat auch schon für viele Punkrock-Bands wie The Stalin, Isseifubi Sepiia oder The Roosterz Videoclips gedreht.




</doc>
<doc id="4459" url="https://de.wikipedia.org/wiki?curid=4459" title="Steven Spielberg">
Steven Spielberg

Steven Allan Spielberg, KBE (* 18. Dezember 1946 in Cincinnati, Ohio) ist ein US-amerikanischer Filmregisseur, Filmproduzent, Drehbuchautor und Schauspieler. Gemessen am Einspielergebnis seiner Filme ist er der bis heute erfolgreichste Regisseur und der zweiterfolgreichste Produzent (nach Kevin Feige).

Zu seinen bekanntesten Filmen, die oft von Träumen, Ängsten und Abenteuern geprägt sind, gehören unter anderem "Der weiße Hai" (1975), "E.T. – Der Außerirdische" (1982), "Jurassic Park" (1993), "Schindlers Liste" (1993), "Der Soldat James Ryan" (1998), "Minority Report" (2002), "Lincoln" (2012) und die vierteilige "Indiana-Jones"-Reihe (1981–2008).

Spielberg wurde bereits fünfzehnmal für den Oscar nominiert (u. a. "Jäger des verlorenen Schatzes", "München", "Lincoln") und konnte ihn davon dreimal gewinnen, zweimal (Film, Regie) 1994 für "Schindlers Liste" und 1999 für seine Regiearbeit an "Der Soldat James Ryan". Er ist mehrfacher Golden-Globe- und Emmypreisträger.

Steven Allan Spielberg wurde als Kind jüdischer Eltern in Cincinnati, Ohio, geboren. Sein Vater ist der Elektroingenieur Arnold Spielberg, seine Mutter war Leah Posner (1920–2017), die bis zu ihrer Heirat 1945 als Konzertpianistin tätig war. Er hat drei jüngere Schwestern: Anne (* 1949), Susan (1953) und Nancy (1956).

Seine Kindheit verbrachte er in Haddonfield, New Jersey, dann ab 1957 in Phoenix, Arizona. Spielberg wuchs wohlbehütet auf, war ein durchschnittlicher Schüler und in sozialer Hinsicht eher ein Einzelgänger, da er auf Grund seiner Dyslexie in der Schule häufig gehänselt wurde. Durch sein Talent beim Fotografieren brachte er es aber zu einer Verdienstmedaille bei den Pfadfindern. Schon als Zehnjähriger filmte Spielberg mit einer 8-mm-Kamera, die er von seinem Vater bekam, da er die Qualität der Familienfilme kritisiert hatte. Sein Vater ermöglichte es als Kriegsveteran, dass sein Sohn unter anderem mit ausrangierten Militärflugzeugen drehen konnte. Schon damals interessierte er sich sehr für den Zweiten Weltkrieg, auch weil sein Vater Offizier und Pilot der United States Air Force war.

Einer seiner ersten Aufnahmen ist der Film über die Kollision zweier Züge. Mit dreizehn Jahren gewann er mit dem 40-minütigen Kriegsfilm "Escape to nowhere" (1960) einen Filmwettbewerb. 1963 folgte sein 140 Minuten langer Abenteuerfilm "Firelight".

Das Filmmaterial für seine erste Produktion, einen 8-mm-Western von vier Minuten, verdiente er mit dem Kalken der Zitruspflanzen in der Nachbarschaft. Das Haus in "E.T." ist laut eigener Aussage eine ziemlich genaue Rekonstruktion des Hauses, in dem er als Kind wohnte. Ebenso war E.T. ein Teil seiner Kindheit, ein Traum in seiner Jugend und sein imaginärer Freund an problemvollen Tagen wie z. B. der Scheidung seiner Eltern. Dadurch ist auch heute für Spielberg die Bedrohung der Familie und ihrer Werte eine immer vorhandene Problematik in seinen Filmen. Genauso seien Horror-Szenen aus "Poltergeist" durchaus autobiographisch zu verstehen. In Arizona hatte man damals meist sternenklare Nächte und als Kind (und auch bis heute) begeisterte er sich für Astronomie und UFOs. Für "Firelight" von 1964 mietete sein Vater einen Kinosaal in Scottsdale. Nach Produktionskosten von 500 Dollar erzielte er damit 600 Dollar Einnahmen. Danach zog die Familie nach Kalifornien, wo die Eltern sich bald scheiden ließen.
Spielberg bewarb sich zweimal an der University of Southern California um ein Filmstudium, wurde aber beide Male abgelehnt. Schließlich begann er ein Studium der englischen Literatur an der California State University, Long Beach. Das Studium konnte er aufgrund seiner Filmkarriere erst im Jahr 2002 abschließen. 1969 wurde Spielbergs 35-mm-Kurzfilm "Amblin’" zu seiner Eintrittskarte nach Hollywood, als der Streifen auf dem Atlanta Film Festival gezeigt wurde. Der erst 22-Jährige erhielt einen Siebenjahresvertrag in der Fernsehabteilung von Universal Pictures, bei der er vier Jahre lang hauptsächlich Fernsehfilme und Serien drehte. Gleich als erstes drehte er eine Episode für Rod Serlings "Night Gallery" mit Joan Crawford. Danach inszenierte er einzelne Serienfolgen, beispielsweise für "Dr. med Marcus Welby" oder "Columbo". Aufsehen erregte er mit dem Fernsehfilm "Duell", welcher in Europa in den Kinofilmverleih kam. Mit seinem ersten Spielfilm "The Sugarland Express" hatte er zwar einen finanziellen Misserfolg und sein (nicht erfolgreiches) Kinodebüt, jedoch hat er von vielen Kritikern sehr gute Noten bekommen. Bereits im Alter von 27 Jahren begeisterte er mit seinem ersten Kinofilm die internationalen Kritiker, die ihn schon bald als Wunderkind bezeichneten. Schon sein zweiter Kinofilm "Der weiße Hai" wurde 1975 ein großer kommerzieller Erfolg und zum bis dato gewinnträchtigsten Film aller Zeiten, trotz vieler Schwierigkeiten wie dem Wetter oder problematischer Filmtechnik. Erst nach einigen Jahren gilt der "Der weiße Hai" als der erste moderne Blockbuster in der Filmgeschichte. Finanziell wurde er erst zwei Jahre nach dem Release von "Der weiße Hai" mit George Lucas Film "Krieg der Sterne" übertroffen. Es folgten dutzende Kinohits, so zum Beispiel die "Unheimliche Begegnung der dritten Art" oder die "Indiana-Jones"-Tetralogie, bei welchem er zusammen mit George Lucas die Figur Indiana Jones entwickelt hat und durch ihre gemeinsamen Faszination das Genre des Films noch mehr belebt wurde. Seinen eigenen Rekord brach er dann 1982 mit "E. T. – Der Außerirdische", der ein noch höheres Einspielergebnis erzielte und elf Jahre lang der umsatzstärkste Film der Kinogeschichte war. Sein Film "Poltergeist" aus dem Jahr 1982 und die Fernsehreihe "Twilight Zone" aus dem Jahr 1983 ergänzten sein vorhandenes Image als Disney-Erbe. Die Filmindustrie hielt Steven Spielberg nach einigen fatalen Fehlschlägen und wenig Erfolg wie z. B. durch "1941 – Wo bitte geht’s nach Hollywood" (1979), "Always" (1989) und Peter Pans Sequel "Hook" (1991) für ausgedient. In den späten 80er Jahren war Spielberg überwiegend als Produzent tätig und wandte sich gleichzeitig vermehrt der Produktion von Fernsehsendungen zu. Spielbergs erfolgreichstes Jahr kam allerdings 1993: In diesem Jahr wurden sowohl der Blockbuster und zugleich sein Comeback "Jurassic Park" als auch "Schindlers Liste" veröffentlicht. Während "Jurassic Park" erneut zahlreiche Box-Office Rekorde brach und mit 920 Mio. eingespielten Dollar über fünf Jahre lang als erfolgreichster Film der Welt galt, war "Schindlers Liste" auch ein Kritikererfolg. In diesem Film setzt sich Spielberg erstmals offen mit seiner jüdischen Identität und der Judenverfolgung in Europa auseinander und konnte diesen mit einfachen Dreharbeiten, keinerlei Kranfahrten und der Benutzung von Handkameras erfolgreich inszenieren. Seine Eltern, Arnold Spielberg und Leah Posner, sind Nachfahren jüdischer Flüchtlinge, die aus Furcht vor russischen Pogromen nach Amerika auswanderten. Diese Geschichte verarbeitete er zudem verschlüsselt in dem von ihm produzierten Zeichentrickfilm "Feivel, der Mauswanderer". Anfang 1994 wurde "Schindlers Liste" mit sieben Oscars ausgezeichnet, unter anderem in den Kategorien Regie und Bester Film, die beide an Spielberg gingen. Sein Image als großer kleiner Junge und Märchenonkel, das ihm seit "E.T." anhing, konnte er damit endgültig abstreifen. Die meiste Zeit seiner bisherigen Filmkarriere verbrachte Spielberg mit handwerklich begabten und technisch brillanten Unterhaltungsfilmen.
Anfang 2007 begann Spielberg seine Arbeit an "Die Abenteuer von Tim und Struppi", einer 3D-Adaption (als Trilogie geplant). Spielberg arbeitete dabei erstmals mit Peter Jackson zusammen. Der erste Teil wurde von Spielberg inszeniert und von Jackson produziert, beim zweiten soll Jackson Regie führen.

2013 leitete er die Wettbewerbsjury der 66. Internationalen Filmfestspiele von Cannes

Steven Spielberg kündigte 2016 an, das Leben von Lynsey Addario mit Jennifer Lawrence in der Hauptrolle verfilmen zu wollen.

Spielberg heiratete 1985 die Schauspielerin Amy Irving, mit der er einen gemeinsamen Sohn hat. Nach der Scheidung heiratete er 1991 die Schauspielerin Kate Capshaw, die er bei den Dreharbeiten zu "Indiana Jones und der Tempel des Todes" kennen gelernt hatte. Das Paar hat drei leibliche und zwei adoptierte Kinder. Kate Capshaw brachte ihre Tochter Jessica Capshaw mit in die Ehe. Seine Patenkinder sind Drew Barrymore und Gwyneth Paltrow. Zusammen mit Kate Capshaw und den fünf Kindern lebt er in Hollywood.

Zu seinem beruflichen Freundeskreis zählen beziehungsweise zählten Regisseure wie George Lucas, Robert Zemeckis, Barbra Streisand, Richard Attenborough, Chris Columbus, Peter Jackson und Barry Levinson sowie die Schauspieler Tom Hanks und Tom Cruise und der Komponist John Williams.

Laut Forbes hat Spielberg ein Vermögen von 3,4 Milliarden US-Dollar.

Seine eigene Filmproduktionsfirma Amblin Entertainment, die er nach seinem Kurzfilm "Amblin" benannte, entstand 1982 noch auf dem Gelände der "Universal Studios". 1994 gründete er mit seinen Freunden Jeffrey Katzenberg und David Geffen das unabhängige Filmstudio DreamWorks SKG, das allerdings 2005 wegen finanzieller Probleme an Paramount Pictures verkauft wurde.

Im Oktober 2005 wurde bekannt, dass er mit Electronic Arts einen Exklusiv-Vertrag über die Entwicklung dreier Computerspiele geschlossen hat.

Eine enge Freundschaft verbindet Steven Spielberg seit 1974 mit dem amerikanischen Filmmusikkomponisten John Williams. Spielberg betont immer wieder, dass Williams der größte musikalische Geschichtenerzähler überhaupt sei. Aus der Zusammenarbeit zwischen Spielberg und Williams entstanden bislang 26 Werke, deren erstes der Film „Sugarland Express“ war. Mit Ausnahme von "Die Farbe Lila" (1985) hat Williams bis zum Jahr 2012 für alle unter der Regie von Spielberg entstandenen Filme die Musik komponiert. Im Jahr 2015 arbeitet Spielberg, aufgrund gesundheitlicher Probleme von Williams, erstmals wieder mit einem anderen Komponisten zusammen: Thomas Newman schrieb die Musik für "Bridge of Spies – Der Unterhändler".

Spielbergs Entwicklung ist vor allem von Filmemachern wie Stanley Kubrick, Walt Disney, Alfred Hitchcock, John Ford, Frank Capra, David Lean, Orson Welles und Akira Kurosawa beeinflusst; zu vielen von ihnen hatte er persönlichen Kontakt. Aber auch seine Begeisterung für Zeichentrickfilme, Comics, Bilder von Norman Rockwell und besonders das Fernsehen haben in seinen Arbeiten sichtbare Spuren hinterlassen. Vor jedem neuen Filmdreh schaut sich Spielberg nach eigenen Angaben immer die Filme "Die sieben Samurai", "Lawrence von Arabien", "Ist das Leben nicht schön?" und "Der schwarze Falke" an.

Als Fan der Fernsehserie "Twilight Zone" produzierte er einen Kinofilm zur Serie. Als bekennender Trekkie teilt Spielberg die völkerverbindende Sicht der Fernsehserie "Raumschiff Enterprise" und spielte in seinen Filmen darauf an, zuletzt mit dem Vulkanier-Gruß zwischen einer Afroamerikanerin und einem Latino in "Terminal" oder von Marty McFly (gespielt von Michael J. Fox) in "Zurück in die Zukunft".
Zu den typischen Markenzeichen von Spielberg-Filmen gehört hauptsächlich die Befriedigung der Interessen und Wünsche des Massenpublikums sowie präzise Beobachtung von Alltagssituationen, Konfrontation amerikanischer Durchschnittstypen mit höchst außergewöhnlichen Ereignissen, eine einerseits kindlich naive, andererseits ernsthaft humanistische Botschaft der Versöhnung, eindrucksvolle Licht- und Spezialeffekte wie Feuerwerke, die in Filmen wie "Unheimliche Begegnung der dritten Art" und "1941 – Wo bitte geht’s nach Hollywood" zu sehen sind. Viele ungewohnte Perspektiven, ein zumeist durchchoreographiertes Verhältnis zwischen Kameraführung und Schauspielern sowie eine Inszenierung, die intensiv an die Gefühle der Zuschauer appelliert (Suspense, Lachen, Gruseln, auch Ekel und Weinen), sind weitere spezifische Merkmale Spielbergs. Die meisten seiner Filme sind durch seine technische Vorliebe, sehr gute Beherrschung des filmischen Handwerks und viel Bewegung (Stunts) geprägt. Dadurch fällt es ihm mit seiner Imagination leicht, das Publikum zu manipulieren und die Zuschauer in die Actionszenen hineinzuziehen. Das Verknüpfen von Angst und Staunen wie bei "E.T." durch Auftreten des Mutterschiffes und bei "Jurassic Park" durch Auftreten der Dinosaurier, soll den Zuschauer ständig in Spannung halten. Bei Spielberg sind in vielen Filmen, besonders den Kriegsfilmen, melodramatische Effekte zu entdecken, die oft durch starkes Gegenlicht, Rauch und Nachtszenen zum Vorschein kommen. Auffallend ist auch, dass in seinen Filmen Kinder selten sterben und häufig im Zentrum der Handlung stehen – und zwar in Genres, in denen dies zuvor untypisch war: Kriegsfilm (Das Reich der Sonne), Science-Fiction ("E.T.", "Jurassic Park") und Utopie "(A.I. – Künstliche Intelligenz)". Ein weiteres Merkmal von Spielberg ist, dass er der Weiterentwicklung seiner Filmfiguren keinen großen Raum lässt und eher an technischen Film- und Hilfsmitteln interessiert ist. Bis heute bleibt Spielberg seinem Prinzip treu, im Wechsel sowohl anspruchsvolle als auch hauptsächlich unterhaltende Filme zu drehen: Im Juni 2005 kam die Neuverfilmung von "Krieg der Welten" in die Kinos; "München" (2005) ist ein Film über den umstrittenen Rachefeldzug des israelischen Geheimdienstes Mossad nach dem palästinensischen Angriff auf die Olympischen Sommerspiele 1972, bei dem elf israelische Sportler getötet wurden. Seit vielen Jahren arbeitet er mit der Produzentin Kathleen Kennedy, dem Filmkomponisten John Williams und dem Filmeditor Michael Kahn zusammen. Seit "Schindlers Liste" ist Janusz Kamiński sein fester Kameramann.

1994 entstand auf Spielbergs Initiative die Survivors of the Shoah Visual History Foundation – eine gemeinnützige Organisation, die Aussagen von Überlebenden der Shoah für Bildungszwecke archiviert. Dafür wurde er am 10. September 1998 mit dem Großen Bundesverdienstorden mit Stern der Bundesrepublik Deutschland ausgezeichnet.

Spielberg fördert durch persönliches und finanzielles Engagement den Nachwuchs in Hollywood, zum Beispiel an den Universitäten, die ihn damals abgelehnt hatten. Ein erneuter Generationswechsel kündigt sich an, und so sind es u. a. Spielberg-Filme, die nun Jungtalente der MTV-Generation dazu bringen, Regisseur werden zu wollen.

Ein weiteres seiner vielen Stiftungsprojekte ist die "Starbright Foundation", die schwer kranken Kindern hilft. Auch im Wahlkampf um die US-Präsidentschaft machte Spielberg seinen inzwischen erheblichen gesellschaftspolitischen Einfluss geltend – durch aktive Unterstützung demokratischer Kandidaten wie John Kerry und zuvor Bill Clinton.

Auf Antrag von Kindern erhielt er die internationale Auszeichnung als Ritter des Ordens des Lächelns.

Im November 2015 wurde ihm von Präsident Barack Obama die Presidential Medal of Freedom verliehen.

Der Asteroid (25930) Spielberg wurde nach ihm benannt.
2005 wurde er in die Science Fiction Hall of Fame aufgenommen.

Im Jahr 2001 wurde Spielberg von Queen Elizabeth zum Knight Commander (ehrenhalber) des Order of the British Empire ernannt.

Da er kein Untertan der britischen Königin ist, wurde er allerdings nicht zum Ritter geschlagen und darf seinem Namen kein "Sir" voranstellen (wohl aber die Abkürzung "KBE" hinter seinem Namen anfügen).




</doc>
<doc id="4464" url="https://de.wikipedia.org/wiki?curid=4464" title="Liste der Biografien/C">
Liste der Biografien/C

__NOEDITSECTION__


</doc>
<doc id="4465" url="https://de.wikipedia.org/wiki?curid=4465" title="Liste der Biografien/D">
Liste der Biografien/D

__NOEDITSECTION__



</doc>
<doc id="4466" url="https://de.wikipedia.org/wiki?curid=4466" title="Liste der Biografien/E">
Liste der Biografien/E

__NOEDITSECTION__



</doc>
<doc id="4467" url="https://de.wikipedia.org/wiki?curid=4467" title="Liste der Biografien/F">
Liste der Biografien/F

__NOEDITSECTION__



</doc>
<doc id="4468" url="https://de.wikipedia.org/wiki?curid=4468" title="Liste der Biografien/G">
Liste der Biografien/G

__NOEDITSECTION__



</doc>
<doc id="4469" url="https://de.wikipedia.org/wiki?curid=4469" title="Liste der Biografien/H">
Liste der Biografien/H

__NOEDITSECTION__



</doc>
<doc id="4470" url="https://de.wikipedia.org/wiki?curid=4470" title="Liste der Biografien/I">
Liste der Biografien/I

__NOEDITSECTION__



</doc>
<doc id="4471" url="https://de.wikipedia.org/wiki?curid=4471" title="Liste der Biografien/J">
Liste der Biografien/J

__NOEDITSECTION__



</doc>
<doc id="4472" url="https://de.wikipedia.org/wiki?curid=4472" title="Liste der Biografien/K">
Liste der Biografien/K

__NOEDITSECTION__



</doc>
<doc id="4473" url="https://de.wikipedia.org/wiki?curid=4473" title="Liste der Biografien/L">
Liste der Biografien/L

__NOEDITSECTION__



</doc>
<doc id="4474" url="https://de.wikipedia.org/wiki?curid=4474" title="Liste der Biografien/M">
Liste der Biografien/M

__NOEDITSECTION__



</doc>
<doc id="4475" url="https://de.wikipedia.org/wiki?curid=4475" title="Liste der Biografien/N">
Liste der Biografien/N

__NOEDITSECTION__



</doc>
<doc id="4476" url="https://de.wikipedia.org/wiki?curid=4476" title="Liste der Biografien/O">
Liste der Biografien/O

__NOEDITSECTION__



</doc>
<doc id="4477" url="https://de.wikipedia.org/wiki?curid=4477" title="Liste der Biografien/P">
Liste der Biografien/P

__NOEDITSECTION__


</doc>
<doc id="4478" url="https://de.wikipedia.org/wiki?curid=4478" title="Liste der Biografien/Q">
Liste der Biografien/Q

__NOEDITSECTION__












</doc>
<doc id="4479" url="https://de.wikipedia.org/wiki?curid=4479" title="Liste der Biografien/R">
Liste der Biografien/R

__NOEDITSECTION__



</doc>
<doc id="4480" url="https://de.wikipedia.org/wiki?curid=4480" title="Liste der Biografien/S">
Liste der Biografien/S

__NOEDITSECTION__



</doc>
<doc id="4481" url="https://de.wikipedia.org/wiki?curid=4481" title="Liste der Biografien/T">
Liste der Biografien/T

__NOEDITSECTION__



</doc>
<doc id="4482" url="https://de.wikipedia.org/wiki?curid=4482" title="Liste der Biografien/U">
Liste der Biografien/U

__NOEDITSECTION__



</doc>
<doc id="4483" url="https://de.wikipedia.org/wiki?curid=4483" title="Liste der Biografien/V">
Liste der Biografien/V

__NOEDITSECTION__



</doc>
<doc id="4484" url="https://de.wikipedia.org/wiki?curid=4484" title="Liste der Biografien/W">
Liste der Biografien/W

__NOEDITSECTION__



</doc>
<doc id="4485" url="https://de.wikipedia.org/wiki?curid=4485" title="Liste der Biografien/X">
Liste der Biografien/X

__NOEDITSECTION__













</doc>
<doc id="4486" url="https://de.wikipedia.org/wiki?curid=4486" title="Liste der Biografien/Y">
Liste der Biografien/Y

__NOEDITSECTION__


</doc>
<doc id="4487" url="https://de.wikipedia.org/wiki?curid=4487" title="Liste der Biografien/Z">
Liste der Biografien/Z

__NOEDITSECTION__



</doc>
<doc id="4489" url="https://de.wikipedia.org/wiki?curid=4489" title="Satanismus">
Satanismus

Als Satanismus werden verschiedene Bewegungen bezeichnet, die sich positiv auf Satan bzw. auf das gesellschaftlich als Böse Angesehene beziehen. Sie stehen nicht unbedingt miteinander in Verbindung. Als literarische Strömung ist Satanismus seit dem 17., als religiöse Bewegung seit dem frühen 18. Jahrhundert belegt. Man unterscheidet in der Regel zwei Richtungen des Satanismus. Der „traditionelle“ (theistische) Satanismus beinhaltet das Verehren von Gottheiten. Darin gilt das Kriterium, dass die Figur Satans mehr oder weniger im Mittelpunkt steht. Beim „modernen“ Satanismus hingegen wird ein atheistischer und rationalistischer Standpunkt vertreten. Kleinster gemeinsamer Nenner zahlreicher Richtungen des modernen Satanismus ist hierbei der Anthropozentrismus, im Besonderen die Betonung der Freiheit des Menschen. Damit steht der Satanismus vor allem im Gegensatz zu religiösen Strömungen, die die Vorherbestimmung und Unvollkommenheit des Menschen betonen. Eine Vermischung des traditionellen Satanismus und modernen Satanismus ist trotz alldem möglich. In der Öffentlichkeit wird Satanismus vor allem als Gegenstand von Schauergeschichten, Sensationsjournalismus und Verschwörungstheorien wahrgenommen.

Der Begriff Satanismus bezieht sich etymologisch auf Satan und damit auf den Kulturraum der monotheistischen Religionen Judentum, Christentum und Islam. Allerdings geht die Idee einer dualistisch angelegten Welt, in der ein Kampf zwischen Gut und Böse ausgefochten wird, auf ältere Religionen wie zum Beispiel den Zoroastrismus zurück. Im Zentrum dieses Glaubens steht der Schöpfergott Ahura Mazda gegen Ahriman. Gnostische Strömungen übernahmen diesen Dualismus. Ein Motiv des modernen Satanismus – die Vergöttlichung des Menschen "(„Deus est homo“)" – findet sich etwa auch bei gnostischen Schlangenkulten der Antike (Ophiten). Sie schimmert in dem Satz „Ihr werdet sein wie Gott und wissen, was gut und böse ist“ durch.

Satan (hebr. שטן) bedeutet ‚Anfeinder‘, ‚Gegner‘ und ‚Widersacher‘. Seine Funktion im Buch Hiob gleicht der eines Staatsanwalts. Satan kann durchaus eine positive Rolle übernehmen. Seine theologisch untergeordnete Funktion wird dadurch sichtbar: Er handelt immer im Auftrag JHWHs, des jüdischen Gottes.

Im Judentum ist Satan derjenige, der die Seite der Anklage am Richterstuhl Gottes vertritt . Diese Auffassung lebt weiter in der Person des Advocatus diaboli, der diese Funktion bei Verhandlungen am Stuhl Petri ausführt. Im Buch Hiob wird Satan als einer der Söhne Gottes bezeichnet, der in der Hierarchie der Engel so weit oben stand, dass er Zutritt zu Gottes Hofstaat hatte . Eine polarisierende Deutung der Welt als ein Kampf Gut gegen Böse entstand später aus anderen religiösen Strömungen (persische und babylonische Religionen) in der jüdischen Kultur und war zunächst wenig bedeutsam. Theologisch relevant wurde sie mit dem aufkommenden Christentum.

Satan wurde erst in späteren jüdischen Mythologien wie dem, nach Otto Eissfeldt auf vor 63 v. Chr. datierten, apokryphen Äthiopischen Buch Henoch als gefallener Engel beschrieben, der sich zusammen mit seinen Anhängern gegen Gottes Willen auflehnte und zur Strafe auf die Erde verbannt wurde (1. Henoch 52,3; 53,6).

Der Begriff des Teufels im Neuen Testament ist ursprünglich griechisch Διάβολος, "Diàbolos", ‚der Verleumder‘, ‚Durcheinanderwerfer‘, ‚Verwirrer‘, was sich von Διά-βαλλειν, "dia-balläin", ‚durcheinanderwerfen‘, herleitet, seltener die griechische Umschrift des hebräischen Wortes "Satan" mit Σατανας, "Satanás". Das Wort personifiziert das Böse in seiner religiösen Funktion des Versuchers, wie es beispielhaft das Bild der Schlange im Paradies darstellt . Im Christentum wird der Teufel als Gegner und Widersacher (hebräisch: "Satan") des christlichen Gottes angesehen. Während im Laufe der Jahrhunderte alle nichtchristlichen („heidnischen“) Religionen in Europa von den Christen verdrängt wurden, erhielt der Teufel eine Vielzahl von Beinamen und neuen Gesichtern, da man die alten Gottheiten zu Feinden Gottes erklärte: eine der bekannteren Darstellungen ist die des bockbeinigen Hirtengottes Pan.

In einigen neo-gnostischen Strömungen wird Satan mit dem römischen Gott Lucifer (‚Lichträger‘ von "lux, lucis" "Licht" und "ferre" "tragen") gleichgesetzt.

Dem Islam ist die Vorstellung vom Iblis, einem Schaitan (arab.: الشيطن), also einem von Allah abgewandten Wesen, als Widersacher Gottes oder eine Art Kräfte-Gegenpols fremd. Das Prinzip Gut gegen Böse als Gegenkräfte ist hier nicht anwendbar. Denn nur Allah ist der absolut Mächtige, Iblis ist einzig Versucher der Menschen, dem Allah eine Frist gesetzt hat. Iblis ist nicht allmächtig, doch gefährlich für die Menschen, solange sie wanken und sich Allah nicht vertrauensvoll zuwenden: „Der Satan stachelt zwischen ihnen (zu Bosheit und Gehässigkeit) auf. Er ist dem Menschen ein ausgemachter Feind.“ (Sure 17:53) Folglich gibt es im Islam in der Regel keine Sekten oder Glaubensrichtungen, die sich mit Satan auseinandersetzen. Nach Sure 7:12 wurde Satan aus Feuer, Adam aus Ton geschaffen. Die Sure weist mehrere Satane den Ungläubigen zu, welche diese beschützen und zu Irrtümern verführen sollen. (Sure 7:27) Die über Satan verhängte Todesstrafe, weil er im Paradies Adam und Eva verführte, wurde ausgesetzt und findet nach islamischer Vorstellung erst beim Jüngsten Gericht statt. (Sure 7:24–25) Die symbolische Steinigung Satans nach der Rückkehr vom Berg Arafat in Mina östlich von Mekka ist eins der traditionellen Rituale der islamischen Pilgerfahrt.

Anfänglich war Satanismus eine von England ausgehende literarische Strömung, die sich mit dem Bösen integrativ auseinandersetzte. Als Begründer gilt John Milton (1608–1674). Seine Dichtung "Paradise Lost" (1667), in der erstmals in der Literaturgeschichte ein Satan beschrieben wird, der dem Menschen seine Potentiale bewusst machen soll, zu Wissen und Göttlichkeit zu gelangen, enthält den Satz: "Better to reign in hell than to serve in heaven" („Lieber in der Hölle herrschen als im Himmel dienen“). Die bekanntesten Vertreter sind der englische Dichter William Blake (1757–1827) sowie die französischen Dichter Marquis Donatien Alphonse François de Sade (1740–1814) und Charles Baudelaire (1821–1867). Baudelaire sah nach dem Sündenfall „keine direkte Verbindung mehr nach oben“ und das Heil in einer "hyperconscience dans le mal" (‚Überbewusstsein im Bösen‘) „vor allem bezüglich der Sexualität“; seine manichäische Haltung zum Bösen mit seiner Ästhetik des Hässlichen fand 1857 Ausdruck im Gedichtband "Les Fleurs du Mal" (dt. "Die Blumen des Bösen"). Marquis de Sades Hauptwerk dieser Richtung "Les 120 Journées de Sodome ou l’École du Libertinage" (dt. "Die 120 Tage von Sodom") wurde erst 1904 herausgeben, aber bereits im Jahr 1785 verfasst. In England griff Lord Byron (1788–1824) diese Ideen mit "Childe Harold’s Pilgrimage" 1812 und "Der Korsar" 1814 auf; sein von Miltons Satan inspiriertes Drama "Cain" aus dem Jahr 1821 gilt als das erste satanistische Werk der Weltliteratur. E.T.A. Hoffmann (1776–1822) als Hauptvertreter der sogenannten Schwarzen Romantik in Deutschland ist Autor des 1815/16 herausgegebenen fantastischen Romans "Die Elixiere des Teufels". 1865 erregte Giosuè Carducci (1835–1907), der spätere italienische Literatur-Nobelpreisträger von 1906, mit seiner "Inno a Satana" (Hymne an Satan) Aufsehen.

In seinem Roman "Demian" thematisiert Hermann Hesse den Satanismus und lässt einen Protagonisten unter anderem aussprechen: „Also müsse man entweder einen Gott haben, der auch Teufel sei, oder man müsse neben dem Gottesdienst auch einen Dienst des Teufels einrichten.“ Und: „Ich habe Kulte begangen, für die ich Jahre von Zuchthaus absitzen müßte, wenn man davon wüßte.“

Mediale Darstellungen von Satanismus stützen sich oft auf verbreitete Klischees wie Tier- und Menschenopfer beziehungsweise Ritualmorde im Zusammenhang mit Schwarzen Messen, ohne dafür konkrete Beweise vorlegen zu können. Bei diesen Berichten werden auch okkultistische Gruppierungen ohne Bezug zum Satanismus, wie der Ordo Templi Orientis, genannt. Teilweise werden auch Kriminalfälle wie der Mordfall von Sondershausen als satanistisch motiviert dargestellt.

Häufig werden auch „sexuelle Ausschweifungen“ und „perverse“ sexuelle Praktiken als Bestandteil von Satanismus und satanischen Messen angesehen. Die Schwarze Messe im "The Black Book of Satan" des Order of Nine Angles (ONA) beispielsweise beinhaltet Hostienfrevel durch Ejakulation auf die Hostie und eine Orgie. In "The Black Book of Satan III" ist auch eine zusätzliche Version für Homosexuelle zu finden. Toleranz gegenüber Homosexualität zeigen auch Äußerungen von Peter H. Gilmore und Anton Szandor LaVey von der Church of Satan, für die das Sexualleben des Einzelnen ausschließlich dessen Privatsache ist und die Mitgliedschaft von Homosexuellen wie Oliver Fehn und Marc Almond. Im Gegensatz dazu stehen wiederum die homophoben Ansichten von Kerry Bolton und entsprechende Äußerungen zahlreicher Black-Metal-Musiker.

Ab 1885 veröffentlichte der Franzose Léo Taxil die Verschwörungstheorie, die Freimaurer wären in Wahrheit Satanisten. In ihren Logenhäusern würden sie regelmäßig sexualmagische Orgien und Schwarze Messen zelebrieren, ihr oberster Chef erhalte seine Anweisungen von Luzifer persönlich. Diese und andere wüste Behauptungen verbreitete er in mehreren Büchern und in der Broschürenserie "Le Diable au XIXe siècle" („Der Teufel im 19. Jahrhundert“), von der 240 Titel erschienen. 1897 gestand Taxil öffentlich ein, dass er sich den ganzen Schwindel nur ausgedacht hatte.

In den 1980er und 1990er Jahren war in den Vereinigten Staaten die Annahme verbreitet, Kinder würden in großer Zahl von Mitgliedern satanistischer Sekten rituell missbraucht. Auslöser war 1980 der Bestseller "Michelle Remembers", in dem die Autorin angab, mittels Hypnotherapie Erinnerungen an Vergewaltigungen und Folterungen zurückerlangt zu haben, die sie seit ihrem fünften Lebensjahr von Mitgliedern der Church of Satan erlitten habe. 1987 schockierte ein Prozess die amerikanische Öffentlichkeit, in dem es um einen Satanistenring von 100 Lehrern und Erziehern ging, die insgesamt 360 Kinder der "McMartin Preschool" in Manhattan Beach, Kalifornien, missbraucht haben sollten. In der zweiten Hälfte der 1980er Jahre wurden immer mehr Fälle ritueller Gewalt an Einrichtungen der Kinderbetreuung aktenkundig: Lehrer, Sozialarbeiter, Therapeuten und Polizisten, die in Fortbildungsseminaren über rituelle Gewalt geschult worden waren, entdeckten mittels suggestiver Befragungsmethoden immer neue Fälle. Es entstand eine anti-satanistische „Moral Panic“, eine Massenhysterie, vergleichbar dem Hexenglauben des europäischen Mittelalters. Die Annahme, es gäbe ein großes Netzwerk satanistischer Gruppen, die rituelle Gewalt an Kindern ausüben und jährlich bis zu 60.000 Menschen töten würden, wurde von einer breiten Koalition von fundamentalistischen Christen, Feministinnen, Ärzten, Polizisten und Sozialarbeitern getragen. Seitdem die Angeklagten im McMartin-Prozess wegen erwiesener Unschuld freigesprochen worden waren und der Wahrheitsgehalt von "Michelle Remembers" in Zweifel gezogen worden war, ging der Glaube an massenhaften satanistischen Kindesmissbrauch Mitte der 1990er Jahre rasch wieder zurück. Heute werden die Berichte darüber auf Erinnerungsverfälschungen, Verschwörungstheorien und den Einfluss von Kinofilmen wie "Rosemaries Baby" oder "Der Exorzist" zurückgeführt.

Satanismus wird auch als rechtsextreme Ideologie dargestellt. Die antichristliche Ideologie sei zugleich antisemitisch und die sozialdarwinistische Position biete „extreme Nähen“ zu einem religiös begründeten „faschistischen Menschen- und Weltbild“. Im Gegensatz dazu bezeichnet Fehn Satanisten als rationale Freidenker. Die Church of Satan, der er angehört, ist offiziell apolitisch; in ihrem Text "Church of Satan Policy on Politics" heißt es:

Allerdings wird rechtsextremes und rechtsesoterisches Gedankengut seit den 1990er Jahren von einzelnen Gruppierungen mit satanischen Inhalten verknüpft. Vorreiter war hier der ONA, der Adolf Hitler in seiner "Mass of Heresy" anruft und den Nationalsozialismus als „(neben traditionellem Satanismus) einzig wahre Häresie“ bezeichnet, die nach einer „Revolution der Seele, einem Triumph des Willens und einer Rückkehr von rassischem Stolz und [rassischer] Pflicht“ rufe. In dessen Tradition stehen unter anderem die Gruppierungen "The Black Order" und "Order of the Left Hand Path/Ordo Sinistra Vivendi" von Kerry Bolton, der ein Adept des ONA war, die "Fraternitas Loki", The Joy of Satan und der "White Order of Thule". Der "Schwarze Orden von Luzifer" des Schweizers Sartorius, der seine Wurzeln im Gegensatz zum ONA im „modernen“ Satanismus von LaVey und Aquino hat, beruft sich wiederum auf die Ansichten Karl Maria Wiliguts.

Die Anfänge des Satanismus werden im manichäisch-gnostischen Dualismus gesehen, der eine prinzipielle „Gleichrangigkeit von Gott und Teufel“ annahm. Einige gnostische Gruppierungen sollen Satan angebetet haben, damit er ihnen nicht schade. Für einen real existierenden Satanismus in Mittelalter und Frühneuzeit vor dem Hintergrund der Verfolgung von Ketzern und der zahlreichen Hexenverbrennungen dieser Epoche gibt es zum gegenwärtigen Zeitpunkt der Forschung keinerlei Anhaltspunkte. Die Annahme eines im Sinne des Satanismus organisierten Hexenkultes wird von Historikern meist abgelehnt. Es finden sich jedoch Hinweise auf einen echten Satanismus im Prozess gegen Gilles de Rais, in dem sich „das Destruktive des Satanismus in extremer Weise konzentriert hat […], auch wenn die Quellen über ihn von keinen ausgedehnten Teufels-Ritualen berichten“.

In der Zeit der Romantik versuchte Robert Southey, seinen Gegner Lord Byron zu diskreditieren, und prägte in diesem Zusammenhang das Schlagwort der "Satanic School".

Eine erste Erscheinung des Satanismus ist ansatzweise der Hellfire Club im England des 18. Jahrhunderts. Satanistische Tendenzen finden sich „[u]nbestreitbar […] im Okkultismus des 19. Jahrhunderts, offenbar als Reaktion auf den als banal empfundenen, fortschrittsgläubigen Materialismus dieser Epoche, der die orthodoxe Gläubigkeit weitgehend ablehnte, aber dennoch ‚dunkle Mysterien‘ verlangte“. Frankreich, das mit Individuen wie Éliphas Lévi eine Pionierrolle für den Okkultismus hatte, wird als „Brutstätte des modernen Satanismus“ angesehen und der Dichter Baudelaire als wichtige Figur dieses modernen Satanismus und „vielleicht […] erste voll bewußte Persönlichkeit in der Geschichte des Satanskultes“ bezeichnet, wobei die Bezeichnung als „moderner Satanismus“ hier noch eine andere Bedeutung hat als bei LaVeys späterer Auslegung. Im 20. Jahrhundert gründeten sich zahlreiche weitere Vereinigungen. Der britische Magier Aleister Crowley wird oftmals als Satanist eingestuft, war allerdings ein wichtiger Vorreiter des modernen Satanismus. Die Verbindung von Satanismus und der auf Crowley zurückgehenden neureligiösen Bewegung Thelema wurde durch den britischen Schriftsteller Dennis Wheatley geprägt.

Bis in die 1960er Jahre hinein gab es keine eigene satanistische Tradition, auf die sich die Anhänger dieser Weltanschauung beziehen konnten. Alle Veröffentlichungen zum Thema stammten nach Darstellung des amerikanischen Religionswissenschaftlers J. Gordon Melton bis dahin ausschließlich von entschiedenen Gegnern des Satanismus, in der Hauptsache von konservativen Christen. Obwohl diese niemals an Schwarzen Messen teilgenommen hatten, beschrieben sie sie dennoch wiederholt in großem Detailreichtum. An diesen nicht-satanistischen Quellen orientierten sich über zwei Jahrhunderte alle Versuche, satanistische Gemeinschaften zu konstituieren. Das änderte sich 1966, als Anton Szandor LaVey die Church of Satan gründete und den Satanismus als Erster öffentlich zu einem eigenständigen achristlichen Religionssystem machte. Seine "Satanische Bibel" (1968) wurde inhaltlich in großen Teilen bereits von Crowley und dem sozialdarwinistischen Buch "Might is Right" (1896), dessen unbekannter Autor unter dem Pseudonym Ragnar Redbeard firmiert, vorweggenommen. Satan „ist hier nicht der mittelalterliche Gottseibeiuns mit der Mistgabel, sondern das Prinzip ‚Lust‘ und ‚unbedingte Freiheit‘ – das auf links gedrehte ‚peace, love and happiness‘ von LaVeys Hippie-Nachbarn im San Francisco der sechziger Jahre“ Stattdessen vertritt diese Kirche eine atheistische Philosophie und bestreitet die „Wirklichkeit einer jeglichen spirituellen Existenz“; die von ihr aufgegriffenen Aspekte der Ritualmagie werden entsprechend als „selbst-veränderndes Psychodrama […], um sich von aufgestauten Gefühlen zu befreien“ und „fast ein Ersatz für Psychotherapie“ erklärt, das keine Glaubenselemente enthalte. Er „wollte, dass Satanismus ein Werkzeug ist, um das Leben eines jeden Satanisten zu verbessern“, und die Church of Satan „sollte das Mittel sein, um diese Philosophie so originalgetreu wie möglich zu verbreiten“. Andere Strömungen innerhalb des Satanismus lehnen LaVeys Auslegung ab, weil sie „sehr menschlich“ sei, besage, dass „die einfachste Hausfrau Satanist sein kann“ und es für die meisten Personen sehr einfach sei, den Inhalten zuzustimmen, sie „nahezu universell lesbar“ seien, und erkennen sie nicht als satanistisch an. LaVey habe nie die dunkle Seite des Lebens praktisch zu erfahren oder Böses zu praktizieren versucht. Stattdessen verbreite die CoS „eigentlich nichts anderes als magisch verbrämten Hedonismus. Aus Crowleys tiefsinnigem ‚Do what thou wilt‘ mache sie ein plattes ‚Do as you like‘. Die Satanskirche wendet sich gegen Puritanismus in jeder Form, aber auch gegen Mystik und Drogengebrauch (sehr zum Unterschied von Crowley). Ihre Sozialmoral ist machiavellistisch, ihr Weltbild kynisch-epikuräisch. Bei ihrer Magie handelt es sich um ein geschickt zusammengestelltes Arsenal von Techniken der Verhaltenstherapie, die LaVey ungeniert zu Höchstpreisen vermarktet.“ Die Church of Satan fand zahlreiche prominente Unterstützer und Anhänger und ist „längst Pop“. Entsprechend gilt es als „‚Verdienst‘ der Church of Satan, dem Satanismus den Nimbus des Elitären genommen und ihn im gottlosen Kapitalismus verankert zu haben, weshalb die magische Konkurrenz sie gern als okkulten Drive-in belächelt“. Von der Church of Satan spaltete sich 1975 nach internen Streitigkeit der Temple of Set ab, der von traditionellen Satanisten ebenfalls nicht anerkannt wird. Obwohl sich herausstellte, dass „Legende und Wirklichkeit in LaVeys bunter Biographie nicht übereinstimmen“, wurde der Mythos um seine Person dadurch „kaum angekratzt“. Nach LaVeys Tod 1997 kam es zu vier Jahre andauernden Streitigkeiten um seine Nachfolge; der Journalist Lawrence Wright äußerte, die Church of Satan habe keine Zukunft, „es sei denn, es käme eine Figur mit ähnlichem Charisma daher“. 2001 wurde Peter H. Gilmore der neue Hohepriester der Kirche.

In den 1970er Jahren soll der Order of Nine Angles gegründet worden sein. Dieser bezeichnete sich als erste Gruppierung in seinen Schriften als Vertreter eines traditionellen Satanismus. Diese Bezeichnung steht nicht für Satanismus im traditionellen Sinne der Verehrung eines realen Satans, sondern für eine vom ONA behauptete geheime Tradition über mehrere Generationen; diese Behauptung wird jedoch angezweifelt. Für den ONA geht traditioneller Satanismus weit über die Befriedigung des Lustprinzips hinaus und beinhaltet Selbstbeherrschung, Selbstüberwindung und kosmische Weisheit. Seine Vorstellung von Satanismus ist pragmatisch mit einem Schwerpunkt auf der Evolution des Individuums durch gefährliche Situationen. Die Bezeichnung als „traditioneller Satanismus“ wird aber auch unabhängig vom ONA von zahlreichen theistischen Satanisten verwandt, andere bevorzugen die Bezeichnung „theistischer Satanismus“, auch zur Abgrenzung vom ONA.

Vielen Subkulturen und Musikrichtungen wird nachgesagt, ihre Szenegänger würden dem Satanismus frönen, wobei entweder den Musikern ein Pakt mit dem Teufel oder die Verwendung von Rückwärtsbotschaften vorgeworfen wird oder man sich darunter unwissentlich Jugendsatanismus vorstellt. Dies ist jedoch in den allermeisten Fällen vollkommen falsch.

Die Gothic-Subkultur findet sich wohl am häufigsten mit diesem Vorurteil konfrontiert. Das Kokettieren der Goths mit satanischer und dunkler Ästhetik – Petruskreuze (das auf dem Kopf stehende Kreuz ist nicht zwangsläufig antichristlich), Pentagramme und andere okkulte Symbole als Schmuck, schwarze Gewänder, düstere Musik – wird als Ausdruck einer Geisteshaltung oder gar Bestätigung für kultische Aktivitäten überbewertet. Die evangelische Informationsstelle Relinfo urteilt im Zusammenhang mit den Gruftis, einer Splitterkultur der Gothic-Szene: „Zwar trifft es zu, dass manch ein ‚Gruftie‘ sich satanistisch weiterbildete und/oder von satanistischen Zirkeln angeworben wurde, den meisten ‚Grufties‘ war Satan aber kein Anliegen. Ihr Outfit und ihre Praktiken entsprangen vielmehr einer morbiden Grundstimmung, die das einigende Element der ‚Gruftie‘-Szene darstellte. Inzwischen sind die Grufties im Gegensatz zum Jugendsatanismus praktisch verschwunden, was deutlich belegt, dass der Zusammenhang der beiden Phänomene ein gar so enger nicht gewesen sein kann.“ Die Texte der Musik der Gothic-Kultur geben hier mehr Aufschluss über eine introvertierte Gefühlswelt von Melancholie und Weltschmerz.

Auch die Metal-Subkultur bedient sich stellenweise satanistischer Symbole. Mit welcher Häufigkeit und Ernsthaftigkeit, hängt ausgesprochen stark davon ab, in welcher Subszene des Metal man sich bewegt. In den meisten Subszenen werden, entgegen allen Vorurteilen, tatsächlich nur sehr selten satanistische Symbole verwendet, und entsprechendes Gedankengut ist mitunter gar nicht präsent. Meist dient satanische Symbolik im Metal ausschließlich der Provokation und Rebellion und der Betonung der eigenen Freiheit. In der Subszene des Death Metal ist eine antichristliche bis satanische Symbolik vereinzelt vorzufinden, was in erster Linie jedoch mit dem Ziel einer künstlerisch inspirierten (manchmal auch kommerziell kalkulierten) Provokation geschieht. Die Black-Metal-Szene hingegen ist über den Satanismus definiert.

Satanismus findet sich auch in der Industrial-Subkultur, wo sich einzelne Musiker mit Okkultismus und Satanismus beschäftigen; einige Musiker wie Reverend Thomas Thorn (The Electric Hellfire Club) und Boyd Rice sind Mitglieder der Church of Satan.





</doc>
<doc id="4491" url="https://de.wikipedia.org/wiki?curid=4491" title="Sprichwort">
Sprichwort

Sprichwörter (Proverben, Parömien) sind traditionell-volkstümliche Aussagen betreffend ein Verhalten, eine Verhaltensfolge oder einen Zustand, die zumeist eine Lebenserfahrung darstellen. Sprichwörter sind wie die Redewendungen ein wichtiger Teil des Thesaurus in fast jeder Sprache. In der Sprachwissenschaft wird die Kunde von den Sprichwörtern nach dem griechischen Wort παροιμἰα "(paroimía)" als wissenschaftliche Disziplin Parömiologie genannt.

Die Abgrenzung vom Sprichwort mit seinem unbekannten Autor zum Zitat und zum „geflügelten Wort“, deren Herkunft nachweisbar ist, ist nicht immer eindeutig. In der Linguistik wird der Wiederholungs- und Unveränderlichkeitsaspekt manchmal mit einem Terminus von Eugenio Coseriu als „wiederholte Rede“ ("discurso repetido"), gefasst. Zitate sind zunächst einmal individuelle Erfindungen, die aber sprichwörtlich werden können. Bei immer mehr geflügelten Worten geht das Zitatbewusstsein verloren. Das gilt besonders für viele aus der Bibel stammende Wendungen. Auffällig ist, dass in protestantischen Gesellschaften mehr auf die Bibel angespielt wird als in katholischen.

Auch manche Buch- und Filmtitel haben mittlerweile schon sprichwörtlichen Charakter angenommen. Sogar gekürzte Refrains aus Volksliedern oder Schlagern werden bereits für Sprichwörter gehalten.

Ein dem Sprichwort ähnelndes Zitat wird als geflügeltes Wort bezeichnet. Nach André Jolles gehören Sprichwort und geflügeltes Wort zu den sogenannten einfachen Formen.

In der Kultur des Mittelalters wird das Sprichwort in allen Lebensbereichen als Ausdrucksmittel geschätzt. Seit dem 12. Jahrhundert empfehlen zahlreiche Lehrwerke der Rhetorik das Sprichwort als Stilmittel zur Unterstützung der Beweiskraft didaktischer Schriften. Mittelalterliche Predigten setzen häufig Sprichwörter neben Schriftwörter. Erkenntnistheoretisch entspricht das Sprichwort den Tendenzen des scholastischen Realismus und dessen architektonischem Idealismus. Da es das Allgemeine, Universelle als das einzig Wirkliche und Beweiskräftige ansieht ("universale ante rem"), erlaubte es dem mittelalterlichen Menschen, im Alltag gleich wie in seiner Theologie zu denken. Aus diesem Grund bezeichnet Johan Huizinga das Sprichwort sogar als das der mittelalterlichen Geisteskultur wesensgemäßeste sprachliche Ausdrucksmittel. Nur im Spätmittelalter, etwa in den Werken Geoffrey Chaucers, wird Skepsis gegenüber abstrakten sprachlichen Formen wie dem Sprichwort deutlich.

Ein Sprichwort hat die Form einer festen und unveränderlichen Formulierung. Darin unterscheidet es sich von der Redewendung.

Oft wird die Form des Sprichworts durch Stabreim, End- oder Binnenreim noch besonders gefestigt.

Mit dem imperativischen Anspruch „"Jeder kehre vor seiner eigenen Tür!"“, „"Man soll …"“, „"Man muss …"“ oder „"Man darf …"“ hat das Sprichwort eine generalisierende Form angenommen.
Es drückt in der Regel einen allgemein gültigen Satz aus, der entweder eine

Viele Sprichwörter sprechen
aus.

Mitunter widersprechen Sprichwörter einander.
Zwar gilt es als Merkmal des echten Sprichwortes, dass sein Autor unbekannt ist, doch beruhen manche
vermeintlichen Sprichwörter nicht auf verallgemeinerten gesellschaftlichen Erfahrungen, sondern haben ihren Ursprung bei lateinischen Autoren oder in der Bibel. Die Mehrzahl der Letzteren fand durch Martin Luthers Übersetzung Eingang in die deutsche Sprache.

Auch manche kernigen Sätze aus der Literatur wurden so populär, dass sie nun vielfach als Sprichwörter gelten, obschon ihre Herkunft nachweisbar ist:

Viele Sprichwörter sind im Laufe der Zeit verändert, vermischt und oft auch inhaltlich weiterentwickelt worden. Diese Sprichwort-Fortentwicklungen sind in der Forschung noch nicht hinlänglich aufgearbeitet worden. Viele Abwandlungen sind spöttisch gemeint und wollen dadurch auch die Trivialität der Aussage des Originals hervorheben oder karikieren.


Weitere bildhafte Beispiele finden sich im Artikel über Katachrese (Bildbruch).













</doc>
<doc id="4492" url="https://de.wikipedia.org/wiki?curid=4492" title="Stuttgart">
Stuttgart

Als Sitz der baden-württembergischen Landesregierung und des Landtags sowie zahlreicher Landesbehörden ist Stuttgart das politische Zentrum des Landes (siehe auch "Liste der Behörden und Einrichtungen in Stuttgart"). Es ist Sitz des Regierungspräsidiums Stuttgart, das den gleichnamigen Regierungsbezirk verwaltet. In Stuttgart tagt das Regionalparlament der Region Stuttgart, einer der drei Regionen im Regierungsbezirk Stuttgart. Darüber hinaus ist Stuttgart Sitz des evangelischen Landesbischofs von Württemberg und Teil der katholischen Diözese Rottenburg-Stuttgart. Die Stadt ist ein wichtiger Wirtschaftsstandort und Finanzplatz. Sie ist bekannt als Heimat der deutschen Automobilfirmen Daimler und Porsche.

Das Stuttgarter Stadtbild wird durch viele Anhöhen (teilweise Weinberge), Täler (insbesondere Stuttgarter Talkessel und Neckartal), Grünanlagen (u. a. Rosensteinpark, Schlossgarten, Höhenpark) sowie eine dichte urbane Bebauung mit hohem Anteil von Nachkriegsbauten, diversen Baudenkmälern, Kirchbauten und einigen Hochhäusern geprägt.

Stuttgart (im lokalen schwäbischen Dialekt "Schduagerd") liegt im Zentrum des Landes Baden-Württemberg. Die Kernstadt befindet sich „zwischen Wald und Reben“ im „Stuttgarter Kessel“, einem vom nordostwärts dem Neckar zufließenden Nesenbach und seinen Nebenbächen, vor allem dem Vogelsangbach, durchflossenen Talkessel. Die Stadtteile reichen im Norden bis in das Neckarbecken, im Westen bis in den Glemswald und auf das Gäu, im Osten bis zu den Ausläufern des Schurwaldes und im Süden bis auf die Filderebene und zu den Ausläufern des Schönbuchs. Im Südosten fließt der Neckar bei den Stadtbezirken Hedelfingen/Obertürkheim von Esslingen am Neckar kommend in das Stadtgebiet und verlässt es im Stadtbezirk Mühlhausen im Nordosten wieder.

Das Stadtgebiet erstreckt sich über eine Höhendifferenz von fast 350 m, was eine Besonderheit unter den Großstädten darstellt: die Höhe reicht von bei der Neckarschleuse Hofen bis auf der Bernhartshöhe nahe dem Autobahnkreuz Stuttgart. Zu den markantesten Erhebungen gehören der Birkenkopf () am Rand des Talkessels, der Württemberg () über dem Neckartal und der Grüne Heiner () an der nordwestlichen Stadtgrenze.

Die Stadt Stuttgart ist eines von 14 Oberzentren in Baden-Württemberg. Sie ist das Oberzentrum der Region Stuttgart, die ihrerseits mit der Stadt Stuttgart und ihren fünf Landkreisen insgesamt 2,67 Millionen Einwohner beherbergt.

Im Bereich des Oberzentrums Stuttgart (Region Stuttgart) liegen folgende Mittelzentren:

Backnang, Bietigheim-Bissingen/Besigheim, Böblingen/Sindelfingen, Esslingen am Neckar, Geislingen an der Steige, Göppingen, Herrenberg, Kirchheim unter Teck, Leonberg, Ludwigsburg/Kornwestheim, Nürtingen, Schorndorf, Vaihingen an der Enz und Waiblingen/Fellbach.

Die Stadt Stuttgart fungiert für die Städte Leinfelden-Echterdingen und Filderstadt – beide im Landkreis Esslingen gelegen – sowie für die Städte Ditzingen, Gerlingen und Korntal-Münchingen – alle drei im Landkreis Ludwigsburg gelegen – als Mittelzentrum.

Die Stadt Stuttgart ist das Zentrum der Metropolregion Stuttgart und eines der drei Oberzentren innerhalb dieser. Die Metropolregion Stuttgart beherbergt insgesamt 5,3 Millionen Einwohner.

Folgende Städte und Gemeinden grenzen an die Landeshauptstadt Stuttgart. Sie werden im Uhrzeigersinn, beginnend im Nordosten, genannt:

Fellbach, Kernen im Remstal (alle Rems-Murr-Kreis), Esslingen am Neckar, Ostfildern, Neuhausen auf den Fildern, Filderstadt und Leinfelden-Echterdingen (alle Landkreis Esslingen), Sindelfingen und Leonberg (Landkreis Böblingen) sowie Gerlingen, Ditzingen, Korntal-Münchingen, Möglingen, Kornwestheim und Remseck am Neckar (alle Landkreis Ludwigsburg). Somit grenzen vier der fünf Landkreise der "Region Stuttgart" an den "Stadtkreis Stuttgart".

Das Stadtgebiet der Landeshauptstadt Stuttgart ist verwaltungsmäßig in fünf „innere“ und 18 „äußere“ Stadtbezirke aufgeteilt. Die Stadtbezirke haben einen Bezirksbeirat und einen Bezirksvorsteher, der in den inneren Stadtbezirken nur ehrenamtlich tätig ist.

Die Stadtbezirke gliedern sich weiter in Stadtteile. Die Zahl der Stadtteile wurde durch die Änderung der Hauptsatzung vom 1. Juli 2007 und 1. Januar 2009 vergrößert. Seitdem besteht das Stadtgebiet von Stuttgart aus 23 Stadtbezirken und 152 Stadtteilen (Stadtbezirke auf der Stadtkarte sind anklickbar).

Durch die Lage im breiten Stuttgarter Talkessel und die dichte Bebauung gibt es ein vergleichsweise warmes und zuweilen schwüles Klima. Die Höhenzüge Schwarzwald, Schwäbische Alb, Schurwald sowie der Schwäbisch-Fränkische Wald schatten zusätzlich die gesamte Region von Winden ab. Aufgrund dessen ist an den Hängen Stuttgarts sogar Weinbau möglich. Der Weinbau in Stuttgart umfasst mit 423 Hektar Rebfläche gut zwei Prozent der Stadtfläche.

Die Jahresmitteltemperatur beträgt in Stuttgart 9,3 (Wetterstation Schnarrenberg), in der Innenstadt und im Neckartal bei 10,6 und auf den Fildern am Flughafen bei 8,5 Grad Celsius. Im Winter bleibt die im Talkessel liegende Innenstadt meist schnee- und eisfrei. Auch starke „gefühlte“ Winde sind in der Innenstadt wegen der dichten Bebauung eher selten. Um trotz der immer wieder auftretenden Inversionswetterlage dennoch genug Frischluft im Kessel zu haben, sind viele Stellen an den Hanglagen – vor allem in Stuttgart-West – unbebaut und dienen als Frischluftschneisen. Auch das im Westen auf der Höhe liegende Waldstück Rot- und Schwarzwildpark dient der tiefer liegenden Innenstadt als Frischluftlieferant. Um die Luftreinhaltung zu verbessern und die Feinstaubwerte zu reduzieren, wurde 2005 ein Durchfahrtsverbot für Lkw erlassen, das jedoch im Zusammenhang mit der Einführung der Feinstaub-Verordnung am 1. März 2008 wieder aufgehoben werden musste. Seit März 2010 ist ein neues Lkw-Durchfahrtsverbot in Kraft.

Die Leelage der Region Stuttgart ist Ursache dafür, dass sie zu den niederschlagsarmen Regionen in Deutschland zählt. Die Wolken regnen sich an der Schwäbischen Alb und dem Schwarzwald ab, sodass nur relativ trockene Luft nach Stuttgart gelangt. Steigende Bevölkerungszahlen führten Anfang des 20. Jahrhunderts zu Trinkwassermangel, worauf 1917 die erste Fernleitung aus dem Donauried über die Alb in Betrieb ging (Landeswasserversorgung). 1959 folgte die Bodensee-Wasserversorgung.

Nach Daten des Statistischen Landesamtes, Stand 2015.

Auf der Markung der Landeshauptstadt Stuttgart befinden sich folgende Naturschutzgebiete: Nach der Schutzgebietsstatistik der Landesanstalt für Umwelt, Messungen und Naturschutz Baden Württemberg (LUBW) stehen 1353,19 Hektar der Stadtfläche unter Naturschutz, das sind 6,53 Prozent.


Stuttgart ist überregional bekannt für seine Gelbkopfamazonenpopulation, die die einzige in freier Wildbahn außerhalb Amerikas ist.

Stuttgart überschritt 1875 die Grenze von 100.000 Einwohnern und wurde damit die erste Großstadt auf dem Gebiet des heutigen Landes Baden-Württemberg. 1905 hatte die Stadt 250.000 Einwohner, bis 1950 verdoppelte sich diese Zahl auf 500.000. Im Jahr 1962 erreichte die Bevölkerungszahl mit 640.560 ihren historischen Höchststand. Die Stadt liegt in der Liste der Großstädte in Deutschland aktuell an sechster Stelle und ist nach München die zweitgrößte Stadt Süddeutschlands.

Das Durchschnittsalter betrug Ende 2016 41,8 Jahre.

Der Anteil der Bevölkerung mit Migrationshintergrund betrug gemäß Zensus 2011 38,6 %. Somit hatte Stuttgart den zweithöchsten Anteil aller deutschen Großstädte – nach Frankfurt am Main mit 44,2 % und vor Nürnberg mit 36,4 %. Bei den unter Fünfjährigen lag dieser Anteil in Stuttgart 2007 bei 64 %. Der Ausländeranteil lag 2016 bei 25,2 %. 44 % der Einwohner Stuttgarts hatten einen Migrationshintergrund.

2016 starben in Stuttgart 5289 Menschen (361 weniger als 2015); dem standen 6773 Geburten (467 mehr als 2015) gegenüber.

Die durchschnittliche Bestandsmiete in Stuttgart liegt bei 9,92 Euro je Quadratmeter und damit über Frankfurt am Main (8,87 Euro) und unter München (10,22 Euro) (Stand: Ende 2017).

Stuttgart gehört zum niederschwäbischen Sprachraum.

Im Jahr 2015 bekannten sich 25,3 % zum protestantischen und 23,6 % zum katholischen Glauben, die verbleibenden 51,1 % gehörten anderen Religionen an oder waren konfessionslos. Im Jahr 2014 bekannten sich 26,2 % zum protestantischen und 24,0 % zum katholischen Glauben, die verbleibenden 49,8 % gehörten anderen Religionen an oder waren konfessionslos. Die Anzahl der Protestanten hat seit 2005 abgenommen und betrug Ende 2014 152.000. Beim Zensus 2011 waren 182.840 Protestanten in Stuttgart gezählt worden (177.740 in der Evangelischen Kirche, 5.100 in Evangelischen Freikirchen).

1534 wurde im Herzogtum Württemberg die Reformation eingeführt. Damit entstand die Evangelische Landeskirche in Württemberg, die bis heute besteht und in Stuttgart ihren Sitz hat. Zu dieser Landeskirche gehören heute alle evangelischen Gemeindeglieder der Stadt, sofern sie nicht Mitglied einer Evangelischen Freikirche oder der Evangelisch-reformierten Gemeinde Stuttgart sind. Letztgenannte gehört zur Evangelisch-reformierten Kirche, die in Leer (Ostfriesland) ihren Sitz hat. Die (lutherischen) Kirchengemeinden der Stadt gehören heute zum Kirchenkreis Stuttgart, der am 1. Januar 2008 durch Vereinigung der Kirchenbezirke Stuttgart, Bad Cannstatt, Degerloch und Zuffenhausen entstanden ist. Der Kirchenkreis Stuttgart ist Teil der Prälatur („Sprengel“) Stuttgart, die ebenfalls in Stuttgart ihren Sitz hat. In Stuttgart sind auch viele Freikirchen vertreten, von denen das Gospel Forum (früher Biblische Glaubensgemeinde) die größte ist.

Seit dem 18. Jahrhundert besiedelten auch wieder Katholiken die Stadt. An der Wende vom 18. zum 19. Jahrhundert erhielten diese wieder eine eigene Kirche: die heutige Domkirche St. Eberhard, die von 1808 bis 1811 erbaut wurde und heute Konkathedrale der Diözese Rottenburg-Stuttgart ist. In den folgenden Jahrzehnten zogen weitere Katholiken in die Stadt. 2006 wurden die bis dahin existierenden vier Stuttgarter Dekanate zu einem Stadtdekanat Stuttgart zusammengefasst. Der Zensus 2011 zählte 150.050 Katholiken in der Stadt. Den ersten Neubau einer katholischen Kirche nach der Reformation stellt die Marienkirche im Stuttgarter Süden dar. Sie wurde in der zweiten Hälfte des 19. Jahrhunderts im Stil der Neugotik erbaut.

In Stuttgart sind mehrere orthodoxe Kirchen ansässig. Die Serbisch-Orthodoxe Kirche "Synaxe der serbischen Heiligen (Hram Srba Svetitelja, Храм Срба Светитеља)" befindet sich seit 1971 am Marienplatz. Die Russisch-Orthodoxe Kirche "St. Nikolai (Церковь св. Николая)" wurde bereits 1895 geweiht. Nachdem die Kirche 1944 bei einem Bombenangriff stark beschädigt wurde, folgte ein Wiederaufbau. 1972 wurde ein durch den berühmten Ikonographen Nikolai Schelechow gestalteter Ikonostas in die Kirche eingebracht. Die Griechisch-Orthodoxe Kirche verfügt über zwei Kirchen in Stuttgart. Im Stuttgarter Westen befindet sich die "Kirche Himmelfahrt Christi" und in Feuerbach die "Kirche der Heiligen Aposteln Petrus und Paulus". Die Rumänisch-Orthodoxe Kirchengemeinde in Stuttgart wurde im Jahre 1964 gegründet und nutzt für ihre Gottesdienste die Leonhardskirche. Die Bulgarisch-Orthodoxe Kirchengemeinde Stuttgarts hält ihre Gottesdienste in der Serbischen und Russischen Kirche ab. Es existieren noch weitere orthodoxe Kirchengemeinden, die in der Regel die Gotteshäuser anderer mitnutzen. Seit dem 30. September 2012 existiert für die derzeit etwa 50.000 Orthodoxen eine Pfarrkonferenz.

Am Katharinenplatz hat die alt-katholische Gemeinde ihre Pfarrkirche. In der neogotischen Katharinenkirche feiert auch die anglikanische Gemeinde ihre Gottesdienste. Zwischen beiden besteht seit 1931 volle Kirchengemeinschaft.

Seit dem 19. Jahrhundert ist die Neuapostolische Kirche in Stuttgart vertreten. Im Oktober 1897 wurden erste Gottesdienste der Neuapostolischen Kirche im Stadtgebiet durchgeführt und die heutige Gemeinde Stuttgart-West gegründet. In den folgenden Jahren wurden weitere Gemeinden im Stadtgebiet gegründet und für diese entsprechende Kirchengebäude erstellt. Die größten Kirchengebäude der Neuapostolischen Kirche in Stuttgart befinden sich in der Einkornstraße (Gemeinde Stuttgart-Ost), sowie in der Immenhofer Straße (Gemeinde Stuttgart-Süd). Bedingt durch einen Konzentrationsprozess der Kirchengemeinden schrumpft die Zahl der Gemeinden im Stadtgebiet trotz leichtem Zuwachs bei den Mitgliederzahlen, insbesondere durch Zuzug. Im Jahr 2008 bestanden 27 Gemeinden im Stadtgebiet, derzeit sind es noch 19 Gemeinden. Sie sind gemeinsam mit den Gemeinden in der Region in fünf rechtlich unselbständige Bezirke aufgeteilt. Des Weiteren befindet sich in der Stuttgarter Heinestraße die Verwaltung für die Gebietskirche Süddeutschland, die aus den beiden Bundesländern Baden-Württemberg und Bayern, sowie weiteren rund 20 Missionsländern besteht.

In Stuttgart sind außer den bereits angeführten Konfessionen auch Gemeinden fast aller bekannten Freikirchen zu finden, so die Siebenten-Tags-Adventisten, die Kirche Jesu Christi der Heiligen der Letzten Tage, die Apostolische Gemeinschaft, die Baptisten, die Heilsarmee und die Methodisten.

In Stuttgart wie in ganz Württemberg durften 1498 bis 1805 keine Juden dauerhaft wohnen und arbeiten, nachdem Eberhard I. ihre Vertreibung oder Gefangennahme testamentarisch verfügt hatte. Allerdings wurde das Verbot immer wieder durchbrochen, so unterhielt der württembergische Hof zur Finanzierung seines Staatshaushalts sogenannte Hoffaktoren, darunter Joseph Süß Oppenheimer, der Opfer eines antisemitischen Justizmords wurde, Mardochai Schloß und Karoline Kaulla. 1828 wurden die Lebensbedingungen der Juden durch das Gleichstellungsgesetz erheblich verbessert.

1832 wurde offiziell die jüdische Gemeinde gegründet, 1837 die erste Synagoge eingeweiht, die 1861 durch einen Neubau im orientalischen (maurischen) Stil in der Hospitalstraße ersetzt wurde. Während der Zeit des Nationalsozialismus 1938 wurde die Synagoge in den Novemberpogromen zerstört. Viele Juden konnten vor der Verfolgung ins Ausland fliehen; mindestens 1200 Mitglieder der ursprünglich 4500 Mitglieder zählenden Gemeinde (1933) wurden jedoch im Holocaust ermordet. Die neue Synagoge am gleichen Ort entstand 1952 als einer der ersten Synagogenneubauten der Bundesrepublik nach dem Krieg. Die Synagoge in der Hospitalstraße 36 ist Zentrum der Israelitischen Religionsgemeinschaft Württembergs, die das ganze Territorium der ehemaligen Staaten Württemberg und Hohenzollern umfasst. Vor allem durch die Zuwanderung von Juden aus Osteuropa wuchs die Gemeinde seit 1990 stark an. Heute hat die jüdische Gemeinde etwa 4000 Mitglieder, von denen jedoch nur ein geringer Teil ihren Glauben praktiziert.

Vor allem durch die Einwanderung aus der Türkei, Bosnien und Herzegowina und den arabischen Ländern seit der Gastarbeiterzeit hat Stuttgart heute eine muslimische Bevölkerung von etwa 65.000 Menschen. Bei der Volkszählung 1987 deklarierten sich 22.599 Einwohner als Muslime. Das Statistische Amt der Landeshauptstadt ging 2006 von rund 50.000, 2009 von rund 60.000 Muslimen in Stuttgart aus. Eine Berechnung für den 9. Mai 2011 auf Grundlage der Zensuszahlen zu Migranten ergab eine Zahl von rund 55.000 Muslimen (9,4 % der Bevölkerung) in der Stadt. Diesen stehen 21 Moscheen unterschiedlicher religiöser Strömungen zur Verfügung. Des Weiteren gibt es in Bad Cannstatt ein Cemevi der Aleviten.

Das Buddhistische Zentrum Stuttgart wurde unter diesem Namen 1986 gegründet. Praktiziert wird der Buddhismus im Stuttgarter Bohnenviertel gemäß der Tradition des Diamantweg der Karma-Kagyü-Linie. Das Zentrum ist eines von über 600 Zentren weltweit und steht unter der spirituellen Leitung des 17. Karmapa Trinley Thaye Dorje und Lama Ole Nydahl.

Der Verband "Die Humanisten Baden-Württemberg" ist Mitglied im Humanistischen Verband Deutschlands. Das Humanistische Zentrum Stuttgart bildet den Sitz des Landesverbandes und hat unter anderem eine Kindertagesstätte, deren Träger der Landesverband ist. Außerdem organisieren die Humanisten eine Jugendgruppe, führen Jugendfahrten sowie Kultur- und Bildungsveranstaltungen durch und bieten Namens- und Jugendfeiern sowie weltliche Hochzeits- und Trauerfeiern an.

Dem jüdisch-christlichen Dialog widmet sich die "Gesellschaft für Christlich-Jüdische Zusammenarbeit Stuttgart". Stuttgart war bis 2007 der Sitz des Dachverbandes christlich-islamischer Dialogorganisationen, des Koordinierungsrats des christlich-islamischen Dialogs (KCID). Auf örtlicher Ebene sind zwei seiner Mitgliedsorganisationen tätig.<ref name="CIG/CIBZ">Christlich-Islamische Gesellschaft Region Stuttgart und Gesellschaft für Christlich-Islamische Begegnung und Zusammenarbeit Stuttgart</ref>

"Siehe auch:" Runder Tisch der Religionen in Stuttgart, Kirchen in Stuttgart.

Aufgrund ihrer Lage ursprünglich bedeutendster Ort auf heutigem Stuttgarter Stadtgebiet war die Altenburg oberhalb der Neckarfurt im heutigen Cannstatt. Diese links des Neckars gelegene Höhe war bereits in vorgeschichtlicher Zeit besiedelt, und hier entstand um das Jahr 90 n. Chr. auch die älteste Siedlung in geschichtlicher Zeit auf heutigem Stuttgarter Stadtgebiet: Ein zur Sicherung der hier zusammenlaufenden Verkehrswege angelegtes römisches Reiterkastell (Kastell Cannstatt), in dem ein rund 500 Mann starker Kavallerieverband stationiert war. Um das Kastell bildete sich ein Dorf, das auch bestehen blieb, als das Kastell 159/160 n. Chr. mit dem Limes ostwärts verlegt wurde. Zu dem Dorf gehörte eine größere zivile Ziegelei, die neben Töpferwaren auch anspruchsvolle Baukeramik produzierte.

Mit dem Einfall der Alamannen um 260 n. Chr. endete die römische Präsenz. Es existieren neben vereinzelten alamannischen und merowingischen Funden – insbesondere im Gräberfeld von Stuttgart-Feuerbach – keine Überlieferungen aus der Völkerwanderungszeit, es erscheint aber plausibel, dass der günstig gelegene Ort durchgehend besiedelt war. So wird er auch bereits 700 n. Chr. als erster in der Gegend anlässlich einer Schenkung an das Kloster St. Gallen urkundlich erwähnt. Besondere Bedeutung für die Umgebung erlangte der Ort, dessen Bewohner ausweislich von Grabfunden bereits um 500 zum Christentum übergetreten waren, durch die zwischen 600 und 700 auf dem Gelände des heutigen Steigfriedhofs errichtete Martinskirche. Sie gehörte zum Bistum Konstanz und war Mutterkirche für den gesamten Raum.

Stuttgart selbst wurde vermutlich während der Ungarneinfälle (vergleiche Schlacht auf dem Lechfeld bei Augsburg) zwischen 926 und 948 im Nesenbachtal fünf Kilometer südwestlich der Altenburg als Gestüt („Stuotengarten“) gegründet. Archäologische Funde zeigen, dass auch hier bereits mindestens seit der späten Merowingerzeit eine bäuerliche Siedlung bestanden hatte. Gemeinhin wird die Gründung Herzog Liudolf von Schwaben zugeschrieben, was eher für einen Zeitraum nach 945 spricht. Der gewählte Standort war auf Grund der natürlichen Gegebenheiten des nach drei Seiten abgeschlossenen Talkessels für die Pferdezucht ideal, für die Entwicklung zu einer größeren Siedlung im Gegensatz zur Neckarfurt eher ungünstig. Seine später erreichte Bedeutung verdankt Stuttgart daher erst seiner Wahl zur Residenz.

Die Siedlung nahe dem Gestüt gelangte in den Besitz der Markgrafen von Baden, und Hermann V. von Baden erhob den Ort 1219 zur Stadt. 1251 kam Stuttgart als Mitgift für Mechthild von Baden an die Grafen von Württemberg. Eberhard I. errichtete ab 1292 eine Wasserburg. Im Konflikt mit Kaiser Heinrich VII., der zum Reichskrieg unter maßgeblicher Beteiligung der Reichsstadt Esslingen führte, ging Stuttgart an das Reich verloren, weswegen es 1312–1315 von Esslingen verwaltet wurde. Eberhard konnte die nach Heinrichs Tod entstandene politische Situation ausnutzen und die verlorenen Gebiete zurückerhalten. Da auch die Burg Württemberg 1311 durch Esslingen zerstört worden war, baute er ab 1317 das gegenüber der anhaltenden Bedrohung durch Esslingen günstiger gelegene Stuttgart unter Verstärkung der Befestigungen zur gräflichen Residenz im entstehenden württembergischen Territorialstaat aus. Aus Beutelsbach wurden Chorherrenstift und Grablege der Württemberger mit päpstlicher Genehmigung ebenfalls nach Stuttgart verlegt, die bisherige der Altenburger Martinskirche inkorporierte, d. h. unselbständige, Stadtkirche wurde als Stiftskirche erheblich erweitert. Schließlich unterstellte 1323 der Bischof von Konstanz auch die Martinskirche dem Stift, das deren Dekanatsfunktion übernahm. Spätestens damit hatte Stuttgart Cannstatt und die Altenburg an Bedeutung überflügelt. Bereits Ende des 14. Jahrhunderts entstand südöstlich außerhalb der Stuttgarter Stadtbefestigung eine erste Vorstadt: die Esslinger oder Leonhardsvorstadt, benannt nach der Leonhardskapelle, um die sie sich bildete. Ende des 15. Jahrhunderts wurde durch Ulrich V. im Nordwesten die geplant angelegte Obere Vorstadt geschaffen, in deren Zentrum ein Dominikanerkloster mit der heutigen Hospitalkirche errichtet wurde. Infolge der vorübergehenden Teilung Württembergs war Stuttgart 1442–1482 nur Hauptstadt eines Landesteils. Im Jahr 1457 fand in Stuttgart der erste nachweisbare Landtag der Württembergischen Landstände für den Stuttgarter Landesteil statt, wobei im selben Jahr in Leonberg ein Landtag für den Uracher Landesteil stattfand.

Mit der Erhebung Eberhards im Bart zum Herzog wurde Stuttgart 1495 Herzogsresidenz. Infolge der von Ulrich geführten Auseinandersetzungen mit Reutlingen und dem Schwäbischen Bund war die Stadt 1520–1534 wie ganz Württemberg habsburgisch, im Bauernkrieg war sie im Frühjahr 1525 einige Tage von Bauern besetzt. 1534 ließ Ulrich bei seiner Rückkehr durch Erhard Schnepf die Reformation einführen. Unter Herzog Christoph wurde um 1565 eine neue Stadtbefestigung errichtet, die die Vorstädte einschloss, die Burg wurde 1553–1570/78 von Aberlin Tretsch zu einem repräsentativen Renaissanceschloss umgebaut und erweitert, womit im Wesentlichen der Bauzustand des heutigen Alten Schlosses geschaffen wurde. Der gestiegene Trinkwasserbedarf Stuttgarts machte mit der Errichtung des Pfaffensees im Glemstal oberhalb von Stuttgart und dem Bau des Christophstollens zur Überleitung des Wassers ins Nesenbachtal 1566–1575 erhebliche wasserbauliche Maßnahmen notwendig. Zwischen 1584 und 1593 entstand das Neue Lusthaus. Um 1595 legte Heinrich Schickhardt den Vorläufer des heutigen Schillerplatzes an. Der Dreißigjährige Krieg hinterließ verheerende Spuren. Nach der Schlacht bei Nördlingen flohen der junge Herzog Eberhard, seine Räte und vier Mitglieder des Landschaftsausschusses ins Exil nach Straßburg. Die vierjährige direkte Herrschaft der Habsburger über Württemberg von 1634 bis 1638 hatte auch für Stuttgart ständige Belastungen durch Einquartierungen feindlicher Truppen zur Folge. König Ferdinand III. kam 1634 und 1636 mehrmals nach Stuttgart und plante die Rekatholisierung Württembergs. 1637 wütete die Pest in Stuttgart. Die Bevölkerung halbierte sich von einem Vorkriegsstand von etwa 10.000 Personen auf unter 5000 Personen im Jahre 1648. Darunter waren nur noch 600 Männer. 1650 eröffnete eine erste Buchhandlung. 1686 entstand das erste Gymnasium. 1688 tauchten im Rahmen des Pfälzischen Erbfolgekriegs französische Truppen unter General Melac vor den Toren der Stadt auf. Dank der Diplomatie der regierenden Herzoginwitwe Magdalena Sibylla blieb Stuttgart das Schicksal Heidelbergs erspart, das in diesem Krieg zerstört wurde. Herzog Eberhard Ludwig verlegte 1718 seine Residenz nach Ludwigsburg, wo das 1704 bis 1733 erbaute Barockschloss entstand. Erst unter Herzog Karl Alexander erlangte Stuttgart wieder seine alte Stellung als Hauptresidenz zurück. Nach dem Tod des Herzogs Karl Alexander vollzog sich der antisemitische Justizmord an dessen Finanzberater Joseph Süß Oppenheimer. 1744 wurde Herzog Carl Eugen für mündig erklärt. 1746 legte dieser den Grundstein zur Errichtung des Neuen Schlosses. Weitere Bauprojekte umfassten die Schlösser Solitude und Hohenheim. Außerdem wurde mit der Errichtung der Hohen Karlsschule Stuttgart am Ende des 18. Jahrhunderts kurzzeitig Universitätsstandort. Ein berühmter Zögling dieser Anstalt war Friedrich Schiller, der dort Medizin studierte. Dennoch war Stuttgart noch am Ende des 18. Jahrhunderts eine sehr provinzielle Stadt mit engen Gassen, Viehhaltung, ackerbautreibender Bevölkerung und etwa 20.000 Einwohnern, wobei hierbei Bedienstete bei Hofe und das Militärpersonal der Württembergischen Armee nicht eingerechnet sind. Aus Gründen der Sparsamkeit und aus Angst vor der Entstehung revolutionären Gedankenguts wurde die Hohe Karlsschule bereits 1794 unter Herzog Ludwig Eugen wieder aufgelöst.

1806 erlangte Stuttgart im Zuge der Napoleonischen Kriege und der Gründung des Rheinbunds eine Rangerhöhung. Die bisherige Residenzstadt des altwürttembergischen Herzogtums stieg nun zur Hauptstadt des um die Gebiete Neuwürttembergs erweiterten Königreichs Württemberg auf. Nachdem die Existenz des neuen württembergischen Staates mit dem Abschluss des Wiener Kongresses 1815 endgültig bestätigt worden war, erlebte Stuttgart im 19. Jahrhundert seinen allmählichen Aufstieg von der bisherigen Enge einer vom evangelischen Pietismus geprägten Kleinstadt zur gemischtkonfessionellen Metropole Württembergs.

Das erste Cannstatter Volksfest fand 1818 statt, und 1820 entstand die Grabkapelle auf dem Württemberg an der Stelle der alten württembergischen Stammburg. Am Anfang des 19. Jahrhunderts entstanden Bauwerke wie das Schloss Rosenstein, das Wilhelmspalais, die Staatsgalerie und der Königsbau. Bildungseinrichtungen wie die 1818 gegründete Ackerbauschule, die 1829 gegründete Vereinigte Real- und Gewerbeschule sowie die 1857 gegründete Stuttgarter Musikschule gehen auf das frühe und mittlere 19. Jahrhundert zurück. Die Tradition Stuttgarts als Stadt der Literatur wurde im 19. Jahrhundert durch zahllose Schriftsteller repräsentiert, die dort wohnten. Namen wie Wilhelm Hauff, Ludwig Uhland, Gustav Schwab und Eduard Mörike sind von überregionaler Bedeutung.

Beim Landesfest zum 25. Regierungsjubiläum König Wilhelms I. am 28. September 1841 gab es einen Umzug durch Stuttgart mit 10.390 Teilnehmern sowie 200.000 Zuschauern. Die erst 1863 fertiggestellte Jubiläumssäule von Johann Michael Knapp erinnert noch heute an dieses Ereignis.
Am 22. Oktober 1845 fuhr die erste württembergische Eisenbahn von der Oberamtsstadt Cannstatt nach Untertürkheim, ab 15. Oktober 1846 auch durch den Rosensteintunnel bis nach Stuttgart (Alter Centralbahnhof beim Schlossplatz).

Ende Mai 1849 nach der Ablehnung der Reichsdeputation durch den preußischen König Friedrich Wilhelm IV. übersiedelte die Frankfurter Nationalversammlung auf Einladung des württembergischen Justizministers Friedrich Römer nach Stuttgart. Das sogenannte Rumpfparlament tagte allerdings nur bis zum 18. Juni, als es gewaltsam aufgelöst wurde.

Internationale Beachtung fand das im Jahre 1857 abgehaltene Zwei-Kaiser-Treffen.

Im Zuge der beginnenden Industrialisierung wuchs die Einwohnerzahl des heutigen Stuttgarts stetig an. 1834 zählte Stuttgart 35.200 Einwohner, 1852 wurde die 50.000-Einwohner-Marke überschritten, 1864 lebten in Stuttgart 69.084 Einwohner, und im Jahr der Reichsgründung, 1871, hatte die Stadt 91.000 Einwohner. 1874 wurde Stuttgart mit der Überschreitung der 100.000-Einwohner-Marke zur Großstadt. Diese Zahl verdoppelte sich, auch durch Eingemeindungen, bis kurz nach der Jahrhundertwende (1901: etwa 185.000, 1904: etwa 200.000).

Ausmaß und Tempo des Einwohnerwachstums in der zweiten Hälfte des 19. Jahrhunderts waren innerhalb des heutigen Stadtgebiets sehr unterschiedlich. Enormes Wachstum war von 1851 bis 1900 in der Residenzstadt (+248 %) nebst Gaisburg (+428 %) und in (Bad) Cannstatt (+298 %) zu verzeichnen. Zu Wachstumsmagneten entwickelten sich auch die aufkommenden Industriestandorte entlang der neuen Eisenbahnlinien Cannstatt–Untertürkheim–Obertürkheim–Esslingen und Cannstatt–Stuttgart–Feuerbach–Zuffenhausen–Ludwigsburg. Ab 1879 kam die Gäubahn Stuttgart–Freudenstadt hinzu, und in Vaihingen und Rohr setzte nun auch ein sprunghaftes Bevölkerungswachstum ein. Schließlich kam es mit der Umgehungsstrecke Untertürkheim–Kornwestheim (Schusterbahn) auch in Münster Ende des 19. Jahrhunderts zu einem starken Wachstum der Einwohnerzahlen.
In den 1880er und 1890er Jahren legte Gottlieb Daimler (1834–1900) in Cannstatt bei Stuttgart die Grundlagen für die ersten Automobile. 1887 gründete er dort die Daimler-Motoren-Gesellschaft. Nach einem Brand der Werksanlagen entstand ab 1903 auf Untertürkheimer Gemarkung das neue Motorenwerk, wo jetzt auch wieder der Konzernsitz der heutigen Daimler AG ist.

Im Jahr 1907 fand in Stuttgart ein Internationaler Sozialistenkongress statt. An der Eröffnung nahmen 60.000 Menschen teil.

Im Jahr 1914 wurde am nördlichen Ende der Innenstadt mit dem Bau des heutigen Bahnhofsgebäudes nach dem Entwurf des Architekten Paul Bonatz begonnen.

Im Ersten Weltkrieg kam es zu Luftangriffen auf die Stadt: Am 22. September 1915 fielen die meisten Bomben, nämlich 29, im Bereich des Bahnhofs und der nahegelegenen Rotebühlkaserne, dabei wurden drei Soldaten getötet und 43 verletzt. Ebenso starben vier Zivilisten. Beim zweiten großen Angriff am 15. September 1918 starben beim Einsturz eines Hauses in der Heusteigstraße, der durch vorangegangenen Pfusch am Bau mitverursacht wurde, elf Menschen.

Am 30. November 1918 wurde das Königreich Württemberg im Zuge der Ereignisse der Novemberrevolution in den deutschen Ländern, nach dem Verzicht König Wilhelms II. auf die Krone (Revolutionäre stürmten seine Residenz, das Wilhelmspalais), zum freien Volksstaat Württemberg innerhalb der Weimarer Republik. Am 26. April 1919 gab sich das Land eine neue Verfassung, die in überarbeiteter Form endgültig am 25. September 1919 von der Verfassunggebenden Landesversammlung verabschiedet wurde.

1920 war die Stadt für wenige Tage Sitz der Reichsregierung (siehe Kapp-Putsch).

Durch die Gleichschaltung der württembergischen Verwaltung und die Zentralisierung Deutschlands zu Beginn der Zeit des Nationalsozialismus 1933 wurde Stuttgart in seiner Stellung als Landeshauptstadt politisch zwar bedeutungslos, blieb aber das kulturelle und wirtschaftliche Zentrum im mittleren Neckarraum. Württemberg wurde mit den Hohenzollernschen Landen zum "Gau der NSDAP Württemberg-Hohenzollern" zusammengefasst.

Während der Zeit des Nationalsozialismus führte die Stadt den Ehrentitel "„Stadt der Auslandsdeutschen“" (siehe Stadt-Ehrentitel der NS-Zeit).

Die Gestapo übernahm das Hotel Silber in der "Dorotheenstraße", in dem politische Gegner des Regimes inhaftiert und gefoltert wurden. „Das Silber“ wurde auch für zahlreiche Prominente Durchgangslager in Konzentrationslager bzw. zur Ermordung, zum Beispiel für Eugen Bolz, Kurt Schumacher oder Lilo Herrmann. Der Letzteren errichtete 1988 eine Studenten- und Bürgergruppe zwischen den "Kollegiengebäuden" in der "Keplerstraße" einen Gedenkstein. Das NS-Gewaltregime benutzte weiterhin das Landgericht in der "Archivstraße 12A" als zentrale Hinrichtungsstätte im südwestdeutschen Raum, in dem mindestens 419 Menschen das Leben genommen wurde. Daran erinnert ein Mahnmal im Lichthof.
Beim Novemberpogrom 1938 wurden die Alte Synagoge niedergebrannt und die Friedhofskapelle der Jüdischen Gemeinde zerstört. Der Großteil der männlichen jüdischen Bürger Stuttgarts wurde unmittelbar danach von der Gestapo verhaftet und in das Polizeigefängnis Welzheim oder in das KZ Dachau verbracht. Seit dem Jahre 1947 erinnert auf dem israelitischen Teil des "Pragfriedhofs" an der "Friedhofstraße 44" ein Mahnmal von dem Bildhauer K. Löffler an die 2498 in der Shoa umgekommenen Juden Württembergs.

An die Deportation der Stuttgarter Juden nach 1939 erinnert das Mahnmal am Nordbahnhof. Bis zum Verbot der Auswanderung am 1. Oktober 1941 konnten nur rund 60 Prozent der deutschen Juden fliehen. Die dann noch in Württemberg und Hohenzollern lebenden Juden wurden während des Krieges gezwungen, in sogenannte Judenwohnungen bzw. jüdische Zwangsaltersheime umzuziehen, dann wurden sie von der Stapoleitstelle Stuttgart auf dem Messegelände Killesberg „konzentriert“. Am 1. Dezember 1941 fuhr der erste Transportzug mit rund 1000 Menschen nach Riga, wo sie ermordet wurden. Bis in die letzten Kriegswochen folgten weitere Züge mit rund 2500 Juden aus der Region. Lediglich 180 dieser württembergischen KZ-Häftlinge überlebten.
Gegen Ende des Zweiten Weltkrieges wurden weite Teile der Stadt bei den anglo-amerikanischen Luftangriffen auf Stuttgart zerstört. Der schwerste Angriff erfolgte am 12. September 1944 durch die britische Royal Air Force auf die Stuttgarter Altstadt. Dabei wurden 75 schwere Luftminen, 4300 Sprengbomben und 180.000 Brandbomben abgeworfen. Dem anschließend entstehenden Feuersturm fielen mehr als 1000 Menschen zum Opfer.
Insgesamt wurde Stuttgart 53-mal angegriffen. Dabei wurden 68 % aller Wohngebäude und 75 % der industriellen Anlagen zerstört. Insgesamt wurden in Stuttgart 4477 Menschen getötet und 8908 Menschen verletzt. Am 21. April 1945 besetzten französische Truppen Stuttgart.

Im Anschluss an die Besetzung Stuttgarts durch französische Besatzungstruppen kam es zu mindestens 1389 Vergewaltigungen in Stuttgart. Am 8. Juli 1945 übergaben die französischen Besatzungstruppen Stuttgart nach mehrfacher Aufforderung an US-Soldaten; ab dann gehörte die Stadt zur amerikanischen Besatzungszone. Stuttgart war die Hauptstadt des von 1945 bis 1952 bestehenden Landes Württemberg-Baden.

Die Militärverwaltung richtete in Stuttgart DP-Lager ein zur Unterbringung sogenannter Displaced Persons (DP). Die meisten DPs waren ehemalige Zwangsarbeiter aus Mittel- und Osteuropa in den Industriebetrieben der Region. Das DP-Lager "Stuttgart-West" beherbergte ausschließlich mehr als 1400 jüdische Überlebende des Holocaust. Das Lager wurde 1949 geschlossen, die verbliebenen DPs wurden in ein DP-Lager in Heidenheim an der Brenz verlegt.

Die Bewerbung der Stadt im Jahre 1948 als neue Hauptstadt der noch zu gründenden Bundesrepublik scheiterte in erster Linie an den finanziell hohen Belastungen (eine Million DM jährlich für Mieten). Neben Stuttgart hatten sich auch die Städte Frankfurt am Main, Kassel und Bonn beworben; eine Kommission des Parlamentarischen Rates hatte zuvor alle Städte auf ihre Eignung geprüft.

In den Nachkriegsjahren wurde insbesondere auf ideologisches Betreiben des neuen Oberbürgermeisters Arnulf Klett beim Wiederaufbau auf historische Rekonstruktionen, vor allem am baukulturell bedeutsamen Stuttgarter Marktplatz, weitgehend verzichtet. Große Teile der Ruinen der Stadt kamen daher auf den Trümmerberg Birkenkopf. Der Wiederaufbau erfolgte überwiegend nach modernistischen Idealen und der Charta von Athen mit funktionalen Trennungen nach Wohn-, Geschäfts- und Industriegebieten. Die Idee war, eine autogerechte Stadt zu schaffen. So wurden auch ganze Straßenzüge und Plätze abgerissen, die nicht oder kaum beschädigt waren. Im 150. Todesjahr von Friedrich Schiller wurden 1955 die letzten Reste seiner alma mater, der Hohen Karlsschule in der Nähe des Neuen Schlosses, abgetragen, um für die Verbreiterung der Bundesstraße 14 (Konrad-Adenauer-Straße) Platz zu schaffen. Diese rigorose Baupolitik wurde bereits von Zeitgenossen teils scharf kritisiert.

Am 25. April 1952 wurde Württemberg-Baden mit dem Land Baden und dem Land Württemberg-Hohenzollern vereinigt. Seither ist Stuttgart die Hauptstadt des Bundeslandes Baden-Württemberg.
Seit den 1950er Jahren ist Stuttgart die zweitgrößte Stadt Süddeutschlands (vor Nürnberg). Im eigenen Bundesland liegt Stuttgart mit einigem Abstand vor Karlsruhe und Mannheim.
Die Bevölkerung, die in den letzten Kriegsjahren vor allem durch Evakuierung, Flucht und Luftangriffe um fast die Hälfte zurückgegangen war (April 1942: etwa 498.000, April 1945: etwa 266.000), wuchs durch den Zustrom Heimatvertriebener aus den ehemals deutschen Ostgebieten in den späten 1940er und den 1950er Jahren wieder massiv an. 1962 erreichte die Stadt mit etwa 640.000 ihren bisher höchsten Einwohnerstand. In den späten 1950er und frühen 1960er Jahren kamen als Folge des Arbeitskräftemangels und des Wirtschaftswunders im Nachkriegs-Westdeutschland auch die ersten Gastarbeiter in die Region Stuttgart. Diese stammten zunächst vorwiegend aus Italien, später auch aus Griechenland und ein Großteil aus dem damaligen Jugoslawien, ab den 1970er Jahren auch aus der Türkei.

Große Medienereignisse waren die Staatsbesuche des französischen Staatspräsidenten Charles de Gaulle am 9. September 1962 sowie der britischen Königin Elisabeth II. am 24. Mai 1965 in Stuttgart.

Die zwischen 1959 und 1963 in Stammheim errichtete Justizvollzugsanstalt Stuttgart wurde 1975 im Zuge des am Oberlandesgericht Stuttgart abgehaltenen Stammheim-Prozesses gegen führende Mitglieder der linksextremistischen Terrororganisation RAF um einen Hochsicherheitstrakt erweitert. Andreas Baader, Ulrike Meinhof, Gudrun Ensslin und Jan-Carl Raspe waren von 1975 bis zu ihren Suiziden am 9. Mai 1976 (Meinhof) bzw. 18. Oktober 1977 (Todesnacht von Stammheim) in diesem Teil des Gefängnisses von Stuttgart-Stammheim inhaftiert. (siehe auch Deutscher Herbst).

Am 1. Oktober 1978 begann die S-Bahn in Stuttgart auf drei Strecken mit dem planmäßigen Betrieb. 1979 wurden 178 Millionen Fahrgäste befördert. Die Zahl stieg bis 2002 auf etwa 300 Millionen an. (Siehe hierzu auch "Verkehr")

Vom 17. bis zum 19. Juni 1983 versammelten sich in Stuttgart die Staats- und Regierungschefs der EG zu einem Gipfeltreffen.

Die Leichtathletik-Europameisterschaften wurden 1986 im Neckarstadion ausgetragen.

Ein weiteres mediales Großereignis war der Besuch Michael Gorbatschows am 14. Juni 1989, als dessen Höhepunkt ein großer Empfang im Neuen Schloss stattfand.

1993 war Stuttgart Gastgeber der Internationalen Gartenbauausstellung und der Leichtathletik-Weltmeisterschaften.

Eine Bewerbung der Stadt um die Olympischen Spiele 2012 scheiterte 2003 bereits in der nationalen Vorauswahl, als sich das NOK für Leipzig entschied.

2006 war Stuttgart, wie auch schon 1974, einer der Austragungsorte der Fußballweltmeisterschaft, unter anderem fand hier das Spiel um Platz 3 statt.

Im Sommer 2010 geriet die Stadt wegen der Proteste gegen das Bahnprojekt Stuttgart 21 ins Blickfeld einer breiten Öffentlichkeit.

Stuttgarts heutiger Gebietsstand ist das Ergebnis mehrerer Eingemeindungswellen. Der Bereich des inneren Stadtgebiets war mit der Eingemeindung von Gaisburg (1901) zu Beginn des 20. Jahrhunderts im Wesentlichen abgeschlossen; die spätere Eingemeindung Kaltentals (1922) und die Zuordnung des Frauenkopfs (von Rohracker 1948) rundeten schließlich die Gebietsfläche des inneren Stadtgebiets ab.

Alle Eingemeindungen ab 1905 bildeten dann nach und nach die Gebietsflächen des äußeren Stadtgebiets. Am 1. April 1942 waren die Eingemeindungen mit der zwangsweisen Zuordnung Stammheims und der südlichen Fildervororte abgeschlossen. In der Nachkriegszeit kamen, auch während der großen Gebietsreform in Baden-Württemberg Mitte der 1970er Jahre, keine weiteren Eingemeindungen hinzu.

In Zeiten der Grafschaft beziehungsweise des Herzogtums Württemberg wurde die Verwaltung der Stadt Stuttgart von einem "Vogt" geleitet. Dieser wurde vom Graf beziehungsweise Herzog in sein Amt eingesetzt und konnte von diesem auch nach Belieben entlassen werden. Nach Aufteilung der Verwaltung in ein Stadtoberamt und ein Amtsoberamt (für das Umland) wurden beide Behörden jeweils von einem "Stadtoberamtmann" beziehungsweise Amtsoberamtmann geleitet. Ab 1811 erhielt der leitende Verwaltungsbeamte der Stadt die Bezeichnung "Stadtdirektor".

Nach Einführung des Selbstverwaltungsrechts der Gemeinden im zum Königreich erhobenen Württemberg im Jahre 1819 erhielten die Städte und Gemeinden ein gewisses Mitspracherecht bei der Bestellung des Ortsvorstehers, der künftig die Bezeichnung "Schultheiß", in Städten "Stadtschultheiß" trug. Oberbürgermeister war seinerzeit in Württemberg lediglich eine besondere Bezeichnung, die der König verleihen konnte. Sie wurde nicht allen Stadtschultheißen in Stuttgart verliehen. Erst mit Inkrafttreten der Württembergischen Gemeindeordnung von 1930 wurde der Titel Oberbürgermeister offiziell für alle Städte mit mehr als 20.000 Einwohnern eingeführt.

Nach 1918 verlor die Stadt mit der Auflösung des Königreichs Württemberg ihre Bedeutung als Residenzstadt; sie wurde Hauptstadt des Volksstaates Württemberg innerhalb des als Weimarer Republik bezeichneten Deutschen Reiches. Während des Kapp-Putsches im März 1920 war Stuttgart für einige Tage Sitz der Reichsregierung.

Nach dem Zweiten Weltkrieg war Stuttgart erst Hauptstadt des Landes Württemberg-Baden und ist seit 1952 Hauptstadt Baden-Württembergs.

Schon sehr frühzeitig nach Kriegsende fanden in der amerikanisch besetzten Zone die ersten Gemeinderatswahlen statt. In Stuttgart fiel der Wahltag auf den 26. Mai 1946. Noch vor Ablauf der zweijährigen Wahlperiode fand am 7. Dezember 1947 die zweite Gemeinderatswahl, mit einer sechsjährigen Wahlperiode, statt. Von 1947 bis 1971 wurde jeweils im 3-Jahre-Abstand die Hälfte des Gemeinderats (30) gewählt („rollierendes System der Erneuerungswahlen“). Die Amtszeit der Gemeinderäte betrug sechs Jahre. Seit 1975 wird der gesamte Gemeinderat für fünf Jahre gewählt.

Das Wahlsystem in Stuttgart ist ein Verhältniswahlsystem, bei dem der Wähler durch das Kumulieren (Stimmenhäufung auf einen Kandidaten bis zu drei Stimmen) und das Panaschieren (Zusammenstellen der Namen aus verschiedenen Listen) sehr weitreichende Einflussmöglichkeiten bei der Stimmabgabe hat. Insgesamt stehen jedem Wähler so viele Stimmen zur Verfügung wie Gemeinderäte zu wählen sind (60). Bei der Sitzverteilung kommt seit 2014 das Sainte-Laguë-Verfahren zum Einsatz. Eine Sperrklausel existiert nicht.

Ergebnis der Kommunalwahl 2014 mit Sitzverteilung:

Im aktuellen Gemeinderat im Rathaus Stuttgart bilden SÖS und Die Linke zusammen mit den beiden Räten von der Piratenpartei und der Studentischen Liste die Fraktionsgemeinschaft SÖS-LINKE-PluS. Fraktionsstatus hat man gemäß der Geschäftsordnung des Stuttgarter Gemeinderates ab vier Mandaten. Der Stadtrat der Stadtisten (1) bildet mit SÖS-LINKE-PluS eine „Zählgemeinschaft“. Damit sind Mandatsträger, die keiner Fraktion angehören, in den beschließenden Ausschüssen vertreten. Die AfD erhielt im Januar 2015 durch den Übertritt eines FDP-Stadtrates Fraktionsstatus, die FDP verlor ihn. Die AfD Fraktion zerfiel zwischenzeitlich und hat sich in "Bündnis Zukunft Stuttgart 23" umbenannt, die AfD wird nur noch durch einen Einzelabgeordneten vertreten.

Am 21. Oktober 2012 wurde Fritz Kuhn zum Oberbürgermeister gewählt. Er hat das Amt am 7. Januar 2013 übernommen.

In allen 23 Stadtbezirken gibt es – teilweise seit 1995 – die Möglichkeit, Jugendräte zu bilden. Aktuell gibt es 12 Gremien in 15 Bezirken. In Bezirken, in denen sich zu wenige Kandidaten gemeldet hatten, existieren Projektgruppen. Wahlberechtigt und wählbar sind alle Jugendlichen zwischen 14 und 18 Jahren, die seit mindestens drei Monaten im Stadtbezirk wohnen. Die Anzahl der Sitze richtet sich nach der Einwohnerzahl. Die Amtszeit beträgt zwei Jahre, die letzten Wahlen fanden vom 18. Januar bis 5. Februar 2016 statt. Jedes der Jugendratsgremien entsendet drei, jede der aktiven Projektgruppen einen Delegierten in den gesamtstädtischen "Arbeitskreis Stuttgarter Jugendrat". Er wählt aus seinen Reihen drei gleichberechtigte Sprecher, die ihn repräsentieren, sowie weitere Vertreter in verschiedene Ausschüsse der Stadt.

Das Wappen der Stadt Stuttgart zeigt ein steigendes schwarzes Pferd – das sogenannte „Stuttgarter Rössle“ – in goldenem Feld. Das Wappen ist in seiner heutigen Form seit dem 11. April 1938 im amtlichen Gebrauch. Die Stadtfarben sind Schwarz-Gelb. Die Stadtflagge wurde am 10. Juli 1950 vom württemberg-badischen Ministerrat verliehen.

Die erste noch erhaltene Abbildung des Stuttgarter Stadtwappens stammt aus dem Stadtsiegel des Jahres 1312. Sie zeigt zwei ungleich große (heraldisch) nach rechts schreitende Pferde im früh- und hochgotischen Dreieckschild. Im Stadtsiegel von 1433 wurde die Form des Stadtwappens geändert. Der Wappenschild zeigt ein (heraldisch) nach rechts galoppierendes Pferd im spätgotischen Rundschild. Diese Wappenform diente im Wesentlichen als amtliches Stuttgarter Stadtwappen bis ins 19. Jahrhundert. Dabei wurde die Darstellung des Pferdes im Laufe der Jahre mehrfach geändert. Es wurde schreitend, laufend, galoppierend, springend, steigend und aufgerichtet dargestellt. 1938 setzte sich die heutige Form durch. Ursprünglich war seine Grundfarbe Silber, erstmals 1699 nach einem Wappenbuch Gold. Diese Farbe setzte sich allmählich in Anlehnung an die württembergischen Hausfarben in der zweiten Hälfte des 19. Jahrhunderts durch. Es ist ein „redendes“ Wappen, das heißt, das ursprüngliche Gestüt, auf das die Stadt zurückgehen soll, wird hier versinnbildlicht.

Der Sportwagenhersteller Porsche – beheimatet in Stuttgart-Zuffenhausen – führt das Stadtwappen in leicht abgeänderter Form in seinem Firmenlogo. Die Ähnlichkeit des Wappens mit dem des italienischen Sportwagenherstellers Ferrari ist hingegen zufällig: Es geht zurück auf Francesco Baracca, den erfolgreichsten italienischen Jagdflieger im Ersten Weltkrieg. Dieser schmückte seinen Flieger mit einem aufbäumenden Pferd, das er von dem Wappen des Kavallerieregiments, in dem er zuvor gedient hatte, dem „Reggimento Piemonte Reale Cavalleria“, abgeleitet hatte. Die Mutter Baraccas gab Enzo Ferrari die Anregung, das Symbol als Glücksbringer auf seinen Autos zu verwenden. Dies setzte Ferrari ab 1932 in die Tat um. Das schwarz gehaltene Pferd unterlegte er dabei mit der gelben Wappenfarbe seiner Heimatstadt Modena. In dieser Zusammensetzung entstand ein Wappen, das mit jenem Stuttgarts große Ähnlichkeiten aufweist.

"Siehe auch:" Liste der Wappen der ehemaligen Städte und Gemeinden in Stuttgart

Stuttgart gehörte zu den Pionieren beim Thema Städtepartnerschaft im Nachkriegseuropa. Bereits drei Jahre nach dem Ende des Zweiten Weltkriegs schloss die Stadt eine Partnerschaft mit St. Helen’s im Land des ehemaligen Kriegsgegners Großbritannien. Heute unterhält Stuttgart Städtepartnerschaften mit folgenden zehn Städten auf vier Kontinenten:

Zusätzlich werden folgende Städtefreundschaften unterhalten:

Im Zuge der deutsch-französischen Freundschaft ist der Stadtbezirk Zuffenhausen schon seit 1977 mit der französischen Stadt La Ferté-sous-Jouarre verbunden, Vaihingen seit 1985 mit Melun. Bad Cannstatt unterhält zudem seit 1996 eine Partnerschaft zu dem ähnlich mineralwasserreichen Újbuda, dem XI. Bezirk von Budapest, Ungarn.

Diese Städte finden sich in nach ihnen benannten Wegen oder Brücken wieder.

Die Staatstheater Stuttgart sind mit ihren Sparten Oper Stuttgart, Stuttgarter Ballett und Schauspiel Stuttgart der größte Drei-Sparten-Theaterbetrieb der Welt. Die Hauptspielstätten befinden sich im Oberen Schlossgarten und wurden 1909 bis 1912 vom Münchner Architekten Max Littmann als Königliche Hoftheater erbaut: Weitgehend original erhalten ist das Opernhaus (früher „Großes Haus“), das Schauspielhaus (früher „Kleines Haus“) wurde im Zweiten Weltkrieg zerstört und 1959 bis 1962 durch einen Neubau nach Entwürfen von Hans Volkart an gleicher Stelle ersetzt. Darüber hinaus gehören das Kammertheater (eröffnet 1983) und die Studiobühne Nord (eröffnet 2010) zu den Spielstätten der Staatstheater. An den Staatstheatern finden pro Spielzeit insgesamt fast tausend Aufführungen statt. Die Oper Stuttgart wurde insgesamt sechsmal zum Opernhaus des Jahres gewählt. Das Stuttgarter Ballett ist eine der weltweit führenden Ballett-Kompagnien.

Die Schauspielbühnen Stuttgart bestehen aus den Spielstätten "Das Alte Schauspielhaus" sowie "Komödie im Marquardt". Das Alte Schauspielhaus wurde 1909 auf dem Gelände einer ehemaligen Kaserne errichtet und war bis zur Wiedereröffnung des Kleinen Hauses der Staatstheater 1962 das renommierteste Theater der Stadt. Die Komödie im Marquardt wurde 1951 im ehemaligen Hotel Marquardt gegründet und dient in erster Linie der komödiantischen Unterhaltung. Die Schauspielbühnen in Stuttgart sind die Sprechtheater mit den höchsten Zuschauerzahlen in Baden-Württemberg und gehören damit zu den Top fünf der deutschen Sprechtheater.

Seit über 20 Jahren besteht das „FITZ“ – Zentrum für Figurentheater im Kulturareal „Unterm Turm“, in dem sich seit 2003 auch das JES – Junges Ensemble Stuttgart – befindet. Weiterhin findet man hier das Theater tri-bühne.

Im Jugend- und Kulturzentrum Forum 3 hat das freie Forum Theater seinen Sitz. In erster Linie sind hier dramatisch-theatralische Inhalte zu sehen.

Das Friedrichsbau Varieté wurde 1994 in einer Rotunde im Neubau des Friedrichsbaus auf historischem Grund wieder ins Leben gerufen, nachdem der prunkvolle Jugendstilbau im Zweiten Weltkrieg vollständig ausgebrannt war. Nach Kündigung durch den Eigentümer L-Bank zog das Theater im Jahr 2014 an den Pragsattel.

Einen bundesweit einzigartigen und besonderen Stellenwert hat in Stuttgart die Kunst der Pantomime. Dieses begründet sich durch das Pantomimetheater Makal City Theater GmbH, das als Gastspiel- und Tourneetheater zu sehen ist, sowie das Internationale Pantomimetheater, das mit ganzjährigen Pantomime-Veranstaltungen und Aufführungen mit Schwarzem Theater seine Heimat im Stuttgarter Osten hat. Darüber hinaus bietet sich dort die Möglichkeit, die Kunst des Pantomimespiels auf professionellem Niveau zu erlernen. Begründer der Pantomime in Deutschland ist der Meisterpantomime Peter Makal „"Ambassador of Art"“.

Die Kabarettbühne Rosenau im Stuttgarter Westen kann auf eine lange und traditionsreiche Geschichte zurückblicken. Sie dient außerdem als Nachwuchsbühne im Bereich Kabarett, Comedy und Kleinkunst. Aufgrund der besonderen Verbindung von kulturellem und kulinarischem Angebot, wird die Rosenau auch als „Wohnzimmer des Westens“ bezeichnet.

Das überregional bekannteste literarische Kabarett Stuttgarts ist das Renitenztheater. Es wurde 1961 gegründet und ist damit die älteste Kabarettbühne der Stadt.

Die Puppenspieler im „Theater am Faden“ lassen seit 1972 die Puppen und Marionetten tanzen, die sie oft selbst hergestellt haben. Weitere Figurentheater sind das „Theater in der Badewanne“ im Höhenpark Killesberg sowie das „Theater Tredeschin“ in der Haußmannstraße. Als Stabpuppentheater bezeichnet sich das „Theater La-Plapper-Papp“ seit 1960.

Das Theater der Altstadt im Westen ist in der Rotebühlstraße zu finden, nachdem der erste Holzbau bereits 1969 und somit elf Jahre nach Bau ausgebrannt war.

Nellys Puppen-Theater spielt mit Puppen und Marionetten für Kinder ab drei Jahren. Im selben Haus spielt das Theater am Olgaeck, das einen Schwerpunkt auf den kulturellen Austausch mit Osteuropa setzt.

Das Theaterhaus Stuttgart führte ab 1984 im Stadtteil Wangen sein Dasein – seit 2000 am Pragsattel, hier wird auch jährlich der Stuttgarter Theaterpreis vergeben. Seit 2008 hat das Theaterhaus mit Gauthier Dance eine feste Ballettkompanie.

Eine Plattform für die freischaffende Tanz- und Performancekunst in Stuttgart bietet das Produktionszentrum Tanz und Performance im alten Felsenkeller in Stuttgart Feuerbach.

Der „Treffpunkt Rotebühlplatz“ ist vorwiegend für Tanz, Theater, das internationale Solo-Tanz-Theater-Festival und Neue Musik bekannt.

Die Staatliche Hochschule für Musik und Darstellende Kunst Stuttgart unterhält in Bad Cannstatt das Wilhelma-Theater.

Unweit des Wilhelma-Theaters liegt seit 2008 das Theaterschiff an der Anlegestelle Mühlgrün in Bad Cannstatt. Auf dem umgebauten Binnenfrachtschiff sind hauptsächlich Komödien und Kabarett zu sehen.

In der Werastraße findet man das „Wortkino“.

Das älteste Amateurtheater Stuttgarts, das ABV-Zimmertheater (gegründet 1921, die Theaterabteilung des Allgemeinen Bildungsvereins 1863 e. V. Stuttgart) spielt im Gebäude des ehemaligen Landtages in der Heusteigstraße.

Schwäbisches Volkstheater spielen neben anderen das „Boulevärle“, das „Stuttgarter Komödle“, „d'Scheureburzler“ und das „Neugereuter Theäterle“.

Im SI-Centrum sind zwei Musical-Theater untergebracht – das „Palladium Theater“ und das „Apollo Theater“. Hier gab es unter anderem die Deutschland-Premieren von "Miss Saigon" (1999), "Tanz der Vampire" (2000), "Die Schöne und das Biest" (2000), "42nd Street" (2004), "Wicked – Die Hexen von Oz" (2010) und "Rebecca" (2013) zu sehen. Aktuell wird das Musical "Mary Poppins" aufgeführt.

Das Kulturzentrum Merlin bietet Kulturprogramm in den Sparten Musik, Kabarett, Theater, Performance, Literatur, Kurzfilm und Kindertheater.

In Stuttgart befinden sich fünf der elf staatlichen Museen Baden-Württembergs, so die Alte und Neue Staatsgalerie. Eröffnet um 1843 und 1984 um den Neubau erweitert, genießt die Staatsgalerie europäische Aufmerksamkeit. Kunst vom 14. Jahrhundert bis in die Moderne ist in den architektonisch interessanten Räumlichkeiten zu betrachten, darunter Werke von Cranach dem Älteren, Rubens, Rembrandt, Monet, Renoir, Cézanne, Picasso und Beuys.

Im Alten Schloss ist das Landesmuseum Württemberg beherbergt. 1862 von Wilhelm I., König von Württemberg, gegründet, reichen seine Wurzeln jedoch bis ins 16. Jahrhundert zurück, in dem die damaligen Herzöge alles was selten, kostbar und ungewöhnlich war, sammelten. Es wird die Landesgeschichte von der Steinzeit bis in die Neuzeit dargestellt. Neben der Zentrale gibt es zwei weitere Zweigstellen in Stuttgart sowie acht Zweigstellen in Baden-Württemberg.

Das Haus der Geschichte Baden-Württemberg wurde 1987 gegründet. Es erhielt im Jahr 2002 auf der Stuttgarter Kulturmeile einen eigenen Museumsbau. Landesgeschichte, landestypische Gegenstände und ein Themenpark, der Probleme der Gegenwart in einen historischen Kontext stellt, sind die drei wichtigsten Themenbereiche. Das Haus der Geschichte unterhält fünf Zweigstellen im Land.

Natur- und Fossilkunde sind die Eckpfeiler des Staatlichen Museums für Naturkunde Stuttgart, das im Rosensteinpark zwei Zweigstellen unterhält: Das Museum am Löwentor und das Museum Schloss Rosenstein. Ersteres widmet sich den zahlreichen Fossilfunden Baden-Württembergs. Ein großer Teil der Ausstellung beinhaltet alles rund um Dinosaurier. Das seit 1954 im Schloss Rosenstein untergebrachte Naturkundemuseum wurde 1791 als „Naturaliensammlung“ gegründet. Die biologische Schausammlung ist ein Publikumsmagnet und die naturwissenschaftliche Sammlung eine der bedeutendsten Europas.

Das Linden-Museum ist ein Museum für Völkerkunde. Seine Ursprünge sind im Jahr 1882 zu suchen, seit 1911 besteht es in einem eigenen Bau. Es ist eines der größten Völkerkundemuseen Europas und informiert über Afrika, Orient, Südasien, Ostasien, Südsee, Nordamerika und Südamerika. Besondere Beachtung verdient die Dauerausstellungen zu den außereuropäischen Ethnien.

Neben diesen staatlichen gibt es viele weitere Museen in der Landeshauptstadt. Das städtische Kunstmuseum Stuttgart wurde im März 2005 als „Nachfolgemuseum“ der Galerie der Stadt Stuttgart eröffnet. Bereits im ersten Jahr nach der Eröffnung des Hauses wurde es mit 330.000 Besuchern zu einem Anziehungspunkt. Seine exponierte Lage in der Fußgängerzone Königsstraße trägt ebenso dazu bei wie die außergewöhnliche Architektur eines die Ausstellungsräume umhüllenden strengen Glaskubus. Moderne Kunst zählt im Wesentlichen zur Sammlung. Es beherbergt die bedeutendste Sammlung von Werken Otto Dix.

Mit knapp 550.000 Besuchern im Jahr 2009 ist das Mercedes-Benz-Museum das meistbesuchte Museum der Stadt. Seit 1923 besteht die Fahrzeugsammlung des Unternehmens. Im Jahr 2006 wurde die Mercedes-Benz-Welt eröffnet. Auf ihrem Weg durch das von UN Studio entworfene Museum erleben die Besucher eine Zeitreise durch die 120-jährige Automobilgeschichte. Historische Fahrzeuge vom ersten Auto der Welt über die legendären Silberpfeile bis zur Gegenwart der Marke Mercedes-Benz sind zu betrachten. Das im Jahr 1976 eröffnete Porsche-Museum in Zuffenhausen zeigte bis zur Fertigstellung des neuen Museums am 31. Januar 2009 etwa 20 ständig wechselnde Exponate. Mittlerweile können in dem architektonisch äußerst interessanten Neubau etwa 80 Fahrzeuge besichtigt werden, wobei auch hier wechselweise Modelle gezeigt werden.

Im Hegelhaus (Geburtshaus von Georg Wilhelm Friedrich Hegel) ist das Leben des in Stuttgart geborenen Philosophen dargestellt. Mehrere Lapidarien sind in und um Stuttgart zu besuchen. Das Straßenbahnmuseum dokumentiert mit historischen Fahrzeugen von 1868 bis 1986 sowie Gegenständen aus Betrieb und Technik die Geschichte der Stuttgarter Straßenbahnen (SSB). Im Feuerwehrmuseum Stuttgart (Münster) wird die Entwicklung der Brandbekämpfung in Stuttgart geschildert. 2002 wurde das Theodor-Heuss-Haus auf dem Killesberg eröffnet und zeigt seitdem in seinem ehemaligen Wohnhaus das Leben des ersten Bundespräsidenten Theodor Heuss. Die Gedenkstätte „Zeichen der Erinnerung“ am Nordbahnhof erinnert daran, dass von diesem Ort während der Zeit des Nationalsozialismus zwischen 1941 und 1945 mehr als 2000 Juden aus Stuttgart und Württemberg deportiert wurden.

Die Württembergische Landesbibliothek ist mit der Badischen Landesbibliothek (BLB) in Karlsruhe die Regionalbibliothek für Baden-Württemberg. Die WLB ist speziell für die Regierungsbezirke Stuttgart und Tübingen zuständig. Besonders widmet sich die Landesbibliothek der Beschaffung, Erschließung, Archivierung und Bereitstellung des Schrifttums über Württemberg, den sogenannten Württembergica. Zusammen mit der BLB hat sie auch das Pflichtexemplarrecht für Baden-Württemberg (seit 1964, vorher nur für Württemberg) und ist damit Archivbibliothek.

Die Universitätsbibliothek Stuttgart (UBS) ist eine zentrale Einrichtung der Universität Stuttgart. Sie bildet den Mittelpunkt des Bibliothekssystems der Universität und gewährleistet die Versorgung von Forschung, Lehre und Studium mit Literatur und anderen Informationsmitteln. Sie steht neben den Angehörigen der Universität auch Bürgern der Stadt zu Verfügung. Zusammen mit anderen wissenschaftlichen Bibliotheken und Dokumentationsstellen im Raum Stuttgart – wie der Universitätsbibliothek Hohenheim – bildet die UBS das Bibliotheksinformationssystem der Region Stuttgart (BISS).

Die Stadtbibliothek Stuttgart befindet sich seit 2013 in einem Bau des südkoreanischen Architekten Eun Young Yi am Mailänder Platz.

Das Hauptstaatsarchiv Stuttgart ist das für die Ministerien des Landes Baden-Württemberg zuständige Archiv. Seit 1965 befindet es sich direkt neben der WLB und gehört seit 2005 als Abteilung dem Landesarchiv Baden-Württemberg an. Es enthält die Bestände der Grafschaft bzw. des Herzogtums Württemberg bis 1806, der württembergischen Zentralbehörden des 19. und 20. Jahrhunderts sowie der Anfang des 19. Jahrhunderts als Folge der Mediatisierung an Württemberg gefallenen Herrschaften und Reichsstädte in Südwürttemberg.

Das Stadtarchiv Stuttgart ist das für die Landeshauptstadt Stuttgart zuständige Archiv. Es bewahrt das historisch wertvolle Schrift- und Bildgut der städtischen Behörden auf und sammelt die Nachlässe stadtgeschichtlich bedeutender Personen und Institutionen sowie Einzeldokumente und Bilder zur Stuttgarter Geschichte. Das im Archiv verwahrte Material ist grundsätzlich öffentlich zugänglich und kann im Lesesaal im Bellingweg 21 in Bad Cannstatt eingesehen werden.

Das Landeskirchliche Archiv verwahrt die Bestände der württembergischen Kirchenleitung und von sonstigen kirchlichen Stellen und Einrichtungen: des herzoglich und königlich württembergischen Konsistoriums, des Evangelischen Oberkirchenrats, Dekanats- und Pfarrarchive, der Bildungseinrichtungen, der Werke und Vereine sowie Nachlässe und Sammlungen. Außerdem verfügt es über die Mikrofilme sämtlicher Kirchenbücher (v. a. Tauf-, Ehe-, Toten- und Familienregister) aus dem Bereich der Evangelischen Landeskirche in Württemberg. Diese werden über das ebenfalls in Stuttgart beheimatete Archivportal Archion im Internet bereitgestellt.

Das „Archiv der AnStifter“ widmet sich den Toten der Stadt. Seit 2005 arbeiten die AnStifter an einem Erinnerungsbuch über „Die Toten der Stadt“. Bisher wurden etwa 5000 Namen von Opfern des Regimes des Nationalsozialismus erfasst.

Orchester

Chöre

Sonstige

Der Neckartalviadukt Untertürkheim ist eine 1400 Meter lange Kombination aus mehreren Brücken im Zuge der Bundesstraße 14 im Neckartal bei Stuttgart-Untertürkheim. Die Planungen für eine Verbindungsstraße vom Remstal ins Neckartal gehen bis ins Jahr 1932 zurück, jedoch wurde erst im Jahr 1986 mit dem Bau begonnen.

Das Nesenbachtal bei Stuttgart-Vaihingen wird durch den Nesenbachviadukt überbrückt. Der ursprüngliche Bau wurde 1945 zerstört und erst 1946 wieder aufgebaut. Im Rahmen des Ausbaus der S-Bahn-Strecke nach Vaihingen wurde das Viadukt 1982/1983 durch eine neue, viergleisige Brücke ersetzt, die dem ehemaligen Viadukt optisch entspricht.

Über das Neckartal führt der Eisenbahnviadukt Stuttgart-Münster und verbindet Untertürkheim mit Kornwestheim. Die Umgehungsbahnstrecke wurde 1896 in Betrieb genommen, die 855 Meter lange Brücke wurde 1985 durch eine Beton-Stahl-Konstruktion ersetzt.

Vorwiegend als Müllverbrennungsanlage dient das Kraftwerk Stuttgart-Münster. Das seit 1908 bestehende, direkt am Neckar gelegene Kraftwerk kann auch als Heiz- und Kohlekraftwerk sowie mit Gasturbinen betrieben werden. 1964 wurde der 182 Meter hohe Schornstein hinzugefügt.

Das Heizkraftwerk Stuttgart-Gaisburg ist ein steinkohlebefeuertes Kraftwerk am Neckarufer in Stuttgart-Gaisburg. Es dient ausschließlich der Fernwärmebereitstellung. Ebenfalls in Gaisburg findet sich das 1874/75 erbaute Gaswerk Stuttgart-Gaisburg, das bis 1972 zur Gaserzeugung durch Kohlevergasung und seitdem zur Gasspeicherung dient. 1928–1929 wurde der 100 Meter hohe Gaskessel gebaut, der als Wahrzeichen des Stadtteils gilt.

Im Züblin-Haus in Stuttgart-Möhringen ist der Firmensitz der Ed. Züblin AG. Der markante Bürobau in Stahlbeton-Fertigteilbauweise wurde 1983–1984 erbaut. Der glasüberdachte Innenhof dient mehrmals jährlich als Ort für Musikveranstaltungen und Schauspielaufführungen.

Im Zentrum von Stuttgart liegt die Stiftskirche, Hauptkirche der Evangelischen Landeskirche in Württemberg. Erstmals datiert wurde sie 1170, danach mehrfach erweitert, zerstört und wiederaufgebaut. Sie gilt als ein Wahrzeichen der Innenstadt.
Die evangelische Leonhardskirche ist die zweitälteste Kirchengründung in der Altstadt Stuttgarts. Ihren Ursprung fand die heutige Kirche in einer dem heiligen Leonhard geweihten Kapelle um 1337, die zunächst wahrscheinlich als Station für Pilger des Jakobswegs diente.

Bei der evangelischen Hospitalkirche handelte es sich um eine spätgotische Hallenkirche, die zwischen 1471 und 1493 für den Dominikanerorden errichtet wurde.

1478 wurde die evangelische Stadtkirche St. Germanus in Untertürkheim gebaut, urkundlich aber bereits 1289 erwähnt. Einem Chronisten nach wurde die Kirche möglicherweise als Dank für einige sehr fruchtbare Jahre erbaut und führte dazu, dass Untertürkheim ein selbständiger Pfarrort wurde.

Die Domkirche St. Eberhard (früher: Stadtpfarrkirche St. Eberhard) ist seit 1978 die zweite Kathedralkirche der Diözese Rottenburg-Stuttgart. 1808 wurde der Grundstein zu diesem ersten katholischen Kirchenneubau in Stuttgart seit der Reformation gelegt. Die Kirche erhielt ihre Weihe am 1. Oktober 1811.

St. Barbara wurde 1783/1784 als katholische Kirche in Hofen erbaut. Seit 1954 werden Wallfahrten zur Stuttgarter Madonna veranstaltet, die der letzte katholische Pfarrer der Stuttgarter Stiftskirche 1535 nach Hofen gebracht hatte.

In Mühlhausen steht die 1380 erbaute evangelische Veitskapelle. Kunsthistorisch bedeutend sind Wandmalereien aus dem 15. Jahrhundert mit Szenen aus der Bibel und der Veits-Legende.

Als älteste Kirche Stuttgarts gilt die Martinskirche in Plieningen. Die aus Holz bestehende Urkirche wurde um 600 nach Christus erbaut. Der Ursprung des romanischen Steinbaus liegt in der St. Martinuskirche, die im 12. Jahrhundert im Mönchhof erbaut wurde.

Die größte Kirche Stuttgarts ist das "Gospel Forum" der gleichnamigen Freikirche; 2200 Besucher haben hier Platz.

Das Alte Schloss liegt im Zentrum Stuttgarts am Schlossplatz und geht auf eine Wasserburg aus dem 10. Jahrhundert zurück. Die erste Burganlage gab es bereits um 950 zum Schutz des Stutengartens. In direkter Nachbarschaft befindet sich das Neue Schloss. Die Grundsteinlegung für die barocke Residenz von Herzog Carl Eugen erfolgte am 3. September 1746, fertiggestellt wurde es erst 1807. Nach dem Ende der Monarchie ging das Neue Schloss 1918 in den Besitz des Landes Württemberg über.

Im Stadtteil Hohenheim liegt das gleichnamige Schloss Hohenheim. Es wurde zwischen 1772 und 1793 von Herzog Carl Eugen für seine spätere Frau Franziska von Leutrum gebaut. Heute wird das Schloss hauptsächlich von der Universität Hohenheim genutzt und ist von den Hohenheimer Gärten umgeben.

Ebenfalls unter Herzog Carl Eugen wurde von 1764 bis 1769 das Schloss Solitude (französisch: "Einsamkeit") als Jagd- und Repräsentationsschloss erbaut. Auf einem langgezogenen Höhenrücken zwischen den Städten Leonberg, Gerlingen und den Stuttgarter Stadtbezirken Weilimdorf und Botnang gelegen, bietet es einen freien Blick nach Norden ins württembergische Unterland Richtung Ludwigsburg. Die Akademie Schloss Solitude ist eine Stiftung des öffentlichen Rechts, die Aufenthaltsstipendien für sechs oder zwölf Monate an Künstler vergibt. Die Künstler wohnen und arbeiten während der Stipendiumszeit in 45 möblierten Studios, die sich in den beiden ehemaligen Officen- und Kavaliersbauten des Schlosses befinden.

Das Naturkundemuseum ist im Schloss Rosenstein untergebracht. Es wurde 1822 bis 1830 unter König Wilhelm I. in klassizistischem Stil erbaut. Es liegt am Rande des Neckartals inmitten des zeitgleich angelegten Rosensteinparks. Vom Schloss hat man einen freien Blick auf das Mausoleum, der Grabkapelle auf dem Württemberg, die für König Wilhelms zweite Frau Katharina Pawlowna erbaut wurde.

Im Stuttgarter Osten entstand im Auftrag des württembergischen Kronprinzen Karl von 1845 bis 1893 die Villa Berg und die darum liegende Parkanlage. Die im Stil der italienischen Neorenaissance erbaute Villa wirkte als Initialbau der südwestdeutschen Villenarchitektur des 19. Jahrhunderts.

Ursprünglich als „Badhaus“ gedacht, wurde 1842 mit dem Bau des ersten Gebäudes der auf Anweisung des Königs so genannten Wilhelma begonnen. Dem Architekten Ludwig von Zanth gelang es, das, was man unter maurischem Stil verstand, mit den Fähigkeiten deutscher Handwerker, den Wohnbedürfnissen eines schwäbischen Monarchen und dem mitteleuropäischen Klima zu verbinden. Als die Wilhelma 1846 anlässlich der Hochzeit von Kronprinz Karl mit der Zarentochter Olga Nikolajewna eingeweiht wurde, gab es einen Festsaal, zwei Hauptgebäude mit mehreren höfischen Räumen, verschiedene Pavillons, Gewächshäuser und großzügige Parkanlagen.

Das Wilhelmspalais am Charlottenplatz war ein Wohnsitz des letzten württembergischen Königs Wilhelm II. und beherbergte lange Jahre die Stuttgarter Zentralbücherei. Erbaut wurde er zwischen 1834 und 1840 in erster Linie als Wohnsitz seiner beiden ältesten Töchter, Marie und Sophie.

Die Stuttgarter Stäffele sind die bekannten Treppenanlagen der Stadt: Es gibt mehr als 400 mit einer Gesamtlänge von über 20 Kilometern. Die meisten stammen noch aus der Zeit des Weinbaus in der Stadt bis Anfang des 19. Jahrhunderts. Um die steilen Terrassen überhaupt kultivieren zu können, mussten Treppen und Wege angelegt werden. Später, als die Stadt immer weiter die Hänge hinauf wuchs und die Weinberge teilweise durch Häuser und Straßen verdrängt wurden, nutzte man die Staffeln als Fußwege zu den neu gebauten Wohngebieten. Einige wurden kunstvoll ausgebaut und mit Bepflanzungen und Brunnen ergänzt.

Bekannte Stäffele sind beispielsweise die Wächterstaffel, die Eugenstaffel, die Sängerstaffel, Buchenhofstaffel oder die Sünderstaffel.

Die Stäffele haben den Einwohnern der Stadt im Volksmund den Spitznamen "Stäffelesrutscher" eingebracht.

Wegen der hügeligen Topografie ist Stuttgart auch eine Stadt der Tunnel. Darunter befinden sich Straßen-, Eisenbahn-, S-Bahn- und Stadtbahntunnel.

Der Wagenburgtunnel von 1941 diente ursprünglich als Luftschutzkeller. Die 824 Meter lange Südröhre wurde bis 1958 ausgebaut und war bei ihrer Eröffnung der längste Straßentunnel Deutschlands. Der Heslacher Tunnel mit 2300 Meter Länge wurde von 1980 bis 1991 gebaut. Es folgen auf der B 14 der Viereichenhautunnel (290 Meter) und der Gäubahntunnel (450 Meter) bis zum Schattenring.

Bei seinem Bau war der 124 Meter lange und 10,5 Meter breite Schwabtunnel der breiteste Tunnel Europas. Gebaut wurde er von 1894 bis 1896 und war damit nach dem Salzburger Sigmundstor der zweite innerstädtische Tunnel Europas. Bis 1972 fuhr auch die Straßenbahnlinie 8 durch diesen Tunnel.

Weitere Tunnel sind:

Der älteste Eisenbahntunnel Stuttgarts ist der viergleisige Pragtunnel nach Feuerbach. Die erste der beiden Röhren wurde 1846 fertiggestellt. Der Kriegsbergtunnel und der Hasenbergtunnel liegen auf der Strecke nach Böblingen und sind Teil der Gäubahn. Der Rosensteintunnel an der Strecke nach Bad Cannstatt war bereits 1844 begonnen und 1846 fertiggestellt worden. Er ist allerdings längst außer Betrieb, jedoch zugemauert noch vorhanden, weil etwa ab 1912 östlich davon zwei neue Röhren angelegt wurden, die heute als Vorortbahntunnel und Fernbahntunnel in Betrieb stehen. Die Innenstadt wird durch den 8788 Meter langen S-Bahn-Tunnel der Verbindungsbahn zwischen den Stationen Hauptbahnhof und Österfeld durchquert. Ein Teil dieses Tunnels heißt ebenfalls Hasenbergtunnel.

Im Rahmen von Stuttgart 21 entsteht eine Reihe von Tunneln, darunter der 9,5 km lange Fildertunnel.

Beginnend Mitte der 1960er Jahre wurde die Stuttgarter Straßenbahn zur Stadtbahn ausgebaut, wobei zahlreiche innerstädtische Strecken in den Untergrund verlegt wurden. Die Tunnel wurden dabei gleich mit einem für die Stadtbahnfahrzeuge erforderlichen erweiterten Lichtraumprofil ausgestattet, so dass die Umspurung von Meter- auf Normalspur möglich war. Bis 1983 war der komplette Innenstadt-Bereich untertunnelt, es folgten der Weinsteigtunnel (1987), Degerloch (1990), Feuerbach Siemensstraße (1984), Feuerbach Wiener Straße (1990), Weilimdorf (1992), Killesberg (1993), Botnanger Sattel (1994), Gerlingen (1997), Waldau (1998), Sillenbuch (1999), Ruit (2000), Steinhaldenfeld (2005), Fasanenhof mit Unterquerung der B27 (2010) sowie Zuffenhausen (2011). Im Rahmen der Bauarbeiten von Stuttgart 21 wurde der Tunnel Hauptbahnhof – Stadtbibliothek verlegt und beide Fahrtrichtungen in verschiedene Röhren aufgeteilt, sowie ein unterirdischer Abzweig vom Tunnel Heilbronner Straße zum Budapester Platz erbaut (2017). Im Bau befindet sich das Verzweigungsbauwerk mit der Haltestelle Staatsgalerie (Inbetriebnahme vsl. 2019).

Ein Wahrzeichen der Stadt ist der Stuttgarter Fernsehturm, der südlich des städtischen Talkessels im Stadtbezirk Degerloch errichtet wurde. Er steht
etwas unterhalb der höchsten Stelle vom Bopser (auch "Hoher Bopser" genannt; ). Als weltweit erster Fernsehturm in Stahlbetonbauweise wurde er von 1954 bis 1955 erbaut und ist 216,61 m hoch. Ursprünglich war als Träger für Radio- und Fernsehantennen ein damals üblicher, etwa 200 Meter hoher Stahlgittermast vorgesehen. Die Idee, den Turmkorb auch touristisch nutzbar zu machen, zahlte sich bereits fünf Jahre nach Bau aus: Die Baukosten von 4,2 Millionen DM waren durch die Eintrittspreise amortisiert. Damit wurde der Fernsehturm das Vorbild für diverse Konstruktionen weltweit.

Auf dem "Frauenkopf" steht () der Stuttgarter Fernmeldeturm der Deutschen Telekom AG. Ebenfalls aus Stahlbeton erbaut, ist er 192 m hoch. Erbaut zwischen 1970 und 1972 kostete er rund 9,5 Millionen DM. Neben diesen beiden gehören der 1966 auf dem "Raichberg" erbaute Stuttgarter Funkturm sowie der Funkturm Stuttgart-Burgholzhof (1989) beim Pragsattel zu den bekannteren Funktürmen der Stadt.

Der 61 Meter hohe Tagblatt-Turm in Stuttgart-Mitte wurde in den Jahren 1924–1928 gebaut und war somit das erste Sichtbetonhochhaus Deutschlands. Auch er gilt als Wahrzeichen des Stadtbilds. Der Name rührt von der ursprünglichen Nutzung durch die Tageszeitung "Stuttgarter Neues Tagblatt" her.

Der 42 Meter hohe Killesbergturm, als Aussichtsturm errichtet, liegt im Höhenpark Killesberg. 1993 wurde im Park die Internationale Gartenbauausstellung ausgestellt. Um einen weiten Überblick über das Gelände zu ermöglichen, bedurfte es einer künstlichen Erhöhung. Die Form kam dadurch zustande, dass die Erbauer einerseits die Vorgabe hatten, einen filigranen, sich in die Landschaft einpassenden Turm zu schaffen, und andererseits der eigentlichen Aufgabe, Übersicht zu gewähren, gerecht werden mussten. Heraus kam die Seilnetzkonstruktion.

Weitere Aussichtstürme sind der Bismarckturm in Stuttgart-Nord und der Aussichtsturm Burgholzhof in Bad Cannstatt. Ersterer steht auf dem "Gähkopf" () und bietet eine gute Aussicht auf das Stuttgarter Stadtgebiet sowie Fernsicht in alle Himmelsrichtungen. Erbaut wurde er zwischen 1902 und 1904. Der 1891 erbaute Aussichtsturm Burgholzhof ermöglicht eine gute Sicht auf Stuttgart-Ost, Bad Cannstatt und ins Neckartal bis Esslingen am Neckar.

Der Kriegsbergturm im Stuttgarter Stadtteil Relenberg ist ein 1895 erbauter Aussichtsturm auf dem 353 Meter ü. NN hohen "Kriegsberg". Dieser ist nur für besondere Anlässe der Öffentlichkeit zugängig.

In Stuttgart-Degerloch steht ein 400 Kubikmeter fassender Wasserturm, der 1911–1912 erbaut wurde.

Der Turm des Hauptbahnhofs ragt im Zentrum der Stadt 56 Meter in die Höhe. Der Bau des Bahnhofs dauerte von der Grundsteinlegung 1914 bis zur Eröffnung 1922, durch den Ersten Weltkrieg verzögert, fast acht Jahre. Auf der Aussichtsterrasse rotiert ein Mercedes-Stern mit fünf Metern Durchmesser.

"Siehe auch:" Liste der höchsten Bauwerke in Stuttgart | Liste der Hochhäuser in Stuttgart | Sendetürme in Stuttgart | Liste der Türme der Stadtbefestigung von Stuttgart

Die Weißenhofsiedlung wurde 1927 als Teil einer Ausstellung vom Deutschen Werkbund initiiert und unter der Leitung von Mies van der Rohe am Stuttgarter Killesberg errichtet. Die Siedlung gilt als eine der bedeutendsten Architektursiedlungen der Neuzeit.

In Holzbauweise und als bewusst traditionalistisches Gegenmodell zur nahe gelegenen Weißenhofsiedlung wurde 1933 auf dem Killesberg – vor dem Hintergrund der nationalsozialistischen Machtübernahme – eine weitere Siedlung, die Kochenhofsiedlung als Modellsiedlung unter der Leitung des Architekten Paul Schmitthenner und von Vertretern der Stuttgarter Schule gebaut.

Der Stuttgarter Hauptbahnhof ist der größte Fernbahnhof in Stuttgart und Zentrum des Stuttgarter S-Bahn-Verkehrs sowie zusammen mit der Haltestelle Charlottenplatz wichtigster Knotenpunkt der Stuttgarter Stadtbahn. Die Architekten Paul Bonatz und Friedrich Eugen Scholer begannen 1914 mit den Erdarbeiten. Die Fertigstellung wurde durch den Ersten Weltkrieg verzögert. Im Jahr 1922 wurde er offiziell eröffnet, jedoch erst 1927 endgültig fertiggestellt. 1987 wurde der Stuttgarter Hauptbahnhof als Kulturdenkmal von besonderer Bedeutung ins Denkmalbuch eingetragen. In den Jahren 2010 und 2012 wurde der Nord- und Südflügel des Bahnhofs wegen des Bahnprojekts Stuttgart 21 zurückgebaut.
Die Mercedes-Benz Arena, ehemaliges „Gottlieb-Daimler-Stadion“ und „Neckarstadion“, wurde 1929 bis 1933 ebenfalls von Paul Bonatz erbaut und 1933 unter dem Namen „Adolf-Hitler-Kampfbahn“ in Betrieb genommen. 1935 wurde es von 35.000 auf 70.000 Plätze erweitert. Nach dem Krieg wurde das Stadion von der US-Besatzung zunächst in „Century Stadium“ und später in „Kampfbahn“ umbenannt und für Baseballspiele genutzt. 1949 erhielt es den Namen „Neckarstadion“. Zwischen 1949 und 1951 wurde das Stadion nochmals auf 97.500 Plätze erweitert. Im Zuge der Fußball-Weltmeisterschaft 1974 wurden die Tribünen neu gebaut. Das Stadion fasste nunmehr 72.000 Zuschauer. 1986 erhielt die Arena für die Leichtathletik-Europameisterschaften als erstes deutsches Stadion eine Farbanzeigetafel. Im Rahmen des Umbaus für die Leichtathletik-Weltmeisterschaften 1993 wurde es in „Gottlieb-Daimler-Stadion“ umbenannt, seit 2008 heißt es „Mercedes-Benz Arena“. Zwischen 1999 und 2005 gab es weitere Baumaßnahmen, 2009–2011 erfolgte der Umbau zum reinen Fußballstadion ohne eine das Spielfeld umgebende Laufbahn.
Direkt neben der Mercedes-Benz-Arena steht die größte Mehrzweckhalle Stuttgarts, die Hanns-Martin-Schleyer-Halle. Sie wurde 1983 erbaut und nach dem ermordeten Arbeitgeberpräsident Hanns Martin Schleyer benannt. Nach der Modernisierung 2005–2006 fasst die Halle 15.500 Sitz- und Stehplätze. Durch ein gemeinsames Forum ist die Schleyer-Halle mit der 2006 eröffneten Porsche-Arena verbunden. Diese wird hauptsächlich für Sportveranstaltungen genutzt. In direkter Nachbarschaft liegt das Carl Benz Center. Das 2006 eröffnete Veranstaltungszentrum bietet rund 20.000 Quadratmeter Nutzfläche.
Im Pragfriedhof wurde von 1905 bis 1907 die im Jugendstil erbaute Feierhalle und das einzige Krematorium Stuttgarts errichtet.
Die Markthalle ist ein Jugendstilgebäude im Stadtzentrum. Sie wurde 1911 bis 1914 an der Stelle errichtet, an der sich seit 1864 ein Gemüsemarkt befunden hatte. Zunächst diente sie als Nahrungsmittelbörse mit über 400 Verkaufsständen. Nach schweren Zerstörungen im Zweiten Weltkrieg wurde die Markthalle wieder aufgebaut und steht seit 1974 unter Denkmalschutz. Heute ist sie ein Verbrauchermarkt. Ganz in seiner Nähe das ehemalige Hotel Silber am Karlsplatz war einst auch Sitz der Gestapozentrale.

Ebenfalls im Stadtzentrum liegt das Stuttgarter Rathaus, der Sitz der Stuttgarter Stadtverwaltung. Der 1901–1905 im Stil der flämischen Spätgotik erbaute prachtvolle Vorgängerbau brannte nach Bombenangriffen 1944 vollständig aus. Trotz der Zerstörung konnten Teile der beiden Seitenflügel beim Wiederaufbau erhalten werden. In seiner heutigen Form existiert das Rathaus seit 1956. Der 60,5 Meter hohe Uhrenturm überragt den Stuttgarter Marktplatz. Im Jahre 2004 wurde das Rathaus unter der Leitung von Professor Walter Belz für 26 Millionen Euro saniert und auf den neuesten technischen Stand gebracht.
Das Carl-Zeiss-Planetarium befindet sich im Mittleren Schlossgarten. Den Grundstein legte der 1969 von der Carl-Zeiss-Stiftung an die Stadt Stuttgart gestiftete Projektor Zeiss VI A. Der Bau des Planetariums konnte jedoch erst 1975 durch die Unterstützung zahlreicher Spenden beginnen und 1977 abgeschlossen werden.

Das Stuttgarter Funkhaus wurde von 1972 bis 1976 vom Architekten Rolf Gutbrod erbaut und galt bei Inbetriebnahme als das modernste Funkhaus Europas. Es steht auf dem Gebiet der ehemaligen Stuttgarter Stadthalle im Stadtteil Berg. Es ist seit 1998 Sitz des Intendanten des Südwestrundfunks und damit Hauptsitz der Zweiländeranstalt sowie Landesfunkhaus für Baden-Württemberg. Im Jahr 2000 wurde das Stuttgarter Funkhaus vom Landesdenkmalamt Baden-Württemberg in die Liste der Kulturdenkmale aufgenommen. Der dreigliedrige Gebäudekomplex in blau-silberner Fassadenverkleidung gilt noch immer als ein einzigartiges Bauwerk in der Rundfunklandschaft. Die bereits genannte Villa Berg in unmittelbarer Nähe diente von 1950 bis 2004 als Sendestudio des Südwestrundfunks.

Als Amtssitz des Staatsministeriums und des jeweiligen Ministerpräsidenten dient die zwischen 1910 und 1913 erbaute Villa Reitzenstein im Stadtbezirk Stuttgart-Ost.

Im Weißenburgpark stehen das Teehaus und der Marmorsaal. Beim 1913 fertiggestellten Teehaus der früheren Villa handelt es sich um einen Jugendstil-Pavillon. Hervorhebenswert ist das farbenprächtige Deckengemälde mit Musikantenszenen. Heute ist das Teehaus mit einer angrenzenden großen Gartenterrasse im Sommer ein beliebtes Ausflugslokal. Der ebenfalls 1913 von Heinrich Henes fertiggestellte Marmorsaal liegt am Hang unterhalb des Teehauses. Der Marmorsaal wurde ursprünglich schon als festlicher Gartensaal genutzt und steht nach einer Renovierung Anfang der 1990er Jahre seit 1994 wieder für Veranstaltungen zur Verfügung.

Das Alte Steinhaus an der Grabenstraße 11 in Stuttgart war ein wehrhafter Wohnbau und neben dem Stuthaus einer der ältesten Profanbauten der Stadt. Es stammt wohl aus der Zeit der Belagerung Stuttgarts durch Rudolf von Habsburg im Jahr 1286, erstmals urkundlich erwähnt wurde es 1393.

Im Möhringen stehen zwei markante Wohnhochhäuser. Das Fasan 2 zeichnet sich dadurch aus, dass zwei Gebäudekomplexe in mehreren Ebenen durch begehbare Brücken miteinander verbunden sind. Fasan 2 wurde zwischen 1964 und 1965 errichtet und ist 64 Meter hoch. In direkter Nachbarschaft steht das zwischen 1961 und 1962 mit 70 Metern und 20 Stockwerken Höhe errichtete Salute Hochhaus, das 1967 den "Paul-Bonatz-Preis" erhielt. Die Wohnsiedlung Hannibal in Asemwald wurde 1968 bis 1972 erbaut und besteht aus drei Wohnblocks mit bis zu 70 Meter Höhe und 22 Stockwerken. Ursprünglich war nach Corbusiers Vorbild der „Wohnmaschine“ ein einziger Komplex geplant, der jedoch aufgrund seiner gigantischen Dimension nicht genehmigt wurde.

Ein weiteres nennenswertes Kulturdenkmal ist das Wohnhaus Arminstraße 4. Es wurde von der Denkmalstiftung Baden-Württemberg zum "Denkmal des Monats Februar 2005" ernannt.

In Stuttgart-Möhringen befindet sich das SI-Centrum. Bestehend aus zwei Musicaltheatern, der Spielbank Stuttgart, 19 Restaurants und Bars, einem Filmpalast mit sechs Kinosälen, 17 Konferenzräumen für bis zu 1000 Personen, dem Millennium Hotel, den SI Suites und den VitaParc SchwabenQuellen (Wellness), ist das Erlebniscenter eine der größten Stuttgarter Freizeiteinrichtungen. Seit 1960 steht dort das Hotel Stuttgart International, in dessen Umgebung über die Jahre ständig neue Gebäude hinzukamen.

Weitere nennenswerte Gebäude sind die Liederhalle, die Villa Gemmingen-Hornberg sowie das Verwaltungsgebäude der Württembergischen Sparkasse.

Von Max Bill und Heinz Mack im Jahr 1989 erschaffen, ist die Bildsäulen-Dreiergruppe eine 32 Meter hohe, dreiteilige Skulptur aus Email auf Stahl. Bis Ende April 2006 stand sie vor der ehemaligen DaimlerChrysler-Konzernzentrale in Möhringen, seitdem vor dem Mercedes-Benz Museum im NeckarPark.

Die Gedenkstätte „Zeichen der Erinnerung“ am Stuttgarter Nordbahnhof erinnert daran, dass von diesem Ort während der Zeit des Nationalsozialismus zwischen 1941 und 1945 mehr als 2000 Juden aus Stuttgart und Württemberg deportiert und ermordet wurden. Mit Hilfe des Vereins „Zeichen der Erinnerung e. V.“ wurde die Gedenkstätte gebaut und am 14. Juni 2006 offiziell eingeweiht. Auf der 70 Meter langen Mauer entlang der Gleise sind die Namen der deportierten Juden zu lesen.

Direkt im Zentrum beginnt am Alten Schloss der 600 Jahre alte Schlossgarten. 1350 wird ein gräflicher Garten nahe dem Alten Schloss erstmals erwähnt. Der etwa 61 Hektar große Schlossgarten folgt dem Lauf des kanalisierten Nesenbachs bis zum Neckar. Er wird in drei große Bereiche aufgeteilt, den „Oberen Schlossgarten“ (etwa 14 Hektar), den „Mittleren Schlossgarten“ (etwa 19 Hektar) und den „Unteren Schlossgarten“ (etwa 28 Hektar). Der Obere Schlossgarten erstreckt sich vom Alten Schloss bis zur Höhe des Hauptbahnhofs und beinhaltet unter anderem die Staatstheater und das Landtagsgebäude. Über den Ferdinand-Leitner-Steg geht er in den Mittleren Schlossgarten über, der im nördlichen Bereich von der Straße „Am Schlossgarten“ begrenzt wird. Hier befinden sich zum Beispiel das Planetarium und der Landespavillon. Über die „Grüne Brücke“ gelangt man in den Unteren Schlossgarten, der sich bis zu den Mineralbädern in Stuttgart-Berg nahe dem Cannstatter Neckarufer zieht. Hier geht der Schlossgarten nahtlos in den etwa 65 Hektar umfassenden Rosensteinpark über, der im Südwesten durch Bahngleise, nördlich durch den zoologisch-botanischen Garten Wilhelma und die „Pragstraße“ und im Nordwesten durch das Löwentor begrenzt wird. Durch den alten Baumbestand und die großflächigen Wiesen gilt der Rosensteinpark als größter englischer Landschaftspark im Südwesten Deutschlands. König Wilhelm I. ließ den Garten zwischen 1824 und 1840 anlegen, was den Bau des klassizistischen Schlosses – das heutige Rosensteinmuseum – beinhaltete. Über den „Lodzer Steg“, den „Brünner Steg“ und den „Bombaystegen“ gelangt man in den sich anschließenden, etwa 50 Hektar umfassenden Höhenpark Killesberg im Stadtbezirk Stuttgart-Nord. Die Anlage geht auf die Reichsgartenschau 1939 zurück, für die das vorher als Steinbruch genutzte Gelände zum Park und Ausstellungsgelände umgestaltet wurde. 1939 bis 1945 war das Gelände Sammlungsort der württembergischen Juden für die Transporte in die Konzentrationslager. Seit den 1950er Jahren war der Höhenpark mehrfach Schauplatz von Gartenbauausstellungen wie der Deutschen Gartenschau 1950, der Bundesgartenschau 1961 und der Internationalen Gartenbauausstellung 1993.

Alle drei Anlagen – der Schlossgarten, der Rosensteinpark und der Killesbergpark – bilden gemeinsam das berühmte Stuttgarter „Grüne U“.

Nördlich des Rosensteinparks liegt der landeseigene zoologisch-botanische Garten, die Wilhelma. Sie existiert in heutiger Form seit dem Jahr 1953. In der historischen Schlossanlage von 1846 werden auf etwa 28 Hektar rund 8000 Tiere in 1050 Arten und etwa 5000 Pflanzenarten gezeigt. Damit ist die Wilhelma nach dem Berliner Zoo der zweitartenreichste Zoo Deutschlands. Wegen der im Jahr 1829 gefundenen Mineralquellen wollte der damalige König Wilhelm I. ein „Badhaus“ im Schlosspark als ein Nebengebäude errichten lassen. Im Jahr 1837 wurde mit der Planung der Anlage, 1842 mit dem Bau des ersten Gebäudes begonnen. Im Verlauf der Planungen war aus dem Badhaus ein komfortables Wohngebäude mit mehreren Räumen geworden, darunter ein Kuppelsaal mit zwei angrenzenden Gewächshäusern mit je einem Eckpavillon. Als die Wilhelma 1846 eingeweiht wurde, gab es einen Festsaal, zwei Hauptgebäude mit mehreren höfischen Räumen, verschiedene Pavillons, Gewächshäuser und großzügige Parkanlagen.

Zum Schloss Hohenheim gehören die Hohenheimer Gärten. 1776 ließ der württembergische Herzog Carl Eugen eine englische Anlage errichten, um die bis ins 20. Jahrhundert mehr als 35 Hektar Parkfläche entstanden. Weite Teile des Ensembles werden heute von der Universität Hohenheim zu Forschungszwecken genutzt. Bedeutendste Teile sind das Landesarboretum mit dem „Exotischen Garten“ sowie der „Botanische Garten“. Die Gärten werden ergänzt durch einen Weinberg und eine Schafweide, die weitere 2,2 Hektar umfassen.

Die Uhlandshöhe ist eine Erhebung am östlichen Rand des Stadtzentrums. Sie liegt etwa im Dreieck zwischen der Stadtmitte, Bad Cannstatt und dem Frauenkopf. Bis ins späte Mittelalter diente sie als Steinbruch. Der Verschönerungsverein Stuttgart kaufte zwischen den Jahren 1861 und 1896 Teile des Geländes und gestaltete eine weitläufige Parkanlage mit Aussichtsterrassen sowie ein Denkmal des Dichters Ludwig Uhland. Hier befindet sich auch die „Sternwarte Uhlandshöhe“, 1919 vom Verein „Schwäbische Sternwarte e. V.“ gegründet.

Der Weißenburgpark ist eine etwa fünf Hektar große Grünanlage in Stuttgart-Süd im Stadtteil Bopser. Auf einer Anhöhe im Park befinden sich das sogenannte Teehaus und der Marmorsaal, die heute als Ausflugslokal beziehungsweise als Veranstaltungsort genutzt werden. Angelegt wurden Gebäude und Park in den Jahren 1843/44.

Der Birkenkopf ist ein 511 Meter hoher Berg und damit der höchste Punkt im inneren Stadtgebiet. Die obersten 40 Meter wurden aus Trümmern der Ruinen des Zweiten Weltkriegs angehäuft.

Im Stadtteil Sillenbuch liegt der Stuttgarter Eichenhain, seit 1958 Naturschutzgebiet. Etwa 200 Eichen stehen dort in einer parkähnlichen Landschaft. Die ältesten unter ihnen sind 300 bis 400 Jahre alt und haben Stämme mit vier bis sechs Meter Umfang.

Der chinesische Qingyin-Garten liegt an der Birkenwaldstraße und bietet einen Blick über den Stadtkern Richtung Süden. Er wurde 1993 für die Internationale Gartenbauausstellung angelegt.

Als ältester noch erhaltener Friedhof Stuttgarts gilt der Hoppenlaufriedhof in Stuttgart-Mitte. Gegründet wurde er im Jahre 1626 als "Spitalfriedhof" nach einer Grundstücksschenkung durch Johann Kercher, der als erster dort beerdigt wurde. Die letzte Erdbestattung fand 1880, die letzte Urnenbestattung 1951 statt.

Im Stadtbezirk Degerloch liegt der größte Friedhof der Stadt mit etwa 31 ha: Der Waldfriedhof Stuttgart wurde 1913 angelegt. Durch eine Standseilbahn wird der 100 Meter höher gelegene Friedhof mit dem Südheimer Platz verbunden. Hier sind viele Prominente beigesetzt.

Im Bad Cannstatter Stadtteil Muckensturm liegt der 1918 eröffnete Hauptfriedhof. Er ist mit 29,6 Hektar der zweitgrößte Stuttgarter Friedhof. Seit 1944 hat er ein armenisches und seit 1985 ein muslimisches Gräberfeld. Ein großes jüdisches Gräberfeld wurde 1937/38 angelegt, da im Pragfriedhof die Plätze knapp wurden.
Der drittgrößte Friedhof ist der Pragfriedhof von 1873 mit einem Jugendstil-Krematorium. Die inzwischen etwa 20 Hektar große Anlage beherbergt das einzige Krematorium Stuttgarts, das zwischen 1905 und 1907 gebaut wurde. Der Friedhof gilt als Sachgesamtheit als Kulturdenkmal. 1874 wurde der Friedhof um einen Teil für Angehörige des israelitischen Glaubens erweitert. Auf dem Gelände des Pragfriedhofs befindet sich auch die russisch-orthodoxe Heilige-Alexander-Nevskij-Kirche.

Der Uff-Kirchhof in Bad Cannstatt gehört zu den ältesten Friedhöfen in Stuttgart. Er ist im 8. oder 9. Jahrhundert an der Kreuzung einer römischen Straße entstanden und diente seit dem Mittelalter als Kirchhof für den Weiler "Uffkirchen" und seine Pfarrgemeinde. Nachdem der Ort Uffkirchen abgegangen war, nutzte Cannstatt Kirche und Friedhof. Die spätgotische Marienkirche, heute „Uffkirche“ genannt, steht unter Denkmalschutz und wird als Friedhofskapelle genutzt.

Der Max-Eyth-See ist ein künstlich angelegter See direkt am Neckar, am Fuße von Weinbergen zwischen Stuttgart-Mühlhausen und Stuttgart-Hofen gelegen. 1920 entstand durch intensiven Kiesabbau eine Grube, die 1935 im Zuge der Kanalisierung des Neckars zum größten See Stuttgarts wurde. 1961 wurden das Gelände und der See unter Landschaftsschutz gestellt. Der Max-Eyth-See gilt als Naherholungsgebiet sowie als Naturraum.
Die Parkseen im Rot- und Schwarzwildpark in Stuttgart-West sind hauptsächlich im Sommer ein stark frequentiertes Ausflugsziel von Spaziergängern und Sportlern. Bärensee, Neuer See und Pfaffensee bilden das etwas über drei Kilometer lange Stauseen-Trio. Künstlich aufgestaut entstanden die Seen zwischen 1566 und 1826 zur Verbesserung der Wasserversorgung Stuttgarts.

Am Wartberg im Stuttgarter Norden liegt der Egelsee. Dieser wurde für die Internationale Gartenbauausstellung (IGA) 1993 künstlich erschaffen.

Zwei Feuerseen befinden sich einmal zentral im gleichnamigen Stadtteil in Stuttgart-West sowie in Vaihingen. An Ersterem liegt die Johanneskirche sowie die S-Bahn Haltestelle Feuersee.

Weitere Seen im Stadtgebiet sind der „Rohrer See“ in Rohr, der „Probstsee“ in Möhringen sowie der „Riedsee“ zwischen Möhringen und Sonnenberg. An den Seen lassen sich seltene Wasservögel beobachten.

Teilweise durch Stuttgarter Stadtgebiet fließen der Neckar, die Körsch, der Feuerbach und der Nesenbach zwischen Vaihingen und Stuttgart-Ost.


Stuttgart verfügt über mehrere Stadien und Arenen für Spitzensport-Veranstaltungen. Das bedeutendste Sportzentrum der Stadt liegt am Cannstatter Wasen im Neckarpark. Dort finden sich unter anderem das Fußballstadion Mercedes-Benz Arena und die vier Multifunktionshallen Hanns-Martin-Schleyer-Halle, Porsche-Arena, Scharrena und Carl Benz Center. Ein weiteres großes Sportgebiet liegt auf der Waldau in Degerloch. Dort befinden sich neben einer Vielzahl von Breitensportanlagen das Gazi-Stadion auf der Waldau und das Eissportzentrum Waldau.

Stuttgart war jeweils einer der Spielorte der Fußball-Weltmeisterschaften 1974 und 2006 sowie der Austragungsort der Leichtathletik-Europameisterschaften 1986 und -Weltmeisterschaften 1993.

Daneben wurden zahlreiche weitere internationale Sportveranstaltungen in Stuttgart durchgeführt, z. B.:

Jährlich werden die Tennisturniere Mercedes-Cup und Porsche Grand Prix, das Reitturnier German Masters, die Turn-Weltcup-Veranstaltung DTB-Pokal, die German Open Championships im Tanzsport und der Stuttgart-Lauf veranstaltet. Bis zum Jahr 2008 wurde in der Schleyer-Halle jährlich ein Sechstagerennen durchgeführt.

Stuttgart ist die Heimat zweier bekannter Fußballvereine. Der Bundesligist VfB Stuttgart wurde bisher fünfmal deutscher Meister; er trägt seine Heimspiele in der Mercedes-Benz Arena aus. Die Stuttgarter Kickers, die in den 1980ern und 1990ern in zwei Spielzeiten auch der Bundesliga angehörten, spielen seit 2016/17 in der Regionalliga Südwest; ihre Heimspiele finden im Gazi-Stadion auf der Waldau in Degerloch statt. Weitere, früher überregional bekannte Fußballvereine sind die Sportfreunde Stuttgart und der FV Zuffenhausen.

Der TV Bittenfeld spielt seit der Saison 2015/16 unter dem Namen TVB 1898 Stuttgart in der Handball-Bundesliga der Männer. Heimspielstätte ist die Scharrena, ein Teil der Heimspiele findet aus Kapazitätsgründen auch in der Porsche-Arena statt. Der VfL Pfullingen/Stuttgart spielte von 2001 bis 2006 in der Bundesliga, wo er seine Heimspiele in der Hanns-Martin-Schleyer-Halle austrug. In der Saison 1990/91 spielte auch die SG Stuttgart-Scharnhausen in der Bundesliga.

Seit 2008 spielt die Frauen-Volleyballmannschaft Allianz MTV Stuttgart (bis 2010 "Allianz Volley Stuttgart", bis 2012 "Smart Allianz Stuttgart") in der Bundesliga. Sie gewann dreimal den DVV-Pokal und wurde von 2015 bis 2017 dreimal in Folge deutscher Vizemeister. Drei Mal Deutscher Meister im Frauen-Volleyball wurde CJD Feuerbach. Der Verein zog seine erste Mannschaft 1996 aus finanziellen Gründen aus der Bundesliga zurück.

Im Eishockey wird Stuttgart von den Stuttgart Rebels in der Regionalliga und im Nachwuchsbereich vertreten. Die Heimspiele werden im Eissportzentrum Waldau in Degerloch ausgetragen. Im American Football sind die Stuttgart Scorpions in der German Football League aktiv. Sie tragen ihre Spiele im Gazi-Stadion auf der Waldau aus. 2007 wurden sie deutscher Vizemeister. Im Wasserball wurde der SV Cannstatt 2006 Deutscher Meister. Im Damen-Tennis ist der TC Weissenhof vierfacher Deutscher Meister und der TEC Waldau Deutscher Meister 2006. Der Hockeyklub HTC Stuttgarter Kickers gewann unter anderem 2005 die deutsche Meisterschaft und 2006 den Europapokal der Landesmeister.

Der zweitgrößte traditionelle Sportverein ist der MTV Stuttgart mit 8700 Mitgliedern. Im Kunstturnen wurde das Frauenteam 2010 und von 2012 bis 2017 Deutscher Meister, die Männer schafften dies 2014. Der MTV war auch in der Saison 2005/06 als letzter Stuttgarter Verein mit einer Basketballmannschaft in einer Profiliga vertreten, bevor er sich aus der 2. Bundesliga zurückzog. Der letzte große Erfolg einer Basketballmannschaft aus Stuttgart war 1950 die deutsche Meisterschaft des BC Stuttgart-Degerloch.

Der Billardverein BC Stuttgart 1891 spielt seit 2013 in der 1. Snooker-Bundesliga und wurde 2014 sowie 2017 Deutscher Meister. Zudem spielte der Verein mehrere Jahre in der 2. Dreiband-Bundesliga und in der 2. Poolbillard-Bundesliga.

Die zwei größten Sportvereine in Stuttgart nach dem VfB Stuttgart sind die zwei Alpenvereinssektionen Stuttgart und Schwaben mit knapp 31.500 und 27.000 Mitgliedern, die dritte DAV-Sektion, die Sektion Breslau mit knapp 800 Mitgliedern, wurde ursprünglich 1877 in Breslau gegründet.



Im Zukunftsatlas 2016 belegte die kreisfreie Stadt Stuttgart Platz 7 von 402 Landkreisen und kreisfreien Städten in Deutschland und zählt damit zu den Orten mit „Top Zukunftschancen“.

Stuttgart zählt zu den einkommensstärksten und wirtschaftlich bedeutendsten Städten Deutschlands und Europas. Die Region Stuttgart ist mit ca. 1500 ansässigen kleinen und mittelgroßen Unternehmen eines der Zentren des deutschen Mittelstandes. Dabei handelt es sich in erster Linie um Zulieferer für die großen, global agierenden Automobil- und Maschinenbau-Firmen. In der Stadt und ihrer Umgebung haben sich unter anderem viele Hightech-Unternehmen angesiedelt, darunter Daimler, Porsche, Bosch, die hier ihr weltweites Hauptquartier haben, aber auch Siemens, Kodak oder Lenovo. Das Bruttoinlandsprodukt betrug im Jahr 2013 45,2 Milliarden Euro, das entspricht 10,7 % ganz Baden-Württembergs. Aufgrund dieser wirtschaftlichen Situation nicht nur der Stadt, sondern der gesamten Region wird diese umgangssprachlich oder scherzhaft oft als "Stuttgarter Speckgürtel" bezeichnet.
Stuttgart gehört laut GaWC-Studie im Jahr 2016 zu den mit „Beta−“ kategorisierten Städten.

Persönlichkeiten wie Fritz Leonhardt, Frei Otto oder Jörg Schlaich gelten als Beispiele bedeutender Ingenieure der Stadt. Ingenieurbüros wie SBP, Leonhardt Andrä und Partner sowie Knippers Helbig planten Bauwerke wie die Expo Achse in Shanghai oder den Flughafen in Shenzhen. Bekannte Architekturbüros sind unter anderem Behnisch & Partner (Olympiagelände München, Bundestagsgebäude) und Behnisch Architekten (NordLB, Ozeaneum Stralsund).

Der Finanzplatz Stuttgart ist mit der Börse Stuttgart nach Frankfurt zweitwichtigster Börsenplatz in Deutschland. Die Landesbank Baden-Württemberg (LBBW) zählt zu den größten deutschen Kreditinstituten und ist Deutschlands größte Landesbank. Ihre Tochter BW-Bank ist zugleich Sparkasse der Stadt Stuttgart. Privatwirtschaftlich organisiert sind die Südwestbank AG, die Schwäbische Bank und das Bankhaus Ellwanger & Geiger.

Mit der Württembergischen Versicherung, Württembergischen Lebensversicherung (beide Töchter der Wüstenrot & Württembergische), SV SparkassenVersicherung, WGV und Allianz Lebensversicherung haben mehrere Versicherungsunternehmen ihren Sitz in Stuttgart.

Mit Wolff & Müller, Züblin und Gottlob Rommel sind in Stuttgart auch drei große nationale Bauunternehmen angesiedelt.

Die Stadt Stuttgart ist ferner seit 1996 Sitz einer Spielbank. Sie ist die dritte Spielbank des Landes Baden-Württemberg nach Baden-Baden und Konstanz. Alle drei werden seit 2003 unter der Regie der "Baden-Württembergischen Spielbanken GmbH & Co. KG" mit Sitz in Baden-Baden betrieben.

In Stuttgart gibt es 175 Beherbergungsbetriebe mit insgesamt 18.900 Betten. 2014 wurden 3,47 Millionen Übernachtungen von 1,82 Millionen Gästen gezählt, 8,2 Prozent mehr als im Vorjahr. Die Auslastung lag bei 71 Prozent.

Mit rund 400 Hektar Rebfläche zählt Stuttgart zu den größten Weinbaugemeinden Deutschlands. Bekannt sind die in der Innenstadt gelegene "Stuttgarter Mönchhalde", das "Cannstatter Zuckerle" sowie die Lagen von Untertürkheim, Rotenberg und Uhlbach (siehe hierzu den Hauptartikel Weinbau in Stuttgart).

Im Stuttgarter Stadtgebiet gibt es insgesamt 25 Umspannwerke der 110-kV-Ebene der EnBW bzw. heute Netze BW. Daneben existieren rund 1400 km 10-kV-Mittelspannungskabel der Stuttgart Netze, die nahezu komplett unterirdisch verlegt sind und 7700 Trafostationen anbinden.

Neben eigener Erzeugung in den Kraftwerken Münster, Gaisburg und den Laufwasserkraftwerken am Neckar wird Stuttgart hauptsächlich über drei Freileitungen versorgt, die von den überregional wichtigen EnBW-Umspannwerken in Pulverdingen, Wendlingen und Hoheneck zu Umspannwerken im Stuttgarter Stadtgebiet (Weilimdorf, Seewiesen, Möhringen) führen. Sie wurden allesamt mit einer Betriebsspannung von 220 kV ausgeführt, seit Ende der 2000er Jahre werden sie jedoch nur mit 110 kV betrieben.

Vom Umspannwerk Möhringen existiert noch eine 110-kV-Leitung zum Umspannwerk Sindelfingen, in Obertürkheim gibt es ein weiteres 110-kV-Umspannwerk, dass von einem Leitungsabzweig der ehemaligen Anlage 9461, einer Freileitung von Hoheneck nach Altbach (früher bis nach Niederstotzingen), gespeist wird. Alle weiteren 110-kV-Leitungen des öffentlichen Stromnetzes in Stuttgart sind aufgrund der Bebauung als Erdkabel ausgeführt.

Im Jahr 2011 beschloss der Gemeinderat der Landeshauptstadt Stuttgart die Gründung eigener, 100 Prozent kommunaler Stadtwerke. Die seit Juli 2012 operativ tätigen Stadtwerke Stuttgart sind die zweite Gründung eines großstädtischen Stadtwerks in Deutschland seit der Marktliberalisierung von 1998. Es bietet seit Februar 2013 Ökostrom und Erdgas für alle Stuttgarter Privat- und Gewerbekunden an. In zunehmendem Maße betreiben die Stadtwerke dazu auch eigene Wind- und Solarstromanlagen und sind Contractor für Energiesysteme zur Wärme- und Stromerzeugung. Im Oktober 2014 entschied zudem der Stuttgarter Gemeinderat mehrheitlich, den Betrieb des 5000 km langen Strom- und des 1700 km langen Gasnetzes in der Landeshauptstadt – rückwirkend zum 1. Januar 2014 – an eine Kooperation der Stadtwerke Stuttgart und der EnBW-Tochter Netze BW zu vergeben. Das Kooperationsmodell hatte bei der Vergabe der Konzession für die Energieversorgungsnetze in den nächsten 20 Jahren die höchste Punktzahl erhalten. Nach einer Übergangsphase ist das Gemeinschaftsunternehmen ab 2016 zunächst für das Strom- und ab 2019 für das Gasnetz verantwortlich.

Früher gab es auch zahlreiche Mittelspannungs-Freileitungen im Stadtgebiet, die jedoch allesamt durch unterirdische Kabel ersetzt worden sind, da diese weniger störungsanfällig sind. Den letzten derzeit noch existierenden oberirdischen Abschnitt bildet eine 55 m lange Freileitung über die Gleise der Gäubahn am Knappenweg in Dachswald, die derzeit durch ein Erdkabel ersetzt wird. Aufgrund des schwierigen Terrains war der Bau des Erdkabels mit einem Umweg von etwa 1 km verbunden.

Die Versorgung der elektrischen Bahnstrecken der Deutschen Bahn im Stadtgebiet erfolgt über die Zentraleinspeisstelle Zazenhausen im Norden der Stadt. Für die S-Bahnen nach Bernhausen und Herrenberg existiert in Rohr ein Unterwerk, das über eine von der Bahnstromleitung Zazenhausen–Eutingen bei Ehningen abzweigende Bahnstromleitung versorgt wird und zum größten Teil parallel zur Bahnlinie Herrenberg-Stuttgart verläuft. Daneben existieren für die Einspeisungen weiterer S-Bahn-Strecken weitere Unterwerke im Umland, etwa in Leonberg oder Waiblingen.

Der Bärensee, der Neue See und der Pfaffensee im Westen der Stadt dienten früher der Trinkwasserversorgung Stuttgarts. Seit 1917 wird Stuttgart unter anderem von der Landeswasserversorgung mit Trinkwasser aus dem Donautal bei Langenau versorgt. Die Leitung erreicht über Göppingen in Rotenberg das östliche Stadtgebiet. Seit 1958 kommt zusätzlich über die Bodensee-Wasserversorgung Trinkwasser aus dem Bodensee. Die Einspeisstelle liegt in Rohr im Südwesten der Stadt. Wassertürme stehen in Degerloch und auf dem Gähkopf (Bismarckturm).

An der südlichen Stadtgrenze liegt der Flughafen Stuttgart, der größte Flughafen des Landes Baden-Württemberg. Das Areal befindet sich überwiegend auf der Gemarkung Filderstadt.

Seit der Eröffnung des neuen Terminals 3 im März 2004 hat der Stuttgarter Flughafen eine Kapazität von 12 Millionen Passagieren. 2003 flogen etwa 7,6 Millionen Gäste, 2004 bereits 8,8 Millionen; 2005 flogen 9,5 Millionen Passagiere von und nach Stuttgart. Bis Ende 2006 waren es über 10 Millionen Passagiere.

An der nördlichen Gemarkungsgrenze von Stuttgart liegt der Sonderlandeplatz Flugplatz Pattonville, der ausschließlich von Sport- und Segelfliegern genutzt wird.

Die Stadt ist auch ein wichtiger Eisenbahnknoten. Vom Stuttgarter Hauptbahnhof führen Verbindungen nach Vaihingen/Enz–Pforzheim–Karlsruhe–Straßburg–Paris (seit Sommer 2007 mit TGV-Verbindungen, siehe LGV Est européenne), nach Heilbronn–Heidelberg–Mannheim–Frankfurt am Main–Mainz–Köln–Düsseldorf–Dortmund/–Hannover–Hamburg/–Berlin, nach Plochingen–Göppingen–Ulm–München–Salzburg–Linz–St. Pölten–Wien(–Bratislava oder –Győr–Budapest), nach Memmingen–Kempten (Allgäu)–Oberstdorf (über Ulm), nach Ravensburg–Friedrichshafen–Lindau (über Ulm), nach Freudenstadt/Rottweil (Zugteilung in Eutingen im Gäu), nach Horb–Rottweil–Singen am Hohentwiel–Schaffhausen–Zürich, nach Waiblingen–Schwäbisch Hall-Hessental–Ansbach–Nürnberg, nach Rottenburg–Horb und Hechingen–Balingen–Sigmaringen–Aulendorf (über Plochingen, Reutlingen und Tübingen, dort Zugteilung), nach Ludwigsburg–Heilbronn–Bad Friedrichshall – Würzburg/Mosbach-Neckarelz und nach Schwäbisch Gmünd–Aalen.

Zum Eisenbahnknoten Stuttgart gehören auch das Containerterminal in Obertürkheim und der Rangierbahnhof Kornwestheim, der über eines der modernsten Container-Terminals im Bereich der DB verfügt. Beide Terminals sind der DUSS (Deutsche Umschlaggesellschaft Schiene-Straße) zugehörig.

Im Jahr 1991 begann der ICE-Schnellverkehr auf der Linie Hamburg–Frankfurt am Main–Stuttgart–München. Im Zuge dessen wurde die neue Schnellfahrstrecke von Stuttgart nach Mannheim eingeweiht.

Im Zuge des umstrittenen Projekts Stuttgart 21 wird der Eisenbahnknoten Stuttgart grundlegend neu geordnet. Dabei entstehen unter anderem rund 60 km neue Eisenbahnstrecken und vier neue Bahnhöfe (neuer Hauptbahnhof, neuer Flughafenbahnhof, S-Bahnhof Mittnachtstraße und der Abstellbahnhof Untertürkheim). Parallel soll die Neubaustrecke Wendlingen–Ulm entstehen. 1997 verabschiedete der Stuttgarter Gemeinderat den städtebaulichen Rahmenplan des Projekts, kurz darauf begann die Bebauung erster Teilgebiete.

Den öffentlichen Personennahverkehr (ÖPNV) bedienen sieben S-Bahn-Linien der DB Regio (siehe: S-Bahn Stuttgart) sowie 15 Stadtbahn-Linien (darunter zwei Bedarfslinien), eine Zahnradbahnlinie, eine Standseilbahnlinie und 56 Buslinien der "Stuttgarter Straßenbahnen AG" (SSB), die Linie 101 des Oberleitungsbusses Esslingen am Neckar (vom Städtischen Verkehrsbetrieb Esslingen am Neckar betrieben) und mehrere Buslinien privater Verkehrsunternehmen. Außerdem übernehmen einige Regionalbahnlinien Nahverkehrsaufgaben innerhalb der Stadt (zum Beispiel die „Schusterbahn“).

Alle diese Nahverkehrsmittel, auch die Zahnradbahn und die Standseilbahn, sind zu einheitlichen Preisen innerhalb des Verkehrs- und Tarifverbunds Stuttgart (VVS) nutzbar.
Stuttgart bietet mit Stadtmobil ein flächendeckendes Carsharing-Angebot an über 130 Stationen und mit „Stella“ 75 E-Roller der Stadtwerke Stuttgart im Stadtgebiet. Die Bahn betreibt seit 2007 rund 45 „Call a Bike“-Fahrrad-Mietstationen sowie Mietstationen von Flinkster, dem Carsharing-Angebot der Bahn. Seit 2012 betreibt car2go in Stuttgart ein Carsharing-Angebot mit insgesamt 550 Elektroautos der Typen Smart Fortwo und Mercedes-Benz B-Klasse.

Bei einer Zählung am 21. Oktober 2014 passierten im Straßenverkehr täglich rund 827.000 Straßenfahrzeuge (bis 3,5 Tonnen) die Stadtgrenze Stuttgarts. Die Zahl der in Stuttgart zugelassenen Fahrzeuge erreichte mit 348.103 Ende 2014 einen neuen Rekord. Auch in der Unfallstatistik nahm die Zahl der registrierten Verkehrsunfälle im Jahr 2015 um 1,4 Prozent zu und hat mit 26.702 Unfällen den höchsten Wert seit 1979 erreicht. Die Stadt liegt nach einer Steigerung auf 73 Stunden pro Jahr auf Platz eins der staureichsten Ballungsräume in Deutschland. Dabei wird die Zunahme der Stauzeit um 8,5 Stunden im Vergleich zum Jahr 2014 überwiegend auf die Rekordzahl von 50.000 mehr zugelassenen Fahrzeugen in Stuttgart zurückgeführt.

Trotz der deutschlandweit höchsten Verkehrsbelastung und Staugefahr überhaupt hat Stuttgart kaum Möglichkeiten zur Ortsumgehung und keinen eigenen Autobahnring wie zahlreiche andere deutsche Städte ("siehe auch Nordostring Stuttgart"), sodass zum intensiven lokalen Verkehr ein extremer Durchgangsverkehr den Stadtkern im Talkessel belastet. Dieses überhöhte Verkehrsaufkommen bringt eine starke Belastung der Luftqualität und ein hohes CO- und Stickoxide-Aufkommen mit sich, die Stadt Stuttgart sah sich deshalb bereits mehrfach gezwungen, einen Feinstaub-Alarm zu verhängen.

Die Autobahn A 8 (Karlsruhe–(S)–Ulm–München) bildet die südliche Stadtgrenze und die A 81 (Singen–(S)–Heilbronn–Würzburg) führt westlich der Stadt vorbei. Ab dem Autobahnkreuz Stuttgart laufen beide Autobahnen dann gemeinsam bis zum einige Kilometer westlich liegenden Leonberger Dreieck, an dem die A 81 dann wieder in nördlicher Richtung abzweigt. Dieser Abschnitt hat drei bis fünf Fahrspuren pro Richtung bei einem enorm hohen Verkehrsaufkommen und einem erheblichen Gefälle.

Am "Autobahnkreuz Stuttgart", früher auch Kreuz Stuttgart-Vaihingen genannt, ist die Geradeaus-Richtung der A 81 ein kurzes Autobahnstück, das als A 831 zur Ausfahrt Stuttgart-Vaihingen und weiter als B14 über den "Schattenring" Richtung Innenstadt führt.
Dieses Autobahnkreuz liegt auf der Sindelfinger Markung; auf Stuttgarter Gebiet im Wald befindet sich dort die ehemalige Hauptverwaltung der IBM Deutschland und der höchste Punkt von Stuttgart, die Bernhartshöhe.

Quer durch die Stuttgarter Innenstadt verlaufen die Bundesstraßen B 14 (Stockach-Herrenberg-Stuttgart-Schwäbisch Hall–Nürnberg-Waidhaus) und B 27 (Blankenburg–Heilbronn–Stuttgart–Tübingen–Lottstetten) sowie durch das Stadtgebiet die B 10 (Eppelborn–Pforzheim–Stuttgart–Ulm–Neusäß) und B 295 (Stuttgart-Leonberg-Calw). Bis auf die B 14 führen alle auf dem Pragsattel zusammen, dem größten Verkehrsknoten der Stuttgarter Innenstadt.

Die B 10 (Richtung Göppingen/Ulm), die B 14 (Richtung Schwäbisch Hall), die B 27 (Richtung Tübingen) und die B 29 (ab Fellbach Richtung Aalen) sind jeweils autobahnähnlich ausgebaut und bilden eine sternförmige Struktur von Schnellstraßen um die Stadt.

Insgesamt führen elf Schnellstraßen vom Stuttgarter Hinterland in Richtung Stuttgarter Stadtzentrum. Diese sind:

Die Stuttgarter Straßennamen wurden 1811 grundsätzlich umgestellt und auch später öfter wieder geändert. In der älteren Literatur und in alten Zeitungen und Zeitschriften werden zwangsläufig auch ältere Straßennamen angegeben.

Stuttgart ist sowohl der am höchsten mit Feinstaub als auch mit Stickstoffdioxid belastete Ort in Deutschland. Deshalb wurde eine Umweltzone eingerichtet. Die Umweltzone, in der das Fahrverbot gilt, ist in Stuttgart auf das gesamte Stadtgebiet inklusive aller 23 Stadtbezirke (Gemarkung Stuttgart) festgelegt. Nur die Autobahnen sind davon ausgenommen. Seit dem 1. März 2008 gilt die Feinstaubplakettenpflicht. Alle Fahrzeuge, die seit diesem Zeitpunkt innerhalb dieser Umweltzone bewegt werden, müssen mindestens der Schadstoffgruppe 2 angehören (auch auf allen Bundesstraßen durch Stuttgart). Fahrzeuge der Schadstoffgruppe 1 (ohne Plakette) unterliegen einem Fahrverbot. Zum 1. Juli 2010 wurde das Fahrverbot nach der Kennzeichnungsverordnung auf Fahrzeuge der Schadstoffgruppe 2 (rote Plakette) ausgeweitet. Der Grenzwert der Stickoxidbelastung wird in Stuttgart regelmäßig um das Doppelte überschritten. Die Feinstaubmessstation „Am Neckartor“ erreichte von 2005 bis 2010 jedes Jahr mit 88 bis 187 Überschreitungen des PM10-Tagesgrenzwertes stets die meisten Überschreitungen in Deutschland.

Im Januar 2016 hat Stuttgart als erste Stadt in Deutschland einen Feinstaubalarm eingeführt. Bei entsprechender Wetterlage werden die Bürger aufgerufen, ihr Kraftfahrzeug nicht zu benutzen. Soweit Appelle zum freiwilligen Umstieg nicht greifen, sollen ab Ende 2017 bei hohen Luftschadstoffwerten Fahrverbote für Fahrzeuge mit geraden oder ungeraden Kennzeichen gelten. Ab 2019 sollen grundsätzlich nur noch Dieselfahrzeuge nach Euro-6-Norm fahren dürfen.

Nach einem im Februar 2017 gefassten Beschluss des Landeskabinetts dürfen bei Feinstaubalarm ab 2018 in den Talkessel sowie Teile von Feuerbach und Zuffenhausen Dieselfahrzeuge nur noch einfahren, wenn sie die Euro-6-Norm erfüllen. Ausnahmeregelungen werden diskutiert, nicht jedoch für Anlieger. Das Verbot soll 2020 auf das gesamte Stadtgebiet ausgedehnt werden. Eine ebenfalls beschlossene Einbeziehung von Fahrzeugen mit Ottomotor, die nicht wenigstens die Euro-3-Norm, erfüllen, scheiterte am Widerstand des Bundes gegenüber der Blauen Plakette.

Am 31. März 1958 wurde der Stuttgarter Hafen durch Bundespräsident Theodor Heuss eröffnet. Die vier Neckarvororte Wangen, Hedelfingen, Obertürkheim und Untertürkheim liegen am zweitgrößten Binnenhafen des Neckars. Nach der Erweiterung 1968 wurde er zum wichtigsten trimodalen Verkehrsknotenpunkt (Wasser, Schiene, Straße) in der Region Stuttgart.

Stuttgart gilt als bedeutende Medienstadt. Im Stuttgarter Funkhaus hat der Intendant des öffentlich-rechtlichen Südwestrundfunks seinen Sitz. Dort werden zwei Hörfunkprogramme für Baden-Württemberg produziert (SWR1 und SWR4). In den Fernsehstudios werden neben aktuellen Magazinen (z. B. Sport) vor allem die Nachrichtensendungen für das Dritte Programm und die Landesschau live hergestellt. Ebenso verfügt Stuttgart mit Regio TV über einen zusätzlichen regionalen Fernsehsender.

Weitere audiovisuelle Medien (zum Beispiel Antenne 1, bigFM, Die Neue 107.7, Freies Radio für Stuttgart) sind ebenfalls in Stuttgart beheimatet. Stuttgart ist neben Karlsruhe einer der beiden Standorte des Landesmedienzentrums Baden-Württemberg, das dem Ministerium für Kultus, Jugend und Sport Baden-Württemberg untersteht.

Darüber hinaus gilt die Stadt als einer der bundesweit führenden Standorte für Fachverlage. Überregional bekannt sind unter anderem Deutscher Sparkassenverlag, Ernst Klett Verlag, Kohlhammer Verlag, Metzler Verlag, Motor Presse Stuttgart und Georg Thieme Verlag. Mit der Deutschen Bibelgesellschaft und dem Katholischen Bibelwerk sind in Stuttgart die mit Abstand größten Bibelverlage ansässig.

Schließlich erscheinen hier die "Stuttgarter Zeitung", die als eine der größten Regionalzeitungen Deutschlands gilt, und die "Stuttgarter Nachrichten" sowie kleinere Lokalausgaben anderer Tageszeitungen wie etwa die "Cannstatter Zeitung". Unter den Stadtmagazinen erscheint "Lift" einmal im Monat, während man "Prinz Stuttgart" im Internet abrufen kann und "Moritz – Das Stadtmagazin" das auflagenstärkste Stadtmagazin in Baden-Württemberg ist.

Rund 11 % aller Gelder für Forschung und Entwicklung in Deutschland werden in Stuttgart ausgegeben. Neben den beiden Universitäten (Stuttgart und Hohenheim) bestehen in Stuttgart fünf Institute der Fraunhofer-Gesellschaft (der zweitgrößte Standort in Deutschland), mehrere Max-Planck-Institute sowie andere Einrichtungen. Große Teile der Stuttgarter Forschungslandschaft sind inzwischen auf dem Forschungscampus in Vaihingen konzentriert worden.



Die Landeshauptstadt Stuttgart ist außerdem „Korporativ Förderndes Mitglied“ der Max-Planck-Gesellschaft.


1919 wurde in Stuttgart von Emil Molt, dem Direktor der Waldorf-Astoria-Zigarettenfabrik, und von Rudolf Steiner auf der Uhlandshöhe die erste Waldorfschule gegründet, eine der von Steiner begründeten Anthroposophie sowie humanistischen Bildungsidealen folgenden Gesamtschulform, die heute in vielen Ländern der Welt besteht.

In Stuttgart befinden sich seit dem Ende des Zweiten Weltkriegs mehrere US-amerikanische Kasernen:

Die Bundeswehr unterhält im Stadtbezirk Bad Cannstatt die Theodor-Heuss-Kaserne (vormals Funkerkaserne). In dieser liegen unter anderem das Karrierecenter der Bundeswehr Stuttgart, die MAD-Stelle 5 und eine Außenstelle des Bundesamtes für das Personalmanagement der Bundeswehr (BAPersBw V Sz Süd), sowie das Landeskommando Baden-Württemberg.
Stuttgart ist Sitz des THW-Landesverbandes Baden-Württemberg der Bundesanstalt Technisches Hilfswerk. Außerdem befindet sich hier eine Geschäftsstelle der Sozialversicherung für Landwirtschaft, Forsten und Gartenbau (SVLFG).

Seit 1874 besteht die Stiftung Evangelische Altenheimat.
Der Körperbehinderten-Verein Stuttgart e. V. kümmert sich mit Veranstaltungen, Tagesstätten sowie einem Fahrdienst für Behinderte um die Eingliederung von körperlich behinderten Menschen in den Alltag.

→ "Hauptartikel: Liste der Ehrenbürger von Stuttgart"

→ "Hauptartikel: In Stuttgart geborene Persönlichkeiten"

→ "Hauptartikel: Bekannte Einwohner von Stuttgart"


Der von Erwin Schwab am 17. August 2009 entdeckte Hauptgürtelasteroid (264020) Stuttgart wurde nach der Stadt benannt.




</doc>
<doc id="4493" url="https://de.wikipedia.org/wiki?curid=4493" title="Steve Jobs">
Steve Jobs

Steven „Steve“ Paul Jobs (* 24. Februar 1955 in San Francisco, Kalifornien; † 5. Oktober 2011 in Palo Alto, Kalifornien) war ein US-amerikanischer Unternehmer. Als Mitgründer und langjähriger CEO von Apple Inc. gilt er als eine der bekanntesten Persönlichkeiten der Computerindustrie. Zusammen mit Steve Wozniak und Ron Wayne gründete er 1976 Apple und half, sowohl das Konzept des Heimcomputers als auch später die Generation der Smartphones sowie Tabletcomputer populär zu machen. Zudem war er mit dem Macintosh ab 1984 maßgeblich an der Einführung von Personal Computern mit grafischer Benutzeroberfläche beteiligt und entwickelte mit dem iTunes Store und dem Medienabspielgerät iPod in den frühen 2000er Jahren wichtige Meilensteine für den Markterfolg digitaler Musikdownloads. Jobs war darüber hinaus Geschäftsführer und Hauptaktionär der Pixar Animation Studios und nach einer Fusion größter Einzelaktionär der Walt Disney Company. Er starb am 5. Oktober 2011 an einer Krebserkrankung. Sein Vermögen wurde im März 2011 vom Wirtschaftsmagazin Forbes Magazine auf 8,3 Milliarden US-Dollar geschätzt.

Steve Jobs wurde als Sohn des syrischen Politikstudenten Abdulfattah Jandali und der Amerikanerin deutscher und Schweizer Abstammung Joanne Carole Schieble in San Francisco geboren. Da weder die Eltern seiner leiblichen Mutter noch die Eltern des Vaters einer Ehe zugestimmt hätten und seine 23-jährigen Eltern nicht für den Unterhalt des Kindes sorgen konnten, gab Schieble ihren Sohn als Sozialwaise zur Adoption frei. Schieble machte ihre Zustimmung zur Adoption davon abhängig, dass ihr Sohn bei Akademikern aufwachsen sollte. Zunächst lehnte ein Anwalt die Adoption kurz nach Jobs’ Geburt ab, weil er und seine Frau sich eine Tochter wünschten und Steve Jobs wurde schließlich kurz nach seiner Geburt von Paul Reinhold Jobs (1922–1993) und dessen armenischstämmiger Frau Clara Jobs (geborene Hagopian, 1924–1986), aus Mountain View, Kalifornien, adoptiert und erhielt von diesen schließlich den Namen Steven Paul Jobs. Dem Ehepaar Jobs, beide keine Akademiker, rang Schieble das Versprechen ab, Jobs den Zugang zum College zu ermöglichen. Von seinen biologischen Eltern wie auch von seiner leiblichen Schwester, der Autorin Mona Simpson, erfuhr er erst rund 20 Jahre später.

Schon in seiner Kindheit erwachte Steve Jobs’ Interesse an der zu dieser Zeit im Wachstum befindlichen Elektronikindustrie. Im Silicon Valley, dem Santa Clara Valley, in dem auch Palo Alto lag, wohnte Jobs in unmittelbarer Nachbarschaft zu Ingenieuren von Firmen wie Hewlett-Packard und Intel. Seine Eltern bemerkten früh, dass Jobs schnell lernte. Schon bei der Einschulung in die Monta Loma Elementary konnte er lesen und langweilte sich in den ersten Jahren eher, als etwas zu lernen, bis sich eine Lehrerin seiner annahm und ihm ermöglichte, eine Klasse zu überspringen.

Im Jahre 1972 erreichte er den High-School-Abschluss an der Homestead High School in Cupertino, Kalifornien, und schrieb sich am Reed College in Portland ein. Das Studium brach Jobs schon nach dem ersten Semester ab, blieb jedoch noch längere Zeit am Campus und besuchte einzelne Vorlesungen. Anfang 1974 arbeitete er einige Monate bei Atari und bereiste anschließend Indien, wo er sich mit dem Hinduismus, dem Buddhismus und der Primärtherapie (Urschreitherapie) beschäftigte. Finanziert hatte die Reise ihm und seinem Freund Dan Kottke der Atari-Ingenieur Allan Alcorn mit der Auflage, über Deutschland zu fliegen. Jobs half in München dann dem dortigen Atari-Vertrieb, Erdungsprobleme amerikanischer 60-Hertz-Netzteile in Atari-Spielecomputern im deutschen 50-Hertz-Stromnetz zu beseitigen.

Im Herbst 1974 war er zurückgekehrt und nahm an Zusammenkünften des Homebrew Computer Clubs teil. Er arbeitete wieder bei Atari und beschaffte einen Auftrag für das Spiel Breakout. Steve Wozniak, ein enger Freund, den er einige Jahre zuvor über den gemeinsamen Freund Bill Fernandez kennengelernt hatte, entwickelte das Spiel in vier Tagen. Jobs behauptete, dass er nur 700 Dollar bekommen habe, und gab Wozniak 350 Dollar, obwohl das Honorar 5000 Dollar betrug.

In den 70er Jahren ernährte sich Steve Jobs nach der strengen Ernährungsweise der Frutarier, wodurch nach eigenen Angaben auch der Name seines Unternehmens "Apple" entstand.

Während dieser Zeit entdeckte John T. Draper (alias "Captain Crunch"), dass man mit einer modifizierten Spielzeugpfeife, die sich in jeder Packung von "Cap’n Crunch" Frühstücksflocken befand, den 2600-Hertz-Ton erzeugen konnte, der bei AT&T von den Vermittlungsstellen verwendet wurde, um die Abrechnung der Gesprächsgebühren zu steuern. Wozniak baute daraufhin eine Blue Box, die diesen Ton erzeugen konnte. Er und Jobs begannen 1974, diese Kästen zu verkaufen, die es dem Besitzer ermöglichten, kostenlose Ferngespräche zu führen.

1976 gründeten Jobs und Wozniak zusammen mit Ronald Wayne die Apple Computer Company in Jobs’ Garage in Los Altos, Kalifornien. Ihr erstes, mit dem Apfel mit Biss (Bite) beworbenes Produkt war der Apple I, der für 666,66 Dollar verkauft wurde. Der Prototyp steckte in einem selbst gebauten Holzgehäuse.

1977 wurde der Apple II eingeführt, der Apple zu einem wichtigen Akteur im Heimcomputermarkt machte. Im Dezember 1980 erfolgte die Umwandlung von Apple in eine Kapitalgesellschaft, und Apple präsentierte den Apple III, der jedoch kein vergleichbar großer Erfolg wurde. 1983 warb Jobs den Pepsi-Manager John Sculley für den Posten als Geschäftsführer bei Apple an. Im selben Jahr brachte Apple den "Apple Lisa" auf den Markt.

In dieser Zeit machte sich Steve Jobs für eine steuerlich begünstigte Einführung von Personal Computern in Schulen stark. Der erste Artikel der New York Times, der Jobs erwähnt, handelt von diesem damals noch nicht durchsetzbaren Gesetzesvorhaben:

1984 stellte Apple den Macintosh vor. Es war der erste kommerziell erfolgreiche Computer mit einer grafischen Benutzeroberfläche (also Bildschirmsymbolen statt Kommandozeilen-Code) und der Computermaus als Standardeingabemedium. Die Entwicklung des „Macs“ fing mit Jef Raskin und seinem Team an, die durch die Technik inspiriert wurden, die im Xerox-Forschungszentrum entwickelt, aber nicht kommerziell verwendet wurde. Der Erfolg des Macintosh brachte Apple dazu, den Apple II zugunsten der Macintosh-Produktlinie aufzugeben, die bis heute verfolgt wird.

Nach einem internen Machtkampf mit Sculley verließ Jobs 1985 das Unternehmen. Fünf nahe Angestellte folgten ihm.

Für Jobs begannen fünf Jahre, die er später als eine seiner kreativsten Phasen bezeichnete.

1986 gründete er mit der Firma NeXT Computer ein weiteres Computerunternehmen. Aus Sorge, dass er bei den geplanten NeXT-Rechnern Apple-Technik verwenden würde, ging Sculley gegen Jobs vor Gericht. Der Vorwurf lautete: Bruch treuhänderischer Verantwortlichkeit („Breach of fiduciary responsibility“) und „ruchlose“ Anstiftung zum Abziehen von Apples Handelsgeheimnissen. Das Verfahren endete am 17. Januar 1986 mit einem Vergleich, in dem sich Jobs verpflichtete, Apple eine Zeit lang Einblicke in NeXT-Entwicklungen zu gestatten, indem er der Firma Prototypen zeigte, und bis zum 1. Juli 1987 keine eigenen Computer auf den Markt zu bringen.

Die NeXT-Workstation war den anderen Geräten am Markt technisch voraus, wurde jedoch außerhalb wissenschaftlicher Anwendungen niemals populär. So entwickelte Tim Berners-Lee das World Wide Web am Schweizer CERN-Institut auf einer NeXT-Workstation. NeXT verwendete zukunftsweisende Techniken wie das objektorientierte Programmieren, Display PostScript und magneto-optische Laufwerke.

Um sich auf die Software-Entwicklung konzentrieren zu können, verkaufte Jobs nach sieben Jahren das Hardwaregeschäft im Februar 1993 an den vormaligen Investor Canon. Von den ursprünglich 530 Mitarbeitern blieben 200 bei NeXT und 100 wechselten zu Canon.

Parallel zur NeXT-Gründung investierte Jobs 1986 gemeinsam mit Edwin Catmull fünf Millionen Dollar (ein Drittel des ursprünglichen Preises) plus weitere fünf Millionen, um Pixar, ein in Emeryville, Kalifornien, ansässiges Computertrickfilm-Studio von dessen Gründer George Lucas aus der Lucasfilm-Grafikabteilung herauszukaufen.

Mit "Toy Story" gelang dem Unternehmen 1995 ein erster Erfolg, und der Börsengang machte Jobs zum Milliardär. Als erster vollständig computeranimierter Kinofilm wurde die Produktion mit dem Special Achievement Award (Oscar für „besondere Leistungen“) ausgezeichnet. Unter Jobs wurden die Pixar-Filme "Findet Nemo" und "Die Unglaublichen – The Incredibles" mit je einem Oscar in der seit 2002 bestehenden Kategorie „Bester animierter Spielfilm“ ausgezeichnet.

Am 24. Januar 2006 gab der Medien- und Entertainment-Konzern Walt Disney Company nach US-Börsenschluss bekannt, dass er Pixar für 7,4 Milliarden Dollar übernehmen werde. Als Teil des Geschäfts wurde Pixar-CEO Steve Jobs in den Verwaltungsrat (genau: Board of Directors) von Disney aufgenommen. Zudem wurde Jobs durch seinen Pixar-Anteil von etwa 50,1 % mit 6 % größter Einzelaktionär bei Disney. Im März 2010 hielt Jobs 138 Millionen Disney-Aktien.

1996 kaufte Apple NeXT für 402 Mio. US-Dollar. Jobs übte seitdem eine Beratertätigkeit im Unternehmen aus. Im August 1997 wurde er Mitglied des Vorstandes und kurz darauf, nach der Entlassung von Gil Amelio im September des Jahres, vorübergehend Geschäftsführer des Unternehmens. Noch im gleichen Jahr beendete Jobs viele Produkte und Forschungsprojekte sowie alle langjährigen Wohltätigkeitsprogramme des Unternehmens. Er begründete dies mit der Notwendigkeit Kosten einzusparen, um die Rentabilität des Unternehmens wiederherzustellen.

Mit dem Kauf von NeXT wurde dessen Technik übernommen und in die Apple-Produkte integriert; hauptsächlich handelte es sich dabei um NeXTStep, das schrittweise aktualisiert und schließlich unter dem Namen „Mac OS X“ zum neuen Betriebssystem der Macintosh-Rechner wurde. Auch das aktuelle (inzw. umbenannte) OS X hat nicht nur oberflächliche Ähnlichkeiten zu NeXTStep wie zum Beispiel das Dock, sondern verwendet dieselben Kerntechnologien, insbesondere FreeBSD, Objective-C und die Cocoa-API.

Unter Jobs’ Führung wurde 1998 der iMac eingeführt, der dem angeschlagenen Konzern half, in die Gewinnzone zurückzukommen. Mit den tragbaren Musikabspielgeräten iPod im Jahr 2001, der Jukebox-Software iTunes, dem iTunes Store (bis 2006 iTunes "Music" Store) und dem iPhone (2007) schuf das Unternehmen einen neuen Markt für „Digital-Lifestyle“-Produkte. An den Erfolg dieser Produkte knüpfte das am 27. Januar 2010 durch Jobs präsentierte iPad an.

Jobs arbeitete bei Apple über mehrere Jahre hinweg für ein Jahresgehalt von einem Dollar und wurde damit in das Guinness-Buch der Rekorde als schlechtest bezahlter Geschäftsführer aufgenommen. Nachdem Apple wieder zu einem gewinnträchtigen Unternehmen geworden war, entfernte das Unternehmen im Januar 2001 das „vorübergehend“ aus Jobs’ Titel des Geschäftsführers. Zusätzlich zu seinem Gehalt erhielt Jobs allerdings einige exklusive Geschenke von der Geschäftsleitung; beispielsweise einen 35 Mio. US-Dollar teuren Jet im Jahr 1999, den er in der ungenutzten Zeit an Apple vermietete, sowie fast 30 Millionen Anteile der Apple-Aktien 2000–2002. Im März 2010 hielt Jobs 5,426 Millionen Apple-Aktien.

Im Januar 2011 übergab Steve Jobs das Tagesgeschäft aus gesundheitlichen Gründen an Tim Cook. Er blieb jedoch weiterhin CEO von Apple. Am 24. August 2011 trat Steve Jobs endgültig als CEO von Apple zurück. Tim Cook wurde schließlich offiziell zum dauerhaften Nachfolger berufen, nachdem er den Konzern bereits seit dem 17. Januar 2011 vertretungsweise geführt hatte. Jobs selbst wurde zum Vorsitzenden des Verwaltungsrats gewählt. Diese Position hatte er bis zu seinem Tod am 5. Oktober inne.

Am 18. März 1991 heiratete Jobs Laurene Powell. Das Paar hat drei Kinder. Aus einer Beziehung zu der Journalistin Chrisann Brennan stammt die 1978 geborene Tochter Lisa Brennan-Jobs. 1996 veröffentlichte seine Schwester Mona Simpson mit dem Buch „A Regular Guy“ die Geschichte von Steve und Lisa. In den 1980er Jahren hatte er außerdem eine Beziehung mit der Folksängerin Joan Baez.

Jobs interessierte sich schon als Student für eine gesunde Ernährungsstrategie. Nachhaltig prägten ihn die Ideen des deutschen Naturheilkundlers Arnold Ehret. Steve Jobs Ernährungsgewohnheiten haben sich im Laufe seines Lebens mehrfach geändert. Die längste Zeit seines Lebens war Steve Jobs Veganer, bekannte sich zeitweise aber auch zum Vegetarismus, Fruitarismus und zum Pescetarismus. Zugleich war Jobs Buddhist. Er bezeichnete sich als Fan von Bob Dylan und den Beatles; letztere waren das Vorbild für sein Geschäftsmodell, wie er in der amerikanischen Dokumentationsserie "60 Minutes" sagte:

Am 31. Juli 2004 unterzog sich Steve Jobs einer Operation, bei der ein Inselzell-Tumor entfernt wurde. Während seiner Abwesenheit vertrat ihn bei Apple COO Tim Cook. Laut der von Steve Jobs autorisierten Biografie von Walter Isaacson verweigerte sich Jobs nach der Diagnose im Oktober 2003 monatelang einer Operation. Vielmehr griff er auf alternative Behandlungsversuche zurück. Spätere Behandlungen schlossen eine individualisierte Therapie auf Basis einer Genomanalyse von Tumor- und Körperzellen ein.

Im August 2008 wurde vom Nachrichtendienst Bloomberg versehentlich ein unvollständiger Nachruf auf ihn veröffentlicht, der aber umgehend wieder gelöscht wurde. Anfang Januar 2009 äußerte sich Jobs in einem offenen Brief über seinen Gesundheitszustand und seine damit verbundene Abwesenheit bei der Macworld. Dabei führte er seinen Gewichtsverlust auf eine Hormonstörung zurück.

Später, im Januar 2009, kündigte Jobs an, sich krankheitsbedingt bis Ende Juni 2009 aus dem Tagesgeschäft von Apple zurückzuziehen. Im Juni 2009 wurde bekannt, dass sich Steve Jobs im April einer Lebertransplantation im Methodist University Hospital in Memphis (Tennessee) unterzogen hatte. Der Grund für die Lebertransplantation wurde nicht bekannt, jedoch wurde angenommen, dass der Tumor Lebermetastasen gebildet hatte. Zur Apple-Präsentation im Yerba Buena Center for the Arts in San Francisco kehrte Jobs am 9. September 2009 auf die Apple-Bühne zurück.

Im August 2011 wurde die erste von Steve Jobs genehmigte Biografie unter dem Titel "Steve Jobs" von Walter Isaacson im Verlag Simon & Schuster angekündigt. Nach einer zuvor im Jahr 2005 erschienenen Biografie des Verlags John Wiley & Sons hatte Jobs den Verkauf aller Werke dieses Verlages in den Apple Stores verbieten lassen, da diese Biografie nicht von ihm autorisiert worden war. In seinem Finanzbericht für das Jahr 2010 erklärte der Verlag, dass es zu einer Einigung gekommen sei und die Bücher des Verlages für das iPad zugänglich sein sollten.

Am 5. Oktober 2011 starb Steve Jobs zu Hause im Kreise seiner Familie an den Folgen seiner Krebserkrankung. Am 7. Oktober wurde er auf einem konfessionslosen Friedhof (Alta Mesa Memorial Park) in Santa Clara, Kalifornien, beigesetzt. Tim Cook lud die Mitarbeiter des Unternehmens zu einer internen Gedenkveranstaltung am 19. Oktober 2011 ein. Eine öffentliche Trauerfeier des Unternehmens wurde ausgeschlossen. Am 20. Oktober 2011 schaltete Apple eine spezielle Gedenkseite auf seiner Internetpräsenz frei, auf der kontinuierlich Beileidsbekundungen veröffentlicht werden, die per E-Mail gesendet wurden.
Ein Jahr nach dem Tod schaltete Apple ein Video über Steve Jobs auf die Startseite der Internetpräsenz.



Anlässlich des ersten Todestags von Steve Jobs entstand eine Wachsfigur, die in Madame Tussauds Hong Kong ausgestellt wird. Jobs ist darauf in seiner charakteristischen Kleidung (Jeans, Pullover, Turnschuhe) zu sehen.

Apple veröffentlichte am 5. Oktober 2012 eine Sonderstartseite mit einem Video über Steve Jobs. Auf einer darauffolgenden Seite würdigt Tim Cook, der neue Apple CEO, Steve Jobs als großen Visionär.

Am 12. September 2017 wurde anlässlich der Präsentation des iPhone X ein Monolog von Steve Jobs zu Beginn des Events in dem verdunkelten Steve Jobs Theater präsentiert.




</doc>
<doc id="4500" url="https://de.wikipedia.org/wiki?curid=4500" title="Suspense">
Suspense

Suspense (engl. für „Gespanntheit“; "die" oder "der" Suspense) ist ein Begriff aus der Theater-, Film- und Literaturwissenschaft. Er leitet sich von lat. "suspendere" („aufhängen“) ab und bedeutet so viel wie „in Unsicherheit schweben“ hinsichtlich eines befürchteten oder erhofften Ereignisses. Neben anderen Typen der dramatischen Spannung ist dem "Suspense" die meiste Aufmerksamkeit zuteilgeworden, weil er die Spannungserzeugung „mit den geringsten“ Mitteln ist und weil Suspense als intensivstes Mittel der Spannungserzeugung gilt.

Alfred Hitchcock wurde oft als „Master of Suspense“ bezeichnet. Er unterschied "Suspense" von "Surprise": Während "Surprise" ein unerwartetes Ereignis charakterisiert, meint der Begriff "Suspense" die Erwartung eines Ereignisses ohne sein Eintreffen. Hitchcock selbst gab seinem Interviewpartner François Truffaut in "Mr. Hitchcock, wie haben Sie das gemacht?" folgendes Beispiel: Wenn eine versteckte Bombe unter einem Tisch, an dem mehrere Leute frühstücken, plötzlich explodiert, ist dies ein Schreck und unterhält 20 Sekunden lang; wenn der Zuschauer die Lunte jedoch lange brennen sieht und die Figuren nichts davon ahnen, ist dies "Suspense" und fesselt fünf oder zehn Minuten lang. Einsatz filmischer Mittel und Kosten bleiben sich gleich, bei besserem Effekt. Beim Suspense im Sinne von Hitchcock muss also zwischen dem Wissen von Figuren und dem Wissen der Leser bzw. Zuschauer unterschieden werden.

In Hitchcocks Film "Psycho (1960)" ist die Spannung der berühmten Duschszene, in der ein Mord geschieht, vom Typus "Surprise": Die Aufregung des Zuschauers entsteht schockartig. Die darauf folgende Spannung ist dagegen vom Typus "Suspense", weil der Mord nach Hitchcocks Aussage das Ausmaß der Bedrohung klargemacht hat und daher keine hektischen Aktionen zur Aufrechterhaltung der Spannung mehr nötig sind.

Patricia Highsmith vermeidet es in ihrem Werkstattbericht "Suspense oder Wie man einen Thriller schreibt", den Begriff Suspense inhaltlich zu definieren, und spricht eher von einem literarischen Genre hauptsächlich US-amerikanischen Ursprungs, das mit bestimmten Publikumserwartungen, einer bestimmten Haltung der Kritiker und einem eher geringen Prestige in der Literaturszene verbunden ist. Spannungstypen mit bestimmten Genres gleichzusetzen, ist allerdings ein fragwürdiges Unterfangen: Denn Suspense kann nicht nur in Thrillern und Kriminalromanen, sondern unter anderem auch in Abenteuerromanen vorkommen.

Als Oberbegriff für dramatische Spannung wird in der Regel der Begriff "Tension" verwendet. Als Unterteilung hat sich die wissenschaftliche Literatur auf die drei Begriffe "Surprise", "Suspense" und "Mystery" geeinigt. In der Praxis sind diese drei Spannungstypen stets miteinander verbunden.
Darüber hinaus gibt es den Spannungstyp "Puzzle". Die Spannung ergibt sich dadurch, dass der Leser oder Zuschauer verschiedene Aspekte eines Textes nicht in einen sinnvollen Zusammenhang bringen kann. Im Film Babel wird der Leser zum Beispiel mit einem Strang in Marokko, einem Strang in Japan und einem Strang in den USA konfrontiert. Er ist gespannt, wie diese zusammengeführt werden.

Psychologen setzen sich seit den 1990ern intensiv mit Suspense auseinander. In einer Definition von Suspense als Emotion beschreibt der US-amerikanische Medienpsychologe Dolf Zillmann Suspense als „emotionale Reaktion, die typischerweise aus akuter Besorgnis um beliebte Protagonisten entspringt, die durch unmittelbar erwartete Ereignisse bedroht werden, wobei diese Besorgnis aus einer hohen aber nicht vollständigen subjektiven Gewissheit über das Eintreten der erwarteten bedauernswerten Ereignisses erwächst“.

Konflikt – der Aufeinanderprall gegensätzlicher Kräfte – ist das Kernelement dramatischer Darstellungen seit der Überwindung des aristotelischen Dramas im 18. Jahrhundert. Die mit Vorahnungen um die Auflösung derartiger Konflikte verbundene emotionale Erfahrung macht Suspense aus. Bei der Rezeption eines Textes oder Filmes entsteht Suspense aus der Befürchtung, dass etwas Unerwünschtes eintritt, oder aus der Hoffnung auf das Eintreten eines erwünschten Umstands. Damit der Rezipient ein Ereignis erwartet, muss ein spannender Text bzw. Film ihm Vorwissen vermitteln. Zudem muss der Rezipient auf Grundlage des Textes Präferenzen hinsichtlich der Ausgangs-Alternativen bilden können. Ob ein Ereignis erwünscht oder unerwünscht ist, hängt davon ab, was der Text diesbezüglich suggeriert. Empirische Untersuchungen zeigen, dass Ängste wie Hoffnungen gleichermaßen abhängen von der Größe einer Gefahr sowie von der emotionalen Einstellung des Lesers gegenüber den Akteuren. Die Größe einer Gefahr bzw. eines Anreizes beschreibt, was für die Figuren auf dem Spiel steht. Sie kann reichen vom Nicht-Erreichen eines Zieles bis hin zu körperlichen Schäden und Tod. Hoffnungen und Ängste bezüglich desselben Ereignisses fallen für beliebte und unbeliebte Protagonisten unterschiedlich aus.

Medien-Rezipienten empfinden Suspense, während sie Zeuge dramatischer Ereignisse werden, die andere Personen betreffen. Sie sind weder direkt bedroht, noch haben sie eine Möglichkeit, den Verlauf der Ereignisse zu beeinflussen. Die hilflose Erregung, in die der Rezipient trotzdem gerät, entspricht Disstress. Der Erregungstransfer von der literarischen / filmischen Figur auf den Rezipienten funktioniert über einen Umweg: Zwar ist nur der Protagonist in Gefahr. Doch der teilnehmende Beobachter erkennt, was für diesen auf dem Spiel steht. Mit dem Ergebnis, dass er mit dem unmittelbar Betroffenen mitfühlt. Voraussetzung dafür, dass aus einem Beobachter ein teilnehmender, mitfühlender Beobachter werde, ist Empathie. Demnach muss ein Text, um Spannung zu erzeugen, den Leser zum teilnehmenden Beobachter machen.

Wie die Beziehung zwischen Rezipient und Figur aufgebaut wird, dazu gibt es verschiedene Ansätze. Die einen sagen, dass dies über Ähnlichkeiten zwischen Rezipient und Figur, die zum Beispiel das Alter, den Lifestyle, das Geschlecht etc. betreffen. Andere gehen davon aus, dass die positive Relation über einen moralisch vorbildlichen Helden hergestellt wird.

Suspense resultiert aus offenen Fragen nach dem Fortgang einer Geschichte. Empirische Untersuchungen belegen, dass nicht Ungewissheit das Suspense-Erlebnis intensiviert, sondern im Gegenteil die subjektive Gewissheit, dass der beliebte Protagonist zu Schaden kommt. Hingegen unterbindet totale subjektive Gewissheit über den Story-Ausgang jeden Suspense. Gewissheit über ein künftiges Schaden bringendes Ereignis bereitet einen Rezipienten kognitiv vor, sodass er bei Konfrontation mit diesem Ereignis vor zu starkem emphatischem Disstress geschützt ist. Die Gewissheit, dass dem Protagonisten nichts geschieht, verhindert Spannung, da kein Grund für ein irgendwie geartetes Mitfühlen besteht. Die größte Spannung entsteht also theoretisch dann, wenn die subjektiv geschätzte Wahrscheinlichkeit für einen positiven Ausgang sehr klein, aber größer Null ist.

Rezipienten schätzen Erfolgswahrscheinlichkeiten, indem sie die Höhe einer Gefahr mit den Defensivkräften der Protagonisten in Verbindung setzen – also mit deren Fähigkeit, eine Herausforderung zu bewältigen. So ist etwa die Wahrscheinlichkeit, dass Menschen im Zuge eines Tsunami zu Schaden kommen, umso geringer, je früher diese über die nahende Gefahr informiert werden, je günstiger ihr Standort ist, je besser ausgerüstet und je kräftiger sie sind. Rezipienten empfinden in dem Maße größere Spannung, wie die Lösungsmöglichkeiten in einer Handlung reduziert werden – etwa wenn einem Helden die Munition ausgeht. Da die Erfolgswahrscheinlichkeiten vom Verhältnis von Gefahr bzw. Anreiz und der Defensivkraft des Protagonisten abhängt, kann der Suspense sowohl über die Erhöhung der Gefahr als auch über eine Verringerung der Defensivkräfte der Protagonisten gesteigert werden. In Anlehnung an die Musikwissenschaften wird diese Technik als Crescendo bezeichnet. Entsprechend haben nur solche Textkonstellationen Suspense-Potential, in denen die Auseinandersetzung sympathischer Protagonisten mit bedrohlichen oder verlockenden Ereignissen angekündigt wird, denen diese Figuren nicht gewachsen zu sein scheinen.

Ausgehend von diesen Erkenntnissen muss ein spannender Text bzw. Film zeigen, dass ein Protagonist in einen Konflikt gerät. Er muss die Gefahr (bzw. den Anreiz) offenlegen, der der Protagonist ausgesetzt ist, und die Konsequenzen des maximal möglichen negativen Ergebnisses verdeutlichen.
Sobald ein Text oder Film einen negativen Ausgang etabliert haben, kann die negative Konsequenz als Anschlusspunkt dienen für Versuche von Figuren, die Gefahr abzuwenden. Dabei können mehrere Figuren kooperieren. Sie können auch unabhängig versuchen, der Gefahr auszuweichen. Einzelne Versuche können sich in Teilversuche aufspalten, die dann jeweils scheitern oder erfolgreich sein können.

Suspense zerfällt in "Erwartung" und "Zweifel". Die Erwartung ist an die Vorstellung von etwas künftig Eintreffendem geknüpft. Da jede vorgestellte Zukunft auch nicht eintreffen kann, ist ihre Erwartung immer auch mit der Vorstellung von Nicht-Erfüllung oder – positiver – dem Eintritt von etwas anderem verbunden, dessen Wahrwerden die Verwirklichung des ursprünglich Erwarteten verhindern würde. Im Zustand von Suspense oder Spannung springt nun die Phantasie des Zuschauers zwischen solch entgegengesetzten Zukunftsvorstellungen, einer befürchteten und einer erhofften („Er schafft’s!“ – „Er schafft’s nicht!“ – „Er schafft’s doch!“ usw.), hin und her. Beim Suspense gibt es also immer genau zwei Möglichkeiten. Der negative Ausgang tritt ein oder er tritt nicht ein.

Je nach Erwartungs-Inhalt handelt es sich um eine "Entscheidungs-" oder "Erklärungsspannung". Im ersten Fall ist man gespannt auf den Ausgang des Außen- oder Innenkampfes zwischen Held und Widerspiel, im zweiten auf die Erklärung eines rätselhaften Umstands (in der Regel eines Mords im Kriminalroman). Entscheidungs- beziehungsweise Erklärungsspannung bedingen unterschiedliche Formen der Überraschung.

Zum Ziel der Erwartung können entweder "berechnende" oder "beschwörende" Handlungen führen. Die Berechnung steht etwa bei einem ungestört verlaufenden Diebstahl im Vordergrund, die Beschwörung bei einer Liebeswerbung. Beim (unmanipulierten) Glücksspiel helfen weder die Berechnung noch die Beschwörung, daher hat es eine besondere dramaturgische Bedeutung.

Die Stärke des Spannungsgefühls hängt von der Wichtigkeit der vorgestellten künftigen Ereignisse für den Protagonisten, mehr noch aber für den Zuschauer (wie brennend seine persönlichen Interessen davon berührt sind) ab sowie von der Erheblichkeit des Unterschiedes zwischen Erhofftem und Befürchtetem.


Suspense als öffentlich geduldetes und gefördertes Medienphänomen gibt es erst seit dem Sport oder dem Bühnenmelodram seit dem späteren 18. Jahrhundert. Das öffentliche Entfachen starker Emotionen setzt ein recht hohes Zivilisationsniveau voraus, um nicht aus dem Ruder zu laufen. Zudem stand die christlich-mittelalterliche Ethik, die sich in Opposition zu den römischen Wagenrennen und Gladiatorenkämpfen entwickelt hatte (Tertullian), jeder Art von Suspense entgegen.

Der Soziologe Norbert Elias hat das Aufkommen einer gesellschaftlich positiv bewerteten Spannung seit dem Spätmittelalter untersucht und bringt mit ihm das Entstehen des Sports in Zusammenhang. Er schlägt als Voraussetzung dafür den Begriff Mimesis vor: Ein sportlicher Kampf sei kein ernster, sondern ein spielerischer, gleichsam nachgeahmter Kampf und die damit verbundene Spannung sei daher etwas Angenehmes.





</doc>
<doc id="4501" url="https://de.wikipedia.org/wiki?curid=4501" title="Split Screen">
Split Screen

Split Screen oder Bildschirmaufteilung (wörtlich „geteilter Bildschirm“) ist eine in visuellen Medien verwendete Technik, die das Bild in zwei (oder mehr) Bereiche aufteilt, um zwei (oder mehr) Handlungen oder Bilder gleichzeitig zu zeigen.

Im Film war der "Split Screen" vor allem in den 1960er und 1970er Jahren eine sehr beliebte Technik, wobei das Verfahren selbst bereits in den 1920er Jahren von Abel Gance in seinem monumentalen Spielfilm Napoleon (1927) angewandt wurde. Vorreiter in den 60er Jahren war der US-amerikanische Künstler Andy Warhol in seinem Spielfilm The Chelsea Girls (1966), ein weiteres berühmtes Beispiel ist der Woodstock-Film von Michael Wadleigh (1970). Der bekannteste Mainstream-Film dieser Epoche ist Thomas Crown ist nicht zu fassen (1968).

Zumeist wird die Darstellung vertikal geteilt, um zum Beispiel zwei Telefonierende gleichzeitig zu zeigen. Der Effekt ist ähnlich dem der Parallelmontage, wirkt aber um einiges künstlicher. In Dr. Jekyll und Mr. Hyde (1931) wird das Bild hingegen diagonal geteilt und steht sinnbildlich für Jekylls Persönlichkeitsspaltung.

"Split Screens", die aus mehreren, verschieden großen Elementen bestehen, sind u. a. zu sehen in:


Duovison bezeichnet ein Verfahren das in den 1970er-Jahren in einigen US-amerikanischen Filmen im Rahmen des New Hollywood Anwendung fand, zum Beispiel bei "Wicked, Wicked" von 1973.

Dabei wird nicht nur ein Bild gleichzeitig, sondern zwei Bilder, entweder nebeneinander oder untereinander gezeigt. Damit kann eine Handlung aus zwei Blickwinkeln gezeigt werden, oder zwei parallel ablaufende Handlungen werden gleichzeitig gezeigt.

Einige wenige Filme wurden komplett mit aufgeteiltem Bild in Duovison gedreht. Die meisten Duovison-Filme haben nur einige Szenen in Duovision. Teilweise wurde die Duovisonsszenen bei Neuauflagen auf Video bzw. DVD herausgeschnitten, bzw. nur ein Bild wurde verwendet.

Bei Interviews oder Diskussionen, bei denen sich die Teilnehmer an unterschiedlichen Orten aufhalten, werden sie teilweise in einem Bild zusammengeschnitten.

Eine neuere Anwendung findet der Split Screen bei Live-Sportübertragungen; die hier verwendete so genannte "Split-Screen-Werbung" zeigt zum überwiegenden Teil die Werbefilme, während in einer Ecke weiterhin die Sportsendung gezeigt wird.

Bei Computerspielen wird der Split Screen als eine Lösung eingesetzt, um mehrere Spieler an einem Gerät und einem Bildschirm spielen lassen zu können und doch jedem sein eigenes Spielfeld zur Verfügung zu stellen, in dem er agieren kann und dessen Blickwinkel er unabhängig von anderen Spielern beeinflussen kann.

Dabei wird der Bildschirm je nach Format des Bildschirms getrennt. Bei 5:4- und 4:3-Geräten gibt es die horizontale Teilung, bei 16:10 und 16:9 meist eine vertikale. Jede Bildschirmhälfte wird einem Spieler zugeteilt, dabei spielen aber beide Spieler dasselbe Spiel.

Diese Technik ist im Konsolenbereich, besonders bei Ego-Shootern und Rennspielen, sehr weit verbreitet.

Eine andere Variante wird dazu eingesetzt, den Bildschirm für einen einzelnen Spieler in zwei grundverschiedene Bereiche zu teilen, beispielsweise einen farbigen Bereich in Einzelpunktgrafik mit der eigentlichen Spielwelt und einen im Textmodus, der nur der Anzeige von Spielständen und anderen Statusinformationen dient. Bei geeigneter Implementierung (beispielsweise über einen Rasterzeileninterrupt oder den Copper des Amiga) kann der zweite Bereich einen ganz anderen, einfacheren Grafikmodus aufweisen, so dass er weniger Ressourcen an Speicherplatz und Zeit verbraucht, beim aktualisierenden Beschreiben weniger Zeit erfordert und dadurch einfach schneller arbeitet.

Das Paradebeispiel einer narrativen Nutzung des Split-Screen-Verfahrens in PC- und Videospielen ist das von Kritikern hoch gelobte Spiel "Fahrenheit". Der Spieler steuert seine Figur in einem der Fenster, während er zeitgleich die Aktionen anderer Figuren beobachtet. Das Verfahren wird, wie in der TV-Serie "24", hauptsächlich zur Erzeugung von Spannung eingesetzt. Zum Beispiel muss der Spieler aus einem Gebäudekomplex fliehen und sieht dabei gleichzeitig, wie ein Polizeibeamter sich der Wohnung des Protagonisten nähert.

Einige Monitore, zum Beispiel Fernsehgeräte, aber insbesondere Überwachungsmonitore, bieten die Möglichkeit, gleichzeitig verschiedene, ständig aktualisierte Quellen oder sequentiell die Kanäle eines Empfängers anzuzeigen. Hier erfolgt die Aufteilung meist quadratisch mit gleichem Seitenverhältnis, also zum Beispiel 2×2 4:3-Bilder auf einer 4:3-Anzeige oder 3×3 16:9-Bilder auf einem 16:9-Gerät. Mehr als 25 (5×5) oder maximal 36 (6×6) Bilder gleichzeitig sind dabei nicht sinnvoll. Unterscheiden sich Seitenverhältnis der Signale und des Anzeigegerätes, kommen auch nicht quadratische Aufteilungen in Betracht, zum Beispiel 4×3 4:3-Bilder auf einem 16:9-Gerät oder 3×4 16:9-Bilder auf einem 4:3-Gerät. Auch asymmetrische Aufteilung ist möglich, zum Beispiel ein großes 4:3-Bild (2/3-Breite) neben drei kleinen übereinander (1/3-Breite) in einem 16:9-Rahmen.




</doc>
<doc id="4502" url="https://de.wikipedia.org/wiki?curid=4502" title="Sydney Pollack">
Sydney Pollack

Sydney Irwin Pollack (* 1. Juli 1934 in Lafayette, Indiana; † 26. Mai 2008 in Los Angeles) war ein US-amerikanischer Filmregisseur, -produzent und Schauspieler sowie mehrfacher Oscar- und Golden-Globe-Preisträger.

Pollacks Eltern, der Apotheker David Pollack und die Pianistin und Sängerin Rebecca Pollack, geb. Miller, waren russisch-jüdische Einwanderer, die sich an der Purdue University kennengelernt hatten. Sydney Pollacks Eltern ließen sich scheiden, als er noch klein war; Rebecca Pollack hatte psychische Probleme und trank. Sie starb, als Pollack 16 Jahre alt war. David Pollack hoffte, dass Sydney Pollack Zahnarzt werden würde, doch er interessierte sich für die Filmbranche. Er wuchs in Brooklyn auf und ging zwei Jahre lang zur US-Army; später nahm er Schauspielunterricht am angesehenen New Yorker "Neighborhood Playhouse School of the Theatre" bei Sanford Meisner, zunächst zwei Jahre lang als Schauspielschüler. Danach war er fünf Jahre lang Meisners Assistent. Anschließend arbeitete er Anfang der 1960er Jahre als Bühnen- und Fernsehdarsteller. Später wurde er Professor an der New Yorker Universität und Fernsehregisseur. Insgesamt hat er 40 Filme produziert.

Sein Leinwanddebüt als Filmschauspieler gab er 1962 mit dem Kriegsfilm "Hinter feindlichen Linien", bei dem auch Robert Redford debütierte. Seitdem waren beide befreundet und Redford war in zahlreichen Filmen Pollacks Hauptdarsteller, nachdem Pollack hinter die Kamera gewechselt hatte. Pollack gehört neben John Frankenheimer, der ihm den Wechsel ins Regiefach nahelegte, Franklin J. Schaffner, George Roy Hill und Martin Ritt, zu den Filmemachern, die Anfang der 1960er Jahre vom Fernsehen ins Kino drängten und dort für frischen Wind sorgten. 1965 debütierte er mit dem Psychodrama "Stimme am Telefon" als Kinoregisseur, weitere 19 Spielfilmproduktionen folgten. 1985 erreichte er mit dem mit insgesamt sieben Oscars ausgezeichneten Liebesdrama "Jenseits von Afrika" den Höhepunkt seines Schaffens. 1973 war Sydney Pollack Mitglied der Jury beim Filmfestival in Cannes und 1986 Präsident der Jury.

Pollack galt als einer der intelligentesten Regisseure und war vor allem bei Schauspielern sehr beliebt. Dabei widmete er sich verschiedenen Genres; so drehte er Western "(Jeremiah Johnson)" ebenso wie Literaturverfilmungen "(Jenseits von Afrika)", Politthriller "(Die drei Tage des Condor)", Melodramen "(Begegnung des Schicksals)" und Komödien "(Tootsie)". Pollack war einer der erfolgreichsten Vertreter der konservativen Hollywood-Ästhetik, der trotz der konventionellen Bildersprache jeden Film mit seinem eigenen Stil prägte und darüber hinaus moralisches Engagement zeigte. Er selbst äußerte sich dazu lakonisch: „It is not impossible to make mainstream films which are really good.“ Der Dokumentarfilm "Sketches of Frank Gehry" aus dem Jahr 2005, an dem er auch als Kameramann mitwirkte, wurde seine letzte Regiearbeit. Neben Gehrys Bauwerken dokumentiert der Film teilweise auch die 40 Jahre währende Freundschaft mit Frank Gehry. Pollack wurde dreimal für einen Oscar nominiert; 1986 erhielt er für "Jenseits von Afrika" den Oscar als bester Regisseur. Der Film "Jenseits von Afrika" beruht auf der Geschichte eines Buches von Isak Dinesen (Karen Blixen), das mit dem Satz beginnt: “I had a farm in Africa, at the foot of the Ngong Hills”, deutsch „Ich hatte eine Farm in Afrika, am Fuße der Ngong-Berge“.

Seine Filme sind in der Regel tragische Liebesgeschichten. Sie bevorzugen eine dramaturgische Kreisstruktur, in deren Verlauf sich der Held auf dem Weg zur Selbsterkenntnis mit einem grundsätzlich feindlichen Gesellschaftsumfeld auseinanderzusetzen hat. Ein Beispiel für diese Kreisstruktur ist das Frühwerk "This Property is Condemned", in dem der Protagonist nach einer langen Rückblende nicht nur symbolisch am Ende auf die an dem Ort vorbeiführenden Bahnschienen zurückkehrt. In "Jeremiah Johnson" wird der von Redford gespielte Trapper in der zweiten Filmhälfte spiegelbildlich mit den Ereignissen des Beginns konfrontiert. Weitere Beispiele für tragische Liebesgeschichten finden sich in "The Way We Were", in dem die Beziehung zwischen der jüdischen Marxistin und Studentin "Katie Morosky" (Barbra Streisand) und dem gutaussehenden Studenten aus reichem Hause "Hubbell Gardner" (Redford) nicht funktioniert, "Havana", "Out of Africa" oder auch "Three Days of the Condor", in dem die kurzzeitige Begegnung zwischen dem CIA-Mitarbeiter "Joseph „Condor“ Turner" (Redford), der die Fotografin "Kathy Hale" (Faye Dunaway) auf seiner Flucht vor dem Geheimdienst als Geisel genommen hat, eine intensive Momentaufnahme bleibt.

Pollack war seit 1958 mit der Schauspielerin Claire Griswold verheiratet, mit der er drei Kinder hatte. Am 26. Mai 2008 verstarb Sydney Pollack an Magenkrebs, der neun Monate zuvor diagnostiziert worden war.







</doc>
<doc id="4531" url="https://de.wikipedia.org/wiki?curid=4531" title="Sylvester Stallone">
Sylvester Stallone

Sylvester „Sly“ Gardenzio Stallone (* 6. Juli 1946 in New York City, New York) ist ein US-amerikanischer Schauspieler, Filmregisseur, Drehbuchautor, Filmproduzent und Unternehmer.
Er wurde dreimal für den Oscar und ebenso oft für den Golden Globe Award nominiert. Mit Letzterem wurde er 2016 ausgezeichnet. Er gilt als einer der erfolgreichsten und berühmtesten Action-Darsteller der Filmgeschichte.

Sylvester Gardenzio Stallone wurde 1946 in New York City als Sohn einer italoamerikanischen Familie geboren und wuchs in einem Vorort von Philadelphia auf. Sein Bruder Frank Stallone ist ebenfalls Schauspieler, Sänger und Songwriter. Sein Vater Frank Stallone Senior (* 1919 in Gioia del Colle, Bari, Italien; † 11. Juli 2011 in Wellington, Florida, Vereinigte Staaten) anglisierte den ursprünglich italienischen Familiennamen "Staglione", um nicht mit verschiedenen Mitgliedern der New Yorker Unterwelt verwechselt zu werden. Seine Mutter heißt Jacqueline Stallone (* 29. November 1921). Durch eine Zangengeburt hat Stallone seit frühester Kindheit eine Muskellähmung im Gesicht, die ihm besonders während seiner Kindheit zu schaffen machte. Aufgrund dieser Lähmung rieten ihm seine Lehrer anfangs von einer Schauspielkarriere ab.

In der Grundschule machte er erste Schritte als Amateurschauspieler und feierte als Football-Spieler in der Landesliga Erfolge. Zwei Jahre lang wurde Stallone auch am "American College of Switzerland", Leysin, ausgebildet. Hier hatte er seinen ersten Bühnenauftritt in Tod eines Handlungsreisenden in der Rolle des Biff. Zurück in den USA schrieb er sich an der Universität von Miami ein und begann, sich als Autor zu versuchen. Stallone verließ die Universität allerdings vor seinem Abschluss, um eine Karriere als Schauspieler in Angriff zu nehmen. Zunächst wenig erfolgreich, trat er mit 24 Jahren aus Geldnot für 200 US-Dollar als Hauptdarsteller "Stud" ( "Deckhengst") in dem Erotikfilm "The Party at Kitty and Stud’s" auf. Daneben übernahm Stallone aber auch kleine Rollen in Filmen von Woody Allen "(Bananas)" und Dick Richards "(Fahr zur Hölle, Liebling)".

Der Durchbruch für Stallone war das Boxer-Drama um "Rocky Balboa", einem Boxer und Niemand aus Philadelphia. Durch einen Kampf des Boxers Chuck Wepner gegen den damaligen Weltmeister Muhammad Ali inspiriert, schrieb Stallone innerhalb weniger Tage ein Drehbuch und bot es einigen Filmproduzenten mit der Bedingung an, die Hauptrolle zu spielen. Er setzte sich schließlich durch. "Rocky" wurde mit einem Budget von knapp 1,1 Mio. US-Dollar gedreht und im Jahr 1976 zum großen Überraschungserfolg an den Kinokassen. Der Film machte Stallone über Nacht zum Star, wurde 1977 in zehn Kategorien für den Oscar nominiert und gewann den Preis für den besten Film, die beste Regie und den besten Schnitt. Stallone selbst erhielt Nominierungen als bester Hauptdarsteller und für das beste Originaldrehbuch. Gleichzeitig in diesen Kategorien waren zuvor für einen Film nur Charlie Chaplin und Orson Welles nominiert worden.
Die mehrfachen Fortsetzungen von "Rocky", die er mit Ausnahme des fünften Teils selbst als Regisseur inszenierte, waren weniger anspruchsvoll als das Original und setzten mehr auf Action, entsprachen aber dem Zeitgeist der 1980er Jahre. Insgesamt gilt die Reihe als eine der bekanntesten filmischen Rezeptionen des American Dream. Der kommerzielle Erfolg hielt an. Stallone wurde weltweit zu einem der populärsten Schauspieler dieses Jahrzehnts.

Im Jahr 1978 gab Stallone mit dem Film "Vorhof zum Paradies" sein Debüt als Regisseur. Unterdessen versuchte er sich auch an Projekten wie Norman Jewisons Gewerkschaftsfilm "F.I.S.T. – Ein Mann geht seinen Weg" – einem typischen Film des New Hollywood. Hierbei spielte Stallone die Hauptrolle und arbeitete am Drehbuch mit.

Einen weiteren kommerziellen Erfolg landete Stallone mit "Rambo", basierend auf dem Bestseller-Roman "First Blood" von David Morrell (erschienen 1972). Hier setzte sich Stallone kritisch mit dem Vietnamkrieg und der damaligen Stimmung der amerikanischen Bevölkerung gegenüber dem US-Militär auseinander. Der Film wurde von den Kritikern kontrovers diskutiert. Stallone drehte auch hier Fortsetzungen. Diese setzten wiederum mehr auf Action, noch mehr Patriotismus sowie den damit verbundenen Zeitgeist der Reagan-Ära und des Kalten Krieges.
1983 arbeitete Sylvester Stallone als Regisseur mit John Travolta an der Fortsetzung von "Saturday Night Fever". Der Film "Staying Alive" erhielt zwar sehr negative Kritiken, wurde jedoch ein beachtlicher kommerzieller Erfolg. Den Höhepunkt seiner Popularität erreichte Stallone im Jahr 1985: Mit "Rambo II" und "Rocky IV" zeichnete er für gleich zwei der drei kommerziell erfolgreichsten Filme des Jahres verantwortlich.

Im Jahr 1986 erschien der Film "Die City-Cobra". Der Titel landete in den US-Jahrescharts von 1986 auf Rang 15. Die nachfolgenden Filme "Over The Top" und "Lock Up" floppten an den nordamerikanischen Kinokassen, obgleich sie in Deutschland jeweils über eine Million Zuschauer in die Kinos lockten. Als auch die Fortsetzungen zu seinen Paraderollen Rocky und Rambo enttäuschten – das Einspielergebnis von "Rambo III" in den Vereinigten Staaten entsprach nur einem Drittel des erfolgreichen Vorgängers, und "Rocky V" geriet zu einem seiner größten Flops–  geriet Stallones Karriere ins Stocken.

Versuche, sein martialisches Image in den 1990er Jahren durch humorvolle Einlagen in Filmen wie "Oscar – Vom Regen in die Traufe" und "Stop! Oder meine Mami schießt!" aufzulockern, scheiterten. Stallone sah ein, dass ihn die breite Masse nur als Actiondarsteller akzeptierte. Mit Filmen wie "Cliffhanger – Nur die Starken überleben", "Demolition Man" und "The Specialist" knüpfte er an seine Erfolge aus den 80er Jahren an. Später aber floppten auch typische Action-Reißer wie "Judge Dredd", "Assassins – Die Killer" und "Daylight" an den US-Kinokassen.

Im Jahr 1997 überzeugte Stallone das Publikum und die Kritiker mit seiner darstellerischen Leistung in "Cop Land". Für seine Rolle als übergewichtiger Sheriff einer überwiegend von Polizisten bewohnten Kleinstadt hatte er extra 15 kg zugenommen und konnte neben Kollegen wie Robert De Niro, Harvey Keitel und Ray Liotta bestehen.

Die nun folgenden Filme "Get Carter – Die Wahrheit tut weh" und "Driven" erwiesen sich erneut als große Flops. Daraufhin entstanden eine Reihe von Filmen mit Geld aus deutschen Filmfonds, die nur kurz in den Kinos waren oder wie "Avenging Angelo" oder "Shade" gar nicht in den deutschen Kinos starteten.

Für sein Comeback begann Stallone mit der Arbeit an Fortsetzungen zu seinen erfolgreichsten Rollen "Rocky" und "Rambo", die zu drehen er sich lange geweigert hatte. Im Dezember 2005 wurde mit den Dreharbeiten zu "Rocky Balboa" begonnen, welcher im Februar 2007 in den deutschen Kinos anlief und den ersehnten Erfolg an den Kinokassen brachte. Mit dem im Folgejahr veröffentlichten, ebenfalls erfolgreichen vierten Rambo-Film gelang es Stallone endgültig, wieder Fuß in Hollywood zu fassen.

Im August 2010 erschien der Actionfilm "The Expendables". Für diesen übernahm Stallone neben der Hauptrolle abermals Drehbuch und Regie. Damit stand er 27 Jahre nach "Staying Alive" erstmals wieder für einen Film hinter der Kamera, der nicht Teil der Rocky- bzw. Rambo-Franchise war. Bereits am Startwochenende spielte der Film knapp 35 Millionen US-Dollar ein – ein Rekord in Stallones Karriere. Mitte September übersprang er in den Vereinigten Staaten die 100-Millionen-Dollar-Hürde. Dies war Stallone zuletzt 25 Jahre zuvor mit "Rocky IV" gelungen. Weltweit spielte der Film knapp 275 Millionen US-Dollar ein. Der Erfolg des Films führte zu zwei Fortsetzungen, die weltweit weitere 500 Millionen US-Dollar einspielten.

Im Jahr 2013 war Stallone zum ersten Mal in seiner Karriere in drei Kinofilmen zu sehen. Sowohl die beiden Actionfilme "Shootout – Keine Gnade" und "Escape Plan" als auch die Sportkomödie "Zwei vom alten Schlag" floppten jedoch in den Vereinigten Staaten mit einem Einspielergebnis von jeweils weniger als 30 Millionen US-Dollar. "Escape Plan" war allerdings ein internationaler Erfolg und spielte allein im Ausland über 100 Millionen US-Dollar ein.

Der Boxerfilm "Creed – Rocky’s Legacy" aus dem Jahr 2015, in dem Stallone zum siebten Mal in die Rolle des "Rocky Balboa" schlüpfte, erwies sich als großer Erfolg bei Publikum und Kritikern. Der Film spielte allein in den Vereinigten Staaten über 100 Millionen US-Dollar ein und bescherte Stallone nach fast 40 Jahren erneut eine Oscar-Nominierung sowie den ersten Golden Globe Award.

Am 21. Mai 2007 wurde Stallone in Australien wegen illegaler Einfuhr von Wachstumshormonen zu einer Geldstrafe in Höhe von 12.000 AU$ (ca. 7.300 Euro) verurteilt. Stallone hatte am 16. Februar 2007 bei seiner Einreise 48 in seinem Gepäck befindliche Ampullen mit den Muskelaufbaupräparaten Jintropin sowie Testosteron verschwiegen. Als Beamte drei Tage später sein Hotelzimmer durchsuchen wollten, warf er vier Ampullen Testosteron aus dem Fenster.

Im Zuge der US-Wahlen 2008 gehörte Stallone, neben anderen namhaften Darstellern wie „Terminator“ Arnold Schwarzenegger und „Superman“ Dean Cain zu den Befürwortern des Präsidentschaftskandidaten John McCain.

Stallone ist zusammen mit Bruce Willis, Demi Moore, Jackie Chan und Arnold Schwarzenegger Mitbegründer der Restaurantkette Planet Hollywood.

Im Jahr 2009 verletzte sich Stallone während der Dreharbeiten zum Film "The Expendables" bei einer Kampfszene mit Steve Austin und zog sich einen Haarriss im Halswirbel zu, dem vier Operationen folgten, in deren Verlauf ihm ein Metallplättchen in den Nacken eingesetzt wurde. Als Resultat dieses Genickbruches darf Stallone künftig keine Stunts mehr ausführen, da die nächste Verletzung an seiner Wirbelsäule eine Querschnittlähmung oder sogar seinen Tod zur Folge haben könnte.

Im Jahr 2011 wurde Stallone in die International Boxing Hall of Fame aufgenommen.

In den deutschsprachigen Fassungen seiner Filme wird Stallone von Thomas Danneberg synchronisiert, der auch Arnold Schwarzeneggers deutsche „Stammstimme“ ist. In den „Expendables“-Filmen spricht Danneberg tatsächlich beide Rollen. In Stallones frühen Filmen, so z. B. in "Rocky", lieh ihm mehrfach Jürgen Prochnow seine Stimme.

Stallone erlitt bei seiner Geburt eine Verletzung des VII. Hirnnerven (Nervus facialis). Der linke untere Abschnitt seines Gesichts ist deswegen gelähmt, nebst Teilen seiner Lippen und seines Kinns, was seinen typischen Gesichtsausdruck erzeugt. Als Kind wurde er dafür gehänselt, inzwischen sind seine eingeschränkte Mimik und die leicht verwaschene Aussprache jedoch zum Markenzeichen geworden.

Stallone heiratete dreimal. Aus seiner ersten Ehe mit Sasha Czack (1974–1985) stammen seine beiden Söhne Sage (* 5. Mai 1976; † Juli 2012), der in "Rocky V" als Rockys Sohn sowie in "Daylight" mitspielte, und Seargeoh (* 1979), als Rockys Baby in "Rocky II" zu sehen. Seine zweite Ehe mit Brigitte Nielsen (1985–1987) blieb kinderlos. Aus der dritten Ehe mit Jennifer Flavin, welche im Mai 1997 geschlossen wurde, gingen drei Töchter hervor: Sophia Rose (* 1996), Sistine Rose (* 1998) und Scarlet Rose (* 2002).


Im Laufe seiner Karriere wurde Sylvester Stallone für diverse renommierte Filmpreise nominiert. Die meisten Nominierungen sind auf das Boxdrama Rocky zurückzuführen, für das er sowohl als Darsteller wie auch als Drehbuchautor Aufmerksamkeit erlangen konnte.
Die Folgejahre seiner Karriere wurden überwiegend von Negativpreisen dominiert, so erhielt er zehn Mal die Goldene Himbeere. Durch das erneute Boxdrama "Creed – Rocky’s Legacy" gehörte Stallone nach fast 40 Jahren erneut zum Nominiertenkreis bei den Oscars sowie Golden Globes und konnte letzteren gewinnen. Für diesen Schritt erhielt er auch den Himbeeren-Erlöser-Preis.

Insgesamt werden Stallone 34 Preise sowie 34 Nominierungen zugesprochen, die folgende Auswahl listet die bekanntesten auf.

Positive Auszeichnungen


Negative Auszeichnungen





</doc>
<doc id="4534" url="https://de.wikipedia.org/wiki?curid=4534" title="Stasi-Unterlagen">
Stasi-Unterlagen

Die Unterlagen des Ministeriums für Staatssicherheit der DDR, kurz Stasi-Unterlagen, lassen sich in Karteien, Akten, audio-visuelle Medien und maschinenlesbare Daten (Disketten, Magnetbänder, Magnetplatten, Datenbanken) aufteilen. Es sind bisher 39 Millionen Karteikarten und 111 Kilometer Akten aufgefunden worden. In der Stasi-Unterlagen-Behörde werden außerdem 1,75 Mio Fotografien, 2.800 Filme und Videos sowie 28.400 Tonbänder verwahrt. Darüber hinaus existieren noch rund 15.500 Behältnisse mit bisher ungesichtetem, zerrissenem Schriftgut. Das so genannte Stasi-Unterlagen-Gesetz regelt die Verwendung der Unterlagen, die vom Bundesbeauftragten für die Unterlagen des Staatssicherheitsdienstes der ehemaligen Deutschen Demokratischen Republik (BStU) verwaltet werden. Es legt unter anderem auch fest, dass die Unterlagen nach archivfachlichen Grundsätzen bewertet, geordnet, erschlossen und verwahrt werden.

Die Überlieferung des Ministeriums für Staatssicherheit sowie die Unterlagen der Bezirksverwaltungen Potsdam und Berlin lagern im Archiv der Zentralstelle in Berlin-Lichtenberg.
In zwölf der ehemals 15 Bezirksstädte der Deutschen Demokratischen Republik gibt es heute Außenstellen der BStU. In ihnen werden die Unterlagen der jeweiligen Bezirksverwaltungen des Staatssicherheitsdienstes archivisch bearbeitet und der Öffentlichkeit zugänglich gemacht.

Einige der Unterlagen wie die sogenannten Rosenholz-Akten oder die über den Spion James W. Hall erlangten Dokumente gerieten nach der Wiedervereinigung in die USA und stehen in Deutschland nur noch teilweise zur Verfügung. Die Zugänglichkeit der Akten für Dritte ist auch ein Streitthema, wie die Verfahren von Helmut Kohl zeigen.

Ab Mitte November 1989 begannen Mitarbeiter der Staatssicherheit Teile ihrer Unterlagen auf Anweisung von Erich Mielke abzutransportieren und zu zerstören. Nachdem das Ministerium für Staatssicherheit in das "Amt für Nationale Sicherheit" umgewandelt wurde und die Volkskammer als neuen Leiter Wolfgang Schwanitz bestimmt hatte, erneuerte dieser am 22. November 1989 unter „strengster Geheimhaltung“ die Anweisung seines Vorgängers Mielke. Bald fiel Bürgerrechtlern auf, dass in Gebäuden der Staatssicherheit Dinge verbrannt wurden und Gegenstände per Laster fortgeschafft wurden. Es wurden deshalb vor mehreren Gebäuden Mahnwachen aufgestellt und Einlass erzwungen. So wurde am Morgen des 4. Dezember 1989 die Bezirksstelle des MfS in Erfurt besetzt und am Abend desselben Tages folgten weitere Besetzungen, beispielsweise in Greifswald, Rostock, Bad Doberan, Stralsund und Wismar. Als Folge davon gab Schwanitz die Anweisung die Vernichtung der Akten zu beenden. Im Februar 1990 gab es mit Zustimmung des Runden Tisches eine Anweisung des Ministerrates, die elektronischen Datenträger zu vernichten. Mit der Selbstauflösung der Hauptverwaltung Aufklärung wurden auch deren Akten weitgehend vernichtet (siehe auch: Rosenholz-Akten). Als Zusatzklausel im Einigungsvertrag wurde vereinbart, unter anderem unter dem Druck eines Hungerstreiks von Bürgerrechtlern im September 1990 in der Zentrale der Staatssicherheit in Berlin, mehreren Mahnwachen und gegen die ursprüngliche Absicht von Vertretern der Bundesregierung und des Ministers des Inneren Peter-Michael Diestel, dass die sonst in Westdeutschland übliche Sperrfrist für Archivgut (Bundesarchivgesetz) nicht angewendet wird und dass Stasi-Opfer ihre Akten einsehen können (Stasi-Unterlagen-Gesetz).

Nach der Wende gab es wiederholt Streit, da die Akten nicht nur für die private Akteneinsicht, Behörden und Forscher, sondern auch für Medienvertreter und Parlamente genutzt werden.

Sehr prominent war beispielsweise der Gerichtsstreit von Helmut Kohl, der sogenannte Fall Kohl. Weitere prominente Fälle betrafen Gregor Gysi und Manfred Stolpe.

13.088 Seiten Dokumente, die der Spion James W. Hall über die Tätigkeit der National Security Agency gegen die Bundesrepublik dem MfS zukommen ließ, gingen in den Besitz der Gauck-Behörde über und wurden 1992 unter Bruch des Stasi-Unterlagen-Gesetzes mit Genehmigung des Bundesinnenministeriums zurück in die USA gebracht.

Die Rosenholz-Dateien, die 1990 in die USA gelangten, wurden hingegen 2003 an Deutschland zurückgegeben und sind einsehbar.

Von den in den letzten Monaten der DDR zerstörten Teilen der Unterlagen fanden sich viele tausend Säcke mit unterschiedlich stark zerschnitzelten Materialien, die wieder rekonstruiert werden sollten. Bis zum Februar 2012 konnte der Inhalt von etwa 440 der insgesamt etwa 16.000 Säcke manuell bearbeitet und rund 1.000.000 Blatt an Schriftgut rekonstruiert werden. Im Jahr 2007 begann zusätzlich ein Projekt zur maschinellen Rekonstruktion. Das Fraunhofer-Institut für Produktionsanlagen und Konstruktionstechnik in Berlin entwickelte die Stasi-Schnipselmaschine, Behördenbezeichnung „Virtuelle Rekonstruktion vorvernichteter Stasi-Akten“. Dabei werden die zum Teil geschredderten Papierschnipsel in Folie eingeschweißt, gescannt, nach mehreren Merkmalen unterschieden und dann virtuell zusammengesetzt.

Die Schriftgutbestände gliedern sich in archivierte Ablagen, das heißt Unterlagen, die vom Staatssicherheitsdienst selbst archiviert wurden, und in Unterlagen der Diensteinheiten. Letzteres sind Akten, die sich 1989/90 noch in Bearbeitung befanden. Es handelt sich um so genannte „aktive“ Vorgänge (operative Vorgänge, also Beobachtung von und Maßnahmen gegen bestimmte Personen) und Verwaltungsschriftgut. Die archivierten Ablagen sind komplett über personenbezogene Karteien zugänglich, jedoch nur in seltenen Fällen themenbezogen recherchierbar. Die Unterlagen der Diensteinheiten werden bei der BStU archivisch erschlossen, so dass sie sachthematisch und personenbezogen zugänglich sind. Bisher wurden 81 Prozent der Unterlagen der Diensteinheiten archivfachlich bearbeitet.

IM-Akte: Die Akte zu einem inoffiziellen Mitarbeiter (IM) besteht gemäß den Aktenführungsprinzipien des MfS in der Regel aus drei Teilen. Teil I, die so genannte Personalakte, enthält Dokumente zur Person des IM. Dabei handelt es sich um Unterlagen, die bei der Überprüfung des IM-Kandidaten angefallen sind, den Werbungsbeschluss, die Verpflichtung (soweit schriftlich erfolgt), regelmäßige Einschätzungen zur Grundlage der Zusammenarbeit, zur Gesinnung, sowie zu Fähigkeiten und Möglichkeiten des IM, außerdem Dokumente zu etwaigen Überprüfungsmaßnahmen nach der Werbung. Teil II, die so genannte Arbeits-/Berichtsakte, besteht aus den Berichten des IM und den Treffberichten des Führungsoffiziers. Teil III, die so genannte Beiakte zur Personalakte, enthält Quittungsbelege über Gehaltszahlungen, Prämien, Urlaubsgeld und andere gezahlte Geldbeträge oder übergebene Sachwerte an den IM.

Operative Personenkontrolle: Bei der Operativen Personenkontrolle (OPK) handelt es sich um einen konspirativen Vorgang zur Aufklärung und Überwachung von Personen. Er wurde meist angelegt bei Verdacht auf politisch nicht konformes Verhalten oder zur Überprüfung von Funktionären. Eine OPK erfolgte auch als Vorlauf für eine inoffizielle Tätigkeit in der Auslandsspionage.

Operativer Vorgang: Ein Operativer Vorgang (OV) ist ein konspiratives Ermittlungsverfahren gegen Unbekannt oder gegen Personen, die nach der DDR-Gesetzgebung eine Straftat begangen hatten oder dies beabsichtigten. Anlass war oft schon nichtkonformes politisches Verhalten. Jeder OV hatte einen Decknamen.

Bei den Karteien handelt es sich einerseits um Informationsspeicher, andererseits um Findmittel zur Aktenrecherche. Die personenbezogenen Karteien waren – und sind auch heute noch – erforderlich, um die vom Staatssicherheitsdienst selbst archivierten Akten heraussuchen zu können.

Die Kartei F 16 ist die zentrale Klarnamenkartei. Sie ist phonetisch geordnet und enthält den vollständigen Namen, die Adresse sowie weitere personenbezogene Angaben der erfassten Person. Der Grund der Erfassung wird jedoch nicht angegeben.

Das definiert erst die Kartei F 22 (Vorgangskartei). Durch diese Kartei wird deutlich, ob es sich beispielsweise um einen Vorgang zu einem inoffiziellen Mitarbeiter, einen Operativvorgang (z.B. die Beobachtung eines Bürgerrechtlers) oder eine weitere Vorgangsart handelt. In der F 22 wird jedoch nicht der Klarname genannt, sondern der Deckname. Der Zusammenhang zwischen den Karteien kann nur über die einmalig vergebene Registriernummer hergestellt werden.

Die F 77- Kartei enthält die Decknamen und ist ebenfalls phonetisch geordnet. Das MfS legte sie zu Zwecken der statistischen Auswertung an.

Die Kerblochkartei (KK) notierte Beruf, Parteizugehörigkeit, Hobbys, Neigungen, Gewohnheiten und Interessen.

Unter audio-visuellen Medien werden Fotografien, Videos, Filme und Tonträger verstanden. Es gibt etwa 1,4 Mio Fotodokumente (Fotopositive und -negative, Dias, Mikrofilme), 31.300 Tondokumente und 2.734 Filme und Videos mit Aufzeichnungen. Bei den maschinenlesbaren Daten handelt es sich um Disketten, Magnetbänder und Magnetplatten des Ministeriums für Staatssicherheit und der Bezirksverwaltungen des MfS. Es sind etwa 7.832 Datenträger vorhanden. Zu den maschinenlesbaren Daten zählen auch die Datenbanken des Staatssicherheitsdienstes.

Um Spekulationen entgegenzutreten, veröffentlichte Peer Steinbrück, Kanzlerkandidat der SPD bei der Bundestagswahl 2013, seine Stasi-Akte. Sie enthält unter anderem Notizen über seine angebliche politische Einstellung; von Seiten der Presse wurde diese Einschätzung Steinbrücks durch die Stasi teils als „amüsant“ bezeichnet.




</doc>
<doc id="4535" url="https://de.wikipedia.org/wiki?curid=4535" title="Stasi-Unterlagen-Gesetz">
Stasi-Unterlagen-Gesetz

Das Gesetz über die Unterlagen des Staatssicherheitsdienstes der ehemaligen Deutschen Demokratischen Republik (Stasi-Unterlagen-Gesetz) wurde am 14. November 1991 vom Deutschen Bundestag verabschiedet. Es regelt die Verwendung 
der Akten des Ministeriums für Staatssicherheit (kurz: "Stasi") und seiner Vorläufer- und Nachfolgeorganisationen (vor 1950: unter anderem die Hauptverwaltung zum Schutze der Volkswirtschaft; ab 17. November 1989 Amt für Nationale Sicherheit).

Das Stasi-Unterlagen-Gesetz ist die gesetzliche Grundlage für den Zugang zu den Unterlagen und definiert die unterschiedlichen Bedingungen für ihre Verwendung. Dieses Gesetz ist die Basis für jegliche Tätigkeit der Behörde der Bundesbeauftragten für die Stasi-Unterlagen. So legt es beispielsweise auch fest, dass die Unterlagen nach archivischen Grundsätzen verwaltet werden sollen.

Bei dem Stasi-Unterlagen-Gesetz handelt es sich um ein Spezialgesetz. Es wurde notwendig, weil das Bundesarchivgesetz aufgrund der dreißigjährigen Sperrfrist und der zahlreichen personenbezogenen Daten die sofortige Nutzung der Stasi-Unterlagen nicht erlaubt hätte. Deswegen muss das Stasi-Unterlagen-Gesetz das Persönlichkeitsrecht und den Datenschutz angemessen berücksichtigen und gegen das Interesse an der Aufarbeitung abwägen. Dies geschieht zum Beispiel dadurch, dass bei Akteneinsichten bestimmte personenbezogene Daten anonymisiert werden. Beispielsweise sieht bei der Einsicht in die eigene Akte die betreffende Person nur die Informationen zu sich selbst, aber keine persönlichen oder intimen Informationen über ihre Eltern oder Freunde, die in der Akte ebenfalls erwähnt sein können.

Es wird ferner auf dieses Gesetz verwiesen, um den Personenkreis festzulegen, dessen Beschäftigung im öffentlichen Dienst untragbar erscheint und welcher grundsätzlich nicht in das Beamtenverhältnis berufen werden darf.

Die Unterlagen wurden auf Initiative der Bürgerbewegung im Zuge der friedlichen Revolution von 1989 sichergestellt (teils in geschreddertem oder ungeordnetem Zustand) und dann vom "Beauftragten der Bundesregierung für die Unterlagen des Staatssicherheitsdienstes der ehemaligen DDR" verwaltet und verarbeitet.

Die Volkskammer bildete 1990 einen "Sonderausschuss zur Kontrolle der Auflösung des Ministeriums für Staatssicherheit (MfS)/Amt für Nationale Sicherheit (AfNS)" und wählte Joachim Gauck zu seinem Leiter. Gauck wurde zu einem der Initiatoren des "Stasiunterlagengesetzes der Volkskammer". 
Am 2. Oktober 1990, dem letzten Tag des Bestehens der DDR, wurde der Abgeordnete der Listenverbindung Bündnis 90 Joachim Gauck von der Volkskammer zum "Sonderbeauftragten für die personenbezogenen Unterlagen des ehemaligen Staatssicherheitsdienstes der DDR" gewählt und am Tag darauf von Bundespräsident Richard von Weizsäcker und Bundeskanzler Helmut Kohl als "Sonderbeauftragter der Bundesregierung für die personenbezogenen Unterlagen des ehemaligen Staatssicherheitsdienstes" in dieser Funktion bestätigt. 

Am 29. Dezember 1991 trat das Stasi-Unterlagen-Gesetz in Kraft. Vier Tage später, am 2. Januar 1992, begann die Akteneinsicht durch Bürger, Wissenschaftler und Medien.

Infolge des Stasi-Unterlagen-Gesetzes änderte sich die Bezeichnung des Amtes. Gauck war fortan "Bundesbeauftragter für die Unterlagen des Staatssicherheitsdienstes der ehemaligen Deutschen Demokratischen Republik". Die Behörde wird (aufgrund ihres sperrigen offiziellen Titels) umgangssprachlich oft als „Gauck-Behörde“ bezeichnet (→ BStU).

Gaucks erste Amtszeit dauerte bis 1995; er wurde für weitere fünf Jahre im Amt bestätigt. Da dieses Amt per Gesetz nur zwei Amtszeiten lang vom gleichen Inhaber bekleidet werden darf, konnte Gauck 2000 nicht wiedergewählt werden.

Im September 2000 wurde Marianne Birthler als seine Nachfolgerin in diesem Amt ernannt. Im März 2011 übernahm der Journalist Roland Jahn das Amt des Bundesbeauftragten, der sich dafür einsetzte, dass Ende 2011 mit einer Gesetzesänderung ein Beschäftigungsverbot für ehemalige Stasi-Mitarbeiter in der Stasi-Unterlagen-Behörde eingeführt wurde und bisher Beschäftigte in andere Bundesbehörden versetzt werden sollen.




</doc>
<doc id="4538" url="https://de.wikipedia.org/wiki?curid=4538" title="Sekunde (Begriffsklärung)">
Sekunde (Begriffsklärung)

Sekunde (verkürzt von ‚zum zweiten Mal verminderter Teil‘, daher das Sekundenzeichen »″«) steht für:


Siehe auch:


</doc>
<doc id="4539" url="https://de.wikipedia.org/wiki?curid=4539" title="Silber">
Silber

Silber ist ein chemisches Element mit dem Elementsymbol Ag und der Ordnungszahl 47. Es zählt zu den Übergangsmetallen. Im Periodensystem steht es in der 5. Periode und der 1. Nebengruppe (Gruppe 11) oder Kupfergruppe. Das Elementsymbol Ag leitet sich vom lateinischen Wort "argentum" für „Silber“ ab. Silber gehört zu den Edelmetallen.

Es ist ein weiches, gut verformbares (duktiles) Schwermetall mit der höchsten elektrischen Leitfähigkeit aller Elemente im unmodifizierten Zustand (Kohlenstoff in der Form von Graphen besitzt nochmals eine höhere Leitfähigkeit) und der höchsten thermischen Leitfähigkeit aller Metalle. Lediglich Supraflüssigkeiten und ungestörte kristalline Ausprägungen des Kohlenstoffs (Diamant, Graphen und graphennaher Graphit, Kohlenstoffnanoröhren) und des Bornitrids weisen eine bessere thermische Leitfähigkeit auf.

Das Wort „Silber“ (althochdeutsch "silabar, silbar" und ähnliche Formen) leitet sich aus der gemeingermanischen Wurzel "*silubra-" ab, ebenso wie die Bezeichnungen in anderen germanischen Sprachen (so engl. "silver"). Das Baskische hat das germanische Wort übernommen: "zilar". Verwandte Bezeichnungen gibt es in den baltischen Sprachen (litauisch "sidabras") und den slawischen Sprachen (russisch "серебро", kroatisch "srebro").

Die Philologie des 19. Jahrhunderts brachte eine Vielzahl von Theorien über den Wortursprung hervor. Der 1870 von Victor Hehn hergestellte Zusammenhang mit dem in Homers Ilias beschriebenen sagenhaften Land "Alybē" () muss Spekulation bleiben. Das Wort könnte aus einer orientalischen Sprache stammen, abgeleitet von der semitischen Wurzel ṢRP (vgl. akkadisch "ṣarāpu", „veredeln, legieren“).

In anderen indoeuropäischen Sprachen geht das Wort für Silber auf die indogermanische Wurzel "*arg" zurück, so und lat. "argentum". Argentinien wurde nach dem Silber benannt, das Europäer dort zu finden hofften; es ist das einzige nach einem chemischen Element benannte Land. Häufiger ist die Namensgebung eines Elementes nach einem Land, z. B. Francium, Germanium und Polonium.

Silber wird von Menschen etwa seit dem 5. Jahrtausend v. Chr. verarbeitet. Es wurde zum Beispiel von den Assyrern, den Goten, den Griechen, den Römern, den Ägyptern und den Germanen benutzt. Zeitweise galt es als wertvoller als Gold. Das Silber stammte meistens aus den Minen in Laurion, die etwa 50 Kilometer südlich von Athen lagen. Bei den alten Ägyptern war Silber als Mondmetall bekannt.

Im Mittelalter und der Frühen Neuzeit wurden in Zentraleuropa Silbererzvorkommen im Harz (Goslar), in Waldeck-Frankenberg (Frankenberg, Goddelsheim, Dorfitter, Thalitter), am Donnersberg (Imsbach), im Thüringer Wald (Ohrdruf), in Sachsen (Freiberg und im übrigen Erzgebirge, besonders Jáchymov), im Südschwarzwald (Schauinsland, Belchen, Münstertal, Feldberg), Böhmen (Kutná Hora) und der Slowakei entdeckt. Ergiebige Silbervorkommen sind darüber hinaus aus Kongsberg (Norwegen) bekannt.

Größter Silberproduzent im Mittelalter war Schwaz. Bis zu 80 % des damaligen Silbers kam aus den Stollen der Schwazer Knappen.

Später brachten die Spanier große Mengen von Silber aus Lateinamerika, unter anderem aus der sagenumwobenen Mine von Potosí, nach Europa. Auch Japan war im 16. Jahrhundert Silberexporteur. Durch das gestiegene Angebot sank der Silberwert in der Alten Welt.

Da nach 1870 vorwiegend Gold als Währungsmetall verwendet wurde, verlor das Silber seine wirtschaftliche Bedeutung immer mehr. Das Wertverhältnis sank von 1:14 einige Zeit lang auf 1:100, später stieg es wieder etwas an. Im März 2018 liegt/lag es bei ungefähr 1:81. Das Angebot an Silber ist von der Verbrauchs- und Produktionsentwicklung anderer Metalle abhängig.

Mitte des 19. Jahrhunderts wurde rostfreier Stahl entwickelt, der dann aufgrund seiner Gebrauchsfreundlichkeit und des attraktiven Preises nach dem Ersten Weltkrieg in die Einsatzbereiche des Silbers vordrang, etwa Servierplatten, Bestecke, Leuchter und Küchengerät. Gegenläufig dazu hat sich der Bereich Fotografie und Fotochemie unter Verwendung der Silbersalze während des ganzen 20. Jahrhunderts breit entwickelt, verlor aber seit Ende der 1990er Jahre im Zuge der Umstellung auf die digitale Abbildungstechnik erheblich an Bedeutung.

Als die größte Silberspekulation wird die Spekulationsblase im Silbermarkt Mitte der 1970er Jahre bis zum Jahr 1980 betrachtet, die insbesondere mit den Brüdern Nelson Bunker Hunt und William Herbert Hunt in Verbindung gebracht wird: Silberspekulation der Brüder Hunt.

Silber hat in der Erdkruste einen Anteil von etwa 0,079 ppm. Es ist damit etwa 20 mal häufiger als Gold und rund 700 mal seltener als Kupfer. In der Natur tritt es gediegen auf, das heißt elementar; meist in Form von Körnern, seltener von größeren Nuggets, dünnen Plättchen und Blechen oder als drahtig verästeltes Geflecht (Dendrit) bzw. als dünne Silberdrähte in hydrothermal gebildeten Erzgängen sowie im Bereich der Zementationszone.

Natürliche Vorkommen an gediegen Silber waren bereits vor der Gründung der International Mineralogical Association (IMA) bekannt. Silber ist daher als sogenanntes "grandfathered" Mineral als eigenständige Mineralart anerkannt.

Gemäß der Systematik der Minerale nach Strunz (9. Auflage) wird Silber unter der System-Nr. „1.AA.05“ (Elemente – Metalle und intermetallische Verbindungen – Kupfer-Cupalit-Familie – Kupfergruppe) beziehungsweise in der veralteten 8. Auflage unter "I/A.01" (Kupfer-Reihe) eingeordnet. Die vorwiegend im englischsprachigen Raum verwendete führt das Element-Mineral unter der System-Nr. „01.01.01.02“ (Goldgruppe).

Neben gediegen Silber, von dem bisher (Stand: 2018) über 5500 Fundorte dokumentiert sind, findet man es vor allem in sulfidischen Mineralen. Zu den wichtigsten sulfidischen Silbererzen zählen unter anderem Akanthit ("Silberglanz") AgS mit einem Silbergehalt von etwa 87 % und Stromeyerit ("Kupfersilberglanz") CuAgS mit etwa 53 % Silberanteil. Das Mineral mit dem höchsten Silberanteil von maximal 99 % ist allerdings das selten vorkommende Allargentum. Ebenfalls selten vorkommende Silberminerale sind unter anderem der Chlorargyrit (veraltet "Hornerz" bzw. "Silberhornerz") AgCl und der Miargyrit ("Silberantimonglanz") AgSbS. Insgesamt sind einschließlich gediegen Silber bisher (Stand: 2018) 167 Silberminerale bekannt.

Neben diesen Silbererzen findet man noch sogenannte silberhaltige Erze, die meist nur geringe Mengen Silber (0,01–1 %) enthalten. Dies sind häufig Galenit (PbS) und Chalkopyrit (CuFeS). Aus diesem Grund wird Silber häufig als Nebenprodukt bei der Blei- oder Kupferherstellung gewonnen.

Ein als "Kongsbergit" bezeichnetes Silberamalgam mit einem Quecksilbergehalt von etwa 5 % wird als Varietät dem Silber zugerechnet. Bekannt ist Kongsbergit bisher von etwas mehr als 30 Fundorten.

Als "Arquerit" wird eine Silbervarietät ("Silberamalgam") mit einem Quecksilbergehalt von 10 bis 15 % bezeichnet.

Eine Silbervarietät mit einem Gehalt zwischen 10 und 30 % Gold ist unter der Bezeichnung "Küstelit" bekannt und konnte bisher (Stand: 2011) an rund 60 Fundorten nachgewiesen werden.

Seit dem 18. Jahrhundert ist bekannt, dass durch Erhitzen von Akanthit bzw. bei Verhüttungsprozessen von Silbererzen künstlich (anthropogen) erzeugte Silberdrähte, meist in Form von Silberlocken entstehen können. Besonders in den letzten Jahrzehnten wurde wiederholt über die künstliche Erzeugung von Silberlocken auf Akanthitstufen in der Fachliteratur berichtet.

Die wichtigsten Silbervorkommen befinden sich in Nordamerika (Mexiko, den USA und Kanada) und in Südamerika (Peru, Bolivien).
Mit rund 30 % der globalen Förderung war Peru 2009 der weltweit größte Silberproduzent. Im Jahr 2015 förderte Mexiko mit 5370 t weltweit das meiste Silber, gefolgt von Peru mit 3850 t. 

Das meiste Silber wird aus Silbererzen gewonnen, die oft zusammen mit Blei-, Kupfer- und Zinkerzen als Sulfide oder Oxide vorkommen. Wichtige Fundorte von gediegenem Silber waren: Freiberg im Erzgebirge; Schwaz (Tirol); Kongsberg/Norwegen (dort auch große Kristalle); Sankt Andreasberg im Harz; Keweenaw-Halbinsel/USA (dort mit gediegenem Kupfer als „halfbreed“); Batopilas/Mexiko; Mansfelder Kupferschiefer-Revier (Eisleben, Sangerhausen; meist Silberbleche; auch als Versteinerungsmaterial von Fossilien).

Zwischen dem Beginn des 20. Jahrhunderts und dem Ende des Zweiten Weltkrieges hat die jährlich geförderte Silbermenge zwar fluktuiert, ist aber im Mittel konstant geblieben. Vom Kriegsende bis heute hat sie sich mehr als verdoppelt.

Das polnische Unternehmen KGHM ist mit durchschnittlich 1.200 Tonnen Jahresförderung das bedeutendste Silberunternehmen der EU und das zweitgrößte weltweit.

Laut einer Studie des Rheinisch-Westfälischen Instituts für Wirtschaftsforschung, des Fraunhofer-Instituts für System- und Innovationsforschung sowie der Bundesanstalt für Geowissenschaften und Rohstoffe beträgt die weltweite Reichweite der Silberressourcen nur noch 29 Jahre. Somit ist mit einer Verknappung von Silber in den nächsten Jahrzehnten zu rechnen. Allerdings wird auch immer mehr Silber recycelt, wodurch die bekannten Vorkommen geschont werden. Ausgehend von den Daten des U.S. Geological Survey vom Januar 2013 ergibt sich in Bezug auf Reserven im Verhältnis zu den weltweiten Produktionszahlen von 2011 und 2012 eine aktuelle Reichweite (statische Reichweite) für Silber von 22 bis 23 Jahren (ohne Substitute und Recycling).

Wie bei den anderen Edelmetallen spielt die Wiederaufarbeitung silberhaltiger Materialien im Rahmen des Recyclings, beispielsweise von Fotopapieren, Röntgenfilmen, Entwickler- und Fixierbädern, Elektronikschrott und Batterien eine wichtige Rolle.

20 % des Silbers wird aus Silbererzen gewonnen. Aus diesen wird das Silber meist durch Cyanidlaugung mit Hilfe einer 0,1%igen Natriumcyanid-Lösung herausgelöst. Dazu wird das Erz zunächst fein zu einem Schlamm zerkleinert. Anschließend wird die Natriumcyanid-Lösung dazugegeben. Dabei ist eine gute Belüftung wichtig, da für das Verfahren Sauerstoff benötigt wird.

Bei der Zugabe von Natriumcyanid gehen sowohl elementares Silber als auch Silbererze (AgS, AgCl) als Dicyanoargentat(I) [Ag(CN)] in Lösung:

Da die Reaktion von Natriumcyanid mit Silbersulfid in einem Gleichgewicht steht, muss das Natriumsulfid entweder durch Oxidation mit Sauerstoff oder durch Fällung (z. B. als Bleisulfid) entfernt werden. Anschließend fällt man das edlere Silber – ähnlich wie bei der Goldgewinnung – mit Zink aus:

Das ausgefallene Rohsilber ("Werksilber") wird abgefiltert und weiter gereinigt (siehe Raffination).

Bei der Gewinnung von Bleierzen, z. B. aus Bleiglanz, entsteht nach dem Rösten und Reduzieren das sogenannte Rohblei oder Werkblei (genauere Informationen zur Bleigewinnung im Artikel Blei). Dieses enthält meist noch einen Anteil Silber (zwischen 0,01 und 1 %). Im nächsten Schritt wird nun das Edelmetall entfernt und so dieses wertvolle Nebenprodukt gewonnen.

Zur Gewinnung muss zunächst das Silber vom größten Teil des Bleis getrennt werden. Dies geschieht durch das Verfahren des "Parkesierens" (nach Alexander Parkes, der dieses Verfahren 1842 erfand). Das Verfahren beruht auf der unterschiedlichen Löslichkeit von Silber und Blei in Zink. Bei Temperaturen bis 400 °C sind Blei (flüssig) und Zink (fest) praktisch nicht mischbar. Zunächst wird bei Temperaturen >400 °C zum geschmolzenen Blei Zink gegeben. Danach wird die Mischung abgekühlt. Da Silber im geschmolzenen Zink leicht löslich ist, geht es in die Zinkphase über. Anschließend erstarrt die Zinkschmelze als so genannter "Zinkschaum" (Zink-Silber-Mischkristalle). Dadurch kann das Silber vom größten Teil des Bleis getrennt werden. Dieser Zinkschaum wird auch als "Armblei" bezeichnet. Er wird anschließend bis zum Schmelzpunkt des Bleis (327 °C) erhitzt, so dass ein Teil des Bleis schmilzt und entfernt werden kann. Danach wird die verbliebene Zink-Blei-Silber-Schmelze bis zum Siedepunkt des Zinks (908 °C) erhitzt und das Zink abdestilliert. Das so gewonnene Produkt wird "Reichblei" genannt und enthält etwa 8–12 % Silber.

Um das Silber anzureichern, wird nun die sogenannte "Treibarbeit" (Läuterung) durchgeführt. Dazu wird das Reichblei in einem Treibofen geschmolzen. Dann wird ein Luftstrom durch die Schmelze geleitet. Dabei oxidiert das Blei zu Bleioxid, das edle Silber bleibt hingegen unverändert. Das Bleioxid wird laufend abgeleitet und so nach und nach das Blei entfernt. Ist der Bleigehalt des Raffinats so weit gesunken, dass sich auf der Oberfläche der Metallschmelze keine matte Bleioxidschicht mehr bildet, das letzte Oxidhäutchen aufreißt und mithin das darunterliegende glänzende Silber sichtbar werden lässt, spricht man vom Silberblick. Die dann vorliegende Legierung wird Blicksilber genannt und besteht zu über 95 % aus Silber.

Silber ist auch in Kupfererzen enthalten. Bei der Kupferherstellung fällt das Silber – neben anderen Edelmetallen – im so genannten Anodenschlamm an. Dieser wird zunächst mit Schwefelsäure und Luft vom Großteil des noch vorhandenen Kupfers befreit. Anschließend wird er im Ofen oxidierend geschmolzen, wobei enthaltene unedle Metalle in die Schlacke gehen und entfernt werden können.

Rohsilber wird auf elektrolytischem Weg im Moebius-Verfahren gereinigt. Dazu wird das Rohsilber als Anode in eine Elektrolysezelle geschaltet. Als Kathode dient ein Feinsilberblech, als Elektrolyt salpetersaure Silbernitratlösung.

Das Verfahren entspricht der elektrolytischen Reinigung des Kupfers. Während der Elektrolyse werden Silber und alle unedleren Bestandteile des Rohsilbers (beispielsweise Kupfer oder Blei) oxidiert und gehen in Lösung. Edlere Anteile wie Gold und Platin können nicht oxidiert werden und fallen unter die Elektrode. Dort bilden sie den Anodenschlamm, der eine wichtige Quelle für Gold und andere Edelmetalle ist. An der Kathode wird nun ausschließlich Silber abgeschieden. Dieses sehr reine Silber bezeichnet man als Elektrolyt- oder Feinsilber.

Silber ist ein weißglänzendes Edelmetall. Das Metall kristallisiert im kubischen-flächenzentrierten Kristallsystem. Unter Normaldruck betragen die Schmelztemperatur 961 °C und die Siedetemperatur 2212 °C. Silber hat aber bereits oberhalb von 700 °C, also noch im festen Zustand, einen deutlichen Dampfdruck. Es siedet unter Bildung eines einatomigen, blauen Dampfes. Das Edelmetall besitzt eine Dichte von 10,49 g/cm³ (bei 20 °C) und gehört daher wie alle Edelmetalle zu den Schwermetallen.

Silber hat einen metallischen Glanz. Frische, unkorrodierte (Schnitt)flächen von Silber zeigen die höchsten Licht-Reflexionseigenschaften aller Metalle, frisch abgeschiedenes Silber reflektiert über 99,5 Prozent des sichtbaren Lichtes. Als „weißestes“ aller Gebrauchsmetalle wird es daher auch zur Herstellung von Spiegeln benutzt. Strichfarbe ist ein gräuliches Weiß. Mit abnehmender Korngröße wird die Farbe immer dunkler und ist bei fotografisch fein verteilten Silberkristallen schwarz. Das Reflexionsspektrum zeigt im nahen UV eine ausgeprägte Plasmakante.

Silber leitet von allen Metallen Wärme und Elektrizität am besten. Wegen seiner Dehnbarkeit und Weichheit (Mohshärte von 2,5-4) lässt es sich zu feinsten, blaugrün durchschimmernden Folien von einer Dicke von nur 0,002 bis 0,003 mm aushämmern oder zu dünnen, bei 2 km Länge nur 0,1 bis 1 g wiegenden Drähten (Filigrandraht) ausziehen.

Im geschmolzenen Zustand löst reines Silber leicht aus der Luft das 20-fache Volumen an Sauerstoff, der beim Erstarren der Schmelze unter Aufplatzen der bereits erstarrten Oberfläche (Spratzen) wieder entweicht. Bereits gering legiertes Silber zeigt diese Eigenschaft nicht.

Silber ist ein Edelmetall mit einem Normalpotential von +0,7991 V. Aus diesem Grund ist es relativ reaktionsträge. Es reagiert auch bei höherer Temperatur nicht mit dem Sauerstoff der Luft. Da in der Luft spurenweise Schwefelwasserstoff HS enthalten ist, laufen Silberoberflächen allerdings mit der Zeit schwarz an, da elementares Silber mit Schwefelwasserstoff in Anwesenheit von Luftsauerstoff Silbersulfid (AgS) bildet:

Silber löst sich nur in oxidierenden Säuren, wie beispielsweise Salpetersäure. In nichtoxidierenden Säuren ist es nicht löslich. Auch in Cyanid-Lösungen löst es sich bei Anwesenheit von Sauerstoff durch die Bildung eines sehr stabilen Silbercyanid-Komplexes, wodurch das elektrochemische Potential stark verschoben ist. In konzentrierter Schwefel- und Salpetersäure löst sich Silber nur bei erhöhten Temperaturen, da es durch Silbernitrat und -sulfat passiviert ist. Silber ist stabil gegen geschmolzene Alkalihydroxide wie Natriumhydroxid. Im Labor verwendet man darum für diese Schmelzen auch Silber- anstatt Porzellan- oder Platintiegel.

Silber wirkt in feinstverteilter Form bakterizid, also schwach toxisch, was aufgrund der großen reaktiven Oberfläche auf die hinreichende Entstehung von löslichen Silberionen zurückzuführen ist. Im lebenden Organismus werden Silberionen jedoch in der Regel schnell an Schwefel gebunden und scheiden aus dem Stoffkreislauf als dunkles, schwer lösliches Silbersulfid aus.
Die Wirkung ist oberflächenabhängig. Dies wird in der Medizin genutzt für Wundauflagen wie für invasive Geräte (z. B. endotracheale Tuben). In der Regel wird Silber für bakterizide Zwecke daher in Medizinprodukten als Beschichtung oder in kolloidaler Form eingesetzt, zunehmend auch Nanosilber. Silberionen finden als Desinfektionsmittel und als Therapeutikum in der Wundtherapie Verwendung. Sie können silberempfindliche Erreger nach relativ langer Einwirkzeit reversibel inhibieren, können darüber hinaus bakteriostatisch oder sogar bakterizid (also abtötend) wirken. Man spricht hier vom oligodynamischen Effekt. In manchen Fällen werden Chlorverbindungen zugesetzt, um die geringe Wirksamkeit des Silbers zu erhöhen.

Dabei kommen verschiedene Wirkmechanismen zum Einsatz:
Die beschriebenen Effekte können zum Zelltod führen.

Neben der Argyrie, einer irreversiblen schiefergrauen Verfärbung von Haut und Schleimhäuten, kann es bei erhöhter Silberakkumulation im Körper außerdem zu Geschmacksstörungen und Riechstörungen sowie zerebralen Krampfanfällen kommen. Silber reichert sich in der Haut, der Leber, den Nieren, der Hornhaut der Augen, im Zahnfleisch, in Schleimhäuten, Nägeln und der Milz an.

Umstritten ist die therapeutische Einnahme von kolloidalem Silber, das seit einigen Jahren wieder verstärkt ins Blickfeld der Öffentlichkeit rückt und über Internet und andere Kanäle vermarktet wird. Es wird vor allem als Universalantibiotikum angepriesen und soll noch andere Leiden kurieren können. Wissenschaftliche Studien über die Wirksamkeit gibt es nicht. Bereits die mit einem gängigen Antibiotikum vergleichbare Wirkung ist bei peroraler Verabreichung stark anzuzweifeln. Sehr geringe oral aufgenommene Mengen bis 5 Mikrogramm Silber pro Kilogramm Körpergewicht und Tag sollen nach Ansicht der amerikanischen Umweltschutzbehörde EPA zu keiner Vergiftung führen.

Die Auswirkungen von Silber in Form von Nanopartikeln auf menschliche Gesundheit und Umwelt werden unter REACH im Jahr 2014 im Rahmen der Stoffbewertung von den Niederlanden geprüft.

Silber gilt in vielen Märchen und Sagen als das einzige Metall, das in der Lage ist, Werwölfe und andere mythologische Wesen zu töten, was auch in modernen Fantasy-Romanen und Filmen häufig aufgegriffen wird.

Der Preis des Silbers wird auf dem offenen Markt bestimmt. Das geschieht seit dem 17. Jahrhundert am London Bullion Market. Die Einführung des Silberfixings 1897 in London markiert den Beginn der Marktstruktur. 1987 wurde die London Bullion Market Association (LBMA) gegründet. Drei LBMA-Mitglieder nehmen am Silberfixing an jedem Arbeitstag unter Vorsitz der Bank of Nova Scotia - ScotiaMocatta teil. Weitere Mitglieder des Silberfixings sind die Deutsche Bank AG London und HSBC Bank USA NA London Branch.

In den 1970er Jahren führte die Silberspekulation der Brüder Hunt zu einem Rekordstand beim Silberpreis. Diese kauften im Zusammenspiel mit vermögenden Geschäftsleuten aus Saudi-Arabien riesige Mengen an Silber sowie Silberkontrakten an den Warenterminbörsen und versuchten, den Silbermarkt zu beherrschen. Am 18. Januar 1980 wurde beim Silberfixing am London Bullion Market ein Rekordstand von 49,45 US-Dollar pro Feinunze ermittelt. Den nächsten Rekord erreichte der Silberpreis erst über 31 Jahre später, am 25. April 2011, als die Feinunze Silber in Hong Kong mit 49,80 US-Dollar gehandelt wurde. Dem Inflationsrechner des United States Department of Labor zufolge entsprechen 49,45 US-Dollar von 1980 im Jahr 2011 einer Summe von 134,99 US-Dollar. Daher dürfte es noch lange dauern bis der Preis von 1980 unter Berücksichtigung der Inflation überschritten wird.

Für den standardisierten Silberhandel an Rohstoffbörsen wurde „XAG“ als eigenes Währungskürzel nach ISO 4217 vergeben. Es bezeichnet den Preis einer Feinunze Silber (31,1 Gramm).

Die früher wichtigste Verwendung war die Herstellung von Silbermünzen als Zahlungsmittel. Für Münzen wurde in der Antike und im Mittelalter nur Silber, Gold und Kupfer bzw. Bronze verwendet. Der Münzwert entsprach weitgehend dem Metallwert (Kurantmünze). In Deutschland waren bis 1871 Silbermünzen (Taler) vorherrschend, die Währung war durch Silber gedeckt (Silberstandard). Nach 1871 wurde der Silber- durch den Goldstandard abgelöst. Der Grund für die Verwendung dieser Edelmetalle waren die hohe Wertspeicherung (Seltenheit) und Wertbeständigkeit von Silber und Gold. Erst in moderner Zeit werden Münzen auch aus anderen Metallen, wie Eisen, Nickel oder Zink hergestellt, deren Metallwert aber geringer ist und nicht dem aufgeprägten Wert entspricht (Scheidemünze). Silber wird als Münzmetall heute meist nur noch für Gedenk- und Sondermünzen verwendet.

Besonders in Zeiten von Wirtschaftskrisen – wie z. B. ab 2007 – hat sich neben Gold auch das Edelmetall Silber durch seine Kurs- und Wertstabilität als eine der wichtigsten Anlageform in verschiedensten Ausprägungen wie z. B. Silberbarren, Silberschmuck oder Silbermünzen erwiesen. Im Umfeld von Währungskrisen gab es seit der Antike mehrmals in der Geschichte ein Silberverbot (s. Goldverbot).

Silber ist neben Gold und Edelsteinen (z. B. Diamanten) ein wichtiges Material für die Herstellung von Schmuck und wird seit Jahrhunderten für erlesenes und wertbeständiges Essbesteck ("Tafelsilber") und Sakrales Gerät verwendet. Silberstempel (Meistermarke, Stadtmarke, Steuermarke u. a. Punzen) geben Auskunft über die Herkunft des Gegenstandes. Bei Schmuck, Gerät und Barren kann der Silbergehalt, sofern angegeben, anhand des Feingehaltstempels abgelesen werden.

Silbermedaillen werden bei vielen Sportwettkämpfen, z. B. bei den Olympischen Spielen, als Zeichen für das Erreichen des zweiten Platzes verliehen. Die olympische Goldmedaille besteht ebenfalls zu 92,5 % aus Silber und ist lediglich mit 6 g reinem Gold vergoldet. Auch in anderen Bereichen werden Auszeichnungen häufig als „silbern“ bezeichnet. Beispiele sind Silberner Bär, Silberner Griffel, Silberner Schuh und Silbernes Lorbeerblatt.

Sehr begehrt ist es auch bei Musikinstrumenten, da es aufgrund seiner Dichte einen schönen, warmen Ton von sich gibt, leicht zu verarbeiten ist und z. B. bei der Querflöte das empfindliche Holz ersetzt.

Silber besitzt die höchste elektrische Leitfähigkeit aller Metalle, eine hohe Wärmeleitfähigkeit und eine ausgeprägte optische Reflexionsfähigkeit. Dadurch ist es für Anwendungen in Elektrik, Elektronik und Optik prädestiniert. Die Reflexionsfähigkeit von Glasspiegeln beruht auf der chemischen Versilberung von Glasscheiben. Dieses Prinzip wird auch bei der Fertigung von Christbaumschmuck, Optiken und Licht- oder Wärmereflektoren verwendet. Eine Suspension von Silberpulver in Klebstoffen macht sie zu elektrisch (und thermisch) leitfähigen Klebern.

Die Schwärzung der Silberhalogenide infolge ihres Zerfalls durch Licht und Entwicklung wird beim Fotopapier genutzt. Es bildete von etwa 1850 bis zur Verbreitung der Digitaltechnik die Grundlage der Fotografie.

Silberlegierungen (mit Kupfer, Zink, Zinn, Nickel, Indium usw.) werden in der Elektrotechnik und Löttechnik als Lotlegierungen (sogenanntes Hartlöten), Kontaktmaterialien (z. B. in Relais) und Leitmaterial (z. B. als Kondensatorbeläge) verwendet. Silberlegierungen werden aber auch in der Dentaltechnik und im dekorativen Bereich verwendet.

Silbergeschirre und -geräte geben beim Gebrauch immer etwas Silber an die Speisen und Getränke ab, was sich besonders bei manchen Getränken (Wein) in einem unangenehmen Metallgeschmack bemerkbar machen kann. Um dies zu vermeiden, werden silberne Trinkgefäße oft innen vergoldet. Durch Silbersulfid angelaufenes Silber wird entweder poliert oder chemisch reduziert (siehe Silberpflege).

Werkstoffe oder Beschichtungsverfahren nutzen die antibakterielle Wirkung von Silber in Medizinprodukten und anderen Anwendungen in Form von Silberbeschichtungen, als kolloidales Silber, Nanosilber oder in Form von Silberfäden.
Beispiele in Medizinprodukten:


In Bezug auf die nichtmedizinische Anwendung von Silber empfiehlt das Bundesinstitut für Risikobewertung (BfR) vorerst generell auf den Einsatz von nanoskaligem Silber oder nanoskaligen Silberverbindungen in verbrauchernahen Produkten zu verzichten.

Silberkatalysatoren finden industrielle Anwendung in der Partialoxidation von Ethen zu Ethylenoxid bzw. von Methanol zu Formaldehyd. Durch die Bedeutung des Silbers für die Oxidationskatalyse sind zahlreiche Untersuchungen zur Wechselwirkung von Silberoberflächen mit Sauerstoff durchgeführt worden. Verschiedene Sauerstoffspezies sind an der Silberoberfläche, im oberflächennahen Bereich und im Silbervolumen lokalisiert. Neben Spezies, die auf das Substrat übertragen werden und mehr oder weniger selektiv zur Oxidation eines Moleküls führen, sind auch Zentren vorhanden, die eine katalytische Dehydrierung ermöglichen. Dies ist interessant im Zusammenhang mit der Tatsache, dass die Partialoxidation von Methanol zu Formaldehyd unterstöchiometrische Mengen an Sauerstoff erfordert. Die Bildung der Sauerstoffspezies ist abhängig von der Temperatur, aber auch von der Art der Reaktionsatmosphäre. Bestimmte O-Spezies sind "ex situ" nicht nachweisbar und stellen hohe Anforderungen an die eingesetzten Charakterisierungsmethoden.

Silber katalysiert anderseits auch die Reduktion organischer Substrate durch Wasserstoff, z. B. die Hydrierung von α,β-ungesättigten Carbonylverbindungen. Die Wechselwirkung von H mit Silberkatalysatoren ist – verglichen mit klassischen Hydrierkatalysatoren wie Platin – nur schwach ausgeprägt. Ag-Katalysatoren sind deshalb in der Lage, Doppelbindungen von bi-/multifunktionellen Molekülen selektiv zu hydrieren (z. B. Hydrierung von Acrolein zu Allylalkohol).

Silber wird als Lebensmittelfarbstoff E 174 auch im Speisenbereich verwendet, zum Beispiel für Überzüge von Süßwaren wie etwa Pralinen und in Likören. Silbersalze färben Glas und Emaille gelb.

Silber ist mit vielen Metallen legierbar. Gut legieren lässt es sich mit Gold, Kupfer oder Palladium (ein Palladiumgehalt von 20 bis 30 Prozent macht das Silber anlaufbeständig). In begrenztem Umfang lässt sich Silber mit Chrom, Mangan oder Nickel legieren. Legieren erhöht zumeist die Härte des Silbers. Mit Cobalt oder Eisen lässt es sich nicht legieren.
Die wichtigsten Silberlegierungen sind heute Kupfer-Silber-Legierungen. Sie werden meist nach ihrem Feingehalt an Silber, angegeben in Tausendstel, bezeichnet. Die gebräuchlichsten Silberlegierungen haben einen Feingehalt von 800, 835, 925 und 935 Tausendstel Teile Silber. 925er Silber wird nach der britischen Währung Pfund Sterling als Sterlingsilber bezeichnet. Es ist die wichtigste Silberlegierung und wird u. a. zur Herstellung von Münzen, Schmuck und Besteck verwendet.

Im Hinblick auf den Export werden heute Korpuswaren vorwiegend aus einer Silberlegierung mit einem Feingehalt von 935/1000 hergestellt, da die Waren mit Silberloten gelötet werden, deren Feingehalt niedriger ist, um letztendlich dem gesetzlich geforderten Gesamtfeingehalt von beispielsweise 925/1000 zu genügen. Eine neuartige Legierung aus England ist Argentium Sterling Silber, das nicht anlaufen soll. Auch bei stark beanspruchten Bestecken geht seit Jahren der Trend zum Sterlingsilber. Silberwaren werden in der Regel abschließend feinversilbert, Bestecke und Verschleißartikel hartversilbert. Durch die reine Silberbeschichtung werden die verkaufsfördernde, strahlendweiße Silberfarbe und ein stark vermindertes Anlaufen der Waren erreicht.

Eine im Mittelalter für die Verzierung von Kunstwerken verwendete Silberlegierung ist das Tulasilber, eine Legierung von Silber, Kupfer, Blei und Schwefel. Silber wird häufig auch vergoldet, man nennt es mit einem aus dem Französischen beziehungsweise Lateinischen stammenden Wort dann „Vermeil“.

Silber kommt in chemischen Verbindungen hauptsächlich in der Oxidationsstufe +I vor, die Oxidationsstufen +II, +III und +IV sind selten und meist nur in Komplexen stabil.

Zu den wichtigsten Silberverbindungen zählen die Silberhalogenide. Sie zersetzen sich im Licht und werden deshalb in der Analogfotografie gebraucht. Silberhalogenide sind außer dem Fluorid schwer in Wasser löslich und dienen zum Nachweis von Halogenid-Ionen.


Die Silberoxide mit Silber in Oxidationsstufen größer +I können nur auf elektrochemischen Wege dargestellt werden. Dies sind die Verbindungen Silber(I,III)-oxid AgO, Silber(II,III)-oxid AgO und Silber(III)-oxid AgO.



Silber in höheren Oxidationsstufen tritt beispielsweise im Tetrapyridinosilber(II)-persulfat – [Ag(CHN)]SO, im Kaliumtetrafluoroargentat(III) K[AgF] oder Caesiumhexafluoroargentat(IV) Cs[AgF] auf. Die giftigen Silbercyanide werden u. a. in galvanischen Bädern zur Versilberung und Farbvergoldung (hellgelb-grünlichgelb) eingesetzt. Bei Silber(I) ist die Neigung zur Bildung von Komplexionen ausgeprägt, meist mit der Koordinationszahl 2. Diese Komplexionen sind mit Ausnahme des erst in stark salzsaurer Lösung entstehenden [AgCl] nur in alkalischer (basischer) oder neutraler Lösung beständig.

Beim Zutropfen von Halogenid-Lösung in die zu prüfende Flüssigkeit bilden sich beim Vorhandensein von Silber-Kationen Niederschläge, z. B.:

Als Nachweisreaktion für Silbersalze erfolgt daher die Zugabe von Salzsäure oder Natriumchloridlösung: Ein weißer Niederschlag von Silberchlorid (löslich in verdünntem Ammoniakwasser, es entsteht der Silberdiamminkomplex [Ag(NH)]). Bei hohen Konzentrationen an Chlorid löst sich das Silberchlorid teilweise wieder auf, da sich komplexe Dichloroargentate(I) bilden:

Der Niederschlag ist bei Iodid-Ionen (AgI) gelb-grünlich und in Ammoniakwasser unlöslich, bei Chlorid- und Bromid-Ionen (AgCl, AgBr) weißlich.

In der Heraldik wird Silber, wie auch Gold, als Metall bezeichnet, das zu den heraldischen Tinkturen zählt. Es wird häufig durch weiße Farbe wiedergegeben.





</doc>
<doc id="4540" url="https://de.wikipedia.org/wiki?curid=4540" title="Schwermetalle">
Schwermetalle

Mit der Bezeichnung Schwermetalle wird eine Gruppe von Metallen zusammengefasst. Da eine eindeutige wissenschaftlich akzeptierte Definition des Begriffes „Schwermetall“ fehlt, gibt es in der Literatur eine Vielzahl unterschiedlicher Definitionen. Mehrere Quellen stufen als Schwermetall ein Metall ein, dessen Dichte größer als 5,0 g/cm³ oder – bei älteren Quellen – größer als 4,5 g/cm³ ist.

In der Kerntechnik wird "Schwermetall" in zwei verschiedenen besonderen Bedeutungen verwendet:

In der Technik (nur NE-Metalle) und der Chemie fallen unter den Begriff „Schwermetall“ Metalle mit einer Dichte > 5 g/cm³. Zu diesen werden üblicherweise unter anderem die Edelmetalle sowie Bismut, Eisen, Kupfer, Blei, Zink, Zinn, Nickel, Cadmium, Chrom und Uran gerechnet.
Eine Studie der IUPAC fand jedoch mindestens 38 Definitionen für die Bezeichnung „Schwermetall“, die angefangen von der Dichte, dem Atomgewicht oder der Ordnungszahl bis zu den chemischen Eigenschaften oder der Toxizität reichen. Folglich unterscheiden sich Listen von „Schwermetallen“ von einem Satz von Richtlinien zu einem anderen; dabei werden oft auch Halbmetalle wie z. B. Arsen mit eingeschlossen. Die Bezeichnung wird oft ohne Angabe der Metalle, auf die sie sich bezieht, verwendet. Aus den oben aufgeführten Gründen ist die Bezeichnung aller anderen Metalle als Leichtmetalle ebenso undefiniert. In der Öffentlichkeit gelten oft alle als „Schwermetall“ bezeichneten Stoffe (wobei deren Verbindungen und Legierungen häufig ebenfalls dazu gerechnet werden) als toxisch. Folgende Elemente haben eine Dichte über 5 g/cm³:
<nowiki>*</nowiki> Halbmetalle
<nowiki>**</nowiki> Da sich diese chemischen Elemente nicht mehr in messbaren Mengen synthetisieren lassen, entziehen sich viele deren Eigenschaften wie die Dichte einer direkten Messung. Modellrechnungen legen jedoch entsprechende Eigenschaften nahe.

Die Tabelle enthält Elemente mit einer Dichte ab 5 g/cm³. Elemente mit bekannter Dichte zwischen 5 und 10 g/cm³ sind gelb, zwischen 10 und 20 g/cm³ orange und über 20 g/cm³ braun hinterlegt.

Schwermetalle kommen in den Gesteinen der Erdkruste vor und sind dort in Erzen als Oxide, Sulfide und Carbonate fest eingebunden und auch in Silikaten eingeschlossen oder liegen zum Teil gediegen vor. Ihre Konzentration in Hydrosphäre, Atmosphäre und Pedosphäre schwankt über viele Größenordnungen. Ihre Konzentration in der Erdkruste reicht von einstelligen parts per billion (ppb) (Iridium, Gold, Platin) bis zu 5 Prozent (Eisen). Durch Verwitterung und Erosion gelangen diese auf natürlichem Wege in Böden und Grundwasser. Dabei enthalten einige Gesteine wie Pikrit, Serpentinit, Basalte und vor allem Erze zum Teil hohe Konzentrationen von Chrom, Nickel und Cobalt, was in deren Umgebung zu einer hohen natürlichen Schwermetallbelastung der Böden führt. Die Stoffkreislaufmengen und die Akkumulation in der Umwelt sind seit der Industrialisierung im 19. Jahrhundert durch wachsende Emissionen aus verschiedenen anthropogenen Quellen jedoch schnell angestiegen. Dazu gehören die Gewinnung von Schwermetallen und deren Verarbeitung, die Düngemittelherstellung, die Verbrennung von Kohle, Müll und Klärschlamm, der Kfz-Verkehr und die Stahl-, Zement- und Glasproduktion. Der bergmännische Abbau von „Schwermetallerzen“ geht häufig mit einer hohen Schwermetallbelastung der Böden einher. An einigen Stellen im Harz, im Siegerland und der Aachener Umgebung hat sich beispielsweise auf den durch Erzbergbau belasteten Böden azonale Vegetation spezifischer Pflanzengesellschaften ausgebildet. Dort bilden die Galmeipflanzen sogenannte „Schwermetallrasen“ aus.

Vor 4,5 Mrd. Jahren – als der Erdmantel noch flüssig war – sanken die Schwermetalle zum Erdmittelpunkt und bildeten den Erdkern. Zum Vorkommen von Schwermetallen in der Erdkruste nehmen Geologen an, dass der größte Teil von Asteroiden stammt. Untermauert wird diese Vermutung durch eine Studie mit Wolfram, welches aus einer Gesteinsprobe aus Grönland stammt. In dieser Gesteinsprobe fand sich 13-mal häufiger das Isotop W als in Gesteinsproben anderer Orte. Matthias Willbold von der University of Bristol, der Erstautor der Studie, sagt: „Die meisten der Edelmetalle, auf denen unsere Wirtschaft und viele wichtige industrielle Prozesse basieren, kamen durch einen glücklichen Zufall auf unseren Planeten – als die Erde von rund 20 Trillionen Tonnen Asteroidenmaterial getroffen wurde.“

Von Natur aus kommen Schwermetalle und ihre Verbindungen in der Biosphäre nur in Spuren vor. Manche von ihnen sind in kleinen Mengen lebenswichtig für Pflanzen, Tiere und den Menschen, sie werden dann als essentielle Schwermetalle oder Spurenelemente bezeichnet. Dazu gehören Chrom, Eisen, Cobalt, Kupfer, Mangan, Molybdän, Nickel, Vanadium, Zink und Zinn. Viele Schwermetalle, auch die essentiellen, können bereits in leichter Überkonzentration für den menschlichen Organismus gesundheitsschädlich oder giftig sein, wobei deren toxische Wirkung auch stark von der chemischen Verbindung des Schwermetalles abhängt. Ein Beispiel dafür ist Chrom, welches in elementarer Form ungiftig, als Chrom(III) essentiell und als Chrom(VI) giftig und karzinogen ist. Im Allgemeinen steigt die Gefährlichkeit der Verbindungen mit ihrer Wasser- und Fettlöslichkeit. Die Stoffe werden meist über die Nahrungskette aufgenommen und gelangen so in den menschlichen Körper. Pflanzen spielen dabei eine große Rolle, da sie Schwermetalle aufnehmen und anreichern können. Beim Menschen wirken chronische Schwermetallvergiftungen oft spezifisch auf bestimmte Organe und rufen charakteristische Krankheitsbilder hervor.

Schwermetalle im Erdboden können mobilisiert ins Grundwasser, in Pflanzen und somit in die Nahrungskette gelangen und dort physiologische Schäden verursachen.

Seit dem Jahr 2006 gibt das amerikanische Blacksmith Institute eine Liste der zehn am stärksten verseuchten Orte der Welt heraus. Dabei sind sämtliche Schwermetalle – zumeist durch Bergbau oder bei der Verhüttung emittiert – jedes Mal in vielfältiger Weise vertreten.

Blei sammelt sich bei der Aufnahme durch Nahrung und Atemluft im menschlichen Organismus an und wirkt schon in geringen Spuren als chronisches Gift. Es reichert sich in Knochen, Zähnen und im Gehirn an und beeinträchtigt die Funktionsfähigkeit des Nervensystems. Besonders Kinder sind gefährdet, sie zeigen oft Intelligenz-, Lern- und Konzentrationsstörungen. Auch die Immunabwehr kommt bei Bleivergiftungen zu Schaden, daraus folgt eine erhöhte Infektanfälligkeit.

Die größte Quelle für Bleivergiftung war in Westeuropa bis in die 1980er Jahre Benzin, dem Tetraethylblei zugesetzt wurde, um die Klopffestigkeit zu erhöhen. Seit der Wiedervereinigung wird auch in Ostdeutschland ausschließlich bleifreies Benzin verwendet, so dass seitdem auch dort die Blutwerte für Blei bei der Bevölkerung zurückgehen. Weltweit wird allerdings noch in Afrika und weiten Teilen Asiens verbleites Benzin verwendet – mit den entsprechenden gesundheitlichen Folgen.

Seit 1973 wurden in Deutschland keine Bleirohre mehr als Wasserleitung im Haus verbaut. Praktisch frei von Bleirohren ist der gesamte süddeutsche Raum, da dort seit über hundert Jahren keine mehr verlegt wurden. Der Grenzwert für Blei im Leitungswasser lag ab dem 1. Dezember 2003 bei 25 µg/L und wurde am 1. Dezember 2013 auf 10 µg/L reduziert.

Cadmium und seine Verbindungen sind schon in geringen Konzentrationen giftig. Es hat sich im Tierversuch als krebserregend erwiesen und ist erbgut- und fruchtschädigend. Der Körper eines Erwachsenen enthält ca. 30 mg Cadmium, ohne dass es für den Aufbau von Körpersubstanzen benötigt wird. Es gehört zu den nichtessentiellen Elementen. Die orale Aufnahme von löslichen Cadmium-Salzen kann Erbrechen und Störungen im Verdauungstrakt, Leberschädigungen und Krämpfe verursachen. Die Inhalation von Cadmium-Dämpfen ruft Reizungen der Atemwege und Kopfschmerzen hervor. Chronische Vergiftungen äußern sich durch den Ausfall des Geruchsvermögens, Gelbfärbung der Zahnhälse, Blutarmut und Wirbelschmerzen, in fortgeschrittenem Stadium durch Knochenmarkschädigungen und Osteoporose. Cadmium ist vermehrt in Verruf gekommen seit dem Auftreten der oft tödlich endenden Itai-Itai-Krankheit in Japan, die mit schweren Skelettveränderungen einhergeht. Die Anreicherung von Cadmium in der Leber und vor allem in der Niere ist besonders bedenklich. Bei Rauchern wurden etwa doppelt so hohe Gehalte von Cadmium wie bei Nichtrauchern festgestellt. Die durchschnittliche Belastung mit Cadmium durch Rauchen beträgt 2 bis 4 µg pro Tag. Mit der Nahrung nimmt der Mensch täglich zwischen 10 und 35 µg Cadmium auf. Laut WHO liegt der kritische Grenzwert bei 10 µg pro Tag und Kilogramm Körpermasse. Die biologische Halbwertszeit beim Menschen liegt zwischen 10 und 35 Jahren.

Kupfer zählt zu den lebensnotwendigen Spurenelementen. Spezielle Verbindungen jedoch können beim Verschlucken großer Mengen Schwäche, Erbrechen und Entzündungen im Verdauungstrakt verursachen. Akute Vergiftungen durch sehr hohe Mengen sind beim Menschen selten, da zwangsläufig Erbrechen ausgelöst wird. Kupfer wirkt in zahlreichen chemischen Prozessen katalytisch, dies betrifft auch Stoffwechselvorgänge.

Kupfer muss vom Menschen jeden Tag in ausreichender Menge aufgenommen werden. Die Speicherkapazität im Körper ist begrenzt. Der tägliche Bedarf eines Erwachsenen liegt bei etwa 1 bis 2 mg. Zahlreiche Nahrungsmittel enthalten dieses Spurenelement, hierzu zählen insbesondere Nüsse, bestimmte Fisch- und Fleischsorten sowie einige Gemüse. Kupfer kann auch durch kupferhaltige Wasserleitungen ins Trinkwasser gelangen, allerdings nur, wenn das Trinkwasser längere Zeit in den Leitungen gestanden hat. Nur bei Wässern mit geringem pH-Wert ist dies mengenmäßig von Bedeutung. In diesem Fall wird empfohlen, abgestandenes Wasser ablaufen zu lassen. Frisches Wasser, das nicht in Leitungen stagniert, wird durch die Werkstoffe, die in der Hausinstallation verbaut wurden, grundsätzlich nicht in seiner Zusammensetzung verändert. Die Trinkwassernormen der WHO und der EU erlauben einen maximalen Kupfergehalt von 2 mg/L. Die deutsche Trinkwasserverordnung übernahm diesen Wert, der mit der Änderungsverordnung zur Trinkwasserverordnung 2011 auf 2,0 mg/L präzisiert wurde.

Ein Kupfergehalt von 2 mg/L verleiht Wasser bereits einen metallischen Geschmack, 5 mg/L machen es ungenießbar. Nach derzeitigem Wissen wird ein mittlerer Gehalt des Trinkwassers von 2 mg/L als gesundheitlich unbedenklich angesehen, dies gilt für lebenslangen Genuss.
Eine stark überhöhte Kupferzufuhr über Wasser oder Nahrungsmittel kann bei Säuglingen und Kleinkindern, deren Kupferstoffwechsel noch nicht vollständig ausgebildet ist, zur frühkindlichen Leberzirrhose führen.
Dies liegt unter anderem daran, dass der spezifische Gesamtbestand des Kupfers im Körper von Säuglingen schon bei Geburt von Natur aus relativ hoch ist. Bei Jugendlichen und Erwachsenen wird überschüssiges Kupfer ähnlich wie bei Vitamin C wieder ausgeschieden.

Vom Umweltbundesamt wurde 2011 der Entwurf der trinkwasserhygienisch geeigneten metallischen Werkstoffe veröffentlicht, Kupfer ist hierbei für alle Bauteiltypen enthalten.
Bei Wässern mit einem niedrigen pH-Wert sollten Kupferbauteile auf der Innenoberfläche verzinnt sein – DIN 50930-6 gibt hierzu detaillierte Beschreibungen der wasserseitigen Rahmenbedingungen. Eine genaue Prüfung ist bei Hausbrunnen notwendig, weil Hausbrunnenwasser vielfach nicht aufbereitet wird. Von dieser Ausnahme abgesehen ist das Trinkwasser aber deutlich besser als sein Ruf und kann unbedenklich auch von Kindern reichlich getrunken werden.

Obwohl Kupfer für den Menschen zu den lebensnotwendigen Spurenelementen zählt, wirkt es auf viele Mikroorganismen wachstumshemmend oder sogar aktiv antimikrobiell. Gezielt genutzt wird diese Eigenschaft für Kontaktoberflächen im medizinischen Bereich als ergänzende Maßnahme im Kampf gegen antibiotikaresistente Mikroorganismen.

Die für einen Menschen tödliche Dosis liegt wahrscheinlich im zweistelligen Milligrammbereich. Viel gefährlicher als die chemische Wirkung ist aber seine Radioaktivität, die Krebs verursachen kann. Zur Entstehung von Krebs reicht vermutlich eine Menge in der Größenordnung einiger Mikrogramm. Aus dieser Abschätzung wurde das weit verbreitete Missverständnis über die besondere Gefährlichkeit von Plutonium abgeleitet. Da die ausgesendete Alphastrahlung schon durch die äußersten Hornhautschichten abgeschirmt wird, ist Plutonium nur bei Inkorporation (beispielsweise die Inhalation von plutoniumhaltigem Staub) gesundheitsschädlich.

Metallisches Quecksilber kann als Quecksilberdampf über die Lunge in den Körper aufgenommen werden. Es reizt die Atem- und Verdauungswege, kann zu Erbrechen mit Bauchschmerzen führen und auch Schäden an Nieren und am Zentralnervensystem hervorrufen.

Thallium und thalliumhaltige Verbindungen sind hochgiftig und müssen mit größter Vorsicht gehandhabt werden.

Schwermetalle werden in vielen Bereichen, zumeist aber für die Metallveredelung verwendet. Dadurch erhalten die ausgewählten Materialien spezielle Eigenschaften. Folgende Anwendungsgebiete sind heute aufgrund ihrer gesundheitsgefährdenden Wirkung verboten:

Weiterhin verwendete Schwermetalle:

Anwendung in der Medizin:


</doc>
<doc id="4541" url="https://de.wikipedia.org/wiki?curid=4541" title="Strontium">
Strontium

Strontium ist ein chemisches Element mit dem Elementsymbol Sr und der Ordnungszahl 38. Im Periodensystem steht es in der 5. Periode sowie der 2. Hauptgruppe, bzw. der 2. IUPAC-Gruppe und gehört damit zu den Erdalkalimetallen. Es ist ein weiches (Mohshärte: 1,5) und sehr reaktionsfreudiges Metall.

Das Element wurde 1790 von Adair Crawford entdeckt und nach seinem ersten Fundort Strontian in Schottland benannt. Elementar, allerdings noch durch Fremdbeimengungen verunreinigt, konnte es 1808 mittels Elektrolyse durch Humphry Davy dargestellt werden. Robert Bunsen gelang 1855 auch die Darstellung reinen Strontiums. Das Element wird nur in geringen Mengen, vor allem für Kathodenstrahlröhren, Pyrotechnik (rote Flammenfarbe), Dauermagnete und in der Aluminiumverhüttung verwendet.

Strontium kommt in geringen Mengen im menschlichen Körper vor, hat jedoch keine bekannte biologische Bedeutung und ist nicht essentiell. Eine medizinische Wirkung von Strontiumsalzen, insbesondere Strontiumranelat gegen Osteoporose, wird untersucht.

Erste Hinweise auf die Existenz des Elements fanden Adair Crawford und William Cumberland Cruikshank im Jahr 1790, als sie ein aus Strontian in Schottland stammendes Mineral, das zunächst für „lufthaltigen Baryt“ (Bariumcarbonat, Witherit) gehalten wurde, genauer untersuchten. Sie stellten das Chlorid her und verglichen mehrere Eigenschaften des späteren Strontiumchlorides mit denen des Bariumchlorides. Dabei stellten sie unter anderem verschiedene Löslichkeiten in Wasser und andere Kristallformen fest. 1791 benannte Friedrich Gabriel Sulzer (1749–1830) das Mineral nach seinem Fundort Strontian Strontianit. Er und Johann Friedrich Blumenbach untersuchten das Mineral genauer und fanden so weitere Unterschiede zum Witherit, wie die unterschiedliche Giftigkeit und Flammenfarbe. In den folgenden Jahren wurden durch Chemiker wie Martin Heinrich Klaproth, Richard Kirwan, Thomas Charles Hope oder Johann Tobias Lowitz das Strontianit weiter untersucht und andere Strontiumverbindungen daraus gewonnen.

1808 gelang Humphry Davy durch elektrolytische Reduktion in Anwesenheit von rotem Quecksilberoxid die Darstellung von Strontiumamalgam, das er anschließend durch Destillation reinigte und so das – wenn auch noch verunreinigte – Metall erhielt. Er benannte es nach dem Strontianit analog zu den anderen Erdalkalimetallen "Strontium". Reines Strontium gewann Robert Bunsen 1855 durch Elektrolyse einer Strontiumchloridschmelze. Er bestimmte auch Eigenschaften des Metalls wie etwa die spezifische Dichte des Elements.

Strontium ist mit einem Anteil von 370 ppm an der kontinentalen Erdkruste auf der Erde verhältnismäßig häufig, die Elementhäufigkeit in der Erdkruste ist vergleichbar mit der von Barium, Schwefel oder Kohlenstoff. Auch im Meerwasser ist eine größere Menge Strontium vorhanden. Das Element kommt nicht gediegen, sondern stets in verschiedenen Verbindungen vor. Entsprechend den geringen Löslichkeiten sind die wichtigsten Strontiumminerale das Strontiumsulfat oder Coelestin mit einem Strontiumgehalt von bis zu 47,7 %. sowie das Strontiumcarbonat oder Strontianit mit einem Strontiumgehalt von bis zu 59,4 % Insgesamt sind bisher (Stand: 2011) rund 200 strontiumhaltige Minerale bekannt.

Die Lagerstätten des wichtigsten Strontiumminerals, Coelestin, entstanden durch Fällung des schwerlöslichen Strontiumsulfats aus Meerwasser. Auch eine hydrothermale Bildung des Minerals ist möglich. Strontianit bildet sich ebenfalls hydrothermal oder als Sekundärmineral aus Coelestin. Die wichtigsten Strontiumlagerstätten und Abbauorte liegen in Spanien, Mexiko, der Türkei, China und im Iran. Großbritannien war ebenfalls über lange Zeit ein wichtiger Förderstaat, die Produktion endete jedoch 1992. Dabei betrug die Förderung an Strontiummineralen im Jahr 2008 weltweit 496.000 Tonnen.

Ausgangsmaterial für die Herstellung von Strontium und Strontiumverbindungen ist meist Coelestin (Strontiumsulfat). Aus diesem wird in der Regel zunächst Strontiumcarbonat gewonnen. Dieses ist die industriell wichtigste Strontiumverbindung und Grundstoff für die Gewinnung des Metalls und anderer Verbindungen.

Um Strontiumcarbonat herzustellen, wird zunächst Strontiumsulfat mit Kohlenstoff bei 1100–1200 °C umgesetzt. Dabei wird das Sulfat zum Sulfid reduziert und es entstehen Strontiumsulfid und Kohlenstoffdioxid. Das Strontiumsulfid wird durch Extraktion mit heißem Wasser gereinigt.

Anschließend wird entweder Kohlenstoffdioxid durch die Strontiumsulfidlösung geleitet oder das Strontiumsulfid wird mit Natriumcarbonat umgesetzt. Dabei entstehen neben Strontiumcarbonat Schwefelwasserstoff beziehungsweise Natriumsulfid. Welche der beiden Varianten genutzt wird, hängt von der Verfügbarkeit der Ausgangsstoffe und der Möglichkeit, die Beiprodukte zu verkaufen, ab.

Feingemahlenes Strontiumsulfat kann auch direkt mit Natrium- oder Ammoniumcarbonat zu Strontiumcarbonat umgesetzt werden. Dabei sind jedoch aufwändige Reinigungsschritte notwendig.

Um Strontiummetall zu erhalten, wird Strontiumoxid mit Aluminium reduziert (Aluminothermie). Dabei entsteht neben elementarem Strontium eine Mischung aus Aluminium- und Strontiumoxid. Die Reaktion findet im Vakuum statt, da unter diesen Bedingungen das Strontium gasförmig vorliegt, einfach abgetrennt und in einem Kühler aufgefangen werden kann.

Strontium ist ein im höchstreinen Zustand hellgoldgelb-glänzendes, sonst silberweißes Erdalkalimetall. Mit einem Schmelzpunkt von 777 °C und einem Siedepunkt von 1380 °C steht es beim Siedepunkt zwischen dem leichteren Calcium und dem schwereren Barium, wobei Calcium einen höheren und Barium einen niedrigeren Schmelzpunkt besitzt. Strontium besitzt nach Magnesium und Radium den niedrigsten Siedepunkt aller Erdalkalimetalle. Mit einer Dichte von 2,6 g/cm zählt es zu den Leichtmetallen. Strontium ist mit einer Mohshärte von 1,5 sehr weich und lässt sich leicht biegen oder walzen.

Wie Calcium kristallisiert Strontium bei Raumtemperatur in einer kubisch-flächenzentrierten Kristallstruktur in der (Kupfer-Typ) mit dem Gitterparameter a = 608,5 pm sowie vier Formeleinheiten pro Elementarzelle. Daneben sind auch zwei weitere Hochtemperaturmodifikationen bekannt. Bei Temperaturen von größer 215 °C wandelt sich die Struktur in eine hexagonal-dichteste Kugelpackung (Magnesium-Typ) mit den Gitterparametern a = 432 pm und c = 706 pm um. Oberhalb von 605 °C ist schließlich eine kubisch-innenzentrierte Struktur (Wolfram-Typ) am stabilsten.

Strontium ist nach Barium und Radium das reaktivste Erdalkalimetall. Es reagiert direkt mit Halogenen, Sauerstoff, Stickstoff und Schwefel. Dabei bildet es immer Verbindungen, in denen es als zweiwertiges Kation vorliegt. Beim Erhitzen an der Luft verbrennt das Metall mit der typischen karminroten Flammenfärbung zu Strontiumoxid und Strontiumnitrid.

Als sehr unedles Metall reagiert Strontium mit Wasser unter Wasserstoff- und Hydroxidbildung. Strontiumhydroxid bildet sich auch schon beim Kontakt des Metalls mit feuchter Luft. Auch in Ammoniak ist Strontium löslich, dabei bilden sich blauschwarze Ammoniakate.

Im Grundwasser verhält sich Strontium meist ähnlich wie Calcium. Strontiumverbindungen sind unter schwach sauren bis basischen Bedingungen unlöslich. Erst bei niedrigerem pH-Werten tritt Strontium in gelöster Form auf. Kommt es infolge von Verwitterungsprozessen o. ä. zum Abbau von Kohlenstoffdioxid (CO) wird das Ausfällen von Strontium zusammen mit Calcium (als Strontium- bzw. Calciumcarbonat) verstärkt. Zusätzlich kann eine hohe Kationenaustauschkapazität des Bodens die Bindung von Strontium fördern.

Es sind insgesamt 34 Isotope und weitere neun Kernisomere bekannt. Von diesen kommen vier, Sr, Sr, Sr und Sr, natürlich vor. In der natürlichen Isotopenzusammensetzung überwiegt dabei das Isotop Sr mit einem Anteil von 82,58 %. Sr mit 9,86 % und Sr mit 7,0 %, sowie Sr mit einem Anteil von 0,56 % sind seltener.

Sr ist ein Betastrahler mit einer Zerfallsenergie von 0,546 MeV und zerfällt mit einer Halbwertzeit von 28,78 Jahren zu Y, das seinerseits rasch (t = 64,1 h) unter Aussendung von energiereicher Betastrahlung (ZE = 2,282 MeV) und von Gammastrahlung zum stabilen Zr zerfällt. Dabei tritt es zumeist als sekundäres Spaltprodukt auf. Es entsteht innerhalb weniger Minuten durch mehrfachen Betazerfall aus primären Spaltprodukten der Massenzahl 90, die bei 5,7 % aller Kernspaltungen von U in Kernkraftwerken und Atombombenexplosionen auftreten. Damit ist Sr eines der häufigsten Spaltprodukte überhaupt.

Größere Mengen Sr gelangen bei allen nuklearen Katastrophen in die Umwelt. Unfälle, bei denen Sr in die Umwelt gelangte, waren der Windscale-Brand, bei dem 0,07 TBq Sr freigesetzt wurden und die Katastrophe von Tschernobyl, bei der die freigesetzte Aktivität an Sr 800 TBq betrug. Nach den oberirdischen Kernwaffentests vor allem in den Jahren 1955–58 und 1961–63 stieg die Belastung der Atmosphäre mit Sr stark an. Dies führte zusammen mit der Belastung an Cs 1963 zur Verabschiedung des Vertrages über das Verbot von Kernwaffenversuchen in der Atmosphäre, im Weltraum und unter Wasser, der solche Tests in den Unterzeichnerstaaten verbot. Daraufhin sank in den folgenden Jahren die Belastung der Atmosphäre wieder deutlich. Die gesamte, durch Kernwaffen freigesetzte Aktivität an Sr betrug etwa 6 · 10 Bq (600 PBq).

Die Aufnahme von Sr, das etwa über belastete Milch in den Körper gelangen kann, ist gefährlich. Durch die energiereiche Betastrahlung des Isotops können Zellen in Knochen oder Knochenmark verändert und somit Knochentumore oder Leukämien ausgelöst werden. Eine Dekorporation des in die Knochen aufgenommenen Strontiums mit Chelatbildnern ist unmöglich, da diese bevorzugt Calcium komplexieren und das Strontium im Knochen verbleibt. Eine Dekorporation mit Bariumsulfat ist nur möglich, wenn sie rasch nach der Inkorporation erfolgt, bevor der Einbau in Knochen erfolgen kann. Auch der Abbau durch biologische Vorgänge verläuft nur sehr langsam, die biologische Halbwertszeit liegt in Knochen bei 49 Jahren, die effektive Halbwertszeit von Sr bei 18,1 Jahren. Möglicherweise bindet Sr an Zellen der Nebenschilddrüsen. Dies würde die Häufung von Fällen eines Hyperparathyreoidismus bei Liquidatoren des Reaktors in Tschernobyl erklären.

Die Betastrahlung von Sr und Y kann in Radionuklidbatterien, etwa für abgelegene Leuchttürme und Funkfeuer in der ehemaligen Sowjetunion, zur langlebigen Isotopenmarkierung, zur Dickenmessung von Materialien oder zum Kalibrieren von Geigerzählern genutzt werden.

Sr ist das Zerfallsprodukt des mit einer Halbwertszeit von 48 Milliarden Jahren sehr langlebigen Rubidiumisotops Rb. Aus dem Verhältnis der verschiedenen Strontiumisotope kann im Rahmen einer Strontiumisotopenanalyse daher das Alter von rubidium- und strontiumhaltigen Gesteinen wie Granit bestimmt werden.

Strontium wird unter verschiedenen Bedingungen in unterschiedlichen Mengen in Knochen und Zähnen eingelagert. Gleichzeitig hängt das Isotopenverhältnis von Sr und Sr von den Gesteinen der Umgebung ab. Daher kann man aus den Isotopenverhältnissen des Strontiums mitunter Rückschlüsse auf Wanderungsbewegungen von prähistorischen Menschen ziehen.

Der kleine deutsche Kugelhaufenreaktor namens "AVR" neben dem Gelände des Forschungszentrums in Jülich gilt nach Angabe des Betreibers als die am stärksten mit Sr kontaminierte Nuklearanlage weltweit. Auch im Boden unter dem Reaktor befindet sich Strontium. Dieses soll beim Rückbau des Reaktors bis 2017 aufwändig entfernt werden.

Strontium wird nur in geringen Mengen produziert und verwendet. Der größte Teil des produzierten Strontiumcarbonats wird für Kathodenstrahlröhren, Dauermagnete sowie die Pyrotechnik verwendet.

Metallisches Strontium wird vor allem in der Aluminiumindustrie (Aluminiumprimär- und Sekundärhütten, sowie Gießereien) ebenso wie Natrium als gefügebeeinflussendes Mittel bei Aluminium-Siliciumlegierungen mit 7–12 % Silicium eingesetzt. Geringe Beimengungen an Strontium verändern das Eutektikum in Silicium-Aluminium-Legierungen und verbessern so die mechanischen Eigenschaften der Legierung. Dies liegt daran, dass Aluminium-Silicium-Legierungen ohne Strontium am Eutektikum grobe, nadelförmige, mechanisch wenig belastbare Körner ausfallen, was durch das Strontium verhindert wird. Seine „veredelnde“ Wirkung hält in gießbereiten Schmelzen (Gieß- und Warmhalteöfen) länger an, als die des Natriums, da es weniger leicht oxidierbar ist. Auf dem Gebiet langsam erstarrender Schmelzen (Sandguss) hat es das Jahrzehnte allein gebräuchliche Natrium teilweise bereits verdrängt. Bei rascher Erstarrung in metallischer Dauerform, insbesondere bei Druckguss ist die Anwendung von Strontium nicht in jedem Fall zwingend, die Ausbildung des erwünschten feinen, „veredelten“ Gefüges wird bereits durch die rasche Erstarrung begünstigt.

Strontium wird Ferrosilicium zugesetzt, es reguliert die Struktur des Kohlenstoffs und verhindert beim Gießen ein ungleichmäßiges Erstarren.

Weiterhin kann Strontium als Gettermaterial in Elektronenröhren, zum Entfernen von Schwefel und Phosphor aus Stahl sowie zum Härten von Akku-Platten aus Blei genutzt werden.

Nur wenige Lebewesen nutzen Strontium in biologischen Prozessen. Hierzu zählen Acantharia, einzellige eukaryontische Lebewesen, die zu den Strahlentierchen gehören und ein häufiger Bestandteil des Zooplanktons im Meer sind. Diese nutzen als einzige Protisten Strontiumsulfat als Baumaterial für das Skelett. Dadurch bewirken sie auch Veränderungen des Strontiumgehaltes in einzelnen Meeresschichten, indem sie zunächst Strontium aufnehmen und nach dem Absterben in tiefere Schichten sinken, wo sie sich auflösen.

Strontium ist nicht essentiell, es sind nur wenige biologische Wirkungen des Elementes bekannt. So ist es möglich, dass Strontium hemmend gegenüber Karies wirkt.

Im Tierversuch bei Schweinen zeigten sich durch eine strontiumreiche und calciumarme Ernährung Symptome wie Koordinationsstörungen, Schwachheit und Lähmungserscheinungen.

Strontium hat in seinen Eigenschaften große Ähnlichkeit mit Calcium. Jedoch wird es im Gegensatz zu Calcium nur in geringen Mengen über den Darm aufgenommen. Verantwortlich hierfür ist möglicherweise der größere Ionenradius des Elementes. Der Gehalt an Strontium beträgt durchschnittlich bei einem 70 Kilogramm schweren Mann nur 0,32 g, im Vergleich dazu enthält der Körper etwa 1000 g Calcium. Das aufgenommene Strontium wird vor allem in den Knochen gespeichert.

Sr wird als Chlorid (unter dem Handelsnamen „Metastron“) zur Radionuklidtherapie von Knochenmetastasen verwendet. 

Strontiumranelat wird unter verschiedenen Handelsnamen als Medikament gegen Osteoporose angeboten.

Wie andere Erdalkalimetalle ist Strontium brennbar. Es reagiert mit Wasser oder Kohlenstoffdioxid, so dass diese nicht als Löschmittel verwendet werden können. Zum Löschen sollten Metallbrandlöscher (Klasse D) verwendet werden, zudem ist die Verwendung von trockenem Sand, Salz und Löschpulver möglich. Weiterhin bildet sich bei Kontakt mit Wasser Wasserstoff, der explosionsgefährlich ist. Für die Beseitigung kleiner Mengen kann Strontium mit Isopropanol, "tert"-Butanol oder Octanol umgesetzt werden.

Wie alle Erdalkalimetalle kommt Strontium in stabilen Verbindungen ausschließlich in der Oxidationsstufe +2 vor. Es handelt sich in der Regel um farblose, häufig gut wasserlösliche Salze.

Mit den Halogenen Fluor, Chlor, Brom und Iod bildet Strontium jeweils ein Halogenid mit der allgemeinen Formel SrX. Es sind typische, farblose und bis auf Strontiumfluorid gut wasserlösliche Salze. Sie können durch Umsetzung von Strontiumcarbonat mit Halogenwasserstoffsäuren wie Flusssäure oder Salzsäure dargestellt werden. Verwendung findet unter anderen Strontiumchlorid als Zwischenprodukt für die Herstellung anderer Strontiumverbindungen sowie in Zahnpasta, wo es gegen schmerzempfindliche Zähne wirken soll.

Industriell wichtig sind vor allem die Strontiumsalze von Sauerstoffsäuren wie Strontiumcarbonat, Strontiumnitrat, Strontiumsulfat oder Strontiumchromat. Strontiumcarbonat ist die wichtigste Handelsform von Strontiumverbindungen, der Großteil des abgebauten Coelestins wird zu Strontiumcarbonat umgesetzt. Verwendet wird es vor allem zur Herstellung von röntgenabsorbierendem Glas für Kathodenstrahlröhren, aber auch für die Herstellung von Strontiumferrit für Permanentmagnete oder Elektrokeramiken. Strontiumnitrat wird vorwiegend in der Pyrotechnik für die Strontium-typische rote Flammenfärbung eingesetzt, das gelbe Strontiumchromat dient als Grundierung gegen Korrosion von Aluminium im Flugzeug- oder Schiffbau.

Strontium(I)-Verbindungen wurden als instabile Zwischenstufen in heißen Flammen nachgewiesen. Dabei ist Strontium(I)hydroxid, SrOH, ähnlich wie Strontium(I)chlorid, SrCl, ein starker Emitter im roten Spektralbereich und fungiert als alleiniger Farbgeber in lichtstarken und tiefgesättigten roten pyrotechnischen Leuchtsätzen.

Organische Strontiumverbindungen sind nur in geringem Maße bekannt und untersucht, da sie sehr reaktiv sind und auch mit vielen Lösungsmitteln wie Ethern reagieren können. In unpolaren Lösungsmitteln sind sie dagegen unlöslich. Dargestellt wurde unter anderem ein Metallocen mit Pentamethylcyclopentadienyl-Anionen (Cp*), das in der Gasphase im Gegensatz zu anderen Metallocenen wie Ferrocen gewinkelt ist.

Eine Übersicht über Strontiumverbindungen gibt die .





</doc>
<doc id="4542" url="https://de.wikipedia.org/wiki?curid=4542" title="Scandium">
Scandium

Scandium (von lat. "Scandia" „Skandinavien“) ist ein chemisches Element mit dem Symbol Sc und der Ordnungszahl 21. Im Periodensystem steht es in der 3. Nebengruppe, bzw. der 3. IUPAC-Gruppe oder Scandiumgruppe. Das weiche, silberweiße Element ist das erste der Übergangsmetalle und wird auch den Metallen der Seltenen Erden zugerechnet.

Scandium wurde 1879 von Lars Fredrik Nilson entdeckt. Aus 10 kg Euxenit und Gadolinit isolierte er ein Oxid mit bisher unbekannten Eigenschaften. Das von ihm vermutete neue Element nannte er zu Ehren seiner Heimat „Scandium“. Schon 1869 sagte Dmitri Iwanowitsch Mendelejew ein Element Eka-Bor mit der Ordnungszahl 21 voraus. Erst Per Teodor Cleve erkannte später die Übereinstimmung des Scandiums mit dem Eka-Bor.

Reines Scandium wurde erstmals 1937 elektrolytisch aus einer eutektischen Schmelze aus Kalium-, Lithium- und Scandiumchlorid bei 700 bis 800 °C hergestellt.

2003 gab es weltweit nur drei Minenproduktionsstätten: Bayan-Obo-Mine (Volksrepublik China), Schowti Wody (Ukraine) und auf der Halbinsel Kola (Russland).

Scandium gehört zu den seltenen Elementen. Elementar kommt es nicht vor, nur in einigen seltenen Mineralen findet man es in angereicherter Form. Scandium als Hauptbestandteil enthalten nur fünf Minerale:


Daneben sind bisher (Stand 2013) noch 14 weitere Minerale bekannt, bei denen Scandium in geringeren Anteilen in der chemischen Formel vertreten sind wie unter anderem Jervisit, Bazzit, Juonniit, Cascandit, Davisit und Scandiobabingtonit.

Als Beimengung in geringer Konzentration findet sich Scandium in einigen hundert Mineralen, wobei einige Quellen mehr als 800 Mineralien angeben. Es ist daher auch in Erzkonzentraten der Übergangsmetalle als „Verunreinigung“ enthalten. Hierzu zählen russische und chinesische Wolframit- und Tantalitkonzentrate. Auch bei der Aufbereitung uranhaltiger Erze fallen Scandiumverbindungen an.<ref name="DOI10.1007/BF00643336">H. A. Das, J. Zonderhuis, H. W. Marel: "Scandium in rocks, minerals and sediments and its relations to iron and aluminium." In: "Contributions to Mineralogy and Petrology." 32, 1971, S. 231–244, .</ref>
Minen befinden sich unter anderem in Schowti Wody in der Ukraine.

Als Ausgangsstoff dient hauptsächlich Thortveitit, das in mehreren Verfahrensschritten zum Scandiumoxid aufbereitet wird. Metallisches Scandium wird anschließend durch Umsetzung zum Fluorid und Reduktion mit Calcium erzeugt.

Laut USGS wird die Jahresproduktion auf 10 bis 15 t geschätzt.

Aufgrund seiner Dichte zählt Scandium zu den Leichtmetallen. An Luft wird es matt, es bildet sich eine schützende gelbliche Oxidschicht.
Scandium reagiert mit verdünnten Säuren unter Bildung von Wasserstoff und dreiwertigen Kationen. In Wasserdampf erfolgt ab 600 °C die Umsetzung zu Scandiumoxid ScO. In wässrigen Lösungen verhalten sich Sc-Kationen ähnlich wie Aluminium, was bei analytischen Trennungen oftmals Schwierigkeiten bereitet.
In einer Mischung aus Salpetersäure und 48 % Fluorwasserstoff soll es beständig sein.

Seine Hauptanwendung findet Scandium als Scandiumiodid in Hochleistungs-Hochdruck-Quecksilberdampflampen, beispielsweise zur Stadionbeleuchtung. Zusammen mit Holmium und Dysprosium entsteht ein dem Tageslicht ähnliches Licht. Scandium wird auch zur Herstellung von Laserkristallen verwendet. Magnetischen Datenspeichern wird Scandiumoxid zur Erhöhung der Ummagnetisierungsgeschwindigkeit zugesetzt. Scandium als Scandiumchlorid wird in Mikromengen als ein sehr wichtiger Bestandteil im Katalysator bei der Chlorwasserstoffherstellung eingesetzt, Forscher des Max-Planck-Instituts für Kohlenforschung nutzten es zudem zur Herstellung eines Katalysators zur Be- und Entladung von Metall-hydridspeichern für Wasserstoff, der neben dem Scandiumchlorid ScCl unter anderem noch Natriumhydrid und Aluminium enthielt. Später wurden jedoch titanenthaltende Katalysatoren verwendet.

Als Legierungszusatz zeigt Scandium gefügestabilisierende und korngrößenfeinende Effekte. Eine Aluminium-Lithium-Legierung mit geringem Scandiumzusatz wird zur Herstellung einiger Bauteile in russischen Kampfflugzeugen verwendet. Auch in der modernen Fahrradindustrie (siehe Rennrad) werden Scandiumlegierungen eingesetzt. Diese Legierungen enthalten ebenfalls nur relativ wenig Scandium. Ende der 1990er Jahre wurde vom Revolverhersteller Smith & Wesson das Revolver-Modell 360PD herausgebracht. Der aus einer Scandium-Aluminium-Legierung bestehende hochwertige Rahmen ermöglicht eine deutliche Gewichtsreduktion, und es können aus dieser Waffe trotzdem starke Ladungen verschossen werden (.357 Magnum bzw. .38 Special +P).

Scandiumpulver ist brennbar und daher als feuergefährlich einzustufen. Es kann durch kurzzeitige Einwirkung einer Zündquelle leicht entzündet werden und brennt nach deren Entfernung weiter. Die Entzündungsgefahr ist umso größer, je feiner der Stoff verteilt ist.



</doc>
<doc id="4543" url="https://de.wikipedia.org/wiki?curid=4543" title="Sauerstoff">
Sauerstoff

Sauerstoff (auch "Oxygenium" genannt; von ‚oxys‘ „scharf, spitz, sauer“ und γεννάω ‚gen-‘ „erzeugen, gebären“, zusammen „Säure-Erzeuger“) ist ein chemisches Element mit dem Elementsymbol O. Entsprechend seiner Ordnungszahl 8 steht es an achter Stelle im Periodensystem und dort zusammen mit den Elementen Schwefel, Selen, Tellur, Polonium und Livermorium, die die Chalkogene bilden, in der sechsten Hauptgruppe, bzw. 16. IUPAC-Gruppe. Sauerstoff ist bezüglich seines Gewichts mit 48,9 % das häufigste Element der Erdkruste, das häufigste Element der Erdhülle und mit rund 30 % das zweithäufigste Element der Erde insgesamt (Eisen ist an 1. Stelle).

Ältere Bezeichnungen für Sauerstoff sind Oxygenium, Lebensluft, Feuerluft und dephlogistisierte Luft.

Unter Normalbedingung tritt Sauerstoff in Form eines kovalenten Homodimers auf, also einer Verbindung aus zwei Sauerstoff-Atomen und mit der Summenformel O, bezeichnet als "molekularer Sauerstoff", "Dioxygen" oder "Disauerstoff". Es ist ein farb- und geruchloses Gas, das in der Luft zu 20,942 % enthalten ist. Es ist an vielen Verbrennungs- und Korrosionsvorgängen beteiligt. Fast alle Lebewesen benötigen Sauerstoff zum Leben (in der Regel geben Pflanzen aber während der Photosynthese mehr Sauerstoff ab, als sie verbrauchen). Sie entnehmen ihn meistens durch Atmung aus der Luft oder durch Resorption aus Wasser (gelöster Sauerstoff). In hohen Konzentrationen dagegen ist er für die meisten Lebewesen giftig.

Die metastabile, energiereiche und reaktive allotrope Form aus drei Sauerstoffatomen (O) wird Ozon genannt.

"Atomarer Sauerstoff", das heißt Sauerstoff in Form freier, einzelner Sauerstoffatome, kommt stabil nur unter extremen Bedingungen vor, beispielsweise im Vakuum des Weltalls oder in heißen Sternatmosphären. Er hat jedoch eine wesentliche Bedeutung als reaktives Zwischenprodukt in vielen Reaktionen der Atmosphärenchemie.

Carl Wilhelm Scheele im Jahre 1771 (veröffentlicht aber erst 1777) und Joseph Priestley im Jahre 1774 haben unabhängig voneinander im Zusammenhang mit der Erforschung von Verbrennungsvorgängen den Sauerstoff entdeckt. Der Entdeckung sehr nahe kam auch Pierre Bayen 1774.

Von der Steinzeit bis über das Mittelalter hinaus war das Feuer für den Menschen eine Erscheinung, die als Gabe des Himmels hingenommen wurde. Über das Wesen des Feuers entstanden verschiedene Vorstellungen durch die Naturphilosophen der Antike bis zu den Alchimisten. Das Feuer wurde als ein Grundstoff der Vier-Elemente-Lehre verstanden. Im 17. Jahrhundert entstand die Vorstellung eines „leichten geheimnisvollen Stoffs“. Dieses Phlogiston würde aus dem brennenden Stoff entweichen, Wärme wurde als Stoff verstanden. Der deutsch-schwedische Apotheker Carl Wilhelm Scheele stellte Versuche an. Beim Erhitzen von Braunstein (Mangandioxid) oder Kaliumpermanganat mit konzentrierter Schwefelsäure ("Vitriol") erhielt er ein farbloses Gas. Dieses Gas förderte die Verbrennung und Scheele nannte es „Feuerluft“ oder nach der Herkunft „Vitriolluft“. Er fand, dass Luft aus diesem Sauerstoff und „verdorbener Luft“ besteht. Gänzlich unabhängig konnte der Engländer Joseph Priestley zwei Jahre später durch Erhitzen von Quecksilberoxid Sauerstoffgas herstellen. Der Brite veröffentlichte seine Erkenntnisse im Jahr 1774, Scheele publizierte sein Buch "Chemische Abhandlung von der Luft und dem Feuer" allerdings erst 1777.

Mit der Entdeckung des Sauerstoffs war seine Bedeutung bei der Verbrennung noch nicht geklärt. Der Franzose Antoine Lavoisier fand bei seinen Experimenten, dass bei der Verbrennung nicht Phlogiston entweicht, sondern Sauerstoff gebunden wird. Durch Wägung wies er nach, dass ein Stoff nach der Verbrennung nicht leichter, sondern schwerer war. Ursache war das zusätzliche Gewicht des während des Verbrennungsprozesses aufgenommenen Sauerstoffs. Anfangs wurde der Sauerstoff als Grundbestandteil für die Bildung von Säuren angenommen. Deshalb wurde die Bezeichnung "Oxygenium" ("Säurebildner") 1779 von Lavoisier für Sauerstoff vorgeschlagen. Tatsächlich enthalten die meisten anorganischen Säuren bei der Lösung von Nichtmetalloxiden in Wasser Sauerstoff. Die Halogene, wie Chlor und Brom, hielt man daher lange Zeit für Oxide unbekannter Elemente. Erst später wurde erkannt, dass Wasserstoff für den Säurecharakter verantwortlich ist (Humphry Davy, ab 1808). 1883 gelang es Karol Olszewski und Zygmunt Wróblewski erstmals, Flüssigsauerstoff herzustellen.

Sauerstoff ist das häufigste und am weitesten verbreitete Element auf der Erde. Es kommt sowohl in der Erdatmosphäre als auch in der Lithosphäre, der Hydrosphäre und der Biosphäre vor. Sauerstoff hat einen Massenanteil von 50,5 % an der Erdhülle (bis 16 km Tiefe, einschließlich Hydro- und Atmosphäre). An der Luft beträgt sein Massenanteil 23,16 % (Volumenanteil: 20,95 %), am Wasser 88,8 % (am Meerwasser allerdings nur 86 %, da dort größere Mengen nichtsauerstoffhaltiger Salze, z. B. Natriumchlorid, gelöst sind).

Zumeist kommt Sauerstoff in seinen Verbindungen auf und in der Erde vor. In der Erdhülle sind neben Wasser fast alle Minerale und damit Gesteine sauerstoffhaltig. Zu den wichtigsten Sauerstoff enthaltenden Mineralen zählen Silicate wie Feldspäte, Glimmer und Olivine, Carbonate wie das Calciumcarbonat im Kalkstein sowie Oxide wie Siliciumdioxid als Quarz.

In elementarem Zustand befindet sich Sauerstoff in Form von O gasförmig in der Atmosphäre und gelöst in Gewässern. Die Menge des relativ reaktionsfreudigen elementaren Sauerstoffs bleibt auf Dauer nur konstant, weil Sauerstoff produzierende Pflanzen so viel nachliefern, wie von aerob atmenden Lebewesen sowie durch andere Verbrennungsprozesse wieder verbraucht wird. Ohne diesen biologischen Kreislauf würde Sauerstoff nur in Verbindungen vorkommen, elementarer Sauerstoff existiert also in einem Fließgleichgewicht. Die Entwicklung der Sauerstoffkonzentration in der Erdatmosphäre ist im Artikel Entwicklung der Erdatmosphäre beschrieben. Das Sauerstoff-Allotrop O Ozon ist in der Atmosphäre nur in geringer Konzentration vorhanden.

Im Weltall ist Sauerstoff nach Wasserstoff und Helium das dritthäufigste Element. Der Massenanteil von Sauerstoff beträgt im Sonnensystem etwa 0,8 % (dies entspricht einem (Atom-)Anzahlanteil von etwa 500 ppm).

Sauerstoff ist "nicht" in der primordialen Nukleosynthese entstanden, entsteht aber in verhältnismäßig großen Mengen in Riesensternen durch Heliumbrennen. Dabei wird zunächst aus drei Heliumkernen C gebildet (Drei-Alpha-Prozess), das anschließend mit einem weiteren Heliumkern zu O fusioniert. O wird durch Fusion eines He- mit einem N-Kern gebildet. Auch in so genannten Hauptreihensternen wie der Sonne spielt Sauerstoff bei der Energiegewinnung eine Rolle. Beim CNO-Zyklus (Bethe-Weizsäcker-Zyklus) stellt Sauerstoff ein Zwischenprodukt der Kernreaktion dar, bei der durch Protoneneinfang eines C-Kerns, der als Katalysator wirkt, ein He-Kern (Alpha-Teilchen) entsteht. In extrem schweren Sternen kommt es in der Spätphase ihrer Entwicklung zum Sauerstoffbrennen, bei dem der Sauerstoff als nuklearer Brennstoff für Reaktionen dient, die zum Aufbau noch schwererer Kerne führen.

Die meisten Weißen Zwerge, die nach Stand der Theorie den Endzustand von 97 % aller Sterne darstellen, bestehen neben Helium und Kohlenstoff zu einem großen Teil aus Sauerstoff.

Technisch wird Sauerstoff heute fast ausschließlich durch Rektifikation von Luft gewonnen. Das Verfahren wurde 1902 zunächst von Carl von Linde entwickelt (Linde-Verfahren) und von Georges Claude wirtschaftlich rentabel gestaltet. Geringe Mengen ergeben sich als Nebenprodukt bei der Wasserstoffproduktion durch Elektrolyse von Wasser.

Zur Sauerstoffgewinnung nach dem Claude-Verfahren wird Luft mit Hilfe von Verdichtern auf 5–6 bar verdichtet, abgekühlt und dann zunächst durch Filter von Kohlenstoffdioxid, Luftfeuchtigkeit und anderen Gasen befreit. Die verdichtete Luft wird durch vorbeiströmende Gase aus dem Prozess auf eine Temperatur nahe dem Siedepunkt abgekühlt. Danach wird sie in Turbinen expandiert. Dabei kann ein Teil der zur Kompression eingesetzten Energie wieder zurückgewonnen werden. Dadurch wird das Verfahren – im Gegensatz zum Linde-Verfahren, bei dem keine Energie zurückgewonnen wird – deutlich wirtschaftlicher.

Die eigentliche Trennung von Stickstoff und Sauerstoff erfolgt durch Destillation in zwei Rektifikationskolonnen mit unterschiedlichen Drücken. Die Destillation erfolgt dabei im Gegenstromprinzip, das heißt durch die Kondensationswärme verdampftes Gas strömt nach oben, kondensierte Flüssigkeit tropft nach unten. Da Sauerstoff einen höheren Siedepunkt als Stickstoff besitzt, kondensiert er leichter und sammelt sich so am Boden, Stickstoff am Kopf der Kolonne. Die Trennung erfolgt zunächst bei 5–6 bar in der sogenannten Mitteldruckkolonne. Die dabei entstehende sauerstoffangereicherte Flüssigkeit wird anschließend in der Niederdruckkolonne (Druck etwa 0,5 bar) weiter getrennt. Durch den flüssigen Sauerstoff der Niederdruckkolonne wird gasförmiger Stickstoff der Hochdruckkolonne geleitet. Dabei verflüssigt sich dieser und erwärmt mit der abgegebenen Kondensationswärme die Flüssigkeit. Der leichter flüchtige Stickstoff wird bevorzugt abgegeben und es bleibt gereinigter flüssiger Sauerstoff zurück. Dieser enthält noch die Edelgase Krypton und Xenon, die in einer separaten Kolonne abgetrennt werden.

Um kleinere Mengen Sauerstoff zu produzieren, kann Sauerstoff aus der Luft durch Adsorption von anderen Gasen getrennt werden. Dazu strömt Luft durch Molekularsiebe. Dabei werden Stickstoff und Kohlenstoffdioxid adsorbiert und nur Sauerstoff und Argon gelangen hindurch. Dies wird im überwiegend medizinisch verwendeten Sauerstoffkonzentrator genutzt.

Ein älteres Verfahren ist das auf chemischen Reaktionen beruhende Bariumoxid-Verfahren. Es ist infolge des hohen Energieaufwandes unwirtschaftlich. Dafür wird Bariumoxid unter Luftzufuhr auf 500 °C erhitzt, wobei sich Bariumperoxid bildet. Beim Erhitzen auf 700 °C wird der zuvor aufgenommene Sauerstoff durch Thermolyse wieder freigesetzt. Vor Entwicklung des Linde-Verfahrens war dieses Verfahren die einzige Möglichkeit, reinen Sauerstoff darzustellen.

Einige sauerstoffreiche anorganische Verbindungen wie Kaliumpermanganat, Kaliumnitrat (Salpeter), Kaliumchlorat und Kaliumchromat geben bei Erwärmung oder Reaktion mit Reduktionsmitteln Sauerstoff ab.

Eine weitere Möglichkeit, Sauerstoff im Labor zu erzeugen, ist die Zersetzung von Wasserstoffperoxid an platinierter Nickelfolie.

Reinen Sauerstoff kann man mittels Elektrolyse von 30%iger Kalilauge an Nickelelektroden erhalten. Dabei entstehen Wasserstoff und Sauerstoff getrennt voneinander.

Molekularer Sauerstoff ist ein farb-, geruch- und geschmackloses Gas, welches bei 90,15 K (−183 °C) zu einer bläulichen Flüssigkeit kondensiert. In dicken Schichten zeigt gasförmiger und flüssiger Sauerstoff eine blaue Farbe. Unterhalb von 54,4 K (−218,75 °C) erstarrt Sauerstoff zu blauen Kristallen. Im Feststoff liegen paramagnetische O-Moleküle mit einem O–O-Abstand von 121 pm (Doppelbindung) vor. Das Element kommt fest in mehreren Modifikationen vor. Zwischen 54,4 K und 43,8 K liegt Sauerstoff in der kubischen γ-Modifikation und zwischen 43,8 K und 23,9 K in einer rhomboedrischen β-Modifikation vor. Unterhalb von 23,9 K ist schließlich die monokline α-Modifikation am stabilsten. Es ist – im Gegensatz zu anderen Nichtmetallen – paramagnetisch und besitzt diradikalischen Charakter. Der Tripelpunkt liegt bei 54,36 K (−218,79 °C) und 0,1480 kPa.
Der kritische Punkt liegt bei einem Druck von 50,4 bar und einer Temperatur von 154,7 K (−118,4 °C). Die kritische Dichte beträgt 0,436 g/cm. Die Dichte als Flüssigkeit bei Normaldruck beträgt 1,142 g/cm.

Sauerstoff ist in Wasser wenig löslich. Die Löslichkeit ist abhängig vom Druck und der Temperatur. Sie steigt mit abnehmender Temperatur und zunehmendem Druck. Bei 0 °C lösen sich aus Luft unter Normaldruck (Sauerstoffpartialdruck von 212 hPa) im Gleichgewicht 14,16 mg/l Sauerstoff.
In der Sauerstoff-Gasentladungs-Spektralröhre werden die Molekülorbitale des Sauerstoffs zum Leuchten angeregt. Die Betriebsbedingungen sind dabei ein Druck von ca. 5–10 mBar, eine Hochspannung von 1,8 kV, eine Stromstärke von 18 mA und eine Frequenz von 35 kHz. Bei der Rekombination der ionisierten Gasmoleküle wird das charakteristische Farbspektrum abgestrahlt. Hierbei wird zum kleinen Teil, bedingt durch die Zuführung von Energie, reversibel Ozon gebildet.

Die Bindung und die Eigenschaften des Sauerstoff-Moleküls können sehr gut mit dem Molekülorbital-Modell erklärt werden. Dabei werden die s- und p-Atomorbitale der einzelnen Atome zu bindenden und antibindenden Molekülorbitalen zusammengesetzt. Die 1s- und 2s-Orbitale der Sauerstoffatome werden jeweils zu σ und σ*- bindenden und antibindenden Molekülorbitalen. Da diese Orbitale vollständig mit Elektronen gefüllt sind, tragen sie nicht zur Bindung bei. Aus den 2p-Orbitalen werden insgesamt sechs Molekülorbitale mit unterschiedlichem Energieniveau. Dies sind die bindenden σ-, π- und π-, sowie die entsprechenden antibindenden σ*-, π*- und π*-Molekülorbitale.

Die π-Orbitale besitzen dabei gleiche Energie. Werden Elektronen in die Molekülorbitale verteilt, kommt es zur folgenden Aufteilung der acht p-Elektronen: sechs füllen die bindenden und zwei in die antibindenden π*-Orbitale; die Bindungsordnung beträgt also (6–2)/2 = 2. Diese beiden bestimmen als Valenzelektronen die Eigenschaften des O-Moleküls. Sauerstoff besitzt für die Verteilung dieser Elektronen insgesamt drei erlaubte und energetisch erreichbare quantenmechanische Zustände.
Im Grundzustand sind die Spins der beiden Valenzelektronen der Hundschen Regel gehorchend parallel angeordnet. Es handelt sich also um einen Triplett-Zustand mit dem Termsymbol Σ. Er ist der Zustand mit der niedrigsten Energie. Durch die beiden ungepaarten Elektronen sind die zwei π*-Orbitale nur halb besetzt. Diese verursacht einige charakteristische Eigenschaften, wie den diradikalischen Charakter und den Paramagnetismus des Sauerstoff-Moleküls.

Trotz der formalen Bindungsordnung „zwei“ lässt sich keine entsprechende korrekte Valenzstrichformel für O angeben.  <O=O> bringt den Doppelbindungscharakter zum Ausdruck, ignoriert aber sowohl die besetzten antibindenden Orbitale als auch den Radikalcharakter. Die Schreibweise  ·O̲̅-O̲̅· wird verwendet, um die biradikalischen Eigenschaften hervorzuheben, deutet jedoch nur eine Bindungsordnung von eins an. Um die Bindungsordnung zwei und den radikalischen Charakter anzudeuten, sollte die Darstellung <O÷O> mit Radikalpunkten auf dem Bindungsstrich verwendet werden.

Sauerstoff besitzt zwei unterschiedliche angeregte Zustände, die beide eine deutlich größere Energie als der Grundzustand besitzen. Bei beiden Zuständen sind die Spins der Elektronen entgegen der Hundschen Regel antiparallel ausgerichtet. Der stabilere angeregte Sauerstoff wird nach der quantenmechanischen Bezeichnung für diesen Zustand auch Singulett-Sauerstoff (O) genannt. Die beiden Singulett-Zustände unterscheiden sich dadurch, ob sich die beiden Elektronen in einem (Termsymbol: Δ) oder beiden π*-Orbitalen (Termsymbol: Σ) befinden. Der Σ-Zustand ist energetisch ungünstiger und wandelt sich sehr schnell in den Δ-Zustand um. Der Σ-Zustand ist diamagnetisch, der energetisch stabilere Δ-Zustand zeigt jedoch aufgrund des vorhandenen Bahnmomentes (die der Projektion des Bahndrehimpulses auf die Kern-Kern-Verbindungsachse entsprechende Quantenzahl – symbolisiert durch Σ, Π, Δ etc. – hat im Δ-Zustand den Wert ±2) Paramagnetismus vergleichbarer Stärke wie der von Triplett-Sauerstoff.

Die Bildung von Singulett-Sauerstoff ist auf verschiedenen Wegen möglich: sowohl photochemisch aus Triplett-Sauerstoff, als auch chemisch aus anderen Sauerstoffverbindungen. Eine direkte Gewinnung aus Triplett-Sauerstoff durch Bestrahlung mit elektromagnetischer Strahlung (z. B. Licht) ist allerdings aus quantenmechanischen Gründen, in Form der Auswahlregeln für die Emission oder Absorption von elektromagnetischer Strahlung, ausgeschlossen. Eine Möglichkeit, dieses Verbot zu umgehen, ist die gleichzeitige Bestrahlung mit Photonen und Kollision zweier Moleküle. Durch diesen unwahrscheinlichen Vorgang, der in der flüssigen Phase wahrscheinlicher ist, entsteht die blaue Farbe des flüssigen Sauerstoffs (Absorption im roten Spektralbereich). Auch mit Hilfe geeigneter Farbstoffe, wie Methylenblau oder Eosin, lässt sich auf photochemischem Weg Singulett-Sauerstoff darstellen. Chemisch wird er aus Peroxiden gewonnen. Bei der Umsetzung von Wasserstoffperoxid mit Natriumhypochlorit entsteht zunächst die instabile Peroxohypochlorige Säure, die schnell in Chlorwasserstoff bzw. Natriumchlorid und Singulett-Sauerstoff zerfällt. Experimentell kann man auch Chlor in eine alkalische Wasserstoffperoxidlösung einleiten, wobei dann zunächst Hypochlorit entsteht, das dann weiter reagiert. Der Singulett-Sauerstoff reagiert schnell mit Emissionen im roten Bereich bei 633,4 nm und 703,2 nm zu Triplett-Sauerstoff.

Diese Form von Sauerstoff ist ein starkes und selektives Oxidationsmittel und wird in der organischen Chemie häufig verwendet. So reagiert er im Gegensatz zu normalen Sauerstoff mit 1,3-Dienen in einer <nowiki>[4+2]</nowiki>-Cycloaddition zu Peroxiden. Mit Alkenen und Alkinen reagiert Singulett-Sauerstoff in einer <nowiki>[2+2]</nowiki>-Cycloaddition.

Sauerstoff reagiert mit den meisten anderen Elementen direkt. Es gibt einige Ausnahmen, insbesondere unter den Nichtmetallen und Edelmetallen. Mit Stickstoff sind Reaktionen nur unter speziellen Bedingungen, etwa bei Blitzen, aber auch im Verbrennungsmotor möglich. Fluor bildet nur bei tiefen Temperaturen unter elektrischen Entladungen die Verbindung Disauerstoffdifluorid (OF). Das edelste Metall Gold, die Halogene Chlor, Brom und Iod, sowie die Edelgase reagieren nicht direkt mit Sauerstoff. Einige weitere Edelmetalle wie Platin und Silber reagieren nur schlecht mit Sauerstoff.

Elementarer, gasförmiger Sauerstoff ist relativ reaktionsträge, viele Reaktionen finden bei Normalbedingungen gar nicht oder nur langsam statt. Der Grund hierfür liegt darin, dass die Reaktionen mit anderen Stoffen kinetisch gehemmt sind. Zur Reaktion werden entweder eine hohe Aktivierungsenergie oder sehr reaktive Radikale benötigt. Diese Barriere kann durch Temperaturerhöhung, Licht oder Katalysatoren (beispielsweise Platin) überschritten werden. Zusätzlich wird bei vielen Metallen die Reaktion dadurch gehindert, dass das Material mit einer dünnen Metalloxidschicht überzogen ist und dadurch passiviert wird. Bei einigen Reaktionen wie der Knallgasreaktion reichen wenige Radikale für eine Reaktion aus, da diese nach einem Kettenreaktions-Mechanismus weiterreagieren. Deutlich stärker oxidierend als gasförmiger Sauerstoff wirkt trotz der tiefen Temperaturen flüssiger Sauerstoff. In diesem bildet sich der reaktive Singulett-Sauerstoff leicht. Auch in Gegenwart von Wasser oder Wasserdampf verlaufen viele Oxidationen mit Sauerstoff leichter.

Reaktionen mit Sauerstoff sind fast immer Redox-Reaktionen, bei denen Sauerstoff in der Regel zwei Elektronen aufnimmt und so zum Oxid reduziert wird. Das Element zählt somit zu den Oxidationsmitteln. Häufig verlaufen diese Reaktionen bedingt durch die große freiwerdende Bindungs- oder Gitterenergie unter starker Wärmeabgabe. Es gibt auch explosionsartig verlaufende Reaktionen, wie die Knallgasreaktion oder Staubexplosionen von feinverteilten Stoffen in Luft oder reinem Sauerstoff.

Neben dem in diesem Artikel beschriebenen Disauerstoff O bildet Sauerstoff mehrere Allotrope, die nach der Anzahl Sauerstoffatome zu unterscheiden sind. Das wichtigste Allotrop ist dabei Ozon O, daneben sind die selteneren Allotrope Tetrasauerstoff (O) und Oktasauerstoff (O) bekannt.

Ozon (O) ist ein blaues, charakteristisch riechendes Gas, das aus drei Sauerstoff-Atomen besteht. Es ist instabil, sehr reaktiv und ein starkes Oxidationsmittel. Gebildet wird es aus molekularem Sauerstoff und Sauerstoff-Atomen, aber auch z. B. durch Reaktion von Stickstoffdioxid mit Sauerstoff unter UV-Strahlung.

Aufgrund seiner hohen Reaktivität ist es in Bodennähe der menschlichen Gesundheit eher abträglich – in der Ozonschicht der Erdatmosphäre dagegen spielt das Ozon eine wichtige Rolle bei der Absorption der auf die Erde treffenden UV-Strahlung.

Eine Hochdruckphase des Sauerstoffs entsteht bei Drücken größer 10 GPa als roter Feststoff. Nach kristallographischen Untersuchungen wird angenommen, dass es sich um Oktasauerstoff O-Ringe handelt. Daneben existiert Tetrasauerstoff als ein sehr seltenes und instabiles Allotrop des Sauerstoffs. Es konnte 2001 im Massenspektrometer nachgewiesen werden. In geringer Konzentration kommt es in flüssigem Sauerstoff vor.

Das häufigste stabile Sauerstoffisotop ist O (99,76 %), daneben kommt noch O (0,20 %) sowie O (0,037 %) vor. Neben den stabilen Sauerstoffisotopen sind noch insgesamt 13 instabile, radioaktive Nuklide von O bis O bekannt, die nur künstlich herstellbar sind. Ihre Halbwertszeiten betragen meist nur Millisekunden bis Sekunden, O besitzt dabei mit zwei Minuten die längste Halbwertszeit und wird häufig in der Positronen-Emissions-Tomographie verwendet.

Als einziges stabiles Isotop besitzt das seltene O einen Kernspin von / und kann damit für NMR-Untersuchungen verwendet werden. Die anderen stabilen Isotope besitzen den Kernspin 0 und sind damit NMR-inaktiv.

Wassermoleküle mit dem um 12 % leichteren O verdunsten schneller. Deshalb müssen Eisschichten mit einem höheren relativen Anteil an O aus wärmeren Zeiten stammen, da nur bei der starken Verdunstung wärmerer Perioden vermehrt O mit zur Wolkenbildung beitragen. Je höher die globale Temperatur ist, desto weiter können mit schweren Sauerstoffisotopen beladene Wolken in die Polarregionen vordringen, ohne vorher abzuregnen.

In kälteren Perioden befindet sich mehr O in Meeressedimenten. Meereis besteht hauptsächlich aus den leichteren Wassermolekülen aus O. Wenn es in einer Kaltphase zu einer starken Neubildung von Meereis kommt, bleibt vermehrt Meerwasser aus O zurück, welches durch die permanente Einlagerung von Sauerstoff in die Kalkschalen der Meerestiere (Calciumcarbonat) verstärkt in Sedimentschichten dieser Zeit nachweisbar ist. Auch gibt es regionale Unterschiede in der O-Anreicherung in Organismen nach Art ihrer Trinkwasserquelle.

Durch eine Isotopenuntersuchung von Eisbohrkernen oder Sedimentproben und die Bestimmung des O-/O-Verhältnisses mit Hilfe eines Massenspektrometers lassen sich Informationen über die Durchschnittstemperatur und damit die Klimaerwärmung und -abkühlung in früheren Zeiten gewinnen.
Daneben kann durch Bestimmung der Zahl der Oszillationen zwischen warm (Sommer) und kalt (Winter) das Alter des Bohrkerns exakt bestimmt werden.

Sauerstoff wird für industrielle Verbrennungs-, Oxidations- und Heizprozesse, in der Medizin und in Luft- und Raumfahrt verwendet.

Sauerstoff zur Anwendung in der Humanmedizin unterliegt aufgrund gesetzlicher Regelungen einer strengen Kontrolle. Der in weiß gekennzeichneten Flaschen abgefüllte medizinische Sauerstoff gilt in Deutschland als Fertigarzneimittel im Sinne des Arzneimittelgesetzes (AMG).

Vorsicht ist bei der Sauerstoffgabe geboten, wenn Patienten an einer chronischen Lungenerkrankung (siehe COPD) mit erhöhtem CO-Partialdruck leiden. Bei ihnen kann das plötzliche „Überangebot“ an Sauerstoff zu einer CO-Narkose mit Atemstillstand führen.

Verletzungen und viele Erkrankungen der Lunge sowie einige Herzkrankheiten und insbesondere Schockzustände können zu einem Sauerstoffmangel (Hypoxie) in den Schlagadern (Arterien) und im Gewebe lebenswichtiger Organe führen. Aus diesem Grund wird Patienten in der Notfall- und Intensivmedizin sehr häufig zusätzlicher Sauerstoff verabreicht. Bei selbstständig atmenden Patienten wird die Umgebungsluft mit Hilfe verschiedener Sonden und Masken mit Sauerstoff angereichert, bei künstlich beatmeten Patienten wird der Sauerstoff im Beatmungsgerät zugemischt. Der Effekt der Sauerstoffanreicherung im Blut ist mit Hilfe der Pulsoxymetrie oder anhand von Blutgasanalysen messbar.

Bei Krankheiten mit einem schweren chronischen Sauerstoffmangel im Blut werden durch eine langfristige und täglich mehrstündige Zufuhr von Sauerstoff (Sauerstoff-Langzeittherapie) sowohl die Lebensqualität als auch die Überlebensdauer verbessert. Der reine Sauerstoff kann bei der Beatmung zu Problemen wegen Verdrängens des Kohlenstoffdioxid aus den Gefäßen sowie zur unerwünschten Erhöhung der Hirnaktivität in Hypothalamus, der Insula sowie im Hippocampus führen. Diese negativen Folgen werden durch den Zusatz von Kohlenstoffdioxid vermieden.

Nach den Empfehlungen der Weltgesundheitsorganisation ist das Einatmen von Sauerstoff zur Behandlung von Cluster-Kopfschmerz-Attacken geeignet. Die Anwendung von hochkonzentriertem Sauerstoff mittels spezieller Maskensysteme lindert die Beschwerden in der Regel innerhalb von Minuten effektiv.

Industriell verwendet wird Sauerstoff hauptsächlich in der Metallurgie zur Herstellung von Roheisen und Stahl, sowie bei der Kupfer-Raffination. Reiner Sauerstoff oder sauerstoffangereicherte Luft dient hier einerseits zum Erreichen hoher Temperaturen, andererseits zum Frischen des Rohstahls, d. h. zum Entfernen unerwünschter Beimengungen von Kohlenstoff, Silicium, Mangan und Phosphor, die oxidiert und abgetrennt werden. Reiner Sauerstoff hat im Vergleich zu Luft den Vorteil, dass kein Stickstoff in die Schmelze eingetragen wird. Stickstoff hat einen negativen Einfluss auf die mechanischen Eigenschaften von Stahl (siehe auch Thomas-Verfahren).
In chemischen Prozessen wird Sauerstoff meist zur Oxidation von verschiedenen Grundstoffen, wie bei der Olefin-Oxidation von Ethen zu Ethylenoxid und bei der teilweisen (partiellen) Oxidation von Schweröl und Kohle verwendet. Benötigt wird Sauerstoff außerdem zur Erzeugung von Wasserstoff- und Synthesegas und der Herstellung von Schwefel- und Salpetersäure. Weitere durch Oxidation mit Sauerstoff hergestellte wichtige Produkte sind Acetylen (Ethin), Acetaldehyd, Essigsäure, Vinylacetat und Chlor.

Verschiedene Brenngase (Propan, Wasserstoff, Ethin u. a.) erzielen erst durch Mischen mit Sauerstoff ausreichend heiße und rußfreie Flammen zum Schweißen und Hartlöten oder Erschmelzen und Formbarmachen von Glas. Nach Aufheizen und Zünden erfolgt das Schneiden von Beton mit einer (selbst abbrennenden) Sauerstofflanze oder das Brennschneiden von Eisen alleine durch einen scharfen Sauerstoffstrahl.

Sauerstoff wird ebenso verwendet zur Darstellung von Ozon, als Oxidationsmittel in Brennstoffzellen und in der Halbleitertechnik. In der Raketentechnik wird flüssiger Sauerstoff als Oxidationsmittel verwendet und mit LOX "(liquid oxygen)" abgekürzt.

In der Umwelttechnik werden Abwässer durch Einleitung von Sauerstoffgas schneller durch Bakterien von organischen Schadstoffen und Giften befreit. In vielen Trinkwasserwerken dient die Trinkwasseraufbereitung mit Ozon (Ozonierung) zur Oxidation von organischen Stoffen oder etwa Eisen und der Entkeimung, und kann zu einer deutlich besseren Reinigungswirkung der Filteranlagen führen.

Für die Lebensmitteltechnik ist Sauerstoff als Lebensmittelzusatzstoff als E 948 zugelassen und wird – neben Stickstoff, Kohlendioxid und Lachgas als Treibgas, Packgas, Gas zum Aufschlagen von Sahne (Schlagobers) u.ä. verwendet.

In der Wellness- und Lebensmittelindustrie wird gelegentlich für Produkte geworben, die mit Sauerstoff angereichert seien. So wird etwa abgepacktes Wasser verkauft, das einen erhöhten Sauerstoffgehalt haben soll. Eine positive Wirkung auf Gesundheit und Wohlbefinden ist nicht zu erwarten, denn Sauerstoff löst sich nur in geringer Menge in Wasser und wird in vielen Größenordnungen mehr – nämlich mit jedem Atemzug – über die Lunge als via Magen aufgenommen.

Die Zink-Luft-Zelle ist ein Primärelement, das Luft aus der umgebenden Atmosphäre aufnimmt und den Sauerstoff chemisch mit dem Metall Zink umsetzt, um elektrische Spannung und Strom zu erzeugen. Der Vorzug dieses Batterietyps ist, dass er seine relativ hohe Energiedichte (bei geringer Stromentnahme) über einen ausgedehnten Zeitraum erstreckt abgeben kann. Das Verschlossenhalten der Ventilationsöffnung etwa durch einen Klebstreifen (Siegel) vor Gebrauch hilft die Alterung der Zelle bei Lagerung zu reduzieren. Gut faustgroße quaderförmige Zellen dieses Typs im Kunststoffgehäuse wurden um 1980 in Blinkleuchten zur Baustellenabsicherung eingesetzt und sind bis heute als Knopfzellen für Hinter-dem-Ohr-Hörgeräte üblich.

Forschung und Entwicklung gehen auch in Richtung Metall-Sauerstoff-Akkus auf Basis von Alkalimetallen. Ziel ist es, die Energiedichte (pro Masse) von Lithium-Ionen-Akkus zu übertreffen.

Sauerstoff befindet sich in der Natur in einem steten Kreislauf. Er wird ständig von autotrophen Lebewesen wie Cyanobakterien (veraltet: Blaualgen), Algen und Pflanzen bei der oxygenen Photosynthese durch Photolyse aus Wasser freigesetzt. Er ist ein Endprodukt dieser biochemischen Reaktion und wird an die Umwelt abgegeben. Cyanobakterien waren wahrscheinlich die ersten Organismen, die molekularen Sauerstoff als Abfallprodukt in der Atmosphäre anreicherten. Zuvor existierte eine praktisch sauerstofffreie, anaerobe Atmosphäre auf der Erde.

Die meisten aeroben Organismen, darunter die meisten Eukaryoten, einschließlich des Menschen und der Pflanzen, und viele Bakterien, benötigen diesen Sauerstoff zum Leben. Eukaryoten brauchen ihn zur Energiegewinnung durch Oxidation in den Mitochondrien. Der Sauerstoff wird dabei in der Atmungskette wieder zu Wasser reduziert. Die Oxygenierung von Stoffwechselprodukten mithilfe von Enzymen (Oxygenasen) wird oft beim Abbau von Stoffen angewendet; die Reaktion benötigt Sauerstoff und findet in allen aeroben Lebewesen statt.

Da Sauerstoff und einige seiner Verbindungen sehr reaktiv sind und Zellstrukturen zerstören können, besitzen Organismen Schutzenzyme wie Katalase und Peroxidase. Für Organismen, denen diese Enzyme fehlen, wirkt Sauerstoff toxisch. Beim Abbau des Sauerstoffs entstehen reaktive Sauerstoffspezies, wie freie Radikale, die ebenfalls biologische Moleküle zerstören können. Werden sie nicht schnell genug abgefangen, entsteht sogenannter oxidativer Stress, der für Alterungsprozesse verantwortlich gemacht wird.

In den Phagozyten (Fresszellen) des Immunsystems dienen diese reaktiven Sauerstoffspezies (Wasserstoffperoxid und Hyperoxidionen) neben Enzymen dazu, aufgenommene Krankheitserreger zu zerstören.

Wird reiner Sauerstoff oder Luft mit einem höheren Sauerstoffanteil über längere Zeit eingeatmet, kann es zur Vergiftung der Lunge, dem sogenannten Lorrain-Smith-Effekt kommen. Dabei werden die Lungenbläschen (Lungenalveolen) durch Anschwellen in ihrer normalen Funktion gehindert.

Der Paul-Bert-Effekt bezeichnet eine Sauerstoffvergiftung des Zentralnervensystems. Diese kann bei Hochdruckatmung jeglicher Sauerstoff-Stickstoff-Gemische auftreten, das Risiko erhöht sich jedoch mit Erhöhung des Sauerstoffanteils und des Gesamtdrucks. Bei Sauerstoff-Teildrücken oberhalb 1,6 bar kommt es innerhalb relativ kurzer Zeit zu einer Vergiftung. Dies spielt beispielsweise beim Tauchen eine Rolle, da es die maximale Tauchtiefe abhängig vom Sauerstoffpartialdruck begrenzt.

In der Raumfahrt wird beispielsweise in Raumanzügen reiner Sauerstoff geatmet, allerdings unter stark vermindertem Druck, um gesundheitliche Folgen zu minimieren und weil der Raumanzug unter normalem Druck zu steif würde.

Hyperoxidanionen (alte Bezeichnung: Superoxidanionen) sind einfach negativ geladene und radikalische Sauerstoffionen (O), die durch Elektronenübertragung auf molekularen Sauerstoff entstehen. Diese sind äußerst reaktiv. Mitunter werden sie als Nebenprodukt des Stoffwechsels (Metabolismus) wie durch Nebenreaktionen bei einigen Oxidasen (Xanthin-Oxidase) gebildet. Hyperoxidanionen entstehen ebenfalls beim Photosynthese-Komplex I und als Nebenprodukt der Atmungskette ("mitochondriale Atmung"). Xenobiotika und cytostatische Antibiotika fördern dabei ihre Entstehung. Beim Auftreten einer Entzündung wird durch eine membranständige NADPH-abhängige Oxidase Hyperoxidanionen ins extrazelluläre Milieu abgegeben. Sie führen zu oxidativem Stress. Beispielsweise kommt es beim Fettsäureabbau in den Peroxisomen zur Übertragung von Elektronen von FADH auf molekularen Sauerstoff. Die entstandenen Hyperoxidanionen können zum Zellgift Wasserstoffperoxid weiterreagieren. Beim Ablauf der Atmungskette entstehen diese radikalischen Sauerstoffspezies in geringen Mengen. Es bestehen Vermutungen, dass die Erbgutschädigungen, die solche Sauerstoffspezies hervorrufen, an Alterungsprozessen beteiligt sind. Es ist daher für den Organismus von essentieller Bedeutung, diese Hyperoxidanionen zügig abzubauen. Dies geschieht mittels der Superoxid-Dismutase.

Gelöster Sauerstoff oxidiert zweiwertiges Mangan zu höheren Oxidationsstufen. Dieses wird nach der Methode von Winkler durch Iodid wieder vollständig reduziert. Die Stoffmenge des dabei gebildeten Iods steht in einem stöchiometrischen Verhältnis von 1:2 zu der Stoffmenge des ursprünglich gelösten Sauerstoffs und kann iodometrisch mit Thiosulfat rücktitriert werden.

Als einfacher Nachweis für das Vorhandensein von Sauerstoff wird die Glimmspanprobe angewandt.

Die zur Verbrennungssteuerung von Otto-Motoren verwendete Lambdasonde misst den Sauerstoffgehalt im Autoabgas in Bezug zum O-Gehalt in der Umgebungsluft. Dazu wird der Abgasstrom durch ein Yttrium-dotiertes Zirconiumdioxidröhrchen geleitet, welches innen und außen mit Platinelektroden versehen ist. Dabei steht die äußere Elektrode in Kontakt mit der Umgebungsluft. Unterschiedliche O-Partialdrücke an den Elektroden führen zu einer elektrischen Potentialdifferenz, die gemessen wird. Die Vorteile dieser Messtechnik liegen in der niedrigen Nachweisgrenze von wenigen ppm und der großen Betriebstemperaturspanne (300 °C bis 1500 °C).

Die Clark-Elektrode ist ein amperometrischer Sensor zur elektrochemischen Bestimmung von gelöstem, gasförmigem Sauerstoff. Platin- und Ag/AgCl-Referenzelektrode befinden sich in einem Elektrolytsystem, welches durch eine gaspermeable Teflonmembran von der Probelösung getrennt ist. Gelöster Sauerstoff kann durch die Membran in die Elektrolytlösung diffundieren und wird in einem Potentialbereich von −600 mV bis −800 mV kathodisch reduziert. Der gemessene Strom ist dabei proportional zur Sauerstoffkonzentration in der Probelösung.

Bei den optischen Methoden bedient man sich der Tatsache, dass Sauerstoff die Fluoreszenz von angeregten Molekülen zu löschen vermag. Auf Basis von fluoreszenten Übergangsmetallkomplexen wurden sog. Optroden entwickelt, die den Sauerstoffgehalt über die Fluoreszenzlöschung von Sondenmolekülen bestimmen. Als Sondenmoleküle kommen häufig Metall-Liganden-Komplexe zum Einsatz. Als Metallionen haben sich Ru(II), Ir(II), Pt(II) und Pd(II) bewährt, als Liganden verschiedene Dipyridine, Phenanthroline und (fluorierte) Porphyrine. Die Sonden werden in Polymermatrices eingebettet. Die Anregung erfolgt zumeist mit LEDs oder Laserdioden. Man unterscheidet zwischen punktuellen Messungen z. B. mittels optischer Lichtleiterfasern und bildgebenden Messverfahren mittels planarer Sensorfilme. Mit Optroden konnten Nachweisgrenzen von 5 ppbv (O, ≈ 5,1 · 10 hPa) erzielt werden, was einer Konzentration in Wasser von 7 pM entspricht.

Sauerstoff bildet Verbindungen mit fast allen Elementen – außer mit den Edelgasen Helium, Neon und Argon. Da Sauerstoff sehr elektronegativ ist, kommt es in fast allen seinen Verbindungen in den Oxidationsstufen −II vor, nur in Peroxiden −I. Diese Ionen werden auch als Closed-shell-Ionen bezeichnet. Peroxide sind meist instabil und gehen leicht in Oxide über.

Positive Oxidationszahlen besitzt Sauerstoff nur in Verbindungen mit dem noch elektronegativeren Element Fluor, mit dem es Verbindungen mit der Oxidationsstufe +I (Disauerstoffdifluorid OF) und +II (Sauerstoffdifluorid OF) bildet. Da bei ihnen die negative Polarisierung beim Fluor vorliegt, werden diese nicht als Oxide, sondern als Fluoride, genauer gesagt Sauerstofffluoride, bezeichnet.

Neben den Oxidverbindungen tritt Sauerstoff noch in ionischen Verbindungen und Radikalen als Peroxid- (O), Hyperoxid- (O (Oxidationsstufe −1/2)) und Ozonidanion (O (Oxidationsstufe −1/3)) sowie als Dioxygenylkation (O) auf.

Sauerstoff bildet abhängig vom Bindungspartner sowohl ionisch als auch kovalent aufgebaute Verbindungen.

Zu den anorganischen Sauerstoffverbindungen zählen die Verbindungen von Sauerstoff mit Metallen, Halbmetallen, Nichtmetallen wie Wasserstoff, Kohlenstoff, Stickstoff, Schwefel und den Halogenen. Sie gehören zu den wichtigsten Verbindungen überhaupt.

Die meisten Sauerstoffverbindungen sind Oxide. In ihnen tritt der Sauerstoff, ionisch oder kovalent gebunden, in der Oxidationsstufe −II auf. Viele natürlich vorkommende Salze, die oft wichtige Quellen zur Herstellung von Metallen sind, sind Oxide.

Mit den Metallen bildet Sauerstoff in niedrigen Oxidationsstufen ionisch aufgebaute und in der Regel basische Oxide.

Mit steigender Oxidationsstufe haben die Oxide zunehmend amphoteren (Zink(II)-oxid, Aluminium(III)-oxid) und schließlich sauren Charakter (Chrom(VI)-oxid).

Mit Nichtmetallen bildet Sauerstoff ausschließlich kovalente Oxide. Die Oxide von Nichtmetallen in niedrigen Oxidationsstufen reagieren meist neutral (Distickstoffmonoxid), mit steigender Oxidationsstufe zunehmend sauer.

Unter den Sauerstoffverbindungen der Nichtmetalle spielen die mit Wasserstoff eine gesonderte Rolle. Sauerstoff bildet mit Wasserstoff zwei Verbindungen. An erster Stelle ist das Wasser zu nennen, ohne das es kein Leben auf der Erde geben würde. Die zweite Verbindung ist das Wasserstoffperoxid (HO), eine thermodynamisch instabile Verbindung, die als Oxidations- und Bleichmittel Verwendung findet.

Obwohl die meisten sauerstoffhaltigen Kohlenstoffverbindungen in den Bereich der organischen Chemie eingeordnet werden, gibt es einige wichtige Ausnahmen. Die einfachen Oxide des Kohlenstoffs Kohlenstoffmonoxid (CO) und Kohlenstoffdioxid (CO), sowie die Kohlensäure und deren Salze, die Carbonate, werden als anorganische Verbindungen angesehen.

Sind in einer salzartigen Verbindung geringere Mengen Oxidionen bekannt als nach der Stöchiometrie und Wertigkeit des Sauerstoffs zu erwarten, spricht man von Suboxiden. In diesen kommen Element-Element-Bindungen vor, die formale Oxidationsstufe des Elements liegt bei unter +1. Elemente, die Suboxide bilden, sind die Alkalimetalle Rubidium und Caesium, aber auch Bor oder Kohlenstoff.

Vor allem mit Alkalimetallen bildet Sauerstoff Verbindungen mit Sauerstoff-Sauerstoff-Bindungen. Hierzu zählen die Peroxide, die Hyperoxide und die Ozonide. Peroxide wie Wasserstoffperoxid besitzen das O-Ion und eine formale Oxidationsstufe des Sauerstoffs von −1. Durch die leichte Spaltung der Sauerstoff-Sauerstoff-Bindung bilden sie leicht Radikale, die auf organische Substanzen bleichend wirken und dementsprechend als Bleichmittel eingesetzt werden. Es sind auch organische Peroxide bekannt.

In "Hyperoxide"n kommt das radikalische Dioxid(1−)-Anion O vor, die formale Oxidationsstufe ist −½ für jedes Sauerstoffatom. Hyperoxid-Ionen bilden sich im Stoffwechsel und zählen dabei zu den Reaktiven Sauerstoffspezies, salzartige Hyperoxide sind lediglich von den Alkalimetallen außer Lithium bekannt. Ozonide leiten sich vom Ozon ab und haben dementsprechend das O-Anion. Salzartige Ozonide sind wie Hyperoxide von allen Alkalimetallen außer Lithium bekannt, dazu gibt es auch organische Ozonide, die durch Addition von Ozon an Alkene entstehen.

Eine weitere große Gruppe der Sauerstoffverbindungen stellen die Hydroxide unter Beteiligung von Wasserstoff dar. Bei diesen handelt es sich um überwiegend ionische Verbindungen, denen das Hydroxidion gemein ist. Bis auf die Hydroxide der Alkalimetalle wie Natriumhydroxid (NaOH) oder Kaliumhydroxid (KOH) sind sie im Allgemeinen wenig löslich in Wasser.

Bei der Reaktion von Nichtmetalloxiden sowie Metalloxiden von Metallen in hohen Oxidationsstufen mit Wasser bilden sich die sogenannten Sauerstoffsäuren, die für die Namensgebung des Sauerstoffs verantwortlich sind.

Die stärksten anorganischen Sauerstoffsäuren leiten sich von den Nichtmetallen Stickstoff (Salpetersäure) und Schwefel (Schwefelsäure) sowie den Halogenen ab (Halogensauerstoffsäuren). Dabei gilt die Regel, dass die Säurestärke (pK-Wert) mit zunehmender Anzahl von Sauerstoffatomen zunimmt:

Sauerstoff ist – neben Kohlenstoff, Wasserstoff und Stickstoff – eines der wichtigsten Elemente der organischen Chemie. Er bildet eine Vielzahl wichtiger funktioneller Gruppen, die sowohl Kohlenstoff-Sauerstoff-Einfachbindungen, als auch – in der Carbonylgruppe – Kohlenstoff-Sauerstoff-Doppelbindungen enthalten.

Zu den einfachsten organischen Verbindungen, die Sauerstoff enthalten, gehört Methanal (HCO), das sich formal von Kohlenstoffdioxid (CO) nur darin unterscheidet, dass statt des zweiten Sauerstoffatoms zwei Wasserstoffatome am Kohlenstoff gebunden sind. Wichtig für die Einteilung in die organische Chemie ist jedoch, dass sich Methanal von dem organischen Alkohol Methanol (CHOH) ableitet, welcher wiederum ein Derivat des einfachsten Alkans Methan (CH) ist.

Die wichtigsten Verbindungklassen:



Eine weitere wichtige Gruppe organischer Sauerstoffverbindungen sind die Kohlenhydrate oder "Saccharide". Chemisch sind dies Polyhydroxycarbonylverbindungen (Hydroxyaldehyde oder Hydroxyketone). Sie kombinieren also Eigenschaften der Alkohole mit denen der Aldehyde und Ketone.

Daneben existieren noch eine Reihe weiterer Verbindungen mit funktionellen Gruppen, bei denen der Sauerstoff an ein weiteres Heteroatom, wie etwa Stickstoff, Schwefel oder Phosphor, beispielsweise bei organischen Phosphaten (etwa ATP oder innerhalb der DNA-Moleküle) gebunden ist.




</doc>
<doc id="4544" url="https://de.wikipedia.org/wiki?curid=4544" title="Selen">
Selen

Selen [] ist ein chemisches Element mit dem Elementsymbol Se und der Ordnungszahl 34. Im Periodensystem steht es in der 4. Periode sowie der 6. Hauptgruppe, bzw. der 16. IUPAC-Gruppe, zählt also zu den Chalkogenen. Es kommt in mehreren Modifikationen vor, die stabilste ist die graue, metallähnliche Form.

Selen (griech. σελήνη [selḗnē], „Mond“) wurde 1817 von Jöns Jakob Berzelius im Bleikammerschlamm einer Schwefelsäurefabrik entdeckt; zuerst hielt Berzelius die Substanz für Tellur (von lat. "tellus" „Erde“), zu dem Selen einige Ähnlichkeiten aufweist; so entwickelt sich bei der Verbrennung beider Elemente ein ausgeprägter Geruch nach Rettich. 1818 schloss Berzelius im Rahmen seiner Experimente aber, dass es sich um ein neues Element handelte; um auf die Ähnlichkeit zum Tellur (Erde) hinzuweisen nannte er es Selen (Mond).

In der unbelebten Natur und bei industriellen Prozessen spielen vor allem die anorganischen Verbindungen eine Rolle. In der belebten Natur dominieren die organischen Verbindungen. In Hefen und Pflanzen kommt Selen vor allem als Selenomethionin vor. Als essentielles Spurenelement ist Selen Bestandteil der 21. biogenen Aminosäure Selenocystein, sowie in Bakterien, Archaea und Eukaryoten enthalten. Tiere bilden kein Selenomethionin, wohl aber Selenocystein. Selenocystein ist der spezifische katalytische Bestandteil der selenabhängigen Enzyme. Im Gegensatz dazu wird Selenomethionin an Stelle von Methionin unspezifisch in viele Proteine eingebaut, ohne dabei eine Funktion auszuüben; es wird als Selenspeicherform angesehen. Die Menge von Selen in Nahrungsmitteln hängt stark vom Selengehalt des Bodens ab. Selenarme Böden in Europa finden sich insbesondere in Deutschland, Schottland, Dänemark, in Teilen der Balkanländer und in Finnland. In manchen selenarmen Gebieten werden dem Boden selenathaltige Düngemittel zugeführt, z. B. in Finnland seit 1984.<ref name="DOI10.1007/s00103-005-1185-4">"Selen in der Umweltmedizin." In: "Bundesgesundheitsblatt - Gesundheitsforschung - Gesundheitsschutz." 49, 2006, S. 88, .</ref>

In kleinen Mengen kommt gediegenes Selen natürlich vor. Selenmineralien wie Clausthalit und Naumannit sind selten.

Selen ist, meist in Form von Metallseleniden, Begleiter schwefelhaltiger Erze der Metalle Kupfer, Blei, Zink, Gold und Eisen. Beim Abrösten dieser Erze sammelt sich das feste Selendioxid in der Flugasche oder in der nachgeschalteten Schwefelsäureherstellung als Selenige Säure.

Selen kann in Tragant-Arten, in Brassica oder im Knoblauch als Se-Methylselenocystein angereichert werden. Die reichhaltigste bekannte Selenquelle unter den Nahrungsmitteln ist die Paranuss.

Industriell gewinnt man Selen als Nebenprodukt bei der elektrolytischen Kupfer- und Nickelherstellung aus dem Anodenschlamm durch Abrösten.

Die Reduktion zum elementaren Selen erfolgt durch Schwefeldioxid.

Im Labormaßstab kann Selen aus der Umsetzung von Seleniger Säure und Iodwasserstoff synthetisiert werden.

In der Lebensmittelergänzung und Tierernährung (in der Tierernährung in der EU seit Mai 2005 zugelassen) wird seit einigen Jahren eine organische Selenquelle eingesetzt, die durch die Zucht bestimmter Brauhefen des Typs "Saccharomyces cerevisiae" (Sel-Plex, Lalmin(TM)) auf selenreichem Nährmedium (Melasse und Natriumselenit) erzeugt wird. Hefen synthetisieren hohe Anteile an Selenomethionin als Aminosäure und binden so bis zu 2000 ppm Selen auf organische Weise. Die größte Anlage zur Erzeugung solcher natürlicher Selenhefen wurde 2004 in São Pedro im brasilianischen Bundesstaat Paraná errichtet.

Selen kommt wie Schwefel in mehreren Modifikationen vor:

Die Bandlücke des Selens beträgt etwa 1,74 eV (an der Grenze vom sichtbaren Licht zum Infrarot).

Durch Belichtung ändert es seine elektrische Leitfähigkeit. Zusätzlich zeigt es einen photovoltaischen Effekt. Die Leitfähigkeit wird nicht durch Elektronen in einem Leitungsband verursacht, sondern durch Leitung von Löchern (siehe bei Elektrische Leitfähigkeit und Defektelektron), also positiv geladenen Elektronenfehlstellen, wodurch unter anderem das Vorzeichen des Hall-Effekts negativ wird. Als Mechanismus für diese Löcherleitung wird eine so genannte „Hopping-Leitfähigkeit“ (der Löcher von einer Kristallfehlstelle zur nächsten) vorgeschlagen.

Beim Erhitzen in Luft verbrennt Selen mit blauer Flamme zum Selendioxid, SeO. Oberhalb von 400 °C setzt es sich mit Wasserstoff zum Selenwasserstoff, HSe, um. Mit Metallen bildet es in der Regel Selenide, zum Beispiel Natriumselenid, NaSe.

Das chemische Verhalten ist dem Schwefel ähnlich, allerdings ist Selen schwerer oxidierbar. Die Reaktion mit Salpetersäure bildet „nur“ Selenige Säure, eine Selen(IV)-Verbindung.

Das Selen weist eine Vielzahl von Isotopen auf. Von den sechs natürlich vorkommenden Isotopen sind fünf stabil. Dabei sind die Anteile folgendermaßen verteilt: Se (0,9 %), Se (9,0 %), Se (7,6 %), Se (23,6 %), Se (49,7 %) und Se (9,2 %).

Se als einziges natürlich vorkommendes radioaktives Isotop besitzt mit ca. 10 Jahren eine der längsten derzeitig bekannten Halbwertszeiten überhaupt. Daneben kennt man weitere 22 radioaktive Isotope, unter denen Se mit einer Halbwertszeit von 120 Tagen und Se mit einer Halbwertszeit von 327.000 Jahren besondere Bedeutung haben. Se findet zur Konstruktion spezieller Gammastrahlenquellen zur zerstörungsfreien Prüfung von z. B. Schweißnähten Anwendung. Se dient in der Nuklearmedizin in Verbindung mit Methionin als Tracer zur Beurteilung der Pankreasfunktion und mit Homotaurocholsäure (SeHCAT) zur Beurteilung der Resorption von Gallensäuren. Se ist Bestandteil von abgebranntem Kernbrennmaterial, wo es bei der Spaltung von Uran mit einer Häufigkeit von 0,04 % entsteht.

Das seltenste der stabilen Isotope Se hat eine gewisse Bedeutung als Spekulationsobjekt erlangt. Es wird immer wieder zu sehr hohen Preisen auf dem Markt angeboten. Außer einigen sehr spezialisierten Anwendungen in der Forschung, wo es zu Markierungszwecken dient, ist für dieses Material jedoch keine besondere technische Verwendung bekannt.

Selen ist für alle Lebensformen essentiell. Selenverbindungen werden daher als Nahrungsergänzung angeboten und zu Futter- und Düngemittelzusätzen verarbeitet. In der Glasindustrie verwendet man es zum Entfärben grüner Gläser sowie zur Herstellung rotgefärbter Gläser. Weitere Anwendungen:


Selen ist ein essentielles Spurenelement für Menschen, Tiere und viele Bakterien. In der Milchviehfütterung wird Selen zugesetzt, da der natürliche Selengehalt der Futtermittel oft nicht zur Versorgung der Nutztiere ausreicht. Das deutsche Futtermittelrecht erwähnt zur Ergänzung der Selenversorgung nur die beiden anorganischen Selenquellen Natriumselenit und -selenat als Futterzusatzstoffe. Diese beiden Verbindungen sind ökonomisch sehr günstig, haben aber den Nachteil einer geringen Bioverfügbarkeit.
Selen wirkt in höheren Konzentrationen jedoch stark toxisch, wobei die Spanne zwischen Konzentrationen, die Mangelerscheinungen hervorrufen, und toxischen Konzentrationen sehr gering ist. Zudem ist die Toxizität von Selen abhängig von der chemischen Bindungsform.

Selen ist in Selenocystein enthalten, einer Aminosäure im aktiven Zentrum des Enzyms Glutathionperoxidase und vieler weiterer Proteine. Wegen seiner hohen Reaktivität mit Sauerstoff spielt Selen bei Tieren und Menschen eine wichtige Rolle beim Schutz der Zellmembranen vor oxidativer Zerstörung (Radikalfänger). Selenocystein ist auch am Katalysemechanismus weiterer Enzyme beteiligt und in vielen Proteinen enthalten, deren Bedeutung noch nicht geklärt ist.

Bevor eine Arbeitsgruppe um Klaus Schwarz am National Institute of Health (USA) Selen als essentiellen Nahrungsbestandteil der Tiere entdeckte, galt Selen als toxische Substanz. In den 1930er Jahren machten Veterinäre in den „Great Plains“ die hohe Aufnahme selenhaltiger Pflanzen für die Alkali-Krankheit und die Blind-Ataxie der Rinder verantwortlich, andererseits berichtete eine Forschergruppe um Schwarz in den 1950er Jahren, dass Selen einer nekrotischen Leberdegeneration vorbeugt. Etwa gleichzeitig stellte eine Gruppe von Forschern der Oregon State University, der auch O. H. Muth und J. E. Oldfield angehörten, ein Selendefizit bei schwachen Kälbern fest. Später wies Hogue nach, dass Selen der Muskeldystrophie der Lämmer vorbeugt. Diesen Berichten folgend haben Forscher verschiedener Einrichtungen Studien zum Nutzen der Selensupplementierung auf Leistung und Gesundheit des Milchviehs begonnen. Es wurde beschrieben, dass Selen vorrangig an der Katalyse des Glutathionperoxidase (GSH-Px)-Systems beteiligt ist. Verschiedene Isoformen der GSH-Px zerstören die während des normalen Fettstoffwechsels gebildeten Peroxide (reaktive Sauerstoffverbindungen). Wenn Peroxide ungehindert in der Zelle verbleiben, greifen sie die Zellmembranen an und destabilisieren sie. Hemken erklärte, dass Selen auch an der Entgiftung gefährlicher Medikamente oder Toxine beteiligt ist. Selen spielt bei Tieren noch in mindestens zwei weiteren Enzym-Systemen eine Rolle: bei der Iodthyronin-Deiodase, einem Enzym, welches das Schilddrüsenhormon T4 aktiviert, und bei der Thioredoxin-Reduktase, einem Enzym, das die reduzierenden Reaktionen reguliert. Bestimmte Plasma-, Herz-, Muskel- und Nierenproteine enthalten Selen. Jedoch ist die Funktion des Selens in diesen Proteinen noch in weiten Bereichen unklar.

Es gibt viele verschiedene Selenoproteine. In den Selenoproteinen ist meist Selenocystein enthalten, das auch als 21. Aminosäure bekannt ist und während der Proteinbiosynthese über eine eigene tRNA eingebaut wird. Selenoproteine kommen in dieser Funktion nur in tierischen Organismen, Bakterien und Archaeen vor. Pflanzen bauen Selen je nach Bodengehalt anstelle des Schwefels unspezifisch in Aminosäuren ein, besonders in Methionin (Se-Methionin) und in geringem Umfang auch Cystein (Se-Cystein) bzw. Derivate davon (Methyl-Se-Cystein). Nur die sogenannten „Selensammlerpflanzen“ (Selenakkumulator-Pflanzen, z. B. Paradiesnuss), die in selenreichen, ariden Gebieten vorkommen, speichern Selen darüber hinaus auch als organisch gebundenes, wasserlösliches Selen oder Selensalze.

Bis dato wurden mindestens 25 Gene für Selenoproteine im menschlichen Genom entdeckt:

Bekannte Selenmangelkrankheiten sind:





In einer kritischen Bewertung der Pharmainformation vom Juni 2005 wird festgestellt, dass die bislang verfügbaren Studien keine Hinweise für einen Nutzen einer zusätzlichen Gabe von Selen in irgendeinem Zusammenhang erbringen konnten. Zwar scheint eine positive Beeinflussung verschiedener Krebsarten möglich, andererseits die Begünstigung anderer Karzinome nicht unwahrscheinlich. Die „SELECT“-Studie („"Sel"enium and Vitamin "E" "C"ancer Prevention "T"rial“) sollte diesbezüglich Auskunft geben und 2013 abgeschlossen werden. Allerdings wurde diese im Oktober 2008 abgebrochen, da während der Studie nachgewiesen werden konnte, dass es keine verbesserte Schutzwirkung im Vergleich zum Placebo gibt und ein Nutzen ausgeschlossen werden konnte. In dieser Studie wurde zwar sogar eine erhöhte Prostatakrebshäufigkeit unter der Gabe von Vitamin E und eine erhöhte Diabetesentstehung unter der Selengabe festgestellt, beides war aber nicht statistisch signifikant.

Im Rahmen der neuerlichen Auswertung von Daten einer Studie kam Saverio Stranges von der Universität in Buffalo zu dem Ergebnis, dass von den 600 Patienten, die Selen einnahmen (tägl. 200 µg) nach fast acht Jahren etwa zehn Prozent an Typ 2 Diabetes erkrankt waren. Bei der Placebo-Kontrollgruppe waren es lediglich sechs Prozent. Bis dato wurde noch keine potentielle Ursache für das erhöhte Diabetes-Risiko gefunden. Hohe Selenkonzentrationen im Blut korrelieren mit dem Risiko, an Diabetes zu erkranken. Somit kommt auch die Pharmainformation vom Februar 2008 zum Schluss: „Eine kritische Haltung gegenüber wenig belegten Konzepten, hinter denen natürlich ein großes finanzielles Interesse steht, hat sich wieder einmal bestätigt.“
Die Studienlage ist diesbezüglich jedoch nicht eindeutig. So werden der Studie von Stranges u. a. methodische Fehler unterstellt, etwa das Fehlen einer vorherigen Familienanamnese, die eine erhöhte familiäre Prävalenz von Diabetes mellitus innerhalb der Selengruppe hätte ausschließen müssen, sowie die Tatsache, dass die untersuchten Probanden Personen waren, die in hohem Maße Sonnenstrahlung und Chemikalien ausgesetzt waren, weswegen sich die Ergebnisse schlecht auf „durchschnittliche“ Probanden übertragen ließen. Zudem liege das Diabetes-Risiko sowohl in der Placebo- als auch in der Selengruppe unter dem amerikanischen Durchschnittswert.
Andere Studien legen weiterhin einen hemmenden Effekt von Selen auf die Entwicklung von Diabetes mellitus nahe, darunter eine jüngst veröffentlichte von Tasnime Akbaraly (Universität Montpellier) durchgeführte Untersuchung an 1162 Männern und Frauen.

Auch eine Arbeit aus dem Jahr 2012 zeigt einen positiven Effekt von Selen nur dann, wenn ein Selenmangel besteht, ansonsten kommt es eher zur Entwicklung eines Diabetes mellitus. Eine große Metastudie aus dem Jahr 2013 zeigt keinen protektiven Nutzen der Selensubstitution bezüglich Herz-Kreislauferkrankungen. Es gab zwar vermehrte Diabetes-2-Fälle in der Selen-Substitutionsgruppe, der Unterschied war jedoch nicht signifikant. Aber es kam vermehrt zu Alopezie und zu Dermatitis.

Selen spielt eine wichtige Rolle bei der Produktion der Schilddrüsenhormone, genauer bei der „Aktivierung“ von Thyroxin (T4) zu Triiodthyronin (T3).

Selen ist Bestandteil eines Enzyms, der Thyroxin-5′-Deiodase, die für die Entfernung eines Iodatoms aus T4 verantwortlich ist. Durch diese Deiodierung entsteht T3. Ein Selenmangel führt zu einem Mangel an Thyroxin-5′-Deiodase, wodurch nur noch ein Teil des verfügbaren T4 deiodiert werden kann. Da T3 im Stoffwechsel wesentlich wirksamer ist, resultiert aus einem T3-Mangel eine Schilddrüsenunterfunktion (Hypothyreose). Eine zusätzliche Einnahme von Selenpräparaten (Natriumselenit) in hohen Dosen von 200–300 μg täglich ist nach ärztlicher Abklärung z. B. bei Hashimoto-Thyreoiditis angezeigt, dies kann auch die Entzündungsaktivität reduzieren.

Die quantitative Bestimmung von Spuren (0,003 %) an Selenat kann elektrochemisch mittels Polarografie erfolgen. In 0,1-molarer Ammoniumchloridlösung zeigt sich eine Stufe bei −1,50 V (gegen SCE). Im Ultraspurenbereich bietet sich die Atomspektrometrie an, wobei mittels Flammen-AAS 100 μg/l (ppb), per Graphitrohr-AAS 0,5 und per Hydridtechnik 0,01 µg/l Selen nachgewiesen werden können.

Selen und Selenverbindungen sind giftig. Direkter Kontakt schädigt die Haut (Blasenbildung) und Schleimhäute. Eingeatmetes Selen kann zu langwierigen Lungenproblemen führen.

Eine Vergiftung durch übermäßige Aufnahme von Selen wird als Selenose bezeichnet. Eine Selen-Aufnahme von mehr als 3000 µg/d kann zu Leberzirrhose, Haarausfall und Herzinsuffizienz führen. Beschäftigte in der Elektronik-, Glas- und Farbenindustrie gelten als gefährdet. Nach anderen Quellen treten schon ab 400 µg/d Vergiftungserscheinungen auf wie Übelkeit und Erbrechen, Haarverlust, Nagelveränderungen, periphere Neuropathie und Erschöpfung.

In Verbindungen tritt Selen am häufigsten in den Oxidationsstufen −II (Selenwasserstoff, Selenide) und +IV (Tetrahalogenide, Selendioxid und Selenate(IV), veraltet "Selenite") auf. In den Selenidionen tritt Selen auch mit nicht-ganzzahligen negativen Oxidationszahlen auf. Seltenere positive Oxidationszahlen sind +I (Halogenide SeX) und +VI (Selenhexafluorid, Selensäure). Dabei sind Selenverbindungen mit der Oxidationszahl +VI stärkere Oxidationsmittel als die analogen Schwefel- und Tellurverbindungen. So lösen Mischungen aus konzentrierter Selen(VI)-säure mit Salzsäure Metalle wie Gold und Platin auf.

Selenwasserstoff, HSe, ist ein farbloses, sehr giftiges Gas, das durch Reaktion von Seleniden (MSe) 
mit starken Säuren, zum Beispiel Salzsäure HCl, entsteht. Aus den Elementen (Wasserstoff und Selen) ist die Verbindung als stark endotherme Verbindung nur bei Temperaturen über 350 °C darstellbar. Selenwasserstoff zersetzt sich bei Zimmertemperatur langsam in die Elemente, der Zerfall wird durch Lichteinfluss beschleunigt. Die wässrige Lösung ("Selenwasserstoffsäure") reagiert schwach sauer; die Säurestärke (K=1,88·10) liegt in der gleichen Größenordnung wie die von HNO. 

Mit den meisten Metallen bildet Selen binäre Selenide, die das Selenid-Anion Se enthalten. Darüber hinaus sind Diselenide Se und Polyselenide Se bekannt, die durch die Reaktion eines Metalls mit einem Überschuss Selen erhalten werden können:

Die Synthese ist durch Zusammenschmelzen der Elemente oder in Lösung möglich. Die Selenide sind hydrolyse- und oxidationsempfindlich. Außer den ionischen Seleniden ist die molekulare Verbindung Kohlenstoffdiselenid, Se=C=Se, bekannt.
Selendioxid ("Selen(IV)-oxid") ist ein farbloser, kristalliner Feststoff, der durch Verbrennen von Selen an der Luft erhalten werden kann. In Wasser bildet es Selenige Säure, HSeO. Es ist ein relativ starkes Oxidationsmittel und wird leicht zu Selen reduziert.

Selentrioxid ("Selen(VI)-oxid") kann durch Entwässerung von Selensäure, HSeO gewonnen werden. Es ist ebenfalls ein kristalliner Feststoff und ein starkes Oxidationsmittel.

Daneben gibt es die festen, kristallinen, gemischtvalenten Selen(IV,VI)oxide SeO und SeO.

Selenmonoxid, SeO, ist nur als instabile Zwischenstufe bekannt.
Selensulfid SeS (eine unstöchiometrische Selen-Schwefel-Verbindung, die aus schwefelähnlichen cyklischen Molekülen variabler Größe und Zusammensetzung besteht, wegen des ungefähren Verhältnisses SeS auch "Selendisulfid" genannt).

Selenate sind die Salze der Selensäure mit den Anionen SeO. Orthoselenate wie das trigonal-bipyramidale Anion SeO und das oktaedrische SeO werden nur selten beobachtet.

Selenhexafluorid ist kann durch die Reaktion von Selen mit elementarem Fluor dargestellt werden. Es ist zwar reaktiver als Schwefelhexafluorid, reagiert aber unter Normalbedingungen nicht mit Wasser.
Die wichtigsten Selenhalogenide sind die Tetrahalogenide, ein Selentetraiodid konnte allerdings nicht synthetisiert werden. Die Tetrahalogenide können aus den Elementen dargestellt werden. Sie können als Lewis-Basen unter Bildung von :SeX wie auch als Lewissäuren (Bildung von SeX) reagieren. Die mit allen Halogenen bekannten Dihalogenide und Monohalogenide sind instabil. 

Selenorganische Verbindungen treten hauptsächlich mit den Oxidationsstufen <II, II und IV auf. Die selenorganischen Verbindungen umfassen im Wesentlichen folgende Substanzgruppen;

Durch vorsichtige Oxidation von Selen können zahlreiche "Selenpolykationen" Se dargestellt und mit einem geeigneten Gegenion kristallisiert werden. Das Gegenion muss eine schwache Lewis-Base sein, da die Selenpolykationen verhältnismäßig starke Lewissäuren sind. Geeignete Oxidationsmittel sind häufig Halogenide der Übergangsmetalle, die bei Temperaturen von typischerweise 200 °C direkt die gewünschte Verbindung ergeben:

Häufig ist die Kristallisation unter den Bedingungen des chemischen Transports erfolgreich, bisweilen müssen aber wasserfreie Lösungsmittel wie Zinn(IV)-chlorid oder Siliciumtetrabromid verwendet werden.

Ist das Metallhalogenid kein geeignetes Oxidationsmittel, wie das bei Halogeniden der Hauptgruppenelemente in der Regel der Fall ist, können die entsprechenden Tellurtetrahalogenide als Oxidationsmittel verwendet werden:

Durch Variation des Gegenions und des Reaktionsmediums konnte eine große Vielfalt von Polykationen dargestellt werden; auch gemischte Selen-Tellurpolykationen sind durch entsprechende Wahl der Reaktanten der Synthese zugänglich.




</doc>
<doc id="4546" url="https://de.wikipedia.org/wiki?curid=4546" title="Silicium">
Silicium

Silicium, auch Silizium, ist ein chemisches Element mit dem Symbol Si und der Ordnungszahl 14. Es steht in der 4. Hauptgruppe (Kohlenstoffgruppe), bzw. der 14. IUPAC-Gruppe, und der 3. Periode des Periodensystems der Elemente. In der Erdhülle ist es, auf den Massenanteil (ppmw) bezogen, nach Sauerstoff das zweithäufigste Element.

Silicium ist ein klassisches Halbmetall, weist daher sowohl Eigenschaften von Metallen als auch von Nichtmetallen auf und ist ein Elementhalbleiter. Reines, elementares Silicium besitzt eine grau-schwarze Farbe und weist einen typisch metallischen, oftmals bronzenen bis bläulichen Glanz auf.

Elementares Silicium ist für den menschlichen Körper ungiftig, in gebundener silicatischer Form ist Silicium für den Menschen wichtig. Der menschliche Körper enthält etwa 20 mg/kg Körpermasse Silicium; die Menge nimmt mit zunehmendem Alter ab.

Standardsprachlich wird das Element ‚Silizium‘ geschrieben. Die Schreibweise mit ‚c‘ ist vor allem in der chemischen Fachsprache gebräuchlich. Beide Schreibweisen entstammen dem lateinischen Ausdruck "silicia" ‚Kieselerde‘, verknüpft mit lat. "silex" ‚Kieselstein‘, ‚Fels‘.

Das englische Wort für Silicium ist . Es ist zum Beispiel in der Bezeichnung "Silicon Valley" enthalten. Die gelegentlich anzutreffende Übersetzung "Silikon" ist ein falscher Freund, denn Silikone sind eine Klasse von chemischen Verbindungen des Siliciums.

Siliciumhaltige Verbindungen, vor allem Gesteine, spielen in der Menschheitsgeschichte als Baumaterial traditionell eine wichtige Rolle. Ein typisches Beispiel für ein frühes Bauwerk aus Stein ist Stonehenge. Ein weiteres wichtiges silicathaltiges Material, das seit langer Zeit als Baumaterial dient, ist Lehm, der zunächst im Astgeflecht-Lehmbau, später in Ziegelform verwendet wurde. Zement, der ebenfalls silicathaltig ist, wurde erstmals von den Römern entwickelt.

Aufgrund ihrer scharfen Schnittkanten fanden siliciumhaltige Gesteine in der Steinzeit auch Einsatz als Werkzeuge. Bereits in vorgeschichtlicher Zeit ist zum Beispiel Obsidian als besonders geeignetes Werkzeugmaterial abgebaut und durch Handel weithin verbreitet worden. Auch Feuerstein wurde in Kreidegebieten, etwa in Belgien und Dänemark, bergmännisch gewonnen. Bei der Metallgewinnung, insbesondere bei der Stahlherstellung, wird Silicat-Schlacke zum Schutz der Herde und Öfen vor Sauerstoffzutritt und als Form aus Ton oder Sand eingesetzt; dabei wurde möglicherweise die Glasherstellung entdeckt.

Zum ersten Mal wurde im Jahre 1789 von Antoine Lavoisier vorhergesagt, dass es sich bei Silex um das Oxid eines Metalles handelt. Im Jahre 1807 postulierte Humphry Davy nach elektrochemischen Versuchen die Existenz der "Metalle" Silicium, Aluminium, Zirconium und Glucinium (Beryllium).

Im Jahre 1811 stellten der Chemiker Joseph Louis Gay-Lussac und Louis Jacques Thénard (vgl. Thénards Blau) unreines und amorphes Silicium (a-Si, die nichtkristalline, allotrope Form des Siliciums) her. Dazu setzten sie Siliciumtetrafluorid mit elementarem Kalium um. Ein ähnliches Vorgehen wurde 1824 von Jöns Jakob Berzelius in Schweden durch Umsetzung eines Hexafluorosilicates mit elementarem Kalium beschritten. Berzelius reinigte das so erhaltene amorphe Silicium durch Waschen. Er erkannte als erster die elementare Natur des Siliciums und gab ihm seinen Namen.

Der Begriff Silicium leitet sich vom lateinischen Wort "silex" (Kieselstein, Feuerstein) ab. Er bringt zum Ausdruck, dass Silicium häufiger Bestandteil vieler Minerale ist. 

Der englische Begriff wurde 1817 von dem schottischen Chemiker Thomas Thomson (1773–1852) vorgeschlagen. Die Endung "-on" soll dabei auf die chemische Verwandtschaft zu den Nichtmetallen Kohlenstoff () und Bor () hinweisen.

Die erstmalige Herstellung reinen, kristallinen Siliciums gelang im Jahre 1854 dem französischen Chemiker Henri Etienne Sainte-Claire Deville mittels Elektrolyse.

Die gesamte Erde besteht zu etwa 15 Massenprozent aus Silicium; insbesondere der Erdmantel setzt sich zu einem beträchtlichen Anteil aus silicatischen Gesteinsschmelzen zusammen. Die Erdkruste besteht zu etwa 25,8 Gewichtsprozent aus Silicium; damit ist es das zweithäufigste chemische Element nach dem Sauerstoff. Hier tritt Silicium im Wesentlichen in Form silicatischer Minerale oder als reines Siliciumdioxid auf.

So besteht Sand vorwiegend aus Siliciumdioxid. Quarz ist reines Siliciumdioxid. Viele Schmucksteine bestehen aus Siliciumdioxid und mehr oder weniger Beimengungen anderer Stoffe, etwa Amethyst, Rosen- und Rauchquarz, Achat, Jaspis und Opal. Mit vielen Metallen bildet Silicium Silicate aus. Beispiele für silicathaltige Gesteine sind Glimmer, Asbest, Ton, Schiefer, Feldspat und Sandstein. Auch die Weltmeere stellen ein gewaltiges Reservoir an Silicium dar: In Form der monomeren Kieselsäure ist es in allen Ozeanen in beträchtlichen Mengen gelöst. Insgesamt sind bisher (Stand: 2011) 1437 Siliciumminerale bekannt, wobei der seltene Moissanit mit einem Gehalt von bis zu 70 % den höchsten Siliciumanteil hat (zum Vergleich: Mineralischer Quarz hat einen Siliciumgehalt von bis zu 46,7 %).

Da Silicium in der Natur auch in gediegener, das heißt elementarer Form vorkommt, ist es bei der International Mineralogical Association (IMA) als Mineral anerkannt und wird in der Strunz’schen Mineralsystematik (9. Auflage) unter der System-Nr. 1.CB.15 (8. Auflage: I/B.05-10) in der Abteilung der Halbmetalle und Nichtmetalle geführt. In der vorwiegend im englischen Sprachraum bekannten Systematik der Minerale nach Dana trägt das Element-Mineral die System-Nr. 01.03.07.01.

Gediegenes Silicium konnte bisher (Stand: 2011) an 15 Fundorten nachgewiesen werden, davon erstmals in der Lagerstätte Nuevo Potosí auf Kuba. Weitere Fundorte liegen in der Volksrepublik China, Russland, der Türkei und in den Vereinigten Staaten.

Silicatische Mineralien werden permanent durch Reaktion mit der Kohlensäure des Wassers zu Metakieselsäure und Carbonaten abgebaut, wie am Beispiel des Calciumsilicats gezeigt werden kann:

Die unlösliche Metakieselsäure reagiert weiter mit Kohlensäure zu löslicher Orthokieselsäure:

Allerdings reagiert Orthokieselsäure mit sich selbst relativ schnell wieder zu (amorphem) Siliciumdioxid und Wasser, sofern der pH-Wert ≥ 3 ist. Die absolute Konzentration der Orthokieselsäure ist relativ gering (z. B. < ca. 7 mmol in Meerwasser).

Durch Einbau von Kieselsäure oder wasserlöslichen Silicaten in Meeresorganismen (1.), die nach dem Absterben auf den Meeresboden sedimentieren, oder durch Vulkanismus und Austritt von Magma am Meeresboden werden die silicatischen Mineralien wieder zurückgebildet (2.), und der Kreislauf ist geschlossen:

Der Zeithorizont, in dem dieser Prozess stattfindet, beträgt mehrere Millionen Jahre, ist also beträchtlich länger als im Fall des Kohlenstoffkreislaufs der belebten Natur.

Neben der bereits erwähnten essentiellen Natur des Siliciums gibt es eine Reihe von Lebewesen, die siliciumdioxidhaltige Strukturen erzeugen. Am bekanntesten sind dabei die Kieselalgen (Diatomeen), Schwämme (Porifera, Spongiaria) und Radiolarien die sich durch enzymkatalysierte Kondensation von Orthokieselsäure Si(OH) ein Exoskelett aus Siliciumdioxid aufbauen.
Auch viele Pflanzen enthalten in ihren Stängeln und Blättern Siliciumdioxid. Bekannte Beispiele sind hier der Schachtelhalm und die Bambuspflanze. Durch das aufgebaute Siliciumdioxidgerüst erhalten diese zusätzliche Stabilität.

Silicium scheint für Knochenbildung und -reifung benötigt zu werden. Bei Kälbern führte die Gabe von Orthosilicat zur Vermehrung von Kollagen in Haut und Knorpel. Die aus Tierversuchen abgeleitete wünschenswerte Zufuhr liegt bei 30 mg/d. Mangelzustände beim Menschen sind bisher nicht bekannt.

Als "Kieselerde" oder "Silicea terra" werden Präparate zum Einnehmen angeboten. Sie enthalten im Wesentlichen Kieselsäureanhydride (Siliciumdioxid) und sollen Haut, Nägel, Knochen und Bindegewebe stärken und gesund erhalten. Eine Wirkung ist wissenschaftlich nicht nachgewiesen.

Ein Überschuss an Silicium kann zur Hämolyse von Erythrocyten führen und als direkte Folge Zellveränderungen verursachen.
Elementares Silicium kann im Labormaßstab durch Reduktion, ausgehend von Siliciumdioxid oder Siliciumtetrafluorid, mit unedlen Metallen gewonnen werden. Bei Reaktion 2.) handelt es sich um ein aluminothermisches Verfahren, das jedoch nur unter Zusatz von elementarem Schwefel funktioniert, die dritte Route entspricht der Elemententdeckung:

Hochreaktives amorphes Silicium kann durch Reduktion mit Natrium oder Acidolyse von Siliciden erhalten werden:

Elementares Silicium findet in unterschiedlichen Reinheitsgraden Verwendung in der Metallurgie (Ferrosilicium), der Photovoltaik (Solarzellen) und in der Mikroelektronik (Halbleiter, Computerchips). Demgemäß ist es in der Wirtschaft gebräuchlich, elementares Silicium anhand unterschiedlicher Reinheitsgrade zu klassifizieren. Man unterscheidet Si (, Rohsilicium, 98–99 % Reinheit), Si (, Solarsilicium, Verunreinigungen kleiner 0,01 %) und Si (, Halbleitersilicium, Verunreinigungen kleiner 10). Für Solarzellen ist die Reinheit des Materials in seiner gesamten Stärke wichtig, um eine möglichst lange Ladungsträger-Lebensdauer zu gewährleisten, für viele Anwendungen in der Mikroelektronik müssen nur die oberen Schichten von etwa 20 bis 30 µm hochrein sein.

Traditionell wird das Siemens-Verfahren eingesetzt, bei dem das Silicium zunächst mit gasförmigem Chlorwasserstoff bei 300–350 °C in einem Wirbelschichtreaktor zu Trichlorsilan (Silicochloroform) umgesetzt wird.

Nach mehreren Destillationsschritten wird das Trichlorsilan in Anwesenheit von Wasserstoff in einer Umkehrung der obigen Reaktion an beheizten Reinstsiliciumstäben bei 1000–1200 °C wieder thermisch zersetzt. Das elementare Silicium wächst dabei auf die Stäbe auf. Der dabei freiwerdende Chlorwasserstoff wird in den Kreislauf zurückgeführt. Als Nebenprodukt fällt Siliciumtetrachlorid an, das entweder zu Trichlorsilan umgesetzt und in den Prozess zurückgeführt oder in der Sauerstoffflamme zu pyrogener Kieselsäure verbrannt wird. Beim Siemensverfahren entstehen pro kg Reinstsilicium 19 kg Abfall- und Nebenstoffe.

Im industriellen Maßstab wird elementares Silicium durch die Reduktion von Siliciumdioxid mit Kohlenstoff im Schmelz-Reduktionsofen bei Temperaturen von etwa 2000 °C gewonnen. Ausgangsmaterial ist Quarzsand oder Quarzkies.

Von diesem industriellen Rohsilicium (Si) wurden im Jahre 2002 etwa 4,1 Millionen Tonnen hergestellt. Es ist für metallurgische Zwecke ausreichend sauber und findet Verwendung als Legierungsbestandteil und Desoxidant für Stähle (Verbesserung der Korrosionsbeständigkeit, Unterdrückung von Zementit) sowie als Ausgangsstoff für die Silanherstellung über das Müller-Rochow-Verfahren, die schließlich vor allem zur Herstellung von Silikonen dienen. Zur Herstellung von Ferrosilicium für die Stahlindustrie (Desoxidationsmittel im Hochofenprozess) wird zweckmäßigerweise nachfolgende Reaktion unter Anwesenheit von elementarem Eisen durchgeführt.

Weitere Aufschlussmöglichkeiten von SiO sind:

Der Sodaaufschluss bei ca. 1600 °C in der Schmelzwanne:

Der Hydrothermalaufschluss bei ca. 200 °C mit Wasser im Autoklaven:

Für die Produktion von Solarzellen muss das Rohsilicium weiter zum Solarsilicium (Si) gereinigt werden. Dafür gibt es verschiedene Verfahren. Diese Verfahren sind aufgrund der vielen aufwändigen Zwischenschritte der energieintensivste Teil bei der Herstellung von Solarmodulen. Daher werden inzwischen verschiedene Herstellungsmethoden wie das UMG-Verfahren (Upgraded Metallurgical Grade) und das FBR-Verfahren (Fluidized Bed Reactor) erprobt und eingesetzt.

Eine chlorfreie Alternative stellt die Zersetzung von Monosilan dar, das nach einem Reinigungsschritt an beheizten Oberflächen oder beim Durchleiten durch Wirbelschichtreaktoren wieder zerfällt.

Das auf diesen Wegen erhaltene polykristalline Silicium (Polysilicium) ist für die Herstellung von Solarmodulen geeignet und besitzt eine Reinheit von über 99,99 %. In der Solartechnik werden genau wie beim Einsatz in der Mikroelektronik die halbleitenden Eigenschaften des Siliciums ausgenutzt.

Nur noch von historischem Interesse ist ein Verfahren, das früher von der Firma DuPont angewendet wurde. Es basierte auf der Reduktion von Tetrachlorsilan mit elementarem Zinkdampf bei Temperaturen von 950 °C.

Aufgrund technischer Probleme und dem in großen Mengen anfallenden Zinkchloridabfall wird dieses Verfahren jedoch heute nicht mehr angewendet.

Für Anwendungen in der Mikroelektronik wird hochreines, monokristallines Silicium (Si) benötigt. Insbesondere Verunreinigungen mit Elementen, die auch als Dotierelemente geeignet sind, müssen durch Tiegelziehen oder Zonenschmelzen auf Konzentrationen unterhalb bestimmter kritischer Werte gebracht werden. Der Hersteller Shin-Etsu bewirbt eine „11N“-Reinheit (= 99,999 999 999 %) seiner Ingots.

Beim "Tiegelziehen" (Czochralski-Verfahren) wird das im Siemensverfahren erhaltene Solarsilicium in Quarztiegeln geschmolzen. Ein Impfkristall aus hochreinem, monokristallinem Silicium wird in diese Schmelze gebracht und langsam unter Drehen aus der Schmelze herausgezogen, wobei hochreines Silicium in monokristalliner Form auf dem Kristall auskristallisiert und dadurch fast alle Verunreinigungen in der Schmelze zurückbleiben. Physikalischer Hintergrund dieses Reinigungsverfahrens ist die Schmelzpunkterniedrigung und Neigung von Stoffen, möglichst rein zu kristallisieren.

Alternativ wird beim Zonenschmelzen mit Hilfe einer (ringförmigen) elektrischen Induktionsheizung eine Schmelzzone durch einen Siliciumstab gefahren, wobei sich ein Großteil der Verunreinigungen in der Schmelze löst und mitwandert.

Hochreines kristallines Silicium ist derzeit das für die Mikroelektronik am besten geeignete Grundmaterial; weniger hinsichtlich seiner elektrischen Eigenschaften als vielmehr wegen der chemischen, physikalischen und technisch nutzbaren Eigenschaften von Silicium und seiner Verbindungen (Siliciumdioxid, Siliciumnitrid usw.). Alle gängigen Computerchips, Speicher, Transistoren etc. verwenden hochreines Silicium als Ausgangsmaterial. Diese Anwendungen beruhen auf der Tatsache, dass Silicium ein Halbleiter ist. Durch die gezielte Einlagerung von Fremdatomen (Dotierung), wie beispielsweise Indium, Antimon, Arsen, Bor oder Phosphor, können die elektrischen Eigenschaften von Silicium in einem weiten Bereich verändert werden. Dadurch lassen sich verschiedenste elektronische Schaltungen realisieren. Wegen der zunehmenden Bedeutung der elektronischen Schaltungen spricht man auch vom Silicium-Zeitalter. Auch die Bezeichnung "Silicon Valley" („Silicium-Tal“) für die Hightech-Region in Kalifornien weist auf die enorme Bedeutung des Siliciums in der Halbleiter- und Computerindustrie hin.

Amorphes Silicium kann mit Hilfe von Excimerlasern in polykristallines Silicium umgewandelt werden. Dies ist für die Herstellung von Dünnfilmtransistoren (Thin-Film-Transistor, TFT) für Flachbildschirme von zunehmender Bedeutung.

Silicium ist im Handel sowohl als feinkörniges Pulver als auch in größeren Stücken erhältlich.
Hochreines Silicium für die Anwendung in Solarmodulen oder in Halbleiterkomponenten wird in der Regel in Form von dünnen Scheiben aus Einkristallen, sogenannten Silicium-Wafern (siehe Abb.), produziert. Aufgrund der hohen Anfangsinvestitionen und langen Bauzeiten für die notwendigen Öfen stellen allerdings weltweit nur wenige Firmen Rohsilicium her.

Die größten Produzenten für metallurgisches Silicium sind:
Es gibt noch ca. 15 andere große Produzenten. In der Volksrepublik China gibt es eine Reihe kleinerer Werke, im Ländervergleich ist sie daher der größte Produzent.

Der Markt für Polysilicium bzw. Reinstsilicium ist seit Mitte der 2000er Jahre im Umbruch. Aufgrund des hohen Bedarfes der Solarbranche kam es schon 2006 zu einer Siliciumknappheit, und nachdem Polysilicium aufgrund der hohen Nachfrage in den Jahren 2008/2009 nicht mehr in ausreichender Menge verfügbar war, stieg sein Preis so stark, dass eine ganze Reihe von Firmen dazu überging, eigene neue Produktionsanlagen zu errichten. Aber auch die etablierten Hersteller (siehe unten) erweiterten ihre Kapazitäten stark, ganz zu schweigen von zahlreichen völlig neuen Anbietern, vor allem aus Asien, so dass die Frage, welcher dieser Hersteller am Ende in der Lage sein würde, seine Anlagen beizeiten in Betrieb zu nehmen und bei nun wieder stark gefallenen Preisen noch profitabel zu produzieren, zum Ende des Jahrzehnts schwer zu beantworten war und auch weiterhin unterschiedlich beantwortet wird.

Silicium ist wie die im Periodensystem benachbarten Germanium, Gallium, Phosphor und Antimon ein Elementhalbleiter. Der gemäß dem Bändermodell geltende energetische Abstand zwischen Valenzband und Leitungsband beträgt 1,107 eV (bei Raumtemperatur). Durch Dotierung mit geeigneten Dotierelementen wie beispielsweise Bor oder Arsen kann die Leitfähigkeit um einen Faktor 10 gesteigert werden. In solchermaßen dotiertem Silicium ist die durch die von Fremdatomen und Gitterdefekten verursachte Störstellenleitung deutlich größer als die der Eigenleitung, weshalb derartige Materialien als Störstellenhalbleiter bezeichnet werden. Der Gitterparameter beträgt 543 pm.

Der von der Wellenlänge des Lichts abhängige komplexe Brechungsindex ist im nebenstehenden Bild dargestellt. Auch hier lassen sich Informationen über die Bandstruktur ablesen. So erkennt man anhand des stark steigenden Verlaufs des Extinktionskoeffizienten "k" einen direkten Bandübergang bei 370 nm ("E" = 3,4 eV). Ein weiterer direkter Bandübergang ist bei ≈ 300 nm ("E" = 4,2 eV) zu beobachten. Der indirekte Bandübergang von Silicium ("E" = 1,1 eV) kann nur erahnt werden. Dass weitere indirekte Bandübergänge vorhanden sind, ist an der weit auslaufenden Kurve von "k" für Wellenlängen > 400 nm erkennbar.

Wie Wasser und einige wenige andere Stoffe weist Silicium eine Dichteanomalie auf: Seine Dichte ist in flüssiger Form (bei T = 1685 K) um 10–11 % höher als in fester, kristalliner Form (c-Si) bei 300 K.

In allen in der Natur auftretenden und in der überwiegenden Zahl der synthetisch hergestellten Verbindungen bildet Silicium ausschließlich Einfachbindungen aus. Die Stabilität der Si-O-Einfachbindung im Gegensatz zur C-O-Doppelbindung ist auf ihren partiellen Doppelbindungscharakter zurückzuführen, der durch Überlappung der freien Elektronenpaare des Sauerstoffs mit den leeren d-Orbitalen des Siliciums zustande kommt.
Die lange Jahre als gültig angesehene Doppelbindungsregel, wonach Silicium als Element der 3. Periode keine Mehrfachbindungen ausbildet, muss mittlerweile jedoch als überholt angesehen werden, da inzwischen eine Vielzahl synthetisch hergestellter Verbindungen mit Si-Si-Doppelbindungen bekannt sind. Im Jahre 2004 wurde die erste Verbindung mit einer formalen Si-Si-Dreifachbindung strukturell charakterisiert.

Mit Ausnahme von salpetersäurehaltiger Flusssäure (in der sich Hexafluorosilicat bildet) ist Silicium in Säuren unlöslich, da es zur Passivierung durch die Bildung einer festen Siliciumdioxid-Schicht kommt. Leicht löst es sich hingegen in heißen Alkalilaugen unter Wasserstoffbildung. Trotz seines negativen Normalpotenzials (−0,81 V) ist es in kompakter Form relativ reaktionsträge, da es sich an der Luft mit einer schützenden Oxidhaut überzieht.

Die mechanischen Eigenschaften von Silicium sind anisotrop (richtungsabhängig). Je nach gewählter Kristallorientierung nimmt der Elastizitätsmodul Werte zwischen 130 GPa und 189 GPa an. Eine allgemeine Beschreibung des elastischen Verhaltens erfolgt in Voigt-Notation wie für alle kubischen Kristalle über die drei unabhängigen elastischen Konstanten C, C und C. Die Elastizitätsmatrix ist für Silicium:
Die elastischen Konstanten haben dabei folgende Werte:
Aus den elastischen Konstanten lassen sich für die einzelnen Hauptkristallrichtungen des Siliciums (100,110 und 111) die jeweiligen Elastizitätsmoduln errechnen:

Es sind insgesamt 23 Isotope zwischen Si und Si des Siliciums bekannt. Von diesen sind drei, die Isotope Si, Si und Si, stabil und kommen in der Natur vor. Das Isotop mit dem größten Anteil an der natürlichen Isotopenzusammensetzung ist Si mit 92,223 %, Si hat einen Anteil von 4,685 % und Si von 3,092 %. Die langlebigsten instabilen Isotope sind Si, das mit einer Halbwertszeit von 153 Jahren unter Betazerfall in P (Phosphor) übergeht und Si, das mit einer Halbwertszeit von 157,36 Minuten ebenfalls unter Betazerfall zu P zerfällt. Alle anderen Isotope haben nur kurze Halbwertszeiten von Sekunden oder Millisekunden. 

Si entsteht in schweren Sternen gegen Ende ihrer Entwicklung in großen Mengen (Sauerstoffbrennen). Dies ist der Grund für den hohen Anteil von Si am gesamten Silicium (92,23 %) bzw. auch an der Häufigkeit von Silicium im Vergleich zu anderen Elementen. Derzeit (2009) wird versucht, die SI-Basiseinheit "Kilogramm" neu zu definieren als eine bestimmte Menge von Si-Atomen. Ebenfalls stabil sind die Isotope Si (4,67 % Anteil am gesamten Silicium) sowie Si (3,1 %).

Das radioaktive Isotop Si zerfällt rasch (Halbwertszeit 157,3 Minuten) durch Beta-Strahlung zu stabilem Phosphor. Dieser Umstand kann genutzt werden, um sehr homogen n-dotiertes Silicium herzustellen. Dazu wird Silicium mit Neutronen bestrahlt, durch Neutroneneinfang entsteht dann Si und folglich P. Eine für dieses Verfahren geeignete Neutronenquelle ist die Forschungs-Neutronenquelle Heinz Maier-Leibnitz. Langlebiger ist Si mit einer Halbwertszeit von 172 Jahren. Spuren dieses Isotops entstehen in der Erdatmosphäre durch Spallation von Argon durch kosmische Strahlung. Si zerfällt zu dem ebenfalls radioaktiven P (Halbwertszeit 14,3 Tage), und dann weiter zu stabilem S (Schwefel). Alle weiteren Isotope zerfallen innerhalb weniger Sekunden (vgl. Liste der Isotope).

Silicium ist als Pulver wie viele Elemente brennbar. Als Pulver und Granulat ist es reizend. Kompaktes Silicium ist ungefährlich.

Hydriertes, das heißt oberflächlich mit Wasserstoff bedecktes, poröses Silicium kann unter Lasereinstrahlung und Zunahme von Sauerstoff hochexplosiv sein, wie Forscher der Technischen Universität München zufällig entdeckt haben. Sprengungen im Mikrometerbereich sind möglich. Die Detonationsgeschwindigkeit und Detonationsenergie sind höher als bei TNT und Dynamit.

1947 entdecken John Bardeen, Walter Brattain und William Shockley den regelbaren elektrischen Widerstand, den Transistor, zunächst an einem Germaniumkristall. Es dauerte einige Zeit, bis das verbindungsfreudige Silicium in der für Halbleitereigenschaften notwendigen Reinheit isoliert werden konnte. 1958 entwickeln Robert Noyce bei Fairchild und Jack S. Kilby bei Texas Instruments unabhängig voneinander die integrierte Schaltung (IC) auf einem Silicium-Chip. Heutzutage stellt Silicium das Grundmaterial der meisten Produkte der Halbleiterindustrie dar. So dient es auch als Basismaterial für viele Sensoren und andere mikromechanischen Systeme (z. B. Hebelarm in einem Rasterkraftmikroskop). Silicium ist ebenfalls der elementare Bestandteil der meisten Solarzellen.

Im November 2005 wurde von ersten erfolgversprechenden Versuchsergebnissen mit Siliciumlasern berichtet.

Silicium wird als energiereicher Brennstoff in vielen Explosivstoffen verwendet.

Da sich Silicium beim Erstarren ausdehnt, während sich die meisten Stoffe zusammenziehen, wird es vielen Gusslegierungen zulegiert. Gusseisen enthält beispielsweise immer etwa 2 % Si. Besondere Bedeutung haben Aluminium-Silicium-Legierungen, in denen der Si-Gehalt bis 20 % betragen kann. Dies ist von allen Aluminiumgusswerkstoffen die wichtigste Sorte.

Silicium tritt in chemischen Verbindungen fast immer vierwertig auf. Demgemäß ist das Siliciumatom in Verbindungen in der Regel vierfach koordiniert. Daneben existieren aber mittlerweile eine Reihe von Verbindungen, in denen Silicium eine fünf- oder sechsfache Koordination aufweist.
Neben dem vierwertigen Silicium sind auch synthetisch hergestellte Verbindungen des zweiwertigen Siliciums (Silylene) bekannt, die jedoch meistens sehr instabil sind. Von größerer Bedeutung ist einzig das Siliciummonoxid, das als Material zur Vergütung von optischen Linsen verwendet wird.
Darüber hinaus wurde 2012 auch eine dreifach koordinierte Verbindung ähnlich der eindimensionalen Struktur von Graphen experimentell nachgewiesen, dem sogenannten Silicen.

Die gesamte Chemie des Siliciums ist im Wesentlichen durch die hohe Affinität des Siliciums zum Sauerstoff geprägt.
Silicium stellt in aller Regel den elektropositiven Partner einer chemischen Verbindung dar, obwohl auch Verbindungen mit formal negativiertem Silicium existieren. Dabei handelt es sich meistens um Silicide, bei denen Silicium auch echte Anionen ausbilden kann.

Besonders erwähnenswert ist die Inversion der Bindungspolarität von Element-Wasserstoff-Bindungen beim Übergang von Kohlenstoff zum Silicium. Hier ändert sich die Elektronegativitätsdifferenz von +0,45 (Kohlenstoff-Wasserstoff) auf −0,2, weshalb Siliciumwasserstoffverbindungen eine gänzlich andere Reaktivität als Kohlenwasserstoffe aufweisen.

Die wichtigsten Verbindungen des Siliciums kann man in folgende Klassen einteilen, von denen jeweils einige Vertreter genannt sind:

Binäre Verbindungen

Silicate

Siliciumhalogenide

Siliciumwasserstoffe

Organische Siliciumverbindungen

Polymere Siliciumverbindungen

Bis heute kommt es immer wieder vor, dass das englische Wort „“ (für Silicium) in populärwissenschaftlichen Artikeln oder bei Filmsynchronisationen fälschlich als „Silikon“ (engl. „silicone“) übersetzt bzw. ausgesprochen wird. Dies geschah beispielsweise in der Science-Fiction-Serie "Star Trek", dem James-Bond-Agententhriller "Im Angesicht des Todes" oder in der Zeichentrickserie "Die Simpsons". Beispiel: „Besteht die Lebensform aus Kohlenstoff oder aus Silikon?“

Sogar in nicht übersetzten Texten wie dem 1980er-Jahre-Hit "Monopoli" fiel Songschreiber und Interpret Klaus Lage auf die falsche Verwendung herein, denn er textete: „[…] deinen Job macht jetzt ein Stück Silikon […]“.




</doc>
<doc id="4547" url="https://de.wikipedia.org/wiki?curid=4547" title="Schwefel">
Schwefel

Schwefel (von althochdeutsch "swëbal"; lateinisch "sulpur" und gräzisiert sulphur bzw. sulfur, wie "swëbal" vermutlich von einer indogermanischen Wurzel "suel-" mit der Bedeutung ‚langsam verbrennen‘, woraus im Germanischen auch deutsch „schwelen“ entstand; die zur Benennung schwefelhaltiger Verbindungen verwendete Silbe „-thio-“ stammt vom griechischen Wort "θεῖον theĩon" „Schwefel“) ist ein chemisches Element mit dem Elementsymbol S und der Ordnungszahl 16. Er zählt zu den Chalkogenen, der sechsten Hauptgruppe des Periodensystems. In der Häufigkeit der in der Lithosphäre vorkommenden Elemente steht er an 16. Stelle. Schwefel ist ein gelber, nichtmetallischer Feststoff, der eine Vielzahl allotroper Modifikationen bildet. In der Natur kommt er sowohl gediegen als auch in Form seiner anorganischen Verbindungen vor, in diesen vor allem als Sulfid oder Sulfat.

Bestimmte Aminosäuren und Coenzyme enthalten Schwefel; in Organismen spielt er eine Rolle bei der anaeroben Energiegewinnung von Mikroorganismen. Den größten Teil des elementar gewonnenen Schwefels verwendet die chemische Industrie zur Herstellung von Schwefelsäure, einer der technisch wichtigsten und meistproduzierten Grundchemikalien. Als Komponente des sauren Regens besitzen Schwefeloxide erhebliche Umweltrelevanz.

Schwefel ist ein seit langem vom Menschen genutztes Element. Chinesen und Ägypter nutzten um etwa 5000 v. Chr. Schwefel zum Bleichen von Textilien, als Arzneimittel und zur Desinfektion. Der Papyrus Ebers beschreibt die Verwendung von Schwefel zur Behandlung von bakteriellen Entzündungen des Auges (Trachom).

Eine natürlich vorkommende Modifikation des Schwefels, genannt "Shiliuhuang", war in China seit dem sechsten Jahrhundert v. Chr. bekannt. Chinesen gewannen im dritten vorchristlichen Jahrhundert Schwefel aus Pyrit.

Das vorklassische Griechenland verwendete Schwefel als Arzneimittel und das durch Verbrennung von Schwefel entstehende Schwefeldioxid sowohl als Desinfektionsmittel zur Verhütung von Infektionskrankheiten wie der Pest als auch zur Schwefelung von Wein. Bereits um 800 v. Chr. erwähnte Homer dies in der Odyssee. Die antike Kriegsführung verwendete Schwefel als Brandwaffe oder Brandbeschleuniger. Plinius der Ältere erwähnte um das Jahr 79 n. Chr. in seinem Werk Naturalis historia die Insel Milos als Lagerstätte des Elements sowie seine Verwendung als Desinfektionsmittel, Arzneimittel und Bleiche.

Eine Abhandlung aus der Zeit der Song-Dynastie um 1044 beschreibt verschiedene Formen des chinesischen Schwarzpulvers, einer Mischung aus Kaliumnitrat, Holzkohle und Schwefel. Roger Bacon beschrieb im Jahr 1242 die Herstellung einer ähnlichen Mischung. Schwarzpulver blieb lange Zeit der einzige Spreng- und Explosivstoff. Die Rolle des deutschen Mönches Berthold Schwarz, dem die Wiederentdeckung des Schwarzpulvers meist zugeschrieben wird, ist historisch nicht eindeutig belegt.

Die Umweltauswirkungen von Schwefeloxiden aus der Verbrennung von Kohle auf die Luftqualität in London beschrieb im Jahr 1661 John Evelyn in einem Brief an Karl II. sowie in seinem Werk Fumifugium "(The Inconveniencie of the Aer and Smoak of London Dissipated)", dem ersten Buch über die Luftverschmutzung in London.

Als einen der ersten chemisch-technischen Prozesse entwickelte John Roebuck ab 1746 das Bleikammerverfahren zur Herstellung von Schwefelsäure. Im November 1777 vermutete Antoine Laurent de Lavoisier erstmals, dass Schwefel ein Element ist. Seine Versuche und Beobachtungen zum Verbrennungsverhalten von Schwefel führten letztendlich zum Fall der Phlogistontheorie. Dennoch gelangte Humphry Davy noch 1809 experimentell zu dem Ergebnis, dass Schwefel Sauerstoff und Wasserstoff enthalte. Der letztendliche Nachweis des Elementcharakters gelang im Jahr 1810 Joseph Louis Gay-Lussac und Louis Jacques Thénard bei der Überprüfung der Davy’schen Versuche.

Seit 1814 wird das Elementsymbol S nach einem Vorschlag von Jöns Jakob Berzelius, der es unter dem Namen Sulphur in seine Atomgewichtstabelle aufnahm, verwendet. Der dänische Chemiker William Christopher Zeise entdeckte um 1822 die Xanthogenate und stellte 1834 mit Ethanthiol das erste Mercaptan her.

Die Entwicklung und Patentierung des Kontaktverfahrens erfolgte im Jahr 1831 durch den Essigproduzenten Peregrine Phillips. Im britischen Patent Nr. 6096 beschreibt er die spontane Oxidation von Schwefeldioxid zu Schwefeltrioxid in Luft in Gegenwart eines Platinkatalysators. Durch nachfolgende Absorption des Trioxids in Wasser gelangte er zu Schwefelsäure. In der Folgezeit ersetzte Vanadiumpentoxid das Platin als Katalysator. Ein weiterer Meilenstein bei der Entwicklung chemisch-technischer Verfahren gelang Charles Goodyear 1839 durch die Entdeckung der Vulkanisierung von Kautschuk mit elementarem Schwefel; sie bildet die Grundlage der Kautschukindustrie. Das Verfahren legte den Grundstein für den Aufbau eines Reifenimperiums durch Frank und Charles Seiberling, die den Namen "Goodyear" im Firmennamen zu seinen Ehren wählten.

In den Jahren 1891 bis 1894 entwickelte der deutschstämmige Chemiker Hermann Frasch das Frasch-Verfahren, mit dem die 1865 in Louisiana entdeckten unterirdischen Schwefellager abgebaut werden konnten.

Im Jahr 1912 wies Ernst Beckmann kryoskopisch nach, dass rhombischer Schwefel aus S-Ringen besteht. Röntgenstrukturanalytisch gelang dieser Nachweis 1935 B. E. Warren und J. T. Burwell. Ab den 1970er Jahren stellte die Arbeitsgruppe um Max Schmidt neue allotrope Modifikationen des Schwefels her.

Schwefel kommt in vielen Erdsphären vor. Den Austausch zwischen diesen Sphären beschreibt der Schwefelkreislauf, das System der Umwandlungen von Schwefel und schwefelhaltigen Verbindungen in Lithosphäre, Hydrosphäre, Erdatmosphäre und Biosphäre sowie den Austausch zwischen diesen Erdsphären. Schwefel kommt dabei in der Oxidationsstufe −2, etwa bei Metallsulfiden und Schwefelwasserstoff, sowie −1 vor, zum Beispiel in Aminosäuren. Die Oxidationsstufe 0 (elementarer Schwefel) tritt in Sedimenten, die aus der bakteriellen Reduktion von Sulfaten stammen, wie etwa in Louisiana, oder bei Schwefelvorkommen vulkanischen Ursprungs auf. In der Oxidationsstufe +4 kommt es als Schwefeldioxid in der Atmosphäre vor und in der Oxidationsstufe +6 als Sulfat in der Hydro- und Lithosphäre.

Schwefel steht bezüglich der Elementhäufigkeit mit einem Massenanteil von

Elementarer Schwefel kommt in der Natur in mächtigen Lagerstätten, zum Beispiel in Sizilien, Polen, Irak, Iran, Louisiana, Texas und Mexiko vor. Weltweit konnte gediegener Schwefel bis 2011 an rund 1500 Fundorten nachgewiesen werden. Neben den bereits genannten Lagerstätten wurde Schwefel unter anderem in mehreren Regionen von Australien, Nord- und Südamerika, Asien und Europa gefunden. Schwefel fand sich in Mineralproben vom Meeresboden des Golfes von Mexiko, des Mittelatlantischen Rückens und des Ostpazifischen Rückens.

Schwefel tritt gediegen, das heißt in elementarer Form, in der Natur auf. Reiner Schwefel ist zwar insgesamt relativ selten, Vulkanausbrüche setzen ihn jedoch in großen Mengen frei. Er findet sich in Vulkanschloten oder an anderen postvulkanischen Erscheinungen als Resublimationsprodukt in pulvriger Form als sogenannte "Schwefelblüte". Synthetisch durch Raffinierung hergestellter Schwefel wird allerdings ebenfalls als "Schwefelblume" oder "Schwefelblüte" bezeichnet.

Elementarer Schwefel ist als eigenständiges Mineral anerkannt und wird von der International Mineralogical Association (IMA) gemäß der Systematik der Minerale nach Strunz (9. Auflage) unter der System-Nr. „1.CC.05“ (Elemente – Halbmetalle (Metalloide) und Nichtmetalle – [Gruppe] Schwefel-Selen-Iod) (8. Auflage: "I/B.03-10"). Die im englischsprachigen Raum ebenfalls geläufige Systematik der Minerale nach Dana führt das Element-Mineral unter der System-Nr. „01.03.05.01“.

Die Modifikationen β-Schwefel und Rosickýit "(γ-Schwefel)" sind ebenfalls als Minerale anerkannt, da sie in der Natur vorkommen.

Oberhalb etwa 95 °C kristallisiert Schwefel monoklin (β-Schwefel). Diese Form wandelt sich unterhalb von 95 °C rasch in den stabilen α-Schwefel um. Er kristallisiert im orthorhombischen Kristallsystem in der Raumgruppe  mit den Gitterparametern "a" = 1044 pm; "b" = 1284 pm und "c" = 2437 pm sowie 128 Formeleinheiten pro Elementarzelle.

Die Dichte von Schwefel beträgt etwa 2,0 bis 2,1 g/cm³ und seine Mohshärte etwa 1,5 bis 2,5. Meist zeigt er hellgelbe bis dunkelgelbe Kristallprismen oder Pyramidenformen, die sich auf Gesteinsflächen aus schwefelreichen Gasen durch unvollständige Oxidation von Schwefelwasserstoff (HS) oder Reduktion von Schwefeldioxid (SO) bilden. Auf einer Strichtafel hinterlässt Schwefel einen weißen Strich.

Schwefel kommt meist in "derber" Form vor, das heißt, ohne mit bloßem Auge erkennbare Kristalle, insbesondere in Sedimenten oder Sedimentgesteinen. Häufig findet er sich in Evaporiten (Salzgesteinen), wo er meistens durch Reduktion von Sulfaten entsteht.

Größere Kristalle sind durchsichtig bis durchscheinend, zeigen auf ihren Flächen einen harzigen bis fettigen Glanz und weisen folgende, optische Eigenschaften auf:
Pulvrige oder massige Aggregate sind dagegen undurchsichtig matt.

Je nach Fundort kann Schwefel in Paragenese mit verschiedenen anderen Mineralen wie beispielsweise Anhydrit, Aragonit, Calcit, Coelestin, Gips und Halit auftreten.

Wesentlich häufiger als in gediegener Form tritt Schwefel in der Natur in gebundener Form in verschiedenen Mineralen auf, vor allem in Sulfiden und in Oxiden, Halogeniden und anderen. Insgesamt waren im Jahr 2010 fast 1000 Schwefelminerale bekannt. Weitverbreitet ist Schwefel in sulfidischen Mineralen, wie Pyrit und Markasit (FeS), Kupferkies (CuFeS), Bleiglanz (PbS) und Zinkblende (ZnS). Schwermetalle liegen in der Natur oft als schwerlösliche Sulfide vor. In Form von Sulfaten, wie Sulfat-Ionen in den Meeren (etwa 0,9 g/l), Gips (CaSO · 2 HO), Schwerspat (BaSO) und anderen schwer wasserlöslichen Sulfaten kommt Schwefel natürlich vor.

Minerale mit den höchsten Schwefelgehalten sind dabei die Sulfide Patrónit (circa 71,6 %), Villamaninit (circa 55,9 %), Hauerit (circa 53,9 %), Pyrit und Markasit (jeweils circa 53,5 %).

Beispiele für Schwefelhalogenide sind Connellit und Kermesit, für Schwefeloxide Hannebachit und Kuzelit, für Schwefelcarbonate Leadhillit und Tychit, für Schwefelsulfate Cyanotrichit und Schwertmannit, für Schwefelphosphate Arsentsumebit und Chalkophyllit und für Schwefelsilikate Haüyn und Nosean.

Eine wichtige Quelle für die Gewinnung von Schwefel sind fossile Brennstoffe wie Erdöl, Erdgas und Kohle. Vor allem Erdgas enthält relativ viel Schwefelwasserstoff (HS). In Braunkohle beträgt der Schwefelgehalt bis zu 10 %.

In der Hydrosphäre tritt Schwefel meist in Form des Sulfat-Ions auf; es ist mit einer Konzentration von 7,68 % des Gesamtsalzgehaltes nach den Chlorid- und Natrium-Ionen das dritthäufigste Ion im Meerwasser. Marine Mikroorganismen nutzen Sulfat zum Abbau des am Meeresboden vorhandenen Methans. Das Sulfat wird dabei zu Schwefelwasserstoff reduziert, das von anderen Mikroorganismen in höheren Meeresschichten wieder oxidiert wird.

Im Süßwasser kommen Sulfate aus natürlichen Quellen wie Gipslagern vor und tragen maßgeblich zur Wasserhärte bei. Für Trinkwasser gilt nach der deutschen Trinkwasserverordnung ein Sulfat-Grenzwert von 240 mg/l. Sulfat-Konzentrationen über 100 mg/l gelten als korrosionsfördernd und greifen sowohl Stahl- als auch Betonkonstruktionen an.

In den oberen Regionen der Atmosphäre finden sich, etwa bedingt durch Vulkanausbrüche, schwefelreiche Partikel als Aerosole mit Partikelgrößen von 0,1 bis 1 Mikrometer. Da die Partikel Sonnenlicht in der Stratosphäre reflektieren, wird ihnen eine kühlende Wirkung auf das Weltklima zugeschrieben.

Durch Verbrennungsprozesse schwefelhaltiger Brennstoffe kommt Schwefel als Schwefeldioxid in der Troposphäre vor. Aus anthropogenen Quellen stammen etwa 35 % der Gesamtschwefeldioxidemissionen von etwa 400 Mio. Tonnen SO jährlich. Der Großteil organischer Sulfide stammt von marinem Phytoplankton, das vor allem Dimethylsulfid und Schwefelwasserstoff freisetzt und als zweitgrößte Gesamtemissionsquelle für schwefelhaltige Partikel gilt.

Schwefel kommt in der Biosphäre in vielfältiger Form vor, oft in reduzierter Form. Im Zuge des Abbaus der Biomasse durch Enzyme und Mikroorganismen wird aus organischen Stoffen Schwefelwasserstoff freigesetzt. Schwefel steht Pflanzen vor allem in Form von anionischem Sulfat aus dem Boden zur Verfügung, welches über die Wurzeln aufgenommen und verteilt wird und sich meistens unmetabolisiert im vakuolären Pflanzensaft befindet. Die Reduktion von Sulfat zu Sulfid erfordert 732 kJ mol. Schwefeldioxid wird dagegen leicht durch Blätter absorbiert und assimiliert. Sulfat ist ein Makronährelement, dessen Mangel zu Ertragsverlusten in der landwirtschaftlichen Produktion führen kann.

Von chemoautotrophen, aeroben, sulfid-oxidierenden Bakterien wird Schwefelwasserstoff mit Sauerstoff zu elementarem Schwefel oxidiert. Von phototrophen (anaeroben) Bakterien wird Schwefelwasserstoff unter anoxischen Bedingungen in anoxygener Photosynthese als Reduktionsmittel zur Assimilation von Kohlenstoffdioxid genutzt und dabei zu elementarem Schwefel oder Sulfat oxidiert.

Diatomarer Schwefel wurde zunächst im Schweif des Kometen IRAS-Araki-Alcock (C/1983 H1) nachgewiesen. Nach dem Nachweis in weiteren Kometen wird mittlerweile angenommen, dass das Vorkommen in Kometenschweifen allgegenwärtig ist. Dabei ist die Herkunft des S-Moleküls nicht geklärt.

Die Wolken der Venus bestehen zum großen Teil aus Schwefeldioxid und Schwefelsäuretröpfchen. Die Schwefelsäure entsteht photochemisch in der oberen Venusatmosphäre durch die ultraviolette Strahlung der Sonne aus Kohlenstoffdioxid und Schwefeldioxid. Die kurzwellige Strahlung setzt aus dem Kohlenstoffdioxid Sauerstoff frei, welcher mit Schwefeldioxid unter Wasseraufnahme zu Schwefelsäure reagiert.

Die Viking-Sonden entdeckten Schwefel auf dem Mars. Der Gehalt der schwefelhaltigen Verbindungen, vorwiegend als Magnesium- und Eisensulfat vorliegend, im Marsstaub lag bei bis zu drei Gewichtsprozenten. Die Bildung der Sulfate erforderte wahrscheinlich eine wässrige Umgebung und wird daher als Hinweis auf das Vorhandensein einer prähistorischen Hydrosphäre auf dem Mars gedeutet.

Auf dem Jupitermond Io wurden zahlreiche Seen aus geschmolzenem Schwefel gefunden. Das breite Farbspektrum der Schwefelablagerungen verleiht dem Mond ein farbenreiches Erscheinungsbild. Bei den Lavaflüssen, die sich über mehrere hundert Kilometer ausdehnen, wird vermutet, dass sie vornehmlich aus Schwefel oder Schwefelverbindungen bestehen.

Untersuchungen von NASA-Forschern legen nahe, dass Salze auf der Oberfläche des Jupitermondes Europa zu zwei Dritteln aus Schwefelsäure bestehen könnten. Andere glauben, dass der mutmaßliche Ozean unter der Eiskruste reich an Schwefelsäure sein könnte.

Bislang wiesen Astronomen 13 verschiedene Schwefelverbindungen im interstellaren Raum nach. Darunter sind Kohlenstoffsulfid (CS), Schwefelmonoxid (SO), Siliciumsulfid (SiS), Carbonylsulfid (COS), Schwefelwasserstoff (HS), Thioformaldehyd (HCS) und Schwefeldioxid (SO). Astronomen haben die Hoffnung, mittels der Detektion von Schwefeldioxid Vulkanismus auf extrasolaren Planeten nachzuweisen.

Die meisten Verbindungen wiesen sie in interstellaren Molekülwolken nach, deren Größe, Dichte und Temperatur die Bildung von Molekülen erlaubt und sie vor hochenergetischer Strahlung schützt. Der Nachweis der Verbindungen gelang den Wissenschaftlern mittels Radioteleskopie im Millimeter-Wellenlängenbereich.

Schwefel wird entweder als elementarer Schwefel gewonnen, der zu über 90 % weiter zu Schwefelsäure verarbeitet wird, oder in Form seines Oxids durch Rösten von sulfidischen Erzen. Elementarer Schwefel wird weltweit gewonnen und gehandelt. Die größten Produktionsstandorte liegen in den Vereinigten Staaten von Amerika, Kanada, der ehemaligen Sowjetunion und Westasien. Die Volksrepublik China ist der weltweit größte Importeur, gefolgt von Marokko und den Vereinigten Staaten. Kanada ist der größte Exporteur, gefolgt von Russland und Saudi-Arabien.

Schwefel kann aus geologischen Lagerstätten von elementarem Rohschwefel oder schwefelhaltigen Verbindungen in Kohlenwasserstoffquellen wie Erdöl, Erdgas und Kohle sowie aus sulfidischen Erzen von Schwermetallen gewonnen werden. In Form von Sulfaten steht Schwefel, zum Beispiel als Gips, in praktisch unbegrenzter Menge zur Verfügung. Die zur Zeit ökonomisch zugänglichen Quellen werden insgesamt auf 5 × 10 t Schwefel geschätzt. Weitere 600 × 10 t Schwefel werden in Form von schwefelhaltiger Kohle, Ölschiefer und -sanden vermutet. In den USA betrug im Jahr 2007 die Menge des gewonnenen elementaren Schwefels 8,2 Millionen Tonnen.

An Vulkanen und in ihrer Nähe kommen Fumarolen vor, die mit ihren Gasen neben Schwefelwasserstoff auch gasförmigen elementaren Schwefel ausstoßen, der beim Abkühlen an der Austrittsstelle kondensiert und Kristalle bildet. Im Mittelalter waren Ablagerungen von solchen Fumarolen auf Island, etwa Námafjall, eine wichtige Quelle für die Herstellung von Schießpulver in ganz Europa. In Ijen, einem Vulkankomplex im indonesischen Ost-Java, befindet sich eine Solfatare, die als größte Schwefellagerstätte Indonesiens gilt. Aus den dort etwa acht Meter dicken Schwefelbänken wird der Schwefel ausgebrochen und mit Bambuskörben aus dem Krater abtransportiert. 

Unterirdische Schwefellagerstätten wurden mittels des von Hermann Frasch entwickelten Frasch-Verfahrens hauptsächlich in den USA und in Polen ausgebeutet. Dazu werden durch darüber liegende Schichten Rohre in die Schwefellagerstätte getrieben. Durch eingespeisten Dampf und überhitztes Wasser verflüssigt der Schwefel und wird durch eingepresste Luft an die Oberfläche gefördert. Noch im Jahr 1995 betrug die jährliche Gewinnung nach diesem Verfahren 3,1 Millionen Tonnen. Die wirtschaftlich abzubauenden Vorkommen sind jedoch selten geworden. In den USA wurde die Förderung des letzten Vorkommens nach diesem Verfahren im Jahr 2001 eingestellt.

Heute fällt Schwefel in großen Mengen als Abfallprodukt bei der Abtrennung von Schwefelwasserstoff aus Erdgasen und der Entschwefelung von Erdöl mit Hilfe des Claus-Verfahrens an. Erdgas enthält bis zu 35 % Schwefelwasserstoff, Erdöl enthält in schwefelarmer Form etwa 0,5 bis 1 % Schwefel, je nach Vorkommen beträgt der Gehalt bis zu 5 % Schwefel. Der grundlegende chemische Prozess der Schwefelrückgewinnung besteht aus zwei Schritten: Im ersten Schritt verbrennt ein Drittel des Schwefelwasserstoffs zu Schwefeldioxid. Die verbleibenden zwei Drittel des Schwefelwasserstoffs reagieren mit dem Schwefeldioxid (SO) unter Komproportionierung zu Schwefel.

Die sulfidischen Erze des Eisens, Kupfers, Zinks, Bleis und anderer Metalle werden an Luft zum Metalloxid und Schwefeldioxid geröstet. Das entstehende Schwefeldioxid wird durch katalytische Oxidation zum Schwefeltrioxid aufoxidiert und direkt zu Schwefelsäure weiterverarbeitet. Die Darstellung aus Pyrit kann vereinfacht durch folgende Gleichungen beschrieben werden:

Beim Erhitzen des Pyrits unter Luftabschluss wird elementarer Schwefel gewonnen. Das Verfahren war schon im Mittelalter bekannt.

Im Claus-Prozess fällt Schwefel flüssig an und wird meist so gelagert und transportiert. Das hat gegenüber dem Umgang mit festem Schwefel eine Reihe von Kosten- und Qualitätsvorteilen, denn fester Schwefel muss vor der Verwendung ohnehin häufig verflüssigt werden. Bei der Lagerung von festem Schwefel kann sowohl durch Luftfeuchtigkeit als auch durch Schwefelbakterien unerwünschte Schwefelsäure gebildet werden. Durch Korrosion gebildetes Eisensulfid wirkt in feiner Verteilung pyrophor und kann Brände oder Explosionen verursachen.

Flüssiger Schwefel wird bei 135 bis 140 °C abgefüllt; die Temperatur darf beim Transport 118 °C nicht unter- und 160 °C nicht überschreiten. Er wird durch Beheizung mit Niederdruckdampf von 3 bis 4 bar im flüssigen Zustand gehalten und per Schiff, in Kesselwagen oder in speziell ausgerüsteten Tankwagen transportiert. Zuvor muss flüssiger Schwefel so weit wie möglich von Schwefelwasserstoff befreit werden. Eine vollständige Entgasung ist meist nicht möglich. Das führt bei offenem Umgang mit flüssigem Schwefel zu Geruchsbelästigung. In Rohrleitungen eingefrorener Schwefel muss auf Grund des hohen Wärmeausdehnungskoeffizienten vorsichtig – konkret: langsam räumlich fortschreitend – aufgetaut werden, da zu schnelles Auftauen zum Bersten der Leitung führen kann.

Die physikalischen Eigenschaften des Schwefels sind stark temperaturabhängig, da bei gegebener Temperatur eine Reihe allotroper Modifikationen vorliegen können. Wird Schwefel auf über 119 °C erhitzt, bildet sich zunächst eine niedrigviskose Flüssigkeit hellgelber Farbe, in der überwiegend S-Ringe vorhanden sind. Wird die Temperatur gehalten, kommt es durch eine Teilumwandlung der S-Ringe in kleinere Ringe zu einer Schmelzpunkterniedrigung, die ihr Minimum bei 114,5 °C hat. Beim weiteren Erhitzen nimmt die Viskosität weiter zu und erreicht bei 187 °C ihr Maximum. Dabei brechen die Schwefelringe auf und bilden langkettige Moleküle, ein Beispiel einer ringöffnenden Polymerisation. Oberhalb dieser Temperatur zerfallen die Ketten wieder in kleinere Bruchstücke und die Viskosität nimmt wieder ab.

Schwefel ist das Element mit den meisten inter- und intramolekularen allotropen Modifikationen. Intermolekulare Allotrope sind Festkörperphasen eines Elements, die sich in der Kristallstruktur unterscheiden. Bislang sind etwa 30 verschiedene Allotrope bekannt. Die bei Normalbedingungen thermodynamisch stabilen Formen bestehen alle aus S-Ringen. Daneben existiert eine Reihe intramolekularer Allotrope in Form von Ringen verschiedener Größe sowie Ketten unterschiedlicher Länge.

Natürlich vorkommender fester Schwefel besteht aus S-Molekülen, in denen die Schwefelatome ringförmig in einer so genannten Kronenform angeordnet sind. Cyclooctaschwefel kommt in drei intermolekularen Allotropen vor.

Die bei Raumtemperatur thermodynamisch stabilste Modifikation des Schwefels ist der orthorhombisch kristallisierende α-Schwefel. Er ist geruch- und geschmacklos und hat die typische schwefelgelbe Farbe. α-Schwefel kristallisiert orthorhombisch in der Raumgruppe  mit den Gitterparametern "a" = 1044 pm, "b" = 1284 pm und "c" = 2437 pm sowie 16 Formeleinheiten S pro Elementarzelle.

α-Schwefel tritt gediegen als "Schwefelblüte" "(Gelber Schwefel)" in der Natur auf, hat eine Dichte von 2,0 g/cm³ bis 2,1 g/cm³, eine Härte von 1,5 bis 2,5 und eine hell- bis dunkelgelbe Farbe sowie eine weiße Strichfarbe. Meist zeigt er hellgelbe prismen- oder pyramidenförmige Kristalle, die sich auf Gesteinsflächen aus schwefelreichen Gasen durch unvollständige Oxidation von Schwefelwasserstoff oder Reduktion von Schwefeldioxid bilden.

Bei 95,6 °C liegt der Umwandlungspunkt zu β-Schwefel. Diese Schwefelmodifikation ist fast farblos und kristallisiert monoklin in der Raumgruppe  mit den Gitterparametern "a" = 1085 pm; "b" = 1093 pm; "c" = 1095 pm und β = 96,2° sowie 6 Formeleinheiten S pro Elementarzelle. Wird β-Schwefel auf 100 °C erhitzt und schnell auf Raumtemperatur abgekühlt, ist diese Modifikation mehrere Wochen beständig.

Seltener ist der ebenfalls monoklin kristallisierende γ-Schwefel (Rosickýit) mit der Raumgruppe  und den Gitterparametern "a" = 844 pm; "b" = 1302 pm; "c" = 936 pm und β = 125,0° sowie 4 Formeleinheiten S pro Elementarzelle. Das Mineral wird im Death Valley in den USA gefunden, wo es durch mikrobiologische Reduktion von Sulfat entsteht und stabilisiert wird.

Cyclohexaschwefel S, bekannt als Engels-Schwefel, liegt in einer Sessel-Konformation mit hoher Ringspannung vor. Die orangefarbigen, rhomboedrischen Kristalle können durch verschiedene Methoden hergestellt werden. Engel stellte bereits 1891 Cyclohexaschwefel durch Ansäuern einer Natriumthiosulfat-Lösung mit Salzsäure her.

Die Dichte beträgt 2,21 g/cm³, der Schmelzpunkt liegt bei etwa 100 °C. Unter Normalbedingungen wandelt sich Cyclohexaschwefel innerhalb weniger Tage in Cyclooctaschwefel um.

Cycloheptaschwefel kann durch Reaktion von Cyclopentadienyl-Titan-pentasulfid mit Dischwefeldichlorid hergestellt werden.

Cycloheptaschwefel liegt je nach Herstellungsbedingungen in vier verschiedenen intermolekularen allotropen Modifikationen vor (α-, β-, γ-, δ-Cycloheptaschwefel). Diese sind alle temperaturempfindlich und wandeln sich bei Temperaturen oberhalb von 20 °C schnell in die thermodynamisch stabile Form um. Bei einer Temperatur von −78 °C sind die Modifikationen jedoch längere Zeit haltbar. Die im Ring vorkommenden Schwefel-Schwefel-Bindungslängen liegen zwischen 199,3 und 218,1 pm.

Größere Schwefelringe (S mit "n" = 9 – 15, 18, 20) können mittels der Cyclopentadienyl-Titan-pentasulfid-Methode oder durch Reaktion von Dichlorsulfanen SCl mit Polysulfanen HS gebildet werden.

Von Cyclononaschwefel S liegen vier intermolekulare Allotrope vor, von denen zwei, α- und β-Cyclononaschwefel genannt, charakterisiert sind.

Mit Ausnahme des Cyclododecaschwefels S sind die intramolekularen Bindungslängen und -winkel in den Schwefelmodifikationen unterschiedlich. Cyclododecaschwefel ist nach Cyclooctaschwefel die stabilste Modifikation. Von Cyclooctadecaschwefel S liegen zwei intermolekulare Modifikationen als Ring-Konformationsisomere vor.

Polymerer Schwefel besteht aus langen polymeren Schwefelketten, genannt Catenapolyschwefel. Die Natur der Endgruppe ist nicht bekannt. Das Polymer wird durch Erhitzen auf Temperaturen oberhalb von 120 °C und anschließendes schnelles Abkühlen in kaltem Wasser oder flüssigem Stickstoff gewonnen. Die maximale Kettenkonzentration findet sich bei Temperaturen zwischen 250 und 300 °C. Vorliegende Schwefelringe können mit Kohlenstoffdisulfid extrahiert werden.

Beim Erhitzen auf 119,6 °C schmilzt der β-Schwefel. Die Schmelze besteht anfangs aus Cyclooctaschwefel-Molekülen, so genanntem λ-Schwefel (Schwefelblüte, S). Nach einer Zeit stellt sich ein Gleichgewicht zwischen den verschiedenen intramolekularen Allotropen in der Schmelze ein, wobei andere Ringe (v. a. S, S, S) temperaturabhängig auftreten. Es treten auch wesentlich größere Ringe wie S sowie bei höheren Temperaturen Kettenstrukturen auf.

Bei weiterer Erhöhung der Temperatur nimmt die Konzentration der kleineren Ringe zunächst zu und die Viskosität ab, so genannter π-Schwefel mit S (6 ≤ "n" ≤ 25, "n" ≠ 8). Ab einer Temperatur von 159 °C beginnt der so genannte λ-Übergang, bei dem die Ringe durch thermische Anregung aufbrechen und durch Polymerisation lange Ketten bilden. Der polymere Schwefel erreicht sein Viskositätsmaximum bei 187 °C. Am λ-Übergang ändern sich eine Reihe physikalischer Eigenschaften, zum Beispiel die Viskosität, die optische Absorption und damit auch die Farbe. Es liegt so genannter ω-Schwefel vor. Wird dieser rasch abgekühlt, liegt er nach Extraktion mit Kohlenstoffdisulfid in fester Form als amorpher, plastischer μ-Schwefel vor, mit S (10 ≤ "n" ≤ 10).

Durch weiteres Erhitzen bis zum Siedepunkt bei 444,6 °C zerfallen die Ketten wieder in kleinere Bruchstücke, und die Viskosität der Schmelze nimmt ab.

Gasförmiger Schwefel ist dunkelrot und besteht anfangs aus S-Ringen, die bei höheren Temperaturen weiter aufbrechen. Bei einer Temperatur von 330 °C besteht der Dampf vorwiegend aus Cycloheptaschwefel S. Bei Temperaturen oberhalb von 550 °C zerfallen die Ringe in kleinere Moleküle wie S. Oberhalb von 700 °C enthält der Dampf vornehmlich S-Moleküle und bei 1800 °C liegt Schwefel in Form einzelner Atome vor.

Die Erhitzung des gasförmigen Schwefels ist mit intensiven Farbänderungen verbunden. Zunächst hat der Schwefeldampf die gleiche gelbe Farbe wie eine Cyclooctaschwefelschmelze. Bei weiterem Erhitzen verändert sich die Farbe von gelb über orange und dunkelrot nach dunkelrotbraun. Das ist auf das Vorliegen der linearen S-Spezies zurückzuführen.

Neutrale Schwefelmoleküle können durch Oxidation beziehungsweise Reduktion die Oxidationsstufe ändern. Schwefelmoleküle mit der Oxidationsstufe +2 sind beispielsweise die hellgelben S-Kationen, die roten S-Kationen und die S-Kationen. Man erhält diese geladenen Schwefelmoleküle durch Reaktion mit Arsenpentafluorid oder Antimonpentafluorid:

Die Ringstruktur der Schwefelmoleküle bleibt hierbei erhalten, wobei sich die ursprüngliche Konformation jedoch ändert.

Cyclooctaschwefel kann durch Sulfidionen zu einem offenkettigen Nonasulfidion mit der Oxidationsstufe −2 reduziert werden. Dieses geladene Schwefelmolekül ist aber nicht stabil und spaltet sich leicht in kürzere kettenförmige Polysulfide auf.

Wasserfrei lassen sich solche Schwefelanionen durch Reduktion mit unedlen Metallen herstellen. Auch in diesem Fall wird die cyclische Struktur in eine kettenförmige Struktur verwandelt.

Schwefel ist ein reaktionsfreudiges Element und reagiert bei erhöhter Temperatur mit vielen Metallen außer Platin, Iridium und Gold unter Bildung von Sulfiden. Mit Quecksilber reagiert Schwefel bereits beim Verreiben bei Raumtemperatur zu Quecksilbersulfid. Mit Halb- und Nichtmetallen reagiert Schwefel bei erhöhter Temperatur. Ausnahmen sind Tellur, molekularer Stickstoff, Iod und Edelgase.

An Luft entzündet sich Schwefel ab einer Temperatur von etwa 250 °C und verbrennt mit blauer Flamme unter Bildung von Schwefeldioxid. Der Zündpunkt kann durch im Schwefel gelöste Gase wie Schwefelwasserstoff und Schwefeldioxid gesenkt werden. An feuchter Luft bildet Schwefel im Laufe der Zeit Schwefelsäure und Schwefeldioxid.

Schwefel reagiert nicht mit nicht-oxidierenden Säuren, von oxidierenden Säuren wie Salpetersäure wird Schwefel zu Sulfat oxidiert. In alkalischer Lösung reagiert Schwefel unter Disproportionierung zu Sulfid und Sulfit. In sulfidischer Lösung löst sich Schwefel unter Bildung von Polysulfiden. In sulfithaltiger Lösung reagiert Schwefel zu Thiosulfat.

In der Organischen Chemie wird elementarer Schwefel zum Beispiel in der Asinger-Reaktion zur Darstellung von 3-Thiazolinen verwendet. Die Gewald-Reaktion – ebenfalls eine Mehrkomponentenreaktion – ermöglicht die Synthese substituierter 2-Aminothiophene, ausgehend von elementarem Schwefel. Mit Grignard-Verbindungen reagiert Schwefel unter Bildung von Thioethern oder Thiolen. Cyclohexan wird unter Freisetzung von Schwefelwasserstoff zu Benzol dehydriert.

Von Schwefel sind 23 Isotope zwischen S und S bekannt, von denen vier stabil sind: S (95,02 %), S (0,75 %), S (4,21 %) und S (0,02 %). Von den radioaktiven Isotopen hat nur das S-Isotop eine Halbwertszeit von 87,51 Tagen, für alle anderen Isotope liegt die Halbwertszeit im Bereich von Sekunden oder Millisekunden. Das S-Isotop entsteht aus Ar durch kosmische Strahlung.

Bei der Fällung von sulfidischen Mineralien kann es je nach Temperatur und pH-Wert zu unterschiedlichen Isotopenverteilungen zwischen Feststoff und Mutterlösung kommen. Die Bestimmung der Schwefel-Isotopenverteilung im Mineral lässt daher Rückschlüsse auf die Bildungsbedingungen zu. Beim Abbau von Sulfaten durch bakterielle Sulfatreduktion kommt es zu einer Isotopenfraktionierung des Schwefels. Die Untersuchung der Schwefel-Isotopenverteilung im gelösten Sulfat lässt daher Rückschlüsse auf biologische Reduktionsprozesse zu.

Schwefel wird sowohl in der chemischen Industrie als auch in der pharmazeutischen Industrie genutzt, unter anderem zur Produktion von Schwefelsäure, Farbstoffen, Insektiziden und Kunstdüngern.

Der mengenmäßig größte Teil des Schwefels, etwa 90 %, wird zur Herstellung von Schwefelsäure mittels des Kontaktverfahrens verwendet. Dabei wird im ersten Schritt durch Verbrennen von Schwefel oder durch das Rösten von Metallsulfiden Schwefeldioxid hergestellt. Dieses wird mit Luft in einer Gleichgewichtsreaktion an einem Vanadiumpentoxid-Katalysator zu Schwefeltrioxid umgesetzt.

Etwa 60 % der Schwefelsäure wird zur Herstellung von Düngemitteln verwendet. Beim Aufschluss von Rohphosphat mit Schwefelsäure entsteht Superphosphat, ein Gemisch aus Calciumdihydrogenphosphat (Ca(HPO)) und Calciumsulfat (CaSO · 2HO).

Weitere schwefelhaltige Dünger sind Ammoniumsulfat und Kaliumsulfat. Daneben dient die Schwefelsäure zum Aufschluss von Erzen, der Herstellung von Caprolactam, als Katalysator bei der Alkylierung von Olefinen, zur Herstellung anderer Säuren wie Fluorwasserstoff sowie in der Papierherstellung nach dem Sulfat-Verfahren. Daneben findet Schwefelsäure Anwendung in zahlreichen anderen Prozessen, wie etwa der Herstellung von Phenol und Aceton nach dem Cumolhydroperoxid-Verfahren.

Gasförmiges Schwefeltrioxid findet weite Verwendung bei der Herstellung von Tensiden durch Sulfonierung von Dodecylbenzol zu Dodecylbenzolsulfonsäure sowie der Sulfatierung von Fettalkoholen und deren Ethoxylaten.

Reiner Schwefel wird sehr häufig bei der Vulkanisation von Kautschuk verwendet. Dazu wird Rohkautschuk mit Schwefel oder schwefelhaltigen Verbindungen versetzt, ein Verfahren, das schon 1839 von Charles Goodyear entwickelt wurde. Die Kautschukpolymerketten werden dadurch unter Ausbildung von Sulfidbrücken aus einem oder mehreren Schwefelatomen vernetzt und so besonders widerstandsfähig gemacht. Der Markt für vulkanisierbare Elastomere in den Vereinigten Staaten betrug im Jahr 2001 5,7 Milliarden US-Dollar.

Im Europäischen Arzneibuch wird nur "Schwefel zur äußeren Anwendung" (Sulfur ad usum externum) geführt. Der pulverförmige Schwefel bildet auf der Haut Schwefelwasserstoff und andere Sulfide, welche wiederum bakteriostatisch wirken. Bei oraler Einnahme kommt eine laxierende Wirkung hinzu. Schwefel wirkt darüber hinaus fungizid und kann Parasiten abtöten. Schwefel wurde vor allem in der Vergangenheit zur Behandlung von Acne vulgaris, von Skabies und von oberflächlichen Mykosen verwendet. Die Anwendung erfolgt meist in Form von Seifen, Salben und Gelen.

Sulfur (Kürzel "Sulph") gilt in der Homöopathie als eine der vierzehn wichtigsten Grundsubstanzen.

In der Schwerindustrie ist Schwefel als Legierungselement für Stahl bedeutend. Automatenstähle, die für die spanenden Fertigungsverfahren wie Drehen und Bohren optimiert sind, sind oft schwefellegiert. Durch den Schwefelzusatz entstehen weiche, zeilenförmig ausgeprägte Mangansulfideinschlüsse im Stahl, die zu erhöhtem Spanbruch führen.

An Luft, besonders bei erhöhter Feuchtigkeit, entwickelt Schwefel leicht Schwefeldioxid und bei weiterer Oxidation Schwefelsäure. Das kann zu Korrosion und Schäden an Stahlkonstruktionen oder Lagertanks führen.

Schwefelspezies in Kohlenwasserstoffen sind starke Katalysatorgifte, die schon in geringer Konzentration wirksam sind. Schwefel reagiert mit den katalytisch aktiven Metall- und anderen Oberflächenzentren der Katalysatoren. Die Vergiftung kann reversibel oder irreversibel sein und der Katalysator kann dabei in seiner Selektivität verändert oder insgesamt deaktiviert werden. Einige Katalysatoren, wie Platin-Rhenium-Katalysatoren für das Katalytische Reforming, werden selektiv mit Schwefel beaufschlagt, um die Anfangsaktivität des Katalysators zu beeinflussen.

Bei älteren Drei-Wege-Katalysatoren wurde als Sulfat auf dem Katalysator gespeicherter Schwefel beim Betrieb im Luftunterschuss als Schwefelwasserstoff freigesetzt. Bei Fahrzeugen mit Magermix-Ottomotor und Speicher-Kat kann es durch Sulfatbildung zu einer Deaktivierung des Katalysators kommen. Zur Regeneration wird die Abgastemperatur auf 650 Grad Celsius erhöht und das gespeicherte Sulfat als Schwefeldioxid emittiert.

Schwefel findet bei der Herstellung von Schwarzpulver, als Salpeterschwefel in der Feuerwerkerei, oder bei anderen Explosivstoffen Verwendung.

Beim so genannten "Schwefeln" handelt es sich um eine Konservierungsmethode für Lebensmittel, wie z. B. Wein oder Trockenobst, mittels Schwefeldioxid oder Schwefelsalzen, wobei deren reduktive Eigenschaften (Antioxidans) genutzt werden. Früher wurde das Schwefeln von Wein durch das Abbrennen von Schwefel in leeren Weinfässern erreicht, heute wird Kaliumpyrosulfit zugegeben, welches in saurer Lösung Schwefeldioxid freisetzt.
Als protektives Kontaktfungizid wirkt Schwefel vorbeugend durch Kontakt an der Pflanzenoberfläche, wo es langsam zu Schwefeldioxid oxidiert wird und die Sporenkeimung hemmt. Verbreitet ist der Einsatz im Weinbau gegen den an der Blattoberfläche wachsenden Echten Mehltaupilz.
Der Farbstoff Ultramarin wird durch das Verbrennen eines Gemisches aus Schwefel, Kaolin, Natriumsulfat, Soda und Aktivkohle erhalten. Die tiefblaue Farbe des Ultramarins rührt von in Sodalith-Käfigen eingesperrten Polysulfid-Radikalionen des Typs S her, die für die Farbgebung im Lapislazuli verantwortlich sind.

Eine weitere Entwicklung ist die Natrium-Schwefel-Zelle, ein wiederaufladbarer Akkumulator, der primär bei kleineren bis mittleren stationären Batterie-Speicherkraftwerken in Japan Anwendung findet. Die Zelle arbeitet bei einer Temperatur von circa 300 bis 350 °C. Als positive Elektrode dient flüssiger Schwefel, als fester Elektrolyt eine Keramik aus Natrium-β-aluminat (NaAlO) und als negative Elektrode flüssiges Natrium. Die elektrochemische Bruttoreaktion ist:

Schwefel oder Schwefelverbindungen werden als Schmierstoffadditive eingesetzt. Die in Drahtziehereien eingesetzten Ziehfette bestanden aus natürlichen Fetten, denen Schwefelblüte beigemischt wurde. Dieses bildet auf der Metalloberfläche eine Schicht von Metallsulfiden, bei Eisen etwa Eisen(II)-sulfid (FeS), Eisen(II)-disulfid (FeS) oder Eisen(III)-sulfid (FeS), die als Schmierstoff wirken. Molybdän(IV)-sulfid ist unter dem Handelsnamen "Molykote" bekannt und dient auf Grund seiner graphitartigen Struktur als festes Schmiermittel. Als Extreme-Pressure-Additiv werden Schwefelverbindungen noch heute Schmierstoffen beigefügt.

In der organischen Chemie wird Schwefel zur Synthese von 3-Thiazolinen in der Asinger-Reaktion – einer Mehrkomponentenreaktion – benutzt.

Schwefelverbindungen kommen in allen Lebewesen vor und haben eine Vielzahl von Funktionen. Schwefel wird als Sulfid oder Sulfat von Pflanzen und Bakterien aus der Umgebung assimiliert und zu organischen Schwefelverbindungen aufgebaut, die letztlich von Tieren mit der Nahrung aufgenommen werden.

Schwefel ist in den proteinogenen Aminosäuren Cystein und Methionin – und in allen darauf aufbauenden Peptiden, Proteinen, Koenzymen und prosthetischen Gruppen – in Form von Thiolgruppen (Oxidationsstufe +II) oder Thioethergruppen enthalten. Andere schwefelhaltige Aminosäuren mit biologischer Funktion sind Cystin und Homocystein. Weiterhin ist er in einigen Cofaktoren (Biotin, Thiaminpyrophosphat) in heterozyklischer Bindung enthalten. Schwefel ist damit ein essentielles Element lebender Zellen. Disulfidbrückenbindungen sind weit verbreitet und tragen einerseits zur Ausbildung und Stabilisierung von Proteinstrukturen (z. B. im Keratin menschlicher und tierischer Haare und Federn) bei, andererseits basieren viele Redoxreaktionen in Zellen auf der Umkehrbarkeit dieser Bindung (in Thioredoxin und Glutathion). In oxidierter Form spielt Schwefel in der Aminosulfonsäure Taurin (Oxidationsstufe +IV) eine biologische Rolle.

Der Gesamtschwefelgehalt des menschlichen Körpers liegt bei etwa 0,25 %, wobei der Gehalt je nach Gewebeart schwanken kann. In den Globinen von Säugetieren wurde ein Gesamtschwefelgehalt zwischen 0,37 % beim Schwein und 0,6 % beim Menschen bestimmt. Zum Beispiel besteht Keratin im Horn von Pferden bis zu 5 % aus Schwefel.

Schwefelhaltige Pflanzenstoffe wie die Cysteinsulfoxide Methiin, Alliin, Isoalliin und Propiin können bis zu 5 % der Trockenmassen von Pflanzen, zum Beispiel bei den als Gewürzmittel genutzten Pflanzen der Gattung Allium wie Knoblauch und Zwiebel, ausmachen. Daneben entstehen durch enzymatische Aktivität oder Oxidation an Luft sekundäre Aromakomponenten wie Diallyldisulfid oder Allicin, die zum Teil für den typischen Geruch und Geschmack dieser Pflanzen verantwortlich sind.

Übergangsmetallsulfide, besonders die des Eisens, bilden die aktiven Zentren einer Reihe von Enzymen. So sind die Ferredoxine eisen- und schwefelhaltige Proteine, die als Elektronenüberträger in metabolischen Reaktionen teilnehmen. Das Ferredoxin im menschlichen Metabolismus wird Adrenodoxin genannt. Komplexe Metalloenzyme wie Nitrogenase, das in der Lage ist, elementaren, molekularen Stickstoff (N) zu reduzieren, sowie Hydrogenase und Xanthinoxidase, weisen Eisen-Schwefel-Cluster auf.

Der für alle genannten Stoffe notwendige Schwefel wird von Tieren je nach Ernährung als schwefelhaltige Aminosäuren und Vitamine mit der Nahrung aufgenommen. Pflanzen und Bakterien wiederum sind in der Lage, Schwefel als Sulfid oder Sulfat zu assimilieren und die genannten Aminosäuren und Vitamine selbst zu synthetisieren.

Im Pflanzenbau werden je nach Pflanzenart etwa 15 bis 50 kg Schwefel pro Hektar in Form schwefelhaltigen Düngers benötigt. Ölpflanzen, Hülsenfrüchte, verschiedene Futterpflanzen und Gemüse benötigen dabei größere Schwefelmengen.

Einige Untergruppen der Proteobakterien, zusammen die "farblosen schwefeloxidierenden Bakterien" genannt, können Schwefelverbindungen und Schwefel oxidieren und aus diesen exergonen Reaktionen Energie gewinnen; siehe dazu exemplarisch das Riesenbakterium "Thiomargarita namibiensis". Außerdem sind die Grünen Schwefelbakterien in der Lage, Photosynthese zu betreiben, indem sie Schwefelwasserstoff, Schwefel oder Thiosulfat an Stelle von Wasser (HO) als Elektronendonator für die Reduktion von CO verwenden. Diese Art von Photosynthese erzeugt keinen Sauerstoff („anoxygen“). Zuletzt können einige Cyanobakterien diesen Stoffwechselweg benutzen. Zwar haben Pflanzen und Tiere in ihren Mitochondrien Enzyme für die Oxidation von Sulfid, diese kommen aber nur noch zur Entgiftung des beim Abbau überschüssigen Cysteins und im Darm entstehenden Schwefelwasserstoffs zum Zuge.

Der Schwefel wird bei Gefäßpflanzen als Sulfat über die Wurzeln aufgenommen und über das Xylem in die Blätter transportiert, wo der überwiegende Teil der Assimilation gekoppelt an die Photosynthese in den Chloroplasten der Mesophyllzellen stattfindet. Die Assimilationsrate beträgt dabei nur rund fünf Prozent der Nitrat-Assimilation und ein bis zwei Promille der CO-Assimilation. Das Grundschema gleicht dabei der Nitrat-Assimilation, der Energieverbrauch ist aber beim Schwefel wesentlich höher.

Das Sulfat wird zunächst zu Sulfit reduziert, dieses dann weiter zu Schwefelwasserstoff. Dieser wird in Cystein gebunden, der ersten stabilen Verbindung der Schwefel-Assimilation:

Sulfat muss im Chloroplasten zunächst aktiviert werden. Das Enzym Sulfat-Adenylyltransferase bildet aus Sulfat und ATP AMP-Sulfat (APS) und Pyrophosphat. Das Gleichgewicht dieser Reaktion liegt stark auf der Seite des ATP, die Bildung von APS ist nur möglich durch die hohe Aktivität der Pyrophosphatase in den Chloroplasten. Anschließend hängt die APS-Kinase an den Ribose-Rest der APS einen weiteren Phosphat-Rest an und bildet das 3-Phospho-AMP-Sulfat (PAPS). Das derart aktivierte Sulfat wird durch die PAPS-Reduktase unter Mitwirkung von Thioredoxin zu Sulfit reduziert, das im Zuge dieser Reaktion vom 3-Phospho-AMP abgespalten wird.

Die Sulfit-Reduktase gleicht in ihrem Aufbau der Nitritreduktase, sie enthält ein Sirohäm und ein 4-Eisen-4-Schwefel-Zentrum. Unter Verbrauch von sechs reduzierten Ferredoxin bildet sie Schwefelwasserstoff. In heterotrophem Gewebe wie Wurzeln wird das reduzierte Ferredoxin nicht durch die Photosynthese bereitgestellt, sondern durch NADPH reduziert.

Um den Schwefelwasserstoff an Serin binden zu können, muss dieses zunächst aktiviert werden. Das geschieht durch die Serin-Transacetylase, die einen Acetylrest von Acetyl-Coenzym A auf das Serin überträgt. Für die Bildung des Acetyl-Coenzym A werden zwei energiereiche Phosphate verbraucht. Der Schwefelwasserstoff wird schließlich durch die O-Acetylserin-(thiol)-Lyase auf das O-Acetylserin übertragen, wobei Cystein und Acetat entstehen.

Bei der Energiegewinnung aus fossilen Brennstoffen wie Steinkohle, Braunkohle und Erdöl werden große Mengen Schwefeldioxid SO freigesetzt. Dieses bleibt als Gas oder im Wasser der Wolken gelöst zunächst in der Erdatmosphäre. Auch bildet es einen Bestandteil des gesundheitsgefährdenden Smogs. Abgebaut werden kann es, indem es von Sauerstoff zu Schwefeltrioxid SO oxidiert wird und als Schwefelsäure HSO mit dem Regen ausgespült wird. Daraus ergibt sich ein weiteres Problem, da diese als Bestandteils des sauren Regens zur Versauerung der Böden beiträgt.

Seit den 1970er-Jahren sind deshalb Maßnahmen zur Rauchgasentschwefelung (REA) in Deutschland gesetzlich vorgeschrieben. Das geschieht meist durch Kalkwäsche. Dabei werden die Rauchgase in einem Absorber mit Calciumhydroxid-Lösung besprüht, wodurch sich das Schwefeldioxid unter Weiteroxidation in Calciumsulfat (Gips) umsetzt.

Daneben wird seit einigen Jahren die Entschwefelung von Fahrzeugkraftstoffen forciert. Durch diese Vorschriften und ihre Umsetzungen konnten die Schwefel(dioxid)emissionen seit den 1960er-Jahren drastisch reduziert werden.

Erdgas und Kokereigas enthalten ab Quelle variierende Mengen an Schwefelwasserstoff. Niedrigsiedendes Benzin enthält von Natur aus praktisch keinen Schwefel. Höhersiedende Erdölfraktionen, wie Diesel und schwerere Öle enthalten typisch mehr Schwefel, etwa als Thiole. Heizöl extraleicht, das in Wohnungen verheizt wird und Dieseltreibstoff, der ebenfalls zivilsationsnah und auf Land verbraucht wird, wurden in Europa ab etwa 1999 im Schwefelgehalt reduziert. Heiz- und Kraftwerke setzen am Land große Mengen Schweröl mit vergleichsweise hohem Schwefelgehalt um und werden verfahrenstechnisch zweckmässig im Rauchgas entschwefelt. Da Schiffsdiesel, die ebenfalls Schweröl verbrennen, auf See eher landfern emittieren wurden hier erst spät, ab 2012, Emissionslimits für Schwefel (SO) vorgeschrieben; auch hier wird erst im Abgas entschwefelt.

Durch sauberere Verfahren wurde die Produktion von Sulfitzellulose in Papierfabriken und Viskosefaser geruchsärmer. In den 1970er Jahren war kilometerweiter Geruch vom hohen Schlot des Chemiefaserwerks Lenzing noch üblich und diente Anrainern am Attersee als Schönwetter-Windrichtungsanzeiger. Geruchsträger sind hier Thiole und Schwefelwasserstoff.

Die Internationale Seeschifffahrts-Organisation (IMO) hat die Grenzwerte für Schiffsabgase von 4,5 Prozent Schwefel ab 2012 auf 3,5 Prozent und ab 2020 auf 0,5 Prozent festgelegt. Für die Nord- und Ostsee wurde ein Schwefelanteil in den Abgasen von 0,1 Prozent ab 2015 festgelegt.

Es existieren verschiedene Nachweisreaktionen für Schwefel.


In Verbindungen tritt Schwefel in allen Oxidationsstufen zwischen −II (Sulfide) und +VI (Sulfate, Schwefeltrioxid und Schwefelsäure) auf.

Schwefelwasserstoff (HS) ist ein farbloses, in geringen Konzentrationen nach faulen Eiern riechendes, giftiges Gas, das durch Reaktion von Sulfiden (MS) mit starken Säuren, zum Beispiel Salzsäure (HCl), entsteht. Es kommt als natürlicher Begleiter von Erdgas vor und entsteht in großen Mengen bei der Hydrodesulfurierung von Erdölfraktionen. Schwefelwasserstoff ist eine schwache Säure. Es ist brennbar, farblos und in Wasser wenig, in Alkohol etwas besser löslich. Schwefelwasserstoff und Metalloxide oder -hydroxide bilden Sulfide wie Zinnober (HgS) und Bleisulfid (PbS). Die Schwerlöslichkeit der Schwermetallsulfide wird in der analytischen Chemie im Trennungsgang zur Fällung der Metalle der Schwefelwasserstoffgruppe genutzt.

Disulfan (HS) ist eine unbeständiges Flüssigkeit. Sie bildet jedoch viele Salze wie zum Beispiel Pyrit. Ihre Salze (Disulfide) enthalten das Anion S. Disulfan ist das erste Glied der homologen Reihe der Polysulfane.

Schwefeldioxid ist das Anhydrid der Schwefligen Säure und ein farbloses, schleimhautreizendes, stechend riechendes und sauer schmeckendes, giftiges Gas. Es ist sehr gut wasserlöslich und bildet mit Wasser in sehr geringem Maße Schweflige Säure.

Schwefeltrioxid ist das Anhydrid der Schwefelsäure. Es bildet bei Normbedingungen farblose, nadelförmige Kristalle, die äußerst hygroskopisch sind und sehr heftig mit Wasser reagieren. Bei 44,45 °C siedet Schwefeltrioxid.

Schwefelmonoxid ist nur in verdünnter Form beständig. In konzentrierter Form wandelt es sich schnell in Dischwefeldioxid um. Es wurde im interstellaren Raum nachgewiesen.

Schwefel bildet eine Reihe von Oxosäuren, von denen die Schwefelsäure die mit Abstand größte technische Bedeutung hat. Die vorkommenden Oxidationsstufen reichen von +VI (Schwefelsäure) bis nahezu 0 (Oligosulfandisulfonsäuren, HSOSSOH). Die Säuren sind nicht alle in Reinform zu isolieren, bilden aber eine Reihe von Salzen und deren Hydrido-Isomeren. So ist Schweflige Säure als Reinstoff nicht zu isolieren, Sulfit- und Hydrogensulfitsalze dagegen sind als stabile Verbindungen bekannt.

Tetraschwefeltetranitrid SN ist ein goldroter Feststoff, der als Ausgangsverbindung für verschiedene Schwefel-Stickstoff-Verbindungen dient.

Dischwefeldinitrid SN liegt in Form eines viergliedrigen, rechteckig-planaren Ringes vor. Die Verbindung kann durch Reaktion von Tetraschwefeltetranitrid mit Silber gewonnen werden.

Polythiazyl (SN) war das erste anorganische Polymer mit elektrischer Leitfähigkeit. Bei sehr niedrigen Temperaturen unterhalb von 0,26 K ist das Material supraleitend. Polythiazyl wird aus Dischwefeldinitrid gewonnen.

Schwefelstickstoff (SN) wurde als Bestandteil von intergalaktischen Molekülwolken nachgewiesen. Im Labor kann es durch elektrische Entladungen in einem Stickstoff-Schwefel-Gas gewonnen werden.

"Schwefelhalogenide" des Typs SX ("n" = 2, 4) sind von Fluor und Chlor bekannt, Fluor bildet außerdem ein Hexafluorid. Daneben ist eine Reihe von gemischten Halogenverbindungen bekannt. Sauerstoff-Halogenverbindungen des Typs SOX (Thionylhalogenide), SOX (Sulfurylhalogenide) und SOX sind bekannt. Vom Iod ist nur eine Iodpolysulfanverbindung des Typs IS bekannt.

Schwefelhexafluorid (SF) ist ein farb- und geruchloses, ungiftiges Gas, das unbrennbar ist und sich äußerst reaktionsträge verhält. Es wird unter anderem als Isoliergas in der Mittel- und Hochspannungstechnik eingesetzt. Das Gas wird als Tracer zum Nachweis der Windströmungen und bei Geruchsausbreitungsuntersuchungen eingesetzt. Wegen des hohen Treibhauspotenzials ist der Einsatz aber umstritten.

Dischwefeldecafluorid (SF) ist eine farblose Flüssigkeit mit Geruch nach Schwefeldioxid.

Schwefeltetrafluorid (SF) ist ein farbloses, nicht brennbares Gas mit stechendem Geruch. Es zersetzt sich in Wasser unter Bildung von Fluorwasserstoff. Es wirkt als schwache Lewis-Säure und bildet zum Beispiel 1:1-Addukte mit organischen Basen wie Pyridin und Triethylamin.

Schwefeldifluorid (SF) ist ein farbloses Gas, das schnell zu Dischwefeldifluorid (SF) dimerisiert. Das letztere liegt in Form von zwei gasförmigen Isomeren vor, dem Thiothionylfluorid (S=SF) und dem Difluordisulfan (FSSF).

Dischwefeldichlorid (SCl) wird durch Chlorierung von elementarem Schwefel gewonnen. Dischwefeldichlorid wird zur Herstellung von Kautschuk-Vulkanisationsmitteln sowie anderen organischen Schwefelverbindungen verwendet. Es dient als Katalysator bei der Chlorierung von Essigsäure.

Schwefeldichlorid (SCl), eine tiefrote Flüssigkeit, wird durch Umsetzung von Dischwefeldichlorid mit Chlorgas hergestellt. Es wird gelöst in Schwefelkohlenstoff (CS) zur Kaltvulkanisation von Kautschuk verwendet. Im Ersten Weltkrieg wurde Schwefeldichlorid zur Herstellung des Kampfstoffes S-Lost verwendet.

Schwefeltetrachlorid (SCl) wird durch direkte Chlorierung von Schwefel mit Chlor hergestellt. Es ist im festen Zustand und unter −30 °C stabil, darüber zersetzt es sich, wobei Chlor und Schwefeldichlorid entstehen.

Schwefelpentafluorchlorid (SFCl), ein farbloses Gas, dient in der präparativen Chemie zur Darstellung von organischen Komponenten mit Kohlenstoff-Schwefel-Doppel- und Dreifachbindungen.

Schwefelpentafluorbromid (SFBr), ein farbloses Gas, kann aus Schwefeltetrafluorid, Silber(II)-fluorid und elementarem Brom hergestellt werden.

Die Thionylhalogenide OSX sind vom Fluor, Chlor und Brom bekannt, die Sulfurylhalogenide vom Fluor und Chlor.

Organoschwefelverbindungen sind organische Verbindungen, die Schwefel enthalten. Die Struktur, das Vorkommen und die Anwendungen der Organoschwefelverbindungen sind vielfältig. Viele Naturstoffe, darunter zwei essentielle Aminosäuren, sind organische Schwefelverbindungen. Organische Schwefelverbindungen treten in fossilen Brennstoffen, etwa in Form von Thiolen oder Thioethern auf. Anionische Tenside sind Natrium- oder Ammoniumsalze von Sulfonsäuren oder Schwefelsäurehalbestern. In der Flotationstechnik eignen sich bestimmte Schwefelverbindungen wie Xanthogenate, Dithiophosphorsäureester, Mercaptane oder Alkylsulfonate als so genannte Sammler.

Die Kohlenstoff-Schwefel-Einfachbindung ist sowohl länger als auch schwächer als die Kohlenstoff-Kohlenstoff-Bindung. Die Bindungslängen liegen zwischen 183 pm in Methanthiol und 174 pm in Thiophen. Die Dissoziationsenergie der Kohlenstoff-Schwefel-Bindung beträgt für Thiomethan 312,5 kJ/mol, die Dissoziationsenergie für Dimethylsulfid und Dimethylether 305 und 322 kJ/mol.
Die organische Chemie des Schwefels ist vielfältig. Praktisch zu allen Kohlenstoff-Sauerstoff-Verbindungen bestehen die organischen Schwefel-Analoga. Diese unterscheiden sich in ihren Reaktionen oft beträchtlich von den Sauerstoffverbindungen.

Bekannte Organoschwefelverbindungen sind Thiole, die auch Mercaptane genannt werden. Thiole entstehen beispielsweise bei der Umsetzung von Kaliumhydrogensulfid mit Alkylhalogeniden. Die Alkylierung von Thioharnstoff mit Alkylhalogeniden und anschließender Umsetzung mit Natronlauge führt ebenfalls zu Thiolen und Freisetzung von Harnstoff. Thiole sind Bestandteil vieler Naturstoffe wie den Abwehrstoffen des Stinktiers (3-Methylbutanthiol) und weisen oft einen unangenehmen Geruch auf. Sie lassen sich leicht durch Oxidation in Disulfide oder über die Stufen der Sulfensäuren und Sulfinsäuren in Sulfonsäuren überführen. Disulfid-Brücken stabilisieren die Struktur von Proteinen und Peptidhormonen wie Insulin. Beim Legen einer Dauerwelle werden die Cystinbindungen im Keratin durch Reduktion mit Thioglycolsäure aufgebrochen. Danach werden die Haare in die gewünschte Form gebracht. Durch nachfolgende Oxidation der Thiolgruppen im Keratin mit Wasserstoffperoxid zu Disulfidbrücken werden die Haare in dieser neuen Form fixiert. Knoblauch, Lauch und andere Pflanzen enthalten eine Reihe von schwefelorganischen Wirkstoffen wie Alliin, die antibiotische Eigenschaften aufweisen.

Thioether lassen sich beispielsweise durch die Reaktion von Alkalisulfid mit Alkylhalogeniden oder durch die Pummerer-Umlagerung herstellen. Mit Alkylhalogenid im Überschuss entstehen Trialkylsulfoniumsalze. Thioether lassen sich leicht zu Sulfoxiden und Sulfonen oxidieren. Sulfoxide mit zwei unterschiedlichen Alkylresten sind am Schwefelatom chiral. Das freie Elektronenpaar fungiert dabei als vierter Substituent.
Als heterocyclische Verbindung ist zum Beispiel Thiophen bekannt. Kohlenstoff-Schwefel-Sauerstoff-Verbindungen wie Sulfoxide, die wie Dimethylsulfoxid als Lösungsmittel verwendet werden, sind verbreitet. Sulfonsäuren beziehungsweise deren Salze, die Sulfonate, finden als Tenside Verwendung. In der organischen Synthese werden Thioacetale als Synthons zur Umpolung der Carbonylfunktion, zum Beispiel in der Corey-Seebach-Reaktion eingesetzt. In der Johnson-Corey-Chaykovsky Reaktion wird eine Carbonylfunktion mittels Schwefel-Yliden in ein Epoxid überführt.

Der Chemie der Riech- und Geschmacksstoffe sind eine Vielzahl schwefelhaltiger organoleptischer Stoffe bekannt. Sie hat etliche Stoffe aus natürlichen Quellen identifiziert und nutzt das Heteroelement zum Designen neuer Riechstoffe und zur Ermittlung olfaktorischer Struktur-Wirkungs-Beziehungen. Der niedrigste Geruchsschwellenwert (10 ppb), der je in natürlichen Aromen gemessen wurde, stammt von dem aus der Grapefrucht isolierten Thioterpineol, dem Schwefel-Analogon des α-Terpineols. Geringfügig schwächere Potenz hat das strukturell ähnliche 8-Thio-"p"-menth-3-on mit dem typischen Geruch der schwarzen Johannisbeere. Übertroffen werden diese Stoffe vom Thiamin-Photolyten "bis"(2-Methyl-3-furyl)disulfid, der zu den geruchsstärksten Verbindungen der organischen Chemie gehört. Im Galbanharz finden sich ausgeprägt riechende Thioester als Strukturverwandte der Senecioester. Ein dem Perillen analoges monoterpenoides Thiophen ist enthalten im Hopfen. Shiitake enthält den Aromastoff 1,2,3,5,6-Pentathiepan (Lenthionin). Spargel enthält 1,2-Dithiolane. Rettich und Radieschen setzen das 4-Methylsulfinyl-3-butenyl-isothiocyanat frei.

Das farb- und geruchslose Erdgas wird mit Tetrahydrothiophen odoriert, um im Leckagefall eine leichte geruchliche Wahrnehmung zu garantieren. Ausströmendes Erdgas kann dadurch bei kleinsten Leckagen wahrgenommen werden.

Schwefel verfügt als Ligand in der metallorganischen Chemie über mannigfaltige Koordinationsmöglichkeiten. Die Metall-Schwefel-Komplexe gelten als Modellverbindungen für das Studium von Metalloenzymen. Schwefel tritt in den Komplexen als verbrückender Mono-, Di- und Polysulfidoligand, als Sulfid, als Schwefelring verschiedener Größe oder als η-Disulfid auf.




</doc>
<doc id="4548" url="https://de.wikipedia.org/wiki?curid=4548" title="Samarium">
Samarium

Samarium (nach dem Mineral Samarskit, das vom deutschen Mineralogen Heinrich Rose nach dem russischen Bergbauingenieur Wassili Samarski-Bychowez benannt wurde) ist ein chemisches Element mit dem Elementsymbol Sm und der Ordnungszahl 62. Im Periodensystem steht das silbrig glänzende Element in der Gruppe der Lanthanoide und zählt damit auch zu den Metallen der Seltenen Erden. Samarium ist das erste natürlich vorkommende Element, das nach einer Person benannt wurde.

Zur Entdeckung des Samariums gibt es in der Literatur mehrere Darstellungen.

1903 stellte der deutsche Chemiker Wilhelm Muthmann metallisches Samarium durch Elektrolyse her.

Samarium wird derzeit fast ausschließlich in China gewonnen.

Gediegen kommt elementares Samarium nicht vor. Einige Mineralien wie Monazit, Bastnäsit und Samarskit enthalten jedoch das Element. Monazit enthält bis zu 1 % Samarium.

Ausgehend vom Monazit oder Bastnäsit werden Seltene Erden über Ionentausch, Solvent-Extraktion oder elektrochemische Deposition aufgetrennt. In einem letzten Verfahrensschritt wird das hochreine Samariumoxid mit metallischem Lanthan zum Metall reduziert und absublimiert.

In Luft ist Samarium halbwegs beständig, es bildet eine passivierende, gelbliche Oxidschicht aus. Metallisch glänzendes Samarium entzündet sich oberhalb von 150 °C. Mit Sauerstoff reagiert es zum Sesquioxid SmO. Mit Wasser reagiert es heftig unter Bildung von Wasserstoff und Samariumhydroxid. Die beständigste Oxidationsstufe ist wie bei allen Lanthanoiden +3.Samarium kommt in drei Modifikationen vor. Die Umwandlungspunkte liegen bei 734 °C und 922 °C. Sm-Kationen färben wässrige Lösungen gelb.

Es existieren vier stabile und 19 instabile, radioaktive Isotope. Die häufigsten natürlichen Isotope sind Sm (26,7 %), Sm (22,7 %) und Sm (15 %).








</doc>
<doc id="4549" url="https://de.wikipedia.org/wiki?curid=4549" title="Sindelfingen">
Sindelfingen

Sindelfingen ist eine Stadt in der Mitte des Landes Baden-Württemberg, etwa 15 km südwestlich von Stuttgart. Sie ist die größte Stadt des Landkreises Böblingen und bildet zusammen mit der südlichen Nachbarstadt Böblingen ein Mittelzentrum für die umliegenden Gemeinden.

Seit dem 1. Februar 1962 ist Sindelfingen Große Kreisstadt.

Sindelfingen liegt außerhalb des Nordostrandes des Oberen Gäus, zu Füßen einiger Höhen des Glemswaldes (Landschaftsschutzgebiet) zwischen der im Stadtgebiet entspringenden Schwippe und dem Sommerhofenbach. Der höchste Punkt der Gemarkung liegt auf 532, der tiefste auf 409 m ü. NN. Das Stadtgebiet erstreckt sich von 425 bis 460 m ü. NN. Der nördliche Schwarzwald ist von Sindelfingen aus in etwa einer halben Stunde, die Schwäbische Alb in 50 Minuten erreichbar.

Der Jahresniederschlag liegt bei 735 mm und ist damit vergleichsweise normal, da er in das mittlere Drittel der in Deutschland erfassten Werte fällt. An 48 % der Messstationen des Deutschen Wetterdienstes werden niedrigere Werte registriert. Der trockenste Monat ist der Januar, die meisten Niederschläge fallen im Juni. Im Juni fallen 2,3 mal mehr Niederschläge als im Januar. Die Niederschläge variieren sehr stark. An nur 15 % der Messstationen werden höhere jahreszeitliche Schwankungen registriert.

Folgende Städte und Gemeinden grenzen an die Stadt Sindelfingen. Sie werden im Uhrzeigersinn beginnend im Osten genannt: Stuttgart (Stadtkreis), Leinfelden-Echterdingen (Landkreis Esslingen) sowie Böblingen, Ehningen, Aidlingen, Grafenau, Magstadt und Leonberg (alle Landkreis Böblingen).

Sindelfingen besteht aus der Kernstadt und den im Rahmen der Gebietsreform 1971 eingegliederten Stadtteilen Maichingen und Darmsheim. Beide eingemeindeten ehemaligen Gemeinden sind Ortschaften im Sinne der baden-württembergischen Gemeindeordnung, das heißt, sie haben jeweils einen Ortschaftsrat, der von der Bevölkerung der Ortschaft bei jeder Kommunalwahl neu gewählt wird. Vorsitzender des Ortschaftsrats ist der Ortsvorsteher.

Seit einigen Jahren entsteht auf der Fläche des ehemaligen Böblinger Flugplatzes der neue Stadtteil Flugfeld, ein gemeinsames Projekt der Städte Sindelfingen und Böblingen. Zwei Drittel des Stadtteils werden auf Böblinger Gemarkung liegen, das restliche Drittel auf Sindelfinger Gemarkung. Im Areal „Forum 1“ wurde beispielsweise 2011 die Landesagentur "INUTEC-BW" („Innovations- und Technologiezentrum Umwelttechnik und Ressourceneffizienz GmbH“) eröffnet. Die gesamte Bauzeit ist bis 2031 projektiert.

In der Kernstadt werden zum Teil Wohngebiete mit eigenem Namen unterschieden, deren Bezeichnungen sich im Laufe der Geschichte aufgrund der Bebauung ergeben haben und die jedoch meist nicht genau abgrenzbar sind. Hierzu gehören beispielsweise Königsknoll, Viehweide, Eschenried, Pfarrwiesen, Rotbühl, Spitzholz, Eichholz, Hinterweil und Goldberg.

Sindelfingen bildet zusammen mit der Nachbarstadt Böblingen ein Mittelzentrum innerhalb der Region Stuttgart, deren Oberzentrum Stuttgart ist. Zum Mittelbereich Böblingen/Sindelfingen gehören neben den beiden Städten noch die Gemeinden im mittleren Teil des Landkreises Böblingen, und zwar Aidlingen, Altdorf, Ehningen, Gärtringen, Grafenau, Hildrizhausen, Holzgerlingen, Magstadt, Schönaich, Steinenbronn, Waldenbuch und Weil im Schönbuch.

Im 4. Jahrtausend v. Chr. existierte eine jungsteinzeitliche Siedlung im Gewann Hinterweil. Auch in der Urnenfelder-, Hallstatt- und Latènezeit gab es im Stadtgebiet vereinzelte Besiedlung, wie Scherbenfunde, Grabhügel und Urnengräber belegen. Im 1. bis 3. Jahrhundert existierte am Nordhang des Goldbergs ein römischer Vicus (Straßendorf), daneben standen über die Gemarkung verteilt kleinere Gutshöfe. Bald nach dem Fall des Limes 260 n. Chr. siedelten sich hier die Alamannen an, die auf der heutigen Sindelfinger Kerngemarkung die drei Dörfer Sindelfingen, Altingen und Bochtelfingen gründeten.

Seit etwa 700 stand im Bereich eines älteren Herrenhofes von Vorfahren der späteren Grafen von Calw ein Vorgängerbau der heutigen Martinskirche mit Friedhof. In der fränkischen Zeit vom 8. bis zum 11. Jahrhundert war Sindelfingen der Mittelpunkt einer fränkischen Grafschaft, die den späteren Grafen von Calw, einer der bedeutendsten Adelsfamilien im heutigen Baden-Württemberg, unterstand. Nach den im 13. Jahrhundert verfassten Sindelfinger Annalen gründete Graf Adalbert (II.) Atzinbart etwa 1050 in seinem Sindelfinger Stammsitz ein Benediktinerdoppelkloster für Mönche und Nonnen, das er bald darauf nach Hirsau in das von ihm wiederaufgebaute Aureliuskloster verlegte, aus dem das weltberühmte Reformkloster Hirsau hervorging. Stattdessen gründete er um 1065 in Sindelfingen ein Chorherrenstift, das 1155 als „praepositura in Sindelvinga“ erstmals urkundlich erwähnt wurde. Für dessen Bau brach er seinen Stammsitz mit der älteren Martinskirche ab und verlegte seinen Sitz nach Calw. Dort baute er eine neue Herrenburg und erschloss sich durch Rodungsarbeit ein geschlossenes Machtterritorium. Der Bau der neuen Martinskirche in Sindelfingen schritt nur langsam voran; 1100 wurde die Krypta geweiht, doch die eigentliche Kirche wurde erst 1132 von den Welfen fertiggestellt, die in Sindelfingen eine Münzstätte einrichteten.
Das Sindelfinger Chorherrenstift wurde in den nächsten Jahrhunderten durch weitere Stiftungen reich und bedeutend, geriet aber 1351 unter die Landesherrschaft der Grafen und späteren Herzöge von Württemberg. 1476 wurde von diesen in Tübingen ein neues Stift gegründet, dessen Besitz den finanziellen Grundstock für die berühmte Eberhard Karls Universität bildete. Dieses neue Stift erhielt den größten Teil des alten Sindelfinger Stiftsbesitzes. Die Sindelfinger Chorherren wurden die ersten Professoren und der Propst Johannes Tegen deren erster Kanzler. Aus den Besitzresten wurde in Sindelfingen das nachfolgende Augustiner-Chorherrenstift gegründet, das 1535 im Rahmen der Reformation durch die Herzöge von Württemberg endgültig aufgelöst wurde.

Um 1130 kam das Dorf Sindelfingen durch Uta von Schauenburg, die Erbtochter Graf Gottfrieds von Calw und Gemahlin Herzog Welfs, mit seinem Nachbardorf Böblingen in den Besitz der Welfen. Im darauffolgenden Erbstreit wurde das Dorf Sindelfingen 1133 von Utas Vetter Adalbert IV. von Calw niedergebrannt. In der zweiten Hälfte des 12. Jahrhunderts bestand in Sindelfingen eine welfische Münzstätte; ein Topf mit zahlreichen Silberbrakteaten aus dieser Werkstatt wurde 1973 im Boden der Martinskirche vergraben entdeckt. Der Besitzübergang an die Pfalzgrafen von Tübingen ist nicht völlig geklärt; er dürfte über den Kauf der Besitzungen von Welf V. durch Kaiser Friedrich Barbarossa und eine nachfolgende Belehnung an die Tübinger Pfalzgrafen erfolgt sein. Im Rahmen von Erbteilungen kamen die Dörfer der Sindelfinger Gemarkung in den Besitz des Grafen Rudolf der Scherer von Tübingen-Herrenberg, das Dorf Böblingen an seinen Vetter, der dort ca. 1250 eine Stadt gründete. Als Reaktion erfolgte 1263 die Gründung der Stadt Sindelfingen zwischen Stiftsbezirk und Dorf Sindelfingen durch den Grafen Rudolf der Scherer; die Dörfer Sindelfingen, Altingen und Bochtelfingen gingen später in der neuen Stadt auf. 1274 erging ein Schreiben von König Rudolph, dass Sindelfingen die gleiche Freiheit wie Tübingen genießen solle. Schon bevor die Stadtmauer fertiggestellt worden war, griffen die Böblinger die Stadt Sindelfingen an. Seit damals bestand eine ausgeprägte Rivalität zwischen den beiden Nachbarstädten. 1351 wurde die Stadt an Württemberg verkauft. Die neuen Herren führten 1535 die Reformation ein. Sindelfingen blieb aber lange Zeit ein unbedeutendes Landstädtchen, das sich nie damit abfinden konnte, im Rahmen des Herzogtums Württemberg zum Oberamt Böblingen zu gehören und der Nachbarstadt untergeordnet zu sein. 1607 erreichten die Bürger Sindelfingens durch eine außerordentliche Steuerzahlung an den Herzog endlich, aus diesem Oberamt herausgelöst zu werden und eine von Böblingen unabhängige Amtsstadt ohne eigene Amtsorte zu werden. Dieses Privileg wurde ihnen dann im 18. Jahrhundert wieder genommen.

Von 1562 bis 1684 gerieten in den Hexenverfolgungen in Sindelfingen 34 Frauen in Hexereiverdacht. 19 der angeklagten Frauen wurden in Hexenprozessen hingerichtet, darunter Barbara Breuninger, die 1609 im Alter von 85 Jahren verurteilt wurde, und Judith Stick 1615. Geführt wurden die Hexenprozesse im Rathaus vor dem Gericht der Stadt.

Im 19. Jahrhundert wurden mechanische Webereien eingeführt, und Sindelfingen wurde eine bedeutende Weberstadt. Aus dieser Zeit stammt die in Sindelfingen beheimatete Weberfachschule. 1850 hatte Sindelfingen 4304 evangelische und 6 katholische Einwohner, die in 461 Haupt- und 203 Nebengebäuden lebten und arbeiteten.
Im Rahmen des Eisenbahnbaus von Stuttgart nach Böblingen zahlten die Sindelfinger Bürger wieder selbst dafür, dass die Bahnlinie über Sindelfingen mit einem eigenen Bahnhof verlaufen sollte. Nachdem die Zahlungen in Stuttgart eingegangen waren, wurde der Streckenverlauf wieder Richtung Böblingen verlegt, ohne Sindelfingen zu berühren. All diese Ereignisse vertieften die traditionelle Feindschaft zwischen den Städten Sindelfingen und Böblingen.

Im 20. Jahrhundert erfolgte eine bedeutende Industrialisierung. Es wurden Maschinenfabriken sowie Industrien für Autos, Büromaschinen, Schuhe, Uhren und anderes errichtet. 1914 wurde das Daimler-Werk in Sindelfingen angesiedelt. Auch die DEHOMAG, eine Büromaschinenfabrik, die den Vorgänger des Computers produzierte und 1929 durch IBM aufgekauft wurde, hatte in Sindelfingen ihren Sitz.

Wilhelm Friedle, bis 1935 Betriebsdirektor der Daimler-Benz AG im Werk Sindelfingen, brachte das Fließband nach Deutschland. Sindelfingen wuchs zu einer bedeutenden Industriestadt heran.

Im Zweiten Weltkrieg wurde Daimler-Benz zu einem der größten Produzenten von Rüstungsgütern. Dies wurde auch gewährleistet durch den Einsatz von Zwangsarbeitern, die nach Deutschland verschleppt wurden, davon allein in Sindelfingen in Daimler-eigenen Werkslagern etwa 3.000 Frauen, Kinder und Männer vorwiegend aus der Sowjetunion und Polen. Mindestens 46 von ihnen wurden Opfer der Zwangsarbeit, wovon Gedenksteine auf dem "Alten Friedhof" in der "Bleichmühlestraße" zeugen. Schwangere Zwangsarbeiterinnen kamen in eine „Entbindungsstation“ im Lager "Böblinger Allee", das mit seinen Bedingungen für ein rasches Sterben der Neugeborenen sorgte. Später wurden die Frauen zu Abtreibungen gezwungen, weil ihre Kinder als „rassisch minderwertig“ galten.

Aufgrund des industriellen Rüstungspotentials wurde die Stadt im Zweiten Weltkrieg verhältnismäßig stark zerstört, danach jedoch wieder aufgebaut. Der starke Einwohnerzuwachs führte zum Bau zahlreicher Wohnsiedlungen. Die Stadt, deren Einwohnerzahl nach Kriegsende bei ca. 8500 lag, überschritt 1957 die Grenze von 20.000. Daraufhin stellte die Stadtverwaltung den Antrag auf Erhebung zur Großen Kreisstadt, dem die Landesregierung von Baden-Württemberg mit Wirkung vom 1. Februar 1962 zustimmte.

Bei der Gebietsreform 1971 erreichte das Stadtgebiet schließlich seine heutige Ausdehnung. Von der Landesregierung war seinerzeit eine Fusion mit der Nachbarstadt Böblingen zur Großstadt Böblingen-Sindelfingen vorgesehen und sogar schon beschlossen worden. Aber vor Inkrafttreten der neuen Rechtsbestimmung erreichte der geschlossene Widerstand der Bürger beider Städte, der seine Kraft aus der jahrhundertelangen Feindschaft beider Städte bezog, dass dieser Plan nicht umgesetzt werden konnte. Ein nicht zu lösender Streitpunkt war dabei der neue gemeinsame Name der neuen Doppelstadt.

1990 war Sindelfingen Gastgeber der zehnten Landesgartenschau Baden-Württemberg.


Die Einwohnerzahlen sind Schätzungen, Volkszählungsergebnisse (*) oder amtliche Fortschreibungen der jeweiligen Statistischen Ämter (nur Hauptwohnsitze). Alle Zahlen seit 1871 stammen vom Statistischen Landesamt Baden-Württemberg.

Die Bevölkerung von Sindelfingen gehörte ursprünglich zum Bistum Konstanz. Da die Stadt seit dem 14. Jahrhundert zu Württemberg gehörte, wurde auch hier ab 1535 durch Herzog Ulrich die Reformation eingeführt, daher war Sindelfingen über Jahrhunderte eine überwiegend protestantische Stadt. Sie gehört seit jener Zeit zum Dekanat Böblingen. Die Hauptkirche der Stadt ist die Martinskirche, eine der ältesten Kirchen des Landes (Weihe 1083). Die zugehörige Kirchengemeinde Sindelfingen war zunächst die einzige der Stadt.

Nach dem Zweiten Weltkrieg wuchs die Bevölkerung infolge Zuzugs stark an. Daher wurde die Kirchengemeinde geteilt. Es entstand die Christusgemeinde (Kirche von 1958), die Johannesgemeinde (Kirche von 1962) und die Versöhnungsgemeinde (Kirche von 1967). Innerhalb der Martinsgemeinde gibt es noch das 1976 erbaute Markuszentrum; die Nikodemuskirche im "Hinterweil" gehört zur Christusgemeinde. Alle vier Kirchengemeinden bilden die Evangelische Gesamtkirchengemeinde Sindelfingen.

Auch in den beiden Stadtteilen Darmsheim und Maichingen wurde infolge der frühen Zugehörigkeit zu Württemberg die Reformation eingeführt. Auch dort gibt es jeweils eine evangelische Kirchengemeinde, die in alten Kirchen ihre Gottesdienste feiert, in Darmsheim in einer ehemaligen Wehrkirche mit spätgotischem Westturm und Fresken im Innern bzw. in Maichingen in einer umgebauten Chorturmkirche mit Erweiterungen aus dem Jahr 1609. Auch die beiden Stadtteilgemeinden gehören wie alle Sindelfinger Kirchengemeinden zum Dekanat bzw. Kirchenbezirk Böblingen innerhalb der Evangelischen Landeskirche in Württemberg.

Katholiken in größerer Zahl gibt es in Sindelfingen nach der Reformation erst wieder seit Ende des 19. Jahrhunderts. Für sie wurde 1952 eine eigene Kirche „Zur Heiligsten Dreifaltigkeit“ gebaut und eine Pfarrei eingerichtet. Weitere Kirchen wurden 1960 (St. Joseph, Pfarrei seit 1965), 1969 (Auferstehung Christi, Pfarrei seit 1974), 1970 (St. Paulus, Pfarrei seit 1974) und 1972 (St. Maria Königin des Friedens, Pfarrei seit 1974) erbaut. Durch die in der Industriestadt Sindelfingen besonders starke Zuwanderung der „Gastarbeiter“ gab es neue Aufgaben für die Seelsorge, denn die meisten von ihnen kamen aus katholischen Ländern: Italien, Spanien und Portugal sowie die große Gruppe der Kroaten aus dem damaligen Jugoslawien.

In Darmsheim gibt es seit 1974 die Kirche St. Stephan. Sie gehört zur Nachbargemeinde Christkönig Dagersheim, mit der sie eine Kirchengemeinde bildet. In Maichingen wurde 1955 die Kirche St. Anna erbaut. Die Pfarrei Maichingen wurde 1961 errichtet.

Im neu gebauten Stadtteil Hinterweil gab es seit 1980 zuerst ein provisorisches Kirchengebäude, das von Katholiken und Protestanten gemeinsam genutzt wurde. An gleicher Stelle wurde 1993 ein ökumenisch ausgerichtetes Gemeindezentrum eingeweiht. Die integrierte Kirche "St. Franziskus" gehört von Anfang an zu Josefsgemeinde.

Die katholischen Gemeinden im Sindelfinger Stadtgebiet bilden die Seelsorgeeinheiten 7, 9 und 10, zu denen teilweise noch benachbarte Kirchengemeinden gehören. Sie alle gehören zum Dekanat Böblingen (zuvor Dekanat Weil der Stadt) der Diözese Rottenburg-Stuttgart.

Neben den beiden großen Kirchen gibt es in Sindelfingen auch Freikirchen und Gemeinden, darunter die Evangelisch-methodistische Kirche (Erlöserkirche), die Evangelisch-Freikirchliche Gemeinde (Baptisten), eine christliche, türkischsprachige Gemeinde ("Türkçe Konuşan Kilise Topluluğu") und das "Internationale Christliche Zentrum" (ICZ). Auch die Neuapostolische Kirche und die Zeugen Jehovas sind in Sindelfingen vertreten.

Seit den 60er Jahren wanderten Griechen zu, die fast ausnahmslos orthodoxe Christen sind. Sie gründeten eine „griechische Gemeinde“ als Verein, der 2013 sein 50-jähriges Bestehen feiern konnte. Seit Anfang der 80er Jahre gibt es eine griechisch-orthodoxe Kirche in Sindelfingen.

Neben den christlichen Glaubensgemeinschaften lebt in Sindelfingen auch eine große Anzahl von Muslimen, die mittlerweile einige Moscheen errichtet haben.

In Sindelfingen wird der Gemeinderat nach dem Verfahren der unechten Teilortswahl gewählt. Dabei kann sich die Zahl der Gemeinderäte durch Überhangmandate verändern. Der Gemeinderat in Sindelfingen hat nach der letzten Wahl 41 Mitglieder (vorher 42). Die Kommunalwahl am 25. Mai 2014 führte zu folgendem amtliche Endergebnis. Der Gemeinderat besteht aus den gewählten ehrenamtlichen Gemeinderäten und dem Oberbürgermeister als Vorsitzendem. Der Oberbürgermeister ist im Gemeinderat stimmberechtigt.

Am 17. Juli 2012 beschloss der Gemeinderat die Einführung eines Jugendgemeinderats in Sindelfingen. Die ersten Wahlen fanden vom 22. bis zum 30. April 2013 statt. Am 3. Mai 2013 wurde der erste Jugendgemeinderat in sein Amt eingesetzt. Aktuell umfasst der Jugendgemeinderat 26 Jugendliche im Alter von 12 bis 18 Jahren. Der zweite Jugendgemeinderat wurde am 3. November 2014 in sein Amt eingesetzt. Für die Periode 2015/16 wurde Ariane Schachtschabel zur Vorsitzenden des Jugendgemeinderats gewählt, sie folgt auf Samet Mutlu, der den Vorsitz 2014/2015 innehatte.

Ein Schultheiß des Dorfes Sindelfingen wird 1255 erwähnt; 1271 wird erstmals ein Schultheiß der Stadt erwähnt, seit 1280 gab es einen Vogt, der bis 1605 in Böblingen seinen Sitz hatte, bis die Stadt vom Amt Böblingen getrennt wurde. Dann leiteten Amtmänner bzw. Oberamtmänner die Stadtverwaltung.

Seit 1819 trug das Stadtoberhaupt die Bezeichnung „Stadtschultheiß“ und seit 1930 Bürgermeister. Mit der Erhebung zur Großen Kreisstadt am 1. Februar 1962 lautet die Amtsbezeichnung Oberbürgermeister. Dieser wird von den Wahlberechtigten auf acht Jahre direkt gewählt. Er ist Vorsitzender des Gemeinderats. Seine allgemeinen Stellvertreter sind der 1. Beigeordnete mit der Amtsbezeichnung „Erster Bürgermeister“ und der 2. Beigeordnete mit der Amtsbezeichnung „Bürgermeister“.

Stadtoberhäupter seit 1819

Zwei Straßen im Bereich der Kernstadt wurden nach ehemaligen Stadtoberhäuptern benannt, die Wilhelm-Hörmann-Straße oberhalb des Klostersees und die Arthur-Gruber-Straße, vormals Jahnstraße, auf dem Weg hinauf zum (ehemals) "Städtischen Krankenhaus".

Das Wappen der Stadt Sindelfingen zeigt in Silber drei liegende schwarze Hirschstangen übereinander, darunter ein schwarzes Kreuz. Die Sindelfinger Stadtflagge ist schwarz-weiß. Wappen und Flagge haben lange Tradition und wurden 1927 offiziell festgelegt. Die Hirschstangen symbolisieren die Zugehörigkeit zu Württemberg. Das Kreuz weist auf die Martinskirche hin, die sich bis ins 7. Jhd bzw. bis ins Jahr 1059 zurückverfolgen lässt.
Maichingens Wappen zeigte eine aufrechte grüne Eichel mit Stiel, das von Darmsheim zwei schräggekreuzte goldene Glevenstäbe.

Sindelfingen unterhält mit folgenden Städten offizielle Partnerschaften:


Sindelfingen hat seit 1955 eine Patenschaft für die Vertriebenen aus der Stadt und dem Gerichtsbezirk Würbenthal im Kreis Freudenthal im Sudetenland übernommen. Seit 1964 besteht eine Patenschaft der Stadt Sindelfingen über die Volksgruppe der Deutschen aus Jugoslawien. Mit Unterstützung der Stadt wurde das Haus der Donauschwaben in der Goldmühlestraße gebaut und 1970 eingeweiht. In ihm haben diese Einrichtungen ihren Sitz: Der Verein Haus der Donauschwaben e.V.; der Weltdachverband der Donauschwaben; die Landsmannschaft der Donauschwaben, Bundes- und Landesverband und Kreisverband Böblingen; der Kreisverband Böblingen der Banater Schwaben und der Arbeitskreis donauschwäbischer Familienforscher.

Die Stadt ist geprägt durch die Automobilindustrie, besonders durch das Mercedes-Benz-Werk Sindelfingen. Mit rund 27.000 Beschäftigten sowie weiteren rund 6.000 Mitarbeitern in der ebenfalls am Standort angesiedelten PKW-Entwicklung von Mercedes-Benz Cars ist es das weltweit größte Automobilwerk der Daimler AG.

In der frühen Neuzeit war das Weberhandwerk ansässig, daher gibt es auch heute noch viele Modefirmen. Die Energieinfrastruktur wird durch die Stadtwerke Sindelfingen GmbH betrieben, an der die Stadt Sindelfingen mit 37,4 % beteiligt ist.

Sindelfingen ist über die Anschlussstellen Sindelfingen-Ost und Böblingen/Sindelfingen der Bundesautobahn 81 (Würzburg–Gottmadingen), die sich im nordöstlichen Stadtgebiet an der Grenze zu Stuttgart mit der A 8 kreuzt, gut erreichbar. Ferner verläuft die Bundesstraße 464 (nach Reutlingen) durch das westliche Stadtgebiet. Die B 14 führt an Sindelfingen vorbei.

Das schon genannte Autobahnkreuz von A 8 und A 81, das Kreuz Stuttgart, liegt auf Sindelfinger Gemarkung; ebenso die Raststätte „Sindelfinger Wald“ und ein Parkplatz an der A 8, der "Sommerhofen" genannt wird. Die A 81 markiert recht genau die Trennlinie von Sindelfingen gegenüber Böblingen; zu beiden Seiten liegen Wohngebiete in direkter Nähe.

Der "S-Bahnhof Sindelfingen" liegt an der Rankbachbahn von Böblingen nach Renningen. Auf dieser Strecke fahren Güterzüge (Güterzugumgehung Stuttgart). Die zeitweise stillgelegten Bahnhöfe Sindelfingen und Maichingen wurden als Haltepunkte seit 14. Juni 2010 für die Linie S60 der S-Bahn Stuttgart wiedereröffnet. Anfangs war das Angebot auf Montag bis Freitag beschränkt, seit 12. Juni 2011 läuft der Betrieb an allen Wochentagen im 30-Minuten-Takt von 5:00 bis 23:00 Uhr mit Anschluss in Böblingen an die S1 und an die Schönbuchbahn. Hierfür wurde die Bahnstrecke von Sindelfingen bis Renningen zweigleisig ausgebaut. Neben „Sindelfingen“ sind „Maichingen“ und „Maichingen-Nord“ S-Bahn-Haltepunkte in Sindelfingen.

Die drei S-Bahn-Haltepunkte an der Linie S1 von Stuttgart nach Herrenberg, „Goldberg“, „Böblingen“ (Bahnhof) und „Hulb“, sind von Sindelfingen aus gut zu erreichen, sie liegen im Bereich der Stadt Böblingen. Die Buslinien des Stadtverkehrs Böblingen-Sindelfingen und die S-Bahn sind in den Verkehrs- und Tarifverbund Stuttgart (VVS) integriert.

Der nahegelegene Flughafen Stuttgart ist über die Autobahn sowie mit der S-Bahn erreichbar. Der Umstieg am Bahnhof Rohr ist zeitlich und kostenmäßig sehr günstig.

Sindelfingen hat eine Außenstelle des Landratsamts Böblingen (Amt für Schule und Bildung und Schulpsychologische Beratungsstelle). Das Amt für Schule und Bildung ist seit dem 1. November 2006 im Landratsamt in Böblingen eingegliedert. Damit ist die durch die Verwaltungsreform des Landes Baden-Württemberg festgelegte Zuordnung zum Landkreis auch räumlich abgeschlossen.

Die Stadt Sindelfingen baute – ausgelöst durch eine Spende – ein "Städtisches Krankenhaus", der alte Standort war beim heutigen Rathaus (dem "Dritten Rathaus"). Nach dem Krieg blieb man dieser Tradition treu; das neue "Krankenhaus auf der Steige" war aber im Wald über der Stadt. Heute gehören die "Kliniken Sindelfingen" zum Klinikverbund Südwest.

In Sindelfingen erscheint als Tageszeitung die Sindelfinger Zeitung. Außerdem erscheint in Sindelfingen das Wochenblatt Böblingen.
Auf dem Wasserturm Steige befindet sich ein UKW-Sender, der das Programm von Energy (Böblingen, Calw, Freudenstadt) ausstrahlt. Bis 2006 gab es auf dem Kamin des Daimler-Heizkraftwerkes einen Analogfernsehsender von Regio TV Böblingen.

In Sindelfingen gibt es ein Staatliches Seminar für Didaktik und Lehrerbildung (seit 2016 Grundschulseminar).

Ferner gibt es fünf Gymnasien (Goldberg-, Pfarrwiesen- und Stiftsgymnasium, Gymnasium Unterrieden und das Technische Gymnasium innerhalb der Gottlieb-Daimler-Schulen), drei Realschulen (Realschule am Goldberg, Klostergarten und Hinterweil), eine Förderschule (Martinsschule), drei Gemeinschaftsschulen (Eichholzschule, Goldberg und Johannes-Widmann-Schule Maichingen) und sechs selbständige Grundschulen (Darmsheim, Gartenstraße, Hinterweil, Klostergarten, Königsknoll und Sommerhofen).

Der Landkreis Böblingen ist Schulträger der beiden Beruflichen Schulen unter dem Namen Gottlieb-Daimler-Schulen im "Technischen Schulzentrum" (Gottlieb-Daimler-Schule I und Gottlieb-Daimler-Schule II) sowie der Bodelschwinghschule für Geistigbehinderte mit Bodelschwingh-Schulkindergarten für Geistigbehinderte, der Schule für Körperbehinderte mit Schulkindergarten und der Schule für Sprachbehinderte und Kranke in längerer Krankenhausbehandlung mit Schulkindergarten für Sprachbehinderte.

Die private Abendrealschule Böblingen-Sindelfingen e. V. rundet das schulische Angebot in Sindelfingen ab.

Das 1970 eingerichtete "Donauschwäbische Museum" im Haus der Donauschwaben zeigt eine Sammlung donauschwäbischen Kulturgutes. Angeschlossen ist eine Spezialbibliothek für donauschwäbisches Schrifttum.

Die "Galerie Stadt Sindelfingen" wurde 1990 gegründet und zeigt Positionen aktueller und moderner Kunst. Sie beherbergt neben der Sammlung Lütze auch die städtische Sammlung. Seither wurden rund 180 Gruppen- und Einzelausstellung mit mehr als 500 nationalen und internationalen Künstlerinnen und Künstlern, sowie mit Kunstwerken aus dem eigenen Sammlungsbestand gezeigt.

Über die Stadtgeschichte informiert das "Stadtmuseum" im Alten Rathaus von 1478 mit angrenzendem Salzhaus von 1592. Im Salzhaus ist auch die "Würbenthaler Heimatstube" untergebracht.

In der Alten Webschule befindet sich das Haus der Handweberei mit "Webereimuseum".

Das Museum Schauwerk Sindelfingen wurde 2010 eröffnet. Es zeigt deutsche und internationale Kunst der 1960er bis in die Gegenwart.

Das Alte Rathaus (heute das Stadtmuseum, der Eintritt ist frei) und die Martinskirche (geweiht 1083) sind die Wahrzeichen der Stadt. "Weitere Sehenswürdigkeiten:"
Sowie




Die seit 1986 bestehende Punk-Rock-Band WIZO stammt aus Sindelfingen.

2010 haben sich außerdem Heisskalt in Sindelfingen aus On Top of the Avalanche und der ebenfalls Sindelfinger Band Big Spin gegründet.

1823 gründete Max Bernauer, der damalige Wirt des Gasthauses Lamm, für die Bewirtung der eigenen Gäste die Brauerei „Lamm Bräu“. Bereits ein Jahr später wurde die Brauerei an Johann Jakob Schlanderer verkauft. 2005 wurde die Bierherstellung aufgegeben. Das ehemalige Brauereigelände zwischen Lange Anwanden, Eyachstraße und Mahdentalstraße wurde mittlerweile mit Wohnhäusern bebaut.


Die Stadt Sindelfingen hat folgenden Personen das Ehrenbürgerrecht verliehen:
Daneben vergibt die Stadt Sindelfingen noch "Ehrenplaketten" in Gold und Silber an Personen, die sich um die Stadt verdient gemacht haben. Ehrungen dieser Art erhielten unter anderem Roger Combrisson (Bürgermeister der Partnerstadt Corbeil-Essonnes) und Arthur Gruber.


die in Sindelfingen gewirkt haben, ohne dort geboren zu sein:





</doc>
<doc id="4554" url="https://de.wikipedia.org/wiki?curid=4554" title="Internationales Einheitensystem">
Internationales Einheitensystem

Das Internationale Einheitensystem oder SI (frz. "") ist das am weitesten verbreitete Einheitensystem für physikalische Größen.

Das SI ist ein metrisches Einheitensystem (d. h. eine Basiseinheit ist der Meter), es ist dezimal (d. h. die Bruchteile oder Vielfachen der einzelnen Basiseinheiten unterscheiden sich nur um ganze Zehnerpotenzen) und es ist ein kohärentes Einheitensystem (d. h. jede abgeleitete Einheit ist ein Potenzprodukt von Basiseinheiten ohne zusätzliche numerische Faktoren).

Durch das SI werden physikalische Einheiten zu ausgewählten Größen festgelegt. Das SI beruht auf sieben Basiseinheiten zu entsprechenden Basisgrößen. Die Auswahl der Basisgrößen und die Definition der zugehörigen Basiseinheiten erfolgte nach praktischen Gesichtspunkten.

Die Einheiten des Internationalen Einheitssystems werden als SI-Einheit bezeichnet, um sie von Einheiten anderer Einheitensysteme abzugrenzen.

Für internationale Regelungen über das SI ist das internationale Maß- und Gewichtsbüro (BIPM) zuständig. Als Referenz-Regelwerk gilt die vom BIPM in periodischen Abständen (üblicherweise alle paar Jahre) neu publizierte Broschüre  – deutsch kurz auch als „die SI-Broschüre“ bezeichnet. Dieser Artikel bezieht sich auf die 2006 erschienene 8. Auflage der SI-Broschüre.

Für die nationale Umsetzung des SI sind meist die metrologischen Staatsinstitute zuständig.

Dies sind zum Beispiel

Diese nationalen Empfehlungen erhalten rechtliche Bedeutung (das heißt im Wesentlichen eine Anwendungspflicht in manchen Tätigkeitsbereichen) erst durch Gesetze oder Rechtsprechung einzelner Staaten.

In der EU ist die Verwendung von Einheiten unter anderem durch die EG-Richtlinie 80/181/EWG weitgehend vereinheitlicht worden. In der Europäischen Union (EU), der Schweiz und den meisten anderen Staaten ist die Benutzung des SI im amtlichen oder geschäftlichen Verkehr gesetzlich vorgeschrieben. Mit der Richtlinie 2009/3/EG wurde die Verwendung von zusätzlichen Angaben in der EU unbefristet erlaubt (durch vorhergehende Richtlinien war dies ursprünglich nur bis zum 31. Dezember 2009 möglich). Dies wird hauptsächlich damit begründet, Exporte von Waren in Drittländer nicht zu behindern. In vielen Staaten gestatten nationale Gesetze bestimmte Ausnahmen von den SI-Regelungen.

Von den USA, Myanmar und Liberia wurde das SI nie offiziell eingeführt. In den USA sind metrische Einheiten seit einem Parlamentsbeschluss 1866 und einem Regierungsdekret 1894 anerkannte Einheiten. In den 1970er Jahren wurden erhebliche Anstrengungen unternommen, das SI einzuführen, doch es scheiterte am fehlenden Willen der Anwender bzw. Betroffenen.<ref name="NZZ02/05">"Einer gegen 290 Millionen" NZZ Folio 02, 2005, abgerufen am 23. Januar 2010.</ref> In vielen Bereichen wie z. B. Wissenschaft, Medizin oder Industrie wird das SI parallel oder ausschließlich genutzt. Ansonsten ist in den USA das angloamerikanische Maßsystem in der Variante der „customary units“ (die auf einer historischen Form des britischen Maßsystems beruht) gebräuchlich.

Wichtig für die internationale Durchsetzung des metrischen Systems war die Unterzeichnung der Meterkonvention 1875 durch 17 Staaten. Dabei wurde auch das "Internationale Büro für Maß und Gewicht" und dessen Generalkonferenz für Maß und Gewicht (CGPM) gegründet. Diese beiden Institutionen sind bis heute für die internationale Standardisierung des SI zuständig.


Das SI ist heute in der ganzen Welt verbreitet. In den meisten Industrieländern ist sein Gebrauch für den amtlichen und geschäftlichen Verkehr gesetzlich vorgeschrieben. In Deutschland geschieht dies durch das Einheiten- und Zeitgesetz und die zugehörige Ausführungsverordnung. Gesetze, die die Einführung des SI regelten, traten 1970 in der Bundesrepublik Deutschland, 1973 in Österreich, 1974 in der DDR und 1978 in der Schweiz in Kraft; 1978 waren alle Übergangsregelungen betreffend Nicht-SI-Einheiten abgeschlossen. 

In einigen Ländern werden neben dem SI weiterhin traditionelle Maßsysteme verwendet:

In der Schiff- bzw. Luftfahrt verwendet man weiterhin nicht-SI-konforme Einheiten für Flughöhe (ft = Feet), Entfernungen (1 sm "oder" NM = 1 Seemeile = 1852 m) und Geschwindigkeiten (1 kn = 1 Knoten = 1 Seemeile pro Stunde). 

In der theoretischen Physik sind unterschiedliche natürliche Einheitensysteme gebräuchlich. 

Im SI gibt es sieben Basiseinheiten. Alle anderen physikalischen Einheiten sind aus diesen Basiseinheiten abgeleitet. Alle physikalischen Einheiten bilden die "kohärenten SI-Einheiten," sofern sie nicht zusammen mit SI-Präfixen (wie "Kilo" oder "Milli") verwendet werden. Eine Ausnahme bildet das Kilogramm, das als Basiseinheit bereits mit dem SI-Präfix "Kilo" versehen ist. Durch Verwendung von SI-Präfixen werden kohärente SI-Einheiten zu "nicht kohärenten SI-Einheiten." Die Gesamtheit all dieser Einheiten, also sowohl die kohärenten als auch die nicht kohärenten SI-Einheiten, bildet die Menge der „SI-Einheiten“.

"Beispiele"

Eine SI-Basiseinheit ist immer die kohärente Einheit der zugehörigen Basisgröße. Daneben kann sie auch noch als kohärente Einheit abgeleiteter Größen dienen.

"Beispiele"

"Anmerkung:"
Die Bezeichnung „SI-Einheit“ wird oft im Sinne von „gesetzliche Einheit“ oder „empfohlene Einheit“ verwendet. Es gibt jedoch auch gesetzliche Einheiten, die keine SI-Einheiten sind. Solche falschen Verwendungen finden sich allerdings auch bei Normungsorganisationen. So heißt es im nationalen Anhang der deutschen Norm DIN ISO 8601:2006-09: „Die Schreibweise von Uhrzeiten mit den physikalischen SI-Einheiten h, min, s nach DIN 1301-1 sollte vermieden werden“. Die Verwendung solcher nicht-SI-Einheiten zusammen mit SI-Einheiten wird zwar sanktioniert – s. u. –, jedoch werden sie dadurch nicht zu SI-Einheiten.

Die Basiseinheiten des SI und die entsprechenden Basisgrößen des zu Grunde liegenden Größensystems ISQ werden nach praktischen Gesichtspunkten willkürlich durch die CGPM festgelegt. Eine SI-Basisgröße kann definitionsgemäß nicht durch andere Basisgrößen ausgedrückt werden. Analog dazu kann eine SI-Basiseinheit nicht als Potenzprodukt anderer Basiseinheiten ausgedrückt werden.

Die Definitionen der Basiseinheiten sind nicht endgültig, sondern werden in ständiger Arbeit mit dem fortschreitenden Stand der Messtechnik sowie nach revidierten prinzipiellen Überlegungen weitergeführt. Im internationalen Größen- und Einheitensystem werden die sieben Basisgrößen durch die Basiseinheiten Meter (m), Kilogramm (kg), Sekunde (s), Ampere (A), Kelvin (K), Mol (mol) und Candela (cd) ausgedrückt und im SI in dieser Reihenfolge definiert. Jeder Basisgröße wird eine Dimension mit demselben Namen zugeordnet. Beispielsweise heißt die Dimension der Basisgröße "Länge" ebenfalls "Länge". Das Symbol der Größe wird mit einem kursiv geschriebenen Buchstaben "„l“" bezeichnet; jenes der Dimension mit einem aufrechtstehenden, großgeschriebenen Buchstaben „L“. Die praktische Realisierung einer Dimension erfolgt durch eine entsprechende kohärente Einheit – im Falle der Länge durch das Meter.

Man kann erkennen, dass nur die drei Basiseinheiten Kilogramm, Sekunde und Kelvin unabhängig von anderen Basiseinheiten definiert sind, während die Definitionen der übrigen vier Basiseinheiten Abhängigkeiten von anderen Basiseinheiten aufweisen:

Des Weiteren fällt auf, dass nur die Einheit "Kilogramm" anhand eines Prototyps definiert wird. Alle anderen Einheiten werden über unveränderliche Naturkonstanten festgelegt, was aber nicht schon immer der Fall war. So gab es bis 1960 beispielsweise ein Urmeter als Prototyp für die Einheit "Meter". Da sich die Masse des Urkilogramms aber theoretisch ändern könnte (und dies wahrscheinlich sogar tut) arbeitet man daran, auch die Einheit "Kilogramm" eindeutig zu definieren (siehe auch Neudefinition des Kilogramms).

Alle physikalischen Größen außer den oben genannten sieben Basisgrößen des ISQ sind "abgeleitete Größen." Analog dazu sind alle Einheiten außer den sieben Basiseinheiten des SI "abgeleitete Einheiten".

Die SI-Einheit einer beliebigen Größe "Q" (steht für engl. ) kann immer als Produkt aus einem numerischen Faktor und dem Produkt aus Potenzen (Potenzprodukt) der Basiseinheiten ausgedrückt werden:

„["Q"]“ stellt symbolisch den Ausdruck „die Einheit der Größe "Q"“ dar, in Übereinkunft der Regeln gemäß dem vom "Joint Committee for Guides in Metrology" herausgegebenen VIM "(International Vocabulary of Metrology – Basic and General Concepts and Associated Terms)".

Der numerische Faktor 10 (mit ganzzahligem "n") repräsentiert das SI-Präfix wie "Kilo" oder "Milli". Ist der numerische Faktor gleich eins (also bei "n" = 0), liegt eine "kohärente SI-Einheit" vor (Ausnahme: Kilogramm). Jede physikalische Größe hat nur eine einzige kohärente SI-Einheit und eine entsprechende Dimension. Eine kohärente SI-Einheit wird bei Verwendung eines SI-Präfixes zu einer "nicht kohärenten SI-Einheit". Die kohärente Form obiger Einheitengleichung kann auch als entsprechende Dimensionsgleichung dargestellt werden:

Die Basis jeder Potenz ist in dieser Darstellung die Dimension einer Basisgröße. Der Exponent wird "Dimensionsexponent" dieser Basisgröße oder der entsprechenden Basiseinheit genannt. Jeder Dimensionsexponent "α", "β", "γ", "δ", "ε", "ζ" und "η" ist entweder Null oder eine positive oder negative, im Allgemeinen ganze Zahl. Der Betrag des Exponenten ist in der Regel deutlich kleiner als 10.

Beispiele für kohärente SI-Einheiten ("n" = 0)

Beispiele für nicht kohärente SI-Einheiten ("n" ≠ 0)

Ein Vorteil der ausschließlichen Verwendung kohärenter SI-Einheiten in Gleichungen liegt darin, dass keine Umrechnungsfaktoren zwischen Einheiten benötigt werden.

22 kohärenten abgeleiteten SI-Einheiten wurden eigene Namen und Einheitenzeichen (Symbole) zugeordnet, die selbst wieder mit allen Basis- und abgeleiteten Einheiten kombiniert werden können. So eignet sich zum Beispiel die SI-Einheit der Kraft, das "Newton" (= kg·m/s), um die Einheit der Energie, das "Joule" als Newton mal Meter (N·m) auszudrücken. Die folgende Tabelle listet diese 22 Einheiten in derselben Reihenfolge wie Tabelle 3 der SI-Broschüre (8. Auflage).

Neben den SI-Einheiten gibt es (vor allem in der Elektrodynamik, Informatik, im Wirtschaftswesen) noch einige weitere gebräuchliche Einheiten, die nicht zum SI gehören, insbesondere das sogenannte Gauß’sche- oder cgs-System.

Die ISO 1000:1992 wurde 2009 zurückgezogen, nachdem die Normenreihen ISO 80000 und IEC 80000 veröffentlicht wurden. Nationale und internationale Normen sowie EWG-Richtlinien haben das SI übernommen. In Deutschland wurden die darin festgelegten Einheiten mit dem "Gesetz über die Einheiten im Messwesen (1969)" (das 2008 durch Einfügung der Bestimmungen des früheren Zeitgesetzes zum "Gesetz über die Einheiten im Messwesen und die Zeitbestimmung" (EinhZeitG) erweitert wurde) für den amtlichen und geschäftlichen Verkehr vorgeschrieben. Die aktuelle Ausführungsverordnung von 1985 nennt in einer Anlage die zulässigen Bezeichnungen und verweist im übrigen auf Nach § 3 der Verordnung Die vorige Verordnung hatte noch etliche Nicht-SI-Einheiten ohne Zusätze erlaubt, zum Beispiel mmHg (Millimeter-Quecksilbersäule) für den Blutdruck. In der Schweiz ist die Bezeichnung mmHg auch für den Druck anderer Körperflüssigkeiten zulässig. Das SI-Regelwerk nennt auch seinerseits Nicht-SI-Einheiten, deren Verwendung zusammen mit dem SI akzeptiert ist. Die SI-Broschüre regelt nicht nur die Einheitennamen, sondern gibt auch Formatierungsregeln für die Schreibweise von Einheitenzeichen und Zahlenwerten.

Nach ISO sind Größensymbole (Formelzeichen) in "kursiver" Schrift zu schreiben, Einheitenzeichen in aufrechter Schrift. Größenangaben sollen stets mit Zahlenwert "und" Einheit gemacht werden; dazwischen kein Multiplikationszeichen:

Darin steht "A" als Symbol für die Größe, {"A"} für den Zahlenwert von "A" und ["A"] für die Einheit von "A" (ausgeschrieben oder als Einheitenzeichen).

Von dieser zusammenhängenden Schreibweise wird abgewichen, wenn viele gleichartige Größenangaben zu machen sind, in Tabellen oder Achsbeschriftungen. Empfohlen wird dafür die Schreibweise "A"/["A"] = {"A"}, also z. B. "T"/K = 300, 400, 500 für "T" = 300 K, 400 K, 500 K. Motivation: Denkt man sich anstelle der Größe "T" das Produkt aus Zahlenwert und Einheit, so kürzt sich die Einheit weg. Um Verwirrung zu vermeiden, falls die Einheit selbst einen Bruch darstellt, wird empfohlen, negative Exponenten einzeln an die Einheitenzeichen des Nenners zu setzen, für einen Wärmewiderstand "R" in Kelvin pro Watt also "R"/K W. Nicht normgerecht, aber üblicher sind die Schreibweisen „"R" in K/W“, „"R" (K/W)“ und „"R" [K/W]“.

Größensymbole (Formelzeichen) sind in "kursiver" Schrift zu schreiben. Die Zeichen können frei gewählt werden – allgemein übliche Formelzeichen wie "l", "m" oder "t" stellen lediglich Empfehlungen dar. Auch DIN-Normen enthalten Empfehlungen für Formelzeichen. Die Wahl von Namen und Symbol einer physikalischen Größe empfiehlt die SI-Broschüre ohne Assoziation zu einer bestimmten Einheit. Demnach sollen Bezeichnungen wie Literleistung vermieden werden. Die Celsius-Temperatur gehorcht dieser Empfehlung allerdings nicht. Weitere, jedoch nicht so bedeutsame Beispiele der Nicht-Einhaltung dieser Empfehlung sind der Stundenwinkel, die Gradtagzahl und der Heizgradtag.

Die Einheitenzeichen von nicht zusammengesetzten Einheiten sind international einheitlich. Unabhängig vom Format des umgebenden Textes sind sie in aufrechter Schrift zu schreiben. Sie werden in Kleinbuchstaben geschrieben, außer wenn sie nach einer Person benannt wurden – dann wird der erste Buchstabe groß geschrieben. Beispiel: „1 s“ bedeutet eine Sekunde, während „1 S“ das nach Werner von Siemens benannte Siemens darstellt. Eine Ausnahme dieser Regel bildet die Nicht-SI-Einheit Liter: Obwohl es nicht nach einer Person benannt ist, kann für sein Einheitenzeichen neben dem klein geschriebenen l auch das groß geschriebene L verwendet werden. Letzteres ist vor allem im angloamerikanischen Raum üblich, um Verwechslungen mit der Ziffer „eins“ zu vermeiden.

Ein SI-Präfix (wie "Kilo" oder "Milli") kann für ein dezimales Vielfaches oder einen Teil unmittelbar vor das Einheitenzeichen einer kohärenten Einheit gestellt werden, um Einheiten in unterschiedlichen Größenordnungen anschaulicher darzustellen. Eine Ausnahme bildet das Kilogramm (kg), das nur vom Gramm (g) ausgehend mit SI-Präfixen verwendet werden darf. Beispielsweise muss es für 10 kg „mg“ und nicht „μkg“ heißen.

Einheitenzeichen folgen nach einem Leerzeichen dem Zahlenwert, auch bei Prozent und Temperaturangaben in Grad Celsius. Zur besseren Leserlichkeit und der Vermeidung von Zeilenumbrüchen sollte ein schmales Leerzeichen verwendet werden. Einzig die Einheitenzeichen °, ' und " für die Nicht-SI-Winkeleinheiten Grad, Minute und Sekunde werden direkt nach dem Zahlenwert ohne Zwischenraum gesetzt.

Hinweise auf bestimmte Sachverhalte sollen nicht an Einheitenzeichen angebracht werden (als tiefgestellte Zeichen); sie gehören dagegen zum Formelzeichen der verwendeten physikalischen Größe oder in erläuternden Text. Falsch ist V als „Einheit“ von Effektivwerten der elektrischen Spannung in Volt, VDC für die Angabe einer elektrischen Gleichspannung in Volt, oder %(V/V) für „Volumenprozent“.

Dimensionssymbole werden als aufrecht stehender Großbuchstabe in serifenloser Schrift geschrieben.

Sprachabhängige Schreibweise:

Eine Einheit hat einen ausgeschriebenen Einheitennamen und ein Einheitenzeichen. Je nach Sprache sind unterschiedliche Schreibweisen für Einheitennamen (dt. "Sekunde", engl. ', frz. ') vorgesehen. Die Einheitennamen unterliegen außerdem der normalen Deklination der jeweiligen Sprache.

Die Einheitenzeichen sind streng genommen international einheitlich, und werden auch nicht dekliniert. In Sprachen, die nicht das lateinische Schriftsystem verwenden, ist es allerdings teilweise üblich, die Einheitenzeichen mit Zeichen des eigenen Alphabetes zu schreiben (Transliteration). Beispielsweise wird auf Russisch üblicherweise Kilometer mit „км“ abgekürzt, und Kilogramm als „кг“.

Wie aus den genannten derzeit gültigen Definitionen der SI-Basiseinheiten ersichtlich, wurde für bisher zwei fundamentale physikalische Konstanten (Naturkonstanten) ein exakter Zahlenwert festgelegt. Das war sinnvoll, da diese Naturkonstanten sich genauer bestimmen ließen als die beteiligten Basiseinheiten (der größte Beitrag zur Unsicherheit des Zahlenwertes stammte von den Maßeinheiten). In der Folge dienen Messungen dieser Naturkonstanten der Darstellung der durch sie definierten Basiseinheit:

Zukünftig sind weitere Neudefinitionen von SI-Basiseinheiten zu erwarten, die mit der exakten Festlegung von einigen Naturkonstanten einhergehen. Mögliche Neudefinitionen von SI-Basiseinheiten werden auf der alle vier Jahre stattfindenden Generalkonferenz für Maß und Gewicht diskutiert. Der formale Beschluss zur Neudefinition wird für die 25. Sitzung der Generalkonferenz für Maß und Gewicht, CGPM, im Herbst 2018 erwartet. 

Im Folgenden sind die mit Stand 2011 vorgeschlagenen Neudefinitionen der SI-Basiseinheiten zusammengefasst.


Auf der nächsten Generalkonferenz für Maß und Gewicht im Jahr 2018 sollen voraussichtlich diese Definitionen festgelegt werden:




</doc>
<doc id="4557" url="https://de.wikipedia.org/wiki?curid=4557" title="Stunde">
Stunde

Die Stunde (von ‚Stehen‘, ‚Aufenthalt‘, ‚feststehender Zeitpunkt‘, ‚kurzer Zeitraum‘, ‚Stunde‘) bezeichnet den vierundzwanzigsten Teil eines Tages. Neben einer Teilung in 24 gleiche Teile gibt es auch andere Stundenbegriffe.

Das lateinische Wort ist , daher das Einheitenzeichen codice_1 oder codice_2.

Zur genauen Unterscheidung einer Stunde (mit 60 Minuten) z. B. von einer Unterrichtsstunde (mit häufig 45 Minuten), wird auch von einer Zeitstunde gesprochen.

Die Stunde ist eine Einheit der Zeit. Das Einheitenzeichen ist h (v. lat. ). Die Stunde gehört zwar nicht zum Internationalen Einheitensystem (SI), ist zum Gebrauch mit dem SI aber zugelassen. Dadurch ist sie eine gesetzliche Maßeinheit. Aufgrund der nichtdezimalen Unterteilung ist bei wissenschaftlichen Berechnungen zuerst eine Umrechnung in Sekunden erforderlich.

Da heutige Atomuhren die Zeit sehr genau messen können und die Rotationsgeschwindigkeit der Erde variiert, wurde die Stunde neu definiert über eine Sekunde, die Atomzeit mit astronomischer Universalzeit verbindet.

Die 24-Stunden-Zählung eines ganzen Tages ist erstmals im Alten Ägypten bezeugt und fand später unter anderem in der griechischen Antike um das 3. vorchristliche Jahrhundert Anwendung, wo sich das 24-Stunden-System aus dem Winkelmaß ableitete. Von dort verbreitete sie sich schon bis zur Zeitenwende über die ganze (alte) Welt.

Im Laufe der Geschichte wurden verschiedene Verfahren zur Stundenzählung, also der Nummerierung, verwendet:

Als "volle Stunde" bezeichnet man den Beginn der "Minute Eins", also beispielsweise 08:00:00; es wird auch „Schlag acht“ genannt. Der Begriff kommt daher, dass (im obigen Beispiel) „die achte Stunde voll“ wird. Daraus abgeleitet sind die verbreiteten Stundenteilungen "halbe Stunde", "Viertelstunde", und die Zeitangaben (chronologisch)
„viertel acht“ (07:15), „halb acht“ (07:30), „dreiviertel acht“ oder „viertel vor acht“ (07:45) und „viertel nach acht“ (08:15).

Der Begriff ‚Stunde‘ wird – neben dem heutigen physikalisch-chronometrischen Begriff – auch verwendet für die historischen chronologischen und astronomischen Zeitsysteme:




</doc>
<doc id="4559" url="https://de.wikipedia.org/wiki?curid=4559" title="Siemens (Einheit)">
Siemens (Einheit)

Siemens ist im SI die Maßeinheit des elektrischen Leitwertes und nach Werner von Siemens benannt. Der Leitwert 1 S ist der Kehrwert des elektrischen Widerstandes 1 Ω. Das Ohm ist die SI-Einheit des elektrischen Widerstandes:

1860 hatte Siemens in Poggendorffs Annalen der Physik und Chemie den Aufsatz "Vorschlag eines reproducirbaren Widerstandsmaaßes" veröffentlicht, Einzelheiten hierzu siehe unter Ohm.

"Mho" ist eine veraltete Bezeichnung für die Einheit "Siemens", die Bezeichnung geht auf William Thomson zurück. Die Bezeichnung Mho (Ohm rückwärts gelesen) und das Symbol ℧ (ein kopfstehendes großes Omega) drücken aus, dass es sich um den Kehrwert der Einheit Ohm handelt. Verwendet wurden sie bis in die 1930er Jahre, in den USA im Bereich der Elektronik informell auch weiterhin.


</doc>
<doc id="4560" url="https://de.wikipedia.org/wiki?curid=4560" title="Stilb">
Stilb

Das Stilb (sb) ist eine veraltete Einheit der Leuchtdichte nicht selbstleuchtender Körper und gilt seit dem 1. Januar 1978 nicht mehr als offizielle Maßeinheit.

Das Wort leitet sich ab vom griechischen Wort "stilbein" (glänzen) und wurde um 1920 durch André-Eugène Blondel geprägt. Während der nordamerikanische Raum bildhaftere Begriffe wie „Kerzen pro Quadratmeter“ bevorzugte, blieb das Stilb in Europa bis zum Zweiten Weltkrieg in Gebrauch.

Das Stilb entspricht - bis auf einen Faktor - der SI-Einheit cd/m²:

mit formula_2 für das Nit.

Als Untereinheit für selbstleuchtende Körper galt das Apostilb bzw. Blondel:

formula_4

mit



</doc>
<doc id="4561" url="https://de.wikipedia.org/wiki?curid=4561" title="Sievert (Einheit)">
Sievert (Einheit)

Das Sievert (Einheitenzeichen: Sv), nach dem schwedischen Mediziner und Physiker Rolf Sievert, ist die Maßeinheit verschiedener gewichteter Strahlendosen bei ionisierender Strahlung. Sie dient zur Bestimmung der Strahlenbelastung biologischer Organismen und wird bei der Analyse des Strahlenrisikos verwendet. Das Sievert wird als Einheit herangezogen für:


Da eine Dosis von 1 Sv ein sehr großer Wert ist, werden die üblicherweise vorkommenden Werte mithilfe eines Vorsatzes für Maßeinheiten (SI-Präfix) in Millisievert (1 mSv = 0,001 Sv = 10Sv) oder Mikrosievert (1 μSv = 0,000 001 Sv = 10Sv) angegeben. In Ausnahmefällen werden die Angaben auch in Nanosievert (1 nSv = 0,000 000 001 Sv = 10Sv) vorgenommen.

Die biologische Wirksamkeit ionisierender Strahlung ist abhängig von der Strahlenart und deren Energie und wird durch Strahlendosen quantifiziert. Weitere Abhängigkeiten sind die Eigenschaften der exponierten Organe und der zeitliche Expositionsverlauf.

Diese Abhängigkeiten können durch Wichtungsfaktoren beschrieben werden, die als dimensionslose Multiplikatoren in die zu ermittelnden Dosen eingehen. Die Wichtung hat den Zweck, Angaben von Strahlendosen bzgl. ihres Schädigungspotenzials miteinander vergleichen zu können, ohne zusätzliche Details zu kennen.

Basisgröße, die jeweils mit den Wichtungsfaktoren multipliziert wird, ist die Energiedosis, gemessen in der Maßeinheit J/kg mit der besonderen Einheitenbezeichnung Gray (Gy). Dass in einer Dosisangabe Wichtungsfaktoren enthalten sind, wird durch die besondere Einheitenbezeichnung Sievert (Sv) kenntlich gemacht. Die physikalische Maßeinheit bleibt unverändert das J/kg.

Körperdosen (Sammelbezeichnung für Organdosen und die effektive Dosis) sind solchermaßen gewichtete Strahlendosen. Sie dienen der Quantifizierung des Risikos für das Auftreten stochastischer Strahlenschäden (Krebs und vererbbare Defekte). Bei Organdosen wird die mittlere Energiedosis eines Organs zur Berücksichtigung der Strahlenart mit dem Strahlungs-Wichtungsfaktor w der Strahlenart multipliziert. Dieser Faktor berücksichtigt die relative biologische Wirksamkeit (RBW) der betrachteten Strahlenart im Vergleich zu Strahlung mit niedrigem linearen Energieübertragungsvermögen (LET). Im Rahmen der Ermittlung der effektiven Dosis und der damit verbundenen Aufsummierung der Organdosen werden diese mit den Gewebe-Wichtungsfaktoren w der betroffenen Organe multipliziert. Diese Faktoren drücken die relative Empfindlichkeit der Organe untereinander bzgl. des Auftretens stochastischer Strahlenschäden aus.

Bzgl. der Größe der Strahlungs-Wichtungsfaktoren und der Gewebe-Wichtungsfaktoren siehe die Artikel Strahlungswichtungsfaktor bzw. effektive Dosis.

Die Äquivalentdosis ist eine Messgröße für die Orts- und Personendosisüberwachung bei äußerer Strahlenexposition. Bei ihr wird als Wichtungsfaktor ein Qualitätsfaktor verwendet, der von der ICRU (International Commission on Radiation Units and Measurements) für ein standardisiertes Weichteilgewebe definiert ist. Ungeachtet der unterschiedlichen Wichtung wird auch hierfür das Sievert als Einheitenbezeichnung verwendet. Im praktischen Strahlenschutz ist dieser Unterschied ohnehin meist nicht maßgebend, so dass die Äquivalentdosis eine geeignete Messgröße darstellt, um bei äußerer Bestrahlung mit hinreichender Genauigkeit auf Körperdosen schließen zu können.

Bei innerer Bestrahlung durch Radionuklide, die dem Körper zugeführt und von ihm inkorporiert werden, beziehen sich Dosisangaben in Sievert auf Organ-Folgedosen und die effektive Folgedosis. In diese Dosen ist die andauernde Exposition durch die inkorporierten Radionuklide eingerechnet, die im Zeitraum ab ihrer Zufuhr stattfindet. Folgedosen (in Sievert) können bei Kenntnis von Radionuklid, zugeführter Aktivität (in Becquerel (Bq)), chemischer Form, Art und Weise der Zufuhr etc. mit Hilfe von Dosiskoeffizienten (in Sv/Bq) abgeschätzt werden. Diese Dosiskoeffizienten sind nuklidspezifisch, wodurch die Strahlenart bzw. deren Strahlungs-Wichtungsfaktor w berücksichtigt ist, und sie berücksichtigen weiterhin die biokinetischen Eigenschaften des zugeführten radioaktiven Stoffs.

Bei den schädigenden Wirkungen ionisierender Strahlen wird zwischen stochastischen und deterministischen Strahlenschäden unterschieden. Siehe dazu die Artikel Strahlenschutz und Strahlenrisiko.

Körperdosen und Äquivalentdosis in Sievert werden als Dosisgrößen im Strahlenschutz in einem Dosisbereich bis zu einigen 100 mSv angewendet, wo stochastische Wirkungen bekanntermaßen auftreten oder (bei niedrigen Dosen) vermutet werden und wo deterministische Wirkungen noch nicht maßgebend sind.

Bei deutlich höheren Dosen mit den dann maßgebenden deterministischen Wirkungen werden die Wichtungsfaktoren hingegen nicht mehr angewendet, sondern Strahlendosen werden allein in Form der Energiedosis in Gray (Gy) angegeben. Ein typischer Anwendungsbereich neben dem Strahlenschutz ist hierfür beispielsweise die Strahlentherapie.

Zur Bewertung eines Strahlenrisikos kann ein Vergleich mit der natürlichen Strahlenexposition dienen. Eine in Deutschland lebende Person erhält eine mittlere effektive Dosis von 2,1 mSv pro Jahr. Weitere Einzelheiten dazu siehe den Artikel Strahlenexposition.

Zur Begrenzung der Strahlenexposition der Bevölkerung legt in Deutschland die Strahlenschutzverordnung zusätzlich zur natürlichen und medizinischen Strahlenexposition einen Grenzwert von 1 mSv pro Jahr für die effektive Dosis von Personen bei geplanten Expositionssituationen fest.

Für Notfall-Expositionssituationen ist ein Eingreifrichtwert der effektiven Dosis von 100 mSv in sieben Tagen für eine Evakuierung vorgesehen. Für das erste Jahr nach Eintritt eines Notfalls ist ein Referenzwert der effektiven Dosis von 100 mSv vorgesehen, der in dieser Zeit nicht überschritten werden darf. Weitere Einzelheiten dazu siehe den Artikel Radiologische Gefährdungslage.

Die maximale erlaubte effektive Jahresdosis für beruflich strahlenexponierte Personen beträgt in Deutschland 20 mSv und über ein Berufsleben dürfen nicht mehr als 400 mSv zusammenkommen. Ein ungeborenes Kind darf bis zu seiner Geburt keine höhere Strahlendosis als 1 mSv erhalten.
Schwellenwerte für deterministische Strahlenwirkungen werden damit nach heutigem Wissen deutlich unterschritten. Klinische Symptome der Strahlenkrankheit treten erst bei einer kurzzeitigen Ganzkörper- oder großvolumigen Teilkörperbestrahlung im Dosisbereich oberhalb von 1 Gray (Gy) auf.

Offizielle Einheit anstelle des Sievert war bis zum 1. Januar 1978 das Rem (rem). Ein Sievert entspricht 100 rem.


</doc>
<doc id="4563" url="https://de.wikipedia.org/wiki?curid=4563" title="Stone (Einheit)">
Stone (Einheit)

Das Stone (englisch "Stein") ist eine britische nicht SI-konforme Einheit von Masse und Gewichtskraft. Es wird in Avoirdupois (Pfund), Unzen und Dram unterteilt. Bei traditionellen englischen Einheiten wurde nur bei wissenschaftlichem Gebrauch zwischen Gewichtskraft und Masse unterschieden. Beispiel: lb als pound-force (Kraftpfund).


Bis 1985 war das Stone in Großbritannien eine offizielle Einheit. Seitdem ist sein Gebrauch zu geschäftlichen Zwecken (z. B. Warenauszeichnung, technische Daten) durch den "Weights and Measures Act" ausdrücklich untersagt. Gleiches gilt für die oben zur Erklärung benutzten Einheiten Dram und (long) ton. In Ländern, in denen britisches Englisch gesprochen wird, wie im Vereinigten Königreich, in Irland, Australien oder Neuseeland ist es jedoch immer noch üblich, das menschliche Körpergewicht in "stone" anzugeben („I have lost two stone five“ – „Ich habe zwei Stone und fünf Pfund (15 kg) abgenommen“). Stone hat als inoffizielle Einheit für menschliches Körpergewicht eine ähnliche Bedeutung wie die veraltete und abgeschaffte Kilokalorie im Deutschen als Einheit für den Energiegehalt von (menschlicher) Nahrung oder PS für die Leistung speziell von Verbrennungsmotoren.

Zum Teil wird das Gewicht von Wrestlern, Boxern und Jockeys noch in Stone und Pfund angegeben, was jedoch zunehmend durch eine Angabe in Pfund ersetzt wird.

Wenn Stone als Einheit mit vorangestellter Zahl verwendet wird, benutzen britische Muttersprachler kein Plural-S, ohne Zahl dagegen schon („What is your weight in stones and pounds?“ – „Wie ist dein Gewicht in Stone und Pfund?“).




</doc>
<doc id="4565" url="https://de.wikipedia.org/wiki?curid=4565" title="Scrupel">
Scrupel

Der Skrupel oder das Scrupel (nach lat.: ', kleiner Kieselstein, auch (englisch) Scruple) ist eine nicht SI-konforme Maßeinheit. 

Das Scrupel war im antiken Rom eine der kleinsten gebräuchlichen Maßeinheiten für die Masse, ist aber auch als Maßeinheit auf andere Größen übertragen worden. Später wurde die Einheit als Apothekergewicht gebraucht und mit dem Einheitenzeichen ℈ oder s.ap. (ap. für ) abgekürzt. 
Als Maßeinheit der Masse betrug das römische Scrupel (, s.tr.) 1/24 einer Feinunze (, oz.tr.), also 1/288 eines Pfunds (, lb.tr.), was in etwa 1,2 Gramm entspricht. Der Wert der Einheiten war jedoch in unterschiedlichen Regionen und im Laufe der Zeit leicht unterschiedlich. 

Das Nürnberger Apothekerpfund betrug historisch 357,84 Gramm. Das Königreich Bayern rundete dieses unter Montgelas 1811 auf 360 Gramm. 

Siehe auch: Alte Maße und Gewichte (Bayern)




Scrupel war auch ein Teil des regionalen Medizinalgewichts, welches 20 Gran wog. Das Aß (holl.) kann mit 0,048 Gramm gerechnet werden. 


Ableitung von der Toise, Altfranzösisches Längenmaß

Als Maßeinheit der Fläche betrug es 1/288 eines Jochs.

Als Maßeinheit der Zeit war ein Scrupel 1/24 einer Stunde.


</doc>
<doc id="4567" url="https://de.wikipedia.org/wiki?curid=4567" title="Mile (Einheit)">
Mile (Einheit)

Die mile (früher auch Englische Meile oder engl. statute mile genannt) ist eine Längeneinheit im Vereinigten Königreich und den USA. Sie beträgt exakt 1609,344 Meter.

1 mile = 1.609,344 m (Seit 1. Juli 1959)

1 mile = 1.760 Yard = 5.280 Fuß = 63.360 Zoll

1 mile = 8 Furlong = 320 Pole = 5.280 Fuß

Bis zur Vereinheitlichung des angloamerikanischen Maßsystems war die Meile im Commonwealth of Nations (Englische Meile, oder engl. statute mile genannt) und den Vereinigten Staaten um 3 mm unterschiedlich definiert. Beide Definitionen basierten allerdings auf einem britischen Statut von 1593, welches die Meile mit 5280 Fuß definiert: Daher wurde die so definierte Meile häufig auch als "statute mile" bezeichnet.

Da die Definitionen des Fuß leicht (um 600 nm) voneinander abwichen (ein britischer Fuß entsprach 0,999998 US-Fuß), hatten auch die Meilen eine leicht abweichende Länge voneinander.

Seit der Vereinheitlichung wird die "mile" international mit 1.609,344 Meter definiert. Die ehemals in den USA verwendete Definition wird nur noch bei der Landvermessung in den USA verwendet und als "survey mile" bezeichnet. Sie entspricht 1.609,347 Metern.



</doc>
<doc id="4569" url="https://de.wikipedia.org/wiki?curid=4569" title="Suzanne Vega">
Suzanne Vega

Suzanne Nadine Vega (* 11. Juli 1959 in Santa Monica, Kalifornien) ist eine US-amerikanische Sängerin und Songwriterin.

Suzanne Vega wurde in Santa Monica im US-Bundesstaat Kalifornien geboren. Ein Jahr nach ihrer Geburt zog ihre Mutter mit ihr nach New York, wo Suzanne in East Harlem und an der Upper West Side aufwuchs. Im Alter von neun Jahren fing sie an, Gedichte zu schreiben; ihr erstes Lied schrieb sie mit 14 Jahren. Zunächst besuchte sie die "La Guardia High School of Music & Art and Performing Arts", wo sie modernen Tanz studierte. Sie erkannte jedoch, dass Musik ihre Berufung war. Als sie am Barnard College der Columbia University Anglistik studierte, trat sie auf kleinen Bühnen im New Yorker Künstlerviertel Greenwich Village auf. 1984 bekam sie ihren ersten Plattenvertrag.

Vega schreibt Musik größtenteils für ihre Gitarre. In der Produktion werden die Songs für eine mehrköpfige Band arrangiert.

Das 1985 veröffentlichte Debütalbum "Suzanne Vega" wurde äußerst positiv aufgenommen. Die Songs stemmen sich dem „Bigger is better“-Motto in der Mitte der 1980er Jahre entgegen. Sie sind jedoch keine typischen Protestsongs, sondern eher introspektiv.

Das 1987 veröffentlichte Nachfolgealbum "Solitude Standing" enthält zwei Songs, die Suzanne Vega einer breiteren Öffentlichkeit bekannt machten: "Tom’s Diner", ein Lied über "Tom’s Restaurant", bekannt auch durch die Adaption der Gruppe DNA und die Tatsache, dass es das erste Lied war, das jemals in das MP3-Format konvertiert wurde, sowie "Luka", ein Lied, das aus der Sicht eines misshandelten Kindes geschrieben wurde. Die Musik ist im Vergleich zu ihrem ersten Album stärker an der Rockmusik orientiert.

Das dritte Album "Days of Open Hand" aus dem Jahr 1990 stellt ein in sich geschlossenes Werk dar. Musik und Text sind getragen von mystischem Symbolismus und tiefen Emotionen. Die Musik ist im Vergleich zu den vorherigen Alben experimenteller.

1992 wurde "99.9°F" veröffentlicht. Das Album besteht aus einem Mix aus akustischem Folk und Songs, die sich zwischen Dance-Beats und Industrial Noise bewegen.

Album Nummer fünf, "Nine Objects of Desire," erschien 1996. Musikalisch variierte Vega den früheren, einfacheren Stil mit der ausführlicheren Produktion von "99.9F°" sowie mit Bossa Nova.

Im September 2001 erschien ihr Album "Songs in Red and Gray". Als Ausdruck ihrer Erfahrungen trat die Beziehung zwischen Mann und Frau, insbesondere deren Fehldeutungen und Scheitern, thematisch in den Vordergrund. Musikalisch konzentrierte sich Vega wieder stärker auf akustische Elemente. Zugleich formulierte sie für sich einen höheren Anspruch, als nur ein unkompliziertes Folk-Album zu produzieren.

2007 erschien "Beauty & Crime", das erste beim Plattenlabel Blue Note Records veröffentlichte Album.

Am 9. Februar 2010 erschien in den USA ihr Album "Close-Up Vol. 1, Love Songs" (weltweites Erscheinungsdatum 14. Juni 2010) auf ihrem eigenen Label „Amanuensis Productions“. Es enthält Neuaufnahmen vorhandener Songs zum Thema „Liebe“. Bis 2012 erschienen vier Alben mit Neuaufnahmen, der zweite Teil zum Thema „Menschen, Orte und Dinge“, der dritte Teil zum Thema „Seinszustand“ („State of being“) und der letzte Teil mit „Familienliedern“. Die Idee dahinter sei zum einen, die Lieder verfügbar zu halten (da sie keinen Plattenvertrag hat) und zum anderen, wenigstens eine Version der eigenen Songs zu besitzen, wenn man schon nicht über die Originalaufnahmen verfügt. Die Neuaufnahmen sind akustische Versionen der Songs.

2011 widmete sich Vega vor allem ihrem Theaterstück "Carson McCullers talks about love", einer fiktiven Autobiographie mit eigens dafür arrangierten Songs der Schriftstellerin Carson McCullers, die mit Vega in der Hauptrolle im April 2011 in New York uraufgeführt wurde.

Nach sieben Jahren Pause veröffentlichte Suzanne Vega im Februar 2014 ein Studioalbum mit zehn neuen Songs. Das Album trägt den Titel "Tales from the Realm of the Queen of Pentacles" und wurde von Gitarrist Gerry Leonard produziert. Bis Mitte des Jahres befand sich Vega auf Welttournee in Europa, den USA, Asien und Australien. Im Jahre 2016 kam Suzanne Vega für einige Auftritte nach Deutschland.

Obwohl Suzanne Vegas kommerzieller Erfolg ab Mitte der 1990er abebbte, prägten einige ihrer Songs wie "Tom’s Diner" und "Luka" das musikalische Gesicht des frühen Jahrzehnts. Die Musikpresse nahm ihren Erfolg Ende der Achtziger zum Anlass, sie mit den ebenfalls stark song-orientierten Musikerinnen Tanita Tikaram, Tracy Chapman und Michelle Shocked zu vergleichen. Der gleichzeitige Erfolg brachte verstärkt feministische Impulse in die Rockmusik und trug dazu bei, die Stellung der Frau im Rock-Business zu verbessern.

Das MP3-Forscherteam um Karlheinz Brandenburg machte die ersten Praxistests mit der A-cappella-Version des Liedes "Tom’s Diner" von Suzanne Vega. Bei seiner Suche nach geeignetem Testmaterial las Brandenburg in einer Hi-Fi-Zeitschrift, dass deren Tester das Lied zum Beurteilen von Lautsprechern nutzten, und empfand das Stück als geeignete Herausforderung für eine Audiodatenkompression. "Tom’s Diner", ein Song über ein kleines Restaurant in New York, wurde somit das weltweit erste Lied im MP3-Format – und Suzanne Vega zur „Mutter von MP3“ („mother of mp3“).

Suzanne Vega trennte sich 1998 nach dreijähriger Ehe von ihrem Mann Mitchell Froom, dem Vater ihrer 1994 geborenen Tochter Ruby. Sie wechselte Manager und Plattenfirma und widmete sich ihrem ersten Buch, "The Passionate Eye: The Collected Writing of Suzanne Vega". 2006 heiratete sie den Anwalt Paul Mills, mit dem sie in New York lebt.


weitere Alben




</doc>
