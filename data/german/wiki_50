<doc id="5727" url="https://de.wikipedia.org/wiki?curid=5727" title="Kanton Wallis">
Kanton Wallis

Das Wallis ( , , frankoprovenzalisch "Valês"), amtlich Kanton Wallis oder Staat Wallis beziehungsweise Canton du Valais oder État du Valais, ist ein Kanton im Südwesten der Schweiz. Der untere und mittlere Teil des Kantons hat eine französischsprachige (teilweise auch noch frankoprovenzalischsprachige), der obere Teil eine deutschsprachige Bevölkerung. Entsprechend gehört er sowohl zur Romandie als auch zur Deutschschweiz. Der Hauptort ist Sitten. Das Wallis ist von der Fläche her der drittgrösste Kanton der Schweiz und liegt vollständig im Gebiet der Alpen.

Das Wallis besteht (mit Ausnahme kleinerer Gebiete jenseits der Pässe Simplon und Gemmi) aus dem Tal der Rhone (Rotten) vom Rhonegletscher bis zum Genfersee und den Rhone-Seitentälern. Im Norden liegen die Berner und Waadtländer Alpen, im Süden die Walliser Alpen mit den mächtigsten und höchsten Bergmassiven der Alpen (Monte Rosa, Mischabel und Weisshorngruppe). Die höchsten Berge der Walliser Alpen und der Schweiz sind die Dufourspitze mit (höchster Berg der Schweiz und damit des Wallis), Nordend , Zumsteinspitze , Signalkuppe , Dom (höchster ganz auf Schweizer Staatsgebiet liegender Berg), Liskamm , Weisshorn , Täschhorn , Matterhorn , Parrotspitze , Dent Blanche , Ludwigshöhe , Nadelhorn , Grand Combin und Lenzspitze Mit dem Aletschgletscher, dem Gornergletscher und dem Walliser Fieschergletscher befinden sich im Wallis die drei grössten Gletscher der Alpen.

Durch den Schutz der umliegenden Berge ist das Haupttal des oberen Wallis, aber auch das Vispertal ausgesprochen trocken und warm mit einem Steppenklima. Die Wasserversorgung wird vielerorts durch Wasserleitungen, sogenannte Suonen oder Bissen, gewährleistet, die in den niederschlagsarmen Zonen im Wallis mindestens bis in die römische Zeit zurückreichen.

Der tiefste Punkt liegt bei am Genfersee.

Die wichtigsten Seitentäler sind nördlich der Rhone das Fieschertal, Lötschental und Dalatal. Südlich der Rhone liegen das Binntal, Nanztal, Saastal, Mattertal, Turtmanntal, Val d’Anniviers (deutsch '), Val d’Hérens (deutsch '), Val de Bagnes (deutsch ' oder auch '), Val d’Entremont und Val d’Illiez.

Im Kanton Wallis gab es am fünf Gemeinden mit mehr als 10'000 Einwohnern, die bevölkerungsreichste Gemeinde ist Sitten mit Einwohnern. Monthey hat , Martigny , Siders und Brig-Glis Einwohner. Weitere Zentren sind Naters, Saint-Maurice und Visp.

Das Wallis besitzt 13 Bezirke, welche aus den 13 Zehnden hervorgegangen sind. Auf dem Kantonswappen werden sie durch 13 Sterne repräsentiert. Die beiden Halbbezirke Westlich Raron und Östlich Raron bildeten gemeinsam einen Zehnden.

Das Wallis weist ein besonders trockenes Klima auf mit nur 500 bis 600 Millimeter Niederschlag pro Jahr: kalte Winter, trockene Sommer, starke Temperaturunterschiede und klare Luft. Grund dafür ist seine Lage zwischen den Gebirgsmassiven der Walliser Alpen im Süden und der Berner Alpen im Norden, die beide bis auf über 4000 Meter reichen und einen Grossteil der Niederschläge abfangen, die von Norden oder vom Mittelmeer her gegen die Alpen strömen. Das Unterwallis gehört zu den trockensten Tälern Europas. Das Steppenklima hat auch starken Einfluss auf die Vegetation, so dass nebst Reben auch Kakteen gedeihen.

Östlich von Siders (), im Oberwallis, wird Deutsch bzw. Walliserdeutsch, ein höchstalemannischer Dialekt, gesprochen. In und westlich von Siders im Mittelwallis und im Unterwallis spricht man Französisch bzw. teilweise noch frankoprovenzalische Mundart. Die Sprachgrenze bildet nördlich der Rhone der kleine Bach "Raspille" zwischen Siders und Salgesch. Südlich der Rhone wird die Sprachgrenze durch den Pfynwald markiert. Kantonale Amtssprachen sind Französisch und Deutsch, kommunale Amtssprache entweder Französisch oder Deutsch. Bei der Volkszählung 2000 lag der Anteil der Französisch sprechenden Bevölkerung bei 62,8 Prozent, Deutsch sprachen 28,4 Prozent. Italienisch wurde von 2,2 Prozent gesprochen, Rätoromanisch und andere rund 6,6 Prozent.

Die römisch-katholische und die evangelisch-reformierte Kirche sind beide öffentlich-rechtlich anerkannt, daneben können auch andere Religionsgemeinschaften anerkannt werden. Im Jahr 2014 waren 74,3 Prozent (2000: 81,2 Prozent) der Bevölkerung katholischen Glaubens und 5,8 Prozent waren evangelisch. 6,4 Prozent der Bevölkerung gehörten anderen Religionen an und 11,6 waren konfessionslos.

Viele Menschen aus den Alpenkantonen zieht es, zumindest vorübergehend, in die städtischen Ballungszentren des schweizerischen Mittellandes. Auch das Wallis ist von dieser Wanderungsbewegung betroffen. Jedes Jahr verlassen zahlreiche, vorwiegend junge Leute das Tal, um woanders zu arbeiten oder an einer Hochschule (Universität etc.), berufsbildenden Schule (Berufsschule etc.) oder in einem Lehrbetrieb eine Ausbildung zu absolvieren. Die meisten von ihnen tun dies, weil die Möglichkeiten dazu im Wallis beschränkt sind. Sie finden keine ihnen entsprechende Anstellung oder die angestrebte Ausbildung wird nicht angeboten. Teilweise besitzen die ausserhalb lebenden Walliser eigene Ferienhäuser, die sie zum Wandern oder Skifahren aufsuchen. Ein Teil der Ausgewanderten kehrt nach ein paar Jahren oder dem Abschluss der Ausbildung wieder ins Wallis zurück. Gerade für Hochschulabgänger ist es oft schwierig, im Wallis eine ihrer Ausbildung entsprechende Stelle zu finden. Erhebungen von 2004 zufolge arbeiten tatsächlich rund zwei von drei Wallisern mit einer höheren Ausbildung nach deren Abschluss nicht im Heimatkanton. Damit verliert dieser jährlich viele hochqualifizierte Arbeitskräfte und es geht ihm Kapital verloren (Talentabwanderung). Der Kanton investiert jedes Jahr rund 50 Millionen Schweizer Franken in die höhere Ausbildung von Personen, die später ausserhalb des Kantons arbeiten und leben.

Die gegenwärtige Kantonsverfassung datiert von 1907; sie hat seither zahlreiche Teilrevisionen erfahren.

Die Kantonshymne ist die "Walliser Hymne".

Gesetzgebende Behörde ist der "Grosse Rat" oder "Grand Conseil". Er zählt 130 vom Volk im Proporzsystem auf vier Jahre gewählte Mitglieder. Gleichzeitig mit den Abgeordneten werden jeweils 130 Stellvertreter (Suppleanten) gewählt.

Vom Grossen Rat erlassene Gesetze unterliegen der Volksabstimmung, falls eine solche innert 90 Tagen nach deren Veröffentlichung von 3000 Stimmberechtigten verlangt wird (fakultatives Referendum). Obligatorisch der Volksabstimmung unterliegen die Teil- und die Partialrevision der Kantonsverfassung (obligatorisches Referendum). Das Volk hat überdies das Recht, mittels Volksinitiative selbst die Ausarbeitung, Änderung oder Aufhebung eines Gesetzes oder die Ausarbeitung oder Änderung der Verfassung zu verlangen. Für eine Gesetzesinitiative braucht es die Unterschrift von 4000 Stimmberechtigten, für eine Verfassungsinitiative deren 6000.

Bei den letzten Wahlen erreichten die Parteien folgende Sitzzahlen:

Die oberste Vollziehungs- und Verwaltungsbehörde ist der aus fünf Mitgliedern bestehende "Staatsrat" oder "Conseil d’État". Die Wahl erfolgt direkt durch das Volk im Majorzsystem auf vier Jahre. Die drei verfassungsmässigen Regionen (Ober-, Mittel- und Unterwallis) haben Anrecht auf mindestens einen Sitz im Staatsrat. Die Bezirksklausel verhindert die doppelte Vertretung eines Bezirkes im Staatsrat. Der Staatskanzler, die Regierungsstatthalter sowie die Regierungsstatthalter-Stellvertreter werden durch den Staatsrat ernannt.

Oberstes kantonales Gericht ist das Kantonsgericht mit Sitz in Sitten. Es ist für Zivil- und Straffälle sowie für das Sozialversicherungsrecht und das Verwaltungsrecht zuständig. Für Zivil- und Straffälle in erster Instanz bestehen neun Bezirksgerichte. Auf Ebene der Gemeinden bestehen ein Gemeinderichteramt als Schlichtungsbehörde sowie ein Polizeigericht.

Öffentlichrechtliche Gemeindearten sind die Einwohnergemeinden, von denen es 126 gibt (2017). Sie sind die Träger der lokalen Selbstverwaltung.

Weiter gibt es 141 Burgergemeinden (u. a. Verwaltung der burgerlichen Güter) und 157 römisch-katholische Pfarrgemeinden sowie evangelisch-reformierte Kirchgemeinden.

Im Kanton Wallis hat die CVP (inklusive der – der nationalen CVP angeschlossen – CSP) ihre dominante Stellung eingebüsst. Zwar hält sie in der nach Majorzwahl gewählten Regierung nach wie vor die absolute Mehrheit inne, im nach Proporzwahl gewählten Parlament hat sie jedoch 2013 die absolute Mehrheit verloren. Nicht nur die CVP, sondern auch die CSP, die FDP, die SP und die SVP gliedern sich in autonome deutsch- und französischsprachige Parteien.

Die Staumauer Grande Dixence am Lac des Dix ist mit einer Höhe von 285 Metern eine der höchsten der Welt und die höchste Europas. Der Stausee liegt auf einer Höhe von 2365 m ü. M. und hat ein Fassungsvermögen von 400 Millionen Kubikmeter Wasser. Die zweithöchste Staumauer der Schweiz ist die des Lac de Mauvoisin mit einer Höhe von 250 Metern. Der Lac de Tseuzier liegt in einem Talkessel, der von bis zu 3200 Meter hohen Bergen umgeben ist. Der Lac de Moiry hat eine hell-türkise Farbe und liegt an der Strecke des Race across the Alps. Mit den Parc d’Attractions du Châtelard wird die Gegend um den Lac d’Emosson erschlossen, am 300 Meter höher gelegenen Lac du Vieux Emosson gibt es über 800 rund 250 Millionen Jahre alte Fussabdrücke von Dinosauriern. Nördlich des Sanetschpasses wurde zwischen 1959 und 1966 der Sanetschsee aufgestaut. Beim Bau des Staudamms am Mattmarksee kam es 1965 zu einem der schwersten Unglücke im Schweizer Bauwesen, 88 Bauarbeiter starben, als eine Gletscherzunge auf ihr Barackendorf stürzte. Der Griessee an der Grenze zu Italien wird vom Griesgletscher gespeist, der Stausee Ferden wurde 1975 gebaut und hat eine Länge von einem Kilometer.
Oberhalb der Massaschlucht liegt der Stausee Gibidum, der vom grössten Gletscher der Alpen, dem Aletschgletscher, gespeist wird.

Der Tourismus ist der wichtigste Wirtschaftssektor im Wallis. 

Im Bezirk Goms wurde 1850 der Hotelier César Ritz geboren. Im Ort Fiesch-Eggishorn leben 968 Einwohner und es gibt über 4'000 Gästebetten, in Bellwald sind es bei 460 Einwohner 4.300 Betten. Binn liegt im Binntal, das für seine Mineralienfunde bekannt ist. Rund 200 verschiedene Mineralien wurden hier gefunden, über ein Dutzend kommen nirgends sonst vor. Im Binntal leben drei Berufsstrahler, diese leben vom Mineraliensammeln. Die Kirche in Ernen ist seit 1214 urkundlich bezeugt, im Dorfkern stehen noch heute viele bis zu 500 Jahre alte Häuser. In der Gemeinde Obergoms liegt die Endstation der Dampfbahn Furka-Bergstrecke, die in Realp im Kanton Uri beginnt. Sie führt über die Steffenbachbrücke nach Tiefenbach und weiter durch den Furka-Scheiteltunnel über Gletsch nach Oberwald. Der erste Teil der Bahn wurde 1992 wiedereröffnet, der letzte Teil zwischen Gletsch und Oberwald im August 2010.

Das Aletschgebiet, das sich über die Bezirke Goms, Östlich Raron und Brig erstreckt, liegt im Zentrum des UNESCO-Weltnaturerbes Schweizer Alpen Jungfrau-Aletsch. Namensgebend ist der grösste Gletscher der Alpen, der Aletschgletscher. Am Gletscher liegt die Bettmeralp, sie kann durch zwei Luftseilbahnen erreicht werden. Da die Bettmeralp oberhalb des Rhonetals liegt, kann bei Inversionswetterlagen ein nebelgefülltes Tal vom sonnigen Hochplateau aus beobachtet werden. Die Fiescheralp liegt auf demselben Hochplateau und ist einer der drei Zugangsorte zum Skigebiet "Aletsch Arena", das 104 Pistenkilometer umfasst. Auf dem Gebiet von Riederalp liegt der Aletschwald, ein alter Arven-Lärchenwald, direkt am Aletschgletscher. Der Wald wurde 1933 von der Naturschutzorganisation Pro Natura gepachtet und unter Schutz gestellt, die Villa Cassel in Riederalp dient heute als Informationszentrum von Pro Natura.

In Brig steht das zwischen 1651 und 1671 errichtete Stockalperschloss, einer der grössten privaten Barockbauten der Schweiz. Das Schloss besitzt einen dreistöckigen Arkadenhof und drei quadratische Türme mit Zwiebelhauben, die nach den Heiligen Drei Königen Kaspar, Melchior und Balthasar benannt werden. In der Gemeinde Termen liegen die Sommer- und Wintersportorte Rosswald und Blatten bei Naters. Im Sommer können Touristen auf dem Massaweg durch die 6,5 Kilometer lange Massaschlucht wandern und im Winter unter anderem auf der Belalp auf über Ski fahren (66 km Skipisten und 4 km Langlaufloipen). Unter dem Namen Belalp Hexe werden seit 1983 jährlich verschiedene Skirennen auf der Belalp gefahren, die Hexenabfahrt ist zwölf Kilometer lang und überwindet 1'800 Höhenmeter, es nehmen rund 2'000 Teilnehmer an den Rennen teil. In Birgisch und Mund VS gibt es mehrere teilweise sehr alte Suonen, diese Wasserleitungen wurden früher im trockenen Innerwallis zur Bewässerung von Feldern und Wiesen benötigt. Die Suone "Wyssa" oberhalb von Mund wurde erstmals 1426 erwähnt, könnte aber schon im Jahr 930 errichtet worden sein.

Visp ist ein kulturelles Zentrum des Oberwallis, im Kulturzentrum "La Poste" finden regelmässig Opern, Theatervorstellungen und Konzerte statt. Bekannt wurde Visperterminen mit seinem Weisswein "Heida" (ein Savagnin), der am höchstgelegenen Weinberge nördlich des Alpenhauptkammes wächst. Die Ritibrücke in Neubrück unterhalb von Stalden VS ähnelt der Stari most und wurde 1599 gebaut, die Kinnbrücke in Stalden 1544. Im Staldenrieder Weiler Gspon liegt auf rund die GsponArena des FC Gspon, laut eigenen Angaben der höchstgelegene Fussballplatz Europas. Die Alp von Törbel ist die Moosalp, hier finden jedes Jahr im Zuge des Alpaufzuges Ringkuhkämpfe statt. Oberhalb von St. Niklaus und Grächen liegen der Riedgletscher und die Bordierhütte, von der aus der Nadelgrat und der Gipfel des Balfrin bestiegen werden kann. Zudem beheimatet St. Niklaus das weltweit einzigartige Bergführermuseum, welches seine Besucher in die Zeit der Alpen- und insbesondere der Zaniglaser Bergführerpioniere entführt, die vor allem über die ersten zwei Generationen hinweg in der ersten Reihe standen und weltweit das Bergführerwesen in den verschiedensten Bereichen massgeblich prägten. Von den insgesamt 82 Hauptgipfeln der Viertausender der Alpen umgeben 36 das Mattertal, das sich von Stalden über St. Niklaus bis Zermatt zieht, darunter mit der Dufourspitze der höchste Berg der Schweiz und einer der Seven Second Summits. Das Matterhorn liegt zwischen Zermatt und Breuil-Cervinia, der von Zermatt aus begangene "Hörnligrat" (Nordostgrat) ist die am häufigsten begangene Aufstiegsroute und zusammen mit dem "Liongrat" (Südwestgrat) auch die einfachste, mit einer Schwierigkeit von III+ auf der UIAA-Skala.

Durch das Saastal fliesst die Saaservispa, im Zentrum des Tals liegt Saas-Grund. Die Antoniuskapelle in Bidermatten steht in der Gemeinde Saas-Balen, gehört jedoch zur Pfarrei St. Bartholomäus in Saas-Grund. Das Gebetshäuslein neben der Kapelle ist aus dem Jahr 1619 und die älteste Kapelle des Saastals. Saas-Fee ist ein Skiort oberhalb von Saas-Grund, auch im Sommer kann auf dem Feegletscher Ski gefahren werden. Eine Besonderheit von Saas-Fee stellt die Metro Alpin dar, eine Art U-Bahn die die Skifahrer von der Station «Felskinn» () zur Station «Mittelallalin» () bringt. Das südlichste der Saas-Dörfer ist Saas-Almagell, neben Tourismus spielt hier die Elektrizitätswirtschaft am Mattmarksee eine Rolle. Der See wurde 2008 komplett abgelassen, um Renovierungsarbeiten an ihm durchzuführen.

Das Lötschental liegt im Bezirk Westlich Raron und wird von der Lonza durchflossen. Der im hintersten Ende des Lötschtals gelegene Langgletscher ist die Quelle des Flusses. Das alpine Skisportzentrum im Lötschental ist die Lauchernalp, neben einem der höchsten Skigebiete der Schweiz gibt es auch den höchsten Winterwanderweg Europas auf gut 3'000 Meter Höhe. In Unterbäch stimmten 1957 erstmals Frauen in einer Schweizer Abstimmung ab, sie durften bei der eidgenössischen Urnenabstimmung über die Ausdehnung der Zivilschutzpflicht auf die Frauen teilnehmen. Die Gemeinde führte im selben Jahr das kommunale Wahlrecht für Frauen ein, 14 Jahre vor der bundesweiten Entscheidung dass Frauen wählen dürfen.

Im Dalatal liegt Leukerbad, den Anfang des Tals bildet die Dalaschlucht. Hier führt seit 2004 der Thermalquellen-Steg entlang, auf dessen Wegstrecke die Thermalwasser führenden Gesteinsschichten zu sehen sind. Um Salgesch wird seit Ende des Zweiten Weltkriegs verstärkt Wein angebaut. Der Illgraben (ein Wildbachgerinne) trägt grosse Mengen Sedimente mit sich und hat durch mehrere Murgänge dafür gesorgt, dass die Rhone hier nicht kanalisiert werden konnte.

Zwischen Leuk und Siders liegt der Pfynwald, einer der grössten Föhrenwälder der Alpen und teil des Naturparks Pfyn-Finges. Im Naturpark wachsen Orchideen und Kleine Kronwicken und es gibt sehr viele Insektenarten. Ein sieben Kilometer langer Abschnitt der Rhone fliesst durch den Park und breitet sich dort ungestört aus, mit Auwäldern, Inseln und Altarmen.

In der Nähe von Siders liegt das Val d’Anniviers, in dem etliche Skigebiete liegen und auch Walliser Trockenfleisch produziert wird. In der Gemeinde Anniviers liegt Zinal, im Sommer gibt es 300 Kilometer markierte Wanderwege, im Winter stehen Langlaufloipen und Abfahrtspisten bereit.
Das Stadtbild von Sitten ist mittelalterlich geprägt, in der Basilique de Valère steht eine der ältesten spielbaren Orgeln der Welt. Der Kern des heutigen Glockenturm der Kathedrale Unserer Lieben Frau entstand Ende des zwölften Jahrhunderts. Neben 140 Kilometer Skipisten hat Crans-Montana mit dem Golf-Club Crans-sur-Sierre einen der ältesten Golfplätze der Schweiz, auf dem Platz wird jährlich das Omega European Masters ausgetragen. 
Auf dem Gebiet von Conthey liegt der Lac de Derborence. Einer der gewaltigsten Bergstürze in der Schweiz im Frühjahr 1749 liess ihn entstehen, seit 1961 ist das Gebiet ein Naturschutzgebiet.

In Ardon VS befindet sich eine Schlucht der Lizerne, an der senkrechten Felswand ist eine alte Suone aufgehängt. Evolène ist der Hauptort des Val d’Hérens, durch das die Borgne fliesst. Die Haute Route führt durch Arolla, einen Ferienort am oberen Talabschluss des Val d’Hérens. An der Landstrasse nach Euseigne liegen im Val d’Hérémence die Erdpyramiden von Euseigne. Sie bestehen aus einem Material das Betonmoräne genannt wird und entstanden nach der Würmeiszeit. Ein kleiner Teil der Pyramiden wird von der Landstrasse in einem Tunnel durchbrochen.

Das 4-Vallées-Skigebiet liegt auf Gebiet der Gemeinden Nendaz, Verbier, Veysonnaz, Thyon und La Tzoumaz und ist mit 626 Pistenkilometer das grösste Skigebiet der Schweiz.

In Saint-Maurice VS liegt die Abtei Saint-Maurice, ein 515 gegründetes Kloster der Augustiner-Chorherren. Monthey ist für seinen Karneval bekannt, der 2012 zum 140. Mal veranstaltet wurde. Das Skigebiet Portes du Soleil liegt teilweise in Frankreich und teilweise in der Schweiz, es umfasst im Wallis die Skiorte Morgins sowie Torgon und im Val d’Illiez die drei Orte Champéry, Champoussin und Les Crosets. In Saint-Gingolph VS bildet der Bach "Morge" die Grenze zwischen Frankreich und der Schweiz, auf der französischen Seite liegt Saint-Gingolph (Haute-Savoie).

603 km Langlaufloipen und/oder 3'096 km Skipisten bieten insgesamt 60 Destinationen im Wallis. Mehr als 100-Pisten-km finden sich in Champéry, Champoussin und Les Crosets im Val d’Illiez, Morgins im Val de Morgins und Torgon, die im Wallis liegen und die zusammen mit den französischen Orten das Skigebiet Portes du Soleil bilden, das insgesamt 650 km Skipisten umfasst, Nendaz, Verbier und Veysonnaz (412 km), Zermatt (360 km), wobei im Mattertal insgesamt 427 km Skipisten vorzufinden sind (Grächen-St. Niklaus 42 km und Törbel 25 km), Thyon (178 km), Crans-Montana (140 km), Grimentz und Zinal (115 km), wobei im Eifischtal insgesamt 210 km Skipisten vorzufinden sind (Chandolin / Saint-Luc 60 km und Vercorin 35 km), Bettmeralp, Fiesch und Riederalp der Aletsch Arena (104 km) und Saas-Fee (100 km), wobei im Saastal insgesamt 202 km Skipisten vorzufinden sind (Saas-Almagell 12 km, Saas-Balen 3 km, Saas-Grund 35 km, Staldenried-Gspon 5 km und Visperterminen 20 km). Mit insgesamt 86-Loipen-km ist das Goms (Blitzingen, Geschinen, Gluringen, Grafschaft VS, Münster VS, Obergoms und Reckingen VS) ein Mekka des Langlaufes.

Im Wallis gibt es Thermalbäder in Leukerbad (grösstes Thermalbadezentrum der Alpen), Ovronnaz, Saillon-les-Bains, Brigerbad, Val-d’Illiez sowie das Soleheilbad in Breiten bei Mörel VS. Golfplätze gibt es in folgenden Orten: 18-Loch-Golfplätze in Crans-Montana, Leukerbad, Siders, Sitten und Verbier (zwei Kurse). 9-Loch-Golfplätze in Crans-Montana, Obergesteln, Zermatt / Täsch und Riederalp, welcher der höchstgelegene Golfplatz Europas ist.

Am Südhang des Rhonetals herrscht im Unterwallis (flächendeckend) und im Mittelwallis (teilweise) Rebbau vor, stellenweise auch in den Seitentälern bis ins Oberwallis. Das Wallis ist mit seiner über 5'236 ha Rebfläche das grösste Weinanbaugebiet der Schweiz. Es konnte nachgewiesen werden, dass im Kanton Wallis bereits zwischen 800 und 600 v. Chr. Reben kultiviert wurden. Neben der Leitsorte Fendant wird in neuerer Zeit wieder vermehrt auf alte, ortstypische Sorten wie Humagne (weiss und rot), Petite Arvine, Amigne, Resi oder Malvoisie zurückgegriffen. In Visperterminen befindet sich der höchste Weinberg nördlich des Alpenhauptkammes, auf einer Höhe von 650 bis Im Val d’Anniviers wird der Gletscherwein produziert, ein oxidativer Wein.

Im Wallis werden in grossem Stil Früchte angebaut, etwa 95 % der Schweizer Aprikosen und die Hälfte der Birnen kommen aus dem Kanton. Die Gemüsesorten mit den grössten Anbauflächen sind in absteigender Reihenfolge Lagerkarotten, Blumenkohl, Frühkarotten und Zwiebeln. Besonders der Spargelanbau hat in den letzten zehn Jahren stark an Bedeutung gewonnen, weisser und grüner Spargel zusammen haben heute die drittgrösste Anbaufläche unter den Gemüsesorten. In Mund wird seit dem Mittelalter Safran angebaut, man vermutet dass er durch Pilger oder Söldner in die Schweiz kam.

In der Viehzucht geniesst neben klassischer Milchwirtschaft die Schaf- und Ziegenhaltung einen bedeutenden Stellenwert. Die hochalpinen Rahmenbedingungen werden zunehmend als Gelegenheit wahrgenommen seltenen und bedrohten Arten eine Chance zum Überleben zu bieten, zum Beispiel Walliser Schwarzhalsziege und Kupferhalsziege sowie Schwarznasenschaf. Allerdings bestehen zwischen Viehzucht und Artenschutz auch Konflikte, etwa im Zusammenhang mit der Wiederansiedlung des Wolfes. Dieser wandert seit den 1980er Jahren von Frankreich und Italien in den Kanton Wallis ein, durch Bauern die um ihre Tiere fürchten und die Jagdlobby ist er jedoch weiterhin stark gefährdet.

Der Industriebetrieb in St. Niklaus der Scintilla AG der Robert Bosch GmbH ist weltweiter Branchenleader in der Herstellung von Stichsäge- und Säbelsägeblättern sowie Starlocks. In 60 Jahren der Stichsäge-Produktion des Werkes St. Niklaus VS konnte im Jahre 2007 das viermilliardste Sägeblatt hergestellt werden.

Im Wallis sind zudem die Chemie- und pharmazeutische Industrie wichtige Arbeitgeber, etwa die Lonza AG in Visp. Die Energiewirtschaft hat durch viele Speicherkraftwerke gute Voraussetzungen. Die Raffinerie Collombey ist eine von zwei Erdölraffinerien in der Schweiz und gehört dem libyschen Ölkonzern Tamoil, sie liegt in der Gemeinde Collombey-Muraz unweit der Ostspitze des Genfersees. Der Aluminiumproduzent Constellium hat Standorte in Chippis, Siders und Steg.

Im Wallis wurden während des Zweiten Weltkriegs 380'000 Tonnen Anthrazitkohle abgebaut. Grosse Schieferverkommen gab es in und um Sembrancher, der Abbau endete Mitte des 20. Jahrhunderts. Schon in den 1960er bis 1980er Jahren wurde im Wallis nach Uran gesucht, durch die niedrigen Weltmarktpreise waren die Minen jedoch nicht wettbewerbsfähig. Bei Martigny und Salvan-Les Marécottes werden seit 2008 erneut Erkundungen unternommen.

Seit dem Jahr 2016 sind das Walliser Lied «Wallis, unser Heimatland» und die dazugehörige Instrumentalversion des Marignan-Marsches nun auch offiziell die Walliser Kantonshymnen. Das Walliser Lied aus dem Jahre 1890 von Leo Luzian von Roten (Text) und Ferdinand Othon Wolf (Melodie) galt im Volksmund schon lange als Walliser Hymne. Der Schweizer Komponist Jean Daetwyler liess das bekannte Walliser Lied in den Marignan-Marsch einfliessen, den er 1939 zum 50. Jubiläum des Mittelwalliser Musikverbands komponierte.

Das Walliserdeutsch des Oberwallis hat, zusammen mit den im Piemont, im Aostatal und im Tessin gesprochenen Südwalserdialekten, die Deklinations- und Konjugationsvielfalt des Althochdeutschen in mancherlei Hinsicht bewahrt. Es wird heute von rund 80'000 Wallisern gesprochen.

Autoren, die u. a. auch in Walliserdeutsch schrieben, sind: Frieda Berchtold, Ludwig Imesch, Eduard Imhof, Georg Julen, Bernadette Lerjen-Sarbach, Markus Marti, Hannes Taugwalder, Hubert Theler und Otto Zumoberhaus.

In Walliserdeutsch singt beispielsweise die Popsängerin Sina. Ihre Single «Wänn nit jetzt wänn dä» («Wenn nicht jetzt wann dann») aus dem Jahr 2008 feierte auch über die Grenzen der Schweiz hinaus Erfolge.

Der Kanton Wallis hat eine eigenständige Küche entwickelt, welche sich von anderen Schweizer Regionalküchen unterscheidet. Typische regionale Produkte sind das runde Walliser Roggenbrot aus Roggenvollkornmehl mit maximal 10 % Weizenanteil, das magere, gesalzene und durch Lufttrockenreifung haltbar gemachte Rindfleisch, das Walliser Trockenfleisch und der Walliser Safran. Die Bezeichnung "Walliser Roggenbrot" ist im Register der Ursprungsbezeichnungen (GUB / AOP) eingetragen und somit eine geschützte Marke. Auch die Angaben "Walliser Trockenfleisch" und "Munder Safran" sind geschützt.

Der Walliser Teller (auch Walliser Platte genannt) besteht aus in dünnen Scheiben geschnittenem Walliser Trockenfleisch aus Rindfleisch, Walliser Trockenspeck und Walliser Rohschinken (walliserdeutsch "Hamma") aus Schweinefleisch, Walliser Trockenwurst (walliserdeutsch "Hüswurscht") aus Rind- und Schweinefleisch, wobei die Fleischwaren alle mittels Lufttrockenreifung haltbar gemacht werden, sowie Walliser Roggenbrot und Walliser Käse (Schnitt- und Hobelkäse). Auch der Walliser Rohschinken und der Walliser Trockenspeck sind als IGP geschützt.

Typische Gerichte sind das Walliser Raclette, das Gesottene (walliserdeutsch "Gsottus") und die Cholera. Der Walliser Raclettekäse zeichnet sich durch seine frische und würzige Art aus, wobei "Walliser Raclette AOP" eine geschützte Ursprungsbezeichnung ist. "Gsottus" besteht aus luftgetrocknetem und gekochtem Schweine- und Rindfleisch, Speck und Wurstwaren und wird zusammen mit Sauerkraut oder Weisskohl und Kartoffeln serviert. Die Cholera ist ein Gemüsekuchen mit Lauch, Kartoffeln, Käse und Äpfeln.

Als typische Weine gelten der Walliser Weisswein Fendant und der Walliser Rotwein Dôle. Der Name "Fendant" ist eine geschützte Ursprungsbezeichnung und darf einzig von Weinen getragen werden, die aus dem Kanton Wallis stammen. Auch der Dôle ist ein AOC-zertifizierter Wein. Als echte Raritäten sind sowohl die Walliser Rotweinsorten Durize und Eyholzer als auch die Walliser Weissweinsorten Gletscherwein, Heida, Himbertscha, Lafnetscha, Mennas, Planscher und Resi zu erwähnen.

Im Wallis gibt es einige Schnellzugstrecken, die Bahnhöfe von Visp und Brig sind wichtige Knotenpunkte. Der Bahnhof Brig liegt an den Strecken Genf–Lausanne–Mailand (Rhonetalstrecke) und Basel–Bern–Mailand, von hier aus fahren die Autozüge durch den Simplontunnel nach Iselle di Trasquera. Der Lötschberg-Basistunnel wurde 2007 in Betrieb genommen, dadurch wurde der Bahnhof Visp zum Umsteigebahnhof für die umliegenden Städte und Gemeinden. Durch den erhöhten Bahnverkehr und dazugehörige Infrastrukturprojekte hat die Bevölkerung von Visp seit der Eröffnung stark zugenommen.

Weitere Strecken sind Lausanne–Simplon, Bern–Lötschberg–Simplon, Martigny–Orsières–Le Châble und Saint-Maurice–Saint-Gingolph.

Im Wallis gibt es mehrere Schmalspurbahnen, die teilweise auch Zahnradbahnen sind. Die Matterhorn-Gotthard-Bahn besteht aus den ehemaligen Bahnen Brig–Visp–Zermatt und Furka–Oberalp. Die Furka-Oberalp-Bahn führt durch die Kantone Graubünden, Uri und Wallis über den Furkapass und den Oberalppass nach Brig, von wo die Brig–Visp–Zermatt-Bahn weiter nach Visp und zum Endhaltepunkt Zermatt fährt. Die Transports de Martigny et Régions verfügt über zwei voneinander getrennte Schienennetze, sie entstand durch die Fusion der Martigny-Châtelard-Bahn (MC) mit der Martigny-Orsières-Bahn (MO), die nicht die gleichen Spurweiten benutzen. Die MC betreibt den Mont-Blanc Express von Martigny über Salvan VS hinauf nach Le Châtelard VS, von wo die SNCF die Strecke weiter bis nach Chamonix-Mont-Blanc betreibt. Der Saint-Bernard Express wird von der MO betrieben und ist im Gegensatz zum Mont-Blanc Express eine normalspurige Eisenbahn von Martigny über Sembrancher nach Orsières. Die Aigle–Ollon–Monthey–Champéry-Bahn ist eine meterspurige Eisenbahn, die von Aigle VD über Ollon und Monthey nach Champéry führt. Sie ist eine der fünf Linien der Transports Publics du Chablais. Von Zermatt aus führt die Gornergratbahn hinauf zum Gornergrat, wo die Bergstation auf einer Höhe von liegt. Sie ist damit nach der Jungfraubahn die zweithöchste Bergbahn Europas.

Daneben gibt es 78 Postautolinien, die Überlandverkehr und die Stadtnetze von Brig-Glis/Naters, Monthey/Collombey-Muraz, Sitten und Martigny betreiben, und viele touristische
Bergbahnen.

Die Autobahn 9 führt durch die Kantone Waadt und Wallis und ist im Wallis teilweise nicht doppelspurig und richtungsgetrennt. Das Teilstück im Oberwallis zwischen Susten und Gampel soll voraussichtlich 2017 fertiggestellt sein. Die ganze Verbindung von Siders Ost bis Gamsen kann erst in den späten 2020er Jahren geschlossen werden; grosse Probleme stellen dabei unter anderem das Teilstück Siders Ost bis Susten, das durch den geschützten Naturpark Pfynwald führt, und der Tunnel Visp, der geologisch sehr schwer fertigzustellen ist.

Die bekanntesten und wichtigsten Passstrassen sind von Italien aus der Simplonpass und der Grosse St. Bernhard, von Frankreich aus der Pas de Morgins und der Col de la Forclaz. Zu anderen Kantonen sind es der Nufenenpass in das Tessin, der Furkapass nach Uri und im Kanton Bern der Grimselpass und der Sanetschpass. Der Sanetschpass kann jedoch nur von der Walliser Seite her befahren werden, vom nahen Gsteig bei Gstaad im Kanton Bern aus wäre der Bau wegen des steilen Geländes zu aufwändig gewesen.

Ab dem Alter von vier Jahren muss seit 2008 jedes Kind zwei Jahre lang den Kindergarten besuchen. Die eigentliche Schulzeit besteht aus sechs Jahren Primarschule und drei Jahren Orientierungsschule (auch Sekundarstufe I), an deren Ende bei Erfüllung der Anforderungen des Programms des letzten Pflichtschuljahres ein Abschlussdiplom erteilt wird. Wenn die neun Jahre obligatorische Schule besucht wurden, aber nicht die Anforderungen des dritten Jahres der Sekundarstufe I erfüllt wurden, wird nur eine Bestätigung des Schulabschlusses erteilt.

Die Sekundarstufe II kann im Wallis als berufliche Grundbildung mit anschliessenden Berufsattest, Fähigkeitszeugnis oder Berufsmaturität absolviert werden, daneben auch als Fachmittelschule mit abschliessender Fachmaturität oder auf dem Gymnasium mit abschliessender Gymnasialer
Maturität. Die Tertiärstufe umfasst Ausbildungen im Bereich der höheren Berufsbildung, höheren Fachschulen und Hochschulen.

Die Walliser Fahne zeigt 13 Sterne in drei vertikalen Reihen (Verteilung 4-5-4) auf rot-weissem Grund. Die rote Hälfte mit den weissen Sternen ist rechts, die fünf mittleren Sterne sind zweifarbig. Wird die Fahne an einem Fahnenmast montiert, so steht die weisse Hälfte mit den roten Sternen an der Mastseite, bildet also das Liek.

Rot und Weiss (früher Rot und Silber) sind die Farben des Bischofs von Sitten. Die 13 Sterne repräsentieren die Zehnden, was eine alte Bezeichnung für die Bezirke des Wallis ist. Die Fahne und das Wappen, damals noch ohne Sterne, gibt es wohl schon seit dem Jahr 999, als Rudolf III. das Wallis dem Bistum Sitten übergab. Urkundlich belegt ist die Fahne seit 1220. Quellen von Ende des 15. Jahrhunderts zeigen Wappen mit 6, 7, 9, 11 und 16 Sternen. Ab 1802 waren es zwölf Sterne, mit dem neuen Bezirk Conthey kam am 12. Mai 1815 der 13. und bisher letzte Stern hinzu.

Nach 57 v. Chr. wurde das von den Römern Vallis Poenina genannte Gebiet des heutigen Wallis erobert und zu einer römischen Provinz. Um 888 wurde es Teil des Königreichs Burgund. König Rudolf III. von Burgund übergab 999 die Grafschaft Wallis mit allen Rechten und Privilegien an den Bischof von Sitten. Ab der zweiten Hälfte des 15. Jahrhunderts bis 1798 war das Wallis in sieben Zehnden eingeteilt und wurde daher auch "Republik der sieben Zehnden" genannt. Diese Republik setzte im 16. Jahrhundert ihre Eigenständigkeit von den Bischöfen von Sitten durch. 1802 erklärte Napoleon I. das Gebiet zur unabhängigen Republik Wallis und 1810 zum französischen Département du Simplon. 1815 trat das Wallis als 22. Kanton der Schweizerischen Eidgenossenschaft bei. Die noch heute gültige Verfassung wurde 1907 verabschiedet, seitdem wurden jedoch einige Passagen durch Volksabstimmungen geändert. Die Frauen des Kantons sind seit 1970 stimmberechtigt. Im Jahr 2000 gab es starke Hochwasser an der Rhone, durch die 3. Rhonekorrektion soll dies in Zukunft vermieden werden. Das Projekt soll den Hochwasserschutz gewährleisten, der Rhone Teile ihres ursprünglichen Flussbetts zurückgeben und durch Freizeit- und Erholungsraum gesellschaftlichen Mehrwert schaffen. Die Baumassnahmen finden in drei Phasen statt und werden voraussichtlich Mitte der 2030er Jahre abgeschlossen sein.




</doc>
<doc id="5729" url="https://de.wikipedia.org/wiki?curid=5729" title="Xenon">
Xenon

Xenon ist ein chemisches Element mit dem Elementsymbol Xe und der Ordnungszahl 54. Im Periodensystem steht es in der 8. Hauptgruppe, bzw. der 18. IUPAC-Gruppe und zählt daher zu den Edelgasen. Wie die anderen Edelgase ist es ein farbloses, äußerst reaktionsträges, einatomiges Gas. In vielen Eigenschaften wie Schmelz- und Siedepunkt oder Dichte steht es zwischen dem leichteren Krypton und dem schwereren Radon.

Xenon ist das seltenste nichtradioaktive Element auf der Erde und kommt in geringen Mengen in der Atmosphäre vor. Trotz seiner Seltenheit wird es vielfach eingesetzt, so als Füllgas von hochwertigen Isolierglaseinheiten, sowie Xenon-Gasentladungslampen, die unter anderem in Autoscheinwerfern (Xenonlicht) eingesetzt werden, und als Inhalationsanästhetikum.

Das Edelgas wurde 1898 von William Ramsay und Morris William Travers durch fraktionierte Destillation von flüssiger Luft entdeckt. Xenon ist das Edelgas mit den meisten bekannten chemischen Verbindungen. Die stabilste ist dabei das Xenon(II)-fluorid, das als starkes Oxidations- und Fluorierungsmittel eingesetzt wird.

Nachdem John William Strutt, 3. Baron Rayleigh, und William Ramsay 1894 das erste Edelgas Argon entdeckt und Ramsay 1895 das bislang nur aus dem Sonnenspektrum bekannte Helium aus Uranerzen isoliert hatten, erkannte dieser aus den Gesetzen des Periodensystems, dass es noch weitere derartige Elemente geben müsste. Er untersuchte daher ab 1896 zunächst verschiedene Minerale und Meteoriten und die von ihnen beim Erhitzen oder Auflösen abgegebenen Gase. Ramsay und sein Mitarbeiter Morris William Travers waren dabei jedoch erfolglos. Es wurden Helium und seltener Argon gefunden. Auch die Untersuchung heißer Gase aus Cauterets in Frankreich und aus Island brachten keine Ergebnisse.

Schließlich begannen sie, 15 Liter Rohargon zu untersuchen und durch Verflüssigung und fraktionierte Destillation zu trennen. Als sie den Rückstand, der bei fast völligem Verdampfen des Rohargons übrigblieb, untersuchten, entdeckten sie das neue Element Krypton. Nachdem sie Neon entdeckt hatten, begannen Ramsay und Travers im September 1898 Krypton durch fraktionierte Destillation weiter zu untersuchen und entdeckten dabei ein weiteres Element mit einem höheren Siedepunkt als Krypton. Sie nannten es nach dem altgriechischen "" „fremd“ "Xenon".

1939 entdeckte Albert R. Behnke die anästhetische Wirkung des Gases. Er untersuchte die Wirkung verschiedener Gase und Gasmischungen auf Taucher und vermutete aus den Ergebnissen, dass Xenon auch bei Normaldruck eine narkotische Wirkung haben müsse. Er konnte dies jedoch aus Mangel an Gas nicht überprüfen. Erstmals bestätigt wurde diese Wirkung 1946 von J. H. Lawrence an Mäusen, die erste Operation unter Xenon-Narkose gelang 1951 Stuart C. Cullen.

Neil Bartlett entdeckte mit Xenonhexafluoroplatinat 1962 erstmals eine Xenonverbindung und damit die erste Edelgasverbindung überhaupt. Nur wenige Monate nach dieser Entdeckung konnten nahezu gleichzeitig im August 1962 Xenon(II)-fluorid von Rudolf Hoppe und Xenon(IV)-fluorid von einer Gruppe um die amerikanischen Chemiker C. L. Chernick und H. H. Claassen synthetisiert werden.

Während Xenon im Universum nicht selten vorkommt und in seiner Häufigkeit mit der von Barium, Rubidium und Nickel vergleichbar ist, zählt es auf der Erde zu den seltensten Elementen. Es ist das seltenste stabile Element, lediglich radioaktive Elemente, die überwiegend als kurzlebige Zwischenprodukte in Zerfallsreihen auftreten, sind seltener. Dass der Gehalt an Xenon gering ist, wird möglicherweise dadurch verursacht, dass sich Xenon sehr viel schlechter in Magnesiumsilikat-Gesteinen des Erdmantels löst als die leichteren Edelgase.

Der größte Teil des Xenons ist vermutlich in der Atmosphäre vorhanden, der Anteil beträgt etwa 0,09 ppm. Aber auch die Ozeane, manche Gesteine wie Granit und Erdgas-Quellen enthalten geringe Mengen Xenon. Entstanden ist dies – wie durch die vom atmosphärischen Xenon abweichende Isotopenzusammensetzung nachweisbar – unter anderem durch Spontanzerfall von Uran und Thorium.

Xenon wird als Indikator für Atomwaffentests von der CTBTO weltweit kontinuierlich gemessen – über die Anlagerung an Silberzeolithe in Xenonfallen.

Meteoriten enthalten Xenon, das entweder seit Entstehung des Sonnensystems in Gesteinen eingeschlossen ist oder durch verschiedene Sekundärprozesse entstanden ist. Zu diesen zählen der Zerfall des radioaktiven Iodisotops I, Spallationsreaktionen und die Kernspaltung schwerer Isotope wie Pu. Auch auf der Erde lassen sich die Xenon-Produkte dieser Reaktionen nachweisen, was Rückschlüsse auf die Entstehung der Erde ermöglicht. Auf dem Mond wurde Xenon gefunden, das durch den Sonnenwind dorthin transportiert wurde (im Mondstaub) sowie im Mondgestein solches, das durch Spallationen oder Neutroneneinfang aus dem Bariumisotop Ba entstanden ist.

Xenon konnte auch in einem Weißen Zwerg nachgewiesen werden. Dabei wurde im Vergleich zur Sonne die 3800-fache Konzentration gemessen; die Ursache für diesen hohen Xenon-Gehalt ist noch unbekannt.

Die Gewinnung von Xenon erfolgt ausschließlich durch das Linde-Verfahren aus Luft. Bei der Stickstoff-Sauerstoff-Trennung reichert es sich auf Grund der hohen Dichte zusammen mit Krypton im flüssigen Sauerstoff an, der sich im Sumpf der Kolonne befindet. Dieses Gemisch wird in eine Kolonne überführt, in der es auf etwa 0,3 % Krypton und Xenon angereichert wird. Dazu enthält das flüssige Krypton-Xenon-Konzentrat neben Sauerstoff noch größere Mengen Kohlenwasserstoffe wie Methan, fluorierte Verbindungen wie Schwefelhexafluorid oder Tetrafluormethan sowie Spuren an Kohlenstoffdioxid und Distickstoffmonoxid. Methan und Distickstoffmonoxid können über Verbrennung an Platin- oder Palladiumkatalysatoren bei 500 °C zu Kohlenstoffdioxid, Wasser und Stickstoff umgesetzt werden, die durch Adsorption an Molekularsieben entfernt werden können. Fluorverbindungen können dagegen nicht auf diese Weise aus dem Gemisch entfernt werden. Um diese zu zerlegen und aus dem Gemisch zu entfernen, kann das Gas mit Mikrowellen bestrahlt werden, wobei die Element-Fluor-Bindungen aufbrechen und die entstehenden Fluoratome in Natronkalk aufgefangen werden können oder über einen Titandioxid-Zirconiumdioxid-Katalysator bei 750 °C geleitet werden. Dabei reagieren die Fluorverbindungen zu Kohlenstoffdioxid und Fluorwasserstoff und anderen abtrennbaren Verbindungen.

Anschließend werden Krypton und Xenon in einer weiteren Kolonne, die unten beheizt und oben gekühlt wird, getrennt. Während das Krypton und Sauerstoffreste am oberen Ende der Kolonne entweichen, sammelt sich Xenon am Boden und kann abgeschöpft werden. Auf Grund der Seltenheit bei gleichzeitig hoher Nachfrage ist Xenon das teuerste Edelgas. Die Gesamtproduktionsmenge 1998 wird auf 5000 m bis 7000 m geschätzt.

Xenon ist bei Normalbedingungen ein einatomiges, farbloses und geruchloses Gas, das bei 165,1 K (−108 °C) kondensiert und bei 161,7 K (−111,45 °C) erstarrt. Wie die anderen Edelgase außer dem Helium kristallisiert Xenon in einer kubisch dichtesten Kugelpackung mit dem Gitterparameter "a" = 620 pm.

Wie alle Edelgase besitzt Xenon nur abgeschlossene Schalen (Edelgaskonfiguration). Dadurch lässt sich erklären, dass das Gas stets einatomig vorliegt und die Reaktivität gering ist. Jedoch ist die Ionisierungsenergie der äußersten Elektronen so niedrig, dass sie sich im Gegensatz zu den Valenzelektronen der leichteren Edelgase auch chemisch abspalten lassen und Xenonverbindungen möglich sind.

Mit einer Dichte von 5,8982 kg/m bei 0 °C und 1013 hPa ist Xenon deutlich schwerer als Luft. Im Phasendiagramm liegt der Tripelpunkt bei 161,37 K und 0,8165 bar, der kritische Punkt bei 16,6 °C, 5,84 MPa und einer kritischen Dichte von 1,1 g/cm.

Die Wärmeleitfähigkeit ist sehr niedrig und liegt, je nach Temperatur, bei etwa 0,0055 W/mK. Unter hohem Druck von 33 GPa und bei einer Temperatur von 32 K verhält sich Xenon wie ein Metall, es ist elektrisch leitfähig.

Wie alle Edelgase ist Xenon reaktionsträge und reagiert kaum mit anderen Elementen. Jedoch ist Xenon zusammen mit Radon das reaktivste Edelgas, es ist eine größere Zahl Xenonverbindungen bekannt. Deren Anzahl übertrifft sogar die des schwereren Radons, da dieses zwar eine geringere Ionisierungsenergie besitzt, jedoch die starke Radioaktivität und kurze Halbwertszeit der Radonisotope bei der Bildung von Verbindungen stört.

Xenon reagiert direkt nur mit Fluor. Je nach Verhältnis von Xenon und Fluor entstehen dabei unter exothermer Reaktion bei erhöhten Temperaturen Xenon(II)-fluorid, Xenon(IV)-fluorid oder Xenon(VI)-fluorid. Verbindungen mit einigen anderen Elementen wie Sauerstoff oder Stickstoff sind ebenfalls bekannt. Sie sind aber instabil und können nur durch Reaktionen von Xenonfluoriden oder wie Xenon(II)-chlorid bei tiefen Temperaturen durch elektrische Entladungen dargestellt werden.

Xenon bildet Clathrate, bei denen das Atom nur physikalisch gebunden und in einen Hohlraum des umgebenden Kristalls eingeschlossen ist. Ein Beispiel hierfür ist das Xenon-Hydrat, bei dem das Gas in Eis eingeschlossen ist. Es ist zwischen 195 und 233 K stabil. In der Nähe der Raumtemperatur ist Xenon bis zu einem gewissen Maß in Wasser löslich. Als inertes Teilchen hat Xenon keine Wechselwirkung mit dem Wasser, allerdings stellt sich der sogenannte hydrophobe Effekt ein und so wird die Beweglichkeit der dem Xenon benachbarten Wassermoleküle bei 25 °C um ca. 30 % erniedrigt. Befinden sich in der Xenon-Wasser-Lösung zusätzlich Salze, so lagern sich große Anionen, wie z. B. Bromid (Br) und Iodid (I) an das Xenon an und bilden einen Xenon-Anion-Komplex, der beim "größeren" Anion stärker ist. Auch in Fullerenen können Xenonatome eingeschlossen sein, diese beeinflussen auch die Reaktivität des Fullerens, etwa bei der Reaktion mit 9,10-Dimethylanthracen.

Es sind insgesamt 37 Isotope sowie zwölf weitere Kernisomere des Xenons bekannt. Von diesen sind sieben, die Isotope Xe, Xe, Xe, Xe, Xe, Xe und Xe, stabil. Die beiden instabilen Isotope Xe und Xe haben so lange Halbwertszeiten, dass sie zusammen einen deutlichen Anteil des natürlichen Xenons ausmachen, ohne dass dieses deshalb nennenswert radioaktiv wäre. Alle anderen Isotope und Isomere haben dagegen nur kurze Halbwertszeiten zwischen 0,6  µs bei Xe und 36,4 Tagen bei Xe. Xenon ist damit nach Zinn das Element mit den meisten stabilen Isotopen. Im natürlichen Isotopengemisch besitzen Xe mit 26,9 %, Xe mit 26,4 % und Xe mit 21,2 % den größten Anteil. Es folgen Xe mit 10,4 % und Xe mit 8,9 %, die übrigen besitzen nur geringe Anteile.

Xenonisotope entstehen bei der Kernspaltung in Kernkraftwerken. Besonders wichtig ist hierbei das kurzlebige Xe, das in größeren Mengen direkt als Spaltprodukt oder aus dem bei der Spaltung entstehenden Te über I gebildet wird. Xe besitzt einen sehr großen Einfangquerschnitt für thermische Neutronen von 2,9 · 10 Barn, wobei sich das extrem langlebige Xe bildet. Dieser Neutronen-Einfangprozess vermindert die Leistung des Reaktors, da die Neutronen nun nicht mehr für Kernspaltungen zur Verfügung stehen. Während des laufenden Betriebes eines Kernkraftwerkes bildet sich ein Gleichgewicht von Bildung und Zerfall von Xe, wird der Reaktor dagegen abgeschaltet, bildet sich aus den schon vorhandenen Spaltprodukten weiterhin Xe, während der Abbau durch die fehlenden Neutronen verlangsamt abläuft. Man spricht hierbei von einer Xenonvergiftung, diese verhindert auch das direkte Wiederanfahren eines abgeschalteten Kernreaktors. Dies spielte eine Rolle bei der Katastrophe von Tschernobyl.

Xe wird in der Nuklearmedizin eingesetzt und dient dort unter anderem zur Untersuchung der Durchblutung von Gehirn, Muskeln, Haut und anderen Organen. Xe wird als Sonde in der Kernspinresonanzspektroskopie zur Untersuchung von Oberflächeneigenschaften verschiedener Materialien und von Biomolekülen eingesetzt.

Xenon wird vor allem als Füllgas von Lampen eingesetzt. Dazu zählt die Xenon-Gasentladungslampe, bei der in Xenon ein Lichtbogen gezündet wird, welcher eine Temperatur von etwa 6000 K erreicht. Dabei gibt das ionisierte Gas eine Strahlung ab, die dem Tageslicht vergleichbar ist. Diese Lampen werden beispielsweise in Filmprojektoren, Blitzlichtern und für die Befeuerung von Start- und Landebahnen auf Flughäfen eingesetzt. Auch in Autoscheinwerfern werden Xenon-Gasentladungslampen verwendet; dieses sogenannte Xenonlicht ist etwa 2,5-mal so lichtstark wie eine Halogenlampe gleicher elektrischer Leistung. Glühlampen können mit Xenon oder Xenon-Krypton-Mischungen gefüllt werden, wodurch eine höhere Temperatur des Glühfadens und damit eine bessere Lichtausbeute erzielt wird.

Xenon ist ein Lasermedium in Excimerlasern. Dabei bildet sich ein instabiles Xe-Dimer, das unter Aussendung von Strahlung bei einer typischen Wellenlänge von 172 nm im ultravioletten Spektralbereich zerfällt. Auch Laser, bei denen Xenon mit verschiedenen Halogenen gemischt wird und sich Xe-Halogen-Dimere bilden, sind bekannt. Sie besitzen andere ausgestrahlte Wellenlängen, so strahlt der Xe-F-Laser Licht einer Wellenlänge von 354 nm ab.
Xenon wird in Ionenantrieben oft als Antriebsmittel (Stützmasse) verwendet. Die nur geringe Schubkräfte erzeugenden Ionentriebwerke sind durch ihren hohen spezifischen Impuls wesentlich effizienter als konventionelle chemische Triebwerke und werden deshalb in manchen Satelliten für Korrekturtriebwerke oder als Hauptantrieb einiger Raumsonden verwendet, die so Ziele erreichen können, die für sie sonst nicht erreichbar wären. Xenon wird verwendet, da es als Edelgas leichter handhabbar und umweltfreundlicher ist als das ebenfalls mögliche Caesium oder Quecksilber.

Xenon wird – bis zu einer Konzentration von 35 %, um nicht narkotisierend zu wirken – versuchsweise als Kontrastmittel in der Röntgendiagnostik verwendet, eventuell ergänzt durch Krypton, um die Absorption zu erhöhen. Durch Inhalation von hyperpolarisiertem Xe kann eine gute Darstellbarkeit der Lunge durch MRT (NMR) erreicht werden.

Die geringe Wärmeleitfähigkeit von Xenon im Vergleich zu Luft, Argon und Krypton eröffnet spezielle Anwendungsmöglichkeiten im Bereich von hochisolierendem Mehrscheiben- Isolierglas. Auf Grund seines hohen Preises wird Xenon als Füllgas bei Isolierglaseinheiten jedoch nur in Sonderfällen verwendet, z.B. wenn es auf besonders hohe Wärmedämmung selbst bei sehr dünnen Isolierglaseinheiten mit Scheibenzwischenräumen unter 8 mm besonders ankommt (Isolierglas in denkmalgeschütztem Rahmen, kleine Fenster unter hoher Klimalast).

Wie die anderen Edelgase geht Xenon auf Grund der Reaktionsträgheit keine kovalenten Bindungen mit Biomolekülen ein und wird auch nicht verstoffwechselt. Über induzierte Dipole können Atome des Gases jedoch mit biologischen Systemen wechselwirken. So wirkt es beispielsweise durch einen noch nicht vollständig geklärten Mechanismus unter Beteiligung von Glutamat-Rezeptoren narkotisierend.

Neuere Forschungen legen nahe, dass unter dem Einfluss von Xenon auch neuroprotektive und analgetische Wirkungen beobachtet werden können.

Xenon wirkt narkotisierend und kann als Inhalationsanästhetikum verwendet werden. Es ist seit 2005 für den Einsatz bei ASA 1 und 2-Patienten in Deutschland, seit 2007 in elf weiteren Ländern zugelassen. Aufgrund der hohen Kosten (200-300 € anstelle 100-80 € bei einer zweistündigen Operation) konnte es sich bis zum Jahr 2015 noch nicht im täglichen Narkosebetrieb durchsetzen.

Aufgrund seines sehr niedrigen Blut-Gas-Verteilungskoeffizienten flutet es sehr schnell an und ab. Beim Abfluten kann wie beim Distickstoffmonoxid eine Diffusionshypoxie entstehen, es muss also mit reinem Sauerstoff ausgewaschen werden. Gegenüber dem häufig verwendeten Distickstoffmonoxid besitzt es einige Vorteile, so ist es ungefährlich im Umgang und kein Treibhausgas. Auch die Hämodynamik ist bei Xenon stabiler als bei anderen volatilen Anästhetika, d. h. es kommt nicht zum Blutdruckabfall, die Herzfrequenz steigt eher etwas an. Nachteilig ist, dass mit Xenon, weil es relativ hohe Konzentration braucht, um narkotisch zu wirken (MAC-Wert im Bereich von 60 bis 70 %), nur noch höchstens 30 oder 40 % Sauerstoff im Atemgasgemisch gegeben werden kann. Der größte Nachteil des Xenons ist sein hoher Preis.

Im Umfeld der Olympischen Winterspiele 2014 in Sotschi erregte eine Recherche des WDR über den Missbrauch von Xenon als Dopingmittel die öffentliche Aufmerksamkeit. Demnach sollen russische Athleten seit den Sommerspielen 2004 in Athen versuchen, ihre Leistungsfähigkeit zu steigern, indem sie während des Trainings die Hälfte des Luftsauerstoffs durch Xenongas ersetzen. Eine entsprechende Studie der Forschungs- und Entwicklungseinrichtung namens Atom-Med-Zentrum sei vom russischen Staat in Auftrag gegeben worden. Laut dieser Institution regt Xenongas im Körper die Produktion von EPO an. In Tierversuchen sei die EPO-Produktion innerhalb eines Tages auf 160 Prozent angestiegen. Ähnliche Effekte vermutet man beim Menschen. Im Mai 2014 setzte die WADA deshalb Xenon, ebenso wie Argon, auf die Dopingliste. Diese Dopingmethode hinterlässt allerdings keine derzeit im Blut nachweisbare Spuren.

Man kennt eine größere Zahl von Verbindungen des Xenons in den Oxidationsstufen +2 bis +8. Am stabilsten sind Xenon-Fluor-Verbindungen, es sind aber auch Verbindungen mit Sauerstoff, Stickstoff, Kohlenstoff und manchen Metallen wie Gold bekannt.

Drei Verbindungen des Xenons mit Fluor sind bekannt: Xenon(II)-fluorid, Xenon(IV)-fluorid und Xenon(VI)-fluorid. Die stabilste hiervon und gleichzeitig die stabilste Xenonverbindung überhaupt, ist das linear aufgebaute Xenon(II)-fluorid. Es wird als einzige Xenonverbindung in geringen Mengen auch technisch genutzt. In Laborsynthesen dient es als starkes Oxidations- und Fluorierungsmittel, etwa zur direkten Fluorierung aromatischer Verbindungen.

Während Xenon(II)-fluorid sich ohne Zersetzung in Wasser und Säuren löst und nur langsam hydrolysiert, hydrolysieren das quadratisch-planar aufgebaute Xenon(IV)-fluorid und das oktaedrische Xenon(VI)-fluorid schnell. Sie sind sehr reaktiv, so reagiert Xenon(VI)-fluorid mit Siliciumdioxid und kann nicht in Glasgefäßen aufbewahrt werden.

Mit Sauerstoff erreicht Xenon die höchstmögliche Oxidationsstufe +8 im Xenon(VIII)-oxid und dem Oxifluorid Xenondifluoridtrioxid XeOF sowie in Perxenaten der Form XeO. Weiterhin sind Xenon(VI)-oxid und die Oxifluoride XeOF und XeOF in der Oxidationsstufe +6 sowie Xenon(IV)-oxid und das Oxifluorid XeOF mit vierwertigem Xenon bekannt. Alle Xenonoxide und -oxifluoride sind instabil und viele explosiv.

Als weitere Xenon-Halogenverbindung ist Xenon(II)-chlorid bekannt; sie ist aber sehr instabil und nur bei tiefen Temperaturen spektroskopisch nachweisbar. Ähnlich konnten auch gemischte Wasserstoff-Halogen-Xenon-Verbindungen und die Wasserstoff-Sauerstoff-Xenonverbindung HXeOXeH durch Photolyse in der Edelgasmatrix hergestellt und spektroskopisch nachgewiesen werden.

Organische Xenonverbindungen sind mit verschiedenen Liganden bekannt, etwa mit fluorierten Aromaten oder Alkinen. Ein Beispiel für eine Stickstoff-Fluor-Verbindung ist FXeN(SOF).

Xenon ist unter supersauren Bedingungen in der Lage, mit Metallen wie Gold oder Quecksilber Komplexe zu bilden. Das Gold kommt dabei vorwiegend in der Oxidationsstufe +2 vor, auch Gold(I)- und Gold(III)-Komplexe sind bekannt.

Einen Überblick über Xenonverbindungen gibt die .



</doc>
<doc id="5730" url="https://de.wikipedia.org/wiki?curid=5730" title="Extensible Markup Language">
Extensible Markup Language

Die Erweiterbare Auszeichnungssprache (), abgekürzt XML, ist eine Auszeichnungssprache zur Darstellung hierarchisch strukturierter Daten im Format einer Textdatei, die sowohl von Menschen als auch von Maschinen lesbar ist.

XML wird auch für den plattform- und implementationsunabhängigen Austausch von Daten zwischen Computersystemen eingesetzt, insbesondere über das Internet, und wurde vom World Wide Web Consortium (W3C) am 10. Februar 1998 veröffentlicht. Die aktuelle Fassung ist die fünfte Ausgabe vom 26. November 2008. XML ist eine Metasprache, auf deren Basis durch strukturelle und inhaltliche Einschränkungen anwendungsspezifische Sprachen definiert werden. Diese Einschränkungen werden entweder durch eine Document Type Description (DTD) oder durch ein XML Schema ausgedrückt. Beispiele für XML-Sprachen sind: RSS, MathML, GraphML, XHTML, XAML, Scalable Vector Graphics (SVG), GPX, aber auch das XML-Schema selbst.

Ein XML-Dokument besteht aus Textzeichen in der UTF-8-Kodierung. XML kann in allen Texteditoren, die UTF-8 unterstützen, angezeigt und bearbeitet werden.

Wenn das XML-Dokument Binärdaten enthalten soll, müssen diese Daten als Text umkodiert werden. Dazu kann z. B. die Base64-Kodierung verwendet werden.

Die wichtigste Struktureinheit eines XML-Dokumentes ist das Element. Elemente können Text wie auch weitere Elemente als Inhalt enthalten. Elemente bilden die "Knoten" des Strukturbaumes eines XML-Dokumentes. Der Name eines XML-Elements kann in XML-Dokumenten ohne Document Type Description (DTD) frei gewählt werden. In XML-Dokumenten mit DTD muss der Name eines Elementes in der DTD deklariert sein und das Element muss sich in einer zugelassenen Position innerhalb des Strukturbaumes gemäß DTD befinden. In der DTD wird u. a. der mögliche Inhalt eines jeden Elementes definiert. Elemente sind die Träger der Information in einem XML-Dokument.

Ein XML-Dokument heißt „wohlgeformt“ (oder ), wenn es alle XML-Regeln einhält. Beispielhaft seien hier folgende genannt:


Soll XML für den Datenaustausch verwendet werden, ist es von Vorteil, wenn das Format mittels einer Grammatik (z. B. einer Dokumenttypdefinition oder eines XML-Schemas) definiert ist. Der Standard definiert ein XML-Dokument als gültig (oder englisch "valid"), wenn es wohlgeformt ist, den Verweis auf eine Grammatik enthält und das durch die Grammatik beschriebene Format einhält.

Programme oder Programmteile, die XML-Daten auslesen, interpretieren und ggf. auf Gültigkeit prüfen, nennt man "XML-Parser". Prüft der Parser die Gültigkeit, so ist er ein "validierender" Parser.

"Beispiel einer XML-Datei"

<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<verzeichnis>
</verzeichnis>
XML-Dokumente besitzen einen physischen und einen logischen Aufbau.


Der logische Aufbau entspricht einer Baumstruktur und ist damit hierarchisch organisiert.
Als Baumknoten gibt es:


Ein XML-Dokument muss genau ein Element auf der obersten Ebene enthalten. Unterhalb dieses Dokumentelements können weitere Elemente und Text verschachtelt werden.

Eine Dokumenttypdefinition (DTD) beschreibt die Struktur und Grammatik von Dokumenten. Sie ist Systembestandteil von XML und per Standard aktiviert.

Werden Dokumente mit Bezug zu einer externen Dokumenttypdefinition oder mit einer integrierten Dokumenttypdefinition erstellt, so prüft der Parser das Dokument bereits beim Öffnen (Lesen). Ein Dokument auf Basis einer Dokumenttypdefinition ist stets ein valides Dokument. Die Übereinstimmung des Dokumentinhaltes mit den Regeln der Dokumenttypdefinition steht im Vordergrund. Die technische Lesbarkeit, also auch das Lesen von nicht validen Dokumenten ist nachrangig. Das ist für Volltextdokumente (erzählende Dokumente, engl. "narrative documents") vorgesehen und der Haupteinsatzzweck.

Dokumente ohne DTD sind eher für den beliebigen Datenaustausch geeignet. Der Parser prüft diese Dokumente nur nach den Regeln der Wohlgeformtheit. Die technische Lesbarkeit steht hier an erster Stelle. Das Prüfen und Auslesen der eigentlichen Informationen wird mit nachgelagerten Prozessen realisiert.

Praktisch alle Webbrowser wie Apple Safari, Google Chrome, Microsoft Internet Explorer, Mozilla Firefox und Opera können XML-Dokumente mit Hilfe des eingebauten XML-Parsers direkt visualisieren.

XML-Dokumente lassen sich anhand ihres beabsichtigten Gebrauchs und ihres Strukturierungsgrads in dokumentzentrierte und datenzentrierte Dokumente unterteilen. Die Grenze zwischen diesen Dokumentenarten ist jedoch fließend. Mischformen können als "semistrukturiert" bezeichnet werden.


Es ist typisch für datenzentrierte XML-Dokumente, dass Elemente entweder Elementinhalt oder Textinhalt haben. Der sogenannte gemischte Inhalt (mixed content), bei dem Elemente sowohl Text als auch Kindelemente enthalten, ist für die anderen XML-Dokumente typisch.

Grundsätzlich sind drei Aspekte beim Zugriff auf ein XML-Dokument von Bedeutung:


Das Einlesen von XML-Dokumenten erfolgt auf unterster Ebene über eine spezielle Programmkomponente, einen XML-Prozessor, auch XML-Parser genannt. Er stellt eine Programmierschnittstelle (API) zur Verfügung, über die die Anwendung auf das XML-Dokument zugreift.

Die XML-Prozessoren unterstützen dabei drei grundlegende Verarbeitungsmodelle.

Weitere Verarbeitungsmodelle:

Oftmals greift der Anwendungscode nicht direkt auf die Parser-API zu. Stattdessen wird XML weiter gekapselt, so dass der Anwendungscode mit nativen Objekten / Datenstrukturen arbeitet, welche sich auf XML abstützen. Beispiele für solche Zugriffsschichten sind JAXB in Java, der Data Binding Wizard in Delphi oder das XML Schema Definition Toolkit in .Net. Die Umwandlung von Objekten in XML ist üblicherweise bidirektional möglich. Diese Umwandlung wird als Serialisierung oder Marshalling bezeichnet.

XML-Parser-APIs sind für verschiedene Programmiersprachen vorhanden, z. B. Java, C, C++, C#, Python, Perl und PHP. Parser-API-Beispiele:


Zur Erstellung von XML-Dokumenten gibt es spezielle Programme, sogenannte XML-Editoren.
Zur Speicherung und Verwaltung von XML-Dokumenten gibt es ebenfalls spezielle Programme, sogenannte XML-Datenbanken.

Ein XML-Dokument kann mittels geeigneter Transformationssprachen wie XSLT oder DSSSL in ein anderes Dokument transformiert werden. Oftmals dient die Transformation zur Überführung eines Dokuments aus einer XML-Sprache in eine andere XML-Sprache, beispielsweise zur Transformation nach XHTML, um das Dokument in einem Webbrowser anzuzeigen.

Um die Struktur von XML-Sprachen zu beschreiben, bedient man sich sogenannter "Schemasprachen".

XML Schema (beziehungsweise XSD für XML-Schema-Definition) ist die moderne Möglichkeit, die Struktur von XML-Dokumenten zu beschreiben.
XML Schema bietet auch die Möglichkeit, den Inhalt von Elementen und Attributen zu beschränken, z. B. auf Zahlen, Datumsangaben oder Texte, z. B. mittels regulärer Ausdrücke.
Ein Schema ist selbst ein XML-Dokument, welches erlaubt, komplexere (auch inhaltliche) Zusammenhänge zu beschreiben, als dies mit einer formalen DTD möglich ist.

Weitere Schemasprachen sind Document Structure Description, RELAX NG und Schematron.

Im Zusammenhang mit XML wurden vom W3-Konsortium auf Basis von XML viele Sprachen definiert, welche XML-Ausdrücke für häufig benötigte allgemeine Funktionen anbieten wie etwa die Verknüpfung von XML-Dokumenten. Zahlreiche XML-Sprachen nutzen diese Grundbausteine.


Heute bedienen sich viele formale Sprachen der Syntax von XML. So ist XML ein wesentliches Instrument, um – wie es das W3C vorsieht – eine offene, für Mensch und Maschine verständliche Informationslandschaft (semantic Web) zu schaffen.

Auch die bekannte Dokumentsprache HTML wurde als „Extensible HyperText Markup Language“ (XHTML) im Anschluss an die Version 4.01 in dieses Konzept integriert, so dass ihr nun XML als Definitionsbasis zu Grunde liegt. Vielfacher Grund für den Einsatz von XML ist das zahlreiche Vorhandensein von Parsern und die einfache Syntax: die Definition von SGML umfasst 500 Seiten, jene von XML nur 26.

Die folgenden Listen stellen einige dieser XML-Sprachen dar.







Darüber hinaus existieren XML-Sprachen für Webservices (z. B. SOAP, WSDL und WS-*), für die Einbindung von Java-Code in XML-Dokumente (XSP), für die Synchronisation von Kalenderdaten SyncML, mathematische Formeln (MathML), Repräsentation von Graphen (GraphML), Verfahren im Bereich des Semantischen Webs (RDF, OWL, Topic Maps, UOML), "Service Provisioning" (SPML), den Austausch von Nachrichten (XMPP) oder Finanzberichten wie bspw. Jahresabschlüssen (XBRL), in Bereichen der Automobilindustrie (ODX, MSRSW, AUTOSAR-Templates, QDX, JADM, OTX), automatisierter Test z. B. von Schaltkreisen (ATML) über Systembiologie (SBML) sowie Landwirtschaft (AgroXML) bis zum Verlagswesen (ONIX) oder Chemie (CIDX) und viele weitere mehr.

Eine Zusammenfassung von XML-Sprachen für Office-Anwendungen findet sich im OpenDocument-Austauschformat ("OASIS Open Document Format for Office Applications").


Linus Torvalds bezeichnete XML als Markup-Sprache als wenig geeignet (Kommentar Nr. 19):



</doc>
<doc id="5732" url="https://de.wikipedia.org/wiki?curid=5732" title="Xanthippe (Begriffsklärung)">
Xanthippe (Begriffsklärung)

Xanthippe steht für:


in der griechischen Mythologie:

Außerdem:
Siehe auch:


</doc>
<doc id="5733" url="https://de.wikipedia.org/wiki?curid=5733" title="XSL Transformation">
XSL Transformation

XSL Transformation, kurz XSLT, ist eine Programmiersprache zur Transformation von XML-Dokumenten.
Sie ist Teil der Extensible Stylesheet Language (XSL) und stellt eine Turing-vollständige Sprache dar.

XSLT wurde vom World Wide Web Consortium (W3C) am 8. Oktober 1999 als Empfehlung veröffentlicht. XSLT baut auf der logischen Baumstruktur eines XML-Dokumentes auf und dient zur Definition von Umwandlungsregeln. XSLT-Programme, sogenannte XSLT-Stylesheets, sind dabei selbst nach den Regeln des XML-Standards aufgebaut.

Die Stylesheets werden von spezieller Software, den XSLT-Prozessoren, eingelesen, die mit diesen Anweisungen ein oder mehrere XML-Dokumente in das gewünschte Ausgabeformat umwandeln. XSLT-Prozessoren sind auch in vielen modernen Webbrowsern integriert, wie zum Beispiel Opera (ab Version 9), Firefox und Internet Explorer Version 5 (ab Version 6 mit vollständiger XSLT-1.0-Unterstützung).

XSLT ist eine Untermenge von XSL, zusammen mit XSL-FO und XPath.

Ursprünglich sollte mit XSL eine DSSSL-artige Sprache in XML-Syntax entstehen. Schnell war jedoch klar, dass eine solche Sprache eigentlich aus drei interagierenden, aber unabhängig voneinander einsetzbaren Teilen besteht:

Die deklarative, funktional-applikative Sprache XSLT ist u. a. aus DSSSL hervorgegangen. Entwickelt wurde XSLT ursprünglich von James Clark (XSLT 1.0, XSLT 1.1), für die derzeitige Weiterentwicklung ist Michael Kay verantwortlich.
Seit dem 23. Januar 2007 ist XSLT 2.0 eine „Recommendation“ (Empfehlung) des W3C und hat damit die seit 1999 gültige Version XSLT 1.0 abgelöst. Inzwischen existiert auch eine Version XSLT 3.0 als Candidate Recommendation vom November 2015 des W3C, welche bereits durch den Saxon-Parser unterstützt wird.

Die Sprache XSLT beschreibt die Umwandlung eines XML-Derivats (auch XML-Dialekt oder XML-Anwendung genannt), in Form eines XML-Dokuments, in ein anderes Dokument, Transformation genannt. Das resultierende Dokument entspricht meist der XML-Syntax, es können aber auch andere Textdateien und sogar Binärdateien erstellt werden.

Dazu werden die XML-Dokumente als logischer Baum betrachtet: Die Quellbäume der zu transformierenden Dokumente und die durch die Transformation entstehenden Zielbäume der zu erzeugenden Dokumente.

Eine Transformation besteht aus einer Reihe von einzelnen Transformationsregeln, die "Templates" (deutsch „Schablonen“) heißen. Ein Template besitzt ein auf XPath basierendes Pattern (deutsch „Muster“), das beschreibt, für welche Knoten es gilt, und einen Inhalt, der bestimmt, wie das Template seinen Teil des Zielbaums erzeugt.

In einem XSLT-Dokument kommen also an Sprachen und XML-basierten Technologien mindestens vor:
Sowie ab XSLT 2.0:

"Template Rules" (deutsch „Schablonen-Regeln“) werden immer dann angewendet, wenn eine bestimmte Bedingung passt. Das folgende Beispiel schließt den Inhalt aller Titel („title“-Tags) in „em“-Tags ein, egal wo sie im Dokument vorkommen, und lässt den Rest unberührt.

<xsl:template match="//title">
</xsl:template>

<xsl:apply-templates/> transformiert die Kindelemente des aktuellen Elements mittels sämtlicher dafür anwendbarer Regeln.

"Conflict Resolution" (deutsch „Konfliktauflösung“) wird dann benötigt, wenn ein Knoten zu mehreren "Template Rules" gleichzeitig passt. In solchen Fällen gelten die folgenden Regeln.

Um Elemente zu sortieren, kann ein Tag for-each mit einem sort kombiniert werden. Die Schleife läuft dann nicht in der Reihenfolge der Knoten des Originaldokuments, sondern in alphabetischer oder numerischer Reihenfolge. Im folgenden Beispiel werden alle Buch-Elemente aufsteigend nach ihrem Preis sortiert.

<xsl:for-each select="buch">
</xsl:for-each>

Mit oder ohne codice_1 ist die Reihenfolge immer die gleiche (aufsteigend), da dies die Default-Einstellung ist. Mit codice_2 erhält man eine absteigende Reihenfolge.

XSLT bietet sowohl binäre Entscheidungen mittels des Tags codice_3 als auch mehrfache Entscheidungen über das Tag codice_4. Das folgende Beispiel gibt genau dann ein Sternchen aus, wenn das Attribut codice_5 des Elements codice_6 den Wert „U.S.“ hat.

<xsl:if test="author/@nationality='U.S.'">*</xsl:if>
Um mehrere Fallunterscheidungen zu treffen, kann die Kombination aus den Tags codice_4 und codice_8 verwendet werden.

<xsl:choose>
</xsl:choose>
Um durch XSLT beliebigen Text ausgeben zu lassen, kann das Tag <xsl:text> verwendet werden, wobei das "Escaping" (die Ausgabe von „<“ und „&“ als „&lt;“ und „&amp;“) abgeschaltet werden kann. Der Inhalt kann als normaler Text oder in einem CDATA-Abschnitt stehen. Der Vorteil des CDATA-Abschnitts besteht darin, dass sein Inhalt nicht interpretiert wird, er kann also auch XML-Syntax enthalten.

Zum Beispiel erzeugt

<xsl:text disable-output-escaping="yes">
</xsl:text>

die Ausgabe:

Zwei wichtige Anwendungsgebiete für XSLT sind:

Beispiele für POP sind etwa:

Eine mögliche Alternative zu XSLT ist DSSSL, das man auch als Vorläufer von XSLT betrachten kann. Der wohl größte Vorteil von XSLT gegenüber DSSSL ist seine XML-basierte Syntax. Somit kann jeder XML-Editor automatisch auch für XSLT eingesetzt werden, außerdem gelten die Syntax-Regeln von XML (Wohlgeformtheit, Gültigkeit) damit auch für XSLT. Dadurch ist es möglich, dass XSLT sich selbst bearbeitet, man kann also Transformationen zur Erzeugung und Bearbeitung von Transformationen entwickeln.

MetaMorphosis ist ebenfalls von DSSSL inspiriert. Im Gegensatz zu XSLT ist es ein „target driven“ (zielgesteuerter) Prozessor. Dabei wird der zu erstellende Zielbaum konstruiert. Die Regeln beschreiben nicht, wie die Eingabedatei verarbeitet werden soll, sondern, wie die Ausgabedatei konstruiert werden soll. Der Prozess beginnt mit einer virtuellen Regel „!begin“ mit der der Transformationsprozess beginnt. Die Transformationsregeln beschreiben, wie die Knoten gefüllt werden sollen. Dabei werden Abfragen in die Quellbäume wie auch in die bis dahin aufgebauten Zielbäume formuliert. Die Abfragesprache ist ein mengenorientierter Ausdruck, der alle Eigenschaften der Knoten auslesen und auch setzen kann. Erzeugte Knoten können nachträglich beliebig manipuliert werden.

Weitere Merkmale von MetaMorphosis unterstützen den industriellen Einsatz: flexible Speicherverwaltung für sehr große Dokumente, Aufbau von Hilfsdatenstrukturen (getindex, putindex) zum schnellen Zugriff, Plugin-Architektur, API für C++, C#, Java, die Möglichkeit dedizierte Frontends und Backend zu implementieren (in C++ wie auch in der MetaMorphosis-Skriptsprache).

Im Rahmen des Anwendungsservers Zope wurde die Template Attribute Language (TAL) entwickelt; TAL-Templates sind (je nach Ausgabeformat) [X]HTML- oder XML-Dokumente, deren Inhalte durch Attribute dynamisch ersetzt werden können, und die damit Prototyp und verwendetes Template vereinen. Dem Element <xsl:for-each> entspricht etwa das Attribut tal:repeat; als Ausdruckssyntax wird die TAL Expression Syntax verwendet. Wenn sich kein HTML- oder XML-Element als Träger des Attributs anbietet, können auch <tal:beliebigerBezeichner>-Elemente verwendet werden.

Eine grundsätzliche Alternative zu XSLT besteht in der Möglichkeit, solche Transformationen in jeder beliebigen Programmiersprache (z. B. Java, C++ oder Perl) abzufassen. XSLT kann dabei jedoch bei Einhaltung bestimmter Voraussetzungen eine gewisse Garantie für wohlgeformte und unter Umständen sogar gültige Zieldokumente gewähren. Außerdem ist die Entwicklung einer Transformation in XSLT in der Regel mit erheblich weniger Aufwand verbunden als die Entwicklung einer Transformation in einer Programmiersprache.

Es ist auch möglich, beides zu koppeln:
Die eigentliche Transformation geschieht dann per XSLT, jedoch werden innerhalb des XSLT-Stylesheets selbstdefinierte Funktionen zur Stringmanipulation aufgerufen. Das (z. B. in Ruby oder Python geschriebene) Programm besteht dann aus diesen selbstdefinierten Funktionen und dem Aufruf einer XSLT-Funktion, die den Stylesheet und die eigenen Funktionen als Parameter erhält.

CSS ist keine Alternative zu XSLT, da es sich bei CSS um eine Formatierungssprache handelt. CSS beschreibt lediglich, wie die Bestandteile eines Baumes (akustisch oder visuell) zu formatieren sind, während XSLT den Baum radikal ändern kann oder als Ergebnis Dokumente liefern kann, die nicht auf XML basieren. So kann man mit XSLT z. B. automatisch Inhaltsverzeichnisse, Indizes, Link-Listen und komplexe Berechnungen erstellen, nicht jedoch mit CSS. Mit XSLT ist es zudem möglich, Ergebnisse zu erzeugen, die CSS als Formatierungssprache verwenden.

Folgendes XSLT erzeugt ein einfaches Inhaltsverzeichnis für eine XHTML-Seite mit Überschriften:
<?xml version="1.0" encoding="iso-8859-1"?>
<xsl:stylesheet

</xsl:stylesheet>
"Siehe auch:" XML, XSL-FO, XPath

Die meisten gängigen Webbrowser (u. a. Mozilla Firefox, Internet Explorer, Google Chrome, Opera) unterstützen mittlerweile XSLT. Folgend eine Auflistung von weiteren bekannten XSLT-fähigen Prozessoren und Bibliotheken.





</doc>
<doc id="5734" url="https://de.wikipedia.org/wiki?curid=5734" title="Extensible Stylesheet Language">
Extensible Stylesheet Language

Extensible Stylesheet Language (XSL) ist eine in XML notierte Familie von Transformationssprachen zur Definition von Layouts für XML-Dokumente. Die Untersprache XSLT wird außerdem zur Übersetzung/Transformation eines XML-Formats in ein anderes XML- oder Textformat genutzt.

Referenzen auf Layouts (auch Stylesheets genannt) können in die zu formatierenden XML-Dokumente eingebunden werden, wobei sich die Layouts speziellen Medien zuordnen lassen. So ist es möglich, ein Layout zum Drucken und ein Layout für die Darstellung am Computer zu verwenden.

Zu XSL gehören:

Die drei Sprachen (XSL-FO, XSLT, XPath) lassen sich gemeinsam als XSL oder auch unabhängig voneinander verwenden.

Ein Dokument ließe sich z. B. gleich in XSL-FO verfassen, eine in der Praxis angewandte Vorgehensweise zum Entwurf neuer Layouts.

XSLT kann nicht nur nach XSL-FO transformieren, sondern in jede beliebige XML-basierte Sprache oder aber auch in Formate, die nicht XML sind. In der Praxis wird XSLT vergleichsweise selten mit XSL eingesetzt. Wesentlich häufiger ist XSLT bei Message Oriented Middleware oder Presentation Oriented Publishing auf XML-Basis anzutreffen, wobei letzteres weitaus häufiger mit XHTML für den Einsatz im WWW als XSL-FO verwendet wird. XSLT wird also häufiger mit anderen XML-basierten Sprachen verwendet als mit XSL-FO.

XPath wird in XSLT für XSLT Patterns und für XQuery verwendet.

XSL geht auf das von James Clark entwickelte DSSSL zurück. Im Gegensatz zu DSSSL bietet XSL zwei wesentliche Neuerungen:

Das erste Working Draft zu XSL behandelte noch alle Komponenten in einem Dokument und wurde im August 1998 veröffentlicht. Im Laufe der Entwicklung wurden XSLT und XPath in eigenständige Dokumente ausgelagert. XSLT 1.0 und XPath 1.0 wurden im November 1999 verabschiedet, XSL selbst im Oktober 2001.

Die derzeit aktuelle Fassung von XSLT 2.0 und XPath 2.0 wurde am 23. Januar 2007 verabschiedet.




</doc>
<doc id="5735" url="https://de.wikipedia.org/wiki?curid=5735" title="X2">
X2

X2 oder X-2 steht für:
X steht für
Siehe auch:


</doc>
<doc id="5736" url="https://de.wikipedia.org/wiki?curid=5736" title="XML Schema">
XML Schema

XML Schema, abgekürzt XSD "(XML Schema Definition)," ist eine Empfehlung des W3C zum Definieren von Strukturen für XML-Dokumente. Anders als bei den klassischen XML-DTDs wird die Struktur in Form eines XML-Dokuments beschrieben. Darüber hinaus wird eine große Anzahl von Datentypen unterstützt.
"XML Schema" beschreibt in einer komplexen Schemasprache Datentypen, einzelne XML-Schema-Instanzen (Dokumente) und Gruppen solcher Instanzen. Ein konkretes XML-Schema wird auch als eine XSD "(XML Schema Definition)" bezeichnet und hat als Datei üblicherweise die Endung .xsd. Im Gegensatz zu DTDs kann bei Verwendung von XML-Schemata zwischen dem Namen des XML-Typs und dem in der Instanz verwendeten Namen des XML-Tags unterschieden werden.

Neben "XML Schema" gibt es weitere Konzepte zur Definition von XML-Strukturen, wie RELAX NG oder Schematron. Auch DTD als Normbestandteil von XML selbst kann verwendet werden.

"XML Schema" unterscheidet zwischen einfachen (atomaren) Datentypen und komplexen Datentypen. Der Begriff "Typ" bezeichnet im nachfolgenden Text jeweils die abstrakte Spezifikation der Struktur eines Abschnitts innerhalb eines XML-Dokumentes. Datentypen in "XML Schema" werden klassifiziert in eingebaute bzw. vordefinierte "(built-in)" und benutzerdefinierte "(user defined)" Datentypen.

In der Spezifikation des W3C für "XML Schema" sind 19 voreingestellte primitive Datentypen (z. B. "boolean, string, float, date" und "NOTATION") und weitere 25 davon abgeleitete primitive Datentypen (wie "ID" und "integer") definiert.

"XML Schema" stellt einige grundlegende atomare Datentypen bereit. Die atomaren Datentypen enthalten die „klassischen“ Typen, wie sie zum Teil auch in anderen Typsystemen (z. B. C, Java oder SQL) spezifiziert sind:

Hinzu kommen weitere XML-spezifische atomare Typen, unter anderem:
Einfache XML-Datentypen dürfen weder XML-Kindelemente enthalten noch XML-Attribute besitzen.

Außer den atomaren Datentypen gehören Listen und Unions (bestehend aus atomaren Elementen und Listen) zu den einfachen Typen:


<xs:simpleType name="monatInt">
</xs:simpleType>
<xs:simpleType name="monate">
</xs:simpleType>

Eine Instanz des neuen Typs könnte wie folgt aussehen:

<monate>
</monate>

Die einzelnen Elemente einer Liste werden durch Leerraum (hier: Leerzeichen) getrennt.

Ein neuer Typ wird als Vereinigungsmenge bereits bestehender Typen definiert. Jede Instanz wählt dann ihren Typ aus dieser Menge.
Das nachfolgende Beispiel definiert einen weiteren Typ codice_15 sowie einen Union-Typ codice_16:

<xs:simpleType name="monatsname">
</xs:simpleType>
<xs:simpleType name="monat">
</xs:simpleType>

XML-Elemente vom Typ codice_16 dürfen entweder ganzzahlige Werte im Bereich 1–12 enthalten oder eine der entsprechenden Monatsbezeichnungen als Zeichenkette. Gültige Instanzen sind beispielsweise:

<monat>Jan</monat>
<monat>2</monat>
In Ergänzung zu den einfachen Typen bieten komplexe XML-Datentypdefinitionen die Möglichkeit, Elementenstrukturen zusammenhängend zu definieren. Solche Strukturen können weitere Elemente und Attribute beinhalten.

Das folgende Beispiel definiert einen neuen Typ codice_18 mit entsprechenden Kindelementen codice_19, codice_20 etc., sowie einem Attribut codice_21:

<xs:complexType name="pc-Typ">
</xs:complexType>
Die Möglichkeiten zur Definition komplexer Typen sollen hier nur exemplarisch erläutert werden. Der interessierte Leser sei auf die unten angegebenen Links zu den Seiten des W3C verwiesen.

Die Kindelemente eines komplexen Typs können auf drei unterschiedliche Arten kombiniert werden:

<xs:complexType name="computer">
</xs:complexType>


XML-Elemente mit beliebigem Inhalt lassen sich mittels des Basistyps codice_41 definieren. Der nachfolgende Code spezifiziert ein codice_31-Element beliebigen Inhalts, d. h. sowohl komplexe XML-Elemente als auch Text können vorkommen.

<xs:element name="kommentar" type="xs:anyType"/>
Sollen in dem Inhalt Text und Tags in beliebiger Reihenfolge vorkommen können, muss der Wert für das Attribut "mixed" auf "true" gesetzt werden:

<xs:element name="tagname">
</xs:element>
Von "leeren XML-Elementen" spricht man, wenn das jeweilige Element aus nur einem einzelnen XML-Tag besteht und keine weiteren XML-Elemente oder Text umschließt (z. B. der XHTML-Zeilenumbruch: codice_43). "XML Schema" bedient sich an dieser Stelle eines kleinen Tricks: Es wird mittels codice_44 ein neuer Typ definiert, ohne ein Kindelement anzugeben. Da codice_44 nach Vorgabe nur komplexe XML-Kindelemente als Inhalt zulässt, bleibt das jeweilige Element in diesem Fall leer.

Neue Datentypen lassen sich zum einen durch die Definition eines neuen Typs erstellen (siehe vorheriger Abschnitt) oder durch die Ableitung eines neuen Typs aus bereits bestehenden.

Bei der Ableitung eines neuen Typs handelt es sich nicht um eine Vererbung im Sinne der Objektorientierung, da keine Eigenschaften vergleichbar den Methoden oder Attribute objektorientierter Klassen vererbt werden. Vielmehr handelt es sich hier um die Wiederverwendung bestehender Typdefinitionen. Dementsprechend ist bei der Ableitung neuer Typen auch keine implizite Substituierbarkeit gegeben, wie sie in anderen Typsystemen üblich ist (explizite Typumwandlungen sind jedoch möglich).

Die "Ableitung" eines neuen Typs kann auf zweierlei Arten erfolgen: Erweiterung oder Einschränkung.

Die Erweiterung eines bisherigen Typs (engl. "extension") um weitere Eigenschaften, d. h. neue Elemente oder Attribute werden hinzugefügt.
Im folgenden Beispiel wird der oben definierte Typ codice_18 um ein Element codice_47 erweitert:

<xs:complexType name="myPC-Typ">
</xs:complexType>

Der neu definierte XML-Typ codice_48 besteht aus allen Kindelementen des Typs codice_18 sowie dem Element codice_47. Letzteres wird, wie in einer codice_22-Definition, an die bisherigen Kindelemente angehängt.
Da keine Substituierbarkeit gegeben ist, darf an einer Stelle an der ein Element vom Typ codice_18 erwartet wird nicht ohne weiteres ein Element vom Typ codice_48 verwendet werden.

Durch Einschränkung bereits bestehender Typen (engl. "restriction") lassen sich ebenfalls neue Definitionen ableiten. Zu diesem Zweck müssen alle Elementdefinitionen des Basistyps wiederholt werden, verändert um die jeweiligen restriktiveren Einschränkungen. Im folgenden Beispiel wird ein neuer Typ codice_54 von codice_18 abgeleitet. In diesem Fall darf maximal ein codice_31-Element auftreten (im Gegensatz zu einer beliebigen Anzahl beim Typ codice_18)

<xs:complexType name="myPC2-Typ">
</xs:complexType>
Zusätzlich zu der Einschränkung komplexer Typen ist es auch möglich, neue Typen als Einschränkung einfacher Typen zu definieren. Ein Beispiel für eine solche Definition befindet sich bereits im Abschnitt zu den einfachen Typen. Ein neuer Typ codice_13 wird als Einschränkung des Typs Integer auf den Wertebereich 1–12 definiert. Grundsätzlich stehen die folgenden Primitive zur Verfügung, um Einschränkungen auf einfachen Typen zu beschreiben:

Die folgenden Beispiele veranschaulichen die Verwendung dieser Komponenten:


<xs:simpleType name="celsiusKörperTemp">
</xs:simpleType>


<xs:simpleType name="plz">
</xs:simpleType>


<xs:simpleType name="size">
</xs:simpleType>
Bei der Definition eines Typs ist es möglich festzulegen, ob und auf welche Art von diesem Typ weitere XML-Elementtypen abgeleitet werden dürfen. So kann man zum Beispiel festlegen, dass von einem Typ codice_18 weitere Typen nur durch das Setzen weiterer Einschränkungen abgeleitet werden dürfen – und nicht durch das Hinzufügen neuer Kindelemente.

Wie im vorangegangenen Abschnitt erläutert erlaubt es "XML Schema," neue XML-Datentypen zu definieren und diese bei der Definition eigener XML-Elemente zu verwenden. Das folgende Beispiel veranschaulicht die Verwendung des bereits definierten Typs codice_18 innerhalb einer Liste von pc-Elementen:

<xs:element name="pc-liste">
</xs:element>

Ein entsprechendes XML-Element könnte wie folgt aussehen:

<pc-liste>
</pc-liste>

In diesem Beispiel erfolgt die Spezifikation des anonymen Listentyps direkt innerhalb der Elementdefinition, während die Spezifikation des pc-Typs extern erfolgt.

Bei dem Entwurf eines komplexen XML-Schemas sollte sowohl die Wiederverwendbarkeit und Erweiterbarkeit der einzelnen XML-Elementtypen als auch die Lesbarkeit des Schemas selbst berücksichtigt werden. Die Verwendung anonymer XML-Elementtypen als Teil größerer Elemente gewährleistet im Allgemeinen eine bessere Lesbarkeit kleinerer XML-Schemata. Die Definition und Benennung einzelner, kleinerer und wiederverwendbarer XML-Elementtypen hingegen ermöglicht eine stärkere Modularisierung der XML-Schema-Struktur. Aufgrund der Vielzahl möglicher Anwendungsszenarien haben sich bisher noch keine allgemeingültigen Entwurfsprinzipien für XML-Schemata herausgebildet (vergleichbar den Normalformen für relationale Datenbanken).

Vergleichbar den Primärschlüsseln in relationalen Datenbanken lassen sich mittels "XML Schema" eindeutige Schlüssel definieren. "XML Schema" unterscheidet zwischen der Eindeutigkeit (engl. "unique") und der Schlüsseleigenschaft.

Das nachfolgende Beispiel definiert ein neues Element "pc-list" mit einer Liste von codice_74-Kindelementen:

<xs:element name="pc-list">
</xs:element>

Die beiden Elemente codice_75 und codice_76 selektieren mit einem XPath Pfadausdruck (im Beispiel: codice_74) eine Menge von codice_74-Elementen. Für diese Menge muss die jeweilige Eindeutigkeits- bzw. Schlüsselbedingung erfüllt werden.
Im obigen Beispiel wird festgelegt, dass die Kombination der Elemente codice_19 und codice_20 für jedes codice_74-Element innerhalb dieser Liste eindeutig sein muss.Durch das codice_76-Element wird festgelegt, dass das Attribut codice_21 innerhalb dieser Liste eindeutig sein muss und von außerhalb referenziert werden kann.

Das folgende Beispiel zeigt die Referenzierung dieses Schlüssels mit dem Attribut codice_84 und dem Schlüsselwort codice_85.

<xs:keyref name="idFremdKey" refer="idKey">
</xs:keyref>

Mit codice_84 bezieht man sich auf das codice_19-Attribut einer Schlüsselbedingung, nicht auf das Schlüsselfeld. Die Werte in codice_88 müssen also immer unter den Schlüsseln zu den codice_89 zu finden sein. (Hintergrund dieses Konstrukts ist die Sicherstellung der referentiellen Integrität, wie man sie von relationalen Datenbanksystemen her kennt.)

"XML Schema" erlaubt es, fremde Schemata wiederzuverwenden.
Hierzu stehen sowohl der codice_90- als auch der codice_91-Tag zur Verfügung sowie die Möglichkeit einer neuen Definition bzw. Anpassung fremder Schemata beim Einbinden.

Typdefinitionen innerhalb eines Namensraumes, die auf mehrere Dateien verteilt sind, lassen sich mittels codice_90 zusammenfügen.

<schema xmlns="http://www.w3.org/2001/XMLSchema"
</schema>

Gleiches Beispiel wie gerade. Annahme es gäbe einen codice_97 codice_98 im Schema codice_95.

<schema xmlns="http://www.w3.org/2001/XMLSchema"
</schema>


Der codice_91-Tag erlaubt es, Elemente aus anderen Namensräumen zu importieren, mit einem Präfix zu versehen und
damit Schema-Bestandteile aus unterschiedlichen Namensräumen wiederzuverwenden.
Annahme ist, dass es einen definierten Typ codice_104 in codice_105 gibt.

<schema xmlns="http://www.w3.org/2001/XMLSchema"
</schema>
Zur Verwendung eines XML-Schemas in einer XML-Datei kann das Attribut codice_106 des Schema-Instance-Namensraums verwendet werden, um die Adresse des Schemas bekannt zu machen.
Somit ist es einer Anwendung wie beispielsweise einem XML-Parser möglich, das Schema zu laden, sofern es ihm nicht schon bekannt ist. Alternativ kann der Anwendung das Schema aber auch über andere Wege bekannt gemacht werden, z. B. über Konfigurationsdateien. Letztere Möglichkeit ist jedoch nicht standardisiert und somit von Anwendung zu Anwendung verschieden.

In folgendem Beispiel wird ausgedrückt, dass der Standard-Namensraum codice_107 ist und dann angegeben, dass das XML-Schema für diesen Namensraum unter codice_108 aufzufinden ist.
<html xmlns="http://www.w3.org/1999/xhtml"
Die Definition gilt für das XML-Element, bei dem die Attribute angegeben sind, und alle Kinderelemente.

Soll Elementen, die keinem Namensraum angehören, ein XML-Schema zugeordnet werden, so geschieht dies, wie im folgenden Beispiel gezeigt, mittels des Attributes codice_109.
<html xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"

<?xml version="1.0" encoding="UTF-8"?>
<schema xmlns="http://www.w3.org/2001/XMLSchema"
</schema>
Dies entspricht, abgesehen vom Namensraum, folgender DTD
<!ELEMENT doc (head, body)>
<!ELEMENT head (title)>
<!ELEMENT title (#PCDATA)>
<!ELEMENT body (#PCDATA)>
Eine XML-Struktur, die dem Schema entspricht ist diese:
<?xml version="1.0" encoding="UTF-8"?>
<doc xmlns="http://de.wikipedia.org/wiki/XML_Schema#Beispiel">
</doc>




</doc>
<doc id="5739" url="https://de.wikipedia.org/wiki?curid=5739" title="Extended Graphics Array">
Extended Graphics Array

Extended Graphics Array (Abkürzung XGA) bezeichnet sowohl einen Typ Grafikkarte, der von IBM im Oktober 1990 für die IBM-PS/2-Serie von Computern eingeführt wurde ("XGA Display Adapter/A"), als auch den dazugehörigen Grafikstandard.

Neben dem ursprünglichen "XGA Display Adapter/A" stellte IBM außerdem den ähnlichen "XGA-2 Display Adapter/A" her, der eine höhere erreichbare Farbtiefe ermöglichte.

Die XGA-Hardware war abwärtskompatibel zum Grafikstandard VGA, der 8514/A-Treiber-Schnittstelle und bot außerdem einen 132-Spalten-Textmodus (üblich waren 40 und 80). Die maximale Bildauflösung betrug 1024 × 768 Bildpunkte, die maximale Farbtiefe 16 bit (65.536 Farben). Diese Maximalwerte konnten zwar aus Speichergründen nicht gleichzeitig erreicht werden, mit einer Erweiterung des Grafikspeichers waren jedoch 256 Farben bei 1024 × 768 Bildpunkten möglich, bzw. 65.536 Farben bei 800 × 600 Bildpunkten. Der Framebuffer ist bei XGA-Grafikkarten direkt ansprechbar, so dass ihre Hardware theoretisch jede Kombination aus Auflösung und Farbtiefe liefern kann, sofern der Grafikspeicher dazu ausreicht. Sie besitzen – anders als bei normalem VGA und analog zu 8514/A – hardwarebeschleunigte Zeichenbefehle und Cursor-Darstellung.

Der XGA-Standard konnte sich im Bereich IBM-PC-kompatibler Computer nicht durchsetzen. Die wenig später erscheinenden SVGA-kompatiblen Grafikkarten von Fremdherstellern waren durch VESA-Kompatibilität vergleichbar flexibel, erreichten ähnliche Leistungen und waren für alle Busarchitekturen verfügbar. Vorbild für diese Urväter der modernen PC-Grafikhardware waren jedoch die Merkmale des XGA-Standards.

Der Name "XGA" wurde in Anlehnung an diesen Grafikstandard auch in einem weiteren Sinne für einen Bildmodus innerhalb des Standards VESA 2.0 benutzt, der der maximalen Bildauflösung (1024 × 768 Bildpunkte) des XGA-Standards entspricht. Zusätzlich enthält VESA 2.0 den Bildmodus "SXGA" ("Super" XGA), mit 1280 × 1024 Bildpunkten, der aber außer dem Namen nichts mit dem ursprünglichen Standard zu tun hat. Auch ähnliche Marketingbezeichnungen für bestimmte Bildmodi, die in den 2000er-Jahren aufkamen und ebenfalls das Kürzel XGA enthalten, sind nicht mit dem XGA-Standard verwandt.




</doc>
<doc id="5740" url="https://de.wikipedia.org/wiki?curid=5740" title="Ytterbium">
Ytterbium

Ytterbium [] ist ein chemisches Element mit dem Elementsymbol Yb und der Ordnungszahl 70. Im Periodensystem steht es in der Gruppe der Lanthanoide und zählt damit auch zu den Metallen der Seltenen Erden. Wie die anderen Lanthanoide ist Ytterbium ein silberglänzendes Schwermetall. Die Eigenschaften des Ytterbiums folgen nicht der Lanthanoidenkontraktion, und auf Grund seiner Elektronenkonfiguration besitzt das Element eine deutlich geringere Dichte sowie einen niedrigeren Schmelz- und Siedepunkt als die benachbarten Elemente.

Ytterbium wurde 1878 von Jean Charles Galissard de Marignac bei der Untersuchung von Gadolinit entdeckt. 1907 trennten Georges Urbain, Carl Auer von Welsbach und Charles James unabhängig voneinander ein weiteres Element, das Lutetium, von Marignacs Ytterbium ab. Der bisherige Name wurde dabei nach längerer Diskussion entgegen den Wünschen Welsbachs, der "Aldebaranium" vorgeschlagen hatte, beibehalten.

Technisch werden das Element und seine Verbindungen auf Grund der komplizierten Abtrennung von den anderen Lanthanoiden nur in geringen Mengen, unter anderem als Dotierungsmittel für Yttrium-Aluminium-Granat-Laser genutzt. Ytterbium(III)-chlorid und Ytterbium(II)-iodid sind Reagenzien in verschiedenen organischen Synthesereaktionen.

Ytterbium wurde 1878 vom Schweizer Chemiker Jean Charles Galissard de Marignac entdeckt. Er untersuchte Gadolinit genauer und versuchte durch Zersetzung von Nitraten in heißem Wasser das unlösliche Erbium von den anderen Mineralbestandteilen abzutrennen. Dabei entdeckte er, dass die erhaltenen Kristalle nicht einheitlich aus rotem Erbiumnitrat bestanden, sondern weitere farblose Kristalle zurückblieben. Das gemessene Absorptionsspektrum zeigte, dass es sich um Kristalle eines bislang unbekannten Elements handeln muss. Dieses nannte er nach dem Fundort des Gadolinites in Ytterby (Schweden) sowie wegen der Ähnlichkeit zum Yttrium "Ytterbium". Eine Trennung der beiden Elemente gelang in einem anderen Experiment durch die Zugabe von hyposchwefliger Säure zu einer Lösung der Chloride.

1907 erkannten unabhängig voneinander der Franzose Georges Urbain, der Österreicher Carl Auer von Welsbach und der Amerikaner Charles James, dass das von Marignac gefundene Ytterbium kein Reinelement ist, sondern ein Gemisch zweier Elemente darstellt. Sie konnten dieses Gemisch in das nun reine Ytterbium und in Lutetium trennen. Dabei nannte Carl Auer von Welsbach die Elemente "Aldebaranium" (nach dem Stern Aldebaran) und "Cassiopeium", während Urbain Neoytterbium und Lutetium als Namen festlegte. 1909 wurde vom internationalen Atomgewichts-Ausschuss, bestehend aus Frank Wigglesworth Clarke, Wilhelm Ostwald, Thomas Edward Thorpe und Georges Urbain, bestimmt, dass Urbain die Entdeckung des Lutetiums zusteht und damit auch die von ihm bestimmten Namen Bestand haben. Es wurde jedoch für das Ytterbium der alte Name Marignacs beibehalten.

Elementares Ytterbium wurde erstmals 1936 von Wilhelm Klemm und Heinrich Bommer erhalten. Sie gewannen das Metall durch Reduktion von Ytterbium(III)-chlorid mit Kalium bei 250 °C. Weiterhin bestimmten sie die Kristallstruktur und die magnetischen Eigenschaften des Metalls.

Ytterbium ist auf der Erde ein seltenes Element, seine Häufigkeit in der kontinentalen Erdkruste beträgt etwa 3,2 ppm.

Ytterbium kommt als Bestandteil von Seltenerd-Mineralen, vor allem denjenigen des Yttriums und der schwereren Lanthanoide wie Xenotim und Gadolinit vor. So enthält Xenotim aus Malaysia bis zu 6,2 % Ytterbium. Ceriterden wie Monazit und Bastnäsit enthalten dagegen geringere Anteile an Ytterbium, so enthält Monazit je nach Lagerstätte zwischen 0,12 und 0,5 % des Elements.

Es sind mehrere seltene Minerale bekannt, in denen Ytterbium das häufigste Seltenerdmetall ist. Dazu zählen Xenotim-(Yb) mit einem Anteil von 32 Gewichtsprozent Ytterbium am Mineral und der Verhältnisformel (YbYLuErDyTmHo)PO und Keiviit-(Yb) mit der Verhältnisformel (YbLuErTmYDyHo)SiO. Diese Minerale sind jeweils Teile einer Mischkristallreihe, aus der auch andere natürlich vorkommende Zusammensetzungen, vor allem mit Yttrium als Hauptbestandteil, bekannt sind.

Wichtigste Quellen für Ytterbium sind die Monazit- und Xenotimvorkommen in China und Malaysia (dort als Begleitmineral von Kassiterit). Auf Grund der geringen Nachfrage wird die Situation der Versorgung mit Ytterbium nicht als kritisch angesehen.

Die Gewinnung von Ytterbium ist vor allem durch die schwierige Trennung der Lanthanoide kompliziert und langwierig. Die Ausgangsminerale wie Monazit oder Xenotim werden zunächst mit Säuren oder Laugen aufgeschlossen und in Lösung gebracht. Die Trennung des Ytterbiums von den anderen Lanthanoiden ist dann durch verschiedene Methoden möglich, wobei die Trennung durch Ionenaustausch die technisch wichtigste Methode für Ytterbium, wie auch für andere seltene Lanthanoide, darstellt. Dabei wird die Lösung mit den seltenen Erden auf ein geeignetes Harz aufgetragen, an das die einzelnen Lanthanoid-Ionen unterschiedlich stark binden. Anschließend werden sie in einer Trennsäule mit Hilfe von Komplexbildnern wie EDTA, DTPA oder HEDTA vom Harz gelöst, und durch die unterschiedlich starke Bindung am Harz erzielt man somit die Trennung der einzelnen Lanthanoide.

Eine chemische Trennung ist über unterschiedliche Reaktionen von Ytterbium-, Lutetium- und Thuliumacetat mit Natriumamalgam möglich. Dabei bildet Ytterbium ein Amalgam, während die Lutetium- und Thuliumverbindungen nicht reagieren.

Die Gewinnung metallischen Ytterbiums kann durch Elektrolyse einer Schmelze aus Ytterbium(III)-fluorid und Ytterbium(III)-chlorid erfolgen, mit Alkali- oder Erdalkalimetallhalogeniden zur Schmelzpunktreduktion, sowie flüssigem Cadmium oder Zink als Kathode. Daneben lässt es sich auch durch metallothermische Reduktion von Ytterbium(III)-fluorid mit Calcium, oder Ytterbium(III)-oxid mit Lanthan oder Cer herstellen. Wird die letzte Reaktion im Vakuum ausgeführt, destilliert Ytterbium ab und kann so von anderen Lanthanoiden getrennt werden.

Ytterbium ist wie die anderen Lanthanoide ein silberglänzendes, weiches Schwermetall. Es besitzt mit 6,973 g/cm eine ungewöhnlich niedrige Dichte, die deutlich niedriger ist als diejenige der benachbarten Lanthanoide wie Thulium bzw. Lutetium und vergleichbar mit der von Neodym oder Praseodym ist. Vergleichbares gilt auch für den verhältnismäßig niedrigen Schmelzpunkt von 824 °C und den Siedepunkt von 1430 °C (Lutetium: Schmelzpunkt 1652 °C, Siedepunkt 3330 °C). Diese Werte stehen der sonst geltenden Lanthanoidenkontraktion entgegen und werden durch die Elektronenkonfiguration [Xe] 4f 6s des Ytterbiums verursacht. Durch die vollständig gefüllte f-Schale stehen nur zwei Valenzelektronen für metallische Bindungen zur Verfügung und es kommt daher zu geringeren Bindungskräften und zu einem deutlich größeren Metallatomradius.

Es sind drei verschiedene Kristallstrukturen bei Atmosphärendruck sowie drei weitere Hochdruckmodifikationen des Ytterbiums bekannt. Bei Raumtemperatur kristallisiert das Metall in einer kubisch-dichtesten Kugelpackung mit dem Gitterparameter a = 548,1 pm. Bei höheren Temperaturen und Drücken geht diese Struktur in eine kubisch-innenzentrierte Kugelpackung über, wobei bei Atmosphärendruck die Übergangstemperatur bei etwa 770 °C, und bei Raumtemperatur der Übergangsdruck bei 4 GPa liegt. Bei tiefen Temperaturen ist eine hexagonal-dichteste Struktur stabil, wobei der strukturelle Phasenübergang, welcher zwischen 0 und 45 °C liegt, stark abhängig ist von Reinheit, Druck und Spannungen im Metall. Diese Phasen besitzen unterschiedlichen Magnetismus. Während die hexagonale Phase (wie durch die vollständig besetzten Orbitale zu erwarten) diamagnetisch ist, zeigt die kubisch-flächenzentrierte Struktur Paramagnetismus (wahrscheinlich durch geringe Mengen Yb im Metall).

Die Reihenfolge der Hochdruckmodifikationen entspricht nicht der bei anderen Lanthanoiden häufig zu findenden Reihenfolge. So sind keine Modifikationen des Ytterbiums mit einer doppelt-hexagonal-dichtesten Struktur oder einer Samarium-Struktur bekannt. Auf die ab 4 GPa stabile kubisch-innenzentrierte Struktur folgt bei 26 GPa eine hexagonal-dichteste Phase. Der nächste Phasenübergang erfolgt bei weiterer Druckerhöhung bei 53 GPa und oberhalb dieses Druckes bildet sich wiederum eine kubisch-dichteste Struktur aus. Ein weiterer bekannter Phasenübergang erfolgt bei 98 GPa. Ab diesem Druck ist bis mindestens 202 GPa eine hexagonale Struktur am stabilsten, mit der , was auch "h"P3-Struktur genannt wird. Mit der Druckerhöhung erfolgt auch eine Änderung der Elektronenstruktur des Ytterbiums, wobei ein Elektron vom f-Orbital in ein d-Orbital übergeht, und die Elektronenkonfiguration ist dann wie bei anderen Lanthanoiden dreiwertig "(trivalent)".

Ytterbium ist ein typisches unedles Metall, das vor allem bei höheren Temperaturen mit den meisten Nichtmetallen reagiert. Mit Sauerstoff reagiert es bei Standardbedingungen an trockener Luft langsam, schneller bei Anwesenheit von Feuchtigkeit. Feinverteiltes metallisches Ytterbium ist, wie andere unedle Metalle, an Luft und unter Sauerstoff entzündlich. Mischungen von feinverteiltem Ytterbium und Organohalogenverbindungen wie Hexachlorethan oder Polytetrafluoroethylen brennen mit smaragdgrüner Flamme. Die Reaktion von Ytterbium mit Wasserstoff ist keine vollständige, denn der Wasserstoff tritt in die Oktaederlücken der Metallstruktur ein und es bilden sich nicht-stöchiometrische Hydrid-Phasen aus, wobei die Zusammensetzung von der Temperatur und dem Wasserstoffdruck abhängt.

In Wasser löst sich Ytterbium nur langsam, in Säuren schneller unter Wasserstoffbildung. In Lösung liegen meist dreiwertige, farblose Ytterbiumionen in Form des Hydrates [Yb(HO)]vor. Das gelbgrüne zweiwertige Ytterbiumion ist in wässriger Lösung nicht stabil, es oxidiert unter Wasserstoffbildung mit einer Halbwertszeit von etwa 2,8 Stunden zum dreiwertigen Ion. Wird Ytterbium in flüssigem Ammoniak gelöst, bildet sich wie bei Natrium durch solvatisierte Elektronen eine blaue Lösung.

Es sind insgesamt 33 Isotope zwischen Yb und Yb sowie weitere 12 Kernisomere des Ytterbiums bekannt. Von diesen kommen sieben mit unterschiedlicher Häufigkeit in der Natur vor. Das Isotop mit dem größten Anteil an der natürlichen Isotopenzusammensetzung ist Yb mit einem Anteil von 31,8 %, gefolgt von Yb mit 21,9 %, Yb mit 16,12 %, Yb mit 14,3 % und Yb mit 12,7 %. Yb und Yb sind mit Anteilen von 3,05 bzw. 0,13 % deutlich seltener.

Das radioaktive Isotop Yb mit einer Halbwertszeit von 32 Tagen entsteht zusammen mit dem kurzlebigen Yb (Halbwertszeit 4,2 Tage) durch Neutronenaktivierung bei der Bestrahlung von Ytterbium in Kernreaktoren. Es kann als Gammastrahlenquelle, etwa in der Nuklearmedizin und Radiographie, genutzt werden.

Ytterbium und seine Verbindungen werden nur in sehr geringem Umfang kommerziell eingesetzt. Als Legierungsbestandteil verbessert es die Kornfeinung, Festigkeit und mechanischen Eigenschaften rostfreien Stahls. Es wurde untersucht, Ytterbiumlegierungen in der Zahnmedizin zu nutzen.

Ytterbium wird wie andere Lanthanoide als Dotierungsmittel für Yttrium-Aluminium-Granat-Laser () genutzt. Vorteile gegenüber n liegen in der höheren möglichen maximalen Dotierung, einer längeren Lebensdauer des höheren Energieniveaus sowie einer größeren Absorptions-Bandbreite. Auch in Faserlasern ist Ytterbium ein wichtiges Dotierungsmittel, das auf Grund ähnlicher Vorteile wie beim YAG-Laser besonders für Hochleistungsfaserlaser genutzt werden kann. Dazu zählen die hohe Dotierung, ein großer Absorptionsbereich zwischen 850 und 1070 nm und ebenso der große Emissionsbereich zwischen 970 und 1200 nm.

Experimentell wurde Ytterbium als Alternative zu Caesium für den Betrieb von Atomuhren untersucht. Dabei konnte eine viermal so hohe Genauigkeit wie bei einer Caesium-Atomuhr gemessen werden.

Ytterbium wird zurzeit als Ersatz für Magnesium in schweren Wirkladungen für kinematische Infrarottäuschkörper untersucht. Dabei zeigt Ytterbium aufgrund einer deutlich höheren Emissivität von Ytterbium(III)-oxid im Infrarotbereich im Vergleich zu Magnesiumoxid eine höhere Strahlungsleistung als herkömmliche Wirkmassen auf der Basis von Magnesium/Teflon/Viton (MTV).

Ytterbium kommt nur in minimalen Mengen im Körper vor und besitzt keine biologische Bedeutung. Nur wenige Lebewesen wie Flechten sind in der Lage, Ytterbium aufzunehmen, und besitzen Ytterbiumgehalte von über 900 ppb. Bei Braunalgen "(Sargassum polycystum)" wurde eine Biosorption von 0,7 bis 0,9 mmol·g gemessen.

Ytterbium und seine löslichen Verbindungen sind leicht toxisch, für Ytterbium(III)-chlorid wurde bei Mäusen ein LD-Wert von 395 mg/kg für intraperitoneale und 6700 mg/kg für perorale Gabe bestimmt. Im Tierversuch an Kaninchen reizt Ytterbiumchlorid die Augen nur leicht und Haut nur bei Verletzungen. Ytterbium gilt als teratogen; in einer Studie mit Goldhamster-Embryos wurden nach Gabe von Ytterbiumchlorid Skelettänderungen wie zusammengewachsene oder zusätzliche Rippen oder Veränderungen an der Wirbelsäule festgestellt.

Es sind Verbindungen des Ytterbiums in der Oxidationsstufe +2 und +3 bekannt, wobei wie bei allen Lanthanoiden +3 die häufigere und stabilere Stufe ist.

Mit den Halogenen Fluor, Chlor, Brom und Iod bildet Ytterbium zwei Reihen von Salzen mit den Formeln YbX und YbX. Die Dihalogenide oxidieren dabei leicht zu den Trihalogeniden, bei höheren Temperaturen disproportionieren sie zu Ytterbiumtrihalogeniden und Ytterbium.
Mehrere Ytterbiumhalogenide werden als Reagenz in organischen Synthesen verwendet. So ist Ytterbium(III)-chlorid eine Lewis-Säure und kann als Katalysator etwa in Aldol-Reaktionen, Diels-Alder-Reaktionen oder Allylierungen genutzt werden. Ytterbium(II)-iodid kann wie Samarium(II)-iodid als Reduktionsmittel oder für Kupplungsreaktionen eingesetzt werden.

Ytterbium(III)-fluorid wird als inerter und nicht giftiger Füllstoff in der Zahnmedizin verwendet. Es setzt kontinuierlich das für die Zahngesundheit wichtige Fluorid frei und ist zudem ein gutes Röntgenkontrastmittel.

Es sind eine Reihe von metallorganischen Verbindungen bekannt. Verbindungen mit einer Sigma-Bindung zwischen Ytterbium und Kohlenstoff sind nur in geringem Umfang bekannt, da es bei diesen wie bei vielen Übergangsmetallen leicht zu Folgereaktionen wie β-Hydrideliminierungen kommt. Sie sind daher mit sterisch anspruchsvollen Resten wie der "tert"-Butylgruppe oder einer größeren Zahl kleiner Reste wie in einem Hexamethylytterbat-Komplex [Yb(CH)] stabil. Die wichtigsten Liganden des Ytterbiums sind Cyclopentadienyl und dessen Derivate. Sandwichkomplexe des Ytterbiums sind nicht mit Cyclopentadienyl, sondern nur mit größeren Liganden wie Pentaphenylcyclopentadienyl bekannt. Weiterhin kennt man Komplexe mit η koordinierten Cyclopentadienyl-Liganden: CpYbX, CpYbX und CpYb (X kann dabei ein Halogenid, Hydrid, Alkoxid oder weiteres sein).

Mit Sauerstoff reagiert Ytterbium zu Ytterbium(III)-oxid, YbO, das wie die anderen dreiwertigen Oxide der schwereren Lanthanoide in der kubischen Lanthanoid-C-Struktur kristallisiert. Dieses lässt sich durch Reaktion mit elementarem Ytterbium zu Ytterbium(II)-oxid reduzieren, das in einer Natriumchlorid-Struktur kristallisiert.

Eine Übersicht über Ytterbiumverbindungen bietet die .




</doc>
<doc id="5741" url="https://de.wikipedia.org/wiki?curid=5741" title="Yttrium">
Yttrium

Yttrium [] ist ein chemisches Element mit dem Elementsymbol Y und der Ordnungszahl 39. Es zählt zu den Übergangsmetallen sowie den Seltenerdmetallen, im Periodensystem steht es in der 5. Periode sowie der 3. Nebengruppe, bzw. der 3. IUPAC-Gruppe oder Scandiumgruppe. Yttrium ist nach dem ersten Fundort, der Grube Ytterby bei Stockholm, benannt, wie auch Ytterbium, Terbium und Erbium.

Yttrium wurde 1794 von Johan Gadolin im Mineral Ytterbit entdeckt. 1824 stellte Friedrich Wöhler verunreinigtes Yttrium durch Reduktion von Yttriumchlorid mit Kalium her. Erst 1842 gelang Carl Gustav Mosander die Trennung des Yttriums von den Begleitelementen Erbium und Terbium.

Yttrium kommt in der Natur nicht im elementaren Zustand vor.
Yttriumhaltige Minerale (Yttererden) sind immer verschwistert mit anderen Seltenerdmetallen.
Auch in Uranerzen kann es enthalten sein.
Kommerziell abbauwürdig sind Monazitsande, die bis zu 3 % Yttrium enthalten, sowie Bastnäsit, der 0,2 % Yttrium enthält.
Weiterhin ist es der Hauptbestandteil des Xenotim (Y[PO]).

Große Monazitvorkommen, die Anfang des 19. Jahrhunderts in Brasilien und Indien entdeckt und ausgebeutet wurden, machten diese beiden Länder zu den Hauptproduzenten von Yttriumerzen.
Erst die Eröffnung der Mountain Pass Mine in Kalifornien, die bis in die 1990er Jahre große Mengen an Bastnäsit förderte, machte die USA zum Hauptproduzenten von Yttrium, obwohl der dort abgebaute Bastnäsit nur wenig Yttrium enthält.
Seit der Schließung dieser Mine ist China mit 60 % der größte Produzent für Seltene Erden.
Diese werden in einer Mine nahe Bayan Kuang, deren Erz Xenotim enthält, und aus ionenabsorbierenden Tonmineralen, die vor allem im Süden Chinas abgebaut werden, gewonnen.

Die Trennung der Seltenen Erden voneinander ist ein aufwändiger Schritt in der Produktion von Yttrium. Fraktionierte Kristallisation von Salzlösungen war zu Anfang die bevorzugte Methode, diese wurde schon früh für die Trennung der seltenen Erden im Labormaßstab verwendet. Erst die Einführung der Ionenchromatographie machte es möglich, die seltenen Erden im industriellen Maßstab zu trennen.

Das aufkonzentrierte Yttriumoxid wird umgesetzt zum Fluorid. Die anschließende Reduktion zum Metall erfolgt mit Calcium im Vakuuminduktionsofen.

Der USGS schätzte die Jahresproduktion für 2014 auf 7.000 t Yttriumoxid (YO) und den Verbrauch auf 6.000 t. Die Produktion erfolgte fast ausschließlich in China. Der Preis für Yttriumoxid mit einer Reinheit von 99,999 % stieg von 25–27 USD je kg im Jahre 2010 auf 136–141 USD im Jahr 2011 und fiel bis 2013 wieder auf 23–27 USD. Im August 2015 lag der Preis bei ca. 5,5 USD je kg.

Yttrium ist an der Luft relativ beständig, dunkelt aber unter Licht. Bei Temperaturen oberhalb von 400 °C können sich frische Schnittstellen entzünden. Fein verteiltes Yttrium ist relativ unbeständig.
Yttrium hat einen niedrigen Einfangquerschnitt für Neutronen.

In seinen Verbindungen ist es meist dreiwertig. Es gibt jedoch auch Clusterverbindungen, in denen Yttrium Oxidationsstufen unter 3 annehmen kann.
Yttrium zählt zu den Leichtmetallen.

Es sind insgesamt 32 Isotope zwischen Y und Y, sowie weitere 24 Kernisomere bekannt. Von diesen ist nur Y, aus dem auch natürliches Yttrium ausschließlich besteht, stabil. Es handelt sich damit bei Yttrium um eines von 22 Reinelementen. Die stabilsten Radioisotope sind Y mit einer Halbwertszeit von 106,65 Tagen und Y mit einer Halbwertszeit von 58,51 Tagen. Alle anderen Isotope haben eine Halbwertszeit unter einem Tag, mit Ausnahme von Y, welches eine Halbwertszeit von 79,8 Stunden hat, und Y mit 64 Stunden. Yttrium-Isotope gehören zu den häufigsten Produkten der Spaltung des Urans in Kernreaktoren und bei nuklearen Explosionen.

"→ Liste der Yttrium-Isotope"

Metallisches Yttrium wird in der Reaktortechnik für Rohre verwendet. Die Legierung mit Cobalt YCo kann als Seltenerdmagnet genutzt werden. Yttrium findet als Material für Heizdrähte in Ionenquellen von Massenspektrometern Verwendung. In der Metallurgie werden geringe Yttriumzusätze zur Kornfeinung eingesetzt, zum Beispiel in Eisen-Chrom-Aluminium-Heizleiterlegierungen, Chrom-, Molybdän-, Titan- und Zirconiumlegierungen. In Aluminium- und Magnesiumlegierungen wirkt es festigkeitssteigernd.
Dotierung von Lithium-Eisenphosphat-Akkumulator mit Yttrium steigert Leistung und Haltbarkeit

Technisch wichtiger sind die oxidischen Yttriumverbindungen:

Die wichtigste Verwendung der Yttriumoxide und Yttriumoxidsulfide sind jedoch die vielfältigen Einsatzmöglichkeiten in mit dreiwertigem Europium (rot) und Thulium (blau) dotierten Luminophoren (Leuchtstoffen) in Fernsehbildröhren und Leuchtstofflampen.

Des Weiteren werden Yttrium-Keramiken und -Legierungen eingesetzt in:

Als reiner Beta-Strahler wird Y in der Nuklearmedizin zur Therapie eingesetzt, zum Beispiel zur Radiosynoviorthese, der Radionuklidtherapie von Knochenmetastasen und der Radioimmuntherapie.

Yttrium gilt als nicht essentiell und giftig. Es ist kein MAK-Wert oder Arbeitsplatzgrenzwert für Yttrium festgelegt.



</doc>
<doc id="5742" url="https://de.wikipedia.org/wiki?curid=5742" title="Yard">
Yard

Das Yard ist eine Einheit der Länge in vielen englischsprachigen Ländern (siehe angloamerikanisches Maßsystem), das dort zusätzlich zu den Längen-Einheiten des metrischen Internationalen Einheitensystems gebräuchlich und amtlich zugelassen ist. Es entspricht 3 Fuß und damit 36 Zoll bzw. ein wenig mehr als 0,9 Meter.

Das englische Wort bedeutete ursprünglich "Gerte" (womit es sprachgeschichtlich verwandt ist), "Zweig, Stock, Stab".

Der Hobby-Archäologe Alexander Thom spekulierte, dass schon in den prähistorischen Kulturen Längeneinheiten von drei Fuß verwendet wurden.

Im angelsächsischen England hatte das Yard eine Länge von 16½ Fuß bzw. 5½ heutige Yard. Im 13. Jahrhundert war hingegen die Elle (engl. "ell," lat. "ulna") zu 45 Zoll Standard, bis diese 1353 unter Eduard III. gesetzlich durch die "verge" beziehungsweise das heutige Yard zu 3 Fuß oder 36 Zoll abgelöst wurde.

Es folgten weitere Definitionen des Yard, so von 1558 bis 1824 das „Königin Elisabeth Yard“, das 1758 zum Teil der „Imperial Standards“ erklärt wurde, und das Birds Standard-Maß von 1760. Mit der "Weights and Measures Act" von 1824 (5° George IV. Cap. 74) wurde auch das Yard physikalisch als Abstand der Mitten der mittleren Striche auf den goldenen Bolzen in einem Bronzestab bei 62 Grad Fahrenheit, der im Board of Trade in Westminster aufbewahrt wird, definiert:

Lokal hielten sich aber auch noch andere Definitionen. In der Präsidentschaft Madras, einer Verwaltungseinheit Britisch Indiens, war ein Yard im 19. Jahrhundert wie folgt geteilt:

1856 erhielten die USA zwei Kopien des britischen Standard-Yards.

Seit Ende des 19. Jahrhunderts wird das Yard vom Meter abgeleitet: Das englische Yard wurde auf 914,3993 mm, das amerikanische Yard auf 914,4019 mm festgelegt. Seit dem Jahr 1956 ist das Yard international einheitlich mit einer Länge von exakt 0,9144 Meter definiert. Es gibt allerdings weitere Festlegungen, und für Anwendungen mit geringerer Exaktheit gelten gerundete Werte (s. u.).

In Großbritannien, nicht aber in den Vereinigten Staaten (wo hierfür der Fuß verwendet wird) ist das Yard – auch nach der Einführung des metrischen Systems – die übliche Einheit für mittlere Distanzen. In der Luftfahrt sind dagegen die Angaben für Flughöhen überwiegend in Fuß. Im angelsächsischen Raum generell findet das Yard heute vor allem noch in der Geodäsie Verwendung.

In der Leichtathletik waren bis Ende der 1970er Jahre neben den Meter-Strecken auch Yard-Strecken üblich, z. B. 100-Yards-Lauf (91,44 m) oder 4-mal-110-Yards-Staffellauf. Eine große Rolle spielt das Yard auch im American Football, wo das Spielfeld in zwölf jeweils zehn Yard große Abschnitte eingeteilt ist. Alle Lauf- und Passstatistiken werden in Yard angegeben. Auch für die Einteilung von Fußballfeldern wurde ursprünglich das Yard benutzt.






</doc>
<doc id="5743" url="https://de.wikipedia.org/wiki?curid=5743" title="Yersinia pestis">
Yersinia pestis

Yersinia pestis – auch Pestbakterium genannt – ist ein gramnegatives, unbegeißeltes, sporenloses, fakultativ anaerobes Stäbchenbakterium. Es zählt zu den Enterobakterien und ist der Erreger der Lungen- und Beulenpest.

"Yersinia pestis" wurde von Alexandre Émile Jean Yersin 1894 entdeckt. Seit 1944 wird das zuvor der Gattung "Pasteurella" zugerechnete Bakterium in die nach Yersin benannte Gattung "Yersinia" gestellt.

Die Virulenz von "Yersinia pestis" entsteht durch Exotoxin-, Endotoxin- und Bakterienkapselbildung.

1980 stellten Dan Cavanaugh und James Williams fest, dass die Virulenz des Bakteriums temperaturabhängig ist. Die Körpertemperatur des Flohs liege bei 24 °C, die des Menschen bei 37 °C und die der Ratte 1,5 °C höher. Der Temperaturunterschied zwischen Floh und Ratte könne die Virulenz des Bakteriums bei der Übertragung um fast das 50-Fache steigern. Dies liege an der Fähigkeit des Bakteriums, bei höheren Temperaturen Schutzmechanismen gegen die Phagocytose, einen Bestandteil der menschlichen Immunabwehr, zu entwickeln. Bei Temperaturen, wie sie im Körper des Flohs vorherrschen, werde dieser Schutz nicht aufgebaut und das Bakterium von Leukozyten und Monozyten vernichtet. Aber 3 Stunden nach Eingang in einen Körper von 37 °C sei der Schutzmechanismus gegen Leukozyten und kurz danach derjenige gegen die Monozyten ausgebildet.

Von den hunderten von bekannten Bakterienstämmen sind nur wenige virulent. Die 40–50 Stämme von "Yersinia pestis" haben bei Mäusen eine große Bandbreite der Dosis, bei der die Hälfte der Versuchstiere stirbt (LD), von unter 3 bis 100 Millionen.

Bricht der Krankheitserreger in die Blutbahn ein, was in 50–90 % der unbehandelten Fälle geschieht, so entsteht die Pestsepsis, also eine Streuung in die Blutbahn. Auf diesem Wege können praktisch alle Organe befallen werden. Unter anderem kommt es zur Lungenpest. Die Gefahr bei der Vermehrung innerhalb des Menschen ergibt sich aus der Ausbildung diverser Pathogenitätsfaktoren bei einer Umgebungstemperatur von 37 °C, also Körpertemperatur. So bildet Yersinia pestis bei dieser Temperatur eine antiphagozytär wirkende Kapsel aus, die als Fraktion 1 (F1) bezeichnet wird, und zwei weitere antiphagozytäre Antigene, die Virulenzantigene V und W. In Bezug auf die Virulenz des Erregers bedeutet dies, dass im Falle der Lungenpest die Übertragung von Mensch zu Mensch möglich ist, wenn es zu Kontakt mit hochinfektiösem Sputum eines an Lungenpest Erkrankten kommt. In diesem Fall kann sich innerhalb von Stunden eine primäre Lungenpest ausbilden.

R. Devignat teilte 1951 die Pestbakterien in 3 Hauptvarianten nach den starken biochemischen Unterschieden ein: Variante 1 (später „Orientalis“ genannt) soll ihren Ausgangspunkt in Indien, Burma und im südlichen China gehabt haben. Sie soll für die Pandemie von 1890 verantwortlich und in wenigen Jahren über die ganze Erde verbreitet worden sein. Variante 2 („Antiqua“ genannt), die er für die älteste hielt, soll in Zentral-Asien entstanden sein und sich über Zentralafrika verbreitet haben und die justinianische Pest im sechsten Jahrhundert verursacht haben. Die dritte Variante („Medievalis“) stamme ebenfalls aus Zentralasien, soll sich in Richtung Krim und die Umgebung des Kaspischen Meeres verbreitet und dann den Schwarzen Tod in Europa und die folgenden Epidemien ausgelöst haben. Dieses Modell war lange Zeit Grundlage für die Erklärung der Ausbreitungswege. Später stellte sich heraus, dass beide Hauptvarianten „Medievalis“ und „Antiqua“ in Kenia auftraten und „Orientalis“ und „Medievalis“ zusammen in der Türkei gefunden wurden.

Mark Achtmann und andere kamen 1999 in ihren Studien zu dem Ergebnis, dass "Yersinia pestis" ein mutierter Klon seines nahen Verwandten "Yersinia pseudotuberculosis" ist, ein relativ harmloses Bakterium, das Magenbeschwerden verursachen kann und nur äußerst selten zum Tode führt. Die beiden Arten haben über 90 % des Genmaterials gemeinsam und würden nach taxonomischen Regeln als Varianten der gleichen Art bezeichnet, wenn sie nicht aus klinischen Gründen scharf unterschieden werden müssten. Die Autoren meinten, dass diese Variante höchstens 20.000 Jahre alt sein könne, das unsicherere Mindestalter aber wahrscheinlich bei 1.000 Jahren liege.

1997 wurde ein Pestbakterienstamm beschrieben, der multiresistent gegen Antibiotika war. Da er in älteren Proben nicht zu finden war, scheint er nach den Aussagen der Forscher erst 1995 entstanden zu sein.

Den ersten umfassenden durch Genomanalyse gestützten Blick auf etwa 1000 Isolate von "Y. pestis" gewannen Morelli und andere 2010 in einer Untersuchung, die zeigte, dass die ältesten pathogenen Stämme in China oder Russland entstanden sein mussten. Es fanden sich weitere Zusammenhänge in der Ausbreitung der Stämme mit dem Handel über die Seidenstraße, die Expeditionen von Zheng He und der dritten Pandemie von 1894.

2011 schließlich hatten Bos, Schuenemann und andere die Gelegenheit, das Genom von Pestbakterien zu untersuchen, die aus Zähnen mittelalterlicher Londoner Leichen isoliert werden konnten. Ein Vergleich mit anderen bekannten Stämmen zeigte, dass es sich um Stämme handelte, die mit den ältesten Stämmen aus China am nächsten verwandt sein müssen. Das bedeutet beispielsweise, dass die mittelalterliche Epidemie tatsächlich von Asien ausging. Es bedeutet überraschenderweise auch, dass, wenn es wirklich noch frühere Pestepidemien gab, deren Stämme ausgestorben sind, da alle heute bekannten Stämme Abkömmlinge der Mittelalter-Variante sind.<ref name="DOI10.1038/nature10549">Kirsten I. Bos, Verena J. Schuenemann u. a.: "A draft genome of Yersinia pestis from victims of the Black Death." In: "Nature." Band 478, 2011, S. 506–510, .</ref>

Bei "Yersinia" sind es wohl 2 Plasmiden, die für "pestis" charakteristisch sind und seine Gefährlichkeit ausmachen. So wurde schon vermutet, dass eine plötzliche und umfassende Veränderung der Virulenz ein Hintergrundfaktor dafür gewesen sein kann, dass eine Pestepidemie plötzlich ausbrach und wieder verschwand, quer über die Jahrhunderte hindurch. Gerade bei Viren und Bakterien ist eine Instabilität des Genmaterials zu beobachten, die zu vielen Mutationen führt. Inzwischen ist es gelungen, das gesamte Genom von "Yersinia pestis" zu entschlüsseln und zu kartografieren. Dabei stellten die Forscher fest, dass das Bakterium genetische Besonderheiten aufweist, die auf häufige „intragenomische Rekombinationen“ hinweisen, dass es also in hohem Maße Gene anderer pathogener Organismen aufnehmen kann. Sie meinten, die Pestbakterien hätten Charakteristiken, die auf ständige Veränderungen hinwiesen. Ein Jahr später entschlüsselte eine andere Forschergruppe einen anderen Bakterienstamm und bestätigte diese Einschätzung.
Annie Guiyoule und Bruno Rasoamanana untersuchten in Madagaskar die Gebiete mit besonders hoher Pestaktivität in den letzten Jahrzehnten. Sie isolierten 187 verschiedene Stämme aus der Zeit von 1926 bis 1996.

Bei moderaten Temperaturen überlebt "Yersinia pestis" an den Mundwerkzeugen der Flöhe rund 3 Stunden. Bereits 1944 ist festgestellt worden, dass Pestbakterien in Salzlösung und einer Temperatur um 25 °C bis zu 2 Wochen, bei 2–4 °C sogar bis zu zwei Jahren außerhalb eines Wirtstieres überleben und virulent sein können. Experimente in der 1. Hälfte des 20 Jh. zeigten auch, dass Sonnenlicht die Bakterien rasch abtötet, die Lebensdauer jedoch stark von der Umgebung der Bakterien abhängt, insbesondere von deren Unterlage. In dünner Lauge auf Glas sterben die Bakterien innerhalb 1 Stunde ab, bei einer dicken Bakterienschicht vervierfachte sich die Lebensdauer und auf Stoff aus Hanf lebten sie bis zu 14 Stunden. Während Temperaturen bei 55 °C tödlich sind, schaden ihnen niedrige Temperaturen nicht. In der Mandschurei wurden sogar noch virulente Bakterien in gefrorenen Pestleichen gefunden. Auch konnten die Bakterien fast einen Monat in Kornstaub überleben, der von infektiösen Ausscheidungen verunreinigt war. Pestbakterien können Menschen bei Raumtemperatur und normaler Luftfeuchtigkeit in einem Zeitraum von mehr als 5 Tagen infizieren.

Flöhe, insbesondere aber der Rattenfloh "Xenopsylla cheopis" können den Pesterreger übertragen. Aber auch "Nosopsyllus fasciatus" und der Menschenfloh "Pulex irritans" werden diskutiert, da "Xenopsylla cheopis" auf tropische Temperaturen angewiesen ist und in Europa nicht überleben kann. Flöhe sind blutsaugende Parasiten, die ihren Wirt direkt mit "Yersinia pestis" infizieren können. Wechselt der Rattenfloh von einem infizierten Nager – beispielsweise der Wanderratte oder der Hausratte – nach dessen Tod auf einen anderen Wirt, etwa Haustiere oder Menschen, ist er in der Lage, diese mit dem Pestbakterium zu infizieren. Dabei kann die Pesterkrankung für den Menschen ebenso tödlich sein wie für die Ratten.

An der Bissstelle kommt es zu einer lokalen Infektion, die durch die Ausbildung einer Pustel gekennzeichnet ist und zur sogenannten Bubonenpest (Beulenpest) führt.

Bei der septischen (blutvergiftenden) Form wird keine Pestbeule entwickelt. Der Patient stirbt schnell ohne besondere äußere Symptome, aber mit einer hohen Bakterienkonzentration im Blut. Wenn diese Pestbakterien die Lunge angreifen, so wird diese Form als „sekundäre Lungenpest“ bezeichnet, die die gefährlichste Form mit dem raschesten Verlauf bildet. Neben hohem Fieber ist der blutige Auswurf eines der wenigen äußeren Symptome.

Die blutvergiftende Wirkung wird ausgelöst, wenn die Bakterien ihren normalen Lebenszyklus vollenden und absterben. Dabei werden große Mengen toxischen Sekrets direkt in den Blutkreislauf abgegeben; Nieren und Leber können nekrotisch werden, wenn sie versuchen, das System von Toxinen zu reinigen. Am Ende erliegt das Opfer einem toxischen Schock.




</doc>
<doc id="5744" url="https://de.wikipedia.org/wiki?curid=5744" title="Yambohnen">
Yambohnen

Yambohne ist die deutschsprachige Bezeichnung für die Pflanzenarten der Gattung "Pachyrhizus" aus der Familie der Hülsenfrüchtler (Fabaceae). Die Gattung umfasst fünf bis sechs Arten.

Obwohl diese Arten mit einer Reihe anderer „Bohnen“ genannter Feldfrüchte nahe verwandt sind, deren Hülsenfrüchte verzehrt werden, werden bei den Yambohnen-Arten hauptsächlich die Wurzelknollen genutzt; die Samen sind zwar giftig, werden aber gegart trotzdem gegessen. Die Wurzelknollen werden als Nahrungsmittel und zur Erfrischung (Wasserspeicher) genutzt. Die Samen, Blätter und die Hülsen sind mehr oder weniger giftig.

Yambohnen haben ihr natürliches Vorkommen von Mexiko bis Südamerika. Drei der Arten werden in Südamerika kultiviert, eine davon, die Yambohne, wurde vor Jahrhunderten mit Galeonen von Mexiko über die Philippinen nach Asien transportiert und dort zu einer der Lieblingspflanzen chinesischer Gärtner. Obwohl Yambohnen in trockenem und nassem, subtropischem oder tropischem Klima gedeihen können, bevorzugen sie heißes Klima mit durchschnittlicher Niederschlagsmenge. Yambohnenpflanzen können Trockenheit tolerieren, sind aber auf Frost oder Staunässe empfindlich.

Yambohnen sind kletternde oder rankende, mehrjährige krautige Pflanze, die schnell wachsen und deren Stängel bis zu 5 Metern Länge erreichen können. Sie entwickeln viele weiße oder violette Blüten. Die Wurzeln sind zuckerrübenförmig oder länglicher und werden bis 5 kg schwer. Sie können als Samen oder Wurzelsteckling vermehrt werden.

Alle Yambohnen-Arten sind untereinander kreuzbar und bilden daher einen primären Genpool. Die Chromosomenzahl beträgt 2"n" = 22.

Von den Yambohnen ist nur das Wurzelfleisch genießbar, da in allen anderen Pflanzenteilen (außer der Blüte) mehr oder weniger des giftigen Rotenon und seiner Glykoside enthalten ist. Die Wurzelborke lässt sich leicht schälen und enthüllt das saftige, süßlich schmeckende, Kartoffeln sehr ähnliche Fleisch, das üblicherweise roh in Salaten oder leicht gekocht gegessen wird.

In der Gattung gibt es etwa fünf bis sechs Arten:





</doc>
<doc id="5745" url="https://de.wikipedia.org/wiki?curid=5745" title="Yajurveda">
Yajurveda

Der Yajurveda (Sanskrit, m., यजुर्वेद, yajurveda, yajus = „Opferspruch“) ist einer der vier Veden, der heiligen Texte des Hinduismus. Er enthält die Opferformeln oder Mantras, die der "Adhvaryu," einer der Priester im vedischen Opferritual, beherrschen muss. Zwei Fassungen des Yajurveda sind überliefert, der „weiße“ (shukla) und der „schwarze“ (kṛṣna/krishna) Yajurveda.

Jeder der vier Veden – das sind Rigveda, Sāma-Veda, Atharvaveda und Yajurveda – umfasst vier Textschichten. Die älteste Schicht sind jeweils die Samhitās (Hymnen), die nächste Schicht sind die Brāhmanas (Ritualtexte), dann kommen die Āranyakas (Waldtexte) und zuletzt die Upanishaden (philosophische Lehren).

Anders als bei den anderen drei Veden sind die zum schwarzen Yajurveda gehörenden Brāhmanas (Erläuterungen zur Opfertheologie) nicht getrennt abgefasst, sondern mit dem Text des Veda selbst verwoben. Für den schwarzen Yajurveda gibt es die folgenden jeweils zu einer Schule gehörenden Sammlungen: die "Kapishthala-Samhita," die "Kathaka-Samhita," die "Maitrayani-Samhitā" und die "Taittirīya Samhitā" (allerdings ist auch ein "Taittirīya-Brāhmana" als eigenständiger Text überliefert, das aber nicht das Brāhmana zur Samhitā ist). Beim weißen Yajurveda sind Samhitā und Brāhmana dagegen getrennt. Dabei gibt es zwei Schulen, "Kanva" und "Madhyandina," zu denen jeweils das "Shatapatha-Brāhmana" gehört.



</doc>
<doc id="5746" url="https://de.wikipedia.org/wiki?curid=5746" title="Yamswurzelgewächse">
Yamswurzelgewächse

Die Yamswurzelgewächse (Dioscoreaceae), auch Yamsgewächse, Yamswurzgewächse oder Schmerwurzgewächse genannt, sind eine Familie in der Ordnung der Yamswurzelartigen (Dioscoreales).

Zur Familie gehören drei Gattungen mit etwa 600 bis 870 Arten. Ihre Arten sind überwiegend in warmen bis tropischen Klimaten verbreitet. In Mitteleuropa ist nur eine Art der Yamswurzelgewächse heimisch, die Schmerwurz ("Dioscorea communis"). Einige Arten sind stärkeliefernde Nahrungspflanzen und von einigen Arten sind die Inhaltsstoffe für ihre medizinische Wirkung bekannt.

Diese Pflanzenarten wachsen als ausdauernde krautige Kletterpflanzen oder verholzende Lianen, selten Sträucher. Sie bilden meistens Rhizome oder Knollen als Speicherorgane.

Die Laubblätter sind selten gegenständig, meist wechselständig und spiralig an der Sprossachse verteilt angeordnet. Oft sind die Laubblätter in Blattstiel und Blattspreite gegliedert. Dies ist bei den Einkeimblättrigen Pflanzen nur selten der Fall, findet sich aber z. B. auch bei den Stechwinden. An den vielfach großen Blättern sind oft extraflorale Nektarien vorhanden. Die Blattspreiten sind einfach oder zusammengesetzt; die Blattnervatur ist bogig-palmat und der Blattrand glatt.

Die Blüten stehen in unterschiedlich aufgebauten Blütenständen zusammen. Es sind getrenntgeschlechtige, meistens zweihäusige (diözische), aber es existieren auch einhäusige (monözische) Taxa.

Die meist eingeschlechtigen, bei "Stenomeris" zwittrigen Blüten sind dreizählig und radiärsymmetrisch. Die Blütenhüllblätter sind gleichgestaltet und haben sechs Tepalen. In den Blüten sind Nektarien vorhanden. In den männlichen Blüten sind meistens zwei Kreise mit je drei Staubblättern vorhanden. Entweder sind alle Staubblätter fertil oder die eines Kreises sind zu Staminodien umgewandelt. Die drei Fruchtblätter sind zu einem unterständigen (synkarpen) Fruchtknoten verwachsen.Die Blütenformel lautet:
formula_1

Es werden unterschiedliche Früchte gebildet. Es sind meist dreikantige, lokulizide Kapselfrüchte, seltener fleischige Beeren oder einsamige Samara.

Yamswurzelgewächse enthalten Flavonole und Calciumoxalat. In Pflanzenteilen der Yamswurzelgewächse sind häufig Steroidsaponine (z. B. Diosgenin) zu finden; sie können als Ausgangsstoff zur halbsynthetischen Herstellung einiger Hormone dienen.

Viele Arten werden in den Tropen als Nutzpflanzen angebaut (Yams). Beispielsweise wird in Ostasien "Dioscorea batatas" angepflanzt. Ihre unterirdischen Knollen sind essbar und in den Tropen ein wichtiger Stärke-Lieferant.

Als „sukkulente“ Zierpflanzen werden einige Arten ("Dioscorea elephantipes" , "Dioscorea mexicana" , "Dioscorea sylvatica" , "Dioscorea macrostachya" (Syn.: "Testudinaria macrostachya" )) verwendet; sie sind allerdings nicht sukkulent, sondern besitzen interessant geformte Knollen.

Die Erstveröffentlichung des Familiennamens erfolgte 1810 durch Robert Brown in "Prodromus Florae Novae Hollandiae", 294. Die Typusgattung ist "Dioscorea" 
Lange Zeit gehörten nur die Arten, die heute in die Gattung "Dioscorea" eingeordnet sind, zu dieser Familie; die Arten einiger ehemaliger Gattungen sind seit 2000 in die "Dioscorea" eingegliedert worden. Manche Autoren gliederten auch die Arten der Gattung "Tacca", die eine eigene Familie Taccaceae darstellen, hier ein.
Die Gattungen der früher eigenständigen Familien Avetraceae , Stenomeridaceae , Tamaceae , Tamnaceae und Trichopodaceae werden jetzt der Familie der Dioscoreaceae zugeordnet.

Hier die drei Gattungen der Yamswurzelgewächse (Dioscoreaceae):



</doc>
<doc id="5748" url="https://de.wikipedia.org/wiki?curid=5748" title="Zeitdimension">
Zeitdimension

Zeitdimension steht für 



</doc>
<doc id="5750" url="https://de.wikipedia.org/wiki?curid=5750" title="Zusammenarbeit">
Zusammenarbeit

Zusammenarbeit steht für:
Siehe auch:


</doc>
<doc id="5752" url="https://de.wikipedia.org/wiki?curid=5752" title="Zeitgeschichte">
Zeitgeschichte

Die Zeitgeschichte oder zeitgenössische Geschichte (von franz. "histoire contemporaine") ist im deutschen Sprachraum jene Epoche der Späten Neuzeit, „die zumindest ein Teil der Zeitgenossen bewusst miterlebt hat, im engeren Sinn die wissenschaftliche Untersuchung und Darstellung dieses Zeitraums durch die Geschichtswissenschaft.“ 

Es handelt sich also nicht um eine abgeschlossene oder dauerhaft abgrenzbare Epoche, sondern um eine dynamische, die sich im Laufe der Zeit verändert. Der Begriff hat in Deutschland durch das 1950 gegründete Institut für Zeitgeschichte (München) Verbreitung gefunden, wobei damals auch noch die Vorgeschichte des Ersten Weltkrieges als Zeitgeschichte untersucht werden sollte.

Als Pionier- und Standardwerk der wissenschaftlichen Zeitgeschichte gilt heute die 1955 veröffentlichte Monografie über das Ghetto Theresienstadt  von H. G. Adler  "Theresienstadt 1941-1945, Das Anlitz einer Zwangsgemeinschaft".""

Im deutschen Sprachraum wurde als Zeitgeschichte zunächst die Epoche seit dem Ende des Ersten Weltkriegs bzw. seit der Oktoberrevolution in Russland ab 1917 verstanden, das Ende des langen 19. und der Beginn des „kurzen 20. Jahrhunderts“. Für eine Zäsur im Jahr 1917 sprechen mehrere Gründe:

In anderen Ländern galten andere Periodisierungen. So wurde in Großbritannien unter "contemporary history" die Zeit seit dem späten 19. Jahrhundert als Zeitgeschichte gefasst, teilweise sogar seit den politischen Reformen 1832.

Zunehmend aber wird mit Ausgang des 20. Jahrhunderts unter Zeitgeschichte die Epoche seit dem Ende des Zweiten Weltkriegs verstanden, da nur noch wenige Zeitzeugen aus der Zeit des Zweiten Weltkriegs leben. Dies gilt besonders für diejenigen, die damals bereits Erwachsene waren oder gar in verantwortlicher Stellung standen.






</doc>
<doc id="5753" url="https://de.wikipedia.org/wiki?curid=5753" title="Zeitskala">
Zeitskala

Der Begriff Zeitskala hat sowohl eine streng quantitative als auch eine eher qualitative Bedeutung. Beide Sichtweisen können die Grundlage entsprechender Zeitsysteme sein.

Im Bereich der meisten Naturwissenschaften und der Technik bedeutet „Zeitskala“ einen scharf definierten, regelmäßigen Verlauf der Zeitachse, auf welche gemessene oder berechnete Zeitpunkte bezogen werden können. Solche Skalen bilden einen genauen Maßstab der Zeitmessung und haben

Die wichtigsten Zeitskalen sind jene, die auf der Greenwich Mean Time und damit auf der Erdrotation beruhen:

Eine Zwischenfunktion hat 

Hingegen brauchen Astronomie, Himmelsmechanik und Raumfahrt den strengen Bezug zur Bahnbewegung der Erde um die Sonne, weshalb um 1960 

Im Gegensatz zu Zeitskalen dieses strengen Sinns stehen relative Zeitmessungen – z. B. mit einer Stoppuhr – wo der Nullpunkt wegen der bloßen Messung einer Zeit"differenz" beliebig sein kann. Im Alltag überwiegt diese Bedeutung des Wortes „Zeit“ und kann daher dem jeweiligen Zweck gut angepasst werden.

Qualitative Zeitskalen sind hingegen dann vorzuziehen, wenn der genaue „Maßstab“ weniger wichtig ist als die Aufeinanderfolge der betrachteten Phänomene. Solche Zeitskalen listen Ereignisse oder Abschnitte, die zu einem bestimmten Zeitpunkt stattgefunden haben, in ihrer Reihenfolge auf. Doch die genaue Zeitdauer zwischen ihnen ist weniger wichtig als die gegenseitige Zuordnung verschiedener Ereignisreihen.

„Zeit“ wird hier als eine Art Distanz zwischen zwei oder mehr Ereignissen verstanden, die "Zeitskala" ist eine systematische Folge dieser Ereignisse und sichert ihren Zusammenhang. Je nach Zweck einer "Zeitskala" bedient sie sich einer geeigneten Zeiteinheit (Sekunde, Tag, Jahr usw). So würde zum Beispiel eine Darstellung von Erdzeitaltern in der Maßeinheit Sekunde dem Zweck der Veranschaulichung nicht dienlich sein, meist wählen die Geologen hier sogar als Einheit die Jahrmillion.

In der Geschichtswissenschaft kann manchmal ohne strenges Zeitmaß gearbeitet werden, wenn z. B. statt der Jahre die Aufeinanderfolge von Dynastien den Zeitrahmen bestimmt.



</doc>
<doc id="5755" url="https://de.wikipedia.org/wiki?curid=5755" title="Zeichentrickfilm">
Zeichentrickfilm

Ein Zeichentrickfilm ist eine Spezialform der Animation und besteht aus vielen, meist per Hand hergestellten Zeichnungen, die zeitlich nacheinander präsentiert werden. Durch geringfügige Änderung des Inhalts, von Bild zu Bild, entsteht beim Betrachter der Eindruck, dass es sich um ein Bewegtbild handelt. Die technisch einfachste Art eines Zeichentrickfilms ist ein Daumenkino.

Die ersten gezeichneten Filme schuf der Franzose Émile Reynaud, mit Hilfe des von ihm entwickelten Praxinoskops. Um 1877 stellte er mit diesem Verfahren, das als Vorläufer der Kinematographie galt, seine ersten animierten Bilder vor. 1906 gilt als das Geburtsjahr des Zeichentrickfilms, als der US-Amerikaner J. Stuart Blackton mit "Humorous Phases of Funny Faces" seinen ersten vollständig animierten Film präsentierte. Zwei Jahre später veröffentlichte der Franzose Émile Cohl seine ersten Zeichentrickfilme, die er direkt auf Filmstreifen zeichnete.

Besonders populär wurden die Filme des Karikaturisten Winsor McCay, der 1911 seine Comicreihe Little Nemo in einem Kurzfilm umsetzte und 1914 mit Gertie the Dinosaur die erste populäre Zeichentrickfigur schuf. Infolgedessen entstanden Anfang der 1920er Jahre viele Studios, deren bekannteste die von Max Fleischer ("Koko der Clown", "Betty Boop", "Popeye"), Pat Sullivan ("Felix the Cat"), Bud Fisher ("Mutt and Jeff") und Walt Disney ("Micky Maus)" waren. In diesen Studios wurde das arbeitsteilige System von Spezialisten entwickelt, welches bis heute besteht, und den bis dahin allein arbeitenden Animator ablöste.

Der erste Zeichentrickfilm in Spielfilmlänge war der argentinische Film „El Apóstol“ aus dem Jahr 1917, jedoch wurden bei einem Brand im Jahr 1926 sämtliche Kopien des Films zerstört. In Europa wurde mit dem schwedischen „Kapitän Grogg“ eines der frühen Werke des Zeichentrickfilms geschaffen. In Deutschland wirkten Rudolf Leonard, Otto Dely sowie Lotte Reiniger, die mit ihren Scherenschnittfilmen große Popularität erlangten. In Österreich waren Ladislaus Tuszyński und Peter Eng die ersten Trickfilmzeichner.

In den Anfängen wurden die Zeichnungen noch direkt auf den Film gezeichnet. Kurze Zeit später wurde dieser Prozess durch ein leicht verbessertes Verfahren abgelöst, bei dem die Papierblätter mit den Zeichnungen direkt unter die Kamera gelegt und aufgenommen wurden. Etwa ab 1920 wurden die Zeichnungen auf Folien („Cels“) übertragen, welche es ermöglichten, die Animation mit aufwendigen Hintergründen zu kombinieren. 1928 kam der Ton hinzu, ab 1930 die Farbe (in dem Revuefilm King of Jazz mit dem Orchester Paul Whiteman). 1933 entwickelte der Erfinder und Zeichner Ub Iwerks, der bis 1930 für Disney gearbeitet hatte, die Multiplan-Kamera, mit der flache Hintergrundelemente auf verschiedenen Ebenen unabhängig voneinander bewegt werden konnten, und so einen räumlicheren Eindruck erzeugten. In den 1950er Jahren adaptierte Iwerks das Xerox-Kopiersystem, welches die Zeichnungen direkt auf Folie kopierte. Die glatten per Hand „geinkten“ Umrisslinien wurden von einem viel raueren Bleistiftstrich abgelöst. Stephen Bosustov entwickelte bei UPA einen neuen, grafisch orientierten Stil mit weniger Details, der besser für das neue Medium Fernsehen geeignet war. In der Folge entwickelten er und andere Studios die „Limited Animation“. Um nicht ständig komplette Figuren neu zeichnen zu müssen, wurde eine Figur so auf mehrere Ebenen verteilt, dass nur noch die sich tatsächlich bewegenden Teile neu gezeichnet werden mussten. Diese von Kritikern beklagte Entwicklung war vor allem dem geringen Budget des Fernsehens geschuldet.

Der Computer zog relativ spät in die Zeichentrickwelt ein. Zuerst in den Kameraraum, wo ungefähr ab 1970 Kamerafahrten vom Rechner kalkuliert und ausgeführt wurden. In den 1990er Jahren ersetzte das Einscannen das frühere Kopieren der Zeichnungen; nachfolgende Arbeitsschritte wie Kolorieren und Kamera fanden jetzt im Computer statt. Heutige Produktionssysteme in großen Studios automatisieren möglichst viele Arbeitsgänge, aber immer noch ist ein Zeichentrickfilm vor allem eine handwerkliche Arbeit, die entweder mit Bleistift und Papier oder auf einem Grafiktablett ausgeübt wird. An einem abendfüllenden Zeichentrickfilm arbeiten etwa 20 bis 400 Menschen und es werden mehrere zehntausend Zeichnungen angefertigt.

Neuere Entwicklungen integrieren häufig auch dreidimensional am Computer erstellte Objekte, die hauptsächlich für Fahrzeuge oder sich bei Kameraschwenks bewegende Objekte eingesetzt werden. Aber auch bei Charakteren werden teilweise Computeranimationen eingesetzt, die beispielsweise realistisch fallendes Haar ermöglichen, sich aber in die klassisch erstellten Zeichnungen integrieren.

Der klassische Arbeitsablauf großer Studios beginnt mit einem Drehbuch und dem Entwurf der handelnden Figuren. Das Drehbuch ist Grundlage für das Storyboard, in dem für jede Einstellung mindestens eine Zeichnung steht, aus der Kameraeinstellung, Bewegung der Figuren und Art des Hintergrundes erkennbar sind. Nach dem Storyboard werden Layouts gezeichnet, und zwar in der Größe, in der sowohl Animatoren wie Hintergrundkünstler arbeiten. Für jede Figur existiert ein Model Sheet einschließlich einer Figurine, die die verbindlichen Vorlagen für alle Zeichner darstellen.

Üblicherweise werden, wenn das Drehbuch komplett ist, die Dialoge der Figuren aufgenommen. Ein "Trackreader" (heutzutage oft eine Software) überträgt sie Laut für Laut in die X-Sheets („exposure sheets, auch dope sheet“). Das X-Sheet ist ein einzelbildgenaues Drehbuch für jede einzelne Einstellung (die im Animationsbereich „Szene“ genannt wird), das für den Animator und den Kameramann verbindlich ist. Pro Einzelbild enthält es eine Zeile, in der eingetragen wird, welcher Laut gerade zu hören ist und welche Zeichnungen unter die Kamera gelegt werden sollen. Außerdem werden sämtliche Kamerabewegungen festgehalten.
Der Animator erhält das Storyboard, die nötigen Modelsheets, eine Kopie des Layouts und das X-Sheet. Er entwirft nun mit einigen skizzenhaften Zeichnungen das Gerüst der Animation, die Schlüsselbilder (engl. "Keyframes") oder Hauptphasen. Das sind jene Zeichnungen, die die Bewegung definieren. Um seine Arbeit zu überprüfen, nimmt er sie mit dem "linetester" auf, einer Software, die per Videokamera aufgenommene Zeichnungen auf einem Rechner abspielt. Dabei kann er jede Zeichnung so lange in der Zeit verschieben, bis das Timing passt. Sind der Animator und der Regisseur mit der Szene zufrieden, geht die „rough animation“ zum Assistenten des Animators. Der zeichnet die „cleanups“, also Reinzeichnungen der Schlüsselbilder, getreu nach den Vorgaben des Modelsheets, und fügt evtl. „breakdowns“ hinzu. Das sind Zeichnungen zwischen den Schlüsselbildern, die die Bewegung noch genauer definieren. Der wachsende Stapel Papier gelangt nun zum Inbetweener oder Zwischenphasenzeichner, der die immer noch fehlenden Zeichnungen zwischen die bereits existierenden einfügt.

Für normale Bewegungen genügen 12 Zeichnungen pro Sekunde Film. Bei extrem schnellen Bewegungen oder Bewegungen quer durchs Bild braucht es bis zu 24 Zeichnungen, damit die Abstände zwischen den Positionen nicht so groß werden und die Bewegungsillusion nicht zerstört wird. Bei Studios wie Disney liegt der Durchschnitt bei etwa 18 Zeichnungen pro Sekunde. TV-Serien kommen stellenweise mit 6 Zeichnungen pro Sekunde aus. Im Laufe der Jahre wurden viele Techniken entwickelt, um Zeichnungen zu sparen, und die Bewegungsillusion statt durch Anfertigung vieler Zeichnungen durch die Wahl der Bildausschnitte, Schnitte oder Kamerafahrten über Standbilder zu erzeugen.

Des Weiteren ist es üblich, die Zeichnungen in verschiedene Ebenen aufzuteilen: In Dialogszenen wird zum Beispiel nur die Mundbewegung animiert, der Körper jedoch nur wenig. Auch werden oft Zeichnungen wiederverwendet. In einer Dialogszene wird zum Beispiel der Körper in einer Schleife animiert, um eine natürliche Bewegung zu simulieren. Dieses Aufteilen in Ebenen wird normalerweise durch den Keyanimator vorgenommen. Daher hat das X-Sheet zwar eine Zeile pro Belichtung, aber mehrere Spalten für die verschiedenen Ebenen.

Sind sämtliche Zeichnungen vorhanden und ist die Szene mehrfach getestet und abgenommen, kann sie koloriert werden. Früher wurden sämtliche Zeichnungen auf Folie übertragen oder kopiert und diese dann per Hand auf der Rückseite ausgemalt. Heutzutage findet das Kolorieren immer mehr im Computer statt. Der Colorist arbeitet am Bildschirm an den eingescannten Zeichnungen. Animationssoftware kann dabei viel automatisieren, per Hand wird beispielsweise nur noch das erste Bild einer Szene koloriert, dann koloriert der Computer alle weiteren Phasen, und schließlich werden nur noch eventuelle Fehler per Hand korrigiert. 

In der Zwischenzeit werden die Hintergründe gemalt. Früher trafen sich die Hintergründe mit den bemalten Folien unter der Kamera wieder, heute werden auch sie eingescannt oder sogar ganz am Computer gemalt. Das Zusammenstellen (Compositing) der verschiedenen Teile der Animation über dem Hintergrund bietet Gelegenheit, noch Spezialeffekte einzufügen. Sind alle Einzelteile eingefügt, wird die Szene gerendert und entweder digital gespeichert oder auf Film ausbelichtet.

Für sich wiederholende Bewegungen oder Abläufe werden Endlosschleifen oder Animationszyklen erstellt. Beispiele hierfür sind Fließbewegungen in Gewässern, laufende oder fliegende Tiere oder sich bewegende Fahrzeuge, die vor einen sich ändernden Hintergrund gelegt werden. Im Falle einer schreitenden Vorwärtsbewegung wird die Figur animiert, einen Schritt mit dem einen Fuß, dann einen Schritt mit dem anderen Fuß zu machen und dieses dann in einen Loopzyklus gesetzt, so dass die Bewegungen sich nahtlos aneinanderreihen.

Die Produktion von abendfüllenden Zeichentrickfilmen fürs Kino ist seit 2004 leicht zurückgegangen. Der Erfolg von Pixar und anderen Produzenten von CGI-Animationsfilmen bewog das Management der Walt Disney Company, keine klassischen Zeichentrickfilme mehr zu produzieren. "Die Kühe sind los" (2004) sollte der vorläufig letzte Kino-Zeichentrickfilm der Disney-Studios sein. Mit "Küss den Frosch" kehrte Disney 2009 jedoch zum klassischen Zeichentrickfilm zurück. Auch andere Studios sind von der Umorientierung ihrer Geldgeber weg vom 2-D, hin zum 3-D-Film betroffen, obwohl der wirtschaftliche Erfolg Pixars eher in seiner inhaltlichen und künstlerischen Virtuosität begründet liegt. Nachdem Disney Pixar für 7,4 Milliarden US-Dollar übernommen hat, entschied John Lasseter als neuer künstlerischer Leiter Disneys, diese Managemententscheidung rückgängig zu machen.

Weltweit werden weiterhin lange Zeichentrickfilme, vor allem aber Fernsehserien produziert. Disney selbst betreibt Studios in Japan und Australien, die in klassischer Technik hauptsächlich für den wachsenden Home-Video-Markt arbeiten. In Japan (Studio Ghibli), Korea (SEK Trickfilmstudios in Nordkorea), Taiwan und China wächst die Trickfilmindustrie, die entweder als Zulieferer für europäische und amerikanische Firmen arbeitet oder mit Produktionen in Eigenregie vor allem den heimischen Markt beliefert. Herausragende künstlerische Persönlichkeiten wie Hayao Miyazaki verweigern sich grundsätzlich dem 3-D-Boom: „Wir benutzen die Technik, die grafisch am besten aussieht. Und Handzeichnungen sind dazu immer noch die geeignetste Methode.“

In Europa werden dank des Cartoon-Programms der EU in den letzten Jahren verstärkt abendfüllende Zeichentrickfilme hergestellt, die meisten davon für Kinder. Durch die Fortschritte der computergestützten Produktion verschwimmen die Grenzen zwischen 2D und 3D zusehends, entscheidend für die Wahl eines Produktionsdesigns sind nicht mehr so sehr die Kosten, sondern hauptsächlich künstlerische und Marketing-Gründe.





</doc>
<doc id="5756" url="https://de.wikipedia.org/wiki?curid=5756" title="Zirconium">
Zirconium

Zirconium, häufig auch Zirkonium, ist ein chemisches Element mit dem Elementsymbol Zr und der Ordnungszahl 40. Sein Name leitet sich vom Zirkon, dem häufigsten Zirconium-Mineral, ab. Im Periodensystem steht es in der 5. Periode; es ist das zweite Element der 4. Gruppe (veraltet 4. Nebengruppe) oder Titangruppe. Zirconium ist ein sehr korrosionsbeständiges Schwermetall. Biologische Funktionen sind nicht bekannt; es kommt in geringen Mengen (4 mg/kg) im menschlichen Organismus vor und ist nicht toxisch.

Das wichtige zirconiumhaltige Mineral Zirkon (Zr[SiO]) ist als Schmuckstein bereits seit der Antike bekannt. Zirconium als Element wurde 1789 von Martin Heinrich Klaproth in einer aus Ceylon stammenden Probe des Minerals Zirkon entdeckt und nach diesem benannt. Erstmals dargestellt wurde das Metall 1824 von Jöns Jakob Berzelius durch Reduktion von KZrF mit Kalium. Dazu erhitzte er "„ein Gemenge aus flusssaurem Zirkon-Kali mit Kalium in einer eisernen Röhre“". Nach Behandlung mit Wasser, Trocknen und längerem Erhitzen mit verdünnter Salzsäure erhielt Berzelius ein "„klumpiges Pulver, welches wie Kohle schwarz“" war und erst "„durch Zusammendrücken mit dem Polierstahl eine dunkelgraue Farbe und Glanz“" erhielt. Die korrekte Atommasse konnte dagegen erst 1924 bestimmt werden, da – neben Fehlern bei der Durchführung der Experimente - nicht bekannt war, dass Zirconium stets geringe Mengen Hafnium enthält. Ohne diese Information ergaben Messungen immer eine etwas zu hohe Atommasse. Die erste praktische Anwendung von Zirconium war der Einsatz als "rauchloses Blitzlichtpulver".

Zirconium kommt in der Erdkruste mit einem Gehalt von ca. 0,016 % vor. In der nach Häufigkeit geordneten Liste der Elemente steht Zirconium an 18. Stelle und ist häufiger als die bekannteren Elemente Chlor und Kupfer. Es ist zwar sehr weit verbreitet, findet sich aber meist nur in sehr geringen Mengen und in sehr kleinen Kristallen (typischerweise um 0,1 mm). Darum wurde Zirconium in früherer Zeit als selten angesehen. Zirconium wird vor allem in silikatischen Intrusivgesteinen wie Granit gefunden. Es kommt nicht gediegen, sondern nur in einigen Mineralen, vor allem als Zirkon (ZrSiO) und Baddeleyit (ZrO) sowie dem selteneren roten Eudialyt (Na(CaCeFeMn)ZrSiO(OHCl)) gebunden vor. Es ist fast immer mit Hafnium vergesellschaftet. Zirkon ist wegen seines hohen Schmelzpunktes von 2550 °C, seiner großen Härte und geringen Reaktivität das älteste auf der Erde auffindbare Mineral und kann auf Grund eingelagerter Uran- und Thoriumisotope für radiometrische Altersbestimmungen verwendet werden.

Als Rohstoffe dienen meist sekundäre Lagerstätten, so genannte Seifenlagerstätten. Diese entstehen, wenn das umliegende Gestein verwittert und nur der besonders verwitterungsresistente Zirkon zurückbleibt. Weitere solche Lagerstätten können durch Wasserströmungen entstehen, die Zirkonkristalle ausspülen und an anderen Stellen anspülen. Primäre Lagerstätten haben dagegen meist einen für den rentablen Abbau zu geringen Zirconium-Gehalt.

Die wichtigsten Zirconium-Lagerstätten liegen in Australien, den USA und Brasilien. Bei abbauwürdigen Reserven von 38 Millionen Tonnen lag die Weltjahresförderung von Zirconiummineralen 2006 bei 920.000 Tonnen (gerechnet als Zirkon). Davon werden nur etwa 5 % zu Metall und Legierungen weiterverarbeitet. Die wichtigsten Förderländer waren 2006 mit großem Abstand Australien und Südafrika. Laut USGS lag die Weltjahresförderung an Zirconiummineralen 2013 bei 1,5 Mio. t, davon 850.000 t in Australien. Weitere wichtige Förderländer waren Südafrika (170.000 t) und China (150.000 t). Die Preise für Zirkon lagen 2012 bei 2.650 USD je Tonne und 2013 bei 1.050 USD je Tonne.

Zirkon als häufigster Zirconium-Rohstoff muss vor der Weiterverarbeitung erst in Zirconiumdioxid umgewandelt werden. Dazu wird der Zirkon in einer Natriumhydroxid-Schmelze gekocht (alkalischer Aufschluss). Das Zirconiumdioxid wird danach mit Koks im Lichtbogen zu Zirconiumkarbonitrid (Kohlenstoff- und stickstoffhaltiges Zirconium) und anschließend mit Chlor zu Zirconiumtetrachlorid umgesetzt.

Eine direkte Reduktion von Zirconiumdioxid mit Kohlenstoff (wie im Hochofenprozess) ist nicht möglich, da die hierbei entstehenden Carbide sehr schwer vom Metall zu trennen sind. Stattdessen wird Zirconiumtetrachlorid im so genannten Kroll-Prozess mit Magnesium in einer Helium-Atmosphäre zu Zirconiummetall reduziert.

Um reineres Zirconium gewinnen zu können, wird das Van-Arkel-de-Boer-Verfahren angewendet. Dabei reagiert während des Erhitzens unter Vakuum zunächst das Zirconium mit Iod zu Zirconium(IV)-iodid. Dieses wird an einem heißen Draht wieder zu Zirconium und Iod zersetzt:

Zirconiumtetraiodid bildet sich bei 200 °C aus Zirconium und Iod; es zerfällt wieder bei 1300 °C.

Zirconium und Hafnium sind auf einfache chemische Art nicht zu trennen. Deshalb enthält auch dieses hochreine Zirconium noch immer Hafnium. Da es für viele Anwendungen in der Reaktor-Technik wichtig ist, dass das Zirconium kein Hafnium mehr enthält, spielen Trennverfahren für diese beiden Metalle eine wichtige Rolle. Eine Möglichkeit sind Extraktionsverfahren, in denen die unterschiedliche Löslichkeit von Zirconium- und Hafniumverbindungen in speziellen Lösungsmitteln ausgenutzt wird. Häufig werden die Thiocyanate und ihre unterschiedliche Löslichkeit in Methylisobutylketon ausgenutzt. Weitere Möglichkeiten bieten Ionenaustauscher oder die fraktionierte Destillation von geeigneten Verbindungen.

Der USGS gibt als US-Importpreise für Zirconium 75 USD je kg im Jahre 2013 an.

Zirconium ist ein silbrig-glänzendes Schwermetall (Dichte 6,501 g/cm bei 25 °C), es ähnelt äußerlich Stahl. Das Metall kristallisiert in zwei unterschiedlichen Modifikationen, in die es durch Temperaturänderung überführt werden kann. Unterhalb von 870 °C kristallisiert α-Zirconium im hexagonalen Kristallsystem (hexagonal-dichteste Kugelpackung, Magnesium-Typ) in der mit den Gitterparametern a = 323 pm und c = 514 pm sowie zwei Formeleinheiten pro Elementarzelle. Bei 870 °C ändert sich die Kristallstruktur zur kubisch-innenzentrierten β-Struktur (Wolfram-Typ) mit der Raumgruppe  und dem Gitterparameter a = 361 pm.

Zirconium ist relativ weich und biegsam. Es lässt sich gut durch Walzen, Schmieden und Hämmern verarbeiten. Durch geringe Verunreinigungen von Wasserstoff, Kohlenstoff oder Stickstoff im Metall wird es aber spröde und schwer zu verarbeiten. Die elektrische Leitfähigkeit ist nicht so hoch wie die anderer Metalle. Sie beträgt nur etwa 4 % von der des Kupfers. Bezogen auf seine schlechte elektrische Leitfähigkeit ist Zirkonium ein relativ guter Wärmeleiter. Im Vergleich zum leichteren Homologen Titan sind Schmelz- und Siedepunkt etwas höher (Schmelzpunkt: Titan: 1667 °C, Zirconium: 1857 °C). Auch die elektrische und Wärmeleitfähigkeit sind besser. Unterhalb von 0,55 K wird Zirconium supraleitend.

Die Eigenschaften des Zirconiums und des schwereren Homologen Hafnium ähneln sich auf Grund der Lanthanoidenkontraktion sehr. Diese bedingt ähnliche Atomradien (Zr: 159 pm, Hf: 156 pm) und damit ähnliche Eigenschaften. Die beiden Metalle unterscheiden sich allerdings erheblich in ihrer Dichte (Zr: 6,5 g/cm, Hf: 13,3 g/cm).

Eine wichtige Eigenschaft, wegen der Zirconium eine große Bedeutung im Reaktorbau erlangt hat, ist sein geringer Einfangquerschnitt für Neutronen. In dieser Eigenschaft unterscheidet sich Zirconium ebenfalls sehr vom Hafnium. Dies macht die aufwändigen Trennverfahren für diese Anwendungen nötig.

Zirconium ist ein unedles Metall, welches besonders unter hoher Temperatur mit vielen Nichtmetallen reagiert. Vor allem als Pulver verbrennt es mit weißer Flamme zu Zirconiumdioxid, bei Anwesenheit von Stickstoff auch zu Zirconiumnitrid und Zirconiumoxinitrid. Kompaktes Metall reagiert erst bei Weißglut mit Sauerstoff und Stickstoff. Bei erhöhtem Druck reagiert Zirconium auch bei Raumtemperatur mit Sauerstoff, da das gebildete Zirconiumoxid im geschmolzenen Metall löslich ist.

Zirconium ist an der Luft durch eine dünne, sehr dichte Zirconiumoxidschicht passiviert und deshalb reaktionsträge. Es ist darum in fast allen Säuren unlöslich, lediglich Königswasser und Flusssäure greifen Zirconium schon bei Raumtemperatur an. Wässrige Basen reagieren nicht mit Zirconium.

Vom Zirconium sind viele Isotope zwischen Zr und Zr bekannt. Dabei ist natürliches Zirconium ein Mischelement, das aus insgesamt fünf Isotopen besteht. Dies sind Zr, das mit einem Anteil von 51,45 % des natürlichen Zirconiums am häufigsten vorkommt, sowie die schwereren Isotope Zr (11,32 %), Zr (17,19 %), Zr (17,28 %) und Zr mit 2,76 % Anteil. Zr ist als einziges natürliches Isotop schwach radioaktiv, es zerfällt mit einer Halbwertszeit von 24 · 10 Jahren unter doppeltem Betazerfall zu Mo. Das Isotop Zr kann mit Hilfe der NMR-Spektroskopie nachgewiesen werden.

"→ Liste der Zirconium-Isotope"

Eine wichtige Verwendung für Zirconium sind die aus Zircaloy hergestellten Hüllen der Uran-Brennelemente in Kernkraftwerken. Diese Legierung besteht aus ca. 90 % Zirconium und geringen Anteilen an Zinn, Eisen, Chrom oder Nickel, darf jedoch kein Hafnium enthalten. Der Grund für die Wahl dieses Elements ist der schon oben beschriebene geringe Einfangquerschnitt für thermische Neutronen bei gleichzeitig großer Korrosionsbeständigkeit, die es auch als Baumaterial für chemische Anlagen, vor allem für spezielle Apparateteile wie Ventile, Pumpen, Rohre und Wärmeaustauscher geeignet macht. Als Legierungszusatz zu Stahl erhöht es ebenfalls die Korrosionsbeständigkeit. Aus entsprechenden Legierungen werden unter anderem chirurgische Instrumente hergestellt.

Da Zirconium mit geringen Mengen Sauerstoff und Stickstoff reagiert, kann es als Gettermaterial in Glühlampen und Vakuumanlagen zur Aufrechterhaltung des Vakuums genutzt werden. Diese Eigenschaft wird auch in der Metallurgie ausgenutzt, um Sauerstoff, Stickstoff und Schwefel aus Stahl zu entfernen.

Wegen seiner Eigenschaft, beim Verbrennen ein sehr helles Licht auszusenden, wurde es neben Magnesium als Blitzlichtpulver verwendet. Im Gegensatz zu Magnesium hat Zirconium den Vorteil, rauchfrei zu sein. Diese Eigenschaft wird ebenso in Feuerwerkskörpern und Signallichtern ausgenutzt.

Zirconium sendet beim Aufprall auf Metalloberflächen einen Funkenschwall ab und ist brennbar. Dieses nutzt das Militär in einigen Munitionssorten wie der Schrotflinten-Spezialmunition Dragon's Breath und der US-amerikanischen Allzweck-Streumunition BLU-97 aus. In der Filmtechnik wird dieser Effekt für nicht-pyrotechnische Aufpralleffekte von beispielsweise Gewehrkugeln auf Metalloberflächen benutzt.

Zirconium-Niob-Legierungen sind supraleitend und bleiben dies auch, wenn starke Magnetfelder angelegt werden. Sie wurden daher früher für supraleitende Magnete verwendet.

Es sind keine toxischen Effekte von Zirconium und seinen Verbindungen bekannt. Wegen der dichten Oxidschicht ist kompaktes Zirconium nicht brennbar. In Pulverform kann es dagegen beim Erhitzen an der Luft anfangen zu brennen. Zirconiumbrände sind sehr gefährlich, da zum Löschen weder Wasser (heftige Reaktion unter Wasserstoffbildung), noch Kohlenstoffdioxid oder Halon verwendet werden können. Zirconiumbrände müssen mit Metallbrandlöschern (Klasse D) oder trockenem Sand gelöscht werden.

Mit Alizarinrot-S bildet Zirconium im Sauren eine charakteristische rot-violette Verbindung (Farblack), welche bei Zugabe von Fluoridionen unter Bildung des Zirconium-Fluorokomplexes wieder verschwindet. Diese Reaktion kann als qualitativer Nachweis sowohl von Zirconium als auch von Fluor dienen. Da schon geringe Mengen Fluorid (und anderer Anionen) stören, ist dieser Nachweis für Mineralanalysen ungeeignet. Daneben sind einige andere organische Verbindungen, wie Tannin, Kupferron, Phenylarsonsäure, Oxin oder Xylenolorange, als Nachweisreagenz geeignet. Eine weitere charakteristische Verbindung ist Zirconiumoxidchlorid ZrOCl · 8 HO, die in typischen Nadeln kristallisiert. In der modernen Analytik kann Zirconium über Atomabsorptionsspektrometrie (AAS) oder Massenspektrometrie (auch anhand des Isotopenmusters) nachgewiesen werden.Eine Möglichkeit zur quantitativen Analyse ist die Fällung von schwerlöslichem Zirconiumhydroxid mit Ammoniak und anschließendem Verglühen zu Zirconiumdioxid.

Zirconium bildet als unedles Metall eine Vielzahl von Verbindungen. Die meisten Zirconiumverbindungen sind Salze. Häufig sind sie sehr stabil und besitzen einen hohen Schmelzpunkt. Die Oxidationsstufe +IV ist bevorzugt und am stabilsten. Es sind aber auch Verbindungen in den Oxidationsstufen +III bis +I, bei Komplexen sogar in den Stufen 0, −I und −II bekannt.

Die wichtigste Zirconiumverbindung ist Zirconiumdioxid ZrO, ein sehr stabiles und hochschmelzendes Oxid. Zirconiumdioxid dient zur Herstellung feuerfester Auskleidungen in Tiegeln und Öfen. Um es hierfür zu verwenden, muss es aber zur Stabilisierung der kubischen Hochtemperaturphase mit Calcium, Yttriumoxid oder Magnesiumoxid stabilisiert werden. Zirkoniumdioxid-verstärktes Aluminiumoxid ("ZTA", "Zirconia Toughened Aluminum Oxide") wird als Technische Keramik für hohe Temperaturen eingesetzt.

Zirconiumdioxid-Kristalle sind farblos und besitzen einen hohen Brechungsindex. Darum dienen sie unter dem Namen Zirkonia als künstlicher Schmuckstein und Ersatz für Diamanten. Daneben wird Zirconiumdioxid als Schleifmittel und wegen der weißen Farbe als Weißpigment für Porzellan genutzt.

Wird Zirconiumoxid mit Yttriumoxid dotiert, ergeben sich weitere Anwendungsmöglichkeiten. Bei drei Prozent Yttriumoxid-Gehalt wird das ZrO in einer verzerrten Fluorit-Struktur stabilisiert. Dadurch wirkt es bei Temperaturen von über 300 °C als Leiter für Sauerstoff-Ionen. Eine wichtige Anwendung hierfür ist die Lambdasonde in Autos, die zum Messen des Sauerstoffgehaltes in Abgasen für den Katalysator dient. Bei 15 % Yttriumoxidgehalt sendet Zirconiumoxid bei 1000 °C ein sehr helles, weißes Licht aus. Dieses findet in der so genannten Nernst-Lampe Anwendung. Da Yttrium-Zirconium-Keramiken eine extrem hohe Bruchzähigkeit besitzen, werden sie beispielsweise in der Zahntechnik als hochstabiles Kronen- und Brückengerüst, in künstlichen Hüftgelenken und Zahnimplantaten oder als Verbindungselement bei Teleskopen verwendet. Dabei lösen sie zunehmend Gold und andere Metalle in der Funktion ab.

Zirconiumoxid wird zudem oft für Kugellager verwendet. Vor allem für die Laufringe der Lager hat ZrO den großen Vorteil, dass der Wärmeausdehnungskoeffizient nahe dem von Stahl ist. Andere technische Keramiken wie Siliciumnitrid haben üblicherweise einen erheblich geringeren Wärmeausdehnungskoeffizienten.

Mit den Halogenen Fluor, Chlor, Brom und Iod bildet Zirconium mehrere Reihen von Verbindungen. Es sind von allen Halogenen Verbindungen der Formen ZrX, ZrX und ZrX bekannt. Dazu kommen noch die Chloride, Bromide und Iodide der Form ZrX. Am stabilsten sind dabei die Tetrahalogenide der Form ZrX. Von keinem der Zirconiumhalogenide sind wichtige Anwendungsbereiche bekannt, wobei Zirconiumchloride als Zwischenprodukte bei der Herstellung von reinem Zirconium entstehen.

Zirconiumsilicat, ZrSiO, besser bekannt unter dem Mineralnamen Zirkon, ist die in der Natur häufigste Zirconium-Verbindung. Es stellt die wichtigste Quelle für Zirconium und seine Verbindungen dar. Daneben wird Zirkon als Schmuckstein verwendet.

Organische Zirconiumverbindungen sind meist instabil. Von Bedeutung sind vor allem organische Zirconiumkomplexe, sog. "Zirconocene", mit Resten wie Cyclopentadienyl. Sie sind technisch wichtig als Katalysator bei der Polymerisation von Alkenen, insbesondere für die Herstellung von Polypropylen.
Eine weitere Anwendung einer organischen Zirconium-Verbindung besteht in der "Hydrozirconierung". Dabei werden Alkene mit Hilfe des Schwartz-Reagenzes CpZrHCl (Cp = Cyclopentadienyl) in Alkohole oder Halogenkohlenwasserstoffe überführt. Bei der Reaktion von terminalen Alkinen mit dem Schwartz-Reagenz entstehen bei der Hydrozirconierung trisubstituierte Doppelbindungen, die weitere Umsetzung mit einem elektrophilen Reagenz führt zu trans-funktionalisierten Alkenen in hoher stereochemischer Reinheit.

Aluminium–Zirconium-Komplexe können als Antitranspirant verwendet werden. Kaliumhexafluoridozirconat(IV) KZrF (CAS-Nummer: 16923-95-8) kann zur Trennung von Zirconium von Hafnium eingesetzt werden.

Zirconiumcarbonat liegt als basischer Komplex vor. Es wird unter anderem in der Papierindustrie verwendet.

Zirkoniumsalze werden – neben aluminiumhaltigen Alaunen – bei der „Weißgerbung“ von Fellen eingesetzt.

Blei-Zirkonat-Titanat-Keramiken (PZT-Keramiken) werden für Piezoelemente verwendet.




</doc>
<doc id="5758" url="https://de.wikipedia.org/wiki?curid=5758" title="Zinn">
Zinn

Zinn ist ein chemisches Element mit dem Elementsymbol Sn () und der Ordnungszahl 50. Im Periodensystem steht es in der 5. Periode und in der 4. Hauptgruppe, bzw. 14. IUPAC-Gruppe oder Kohlenstoffgruppe. Das silberweiß glänzende und sehr weiche Schwermetall lässt sich mit dem Fingernagel ritzen. Zinn hat einen für Metalle sehr niedrigen Schmelzpunkt. Seine Hauptverwendung lag früher im Bereich der Herstellung von Geschirr, das von Zinngießern innerhalb der städtischen Handwerkszünfte bis ins 19. Jahrhundert als weit verbreitete Gebrauchs- und Ziergegenstände, als Bestandteile der bürgerlichen Haushalte, hergestellt wurden. Moderne Nutzung ist im Bereich von Elektrolöten sowie im Verzinnen von lebensmittelechten Konserven oder auch in der Medizin. Historisch hat der Mensch Zinn zuerst als Beimengung zum Kupfer als Legierungsmittel zur Herstellung der Bronze genutzt.

Das Wort "Zinn" (ahd., mhd. "zin") ist vielleicht verwandt mit ahd. "zein" „Stab“, „Stäbchen“, „Zweig“ (siehe Zain). Der Duden weist in diesem Zusammenhang darauf hin, dass das Metall früher in Stabform gegossen wurde. Eine andere Erklärung geht davon aus, dass das Hauptzinnerz Kassiterit (Zinnstein) auch in Form von Nadeln oder „Stäbchen“ auftritt.

Die metallurgische Verarbeitung von Zinn begann etwas später als die von Kupfer. Während die Erschmelzung von Kupfer für die Vinča-Kultur auf 5400–4800 v. Chr. auf dem Balkan datiert wurde, ist diese für den Vorderen Orient auf dem Gebiet des heutigen Iran und der Türkei zwischen 5200 und 5000 v. Chr. erfolgt. Die älteste datierte Legierung von Zinnbronze aus dem Zinnmineral Stannit wurde in der Ausgrabungsstätte Pločnik auf dem Gebiet des heutigen Serbien auf ca. 4650 v. Chr. datiert.
Im südtürkischen Taurusgebirge, wo auch Zinnerz abgebaut worden sein könnte, wurden das Bergwerk Kestel und die Verarbeitungsstätte Göltepe entdeckt und auf etwa 3000 v. Chr. datiert. Ob es sich hier um die Quelle des großen vorderasiatischen Zinnverbrauches handelte, bleibt vorläufig offen. Zinnbronzen, Gold und Kupfer wurden zuerst nur wegen ihrer Farbigkeit als Schmuck verwendet. Die ersten Metallschmiede der Vinča-Kultur wählten die zinnhaltigen Mineralien mutmaßlich wegen deren schwarz-grünen Färbung aus, die Ähnlichkeit zu manganreichen Kupfererzen besaßen. Den Metallschmieden der Zinnbronzen waren die spezifischen Eigenschaften des neuen Metalls bewusst, was aus den angewendeten Techniken bei der Verarbeitung der zinnreichen Erze abgeleitet werden kann.

Durch die Legierung Bronze, deren Bestandteile Kupfer und Zinn sind, gelangte dieses zu größerer Bedeutung (Bronzezeit). Für Ägypten bestätigt sich die Verwendung von Zinn durch Funde kleiner Bronzestatuetten aus der Zeit der Pyramiden (4. Dynastie, um 2500 v. Chr.). Auch in einem ägyptischen Grabmal aus der 18. Dynastie (um 1500 v. Chr.) wurden Gegenstände aus Zinn gefunden. In Indien war die Bronzeherstellung bereits um 3000 v. Chr. bekannt.
Seit dem 2. Jahrtausend v. Chr. wurde Zinn in Mittelasien an der Route der späteren Seidenstraße nachweislich in größerem Maße in Bergwerken abgebaut. Ab etwa 1800 v. Chr. (Shang-Dynastie) ist Zinn in China bekannt. Ein Schriftwerk über die Küste jener Zeit, das K'ao kung chi (Chou-Dynastie, ab 1122 v. Chr.), beschreibt eingehend die Mischungsverhältnisse von Kupfer und Zinn, die je nach Art der für sakrale Gefäße, Gongs, Schwerter und Pfeilspitzen, Äxte oder Ackerbaugerät zu verwendenden Bronze verschieden waren.
Bereits früher dürfte es in den eigentlichen asiatischen Lagerstätten in Yunnan und auf der Halbinsel Malakka bekannt gewesen sein. Im Tal des Euphrat wurden seit 2000 v. Chr. Bronzegeräte und deren Herstellung zu einem bedeutenden Kulturfaktor; die Technik wurde dann von Griechen und Römern weiterentwickelt.

Die Ausbreitung des Handels mit Zinn bestätigt ebenfalls seine frühe und weitreichende Nutzbarmachung. Es wurde zunächst aus Zentralasien mit Karawanen in die Gebiete des heutigen Nahen und Mittleren Ostens gebracht. Dort holte man sich das Zinnerz ab dem 3. Jahrtausend v. Chr. aus den Lagerstätten des alten Reiches Elam östlich des Tigris und aus den Bergen von Chorasan an der persischen Grenze zu Turkmenistan und Afghanistan. Von dort scheint man es in das Land der Pharaonen weitergeliefert zu haben. In der Bibel wird Zinn im 4. Buch Mose erstmals erwähnt .

Die Phönizier hatten wahrscheinlich auf dem Seeweg Verbindungen mit den zinnreichen indischen Inseln Malakka und Bangka, ohne dass dazu genaue Angaben zu machen sind. Später transportierten die Phöniker das Zinnerz mit ihren Schiffen entlang der spanischen und französischen Küstengebiete bis zu den Inseln in der Nordsee. Auf diesen Fahrten entdeckten sie auf den sogenannten Zinninseln, zu denen möglicherweise die Insel Wight gehörte, und in den Bergen von Cornwall zinnreiche Gebiete, bauten dort das Erz ab und führten es in andere Länder aus. In kleinerem Maße begann der Zinnerzabbau in handelsmöglichen Ausmaßen auch in Frankreich (u. a. am Cap de l'Etain), in Spanien (Galicien) und in Etrurien (Cento Camerelle bei Campiglia Marittima).

In den Epen Homers sowie bei Hesiod tauchen Zinneinlagen als Schmuckornament an Streitwagen und Wehrschilden des Agamemnon sowie des Herakles auf; für Achilles werden zinnerne (wohl »verzinnte«) Beinschienen beschrieben. Durch Plautus wird Zinn erstmals als Geschirr für Speisen erwähnt. Als Gebrauchsmetall für Geschirr war es bei den Griechen wohl nicht bekannt. Das Zinn, das die Griechen für den Bronzeguss benutzten, stammte nach Herodot von den Kassiteriden, deren geographische Lage diesem aber unbekannt war. Diese Inseln werden auch von Strabon erwähnt und beschrieben, der sie weit nördlich von Spanien lokalisiert, in der Nähe Britanniens.

Der römische Schriftsteller Plinius nannte Zinn in seiner Naturgeschichte "plumbum album" („weißes Blei“); Blei hingegen war "plumbum nigrum" („schwarzes Blei“). Er beschreibt daneben auch das Verzinnen von Kupfermünzen und berichtet von zinnernen Spiegeln und Ampullen und beschreibt, dass Bleiwasserrohre mit Zinnlegierung verlötet wurden. Die hohe Nachfrage nach dem in der Alchemie dem Jupiter zugeordneten Zinn wird sogar als ein Grund für die römische Besetzung Britanniens angeführt. In der südwestlichen Region Cornwall wurde von 2100 v. Chr. bis 1998 Zinnerz gefördert, in der Antike ein wichtiger Zinnlieferant des Mittelmeerraums und bis ins späte 19. Jahrhundert der größte der Welt. Im Lateinischen heißt Zinn "stannum", daher rührt auch das chemische Symbol (Sn).

Während der Völkerwanderung erlahmte der bergmännische Abbau von Zinnerzen völlig. Nur wenige Kultgegenstände wurden noch gefertigt. Im Konzil von Reims (813) wird neben Gold und Silber ausdrücklich nur Zinn für die Herstellung solcher Gegenstände gestattet. Die Gräberfunde von Capetiennes bestätigen dies insofern, als es zur Zeit der ersten Kreuzzüge üblich war, Priester mit Zinnkelchen und Bischöfe wie auch Äbte mit Zinnkrummstäben beizusetzen.

Der Brauch, kleine Bildnisse aus Zinnlegierung, sogenannte Pilgerzeichen, auf der Brust zu tragen, stammt vermutlich ebenfalls aus der Zeit der Kreuzzüge. Je nach Region waren dies in Mittel- und Südfrankreich St. Denis bzw. St Nicolas, in England der Heilige Thomas von Canterbury. Die von den palästinischen Pilgerorten heimgebrachten religiösen Münzen und Ampullen, kleinen Glöckchen und Pfeifen waren aus Zinn. Sie mussten nach anerkanntem Vollzug der Pilgerfahrt zur Abwendung eventuellen Missbrauchs in Flüsse und Seen geworfen werden. 

Ab 1100 begann die Bevölkerung in Europa nach und nach das bisher aus Ton und Holz bestehende Essgeschirr durch solches aus dem stabileren Zinn zu ersetzen. Um 1200 begann in den größeren Städten die handwerkliche Verarbeitung des Zinns in Zinngießereien. 
Die Venezianer pflegten damals Handelsbeziehungen zu den zinnreichen indischen Inseln Malakka und Bangka. 

Lange nachdem Bronze durch Eisen verdrängt worden war (Eisenzeit), erlangte Zinn Mitte des 19. Jahrhunderts durch die industrielle Herstellung von Weißblech von Neuem große Bedeutung.

Primäre Zinnvorkommen umfassen Greisen-, hydrothermale Gang- und seltener auch Skarn- und Vulkanisch-exhalative-Lagerstätten (VHMS). Da das wirtschaftlich bedeutendste Zinnmineral Kassiterit SnO, auch Zinnstein genannt, ein sehr stabiles Schwermineral ist, kommt ein großer Teil der Zinnproduktion auch aus sekundären Seifenlagerstätten. In einigen primären Lagerstätten besitzt auch das Sulfidmineral Stannit CuFeSnS Bedeutung für die Zinnproduktion. Auf primären Zinnlagerstätten kommt das Element oft mit Arsen, Wolfram, Bismut, Silber, Zink, Kupfer und Lithium vergesellschaftet vor.

Zur Gewinnung von Zinn wird das Erz zuerst zerkleinert und dann durch verschiedene Verfahren (Aufschlämmen, elektrische/magnetische Scheidung) angereichert. Nach der Reduktion mit Kohlenstoff wird das Zinn knapp über seine Schmelztemperatur erhitzt, so dass es ohne höher schmelzende Verunreinigungen abfließen kann. Heute gewinnt man einen Großteil durch Recycling und hier durch Elektrolyse.

In der kontinentalen Erdkruste ist es mit einem Anteil von etwa 2,3 ppm vorhanden.

Die aktuellen Reserven für Zinn werden mit 4,7 Millionen Tonnen angegeben, bei einer Jahresproduktion von 289.000 Tonnen im Jahr 2015. Zu über 80 % kommt die Produktion derzeit aus Seifenlagerstätten (Sekundärlagerstätten) an Flüssen sowie im Küstenbereich, vornehmlich aus einer Region beginnend in Zentralchina über Thailand bis nach Indonesien. Die größten Zinnvorkommen der Erde wurden 1876 im Kinta Valley (Malaysia) entdeckt. Dort wurden bis heute etwa 2 Millionen Tonnen geschürft. Das Material in den Schwemmlandlagerstätten hat einen Metallanteil von etwa 5 %. Erst nach verschiedenen Schritten zur Konzentrierung auf etwa 75 % wird ein Schmelzprozess eingesetzt.

In Deutschland sind größere Ressourcen im Erzgebirge vorhanden, wo das Metall vom 13. Jahrhundert an bis 1990 gewonnen wurde. Beispiele sind die Greisenlagerstätte Altenberg und die Skarnlagerstätte Pöhla. Durch verschiedene Firmen findet derzeit auch Exploration auf Zinn im Erzgebirge statt. Im August 2012 veröffentlichte erste Untersuchungsergebnisse für die Orte Geyer und Gottesberg, einen Ortsteil von Muldenhammer, lassen Vorkommen in Höhe von rund 160.000 Tonnen Zinn für beide Orte insgesamt vermuten. Diese Zahlen bestätigen prinzipiell auch Angaben, wie sie nach zu DDR-Zeiten vorgenommenen Prospektionen geschätzt wurden. Nach Aussage der "Deutschen Rohstoff AG" handelt es sich um das weltweit größte noch unerschlossene Zinnvorkommen. Da einerseits der Erzgehalt mit 0,27 Prozent für Gottesberg und 0,37 Prozent für Geyer verhältnismäßig gering ist, andererseits das Erz verhältnismäßig schwer aus dem Gestein zu lösen ist, ist offen, ob sich der Abbau wirtschaftlich lohnen würde. Sollte es dazu kommen, würden als Nebenprodukt auch Zink, Kupfer und Indium anfallen.

Die bedeutendste Fördernation für Zinn ist China, gefolgt von Indonesien und Myanmar. In Europa war 2009 Portugal der größte Produzent, wo es als Beiprodukt der VHMS Lagerstätte Neves Corvo gefördert wird.

Kassiterit wurde von der US-amerikanischen Börsenaufsicht SEC als sogenanntes „conflict mineral“ eingestuft, dessen Verwendung für Unternehmen gegenüber der SEC berichtspflichtig ist. Als Grund hierfür werden die Produktionsorte im Osten des Kongo angeführt, die von Rebellen kontrolliert werden und so im Verdacht stehen, bewaffnete Konflikte mitzufinanzieren.

Zinn kann drei Modifikationen mit verschiedener Kristallstruktur und Dichte annehmen:
Daneben kann noch eine zweidimensionale Modifikation namens Stanen (ähnlich der Kohlenstoffmodifikation Graphen) synthetisiert werden.

Natürliches Zinn besteht aus zehn verschiedenen stabilen Isotopen; das ist die größte Anzahl unter allen Elementen. Außerdem sind noch 28 radioaktive Isotope bekannt.

Die Rekristallisation von β-Zinn zu α-Zinn bei niedrigen Temperaturen äußert sich als die sogenannte Zinnpest.

Beim Verbiegen des relativ weichen Zinns, beispielsweise von Zinnstangen, tritt ein charakteristisches Geräusch, das "Zinngeschrei" (auch Zinnschrei), auf. Es entsteht durch die Reibung der β-Kristallite aneinander. Das Geräusch tritt jedoch nur bei reinem Zinn auf. Bereits niedrig legiertes Zinn zeigt diese Eigenschaft nicht; z. B. verhindern geringe Beimengungen von Blei oder auch Antimon das Zinngeschrei. Das β-Zinn hat einen abgeflachten Tetraeder als Raumzellenstruktur, aus dem sich zusätzlich zwei Verbindungen ausbilden.

Durch die Oxidschicht, mit der Zinn sich überzieht, ist es sehr beständig. Von konzentrierten Säuren und Basen wird es allerdings unter Entwicklung von Wasserstoffgas zersetzt. Jedoch ist Zinn(IV)-oxid ähnlich inert wie Titan(IV)-oxid. Zinn wird von unedleren Metallen (z. B. Zink) reduziert; dabei scheidet sich elementares Zinn schwammig oder am Zink haftend ab.

Zinn besitzt insgesamt zehn natürlich vorkommende Isotope. Es sind dies Sn, Sn, Sn, Sn, Sn, Sn, Sn, Sn, Sn und Sn. Sn ist dabei mit 32,4 % Anteil an natürlichem Zinn das häufigste Isotop. Von den instabilen Isotopen ist Sn mit einer Halbwertszeit von 230.000 Jahren das langlebigste. Alle anderen Isotope haben eine Halbwertzeit von nur maximal 129 Tagen, jedoch existiert bei Sn ein Kernisomer mit 44 Jahren Halbwertzeit. Als Tracer werden am häufigsten die Isotope Sn, Sn, Sn und Sn verwendet. Zinn hat als einziges Element drei stabile Isotope mit ungerader Massenzahl und mit zehn stabilen Isotopen die meisten stabilen Isotope von allen Elementen überhaupt.

"→ Liste der Zinn-Isotope"

Als qualitative Nachweisreaktion für Zinnsalze wird die Leuchtprobe durchgeführt: Die Lösung wird mit ca. 20%iger Salzsäure und Zinkpulver versetzt, wobei "naszierender Wasserstoff" frei wird. Der naszierende, atomare Wasserstoff reduziert einen Teil des Zinns bis zum Stannan SnH. In diese Lösung wird ein Reagenzglas eingetaucht, das mit kaltem Wasser und Kaliumpermanganatlösung gefüllt ist; das Kaliumpermanganat dient hier nur als Kontrastmittel. Dieses Reagenzglas wird im Dunkeln in die nichtleuchtende Bunsenbrennerflamme gehalten. Bei Anwesenheit von Zinn entsteht sofort eine typisch blaue Fluoreszenz, hervorgerufen durch SnH.

Zur quantitativen Bestimmung von Zinn eignet sich die Polarographie. In 1 M Schwefelsäure ergibt Zinn(II) eine Stufe bei −0,46 V (gegen Kalomelelektrode, Reduktion zum Element). Stannat(II) lässt sich in 1 M Natronlauge zum Stannat(IV) oxidieren (−0,73 V) oder zum Element reduzieren (−1,22 V). Im Ultraspurenbereich bieten sich die Graphitrohr- und Hydridtechnik der Atomspektroskopie an. Bei der Graphitrohr-AAS werden Nachweisgrenzen von 0,2 µg/l erreicht. In der Hydridtechnik werden die Zinnverbindungen der Probelösung mittels Natriumborhydrid als gasförmiges Stannan in die Quarzküvette überführt. Dort zerfällt das Stannan bei ca. 1000 °C in die Elemente, wobei der atomare Zinndampf spezifisch die Sn-Linien einer Zinn-Hohlkathodenlampe absorbiert. Hier sind 0,5 µg/l als Nachweisgrenze angegeben worden.

Weitere qualitative Nachweisreagenzien sind Diacetyldioxim, Kakothelin, Morin und 4-Methylbenzol-1,2-dithiol. Zinn kann auch mikroanalytisch über die Bildung von Goldpurpur nachgewiesen werden.

Metallisches Zinn ist auch in größeren Mengen an sich ungiftig. Die Giftwirkung einfacher Zinnverbindungen und Salze ist gering. Einige organische Zinnverbindungen dagegen sind hochtoxisch. Die Trialkyl-Zinnverbindungen (insbesondere TBT, engl. „Tributyltin“, Tributylzinn) und Triphenylzinn wurden mehrere Jahrzehnte in Anstrichfarben für Schiffe verwendet, um die sich an den Schiffsrümpfen festsetzenden Mikroorganismen und Muscheln abzutöten. Dadurch kam es in der Umgebung von großen Hafenstädten zu hohen Konzentrationen an TBT im Meerwasser, die die Population diverser Meereslebewesen bis heute beeinträchtigen. Die toxische Wirkung beruht auf der Denaturierung einiger Proteine durch die Wechselwirkung mit dem Schwefel aus Aminosäuren wie beispielsweise Cystein.

Seit Jahrhunderten wird reines Zinnblech großflächig zur Herstellung als Orgelmetall im Sichtbereich verwendet. Diese behalten ihre silbrige Farbe über viele Jahrzehnte. Das weiche Metall wird aber in der Regel in einer Legierung mit Blei, dem sogenannten "Orgelmetall," verwendet und hat für die Klangentfaltung sehr gute vibrationsdämpfende Eigenschaften. Zu tiefe Temperaturen sind wegen der Umwandlung in α-Zinn für Orgelpfeifen schädlich; siehe Zinnpest. Viele Haushaltsgegenstände, Zinngerät (Geschirr), Tuben, Dosen und auch Zinnfiguren wurden früher ganz aus Zinn gefertigt, rundweg der einfacheren Verarbeitungstechnologie der Zeit entsprechend. Mittlerweile jedoch wurde das relativ kostbare Material meist durch preiswertere Alternativen ersetzt. Ziergegenstände und Modeschmuck werden weiterhin aus Zinnlegierungen, Hartzinn bzw. Britanniametall hergestellt.

Seit dem Mittelalter war der Zinngießer ein spezieller Handwerksberuf, der sich bis heute, allerdings in ganz geringem Umfang, erhalten hat. Er ist heute rechtlich in der Berufsbezeichnung Metall- und Glockengießer/-in aufgegangen. Aufgabe des Zinnputzers war die Reinigung von vor allem oxidierten, aus Zinn gefertigten Gegenständen mit einem Kaltwasserauszug des Ackerschachtelhalms, der volkstümlich deshalb auch Zinnkraut genannt wurde. Es war ein eher wenig angesehenes Wandergewerbe und wurde in den Häusern bürgerlicher oder großbäuerlicher Haushalte ausgeübt.

Der Jahresweltverbrauch an Zinn liegt bei etwa 300.000 t. Davon werden etwa 35 % für Lote, etwa 30 % für Weißblech und etwa 30 % für Chemikalien und Pigmente eingesetzt. Durch die Umstellung der Zinn-Blei-Lote auf bleifreie Lote mit Zinnanteilen > 95 % wird der jährliche Bedarf um etwa 10 % wachsen. Die Weltmarktpreise steigen in den letzten Jahren kontinuierlich. So wurden an der LME (London Metal Exchange) 2003 noch etwa 5000 US-Dollar pro Tonne bezahlt, im Mai 2008 jedoch bereits mehr als 24.000 US-Dollar pro Tonne. Die zehn größten Zinnverbraucher (2003) weltweit sind nach China auf Platz 1 die Länder USA, Japan, Deutschland, übriges Europa, Korea, übriges Asien, Taiwan, Großbritannien und Frankreich.

Die weltweite Finanzkrise ab 2007 sowie ein schwaches Wirtschaftswachstum in den Schwellen- und Entwicklungsländern setzte den Preis unter Druck. Im August 2015 sank der Preis je Tonne kurzfristig auf unter 14.000 US-Dollar. Im Oktober 2015 hatte der Preis sich wieder leicht auf rund 16.000 US-Dollar erholt. Durch den starken US-Dollar kommt der günstige Preis nur teilweise in vielen Verbraucherländern an. Die weltweite Produktion lag 2011 bei rund 253.000 Tonnen, von denen alleine 110.000 Tonnen in China gefördert worden sind; weitere 51.000 Tonnen stammten aus Indonesien. Aufgrund des relativ niedrigen Erlöses durch den Export von Zinn, verglichen mit Erdöl oder Erdgas beispielsweise, spielt es in den Produktionsländern keine besondere wirtschaftliche Rolle.

Als Legierungsbestandteil wird Zinn vielfältig verwendet, mit Kupfer zu Bronze oder anderen Werkstoffen legiert. Nordisches Gold, die Legierung der goldfarbigen Euromünzen, beinhaltet unter anderem 1 % Zinn.

Als Bestandteil von Metall-Legierungen mit niedrigem Schmelzpunkt ist Zinn unersetzlich. Weichlot (sogenanntes Lötzinn) zur Verbindung elektronischer Bauteile (beispielsweise auf Leiterplatten) wird mit Blei (eine typische Mischung ist etwa 63 % Sn und 37 % Pb) und anderen Metallen in geringerem Anteil legiert. Die Mischung schmilzt bei etwa 183 °C. Seit Juli 2006 darf jedoch kein bleihaltiges Lötzinn in elektronischen Geräten mehr verwendet werden (siehe RoHS); man setzt nun bleifreie Zinnlegierungen mit Kupfer und Silber ein, z. B. Sn95.5Ag3.8Cu0.7 (Schmelztemperatur ca. 220 °C).

Da man aber diesen Legierungen nicht traut (Zinnpest und „Tin whiskers“), ist bei der Fertigung elektronischer Baugruppen für Medizintechnik, Sicherheitstechnik, Messgeräte, Luft- u. Raumfahrt sowie für militärische/polizeiliche Verwendung weiterhin die Verwendung bleihaltiger Lote zulässig. Im Gegenteil ist der Einsatz "bleifreien" Lotes in diesen sensiblen Bereichen trotz RoHS verboten.

Hochreine Zinn-Einkristalle eignen sich auch zur Herstellung von elektronischen Bauteilen.

In der Floatglasherstellung schwimmt die zähflüssige Glasmasse bis zur Erstarrung auf einer spiegelglatten flüssigen Zinnschmelze.

Zinnverbindungen werden dem Kunststoff PVC als Stabilisatoren beigemischt. Tributylzinn dient als sog. Antifouling-Zusatz in Anstrichstoffen für Schiffe und verhindert den Bewuchs der Schiffskörper, es ist mittlerweile jedoch umstritten und weitgehend verboten.

In Form einer transparenten Zinnoxid-Indiumoxid-Verbindung ist es elektrischer Leiter in Anzeigegeräten wie LC-Displays. Das reine, weiße, nicht sehr harte Zinndioxid besitzt eine hohe Lichtbrechung und wird im optischen Bereich und als mildes Poliermittel eingesetzt. In der Zahnheilkunde wird Zinn auch als Bestandteil von Amalgamen zur Zahnfüllung eingesetzt. Die sehr toxischen organischen Zinnverbindungen finden als Fungizide oder Desinfektionsmittel Verwendung.

Zinn wird anstelle von Blei auch zum Bleigießen verwendet.
"Stannum metallicum" („metallisches Zinn“) findet auch bei der Herstellung von homöopathischen Arzneimitteln sowie als Bandwurmgegenmittel Verwendung.

Unter der Bezeichnung Argentin wurde Zinnpulver früher zur Herstellung von unechtem Silberpapier und unechter Silberfolie verwendet.

Weißblech ist verzinntes Eisenblech, es wird beispielsweise für Konservendosen oder Backformen verwendet. "Tin", das englische Wort für Zinn, ist gleichzeitig ein englisches Wort für Dose bzw. Konservenbüchse.

Zu dünner Folie gewalzt nennt man es auch Stanniol, das beispielsweise für Lametta Verwendung findet. Jedoch ist Zinn im 20. Jahrhundert durch das viel preiswertere Aluminium verdrängt worden. Bei manchen Farbtuben und Weinflaschenverschlüssen findet Zinn ebenfalls Verwendung.

Zinn wird in der EUV-Lithografie zur Herstellung von integrierten Schaltkreisen („Chips“) – als notwendiger Bestandteil bei der Erzeugung von EUV-Strahlung durch Zinn-Plasma – eingesetzt.

Zinnverbindungen kommen in den Oxidationsstufen +II und +IV vor. Zinn(IV)-Verbindungen sind stabiler, da Zinn ein Element der IV. Hauptgruppe ist und zudem der Effekt des inerten Elektronenpaares noch nicht so stark ausgeprägt ist wie bei den schwereren Elementen dieser Gruppe, z. B. dem Blei. Zinn(II)-Verbindungen lassen sich deshalb leicht in Zinn(IV)-Verbindungen umsetzen. Viele Zinnverbindungen sind anorganischer Natur, es ist aber auch eine Reihe von zinnorganischen Verbindungen ("Zinnorganylen") bekannt.










</doc>
<doc id="5759" url="https://de.wikipedia.org/wiki?curid=5759" title="Zoologie">
Zoologie

Die Zoologie ( [zóon], „Tier“, „lebendes Wesen“ und "λόγος" [lógos], „Wort, Satz, Rede“, auch „Vernunft“ (lat. ratio): die Lehre von den formalen Regeln des gültigen Schließens.), im weitesten auch Tierkunde, ist die Disziplin der Biologie, deren Forschungsgegenstand die Tiere ("Animalia"), insbesondere die Vielzelligen Tiere ("Metazoa") sind. Die Zoologie untersucht mit verschiedenen naturwissenschaftlichen Methoden Gestalt und Körperbau (Morphologie, Anatomie), Lebenstätigkeiten (Physiologie), Entwicklungs- und Stammesgeschichte (einschließlich Paläozoologie), Erbgeschehen (Genetik), Umweltbeziehungen (Ökologie), Verbreitung (Zoogeographie) sowie das Verhalten (Verhaltensbiologie) der Tiere und erstellt eine Systematik des Tierreiches. Die meisten Zoologen haben heute Biologie als Studienfach studiert. Aber auch Tierärzte, Forstwissenschaftler und Geographen arbeiten teilweise als Zoologen.



Das Studium der Zoologie ist in Deutschland, Österreich und der Schweiz Bestandteil eines Biologiestudiums. Naturwissenschaftliche Grundlagen wie Physik, Chemie, Mathematik (hier vor allem Statistik), Botanik und Mikrobiologie sind anfänglich ebenfalls wichtig und ein großer Baustein auf dem Weg zur Spezialisierung auf ein zoologisches Fach im Fortgeschrittenenstudium (meist Master). Nahezu alle Teilgebiete der Zoologie setzen eine sehr gute Kenntnis in Biochemie und Molekularbiologie voraus. Dies gilt auch für solche klassischen Fächer wie die Morphologie, die Anatomie, die Evolutionsforschung und Taxonomie. In den ersten vier bis sechs Semestern wird dem Biologiestudenten eine Fülle von theoretischen und praktischen Lehrveranstaltungen angeboten. Zoologische Schwerpunkte sind je nach Angebot der Universität meist in Master Studiengängen der Ökologie, Landschaftsökologie, Meeresbiologie und der Biodiversitätsforschung zu finden. Hier beginnt die Konzentrierung auf einige Wahlfächer innerhalb der Biologie. Häufig wird die experimentelle Arbeit in kleinen Gruppen noch wichtiger. Innerhalb der Zoologie wird in allen Universitäten eine Fülle von Praktika angeboten, die meist ganztägig und täglich über mehrere Wochen (manchmal auch über ein ganzes Semester) durchgeführt werden. Viele zoologische Praktika sind auch so angelegt, dass sie das „forschende Lernen“ unterstützen.

Zoologie ist ein sehr facettenreiches Fach. Daher ist die Kombination mit einem Nebenfach, sofern es die Bachelor-Prüfungsordnung zulässt, interessant. Die Grundlagen der Verhaltensforschung werden häufig mit Psychologie kombiniert. Bei einer Ausrichtung auf Neurobiologie ist Physik und Informatik besonders hilfreich und wird häufig dazu studiert.

Ungefähr die Hälfte der Zoologiestudenten beginnt nach ihrer Masterarbeit mit einer Doktorarbeit.

Neben dem regulären Studiengang gibt es meist Möglichkeiten an der Forschungsarbeit in den Instituten teilzunehmen. In den meisten Universitäten läuft dies unter der Bezeichnung „freie Mitarbeit“ oder Projektpraktikum, und meist wird die Mitarbeit in Form einer Bescheinigung bestätigt.

Der Studienführer Biologie zählt in Deutschland 54 Standorte an denen das Fach studiert werden kann. Die Studienpläne und Studienordnungen an den verschiedenen Universitäten im Fach Zoologie sind recht unterschiedlich. Die Ausprägungen der zoologischen Arbeitsgruppen ist sehr verschieden: Manche arbeiten explizit tierökologisch, zoologisch, wildbiologisch, andere vermitteln zoologische Grundlagen in der Genetik, Neurobiologie, Ökologie, Evolutionsbiologie oder einem anderen Fach der Zoologie.

Master-Studiengänge der Zoologie werden von den Universitäten Basel, Wien, Graz, Innsbruck und Salzburg angeboten. Andere Hochschulen haben die Trennung von Zoologie, Botanik und anderen klassischen Fachrichtungen der Biologie aufgegeben und integrierten die zoologischen Aspekte in speziellere, beispielsweise physiologisch oder ökologisch ausgerichtete Master-Studiengänge ("Integrative Zoologie", etwa in Rostock).




</doc>
<doc id="5760" url="https://de.wikipedia.org/wiki?curid=5760" title="Zentralbank">
Zentralbank

Eine Zentralbank (auch Notenbank, Zentralnotenbank, zentrale Notenbank oder Nationalbank) ist eine für die Geld- und Währungspolitik eines Währungsraums oder Staates zuständige Institution. In vielen Staaten wurden die Zentralbanken auf das Hauptziel festgelegt, die Preisniveau- und Geldwertstabilität zu wahren. Eine Zentralbank hält die Währungsreserve eines Währungsraumes, refinanziert Geschäftsbanken und den Staat. Zentralbanken emittieren Banknoten und bringen diese in Umlauf. Zur Erfüllung ihrer Ziele und Aufgaben steht der Notenbank eine Reihe von Instrumentarien (im Wesentlichen die Steuerung der Zinshöhe und der Geldmengen) zur Verfügung, die die verschiedenen Zentralbanken in unterschiedlichen Intensitäten einsetzen. Der Abhängigkeitsgrad der Notenbanken von anderen staatlichen Institutionen richtet sich nach den wirtschaftlichen und politischen Verflechtungen des jeweiligen Landes. Da es nationale und supranationale Währungsräume gibt, sind Zentralbanken entsprechend auf nationaler Ebene (Federal Reserve System, Schweizerische Nationalbank, Bank of England etc.) und supranational (z. B. Europäische Zentralbank oder BIZ) vorzufinden.

Überall auf dem europäischen Kontinent existierten im 16. und 17. Jahrhundert kleine Bankhäuser, welche ihre eigenen Münzen prägten. Das Recht dazu wurde ihnen von staatlichen Stellen verpachtet. Die meisten dieser Banken waren private Banken und damit Privatnotenbanken. Über die Münzprägung entwickelten sich Zettelbanken, die Zettel, Kassenanweisungen und später Banknoten emittierten. Dies waren Quittungen für Münzgeld und hinterlegte Edelmetalle, das diese Banken in Verwahrung nahmen. Die Quittungen wurden als Zahlungsmittel verwendet. Sie gaben ihren Inhabern das Recht, von einer dazu verpflichteten Bank jederzeit die Herausgabe der entsprechenden Menge Münzgeld zu verlangen.

Im Jahr 1609 wurde die Amsterdamer Wechselbank gegründet. Sie war das erste Institut eines Netzwerks aus öffentlichen Girobanken in Mittel- und Südeuropa. Zu diesem Netzwerk zählten auch die Hamburger Bank, der Banco Giro in Venedig 
und der Nürnberger Banco Publico. Die Girobanken stellten eine öffentliche Infrastruktur 
für bargeldlose internationale Zahlungen zur Verfügung. Hierdurch sollten sie die Effizienz des Handels steigern und die Geldwertstabilität gewährleisten. Die Girobanken erfüllten somit bereits wesentliche Funktionen moderner Zentralbanken.

Die Schwedische Reichsbank gilt als die älteste heute noch existierende Zentralbank. 1656 wurde die "Stockholms Banco" von der schwedischen Regierung als private Einrichtung zugelassen; trotzdem unterlag sie einer starken staatlichen Lenkung. Die Regierung platzierte den größten Teil ihres Vermögens in der Bank. Gleichzeitig forderte sie, dass entstehende Gewinne mit der Stadt Stockholm und dem Staat geteilt werden.

Beinahe drei Jahrzehnte später (1694) wurde die Bank of England gegründet. Wie die Schwedische Reichsbank wurde auch die Bank of England als Aktiengesellschaft gegründet und hatte als wichtigste Aufgabe, der Regierung Geld zu leihen. Dafür erhielt sie Privilegien wie z. B. begrenzte Haftung und ihren Konkurrenten wurden Beschränkungen auferlegt (z. B. durften sie nicht mehr als sechs Kapitalgeber haben). Später entstanden in Europa weitere Zentralbanken, vorrangig mit der Aufgabe, Staatsschulden zu finanzieren.

Auch wenn die hauptsächliche Aufgabe der frühen Zentralbanken in der Finanzierung der Staatsschulden zu sehen war, nahmen sie als private Instanzen weitere Bankgeschäfte wahr. Aufgrund ihrer Privilegien nahmen sie bald eine dominierende Stellung ein. Andere Banken ersetzten ihre Münzreserven durch Noten der Zentralbanken. Die Zentralbanken verwalteten im Rahmen ihrer Aufgabe als Bank der Banken Konten für andere Geschäftsbanken und wickelten Transaktionen zwischen den Banken ab (Clearing). Durch die damit verbundene Funktion als Aufbewahrungsort (für andere Banken), verfügten die Zentralbanken über große Gold- bzw. Silberreserven, aber auch über ein gut ausgebautes Netzwerk von Banken. Diese Faktoren führten dazu, dass die Zentralbanken zur letzten Refinanzierungsstelle "(lender of last resort)" in finanziellen Krisensituationen wurden, d. h., sie stellten ihren Kunden in Zeiten finanzieller Nöte Bargeld bereit.

Im 19. Jahrhundert entwickelte sich das Bankwesen stetig weiter. Ein treibender Faktor, auch die Regulierungen weiterzuentwickeln, waren Finanzkrisen. Nach Finanzkrisen wurde oft der Bedarf gesehen, das Bankgeschäft restriktiver zu handhaben. In den meisten Fällen führte das dazu, dass die Zentralbanken das alleinige Recht hatten, Banknoten herauszugeben. Um die Umwandlung der von den Banken ausgegebenen Banknoten in Münzgeld bzw. Gold zu gewährleisten, entwickelte sich das Erfordernis, die Banknoten durch Bestände zunächst an Münzen, später an Edelmetallen (Gold, Silber), abzusichern (Deckungspflicht). Mit der Einführung der "Peelschen Bankakte" im Jahre 1844 wurde in England erstmals gesetzlich festgelegt, dass alle Banknoten von der Bank of England voll durch Gold gedeckt werden müssen. Dieser so genannte Goldstandard wurde 1873 in Großbritannien eingeführt und in den meisten europäischen Ländern übernommen. Die Einführung des Goldstandards führte dazu, dass die Zentralbanken große Goldreserven zur Deckung ihrer Geldbestände hielten. Das Hauptziel, welches die Zentralbanken damit anstrebten, war die Sicherstellung der Preisstabilität. Mit der Zeit überstieg die Menge an Papiergeld die Menge an Münzen und Edelmetallen deutlich (s. Geldschöpfung). 1914 wurde im Zusammenhang mit dem Ersten Weltkrieg die Golddeckungspflicht in vielen Ländern aufgehoben.

Nach dem Ersten Weltkrieg, als Arbeitslosigkeit und Preisinstabilität eine große Rolle spielten, begannen die Zentralbanken mehr Wert auf die Erhaltung des wirtschaftlichen Gleichgewichts zu legen. Dies wurde vor allem während der Wirtschaftskrise von 1929 bis 1933 deutlich. Aufgrund der beiden Weltkriege in der ersten Hälfte des 20. Jahrhunderts bestand die Hauptaufgabe der Zentralbanken in dieser Zeit in der Bereitstellung finanzieller Ressourcen zur Deckung der Kriegsausgaben. Nach dem Zweiten Weltkrieg wurde der Einfluss des Staates auf die Zentralbanken größer. Die Ziele der Zentralbanken wurden auf die Förderung von Beschäftigung und Einkommenszuwachs erweitert. Die Notenbanken wurden damit zu einem Hauptinstrument zur Unterstützung staatlicher Ziele, was mitunter auch als Verlust von deren Autonomie bezeichnet wird. Einige Banken, wie die Reserve Bank of India wurden verstaatlicht. Andere, wie das Federal Reserve System gelten zwar als institutionell unabhängig, müssen aber trotzdem der Regierung über die Geschäfte berichten.

Bis zum Ende der 1980er Jahre hat faktisch keine Zentralbank ein numerisches Inflationsziel zur Unterstützung der Preisstabilität vorgegeben. In den Neunzigerjahren des 20. Jahrhunderts setzten sich jedoch immer mehr Zentralbanken ein explizites Inflationsziel. Einigen Zentralbanken wird eine solche Zielinflationsrate auch durch die jeweilige Regierung vorgeschrieben (z. B. Bank of England). Gegenwärtig gibt es keine einheitliche Handhabe der Zentralbanken hinsichtlich der numerischen Bezifferung der Preisniveaustabilität.

Heute konzentrieren sich die Zentralbanken auf drei Hauptziele, die sich im Laufe der Geschichte entwickelt haben: Preisstabilität, wirtschaftliches Gleichgewicht und finanzielle Stabilität. Im Moment gestaltet sich die Erreichung dieser Ziele im Hinblick auf die Finanzkrise seit 2007 recht schwierig.

Mit der Errichtung von Zentralbanken war oft auch eine Zentralisierung des Geldwesens und die Schaffung einer einheitlichen Währung verbunden. Bis dahin hatten die einzelnen Notenbanken vielfach ihre eigenen Währungen ausgegeben. 1998 wurde beispielsweise die Europäische Zentralbank errichtet und der Euro als neue europäische Währung geschaffen, anstelle der Zentralbanken der einzelnen Länder und der Landeswährungen.

Die Ziele der Zentralbank werden meist gesetzlich vorgegeben. In den entwickelten Staaten gilt als Hauptziel die Bewahrung der Geldwert- und Preisniveaustabilität. Oftmals werden in den jeweiligen Notenbankstatuten weitere gesamtwirtschaftliche Ziele der Geldpolitik, wie beispielsweise Wirtschaftswachstum, Konjunktur- oder Wechselkursstabilität, umschrieben. In Staaten mit gebundener Währung sind die Zentralbanken dazu verpflichtet, den Kurs zum Währungsmedium durch Käufe und Verkäufe desselben stabil zu halten.

Die nachfolgende Tabelle soll die gesetzlich festgelegten Ziele einiger großer Zentralbanken beispielhaft zeigen.

Welche Ziele eine Zentralbank verfolgen soll, war lange Zeit ein Streitpunkt innerhalb der ökonomischen Debatte. Im Zentrum stand dabei die Frage ob es eine Austauschbeziehung zwischen Beschäftigung und Inflation geben kann, wie er in der Phillips-Kurve dargestellt wird. Keynesianer vertraten die Ansicht, dass die Geldpolitik auch langfristig Wachstum und Beschäftigung beeinflussen kann, während Monetaristen annehmen, dass die Geldpolitik keine solchen Effekte haben kann und sich daher darauf beschränken sollte, die Preisstabilität zu gewährleisten. Durch die Erfahrungen mit Stagflation in den 1970er Jahren hat sich die monetaristische Sichtweise weitestgehend durchgesetzt, auch wenn keynesianische Stimmen nie ganz verstummt sind. Unstrittig ist hingegen, dass eine expansive Geldpolitik kurzfristig zu höherem Output und größerer Beschäftigung führt.

Die rechtlichen Regelungen über das Notenbankwesen unterscheiden sich erheblich von Land zu Land. Dennoch ist es möglich, anhand der Zentralbankbilanz, vier grundsätzliche Notenbankfunktionen zu identifizieren.

Zu den Währungsreserven (Position (1) der Zentralbankbilanz) zählen der Bestand an Gold und die Goldforderungen, sowie die konvertiblen Devisen (umtauschbare Währungen). Die konvertiblen Devisen umfassen die Forderungen in Fremdwährungen in Form von Bargeld, Bankguthaben, Wertpapieren und Auslandskrediten abzüglich der Auslandsverbindlichkeiten in Fremdwährung (Nettoauslandsforderung).

Die Zentralbank steht an der Spitze des Bankensystems eines Landes und bietet den Geschäftsbanken die Möglichkeit, sich bei ihr Zentralbankgeld zu verschaffen um den normalen Zahlungsverkehr reibungslos abzuwickeln. In diesem Fall spricht man seitens der Geschäftsbanken von Refinanzierung. Die Position (2) der Zentralbankbilanz zeigt ebendiese Versorgung der Geschäftsbanken mit Zentralbankgeld. Den gegenläufigen Posten zu den Refinanzierungsgeschäften auf der Aktivseite bildet auf der Passivseite die Position (6) der Zentralbankbilanz, welche die Verbindlichkeiten gegenüber den Geschäftsbanken darstellt. Dahinter verbergen sich Einlagen der Geschäftsbanken auf Girokonten der Zentralbank, die in erster Linie Mindestreserveguthaben sind und Guthaben der Geschäftsbanken aus Einlagefazilitäten, d. h., Geschäftsbanken legen ihre überschüssigen Liquiditätsreserven bei der Zentralbank an.
Die Zentralbank soll außerdem als letzte Refinanzierungsstelle "(lender of last resort)" in wirtschaftlichen Krisensituationen Liquidität zur Verfügung stellen, um einen Vertrauensverlust in das Kreditwesen und das Bankensystem abzuwehren. Diese Aufgabe kann allerdings ein Sinken der privaten Eigenverantwortlichkeit der Geschäftsbanken zur Folge haben. Daher erfolgt die Zurverfügungstellung von Zahlungsmitteln zur Deckung des notwendigen Bedarfs nur zu hohen Zinssätzen. Die Zentralbank soll jedoch nur als letzte Refinanzierungsstelle fungieren, wenn die Geschäftsbanken ohne eigenes Fehlverhalten in Mitleidenschaft einer Bankkrise geraten sind.

Neben den Geschäftsbanken kommt als Kreditnehmer bei der Zentralbank weiterhin der Staat in Frage. In vielen Fällen unterstützt die Zentralbank den öffentlichen Sektor bei der Finanzierung seiner Aufgaben durch Kreditgewährung. Dies spiegelt sich in Position (3) der Zentralbankbilanz wider. In der Europäischen Union ist eine direkte Finanzierung der Staatsverschuldung durch das ESZB verboten ( AEUV). Dadurch soll eine übermäßige Verschuldung verhindert und die Geldwertstabilität gewahrt werden.
Des Weiteren ist die Zentralbank an der Kassenhaltung des öffentlichen Sektors beteiligt und fungiert in diesem Sinne als Hausbank des Staates, d. h., der Staat führt seine Guthaben überwiegend bei der Zentralbank. Diese Einlagen werden unter der Position (7) der Zentralbankbilanz gelistet. Darüber hinaus kauft die Zentralbank im Rahmen von Offenmarktgeschäften Wertpapiere, um die Geldmenge zu steuern. Diese Wertpapierbestände werden unter der Position (4) der Zentralbankbilanz aufgeführt.

Die Position (5) der Zentralbankbilanz ist ein besonderes Merkmal der Zentralbank und weist auf ihr Notenmonopol hin. Die Zentralbank hat die alleinige Befugnis, die Banknoten zu emittieren und in Umlauf zu bringen (Notenprivileg). Daher erhielt die "Noten"bank auch ihren Namen. Der Banknotenumlauf steht auf der Passivseite der Zentralbankbilanz und verdeutlicht, dass Banknoten im bilanziellen Sinne Forderungen an das Zentralbanksystem darstellen. Aus dem Notenmonopol leitet sich auch die Aufgabe ab, die Qualität des Bargeldes aufrechtzuerhalten. Das heißt Falschgeld auszusondern und beschädigte Münzen und Geldscheine zu ersetzen.

Aufgrund ihres Banknotenausgabemonopols kann die Zentralbank binnenwirtschaftlich (auf die eigene Währung bezogen) niemals illiquide werden, da sie das Zahlungsmittel selbst schaffen kann. Nur in der Fremdwährung besteht das Risiko einer Insolvenz, da die Zentralbank nicht über die Herstellungsgewalt fremder Währung verfügt.

Aus historischen Gründen liegt in vielen Staaten das Münzrecht nicht bei den Zentralbanken, sondern bei den Regierungen. So etwa im Eurosystem. Hier ist die geldpolitische Unabhängigkeit der EZB dadurch gewahrt, dass die Ausgabe von Münzen durch die EZB genehmigt werden muss.

Bei der Versorgung der Banken mit Zentralbankgeld entsteht der Zentralbank im Normalfall ein Gewinn. Dieser kommt dadurch zustande, dass das zur Refinanzierung der Geschäftsbanken ausgegebene Zentralbankgeld auf der Passivseite der Zentralbankbilanz regelmäßig minderverzinst oder unverzinst ist (z. B. Bargeld), während die auf der Aktivseite stehenden Forderungen in der Regel verzinst werden. Der abzüglich der sonstigen Kosten entstehende Gewinn ist eine Form von Seigniorage. Der Zentralbankgewinn fließt in der Regel dem Fiskus zu, in manchen Fällen werden auch weitere Gruppen beteiligt. In entwickelten Staaten spielt er nur eine geringe Rolle für die Staatsfinanzen. In solchen, deren Möglichkeit Steuern zu erheben eingeschränkt ist, ist der Anteil der Seigniorage an der Finanzierung des Staates höher. Es gibt weitere Definitionen der Seigniorage, etwa die monetäre Seigniorage. Diese nimmt mit der Rate, mit der der Bargeldumlauf erhöht wird, zu. Da diese Rate von der Notenbank festgelegt werden kann, können im Kriegsfall durch diese Art Seigniorage erhebliche finanzielle Mittel mobilisiert werden. Dafür muss jedoch eine hohe Inflation in Kauf genommen werden, die das Vertrauen in die jeweilige Währung untergraben kann. Die unterschiedlichen Definitionen der Seigniorage sind nicht deckungsgleich.

Inwiefern eine Zentralbank die Aufgabe der Finanzmarktaufsicht wahrnimmt, hängt vom jeweiligen monetären System ab. Grundsätzlich sind Zentralbanken für die Ausübung dieser Funktion nicht zwingend erforderlich, sodass auch selbstständige Institutionen die Finanzmarktaufsicht ausüben können.
Aufgrund der Finanzkrise seit 2007 wird sich die Finanzmarktaufsicht künftig restriktiver gestalten und auch institutionell verändern. Die großen Zentralbanken reorganisieren im Rahmen dessen ihre Aufgaben- und Verantwortlichkeitsbereiche. Die mögliche Funktion der Finanzmarktaufsicht leitet sich im Gegensatz zu den vier erstgenannten Funktionen nicht aus der Zentralbankbilanz ab.

In Zentralverwaltungswirtschaften übernahm üblicherweise das Monobankensystem die Funktionen einer Zentralbank. Gemäß sozialistischen Programmen wurde das Geld- und Kreditwesen weitgehend monopolisiert. Ein Monobankensystem besteht aus einer Zentralbank, die in der Regel dem Finanzministerium und den obersten Planungsbehörden direkt unterstellt sind und einigen wenigen ihr direkt untergeordneten Geschäftsbanken. Durch das Monobanksystem wurden die Staatsunternehmen mit Verrechnungsgeld und die Haushalte mit Bargeld versorgt. Das Monopolbankensystem übernahm auch Aufgaben, die über die einer Zentralbank hinausgehen. Es war dafür zuständig die durch den Zentralplan vorgesehenen Kreditmittel an die Unternehmen zu verteilen, den internationalen Zahlungsverkehr samt Außenhandelsfinanzierung und Devisengeschäften abzuwickeln und die Ersparnisse der Bevölkerung zu sammeln und an das Finanzministerium weiterzuleiten.

Zur Erfüllung ihrer Aufgaben stehen der Zentralbank eine Reihe von Instrumenten zur Verfügung, mit Hilfe derer Einfluss auf die wirtschaftliche Entwicklung innerhalb und außerhalb des Währungsraums genommen werden kann. Einen Überblick über die verschiedenen Instrumente geben die Artikel zu Geldpolitik und Währungspolitik. Die monetäre Ordnungspolitik teilt sich in währungspolitische und geldpolitische Instrumente auf.

Gegenstand der Währungspolitik ist die Regelung der Beziehungen zwischen der eigenen Währung der Volkswirtschaft und den Währungen anderer Währungsgebiete. Die Wahl der Währungspolitik hängt mit dem Wechselkurssystem zusammen in das die Währung eingebunden ist. In einem System fester Wechselkurse sind regelmäßige Interventionen erforderlich. Wenn ein Currency Board installiert wurde, hat die Zentralbank keine Freiheiten in ihrer Geldpolitik mehr.


Unter Geldpolitik wird eine Politik verstanden, die die allgemeine Wirtschaftspolitik unterstützt indem sie das Geldangebot und indirekt die Geldnachfrage sowie die Kreditnachfrage steuert. Das Geldangebot kann gesteuert werden, indem gegen Sicherheiten Geld verliehen wird. Dazu stehen verschiedene Instrumente, etwa Diskontpolitik, Pensionsgeschäfte, Lombardpolitik oder Spitzenrefinanzierung, zur Verfügung. Darüber hinaus gibt es noch weitere Instrumente, wie die Mindestreserve- oder Offenmarktpolitik, die Einfluss auf das Geldangebot nehmen. Die Geld- und Kreditnachfrage wird in erster Linie durch die Zinspolitik gesteuert.


Die Unabhängigkeit einer Zentralbank wird häufig von den vielfältigen wirtschaftlichen und politischen Verflechtungen eines Wirtschaftssystem beeinträchtigt. Eine Zentralbank kann von den Weisungen der Regierung unabhängig sein (bspw. Deutsche Bundesbank oder amerikanische Federal Reserve System), sie kann aber auch von der Staatsregierung weisungsgebunden sein (Banca d’Italia, People’s Bank of China). Ist eine Zentralbank von Weisungen der Regierung abhängig, so ist der Staat der eigentlich Verantwortliche für die Geld- und Währungspolitik.
Die Unabhängigkeit der Zentralbank dient dazu, zu vermeiden, dass die Regierung eine zu expansive Geldpolitik betreibt. Regierungen neigen zu expansiver Geldpolitik, weil sie so kurzfristig bessere Wirtschaftsdaten erzielen und so mehr Zustimmung erhalten können. Die negativen Folgen einer expansiven Geldpolitik werden in der Regel nicht der Regierung angelastet. Einige monetäre Effekte unterschiedlicher institutioneller Ausgestaltungen der Zentralbanken, insbesondere im Bezug auf die Inflation, sind empirisch nachvollziehbar. Soll der Zentralbankgewinn im nennenswerten Umfang zur Finanzierung des Staates beitragen, ist es hilfreich die Zentralbank unmittelbar der Regierung zu unterstellen.
Hinsichtlich des Grads der (Un-)Abhängigkeit einer Zentralbank gegenüber der Regierung ist international ein breites Gestaltungsspektrum zu beobachten. Gründe hierfür sind zum einen die unterschiedlichen Definitionen von Unabhängigkeit, zum anderen aber auch die geschichtlichen Erfahrungen der jeweiligen Länder mit ihren Zentralbanken. Preisniveaustabilität ist das vorrangige Ziel der supranationalen EZB. Da ihr diese Aufgabe durch den Vertrag von Maastricht vorgeschrieben ist, befindet sich die EZB in einer Zielabhängigkeit. In Bezug auf die Realisierung dieses Ziels durch den Einsatz verschiedener geldpolitischer Instrumentarien ist sie jedoch weisungsunabhängig, d. h., sie besitzt Instrumentenunabhängigkeit.

Unter Zielabhängigkeit (goal dependence) versteht man, dass die Regierung die Ziele der Zentralbank beeinflussen kann. Ist bspw. die Preisstabilität als oberes Ziel der Zentralbank gesetzlich vorgegeben, liegt eine Zielabhängigkeit vor. Kann die Zentralbank hingegen ihre Aufgaben selbst festlegen, handelt die Zentralbank zielunabhängig.

Unter Instrumentenabhängigkeit (instrument dependence) versteht man, in welchem Maße die Regierung die Zentralbank bei der Zielerreichung beeinflusst. Ist die Zentralbank bei der Wahl ihres geldpolitischen Instrumentariums weisungsabhängig, d. h., entscheidet die Regierung, welche Instrumente bei der Erreichung der Geldwertstabilität eingesetzt werden, spricht man von Instrumentenabhängigkeit. Kann die Zentralbank ihre geldpolitischen Instrumente frei wählen, handelt sie instrumentenunabhängig.

Kritiker meinen, das geltende Mischgeld-Bankensystem, an dem Geschäftsbanken und eine Zentralbank beteiligt sind, führe zu schlechteren Ergebnissen hinsichtlich Geldwertstabilität und Inflationsrate als ein Modell marktförmiger Geldschöpfung. Nach dem marktwirtschaftlichen Modell des Mehrbankensystems ohne Zentralbank finde hingegen eine systembedingte Kontrolle der Geldschöpfung statt. Die gegenwärtigen Beschränkungen durch
führten zu geldmengeninduzierten Finanzkrisen, da die Zentralbank durch planwirtschaftliche Geldmengensteuerung in den Wettbewerb eingreife.

Der Wirtschaftswissenschaftler Kevin Dowd vertrat 1994 die Ansicht, dass das Finanzsystem ohne staatliche Eingriffe stabiler sei als es in seiner jetzigen Form ist. Es sei entgegen verbreiteter Annahmen in sich stabil und benötige weder einen Lender of last resort noch ein staatliches Einlagensicherungssystem. Eine Quelle der Instabilität im gegenwärtigen System sei, dass die Zentralbanken nicht genügend Signale erhalten, um eine funktionierende Politik etablieren zu können und somit die Politik die tatsächlich umgesetzt wird schädliche Auswirkungen nach sich zieht. Als Beispiel nennt er das Federal Reserve System, das in den 1930er Jahren seiner Rolle als Lender of Last Resort nicht nachkam.

In seinem Werk Human Action vertrat Ludwig von Mises 1949 die Auffassung, dass die zyklischen Auf- und Abschwünge der Wirtschaft, und damit auch die Entstehung von Depressionen, das Ergebnis der Senkung des Zinssatzes durch die Expansion von Krediten seitens der Banken ist. Dies wird als Überinvestitionstheorie bezeichnet. Durch die damit zusätzlich zur Verfügung stehenden Darlehen werde versucht, die Konjunktur künstlich zu beleben. Von Mises sieht die Gefahr, dass dadurch Kredite in Wirtschaftszweige und Geschäfte fließen, die vor der Senkung des Zinssatzes als unrentabel erschienen. Er vertritt die Ansicht, dass die so angekurbelte Wirtschaft früher oder später zusammenbrechen müsse. Die Krediterweiterungspolitik von Banken sei somit eine Fehlleitung der Unternehmenstätigkeit. Von Mises kommt zu dem Ergebnis, dass periodisch wiederkehrende Wirtschaftskrisen nur zu verhindern seien, wenn man auf die Ankurbelung der Wirtschaft durch die Bankpolitik verzichten würde. Vielmehr sollte der Zinsfuß durch den Marktmechanismus geregelt werden.

Auch Friedrich August von Hayek, wie Mises ein Vertreter der Österreichischen Schule, sah 1976 den Grund für die Instabilität der Wirtschaft darin, dass eine expansive Geldpolitik zu Investitionen in an sich unrentable Projekte führt, die früher oder später bereinigt werden müssen. In einer späteren Schaffensperiode machte er als Ursache für die expansive Geldpolitik aus, dass die Verfügbarkeit des Geldes nicht durch den Marktprozess bestimmt, sondern durch die Zentralbanken reguliert wird. Hayek fordert, die Aufgaben der Zentralbanken in private Hände zu geben und zu dezentralisieren. Ein solches System wird als Free Banking bezeichnet. Der Zinssatz würde dann wie jeder andere Preis durch die Nachfrage und das Angebot nach Geld auf dem Markt bestimmt werden. Selbst unter den Laissez-faire-Befürwortern ist nur eine Minderheit für die Realisierung eines Free Banking.




</doc>
<doc id="5761" url="https://de.wikipedia.org/wiki?curid=5761" title="Zeit">
Zeit

Die Zeit ist eine physikalische Größenart. Das allgemein übliche Formelzeichen der Zeit ist "t", ihre SI-Einheit ist die Sekunde s.

Die Zeit beschreibt die Abfolge von Ereignissen, hat also im Gegensatz zu anderen physikalischen Größen eine eindeutige, unumkehrbare Richtung. Mit Hilfe der physikalischen Prinzipien der Thermodynamik kann diese Richtung als Zunahme der Entropie, d. h. der Unordnung in einem abgeschlossenen System bestimmt werden. Aus einer philosophischen Perspektive beschreibt die Zeit das Fortschreiten der Gegenwart von der Vergangenheit kommend und zur Zukunft hinführend. Nach der Relativitätstheorie bildet die Zeit mit dem Raum eine vierdimensionale Raumzeit, in der die Zeit die Rolle einer Dimension einnimmt. Dabei ist der Begriff der Gegenwart nur in einem einzigen Punkt definierbar, während andere Punkte der Raumzeit, die weder in der Vergangenheit noch der Zukunft dieses Punkts liegen, als „raumartig getrennt“ von diesem Punkt bezeichnet werden.

Im SI-Einheitensystem ist die Zeit eine von mehreren Basisgrößen, aus denen weitere Größen aufgebaut werden können.

Die bürgerliche Zeit (UT, MEZ usw.) richtet sich annähernd nach dem Sonnenstand und ist durch staatliche Regelungen innerhalb einer gewissen Zeitzone einheitlich.

In der Philosophie fragt man seit jeher nach dem "Wesen der Zeit", was auch Themen der Weltanschauung berührt. Für die physikalischen, die Bio- und Humanwissenschaften ist die Zeit ein zentraler, auch messtechnisch erfassbarer Parameter, u. a. bei allen bewegten Körpern (Dynamik, Entwicklung), in der Chronobiologie oder der Zeitsoziologie. Die Psychologie untersucht die Zeitwahrnehmung und das Zeitgefühl. Die Ökonomie betrachtet Zeit auch als Wertgegenstand. In den Sprachwissenschaften bedeutet „Zeit“ die grammatische Form der Zeitwörter, das Tempus.

Die wohl markanteste Eigenschaft der Zeit ist der Umstand, dass es stets eine in gewissem Sinne aktuelle und ausgezeichnete Stelle zu geben scheint, die wir die Gegenwart nennen, und die sich unaufhaltsam von der Vergangenheit in Richtung Zukunft zu bewegen scheint. Dieses Phänomen wird auch als das Fließen der Zeit bezeichnet. Dieses Fließen entzieht sich jedoch einer naturwissenschaftlichen Betrachtung, wie im Folgenden dargelegt wird. Auch die Geisteswissenschaften können die Frage nicht eindeutig klären.

Der Unterschied bzw. Nicht-Unterschied zwischen Raum und Zeit ist der Hauptgegenstand der Relativitätstheorien Albert Einsteins:

Die Zeit dient in der Physik in analoger Weise zur Beschreibung des Geschehens wie der Raum. Die Physik besagt lediglich, dass unter allen denkbaren Strukturen im dreidimensionalen Raum in Kombination mit allen dazu denkbaren zeitlichen Abläufen nur solche beobachtet werden, die den physikalischen Gesetzen gehorchen. Dabei könnte es sich ebenso gut um unbewegliche Strukturen in einem vierdimensionalen Raum handeln, die durch die physikalischen Gesetze bestimmten geometrischen Bedingungen unterworfen sind. Nach Newton ist dabei die Struktur der Raumzeit vorgegeben, wobei die Zeit absolute Bedeutung hat; nach Albert Einstein gilt eine spezielle „Relativität der Gleichzeitigkeit“. Etwas, das man als Fließen der Zeit interpretieren könnte, kommt in der Physik nur durch wahrscheinlichkeitstheoretische Begriffe vor, die mit dem Begriff der Entropie zusammenhängen (siehe unten), obwohl die Begriffe Vergangenheit, Gegenwart und Zukunft in den Einsteinschen Theorien mathematisch-präzise sind und messbare Bedeutung haben. Bei genauer Betrachtung erweist es sich aber zunächst als völlig unklar, wie ein Fließen der Zeit in der Sprache der Physik oder Mathematik oder irgendeiner anderen Wissenschaft präzise beschrieben werden könnte.

So ist beispielsweise die Aussage, dass die Zeit fließe, nur dann sinnvoll, wenn eine davon unterscheidbare Alternative denkbar ist. Die naheliegende Alternative der Vorstellung einer stehenden Zeit, beispielsweise, führt jedoch zu einem Widerspruch, da sie nur aus der Sicht eines Beobachters denkbar ist, für den die Zeit weiterhin verstreicht, sodass der angenommene Stillstand als solcher überhaupt wahrnehmbar ist (siehe auch Kritik der reinen Vernunft von Immanuel Kant): "Könnte man die Zeit anhalten, für wie lange „stünde“ dann die Zeit?"

Das scheinbare Fließen der Zeit wird daher von vielen Physikern und Philosophen als ein subjektives Phänomen oder gar als Illusion angesehen. Man nimmt an, dass es sehr eng mit dem Phänomen des Bewusstseins verknüpft ist, das ebenso wie dieses sich einer physikalischen Beschreibung oder gar Erklärung entzieht und zu den großen Rätseln der Naturwissenschaft und Philosophie zählt. Damit wäre unsere Erfahrung von Zeit vergleichbar mit den Qualia in der Philosophie des Bewusstseins und hätte folglich mit der Realität primär ebenso wenig zu tun wie der phänomenale Bewusstseinsinhalt bei der Wahrnehmung der Farbe Blau mit der zugehörigen Wellenlänge des Lichts.

Hinfällig wäre damit unsere intuitive Vorstellung, es gäbe eine von der eigenen Person unabhängige Instanz nach Art einer kosmischen Uhr, die bestimmt, welchen Zeitpunkt wir alle im Moment gemeinsam erleben, und die damit die Gegenwart zu einem objektiven uns alle verbindenden "Jetzt" macht.

In der Physik ist Zeit (Formelzeichen: "t" oder τ, von lat. "tempus" (Zeit)) die fundamentale Größe, über die sich zusammen mit dem Raum die Dauer von Vorgängen und die Reihenfolge von Ereignissen bestimmen lassen. Da sie sich bisher nicht auf grundlegendere Phänomene zurückführen lässt, wird sie über Verfahren zu ihrer Messung definiert, wie es auch bei Raum und Masse der Fall ist. Im SI-Einheitensystem wird Zeit in Sekunden (Einheitenzeichen s) gemessen. Daraus leiten sich unmittelbar die Einheiten Minute und Stunde ab, mittelbar (über die Erdbewegung und gesetzlich festgelegte Schaltsekunden) auch Tag und Woche, dazu (abhängig vom Kalender) Monat, Jahr, Jahrzehnt, Jahrhundert und Jahrtausend.

Die Zeitmessung ist eine der ältesten Aufgaben der Astronomie. Dort wird zwischen einem Sonnentag (bürgerliche Zeit) und einem Sterntag unterschieden, welche im Jahr um einen Tag differieren. Der Sonnentag hat keine ganze Anzahl von Sekunden nach SI; der Unterschied wird durch Schaltsekunden ausgeglichen. Diese Probleme führten zur Einführung verschiedener Zeitskalen:
Astronomische Daten und Zeiten werden oft zweckmäßig als Julianisches Datum (JD) oder modifiziert als Modifiziertes Julianisches Datum (MJD) angegeben.

Heute ist die Zeit in der Physik, wie andere Messgrößen auch, operational, das heißt über ein Messverfahren, definiert. Zur Zeitmessung werden hauptsächlich Systeme verwendet, die periodisch in denselben Zustand zurückkehren. Die Zeit wird dann durch das Zählen der Perioden bestimmt. Ein solches Gerät nennt man Uhr. Doch auch monotone Bewegungen können Basis der Zeitmessung sein, z. B. bei den früheren Sand- und Wasseruhren.
Eine Uhr ist umso besser, je genauer der periodische Vorgang reproduzierbar ist und je weniger er sich von äußeren Bedingungen beeinflussen lässt, beispielsweise von mechanischen Störungen, wie der Temperatur oder dem Luftdruck. Daher sind Quarzuhren deutlich präziser als mechanische Uhren. Die genauesten Uhren sind Atomuhren, die auf atomaren Schwingungs­prozessen beruhen. Damit ist ein relativer Gangfehler von 10 erreichbar, was einer Sekunde Abweichung in 30 Millionen Jahren entspricht. Die Zeit und damit auch die Frequenz, ihr mathematischer Kehrwert, sind die physikalischen Größen, die mit der höchsten Präzision überhaupt messbar sind, was dazu geführt hat, dass die Definition der Länge mittlerweile auf die der Zeit zurückgeführt wird, indem man den Meter als diejenige Strecke definiert, die das Licht im Vakuum während 1/299.792.458 Sekunden zurücklegt.

Isaac Newton beschreibt das Phänomen der Zeit mit den folgenden Worten:
Der grundlegende Begriff der „absoluten Zeit“ galt in der Physik lange als „selbstverständlich zutreffend“, von etwa 1700 bis zum Jahr 1905, d. h. bis zur Formulierung der speziellen Relativitätstheorie durch Albert Einstein. Der Newtonsche Zeitbegriff liegt auch heute noch dem Alltagsverständnis des Phänomens zugrunde, obwohl sich durch viele Präzisionsmessungen (in Verbindung mit scharfen logischen Schlüssen) erwiesen hat, dass nicht Newton, sondern Einstein „Recht hatte“.

Obwohl die Energie-Zeit-Unschärferelation formula_1 auf den ersten Blick die Form der Heisenbergschen Unschärferelation besitzt, ist sie anderer Natur. In der Quantenmechanik ist die Zeit formula_2 ein Parameter. Einen Operator formula_3 für die Zeit gibt es nicht. Bei Versuchen, ihn einzuführen, stößt man auf Widersprüche.

Durch die Entdeckungen im Zusammenhang mit der Relativitätstheorie musste der newtonsche Begriff der absoluten Zeit aufgegeben werden. So beurteilen Beobachter, die sich relativ zueinander bewegen, zeitliche Abläufe unterschiedlich. Das betrifft sowohl die Gleichzeitigkeit von Ereignissen, die an verschiedenen Orten stattfinden, als auch die Zeitdauer zwischen zwei Treffen zweier Beobachter, die sich zwischen diesen Treffen relativ zueinander bewegen (Zeitdilatation). Da es kein absolut ruhendes Koordinatensystem gibt, ist die Frage, welcher Beobachter die Situation korrekt beurteilt, nicht sinnvoll. Man ordnet daher jedem Beobachter seine sogenannte Eigenzeit zu. Ferner beeinflusst die Anwesenheit von Massen den Ablauf der Zeit, sodass diese an verschiedenen Orten im Gravitationsfeld unterschiedlich schnell verstreicht. Damit ist Newtons Annahme, die Zeit verfließe ohne Bezug auf äußere Gegenstände, nicht mehr haltbar.

Zeit und Raum erscheinen in den Grundgleichungen der Relativitätstheorie fast völlig gleichwertig nebeneinander und lassen sich daher zu einer vierdimensionalen Raumzeit vereinigen. Mathematisch hat man es aber nicht mit einem vierdimensionalen Euklidischen Raum zu tun, dem formula_4, sondern mit einem sog. Minkowski-Raum formula_5. In diesem Raum haben nicht x und ct analoge metrische Struktur, sondern z. B. x und ict, wobei c die Lichtgeschwindigkeit und i die „imaginäre Einheit“ der komplexen Zahlen ist. Raum und Zeit sind also auch in der speziellen Relativitätstheorie nicht völlig identisch, sondern es bleibt die Möglichkeit des thermodynamischen Verhaltens, siehe unten.

Im dreidimensionalen Raum ist die Wahl der drei Koordinatenachsen willkürlich, sodass Begriffe wie links und rechts, oben und unten, vorne und hinten relativ sind. In der speziellen Relativitätstheorie stellt sich heraus, dass auch die Zeitachse nicht absolut ist. So verändern sich mit dem Bewegungszustand eines Beobachters auch die Orientierung seiner Zeit- und Raumachsen in der Raumzeit. Es handelt sich dabei um eine Art Scherbewegung dieser Achsen, die mathematisch mit den Drehungen nahe verwandt ist. Damit lassen sich Raum und Zeit nicht mehr eindeutig trennen, sondern hängen in nichttrivialer Weise voneinander ab (sog. Lorentztransformationen). Die Folge sind Phänomene wie Relativität der Gleichzeitigkeit, Zeitdilatation und Längenkontraktion. Diese im Zusammenhang mit der Relativitätstheorie entdeckten Eigenschaften von Zeit und Raum entziehen sich weitgehend der Anschauung. Sie sind jedoch mathematisch präzise beschreibbar und – soweit experimentell zugänglich – auch bestens bestätigt. Allerdings lässt sich durch eine Bewegung die Zeitachse nicht umdrehen, das heißt, Vergangenheit und Zukunft lassen sich nicht vertauschen; die entstehende Theorie behält die grundlegende Eigenschaft der Kausalität.

Zeit ist in der allgemeinen Relativitätstheorie nicht unbedingt unbegrenzt. So gehen viele Physiker davon aus, dass der Urknall nicht nur der Beginn der Existenz von Materie ist, sondern auch den Beginn von Raum und Zeit darstellt. Nach Stephen W. Hawking hat es einen Zeitpunkt „eine Sekunde vor dem Urknall“ ebenso wenig gegeben wie einen Punkt auf der Erde, der 1 km nördlich des Nordpols liegt.

Martin Bojowald entwickelte 2008 jedoch im Rahmen der Schleifenquantengravitation (SQG) eine Theorie, nach der das Universum auch vor dem Urknall schon existierte. Die üblichen kosmologischen Modelle der Allgemeinen Relativitätstheorie haben dabei ihre Grenzen aufgrund der dargestellten Singularität.

Die erwähnten relativistischen Effekte lassen sich im Prinzip als Zeitreisen interpretieren. Inwieweit über die Krümmung der Raumzeit und andere Phänomene auch Reisen in die Vergangenheit prinzipiell möglich sind, ist nicht abschließend geklärt. Mögliche Kandidaten sind sogenannte Wurmlöcher, die Bereiche der Raumzeit mit unterschiedlicher Zeit verbinden könnten, ferner spezielle Flugbahnen in der Umgebung eines hinreichend schnell rotierenden Schwarzen Loches und schließlich die Umgebung zweier kosmischer Strings, die hinreichend schnell aneinander vorbeifliegen. Der erforderliche Aufwand für eine praktische Nutzung einer dieser potenziellen Möglichkeiten würde jedoch die heutigen Mittel der Menschheit bei Weitem übersteigen.

Die bei Reisen in die Vergangenheit auftretenden Paradoxe ließen sich im Rahmen der Everettschen Vielwelten-Theorie vermeiden. Danach wäre die Vergangenheit, in die man reist, in einer Parallelwelt angesiedelt. Der ursprüngliche Ablauf der Dinge und der durch die Zeitreise modifizierte würden sich beide parallel und unabhängig voneinander abspielen.

Der Zeitbegriff hängt eng mit dem Kausalitäts­begriff zusammen. So betrachten wir es als selbstverständlich, dass die Ursache vor ihrer Wirkung auftritt, genauer gesagt wird jeder Beobachter von korrelierten Ereignissen den Vorgang so beschreiben, dass in seinem Modell des Vorgangs die Wirkung durch die Ursache bedingt ist. Die Vergangenheit ist unveränderlich, sie kann nicht von gegenwärtigen Ereignissen beeinflusst werden. Die Zukunft hingegen hängt von der Gegenwart kausal ab, kann also durch Ereignisse oder Handlungen in der Gegenwart beeinflusst werden.

In der Relativitätstheorie wird die zeitliche Reihenfolge mancher Ereignisse, die an verschiedenen Orten stattfinden, von relativ zueinander bewegten Beobachtern unterschiedlich beurteilt. Das ist genau dann der Fall, wenn die beiden Ereignisse nur durch ein Signal mit Überlichtgeschwindigkeit in Kontakt treten könnten. Könnte eine Wechselwirkung mit Überlichtgeschwindigkeit stattfinden, dann könnte man mit folgendem System eine Botschaft in die Vergangenheit schicken:
Daher wäre das Kausalitätsprinzip verletzt. Mitte des 20. Jahrhunderts wurde vermutet, dass es überlichtschnelle Tachyonen geben könnte. Sollten sie mit gewöhnlicher Materie in Wechselwirkung treten können, so wäre die Kausalität verletzt. Die Hypothese der Existenz von Tachyonen hat daher kaum Anhänger.

Die Gesetze der Physik, die den Grundkräften der Phänomene unseres Alltags zugrunde liegen, sind invariant bezüglich einer Inversion der Zeit. Das bedeutet, dass zu jedem Vorgang, der diesen Gesetzen gehorcht, auch der zeitumgekehrte im Prinzip möglich ist. Diese Aussage steht im Widerspruch zu unserer Alltagserfahrung. Fällt eine Keramiktasse zu Boden, so zerbricht sie in Scherben. Dass sich umgekehrt diese Scherben von selbst wieder zu einer intakten Tasse zusammenfügen, ist dagegen noch nie beobachtet worden. Ein solcher Vorgang stünde jedoch nicht prinzipiell im Widerspruch zu den Naturgesetzen. Er ist lediglich extrem unwahrscheinlich.

Der Hintergrund dieses Umstandes ist eine Wahrscheinlichkeits­überlegung, die im zweiten Hauptsatz der Thermodynamik formuliert wird. Danach nimmt die Entropie, welche das Maß der Unordnung eines abgeschlossenen Systems angibt, stets zu und damit seine Ordnung ab. Eine vorübergehende Zunahme der Ordnung ist prinzipiell nicht ausgeschlossen, aber je nach Größe mehr oder weniger unwahrscheinlich. Um die spontane Wiedervereinigung von Scherben zu einer Tasse zu provozieren, müsste man eine mehr als astronomische Zahl von Scherbenhaufen anlegen und beobachten.

Der zweite Hauptsatz der Thermodynamik – und die damit zusammenhängenden Reibungsphänomene – verletzen also die Symmetrie bezüglich der beiden Richtungen der Zeit. Er lässt sich daher auch nicht aus den Grundgesetzen der Physik herleiten, sondern hat die Eigenschaft eines Postulats. Die beiden Richtungen der Zeit verlieren damit ihre Gleichwertigkeit, und man spricht vom thermodynamischen Zeitpfeil. Er wird als potenzielle Basis für das Fließen der Zeit von der Vergangenheit in die Zukunft angesehen, so wie wir es in unserer Alltagswelt erfahren.

Oft ist in diesem Zusammenhang von einer Umkehrbarkeit oder Unumkehrbarkeit der Zeit die Rede. Dabei handelt es sich jedoch um eine sprachliche und logische Ungenauigkeit. Könnte jemand die Zeit umkehren, dann sähe er sämtliche Vorgänge rückwärts ablaufen. Dieser umgekehrte Lauf der Zeit wäre aber nur aus der Sicht eines Beobachters erkennbar, der einer Art persönlicher Zeit unterworfen ist, die weiterhin unverändert vorwärts läuft. Eine solche Spaltung der Zeit in eine, die einem Experiment oder Gedankenexperiment unterworfen wird, und eine weitere unveränderte, hat jedoch keinen Sinn.

Die Gesetze der Physik, die die Phänomene der schwachen und starken Wechselwirkung beschreiben, sind nicht invariant bezüglich einer Zeitumkehr. Zu einem Prozess im Bereich der Kern- und Elementarteilchenphysik ist der zeitumgekehrte daher nicht unbedingt mit den Gesetzen der Physik verträglich. Das CPT-Theorem besagt, dass der Prozess wieder in Einklang mit den Naturgesetzen steht, wenn er nicht nur zeitumgekehrt, sondern zusätzlich spiegelbildlich betrachtet und aus Antimaterie aufgebaut wird. Aus dem CPT-Theorem folgt, dass Prozesse, welche eine sogenannte CP-Verletzung darstellen, wie es bei einigen Teilchenzerfällen der Fall ist, nicht invariant bezüglich einer Zeitumkehr sein können.

Im Formalismus der Beschreibung von Antimaterie sind Antiteilchen gleichwertig zu gewöhnlichen Teilchen, die sich in gewissem Sinne rückwärts in der Zeit bewegen. In diesem Sinne hat die Paarvernichtung von einem Teilchen mit seinem Antiteilchen eine formale Ähnlichkeit mit einem einzigen Teilchen, das sich an dieser Stelle in die Vergangenheit zurückzubewegen beginnt, sodass es dort doppelt und in der Zukunft gar nicht existiert.

Es gibt deutliche Hinweise darauf, dass das Phänomen Zeit im Bereich der Planck-Zeit von 10 s seine Eigenschaften als Kontinuum verliert. So führt die konsequente Anwendung der bekannten physikalischen Gesetze zu dem Ergebnis, dass jeder Vorgang, der kürzer ist als die Planck-Zeit, nur einem Objekt zugeordnet werden kann, das sofort zu einem Schwarzen Loch kollabieren muss (siehe Planck-Einheiten). Diese Überlegung zeigt, dass die bekannten physikalischen Gesetze jenseits der Planck-Zeit versagen. Eine Klärung der damit verbundenen Fragen erhofft man sich von einer noch zu entwickelnden Theorie der Quantengravitation, die die beiden fundamentalen Theorien der Physik, die Relativitätstheorie und die Quantenphysik, vereinigen würde. In einer solchen Theorie wäre die Zeit im Bereich der Planck-Zeit möglicherweise quantisiert. So geht man beispielsweise in der Loop-Quantengravitation, einem Kandidaten für die Theorie der Quantengravitation, davon aus, dass das Gefüge der Raumzeit ein vierdimensionales, schaumartiges Spin-Netzwerk darstellt mit „Blasen“ von der Größenordnung der Planck-Einheiten. Allerdings darf man sich diesen „Schaum“ nicht "in" Raum und Zeit eingebettet vorstellen, sondern der Schaum "ist" in dieser Theorie Raum und Zeit.

In der Antike haben sich u. a. die Philosophen Heraklit, Platon, Aristoteles und Augustinus mit dem Begriff der Zeit befasst, in der Neuzeit vor allem Newton, Leibniz, Kant, Heidegger und Bergson.

Heraklits Flussbilder, die vom gleichbleibenden Flussbett symbolisiert werden, in dem aber Alles fließt ("panta rhei"), stehen als Metapher für die Zeit. Unwandelbare periodische Übergänge von Tag und Nacht, also die Beständigkeit des Flusslaufes, und die Dynamik seines Fließens stehen als die "Einheit der Gegensätze".

Für Platon haben Raum und Zeit keine Wesenheit, sondern sind nur bewegte Abbilder des eigentlich Seienden (Ideenlehre). Für Aristoteles ist der Zeitbegriff untrennbar an Veränderungen gebunden, Zeit ist das Maß jeder Bewegung und kann nur durch diese gemessen werden. Sie lässt sich in unendlich viele Zeitintervalle einteilen (Kontinuum).

Augustinus unterscheidet erstmals zwischen einer physikalisch exakten (messbaren) und einer subjektiven, erlebnisbezogenen Zeit. Zeit und Raum entstanden erst durch Gottes Schöpfung, für den alles eine Gegenwart ist. Das Geheimnis der Zeit fasst Augustinus in folgendem Ausspruch zusammen:

„Was also ist ‚Zeit‘? Wenn mich niemand danach fragt, weiß ich es; will ich es einem Fragenden erklären, weiß ich es nicht.“ (Confessiones XI, 14)

Für Isaac Newton bilden Zeit und Raum die „Behälter“ für Ereignisse, sie sind für ihn ebenso real wie gegenständliche Objekte: „Zeit ist, und sie tickt gleichmäßig von Moment zu Moment.“ In der Naturphilosophie dominiert Newtons Auffassung, weil sie ermöglicht, Zeit und Raum unabhängig von einem Bezugspunkt oder Beobachter zu beschreiben.

Im Gegensatz dazu meint Gottfried Wilhelm Leibniz, dass Zeit und Raum nur gedankliche Konstruktionen sind, um die Beziehungen zwischen Ereignissen zu beschreiben. Sie haben kein „Wesen“ und es gebe daher auch keinen „Fluss“ der Zeit. Er definiert die Zeit so: „Die Zeit ist die Ordnung des nicht zugleich Existierenden. Sie ist somit die allgemeine Ordnung der Veränderungen, in der nämlich nicht auf die bestimmte Art der Veränderungen gesehen wird.“

Nach Immanuel Kant ist die Zeit ebenso wie der Raum eine „reine Anschauungsform“ des inneren Sinnes. Sie seien unser Zugang zur Welt, gehörten also zu den subjektiv-menschlichen Bedingungen der Welterkenntnis, in deren Form das menschliche Bewusstsein die Sinneseindrücke erlebt.

Kant schreibt ihr jedoch eine empirische Qualität für Zeitmessungen und entfernte Ereignisse zu. Wir können die Zeit aus unserer "Erfahrung" nicht wegdenken und auch nicht erkennen, ob sie einer – wie auch immer gearteten – Welt an sich zukommt. In ähnlicher Weise beschreibt Martin Heideggers Hauptwerk „Sein und Zeit“ letztere als eine Wirklichkeit, die das Menschsein zutiefst prägt.

Zwischen der subjektiv wahrgenommen Zeit und der objektiv messbaren bestehen oft deutliche Differenzen. Die folgenden Abschnitte sollen diese kurz und übersichtlich darstellen.

Die Wahrnehmung der Zeitdauer hängt davon ab, was in der Zeit passiert. Ein ereignisreicher Zeitraum erscheint kurz, „vergeht wie im Flug“. Hingegen dauern ereignisarme Zeiträume manchmal quälend lange. Von dieser Beobachtung leiten sich auch die Begriffe Kurzweil und Langeweile ab.

Paradoxerweise empfindet man im Rückblick die Zeiten gerade umgekehrt: In ereignisreichen Zeiten hat man viele Informationen eingespeichert, sodass dieser Zeitraum lange erscheint. Umgekehrt erscheinen ereignisarme Zeiten im Rückblick kurz, da kaum Informationen über sie gespeichert sind.

Gleichzeitigkeit in der Wahrnehmung ist komplexer, als es auf den ersten Blick den Anschein hat. Es gibt verschiedene Schwellen:

Fast alle Lebewesen, bis hin zum Einzeller, besitzen eine biologische innere Uhr, die sich mit dem Tag-Nacht-Wechsel und anderen natürlichen Zyklen synchronisiert. Die innere Uhr zum Tagesrhythmus läuft aber auch ohne Tageslicht, wie an Pflanzen in der Dunkelheit gezeigt werden konnte, aber auch an Menschen in Bunker-Experimenten, in denen die freiwilligen Versuchspersonen ohne jeden Hinweis auf äußere Zeitrhythmen lebten. Dabei stellte sich nach einiger Zeit ein konstanter Wach-Schlaf-Rhythmus von im Mittel etwa 25 Stunden ein. Man bezeichnet ihn als circadianen Rhythmus (von lat. "circa", ungefähr, und lat. "dies", Tag).

Die vergleichende Kulturwissenschaft und die philosophische Reflexion darauf führen immer mehr zu der Einsicht, dass es die Zeit als anthropologische Konstante, die allen Menschen gleicherweise zukommt, überhaupt nicht gibt. Vielmehr existieren kulturspezifische Zeitauffassungen mit diversen Strukturen, wie:

Aus soziologischer Sicht sind Zeitstrukturen notwendig, um die Bürger vom Entscheidungsstress zu entlasten (A. Gehlen), ihre bürgerlichen Pflichten festzusetzen, ihre Angelegenheiten zu verwalten und ihre Handlungen zu koordinieren. Hilfreich dafür sind Kalender mit festgelegten Zeitrhythmen (Jahr, Monate, Wochen, Sonn- und Feiertage usw.) und Funktionen (z. B. kirchlich, national oder international wiederkehrende Anlässe, deren es zu gedenken gilt). Je nach der Komplexität gesellschaftlicher Ordnung werden Zeitfenster zur Einteilung der Lebensalter mit ihren jeweiligen Funktionen bestimmt: Säuglingsalter, Zeit der Kindheit, Jugendlichenalter, Zeit des Erwachsenseins, Greisenalter oder: Kindergartenzeit, Schulzeit, Zeit des Studiums bzw. Lehrzeit, Erwerbsarbeitszeit, Freizeit. Innerhalb dieser gesellschaftlichen Zeitfestlegungen fädeln die Bürger ihre individuellen Biographien auf: z. B. Geburt, Initiationsriten (Taufe o. Ä.), Schuleintritt, schulische Karriere, Studium oder Berufseintritt, Heirat etc.

Welche gesetzliche Zeit an welchem Ort gilt, ist eine politische Entscheidung des jeweiligen Staates. In Deutschland steht das Recht der Zeitbestimmung nach Abs. 1 Nr. 4 GG allein dem Bund zu. Die Zeit in Deutschland wurde bis 12. Juli 2008 durch das Gesetz über die Zeitbestimmung und wird seither durch das Einheiten- und Zeitgesetz geregelt.


Als "Tempus" bezeichnet man die Zeitform in der Grammatik. In verschiedenen Sprachen gibt es unterschiedliche Zeitformen, die unterschiedlich gebildet werden. In der hochdeutschen Sprache wird die Zeit auf drei Weisen dargestellt.

Einen zeitlich anhaltenden Verlauf kann man auch mit Partizip angeben. Beispiel: "das fließende Wasser."

Einen Extremfall stellt die umstrittene Behauptung von Benjamin Lee Whorf dar, der in einer Untersuchung der Sprache der Hopi festgestellt haben will, dass die Hopi-Sprache kein Konzept für den Begriff der Zeit besäße. Dies führte zum "linguistischen Relativitätsprinzip" alias Sapir-Whorf-Hypothese, wonach das Denken von den gesprochenen Sprachen abhängt.

Tempus ist außerdem ein Grundbegriff der Musiktheorie.

Als Musik ist Zeit nicht nur durch das Metrum, zum Beispiel Tempus, zu verstehen, sondern durch die Schwingung selbst und jede denkbare praktische Involvierung. Derart tritt Zeit als elementare Voraussetzung der Musik auf. Musik ist von den Künsten der Zeit am nächsten, was durch entsprechende Stellungnahmen, Musik sei besonders flüchtig und ein „Medium in der Zeit“, betont wird. Musik jenseits der Zeit wird indes von Musikern oft angesteuert und bildet damit einen eigenen theoretischen Horizont.

Klassiker

Wissenschaftsgeschichte

Naturphilosophie

Kulturwissenschaften

Populäre Literatur zur modernen Physik

Artikel




</doc>
<doc id="5762" url="https://de.wikipedia.org/wiki?curid=5762" title="Zwölftontechnik">
Zwölftontechnik

Mit den Begriffen Zwölftontechnik, Reihentechnik und Dodekaphonie (griech. "dodeka" = 12, "phone" = Stimme) werden kompositorische Verfahren zusammengefasst, die von einem Kreis Wiener Komponisten um Arnold Schönberg, der sogenannten „Schönberg-Schule“ oder „Wiener Schule“, in den Jahren um 1920 entwickelt wurden.

Grundlage der Zwölftontechnik ist die Methode des Komponierens "mit zwölf nur aufeinander bezogenen Tönen". Die Zwölftonreihe und ihre regelrechten Modifikationen wurden zum neuen Ordnungsprinzip des musikalischen Materials und lösten in der Folge die keinen spezifischen Regeln unterworfene freie Atonalität ab.

Die „Totalität der Zwölftontechnik“ im Verständnis von Schönberg erfuhr im musiktheoretischen Diskurs der Folgezeit vielfache Erweiterungen. Als „Reihentechnik“ oder „serielle Technik“ beschäftigte sie sich auch mit nicht zwölftönigen Reihen. Die Ausdehnung des Reihenprinzips auf alle Parameter des Tones erweiterte die Zwölftontechnik zur seriellen Technik, die sich in den frühen 1950er Jahren im französisch-, italienisch- und deutschsprachigen Raum verbreitete.

Die "Erfindung" der Zwölftontechnik hat Arnold Schönberg allein sich selbst zugeschrieben. Gleich ihm haben aber auch Komponisten wie Josef Matthias Hauer, Herbert Eimert, Anton Webern, Josef Rufer und Alban Berg in den frühen Jahren wichtige Beiträge zur Entwicklung der Zwölftontechnik geleistet. Josef Matthias Hauer hat 1919 von allen als Erster mit seiner 12tönigen Komposition "Nomos", op. 19 in diesem System komponiert. 

Die Zwölftontechnik hat sowohl in der kompositorischen Praxis als auch im analytischen Denken vielfältige und tiefgreifende Auswirkungen auf die Musik der Moderne und der Avantgarde gehabt. Sie zählt zu den einflussreichsten musikgeschichtlichen Entwicklungen in der westlichen Musik des 20. Jahrhunderts. Da sie sich vom frühesten Anfang an in die verschiedensten Schulen und Individualstile verästelt hat, werden in diesem Artikel Diskussionen und Nachwirkungen nicht geschlossen an den Schluss gestellt, sondern im Zusammenhang mit ihren jeweiligen Auslösern besprochen.

Arnold Schönberg hat in seinem erstmals 1935 gehaltenen Vortrag "Composition With Twelve Tones" eine einfache Einführung in die Zwölftontechnik gegeben.

Oktavlagen und Enharmonische Verwechslungen bleiben bei dieser zunächst abstrakten Reihenformulierung unberücksichtigt; etwa vertritt cis alle anderen Töne cis/Cis, bzw. des/Des.

Eine "Grundreihe" enthält also jeden Ton genau einmal. Dabei wird versucht, die einzelnen Tonreihen zu spiegeln oder auch aufsteigend und absteigend einzusetzen. Die Grundreihe aus Schönbergs "Klavierstück" op. 33a lautet:

Abgeleitet von einer Grundreihe (G) werden
Das ergibt für Schönbergs op. 33a:

In der kompositorischen Umsetzung sind die Oktavlagen der einzelnen Töne frei wählbar. Aus der absteigenden Quart b-f zu Beginn der Grundreihe kann die aufsteigende Quint b-f werden sowie jede andere Kombination von Oktavlagen.

Jede dieser vier Reihenformen kann auf jede der zwölf chromatischen Stufen transponiert werden. Damit steht der Komposition ein Vorrat von insgesamt 48 verschiedenen Reihenformen zu Verfügung, die üblicherweise in einer Reihentabelle zusammengefasst werden.

Schönberg bezeichnete in seinen Kompositionsskizzen die Reihenformen durch Intervallsymbole: K+2 bedeutet Krebs um eine große Sekunde (+2) nach oben transponiert; K−3 dementsprechend um eine kleine Terz (−3) tiefer. Andere Komponisten nummerieren jeweils von 1 bis 12 durch; oder der jeweilige Anfangston wird zur Bezeichnung herangezogen: Grundreihe auf fis; oder KU(e) = Krebsumkehrung mit dem Anfangston/auf e.

Die 48 Reihenformen sind das Material für horizontale (melodische) Abläufe genauso wie für vertikale Bildungen (Akkorde). Mehrere verschiedene Reihenformen können gleichzeitig ablaufen; aus einer Reihe, die eine Melodie bildet, können aber auch Teile in begleitende Akkorde ausgelagert sein. Unmittelbare Tonwiederholungen sind erlaubt, aber weder Oktavsprünge noch Oktavzusammenklänge, auch nicht, wenn zwei chromatisch gleiche Töne in unterschiedlichen Oktavlagen verschiedenen gleichzeitig ablaufenden Reihenformen angehören. Auch Interpolationen sind möglich: Ein Ausschnitt einer anderen Reihenform wird in einen Reihenablauf eingelagert; der Rest dieser anderen Reihenform erscheint an anderer Stelle in der Komposition.

Die erstmals 1950 in New York erschienene Sammlung "Style and Idea" (deutsch 1976 als "Stil und Gedanke)" enthält Schönbergs wichtigste Schriften zur Zwölftontechnik. Es handelt sich um eine Sammlung von Essays und Vorträgen, deren Urfassungen Schönberg größtenteils nach seiner Emigration in die USA auf Englisch geschrieben hatte. Sie befassen sich mit verschiedenen musikalischen, aber auch mit politischen Themen.

Für die Zwölftontechnik sind insbesondere folgende Texte von Bedeutung:

Wesentlich ist außerdem:

Die Thesen dieser Schriften werden im folgenden Kapitel im Zusammenhang mit der Darstellung der Kompositionstechnik besprochen.

In den Notenbeispielen sind die Töne der Reihenformen durch Zahlen neben den Notenköpfen gekennzeichnet. Wie in der oben gegebenen Reihentabelle sind Grundreihe und Umkehrung mit 1 bis 12, die Krebsformen mit 12 bis 1 nummeriert.

Takt 1 bringt die mit b beginnende Grundreihe, zu Vierergruppen zusammengefasst als vierstimmige Akkorde; Takt 2 verfährt entsprechend mit der mit a beginnenden Krebsumkehrung. Die Takte 3 bis 5 schichten zwei Reihenformen übereinander, in der rechten Hand KU(a), in der linken K(e). Entscheidend bei der Zuordnung sind nicht die Spielhand oder das System, in das die Note geschrieben ist, sondern die Instrumentierung: Das dis in Takt 5 wird von der linken Hand gespielt (original mit Violinschlüssel ins untere System notiert), gehört aber in die Reihe KU(a) und ist daher in den klanglich oberen Bereich gesetzt, während die Quart f-b der rechten Hand innerhalb des Gesamtklangs am tiefsten liegt und in die untere Ebene K(e) gehört.

Die Grundreihe läuft im ersten Takt zwar vollständig und korrekt ab, wäre aus ihm allein aber nicht ableitbar. Da sich die Reihe indifferent gegenüber der Oktavlage verhält, also nur eine zeitliche Reihenfolge der Töne definiert, nicht aber ihr räumliches Übereinander, lässt sie sich aus gleichzeitig eintretenden Tönen nicht eindeutig rekonstruieren. Im ersten Akkord sind die ersten vier Reihentöne konsequent von oben nach unten angeordnet, im zweiten ist die Anordnung schon verändert: der gemäß Reihe zeitlich früheste Ton, der 5. (a), ist der tiefste, der folgende 6. (fis) der oberste; die beiden übrigen dieser Vierergruppe liegen in der Mitte. Aus dem Anfangstakt lässt sich also nur ableiten, welche vier Töne den Anfang der Reihe bilden, welche vier die Fortsetzung und welche vier den Schluss, nicht aber, welche Reihenfolge innerhalb der Vierergruppen gilt. In vielen zwölftönigen Kompositionen muss die vom Komponisten gemeinte Folge aus verschiedenen Stellen rekonstruiert werden.

Ab Takt 3 laufen die Reihenformen im Prinzip als melodische Bildungen ab (vor allem Anfang von Takt 4, Anfang von Takt 5; jeweils rechte Hand), sind aber mehrfach als Zusammenklänge ineinandergeschoben: in Takt 3 werden in der rechten Hand die Töne 12 bis 9 nacheinander angeschlagen, aber gehalten, so dass sie sich zu einem Akkord zusammensetzen; in der Linken treten die Töne 12 und 11 sofort als Zusammenklang ein.

Die Takte 14 bis 18 zeigen einen freieren Umgang mit der Reihenfolge der Töne:

Konsequent einstimmig ist die untere Schicht U(es); die obere G(b) (die in Takt 17 und 18 in der originalen Partitur teilweise ins untere System notiert und von der linken Hand zu spielen ist) ist zu drei- und zweistimmigen Gebilden zusammengeschoben. In Takt 14 läuft die Grundreihe in der rechten Hand bis zum 5. und 6. Ton und daraufhin wieder zurück zum Anfang; Takt 15 ist eine fast wörtliche Wiederholung. Die strenge Reihenfolge der Töne steht also durchaus zur Disposition. Ähnlich die untere Schicht vom letzten Viertel des Taktes 16 bis zum Anfang von Takt 18: Die Töne 7 und 8 werden in der normalen Reihenfolge eingeführt, nach einem Rückgriff auf 7 und wiederum 8 erscheint 9. Nach dem 10. Ton F beginnt beim Übergang zu Takt 18 wieder die Folge 7-8-9. – Zu beachten ist die Stimmkreuzung zwischen den Reihen in Takt 15: Der 3. Ton der unteren Ebene des liegt über dem h der oberen Ebene. Der Unterschied in der Artikulation ist allerdings deutlich genug, um keinen Zweifel über die Zusammenhänge aufkommen zu lassen; auch wird der Pianist vermutlich die untere Ebene leicht hervorheben.

An diesen Takten wird die Problematik der Aussage deutlich, die Reihe organisiere sowohl die horizontalen (melodischen) Bezüge als auch die vertikalen (akkordischen). Die genauere Fassung lautet: Die Reihe organisiert entweder das eine oder das andere; beides gleichzeitig ist nicht möglich. Die kleine Sept es-des in der rechten Hand in Takt 16 wird gebildet aus dem 7. und 8. Reihenton, ähnlich die große Sept as-g im folgenden Takt aus 9 und 10. Dadurch entsteht in der Oberstimme aus dem 7. und 9. Ton, also zwei in der Reihe an sich nicht als benachbart vorgesehenen Tönen, eine sehr auffällige melodische Bewegung des-g. Ähnlich ist in Takt 14 der Akkord c-f-b der rechten Hand durch die Zusammenrückung der ersten drei Töne der Grundreihe gebildet (freilich entsteht schon drei Achtel später durch das Überhalten des Tons b die reihenfremde Zusammensetzung 1-6-5), aber mit Eintritt des Tons es in der linken Hand entsteht aus der Übereinanderschichtung zweier unterschiedlicher Reihenformen ein Akkord, der keiner Reihenform entstammt.

Als Schönberg das schrieb, war die Vermeidung der Tonalität noch ein virulentes Problem. Die Hörweisen nicht nur der Hörer, sondern auch der Komponisten waren durch eine traditionelle Musiksprache geprägt; die heute im musikalischen Hören gewöhnlich gewordene Atonalität wirkte fremd und für viele Hörer erschreckend. Zwar waren auch vor Schönbergs Ankunft in den USA die amerikanischen Komponisten Henry Cowell und Charles Ives bereits zu atonalen Strukturen vorgestoßen; eine Breitenwirkung zumindest in musikalischen Kreisen, wie sie dann von Schönbergs Zwölftontechnik ausgehen sollte, war ihnen aber versagt geblieben. Insofern war Schönbergs Versuch, eine neue musikalische Sprache zunächst durch die Abgrenzung von einer alten, fest etablierten zu stabilisieren, vermutlich nicht nur naheliegend, sondern unvermeidlich.

Schönberg ist mit seiner Berufung auf seine "Harmonielehre" von 1911 allerdings ein aufschlussreicher Gedächtnisfehler unterlaufen. Seine Argumentation in dem um Jahrzehnte älteren Buch beschäftigt sich tatsächlich mit Wiederholungen von Tönen in reinen Tonsatzübungen zur traditionellen tonalen Musik (also kurzen Akkordfolgen ohne künstlerischen Anspruch)
Es folgt eine Reihe von Fällen, in denen eine Tonwiederholung innerhalb einer Tonsatzübung kein oder nur ein geringes Problem ist. Dann:
(Vgl. hierzu die ausführliche Analyse von "Mit dem grünen Lautenbande" im Artikel "Die schöne Müllerin.)"

Tatsächlich zeigt eine Analyse von Schuberts "Mit dem grünen Lautenbande", dass der höchste Ton der Melodie Gegenstand einer bewussten Dramaturgie ist: er ist zunächst Ziel einer konsequenten melodischen Aufwärtsentwicklung, erscheint dann noch gesteigert als auffällige Dissonanz, wird schließlich, wenn die Melodie sich in eine andere Richtung entwickelt, spielerisch in die Beiläufigkeit entlassen. Gleichzeitig aber zeigt die Analyse eines anderen Tons als des Hochtons – der also aus dem Inneren des Tonraums stammt –, dass nicht alle Töne so empfindlich auf Wiederholung reagieren, sich daher auch nicht zum Gegenstand einer gezielten Dramaturgie machen lassen.

Ein Komponist der tonalen Musik kann also mit einigen wenigen exponierten Tönen in seinen melodischen Linien spielen. Für alle anderen Töne ist die Tatsache der Wiederholung meistens gleichgültig; viel zu stark sind die Sinnstrukturen, die vor allem durch die Harmonik gesetzt werden. Völlig anders ist die Situation in der Musik, die auf die Sinnstrukturen der Tonalität verzichtet. Béla Bartók baut weite Teile seines vierten Streichquartetts (1928) auf einem Motiv auf, das erstmals im Takt 7 des ersten Satzes im Violoncello auftritt:

Der 4. und 5. Ton sind Wiederholungen des 2. und 1. Wie sehr ihre Wirkung dadurch abgeschwächt ist, zeigt die dramatische Wirkung des Schlusstons b, der neu ist und durch diese Neuheit – nach der Schwäche der vorhergehenden – eine dynamisch forttreibende Wirkung erhält. Nimmt man jedoch die diesem Motiv von Takt 7 vorhergehenden Töne hinzu, dann ändert sich die Wirkung grundlegend:

Das b hat sich in Takt 6 schon ausgebreitet, und es wurde auf vergleichbare Weise erreicht wie der Schlusston, über c und h. Der Schlusston des Motivs, der im ersten Notenbeispiel neu war, ist nun ein wiederholter. In dieser Version kehrt das Motiv in sich zurück, es verliert seine dynamisch-forttreibende Wirkung, es schließt, wirkt wie eine Zusammenfassung des Vorhergehenden. Das hat mit einem Grundton im traditionellen Sinn nicht das geringste zu tun; niemand, der dieses Quartett einmal gehört hat, wird daran zweifeln, dass es durch und durch atonal ist. Dennoch liegt darin eine starke die Töne gewichtende Wirkung; das Schluss-b im ersten Notenbeispiel ist etwas ganz anderes als das Schluss-b im zweiten. Da die Überlagerung durch die starken Sinnstrukturen der Funktionsharmonik fortfällt, verändert die Tatsache der Neuheit oder der Wiederholung in einem atonalen Zusammenhang die Wirkung eines Tones fundamental – und zwar "jedes" Tons, nicht nur einiger Spitzentöne. Die Ergebnisse dieses Phänomens sind für einen die tonale Sprache gewöhnten Komponisten unvorhersehbar – sie werden durch die Verwendung verschiedener Intervalle noch kompliziert – und von einschüchternder Kraft. Ein pathetisch inszenierter Zielton etwa wirkt unerträglich banal (weil nicht durch eine entsprechende Harmonik überdeckt wird, dass er kurz zuvor schon erklang); oder er wirkt gar nicht als Zielton, sondern als Ausgangspunkt für etwas Neues, das der Komponist nicht vorgesehen hat; oder er klingt – horribile dictu in atonaler Musik – einfach falsch. Die Atonalität ist alles andere als ein Land der Gesetzlosigkeit, und ein Komponist, der sich von den Zwängen der Tonalität gerade frei gemacht hat, mithin halb und halb noch darinsteckt, und der nun glaubt, nach Belieben schalten und walten zu können, kann böse Überraschungen erleben.

Im Zitat zu Anfang dieses Kapitels spricht Schönberg eindeutig nicht von der Tonikawirkung innerhalb eines fraglos tonalen, funktionsharmonischen Zusammenhangs – eine solche kommt jedenfalls nicht durch Tonwiederholung zustande –, sondern von Tonwiederholungen in einem atonalen Zusammenhang. Diese werden in der "Harmonielehre" nicht diskutiert. Dennoch hat Schönbergs Hinweis auf das Buch einen wenn auch unabsichtlichen Sinn. Denn als die "Harmonielehre" entstand – sie erschien erstmals 1911 –, tat Schönberg gerade seine ersten Schritte im damals völlig neuen Gebiet der Atonalität; deren erste kompositorische Probleme und die Arbeit an dem Buch, das an anderen Stellen durchaus die neuen Entwicklungen reflektiert, dürften sich in seiner Erinnerung vermischt haben. Noch in der viel späteren Äußerung über die Zwölftontechnik schwingt die exorbitante Anstrengung nach, die, bei aller Entdeckerfreude, die ersten Schritte in die Atonalität zweifellos erforderten, sowie vielleicht die Frustration darüber, dass eine Unzahl engagierter Versuche in klanglichen Wechselbälgern endeten, die die Vorstellungen des Komponisten in keiner Weise wiedergaben. Was Schönberg also als ein Verfahren zur Tonalitätsvermeidung bezeichnet, ist tatsächlich die Reaktion auf eine genuin atonale Problemstellung. Hier scheint sich ein für beide Komponistenpersönlichkeiten bezeichnender Vergleich mit Bartók anzubieten: Bartók, der in den unvorhergesehenen Wirkungen der Töne eine große Chance sah und ihrer konzentrierten Erforschung und Erprobung ganze Streichquartette widmete; Schönberg, der diese Wirkungen zu fürchten gelernt hatte und ein System zu ihrer Vermeidung erdachte.

Aber diese Formulierung trifft den Sachverhalt nicht. Schon weil das System nicht funktioniert.

Wenn etwa in der ersten Reihe cis der 10. Ton ist, in der folgenden Reihe, die eine veränderte Reihenfolge bringt, aber der 3., dann wird cis wiederholt, bevor die übrigen elf Töne vollständig durchliefen, und dadurch unangemessen bevorzugt. Das schlösse aber auch die Verwendung verschiedener Reihenformen aus. Nur solange immer ein- und dieselbe Reihenform hintereinander abläuft, wird die verfrühte Wiederholung eines Tons verhindert; sobald auf eine Reihenform eine andere folgt, rücken Wiederholungen von Tönen unregelmäßig aneinander und auseinander. Vgl. dazu in Takt 2 von op. 33a (Notenbeispiel ) den obersten Ton d des letzten Akkords (4. Ton von KU(a)), der sich schon im folgenden Takt eine Oktave tiefer als erste obere Note der linken Hand wiederholt (11. Ton von K(e)). Ebenso in Takt 3 den letzten Ton der linken Hand G (9. Ton von K(e)), der nur durch zwei Töne von g (Takt 4, rechte Hand, dritte Note; 6. Ton von KU(a)) getrennt ist. Solche Fälle sind häufig. Erst auf größere Strecken hin entsteht durch den Einsatz immer vollständiger Reihenformen eine statistische Gleichverteilung der Töne, falls der Komponist es nicht durch kompositorische Mittel verhindert.

Genau das hat Schönberg immer wieder getan. Das spektakulärste Beispiel ist die "Musette" aus der "Suite" für Klavier op. 25, in deren Anfangs- und Schlussabschnitt ein Ton (g) aus der Reihe ausgliedert ist und als Orgelpunkt ständig mitläuft. Aber darüber hinaus ist die Bildung langer Flächen aus einigen wenigen Reihentönen eines von Schönbergs häufigsten kompositorischen Mitteln. Zu Anfang des 3. Streichquartetts op. 30 wiederholen zweite Violine und Bratsche abwechselnd zwölf Takte lang ein aus fünf Tönen gebildetes Motiv, über dem ab dem 5. Takt die Hauptstimme der ersten Violine steht. Die Takte 19 und 20 des "Klavierstücks" op. 33a lauten so:

Ab dem Ende von Takt 19 entsteht durch ständige Wiederholungen und Rückgriffe von jeweils 4 in ihrer Oktavlage festgelegten Tönen aus K(e) und KU(a) eine harmonisch stehende, aber in sich durch scharf umrissene Rhythmen stark bewegte Fläche. Solche Flächen gehören zu den gewöhnlichsten kompositorischen Mitteln von Schönbergs zwölftönigen Werken. Sie nähern sich in auffälliger Weise Kompositionstechniken Bartóks: Der Tonsatz schießt sich auf ein paar Töne ein, die, mit ganz bestimmten, immer wiederkehrenden Rhythmen verbunden, über eine längere Strecke festgehalten werden, so dass die daraufhin neu eintretenden Töne eine starke Erneuerungswirkung haben. Schönberg wirkt in der Anwendung dieser Mittel allerdings im Allgemeinen nervöser als Bartók; seine Strecken sind kürzer, und oft erscheint ihre Fortführung nicht, wie bei Bartók, als logische Konsequenz, sondern als Affektbruch.

Innerhalb derartiger Passagen wird die Reihenfolge der Töne grundlegend fragwürdig; sie führen aber regelmäßig auch zu einem starken Überwiegen einer bestimmten Gruppe von Tönen über die restlichen zumindest für einen gewissen Zeitraum.

Man muss diese Äußerung nicht ablehnen, es genügt einige Großzügigkeit bei ihrer Interpretation. Wahrscheinlich war Schönberg 1935 noch zu sehr daran interessiert, das Formbildende, Logikstiftende der Zwölftonreihe nach außen hin zu etablieren, als dass er vor einem Publikum, dem die Zwölftontechnik neu war, hätte ausführen wollen, welchen Grad an Freiheit er zu diesem Zeitpunkt schon gewonnen hatte. Nimmt man das "„vielleicht“" und die "„leichte Abweichung“" im zweiten Satz dieses Zitats als starke Verkleinerungen, dann kommt man zu einer durchaus zutreffenden Beschreibung: Am Anfang (und, wie die Tabelle zu op. 33a zeigt, am Schluss) des Stücks werden Reihenfolge und Vollständigkeit der Reihentöne mehr oder weniger präzise beibehalten, in der Mitte des Stücks treten zum Teil tiefgreifende Abweichungen auf.

Schönberg empfand den Verzicht auf die Tonalität nicht nur als Fortschritt.

An einem Buch über "Die formbildenden Tendenzen der [tonalen] Harmonie" hat Schönberg noch bis 1948 gearbeitet. Dass mit dem etwa 1909 erfolgten Übergang in die Atonalität diese formbildenden Tendenzen fortgefallen waren, führte zunächst zur Komposition nur kurzer Stücke; längere Stücke waren auf einen Text angewiesen, der die Formbildung zu übernehmen schien.

Eine Tabelle zeigt den Einsatz der Reihe in Schönbergs "Klavierstück" op. 33a:

Anmerkungen:
Die Aufstellung ist vereinfacht; einzelne Schlusstöne am Taktanfang und Auftakte sowie Sforzati sind nicht berücksichtigt.

Über weite Strecken des Stücks begnügt Schönberg sich mit vier Reihenformen: G(b), K(e), U(es) und KU(a).

Es handelt sich also nur um zwei wirklich verschiedene Reihen, die entweder vorwärts oder rückwärts ablaufen. Sobald zwei Reihenformen gleichzeitig ablaufen, sind das immer die Kombinationen G(b)-U(es) und K(e)-KU(a). Dazu schrieb Schönberg:

Die jeweils ersten sechs Töne der Grundreihe auf b und der Umkehrung auf es (der Anfangston steht also eine Quint tiefer) ergeben sämtliche zwölf chromatischen Töne ohne Wiederholung eines Tons (was automatisch auch für die jeweiligen Töne 7 bis 12 gilt). Damit konnte Schönberg diese beiden Reihenformen gleichzeitig ablaufen lassen, ohne innerhalb der Reihenhälften eine zu frühe Wiederholung eines Tons, der zwei unterschiedlichen Reihenformen angehört, befürchten zu müssen: Takt 14 bis 16 (zweite Note) ergibt ein vollständiges und wiederholungsfreies Zwölftonfeld; ebenso Takt 16 (Einsatz der rechten Hand) bis Ende Takt 18, obwohl die Reihenabläufe für sich genommen unvollständig sind (siehe das Notenbeispiel oben).

Nur in Takt 27 Ende bis Takt 32 Anfang benutzt Schönberg zusätzliche Reihenformen:

Auch hier haben die Anfangstöne der untereinander stehenden Reihenformen den Abstand einer Quint, so dass sie übereinandergeschichtet werden können. G(f)-K(h) und U(b)-KU(e) beziehen sich wiederum als Krebsformen aufeinander.

In Stil und Gedanke schrieb Schönberg:
Die Grundreihe – in op. 33a wohl eher die in den ersten Takten exponierten vier Hauptreihen – fungiert also in etwa wie die Haupttonart traditioneller tonaler Musik: sie bildet einen Ausgangspunkt, von dem das Stück zuerst in andere Tonarten – in andere Reihenformen – wegmoduliert und dann zum Ausgangspunkt zurückmoduliert. Diese Formung ist aus der Anordnung der Reihenformen in op. 33a klar ablesbar. Die Takte 27 bis 32 entsprechen also einem in anderen Tonarten stehenden Mittelteil in der tonalen Musik.
Für die musikästhetische und geschichtsphilosophische Untermauerung der Zwölftontechnik ist der deutsche Philosoph Theodor W. Adorno (1903–1969) zu nennen, der die Zwölftontechnik als "die" progressive Antwort auf die in seinen Augen reaktionär gewordene Tonalität interpretierte und auch selbst Stücke mittels der Zwölftontechnik komponierte. Allerdings war sein Umgang mit den Zwölftonreihen nie so strikt wie etwa bei Schönberg, sondern er verteidigte, auch theoretisch, eine gewisse künstlerische Freiheit, die er durch einen allzu orthodoxen Umgang mit der Zwölftontechnik in Gefahr geraten sah. So erweiterte er z. B. für die Vertonung des Trakl-Gedichts „Entlang“ (op. 5, Nr. 4) die Tonreihe auf 98 Töne. Im Übrigen beriet Adorno Thomas Mann für seinen Roman "Doktor Faustus" musikalisch, insbesondere hinsichtlich der musiktheoretischen Reflexionen über die Zwölftonmusik bzw. -technik.

Eine regelhafte Kodifizierung der um 1920 entstandenen Zwölftontechnik ist nicht vor den vierziger Jahren fassbar. Von den „klassischen“ Komponisten der Zwölftontechnik (Schönberg, Berg, Webern) hat nur Schönberg einen theoretischen Beitrag zur Erklärung der Technik geliefert. Sein erstmals 1935 an der University of Southern California gehaltener Vortrag "Composition With Twelve Tones" wird von Vertretern der regelhaften Zwölftontechnik allerdings als "„zumindest enttäuschend“" empfunden. Nach Schönbergs Emigration im Jahr 1933 und dem Beginn seiner Lehrtätigkeit in den USA verbreitete sich die Zwölftontechnik an amerikanischen Hochschulen, wo sie sehr bald zu einer in hohem Maß verschulten Satztechnik geworden zu sein scheint. Darüber hinaus beriet Schönberg in seinen letzten beiden Lebensjahren Josef Rufer bei der Abfassung von dessen 1952, ein Jahr nach Schönbergs Tod, erschienenem Buch "Die Komposition mit zwölf Tönen" – in einem allerdings nicht mit letzter Genauigkeit bestimmbaren Umfang; Schönberg war nach dem Krieg nicht nach Europa zurückgekehrt, Rufer andererseits nie emigriert. Neben Rufers Buch waren es die Schriften von René Leibowitz ("Schönberg et son école" 1946, "Introduction à la musique de douze sons" 1949), in zweiter Linie auch die Lehrbücher von Herbert Eimert und Hanns Jelinek, die das bis heute in Allgemeinen Musiklehren und Nachschlagewerken verbreitete Bild von der Zwölftontechnik als einer in erster Linie regelhaften Anordnungsanweisung für Noten prägten.

Die Schwächen dieser Regelwerke sind auch ohne analytische Betrachtung bedeutender zwölftöniger Kompositionen offensichtlich: Sie sagen nicht das Geringste über das Funktionieren der Reihentechnik in einer Komposition aus; tendieren vielmehr zur Isolation der Tonhöhenorganisation von anderen Parametern des musikalischen Satzes. Die Betrachtung der geschichtlich prägenden Zwölftonkompositionen – die ja im Großen und Ganzen früher entstanden als das Regelwerk – zeigt, dass keine der Regeln und Anweisungen dieser Lehrbücher mit einiger Zuverlässigkeit von den Komponisten beachtet worden ist, dass die Regeln die Vielfalt der Herangehensweisen auch nicht im Ansatz einzufangen vermögen. Nichtsdestoweniger sind die Regelsysteme zum Ausgangspunkt einer akademischen Kompositionsweise geworden, die, abgesehen von unzähligen Nachfolgern in Europa nach 1945, vor allem um die Mitte des 20. Jahrhunderts an den Hochschulen Nordamerikas verbreitet war. Glenn Gould hat in einem 1974 geschriebenen Aufsatz diese Atmosphäre der Zwölfton-Orthodoxie charakterisiert. 1953 war der in die USA emigrierte Ernst Krenek – als Österreicher und als bekannter Komponist eine Kapazität auf dem Gebiet der Zwölftonkomposition –, zur Abhaltung einer Meisterklasse an das Konservatorium Toronto gekommen, an dem Gould studierte.

Gould lässt keinen Zweifel daran, dass schon geringfügige Abweichungen von der Norm an einer nordamerikanischen Musikhochschule der fünfziger Jahre für Aufsehen sorgten.

1966 erschien der Aufsatz "Zur Theorie einiger Reihen-Kombinationen" von Eberhardt Klemm. Klemm ersetzt in der Grundreihe aus Schönbergs Violinkonzert op. 36 die Töne durch Zahlen: den Anfangston a durch die 0, die weiteren Töne durch die Zahl der Halbtöne, die sie über dem Anfangston stehen (das folgende b also durch eine 1, den dritten Ton es durch eine 6 usw.).

Es folgt eine Reihe algebraischer Transformationen. Klemm bezieht sie nur sporadisch auf real komponierte Strukturen, und der Bezug zu vom Komponisten möglicherweise intendierten künstlerischen Aussagen bleibt locker. "„In der vorliegenden Studie geht es weniger um die Beschreibung kompositorischer Sachverhalte als um theoretische Einsichten in die Struktur der Zwölftonreihen.“"

Klemms Ansatz steht im Zusammenhang mit einem starken Interesse an mathematischen Analysemethoden, das durch die zweite Hälfte des 20. Jahrhunderts anhielt und sich mit dem gesamten verfügbaren Musikrepertoire nicht nur der westlichen Welt befasste. Durchgesetzt hat sich aber die Mitte der sechziger Jahre von Allen Forte begründete Theorie der "pitch class sets", die mehrfach auf Werke der Wiener Schule angewendet wurde.

Durch ihre Affinität zur Algebra ist die regelhafte Zwölftontechnik das früheste Beispiel für moderne Kompositionsmethoden, in der kompositorische Entscheidungen nicht durch das Gehör, sondern mithilfe mathematischer Verfahren gefällt werden. Inwieweit einzelne Komponisten, die zur Definition von Tonhöhenfolgen mehr oder weniger komplizierte mathematische, aber deshalb nicht unbedingt serielle Verfahren verwendeten – vor allem Iannis Xenakis, aber (teilweise) auch György Ligeti –, einer Anregung durch die Zwölftontechnik folgten oder doch eher einem durch den Aufstieg naturwissenschaftlichen Denkens geprägten Zeitgeist, wird sich schon deshalb oft nicht entscheiden lassen, weil keiner dieser Komponisten auf eine Auseinandersetzung sowohl mit der modernen Naturwissenschaft als auch mit der Zwölftontechnik verzichten konnte. Die bekannteste direkte Nachfolge der regelhaften Zwölftontechnik ist die Serielle Musik im Europa der fünfziger Jahre. Ihre Vertreter (Pierre Boulez, Karlheinz Stockhausen, Henri Pousseur und viele weitere) beriefen sich auf Anton Webern, nicht auf Schönberg. Ihre Webern-Analysen sind allerdings seit den siebziger Jahren von verschiedenen Seiten scharf kritisiert worden. In der Seriellen Musik unterliegen nicht nur die Tonhöhen, sondern auch alle anderen Parameter des musikalischen Satzes, wie Tondauer, Lautstärkeangaben, Artikulation usw. der Organisation in voneinander unabhängigen Reihen. Die Zahl Zwölf spielt nur für die Ordnung der chromatischen Töne noch eine Rolle. Vor allem die rhythmischen Verhältnisse geraten dabei aufgrund intrikater Zahlenverhältnisse oft in die Gefahr sowohl der vollständigen Unausführbarkeit als auch der Unüberprüfbarkeit durch den Komponisten.


chronologisch


Zur Aufschlüsselung der Kurztitel vgl. die Literaturliste


</doc>
<doc id="5767" url="https://de.wikipedia.org/wiki?curid=5767" title="Zweiter Weltkrieg">
Zweiter Weltkrieg

Der Zweite Weltkrieg von 1939 bis 1945 war der zweite global geführte Krieg sämtlicher Großmächte des 20. Jahrhunderts und stellt den bislang größten militärischen Konflikt in der Geschichte der Menschheit dar. Im Kriegsverlauf bildeten sich zwei militärische Allianzen, die als „Achsenmächte“ und „Alliierte“ bezeichnet werden. Direkt oder indirekt waren über 60 Staaten am Krieg beteiligt, über 110 Millionen Menschen standen unter Waffen. Die Zahl der Kriegstoten liegt zwischen 60 und 70 Millionen ("s. u." Opferzahlen). Er war gekennzeichnet unter anderem durch Blitzkriege, Flächenbombardements, den bisher einzigen Einsatz von Atomwaffen sowie durch Holocaust, Porajmos und zahllose Kriegsverbrechen.

Der Zweite Weltkrieg begann mit dem deutschen Überfall auf Polen am 1. September 1939. Zu dieser Zeit befand sich das verbündete Japan noch in einem Grenzkrieg mit der Sowjetunion (1938/39) und in Ostasien mit China seit dem Zwischenfall an der Marco-Polo-Brücke (1937) im Krieg. Beide Achsenmächte beteiligten sich nicht an Kampfhandlungen in der jeweils anderen Hemisphäre (Europa, Afrika, Amerika und Atlantischer Ozean – Asien, Australien sowie Pazifischer und Indischer Ozean).

Bis Mitte 1941 wurde der Konflikt von der Wehrmacht in Europa vorwiegend als rascher, mechanisierter Eroberungskrieg geführt. Nach Polen wurden in kurzen, konzentriert geführten Feldzügen Dänemark, Norwegen, Belgien, die Niederlande, Luxemburg, der Großteil Frankreichs, Jugoslawien und Griechenland erobert und besetzt. Westpolen, Luxemburg und Elsass-Lothringen wurden ins Deutsche Reich eingegliedert. Andere Gebiete wurden mit vom Deutschen Reich abhängigen Regierungen beherrscht und wirtschaftlich ausgebeutet. Juden, Oppositionelle und des Widerstands gegen den Nationalsozialismus verdächtigte Personen wurden planmäßig verschleppt, zur Zwangsarbeit herangezogen oder sofort ermordet. Großbritannien war von der Kapitulation Frankreichs (22. Juni 1940) bis zum deutschen Angriff auf die Sowjetunion (22. Juni 1941) Deutschlands einzig verbliebener europäischer Kriegsgegner. Dieses Durchhalten der Briten, das von Churchills Standfestigkeit gegenüber Adolf Hitler angeführt wurde, war von großer, mitentscheidender Bedeutung für den Verlauf des Zweiten Weltkrieges. Das nationalsozialistische Deutsche Reich führte den Krieg gegen die UdSSR als einen Vernichtungskrieg. Hitler gilt dabei als treibende Kraft. Bereits in "Mein Kampf" hatte er die Vorstellung der Eroberung von „Lebensraum im Osten“ weiterentwickelt, indem er sie mit Sozialdarwinismus, Rassenideologie, Antisemitismus und Antibolschewismus verknüpfte. Immer wieder betonte er, dass er Osteuropa bis zum Ural als Ergänzungs- und Siedlungsraum für ein künftiges „Großgermanisches Reich“ begriff. Der Vormarsch der Wehrmacht konnte im Winter 1941/42 vor Moskau erstmals abgewehrt werden. Nachdem die Rote Armee im Winter 1942/43 einen erneuten Vorstoß bei Stalingrad stoppen konnte, drängte sie die Invasoren nach und nach zurück. Im Juni 1944 gelang ihr die Zerschlagung der Heeresgruppe Mitte, womit die deutsche Niederlage unausweichlich geworden war. Bis Ende 1944 musste die unterlegene Wehrmacht sich an die Reichsgrenzen zurückziehen.

Mit dem Kriegseintritt des Königreichs Italien im Juni 1940 wurde auch Nordafrika zum Kriegsschauplatz. Italienische Truppen mussten in Ägypten gegen britische Verbände empfindliche Verluste hinnehmen und verloren die Kontrolle über Italienisch-Ostafrika. Das ab Februar 1941 an den Kämpfen beteiligte Deutsche Afrikakorps konnte die Niederlage der Achsenmächte in Nordafrika verzögern, nicht abwenden. Nach den beiden Schlachten bei El-Alamein (1942) schwanden Deutschlands Aussichten, global gegen das britische Empire vorgehen zu können. Im November 1942 landeten anglo-amerikanische Truppen in Nordafrika und zwangen die deutschen und italienischen Truppen in Tunesien zur Kapitulation (Mai 1943). Nach der Landung auf Sizilien (Juli 1943), in der Normandie (Juni 1944) und in Südfrankreich (August 1944) führten US-amerikanische, britische, kanadische und französische Truppen in Kontinentaleuropa neben den sowjetischen Truppen einen Landkrieg gegen die Truppen der Wehrmacht. Italien stand seit Oktober 1943 offiziell auf der Seite der Alliierten.

Im Oktober 1944 drangen westalliierte Truppen bei Aachen auf das Gebiet des Deutschen Reiches vor. 1945 begann die Rote Armee, Ostpreußen zu erobern. Mit Durchhaltebefehlen trieb die politische und militärische Führung die deutschen Truppen noch im Frühjahr 1945 weiter in einen längst verlorenen Krieg, wodurch auf beiden Seiten noch Hunderttausende von Menschen getötet wurden. Am 25. April 1945 stießen an der Elbe US-amerikanische Truppen auf sowjetische Truppen. Am 30. April 1945 beging Hitler während des Kampfes um Berlin Selbstmord. Die Verteidiger der Stadt kapitulierten am 2. Mai 1945. Am 8. Mai 1945 (VE-Day) trat die bedingungslose Kapitulation der Wehrmacht in Kraft; der Krieg in Europa war damit beendet. Nach Ende des Zweiten Weltkrieges stieg die Sowjetunion neben den USA in den Rang einer Supermacht auf.

Nach dem japanischen Angriff auf Pearl Harbor am 7. Dezember 1941 erklärten die USA dem Kaiserreich Japan den Krieg; der Konflikt wurde zum Weltkrieg, als Hitler am 11. Dezember 1941 den USA den Krieg erklärte, obwohl er dazu nach dem Dreimächtepakt nicht verpflichtet war. Die UdSSR blieb gemäß dem Neutralitätspakt vom 13. April 1941 gegenüber Japan vorerst neutral. Auf der Arcadia-Konferenz (Dezember 1941–Januar 1942) wurde der Schwerpunkt der US-amerikanischen und britischen Kriegsanstrengungen auf die Bekämpfung des Deutschen Reichs gelegt. Die US-Rüstungsindustrie baute in Rekordzeit neue Schiffe für die Pazifikflotte der United States Navy, die ab Mitte 1942 in kombinierten See-Luftschlachten der japanischen Marine schwere Verluste zufügen konnte. Japanische Truppen hatten bis dahin Hongkong, Britisch-Malaya, die Philippinen, Teile Burmas, Niederländisch-Indien und Teile von Neuguinea erobert. Der nördliche Teil Indochinas und der südliche Teil wurden im September 1940 und im Juli 1941 besetzt. Thailand wurde von Indochina aus besetzt und zur Kriegserklärung an die USA gezwungen. Die Schlacht um Midway (Anfang Juni 1942), in der die japanische Marine vier ihrer sechs großen Flugzeugträger verlor, brach die japanische Überlegenheit im See-Luft-Krieg und bewirkte die "Wende im Pazifikkrieg". Bis 1945 kämpften sich die US-Truppen im Zuge des sogenannten "Island Hopping" immer näher an die vier Hauptinseln Japans heran, wobei große Teile Südostasiens weiter von japanischen Truppen besetzt blieben. Von Tinian aus starteten die beiden Bomber, die im August 1945 je eine Atombombe auf Hiroshima und Nagasaki abwarfen. Am 2. September 1945 endete der Zweite Weltkrieg mit der Kapitulation Japans.

„Dieser Krieg war ein historisch beispielloser Angriff auf die Menschlichkeit, eine Zerstörung aller kulturellen Ideale, die die Aufklärung hervorgebracht hatte, ein Absturz, wie es ihn bis dahin nicht gegeben hatte. Er war Europas Armageddon.“ Er veränderte grundlegend die politischen und sozialen Strukturen der Welt. Die Organisation der Vereinten Nationen (UNO) wurde gegründet, deren ständige Mitglieder im Sicherheitsrat die Hauptsiegermächte des Zweiten Weltkriegs wurden: USA, Sowjetunion, China, Großbritannien und Frankreich. Die USA und die Sowjetunion wurden zu Supermächten, deren Rivalität zum Kalten Krieg und zu neuen Militärbündnissen führte. Die europäischen Kolonialmächte Großbritannien und Frankreich verloren ihre Großmachtstellung, und die meisten ihrer afrikanischen und asiatischen Kolonien wurden unabhängig. „Erst mit dem Fall der Mauer 1989 und dem Ende des Kalten Krieges ging die vom Zweiten Weltkrieg […] geprägte Phase der Geschichte zu Ende.“

<br>

In den Jahren von 1920 bis zum Ende des Zweiten Weltkriegs 1945 erlangte in weiten Teilen Europas der Faschismus beziehungsweise Rechtsextremismus zunehmend die politische Meinungsherrschaft. In Italien bekam Benito Mussolini bereits 1922 mit dem Marsch auf Rom die Macht übertragen. In Deutschland wuchs der Nationalsozialismus ab etwa 1930 zur Massenbewegung heran. Am 30. Januar 1933 wurde ihr und ihren rechtskonservativen Verbündeten die politische Macht übergeben, als Reichspräsident Paul von Hindenburg Adolf Hitler zum Reichskanzler ernannte. Dieser bildete aus Nationalsozialisten und Deutschnationalen das Kabinett Hitler.

Die Revision der internationalen Ordnung nach dem Versailler Vertrag, bereits ein Ziel früherer deutscher Regierungen, gehörte zum Programm der Nationalsozialisten und ihrer Verbündeten. Mit der 1935 vollzogenen Wiedervereinigung des Saargebietes mit dem Deutschen Reich und der Wiedereinführung der allgemeinen Wehrpflicht (ebenfalls 1935), dem Einmarsch in das entmilitarisierte Rheinland im März 1936, dem „Anschluss Österreichs“ (März 1938) und der Abtrennung des Sudetenlandes von der Tschechoslowakei im Münchner Abkommen (30. September 1938) wurde die Versailler Friedensordnung schrittweise aufgelöst. Begünstigt wurde dies durch die britische und französische Appeasement-Politik, die auf eine friedliche Verständigung mit dem nationalsozialistischen Deutschland abzielte. Selbst nach dem Einmarsch in die sogenannte Rest-Tschechei im März 1939 gab es lediglich Proteste auf britischer und französischer Seite. Kurz darauf gab Litauen unter dem Druck der Verhältnisse das Memelland an Deutschland zurück, die Slowakei wurde ein eigener Staat und durch einen „Schutzvertrag“ eng an Deutschland gebunden. Großbritannien und Frankreich wollten das deutsche Expansionsstreben eingrenzen und gaben am 31. März 1939 eine Garantieerklärung für Polen ab, die kurze Zeit später in ein förmliches Bündnis umgewandelt wurde.

Bereits im Oktober 1935 griff Italien, das enge Beziehungen zum Deutschen Reich pflegte, Äthiopien an und besetzte am 7. April 1939 Albanien.

Im Spanischen Bürgerkrieg bekämpften sich von 1936 bis 1939 eine hauptsächlich von Republikanern, Sozialisten und Kommunisten geführte "Volksfrontregierung" und Anhänger einer Militärrevolte des Generals Francisco Franco. Die Sowjetunion und die französische Volksfront lieferten der „Volksfront“ Waffen und Kriegsmaterial, während Italien und Deutschland die Truppen der Nationalisten Francos unterstützen. Die deutsche Regierung entsandte zu diesem Zweck die Legion Condor, die italienische den Corpo Truppe Volontarie (CTV), die entscheidend zum Sieg des Franquismus beitrugen.

Am 23. August 1939 schlossen Deutschland und die Sowjetunion überraschend einen Nichtangriffspakt, später „Hitler-Stalin-Pakt“ genannt. In einem geheimen Zusatzprotokoll wurde die Aufteilung Europas in geographisch genau bezeichnete, aber ansonsten nicht näher definierte „Interessensphären“ beschlossen. Dies lief letztlich hinaus auf die Aufteilung Polens zwischen Deutschland und der Sowjetunion sowie die einseitige Eroberung und Besetzung weiterer Gebiete (unter anderem der baltischen Staaten und Finnlands) sowie weiter Teile Rumäniens durch die UdSSR.

Die japanische Expansionspolitik begann in den 1930er-Jahren, als der Einfluss der militärischen Führung auf die kaiserliche Regierung stärker wurde. Japan verstand sich als Schutz- und Ordnungsmacht, die dazu auserkoren sei, die anderen ostasiatischen Völker zu beherrschen. Die Rohstoffvorkommen und das Reservoir an Arbeitskräften, das die Nachbarländer boten, sollten der japanischen Wirtschaft zugutekommen. Das Hauptinteresse galt zunächst der Republik China, deren stark industrialisierte Region Mandschurei bereits 1931 annektiert und zum Protektorat Mandschukuo erklärt wurde. Als Reaktion auf die internationalen Proteste trat Japan 1933 aus dem Völkerbund aus. Ende 1936 schlossen Deutschland und Japan den Antikominternpakt. Mitte 1937 begann Japan den Zweiten Japanisch-Chinesischen Krieg.

Die Möglichkeit, dass ein umfassender Krieg eintreten könnte, wurde von den Großmächten einkalkuliert, so dass sie entsprechende Vorbereitungen trafen. Die Kriegsvorbereitungen umfassten daher beispielsweise die Bevorratung von kriegswichtigen Ressourcen und Gütern sowie die Ausdehnung von Zivilschutzprogrammen.

Im europäischen Kontext war der Zweite Weltkrieg ein vom nationalsozialistischen Deutschland ausgelöster Raub-, Eroberungs- und Vernichtungskrieg mit dem langfristigen Ziel, ein unangreifbares deutsches Großreich aus eroberten und abhängigen Gebieten zu schaffen. Ziel war von Beginn an die deutsche Weltmachtstellung und die „rassistische Neuordnung des [europäischen] Kontinents“. Dabei vermischten sich klassische machtpolitische mit rassenideologischen Motiven. Hierzu zählten einerseits die Gewinnung von „Lebensraum im Osten“ mit Umsiedlung oder Vernichtung der dort lebenden, als „rassisch minderwertig“ angesehenen, vorwiegend slawischen Völker, andererseits die „Endlösung der Judenfrage“. Beides wurde durch die antisemitische Vorstellung eines „jüdischen Bolschewismus“ als Teil einer Verschwörung des „Weltjudentums“ begründet, die in Gestalt der Sowjetunion als Bedrohung der Lebensgrundlagen der „arischen Rasse“ und der durch sie repräsentierten europäischen Zivilisation gesehen wurde.
Nach dem Willen der nationalsozialistischen Führung sollte die Volksgruppe der Slawen zunächst unterworfen und das eroberte Osteuropa von deutschen Siedlern, sogenannten Wehrbauern, nutzbar gemacht werden. Nach Vernichtung ihrer Elite sollten die slawischen Völker für immer ein Reservoir an ungebildeten und unterwürfigen Land- und Hilfsarbeitern stellen. Die eroberte Sowjetunion sollte in Gebiete unter der Leitung von Reichskommissaren aufgeteilt werden. Nur Weißrussen, Ukrainer und baltische Völker wurden als lebenswerte Völker eingestuft. Nach den Worten Alfred Rosenbergs würden „dem Russentum [.] sicher sehr schwere Jahre bevorstehen“.

Die deutsche Strategie sah die Nutzung einer politisch und zeitlich begrenzten Gelegenheit zur strategischen Offensive vor. Sie verfolgte militärische, rassisch-hegemoniale, wirtschaftliche und diplomatische Ziele. In militärischer Hinsicht sollte der Blitzkrieg einen raschen und ausgiebigen Raumgewinn ermöglichen, um der sich abzeichnenden Überlegenheit der gegnerischen Rüstung zuvorzukommen. Damit stellte diese Strategie eine spezielle Ausprägung des Bewegungskriegs in Kombination mit der Entscheidungsschlacht dar, die auf deutsche Erfahrungen im Ersten Weltkrieg zurückgriff. In wirtschaftlicher Hinsicht sollte sie Ressourcen schonen, um die Industriekapazitäten nicht zu Ungunsten der Konsumwirtschaft zu belasten. In der deutschen Bevölkerung sollte keine Unzufriedenheit wegen einer möglichen materiellen Verknappung entstehen. Zur Sicherung der „Heimatfront“ und im Sinne einer optimalen Nutzung der eroberten Kapazitäten wurde ein Zweifrontenkrieg zunächst vermieden. Drittens sollte die Ausplünderung der besetzten Territorien, vor allem in Ostmittel- und Osteuropa, die Versklavung ihrer Bewohner zugunsten des Deutschen Reiches und seiner „arischen“ Bevölkerung die rassisch motivierten Hegemonialvorstellungen des Nationalsozialismus verwirklichen. Die diplomatische Gewinnung von europäischen und außereuropäischen Verbündeten sollte diese Hegemonialstellung absichern, vor allem im Hinblick auf die geplante oder erwartete Auseinandersetzung mit den „Flügelmächten“ USA und Sowjetunion.

Die Empörung über den Versailler Vertrag, insbesondere die harten und als ungerecht empfundenen Reparationsforderungen, sowie die einseitige Schuldzuweisung an die Mittelmächte fanden in weiten Teilen der deutschen Bevölkerung Widerhall. Die Revision des Versailler Vertrags und die Rückkehr des Deutschen Reiches in den Kreis der Großmächte war stets mit besonderem Nachdruck von der deutschen Generalität, dem monarchistisch und antirepublikanisch gesinnten Teil des deutschen Bürgertums und der wirtschaftlichen Elite angestrebt worden. Für die Nationalsozialisten war dies lediglich ein Etappenziel.

In der geheimen Denkschrift zum Vierjahresplan forderte Hitler im August 1936 die Einsatzfähigkeit der deutschen Armee und die Kriegsfähigkeit der Wirtschaft innerhalb von vier Jahren, um eine kriegerische „Erweiterung des Lebensraumes bzw. der Rohstoff- und Ernährungsbasis“ für das Deutsche Reich zu erzielen. Am 5. November 1937 präzisierte er vor den militärischen und außenpolitischen Führungskräften des Reiches seine Kriegsziele. Er lehnte Autarkie und Rückkehr Deutschlands zum Welthandel ab; nur der Erwerb eines größeren Lebensraumes sei ein Ausweg. Sein unabänderlicher Entschluss sei, spätestens 1943/45 die deutsche Raumfrage zu lösen.

Nach dem 13. Oktober 1943, dem Tag der Kriegserklärung der Badoglio-Regierung in Italien, befand sich das Deutsche Reich im Kriegszustand mit 34 Staaten und hatte nur noch das Kaiserreich Japan als nennenswerten Verbündeten. Diese beiden Staaten kämpften, unabhängig voneinander, einen aussichtslosen Krieg gegen den "Rest der Welt". Weitere 18 Staaten erklärten dem Deutschen Reich bis März 1945 den Krieg. Deutschlands bisherige Verbündete in Südosteuropa, Ungarn und Rumänien, schieden 1944 aus. Finnland unterzeichnete am 19. September 1944 einen separaten Waffenstillstand mit der UdSSR. Bulgarien wurde im September von der "Roten Armee" besetzt, obwohl es sich nicht im Kriegszustand mit der Sowjetunion befand. In Serbien, Kroatien, Mazedonien und Montenegro wurden im Dezember 1944 „Volksregierungen“ gebildet, nachdem die Rote Armee Ende Oktober 1944 Belgrad besetzt und Tito sich in Moskau über das weitere Vorgehen verständigt hatte. Nach dem Rückzug der Wehrmacht bildete sich in Tirana am 10. November 1944 eine kommunistische Regierung des Partisanen-Obersten Enver Hoxha.

Italien hatte nach dem Ersten Weltkrieg Julisch Venetien, Istrien, das Trentino sowie das deutschsprachige Südtirol annektiert. Im Oktober 1935 überfiel es das Kaiserreich Abessinien (heute Äthiopien) und annektierte das Land. Diese völkerrechtswidrige Annexion war Teil von Mussolinis erklärtem Ziel, das Römische Reich wiedererstehen zu lassen. 1938 nahm Mussolini nach dem "Anschluss Österreichs" eindeutig Stellung zugunsten des Deutschen Reiches. Im April 1939 ließ er ohne Hitlers vorherige Kenntnis Albanien besetzen und behauptete, diese sei das Gegenstück zur deutschen Annexion Tschechiens. In weiteren Abkommen band sich Mussolini an das Deutsche Reich und Adolf Hitler, z. B. im sogenannten Stahlpakt (Mai 1939). Schließlich trat Italien im Juni 1940 auf der Seite der Achsenmächte ("Achse Berlin-Rom-Tokio") in den Zweiten Weltkrieg ein, weil Mussolinis fatale Fehlspekulation diesen glauben ließ, der Krieg sei so gut wie beendet. Nachdem die Alliierten auf Sizilien und in Süditalien (1943) gelandet waren, überstimmte die innerparteiliche Opposition Mussolini im "Großen Rat" und ließ ihn nach einem anschließenden Besuch beim König verhaften. Italien schied nach dem Waffenstillstand von Cassibile aus dem Achsenbündnis aus und trat auf der Seite der Alliierten erneut in den Krieg ein.

Seit der Modernisierung im Zuge der Meiji-Restauration im Jahre 1868 strebte das japanische Kaiserreich eine territoriale Ausdehnung auf dem asiatischen Kontinent an, die vor allem der Sicherung wichtiger Rohstoffe dienen sollte. Die Bemühungen konzentrierten sich besonders auf China, das als schwach eingeschätzt wurde. Von einer expansiven Dynamik ermutigt, betrachtete Japan die zunehmenden Spannungen in Europa als Gelegenheit, dem wachsenden Einfluss der Vereinigten Staaten von Amerika in Ostasien entgegenzutreten. Zu den geostrategischen Überlegungen kamen die häufige Einmischung der Streitkräfte in die Angelegenheiten der zivilen Führung und eine wechselseitige kulturelle Aversion zwischen breiten Bevölkerungsschichten in Japan und den Vereinigten Staaten.

Japan sah sich, ähnlich dem Deutschen Reich in Europa, einer sich im Laufe der Jahre verschlechternden strategischen Ausgangslage in Ostasien gegenübergestellt. Ursache war vor allem seine bündnispolitische Isolation. Dem vorwiegend US-amerikanischen Unwillen, die japanische Ausdehnung in der Region hinzunehmen, schlossen sich China, die Sowjetunion und die Kolonialmächte grundsätzlich an. Konkret sah sich das japanische Kaiserreich in einem vierfachen geostrategischen Kontext bedroht. Im Osten war dies die Pazifikflotte der Vereinigten Staaten in Pearl Harbor, im Norden die Sowjetunion, im Westen China sowie im Süden Australien, Neuseeland, Niederländisch-Indien und die Philippinen. Sie waren aufgrund ihrer räumlichen Ausdehnung und Lage als Operationsbasen gegen Japan geeignet.

Diese geostrategische Ausgangslage veranlasste die japanische Führung, ähnlich wie die deutsche, zu einer Mischung diplomatischer Instrumente mit einem Bewegungskrieg. Sie schloss daher nach gescheitertem Vordringen auf sowjetisches Gebiet im Jahre 1938/39 mit der UdSSR einen Nichtangriffspakt. Der Angriff der Kaiserlich Japanischen Marineluftstreitkräfte auf Pearl Harbor, deren Aufbau angesichts der Einschränkungen des Washingtoner Flottenabkommens qualitativ ausgerichtet war, beabsichtigte vor allem, der Marine der Vereinigten Staaten angesichts ihrer zunehmenden Rüstung einen entscheidenden Schlag zu versetzen. Auch in Südostasien selbst konzentrierte sich Japan im ersten Schritt auf die Neutralisierung konzentrierter militärischer Ressourcen, beispielsweise der Ansammlung von B-17-Langstreckenbombern auf den Philippinen. Die folgende, umfangreiche japanische Invasion Südostasiens diente zum einen der Beschaffung von Rohstoffen, vorrangig von Erdöl, und zum anderen, den USA den Nachschubweg nach Australien abzuschneiden.

An der Westfront sahen die Kriegsplanungen der Westmächte, ähnlich wie im Ersten Weltkrieg, im Wesentlichen eine Abnutzung des deutschen Heeres vor. Sie sollte durch Bombardierungen der großen Städte und Blockade des deutschen Wirtschaftskreislaufes ergänzt werden.

Die kommunistische Führung sah die Sowjetunion von einer prinzipiell feindlich gesinnten kapitalistischen Welt umgeben und hielt einen Krieg für unvermeidlich. Für sie galt es, den Krieg so lange hinauszuzögern, bis die Fünfjahrespläne das Potenzial geschaffen hätten, um einer Auseinandersetzung gewachsen zu sein. Aber dieses Ziel schloss eine Offensive nicht aus, um das eigene Gewicht bei günstiger Gelegenheit entscheidend in die Waagschale zu werfen. Mit dem deutsch-sowjetischen Nichtangriffspakt glaubte Stalin, ein gemeinsames Vorgehen der kapitalistischen Mächte gegen die Sowjetunion verhindert zu haben und die Rolle eines "Zuschauers" bei der Selbstzerstörung des Kapitalismus für längere Zeit einnehmen zu können.

Die Sowjetunion eignete sich nach dem Beginn des "Unternehmens Barbarossa" bewusst Lehren der vorangegangenen deutschen Aufrüstung an. Zu Lande folgte sie dem deutschen Beispiel der Heeresgruppe, deren Kernstück mobile und schwer gepanzerte Divisionen bildeten, und gründete zentral koordinierte Luftflotten, die durch deutliche Verbesserung im Informationsfluss eine zielgerichtete Luftnahunterstützung ermöglichten. Stalin delegierte nach der vorangegangenen, politisch motivierten Dezimierung des Offizierskorps die operative Führung an Marschall Georgi Konstantinowitsch Schukow, dessen überdurchschnittliche Kompetenzen die erfolgreiche Führung von mehreren Millionen Mann ermöglichten.

Stärke der Streitkräfte (in Millionen):

Rüstungsproduktion im Zweiten Weltkrieg:

Die totale Mobilmachung menschlicher und materieller Ressourcen gab den Ausschlag im Zweiten Weltkrieg, insbesondere die industrielle Massenproduktion von Rüstungsgütern. Allein die USA fertigten mehr Kriegsgüter als die drei Achsenmächte zusammen, obwohl sie erst im Dezember 1941 in den Krieg eintraten.

In der ersten Phase des Krieges eroberte Deutschland Polen (September 1939), Dänemark und Norwegen (April–Juni 1940) sowie die Niederlande, Belgien und Frankreich (Mai–Juni 1940). Die schnelle Niederlage Frankreichs kam für die meisten Menschen unerwartet, nicht zuletzt für Josef Stalin. Dennoch erreichte Hitler sein Hauptziel nicht, Großbritannien aus dem Krieg herauszuhalten, zur Aufgabe zu zwingen oder militärisch zu besiegen. Dies wurde spätestens im Oktober 1940 während der Luftschlacht über England deutlich. Großbritannien blieb der einzige Staat, der vom Beginn des Krieges an durchgehend handlungsfähiger Gegner Deutschlands war.

Hitler befahl am 31. August 1939 den Angriff der Wehrmacht auf Polen um 4.45 Uhr des folgenden Tages. Diese Weisung enthielt taktische Weisungen für das Verhalten der Wehrmacht im Westen, im Norden (Ostsee-Eingänge) und verbot Angriffe gegen „das englische Mutterland“ mit unzureichenden Teilkräften.
Diesem Überfall ging keine formale Kriegserklärung voraus. Um die Invasion Polens zu rechtfertigen, fingierte die deutsche Seite mehrere Vorfälle, so zum Beispiel den vorgetäuschten Überfall auf den Sender Gleiwitz von als polnische Widerstandskämpfer verkleideten SS-Angehörigen am 31. August. Dabei verkündeten diese in polnischer Sprache über Radio wahrheitswidrig eine "Kriegserklärung" Polens an das Deutsche Reich. Fast drei Millionen deutsche Soldaten mit 400.000 Pferden und 200.000 Fahrzeugen waren aufmarschiert, um Polen zu überfallen. 1,5 Millionen Mann waren bis zur polnischen Grenze vorgerückt, viele mit Platzpatronen, um vorzutäuschen, sie zögen nur ins Manöver. Mit der Unklarheit war es vorbei, als sie Befehl erhielten, scharfe Munition zu laden.
Den militärischen Angriff begann das deutsche Linienschiff "Schleswig-Holstein" auf die polnische Stellung „Westerplatte“ bei Danzig. Die polnische Armee mit ungefähr 1,1 Millionen Soldaten stand 1,5 Millionen deutschen Soldaten gegenüber. Technisch und in der Art der Kriegführung war sie unterlegen. Nach dem Einmarsch der "Roten Armee" in Ostpolen am 17. September 1939 wurde das Kräfteverhältnis nochmals dramatisch zu Gunsten der Aggressoren verschoben. Die polnische Regierung rechnete andererseits mit der Unterstützung durch Frankreich und Großbritannien, die am 2. September aufgrund der „Garantieerklärung vom 30. März 1939“ ein Ultimatum an das Deutsche Reich gestellt hatten.

Es forderte den sofortigen Rückzug aller deutschen Truppen aus Polen. Die britisch-französische Garantieerklärung hätte diese Staaten verpflichtet, spätestens 15 Tage nach einem deutschen Angriff eine eigene Offensive im Westen Deutschlands zu beginnen. Hitler nahm an, dass die beiden Westmächte ihn ebenso wie beim Einmarsch in die „Rest-Tschechei“ gewähren lassen würden und ließ den Westwall nur schwach besetzen. Ein Angriff der Westmächte blieb aus, jedoch erklärten Großbritannien und Frankreich am 3. September nach Ablauf des Ultimatums Deutschland den Krieg. Chamberlain begründete die Kriegserklärung am selben Tag in einer über die BBC.
In der Nacht zum 17. September, nach der Zerschlagung der organisierten polnischen Verteidigung durch die Wehrmacht, begann die sowjetische Besetzung Ostpolens in Übereinstimmung mit dem geheimen Zusatzprotokoll des deutsch-sowjetischen Nichtangriffspaktes. Am nächsten Tag floh die polnische Regierung von Warschau über Südostpolen nach Rumänien. Am 28. September trat Präsident Ignacy Mościcki im rumänischen Exil von seinem Amt zurück. Erst am 18. Dezember 1939 erklärte die neue Polnische Exilregierung den Kriegszustand mit der Sowjetunion. Großbritannien und Frankreich schlossen sich dem nicht an.

Warschau war vom 20. September bis zur Kapitulation Ziel intensiver Luftangriffe, die 25.000 Zivilisten und 6000 Soldaten das Leben kosteten. Die Bombardements erfolgten mit maximaler Stärke, weil Hitler demonstrieren lassen wollte, was auch französische und britische Städte treffen könne. Am 26. September kapitulierten rund 120.000 polnische Soldaten in der Hauptstadt Warschau, nachdem sie am 18. September von deutschen Truppen eingeschlossen worden waren. Die Festung Modlin wurde nach 16-tägiger Belagerung am 29. September übergeben.
Polens letzte Truppen kapitulierten am 6. Oktober nach der Schlacht bei Kock.

Am 8. Oktober teilten das Deutsche Reich und die Sowjetunion im Abkommen von Brest-Litowsk das eroberte Gebiet entlang einer Demarkationslinie, was als die „Vierte Teilung Polens“ in die Geschichte einging. Nicht nur die nach dem Versailler Vertrag abgetretenen Gebiete wurden wieder in das Reich eingegliedert, sondern darüber hinaus weite Bereiche Zentralpolens einschließlich der Stadt Łódź. Der Rest Polens wurde deutsches Generalgouvernement, das von Krakau aus „verwaltet“ wurde.

Die anschließende Besatzungszeit war von extremen Repressalien der Besatzer gegen die Zivilbevölkerung geprägt. Deportationen zur Zwangsarbeit waren nur die sichtbarste Ausprägung, insbesondere die Juden wurden Opfer der nationalsozialistischen Rassen- und Vernichtungspolitik. Im östlichen Teil Polens wurden zahlreiche „Klassenfeinde“ von den sowjetischen Besatzern in den Gulag deportiert; die militärische Elite wurde in Katyn und anderswo „liquidiert“.

Die auf einen schnellen Sieg ausgelegte – und hierbei erfolgreiche – Taktik beim Angriff auf Polen förderte die Verwendung des Begriffs „Blitzkrieg“ und prägte die weitere Kriegführung Deutschlands bis Ende 1941.

Am 3. September erklärten Frankreich und das Vereinigte Königreich Deutschland den Krieg. Aufgrund dessen begann am 5. September eine begrenzte und eher symbolische Offensive der Franzosen gegen das Saargebiet. Die Deutschen leisteten keinen Widerstand und zogen sich zum stark befestigten Westwall zurück. Danach blieb es ruhig an der Westfront. Diese Phase wird als „Sitzkrieg“ bezeichnet. Bis auf vereinzelte Artilleriescharmützel erfolgten keine weiteren Angriffe. Auf deutscher Seite rollte die Propagandamaschinerie an. Mit Flugblättern und Parolen über Lautsprecher fragte man die Franzosen „"Warum führt ihr Krieg?"“ oder verkündete „"Wir werden nicht zuerst schießen"“.

Am 27. September erging eine Weisung Hitlers an das Oberkommando des Heeres zur Ausarbeitung eines Angriffsplans, des sogenannten „Fall Gelb“. Bis zum 29. Oktober waren die Planungen abgeschlossen. Sie sahen vor, dass zwei Heeresgruppen durch die Niederlande und Belgien vorstoßen sollten, um somit sämtliche alliierten Kräfte nördlich der Somme zu zerschlagen.

Letztlich fand jedoch 1939 kein Angriff statt, da aufgrund schlechter Witterungsbedingungen und viel größerer Verluste in Polen als erwartet (22 % Verluste bei Kampfflugzeugen, 25 % bei Panzern) der Angriff insgesamt neunundzwanzigmal verschoben wurde.

Am 30. November 1939 überschritten sowjetische Truppen unter Marschall Kirill Merezkow im sogenannten Winterkrieg die Grenze zu Finnland. Die Rote Armee griff mit 1500 Panzern und 3000 Flugzeugen an und erwartete einen schnellen Sieg; die Sowjetunion unterschätzte die Finnen, die mit nur 150.000 Soldaten, darunter viele Reservisten und Jugendliche, die Truppen der "Roten Armee" mit über einer Million Mann zurückschlugen. Die Rote Armee hatte 84.994 Tote und Vermisste zu beklagen. Die Finnen hatten 25.000 Mann verloren. Erst nach umfassenden Umgruppierungen und Verstärkungen konnte die Rote Armee Anfang Februar 1940 auf der Karelischen Landenge größere Durchbrüche erzielen. Schweden unterstützte Finnland indirekt, ohne seine Neutralität aufzugeben. Großbritannien und Frankreich griffen nicht zugunsten der Finnen in den Krieg ein, da beide Staaten nicht einen weiteren Kriegsgegner haben wollten. Das Deutsche Reich sympathisierte zwar mit Finnland, eine militärische Unterstützung erfolgte jedoch wegen des bestehenden Nichtangriffspakts mit der Sowjetunion nicht.

Ein Friedensvertrag, der am 12. März 1940 unterzeichnet wurde, legte fest, dass Finnland große Teile Kareliens an die Sowjetunion abtreten musste, darunter mit Wyborg die damals zweitgrößte Stadt Finnlands. Als direkte Reaktion auf den sowjetischen Angriff nahm Finnland 1941 im Fortsetzungskrieg am deutschen Krieg gegen die Sowjetunion teil, um die verlorenen Gebiete zurückzuerobern.

Eine wesentliche Folge des Winterkriegs war, dass Stalin mit einer Reorganisation der Roten Armee begann, in deren Verlauf Offiziere rehabilitiert wurden, die im Zuge des Großen Terrors nach Sibirien verbannt worden waren. Diese Reorganisation trug erheblich dazu bei, dass die Rote Armee 1941 mehr Kampfkraft hatte, als die Deutschen angenommen hatten.

Zum Ende des Jahres 1939, nach dem Ausfall der Eisenerzeinfuhren aus Frankreich (lothringische Minette), deckten die Erzlieferungen aus dem neutralen Schweden 49 Prozent des deutschen Bedarfs. Diese wurden von den schwedischen Abbaugebieten bei Kiruna mit der Erzbahn zum ganzjährig eisfreien Verladehafen Narvik in Norwegen transportiert. Norwegen hatte daher für das Deutsche Reich eine außerordentliche wirtschaftliche und militärische Bedeutung. Ein weiterer wichtiger Rohstoff war das finnische Nickel. Die Briten wollten diese wichtigen Rohstofflieferungen stören und frühestmöglich unterbinden (→Altmark-Zwischenfall), weswegen am 5. Februar 1940 im obersten franko-britischen Kriegsrat die Landung von vier Divisionen in Narvik vereinbart worden war. Am 21. Februar erging eine Weisung Hitlers für die Planung von Unternehmen in Skandinavien. Am 1. März wurde das "Unternehmen Weserübung" beschlossen. Es sah vor, Dänemark einzunehmen und es als „Sprungbrett“ für die Eroberung Norwegens zu benutzen. Im März kam es zu ersten Angriffen auf britische Kriegsschiffe.

Am 5. April begann die alliierte "Operation Wilfred", in der die Gewässer vor Norwegen vermint und weitere Truppen ins Land gebracht werden sollten. Einen Tag später lief das deutsche "Unternehmen Weserübung" an. Dabei wurde fast die gesamte Kriegsmarine mobilisiert und die Hälfte der gesamten deutschen Zerstörerflottille nach Narvik geschickt. Am 9. April wurde eine Gebirgsjäger-Division in Narvik angelandet.
Die britische militärische Führung hielt eine Landung der Deutschen für recht unwahrscheinlich, was dazu führte, dass von alliierter Seite nur geringe Gegenmaßnahmen getroffen wurden. Die Deutschen konnten ihren Brückenkopf ohne größeren Widerstand ausweiten, sodass am 10. April bereits Stavanger, Trondheim und Narvik besetzt wurden, nachdem zuvor bereits Dänemark kampflos besetzt worden war. Großbritannien besetzte am 12. April aus strategischen Gründen die dänischen Färöer im Nordatlantik.

Beim Versuch, die Hauptstadt Oslo zu besetzen, wurden schwere Einheiten der Kriegsmarine eingesetzt, die im engen Fahrwasser des Oslofjordes wenig geeignet waren. Dabei wurde das deutsche Flaggschiff, der Schwere Kreuzer "Blücher", deren erster Kampfeinsatz ihr letzter war, durch norwegische Küstenbatterien versenkt. Oslo wurde, später als von den Deutschen geplant, von Luftlandetruppen eingenommen.

Am 13. April versenkten neun Zerstörer und das Schlachtschiff "HMS Warspite" bei einem zweiten britischen Angriff die restlichen acht noch im Ofotfjord vor Narvik befindlichen deutschen Zerstörer. Zwei Leichte Kreuzer der Kriegsmarine und zahlreiche Frachter wurden von britischen U-Booten und Flugzeugen der Royal Air Force ebenfalls versenkt.

Am 17. April landeten die Alliierten schließlich bei Narvik und setzten die Truppen der Wehrmacht bei gleichzeitigem massiven Beschuss durch Schiffe der Royal Navy unter starken Druck. Bis zum 19. April wurden große alliierte Verbände, darunter polnische Soldaten und Teile der Fremdenlegion, in Norwegen angelandet. Sie eroberten Narvik und drängten die Gebirgsjäger der Wehrmacht in die Berge zurück.

Inzwischen verbesserte sich das Wetter in Norwegen, sodass die Wehrmacht ihre Fronten festigen und bei Angriffen deutscher Flugzeuge am 3. Mai vor Namsos ein britischer und ein französischer Zerstörer versenkt werden konnten.

Noch im selben Monat beschloss Churchill wegen der deutschen Erfolge in Frankreich den Abzug der Alliierten aus Norwegen. Bevor die 24.500 Soldaten evakuiert werden konnten, gelang es ihnen jedoch noch, in Narvik einzudringen und den wichtigen Hafen zu zerstören. Am 10. Juni kapitulierten schließlich die verbliebenen Soldaten der Norwegischen Streitkräfte, woraufhin das Unternehmen Weserübung abgeschlossen war.

Norwegen unter deutscher Besatzung wurde Reichskommissariat und Teil des deutschen Herrschaftsgebietes, sollte jedoch nach dem Willen Hitlers als selbständiger Staat bestehen bleiben. Im weiteren Verlauf wurde Norwegen stark befestigt, weil Hitler eine Invasion befürchtete. Im Februar 1942 wurde eine Marionettenregierung unter Vidkun Quisling eingesetzt.

Am 10. Mai 1940 begann der Angriff deutscher Verbände („Fall Gelb“) mit insgesamt sieben Armeen auf die neutralen Staaten Niederlande, Belgien und Luxemburg. 136 deutsche Divisionen standen rund 137 alliierten gegenüber. 

Die belgische Armee leistete etwas länger Widerstand. Bis zum 16. Mai wurden die Festungen Lüttich, Namur und die Dyle-Stellung eingenommen, am 17. Mai Brüssel und tags darauf Antwerpen. Dadurch gelang es den deutschen Angreifern, die belgischen Truppen nördlich dieser Linie von den britischen und französischen Verbänden abzuschneiden, die inzwischen nach Belgien vorgerückt waren. Die belgische Regierung flüchtete über Frankreich nach Großbritannien. Am 28. Mai unterzeichnete der im Lande gebliebene König Leopold III. gegen den Willen des Kabinetts die Kapitulation. Regierungspräsident Eggert Reeder wurde Chef der deutschen Militärverwaltung.

Um die Maginot-Linie zu umgehen, wurde das neutrale Luxemburg von der Wehrmacht besetzt. Großherzogin Charlotte und die Regierung waren kurz vorher ins Exil nach Großbritannien geflohen. Luxemburg wurde ein sogenanntes „CdZ-Gebiet“, das einem Chef der Zivilverwaltung unterstand. Am 30. August 1942 wurde es von Deutschland annektiert. Die männliche Bevölkerung im wehrfähigen Alter wurde zum Dienst in der Wehrmacht gezwungen. Etwa 100.000 Elsässer und Lothringer wurden in den Vichy-regierten Teil Frankreichs ausgewiesen.

In Frankreich vertrauten Regierung und Militärs auf die stark befestigte Maginot-Linie entlang der deutsch-französischen Grenze. Weil die belgischen Ardennen für Panzer als unüberwindbar galten, wurden sie für eine natürliche Verlängerung der 130 km langen Maginotlinie gehalten (siehe Karte). Der Feldzugplan des Generalleutnants Erich von Manstein sah dagegen einen schnellen Vorstoß der Heeresgruppe A durch die Ardennen mit sechs Panzer- und fünf motorisierten Divisionen vor, um die alliierten Truppen im Raum der Straße von Calais von Süden her zu umfassen und bis zur Kanalküste vorzurücken, während die nördliche Heeresgruppe B und die südliche Heeresgruppe C eher defensiv agieren sollten. Diesem Plan kam entgegen, dass starke alliierte Kräfte, darunter die Masse der British Expeditionary Force, weit nach Norden vorrückten, um den bedrängten Belgiern und Niederländern zur Hilfe zu kommen, und auf diese Weise Raum für deutsche Truppen der Heeresgruppe A in ihrem Rücken ließen. Am 19. Mai erreichte die deutsche 6. Armee den Fluss Schelde und die Panzergruppe Kleist stieß bis Abbeville, ungefähr 100 km südlich von Calais, vor. Der Vormarsch in diese Gebiete erfolgte so schnell, dass die britischen und französischen Einheiten bei Dünkirchen eingekesselt wurden. Dieser schnelle und überraschende Vormarsch wurde später von Churchill als „Sichelschnitt“ bezeichnet. Hitler entschied in Übereinstimmung mit von Rundstedt und im Widerspruch zur Meinung anderer Generäle, die angeschlagene Panzertruppe zu schonen, ihren Vormarsch anzuhalten und die Einschließung von Dünkirchen der Luftwaffe und den Artillerieregimentern zu überlassen.

Als sich die Briten zurückzogen, bereitete sich Frankreich auf die Verteidigung vor. Der „Fall Rot“, die eigentliche Schlacht um Frankreich, begann am 5. Juni mit einer deutschen Offensive an der Aisne und der Somme. Am 9. Juni überschritten deutsche Soldaten die Seine. Am 10. Juni trat Italien auf Seiten Deutschlands in den Krieg ein und begann am 21. Juni eine Offensive in den Westalpen, obwohl die Regierung Pétain am 20. Juni Italien um Waffenstillstand gebeten hatte. Am 14. Juni besetzten Teile der 18. Armee die französische Hauptstadt Paris. Um ihre Zerstörung zu verhindern, war sie zur offenen Stadt erklärt und kampflos von den französischen Truppen geräumt worden. Am selben Tag durchbrachen deutsche Truppen südlich von Saarbrücken die Maginot-Linie, und die symbolträchtige Festung Verdun konnte ebenfalls eingenommen werden.

Nachdem deutsche Truppen am 17. Juni Orléans und Nevers an der Loire (260 km südlich von Paris) sowie Dijon erreicht hatten, traf ein Waffenstillstandsgesuch von Philippe Pétain, dem Ministerpräsidenten der neu gebildeten französischen Regierung, in Hitlers Hauptquartier ein. Der "Führer" wurde daraufhin von Keitel als „der größte Feldherr aller Zeiten“ gelobt. Hitler traf sich am 18. Juni mit Mussolini in München, um die Waffenstillstandsbedingungen mit ihm abzustimmen. Die weitreichenden Forderungen des "Duce", unter anderen Nizza, Korsika und Savoyen sowie die Nutzung von Häfen und Eisenbahnen in Afrika für militärische Zwecke, wies Hitler zurück. Ihm lag daran, eine Fortsetzung des Krieges durch die französische Flotte und in den Kolonien zu verhindern. Dennoch begann Italien noch am 21. Juni eine Offensive in den Alpen, die nur geringfügige Geländegewinne erbrachte, unter anderen Mentone. Die Waffenstillstandsbedingungen wurden am 21. Juni 1940 im "Wagen von Compiègne" von Keitel dem französischen General Charles Huntziger überreicht. Am 22. Juni unterzeichnete die französische Delegation, nachdem fast alle ihre Gegenvorstellungen zurückgewiesen worden waren, den Waffenstillstandsvertrag. Er trat am 25. Juni um 01:35 Uhr in Kraft, nachdem am Tag zuvor auch der italienisch-französische Waffenstillstand unterzeichnet worden war. Frankreich durfte nur noch 100.000 Soldaten mit leichten Waffen unterhalten; Artillerie und Panzer waren nicht erlaubt.
Nur sechs Wochen und drei Tage hatte der sogenannte „Blitzkrieg“ im Westen gedauert, in dem etwa 100.000 französische, 35.000 britische und etwa 46.000 deutsche Soldaten ihr Leben verloren. Es war kein bravouröser "Blitzkrieg" oder "Blitzsieg", wie die deutsche Propaganda glauben machen wollte. Französische Jagdflieger schossen mehrere Hundert deutsche Kampfflugzeuge ab, und fast 1000 deutsche Kampfpiloten gerieten in Gefangenschaft. Frankreich wurde in zwei Zonen geteilt: Der Norden und Westen Frankreichs war deutsch besetzt; hier befanden sich wichtige Flugfelder und Marinebasen (unter anderen Brest, Lorient, St. Nazaire, La Rochelle und Bordeaux) für den Krieg gegen Großbritannien.

Politisch-strategisch befand sich das Deutsche Reich nach dem Sieg im Westen in einer Situation, die ihm grundlegend neue Optionen zur Fortsetzung des Krieges eröffnete: für den Krieg gegen Großbritannien im Westen, es hatte die Gleichgewichte im Mittelmeerraum verschoben, und es konnte auf die Wirtschaftsressourcen Westeuropas, Mitteleuropas und Ostmitteleuropas zurückgreifen und damit den Krieg auf lange Zeit durchhalten, u. a. Industriegüter aus dem "Protektorat Böhmen und Mähren", Eisenerze aus Schweden, die über den norwegischen Hafen Narvik nach Deutschland verschifft wurden, landwirtschaftliche Produkte aus Polen, Dänemark, den Niederlanden und Griechenland, Industriegüter aus Belgien und Frankreich, Wolfram aus Portugal sowie Erdöl aus Rumänien. Für internationale Geldtransaktionen und Devisengeschäfte konnte die neutrale Schweiz genutzt werden.

Drei Schlachtschiffe der französischen Flotte, die in Mers-el-Kébir vor Anker lag, wurden am 3. Juli 1940 nach einem britischen Ultimatum, das unbeantwortet blieb, auf Befehl Churchills durch Schiffe der "Royal Navy" versenkt oder schwer beschädigt, damit sie nicht in deutsche Hände fallen konnten (Operation Catapult). Dabei kamen 1297 französische Matrosen ums Leben. Der östliche und südliche Teil Frankreichs blieb unter französischer Kontrolle. Marschall Philippe Pétain regierte von Vichy aus den so genannten „État français“ als Marionettenstaat des Deutschen Reichs. Im November 1942 wurde die bisher unbesetzte Zone von deutschen und italienischen Truppen besetzt, nachdem anglo-amerikanische Truppen in Nordafrika gelandet waren. Die 50.000 Soldaten der "Vichy-Regierung" leisteten keinen Widerstand gegen Deutsche und Italiener. Der Rest der demobilisierten französischen Kriegsmarine wurde im Hafen von Toulon von den Besatzungen versenkt.

Trotz der Kapitulation Frankreichs ging der Krieg weiter, da Großbritannien Hitlers sogenanntes Friedensangebot vom 19. Juli 1940 nicht annahm. Obwohl der Ausgang des Krieges mit Großbritannien noch völlig offen war, verkündete Hitler schon am 31. Juli den Generälen seine grundsätzliche Absicht, für 1941 einen Angriff auf die Sowjetunion vorbereiten zu lassen. Kurz darauf, am 17. September, verschob er das "Unternehmen Seelöwe" auf eine unbestimmte Zeit.

Hitler bemühte sich, seine Herrschaft über das „Neue Europa“ zu konsolidieren und durch weitere Bündnisse mit Spanien, Frankreich, Ungarn, Rumänien und Bulgarien abzusichern. Franco und Pétain widersetzten sich einem formellen Bündnis mit Deutschland.

 Charles de Gaulle (1890–1970), bisher "Militär-Staatssekretär", war Organisator des Widerstandes als „Führer des freien Frankreich“ vom Exil in London aus. Von der Propaganda des Vichy-Regimes als "Le Général micro" und "Fourrier" (Verpflegungsunteroffizier) der Juden verspottet, rief er seine Landsleute immer wieder zum Widerstand auf. Am 18. Juni 1940 hatte er sich in einer Rundfunkrede an alle Franzosen gewandt: „Frankreich hat eine Schlacht verloren. Aber den Krieg hat Frankreich nicht verloren!“ Er sagte voraus, dass das Industriepotential der Vereinigten Staaten in diesem Krieg das Blatt wenden werde. Damit wies er die Meinung von Defätisten zurück, Großbritannien werde binnen drei Wochen geschlagen sein.

Die Schweiz konnte ihre Unabhängigkeit wahren und wurde nie Ziel einer deutschen Offensive. Dennoch wappnete sie sich intensiv gegen eine mögliche deutsche Invasion. Die Rheinebene konnte geflutet werden, um sie – nach den militärischen Erkenntnissen aufgrund des erfolgreichen deutschen Westfeldzugs durch die Ardennen (s. o.) – für Panzer unpassierbar zu machen. Im "Réduit" wurden 26.000 lokal individuell passend getarnte Bunker und Artilleriestellungen angelegt. Sie sollten bis zu sechs Monate autonom in Bereitschaft bleiben können.

General Henri Guisan verlegte Heereseinheiten in das Alpenréduit um den Gotthard als Zentrum. Das Konzept des "Réduit national" sah langwierige Gebirgskämpfe sowie die Zerstörung der Alpentranversale vor. Die schweizerische Bevölkerung akzeptierte mehrheitlich diese Verteidigungskonzeption. Kritiker bemängelten dagegen, dass die "Achsenmächte" das ressourcenreiche Mittelland mit wenig Aufwand erobern und die Armee im Réduit aushungern könnten. 1942 erreichte das Réduit dank abnehmender Bedrohung seitens der Achsenmächte und Fertigstellung der Befestigungen seine volle Wirkung. Es schien, dass diesen Mächten eine unabhängige Schweiz mit funktionierendem Gütertransport durch die Alpen und wegen des Transfers von Devisen mehr nützen würde als ein erobertes Land mit zerstörten Produktionsanlagen. Nach der Landung der Alliierten in der Normandie im Juni 1944 verlegte der Oberbefehlshaber Guisan aufgrund der entspannteren Bedrohungslage wieder Truppen aus dem Réduit ins Mittelland zurück.

Im August 1942 kam es vorübergehend zu einer vollständigen Grenzschließung für Flüchtlinge als Höhepunkt einer allgemein sehr restriktiven Zulassung von jüdischen Flüchtlingen in die Schweiz. 1939–1945 wurden insgesamt rund 300.000 Menschen aufgenommen (davon etwa ein Drittel internierte Soldaten) und rund 20.000 Menschen an der Grenze zurück- oder ausgewiesen.

Die Entschlossenheit der Schweiz, ihre Neutralität oder die Verletzung ihres Luftraums gegen jeden Angreifer zu verteidigen, stand international außer Zweifel. Nach den Luftkämpfen im Pruntruter Zipfel im Jahr 1940 war zwar vom General Zurückhaltung angeordnet worden, aber auch englische Bomber auf dem Weg nach Italien wurden am 12. Juli 1943 beschossen und zwei davon zum Absturz gebracht. Bei versehentlichen Bombardierungen Schweizer Grenzorte durch US-Piloten wurden diese, falls abgeschossen, für den Rest des Krieges interniert.

Als „Luftschlacht um England“ bezeichnete die nationalsozialistische Propaganda die Vorbereitung einer Invasion Großbritanniens durch Ausschaltung der "Royal Air Force". Hitler glaubte nicht an einen Erfolg und zog einen Friedensschluss mit Großbritannien vor, freilich nur, wenn es die ehemals deutschen Kolonien zurückgeben und auf Einfluss in Europa verzichten würde.

In den zwei Jahren zwischen dem Münchner Abkommen und der „Luftschlacht um England“ hatten die Briten ihre Luftverteidigung verbessert. An der Süd- und Ostküste der Britischen Insel wurden „Chain Home“-Radarstationen installiert. Die britische Industrie konnte in den drei Monaten vor dem Beginn des Zweiten Weltkrieges mehr als 1400 Jagdflugzeuge produzieren. Die Royal Air Force (RAF) warb erfolgreich Piloten aus dem Commonwealth, Frankreich, den USA, Polen und der Tschechoslowakei an, denn auf einen Piloten der RAF kamen sechs deutsche. Bei den Flugzeugen sah es ähnlich aus: Im Westfeldzug kamen auf ein britisches Kampfflugzeug etwa vier deutsche Jäger und Bomber. Deshalb setzte Dowding auch ausländische Freiwillige als Jagdflieger ein, zunächst aus den Commonwealth-Staaten Kanada, Australien und Neuseeland, dann aber auch aus Polen, Tschechien und Frankreich. Ein Fünftel der insgesamt in der Luftschlacht um England eingesetzten knapp 3000 „Spitfire“- oder „Hurricane“-Piloten stammte nicht aus Großbritannien.

Am 2. Juli begann Göring die Luftschlacht mit einer begrenzten Offensive gegen die Schifffahrt im Ärmelkanal. Dowding, Kommandeur der britischen Luftverteidigung, nahm die Herausforderung nicht an. Die nächste Phase begann Mitte August. Die RAF sollte durch die Vernichtung ihrer Flugzeuge in der Luft zerschlagen werden, während die Bekämpfung der Schifffahrt weiterging. Im August und September schossen britische Jäger 341 deutsche Flugzeuge ab und verloren selbst 108. Die RAF hatte den Vorteil, dass die Piloten der abgeschossenen Maschinen nicht jedes Mal für sie verloren waren, sofern sie sich mit dem Fallschirm retten konnten. In der nächsten Phase konzentrierte die Luftwaffe ihre Angriffe auf London. Hitler sprach von Vergeltung und völliger Vernichtung, nachdem in der Nacht zum 26. August auf Befehl Churchills die RAF einen Angriff mit 60 Bombern auf Berlin geflogen hatte, der kaum Schäden verursacht hatte. Am 7. September griff die "Luftwaffe" die Londoner Docks mit 300 Bombern und 600 Jägern an, aber sie verlor wieder mehr Flugzeuge als die britischen Jagdstaffeln. Am 15. September erreichten die deutschen Angriffe, von den Briten „The Blitz“ genannt, ihren Höhepunkt mit zwei Tagesangriffen. Die deutschen Bomber wurden dezimiert und die Jäger abgewiesen. Die Entscheidung, London anzugreifen, gilt als ein großer strategischer Fehler mit weit reichenden Folgen, denn weitere Angriffe auf London bis zum Jahresende mit durchschnittlich 160 Bombern bewirkten, militärisch besehen, wenig, waren aber für die Luftwaffe äußerst verlustreich. Am 17. September 1940 verschob Hitler das „Unternehmen Seelöwe“ auf unbestimmte Zeit.

Die Luftwaffe setzte im Winter und Frühjahr ihre Nachtangriffe fort, nicht um die Invasion vorzubereiten, sondern um die Industrie zu treffen und die Bevölkerung zu demoralisieren. In der Nacht vom 14. auf den 15. November 1940 waren die Motorenfabriken in Coventry Ziel eines Angriffs der Luftwaffe, wobei durch Brandbomben auch drei Viertel der Wohngebiete getroffen und 568 Bewohner getötet wurden. Der Begriff „coventrieren“, eine Wortprägung des "Reichsministers für Volksaufklärung und Propaganda", Joseph Goebbels, fand daraufhin Eingang in den deutschen Militärjargon.

Insgesamt verloren bei Luftangriffen auf London, Coventry und weitere britische Städte 1940/41 etwa 43.000 Zivilisten das Leben. Allein in London wurden bei 57 Nachtangriffen zwischen dem 9. September 1940 und dem Neujahrstag 1941 14.000 Menschen getötet. Im Oktober 1940 hatte die Luftwaffe 1733 Kampfflugzeuge verloren, die RAF 915.

„Die Luftschlacht endete als militärisches Patt, war aber eine politische und strategische Niederlage ersten Ranges für Hitler, dem es zum ersten Mal nicht gelungen war, einem Land seinen Willen aufzuzwingen.“ Mitentscheidend für den Misserfolg der Luftwaffe waren die Fehleinschätzung der Effektivität der britischen Radaranlagen und des Leitsystems sowie die mangelnde Reichweite der deutschen Jagdflugzeuge. Die britischen Flugzeugwerke fertigten außerdem mehr Maschinen als die deutschen.

Mit dem Ende der Luftschlacht „war auch die Invasion geplatzt.“ Am 18. Dezember 1940 gab Hitler seine formelle Weisung für das "Unternehmen Barbarossa" heraus, „auch vor Beendigung des Krieges gegen England Sowjetrussland in einem schnellen Feldzug niederzuwerfen.“ Hitlers Entschluss war auch dadurch geprägt, „London via Moskau“ zu besiegen. Ab Mai 1941 gingen die deutschen Luftangriffe auf Großbritannien deutlich zurück, weil Bomber und Jagdflugzeuge für den bevorstehenden Angriff auf die Sowjetunion gebraucht wurden.

Insgesamt verloren 61.000 Briten durch deutsche Luftangriffe ihr Leben, davon 8.800 bei Angriffen mit den „Vergeltungswaffen“ "V1" und "V2".

Nachdem der Kriegsgegner Großbritannien nicht besiegt werden konnte, suchte Hitler nach einem Ausweg. In Hitlers Vorstellung boten sich zwei Möglichkeiten an: ein Angriff auf britische Positionen im Mittelmeer oder ein Angriff auf die Sowjetunion, deren Ausbeutung als „Lebensraum im Osten“ seit langer Zeit fester Bestandteil seiner Ideologie war.

Zunächst wandte er sich der Mittelmeeroption zu. Spaniens Diktator Franco war im Juni 1940 noch bereit gewesen, an deutscher Seite in den Krieg einzutreten. Er forderte dafür Gibraltar, Französisch-Marokko, Oran und Vergrößerung der Kolonien Spanisch-Sahara und Spanisch-Guinea sowie vorherige umfangreiche Lieferungen von Waffen, Rohstoffen und Nahrungsmitteln. Hitler hielt Spaniens Unterstützung damals nicht für nötig und ließ ausweichend antworten. Als er sich am 23. Oktober in Hendaye mit Franco traf, zeigte Hitler nunmehr ein viel größeres Interesse am Kriegseintritt Spaniens, den er für Januar 1941 vorschlug. Spanische und deutsche Truppen könnten Gibraltar erobern. Franco und Súñer, dessen Schwiegersohn und späterer Außenminister, waren jedoch nicht mehr von der baldigen Niederlage Großbritanniens überzeugt. Sie ließen sich nicht zu unbedachten Schritten verleiten und wiederholten absichtlich überzogene Forderungen nach der Lieferung von Waffen. Hitler wiederum musste hinsichtlich der spanischen Kolonialwünsche in Nordafrika Rücksicht auf "Vichy-Frankreich" nehmen. Franco war daher lediglich mit der Unterzeichnung eines Protokolls einverstanden, in dem Spanien seine Bereitschaft erklärte, Mitglied des "Dreimächtepakts" zu werden und in den Krieg einzutreten – unter dem Vorbehalt, dass der Zeitpunkt noch gemeinsam festgesetzt werden sollte. Damit war die Abmachung für Hitler praktisch wertlos. Im internen Kreis „wütete“ er später über das „Jesuitenschwein“ und den „falsche[n] Stolz des Spaniers“.

Wie in Hendaye hinsichtlich Spaniens, so blieb auch in Montoire beim Treffen mit Pétain am 24. Oktober 1940 offen, ob es zu einer konkreten Zusammenarbeit mit Frankreich kommen würde. Hitler wollte, wenn schon nicht eine Kriegserklärung an England, so wenigstens die Verteidigung der französischen Kolonien in Nordafrika und Nahost gegen Angriffe der FFL und der Briten erreichen sowie die Überlassung von Stützpunkten an der afrikanischen Mittelmeer- und Atlantikküste für den Seekrieg gegen Großbritannien. Marschall Pétain stimmte im Prinzip einer Zusammenarbeit mit Deutschland zu, lehnte aber indirekt einen Kriegseintritt Frankreichs ab, indem er darauf hinweisen ließ, dass eine Kriegserklärung nur durch Parlamentsbeschluss ausgesprochen werden könne. Ein solcher Beschluss sei fraglich. Das Ergebnis des Treffens war daher für den Krieg gegen Großbritannien bedeutungslos.

Italien war im Juni 1940, kurz vor der französischen Kapitulation, Deutschlands Kriegsverbündeter geworden. Der japanische Botschafter Saburō Kurusu und die Außenminister Galeazzo Ciano (Italien) sowie Joachim von Ribbentrop (Deutschland) unterzeichneten am 27. September 1940 in Berlin den "Dreimächtepakt", der gegenseitigen Beistand für den Gewinn der Hegemonie über Europa beziehungsweise Ostasien vorsah. Die Bestimmungen richteten sich nicht gegen die Sowjetunion; vielmehr sollten die USA von einem Kriegseintritt abgehalten werden. Obwohl der Pakt ein großer propagandistischer Erfolg war, blieb er für die Bildung einer aktiven Front gegen Großbritannien ohne sofortige Wirkung.

In Osteuropa gewann Hitler Rumänien als Verbündeten hinzu, das für ihn wegen der strategischen Lage und der Erdölfelder bei Ploiești äußerst wertvoll war. Zwar ließ er die Sowjetunion das nach dem Ersten Weltkrieg verlorene Bessarabien einfordern, wie im Hitler-Stalin-Pakt vorgesehen. Doch Hitler garantierte im Sommer 1940 Rumäniens Bestand, das seinerseits aus dem Völkerbund austrat.

Mussolini hoffte, dass nach dem deutschen Achsenpartner auch Italien militärische Erfolge erringen könne, obwohl König Viktor Emanuel III. noch 1939 die realistische Einschätzung vertreten hatte, das Heer befinde sich in einem erbärmlichen Zustand und die Offiziere würden nichts taugen. Nachdem Italien am 10. Juni 1940 in den Krieg eingetreten war, ließ Mussolini britische Positionen im Mittelmeer sowie in Nord- und Ostafrika angreifen. Nach geringen italienischen Anfangserfolgen in Ägypten und der Besetzung Britisch-Somalilands ging im Spätsommer und Herbst 1940 die Initiative verloren. Die Gegenoffensiven von britischen und Commonwealth-Truppen (Operation Compass) führten Anfang 1941 zu einer verheerenden Niederlage in Ägypten und im Gebiet zwischen Tobruk und der libysch-ägyptischen Grenze.

130.000 italienische Soldaten in Nordafrika gerieten in britische Gefangenschaft. Im Februar 1941 reagierte Hitler mit der Entsendung des Deutschen Afrikakorps (Unternehmen Sonnenblume), um wenigstens zu verhindern, dass Italien die Kolonie Libyen verliere. In Ostafrika verlor Italien bis Ende November 1941 30.000 Soldaten (24.000 Kriegsgefangene und 6000 Gefallene) und seine dortigen Kolonien.

Die Großmachtambitionen Mussolinis waren bereits seit den 1930er-Jahren auf den Balkan gerichtet. Am 28. Oktober 1940 griffen italienische Verbände Griechenland an (Griechisch-Italienischer Krieg). Mussolini glaubte an einen raschen Sieg; stattdessen entwickelte sich der Krieg zu einem Fiasko. Die griechischen Truppen waren gut organisiert und kannten sich in dem schwierigen Gelände des Pindos-Gebirges aus. „Binnen vierzehn Tagen hatte sich der erwartete Triumph in eine Demütigung für Mussolinis Regime verwandelt“, als die Angreifer bis über die Grenzen Albaniens zurückgedrängt worden waren.

Noch bedeutsamer war, dass die Position der Achse in Nordafrika ernstlich geschwächt wurde, weil angesichts des sich anbahnenden Debakels dringend benötigte italienische Truppen von dort nach Griechenland verlegt wurden. Dabei war Nordafrika von größter Bedeutung: Wären die schwachen britischen Truppen aus Ägypten und vom Suezkanal vertrieben worden, hätte der Weltkrieg einen anderen Verlauf genommen.

Anfang des Jahres 1941 versuchte das Deutsche Reich im Balkankonflikt zu vermitteln. So unterbreitete Hitler dem Königreich Jugoslawien den Vorschlag, dem "Dreimächtepakt" beizutreten, was jedoch abgelehnt wurde. Griechenland verzichtete ebenfalls auf jeden Vermittlungsversuch, da seine Armee die italienischen Soldaten an der Front zum Rückzug zwingen konnte. Eine italienische Großoffensive am 9. März wurde zum Desaster. Am 27. März trat Jugoslawien schließlich dem "Dreimächtepakt" bei. Die Folge waren antideutsche Demonstrationen und ein Staatsstreich des serbischen Offizierskorps gegen die Regierung des Prinzregenten Paul, woraufhin der Beitritt wieder rückgängig gemacht wurde.

Diese unerwartete Wendung führte zu Hitlers Entscheidung, Jugoslawien anzugreifen. Er rechtfertigte den Angriff als Vergeltung gegen eine serbische „Verbrecherclique“ in Belgrad. Am 6. April überschritten Verbände der Wehrmacht die Grenze nach Jugoslawien, und die Luftwaffe begann, Belgrad in Schutt und Asche zu legen (→ Unternehmen Strafgericht), obwohl die Hauptstadt zur „offenen Stadt“ erklärt worden war. Der weitere Vormarsch erfolgte wie in einem geplanten Manöver. Am 10. April wurde Zagreb besetzt, wo am selben Tag der Unabhängige Staat Kroatien ausgerufen wurde. Belgrad wurde am 13. April von deutschen Truppen besetzt. Am 17. April unterschrieben die jugoslawischen Befehlshaber die Kapitulation der jugoslawischen Armee.

Ebenfalls am 6. April begann der deutsche Feldzug gegen Griechenland. Anders als in Jugoslawien war der griechische Widerstand stellenweise ausgesprochen hart. Besonders in den Gebirgslagen und im Gebiet der stark verteidigten Metaxas-Linie kamen deutsche Soldaten nur langsam und unter hohen Verlusten voran. Am 9. April fiel Saloniki. Gleichzeitig wurde die griechische Armee in Ostmazedonien abgeschnitten und die Metaxas-Linie stärker bedrängt. Die griechischen Verstärkungen von der albanischen Front wurden bei ihrem Vormarsch durch die gebirgige Landschaft von deutschen und italienischen Panzereinheiten sowie Luftangriffen aufgehalten. Am 21. April mussten 223.000 griechische Soldaten kapitulieren.

Die in Griechenland stationierten britischen Verbände bauten unterdessen eine Verteidigung an den Thermopylen auf. Diese wurde am 24. April überrannt, woraufhin die Alliierten eine amphibische Evakuierungsoperation einleiten mussten, in der 50.000 Soldaten nach Kreta und Ägypten verschifft wurden. Am 27. April rückte die Wehrmacht in Athen ein.

Hitler befahl am 25. April, Kreta mit Luftlandetruppen, Fallschirmjägerverbänden und der 5. Gebirgs-Division Mitte Mai 1941 zu erobern. Am 20. Mai 1941 landeten deutsche Fallschirmspringer auf Kreta. Dabei hatten sie hohe Verluste. Die gelandeten Einheiten konnten zunächst keine Flugplätze für Nachschub und Verstärkungen erobern. Erst durch verstärkten Einsatz der Luftwaffe und nach erfolgreichen Landungen auf umkämpften Flugplätzen stabilisierte sich die Lage für die Angreifer. Die Alliierten, darunter Neuseeländer und Australier, verteidigten Kreta eine Woche lang, bis sie sich mit etwa 17.000 Mann nach Ägypten absetzen mussten. Aufgrund der hohen deutschen Verluste beschloss Hitler, in Zukunft keine Luftlandungen mehr durchzuführen. Der Versuch, die strategisch wichtige Insel Malta zu erobern, unterblieb daher.

Die Absicht, die Sowjetunion zu überfallen, erörterte Hitler am 31. Juli 1940 – parallel zu den Invasionsplänen gegen Großbritannien – in einem Kreis der höchsten Generale. Zu dieser Zeit hoffte Hitler noch, dass Großbritannien über kurz oder lang aufgeben würde und er auf der Basis einer „Verständigung mit England“ alle Kraft nach Osten werfen könne, um sein großes Ziel anzugehen, „Lebensraum im Osten“ zu erobern. Wenn Russland geschlagen sei, dann sei Englands letzte Hoffnung getilgt. Am 18. Dezember 1940 erfolgte die Weisung, im Mai 1941 die Sowjetunion anzugreifen. Hintergrund dieser Entscheidung war auch die Erkenntnis der Unmöglichkeit einer Landung auf der britischen Insel, solange Luftwaffe und Marine dazu zu schwach waren. Wenn auch nicht alleiniges Motiv, so stand doch der Wunsch dahinter, London via Moskau zum Ausscheiden aus dem Krieg zu zwingen. Ein Angriff auf die Sowjetunion wurde von Hitler als wenig riskant angesehen, weil er die politische Stabilität der Sowjetunion und deren militärisches Potential völlig unterschätzte. Gegenüber Mannerheim gab er am 4. Juni 1942 in Finnland in einem vertraulichen Gespräch, das ohne Hitlers Wissen aufgezeichnet wurde, diese Unterschätzung unumwunden zu. Mit seiner Fehleinschätzung des sowjetischen Militärpotentials stand Hitler nicht alleine da; fast alle seine Befehlshaber teilten sie ebenfalls. Am 30. März 1941 verkündete er vor über 200 höheren Offizieren in der Reichskanzlei, der bevorstehende Krieg sei ein rassenideologischer Vernichtungskrieg und ohne Rücksicht auf kriegsvölkerrechtliche Normen zu führen. Die Befehlshaber müssten jegliche persönlichen Gewissensbisse überwinden. Im Osten sei „Härte mild für die Zukunft.“ Keiner der Anwesenden nahm den Anlass wahr, Hitlers Forderungen nachher noch einmal zur Erörterung zu stellen.

Mit dem Angriff auf die Sowjetunion, dem "Unternehmen Barbarossa", entstand am 22. Juni 1941 eine neue Front im Osten Deutschlands. Sie wurde (neben der japanisch-chinesischen) die am längsten bestehende Front im Zweiten Weltkrieg, die die meisten Opfer forderte. Die deutschen Truppen eroberten riesige Gebiete des europäischen Teils der Sowjetunion; zusammen mit unmittelbar nachrückenden Einheiten der SS und Einsatzgruppen hatten sie den Auftrag, die Gebiete rücksichtslos auszubeuten, einen Teil ihrer Einwohner zu töten und die anderen zur Zwangsarbeit zu zwingen. Dabei wurden systematisch viele Zehntausende Juden umgebracht.

Ein halbes Jahr später wurden die USA, die bereits zuvor Großbritannien indirekt unterstützt hatten, durch Hitlers Kriegserklärung offizieller Kriegsgegner Deutschlands. Amerika brauchte Zeit, seine Wirtschaft auf den Krieg umzustellen. Eine Konfrontation der Wehrmacht mit anglo-amerikanischen Landstreitkräften fand erstmals im November 1942 in Nordafrika statt ("Operation Torch").

Der Balkanfeldzug hatte den Angriffszeitpunkt für einen Überfall auf die Sowjetunion um vier Wochen verschoben. Der Angriff fand erst am 22. Juni 1941 statt. Obwohl Berechnungen auf deutscher Seite zeigten, dass die Versorgung der Wehrmacht nur bis zu einer Linie entlang Pskow, Kiew und der Krim möglich war, verlangte Hitler die Eroberung Moskaus im Rahmen eines einzigen, ununterbrochenen Feldzuges. Hier zeigte sich dessen gefährliche Unterschätzung der Sowjetunion, die schon nach der Kapitulation Frankreichs im Juni 1940 zum Ausdruck gekommen war ("s. o."). Für den Überfall standen drei Heeresgruppen (Nord, Mitte, Süd) bereit. Die Heeresgruppe Nord (von Leeb) sollte die baltischen Staaten erobern und dann nach Leningrad vorstoßen. Auf der Heeresgruppe Mitte (von Bock) lag die Hauptlast. Sie sollte nach Moskau vorrücken und war entsprechend stark gerüstet. Die Heeresgruppe Süd (von Rundstedt) sollte die Ukraine erobern. Vom besetzten Norwegen aus wurden ebenfalls Angriffe gegen die Sowjetunion unternommen. Sie zielten auf Murmansk, den Hafen und die dortige Eisenbahnverbindung, die „Murmanbahn“. An dem Feldzug beteiligt waren 600.000 Soldaten aus verbündeten, neutralen und besetzten Staaten in geschlossenen Großverbänden bis zur Ebene von Armeen und unter der Befehlsgewalt ihrer eigenen Offiziere. Später kamen 30.000 Freiwillige aus neutralen und besetzten Gebieten (u. a. Polen, Estland, Lettland, Litauen, Weißrussland, Ukraine, Russland, Kaukasus) hinzu, meist Repräsentanten rechtsradikaler oder faschistischer Strömungen in ihren Heimatländern.

Am frühen Morgen des 22. Juni 1941, zwischen 3:00 Uhr und 3:30 Uhr, begann der Angriff gegen die Sowjetunion. Obwohl ihm mehrere ernst zu nehmende Hinweise, unter anderen von Harro Schulze-Boysen, Arvid Harnack und Richard Sorge, zugegangen waren, blieb Stalin davon überzeugt, dass Hitler die Sowjetunion nicht vor einem Sieg über Großbritannien angreifen werde. Der Angriff wurde von 153 deutschen Divisionen, darunter 19 Panzer- und 12 motorisierte Divisionen, auf einer Frontlänge von 1600 km zwischen der Ostsee und den Karpaten geführt. Zwei Divisionen operierten von Finnland aus. Die militärischen Befehlshaber der Roten Armee waren nicht auf diese bisher größte militärische Offensive der Weltgeschichte mit etwas über drei Millionen Heeressoldaten eingestellt. Innerhalb einer Woche kamen Soldaten aus den verbündeten Staaten Rumänien, Italien, Slowakei und Ungarn sowie Finnland hinzu, das kein Bündnis mit Deutschland hatte, und Wert auf die Feststellung legte, dass es gegen die Sowjetunion einen „Fortsetzungskrieg“ zur Rückeroberung der 1940 abgetretenen Gebiete führe. Die Rote Armee hatte an der Westgrenze annähernd drei Millionen Soldaten stationiert, die mit Panzern, Artillerie und Flugzeugen den Angreifern zwar weit überlegen, jedoch nicht kampfbereit waren. Viele der sowjetischen Soldaten an der Grenze ergaben sich ohne Widerstand, während die motorisierten deutschen Truppen zunächst zügig vorankommen konnten. Die damalige Fähigkeit der sowjetischen Streitkräfte, einen Angriff oder einen Krieg gegen Deutschland zu führen, muss auch nach neueren Erkenntnissen stark bezweifelt werden. Der erste Wehrmachtbericht am Morgen des 22. Juni 1941 erweckte dagegen den Eindruck, sowjetische Truppen seien nach Ostpreußen eingedrungen. Er unterstützte damit die Präventivkriegslegende der NS-Propaganda, die den Angriff als Verteidigungskrieg darstellte. Tatsächlich war der Überfall auf die Sowjetunion im Wesentlichen ein ideologisch verbrämter Eroberungs- und Vernichtungskrieg mit dem von Hitler bereits Jahre zuvor formulierten Ziel der Gewinnung von „Lebensraum im Osten“. Damit war „ein blockadefestes Großimperium“ bis zum Ural und über den Kaukasus hinaus gemeint.

Am 22. Juni mittags verlas der sowjetische Außenminister Molotow im Rundfunk eine Rede, in der er den Ausbruch des Krieges bekannt gab. Erst elf Tage später richtete sich Josef Stalin am 3. Juli mit einer Rundfunkansprache an das Volk. Davor war Minsk eingeschlossen und wenig später besetzt worden. Hitler beharrte gegenüber dem OKH lange Zeit auf dem Vorrang der Eroberung der Ukraine anstelle Moskaus. Das Hauptziel der NS-Führung bestand darin, sich die Ölvorräte des Kaukasus und das Getreide in der Ukraine zu sichern. Dies würde sie nach Hitlers Überzeugung unbesiegbar machen. Trotz siegreicher Kesselschlachten scheiterte der Plan "Barbarossa" bereits im August 1941, weil aus diesen Schlachten große Teile des Gegners entkamen und sich neu formierten, der Überraschungseffekt des Überfalls abflaute, die deutschen Verluste zunahmen und Hitlers „Zickzack der Anordnungen“ zur Schwerpunktbildung bei der "Heeresgruppe Mitte" oder der "Heeresgruppe Süd" sich häuften. Erst nach der Einnahme Kiews und Charkows wurde am 2. Oktober der Vorstoß auf Moskau wieder aufgenommen. Doch schon im Oktober begann es zu regnen, im November setzte Frost mit minus 22 Grad Celsius ein. Daraufhin verlangsamte sich die deutsche Offensive, sie blieb immer häufiger in Schlamm oder Schnee stecken, und der Angriff auf Moskau kam am 5. Dezember wegen arktischer Temperaturen von bis zu minus 50 °C und der sich versteifenden sowjetischen Gegenwehr zum Erliegen. Am Tag darauf setzte eine sowjetische Gegenoffensive mit gut für den Winterkrieg ausgerüsteten Einheiten aus Fernost unter dem Befehl von Schukow ein, wodurch eine Eroberung der Hauptstadt Moskau durch deutsche Truppen verhindert wurde. Die Flucht der Heeresgruppe konnte zwar durch einen unbedingten Haltebefehl Hitlers gestoppt werden, aber sein Ziel, „die Sowjetunion in einem schnellen Feldzug niederzuwerfen“, war misslungen, „Barbarossa“ gescheitert. Die verlorene Schlacht um Moskau war der geopolitische Wendepunkt des Zweiten Weltkrieges, „die eigentliche Zäsur“, weil die Serie der deutschen Blitzsiege abriss. Die Wehrmacht verlor bis Ende Januar 1942 rund ein Drittel ihrer Soldaten. Eine Million Gefallene, Verwundete oder Vermisste konnten nur zur Hälfte ersetzt werden. Noch weit stärkere Verluste hatte die Rote Armee mit bis zu diesem Zeitpunkt rund 3,3 Millionen Gefangenen, einer nicht näher bekannten Zahl von Toten sowie 2,2 Millionen Verwundeten und Kranken.
Finnland versuchte im Fortsetzungskrieg, mit deutscher Unterstützung die im Winterkrieg an die Sowjetunion verlorenen Gebiete in Karelien zurückzuerobern. Nachdem es dieses Ziel im Sommer 1941 erreicht hatte, blieb Finnland jedoch nicht defensiv, sondern besetzte bis Dezember 1941 umstrittene, nie zuvor finnisch gewesene karelische Gebiete.

Als Reaktion auf den deutschen Angriff marschierten britische und sowjetische Truppen am 25. August 1941 im Rahmen der Anglo-Sowjetischen Invasion in den Iran ein. Ziel des Angriffs waren zum einen die Sicherung der Ölförderung der Anglo-Iranian Oil Company und zum anderen die Übernahme der Transiranischen Eisenbahn, um die sowjetischen Truppen auch auf dem Weg über den Iran mit britischem und US-amerikanischem Nachschub versorgen zu können.

Die Rote Armee hatte sich neu organisiert. Die Großbetriebe der Rüstungsproduktion wurden, unerreichbar für die deutsche Luftwaffe, an den Ural verlegt. Am 16. Dezember gab Hitler den Befehl zum Halten. Bis zum Ende des Jahres wurde die Wehrmacht jedoch weiter zurückgedrängt. Auch die ökonomische Zwischenbilanz fiel Ende 1941 nüchtern aus: Der Verlust des Donezbeckens hatte nicht, wie von Hitler erwartet, zum Zusammenbruch der sowjetischen Wirtschaft geführt. Das „Reichskommissariat Ukraine“, schrieb zum Beispiel ein im Zivilberuf als Professor für Volkswirtschaft tätiger Beamter an den Chef der Wehrmachtrüstung, „erweise sich als völliger Fehlschlag“. Junge, schlecht ausgebildete, „inkompetente“ Beamte, die mit Reitpeitschen umherliefen, würden ein brutales „Herrentum“ praktizieren. Es sei zu befürchten, dass „sich die Gesamtstimmung des ukrainischen Volkes gegen uns wendet.“ Die Ausschaltung der Juden in Handel und Handwerk habe das „Rückgrat der Wirtschaft“ zerstört. Dadurch, dass man die russischen Kriegsgefangenen verhungern lasse, werde „Raubbau“ an „verfügbarer menschlicher Arbeitskraft“ getrieben.

Hitlers „Weisung Nr. 41“ vom 5. April 1942 („Fall Blau“) legte für die Sommeroffensive fest, dass zunächst Stalingrad an der Wolga, danach der Kaukasusraum bis zur türkischen und iranischen Grenze erobert werden sollte, um die dortigen Erdölzentren in die Hand zu bekommen. Zunächst trat im Südabschnitt der Front die Rote Armee zum Gegenangriff an. In der Schlacht bei Charkow wurden im Mai 1942 die angreifenden sowjetischen Verbände vollständig eingeschlossen. Erneut gerieten fast 250.000 sowjetische Soldaten in Gefangenschaft. Von Mai bis Juli wurden Sewastopol und die Halbinsel Kertsch auf der Krim erobert, die als Sprungbrett für die Offensive bis zum Kaukasus dienen sollten. Dabei gerieten 150.000 Rotarmisten in Gefangenschaft. Weil im Juni 1942 Tobruk in Nordafrika fiel (→ Unternehmen Theseus), weckte die NS-Propaganda nach der Krise im Winter wieder große Hoffnungen auf einen baldigen Gesamtsieg.
Ende Juni 1942 begann die Sommeroffensive im Süden der Ostfront zwischen Kursk und Taganrog am Asowschen Meer, deren Bedeutung Hitler noch einmal am 1. Juni 1942 auf einer Oberbefehlshaber-Besprechung in Poltawa der Heeresgruppe Süd herausgestellt hatte: „Wenn ich das Öl von Maikop und Grosny nicht bekomme, dann muß ich diesen Krieg liquidieren.“ Stalin sah ähnliche Folgen für die Sowjetunion voraus, falls „unsere wichtigste Wasserstraße und bald auch unser Erdöl verloren gehen“. Am 3. Juli überschritten deutsche Kräfte den Don bei Woronesch. Zwanzig Tage später konnte Rostow am unteren Don erobert werden, doch blieb die Gefangenenzahl gering, da die Rote Armee – im Gegensatz zu 1941 – einen strategischen Rückzug hinter den Don, die Wolga bei Stalingrad und zum westlichen und mittleren Kaukasus einleitete. Am selben Tag, dem 23. Juli, wurde die „Weisung Nr. 41“ ("s. o.") so abgeändert, dass statt des vorgesehenen Nacheinanders nunmehr zwei gleichzeitige Vorstöße ins Kaukasusgebiet und gegen Stalingrad vorgesehen waren. Im Unterschied zur Weisung vom April, bei der Halders Handschrift zu erkennen war, ging diese Weisung direkt auf eine Entscheidung Hitlers zurück. Der Generalstab hatte sie verhindern wollen. „Von da an war eine Niederlage voraussehbar.“ Hitler weigerte sich auch, realistische Schätzungen der sowjetischen Panzerproduktion zur Kenntnis zu nehmen, die tatsächlich mehr als das Vierfache der deutschen erreicht hatte.

Die Heeresgruppe Süd wurde in die Heeresgruppe A (→ Kaukasus) und Heeresgruppe B (→ Stalingrad) geteilt. Die schwächere Heeresgruppe B bekam den Auftrag, Stalingrad zu erobern und danach die Wolga hinunter bis Astrachan, 75 km nördlich vom Kaspischen Meer entfernt, vorzudringen, um so die Fortsetzung des sogenannten "Persischen Korridors" zu sperren. Die Heeresgruppe A sollte die Ostküste des Schwarzen Meeres besetzen, die Ölquellen von Maikop und Grosny im westlichen Kaukasus in Besitz nehmen und schließlich, weit südlich am Kaspischen Meer, Baku und dessen Ölquellen erobern. Diese Strategie lässt sich „nur als glatter Wahnsinn bezeichnen“. Tatsächlich kam sie nur bis in den Westkaukasus und eroberte das nördlich davon gelegene Maikop, dessen Ölanlagen aber systematisch zerstört worden waren. Das nächstgelegene und wichtige Erdölgebiet von Grosny, dessen Besitz Hitler als wesentlich für die Weiterführung des Krieges ansah, wurde nicht erreicht. Damit wurde schon Mitte August deutlich, dass das operative Ziel der Heeresgruppe A nicht erreicht werden würde; der Angriff auf die Passhöhen des Kaukasus musste Ende August 1942 eingestellt werden. Auch die Heeresgruppe B konnte ihr strategisches Ziel nicht erreichen, obwohl Hitler am 8. November 1942 im Münchener Löwenbräukeller noch von einem Erfolg gesprochen hatte: „Ich wollte zur Wolga kommen, und zwar an einer bestimmten Stelle, an einer bestimmten Stadt. […] Dort schneidet man nämlich 30 Millionen Tonnen Verkehr ab. […] Es kommt kein Schiff mehr die Wolga hoch. Das ist das Entscheidende.“ Zwar eroberte sie fast ganz Stalingrad, wurde dort aber Ende November 1942 von sowjetischen Truppen eingekesselt und musste am 31. Januar 1943 kapitulieren.

Als Hitler mit Goebbels im Führerhauptquartier "Werwolf" bei Winniza (Ukraine) am 19. August unter vier Augen sprach, war er dagegen noch übertrieben optimistisch gewesen: Man werde nach den Ölquellen von Maikop, Grosny und Baku Kleinasien erobern und danach den Iran, den Irak sowie Palästina, um derart die Briten von ihrer Ölversorgung abzuschneiden. Beim baldigen Angriff auf Stalingrad erwarte er die Eroberung der Stadt innerhalb von acht Tagen. Zur selben Zeit wuchs in der Sowjetunion die Enttäuschung über die ausbleibende Eröffnung einer „zweiten Front“ durch die Alliierten in Westeuropa. Gleichwohl trugen die auf der Basis des Leih- und Pachtgesetzes erfolgten Hilfslieferungen der Amerikaner wesentlich dazu bei, dass die Rote Armee die Kriegführung durchhalten konnte. Dabei waren neben den gelieferten Militärgütern die Nahrungsmittel von Bedeutung. Bei den sowjetischen Soldaten hießen die Büchsen mit festem, rosa Pressfleisch „Zweite Front“. Mehr als die Hälfte der in die UdSSR gelieferten Güter waren, an Gewicht gemessen, Lebensmittel: „Sie reichten aus, um jeden sowjetischen Soldaten während des gesamten Krieges täglich mit schätzungsweise einem halben Pfund Nahrungskonzentrat zu versorgen.“

Die bisherigen Verluste (mehr als 1 Million Soldaten seit Beginn des Russlandfeldzuges), gigantische Überdehnung der Front, unzureichender Nachschub und massiver sowjetischer Widerstand ließen indes den Vormarsch der Heeresgruppen A und B Anfang September 1942 zum Stillstand kommen. Deswegen kam es zu einer Führungskrise im deutschen Oberkommando, in deren Verlauf der Oberbefehlshaber der Heeresgruppe A, Feldmarschall Wilhelm List, und der Generalstabschef des Heeres, Generaloberst Halder, von Hitler entlassen wurden. Hitler übernahm selbst (bis zum 22. November 1942) den Oberbefehl der Heeresgruppe, Nachfolger Halders wurde General Kurt Zeitzler.

Am 4. Oktober 1942 besprachen die Vertreter des sowjetischen Oberkommandos, Georgi Schukow und Alexander Wassilewski, mit den Befehlshabern der um Stalingrad eingesetzten "Fronten" (sowj. Armeen) die geplanten Umfassungsoperationen, durch die die 6. Armee im Raum zwischen Wolga und Don eingeschlossen und vernichtet werden sollte: Im November 1942 wurde durch die Operation Uranus die Verbindung zwischen Stalingrad und der deutschen Front westlich der Wolga unterbrochen. Die Operation Kolzo(russ.: Ring) vollendete die sowjetische Einschließung Stalingrads.

Mit dem Einmarsch deutscher Truppen wurde in den verschiedenen Staaten Europas eine Umgestaltung entsprechend den nationalsozialistischen besatzungspolitischen, rassenideologischen und bevölkerungspolitischen Vorstellungen eingeleitet, die die Besatzer mit allen Mitteln der Repression durchzusetzen versuchten. Das betraf vor allem den politischen und militärisch-politischen Widerstand und die jüdische Minderheit, die im gesamten deutschen Machtbereich zum Objekt von Verfolgung und Vernichtung wurde.

Mit dem Generalplan Ost entstand unter Heinrich Himmler, dem Reichskommissar für die Festigung deutschen Volkstums, ein umfassendes bevölkerungs- und siedlungspolitisches Konzept zur kolonialistischen „Germanisierung“ der besetzten und noch zu erobernden Ostgebiete. Besonders die Bevölkerung Polens, Serbiens, der Ukraine, Weißrusslands und Russlands sollte demnach „durchaus niedergehalten werden“. Aus der rücksichtslosen Ausplünderung dieser Gebiete ergab sich, dass Millionen der Hungertod drohte, was von den Planern hingenommen, wenn nicht begrüßt wurde. Nach der Entscheidung für den „Arbeitseinsatz“ als dem ökonomisch ergiebigeren Umgang mit der Bevölkerung vor allem der Sowjetunion wurden Millionen Zwangsarbeiter nach Deutschland verschleppt. Repression und Ausbeutung stießen bald auf Widerstand.

In den Niederlanden streikten zum Beispiel die Polizei und die Eisenbahner. In Frankreich kam es zu bewaffneten Angriffen. In den Balkanstaaten und in Osteuropa war der Widerstand besonders stark und verteilte sich oft auf verschiedene Gruppierungen. Jugoslawische Partisanen unter der Führung von Tito konnten einzelne zusammenhängende Gebiete befreien, und in Griechenland kontrollierten Partisanen der ELAS, EDES und EKKA die Berge. In der Sowjetunion bekämpften kommunistische und anarchistische Gruppen das deutsche Besatzungsregime. Der Partisanenkrieg in der Sowjetunion war von der Roten Armee schon vor dem Krieg geplant worden; entsprechende Einheiten wurden aufgestellt, die nach der Eroberung eines Gebietes den Widerstand gegen die Besatzer im Hinterland der Front weiterführen sollten.

Im Allgemeinen war der Partisanenkrieg durch zahlreiche Verstöße gegen das Kriegsrecht gekennzeichnet. Die Partisanen machten meistens keine Gefangenen oder zwangen sie zum Überlaufen. Auf deutscher Seite enthielt der Kommissarbefehl die Anweisung, Politkommissare der Roten Armee nicht als Kriegsgefangene zu behandeln, sondern sie „nach durchgeführter Absonderung zu erledigen“. So nahm der Partisanenkrieg in Osteuropa seinen Anfang als systematischer Ausrottungskrieg. In Griechenland (Kefalonia, Chortiatis), Frankreich (Oradour, Maillé) oder Italien (Marzabotto, Caiazzo) kam es zu vereinzelten Massakern an der Zivilbevölkerung.

Die Vereinigten Staaten hatten in dem Konflikt zunächst formal Neutralität gewahrt. Die isolationistische Grundstimmung in der US-Bevölkerung ermöglichte es Präsident Roosevelt nicht, direkt an der Seite Großbritanniens und der Sowjetunion in den Krieg einzugreifen.

Japan nutzte den Ausbruch des Zweiten Weltkriegs in Europa zur Besetzung des nördlichen Teils von Französisch-Indochina, zwang Großbritannien zur Schließung der Burmastraße und schloss im September 1940 in Berlin den "Dreimächtepakt" mit Deutschland und Italien, der dazu dienen sollte, die USA von einem Kriegseintritt abzuhalten. Der Kongress der USA schuf mit dem Leih- und Pachtgesetz vom 11. März 1941 die legale Grundlage für die vorher bereits praktizierte Unterstützung Großbritanniens. Am 31. Juli 1941 froren die USA, Großbritannien und die Niederlande die finanziellen Mittel Japans ein, was praktisch einem Embargo gleichkam, sodass die Führung des japanischen Kaiserreichs in einem Krieg gegen die USA, Großbritannien und die Niederlande die einzige Möglichkeit sah, ihre imperialistischen Ambitionen in Südostasien abzusichern.

Nach dem Angriff Japans auf die US-Pazifikflotte in Pearl Harbor am 7. Dezember 1941 und den am 11. Dezember erfolgten Kriegserklärungen Deutschlands und Italiens befanden sich die USA offiziell im Kriegszustand mit den Achsenmächten. Trotz des japanischen Angriffs und unmittelbar nach der Beantragung der Kriegserklärung an Japan im Kongress erinnerte Roosevelt seine Berater daran, dass Deutschland das Hauptziel bleibe. Der Grundsatz „Germany first“ wurde während der Arcadia-Konferenz mit dem Entschluss, Deutschland als den gefährlichsten und von GB und der UdSSR einzigen direkt erreichbaren Gegner zuerst zu besiegen, bestätigt. Außerdem würde die Niederringung Deutschlands den Zusammenbruch Japans über kurz oder lang herbeiführen.

Durch Hitlers Kriegserklärung an die USA und den Rückschlag vor Moskau wurde der Dezember 1941 zum Wendepunkt der Weltpolitik. Von nun an war Deutschland nicht mehr in der Lage, den Zweiten Weltkrieg eindeutig zu gewinnen.

Ähnlich wie auf dem europäischen Kriegsschauplatz mussten die Italiener in Nordafrika schwere Rückschläge gegen die Briten hinnehmen. Die italienische Offensive gegen Ägypten im September 1940 kam bereits nach 100 Kilometern infolge der Zerstörung der Nachschubbasen in Libyen und Ägypten zum Erliegen. In der folgenden britischen Gegenoffensive gerieten gegen Ende des Jahres 1940 130.000 Italiener in britische Gefangenschaft.
Der deutsche Generalleutnant Erwin Rommel bekam deshalb im Februar 1941 den Auftrag, mit zwei Infanteriedivisionen und einer Panzerdivision des neu aufgestellten Deutschen Afrikakorps den erfolglosen Bündnispartner bei dessen Verteidigung zu unterstützen. Rommel hielt eine defensive Haltung für unangebracht, stattdessen wollte er angreifen. Am 31. März begann Rommel den Vormarsch. Schon am 10. April standen deutsche Panzer vor der ostlibyschen Hafenstadt und Festung Tobruk, die kurz zuvor noch von den Italienern ausgebaut und dann beinahe kampflos geräumt worden war. Nach drei erfolglosen Angriffen musste Rommel vorerst die Eroberung Tobruks zurückstellen. Auch weitere Vorstöße konnten auf Grund von Versorgungsengpässen nicht durchgeführt werden, sodass beide Seiten zu einem Stellungskrieg übergingen. Im November 1941 griffen die Briten wieder an, wobei es der Besatzung von Tobruk endlich gelang, den Belagerungsring zu sprengen. Am 7. Dezember zog sich das Afrikakorps zur Gazala-Linie (60 km westlich von Tobruk) zurück. Nachdem Tobruk einer Eroberung durch das Afrikakorps widerstehen konnte, griff Rommel erst im nächsten Jahr wieder an.

Am 26. Mai 1942 befahl Rommel das "Unternehmen Theseus", um Tobruk zu erobern. Nach schweren Panzergefechten gelang es den Achsenmächten am 10. Juni Bir Hacheim einzunehmen. Danach wurden Stadt und Festung am 20. Juni besetzt, wofür Rommel als jüngster Offizier der Wehrmacht die Beförderung zum Generalfeldmarschall erhielt. Die deutschen und italienischen Erfolge wurden durch die Verlegung großer Teile der britischen Mittelmeerflotte in den Indischen Ozean für den Krieg gegen Japan begünstigt. Ziele des weiteren Vormarsches durch die Libysche Wüste waren Alexandria und der Sueskanal. Kurz vor der ägyptischen Bahnstation von El-Alamein hatten die Briten einen 7 Kilometer breiten Verteidigungsgürtel zwischen Mittelmeer und Qattara-Senke aufgebaut, in dem bei der ersten Schlacht von El-Alamein die Offensive der Achsenmächte steckenblieb (Juli 1942). Am 23. Oktober 1942 befahl der neue britische Befehlshaber Bernard Montgomery den Gegenangriff zur zweiten Schlacht von El-Alamein. Das zahlenmäßig unterlegene Afrikakorps musste den Rückzug antreten.
Die Lage der deutschen Truppen in Nordafrika wurde aussichtslos, nachdem am 8. November 1942 in der "Operation Torch" alliierte Truppen in Casablanca und Algier gelandet und somit die deutschen und italienischen Truppen in Nordafrika von zwei Seiten in die Zange genommen waren. Am 13. November fiel Tobruk wieder in britische Hand, am 23. Januar 1943 Tripolis.

Deutsche und italienische Truppen rückten im November 1942 in Tunesien ein, um Briten und US-Amerikanern zuvorzukommen. Im Februar 1943 konnte Rommel den US-Amerikanern in der Schlacht am Kasserinpass nahe der tunesisch-algerischen Grenze eine schwere Niederlage zufügen, deren weiteres Vordringen dennoch nicht aufhalten. Im März und April wurden die Truppen der Achsenmächte im Tunesienfeldzug eingekesselt. Lediglich an der Mareth-Linie wurde noch erbitterter Widerstand geleistet. Am 12. Mai 1943 – Rommel war inzwischen aus Nordafrika abberufen worden – kapitulierten dessen Nachfolger, General von Arnim, und sein Stab in Hammamet (Tunesien). Am 13. Mai ergab sich die italienische 1. Armee. Fast 250.000 deutsche und italienische Soldaten gerieten bei Tunis in Kriegsgefangenschaft. Die deutsche Bevölkerung reagierte entsetzt auf die hohen deutschen Verluste in Nordafrika, die als endgültige Kriegswende gedeutet wurden. Hinter vorgehaltener Hand wurde von einem „zweiten Stalingrad“ oder von „Tunisgrad“ gesprochen. Auch die Gesamtbilanz des Krieges in Nordafrika wies eindeutige Sieger aus: US-Amerikaner, Briten und Franzosen hatten insgesamt etwa 220.000 Mann an Gefallenen, Verwundeten und Vermissten einschließlich Gefangenen zu beklagen. Bei Deutschen und Italienern summierten sich die Verluste auf 620.000 Mann.

Nach dem Erfolg in Tunesien entschieden sich Großbritannien und die USA zunächst für eine Landung auf Sizilien, um dadurch den Seeweg zwischen Ägypten und Gibraltar zu öffnen – was zu einer Verkürzung der bisherigen Schifffahrtsrouten um Afrika herum führen würde. Die sowjetische Führung hätte bevorzugt, wenn Briten und Amerikaner die zweite Front in Frankreich eröffnet hätten, weil sie sich davon eine stärkere Entlastung für die eigene Front erhoffte. Churchill lehnte ab, weil es für eine Invasion im Westen im Jahre 1943 aus seiner Sicht noch zu früh sei. Aber auch nach einer Landung im Süden Europas wäre dem Deutschen Reich eine Verstärkung der Ostfront im Sommer 1943 nicht mehr möglich gewesen. Am 10. Juli 1943 landeten Amerikaner und Briten unter dem Oberbefehl Dwight D. Eisenhowers im Südosten Siziliens "(Operation Husky)". Daraufhin brach Hitler am 13. Juli das "Unternehmen Zitadelle" ab und verlegte am 17. Juli gegen den Willen Mansteins das II. SS-Panzerkorps aus Russland nach Italien. So zeigte die Landung auf Sizilien Wirkung, wenn sie auch nicht die von Stalin gewünschte zweite Front war. Der Große Faschistische Rat beschloss auf einer Sitzung am 24. Juli 1943 mit 28:19 Stimmen die Rückkehr Italiens zu verfassungsmäßigen Zuständen. Die Mehrheit versprach sich davon bessere Bedingungen der Alliierten im Falle einer Kapitulation Italiens. Am folgenden Tag ließ König Viktor Emanuel III., in Absprache mit Dino Grandi und dessen Verbündeten, Mussolini nach einem Besuch im Königspalast von Carabinieri verhaften. Als neuer Ministerpräsident wurde Pietro Badoglio ernannt. Im Unternehmen Lehrgang verließen am 17. August 39.000 deutsche und 62.000 italienische Soldaten Sizilien und setzten über die Straße von Messina auf das italienische Festland über.

Dort landeten am 3. September bei Reggio Calabria zwei britische Divisionen gegen nur geringen Widerstand der Verteidiger. Am selben Tag schloss die neue italienische Regierung mit den Alliierten den Waffenstillstand von Cassibile, der fünf Tage später von Eisenhower über „Radio Algier“ bekanntgegeben wurde. Daraufhin wurde der "Fall Achse" ausgelöst, in dem 20 deutsche Divisionen die Hälfte des italienischen Heeres entwaffneten und internierten. Am 12. September gelang es 72 deutschen Fallschirmjägern in einer Kommandoaktion, Mussolini aus seiner Gefangenschaft im Hotel Campo Imperatore zu befreien. Er proklamierte die "Repubblica Sociale Italiana", die er von der kleinen Stadt Salò am Gardasee aus führte und ließ den Kampf gegen die Alliierten an deutscher Seite fortsetzen. Den Begriff „faschistisch“ hielt er inzwischen für so wenig werbewirksam, dass er im Staatsnamen auf ihn verzichtete. Als sich die auf der griechischen Insel Kefalonia stationierten italienischen Soldaten ihrer Entwaffnung widersetzten, wurden zwischen dem 18. und dem 23. September etwa 5000 Italiener gefangengenommen und von deutschen Gebirgsjägertruppen erschossen. Am 13. Oktober erklärte die Badoglio-Regierung dem Deutschen Reich den Krieg. An der Seite der offiziellen italienischen Verbände operierte eine Partisanenarmee von 256.000 Frauen und Männern.
Der Vormarsch der Alliierten in Süditalien erfolgte nur sehr langsam. Deutsche Soldaten verteidigten ihre Stellungen bis zum Äußersten, während im Hinterland schon die nächsten Verteidigungsstellungen ausgehoben wurden. An der "Gustav-Linie" zwischen Ortona an der Adria und dem Golf von Gaeta am Tyrrhenischen Meer blieben im Winter 1943/44 die alliierten Angriffe erfolglos. Auch eine US-amerikanische Landung (Ende Januar 1944), nördlich im Rücken der "Gustav-Linie", führte nicht zum Ziel. Zusätzliche deutsche Divisionen wurden nach Italien verlegt.
Am 15. Februar 1944 wurde während der Schlacht um Monte Cassino das von den Deutschen nicht besetzte Bergkloster, das eine strategische Lage in der Gustav-Linie hatte, aus der Luft bombardiert und zwei Tage später durch Artilleriebeschuss völlig zerstört. 50.000 deutsche Verteidiger, darunter viele Fallschirmjäger der Landung auf Kreta, hatten sich vor (sic!) dem Kloster verschanzt, das von 200.000 alliierten Soldaten aus 36 Nationen erfolglos angegriffen wurde. Vorher hatte Churchill leichtsinnig angekündigt, Italien sei „der weiche Unterleib Europas.“ Erst drei Monate später, am 18. Mai, eroberten neuseeländische, indische und polnische Truppen Monte Cassino.

Nachdem das Hindernis Monte Cassino überwunden war, vereinten die Alliierten am 25. Mai ihre beiden Fronten nördlich und südlich der Gustav-Linie und begannen, weiter nach Norden vorzurücken. Generalfeldmarschall Albert Kesselring, Oberbefehlshaber der Heeresverbände in Italien, ließ Rom zur "offenen Stadt" erklären. Am 5. Juni besetzten daraufhin alliierte Truppen kampflos die Stadt. Die Hoffnung der Alliierten, die Wehrmacht danach bis in die Alpen zurückdrängen zu können, wurde an der Verteidigungslinie in den nördlichen Apennin zwischen La Spezia am Mittelmeer und Rimini an der Adria vorerst zerschlagen, sodass 1944 der Krieg in Italien „noch längst nicht zu Ende war, aber am Ausgang dieses Kampfes konnte es im Frühsommer 1944 keine ernsthaften Zweifel mehr geben.“

Trotz der angespannten Kräfte- und Nachschubsituation hatte Hitler am 23. Juli 1942 in Abänderung des ursprünglichen Plans („Fall Blau“) und gegen teilweise erhebliche Bedenken der Generalität neben der südlichen Offensive in Richtung des Kaukasusgebietes eine gleichzeitige Offensive gegen Stalingrad befohlen ("siehe auch Abschnitt" Der Krieg gegen die Sowjetunion). Die Heeresgruppe Süd wurde deswegen in die Heeresgruppe A (→ Kaukasus) und Heeresgruppe B (→ Stalingrad) aufgeteilt. Ursprünglich sollte zuerst Stalingrad als Verkehrsknotenpunkt und danach das Kaukasusgebiet mit seinen Ölquellen erobert werden. Aus dem Nacheinander wurde die Gleichzeitigkeit zweier Offensiven mit gefährlich überdehnten Flanken. Eine deutsche Panzerabteilung erreichte am Abend des 23. August 1942 die Wolga; am selben Tag bombardierten 600 Maschinen der Luftwaffe Stalingrad und die ersten Einheiten der 6. Armee konnten in die Außenbezirke der Stadt eindringen. In erbitterten Einzelkämpfen in den Häusern und Straßen kamen die Deutschen nur unter hohen Opfern voran. Schließlich beherrschte die 6. Armee etwa 90 Prozent der in einen Trümmerhaufen verwandelten Stadt, die vollständige Inbesitznahme misslang jedoch. Einen schmalen, westlichen Uferstreifen der Wolga, an dem ständig neue Truppen angelandet wurden, konnten die sowjetischen Verteidiger unter hohen Verlusten halten.

Am 19. November begann die Großoffensive der Roten Armee ("Operation Uranus") gegen die rumänischen und deutschen Linien weit nordwestlich und südlich von Stalingrad mit einer riesigen Umzingelungsbewegung. Wenige Tage später vereinigten sich die sowjetischen Panzerspitzen bei Kalatsch am Don. Damit war die 6. Armee weiträumig eingekesselt. Die von Göring versprochene Luftversorgung war nicht möglich. Die deutschen Verbände waren recht unbeweglich und völlig unterversorgt. Ein Entsatzangriff der 4. Panzerarmee ("Unternehmen Wintergewitter"), der bis zu 48 Kilometer an den Belagerungsring heranführte, musste am 23. Dezember abgebrochen werden. Generaloberst Paulus schätzte einen Ausbruchsversuch wegen mangelnder Treibstoffreserven als unmöglich ein, fühlte sich an den Haltebefehl Hitlers gebunden und gab weder einen Befehl zum Ausbruch aus dem Kessel noch wollte er kapitulieren. Am 10. Januar 1943 eröffneten daraufhin sieben sowjetische Armeen den Angriff auf die Stadt. Bis zum 23. Januar eroberten sie die Flugplätze Pitomnik und Gumrak. Am 24. Januar gelang es ihnen, den Kessel in eine nördliche und eine südliche Hälfte zu spalten. Am 25. Januar verließ die letzte "Ju 52" den Behelfsflugplatz Stalingradski. Am 31. Januar ging Paulus, zwischenzeitlich zum Generalfeldmarschall befördert, angesichts der aussichtslosen Lage in sowjetische Gefangenschaft, ohne eine Gesamtkapitulation der 6. Armee auszusprechen. Es folgten ungeregelte Teilkapitulationen von Einheiten des Südkessels; der Nordkessel kämpfte noch bis zum 2. Februar. Die sowjetischen Verluste betrugen 500.000 Tote, die deutsche Armee und ihre Verbündeten verloren – Tote und Gefangene zusammengerechnet – eine halbe Million Mann. Als die BBC die Gefangennahme von 91.000 deutschen Soldaten meldete, verbreitete sich in Deutschland die Erkenntnis, dass Goebbels die Bevölkerung angelogen hatte, als er im Rundfunk verkündete, die gesamte 6. Armee sei kämpfend untergegangen. Der Schock dieser Niederlage war unbeschreiblich. Vermutlich 110.000 Soldaten gerieten in Kriegsgefangenschaft, von denen 1955 nur etwa 5.000 zurückkehrten, unter ihnen Generalfeldmarschall Paulus, sein Stabschef und die meisten anderen hohen Offiziere.

Die Schlacht von Stalingrad war, nach der Niederlage gegen die Briten bei El-Alamein im Oktober 1942 ("s. o."), die zweite, noch größere Katastrophe der deutschen Wehrmacht. Sie war der psychologische Wendepunkt des Zweiten Weltkrieges. Von nun an ging es an allen Fronten unaufhaltsam zurück, und die Zweifel der Deutschen am „Endsieg“ nahmen massiv zu, ungeachtet der Sportpalastrede von Goebbels am 18. Februar 1943 mit dem Aufruf zum „totalen Krieg“ und der frenetischen Zustimmung ihrer ausgewählten Zuhörer. So kommt Heinz Boberach, der Herausgeber der "Meldungen aus dem Reich", zu dem Befund, dass mit der Niederlage von Stalingrad 1943 ein Stimmungsumschwung begonnen habe, der durch die Kapitulation der deutschen Truppen in Nordafrika (im Mai 1943) und die Steigerung der Luftangriffe auf das Reich noch verstärkt worden sei.

Am 16. Februar wurde die Stadt Charkow von Truppen der Wehrmacht und Waffen-SS unter dem Befehl von SS-Obergruppenführer Paul Hausser gegen den Befehl Hitlers aufgegeben, um einer drohenden Einkesselung zu entgehen. Fünf Tage danach begann eine deutsche Gegenoffensive. Bis zum 14. März wurde das Gebiet bis zum mittleren Donezk einschließlich Charkows zurückerobert. Dabei wurden erhebliche Geländegewinne erzielt, dem Gegner hohe Verluste beigebracht und wieder eine geschlossene Front hergestellt. Ein im Frühjahr 1943 potentiell bevorstehender Zusammenbruch der Ostfront wurde so verhindert. Eine weitere Offensive im Sommer, das "Unternehmen Zitadelle", sollte den Frontbogen bei Kursk ausräumen, große Teile der Roten Armee einkesseln und schwankende Verbündete nach der Niederlage bei Stalingrad von Deutschlands Stärke überzeugen. Das Unternehmen gipfelte in der größten Panzerschlacht der Geschichte. Der monatelang vorbereitete Angriff war von der Roten Armee vorausgesehen worden, die sich durch tiefe Verteidigungsstellungen vorbereitet hatte, und blieb nach einigen Tagen stecken. Der deutsche Vorstoß wurde auf dem Höhepunkt der Schlacht am 13. Juli abgebrochen. Die deutsche Wehrmacht verlor in wenigen Tagen mehr Soldaten und Material als in der monatelangen Schlacht um Stalingrad. Die sowjetische Gegenoffensive bei Orel, die ihrerseits das Ziel verfolgte, Teile der Heeresgruppe Mitte einzukesseln, und die Verlegung des II. SS-Panzerkorps nach Italien aufgrund der am 10. Juli erfolgten Landung der Westalliierten auf Sizilien (Operation Husky) waren die entscheidenden Gründe für den Abbruch des Unternehmens "Zitadelle".

Die im "Unternehmen Zitadelle" verlorenen deutschen Panzerreserven konnten nicht mehr ersetzt werden, die Verluste bedeuteten damit die endgültige Kriegswende zugunsten der Sowjetunion. Nach mehreren sowjetischen Gegenoffensiven in den folgenden Monaten musste die Wehrmacht an der gesamten Front den Rückzug antreten, wobei auch die Schlacht um die Krim mit einer deutschen Niederlage endete. Weitere größere Schlachten waren die Schlacht am Dnepr und die Dnepr-Karpaten-Operation. Am Ende des Jahres 1943 war Kiew wieder in der Hand der Sowjetunion.

Mitte Januar 1944 verlief die Ostfront von Leningrad im Norden über die Pripjet-Sümpfe bis zur Krim im Süden. In der am 14. Januar 1944 begonnenen Leningrad-Nowgoroder Operation wurde der deutsche Belagerungsring um Leningrad im selben Monat gesprengt. Die folgende sowjetische Frühjahrsoffensive brachte weitere Gebietsgewinne, und die Wehrmacht musste sich bis zum Peipussee zurückziehen. Am 12. Mai war die Krim wieder in sowjetischer Hand. Am 9. Juni begann die Offensive an der finnischen Front auf der Karelischen Landenge. Ende Juni kam dieser Angriff auf Höhe der alten Grenze von 1940 zum Stillstand.

Mit Jahresbeginn übernahm Erwin Rommel den Oberbefehl der deutschen Heeresgruppe B an der Westfront nördlich der Loire. Am 21. Januar 1944 begann die deutsche Luftwaffe wieder mit Angriffen auf London, die bis zum April fortgesetzt wurden.
Während die Alliierten damit beschäftigt waren, riesige Mengen Versorgungsmaterial anzuhäufen, verstärkten die Deutschen ihre Küstenbefestigungen am Atlantikwall.

Der Plan für die "Operation Overlord" ging auf schon 1941 erarbeitete Invasionspläne zurück und war vom britischen Lieutenant General (Generalleutnant) Sir Frederick E. Morgan für die endgültige Fassung überarbeitet worden. Der Plan sah vor, mit vier Armeen zu landen und dann schnell ins Landesinnere vorzustoßen. Hitler und der deutsche Planungsstab waren unzureichend auf die Invasion eingestellt. Sie erwarteten die Landung am Pas-de-Calais, der engsten Stelle des Ärmelkanals. Die Küste des Département Calvados, wo die Alliierten schließlich an Land gingen, wurde stellenweise nur mit einigen Metern Stacheldraht und wenigen MG-Nestern verteidigt. Andere Abschnitte waren trotz der falschen Erwartungen des OKW über den Ort der Invasion dennoch recht schwer befestigt. Das Invasionsgebiet war aufgeteilt in fünf Landungsabschnitte mit den Decknamen "Juno", "Gold", "Sword" (britisch/kanadische Landungsabschnitte), sowie "Utah" und "Omaha" (US-amerikanische Landungsabschnitte). Die Bombardierungen der Küste aus der Luft und Beschießungen von See verliefen planmäßig, verfehlten bei "Omaha" jedoch die erste deutsche Linie. Das führte, zusammen mit der Tatsache, dass die Deutschen dort zwei Divisionen statt der nur einen vermuteten Division zur Verfügung hatten, zu sehr schweren Verlusten (etwa 70 Prozent) der ersten Welle der anlandenden Soldaten.

Am 6. Juni 1944, dem so genannten "D-Day", und danach waren an der "Operation Neptune", dem eigentlichen Invasionsunternehmen, etwa 6700 Schiffe und über 14.000 Flugzeuge beteiligt, die insgesamt fast 160.000 alliierte Soldaten aus den USA, Kanada und Großbritannien an Land setzten. Am frühen Morgen des 6. Juni starteten zwei US-Luftlandedivisionen zu ihren Einsätzen in das Hinterland. Wegen Navigationsfehlern und überraschend starkem deutschen Flakfeuer erreichten viele Maschinen nicht die vorgesehenen Absprungzonen, sodass die Fallschirmspringer über weiten Teilen der Halbinsel Cotentin abgesetzt wurden.

Obwohl die Alliierten gewaltige Kräfte aufgeboten hatten, kamen sie stellenweise nur sehr langsam voran. Andererseits gelang es der deutschen Seite aufgrund der alliierten Luftüberlegenheit und des großflächig zerstörten Schienennetzes nicht, schnell zusätzliche Einheiten in das Kampfgebiet der Normandie zu verlegen. Die deutschen Truppen in der Normandie wurden an unerwarteter Stelle überrascht, auch weil Hitler sehr häufig davon gesprochen hatte, dass die Invasion mit einem Täuschungsangriff beginnen werde. Von Rundstedt, der "Oberbefehlshaber West", hatte zwar am frühen Morgen um die Freigabe zweier bei Paris stationierter Panzerdivisionen gebeten. Alfred Jodl hatte das abgelehnt. Erst gegen Mittag stimmte Hitler dem verspäteten Einsatz dieser Reserve gegen den 150 Kilometer entfernten alliierten Brückenkopf zu. Seine Adjutanten hatten bis etwa 10 Uhr gezögert, Hitler, der erst gegen drei Uhr morgens zu Bett gegangen war, wegen einer möglichen Falschmeldung zu wecken. „Diese Verzögerung war entscheidend.“

Cherbourg im Norden der Cotentin-Halbinsel ging am 26. Juni nach starkem amerikanischen Artilleriebeschuss und heftigen Straßenkämpfen (→ Schlacht um Cherbourg) verloren. Die Einnahme von Caen, einem Primärziel des ersten Landungstages, erwies sich für die alliierten Truppen der Briten und Kanadier an der Ostseite des Normandie-Brückenkopfes als ungleich schwieriger. Erst nach sechs Wochen verlustreicher Kämpfe konnten sie die Stadt am 19. Juli vollständig besetzen.

Am 15. August begann eine zweite Invasion in Südfrankreich an der Côte d’Azur zwischen Toulon und Cannes ("Operation Dragoon"). An der Landung waren 880 alliierte Seeschiffe, darunter vier Flugzeugträger, sechs Schlachtschiffe, 21 Kreuzer und über 100 Zerstörer, insgesamt 34 französische Schiffe und 1370 Landungsboote sowie ungefähr 5000 Flugzeuge beteiligt. Drei US-amerikanische Divisionen bildeten die Angriffstruppen. Die US-amerikanischen und französischen Truppen stießen kaum auf Widerstand und rückten zügig durch das Rhône-Tal nach Norden vor. Im September hatten sie bereits die Vogesen und das Elsass erreicht.
In der Normandie unternahmen die Amerikaner am 25. Juli einen Ausbruchsversuch aus ihrem Brückenkopf-Sektor (→ "Operation Cobra"), der in den Folgetagen im Westen zur Abschnürung der Cotentin-Halbinsel bis nach Avranches führte. Im Osten konnten US-amerikanische Einheiten bei Saint-Lô nach anfänglicher Verzögerung schnell die deutsche Front durchbrechen. Am 6. August starteten die Deutschen zwar unter dem leitenden Oberbefehlshaber West, Generalfeldmarschall Günther von Kluge, einen Gegenangriff bei Mortain (→ "Unternehmen Lüttich"). Dieser wurde schon nach zwei Tagen wieder gestoppt, was mit Hilfe der nördlich kämpfenden Briten und Kanadier zum Kessel von Falaise führte.

Am 25. August wurde Paris befreit (→ Schlacht um Paris). Der deutsche Stadtkommandant, General Dietrich von Choltitz, hatte Hitlers Befehl, die Stadt bis zum letzten Mann zu verteidigen und dann zu zerstören, nicht ausgeführt und ergab sich mit seinen Truppen aus Mangel an Waffen kampflos. Wegen der enormen Materialfülle und absoluten Luftherrschaft konnten deutsche Truppenansammlungen zu jeder Zeit zerschlagen werden, und die Alliierten kamen in der Folgezeit recht zügig voran. Zwar überdehnten sie bei ihrem schnellen Vorstoß zum deutschen Westwall ihre Versorgungslinien, aber nach dem Aufbau neuer, schneller Nachschubwege (→ "Red Ball Express") gelang es vor allem, den in großen Mengen benötigten Treibstoff bereitzustellen. Bereits am 3. September fiel Brüssel und am Tag darauf konnte Antwerpen besetzt werden. Einzig bei der Luftlandeoperation "Market Garden" konnte das II. SS-Panzerkorps Amerikanern, Briten und Polen bei und in Arnheim noch einmal eine schwere Niederlage beibringen.

Nach dem Verlust der Atlantikhäfen am Ärmelkanal setzte die deutsche Marine ihren U-Boot-Krieg von Norwegen aus fort. Bis zum 1. September griffen die Deutschen von Abschussrampen in Nordfrankreich aus mit Marschflugkörpern (V1) und Raketen (V2) London an. Beide Typen, von denen 9300 und 3000 gestartet wurden, waren für die Bekämpfung von Einzelzielen zu ungenau und konnten daher nur gegen große Städte eingesetzt werden. In London kamen durch Angriffe mit der "V1" über 6000 Menschen ums Leben. Mit Arbeiten an dem Projekt "Friesenwall" sollte dem direkten Eindringen der Alliierten an der deutschen Nordseeküste entgegengewirkt werden. Er wurde jedoch nicht fertiggestellt.

Am 21. Oktober eroberten US-Soldaten nach heftigen Kämpfen Aachen als erste deutsche Großstadt und stießen von dort bis zur Rur vor, wurden aber im Hürtgenwald in verlustreiche Kämpfe verwickelt. Die Schlacht im Hürtgenwald wurde die längste Schlacht (Oktober 1944 bis Februar 1945), die je auf deutschem Boden tobte. Insgesamt fielen 35.000 deutsche und US-amerikanische Soldaten. Das stark bewaldete, hügelige Gebiet und die schlechte, kalte Witterung begünstigten die deutschen Verteidiger, so dass die amerikanischen Soldaten ihre materielle Überlegenheit nicht ausspielen konnten. Erst im Februar 1945 gelang es der US-Armee, weiter zum Rhein vorzurücken. Auch im Süden, in Lothringen und im Elsass, blieb es bei Teilerfolgen für die Alliierten: die Festung Metz und Straßburg wurden besetzt. Am 16. Dezember eröffneten die Deutschen die Ardennenoffensive, um die Oberhand im Westen zurückzugewinnen. Die Alliierten verloren dabei 76.000, die Deutschen 90.000 Mann. Auch die Operationsziele der deutschen Angreifer, die Fronten der Alliierten zu spalten, in breiter Front nach Belgien vorzustoßen und den alliierten Nachschubhafen Antwerpen zu besetzen, konnten nicht erreicht werden. Zum Jahreswechsel 1944/45 war nicht mehr zu übersehen, dass die Offensive steckengeblieben war, nachdem das "Unternehmen Bodenplatte" gescheitert war.

Da in der Ardennenoffensive und beim Unternehmen Nordwind (Januar 1945) die letzten Treibstoffreserven verbraucht wurden, waren Luftwaffe, Heer und Marine an allen Kriegsschauplätzen danach weitgehend bewegungslos, weil die deutschen Hydrierwerke in der zweiten Jahreshälfte 1944 immer wieder bombardiert worden waren. Es nützte nichts, dass immer noch viele Panzer und Flugzeuge fertiggestellt wurden.

Am 7. März 1945 erreichten US-Soldaten die nicht vollständig zerstörte Brücke bei Remagen südlich des Ruhrgebiets, sodass sie einen Brückenkopf auf dem rechtsrheinischen Ufer einrichten konnten.
Am 23. März begann die "Operation Plunder" zur Rheinüberquerung nördlich des Ruhrgebiets bei Wesel durch britische, amerikanische und kanadische Soldaten. Die Heeresgruppe B der Wehrmacht unter Feldmarschall Walter Model mit über 320.000 Soldaten – mehr als in Stalingrad – wurde am 1. April im sogenannten "Ruhrkessel" eingeschlossen. Damit war der Krieg im Westen, militärisch gesehen, endgültig verloren. Die Heeresgruppe B kapitulierte am 18. April, weil zwei Drittel der Soldaten ohne Waffen waren und in hellen Scharen desertierten. Am selben Tag nahmen US-Truppen Magdeburg ein, einen Tag später Leipzig.
Während der Besetzung deutscher Städte in Südwestdeutschland durch französische Soldaten kam es, „insbesondere durch eine Minderheit der gefürchteten Kolonialsoldaten aus Nordafrika, zu ausgiebigen Plünderungen und zahlreichen Vergewaltigungen. […] In Freudenstadt, dem schlimmsten Fall, zogen sich die Plünderungen und Vergewaltigungen über drei Tage hin.“ Die französischen Truppen zogen weiter in Richtung Rottweil und Stuttgart. Zugleich rückte die britische Armee vom Niederrhein aus zügig nach Norddeutschland vor.

Am 25. April trafen sich US-amerikanische und sowjetische Truppen südlich von Torgau an der Elbe. Damit waren die auf ihrem Heimatboden und in angrenzenden Gebieten kämpfenden deutschen Truppen in zwei voneinander getrennte Kampfräume gespalten. Am 26. April fiel Bremen an die Briten. In rascher Folge nahmen sie Lübeck (2. Mai) und Hamburg (3. Mai) ein, während britisch-kanadische Truppen in Wismar einmarschierten.

Am 5. Mai kapitulierte Generaloberst Blaskowitz, dessen Truppen in Holland eingekesselt waren. Während die britischen Einheiten Norddeutschland eroberten, drangen US-Truppen rasch nach Süddeutschland und weiter nach Tirol-Vorarlberg vor, „oft als Befreier begrüßt […]. Viele Soldaten ließen sich einfach überrollen und gefangen nehmen.“ Die Amerikaner besetzten am 30. April München. Stuttgart fiel am 22. April an die französische Armee, die nach Süden bis Vorarlberg vordrang. Die US-Armee traf am 3. Mai am Brennerpass mit ihren Landsleuten zusammen, die von Süden her Oberitalien besetzt hatten.

In Italien wurde Bologna am 21. April von polnischen Truppen besetzt. Benito Mussolini flüchtete am 25. April vor den Alliierten, die am 27. April Genua besetzten, von Salò aus in Richtung Schweiz. Einen Tag später ergriffen italienische Partisanen Mussolini in Dongo und erschossen ihn. Am 2. Mai kapitulierten die deutschen Einheiten in Italien, am selben Tag marschierten britische Truppen in Triest ein.

In zeitlicher Abstimmung mit der Invasion im Westen gelang der Sowjetunion im Juni und Juli 1944 mit der Operation Bagration die vollständige Zerschlagung der Heeresgruppe Mitte. Sie gilt mit einem Verlust von 28 Divisionen der Wehrmacht als verlustreichste Niederlage in der deutschen Militärgeschichte. Die Rote Armee konnte bis kurz vor Warschau und zur Grenze Ostpreußens vorstoßen. Am 3. Juli eroberten die sowjetischen Truppen Minsk zurück, weiter südlich drang ab dem 13. Juli in Galizien eine weitere sowjetische Offensive bis Lemberg an die Weichsel vor. Ab diesem Zeitpunkt war die Wehrmacht nur noch zu hinhaltendem Widerstand gegen die Rote Armee fähig.

Am 1. August begann der Warschauer Aufstand der Polnischen Heimatarmee. Am 20. August marschierte die Rote Armee in Rumänien ein, woraufhin am 23. August König Michael durch einen Staatsstreich den Diktator Ion Antonescu stürzte und am 24. August die rumänische Armee den Kampf an Deutschlands Seite einstellte. Als die Wehrmacht am 29. August aufgrund zunehmender Partisanenaktivitäten mit der militärischen Besetzung der Slowakei begann, brach dort der Slowakische Nationalaufstand aus, der von Teilen der slowakischen Armee getragen wurde. Die Erfolge der Sowjetunion zwangen die Wehrmacht zum Rückzug aus Griechenland; am 13. Oktober rückten britische Einheiten in Athen ein. Am 5. September nahm die Rote Armee Bulgarien ein; der Unterstützung durch die Sowjetunion sicher, führten die bulgarischen Kommunisten am 9. September eine gewaltsame Änderung der Staatsform herbei und übernahmen die Führung im Land.

Die finnische Regierung schloss am 19. September einen Waffenstillstand mit der Sowjetunion. Am 20. Oktober eroberten sowjetische Einheiten und jugoslawische Partisanen unter Tito die Hauptstadt Belgrad. Im Baltikum zog sich die Heeresgruppe Nord am 13. Oktober aus Riga nach Kurland zurück. In Ostpreußen kam die Offensive der Sowjetunion im Oktober nach anfänglichen Erfolgen zum Erliegen.

In der Schlacht um Budapest wurde die ungarische Hauptstadt belagert, konnte aber erst am 11. Februar 1945 von der Roten Armee eingenommen werden.
Die Rote Armee stieß Anfang 1945 von Warschau (Befreiung am 17. Januar) aus nach Norden vor und schnitt damit Ostpreußen vom Deutschen Reich ab. Zehntausende Deutsche flohen während der Schlacht um Ostpreußen über das zugefrorene Frische Haff nach Westen. 
Insgesamt gelangten über zwei Millionen Flüchtlinge über das Meer nach Westen. Im Zuge dieser Rettungsaktion ("Unternehmen Hannibal") wurde am 30. Januar das ehemalige KdF-Schiff „Wilhelm Gustloff“ mit Tausenden von Menschen an Bord von dem U-Boot S-13 der Baltischen Flotte torpediert und ging auf Höhe von Stolpmünde unter, wo 11 Tage später die "Steuben" ebenfalls ein Opfer von S-13 wurde. Die Versenkungen der "Gustloff", "Steuben", "Goya" (16. April 1945) und "Cap Arcona" (3. Mai 1945) mit zusammen mehr als 20.000 Opfern gelten als die größten Katastrophen der Schifffahrt.

Am 27. Januar erreichte die Rote Armee das KZ Auschwitz-Birkenau, das von der SS zuvor aufgegeben worden war. Am selben Tag erreichten erste sowjetische Einheiten Küstrin und damit die Oder. In der Schlacht um Königsberg besetzten die russischen Angreifer am 9. April endgültig die Stadt.

Nach der sowjetischen Weichsel-Oder-Operation stand die Rote Armee Ende Januar 1945 entlang der Oder und Neiße von Stettin bis Görlitz knapp 80 Kilometer vor Berlin. Bei den Seelower Höhen wurde eine der größten Schlachten des Zweiten Weltkrieges geschlagen (16. April–18. April). Einer Million deutschen Soldaten, viele davon junge, kaum kampferfahrene Rekruten, mit 1500 Panzern, 10.400 Geschützen und 3300 Kampfflugzeugen, von denen viele mangels Treibstoff am Boden bleiben mussten, standen 1,4 Millionen sowjetische Soldaten mit 4000 russischen Panzern und 23.000 Geschützen gegenüber. Es war der gewaltigste Feuerschlag des gesamten Krieges: Am ersten Tag wurden 1,2 Millionen Geschosse abgefeuert, deren Erschütterungen noch im 60 km entfernten Osten Berlins die Wände beben ließen. Weiter nördlich, in Pommern, hatte Rokossowskis „Zweite weißrussische Front“ 1,4 Millionen Soldaten, über 4000 Panzer und 23.000 schwere Geschütze. Im Süden, an der Neiße, verfügte Konjews „Erste Ukrainische Front“ über weitere 1,1 Millionen Soldaten und 2150 Panzer. Alle "Fronten" wurden aus der Luft von 7500 Kampfflugzeugen unterstützt. Unterdessen wurde im Süden der sowjetische Belagerungsring um Breslau am 15. Februar geschlossen, das erst am 6. Mai in die Hände der Roten Armee fiel. Am 25. April schloss sich der Belagerungsring in der Schlacht um Berlin um die Hauptstadt, am 28. April scheiterte der Versuch der 12. Armee unter General Walther Wenck, die Eingeschlossenen zu entsetzen. Adolf Hitler tötete sich selbst am 30. April im Führerbunker unter der Neuen Reichskanzlei. Am 2. Mai erteilte General Helmuth Weidling an die letzten Verteidiger von Berlin den Befehl zur Einstellung der Kampfhandlungen.

Nach dem Scheitern der Plattenseeoffensive im Frühjahr 1945 war Ungarn am 4. April vollständig von der Roten Armee erobert. In der Wiener Operation besetzte die Rote Armee, über die burgenländische Grenze vom Südosten kommend, in einem Zangenangriff zwischen dem 4. und 13. April Wien, kurz danach Niederösterreich, das Burgenland und die Steiermark. Im Alpenvorland und im Norden verlangsamte sich der sowjetische Vormarsch. Am 3. Mai erreichten amerikanische Truppen Salzburg und stießen weiter in das Alpenvorland vor. Am 5. Mai befreiten ihre Vorausabteilungen das KZ Mauthausen und trafen am 7. Mai mit den Sowjets am Fluss Enns an der Grenze von Ober- und Niederösterreich zusammen. Am selben Tag erreichte die Rote Armee Graz. Am 8. Mai 1945 trat um 23:00 Uhr mitteleuropäischer Zeit die bedingungslose Kapitulation der deutschen Streitkräfte in Kraft. Die meisten der 900.000 Soldaten der Heeresgruppe Mitte (der früheren Heeresgruppe A) unter Generalfeldmarschall Schörner gerieten in sowjetische Gefangenschaft. Auch der am 5. Mai beginnende Prager Aufstand forderte im Zusammenhang mit der anfangs ungeordneten Vertreibung der Deutschen aus der Tschechoslowakei eine unbekannte Zahl an Opfern. Am 10. Mai rückten sowjetische Einheiten in Prag ein.

Einen Tag, bevor Hitler sich am 30. April das Leben nahm, hatte er in seinem politischen Testament Großadmiral Karl Dönitz zum Reichspräsidenten und Oberbefehlshaber der Wehrmacht und Propagandaminister Joseph Goebbels zum Reichskanzler bestimmt. Nachdem dieser sich am 1. Mai ebenfalls das Leben genommen hatte, erklärte Dönitz am selben Tag in einer Rundfunkansprache die Fortsetzung des militärischen Kampfes gegen „den vordrängenden bolschewistischen Feind“. Dönitz wollte damit erreichen, dass möglichst viele deutsche Soldaten in amerikanisch-britische statt sowjetische Gefangenschaft gerieten. Nachdem die letzten Einheiten in Berlin am 2. Mai kapituliert hatten, schlug er sein Hauptquartier am 3. Mai in Flensburg-Mürwik auf und benannte eine "Geschäftsführende Reichsregierung" unter Graf Schwerin von Krosigk. Am 4. Mai unterzeichnete der neu ernannte Oberbefehlshaber der Kriegsmarine, Generaladmiral Hans-Georg von Friedeburg, auf dem Timeloberg eine Urkunde zur bedingungslosen Kapitulation der Wehrmachteinheiten, die im Nordwesten gegen britische Truppen gekämpft hatten – diese Teilkapitulation trat am 5. Mai um 7 Uhr in Kraft.

Nachdem Eisenhower das Ansinnen eines separaten Waffenstillstands mit den Westalliierten zurückgewiesen hatte, unterzeichnete Generaloberst Alfred Jodl in Reims am 7. Mai die bedingungslose Kapitulation aller deutschen Truppen. Sie trat am 8. Mai, 23:01 Uhr mitteleuropäischer Zeit in Kraft. In einem weiteren Dokument wurde die Ratifizierung dieser bedingungslosen Kapitulation durch das Oberkommando der Wehrmacht sowie die Oberbefehlshaber von Heer, Luftwaffe und Marine vereinbart. Das geschah durch Unterzeichnung einer weiteren Kapitulationsurkunde im sowjetischen Hauptquartier in Berlin-Karlshorst. In den späten Abendstunden des 8. Mai wurde die Urkunde von Generalfeldmarschall Keitel (für das OKW und das Heer), Generaladmiral von Friedeburg (Kriegsmarine) und Generaloberst Stumpff (Luftwaffe, als Vertreter des Oberbefehlshabers Generalfeldmarschall von Greim) unterzeichnet. Die Ratifizierung zog sich bis nach Mitternacht hin. Da die Kapitulation ebenfalls erst am 9. Mai in Moskau bekannt gegeben wurde, wurde/wird in der Sowjetunion beziehungsweise in den Postsowjetischen Staaten der 9. Mai als "Tag des Sieges" begangen.
Zum Kriegsende in Europa am 8. Mai befanden sich im Westen die Kanalinseln und die Städte Lorient, Saint-Nazaire, La Rochelle, im Osten das nördliche Kurland und im Südosten Teile der Ägäis noch unter der Kontrolle der Wehrmacht. Auch in Dänemark und Norwegen blieb die deutsche Herrschaft bis zur Kapitulation erhalten, in den Niederlanden die Provinzen Nord- und Südholland sowie die Provinz Groningen. Das Deutsche Reich selbst war weitgehend besetzt, lediglich der Alpenraum, Teile des Protektorats Böhmen und Mähren, der Großteil Schleswig-Holsteins und Ostfriesland standen noch unter Kontrolle deutscher Truppen.

Am 8. und 9. Mai versuchten ungezählte deutsche Soldaten aus dem sowjetischen Machtbereich in die von den Westalliierten kontrollierten Gebiete zu gelangen, vor allem solche aus dem böhmisch-mährischen Raum. Der großen Mehrheit gelang dies nicht, zumal die US-Armee sich strikt an die Waffenstillstandsbedingungen hielt und in ihren Bereich gelangte deutsche Soldaten in Lagern (unter anderen Pisek) festhielt und der Sowjetunion übergab. Keinerlei Aussicht, der Gefangenschaft zu entgehen, bestand für die eingeschlossene Heeresgruppe Kurland. Stalin verkündete am 9. Mai den „Völkern der Sowjetunion“, man feiere den Sieg, schicke sich jedoch nicht an, „Deutschland zu zerstückeln oder zu vernichten“.

Der Oberste Sowjet hob in einer einseitigen Erklärung den Kriegszustand mit Deutschland erst am 25. Januar 1955 auf.

Der deutsche Bundespräsident Richard von Weizsäcker erklärte am 8. Mai 1985 in seiner Ansprache zum 40. Jahrestag der Beendigung des Krieges in Europa und der nationalsozialistischen Gewaltherrschaft vor dem deutschen Bundestag, sie sei als Befreiung vom Nationalsozialismus in die nationale Erinnerungskultur eingegangen.

Japan war vor dem Zweiten Weltkrieg bereits an mehreren Kriegen beteiligt gewesen. Unter Tennō Yoshihito kämpfte Japan an der Seite der Alliierten im Ersten Weltkrieg, in dem Japan Kolonien des deutschen Kaiserreichs übernehmen konnte, darunter einen Teil Deutsch-Neuguineas (japanisches Südseemandat). Etwa zehn Jahre zuvor war es wegen des Streits um die Vorherrschaft in der Mandschurei und in Korea zum Russisch-Japanischen Krieg (1904–1905) gekommen.

Zur Überwindung der Wirtschaftskrise ab 1929 schlugen einflussreiche Politiker und Militärs eine territoriale Expansion Japans vor. Ab den 1930er-Jahren erlangten Militärs verstärkt Kontrolle über die Regierung, einschließlich des Amts des Premierministers; politische Gegner wurden verfolgt und Medien zensiert. Der aggressive Einsatz für eine Neuordnung der Pazifikregion hatte vorgeblich zum Ziel, die Hegemonie über die asiatischen Länder und deren Kolonien durch westliche, europäische Staaten zu beenden (Panasienbewegung). Tatsächlich war es der Wille, durch gewaltsame Sicherung von Rohstoff- und Absatzgebieten sowie Siedlungsland für Auswanderer die chronischen wirtschaftlichen Schwierigkeiten Japans zu lösen.

Die japanische Expansion richtete sich zunächst gegen die Republik China. Nach dem Mukden-Zwischenfall am 15. September 1931, der vermutlich von den Japanern selbst inszeniert wurde, kam es drei Tage später zur Mandschurei-Krise, und im Februar 1932 wurde ein japanischer Vasallenstaat Mandschukuo errichtet. Nach internationalen Protesten über das Vorgehen in China trat Japan 1933 aus dem Völkerbund aus; 1936 schloss es sich dem Antikominternpakt an.

Am 7. Juli 1937 kam es zum Zwischenfall an der Marco-Polo-Brücke in Peking, den die japanische Armee zum Anlass nahm, ohne Kriegserklärung in Nordchina einzudringen und die Haupthäfen entlang der gesamten chinesischen Küste zu besetzen. Da sie auch das Hinterland von Hongkong und Macau besetzt hielten, blockierte sie fast die gesamte chinesische Küste, um die wirtschaftlichen Verbindungen Chinas nach Übersee abzuschneiden. Diese Ereignisse werden von einigen Historikern als der eigentliche Beginn des Zweiten Weltkrieges angesehen. Gleichwohl unterschied sich der Krieg in China sehr von dem Krieg in Europa, der am 1. September 1939 begann. Im Frühjahr und Sommer 1940, als die deutsche Wehrmacht die Niederlande, Belgien und Frankreich überrannte und „Großbritannien beinahe in die Knie zwang“, war kein Ende des asiatischen Krieges in Sicht.

China stand damals an einem Scheideweg, da die Kommunisten unter Mao Zedong und die Nationalisten der Kuomintang unter Chiang Kai-shek um die Vorherrschaft im Land kämpften. Die Kommunisten hatten sich nach dem Langen Marsch in das Landesinnere nach Yan’an zurückgezogen und griffen beim Kampf gegen die Japaner nur vereinzelt ein.

Um den 8. Dezember 1937 erreichten japanische Truppen Nanjing, die Hauptstadt der Kuomintang, und kesselten sie ein. Chiang Kai-shek ließ die Hauptstadt in das entfernte Chongqing verlegen. Bei der Besetzung der Stadt kam es in den folgenden sechs Wochen zum Massaker von Nanking, in dem mindestens 200.000 chinesische Zivilisten und Kriegsgefangene ermordet und etwa 42.000 Frauen und Mädchen aller Altersstufen vergewaltigt wurden. „Die Berichte über die Mord- und Vergewaltigungsorgie erschütterten die Welt.“ Die öffentliche Meinung im Westen, insbesondere in den USA, wandte sich scharf gegen Japan. Im Juli 1939 kündigte die Regierung der USA einen seit 1911 bestehenden wichtigen Handelsvertrag, durch den fast ein Drittel aller japanischen Einfuhren betroffen waren. Ein Ausweg aus der zunehmenden Isolation schien ein Bündnis mit Deutschland zu sein, das auch vom deutschen Außenminister Ribbentrop befürwortet wurde.

Der Weg nach Pearl Harbor war zwar keine Einbahnstraße, aber im Sommer 1940 unternahm die japanische Führung entscheidende Schritte, sodass die beiden Kriege in Europa und Asien zu einem einzigen globalen Flächenbrand verschmolzen. Japan nutzte die Niederlage der Westmächte und erpresste im Juni 1940 von Großbritannien und Frankreich, die lebenswichtigen Hilfslieferungen an die chinesischen Nationalisten über Burma und Indochina einzustellen. Die niederländische Exilregierung in London wurde unter Druck gesetzt, Öl aus Niederländisch-Indien nach Japan zu exportieren. Außerdem setzte es in Nanking Wang Jingwei als Chef einer Marionettenregierung ein.

Fürst Konoe Fumimaro, der im Juli 1940, nach den dramatischen Ereignissen in Europa, zum zweiten Mal Ministerpräsident geworden war, hatte im selben Jahr in einer Denkschrift argumentiert, der Krieg in China werde letztlich zu einer „großostasiatischen Wohlstandssphäre“ führen, gebildet aus Japan, Mandschukuo und China sowie ehemaligen Kolonien Großbritanniens, der Niederlande und Frankreichs. Geprägt hatte den Ausdruck Matsuoka Yōsuke, Außenminister im zweiten Kabinett Konoe. Der "Dreimächtepakt" mit Deutschland und Italien vom 27. September 1940 erweiterte den bestehenden Antikominternpakt um gegenseitige militärische Unterstützung. Damit verwarf Japan seine im September 1939 verkündete Neutralität und unterstrich seine aggressive Außenpolitik vor allem gegenüber China. Der Pakt richtete sich nicht gegen die Sowjetunion, sondern sollte vor allem die USA aus dem Krieg heraushalten. Die amerikanische Reaktion zeigte rasch, wie haltlos Matsuokas und Ribbentrops Behauptungen gewesen waren, der "Dreimächtepakt" werde abschreckend wirken. Im "Weißen Haus" verstärkte sich die Ansicht, dass Japan eine aggressive, kriegslüsterne Macht sei, ein asiatisches Gegenstück zum nationalsozialistischen Deutschland, die aufgehalten werden müsse. Bestätigt wurde diese Auffassung, als Japan im September 1940, als noch Verhandlungen mit den Franzosen im Gange waren, in zweitägigen Gefechten den nördlichen Teil von Französisch-Indochina gewaltsam besetzte. Schon im folgenden Monat verhängten die USA ein totales Ausfuhrverbot für Eisen- und Stahlschrott nach Japan, und Großbritannien öffnete wieder die Burmastraße für den Nachschub nach China.

Die japanische Führung wollte die Niederlagen Frankreichs und der Niederlande sowie die erwartete Niederlage Großbritanniens im Krieg gegen Deutschland zu einer Südexpansion (Indochina, Niederländisch-Indien, Hongkong, Malaya und Singapur) ausnutzen. Am 25. Juni 1940 sagte Heeresminister Shunroku Hata zu seinen Mitarbeitern: „Ergreifen wir die goldene Gelegenheit! Nichts soll uns aufhalten!“ Mit einer japanischen Besitzergreifung der britischen, französischen und niederländischen Kolonien in Südostasien wäre die Möglichkeit eines Zusammenbruchs Chinas in greifbare Nähe gerückt. Die Errichtung einer japanischen Hegemonialmacht in Ostasien und die Hegemonie eines nationalsozialistischen Deutschlands in Europa hätten darüber hinaus bedeutet, dass Amerika sich einer von totalitären Mächten gemeinsam beherrschten Alten Welt gegenübergesehen hätte, denn auch die Sowjetunion schien zu dieser Zeit ihre Einflusssphäre mit den Achsenmächten und Japan auf friedliche Weise abzugrenzen.

Das Jahr 1941 begann mit verstärkten Bemühungen der USA und Japan, einen drohenden Krieg zu vermeiden. Gleichzeitig nahmen die Kriegs- und Eroberungspläne der Japaner für Südostasien konkrete Formen an. In Verhandlungen zwischen dem US-Außenminister Cordell Hull und dem neu ernannten japanischen Botschafter Kichisaburō Nomura waren die Japaner bereit, auf ein weiteres Vorgehen nach Süden zu verzichten, wenn ihnen die Amerikaner die Unterwerfung Chinas ermöglichten. Aber die Weigerung, Japan freie Hand in China zu lassen, sollte im Dezember 1941 letzten Endes den japanischen Angriff auf Pearl Harbor auslösen. Am 2. Juli fiel in Japan die Entscheidung, den territorialen Anspruch nach Südostasien auszuweiten, wo die ergiebigen Bodenschätze der niederländischen und britischen Kolonien ein lohnendes Ziel waren. Zwei Tage nach der Besetzung auch des südlichen Teils von Indochina, der als Sprungbrett für diese Südexpansion gebraucht wurde, froren die USA, Großbritannien und seine Dominions sowie Niederländisch-Indien am 26. Juli 1941 die japanischen Auslandsguthaben in ihren Ländern ein, was praktisch einem völligen Exportembargo – auch von Erdöl – gleichkam. Wegen dieses Embargos blieb ein Krieg die vermeintlich einzige Alternative für Japan, weil dessen Ölreserven in spätestens zwei Jahren aufgebraucht sein würden. Am 5. November 1941 fiel in Tokio die Entscheidung, den Krieg im folgenden Monat mit Angriffen auf Pearl Harbor, Malaya und die Philippinen auszulösen. Das strategische Ziel war, innerhalb von acht Monaten die Herrschaft über Südostasien und den Westpazifik zu gewinnen, um von dieser Machtbasis aus längere Zeit gegen die Vereinigten Staaten zu kämpfen oder sie zu einem Verhandlungsfrieden zu Japans Vorteil zwingen zu können. Zugleich rechnete man damit, dass im Zuge der Expansion die Hilfslieferungen an China unterbrochen werden könnten. Letzte Verhandlungen in Washington zwischen Nomura, dem Sondergesandten Saburō Kurusu und Hull, den Krieg zu vermeiden, scheiterten an Hulls kompromissloser Forderung nach Rückzug aller japanischen Truppen aus China und Indochina. Im Gegenzug wollten die USA die japanischen Guthaben freigeben. Wie nicht anders zu erwarten, wurde Hulls "Zehnpunkteprogramm", als es am 27. November in Tokio eintraf, als Ultimatum aufgefasst – praktisch als Beleidigung. Die Kaiserliche Konferenz vom 1. Dezember 1941 stellte fest, dass Japan die „äußerst hochmütige, starrsinnige und respektlose“ Haltung der Vereinigten Staaten nicht dulden könne.

Beim Angriff auf Pearl Harbor am 7. Dezember 1941 versenkten japanische Flugzeuge, die von sechs Flugzeugträgern aus gestartet waren, in zwei Wellen fünf Schlachtschiffe, von denen drei später wieder flottgemacht werden konnten, und vierzehn weitere größere Kriegsschiffe der USA. Vizeadmiral Nagumo, der Kommandant der Flugzeugträgergruppe Kidō Butai, ließ keine dritte Angriffswelle aufsteigen, weil er sich Sorgen um den Standort der nicht anwesenden drei amerikanischen Träger machte, die einen schweren Gegenschlag führen konnten. Durch diese Entscheidung blieben Docks und Werftanlagen sowie Nachschubdepots und Treibstofflager intakt, was den USA einen raschen Wiederaufbau ihrer pazifischen Flotte in den nächsten sechs Monaten ermöglichte. Am nächsten Tag erklärte der amerikanische Kongress Japan den Krieg, der am selben Tag auch die von Großbritannien, seinen Dominions und den Niederlanden folgten. Am 10. Dezember wurden vor der Ostküste der malaiischen Halbinsel der britische Schlachtkreuzer "Repulse" und das moderne Schlachtschiff "Prince of Wales", das erst wenige Monate zuvor in Dienst gestellt worden war, von japanischen Torpedoflugzeugen versenkt. Die Versenkung der beiden Großkampfschiffe war ein deutliches Zeichen für den sich abzeichnenden Bedeutungsverlust von solch großen Kriegsschiffen gegenüber land- und seegestützten Luftstreitkräften.

In den nächsten Monaten drängten die Japaner weiter nach Süden vor und besetzten, ideologisch vorbereitet durch den Schlachtruf „Asien den Asiaten“, europäische und US-amerikanische Kolonien wie Hongkong, Teile Burmas und Indiens, Britisch-Malaya, Singapur, Niederländisch-Indien und die Philippinen.

Innerhalb von vier Monaten (Dezember–März) hatten japanische Truppen weite Teile Südostasiens und einen Großteil der Pazifikinseln mit etwa 450 Millionen Menschen unter ihre Kontrolle gebracht. Dies war die größte Ausdehnung japanischer Macht in der Geschichte des Kaiserreichs. Die Eroberungen Malayas und von Niederländisch-Indien waren besonders wichtig für Japan, weil es dort reiche Erzvorkommen, eine umfangreiche Gummiproduktion und große Erdölfelder gab. 80.000 Briten, Australier und Inder mussten am 15. Februar 1942 in Singapur, dem „Gibraltar des Ostens“ und Großbritanniens größter Militärbasis in Südostasien, kapitulieren. Die Schlacht um Singapur gilt als Sinnbild des japanischen Blitzkrieges, später auch der Brutalität japanischer Soldaten, denn von den alliierten Gefangenen starben mehr als 11.000 an Hunger und Erschöpfung beim Bau der Thailand-Burma-Eisenbahn. Die Invasion Burmas begann am 15. Februar 1942. Niederländisch-Indien wurde Mitte März 1942 erobert. Auf den Philippinen musste General Douglas MacArthur bald Manila räumen und sich auf die Insel Corregidor zurückziehen, wo die letzten US-Truppen am 5. Mai 1942 kapitulierten. Nichts schien die Japaner aufhalten zu können.

Nach der Eroberung von Rabaul an der Nordostspitze der Insel Neubritannien (Januar 1942) hatten die Japaner eine hervorragende Ausgangsbasis für ein weiteres Vordringen in Richtung Ostpazifik und Südsee gewonnen.

Die Schlacht im Korallenmeer (Anfang Mai 1942) endete unentschieden (je ein gesunkener und ein schwer beschädigter Flugzeugträger auf beiden Seiten), und die Japaner gaben ihre Absicht auf, bei Port Moresby im Süden von Neuguinea zu landen, sodass die Alliierten ein Vorfeld nördlich von Australien halten konnten. Es war die erste kombinierte See-Luft-Schlacht in der Seekriegsgeschichte. Trotz des Rückschlags im Korallenmeer konnten die japanischen Streitkräfte bisher zufrieden sein: 340.000 alliierte Soldaten waren in Gefangenschaft geraten, und die alliierten Flotten hatten acht Schlachtschiffe, zwei Flugzeugträger, sieben Kreuzer und zahlreiche kleinere Kriegsschiffe verloren. In der Schlacht um Midway Anfang Juni 1942, in der Yamamoto annahm, die amerikanische Navy habe nur noch zwei Träger – die er zudem im Südpazifik wähnte – glaubte er, die verbliebene Pazifikflotte der USA zu einem Entscheidungskampf herausfordern zu können. Aber die amerikanische Flotte war dank ihrer Funkaufklärung detailliert über die Pläne des Gegners informiert. Bei Luftangriffen von Flugzeugen dreier amerikanischer Träger verlor die japanische Marine vier Flugzeugträger und 200 Flugzeuge mit besonders erfahrenen Piloten und Pilotenausbildern. Ihre Flotte war so empfindlich geschwächt worden, dass die japanische Überlegenheit im See-Luft-Krieg verloren war. Die Schlacht „gilt mit Recht als der Wendepunkt des Krieges im Stillen Ozean.“

Nach dem Bau eines Flugplatzes auf Guadalcanal hätte Japan den alliierten Schiffsverkehr zwischen den USA und Australien bedrohen können. Die US Navy setzte im August 1942 ihre einzige noch verfügbare intakte Marine-Infanteriedivision (USMC) ein, um den Flugplatz zu erobern, was rasch gelang. Hartnäckig versuchten die Japaner, die Insel zurückzuerobern. Erst nach monatelangen Kämpfen gelang es den Alliierten, sich auf der Insel endgültig zu behaupten (→ Schlacht um Guadalcanal). Dieser Erfolg markierte einen weiteren Wendepunkt zugunsten der USA, die jetzt nicht nur mehr Kriegsschiffe und Flugzeuge besaßen, sondern auch taktisch überlegen waren.

Die härtesten Kämpfe tobten von Ende 1942 bis Mitte 1944 auf Neuguinea, auf den Salomonen, den Gilbertinseln, den Marshallinseln und den Marianen. Ein erfolgreiches taktisches Mittel war dabei das „Island Hopping“, bei dem die Amerikaner die starken japanischen Stützpunkte, zum Beispiel das wichtige Rabaul mit seinem Hafen und den Flugfeldern, umgingen und sich Insel für Insel näher an die japanische Hauptinsel Honshū herankämpften.

Zu Beginn des Jahres 1943 gelang es den Amerikanern, japanische Funkcodes zu entschlüsseln. Damit wurden auch die Erfolge der US-amerikanischen U-Boote gesteigert, deren stetig steigende Versenkungsraten einen wesentlichen Anteil am Sieg über Japan hatten, denn sie torpedierten etwa ein Drittel von 686 japanischen Kriegsschiffen. Der japanischen Marine gelang es während des gesamten Krieges nicht, ein wirksames Schutzsystem für ihre Transportschifffahrt zu entwickeln. Dies lag sowohl an der Unterschätzung der U-Boot-Gefahr in der japanischen Militärdoktrin als auch an der großen technologischen Unterlegenheit Japans im Bereich der Radar- und der Unterwasserschallortung. Vor allem der daraus resultierende Mangel an Treibstoff machte es erforderlich, Flottenverbände weit außerhalb der Hauptkampfgebiete, in der Nähe von Treibstoffquellen, zu stationieren, was die taktischen und strategischen Optionen der japanischen Flotte stark einschränkte.

Im April 1943 gelang es den Amerikanern, von Guadalcanal aus fünf Begleitmaschinen von Yamamotos Flugzeug, der sich auf einem Inspektionsflug befand, abzuschießen. Admiral Yamamoto, Oberbefehlshaber der japanischen Marine, kam beim Absturz seiner Maschine in den Dschungel ums Leben. Der Verlust dieser Führungs- und Identifikationsfigur war für die japanische Öffentlichkeit ein schwerer Schlag (→ Operation Vengeance).

Im November 1943, kurz vor dem Treffen mit Stalin in Teheran, vereinbarten Roosevelt und Churchill mit Chiang Kai-shek in Kairo, dass der Krieg gegen Japan ebenso wie der gegen Deutschland mit der bedingungslosen Kapitulation enden sollte. Chiang Kai-shek wurde damit nicht nur als "der" Repräsentant Chinas, sondern auch als Staatschef einer "Großmacht" anerkannt.

Ab 1944 begann die Erfolgszeit der amerikanischen Task Forces, die mit schnellen "Trägerraids" überraschend vor der Küste Japans auftauchten und fast nach Belieben Ziele aller Art angriffen. Die Japaner reagierten mit dem Einsatz von Kamikaze-Fliegern und bemannten Kaiten-Torpedos. Die von den Japanern erwarteten hohen Verluste amerikanischer Kriegsschiffe blieben aus.

In der ab Mitte Juni 1944 begonnenen Schlacht um Saipan, verbunden mit der Schlacht in der Philippinensee, verloren die Japaner fast alle eingesetzten Flugzeuge mitsamt Besatzungen und durch U-Boote drei Flugzeugträger. Der Verlust von Saipan löste in Japan ein politisches Erdbeben aus: Die Regierung von General Tojo musste zurücktreten und wurde abgelöst durch ein Kabinett unter General Koiso Kuniaki, der sogleich das Wehrpflichtalter auf 17 Jahre senkte. Ende Oktober bis Anfang November 1944 kam es während der Landungen auf Leyte (Philippinen) zur See- und Luftschlacht im Golf von Leyte. Japan setzte den größten Teil seiner Flotte ein und machte damit aus den Kämpfen um Leyte die größte Seeschlacht des Zweiten Weltkrieges. Die Japaner verloren mit vier Flugzeugträgern, drei Schlachtschiffen, zehn Kreuzern und neun Zerstörern fast ihre komplette verbliebene Seestreitmacht.

Erst nach der Eroberung der Marianen-Inseln im Sommer 1944 lag Japan innerhalb des Aktionsradius der neuen Boeing B-29 der USAAF. Die US-Luftwaffe ging zu nächtlichen Flächenbombardements aus relativ geringer Höhe auf die überwiegend aus Holz gebauten japanischen Städte über, bei denen hunderttausende Menschen ums Leben kamen. Beim größten Angriff dieser Art starben in Tokio in der Nacht zum 9. März 1945 etwa 85.000 Menschen, mehr als bei jedem anderen Luftangriff im Zweiten Weltkrieg und fast so viele wie durch den Atombombenangriff auf Hiroshima. Weitere Luftangriffe zerstörten bis Kriegsende zahlreiche japanische Großstädte.

Bei der "Operation Hailstone" wurde am 17. Februar 1944 der wichtige japanische Flottenstützpunkt Truk auf den Karolinen angegriffen. Dabei konnten zwölf Torpedobomber des US-Trägers "Enterprise" beim ersten radargestützten Nachtangriff die in der Lagune liegenden japanischen Schiffe angreifen. Trotz heftigen Abwehrfeuers konnten diese nur ein US-Flugzeug abschießen. Mit Verlusten von über 200.000 BRT und schweren Schäden an den Einrichtungen wird dieser Angriff auch als "Pearl Harbor" der Japaner bezeichnet.

Die Rückeroberung der Philippinen erwies sich als langer und verlustreicher, sechs Monate dauernder Feldzug (Oktober 1944–März 1945). Den amerikanischen Verlusten, 8.000 Mann, standen disproportional höhere japanische Verluste wie meist im Pazifikkrieg gegenüber: Allein auf der Insel Luzon fielen 190.000 Japaner.

Bei den Kämpfen auf den japanischen Inseln Iwojima und Okinawa wurden US-Schiffe von einer großen Zahl Kamikaze-Fliegern angegriffen. Die US-Streitkräfte verloren fast 7.300 Marines und etwa 5.000 Seeleute und Piloten. 36 Schiffe der US Navy sanken, und fast 400 Flugzeuge wurden zerstört. Die Japaner verloren 113.000 Soldaten und mit den Kamikazemaschinen rund 7.800 Flugzeuge.

Nach den Kämpfen auf Iwojima und Okinawa warfen die Amerikaner mit einem B-29-Bomber, der von Tinian aus gestartet war, am 6. August 1945 die erste Atombombe auf Hiroshima. Kurz darauf, am 9. August wurde die zweite über Nagasaki gezündet.

Die Sowjetunion stand zu ihrer bei der Konferenz von Jalta eingegangenen Verpflichtung, 90 Tage nach dem Kriegsende in Europa in Fernost den Krieg zu beginnen und Japan und seine Verbündeten anzugreifen. Dem ist die Rote Armee auf den Tag genau nachgekommen (8. August), nachdem bereits im April 1945 der Neutralitätspakt mit Japan gekündigt worden war. Mit der Operation Auguststurm wurde die Mandschurei besetzt. Das eroberte Gebiet wurde gemäß den alliierten Kriegszielen (Kairoer Erklärung) von der Sowjetunion 1946 an die Republik China zurückgegeben.

Wenige Tage später, am 15. August 1945 verkündete der japanische Tennō in einer Rundfunkansprache ("Gyokuon-hōsō") die Kapitulation Japans, die am 2. September in der Bucht von Tokio auf der "USS Missouri" unterzeichnet wurde.

Die Besetzung der japanischen Hauptinseln wurde allein durch amerikanische Truppen durchgeführt, während die anderen beteiligten Mächte (Großbritannien, Sowjetunion und China) an der Besetzung der vormals japanischen Außengebiete beteiligt wurden.

Der Kriegszustand zwischen Japan und den Alliierten endete formell erst am 28. April 1952 mit der Unterzeichnung des Friedensvertrags von San Francisco.

Der Strategiehistoriker Colin Gray deutet den Zweiten Weltkrieg mit seinen Operationen auf drei Kontinenten zu Lande, zu Wasser und in der Luft als komplexes Ereignis, das von einer „eleganten Schlichtheit in seinem Ablauf und seiner Struktur“ durchzogen werde. Gray zufolge waren die beiden wichtigsten Kriegsschauplätze, die Ostfront und der pazifische Raum, grundsätzlich voneinander unabhängig. Allerdings stellten wichtige Ereignisse wie die deutsche Kriegserklärung an die Vereinigten Staaten nach dem japanischen Angriff auf Pearl Harbor immer wieder kriegswichtige Bezüge her. Ihnen gemeinsam sei vor allem gewesen, dass es sich bei beiden Feldzügen um „riesige Belagerungsoperationen“ gehandelt habe. Darüber hinaus ordnet Gray den Zweiten Weltkrieg trotz einer im Vergleich zum Ersten Weltkrieg verstärkten verbundenen Gefechtsführung, wie beispielsweise den Blitzkrieg, als Abnutzungskrieg ein.

Im Polenfeldzug hatte die Luftwaffe die Luftherrschaft, da die polnischen Luftstreitkräfte mit ihren größtenteils veralteten Flugzeugen nur wenig Widerstand leisten konnten. Bei den Luftangriffen auf Warschau (September 1939) wurden die ersten Angriffe auf vor allem zivile Ziele geflogen. Am 14. Mai 1940 zerstörte ein Angriff der Luftwaffe die Altstadt von Rotterdam (s. o. Westfeldzug).

Der Luftkrieg in den ersten Monaten der Luftschlacht um England richtete sich noch ausschließlich gegen militärische Ziele wie Fliegerhorste, Marinestützpunkte und Radarstellungen (→ Chain Home) und hatte letztlich das Erringen der Luftüberlegenheit zum Ziel. Er radikalisierte sich, als die deutsche Luftwaffe am 24. August 1940 einen ersten Angriff auf London flog und Churchill Vergeltungsangriffe auf Berlin befahl. Bis Ende des Jahres starben in London rund 14.000 Menschen.
Am 14. November 1940 flog die deutsche Luftwaffe einen schweren Luftangriff auf Coventry. Dabei kamen mindestens 568 Menschen ums Leben. Neben Fahrzeug- und Motorenwerken wurden Tausende von Wohnhäusern getroffen und die mittelalterliche St.-Michaels-Kathedrale zerstört. Die nationalsozialistische Propaganda erfand den Begriff des „Coventrierens“ für das Flächenbombardement. Die Royal Air Force griff ab Mai 1940 nadelstichartig deutsche Städte (z. B. Mönchengladbach) und Industrieanlagen wie die Deurag-Nerag-Raffinerie an (→ Luftangriffe auf Hannover). Nachdem die Luftwaffe Anfang 1941 die Luftschlacht um England abgebrochen und einen Großteil ihrer Bomber und Jagdflugzeuge wegen des geplanten Angriffs auf die Sowjetunion nach Osten verlegt hatte, flog die RAF mehr Nachtangriffe auf deutsche Großstädte.

Beim Luftangriff auf Belgrad am 6. April 1941 wurde die Stadt, die nur schwach verteidigt werden konnte, von der Luftwaffe in weiten Teilen zerstört. Bei der deutschen Offensive gegen die Sowjetunion spielte die Luftwaffe eine bedeutende Rolle, konnte aber weder die Schlacht um Moskau noch die um Stalingrad für die deutsche Seite entscheiden. Deutsche Bomber und Jäger wurden zumeist nur zur Luftnahunterstützung der Heerestruppen eingesetzt. Die United States Army Air Forces (USAAF) flogen im April 1942 den ersten Bombenangriff auf Tokio; ab August 1942 begann die 8. Luftflotte der USAAF in Europa mit eigenen Luftangriffen.

Da die Bombenangriffe mit wenigen Maschinen hohe Verlustquoten aufwiesen und ihr Ziel meistens verfehlten, ging die RAF ab Frühjahr 1942 dazu über, große Bomberpulks nach Deutschland zu schicken, um großflächig Städte zu zerstören. Ziel war es, neben der Zerstörung von Industrieanlagen vor allem die Moral der Bevölkerung zu brechen ("morale bombing"). Arthur Harris, ab Februar 1942 Oberkommandierender des Bomber Command, wurde vom Luftfahrtministerium erlaubt, er könne seine Luftstreitkräfte ab sofort ohne jede Beschränkung einsetzen.

Die Umsetzung dieser „Area Bombing Directive“ begann mit dem Luftangriff auf Lübeck im März 1942, der Ende Mai 1942 im 1000-Bomber-Angriff auf Köln (Operation Millennium) und dann in zahlreichen Städten des Ruhrgebiets seine Fortsetzung fand. Im Januar 1943 flog die Royal Air Force den ersten großen Angriff auf Berlin. Hier warfen zum ersten Mal "Pfadfinder-Flugzeuge" Zielmarkierungsbomben ab. Ende desselben Monats griff auch die USAAF als erste Ziele auf deutschem Boden U-Boot-Werften in Wilhelmshaven an. Im März 1943 wurde das deutsche Rüstungszentrum Essen von der RAF angegriffen. Dabei wurde eine Panzerfabrik zerstört, wodurch sich die Produktion der Panzer "Tiger" und "Panther" verzögerte, was zu einer Verschiebung der Offensive bei Kursk (s. o.) führte. Göring zog immer mehr Jägerstaffeln von der Ostfront für den Schutz deutscher Städte ab. Die negativen Auswirkungen für den Kriegsverlauf im Osten dürften wesentlich größer gewesen sein als die Abschüsse, die die Jäger den alliierten Bombern zufügen konnten. In diesem Frühjahr 1943 stiegen die Verluste der alliierten Bomberflotten in beängstigende Höhen. Nicht einmal ein Fünftel der Besatzungen der RAF überlebte einen Zyklus von 30 Einsätzen. Die 8. US-Luftflotte verlor durch Abschüsse so viele Flugzeuge, dass sie in diesem Jahr nicht mehr in der Lage war, die für den Erfolg einer Invasion in Westeuropa nötige Luftüberlegenheit herzustellen. Im Juli 1943 wurde Hamburg durch einen Feuersturm zerstört, in dem 40.000 Bürger ihr Leben verloren. Die USAAF konzentrierte sich in Tagesangriffen vorwiegend auf Industrieziele, während Bomber der RAF bei Nacht die Städte bombardierten. Die US-Bomberverbände hatten zunächst beträchtliche Verluste, beispielsweise bei den Angriffen gegen Schweinfurt und Essen. Als ab Frühjahr 1944 Langstreckenjäger der USAAF die Bomber begleiteten, gingen die Verlustzahlen deutlich zurück. Mit den massiven Luftangriffen hofften die Alliierten auch, Widerstand gegen die NS-Führung hervorrufen und den Krieg verkürzen zu können.

Ab Frühjahr 1944 erhöhte sich die Luftüberlegenheit derart, dass beinahe täglich alliierte Bomber in das Reichsgebiet einfliegen konnten. In der "Big Week" wurden im Februar 1944 ausgewählte Ziele der deutschen Rüstungsindustrie mit 6.000 Bombern der RAF und der USAAF angegriffen. Als ab Mai 1944 die kriegswichtigen Raffinerien und Hydrieranlagen, unter anderen die Leunawerke, verstärkt bombardiert wurden, wurde die Treibstoffversorgung des Heeres und insbesondere der Luftwaffe erheblich beeinträchtigt. Mit dem darauf folgenden Ausfall von 90 % der deutschen Benzinproduktion war der Krieg laut Albert Speer für das Deutsche Reich auch „produktionstechnisch verloren“.

Die schweren Luftangriffe auf Dresden vom 13. bis 15. Februar 1945 töteten etwa 25.000 Menschen und sind bis heute Gegenstand kontroverser Betrachtungen zwischen militärischer Notwendigkeit oder Bruch des damaligen Kriegsvölkerrechts. Zur selben Zeit wurden bis Ende März 1945 auch kleinere Städte wie Pforzheim, Swinemünde, Würzburg, Hanau, Hildesheim und Paderborn noch großflächig zerstört.

Mit der Entwicklung des Marschflugkörpers V1 und der Rakete V2 hoffte die nationalsozialistische Führung auf eine „Wunderwaffe“. Da beide Waffen nicht punktgenau eingesetzt werden konnten, waren sie ungeeignet zur gezielten Zerstörung militärischer Ziele. Jede vierte V1 war ein Blindgänger, andere wurden von britischen Jagdflugzeugen abgeschossen. Aber in der deutschen Bevölkerung konnte Hoffnung auf eine Wende geweckt oder wachgehalten werden, etwa in der Flüsterpropaganda: „Da kommt noch was! Das ist noch nicht alles.“ Ihre Funktion war vor allem die Terrorisierung der britischen Zivilbevölkerung. Zwischen Juni 1944 und März 1945 wurden mit ihnen vorwiegend London und später Antwerpen angegriffen.

Im Bombenkrieg starben rund 600.000 Deutsche und 60.595 Briten. Von den 125.000 Freiwilligen des britischen Bomberkommandos sind über 55.000 Soldaten gefallen, mehr als in jeder anderen britischen Waffengattung.

Im Krieg gegen Japan ging die USAAF nach anfänglichen, erfolglosen Präzisionsangriffen aus großer Höhe zu Flächenbombardements aus relativ geringer Höhe auf japanische Städte über. Die amerikanischen Luftangriffe auf Tokio im Februar und März 1945 zerstörten die Stadt, die überwiegend aus Holzhäusern bestand, fast vollständig, wobei über 100.000 Menschen starben. Bei den Bombardements anderer Großstädte kamen Hunderttausende von Menschen ums Leben. Den Schlusspunkt setzten die US-amerikanischen Atombombenabwürfe auf Hiroshima und Nagasaki am 6. und 9. August 1945. Sie sollten zum einen Japan militärisch zur Kapitulation zwingen und zum anderen ein politisches Zeichen militärischer Stärke in der aufkommenden Blockkonfrontation setzen.

Mit der Versenkung des britischen Dampfers "Athenia" am 3. September 1939 begann der deutsche U-Boot-Krieg im Atlantik. Als Propagandaschlag von Konteradmiral Karl Dönitz geplant, gelang es Kapitänleutnant Günther Prien, mit "U 47" am 14. Oktober 1939 in die Bucht von Scapa Flow einzudringen und im Hauptstützpunkt der Home Fleet das Schlachtschiff "Royal Oak" der britischen Marine zu versenken, wobei über 800 Mann ums Leben kamen. Fanden bis zur Mitte des Jahres 1940 hauptsächlich Aktionen durch einzelne U-Boote statt, konnten nach der Eroberung Frankreichs von fünf U-Boot-Stützpunkten (vorerst provisorisch, später mit massiven Bunkern) an der Atlantikküste aus U-Boote wesentlich schneller die Operationsgebiete im Nordatlantik und vor dem Ärmelkanal erreichen. Die alliierten Konvois waren aus Mangel an Geleitschiffen nur schwach gesichert. Außerdem setzten die U-Boot-Kommandanten die neue Taktik eines nächtlichen Überwasserangriffs ein, der die nur Unterwasserziele ortenden alliierten ASDIC-Sonargeräte wirkungslos machte.

Die jetzt folgenden Versenkungen durch deutsche U-Boote wurden von der nationalsozialistischen Propaganda ausgeschlachtet; viele Kommandanten wurden zu Helden stilisiert und mit Orden dekoriert. Die Alliierten verloren 1940 und 1941 je 4,4 Millionen BRT Schiffsraum, denen nur 1,2 und 2 Millionen BRT an Neubauten gegenüberstanden.

Um den Druck auf die britischen Nachschubtransporte zu erhöhen und um den U-Boot-Krieg zu unterstützen, lief im Mai 1941 ein Geschwader aus Gotenhafen mit Ziel Atlantik aus. Es bestand aus dem gerade erst in Dienst gestellten Schlachtschiff "Bismarck", dem ebenfalls erst wenige Monate im Dienst befindenden Schweren Kreuzer "Prinz Eugen" und einigen Zerstörern. Die Aktion bekam den Decknamen "Unternehmen Rheinübung", führte zum Untergang des britischen Schlachtkreuzers "HMS Hood" am 24. Mai 1941 und endete drei Tage später mit der Versenkung der "Bismarck".

Nach der Kriegserklärung Deutschlands an die Vereinigten Staaten am 11. Dezember 1941 entsandte Vizeadmiral Dönitz Langstrecken-U-Boote zur Ostküste der USA (Unternehmen Paukenschlag), wo sie in den ersten Januartagen 1942 eintrafen. Die zunächst schlecht organisierte US-Küstenverteidigung stand den Angriffen auf die Handelsschifffahrt hilflos gegenüber. Als die Verteidigung im Frühjahr zunahm, wichen U-Boot-Kommandanten in die Karibik und den Südatlantik aus. Nachdem sie dort sechs brasilianische Handelsschiffe hatten torpedieren lassen, wobei fast 1000 Seeleute und Passagiere ums Leben kamen, erklärte Brasilien als einziger südamerikanischer Staat am 22. August 1942 dem Deutschen Reich den Krieg und entsandte 1944 ein Expeditionskorps nach Italien. Andere Boote operierten zur selben Zeit im Nordatlantik in Rudeln und konnten so den Druck auf die Konvois aufrechterhalten. Es kam im Laufe des Jahres zu mehreren großen Geleitzugschlachten. Im Herbst 1942 steigerten sich die Erfolge der U-Boote noch weiter, da viele Geleitkräfte für die Sicherung der Transporte nach Nordafrika (Material für Operation Torch) eingesetzt waren. 1942 wurden 8,2 Millionen BRT alliierten Schiffsraums versenkt; 7,2 Millionen BRT wurden neu gebaut (s. u.).

Ende 1942 gelang es britischen Kryptoanalytikern in Bletchley Park bei London, den mit Hilfe der ENIGMA verschlüsselten Funkverkehr der deutschen U-Boote erneut zu brechen. Durch Entschlüsselung des deutschen Funkverkehrs, Unterwasserschallortung von Schiffen und Radarortung von Flugzeugen aus entstand ab 1943 eine katastrophale Situation für die deutschen U-Boote. Im Mai 1943 konnten die Alliierten die Verbesserung der technischen Ausstattung der Konvoi-Geleitkräfte ("escorts") durch Radar, Sonar und Hedgehog-Granatwerfer sowie ihre Luftüberlegenheit mittels Geleitflugzeugträger in vollem Maße nutzen, sodass in diesem Monat 43 deutsche U-Boote versenkt wurden. Großadmiral Dönitz stellte daraufhin am 20. Mai den U-Boot-Krieg vorübergehend ein. „Damit trat auch im Seekrieg eine entscheidende Wende zugunsten der Alliierten ein.“

Nach der Landung der Alliierten in der Normandie, Anfang Juni 1944, gingen bald auch die deutschen U-Boot-Stützpunkte an der französischen Atlantikküste verloren. Die U-Boote wurden in die Nord- und Ostsee sowie norwegischen Küstengewässer zurückgedrängt oder operierten häufiger vor der britischen Ostküste. Das damals modernste U-Boot vom Typ XXI kam bis Kriegsende nicht mehr zum Einsatz. Bei Bekanntwerden der bevorstehenden Kapitulation der Wehrmacht wurde am 4. Mai 1945 die "Operation Regenbogen" gestartet: Obwohl Dönitz’ Befehl an diesem Tage lautete, alle Schiffe zu übergeben, wurden die meisten U-Boote von ihren Besatzungen selbst versenkt. Die übrigen Boote liefen nach dem 8. Mai mehrheitlich britische oder US-amerikanische Häfen an.

Schiffsraumbilanz des Handelskrieges:

Die Kriegswirtschaft war von entscheidendem Einfluss auf den Kriegsverlauf und seinen Ausgang. Während anfangs die jeweilige Militärtaktik entscheidenden Einfluss hatte, war der Kriegsverlauf ab 1942 wesentlich durch die quantitative Übermacht der Kriegsproduktion der Alliierten beeinflusst. Das Dritte Reich und Japan verfolgten eine Blitzkriegstaktik und waren auf einen längeren Krieg nicht vorbereitet. Großbritannien, die Sowjetunion und die USA hingegen hatten seit Kriegsbeginn konsequent eine drastische Ausweitung der Kriegsproduktion mit dem Ziel herbeigeführt, den Zweiten Weltkrieg nach Art eines Abnutzungskriegs zu gewinnen. Im Dritten Reich war erst Anfang 1942 eine große Ausweitung der Kriegsproduktion angestoßen worden.

Die Kriegswirtschaft im Zweiten Weltkrieg führte vor allem bei den Alliierten zu einer deutlichen Ausweitung der Frauenarbeit. Im Dritten Reich und in Japan wurden in großem Umfang Zwangsarbeiter eingesetzt.

Kriegsmateriallieferungen Großbritanniens und der USA an die Sowjetunion (in Tonnen) via:

Im Kriegsverlauf wurden nach entsprechenden Befehlen von deutschen Truppen zahlreiche Kriegsverbrechen an Juden, Sinti und Roma und Osteuropäern verübt. Während der Leningrader Blockade verhungerten mehr als eine Million Menschen. In deutschen Sammellagern starben über drei Millionen sowjetische Kriegsgefangene. Es waren keine Vorbereitungen für deren existenzsichernde Unterkunft und Versorgung getroffen worden, obwohl das Oberkommando der Wehrmacht schon im März 1941 für die Wochen nach dem Überfall, den Sommer und Herbst 1941, mit zwei bis drei Millionen sowjetischen Kriegsgefangenen gerechnet hatte. Die Wehrmacht ließ sie aus Gleichgültigkeit oder gezielt verhungern; sie starben an Krankheiten, Misshandlungen, bei der Zwangsarbeit oder wurden ermordet.

Truppen der Achsenmächte und der Alliierten verübten in den meisten vom Krieg betroffenen Ländern Vergewaltigungen. In der Wehrmacht wurden 5349 Soldaten wegen Sexualverbrechen verurteilt.
Wie groß die Zahl der tatsächlich von Soldaten der Wehrmacht begangenen Vergewaltigungen war, lässt sich aufgrund des mangelnden Interesses der Wehrmachtführung an Strafverfolgungen und der „dürren Quellenlage“ nicht seriös schätzen.

Auch über das Ausmaß der sexuellen Übergriffe durch Soldaten der Roten Armee während ihres Vormarsches auf deutschem Territorium lässt sich nur spekulieren, da keine nur annähernd gesicherten Befunde darüber vorliegen. Der Statistiker Gerhard Reichling schätzt, dass 1,9 Millionen deutsche Frauen und Mädchen während des Vormarsches bis Berlin von Männern der Roten Armee vergewaltigt worden seien, davon 1,4 Mio in den ehemaligen Ostgebieten, während ihrer Flucht und Vertreibung und 500.000 in der sowjetischen Besatzungszone. Historiker wie Norman Naimark gehen von Zehntausenden, wahrscheinlicher sogar Hunderttausenden und möglicherweise von bis zu zwei Millionen Opfern aus.

Catherine Merridale schätzt die Opfer von Vergewaltigungen durch Angehörige der Roten Armee auf „Zehn-, höchstwahrscheinlich sogar Hunderttausende deutscher Frauen und Mädchen“. Für Schätzungen der Zahl der deutschen Frauen, die durch Soldaten der westlichen Alliierten vergewaltigt wurden, gibt es bislang keine ausreichende Grundlage.

Japan ging insbesondere gegen Chinesen mit großer Brutalität vor. Dabei kam es zu Kriegsverbrechen japanischer Soldaten in Republik China (Massaker von Nanking) sowie grausamen medizinischen Experimenten an Gefangenen. Nach chinesischen Angaben sollen zwischen fünf und zehn Millionen chinesische Zivilisten getötet worden sein. Die Bombardierung Shanghais 1937 war der Auftakt des japanischen Eroberungsfeldzuges durch Südostasien. Der Feldzug kostete bis 1945 insgesamt etwa 20 Millionen Menschen das Leben. Die Einheit 731 führte in Lagern grausame Experimente an Gefangenen durch; es sind japanische Menschenversuche mit biologischen Krankheitserregern an Chinesen bekannt geworden. Von 1932 bis 1945 kam es zu Vergewaltigungen von Frauen und Mädchen durch japanische Soldaten in besetzten Gebieten. Die genaue Anzahl der Vergewaltigungen wurde nie ermittelt. Nur in wenigen Fällen, wie die Massenvergewaltigungen während des Massakers von Nanking, liegen genauere Untersuchungen vor. Die vergewaltigten Frauen und Mädchen wurden nach der Vergewaltigung häufig getötet. Eine Strafverfolgung durch die japanische Militärjustiz erfolgte nicht. Die japanische Armee verschleppte zwischen 1932 und 1945 nach Schätzungen 100.000 bis 300.000 Mädchen und Frauen, meist im Alter zwischen 14 und 25 Jahren, als „Trostfrauen“ ("ian-fu") in Militärbordelle. Etwa 100.000 davon stammten aus der japanischen Kolonie Korea. Dazu kamen Mädchen und Frauen aus China, Indonesien, Malaysia, Philippinen, Australien und auch aus Japan. Die Frauen und Mädchen mussten Tag für Tag etwa 30 bis 40 Soldaten zu Diensten sein. Bis zum Kriegsende starben etwa 70 Prozent dieser Frauen an Krankheiten, Folter oder Hunger. Noch in den letzten Kriegswochen wurden Tausende der „Trostfrauen“ ermordet. Die Gesamtzahl der Zivilisten, die von Japanern im Zusammenhang mit ihrer kriegerischen "Lebensraum"-Politik getötet wurden, wird auf sechs bis mehr als 14 Millionen Menschen geschätzt.

Nach dem Ende des Zweiten Weltkrieges wurden 24 Deutsche im Nürnberger Prozess gegen die Hauptkriegsverbrecher angeklagt, davon zwölf zum Tod durch den Strang verurteilt, zwei wurden freigesprochen. In zwölf Nachfolgeprozessen wurden 185 Personen aus der nationalsozialistischen Führung, Ärzte, Juristen und führende Personen aus der Wirtschaft und Offiziere aus dem Oberkommando der Wehrmacht angeklagt, davon 24 zum Tod durch den Strang verurteilt (wovon zwölf in Haftstrafen gemildert wurden), 35 wurden freigesprochen. Erstmals in der Geschichte mussten sich Politiker, Militärs und andere Verantwortungsträger persönlich für das Planen und Führen eines Angriffskrieges und für Verbrechen gegen die Menschlichkeit verantworten. In der Nachkriegszeit von vielen deutschen Politikern als Siegerjustiz kritisiert, gelten diese Prozesse heute als Grundlage für das moderne Völkerstrafrecht. In weiteren 745 Kriegsverbrecherprozessen, unter anderen in Hamburg, Dachau und Rastatt, wurden mindestens 677 Todesurteile ausgesprochen, von denen 212 in Haftstrafen umgewandelt wurden. Die Mehrheit der Kriegsverbrecher aus SS und Wehrmacht wurde nie vor Gericht gestellt.

Japanische Hauptkriegsverbrecher wurden in den Tokioter Prozessen vom "International Military Tribunal for the Far East" abgeurteilt. Diese Prozesse endeten mit sieben Todesurteilen, 16 lebenslangen und zwei langjährigen Haftstrafen. In weiteren Prozessen wurden 984 Todesurteile gefällt und in 920 Fällen vollstreckt, 3716 Personen wurden zu Gefängnisstrafen verurteilt und 1000 für nicht schuldig befunden.

Die Entrechtung und Verfolgung der jüdischen Minderheit war ein immanenter Bestandteil der nationalsozialistischen Politik. In zeitlicher Übereinstimmung mit der Ausweitung des Krieges durch den Überfall auf die Sowjetunion radikalisierte sich die Haltung gegenüber der Minderheit zur Vernichtungspolitik. Im von der Wehrmacht geschützten Hinterland im Osten führten die Einsatzgruppen der Sicherheitspolizei und des SD, Polizeireserveeinheiten und Wehrmachteinheiten unter dem Vorwand der Partisanenbekämpfung Massentötungen von Juden durch. Am 18. Dezember 1941 notierte Himmler in seinem Dienstkalender, Hitler habe auf sein Nachfragen das bisherige Vorgehen der Einsatzgruppen bestätigt und befohlen: „Judenfrage / als Partisanen auszurotten“.

Der „Kommissarbefehl“ vom 6. Juni 1941 veranlasste Wehrmachteinheiten und Einsatzgruppen zur Tötung von etwa 5000 kriegsgefangenen Rotarmisten mit tatsächlicher oder angenommener politischer Funktion. In einem Befehl Heydrichs an die Einsatzgruppen (17. Juli 1941) wurden Juden automatisch mit Politkommissaren gleichgesetzt. Bis Dezember 1941 wurden von Einsatzgruppen und Soldaten der Wehrmacht gemäß Partisanen- und Kommissarbefehl ungefähr eine halbe Million Menschen ermordet, fast 99 Prozent davon waren Juden. An vielen Orten unterstützten Wehrmachteinheiten logistisch die Einsatzgruppen. Schon vor Beginn des Feldzuges im Osten gab es Anweisungen, in denen „rücksichtsloses und energisches Durchgreifen besonders gegen bolschewistische Hetzer, Freischärler, Saboteure und Juden“ gefordert wurde. Die Wirklichkeit des Krieges ging noch darüber hinaus, als in den rückwärtigen Heeresgebieten oft ganze Dörfer niedergebrannt und alle Einwohner rücksichtslos erschossen wurden, wenn sie bloß im Verdacht standen, Partisanen Unterschlupf und Essen gewährt zu haben, während die Partisanen selbst rechtzeitig wieder in Wäldern verschwunden waren.
Ende 1941/Anfang 1942 entstanden sechs Vernichtungslager im besetzten Polen (Kulmhof, Belzec, Sobibor, Majdanek, Treblinka, Auschwitz-Birkenau). In Birkenau (Auschwitz II) wurde ein neues Tötungsmittel verwendet, das von den Ärzten im Euthanasieprogramm bereits im kleineren Umfang erprobt worden war: kristallisierte Blausäure (Zyklon B). Ende 1942 lebten von 2,3 Millionen Juden im Generalgouvernement keine 300.000 mehr. In einigen Ländern (beispielsweise in Dänemark, wo es zur Rettung der dänischen Juden kam), widersetzten sich die Regierung und/oder die Bevölkerung der Deportation und Ermordung ihrer jüdischen Mitbürger.

Etwa 200.000 Deutsche, die meisten davon Angehörige der Einsatzgruppen und anderer SS-Formationen, waren an den Massenmorden beteiligt. Spätestens im Sommer 1943 hat die große Mehrheit der Deutschen zumindest damit gerechnet, dass die im NS-Herrschaftsbereich lebenden Juden umgebracht werden sollten. Viele hatten Kenntnis von Massenmorden in Osteuropa.

Mindestens 13 Millionen (wahrscheinlich etwa 15 Millionen) Zivilisten wurden von Einsatzgruppen, SS-Angehörigen, Ordnungspolizei, Soldaten der Waffen-SS, Wehrmacht und verbündeten Truppen der Achsenmächte, wie zum Beispiel von der kroatischen Ustascha, ermordet. Die meisten Massenmorde fanden im Rücken der Ostfront auf sowjetischem Gebiet und in Ostpolen statt (mindestens zwölf Millionen). Von den etwa 15 Millionen in Europa ermordeten Zivilisten waren mehr als 6,2 Millionen jüdischer Abstammung, ferner mindestens 220.000 Sinti und Roma, etwa 275.000 „Euthanasie“-Opfer sowie Homosexuelle, Zeugen Jehovas und Freimaurer. An der Ermordung von Geisteskranken waren auch Ärzte beteiligt. Im Generalgouvernement, in den besetzten sowjetischen Gebieten, in Jugoslawien und in Frankreich wurden ungezählte Partisanen nicht nach dem Kriegsvölkerrecht behandelt. In allen besetzten Ländern gab es darüber hinaus zahlreiche Geiselerschießungen.

Die Befreiung des KZ Auschwitz durch sowjetische Soldaten am 27. Januar 1945 ist in der Bundesrepublik seit 1996 offizieller „Tag des Gedenkens an die Opfer des Nationalsozialismus“; auch international wird seit 2005 dieses Datums gedacht. In den USA gibt es seit 1980 die "Days of Remembrance", die eine Woche dauern. In Israel ist Jom haScho’a („Tag des Gedenkens an Shoa und Heldentum“) ein ernster Nationalfeiertag.

In Europa ermordete Juden (Zahlen in 1000, auf- oder abgerundet):

Von allen beteiligten Staaten hatte die Sowjetunion die meisten zivilen Opfer zu beklagen. Am Beispiel von Leningrad lassen sich die Ausmaße des millionenfachen Hungertodes exemplarisch verdeutlichen: Nachdem die Stadt Anfang September 1941 von deutschen Truppen eingekesselt worden war, konnte die Bevölkerung nicht mehr ausreichend versorgt werden. Während der Leningrader Blockade waren bereits bis zum Sommer 1942 ungefähr 470.000 Menschen gestorben. Die hungernden Menschen alterten so rasch, dass selbst nahe Verwandte sie nicht mehr erkannten. Zuerst wurden Tauben und Möwen, danach Katzen und Hunde verzehrt. (Nicht einmal Pawlows berühmte Versuchshunde im Physiologischen Institut blieben verschont.). Die Schätzungen der Gesamtopferzahl reichen von 700.000 bis 1.100.000 Menschen bis zum Ende der Blockade am 27. Januar 1944.

In anderen von deutschen Truppen besetzten Ländern Ost- und Südosteuropas (Polen, Serbien, Griechenland) musste die einheimische Bevölkerung ebenfalls einen sehr hohen Blutzoll zahlen, weil dort, vor allem in Polen, ebenso „ein Vernichtungskrieg geführt wurde“ Dazu kamen in Serbien und Griechenland Geiselerschießungen nach tatsächlichen oder vermuteten Partisanenaktionen.

In den besetzten Ländern Nord- und Westeuropas (Norwegen, Dänemark, Niederlande, Belgien, Luxemburg, Nord- und Westfrankreich, britische Kanalinseln) lag dem Deutschen Reich aus politischen wie militärischen Gründen viel daran, sich als „korrekte Besatzungsmacht“ zu präsentieren, sicherte es doch die Disziplin der Truppe und sparte Ressourcen. Aber auch dort wurden Menschen, die als „rassisch minderwertig“ eingestuft wurden, und all jene, die das Besatzungsregime als widerständig einschätzte, zu keiner Zeit „korrekt“ behandelt. Da im Zweiten Weltkrieg weltweit kein Soldat so üppig bezahlt wurde wie der deutsche, kauften sie „die Länder Europas buchstäblich leer“. Sie verschickten Abermillionen Feldpostpäckchen von der Front in die Heimat. „Schuhe aus Nordafrika, aus Frankreich Samt und Seide, Likör und Kaffee, Tabak aus Griechenland, Honig und Speck aus Russland, Heringe en masse aus Norwegen.“ Die Adressaten waren hauptsächlich Frauen. Im besetzten Teil Frankreichs bekamen die deutschen Soldaten den Beinamen « doryphores » („Kartoffelkäfer“), die alles kahl fressen. Die Kaufkraft der deutschen Soldaten wurde dadurch gestärkt, dass der für die Reichsmark günstige Wechselkurs in Berlin festgesetzt wurde. „Jetzt bekommt man auch wieder allerhand für unser Geld zu kaufen“, schrieb ein Soldat. Die Besatzungsmacht transportierte Lebensmittel, Konsumgüter und Industrieprodukte nach Deutschland, „um auf diese Weise die Deutschen im Reich zu ernähren und bei Laune zu halten.“ Als Folge stiegen in den deutsch besetzten Ländern die Preise; nach und nach wurde fast alles rationiert. Der Schwarzmarkt blühte auf. Einzelne Sparten und Personen verdienten gut an den Deutschen. Renault konnte durch das Motorisierungsprogramm der Wehrmacht seinen Umsatz bis 1942 verfünffachen. Auch viele Baufirmen machten in großem Stil Umsatz und Gewinn, indem sie für die Besatzungsmacht Baracken, Straßen, Flugplätze und anderes bauten.

Für die deutsche Zivilbevölkerung hatte der Krieg zunächst keine direkten negativen Konsequenzen. Obwohl im weiteren Verlauf fast alle Waren des täglichen Bedarfs mit Lebensmittelkarten oder Bezugsscheinen rationiert wurden, gab es in den ersten Kriegsjahren keine mangelnde Versorgung mit Gütern. Das lag vor allem daran, dass meist zu Ungunsten der dortigen Bevölkerung viele Erzeugnisse und Rohstoffe aus den besetzten Ländern ins Reichsgebiet transferiert wurden. Zu den Begünstigten zählten 95 Prozent der Deutschen. Sie empfanden den Nationalsozialismus nicht als System der Unfreiheit und des Terrors, sondern als Regime der sozialen Wärme, als eine Art „Wohlfühl-Diktatur.“ Hierzu gehörte auch, dass der Sport nach einer kurzen Pause zu Kriegsbeginn weiterging und z. B. die deutsche Fußballmeisterschaft 1943/44 komplett stattfinden konnte. Erst im Spätjahr 1944 musste der meiste Sport abgesagt werden. Unmittelbare Auswirkungen für die deutsche Zivilbevölkerung gab es mit den zunehmenden alliierten Luftangriffen auf deutsche Städte ab Anfang 1942 und der „Totalisierung“ der Kriegführung im Jahr darauf.

Die Arbeitskraft der zur Wehrmacht einberufenen Männer wurde durch Kriegsgefangene und Zwangsarbeiter aus West- und Osteuropa teilweise ersetzt. Allein von April bis Dezember 1942 wurden ungefähr 1,3 Millionen zivile Arbeitskräfte, je zur Hälfte Männer und Frauen mit einem Durchschnittsalter von etwa 20 Jahren, nach Deutschland geholt. Hinzu kamen 1942 noch 450.000 sowjetische Kriegsgefangene. Der größte Teil dieser Zivilarbeiter und Kriegsgefangenen wurde in der Industrie eingesetzt. Als seit dem Spätherbst vermehrt Rüstungsarbeiter zum Kriegsdienst eingezogen wurden, fehlten im ersten Halbjahr 1943 der deutschen Kriegswirtschaft 1,5 Millionen Arbeitskräfte, was sich durch die vermehrte Dienstverpflichtung von Frauen nicht ausgleichen ließ. Zwischen Anfang 1943 und dem Kriegsende wurden weitere 2,5 Millionen Zivilarbeiter und Kriegsgefangene nach Deutschland gebracht. Im August 1944 arbeiteten mehr als sieben Millionen „Fremdarbeiter/innen“ in Deutschland, zumeist gegen ihren Willen und unter zunehmend brutaleren Bedingungen. Anfang 1945 war ein Viertel aller Beschäftigten in der deutschen Wirtschaft ausländischer Herkunft. Nur durch deren Einsatz und den von Kriegsgefangenen war es dem Deutschen Reich möglich, den Krieg weiterzuführen, der ohne ihn spätestens im Frühjahr 1942 verloren gewesen wäre. Der Ausländereinsatz in der Landwirtschaft ermöglichte es außerdem, die Versorgungslage der deutschen Bevölkerung bis in die letzte Kriegsphase auf hohem Niveau zu halten, was für die Loyalität der Bevölkerung gegenüber dem Regime ausschlaggebend gewesen ist.

Ab Oktober 1944 wurde der Volkssturm, das heißt „alle waffenfähigen Männer im Alter von 16 bis 60 Jahren“, zum Dienst an der Front einberufen. Der Kulturbetrieb wurde während des gesamten Krieges aufrechterhalten, insbesondere Filme wie „Die Feuerzangenbowle“ dienten der Zerstreuung und Ablenkung vom Kriegsalltag. Aber Kriegsmüdigkeit, Überarbeitung und Erschöpfung sowie das Gefühl, dass man den Ereignissen hilflos ausgesetzt sei, ließen im Herbst 1944 die Abneigung gegen das NS-Regime stärker werden. Auch Hitler selbst geriet dabei in die Kritik, weil er derartiges Leid heraufbeschworen habe. Ein äußerliches Zeichen hierfür war, dass der Gruß „Heil Hitler“ jetzt verschwand. Für die Zivilbevölkerung im Osten des Reiches erreichten die Kriegseinwirkungen ihren Höhepunkt mit dem Einmarsch und der Besetzung durch die Rote Armee. Im Westen wurde der Einmarsch der britischen und US-amerikanischen Truppen von der deutschen Bevölkerung überwiegend mit Erleichterung zur Kenntnis genommen.

Im Zweiten Weltkrieg wurden in Europa ca. 20 Milliarden Kriegsflugblätter hinter den feindlichen Linien abgeworfen, und es ist anzunehmen, dass die Mehrzahl der Bewohner der am Krieg beteiligten Länder von den Flugblattinhalten erreicht wurden.

Schon vor dem Zweiten Weltkrieg waren in der Wehrmacht Propagandakompanien aufgestellt worden, die die deutsche Bevölkerung im Sinne des NS-Regimes positiv auf die Kriegsereignisse einstimmen sollten. Kriegsberichterstattung per Radio und Wochenschau dienten der Information, der NS-Propaganda und anderen Zwecken (z. B. Glaube an den Endsieg; siehe auch ). Die Deutsche Wochenschau berichtete vor dem Hauptfilm positiv vom Fortgang des Krieges. Leni Riefenstahl folgte mit einem „Sonderfilmtrupp“ den Truppen in Polen. Elend und Leid, Sterben und Tod wurden in allen Medien weitgehend ausgeblendet. Die Volksgenossen lasen die gleichen Zeitungen, sahen die gleichen Wochenschauen, hörten die gleichen Wehrmachtberichte. Es war eine Mixtur aus Dokumentation und Unterhaltung; auch die echten Kriegsbilder vermittelten falsche Kriegs-Bilder.

Während des Krieges beschwor Goebbels in den gleichgeschalteten Medien den bevorstehenden Endsieg und glorifizierte die Erfolge der Wehrmacht, indem er zukünftige Positionen des deutschen Heeres als schon teilweise erreicht darstellte. Auch sagte er die Einnahme von Städten voraus, die wenige Tage später tatsächlich eingenommen wurden. Des Weiteren verhöhnte Goebbels Gegner Deutschlands: Er charakterisierte beispielsweise Winston Churchill als „Trunkenbold“ und eiferte damit Hitler nach; in öffentlichen Reden wiederholte er gern dessen Charakterisierungen von Churchill als „Schwätzer“ oder „verlogenes Subjekt“ oder „Faulpelz ersten Ranges“.

Die NS-Führung rechtfertigte den Feldzug gegen die Sowjetunion mit der „Verteidigung des Abendlandes gegen den Bolschewismus“ und gegen die „jüdisch-bolschewistischen Untermenschen“. Den Soldaten der (neuen) Ostfront wurde der Angriff am frühen Morgen des 22. Juni in einer von Offizieren verlesenen Proklamation als „die Sicherung Europas und damit die Rettung aller“ erklärt. Die SS ließ 1942 die Broschüre "Der Untermensch" publizieren, die mit Hetzartikeln und fratzenhaften Bildern die Russen als rassisch minderwertig darstellte.

Die Auslandsillustrierte "Signal" erschien 1940 bis 1945, erreichte eine maximale Auflage von 2,5 Millionen Exemplaren und wurde zeitweise in 20 Sprachen gedruckt. Sie hatte acht Farbseiten und warb für eine „Neue Ordnung“ in Europa mit dem angeblichen Ziel der "Abwehr gegen den Bolschewismus". Die Pariser Zeitung (1941–1944), mit einer deutschen und einer französischen Ausgabe, veröffentlichte auch Beiträge bekannter französischer Persönlichkeiten wie Alphonse de Châteaubriant, Georges Oltramare und Lucien Rebatet und versuchte darüber hinaus, prodeutsche Sympathien vornehmlich über die kulturelle Ausstrahlung Deutschlands zu verbreiten. Daneben gab es viele weitere Publikationen, die im Ausland die deutsche Perspektive verbreiteten.

Im August 1942 äußerte Goebbels in einer Propaganda-Anweisung die Besorgnis, „dass sich das deutsche Volk zur Zeit in weiten Kreisen in dem Glauben wiegt, die militärischen Ereignisse im Osten […] würden zu einem baldigen Kriegsende führen“. Erst nach der Niederlage in Stalingrad (Ende Januar 1943) kann von einer „Talsohle der Stimmungslage“ in der deutschen Bevölkerung gesprochen werden. Am 18. Februar 1943 rief Goebbels die deutsche Bevölkerung in der Sportpalastrede zum "totalen Krieg" auf. Doch trotz zunächst positiver Reaktionen in der Bevölkerung erreichte sie ihren Zweck, die personellen und materiellen Ressourcen zu mobilisieren, nur begrenzt; ihre Wirkung ließ schnell nach. Im weiteren Verlauf forderte die NS-Propaganda den Widerstandswillen der Bevölkerung „bis zum Endsieg“, gegen den „angloamerikanischen Bombenterror“ und die „rasende Rachsucht“ der Roten Armee immer stärker, je näher die Alliierten auf die Reichsgrenzen vorrückten.

Auch in Großbritannien wurde Propaganda gegen den Kriegsgegner gemacht. 1940 gelang es Churchill in mehreren berühmten Reden, darunter der „Blut-Schweiß-und-Tränen-Rede“ und ihrer Fortsetzung "(We Shall Fight on the Beaches)", das Einverständnis der britischen Bevölkerung für Krieg und Widerstand gegen Deutschland zu gewinnen. Folglich ließ er auch das sogenannte Friedensangebot, den „Appell an die Vernunft, auch in England“, den Hitler in seiner Reichstagsrede vom 19. Juli 1940 an Großbritannien richtete, innerhalb einer Stunde zurückweisen.

Die USA stellten nach dem japanischen Überfall auf Pearl Harbor und der deutschen Kriegserklärung im Dezember 1941 die doppelte Bedrohung aus West und Ost heraus, sozusagen die Gefahr des Zweifrontenkrieges aus US-Sicht. 1942 brachten sie eine Illustrierte mit dem Namen "Victory" (analog zur deutschen Illustrierten "Signal") heraus.

Der Zweite Weltkrieg begann in Europa mit einem fingierten, angeblich polnischen Überfall auf den Sender Gleiwitz am Abend des 31. August 1939. Die deutsche Bevölkerung wurde am nächsten Tag stündlich durch Rundfunksondermeldungen unterrichtet, dass der "Führer" der Wehrmacht befohlen habe, in Polen einzumarschieren. So, wie er mit einer Lüge im Rundfunk begonnen hatte, endete er auch mit einer Lüge im Rundfunk: Am 1. Mai 1945, abends, gab Dönitz über den Hamburger "Deutschlandsender" Hitlers Tod bekannt. Dieser habe ihn „an der Spitze seiner Truppen“ ereilt.

Der deutsche Wehrmachtbericht wurde im Großdeutschen Rundfunk täglich um die Mittagszeit vor den folgenden Nachrichten ausgestrahlt. Hinzu kamen die im Radio mit Fanfarenstößen eingeleiteten Sondermeldungen über herausragende Erfolge. Wehrmachtberichte erwähnten auch Kampfhandlungen der feindlichen Streitkräfte, beispielsweise die Luftangriffe der Alliierten auf Kriegsziele und Städte im Reichsgebiet. Sie besaßen amtlichen Charakter und waren die maßgebliche Quelle für die Kommentierung des Kriegsgeschehens in den Medien. Die 2080 gesendeten Wehrmachtberichte sind, so der Archivar Erich Murawski 1962, ein Gemisch aus nüchternem Militär-Rapport und politischer Propaganda und gelten Historikern daher als ebenso wertvolle wie fragwürdige Sekundärquelle. Berichtet wurde in knapper Form; ausführlicher und teilweise übertrieben, wenn Erfolge zu vermelden waren. Sie vermieden weitgehend direkte Falschmeldungen, operierten aber mit Auslassungen, tendenziösen Hervorhebungen, Verharmlosungen sowie mit Beschönigungen und Verschleierungen. Aktuelle Untersuchungen betonen stärker den propagandistischen Charakter des Wehrmachtberichts. Der deutsche Militärhistoriker Jörg Echternkamp nennt die Praxis der Darstellung der „beschönigende[n] ‚Frontbegradigung‘ im Wehrmachtbericht“ in einer Reihe mit propagandistischen Verlautbarungen, die über den „wahren Sachverhalt“ des Kriegsverlaufs „hinwegtäuschen“.

Im Krieg in Ostasien setzten auch die Japaner ab 1943 verstärkt auf Rundfunkpropaganda gegen die Amerikaner, indem sie über Radio Tokyo die Sendung „The Zero Hour“ ausstrahlten. Für die überwiegend weiblichen Moderatoren, die Amerikanisch mit einem japanischen Akzent sprachen, bürgerte sich im GI-Sprachgebrauch der Begriff Tokyo Rose ein.

Die Mehrheit der deutschen Bevölkerung stand dem Kriegsbeginn zunächst skeptisch gegenüber, ließ sich dann von den folgenden Siegesmeldungen blenden. Aus Angst vor Strafen wagten nur wenige Menschen, sich aktiv gegen den Krieg auszusprechen. Zentren des zivilen Widerstands waren die „Weiße Rose“, der „Kreisauer Kreis“ und die „Rote Kapelle“.

Wenngleich die Wehrmacht prinzipiell hinter Hitlers Ideen stand und seine Kriegführung mittrug, sahen ab 1943 einige Generäle die zwangsläufige Niederlage deutlich vor Augen und setzten daher auf einen Waffenstillstand, um der Wehrmacht und der deutschen Bevölkerung Zeit zur Umgruppierung des Heeres und Neuorganisation des Staates zu geben. Am 20. Juli 1944 verübten einige Widerständler ein Attentat auf Hitler im Führerhauptquartier „Wolfsschanze“. Der Versuch, Hitler zu töten, misslang aber ebenso wie der anschließende Versuch eines Staatsstreichs in Berlin (→ Operation Walküre). Die Attentäter wurden hingerichtet. Einige wenige Soldaten lehnten den Krieg auch aus ideologischen Gründen ab und versuchten, ihn durch Sabotagemaßnahmen zu verkürzen. Die weit überwiegende Mehrheit kämpfte bis zum Schluss weiter. Zahlreiche deutsche Soldaten und Hilfsverbände (u. a. Polizeireserve) beteiligten sich an Kriegsverbrechen, was Widerstand der Bevölkerung in den besetzten Gebieten provozierte oder begünstigte.

In Dänemark (→ Dänischer Widerstand) empfand die Bevölkerung die deutsche Besatzung nach den Worten des Königs als „Alpdruck“. In den Niederlanden entwaffneten die Deutschen die dortige Polizei, weil sie einen Aufstand befürchteten. Der pro-deutschen Bewegung des Vidkun Quisling in Norwegen folgte keine Massenbewegung der Bevölkerung, die Mehrheit lehnte die deutsche Besatzung ab. Die schärfsten Formen des westeuropäischen Widerstands gab es in Frankreich, wo die Résistance, auch Maquis (nach dem mediterranen Buschgestrüpp „maquis“) genannt, gegen die deutsche Besatzung kämpfte.

Stärker waren Widerstandsbewegungen in Südost- und Osteuropa: In der Sowjetunion, in Griechenland (→ELAS), in Albanien und in Jugoslawien (→ Marschall Tito) kämpften große Partisanenarmeen. Die polnische „Heimatarmee“ konnte nur auf wenig Unterstützung von außen hoffen. Aus dem ständigen Kleinkrieg gegen die deutschen Besatzer gingen die Partisanen häufig als Sieger hervor. Gegen Ende des Krieges konnten größere Gebiete von den deutschen Besatzern befreit werden, so etwa in Jugoslawien, wo Tito im Anschluss die Macht übernahm, oder in Griechenland, wo die Hegemonie der ELAS mit britischen Interessen kollidierte und zum Griechischen Bürgerkrieg führte.

Mit der Unterzeichnung des Antikominternpaktes zwischen Deutschland und Japan wurde bereits 1936 der Grundstein für die spätere "Achse Deutschland–Japan–Italien" gelegt. Nach dem Hitler-Stalin-Pakt verschlechterte sich das Verhältnis zu Japan zunächst, aber weil sich Japan Zugriff auf die französischen, niederländischen und britischen Kolonien in Asien erhoffte, ging es Ende September 1940 mit Deutschland und Italien den "Dreimächtepakt" ein, dem fünf südosteuropäische Staaten beitraten. Die Initiative dazu ergriff Japan schon im Juni 1940; aber erst, nachdem Hitler klar geworden war, dass es nicht gelingen würde, Großbritannien durch eine Invasion militärisch auszuschalten, war dieser bereit, ein Bündnis mit Japan abzuschließen. Mit diesem verpflichteten sich die drei Partner, sich gegenseitig zu unterstützen, falls einer der Partner von einer Macht angegriffen werden würde, „die gegenwärtig nicht in den europäischen Krieg oder in den chinesisch-japanischen Konflikt verwickelt ist.“ Da der Vertrag „in keiner Weise den politischen Status berühren“ sollte, „der gegenwärtig zwischen den drei vertragschließenden Teilen und Sowjetrußland besteht“, wurde deutlich, dass der Vertrag vorwiegend die USA von einem Kriegseintritt abhalten sollte.

Großbritannien konnte im Herbst 1940 in der Luftschlacht um England eine deutsche Invasion verhindern und vertraute auf wirtschaftliche und militärische Unterstützung durch die USA. Insbesondere der amerikanische Präsident Franklin D. Roosevelt wollte aus machtpolitischen und weltanschaulichen Gründen die USA zum „Arsenal der Demokratie“ gegen das nationalsozialistische Deutschland machen. Großbritannien erhielt 1941 aufgrund des „Zerstörer-für-Stützpunkte-Abkommens“ 50 Zerstörer zur Abwehr deutscher U-Boote. Im August 1941 trafen sich Churchill und Roosevelt auf einem britischen Kriegsschiff in der Argentia-Bucht (Neufundland) und verkündeten die Atlantik-Charta: Ablehnung aller territorialen Veränderungen ohne Zustimmung der betroffenen Völker und Recht aller Völker auf diejenige Regierungsform, unter der sie leben wollen. Nach dem japanischen Angriff auf Pearl Harbor am 7. Dezember 1941 erklärten die USA Japan den Krieg. Deutschland und Italien erklärten daraufhin den USA den Krieg, ohne dazu vertragsrechtlich verpflichtet zu sein ("s. o."). Der europäische und der ostasiatische Krieg waren zum Weltkrieg geworden.

Auf der Arcadia-Konferenz (Dezember 1941/Januar 1942 in Washington) vereinbarten Churchill und Roosevelt als wichtigsten Beschluss, zuerst die deutsche Gefahr auszuschalten: „Germany first“. In Casablanca (Januar 1943) einigten sie sich darauf, zuerst den Krieg in Nordafrika mit der Eroberung Tunesiens im Sommer 1943 zu Ende zu bringen und weiter auf Sizilien und in Süditalien fortzusetzen. Die Invasion Westeuropas wurde auf 1944 verschoben. Während der Quadrant-Konferenz in Québec (August 1943) wurde die Operation Overlord (Invasion in der Normandie) beschlossen und General Frederick E. Morgan beauftragt, einen detaillierten Plan zu entwerfen. In Kairo (November 1943) vereinbarten Roosevelt, Churchill und Chiang Kai-shek, den Krieg in Ostasien bis zur bedingungslosen Kapitulation Japans fortzusetzen. Auf der Moskauer Außenminister-Konferenz (19. Oktober bis 1. November 1943) koordinierten Hull, Eden und Molotow die weitere Zusammenarbeit, erörterten den Eintritt der UdSSR in den Krieg gegen Japan und formulierten unter anderen die Moskauer Deklaration: Entmilitarisierung, Entnazifizierung, Demokratisierung und Dezentralisierung Deutschlands. Gegenstand der Teheran-Konferenz (28. November bis 1. Dezember 1943) war die Absprache zwischen Roosevelt, Churchill und Stalin über die weitere Vorgehensweise auf dem europäischen Kriegsschauplatz im Jahr 1944 und die Zeit nach einem Sieg der Alliierten über Deutschland. In Jalta (Februar 1945) wurde Deutschland in vier Besatzungszonen aufgeteilt. Für Ostmitteleuropa und den Balkan wurden Einflusszonen verabredet. Stalin versprach, dass die Sowjetunion zwei Monate nach der deutschen Kapitulation in den Krieg gegen Japan eintreten werde. Auf der Potsdamer Konferenz sollten die Grenzziehungen in Europa und die deutschen Reparationsleistungen, die Verwaltung des besetzten Deutschlands sowie der noch andauernde Pazifikkrieg besprochen werden.

Während des Zweiten Weltkrieges wurden Schätzungen zufolge über 65 Millionen Menschen getötet. Es kamen mehr Zivilisten um als Soldaten bei Kampfhandlungen. Am stärksten betroffen war die Sowjetunion mit etwa 27 Millionen getöteten Menschen, davon ungefähr die Hälfte als Soldaten, von denen drei Millionen in deutscher Kriegsgefangenschaft starben. In den sowjetischen Opferzahlen sind die etwa 650.000 getöteten Soldaten der 1939/40 von der UdSSR annektierten baltischen Staaten enthalten.

Grundsätzlich gilt, dass Zahlenangaben zu den Toten des Weltkriegs oft methodisch nicht gesicherte Schätzwerte darstellen, die in der Literatur unterschiedlich angegeben werden. Die folgende Tabelle basiert, sofern nicht in gesonderten Einzelnachweisen angegeben, auf Daten aus dem zehnten Band der vom Militärgeschichtlichen Forschungsamt herausgegebenen Reihe Das Deutsche Reich und der Zweite Weltkrieg 2008. Darin sind neutrale Staaten und Kolonien nicht berücksichtigt. Die wiedergegebenen Schätzungen gehen meist auf offizielle Angaben der jeweiligen Regierungen zurück. Die Zahl der Kriegstoten der in der Tabelle genannten Staaten ergibt eine Summe von mindestens 65 Millionen, darunter mehr als die Hälfte Zivilisten.

Insgesamt sind von den 5,7 Millionen Kriegsgefangenen der Roten Armee 3,3 Millionen ums Leben gekommen, die meisten von ihnen verhungert, aber auch Krankheiten, Misshandlungen, Erschießungen oder der Haft in einem "Sonderlager" zum Opfer gefallen. Dies bedeutet, dass 58 % der sowjetischen Kriegsgefangenen in deutscher Gefangenschaft starben. Die Zahl der in deutschem Gewahrsam zu Tode gekommenen westalliierten Kriegsgefangenen war im Verhältnis deutlich geringer. So starben von 1,8 Millionen in deutsche Kriegsgefangenschaft geratenen französischen Soldaten knapp 50.000, das sind 2,8 %. Von den 3,1 Millionen deutschen Kriegsgefangenen in sowjetischem Gewahrsam kamen 1,1 Millionen (35 %) um. China, wo der Krieg schon Mitte 1937 mit der japanischen Aggression begann, hatte mit ungefähr 14 Millionen im Krieg getöteten Menschen die zweithöchste Anzahl an Todesopfern zu beklagen. Aber auch in Indien verhungerten 1943 und 1944 mehr als zwei Millionen Zivilisten, davon die allermeisten in Bengalen, nachdem die Reisimporte aus dem japanisch besetzten Birma ausblieben.

Zu den vielen Verwundeten müssen auch zahlreiche als Deserteure verurteilte Soldaten hinzugezählt werden, die depressiv oder geisteskrank und deshalb unfähig zum Militärdienst waren, und dennoch verurteilt wurden, um die „Moral der Truppe aufrecht“ zu erhalten. Das geschah nicht nur in Deutschland, sondern auch in anderen kriegsbeteiligten Staaten.

Es gab viele tote Zivilisten durch Bombardierungen von Großstädten wie Chongqing, Warschau, Coventry, London, Köln, Düsseldorf, Hamburg, Tokio, Dresden und im Ruhrgebiet. Sehr viele Zivilisten kamen bei den Schlachten um Stalingrad, Breslau, Königsberg, während der Leningrader Blockade und der Aushungerung von Charkow ums Leben. Die Versenkung der Flüchtlingsschiffe "Armenija", "Wilhelm Gustloff", "Goya", "Steuben" und "Cap Arcona" forderte Zehntausende Opfer. Im harten Winter 1944/45, in Straflagern der Sowjetunion und bei gewaltsamen Vertreibungen von Menschen nach dem Krieg starben weitere, ungezählte Menschen (zum Beispiel Sudetendeutsche infolge der Beneš-Dekrete).

Vielen Menschen war es nicht möglich, aus dem nationalsozialistischen Herrschaftsbereich zu fliehen, weil Staaten (wie die USA oder die Schweiz) zeitweise die Grenzen schlossen und (auch jüdischen) Flüchtlingen kein Asyl gewährten.

Die beiden Atombombenabwürfe auf Hiroshima und Nagasaki töteten direkt und indirekt bis Ende 1945 mehr als 230.000 Menschen.

Insgesamt gerieten 11 Millionen Angehörige der Wehrmacht und der Waffen-SS in Kriegsgefangenschaft, davon 7,7 Millionen auf Seiten der Westmächte und 3,3 Millionen auf Seiten der UdSSR.

Zur Zwangsarbeit unter dem NS-Regime wurden zwischen sieben und elf Millionen Menschen fast überall im Deutschen Reich und den besetzten Gebieten eingesetzt. Zum Teil arbeiteten sie in Fabriken neben KZ-Häftlingen unter ähnlich menschenunwürdigen Bedingungen, zum kleineren Teil glichen die Lebensbedingungen denen der Arbeit gebenden Handwerker- und Bauernfamilien. Der für sie als oberster Verantwortlicher ernannte Gauleiter Fritz Sauckel wurde 1946 im Rahmen der Nürnberger Prozesse zum Tode verurteilt und hingerichtet. Nach Kriegsende wurden deutsche Kriegsgefangene ebenfalls als Bestandteil der Reparationsleistungen zu Zwangsarbeit verpflichtet, vor allem in der Sowjetunion (bis 1956), aber auch in Westeuropa (→ Deutsche Zwangsarbeiter nach 1945).

Nach Kriegsende gab es in Europa 6,5–12 Millionen als „Displaced Persons“ bezeichnete Personen, bei denen es sich in der Mehrzahl um befreite Kriegsgefangene, Zwangsarbeiter aus ehemals besetzten Staaten und KZ-Häftlinge handelte. Diese wurden bis zu ihrer Repatriierung oder Aufnahme in Drittstaaten in sogenannten DP-Lagern untergebracht.

Auch die materiellen Schäden waren enorm. In Deutschland verloren etwa vier Millionen Menschen ihre Wohnung und es mussten 400 Millionen Kubikmeter Schutt weggeräumt werden. In Köln, wo vor dem Krieg 750.000 Menschen gelebt hatten, waren es nur noch 40.000. Die „Trümmerfrauen“ wurden zu einem Symbol des Aufräumens und des Wiederaufbaus. In Frankreich wurden zwei, in Japan drei und in der Sowjetunion sechs Millionen Wohnungen zerstört. Fast die Hälfte der Eisenbahnschienen war beschädigt: in Deutschland 34.000 km, in Japan 50.000 km, in Frankreich 37.000 km.

Die späteren Siegermächte gingen im Abschlussprotokoll von Jalta davon aus, dass die Deutschen einen Schaden von 20 Milliarden Dollar in Europa angerichtet hätten. Bezogen auf das jährliche Sozialprodukt lag der Schaden in Deutschland (4,8 Mrd. Dollar) bei 140 Prozent, in Frankreich (2,1 Mrd. Dollar) bei 130 Prozent, in Polen (2 Mrd. Dollar) bei 300 Prozent und in der UdSSR (12,8 Mrd. Dollar) bei 250 Prozent. Die Sowjetunion sollte deswegen Reparationen im Wert von 10 Milliarden Dollar erhalten.

1942 betrugen Deutschlands Ausgaben für die Kriegführung 140 Mrd. RM (heute:  Mrd. EUR). Dem standen nur Reichseinnahmen in Höhe von 69 Mrd. RM (heute:  Mrd. EUR) gegenüber. Der Rest wurde durch neue Schuldverschreibungen finanziert. Die Kriegskosten des Deutschen Reiches (z. B. Wehrsold für Millionen Soldaten, Produktionskosten für Panzer, U-Boote und Flugzeuge, Kriegerwitwenrenten) beliefen sich bei Kriegsende insgesamt auf 156 Mrd. Dollar (USA: 206 Mrd. Dollar, Großbritannien: 78 Mrd. Dollar). Deutschlands Kriegskosten (156 Mrd. Dollar) und Kriegsschäden (4,8 Mrd. Dollar) ("s. o.") ergeben die gigantische Summe von 160,8 Mrd. Dollar (entsprechend heutiger Kaufkraft und inflationsbereinigt:  Billionen US-Dollar).

Infolge des Zweiten Weltkriegs schieden Deutschland, Italien und Japan aus dem Kreis der militärischen Großmächte aus. Die westeuropäischen Staaten Frankreich, Niederlande und Großbritannien wurden so weit geschwächt, dass sie nach dem Krieg ihre Kolonialreiche aufgeben mussten. An deren Stelle traten die USA und die Sowjetunion als neue Weltmächte, aufgrund der atomaren Rüstung dann als sogenannte Supermächte.

Nach dem Ende des Zweiten Weltkrieges in Europa berieten die Siegermächte im Juli und August 1945 in Potsdam über die weitere Zukunft Europas und Deutschlands. Die Zielrichtung der gefassten Potsdamer Beschlüsse hatte sich bereits auf der Konferenz von Jalta im Februar 1945 angedeutet.

Deutschland wurde in vier Besatzungszonen eingeteilt; seine Ostgebiete (Pommern, Schlesien, Ostpreußen) wurden vorbehaltlich einer endgültigen Friedensregelung der Verwaltung Polens und der Sowjetunion unterstellt. Polen erhielt dadurch eine neue Grenze im Westen (Oder-Neiße-Linie) und im Osten. Das durch die Bestimmungen des Münchner Abkommens von 1938 von Deutschland eingegliederte Sudetenland fiel an die Tschechoslowakei zurück, da die faktische Annexion im Zuge der „Zerschlagung der Rest-Tschechei“ durch das Deutsche Reich nachträglich für nichtig erklärt wurde. Österreich wurde als Staat wiederhergestellt – dies hatten die späteren Siegermächte bereits 1943 in der Moskauer Deklaration angekündigt – und ebenfalls in vier Besatzungszonen eingeteilt, bis es 1955 mit dem Österreichischen Staatsvertrag unabhängig wurde.

Aufgrund der durch die drei Hauptsiegermächte de facto beschlossenen Gebietsverkleinerung Deutschlands wurden nach unterschiedlichen Angaben zwischen 12 und 14 Millionen Deutsche (Schlesier, Sudetendeutsche, Ostpreußen, Pommern, Ostbrandenburger, Donauschwaben und Danziger) aus ihrer angestammten Heimat vertrieben. Lange wurde dabei die Zahl der Todesopfer mit 2 Millionen oder gar mehr angegeben. Neuere Untersuchungen stellen dar, dass diese Zwei-Millionen-Zahl als Ergebnis von Bevölkerungsbilanzen berechnet wurde, während gesicherte Personendaten auf der Grundlage von Todesfallmeldungen zu einer Zahl von rund 500.000 Opfern führen. 3,5 Millionen Polen verloren durch die anschließende Westverschiebung der polnischen Ostgrenze ihre Heimat.
Die deutschen und japanischen Kriegsverbrechen wurden in mehreren Prozessen (zum Beispiel den Nürnberger Prozessen) verhandelt. Das Stuttgarter Schuldbekenntnis einiger führender evangelischer Christen zu Versäumnissen in der Zeit des Nationalsozialismus im Oktober 1945 blieb eine seltene Ausnahme im beginnenden, von den Alliierten erzwungenen Entnazifizierungs-Geschehen.
Die zum größten Teil zerstörten Städte und der Mangel an Lebensmitteln – insbesondere fehlende Rohstoff- und Düngemittel – verursachten bei der Bevölkerung ein Leben in Armut. Weil viele Männer im Krieg gefallen oder in Kriegsgefangenschaft geraten waren, mussten „Trümmerfrauen“ den Schutt in den Städten beseitigen. Lebensmittel waren nur über Lebensmittelmarken oder aus eigenem Anbau zu haben, weshalb Stadtbewohner massenhaft aufs Land fuhren, um Sachgüter gegen Lebensmittel einzutauschen. Darüber hinaus verloren zu damaliger Zeit weltweit führende deutsche Wirtschaftsunternehmen bedeutende Patente und Warenzeichen. Diese Situation änderte sich erst durch den bald darauf einsetzenden weltweiten Nachkriegsboom, der in Deutschland vielfach als Wirtschaftswunder bezeichnet wurde.

Japan musste die besetzten pazifischen Inseln an Australien und Großbritannien zurückgeben; es verlor weiterhin Korea, Formosa (Taiwan), Südsachalin und die Kurileninseln. Die alliierte Besetzung Japans endete mit dem Friedensvertrag von San Francisco von 1951, der die Souveränität Japans wiederherstellte. Einige japanische Inseln, darunter die Ryūkyū-Inseln, blieben bis 1972 unter amerikanischer Militärverwaltung.

Mit der Gründung der „Organisation der Vereinten Nationen“ (UNO) auf der Konferenz von San Francisco und dem Inkrafttreten der UN-Charta am 24. Oktober 1945 wurde der Versuch unternommen, das informelle Kriegsbündnis der Anti-Hitler-Koalition in eine permanente Institution zur Wahrung des Weltfriedens zu transformieren. Die Initiative hierzu war maßgeblich von dem verstorbenen US-Präsidenten Franklin D. Roosevelt ausgegangen. Kernpunkt der Charta war die Schaffung eines Systems, das die friedliche Beilegung von Streitigkeiten und die kontrollierte Intervention bei Verstößen ermöglichen sowie die internationale Zusammenarbeit fördern sollte. Eine besondere Rolle als Garanten des Weltfriedens wurde dabei für die Hauptsiegermächte USA, Sowjetunion, Großbritannien, Frankreich und China vorgesehen, die permanente Sitze und ein Vetorecht im Sicherheitsrat der Vereinten Nationen erhielten. Am 10. Dezember 1948 wurde die Allgemeine Erklärung der Menschenrechte verabschiedet, auf deren Grundlage später weitere international bindende Menschenrechtsabkommen entstanden sind, darunter die Konvention über die Verhütung und Bestrafung des Völkermordes.

Der Zweite Weltkrieg ging sowohl in Europa als auch in Asien relativ nahtlos in den Kalten Krieg über. Schon während des Krieges gab es Differenzen zwischen der Sowjetunion und den westlichen Alliierten, die zugunsten des gemeinsamen Ziels nicht in den Vordergrund gestellt wurden. An diesen Differenzen war nicht allein die Sowjetunion schuld. Die Atombomben auf Hiroshima und Nagasaki lösten einen Rüstungswettlauf zwischen den USA und der UdSSR aus. Ebenso waren die großen Erweiterungen des sowjetischen Einflussbereiches nach Westen und das beständige kommunistische Vordringen in Ostasien nicht nur ein Ergebnis des Zweiten Weltkrieges, sondern auch ein Grund für den Kalten Krieg.
In einer Rede in Fulton, Missouri, gebrauchte Winston Churchill 1946 erstmals öffentlich das Bild des „Eisernen Vorhangs“ zur Beschreibung des nunmehr geteilten Nachkriegseuropas. Ab etwa (1947) kam es zunehmend zu Spannungen zwischen den einstigen Verbündeten. Während die Westmächte in ihren Einflusszonen die parlamentarische Demokratie förderten, errichtete die Sowjetunion in den Staaten Osteuropas sogenannte "Volksdemokratien" unter Führung der Kommunisten. In der Folge verschärften sich die Spannungen und führten zu einer unversöhnlichen Gegnerschaft der einstigen Verbündeten, zur lange dauernden Teilung Deutschlands und Europas und zum Beginn des Kalten Krieges. 1949 wurde die NATO gegründet; der westdeutschen Wiederbewaffnung und dem NATO-Beitritt der Bundesrepublik Deutschland (1955) folgte als Gegenstück der Ostblockstaaten der Warschauer Pakt. Mit dem Zusammenbruch der osteuropäischen Diktaturen im Zuge der Revolutionen im Jahr 1989, der deutschen Wiedervereinigung und der mit der Auflösung der Sowjetunion einhergehenden Wiederherstellung des Selbstbestimmungsrechts der Völker der früheren sowjetischen Republiken wurden weitere Nachwirkungen des Zweiten Weltkrieges beseitigt.

Weitere Nachfolgekonflikte, die direkt oder indirekt mit dem Zweiten Weltkrieg in Beziehung stehen, waren:

Diese und andere Konflikte standen zum einen in Zusammenhang mit der beginnenden Blockkonfrontation als Konflikte über Einflusssphären in einer neugestalteten Weltlage, zum anderen mit der verstärkt einsetzenden Dekolonisation.

In Teilen Osteuropas, so im Baltikum, in Polen und in der Ukraine, kam es bereits vor Kriegsende zu von nationalistischen Organisationen (Waldbrüder, OUN) geführten, teilweise bis in die frühen 1950er-Jahre andauernden Untergrundaktionen gegen Sowjetisierung und Stalinisierung. Nach dem Tod Stalins im März 1953 entlud sich der Widerstand gegen die etablierten Systeme sowjetkommunistischer Prägung in mehreren, von der Roten Armee niedergeschlagenen Volksaufständen (Aufstand des 17. Juni 1953 in der DDR, Ungarischer Volksaufstand 1956).

Die Beschäftigung der europäischen und der deutschen Öffentlichkeit mit dem Zweiten Weltkrieg hält weiterhin an.
Das gewaltige Ausmaß des Zweiten Weltkrieges hat sich in mehreren Sprachen niedergeschlagen. So wird er im Deutschen häufig nur als „der Krieg“ bezeichnet. Ebenso ist für die verhältnismäßig lange und prosperierende Friedenszeit, die dem Krieg in den Industrieländern folgte, im Deutschen und in anderen westlichen Sprachen der Begriff der "Nachkriegszeit" (englisch: "postwar period") als sprachliche Abgrenzung zum Kriegsgeschehen entstanden, die selten auf andere Kriege angewandt wurde. Darüber hinaus haben kriegsverwandte Begriffe aus ihrer Herkunftssprache Eingang in die Sprachen anderer ehemaliger Kriegsteilnehmer gefunden, beispielsweise „Blitzkrieg“, „morale bombing“, „Baedeker Blitz“ oder „Ketsu-go“.

Einige Historiker sprechen von einem "zweiten Dreißigjährigen Krieg", mit dem sie die Zeitspanne zwischen 1914 und 1945 meinen, weil der Zweite Weltkrieg ohne den Verlauf und die Folgen des Ersten Weltkrieges nicht zu verstehen sei. Erstmals sprach De Gaulle im September 1941 in einer Radioansprache von London aus von „la nouvelle Guerre de Trente Ans“. Die Führung des NS-Staates habe alles daran gesetzt, eine Niederlage wie 1918 durch Stabilisierung der "Heimatfront" und Radikalisierung der Kriegführung zu verhindern. Dolchstoßlegende, Diktatfrieden von Versailles und militanter Antisemitismus hätten über die Zwischenkriegszeit hinweg den Boden für die aggressive NS-Außenpolitik zur Neuordnung Europas bereitet. Beide Kriege haben auch gemein, dass der Gegner durch Feindbilder „verteufelt“ und die Grenze zwischen Soldaten und Zivilisten verwischt wurde. Demgegenüber gebe es aber auch wichtige Unterschiede: zum Beispiel die Einzigartigkeit des Zweiten Weltkriegs, die im Zivilisationsbruch der Shoa liege, oder der bedenkenlose Einsatz von Massenvernichtungswaffen gegen Zivilisten wie in Dresden und Hiroshima.







</doc>
<doc id="5769" url="https://de.wikipedia.org/wiki?curid=5769" title="Ziegenproblem">
Ziegenproblem

Das Ziegenproblem, Drei-Türen-Problem, Monty-Hall-Problem oder Monty-Hall-Dilemma ist eine Fragestellung mit Bezug zur Wahrscheinlichkeitstheorie. Es geht dabei um die Frage, ob eine Wahl, die zunächst zufällig unter drei a priori gleich wahrscheinlichen Möglichkeiten getroffen wurde, geändert werden sollte, wenn zusätzliche Informationen verfügbar werden.

Die Aufgabenstellung ist lose der von Monty Hall moderierten Spielshow "Let’s Make a Deal" nachempfunden, die im deutschen Sprachraum in der Variante "Geh aufs Ganze!" bekannt wurde. Die erstgenannten Bezeichnungen beziehen sich auf die Problemformulierung, bei der den Entscheider Ziegen als Trostpreise hinter zwei von drei Türen erwarten, wenn er nicht jene Tür gewählt hat, die für den Hauptpreis steht, ein Auto.

Verschiedene Auffassungen des Ziegenproblems werden oft als Beispiel dafür herangezogen, dass der menschliche Verstand zu Trugschlüssen neigt, wenn es um das Bestimmen von Wahrscheinlichkeiten geht, und wurden Gegenstand lang anhaltender öffentlicher Diskussionen.

Die gestellte Aufgabe geht auf den Biostatistiker Steve Selvin zurück, der sie 1975 im "American Statistician" in einem Leserbrief vorstellte. Weiteren Kreisen bekannt und zum Gegenstand einer kontroversen Debatte wurde das Problem 1990 durch Publikation in Marilyn vos Savants Kolumne „Ask Marilyn“ im Magazin "Parade." Diese Version beruhte auf einem Leserbrief, den vos Savant erhalten hatte von Craig F. Whitaker aus Columbia, Maryland:

Die Fragestellung in dieser Form ist unterbestimmt; die richtige Antwort hängt davon ab, welche Zusatzannahmen getroffen werden.
Vos Savant gab die Antwort „Ja, Sie sollten wechseln. Das zuerst gewählte Tor hat die Gewinnchance von 1/3, aber das zweite Tor hat eine Gewinnchance von 2/3“. Vos Savants Antwort ist, obwohl unter Zusatzannahmen richtig, auch unter diesen Zusatzannahmen für viele Menschen kontraintuitiv. In der Folge erhielt vos Savant nach ihrer eigenen Schätzung zehntausend Briefe, die ganz überwiegend die Richtigkeit ihrer Antwort bezweifelten.

Wenn man die Frage Personen stellt, die sich noch nicht mit dem Problem beschäftigt hatten, vermuten diese häufig, dass die Gewinnchancen für die Tore 1 und 2 gleich hoch seien. Als Grund dafür wird oft angegeben, dass man ja nichts über die Motivation des Showmasters wisse, das Tor 3 mit einer Ziege dahinter zu öffnen und einen Wechsel anzubieten. Es greife daher das Indifferenzprinzip.

Die Intuition beim Verständnis des Leserbriefs geht davon aus, dass es sich bei der Problemstellung um die Beschreibung einer einmaligen Spielsituation handelt. Außerdem zeugt die Antwort von einer gewissen Vertrautheit mit Spielshows wie "Geh aufs Ganze", in denen der Showmaster (Moderator) eine aktive und unberechenbare Rolle spielt. Im Gegensatz zu den Problemvarianten, in denen der Moderator auf einen an fixe Verhaltensregeln gebundenen „Handlanger“ reduziert wird, darf realistischerweise angenommen werden, dass er völlig frei in seinen Entscheidungen ist (Monty Hall: „Ich bin der Hausherr!“). Diese Freiheit kann anhand einiger Beispiele illustriert werden, wobei vor jedem Spiel Auto und Ziegen hinter den drei Toren zufällig neu verteilt wurden. Weil die Kandidaten diese Spielshow, für die sie sich als Teilnehmer beworben haben, kennen, ist ihnen die Unberechenbarkeit des Moderators natürlich bewusst.


Angesichts der verschiedenen Verhaltensmöglichkeiten des Moderators sollte Doris ihre Gewinnchancen sorgfältig abwägen. Wenn sie glaubt, dass der Moderator nett zu ihr sei und sie von ihrer ersten falschen Wahl abbringen möchte, dann sollte sie wechseln. Wenn sie allerdings meint, dass ihr der Moderator nicht gut gesinnt sei und sie nur von ihrer ersten, richtigen Wahl ablenken möchte, dann sollte sie bei Tor 1 bleiben. Wenn Doris den Moderator nicht einschätzen kann – auch im Leserbrief werden keine entsprechenden Hinweise gegeben –, hat sie keine Möglichkeit, ihre Gewinnchance korrekt zu berechnen. Insbesondere kann sie sich nach dem Eingreifen des Moderators nicht mehr auf das Indifferenzprinzip berufen, und die Antwort auf die Frage „Ist es von Vorteil, die Wahl des Tores zu ändern?“ lautet in ihrem Fall also: „Nicht unbedingt.“

Obwohl die Frage des Leserbriefs damit bereits beantwortet ist, wurde der Vorschlag gemacht, Doris bei ihrer Entscheidung zu unterstützen und ihr eine echte 50:50-Chance auf den Gewinn zu verschaffen. Dazu wird angenommen, dass sie die Möglichkeit hat, sich nach dem Wurf einer fairen Münze für eines der beiden verbleibenden Tore zu entscheiden. Auf diese Weise kann sie sicherstellen, dass ihre Gewinnwahrscheinlichkeit unabhängig von den Absichten des Moderators genau 1/2 beträgt.

Durch die Antwort von Marilyn vos Savant auf den Leserbrief erzielte das Problem international auch außerhalb der Fachwelt hohe Aufmerksamkeit und führte zu heftigen Kontroversen. Ihre Antwort lautete:

Marilyn vos Savant berücksichtigt dabei nicht eine bestimmte Motivation des Moderators; es ist laut Leserbrief nicht ausgeschlossen, dass der Moderator nur deswegen ein Ziegentor öffnet, um den Kandidaten von seiner ersten, erfolgreichen Wahl abzulenken. Stattdessen fasst vos Savant den Leserbrief offensichtlich so auf, dass die Spielshow immer wieder nach demselben Muster abläuft:

Somit erhält sie als Lösung die durchschnittliche Gewinnwahrscheinlichkeit aller möglichen Kombinationen von Toren, die von den jeweiligen Kandidaten gewählt werden und vom Moderator daraufhin geöffnet werden können. Weil die erste Wahl eines Kandidaten als beliebig und die Verteilung von Auto und Ziegen hinter den Toren als zufällig angesehen wird, darf jede der neun Möglichkeiten als gleich wahrscheinlich betrachtet werden:

Drei von neun Kandidaten gewinnen, wenn sie bei ihrer ersten Wahl bleiben, während sechs von neun Kandidaten durch Wechseln das Auto bekommen. Ein Kandidat hat durch Wechseln also eine durchschnittliche Gewinnchance von p = 2/3.

Diese Lösung kann auch grafisch veranschaulicht werden. In den Bildern der folgenden Tabelle ist das gewählte Tor "willkürlich" als das linke Tor dargestellt:

Wegen der Auffassung von vos Savant und unter Berücksichtigung der von ihr vorgeschlagenen Wechselstrategie lässt sich eine alternative Sicht des Ablaufs der Spielshow formulieren:

Beispielsweise möchte ein Kandidat Tor 2 und Tor 3 öffnen lassen. Er zeigt daher zunächst auf Tor 1, das verschlossen bleibt, und wechselt dann zu Tor 2, wenn der Moderator Tor 3 geöffnet hat, oder umgekehrt. Der Kandidat hat damit offensichtlich eine durchschnittliche Gewinnchance von p = 2/3. Demnach wäre es für einen Kandidaten, der mehrmals an dieser Spielshow teilnehmen dürfte, von Vorteil, die Wahl des Tors immer zu ändern.

Es sind vor allem die folgenden Hauptargumente, die zu Zweifeln an vos Savants Antwort führen. Während das erste Argument nicht stichhaltig ist und auf falsch angewandter Wahrscheinlichkeitstheorie basiert, verdeutlichen die weiteren Argumente, dass das Originalproblem eine Vielzahl von Interpretationen zulässt:


Das erste Argument wird durch den ausgeglichenen Moderator widerlegt, das zweite wird anhand der erfahrungsbezogenen Antwort und das dritte anhand des faulen Moderators ausgeführt.

Weil die im Leserbrief von Whitaker formulierte Aufgabe einigen Wissenschaftlern nicht eindeutig lösbar erschien, wurde von ihnen eine Neuformulierung des Ziegenproblems vorgeschlagen. Diese als Monty-Hall-Standard-Problem bezeichnete Umformulierung, die zur gleichen Lösung wie der von Marilyn vos Savant führen soll, stellt bestimmte Zusatzinformationen bereit, welche die erfahrungsbezogene Antwort ungültig machen, und berücksichtigt im Unterschied zur Interpretation von vos Savant auch die konkrete Spielsituation:

Insbesondere hat der Moderator die Möglichkeit, frei darüber zu entscheiden, welches Tor er öffnet, wenn er die Auswahl zwischen zwei Ziegentoren hat (Sie haben also zuerst das Auto-Tor gewählt). Aufgeteilt in Einzelschritte, ergeben sich damit die folgenden Spielregeln, die dem Kandidaten, der ein Auto gewinnen kann, bekannt sind:


Bedeutung der Zusatzannahme zum Verhalten des Moderators:

Mit einer solchen Zusatzannahme entsteht jeweils ein anderes Problem, das zu unterschiedlichen Gewinnchancen bei der Torauswahl des Kandidaten führen kann. Dazu wird immer vorausgesetzt, dass der Kandidat die dem Moderator unterstellte Entscheidungsprozedur kennt.

Für diese Lösung wird die folgende Zusatzannahme gemacht:

Wie soll sich der Kandidat im vorletzten Schritt entscheiden, wenn er zunächst Tor 1 gewählt und der Moderator daraufhin Tor 3 mit einer Ziege dahinter geöffnet hat?

Das Auto ist mit der Wahrscheinlichkeit 1/3 hinter dem vom Kandidaten zunächst gewählten Tor 1. Wegen der Symmetrie im Regelwerk, insbesondere wegen der Spielregeln 4 und 5, wird diese Wahrscheinlichkeit durch das Öffnen eines anderen Tors mit einer Ziege dahinter nicht beeinflusst. Deshalb ist nach dem Öffnen des Tors 3 das Auto mit 2/3-Wahrscheinlichkeit hinter Tor 2, und ein Wechsel führt mit der Wahrscheinlichkeit 2/3 zum Erfolg.

Für die Erklärung wird angenommen, dass der Kandidat zu Anfang Tor 1 gewählt hat und sich anschließend umentscheidet. Für die Situationen, in denen der Kandidat die Tore 2 oder 3 gewählt hat und der Moderator dementsprechend andere Tore öffnet, gilt eine analoge Erklärung. Es müssen sechs Fälle betrachtet werden, um die Gleichwahrscheinlichkeit des Öffnens der Tore 2 und 3 durch den Moderator gemäß Regel 4 modellieren zu können. Das entspricht einem Zufallsexperiment, bei dem die beiden Ziegen voneinander unterschieden werden können und jede Verteilung von Auto und Ziegen hinter den drei Toren gleich wahrscheinlich ist (Laplace-Experiment).

Zur Auswertung der Tabelle müssen nun die Fälle betrachtet werden, in denen der Moderator das Tor 3 öffnet (das ist die Bedingung). Das sind die Fälle 2, 4 und 5. Man sieht, dass in zwei dieser drei Fälle der Kandidat durch Wechseln gewinnt. Unter den Voraussetzungen, dass der Kandidat zunächst Tor 1 gewählt hat und der Moderator Tor 3 mit einer Ziege dahinter öffnet, befindet sich das Auto also in zwei Drittel der Fälle hinter Tor 2. Der Kandidat sollte also seine Wahl zugunsten von Tor 2 ändern. Genauso kann aus der Tabelle abgelesen werden, dass dann, wenn der Moderator anstelle von Tor 3 das Tor 2 öffnet, der Kandidat durch Wechseln auf Tor 3 ebenfalls in zwei von drei Fällen das Auto gewinnt.

Es sind die Ereignisse definiert:

Es liegt folgende Situation vor: Der Kandidat hat Tor 1 gewählt, und der Moderator hat daraufhin das Tor 3 geöffnet. Lohnt es sich für den Kandidaten zu wechseln? Wie groß ist die Wahrscheinlichkeit, dass das Auto hinter Tor 2 ist? Gesucht ist also die bedingte Wahrscheinlichkeit formula_7, dass das Auto hinter Tor 2 ist, wenn bekannt ist, dass es nicht hinter Tor 3 ist. Man kann diese Wahrscheinlichkeit mit dem Satz von Bayes ermitteln.

Auf Grund der Aufgabenstellung (Regeln 1, 4 und 5 und der Wahl des Kandidaten) gelten folgende Voraussetzungen:

Die Anwendung des Satzes von Bayes ergibt dann:

Der Kandidat sollte also wechseln, um seine Gewinnchancen von anfangs 1/3 auf nun 2/3 zu verdoppeln.

Für diese Lösung wird die folgende Zusatzannahme gemacht:

Für die folgende Erklärung wird angenommen, dass der Kandidat zu Anfang Tor 1 gewählt hat. Für die Situationen, in denen der Kandidat die Tore 2 bzw. 3 gewählt hat und der Moderator dementsprechend andere Tore öffnet, gilt eine analoge Erklärung. Obwohl es hier ausreichen würde, die drei ersten Spielsituationen zu betrachten, werden sechs Fälle unterschieden, um die Problemstellung vergleichbar mit der obigen tabellarischen Lösung beim ausgeglichenen Moderator modellieren zu können. Jede Spielsituation wird also zweimal betrachtet. Das entspricht einem Zufallsexperiment, bei dem die beiden Ziegen voneinander unterschieden werden können und jede Verteilung von Auto und Ziegen hinter den drei Toren gleich wahrscheinlich ist (Laplace-Experiment).

Zur Auswertung der Tabelle müssen nun die Fälle betrachtet werden, in denen der Moderator das Tor 3 öffnet (das ist die Bedingung). Das sind die Fälle 1, 2, 4 und 5. Man sieht, dass nur in zwei von vier dieser Fälle der Kandidat durch Wechseln gewinnt. Seine Gewinnwahrscheinlichkeit ist demnach hier nur p = 1/2. Es kann ebenso leicht aus der Tabelle abgelesen werden, dass, wenn der Moderator Tor 2 öffnet, der Kandidat sicher gewinnt, wenn er zu Tor 3 wechselt.

Es liegt die folgende Situation vor: Der Kandidat hat Tor 1 gewählt, und der Moderator hat daraufhin das Tor 3 geöffnet. Es gelten dann folgende mathematische Beziehungen unter Berücksichtigung der oben definierten Ereignismengen:

Die Anwendung des Satzes von Bayes ergibt dann für die bedingte Wahrscheinlichkeit, dass sich das Auto hinter Tor 2 befindet:

Für die bedingte Wahrscheinlichkeit, dass sich das Auto tatsächlich hinter Tor 1 befindet, gilt aber ebenfalls

Der Gewinn hinter Tor 2 ist genauso wahrscheinlich wie der Gewinn hinter Tor 1. Der Kandidat kann demnach in diesem Fall also ebenso gut bei Tor 1 bleiben wie zu Tor 2 wechseln. Hat der Moderator Tor 3 geöffnet, ist seine Gewinnchance also unabhängig von der Entscheidung 1/2.

Bei dieser Lösung wird von der folgenden Zusatzannahme ausgegangen:
Dann gelten folgende mathematische Beziehungen unter Berücksichtigung der oben definierten Ereignismengen:

Die Anwendung des Satzes von Bayes ergibt dann für die bedingte Wahrscheinlichkeit, dass sich das Auto hinter Tor 2 befindet:

Diese Berechnung beschreibt den allgemeinen Fall, aus dem sich der „ausgeglichene Moderator“ (formula_17) und der „faule Moderator“ (formula_18) als Spezialfälle ableiten lassen.

Aus der Betrachtung des unausgeglichenen Moderators lässt sich ableiten, dass unabhängig von seiner jeweiligen Vorliebe für ein bestimmtes Ziegentor die Gewinnwahrscheinlichkeit durch Wechseln nach dem Öffnen eines Ziegentores immer mindestens 1/2, im Durchschnitt sogar 2/3 beträgt. Solange der Moderator gemäß den Spielregeln gezwungen ist, immer ein nichtgewähltes Ziegentor zu öffnen und daraufhin einen Wechsel anzubieten, sollte ein Kandidat also in jedem Fall seine Wahl des Tors ändern.

In einem Artikel auf der ersten Seite der Sonntagsausgabe der "New York Times" im Jahr 1991 wurde über den Versuch der Klärung der damals schon seit 10 Monaten währenden Debatte zur Lösung des „Monty-Hall-Problems“ berichtet. Zu diesem Klärungsversuch waren die folgenden vier Personen um ihren Beitrag gebeten worden: Martin Gardner, Persi Diaconis, Monty Hall und Marilyn vos Savant. Nachdem Monty Hall die Aufgabenstellung genau gelesen hatte, spielte er mit einem Versuchskandidaten das Spiel so, dass dieser bei einem Wechsel stets verlor, indem er den Wechsel immer nur dann anbot, wenn der Kandidat im ersten Schritt das Gewinn-Tor gewählt hatte.

Gardner bestätigte diese Variante mit den Worten: Sonst könnte der Moderator den Wechsel auch nur dann anbieten, wenn es zu seinem Vorteil wäre, den Kandidaten wechseln zu lassen, wodurch die Chancen bei einem Wechsel auf Null sinken würden. Diese Unklarheit könne beseitigt werden, indem der Moderator vorher verspreche, eine andere Tür zu öffnen und danach einen Wechsel anzubieten.

Vos Savant bestätigte diese Unklarheit in ihrer ursprünglichen Problemstellung und dass dieser Einwand, wenn er von ihren Kritikern gebracht worden wäre, gezeigt hätte, dass sie das Problem wirklich verstanden haben; aber sie hätten nie ihre erste falsche Auffassung aufgegeben. In ihrem später veröffentlichten Buch schreibt sie, dass sie auch Briefe von Lesern erhalten habe, die auf diese Unklarheit hingewiesen hatten. Diese Briefe seien aber nicht veröffentlicht worden.

Diaconis sagte zur Aufgabenstellung: Das stand ganz im Gegensatz zu den Veröffentlichungen, die ihre Lösung gerade auf exakte Mathematik im Gegensatz zur „Intuition“ gründeten.

Monty Hall selbst gab folgenden Rat: 

Andrew Vázsonyi schildert, wie der berühmte Mathematiker Paul Erdős im Jahr 1995 auf das Ziegenproblem und die Behauptung der 2/3-Lösung reagiert hat. Nachdem Vázsonyi zunächst von einem Freund von dem Problem, direkt angelehnt an vos Savants Originalversion, gehört hatte, löste er es mit einem Entscheidungsbaum und konnte die 2/3-Lösung, die sich ergab, kaum glauben. Als er dann Problem und Lösung Erdős vorlegte, sagte „einer der größten Experten in Wahrscheinlichkeitstheorie“: "Nein, das ist unmöglich. Da besteht kein Unterschied." Die Reaktion auf die Lösung mit dem Entscheidungsbaum beschreibt Vázsonyi so: "Zu meiner Verblüffung überzeugte ihn das nicht. Er wollte eine einfache Lösung ohne Entscheidungsbäume. Ich gab an diesem Punkt auf, weil ich keine Erklärung auf der Basis des gesunden Menschenverstands habe." Es sei „hoffnungslos“ für jemanden, der sich in Entscheidungsbäumen und mit dem Satz von Bayes nicht auskenne, die Lösung zu verstehen. Als Vázsonyi von Erdős nach einer Stunde noch einmal gebeten wurde, ihm den Grund für den Wechsel zu nennen, führte er ihm schließlich eine Computersimulation vor. Laut Vázsonyi wandte Erdős ein, dass er den Grund immer noch nicht verstehe, er sei aber widerwillig überzeugt gewesen.

Einige Tage später teilte Erdős laut Vázsonyi mit, er habe die Lösung jetzt verstanden, nachdem ihm der Mathematiker Ron Graham die Begründung für die Antwort gegeben habe. Vázsonyi schreibt jedoch, dass er selbst diese Begründung nicht verstand.

In seinem Buch über Paul Erdős gibt Paul Hoffmann Grahams Begründung wieder: „Der Schlüssel zum Monty-Hall-Problem ist, dass man im Voraus weiß, dass der Moderator einem immer die Möglichkeit gibt, eine andere Tür zu wählen. Das gehört zu den Spielregeln und muss in die Betrachtungen einbezogen werden.“

Am Ende seines Artikels schreibt Vázsonyi im Abschnitt „Marilyn weiß es am besten“, dass er später durch einen Artikel zum Thema im "Skeptical Inquirer" aus dem Jahr 1991 einen tieferen Einblick in das Problem bekommen habe. In diesem Artikel, durch den auch Gero von Randow auf das Problem gestoßen war, wird exakt die Originalaufgabe vos Savants aus dem Magazin "Parade" gestellt.

Im Februar 1975 veröffentlichte die akademische Zeitschrift "The American Statistician" einen Brief von Steve Selvin, damals Assistenzprofessor für Biostatistik an der Universität von Kalifornien in Berkeley, an den Editor. In diesem Brief, überschrieben mit „A Problem in Probability“, schlug er eine Textaufgabe als Übung in Wahrscheinlichkeitsrechnung vor. Die von ihm gegebene Lösung ähnelt der Tabelle, wie sie im Abschnitt zu vos Savants Antwort dargestellt ist. Im August desselben Jahres erschien ein weiterer Brief vom selben Autor mit dem Titel „On the Monty Hall Problem“, in dem er sich auf seinen ersten Brief bezog und auf Einwände seitens der Leser bezüglich seines Lösungsvorschlags reagierte. Zu diesem Zeitpunkt tauchte also zum ersten Mal der Begriff „Monty Hall Problem“ im medialen Raum auf.

In seinem zweiten Brief präsentierte Selvin weitere Argumente zugunsten seiner Lösung, einschließlich einer formalen mathematischen Berechnung mithilfe bedingter Wahrscheinlichkeiten. Er fügte hinzu, dass seine Berechnungen auf bestimmten, nicht expliziten, Annahmen bzgl. des Verhaltens des Moderators Monty Hall beruhten. Außerdem zitierte er einen Leser, der darauf hinwies, dass die kritischen Annahmen bzgl. des Moderatorverhaltens notwendig seien, um das Problem überhaupt lösen zu können, und dass die Anfangsverteilung nur ein Teil des Problems darstellte, während es sich hier doch um ein subjektives Entscheidungsproblem handelte.

Es liegt nahe, dieses frühe Monty-Hall-Problem als einen Vorläufer der heute als Ziegenproblem bekannten Fragestellung anzusehen, einschließlich des Disputs über die damals schon umstrittenen zusätzlichen Annahmen bzgl. der Verhaltensregeln des Moderators.

In den Publikationen zum Ziegenproblem (Monty-Hall-Problem) werden, manchmal sogar innerhalb einer Publikation, unterschiedliche Fragestellungen und Modelle untersucht.

Autoren wie Gill und Krauss & Wang sowie Krauss & Atmaca legen ihrer Lösung vos Savants Originaltext zugrunde und machen ihre Zusatzannahmen erst im Laufe ihrer Analyse explizit. Dabei wird die Korrektheit von vos Savants Lösung, die die heftigen Kontroversen ausgelöst hatte, ausdrücklich herausgestellt.

Im Anhang von vos Savants Buch schreibt Donald Granberg, es sei Konsens, dass vos Savants Antwort im Wesentlichen korrekt sei, vorausgesetzt, man mache sieben „hoch plausible“ Annahmen. Darunter befindet sich die Annahme, dass der Moderator verpflichtet ist, nach der ersten Wahl eine nichtgewählte Ziegentür zu öffnen, sowie die Annahme, dass der Moderator ehrlich ist.

Krauss & Wang fügen der Aufgabe vos Savants, die sie als „Standardversion“ bezeichnen, mehrere Annahmen hinzu, damit sich die Lösung vos Savants präzise herleiten lässt. Auch in Krauss & Atmaca wird mit dem Originalproblem vos Savants begonnen, wobei der Moderator, bevor er die Ziegentür öffnet, entsprechend der Formulierung Gero von Randows noch sagt "Ich zeige Ihnen mal was." Nach Steinbach sind diese Worte des Moderators aus der Sicht des Kandidaten „unsinnig“, wenn er auf Grund der Spielregeln sowieso erwartet, eine Ziege gezeigt zu bekommen. Auch Henze lässt in seiner Aufgabenformulierung den Moderator, bevor er die Ziegentür öffnet, sagen "Soll ich Ihnen mal was zeigen?", und schreibt, nachdem er die Lösung vos Savants als korrekt dargestellt hat: "Bei allen diesen Betrachtungen ist natürlich entscheidend, dass der Moderator die Autotür geheimhalten muss, aber auch verpflichtet ist, eine Ziegentür zu öffnen." In einer Vorlesung im Sommersemester 2014 schreibt er diesen Zusatz zu Beginn in die Aufgabenstellung und stellt ausführlich heraus, dass vos Savant recht hatte.

Lucas verwendet eine Problemformulierung, die dem Moderator von vornherein gewisse Verhaltensregeln vorschreibt. Bei der Beurteilung der heftigen Reaktionen auf vos Savants Lösung spielt es für Lucas jedoch keine Rolle, dass diese Verhaltensregeln in dem von vos Savant vorgelegten Problem nicht formuliert worden waren.

Morgan et al. sowie Gill wiederum thematisieren nicht, dass in vos Savants Originalfragestellung die Regel fehlte, dass der Moderator verpflichtet ist, nach der ersten Wahl eine nicht gewählte Ziegentür zu öffnen und einen Wechsel anzubieten. Den einzigen Fehler in vos Savants Lösung sehen Morgan et al. darin, dass sie nicht explizit angenommen hat, dass der Moderator dann, wenn der Kandidat die Autotür gewählt hat, beide möglichen Ziegentüren mit gleicher Wahrscheinlichkeit öffnet. Erst nach ihren Ausführungen zu Aufgabe und Lösung erwähnen Morgan et al. und Gill andere Möglichkeiten des Spielablaufs. Morgan et al. gehen nun sogar davon aus, dass der Moderator, ohne den Spieler zu informieren, auch die Autotür öffnen darf, was bei einem „plausiblen Szenario“ zur „populären Antwort 1/2“ für den Fall führe, dass er eine nicht gewählte Ziegentür öffnet. Sie schreiben sogar, dass es die Perspektive des Moderators verlangt, das „vos-Savant-Szenario“ nicht zu befolgen, um Spieler davon abzuhalten, immer zu wechseln. Dem Moderator zu erlauben, sofort auch die vom Kandidaten gewählte Tür zu öffnen, nennen sie eine „Verallgemeinerung“, die an den Betrachtungen der bedingten Wahrscheinlichkeiten nichts ändere.

Götz (2006) sieht „das berühmte 'Ziegenproblem'“ als „hinreichend diskutiert“ an. In seiner Beschreibung der Problemstellung heißt es: "Jetzt kommt der entscheidende Punkt. Der Spielleiter fragt die Kandidatin, ob sie bei ihrer ursprünglichen Wahl der Türe bleiben möchte oder auf die andere, noch geschlossene Türe wechseln möchte." Zur Lösung schreibt er, "dass die Strategie „Wechseln“ mit Wahrscheinlichkeit 2/3 zum Auto führt". Nach verschiedenen Lösungsansätzen erwähnt er, dass „R. Grothmann (2005)“ darauf hingewiesen habe, "dass es klar sein muss, ob der Spielleiter eine nicht gewählte Tür öffnen muss oder auch die gewählte öffnen kann".

„Das aus den Medien bekannte umstrittene Ziegenproblem“ wird von Steinbach „vollständig analysiert und gelöst“. Dabei geht er von Gero von Randows Problemformulierung aus. Steinbach vermutet, dass die unterschiedlichen Antworten auf die Originalfrage darauf zurückzuführen sind, dass die Befürworter der 2/3-Lösung die Perspektive des „Denksportlers“, die Befürworter der Lösung 1/2 die des Kandidaten einnehmen: "Allein aus den Worten des Moderators und dem Anblick der Ziege kann der Kandidat nämlich nicht erkennen, ob irgendeine Spielregel gilt – und schon gar nicht, welche. […] Es bleibt nur der Münzwurf: so erwischt der Kandidat – unabhängig vom Verhalten des Moderators! – mit Wahrscheinlichkeit 1/2 die richtige Tür."

Gigerenzer und Grams stellen heraus, dass ein Großteil der Debatte zum Ziegenproblem darauf zurückgeht, dass von den Autoren nicht ausreichend zwischen „Entscheidung bei Risiko“ und „Entscheidung bei Ungewissheit“ unterschieden wird: „Unter den Tausenden von Artikeln, die über das Monty-Hall-Problem veröffentlicht wurden, blieb der Unterschied zwischen Risiko und Ungewissheit praktisch unbeachtet“ (Gigerenzer).

In Bezug auf die verschiedenen Lösungen, wie sie auch oben wiedergegeben wurden, resümiert Götz „WECHSELN IST NIE SCHLECHTER ALS BLEIBEN!“ (Versalien gemäß Referenz). Auf diesen Sachverhalt hatten bereits 1991 Morgan et al., die „Entdecker“ der auf Zusatzannahmen über das Moderatorverhalten basierenden Lösungen, aufmerksam gemacht. Trotz dieser qualitativen Übereinstimmung und der Tatsache, dass die Problemstellung „Ist es von Vorteil, die Wahl des Tores zu ändern?“ nach einer Aktion und "nicht" nach einer Wahrscheinlichkeit fragt, sind die Annahmen, die zu unterschiedlichen Wahrscheinlichkeits"werten" führen, immer wieder Gegenstand heftiger Diskussionen. So enthält allein die Bibliografie des 2009 erschienenen Buchs "The Monty Hall Problem" von Rosenhouse über hundert Veröffentlichungen.

Georgii kommt zunächst unter der Annahme, dass der Moderator nach der ersten Wahl des Kandidaten zum Öffnen einer nicht gewählten Ziegentür verpflichtet ist, unmittelbar zur Gewinnwahrscheinlichkeit 2/3 bei einem Türwechsel. Die „Trivialität“ dieser Lösung, die "genau der Antwort vos Savants" entspricht, liegt nach Georgii daran, "dass wir den Moderator auf eine feste Verhaltensweise festgelegt haben, dass er also das Spiel immer so durchführt wie beschrieben". Den „tieferen Grund“ für diese Festlegung sieht er "darin, dass wir implizit von einer frequentistischen Interpretation der bedingten Wahrscheinlichkeiten ausgegangen sind, welche die Wiederholbarkeit des Vorgangs und also feste Regeln voraussetzt". Entsprechend der Bemerkung von Morgan et al. die Perspektive des Moderators verlange es, das "„vos-Savant-Szenario“" nicht zu befolgen, schreibt auch Georgii: "Nun wird der Moderator das Spiel aber nicht regelmäßig durchführen." Unter diesem Gesichtspunkt sei die „subjektive Interpretation“ angemessener. Als Beispiel nennt er dann die Variante mit Gewinnwahrscheinlichkeit 1/2, bei der der Moderator vor dem Wechselangebot mit gleicher Wahrscheinlichkeit eine der beiden Ziegentüren öffnet, unabhängig davon, welche Tür der Spieler gewählt hat. Nach diesen Ausführungen zieht er folgenden Schluss: "Ähnlich wie beim Betrand’schen Paradoxon beruhen die verschiedenen Antworten auf einer unterschiedlichen Interpretation einer unscharf gestellten Aufgabe. […] Die philosophische Unsicherheit über die Bedeutung bedingter Wahrscheinlichkeiten kommt dabei erschwerend hinzu."

Die Bemerkung Georgiis, dass es darauf ankomme, „wie der Spieler das Verhalten des Moderators einschätzt“, lässt sich auch anwenden auf die Frage, mit welcher Wahrscheinlichkeit der Moderator eine bestimmte Ziegentür öffnet, wenn der Kandidat die Autotür gewählt hat. Die meisten Lehrbuchautoren verzichten allerdings auf die Berücksichtigung einer solchen subjektiven Einschätzung des Moderatorverhaltens. Konkret gehen sie davon aus, dass der Moderator "ausgeglichen" agiere, das heißt, dass er die Auswahl des Tors gemäß einer Gleichverteilung vornimmt. Dadurch wird dieser Ansatz zur häufigsten in der Fachliteratur vertretenen Erklärung dafür, dass ein Torwechsel mit der Wahrscheinlichkeit von 2/3 zum Gewinn führt. Diese Gewinnwahrscheinlichkeit von 2/3 bei einem Torwechsel bezieht sich explizit auf den Zeitpunkt "nach" dem Öffnen eines Tores durch den Moderator.

Untersuchungen, bei denen der Kandidat den Moderator auch dahingehend einschätzt, seine Torauswahl nicht gleichwahrscheinlich vorzunehmen, wurden erstmals 1991 von Morgan et al. und unabhängig davon 1992 von Gillmann veröffentlicht. Dabei haben Morgan et al. vos Savants Aufgabe so abgeändert, dass sich die Fragestellung genau auf die genannten Türnummern bezog, die bei vos Savant nur als erläuternde Beispiele vorkamen. Die Variante vos Savants mit einer Million Türen bezeichneten Morgan et al. als „dubiose Analogie“. Die Anwendung des Verfahrens von Morgan et al. auf diese Variante liefert ohne Zusatzannahmen dasselbe Ergebnis wie bei nur drei Türen, nämlich einen Wert zwischen 1/2 und 1 – gegenüber 99,9999 % bei vos Savant.

In ihrer Erwiderung auf Morgan et al. weist vos Savant auf die verkürzte Wiedergabe sowohl ihrer Fragestellung als auch ihrer Antwort hin, deren vollständige Version sie in ihrem Antwortbrief wiedergibt. Morgan et al. wiederum antworten darauf, dass in dieser Darstellung der Hinweis fehle, dass die Fragestellung von einem „Leser in Columbia, Maryland“ stamme. Das sei deshalb wichtig, weil die Einschränkung, „dass der Moderator eine Ziege zeigen muss“, von vos Savant selbst hinzugefügt worden sei. Vos Savant selbst hat darauf hingewiesen, dass sie den Eindruck hatte, dass diese „bedeutendste“ einschränkende Bedingung in der ursprünglichen Leserfrage nicht genügend hervorgehoben worden war und dass sie sie deshalb in ihrer Antwort hinzugefügt habe.

Bei den anderen in ihrer ursprünglichen Fragestellung nicht formulierten Voraussetzungen bleibt sie bei ihrer Auffassung, dass sie ihr für ein allgemeines Verständnis des Problems nicht wichtig erscheinen, da Ereignisse standardmäßig als „zufällig“ betrachtet werden. Diese Auffassung teilt auch Steinbach, der diese Annahmen, bevor er sie unter der Überschrift „Haarspaltereien“ mathematisch untersucht, als „stillschweigend, aber unstrittig und irrelevant“ bezeichnet.

Nach Georgii reduzieren sich die unterschiedlichen Standpunkte zu der „unscharf gestellten Aufgabe“ auf die Frage, ob es Bestandteil einer festen Spielregel ist, dass der Moderator eine nicht gewählte Ziegentür öffnen und einen Wechsel anbieten muss.

Während bei Georgii die Frage, mit welcher Wahrscheinlichkeit der Moderator eine bestimmte Ziegentür öffnet, wenn der Kandidat die Autotür gewählt hat, nicht thematisiert wird und für seine Lösung keine Rolle spielt, verweist Götz dazu auf zwei „unterschiedliche Wahrscheinlichkeitsbegriffe, die den jeweiligen Betrachtungsweisen zugrunde liegen.“ Die „klassische Lösung“ ohne die Betrachtung dieses Moderatorverhaltens sei „frequentistisch“ zu deuten und empirisch zu überprüfen. Demgegenüber liefere eine „Bayesianische Lösung […] die Bewertungsgrundlage einer Einzelsituation. Wie soll sich die Kandidatin hic et nunc verhalten, nachdem der Spielleiter eine Tür geöffnet hat? […] Man fragt also nach Zustandswahrscheinlichkeiten oder Erkenntniswahrscheinlichkeiten (und nicht nach Wahrscheinlichkeiten zukünftiger Zufallsereignisse).“ Mit anderen Worten: Die Kandidatin macht "nach" der Toröffnung durch den Moderator die Bewertung seiner beiden Handlungsoptionen davon abhängig, welches grundsätzliche Verhalten sie dem Moderator unterstellt. Dabei wird der Extremfall eines "faulen Moderators" durch die Antwort auf die folgende Frage charakterisiert: „Hätte der Moderator, nachdem er meine Entscheidung für ein Tor gesehen hat, das von ihm gerade geöffnete Tor auch unter allen anderen Umständen ausgewählt, sofern es ihm nur möglich – kein Auto dahinter – gewesen wäre?“

Wenn die Kandidatin nichts über die Vorlieben des Moderators weiß, „bringt Wechseln“ laut Götz „eine Erfolgschance von 2/3“. "Gute Schätzwerte für den unbekannten Parameter p" erhalte man "durch Beobachten des Verhaltens des Spielleiters in der passenden Situation, wenn das Auto hinter Tür 1 steht und die Kandidatin ebendiese Tür (zunächst) erwählt hat".

Bayessche Untersuchungen wurden erstmals von Morgan et al. durchgeführt, und zwar auf Basis ihrer Ergebnisse, bei denen der Moderator das zu öffnende Tor zufällig gemäß dafür angenommener A-Priori-Wahrscheinlichkeiten auswählt.

Die im letzten Abschnitt vorgenommene Charakterisierung des Verhaltens eines "faulen Moderators" zeigt, dass eine diesbezügliche Lösung nicht an eine Nummerierung der Tore gebunden ist (üblicherweise „Kandidat wählt Tor 1. Moderator öffnet Tor 3, wenn immer es möglich ist“).

Soll beispielsweise die für die Variante eines "faulen Moderators" gefundene 50:50-Lösung empirisch geprüft werden, so ist dabei zu berücksichtigen, dass sich die auf dieser Basis hergeleitete Aussage auf ein bedingtes Ereignis bezieht. Bei einer Versuchsreihe von 300 Spielshows, die gemäß der Zusatzannahme "fauler Moderator" durchgeführt werden, durchlaufen damit ungefähr 100 Shows nicht das Ereignis, das Gegenstand der Untersuchung ist. Konkrete Ursache dafür ist, dass bei einem hinter Tor 3 verborgenen Auto der Moderator gezwungen ist, Tor 2 zu öffnen. Solche Spielverläufe liegen aber außerhalb des Untersuchungsbereichs, so dass die nach einem Torwechsel stets erzielten Gewinne bei der Versuchsreihenauswertung unberücksichtigt bleiben müssen.

Die „global“ für alle denkbaren Entscheidungssituationen festgelegte Torwechsel-Strategie bringt "insgesamt" einen 2:1-Vorteil. Allerdings können durch einen asymmetrischen Spielverlauf Entscheidungssituationen entstehen, bei denen ein Torwechsel gegenüber dem Durchschnitt aussichtsreicher beziehungsweise weniger aussichtsreich ist. Solche Effekte sind im Hinblick auf eine asymmetrische Wahrscheinlichkeitsverteilung bei der Auslosung des Gewinntors offensichtlich, aber sie können, wie die Ergebnisse für den "faulen Moderator" zeigen, auch durch ein asymmetrisches Moderatorverhalten verursacht werden. Beim Moderatorverhalten sind allerdings die möglichen Abweichungen für die Gewinnwahrscheinlichkeit beim Torwechsel vom A-Priori-Wert 2/3 nach unten begrenzt, da der Wert 1/2 nicht unterschritten werden kann, denn „Wechseln ist nie schlechter als Bleiben“ – siehe oben.

Auch wenn die „klassische“ vos-Savant-Lösung übereinstimmend mit der Lösung für den "ausgeglichenen Moderator" für einen Torwechsel einen 2:1-Vorteil vorhersagt, sind ihre Betrachtungswinkel und Argumente doch sehr unterschiedlich: Einmal wird eine A-Priori-Wahrscheinlichkeit für die Situation unmittelbar "vor" der Entscheidung des Moderators für ein zu öffnendes Tor angegeben. Das andere Mal bezieht sich die Wahrscheinlichkeit auf den Zeitpunkt, wenn der Moderator „sein“ Tor bereits geöffnet hat, wobei allerdings die Zusatzannahme gemacht wird, dass der Moderator seine Auswahl gleichwahrscheinlich getroffen hat. Der Umstand, dass beide Ansätze die gleiche Gewinnwahrscheinlichkeit liefern, folgt aus einer Symmetriebetrachtung, die den A-Posteriori-Wert aus dem A-Priori-Wert herleitet.

Mit unterschiedlichen Annahmen über die Wahrscheinlichkeit, mit der der Moderator eine bestimmte Ziegentür öffnet, wenn der Kandidat die Autotür gewählt hat, lassen sich für den jeweiligen Einzelfall auch unterschiedliche Gewinnwahrscheinlichkeiten errechnen. Dieser Aspekt wurde von einigen Autoren als Ausgangspunkt spieltheoretischer Untersuchungen des Ziegenproblems genommen. Dabei wird die Zusatzannahme über diese Wahrscheinlichkeit als gemischte Strategie im Sinne eines Zwei-Personen-Spiels aufgefasst, das sogar Nullsummencharakter besitzt. Einbezogen in den sequentiellen Spielablauf wird auch das Verstecken des Autos, das als erster Zug des Moderators gewertet wird. Mit einem einfachen Argument, das für beide Spieler naheliegende, in Bezug auf die Tore symmetrische Strategien verwendet, konnte Gill zeigen, dass der Minimax-Wert 2/3 beträgt.

Die Menge der Minimax-Strategien für beide Spieler wurde von Gnedin bestimmt. Dabei besitzt der Kandidat nur eine einzige Minimax-Strategie, bei der er sein zuerst gewähltes Tor gemäß einer Gleichverteilung auslost und anschließend immer das Tor wechselt. Die Aussage ist insofern bemerkenswert, da sie ohne A-Priori-Annahme über das Verhalten des Moderators auskommt und trotzdem Aussagen für jede einzelne im Spiel auftauchende Entscheidungssituation macht. Ein noch stärkeres Argument für den Kandidaten, nie das anfangs gewählte Tor beizubehalten, ergibt sich aus Gnedins Dominanz-Analysen für Strategien.

Neben den oben dargestellten Interpretationen „des“ Ziegenproblems gibt es noch weitere Varianten, die in der Fachliteratur untersucht wurden. Generell ist dazu anzumerken, dass bei den Autoren – wie schon im Hinblick auf die oben dargestellten Interpretationen – kein Konsens darüber besteht, welches mathematische Modell „dem“ Ziegenproblem und seiner Fragestellung entspricht. Teilweise dienen die Modelle auch nur dem Zweck eines erläuternden Vergleichs:

Lucus, Rosenhouse, Madison und Schepler sowie Morgan et al. analysieren unter anderem auch die Variante, bei der der Moderator sein Tor zufällig unter den "beiden" verbliebenen Toren wählt und dabei gegebenenfalls auch das Tor mit dem Auto öffnet. Eine kurze Berechnung bestätigt die auch intuitiv naheliegende Vermutung, dass für diese Variante in dem Fall, dass ein Tor mit Ziege geöffnet wird, die Gewinnwahrscheinlichkeit beim Wechseln 1/2 beträgt.

Georgii lässt in einer der zwei von ihm untersuchten Varianten auch zu, dass der Moderator das zuerst vom Spieler gewählte Tor mit einer Ziege öffnet. Wenn der Moderator dabei zufällig mit gleicher Wahrscheinlichkeit zwischen den beiden Ziegentoren auswählt, beträgt die Gewinnwahrscheinlichkeit bei einem Wechsel entsprechend der „Antwort der Kritiker“ auch dann 1/2, wenn er ein nicht gewähltes Ziegentor öffnet.

Das US-amerikanische Filmdrama 21 (2008) thematisiert das Ziegenproblem als Aufreißer für eine von zwei mathematischen Strategien, mit denen im Verlauf des Films große Geldsummen beim Black-Jack-Spielen erbeutet werden.

Jamie Hyneman und Adam Savage untersuchen in Episode 177 "Mythen ohne Ende" ihrer Dokumentarserie "Mythbusters" das Ziegenproblem. Dabei wurden die beiden Behauptungen, dass (1) Personen dazu neigen, bei ihrer ersten Wahl zu bleiben und (2) dass das Ändern der ursprünglichen Entscheidung die Gewinnchance signifikant erhöht, bestätigt.

Im Rahmen ihrer Mitarbeit bei Wikipedia fanden W. Nijdam und Martin Hogbin 2010 einen Fehler in der damals knapp 20 Jahre alten Arbeit von Morgan et al. Demnach ist, wenn eine nicht-informative A-priori-Verteilung für das Moderatorverhalten zugrunde gelegt wird, die Gewinnwahrscheinlichkeit beim Torwechsel 2/3 und nicht formula_19, wie Morgan et al. berechnet hatten. Die Bestätigung dieses Sachverhalts nutzten Morgan et al., um erstmals die originale Fragestellung aus Craig F. Whitakers Leserbrief an Marilyn vos Savant zu veröffentlichen.





</doc>
<doc id="5771" url="https://de.wikipedia.org/wiki?curid=5771" title="Zwergpinguin">
Zwergpinguin

Der Zwergpinguin ("Eudyptula minor") ist die kleinste Art aus der Familie der Pinguine (Spheniscidae). Die Vögel werden gewöhnlich 35 bis 40 Zentimeter groß und wiegen etwa ein Kilogramm. Die durchschnittliche Lebenserwartung liegt bei 7 Jahren. Der aktuelle Bestand wird auf etwa 1,2 Millionen Individuen geschätzt.

Das Hauptverbreitungsgebiet des Zwergpinguins ist Neuseeland. Dort heißen sie "little blue penguins" oder einfach nur "blue penguins". In der Sprache der Māori heißen sie "Kororā". Es finden sich zahlreiche Kolonien rund um Neuseelands Nord- und Südinsel, auf Stewart Island sowie den Chatham-Inseln. Der Zwergpinguin ist außerdem die einzige Pinguinart, die auf dem australischen Festland brütet. Brutkolonien finden sich entlang Australiens Südküste und auf Tasmanien. In Australien werden sie nur "little penguins" oder "fairy penguins" genannt. Sie sind nicht sehr scheu und brüten manchmal unter Wohnhäusern.

Zwergpinguine ernähren sich von Fischen (vornehmlich Heringsartige, in Neuseeland z. B. "Sprattus antipodum"), Tintenfischen und kleineren Krebstieren. Dazu unternehmen sie ausgedehnte Jagd- und Tauchzüge, die allerdings nicht allzu weit entfernt von ihren Brutkolonien stattfinden. Dabei erreichen sie Tauchtiefen von bis zu 70 Metern und eine durchschnittliche Schwimmgeschwindigkeit von 7 km/h. Sie jagen tagsüber, aber sie füttern ihre Jungen bei Nacht.

Sie leben das ganze Jahr über in großen Kolonien. Sie nisten in Felsspalten, unter Baumwurzeln oder in Erdlöchern. In Neuseeland sind an zahlreichen Orten auch Nistkästen installiert, die von den Pinguinen als Brutstätte verwendet werden. Die Brutzeit ist variabel und kann sich von Mai bis März erstrecken. Aus zwei gelegten Eiern schlüpfen nach 33 bis 39 Tagen Brutzeit die Küken. Nach etwa sechs Wochen werden die Küken flügge. Je nach Beginn der Brutsaison kommt es vor, dass ein Paar – nachdem die ersten Küken das Nest verlassen haben – ein zweites Gelege großzieht. Während der Brut kehren die adulten Pinguine in der Abenddämmerung in ihre Kolonien zurück, um die Jungen zu füttern.

Der Zwergpinguin wurde 1781 durch den deutschen Naturforscher Johann Reinhold Forster beschrieben und 1856 durch den italienischen Zoologen Charles Lucien Bonaparte der neu eingeführten Gattung "Eudyptula" zugeordnet, die seitdem meist als monotypisch gilt, d. h. der Zwergpinguin ist die einzige Art der Gattung. Ein DNA-Vergleich von verschiedenen genetischen Markern zeigt jedoch, dass es sich beim Zwergpinguin eigentlich um eine Superspezies mit zwei kryptischen Arten handelt, eine neuseeländische Art und eine weitere die an der Südküste Australiens vorkommt. Hybridisierungen zwischen den beiden Arten finden nur in Ausnahmefällen statt.

Der durchschnittliche Sequenzunterschied zwischen den australischen und den neuseeländischen Zwergpinguinen liegt bei 3,8 %, während sie lediglich 0,8 % beim Vergleich von Brillenpinguin ("Spheniscus demersus") und Magellan-Pinguin ("S. magellanicus") beträgt und nur bei 1,5 % beim Vergleich von Felsenpinguin ("Eudyptes chrysocome") und Nördlicher Felsenpinguin ("E. moseleyi") liegt. Für die neuseeländischen Zwergpinguine wird weiterhin der wissenschaftliche Name "Eudyptula minor" zu Verfügung stehen, da die Typuslokalität der Art der Dusky Sound im Fiordland im Südwesten der Südinsel ist. Für die australische Art wird der wissenschaftliche Name Eudyptula novaehollandiae vorgeschlagen. Typuslokalität ist Port Jackson bei Sydney.

Die beiden Arten geben auch unterschiedliche Rufe von sich und zeigen ein unterschiedliches Verhalten. Die australische Art kommt bevorzugt nach Anbruch der Dämmerung in Gruppen an Land, ein Verhalten das in Neuseeland nur an der Küste von beobachtet wurde. Die Population an der Küste von Otago gehört genetisch zur australischen Art. Sie hat sich wahrscheinlich vor einigen tausend Jahren an diesem neuseeländischen Küstenabschnitt angesiedelt. Möglicherweise hat sich das Verhalten der australischen Art entwickelt um eine Begegnung mit Raubbeutlern zu vermeiden. Die neuseeländischen Zwergpinguine brüteten vor Ankunft des Menschen auf einer Insel auf der es keine landlebenden Raubtiere gab. Im Unterschied zur neuseeländischen Art brüten die australischen Zwergpinguine, abhängig vom Nahrungsangebot und von der Temperatur des Oberflächenwassers, nach einer erfolgreichen ersten Brut oft ein zweites Mal.

Auf Phillip Island südöstlich von Melbourne kann diese nächtliche „Pinguin-Parade“ in touristischer Open-Air-Theater-Atmosphäre beobachtet werden. Die Tiere lassen sich von der Beleuchtung und den Touristen offenbar nicht stören. Ähnliche Wanderungen lassen sich auch an anderen Stellen der australischen Südküste beobachten, allerdings ohne touristische Aufbereitung einerseits und Eintrittsgelder andererseits. Die bekannteste Alternative befindet sich bei den Zwölf Aposteln an der Great Ocean Road. Die Pinguine kommen jeden Tag zum Sonnenuntergang und spazieren in Gruppen über den Strand. In der Regel kommen etwa 400 Pinguine, teilweise aber auch über 1000. Eine weitere Beobachtungsmöglichkeit bietet sich am St. Kilda Pier in Melbourne. Das neuseeländische Pendant findet sich in Oamaru, die "Oamaru Blue Penguin Colony".

Zu den wichtigsten natürlichen Feinden des Zwergpinguins zählen der Australische Seelöwe, der Neuseeländische Seelöwe sowie der Neuseeländische Seebär und die in den dortigen Gewässern vorkommenden Haie.

Obwohl die Art insgesamt nicht gefährdet ist, sind Kolonien in Gebieten mit intensiverer menschlicher Aktivität von Verschmutzung und verwilderten Haustieren bedroht.

Seit Anfang 2018 sind mehrere Tausend Zwergpinguine hauptsächlich an der Ostküste Neuseelands, u. a. in der Bay of Plenty-Bucht, meistens bereits tot angeschwemmt worden. Forscher sehen die Auswirkungen von La Niña als mögliche Todesursache. Laut dem Pinguin-Experten Graeme Taylor gab es in Neuseeland zuletzt 1998 ein derartiges Massensterben.



</doc>
<doc id="5772" url="https://de.wikipedia.org/wiki?curid=5772" title="Bürgergesellschaft">
Bürgergesellschaft

Unter Bürgergesellschaft oder "Zivilgesellschaft" wird in den westlichen Demokratien eine Gesellschaftsform verstanden, welche durch die aktive Partizipation ihrer Mitglieder am öffentlichen Leben gestaltet und weiterentwickelt wird. Getragen wird die Bürgergesellschaft durch das Engagement ihrer Akteure, der Bürger.

Historisch hat sich die Bürgergesellschaft mit Überwindung des Absolutismus als eines politischen Systems ohne gesellschaftliche Mitwirkungsrechte entwickelt. Zentrale Forderung des Verfassungsliberalismus und der Idee der Menschenrechte war die vor staatlicher Einmischung geschützte individuelle Handlungsfreiheit in einer vom Staat unabhängigen Gesellschaft.

Sozialwissenschaftliche Konzepte des ausgehenden 20. Jahrhunderts fordern die permanente Mitsprache einer kritischen Öffentlichkeit bei politischen Entscheidungen (deliberative oder partizipatorische Demokratie).

Der Begriff der Bürgergesellschaft oder "Zivilgesellschaft" hängt in der politischen und wissenschaftlichen Diskussion eng zusammen mit dem Begriff der bürgerlichen Gesellschaft. Er knüpft an den Begriff der "politiké akoionia" (Polis) aus der politischen Philosophie des Aristoteles an, später übersetzt ins Lateinische als "societas civilis" sowie "société civile" (frz.) und "civil society" (engl.).

Prägend für das heutige Begriffsverständnis ist vor allem die Vorstellung der englischen "civil society", die seit der Aufklärung einen fortschreitenden Prozess der Zivilisierung durch Arbeit und wirtschaftliche Entwicklung, durch Bildung und Kultur sowie die Überwindung althergebrachter Beschränkungen durch Status und Geburt umfasst sowie die Überzeugung von der zivilisierenden Wirkung der freiwilligen Zusammenschlüsse in Vereinigungen.

Damit bezeichnet der Begriff der Bürgergesellschaft auch heute ganz vorwiegend einen politischen Prozess. Die Bürgergesellschaft wird regelmäßig nicht statisch als bereits bestehendes System, sondern dynamisch als Zielperspektive zur Fortentwicklung politisch-gesellschaftlicher Ordnungen angesehen. Bürgergesellschaft beschreibt somit keinen Zustand, sondern einen Prozess hin zu einer umfassenderen demokratischen Teilhabe auf der Basis von Eigeninitiative und Selbstorganisation außerhalb von unmittelbaren staatlichen und wirtschaftlichen Institutionen.

Die älteste buchliche Überlieferung des Begriffs der Bürgergesellschaft stammt von Adam Ferguson. In seinem 1768 veröffentlichten "Versuch über die Geschichte der bürgerlichen Gesellschaft" erörtert er das Verhältnis von individueller Tugendhaftigkeit innerhalb und der Gesamtentwicklung der betroffenen Gesellschaft. Ferguson kommt zu dem Schluss, dass Tugendhaftigkeit Voraussetzungen hat, die durch die Ergebnisse der Tugendhaftigkeit nicht automatisch in ihrem Bestand gesichert sind oder sogar gefährdet werden können.

Im Deutschen taucht in Anlehnung an Ferguson zunächst die Übersetzung als bürgerliche Gesellschaft bei Georg Wilhelm Friedrich Hegel in seinen „Grundlinien der Philosophie des Rechts“ von 1821 auf. Hegel beschreibt mit dem Begriff der bürgerlichen Gesellschaft in seinem System der Dialektik die Wechselwirkung zwischen der Privatsphäre einerseits, welche für Hegel durch die Familie verkörpert wird, und der Gesamtgesellschaft andererseits, welche durch den Staat verkörpert wird. Hegel beschreibt wie Ferguson keine originär politische, sondern eine sittliche Kategorie.

Im kommunistischen Manifest von 1848 beschreiben Friedrich Engels und Karl Marx die "bürgerliche Gesellschaft" nicht als sittliche, sondern als ökonomische Kategorie. Für Engels und Marx ist die "bürgerliche Gesellschaft" durch Produktionsbedingungen gekennzeichnet, welche durch eine strikte Trennung von Kapital und Arbeit bestimmt werden. Die bürgerliche Gesellschaft gilt bei Engels und Marx zwar als Fortschritt gegenüber dem Feudalismus, gleichzeitig aber auch nur als zu überwindendes historisches Übergangsstadium zum Sozialismus und schließlich zum Kommunismus.

In der Gettysburg Address von 1863 beschrieb der damalige Präsident der Vereinigten Staaten Abraham Lincoln die ideale amerikanische Demokratie als "government of the people, by the people, for the people".

Willy Brandt wollte nach seiner Wahl zum deutschen Bundeskanzler im Jahr 1969 "mehr Demokratie wagen" im Sinne einer "Demokratisierung der Demokratie".

Soweit der Begriff der Bürgergesellschaft nicht als Synonym zur Zivilgesellschaft verwendet wird, wird zur Unterscheidung auf die Entstehung und Funktion der Zivilgesellschaft verwiesen. Eine klare definitorische Unterscheidung existiert jedoch nicht.

In Westeuropa vermittelt sich die Zivilgesellschaft über ein Kollektivbewusstsein, das der Gesellschaft den Zusammenhalt ermöglicht und Verunsicherungen, die mit dem Prozess eines ideologischen Ökonomismus, dem Abbau des Sozialstaats und der Globalisierung einhergehen, durch Selbstorganisation, Freiwilligkeit, Eigenverantwortung, Vertrauen und solidarische Unterstützung, aber auch Traditionsbewußtsein und Nationalgefühl abfedern kann.

Kreise, die eine nichtstaatliche Ordnung bereits etabliert haben oder nach dem Konzept des schlanken Staates befürworten, bevorzugen den Begriff der Bürgergesellschaft. Dies betrifft sowohl den Bereich der Kirchen als auch liberale und konservative Parteien. Mit der Verwendung des Begriffs der Bürgergesellschaft wird der historische Bezug zur bürgerlichen Gesellschaft des 19. Jahrhunderts zum Ausdruck gebracht und die Entwicklung zu einer sich selbst steuernden Gesellschaft, in die der Staat nicht oder jedenfalls nur bei erkennbaren Defiziten der Selbstorganisation eingreifen soll.

Teilweise wird der Zivilgesellschaft eine bloß subsidiäre Funktion zugewiesen. Nach diesem Verständnis übernimmt die Zivilgesellschaft Aufgaben, welche durch staatliche Institutionen nicht oder nicht hinreichend erfüllt werden. Die Bürgergesellschaft hingegen erhebt den Anspruch, selbst einen eigenen Ordnungsrahmen darzustellen. Nach diesem Verständnis beinhaltet der Begriff der Bürgergesellschaft den Begriff der Zivilgesellschaft, geht aber über diesen hinaus. Ziel der Bürgergesellschaft ist somit nicht nur das Nutzen von staatlichen Freiräumen und die Erfüllung gemeinnütziger Aufgaben, sondern darüber hinaus auch die Gestaltung des politischen Ordnungsrahmens.

Wo soziale Bewegungen gegen kapitalistisches Marktkalkül und autoritäre Herrschaftsansprüche betont werden sollen wie in der osteuropäischen Dissidentenbewegung oder Bestrebungen gegen die Militärdiktaturen in Lateinamerika, Afrika und Asien, wird heute meist der Begriff der Zivilgesellschaft verwendet. Viele Nichtregierungsorganisationen bevorzugen den Begriff der Zivilgesellschaft und fordern damit einhergehend entweder eine staatliche Übernahme der von ihnen bisher erfüllten Aufgaben oder zumindest eine aktive staatliche Unterstützung für ihre zivilgesellschaftliche Aufgabenerfüllung.

Mitunter wird der Begriff der Bürgergesellschaft auch als Zusammenfassung ehrenamtlichen Engagements verwendet.

Die Globalisierung, die Auswirkungen der digitalen Revolution auf den Arbeitsmarkt (das sog. Ende der Arbeit) und die Wissensgesellschaft werden als wesentliche Aspekte einer gesellschaftlichen Entwicklung verstanden, die dem einzelnen eine zunehmende Individualisierung sowohl ermöglicht als auch abverlangt. Die Bürgergesellschaft beschreibt danach das Verhältnis von Staat, Wirtschaft, Gesellschaft und dem einzelnen Bürger unter diesen sich wandelnden Bedingungen.

Mit einer Betonung nationalstaatlicher Außen- und Sicherheitspolitik in der Berliner Republik geht eine zunehmende Angleichung der Lebensgewohnheiten in Städten und ländlichen Regionen (funktionale Verstädterung) einher. Bundesweit ist die Motivation in der Bevölkerung gestiegen, auf regionaler und lokaler Ebene politische Entscheidungen mitzubestimmen. Folge ist eine "neue Subsidiaritätsordnung", in der die Bürger zunehmend "für sich selbst sorgen". Das schließt auch das Verhalten auf dem Arbeitsmarkt ein, der mit der Agenda 2010 das Leitbild des "Unternehmers in eigener Sache" (Ich-AG) hervorgebracht hat. Der computergestützte Zugang zu umfassenden Informationen im Internet und deren Organisation, etwa in Open Source-Projekten stellt die Legitimation der auf Herrschaftswissen basierenden repräsentativen Demokratie in Frage.

Die Bürgergesellschaft ist heterogen strukturiert und besteht aus einer Vielzahl auf freiwilliger Basis gegründeter, auch konkurrierender Organisationen - im Einzelfall auch einzelnen Bürgern - die ihre unterschiedlichen Interessen artikulieren und autonom organisieren (Nichtregierungsorganisationen). Sie ist im Zwischenbereich von Privatsphäre und Staat angesiedelt. Die Akteure der Zivilgesellschaft sind damit zwar in die Politik involviert, ohne jedoch nach staatlichen Ämtern zu streben. Entsprechend sind Gruppen, die ausschließlich private Ziele verfolgen wie Familien oder Unternehmer ebenso wenig Teil der Bürgergesellschaft wie politische Parteien, Parlamente oder staatliche Verwaltungen. Die Bürgergesellschaft stellt ein pluralistisches Sammelbecken höchst unterschiedlicher Akteure wie den neuen sozialen Bewegungen einschließlich der Kirchen dar, die jedoch einen bestimmten methodischen Minimalkonsens teilen, insbesondere die Gewaltlosigkeit.

Ralf Dahrendorf beschrieb die Bürgergesellschaft als das "schöpferische Chaos der vielen, vor dem Zugriff des (Zentral-)Staates geschützten Organisationen und Institutionen". Die Bedeutung der Bürgergesellschaft liege in der Steigerung der Lebenschancen der Menschen, indem sie die Lücke zwischen staatlichen Organisationen und den Individuen schließe und dem Zusammenleben der Menschen Sinn gebe. Während der Markt die Angebotsseite steuere und der Rechtsstaat die Zugangschancen garantiere, sei es Aufgabe der Bürgergesellschaft, die Menschen in die Lage zu versetzen, zwischen den sich ihnen bietenden Optionen eine Auswahl zu treffen (Multi-Optionsgesellschaft).

Die Bürgergesellschaft ist somit eine politische Ordnung, in welcher Demokratie ausgehend von der Eigeninitiative der Bürger wahrgenommen wird. Dieser Ansatz soll demokratische Beteiligung gerade auch über die Teilnahme an Wahlen und Abstimmungen hinaus ermöglichen. In der Bürgergesellschaft stehen Gruppierungen im Vordergrund, die sich nicht auf aktuelle caritative und wohltätige Aufgaben beschränken, sondern darüber hinaus den Anspruch erheben, auf die gesellschaftliche Entwicklung gestalterisch Einfluss zu nehmen.

Wesentliche Bedingung für die Bürgergesellschaft ist das Primat der Politik, um eine Wechselwirkung zwischen Bürgern und Staat zu gewährleisten. Ein Beispiel ist die gesetzliche Verankerung neuer Partizipationsformen wie die der Volksentscheide in den Bundesländern und Gemeinden.

Rund 90 % der dem Begriff Zivilgesellschaft zugeordneten Tätigkeiten entfallen auf die Bereiche Gesundheits-, Veterinär- und Sozialwesen, Erziehung und Unterricht, Kultur, Sport und Unterhaltung sowie Interessenvertretungen, kirchliche und sonstige Vereinigungen. Zu den historisch bedeutsamsten Handlungsfeldern gehören die Umweltbewegung, die Arbeiter- und Frauenbewegung sowie die Bewegung gegen die militärische und die zivile Nutzung der Kernenergie (Kampf dem Atomtod, Anti-Atomkraft-Bewegung).

Die Bürgergesellschaft bedient sich der Instrumente der direkten Demokratie und der Bürgerbeteiligung. Organisationsformen sind z. B. Bürgerinitiativen, Nachbarschaftsinitiativen oder sog. Zukunftswerkstätten. Ausdrucksformen sind Demonstrationen, Petitionen, Bürgerbegehren und Verbandsklagen, die formelle Beteiligung in der Bauleitplanung und an Planfeststellungsverfahren, aber auch Arbeitskämpfe, Tauschkreise, Selbsthilfegruppen oder das Vereins- und Stiftungswesen bis hin zum Whistleblowing. Insofern ist die Bürgergesellschaft auch Ausdruck eines gewachsenen politischen Selbstbewußtseins und Antwort auf ein wahrgenommenes Demokratiedefizit in der Postdemokratie.

Die Meinungsbildung gegenüber Parteien und Parlamenten vollzieht sich zunehmend in sozialen Netzwerken, insbesondere im Internet.

Unter den Stichworten „motivierender Staat“, „moderierender Staat“ und „aktivierender Staat“ ("enabling state") wird dem Staat die Rolle eines Ausgleichs zwischen seiner eigenen hierarchischen Steuerung, marktlichem Wettbewerb und gesellschaftlicher Selbstverantwortung zugedacht. Da privatwirtschaftliche Marktmechanismen allein die dadurch hervorgerufenen Probleme wie Massenerwerbslosigkeit, Armut und soziale Ungleichheit vernachlässigen, soll der Staat einerseits gewisse soziale Standards gewährleisten, andererseits aber auch für die Erschließung neuer Märkte sorgen.

Mit dem Verhältnis von staatlicher Regulierung, ökonomischem Wettbewerb und gesellschaftlicher Teilhabe sowie dessen Auswirkungen beschäftigt sich die Governance-Diskussion.

In ihrem Bericht aus dem Jahr 2002 hat die Enquete-Kommission des Deutschen Bundestages rechtspolitische Handlungsempfehlungen zur Zukunft des bürgerschaftlichen Engagements entwickelt, die staatliche Institutionen (Verwaltungsreform) und die Wirtschaft (Corporate Citizenship) mit einbeziehen.

Theoretisch wird die Mehrebenendemokratie in der Europäischen Union, die aus der europäischen Administration und den Mitgliedsstaaten besteht, zu einem Staatsmodell für die Bürgergesellschaft weiterentwickelt. Der überkommene Nationalstaat auf mittlerer Ebene soll den Vollzug der auf der obersten Ebene durch einen europäischen Verfassungsstaat getroffenen Entscheidungen gewährleisten, indem er die "kleine Lebens- und Verantwortungspolitik" auf der untersten Ebene, in der Bürgergesellschaft, vernetzt und moderiert. Wesentliche Kennzeichen dieser Ordnung sind Föderalismus, Subsidiarität und der Wettbewerb um Lösungen. Der Staat wird dabei als "neutral" gedacht, der gesellschaftliche Zusammenhalt werde durch das Bewusstsein einer umfassenden wechselseitigen Abhängigkeit und gemeinsamer Herausforderungen, die nur kooperativ bewältigt werden könnten ("self-reliance"), gewahrt.

Nach der marxistischen Theorie Antonio Gramscis stehen sich Staat („società politica“) und Bürgergesellschaft („società civile“) nicht als zwei verschiedene Größen gegenüber, sondern greifen ineinander. Der Staat bediene sich der Bürgergesellschaft zum eigenen Machterhalt, indem er in den Institutionen der Bürgergesellschaft wie Schulen, Universitäten, Kirchen, Vereinen, Gewerkschaften und Massenmedien Zustimmung ("Konsens") zum staatlichen Zwangsapparat organisiere. Durch Hegemonie und Konsens bilde sich eine wirkliche und dauerhafte Einheit von Basis und Überbau, entstehe ein „integraler Staat“.

Der bürgerliche Rechtsstaat hat indessen gerade die historische Funktion, Gleichheit und Autonomie als Voraussetzung einer wirksamen Zivilgesellschaft zu gewährleisten und steht mit der Bürgergesellschaft "in einer lebendigen Wechselwirkung".

Theoretisch wird die Konzeption der Bürgergesellschaft, in der es nur schlichte „Bürger“ gibt, angezweifelt. Der Begriff „Bürgergesellschaft“ verschleiere die realen gesellschaftlichen Interessengegensätze und konstatiere einen fiktiven Volonté générale. In der Gestalt des „Bürgers“ scheine der Gegensatz von „Bourgeois“ und „Citoyen“, der die politischen Prozesse in der liberalen Demokratie entscheidend geprägt und maßgebend ihre Krisenhaftigkeit bestimmt habe, aufgehoben.

Tatsächlich verberge sich hinter der staatlichen Forderung nach ehrenamtlichem Engagement und "Zivilcourage" ein Paternalismus alter Prägung, der sich als unpolitisch ausgebe und im Konzept der Bürgergesellschaft sowohl das Bestreben nach politischer Partizipation und Demokratisierung unterschlage als auch durch subtile Steuerungsmechanismen (Nudging) eine tatsächlich nicht gegebene Freiwilligkeit vortäusche.

Ebenso werde die Steuerungsmacht der kapitalistischen Ökonomie ausgeblendet, wenn man das Konzept der Bürgergesellschaft auf eine rein soziale Dimension reduziere. Die Bürgergesellschaft bleibe ohne Betrachtung der wirtschaftlichen Rahmenbedingungen unvollständig, zumal etwa die Bewegung gegen Sozialabbau in Deutschland eine unmittelbare Reaktion auf die wirtschaftspolitische Agenda 2010 darstellt. Politik und Wirtschaft räumten der globalen Wettbewerbsfähigkeit oberste Priorität ein und zerstörten damit die moralische Legitimität der sozialen Ordnung.

Aufgaben, die der Staat im Interesse der Haushaltskonsolidierung nicht mehr wahrnehmen wolle, würden an die Bürgergesellschaft als Reparaturbetrieb delegiert. Gerade dort, wo soziales Engagement am dringendsten nötig wäre, sei es jedoch am wenigsten vorzufinden. Während in bevorzugten Wohngebieten regelmäßig auch das gesellschaftliche Leben und die Vereinstätigkeit sehr stark ausgeprägt sind, findet in benachteiligten Wohngebieten sowohl die karitativ-gemeinnützige Aufgabenerfüllung als auch die Einbindung der Bevölkerung in gesamtgesellschaftliche Zusammenhänge nur unzureichend statt. Die Worte des amerikanischen Präsidenten John F. Kennedy aus seiner Amtsantrittsrede im Jahr 1961 "Frage nicht, was Dein Land für Dich tun kann, frage lieber, was Du für Dein Land tun kannst" werden als Absage an das im Grundgesetz verankerte Sozialstaatsprinzip verstanden.

Schließlich wird in einer zu großen Einflussnahme von einzelnen Gruppen auf die politische Ordnung in Gestalt des Lobbyismus und Exklusionsmechanismen wie des historisch bedingt ungleichen Zugangs zu diesen Gruppen, insbesondere nur für Männer eine Gefährdung demokratischer Grundprinzipien erkannt, wonach die Gleichheit aller Bürger gerade durch das allgemeine Wahlrecht sichergestellt wird.

Eine glaubwürdige Dezentralisierung politischer Entscheidungen und Anpassung an regionale bzw. lokale Traditionen und Ressourcen werden gegenüber einer schwerfälligen Bundespolitik und im Hinblick auf ein bürgernahes Europa dagegen als politischer Steuerungsgewinn betrachtet.

Die Entwicklung und Verbreitung des Begriffes der Zivilgesellschaft ist in Mittel- und Osteuropa stark mit dem Zerfall des Kommunismus verbunden. Es waren zunächst die Bürgerrechtsbewegungen in Polen, der Tschechoslowakei, Ungarn und Bulgarien, die die Möglichkeiten zur Schaffung und Ausweitung der gesellschaftlichen Sphäre in außerstaatlichen Organisationen und Vereinigungen im Kampf gegen die starre Parteibürokratie, sowie die Zielvorstellung einer gesellschaftlichen Transformation (Perestroika) mit dem Begriff der "zivilen Gesellschaft" bezeichneten.

Die Transitionsprozesse beispielsweise in der arabischen Welt (Arabischer Frühling) zielen zwar auf die Entwicklung demokratischer Strukturen wie Mehr-Parteien-Systeme, Bürgerrechte und Rechtsstaatlichkeit ab, folgen jedoch angesichts kultureller, religiöser, sozialer und wirtschaftlicher Besonderheiten (Rentierstaaten) eigenen Regeln und können nicht mit der Ausprägung einer Zivilgesellschaft nach westlichem Verständnis gleichgesetzt werden.




</doc>
<doc id="5774" url="https://de.wikipedia.org/wiki?curid=5774" title="Zeichen">
Zeichen

Ein Zeichen ist im weitesten Sinne etwas, das auf etwas anderes hindeutet, etwas bezeichnet.

Zeichentheoretiker sehen darin ein semiotisches Phänomen und bestimmen im engeren Sinne Zeichen als eine Unterklasse dieses Phänomens. Dort stehen Zeichen anderen semiotischen Phänomenen wie den Symbolen und Anzeichen (vgl. Index, Signal) gegenüber. Sprachzeichen sind Grundelemente einer Sprache.

"Zeichen" ist dabei allgemein etwas Unterscheidbares, dem eine Bedeutung zugesprochen wird; ein "sprachliches Zeichen" als Grundelement eines Kommunikationssystems (also auch Gesten, Gebärden, Laute, Markierungen auch Symbole).

"Zeichen" kommt aus indogermanisch "dei" für „hell glänzen“, „schimmern“, „scheinen“, und wird im Althochdeutsch zu "zeihhan" „Wunder“, „Wunderzeichen“. Dem deutschen Wort liegt ursprünglich die irdische Erscheinung einer höheren Macht zugrunde.

Das Wort „Zeichen“ kann entsprechend bedeuten:

Einen "einseitigen" Zeichenbegriff vertraten nicht nur Ogden/Richards, sondern schon die klassische Zeichentheorie. Geht man davon aus, dass ein Zeichenkörper nicht direkt, sondern nur auf Grund einer Vermittlungsinstanz {Vorstellung, Begriff, Gebrauch} etwas Außersprachliches bezeichnet, kann diese dreistellige Relation als semiotisches Dreieck veranschaulicht werden.

Einen "zweiseitigen (bilateralen)" Zeichenbegriff vertrat (nach herrschender Vorstellung) "de Saussure": das Zeichen als psychische Einheit, bestehend aus einer Ausdrucksseite "(signifiant)" und aus einer Inhaltsseite "(signifié)", wie zwei Seiten eines Blatts Papiers. Nach anderer Auffassung soll de Saussure den Ausdruck „Zeichen“ auch zur Bezeichnung des Signifikanten allein verwendet haben (Zeichen i. S. v. [1.]). Dann ist unklar, ob de Saussure "Zeichen" im Sinne von [1.] [2.] oder im Sinne einer Kombination von beiden verwendet.

Definiert man das Zeichen so als "psychische Einheit", dann wird der Bezug auf die Wirklichkeit Referenz und der pragmatische zu den Sprachbenutzern ausgeblendet.

Zeichen ist im weitesten Sinn alles, was für etwas anderes steht; was als „zuvor Erkanntes zur Erkenntnis eines anderen führt“, „eine andere Gegebenheit … repräsentiert bzw. diese bezeichnet oder darstellt …“, „irgendetwas, das einem anderen, dem Bezeichneten zugeordnet ist“; das, was zu diesem in einer „Verweisbeziehung“ steht. „Ein Zeichen zeigt etwas an, d. h., es verweist auf etwas, das außerhalb des Zeichens selbst liegt.“ Ein Zeichen „ist alles, was und insofern es dazu dient, etwas anzuzeigen oder kenntlich zu machen“.

Zeichen sind „physikalische Dinge“ (Markierungen mit Tinte auf Papier, Tonwellen etc.). „Was sie zu Zeichen macht, ist die vermittelnde (intermediäre) Stellung, die sie zwischen einem Objekt und einem Zeichenverwender, d. h. einer Person einnehmen.“

Nach Gottlob Frege ist das Zeichen das, was „uns dazu dient, irgendetwas zu bezeichnen, auszudrücken oder zu behaupten“. Es ist „nur ein willkürlich gewähltes Mittel des Gedankenausdrucks, das ganz außerhalb der Betrachtung bleibt. In dieser Stellvertretung liegt der Nutzen der Zeichen“.

Grundlage der Zeichentheorie ist der Grundsatz "aliquid stat pro aliquo" „Etwas steht für etwas“. „Ein Wesensmerkmal eines Zeichens ist demnach seine Stellvertreterfunktion: Ein Zeichen steht per definitionem ‚für etwas anderes‘, es ist also prinzipiell nicht selbstreferentiell.“ Die aliquid-pro-aliquo-Zeichendefinition ist ihrer Formulierung nach ein Grundsatz der mittelalterlichen Scholastik, der Sache nach aber schon bei Aristoteles angelegt.

Schon seit Aristoteles wird vertreten, dass Zeichen Dinge der Welt nicht unvermittelt, sondern vermittelt über einen "Begriff", "Vorstellung" etc. bezeichnen, was eine naive Konzeption überwindet: „Die Sachen werden von den Zeichen nicht präsentiert, sondern repräsentiert.“. Diese Einsicht wird „für die ganze Geschichte der Semiotik entscheidend“

Nach Ferdinand de Saussure ist ein Zeichen die Beziehung (Verbindung) zwischen "Bezeichnetem" (Signifié, Signifikat) und "Bezeichnendem" (Signifiant, Signifikant). Das Bezeichnete entspricht einer Vorstellung oder einem Konzept, das Bezeichnende ist ein Lautbild. Das Lautbild ist auch etwas Gedachtes (also ein psychischer Eindruck und "nicht" die physikalische Schallwelle), da man für sich selber eine Lautfolge gedanklich „aussprechen“ kann, ohne die Lippen zu bewegen. Der Zusammenhang zwischen Bezeichnetem und Bezeichnendem ist beliebig (arbiträr). Beliebig bedeutet hier nicht, dass jede Person frei einen Signifikanten für ein Signifikat aussuchen kann, sondern dass die ursprüngliche Festlegung eines Zeichens unmotiviert ist. Zeichen für die Kommunikation zwischen Menschen bedürfen der „Verabredung“, einer Konvention. Ist das Zeichen erst einmal zur Konvention geworden, bleibt es fest zugeordnet.

Charles S. Peirce entwickelte eine pragmatische Semiotik und erweiterte den dyadischen Zeichenbegriff zu einem spezifischen triadischen Modell. Dies führt zu einer prozesshaften und dynamischen Zeichentheorie.

Peirce definiert das Zeichen als eine triadische Beziehung zwischen einem "Repräsentamen", einem "Interpretanten" und einem "Objekt".

Ein "Repräsentamen" ist ein Zeichenträger (z. B. ein Bild, ein Wort), ein Zeichen im engeren Sinn, „das für jemanden in irgendeiner Hinsicht oder durch irgendeine Eigenschaft für etwas steht.“

Ein "Interpretant" ist ein Gedanke, den der Zeichenträger bei einem Interpreten hervorruft und selbst wieder ein Zeichen (im engeren Sinn) ist.

Mit den Worten Peirce: „Ein Zeichen oder Repräsentamen ist alles, was in einer solchen Beziehung zu einem Zweiten steht, das sein Objekt genannt wird, dass es fähig ist, ein Drittes, das sein Interpretant genannt wird, dahin gehend zu bestimmen, in derselben triadischen Relation zu jener Relation auf das Objekt zu stehen, in der es selber steht. Dies bedeutet, dass der Interpretant selbst ein Zeichen ist, das ein Zeichen desselben Objekts bestimmt und so fort ohne Ende.“

Umberto Eco schlägt vor, "alles" Zeichen zu nennen, was aufgrund einer vorher vereinbarten sozialen Konvention als etwas aufgefasst werden kann, "das für etwas anderes steht". Er übernimmt damit weitgehend die Definition von Charles W. Morris (1938).

In religiösen und spirituellen Zusammenhängen werden unter Zeichen
verstanden.

Ob eine Kommunikationsabsicht zum Zeichenbegriff dazugehört, hängt vom verwendeten Zeichen- wie vom Kommunikationsbegriff ab.

Wenn es heißt: „Jedes Zeichen dient der Verständigung, der Kommunikation“, dann gilt dies für Sprachzeichen. Der semiotische Zeichenbegriff kann weiter sein. Er bezieht auch bloße Anzeichen in den Zeichenbegriff ein (Rauch als Zeichen für Feuer).

Siehe auch unten zur Unterscheidung zwischen indexikalischen und Kommunikationszeichen.

„Arbitrarität und Konventionalisierung sind die beiden zentralen Charakteristika sprachlicher Zeichen.“


Aus der Arbitrarität und Konventionalität von Zeichen folgt ihre "Veränderlichkeit".

Neben der Arbitrarität und Konventionalität wird als dritte kennzeichnende Eigenschaft von Sprachzeichen nach der Theorie von de Saussure die "Assoziativität" der Zeichen angeführt.

Dies setzt eine psychologisch (mentalistisch, kognitiv(istisch)) orientierte Zeichentheorie voraus und beschreibt das Verhältnis von Zeichenform und Zeicheninhalt in psychologischer Perspektive als "assoziativ". Dass, wie das Phänomen der Aphasie zeigt, Zeichenform und Zeicheninhalt "unabhängig voneinander verloren gehen" wird nicht als Widerspruch zu der Behauptung de Saussures von der Untrennbarkeit von Zeicheninhalt und Zeichenausdruck (an-)gesehen.

Zeichen werden immer in einem physischen, sozialen und psychischen "Kontext" aktualisiert ("Situation"), sodass wir das Zeichen verstehen, weil wir es im Rahmen einer Gesamtsituation interpretieren.

Ein Zeichen oder eine Zeichenmenge gehören zu einem bestimmten Zeichensystem (der Chemie, Morsecode, Flaggensignale etc.).

Das (ein) System der Sprachzeichen wird in der Sprachwissenschaft seit Ferdinand de Saussure Langue genannt.

Die Bedeutung eines Zeichens hängt von seiner Stellung im Zeichensystem und dessen Struktur ab. De Saussure verwendete dafür den Ausdruck "valeur" (franz.: Wert), der im Deutschen mit "Wert", "sprachlicher Wert", "Stellenwert eines Zeichens" oder mit "systemischer Wert" wiedergegeben wird.


Nach dem (extremen) Strukturalismus allein davon: „Jedes Zeichen hat einen Wert nur durch seine Opposition zu den anderen Zeichen des Systems. Was hier wichtig ist, ist also nicht die positive Qualität, sondern der differentielle Charakter der Zeichen.“

Zu beachten ist, dass ein Zeichen in verschiedenen systematischen Zusammenhängen stehen und damit „ganz unterschiedliche Werte“ (je nach System im Konkreten) haben kann.

Nach de Saussure kommt einem Zeichen in einem System ein fester Wert „als Produkt differentieller Relationen“ zu.

In der (strukturalistischen) Linguistik werden insbesondere zwei Systemaspekte unterschieden:

Eigenschaft eines Zeichens ist weiterhin seine "Linearität". Diese beruht darauf, dass das Zeichen in der Zeit verwirklicht wird.

Der Ausdruck Symbol wird zum Teil umgangssprachlich mit dem Begriff Zeichen gleichgesetzt.

Fachsprachlich bezeichnet Symbol


Unter dem Einfluss der amerikanischen ist auch in der deutschen Linguistik eine Terminologie von Charles S. Peirce verbreitet, in der zwischen Symbol, Ikon und Index unterschieden wird. Die Terminologie von Peirce für den Ausdruck „Symbol“ widerspricht dabei der europäischen Tradition.

Peirce unterteilt die Zeichen in drei Zeichen-Trichotomien, so dass sich neun Subzeichenklassen und, durch deren Kombination untereinander, zehn Hauptzeichenklassen ergeben. Unter den Subzeichenklassen sind die wohl bekanntesten: Ikon, Index und Symbol. Sie gehören zur zweiten Trichotomie, in der die Objektrelation des Zeichens thematisiert wird.

Die Einteilung ist idealtypisch. In der Wirklichkeit sind Zeichen Kombinationen dieser Grundtypen.

Quer zu der Einteilung der Zeichen in Index, Ikon und Symbol steht die Einteilung in sprachliche und nichtsprachliche – auch verbale und nonverbale – Zeichen. Der Einteilungsgrund ist die Benutzung von Sprache zum Zwecke der Kommunikation.

Die Terminologie ist allerdings nicht einheitlich. Im weiteren Sinn sind nichtsprachliche Zeichen alle Zeichen, die nicht sprachlicher Art sind. Darunter werden paraverbale und nichtsprachliche Zeichen im engeren Sinn ("nonverbale Zeichen") gefasst.

"Paraverbale Zeichen" sind nichtsprachliche Zeichen im weiteren Sinn, die sich in einer sprachlichen Äußerung manifestieren. Gemeint sind damit etwa stimmliche Qualitäten, die mitgeteilte Stimmung (z. B. Angst, Unsicherheit ..).

Nichtsprachliche Zeichen im engeren Sinn sind nichtsprachliche Zeichen, die unabhängig von der Sprache existieren. Dies betrifft z. B. die Gestik, Mimik, die Körperhaltung, im weiteren Sinn auch die Kleidung, die Wohnungseinrichtung, die Frisur oder auch z. B. Verkehrszeichen, Piktogramme.

Zeichen im weiteren Sinn können eingeteilt werden in Zeichen mit Kommunikationsabsicht ("Kommunikationszeichen"; "Zeichen im engeren Sinn"; "Zeichen für") und Zeichen ohne Kommunikationsabsicht ("indexikalische Zeichen" (im engeren Sinn); "Zeichen von").

Dies ist eine idealtypische Unterscheidung, da häufig die Grenze nicht ausmachbar ist (z. B. die Grenze zwischen einem "natürlichen, spontanen Lächeln" und z. B. einem "täuschenden Lächeln").

Zeichen ohne Kommunikationsabsicht werden auch "Indiz" ("Anzeichen", "natürliche", "uneigentliche Zeichen") genannt und sind Indexe (im Sinne von Peirce) oder Symptome (in anderer Terminologie).

Die Unterscheidung setzt voraus, dass man - wie das herrschende Verständnis - für eine Kommunikation eine Absichtlichkeit und damit Gerichtetheit verlangt. Fasst man wie Watzlawick den Kommunikationsbegriff weiter und betrachtet als Kommunikation als Mitteilung und Mitteilung als etwas, was - unabhängig von einer Kommunikationsabsicht - interpretierbar ist, so sind alle Zeichen Kommunikationszeichen.

Charles S. Peirce unterschied bei einem Zeichen "type" und "token". Im Deutschen spricht man unterschiedlich unter anderem von "Muster (oder Typ) - Vorkommnis" oder vom "virtuellen Zeichen - aktuellen Zeichen".

Beispiel: In dem Wort „Hallo!“ hat der Buchstabe l als Muster (type) zwei Vorkommnisse (token).

Das Zeichen als Muster nennt man virtuelles Zeichen, da es eine abstraktive Größe ist, die dem einzelnen Gebrauch zugrunde liegt, realisiert jedoch nicht als solches, sondern nur (in der konkreten Verwendung) als aktuelles Zeichen vorkommt.

Die chinesische Schrift ist der Prototyp einer ikonischen Schrift. Gerade das Beispiel zeigt, dass auch diese konventioneller Festlegungen bedürfen, um Missverständnissen entgegenzuwirken.
Wörter in einer Alphabetschrift bestehen aus Buchstabensequenzen.

Erst das ganze einzelne Wort ist im linguistischen Sinn ein Zeichen, und zwar ein symbolisches. Nicht zu verwechseln mit dem Begriff des Zeichens ist der Begriff des Schriftzeichens (der „Letter“). Letzterer muss nicht einer Bedeutung (Bezeichnetem) zugeordnet sein, sondern ist bei Alphabet- und Silbenschriften einer bestimmten Lautung oder Funktion innerhalb des Schriftsystems zugeordnet. (Im Englischen ist die Unterscheidung eindeutiger: "sign" vs. "character".)

Verwandt mit den Schriftzeichen, aber nur in ihrer Form arbiträr, und weniger in der Funktion, sind die Zahlzeichen. Entgegen der formalen Parallelen zwischen "Ziffer" und "Letter" und "Zahl" und "Wort" übernimmt nur in der elementarsten Mathematik (dem „Zählen“) die Zahl – in Wort, Geste und Schriftzeichen – die Funktion des Zeichens, in der eigentlichen Mathematik (dem „Rechnen“) die Ziffer, die das Zahlensystem repräsentiert.

Mathematische und physikalische Größen (Variable und Konstanten) werden in Rechnungen, aber auch in Texten durch "Formelzeichen" (DIN 1304) gekennzeichnet. Für Rechenvorschriften gibt es "mathematische Zeichen" (DIN 1302). Für konkrete Werte physikalischer Größen, die als Produkt von Zahlenwert und Maßeinheit angegeben werden, gibt es international festgelegte "Einheitenzeichen" (DIN 1301).

Zeichen bilden die Bausteine logischer Kalküle. Deren wesentliche Eigenschaft besteht gerade darin, dass logische Schlussregeln ausschließlich auf zeichenhaften Formeln ausgeführt werden. Bestimmte Zeichenkombinationen werden aus anderen Zeichenkombinationen rein formal abgeleitet. Der Bezug auf eine Wirklichkeit, ein Bezeichnetes, ist innerhalb des Kalküls nicht vorhanden - er ergibt sich erst durch die Interpretation der Zeichen. Die Untersuchung derartiger Interpretationen ist Gegenstand der Modelltheorie.





</doc>
<doc id="5775" url="https://de.wikipedia.org/wiki?curid=5775" title="Zufall">
Zufall

Von Zufall spricht man dann, wenn für ein einzelnes Ereignis oder das Zusammentreffen mehrerer Ereignisse keine kausale Erklärung gegeben werden kann. Als kausale Erklärungen für Ereignisse kommen in erster Linie allgemeine Gesetzmäßigkeiten oder Absichten handelnder Personen in Frage. Die "Erklärung" für Zufall ist also gerade der Verzicht auf eine (kausale) Erklärung.

Das Wort „Zufall“ in der in diesem Artikel beschriebenen Bedeutung kam erst im 17. Jahrhundert in allgemeinen Gebrauch und gilt unter Linguisten als vom lateinischen "ac-cidens" in Wortform und Sinn vorgeprägt. Im deutschen Sprachraum kam "Zufall" (mittelhochdeutsch "zuoval": „Anfall“) zuerst bei Meister Eckhart bzw. in der Sprache der Mystiker des 14. Jahrhunderts als Lehnübersetzung von "accidens" und scholastische Wiedergabe des aristotelischen "symbebêkós" vor.

Wenn von Zufall gesprochen wird, kann konkret gemeint sein:

Fall 1 ist in der makroskopischen Welt bisher nicht beobachtet worden und dürfte prinzipiell nicht nachweisbar sein. In der Quantenmechanik wird die Existenz des objektiven Zufalls im Rahmen ihrer verschiedenen Interpretationen diskutiert. So ist der Zeitpunkt des Zerfalls des nächsten radioaktiven Atoms aus einer Stoffmenge nicht vorhersagbar.

Fall 2 bedeutet, dass die Kausalkette oder die Einflussfaktoren nicht lückenlos nachgewiesen sind, aber ihr Vorhandensein zu vermuten ist. "Beispiele:"

Fall 3 setzt eine gewisse Komplexität voraus. "Beispiele:"

Fall 4 ist der Versuch, voneinander unabhängige Dinge in Verbindung zu bringen. (Das ist eine der Formen magischen Denkens.) "Beispiel:" Zwei Menschen haben jeweils eine Telefonnummer. Ob der ältere oder jüngere die größere Nummer hat, ist „Zufall“.

Verwendet man Zufall als Beschreibung dafür, dass die eingetretene Endsituation keine Begründung in der Ausgangssituation finden kann, dann muss auch gelten:


Auch umgangssprachlich wird der Begriff Zufall verwendet, wenn ein Ereignis nicht kausal erklärbar ist. Er ist schwer abgrenzbar gegen Unberechenbarkeit und Unvorhersagbarkeit. Wenn gezielt Zufall als Gestaltungselement bei Auswahlverfahren genutzt wird, wird in diesem Zusammenhang der Begriff „Zufallsprinzip“ verwendet.

Eine systematische Untersuchung des Phänomens Zufall geschieht

Teilbereiche der Philosophie beschäftigen sich mit der Frage, ob unsere Welt im innersten deterministisch (also kausal eindeutig vorherbestimmt) oder zufällig ist. Bei auf den ersten Blick zufällig erscheinenden Ereignissen stellt sich die Frage, ob der Beobachter lediglich zu wenig Informationen hatte, um eine exakte Vorhersage zu treffen, oder ob das beobachtete System "in sich" zufällig ist. 

Bei der ersten Art – den deterministischen Systemen – ist das Ergebnis eines Experiments bei identischen Bedingungen immer gleich. Eine beobachtete Varianz lässt darauf schließen, dass der Beobachter an zumindest einer Stelle ungenau gemessen hat. Heute untersucht die Chaosforschung deterministisch chaotische Systeme; das sind deterministische Systeme, die sich aber aufgrund ihrer großen Komplexität für den Menschen momentan unvorhersagbar verhalten.

Die Quantenphysik hat eine neuerliche Diskussion darüber ausgelöst, ob die Welt fundamental deterministischen oder im innersten zufälligen Prinzipien gehorcht. Die experimentell nachgewiesene Verletzung der Bellschen Ungleichung impliziert, dass die Natur auf mikroskopischer Ebene nicht durch eine sowohl realistische als auch lokale Theorie beschrieben werden kann. Dies bedeutet, dass das Ergebnis eines Experiments selbst bei Kenntnis aller lokalen Gegebenheiten im Allgemeinen nicht exakt vorhergesagt werden kann und dementsprechend auch verschiedene Konsequenzen aus identischen Ausgangssituationen folgen können. So ist es beispielsweise nicht möglich, den exakten Zeitpunkt des Zerfalls eines Atomkerns zu bestimmen, und zwar nicht, weil noch Eigenschaften des Kerns unbekannt wären, sondern weil keine (lokalen) Ursachen existieren. Im Rahmen der Kopenhagener Deutung der Quantenmechanik spricht man daher von einem objektiven Zufall.

Andere Interpretationen der Quantenmechanik unterscheiden sich nicht in ihrem physikalischen Inhalt von der Kopenhagener Deutung, allerdings in ihrer Bewertung des Zufalls. So geht die Viele-Welten-Interpretation beispielsweise davon aus, dass immer alle quantenmechanischen Möglichkeiten tatsächlich realisiert sind und nur in den jeweiligen Welten zufällig erscheinen. Alle Welten zusammen wären demnach deterministisch beschreibbar. Des Weiteren existieren nicht-lokale Interpretationen (z. B. die De-Broglie-Bohm-Theorie), in denen der Zufall auf das Unwissen bezüglich des Zustands des gesamten Universums zurückgeführt wird.

Schließlich darf der quantenmechanische Zufall nicht mit Regellosigkeit gleichgesetzt werden. Auch wenn die einzelnen Messergebnisse nicht vorhersagbar sind, so sind die Wahrscheinlichkeiten ihres Eintretens durch die quantenmechanischen Gesetzmäßigkeiten streng determiniert. Auf makroskopischer Ebene spielen Quanteneffekte aufgrund der Dekohärenz keine Rolle, so dass uns die klassische Welt immer deterministisch erscheint.

Zwischen den Begriffen Zufall und freier Wille existiert ein enger Zusammenhang. Es kann argumentiert werden, dass eine freie Entscheidung, zumindest teilweise, durch andere Einflüsse (innerer und äußerer Art) nicht beeinflusst ist. Sie ist also nicht determiniert. Dies lässt sich indes gerade auch als Definition von Zufall ansehen: Nach dieser Auffassung kann es in einem Universum ohne Zufall keinen freien Willen geben, da jede Entscheidung bei Kenntnis aller Einflussgrößen vorhergesagt werden könnte. Aber wenn unsere Entscheidungen zufällig zustande kommen, ist das erst recht nicht, was wir uns unter freiem Willen vorstellen.

Immanuel Kant schlägt dafür in der "Kritik der reinen Vernunft" folgenden Ausweg vor: Der Widerspruch zwischen Determinismus und Unbestimmtheit des Willens („Antinomie“ der Willensfreiheit) entsteht nur, wo Erscheinungen (der Erfahrungswelt) mit dem „Ding an sich“ gleichgesetzt werden. „Denn, sind Erscheinungen Dinge an sich selbst, so ist Freiheit nicht zu retten. […] Wenn dagegen Erscheinungen für nichts mehr gelten, als sie in der Tat sind, nämlich nicht für Dinge an sich, sondern bloße Vorstellungen, die nach empirischen Gesetzen zusammenhängen, so müssen sie selbst noch Gründe haben, die nicht Erscheinungen sind.“ (B 564f, Kritik der reinen Vernunft). Willensfreiheit bedeutet danach „das Vermögen, einen Zustand von selbst anzufangen“ (B 561, Kritik der reinen Vernunft).

Wie frei der menschliche Wille wirklich ist, und wie sehr menschliche Entscheidungen von Erfahrungen, Gefühlen und Instinkten geprägt sind, ist ein Untersuchungsgegenstand der Psychologie. Ein Mensch mit einem freien Willen hat vielleicht nur einen umfangreichen Erfahrungsschatz, moralische Grundsätze und einen scharfen Verstand, die ihm eigenständige, differenzierte Entscheidungen auf fundierter Basis erlauben, welche womöglich absolut deterministisch zustande kommen. Ein solcher Willen ist immerhin ein Stück weit frei von gesellschaftlichen Zwängen, Gewohnheiten usw.

Die christliche Religion setzt keinen freien Willen im Menschen voraus, so weit es sich um die Möglichkeit handelt, sich Gott zuzuwenden oder sich von ihm abzukehren. Paulus, Augustinus und die Reformatoren sind wichtige Vertreter der Willensunfreiheit des Menschen in christlicher Hinsicht. Da diese Willensunfreiheit aber zu Schwierigkeiten mit den Konzepten von Sünde, Schuld und Vergebung führt, wird im heutigen Katholizismus, in manchen nichtreformatorischen Ausprägungen des Protestantismus und in anderen Konfessionen Willensfreiheit positiv vertreten. Neben Determinismus und Zufall als „Naturkräften“ und den freien Willen des Menschen tritt in religiösen Vorstellungen das Wirken höherer Wesen als weiteres Kausalprinzip.

Die Untersuchung der menschlichen Fähigkeit, Zufallserscheinungen zu beurteilen, fällt in das Gebiet der Kognitionspsychologie. Maßgebliche Beiträge hierzu stammen von den Wissenschaftlern Amos Tversky und Daniel Kahneman. Der Mensch besitzt eine Grundfähigkeit zum Einschätzen von Wahrscheinlichkeiten, jedoch sind im Einzelnen verschiedene systematische Fehleinschätzungen identifiziert worden. Prominente Beispiele sind zum einen Nichtberücksichtigung von bedingten Wahrscheinlichkeiten oder die Umkehr der Schlussrichtung von Aussagen mit diesen, wie das bekannte Ziegenproblem illustriert.

Weiter neigen Versuchspersonen dazu, in zufälligen Mustern Regelmäßigkeiten wahrzunehmen (Apophänie) und davon auf einen systematischen Erzeugungsprozess zu schließen. Damit verwandt ist die von H. Reichenbach 1934 formulierte Beobachtung, dass Menschen beim Versuch, sich zufällige Zahlensequenzen auszudenken, eine Tendenz zeigen, die Frequenz aufeinander folgender identischer Ziffern zu unterschätzen. Ein klassischer Datensatz für statistische Nachweise besteht aus einer großen Zahl im Rahmen eines Versuches zum Nachweis von Gedankenübertragung eingesendeter Zahlenfolgen, dem Zenith Radio Experiment von 1937, dessen Ergebnisse zunächst von L. D. Goodfellow in dieser Hinsicht untersucht wurden.

Eine andere Klasse von Fehlurteilen rührt aus der Anwendung fehlerhafter Varianten des Gesetzes der großen Zahl.

Derartige Denkfehler unterlaufen auch ausgebildeten Mathematikern. Ein bekannteres Beispiel ist das von Paul Erdős, der für das Verständnis des Ziegenproblems mehrere Anläufe brauchte. Persi Diaconis fasst die Situation wie folgt zusammen: „Our brains are just not wired to do probability problems very well.“ (in etwa: „Unser Gehirn ist einfach nicht so verdrahtet, um mit Wahrscheinlichkeitsproblemen sehr gut umzugehen.“) Ein Erklärungsansatz sind von Tversky und Kahneman untersuchte automatische Denkprozesse, sogenannte Urteilsheuristiken.

T. Griffiths und J. Tenenbaum versuchen die Diskrepanz zwischen menschlicher Intuition und stochastischer Sichtweise dahingehend aufzulösen, dass die menschlichen Einschätzungen mit mathematischen Vorhersagen der Frage nach der Likelihood eines bestimmten generierenden Prozesses im Einklang stehen (und nicht mit der Wahrscheinlichkeit eines Ereignisses unter einem vorgegebenen generierenden Prozess).

Zufall (lat. "casus fortuitus") ist im deutschen Zivilrecht die weder auf Vorsatz noch auf Fahrlässigkeit einer Person beruhende Ursache von Ereignissen. Grundsätzlich trägt jeder, der durch Zufall einen Schaden erleidet, diesen Schaden selbst; jedoch haften z. B. der Schuldner im Verzug und der Dieb. Letzterer haftet nach dem römischen Rechtssatz fur semper in mora, weil er immer im Verzug ist (nämlich im Verzug der Rückgabe). Dies hat zur Folge, dass der Dieb immer für den zufälligen Untergang der Sache haftet, selbst wenn der Untergang der Sache für ihn weder vermeidbar noch vorhersehbar war.





</doc>
<doc id="5776" url="https://de.wikipedia.org/wiki?curid=5776" title="Zeppelin (Begriffsklärung)">
Zeppelin (Begriffsklärung)

Zeppelin steht für:

"Unternehmen":

"Luft-", "See-", und "Landfahrzeuge":
Zeppelin ist der Familienname oder Teil des Familiennamens folgender Personen:
Siehe auch:



</doc>
<doc id="5782" url="https://de.wikipedia.org/wiki?curid=5782" title="Zement (Begriffsklärung)">
Zement (Begriffsklärung)

Das Wort Zement bezeichnet:
Siehe auch:


</doc>
<doc id="5783" url="https://de.wikipedia.org/wiki?curid=5783" title="Zirkon">
Zirkon

Zirkon ist ein Mineral aus der Mineralklasse der „Silikate und Germanate“ mit der chemischen Zusammensetzung Zr[SiO] und damit chemisch gesehen ein Zirconium-Silikat, das strukturell zu den Inselsilikaten zählt. Sehr typisch sind zum Teil hohe Gehalte an Hafnium, Uran, Thorium, Yttrium, Cer und anderen Metallen der Seltenen Erden (Rare Earth Elements, REE). Zirkon bildet eine lückenlose Mischkristallreihe mit seinem wesentlich selteneren hafniumdominanten Analogon Hafnon. Reidit ist eine Hochdruckmodifikation von Zirkon.

Das Mineral kristallisiert im tetragonalen Kristallsystem und entwickelt meist kurzprismatische Kristalle mit quadratischem Querschnitt und pyramidalen Kristallenden sowie Kristalle mit dipyramidalem Habitus. Die meist eingewachsenen, nur selten aufgewachsenen Kristalle können bis zu 30 cm Größe erreichen. Zirkon findet sich ferner in radialstrahligen Aggregaten, unregelmäßigen Körnern, massiv sowie in Form von abgerollten, stark verrundeten Kristallen. In reiner Form ist Zirkon farblos und durchsichtig. Durch vielfache Lichtbrechung aufgrund von Gitterfehlern oder polykristalliner Ausbildung kann er aber auch weiß erscheinen, wobei farblose bis weiße Zirkone nur selten zu finden sind. Meist nimmt das Mineral durch verschiedene Fremdbeimengungen eine graue, braune bis rotbraune und seltener auch gelbe, grüne oder blaue Farbe an.

Exemplare, die aufgrund ihrer Größe und Reinheit Edelsteinqualität zeigen, sind aufgrund ihres diamantähnlichen Glanzes ein beliebter Ersatz für Diamanten. Zirkon ist nicht zu verwechseln mit dem synthetisch hergestellten Zirkonia (Formel: ZrO, Zirconium(IV)-oxid), der ebenfalls als Schmuckstein und Diamantimitation dient.

Der Name Zirkon stammt entweder vom arabischen "zarqun" für „Zinnober“ oder vom persischen زرگون "zargun" für „goldfarben“. Verändert finden sich diese Bezeichnungen im Namen "Jargon" wieder, womit helle Zirkone benannt worden sind.

Der seit der Antike verwendete Name Hyacinth (Hyazinth) bezog sich ursprünglich auf ein blaues oder violettes Mineral. Er stammt vom griechischen Wort Υάκινθος "hyakinthos" für „Jüngling“ – in der griechischen Mythologie war Hyakinthos eine Blume, die aus dem Blut des gleichnamigen Jünglings entstand. Schon im Jahre 300 vor Christi Geburt war das Mineral von Theophrastos von Eresos nach dem griechischen Wort λυγκύριον "lyncurion" als "Lyncurion" bezeichnet worden. Ein mit dem heutigen Zirkon wahrscheinlich identisches Mineral nannte Plinius der Ältere in seiner um 77 n. Chr. entstandenen Naturgeschichte ("Naturalis historia") "Chrysolithos". Von Georgius Agricola 1546 als "Hyacinthus" und von Barthélemy Faujas de Saint-Fond 1772 als "Hyacinthe" bezeichnet.

Jean-Baptiste Romé de L’Isle bildete als Erster die charakteristische Kristallform des Zirkons mit Prisma und Pyramide ab und unterschied säulig-gestreckte und pseudorhombendodekaedrische Varietäten. Martin Heinrich Klaproth wies darauf hin, dass Romé als Erster des "Jargon de Ceylan" „als einer besondern Steinart … gedacht“ hatte. Erstmals als Zirkon "(Silex Circonius)" bezeichnet wurde das Mineral 1783 durch Abraham Gottlob Werner, dessen Schüler Christian August Siegfried Hoffmann den Zirkon in das von ihm nach den Vorträgen von Werner verfasste „Handbuch der Mineralogie“ aufnahm.

Martin Heinrich Klaproth analysierte im Jahre 1789 gelbgrüne und rötliche Zirkone von "Ceylon" (heute Sri Lanka) und entdeckte darin „eine bisher unbekannte, selbständige, einfache Erde“, der er den Namen „Zirkonerde“ "(Terra circonia)" gab. Dieselbe Erde fand Klaproth in einem Hyazinth von Ceylon, wodurch sich Zirkon einerseits und Hyazinth andererseits „als zwei Arten oder Gattungen eines eigenthümlichen Steingeschlechts“ erwiesen; die neue Erde könnte eventuell auch „Hyacintherde“ genannt werden. Erst René-Just Haüy vereinigte Hyazinth und Zirkon bei exakter Bestimmung der Kristallformen zu einem einzigen Mineral. Das chemische Element Zirconium isolierte erstmals der schwedische Mediziner und Chemiker Jöns Jakob Berzelius.

Eine Typlokalität (Fundort erstmaliger Entdeckung) für den Zirkon ist nicht bekannt, daher gibt es auch keine entsprechend definierten Mineralproben (Typmaterial).

Bereits in der veralteten, aber noch gebräuchlichen 8. Auflage der Mineralsystematik nach Strunz gehörte der Zirkon zur Mineralklasse der „Silikate und Germanate“ und dort zur Abteilung der „Inselsilikate (Nesosilikate)“, wo er als Namensgeber die „Zirkongruppe“ mit der System-Nr. "VIII/A.09" und den weiteren Mitgliedern Coffinit, Hafnon, Reidit, Thorit und Thorogummit bildete.

Die seit 2001 gültige und von der International Mineralogical Association (IMA) verwendete 9. Auflage der Strunz'schen Mineralsystematik ordnet den Zirkon ebenfalls in die Abteilung der „Inselsilikate (Nesosilikate)“ ein. Diese ist allerdings weiter unterteilt nach der möglichen Anwesenheit weiterer Anionen und der Koordination der Kationen, so dass das Mineral entsprechend seiner Zusammensetzung in der Unterabteilung der „Inselsilikate ohne weitere Anionen mit Kationen in oktaedrischer [6] und gewöhnlich größerer Koordination“ zu finden ist, wo es zusammen mit Coffinit, Hafnon, Stetindit, Thorit und Thorogummit die „Zirkongruppe“ mit der System-Nr. "9.AD.30" bildet.

Auch die vorwiegend im englischen Sprachraum gebräuchliche Systematik der Minerale nach Dana ordnet den Zirkon in die Klasse der „Silikate und Germanate“ und dort in die Abteilung der „Inselsilikatminerale“ ein. Hier ist er als Namensgeber der „Zirkongruppe“ mit der System-Nr. "51.05.02" und den weiteren Mitgliedern Hafnon, Thorit, Coffinit, Thorogummit und Stetindit innerhalb der Unterabteilung der „Inselsilikate: SiO-Gruppen nur mit Kationen in >[6]-Koordination“ zu finden.

Die Formel des reinen Zirkons mit Endgliedzusammensetzung Zr[SiO] erfordert Gehalte von 67,1 Gew.-% (Gewichtsprozent) ZrO und 32,9 Gew.-% SiO. Natürliche Zirkone enthalten häufig ein breites Spektrum formelfremder Begleitelemente und Einschlüsse verschiedener anderer Minerale, wozu Entmischungen, Einlagerungen und zonierte Verwachsungen zählen. Die wichtigsten Begleitelemente sind Hafnium, Thorium, Uran, Yttrium, Cer und andere Metalle der Seltenen Erden sowie Phosphor, Niob, Tantal, Aluminium, Eisen und Calcium. Dabei ist die Isotypie von Zirkon (Zr[SiO]) und Xenotim-(Y) (Y[PO]) die Ursache für die gekoppelte (heterovalente) Substitution Zr und Si durch Y und P. Der größere Teil der teilweise sehr hohen Y-Gehalte ist aber nicht auf einen diadochen Einbau von Yttrium für Zirkon zurückzuführen, sondern auf zonierte, zum Teil sogar epitaktische Verwachsungen mit dem diskreten Fremdmineral Xenotim (vergleiche das nebenstehende REM-Bild und unter Varietäten).

Hafnium wurde erstmals in Zirkonen aus Norwegen röntgenspektroskopisch durch die Physiker Dirk Coster und George de Hevesy 1923 in Kopenhagen nachgewiesen. Es wurde auch sehr schnell klar, dass Hafnium in zirconiumhaltigen Mineralien – und damit in allen Zirkonen – immer enthalten ist, da Hf-Ionen aufgrund der Lanthanoidenkontraktion einen zum leichteren Homologen Zr vergleichbaren Ionenradius aufweisen und damit perfekt in die Kristallstrukturen der Zirconium-Verbindungen passen. Mit seinem hafniumdominanten Analogon Hafnon (Hf[SiO]) bildet Zirkon somit eine lückenlose Mischkristallreihe. Gehalte von 45,30 Gew.-% Hafniumdioxid (HfO) und von 27,69 Gew.-% Zirconiumdioxid (ZrO) charakterisieren den Mittelpunkt der Mischkristallreihe mit der Formel (ZrHf)SiO. Bei Kristallen mit Hafniumdioxidgehalten > 45,30 Gew.-% handelt es sich danach um Hafnone, ist der Wert kleiner als 45,30 Gew.-%, liegt ein Zirkon vor. Normalerweise beträgt der HfO-Gehalt der Zirkone etwa 1 bis 1,5 Gew.-%, das Hf/Zr-Verhältnis 0,02–0,04.

In Extremfällen kann Zirkon ferner bis zu 12 Gew.-% Thoriumdioxid (ThO) oder 1,5 Gew.-% Uran(V,VI)-oxid (UO) enthalten. Eine yttriumhaltige Zirkonvarietät wurde "Ribeirit" genannt und enthält 7,45 Gew.-% YO („Yttererden“). In einem graugrünen bis graubraunen Zirkon aus Hayamadake, Präfektur Fukushima, Japan, wurden 10,14 Gew.-% YO festgestellt.

Die zum Teil beträchtlichen Gehalte an Uran und Thorium machen den Zirkon zum Hauptträger der Radioaktivität in den Gesteinen. Allerdings ist auch formelreiner Zirkon schwach radioaktiv, da er zu 2,8 % aus dem Isotop Zr besteht, das mit der extrem langen Halbwertszeit von 24·10 Jahren unter doppeltem Betazerfall zu Mo zerfällt.

Zirkon kristallisiert tetragonal in der mit den Gitterparametern "a" = 6,61 Å und "c" = 5,98 Å sowie vier Formeleinheiten pro Elementarzelle.

Die Struktur des Zirkons enthält inselartig [SiO]-Tetraeder in einer innenzentrierten Elementarzelle aus Zr-Ionen, wobei jedes Zr-Ion von acht O-Ionen umgeben ist. Die [SiO]-Tetraeder sind spiegelsymmetrisch und nach vierzähligen Schraubenachsen angeordnet. Letztere weisen gegenläufigen Drehsinn parallel [001] durch die Mitte der vier Viertelzellen auf. Das prinzipielle Strukturelement im Zirkon sind Zickzack-Ketten aus alternierenden, kantenverknüpften ZrO-Dodekaedern parallel [100], die durch gemeinsame Ecken und Kanten mit den [SiO]-Tetraedern zu einem dreidimensionalen Gerüst verbunden sind.
Zirkon ist isotyp zu Xenotim-(Y), Béhierit (Ta[BO]), Chernovit-(Y), Hafnon, Thorit und Wakefieldit-(Y) sowie einer Reihe künstlicher Verbindungen, d. h. er kristallisiert mit der gleichen Struktur wie diese Minerale und Phasen.

In manchen Zirkonen ist der Gitterbau durch die Wirkung hochenergetischer radiogener Teilchen (aus dem radioaktiven Zerfall der im Zirkon enthaltenen Elemente Uran und Thorium) teilweise zerstört (metamiktisiert) – solche Kristalle weisen meist dunklere, braune Farben auf. Durch die Metamiktisierung kann Wasser ins Kristallgitter eingelagert werden. Die Folge ist eine merkliche Verringerung von Brechungsindex, Dichte und Härte. Eine Doppelbrechung ist überhaupt nicht mehr vorhanden. Insofern unterscheidet man Zirkone von ihren Stadien her in
die bezüglich ihrer Eigenschaften zwischen den beiden ersten Gruppen liegen. Durch Erhitzen auf über 1000 °C können die Tiefzirkone wieder zu Hochzirkonen rekristallisieren.

Zirkon bildet fast immer ringsum ausgebildete, aber eingewachsene und nur selten aufgewachsene, im Querschnitt oft quadratische Kristalle, deren durchschnittliche Größe, z. B. in granitoiden Gesteinen, zwischen 100 und 300 µm liegt. Gelegentlich erreichen sie aber auch Größen von mehreren Zentimetern, vor allem in Pegmatiten oder Schwermineralseifen. Der bisher größte bekannte Zirkon weltweit maß 10 cm × 10 cm × 30 cm, wog über 7 kg und wurde bei Brudenell in der kanadischen Provinz Ontario gefunden.

Zirkonkristalle sind in den meisten Fällen an beiden Enden terminiert. Ihre die Kristallisationsgeschwindigkeit reflektierenden Längen-/Breitenverhältnisse variieren zwischen 1 und 5. Tatsächlich finden sich nadelige Kristalle häufig in schnell auskristallisierten, porphyrischen, subvulkanischen Intrusionen sowie oberflächennah intrudierten Graniten und Gabbros.

Zirkone treten im Wesentlichen in drei verschiedenen Grundtypen mit den Hauptflächenformen {100}, {110}, {101} und {301} auf (siehe dazu auch die zugehörigen Grafiken). Zu diesen drei morphologischen Grundtypen des Zirkons gehören ein pyramidaler Habitus mit {101} und/oder {211}, ein prismatischer Habitus mit {100} und/oder {110} und ein gestreckter Habitus mit prismatischen und pyramidalen Flächenformen. Zum pyramidalen Habitus zählen die typisch dipyramidalen Kristalle, die die Pyramide {101} allein oder mit schmalen Flächen des Prismas II. Stellung {100} zeigen. Wesentlich häufiger sind die Kristalle mit prismatischem Habitus. Hier treten zu den trachtbestimmenden Prismen II. Stellung {100} und/oder I. Stellung {110} die tetragonalen Pyramiden II. Stellung {101} und {301}, die tetragonale Pyramide I. Stellung {112} sowie die tetragonale Dipyramide {211}. Sehr charakteristisch sind kurzprismatische Kristalle mit {110} und {101}, die einen pseudorhombendodekaedrischen Habitus (sogenannter Hyazinth-Habitus) aufweisen und an entsprechende Granatkristalle („Granatoeder“) erinnern (vergleiche die Kristallzeichnung Nr. 3).

Bei Vergleichen mit historischen Kristallzeichnungen muss beachtet werden, dass die Aufstellung der Kristalle in modernen Zeichnungen gegenüber der früheren morphologischen Orientierung um 45° gedreht ist. So wird die früher als {111} indizierte Pyramide heute als {101} aufgestellt.

Im Gegensatz zu den formähnlichen Mineralen Kassiterit und Rutil bildet Zirkon nur selten knieförmige Zwillinge mit (112) als Zwillingsebene aus. Solche Zwillinge sind aus der „Meredeth Freeman Zircon Mine“ im Henderson County in North Carolina beschrieben worden, daneben auch kreuzförmige Zwillinge nach (101) und visiergraupenähnliche Zwillinge nach (111). Die Gesetzmäßigkeit der kreuzförmigen Zwillinge hat jedoch Georges Friedel schon 1904 bezweifelt. Große Zwillinge nach (112), aber nicht kreuzförmig, sondern als Kniezwillinge, sind vor allem von Brudenell Township, Renfrew County, Ontario in Kanada, bekannt.
Zirkon kommt außerdem in traubigen, nierigen und radialstrahligen Aggregaten sowie unregelmäßigen Körnern vor. Aufgrund seiner Verwitterungsbeständigkeit findet sich der Zirkon in Lockersedimenten und Seifen in Form von losen, abgerollten Kristallen, in Schlacken und mit basaltischen Gesteinen verknüpften Xenolithen, in skelett- und bäumchenförmigen Aggregaten.

Charakteristisch sind Verwachsungen mit anderen Mineralen wie z. B. Xenotim-(Y), darunter auch perfekt orientierte (epitaktische) Verwachsungen (siehe die nebenstehende Kristallzeichnung).
Verwachsungen mit Baddeleyit werden „Zirkon-Favas“ oder „Caldasit“ genannt. Da Thorit und Zirkon komplett analoge Strukturen aufweisen, sind auch epitaktische Verwachsungen von Zirkon mit Thorit möglich. Solche kennt man unter anderem von Bassano Romano, Provinz Viterbo, Latium, aus dem Steinbruch San Vito bei San Vito unweit Ercolano, Monte Somma, Somma-Vesuv-Komplex, Metropolitanstadt Neapel, Kampanien, beide in Italien, sowie aus den Auswürflingen des Laacher-See-Vulkans in der Vulkaneifel.

In reiner Form ist Zirkon farblos und wasserklar-durchsichtig. Durch vielfache Lichtbrechung aufgrund von Gitterbaufehlern oder polykristalliner Ausbildung kann er aber auch durchscheinend weiß sein und durch Fremdbeimengungen eine braune und braunrote, seltener auch gelbe, grüne oder blaue Farbe annehmen. Die Strichfarbe des Zirkons ist hingegen immer weiß. Die Oberflächen der durchsichtigen bis opaken Kristalle weisen auf allen Flächen einen starken glas- bis diamantähnlichen Glanz, auf Bruchflächen sowie im metamikten Zustand hingegen Fettglanz auf. Manche Zirkone zeigen auch Chatoyance (Katzenaugeneffekt).

Zirkon besitzt eine sehr unvollkommene Spaltbarkeit nach {100}, bricht aufgrund seiner Sprödigkeit aber ähnlich wie Quarz, wobei die Bruchflächen muschelig ausgebildet sind. Mit einer Mohshärte von 7,5 gehört Zirkon zu den harten Mineralen, und steht damit zwischen den Referenzmineralen Quarz (Härte 7) und Topas (Härte 8). Die gemessene Dichte für Zirkon beträgt je nach Autor 4,6 bis 4,7 g/cm³, die berechnete Dichte liegt bei 4,714 g/cm³. Bei der Metamiktisierung (Isotropisierung) sinkt die Dichte des Minerals auf Werte von 3,9 bis 4,2 g/cm³ („low density zircons“).

Bei Normaldruck ist Zirkon bis zu einer Temperatur von 1676 °C stabil. Darüber zersetzt er sich in tetragonales Zirconiumdioxid (ZrO) und Siliciumdioxid (SiO) in der Modifikation β-Cristobalit "(Hochcristobalit)", besitzt also keinen kongruenten Schmelzpunkt.

Ab 1689 °C bildet sich SiO- reiche Schmelze (~95 mol-% SiO), die mit weiter steigenden Temperaturen zunehmend reicher an ZrO wird.

Im Dünnschliff ist Zirkon farblos bis blassbraun und weist in stark gefärbten Körnern einen deutlichen Pleochroismus auf. So wurde an bräunlich-perlgrauen Körnern ein Pleochroismus von ω = nelkenbraun nach ε = spargelgrün, an blass nelkenbraunen Körnern ein Pleochroismus von ω = grauviolettblau nach ε = grauolivgrün und an gelblichweißen Körnern ein Pleochroismus von ω = blassblau nach ε = blassgelb beobachtet. Charakteristisch für das Mineral ist eine hohe Lichtbrechung (starkes Relief mit dunkler Umrandung) und eine hohe Doppelbrechung (δ = 0,044 bis 0,055) mit lebhaften roten, blauen und grünen Interferenzfarben der II. und III. Ordnung. Metamikte Zirkone können anomal zweiachsig sein und dann Achsenwinkel von 2V = 10° zeigen, während ihre Doppelbrechung auf Werte von δ = 0,000 zurückgeht. Weitere Charakteristika sind der oft vorhandene Zonarbau und die pleochroitischen Höfe, die am besten zu erkennen sind, wenn der Zirkon als Einschluss in farbigen Mineralen wie Biotit und Turmalin auftritt. Im Zirkon selbst sind Einschlüsse von Apatit, Monazit, Xenotim-(Y), Rutil, Hämatit, Ilmenit, Magnetit, Biotit, Kassiterit, Quarz, Turmalin und Glas beobachtet worden, die immer eine gewisse Trübung (Graufärbung) verursachen.

Vor dem Lötrohr, auch im warmen Luftstrom, ist der Zirkon unschmelzbar. Mit Sauerstoff wird er weiß, ohne zu schmelzen. Nur mit erwärmtem Sauerstoff entsteht oberflächlich ein weißes Email; letzteres auch, wenn der Zirkon beim Erhitzen im Knallgas-Strom zu schmelzen anfängt. Zirkon wird durch Phosphorsalz nicht wahrnehmbar angegriffen. Wird das Pulver mit Ätzkali – oder mit Soda am Platindraht – zusammengeschmolzen und dann mit Salzsäure gekocht, so wird Kurkuma-Papier von der verdünnten sauren Flüssigkeit orange gefärbt (Reaktion auf Zirconium). Wird die salzsaure Lösung bis zur Kristallisation konzentriert und dann mit gesättigter Kaliumsulfat-Lösung gekocht, so bildet sich ein weißer Niederschlag von Zirconium(IV)-oxid. In Säuren ist er unlöslich. Von konzentrierter Schwefelsäure (HSO) wird Zirkon nur in feinstem Pulver angegriffen, in heißer, konzentrierter Fluorwasserstoffsäure (HF) ist er schwach löslich. Zirkon ist aufschließbar durch Schmelzen mit Alkalicarbonaten und Kaliumdisulfat sowie anderen Bisulfaten, besonders aber mit Kaliumfluorid und Fluorwasserstoff-Kaliumfluorid.

Durch Glühen – je nach Behandlung in der Oxidations- bzw. Reduktionsflamme – entsteht zum Teil eine dunklere Färbung, zum Teil werden die Kristalle entfärbt. Einige Zirkonkristalle zeigen beim Glühen Thermolumineszenz; insbesondere bei helleren durchsichtigen Kristallen erzeugt bereits eine „sehr gelinde Erwärmung“ ein hell- bis intensiv grünes Licht, wobei die Phosphoreszenz zwei bis drei Minuten anhält. Zirkon kann ferner auch Kathodolumineszenz sowie gelbe, orangegelbe bis grünorangefarbene Fluoreszenz im kurzwelligen UV-Licht (254 nm) aufweisen. Hervorgerufen wird dies durch strahlungsinduzierte Kristalldefekte sowie den Einbau von (UO) (Uranyl-Ion) als Verunreinigung, oder Dy, Er, Nd, Yb. Durch Bestrahlung hervorgerufene Gitterdefekte können beim Erhitzen, manchmal reicht Sonnenlicht, ausheilen, was mit einem Verlust der durch diesen Defekt verursachten Färbung einhergeht. In der Folge ändert sich die Farbe – es bleibt nur die Färbung durch stabile Defekte wie Fremdionen übrig – oder verschwindet vollständig.

In der Vergangenheit wurden verschiedenen Zirkone, die reich an Metallen der Seltenen Erden (Rare Earth Elements, REE) waren, unter eigenen Bezeichnungen beschrieben. Dazu zählen Alvit, Hagatalith, Naëgit, Nogizawalith, Oyamalith und Yamaguchilith. Die zumeist stark metamikten Minerale stammen hauptsächlich aus Graniten und Granitpegmatiten in Japan. Ihre Gehalte an REEO und PO können, z. B. im Nogizawalith, 26 Gew.-% und 9,8 Gew.-% erreichen. Schon vor Jahrzehnten ist gezeigt worden, dass es sich bei diesen Zirkon-„Varietäten“ tatsächlich um (zonierte) Verwachsungen von Zirkon und Xenotim-(Y) handelt, gelegentlich sogar in perfekter epitaktischer Orientierung. Sehr wahrscheinlich entstanden sie durch Einwirkung hydrothermaler, an Yttrium, Phosphor, und den Metallen der Seltenen Erden angereicherten Lösungen auf metamikte Zirkone. Im Alvit sind die Verwachsungen mit Xenotim-(Y)-Kristallen bis zu 0,1 mm Größe relativ grob. Im Hagatalith und Yamaguchilith sind die Xenotim-Domänen kleiner und seltener, wohingegen im Oyamalith und Naëgit überhaupt keine diskreten Phasengrenzen erkennbar sind.


Zirkon gehört zu den frühesten Mineralbildungen der Erde und des Mondes (siehe auch Altersbestimmung). Die ältesten bekannten Zirkonkristalle haben ein Alter von bis zu 4,4 Milliarden Jahren. Als mikroskopisch kleiner, akzessorischer Gemengteil ist er in verschiedenen magmatischen Gesteinen praktisch weltweit vorhanden. Er ist als primäres Kristallisationsprodukt Bestandteil von Magmatiten wie Graniten, Syeniten und Alkalisyeniten sowie insbesondere in deren Pegmatiten, daneben auch in Vulkaniten (Rhyolithen und Trachyten). Große Einkristalle sind vor allem in pegmatitischen Nephelinsyeniten enthalten. In metamorphen Gesteinen (kristallinen Schiefern) tritt Zirkon als Nebengemengteil in Form von aus den Edukten vererbten Kristallen und Körnern auf. Sehr große Kristalle und Zwillinge sind von Brudenell Township im Renfrew County, Ontario in Kanada, bekannt.

Infolge seiner Resistenz gegenüber chemischer und mechanischer Verwitterung findet man Zirkon auch in Sedimentgesteinen sowie in detritischer Form, worunter man durch Erosion aus dem Gesteinsverband freigelegte, transportierte und abgelagerte Zirkone versteht. Solchermaßen angereicherte Zirkone finden sich auch in Seifen, die zum Teil lagerstättenrelevante Größenordnungen erreichen. Darüber hinaus ist Zirkon auch auf alpinotypen Klüften und in vulkanischen Sanidin-Auswürflingen zu finden.

Analysen der Form und Kristallflächenausbildung von Zirkonen ermöglichen Rückschlüsse auf die Bildungsbedingungen und die weitere Entwicklung von Zirkonen. Bereits in den 1950er Jahren wurde davon ausgegangen, dass die Morphologie des Zirkons als Frühkristallisat die physikochemischen Bedingungen zur Zeit seiner Kristallisation widerspiegelt. Zu diesen physikochemischen Faktoren zählen die chemische Zusammensetzung und Viskosität des Magmas sowie die Oberflächenspannung der Kristalle gegenüber der Schmelze und die Unterkühlungsrate der Schmelze. Daraus entwickelte Jean-Pierre Pupin die Theorie, dass in granitischen Schmelzen die relative Größenbeziehung der beiden häufigsten Prismen des Zirkons – {100} und {110} – zueinander durch die Temperatur kontrolliert wird und die Ausbildung dieser beiden Prismen folglich als Geothermometer für die Bildungstemperatur des jeweiligen granitischen Gesteins verwendet werden kann. Andererseits wird bestritten, dass die Ausbildung der Prismenflächen von der Temperatur des Magmas gesteuert wird und damit die Morphologie von Zirkonkristallen als Geothermometer angesehen werden kann. So soll die Ausbildung der Flächenformen {100} und {110} der Zirkonkristalle vielmehr hauptsächlich durch chemische Bedingungen beeinflusst werden. Ein erhöhter Uran- und/oder Thoriumgehalt in einer granitischen Schmelze beeinträchtigt oder verhindert beispielsweise das Wachstum von {100} zugunsten von {110}, wodurch sich Kristalle mit durch das Prisma {110} dominierten Morphologien entwickeln.

Typische Begleitminerale des Zirkons sind – in Abhängigkeit des Muttergesteins (hier im Sinne von Gestein, das nutzbare Minerale beziehungsweise Edelsteine enthält) – die Feldspäte (Albit und Mikroklin), Amphibole, Glimmer (Muskovit, Biotit, Phlogopit und Vermiculit) sowie Quarz. In Seifen wird das Mineral häufig mit anderen stabilen Schwermineralen wie Turmalin, Topas, Kassiterit, Kyanit, Sillimanit, Korund, Granat, Spinell und gelegentlich auch Gold angetroffen. Zirkonreiche Seifenlagerstätten werden in Indien, den USA, Australien, Sri Lanka und Südafrika abgebaut.

Als häufige Mineralbildung konnte Zirkon bisher (Stand 2017) von ca. 5100 Fundorten beschrieben werden. Eine Typlokalität ist für das Mineral jedoch nicht definiert. Angesichts der sehr großen Anzahl an Fundorten für Zirkon können hier nur einige wenige, vor allem größere Kristalle liefernde Lokalitäten erwähnt werden.

Die am besten ausgebildeten Zirkone Deutschlands stammen aus Auswürflingen und Xenolithen der Vulkaneifel, Rheinland-Pfalz. Aus erstarrten Laven bei Niedermendig konnten rote Kristalle mit bis zu 3 cm Länge erhalten werden. Vulkanische Sanidin-Auswürflinge, z. B. aus dem Laacher-See-Gebiet, liefern Zirkone, die frisch rosafarben sind, aber meist zu farblosen bis grauweißen Tönen verblassen. Ein deutliches Skelettwachstum mit pinsel- bis bäumchenförmiger Ausbildung weisen Zirkone vom „Ettringer Bellerberg“ (Steinbruch Caspar) bei Ettringen unweit Mayen auf. Im 15 km südöstlich von Sebnitz liegenden „Seufzergründel“ bei Hinterhermsdorf in der Sächsischen Schweiz sind seit mindestens 1546 bis zu 10 mm große Zirkonkristalle aus Seifen in einem schwermineralführenden Bach gewaschen worden. Georgius Agricola schreibt dazu:

Seifenfunde in der Göltzsch im Sächsischen Vogtland und einigen ihrer Zuflüsse führten ab 1994 zu den qualitativ besten und größten Edelsteinzirkonen Europas. Diese stammen aus einem rund 1 km Durchmesser aufweisenden Diatrem bei Ebersbrunn südwestlich Zwickau. Facettierte, lupenreine Zirkone aus diesen Seifen erreichen Größen von bis zu 1,7 cm und wiegen bis zu 11 ct. Der größte facettierte Zirkon aus diesem Gebiet wurde aus einem braunroten Rohstein von 2 cm × 1,6 cm Größe und einem Gewicht von 10,2 g geschliffen. Der größte „Göltzsch-Zirkon“ maß 4,4 cm × 3,6 cm × 3,8 cm und wog 120 g – er wurde allerdings nicht verschliffen. Von derartigen Zirkonen nimmt man an, dass sie vor dem Beginn des fluviatilen Transportes Kantenlängen von bis zu 5 cm aufgewiesen haben.

In der Schweiz wurden seit 1997 in Nephelinpegmatiten am Bergmassiv Gridone oberhalb des Centovalli in den Tessiner Alpen bis zu 9 cm große, braunrosa bis rotbraun gefärbte Zirkone geborgen, die teils in grobspätigem Albit oder apatitführendem Biotit, teils am Kontakt von Albit zu Nephelin sitzen. Der einzige Zirkon aus einer alpinen Kluft in der Schweiz ist ein 3,5 mm × 2 mm großer Kristall, der aus der Rimpfischwäng bei Zermatt im Wallis geborgen wurde. Daneben kennt man Zirkon aus dem Granit der Grimsel, Kanton Bern und Kanton Wallis, sowie aus dem Gneis des Piz Blas und Piz Rondadura im Val Nalps bei Sedrun im Kanton Graubünden in bis zu 1 mm großen Kristallen.

Aus Österreich, insbesondere aus Klüften im Amphibolit und Biotitschiefer des Totenkopfes oberhalb des Stubachtals im Salzburger Land kennt man Kristalle bis zu 2,5 mm Größe; weiterhin von der „Aigner Alp“ bei Schellgaden im Murwinkel, Lungau, der „Dorfer Alpe“ im Dorferbachtal bei Prägraten, Virgental, Osttirol und vom „Prickler Halt“, einem Kamm zwischen Ladinger Spitz und Speikkogel auf der Saualpe in Kärnten.

In Italien fand man Zirkone in der „Burgumer Alpe“ im Pfitscher Tal, Südtirol und in der autonomen Region Trentino-Südtirol mit bis zu 1 cm großen Kristallen. Des Weiteren wurde das Mineral in „Le Prese“, Sondalo im Veltlin, Provinz Sondrio in der Region Lombardei, und aus dem Steinbruch „Cave dell'Acqua“ westlich von Figline di Prato bei Monte Ferrato, Provinz Prato, Toskana gefunden. Im französischen Zentralmassiv trat es in maximal 5 mm großen, hyazinth- oder ziegelroten, farblosen oder gelben Kristallen in Basalttuffen und Sanden des Riou Pezzouliou beim Dorf Espaly bei Le Puy-en-Velay, Département Haute-Loire, Region Auvergne-Rhône-Alpes sowie in Trachyt-Lavadomen des Puy-de-Dôme bei Clermont-Ferrand, Département Puy-de-Dôme, Region Auvergne-Rhône-Alpes auf.

In Norwegen fand man Zirkon vor allem im „Store Kufjord“ (eigentlich die Bezeichnung eines tief in die Insel schneidenden Fjordes) und anderen Pegmatiten auf der ca. 50 km nördlich von Alta liegenden Insel Seiland, Finnmark. Der zirkonreichste Nephelinsyenit-Pegmatit, 1,5 km lang und bis 10 m mächtig, befindet sich am Ostufer des Store Kufjord und lieferte bis 15 cm große Kristalle, die durch die Ausbildung der zum Teil sogar trachtbestimmenden steilen Pyramide {301} ein verrundetes Aussehen aufweisen (vergleiche die Kristallzeichnung Nr. 7). Weitere norwegischen Fundstellen für Zirkon sind Syenitpegmatite im Gebiet des plutonischen Larvik-Komplexes im Bereich des Langesundsfjordes in den Provinzen Vestfold und Telemark. Berühmte Fundstellen sind hier die Insel Stokkøya, die Steinbrüche „Tuften“, „Granit“ und „Almenningen“ im Tvedalen, der Steinbruch „Saga I“ bei Mørje, die Svenner-Inseln bei Stavern sowie das Husefjell auf Vesterøya bei Sandefjord. Bis zu 10 cm große Zirkonkristalle stammen aus den Steinbrüchen Hàkestad und Stàlaker bei Tjølling. Zirkon, auch in epitaktischen Verwachsungen mit Xenotim-(Y), stammt aus dem Feldspatbruch „Igletjødn“ (Igletjern) beim Hof Hæstad und anderen Granitpegmatiten auf der südsüdwestlich von Flekkefjord liegenden Insel Hidra (Hitterø), Vest-Agder. Insbesondere für die Zirkonvarietät "Alvit" bekannt sind der ehemals im Lindvikskollen-Kalstadgangen-Pegmatit bauende Steinbruch „Lindvikskollen“ und die Feldspatgrube „Tangen“, beide bei Kragerø unweit Fredrikstad, Telemark.

An den Ufern des Ilmen-Sees im Ilmengebirge bei Miass im mittleren Ural, Oblast Tscheljabinsk, Russland, wurden bereits 1826 Kristalle mit teils säuligem, teils pyramidalem Habitus gefunden. Die bis zu 17 cm langen und 10 cm dicken Kristalle stammen aus Nephelinsyeniten (Miaskiten), miaskitischen Pegmatiten in Granitgneisen, Pegmatiten in Pyroxensyeniten sowie Granitpegmatiten. Eine der bekanntesten Fundstellen ist der Schurf „Bljumovskaja kop“. Die ca. 120 km nordnordöstlich von Miass gelegenen Višnevye-Berge (Višnevogorsk) gehören wie das Ilmengebirge geologisch zum Syserts-Ilmenogorsk-Antiklinorium. Sie enthalten metasomatische Albitite, die sich aus alkalischen Gesteine miaskitischer Zusammensetzung ableiten. Diese Albitite, z. B. der an der Lokalität „Kurochkin Log“, liefern bis zu 10 cm große Zirkonkristalle. Bis Mitte der 1990er Jahre wurden diese Albitite als Zirkon-Pyrochlor-Erz abgebaut.

Auf der Halbinsel Kola in der Oblast Murmansk besitzen vor allem zwei Fundstellen Weltgeltung: Der „Peak Marchenko“ des Berges Kukisvumchorr im Chibinen-Massiv und der „Pegmatit Nr. 24“ am Berg Vavnbed (deutsch: „Nackter Hintern“) im Lowosero-Massiv. Die erstere Fundstelle lieferte braune Kristalle bis zu 5 cm Größe, vom letzteren, in Albitpegmatiten liegenden Fundort kamen dipyramidale Zirkonkristalle (vergleiche die Kristallzeichnung Nr. 1) bis zu 9 cm Größe.

In Afrika werden Zirkone hauptsächlich in den Edelsteinpegmatiten und -seifen in Madagaskar, vor allem in der Provinz Fianarantsoa, gefunden. Bekannte Fundorte sind die „Sakavalana Mine“ (gleichzeitig Typlokalität für Pezzottait) bei Ambatovita unweit Mandrosonoro, Distrikt Ambatofinandrahana, Region Amoron’i Mania, und die Phlogopitlagerstätte „Sakasoa“ im District Iakora, Region Ihorombe, wobei „Sakasoa“ auch Zirkon-Kniezwillinge geliefert hat. Weitere bekannte Fundstellen befinden sich in der Region Anosy. Dazu zählen Itrongay bei Mahasoa East, Distrikt Betroka, sowie die Gemeinde Tranomaro im Distrikt Amboasary. Zirkone stammen auch aus den Pegmatiten von Ampanobe im gleichnamigen Pegmatitfeld bei Ankazobe im Distrikt gleichen Namens, Region Analamanga.

Eine weitere weltbekannte Zirkonfundstelle sind die Alkalipegmatite um den Mount Malosa bei Zomba auf dem gleichnamigen Plateau und im gleichnamigen Distrikt in Malawi. Sie gehören geologisch zur Alkaligesteinsprovinz Chilwa und sind für ihre großen Aegirin-, Feldspat- und Arfvedsonit-Kristalle sowie seltene Berylliumminerale und Minerale mit Metallen der Seltenen Erden berühmt.

Etwa seit dem Jahre 2000 werden auch bei Imilchil im Hohen Atlas, Provinz Errachidia, Region Drâa-Tafilalet in Marokko, Zirkone gefunden. Zu den Fundpunkten zählen der ca. 18 km südöstlich von Imilchil liegende Gebirgspass Tizi-n'-Inouzane (Tizi-n-Ouazane) mit knapp zentimetergroßen Kristallen auf Feldspat sowie der Berg „Jebel Ewargizen“ bei Tirrhist. Neben Granat, Apatit und Magnetit findet sich hier in Pegmatiten in Episyeniten auch Zirkon.

Eine Reihe von Fundstellen für Zirkon existiert auch in Mosambik. Dazu zählen der Monte Salambidua bei Tete in der gleichnamigen Provinz sowie der 140 km nordöstlich von Lichinga bei der Ansiedlung Navago in der Provinz Niassa liegende Carbonatit von Luicuisse. Viel häufiger ist Zirkon aber in den Pegmatiten und Tantallagerstätten des „Alto-Ligonha-Distrikt“ "sensu lato" in der Provinz Zambezia. Zu den Fundpunkten gehören der Pegmatit von Muiâne (Emdal Mines) und die benachbarten Pegmatite Naipa, Maridge, Nanro, Nacuissupa und Nihire, die Isabela Mine und die Niesse Mine, die Pegmatitgruppe Muhano-Majamala-Cochiline, die Pegmatitgruppe Mocachaia-Alata-Intotcha-Nahora, die Pegmatitgruppe Namacotcha-Conco-Napire-Nassupe-Munhamola-Moneia, die Pegmatitgruppe Namivo-Tomeia-Nampoça und der Marropino-Pegmatit sowie die Pegmatite von Boa Esperança, Namecuna, Namirrapo und Nuaparra. Von Namecuna wurden Kristalle bis zu 6,5 cm × 3,5 cm × 3,5 cm beschrieben. In den genannten Lokalitäten findet sich der Zirkon in den inneren Zonen der Pegmatite in Begleitung von Quarz, Bismutit und verschiedenen Vertretern der Columbitreihe – in einigen Pegmatiten auch in Verwachsungen mit Xenotim-(Y) oder Mikrolith. Die yttrium-, niob-tantal-, thorium- und uranreiche Zirkonvarietät Naëgit wurde im Nuaparra-Pegmatit beobachtet und dort von Quarz, Bismutit, Thorit, Rhabdophan und Metatorbernit begleitet. Die REE-, uran- und thoriumreiche Varietät "Cyrtolith" fand sich in Morrua, während alterierte, bräunliche Zirkone der Varietät Malakon im Gebiet von Ribaue identifiziert worden sind. Einige Zirkone aus dem Alto-Ligonha-Distrikt, insbesondere die von Namacotcha, weisen hohe Gehalte an HfO bis zu 32 Gew.-% auf.

In Asien wird Zirkon seit altersher aus den Edelsteinseifen auf Ceylon, heute Sri Lanka, „in erheblicher Menge“ gewonnen. Die Fundorte befinden sich vor allem in einem vergleichsweise großen Gebiet um die Stadt Ratnapura (Sinhala: „Stadt der Juwelen“) im Distrikt Ratnapura in der Provinz Sabaragamuwa. Ebenfalls im Distrikt Ratnapura befinden sich zwei Fundstellen, die bis zu 10 cm große Zirkonkristalle geliefert haben. Dies sind der „Giant Crystal Quarry“ bei Embilipitiya und Calcitgänge in hochmetamorphen Biotitgneisen in den Katukubura Hills bei Kolonne.

In Afghanistan sind Zirkone vor allem aus dem Pegmatitfeld von Dara-i-Pech (Pech-Tal) im Distrikt von Chapa Dara, Provinz Kunar, bekannt. Die Be-Nb-Ta-Li-reichen Pegmatite liefern rote scharfkantige Kristalle von bis zu 8 cm Größe und meist dipyramidalem Habitus. Ebenfalls im Tal von Pech befindet sich das Fundgebiet von Manogay (Managi). Muttergestein der Zirkonkristalle sind hier aber nicht Pegmatite, sondern proterozoische Marmore.

Zahlreiche Fundorte für ausgezeichnet ausgebildete Zirkone befinden sich in Pakistan. Hierzu gehören das 15 km nordnordwestlich von Astore im Tal des Astor liegende Dorf Harchu, Distrikt Astore; miarolithische Granitpegmatite im Stak-Tal bei Stak Nala, Rakaposhi-Haramosh-Berge, Distrikt Skardu, Baltistan; Alchuri im Shigar-Tal, Distrikt Skardu, Baltistan; die Granitpegmatite von Chilas, Distrikt Diamir, alle in Gilgit-Baltistan (ehemals Northern Areas), sowie der 40 km nordnordwestlich von Peschawar bei Hameed Abad Kafoor Dheri liegende Zagi Mountain (Shinwaro), Khyber Pakhtunkhwa (ehemals North-West Frontier Province). Bei dem letztgenannten Fundort handelt es sich um ein 3 km × 5 km großes Gebiet mit zahlreichen alpinotypen Klüften.

Meist um Einzelkristalle – gelegentlich idiomorph, häufiger mehr oder weniger stark abgerollt – handelt es sich bei Funden von Zirkonkristallen in Myanmar. Dazu zählen das Edelsteinschürfgebiet „Thabeikkyin“ östlich der gleichnamigen Stadt (Thabeikkyin oder Tha Pate Kyin Township) im Bereich der unteren Abhänge des Shan-Plateaus in Richtung Mogok, sowie „Baw-lon-gyi West“ (Bon-lon West) bei der Stadt Kyatpyin unweit Mogok, beide im Distrikt Pyin U Lwin in der Mandalay-Region in Myanmar. Im Bereich der letzteren Fundstelle werden aus kiesigen Alluvionen neben Zirkonen auch Spinelle, Rubine und blaue Saphire sowie Painit gewonnen.

In den Vereinigten Staaten kennt man zahlreiche interessante Fundstellen für Zirkon, darunter vor allem Granitpegmatite in North Carolina. Zu den bekanntesten zählt zweifellos die 1869 von General Clingman entdeckte „Freeman Mine“ bzw. „Meredeth Freeman Zircon Mine“ bei Tuxedo im „Zirconia Pegmatite District“ innerhalb des Henderson County. Von den hier zu findenden graubraunen Zirkonkristallen beutete Clingman „in wenigen Wochen 1000 Pfund“ aus – auch Zwillinge nach mehreren Gesetzen. Ein ehemals auf Vermiculit abgebauter Pegmatit im „Tigerville Prospect“, Greenville County, South Carolina, lieferte bis zu 3 cm große Zirkone. Aus einem unbenannten Pegmatit bei Mellen im Ashland County, Wisconsin, wurden bis zu 20 cm lange, feinnadelige Kristalle („crystals of zircon up to 7 1/4 inches long and 1/16 to 1/8 inch in diameter“) beschrieben. In Graniten bei Haddam, Connecticut wurden ebenfalls Zirkone gefunden, darunter auch als „Calyptolith“ bekannte von der Chrysoberyll-Lokalität Haddam, Middlesex County Nach George Frederick Kunz wurden Zirkone als „schöne schwarze Kristalle“ nahe Franklin, Sussex County, New Jersey gefunden.

Im Bundesstaat New York sind seit langem verschiedene Fundstellen bekannt, die größere Kristalle geliefert haben. Am Ausgang der „Two Ponds“ im Orange County fand man Kristalle bis 2 cm Länge zusammen mit Skapolith, Pyroxen und Titanit; am „Deer Hill“ südöstlich von Canterbury dunkelbräunlichrote bis schwarze Kristalle von bis zu 3 cm Länge und bei Amity, Town of Warwick, weiße, rötlich- und nelkenbraune sowie schwarze Kristalle. Bei „Diana“, Diana Township, Lewis County, traten bis zu 4 cm lange Kristalle zusammen mit Titanit und Skapolith; im St. Lawrence County mit Apatit in körnigen Kalksteinen bei „Robinson’s“ und bei Long’s Mills (Harder Farm?) im Gebiet von Hammond bis 3 cm lange Kristalle sowie bei Rossie, bei Fine („Fred Scott Farm Pegmatites“) und bei Pitcairn auf.

Aus der „Crystal King Zircon Mine“ („Ashton Location“) im Wichita Mountains Wildlife Refuge bei Indiahoma, Comanche County, Oklahoma wurden scharfkantige, glänzende, bräunlichrote Kristalle bis zu 2 cm Größe geborgen. In den 1950er und 1960er Jahren wurde Zirkon im nahegelegenen, im kambrischen Quanah-Granit sitzenden „Hale Spring Pegmatite“ abgebaut.
In Colorado vom „Mount Cheyenne“, richtiger wohl aus dem Gebiet „North Cheyenne Cañon – Helen Hunt Falls Area“ bei Colorado Springs, El Paso Co. fand man glänzende rötlichbraune, fleischrote oder grüne, pyramidale Zirkonkristalle. Vom „St. Peters Dome“ im Cheyenne bzw. St. Peters Dome District, El Paso County stammen scharfkantige, pyramidale, braunrosa Zirkonkristalle bis zu 2 cm Größe. Schließlich sind von der „Pacoima Canyon Pegmatite Locality“ (REE-U-Th) im Allanitpegmatit des Pacoima-Canyon, San Gabriel Mountains, Los Angeles County, Kalifornien, prismatische Zirkonkristalle bis zu 5 cm Länge bekannt.

Aus Syenitpegmatiten und Linsen in Syenitgneisen der 23 km südwestlich von Eganville liegenden Lokalität „Kuehl Lake“ bei Brudenell Township, Renfrew County, Ontario in Kanada, kamen sehr große, bräunlich- bis hyazinthrote, opake Kristalle bis zu 30 cm Länge und 10 cm Breite, die zusammen mit Apatit, Titanit, Hornblende und Calcit gefunden worden sind. Die Fundstelle ist seit den frühen 1880er Jahren bekannt. Die gleichfalls im Renfrew County liegende „Turner’s Island Mine“ befindet sich am Nordende von Turners Island im Lake Clear, ca. 5 km östlich des Westendes des Sees und 12 km südwestlich von Eganville bei Sebastopol Township. Sie ist ebenfalls seit dem 19. Jahrhundert bekannt und gehört aufgrund der hier vorkommenden Riesenkristalle zu den legendären Fundstellen der Welt. Aus den Gängen, die hier durch Hornblendegneise setzen, kennt man neben einem Zirkonkristall von einem Fuß (ca. 30 cm) Länge, einen 700 Pfund (ca. 315 kg) schweren Apatit, einen gleichfalls einen Fuß langen Titanitkristall sowie Titanitkristalle bis zu 18 kg Gewicht. Von hier stammen auch mehrere Zentimeter große, verzwillingte Zirkonkristalle, ferner auch aus der für ihre „Betafit“-Kristalle berühmten „Silver Crater Mine“ (Basin Property), Faraday Township, Hastings County. An diesem wahrscheinlich eine Carbonatit-Intrusion in Biotitamphibolite und syenitisierte Gneise darstellenden Fundort ist der Zirkon häufig mit Betafit vergesellschaftet. In der Regionalen Grafschaftsgemeinde Témiscamingue in der Region Abitibi-Témiscamingue in Québec ist entlang der Ostseite und der Hügel des Lake Sheffield der regionalmetamorph überprägte Alkaligesteinskomplex von Kipawa aufgeschlossen, der in mafischen Gneisen Pegmatit-Linsen aus grobkörnigem Eudialyt, Feldspat, Nephelin, Agrellit und unterschiedlichen Vertretern der Wöhleritgruppe sowie Alkali-Amphibolite und nichtagpaitische Nephelinsyenite enthält. Hier finden sich beige-rötliche bis rötlichbraune, zentimetergroße Zirkonkristalle, die zum Teil mit Magnesiokatophorit und/oder Mosandrit vergesellschaftet sind. Schließlich wurden im „Poudrette Quarry“ am Mont Saint-Hilaire, Regionale Grafschaftsgemeinde La Vallée-du-Richelieu, Montérégie, Québec, winzige, aber perfekt ausgebildete dipyramidale Kristalle von gelber Farbe gefunden, die als „Jargon“ bezeichnet worden sind.

In Brasilien kommen braune bis nahezu weiße, opake Zirkonkristalle von bis zu mehreren Zentimetern Größe sowie Megakristalle von mehr als 50 kg Gewicht aus Nephelinsyeniten im Alkaligesteinskomplex von Peixe, Bundesstaat Tocantins vor. Ein häufig genannter Fundstellenname ist „Alminhas“.

Der Alkaligesteinskomplex von Poços de Caldas in Minas Gerais lieferte unter anderem grünliche dipyramidale Kristalle, die in Hohlräumen in Baddeleyit sitzen oder massige Aggregate aus „Caldasit“ bilden – einer nur hier vorkommenden Mixtur aus Zirkon und Baddeleyit. Metamikter Zirkon in Kristallgruppen bis über 6 cm Größe trat im Pegmatit „Alto Assis Moraes“ in Santa Luzia, Paraíba, auf. Aus der Region „Naque“ in Minas Gerais wurden kastanienbraune Zirkon-Hafnon-Mischkristalle von mehreren Zentimetern Länge gemeldet.

Zu den Fundstellen mit den weltweit größten Zirkonkristallen zählt „Mud Tank“ bei Alcoota Station, Strangways Range, Central Desert Region, Northern Territory, Australien. Mud Tank ist eine in Carbonatiten sitzende Vermiculit-Zirkon-Lagerstätte, die im Tagebau abgebaut wird. Das Sammelgebiet von Mud Tank befindet sich in 6 km Entfernung vom Plenty Highway. Die hier gefundenen Zirkonkristalle können Größen bis zu 2,5 cm erreichen, sind honig- bis zimtbraun, wachsglänzend und weisen häufig durchscheinende Bereiche auf.

In meist abgerollter Form auf Seifenlagerstätten wird Zirkon – neben Fundstellen in Myanmar, Sri Lanka, Australien, Brasilien, Madagaskar und Mosambik – auch in Kambodscha, Thailand, Korea, Nigeria und Tansania gefördert.

Auch in einigen Mineralproben vom Meeresboden im Gebiet des Mittelatlantischen Rückens und des Südwestindischen Rückens sowie aus Tiefbohrungen vor der Küste von New Jersey wurde Zirkon gefunden, ebenso in einigen vom Mond stammenden Gesteinsproben.

Seit der Entwicklung der radiometrischen Altersbestimmung kommt Zirkonen besonders in der Geochronologie Bedeutung zu, da sie Spuren der radioaktiven Nuklide U, U und Th (von 10 ppm bis zu 5 Gew.-%) enthalten. Alle diese Isotope zerfallen über Zerfallsreihen zu verschiedenen Bleiisotopen. Durch Messen der entsprechenden Uran-Blei- bzw. Thorium-Blei-Verhältnisse kann das Kristallisationsalter eines Zirkons bestimmt werden.
Verhältnisse stabiler Isotope geben Auskunft über die Umgebung, in der die Kristalle entstanden sind. Zirkone bewahren diese Information, da sie gegenüber geologischen Einflüssen wie Verwitterung und selbst hochgradiger Gesteinsmetamorphose äußerst resistent sind. So deuten Zirkone vom Mount Narryer und aus den Jack Hills im Narryer-Gneis-Terran, Yilgarn-Kraton, Westaustralien, die mit einem Alter von 4,404 Milliarden Jahren die ältesten bisher auf der Erde gefundenen Minerale darstellen, auf eine überraschend frühe Existenz kontinentaler Kruste und auf einen flüssigen Ozean hin. Die Jack Hills liegen südlich vom Murchison River an der Grenze zwischen dem Shire of Murchison und dem Shire of Meekatharra, etwa 800 km nördlich von Perth. Als ältestes datiertes Mineral Europas gilt ein 3,69 Milliarden Jahre alter Zirkonkristall aus Gneisen, die im Øvre-Pasvik-Nationalpark im Norden Norwegens, unweit der Stadt Kirkenes im Pasviktal in der Gemeinde Sør-Varanger, anstehen. Zirkone in einer Mondgesteinsprobe (Brekzie 72215) wurden auf 4,417 Milliarden Jahre datiert und zeigen damit einen sich länger hinziehenden Erstarrungsprozess der Mondkruste nach Entstehung des Mondes an.

Eine wichtige Rolle spielt der Zirkon bei der Analyse des Schwermineralspektrums von Sedimentgesteinen. Durch Bestimmung von Kristalltracht und Kristallhabitus (dazu zählt auch das Längen-/Breitenverhältnis und der Abrollgrad) der Zirkone sowie der Ermittlung ihres Spurenelementgehaltes können Herkunfts- und Liefergebiete der Sedimente mit ihren diskreten Gesteinstypen eingegrenzt oder sogar zugeordnet sowie die Aufarbeitung, mechanische Abrasion und Sortierungseffekte umfassenden Transportprozesse bis zum Ablagerungsraum der Sedimente im Idealfall auch quantifiziert werden.

Aufgrund seiner hohen BG-Dispersion von 0,038 (im Vergleich dazu: Diamant: 0,044, Zirkonia: 0,066 und Quarz: 0,013) sind größere Exemplare geschätzte Schmucksteine. Farblose Zirkone erhalten meist Brillantschliff, farbige Steine auch Treppenschliff.
Durch Wärmebehandlung kann die Farbe von braunen oder braunroten bzw. trüben Zirkonen verändert werden. Gefärbte Zirkone werden durch Glühen unter oxidierenden Bedingungen (850–900 °C) farblos oder gelb bis rotgelb. Bei Wärmezufuhr unter reduzierenden Bedingungen (900–1000 °C) entstehen blaue Kristalle. Für Laien ist eine Unterscheidung des farblosen Zirkons von Diamant nur schwer möglich, da beide Minerale vergleichbare Brillanz und Dispersion („Feuer“) aufweisen. Diese Eigenschaften führten zu der Bezeichnung "Matara-Diamant". Solche farblosen, in Sri Lanka vorkommenden Zirkone hielt man im 19. Jahrhundert für minderwertige Diamanten. Ebenso ist für Laien eine Verwechslung des blauen Zirkons mit Spinell möglich. Für farbige Zirkone existieren diverse Handelsnamen. Als "Ratanakiri", abgeleitet von „Ratanakiri“ (kambodschanisch für „Edelsteinberg“), werden blaue Zirkone aus der Provinz Preah Vihear in Kambodscha bezeichnet. Auch mit dem Terminus "Starlit" wurde eine Zirkonvarietät benannt, die durch Brennen anderer Zirkone bei hohen Temperaturen einen blauen Farbton erhält. "Kaduna"-Zirkone stammen aus Nigeria und zeichnen sich durch eine honiggelbe Färbung aus. Die durch Brennen erhaltenen Farben sind jedoch nicht immer beständig – ultraviolette Strahlung und/oder das direkte Sonnenlicht können Veränderungen der Färbung bewirken.

Einer der größten bekannten geschliffenen Zirkone wird in der Smithsonian Institution aufbewahrt. Er ist von brauner Farbe und hat ein Gewicht von 105,80 Karat.

Zirkon ist das wichtigste Erz sowohl für Zirconium als auch Hafnium. Zirconium findet Verwendung als Legierungsmetall (Ferrozirkon) und – in Form der korrosionsfesten Legierung Zirkalloy (mit kleinen Mengen von Eisen, Chrom und Zinn) – als Reaktormaterial. Hier wird es wegen seines geringen Neutroneneinfangquerschnitts als Hüllmaterial für Brennstoffstäbe verwendet. Zirconium-Niob-Legierungen weisen supraleitende Eigenschaften auf, auch enthalten die meisten Superlegierungen auf Nickel- und Cobalt-Basis zwischen 0,03 und 2,2 % Zirconium. Gläser aus Zirconiumfluoriden weisen eine extrem große Infarotdurchlässigkeit auf und werden daher in der Glasfasertechnik verwendet. Zirkonglas dient der Ummantelung von radioaktiven Abfällen (z. B. Plutonium) zur Endlagerung, wobei die Behälter nach aktuellen Forschungen etwa 2000 Jahre der Strahlung standhalten. Wissenschaftler um Ian Farnan vom britischen Cambridge Nuclear Energy Centre an der University of Cambridge haben allerdings in Experimenten herausgefunden, dass die erwartete Haltbarkeit des Zirkonglases gegen das Plutoniumisotop Pu nur etwa 210 Jahre beträgt.

Bei dem aus Zirconium hergestellten Zirkonia handelt es sich um künstlich hergestellte Einkristalle aus Zirconium(IV)-oxid, die in der kubischen Hochtemperaturphase stabilisiert wurden und häufig als preiswerte Diamantimitation für Schmuck verwendet werden. Zirkonia lässt sich optisch nur schwer von Diamanten unterscheiden – hierfür wird die unterschiedliche Wärmeleitfähigkeit beider Substanzen verwendet. Während Diamanten besonders gut wärmeleitend sind, leiten Zirkonia Wärme besonders schlecht. Weitere relativ einfache und durch zerstörungsfreie Messverfahren zu ermittelnde Unterschiede zum Diamanten sind die unterschiedliche Lichtbrechung (Brechungsindex Zirkonia 2,18, Diamant 2,42), Dispersion (Zirkonia 0,066, Diamant 0,044) und Dichte (Zirkonia 5,8 g/cm³, Diamant 3,5 g/cm³). Stabilisiertes Zirkoniumoxid wird in verschiedenen Formen und Dimensionen hergestellt. Da die Verbindung ZrO einen extrem hohen Schmelzpunkt aufweist, werden schlickergegossene Ziegelsteine aus polykristallinem Zirkon oder Tiegelmaterial aus Zirkonia zur Herstellung mechanisch widerstandsfähiger, säurebeständiger und hochfeuerfester Werkstoffe verwendet. Solche hochfeuerfesten Oxidkeramiken weisen nur geringe Wärmeleitung und thermische Ausdehnung auf.

In der chemischen Industrie findet Zirconium Anwendung bei der Herstellung von Spinndüsen, Rohren, Rührern, Ventilen und Wärmetauschern. Zusammen mit Aluminiumoxid bzw. Korund findet Zirkon als Formsand in Gießereien, in der Glasindustrie und als Schleifmittel Verwendung. Poröse, ZrO-basierte Keramiken sind ausgezeichnete Wärmeisolatoren – so können in Behältern aus Zirkonia Hochtemperaturgläser und Metalle mit hohem Schmelzpunkt geschmolzen werden. Zirkonia wird auch zur Herstellung von Schmelztiegeln und abrasionsfesten Werkstoffen wie beispielsweise Zahnimplantataufbauten und Zahnkronen/-brückengerüsten verwendet.

Anwendung findet Zirkonia schließlich auch in Form von polykristallinen Fasern zur Verstärkung in Verbundwerkstoffen () und allgemein für Höchsttemperatur-Isoliermaterialien. Die Hauptanwendungsgebiete der ZrO-Fasern sind Hochtemperaturöfen sowie Hitzebarrieren in Raketen, Raumfähren und Abschussrampen. Mit solchen Fasern isolierte Hochtemperatur-Laboröfen lassen sich sehr schnell aufheizen und anschließend auch sehr schnell wieder abkühlen. Für die Herstellung von glasfaserverstärktem Zement entwickelte „Cemfil“-Glasfasern enthalten einen hohen Anteil an Zirkon und sind dadurch besonders alkalibeständig. Diese Fasern erreichen zwar nicht dieselben Verstärkungseffekte wie Asbest, stellen aber wegen ihrer Unschädlichkeit gute Ersatzmaterialien für Asbestfasern dar.

Andere Zirconium-Verbindungen werden für Glasuren in der keramischen und in der Glasindustrie verwendet. Zu solchen mit Zirkon hergestellten Spezialkeramikprodukten zählen Zirkonporzellan, Zirkonsteatit, Zirkonglasuren und Zirkonemails. Die bei der Verbrennung von Zirconium entstehende Flamme weist eine Temperatur von 4660 °C auf und gibt ein reinweißes, sonnenartiges Licht ab. Daher wird Zirconium in Blitzlampen sowie in Feuerwerk und Leuchtspurmunition benutzt. Airbag-Gasgeneratoren und pyrotechnische Sicherheitsgurtstraffer enthalten ebenfalls Zirconium.

In der populärwissenschaftlichen Literatur wird Zirkon mitunter fälschlich als moderner Hochleistungswerkstoff in der Wiederherstellungsmedizin, vor allem der Zahnmedizin, genannt. Dabei ist jedoch regelmäßig nicht das über seine chemische Formel ZrSiO definierte Silikat Zirkon gemeint, sondern Zirkoniumdioxid ZrO mit geringen Beimengungen von Yttriumoxid zur Optimierung der Materialeigenschaften. Das Silikat Zirkon hingegen wird in der Wiederherstellungsmedizin nicht eingesetzt.

In den Natur- und heilkundlichen Schriften der mittelalterlichen Nonne und Universalgelehrten Hildegard von Bingen ist unter anderem die Verwendung von "Hyazinth" als Heilstein überliefert. Je nach Durchführung vorgeschriebener Anwendungsregeln soll er in der Lage sein, Sehschwäche, trübe Augen und Augenschmerzen, Fieber, Herzbeschwerden und durch teuflische Zauber ausgelösten Wahnsinn zu heilen. Zudem könne er durch seine innere Wärme bei Männern und Frauen das „Feuer des Blutes“ (Libido) auslöschen.

Der von Hildegard von Bingen beschriebene "Hyazinth" entspricht jedoch nicht der heute unter diesem Begriff bekannten gelbroten bis braunen Zirkonvarietät, auch wenn dies in vielen aktuellen esoterischen Publikationen fälschlich behauptet wird. Im griechischen Wortursprung ist ὐάκινθος ‚Hyacinthus‘ die Bezeichnung für einen blauen Farbton und die gleichnamige Blumengattung. Bei dem historischen "Hyazinth" handelte es sich demnach um einen blauen Stein

Dennoch wird der Zirkon auch von heutigen Esoterikern als bedeutender Heilstein angesehen, der angeblich Krampfadern und Wasserblasen an Beinen und Füßen beseitigen sowie Hodenerkrankungen heilen können soll. Daneben wird er nach Uyldert (1983) in der Varietät "Hyazinth" als Planetenstein dem Jupiter und nach Richardson und Huett (1989) als Zirkon dem Pluto zugeordnet. Als Amulettstein ist der Zirkon dem Tierkreiszeichen Jungfrau und als Monatsstein dem Dezember zugeordnet.

Ein "Roter Zirkon" spielt bei dem 2015 von Bert Saurbier veröffentlichten, gleichnamigen Eifel-Thriller die zentrale Rolle. In einem geheimen Forschungszentrum auf Burg Vogelsang mitten im Nationalpark Eifel arbeitet ein internationales Expertenteam daran, das Geheimnis um einen etwa zwei Meter langen, feuerroten Zirkonkristall zu lüften. Dieser steckte in einem Milliarden Jahre alten australischen Meteoriten und erzeugt ein Kraftfeld, der Objekte in seiner Nähe deutlich an Gewicht verlieren lässt.





</doc>
<doc id="5785" url="https://de.wikipedia.org/wiki?curid=5785" title="Zecken">
Zecken

Die Zecken (Ixodida) sind eine Ordnung der Milben (Acari), die der Überordnung Parasitiformes zugeordnet werden. Unter den Zecken finden sich die größten Milbenarten. Alle Arten sind blutsaugende Ektoparasiten an Wirbeltieren, darunter auch dem Menschen. Viele Zeckenarten sind bedeutende Krankheitsüberträger. 2004 waren weltweit etwa 900 Zeckenarten bekannt.

Wie bei den meisten Milbenarten besteht der Körper der Zecken aus zwei beweglich gegeneinander abgesetzten Abschnitten. Der vordere Abschnitt, bei den Milben generell Gnathosoma benannt, trägt bei den Zecken (aus historischen Gründen) den abweichenden Namen Capitulum. Dieser Abschnitt entspricht dem, was landläufig als "Zeckenkopf" bezeichnet wird. Der übrige Rumpf wird Idiosoma genannt. Der vordere, die Beine tragende Abschnitt, das Podosoma, geht ohne scharfe Grenze in den hinteren Abschnitt, das Opisthosoma, über. Auf dem hinteren Abschnitt des Capitulum tragen viele Schildzecken zwei auffallende Porenfelder, die nach verschiedenen Ansichten entweder als Drüsen oder als Sinnesorgan dienen. Seitlich am Idiosoma sitzen die vier Beinpaare. Die Beine bestehen aus sechs deutlich gegeneinander abgesetzten Segmenten (benannt Coxa-Trochanter-Femur-Patella oder Genu-Tibia-Tarsus). An der Spitze des Tarsus sitzen zwei Krallen und bei den Schildzecken (und den Larven der Lederzecken) ein Haftpolster (Pulvillus) zum Festhalten an glatten Oberflächen. Seitlich am Idiosoma sitzen zwei Öffnungen der Tracheen, die Stigmen heißen und luftgefüllte Kanäle sind, die die Körperoberfläche für die Atmung vergrößern. Vor allem bei Schildzecken sitzen sie meist innerhalb eines sklerotisierten und auffallend skulpturierten Stigmenfelds. Viele Zeckenarten besitzen kleine, wenig auffallende Augen, die bei den Schildzecken paarweise auf der Körperoberseite (dorsal) sitzen, aber z. B. bei der Gattung "Ixodes" fehlen. Bei den Lederzecken kann eine höhere Anzahl vorkommen, die randlich auf der Körperunterseite (ventral) sitzen. Zumindest bei einer Zeckenart, der Kamelzecke "Hyalomma dromedarii", ist optische Wirtsfindung (Skototaxis) durch die Wahrnehmung der Silhouette des Wirts nachgewiesen.

Die beiden Familien Schildzecken und Lederzecken unterscheiden sich dadurch, dass bei den Schildzecken der namengebende Schild (Scutum) ausgebildet ist, der oben (dorsal) auf dem Idiosoma sitzt. Bei vielen Zeckenarten wie dem Gemeinen Holzbock bedeckt er beim Männchen den gesamten Rumpf, beim Weibchen nur etwa die Hälfte. Bei den Lederzecken fehlt ein Schild. Außerdem sitzt bei den Lederzecken das Capitulum mit den Mundwerkzeugen etwas bauchseitig (ventral) am Körper, so dass es bei Betrachtung von oben nicht sichtbar ist.

Kennzeichnend für die Zecken sind vor allem die vorn am Capitulum sitzenden Mundwerkzeuge. Diese sind für die blutsaugende Lebensweise eigentümlich umgestaltet. Außen sitzen zwei viergliedrige Taster (Palpen), die Sinnesorgane sind und nicht am Saugvorgang teilnehmen. Sie umhüllen in Ruhestellung häufig die eigentlichen Mundwerkzeuge. Zentral sitzt ein Hypostom genannter Stechrüssel, der häufig Zähne aufweist, die als Widerhaken wirken. Auf der Oberseite (dorsal) und meist von unten her nicht sichtbar sitzen die beiden Cheliceren. Diese bestehen aus einem zweiteiligen Schaft, der parallel zum Hypostom nach vorne gestreckt wird und der unbeweglich mit breiter Basis am basalen Teil des Capitulums ansitzt. An der Spitze tragen sie mehrere bewegliche zahnförmige Vorsprünge, Chelicerenfinger genannt. Die Zecke ritzt beim Saugvorgang mit ihren Cheliceren die Haut ein und schiebt anschließend das Hypostom in die Wunde. Entgegen einer verbreiteten Vorstellung ist das Hypostom aber kein hohler Saugrüssel: die Mundöffnung liegt basal zu ihm auf der breiteren Basis des Capitulums. Das Hypostom kann eine eingesenkte Nahrungsrinne tragen. Dieser Vorgang wird umgangssprachlich als Zeckenbiss bezeichnet, korrekt ist jedoch Zeckenstich.

Beim Saugvorgang schafft das Tier mit den Mundwerkzeugen eine Wunde, indem Gewebe mit kleinen Blutkapillaren aufgerissen wird. Das sich hier ansammelnde Blut wird anschließend aufgesaugt (sog. pool-feeder). Langrüsselige Tiere (Prostriata) wie der Gemeine Holzbock verankern sich beim Saugvorgang vorwiegend mit den Mundwerkzeugen, kurzrüsselige (Metastriata) wie die "Dermacentor"-Arten scheiden zu diesem Zweck eine leim- oder kittartige Substanz aus. Der Saugvorgang ist bei den Lederzecken relativ kurz, etwa 30 bis 60 Minuten, Ausnahmen bilden die Larven. Bei den Schildzecken kann er viele Tage bis Wochen dauern. Der Körper der weiblichen Schildzecken kann dabei auf das Zwanzigfache seines ursprünglichen Volumens und das Hundertfache des Gewichts anschwellen, daran sind neben der Dehnung der Kutikula auch echte Wachstumsvorgänge beteiligt. Bei den Lederzecken wird weniger Blut, meist etwa das Fünffache des Körpervolumens und das Zehnfache des Gewichts bei einem Saugvorgang aufgenommen.

Beim Saugvorgang gibt die Zecke Speichel in die Wunde ab. Dieser enthält bei den bisher untersuchten Arten viele Hundert unterschiedliche Proteine, die größtenteils bei keiner anderen Tiergruppe gefunden wurden. Wichtigste Funktion des Speichels ist es, das Zusammenklumpen der Blutplättchen zu verhindern, das ansonsten den Wundverschluss einleitet. Dazu greifen etliche Enzyme an verschiedenen Stellen der Signalkaskade ein. Auch die weitere Blutgerinnung wird so unterdrückt. Außerdem werden Entzündungsreaktionen unterdrückt (z. B. durch Prostaglandine) und das Schmerzempfinden gehemmt, um Abwehrreaktionen des Wirts zu vermeiden. Gegen Hormone und Signalstoffe wie Histamin, Serotonin und Bradykinin wirksame Hemmstoffe können teilweise mehrere dieser Zwecke parallel erreichen. Der abgegebene Speichel kann Bakterien, Viren und andere Krankheitserreger enthalten, durch die der Zeckenstich sein besonderes Risiko erhält. Obwohl der Zeckenspeichel generell die Funktion der körpereigenen Immunabwehr an der Einstichstelle vermeidet, kann es beim Menschen in seltenen Fällen zu allergischen Reaktionen vom Soforttyp kommen. Die immunmodulatorischen Beziehungen zwischen Parasit und Wirt sind dabei äußerst komplex. Nach wiederholten Kontakten mit Zecken kann die Immunabwehr stark ansteigen, was allerdings artspezifisch ist, weil Zeckenarten wirtsspezifische Immunmodulatoren entwickelt haben.
Dabei können unerwartete Wechselbeziehungen auftreten. Beispielsweise waren Mäuse dann immun gegen Zecken-Borreliose, wenn sie vorher mehrfach von nicht infizierten Zecken gestochen worden waren.
Selten, aber lebensgefährlich ist die Zeckenparalyse, bei der ein als Nervengift wirkender Stoff eine Hemmung der motorischen Nerven bewirken kann, die sich von der Einstichstelle her fortsetzt.

Nach einer ausgedehnten Blutmahlzeit erreichen vor allem weibliche Zecken eine Größe von bis zu 3 cm.

Zecken sind weltweit verbreitet und kommen überall da vor, wo ihre Wirtsarten leben. Die Verbreitung der einzelnen Arten hängt von der Verbreitung ihrer jeweiligen Wirte und außerdem von Umweltfaktoren wie Temperatur und Luftfeuchte ab. Die meisten Zeckenarten besitzen einen oder mehrere Vorzugswirte, können aber bei Nahrungsmangel notfalls auch an anderen Wirten Blut saugen. Etwa zwanzig Zeckenarten kommen in Deutschland vor, einige davon sehr selten oder eventuell nur vorübergehend eingeschleppt. Die Schildzecke Gemeiner Holzbock ("Ixodes ricinus") ist dabei die deutsche Zeckenart, die am häufigsten Menschen befällt. Andere häufige Schildzeckenarten sind hier z. B. die Igelzecke ("Ixodes hexagonus"), die Schafzecke ("Dermacentor marginatus"), in Süddeutschland auch die Auwaldzecke ("Dermacentor reticulatus"). Eine Reihe weiterer Arten lebt fast nur an Vögeln oder ist sehr selten und geht so gut wie nie auf den Menschen über. Weltweit die häufigste Art, die auch auf dem Menschen parasitiert, ist die Braune Hundezecke ("Rhipicephalus sanguineus"), die in Deutschland wegen zu geringer Wärme aber nicht dauerhaft leben kann.

Die meisten Arten der Familie der Lederzecken sind auf die Tropen und Subtropen beschränkt. In Mitteleuropa lebt die Art "Argas vespertilionis" an Fledermäusen. Häufigste Art ist aber die Taubenzecke "Argas reflexus", die an Stadttauben, seltener auch an anderen Vogelarten, in Mitteleuropa ausschließlich in Häusern und anderen Gebäuden, lebt.

Unter den Zeckenarten gibt es prinzipiell zwei Strategien der Wirtsfindung:

Zur Wirtsfindung dienen ihnen verschiedene chemische Sinne, vor allem Kohlendioxid-Sensoren, die in einem speziellen Organ am letzten Beinglied (Haller-Organ) sitzen. Die Braune Hundezecke ist ein Beispiel für einen Jäger.

Bei den Männchen dauert eine Blutmahlzeit in der Regel nur wenige Tage, da sie nur für ihre eigene Ernährung Blut benötigen. Sie können beim Warten auf ein Weibchen mehrere Male Blut saugen. Die Weibchen sind nicht nur zur eigenen Ernährung auf Blut angewiesen, sondern auch zur Eibildung und brauchen daher eine wesentlich größere Blutmenge. Ihre Blutmahlzeit kann ungestört Wochen andauern.

Zum Auffinden des Nahrungsopfers ist den Zecken ihr Haller-Organ behilflich. Dieser grubenförmige Chemorezeptor, der mit Sinnesborsten ausgestattet ist, befindet sich am letzten Beinelement (dem Tarsus) des ersten Beinpaares und kann Stoffe wie Ammoniak, Kohlendioxid, Milchsäure und vor allem Buttersäure erkennen, die von den jeweiligen Wirtstieren durch Atem und Schweiß abgegeben werden. In der Lauerstellung (das vordere Beinpaar wird leicht schwenkend nach vorne gestreckt, mit den hinteren drei Beinpaaren umklammern sie ihren Ansitz) wird dieses Organ vorgestreckt, damit die Zecken die Sinnesreize besser empfangen können. Die wartenden Zecken wechseln sofort von der Wartestellung (die eingefalteten Vorderbeine liegen nahe am Körper) in die Lauerstellung, wenn sie durch Geruchsreize, Lichtveränderung – besonders von hell zu dunkel – oder durch Vibrationen bemerken, dass sich möglicherweise ein Wirt nähert. Sie hängen sich anschließend an alles, was ihren jeweiligen Aufenthaltsort streift und krabbeln dann oft bei Tier und Menschen bis zu mehreren Stunden lang am Körper umher, bis sie eine passende Einstichstelle gefunden haben. Zecken sind dabei sehr wählerisch und bevorzugen etwas feuchte, warme und gut durchblutete, dünne Haut. Beim Menschen sind besonders die Kniekehlen, der Haaransatz, die Leistenbeuge und die feine Haut hinter den Ohren ein beliebtes Ziel.

Nach Beendigung der Blutmahlzeit lassen sie sich von ihrem Wirt abfallen und die Weibchen suchen anschließend eine geschützte Stelle am Boden, um alsbald Eier abzulegen. Eine Eiablage kann mehrere Tage dauern, wobei etwa alle zehn Minuten ein Ei abgelegt wird. Nachdem ein solches aus der Bauchöffnung ausgetreten ist, wird es mit den Mundwerkzeugen an einer Drüse vorbeigeführt und dabei mit einer Schutzschicht versehen, die das frische Ei vor dem Vertrocknen schützt. Bei einer Eiablage der Schildzecken werden tausende Eier produziert (bis 20.000 in den Gattungen "Hyalomma" und "Amblyomma"), wonach das Weibchen stirbt.

Lederzecken-Arten, die viel öfter an ihren Wirten saugen müssen als Schildzecken, findet man deshalb beinahe ausschließlich in Nestern, Bauten oder Schlupfwinkeln ihrer Wirte (wenige tropische Arten sind aktive Jäger). Im Gegensatz zu den Schildzecken nimmt hier das Weibchen mehrere Male hintereinander Blutmahlzeiten auf und legt anschließend jedes Mal Eier (bis zu sieben Mal). Die Eizahl ist dafür aber jedes Mal geringer. Sie ziehen sich nach jeder Blutmahlzeit in Spalten und Winkel zurück und warten anschließend ab, bis wieder ein Wirt in Reichweite kommt. Arten der großen Gattung "Ornithodoros", die Zugvögel befallen, können die Zeit während der Abwesenheit ihres Wirtes im Nest abwarten. Es wird berichtet, dass Lederzecken viele Jahre ohne Nahrungsaufnahme wartend überleben können. Den Rekord hält "Ornithodoros papillipes" mit elf Jahren. Dies kann bei gebäudebewohnenden Arten wie der Taubenzecke auch für den Menschen zu großen Problemen führen.

Zecken durchlaufen nach dem Schlüpfen wie alle Milben stets drei Entwicklungsstadien und zwei Häutungsprozesse: Larve (mit sechs Beinen), Nymphe (mit acht Beinen) und Adulte (die erwachsenen Männchen und Weibchen). Die Geschlechtsmerkmale bilden sich erst in der adulten Phase aus.

Die "Argasidae" (Lederzecken) haben mehrere, von zwei bis zu acht Nymphenstadien. Jede Larve und Nymphe ist auf Blut eines Wirtes angewiesen. Dabei wird häufig dieselbe Wirtsart in allen Stadien befallen. Bei den Lederzecken findet die Befruchtung des Weibchens abseits des Wirts in der Umgebung (meist im Bau oder Nest des Wirts) statt. Die Tiere finden sich gegenseitig durch Signalstoffe (Pheromone). Diese wirken häufig schon auf ältere Nymphen. Eine als Pheromon wirksame Substanz ist das im Kot enthaltene Guanin.

Bei den "Ixodidae" (Schildzecken) kommt nur ein Nymphenstadium vor. Bei vielen Arten wechseln die Tiere zwischen den verschiedenen Stadien die Wirtsart, häufig mit Größenzunahme. Es kommen aber Arten vor, bei denen die Häutung von der Larve zur Nymphe auf dem Wirt erfolgt, manchmal sogar beide Häutungen, so dass nur das reife Weibchen den Wirt verlässt (Zwei- und Ein-Wirt-Arten, z. B. Gattung "Rhipicephalus"). Bei vielen Arten bleiben Larven und Nymphen im Bau oder im Lager des Wirtes. Seltener sind alle drei Stadien freilebend. Beim Gemeinen Holzbock schlüpft z. B. aus dem Ei die sechsbeinige Larve. Diese sucht sich schon nach wenigen Tagen einen geeigneten Zwischenwirt (Nagetier), saugt sich dort fest und nimmt innerhalb von zwei bis drei Tagen Blut auf. Nach dem Saugen lässt sie sich abfallen und häutet sich nach einigen Monaten zur ersten achtbeinigen, rund 1,5 bis 2 mm großen Nymphe. Diese sucht sich nun abermals einen größeren Wirt (zweiter Zwischenwirt – Katze) und saugt dort ebenfalls Blut. Unter mitteleuropäischen Klimabedingungen suchen die meisten Nymphen, die sich im Sommer oder Herbst gehäutet haben, jedoch nicht sofort einen neuen Wirt für eine Blutmahlzeit, sondern treten zunächst bis zum nächsten Frühjahr in ein Ruhestadium ein (kann in besonders milden Wintern auch ausfallen).
Erst nach dieser Pause suchen sie sich einen Wirt und anschließend findet eine weitere Häutung zum adulten Tier statt. Das ausgewachsene Tier befällt danach den Endwirt (Mensch, Rind). Auf dem Wirt findet die Paarung statt, wonach das Männchen stirbt. Kommt es nicht sofort zur Paarung, verbleibt das Weibchen im halb vollgesogenem Zustand auf dem Wirt und wartet so auf ein Männchen.
Das Weibchen lässt sich nach dieser letzten Blutmahlzeit fallen und legt kurz darauf seine Eier ab.

Zecken übertragen beim Zeckenstich aufgrund ihrer Lebensweise häufig Krankheitserreger zwischen den Wirten, ohne jedoch selbst zu erkranken. Es handelt sich dabei um mehr Arten von Krankheitserregern als bei jeder anderen parasitischen Tiergruppe. Auch Menschen sind durch Erkrankungen wie Borreliose, Frühsommer-Meningoenzephalitis ("FSME"), Babesiose, Ehrlichiose, Rickettsiosen oder Neoehrlichiose betroffen.

Wichtigste Überträger in Mitteleuropa sind die Arten der Gattung "Ixodes" mit der häufigsten einheimischen Art, dem Gemeinen Holzbock ("Ixodes ricinus"), daneben auch die Gattungen "Rhipicephalus", "Dermacentor", "Haemaphysalis", "Amblyomma" und aus der Familie der Lederzecken die Gattungen "Argas" und "Ornithodorus". Während Zecken in der Vergangenheit nur im Sommerhalbjahr eine Gefahr darstellten, da sie in den Wintermonaten Winterruhe hielten, sind sie mittlerweile – bedingt durch die globale Erwärmung – in milden Wintern ganzjährig aktiv.

Für weitere ausführliche Informationen diesbezüglich siehe Zeckenstich.

Als natürliche Feinde der Zecken sind bisher festgestellt worden:

Die ökologischen Ansprüche der verschiedenen Zeckenarten und demgemäß auch ihr Lebensraum sind sehr unterschiedlich. Viele Arten, z. B. der Gemeine Holzbock, sind sehr luftfeuchtebedürftig und vertrocknen bei direkter Sonneneinstrahlung rasch. Obwohl Zecken auch starke Fröste unbeschadet überstehen können, wirken sich vor allem lang andauernde Kälteperioden für viele Arten letal aus und begrenzen das Verbreitungsgebiet nach Norden. Einzelne Jahre mit abweichenden Wetterbedingungen, z. B. milde Winter, können sich stark auf die Populationsgröße auswirken.

Zurzeit wird diskutiert, wie sich der derzeitige Klimawandel auf die Verbreitung der Zecken in Mitteleuropa oder Nordamerika auswirkt. Einige Zeckenarten haben nachweisbar ihr Verbreitungsgebiet nach Norden ausdehnen können (z. B. "Ixodes ricinus" in Skandinavien), bei anderen sind die Auswirkungen umstritten. Dabei sind stets umfangreiche Wechselbeziehungen, z. B. zwischen Temperatur und Luftfeuchte, in Rechnung zu stellen.

Schwestergruppe der Zecken sind vermutlich Milben der Ordnung Holothyrida. Diese saugen tote Tiere (vor allem Arthropoden) aus.

Die Zecken selbst werden in drei Familien eingeteilt und es gibt insgesamt weltweit mehr als 850 Arten.


Fossile Belege sind äußerst selten. Nahezu alle fossilen Zecken wurden in kreidezeitlichem und tertiärem Bernstein gefunden. Die ältesten Funde sind rund 100 Millionen Jahre alt (Birmit und New-Jersey-Bernstein). Bei den kreidezeitlichen Fossilien handelt es sich um Larven; alle bisher gefundenen adulten Zecken stammen aus Bernstein tertiärer Lagerstätten (eozäner Baltischer Bernstein, miozäner Dominikanischer Bernstein). In der Forschung zur Evolution der Zecken herrscht Einigkeit, dass deren Entwicklung deutlich früher begann als die ältesten Fossilien andeuten. Uneinigkeit hingegen besteht in der Frage, ob dies schon im Devon oder erst in der Trias der Fall war und ob die ersten Wirte Amphibien oder Reptilien waren.




</doc>
<doc id="5786" url="https://de.wikipedia.org/wiki?curid=5786" title="Zagreb">
Zagreb

Zagreb (deutsch "Agram", heute selten genutzt; ) ist die Hauptstadt und zugleich größte Stadt Kroatiens. Die Stadt Zagreb selbst hat auch die Funktionen einer Gespanschaft. Die nähere Umgebung der Stadt bildet getrennt von dieser die Gespanschaft Zagreb, deren Verwaltungssitz auch die Stadt Zagreb ist. In Zagreb residieren ein katholischer Erzbischof, die Kroatische Akademie der Wissenschaften und Künste sowie wichtige Verwaltungs- und Militärbehörden. Als Handels- und Finanzzentrum hat die Stadt nationale und regionale Bedeutung. 

Die Zagreber Kathedrale ist Sitz der katholischen Erzdiözese Zagreb.

Der Name Zagreb kommt vermutlich von "zagrabiti" „(Wasser) schöpfen“. Anderen Quellen zufolge bedeutet "Zagreb" „hinter dem Berge“ (kroat. "za bregom") oder „hinter dem Damm“ "(za grebom)".

Zagreb ist die größte kroatische Stadt. Es ist auch die einzige Kroatiens, die (mit Vororten) mehr als eine Million Einwohner hat. Nach der Volkszählung von 2011 lebten 790.017 Menschen in der Stadt. Im Umland, in dem sich äußere Vororte und nahegelegene kleinere Städte wie Dugo Selo, Samobor, Velika Gorica oder Jastrebarsko befinden, lebten 317.606 Menschen. Die Mehrheit der Bevölkerung stellen mit 93,14 % die Kroaten. 2,22 % gehören der serbischen Minderheit an, 1,03 % gehören der bosniakischen Minderheit an und 2,31 % verschiedenen anderen Minderheiten, darunter Deutschsprachige, Ungarn, Slowenen, Tschechen und Ukrainer.
Anmerkungen

Der Name Zagreb wurde zum ersten Mal im Jahre 1094 erwähnt, als der in Personalunion ungarisch-kroatische König Ladislaus I. die Zagreber Diözese gründete. Die Stadt entwickelte sich aus den beiden Siedlungskernen "Kaptol (Bischofsstadt)" im Osten und "Gradec (Oberstadt)" im Westen. Kaptol war die Stadt des Klerus, in der seit dem 11. Jahrhundert der Bischof und die Kanoniker des Zagreber Bistums residierten. In der Oberstadt auf dem westlich benachbarten Bergsporn siedelten sich Kaufleute und Handwerker an. Interessenskonflikte zwischen den beiden Siedlungen führten immer wieder zu Auseinandersetzungen.

Im 13. Jahrhundert hatte Südosteuropa unter verheerenden Plünderungen der Tataren (mongolische Volksstämme) zu leiden. Der König von Kroatien und Ungarn, Béla IV., organisierte von Gradec aus die Verteidigung. Aus Dankbarkeit für die Unterstützung verlieh er 1242 den Einwohnern von Gradec die Bulla Aurea, ein Symbol der Freiheit und Unabhängigkeit. Durch dieses Dokument wurde Gradec zur freien königlichen Stadt. Nun erlebte es seine wirtschaftliche Blüte. Es entstanden Paläste, Kirchen und Befestigungswerke nach mittel- und westeuropäischem Vorbild.

1557 wurde Zagreb erstmals als Kroatiens Hauptstadt erwähnt. Die Stadt lag im Hinterland der 1583 zur Abwehr der Türken eingerichteten Militärgrenze. 1669 wurde eine jesuitische Akademie (Neoacademia Zagrabiensis) als Vorläufer der dann 1874 gegründeten Universität Zagreb eingerichtet.

Später entwickelte sich im Süden der beiden Bergsiedlungen langsam die Unterstadt "(Donji grad)", zunächst um den im 17. Jahrhundert angelegten späteren Hauptplatz, den heutigen Ban-Jelačić-Platz.

Von 1756 bis 1776 übernahm Varaždin vorübergehend die Rolle als kroatische Hauptstadt.
1850 wurden die zwei Städte Gradec und Kaptol zur Stadt Zagreb vereint und mit der Unterstadt verbunden. Nun setzte in der Unterstadt ein schnelles Wachstum ein. Ein schweres Erdbeben richtete 1880 beträchtlichen Schaden an, ermöglichte jedoch auch eine Modernisierung und dynamische Weiterentwicklung der Stadt.

Kaptol ist bis heute das Zentrum der katholischen Kirche und des geistlichen Lebens in Kroatien. Gradec, heute Oberstadt genannt, wurde zum politischen und administrativen Zentrum. In der Unterstadt mit ihren vielen prächtigen Gebäuden aus dem späten 19. Jahrhundert pulsiert das wirtschaftliche, wissenschaftliche und kulturelle Leben.
Zagreb war zur Zeit des Königreichs Ungarn Sitz des Komitats Zágráb.

Am 29. Oktober 1918 beschloss das kroatische Parlament in Zagreb die Aufhebung sämtlicher staatsrechtlicher Beziehungen zwischen Kroatien und der Österreichisch-Ungarischen Monarchie. Am selben Tag wurde der Staat der Slowenen, Kroaten und Serben mit Zagreb als Hauptstadt gegründet. Zu Erinnerung daran wurde eine Gasse in der Nähe des St.-Markus-Platzes in Gornji Grad „Straße des 29. X. 1918“ genannt.

Am 1. Dezember vereinigte sich der neue Staat mit dem Königreich Serbien zum Königreich der Serben, Kroaten und Slowenen, das später in Königreich Jugoslawien umbenannt wurde. Staatsoberhaupt wurde der serbische König Peter I. Vier Tage später demonstrierten die Einwohner von Zagreb auf der Ilica-Straße gegen die Staatsregierung. Die königliche serbische Gendarmerie erschoss 20 Menschen, die als „Dezember-Opfer“ bekannt wurden.

Während des Königreichs Jugoslawien war Zagreb das ökonomische und kulturelle Zentrum und die zweitgrößte Stadt des Landes. In etwa zwanzig Jahren stieg die Bevölkerung durch die Immigration aus armen Dörfern um den Faktor 2,5 an. Am 15. Mai 1926 wurde die erste Übertragung von Radio Zagreb gesendet. Sie startete mit den Worten „Halo, halo! Ovdje Radio Zagreb!“ (dt. „Hallo, hallo! Hier Radio Zagreb!“).

Während des Zweiten Weltkrieges war Zagreb die Hauptstadt des Unabhängigen Staats Kroatien, eines Vasallenstaates der Achsenmächte.
Vor dem Weltkrieg lebten in Zagreb ca. 12.000 Juden. Nach dem Krieg waren es nur noch wenige tausend. Heute umfasst die Jüdische Gemeinde von Zagreb etwa 2000 Mitglieder, während es in ganz Kroatien 3000 Menschen jüdischen Glaubens gibt.

Am 8. Mai 1945 marschierten die Tito-Partisanen in Zagreb ein. Kroatien wurde daraufhin als Sozialistische Republik Kroatien in die "Föderative Volksrepublik Jugoslawien", die spätere Sozialistische Föderative Republik Jugoslawien, eingegliedert.

In den Jahren 1970 und 1971 war Zagreb der Mittelpunkt des Widerstandes gegen die kommunistische Regierung. Es fanden Demonstrationen gegen die Politik der Belgrader Zentralregierung statt, der Kroatische Frühling wurde niedergeschlagen und endete mit Massenverhaftungen.

Am 10. September 1976 kollidierten bei Zagreb ein jugoslawisches und ein britisches Flugzeug. Das Unglück forderte 176 Tote, davon 27 Deutsche.

1987 fand in Zagreb die Universiade statt. Die Stadt war Gastgeber des Eurovision Song Contest 1990 im Konzerthaus „Vatroslav Lisinski“ weil im Jahr davor die kroatische Band Riva aus Zadar mit dem Lied "Rock Me" gewann.

Am 25. Juni 1991 erklärte das kroatische Parlament die Unabhängigkeit Kroatiens und Zagreb zur Hauptstadt des Landes. Am 7. Oktober 1991 wurde Zagreb im Zuge des Kroatienkrieges von der Jugoslawischen Volksarmee angegriffen. Die Stadt war zum Zeitpunkt der Bombardierung überfüllt mit Flüchtlingen aus Ostslawonien und Vukovar. Am darauf folgenden Tag, am 8. Oktober 1991, setzte Kroatiens Regierung die nach einer Volksabstimmung erklärte Unabhängigkeit offiziell in Kraft.

Am 2. und 3. Mai 1995 schlugen Streubomben in der Innenstadt von Zagreb ein. Der Angriff kostete sieben Menschen das Leben, 214 weitere wurden verletzt ("siehe auch: Raketenbeschuss auf Zagreb").

1994 feierte man Zagrebs 900-jähriges Jubiläum. Papst Johannes Paul II. kam nach Zagreb und feierte eine Messe am 11. September auf der Zagreber Reitbahn mit mehr als einer Million Gläubigen.

Zagreb liegt 122 Meter über dem Meeresspiegel im kontinentalen Bereich Mittelkroatiens am Fuß des nördlich gelegenen Medvednica-Gebirges. Eine Besonderheit der Stadt ist ihre Lage am Schnittpunkt zwischen Mittel- und Südeuropa. Die kroatische Hauptstadt erstreckt sich an beiden Seiten der Save, dem größten Fluss Sloweniens und Kroatiens. Sie befindet sich im Südwesten der Pannonischen Tiefebene in einem Gebiet, das auch als Hrvatsko Prigorje bezeichnet wird. Die Entfernung zum Adriatischen Meer beträgt etwa 170 Kilometer.

Zagreb ist die Hauptstadt und der Regierungssitz der Republik Kroatien.
In Zagreb tagt auch das kroatische Parlament, der Sabor.
Bürgermeister von Zagreb ist Milan Bandić. Stärkste Fraktion im Stadtrat ist die Sozialdemokratische Partei Kroatiens. Das Regierungsviertel befindet sich in der "Gornji Grad" (Obere Stadt), der Altstadt von Zagreb.

Im Jahre 2004 wurde ungefähr 30 % des kroatischen Bruttosozialprodukts in Zagreb erwirtschaftet. Auch 2011 steuerte Zagreb ein Drittel zum Bruttosozialprodukt bei. Dies macht die Stadt zum wichtigsten Wirtschaftsstandort Kroatiens.

Wichtige Wirtschaftszweige in Zagreb sind die Pharmaindustrie, die Elektrotechnik, der Handel und der Tourismus.

Im südöstlichen Teil der Stadt liegt das größte Industriegebiet Žitnjak.

Die Kroatische Nationalbank und die einzige kroatische Börse haben ihren Sitz in Zagreb.

Viele Unternehmen wie z. B. der Öl- und Gaskonzern INA haben ihren Hauptsitz in Zagreb. Im Westen der Stadt sind an mehreren Standorten der Pharmakonzern Pliva, der Elektrotechnikkonzern Končar Group und Ericsson-Tesla angesiedelt.

Besucher aus den nahegelegenen EU-Nachbarländern entdecken Zagreb zunehmend als günstige Einkaufsstadt: Neben immer größer werdenden Einkaufszentren an der Peripherie im Osten und Westen der Stadt lädt in der Zagreber Innenstadt besonders die Hauptgeschäftsstraße Ilica mit ihren zahlreichen traditionsreichen Handwerkergeschäften wie zum Beispiel Schustern, Hutmachern, Ledertaschenläden, Küfnern, Boutiquen und Juwelieren zum Einkaufen ein.

Die Messe Zagreb ("Zagrebački Velesajam") ist der bedeutendste Messestandort der Region.

In Zagreb hat auch die Deutsch-Kroatische Industrie- und Handelskammer ihren Sitz.

Zagreb wird sowohl im Bereich Straße als auch im Bereich der Eisenbahn als Zwischenstation dem Paneuropäischen Verkehrskorridor X zugerechnet.

Zagreb ist ein wichtiger Knotenpunkt im Netz der Kroatischen Eisenbahnen. Südlich des Stadtzentrums befindet sich am "König-Tomislav-Platz" der für den Personenverkehr bedeutsame Hauptbahnhof "(Glavni kolodvor)". Internationale Direktverbindungen im Tagesverkehr werden unter anderem nach Ljubljana (2:30 Stunden), Budapest (6 Stunden), Belgrad (6 Stunden), Wien (6 Stunden) und München (Kurswagen, ca. 9 Stunden), sowie mit Nachtzug (EN) von und nach München angeboten. Andere Reiseziele erfordern gegenwärtig das Umsteigen in Villach.

Im innerkroatischen Verkehr wird Split in sechs Stunden erreicht. Im Schienenpersonennahverkehr werden neben dem Hauptbahnhof auch der westlich des Stadtzentrums gelegene Westbahnhof "(Zapadni kolodvor)" sowie die südlich der Save liegende Station "Zagreb Klara" bedient. Südlich der Save befindet sich zudem ein großer Rangierbahnhof.

Zagreb ist durch ein gut ausgebautes Autobahn-Netz unter anderem mit den Hafenstädten Rijeka und Split und der Region Dalmatien (A1) sowie mit der ostkroatischen Region Slawonien (A3) verbunden, darüber hinaus auch mit Slowenien (A2) und Ungarn (A4).

Zagreb besitzt einen internationalen Verkehrsflughafen, gelegen etwa 20 km südöstlich des Stadtzentrums auf dem Gebiet der Ortschaft Pleso. Der IATA-Flughafencode ist "ZAG".

Der ÖPNV der Stadt wird im Wesentlichen vom kommunalen Verkehrsunternehmen Zagrebački električni tramvaj (ZET) durchgeführt. ZET betreibt die Straßenbahn Zagreb sowie den örtlichen Stadtbusverkehr. Darüber hinaus existiert in Zagreb außerdem eine Standseilbahn. Früher verkehrte außerdem noch eine Gondelbahn auf den Sljeme.

Südöstlich des Stadtzentrums befindet sich der Busbahnhof "(Autobusni kolodvor Zagreb)" an der "Avenija Marina Držića". Von hier werden nahezu alle Landesteile Kroatiens sowie zahlreiche Städte Europas regelmäßig angefahren.

Höchste wissenschaftliche Einrichtung in Kroatien ist die Kroatische Akademie der Wissenschaften. Die Universität Zagreb wurde am 23. September 1669 gegründet und ist eine der ältesten Universitäten in Ostmitteleuropa. Die Gebäude der Fakultäten befinden sich in mehreren Stadtteilen; die zur Universität Zagreb gehörende Universitätsbibliothek Zagreb liegt seit 1995 in einem Stadtteil außerhalb des Zentrums. Die Kunstakademie Zagreb und die Musikakademie Zagreb genießen internationalen Ruf.

Weitere Hochschulen sind die Gesundheitshochschule in Zagreb, die Sozialwissenschaftliche Fachhochschule in Zagreb und die Technische Fachhochschule in Zagreb.

Das im Jahr 1950 gegründete Ruđer-Bošković-Institut ist das größte interdisziplinäre Institut Kroatiens und beschäftigte im Jahr 2005 insgesamt 200 Wissenschaftler.

Eine Auswahl der in Zagreb erscheinenden Zeitungen und Zeitschriften:


Im 19. und 20. Jahrhundert erschienen auch zwei deutschsprachige Tageszeitungen für Zagreb, das Agramer Tagblatt und die Agramer Zeitung.

Der Bezirk auf einem Bergsporn um die Kathedrale bildete sich mit der Gründung des Zagreber Bistums im 11. Jahrhundert. Hier residierte nicht nur der Bischof, sondern nach Norden erstreckten sich zu beiden Seiten der Hauptstraße die geräumigen Hofe der Domherren. Außerhalb im Süden und Norden siedelten sich Bedienstete und Handwerker an und bildeten mit der Zeit zwei Vorstädte. Die Kernanlage wurde im 15. Jahrhundert mit einer noch ablesbaren Mauer versehen.


Die westlich des Kathedralberges im 13. Jahrhundert auf älteren Siedlungsplätzen planmäßig angelegte Oberstadt zeichnet sich durch eine geschlossene historische Bebauung aus, die heute besonders durch die Architektur des Barock und des Historismus geprägt wird. Die im 13. Jahrhundert angelegte Stadtmauer mit ihren vier Toren ist in ihrem Verlauf noch gut ablesbar. Eindrucksvolle Adelspalais wechseln mit kleineren, eingeschossigen Anwesen der Bürger, Handwerker und Kaufleute ab.


Die Unterstadt entstand vor allem seit der Mitte des 19. Jahrhunderts, als sich die Besiedlung Zagrebs in die Ebene nach Süden ausdehnte. Das sehenswerte Areal zeichnet sich durch eine große Anzahl von qualitätvollen und gut erhaltenen Bauten des Historismus (etwa 1860 bis 1900) und des Jugendstils aus und besitzt auch einige bemerkenswerte Projekte der architektonischen Moderne.





In Zagreb hat das Filmstudio Zagreb Film seinen Sitz. Es produzierte seit 1953 mehr als 600 Animationsfilme, gewann über 400 internationale Preise (darunter einen Oscar) und begründete durch seinen einzigartigen Stil die "Zagreber Schule".

Die Stadtbezirke (kroat. "Gradski četvrti") in alphabetischer Reihenfolge, mit in Klammern angegebener Bevölkerungszahl aus dem Jahr 2011, sind:

Der Basketball-Rekordmeister KK Cibona kommt aus Zagreb. Neben Cibona Zagreb spielt auch KK Cedevita in der überregionalen ABA-Liga. KK Zagreb hingegen spielt in der 1. kroatischen Basketballliga. Es gibt auch einen Zagreber Damen-Basketball-Verein und einen Zagreber Veteranen-Basketball-Verein.

Der KHL Medveščak Zagreb ist der erfolgreichste Eishockeyverein Kroatiens. Von der Saison 2009/10 bis 2012/2013 nahm der Verein aufgrund der deutlichen Überlegenheit auf nationaler Ebene an der Österreichischen Eishockey-Liga teil. Seit der Saison 2013/2014 spielt der Verein in der russischen Kontinental Hockey League. Zudem gibt es in Zagreb mit dem KHL Grič den einzigen reinen Fraueneishockey-Verein in Kroatien.

Der mit Abstand bekannteste Fußballverein Zagrebs ist Dinamo Zagreb, welcher seine Heimspiele im Maksimir-Stadion austrägt. Der Verein ist Kroatiens Rekordmeister, Rekordpokalsieger, hat einige Meistertitel und Pokale im ehemaligen Jugoslawien errungen und gewann 1967 einen europäischen Pokal, den Messepokal. Daneben gibt es in Zagreb noch die Vereine NK Zagreb, NK Lokomotiva, NK Lucko und NK Hrvatski Dragovoljac, wie auch zahlreiche kleine lokale Clubs wie z. B. NK Hašk. Die 1 Liga heißt 1. HNL

Der Verein RK Zagreb ist kroatischer Rekordmeister im Handball. Daneben spielen noch RK Agram Medvešćak und RK Dubrava in der 1. kroatischen Handballliga.
Der RK Zagreb gewann in den Jahren 1992 und 1993 die EHF Champions League der Männer und erreichte 1995, 1997, 1998 und 1999 das Finale. Zudem wurde er 18 mal kroatischer Handballmeister und 15 mal Pokalsieger. Er ist in Kroatien ohne gleichwertige Konkurrenz. So wurde er auch von 1991 bis heute in jedem Jahr, außer 2001 und 2002, wo nur der Meistertitel errungen wurde, Meister und Pokalsieger.

Im Januar 2005 fand auf dem Zagreber Hausberg Medvednica unter der Bezeichnung Snow Queen Trophy das erste alpine Slalom-Rennen der Damen statt. Das erste Slalom-Rennen der Herren im alpinen Skiweltcup fand im Februar 2008 statt.

In Zagreb finden das Tennisturnier Zagreb Open und die internationale Ruderregatta Grand Prix Jarun statt.
Im August 2005 fand auf der Regattastrecke des Jarun-Sees die Weltmeisterschaft im Kanurennsport statt.

Der Verein HAOK Mladost Zagreb wurde 1949 gegründet. Sowohl die Herren- als auch die Damenmannschaft stellten vielfach den Landesmeister in Jugoslawien und in Kroatien. Die Mannschaften waren auch unter den drei Erstplatzierten der Indesit European Champions League.

HAVK Mladost Zagreb ist der erfolgreichste Wasserballklub aus der Hauptstadt Kroatiens. Mehrfacher kroatischer Meister und auch Europacupsieger der Landesmeister.

Zagreb unterhält Städtepartnerschaften mit folgenden Städten:






</doc>
<doc id="5788" url="https://de.wikipedia.org/wiki?curid=5788" title="Zahlennamen">
Zahlennamen

In diesem Artikel geht es um den Aufbau von Zahlennamen und die Benennung von Zahlen im Dezimalsystem (→Zahlwort).

Am Beispiel der Zahl "vierhundertsiebenundzwanzigtausendfünfhundertvierunddreißig" (427.534) kann man den abgestuften Aufbau der Zahlennamen ersehen. Auffällig ist dabei in der deutschen Sprache die systematische Umkehrung der Zehner- und der Einerstelle, die zum Beispiel im Englischen nur von 13 bis 19 vorkommt.

Die Werte der Dezimalziffern sind: Null, Eins, Zwei, Drei, Vier, Fünf, Sechs, Sieben, Acht, Neun. Der Name Null steht immer alleine; auf den anderen neun Zahlennamen baut das gesamte Namenssystem auf. Bis auf die Sieben sind all diese Zahlwörter einsilbig.

Aus dem urgermanischen Wort "*tehun," das unter anderem mit altgriechisch "deka" (δεκα) und lateinisch "decem" verwandt ist, hat sich über althochdeutsch "zehan" das heutige Wort "zehn" entwickelt.

Elf und zwölf von gotisch "ainlif" und "twalif" mit der Nachsilbe "-lif" (= „das Übrigbleibende“ oder „das Darüberhinausgehende“). Auch in allen anderen germanischen Sprachen, beispielsweise im Englischen (eleven, twelve) oder Niederländischen (elf, twaalf), gibt es diese Ausnahmen. Hier merkt man den früheren Ansatz für ein auf zwölf Zahlen basierendes Zahlensystem. Siehe auch Dutzend (= 12), Schock (fünf Dutzend = 60) und das Gros (zwölf Dutzend = 144).

Im Gegensatz zu den Zahlen über zwanzig, bei denen die Einerstelle und die Zehnerstelle mit einem „und“ verknüpft werden (siebenundzwanzig), entfällt dies bei den Zahlen von dreizehn bis neunzehn. Bei den Zahlen sechzehn und siebzehn wird die Einerstelle verkürzt ausgesprochen und geschrieben („sechzehn“ statt „sechszehn“ und „siebzehn“ statt „siebenzehn“).

Zwanzig: von gotisch "twai tigjus" (= „zwei Zehn-Einheiten“), später "twai tig." Diese Bildungsform setzt sich bis neunzig fort, wobei auch hier die Endsilben der Sechs und der Sieben teils verkürzt sind („sechzig“ statt „sechszig“ und „siebzig“ statt „siebenzig“). Eine Ausnahme bildet die Verwendung von „dreißig“ (statt „dreizig“).
Die Einereinheit wird zuerst genannt („fünfundzwanzig“). Dabei wird im Fall der Eins diese verkürzt („einundvierzig“).

In manchen Sprachen sind noch Reste eines Vigesimalsystems erhalten: Zum Beispiel ist im Französischen (in Frankreich und Kanada) diese Reihe nur bis 60 nach diesem Muster aufgebaut. Danach folgen „sechzig-und-zehn“ "(soixante-dix)," „vier-mal-zwanzig“ "(quatre-vingts)" und „vier-mal-zwanzig-und-zehn“ "(quatre-vingt-dix)." Allerdings gibt es im belgischen Französisch abweichend für 70 und 90 die Zahlwörter "septante" und "nonante" und im Schweizer Französisch zusätzlich "huitante" und "octante" für 80. Das Dänische kennt für die Zahlen von 50 bis 90 das Vigesimalsystem; so heißt beispielsweise 60 im Dänischen "tres(indstyve)," d. h. „drei-mal-zwanzig“, oder 50 heißt "halvtreds(indstyve)," d. h. „halb drei-mal-zwanzig“ (für „2,5 × 20“).

Im Gegensatz zur deutschen Sprache kommt in einigen anderen Sprachen, wie der russischen, ukrainischen, englischen, schwedischen oder französischen, die Zehnereinheit zuerst (z. B. im Englischen „twenty-five“). Weitere Sprachen, in denen Einer- und Zehnernamen wie im Deutschen gereiht werden, sind das Niederländische, das Dänische, das Luxemburgische, das Slowenische und das Arabische. Im Tschechischen sind beide Varianten möglich, d. h. „Zwanzig und eins“ oder „Einundzwanzig“; desgleichen im Norwegischen, wo die dem Deutschen oder Dänischen entsprechende Reihung offiziell per Gesetz durch die dem Englischen oder Schwedischen entsprechende abgelöst wurde, in der gesprochenen Sprache aber nach wie vor üblich ist.

Hundert: von gotisch "hunda" und lateinisch "centum." Ursprünglich nur als Mehrzahlwort verwendet, das heißt, erst ab zweihundert. Das erste Hundert wurde noch bis ins Mittelhochdeutsche durch das Zahlwort "zehen-zec/ic, zehent-, zên-zic" („zehnzig“) abgeschlossen. Heutzutage wird entweder die Hundert, oder die einfache Hundert, also Einhundert, verwendet. Um ein Mehrfaches von hundert auszudrücken, wird eine einstellige Zahl vor die "Hundert" gestellt. So ist der Zahlname für das Dreifache von hundert "dreihundert." Wenn das Mehrfache von hundert größer als 9 ist, wechselt man zum Tausender.

Für den speziellen Zahlenbereich von 1100 bis 1999, also eigentlich schon im nachfolgenden Tausenderbereich, gibt es jedoch im Deutschen – und ähnlich in diversen anderen Sprachen – die Bezeichnungen "Elfhundert, Zwölfhundert" bis "Neunzehnhundert," die vor allem bei Jahreszahlen und gelegentlich umgangssprachlich verwendet wird. Abweichend vom Deutschen wird dies im Englischen auch oft entsprechend bis zu Zahlenwerten von 9999 fortgesetzt.

Tausend: von gotisch "thusundi." Für Zahlen über Einhundert hat sich im indogermanischen Sprachraum keine einheitliche Bezeichnung entwickelt. Der Wortstamm „Tausend“ kommt nur im germanischen, slawischen und baltischen Sprachraum vor, während im romanischen die Bezeichnung von lateinisch "mille" hergeleitet ist und im griechischen von "χιλιοι."

Million: von lateinisch "mille" (= tausend) und "-one" (vergrößerndes Suffix); also eigentlich „Großtausend“. Die "Million" ist das Quadrat der "Tausend."

Die "Milliarde" ist die dritte Potenz zur "Tausend" oder auch tausend Millionen.

Ab einer Milliarde wiederholt sich das Schema -illion und -illiarde. Die Präfixe leiten sich aus dem Lateinischen ab: Bi- für 2 (Billion und Billiarde), Tri- für 3, Quadri- für 4, Quinti- (auch: Quinqui-) für 5 und so weiter. Sie geben also Potenzen der Million an: eine Billion" ist 1 000 000, eine Trillion" ist 1 000 000, eine "Quadrillion" ist 1 000 000 und so weiter. Eine "Billiarde" sind "tausend" Billionen. Das gleiche Schema lässt sich auf "Trilliarde, Quadrilliarde" und so weiter anwenden. Dieses System wird als Lange Skala bezeichnet. Es geht auf Nicolas Chuquet und Jaques Peletier du Mans zurück.

Seit dem 17. Jahrhundert gibt es zwei unterschiedliche Konventionen für Namen großer Zahlen oberhalb der Million, die auch noch identische Zahlennamen für völlig verschiedene Zahlen verwenden. Das führt in der Praxis oft zu Missverständnissen:

Das System der langen Skala sollte auf Vorschlag der 9. Konferenz des Bureau International des Poids et Mesures von 1948 weltweit einheitlich verwendet werden. Nachdem auch Frankreich 1961 per Gesetz vom bis dahin üblichen System der kurzen Skala gewechselt hatte, wurde das System der langen Skala für eine kurze Zeit in ganz Europa verwendet. Doch infolge des Einflusses der USA und der internationalen Medien wird immer stärker davon abgewichen. Praktisch alle englischsprachigen Länder einschließlich des Vereinigten Königreichs verwenden es nicht mehr; in Kanada wird es nur mehr im Französisch sprechenden Teil, in Südafrika nur von Afrikaans-Sprechern verwendet.

Das System der kurzen Skala wird in den USA offiziell verwendet, in den übrigen englischsprachigen Ländern ist es mittlerweile gängiger Sprachgebrauch. Verwendung findet es auch in Puerto Rico, Brasilien und in der Türkei, wobei aber im Sprachgebrauch der Türkei das Wort "milyar" für "Milliarde" (10) fest verankert ist. Das britische Englisch hat sich dem US-amerikanischen Sprachgebrauch angepasst. Im US-Englisch fehlen die Bezeichnungen auf die Endung "-arde" (Milliarde, Billiarde, ...); im britischen Englisch werden sie nur noch selten verwendet. Mehr zur Entstehung dieses Systems ist im Artikel Billion zu finden. Vielleicht auch wegen der möglichen Missverständnisse sind diese großen Zahlennamen jenseits der "billion" im täglichen Sprachgebrauch im englischen Sprachraum auch eher selten, meist greift man lieber zu Konstruktionen wie "a thousand million millions."

Zahlwörter mit einem Wert ab 1 000 000 werden nach dem System von Nicolas Chuquet nach lateinischen Präfixen benannt. Eine Ausnahme stellt dafür das Zahlwort "Million" dar. Dieses leitet sich vom lateinischen "mille" (1000) ab. Die Nicht-Kombinationspräfixe, also Präfixe, die nicht in Kombinationen mit anderen Präfixen auftauchen (abgesehen bei der Bildung der Präfixe mit einem Wert von über 999), leiten sich von lateinischen Ordinalzahlen ab. Die Kombinationspräfixe leiten sich von lateinischen Kardinalzahlen ab.

Kombinieren lassen sich die Präfixe nach dieser Reihenfolge: Einer+Zehner+Hunderter.

Steht vor einem Zehner- oder Hunderter-Präfix beispielsweise ein eingeklammertes M, bedeutet das, dass man dieses M bei der Kombination mit einem Einer-Präfix, bei welchem auch dieses eingeklammerte M dabei ist, zu dem Einer-Präfix anfügen soll (das eingeklammerte M im Zehner- oder Hunderter-Präfix entfällt). – Dies gilt auch für alle anderen eingeklammerten Buchstaben.

Beispiele:


Um aus diesen Präfixen ein Zahlwort zu bilden, muss man die Endung -llion anfügen. Die gebildete Zahl entspricht 10 (n steht dabei für den Wert des gebildeten Präfixes; z. B. treszenti- = 103). Hängt man zu dem Präfix die Endung -lliarde dran (nach Jaques Peletier du Mans), wird die Nullenanzahl um 3 Nullen größer, als die Nullenanzahl des Zahlwortes mit der Endung -llion.

Beispiel:


Falls man ein Zehner-Präfix nimmt, ohne diesen mit einem Hunderter-Präfix zu kombinieren, muss man die Endung -a (falls vorhanden) durch -i ersetzen.

Beispiel:


Die Bildung der Präfixe einer Zahl mit 6000 und mehr Nullen funktioniert so:

Um das Zahlwort mit dem Wert 10 zu bilden,


Das Zahlwort für 10 lautet folglich: Millinillion.

Dieses System geht auf John Horton Conway und Allan Wechsler zurück.


Nach dem System von Nicolas Chuquet kann man von (spät)lateinischen Zahlwörtern folgende Präfixe herleiten:

18 - duodeviginti
19 - undeviginti
28 - duodetriginta
29 - undetriginta
38 - duodequadraginta
39 - undequadraginta
48 - duodequinquaginta
49 - undequinquaginta
58 - duodesexaginta
59 - undesexaginta
68 - duodeseptuaginta
69 - undeseptuaginta
78 - duodeoctoginta
79 - undeoctoginta
88 - duodenonaginta
89 - undenonaginta
98 - duodecenti
99 - undecenti

Die folgenden Abkürzungen sind in der deutschen Sprache gültig:



Bruchzahlen werden mit den Ordinalzahlen und dem Suffix –el gebildet (drittel, viertel, fünftel usw.).

Die Begriffe "eintel" (anstatt "ganz") und "zweitel" (anstatt "halb") sind oft nur in mathematischen Ausdrücken gebräuchlich.

Bruchzahlen als Adjektive können auch substantiviert werden. Beispiel: "zwei Zweitel sind gleich ein Eintel."

Die Myriade steht für eine Anzahl von 10.000 (altgriech. μυριάς – myriás), dazu die Längeneinheit Myriameter = 10.000 m. Der Plural "Myriaden" bezeichnet hingegen eine unzählbare Menge (μύριοι – mýrioi: unzählige, unendlich viele).

Aufgrund nicht mehr fassbarer Zahlenwerte wurde im Englischen in Anlehnung an "Million, Billion" und wohl auch an Zahlennamen wie "decillion, undecillion, duodecillion" usw. das Wort „zillion“ geprägt, das umgangssprachlich für eine gewaltige, jedoch unbestimmte Anzahl steht und keine mathematische Gültigkeit hat.

Erstmals nachweisbar ist „Zillion“ 1944 beim Journalisten und Schriftsteller Damon Runyan (1880–1946), doch finden sich schon früher mit „Bazillion“ (1939, NY Times), „Jillion“ [ʤilljən] (1942) und „Squillion“ (1943) ähnlich gebildete Namen für fiktive Zahlen unermesslicher Größen. Seither hat sich die Zahl solcher im Allgemeinen scherzhaft oder als Jargon gebrauchter englischer Phantasienamen für große Zahlen stark vermehrt, wenn auch keiner dieser Namen so großen Anklang gefunden hat wie „Zillion“. Beispielsweise existieren jetzt (in alphabetischer Ordnung):

Im Deutschen finden sich diese Bezeichnungen jedoch wohl nur in Übersetzungen angelsächsischer Quellen. Die Donald-Duck-Übersetzerin Erika Fuchs allerdings hat Dagobert Ducks Vermögen von "607 Tillionen, 386 Zillionen" etc. bzw. von 5 "multiplujillion, 9 impossibidillion, 7 fantasticatrillion" bzw. von 5 "billion quintiplitillion unptuplatillion multuplatillion impossibidillion fantasticatrillion" Dollars umgerechnet und mit ihren Wortschöpfungen von "Fantastilliarden, Fantastillionen" und "Pimpillionen" wiedergegeben.

In ein originelles System gebracht wurden fiktive Zahlen unter Einschluss von "zoogol" und "gazoogol" (Neuschöpfungen in Anlehnung an das vom neunjährigen Mathematikerneffen Milton Sirotta 1938 geprägte „Googol“ – formula_1, also 1 mit 100 Nullen) vom franko-amerikanischen „Pataphysiker“ André Joyce in der Darstellung von Michael Joseph Halm.

Eine Anspielung auf die Zillionen ist das Album "How to Be a … Zillionaire!" von der Gruppe ABC.




</doc>
<doc id="5793" url="https://de.wikipedia.org/wiki?curid=5793" title="Zins">
Zins

Zins (‚ „Abschätzung“) ist in der Wirtschaft das Entgelt, das der Schuldner dem Gläubiger als Gegenleistung für vorübergehend überlassenes Kapital zahlt.

Das Wort Zins ist ein Lehnwort aus einer früheren Vermögens- oder Einkommensabgabe (, wörtlich „Abschätzung“, von , „schätzen“), woraus sich zur Zeit der Merowinger der Zensus als Synonym für Abgaben entwickelte. Der Zinsschuldner () hatte diese Abgabe entweder in Getreide („Korngült“), sonstigen Naturalien („Küchenzinsen“; Eier, Gänse, Hühner), als Erbzins (heute Erbpacht) oder in Geld zu bezahlen („Pfennigzins“). Hiermit erfasste man alle Natural- oder Geldabgaben besitz-, personen- oder hoheitsrechtlicher Art. Heute steht das Wort Zensus für eine Volkszählung.

Der Zins ist Erkenntnisobjekt insbesondere in der Volkswirtschaftslehre, Betriebswirtschaftslehre, Bankbetriebslehre, Rechtswissenschaft oder Sozialpsychologie. Die Volkswirtschaftslehre definiert ihn als Preis für die befristete Überlassung des Produktionsfaktors Kapital. Diese Kapitalüberlassung kann einerseits in Form des Kredits (Kreditzins, Sollzins) und andererseits als Geldanlage (Habenzins) geschehen. Die Zahlung des Zinses erfolgt beim Kredit durch den Kreditnehmer an den Kreditgeber, bei der Geldanlage durch den Schuldner/Emittent an den Anleger. Beim Kreditnehmer stellt diese Zahlung einen Zinsaufwand dar, beim Kreditgeber entsprechend einen Zinsertrag (umgekehrt beim Negativzins). Bei knappem Kapital- oder Geldangebot ist das Zinsniveau hoch, bei hohem Überschuss niedrig. Auf dem Kapitalmarkt heißt der Zins Kapitalmarktzins, auf dem Geldmarkt entsprechend Geldmarktzins. Der Leitzins der Zentralbanken beeinflusst vor allem den Geldmarktzins. 

Die Zinsen sind Entgelt für die dem Gläubiger entgangene eigene Nutzung und gelten deshalb als Opportunitätskosten.

Der Zins kann auf eine bewegte Wirtschaftsgeschichte zurückgreifen. Insbesondere Religionen verboten ihn zumindest temporär, erlaubten ihn wieder, schränkten ihn ein und befassten sich mit dem Wucherzins. Um 2400 vor Christus dürfte bei den Sumerern der älteste Zinsbegriff (maš; ) entstanden sein. Damit deutet dieser Zinsbegriff auf den Naturallohn hin. Auch der Zinseszins (mašmaš) hat hier seinen Ursprung. In Babylon kannte man den Marktzins als „şibat kârim“. Der Codex Hammurapi aus dem 18. Jahrhundert vor Christus erlaubte den Zins, bei Nichtzahlung drohte die Schuldknechtschaft. Zur Verhinderung von Auswüchsen führte Hammurapi I. einen Höchstzins ein, der für Gerste bei 33 1/3 % und für Silber bei 20 % lag. Bereits damals kam das Kreditrisiko in der Höhe des Zinssatzes zum Ausdruck, denn Gerstenkredite galten wegen des Ernterisikos als riskant. 

Das jüdische Bundesbuch verbot zwischen 1000 und 800 vor Christus den Zins bei Krediten an Arme (). Das Deuteronominum verlangt: „Du sollst von Deinen Volksgenossen keinen Zins nehmen, weder Zins für Geld, noch Zins für Speise, noch Zins für irgendetwas, was man leihen kann“ (). Unter „Volksgenossen“ verstand der Tanach nur die Juden. Daraus folgerte man, dass Juden Kredite an Nichtjuden verleihen durften. Platon war der Auffassung, dass die Zinseinnahme den Staat schädige. Dem pflichtete Aristoteles im Ergebnis bei. Wucherer veranlassten Solon 550 vor Christus in Griechenland, den Höchstzins auf 12 % zu beschränken, auch Indien regulierte 324 v. Chr. gesetzlich den Zins. Geldverleiher durften in Judäa 30 nach Christus Zinsen auf Depositen vergüten.

Für den Darlehenszins verwendeten die Römer nicht „census“, sondern oder . Es handelte sich zunächst um eine Gebühr für die Vermietung einer vertretbaren Sache (). Das römische Recht kannte mit dem Mutuum ein zinsloses Darlehen meist aus Gefälligkeit an Verwandte oder Freunde, bei dem Zinsen nur gesondert durch eine Stipulation erhoben werden konnten. Der Schuldner hieß dabei . Das Zwölftafelgesetz von 451 v. Chr. begrenzte den Zins auf ein Zwölftel der Darlehenssumme (), der deshalb 8,33 % nicht übersteigen durfte. Titus Manlius Imperiosus Torquatus halbierte 407 v. Chr. diesen Zinssatz (). In der Römischen Republik traten im Jahre 387 v. Chr. die „Gesetze des Licinius und des Sextius“ () in Kraft, wonach die bezahlten Zinsen auf das Kapital angerechnet und für den Rest Tilgungsfristen von 3 Jahren bestimmt wurden. Zum Ende der Römischen Republik um 27 v. Chr. lag der Höchstzins () bei 12 %, Justinian I. verminderte ihn 533 n. Chr. auf 6 %. Nur für Seedarlehen () sah er wegen des damit verbundenen Risikos unbeschränkte Zinsen vor. Zinseszinsen () unterlagen einem Verbot.

Mit Aufkommen des Christentums stieß die Zinszahlung auf heftige Kritik der Kirche, denn in Not geratene bedürftige Personen sollten zinslose Darlehen bekommen (, ). „Usura“ erhielt in der Kirchensprache die Konnotation für verbotenen Zins. Das kanonische Recht erklärte Zinseinnehmen für Raub (). Ein Verstoß gegen dieses kanonische Zinsverbot hatte die Exkommunikation, Ausweisung aus der Gemeinde, Verweigerung des kirchlichen Begräbnisses oder Versagung der Absolution zur Folge. Karl der Große erklärte in seiner „Allgemeinen Ermahnung“ () im März 789 das Zinsverbot zum weltlichen Verbot. Der Islam übernahm das christliche Zinsverbot und forderte nach 622 n. Chr. dazu auf, nicht Zins (; „Zuwachs, Vermehrung“) zu nehmen, indem die Gläubiger in mehrfachen Beträgen wiedernehmen, was sie ausgeliehen haben (Koran, 3:130). Nach Sure 2:279 hat der Kreditnehmer dem Kreditgeber nur das Kapital zurückzuerstatten. Beim islamischen Zinsverbot ist es bis heute in der Scharia geblieben.

Der Patriarch Photios I. hielt vor 863 das christliche Zinsverbot für falsch und ließ Verzugszinsen ausdrücklich zu, der byzantinisch-orthodoxe Rechtsgelehrte Theodoros Balsamon ließ die Zinsen (, „Junges“) nach 1193 als „Interesse“ gelten, heute noch im Englischen und Französischen für Zins gebräuchlich (, ) und auch zeitweise im Deutschen. Das bisherige kanonische Zinsverbot wurde durch Papst Innozenz III. im Jahre 1215 erneuert und verschärft. Thomas von Aquin hielt um 1268 Zinseinnehmen „von irgendeinem Menschen schlechthin [für, d. Verf.] böse“. Das kanonische Zinsverbot erlaubte stattdessen den Rentenkauf, den erstmals 1270 das Hamburger Stadtrecht als durch Wiederkauf ablösbar anerkannte. Bereits 1532 erkannte das Reichskammergericht an, das der Kreditnehmer neben einem Darlehen auch das „aufgelauffen Interesse zu bezahlen schuldig“ sei. 

In England verbot Heinrich VII. 1512 den Zins () und erklärte alle bisherigen zinstragenden Geschäfte für nichtig. Heinrich VIII. erließ 1545 ein Gesetz, wonach der Zins () als legaler Ausgleich () für die Geldnutzung () galt, während der Wucher () illegal sei. Es bestätigte den seit 1198 bestehenden Höchstzins von 10 %. Das lateinische Wort "Interesse" () betraf im Mittelalter einen zu ersetzenden Schaden, danach auch einen entgangenen Gewinn. Heinrich VIII. sorgte mit seinem Gesetz aus 1545 für die heute noch im englischsprachigen Raum gebräuchliche Unterscheidung zwischen dem regulären Zins () und dem Wucher ().

Juden brauchten die christlichen Regeln des Zinsverbots nicht zu befolgen und entwickelten sich deshalb im Hochmittelalter zu Geldverleihern. Ihnen erlaubte die Thora Zinsgeschäfte () mit Angehörigen anderer Religionen (Nichtjuden). Die Reichspolizeiordnung von 1577 begrenzte den Höchstzinssatz für den Geldverleih der Juden auf 5 %. Erste mathematische Zinsberechnungen ermöglichte 1614 John Napier mit der Erfindung des Logarithmus, 1617 beschrieb er das exponentielle Wachstum von Schulden durch Zinsen.

Eine Lockerung des Zinsverbots trat inzwischen durch die Reichsabschiede von 1500, 1548 und 1577 ein, die nach ihrem Wortlaut einen Zins von 5 % für den Rentenkauf erlaubten, was die Allgemeinheit jedoch auch auf Darlehen bezog. Heinrich VIII. legalisierte 1545 die Zinszahlung in England nach seinem Bruch mit dem Papst. Im Jahre 1638 plädierte der Universalgelehrte Claudius Salmasius für die Zulässigkeit des Zinses. In Frankreich legte Maximilien de Béthune, duc de Sully 1601 den Höchstzins auf 6 ¼ % fest. Das Reichskammergericht erkannte den Darlehenszins erstmals nach dem Jüngsten Reichsabschied von 1654 als einklagbar an. Im Westfälischen Frieden von 1648 wurden mit 5 % verzinste Darlehen für zulässig erklärt. Im Anschluss daran hielt die deutsche Rechtswissenschaft das Zinsverbot für gewohnheitsrechtlich abgeschafft. John Locke veröffentlichte 1692 die bereits 1668 von ihm verfassten „Betrachtungen über die Senkung des Zinssatzes und die Erhöhung des Geldwertes“, worin er die Auffassung vertrat, dass zu niedrige Zinsen die Geldgeber zum Horten veranlassten und zu hohe Zinsen die Gewinne der Kaufleute schmälerten und einen Rückgang der Geldnachfrage bewirken würden.

Nach faktischer Aufhebung des Zinsverbots gab es den erlaubten Zins () und den Wucher () als einen über dem gesetzlichen Höchstzins liegenden Zins. Das in Deutschland eingeführte Wort Zins stammte aus der Klosterverwaltung. Ein deutsches Rechtslexikon definierte 1738 „Zins ist was vor den Gebrauch einer Summe Geldes oder andern Sache in gleichen entrichtet wird“. In Italien bezeichnete Ferdinando Galiani 1750 den Zins humorvoll als „die Frucht des Geldes“, als „Preis für das Herzklopfen“ (des Gläubigers). Cesare Beccaria unterschied 1769 scharf zwischen Interesse und Zins, das erstere ist der unmittelbare Nutzen einer Sache, der Zins dagegen der „Nutzen des Nutzens“ (). Zinsen wurden in vergangenen Jahrhunderten an bestimmten Tagen im Jahr fällig (so genannte Zinstage) und mussten am Zahltag bezahlt werden.

In Österreich erließ am 29. Januar 1787 Joseph II. ein Patent, wonach die Höchstzinssätze entfielen. Doch bereits am 2. Dezember 1803 führte Franz II. eine erneute Zinsobergrenze von 5 % bzw. 6 % ein. Das Allgemeine Preußische Landrecht (APL) vom Juni 1794 entschied sich für mehrere Höchstzinssätze: „Bey Darlehen können, der Regel nach, nur Fünf vom Hundert jährliche Zinsen vorbedungen werden“ und „Kaufleuten ist erlaubt, Sechs, und Juden Acht vom Hundert, an Zinsen sich verschreiben zu lassen“ (I 11, §§ 804 f. APL). Im Jahre 1848 entfiel diese Begrenzung. Das im Juni 1811 in Kraft getretene ABGB sah einen Höchstzinssatz von 6 % vor (§ 994 ABGB), der jedoch durch das Zinsgesetz vom Juni 1868 entfiel. Der französische Code civil (CC) entschied sich im März 1804 für die Zinsfreiheit (Art. 1907 CC), doch legte ein Gesetz vom 3. September 1807 eine Zinsobergrenze von 5 % (zivile Rechtsgeschäfte) und 6 % (Handelsgeschäfte) fest, was bis 1918 galt. Die katholische Kirche hob das kanonische Zinsverbot offiziell erst 1822 auf. Im Jahre 1858 gab es noch einen weiten Begriffsinhalt, denn unter Zins verstand man damals auch jede „Abgabe, welche auf einem Bauerngute als Reallast ruht, …“.

In Deutschland gab es seit Januar 1937 eine staatliche Zinsreglementierung, die mit Hilfe der „Zinsverordnung“ den Kreditinstituten im „Sollzinsabkommen“ Höchstzinssätze vorschrieb, die im Kreditgeschäft nicht überschritten und im „Habenzinsabkommen“ beim Einlagengeschäft maximal vergütet, aber auch unterschritten werden durften. Sollzinsen und Habenzinsen blieben dadurch stabil, Anpassungsbedarf bestand nicht. Diese Zinsverordnung endete im April 1967. Nach Freigabe der Zinsen im April 1967 konnten sich Soll- und Habenzinsen frei der Marktentwicklung anpassen, wodurch jedoch für die Marktteilnehmer Marktrisiken und insbesondere Zinsänderungsrisiken entstanden. 

Im Jahre 1992 sah das pakistanische Bundes-Schariagericht in allen Formen des Zinsennehmens einen Verstoß gegen die Scharia. Im Rahmen des islamischen Finanzwesens entwickelten sich seither Rechtsinstitute, die zinsähnliche Einnahmen (wie und ) zum Inhalt haben.

Seit Januar 2012 verbreiten sich in der Eurozone Negativzinsen, zunächst in Form einer negativen Rendite, dann aber auch durch einen negativen Nominalzins, so dass Gläubiger bei ihrer Geldanlage einen Zinsaufwand zahlen müssen.

Für eine Geldanlage werden Zinsen oder ähnliche Vergütungen bezahlt. Der Geldmarktzins ist der Zinssatz für kurzfristige Kreditaufnahme auf dem Geldmarkt, besonders im Verkehr von Kreditinstituten untereinander (Interbankenhandel) oder zwischen Kreditinstituten und Zentralbank, wo er speziell Leitzins genannt wird. Kapitalmarktzins ist der Zinssatz für langfristige Kredite auf dem Kapitalmarkt.

Miete oder Mietzins ist das Entgelt für die Überlassung von Immobilien wie Wohnungen, Geschäftsräume, Häuser, Ferienhäuser, Garagen usw. Der Begriff Miete wird aber auch als Bezahlung für die zeitlich begrenzte Überlassung beweglicher Gegenstände wie Autos, Werkzeug, Bagger, Mietwagen, verwendet.

Pacht oder Pachtzins ist der Zins für die Überlassung von Grundstücken und Immobilien, die der Pächter nicht nur nutzen, sondern auch bewirtschaften und die Früchte ziehen kann.

Erbbaurechtszins ist die regelmäßige Abgabe für im Erbbaurecht überlassene Grundstücke, in der Schweiz entsprechend „Baurechtszins“ genannt.

Falls eine Schuld verzinslich ist, aber ein Zinssatz nicht ausdrücklich vereinbart oder gesetzlich vorgeschrieben ist, gilt nach BGB ein gesetzlicher Zinssatz von 4 % p. a.

Der Verzugszinssatz ist in BGB gesetzlich festgelegt und liegt für Rechtsgeschäfte, an denen ein Verbraucher beteiligt ist, 5 Prozentpunkte p. a. über dem Basiszinssatz, für Immobiliendarlehen an Verbraucher nach 
nur 2,5 Prozentpunkte p. a. über dem Basiszinssatz. Wenn kein Verbraucher beteiligt ist, liegt der Verzugszinssatz mit 9 Prozentpunkten p.a über dem Basiszinssatz deutlich höher. Für Prozesszinsen gilt nach BGB der gleiche Zinssatz wie für Verzugszinsen.

Der Zinssatz für Steuerzinsen beträgt nach AO 0,5 % pro Monat (6 % p. a.).

Die Zentralbanken steuern über verschiedene Finanzinstrumente die Geldpolitik ihres Währungsraumes mit so genannten Leitzinsen. Volkswirtschaftliche Ziele, die durch Beeinflussung des Zinsniveaus erreicht werden sollen, sind z. B. Preisniveaustabilität (Hauptziel der EZB) oder auch Wirtschaftswachstum.

Zentralbankzinssätze sind unter anderem:

Es gibt vor allem im internationalen Kreditverkehr folgende Marktzinsen:


Einige Ökonomen haben über Entstehung, Verlauf, Entwicklung oder Auswirkungen des Zinses Theorien aufgestellt, von denen die wichtigsten erwähnt werden. Einen guten Überblick hierüber verschaffte 1967 der Wirtschaftswissenschaftler Friedrich A. Lutz. Da der Zins als Preis gilt, hat er mit diesem die Preisfunktionen gemeinsam. Spezifische Funktionen des Zinses sind darüber hinaus:

Der theoretischen Erklärung des Zinses widmen sich Zinstheorien:

Im Verständnis klassischer und neoklassischer Wirtschaftswissenschaftler erfüllt der Zins (und allgemeiner das Kapitaleinkommen) eine wichtige Funktion als Allokationsmechanismus, also einen Mechanismus, der Messungen erlaubt und daher Entscheidungshilfe bietet: Eine Kühlschrankfabrik am Nordpol vermöchte womöglich tatsächlich kostendeckend zu arbeiten, dennoch wäre die niedrigere Rendite ein Indiz und Anreiz dafür, dass eine andere Investition sinnvoller wäre – für die Allgemeinheit ebenso wie für die Investoren.

Die Rendite­niveaus in unterschiedlichen Branchen (beispielsweise Flugzeuge, Autos, Informationstechnologie) sind ein Indikator für die Knappheit im volkswirtschaftlichen Sinn. Ein allgemeines Verbot von Zinsen würde also erschweren, diese Knappheit zu finden und zu beseitigen. Des Weiteren besagen die Erfahrungen aus dem islamischen Bankwesen, dass Nullzinsgebote schlichtweg umgangen werden – Kapital kann aufgrund der Liquiditätspräferenz eine Rendite fordern, und ohne Investition keine wirtschaftliche Entwicklung. Dies führt zu der Vermutung, dass selbst die Schwächsten einer Gesellschaft in einer Wirtschaft ohne Nullzinsgebot schlussendlich wirtschaftlich besser gestellt sind als in einer Wirtschaft, die das Nehmen von Zinsen bzw. Kapitaleinkommen effektiv verbietet und verfolgt.

Ein hypothetischer Investor, der aus rein altruistischen Motiven handelte, müsste das Renditeniveau zuhilfenehmen, um herauszufinden, wo er am nachhaltigsten die Versorgung der Gesellschaft mit Gütern – und somit die langfristige Reduzierung der wirtschaftlichen Knappheit – unterstützt. Die Vorstellung, dass pur egoistisches und rein altruistisches Handeln sich bei besserem Wissen um die Umstände immer ähnlicher sehen, beziehungsweise der Investor, der angelockt von hohen Kapitaleinkommen die Knappheit der Allgemeinheit da beseitigt, wo sie am allergrößten ist, und so unfreiwillig altruistisch handelt, ist ein zentrales Element von Adam Smiths Unsichtbarer Hand und der klassischen liberalen Ethik.

Der österreichische Ökonom Eugen von Böhm-Bawerk (1851–1914) untersuchte als einer der ersten das Zinsphänomen systematisch. Bei der Untersuchung der Frage, weswegen man überhaupt Zinsen verlangt, stellte er fest, dass das Einkommen im Lauf des Lebens ansteigt und man daher für heute verliehenes Geld in Zukunft auch mehr zurück erwartet, da man sonst nicht bereit wäre, durch das Verleihen von Geld sparsamer sein zu müssen.

Zweitens beobachtete Böhm-Bawerk, dass Menschen ihre zukünftigen Bedürfnisse meist unterschätzen und Geld lieber sofort ausgeben („Gegenwartspräferenz“). Um sie dennoch zum Verleihen zu bewegen, müsse man ihnen als Ausgleich Zinsen anbieten.

Der dritte Grund für das Verlangen von Zinsen ist nach Böhm-Bawerk darin zu sehen, dass Arbeit bei der Herstellung von Maschinen sehr nützlich eingesetzt wird, indem sie gewissermaßen in einen "Produktionsumweg" geleitet werden kann. Wenn Arbeiter eine Maschine produzieren, kann hinterher mehr damit hergestellt werden, als die Arbeiter vorher leisten konnten. Es entsteht eine „zusätzliche Ergiebigkeit“, ein Produktivitätszuwachs, und ein Gläubiger kann vom Schuldner erwarten, ihn „angemessen“ daran zu beteiligen. Zinsen lassen sich danach aus der zusätzlichen Ergiebigkeit der auf einen Produktionsumweg geleiteten Arbeit erklären. Um die Arbeiter im Voraus zu entlohnen, benötigt der Unternehmer Kapital, wofür er Zinsen zahlen muss und aus der zusätzlichen Ergiebigkeit der Arbeit auch zahlen kann. Böhm-Bawerk wollte so mit einer eigenen Erklärung des Zinses ein bedeutendes Argument des Marxismus entkräften, wonach der Zins Teil des Mehrwerts ist, der wiederum durch Ausbeutung der Arbeiter durch die Kapitalisten gewonnen wird.

Der Zins ist – nach Böhm-Bawerk – nicht der Preis des Geldes, sondern der Preis für die Zeit und belohnt den Verleiher für eine hypothetische Verschiebung seines Konsums.

Der österreichische Nationalökonom Ludwig von Mises erklärte den Zins aus den subjektiven Wertungen der Menschen. Sie ziehen die Behebung eines unmittelbaren Unbefriedigtseins (etwa Hunger) der Behebung eines künftigen Unbefriedigtseins vor, daher wird eine bestimmte Menge heutiger Güter einer gleich großen Menge künftiger gleichartiger Güter vorgezogen. Da man demnach eine Menge heutiger Güter mit einer größeren Menge künftiger Güter wertmäßig gleichsetzen kann, ergibt sich ein Mengenunterschied zwischen diesen Gütern, der Zins.

Nach der "Liquiditätspräferenztheorie" von John Maynard Keynes beruht Zins auf der besonderen Begehrtheit des Geldes. Nach ihm ist Zins die "Belohnung für die Aufgabe von Liquidität" über einen bestimmten Zeitraum oder – was das Gleiche ist – für die "Nichthortung von Geld".

Der Vorteil des Geldbesitzes wird von Keynes "Liquiditätsprämie des Geldes" genannt. Sie besteht darin, dass man mit Geld überall und jederzeit problemlos zahlen kann, nicht aber mit anderen Dingen, beispielsweise mit einem Schuldschein aus einem Kreditvertrag. Außerdem hat ein Geldbesitzer Wahlfreiheit im Angebot von Waren und Dienstleistungen, die er für sein Geld erwerben kann.

Naturgemäß haben alle Wirtschaftsteilnehmer eine Vorliebe für den Besitz von Geld, eine "Liquiditätspräferenz" („liquidity-preference“), wie J. M. Keynes sich ausdrückt. Sie wollen zahlungsfähig sein und unter dem Marktangebot frei wählen können. Die Liquiditätspräferenz hängt nach Keynes ab von vier Beweggründen („Motiven“) zum Halten von Geld:


Einkommensmotiv und Geschäftsmotiv zusammen nennt Keynes auch "Umsatzmotiv" („transactions-motive“).

Wer Geld weggibt, gibt – nach Keynes – die Verfügung über Geld als Universalzahlungsmittel auf. Der Vorteil des Geldbesitzes, die "Liquiditätsprämie des Geldes", wird beim Kreditgeschäft vom Kreditgeber an den Kreditnehmer verliehen. Für den dabei entgangenen Vorteil lässt sich der Kreditgeber einen Zins bezahlen, welcher die Höhe der Liquiditätsprämie verkörpert. Dieser Zins ist der Preis dafür, dass er über das verliehene Geld während der Laufzeit des Kredits nicht verfügen kann. Umgekehrt ist der Kreditnehmer bereit, für den erworbenen Vorteil des Geldbesitzes diesen Zins zu bezahlen.

Die Tatsache, dass Geld beim Behalten praktisch keine Nachteile (Durchhaltekosten) verursacht, macht es Kreditanbietern risikolos, ihr Geld vom Angebot zurückzuhalten, zu horten, solange ihnen der Zins für Kredite nicht hoch genug erscheint oder sie sein Steigen erwarten. Damit wird dem Wirtschaftskreislauf Geld in spekulativer Absicht entzogen und in der "Spekulationskasse" gehalten. Es verschwindet in der so genannten Liquiditätsfalle („liquidity trap“), wie Keynes sagt. Diese Zurückhaltung verhindert, dass der entsprechende Zinssatz gegen null sinkt. Keynes bemängelte, dass dadurch die Wirtschaft massiv gestört werden kann. Als Gegenmaßnahme schlug er eine ständige maßvolle Geldentwertung (Inflation) vor, welche gehortetes Geld entwertet und somit Geldhortung kostspielig macht.

Der Wirtschaftshistoriker Richard Sylla wies 1991 einen U-förmigen Verlauf der Zinskurven in der Antike nach. Demnach gab es zu Beginn einer Kultur wegen der großen Risiken noch hohe Zinsen, das Zinsniveau sank bei Stabilisierung einer Gesellschaft und stieg beim Verfall einer Kultur. Im römischen Imperium lagen die Zinsen bei 4 %, als es bis zum 2. Jahrhundert den Höhepunkt seiner Macht erreichte. Nach dem Verfall Roms (476 n. Chr.) erreichten die Zinsen dort ihren Höhepunkt.


Es gibt eine Vielzahl von Komposita, die den Zins als Wortbestandteil enthalten. Das Wort Zins steht zum einen für den Zinssatz, angegeben in Prozent pro Zeitintervall, üblicherweise pro Jahr. Zum anderen steht das Wort Zins für den "Zinsbetrag", also den konkreten Geldbetrag, der sich aus der Höhe des verzinsten Kapitals und dem vereinbarten Zinssatz ergibt. Zinseszins ist die Mitverzinsung desjenigen Zinses, der auf das Kapital aufgeschlagen wird. Mathematisch wird in diesem Zusammenhang zwischen der einfachen oder linearen Verzinsung und der exponentiellen Verzinsung (Zinseszins) unterschieden.

Nominalzins ist der für einen Kredit vereinbarte oder bezahlte Zinssatz, Realzins der Zinssatz nach Abzug der Inflations­rate. Der Realzins kann auch bei positivem Nominalzins negativ sein, wenn die Inflationsrate höher ist als der Nominalzins (siehe auch Reale Größe). Effektivzins ist der Zinssatz, der sich aus der Einbeziehung des Nominalzinses und weiterer preisbestimmender Faktoren – beispielsweise Gebühren – ergibt. Als "Zinsstruktur" bezeichnet man die Abhängigkeit des Zinssatzes von der Dauer einer Geldanlage. 

Der Zinssatz ist der wesentliche Teil einer Zinsrechnung, bei der zwischen verschiedenen Zinsberechnungsmethoden zu wählen ist; die Zinsstruktur reflektiert verschiedene Zinssätze. Ein Referenzzinssatz ist eine Bezugs- und Orientierungsgröße. Der Verzugszinssatz ist beim Zahlungsverzug vom Schuldner an den Gläubiger zu entrichten. Das Zinsniveau des Marktzinses entscheidet darüber, ob eine Hoch- oder Niedrigzinsphase besteht.

Ein Zwischenzins kann sich ergeben, wenn ein Schuldner eine Verbindlichkeit vor dem Tag der Fälligkeit begleicht.

Seit den Anfängen des Münzwesens gibt es Kritik am Zins und Vorbehalte gegenüber Geldverleihern. Aristoteles betrachtete den Zins als widernatürlich.

Der walisische Philosoph und Ökonom Richard Price veranschaulichte im 18. Jahrhundert anhand des Gedankenexperiments des Josephspfennigs die Kritik an der durch Zinseszinseffekte exponentiell anwachsenden Geldmenge, ließ dabei aber bestimmte Rahmenbedingungen und Auswirkungen unberücksichtigt.
Der Kaufmann, Finanztheoretiker und Sozialreformer Silvio Gesell stellte die Freiwirtschafts­theorie auf. Danach sollte der Zins möglichst minimiert werden. Diese Freigeldtheorie kam nur in einzelnen lokalen Experimenten zur Anwendung (das bekannteste 1932/33 im österreichischen Wörgl), hat aber heute noch Anhänger und findet seit der Finanzkrise ab 2007 wieder Beachtung in den Medien.

Im antisemitischen Klischee des raffgierigen jüdischen Geldverleihers verbinden sich Zinskritik und Rassismus. In den Jahren nach dem Ersten Weltkrieg ist hier der Nationalsozialist Gottfried Feder besonders hervorgetreten, der das Schlagwort „Brechung der Zinsknechtschaft“ prägte. Gemeint war „Zinsknechtschaft des jüdischen Weltwucherkapitals“.

Moderne deutschsprachige Vertreter der Zinskritik argumentieren meist ökonomisch oder sozial wie Dieter Suhr, Helge Peukert, Bernd Senf, Helmut Creutz und Franz Hörmann. Nach Ansicht der Zinskritiker vergrößern Zinsen stetig die Schere zwischen Arm und Reich. Zudem entstünden zwangsmäßig periodische Wirtschafts- und Schuldenkrisen, aus denen Kriege folgen könnten. Weitere Kritikpunkte sind Zeit- und Lohndiebstahl, Wachstumszwang, das (annähernd) exponentielle Anwachsen der Staatsschulden, die Ungleichbehandlung durch fehlende Einheitszinsen, das Weiterreichen von versteckten Zinsen, die in allen Produkten enthalten sind, an die Endverbraucher, was zur allgemeinen Verteuerung führt. Teilweise wird das gegenwärtige Zinswesen mit einem Ponzi-Schema verglichen.

Das BGB bietet keine Legaldefinition des Begriffs „Zins“ an, sondern der Begriff wird vielmehr in den einzelnen einschlägigen Vorschriften bereits als bekannt vorausgesetzt. Das BGB kennt einen "gesetzlichen Zins", den Basiszinssatz als Bezugswert, den Verzugszinssatz und den Zinseszins. Nach der Rechtsprechung des Reichsgerichts (RG), der zunächst auch der Bundesgerichtshof (BGH) gefolgt ist, war unter „Zins“ die fortlaufend zu entrichtende Vergütung für den Gebrauch eines in Geld oder anderen vertretbaren Sachen bestehenden Kapitals zu verstehen, die nach Bruchteilen des Kapitals berechnet wird und im Voraus dem Betrag nach bestimmt ist. Der BGH hat diese Definition später in zwei entscheidenden Punkten modifiziert.

Es ist nicht mehr erforderlich, dass die Zinsschuld in zeitlich nacheinander folgenden Teilbeträgen entrichtet wird. Vielmehr kann die betreffende Summe auch auf einmal geleistet werden; es ist sogar möglich, den Gesamtbetrag von vornherein von der auszuzahlenden Kreditsumme einzubehalten. Schließlich genügt es, wenn der geschuldete Zins zum Zeitpunkt seiner Entstehung der Höhe nach lediglich bestimmbar ist. Damit ist es bei Gelddarlehen möglich, die Zinshöhe an einen beweglichen Marktfaktor – zum Beispiel an einen Referenzzinssatz wie EURIBOR oder LIBOR – zu binden. Somit wird heute der Zins allgemein als laufzeitabhängige, jedoch gewinn- und umsatzunabhängige, in Geld zu entrichtende Vergütung für die Möglichkeit des Kapitalgebrauchs definiert, die in einem Bruchteil des Kapitals ausgedrückt wird.

Nach herrschender Meinung sind Zinsen die laufzeitabhängige, gewinn- und umsatzunabhängige, in Geld oder anderen vertretbaren Sachen zu entrichtende Vergütung für den Gebrauch eines auf Zeit überlassenen Kapitals. Die Zinshöhe darf auch von dem Ausgang eines ungewissen Ereignisses abhängig gemacht werden. Ansonsten ist die vertraglich vereinbarte Zinshöhe gesetzlich nicht begrenzt, weil die freie Zinsvereinbarung als Teil der Vertragsfreiheit gilt. Gesetzliche Schranken der Zinshöhe sind Sittenwidrigkeit und Zinswucher. Nicht einmal die Gleichartigkeit von Zins und Hauptschuld ist erforderlich. Wesentliches Merkmal bleibt die akzessorische Natur des Zinses zu einer Hauptforderung, die meist als Kapitalschuld besteht. Ohne deren Bestand können Zinsen nicht selbständig entstehen. Das Darlehen muss zudem ausgezahlt worden sein. Der Zins ist im Verhältnis zum Kapital in der Regel eine Nebenschuld, die sich regelmäßig erneuert. Sind Zinsen entstanden, werden sie vom Hauptanspruch unabhängig und können selbständig eingeklagt, abgetreten, verpfändet oder gepfändet werden. Wenn der Hauptanspruch erlischt, endet die Zinspflicht sogleich.

Ob eine Leistung Zins ist oder nicht, hängt nicht von ihrer Bezeichnung ab („Gebühr, Provision, Spesen“), sondern richtet sich nach ihrem wahren wirtschaftlichen Zweck. Keine Zinsen sind daher Vergütungen für besondere Leistungen bei der Kapitalbeschaffung und -auszahlung wie etwa sogenannte Bereitstellungszinsen sowie Bearbeitungs- und Verwaltungsentgelte. Die Rechtsprechung hat es stets abgelehnt, anders geartete Leistungen als Zinsen zu akzeptieren, wie Gewinn- oder Umsatzbeteiligungen, die unabhängig von der Höhe der Kapitalleistung und ihrer Bedeutung für den Kapitalnehmer allein auf dem Erfolg beruhen, den der Kapitalnehmer erzielt. Zu den Zinsen gehören Überziehungszinsen und eine einmalige Gebühr beim Teilzahlungskredit. Ein zur Senkung des Nominalzinses führendes Disagio (Damnum) gehört zu den Zinsen, da es sich in der Bankenpraxis zu einem Rechenfaktor für die Zinsbemessung entwickelt hat. Auch der Bundesfinanzhof stellt beim Disagio auf den Zinsbegriff des bürgerlichen Rechts ab. Bei Wucherfragen steht der "Effektivzins" im Vordergrund, der auch alle Kosten und Nebenleistungen beinhaltet, auch Kreditvermittlungskosten.

Zinsänderungs- oder Zinsgleitklauseln stellen Preisanpassungsklauseln dar, die den Kreditinstituten gestatten, den bei Vertragsabschluss festgelegten Preis nachträglich zu ändern. Es handelt sich um eigenständige Preisnebenabreden, die die Änderung eines vereinbarten Zinssatzes bewirken sollen. Die Kreditinstitute verfolgen hiermit das rechtlich anerkannte Ziel, Zinsänderungen auf den Kapital- und Geldmärkten an ihre Kunden weiterzugeben, ohne dass es einer Vertragsänderung bedarf. Diese Klauseln waren bereits mehrfach Gegenstand der höchstrichterlichen Rechtsprechung des BGH. Derartige Zinsänderungsklauseln kommen sowohl in Kreditverträgen als auch bei der Geldanlage vor. Für eine nach BGB und Abs. 1 Satz 5 Nr. 5 BGB genügende Zinsanpassungsklausel im Kreditgeschäft bedarf es der Angabe der notwendigen Berechnungsparameter. Dabei sind als Referenzzinssätze der Basiszinssatz nach BGB, EURIBOR, LIBOR oder EONIA geeignet. Wenn sich eine Bank in einem formularmäßigen Kreditvertrag einseitig eine Zinsänderung vorbehält, so ist eine derartige Klausel grundsätzlich dahin auszulegen, dass sie lediglich eine Anpassung (Erhöhung oder Senkung) des Vertragszinses an kapitalmarktbedingte Änderungen der Refinanzierungskonditionen der Bank gemäß BGB ermöglicht. Eine solche Klausel hält der gerichtlichen Inhaltskontrolle stand.

Nach Nr. 4 BGB ist die Vereinbarung eines Zinssatzänderungsrechts der Kreditinstitute unwirksam, sofern nicht die Vereinbarung der Änderung oder Abweichung unter Berücksichtigung der Interessen der Banken für den Kunden zumutbar ist. Deshalb sind derartige unzumutbare Klauseln in Sparverträgen nichtig. Die Zumutbarkeit einer Zinsanpassungsklausel sei dann zu bejahen, wenn die Interessen der Banken die für das jeweilige Geschäft typischen Interessen des Kunden überwiegen oder ihnen zumindest gleichwertig sind. Das setze eine Fassung der Klausel voraus, die nicht zur Rechtfertigung unzumutbarer Änderungen dienen kann, und erfordere im Allgemeinen auch, dass für den Kunden zumindest ein gewisses Maß an Kalkulierbarkeit der möglichen Zinsänderungen besteht.

Das „anerkennenswerte Interesse“ der Banken und Sparkassen, die Zinsen in Zeiten des wechselhaften Kapitalmarktes anzupassen, änderten hieran nichts. Ihnen sei zuzumuten, unter den Bezugsgrößen des Kapitalmarktes diejenigen oder eine Kombination von ihnen auszuwählen und sie für den Kunden erkennbar und ausdrücklich zum Maßstab für künftige Zinsänderungen zu machen.

Dabei erkennt die Rechtsprechung an, dass insbesondere der Zinssatz den wechselnden und bei Vertragsabschluss meist nicht überschaubaren künftigen Refinanzierungsmöglichkeiten angepasst werden muss. Der BGH hat Bankkredite mit inhaltlich unbeschränkten Zinsänderungsklauseln bisher einschränkend dahin ausgelegt, dass sie den kreditgebenden Kreditinstituten Änderungen des Zinssatzes nur nach Maßgabe der kapitalmarktbedingten Veränderungen ihrer Refinanzierungskonditionen gestatten. Ein berechtigtes Interesse der Kreditinstitute, ihre Zinssätze den veränderlichen Gegebenheiten des Kapitalmarktes nicht nur bei Neuabschlüssen, sondern auch bei bestehenden Verträgen anzupassen, ist vom Bundesgerichtshof für das Aktivgeschäft mehrfach anerkannt worden. Ein solches Interesse ist auch für das Passivgeschäft grundsätzlich anzuerkennen, muss jedoch den vom BGH hierzu entwickelten Leitlinien entsprechen und insbesondere eine angemessene Bezugsgröße aufweisen.

Bonitätsorientierte Zinsänderungsklauseln knüpfen die Höhe des vom Kreditnehmer zu zahlenden Zinssatzes an das sich aus dem aktuellen Rating ergebende Ausfallrisiko des Kreditnehmers. Dieser allein kann seine eigene Bonität und damit diese Art der Zinsänderung beeinflussen. Auslöser einer Zinsänderung sind somit nicht veränderte Marktzinsen, sondern alleine die etwaigen Ratingveränderungen des Kreditnehmers. Um diese zu berücksichtigen, wird in aller Regel im Kreditvertrag eine Vereinbarung getroffen, wonach sich die vorher festgelegten Kreditmargen je nach eintretenden Ratingveränderungen ebenfalls verändern sollen (so genannte „margin grids“ oder „margin ratchets“; siehe Covenants). Dadurch soll erreicht werden, dass die Kreditmargen mit der Erhöhung des Ausfallrisikos (also mit Ratingverschlechterung) automatisch ansteigen sollen und umgekehrt, ohne dass es hierzu neuer vertraglicher Vereinbarungen bedarf.

Diese Abwälzung des Bonitätsänderungsrisikos auf den Kreditnehmer ist anerkannt, wie auch die Ansprüche auf Nachbesicherung zeigen. Die Nachbesicherung ist ebenfalls an Bonitätsverschlechterungen geknüpft, wie sie durch eine wesentliche Verschlechterung der Vermögensverhältnisse eintreten kann. Diese Art der Zinsänderungsklauseln ist von der Rechtsprechung ebenfalls anerkannt. Der mit der Veränderung eines individuellen Ausfallrisikos verbundene Wechsel in eine andere Ratingklasse („Ratingmigration“) stellt einen sachlichen Grund für eine Zinsänderung dar.



</doc>
<doc id="5795" url="https://de.wikipedia.org/wiki?curid=5795" title="Zwischenablage">
Zwischenablage

Die Zwischenablage (engl. "Clipboard") oder "Ablagemappe" ist ein Zwischenspeicherbereich, der den einfachen Austausch von Daten (Text, Bilder und andere Objekte) zwischen Programmen in einem zweistufigen Vorgang ermöglicht.

Sie dient als "Zwischenspeicher" für Copy & Paste beziehungsweise Cut & Paste; Markierte Daten werden durch die Funktionen „Kopieren“ oder „Ausschneiden“ (engl. "Copy" bzw. "Cut") vom Ursprungsort in die Zwischenablage kopiert. Durch die Funktion „Einfügen“ (engl. "Paste") gelangen die Daten aus der Zwischenablage in ein Dokument eines anderen Programms.

Die Zwischenablage wurde erstmals im Betriebssystem der Apple Lisa systemweit realisiert. Zuvor musste jedes Anwendungsprogramm eine solche Funktion selbst realisieren, wenn sie notwendig war. Dies erfolgte aber nur in wenigen Programmen. Heutzutage findet sich das Konzept einer Zwischenablage in nahezu allen Betriebssystemen und gilt als selbstverständlich.

Technisch kann die Zwischenablage auch anstelle eines Speicherbereichs durch Interprozesskommunikation realisiert werden.

Es gibt auch Programme, die den Funktionsumfang der Zwischenablage erweitern, indem sie beispielsweise eine Historie der letzten Inhalte zur Verfügung stellen oder es erlauben, zwischen mehreren Zwischenablagen umzuschalten, so dass der Inhalt nicht jedes Mal überschrieben wird. Diese Funktion ist beispielsweise im Texteditor Emacs vorhanden.

Für die meisten Programmiersprachen gibt es Bibliotheken, die eine einfache Zugriffsmöglichkeit auf die Zwischenablage bereitstellen.

Unter Windows konnte bis Windows XP der Inhalt der Zwischenablage über den Systemdienst "Ablagemappe" mit dem Programm codice_1 eingesehen und verwaltet werden, wobei codice_2 für das Windows-Installationsverzeichnis steht (üblicherweise "C:\WINDOWS" oder "C:\WINNT"). Außerdem gibt es Erweiterungs-Software für die Zwischenablage (siehe unten).

Im Unix-Desktop KDE ist das Programm Klipper für die Verwaltung der Zwischenablage zuständig. Auf der Linux-Konsole bietet GPM (General Purpose Mouse Manager) eine ähnliche Funktion, allerdings nur für Text. Das Einfügen erfolgt auf der Linuxkonsole mit der Rolltaste der Maus bzw. der mittleren Maustaste.

Unter AmigaOS werden alle Zwischenablagen in codice_3 abgelegt.

Daten, die in die Zwischenablage kopiert wurden, existieren dort meist in mehreren Formaten. Ein Text kann z. B. als reine Zeichenfolge (plain text) und im Rich-Text-Format in der Zwischenablage vorliegen. Die "Quellanwendung" speichert alle ihr bekannten Datenformate in der Zwischenablage.

Beim Einfügen wählt zumeist die "Zielanwendung" das Datenformat aus, das im aktuellen Kontext am besten passt. Textverarbeitungsprogramme bieten aber dem Anwender häufig die Möglichkeit, selbst das Datenformat auszuwählen.

Nicht nur Zeichenketten, sondern auch ganze Dateien können in die Zwischenablage gesetzt werden, um später an einem anderen Ort wieder eingefügt beziehungsweise kopiert zu werden.

Wie erwähnt, kann die Zwischenablage gleichermaßen zum Kopieren und zum Verschieben von Material verwendet werden.


</doc>
<doc id="5796" url="https://de.wikipedia.org/wiki?curid=5796" title="Zugspitze">
Zugspitze

Die Zugspitze ist mit der höchste Gipfel des Wettersteingebirges und gleichzeitig Deutschlands höchster Berg. Das Zugspitzmassiv liegt südwestlich von Garmisch-Partenkirchen in Bayern und im Norden Tirols. Über ihren Westgipfel verläuft die Grenze zwischen Deutschland und Österreich. Südlich des Berges schließt sich das Zugspitzplatt an, eine Karst-Hochfläche mit zahlreichen Höhlen. An den Flanken der Zugspitze befinden sich drei Gletscher: der Nördliche Schneeferner mit 27,9 ha und der Höllentalferner mit 24,7 ha; außerdem der kleinere Südliche Schneeferner mit 4,8 ha.

Die erste namentlich nachgewiesene Besteigung der Zugspitze geschah am 27. August 1820 durch den Vermessungsingenieur und damaligen Leutnant des bayerischen Heeres Josef Naus, seinen Messgehilfen Maier und den Bergführer Johann Georg Tauschl.

Anlässlich der Heirat mit Elisabeth von Österreich-Ungarn („Sisi“), schenkte Kaiser Franz Joseph I. von Österreich im Jahr 1854 den östlichen Teil des Zugspitzgipfels seinem Vetter Ludwig (damals war er noch nicht König und erst 9 Jahre alt).

Heute gibt es drei Normalwege auf den Gipfel: Von Nordosten aus dem Höllental, von Südosten aus dem Reintal und von Westen über das "Österreichische Schneekar". Mit dem Jubiläumsgrat, der Zugspitze, Hochblassen und Alpspitze verbindet, führt eine der bekanntesten Gratrouten der Ostalpen auf die Zugspitze. Für Bergsteiger gibt es in der unmittelbaren Umgebung zahlreiche Unterkünfte. Direkt an der Zugspitze befinden sich das Münchner Haus auf dem Westgipfel und die Wiener-Neustädter-Hütte in der Westflanke.

Die erste Seilbahn, die Tiroler Zugspitzbahn, wurde 1926 von der Leipziger Firma Adolf Bleichert & Co. nach dem Bleichert-Zuegg-System gebaut und endete auf einem Grat, der "Kammstation", unterhalb des Gipfels auf Höhe, bevor die Endstation 1991 auf die Gipfelstation auf Höhe verlegt wurde. Eine Zahnradbahn, die Bayerische Zugspitzbahn, führt seit 1930 durch das Innere der Nordflanke und endet auf dem Zugspitzplatt, von wo eine weitere Seilbahn zur Gipfelregion hinaufführt. Als dritte Seilbahn nahm 1963 die Eibsee-Seilbahn den Betrieb auf, die 2017 durch die leistungsfähigere "Seilbahn Zugspitze" ersetzt wurde. Mit der Bayerischen Zugspitzbahn und der Eibsee-Seilbahn gelangen jährlich durchschnittlich 500.000 Menschen auf den Gipfel. Im Winter bedienen mehrere Skilifte ein Skigebiet auf dem Zugspitzplatt. In der 1900 eingeweihten meteorologischen Station und der Forschungsstation Schneefernerhaus werden hauptsächlich Klimaforschungen betrieben.

Ab dem frühen 14. Jahrhundert begann die Aufnahme von Namen aus dem Wettersteingebirge in Verträge und Karten, die sich im 15. Jahrhundert intensivierte. 1536 wurde ein Grenz-Vertrag aus dem Jahr 1500 präzisiert, in dem der Verlauf über eine "„Schartten“" festgelegt wurde. Im 17. Jahrhundert bekam die Scharte im Vertrag die Ergänzung "„jetzt Zugspüz genant“". Die erwähnte Scharte bezieht sich auf einen Geländeeinschnitt am Gipfel der Zugspitze und wird in weiteren Quellen immer wieder verwendet. Im Mittelalter war „Scharte“ der verbreitete Name für die Zugspitze.

Die Zugspitze wurde erstmals 1590 namentlich erwähnt. In einer Beschreibung der Grenze zwischen der Grafschaft Werdenfels und Österreich heißt es, dass selbige "„von dem Zugspitz und über den Derle“" und weiter zu einer Loisach-Brücke verläuft. Ein weiterer Grenzvertrag besagte 1656: "„Der höchste Wetterstain oder Zugspitz“". Aus der zweiten Hälfte des 18. Jahrhunderts stammt eine Karte, die "das Reintal in der Grafschaft Werdenfels" zeigt. Sie stellt das Reintal vom Reintaler Hof bis zum Zugspitzplatt dar und enthält markante Punkte in der Umgebung, Details zur Weidenutzung und Wegverläufe, darunter auch den Weg über den damals wesentlich größeren Schneeferner in die Gipfelregionen der Zugspitze. Ein eindeutiger Weg zum Gipfel ist auf der Karte nicht zu erkennen.

Der Name der Zugspitze leitet sich vermutlich von den „Zugbahnen“ der Lawinen ab, die hier im Winter von den oberen Bereichen des Massivs ins Tal abgehen und charakteristische Lawinenüberreste mit Steinen und Geröll hinterlassen. Beim Eibsee gibt es mehrere Flurstücke mit dem gleichen Namensbezug: "Zug", "Zuggasse", "Zugstick", "Zugmösel" oder "Zugwankel". Bis ins 19. Jahrhundert war als Name "der" Zugspitz gebräuchlich. In einer Karte aus dem Jahr 1836 wurde daraus "die" Zugspitze.

Die Zugspitze ist mit einer Höhe von 2962 Metern (Ostgipfel) der höchste Berg des Zugspitzmassivs. Dieser Wert nach dem Amsterdamer Pegel wird als offizielle Höhe vom Landesamt für Digitalisierung, Breitband und Vermessung genannt. Nach dem in Österreich verwendeten 27 cm tiefer liegenden Triester Pegel wird dieselbe Höhe angegeben. Ursprünglich hatte die Zugspitze drei Gipfel: Ost-, Mittel- und Westgipfel. Als einziger davon ist der vollständig in Deutschland liegende Ostgipfel in seiner ursprünglichen Form erhalten geblieben. Der Mittelgipfel fiel 1930 einer Seilbahn-Gipfelstation zum Opfer. 1938 wurde der Westgipfel gesprengt, um Bauplatz für eine geplante Flugleitstelle der Wehrmacht zu gewinnen. Diese wurde jedoch nie gebaut. Ursprünglich hatte die Höhe des Westgipfels 2964 m betragen.

Die Zugspitze erhebt sich elf Kilometer südwestlich von Garmisch-Partenkirchen und knapp sechs Kilometer östlich von Ehrwald. Über den Westgipfel verläuft die Grenze zwischen Deutschland und Österreich. Damit gehört das Zugspitzmassiv zum deutschen Bundesland Bayern und zum österreichischen Tirol. Die verwaltenden Gemeinden sind auf bayerischer Seite Grainau und Garmisch-Partenkirchen, auf der Tiroler Seite Ehrwald. Nach Westen fällt das Zugspitzmassiv in das Tal der Loisach ab, die das Massiv nach Nordosten in einem Bogen umfließt, während im Osten die Flüsse Hammersbach und Partnach entspringen. Südlich trennt das "Gaistal" mit der Leutascher Ache das Wettersteingebirge von der Mieminger Kette. Im Norden befindet sich der Eibsee zu Füßen der Zugspitze. Der nächsthöhere Berg in der Umgebung ist der Zwölferkogel () in den Stubaier Alpen, so dass für die Zugspitze der Dominanz-Wert 25,8 km beträgt. Als Referenzpunkt für die Schartenhöhe dient die Parseierspitze (). Um sie von der Zugspitze zu besteigen, muss bis zum Fernpass () abgestiegen werden, so dass sich eine Schartenhöhe von 1746 m ergibt.

Das Massiv der Zugspitze umfasst weitere Gipfel. Nach Süden wird das Zugspitzplatt in einem Bogen vom Zugspitzeck () und Schneefernerkopf (), den Wetterspitzen (), dem Wetterwandeck (), den Plattspitzen () sowie den Gatterlköpfen () umrahmt. Das Massiv endet mit dem Gatterl (), einer Scharte zum Hochwanner hin. Von der Zugspitze nach Osten verläuft der "Jubiläumsgrat" in Richtung Alpspitze und Hochblassen über die Höllentalspitzen. In nordöstlicher Richtung zieht der kurze "Riffelwandkamm" über die Riffelwandspitzen () und die Riffelköpfe (), zur Riffelscharte (). Von hier verläuft der "Waxensteinkamm" über die Riffelspitzen bis hin zum Waxenstein.

Das "Platt" (auch Zugspitzplatt) ist eine Hochfläche unterhalb des Zugspitzgipfels in südlicher und südöstlicher Richtung auf einer Höhe zwischen 2000 und 2650 m. Es bildet den Abschluss des Reintals und ist durch Verwitterung, Verkarstung und glaziale Überprägung entstanden. Die Fläche enthält Rundhöcker, Dolinen, Karren oder Schratten als Folge der Eiszeiten. Außerdem sind von verschiedenen Kaltzeiten Moränen zurückgeblieben. Zu Beginn des 19. Jahrhunderts war das "Platt" zum letzten Mal vollständig vergletschert. Heute besteht es zu 52 % aus Schutt, zu 32 % aus anstehendem Gestein und zu 16 %, vor allem im mittleren und unteren Bereich, aus Böden mit Vegetation.

Die Zugspitze gehört in der naturräumlichen Haupteinheitengruppe Nördliche Kalk-Ostalpen (Nr. 93; Teil der Nördlichen Kalkalpen), in der Haupteinheit Inntaler Riffkalkketten (933) und in der Untereinheit Wettersteingebirge (933.0) zum Naturraum "Wettersteinketten" (933.04).

Angrenzende Naturräume im Uhrzeigersinn sind: Die Landschaft fällt nach Nordosten in den vom Hammersbach durchflossenen Naturraum Höllental (933.01) ab und nach Osten in den von der Partnach durchflossenen Naturraum Reintal (933.02). Nach Süden leitet sie zu den Wetterspitzen über, um von dort in den zum Naturraum Leutasch (930.32) zählenden Teil "Obere Leutasch" (930.320) abzufallen. Nach Südwesten bis Westen fällt sie direkt in den Naturraum Ehrwalder Becken ("Lermooser Becken"; 930.22) ab, der in der Haupteinheit Becken und Talboden zwischen den Hauptgruppen der Nördlichen Kalk-Ostalpen (930) zur Untereinheit Fernpaß-Loisachtaler Becken und Talböden (930.2) gehört. Nach Nordwesten fällt die Landschaft in den am Hohen Egg und an den Pollerköpfen liegenden Naturraum "Nordwestlicher Wettersteinsockel" ("Törlenplatte"; 933.00) ab. Nach Norden fällt sie zur beim Eibsee gelegenen "Eibseeplatte" (930.250) ab und nach Nordosten unter anderem über den Waxenstein zum "Südliches Werdenfelser Mittelgebirge" (930.251), die beide Teile des Naturraums "Werdenfelser Mittelgebirge" (930.25) sind.

Klimatisch gesehen liegt die Zugspitze in der gemäßigten Klimazone und im Bereich der Westwindzone. Als erstes hohes orografisches Hindernis dieser Westwinde in den Alpen ist die Zugspitze Wetterereignissen besonders ausgesetzt. Es kommt zum „Nordstau der Alpen“, der die feuchten Luftmassen staut und für intensive Niederschläge sorgt. Andererseits hat die Zugspitze damit gleichzeitig eine abschirmende Funktion für südlicher gelegene Alpenteile. Dem Nordstau entgegengesetzt wirkt die Föhn-Wetterlage, die an 60 Tagen pro Jahr in der Region auftritt. Dabei strömen trockene und warme Luftmassen von Süd nach Nord. Sie können im Winter für außergewöhnlich hohe Temperaturen sorgen. Allerdings herrscht auf der Zugspitze trotzdem durchschnittlich an 310 Tagen Frost. Vergleichbare Werte sind erst wieder auf Spitzbergen im Arktischen Ozean anzutreffen.

Für die Normalperiode zwischen 1961 und 1990 betrug der jährliche Durchschnittsniederschlag auf der Zugspitze 2003,1 mm, niederschlagsreichster Monat war dabei der April mit 199 mm, niederschlagsärmster der Oktober mit 108,8 mm. Im Vergleich betrug der Wert für das Jahr 2009 2070,8 mm, hier war der niederschlagreichste Monat der März mit 326,2 mm und niederschlagärmster der Januar mit 56,4 mm. Die durchschnittliche Temperatur in dieser Normalperiode betrug −4,8 Grad Celsius, wobei der Juli sowie der August mit 2,2 °C am wärmsten und der Februar mit −11,4 °C am kältesten waren. Verglichen damit betrug die Durchschnittstemperatur im Jahr 2009 −4,2 °C, am wärmsten war der August mit 5,3 °C und am kältesten der Februar mit −13,5 °C. Durchschnittlich schien die Sonne in der Normalperiode an 1846,3 Stunden im Jahr, am sonnenreichsten war der Oktober mit 188,8 Stunden und am sonnenärmsten der Dezember mit 116,1 h. Im Jahr 2009 gab es an 1836,3 h Sonnenschein, den wenigsten im Februar mit 95,4 h und den meisten im April mit 219 h. 2009 war gemäß der Wetterbilanz des Deutschen Wetterdienstes die Zugspitze mit −4,2 °C im Jahresmittel der kälteste Ort Deutschlands.

Die tiefste gemessene Temperatur auf der Zugspitze betrug am 14. Februar 1940 −35,6 °C. Der 5. Juli 1957 brachte die höchste; ihr Wert betrug 17,9 °C. Eine Sturmbö vom 12. Juni 1985 erreichte mit 335 km/h die höchste auf der Zugspitze gemessene Windgeschwindigkeit. Die höchste gemessene Schneehöhe war mit 7,80 m am 26. April 1980.

Alle gebirgsbildenden Schichten bestehen aus Sedimenten des Mesozoikums, die sich ursprünglich auf dem Meeresboden abgelagert haben. Der Sockel des Berges besteht aus Muschelkalk-Schichten, der obere Bereich wird von Wettersteinkalk gebildet. Mit bis zu 800 m hohen Steilwänden bildet vorwiegend Wettersteinkalk aus der oberen Trias die Wände, Grate, Türme und das Gipfelgestein des Gebirges. Aufgrund des häufigen Vorkommens von marinen Kalkalgen im Wettersteinkalk ist davon auszugehen, dass dieses Gestein einst in einer Lagune entstand. Die Farbe des Gesteins variiert zwischen grauweiß und hellgrau bis gefleckt. An mehreren Stellen sind Blei und Zinkerze enthalten. Diese Bodenschätze wurden zwischen 1827 und 1918 im Höllental durch Bergbau gewonnen. Die dunkelgrauen, fast waagerechten und zum Teil mit Gras bewachsenen Schichten des Muschelkalks ziehen sich vom Fuß der Großen Riffelwandspitze bis zu den Ehrwalder Köpfen hin. Bei einem Blick auf die Zugspitznordwand ist zu erkennen, dass das Bergmassiv aus ursprünglich zwei Gebirgen bestand, die übereinander geschoben wurden.

Im Zugspitzmassiv befinden sich drei der fünf deutschen Gletscher, neben dem Höllentalferner der Südliche und der Nördliche Schneeferner.

Der Höllentalferner liegt nordöstlich der Zugspitze in einem Kar unterhalb des Jubiläumsgrates im Süden und den Riffelwandspitzen im Westen und Norden. Er ist nach Nordosten exponiert. Das Nährgebiet wird von einer Mulde gebildet, in der sich große Lawinen-Schneemengen sammeln. Nach Süden hin schottet der Jubiläumsgrat den Gletscher vor Sonneneinstrahlung gut ab. Diese Umstände führten dazu, dass der Gletscher zwischen 1981 und 2006 nur einen relativ geringen Flächenverlust hatte. Seinen neuzeitlichen Höchststand hatte der Höllentalferner um 1820 mit einer Größe von 47 ha. Danach verlor er kontinuierlich an Fläche, bis er sich zwischen 1950 und 1981 wieder um 3,1 ha auf 30,2 ha vergrößerte. Seitdem verlor der Gletscher bis 2006 eine Fläche von 5,5 ha und war nur noch 24,7 ha groß. Sein höchster Punkt befand sich 2006 auf 2569 und sein niedrigster auf 2203 m.

Südwestlich der Zugspitze befindet sich zwischen "Zugspitzeck" und Schneefernerkopf der nach Osten exponierte Nördliche Schneeferner. Er ist mit einer Fläche von 27,9 ha (2013) der größte deutsche Gletscher, der jedoch Ende des 19. Jahrhunderts noch 103 ha umfasste. Um das Jahr 1820 war das komplette Zugspitzplatt vergletschert, von diesem "Plattgletscher" sind nur noch der Nördliche und der Südliche Schneeferner übrig geblieben. Grund für die relativ konstante Flächenentwicklung des nördlichen Schneeferners in den letzten Jahren ist trotz fehlenden Schattens die günstige Geländebeschaffenheit. Sie führt dazu, dass der Gletscher eher an Mächtigkeit als an Fläche verliert oder gewinnt. In der jüngeren Vergangenheit wurde der Gletscher darüber hinaus von den Skigebietsbetreibern künstlich genährt, indem große Schneemengen mit Pistenraupen auf den Gletscher geschoben wurden, um die Skisaison zu verlängern. 1993 wurde zudem begonnen, den Nördlichen Schneeferner im Sommer mit Kunststoffplanen abzudecken, um ihn vor der Sonneneinstrahlung zu schützen. Dieses Unterfangen wurde von der Bayerischen Zugspitzbahn 2013 jedoch wieder aufgegeben. Seinen letzten Hochstand hatte der Nördliche Schneeferner im Jahr 1979, als er 40,9 ha maß. Bis zum Jahr 2006 verringerte sich seine Fläche auf 30,7 ha. Der höchste Punkt lag dabei auf 2789 und der niedrigste auf 2558 m. Bis 2013 schrumpfte er weiter auf 27,9 ha.

Der Südliche Schneeferner wird umrahmt von den Wetterspitzen und dem Wetterwandeck. Auch er ist ein Rest des großen "Plattgletschers". Der südliche Schneeferner reicht bis hinauf zum Grat und hat deshalb keinen Schutz vor der Sonneneinstrahlung. Inzwischen ist er durch einen freigetauten Felsriegel in zwei Becken geteilt. Es ist umstritten, ob der Südliche Schneeferner noch als Gletscher einzustufen ist. Auch der Südliche Schneeferner hatte 1979 seinen letzten Hochstand, als er eine Fläche von 31,7 ha umfasste. Diese ging jedoch bis 2009 auf 4,8 ha zurück. Der höchste Punkt des Gletschers befand sich auf 2665 und der niedrigste auf 2557 m.

Die Gletscherschmelze ist ein weltweites Problem. Auch die Zugspitze ist davon nicht ausgenommen. Es gibt einen alten Versorgungsstollen an der Zugspitze. Vor 30 Jahren war der Stollen komplett vereist. Ein Forscherteam der Universität Bonn stellte allerdings fest, dass von den meterdicken Eisschichten nicht mehr viel vorhanden ist. Messungen mit Hilfe von Schallwellen und elektrischer Leitfähigkeit ließen Wissenschaftler auf dasselbe Ergebnis kommen: im Fels der Zugspitze ist nur noch wenig Permafrost vorhanden.

Das Gestein solch mächtiger Berge wird durch das Eis in den Spalten und Klüften zusammengehalten. Schmilzt dieses können Teile davon abbrechen. Es wird vermutet, dass vor 3.700 Jahren aus diesem Grund ein Bergsturz an der Zugspitze stattgefunden hat.

Im August 2007 wurde deshalb ein Frühwarnsystem erstellt. Am Gipfel der Zugspitze wurde in Nordsüdrichtung ein 60 Meter langer Tunnel mit 12 Zentimetern Durchmesser erstellt. Dieser soll regelmäßig darüber Aufschluss geben, wie viel Eis im Gipfelbereich vorhanden ist.

Unterhalb des Zugspitzplatts haben chemische Verwitterungsvorgänge im Wettersteinkalk eine Vielzahl an Höhlen und Schächten geschaffen. In den 1930er Jahren wurde die Anzahl der Höhlen auf 300 geschätzt; erste Forschungen darin gab es 1931. Bis 1955 waren 62 Höhlen bekannt, bis 1960 wurden 47 weitere entdeckt. Größere Erkundungen fanden 1935, 1936 sowie zwischen 1955 und 1968 statt. Während einer Expedition im Jahr 1958 wurde der Finkenschacht entdeckt, die bis dahin tiefste Höhle der Zugspitze. Er ist 131 m tief, 260 m lang und trifft auf einen Wasserlauf.

Die Flora ist aufgrund der Bodenverhältnisse nicht besonders vielgestaltig, doch zeigt sich die Pflanzenwelt vor allem am Schachen, an der Tieferen Wies bei Ehrwald, im Höllen-, Gais- und Leutaschtal besonders farbenfroh.

Der schattige und feuchte Norden des Massivs, wie zum Beispiel der Wettersteinwald, gehört zu den artenreichsten Gebieten der Zugspitze. Die Latschenkiefer reicht bis in Höhen von über 1800 m. Die Wäldern darunter bestehen vorwiegend aus Fichten und Tannen, aber auch Heckenkirsche, Waldmeister, Einbeere, Wiesenraute und Ehrenpreis kommen hier vor. An weniger stark bewachsenen Plätzen blühen Schwarze Akelei, Alpenrebe, Blauer- und Gelber Eisenhut, Wetterdistel, Alpenmaßliebchen, Gold-Fingerkraut, Rundblättriger Steinbrech, Mauerhabichtskraut, Bergminze und Alpen-Vergissmeinnicht. Auf den felsigen Böden des Bergwaldes gedeihen Fingerkraut, klebriger Salbei, Pestwurzen, Alpenrose, Türkenbund, Knabenkraut, Fliegen-Ragwurz; vor allem im Höllental, in Grainau und am Eibsee das Maiglöckchen und der Seidelbast.

Nach Süden hin wandelt sich das Bild in Lärchen-(vorwiegend an der Ehrwalder Alm, im Gais- und Leutaschtal) und Kiefernwälder und in einen Mischwald aus Buchen und Bergahorn. Auch dort wachsen Latschenkiefern auf höheren Lagen bis über 2000 Metern.

Relativ selten sind im ganzen Zugspitzgebiet Linde, Birke, Eberesche, Wacholder und Eibe. Die unterschiedlichsten Arten Moose, die in den Wäldern oft freiliegende Kalksteinfelsen ganz überwuchern kommen dagegen sehr zahlreich vor.

Begrenzt auf trockene Stellen sind Heidelbeere, Moosbeere und Preiselbeere. An geschützten Standorten steht der Frauenschuh. Unterhalb der Waxensteine sind Felder mit Himbeeren und vereinzelt auch wilde Erdbeeren zu finden. Bis in eine recht große Höhe gedeihen der Alpen-Mohn und der Gegenblättrige Steinbrech. In den Geröllhalden gibt es Heller- und Hornkräuter sowie den Weißen Silberwurz, Alpenleinkraut und Moschus-Steinbrech. Nach der Schneeschmelze sprießen Dunkler Mauerpfeffer und Schnee-Enzian als Erste, ihre Samen beginnen bereits im Herbst zu keimen. Auch die bekannten Alpenblumen Edelweiß, Enzian und selten das Alpenveilchen blühen an der Zugspitze.

In den Felsen um die Zugspitze befindet sich der Lebensraum der Gämsen. Auf der Südseite des Massivs ist das Murmeltier verbreitet. Am Zugspitzgipfel findet sich hauptsächlich die Alpendohle, die von fütternden Menschen angezogen wird. Etwas tiefer ist der Bereich des Schneehasen und der Haselmaus. Vorkommende alpine Vögel sind außerdem Steinadler, Schneehuhn, Schneefink, Alpenflühlerche und Bergfink. Auch die Felsenschwalbe, der die Schwalbenwand am Kreuzeck ihren Namen verdankte ist häufig anzutreffen. Die Senke von Mittenwald und Seefeld, ebenso wie der Fernpass sind Vogelzugstrassen.

In felsigem Gelände leben die Bergeidechse und der schwarze Alpensalamander, auch „Bergmandl“ genannt, der meist nach einem Regenschauer auf Bergsteigen zu sehen ist. Auf der West- und Südseite des Zugspitzmassivs sind vor allem im Juli und August Schmetterlinge wie Apollofalter, alpine Perlmutter, Bläuling, Spanner, Mohren- und Dickkopffalter zu beobachten. Die Wälder um die Zugspitze beherbergen Rotwild, Eichhörnchen, Wiesel, Auer-, Hasel- und Birkhuhn. Auf den Gletschern leben Gletscherflöhe und Bärtierchen.

Bis auf den Gipfel der Zugspitze reichen Teile des Landschaftsschutzgebiets "Wettersteingebiet einschließlich Latschengürtel bei Mittenwald" (CDDA-Nr. 395756; 1976 ausgewiesen; 85,8919 km² groß). Bis an die Gipfelregion heran ziehen sich Teile des Fauna-Flora-Habitat-Gebiets "Wettersteingebirge" (FFH-Nr. 8532-371; 42,5691 km²) und bis lediglich an die Innere Höllentalspitze heran solche des Naturschutzgebiets "Schachen und Reintal" (CDDA-Nr. 20723; 1970; 39,6502 km²) und des Vogelschutzgebiets "Schachen und Reintal" (VSG-Nr. 8532-471; 39,6564 km²).

Seit 1851 steht auf dem Gipfel der Zugspitze ein Gipfelkreuz. Die treibende Kraft zur Errichtung eines Kreuzes auf dem Gipfel war der Pfarrer Christoph Ott. In seiner Eigenschaft als meteorologischer Beobachter auf dem Hohen Peißenberg sah er die Zugspitze aus der Ferne und ärgerte sich darüber, dass "„der erste Fürst der bayerischen Gebirgswelt sein Haupt kahl und schmucklos in die blauen Lüfte des Himmels emporhebt, wartend, bis patriotisches Hochgefühl und muthvolle Entschlossenheit es über sich nehmen würden, auch sein Haupt würdevoll zu schmücken.“" Daraufhin organisierte er für den 11. bis 13. August 1851 eine Expedition mit dem Ziel, auf der Zugspitze ein Gipfelkreuz zu errichten. Durch die Partnachklamm und das Reintal erreichten 28 Träger unter der Führung von Forstwart Karl Kiendl die Zugspitze. Die 610 Gulden und 37 Kreuzer teure Unternehmung war erfolgreich. Als Ergebnis stand ein 28-teiliges, 14 Fuß (ca. 4,7 m) hohes, vergoldetes Kreuz aus Eisen auf dem Westgipfel. Pfarrer Ott selbst bestieg die Zugspitze jedoch erst 1854. Nach 37 Jahren hatte das Kreuz durch zahlreiche Blitzeinschläge Schaden genommen; überdies waren die Halterungen stark beschädigt. Im Winter 1881/1882 wurde es daher zum ersten Mal ins Tal gebracht und renoviert. Am 25. August 1882 brachten sieben Bergführer und 15 Träger das Kreuz wieder nach oben. Weil inzwischen eine barackenartige Unterkunft auf dem Westgipfel errichtet worden war, platzierten die Männer das Kreuz auf dem Ostgipfel, der damals nur der zweithöchste war. Dort verblieb es knapp 111 Jahre, bis es am 18. August 1993 erneut demontiert wurde. Die Beschädigungen stammten dieses Mal nicht nur von Wettereinflüssen, sondern auch von amerikanischen Soldaten, die am Kriegsende 1945 auf das Kreuz geschossen hatten. Weil das Gipfelkreuz nicht mehr zu reparieren war, wurde eine originalgetreue Nachbildung angefertigt. Nach zwei Monaten transportierte die Zahnradbahn das neue Kreuz am 12. Oktober zum Zugspitzplatt, von wo es mit dem Helikopter zum Gipfel geflogen wurde. Das originale Gipfelkreuz ist im Werdenfels-Museum in Garmisch-Partenkirchen zu sehen. Das neue Kreuz hat eine Höhe von 4,88 m. Es wurde 2009 für 15.000 Euro renoviert und neu vergoldet und steht seit 22. April 2009 wieder auf dem Ostgipfel. Während der Bauarbeiten zur neuen Eibseeseilbahn (2015–2017) wurde das Gipfelkreuz beim Enteisen des Baukrans beschädigt. Beim Schwenken des Krans schlug eine Kette einen der dreiteiligen goldenen Strahlen ab, welcher von Bergführern jedoch wieder geborgen werden konnte. Am 17. Oktober 2017 wurde das Kreuz abmontiert und mit einer Transportseilbahn zu Tal befördert, um in einer Schlosserei in Eschenlohe repariert zu werden. Im Dezember 2017 wurde es wieder installiert. 

2012 wurde ein muslimisches Gebetshaus am Gipfel errichtet. Gleichzeitig wurde im neuen Werbeprospekt ein Foto des Gipfels ohne das Gipfelkreuz veröffentlicht. Die Bildauswahl wurde von den bayerischen Kirchen als Verleugnung der religiösen Wurzeln des Landes und deplatzierte Anbiederung an die muslimischen Gäste kritisiert.

Für Aufsehen sorgte am 19. März 1922 der Pilot Franz Hailer, der erstmals ein Flugzeug auf der Zugspitze landete. Die mit Kufen ausgestattete Rumpler C. I.-Doppeldeckermaschine landete auf dem Schneeferner, 50 m unterhalb des Gipfels. Am 29. April 1927 gelang Ernst Udet der Start auf dem Schneeferner mit einem Segelflugzeug, er erreichte nach 25 min Flug Lermoos. Per Seilbahn war der in Einzelteile zerlegte Flieger auf die Zugspitze transportiert worden. Im Winter 1931/32 wurde eine Poststelle der damaligen Reichspost auf der Zugspitze eingerichtet. Sie existiert noch heute im Restaurant "Sonn Alpin" mit der Anschrift: "82475 Zugspitze". Vier Jahre nach dem Segelflugstart gelang 1931 der erste Ballonstart von der Zugspitze.

Im April 1933 wurde der Berg von 24 SA-Männern besetzt, die auf dem Turm der Wetterstation eine Hakenkreuz-Fahne hissten. Einen Monat später formierten sich SA- und SS-Männer auf dem Schneeferner in Form eines Hakenkreuzes. Am 20. April 1945 warf die US-Luftwaffe über der Zugspitze Bomben ab, die die Talstation der Tiroler Zugspitzbahn zerstörten und das Kammhotel beschädigten. Nach Kriegsende beschlagnahmten die Alliierten die Zugspitzbahn und das Schneefernerhaus. 1948 nahm die Deutsche Post eine Richtfunkanlage auf dem Gipfel in Betrieb.

Im September 1948 ließ Hans Zimmer über die 1000 m tiefe Schlucht zwischen Ost- und Westgipfel ein 130 m langes Hochseil zum Turmgebäude der Seilschwebebahn spannen. Den Seillauf bei schlechtem Wetter unternahm Siegward Bach, der dieses Wagnis wie Gisela Lenort später wiederholte. Zwei Mitglieder der Traber (Artistenfamilie) fuhren dieselbe Strecke 1953 auf einem Hochseil mit dem Motorrad.

Seit 1953 findet auf dem "Gatterl" jährlich die Gatterlmesse statt. Anlass ist das Gedenken an den Lawinentod von vier bayerischen Grenzpolizisten im Jahr 1952 und an alle tödlich Verunglückten im Zugspitzgebiet.

1962 zerstörte ein Brand das Kammhotel bei der Bergstation der Tiroler Zugspitzbahn. Das Erdbeben von Friaul 1976 wirkte auf der Zugspitze besonders stark; der diensthabende Meteorologe befürchtete, der Beobachtungsturm könnte einstürzen. Auf dem Zugspitzplatt wurde 1981 eine Kapelle gestiftet, die der Erzbischof von München und Freising, Josef Ratzinger, im Oktober "Mariä Heimsuchung" weihte. Am 25. März wurde in der Gipfelstation ein Geldautomat installiert, der aber mittlerweile wieder demontiert ist. 1995 erfolgte die Eröffnung eines 450 m² großen Ausstellungsraumes auf dem Gipfel, in dem Künstler halbjährlich wechselnd ihre Werke präsentieren. Ebenfalls 1995 wurde der Grenzverkehr zwischen Deutschland und Österreich auf dem Gipfel freigegeben.

Seit dem Jahr 2000 wird alljährlich der Zugspitz-Extremberglauf ausgetragen. Er sorgte im Juli 2008 für großes Medienecho, als nach einem sommerlichen Wettersturz zwei Teilnehmer an Erschöpfung und Unterkühlung starben.

Ende August 2009 balancierte der Schweizer Freddy Nock auf dem Seil der Zugspitz-Gletscherbahn vom Zugspitzplatt zum Gipfel. Die 995 m lange und bis zu 56 % steile Strecke (Höhenunterschied: 348 m) legte er ungesichert in 50 min zurück. Am 20. August 2011 balancierte Nock wieder über das Seil der Zugspitz-Gletscherbahn, jedoch verzichtete er diesmal auf eine Balancierhilfe.

Die erste nachgewiesene Besteigung der Zugspitze gelang am 27. August 1820 dem Leutnant Josef Naus und dem Bergführer Johann Georg Tauschl zusammen mit Naus’ Messgehilfen und Offiziersburschen Maier. Bereits am 21. Juli hatte Naus den Weg durch das Reintal bis zum Nördlichen Schneeferner erkundet. Der Leutnant befand sich im Rahmen eines Vermessungsauftrags des "Königlich Bairischen Topographischen Bureaus" für den "Atlas von Bayern" im Werdenfelser Land. Als Gruppe stiegen die drei zusammen mit Hauptmann Jetze und Leutnant Antlischek am 26. August zur Hirtenunterkunft "Angerhütte" auf. Am 27. August um vier Uhr morgens brachen die drei Erstbesteiger in Richtung Zugspitzplatt und Zugspitzgipfel auf. Vom Schneeferner aus versuchten sie, den Westgipfel über den Westgrat zu erreichen. Der erste Versuch schlug fehl, der zweite war erfolgreich. Den Westgipfel erreichten sie schließlich um 11:45 Uhr, wo sie als Zeichen ihrer Anwesenheit einen Bergstock mit Tuch hinterließen. Ein Gewitter und Schneefall ließen die Erstbesteiger schnell wieder absteigen. Sie kehrten am 28. August gegen drei Uhr nachts zur Hirtenhütte zurück. Der Bergführer Tauschl erhielt einen Lohn von zwei Gulden und 42 Kreuzer.

Aufgrund eines Kartenfundes im Archiv des Deutschen Alpenvereins (DAV) gibt es neue Vermutungen über die Erstbesteigung der Zugspitze. Im September 2006 wurde eine historische Karte vermutlich aus der ersten Hälfte des 18. Jahrhunderts, die schon früh in Büchern über die Zugspitze erwähnt wurde, aber seit 1945 als verschollen galt, im Archiv des DAV wiedergefunden. Dort ist ein Steig über das Zugspitzplatt zum Gipfel und auf der anderen Seite wieder herunter zum Eibsee eingezeichnet. Eine Zeitentabelle in der Legende dieser Karte aus dem 18. Jahrhundert beschreibt den Weg „ybers blath uf Zugspitze“ und gibt eine realistische Dauer von 8,5 h an, so dass angenommen wird, der Gipfel könnte schon vor 1820 bestiegen worden sein. Diese Annahme ist jedoch umstritten. Kurt Brunner und Thomas Horst vom Lehrstuhl für Kartographie und Topographie an der Universität der Bundeswehr in München veröffentlichten in der Fachzeitschrift für Kartengeschichte "Cartographica Helvetica" (Heft 35, 2007) eine wissenschaftliche Publikation, die zu folgendem Schluss kommt: „Die aufgefundene Karte des Reintals ist somit keinesfalls ein Beleg für eine frühe Erstbesteigung der Zugspitze.“

Der Historiker Thomas Linder glaubt, dass Hirten oder Jäger mindestens bis in die Gipfelregionen vorgestoßen sind. Denkbar ist auch, dass Schmuggler Wege über den Zugspitz-Gipfel benutzt haben. Bereits 1804 haben in der Umgebung kartographische Aufnahmen für die "Grafschaft Werdenfels" stattgefunden. Es gibt Mutmaßungen, dass im Zuge dieser Arbeiten der kurfürstliche Ingenieur-Geograph Alois von Coulon auch den Gipfel erreicht haben könnte. Da Coulon für das "Topographische Bureau" arbeitete, ist es aber äußerst unwahrscheinlich, dass die Besteigung dort nicht zur Kenntnis genommen worden wäre.

Im Jahr 1823 erreichten Simon Resch und der „Schaf-Toni“ zum ersten Mal den Ostgipfel. Auch die zweite Besteigung des Ostgipfels am 18. September 1834 gelang Simon Resch mit seinem Sohn Johann und dem Bergführer Johann Barth. Da Reschs erste Besteigung angezweifelt worden war, wurde dieses Mal auf dem Gipfel ein Feuer angezündet. Am 27. September kam es zur dritten Besteigung des Ostgipfels durch die königlichen Forstgehilfen Franz Oberst und Schwepfinger zusammen mit Johann Barth. Oberst errichtete am Gipfel eine Fahnenstange mit Bayern-Flagge, die vom Tal aus sichtbar war.

Die erste Besteigung von Österreich aus gelang im August 1837. Von Ehrwald aus stiegen die Vermesser Joseph Feuerstein und Joseph Sonnweber auf den Westgipfel und hinterließen dort eine Signalstange mit ihren Initialen.

Zum dritten Mal wurde der Westgipfel am 10. September 1843 durch den Schafhirten Peter Pfeifer bestiegen. Er erkundete den Weg für eine Gruppe von acht Bergsteigern, die den Gipfel später im Auftrag von Bayerns Kronprinzessin Marie erreichten. Sie ließ den Weg für eine eigene Besteigung der Zugspitze prüfen.

Weitere Meilensteine:

Die Besteigungszahlen der Zugspitze stiegen jährlich stark an. Wurde der Gipfel 1854 22 mal bestiegen, gab es bis zum Jahr 1899 schon 1600 Besteigungen. Vor dem Bau einer Seilbahn im Jahr 1926 waren es schon über 10.000.

Der leichteste der Normalwege führt durch das Reintal und ist der Weg der Erstbesteiger. Gleichzeitig ist er auch der längste Anstieg. Ausgangspunkt ist das Skistadion () von Garmisch-Partenkirchen. Durch die Partnachklamm führt der Weg entlang der Partnach zur Bockhütte (), wo das Reintal beginnt. Oberhalb der Partnach, die zwischendurch versickert, führt der Weg bis zur Reintalangerhütte (). Bis dorthin ist der Anstieg relativ flach, wird danach aber steiler. Von der Hütte geht es durchs "Brunntal" hinauf zur Knorrhütte (), die am Ostrand des Zugspitzplatts steht. Hier trifft auch die Variante von Ehrwald über das Gaistal und das "Gatterl" auf den Reintalweg. Über das Zugspitzplatt führt die Route nun in Richtung Nördlicher Schneeferner. Oberhalb der Station "Sonn-Alpin" beginnt am "Punkt 2815" der versicherte Teil des Anstieges zum Zugspitzgipfel. Insgesamt sind auf der Tour 2232 Höhenmeter zu überwinden, die reine Gehzeit beträgt zwischen acht und zehn Stunden.

In Hammersbach () beginnt der Anstieg über das Höllental, entlang des Hammersbaches. Der Weg durch die Höllentalklamm wurde in den Jahren 1902 bis 1905 gebaut. Dabei wurden in der 1026 m langen Klamm zwölf Tunnel mit einer Länge von 288 Metern geschaffen. Weitere 569 m Weg wurden als Halbprofil aus dem Fels gesprengt, während 120 m auf Stegen und 49 m über Geröll verlaufen. Die Baukosten betrugen insgesamt 57.000 Mark. Jährlich durchqueren rund 60.000 Menschen die Klamm. Auf dem "Stangensteig" kann die Klamm auch umgangen werden. Nach der Klamm folgt die Höllentalangerhütte (), danach wird der "Höllentalanger" überquert. Oberhalb davon quert man das "Brett" mit Stahlstiften in einer Felswand. Über den "Grünen Buckel" geht es auf den Höllentalferner zu. Der Gletscher ist im Sommer meist aper, sodass für seine Überquerung Steigeisen nötig sind. Noch größere Schwierigkeiten bereitet aber die Randkluft, da sich das Eis durch Abschmelzung immer weiter vom Fels entfernt. Nach dem Ferner führt ein Klettersteig auf den Gipfel der Zugspitze. Auf dieser Tour sind 2204 Höhenmeter zu überwinden, für die zwischen sieben und acht Stunden benötigt werden. Es besteht auch die Möglichkeit, über den "Riffelsteig" vom Eibsee auf die Höllentalroute zu gelangen. Über die "Riffelscharte" trifft der Steig vor dem "Brett" auf den Tourverlauf.

Ein dritter Aufstieg führt über das "Tiroler Schneekar". Ausgangspunkte sind der Eibsee () oder Ehrwald (). Die beiden Wege treffen oberhalb des "Gamskars" zusammen. Danach geht es weiter zur Wiener-Neustädter-Hütte () und durch das "Schneekar", an dessen Ende wiederum ein Klettersteig beginnt. In dessen Verlauf wird der Stopselzieher, eine natürliche Auswaschungshöhle durchstiegen. Der Weg trifft dann auf die versicherten Passagen des Reintal-Anstieges. In acht Stunden sind dabei mindestens 2012 Höhenmeter zu überwinden.

Eine der bekanntesten Gratrouten der Ostalpen ist der Jubiläumsgrat, der von der Zugspitze nach Osten verläuft und über die Innere (), Mittlere () und Äußere Höllentalspitze () sowie die Vollkarspitze () zum Hochblassen () führt. Davor zweigt die Route in Richtung "Grießkarscharte" () und zur Alpspitze () ab. Der Grat wurde zwischen 1909 und 1915 von der DAV-Sektion München teilweise mit Drahtseilen versichert. Ursprünglich wurde die Tour "Jubiläumsweg" genannt, nach einer tragischen Rettungsaktion 1979 ersetzte die Bezeichnung "Jubiläumsgrat" diese irreführende und Einfachheit suggerierende Benennung. Während der Tour, die kein reiner Klettersteig ist, müssen immer wieder unversicherte Passagen bewältigt werden, die dem unteren III. Schwierigkeitsgrad entsprechen. Die klettertechnische Schlüsselstelle ist eine glatte Rinne (III-). Im Bereich der Vollkarspitze befindet sich die klettersteigtechnische Schlüsselstelle (D). Die Schwierigkeiten auf der ungefähr acht Kilometer langen Kletterstrecke liegen um I und II sowie B. Normalerweise kann die Begehung im Sommer an einem Tag bewältigt werden. Zwischen Mittlerer und Äußerer Höllentalspitze steht die "Höllengrathütte" (), eine Biwakschachtel. Sie wird meist bei Winterbegehungen genutzt, bei denen die Tour in zwei Abschnitte gegliedert wird. Ein Zustieg zur Tour ist auch von der Knorrhütte über den "Brunntalgrat" möglich und trifft im Bereich der Inneren Höllentalspitze auf die Route.

Im Bereich der Zugspitze befinden sich zahlreiche Berghütten. Im Höllental ist die Höllentalangerhütte () mit 60 Betten und 46 Matratzenlagern ein Stützpunkt. Unterkünfte im Reintal sind die Reintalangerhütte () mit 90 Schlafplätzen und am Rand des Zugspitzplatts die Knorrhütte () mit 108 Übernachtungsplätzen. Die Knorrhütte war 1855 die erste Hütte im gesamten Wettersteingebirge. Alle Hütten sind je nach Witterung von Mai bis Oktober geöffnet. Direkt an der Zugspitze befinden sich mit der Wiener-Neustädter-Hütte und dem Münchner Haus zwei weitere Hütten. Das Schneefernerhaus, ein früherer Hotel- und Gastronomiebetrieb, ist heute eine Forschungsstation und bietet keine Übernachtungsmöglichkeit für Gäste mehr an.

Als erste Hütte an der Zugspitze wurde die Wiener-Neustädter-Hütte () im Jahr 1884 erbaut. Sie dient für den bereits 1879 eröffneten Klettersteig durch das "Österreichische Schneekar" als Stützpunkt. Die Hütte befindet sich am Westrand des Kars und steht unterhalb der Tiroler Zugspitzbahn. Vom Österreichischen Touristenklub betrieben, bietet sie 34 Bergsteigern in der Zeit von Juli bis Oktober eine Übernachtungsmöglichkeit.

Seit 1883 steht knapp unter dem Westgipfel eine Unterkunft. Damals errichtete die Alpenvereinssektion München eine Holzhütte mit Platz für zwölf Personen. Obwohl eine weitere touristische Erschließung des Gipfels auch kritisiert wurde, forderten in der Folge immer mehr Mitglieder den Bau einer größeren Hütte. So wurde schließlich das Münchner Haus () errichtet. Zunächst wurde 1896 ein 200 Quadratmeter großer Bauplatz in den Fels gesprengt. Die bis zum 19. September 1897 errichtete Berghütte kostete 36.615 Mark. Sie war mit einer 21 Kilometer langen Telefonleitung und einem 5,5 km langen Blitzableiter versehen. In den Jahren 1911 bis 1914 wurde die Hütte erweitert und erhielt ihr heutiges Aussehen. Sie bietet 30 Betten zur Übernachtung und ist von Mai bis Oktober geöffnet. Es übernachten dort durchschnittlich 2000 Personen pro Jahr, hinzu kommen Tagestouristen.

Das Schneefernerhaus () war ab 1930 zunächst der Bahnhof der Bayerischen Zugspitzbahn. Im Juni 1931 wurde das angebaute Hotel eingeweiht. Nach dem Krieg beschlagnahmten die US-Streitkräfte das Haus als "Recreation Facility" (Erholungszentrum). Erst 1952 wurde es wieder freigegeben und renoviert, Wiedereröffnung war im Dezember desselben Jahres. Am 15. Mai 1965 ereignete sich ein schweres Lawinenunglück. Die Lawine hatte sich oberhalb des Hauses gelöst und war über die Sonnenterrasse hinweggefegt. Dabei verloren 10 Menschen das Leben und 21 wurden schwer verletzt. Ende der 1980er Jahre wurde der Bahnhof verlegt und der Hotel- und Gastronomiebetrieb im Januar 1992 eingestellt. Zwischen 1993 und 1997 erfolgte der umfangreiche Umbau zu einer Forschungsstation, die bereits 1996 in Betrieb genommen wurde. Während der Arbeiten kam es 1994 zu einem Brand, der den fünften Stock und das Dachgeschoss völlig zerstörte.

Seit 1949 gibt es auf dem Zugspitzplatt ein Skigebiet, gegenwärtig betrieben von der Bayerischen Zugspitzbahn Bergbahn AG auf einer Höhe von 2000 bis . Die Skifahrer erreichen es über die Seilbahnen von Ehrwald und Eibsee aus oder mit der Zahnradbahn. Von den Zugspitz-Gipfelstationen der Seilbahnen bringt eine Großkabinenbahn die Wintersportler zur Station "Sonn Alpin", wo sich auch die einzigen Restaurants des Gebiets befinden. Über das Platt verteilt werden die Skifahrer von fünf Liften transportiert. Seit dem Winter 2012/2013 gibt es zwei Sesselbahnen sowie drei Schlepplifte, von denen zwei als Parallelschleppliftanlagen, das heißt mit zwei gleich langen nebeneinander verlaufenden Anlagen betrieben werden. Diese acht Lifte haben eine mögliche Förderleistung von 11.640 Personen pro Stunde. Die größte Kapazität haben dabei die 6er Sesselbahnen mit jeweils 2200 Personen. Zum Beginn der Wintersaison 2012/2013 wurde als Ersatz für die Doppelschleppliftanlage Wetterwandeck der neue 6er Sessellift zum Wetterwandeck fertiggestellt (Höhenunterschied: 300 Meter, Kapazität bis zu 2.200 Personen pro Stunde, Länge: 1.600 m – damit längster Lift auf dem Zugspitzplatt, 67 Sechser-Sessel).

Insgesamt sind die Beförderungsanlagen 6050 Meter lang und überwinden einen Höhenunterschied von 1535 m. Der Schlepplift "Weißes Tal" überwindet mit 350 m den größten Höhenunterschied. Das Gebiet besteht aus 13 Skipisten mit mittlerer Schwierigkeit (rot) und einem Pistenverbund leichter Schwierigkeit (blau) auf dem Nördlichen Schneeferner. Daraus ergibt sich ein Gesamthöhenunterschied von zirka 2900 Metern und eine Gesamtpistenlänge von ungefähr 20 Kilometern, darunter 14 km mit mittlerer Schwierigkeit. Längste Piste ist der "Super G" mit 2,9 km bei 500 m Höhenunterschied. Darüber hinaus bestand bis in den Winter 2011/12 ein Funpark und die Möglichkeit, den Gebrauch von Lawinenverschüttetensuchgeräten zu trainieren.

Für Skitourengeher ist besonders die Route von Ehrwald über das Gatterl von Bedeutung. Die „Neue Welt“ genannte südseitig exponierte Abfahrt vom Schneefernerkopf nach Ehrwald gilt als extrem schwierige und gefährliche Steilabfahrt, die neben Steigungen bis zu 40 Grad auch eine Abseilstelle aufweist.

Die erste Luftseilbahn ins Zugspitzmassiv war die Tiroler Zugspitzbahn. 1923 wurde in Reutte die "Österreichische Zugspitzbahn AG" gegründet, die 1924 eine Konzession zum Bau einer Seilbahn von Ehrwald auf das Zugspitzeck erhielt. Nach 14 Monaten Bauzeit war die Bahn bis Juli 1926 fertig gestellt und ein Hotel, genannt "Kammhotel" errichtet. Die Bahn endete auf 2805 Metern, sodass mit ihr der Gipfel nicht direkt erreicht werden konnte. Um Skifahrer auf das Zugspitzplatt zu befördern, war ein Tunnel nötig. Er wurde zwischen 1927 und 1929 gebaut und war 700 Meter lang. 1937 übernahm die "Bayerische Zugspitzbahn AG" mit 99 Prozent die Mehrheit an der Österreichischen AG. Im selben Jahr wurde der Tunnel bis zum Schneefernerhaus verlängert. Nach dem Krieg wurde die Seilbahn als "Deutscher Besitz im Ausland" enteignet und ging wieder in österreichisches Eigentum über. Am 15. Mai 1964 erfolgte die Eröffnung einer Gipfelseilbahn als Verbindung der österreichischen Endstation mit dem Gipfel.

Im Juli 1991 war der Neubau der Seilbahn von Ehrwald auf den Gipfel abgeschlossen. Sie ist 3,6 Kilometer lang und führt von Ehrwald-Obermoos () über drei Stützen auf die Zugspitze (). Im Februar 2003 beschädigte ein Brand in der Talstation die Bahn schwer. Sie konnte im August desselben Jahres wieder eröffnet werden.

Nach dem Beginn des Baus der Jungfraubahn auf das Jungfraujoch 1896 und der Eröffnung der Gornergratbahn 1898 in der Schweiz gab es auch erste Pläne für eine technische Erschließung der Zugspitze. Ein erstes Gesuch lehnte Prinzregent Luitpold von Bayern 1899 ab, weil er "„keinerlei Verkehrsbedürftnis“" sah. 1914 wurde erstmals eine Planungsgenehmigung für eine solche Bahn erteilt, die jedoch wegen des Ersten Weltkrieges scheiterte. 1925 wurde eine weitere Konzession erteilt, die allerdings verfiel.

Am 1. April 1928 erhielt ein Konsortium mit einem Kapital von fünf Millionen Reichsmark die Genehmigung für den Bau einer Bahn zwischen Garmisch-Partenkirchen über den Eibsee hinauf zur Zugspitze, genannt "Bayerische Zugspitzbahn". Die Fertigstellung war für den Beginn der Oberammergauer Passionsspiele 1930 geplant. Um diese knappe Bauzeit einhalten zu können, wurde der Zugspitztunnel nicht nur von unten herauf gebohrt, sondern auch von oben und mit Hilfe der "Fenster I", "III", "IV" und "0" in der Nordwand vorangetrieben. Über diese künstlichen Wandöffnungen wurden die Arbeiter durch Hilfsseilbahnen mit dem nötigen Material versorgt. Insgesamt bewegten teilweise bis zu 2500 Arbeiter 85.000 Kubikmeter Erde und 160.000 Kubikmeter Fels. Sie verbrauchten dabei knapp 198 Tonnen Sprengstoff. Bei den Bauarbeiten verloren zehn Menschen ihr Leben. Am 8. Februar gelang der Tunnel-Durchbruch zum Zugspitzplatt. Die Eröffnung der Bahn war am 8. Juli 1930, das Hotel Schneefernerhaus am Bahnhof Zugspitzplatt wurde wie die Gipfelseilbahn am 20. Januar 1931 eröffnet. Die Seilbahn wurde 1977 zu einer Großkabinenbahn ausgebaut und 1992 erneut modernisiert.

1950 erbaute man eine Verbindungsseilbahn zwischen Schneefernerhaus und Zugspitzplatt, die 1966 erneuert wurde. Zwischen 1985 und 1988 wurde der Endbahnhof nach unten verlegt, so dass er seitdem mitten im Skigebiet liegt. Zwischen Garmisch () und Grainau () verläuft die Bahn als Reibungsbahn und im Anschluss daran bis zur Endstation "Gletscher-Bahnhof" () als Zahnradbahn. Die Strecke ist insgesamt 19 km lang, wovon 4,4 km durch den Zugspitz-Tunnel verlaufen. Eine Fahrt dauert ungefähr 45 min. Vom Bahnhof führt die Zugspitz-Gletscherbahn auf den Gipfel. Auf der Bahnstrecke kam es jeweils 1999 und 2000 zu Kollisionen, bei denen mehrere Menschen verletzt wurden.

Erste Pläne für eine Seilbahn vom Eibsee zur Zugspitze gab es bereits 1909 mit der Genehmigung zur Projektierung, die 1911 verlängert wurde. Das Projekt scheiterte jedoch zunächst an der Finanzierung. 1960 erhielt die Bayerische Zugspitzbahn AG die Konzession für die Eibsee-Seilbahn. Bis zum Dezember 1962 wurde eine 4500 m lange Seilbahn zwischen Eibsee () und Gipfel gebaut. Sie verlief über zwei 65 und 85 Meter hohe Stützen und überwand 2000 Höhenmeter. Die Neigung betrug bis zu 46 Grad. Bei der Jungfernfahrt am 1. Dezember 1962 führte eine Blockade des elektronischen Bremssystems zum Abbruch der Eröffnung. Die Kabine mit den Ehrengästen war mitten auf der Strecke steckengeblieben. Seilprobleme bei Stürmen sorgten dafür, dass die Bahn ihren Betrieb erst am 15. Mai 1963 aufnehmen konnte. 1973 wurde die obere Stütze von einer Lawine schwer beschädigt.

2017 wurde die alte Seilbahn durch die heutige, leistungsfähigere Bahn ersetzt. Die letzte planmäßige Fahrt der bisherigen Bahn erfolgte am 2. April 2017. Am 21. Dezember 2017 wurde die neue Seilbahn Zugspitze in Betrieb genommen.

Von Juli 1899 bis Juli 1900 wurde am Münchner Haus ein meteorologisches Observatorium, die "Königlich Bayerische Meteorologische Hochstation Zugspitze", angebaut und am 19. Juli 1900 eingeweiht. Erster Wetterbeobachter auf der Bergwetterwarte war der spätere Antarktisforscher Josef Enzensperger, der dort oben sieben Monate überwinterte. Das Observatorium wird seit dem 11. November 1952 vom Deutschen Wetterdienst betrieben. Seit der Inbetriebnahme gibt es von der Zugspitze fast lückenlose Wetterbeobachtungen. Die einzige Unterbrechung der Messreihen trat nach dem Zweiten Weltkrieg zwischen dem 5. Mai und dem 9. August 1945 ein. Die im 24-Stunden-Dienst betriebene Station liefert täglich 24 stündliche Wettermeldungen mit Temperatur, Luftdruck, Strahlung, Windgeschwindigkeit sowie Art und Grad der Bewölkung. Alle sechs Stunden erfolgt eine Niederschlagsmessung und alle zwölf Stunden die Aufnahme der Temperatur-Extremwerte, des Erdbodenzustandes und der Schneehöhe. Die tägliche Sonnenscheindauer misst ein Autograf.

Seit 1994 ist die Wetterwarte Teil des "Integrierten Mess- und Informationssystems zur Überwachung der Umweltradioaktivität" (IMIS) des Deutschen Wetterdienstes. Bei diesen Messungen werden in jedem Winter erhöhte Caesium-137-Werte gemessen, weil vermehrt radioaktiv verseuchtes Holz verbrannt wird. Diese Radioaktivität ist noch die Folge der Katastrophe von Tschernobyl, wobei die Werte aber unbedenklich sind. Als 1998 in einem spanischen Stahlwerk versehentlich eine Kapsel mit Caesium 137 verbrannt wurde, überschritten die Werte mit 0,000022 Becquerel zum bisher einzigen Mal deutlich den Normalwert.

Neben der vom Deutschen Wetterdienst (DWD) betriebenen Wetterwarte werden in einer Beobachtungsanlage auf dem Gipfel auch Daten für Forschungsprojekte am "Institut für Meteorologie und Klimaforschung – Atmospherische Umweltforschung" (IMK-IFU) des Karlsruher Instituts für Technologie (KIT) gesammelt. Dort beschäftigt man sich mit dem Einfluss menschlicher Aktivitäten auf die chemische Zusammensetzung der Erdatmosphäre. Außerdem ist die Zugspitze Teil des Global-Atmosphere-Watch-Programms, das weltweit klimarelevante Stoffe in der Atmosphäre misst. Dafür wurde auf dem Dach der Gipfelstation ein Spektrometer eingebaut, das die Dicke der Erdatmosphären-Schichten feststellt.

Nach der Schließung des Hotels Schneefernerhaus und seinem Umbau (1993–1997) zur "Umweltforschungsstation Schneefernerhaus" (UFS) haben ab 1996 verschiedene Institutionen mit ihrer Forschung begonnen. Die Station kann ganzjährig mit den Seilbahnen oder mit einer Sonderfahrt bis zum alten Bahnhof mit der Zahnradbahn erreicht werden. Die Grundausstattung stammt aus Mitteln des Bundesforschungsministeriums und der Deutschen Bundesstiftung Umwelt. Als Dauermieter sind in der UFS der Deutsche Wetterdienst mit Meteorologie und radiologischen Messungen und das Umweltbundesamt mit luftchemischen Messungen beschäftigt. Zuletzt (Stand: 2009) fanden folgende Forschungsprojekte statt: Die UFS bearbeitete ein Projekt, in dem atmosphärische Messdaten von Satelliten auf ihre Verwertbarkeit getestet werden. Das Deutsche Zentrum für Luft- und Raumfahrt und das Deutsche Fernerkundungsdatenzentrum beteiligten sich an einem globalen Netzwerk, das eine Früherkennung von Klimasignalen in den oberen Luftschichten ermöglichen soll. In 87 Kilometern Höhe, der Mesopause, wird dazu mit Hilfe eines Infrarotspektrometers der sogenannte Airglow gemessen. Ein weiteres Projekt ist die Messung von klimarelevanten Spurenstoffen in der Troposphäre. Das Karlsruher Institut für Technologie befasste sich am Schneefernerhaus mit der vertikalen Verteilung von Wasserdampf in der Atmosphäre, die mit LIDAR gemessen wird. Daneben werden regionale Klimaszenarien berechnet, die eine Abschätzung der langfristigen Wasserverfügbarkeit erlauben.

Das Meteorologische Institut der Ludwig-Maximilians-Universität München (LMU) beschäftigt sich mit der Analyse von Wolken und Schnee für die Klima- und Wettervorhersage. Mit einem Mikrowellen-Radiometer wird der Flüssigkeitsgehalt von Wolken bestimmt. Mehrere Institute arbeiten an einem Vorhaben, das mit Hilfe von Fernerkundung die mikrophysikalischen Eigenschaften von Schnee bestimmen soll. Die Freie Universität Berlin forscht an den Streueigenschaften von Aerosolen, die hauptsächlich in Luftschichten bis 3000 Meter auftreten, weshalb das Schneefernerhaus ein geeigneter Forschungsstandort ist. Forschungsschwerpunkt des Helmholtz-Zentrums München ist die kosmische Strahlung und deren Auswirkung auf das Klima. An einem Verfahren zur Probeentnahme aus der Troposphäre zum Zweck der Bestimmung darin enthaltener organischer Schadstoffe arbeitet die Masaryk-Universität. Die LMU und das Bayerische Landesamt für Umwelt überwachen Bayern vom Schneefernerhaus aus seismologisch. Die medizinische Abteilung der Technischen Universität München untersucht Auswirkungen des Hochgebirgsklimas auf Allergien. Das rechtsmedizinische Institut der LMU befasst sich mit Auswirkungen von Luftdruck und Klima in der Höhe auf die Atemalkoholbestimmung.

Von der Zugspitze aus werden neben Richtfunk-Verbindungen Radio- und Fernsehprogramme ausgestrahlt.
Auf dem Turm der Wetterwarte des Deutschen Wetterdienstes befindet sich Deutschlands höchstgelegene Amateurfunk-Relaisstation.

Karten




</doc>
<doc id="5798" url="https://de.wikipedia.org/wiki?curid=5798" title="Zivilisation">
Zivilisation

Als Zivilisation (von : ‚römischer Volksangehöriger‘, ‚Städter‘; seit dem Hochmittelalter ‚Bürger‘) wird eine menschliche Gesellschaft bezeichnet, bei der die sozialen und materiellen Lebensbedingungen durch technischen und wissenschaftlichen Fortschritt ermöglicht und von Politik und Wirtschaft geschaffen werden. Allgemeingültige Kennzeichen für Zivilisationen sind die Staatenbildung, hierarchische Gesellschaftsstrukturen, ein hohes Maß an Urbanisierung und eine sehr weitgehende Spezialisierung und Arbeitsteilung.

Der Begriff "Zivilisation" ist von dem im Deutschen seit dem 17. Jahrhundert belegten Adjektiv "zivil" (‚bürgerlich‘) abgeleitet. Im 18. Jahrhundert benutzte man im Französischen die Idee der Zivilisation als Gegensatz zum Begriff „Barbarei“. So konnten nichteuropäische Gesellschaften als unzivilisiert charakterisiert werden. In den romanischen und angelsächsischen Sprachen werden die Begriffe „Kultur“ und „Zivilisation“ anders als im Deutschen gebraucht. Die Geschichtswissenschaft versteht unter Kulturen großräumige und langlebige Gebilde, die eine große Prägekraft entwickeln, obwohl sie häufig eine Vielzahl von Erscheinungsformen und Entwicklungsstufen aufweisen.

Die heutige Definition von Zivilisation in der internationalen Politik versteht diese bildlich vorgestellt als „Kulturdach“ für mehrere ähnlich gelagerte Kulturen, die geographisch nicht aneinander gebunden sein müssen. Staaten einer Zivilisation teilen eine Weltanschauung. Kultur wird in diesem Zusammenhang definiert als lokal begrenzte, Sinn stiftende Produktion von gemeinsamen Werten und Normen. Im Anschluss an den Sozialwissenschaftler Norbert Elias und dessen Theorie "Über den Prozeß der Zivilisation" wird der Begriff auch im Sinne von „Zivilisierung“ verwendet.

Der Begriff "civilisation", der sich im ausgehenden 18. Jahrhundert ursprünglich auf die französische Gesellschaft des Ancien Régime bezog und die positiven Erwartungen im Zeitalter der Aufklärung an den Fortschritt der Gesellschaft zum Ausdruck brachte, erfuhr im Zuge des Kolonialismus im 19. Jahrhundert eine Neubewertung. Es etablierte sich die Vorstellung von unzivilisierten außereuropäischen Gesellschaften, denen die eigene zivilisierte Gesellschaft gegenübergestellt wurde.

Während sich vor allem in den angelsächsischen Ländern eine Gleichsetzung von Kultur und Zivilisation durchsetzte, entwickelte sich dagegen in Deutschland eine Abgrenzung der als tiefgründig und wertvoll verstandenen deutschen Kultur gegenüber der als oberflächlich dargestellten westlichen Zivilisation. In diesem Sinne übten unter anderem Oswald Spengler und Arnold Gehlen Zivilisationskritik. Die Unterscheidung zwischen Kultur und Zivilisation blieb bis nach 1945 im deutschen Sprachraum vorherrschend.

Etymologisch stammt das Wort "Zivilisation" vom französischen "civilisation". Es kann weiter verfolgt werden über das lateinische "civilis" und seine Wurzel im Begriff "civis". Dieser bezeichnet die "Bürger" (anfangs spezifisch "Stadtbewohner") Roms. Dort tritt eine Verwandtschaft mit dem lateinischen Begriff "civitas" auf, welcher Städte und Stadtstaaten bezeichnet. Eine Rückführung des Begriffs auf eines der entscheidenden Merkmale von Zivilisationen, dem Bau von Städten, ist somit belegbar.

Zivilisation, einem Volk oder einer bestimmten Menschheit zugesprochen, umreißt:
Der Beginn der Zivilisation wird oft in den frühen Hochkulturen gesehen. Durch die Sesshaftigkeit infolge der Landwirtschaft waren nun mehr Menschen als jemals zuvor an einem Ort über längere Zeit gebunden. Hieraus ergaben sich neue Regelungen für das Zusammenleben in den neu entstandenen Städten: Religion, Herrschaft, Kultur etc., welche die "Wiege der Zivilisation" bilden.

Die Allgemeine Erklärung der Menschenrechte, auf die sich die UNO 1948 als verbindlich für alle Menschen und Staaten geeinigt hat, wird umgangssprachlich als "Zeichen der Zivilisation" bezeichnet.

„Zivilisation“ wird seit der Aufklärung auch als politischer Kampfbegriff gebraucht.

Karl Marx analysiert dies in seiner Schrift "Der Bürgerkrieg in Frankreich". Er zitiert den Anführer der Konterrevolution gegen die Pariser Kommune, Adolphe Thiers: Und kommentiert: 

In Tage in Burma lässt George Orwell seine Hauptfigur, den Händler Flory, ausrufen: 

Einschlägiges Zitat:
Auch in der Gegenwart wird Zivilisation gelegentlich ideologisch gebraucht, wenn ihn Samuel Huntington in The Clash of Civilizations zur Prognose weltweiter Konflikte benutzt. Huntington unterscheidet folgende „Zivilisationen“: Islam, Westen, Konfuzianismus, japanische Zivilisation, Latino-Amerikanismus, orthodox-slawische Zivilisation, Hinduismus, afrikanische Zivilisation.

Der Politikwissenschaftler Bassam Tibi schrieb in „Krieg der Zivilisationen“ eine eigene Ausdeutung der Huntington'schen Thesen. In seinem Buch „Die fundamentalistische Herausforderung - Der Islam und die Weltpolitik“ sah er den islamischen Fundamentalismus nicht als religiöse Richtung, sondern als Ergebnis der Konfrontation der nach seiner Ansicht rückständigen islamischen Welt mit der westlichen Zivilisation.

Gazi Çağlar behauptet in „Der Mythos vom Krieg der Zivilisationen“, dass Samuel Huntington und Bassam Tibi zyklischen Geschichtsphilosophien anhängen und in direkter Nachfolge Oswald Spenglers stehen.

Norbert Elias hat (zuerst 1939 in "Über den Prozess der Zivilisation") den Begriff „Zivilisation“ im Sinne von „Zivilisierung“ verwendet. In diesem Hauptwerk beschreibt er „Zivilisierung“ als einen langfristigen Wandel der Persönlichkeitsstrukturen, den er auf einen Wandel der Sozialstrukturen zurückführt. Faktoren des sozialen Wandels sind der kontinuierliche technische Fortschritt und die Differenzierung der Gesellschaften einerseits sowie der ständige Konkurrenz- und Ausscheidungskampf zwischen Menschen und Menschengruppen andererseits. Diese führen zu einer Zentralisierung der Gesellschaften (Einrichtung staatlicher Gewalt- und Steuermonopole) sowie zur Geldwirtschaft. Das Bindeglied zwischen diesen sozialstrukturellen Veränderungen und den Veränderungen der Persönlichkeitsstruktur ist die Tatsache, dass die gegenseitigen Abhängigkeiten wachsen, die „Interaktionsketten“, in die Menschen eingebunden sind. Dies erzwingt eine zunehmende Affektkontrolle (auch als Bedingung sozialer Evolution), d. h. zwischen spontanen emotionalen Impuls und tatsächliche Handlung tritt immer mehr ein Zurückhalten dieses Impulses und ein Überdenken der (Rück-)Wirkungen des eigenen Handelns. Diese Haltung wird durch Verstärkung des „Über-Ich“ verinnerlicht und verfestigt, d. h. der Zentralisierung innerhalb der Gesellschaft folgt mit gewisser Verzögerung eine „Zentralisierung“ innerhalb der Persönlichkeit. Dies bewirkt ein "Sinken der Gewaltbereitschaft", ein "Vorrücken der Scham- und Peinlichkeitsschwellen" sowie eine "Psychologisierung" (Steigerung der Fähigkeit, die Vorgänge innerhalb anderer Menschen zu verstehen) und "Rationalisierung" (Steigerung der „Langsicht“, d. h. der Fähigkeit, die Folgen der eigenen Handlungen über immer mehr Glieder der Kausalketten „vorauszuberechnen“).

Elias zeigt dies mit umfangreichem empirischem Material besonders am Beispiel der französischen Geschichte, in der diese langfristigen Trends besonders frühzeitig zu beobachten waren. Seit dem Mittelalter kam es zur „Verhofung“ bzw. „Verhöflichung“ des alten Burg- und Landadels an den Höfen der ihre Macht konzentrierenden Monarchen. Dies folgte im Wesentlichen der Entstehung der stehenden Söldnerheere und ihrer Finanzierung durch ein sich modernisierendes monetäres zentrales Steuerwesen (anstelle von Naturalabgaben). Die neue Heeresverfassung machte die unzuverlässigen feudalen Heere des Adels überflüssig, da sie dank der Steuern auch bezahlt werden konnten, die wiederum der Adel nicht erheben konnte, der relativ zur Zentralmonarchie verarmte. Der König (am gewandtesten Ludwig XIV.) eröffnete dann den Adeligen am Hofe neue Karrierechancen, wo sie statt auf Faustrecht auf Courtoisie und höfisches Intrigieren umgeschult wurden, also auf psychologischen Scharfblick, und aus Raufbolden mit Schwertern Hofleute mit Galanteriedegen wurden. Das Ganze war ein von niemandem geplanter strukturierter Prozess sozialen Wandels (eine Figuration), indem sich raubritterliche Brutalität zusehends als unpraktisch erwies (Duellverbote) und die Manieren sich verfeinerten. Diese Sitten wurden dann zumal auch vom Bürgertum kopiert (vgl. Gabriel Tarde) und veränderten die Gesellschaft insgesamt, "zivilisierten" sie.

Claude Lévi-Strauss schlug vor, Kulturen nach ihrer weltanschaulichen Einstellung zum Kulturwandel zu unterscheiden. Er hatte festgestellt, dass „primitive“ naturangepasste Ethnien komplexe soziale Verhaltenssysteme haben, um jeglichen Wandel der bewährten Lebensweisen so weit wie möglich zu vermeiden. Er bezeichnete sie als „kalte Gesellschaften“. „Heiße Gesellschaften“ nannte er demgegenüber die modernen Zivilisationen, bei denen eine fortschreitende Entwicklung in allen Lebensbereichen kennzeichnend ist. Je größer der Antrieb zu tiefgreifender und schneller Modernisierung der Zivilisation ist, desto „heißer“ ist sie. Das Modell wurde von anderen Wissenschaftlern ausgebaut und verfeinert.

In anderen Kulturen kann der Begriff „Zivilisation“ bisweilen eine ganz andere Bedeutung haben, wie das folgende Zitat zeigt:

Innerhalb der Astrobiologie und Exosoziologie wird spekuliert, ob es auch auf anderen Welten (Exoplaneten) Lebewesen mit wissenschaftlich-technischer Organisation gibt. Diese werden als extraterrestrische Zivilisationen bezeichnet. Über die Wahrscheinlichkeit ihrer Existenz und möglichen Häufigkeit wird mit Hilfe der Drake-Gleichung diskutiert. Die Kardaschow-Skala kategorisiert mögliche Entwicklungsstufen nach dem Energieverbrauch.




</doc>
<doc id="5799" url="https://de.wikipedia.org/wiki?curid=5799" title="Zeichenkette">
Zeichenkette

Eine Zeichenkette, auch Zeichenreihe oder (aus dem Englischen) ein , ist in der Informatik eine endliche Folge von Zeichen (z. B. Buchstaben, Ziffern, Sonderzeichen und Steuerzeichen) aus einem definierten Zeichensatz. Zeichen können sich in einer Zeichenkette wiederholen, die Reihenfolge der Zeichen ist definiert. Eine Zeichenkette kann auch "leer" sein, also kein Zeichen enthalten und die Länge 0 haben. Zeichenketten sind somit Sequenzen aus Symbolen mit endlicher Länge.

In der Programmierung ist eine Zeichenkette ein Datentyp, der eine Kette von Zeichen mit fester oder variabler Länge enthält. Damit werden hauptsächlich Wörter, Sätze und ganze Texte gespeichert. Fast jede Programmiersprache besitzt einen derartigen Datentyp und manche Programmiersprachen arbeiten ausschließlich mit diesem Datentyp. Beispiele dafür sind sed, awk und bash. Im Quelltext eines Computerprogramms stellen Zeichenketten Text dar, der nicht als Programmierbefehl aufgefasst wird, sondern Information enthält. So können zum Beispiel Fehlermeldungen oder andere Ausgaben an den Benutzer als Zeichenkette im Quelltext festgehalten werden oder Benutzereingaben als Zeichenketten in Variablen abgespeichert werden.

Die Grundlagen von Programmiersprachen werden in der Theoretischen Informatik untersucht. Dort wird der gegebene Zeichensatz als Alphabet bezeichnet und die Zeichenketten werden „Wörter“ genannt. Die Theorie solcher Wörter sind ein Thema der formalen Sprachen. Im Zusammenhang mit Programmiersprachen stellen sich dagegen Fragen der Darstellung, der Speicherung und des Umgangs mit Zeichenketten.

Zeichenketten können auf verschiedenen Ebenen repräsentiert werden. Eine davon ist der Quelltext eines Programms, der vom Übersetzer gelesen und interpretiert wird. Eine andere ist, wie eine Zeichenkette zur Laufzeit eines Programms im Speicher abgelegt wird.

Im Allgemeinen wird eine literale Zeichenkette in den Programmiersprachen durch das einfache Aneinanderfügen von Zeichen repräsentiert. Sie wird durch einfache oder doppelte Anführungsstriche eingeschlossen:


Solche Strings müssen normalerweise in einer einzigen Zeile notiert werden. In manchen Programmiersprachen wie etwa Python können jedoch Strings, die durch verdreifachte Anführungszeichen begrenzt werden, auch mehrere Zeilen umfassen.

Es gibt mehrere Verfahren, um Zeichenketten effizient abzuspeichern. Zum Beispiel kann ein Zeichen aus dem verwendeten Zeichensatz als Abschlusszeichen definiert werden. Eine Zeichenkette hört dann vor dem ersten Vorkommen dieses Zeichens auf. Eine andere Möglichkeit ist, die Länge der Zeichenkette separat zu speichern.

In Programmiersprachen wie C werden die Zeichenketten fortlaufend im Speicher abgelegt und mit dem Nullzeichen (NUL in ASCII) abgeschlossen. Das Nullzeichen ist das Zeichen, dessen binäre Repräsentation nur aus Nullen besteht. Das folgende Beispiel zeigt, wie eine Zeichenkette mit 5 Zeichen in einem Puffer von 10 Byte Länge abgelegt werden könnte:
Die Länge der obigen Zeichenkette ist 5; sie benötigt aber 6 Bytes im Speicher. Buchstaben nach dem NUL-Zeichen zählen nicht mehr zur Zeichenkette; sie können zu einer neuen Zeichenkette gehören oder einfach ungenutzt sein. Eine Zeichenkette in C ist ein Array vom Typ char, wobei die Zeichenkette als Ende-Kennung ein Nullzeichen enthält. Deswegen heißen solche Zeichenketten auch "nullterminiert", ein älterer Begriff ist "ASCIIZ-String". Da das Nullzeichen selbst auch noch Speicherplatz benötigt, den die Zeichenkette belegt, ist der Speicherbedarf einer Zeichenkette immer mindestens 1 Zeichen größer als die nutzbare Länge der Zeichenkette.
Als „Länge der Zeichenkette“ wird die Anzahl der Zeichen vor der Endekennung bezeichnet.
Sie wird von der C-Funktion codice_9 ermittelt.

Der Vorteil dieser Methode ist, dass die Länge eines Strings nur durch den verfügbaren Speicher begrenzt ist und nicht zusätzlich von der Kapazität des Längenfeldes; ein Nachteil ist, dass er keine Null-Zeichen enthalten kann, und dass der Umgang vergleichsweise schwierig und ineffizient ist; beispielsweise kann die Länge eines solchen Strings nur durch das Abzählen der Zeichen ermittelt werden.

Eine andere Art, Zeichenketten abzulegen, wird in den Programmiersprachen Pascal, BASIC, PL/I und anderen verwendet:
Zeichenketten, die so gespeichert werden, können eine bestimmte Länge nicht überschreiten. In Turbo Pascal wird die Länge zum Beispiel im „nullten“ Zeichen gespeichert. Da ein Zeichen 8 Bit groß ist, ist die Länge damit auf 255 Zeichen begrenzt.
Die Nachfolgesprache Object Pascal hat das Längenfeld auf 31 Bit erweitert und unterstützt Zeichenketten von bis zu 2 Gigabyte Länge. Auch in REXX wird die Länge in vier Bytes gespeichert, sodass die Begrenzung durch das Längenfeld nicht stärker ist als durch den Speicher.

Die Speicherung von Zeichenketten benötigt viel Speicherplatz und ist eine sehr häufige Aufgabe. Deshalb verwenden viele höhere Programmiersprachen eine besondere Verwaltung, um das möglichst effizient gestalten zu können. Dies ist aber dem Zugriff der Programmierer einer Anwendung entzogen; es gibt in aller Regel keine Möglichkeit, auf diese Verwaltung direkt zuzugreifen oder auch nur festzustellen, ob eine solche aktiv ist.

Es werden alle Zeichenketten in einem zentralen „Pool“ abgelegt. Das Ziel ist, dass jede benötigte Zeichenkette nur genau ein einziges Mal gespeichert wird. Die Variable im Anwendungsprogramm erfährt nur eine Kennnummer, um bei Bedarf auf die Zeichenkette zugreifen zu können.

Die Verwaltung bedient sich für die Organisation schneller und effizienter Methoden (meist einer Hashtabelle). Jedes Mal, wenn eine Zeichenkette gespeichert werden soll, wird nachgesehen, ob eine inhaltsgleiche bereits bekannt ist. Ist das der Fall, wird die Kennnummer der bereits existierenden Zeichenkette zurückgegeben; ansonsten muss sie neu angelegt werden.

Jedes Mal, wenn eine Zeichenkette gespeichert wird, wird ihr Referenzzähler um eins erhöht. Wird eine Zeichenkette an einer Stelle des Programms nicht mehr benötigt (weil ein Unterprogramm beendet ist und die darin enthaltenen Literale sinnlos werden, oder weil eine Variable einen anderen Wert erhält), wird dies der Verwaltung gemeldet und der Referenzzähler um eins vermindert. Damit lässt sich feststellen, welche der gespeicherten Zeichenketten im Moment verwendet werden – hat der Referenzzähler den Wert Null, wird sie zurzeit nicht gebraucht. Dadurch wäre es möglich, bei Engpässen an Speicherplatz die Verwaltung zu reorganisieren und unbenötigte Zeichenketten zu löschen (Garbage Collection). Dies wird allerdings möglichst vermieden, weil es dazu kommen kann, dass bei jedem Aufruf eines Unterprogramms immer wieder gleichlautende Zeichenketten erneut zugewiesen werden; fortgeschrittene Verwaltung registriert auch die Häufigkeit des Abspeicherns und löscht nur besonders selten benutzte und lange Zeichenketten.

Handelt es sich um eine Programmiersprache, in der ein Quelltext kompiliert und das Ergebnis in einer Objektdatei abgelegt wird, dann erhalten in ihrer Datensektion nach Auflösung aller Präprozessor-Operationen die resultierenden statischen Zeichenketten meist eine ähnliche tabellarische Verwaltung. Allerdings gibt es hier weder ein Löschen noch Referenzzähler. Diese Literale stehen auch der zentralen Zeichenkettenverwaltung nicht zur Verfügung, da bei dynamischer Einbindung nicht gesichert ist, dass diese Datensektion immer geladen ist.

Traditionell wurden zur Repräsentation eines einzelnen Zeichens 8 bit entsprechend einem Byte verwendet, was bis zu 256 verschiedene Zeichen ermöglicht. Um gleichzeitig Zeichen vieler Fremdsprachen und vor allem auch nichtlateinischer Schriften wie etwa Griechisch verarbeiten zu können, reicht das nicht aus.

Mittlerweile sehen die Programmiersprachen für die Speicherung eines einzelnen Zeichens 2 Byte oder 4 Byte vor; konsequenterweise vermeidet man heute in diesem Zusammenhang das Wort "byte" und spricht allgemein von "char".

Unter Microsoft Windows sind alle Systemfunktionen, die Zeichenketten verwenden, in einer Version mit nachgestelltem codice_10 (für ANSI, meint 1 Byte nach ISO 8859) verfügbar sowie mit nachgestelltem codice_11 (für "wide", Multibyte). Einfacher ist es aber, dies gar nicht explizit anzugeben: Kompiliert man ein Programm mit der entsprechenden Option, so werden automatisch alle neutralen Funktionsaufrufe auf 1 Byte/Zeichen oder auf Multibyte umgestellt. Genauso gibt es für die Programmiersprachen C++ und C Präprozessor-Makros, mit deren Hilfe sämtliche Standardfunktionen und Literale in einer unbestimmten Version im Quelltext notiert werden können; bei der Kompilierung wird dann die gerade angemessene Funktion eingesetzt. Per Definition verarbeiten die historischen Standardfunktionen in C immer genau 1 Byte/Zeichen.

Intern ist es inzwischen in praktisch allen aktuellen Programmiersprachen üblich, mehrere Bytes für ein Zeichen zu verwenden und darin die größeren Zahlen nach UCS („Unicode“) abzulegen.

In der Kommunikation nach außen und beim Abspeichern in Dateien ist hingegen eine Mischform gebräuchlich. Um in Dateien und bei der Datenfernübertragung Platz und Übertragungszeit zu sparen, werden vorwiegend aus lateinischen (englischen) Buchstaben bestehende Texte mit 1 Byte/Zeichen notiert. Ist die Kodierung kleiner als 128 (ein „ASCII-Zeichen“), wird das Zeichen verwendet wie es ist. Hat das Byte dagegen einen Wert ab 128, so wird dies als Beginn einer aus mehreren Bytes bestehenden Sequenz interpretiert, die ein einzelnes Zeichen repräsentiert. Das standardisierte Format hierfür ist UTF-8 (dazu auch UTF-16). Werden solche Zeichen angetroffen und sind für die interne Repräsentation mehrere Bytes verfügbar, sollte so früh wie möglich (während des Einlesevorgangs) die Dekodierung erfolgen, da später nicht mehr zu unterscheiden ist, wie diese Sequenz gemeint war. Dieselbe Technik wird auch angewendet, um URL zu kodieren; das Wikilink codice_12 führt auf „codice_13“.

Eine proprietäre Zwischenform war in den 1990er Jahren auf Systemen von Microsoft unter dem Namen „Multibyte Character Set“ gebräuchlich. Hier wurden verschiedene Formate und Kodierungen/Dekodierungen eingesetzt, um der Problematik abzuhelfen, mit 1 Byte/Zeichen auch asiatische Schriften abdecken zu müssen. Mittlerweile wird dies zwar noch nach außen unterstützt; interne Darstellungen und Entwicklungen verwenden es allerdings nicht mehr, sondern benutzen Unicode.

Die Basisoperationen mit Zeichenketten, die in fast allen Programmiersprachen vorkommen, sind Länge, Kopieren, Vergleichen, Verketten, Bilden von Teilketten, Mustererkennung, Suchen von Teilketten oder einzelnen Zeichen.

Zum Kopieren von Zeichenketten wird in vielen höheren Programmiersprachen der Zuweisungsoperator (meist „=“ oder „:=“) benutzt. In C wird das Kopieren mit der Standardfunktion codice_14 oder codice_15 durchgeführt.
Wie zeitaufwendig das Kopieren ist, hängt stark von der Repräsentation der Zeichenketten ab. Bei einem Verfahren mit Referenzzählern besteht das Kopieren nur aus dem Erhöhen des Referenzzählers. In anderen Verfahren muss eventuell die Zeichenkette alloziert und komplett kopiert werden.
Das Vergleichen von Zeichenketten auf gleich und ungleich wird von vielen höheren Programmiersprachen mit den Operatoren „=“ oder „<>“ bzw. „!=“ unterstützt. In einigen Sprachen wie Pascal lässt sich zudem ein lexikographischer Vergleich mit „<“ und „>“ durchführen. Sind diese Operatoren nicht vorhanden, werden Funktionen genutzt. Bei der Standardfunktion codice_16 in C gibt es drei Ergebnisse: gleich, größer oder kleiner. Dabei hat das erste Zeichen die höchste Wertigkeit.
Es gibt aber auch kompliziertere Vergleichsfunktionen, die Groß-/Kleinbuchstaben, Einordnung von Umlauten usw. berücksichtigen. Beim Suchen in Wörter- und Telefonbüchern spielt dies eine Rolle.

Zum Verketten gibt es in vielen Programmiersprachen Operatoren wie „+“ (BASIC, Pascal, Python, Java, C++), „&“ (Ada, BASIC), „.“ (Perl, PHP) oder „||“ (REXX). In C gibt es dafür die Funktion codice_17.

Um an eine bereits bestehende Zeichenkette eine andere anzufügen, stellen einige Sprachen einen eigenen Operator zur Verfügung („+=“ in Java und Python, „.=“ in Perl und PHP). Dabei wird üblicherweise der Operand nicht einfach hinten angefügt, sondern der Ausdruck "alt"+"neu" ausgewertet und der Variablen "alt" zugewiesen, da Strings in der Regel als unveränderlich betrachtet werden; es handelt sich also nur um eine abkürzende Schreibweise. Es gibt jedoch in vielen modernen Programmiersprachen, wie Java, C-Sharp oder Visual Basic .NET sogenannte "String-Builder-Klassen", die veränderbare Strings darstellen. Allerdings lassen sich String und String-Builder in der Regel nicht gegenseitig austauschen, sondern müssen ineinander umgewandelt werden.

Direkt (mit oder ohne Whitespace) hintereinander notierte Strings werden in manchen Sprachen implizit verkettet (C, C++, Python, REXX).

Um eine Teilkette zu erhalten, gibt es verschiedene Möglichkeiten.
Durch die Angabe von ("Zeichenkette", "Startindex", "Endindex") bzw. ("Zeichenkette", "Startindex", "Länge") kann eine Teilkette eindeutig definiert werden.
Diese Operation heißt häufig codice_18.
Einige Programmiersprachen, zum Beispiel Python, bieten syntaktischen Zucker für diese Operation an (siehe Beispiele).

In Oracle sind in gespeicherten Prozeduren, Funktionen und PL/SQL-Blöcken folgende Basisoperationen möglich:

DECLARE
BEGIN
END;

 text$ = "FRANK"

Das nachgestellte Dollarzeichen gibt an, dass es sich um eine Zeichenkettenvariable handelt. Da ein String durch Anführungszeichen begrenzt wird, können sie selbst nur über die codice_19- bzw. codice_20-Funktion in den String eingebaut werden, die 34 ist der ASCII-Code des Anführungszeichens.

Mehrere Zeichenketten können (je nach BASIC-Dialekt) mit dem Pluszeichen oder mit dem Kaufmanns-Und „&“ zu einer verbunden („konkateniert“) werden:

Dieses C-Programm definiert zwei Zeichenketten-Variablen, die jeweils 5 Zeichen „Nutzlast“ aufnehmen können. Da Zeichenketten mit einem Nullzeichen abgeschlossen werden, muss das Array 6 Zeichen haben. Anschließend wird in beide Variablen der Text „FRANK“ kopiert.

int main(void)

Um zwei Strings aneinanderzuhängen, existiert die Standardfunktion codice_17. Diese allozziert jedoch "nicht" den für den Zielstring notwendigen Speicherplatz. Dies muss vorher separat erfolgen.

int main(void)

String text1 = "FRANK";
String text2 = text1;
Zeichenketten in Java sind Objekte der Klasse String. Sie sind nach dem Erzeugen nicht mehr änderbar. Im obigen Beispiel repräsentieren "text1" und "text2" dasselbe Objekt.

Die Konkatenation von Zeichenketten wird durch den (für diesen Fall überladenen) Plus-Operator durchgeführt:

String text1 = "FRANK";
String text2 = "ENSTEIN";
String ganzerName = text1 + text2;

var vorname, nachname, name: string;
vorname := 'FRANK';
nachname := 'MEIER';
name := vorname + ' ' +nachname;

Bei PHP verhält es sich ähnlich wie bei Perl.
$text = "FRANK";

$text2 = $text; // $text2 ergibt "FRANK"

$text3 = «<HEREDOC
Ich bin ein längerer Text mit Anführungszeichen wie " oder '
HEREDOC;

Texte werden mit einem Punkt konkateniert.
$text = "FRANK";
$text = "FRANK" . "ENSTEIN"; // $text ergibt "FRANKENSTEIN"

$text = "FRANK";
$text .= "ENSTEIN"; // $text ergibt "FRANKENSTEIN"

In Rexx wird alles – einschließlich Zahlen – als String repräsentiert. So wird einer Variablen ein String-Wert zugewiesen: codice_22
Die folgenden Ausdrücke ergeben jeweils den Wert codice_23:


Angenommen, die Variable codice_27 enthalte die Zeichenkette codice_28. Dann lassen sich das erste Zeichen (codice_29), die ersten fünf Zeichen (codice_30), das siebte bis zehnte (codice_31) sowie die letzten vier (codice_32) wie folgt ermitteln:


Dieses Verfahren wird "Slicing" genannt (von engl. „to slice“ mit der Bedeutung „in Scheiben schneiden“ bzw. „aufteilen“). Das erste Zeichen hat den Index 0.


Rexx kann Strings auch wortweise verarbeiten, wobei Wörter durch (beliebig viele) Leerzeichen getrennt werden. Das erste Zeichen hat, wie bei Pascal-Strings, den Index 1.


Dieses Verfahren wird "Tokenizing" genannt (von engl. „token“ mit der Bedeutung „Kürzel“ oder „Spielstein“ und meint hier etwa „Stück“ oder „Bröckchen“) und ist auch in anderen Sprachen eine Standardfunktion.



Mittels der Unit StrUtils:

Verschiedene Algorithmen arbeiten vorwiegend mit Zeichenketten:

Heute schreibt ein Programmierer diese Art Algorithmen meist nicht mehr selbst, sondern benutzt Konstrukte einer Sprache oder Bibliotheksfunktionen.

Immer dann, wenn Zeichenketten aus der Außenwelt in die innere Repräsentation übernommen werden, sollten besondere Vorkehrungen getroffen werden. Neben unerwünschten Steuerzeichen und der Formatierung ist vor allem die maximale Länge der Zeichenkette zu überprüfen.

"Beispiel:" Eine internationale Telefonnummer soll aus einer Datei eingelesen werden. Sie soll ausschließlich Ziffern enthalten und durch ein Tabulatorzeichen (ASCII 9) von der Anschrift abgetrennt werden. Für die Aufnahme ist eine Zeichenkette fester Länge mit 16 Zeichen vorgesehen; dies reicht für alle gültigen Telefonnummern aus. – In den Eingabedaten könnten Leerzeichen oder Bindestriche enthalten sein und die Telefonnummer verlängern. Auch wenn versehentlich statt TAB ein genauso aussehendes Leerzeichen folgt, ergeben sich mehr als 16 Zeichen.

Wird dies nicht durch geeignete Prüfungen kontrolliert und darauf angemessen reagiert, kommt es zum Pufferüberlauf und möglicherweise zum Absturz des Programms oder zu mysteriösen Folgefehlern.

Zur häufigsten Angriffsmethode auf Webserver zählen Pufferüberläufe. Dabei wird versucht, einer Zeichenkettenvariablen einen Inhalt zuzuweisen, dessen Länge die Länge der Variablen übersteigt. Hierdurch werden andere, benachbarte Variablen im Speicher überschrieben. Bei geschickter Ausnutzung dieses Effekts kann ein auf einem Server laufendes Programm manipuliert und für Angriffe auf den Server missbraucht werden. Es reicht aber schon, die Server-Software so zum Absturz zu bringen; da sie die Netzverbindung bewachen soll („Gateway“), reißt ihr Ausfall eine Lücke, die einen schwach gesicherten Server nun schutzlos jeder Manipulation überlässt.

Soweit nicht in überschaubarer Umgebung bereits die Gültigkeit überwacht wurde, sollten Zeichenketten-Operationen nur mit Funktionen durchgeführt werden, bei denen die maximale Länge der Zeichenkette überprüft wird. In C wären das Funktionen wie z. B. codice_59, codice_60, … (anstelle von codice_14, codice_62, …).



</doc>
<doc id="5804" url="https://de.wikipedia.org/wiki?curid=5804" title="Zehn Gebote">
Zehn Gebote

Die Zehn Gebote, auch Zehn Worte () oder Dekalog () genannt, sind eine Reihe von Geboten und Verboten (hebr. Mitzwot) des Gottes Israels, JHWH, im Tanach, der Hebräischen Bibel. Diese enthält zwei leicht unterschiedliche Fassungen. Sie sind als direkte Rede Gottes an sein Volk, die Israeliten, formuliert, und fassen seinen Willen für das Verhalten ihm und den Mitmenschen gegenüber zusammen. Sie haben im Judentum und Christentum zentralen Rang für die theologische Ethik und haben die Kirchen- und Kulturgeschichte Europas und des außereuropäischen Westens mitgeprägt.

Vom Dekalog gibt es je eine Fassung im 2. Buch Mose (Exodus) und im 5. Buch Mose (Deuteronomium), die in Details voneinander abweichen:

Mit beginnt in der Tora die Sinai-Erzählung: Nach der Ankunft der aus Ägypten befreiten Israeliten am Berg Sinai beansprucht JHWH sie als sein erwähltes Bundesvolk, worauf sie Mose versprechen, alle Gebote Gottes zu erfüllen. Nach seiner Theophanie redet Gott auf dem Berg mit Mose. Davor und danach beauftragt er ihn, das Volk vom Betreten des Berges abzuhalten und so vor seinem tödlichen Anblick zu schützen. Zum Schluss richtet Mose die Warnung dem Volk aus („… und sagte es ihm.“). Der Satz lässt sich auch objektlos übersetzen („und sagte ihm:“): Dann würde Mose dem Volk die folgende Dekalogrede mitteilen, die er zuvor von Gott empfangen hätte.

Nach dem Bundesmahl der siebzig Ältesten redet erstmals von steinernen Tafeln, die Gott Mose allein übergeben werde. Nach den Anweisungen zum Bau der Stiftshütte (–) nennt zwei Steintafeln, die Gott mit seinem Finger beschrieben habe. Diese enthalten nach dem Kontext alle zuvor ergangenen Gebote, nicht nur den Dekalog. Nach habe Gott selbst die Tafeln gemacht und sie beidseitig beschrieben. Mose habe diese Tafeln im Zorn über Israels Abfall zerbrochen und in seinem Auftrag neue angefertigt, von denen es heißt ():

Vor der Landnahme der Israeliten kommt Mose in darauf zurück: Nach der Sinai-Theophanie habe Gott ihnen den Bund offenbart und sie verpflichtet, diesen in Form der „Zehn Worte“ zu halten. Dazu habe Gott diese auf zwei Steintafeln geschrieben. Das stellt erstmals die Identität von Ex 20,2–17 mit den „Zehn Worten“ und zwei Gebotstafeln heraus und betont ihren Rang als von Gott selbst geoffenbarte und aufgeschriebene Bundesurkunde.

In erinnert Mose das versammelte Volk daran, dass Gott seinerzeit auf dem Sinai (hier Horeb genannt) das Volk zwar laut und direkt angesprochen, dieses den Berg aber aus Furcht gemieden habe. Deshalb verkünde er, Mose, dem Volk seither Gottes Worte. Darauf wiederholt er die Dekalogrede als Vollzitat und bekräftigt dann, Gott selbst habe ebendiesen Wortlaut damals verkündet, unverändert auf die Gebotstafeln geschrieben und diese ihm gegeben . Nun erst erfuhr das Volk nach dem Gesamtduktus des Pentateuch also mündlich den Inhalt des schon offenbarten und verschrifteten Dekalogs. Nach legte Mose beide Steintafeln in die Bundeslade, die als bewegliches Heiligtum Gottes rettende Präsenz bei seinem Volk bis zur Zeit König Davids verbürgte (–; ).

Aus dieser erzählerischen Situierung ergaben sich Hauptfragen der Auslegung und Forschung:

Die Reihung wird in Ex 20,2 mit der im Tanach häufigen Theophanieformel „Ich bin JHWH“ eröffnet, die hier um die Zusage „dein Gott“ erweitert und auf die Tradition vom Auszug (Exodus) der Israeliten aus Ägypten (Ex 2–15) bezogen ist. Gott erscheint seinem Volk demnach nicht als Unbekannter, sondern erinnert es mit seinem Namen an seine frühere Befreiungstat, die seinen Willen bereits ausdrückte.

Gottes „Ich“ (hier in der betonten hebräischen Form "Anochi") erscheint als einzigartiger, alle anderen Ansprüche ausschließender Rechtsanspruch auf ein kollektives „Du“. Die Anrede gilt dem ganzen im Exodus aus Ägypten erwählten Gottesvolk Israel und jedem einzelnen Angehörigen dieses Volkes. Gottes Selbstoffenbarung in der Geschichte der Hebräer begründet hier sein Recht auf alle ihre Nachfahren. Darum schärft die Haggada zum Pessach dem gläubigen Juden ein: „In jeder Generation betrachte sich der Mensch, als sei er selbst aus Ägypten ausgezogen.“ Diese Exklusivität Gottes, die das angeredete Volk zu seinem Gegenüber macht und an seine Befreiungsgeschichte erinnert, ist eine Besonderheit des Judentums unter den altorientalischen Religionen. Damit ist das Volk Israel und sein Gottesverhältnis zugleich von allen anderen Völkern unterschieden, so dass der Fortsatz „Du sollst keine Götter neben mir“ [wörtlich: vor meinem Angesicht] „haben“ als logische Folgerung erscheint: „Nur für den, dem Gott sich so offenbart hat, gilt auch das folgende Gesetz.“

Der im Exodushandeln JHWHs für Israel implizierte Ausschluss fremder Götter ist im Alten Orient einmalig.

Das biblische Fremdgötterverbot wird sogleich im Bilderverbot konkretisiert, das nach beiden Dekalogversionen sowohl Abbildungen fremder wie des eigenen Gottes verbietet. Damit wird JHWHs Verehrung endgültig von allen anderen Kulten unterschieden. Denn dort wurden auch höchste und einzige Götter immer in Bildern dargestellt und verehrt, die ihre Kräfte vergegenwärtigten.

Gottesbilder wurden auch in Israels Nachbarschaft nicht mit dem abgebildeten Gott identifiziert und oft verhüllt, um die Transzendenz zu wahren. Doch das Bilderverbot stellt den unsichtbaren Gott gegen die im Bild greifbaren Götter, weil er für Israel der Schöpfer aller Dinge ist und sich vorbehält, wem und wie er sich offenbart. Diese Unabhängigkeit korrespondiert mit der Selbstbindung JHWHs an die Befreiung seines Volkes. Die Erinnerung an den Exodus sperrt sich dagegen, ihn nach Art fremder Götter zu verehren, die in der Regel Herrschaftsverhältnisse absegneten. Israels Gott will nicht im Kult repräsentiert, sondern im Sozialverhalten in allen Lebensbereichen verehrt werden.

In beiden Versionen erstreckt sich der Verbotsbereich auf Himmel, Erde und Unterwelt, also alle „Stockwerke“ des damaligen Weltbilds. Die deuteronomische Auslegung in bekräftigt das Verbot, Gott weder als Mann noch Frau noch Tier noch Gestirn darzustellen, wie es in den kanaanäischen Fruchtbarkeitskulten und babylonischen Astralkulten üblich war. Gläubige Juden können daher nichts in der Welt der geschaffenen Dinge als göttlich betrachten. Sie wurden darum im Hellenismus später als „Atheisten“ bezeichnet.

Da Gott sich für Juden von Beginn an durch sein – ebenfalls exklusiv gedachtes – Wort offenbarte , betrifft das Bilderverbot im Tanach nur optische und gegenständliche Abbilder, nicht Sprachbilder. Diese zeigen eine große Vielfalt an Metaphern, Vergleichen und Anthropomorphismen.

Ältere Vorformen wie gebieten mit dem Ausschluss anderer Götter zugleich die Zerstörung ihrer Kultstätten in Israel. Dies reagierte eventuell auf Gleichsetzungen JHWHs mit dem kanaanäischen Baal im Bild des Stiers , die hinter der Erzählung vom "Goldenen Kalb" in steht. Dieser Synkretismus wurde wohl seit dem Auftreten des Propheten Elija im Nordreich Israel als Übernahme von Wesenszügen Baals aufgefasst und abgelehnt . Auch Hosea kämpfte für das erste Gebot gegen die „Hurerei“ des Baalskultes (; ; ; ). Doch nach vergeblichen Anläufen von Hiskijas ließ erst König Josia die noch bestehenden Baalkultorte um 620 v. Chr. zerstören (). So wurde die alleinige Verehrung JHWHs innenpolitisch durchgesetzt.

Um sein Gewicht zu unterstreichen, wird das Bilderverbot nochmals mit einer ähnlichen Gottesrede wie der Präambel bekräftigt. Es bildet daher mit der exklusiven Selbstvorstellung JHWHs eine unauflösbare Einheit. Erst dadurch wird der indikativisch formulierte Zuspruch („Ich bin…“) zum ebenso verbindlichen Anspruch („Du sollst…“, wörtlich „Du wirst…“).

Auf die Gebote der Sabbat-Heiligung und des Ehrens der Eltern folgen eine Reihe von apodiktisch – begründungslos und kategorisch – formulierten Einzelverboten. Sie schließen ein bestimmtes Verhalten generell aus, ohne das positiv intendierte Verhalten festzulegen, erheben also Anspruch auf kollektive und zeitübergreifende Geltung. Dabei sind sie wörtlich als ermutigender Zuspruch formuliert („Du "wirst" nicht …“), drücken also ein unbedingtes Zukunftsvertrauen in den Adressaten aus.

Das unterscheidet sie von einer Vielzahl aus der alltäglichen Rechtsprechung stammender Gebote zu bestimmten Einzelfällen (Kasuistik). Solche „Wenn-dann“-Bestimmungen haben Vorbilder und Parallelen in der altorientalischen Umgebung Israels, beispielsweise im Codex Hammurapi.

William Sanford LaSor deutet die Sinaiperikope (Ex 20–24) als Gründungsurkunde des Bundes zwischen JHWH und dem Volk Israel. Der Dekalog ähnele einem damals üblichen Vertrag zwischen einem Großkönig und seinem Vasallen. Auch Lothar Perlitt sieht Parallelen zu hethitischen Staatsverträgen, die von den Israeliten nachgeahmt worden seien. Er schließt daraus ein hohes Alter des Textes.

Folgende Ähnlichkeiten findet LaSor:


Hieraus folgert LaSor, dass der Dekalog nie als Moralkodex konzipiert war, sondern als Verordnung, die das Bundesverhältnis regelt und als Grundvoraussetzung der gnädigen Zuwendung Gottes zum Volk Israel gesetzt wurde. Halte sich das Volk nicht an diese Gebote, breche es folglich den Bund und höre in gewissem Sinne auf, Gottes Volk zu sein. Aus diesem Zusammenhang lasse sich auch die weitere Geschichte Israels verstehen. Das Volk entferne sich immer wieder von JHWH; dieser leite dann eine Art Gerichtsverfahren ein, indem er zuerst die Propheten sende, die das Volk letztmals zur Umkehr rufen und ihm das drohende Gericht ankündigen. Erst danach lasse er seinen Fluch über das Volk kommen.

Die Zehn Gebote sind in einem jahrhundertelangen Prozess entstanden und zusammengewachsen. Sie waren anfangs nur eine von mehreren formal wie inhaltlich verwandten Gebotsreihen, die JHWHs Willen zusammenfassten: , ,  – ein sogenannter Dodekalog (Zwölfwort), eventuell bezogen auf die Zwölf Stämme Israels – und . Auch die beiden Dekalogvarianten enthalten je zwölf Einzelforderungen, die aber schon innerhalb der Tora als „Zehnwort“ bezeichnet und entsprechend eingeteilt wurden. Die älteste bekannte Bibelhandschrift zum Dekalog, der "Papyrus Nash" (um 100 v. Chr.), bezeugt einen Mischtext aus Ex 20 und Dtn 5. Demnach war der Dekalog damals noch nicht endgültig formuliert, sondern wurde bis zum Abschluss des jüdischen Bibelkanons (um 100 n. Chr.) weiterentwickelt.

Die ersten drei Gebote (nach lutherischer und katholischer Zählung) sind als direkte Gottesrede formuliert und ausführlich begründet (Ex 20,2–6). Die folgenden knappen und unkonditionalen Einzelweisungen (Ex 20,7–17) reden von Gott in der dritten Person. Beide Teile entstanden daher wohl unabhängig voneinander, wurden nachträglich miteinander verknüpft und zuletzt gemeinsam unter Gottes einleitende Selbstvorstellung gestellt. Erst dadurch erhielten die „Prohibitive“ (unbedingt ausschließende Verbote), deren persönliche Anredeform im altorientalischen Recht verbreitet war, den Charakter eines gesamtisraelitischen Bundesrechts.

Ähnliche Selbstvorstellungen JHWHs (; ) und Kritikreihen am Maßstab der Sozialgebote (; ) findet man in der Prophetie im Tanach. Darum wird eine Vorform des Dekalogs, die das erste Gebot mitsamt dem Ausschluss anderer Götter und einige weitere Gebote enthielt, spätestens in das 8. Jahrhundert v. Chr. datiert. Die einzelnen Sozialgebote stammen aus nomadischer Zeit (1.500–1.000 v. Chr.) und reflektieren deren Verhältnisse: etwa das Verbot, Vieh, Sklaven und Frau des Nächsten zu begehren. Sie wurden aus vielen ähnlichen Weisungen an Sippenangehörige gezielt ausgewählt, um Gottes Willen so allgemeingültig wie möglich zusammenzufassen.

Da Ex 20 den Erzählfaden der Tora unterbricht, während Dtn 5 die vorangehende und folgende Moserede verbindet, waren die Zehn Gebote als selbständige Einheit in verschiedenen Zusammenhängen zitierbar. Nach Lothar Perlitt wurde diese Einheit von den Autoren des deuteronomistischen Geschichtswerks im 7. Jahrhundert v. Chr. geschaffen. Doch die Exodusversion des Sabbatgebots spielt auf an, das zum priesterschriftlichen Schöpfungsbericht gehört: Demnach wurden die ersten drei Gebote wahrscheinlich erst ab dem Babylonischen Exil (586–539 v. Chr.) vor eine schon bestehende Verbotsreihe gestellt. Erst die Abschlussredaktion der fünf Bücher Mose stellte die bestehende Reihe beide Male den folgenden Gesetzeskorpora voran.

Dies gab den Zehn Geboten ihre überragende Bedeutung als lebensnotwendige Grundregeln für alle Lebensbereiche in der weiteren Geschichte von Juden- und Christentum. Sie gelten gläubigen Juden und Christen als Kern und Konzentrat der Offenbarung Gottes an Mose, den zum Führer Israels berufenen Empfänger und Vermittler seines Willens für das erwählte Gottesvolk.

Für die Gebote der Kulttafel gibt es keine außerbiblischen Parallelen. Dagegen wurden die sozialen Gebote des Dekalogs mit außerbiblischen Texten wie dem „Negativen Sündenbekenntnis“ (Kapitel 125 im "Ägyptischen Totenbuch", um 1500 v. Chr.) verglichen, das dem Bericht des Porphyrios über das ägyptische Totengericht zugrunde lag: „Ich habe die Götter, die meine Eltern mich gelehrt haben, verehrt alle Zeit meines Lebens, und jene, die mir das Leben geschenkt haben, habe ich immer in Ehren gehalten. Von den anderen Menschen aber habe ich keinen getötet und keinen eines mir anvertrauten Gutes beraubt noch sonst ein nicht wiedergutzumachendes Unrecht begangen…“ Die hier indirekt vorausgesetzten Regeln und ihre Abfolge (Götter verehren, Vater und Mutter ehren, nicht töten, nicht rauben, kein sonstiges Unrecht begehen) verglich schon John Marsham, ein Bibelexeget des 17. Jahrhunderts, mit dem Dekalog. Frühere Alttestamentler verglichen diesen direkt mit den im Totenbuch gelisteten 42 Verfehlungen. Weil dieses keine Parallelen zum Gebot der Alleinverehrung, der Sabbatruhe und Bilderverbot enthält, seine Textform anders ist und in magischen Zusammenhängen steht, sehen heutige Wissenschaftler wie der Ägyptologe Jan Assmann und der Alttestamentler Matthias Köckert darin kein Vorbild für den Dekalog und die JHWH-Religion.

Ex 20,2–17 nennt weder Gebotszahl noch Gebotstafeln; ihre Identität mit den „Zehn Worten“ ergibt sich aus ; und . Die doppelt überlieferte Dekalogrede enthält jedoch elf Verbots- und zwei Gebotssätze, wobei Fremdgötter-, Bilder- und Verehrungsverbote sowie Arbeits- und Ruhegebot als thematische Einheiten erscheinen. Daraus entwickelten sich schon seit etwa 250 v. Chr. verschiedene Versuche, die Rede in zehn Einzelgebote einzuteilen und so die biblische Zehnernorm zu wahren. Die Zehnzahl war auch eine Lern- und Merkhilfe, da man die Gebote so an den Fingern abzählen konnte, und in magischer Zahlensymbolik bedeutsam.

Auch veranlassten die biblisch überlieferten Gebotstafeln wohl schon vor der Zeitenwende eine Zweiteilung des Dekalogs, meist in eine auf das Verhalten zu Gott bezogene „Kulttafel“ (Selbstvorstellung bis Sabbatgebot) und eine auf das Verhalten untereinander bezogene „Sozialtafel“ (Elterngebot bis Begehrensverbote).

Juden zählen JHWHs Selbstvorstellung im ersten Satz gemäß dem Anfang des Gebets Schma Jisrael als erstes, die beiden Folgesätze gemeinsam als zweites Gebot. Sie folgen damit dem Talmud, der nicht zwischen Fremdgötter- und Bilderverbot unterschied, sondern gemäß die Verehrung von in Kultbildern dargestellten Fremdgöttern verbietet. Orthodoxe, Reformierte und Anglikaner dagegen orientieren sich an Ex 20 und trennen Fremdgötter- und Bilderverbot, so dass letzteres auch Bilder des eigenen Gottes verbietet. Sie fassen aber wie Juden die Verbote, eine andere Frau und fremde Güter zu begehren, als ein Gebot zusammen.

Katholiken und Lutheraner zählen Selbstvorstellung, Fremdgötter- und Bilderverbot als gemeinsames erstes Gebot. Damit lassen sie das Bilderverbot allenfalls für den eigenen Gott gelten; vielfach wurde es als für Christen ungültig vernachlässigt. Um die Zehnzahl zu bewahren, unterteilen sie das Verbot des Begehrens in zwei Verbote. Die Katholiken nennen wie Dtn 5 die Frau zuerst und für sich die Lutheraner wie Ex 20 das Haus.
Bis 70 wurde der Dekalog täglich im Jerusalemer Tempel verlesen. Er war nach einigen Schriftrollen vom Toten Meer sowie samaritanischen Inschriften auch Teil der Tefillin.

Philon von Alexandria verfasste um 40 den Traktat "De decalogo". Er verstand ihn als einzige direkte Offenbarung Gottes und teilte ihn in zweimal fünf Gebote ein, um so eine Analogie zu den „ewigen Ideen“ Platons und zehn Kategorien des Aristoteles herzustellen. Sie waren für ihn „Hauptpunkte“ (Grundprinzipien) aller Toragebote, ja aller Gesetze überhaupt, die er in zehn jedem Dekaloggebot zugeordnete Themengruppen einteilte.

Das Rabbinat lehnte um 100 einen solchen Vorrang des Dekalogs und darum auch seine tägliche Lesung ab, nachdem „Minim“ (gemeint waren eventuell auch Christen) behaupteten: Am Sinai habe Gott nur den Dekalog offenbart, alle übrigen Gebote müssten nicht unbedingt befolgt werden. Dennoch blieb dieser nach Fragmenten aus der Geniza von Kairo Teil des täglichen privaten jüdischen Morgengebets, wo er bis heute rezitiert wird.

Im Talmud gesammelte rabbinische Exegese betont die besondere Wichtigkeit der ersten Gebote, in denen Gott in Ich-Form das Volk direkt anredet. Sie fasste Gottes Selbstvorstellung als eigenständiges erstes, Fremdgötter- und Bilderverbot gemeinsam als zweites und die Verbote des Begehrens gemeinsam als zehntes Gebot auf. So entspricht der Ehrung des einzigen befreienden Gottes die Absage an alle anderen Götter, die üblicherweise in Bildern verehrt wurden. Wichtige Auslegungen des Dekalogs waren die Midraschim "Mek", "PesR (21–24)" und "Aseret Hadibberot" (10. Jahrhundert). Umstritten war, ob die beiden überlieferten Gebotstafeln je eine Hälfte des Dekalogs oder beide den ganzen Text enthielten. Seit etwa 250 v. Chr. wurden die Dekaloggebote auf die Gottes- und die Nächstenliebe verteilt, die als gleichrangig eingeschärft wurden, so dass man Gott nur lieben könne, indem man die konkreten Sozialgesetze der Tora erfülle. Im siebten und zehnten Gebot sah man die übrigen impliziert, da ihr Bruch unweigerlich den Bruch der anderen Gebote nach sich ziehe.

Im Hochmittelalter wurden die Unterschiede des Wortlauts in Ex 20 und Dtn 5 spekulativ erklärt: Gott bzw. Mose hätten beide Versionen zugleich verkündet, beide seien daher gleichwertig. Für Abraham ibn Esra hatten die geringfügig verschiedenen Worte oder Buchstabenkombinationen in jedem Fall dieselbe Bedeutung; größere Zusätze in Dtn 5 erklärte er als von Mose ergänzte Erläuterungen. Nachmanides dagegen sah Ex 20 und Dtn 5 als dieselbe, von Mose überlieferte Gottesrede; vorausgegangen sei die in Ex 19,16–19 und Ex 20,18–21, gefolgt die in Dtn 5,22f. beschriebene Volksreaktion. In Ex 20 / Dtn 5 zählte Isaak Abrabanel 13 Einzelgebote und verstand die „zehn Worte“ nach Dtn 4,13; 10,4 daher als Redeabschnitte. Dies reflektierten die masoretischen Akzentsysteme: Infralineare Akzente unterteilten den Text in zehn, supralineare in 13 Einheiten. Erstere wurden eher für private, letztere für öffentliche gottesdienstliche Lesungen verwendet.

Saadia ben Joseph Gaon sah ähnlich wie Philo alle 613 Toragebote im Dekalog inbegriffen. Er beschrieb die Dekaloggebote poetisch als ihren Ursprung, indem er sie auf 613 Buchstaben von Ex 20 zurückführte. Er übernahm sie auch in die Gottesdienstliturgie des Schawuotfestes. Jehuda Hallevi nannte den Dekalog die „Wurzel des Wissens“. Josef Albo verstand die erste Tafel theologisch, die zweite ethisch, und beide zusammen als Hauptinhalt der Religion. Abraham bar Chija und ähnlich Samuel David Luzzatto teilten Dekalog und sonstige Toragebote in die drei Kategorien „Gott und Mensch“, „Mensch und Familie“, „Mensch und Mitmensch“ ein.

In der jüdischen Orthodoxie wird der Dekalog nur als Teil eines regulären Tora-Abschnitts und beim Schawuot-Fest verlesen, wobei die Gemeinde stehend zuhört. Dieser Praxis widersprach Maimonides: Die Menschen sollten nicht glauben, ein Teil der Tora sei wichtiger als andere. Das Reformjudentum führte die Dekaloglesung in den wöchentlichen Sabbat-Gottesdienst ein.

Im Neuen Testament werden die Zehn Gebote als allgemein bekannte und gültige Willenserklärung Gottes für alle Juden vorausgesetzt. Sie werden daher nirgends insgesamt wiederholt, sondern zu jeweils passenden Anlässen einzeln zitiert und gedeutet.

Jesus von Nazaret zitierte laut den synoptischen Evangelien öfter einzelne Dekaloggebote und legte sie aus. Nach knüpfte er an die im rabbinischen Judentum längst übliche Konzentration der ganzen Tora auf das Doppelgebot der Gottes- und Nächstenliebe an. Indem er die Nächstenliebe dem ersten Gebot gleichstellte, gab er ihr Vorrang vor allen Einzelgeboten.

Die als „Antithesen“ zusammengestellten Torapredigten der Bergpredigt (Mt 5–7) kommentieren die Dekaloggebote „morde nicht“ (Mt 5,21 ff.), „brich nicht die Ehe“ (Mt 5,27 ff.) und indirekt „rede kein Falschzeugnis“ (Mt 5,33 ff.) im Sinne dieses obersten Maßstabs: Sie verschärfen sie, indem sie schon die falsche innere Einstellung zum Nächsten als Bruch und Vergehen gegen Gott erklären. Schon Hass morde, schon ein begehrlicher Blick breche die Ehe, jeder Eid, nicht erst der Meineid vor Gericht wird verboten, da die Bekräftigung einer Aussage im Schwur impliziert, dass ohne sie die Aussage gelogen sein könnte. In der matthäischen Komposition der Bergpredigt folgen diese Auslegungen den „Seligpreisungen“ an das Volk der Armen. Diese treten somit an die Stelle der „Präambel“ des Dekalogs. Die unbedingte Zusage des Reiches Gottes an die Armen aktualisiert die Zusage „Ich bin JHWH, dein Gott, der dich aus Ägyptenland befreit hat“: Der vergangenen Befreiungstat Gottes entspricht eine kommende Befreiung und Herstellung von Gerechtigkeit für alle Armen, wie sie das Judentum vom Messias erwartet.

Die Zusammenstellung legt nahe, dass Jesus alle zehn Gebote je nach Situation mit einer Halacha mündlich auslegte. Ein ausdrücklicher Kommentar zum Fremdgötterverbot ist seine Predigt zum Vorratsammeln (). Das Anhäufen von Besitz und Reichtümern mache diese zum Götzen (Mammon) und stehe dem notwendigen Teilen mit den Armen entgegen. Damit widerspreche es der Liebe zu dem Gott, der die Armen liebt: „Wo dein Schatz ist, da ist dein Herz … Niemand kann zwei Herren dienen.“ Aus demselben Grund ordnete Jesus wie andere damalige Toralehrer nach das Sabbatgebot der Lebensrettung und dem Heilen von Menschen unter und erlaubte seinen Nachfolgern den Sabbatbruch bei akuter Lebensgefahr.

Nach verwies er einen reichen Großgrundbesitzer, der ihn nach den Bedingungen für seinen Eintritt in das Reich Gottes fragte, auf den Dekalog als gültigen Willen Gottes, den die Version Mt 19,18 f. mit dem Verweis auf das Gebot der Nächstenliebe ergänzt. Dem Fragenden fehle eins, um Gottes Reich zu erlangen: das Aufgeben allen Besitzes zu Gunsten der aktuell Armen (v. 21). Dies deutet das zehnte Gebot in gleichem Sinn wie das erste: Anhäufen und Festhalten von Reichtum sei Raub an den Armen. Was die Zehn Gebote negativ ausschließen, erhält durch Jesu Ruf in die Nachfolge eine positive Zielrichtung: Gottes endgültiger Wille sei nicht die Bewahrung einer bestehenden, sondern die Anbahnung einer neuen Ordnung, in der die Armen zu ihrem Recht kommen.

Das Gebot der Elternehrung hat Jesus nach relativiert: „Wer den Willen Gottes erfüllt, der ist für mich Bruder und Schwester und Mutter.“ Nach hat er es aber für Juden allgemein gelten lassen und gegen ungültige Gelübde, die die Eltern materiell belasteten, bekräftigt. Da zur Nachfolge Jesu das Aufgeben der familiären Bindungen gehörte, fordern frühe Aussendungsregeln aus der Logienquelle die Unterordnung der Eltern- unter die Gottesliebe () und sogar die Geringachtung der eigenen Verwandten gegenüber der Liebe zu Jesus ().

Für Paulus von Tarsus hat Jesus Christus als einziger Mensch Gottes Willen ganz erfüllt. Von seiner, nicht unserer Erfüllung hänge das Heil ab; wer die Tora weiterhin zum Heilsweg erkläre, leugne das Heil, das Gott mit Kreuz und Auferweckung Jesu für alle Menschen geschaffen habe (Galaterbrief). Wie für Jesus, so erfüllt auch für Paulus die Nächstenliebe alle Gebote der Tora ( und ) und hebt sie damit unter Umständen auf. Deshalb erhielten die Toragebote bei ihm einen neuen Stellenwert: Besonders die Kult- und Opfergebote, die als Konkretion des ersten und zweiten Gebots im Pentateuch breiten Raum einnehmen, spielten für Paulus keine entscheidende Rolle mehr. Kultische Reinheit vor Gott sei nicht durch menschliche Anstrengung zu erwerben, sondern durch den Sühnetod Jesu Christi letztgültig erworben worden.

Besonders im Römerbrief spielte Paulus auf die Sozialgebote des Dekalogs an (: siebtes und sechstes Gebot; : neuntes und zehntes Gebot). Indem er sie dem Gebot der durch Jesu Lebenshingabe erfüllten Nächstenliebe unterstellte, verallgemeinerte er sie: Die Liebe zum Anderen löse jedes „Begehren“ (ohne besonderes Objekt) ab. Denn diese Sünde habe Christi Weg ans Kreuz aufgedeckt (). Der Folgesatz („die Liebe tut dem Nächsten nichts Böses“) bezieht sich auf das Böse zurück, das die römische Staatsmacht den Christen zufügte und dem sie mit Gewaltverzicht, Wohltaten und Opferbereitschaft begegnen sollten: „Lass dich nicht vom Bösen überwinden, sondern überwinde das Böse mit Gutem!“ (). Darum sollten sich die verfolgten Christen den römischen Staatsbeamten unterordnen und ihnen Steuern zahlen (), sich aber nicht deren heidnischen Sitten anpassen, sondern im Vertrauen auf Gottes Endgericht innergemeindliche Solidarität üben (). Ihre Feindesliebe sollte die Zehn Gebote auch der heidnischen Umwelt als vernünftige Ethik nahebringen. Das war für Paulus möglich, weil Christus seinen Nachfolgern den Heiligen Geist geschenkt habe, der ihnen das „Gesetz des Lebens“ einpflanze und sie von allem bloßen Buchstabenglauben zur Liebe befreie ().

In begründet eine frühchristliche Haustafel die Mahnung an die Kinder, ihren Eltern zu gehorchen, mit dem vierten Gebot. begründet Gottes Erwählung der Armen mit dem Dekalog und mahnt die Christen: Der Bruch eines Einzelgebots breche bereits Gottes ganzen Willen. spielt im Rahmen einer Vision vom Endgericht auf das fünfte bis siebte Gebot an. Somit blieb der ganze Dekalog für die Urchristen gültig.

Altkirchliche Theologen wie Irenäus von Lyon, Justin der Märtyrer und Tertullian sahen eine inhaltliche Übereinstimmung des Dekalogs mit den wichtigsten ethischen Prinzipien, die der Mensch von Natur aus kenne. Sie begründeten damit eine Auslegungstradition, die den Dekalog mit dem Naturrecht identifizierte oder analogisierte.

Augustinus von Hippo dagegen verstand den Dekalog als Entfaltung des Doppelgebots der Gottes- und Nächstenliebe. Demgemäß wies er die ersten drei Gebote der Gottes-, die anderen sieben der Nächstenliebe zu. Nur durch die Liebe Christi habe sich der Fluch des Gesetzes, das die menschliche Sünde aufdecke, in eine Gabe der Gnade verwandelt, so dass der Dekalog zur Norm christlichen Lebens werden könne.

In der Scholastik wurde der Dekalog meist nicht als Ganzes ausgelegt, sondern einzelne Dekaloggebote im Rahmen einer Tugendlehre. Bei Petrus Lombardus und ausführlich bei Thomas von Aquin wurde der Dekalog zum Hauptbestandteil ihrer Lehre vom „Gesetz“ im Gegenüber zur Lehre von der Gnade.

Nach dem Konzil von Trient (1545–1563) wurde der Dekalog Grundlage für eine katholische Morallehre und Gewissenserforschung, zunächst zur Ausbildung von Beichtvätern. Er blieb fortan Gliederungsprinzip für verbindliche ethische Lebensregeln bzw. christliche Pflichten, wobei Verbote ein Übergewicht erhielten. Dabei wurden diese von ihrem historischen Entstehungskontext gelöst, so dass sie entweder als strenge unveränderliche Gesetze oder als zeitlose und damit beliebig zu befolgende allgemeine Normen erschienen.

Der Katholische Katechismus zitiert den ersten Satz, das Fremdgötter- und das Bilderverbot zusammen als erstes Gebot.

Im Katechismus der Katholischen Kirche (KKK, 1. Auflage 1992) steht zwischen den Absätzen 2330 und 2331: „Du sollst nicht die Ehe brechen.“ Nach KKK 2351 werden Unkeuschheit und in 2352 Masturbation als ungeordnet bzw. unreif beschrieben.

Martin Luthers Großer Katechismus beginnt mit dem Fremdgötterverbot, das für sich als erstes Gebot erscheint. Dann schließt als zweites Gebot das Verbot des Namensmissbrauchs an. Sein Kleiner Katechismus dagegen zitiert Selbstvorstellung und Fremdgötterverbot gemeinsam als erstes, das Verbot des Namensmissbrauchs als zweites Gebot. Das Bilderverbot nennt Luther weder im Großen noch im Kleinen Katechismus direkt. Lutheraner folgen Ex 20 und unterscheiden innerhalb des Verbotes, fremden Besitz zu begehren, zwischen dem erstgenannten „Haus“ und den übrigen Gütern, zu denen die „Frau“, Knechte und Tiere gehören.

Anglikaner und Reformierte folgen wie die Juden der Exodusversion des Dekalogs. Sie sehen Gottes Selbstvorstellung als „Präambel“ gegenüber allen folgenden Geboten. Die Reformierten und die Siebenten-Tags-Adventisten trennen Fremdgötter- und Bilderverbot. Deshalb fehlen bei ihnen alle Bilder, nicht nur Götterbilder im Gottesdienstraum. Anglikaner und Reformierte beziehen das zehnte Gebot auf das „Haus“ des Nächsten, das im biblischen Sprachgebrauch auch allen familiären Anhang und Besitz umfasste.
Die Pfingstbewegung, die charismatische Bewegung, evangelikale und freikirchliche Christen betonen, dass sich die Zehn Gebote nur ganz oder gar nicht befolgen lassen. Sie lehnen damit eine „säkulare“, nur an den Sozialgesetzen interessierte Übernahme ohne Glauben an den, der laut Bibel die Gebote erlassen hat und ihre gesamte Befolgung verlangt, ab. Damit geht jedoch auch ein gewisser Konservatismus bei der Ausdeutung einzelner Gebote einher.

Die Liberale Theologie betonte im Anschluss an eine spiritualisierende Deutung der Bergpredigt oft, es komme bei allen Geboten weniger auf den Wortlaut als auf die innere Einstellung an. Damit wurde die konkrete Befolgung der Dekalogforderungen tendenziell beliebig.
In der Neuzeit wurde der Dekalog als überzeitliches Kulturerbe und Grundlage autonomer, das heißt durch eigene Einsicht begründeter Ethik aufgefasst und in allgemein einsehbare Vernunftregeln wie den Kategorischen Imperativ übersetzt. Außerhalb der christlichen Kirchen werden die zehn Gebote in Europa oft als „ethisches Minimum“ aufgefasst, wobei diese Einordnung eher an die auf den Mitmenschen bezogenen Gebote der Sozialtafel anknüpft als an die Kulttafel mit ihrem besonderen Gottesbezug. Zudem kennt nur noch eine Minderheit der westeuropäischen Bevölkerung ihren Wortlaut, während sie Christen in den USA und in einer Minderheitssituation (Diaspora) oft gut vertraut sind.
In der Zeit des Nationalsozialismus waren die Zehn Gebote manchmal Basis für kirchlichen Widerspruch zu gesellschaftlichen Entwicklungen. So veröffentlichten die deutschen katholischen Bischöfe am 12. September 1943 einen „Hirtenbrief über die Zehn Gebote als Lebensgesetz der Völker“, in dem sie gegen damalige Massenmorde der Nationalsozialisten protestierten:
Der Einfluss des Dekalogs auf die europäische Rechtsgeschichte ist noch wenig erforscht worden. Er bildet im biblischen Kontext eine Art Verfassungsentwurf einer volkhaften Gemeinschaft, die sich als durch eine innergeschichtliche Befreiungserfahrung konstituiert und darum ihrem Gott verpflichtet ansieht. Daraus leitet der Dekalog grundlegende Regeln für diese Gemeinschaft und jedes ihrer Mitglieder ab, die für jede Gesellschaftsform verbindlich bleiben sollen.

Vermittelt durch die Kirchengeschichte wirkte der Dekalog weniger gesellschaftsformierend, sondern eher individuell als Inbegriff sogenannter christlicher Tugenden weiter. Für direkte Einflüsse des Dekalogs auf materiales Recht gibt es daher nur wenige historische Beispiele: etwa die spätantike "Collatio legum Mosaicarum et Romanorum" (um 390), die römische Rechtssätze den Dekaloggeboten zuordnete, oder die mittelalterlichen Gesetze, die Alfred der Große (ca. 849–899) jeweils mit einer Paraphrase des zugehörigen Dekaloggebotes einleitete.

Schon der römische Kaiser Julianus stellte 363 heraus, dass die Gebote der „Kulttafel“ (Fremdgötterverbot, implizit Namensheiligung, und Sabbatgebot) nicht konsensfähig seien, während kaum ein Volk die übrigen Gebote ablehnen würde. Die neuzeitliche Rechtsgeschichte wurde als Versuch gedeutet, ebendiesen vernünftig einsehbaren Rechtskonsens herzustellen, ohne allgemein den Glauben an den Geber dieser für das Zusammenleben unaufgebbaren Grundregeln zu fordern. Heute stellen manche Alttestamentler und Historiker heraus, dass die modernen Menschenrechte zwar gegen den theokratischen Geltungsanspruch des Dekalogs formuliert und durchgesetzt wurden, gleichwohl aber in ihm angelegt und von ihm beeinflusst waren. So sei etwa die Verfassungstheorie des Theologen Emmanuel Joseph Sieyès in der Französischen Revolution von biblischem Recht mitbestimmt gewesen. Das spezifisch jüdische Sabbatgebot hatte in Form der allgemeinen gesetzlichen Sonntagsruhe konkrete rechts- und sozialgeschichtliche Folgen.

In den USA ist das Verhältnis von biblischer Rechtstradition zu den Grundprinzipien der US-Verfassung bis heute umstritten. Versuche von konservativen Christen, dem Dekalog öffentliche Aufmerksamkeit und Geltung etwa in staatlichen Behörden, Schulen, Gerichtsgebäuden zu verschaffen, zogen seit 1945 einige Musterprozesse und Grundsatzurteile des Supreme Court nach sich. Vertreter eines konsequenten Ausschlusses des Dekalogs aus der Öffentlichkeit ist etwa der Philosoph Harry Binswanger: Er sieht die ersten drei Gebote des Dekalogs als Aufforderungen zur Unterordnung, die sinnvolle Inhalte der Sozialgebote nicht vernunftgemäß begründen könnten, da dies dem Menschenrecht auf individuelle Selbstbestimmung widerspreche.

Thomas Mann schrieb 1943 in den USA auf Englisch eine Novelle für den Sammelband "The Ten Commandments", die er 1944 ins Deutsche übersetzte und unter dem Titel "Das Gesetz" in Stockholm veröffentlichte. Sie beschreibt die Entstehung der Zehn Gebote romanhaft als Anleitung zur Menschwerdung des Menschen: zitiert nach Karl-Josef Kuschel: "Weltethos aus christlicher Sicht" (April/Mai 2008)

Obwohl sie nur Israel anreden, seien sie „eine Rede für alle“, deren universale Geltung jeder Hörer unmittelbar verstehen könne. Mann stellte ihren Gegensatz zur nationalsozialistischen Barbarei heraus, die damals jedes allgemeine Fundament der Humanität und Moral außer Kraft zu setzen versuchte:
Der katholische Theologe Stephan Sigg hat 2011 ein Jugendbuch "„10 gute Gründe für Gott – Die 10 Gebote in unserer Zeit“" herausgegeben, das jungen Leuten die Zehn Gebote nahebringen möchte. Borromäusverein und Sankt Michaelsbund wählten das Buch als „religiöses Kinderbuch des Monats“ April 2011 mit der Begründung: „Die Geschichten sind mit viel Ironie, Humor, aber immer ohne pädagogischen Zeigefinger und belehrenden Unterton unterhaltsam erzählt. Mit ihren meist subtilen inhaltlichen Bezügen zu den Zehn Geboten provozieren sie den Leser zum Nachdenken.“

Im Roman Die Entdeckung des Himmels erzählt Harry Mulisch von einer Suche nach den Gesetzestafeln.


Gottes Übergabe der Steintafeln an Mose, selten mit der ganzen Tora (Ex 24,12), meist mit den Zehn Geboten (Ex 34,28), wurde seit dem 6. Jahrhundert ein Standardmotiv der christlichen Kunst, besonders in byzantinischer Ikonographie und in illustrierten Bibelhandschriften des Hochmittelalters, später auch in Druckwerken. Ein berühmtes Beispiel ist das Apsismosaik im Katharinenkloster (Sinai). Die meisten dieser Darstellungen typisieren Mose als demütigen Empfänger der Tafeln aus Gottes Hand, manchmal verbunden mit dem Motiv des brennenden Dornbuschs als Sinnbild seiner Berufung, während die Israeliten fast nie erscheinen. Oft wird ein Mosebild einem Bild Jesu Christi gegenübergestellt, so dass der Empfang des Dekalogs allen Völkern gelten und auf die Erfüllung der Tora durch den Sohn Gottes vorausweisen soll.

Lucas Cranach der Ältere schuf 1516 ein großes Wandbild für den Gerichtssaal in Wittenberg. Zehn Bildfelder zeigen die Relevanz je eines Gebots im Alltagsleben. Alle Teilbilder werden von einem Regenbogen überwölbt, der an die Bundeszusage von Gen 9 erinnert. Dies deutete den Dekalog als Universalgesetz Gottes für die vor dem Untergang gerettete Menschheit, auf dem alle konkrete Gesetzgebung und Rechtsprechung gründet.

Viele Künstler stellten die Zerschlagung der Gesetzestafeln durch Mose dar, darunter Raffael (Fresken in den Loggien des päpstlichen Palastes im Vatikan), Nicolas Poussin, Rembrandt (Moses zerschmettert die Gesetzestafeln), Julius Schnorr von Carolsfeld und Marc Chagall ("Moses zerbricht die Gesetzestafeln", 1955–1956). Die Übergabe der Gesetzestafeln stellten unter anderem Cosimo Rosselli in einem Wandgemälde der Sixtinischen Kapelle und wiederum mehrmals Chagall dar.

Die Dekalogtafeln in Hugenottenkirchen dienten oft als Ersatz für bildliche Darstellungen.

In antijudaistischen Skulpturen der Ecclesia und Synagoge in und an Kirchen des Hochmittalters wird die Figur der Synagoge mit verbundenen Augen und Gesetzestafeln dargestellt.

Die Stadt Bremen ließ um 1890 die Zehn Gebote als Mosaiken an der Außenfassade des Bremer Landgerichtsgebäudes unterhalb der Fensterbrüstungen des Saales anbringen, in dem das Schwurgericht tagte. Die Nationalsozialisten verboten die Schriftbilder, worauf Bremer Bürger sie mit Steintafeln verdeckten, statt sie wie verlangt zu zerstören.

In Austin, Texas, wurden in den 1960er Jahren Stelen mit den Zehn Geboten vor dem Parlamentsgebäude aufgestellt. Während ähnliche Monumente vor Gerichtsgebäuden in den USA in den meisten Bundesstaaten aufgrund der verfassungsgemäßen Trennung von Religion und Staat verboten und entfernt wurden, befand der "Supreme Court" in diesem Fall, die Stelen könnten als allgemeines historisches Kunstwerk stehen bleiben.

Das Thema der biblischen Zehn Gebote wurde mehrfach verfilmt. Cecil B. DeMille war Regisseur von zwei Monumentalfilmen: Die Zehn Gebote (1923) und Die zehn Gebote (1956). Das Fernsehen verfilmte diesen Filmstoff neu: Die Zehn Gebote (2006). Krzysztof Kieślowski schuf den zehnteiligen Filmzyklus "Dekalog", der jedes Einzelgebot mit einer Gegenwartsgeschichte aktualisierte. Er schrieb zudem mit Krzysztof Piesiewicz das Drehbuch für ein Theaterstück dazu. 2007 erschien die Filmkomödie "Das 10 Gebote Movie" als Parodie auf die Zehn Gebote.


Überblick

Bibelwissenschaft

Judentum


Christentumsgeschichte

Theologische Ethik

Gegenwartsbezogene Auslegungen

Kunst
Literatur

Musik



</doc>
<doc id="5806" url="https://de.wikipedia.org/wiki?curid=5806" title="Zeus">
Zeus

Zeus (, klassische Aussprache ungefähr „“; bzw. "Dias"; ) ist der oberste olympische Gott der griechischen Mythologie und mächtiger als alle anderen griechischen Götter zusammen. Über ihm stand nur das personifizierte Schicksal – seine Töchter, die Moiren. Auch er hatte sich ihnen zu fügen.

Der Name entspringt derselben indogermanischen Wortwurzel *"diu" („hell“, „Tag“), die im lat. Iuppiter und dem vedisch-altind. "Dyaúh pitá" „Vater Himmel“ enthalten ist. Sie ist Ausdruck eines gemeinsamen indogermanischen Gottesbildes und von den jeweiligen Wörtern für „Gott“ abgeleitet; z. B. lat. "deus", germ. *"Tiwaz" und vedisch-altind. "devá".

Zeus ist ein Sohn des Titanenpaares Kronos und Rhea (daher auch der Beiname bzw. Patronym: "Kronion" – , "Kronides" – ) und Bruder von Hestia, Demeter, Hera, Hades und Poseidon. Nach Hesiod verschlingt Kronos alle seine Kinder gleich nach der Geburt, da er fürchtete, diese könnten ihn entmachten, so wie er selbst seinen Vater Uranos entmachtet hatte. Als Zeus geboren werden sollte, beschließt Rhea auf den Rat von Gaia und Uranos hin, ihn im Verborgenen auf die Welt zu bringen. Sie geht dazu in eine Höhle bei der Stadt Lyktos auf Kreta, woraufhin der neugeborene Zeus von Gaia versteckt wird. Kronos gibt sie anstatt Zeus einen in eine Windel gewickelten Stein, den er verschlingt. Nach anderen Überlieferungen liegt der Geburtsort des Zeus in einer Höhle des Berges Dikti oder des Ida, wo er von den Nymphen Adrasteia und Ide aufgezogen, von der Ziege Amaltheia versorgt und von den Kureten beschützt wird. Seinen Beinamen Idaios verdankt er dieser Variante des Mythos. (Näheres unter "Ammen des Zeus".)

Er wächst nach Hesiod schnell heran und bringt mit List und unter Mithilfe Gaias den Kronos dazu, zuerst den Stein und dann alle seine verschluckten Kinder wieder auszuwürgen. In der "Bibliotheke des Apollodor" wendet Zeus sich an Metis, die Kronos eine Droge verabreicht, welche ihn zum Speien bringt.

Als Herrscher der Götterversammlung wird Zeus bereits bei Homer dargestellt, jedoch ohne einen erläuternden Mythos.
Nach Hesiod müssen Zeus und seine Geschwister ihren Vater Kronos sowie die riesigen Titanen bekämpfen, um die Herrschaft über die Welt zu erringen. Sie kämpfen vom Olymp aus gegen die Titanen, die sich auf dem Othrys verschanzt haben. Als der Kampf nach zehn Jahren noch nicht entschieden ist, rät Gaia ihm, die im Tartaros gefangen gehaltenen Geschwister der Titanen, die Kyklopen und Hekatoncheiren, zu befreien. Von den Kyklopen erhält er Blitz, Zündkeil und Donner als Waffen, die Hekatoncheiren stehen ihm kämpfend zur Seite. Die Titanen werden von den Göttern besiegt und in den Tartaros verbannt, die Hekatoncheiren werden zu deren Wächtern. Den Göttern wird von Gaia geraten, Zeus zu ihrem Herrscher zu machen. Dieser teilt die Welt in drei Reiche ein: Zeus selbst beherrscht den Himmel, Poseidon das Meer und Hades die Unterwelt.

In der "Bibliotheke" muss Zeus zuerst die Kampe erschlagen, um die Kyklopen und Hekatoncheiren zu befreien. Zudem erhalten auch Hades und Poseidon Waffen von den Kyklopen, die sich auch aktiv am Kampf beteiligen.

Über das Schicksal von Kronos gibt es viele verschiedene Versionen. Homer und andere Texte berichten davon, dass er mit den anderen Titanen im Tartaros gefangen wird. Orpheus beschreibt in seinen Geschichten, dass Kronos bis zur Unendlichkeit in der Höhle von Nyx gefangen gehalten wird. Pindar berichtet von der Entlassung Kronos’ aus dem Tartaros und dass Zeus ihn zum Herrscher des Elysion machte.

Die Herrschaft der olympischen Götter unter Zeus wurde durch einen Angriff der Giganten bedroht. In der Gigantomachie aber besiegten die Götter die Giganten.

Der Schild des Zeus heißt Aigis oder Ägis (griech. Ziegenfell). Dieser wurde von Hephaistos geschmiedet und wird meist als schuppen- und schlangenbewehrter Halskragen dargestellt. Die Aigis ist Sinnbild der schirmenden Obhut (Ägide) der Götter.

Verheiratet war Zeus mit seiner Schwester Hera, mit der er vier Kinder hatte, Ares, Hebe, Eileithya und Hephaistos. Aber er hatte auch viele Liebschaften, unter anderem mit der Göttin Leto, einer Tochter des Titanen Koios, die ihm Apollon, den Gott des Lichts und der Musik, und Artemis, heilbringende Göttin der Natur und der Jagd, gebar, oder Leda, von der er die Dioskuren Kastor (Castor) und Polydeukes (Pollux) bekam. Daneben war er auch Vater vieler Nymphen, Halbgöttinnen und Sterblicher. Diese Liebschaften waren nie von Dauer, vor allem wegen Heras maßloser Eifersucht. Um die Kinder, die aus diesen Seitensprüngen entstanden waren (unter anderem Herakles und die schöne Helena), kümmerte er sich aber. Die einzige Liebschaft von Dauer war wahrscheinlich die zum Königssohn Ganymed. Dieser war so schön, dass Zeus ihn in Gestalt eines Adlers auf den Olymp entführte. Dort diente er ihm als Mundschenk. Auch die Göttin Aphrodite soll nach Homer eine Tochter von Zeus und der Dione gewesen sein. Geläufiger ist jedoch die Version des Hesiod, nach der sie aus dem Schaum (daher ihr Name, von griech: aphros=Schaum) entstand, der sich um die abgeschnittenen Genitalien des Uranos im Meer vor Kythera gebildet hatte. Seine Lieblingstochter Athene, die Göttin der Weisheit, entsprang seinem Kopf, obwohl da möglicherweise von Hephaistos nachgeholfen wurde. Doch auch andere Götter stammen von ihm ab, wie Dionysos, der Gott des Weines (siehe Schenkelgeburt), die Göttin Iris, die als Botschafterin die Kommunikation zwischen Menschen und Göttern sicherstellte, oder Hermes, der Götterbote und Schutzgott.

Um Frauen zu verführen, nahm Zeus oft eine andere Gestalt an:

Das älteste und erste in der Antike berühmte Zeus-Orakel befand sich im Eichenhain von Dodona (die Eiche ist ebenfalls der heilige Baum des Zeus). Auch in Olympia gab es ein Zeus-Orakel; hier wurde der Zeus Olympios verehrt. Auf Kreta nahmen Kulte Bezug auf seine Geburt und Kindheit mit Höhlen- und Geburtskulten. Siehe auch Höhle von Psychro, Idäische Grotte.

Verehrt wurde Zeus als Allgott, als denkendes Feuer, das alles durchdringt, als Vater der Götter und Menschen, als Gott des Wetters, als Schicksalsgott usw. Die Epiphanie des Zeus ist stets der Blitz, etwa bei Homer.

Da Zeus als Götterherrscher galt, war sein Kult oft mit Monarchen verbunden. So ist bezeichnend, dass der große Zeustempel in Athen, das Olympieion, während der Tyrannis des Peisistratos begonnen, durch König Antiochos IV. fortgeführt und erst unter Kaiser Hadrian vollendet wurde, während man die Bauarbeiten zur Zeit der attischen Demokratie ruhen ließ.

Die Zeusverehrung erlosch erst am Ende der Spätantike um das Jahr 600 n. Chr.

Je nach Art der Verehrung erhielt Zeus verschiedene Beinamen, etwa:

Zeus spielt auch eine wichtige Rolle in der Philosophie der Antike. Die Orphiker sahen Zeus als den Weltgrund an, der Platoniker Xenokrates identifizierte Zeus mit dem kosmischen Nous, in der Philosophie der Stoa wurde Zeus als die Urkraft oder kosmische Vernunft aufgefasst.

Die wohl bekannteste Darstellung des Zeus ist die heute nicht mehr erhaltene Kolossalstatue des Phidias in Olympia. Weiterhin gibt es zahlreiche Darstellungen von Zeus als Krieger mit dem Attribut des Blitzbündels oder des Zepters, thronend als Göttervater.

Oft wurden auch die zahlreichen Mädchen- und Frauenraube des Zeus dargestellt, wie zum Beispiel der Raub der Europa und ähnliche, aber auch der des Knaben Ganymed.
Seine Attribute sind Zepter, Adler, Blitzbündel, Helm, bisweilen auch der Eichenkranz, seine Begleiterin manchmal die Siegesgöttin Nike.




</doc>
<doc id="5808" url="https://de.wikipedia.org/wiki?curid=5808" title="Kyklop">
Kyklop

Kyklopen ( „Kreisäugige“, Sg. „Kyklops“) oder Zyklopen (eingedeutscht nach , Sg. "Cyclops") sind Gestalten der griechischen Mythologie, die in Abstammung, äußerer Gestalt, Lokalisation und Eigenschaften voneinander differieren. Ihnen gemeinsam ist das ungewöhnliche Aussehen der Augen als kreisrunde Augen oder als Einzelauge auf der Stirn. Bereits in der Antike wurden drei Arten von Kyklopen unterschieden: Die hesiodschen Gewitterdämonen, die später zu vulkanischen Dämonen umgedeutet wurden, die homerischen Riesen und schließlich die mythischen Baumeister.

Von der Figur abgeleitet ist die Bezeichnung "Zyklopie" für bestimmte Schädelfehlbildungen.

In Hesiods "Theogonie" sind die Kyklopen die gottgleichen aber einäugigen Söhne des Uranos und der Gaia, ihre Geschwister sind die Hekatoncheiren und die Titanen. Sie bekamen die Namen Brontes (Βρόντης), Steropes und Arges. Wie ihre Geschwister werden sie von Uranos in Gaia, der Erde, eingeschlossen und erst von Zeus befreit, der dafür von ihnen Blitz, Zündkeil und Donner für seinen Kampf gegen die Titanen erhält.
In Hesiods "Eoien" werden sie von Apollon getötet.

In der "Bibliotheke des Apollodor" werden sie mit ihren Geschwistern in den Tartaros verbannt. Sie werden bereits nach der Entmannung des Uranos von den Titanen wieder heraufgeholt, von Kronos jedoch wieder zurückgeschickt. Zeus befreit sie nach zehnjährigem Kampf gegen die Titanen, indem er ihren Wächter Kampe tötet, und erhält die Waffen wie bei Hesiod sowie einen Helm für Hades und einen Dreizack für Poseidon. Sie werden von Apollon getötet, als dieser sich an Zeus für den Tod seines Sohnes Asklepios rächte. Asklepios hatte mehrere Tote wieder auferstehen lassen und war dafür von Zeus mit dem Blitz getötet worden, den er von den Kyklopen erhielt. Der Pfeil, mit dem die Kyklopen getötet wurden, soll nach späterer Überlieferung unter die Sterne versetzt worden sein.

In Nonnos "Dionysiaka" begleiten die Kyklopen Dionysos bei seinem Feldzug gegen Indien. Ihre Namen sind Brontes, Steropes, Arges, Euryalos, Elatreus, Trakhios und Halimedes. Als einziger Kyklop, der nicht mit auf die Reise geht, wird Polyphem genannt.
In späterer Sage erscheinen sie als Gehilfen des Hephaistos, die im Inneren von Vulkanen Waffen schmieden. Die Umdeutung von Gewitterdämonen hin zu vulkanischen Dämonen ergibt sich daraus, dass vulkanische Phänomene einerseits in einen Zusammenhang mit Gewittern gebracht und andererseits als göttliche Schmiedetätigkeiten gedeutet wurden. Erste Ansätze dieser Vorstellung finden sich bei Euripides, der als Polyphems Wohnsitz den Ätna angibt. Als Gehilfen des Hephaistos erscheinen sie erstmals bei Kallimachos, der sie auf den vulkanischen Liparischen Inseln wohnen lässt. In Vergils "Aeneis" schmieden die Kyklopen Brontes, Steropes und Pyracmon auf der Insel Volcania Blitze und Donnerkeile für Jupiter, einen Streitwagen für Mars und einen Schild für Athene, in der "Georgica" lässt Vergil sie im Ätna wohnen.

Bei Kallimachos erhält Artemis von den Kyklopen den Bogen, den sie zur Jagd benutzt.

Die bekannteren Kyklopen, denen Odysseus gemäß der Odyssee Homers auf seinen Irrfahrten begegnete, waren die Söhne des Poseidon. Besonders mit Polyphem hatten Odysseus und seine Männer große Schwierigkeiten: Er sperrte Odysseus und zwölf seiner Gefährten in seine Wohnhöhle ein und verspeiste sechs der Männer, bevor Odysseus mit seinen verbliebenen Gefährten durch Listen und Blendung des Polyphem die Flucht gelang.

Eine weitere Ausbildung der Sage findet man in der Erwähnung der Kyklopen, die nach Strabon aus Lykien kamen und in Tiryns und Mykene Mauern und andere Bauwerke errichteten, welche als „Zyklopenmauern“ bezeichnet werden. Dabei handelt es sich um eine ätiologische Sage, mit deren Hilfe die für die griechische Antike unverstandenen Ruinen aus dem Späthelladikum und insbesondere deren Mauerwerk erklärt werden sollte. Die Hellenen der Antike trauten ihren Vorfahren den Umgang mit den gewaltigen Steinquadern und deren beinahe fugenlosen Zusammenbau nicht zu, so dass diese Bauwerke mythischen Figuren zugeschrieben wurden. Dafür wurden Anleihen bei den anderen Kyklopen genommen.

Historiker und Mythenforscher mutmaßen, dass die Legenden der einäugigen Riesen auf Gorillas, embryonale Fehlentwicklungen (Zyklopie), Funde von Elefantenschädeln in Nordafrika oder auf den Mittelmeerinseln begründen. Sie nehmen an, dass die große Nasenöffnung des Schädels fälschlicherweise als eine einzelne große Augenhöhle interpretiert wurde. Auch einige antike figürliche Darstellungen des Kyklopenkopfes zeigen Ähnlichkeiten zur Schädelstruktur von Elefanten. Neben verschiedenen großen Elefantenarten, die in prähistorischer Zeit auf einigen Mittelmeerinseln lebten, gab es auch einige Zwergelefanten verschiedener Größen, etwa auf Malta, Kreta, Zypern oder in Sizilien. Viele dieser Arten wurden mit großer Wahrscheinlichkeit neben anderen endemischen Insel-Formen wie Zwerg-Hirschen und Zwerg-Nilpferden zum Teil erst relativ spät vom Menschen ausgerottet. Selbst die Schädel sehr kleiner Zwergelefanten-Arten waren deutlich größer als die eines Menschen, was dann in deutlich übermenschengroßen Kyklopen-Darstellungen resultierte. Funde solcher Elefanten stammen häufig aus Höhlen, in die die Tiere hineinfielen, was dazu führte, dass ihre Überreste gut erhalten bleiben konnten. Auch Polyphem lebte in einer Höhle, hier bildeten möglicherweise in Höhlen gefundene Elefanten-Fossilien die Ursprünge dieses Mythos. Die meisten alten Kyklopen-Darstellungen zeigen diese Gestalten 3–5 m groß, weswegen man eher davon ausgeht, dass Schädelfunde von Zwergelefanten und nicht großer Arten wie etwa Deinotherien, die Ursprünge dieser Mythengestalten bildeten.

Über die Möglichkeit, dass der Kyklopen-Mythos auf Funden fossiler Elefantenschädel beruht, spekulierte erstmals 1914 der österreichische Paläontologe Othenio Abel. Um seine Theorie zu untermauern, behauptete Abel, bereits der griechische Philosoph Empedokles hätte eine ähnliche Annahme getroffen. Willy Ley fügte 1948 der These von Abels hinzu, dass sich Giovanni Boccaccio ebenfalls auf Empedokles berief, als er versteinerte Mammutknochen als Erklärung für die Legende der Kyklopen heranzog. Obwohl sich weder in den überlieferten Schriften von Empedokles, noch in den Werken Boccaccios Beschreibungen von Knochenfunden und Bezüge zu Kyklopen finden lassen, wurden die Theorien von Abels und Ley später ungeprüft übernommen und Elefantenschädel als Erklärung für den antiken Glaube an einäugige Riesen schlechthin benutzt. Gegen diese Theorie spricht zudem die Etymologie des Wortes Kyklop, das sich als „ringäugig“ übersetzen lässt. Somit scheinen eher die Ringsymbolik (Unbegrenztheit - Ewigkeit, Symbol der Sonne, Feuer, Erkenntnis) und die Nähe zum Schmiedehandwerk, welches mystifiziert wurde, den Begriff geprägt zu haben, zumal Kyklopen als Schmiede tätig waren. Die embryonale Fehlentwicklung Zyklopie tritt zu selten auf, als dass sie den Kyklopen-Mythos beeinflusst haben könnte.

Die ursprünglichen Beschreibungen der Kyklopen und der Name selbst sprechen zunächst nur von rund- oder ringäugig. Die Vorstellung der Einäugigkeit der Kyklopen mit einem zentralen Auge in der Stirn ist nach dem Wortlaut der Quellen nicht zwingend. In Homers Odyssee blendet der listenreiche Odysseus den Kyklopen Polyphem mit einem im Feuer erhitzten Balken, was zur Annahme der Einäugigkeit geführt hat. Sie wird von Hesiod in der "Theogonie" explizit ausgeführt.

Von antiken Künstlern wurden die Kyklopen als Riesen mit einem einzelnen großen Auge auf der Stirn dargestellt, doch oft so, dass darunter auch die Augen an der gewöhnlichen Stelle wenigstens angedeutet waren (Relief des kapitolinischen Museums, Kyklop in der Schmiede des Hephästos). Moderne Darstellungen sehen Kyklopen zumeist einäugig und sind vorwiegend durch Homers Polyphem beeinflusst.




</doc>
<doc id="5809" url="https://de.wikipedia.org/wiki?curid=5809" title="Lauchgewächse">
Lauchgewächse

Die Unterfamilie der Lauchgewächse oder Zwiebelgewächse (Allioideae) gehört zur Pflanzenfamilie der Amaryllisgewächse (Amaryllidaceae) in der Ordnung der Spargelartigen (Asparagales) innerhalb der Monokotyledonen. Viele Arten werden als Zierpflanzen oder Nahrungspflanzen genutzt. Die medizinischen Wirkungen einiger Arten wurden untersucht.

Es sind ausdauernde krautige Pflanzen. Alle Arten sind nicht immergrün, besitzen also nur Laubblätter während der günstigen Jahreszeit (Sommer oder Regenzeit). Oft bilden sie Zwiebeln mit Tunika, Knollen oder Rhizome als Überdauerungsorgane. Die Wurzeln sind oft kontraktil. Die meisten Arten besitzen den typischen Zwiebelgeruch.

Die Laubblätter sind wechselständig und spiralig oder zweizeilig, fast immer in einer grundständigen Rosette angeordnet. Die einfachen, ganzrandigen Laubblätter sind sehr unterschiedlich gestaltet. Nur selten ist ein Blattstiel ausgebildet (beispielsweise "Allium ursinum", "Allium victorialis").

Es ist ein mehr oder weniger langer, unbeblätterter Blütenstandsschaft vorhanden. Die scheindoldigen Blütenstände sind aus gestauchten, zymösen Teilblütenständen zusammengesetzt und sind manchmal fast kugelrund. Der Blütenstand ist im knospigen Zustand von zwei oder mehr membranartigen Hochblättern schützend umhüllt. Es sind keine Deckblätter vorhanden.

Die zwittrigen, meist radiärsymmetrischen, bei "Miersia", "Gethyum" und "Solaria" mehr oder weniger zygomorphen, Blüten sind dreizählig. Fast alle Arten besitzen zwei Kreise mit je drei Blütenhüllblättern, außer "Gilliesia" und "Schickendantziella" bei denen ein Kreis fehlt. Die Blütenhüllblätter sind gleichgestaltig und meist an ihrer Basis verwachsen. Es sind meist zwei Kreise mit je drei fertilen Staubblättern vorhanden. Bei "Gilliesia", "Gethyum", "Miersia" und "Solaria" sind die Staubfäden zu einer den Griffel umgebenden Röhre verwachsen. Wobei bei "Gilliesia" und "Gethyum" nur drei fertile Staubblätter vorhanden sind und die drei anderen zu kurzen Staminodien reduziert sind. Bei "Trichlora" und einigen "Leucocoryne"-Arten wechselt jeweils ein fertiles Staubblatt mit einem Staminodium ab. Die drei Fruchtblätter sind zu einem oberständigen, dreifächerigen Fruchtknoten verwachsen. Je Fruchtknotenkammer sind meist einige, bei "Allium" nur ein bis zwei, Samenanlagen vorhanden. Es sind meist Septalnektarien im oberen Teil des Fruchtknotens vorhanden, außer bei "Gilliesia" und "Gethyum". Bei allen Arten sind die Griffel nicht hohl im Gegensatz zu den Themidaceae. Die Bestäubung erfolgt meist durch Insekten (Entomophilie).

Es werden Kapselfrüchte gebildet.

Die 2 bis 20 µm langen Chromosomen sind je nach Tribus in einer Basiszahl von x = 4, 6, (7), 8, (9) vorhanden.

Typisch, aber nicht bei allen Arten vorhanden, ist die Anreicherung von schwefelhaltigen Verbindungen, die nach Verletzung von Zellen durch Spaltung die Freisetzung der charakteristisch riechenden Lauchöle verursachen. Steroidsaponine sind häufig zu finden. Nur selten sind Idioblasten mit Schleim und Oxalatraphiden gefüllt. Es sind Flavonoide vorhanden.

Die Unterfamilie Allioideae kommt weltweit in allen Klimazonen vor. In Australien und angrenzenden Gebieten findet man nur wenige Arten.

Die molekulargenetischen Untersuchungen in den letzten gut zehn Jahren haben dazu geführt, dass die Familiengrenzen innerhalb der Ordnung der Spargelartigen (Asparagales) sich stark verschoben haben. Die Systematik dieser Unterfamilie, früher Familie, wurde lange diskutiert, dabei wurden Unterfamilien und Tribus aufgestellt und wieder verworfen, so wird man in der Literatur oft auf scheinbare Ungereimtheiten stoßen. Hier dargestellt ist die Systematik nach Mark W. Chase et al. 2009. Die Familie der Amaryllidaceae wurde um die Taxa der ehemaligen Familien Agapanthaceae und Alliaceae erweitert. Die bisherigen Unterfamilien der bisherigen Alliaceae werden einen Rang niedriger gestuft und bilden die drei Tribus der Unterfamilie Allioideae s. l. Der Familienname Alliaceae wurde von Moritz Balthasar Borkhausen veröffentlicht. Typusgattung ist "Allium" Weitere Synonyme für Allioideae sind Cepaceae , Gilliesiaceae , Tulbaghiaceae , Milulaceae . Früher wurden diese Taxa auch in die Familie der Liliengewächse (Liliaceae) eingeordnet.

Die Unterfamilie Lauchgewächse (Allioideae) wird seit 2014 in vier Tribus gegliedert und umfasst derzeit etwa 15 (früher bis 30) Gattungen mit fast 800 Arten:





Viele Gattungen, die früher in dieser Unterfamilie Allioideae eingeordnet waren gehören heute zur Unterfamilie Brodiaeoideae (Syn.: Themidaceae).





</doc>
<doc id="5810" url="https://de.wikipedia.org/wiki?curid=5810" title="Lauch (Gattung)">
Lauch (Gattung)

Die Lauch-Arten ("Allium") bilden die einzige Pflanzengattung der Tribus Allieae, die zur Unterfamilie der Allioideae innerhalb der Familie der Amaryllisgewächse (Amaryllidaceae) gehört. Einige Arten sind bekannte Speise- und Würzpflanzen, andere Arten werden als Zierpflanzen genutzt. Verantwortlich für den charakteristischen Geruch der meisten Arten ist Allicin, das bei Verletzung von Pflanzenteilen durch ein Enzym aus einer schwefelhaltigen Aminosäure, dem Alliin, gebildet wird.

Die Lauch-Arten wurden durch den Verein zur Erhaltung der Nutzpflanzenvielfalt e.V. (VEN) zum „Gemüse des Jahres“ 2013/2014 in Deutschland gewählt.

 

"Allium"-Arten sind ausdauernde krautige Pflanzen, die je nach Art Wuchshöhen von 5 bis 200 Zentimeter aufweisen. Oft bilden sie Zwiebeln als Überdauerungsorgane, manche Arten bilden zusätzlich Rhizome. Je nach Art kann die Zwiebelhülle glatt oder in Längsfasern bis -streifen geteilt, sie kann netzartig sein oder maschen- bis lochartige Strukturen aufweisen. Die meisten Arten haben den typischen Zwiebelgeruch.

Die einfachen, parallelnervigen Laubblätter sind meist ungestielt. Die je nach Art 5 bis 80 Zentimeter langen Blattspreiten können flach mit einer Breite von 0,3 bis 15 Zentimeter oder zylindrisch mit einem Durchmesser von weniger als 1 Millimeter bis über 2 Zentimeter sein, seltener sind sie fadenförmig, dreikantig, halbzylindrisch oder in viele fadenartige Zipfel geteilt.

Es wird ein mehr oder weniger langer unbeblätterter Blütenstandsschaft gebildet. Die doldigen Blütenstände sind manchmal fast kugelrund. Manchmal werden Brutzwiebelchen in den Blütenständen gebildet. Oft ist ein großes Hochblatt vorhanden, das im knospigen Zustand die Blüten schützt.

Die meist zwittrigen, meist radiärsymmetrischen Blüten sind dreizählig. Wenige Arten bilden eingeschlechtige Blüten und sind dann zweihäusig getrenntgeschlechtig (diözisch). Die zwei mal drei Blütenhüllblätter sind bei den meisten Arten gleichgestaltig. Die Farbe der Blütenhüllblätter der "Allium"-Arten ist oft weiß, gelb, rosa, blau, violett oder rot. Es sind zwei Kreise mit je drei fertilen Staubblättern vorhanden. Die drei Fruchtblätter sind zu einem oberständigen Fruchtknoten verwachsen.

Es werden Kapselfrüchte gebildet. Die schwarzen Samen sind verkehrt-eiförmig bis kugelig.

Die Erstveröffentlichung der Gattung "Allium" erfolgte 1753 durch Carl von Linné in "Species Plantarum". Synonyme für "Allium" sind: "Caloscordum" , "Cepa" , "Milula" , "Nectaroscordum" 

Die monophyletische Gattung "Allium" ist die einzige Gattung der Tribus Allieae, die zur Unterfamilie der Allioideae innerhalb der Familie der Amaryllisgewächse (Amaryllidaceae) gehört.

Die Gattung "Allium" wird nach N. Friesen, R. M. Fritsch & F. R. Blattner 2006 in 15 und Li et al. 2010 in 13 Untergattungen mit insgesamt etwa 72 Sektionen gegliedert. Sie umfasst etwa 940 Arten. Die größte Artenzahl findet sich im Mittelmeerraum, im Orient und von Turkestan bis Tibet.

Hier eine Auswahl der Arten:















Folgende häufig kultivierte Arten finden als Lebensmittel Verwendung: Zwiebel ("Allium cepa"), Winterzwiebel ("Allium fistulosum"), Knoblauch ("Allium sativum"), Schalotte ("Allium ascalonicum"), Schnittlauch ("Allium schoenoprasum"), Porree ("Allium ampeloprasum"). Wild wachsend, jedoch heutzutage auch oft in der Küche genutzt, ist der Bärlauch ("Allium ursinum").

Viele Arten und Sorten der Gattung "Allium" werden als Zierpflanzen verwendet. Ein Beispiel ist der Sternkugel-Lauch ("Allium cristophii").

Die Zwiebel des Allermannsharnisch (auch Siegwurz, wilder Alraun) wurde als Schutz gegen Wunden, Unglücksfälle, Zauberei für Menschen und Tiere benutzt und von Marktschreiern oft in menschenähnliche Gestalt gebracht, bekleidet und zu hohen Preisen verkauft. Auch andere Alliumarten finden sich in der Heilkunde.

Die Vorfahren der kultivierten Lauch-Arten sind zumeist im inneren Asien heimisch,

aber als derbe Würzen schon in grauer Vorzeit verbreitet worden.
Den Ägyptern galten die Laucharten sogar als heilig und geweiht und wurden daher von Priestern und Frommen nicht berührt.

Die Zwiebel von Askalon beschreibt schon Theophrast; Knoblauch und Zwiebeln spielten am persischen Hof eine große Rolle, und auch Homer kennt die Zwiebel und erwähnt sie als Beiessen zum Mischtrank des Nestor. Auch später blieben in Griechenland und Italien die Lauchgewächse beliebteste Volksnahrung; mit steigender kultureller Verfeinerung schlug jedoch bei den höheren gesellschaftlichen Schichten die Vorliebe in Widerwillen um, und Zwiebel- und Knoblauchgeruch verrieten den Mann aus dem niedrigsten Volk. Jemand "„Zwiebel anwünschen“" bedeutete nichts Gutes, und Horaz wird nervös, wenn er des Knoblauchs gedenkt.

Dem scharfen Geruch und Geschmack verdankten die Laucharten anderseits abergläubische Anwendung gegen Gift und Zauberei, und eine bestimmte Art ("Allium nigrum") galt als die bei Homer „Moly“ genannte Pflanze, durch welche Odysseus den Zauberkünsten der Kirke widerstand.



</doc>
<doc id="5812" url="https://de.wikipedia.org/wiki?curid=5812" title="Zeus-Statue des Phidias">
Zeus-Statue des Phidias

Die Zeus-Statue des Phidias war die sitzende Kolossalstatue des Zeus für den im Jahre 456 v. Chr. fertiggestellten Zeustempel von Olympia. Das Sitzbild wurde von dem Bildhauer Phidias zwischen 438 und 430 v. Chr. geschaffen und gehörte nicht nur wegen seiner Höhe von etwa 13 Metern zu den „Sieben Weltwundern der Antike“. Die Statue war aus Gold und Elfenbein gefertigt. Der Thron bestand aus Ebenholz. Zeus hielt in seiner Rechten eine Nike, in seiner Linken einen Stab. Basis und Thron waren darüber hinaus mit freiplastischen Figuren und Reliefs reich geschmückt, bemalte Schranken hielten den Besucher auf Abstand.

Während Fundamentreste der Statuenbasis in Olympia erhalten sind, ist die Statue selbst verloren und nur noch aus Münzdarstellungen und antiken Beschreibungen zu rekonstruieren. Einer Legende des 12. Jahrhunderts zufolge befand sich die Statue im 5. Jahrhundert n. Chr. in Konstantinopel, wo sie im Jahr 475 einem Brand zum Opfer fiel.

Die Statue selbst ist nicht erhalten, doch konnten die Fundamente ihrer Basis im zwischen 480/70 und 456 v. Chr. errichteten Zeustempel ausgegraben werden. Sie setzte auf Höhe der fünften Innensäulen von Osten an und nahm das hintere Drittel des Mittelschiffs in ganzer Breite ein. Ihre Maße betrugen 6,65 Meter in der Breite und 9,93 Meter in der Tiefe. Im mittleren Drittel des Mittelschiffs befand sich ein 12 Zentimeter tiefes und im Quadrat 6,40 Meter großes Becken aus dunkelgrauen bis schwarz-bläulichen Platten eleusinischen Kalksteins, die von weißem Marmor eingefasst wurden. Es diente entweder dem Auffangen des Öls, das man für die Pflege des Elfenbeins benötigte, oder diente als Wasserbehältnis der Regulierung der Luftfeuchtigkeit.

Basisbreite und Tempelinnenraum erlauben die Rekonstruktion einer 12 bis 13 Meter hohen Statue. Die Fundamente der Basis wurden nach Fertigstellung des Tempels verstärkt, waren also ursprünglich nicht für ein Standbild der später realisierten Ausmaße konzipiert. Zugleich wurde die Säulenaufstellung im Inneren der Cella leicht verändert.

Die Zeusstatue wurde erst ab 438/435 v. Chr., also fast zwanzig Jahre nach Ende der Bauarbeiten des Tempels, von Phidias geschaffen, der bis um 430 v. Chr. an dieser Statue, einem seiner größten Meisterwerke, arbeitete. Die Verzögerung gegenüber der Fertigstellung des Tempels wird einerseits mit Reparaturarbeiten nach einem schweren Erdbeben im 5. Jahrhundert v. Chr. zusammenhängen, kann aber andererseits auch in der politischen Situation in Griechenland nach Ende des ersten Peloponnesischen Krieges begründet liegen.

Repliken der Statue oder ihrer Teile sind nicht erhalten. Vermutungen, eine Kopie der Statue habe Antiochos IV. im Tempel des Apollon in Daphne bei Antiochia aufstellen lassen, tragen zur Rekonstruktion nicht bei. Doch wurden neben Elfenbeinstücken auch als Glasmatrizen dienende Tonmodel der Statue in der auch in der antiken Überlieferung genannten Werkstatt des Phidias entdeckt, die wahrscheinlich von Gewandpartien des Zeus stammten und wenigstens einen vagen Eindruck von der Plastizität des Zeus vermitteln können. Ein Keramikbecher, in dessen Boden die Worte: ΦΕΙΔΙΟΥ ΕΙΜΙ (Φειδίου εἰμί; "Pheidiou eimi" „des Pheidias [Eigentum] bin ich“) eingeritzt sind, wurde im Schutt der Werkstatt neben Resten von Material und Werkzeug gefunden.

Zahlreiche Münzemissionen der römischen Kaiserzeit bilden entweder den Kopf oder die ganze Statue des Zeus in Profil oder Dreiviertelansicht ab. Demnach war Zeus sitzend auf einem hohen Thron dargestellt. Seine Füße ruhten auf einem Schemel. In der rechten Hand hielt er eine geflügelte Nike, in der linken Hand eine aufgestützte Lanze. Sphingen sind unterhalb der Lehne dargestellt.

Die Statue des Zeus wurde häufig in antiken Schriften erwähnt, oft ohne weitere Beschreibung, oft in anekdotischem Zusammenhang, zumeist aber einfach nur als Werk des Phidias. Einige erste technische Details stammen bereits von Kallimachos von Kyrene, einem Gelehrten des 3. Jahrhunderts v. Chr. Er beschreibt in einem recht fragmentarisch erhaltenen Gedicht vor allem die Maße und erwähnt, dass sich auf der Thronlehne des Zeus Horen befanden, auch der Begriff "Nike" fällt in dem Zusammenhang. Demnach war der Zeus 30 Ellen hoch, was etwa 13,20 Meter entspricht, wohl an der Basis war die Statue 20 Ellen, also 8,80 Meter breit und der Thron war 5 Ellen niedriger als der Zeus, demnach etwa 12 Meter hoch. Seine Kosten könne man im Übrigen nicht berechnen.

Der griechische Reiseschriftsteller Pausanias gibt eine ausführliche Beschreibung der Statue, nach der das Aussehen aber nur bedingt rekonstruiert werden kann, da vieles in der Beschreibung Raum für Interpretationen bietet. Pausanias weigert sich bewusst, Maße der Statue zu nennen, da das Ergebnis jeder Vermessung der Größe und dem Eindruck der Statue nicht gerecht werden könne. Die Statue war auf einem inneren Gerüst aufgebaut, außen mit Gold, Elfenbein und Ebenholz verkleidet, war also chryselephantin, und mit gegossenem farbigen Glas und Edelsteinen verziert. Sie zeigte auf einem Thron sitzend Zeus, der mit einem Heben seiner Augenbraue die Erde regierte. Die Rechte hielt eine mit einer Taenie geschmückte Nike, in der Linken hatte er einen mit Edelmetallen verzierten Stab, auf dessen Ende ein Vogel saß. Sein Haar war langgelockt, darauf trug er einen Olivenkranz. Die Füße des Gottes ruhten auf einem mit figürlichen Reliefs dekorierten Schemel.

Die Statue war mit Reliefs und Freiplastiken geschmückt. Die Basis war mit goldenen Bildern zahlreicher Götter und Götterpaare verkleidet. Der Thron besaß wohl Füße in Form von Löwentatzen. Der Thron war wie die Statue aus Gold, Elfenbein und Ebenholz, darüber hinaus mit Edelsteinen besetzt. Vier tanzende Niken befanden sich an jedem der vier Thronfüße, zwei weitere Niken kamen pro Vorderfuß hinzu. Zusätzlich zierten knabenraubende Sphingen die Vorderbeine, wohl unterhalb der seitlichen Thronlehnen. Niobidenfriese zierten den Thron, dessen oberer Abschluss die schon bei Kallimachos erwähnten Horen sowie Chariten trug. Streben versteiften die Thronbeine und waren an der Frontstrebe mit Knabenfiguren in Form von Plastiken oder Reliefs geschmückt. Die anderen Streben zeigten eine Amazonomachie mit Herakles, Theseus und 27 weiteren Kämpfern auf Seiten der Griechen, denen 29 Amazonen entgegentraten.

Bemalte Schranken aus der Hand des Panainos, der auch für die farbliche Gestaltung der Statue selbst verantwortlich zeichnete, hielten die Besucher auf Abstand. Die Frontschranke war hierbei monochrom in einem kräftigen Blau gehalten, während die drei übrigen Schranken mit jeweils drei Bildfeldern bemalt waren: Herakles, wie er dabei ist, dem Atlas die Last von den Schultern zu nehmen; Theseus und Peirithoos, wohl in der Unterwelt, Personifikationen der Hellas und der Salamis mit Schiffsschnäbeln in den Händen als Anspielungen auf die Seesiege der Griechen gegen die Perser; der löwenbezingende Herakles; die Schändung Kassandras durch den lokrischen Aias; Hippodameia und Sterope, Tochter und Ehefrau des Oinomaos; der gefesselte Prometheus und Herakles; Achilleus, der die sterbende Amazone Penthesilea stützt; schließlich und die Geschichte des ersten Bildes wieder aufnehmend: zwei Hesperiden mit zwei Äpfeln, um deren Äpfel rauben zu können, Herakles dem Atlas, Vater der Hesperiden, die Last von den Schultern nahm, damit dieser die Äpfel pflücken könne.

Jede Seite der Thronschranken wies also die Abfolge „Herakles-Mythos“ – „dramatische Liebesgeschichte“ – „mythische Frauengestalten“ auf. Denn auch Theseus und Peirithoos saßen in der Unterwelt, dem Hades, fest, weil sie Persephone entführen wollten.

Strabon nennt Panainos, der ein naher Verwandter des Phidias war, übrigens „Synergolabos“ (), was auf eine Position in Augenhöhe mit Phidias hinweist. Denn als Synergolabos war er Mitauftragnehmer für die ausgeschriebene Zeusstatue. In der Erörterung mit Panainos soll Phidias die berühmten Worte geäußert haben, dass ihm als Vorbild der künstlerischen Gestaltung die Verse Homers über Zeus gedient haben:
Diese Künstleranekdote wurde bis in byzantinische Zeit immer wieder aufgegriffen.

Als unglücklich galt bei den Griechen jener, der das Heiligtum und die Dinge darin nicht gesehen habe. "Auch eine vernunftlose Kreatur müsste der Anblick des Zeus erschüttern". Der Zeus von Olympia war das letzte Werk des griechischen Bildhauers Phidias, von dem auch die in gleicher Technik errichtete Statue der Athene Parthenos auf der Akropolis in Athen stammte. Sie stellte den obersten der Götter mit gerunzelter Augenbraue "(supercilium)" dar. Denn mit einem Heben der Braue regierte Zeus nach antikem Glauben die Welt; mit einem Stirnrunzeln ließ er den Olymp erbeben. Bereits die Antike warf Phidias vor, er hätte bei seiner Statue die Regeln der rechten Proportion verletzt. Denn der sitzende Zeus reichte bis an das Tempeldach, das er zerstört hätte, wäre er aufgestanden. Andererseits muss der Anblick ein emotional erregendes Ereignis gewesen sein. Im frühen 2. Jahrhundert v. Chr. erschrak der römische Feldherr Aemilius Paullus beim Anblick der Statue und äußerte die Ansicht, dass allein Phidias den Zeus Homers nachgebildet habe. Aemilius Paullus war so bewegt von dem lebensechten Eindruck der Statue, dass er ein Opfer an den Gott anordnete, das einem Opfer für den kapitolinischen Jupiter vergleichbar war.

Die Statue des Zeus findet sich erstmals im späten 2. Jahrhundert v. Chr. bei Antipatros von Sidon und bei Philon von Byzanz im Kanon der Sieben Weltwunder der Antike. Philon beschreibt seine Wirkung sogar ausdrücklich, indem er äußert, nur für dieses Bild hätten die Götter das Elfenbein erfunden; und während man die anderen Wunder nur bewundere, würde man dieses sogar anbeten, denn als Werk der Kunst wäre es unglaublich, als Bildnis des Zeus aber heilig. Als Weltwunder findet die Statue Erwähnung bis in die Spätantike, und zwar mit teils immer fantastischer werdenden Größenangaben. Trifft Hyginus mit 60 Fuß oder knapp 18 Metern die tatsächlich erreichbare Höhe noch relativ gut, so maß die Statuenhöhe laut Ampelius 150 Ellen oder über 66 Meter, und gar 170 Ellen oder 75 Meter nennt ein Anonymus als Höhe. Demgegenüber ist die Höhe von 100 Fuß oder rund 30 Meter bei Vibius Sequester eine maßvolle Übertreibung. Noch der römische Staatsmann und gelehrte Schriftsteller Cassiodor erwähnt im 6. Jahrhundert n. Chr. die Statue wohlwollend von höchster Eleganz unter den Sieben Weltwundern.

Bereits im 2. Jahrhundert v. Chr. muss die Statue unter den klimatischen Bedingungen oder dem Einwirken von Erdbeben so gelitten haben, dass eine grundlegende Reparatur notwendig wurde, die Damophon ausführte. 

Im Jahr 40 n. Chr. scheiterte der römische Kaiser Caligula mit dem Versuch, die Statue nach Rom zu schaffen, und zwar der älteren Überlieferung nach, weil man Caligula davon überzeugen konnte, die Statue nicht ohne ihre automatische Zerstörung abbauen zu können. Einer späteren, anekdotischen Wendung des Vorhabens nach, habe Zeus selbst eingegriffen und ein lautes Lachen hören lassen, nachdem er die für den Transport bestimmten Schiffe zerstört hatte.

Im 2. Jahrhundert n. Chr. berichtet Lukian, ein vielgereister Wanderredner und Satiriker, der in seinem Leben viermal Olympia besuchte, von einem Lockenraub, gegen den sich selbst der olympische Zeus nicht habe wehren können. Inwieweit hier ein tatsächliches Geschehen zugrunde liegt oder Lukian nur im Rahmen seiner Erörterungen über die Hilflosigkeit der Götter eine hübsche, zudem gegen die Stoiker, denen das Haupthaar als Sitz von Leben und Kraft galt, gerichtete Geschichte erfunden hat, lässt sich nicht klären.

Das weitere Schicksal der Statue ist unbekannt. Laut einem stark verderbten Scholion zu Lukian brannte der Zeustempel im 4. Jahrhundert n. Chr. ab, was auch die Zeusstatue betroffen haben muss. Da der Tempel aber erst 522 oder 551 n. Chr. durch ein Erdbeben niedergeworfen wurde, müsste er nach dem Brand renoviert worden sein. 

Georgios Kedrenos, ein byzantinischer Historiker des 11. oder 12. Jahrhunderts, erzählt die Geschichte, dass ein elfenbeinerner Zeus, für Kedrenos ein Anathem des Perikles, von Olympia nach Konstantinopel gebracht und im Lauseion, dem Palast des obersten Eunuchen Lausos, Vorsteher der kaiserlichen Schlafgemächer ("praepositus sacri cubiculi"), unter Theodosius II., aufgestellt worden sei. Angesichts der von Kedrenos weiterhin aufgezählten Kunstwerke des Lauseion – eine archaische, aus hartem grünen Stein gefertigte Athena von Lindos, ein archaisches Herabildnis von Samos, die Aphrodite von Knidos des Praxiteles, Eros und Kairos des Lysipp, daneben Einhörner, Taurelephanten, Pane, Kentauren und weitere Kreaturen – scheint die Erwähnung des Zeus nur den Wert der Sammlung unterstreichen zu sollen. Denn namentlich die Athena, die Aphrodite und die Hera – alle von üblicher Statuengröße – werden auch von Johannes Zonaras im 12. Jahrhundert für das Lauseion erwähnt, der Zeus jedoch fehlt. Das Lausoeion brannte 475 n. Chr. ab. So bleibt die Erwähnung bei Kedrenos einmalig und unglaubwürdig, der hergestellte Bezug zu Perikles verstärkt diesen Eindruck. Sollte er seine Informationen aus Malchos gezogen haben, bleibt es verwunderlich, dass diese Quelle keinen weiteren Niederschlag gefunden hat.




</doc>
<doc id="5816" url="https://de.wikipedia.org/wiki?curid=5816" title="Zahlensystem">
Zahlensystem

Ein Zahlensystem (seltener auch Zahlsystem genannt) wird zur schriftlichen Darstellung von Zahlen verwendet (→Zahlschrift). Eine Zahl wird dabei nach festgelegten Regeln als Folge von Zahlzeichen, auch Ziffern genannt, dargestellt. Die moderne Forschung unterscheidet zwischen additiven, hybriden und positionellen (Stellenwert-) Zahlensystemen.

In einem Additionssystem wird eine Zahl als Summe der Werte ihrer Ziffern dargestellt. Dabei spielt die Position der einzelnen Ziffern keine Rolle.

Ein Beispiel ist das Strichsystem (Unärsystem), das sich anbietet, wenn etwas schriftlich mitgezählt werden soll (wie zum Beispiel die Getränke auf einem Bierdeckel). Hierbei wird die Zahl formula_1 durch formula_1 Striche dargestellt. Dies ist vermutlich eines der ältesten Zählsysteme überhaupt. Das Unärsystem wird bei der Darstellung größerer Zahlen sehr schnell unübersichtlich. Deshalb ist es meist üblich, die Zahlen in Blöcke zusammenzufassen, indem man etwa jeden fünften Strich quer über die vier vorangegangenen Einzelstriche legt. Obwohl es aus diesem Grund nicht geeignet ist, große Zahlen darzustellen, wird es im Alltag dennoch in manchen Situationen verwendet. Eine Addition um einen Zahlenwert ist einfach durch das Hinzufügen eines Striches möglich. Herkömmliche Systeme lassen eine so einfache und schnelle Erweiterung im Allgemeinen nicht zu.

Hierbei wird eine Grundziffer einem Zeichen vorangestellt, das eine Potenz der Basis wiedergibt; die Werte beider werden miteinander multipliziert. In den europäischen Zahlensystemen kamen solche Hybridsysteme so gut wie nicht vor, wohl aber, schon seit Beginn des zweiten Jahrtausends v. Chr., in Mesopotamien, später auch in China und im Nahen Osten allgemein. Sowohl aus Äthiopien als auch aus Südindien und Sri Lanka sowie der Maya-Kultur sind solche hybriden Zahlensysteme bekannt.

"Beispiele im japanisch-chinesischen Zahlensystem:"

Im Alltag und in der Wissenschaft wird eine Zahl üblicherweise durch Ziffern (0, 1, 2, …, 9, die allein die ersten zehn der natürlichen Zahlen darstellen, und Buchstaben) und weitere Zahlenzeichen wie Vorzeichen (plus, minus) und Trennzeichen (Komma, Leerzeichen) dargestellt. Die Anzahl der verwendeten Ziffern wird „Basis des Stellenwertsystems“ genannt. Die gängigsten Basen sind 2 (beim Dualsystem), 8 (beim Oktalsystem), 10 (beim im Alltag gebrauchten Dezimalsystem) oder 16 (beim in der Datenverarbeitung wichtigen Hexadezimalsystem).

Die Ziffern haben eine durch Konvention festgelegte Reihenfolge ihres Wertes. Beim Hochzählen (das entspricht der Addition einer Eins) wird in dieser Reihenfolge zur nächsten Ziffer übergegangen. Bei der Addition einer Eins auf die höchstwertigste Ziffer wird auf die niederwertigste Ziffer übergegangen, und auf der nächst höheren Stelle wird eine Eins addiert.

Dazu werden die Ziffern je nach ihrer Stelle unterschiedlich bewertet, wobei der Stellenwert eine Potenz der Basis ist (zum Beispiel „Einerstelle“, „Zehnerstelle“, „Hunderterstelle“, …). Die Stelle mit der niedrigsten Bewertung steht dabei ganz rechts. Die Berechnung des Zahlenwertes erfolgt dann durch Multiplikation der einzelnen Ziffernwerte mit den zugehörigen Stellenwerten und der Addition dieser Produkte.

Auf diese Weise lässt sich in einem Stellenwertsystem jede natürliche Zahl darstellen. Für die Erweiterung auf negative Zahlen wird ein Vorzeichen links vor die Ziffernfolge gesetzt, mit dem angegeben wird, ob eine Zahl positiv oder negativ ist. Durch die Verwendung negativer Exponenten lassen sich in einem Stellenwertsystem auch rationale Zahlen schreiben, wobei der Übergang von nichtnegativen zu negativen Exponenten durch ein Trennzeichen in der Zahldarstellung markiert wird, beispielsweise ein Komma oder einen Punkt.

Die Menge der darstellbaren Zahlen lässt sich bei einer unbeschränkten Anzahl von Stellen an einer Zahlengeraden veranschaulichen. Steht nur eine beschränkte Anzahl von Stellen zur Verfügung, wird das an einem Zahlenkreis veranschaulicht. Bei dieser Beschränkung kann eine Addition oder Subtraktion von Zahlen aus dem Bereich der darstellbaren Zahlen herausführen.




</doc>
<doc id="5818" url="https://de.wikipedia.org/wiki?curid=5818" title="Zahl">
Zahl

Zahlen sind abstrakte mathematische Objekte beziehungsweise Objekte des Denkens, die sich historisch aus Vorstellungen von Größe und Anzahl entwickelten. Durch eine Messung wird ein als Größe verstandener Aspekt einer Beobachtung mit einer Zahl in Verbindung gebracht, beispielsweise bei einer Zählung. Sie spielen daher für die empirischen Wissenschaften eine zentrale Rolle.

In der Mathematik, welche Zahlen und ihre Struktur formal untersucht, schließt der Begriff sehr verschiedenartige Konzepte mit ein. Diese entwickelten sich als Verallgemeinerungen bestehender intuitiver Zahlkonzepte, sodass man sie ebenfalls als "Zahlen" bezeichnet, obwohl sie teilweise wenig Bezug zu den ursprünglich mit Messungen verbundenen Konzepten haben. Manche dieser Konzepte sind in der Mathematik von grundlegender Bedeutung und finden Verwendung in nahezu allen Teilgebieten.

In die Urgeschichte zurück reicht das Konzept der natürlichen Zahlen, welche zum Zählen verwendet werden können und grundlegende Bedeutung besitzen. Ab etwa 2000 v. Chr. rechneten Ägypter und Babylonier mit Bruchzahlen (rationalen Zahlen). In Indien entwickelte sich im 7. Jh. n. Chr. ein Verständnis von der Null und den negativen Zahlen. Irrationale Zahlen wie formula_1 oder formula_2, deren Notwendigkeit sich aus Erkenntnissen aus dem antiken Griechenland ergab (spätestens ab dem 4. Jh. v. Chr.), wurden in der Blütezeit des Islam eingeführt.

Die Idee imaginärer Zahlen, durch die die reellen Zahlen später zu den bedeutenden komplexen Zahlen erweitert wurden, reicht in die europäische Renaissance zurück. Der Begriff der reellen Zahl konnte erst im 19. Jahrhundert hinreichend geklärt werden. Ende des 19. Jahrhunderts konnte erstmals auch unendlichen Größen ein präziser Sinn als Zahlen gegeben werden. Auch wurden erstmals die natürlichen Zahlen axiomatisch definiert. Mit den Anfang des 20. Jh. geschaffenen ersten zufriedenstellenden Grundlagen der Mathematik erfuhren auch die bedeutendsten Zahlbegriffe eine dem heutigen Stand entsprechende vollständig formale Definition und Bedeutung.

Vom Begriff der "Zahl" abzugrenzen sind "Ziffern" (spezielle "Zahlzeichen"; zur Darstellung bestimmter Zahlen verwendete Schriftzeichen), "Zahlschriften" (Schreibweisen von Zahlen z. B. mit Hilfe von Ziffern unter Verwendung bestimmter Regeln), "Zahlwörter" ("Numerale", zur Benennung bestimmter Zahlen verwendete Wörter) und "Nummern" (Identifikatoren, die selbst Zahlen, oder aber – in der Regel Ziffern enthaltende – Zeichenketten sein können).

Das deutsche Wort "Zahl" geht vermutlich auf das urgermanische Wort "*talō" ("Berechnung", "Zahl", "Rede") zurück, das vermutlich Wurzel der althochdeutschen Wörter "zala" ("Ordnung", "geordnete Darlegung", "Bericht", "Aufzählung") und "zalōn" ("berichten", "rechnen", "zählen", "berechnen", "zahlen") ist. Aus "zala" wurde im Mittelhochdeutschen "zale" oder "zal", auf das das heutige Wort "Zahl" zurückgeht.

Das urgermanische Wort findet seinen Ursprung vermutlich in einem urindogermanischen Etymon "*del-" ("zielen", "berechnen", "nachstellen"). Auch ein Zusammenhang mit dem urindogermanischen "*del-" ("spalten") ist möglich; die ursprüngliche Bedeutung wäre dann möglicherweise „eingekerbtes Merkzeichen“.

Die Mathematik untersucht Beziehungen zwischen mathematischen Objekten und beweist strukturelle Eigenschaften in diesen Beziehungen. Elementare Beispiele für zwischen Zahlen definierte Beziehungen sind etwa die allgemein bekannten Rechenoperationen ("Grundrechenarten") über den rationalen Zahlen (Brüche), Vergleiche („kleiner“, „größer“, „größer gleich“ etc.) zwischen rationalen Zahlen und die Teilbarkeitsrelation zwischen ganzen Zahlen („3 ist ein Teiler von 9“). Zudem werden Eigenschaften über bestimmten Zahlen definiert, zum Beispiel ist über den "ganzen Zahlen" die Eigenschaft definiert, eine Primzahl zu sein.

Solche Verknüpfungen sind nicht als vom Zahlbegriff unabhängige willkürliche Operationen zu verstehen, vielmehr werden bestimmte "Zahlbereiche" meist untrennbar von bestimmten Verknüpfungen betrachtet, da diese die zu untersuchende Struktur maßgeblich bestimmen. Spricht man etwa über die natürlichen Zahlen, gebraucht man fast immer zumindest auch ihre Ordnung („formula_3“, „formula_4“), welche maßgeblich unseren Begriff von natürlichen Zahlen bestimmt.

In der Schulmathematik, der Informatik und der numerischen Mathematik befasst man sich mit Verfahren, um solche Verknüpfungen auf konkreten Darstellungen von Zahlen auszuwerten ("Rechnen"). Als Beispiel sei hier die schriftliche Addition genannt: Unter Verwendung der Darstellung von Zahlen in einem Stellenwertsystem ist es hier möglich, durch systematisches Abarbeiten der Ziffern eine Darstellung für die Summe der beiden Zahlen zu erlangen. In der Informatik und der numerischen Mathematik werden solche Verfahren entwickelt und auf ihre Leistungsfähigkeit hin untersucht. Einige solcher Verfahren sind von fundamentaler Bedeutung für die heutigen Computer.

In der abstrakten Algebra befasst man sich mit der Struktur von Verallgemeinerungen solcher Zahlbereiche, wobei nur noch das Vorhandensein von Verknüpfungen mit gewissen Eigenschaften über einer beliebigen Menge von Objekten vorausgesetzt wird, welche die Struktur der Verknüpfungen nicht eindeutig bestimmen, sondern viele verschiedene konkrete Strukturen mit diesen Eigenschaften ("Modelle") zulassen (siehe "algebraische Struktur"). Ihre Resultate lassen sich auf konkrete Zahlbereiche anwenden, welche wiederum in der abstrakten Algebra als Motivation und elementare Beispiele dienen können.

Die Zahlentheorie behandelt Eigenschaften (im weiteren Sinne) von Zahlen, etwa Existenz, Häufigkeit und Verteilung von Zahlen mit bestimmten Eigenschaften. Eigenschaften "transfiniter" (in bestimmten Sinnen „unendlicher“ Zahlen) sind allerdings Gegenstand der Mengenlehre.

In der Mathematik werden solche Verknüpfungen, Beziehungen und Eigenschaften als Prädikate oder Relationen, einschließlich Funktionen, aufgefasst.

Der Begriff der "Zahl" ist nicht mathematisch definiert, sondern ist ein gemeinsprachlicher Oberbegriff für verschiedene mathematische Konzepte. Daher gibt es im mathematischen Sinn keine "Menge aller Zahlen" oder dergleichen. Die Mathematik spricht, wenn sie sich mit Zahlen befasst, stets über bestimmte wohldefinierte "Zahlbereiche", d. h. nur über bestimmte Objekte unseres Denkens mit festgelegten Eigenschaften, die salopp alle als "Zahlen" bezeichnet werden. Seit dem Ende des 19. Jahrhunderts werden in der Mathematik Zahlen rein mittels der Logik unabhängig von Vorstellungen von Raum und Zeit definiert. Grundsteine wurden hier von Richard Dedekind und Giuseppe Peano mit der Axiomatisierung der natürlichen Zahlen (Siehe Peano-Axiome) gelegt. Dedekind schreibt zu diesem neuen Ansatz:
Zu unterscheiden sind axiomatische Definitionen von mengentheoretischen Definitionen von Zahlen: Im ersteren Fall wird die Existenz gewisser Objekte mit auf ihnen definierten Verknüpfungen mit bestimmten Eigenschaften in Form von Axiomen postuliert, so etwa auch bei den frühen Axiomatisierungen der natürlichen und der reellen Zahlen durch Peano und Dedekind. In der Folge der Entwicklung der Mengenlehre durch Georg Cantor ging man dazu über, zu versuchen, sich auf mengentheoretische Axiome zu beschränken, wie es in der Mathematik heute etwa mit der Zermelo-Fraenkel-Mengenlehre (ZFC) üblich ist. Die Existenz gewisser Zahlenmengen und Verknüpfungen über ihnen mit gewissen Eigenschaften wird dann aus diesen Axiomen gefolgert. Mitunter wird ein Zahlbereich als eine bestimmte Klasse definiert. Die axiomatische Mengenlehre versucht eine einzige, einheitliche formale Grundlage für die gesamte Mathematik zu sein. Innerhalb ihrer lässt sich auf reichhaltige Weise mit den Zahlbereichen umgehen. Formuliert wird sie in der Regel in der Prädikatenlogik erster Stufe, welche die Struktur der mathematischen Sätze sowie die Möglichkeiten zur Schlussfolgerung aus den Axiomen festlegt.

Ein elementares Beispiel einer mengentheoretischen Definition einer Menge von Zahlen ist die von John von Neumann eingeführte Definition der natürlichen Zahlen als die kleinste induktive Menge, deren Existenz im Rahmen der Zermelo-Fraenkel-Mengenlehre durch das Unendlichkeitsaxiom postuliert wird.

Als mengentheoretische Konzepte werden Ordinal- und Kardinalzahlen in aller Regel mengentheoretisch definiert, ebenso die Verallgemeinerung der surrealen Zahlen.

Die Peano-Axiome etwa und die auf Dedekind zurückgehende Definition der reellen Zahlen basieren im Gegensatz zu ZFC auf der Prädikatenlogik zweiter Stufe. Während die Prädikatenlogik erster Stufe eine klare, allgemein akzeptierte Antwort darauf liefert, wie gültige Schlüsse vorzunehmen sind, wobei diese sich systematisch berechnen lassen, führen Versuche, dies für die Prädikatenlogik zweiter Stufe zu klären, meist dazu, dass eine komplexe Metatheorie eingeführt werden muss, die ihrerseits mengentheoretische Begriffe metasprachlich einführt und von deren Details die in der Folge erschlossenen Möglichkeiten der Folgerung in der Prädikatenlogik zweiter Stufe abhängen. ZFC ist ein Kandidat für eine solche Theorie. Diese Einschränkungen lassen die Prädikatenlogik zweiter Stufe in einem Teil der Philosophie der Mathematik ungeeignet erscheinen, auf grundlegender Ebene verwendet zu werden. Die Prädikatenlogik erster Stufe dagegen ist nicht hinreichend, um gewisse wichtige intuitive Eigenschaften der natürlichen Zahlen zu formulieren und (bei Betrachtung dieser in einer mengentheoretischen Metatheorie, etwa aufgrund des Satzes von Löwenheim-Skolem die Abzählbarkeit) sicherzustellen.

Einige wichtige Zahlbereiche seien hier in ihrem mathematischen Kontext vorgestellt. Im Laufe der Geschichte der Mathematik wurden immer weitere Zahlbereiche eingeführt, um gegenüber bisherigen Zahlbereichen bestimmte Probleme allgemeiner behandeln zu können. Insbesondere wurden bestehende Zahlbereiche durch Hinzufügen zusätzlicher Elemente zu neuen Zahlbereichen erweitert, um über gewisse Operationen allgemeiner sprechen zu können, siehe hierzu auch den Artikel zur Zahlbereichserweiterung.

Zum Begriff des "Zahlbereichs" siehe den Abschnitt zur Definition.

Die "natürlichen Zahlen" 1, 2, 3, 4, 5, … oder 0, 1, 2, 3, 4, 5, … bilden diejenige Menge von Zahlen, die üblicherweise zum "Zählen" verwendet wird, wobei je nach Definition die Null miteingeschlossen wird oder nicht. Die natürlichen Zahlen sind mit einer Ordnung („kleiner“) versehen. Es gibt ein kleinstes Element (je nach Definition die Null oder die Eins) und jedes Element hat einen Nachfolger und ist kleiner als sein Nachfolger. Indem man ausgehend vom kleinsten Element immer wieder den Nachfolger bildet, erreicht man schließlich jede natürliche Zahl und sukzessive immer weitere, sodass es ihrer unendlich viele gibt. Die natürlichen Zahlen sind zudem mit Addition und Multiplikation versehen, je zwei natürlichen Zahlen lassen sich damit eine Summe und ein Produkt zuordnen, die wieder natürliche Zahlen sind. Diese Operationen sind assoziativ und kommutativ, zudem sind sie im Sinne des Distributivgesetzes miteinander verträglich: formula_5. Diese drei Eigenschaften sind auch grundlegend für viele allgemeinere Zahlbereiche wie die ganzen, rationalen, reellen und komplexen Zahlen. Die Ordnung der natürlichen Zahlen ist in gewisser Hinsicht mit der Addition und Multiplikation "verträglich": Sie ist "verschiebungsinvariant", d. h. für natürliche Zahlen formula_6 folgt aus formula_7 auch formula_8, zusätzlich zur Verschiebungsinvarianz folgt auch formula_9.

Die Existenz der "Menge aller natürlichen Zahlen" wird in der Mengenlehre durch das Unendlichkeitsaxiom sichergestellt.

Diese Menge wird mit formula_10 oder formula_11 bezeichnet.

In der Menge der natürlichen Zahlen existiert für zwei Zahlen formula_12 keine natürliche Zahl formula_13, sodass formula_14. Die "ganzen Zahlen" erweitern die natürlichen Zahlen so, dass für zwei beliebige Elemente eine solche Zahl formula_13 existiert. Hierzu fügt man die "negativen Zahlen" den natürlichen Zahlen hinzu: Zu jeder natürlichen Zahl formula_16 existiert eine zweite ganze Zahl formula_17, sodass formula_18, welche als "additives Inverses" bezeichnet wird. Die obige Zahl formula_13, genannt "Differenz", ist dann als formula_20, kurz formula_21, gegeben. Hierdurch ist die Subtraktion auf den ganzen Zahlen definiert, welche jedoch im Wesentlichen eine Kurzschreibweise darstellt.

Die Ordnung über den natürlichen Zahlen wird auf die ganzen Zahlen erweitert, hierbei gibt es kein kleinstes Element mehr, dafür hat jedes Element einen Vorgänger und einen Nachfolger (der Vorgänger der formula_22 ist die formula_23, der der formula_23 die formula_25 etc.). Die Verträglichkeit mit der Addition, die Verschiebungsinvarianz, bleibt dabei erhalten. Zudem ist das Produkt von zwei ganzen Zahlen größer Null stets wiederum größer Null.

Die ganzen Zahlen bilden einen Ring.

Die Menge der ganzen Zahlen wird mit formula_26 oder formula_27 bezeichnet.

Ebenso wie die natürlichen Zahlen zu den ganzen Zahlen erweitert werden, um ein additives Inverses und die Subtraktion zu erhalten, erweitert man die ganzen Zahlen zu den rationalen Zahlen, um ein multiplikatives Inverses und die Division zu erhalten. D. h. die rationalen Zahlen enthalten die ganzen Zahlen und zu jeder ganzen Zahl formula_28 fügt man die formula_29 genannte Zahl ("Stammbruch") als multiplikatives Inverses hinzu, sodass formula_30. Zudem soll das Produkt zweier beliebiger rationaler Zahlen definiert sein, allgemein erhält man rationale Zahlen der Form formula_31, genannt "Bruch", wobei eine ganze Zahl formula_32 mit dem Bruch formula_33 identifiziert wird. Für ganze Zahlen formula_34 werden die Brüche formula_35 und formula_36 miteinander identifiziert; diese Identifizierung wird auch als "Erweitern" und "Kürzen" bezeichnet. Somit erhält man eine mit der Multiplikation ganzer Zahlen kompatible Multiplikation und Division.

Mittels der Dezimalbruchdarstellung lässt sich eine mit der Ordnung der ganzen Zahlen kompatible Ordnung definieren, die auch die Verträglichkeit mit Addition und Multiplikation erhält.

Die rationalen Zahlen bilden einen (geordneten) Körper. Die Konstruktion der rationalen Zahlen aus den ganzen Zahlen wird verallgemeinert als Quotientenkörperbildung zu einem Ring.

Die Menge der rationalen Zahlen wird mit formula_37 oder formula_38 bezeichnet. In der (deutschen) Schulmathematik kommt daneben die Bezeichnung formula_39 vor („Menge der (positiven) Bruchzahlen“), wenn die positiven Brüche vor den negativen ganzen Zahlen eingeführt werden.

Mit der Addition und Multiplikation ganzer oder rationaler Zahlen lassen sich sogenannte "Polynomfunktionen" definieren: Jeder ganzen bzw. rationalen Zahl wird dabei eine Summe von Potenzen multipliziert mit konstanten Zahlen ("Koeffizienten") zugeordnet. Etwa einer beliebigen Zahl formula_40 der Wert formula_41 definiert als formula_42. Für viele solcher Polynomfunktionen existiert keine rationale Zahl, sodass der Wert der Polynomfunktion an dieser Stelle gleich Null wird ("Nullstelle"). Fügt man nun Nullstellen bestimmter Polynomfunktionen den rationalen Zahlen hinzu, wobei Multiplikation und Addition wohldefiniert bleiben, erhält man eine "algebraische Erweiterung". Erweitert man die rationalen Zahlen um solche Nullstellen für alle nicht-konstanten Polynome, erhält man die "algebraischen Zahlen". Erweitert man die ganzen Zahlen um Nullstellen für alle nicht-konstanten Polynome, deren Koeffizienten ganzzahlig sind und deren Koeffizient zur höchsten Potenz formula_43 ist, so erhält man die "ganzalgebraischen Zahlen".

Algebraische Erweiterungen werden in der Körpertheorie, insbesondere in der Galois-Theorie, untersucht.

Betrachtet man Probleme wie etwa das Finden von Nullstellen von Polynomfunktionen über den rationalen Zahlen, stellt man fest, dass sich in den rationalen Zahlen beliebig gute "Näherungen" konstruieren lassen: Etwa findet sich bei zahlreichen Polynomfunktionen zu jeder festgelegten Toleranz eine rationale Zahl, sodass der Wert der Polynomfunktion an dieser Stelle höchstens um die Toleranz von der Null abweicht. Zudem kann man die Näherungslösungen so wählen, dass sie „nah beieinander“ liegen, denn Polynomfunktionen sind "stetig" („weisen keine ‚Sprünge‘ auf“). Dieses Verhalten tritt nicht nur bei Nullstellen von Polynomfunktionen auf, sondern auch bei zahlreichen weiteren mathematischen Problemen, die eine gewisse Stetigkeit aufweisen, sodass man dazu übergeht, die Existenz einer Lösung zu garantieren, sobald beliebig gute Näherungen durch nahe beieinander gelegene rationale Zahlen existieren. Eine solche Lösung nennt man dann eine "reelle Zahl". Um die Existenz solcher Lösungen zu zeigen, reicht es zu fordern, dass es zu jeder Menge rationaler Zahlen, die nicht beliebig große Zahlen enthält, unter den reellen Zahlen, die größer oder gleich als all diese Elemente der Menge sind, eine kleinste gibt. Alternativ lassen sich die reellen Zahlen explizit als Folgen von rationalen Zahlen, die sich einander „annähern“, definieren.

Die Menge der reellen Zahlen ist überabzählbar. Daher ist es nicht möglich, jede beliebige reelle Zahl sprachlich eindeutig zu beschreiben.

Die Abgeschlossenheit der reellen Zahlen unter solchen Näherungsprozessen bezeichnet man als Vollständigkeit. Diese erlaubt es, zahlreiche Begriffe aus der Analysis, wie den der Ableitung und den des Integrals, über Grenzwerte zu definieren. Grenzwerte erlauben zudem die Definition zahlreicher wichtiger Funktionen, etwa der trigonometrischen Funktionen (Sinus, Cosinus, Tangens etc.), was über den rationalen Zahlen nicht möglich ist.

Die reellen Zahlen behalten maßgebliche Eigenschaften der Addition, Multiplikation und der Ordnung in den rationalen Zahlen und bilden somit ebenfalls einen geordneten Körper. Sie lassen sich nicht erweitern, ohne diese Eigenschaft oder das archimedische Axiom zu verletzen, also „unendlich kleine strikt positive Zahlen“ einzuführen.

Die Idee des Übergangs von den rationalen zu den reellen Zahlen wird durch verschiedene Konzepte der "Vervollständigung" verallgemeinert.

Die Menge der reellen Zahlen wird mit formula_44 oder formula_45 bezeichnet.

Manche Polynomfunktionen besitzen keine Nullstellen in den reellen Zahlen. Beispielsweise nimmt die Funktion formula_46 für jede reelle Zahl formula_40 einen Wert größer als Null an. Es lässt sich zeigen, dass durch das Hinzufügen einer Zahl formula_48, genannt "imaginäre Einheit", die die Gleichung formula_49 erfüllt, wobei die grundlegenden Eigenschaften der Addition und Multiplikation erhalten bleiben sollen, bereits die reellen Zahlen zu den "komplexen Zahlen" erweitert werden, in denen alle nicht konstanten Polynomfunktionen eine Nullstelle besitzen. Die komplexen Zahlen bilden damit den "algebraischen Abschluss" der reellen Zahlen. Grenzwertprozesse sind in den komplexen Zahlen ebenso möglich wie in den reellen Zahlen, jedoch sind die komplexen Zahlen nicht mehr geordnet. Sie lassen sich als Ebene (zweidimensionaler Vektorraum über den reellen Zahlen) auffassen. Jede komplexe Zahl lässt sich eindeutig in der Form formula_50 „darstellen“, wobei formula_51 und formula_52 reelle Zahlen sind und formula_48 die imaginäre Einheit bezeichnen.

Die "Funktionentheorie" ist das Teilgebiet der Analysis, das sich mit den analytischen Eigenschaften von Funktionen über den komplexen Zahlen befasst.

Die Menge der komplexen Zahlen wird mit formula_54 oder formula_55 bezeichnet.

Die Ordinal- und Kardinalzahlen sind Konzepte aus der Mengenlehre. In der Mengenlehre definiert man die Kardinalität einer Menge als Kardinalzahl, die Kardinalität ist eine Verallgemeinerung des Konzepts der „Anzahl der Elemente“ einer endlichen Menge auf unendliche Mengen. Die Kardinalitäten endlicher Mengen sind somit natürliche Zahlen, welche auch in den Kardinalzahlen enthalten sind.

Ordinalzahlen verallgemeinern das Konzept der „Position in einer (wohlgeordneten) Menge“ auf unendliche Mengen. Ordinalzahlen beschreiben dann eindeutig die Position eines Elementes in einer solchen Wohlordnung. Die Ordinalzahlen sind selbst wohlgeordnet, sodass die Reihenfolge von wohlgeordneten Objekten der Reihenfolge der ihnen zugeordneten „Positionen“ (also Ordinalzahlen) entspricht. Für Positionen in Anordnungen endlich vieler Objekte lassen sich natürliche Zahlen verwenden, welche den "kleinsten" Ordinalzahlen entsprechen.

Kardinalzahlen werden heutzutage als spezielle Ordinalzahlen definiert, wodurch sie ebenfalls eine Ordnung erhalten. Neben der Ordnung sind auf Kardinalzahlen und Ordinalzahlen auch Addition, Multiplikation und Potenzierung definiert, welche eingeschränkt auf die natürlichen Zahlen mit den üblichen Begriffen für natürliche Zahlen übereinstimmen, siehe hierzu Kardinalzahlarithmetik und transfinite Arithmetik.

Sowohl die Ordinalzahlen als auch die Kardinalzahlen bilden echte Klassen, das heißt, sie sind im Sinne der modernen Mengenlehre keine Mengen.

Die hyperreellen Zahlen sind eine Verallgemeinerung der reellen Zahlen und Untersuchungsgegenstand der Nichtstandardanalysis. Diese erlauben die Definition von Begriffen aus der Analysis wie die der Stetigkeit oder der Ableitung ohne die Verwendung von Grenzwerten.

Die komplexen Zahlen lassen sich als zweidimensionaler Vektorraum über den reellen Zahlen auffassen (siehe Gaußsche Zahlenebene), das heißt als zweidimensionale Ebene, bei der neben der üblichen koordinatenweisen Addition eine Multiplikation zwischen zwei Punkten der Ebene definiert ist. Es gibt zahlreiche ähnliche Strukturen, die man unter dem Begriff "hyperkomplexe Zahlen" zusammenfasst. Diese Strukturen sind in der Regel endlichdimensionale Vektorräume über den reellen Zahlen (vorstellbar als zwei- oder höherdimensionaler Raum) mit einer zusätzlichen Multiplikation. Oftmals lassen sich die reellen Zahlen selbst in diese Strukturen einbetten, wobei die Multiplikation eingeschränkt auf die reellen Zahlen der üblichen Multiplikation von reellen Zahlen entspricht.


In der Mathematik spricht man mittels der Sprache der Logik über in dieser definierte mathematische Objekte wie etwa Zahlen, mit ihr lassen sich auch konkrete Zahlen mitunter eindeutig beschreiben, unter Umständen mittels Formeln. Über die gängigen logischen Formalismen hinaus existieren jedoch systematische Bezeichnungen für bestimmte Zahlen, etwa in Form von speziellen Kombinationen von Schriftzeichen (mitunter eigens dafür verwendete "Ziffern") oder mittels besonders konstruierter Wörter der natürlichen Sprache, wie etwa Numerale. Bezeichnungen für bestimmte Zahlen werden außerhalb der Mathematik verwendet, um konkrete Beobachtungen zu beschreiben, etwa eine Anzahl beobachteter Objekte ("Ich sehe fünf Bananen") oder mittels eines anderen Messverfahrens bestimmte Messwerte ("Der Türrahmen ist zwei Meter hoch"). Des Weiteren erlauben solch systematische Zahldarstellungen mitunter einfaches, systematisches Rechnen mit konkreten Zahlen – gerade auch durch Rechenmaschinen und Computer. Die Rechenverfahren zur Berechnung gewisser Operationen zwischen konkreten Zahlen hängen stark von der gewählten Darstellung ab.

In der Kultur- und Mathematikgeschichte haben sich zahlreiche "Zahlensysteme" zu solchen systematischen Zahldarstellungen entwickelt. Belege für die Darstellung von Zahlen reichen bis in die späte Steinzeit zurück, wobei Schwierigkeiten bestehen, Zahlzeichen von bloßen Zählzeichen zu unterscheiden, das heißt zu erkennen, ob den Menschen Zahlen als abstrakte Bedeutung jener bewusst waren, oder nur eine werkzeugartige Verwendung vorlag, bei denen die physische Konstruktion des Zählzeichens, nicht aber eine Bedeutung relevant war, seine Aufgabe zu erfüllen. Zu dieser Problematik siehe etwa den Artikel zum Ishango-Knochen, einem Fund aus der späten Altsteinzeit, der verschiedenartige Interpretationen zulässt.

Beispiele für solche Darstellungen sind Strichlisten (Unärsystem) und die Ziffernfolgen verwendenden Stellenwertsysteme, wie sie heute für die Darstellung natürlicher Zahlen üblich sind und auch für die Zahldarstellung in Computern in Form des Dualsystems verwendet werden.

Betrachtet man sprachliche Darstellungen von Zahlen formal, so lässt sich nicht jeder Zahl eine solche Darstellung in einem formalen Sinne zuordnen, d. h. in einem mathematischen formalen Sinne existieren "mehr" Zahlen als mögliche Darstellungen in einer Sprache: Da sprachliche Formulierungen stets endlich sind, kann es von ihnen nur abzählbar viele verschiedene geben, während die Mathematik auch überabzählbare Zahlbereiche betrachtet. Man spricht dennoch auch von Darstellungen überabzählbarer Zahlbereiche, wenn man sich bei solchen formalen Darstellungen nicht mehr auf zu sprachlichen Formulierungen korrespondierende beschränkt, in ihrer Struktur können sie jedoch den Zahlensystemen ähneln, etwa lassen sich die reellen Zahlen als spezielle formale Reihen definieren, welche der Darstellung in Stellenwertsystemen strukturell ähneln.

Einige Beispiele für Darstellungen von Zahlen:

Ebenso wie Zahlen sprachliche Ausdrücke, Zeichenketten oder der gleichen zugeordnet werden, können umgekehrt Zahlen bestimmten Objekten zugeordnet werden, zum einen für abstrakte Überlegungen, zum anderen, um Darstellungen von Zahlen konkret zur systematischen Bezeichnung von anderen Objekten einzusetzen, etwa Information mittels Zahlen zu kodieren. Ein solches Vorgehen erlaubt die Anwendung von den auf Zahlen definierten Operationen auf diese Bezeichnungen. Ein verbreitetes Beispiel ist die Nummerierung, bei der jedem Objekt einer bestimmten betrachteten Gesamtheit eine (meist natürliche) Zahl zugeordnet wird: Dies erlaubt zum einen die Benennung der Objekte mittels ihrer Nummern, und schafft zum anderen mittels der auf den natürlichen Zahlen definierten Ordnung („kleiner“) eine Ordnung der Objekte, dies erlaubt etwa im Falle natürlicher Zahlen ein sequentielles Durchgehen aller Objekte. Zu beachten ist, dass nicht jede Nummer eine Zahl als von der Darstellung unabhängiges mathematisches Objekt ist. Manche Nummern sind als spezielle Symbolfolgen zu verstehen, die als Identifikatoren dienen, selbst wenn sie nur aus Ziffern bestehen (z. B. ISB- oder Hausnummern).

Ein anderes Beispiel ist die Interpretation digitaler Information in der Datenverarbeitung: Als binäre Folge vorliegende Daten können auf natürliche Weise als natürliche Zahl, dargestellt im Dualsystem, interpretiert werden (Randfälle wie führende Nullen müssen dabei natürlich beachtet werden). Arithmetische Operationen über dieser Kodierung als Zahl werden u. a. in der Kryptographie und der Datenkompression eingesetzt.

Auch in der reinen Mathematik finden sich Anwendungen dieses Prinzips, wobei üblicherweise nicht als Zahlen aufgefassten mathematischen Objekten Zahlen zugeordnet werden, etwa in Form von Gödelnummern, welche logische Formeln oder Algorithmen identifizieren.

Weitere Beispiele sind die Repräsentation von Spielsituationen mittels surrealer Zahlen in der Spieltheorie, die Darstellung von Drehstreckungen im zweidimensionalen euklidischen Raum durch komplexe Zahlen sowie Drehungen im Dreidimensionalen mittels Quaternionen.

Man geht davon aus, dass das Zahlenverständnis durch eine längere Entwicklung durch immer weitere graduelle Abstraktion entstanden ist, ausgehend von der Unterscheidung von Anzahlen von Gegenständen der Wahrnehmung: So gibt es die einfache Fähigkeit, einen einzelnen von mehreren zu unterscheiden. Weitergehend lassen sich verschiedene Anzahlen von gleichen Anzahlen (jeder Gegenstand in der einen Gruppe kann einem in der anderen zugeordnet werden) und kleinere von größeren Anzahlen unterscheiden. Derlei Fähigkeiten finden sich in Teilen des Tierreichs in je nach Spezies sehr unterschiedlichem Ausmaß (insbesondere unter den Vögeln und Säugetieren). Die Theorie von einem solchen graduellen Übergang wird durch die Grammatik mancher Sprachen unterstützt, in denen Singular, Dual (im Deutschen nicht mehr vorhanden) und Plural unterschieden werden. Die Sprachen einiger Völker verfügen noch heute über kein ausgeprägtes System von Zahlwörtern. Beim Stamm der Pirahã etwa wurden zwar gewisse Fähigkeiten zum Umgang mit Größen von Mengen festgestellt, es ließ sich jedoch kein Vorhandensein eines Verständnisses von Zahlen in dem Sinne feststellen, dass Anzahlen geistig erfasst worden wären. In der Sprache der Pirahã sind lediglich drei Wörter für relative Größenangaben bekannt, selbst ein Wort für die "Eins" scheint zu fehlen, während das Konzept jedoch anscheinend auch ohne bekannte sprachliche Repräsentation verstanden wird. Versuche, manchen Vertretern des Volks das Zählen beizubringen, schlugen fehl.

Ein genauer Zeitpunkt, seit wann in der Menschheitsgeschichte ein Zahlenverständnis besteht, lässt sich nicht angeben. Die Einkerbungen im vermutlich über 30.000 Jahre alten Ishango-Knochen und ähnlichen Funden werden mitunter als Zahlzeichen interpretiert. Eine Problematik bei solchen frühen Funden besteht darin, zu beurteilen, ob den Einkerbungen tatsächlich eine Betrachtung von Zahlen als abstrakten Objekten zugrunde liegt, oder ob es sich lediglich um Zählzeichen handelt: Im letzteren Fall dienen die Einkerbungen lediglich als eine Art Werkzeug, um Anzahlen zu vergleichen: Durch Abgleich jeder Kerbe mit einem Objekt lässt sich etwa eine bestimmte Menge abzählen. Zahlen kommen jedoch erst dann ins Spiel, wenn Anzahlen unabhängig von der konkreten Realisierung in Kerben o. ä. betrachtet werden. Der Mathematikhistoriker Hans-Ludwig Wußing geht davon aus, dass abstrakte Zahlenbegriffe erst nach der Sesshaftwerdung, frühestens vor etwa 6.000 Jahren in den frühen Hochkulturen erstmals in Erscheinung traten. Klarer Hinweis für eine solche Abstraktion ist die Verwendung von Zahlensystemen, die über das Unärsystem, d. h. einfache Strichlisten, hinausgehen. Ob eine solche beim Ishango-Knochen vorliegt, ist umstritten. Der heutige Mensch ist die einzige Art, bei dem ein Zahlenverständnis allgemein wissenschaftlich anerkannt nachgewiesen werden konnte.

Im alten Ägypten fand mindestens seit ca. 3.000 v. Chr. ein additives Zahlensystem zur Basis 10 Verwendung zur Darstellung natürlicher Zahlen. Dort wurden die Grundrechenarten der Addition, Subtraktion, Multiplikation und Division bereits betrieben. Für die ersteren beiden gab es auch besondere Schriftzeichen. Besonders bedeutsame Zeugnisse mathematischer Fähigkeiten dieser Kultur sind der Moskauer Papyrus und der Papyrus Rhind – beide in hieratischer Schrift verfasst in der Zeit zwischen 2000 v. Chr. und 1800 v. Chr. Aus diesem lässt sich über die natürlichen Zahlen hinausgehend eine besondere Notation für Stammbrüche entnehmen. Andere Verhältnisse wurden systematisch in Summen von Stammbrüchen überführt (formula_77 besaß jedoch auch ein eigenes Zeichen). Motivation der altägyptischen Mathematik waren dabei meist Bauwesen, Landvermessung und Wirtschaft, Beweise finden sich nicht. Jedoch finden sich zum Teil auch Probleme, die als humorvoll oder unterhaltsam intendiert interpretiert werden.

Ebenfalls gibt es reichhaltige mathematische Zeugnisse aus dem Mesopotamien des Altertums. In sumerischer Zeit entwickelte sich dort ein additives Zahlensystem basierend auf den Basen 10 und 60. Aus altbabylonischer Zeit zwischen 1.800 und 1.600 v. Chr. gibt es besonders zahlreiche Funde mit weitergehenden Errungenschaften: Es entstand ein sexagesimales Stellenwertsystem, jedoch mit der Einschränkung, dass es keine Ziffer Null gab und die Notation daher uneindeutig war. Innerhalb dieses Systems wurden auch allgemeinere rationale Zahlen in einer der heute gebräuchlichen Dezimalbruchentwicklung entsprechenden Weise dargestellt, d. h. es konnten etwa formula_78- und formula_79-Stellen gebraucht werden. Auf diese Weise nicht darstellbare Brüche oder (in moderner Sprechweise) Logarithmen, wie sie bei der Zinsrechnung auftraten, wurden näherungsweise dargestellt. In Gestalt des babylonischen Wurzelziehens wurden auch systematische Approximationen vorgenommen. Zudem wurden Lösungen für quadratische, kubische und biquadratische Gleichungen gefunden. Diese Gleichungen wurden mit geometrischen Begriffen beschrieben (ein in moderner Sprechweise in solchen Gleichungen auftretendes Quadrat wurde als Flächeninhalt beschrieben, von dem etwa eine Seitenlänge subtrahiert wird, dass als Flächeninhalte und als Längen bezeichnete Größen addiert werden konnten, legt jedoch ein recht abstraktes, algebraisches Verständnis nahe). Diese Errungenschaften entstammten praktischen Bedürfnissen der Wirtschaft, des Bauwesens und der Astronomie.

Aus dem antiken Griechenland sind eine Vielzahl mathematischer Erkenntnisse überliefert. Erstmals (soweit bekannt) kam es hier zu einem ausgeprägten Verständnis von Beweisen, durch die die Ergebnisse in einer der heutigen Mathematik nahekommenden Strenge bewiesen wurden. Eine besondere Bedeutung hatte ab dem 6. Jahrhundert v. Chr. die Schule der Pythagoreer, gegründet von Pythagoras von Samos (ca. 570–510 v. Chr.), welcher vermutlich durch Reisen nach Ägypten, Mesopotamien und evtl. auch Indien beeinflusst war. In dieser religiösen Gruppierung trennte sich die Mathematik vom aus den Notwendigkeiten des Alltags entspringenden Rechnen, wobei (natürliche) Zahlen eine zentrale Rolle spielten. Die Überlieferungslage bezüglich dieser Zeit der Mathematikgeschichte, den mutmaßlich etwas früher lebenden Thales von Milet mit eingeschlossen, ist allerdings noch sehr dünn, die meisten Dokumente stammen aus späterer Zeit, sodass sich nicht sicher sagen lässt, welche Konzepte dort schon bekannt waren und mit welcher Methodik verfahren wurde.

Aus nicht vollständig geklärten Gründen legte die darauffolgende griechische Mathematik einen großen Wert auf die Geometrie, trotz des Einflusses der Pythagoreer, unter denen die Arithmetik als grundlegend aufgefasst worden war. Bedeutende Protagonisten waren hier Eudoxos von Knidos (* zw. ca. 397 und 390 v. Chr., † zw. ca. 345 und 338 v. Chr.) und Euklid (ca. 360–280 v. Chr.).

Bezüglich des Zahlbegriffs der Griechen muss festgestellt werden, dass sie nicht über ein Konzept rationaler Zahlen als algebraische Objekte oder Erweiterung der natürlichen Zahlen verfügten. Die aus moderner Sicht oft als Aussagen über solche interpretierten Ergebnisse wurden geometrisch als Aussagen über Längen- und Flächenverhältnisse formuliert: Eine Länge oder Fläche konnte ein ganzzahliges Vielfaches einer anderen sein, dementsprechend lassen sich Verhältnisse zwischen zwei solchen Vielfachen einer Länge oder Fläche im heutigen Verständnis als (positive – mit negativen Zahlen vergleichbare Konzepte waren nicht vorhanden) rationale Zahlen beschreiben, im griechischen Verständnis von Zahlen waren sie jedoch nicht enthalten. Erst recht gab es keine irrationalen "Zahlen" in der griechischen Mathematik – es traten lediglich geometrische Verhältnisse auf, die keinem Verhältnis von zwei ganzzahligen Vielfachen einer Größe entsprachen; man spricht von "Inkommensurabilität". Selbst die Eins wurde bei Euklid nicht zu den Zahlen gezählt.

Die Existenz der inkommensurablen Verhältnisse war spätestens seit Aristoteles (384–322 v. Chr.), welcher einen recht allgemeinen Beweis lieferte, womöglich aber schon vor 400 v. Chr. in Griechenland bekannt. Dies zeigte die Unmöglichkeit des pythagoreischen Ansatzes, die in der Geometrie auftretenden Verhältnisse mittels der Arithmetik zu beschreiben – in heutiger Begrifflichkeit eine Unzulänglichkeit der rationalen Zahlen. Der Übergang zu einer geometrischen Grundlegung, die den Umgang mit solchen Verhältnissen erlaubte, wird maßgeblich auf Eudoxos zurückgeführt, welcher selbst noch Schüler des bedeutenden Pythagoreers Archytas von Tarent gewesen war, welcher die Arithmetik als einzige mögliche Grundlage für Beweise ansah.

Eudoxos lieferte eine Definition der Gleichheit zweier geometrischer Verhältnisse (von Längen oder Flächen): Zwei Verhältnisse sind demzufolge gleich, wenn alle – in moderner Interpretation – rationalen Verhältnisse, die kleiner bzw. größer sind als das eine Verhältnis, auch kleiner bzw. größer sind als das andere. Diese Definition gilt sogar analog für den heutigen Begriff der reellen Zahlen. Einige Stimmen sahen oder sehen hierin bereits ein Vorhandensein der reellen Zahlen in der griechischen Mathematik. Diese Aussagen sind jedoch problematisch: Zum einen war eben nicht einmal das Konzept der rationalen Zahlen vorhanden, zum anderen wurde nichts darüber ausgesagt, dass bestimmte Verhältnisse existieren, sodass diese etwa ordnungsvollständig sind, sondern vielmehr durch die Geometrie "gegebene" Verhältnisse untersucht. In jedem Fall ermöglichte diese Definition eine Vielzahl von Beweisen, deren Techniken wie die Exhaustionsmethode als Vorläufer heutiger Begriffe der Analysis gelten, wobei gewisse Abschätzungen bereits eine zentrale Rolle spielten. Zudem war Richard Dedekind bei seiner Definition der reellen Zahlen eigenen Angaben zufolge durch Eudoxos inspiriert.
Archimedes von Syrakus (287–212 v. Chr.), welcher aufbauend auf Eudoxos besonders weitreichende Beweise für bestimmte geometrische Verhältnisse sowie bestimmte Näherungen lieferte, gilt auch als erste Person, die infinitesimale Größen einführte: Im Archimedes-Palimpsest wandte er ein Prinzip vergleichbar dem Prinzip von Cavalieri an, bei dem eine Fläche in unendlich viele "infinitesimale" Linien zerlegt wird. Eine solche Vorgehensweise entsprach schon damals nicht den Ansprüchen an einen mathematischen Beweis, Archimedes sah in diesem mechanisch motivierten Verfahren jedoch ein nützliches Werkzeug, um an ein Problem heranzugehen und später einfacher einen korrekten Beweis finden zu können. Die Existenz von von Null verschiedenen infinitesimalen Größen widerspricht der Definition des Eudoxos von Gleichheit und auch dem von Archimedes selbst aufgestellten sogenannten "Archimedischen Axiom".





</doc>
<doc id="5820" url="https://de.wikipedia.org/wiki?curid=5820" title="Zytostatikum">
Zytostatikum

Zytostatika (oder Cytostatika, vom griechischen "Cyto" = Zelle und "statik" = anhalten, Singular: Zytostatikum) sind natürliche oder synthetische Substanzen, die das Zellwachstum beziehungsweise die Zellteilung hemmen. Sie werden vor allem zur Behandlung von Krebs (Chemotherapie), teilweise auch bei der Behandlung von Autoimmunerkrankungen eingesetzt.

Neben den klassischen Zytostatika werden heute in der Behandlung von Tumorerkrankungen auch weitere Substanzen wie zum Beispiel Hormone, therapeutische monoklonale Antikörper, Zytokine und sogenannte „small molecules“ wie zum Beispiel Signaltransduktions-Inhibitoren, Proteaseinhibitoren etc. eingesetzt. Diese Substanzen werden meist nicht als Zytostatika bezeichnet, da sie nicht "direkt" die Zellteilung beziehungsweise das Zellwachstum hemmen. Monoklonale Antikörper und Zytokine sind beispielsweise Krebsimmuntherapeutika.

Die Wirksamkeit von Zytostatika (Chemosensitivität) können durch Chemosensitivitätstests ex vivo vor Beginn einer Chemotherapie bewertet werden.

Während des Ersten Weltkriegs stellten Ärzte fest, dass der Kampfstoff Schwefel-Lost (Senfgas) antiproliferative (wachstumshemmende) Wirkung hat. Nach dem Krieg wurde der weniger giftige Stickstoff-Lost (= Mechlorethamin) entwickelt und um 1942 als erstes Zytostatikum in der Medizin eingesetzt. Bis heute ist Stickstoff-Lost in den USA zugelassen, und seine Derivate sind in zahlreichen modernen Behandlungsschemata enthalten.

Die zytostatische Wirkung der Platinkomplexe wurde 1965 zufällig bei einem Versuch mit Zellkulturen und einer Platinelektrode entdeckt.

Andere Substanzen wie Mitotan und die Vinca-Alkaloide wurden in der Pharmaindustrie in ganz anderen Bereichen entwickelt, fielen jedoch beim Tierversuch durch ihr wachstumshemmendes Potenzial auf.

Zytostatika stören die Stoffwechselvorgänge, die im Zusammenhang mit Zellwachstum oder Zellteilung stehen. Daher schädigen sie vor allem schnell wachsende Zellen wie Epithelzellen (unter anderem Haarwurzelzellen, Schleimhautepithel von Mund und Magen-Darm-Trakt). Da Tumorzellen eine erhöhte Zellteilungsrate und eine eingeschränkte Reparaturkapazität haben, sind sie etwas empfindlicher gegenüber Zytostatika als gesunde Zellen. Dieser Unterschied ermöglicht erst die Therapie mit diesen häufig hochtoxischen Substanzen.

Da die Giftwirkung auch gesunde Zellen beeinträchtigt, kommt es zu vielerlei negativen Begleiterscheinungen. Insbesondere die Schleimhaut des Magen-Darmtraktes und das blutbildende Knochenmark sind empfindlich. Fast alle Zytostatika verursachen in unterschiedlichem Ausmaß vorübergehenden Haarausfall, Übelkeit und Erbrechen sowie eine Verminderung der weißen und/oder roten Blutkörperchen im Blut (Myelosuppression). Darüber hinaus haben die einzelnen Wirkstoffgruppen noch weitere, unterschiedliche Nebenwirkungen, z. B. auf das zentrale Nervensystem. Einige Zytostatika sind selbst karzinogen (krebserregend) und mutagen (keimbahnschädigend).

Obwohl heutzutage komplexe Begleitbehandlungen zu den Zytostatika eingesetzt werden, muss noch immer ein Teil der Therapien dosisreduziert, unterbrochen oder gar abgebrochen werden.

Die WHO-Einteilung der Nebenwirkungen in Schweregrade richtet sich nach den Maßnahmen, die im Einzelfall getroffen wurden:


Der als Nebenwirkung häufig auftretende Symptomkomplex der subjektiven Ermüdung einiger mit Zytostatika behandelter Patienten, ausgelöst durch oben genannte Veränderungen des Blutbildes, wird als Fatigue bezeichnet.

Der Verbrauch an Zytostatika steigt. Verbesserte und individuell angepasste Therapien mit optimierter Begleitmedikation und geringeren Nebenwirkungen verbessern die Verträglichkeit und ermöglichen längere Therapiezeiträume. Wir werden immer älter. Die Wahrscheinlichkeit von Krebserkrankungen und -behandlungen steigen. Damit erhöht sich die Umweltrelevanz durch nicht abgebaute zytostatisch aktive Wirkstoffe sowie Stoffwechsel- und Umwandlungsprodukte. Bereits in den achtziger Jahren wurde erstmals Methotrexat im Abwasser einer onkologischen Klinik nachgewiesen. Laborexperimente zeigten, dass unterschiedliche Zytostatika nicht biologisch abbaubar sind. Cyclophosphamid, Ifosfamid, Cisplatin und Mitomycin erwiesen sich als resistent. 

Bei Forschungsprojekten und Untersuchungsprogrammen der Bundesländer stellten Wissenschaftler mehr als 150 unterschiedliche Arzneimittelrückstände in Umweltproben fest. Über die aerobe und anaerobe Abbaubarkeit von Zytostatika in Kläranlagen und die Wirkung auf aquatische Organismen – u. a. in Bezug auf Stoffwechselprozesse, Erbgutschädigung und Fortpflanzungsgefährdung – ist insgesamt noch zu wenig bekannt.

Alkylantien (Alkylanzien) sind die ältesten Zytostatika. Sie können Alkylgruppen auf die DNA übertragen. Da die Alkylantien mit zwei oder mehr "funktionellen Gruppen" versehen sind, können sie zwei DNA-Stränge vernetzen und dadurch verhindern, dass diese während der Zellteilung korrekt verdoppelt werden. Die Wirkung beruht also auf einer Hemmung der DNA-Replikation. Alkylantien sind mutagen und karzinogen. Ihre Hauptnebenwirkungen sind Übelkeit, Anämie und Immunschwächung. Sie werden bei Lymphomen, Leukämie, Brust- und Lungenkrebs sowie bei Sarkomen noch oft eingesetzt. Besondere Bedeutung haben sie gegen bösartige Hirntumore.





Der Komplex cis-[Pt(NH)Cl] = Cisplatin und seine Verwandten gehören zu den wirksamsten Chemotherapeutika überhaupt. Sie verursachen ebenfalls Quervernetzungen der DNA durch kovalente Bindung des Platinatoms an zwei Nukleinbasen. Platine verursachen Übelkeit, Anämie, Gehör-, Nerven- und Nierenschäden. Ihr Haupteinsatzgebiet sind Hoden-, Gebärmutter- und Eierstockkrebs sowie Tumoren der Halsregion. Ein neueres Platin-Analogon, Oxaliplatin, wird derzeit bei Darmkrebs eingesetzt.


Interkalantien binden nichtkovalent an die DNA und verhindern die Anbindung der Polymerasen, welche zur Replikation und Transkription der Erbsubstanz dienen. Das heißt, Zellteilung und Zellfunktion werden gestört. Die Substanzen werden wegen der geringen Rate an resistenten Tumoren sehr oft und bei fast allen soliden Tumoren eingesetzt; sie eignen sich auch als Mono-Therapie bei Patienten, die starkwirksame Kombinationen nicht vertragen. Übelkeit und Anämie sowie verschiedene Organschäden sind ihre häufigsten Nebenwirkungen.



Die Vertreter dieser Substanzgruppe mit antibakterieller und gleichzeitig zytostatischer Wirkung wurden aus Pilzen isoliert. Die Wirkmechanismen sind unterschiedlich, meist DNA-Vernetzung durch Interkalation oder Alkylierung. Es sind vorwiegend Peptide, daher können bei der Anwendung allergische Reaktionen auftreten. Weitere Nebenwirkungen sind Lungen- oder Leberschäden. In Protokollen gegen Hodenkrebs, Blasenkrebs und maligne Lymphome sind oft Antibiotika vertreten.


Diese Stoffe binden an das Tubulin, ein Eiweißmakromolekül, welches zur Zellteilung (siehe Mitose) notwendig ist. Der Einsatz ist bei Lymphomen und Leukämien, seltener bei soliden Tumoren üblich. Ihre unangenehmste Nebenwirkung ist eine Schädigung des Nervensystems.


Eine relativ neue Substanzgruppe, obwohl sie bereits in den 1960er Jahren am "National Cancer Institute" in den USA durch ein systematisches Screening von 35.000 Pflanzengattungen entdeckt wurde, und zwar in der Pazifischen Eibe ("Taxus brevifolia"). Erst seit sie synthetisch hergestellt werden können (1994), finden Taxane zunehmende Verbreitung bei Brust-, Prostata- und Lungenkrebs und beim Hautkrebs, oft als Monotherapie. Die Wirkung beruht auf der Bildung von anormalen Molekülen im Zellskelett, was die geordnete Zellteilung verhindert.


Die Topoisomerasen I und II sind Enzyme, welche gezielte, reversible Unterbrechungen im DNA-Strang herstellen. Die Hemmung bewirkt irreguläre, nichtbehebbare DNA-Brüche und spontane Vernetzungen. Diese neue Substanzklasse ist vielversprechend bei soliden Tumoren, Lymphomen, Hirntumoren und kindlichen Tumoren. Ihre Neigung zur Knochenmarksdepression (Anämie) ist allerdings gefürchtet.



Antimetabolite werden als falsche Bausteine in die DNA oder RNA eingebaut oder verhindern den Einbau der korrekten Bausteine, und stören so die Zellteilung und den Stoffwechsel. Ihre Nebenwirkungen sind Übelkeit und Anämie sowie Nierenschäden.

Darm- und Brustkrebs und viele andere solide Tumoren sowie Leukämie sind die Einsatzgebiete für Antimetaboliten. Man vermutet, dass die Empfindlichkeit der Zellen gegenüber Strahlung gesteigert wird. 5-Fluoruracil ist aus diesem Grund die wichtigste Substanz in der Radiochemotherapie.










</doc>
<doc id="5821" url="https://de.wikipedia.org/wiki?curid=5821" title="Zermelo-Fraenkel-Mengenlehre">
Zermelo-Fraenkel-Mengenlehre

Die Zermelo-Fraenkel-Mengenlehre ist eine verbreitete axiomatische Mengenlehre, die nach Ernst Zermelo und Abraham Adolf Fraenkel benannt ist. Sie ist heute Grundlage fast aller Zweige der Mathematik. Die Zermelo-Fraenkel-Mengenlehre ohne Auswahlaxiom wird durch ZF abgekürzt, mit Auswahlaxiom durch ZFC (wobei das C für das engl. Wort "choice", also Auswahl oder Wahl steht).

Die Zermelo-Fraenkel-Mengenlehre ist eine Erweiterung der Zermelo-Mengenlehre von 1907, die auf Axiomen und Anregungen von Fraenkel von 1921 beruht. Fraenkel ergänzte das Ersetzungsaxiom und plädierte für reguläre Mengen ohne zirkuläre Elementketten und für eine reine Mengenlehre, deren Objekte nur Mengen sind. Zermelo komplettierte 1930 das Axiomensystem der Zermelo-Fraenkel-Mengenlehre, das er selbst als ZF-System bezeichnete: Er nahm das Ersetzungsaxiom Fraenkels auf und fügte das Fundierungsaxiom hinzu, um zirkuläre Elementketten auszuschließen, wie es Fraenkel forderte. Das originale ZF-System ist verbal und kalkuliert auch Urelemente ein, die keine Mengen sind. Auf solche Urelemente verzichten spätere formalisierte ZF-Systeme meist und setzen damit Fraenkels Ideen vollständig um. Die erste präzise prädikatenlogische Formalisierung der reinen ZF-Mengenlehre schuf Thoralf Skolem 1929 (noch ohne Fundierungsaxiom). Diese Tradition hat sich durchgesetzt, so dass heute das Kürzel ZF für die reine Zermelo-Fraenkel-Mengenlehre steht. Die dem originalen ZF-System näherstehende Version mit Urelementen wird heute aber auch noch gebraucht und zur klaren Unterscheidung als ZFU bezeichnet.

Es hat sich gezeigt – dies ist eine empirische Feststellung –, dass sich "so gut wie alle bekannten mathematischen Aussagen" so formulieren lassen, dass sich beweisbare Aussagen aus ZFC ableiten lassen. Die ZFC-Mengenlehre ist daher ein bewährter und weithin akzeptierter Rahmen für die ganze Mathematik geworden. Ausnahmen finden sich überall dort, wo man mit echten Klassen arbeiten muss oder will. Man benutzt dann gewisse Erweiterungen von ZFC, die Klassen oder zusätzliche sehr große Mengen zur Verfügung stellen, etwa eine Erweiterung zur ZFC-Klassenlogik oder die Neumann-Bernays-Gödel-Mengenlehre oder ein Grothendieck-Universum. In jedem Fall wird ZFC heute aber als "das" grundlegende Axiomensystem für die Mathematik angesehen.

Wegen der grundlegenden Bedeutung der ZFC-Mengenlehre für die Mathematik wurde seit 1918 im Rahmen des Hilbert-Programms ein Widerspruchsfreiheitsbeweis für die Mengenlehre gesucht. Gödel, der sich mit wichtigen Beiträgen an diesem Programm beteiligte, konnte aber 1930 in seinem Zweiten Unvollständigkeitssatz zeigen, dass ein solcher Widerspruchsfreiheitsbeweis im Rahmen einer widerspruchsfreien ZFC-Mengenlehre unmöglich ist. Die Annahme der Widerspruchsfreiheit von ZFC bleibt daher eine durch Erfahrung gehärtete Arbeitshypothese der Mathematiker:

ZF hat unendlich viele Axiome, da zwei Axiomenschemata (8. und 9.) verwendet werden, die zu jedem Prädikat mit bestimmten Eigenschaften je ein Axiom angeben. Als logische Grundlage dient die Prädikatenlogik der ersten Stufe mit Identität und dem undefinierten Elementprädikat formula_1.

1. "Extensionalitätsaxiom": Mengen sind genau dann gleich, wenn sie dieselben Elemente enthalten.

2. "Leermengenaxiom", veraltet "Nullmengenaxiom": Es gibt eine Menge ohne Elemente.

3. "Paarmengenaxiom": Für alle formula_6 und formula_4 gibt es eine Menge formula_8, die genau formula_6 und formula_4 als Elemente hat.

4. "Vereinigungsaxiom:" Für jede Menge formula_6 gibt es eine Menge formula_4, die genau die Elemente der Elemente von formula_6 als Elemente enthält.

5. "Unendlichkeitsaxiom:" Es gibt eine Menge formula_6, die die leere Menge und mit jedem Element formula_25 auch die Menge formula_26 enthält (vgl. "Induktive Menge").

6. "Potenzmengenaxiom:" Für jede Menge formula_6 gibt es eine Menge formula_30, deren Elemente genau die Teilmengen von formula_6 sind.

7. "Fundierungsaxiom" oder "Regularitätsaxiom:" Jede nichtleere Menge formula_6 enthält ein Element formula_4, so dass formula_6 und formula_4 disjunkt sind.

8. "Aussonderungsaxiom:" Hier handelt es sich um ein Axiomenschema mit je einem Axiom zu jedem Prädikat formula_30: Zu jeder Menge formula_6 existiert eine Teilmenge formula_4 von formula_6, die genau die Elemente formula_8 von formula_6 enthält, für die formula_53 wahr ist.

9. "Ersetzungsaxiom" (Fraenkel): Ist formula_6 eine Menge und wird jedes Element von formula_6 eindeutig durch eine beliebige Menge ersetzt, so geht formula_6 in eine Menge über. Die Ersetzung wird präzisiert durch zweistellige Prädikate mit ähnlichen Eigenschaften wie eine Funktion, und zwar als Axiomenschema für jedes solche Prädikat:

In der Mathematik wird häufig auch das Auswahlaxiom benutzt, das ZF zu ZFC erweitert:

10. "Auswahlaxiom:" Ist formula_6 eine Menge von paarweise disjunkten nichtleeren Mengen, dann gibt es eine Menge, die genau ein Element aus jedem Element von formula_6 enthält. Dieses Axiom hat eine komplizierte Formel, die mit dem Eindeutigkeitsquantor formula_68 etwas vereinfacht werden kann:

Zermelo formulierte das originale ZF-System für Mengen und Urelemente. Mengen definierte er als elementhaltige Dinge oder die Nullmenge. Urelemente sind dann Dinge ohne Elemente, und zwar betrachtete er die Nullmenge als ausgezeichnetes Urelement, das als gegebene Konstante formula_5 die ZF-Sprache erweitert. Mengen und Urelemente sind damit präzise definierbar:

Von der üblichen reinen ZF-Mengenlehre wird die Mengenlehre mit Urelementen unterschieden durch angehängtes U. Die Axiome von ZFU und ZFCU lauten abgesehen vom Leermengenaxiom verbal wie die Axiome von ZF oder ZFC, werden aber wegen der anderen Rahmenbedingungen anders formalisiert; ableitbare Mengenbedingungen können dabei entfallen.

ZFU umfasst folgende Axiome:

Aus den ZFU-Axiomen und dem Axiom formula_90 folgen offenbar die ZF-Axiome. Denn aus dem "Ersetzungsaxiom" ist wie in ZF (siehe unten) das "Paarmengenaxiom" ableitbar und auch das "Aussonderungsaxiom", letzteres hier in folgender Form für jedes einstellige Prädikat formula_30:

ZFCU umfasst die Axiome von ZFU und folgendes "Auswahlaxiom":

Das ZF-System ist redundant, das heißt, es hat entbehrliche Axiome, die aus anderen ableitbar sind. ZF bzw. ZFU wird schon vollständig beschrieben durch das Extensionalitätsaxiom, Vereinigungsaxiom, Potenzmengenaxiom, Unendlichkeitsaxiom, Fundierungsaxiom und Ersetzungsaxiom. Das gilt wegen folgender Punkte:


Paarmengenaxiom, Vereinigungsaxiom und Potenzmengenaxiom können auch aus der Aussage gewonnen werden, dass jede Menge Element einer "Stufe" ist. Unendlichkeitsaxiom und Ersetzungsaxiom sind im Rahmen der übrigen Axiome äquivalent zum Reflexionsprinzip. Durch Kombination dieser beiden Einsichten formulierte Dana Scott ZF zum äquivalenten Scottschen Axiomensystem um.

Man kann ZF und ZFU auch auf einer Prädikatenlogik ohne Gleichheit aufbauen und die Gleichheit definieren. Die Ableitung aller Gleichheitsaxiome sichert nur die in der Logik übliche Identitätsdefinition:

Zur Definition eignet sich nicht das Extensionalitätsaxiom! Die Identitätsdefinition macht dieses Axiom nicht überflüssig, weil es aus der Definition nicht ableitbar wäre. Eine Gleichheitsdefinition per Extensionalität formula_97 wäre als Alternative in ZF nur dann möglich, wenn man das Axiom formula_98 hinzunähme, was die Ableitbarkeit der obigen Formel sichert. Diese Möglichkeit scheidet natürlich bei ZFU aus.

Das Ersetzungsaxiom ist das einzige Axiomenschema in ZF, wenn man die Redundanzen der Axiome beseitigt und sich auf ein System unabhängiger Axiome beschränkt. Es lässt sich nicht durch endlich viele Einzelaxiome ersetzen. ZF ist also im Gegensatz zu den Theorien Neumann-Bernays-Gödel (NGB) und New Foundations (NF) nicht endlich axiomatisierbar. 





</doc>
<doc id="5823" url="https://de.wikipedia.org/wiki?curid=5823" title="ZNS">
ZNS

Die Abkürzung ZNS steht für:

ZnS ist die chemische Summenformel von Zinksulfid


</doc>
<doc id="5825" url="https://de.wikipedia.org/wiki?curid=5825" title="1977">
1977

Das Jahr 1977 stand vor allem in Deutschland im Zeichen des RAF-Terrors "(Deutscher Herbst)". Dieser erreichte mit der Entführung der Landshut sowie der Entführung und Ermordung Hanns Martin Schleyers ihren Höhepunkt.





















Einträge von Leichtathletik-Weltrekorden siehe unter der jeweiligen Disziplin unter Leichtathletik.





Zitate aus dem und über das Jahr 1977:






















































</doc>
<doc id="5829" url="https://de.wikipedia.org/wiki?curid=5829" title="1939">
1939































































































</doc>
<doc id="5830" url="https://de.wikipedia.org/wiki?curid=5830" title="1945">
1945

Das Jahr 1945 markiert das Ende des Zweiten Weltkrieges und damit den Beginn der Nachkriegszeit.

In Europa wird die Wehrmacht an der Ostfront von der Roten Armee in ihrer Winteroffensive an die Oder zurückgedrängt, während mit der Ardennenoffensive ein letzter Vorstoß gegen die Alliierten an der Westfront scheitert und die deutschen Städte im Bombenkrieg zerstört werden.

Im Februar diskutieren Roosevelt, Churchill und Stalin auf der Konferenz von Jalta die Nachkriegsordnung. An der Westfront gelingt den Alliierten Ende März die Überschreitung des Rheins als letzte Barriere vor der Besetzung Deutschlands. Ende April marschiert die Rote Armee in Berlin ein. Adolf Hitler begeht am 30. April im Führerbunker Suizid, die bedingungslose Kapitulation der Wehrmacht tritt am 8. Mai um 23:01 Uhr MEZ in Kraft.

Deutschland und Österreich werden in Besatzungszonen eingeteilt, am 5. Juni übernehmen die Alliierten in der Berliner Erklärung formal die Regierungsgewalt in Deutschland. Am 20. November beginnt der Nürnberger Prozess gegen die Hauptkriegsverbrecher.

In Asien werden die Japaner im Pazifikkrieg von den US-Streitkräften Insel für Insel an die japanischen Hauptinseln zurückgedrängt, halten jedoch unter anderem in China (siehe Zweiter Japanisch-Chinesischer Krieg) noch weite Gebiete. Nach den Atombombenabwürfen auf Hiroshima und Nagasaki am 6. und 9. August und dem Eintritt der Sowjetunion in den Krieg gegen Japan (8. August), leitet die erste öffentliche Ansprache des Kaisers an die Bevölkerung die Kapitulation ein (15. August). Die Kapitulationszeremonie am 2. September an Deck des amerikanischen Schlachtschiffes USS Missouri beendet den Zweiten Weltkrieg.

Die Unterzeichnung der Charta der Vereinten Nationen am 26. Juni und das Potsdamer Abkommen vom 2. August bildeten den Rahmen der politischen Weltordnung der kommenden Jahrzehnte, geprägt vom Kalten Krieg.









































































































</doc>
<doc id="5831" url="https://de.wikipedia.org/wiki?curid=5831" title="1933">
1933

Die Politik des Jahres 1933 ist geprägt durch die „Machtergreifung“ der Nationalsozialisten unter Adolf Hitler im Deutschen Reich und das damit verbundene Ende der Weimarer Republik und den Beginn des „Dritten Reichs“. Praktisch zeitgleich beginnt in Österreich durch die von der christlich-sozialen Bundesregierung unter Engelbert Dollfuß so bezeichnete „Selbstausschaltung des Parlaments“ die Zeit des austrofaschistischen Ständestaates, womit nach Italien (1922), Albanien (1925), Polen (1926), Litauen (1926) und Jugoslawien (1929) zwei weitere kurz nach dem Ersten Weltkrieg entstandene Demokratien in Europa scheitern.

Im Deutschen Reich führen die Nationalsozialisten das Einparteiensystem ein und beginnen innerhalb kurzer Zeit mit dem Terror gegen Juden, Minderheiten und Andersdenkende und der Errichtung von Konzentrationslagern, das erste dieser Lager ist das KZ Dachau.

Nach einer inszenierten Volksabstimmung tritt Deutschland außerdem aus dem Völkerbund aus, ebenso wie Japan, womit die eklatante Ohnmacht der nach dem Ersten Weltkrieg zur Wahrung des Friedens gegründeten völkerrechtlichen Organisation offengelegt wird.

Wirtschaftlich ist das Jahr überschattet von der seit Jahren andauernden Weltwirtschaftskrise. In den Vereinigten Staaten beginnt der neu gewählte Präsident Franklin D. Roosevelt mit der Bekämpfung der Großen Depression mit dem "New Deal".

Obwohl die Nationalsozialisten bei der Reichstagswahl am 6. November 1932 erstmals Verluste haben hinnehmen müssen, gelingt es nicht, eine stabile Regierung zu etablieren. Das Kabinett Papen wurde am 3. Dezember 1932 mit Unterstützung durch Reichspräsident Paul von Hindenburg vom Kabinett Schleicher abgelöst. Der vom „Verrat“ seines früheren Weggefährten Kurt von Schleicher zutiefst enttäuschte Franz von Papen trifft sich am 4. Januar im Kölner Haus des Bankiers Kurt Freiherr von Schröder mit Adolf Hitler zu Geheimverhandlungen, bei denen sie eine gemeinsame Regierungsübernahme vereinbaren. Diesem Gespräch folgten weitere, zuletzt auch unter Anwesenheit des Staatssekretärs des Reichspräsidenten Otto Meissner und dem Sohn des Reichspräsidenten Oskar von Hindenburg.

Am 30. Januar 1933 erfolgt die Ernennung Adolf Hitlers zum Reichskanzler durch Reichspräsident Hindenburg. Hindenburg, der sich lange gesträubt hat, wird mit dem Hinweis beruhigt, dass ein von einer konservativen Kabinettsmehrheit „eingerahmter“ NSDAP-Führer nur eine geringe Gefahr bedeute. Hitler bildet daraufhin eine so genannte Nationale Regierung aus Konservativen, Deutschnationalen und Nationalsozialisten. Von Papen wird Vizekanzler, der Regierung gehören außer Hitler nur zwei weitere Nationalsozialisten an, nämlich Wilhelm Frick als Innenminister und Hermann Göring als Minister ohne Geschäftsbereich und kommissarischer preußischer Innenminister.

Bereits am 1. Februar wird der Reichstag auf Wunsch Hitlers vom Reichspräsidenten aufgelöst. Die letzte freie Wahl am 5. März wird zu einem überwältigenden Erfolg für die NSDAP, die 43,9 % der Stimmen erhält. Die Einberufung des neuen Reichstags wird am 21. März mit dem "Tag von Potsdam" öffentlichkeitswirksam zelebriert.

Von Beginn der Machtergreifung an beginnen die Nationalsozialisten mit der Ausschaltung der Demokratie und der Gleichschaltung des Reiches. Durch die "Verordnung des Reichspräsidenten zum Schutze des Deutschen Volkes" vom 4. Februar werden die Grundrechte der Weimarer Verfassung, insbesondere die Versammlungs- und Pressefreiheit, eingeschränkt. Am 13. März wird das Reichsministerium für Volksaufklärung und Propaganda unter Propagandaminister Joseph Goebbels gegründet. Am 23. März beschließt der Reichstag das "Gesetz zur Behebung der Not von Volk und Reich", das der Regierung Hitler quasi diktatorische Vollmachten überträgt. Nur die Abgeordneten der SPD unter Otto Wels stimmen gegen dieses Gesetz. Mit den Gesetzen vom 31. März und 7. April werden den Ländern ihre relativen Souveränitätsrechte entzogen und Reichsstatthalter eingesetzt.







In Österreich kommt es am 4. März aufgrund einer verfahrenstechnischen Unachtsamkeit zur Beschlussunfähigkeit des Nationalrats, die der christlichsoziale Bundeskanzler Engelbert Dollfuß für einen Staatsstreich nutzt, indem er diese als „Selbstausschaltung des Parlaments“ bezeichnet. Als der Nationalrat unter dem dritten Nationalratspräsidenten Sepp Straffner am 15. März zusammentreten will, um diesen Verfahrensfehler zu korrigieren, werden die Abgeordneten von der austrofaschistischen Bundesregierung mit Polizeigewalt am Zusammentreten gehindert. Obwohl eine von über einer Million Menschen unterschriebene Petition ihn auffordert, die Regierung Dollfuß abzuberufen und auf Vorschlag einer von ihm bestellten Interimsregierung Neuwahlen zu veranlassen, bleibt der ebenfalls christlichsoziale Bundespräsident Wilhelm Miklas untätig, was es Dollfuß ermöglicht, weiter diktatorisch zu regieren. Am 23. Mai wird auch der Verfassungsgerichtshof am vollständigen Zusammentreten gehindert und damit die Gewaltentrennung in Österreich abgeschafft.

Zunächst geben die Christlichsozialen an, nur für einige Zeit autoritär regieren und in Verhandlungen mit der Opposition eine Änderung der Geschäftsordnung des Nationalrates und eine Reform der Verfassung erreichen zu wollen. Ernsthafte Gespräche darüber finden jedoch nie statt. Die Dollfuß-Regierung löst stattdessen am 31. März den sozialdemokratischen Republikanischen Schutzbund und am 26. Mai die Kommunistische Partei Österreichs durch Verordnung auf. Am 19. Juni werden auch die Großdeutsche Volkspartei und die NSDAP verboten.

Ab April wendet Dollfuß sich zunehmend um Unterstützung gegen Deutschland an Benito Mussolini, der im Gegenzug nachdrücklich die endgültige Abschaffung des Parteienstaats fordert. Dollfuß verkündet daraufhin in einer Rede am Wiener Trabrennplatz am 11. September die Errichtung des Ständestaates. Da er sich dabei auf Papst Pius XI. und dessen Sozialenzyklika "Quadragesimo anno" beruft, wird er von der katholischen Kirche unter Kardinal Theodor Innitzer unterstützt. Bei einer Regierungsumbildung am 20. September wird Parteiobmann Carl Vaugoin entmachtet und Heimwehrführer Emil Fey Vizekanzler. Ernst Rüdiger Starhemberg löst den Heimatblock auf und tritt mit der Heimwehr in die am 20. Mai gegründete Vaterländische Front ein, die den Alleinvertretungsanspruch für die gesamte österreichische Bevölkerung stellt.

Am 3. Oktober wird Dollfuß vom Nationalsozialisten Rudolf Drtil durch zwei Schüsse leicht verletzt. Der Attentäter wird unter Berücksichtigung ‚geistiger Minderwertigkeit‘ zu fünf Jahren Kerker verurteilt. Durch Verordnung vom 10. November wird mit Wirkung des folgenden Tages das standrechtliche Verfahren und mit ihm die 1920 abgeschaffte Todesstrafe für Mord, Brandstiftung und „"öffentliche Gewalttätigkeit durch boshafte Beschädigung fremden Eigentums"“ wieder eingeführt.

In Spanien ist es der Zweiten Republik im Laufe des Vorjahres trotz verschiedener Aufstände und Putschversuche gelungen, eine gewisse Stabilität zu erlangen. Doch ein Aufstand im Januar in dem andalusischen Dorf Casas Viejas, der von der Regierung brutal niedergeschlagen wird, führt zu einer rapiden Verschlechterung des Klimas im Land und zu einer Steigerung der Skepsis der demokratischen Staatsform gegenüber. Premierminister Manuel Azaña gründet eine neue paramilitärische Polizeitruppe, die "Guardia de Asalto" (Sturmgarde), um sie gegen ihre Feinde verteidigen zu können. Ihr Oberbefehlshaber wird General Emilio Mola.

Im September schließlich zerbricht die Regierungskoalition aus Liberalen und Sozialisten. Bei den darauf folgenden Wahlen am 19. November, bei der erstmals auch Frauen wahlberechtigt sind, siegen die Konservativen unter Alejandro Lerroux und bilden eine Regierung mit der rechtsautonomen "Confederación Española de Derechas Autónomas" unter José María Gil-Robles y Quiñones und der monarchistischen "Renovación Española". Die Wahlbeteiligung liegt dabei bei knapp 60 %, weil die von der Linken enttäuschte Arbeiterschaft sich in weiten Teilen der Stimme enthält.

Im Teatro de la Comedia in Madrid wird am 29. Oktober die faschistische Falange Española gegründet. Den Vorsitz übernimmt eine Dreiergruppe, die aus dem Anwalt José Antonio Primo de Rivera, dem Piloten Julio Ruiz de Alda und dem Schriftsteller Alfonso García Valdecasas besteht. Die Bewegung kann bis zum Ende des Jahres rund 2.000 Mitglieder gewinnen, vor allem enttäuschte Anhänger der traditionellen Rechtsparteien und Studenten, die über die im November gegründete Studentengruppe "Sindicato Universitario Español" (SEU) zur Partei kommen.

In den Vereinigten Staaten wird am 4. März der Demokrat Franklin D. Roosevelt als 32. US-Präsident angelobt. Er löst den Republikaner Herbert Hoover ab, den er bei den Präsidentschaftswahlen im November des Vorjahres erdrutschartig geschlagen hat. Es ist die letzte reguläre Amtseinführung eines US-Präsidenten an einem 4. März. Diese seit den Anfängen der USA bestehende Tradition wird ab 1937 mit der zweiten Einführung Roosevelts durch den 20. Januar ersetzt.

Roosevelt wird am ehesten zugetraut, die vorwiegend wirtschaftlichen Probleme lösen zu können. Mit dem "New Deal", einem Wahlversprechen, das er sofort nach seiner Angelobung in die Tat umzusetzen beginnt, wird über die folgenden Jahre die Große Depression bekämpft.

Außenpolitisch bemüht sich Roosevelt den Eindruck eines US-amerikanischen Imperialismus zu zerstreuen. Gleich bei seiner Antrittsrede verkündet er eine "Good Neighbor Policy" mit den lateinamerikanischen Staaten und unterzeichnet am 26. Dezember gemeinsam mit seinem Außenminister Cordell Hull die "Konvention von Montevideo", mit der die Vereinigten Staaten Abstand von einer Interventionspolitik im Sinne der "Monroe-Doktrin" und der "Roosevelt-Corollary" nehmen.

Am 23. März unterzeichnet Präsident Roosevelt ein als "Cullen-Harrison Act" bekannt gewordenes Gesetz, um den "Volstead Act" aufzuheben und Herstellung und Verkauf bestimmter alkoholischer Getränke zu erlauben. Am 5. Dezember hebt die Unterzeichnung des 21. Verfassungszusatzes den 18. Zusatzartikel auf. Die Prohibition in den Vereinigten Staaten ist damit nach fast 15 Jahren beendet.

Am 17. November erkennt die US-Regierung die seit Ende 1922 existierende Sowjetunion völkerrechtlich an.

In Nicaragua wird der neu gewählte Präsident Juan Bautista Sacasa am 1. Januar in sein Amt eingeführt. Bereits am nächsten Tag verlassen die letzten Einheiten der United States Army das Land. Sie hinterlassen eine von ihnen aufgebaute und trainierte Nationalgarde, die "Guardia Nacional de Nicaragua" unter dem Befehl ihres Vertrauten Anastasio Somoza García.

Die Amtsübernahme durch den Liberalen Sacasa führt zu einem Ende des seit 1927 andauernden Bürgerkriegs, weil der Aufständische General Augusto César Sandino seine Loyalität zu der neuen Regierung bezeugt und mit seinen Truppen die Waffen niederlegt, die im Gegenzug Amnestie erhalten sowie Landbesitz im Norden des Landes in Jinotega.


















































</doc>
<doc id="5832" url="https://de.wikipedia.org/wiki?curid=5832" title="1968">
1968

Das Jahr 1968 ist in vielen Ländern der Höhepunkt der linksgerichteten Studenten- und Bürgerrechtsbewegungen der 1960er-Jahre, die daher auch als 68er-Bewegung bezeichnet werden. In den USA sind das die Proteste gegen den Vietnamkrieg und die schwarze Bürgerrechtsbewegung, deren Anführer Martin Luther King im April des Jahres ermordet wird, in Frankreich die Mai-Unruhen, in der Bundesrepublik die Studentenbewegung, die Proteste gegen die Notstandsverfassung, und die Außerparlamentarische Opposition, in der ČSSR der Prager Frühling, in Polen die März-Unruhen, die Studentenproteste in Mexiko und in Japan die Proteste von Zengakuren.

Am 28. Dezember zerstört eine Israelische Kommandoeinheit in einer Vergeltungsaktion am Beiruter Flughafen 13 Flugzeuge.

Am 30. Januar startet die Nationale Front für die Befreiung Südvietnams (FNL) aus dem kommunistischen Nordvietnam mit rund 84.000 Kämpfern die Tet-Offensive und greift die Provinzhauptstädte Saigon und Huế an. Strategie und Stärke der Angriffe überraschen die amerikanischen und südvietnamesischen Truppen, welche sich bis dahin in dem Konflikt eher in der Oberhand sahen. Die Offensive endet in einer schweren militärischen Niederlage für die FNL, welche die Hälfte ihrer Truppen verliert. Saigon und Huế werden schwer zerstört. Die FNL wird stark geschwächt und tritt im weiteren Verlauf des Krieges kaum noch in Erscheinung. Sie kann jedoch einen wichtigen psychologischen Erfolg verbuchen: Erstmals wird der US-Öffentlichkeit deutlich, dass der Vietnamkrieg mit einer Niederlage enden könnte. Präsident Lyndon B. Johnson verliert an Popularität und politischer Glaubwürdigkeit, und die Proteste gegen den Krieg werden schärfer.

Das von US-Truppen begangene Massaker von My Lai am 16. März, das allerdings erst im darauffolgenden Jahr durch einen Artikel im Magazin Life bekannt wird, dreht die öffentliche Stimmung endgültig.

In der Tschechoslowakei kommt es unter dem Motto „Sozialismus mit menschlichem Antlitz“ zu einer schrittweisen Liberalisierung der Verhältnisse unter Alexander Dubček, der im Januar zum ersten Sekretär der KSČ aufsteigt. Unter anderem wird die Pressezensur aufgehoben. Diese Entwicklung endet jedoch in der Nacht zum 21. August schlagartig, als etwa eine halbe Million Soldaten der Sowjetunion, Polens, Ungarns und Bulgariens in die Tschechoslowakei einmarschieren und innerhalb von wenigen Stunden alle strategisch wichtigen Positionen des Landes besetzen. Dubček und andere hochrangige Regierungsmitglieder werden festgenommen, nach Moskau gebracht und zu Gunsten des linientreuen Gustáv Husák entmachtet.

Im seit dem Vorjahr andauernden Biafra-Krieg wird die abtrünnige Provinz Biafra von den wesentlich besser ausgerüsteten Truppen der nigerianischen Regierung zu zwei Dritteln besetzt. In der Region kommt es zu einer Hungerkatastrophe, deren Bilder um die Welt gehen.










Einträge von Leichtathletik-Weltrekorden siehe unter der jeweiligen Disziplin unter Leichtathletik.




























































</doc>
<doc id="5833" url="https://de.wikipedia.org/wiki?curid=5833" title="1969">
1969

Das Jahr 1969 markiert das Ende der 1960er-Jahre. Prägend für dieses Jahr war insbesondere die erste Mondlandung in der Geschichte der Menschheit. Weitere bedeutende Ereignisse waren Regierungswechsel in Deutschland, den USA und Frankreich. Auch die brutalen Morde der Manson Family in Kalifornien sowie der Vietnamkrieg beherrschten das Geschehen. Musikalisch und kulturell blieb das Woodstock-Festival in Erinnerung.
















Einträge von Leichtathletik-Weltrekorden siehe unter der jeweiligen Disziplin unter Leichtathletik.












































































</doc>
<doc id="5834" url="https://de.wikipedia.org/wiki?curid=5834" title="1989">
1989

Das Jahr 1989 stand maßgeblich unter dem Einfluss der politischen Umwälzungen in den europäischen Ostblockstaaten, welche durch wachsenden Protest der Bevölkerung hervorgerufen wurden. Mit den ersten demokratischen Parlamentswahlen in Polen, dem Abbau der Grenzanlagen Ungarns zu Österreich im Mai, der Grenzbefestigungen der Tschechoslowakei im Dezember und dem Fall der Berliner Mauer am 9. November 1989 kam es zur Öffnung des Eisernen Vorhangs. Dies leitete das Ende des Kalten Krieges ein und markierte das Ende des „kurzen 20. Jahrhunderts“. In China löste dagegen das Militär am 3. und 4. Juni 1989 die monatelange Besetzung des Platzes des himmlischen Friedens mit dem Tian’anmen-Massaker gewaltsam auf und unterband die Bestrebungen von Studenten nach weitergehender Öffnung der Gesellschaft und Demokratie.

Die Sowjetunion zog indessen ihre Truppen aus Afghanistan zurück. Damit war auch der zehn Jahre lang andauernde Sowjetisch-Afghanische Krieg beendet. Im Januar 1989 trat George H. W. Bush das Amt des 41. Präsidenten der Vereinigten Staaten an. Bei der Wahl des deutschen Bundespräsidenten 1989 wurde Richard von Weizsäcker im Amt bestätigt.






























































Siehe auch Filmjahr 1989



</doc>
<doc id="5835" url="https://de.wikipedia.org/wiki?curid=5835" title="2002">
2002





















"Siehe auch:" 



Einträge von Leichtathletik-Weltrekorden siehe unter der jeweiligen Disziplin unter Leichtathletik.










Dies ist eine Liste der bedeutendsten Persönlichkeiten, die 2002 verstorben sind. Für eine ausführlichere Liste siehe Nekrolog 2002.




















</doc>
<doc id="5836" url="https://de.wikipedia.org/wiki?curid=5836" title="1954">
1954

1954 endete der Indochinakrieg mit der Niederlage Frankreichs in der Schlacht von Điện Biên Phủ. Mit dem Algerienkrieg begann gleichzeitig ein weiterer kolonialer Befreiungskrieg gegen Frankreich.

In Deutschland sorgte derweil der Präsident des Verfassungsschutz Otto John mit seinem Abtauchen in der DDR für einen Skandal.

In den USA erreichte die McCarthy-Ära mit dem Communist Control Act of 1954 ihren Höhepunkt.

Beim 11. April des Jahres 1954 soll es sich laut Berechnungen britischer Wissenschaftler der Cambridge University aus dem Jahr 2010 um den bedeutungslosesten Tag des 20. Jahrhunderts gehandelt haben.









Einträge von Leichtathletik-Weltrekorden siehe unter der jeweiligen Disziplin unter Leichtathletik.



























































</doc>
<doc id="5837" url="https://de.wikipedia.org/wiki?curid=5837" title="2001">
2001

Das Jahr 2001 war das erste Jahr des 21. Jahrhunderts. Das prägendste Ereignis waren die Terroranschläge am 11. September 2001 auf das World Trade Center und das Pentagon in den USA, bei denen rund 3000 Menschen ums Leben kamen. Die Anschläge werden häufig als historische Zäsur bezeichnet und sorgten sowohl in den USA als auch in Europa für immer noch anhaltende Debatten um innen- wie außenpolitische Veränderungen. Sie führten den Krieg in Afghanistan in eine neue Phase und dienten als Begründung für den zwei Jahre später begonnenen Irakkrieg. Ausgehend von dem Ereignis stiegen die Spannungen zwischen der muslimischen und der westlichen Welt.























"Siehe auch:" 


"Siehe auch:" 

Einträge von Leichtathletik-Weltrekorden siehe unter der jeweiligen Disziplin unter Leichtathletik.










Dies ist eine Liste der bedeutendsten Persönlichkeiten, die 2001 verstorben sind. Für eine ausführlichere Liste siehe Nekrolog 2001.



















</doc>
<doc id="5838" url="https://de.wikipedia.org/wiki?curid=5838" title="Ägyptisches Museum Berlin">
Ägyptisches Museum Berlin

Das Ägyptische Museum Berlin, eigentlich "Ägyptisches Museum und Papyrussammlung" der Staatlichen Museen zu Berlin, befindet sich seit dessen Wiedereröffnung im Oktober 2009 wieder im Neuen Museum. Es beherbergt eine der weltweit bedeutendsten Sammlungen der ägyptischen Hochkultur, die Statuen, Reliefs und Kleinkunstobjekte aus sämtlichen Epochen der altägyptischen Geschichte umfasst. Als bekanntestes Ausstellungsstück und Publikumsmagnet gilt die 1920 von James Simon übereignete Büste der Nofretete.

Das Museum ging aus der 1828 auf Empfehlung Alexander von Humboldts gegründeten ägyptischen Abteilung der Kunstsammlungen König Friedrich Wilhelm III. hervor. Erster Leiter dieser Abteilung, die zunächst im Schloss Monbijou untergebracht war, wurde Giuseppe Passalacqua, ein Kaufmann aus Triest, dessen archäologische Sammlung den Grundstock der Abteilung bildete. Eine Expedition unter Karl Richard Lepsius von 1842 bis 1845 brachte viele weitere Sammelstücke nach Berlin.

1850 erhielt das Museum ein eigenes neues Gebäude auf der Museumsinsel, das nach seinem Wiederaufbau 2009 wiedereröffnete Neue Museum des Architekten Friedrich August Stüler. James Simon schenkte dem Museum 1920 neben anderen Stücken die Büste der ägyptischen Königin Nofretete, das bekannteste Exponat der Sammlung. Simon hatte die Grabungen Ludwig Borchardts im ägyptischen Tell el-Amarna finanziert und die Fundstücke nach Deutschland gebracht.

Durch den Zweiten Weltkrieg wurde die Sammlung auseinandergerissen. Das Neue Museum wurde 1943 stark beschädigt und zahlreiche Ausstellungsstücke verbrannten. Die Sammlung wurde an verschiedene Orte ausgelagert. Die Büste der Nofretete überstand den Krieg in einem Stollen in Thüringen und wurde später in das Museum Wiesbaden gebracht.

Der Hauptteil der Sammlung befand sich in Ost-Berlin und wurde ab 1958 im Bodemuseum wieder ausgestellt. In West-Berlin wurde der Rest der Sammlung, der aus Westdeutschland zurückkehrte, seit 1967 im östlichen Stülerbau gegenüber dem Schloss Charlottenburg ausgestellt. Im Innenhof des Museums in Charlottenburg stand ein Buddy Bär („Die Mumie“ von Ralf Nepolsky), der nach dem Umzug des Museums nach Berlin-Mitte als verschollen gilt.

Nach der Wiedervereinigung wurden beide Sammlungen wieder zusammengeführt. Die Sammlung im Bodemuseum wurde in den 1990er Jahren wegen Sanierungsarbeiten geschlossen. Im August 2005 zog die ägyptische Sammlung aus Charlottenburg auf die Museumsinsel zurück, zunächst ins Alte Museum wo bis 2009 ein repräsentativer Querschnitt der Sammlung unter Ausnahme der Großobjekte gezeigt wurde. Der Hauptteil der für die ständige Ausstellung vorgesehenen Exponate ist seit Oktober 2009 wieder an seinem ursprünglichen Platz im aufgebauten Neuen Museum zu finden. Allerdings kann auch dort ein Großteil der monumentalen Plastik und Architektur aus Platzmangel nicht gezeigt werden, darunter das Kalabscha-Tor und der Tempelhof aus dem Totentempel Sahures. Diese sollen nach dem Masterplan Museumsinsel erst sehr viel später im noch zu bauenden und umstrittenen vierten Flügel des Pergamonmuseums gezeigt werden.

Seit Juli 2009 ist Friederike Seyfried Direktorin des Ägyptischen Museums Berlin, die Dietrich Wildung nach zwanzigjähriger Amtszeit ablöste.

Die Sammlung gibt einen umfangreichen Einblick in Kunst und Kultur Altägyptens über einen Zeitraum von vier Jahrtausenden. Sie beleuchtet auf drei Museumsebenen die Alltagswelt im Niltal, die Verehrung von Königen und Göttern, den Jenseitsglauben und zeigt zum Teil bedeutende altägyptische Schriften auf Papyrus. Zu den bekanntesten Stücken zählt die Büste der Nofretete, der „Berliner Grüne Kopf“ und der Papyrus Westcar.





</doc>
<doc id="5839" url="https://de.wikipedia.org/wiki?curid=5839" title="2000">
2000

Das Jahr 2000 markiert das letzte Jahr des 20. Jahrhunderts sowie das erste der 2000er-Jahre.



























"Einträge von Leichtathletik-Weltrekorden siehe unter der jeweiligen Disziplin unter Leichtathletik."














Dies ist eine Liste der bedeutendsten Persönlichkeiten, die 2000 verstorben sind. Für eine ausführlichere Liste siehe Nekrolog 2000.






















</doc>
<doc id="5841" url="https://de.wikipedia.org/wiki?curid=5841" title="2000er">
2000er

Die 2000er Jahre umfassen das Jahrzehnt zwischen dem 1. Januar 2000 und dem 31. Dezember 2009.

Als eines der prägendsten Ereignisse gelten die Terroranschläge am 11. September 2001 auf das World Trade Center und das Pentagon in den USA, bei denen rund 3000 Menschen ums Leben kamen. Die Anschläge wurden häufig als historische Zäsur bezeichnet und führten in der gesamten Dekade sowohl in den USA als auch in Europa zu anhaltenden Debatten um innen- wie außenpolitische Veränderungen. Sie führten den Krieg in Afghanistan in eine neue Phase und begründete den zwei Jahre später erklärten Irakkrieg, in dessen Folge der damalige Diktator Saddam Hussein gestürzt wurde. Ausgehend von dem Ereignis stiegen die Spannungen zwischen der muslimischen und der westlichen Welt über die folgenden Jahre.

Der rasante Aufstieg Chinas zu einer Industrienation führte zu einem Rohstoffboom und einer neuen Struktur der globalen Wirtschaftsordnung. Die G20 wurden zu einem der wichtigsten Gremien der Vereinten Nationen.

Als Konsequenz aus globalen Geldspekulationen platzte in den USA und anderen europäischen Staaten Ende des Jahres 2007 eine Immobilienblase, woraus sich eine weltweite Bankenkrise entwickelte und den Zusammenbruch der amerikanischen Großbank Lehman Brothers zufolge hatte. Zur Stabilisierung des Bankensystems wurde in mehreren Ländern beschlossen, die Geldinstitute durch staatliche Eingriffe mit Krediten zu versorgen. Durch diese weitreichenden Rettungen stieg die Staatsverschuldung vieler Länder an, was zur Eurokrise führte.

Die Nutzung digitaler Medien erreichte in diesem Jahrzehnt eine neue Qualität. Das Internet begann im Alltag eine immer wichtigere Rolle zu spielen und die Nutzung über Mobilfunk nahm zu. Außerdem erlangten soziale Netzwerke wie Facebook, Myspace oder Twitter gerade bei jungen Leuten große Popularität.
Die Online-Enzyklopädie Wikipedia wurde am 15. Januar 2001 gegründet.

Die Ansichten, wie das "Jahrzehnt umgangssprachlich" zu bezeichnen ist, sind unterschiedlich. Keiner der Vorschläge stößt auf ungeteilte Zustimmung. Die am häufigsten anzutreffenden Bezeichnungen sind die 2000er (Jahre) und die Nullerjahre, letztere erst öfter seit 2009 im Zuge der aufkommenden Jahrzehntrückblicke. Dabei wird "Nullerjahre" (oder auch "Nuller") eher mündlich und umgangssprachlich verwendet, während sich schriftsprachlich die Schreibung mit der Jahreszahl durchgesetzt hat ("2000er Jahre").
















</doc>
<doc id="5843" url="https://de.wikipedia.org/wiki?curid=5843" title="21. Jahrhundert">
21. Jahrhundert

Das 21. Jahrhundert begann mit dem 1. Januar 2001 und endet mit dem 31. Dezember 2100.


















</doc>
<doc id="5844" url="https://de.wikipedia.org/wiki?curid=5844" title="20. Jahrhundert">
20. Jahrhundert

Das 20. Jahrhundert begann am 1. Januar 1901 und endete mit dem 31. Dezember 2000. Um Zentenniumsfeier und das Jubiläum zum 30. Reichsgründungstag am 18. Januar 1901 nicht miteinander in Konkurrenz geraten zu lassen, erließ Kaiser Wilhelm II. abweichend für Deutschland ein Dekret, welches den Beginn des neuen Jahrhunderts auf den 1. Januar 1900 festlegte. Das 20. Jahrhundert zählt zur Epoche der Neuzeit und war besonders durch den Imperialismus und die beiden Weltkriege sowie den daraus erwachsenden Niedergang der europäischen Kolonialreiche und den Kalten Krieg geprägt, ebenso von der exponentiellen Zunahme der Weltbevölkerung, der Automatisierung und der Digitalisierung von Wirtschaftsprozessen sowie der Polarisierung zwischen der Ersten und der Dritten Welt. Wichtige Technologien wie Kunststoffe, Elektronik, Raumfahrt und Antibiotika veränderten die Welt.

Viele Historiker nutzen für ihre Periodisierungen nicht die kalendarischen Einteilungen, sondern berufen sich bei der Festlegung von Zäsuren auf politische, soziale oder kulturelle Aspekte. Weit verbreitet ist die These vom „Langen 19. Jahrhundert“, das bis zum Beginn des Ersten Weltkriegs (1914) dauerte. Auch den Wendepunkt mit der Oktoberrevolution 1917 zu verbinden, ist eine gängige These. Parallel dazu wird das 20. Jahrhundert auch als das „kurze 20. Jahrhundert“ bezeichnet, das eben vom Ende des Ersten Weltkriegs bis zum Ende der Sowjetunion und ihres Machtbereichs 1989 bis 1991 dauert. Grundlage für die Periodisierung kann zum Beispiel der Ost-West-Konflikt sein. Seine Wurzeln hatte er bereits im Aufstieg der Arbeiterbewegung im 19. Jahrhundert. Im 20. Jahrhundert versuchten viele Organisationen, aus den Theorien von Karl Marx und Friedrich Engels neue Staatsorganisationen herzustellen. Dieser Prozess begann mit der Oktoberrevolution von 1917 und endete mit dem Zusammenbruch des als „Real existierender Sozialismus“ bezeichneten Versuchs um 1990.

Das Gedankengut der Französischen Revolution (1789) hatte viel bewirkt und Napoleon Bonaparte die politische Landkarte Europas völlig umgestaltet. Die Industrialisierung und die daraus resultierenden kapitalistischen Gesellschaften hatten sich im 19. Jahrhundert durchgesetzt. Die soziale Frage geriet in den Vordergrund und es entwickelten sich Gewerkschaften, sozialdemokratische Parteien und andere Organisationen der Arbeiterbewegung. Als Reaktion darauf entstanden in einigen Industrieländern sozialstaatliche Reformen aber auch Ausweitungen der demokratischen Mitbestimmung, etwa des Wahlrechts. Der technische Fortschritt erhöhte die Mobilität und verkürzte die Kommunikationswege durch die Eisenbahn und erste Kraftfahrzeuge spürbar.

In Europa standen sich völlig unterschiedliche Systeme und Regime gegenüber. Im Vereinigten Königreich oder auch in Frankreich hatten sich funktionierende plurale und liberale bürgerliche Demokratien durchgesetzt, die mit der Industrialisierung und der Durchsetzung der kapitalistischen Produktionsweise entstanden. In Deutschland herrschte dagegen ein repressives obrigkeitsstaatliches Regime, das seine Gegner unterdrückte und sich vor allem auf das Militär stützte. Noch autoritärer war das russische Zarenreich, wo sich großes Elend breiter Schichten, der Reichtum einer kleinen Oberschicht und ein ultrarepressives politisches Regime gegenüberstanden und entsprechende Unzufriedenheiten hervorriefen.

Am Ausgang des 19. Jahrhunderts war aber vor allem die Zuspitzung der Gegensätze der imperialen Staaten prägend. Kriege und Krisen zwischen den großen Mächten folgten teils ohne Unterbrechung aufeinander. Die Märkte in den Industrieländern konnten die immer massenhafter produzierten Waren kaum noch abnehmen, so dass dringend Absatzmärkte außerhalb der Heimat gesucht wurden. Da die Welt um 1900 bereits „aufgeteilt“ war, kam es immer wieder zu Auseinandersetzungen. Das aufstrebende und nach Kolonien suchende deutsche Kaiserreich geriet hier immer öfter in Konflikt mit schon existierenden Großmächten wie Großbritannien oder Frankreich. Die Rüstungsausgaben der Großmächte machten den übergroßen Teil der Staatsausgaben aus und zwischenstaatliche Konflikte und Konkurrenzen wurden in vielen Krisen und Kriegen, meist außerhalb Europas, ausgetragen.

Dann kam es zu den „Urkatastrophen“ der Weltkriege. Nach einer relativ friedlichen "Belle Époque" und einem Flottenwettrüsten eskalierten 1914 die Rivalitäten der europäischen Mächte zum Ersten Weltkrieg der Mittelmächte gegen die Entente, welche ihn schließlich siegreich beendete. Die Pariser Vorortverträge, darunter der Versailler Vertrag, sollten eine stabile Nachkriegsordnung etablieren. Die Doppelmonarchie Österreich-Ungarn wurde aufgelöst, die zweite polnische Republik gegründet, Deutschland verlor große Teile seines Gebietes, darunter auch das 1871 von Frankreich annektierte Elsaß-Lothringen.

Nach Ende des Kriegs entstanden in vielen europäischen Ländern neue Demokratien und das allgemeine Wahlrecht setzte sich fast überall in Europa durch. In Russland wurde der Erste Weltkrieg durch die Oktoberrevolution bereits 1917 vorzeitig beendet. Das Zarenreich, das letzte autokratische Regime Europas, wurde nach einem Bürgerkrieg durch eine Räterepublik ersetzt. Aus der Theorie Lenins abgeleitet, sollte sich in Russland der erste sozialistische Staat entwickeln, der sich nach dessen Tod unter Stalin allerdings in eine totalitäre Diktatur verwandelte.

In den 1920er Jahren entwickelte sich vielerorts ein neues Leben. Die „Goldenen Zwanziger Jahre“ brachten nach dem Krieg einen Wirtschaftsaufschwung mit sich und neue Formen der Unterhaltung entwickelten sich in den europäischen Städten. Die USA wurden nicht nur militärisch und politisch zu einer Weltmacht, sondern hatten mit dem Aufblühen von Jazz und anderer Unterhaltungskultur in Europa auch einen kulturellen Einfluss. Mit der folgenden Weltwirtschaftskrise ab 1929 verschärften sich aber auch weltweit die sozialen Probleme. In Deutschland waren die alten militärischen, politischen und wirtschaftlichen Eliten nicht ausgetauscht worden und hatten sich nie in die demokratische Republik integrieren lassen. Der letztlich gescheiterte Hitler-Ludendorff-Putsch von 1923 gab einen Vorgeschmack auf das, was aus dem Bündnis aus deutschnationalen Eliten und unzufriedenen Verlierern der Republik folgen sollte.

Die unzureichende Nachkriegsordnung und die drückende Wirtschaftskrise, die Armut und Erwerbslosigkeit zur Folge hatte, förderte in vielen europäischen Ländern den Aufstieg des Faschismus. Dabei handelt es sich um eine nationalistische und totalitäre Ideologie. Die faschistischen Diktaturen negierten das Individuum, schufen sich riesige Armeen und verfolgten eine Modernisierungsideologie, die sich beispielsweise in der Kunst des Futurismus ausdrückte.

Die deutsche Spielart des Faschismus war der Nationalsozialismus. Adolf Hitler, der Vorsitzende der nationalsozialistischen NSDAP, gelangte 1933 an die Macht und errichtete sehr schnell eine totalitäre Diktatur. Die Machthaber entwickelten schon 1933 den Begriff Gleichschaltung, mit dem sie die völlige Unterwerfung des politischen, kulturellen und sonstigen öffentlichen Lebens unter ihre Ideologie beschrieben. Politische Gegner wie Sozialdemokraten, Kommunisten, Gewerkschafter und Liberale wurden verfolgt, inhaftiert und ermordet. Im Gegensatz zum italienischen Ursprung des Faschismus, war der deutsche zusätzlich durch einen extremen Antisemitismus geprägt, der mit dem Holocaust zum größten Völkermord in der Geschichte der Menschheit führte.

Jedoch gelang es den Nationalsozialisten auch, die große Masse der deutschen Bevölkerung zu erreichen. Mit (scheinbaren) sozialpolitischen Maßnahmen nach der Machtübernahme, wie der Erklärung des 1. Mai zum Feiertag und letztlich des Begriffs „National"sozialismus"“ konnten sie auch große Teile der Arbeiterschaft gewinnen. Unterstützt wurde dies mit einem großen Aufwand für Propaganda und einer betäubenden Massenkultur, die viele in ihren Bann zog.

Es gab aber auch Widerstand gegen die Ausbreitung des Faschismus. Zwischen 1936 und 1939 tobte in Spanien ein Bürgerkrieg, bei dem sich die demokratisch gewählte Regierung der jungen spanischen Republik und ihre Anhänger den faschistischen Truppen des Generals Francisco Franco gegenüberstanden. Sozialisten, Kommunisten, Anarchisten und viele andere unterstützten die Republikaner in ihrem Kampf, unterlagen aber schließlich, auch, da das nationalsozialistische Deutschland die Franco-Truppen militärisch unterstützte.

Im Deutschen Reich stellte sich der Widerstand komplizierter dar. Die Terrorherrschaft der Nationalsozialisten hatte viele Menschen eingeschüchtert, zudem gewannen die Herrschenden immer mehr an Zuspruch. Vor allem aber war die deutsche Arbeiterbewegung seit der Weimarer Republik tief gespalten. Die illegalisierte KPD hatte erst lange nach 1933 von ihrer Sozialfaschismusthese abgesehen, die Sozialdemokraten und Faschisten auf eine Stufe stellte. Auch die Sozialdemokratie, die im Exil in Prag und später in Paris residierte, tat sich schwer, Kontakte zu den Kommunisten zu knüpfen. Die erhoffte Einheitsfront blieb lange aus, trotz vieler Bemühungen. Trotzdem bildeten sich in Deutschland viele Widerstandszellen heraus, die trotz der bisher ungekannten Repressionsbedrohung illegal arbeiteten. Das bekannteste Beispiel für den Widerstand aus diesen Kreisen war das Bombenattentat auf Hitler 1939 durch den bayrischen Kommunisten Georg Elser. Neben dem Widerstand der Arbeiterbewegung existierte auch ein bürgerlicher. Die Bekennende Kirche wandte sich gegen die Machthaber, Gruppen wie die Weiße Rose um die Münchner Sophie und Hans Scholl verbreiteten Aufrufe gegen die Nationalsozialisten. Am 20. Juli 1944 verübten schließlich ranghohe Militärs der Wehrmacht ein Attentat auf Hitler, das allerdings missglückte.

1939 begann das Deutsche Reich schließlich mit dem Überfall auf Polen den Zweiten Weltkrieg. Im Laufe der nächsten sechs Jahre fielen ihm rund 60 Millionen Menschen zum Opfer. Über 50 Länder traten in den Krieg ein. Am 8. Mai 1945 wurde der Krieg in Europa mit der Kapitulation Deutschlands und einer verheerenden Bilanz an Opfern und Zerstörung beendet.

Im asiatisch-pazifischen Raum tobte noch für einige weitere Monate der Krieg zwischen den USA und dem mit Deutschland verbündeten Japan, der mit dem Angriff auf Pearl Harbor begann. Mit den Atombombenabwürfen auf Hiroshima und Nagasaki fand diese Schlacht ihren Höhepunkt und gleichzeitig ihr Ende.

Am 8. Mai 1945 kam es zur bedingungslosen Kapitulation der Wehrmacht und Deutschland wurde in vier Besatzungszonen aufgeteilt. Die neuen Supermächte nach dem Ende des Kriegs waren die USA und die Sowjetunion, die sich in Deutschland direkt gegenüberstanden. Mit der Truman-Doktrin brach der schwelende Konflikt als Kalter Krieg offen aus. Deutschland wurde zu einem Schauplatz der Auseinandersetzungen. Auf die Einführung der D-Mark in den drei westlichen Besatzungszonen reagierte die östliche mit der Abriegelung West-Berlins. Bald entstanden zwei deutsche Staaten. Am 23. Mai 1949 die Bundesrepublik Deutschland in den britischen, französischen und US-amerikanischen Besatzungszonen und gut vier Monate später, am 7. Oktober 1949, die Deutsche Demokratische Republik. In der Bundesrepublik stand die Integration in den Einflussbereich der USA nicht zur Debatte. Dies war auch der Sowjetunion bewusst, die sich plötzlich an einer Landesgrenze mit der konkurrierenden Supermacht konfrontiert sah, und sie versuchte, auf ein neutrales geeintes Deutschland zu drängen. Mit den Stalin-Noten von 1952 wurde diese Politik konkret, wobei bis heute deren Ernsthaftigkeit umstritten ist. Die Perspektive eines geeinten Deutschlands gab auch die DDR offiziell mit ihrer neuen Verfassung von 1968 auf. Die deutsche Teilung war zementiert und seit 1961 durchzog eine massiv gesicherte Grenze das Land. Trotzdem waren vor allem in den 1970er Jahren Ansätze zum Dialog erkennbar. Die Ostpolitik Willy Brandts suchte den Kontakt zu den östlichen Nachbarn, die KSZE-Konferenzen in den 1970er Jahren brachten beide Blöcke an einen Tisch und letztlich schon viel früher, 1950, gelang ein Ansatz zur Normalisierung des traditionell problematischen Verhältnisses zwischen Deutschland und Polen durch die Anerkennung der Oder-Neiße-Grenze.

In Westeuropa begann erstmals die Konkretisierung der lang gehegten Träume von den "Vereinigten Staaten von Europa" und die Kriegsfolgen, Armut sowie die großen Vertreibungen bewirkten erste konkrete europäische Einigungsbewegungen. Der Schuman-Plan von 1950, die Gründung der Montanunion 1952 und schließlich die Unterzeichnung der Römischen Verträge von 1957 waren erste Schritte auf diesem Weg, der trotz aller Rückschläge zur Europäischen Integration führte, aus der 1993 die EU in ihrer heutigen Gestalt hervorging. Der Europarat, der Europäische Gerichtshof für Menschenrechte, die Westeuropäische Union sowie die Europäische Wirtschaftsgemeinschaft wurde geschaffen und eine Zollunion begünstigte eine grenzüberschreitende Zusammenarbeit.
Im Einflussbereich der Sowjetunion entstand als Pendant zu den wirtschaftlichen Zusammenschlüssen des Westens der Rat für gegenseitige Wirtschaftshilfe (RGW, im Westen auch "Comecon" genannt).

Weltweit lösten sich seit Kriegsende ehemalige Kolonien von ihren einstigen Beherrschern. An einigen Stellen gelang dies friedlich, an anderen mussten die Befreiungsbewegungen Gewalt einsetzen. Was anfangs vor allem direkt abhängige Kolonien betraf, weitete sich später auch auf de facto abhängige Regime aus. So wurde 1979 das Regime des persischen Schahs Mohammad Reza Pahlavi in der islamischen Revolution gestürzt. Der Schah und sein diktatorisches Regime hielt sich vor allem aufgrund der starken Unterstützung durch den Westen. An seine Stelle wurde eine islamische Republik installiert, die zwar unabhängig wurde, in der aber weiterhin scharfe Menschenrechtsverletzungen herrschten.

In den 1970er Jahren veränderten sich die ökonomischen Eckdaten in den Industriestaaten außerhalb des sowjetischen Einflussbereichs spürbar. Die materielle Warenproduktion hatte nach Ende des Kriegs immense Produktivitätssteigerungen vollzogen und brachte hohe Profitraten. Deren Steigerung schwächte sich in den 1970er Jahren nun deutlich ab. Die Dritte industrielle Revolution brachte die Computertechnik in den Produktionsprozess ein, die Ölkrise wirkte zusätzlich lähmend auf die Industrie. In Europa brachen die schwersten Wirtschaftskrisen seit Ende des Kriegs aus. Die Erwerbslosigkeit wurde in vielen Ländern ein massenhaftes Phänomen. Anstelle starker Lohnsteigerungen in den Jahrzehnten zuvor, die maßgeblich zum Wachstum beitrugen, gab es nun zeitweise Lohnsenkungen. Neue Arbeitsverhältnisse kamen auf, zunehmende Beschäftigung in Büros und in der Dienstleistungsbranche konnten die wegfallenden Industriearbeitsplätze allerdings nur unzureichend ersetzen. Mit diesem Wandel, der auch zunehmend prekäre Beschäftigung mit einschloss, vollzog sich auch eine Schwächung der Gewerkschaften. Beginnend mit Großbritannien unter Margaret Thatcher setzte sich nun immer mehr die politische und wirtschaftliche Theorie des Neoliberalismus um. Entwickelt als Reaktion auf die Weltwirtschaftskrise von 1929 und den folgenden Jahren und als Gegenbewegung zur damals bevorzugen Lösungsstrategie des Keynesianismus, sah er den freien Markt als Zentrum der Wirtschaftspolitik an und versprach so eine Lösung der Probleme des Postfordismus. So sollte als Ausweichort zur Profitgewinnung der Wirtschaft vielerorts die Privatisierung der Öffentlichen Daseinsvorsorge fungieren, etwa durch Privatisierung von Bahngesellschaften oder Versorgungsbetrieben. Diese Politik rief teils heftige Gegenwehr der Gewerkschaften und linken Parteien hervor, durchsetzen konnten sie sich allerdings nicht. Die Vorherrschaft dieser Art von Politik weitete sich mit dem Zusammenbruch der Sowjetunion, dem damit verbundenen Wegfall einer eventuellen Systemalternative und der Enttäuschung weiter Kreise der politischen Linken aus.

Als 1985 in der Sowjetunion mit Michail Gorbatschow ein neuer Generalsekretär an die Macht kam, war die Supermacht bereits großen Problemen ausgesetzt. Die Versorgungslage gestaltete sich immer schwieriger, ein Problem, mit dem auch die DDR konfrontiert war, deren Sozialpolitik unter der Regierung Honecker – etwa Wohnungsbau und Ausweitung der Versorgung mit Konsumgütern – nicht mit der volkswirtschaftlichen Leistung standhalten konnte. Mit der Politik von Perestroika und Glasnost versuchte Gorbatschow gesellschaftliche Reformen durchzusetzen. Die zunehmende Meinungsfreiheit in der Sowjetunion konnte freilich die Probleme nicht beseitigen. Als sich die sowjetische Intervention in Afghanistan als Fiasko abzuzeichnen begann, wurde die Nuklearkatastrophe von Tschernobyl am 26. April 1986 zu einem Symbol für das Versagen des kommunistischen Systems und offenbarte die allgemeine Missachtung der Bevölkerungsinteressen durch die Behörden. Die sowjetische Reformpolitik stieß zudem auf zum Teil heftige Ablehnung in den anderen Ostblockstaaten. So verharrte die DDR-Führung auf ihrer über die Jahre erprobten Linie und unterdrückte sogar Nachrichten aus der Sowjetunion. Sie nahm beispielsweise 1988 die sowjetische Zeitschrift "Sputnik" aus dem Postvertrieb, was einem Verbot gleichkam, da diese einen Artikel veröffentlichte, der sich mit den Verbrechen des Stalinismus auseinandersetzte. Die Opposition in der DDR stieg zunehmend an. Im Sommer 1989 nutzten schließlich unzählige DDR-Bürger die Öffnung der Grenze zwischen Ungarn und Österreich und flohen über Budapest in den Westen, weitere suchten Zuflucht in der Deutschen Botschaft Prag. Im Herbst 1989 gingen erstmals in Leipzig Menschen auf die Straße, um auf den Montagsdemonstrationen für politische Reformen zu protestieren. Am 4. November fand auf dem Berliner Alexanderplatz die größte nicht staatlich organisierte Demonstration in der Geschichte der DDR statt. Die Teilnehmer forderten eine demokratische DDR mit einem pluralen Parteiensystem, ohne Staatssicherheit und ein Ende der Entmündigung. Eine Vereinigung mit der Bundesrepublik wurde explizit abgelehnt. Diese Stimmung dominierte fünf Tage lang die DDR, bis am 9. November die Berliner Mauer und die Grenzen zur Bundesrepublik geöffnet wurden und noch in der Nacht zehntausende Menschen den Westteil Berlins besuchten. Die DDR-Führung konnte sich nicht mehr halten, Mitglieder des Politbüros traten zurück, die Führung wurde von Honecker auf Egon Krenz übertragen, aber auch dieser war zu einem Bruch nicht in der Lage. Nachdem der Führungsanspruch der SED aus der Verfassung der DDR getilgt wurde, hielt die ehemalige Staatspartei gegen den Willen ihrer Führung im Dezember einen Parteitag ab, der sich über zwei Wochenenden hinzog. Es war der erste Parteitag, dessen Delegierte frei gewählt wurden und auf dem frei diskutiert werden konnte. In der Folge wurde die Parteiführung komplett ausgetauscht, die Strukturen verändert und dem Parteinamen SED das Kürzel PDS – Partei des Demokratischen Sozialismus – beigefügt. Die ehemalige Staatspartei, die sich ab 1990 nur noch PDS nannte, konnte sich bei der folgenden Volkskammerwahl 1990 nur noch schwer gegen die neue Konkurrenz durchsetzen und kam nur auf den dritten Platz.

Nach der Maueröffnung wurde der Ruf nach der Einheit Deutschlands immer lauter. Aus der Parole der Montagsdemonstrationen "Wir sind das Volk" wurde bald "Wir sind ein Volk". Nach der Volkskammerwahl begannen Verhandlungen der DDR-Regierung mit der der Bundesrepublik über einen Beitritt des Landes. Im Sommer wurde die D-Mark auch auf dem Gebiet der DDR zum offiziellen Zahlungsmittel. In der Folge standen dem großen Warenangebot zu Preisen wie im Westen die Gehälter auf DDR-Niveau gegenüber. Viele Betriebe, die von der schwachen DDR-Währung profitierten und preisgünstige Waren für den Export produzierten, waren nicht mehr konkurrenzfähig. Nachdem die Volkskammer schließlich die Auflösung der DDR und den Beitritt des Gebietes zum Geltungsbereich des Grundgesetzes beschloss, wurde am 3. Oktober der Einigungsvertrag vollzogen.

Die Revolutionen im Jahr 1989 führten zum Zusammenbruch der realsozialistischen Systeme in Zentral- und Osteuropa. Einige dieser Aufstände, wie die Samtene Revolution in der Tschechoslowakei oder die Singende Revolution in den baltischen Staaten, blieben friedlich. Andere verliefen gewalttätig, etwa der Sturz des rumänischen Diktators Nicolae Ceaușescu, der sich schon Jahre vorher von der Sowjetunion distanzierte und ein neostalinistisches System installiert hatte. Der gescheiterte Augustputsch in Moskau 1991 führte zum Verbot der KPdSU und zum endgültigen Zerfall der Sowjetunion. Der KPdSU-Funktionär Boris Jelzin ersetzte Michail Gorbatschow und wurde Präsident der neuen Russischen Föderation.

Mit dem Untergang der Sowjetunion hörte auch die Phase der Bipolarität in der Welt auf. Die USA waren die einzige verbliebene Weltmacht. Entsprechend änderten sich auch die Konfliktlinien. Wurde in der Zeit des Ost-West-Konflikts und des Kalten Kriegs Stellvertreterkriege geführt, in denen die beiden Machtblöcke mittels jeweils unterstützter dritter Parteien aufeinandertrafen, so brachen mit dem letzten Jahrzehnt des 20. Jahrhunderts andere Kriege aus. Bereits 1991 begann der Golfkrieg zwischen den USA und dem Irak unter dem Diktator Saddam Hussein, der Jahre vorher noch von den Amerikanern als antisowjetische und anti-iranische Kraft gestützt wurde. Es folgten Kriege auf dem Balkan, wo der Staat Jugoslawien in seine Einzelstaaten auseinanderbrach. Auch in Osteuropa brachen Staaten in ihre Teilbestände auseinander. Bei der Sezession der baltischen Staaten gelang dies nur mit Gewalt, bei der Teilung der Tschechoslowakei in ihren tschechischen und slowakischen Teil wurde hingegen keine Waffe benutzt. Kriegerische Konflikte verloren ihre Zentren, die Zeit der großen Panzerschlachten war genauso beendet wie der Krieg zwischen zwei Armeen zweier Staaten. An ihre Stellen traten Luftangriffe und andere aus der Ferne gesteuerte Methoden der Kriegführung, die sich gegen einen nicht-staatlichen, meist als Guerilla organisierten Gegner richteten.

Auf der anderen Seite vergrößerte sich die Europäische Union seit den 1990er Jahren stetig. Im neuen Jahrtausend sollten auch immer mehr Staaten des ehemaligen sowjetischen Einflussbereichs ihr beitreten. Durch die Installierung der europäischen Gemeinschaftsorgane konnte bereits am 1. November 1993 der europäische Binnenmarkt Wirklichkeit werden. Die OEEC und EFTA ermöglichten eine große Freihandelszone. Es folgte die Europäische Gemeinschaft bzw. die EU und die EU-Erweiterung mit den mittel- und osteuropäischen Ländern.

Albert Einstein entwickelt die Spezielle und später die Allgemeine Relativitätstheorie, in deren Folge sowohl Kernkraftwerke als auch die Atombombe entwickelt werden. Mit der Begründung der Polymerchemie wird die Basis für die Entwicklung der Kunststoffindustrie gelegt und der Siegeszug von Plastik nimmt seinen Lauf. Die Identifikation der Desoxyribonukleinsäure als Erbsubstanz gelingt Oswald Avery; ihre Struktur entschlüsseln Francis Crick und James Watson. Damit wird die Gentechnologie begründet. Hans Krebs entdeckt zentrale metabolische Reaktionszyklen wie etwa den Citratzyklus. Die Architektur von Atomen wird von Ernest Rutherford durchleuchtet. Christiaan Barnard führt die erste Herztransplantation durch. Die über 300 Jahre alte Fermatsche Vermutung wird von Andrew Wiles und Richard Taylor bewiesen. Der Orthopäde Gawriil Abramowitsch Ilisarow entwickelt grundlegende Verbesserungen orthopädischer Operationsmethoden. Durch seine Forschungsarbeiten zur Kallusdistraktion gelingt ihm die Entwicklung des Fixateur externe, womit er einen fundamental bedeutenden Beitrag zur Osteosynthese leistet.

Im 20. Jahrhundert entwickeln sich technologische und elektronische Geräte zu Massenkonsumgütern wie Haushaltsgeräte, Werkzeuge, Computer, Kommunikationsmittel, Medien, Ton- und Bildwiedergabegeräte sowie auch Fortbewegungsmittel. Mechanische Geräte werden in immer mehr Bereichen durch digitale oder elektrische Innovationen ersetzt; Hygiene, Verpackung und Mobilität gewinnen an Bedeutung.

Der Verbrennungsmotor sowie die Elektrizität ersetzen zunehmend die Dampfmaschine zum Antrieb von Schienen- und Wasserfahrzeugen. Der individuelle Straßenverkehr gewinnt gegenüber dem Schienenverkehr an Dominanz, was sich signifikant auf die Stadtplanung auswirkt. Der Luftverkehr kommt auf und entwickelt sich zum planmäßigen Linienverkehr. Globaler Personenfernverkehr wird bald fast ausschließlich in der Luft abgewickelt. Im Schienenverkehr kommen Hochgeschwindigkeitszüge, in der globalen Handelsschifffahrt Tank- und Containerschiffe auf.

Am 4. Juni 1944 durchbrach eine Rakete vom typ Aggregat 4 (V2) als das erste von Menschen konstruierte Objekt, die Grenze zum Weltraum (nach Definition der FAI mehr als 100 km Höhe, die Kármán-Linie). Am 4. Oktober 1957 wurde mit Sputnik 1 der erste künstliche Erdsatellit gestartet – der Beginn der Raumfahrt. Im selben Jahr wurde am 3. November die Hündin Laika, als erstes Lebewesen, ins All befördert.
Juri Gagarin gelang es am 12. April 1961 mithilfe von Wostok 1, die erste Erdumkreisung durchzuführen. Bei der Mission Woschod 2, 1965, glückte der erste Weltraumausstieg von Alexei Leonow. Drei Jahre später, am 21. Dezember, gelang die erste bemannte Mondumkreisung der Mission Apollo 8. Am 20. Juli 1969 landete Apollo 11 zusammen mit Neil Armstrong, als erstem Menschen auf dem Mond.
Die Apollo 17 startete am 7. Dezember 1972 den letzten bemannten Flug zum Mond. 1977 wurden mit der Voyager 1 und der Voyager 2 erstmals Sonden losgeschickt, die eine Goldene Datenplatte mit Aufnahmen der Erde enthalten.
Mit 51 Pegasi b, wurde 1995 der erste Planet außerhalb unseres Sonnensystems entdeckt. 1998 begann das Projekt der Internationalen Raumstation ISS.

Die Bildende Kunst des 20. Jahrhunderts war von der Avantgarde und Stilrichtungen wie Moderne, Kubismus, Pop Art und Surrealismus geprägt. Herausragende Protagonisten waren Salvador Dalí, Pablo Picasso und Max Beckmann.

Das 19. Jahrhundert verabschiedete sich mit Tendenzen, die die bekannte europäische Musikkultur langsam auflösten. Franz Liszt und sein Schwiegersohn Richard Wagner experimentierten mit neuen Harmonien, Claude Debussy rezipierte Wagner, ließ sich von fernöstlicher Pentatonik beeinflussen und wandelte die Malerei des Impressionismus in die Musik mit gleicher Bezeichnung um. Betroffen waren alle von den ökonomischen Entwicklungen. Wagner schrieb bereits im ausgehenden 19. Jahrhundert über die Ökonomisierung der Kunst, in der diese zur Ware werde – gewiss ohne bereits den marxschen Begriff zu gebrauchen. Im Laufe des 20. Jahrhunderts verband sich an vielerlei Stellen die ökonomische, politische und gesellschaftliche Entwicklung mit der Kunst. Der Periode der atonalen Musik folgte die Zwölftonmusik des österreichischen Komponisten Arnold Schönberg. Schönberg strich sämtliche Hierarchien der Töne aus der Musik und ersetzte sie durch alle 12 Töne, die gleichberechtigt in einem Stück fungierten.

Der europäische Faschismus hatte tiefgreifende Folgen auch auf die Entwicklung der Musik. Die in den 30er Jahren bereits entwickelte Moderne wurde als „entartet“ oder „jüdisch-bolschewistisch“ gebrandmarkt, die meisten Komponisten und Musiker mussten ins Exil fliehen. Vor allem die Nationalsozialisten setzten an ihre Stelle konservative Töne, wie die des noch in der Spätromantik verhafteten Hans Pfitzner. Die repressive und rückwärtsgewandte Kulturpolitik der Nazis setzte dem europäischen Musikleben stark zu und verhinderte, dass 1945 ungebrochen an die Entwicklungen Anschluss gehalten werden konnte.

In der Sowjetunion und ihren späteren Satellitenstaaten entwickelte sich eine vom Staat beeinflusste Musik unterdessen gänzlich anders. Zwar installierten die Herrschenden die Ideologie des Sozialistischen Realismus, dieser Begriff blieb allerdings schwammig. So galt die Zwölftonmusik als „bürgerlich-dekadent“, als allerdings Hanns Eisler mit ihr experimentierte und ernsthaft komponierte, nahm sie still Einzug in den Kanon des Sozialistischen Realismus. Auch in der Sowjetunion entwickelte sich ein reichhaltiges Musikleben, das vor allem in der Zeit des Stalinismus ständig zwischen Anpassung und Verfolgung pendelte. Sergei Prokofjew und vor allem Dmitrii Schostakowitsch bewegten sich ständig zwischen den Polen höchster Auszeichnung und der Furcht vor der Verhaftung. Trotzdem gehören ihre Werke zu den bedeutendsten der Kunstmusik des 20. Jahrhunderts.

Auch in der westlichen Welt war das Musikschaffen nicht von der Politik abgekoppelt. In den 60er und 70er Jahren, im Umfeld der 68er-Bewegung und der folgenden sozialen Bewegungen, zum Beispiel gegen den Vietnamkrieg, fungierten viele Kunstschaffende als politische Akteure. Vor allem in Italien wurde drei Namen aus der Kunstmusik für diese "engagierte Musik" bekannt: Der Komponist Luigi Nono, der Dirigent Claudio Abbado und der Pianist Maurizio Pollini. Auch in Deutschland fungierte mit Hans Werner Henze ein gewichtiger Vertreter der Kunstmusik, der sich zu den politischen Ereignissen der Zeit positionierte, das als drückend empfunden Land aber schon in den 50er Jahren Richtung Italien verließ.

Stilistisch war die Nachkriegszeit von der seriellen Musik, der Verwendung von Synthesizern und anderen elektronischen Stilmitteln geprägt. Diese breiteten sich mit der Verzögerung von Jahrzehnten auch in der populären Musik aus.

Das 20. Jahrhundert war aber vor allem durch den Aufstieg der populären Musik gekennzeichnet. Aus den USA kam Anfang des Jahrhunderts der Ragtime nach Europa und vor allem nach dem Ersten Weltkrieg breitete sich überall in den europäischen Städten der Jazz aus. Die Vielzahl an Unterhaltungslokalen machte es möglich. Nach dem Zweiten Weltkrieg brachten wiederum amerikanischen Besatzungstruppen den Swing nach Deutschland, der während der NS-Herrschaft verboten war. Später breitete sich der Rock ’n’ Roll aus, der auf scharfen Widerstand der konservativen deutschen Gesellschaft stieß. Ähnlich wie Beatmusik wurde er zum Ausdruck einer rebellierenden neuen Generation.

Deutlicher wurden diese generationsgeschichtlichen Zusammenhänge nochmals in den Jahren nach 1990, als sich vor allem in Berlin eine neue Richtung der elektronischen Musik herausbildete. Techno stand für einen neuen Hedonismus, den die neue Weltordnung nach dem Zusammenbruch der Sowjetunion und der Wegfall der Blockauseinandersetzung hervorbrachte und prägte eine gesamte Jugendgeneration.

Das 20. Jahrhundert war das Jahrhundert des Films. 1895 fand in Berlin die erste belegte Aufführung eines Stummfilms statt. In den folgenden drei Jahrzehnten entwickelte sich dieser zur Blüte. Schon im Ersten Weltkrieg gehörten Filme zu einem gewichtigen Teil der Propaganda, sie brachten die neuen bedrohlichen Panzer an die Heimatfront und trugen dazu bei, dass Militärs wie Paul von Hindenburg zu Kriegshelden stilisiert wurden. In Deutschland entstand in Berlin-Weißensee das zeitweise weltweit bedeutendste Zentrum des Films. Dort entstanden Klassiker wie "Das Cabinet des Dr. Caligari", "Nosferatu – Eine Symphonie des Grauens" oder "Metropolis". Sehr bald entwickelte sich jedoch eine ernstzunehmende Konkurrenz im kalifornischen Hollywood, wo im Laufe des 20. Jahrhunderts die größte Ansammlung von Filmstudios in der westlichen Welt entstehen sollte.

Nachdem sich um 1930 langsam der Tonfilm durchsetzte, stieg Hollywood endgültig zur führenden „Filmmacht“ auf. Während des Zweiten Weltkriegs spielte der Film eine immense Rolle für die Propaganda der kriegführenden Parteien. Bekanntestes und herausragendes Beispiel dieser Art von Film ist "Der große Diktator" mit Charlie Chaplin als Regisseur und in mehreren Hauptrollen unter anderem in der Figur des an Hitler angelehnten ins Lächerliche gezogenen Anton Hynkel.

Nach dem Krieg spaltete sich auch die Filmgeschichte in Deutschland. Im Westen wurden über Jahrzehnte vorrangig belanglose Unterhaltungs- und Heimatfilme produziert. Die jüngere Vergangenheit wurde explizit ausgeblendet. Erst in den 70er Jahren gewann das Kino der Bundesrepublik langsam wieder an Bedeutung. In der DDR hingegen entstand mit der DEFA ein Filmproduzent von hoher Qualität, der eine ganze Reihe an Autorenfilmen und vor allem solchen Werken produzierte, die sich mit der NS-Vergangenheit auseinandersetzten. Allerdings entstanden auch Filme, deren Ansatz nicht den Vorstellungen der politischen Führung entsprach. Der Film "Spur der Steine" beispielsweise, mit Manfred Krug in der Hauptrolle, wurde 1966 drei Tage nach der Uraufführung aus dem Programm genommen und in der DDR erst wieder 1989 gezeigt. Dieses Schicksal teilten noch eine Reihe anderer Filme.

Im 20. Jahrhundert wurden viele Sportarten professionalisiert und es etablierten sich weltweit beachtete Sportereignisse, die in regelmäßigen Abständen wiederholt wurden, so Welt- und Kontinentalmeisterschaften in vielen Sportarten, die Olympischen Sommer- und Winterspiele und andere. Durch die Berichterstattung der Massenmedien und die entsprechende Aufmerksamkeit der Öffentlichkeit erzielten Spitzenathleten Einkommen, von denen sie ihren Lebensunterhalt bestreiten konnten und die ihnen ermöglichten, sich hauptberuflich auf ihren Sport zu konzentrieren. Später im Jahrhundert wuchsen die Einkommen entsprechend herausragender Aktiver in einzelnen Sportarten zu Gehältern der Oberschicht an. Zu den Sportarten, mit denen zunehmend solche Einkünfte erzielt werden konnten, zählen u. a. American Football, Basketball, Baseball, Eishockey, Radsport, Tennis, Golf, Automobilsport und Fußball. In letzterem etablierten sich weltweit organisierte Profiligen, auch in Deutschland, Österreich und der Schweiz. Mit der Möglichkeit, mit Sport nennenswerten Gewinn zu erzielen, erwuchsen auch entsprechende Manipulationstechniken, so wurden etwa Doping oder in Deutschland der Bundesliga-Skandal bekannt.



100(0) Schlüsseldokumente zur deutschen Geschichte im 20. Jahrhundert. In: 1000dokumente.de


</doc>
<doc id="5845" url="https://de.wikipedia.org/wiki?curid=5845" title="1910er">
1910er

























</doc>
