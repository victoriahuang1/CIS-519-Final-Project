<doc id="10690" url="https://de.wikipedia.org/wiki?curid=10690" title="Chromosom">
Chromosom

Chromosomen (von griechisch "chrōma" ‚Farbe‘ und "sōma" ‚Körper‘, also wörtlich „Farbkörper“) sind meist stabförmige Körperchen, die bei der Teilung von Zellkernen (Mitose oder Meiose) auftreten. Es handelt sich um Makromolekül-Komplexe, die der Speicherung und Weitergabe der Erbinformation (Gene) dienen. Die beteiligten Makromoleküle, die zusammen auch als Chromatin bezeichnet werden, sind Desoxyribonukleinsäure (DNA) und verschiedene Proteine. Die Bezeichnung „Chromosom“ rührt daher, dass diese Strukturen mit basischen Farbstoffen spezifisch angefärbt werden können.

Die Chromosomen gehen als einzelne Körperchen zu Beginn der Kernteilung (Prophase) durch eine Verdichtung (Kondensation) aus dem vorher einheitlich erscheinenden Kerninhalt (Chromatin) hervor. Sie stellen die Transportform des Chromatins dar, wobei jedes Chromosom zwei identische und parallel liegende DNA-Doppelstränge enthält, die mit den begleitenden Proteinen als Chromatiden bezeichnet werden. In der Anaphase werden die Chromatiden getrennt und treten auseinander, wobei sie den sich bildenden Tochterkernen zugeteilt werden. Nach Abschluss der Kernteilung und in der stoffwechselaktiven Phase des Zellzyklus, die als Interphase bezeichnet wird, gehen die Chromosomen wieder in einen dekondensierten Zustand über und sind mit den klassischen Färbemethoden nur noch als weitgehend homogenes Chromatin darstellbar. Nur in diesem dekondensierten Zustand kann die DNA abgelesen oder dupliziert werden. Mit Hilfe einer speziellen Nachweistechnik, der Fluoreszenz-in-situ-Hybridisierung, lässt sich aber zeigen, dass auch in der Interphase jedes Chromosom im Zellkern einen abgegrenzten Bereich einnimmt, ein Chromosomenterritorium "(siehe Abbildungen)".

Chromosomen treten nur bei Eukaryoten (Lebewesen mit Zellkernen) auf, zu denen alle Tiere, Pflanzen und Pilze gehören. Prokaryoten (Lebewesen ohne Zellkern), also Bakterien und Archaeen, besitzen keine Chromosomen im klassischen Sinn, sondern ein oder mehrere, meist zirkuläre DNA-Moleküle, die manchmal als „Bakterienchromosom“ bezeichnet werden, obwohl diese mit den eukaryotischen Chromosomen nicht viel gemeinsam haben. Fast alle Gene der Eukaryoten liegen auf den Chromosomen. Einige wenige liegen auf DNA in den Mitochondrien und bei Pflanzen auch in den Plastiden. In den Mitochondrien und Plastiden ist die DNA ringförmig wie bei Bakterien (vgl. Endosymbiontentheorie).

Der Name "Chromosom" wurde 1888 von dem Anatomen Heinrich Wilhelm Waldeyer vorgeschlagen, nachdem Walther Flemming einige Jahre zuvor den Begriff "Chromatin" für die färbbare Substanz im Zellkern eingeführt hatte. Noch 1906 nutzte Oscar Hertwig parallel dazu den Begriff "Kernsegmente", welcher verdeutlichen sollte, dass bei der Teilung des Kerns (Mitose) „das Chromatin in Segmente zerlegt wird“. Eine weitere alte Bezeichnung, die ebenfalls eine Weile parallel zu "Chromosom" benutzt wurde, ist "Kernschleife", zum Beispiel bei Karl Heider (1906).

Die Geschichte der Entdeckung der Chromosomen und ihrer Funktion lässt sich nicht von der vorangegangenen Entdeckung des Zellkerns trennen "(siehe zuerst dort)".

1842 beschrieb der Schweizer Botaniker Carl Wilhelm von Nägeli „transitorische Zytoblasten“ (anfärbbare stäbchenförmige Strukturen im Zellkern von Pflanzenzellen) bei denen es sich vermutlich um Chromosomen handelte. Auch Abbildungen aus den Werken anderer Forscher lassen sich mit heutigem Wissen als Chromosomen bzw. mitotische Zellteilung deuten (Matthias Schleiden 1846, Rudolf Virchow 1857, Otto Bütschli 1873).
1873 beschrieb Anton Schneider an Plattwürmern, dass der Zellkern sich „in einen Haufen feinlockig gekrümmter, auf Zusatz von Essigsäure sichtbar werdender Fäden verwandelt. An Stelle dieser dünnen Fäden traten endlich dicke Stränge auf, zuerst unregelmäßig, dann zu einer Rosette angeordnet, welche in einer durch den Mittelpunkt der Kugel gehenden Ebene (Äquatorialebene) liegt.“ Die „indirekte Kernteilung“ (Mitose) war entdeckt – aber noch nicht verstanden. So ging Walther Flemming 1882 noch davon aus, dass sich die „Kernfäden“ erst während der frühen Phase der Kernteilung aus einem zuvor durchgehenden Faden voneinander trennen. Zwar beobachtete er eine Längsspaltung der Chromosomen zu einem späteren Zeitpunkt (heute als Metaphase bezeichnet), nahm aber an, dass sich "ganze" Chromosomen (also mit beiden Chromatiden) später (heute: Anaphase) in Richtung der künftigen Zellkerne bewegen. Auch schloss er nicht aus, dass sich Zellkerne zumindest in manchen Fällen auch neu bilden könnten, also nicht durch Teilung aus bestehenden Kernen. 1884 beschrieben dann mehrere Autoren (L. Guignard, Emil Heuser und Edouard van Beneden) die Aufteilung der Chromosomenhälften (heute: Chromatiden) auf die Tochterzellkerne.

Da die Chromosomen während der Interphase nicht sichtbar waren, war zunächst unklar, ob sie sich nach einer Kernteilung auflösen und vor jeder Kernteilung neu bilden oder ob sie im Kern als jeweils eigene Einheiten überdauern. Letztere Idee wurde als Lehre von der Erhaltung der Individualität der Chromosomen bezeichnet und von Carl Rabl vorgeschlagen (1885). Er war auch der erste, der erstens eine konstante Zahl von Chromosomen bei verschiedenen Mitosen eines Gewebes feststellte und zweitens daraus schloss, dass die Chromosomen auch in der Interphase und somit kontinuierlich vorhanden sein müssten. Er ließ aber zunächst noch die Möglichkeit offen, dass diese Zahl in verschiedenen Geweben unterschiedlich sein könnte. Rabl war ebenfalls der erste, der annahm, dass jedes Chromosom im Interphasekern ein eigenes Territorium bildet.

Die Idee der Chromosomenkontinuität fand keineswegs ungeteilte Zustimmung. Ein wichtiger Gegner war Oscar Hertwig (1890, 1917). Theodor Boveri dagegen befürwortete Rabls Ideen und unterstützte sie mit weiteren experimentellen Befunden (1904, 1909). Ebenfalls in den 1880er Jahren entwickelte August Weismann seine Keimplasmatheorie "(siehe auch dort)", bei der er davon ausging, dass das Erbmaterial (nur) in den Chromosomen lokalisiert sei. Wichtige Schlussfolgerungen waren, dass Vererbung ausschließlich über die Keimbahn stattfinde und dass eine Vererbung erworbener Eigenschaften abzulehnen sei. Was sich später als weitgehend richtig erwies, war damals heftig umstritten. Eine schonungslose Kritik findet sich beispielsweise in Meyers Konversations-Lexikon von 1888 unter dem Stichwort "Erblichkeit".

Im Jahr 1900 wurden die Mendelschen Regeln wiederentdeckt und bestätigt. In der Folge entwickelte sich die neue Wissenschaft der Genetik, in deren Rahmen der Zusammenhang von Chromosomen und Vererbung vielfach gezeigt wurde. Beispielsweise konnte Thomas Hunt Morgan 1910 an "Drosophila melanogaster" den Nachweis führen, dass die Chromosomen die Träger der Gene sind. 1944 zeigte Oswald Avery "(siehe dort)", dass das eigentliche Erbmolekül die DNA ist, und nicht etwa Proteine in den Chromosomen.

Die weitere Geschichte bis 1950 (Aufklärung der Struktur der DNA) ist im Artikel Chromosomentheorie der Vererbung beschrieben. Eine Zeittafel einiger wichtiger Entdeckungen ist im Artikel Chromatin zu finden.

Im Jahr 2000 haben zwei internationale Wissenschaftlerteams das menschliche Erbgut weitgehend entziffert, im Jahr 2003 waren 99 Prozent sequenziert. Mit dem Chromosom 1 wurde 2005/2006 das letzte der 24 verschiedenen menschlichen Chromosomen genau analysiert (99,99 %). Über 160 Wissenschaftler aus Großbritannien und den USA publizierten diese Gemeinschaftsarbeit.

2014 gelang erstmals das Design und die Konstruktion eines synthetischen Chromosoms, und zwar in der Bäckerhefe "Saccharomyces cerevisiae".

Abgesehen von Spezialfällen (siehe Riesenchromosomen unten) enthält ein Chromosom im einfachen Fall "einen" durchgehenden DNA-Doppelstrang (auch: DNA-Doppelhelix). Der DNA-Doppelstrang wird manchmal auch als DNA-Molekül bezeichnet, obwohl es sich streng genommen um zwei Einzelstrang-Moleküle handelt "(siehe Desoxyribonukleinsäure)".
An den DNA-Doppelstrang lagern sich "Histone" und andere Proteine an (siehe unten). Die Mischung aus DNA, Histonen und anderen Proteinen wird als Chromatin bezeichnet. Aus "einem" DNA-Doppelstrang wird durch diese Protein-Anlagerung "ein" Chromatid aufgebaut. In diesem Fall besteht das Chromosom also aus einem Chromatid.
Der beschriebene Fall tritt immer direkt nach einer Kernteilung auf; bei den meisten Tieren und Pflanzen zusätzlich in allen Zellen, die sich nicht mehr teilen können (Ausnahme: Polytänchromosomen bei Insekten, siehe auch unten), und in Zellen, die zeitweilig nicht mehr wachsen, sich also in der G0-Phase befinden "(siehe Zellzyklus)".

Wenn eine Zelle wächst, um sich später zu teilen, dann muss in einem bestimmten Abschnitt des Zellzyklus (S-Phase) die DNA verdoppelt („repliziert“) werden. Dies ist erforderlich, damit später beide Tochterkerne das ganze Erbgut, also je eine Kopie aller Chromosomen, erhalten können. Nach der DNA-Verdopplung hat jedes Chromosom zwei identische DNA-Doppelstränge. Diese beiden Doppelstränge werden räumlich getrennt voneinander mit Proteinen verpackt: Zwei "Schwester-Chromatiden" entstehen. Während der Kernteilung (Mitose) werden die beiden Schwester-Chromatiden eines Chromosoms als zwar parallel verlaufende, aber durch eine schmale Lücke getrennte Einheiten mikroskopisch sichtbar "(siehe Schemazeichnung rechts und erste Abbildung des Artikels)". An einer Stelle, die "Centromer" oder Zentromer genannt wird, ist jedes Chromosom zu diesem Zeitpunkt schmaler als im sonstigen Verlauf: Hier hängen die Schwester-Chromatiden noch zusammen. Im weiteren Verlauf der Mitose (am Übergang von der Metaphase zur Anaphase, siehe unten) werden die beiden Schwester-Chromatiden getrennt – wobei durch die Trennung zwei Tochterchromosomen entstehen – und auf die neu entstehenden Zellkerne verteilt: Die Chromosomen in diesen neuen Kernen bestehen jetzt wieder aus einem Chromatid. Demnach enthält ein Chromatid immer genau einen DNA-Doppelstrang, während ein Chromosom je nach Phase des Zellzyklus ein oder zwei DNA-Doppelstränge enthält und entsprechend aus einem oder zwei Chromatiden besteht. (Ausnahme: die erwähnten Polytänchromosomen, die über tausend Doppelstränge enthalten können.)
Durch das Centromer werden die Chromatiden in zwei "Arme" unterteilt. Je nach Lage des Centromers spricht man von metazentrischen Chromosomen (Centromer in der Mitte), akrozentrischen Chromosomen (Centromer am Ende, der kürzere Arm sehr klein; beim Menschen die Chromosomen 13, 14, 15, 21, 22 und das Y-Chromosom) oder submetazentrischen Chromosomen (Centromer zwischen Mitte und Ende). Der kürzere Arm wird als "p-Arm" ("petit", französisch für klein), der längere als "q-Arm" bezeichnet (q folgt im lateinischen Alphabet auf p). Wie in der Schemazeichnung werden Chromosomen generell mit den kurzen Armen nach oben dargestellt.

Die Enden der Chromosomen heißen "Telomere" (Einzahl: Telomer). Sie enthalten eine kurze, sich identisch wiederholende DNA-Sequenz (beim Menschen TTAGGG). Dort werden die Chromosomen bei jeder Verdopplung ein wenig kürzer. Die Telomere spielen daher bei Alterungsprozessen eine wichtige Rolle. Neben Centromer und Telomeren sind Startpunkte für die DNA-Verdopplung (Replikation) der dritte essentielle Bestandteil eines Chromosoms "(siehe ARS-Element)".

Beim Menschen enthalten die kurzen Arme der akrozentrischen Chromosomen Gene für die ribosomale RNA. Diese kurzen Arme können in kondensierten Metaphasechromosomen durch einen Satelliten verlängert sein, so dass Satellitenchromosomen ("SAT-Chromosomen") vorliegen (nicht zu verwechseln mit Satelliten-DNA). Die Gene für die ribosomale RNA liegen in vielen, tandemartig hintereinanderliegenden Kopien vor. Im Interphase-Zellkern bildet sich an diesen der Nucleolus. Daher werden sie auch als Nucleolus-organisierende Regionen (NOR) bezeichnet.

Im Folgenden sind die Phasen während der Mitose kurz wiedergegeben:
Nach der Kernteilung erfolgt in der Regel auch die Zellteilung, die Cytokinese oder Zytokinese, die aber nicht mehr zur Mitose gerechnet wird.

In der Mitte des 20. Jahrhunderts wurden Techniken entwickelt, um die Chromosomen aus Zellen, die sich in der Metaphase befinden, zu „spreiten“: Im entstandenen Metaphasepräparat liegen die Chromosomen einer Zelle nebeneinander auf einem Objektträger, so dass sie im Mikroskop abgezählt und miteinander verglichen werden können "(siehe erste Abbildung oben)". In gut gelungenen Präparaten haben die einzelnen Chromosomen dabei die häufig dargestellte X-ähnliche Form. Mit den klassischen Färbemethoden wie zum Beispiel Giemsa-Färbung werden Chromosomen auf ganzer Länge gleichmäßig eingefärbt. Daher war es zunächst nicht oder nur schwer möglich, Chromosomen ähnlicher Größe sicher voneinander zu unterscheiden. Um 1970 wurde entdeckt, dass einige Bereiche der Chromosomen den Giemsa-Farbstoff nicht mehr annehmen, wenn die Chromosomen zuvor mit Trypsin behandelt wurden. Durch die hervorgerufene G-Bänderung entstanden entlang der Chromosomen abwechselnd gefärbte Abschnitte (die G-Banden, G für Giemsa) und ungefärbte (die R-Banden, R für revers). Durch das Bandenmuster ist beim Menschen und etlichen Tieren eine eindeutige Identifizierung aller Chromosomen möglich. Die stoffliche Grundlage für das unterschiedliche Färbeverhalten der Banden, also die Frage, warum einige Bereiche nach der Trypsinbehandlung den Farbstoff nicht mehr aufnehmen, ist bis heute ungeklärt. Es stellte sich jedoch heraus, dass G- und R-Banden sich in einigen Eigenschaften unterscheiden.

R-Banden enthalten überdurchschnittlich viele Gene, überdurchschnittlich viele G-C-Basenpaarungen und werden während der Replikation der Chromosomen früh verdoppelt. Beim Menschen sind sie reich an Alu-Sequenzen "(siehe dort und Abbildung rechts)".

G-Banden sind genarm, die Anzahl der G-C-Basenpaare liegt unter dem Durchschnitt (dafür haben sie mehr A-T-Paare; siehe Desoxyribonucleinsäure) und sie werden während der Duplizierung der Chromosomen eher spät repliziert. Beim Menschen sind sie reich an L1-Elementen "(siehe Long interspersed nuclear element)".

Als weitere Bandentypen werden manchmal C-Banden (die Centromerregionen) und T-Banden unterschieden. Letztere sind eine Untergruppe der R-Banden, besonders genreich und liegen häufig in der Nähe der Telomere, daher der Name.

Die Anzahl der R- und G-Banden ist abhängig vom Kondensationsgrad der Chromosomen. In der Metaphase haben alle menschlichen Chromosomen zusammen etwa 400 dieser Banden, während in den noch nicht so stark kondensierten Prophasechromosomen bis zu 850 Banden unterschieden werden können.

Nomenklatur: Um eine genaue Bezeichnung aller chromosomalen Regionen zu ermöglichen, wurden für den Menschen und einige andere Organismen standardisierte Bezeichnungssysteme eingeführt. Beim Menschen hat jede Bande eine Bezeichnung, die sich aus folgenden Elementen zusammensetzt: Nummer des Chromosoms, "p" oder "q" für den jeweiligen Arm ("p" wie franz. "petite" für den kurzen Arm; q wie franz. "queue" für den langen) sowie Zahlen, die vom Centromer aus aufwärts zählen. Zur feineren Unterscheidung können die Zahlen mehrere Stellen haben. Die Bande 3q26.31 ist demnach eine Unterbande von 3q26. Die Bezeichnung „3q“ steht entsprechend für den gesamten langen Arm des Chromosoms 3. Centromerregionen werden auch mit c bezeichnet (3c). Telomerbereiche werden der Einfachheit halber gerne mit tel (etwa 3ptel oder 3qtel) und telomernahe Bereiche mit ter (3pter) bezeichnet. Schematische Darstellungen der Standardbanden heißen Idiogramme. Beispiele sind in der Abbildung rechts und auf der Website von Ensembl zu sehen. In Idiogrammen sind G-Banden stets dunkel, R-Banden weiß eingezeichnet. Bereiche aus repetitiven Elementen werden manchmal schraffiert dargestellt. Eine sortierte Anordnung aller mitotischen Chromosomen aus einer Zelle wird als Karyogramm bezeichnet (Abbildung weiter unten). Der Karyotyp eines Lebewesens gibt an, wie viele und gegebenenfalls welche Chromosomen dieses Individuum hat. Der Karyotyp einer Frau wird als 46,XX angegeben, der eines Mannes als 46,XY "(siehe unten, Geschlechtsbestimmung)".

Das menschliche Genom, also die Gesamtlänge der DNA, umfasst etwa 3,2 Gbp (= Gigabasenpaare oder Milliarden Basenpaare) mit bisher gefundenen 23.700 Genen. Menschen haben zwei Kopien des Genoms (2n), eine von der Mutter und eine vom Vater, die in jedem Zellkern vorliegen. Aus dem Molekularmodell der DNA ergibt sich für 10 Basenpaare in der Doppelhelix eine Länge von 3,4 Nanometern (milliardstel Metern). Daraus lässt sich hochrechnen, dass die Gesamtlänge der DNA in jeder menschlichen Zelle über 2 Meter beträgt. Diese sind beim Menschen auf 2n = 46 Chromosomen verteilt, so dass ein Chromosom durchschnittlich etwa 140 Mbp (= Megabasenpaare oder Millionen Basenpaare) und damit einen DNA-Faden von knapp 5 cm Länge mit etwas über 1000 Genen enthält. Chromosomen während der Kernteilung haben jedoch nur eine Länge von einigen Mikrometern (millionstel Metern). Sie sind demnach um einen Faktor von etwa 10000 verkürzt oder „kondensiert“. Auch im Interphasekern sind Chromosomen kaum länger. Die hier vorhandenen Chromosomenterritorien entstehen im Wesentlichen durch Dekondensation der Tochterchromatiden in die Breite. Während ein Tochterchromatid in der Metaphase einen Durchmesser von etwa 0,6 Mikrometern hat, kann ein Chromosomenterritorium einen Umfang einnehmen, der etwa seiner Länge entspricht. Chromosomenterritorien können jedoch sehr unregelmäßige Formen haben. Aus den angegebenen Zahlenwerten wird deutlich, dass Chromosomen auch während der Interphase stark kompaktiert, also aufgefaltet, sein müssen "(siehe nächster Abschnitt)".

Chromosom 1 als größtes menschliches Chromosom hat 249 Mbp, das kürzeste Chromosom 21 hat weniger als ein Fünftel davon, nämlich 47 Mbp. Die Gene sind zwischen den Chromosomen ungleichmäßig verteilt. Das relativ genreichste Chromosom 19 enthält auf 59 Mbp etwa 1500 kodierende Gene, während das genarme Chromosom 18 auf 80 Mbp nur etwa 640 enthält "(siehe auch Abbildung „Genreiche und genarme Regionen“ oben)". Am genärmsten ist jedoch das Y-Chromosom, das auf 57 Mbp nur 72 kodierende Gene enthält. (Stand der Angaben zu Größen und Gendichten in diesem Absatz: Dezember 2015)

Bei der Hausmaus ("Mus musculus") sind die Unterschiede zwischen den Chromosomen kleiner. Das 3,5 Gbp große Genom mit 22.600 beschriebenen Genen ist verteilt auf 20 verschiedene Chromosomen (2n=40) mit 61 Mbp (Chromosom 19) bis 195 Mbp (Chromosom 1).

Die Länge der einzelnen Chromosomen bei anderen Säugern schwankt stark, in Abhängigkeit von der Anzahl. Einige haben wenige, große Chromosomen (z. B. der indische Muntjak, "Muntjak muntjacus": 2n=6 beim Weibchen und 2n=7 beim Männchen; dem X-Chromosom entsprechen hier also zwei Y-Chromosomen), andere haben viele kleine (z. B. Nashorn, "Diceros bicornis": 2n=84). Die genauen Längen (in Basenpaaren) sind jedoch erst bei einer kleinen Anzahl von Tieren bekannt.

Bei Eidechsen und Vögeln treten Chromosomen von extrem unterschiedlicher Größe auf "(siehe Abbildung)". Die Makrochromosomen ähneln dabei von der Größe her Säugerchromosomen. Das Chromosom 1 des Huhns ("Gallus gallus") enthält beispielsweise 188 Mbp. Daneben gibt es aber auch viele Mikrochromosomen, deren Größe 1 Mbp noch unterschreiten kann. Der Übergang von Makro- zu Mikrochromosomen ist oft fließend, so dass die Abgrenzung beider Gruppen voneinander zum Teil unterschiedlich vorgenommen wird. Beim Huhn können die Makrochromosomen z. B. die Chromosomen 1–8 oder 1–10 umfassen. Für einen bildlichen Größenvergleich siehe Ensembl. Von dort sind auch die Größen in Mbp übernommen. Die Begriffe Makro- und Mikrochromosomen wurden von Theophilus S. Painter 1921 eingeführt, der die Spermatogenese in Eidechsen untersuchte.
Im vorherigen Abschnitt wird dargelegt, dass die DNA sowohl während der Kernteilung als auch in der Interphase sehr stark aufgewickelt oder „kondensiert“ sein muss. Es ist jedoch noch weitgehend unklar, wie diese Verpackung organisiert ist. Eine wichtige Rolle spielen basische Strukturproteine, die Histone. DNA, Histone und weitere Proteine machen jeweils etwa ein Drittel der chromosomalen Masse aus. Diese wird auch als Chromatin bezeichnet. Die Verwendung des Begriffs Chromatin ist besonders für Beschreibungen des Zellkerns in der Interphase üblich, da hier einzelne Chromosomen nicht ohne spezielle Anfärbung (Fluoreszenz-in-situ-Hybridisierung) voneinander unterschieden werden können.

Auf der untersten Verpackungsebene ist der DNA-Faden in Nucleosomen aufgewickelt, welche acht Histonenmoleküle enthalten "(siehe Abb., Unterabbildung 2)". Nucleosomen haben einen Durchmesser von etwa 10 Nanometern (nm), daher spricht man hier auch von der 10-nm-Fiber. Deren Struktur wird oft mit einer Perlenkette verglichen, bei der der Faden allerdings um die Perlen herumgewickelt ist. In einem Nucleosom sind 146 Basenpaare der DNA aufgewickelt, hinzu kommt Linker-DNA zwischen den Nucleosomen. Die 10-nm-Fiber lässt sich im Elektronenmikroskop nachweisen, ebenso wie die nächsthöhere Verpackungsebene, die 30-nm-Fiber. Die interne Struktur der 30-nm-Fiber, also wie diese durch Auffalten aus der 10-nm-Fiber zusammengesetzt ist, ist jedoch ebenso unklar wie alle höheren Verpackungsebenen. Für letztere werden verschiedene Modelle diskutiert. Im Loop-Modell (von engl. "loop" „Schlaufe“) wird angenommen, dass die 30-nm-Fiber in großen Schlaufen verläuft, die an einer Art Rückgrat befestigt sind. Im Chromonema-Modell wird dagegen angenommen, dass sich die 30-nm-Fiber durch weiteres Auffalten verdickt und so Abschnitte von 120 nm und dicker entstehen. Wie die strukturelle Veränderung vom Interphasezustand zum Prophasechromosom vor sich geht, ist ebenfalls unklar. Beim Übergang der Prophasechromosomen zu den noch stärker kondensierten Metaphasechromosomen scheint Einigkeit darin zu bestehen, dass es sich hier um ein spiralförmiges Aufwickeln handelt.

Die Kondensation der Chromosomen bzw. des Chromatins ist innerhalb des Zellkerns nicht gleichmäßig. Manche Bereiche des Kerns werden durch DNA-Farbstoffe besonders stark gefärbt. Hier ist die Kondensation also besonders stark. Diese Bereiche werden als Heterochromatin bezeichnet, weniger stark gefärbte dagegen als Euchromatin. In den stärker kondensierten Bereichen ist die Genaktivität behindert bis blockiert, siehe Epigenetik.

Es sind zwei Arten von Riesenchromosomen bekannt, Polytänchromosomen und Lampenbürstenchromosomen.

Eine Besonderheit bezüglich des inneren chromosomalen Aufbaus stellen die Polytänchromosmen dar. Sie sind aus verschiedenen Insekten bekannt und besonders gut in der Fruchtfliege "Drosophila melanogaster" und in "Chironomus" untersucht. Sie entstehen durch mehrere Runden von Verdopplung der DNA "ohne" anschließende Kernteilung (Endoreduplikation). Im Gegensatz zur „normalen“ Polyploidie sind in Polytänchromosomen die vielfach replizierten DNA-Fäden von beiden homologen Chromosomen (also der vom Vater und der von der Mutter vererbten Kopie) parallel angeordnet, ähnlich einem Kabelstrang. Alle Kopien eines Gens liegen daher nebeneinander.

Eine andere Form von sehr großen Chromosomen kommt in den Eizellen von Amphibien vor. Da sie vom mikroskopischen Bild her einer Flaschen- oder Lampenbürste ähneln, wurden sie Lampenbürstenchromosomen genannt.

Während bei manchen Lebewesen die Geschlechtsbestimmung durch Umweltbedingungen wie die Temperatur während der Embryonalentwicklung erfolgt, wird das Geschlecht bei anderen durch die geerbten Chromosomen bestimmt: Sie haben ein chromosomales Geschlecht. Verschiedene Tiergruppen haben unterschiedliche Methoden der chromosomalen Geschlechtsbestimmung hervorgebracht, teilweise sind ähnliche Systeme unabhängig voneinander entwickelt worden.
Bei Säugern und einigen anderen Tiergruppen haben Weibchen zwei X-Chromosomen, während Männchen ein X- und ein Y-Chromosom haben. Wenn wie im Säugermännchen zwei verschiedene Geschlechtschromosomen vorliegen spricht man von Hemizygotie. Bei Vögeln haben Männchen zwei Z-Chromosomen, Weibchen sind mit einem Z- und einem W-Chromosom das hemizygote Geschlecht. Bei vielen Insekten aus der Gruppe der Hautflügler sind Weibchen diploid, die Männchen aber nur haploid.

Im hemizygoten Geschlecht liegen etliche Gene nur auf einem Chromosom vor. Bei einem Gendefekt kann dieser daher nicht durch ein intaktes Gen auf einem homologen Chromosom aufgefangen werden. Daher gibt es beim Menschen eine Reihe von Erbkrankheiten, die praktisch nur bei Männern auftreten. Die bekanntesten Beispiele sind eine Form der Bluterkrankheit, die Duchenne’sche Muskeldystrophie und die Rot-Grün-Blindheit.

Bei chromosomaler Geschlechtsbestimmung liegt in einem der Geschlechter ein Chromosom zweimal vor, das beim anderen nur einmal da ist. Um zu verhindern, dass hier auch doppelt so viel Genprodukt wie im anderen Geschlecht erzeugt wird, haben verschiedene Tiergruppen verschiedene Strategien zur „Dosiskompensation“ entwickelt "(siehe Geschlechtschromosom, X-Inaktivierung und Geschlechts-Chromatin)".

Alle verschiedenen Chromosomen, die in einem Individuum vorkommen, bilden zusammen den Karyotyp. In vielen Fällen (auch bei Säugern), finden sich im Karyotyp, abgesehen von den Geschlechtschromosomen im hemizygoten Geschlecht, immer zwei homologe Chromosomen, nämlich solche, die die gleichen Gene tragen. Man spricht in diesen Fällen von einem doppelten oder diploiden Chromosomensatz, der mit 2n abgekürzt wird. Bei sich geschlechtlich vermehrenden Organismen wurde von beiden Elternteilen je einer vererbt.

Die Individuen einer Art und vom gleichen Geschlecht haben normalerweise dieselbe Ausstattung an Chromosomen und somit den gleichen Karyotyp. Eine Ausnahme bilden die B-Chromosomen, die in manchen Arten vorkommen und die bei verschiedenen Individuen und auch in verschiedenen Körperzellen in unterschiedlicher Anzahl vorhanden sein können. Zur besseren Unterscheidung von den B-Chromosomen können die normalen Chromosomen als A-Chromosomen bezeichnet werden.

Auch bei letzteren kann zwischen den Geschlechtern die Art und – seltener – auch die Zahl der Chromosomen abweichen; sie haben dann einen anderen Karyotyp "(siehe auch oben, Geschlechtsbestimmung)". Menschen haben zum Beispiel in beiden Geschlechtern 46 Chromosomen. Der Karyotyp wird entsprechend als 46,XX für Frauen und 46,XY für Männer angegeben. Karyotypen werden mit Hilfe von Karyogrammen bestimmt "(siehe unten)".

Um eine Zunahme der Chromosomenanzahl von Generation zu Generation zu verhindern, muss vor der Ausbildung der Keimzellen eine Reduktionsteilung stattfinden. Diese ist Bestandteil der Meiose. Während der Meiose kommt es durch Crossing over auch zu einer Rekombination der homologen Chromosomen. Dadurch entstehen genetisch neu zusammengesetzte Chromosomen, die sich von denen der Elternorganismen unterscheiden.
Es unterliegt dem Zufall, welche der rekombinierten Chromosomen zusammen in den resultierenden Zellen mit einem Chromosomensatz (haploide Zellen) enden, also welche väterlichen und mütterlichen Abschnitte im neuen haploiden Chromosomensatz der Keimzellen (Eizellen und Spermien) zusammenkommen.

Bei diploiden "Tieren" werden haploide Keimzellen (Eizellen und Spermien) erzeugt. Eine in wenigen Tierarten gefundene Abweichung von einer zufälligen Verteilung der Chromosomen tritt bei der Hybridogenese auf.
Die Keimzellen können wieder zur ersten Zelle eines neuen Lebewesens verschmelzen, der Zygote.

Bei "Pflanzen" und "Einzellern" können sich haploide und diploide Generationen abwechseln "(siehe Generationswechsel)". Manchmal ist dabei die haploide Generation die dominante und der diploide Status ist nur sehr kurz.

Gelegentlich findet sich die Auffassung, dass alle höheren Tiere und Pflanzen zwei Chromosomensätze hätten, also diploid seien. Dies ist jedoch nicht der Fall. Zwar sind die Mehrzahl der Tiere und viele Pflanzen diploid, es gibt jedoch auch etliche mit anderen Ploidiegraden.

"Haploide" Individuen kommen beispielsweise wie gerade beschrieben beim Generationswechsel der Pflanzen vor. Außerdem kommen haploide Männchen bei etlichen Insektenarten (Haplodiploidie, siehe auch oben, Geschlechtsbestimmung) und wohl auch bei einigen Milben vor. Es ist ein Fall von haploiden "weiblichen" Tieren bekannt: Die Milbenart "Brevipalpus phoenicis", ein Schädling tropischer Nutzpflanzen, besteht nur aus haploiden Weibchen, die sich parthenogenetisch vermehren. Einer Untersuchung zufolge handelt es sich eigentlich um genetische Männchen, die durch eine Infektion mit Bakterien zu Weibchen verändert werden. Verweiblichung durch Bakterieninfektion ist auch bei anderen Gliederfüßern bekannt, meist durch Wolbachia.

Bei manchen Arten kommen mehr als zwei Chromosomensätze und somit höhere Ploidiegrade vor. Diese werden als triploid = 3n, tetraploid = 4n, hexaploid = 6n oder allgemein als polyploid bezeichnet. Bei Pflanzen wird in der Regel die haploide Chromosomenzahl eines Organismus mit x (Grundzahl) bezeichnet. Diploide Pflanzen haben dann 2x Chromosomen, tetraploide 4x usw. Das Genom einer tetraploiden Pflanze mit der Grundzahl x = 7 wird dann als 2n = 4x = 28 beschrieben.

"Tetraploidie" ist nach Diploidie wohl der zweithäufigste Ploidiegrad. Er wurde bei vielen Blütenpflanzen, Insekten und auch bei Amphibien beobachtet. Tetraploidie kann zustande kommen, indem eine Zellteilung nach Chromosomenverdopplung verhindert wird. Viele Nutzpflanzen, z. B. bei den Getreidesorten, entstanden durch Polyploidisierung aus diploiden Wildformen.

Bei Pflanzen kommen auch noch höhere Ploidiegrade vor. Sie können beispielsweise entstehen, wenn zwei Arten gekreuzt werden und die Kinder alle Chromosomen der Eltern behalten. Man spricht dann von Additionsbastarden. "Hexaploid" ist beispielsweise der moderne Saatweizen.

"Triploide" Individuen können entstehen, wenn sich diploide und tetraploide Individuen paaren. Dies ist möglich, wenn beide zu nahe verwandten Arten gehören. In der Regel werden triploide Individuen jedoch steril sein, da eine ungerade Anzahl von Chromosomensätzen zu Schwierigkeiten bei der Paarung der Chromosomen während der Meiose führt. Ausnahmen, also fortpflanzungsfähige triploide Individuen, wurden bei den Amphibien entdeckt. Hier kommen manchmal Diploidie, Tetraploidie und auch Triploidie in nahe verwandten Arten oder in der gleichen Art nebeneinander vor. Beim Wasserfrosch wird einer der Chromosomensätze vor der Meiose gezielt eliminiert (siehe Hybridogenese). In Pakistan wurde eine lokal begrenzte, triploide Population der Wechselkröte gefunden, bei der ebenfalls ein Chromosomensatz vor der Meiose gezielt eliminiert wird.

Zumindest theoretisch kann ein fließender Übergang beispielsweise von tetraploid zu diploid bestehen. In einem tetraploiden Lebewesen sind wie oben beschrieben alle Chromosomen"paare" doppelt vorhanden. Veränderungen an einem der beiden Paare, zum Beispiel der Verlust einzelner Gene, können daher toleriert werden. Auch können sich die Genkopien auf den beiden Paaren während der weiteren Evolution auseinanderentwickeln und verschiedene Funktionen übernehmen. Chromosomenmutationen (siehe unten) an nur einem der beiden Paare sind ebenfalls möglich. Kommen viele solche Veränderungen im Lauf der Zeit zusammen, so haben sich schließlich die ursprünglich identischen Chromosomenpaare so weit auseinanderentwickelt, dass nicht mehr von vierfachen Chromosomensätzen gesprochen werden kann: Es liegt wieder Diploidie vor. Zwei Runden (daher „2R-Hypothese“) solcher Genomduplikationen sind für die frühe Entstehungsgeschichte der Wirbeltiere vorgeschlagen worden, so dass sich die heutigen diploiden Wirbeltiere aus ursprünglich oktaploiden (= 8n) Lebewesen entwickelt hätten. Dies würde erklären, warum beispielsweise die Hox-Gen-Cluster pro haploidem Genom der Wirbeltiere viermal vorkommen, bei anderen Tieren aber nur einmal.

Der Ploidiegrad einzelner Körperzellen eines Mehrzellers kann durchaus vom Ploidiegrad des Organismus abweichen. Das bekannteste Beispiel hierfür sind sicher die Polytänchromosomen mancher Insekten "(siehe auch oben)". Aber auch für die Rattenleber wurden beispielsweise neben den vorherrschenden diploiden Zellen in seltenen Fällen auch haploide, triploide und tetraploide Zellen beschrieben. Tetraploidie entsteht durch Verdopplung der Chromosomen ohne Kernteilung, also durch Endoreduplikation oder Endomitose. Haploide und triploide Körperzellen wurden in diploiden Organismen so selten gefunden, dass experimentelle Fehler oder Artefakte hier nicht ausgeschlossen werden können. Ihr potentieller Entstehungsmechanismus ist ungeklärt. Hohe Ploidiegrade gehen mit entsprechend größeren Zellkernen einher. Aufgrund der größeren Menge an genetischem Material können so auch sehr große Körperzellen versorgt werden.

Wenn nicht anders angegeben, beruhen die Zahlenangaben auf Flindt, 1985.

Als Karyogramm bezeichnet man eine sortierte Darstellung der Chromosomen eines Metaphasepräparats. Diese Präparate werden erstellt, indem Zellkulturen mit einem Mittel versetzt werden, das die Bildung von Mikrotubuli verhindert, z. B. Colchizin oder Nocodazol. Dadurch kann sich kein Spindelapparat ausbilden, und die Zelle kann nicht in Anaphase gehen. Als Folge sammeln sich etliche Zellen in der Metaphase "(siehe oben)" an, und die Ausbeute wird entsprechend erhöht. Die Zellen werden hypoton behandelt, wodurch sie anschwellen, fixiert und auf einen Objektträger aufgetropft, wodurch die Metaphasechromosomen nebeneinander zu liegen kommen "(siehe erste Abbildung oben)". Die Chromosomen werden angefärbt, fotografiert und im Karyogramm der Größe nach angeordnet, so dass der Karyotyp bestimmt werden kann "(siehe Abbildung rechts)".

Karyogramme werden sowohl bei der Untersuchung der Karyotypen von Organismen als auch in der klinischen Anwendung bei Verdacht auf Chromosomenveränderungen eingesetzt.

Dauerhafte Veränderungen an den Chromosomen können auftreten, wenn an mindestens zwei Stellen Brüche in der DNA-Doppelhelix auftreten. In den meisten Fällen werden DNA-Doppelstrangbrüche wieder korrekt repariert, so dass es nicht zu bleibenden Veränderungen kommt. Werden jedoch bei einer DNA-Reparatur von zwei verschiedenen Brüchen die falschen Enden zusammengefügt, so kommt es zu Chromosomenmutationen. Liegen die Bruchpunkte auf dem gleichen Chromosom, können Deletionen (Verlust eines Abschnitts) oder Inversionen (umdrehen) auftreten. Ein weiterer Mutationstyp innerhalb eines Chromosoms ist die Duplikation (Verdopplung eines Abschnitts). Sind die Doppelstrangbrüche auf verschiedenen Chromosomen, so kann es zu Translokationen kommen. Diese Phänomene werden in ihren eigenen Artikeln ausführlicher beschrieben.

Chromosomenmutationen spielen sowohl bei der Chromosomenevolution als auch im klinischen Bereich eine Rolle. Bezüglich der klinischen Bedeutung sind Erbkrankheiten "(siehe auch unten)", Tumorentstehung (z. B. das Philadelphia-Chromosom) und Strahlenbiologie zu nennen.

Von den genannten strukturellen Veränderungen sind zahlenmäßige Veränderungen zu unterscheiden, also ein zusätzliches oder ein fehlendes Chromosom. Diese werden nicht als Chromosomenmutation bezeichnet. Da nur ein einzelnes Chromosom betroffen ist, spricht man von Trisomie ("nicht" Triploidie) oder Monosomie "(siehe Chromosomenaberration)".

Als Chromosomenevolution wird die Veränderung von Chromosomen im Lauf der Evolution bezeichnet. Ähnlich wie an äußeren körperlichen Merkmalen oder an der Sequenz einzelner Gene lässt sich auch an den Chromosomen die Stammesgeschichte nachvollziehen. Beispielsweise sind die Chromosomen des Menschen (46 Stück) denen der großen Menschenaffen (Schimpansen, Gorillas und Orang-Utans, je 48 Chromosomen) sehr ähnlich. Es gibt innerhalb dieser Artengruppe nur zwei zwischen-chromosomale Umbauten. Spezifisch menschlich ist das Chromosom 2. Bei den anderen genannten Arten finden sich statt diesem zwei kleinere Chromosomen, die die entsprechenden Gensequenzen enthalten "(siehe Abbildung)". Gorilla-spezifisch ist dagegen eine Translokation zwischen jenen Chromosomen, die den menschlichen Chromosomen 5 und 17 entsprechen. Daraus ergibt sich der ursprüngliche Karyotyp der Gruppe mit 48 Chromosomen, so wie er heute noch bei Schimpansen und Orang-Utans vorhanden ist.

Eine evolutionär stabile Veränderung der Chromosomen ist nur möglich, wenn eine Chromosomenmutation in der Keimbahn auftritt. Eine „balancierte“ Veränderung, bei der alle Chromosomenabschnitte in der richtigen Anzahl vorhanden sind, hat dabei für den Träger zunächst keinen Krankheitswert. Es kommt jedoch zu Schwierigkeiten bei der Meiose. Die Veränderung tritt ja zunächst nur an jeweils "einem" Chromosom auf (bzw. an zweien bei Fusionen oder Translokationen), nicht aber an den jeweiligen homologen Chromosomen. Da also anders als sonst identisch aufgebaute Partner fehlen, kommt es nicht zu einer normalen meiotischen Paarung. Das Risiko für Segregationsfehler und daraus resultierende Keimzellen mit überzähligen oder fehlenden chromosomalen Abschnitten (und folglich kranken Kindern) steigt stark an. In den allermeisten Fällen werden solche Veränderungen daher in den Folgegenerationen wieder verlorengehen. Eine stabile Situation wird nur dann erreicht, wenn "beide" Kopien der beteiligten Chromosomen die entsprechende Veränderung tragen. Dies könnte beispielsweise geschehen, wenn ein dominantes Männchen mit "einer" Veränderung zahlreiche Kinder hat, die sich wiederum untereinander paaren, so dass Enkel mit der Veränderung auf beiden Kopien der beteiligten Chromosomen entstehen. Diese Nachkommen haben nun keinen Selektionsnachteil, wenn sie sich untereinander paaren. Bei der Paarung mit Individuen mit den ursprünglichen Chromosomen tritt jedoch bei entstehenden Kindern bedingt durch Segregationsfehler wiederum eine verminderte Fruchtbarkeit auf. Es wird daher vermutet, dass „fixierte“ Chromosomenveränderungen ein Mechanismus zur Artbildung sind.

Näher verwandte Arten oder Artgruppen müssen nicht immer ähnlichere Chromosomen haben als weiter entfernte Arten. Beispielsweise ähneln Chromosomen der großen Menschenaffen einschließlich des Menschen sehr stark denen von Makaken ("Macaca fuscata"). Die Chromosomen der näher verwandten kleinen Menschenaffen (Gibbons) unterscheiden sich jedoch sowohl von denen der großen Menschenaffen als auch denen der Makaken sehr stark. Durch zahlreiche Umbauten sind nur fünf der Gibbon-Chromosomen auf ihrer ganzen Länge (nur) einem menschlichen Chromosom homolog. Offensichtlich gehen also evolutionäre Veränderungen im Karyotyp in manchen Gruppen (z. B. den Gibbons) sehr viel schneller voran als in anderen (Makaken, große Menschenaffen). Es wird vermutet, dass dies nicht an einer höheren Mutationsrate liegt, sondern an einer häufigeren Fixierung von aufgetretenen Veränderungen. Eine Ursache hierfür könnten unterschiedliche Lebensstile bzw. Sozialverhalten sein. Gibbons leben in kleinen Gruppen, in denen sich Chromosomenveränderungen schneller durchsetzen könnten als in großen Herden. Bei Gibbons finden sich chromosomale Polymorphismen (Unterschiede) im Karyotyp von untersuchten Tieren der gleichen Art, die darauf hindeuten, dass die schnelle Chromosomenevolution in dieser Tiergruppe nach wie vor anhält. Die verhältnismäßig große Anzahl der Polymorphismen deutet allerdings auch darauf hin, dass der selektive Nachteil von Mischformen möglicherweise geringer ist als ursprünglich gedacht.

Menschen haben 46 Chromosomen, davon 2 Geschlechtschromosomen oder Gonosomen (XX bei Frauen, XY bei Männern, siehe oben: Geschlechtsbestimmung). Die Chromosomen der übrigen 22 Chromosomenpaare werden als Autosomen bezeichnet. Die Autosomen wurden ihrer Größe im mikroskopischen Präparat entsprechend von 1 bis 22 durchnummeriert. Menschen sind wie andere Säugetiere diploid, eine Zelle hat also einen doppelten Chromosomensatz: Es sind je zwei Exemplare der Chromosomen 1 bis 22 vorhanden, dazu die beiden Geschlechtschromosomen.

Obwohl sich das X-Chromosom mit 155 Megabasen und das Y-Chromosom mit 59 Megabasen in ihrer Größe stark unterscheiden, haben sie auch Gemeinsamkeiten. An beiden Enden enthalten sie Regionen, in denen sich die DNA-Sequenz zwischen X- und Y-Chromosom stark ähnelt, die pseudoautosomale Regionen (PAR). In den PARs befinden sich mehrere Gene, die also in beiden Geschlechtern doppelt vorhanden sind, und die auch nicht der X-Inaktivierung unterliegen "(siehe oben: Dosiskompensation)". In diesen Regionen ist während der Meiose eine Rekombination zwischen X- und Y-Chromosom möglich.

Auch in nicht rekombinierenden Regionen des Y-Chromosoms haben etwa die Hälfte der Gene Entsprechungen auf dem X-Chromosom. Dies sind vor allem Gene des Grundstoffwechsels. Zwei der Gene, die auch auf dem X-Chromosom vorkommen, sind nur im Hoden aktiv. Die übrigen Gene ohne Entsprechung auf dem X-Chromosom sind ebenfalls nur im Hoden aktiv, bestimmen das männliche Geschlecht und steuern die Spermien-Produktion. Ein Verlust eines Stückes des langen Armes nahe dem Zentromer führt zu Kleinwuchs.

Durch Chromosomenaberrationen, also Chromosomenmutationen, Chromosomeninstabilität, Chromosomenbrüche oder eine falsche Anzahl von Chromosomen (numerische Chromosomenaberration oder Genommutation), kann es zu klinischen Syndromen mit zum Teil schwerwiegender Symptomatik kommen.

Eine Zuordnung der Krankheitsbilder zu entweder Chromosomenmutationen oder numerischen Chromosomenaberration ist nicht immer möglich. So wird z. B. das Down-Syndrom in den meisten Fällen durch ein zusätzliches, komplettes Chromosom 21 verursacht (freie Trisomie). Etwa 3 % der Fälle beruhen jedoch auf Translokationen, bei denen ein Teil des Chromosoms 21 an ein anderes Chromosom fusioniert ist. Nur dieser Teil ist dann dreifach vorhanden. Die folgenden Syndrome sind meist in ihren jeweils eigenen Artikeln ausführlich behandelt und hier nur übersichtsartig dargestellt.

Freie Trisomien bei Lebendgeborenen sind bei den Autosomen nur für die Chromosomen 21, 18 und 13 bekannt. Alle drei gehören zu den genarmen Chromosomen (vergleiche zweite Abbildung im Abschnitt G-, R- und andere Chromosomenbanden oben). Daraus lässt sich schließen, dass freie Trisomien der anderen Autosomen mit dem Leben unvereinbar sind.



Markerchromosomen sind alle nicht ohne weiteres definierbaren Chromosomen, die zusätzlich zu den normalen Chromosomen auftreten. Sie bestehen aus Material der normalen Chromosomen, sind aber meist klein, so dass eine Identifizierung durch G-Bänderung "(siehe oben)" nicht möglich ist. Diese kann mit hochauflösender Fluoreszenz-in-situ-Hybridisierung erreicht werden.

Monosomien von Autosomen kommen nicht vor. Die damit einhergehenden Schäden sind offenbar mit dem Leben unvereinbar. Es gibt jedoch eine Vielzahl unterschiedlicher Deletionen von Teilstücken eines Autosoms, die teilweise nur aus wenigen klinischen Fällen bekannt sind. Die folgende Liste ist daher nicht vollständig und umfasst nur die bekanntesten Beispiele.


Weitere Beispiele sind das Williams-Beuren-Syndrom (7q11.23) und das Smith-Magenis-Syndrom (17p11.2 – Häufigkeit zwischen 1:15.000 bis 1:25.000 Geburten angegeben).

Eine Besonderheit stellen Deletionen der Region 15q11.2-q12 dar. Diese Region unterliegt einer epigenetischen Regulation, dem „Imprinting“: Je nachdem, ob diese Region vom Vater oder von der Mutter vererbt wurde, sind bestimmte Gene aktiv oder inaktiv. Normalerweise sind beide Fälle jeweils einmal vorhanden. Fehlt jedoch einer der beiden, z. B. durch Deletion, so unterscheiden sich die Krankheitsbilder, je nachdem ob eine von der Mutter vererbte (Angelman-Syndrom) oder eine vom Vater vererbte (Prader-Willi-Syndrom) Region fehlt.

Der ICD-10-Code O35.1 wird bei der Betreuung einer werdenden Mutter bei (Verdacht auf) Chromosomenbesonderheit beim ungeborenen Kind angegeben.




</doc>
<doc id="10692" url="https://de.wikipedia.org/wiki?curid=10692" title="Michelangelo">
Michelangelo

Michelangelo Buonarroti [], oft nur Michelangelo (vollständiger Name "Michelangelo di Lodovico Buonarroti Simoni"; * 6. März 1475 in Caprese, Toskana; † 18. Februar 1564 in Rom), war ein italienischer Maler, Bildhauer, Baumeister (Architekt) und Dichter. Er gilt als einer der bedeutendsten Künstler der italienischen Hochrenaissance und weit darüber hinaus.

Michelangelo stammte aus einer angesehenen Bürgerfamilie in Florenz, die zur Partei der Guelfen gehörte. Er war der zweite Sohn des Lodovico di Leonardo Buonarroti Simoni und der Francesca di Neri und wurde am 6. März 1475 in Caprese in der heutigen Provinz Arezzo geboren, wo sein Vater für ein Jahr als Stadtvogt amtierte. Danach zog seine Familie nach Florenz zurück. Getauft wurde er am 8. März 1475 in der Kirche San Giovanni zu Caprese. Michelangelo hatte vier Brüder: Lionardo (1473–1510), Buonarroto (1477–1528), Giovansimone (1479–1548) und Sigismondo (1481–1555). Seine Amme war die Frau eines Steinmetzen aus Settignano bei Florenz. Michelangelos Mutter starb, als er sechs Jahre alt war; sein Vater heiratete in zweiter Ehe 1485 Lucrezia Ubaldini (gest. 1497).

Um 1482 kam Michelangelo in die Lateinschule des Francesco da Urbino. Schon als Junge wollte Michelangelo gegen den Widerstand seines Vaters Künstler werden. Nach einem heftigen Streit siegte sein Wille über den Stolz seines Vaters, und so wurde er mit 13 Jahren bezahlter Schüler in der Werkstatt von Domenico Ghirlandaio. Bei ihm studierte Michelangelo die Grundlagen der Freskokunst, mit der er zwanzig Jahre später in Rom reüssierte. Wie alle florentinischen Künstler seiner Zeit lernte er auch in der Brancacci-Kapelle der Kirche Santa Maria del Carmine.

Obwohl sich Michelangelo zunächst der Malerei zuwandte, war er mehr der Bildhauerei zugeneigt. Noch vor Ende seiner Ausbildungszeit als Maler trat er 1489 mit Unterstützung seines Freundes Francesco Granacci in die Kunstschule von Lorenzo il Magnifico ein. Die Leitung hatte Bertoldo di Giovanni inne, ein Schüler des berühmten Bildhauers Donatello. Eine seiner ersten Statuen war der "Faunskopf" (verschollen), den Michelangelo nach einer Bemerkung Lorenzos mit einer Zahnlücke versah, um ihn realistischer erscheinen zu lassen. Das in dieser Zeit entstandene Marmorrelief Kentaurenschlacht gilt als das älteste erhaltene bildhauerische Werk Michelangelos, da die Zuschreibung des Reliefs Madonna an der Treppe umstritten ist. Lorenzo de’ Medici behandelte Michelangelo wie seinen eigenen Sohn und förderte ihn in Kunst und Philosophie. Bei einem Streit schlug ihn sein Mitschüler Torrigiano ins Gesicht und entstellte ihn, was dazu führte, dass Michelangelo sein ganzes Leben hindurch unter seiner „Hässlichkeit“ litt. Michelangelo ist durch diese und andere erlittenen Kränkungen in depressive Krisen gestürzt. Jedoch ist er aus diesen gestärkt hervorgegangen, wovon seine grandiosen Werke zeugen.

Michelangelo hatte der Schule und dem Haushalt der Medici kaum drei Jahre angehört, als sein berühmter Mäzen Lorenzo starb. Dessen Sohn Piero di Lorenzo de’ Medici erbte die Stellung, aber nicht die Qualitäten seines Vaters. Florenz rieb sich bald an seiner Herrschaft, und gegen Herbst 1494 wurde offensichtlich, dass ihm und seinen Anhängern eine Katastrophe drohte. Michelangelo war von Natur aus plötzlichen und dunklen Vorahnungen ausgesetzt; eine davon ergriff ihn nun, und ohne den bald folgenden Aufstand des Volks abzuwarten, setzte er sich mit zwei Begleitern nach Bologna ab.

Inzwischen zwanzig Jahre alt, wurde er dort freundlich von einem Mitglied der Familie von Ulisse Aldrovandi aufgenommen, in dessen Auftrag er zwei Heiligenfiguren und einen Engel für die Grabstätte des heiligen Dominikus in der Basilika San Domenico erstellte. Nach rund einem Jahr, als die Arbeit in Bologna scheiterte und in Florenz sein Name während seiner Abwesenheit auf eine Liste von Künstlern gesetzt worden war, die einen neuen Versammlungssaal für den Großen Rat in Florenz ausstatten sollten, kehrte Michelangelo nach Hause zurück.

Nach der Machtübernahme durch Savonarola im Jahr 1494, die den ganzen Charakter des bürgerlichen Lebens in Florenz verändert hatte, erhielt Michelangelo keine Aufträge von der Stadtregierung. Doch er blieb nicht ohne Beschäftigung, denn er fand einen Freund in einem weiteren Lorenzo, dem Sohn von Pierfrancesco de Medici, für den er eine Statue des jungen Heiligen Johannes ausführte. Nachdem er das antike Vorbild eines schlafenden Cupidos imitiert hatte, schlug ihm derselbe Patron vor, sein Werk so zu färben und zu behandeln, dass es antik aussehe und als solches verkauft werde. Ohne den Lohn für seine Arbeit zu erhöhen, machte Michelangelo zum Spaß bei diesem Betrug mit, und das Stück wurde als echtes Werk der Antike an einen römischen Sammler teuer verkauft, den Kardinal von San Giorgio, Raffaele Riario. Als der Kardinal den Betrug aufdeckte, musste der Händler die Kaufsumme zurückerstatten; dem jungen Bildhauer Michelangelo wurde dargelegt, dass der Kunstliebhaber, der gerade unfreiwillig einen so hohen Tribut an seine Fähigkeiten gezahlt hatte, sich gewiss seiner annehmen werde, wenn er nach Rom komme.

Michelangelo nahm an und kam das erste Mal Ende Juni 1496 in Rom an. Kardinal Riario beauftragte ihn, als Entschädigung für den Kunstschwindel einen antiken Bacchus zu schaffen. Später hatte man vermutet, dass der eigentliche Auftraggeber Jacopo Galli sei, ein römischer Adeliger, da man die Statue in seinem Garten vorfand, doch ein Briefwechsel zwischen Michelangelo und dessen Vater beweist eindeutig, dass Riario der Auftraggeber war. Schließlich gewann Michelangelo die Gunst des Kardinals Jean Bilhères de Lagraulas (auch "Jean de Villiers de La Groslaye"), Abt von St. Denis und Kardinalpriester von Santa Sabina, von dem er den Auftrag für die Pietà von St. Peter bekam.

Diese kontrastierenden Themen sind beide originell konzipiert wie auch technisch genial ausgeführt: die Mutter mit dem toten Körper des Sohnes auf ihrem Schoß, die mit ihrer linken freien Hand, in eine erweiterte Richtung deutend, die Tragödie ausdrucksvoll begleitet; und der sinnliche junge Weingott (der in der Antike niemals selbst in einem schwankenden Zustand gezeigt worden wäre, sondern nur seine Satelliten). Die Pietà ist die einzige Statue Michelangelos, die er signierte, was auf die Bedeutung hinweist, die sie für den Künstler selbst hatte. Über der Brust der Madonna liegt diagonal ein Band, auf dem die Worte eingemeißelt stehen: MICHAEL ANGELUS. BONAROTUS. FLORENT. FACIEBA[T].

Michelangelos erster Aufenthalt in Rom dauerte fünf Jahre von Sommer 1496 bis Sommer 1501. Der Zeitraum war von extremen politischen Unruhen in Florenz geprägt. Die Aufregung über die französische Invasion, das mystische und asketische Regime von Savonarola, sein Sturz und schließlich die äußeren Kriege und inneren Dissidenzen, die einer neuerlichen Einigung vorausgingen, hatten allesamt eine für die Kunst ungünstige Atmosphäre geschaffen.

Trotzdem hatte Ludovico Buonarroti, der in den Wirren von 1494 sein kleines permanentes Amt verloren hatte und der seinen Sohn Michelangelo inzwischen als Hauptstütze seines Hauses betrachtete, ihn wiederholt gedrängt, nach Hause zu kommen. Familienpflicht und Familienstolz beherrschten das Verhalten Michelangelos. Während der besten Jahre seines Lebens nahm er ohne Murren harte Entbehrungen um seines Vaters und seiner Brüder willen auf sich, die sich von ihm unterstützen ließen.

Nach seiner Heimkehr infolge einer Krankheit erhielt Michelangelo von Kardinal Francesco Piccolomini den Auftrag, eine Grabstätte mit 15 Skulpturen auszuschmücken, die bereits in der Kathedrale von Siena zu Ehren des berühmtesten Mitglieds der Familie, Papst Pius II., begonnen worden war. Nur vier dieser Figuren wurden schließlich ausgeführt, freilich nur teilweise durch die Hand des Meisters selbst.

Ein Werk größeren Interesses in Florenz lenkte ihn vom Auftrag für Siena ab: die Ausführung der kolossalen Statue des David. Sie wurde aus einem riesigen Marmorblock gehauen, den ein anderer Bildhauer, Agostino di Duccio, 40 Jahre zuvor erfolglos zu bearbeiten begonnen hatte und der seitdem nutzlos herumlag. Es gelang Michelangelo, ohne Rücksichtnahme auf die traditionelle Behandlung des Themas oder den historischen Charakter seines Helden, einen jugendlichen, düsteren Koloss herauszumeißeln, wachsam gespannt und ausgeglichen vor seiner großen Tat.

Das Ergebnis beeindruckt durch die freie und gleichzeitig präzise Ausführung und die triumphierende Kraft des Ausdrucks. Die besten Künstler von Florenz sollten gemeinsam den Ort zur Aufstellung der Statue festlegen. Sie einigten sich schließlich auf die Terrasse des Palastes der Signoria gegenüber der Loggia dei Lanzi. Michelangelos David behielt hier seinen Platz, bis er 1882 zu seinem Schutz in einen Saal der Akademie der Künste versetzt wurde, wo er unvermeidlich eingeengt erscheint; nur eine Kopie des Werkes befindet sich heute vor der Signoria. Nach einer Serie leichter Erdbeben in der Toskana kündigte der Kulturminister Italiens 2014 an, die Statue mit einem erdbebensicheren Sockel auszustatten.

Weitere Bildhauereiarbeiten aus derselben Periode: ein zweiter David in Bronze und in kleinerem Maßstab, in Auftrag gegeben von Marschall Pierre Rohan und von dem jungen Meister Benedetto da Rovezzano zur Vollendung übergeben, der ihn 1508 nach Frankreich versandte; ein großartiger, grob behauener Sankt Matthäus für die Kathedrale von Florenz, den er begann, aber nie vollendete; eine Madonna mit dem Kinde im Auftrag eines Händlers aus Brügge sowie zwei unvollendete Basreliefs über das gleiche Thema.

Auch als Maler war Michelangelo zur selben Zeit keineswegs müßig, sondern schuf für seinen und Raffaels gemeinsamen Patron Angelo Doni die Heilige Familie (Tondo Doni, Tempera auf Holz), die sich heute in den Uffizien befindet. Im Herbst 1504, als er den David vollendete, beauftragte ihn die Florentiner Regierung mit einem Monumentalgemälde. Leonardo da Vinci war engagiert worden, seinen großartigen Karton der Schlacht von Anghiari auf die Wände des großen Saals des Stadtrats zu malen. Der Gonfaloniere Piero Soderini stellte nun für Michelangelo die Bestellung eines begleitenden Werks sicher.

Michelangelo wählte ein Ereignis von 1364 in der Schlacht von Cascina während des Kriegs mit Pisa, als die Florentiner Soldaten vom Feind während des Badens überrascht wurden. Mit gewohntem Schwung machte er sich an die Aufgabe und hatte einen großen Teil des Kartons vollendet, als er Anfang Frühjahr 1505 die Arbeit abbrach, um eine Berufung nach Rom durch Papst Julius II. anzunehmen. In Karl Woermanns "Geschichte der Kunst" (1911) wird dazu berichtet, dass uns die Kupferstiche von Agostino Veneziano und Marc Antons (Marcantonio Raimondi) die beste Vorstellung einiger Gruppen dieses Schlachtbildes geben können, welches als spurlos vernichtetes Werk gilt.

Sein souverän gestalteter, unvollendeter Karton zeigt, wie sehr Michelangelo vom Vorbild seines älteren Rivalen Leonardo profitiert hatte. Michelangelos Jugendwerke sind zum größten Teil vergleichsweise ruhig im Charakter. Seine frühe Bildhauerei übertrifft die Werke der Antike in ihrer Wissenschaft und Perfektion und strahlt dennoch antike Abgeklärtheit aus. Sie ist von intellektueller Forschung, nicht von Aufruhr oder Anstrengung geprägt. Auf dem Karton der Badenden kamen erstmals die Qualitäten zum Ausdruck, die später sprichwörtlich mit Michelangelo assoziiert wurden, seine "furia" und "terribilità", die seine unvergleichliche technische Meisterschaft und sein Wissen begleiten. Mit Michelangelos Abreise nach Rom Anfang 1505 kann die erste Phase seiner Karriere als beendet gelten.

Kurz nach seiner Ankunft in Rom erhielt Michelangelo von Papst Julius II. einen angemessenen Auftrag. Der eigenwillige und unternehmensfreudige Geist hatte die Idee zu einem Grabmonument, das ihn rühmen und nach seinem Tode feiern sollte, das jedoch noch zu Lebzeiten und nach eigenen Plänen auszuführen war.
Nach Annahme von Michelangelos Entwurf verbrachte der Künstler den Winter 1505/1506 in den Steinbrüchen von Carrara und überwachte den Aushub und die Lieferung des Marmors. Im Frühjahr kehrte er nach Rom zurück, und als der Marmor ankam, machte er sich energisch an die Vorbereitung der Arbeit. Für eine Weile verfolgte der Papst den Fortschritt gespannt und war voller Güte für den jungen Bildhauer. Aber dann wechselte seine Stimmung. In Michelangelos Abwesenheit hatte Julius Donato Bramante – kein Freund Michelangelos – ausgewählt, um einen neuen architektonischen Plan auszuführen: den Neubau der Peterskirche. Dem Einfluss und der Böswilligkeit Bramantes schrieb Michelangelo die ihm nun zukommende unwillkommene Einladung zu, das große bildhauerische Werk zu unterbrechen, um die Sixtinische Kapelle mit Fresken zu dekorieren.

Bald wurden die Gedanken Julius’ von Kriegsplänen und Eroberungen abgelenkt. Eines Tages hörte Michelangelo ihn bei Tisch zu seinem Juwelier sagen, dass er kein Geld mehr für Steine auszugeben gedenke, ob klein oder groß. Zum Unbehagen des Künstlers trug noch bei, dass er, als er persönlich erschien, um Zahlungen einzufordern, Tag für Tag vertröstet und schließlich mit wenig Höflichkeit entlassen wurde. Darauf ergriff ihn seine dunkle Stimmung. Überzeugt, dass nicht nur seine Beschäftigung, sondern auch sein Leben in Gefahr sei, verließ er plötzlich Rom, und bevor die Boten des Papsts ihn einholen konnten, war er im April 1506 auf sicherem Florentiner Territorium.

Nachdem er wieder zuhause war, überhörte er jeglichen Antrag aus Rom wegen einer Rückkehr und blieb den Sommer über in Florenz. Womit er beschäftigt war, weiß man nicht bestimmt, aber anscheinend unter anderem mit der Fortsetzung des großen Schlachtengemäldes.

Während desselben Sommers plante und führte Julius den siegreichen Feldzug durch, der in seinem widerstandslosen Einzug an der Spitze seiner Armee in Bologna endete. Michelangelo ließ sich überzeugen, sich unter sicherem Geleit und Versprechen erneuter Gunst dorthin zu begeben. Julius empfing den Künstler freundlich, denn in der Tat bestand zwischen den beiden vulkanischen Naturen eine natürliche Affinität. Er verlangte von ihm sein eigenes Bildnis in Bronze, das als Symbol seiner erobernden Autorität über den Haupteingang der Basilika San Petronio gesetzt werden sollte.

In den nächsten fünfzehn Monaten widmete Michelangelo seine ganze Kraft dieser neuen Aufgabe, doch der gezahlte Preis ließ ihm kaum etwas zum Leben. Außerdem war er in der Technik der Metallbearbeitung unerfahren, und ein Assistent, den er aus Florenz hatte herbeirufen lassen, stellte sich als aufsässig heraus und musste entlassen werden. Trotzdem setzte sich sein Genie gegen alle Schwierigkeiten durch, und am 21. Februar 1508 wurde der majestätische Bronzekoloss des sitzenden Papstes mit Robe und Zepter, mit einer Hand die Schlüssel greifend und die andere in einer Geste der Segnung und des Kommandos ausgestreckt, zu seinem Platz über dem Kirchenportal gehoben.

Drei Jahre später wurde die Skulptur in einer Revolution zerstört. Das Volk Bolognas erhob sich gegen die Autorität des Papstes; seine Delegaten und Anhänger wurden verjagt und das Bildnis von seinem Platz geschleudert. Das Werk Michelangelos wurde höhnisch durch die Straßen geschleift, zerschlagen und die Bruchstücke in den Ofen geworfen.

Inzwischen war der Künstler nach der Beendigung der Arbeit seinem versöhnten Meister nach Rom zurückgefolgt. Hier erwartete ihn jedoch nicht die Weiterführung des päpstlichen Grabmals, sondern die Ausführung einiger Malereien in der Sixtinischen Kapelle, was vor seiner Abreise in Frage gestellt worden war. Er behauptete immer, die Malerei sei nicht sein Geschäft; er war sich der Hoffnungen seiner Feinde bewusst, dass eine große Unternehmung in Freskomalerei seine Fähigkeiten übersteigen würde; und er ging das Projekt mit Bedenken und Widerwillen an. Tatsächlich ist dieses ihm aufgedrängte Werk bis heute sein wichtigster Ruhmestitel geworden.

Seine Geschichte ist die eines unbeugsamen Willens und fast übermenschlicher Energie, wenn auch sein Wille sich kaum jemals durchsetzen konnte und seine Energie immer mit den Umständen kämpfte. Das einzige Werk seines ganzen Lebens, das er entsprechend seiner ursprünglichen Vorstellung vollenden konnte, war die Dekoration der Sixtinischen Decke. Der erste Plan des Papstes umfasste lediglich die zwölf Apostel. Michelangelo begann entsprechend, konnte sich aber nicht mit so Dürftigem zufriedengeben und schlug stattdessen einen Entwurf mit vielen hundert Figuren vor, die die Geschichte der Schöpfung bis zur Sintflut verkörpern sollten, mit zusätzlichen Bildnissen von Propheten und Sibyllen und den Vorvätern Christi.

Das Ganze sollte durch ein ausgefeiltes Rahmenwerk aus gemalter Architektur eingefasst und unterteilt werden, mit einer Vielzahl namenloser menschlicher Gestalten, die zwischen dem statischen Rahmenwerk und den großen dramatischen und prophetischen Szenen vermitteln sollten. Der Papst gewährte dem Künstler die Freiheit, nach seinen Vorstellungen zu verfahren. Gegen Mai 1508 waren die Vorbereitungen in der Kapelle beendet, und die Arbeit begann. Später im selben Jahr berief Michelangelo ein paar Assistenzmaler aus Florenz. In den Traditionen der früheren Florentiner Schule ausgebildet, waren sie anscheinend nicht in der Lage, Michelangelos Entwürfe in Fresko entweder genügend frei oder hinreichend gleichförmig auszudeuten, um ihn zufriedenzustellen. Jedenfalls entließ er sie bald und führte den Rest der kolossalen Aufgabe alleine durch, abgesehen von notwendiger, rein mechanischer Hilfe.

Die körperlichen Bedingungen der anhaltenden Arbeit mit dem Gesicht nach oben an dieser weit ausgedehnten Deckenfläche waren extrem ungünstig und aufreibend. Nach viereinhalb Jahren mühseliger Arbeit war die Aufgabe vollendet. Michelangelo war während seines Fortschreitens gleichermaßen durch Zahlungsverzögerungen und durch feindliche Intrigen geplagt worden, indem seine Gegner Zweifel an seinen Fähigkeiten aufwarfen und die Überlegenheit Raffaels rühmten. Dieser sanfte Geist wäre von Natur aus kein Feind gewesen, aber unglücklicherweise verhinderte Michelangelos launisches, auf sich selbst konzentriertes Temperament eine Freundschaft zwischen den beiden Künstlern, die den Unfriedenstiftern hätte Einhalt gebieten können.

Einmal zwang ihn ein dringender Bedarf an Geldern zur Förderung des Projekts, seine Arbeit für einen Moment zu unterbrechen und seinen rücksichtslosen Patron bis nach Bologna zu verfolgen. Dies war zwischen September 1510, als die große Reihe der Themen entlang dem Zentrum des Gewölbes fertiggestellt war, und Januar 1511, als der Meister sich wieder an die Arbeit machte und anfing, die komplizierten seitlichen Räume seines dekorativen Plans auszufüllen.

Die Hauptfläche der Sixtinischen Decke bildet das die Kapelle überlagernde Tonnengewölbe und teilt sich in vier größere Felder auf, die sich mit fünf kleineren Feldern abwechseln. 
Folgenden Themen werden in dieser Reihenfolge von Michelangelo behandelt:


Die Figuren in den letzten drei Szenen sind in kleinerem Maßstab als die der ersten sechs. In den Feldern 1, 3, 5, 7 und 9 ist das Bildfeld durch das architektonische Rahmenwerk mit seinen sitzenden Paaren von Unterstützen – gewöhnlich als Sklaven oder Atlasse bekannt – eingeengt.

Diese kleineren Kompositionen flankierend, befinden sich entlang der seitlichen Flächen zwischen der Gewölbekrone und den Mauern an den Seiten sitzende Figuren, abwechselnd Propheten und Sibyllen. Die sitzenden architektonischen Figuren sind großartig in der Vielfalt ihrer Posen und strahlen viel Lebenskraft aus.

Die Arbeitsweise des Deckenfreskos der Sixtinischen Kapelle im Vatikan ist relativ simpel. Es wurden dazu Kartons mit den Entwürfen, die Michelangelo zuvor im Maßstab 1:1 aufgezeichnet und in die er an den wichtigsten Stellen Löcher gemacht hatte, auf den noch feuchten Putz aufgelegt und mit Kohlestaub an den Löchern bearbeitet. Danach wurden die Schablonen wieder abgenommen, und er konnte sich beim Malen auf die Markierungen konzentrieren.

Zwei weitere Propheten werden an den Enden der Reihe eingeführt, so dass es insgesamt sieben Propheten und fünf Sibyllen gibt. Die Dreiecke rechts und links der Propheten an den beiden Enden enthalten den Tod Goliaths, den Tod des Holofernes, die dreiste Schlange und die Bestrafung Hamans. In den zwölf Lunetten über den Fenstern sind Gruppen der Vorfahren Christi, deren Namen mit Inschriften bezeichnet sind, und in den zwölf Dreiecken über ihnen (zwischen den Propheten und Sibyllen) andere verwandte Gruppen, hockend oder sitzend. Letztere sind in vergleichsweise einfachen menschlichen Handlungen gezeigt – erhöht, aber nicht verfälscht.

Das Werk spiegelt alle Fähigkeiten Michelangelos auf ihrem Höhepunkt wider. Der Künstler scheint im Laufe der Arbeit an Souveränität gewonnen zu haben. Offenbar hat er mit dem chronologisch letzten Thema begonnen, der Trunkenheit Noahs, und rückwärts gearbeitet, wobei er ab dem vierten Thema (Versuchung durch die Schlange und Vertreibung aus dem Paradies) den Maßstab seiner Figuren vergrößert zu haben scheint, um die Wirkung zu verbessern. Absolutes Spitzenwerk aber behauptet das Fresko der „Erschaffung Adams“, das man abertausend Mal publiziert findet in der Welt und eine qualitative Steigerung aller Figuren verkörpert.

Michelangelo hat durch seine enorme Persönlichkeit und kraftvolle Malerei einen hohen Einfluss auf sämtliche Maler seiner Zeit ausgeübt. Manche aber sind in plumpen Übertreibungen und Klobigkeiten verharrt und konnten dem Vorbild in seiner Größe und Kraft in keiner Weise nahekommen. Einige wenige aber zeigten eine gewisse Unabhängigkeit und entwickelten dadurch Bilder von starker Ausdruckskraft.

Kaum war die Sixtinische Kapelle vollendet, nahm Michelangelo die Arbeit an dem Marmor für Julius’ Monument wieder auf. Aber nach nur vier Monaten starb Julius. Seine Erben gingen sofort (im Sommer 1513) einen neuen Vertrag mit Michelangelo für eine verkleinerte Ausführung des Monuments ein. Die ursprünglichen Pläne sind unbekannt. Wir wissen nur, dass das Monument in einer der Kapellen von St. Peter stehen sollte, losgelöst von der Wand, viereckig und frei, was in der bisherigen Grabarchitektur der Renaissance unbekannt war.

Auch der neue Plan war noch umfangreich und prachtvoll. Er sah eine große dreiseitige Struktur mit zwei Stockwerken vor, hervorstehend von der Kirchenwand, und an seinen drei freien Seiten mit Statuen geschmückt. Im oberen Stock sollte die Kolossalfigur des Papstes liegen, mit einer Vision der Jungfrau mit dem Kind über ihm, klagenden Engeln an den Seiten, Propheten und Allegorien in den Ecken – insgesamt 16 Figuren. Im unteren Stock waren 24 Figuren in Nischen und auf vorstehenden Sockeln vorgesehen: in den Nischen Sieger; vor den Endpilastern zwischen ihnen Sklaven oder Gefangene, die anscheinend entweder eroberte Provinzen oder Künste und Wissenschaften in Sklaverei nach dem Tod ihres Patrons symbolisieren.

Ein sehr beschädigter und umstrittener Entwurf des Meisters in Berlin, mit einer Kopie von Sacchetti, soll den Entwurf in diesem Stadium der Verkleinerung darstellen. Das gesamte Werk sollte innerhalb von neun Jahren fertiggestellt werden. Während der nächsten drei Jahre scheint Michelangelo wenigstens drei der versprochenen Figuren vollendet zu haben, für die Blöcke aus Carrara schon im Juli 1508 in Rom angekommen waren. Neben David sind dies seine berühmtesten überlieferten Skulpturen, der Moses, seit 1545 in der Kirche San Pietro in Vincoli in Rom, und die beiden Sklaven im Louvre.

Moses, ursprünglich für eine der Seiten im oberen Stock vorgesehen, ist nun auf Augenhöhe platziert: im Zentrum der Hauptansicht des Monuments, wie es schließlich, in einem reduzierten und geänderten Maßstab, von Michelangelo und seinen Assistenten in hohem Alter beendet wurde. Der Prophet, der vom Berg Sinai hätte herabkommen und die Israeliten das goldene Kalb anbeten sehen sollen, sitzt stark bärtig und eingehüllt, lediglich mit enthülltem linkem Arm, seinen Kopf erhoben und nach links gewandt, seine linke Hand auf dem Schoß und die rechte die Gesetzestafeln greifend. Das Werk ist, abgesehen von ein oder zwei Stellen, äußerst vollendet, und die Statue sieht aus wie einer der Propheten der Sixtinischen Decke in Marmor gehauen – eine Inkarnation majestätischer Entrüstung und Bedrohung.

Die zwei Sklaven im Louvre sind junge männliche Figuren von gleichermaßen perfekter Ausführung, bis auf das Band auf der Brust des einen und am rechten Bein des anderen nackt. Der eine, mit der linken Hand an den Kopf erhoben und der rechten an die Brust gepresst, die Augen fast geschlossen, scheint den Qualen des Todes zu erliegen. Der andere, mit den Armen hinter dem Rücken, schaut nach oben, hoffnungslos kämpfend. Alle drei Figuren wurden zwischen 1513 und 1516 beendet.

1513 war Kardinal Giovanni de Medici unter dem Titel Leo X. Julius II. auf dem Papstthron nachgefolgt. Etwa zur selben Zeit hatten die Medici, auch durch Gewalt und Betrug, ihren Einfluss in Florenz wiederhergestellt, indem sie die freien Institutionen stürzten, die seit den Tagen Savonarolas vorgeherrscht hatten. Auf der einen Seite war diese Familie traditionell Freund und Patron Michelangelos; auf der anderen Seite war er ein patriotischer Freund der Republik Florenz. Von da an standen also seine persönlichen Sympathien und seine politische Treue in Konflikt.

Es ist oft geäußert worden, dass Kummer und Verwirrung über diesen Konflikt ihren Schatten über einen Großteil seiner Kunst geworfen haben. Zunächst einmal unterbrach er nach der Machtübernahme der Medici erneut seine Arbeit am Grabmal Julius’. Leo X. und seine Verwandten hegten einen großen neuen Plan zur Anreicherung und Verzierung der Fassade ihrer eigenen Familienkirche San Lorenzo in Florenz. Michelangelo ließ sich von der Idee mitreißen, vergaß seine andere große Aufgabe und bot seine Dienste für die neue Fassade an.

Sie wurden gerne akzeptiert, obwohl man zunächst die Arbeit Leonardo da Vinci hatte anvertrauen wollen. Julius’ Erben ihrerseits zeigten sich entgegenkommend, und das Gesuch Leos erlaubte ihnen, den drei Jahre alten Vertrag zugunsten eines anderen zu annullieren, nachdem das Ausmaß und die bildhauerischen Dekorationen des Julius-Monuments wiederum um fast die Hälfte reduziert worden waren. Michelangelo erstellte für die Fassade von San Lorenzo zügig einen Plan aus kombinierter Bildhauerei und Architektur, so großartig und ehrgeizig wie derjenige für das ursprüngliche Julius-Monument. Der Vertrag wurde im Januar 1518 unterzeichnet, und der Künstler begab sich nach Carrara, um den Bruch des Marmors zu überwachen.

Obwohl Michelangelo mit nunmehr 43 Jahren die zweite Hälfte seines Lebens bevorstand, waren seine besten Tage vorüber. Alle bisherigen Widrigkeiten waren nichts im Vergleich zu denen, die ihm noch bevorstanden. Zur Materiallieferung für die Fassade von San Lorenzo hatte er eine Firma von Steinmetzen in Carrara beauftragt, und er selbst ging anscheinend mit ihnen eine Art Partnerschaft ein.

Als alles dort unter seiner Aufsicht gut fortschritt, baten ihn die Medici und der Florentiner Magistrat aus politischen Gründen, nach neuen Steinbrüchen in Pietrasanta bei Serravalle auf Florentiner Gebiet umzuziehen. Zur Entrüstung seiner alten Kunden in Carrara und seiner eigenen musste Michelangelo nun seinen Arbeitsort hierhin verlegen. Die mechanischen Schwierigkeiten beim Aushub und Transport des Marmors, die Untreue und Inkompetenz seiner Mitarbeiter erzürnten ihn so sehr, dass er den ganzen Auftrag hinwarf. Die Verträge für die Fassade wurden im März 1518 annulliert, und aus dem ganzen prachtvollen Plan wurde nichts.

Michelangelo kehrte nach Florenz zurück, wo zahlreiche Arbeitsvorschläge auf ihn zukamen. Der König von Frankreich wünschte etwas von seiner Hand, um es neben zwei Bildern Raffaels zu platzieren, die sich in seinem Besitz befanden. Die Behörden von Bologna wollten von ihm die Fassade ihrer Kirche St. Petronius gestaltet haben; die von Genua eine Bronzestatue ihres großen Kommandeurs Andrea Doria. Kardinal Grimani bat inständig um jegliche Gemälde oder Statuen, die er übrig habe; andere Kunstliebhaber bedrängten ihn um Kleinigkeiten wie Stiftzeichnungen oder Entwürfe.

Schließlich flehte ihn sein Freund und Anhänger Sebastiano del Piombo in Rom – immer begierig, die Fehde zwischen Michelangelo- und Raffael-Anhängern zu nähren – nach Raffaels Tod an, nach Rom zurückzukehren, um den Schülern des toten Meisters die Malarbeit zu entreißen, die noch in den Kammern des Vatikan erledigt werden musste. Michelangelo kam keiner dieser Bitten nach. Sichere Kenntnisse über seine Tätigkeit zwischen 1518 und 1522 beschränken sich auf die Grobbearbeitung weiterer vier Sklaven für das Grabmal Julius’ und die Ausführung eines Auftrags für drei römische Bürger für die Statue "Der auferstandene Christus", den er schon 1514 erhalten hatte.

Die grob bearbeiteten Sklaven befanden sich lange Zeit in einer Grotta in den Boboli-Gärten, ihr heutiger Standort ist die Galleria dell’Accademia in Florenz. Der Christus, praktisch vom Meister beendet, mit den letzten Ausbesserungen durch seine Schüler, steht in der Kirche Santa Maria sopra Minerva in Rom, für die er bestimmt war; er zeigt wenig Hingebung und Erfindungsgeist, wenn auch die von Michelangelo selbst fertiggestellten Teile formal und handwerklich äußerst vollendet sind.

Die nächsten zwölf Jahre (1522–1534) verbrachte Michelangelo in Florenz, wieder hauptsächlich in den Diensten seiner gegensätzlichen und launischen Patrone – der Medici. Der Plan einer großen Gruppe von Monumenten für verstorbene Mitglieder dieser Familie, die in einer neuen Sakristei oder Grabkapelle in San Lorenzo aufgestellt werden sollte, wurde Michelangelo erstmals 1520 von Kardinal Giulio de Medici angetragen. Allerdings ging kein praktischer Impuls für das Werk aus, bis Giulio nach dem Tod Leos X. und dem kurzen Pontifikat des puritanischen und ikonoklastischen Hadrian VI. 1523 selbst unter dem Titel Clemens VII. Papst wurde.

Selbst dann war die Initiative nur schwankend. Zuerst schlug Clemens vor, Michelangelo einen weiteren Künstler, Andrea Sansovino, für diese Aufgabe beizuordnen. Nachdem dieser Vorschlag auf Michelangelos entschiedenen Einspruch fallengelassen wurde, lenkte Clemens den Künstler als Nächstes mit einer Bestellung für einen neuen architektonischen Entwurf ab, nämlich für die vorgeschlagene Medici- oder Laurentinische Bibliothek. Die Biblioteca Laurenziana war von Clemens VII. als vorrangiges Projekt eingestuft worden und sollte, mit 50.000 Dukaten ausgestattet, so schnell wie nur möglich erbaut werden. Die Arbeit nahm Michelangelos Zeit zwischen April 1524 und Oktober 1526 voll in Anspruch. Erst danach widmete er sich wieder der Arbeit an der Kapelle. Nach vielen Änderungen schließlich Gestalt annehmend, enthielten die Pläne für die Grabkapelle ("Sagrestia Nuova") nicht wie zunächst vorgesehen Denkmäler für die Gründerväter des Hauses, Cosimo il Vecchio, Lorenzo il Magnifico oder Leo X., sondern nur für zwei jüngere Mitglieder des Hauses, die kurz zuvor gestorben waren, Giuliano, duc de Nemours, und Lorenzo, Herzog von Urbino.

Michelangelo brütete lange über verschiedenen Entwürfen für diese Arbeit und war noch mit der Ausführung beschäftigt – seine Zeit wurde teilweise auch für die Baupläne für die Medici-Bibliothek in Anspruch genommen –, als politische Revolutionen ihn unterbrachen. 1527 ereignete sich der Sacco di Roma und damit der Untergang Papst Clemens’. Die Florentiner nahmen die Gelegenheit wahr, die Medici aus der Stadt zu vertreiben und wieder eine Republik zu errichten.

Natürlich standen damit keine Geldmittel mehr für die Arbeiten in San Lorenzo zur Verfügung, und Michelangelo beschäftigte sich auf Einladung der neuen Signoria eine Weile mit einer Gruppe aus "Herkules und Cacus" und einer weiteren aus "Samson und den Philistern" – letztere aus einem Marmorklotz zu hauen, der schon für einen anderen Zweck von Baccio Bandinelli bearbeitet worden war.

Bald darauf wurde er aber gerufen, um die Stadt selbst vor Gefahr zu schützen. Clemens und sein Feind Karl V. hatten sich versöhnt und waren nun beide erpicht, Florenz wieder unter die Herrschaft der Medici zu bringen. Hinsichtlich der bevorstehenden Belagerung wurde Michelangelo zum leitenden Techniker für die Befestigungen berufen. Er verbrachte den Frühsommer 1529 mit der Verstärkung der Verteidigungsanlagen von San Miniato; von Juli bis September war er auf einer diplomatischen Mission in Ferrara und Venedig.

Nachdem er Mitte September zurückkehrte, erwies sich die florentinische Sache wegen internen Verrats und der überwältigenden Stärke der Feinde als aussichtslos. Nach einem Anfall von Melancholie reiste er plötzlich nach Venedig ab, wo er für eine Weile blieb und wegen eines zukünftigen Wohnsitzes in Frankreich verhandelte. Noch während der Belagerung kehrte er nach Florenz zurück, aber am letzten Todeskampf um die Freiheit der Stadt hatte er keinen Anteil mehr.

Als sich die Stadt 1530 ihren Eroberern unterwarf, wurde den meisten, die an ihrer Verteidigung mitgewirkt hatten, keine Gnade zuteil. Michelangelo glaubte sich mit den anderen in Gefahr, aber auf Intervention Baccio Valoris wurde er sogleich von Papst Clemens wieder angestellt. In den nächsten vier Jahren setzte er zeitweise seine Arbeit an den Medici-Monumenten – ab 1532 mit der Unterstützung Giovanni Angelo Montorsolis und anderen Schülern – und dem Bau der Laurentinischen Bibliothek fort.

1531 erkrankte Michelangelo schwer; 1532 hatte er einen längeren Aufenthalt in Rom und ging einen weiteren Vertrag für die Vollendung des Julius-Monuments ein, das jetzt noch mehr reduziert wurde und statt in St. Peter in der Kirche San Pietro in Vincoli platziert werden sollte. Im Herbst 1534 verließ er endgültig Florenz. Die anstehenden Arbeiten in der Medici-Kapelle wurden von Schülern beendet, und die Kapelle wurde erst 1545 zur Betrachtung geöffnet.

Die Statuen für das Medici-Monument zählen neben Moses und den Sklaven zu den besten Werken aus Michelangelos mittlerer Periode der Bildhauerei. Sie bestehen aus einer Madonna mit Kind und zwei monumentalen Gruppen, beide mit einer sitzenden Porträt-Statue in einer Nische und zwei emblematischen Figuren, die an jeder Seite oberhalb eines Sarkophags lehnen. Die unvollendete Madonna mit Kind verbindet ein realistisches, natürlich lebhaftes Motiv mit gelehrt komplexem Design und majestätischer Wirkung. Sie wurde schließlich – entgegen der anfänglichen Absicht des Künstlers – an einer leeren Wand der Kapelle aufgestellt und von Statuen der Heiligen Cosmo und Damian, Werken von Schülern, in großem Abstand flankiert.

Die Porträts sind nicht realistisch, sondern typisch behandelt. Lorenzo scheint schlaues Grübeln und konzentrierte innere Überlegung zu versinnbildlichen, Giuliano Wachsamkeit und selbstsichere praktische Umschau unmittelbar vor einer Handlung. Diesem Kontrast zwischen meditativem und aktivem Charakter entspricht der Kontrast zwischen den emblematischen Gruppen, die die Porträts begleiten. Zu den Füßen des Herzogs Giuliano lehnen Nacht und Tag, erstere weiblich, letzterer männlich personifiziert. Die Nacht versinkt in einer Haltung tiefen, unruhigen Schlummerns; der Tag, mit Kopf und Gesicht aus dem Marmor herausgestemmt, erwacht voll Zorn und Unruhe.

Ebenso grandios, aber weniger stark, sind die Haltungen der beiden korrespondierenden Figuren, die zwischen Schlafen und Wachen am Sarkophag des nachdenklichen Lorenzo lehnen. Von diesen ist die männliche Figur als Abend bekannt, die weibliche als Morgen (Crepuscolo und Aurora). Michelangelos ursprüngliche Vorstellung, die teilweise auf antiken Vorbildern in Giebel- und Sarkophaggruppen basierte, verband Erde und Himmel mit Nacht und Tag auf dem Monument Giulianos, und andere, zweifellos entsprechende Figuren, mit Morgen und Abend auf dem Monument Lorenzos. Diese Figuren fielen später aus dem Plan heraus, und die für sie vorgesehenen Winkel blieben leer.

Nach seinen eigenen Aufzeichnungen wollte Michelangelo darstellen, wie die Elemente und Mächte von Erde und Himmel den Tod der Fürsten beklagen. Auf der breiten Basis am Fuß der Monumente sollten Flussgötter liegen. Sie wurden nie vollendet, aber ein Bronzeabdruck eines von ihnen sowie der Torso eines großen Modells sind identifiziert worden und im Nationalmuseum bzw. in der Akademie in Florenz zu sehen.

Michelangelo hatte beabsichtigt, entsprechend dem neuen Vertrag von 1532 all seine Kräfte der Fertigstellung des Julianischen Monuments zu widmen, sobald er die Medici-Grabmäler beendet haben würde. Aber seine Absicht wurde wiederum enttäuscht. Papst Clemens bestand darauf, dass er seine Dekorationen der Sixtinischen Kapelle vervollständigen müsse, indem er die große Frontwand über dem Altar neu bemale, die bis dahin mit Fresken von Perugino ausgeschmückt war. Das gewählte Thema war das Jüngste Gericht, und Michelangelo begann Entwürfe vorzubereiten. Im Herbst 1534, mit 60 Jahren, ließ er sich für den Rest seines Lebens in Rom nieder. Unmittelbar darauf starb Clemens. Sein Nachfolger im Papstamt war Paul III. aus dem Haus der Farnese.

Mehr noch als sein Vorgänger beanspruchte Paul III. Michelangelo für sich und zwang ihn, alle anderen Engagements aufzuschieben. In den folgenden sieben Jahren war Michelangelos Zeit im Wesentlichen mit der Malerei des Jüngsten Gerichts ausgefüllt. Anders als bei den Deckenfresken verwendete Michelangelo darin beinahe verschwenderisch blaue Farbe, die zur damaligen Zeit aus zerriebenem Lapislazuli bestand und entsprechend teuer war. Das lag unter anderem daran, dass dieses Werk der Papst persönlich in Auftrag gegeben hat , und ihm damit ein erheblich höheres Budget für das Wandgemälde zur Verfügung stand. Heute gilt es, gemessen am Wert der Materialien, als eines der teuersten Gemälde der Welt. Da es Michelangelo nicht gestattet war, seine Fresken zu signieren, wandte er einen Trick an, um sich dennoch darin zu verewigen. Die Haut, die Bartholomäus in seiner linken Hand hält, zeigt Michelangelos Konterfei . Nachdem dieses 1541 vollendet war, musste er anschließend zwei weitere große Fresken in einer neuen Kapelle, die der Papst im Vatikan hatte bauen lassen, und die nach ihm Cappella Paolina genannt wurde, übernehmen. Die Sujets dieser Fresken waren die Konversion des Paulus und das Martyrium des Petrus.

Das Fresko des Jüngsten Gerichts in der Sixtinischen Kapelle ist eines der berühmtesten Einzelbilder der Welt. Darin hat Michelangelo alle geistigen Erfahrungen als Künstler zum Ausdruck gebracht. Im Zentrum des Bildes steht der Weltrichter. Die göttliche Gerechtigkeit scheidet unerbittlich die Guten von den Verdammten. In den Lünetten am oberen Rand des Bildes sieht man die Attribute Christi: Kreuz, Säule und Dornenkrone, die Passionssymbole. Auf der linken Seite des Bildes sieht man, wie ein Begleiter Johannes den Täufer am rechten Arm ergreift, um ihn auf die beiden Frauen zu seiner Rechten hinzuweisen. Es handelt sich um Herodias, die ihre Tochter Salome um Verzeihung bittet. 
Pavel Florenskij weist auf die besondere „Raumordnung im ‚Letzten Gericht‘“ Michelangelos hin und schreibt weiter: 
Nach der Vollendung des "Weltgerichtes" forderte Papst Paul III. von Michelangelo, seine Privatkapelle, die "Cappella Paolina", mit Fresken zu schmücken. In den beiden Fresken erreichte Michelangelo nochmals einen geistigen Höhepunkt. In Symbolen stellt der Künstler das Schicksal des einzelnen Menschen dar, denn die "Bekehrung Pauli" und die "Kreuzigung Petri" sind innere Selbstbildnisse und sollen die planlos herumirrenden Zuschauer erschrecken und zum Erkennen anregen. Von sich sagte Michelangelo, dass die Freskenmalerei keine Sache für alte Leute sei, daher er nicht mehr die Kraft in sich fühle, die eine solche Liebe wie die Malerei beanspruche.

In den unvollendeten Skulpturen ist an die Stelle des Bildwerkes ein Zeichen getreten, das sich der Deutung durch das Wort entzieht.

Kunst, die ent-hüllt oder als Schönheit wieder ver-hüllt, die Wahrheit wieder verschleiert, ist ein bewusstes und gewolltes Nachvollziehen des Schöpfungszyklus.

1547 übernahm Michelangelo die Bauleitung am immer noch fragmentarischen neuen Petersdom. Unter Rückbezug auf die Pläne seines Vor-Vorgängers Donato Bramante entwarf er auch die Rippenkuppel inmitten eines Zentralbaues, die jedoch erst nach seinem Tod in veränderter Form von Giacomo della Porta ausgeführt wurde.

Michelangelo Buonarroti verstarb am 18. Februar 1564 in Rom. Er wurde in der Kirche Santa Croce in Florenz beigesetzt.

Michelangelo sah sich in erster Linie als Bildhauer, nicht als Maler, Architekt oder Dichter, obwohl er auf allen diesen Gebieten Bedeutendes und Wegweisendes leistete. Doch die Skulptur stellte er über alle anderen Kunstformen, was viele seiner Briefe belegen, die noch dazu meist mit „Michelangiolo, scultore“ („Michelangelo, Bildhauer“) unterzeichnet sind.

Seinen platonischen Auffassungen entsprechend basierte Michelangelos künstlerisches Schaffen auf der Vorstellung, dass der Geist als höchstes Prinzip die Idee enthält, die allem sinnlichen Erfahren übergeordnet ist.

So sah er schon im rohen Marmorblock das Kunstwerk vorgeformt, es schlummerte als Idee bereits im Stein und musste nur noch aus ihm „befreit“ werden.

Er betrachtete den Stein zudem als etwas, dem Seele zu verleihen war. Die Auseinandersetzung mit Beschaffenheit und Form des Materials war für ihn dabei von großer Bedeutung. Die Wahl des Blocks stellte für Michelangelo bereits einen wichtigen Aspekt seiner künstlerischen Arbeit dar, verbrachte er doch immer wieder etliche Wochen, teilweise gar Monate, in den Steinbrüchen.

Die Grundidee entstand mit Hilfe von ausschließlich nach dem Modell entstandenen Zeichnungen. Machte er sich dann an den Block, bearbeitete er in der Regel alle Partien der Figur gleichzeitig, um die Gesamtheit im Auge zu behalten. Seitenansichten wurden nicht getrennt entwickelt, sie ergaben sich aus dem Fortschreiten des Werkes. Lediglich der Rückenansicht und dem Gesicht widmete er sich oftmals als letztes. Er ging bei der Bearbeitung der Oberflächen stufenweise vor. So standen bei seinen zahlreichen unvollendeten Arbeiten, die uns Einblick in seine Vorgehensweise gewähren, perfekt ausgearbeitete und polierte neben halb und grob gehauenen Partien.

Ein besonderer Aspekt in Michelangelos Schaffen und gleichzeitig ein Ausdruck seines Respekts vor dem Material zeigt seine Gestaltung und Behandlung der Sockel seiner Skulpturen. In frühen Werken, wie dem Bacchus, der Pietá der Peterskirche, dem David oder dem Christus ist noch eine gewisse realistische Nachahmung der Natur erkennbar.

Später, etwa bei Moses, Rachel, Lea, Sieger und den Sklaven des Louvre ist die Form der Sockel einem geometrischen Prinzip unterworfen, das sich allerdings durch ein Fehlen von konsequenter Strenge auszeichnet. Diese Sockel sind von zahlreichen, subtilen Unregelmäßigkeiten und Asymmetrien belebt und erlangen so eine künstlerische Aussage. Sie stehen gleichwertig neben der eigentlichen Darstellung, wobei eine größere Harmonie durch Betonung der Ganzheit erreicht wird.

Michelangelo entwickelte im Laufe seines Lebens eine große Anzahl an Plänen zu Werken und Projekten von teilweise gigantischen Ausmaßen. Nur ein Bruchteil dessen, was sein Geist hervorbrachte, wurde letztlich ausgeführt.
Die Gründe dafür werden sehr konträr diskutiert. Von einfachen Erklärungen, wie Zeitmangel oder Interesseverlust, bis zu philosophischen und psychologischen Interpretationen sind in der Literatur zu dieser Problematik mannigfaltige Ansätze zu finden.

Das markanteste Beispiel für die rudimentäre Realisierung eines großangelegten Projekts ist die geistige und künstlerische Arbeit am Grabmal des Papstes Julius II. Über 40 Jahre beschäftigte sich Michelangelo mit diesem seinem ehrgeizigsten Vorhaben, das er selbst als „seine Tragödie“ bezeichnete.
Vom ursprünglichen Entwurf eines freistehenden Monuments mit mehr als 40 Figuren blieben nach vielerlei Beschneidungen und Revisionen, bedingt durch zahlreiche äußere Einflüsse, die vergleichsweise bescheidene Lösung eines Wandgrabs mit lediglich drei selbstausgeführten Figuren (Moses, Rahel und Lea) sowie einige einzelne Skulpturen, die keine Verwendung im Ensemble finden (sechs Sklaven, Sieger).

Das Unvollendete reflektiert sich in einem großen Teil von Michelangelos bildhauerischer Arbeit.
Immerhin wird im Allgemeinen davon ausgegangen, dass das „non-finito“ bei Michelangelo kein von vornherein feststehendes Prinzip war, wie etwa fast 400 Jahre später bei Rodin, der sich zweifellos von der Vorstellung des Unvollendeten in Michelangelos Skulpturen inspirieren ließ und diesen Effekt kalkuliert in sein eigenes Werk integrierte, um besonders ausgearbeiteten Partien mehr Nachdruck zu verleihen.

Es wird allerdings die Ansicht vertreten, dass das Nichtzuendeführen mancher Figuren das Ergebnis wohlerwogener ästhetischer Entscheidungen während des Arbeitsprozesses gewesen sei.

Einige Autoren sind der Meinung, dass der „Perfektionist“ Michelangelo mit der Realisierung seiner „Idee“ in Form einer gänzlich ausgearbeiteten Figur immer unzufrieden gewesen wäre und lieber die Unzulänglichkeit einer gewissen Offenheit in Kauf nahm, als das Risiko einzugehen, durch völlige Festlegung den Kern nicht in absoluter Weise zu treffen. Ähnliche Mutmaßungen schreiben Michelangelo etwa diese Haltung zu: „Ganz perfekt geht es sowieso nicht, also ist eine Weiterführung nicht sinnvoll.“ Insgesamt ist es schwer zu entscheiden, bei welchen der unvollendeten Skulpturen solche Überlegungen eine Rolle gespielt haben mögen.

Betrachtet man die in unterschiedlichen Stadien belassenen Köpfe der Abendröte und des Tages in der Gesamtheit der anderen, weitestgehend ausgefeilten Figuren der Medici-Gräber, stellt sich die Frage, ob hier wirklich ein bewusster Abbruch der Arbeit aus künstlerischen Überlegungen heraus stattfand, oder ob die geplante Vollendung wegen äußerer Umstände unterblieb.

An der Pietà Rondanini arbeitete Michelangelo bis zu seinem Tod und konnte sie nicht fertigstellen. Hier ist ersichtlich, dass der Künstler während des Schaffens eine völlige Umgestaltung vornahm und sogar Teile der Skulptur wieder zerstörte. Ob dies geschah, um eine ursprüngliche Idee durch eine neue zu ersetzen, oder ob der Meister sich schlicht „verhauen“ hat, bleibt offen.

Genauso unerklärt und Spekulationen unterworfen ist die Frage, ob die vier unvollendeten Sklaven nicht perfekter hätten gestaltet werden können oder ob sie einfach liegenblieben, weil sie nicht mehr in das beschnittene Programm des letztlich ausgeführten Julius-Grabmals passten.


Neben dem bildnerischen Werk entstanden eine Reihe von Sonetten, die vor allem seiner langjährigen Freundin Vittoria Colonna und seinem Freund Tommaso de’ Cavalieri gewidmet sind, sowie Madrigale und andere Gedichte.


Einige dieser Dichtungen wurden von verschiedenen Komponisten vertont:


Sonett an Tommaso de’ Cavalieri, Übersetzung: Rainer Maria Rilke







</doc>
<doc id="10693" url="https://de.wikipedia.org/wiki?curid=10693" title="Rembrandt van Rijn">
Rembrandt van Rijn

Rembrandt Harmenszoon van Rijn (* 15. Juli 1606 in Leiden; † 4. Oktober 1669 in Amsterdam; bekannt unter seinem Vornamen Rembrandt) gilt als einer der bedeutendsten und bekanntesten niederländischen Künstler des Barocks. Sein Schaffen fiel in die Epoche des Goldenen Zeitalters, als die Niederlande eine politische, wirtschaftliche und künstlerische Blütezeit erlebten. Rembrandt studierte bei Pieter Lastman, eröffnete 1625 in Leiden sein erstes Atelier und zog bald Aufmerksamkeit auf sich. 1631 zog er nach Amsterdam, wo er sich zu einem gefeierten Künstler entwickelte. Trotzdem litt er zeitweise unter erheblichen finanziellen Problemen, ging 1656 in Insolvenz und starb in Armut.

Rembrandt betätigte sich als Maler, Radierer und Zeichner, führte eine Werkstatt und bildete Künstler aus. Sein Gesamtwerk umfasst unter anderem Porträts, Landschaften sowie biblische und mythologische Themen. Zu seinen bekanntesten Arbeiten zählen "Die Blendung Simsons", "Die Nachtwache", "Die Anatomie des Dr. Tulp" und "Das Hundertguldenblatt". In seinen Historiendarstellungen griff Rembrandt zahlreiche Motive auf, die bis dahin nicht künstlerisch bearbeitet worden waren, oder er suchte nach neuen Darstellungsmöglichkeiten traditioneller Motive. Viele dieser Werke zeichnen sich durch starke Hell-Dunkel-Kontraste aus, weshalb er als ein Meister des Chiaroscuro gilt.

Rembrandt wurde bereits zu Lebzeiten durch Nachstiche und Kopien seiner Bilder rezipiert. Nach seinem Tod wurde seine koloristische Malweise in der Kunstkritik und Kunstliteratur des Klassizismus negativ bewertet, während sich seine Werke bei Sammlern großer Beliebtheit erfreuten und hohe Preise erzielten. Im 18. Jahrhundert fand Rembrandt Nachfolger unter deutschen und englischen Künstlern. Rembrandts Leben wurde in dieser Zeit mystifiziert und mit Legenden ausgeschmückt; erst in der Mitte des 19. Jahrhunderts wurde aus diesem Rembrandt-Bild durch Quellenforschung seine reale Biographie extrahiert. Seit den 1970er Jahren beschäftigt sich das Rembrandt Research Project mit der Erforschung von Rembrandts Werken. Es hat diese auf ihre Authentizität hin untersucht, so dass sich die Zahl der nachweislich von Rembrandt selbst gemalten Bilder von einst angeblich über 700 auf etwa 350 reduziert hat.

Rembrandt wurde am 15. Juli 1606 in Leiden als achtes von neun Kindern geboren. Die Eltern waren der Müller Harmen Gerritszoon van Rijn und dessen Frau Neeltgen Willemsdochter van Zuytbrouck, eine Bäckerstochter. Wie viele andere Kinder der Stadt besuchte Rembrandt zwischen 1612 und 1616 die Grundschule und anschließend, von 1616 bis 1620, die streng calvinistische Lateinschule. Dort wurde er in Biblischer Geschichte und den Klassikern unterrichtet. Zudem erhielt Rembrandt Rhetorikunterricht, der möglicherweise seine Malerei beeinflusste. Nach der achtjährigen Schulzeit schrieb er sich an der philosophischen Fakultät der Universität Leiden ein. Dieses Studium brach er jedoch nach kurzer Zeit ab, um eine Ausbildung zum Maler zu beginnen. Von 1620 bis 1624 war er Schüler von Jacob Isaacsz van Swanenburgh. Der in Italien geschulte Lehrer hatte sich auf Architekturmalerei und die szenische Darstellung der Hölle spezialisiert und vermittelte seinem Schüler die Grundlagen der Malerei. Die Gestaltung des Feuers in den Bildnissen der Hölle hat möglicherweise Rembrandts Interesse an der Darstellung des Lichtes geweckt. Im Anschluss absolvierte er 1624 eine sechsmonatige Lehrzeit bei dem Historienmaler Pieter Lastman in Amsterdam, die Rembrandt stärker prägte als die vorherige Ausbildung. Lastman führte ihn in die Historienmalerei ein, die in der damals gültigen Rangordnung der Malereigattungen die höchste Position innehatte. Die Ausbildung bei zwei Meistern war zu der damaligen Zeit nicht ungewöhnlich.

1625 kehrte Rembrandt nach Leiden zurück. Dort gründete er mit seinem Freund Jan Lievens eine eigene Werkstatt. Er widmete sich vor allem der Historienmalerei nach dem Vorbild seines Lehrers Lastman und physiognomischen Studien. Drei Jahre später fertigte er erstmals eine Radierung an und begann, Schüler aufzunehmen. Im selben Jahr zeigte der Sekretär des Statthalters Friedrich Heinrich, Constantijn Huygens, der im November 1628 Leiden besuchte, Interesse an der Kunst Rembrandts. In der Folge unterstützte er den Künstler und vermittelte ihm Aufträge. So konnte Rembrandt in den Jahren 1629 und 1630 sogar zwei Bilder an die englische Krone veräußern. "Die Auferweckung des Lazarus" und "Judas bringt die dreißig Silberlinge zurück" wurden mehrmals durch andere Künstler kopiert. Am 27. April 1630 starb Rembrandts Vater.

Nach seinen ersten Erfolgen und angezogen von der steigenden Bedeutung der niederländischen Hauptstadt gab Rembrandt 1631 das gemeinsam mit Lievens betriebene Leidener Atelier auf und zog nach Amsterdam. Dort kaufte er sich bei dem Kunsthändler Hendrick van Uylenburgh ein, der eine große Werkstatt besaß, in der Kopien hergestellt und Restaurierungen durchgeführt wurden. Schon nach kurzer Zeit erhielt Rembrandt von reichen Kaufleuten Porträtaufträge. Im folgenden Jahr kaufte Statthalter Friedrich Heinrich auf Vermittlung von Constantijn Huygens einige Gemälde Rembrandts und gab einen Passionszyklus in Auftrag. Ebenfalls im Jahr 1632 erhielt Rembrandt den Auftrag für das Bild "Die Anatomie des Dr. Tulp", das er im selben Jahr fertigstellte. Insgesamt entstanden in diesem Jahr 30 Gemälde. Rembrandt arbeitete wohl als Werkstattleiter für Uylenburgh, denn vor der Aufnahme in die Amsterdamer Gilde und der damit verbundenen Selbständigkeit musste er zunächst bei einem anderen Meister oder in einer Werkstatt tätig gewesen sein.

Am 2. Juli 1634 heiratete Rembrandt Saskia van Uylenburgh, die Nichte seines Kunsthändlers und Tochter eines wohlhabenden Patriziers. Im selben Jahr trat er der Lukasgilde bei. Dies ermöglichte ihm, als selbstständiger Meister Lehrlinge und Schüler auszubilden. Im Jahr 1635 arbeitete er unter anderem an den Bildern "Die Opferung Isaaks" und "Simson bedroht seinen Schwiegervater". Rembrandts erster Sohn, am 15. Dezember 1635 auf den Namen Rombertus (andere Schreibweise Rombartus) getauft, starb bereits nach wenigen Monaten. 1636 zog das Ehepaar, das bis dahin immer noch beim Kunsthändler Uylenburgh gewohnt hatte, in die Nieuwe Doelenstraat um. Neben seiner künstlerischen Tätigkeit handelte Rembrandt dort mit Kunstwerken und baute eine Sammlung von historischen und wissenschaftlichen Objekten, Pflanzen und Tieren sowie Exotika (Gegenständen aus fernen Ländern wie Indien) auf. 1638 verklagte Rembrandt die Verwandten seiner Frau in einem Beleidigungsprozess, weil diese ihr Verschwendung vorgeworfen hatten. Diesen Vorwurf begründeten die Verwandten Saskias damit, dass ihr Erbe von etwa 40.000 Gulden nahezu aufgebraucht war. Ebenfalls in diesem Jahr wurde seine erste Tochter namens Cornelia geboren, die – wie schon sein erstgeborener Sohn – kurze Zeit später verstarb.

Rembrandt kaufte am 5. Januar 1639 ein neues Haus in der Breestraat, in dem sich heute das Museum Het Rembrandthuis befindet. Dazu nahm er einen Kredit auf, den er in fünf bis sechs Jahren abzahlen wollte. In das Jahr 1639 fiel auch die Fertigstellung des letzten Bildes des Passionszyklus. Das folgende Jahr 1640 war für Rembrandt durch zwei Schicksalsschläge gekennzeichnet: Seine zweite Tochter, die am 29. Juli auf den Namen Cornelia getauft worden war, verstarb kurz darauf. Nur einen Monat später starb auch die Mutter Rembrandts.

Künstlerisch vollzog sich bei ihm eine Wende, als er begann, sich auch der Landschaftsmalerei und dem Radieren von Landschaften zu widmen. Sein zweiter Sohn Titus wurde am 22. September 1641 getauft. Im folgenden Jahr stellte Rembrandt das Bild "Die Nachtwache" fertig. Am 14. Juni 1642 verstarb seine Ehefrau Saskia. Dieses Ereignis bedeutete einen tiefen Einschnitt in Rembrandts Leben. Waren die Jahre zuvor von hoher Produktivität gekennzeichnet, ließ seine künstlerische Aktivität nun deutlich nach. Er schuf nur wenige Gemälde und Radierungen, wie das zu seinen bekanntesten Werken gehörende "Hundertguldenblatt". Zudem identifizierte er sich stark mit seiner Vaterrolle und kümmerte sich in besonderem Maße um seinen Sohn Titus. Seine familiäre Situation griff Rembrandt auch in Kunstwerken auf, wie etwa in der Zeichnung, die einen Mann beim Füttern eines Kindes zeigt. Damit sie ihn im Haushalt entlastete, holte er Geertje Dircx zu sich, die ein besonders enges Verhältnis zu Titus entwickelte. So bedachte sie ihn als Haupterben in ihrem Testament, als sie 1648 schwer erkrankte. 1649 stellte Rembrandt die wesentlich jüngere Hendrickje Stoffels ein.

Nachdem Hendrickje Rembrandts neue Partnerin geworden war, kam es zum Streit mit Geertje Dircx. 1649 verklagte sie ihn vor Gericht auf Unterhalt und erreichte tatsächlich, dass Rembrandt zu einer höheren Zahlung verurteilt wurde. Als sie jedoch im darauffolgenden Jahr entgegen der vor Gericht getroffenen Absprache weiteren Schmuck verpfändete, den sie von Rembrandt bekommen hatte, sammelte dieser zusammen mit ihrem Bruder belastende Aussagen gegen sie und setzte durch, dass sie fünf Jahre in einer Besserungsanstalt (dem Spinhuis in Gouda) verbringen musste.

Von dem sizilianischen Mäzen Antonio Ruffo erhielt Rembrandt im Jahr 1652 den Auftrag, das Bild "Aristoteles mit der Büste Homers" zu malen. Trotz der guten Auftragslage, den Erlösen aus dem Verkauf von Radierungen und den Honoraren aus seiner Lehrtätigkeit konnte er seine Schulden nicht abtragen und musste sich weiterhin Geld leihen. 1654 wurde Hendrickje Stoffels vor den Amsterdamer Kirchenrat geladen, der sie wegen unzüchtigen Zusammenlebens mit Rembrandt rügte. Sie gebar die dritte Tochter Rembrandts, die ebenfalls Cornelia genannt und am 30. Oktober 1654 getauft wurde.

Rembrandt überschrieb am 17. Mai 1656 sein Haus auf seinen Sohn Titus, bevor er kurz darauf für zahlungsunfähig erklärt wurde. In den beiden darauffolgenden Jahren wurden das Haus und seine Sammlung versteigert. Mit dem Erlös konnten die Schulden jedoch nicht vollständig beglichen werden. Rembrandt zog daraufhin in die Rozengracht um, wo vor allem sozial schwächere Schichten wohnten. Dort führte er ein abgeschiedenes Leben unter mennonitischen und jüdischen Freunden. Die Vormundschaft für Titus wurde von Louys Crayers (1623–1688) übernommen, der in einem langen Prozess das Erbteil für Titus aus der Konkursmasse erstritt. 1660 stellten Titus und Hendrickje Stoffels Rembrandt in ihrer Kunsthandlung an. Dadurch hielt er Geschäftskontakte aufrecht, nahm weiterhin Aufträge an und unterrichtete Schüler. Ruffo erwarb 1661 das Bild "Alexander der Große" und bestellte ein Gemälde, das Homer zeigen sollte. 1663 verstarb Hendrickje Stoffels.

1665 wurde Titus volljährig und erhielt sein Erbe ausgezahlt. Zur selben Zeit arbeitete Rembrandt an dem Gemälde "Die Judenbraut". Drei Jahre später starb sein Sohn, der ein halbes Jahr zuvor Magdalena van Loo geheiratet hatte, und wurde am 7. September 1668 beigesetzt. Rembrandt zog nach diesem Ereignis zu seiner Schwiegertochter. Diese gebar seinen Enkel, dessen Pate er am 22. März 1669 wurde. Noch im selben Jahr, am 4. Oktober, verstarb Rembrandt. Das Bild "Simeon im Tempel" blieb unvollendet. Am 8. Oktober wurde Rembrandt in der Westerkerk beigesetzt.

Wurden Rembrandt in den 1920er-Jahren noch teilweise über 700 Gemälde zugeschrieben, geht die Fachwelt mittlerweile davon aus, dass sein Gesamtwerk etwa 350 Gemälde, 300 Radierungen und 1000 Zeichnungen umfasst.

Die Hauptthemen seiner Gemälde und Radierungen sind Historien und Porträts, einschließlich Selbstporträts. Viele der Historiengemälde und -radierungen zeigen hier erstmals künstlerisch verarbeitete biblische Szenen und Mythen oder setzen ein traditionelles Thema deutlich anders um, als es in Vorbildern geschehen war. Daneben war Rembrandt ein erfolgreicher Porträtmaler, dem es gelang, die Porträtierten glaubhaft in Handlungen einzubinden. Die Selbstporträts legen Zeugnis von seiner Selbstsicht ab und vermitteln seine Auseinandersetzung mit dem eigenen Altern. Vor allem die Radierungen zeigen ihn mit verschiedenen Gesichtsausdrücken und Gesten und dienten damit auch Studienzwecken. Rembrandt malte und radierte nur wenige Landschaften und Genreszenen. Mit dem Bild "Tote Pfauen" ist nur ein Stillleben bekannt. Viele der Zeichnungen fertigte Rembrandt ausschließlich zu Studienzwecken für seine Schüler an. In einigen hielt er auch kleine Begebenheiten aus seinem Privatleben und andere Eindrücke fest.

Rembrandt versah seine ersten Bilder mit dem Monogramm "RH", später mit "RHL", wobei das "L" für die Stadt Leiden steht. Im Alter von 26 Jahren begann er, seine Werke mit "Rembrant" zu signieren. Erst ab Anfang 1633 signierte er mit "Rembrandt", der heute verbreiteten Schreibweise seines Namens.

Viele Gemälde Rembrandts lassen sich der Gattung der Historienmalerei zuordnen. Sie zeigen Szenen aus dem Alten und Neuen Testament, Mythen oder Porträts historischer Persönlichkeiten. Dabei entwickelte Rembrandt eine besonders verdichtete Darstellung der Handlung, so dass in der Abbildung eines bestimmten Augenblickes darüber hinausreichende erzählerische Zusammenhänge zum Ausdruck kommen. Der Fokus auf die Historie war auch eine Folge seiner Ausbildung bei dem berühmten Historienmaler Pieter Lastman, an dessen Themen und Kompositionen Rembrandt sich zunächst orientierte. Ein Beispiel dafür ist das Gemälde "Steinigung des Heiligen Stephanus" aus dem Jahr 1625, das zu den frühesten Werken Rembrandts zählt. Lange Zeit galt es als Gemälde Lastmans, dessen Werk es stilistisch stark ähnelt. Rembrandt verwendete die Komposition eines verschollenen Lastman-Gemäldes mit demselben Thema, nutzte aber bereits den für ihn typischen Einsatz von Licht und Schatten. Die Pharisäer und Ältesten im Bildhintergrund sind als treibende Kräfte hinter der Hinrichtung hell beleuchtet, die ausführenden Personen im Vordergrund verschattet. Dieses Mittel sollte er immer wieder zur Betonung von Personen und Handlungen einsetzen.

Zwischen 1632 und 1646 fertigte Rembrandt einen sieben Gemälde umfassenden Zyklus von Bildern aus der Kindheitsgeschichte Jesu und der Passion. Der Auftrag wurde vom Statthalter Friedrich Heinrich auf Vermittlung von Constantijn Huygens erteilt und umfasste ursprünglich die fünf Bilder "Kreuzabnahme", "Kreuzaufrichtung", "Himmelfahrt", "Grablegung" und "Auferstehung", weshalb sich die Bezeichnung als "Passionszyklus" in der Fachliteratur etabliert hat. Die beiden Gemälde "Anbetung der Hirten" und "Beschneidung im Tempel", das heute nur über eine Kopie bekannt ist, malte Rembrandt erst später als Ergänzung dieses Zyklus. Rembrandt lieferte die Bilder in großen Abständen und teils mit Verspätung, weshalb er Huygens mit anderen Bildern zu bestechen versuchte und in diesem Zusammenhang "Die Blendung Simsons" anfertigte. Der zeitliche Rahmen der Arbeit bedingte auch Unterschiede in den Maßen der Bilder, den Farben, der Größe der Figuren und dem Malstil insgesamt, so dass die Bilderserie keine homogene Arbeit ist. Beim Malen der "Kreuzabnahme" setzte Rembrandt sich mit einer Komposition von Peter Paul Rubens auseinander, die ihm über einen Stich bekannt war. Rubens hatte den Leichnam Christi bildparallel dargestellt und alle Helfer um diesen herum angeordnet. Diesen Aufbau veränderte Rembrandt grundlegend. Das Kreuz ist schräg gestellt und die Personen sind in Gruppen aufgeteilt, die entweder um Jesus trauern oder bei dessen Abnahme vom Kreuz helfen. Rechts des Leichnams stellte Rembrandt Nikodemus dar, wie es in vergleichbaren Historiengemälden üblich war, links von ihm zeigte er Maria, die von zwei Frauen gestützt wird. Ihre Anwesenheit geht nicht auf die Bibel zurück, sondern greift eine im Mittelalter entstandene Legende auf. Rembrandt legte bei der Darstellung den Schwerpunkt auf das Leiden des Gekreuzigten. So sind an den Balken des Kreuzes noch die blutigen Spuren der Dornenkrönung, der Annagelung und der Seitenwunde zu sehen. Der Kontrast zwischen Hell und Dunkel betont das Kreuz und den Leichnam sowie die Hände und Gesichter der Trauernden.

Das 205 Zentimeter hohe und 272 Zentimeter breite Gemälde "Die Blendung Simsons" gehört zu den bedeutendsten Bildern Rembrandts. Es zeigt eine Episode aus der Geschichte des Richters Simson, die Rembrandt in mehreren Bildern behandelte. Simson war ein Nasiräer, was ihm besondere Stärke verlieh, wenn er sich an drei Bedingungen, wie etwa das Verbot sich Bart und Haare zu schneiden, hielt. Die hier dargestellte Szene schließt sich an das Schneiden des Haares durch Delila an, die ihn an die Philister verriet. Dieser Aspekt der Handlung ist auch in diesem Gemälde aufgegriffen, da Delila im Hintergrund abgebildet ist, wie sie mit dem Haarschopf und der Schere in der Hand flieht. Auch mit den weiteren Personen stellte Rembrandt verschiedene Aspekte der Handlung dar. So musste Simson, nachdem ihm die Haare abgeschnitten worden waren, zu Boden gerungen und gefesselt werden, bevor ihm die Augen ausgestochen wurden. Dies vermittelte Rembrandt über die Kämpfer, von denen einer furchtsam den Schauplatz betritt, ein anderer Simson am Boden hält, einer ihn fesselt und einer die Augen aussticht. Dabei ist die unmittelbare Handlung des Gemäldes der Höhepunkt der Geschichte, das Blenden mit dem eindringenden Messer, wobei das Blut aufspritzt. Der Betrachter kann aber über das Bild die gesamte Handlung rekonstruieren.

Neben dem Streben, möglichst viel Handlung, auch über den dargestellten Moment hinaus, in seinen Bildern zu vermitteln und die Handlung auf ihrem Gipfelpunkt, wie etwa bei der "Blendung Simsons", abzubilden, nahm Rembrandt auch äußere Einflüsse aus seiner näheren Umgebung in seine Historien auf. Dies wird am Beispiel der Judendarstellung besonders deutlich. So verwendete Rembrandt über lange Zeit den Juden zugeordnete körperliche Merkmale nur bei Darstellungen in negativen Zusammenhängen, wie etwa bei den Hohenpriestern, und verstärkte diese traditionell dargestellten Gesichtszüge noch. Nach seinem konkursbedingten Umzug studierte er erstmals direkt an jüdischen Modellen. Eine dieser Studien ist das Gemälde "Ein Christus nach dem Leben", in dem er den Sohn Gottes, dessen Aussehen sonst dem niederländischer Modelle angeglichen wurde, mit jüdischen Gesichtszügen gestaltete.

1653 malte Rembrandt im Auftrag des sizilianischen Aristokraten Ruffo die historische Halbfigur "Aristoteles", ein Bild, das zu den bedeutenden Spätwerken Rembrandts zählt. Es folgten später noch zwei weitere Bilder auf Bestellung Ruffos, die Alexander den Großen und Homer zeigen. Ruffo war mit dem Porträt von Aristoteles sehr zufrieden und erwähnte es lobend in einem Brief an den Maler Giovanni Francesco Barbieri, der ein Pendant dazu anfertigen sollte, weil Rembrandt die beiden weiteren bestellten Bilder erst mit großer Verzögerung zu Beginn der 1660er-Jahre lieferte. Auch das Bildnis Alexander des Großen wurde von Ruffo positiv aufgenommen, der aber nach einiger Zeit bemerkte, dass die Leinwand an drei Seiten vergrößert worden war und sich daraufhin beschwerte. Den "Homer" empfand Ruffo als unvollendet, weshalb er ihn zurückschickte und von Rembrandt Nachbearbeitungen forderte. Die Themen der Bilder scheint Rembrandt selbst gewählt zu haben, da er die beiden folgenden bereits im "Aristoteles"-Porträt angelegt hat. Der Philosoph ist in einem Moment des Sinnierens dargestellt. Seine rechte Hand hat er auf eine Büste gelegt, die Homer darstellt. Mit der linken Hand berührt er auf Hüfthöhe eine goldene Ehrenkette mit einem Bildnis Alexander des Großen. Darin kommt auch Rembrandts Kenntnis der historischen Zusammenhänge zum Ausdruck. Aristoteles war ein Kenner der Werke Homers und vermittelte sie seinem Schüler Alexander dem Großen.

Im Anschluss an seinen Umzug nach Amsterdam begann Rembrandt bei seiner Arbeit im Atelier Uylenburghs verstärkt Porträts zu malen und eroberte mit ihnen rasch den Markt für dieses Genre. Der Erfolg basierte auf Erfahrungen aus der Historienmalerei, mit denen Rembrandt die etablierten Bildnismaler überflügelte. Er band die Porträtierten in kleine Handlungen ein, wie etwa die Übergabe eines Briefes durch die Frau an ihren Mann in einem Doppelporträt, was den Bildern Lebendigkeit verleiht. Zudem gelang es Rembrandt, die menschliche Haut besonders realistisch wiederzugeben. Im Vergleich mit anderen Porträtmalern nahm sich Rembrandt mehr Freiheiten heraus, so dass seine Bilder im Vergleich mit anderen Porträts derselben Person geringere Übereinstimmungen der körperlichen Merkmale aufweisen. Der Zweizeiler „Das ist Rembrandts Hand, und das Gesicht von de Gheyn. Staune. Leser, das ist de Gheyn und ist es nicht.“ des Dichters Constantijn Huygens über das Porträt seines Freundes Jakob de Gheyn der Jüngere wird als Kritik an der Darstellung de Gheyns durch Rembrandt oder aber als Sinnieren darüber, dass ein Porträt nicht der Dargestellte selbst, sondern nur ein Abbild von ihm ist, gedeutet.

Das erste von Rembrandt gemalte Gruppenporträt, das seinen Durchbruch als Porträtmaler markierte, ist das 169,5 Zentimeter hohe und 216,5 Zentimeter breite Bild "Die Anatomie des Dr. Tulp", das 1632 kurz nach seinem Umzug nach Amsterdam im Auftrag des Prälektors der Chirurgengilde, Nicolaes Tulp, entstand. Es zeigt eine öffentliche anatomische Vorlesung, die zu dieser Zeit alltäglich und populär war. Rembrandt bildete nicht die Porträtierten in einer Reihe ab, wie es Tradition war, sondern stellte sie um den Leichnam versammelt dar. Dessen Sehne am linken Unterarm ist freigelegt und wird vom Chirurgen mit der Zange angehoben, während er seinen Vortrag hält. Mit Ausnahme Tulps, der auf einem Sessel sitzt, stehen alle Figuren, die als Mitglieder der Gilde zu identifizieren sind, und werden in Posen abgebildet, die für das Verfolgen eines Vortrages typisch sind. So zeigt Rembrandt den konzentrierten Blick auf den Redner ebenso wie einen prüfenden in das Lehrbuch in der rechten unteren Bildecke oder das sachkundige Mustern des Präparates. Somit sind alle Figuren in einem gemeinsamen Geschehen vereinigt. Die einzelnen Gesichtszüge sind deutlicher herausgearbeitet, als es die Situation verlangt, was auf den heutigen Betrachter wie eine übertriebene Pose wirkt. Diese Übertreibung legte Rembrandt jedoch mit der Zeit ab.

Ein Beispiel der zu Beginn der Amsterdamer Zeit entstandenen Einzelporträts ist das 130 Zentimeter hohe und 103 Zentimeter breite "Porträt des Predigers Johannes Wtenbogaert", das 1633 von Rembrandt im Auftrag der remonstrantischen Gemeinde gemalt wurde. Es zeigt den Pfarrer Johannes Wtenbogaert, der für kurze Zeit aus seiner Verbannung in die Niederlande zurückgekehrt war. Er hat für den 13. April 1633 in seinem Tagebuch vermerkt, dass er den ganzen Tag für Rembrandt Modell saß. Teile des Bildes, wie die Hände, stammen nicht von Rembrandt selbst, sondern wurden von einem Ateliermitarbeiter gemalt. Diese Praxis kam bei einigen Porträts Rembrandts vor, da es nicht ungewöhnlich war, dass in Porträtwerkstätten verschiedene Maler an einem Bild arbeiteten.

Eines der berühmtesten Gemälde Rembrandts ist das Gruppenporträt "Die Nachtwache", das 1642 gemalt wurde. Das 363 Zentimeter hohe und 437 Zentimeter breite Bild wurde von der Gilde der Büchsenschützen in Auftrag gegeben, die ein neues Schützenhaus bezog und zum Schmuck des Festsaals mehrere Gruppenporträts bestellte. Rembrandt erfüllte diesen Auftrag wie schon bei der "Anatomie des Dr. Tulp", indem er die Porträtierten in eine Handlung einband. Der Kapitän Frans Banning Cocq erteilt den Marschbefehl an Leutnant Willem van Ruytenburgh, der diesen nun weitergibt. Kapitän und Leutnant stehen als Ausgangspunkt der Bildhandlung mittig im Vordergrund. Einzelne Mitglieder der Kompanie haben den Befehl bemerkt und machen sich marschbereit. Die Tätigkeit der Gilde wird von drei Schützen symbolisiert, die verschiedene Phasen des Schusses zeigen. Im linken Vordergrund stopft einer die Büchse, hinter dem Leutnant ist das Mündungsfeuer eines feuernden Schützen zu sehen und rechts vom Leutnant pustet ein alter Mann abgebranntes Pulver von der Zündpfanne. In der linken Bildhälfte stellte Rembrandt zwei kleine Mädchen dar, die als Marketenderinnen auftreten und von denen nur die vordere als Allegorie zu erkennen ist. Sie trägt am Gürtel ein Huhn, dessen Kralle das Symbol der Büchsenschützengilde war, das Trinkhorn der Gilde und eine Pastete. So weist das Bild auf die Feier der Gildengemeinschaft mit einer gemeinsamen Mahlzeit hin. Rembrandt erweckt mit der Andeutung weiterer Figuren im Hintergrund den Anschein, dass die ganze Kompanie anwesend ist, zu der nicht nur Schützen, sondern auch Spieß- und Lanzenträger gehörten. Das Gemälde zeigt einen gewöhnlichen Aufmarsch der Gilde, weshalb über lange Zeit Titel wie "Kapitän Frans Banningh Cocq gibt seinem Leutnant den Befehl zum Aufmarsch der Bürgerkompanie" verbreitet waren. Erst als die Firnisschichten nachgedunkelt waren und das Bild deshalb wie eine nächtliche Szene erschien, bürgerte sich gegen Ende des 18. Jahrhunderts der Titel "Die Nachtwache" ein. Um das Bild ranken sich verschiedene Gerüchte und Anekdoten wie etwa, dass die Dargestellten Mitglieder einer Theatergruppe seien, oder dass sich Rembrandts Ruf als Porträtmaler durch die ungewöhnliche Komposition des Bildes verschlechtert hätte. Diese Spekulationen werden von der Forschung abgelehnt.

Das 99,5 Zentimeter hohe und 83 Zentimeter breite "Porträt einer Dame mit Straußenfeder" ist ein Beispiel für Rembrandts Frauenporträts und seine Porträts im letzten Jahrzehnt seines Lebens. Ab Beginn der 1660er-Jahre erlebte Rembrandt nach einer längeren Phase mit wenigen Porträtaufträgen einen Anstieg der Zahl dieser Aufträge. Diese Arbeiten sind alle von einem starken Hell-Dunkel und einer ruhigen Haltung der Dargestellten geprägt. Das Porträt der unbekannten Frau, die eine Pfauenfeder in der Hand hält, wird durch zwei helle Dreiecke geprägt. Das obere umfasst den Kopf und die Schulterpartie, das untere die Unterarme, Hände und die Feder. Beide werden von einem schwarzen Bereich der Kleidung getrennt. Diese hebt sich nur leicht vom ebenfalls dunklen Hintergrund ab.

Zeit seines Lebens fertigte Rembrandt Porträts an, die ihn selbst mit verschiedenen Gesten und unterschiedlichem Gesichtsausdruck sowie in verschiedenen Rollen zeigen. Er stellte sich „annähernd fünfzigmal in Farbe, zwanzigmal in Radierungen und ungefähr zehnmal in Zeichnungen“ selbst dar.

Das Studium an sich selbst nahm Rembrandt vor allem zu Beginn seiner Laufbahn vor, als er Radierungen anfertigte, die ihn in verschiedenen emotionalen Zuständen mit den dazugehörigen Haltungen und der entsprechenden Körpersprache darstellen. Im Spätwerk fertigte er stattdessen vermehrt Bildnisse an, die sein Alter zum Thema haben oder in denen er historische Rollen annimmt.

Das 102 Zentimeter hohe und 80 Zentimeter breite "Selbstporträt" aus dem Jahr 1640 zeigt Rembrandt vor einem hellen, neutralen Hintergrund, so dass die Figur besonders betont ist. Er trägt Kleidung aus Seide und Brokatstoff. Der Mantel ist mit einem Pelzkragen besetzt. Über dem auf einer Barriere aufgestützten Arm liegt eine schwere und kostbare Stola. Als Kopfbedeckung trägt Rembrandt ein Barett. Das Gesicht ist im Halbprofil mit einem melancholischen Ausdruck gemalt. Der Blick ist auf den Betrachter des Bildes gerichtet. In der rechten unteren Bildecke auf der Barriere ist die Signatur "Rembrandt f. 1640" sichtbar. Mit der perfekten Malweise und der Darstellung des Porträtierten ähnelt dieses Bild Werken von Raffael oder Tizian.

Rembrandts Alterung ist in seinen Porträts nachvollziehbar. So zeigen die Bilder ihn mit schütterem Haar und stärker werdenden Falten. Er porträtierte sich jedoch nicht nur, sondern stellte sich zum Teil auch in einen größeren erzählerischen Zusammenhang, indem er historische Rollen einnahm. Ein Beispiel hierfür ist das "Selbstporträt als Apostel Paulus" aus dem Jahr 1661. Es zeigt den dunkel gekleideten Rembrandt vor einem überwiegend dunklen Hintergrund. Nur die linke obere Bildecke, in der auch die Signatur angebracht ist, ist heller. Der weiße Turban, den er als Kopfbedeckung trägt, ist der hellste Abschnitt des Bildes. In der Hand hält Rembrandt eine Ausgabe des Alten Testaments; die dargestellten Buchstaben sind der hebräischen Schrift nachempfunden. Das Schwert als typisches Attribut des Apostels Paulus von Tarsus, der mit einem solchen hingerichtet wurde, ist mit seinem Knauf nur angedeutet. Ein weiteres Gemälde aus dieser Schaffensphase ist das "Selbstbildnis als Zeuxis" um 1663/64, das lange Zeit als Darstellung des Demokrit galt. Demokrit galt in der Antike als der "lachende Philosoph", aufgrund seiner Lehre von der Wohlgemutheit als höchstem Gut. Mit der Interpretation als Demokrit war auch die Deutung verbunden, dass Rembrandt sein Altern positiv betrachtete. Nach aktuellem Stand der Forschung stellt dieses Bild jedoch Zeuxis von Herakleia dar, der beim Malen eines Porträts einer hässlichen Frau an einem Lachanfall starb. Damit könnte das Bild auch die Erkenntnis Rembrandts über seine eigene Überheblichkeit und Sterblichkeit symbolisieren. Diese Interpretation gilt jedoch ebenfalls nicht als sicher. So wird angeführt, dass bei Röntgenuntersuchungen festgestellt wurde, dass Rembrandt in einer früheren Version des Bildes nur lächelte und nicht lachte.

Die Insolvenz-Inventarliste Rembrandts von 1656 führt zwölf Landschaftsgemälde von seiner Hand auf, von denen sich nach heutigem Wissensstand acht erhalten haben. Daneben werden ihm 32 Radierungen und zahlreiche Zeichnungen mit Landschaftsdarstellungen zugeschrieben. Landschaftsgemälde standen zu Lebzeiten Rembrandts in der traditionellen Hierarchie der Gattungen unter der Porträt- und Historienmalerei und waren dementsprechend preiswerter. Rembrandt selbst wird sich als Historienmaler gesehen haben. Landschaften zeichnete er bei Wanderungen in der Umgebung Amsterdams eher zu seinem persönlichen Vergnügen. Dies erklärt, warum er nur wenige Landschaftsgemälde schuf, die sich darüber hinaus deutlich von denen seiner Zeitgenossen unterscheiden.

Im Zeitraum zwischen 1636 und 1655 malte Rembrandt einige Landschaftsgemälde, was nicht notwendigerweise bedeutet, dass diese Bilder keine Figuren enthalten. Der Großteil von ihnen zeigt Phantasielandschaften, nur eine Minderheit ist von Rembrandt realistisch gemalt worden. Im Unterschied zu seinen Zeichnungen und Radierungen, die meist weite, offene und realistisch gehaltene Landschaften zeigen, wirken die Gemälde überwiegend bewegungslos und beengt. Im Gegensatz zu den Historien und Porträts unterschieden sich die Landschaftsgemälde Rembrandts stark von den traditionellen Gemälden dieser Gattung. Sie hatten begrenzten Einfluss auf nachfolgende Künstler im England um das Jahr 1800. Während viele italienische und den Italienern nacheifernde Künstler Landschaften der römischen oder griechischen Antike wählten, malte Rembrandt oftmals solche, die eher dem israelischen Raum zugeordnet werden können. Wie die Maler idealisierter Landschaften stellte Rembrandt in seinen Gemälden nicht die Realität dar. Er ging jedoch noch weiter, indem er auch auf die Basis des Studiums der Natur für das Malen des Bildes verzichtete.

Ein Beispiel für die fantastischen Landschaften ist das Gemälde "Landschaft mit Gebäuden", das Rembrandt zwischen 1642 und 1646 schuf. Es ist die am meisten klassische Landschaftskomposition unter seinen Werken und orientierte sich vermutlich an der 1604 entstandenen "Landschaft mit der Flucht nach Ägypten" von Annibale Carracci, einem Gemälde, das Rembrandt als Kopie bekannt gewesen sein dürfte. In beiden Bildern dominiert eine Gruppe von Gebäuden den Horizont. Ein Teil von ihnen wird von der Sonne beleuchtet, der andere liegt im Schatten. Die Gebäude gliedern sich farblich und kompositorisch so in die Landschaft ein, dass sie wie natürlich zu ihr gehörend erscheinen. Im Vordergrund ist ein Fluss zu sehen, über den eine Brücke führt. Es ist möglich, dass Rembrandt das Gemälde nicht vollendete und deshalb keine Figuren in das Bild integriert sind.

Eine der realistischen Landschaften ist die 17 × 23 Zentimeter große "Winterlandschaft" aus dem Jahr 1646. Das kleine Format und die Ausführung lassen vermuten, dass sie auf einer Zeichnung basiert. Die Darstellung des Wetters und der Wolken ist der Realität nachempfunden. Der Vordergrund des Bildes ist relativ leer. In seiner linken Ecke sitzt ein Mann, in seiner rechten Hälfte befinden sich drei weitere Figuren. In der Ausführung ist diese Landschaft nicht so repräsentativ und prunkvoll wie viele andere Winterlandschaften, die im 17. Jahrhundert in den Niederlanden entstanden.

Von den zahlreichen Zeichnungen, die Rembrandt im Laufe seines Lebens anfertigte, sind heute etwa 1000 erhalten. Er verkaufte nur wenige dieser Zeichnungen, der Großteil diente Studienzwecken. Es handelte sich um Skizzen, Vorzeichnungen, Nachzeichnungen und Erinnerungsstützen, die seinen Schülern in der Werkstatt nach Themen geordnet zugänglich waren. Einige Zeichnungen legen Zeugnis davon ab, dass Rembrandt sich mit bestimmten Problemen stärker befasste. So widmete er sich in der zweiten Hälfte der 1630er-Jahre der Symmetrie und Asymmetrie im von Leonardo da Vinci angefertigten Werk "Das letzte Abendmahl". Dieses war Rembrandt über einen Stich bekannt und veranlasste ihn, in verschiedenen Zeichnungen den Aufbau dieses Bildes zu studieren. Seine so gewonnenen Erkenntnisse übertrug Rembrandt in das Gemälde "Simson an der Hochzeittafel, das Rätsel aufgebend", das sich in der Komposition an das Abendmahl anlehnt.

Im Laufe der Zeit befasste sich Rembrandt immer wieder mit der Darstellung bestimmter Themen, wie etwa der Geschichte von Susanna im Bade. Ein Beispiel der Umsetzung dieser biblischen Erzählung ist die mit roter Kreide angefertigte Zeichnung "Susanna im Bade", die um 1637 entstand. Sie orientiert sich kompositorisch an einem Historiengemälde von Pieter Lastman, bei dem Rembrandt studiert hatte. Susanna wird nach der biblischen Erzählung von zwei alten Richtern bedrängt und vor die Wahl gestellt, ihnen zu Willen zu sein oder verleumdet zu werden. Rembrandt übernahm die große Anlage des Bildes, die Gruppierung der Figuren und wesentliche Bildelemente Lastmans in seine Kreidezeichnung. Der Hauptunterschied zum Original liegt in der weiteren Ausgestaltung der Szene, wobei Rembrandt den Dialogcharakter betont. Über die Körpersprache der beiden Alten transportiert er die Alternativen der Susanna: Der linke weist mit dem Daumen auf das Schloss als Drohung mit der Verleumdung und Anklage, der rechte lockt Susanna mit seinem Finger. Letzterer wird von Susanna mit einem abweisenden Blick bedacht, womit ihre Ablehnung des Ansinnens dargestellt wird.

Die neuere Rembrandt-Forschung sieht in einem Großteil der Zeichnungen seines Spätwerks nicht mehr primär den ursprünglich vermuteten "Vorzeichnungscharakter" - sie gelten inzwischen als autonome Kunstwerke. Eine der bevorzugten Techniken Rembrandts wurde die Rohrfeder, häufig auch in Bister laviert.

Rembrandt schuf etwa 300 Radierungen, von denen 80 Kupferplatten erhalten geblieben sind. Ihre Verbreitung über Reproduktionen trug zum Ruhm des Künstlers in ganz Europa bereits zu Lebzeiten bei. Die frühen Radierungen Rembrandts weisen deutliche Stilunterschiede zu seinen Zeitgenossen auf und legen nahe, dass er sich dieser Kunstgattung als Autodidakt näherte. Rembrandts Technik war freier als die anderer Künstler, die sich mit regelmäßigen Linien und Schraffierungen dem Kupferstich annäherten, so dass seine Radierungen lebendiger erscheinen. Mit dem Spiel von Hell und Dunkel und der über unterschiedliche Schraffuren erzeugten Perspektive verlieh er ihnen einen malerischen Charakter.

"Die Landschaft mit den drei Bäumen" aus dem Jahr 1643 gehört zu den ersten realistischen Landschaftsdarstellungen Rembrandts, nachdem er in seinen früheren Gemälden heroische Landschaften mit Obelisken, Wasserfällen und Burgen kreierte. Nun konzentrierte er sich auf die Weite der Landschaft und die Darstellung der Wolken. Die Radierung "Die Landschaft mit den drei Bäumen" zeigt die für die Niederlande typische flache Landschaft nach einem Gewitter.

Die 38,5 Zentimeter breite und 45 Zentimeter hohe Radierung "Die drei Kreuze" aus dem Jahr 1653 zeigt eine Interpretation der Kalvarienszene, eines traditionellen Themas von Bildern, dem sich Rembrandt von einem neuen Standpunkt aus näherte. Er fokussierte auf die Reaktionen der Anwesenden auf Jesu Tod und das nachfolgende Erdbeben sowie die drei Kreuze. Aus dem Himmel brechen Lichtstrahlen hervor, die in ihrer geometrischen Struktur den sakralen Charakter der Radierung herausstellen. Sie beleuchten Jesus und den guten Schächer, während der zweite Räuber im Dunkeln bleibt. Die Wirkung auf die anwesenden Personen stellte Rembrandt auf verschiedene Weise dar. So ist beispielsweise der Hauptmann auf die Knie gefallen, während am linken Bildrand im Vordergrund ein überwältigter Mann weggeführt wird. Die Gestaltung dieses Mannes wurde von Rembrandt einem Stich von Lucas van Leyden entlehnt, der die Erschütterung des Paulus nach seiner Bekehrung zeigt. Weiterhin sind Frauen zu Boden gestürzt, und die meisten der dargestellten Figuren zeigen auf irgendeine Art und Weise Gefühle von Verzweiflung, Angst und Schmerz. Darin rezipierte Rembrandt vor allem Darstellungen aus der Renaissance und der Antike.

Rembrandt begann wahrscheinlich schon in Leiden mit dem Aufbau seiner umfassenden Sammlung verschiedener Objekte und Kunstwerke. Ab 1628 finden sich präzise wiedergegebene exotische und ethnologische Gegenstände in den Werken Rembrandts, die nahelegen, dass die Sammlung auch Studienzwecken diente und Atelierrequisiten beinhaltete. Es könnte sich aber auch um einen Vorrat von wertvollen Gegenständen gehandelt haben, die zum Verkauf bestimmt waren, da Rembrandt sich auch als Kunsthändler betätigte. Mit dem enzyklopädischen Anspruch der Sammlung wollte sich Rembrandt möglicherweise auch in den höheren Kreisen der Gesellschaft profilieren.

Die Sammlung teilte sich in zwei Bereiche auf, zum einen in die "Naturalia" wie Steinkorallen und Muscheln, zum anderen in die "Artificialia", die Gegenstände wie Münzen, Waffen, Musikinstrumente und Gipsabgüsse von Büsten griechischer Philosophen und römischer Kaiser umfassten. Rembrandt teilte die Kollektion von Kunstwerken in Gemälde, Papierkunst, Kupferstiche und Holzschnitte ein. Sie umfasste unter anderem Gemälde von Meistern, die ihn stark beeinflussten, wie Pieter Lastman und dessen Umkreis, von Hercules Seghers und von befreundeten oder stilistisch nahestehenden Künstlern wie Jan Lievens. Daneben besaß Rembrandt Werke von Palma Vecchio, Lucas van Leyden, Raffael und Peter Paul Rubens. Die Kupferstiche stammten zum Beispiel von Hans Holbein dem Jüngeren und Martin Schongauer. Ein ganzes Album war mit Stichen und Holzschnitten von Lucas Cranach dem Älteren gefüllt. Weiterhin waren Tizian, Mantegna, Michelangelo, Annibale und Agostino Carracci in der Sammlung vertreten.

Infolge seines Konkurses musste sich Rembrandt auch von seiner Sammlung trennen. Aufgrund der vor der Versteigerung erstellten Inventare sind heute noch der Umfang der Sammlung und die darin enthaltenen Werke und Objekte bekannt. Bereits kurze Zeit später, als er in eine kleine Wohnung gezogen war, erwarb er eine neue Sammlung. Dies legt den Schluss nahe, dass das Sammeln für Rembrandt eine Art von Obsession war. Das Museum Het Rembrandthuis in Amsterdam präsentiert eine Rekonstruktion der Sammlung um 1650. Dabei orientierte es sich an den Inventaren, welche die Exponate auch räumlich zuordneten.

Zwischen 1628 und 1663 bildete Rembrandt Schüler in seiner Werkstatt aus. In Leiden befand sich sein Atelier im Haus seiner Eltern, so dass zwischen Wohnung und Arbeitsplatz keine Trennung bestand. Als ersten Schüler nahm er dort im Februar 1628 Gerard Dou auf, der mit seinen Genrebildern und Porträts später Berühmtheit erlangen sollte. Im November desselben Jahres folgte Isaac Jouderville. In Amsterdam arbeitete Rembrandt erst in der Werkstatt des Kunsthändlers Hendrick van Uylenburgh, bis er 1634 in die Lukasgilde eintrat und damit das Recht erhielt, eine eigene Werkstatt zu führen und Schüler aufzunehmen. In seinem Haus richtete er sich im ersten Stock sein Atelier ein und im zweiten Obergeschoss, unter dem Dach, die Werkstatt, in der seine Schüler arbeiteten. Für die Schüler waren kleine Arbeitsräume durch bewegliche Trennwände abgeteilt. Ihnen waren Zeichnungen, Stiche und Gemälde ihres Meisters zugänglich, die sie kopierten oder in freien Varianten wiedergaben. Diese Arbeiten veräußerte Rembrandt, was die 100 Gulden, die von den Eltern für ein Jahr gezahlt wurden, aufbesserte. Das Lehrgeld war in Anbetracht dessen, dass Rembrandt den Schülern weder Wohnraum noch Verpflegung bot, sehr hoch. Einige Schüler blieben nach dem Ende ihrer Lehrzeit als Assistenten in Rembrandts Werkstatt.

Die genaue Zahl der Schüler ist nicht bekannt. Frühe Biographen Rembrandts haben die Namen von rund 20 von ihnen überliefert. Die Aufzeichnungen über Rembrandts Schüler bei den Gilden von Leiden und Amsterdam gingen verloren. So wird ihre Zahl heute auf rund 50 geschätzt. Vom deutschen Künstler Joachim von Sandrart, der von 1637 bis 1645 in Amsterdam gelebt hat, wurde überliefert, dass bei Rembrandt „unzählige“ junge Männer studierten und arbeiteten. Diese Aussage legt eine höhere Schülerzahl nahe. Zu den Schülern gehörten unter anderem Carel Fabritius, Ferdinand Bol, Willem Drost, Gerbrand van den Eeckhout, Govert Flinck, Arent de Gelder, Samuel van Hoogstraten, Nicolaes Maes, Jürgen Ovens, Lambert Doomer und Franz Wulfhagen.

Rembrandt erlangte schon früh überregionale Bekanntheit und Ruhm. So notierte der englische Reisende Peter Mundy, der sich 1640 in den Niederlanden aufhielt, in seinem Tagebuch, dass es „in diesem Land zahlreiche hervorragende Künstler gab, einige gibt es noch, beispielsweise Rembrandt“. Ein Jahr später schrieb der frühe Rembrandt-Biograph und Stadthistoriker von Leiden Jan Janszoon Orlers über Rembrandt, „dass er zu einem der gegenwärtigen renommiertesten Maler unseres Jahrhunderts geworden ist“. Bereits 1629 und 1630 erwarb die englische Krone zwei seiner Bilder und über Stiche verbreitete sich die Kenntnis seiner Werke in großen Teilen Europas. Drei Bilder verkaufte Rembrandt an den Sizilianer Antonio Ruffo, der sie auf eine Liste der hundert schönsten Gemälde seiner Sammlung setzen ließ.

Nach dem Tod Rembrandts war die Sicht auf seine Werke gespalten. Die klassizistische Kunstauffassung dominierte zwischen 1750 und 1850 in Italien, Frankreich, den Niederlanden und England und stand im Gegensatz zum Kolorismus, dem Künstler wie Caravaggio und Rembrandt zuzurechnen sind. In der 1675 erschienen "Teutschen Akademie" warf der deutsche Maler Joachim von Sandrart Rembrandt vor, „die Regeln der Kunst – Anatomie, Proportion, Perspektive, die Norm der Antike und die Zeichenkunst Raffaels – nicht beachtet und die vernünftige Ausbildung in den Akademien bekämpft“ zu haben Sandrart bewertete Rembrandt zudem als ungebildet und tadelte dessen Kunstsammlung, die er zuvor in seiner Biographie noch gelobt hatte, so dass das Publikum sie nun für wertlos hielt. 1681 veröffentlichte Anries Pels das Lehrgedicht "Gebruik en Misbruik des Toneels" "(Gebrauch und Missbrauch des Theaters)", in dem er auch auf die Malerei einging und Rembrandt als „den ersten (namhaftesten) Ketzer in der Malerei“ bezeichnete, da er sich geweigert habe, seinen „berühmten Pinsel den Regeln zu unterstellen“. Der Kunstschriftsteller Arnold Houbraken ging in seinem Werk "Groote Schouburgh" aus dem Jahr 1718 noch weiter, indem er angebliche Zitate Rembrandts und unzutreffende biographische Informationen erfand sowie Legenden verbreitete. Zu diesem Zeitpunkt waren die Fakten über Rembrandts Leben zu großen Teilen in Vergessenheit geraten. Deshalb schloss man aus seinen Bildern auf einen niedrigen sozialen Stand und einen schlechten Charakter. Dies wurde auf seine künstlerische Auffassung übertragen. In dem rund 20 Seiten umfassenden Beitrag, an dem neben Houbraken mehrere Autoren beteiligt gewesen sein dürften, wurde Bezug auf viele der vorherigen Kritiker und Kritiken genommen. Der harschen Kritik steht die Tatsache entgegen, dass Rembrandts Kunstwerke bei Sammlern beliebt waren. Im Paris der zweiten Hälfte des 17. sowie des 18. Jahrhunderts, als die dort aktiven Künstler glatte Idealkompositionen schufen, gab es einen großen Markt für niederländische Realisten und vor allem Rembrandt. Aufgrund der gestiegenen Preise seiner Werke kamen zudem vermehrt Fälschungen auf den Kunstmarkt. Das bestehende Interesse veranlasste den französischen Kunsthändler Gersaint im Jahr 1751, einen ersten Katalog der Radierungen Rembrandts zu erstellen, was einer kunsthistorischen Pionierleistung gleichkam.

Auch in Deutschland und England fanden die Bilder Rembrandts Anklang und wurden sowohl vom Bürgertum als auch von Adeligen erworben. In England erzielten seine Werke so hohe Preise, dass der britische Kunsthändler John Smith 1836 den ersten Katalog der Gemälde erstellte. Die in ganz Europa in Sammlungen vertretenen Bilder von Rembrandt, seinen Schülern und Nachfolgern inspirierten im 18. Jahrhundert Rembrandt-Nachfolger. In Deutschland beschäftigte sich der Maler Januarius Zick mit den Kostümen der Figuren und der Helldunkel-Malerei in Rembrandts Gemälden, in England erwarb Joshua Reynolds Gemälde, die Rembrandt gemalt hatte, und orientierte sich an der Farbgebung, in Italien beschäftigte sich Giovanni Battista Tiepolo mit Kompositionen von Rembrandts Stichen, und die Dichter des Sturm und Drang, einer Strömung der deutschen Literatur in der Zeit von 1770 bis etwa 1785, lobten das Volkstümliche und Natürliche der Kunst Rembrandts.

Nach Errichtung von Denkmälern für Albrecht Dürer in Deutschland und Peter Paul Rubens in Belgien fand 1853 die Enthüllung eines Rembrandt-Denkmals in Amsterdam statt. Wenn dies auch vor allem aus patriotischen Motiven geschah, folgte doch als Ergebnis ein neues Interesse der Kunsthistoriker an Rembrandt. Erstmals wurde sein Leben gründlich erforscht, wobei Dokumente in Archiven gefunden wurden, die aufzeigten, dass die bisherigen Veröffentlichungen zahlreiche Fehlinformationen enthielten. 1854 erschien die erste kunstwissenschaftliche Monographie über Rembrandt, deren Autor Eduard Kolloff viele seiner Werke aus eigener Anschauung kannte. In diesen Entwicklungen liegt die Grundlage der eigentlichen Rembrandt-Forschung.

Bedeutende Kunsthistoriker wie Abraham Bredius und Wilhelm von Bode forschten zu Rembrandt und seinem Umfeld. Jan Emmens korrigierte das Bild von Rembrandt als Brecher der Regeln der Kunst seiner Zeit, zu dem ihn vor allem die klassizistische Kunstliteratur gemacht hatte, zeigte historische Bezüge auf und ging auf Rembrandts Atelierarbeit und dessen künstlerische Vorbilder ein. Christian Tümpel setzte sich mit fehlgedeuteten und noch gar nicht gedeuteten Historiendarstellungen Rembrandts auseinander und das Rembrandt Research Project arbeitete an der Klärung der Urheberschaft seiner Gemälde und der seines Umkreises.

Der Erfolg Rembrandts am Kunstmarkt ist ungebrochen. So konnten Werke von ihm in den letzten Jahren hohe Auktionsergebnisse erzielen. Am 13. Dezember 2000 wurde das 1632 gemalte Porträt "Ältere Dame mit einer Haube" bei Christie’s in London (Los-Nr.: 52) für 19.803.750 Pfund, umgerechnet 28.675.830 Dollar, versteigert. Das 1633 entstandene Porträt "Ein Herr im roten Rock" aus der Sammlung der Bellagio Gallery of Fine Art in Las Vegas wurde am 26. Januar 2001 bei Christie’s in New York (Los-Nr.: 81) aufgerufen und für 12.656.000 Dollar vom Kunsthändler Noortmann erworben. Am 25. Januar 2007 wurden bei Sotheby’s in New York gleich zwei Bilder angeboten, von denen das Porträt "Eine Frau mit schwarzer Kappe" (Los-Nr.: 6) von 1632 für 9.000.000 Dollar und "Der Apostel Jakobus" (Los-Nr.: 74) aus dem Jahr 1661 für 25.800.000 Dollar versteigert wurden. Das am 8. Dezember 2009 bei Christie’s in London versteigerte Porträt "Ein Mann mit den Armen in der Hüfte" (Los-Nr.: 12) von 1658, das aus dem Besitz von Barbara Piasecka Johnson stammte, erzielte mit 20.201.250 Pfund, oder 33.210.855 Dollar den bisher höchsten jemals für ein Werk Rembrandts erzielten Preis.

Die Bestimmung der Eigenhändigkeit von Werken Rembrandts fiel bereits seinen Zeitgenossen schwer, da sie von denen anderer Künstler wie Govert Flinck, Jan Lievens oder Aert de Gelder zum Teil nur schwer zu unterscheiden sind. Zudem wurden in der Werkstatt Kopien und Varianten angefertigt, so dass zum Beispiel zehn Versionen des "Reuigen Judas" bekannt sind, die nicht eindeutig einem bestimmten Künstler zugeordnet werden können. Zum Teil können Archivalien, literarische Erwähnungen oder Reproduktionsstiche zur Bestimmung des Urhebers herangezogen werden, was aber nicht besonders zuverlässig ist. Hinzu kommen naturwissenschaftliche Untersuchungen der Werke und die Kennerschaft über spezifische Qualitäts- und Stileigenschaften des Künstlers, nach denen Übereinstimmungen und Abweichungen im Vergleich mit nicht dokumentierten Werken festgestellt werden können. Sie unterliegen jedoch subjektiven Gesichtspunkten.

Zu Beginn des 20. Jahrhunderts war eine optimistische Zuschreibungspraxis verbreitet, die stilistische Merkmale für die Bewertung eines Gemäldes als eigenhändiges Werk Rembrandts weit fasste. Seit 1968 nimmt eine im Rembrandt Research Project zusammengefasste Expertengruppe die Bewertung der Bilder, die Rembrandt zugeschrieben werden, vor. Sie teilten die Werke in drei Kategorien ein: Kategorie A umfasst Gemälde, deren Urheberschaft Rembrandts gesichert ist, Kategorie B solche, deren Urheberschaft Rembrandts nicht als sicher angesehen, aber auch nicht abgesprochen werden kann, und Kategorie C beinhaltet Werke, deren Urheberschaft Rembrandts nicht bestätigt werden kann und die seinem Umkreis zugeordnet werden. Dabei ist die Zuordnung einiger Werke in die jeweilige Kategorie nicht unumstritten gewesen. So wurde 1982 von den drei auf vergoldete Kupferplatten gemalten Bildern "Lachender Soldat" aus dem Mauritshuis, "Betende alte Frau" der Residenzgalerie und ein "Selbstbildnis" aus dem Schwedischen Nationalmuseum, die alle ein ähnliches kleines Format aufweisen, mit der "Betenden alten Frau" nur das am genauesten gemalte Bild als authentisch erklärt. Im Katalog der Ausstellung "Der junge Rembrandt. Rätsel um seine Anfänge", die 2001 in Amsterdam und Kassel zu sehen war, wurden aber auch die beiden anderen Bilder zum sicheren Kern der authentischen Werke aus Rembrandts Schaffen der Jahre 1627 bis 1629 gezählt. Das Rembrandt Research Project verringerte die Zahl der als authentisch geltenden Werke Rembrandts auf rund 350 und publizierte seine Forschungsergebnisse in bisher vier Katalogen. Zu den prominentesten Abschreibungen zählt dabei das Porträt "Der Mann mit dem Goldhelm" der Berliner Gemäldegalerie. Es wurde nicht sicher nachgewiesen, aber es existiert die Hypothese, dass es von dem aus Augsburg stammenden Maler Johann Ulrich Mayr, der zeitweise in Rembrandts Werkstatt arbeitete, angefertigt wurde, da der Helm aus einer Augsburger Waffenschmiede stamme. Daneben besteht die Hypothese, dass der Urheber dieses Porträts nicht in der Werkstatt, sondern im weiteren Umkreis Rembrandts zu suchen ist. Ebenfalls von Abschreibungen in größerem Umfang waren die Zeichnungen betroffen, während die Radierungen schon weitgehend von Schulwerken und Nachahmungen befreit waren.

Neben der Frage der Authentizität der Werke Rembrandts hat das Rembrandt Research Project auch neue Erkenntnisse zur Werkstatt und zum Unterricht Rembrandts und Archivfunde zur Biographie des Künstlers, zu Modellen und frühen Provenienzen seiner Werke vorzuweisen. Weiterhin hat es viele naturwissenschaftliche Erkenntnisse zu Werken Rembrandts in einer Datenbank zusammengetragen, so etwa zu den verwendeten Pigmenten, Bindemitteln und Malgründen. Zudem wurden mit Röntgenaufnahmen und Neutronenbestrahlung viele Hinweise zum Malprozess erzielt.

Rembrandts Arbeiten dienten vielen Künstlern als Inspiration, sie wurden teils kopiert oder als Vorbild für eigene Arbeiten verwendet. Dies begann bereits zu Rembrandts Lebzeiten. Ein Beispiel ist der Maler Gerrit Lundens, der mehrere Kopien der "Nachtwache" anfertigte und deren Komposition auf eigene Werke übertrug. Insgesamt sind bisher zehn solcher Werke von Lundens bekannt. An seiner zwischen 1642 und 1649 entstandenen Kopie, die sich in der National Gallery in London befindet, ist zudem der ursprüngliche Zustand von Rembrandts Werk vor der Verkleinerung und dem Nachdunkeln nachvollziehbar. Eine weitere zeitgenössische Rezeption dieses Bildes stellt ein Aquarell im Familienalbum des Frans Banningh Cocq dar, das um 1650 entstand. Neben solchen Kopien waren auch viele Stiche von Werken Rembrandts im Umlauf, die ihn in ganz Europa bekannt machten. So übte Rembrandt in der Epoche des Barock beispielsweise Einfluss auf andere Porträtmaler wie Johann Kupetzky aus.

Nach dem Tod Rembrandts ließ sein Einfluss auf nachfolgende Künstlergenerationen nicht nach, so dass immer wieder von ihm inspirierte und an seinen Gemälden und Stichen orientierte Werke entstanden. Einer der Rembrandtnachfolger im 18. Jahrhundert war Christian Wilhelm Ernst Dietrich, der Rembrandt nicht nachahmte, sondern dessen Kompositionen erzählerischer darstellte und die Dramatik Rembrandts zurücknahm. Auch Max Liebermann war von Rembrandt beeinflusst. In seinem Frühwerk sind Einflüsse Rembrandts, der Liebermann durch seinen Lehrer Ferdinand Pauwels im Kassler Fridericianum näher gebracht wurde, auszumachen. Bei seinem Aufenthalt in Amsterdam im Jahr 1876 ließ Liebermann sich im Rijksmuseum Radierungen Rembrandts vorlegen und kopierte diese in Federzeichnungen. Er kopierte unter anderem eine Radierung, die ein Porträt von Rembrandts Mutter zeigte. Auf die Radierungen Rembrandts bezog sich auch der französische Graphiker Rodolphe Bresdin, der seinem Vorbild in der Darstellung von Helligkeit im Kontrast zur Schwärze nacheiferte. Ein weiterer Künstler, der von Rembrandts Werken beeindruckt war, war Vincent van Gogh, der besonders "Die Judenbraut" schätzte. Er malte einige Gemälde nach Werken Rembrandts. Auch Édouard Manet kopierte mit der "Anatomie des Dr. Tulp" ein Werk Rembrandts und Pablo Picasso nahm in einigen seiner Werke Bezug auf Rembrandt. Einfluss hatten Rembrandt und seine Werke zudem auf viele weitere Künstler wie etwa Hans von Marées, Ilja Repin, Wilhelm Leibl, Franz von Lenbach, Max Slevogt, Eugène Delacroix und Gustave Courbet. Die Expressivität der Selbstporträts Rembrandts beeinflusste darüber hinaus eine Reihe von Künstlern wie Francisco de Goya und Anton Raphael Mengs bei ihrer eigenen Selbstdarstellung.

Bilder Rembrandts wurden auch von Glenn Brown verarbeitet, der in seinen Werken oftmals Gemälde berühmter Künstler rezipiert. Sein Werk "Joseph Beuys (after Rembrandt)" aus dem Jahr 2001 orientierte sich dabei an einem Porträt Rembrandts. Die Künstlerin Devorah Sperber bildete das Selbstporträt Rembrandts aus dem Jahr 1659, das in der National Gallery of Art in Washington hängt, in einer Installation "After Rembrandt" aus Garnspulen in einer verpixelten Detailansicht nach. Hiroshi Sugimoto fertigte 1999 einen Silbergelatineabzug "Rembrandt van Rijn" an, der eine Wachsfigur zeigt, die dem Selbstporträt von 1659 in der National Gallery in London nachempfunden ist.

Die Person Rembrandts wurde zum Gegenstand verschiedener historischer Romane. 1934 veröffentlichte der in Russland geborene Autor Valerian Tornius den Roman "Zwischen Hell und Dunkel". Der Fokus dieses Buches liegt auf dem Kontrast zwischen Rembrandts Erfolgen und seinem materiellen Abstieg bis zum Tod in Armut. Daneben spielt seine Huldigung als Genie eine zentrale Rolle. Eine Reihe von Romanen setzte sich mit Rembrandts Bezug zur Religion auseinander wie "Die Sendung des Rembrandt, Harmenszoon van Rijn" von Meta Scheele aus dem Jahr 1934 und "Rembrandt und das große Geheimnis Gottes" von Kurt Schuder aus dem Jahr 1952. Im Buch "Licht auf dunklem Grund. Ein Rembrandt-Roman" von Renate Krüger, das 1967 erschien, wird Rembrandts Umzug in das Judenviertel Amsterdams und seine Beziehung zu den dortigen Nachbarn behandelt.

Das von Alexandra Guggenheim verfasste Buch "" erschien im Jahr 2006 und beschäftigt sich mit dem fiktiven Schüler Rembrandts, Samuel Bol. Der Maler erhält den Auftrag, ein Porträt eines Anatomen bei der Arbeit zu erstellen, aber es ist kein Leichnam eines Hingerichteten vorhanden. Als die Vorlesung schließlich stattfindet, wird die Leiche eines kleinen Diebes seziert, was Bol misstrauisch stimmt. Trotz dieser Kriminalgeschichte liegt ein Hauptaugenmerk des Romans auf der Arbeit Rembrandts als Maler, dessen Stil und Motivwahl. Ebenfalls 2006 erschien der Roman "Van Rijn" von Sarah Emily Miano, in dem der alte und mittellose Rembrandt, dessen Atelier der junge Verleger Pieter Blaeu 1667 besucht, auftritt. In dem Roman werden zudem weitere Charaktere mit Bezug zu Rembrandt aufgegriffen.

In dem Roman "Die Farbe Blau" erzählt Jörg Kastner die Erlebnisse des Malers Cornelius Suythof bei der Aufklärung einer Verschwörung gegen die Niederlande im Jahr 1669. Suythof wird als Schüler Rembrandts beschrieben. Rembrandt selber spielt als Maler in der Geschichte eine wesentliche Rolle. Suythof heiratet am Ende Rembrandts Tochter Cornelia.

Der Roman Der Maler und das Mädchen der niederländischen Schriftstellerin Margriet de Moor beleuchtet zwei fiktive Handlungsstränge von Elsje Christiaens und dem Künstler, der zeichnerisch die Tote am Kalvarienort festgehalten hat.

Rembrandt van Rijn wurde in mehreren Filmen rezipiert. So entstand 1936 unter der Regie Alexander Kordas der Film "Rembrandt", dessen Drehbuch Carl Zuckmayer und June Heart geschrieben hatten. Der Film versuchte die Maltechnik Rembrandts auf die Bildführung zu übertragen und setzt nach dem Tod seiner Ehefrau ein. Die Hauptrolle spielte Charles Laughton. 1942 folgte der von Hans Steinhoff inszenierte Film "Ewiger Rembrandt", in dem der Maler von Ewald Balser verkörpert wurde. Er präsentiert zum Teil die nationalsozialistische Kulturauffassung und beschäftigt sich mit der Entstehung des Gemäldes "Die Nachtwache", wobei er sich inhaltlich an dem Roman "Zwischen Hell und Dunkel" von Valerian Tornius orientierte.

In den 1970er und 1980er Jahren wurden einige Fernsehfilme produziert, die Rembrandt zum Thema hatten. Im Jahr 1999 folgte der Kinofilm "Rembrandt", in dem Klaus Maria Brandauer unter der Regie Charles Mattons den Maler darstellte. Der Film geht auf viele biografische Aspekte Rembrandts ein und präsentiert seine Vision der Malerei. Die 55-minütige Dokumentation "Die Rembrandt GmbH" aus dem Jahr 2006 setzt sich mit der Arbeit des Rembrandt Research Projects und Rembrandts künstlerischer Leistung auseinander, während Peter Greenaway 2007 in seinem Film "Nightwatching", in dem Martin Freeman Rembrandt spielte, eine nicht historisch korrekte Darstellung der Person wählte und sie viel mehr als Projektionsfläche für seine eigene filmische Kunst nutzte. So interpretiert Greenaway den abgefeuerten Schuss in der "Nachtwache" als Mord, die Schärpe des Gildemeisters als Schwanz des Teufels und das als Allegorie eingefügte Mädchen als uneheliche Tochter eines Mitglieds der Gilde. Der Darstellung, Greenaway habe eine neue Interpretation des Bildes gefunden, wurde von dem Rembrandt-Experten Ernst van de Wetering widersprochen.

Diese Liste enthält 27 Werke Rembrandts, die einen repräsentativen Querschnitt durch sein malerisches Werk darstellen. Die Auswahl orientiert sich an dem Buch "Rembrandt" von Michael Kitson, das 2007 bei Phaidon Press in New York erschien.




</doc>
<doc id="10694" url="https://de.wikipedia.org/wiki?curid=10694" title="Magisches Quadrat">
Magisches Quadrat

Ein magisches Quadrat ist eine quadratische Anordnung von Zahlen oder Buchstaben, die bestimmte Forderungen erfüllt.

Die Definition eines "normalen" magischen Quadrates lautet:

Die Kantenlänge formula_1 wird als "Ordnung" der magischen Quadrate verwendet.

Es ist auch erkennbar, dass jede arithmetische Folge für ein magisches Quadrat geeignet ist.
Es gibt noch zahlreiche Varianten von magischen Quadraten, bei denen nicht alle diese Bedingungen erfüllt sind oder zusätzliche Einschränkungen gefordert sind (siehe unten).

Semimagisches Quadrat

Zahlenquadrate, bei denen nicht auch die beiden Diagonalen die magische Zahl oder die Zielsumme ergeben, gelten als misslungen und dissonant. Sie streben nach Auflösung des Widerspruches. Diese misslungenen Zahlenquadrate werden als semimagische Quadrate bezeichnet.

Semimagisches Quadrat 3. Ordnung mit der 7 im mittleren Feld und den Zahlen 1 bis 9.

Für die Auflösung des Widerspruches gibt es bei Quadraten der dritten Ordnung zwei Wege. Der erste Weg führt über die Anpassung des mittleren Elementes bei Beibehaltung der Zielsumme. Der zweite Weg ändert die Zielsumme bei unverändertem mittleren Element. Man kann immer reelle Lösungen mit Übereinstimmung von drei Elementen finden. Von Interesse sind daher Lösungen mit mehr als drei übereinstimmenden Elementen.

Die Reihensumme wird als "magische Zahl" bezeichnet. Es ist leicht zu sehen, dass die magische Zahl
formula_2 mal der Summe der Zahlen von 1 bis formula_3 sein muss:

Denn: Sei formula_5 die Summe der Zahlen einer Zeile. Wir haben formula_1 Zeilen, die alle die gleiche Zeilensumme haben sollen; und die Summe über alle Zeilen, also formula_7, ist gleich der Summe aller Einträge des Quadrats, also identisch mit formula_8 (Gaußsche Summenformel).

Die ersten magischen Zahlen beginnend mit formula_9 sind
Darin sind die ersten drei Glieder hypothetisch. Ein magisches Quadrat der Kantenlänge 1 ist trivial. Für die Kantenlänge 2 gibt es keine Lösung mit vier unterschiedlichen Zahlen.

Es ist offensichtlich, dass durch Rotation um 90°, 180° und 270° sowie durch Spiegelung an den Hauptachsen und Diagonalen aus einem magischen Quadrat wieder ein magisches Quadrat entsteht. Diese acht magischen Quadrate sind äquivalent; es genügt, eines davon zu untersuchen. Es hat sich eingebürgert, hier die Frénicle-Standardform zu verwenden:


Zu jedem normalen magischen Quadrat kann ein Komplement gebildet werden. Für die Bildung des komplementären Quadrates sind alle Einträge mit −1 zu multiplizieren und anschließend zu jedem Eintrag die Konstante formula_10 zu addieren. Die Elemente im Ausgangsquadrat und im Komplement ergänzen sich damit zu formula_10. Das komplementäre Quadrat hat dieselbe Struktur wie das Ausgangsquadrat.
Die Komplementbildung ist keine Tauschoperation, da sie nicht unabhängig von der Struktur des Ausgangsquadrates ist! Magische Quadrate mit bestimmten Strukturen können selbstkomplementär sein, d. h., das Komplement ist dann äquivalent zum Ausgangsquadrat. Von den 12 Strukturen der Ordnung 4 sind die magischen Quadrate der 3. und 6. Struktur selbstkomplementär.

Der exakte Vergleich erfolgt durch Einordnung der magischen Quadrate in die Lösungsmenge des homogenen linearen Gleichungssystems. Das entspricht der Einordnung in den nichtgeometrischen Vektorraum. Jedes magische Quadrat hat seinen genau bestimmbaren Platz in der Lösungsmenge. Die Lösungsmenge ist ein vorzügliches Beispiel für einen nichtgeometrischen Vektorraum. Bei magischen Quadraten höherer Ordnung kommt die Methode der Einordnung an Grenzen der Vorstellungskraft. Für magische Quadrate 3. und 4. Ordnung ist sie jedoch didaktisch sehr interessant. Bei höherer Ordnung muss man auf Strukturanalyse und die Methode der Korrelation zurückgreifen.

Alle magischen Quadrate besitzen eine innere Struktur. Diese Strukturen sind je nach Ordnung des Quadrates verschieden und werden mit steigender Ordnung immer komplexer. Für normale magische Quadrate 4. Ordnung sind genau 12 Strukturgruppen mit identischer Paarsumme existent. Nach ihrem Entdecker Henry Dudeney werden diese auch Dudeney-Muster genannt. Die Bilder der Strukturen können zur Analyse der Symmetrieeigenschaften der magischen Quadrate verwendet werden.

Allgemeine reelle Zahlenquadrate bestehen aus reellen Zahlen. Ihre einzige Bedingung ist, dass Zeilen, Spalten und Diagonalen dieselbe Summe s ergeben. Die Summe s ist frei wählbar. Allgemeine reelle Zahlenquadrate sind Lösungsmenge eines homogenen linearen Gleichungssystems. Das Gleichungssystem hat formula_12 lineare Gleichungen.

Beispiel eines Ergebnisses der Lösungsmenge dritter Ordnung und s= 3/2:
Eine herausragende Eigenschaft allgemeiner reeller Zahlenquadrate dritter Ordnung ist, dass das mittlere Zahlenelement immer das arithmetische Mittel aller Zahlen des Quadrates enthält. Das mittlere Zahlenelement ist daher nicht nur vom räumlichen Begriff her der Mittelwert, sondern auch gleichzeitig vom numerischen Begriff.

Legt man als weitere Bedingung fest, dass das Zahlenquadrat nur aus natürlichen Zahlen besteht, so erhält man für jede Zielsumme s eine "endliche" Lösungsmenge. Für Quadrate 3. Ordnung und formula_13 gibt es 25 Lösungen (15 mit und 10 ohne Wiederholung von Zahlen).

Die Zielsumme s ist eine freie Variable der Lösungsmenge des homogenen linearen Gleichungssystems. Man kann daher für die Zielsumme s auch die errechnete magische Zahl einsetzen. Bei der magischen Zahl 15 erhält man so 9 Lösungen (8 mit und 1 ohne Wiederholung von Zahlen). Das ist das Lo-Shu und sein Hofstaat.

Erfüllt ein magisches Quadrat zusätzlich die Bedingung, dass die Summen zweier Elemente, die punktsymmetrisch zum Mittelpunkt (bei geraden) oder zum zentralen Element (bei ungeraden magischen Quadraten) liegen, gleich sind, so wird es "symmetrisches magisches Quadrat" genannt. Es ist genauer die Bezeichnung "zentralsymmetrisches magisches Quadrat" oder "assoziatives magisches Quadrat" zu verwenden. Wie man leicht zeigen kann, muss die Summe zweier solcher Elemente formula_14 betragen; bei ungeraden symmetrischen magischen Quadraten hat das Mittelfeld den Wert formula_15. Symmetrische magische Quadrate haben die einfachste innere Struktur der magischen Quadrate. Das magische Quadrat 3 mal 3 ist ein symmetrisches magisches Quadrat. Bei den magischen Quadraten 4 mal 4 ist nur eine der 12 Strukturgruppen (Gruppe 3) die Gruppe der symmetrischen magischen Quadrate. Sie ist in den Strukturbildern die sternförmige Darstellung.

Bei symmetrischen magischen Quadraten kann das Komplement des Ausgangsquadrates durch Rotation um 180° immer auf das Ausgangsquadrat abgebildet werden, d. h., alle symmetrischen magischen Quadrate sind selbstkomplementär (selbstähnlich).

Bei einem pandiagonalen magischen Quadrat muss nicht nur die Summe der Diagonalen, sondern auch die der "gebrochenen Diagonalen" gleich sein. Die gebrochenen Diagonalen verlaufen parallel zur Haupt- bzw. Gegendiagonale, wobei Elemente außerhalb des Quadrats um eine Kantenlänge verschoben werden.
Im Gegensatz zu symmetrischen magischen Quadraten ist bei Quadraten mit pandiagonaler Eigenschaft diese besondere Eigenschaft nicht immer unmittelbar aus dem Bild der inneren Struktur ablesbar. Die kleinstmögliche Ordnung für Quadrate mit pandiagonaler Eigenschaft ist die 4. Ordnung. Die Strukturgruppe 1 der Quadrate 4. Ordnung besteht aus den 48 pandiagonalen Quadraten. Bei magischen Quadraten höherer Ordnung gibt es mehrere Strukturgruppen die aus Quadraten mit pandiagonaler Eigenschaft bestehen oder solche enthalten. Die magischen Quadrate der symmetrischen Strukturgruppe der 5. Ordnung haben nur teilweise die pandiagonale Eigenschaft. Die symmetrische Strukturgruppe ist eine Hauptstrukturgruppe. Bei Hauptstrukturgruppen steht der Mittelwert im Mittelfeld des Quadrates. Bei 5 mal 5 ist das der Wert 13. Diese Festlegung sichert die unverzerrte Darstellung der inneren Struktur. Jedes ungerade pandiagonale Quadrat kann durch Verschieben im Verschiebungscluster in ein Quadrat dieser Struktur gebracht werden. Es gibt bei der 5. Ordnung noch drei weitere Hauptstrukturgruppen die aus pandiagonalen Quadraten bestehen. Diese unverzerrten Strukturen sind ästhetisch reizvoll und zeigen den mathematischen Zusammenhang zwischen Mittelwertsbildung und Symmetrie. Durch Verschieben im Verschiebungscluster werden zu jeder Hauptstrukturgruppe die Nebenstrukturgruppen gebildet.

Magische Quadrate, die sowohl symmetrisch als auch pandiagonal sind, nennt man "ultramagisch."

Es gibt zahlreiche Varianten von magischen Quadraten, bei denen die Forderung fallengelassen wird, dass nur die Zahlen von 1 bis formula_3 vorkommen sollen, dafür aber zusätzliche Bedingungen erfüllt sein müssen. Die bekanntesten davon sind "magische Primzahlenquadrate," bei denen sämtliche Elemente Primzahlen (oder 1) sein müssen.

Das magische Primzahlenquadrat 3. Ordnung mit der kleinstmöglichen magischen Summe von 111 wurde im Jahr 1900 von Henry Ernest Dudeney entdeckt, der die 1 als Primzahl ansah. Es galt seinerzeit als das erste magische Primzahlenquadrat in der Lösungsmenge allgemeiner magischer Quadrate 3. Ordnung.

Das erste echte magische Primzahlenquadrat 3. Ordnung hat die kleinstmögliche magische Summe von 177.

Für den Mittelwert 127 gibt es erstmals zwei verschiedene magische Primzahlenquadrate in der Lösungsmenge allgemeiner magischer Quadrate 3. Ordnung.

Es gibt ein (triviales) magisches Quadrat mit Kantenlänge 1, jedoch keines mit Kantenlänge 2. Abgesehen von Symmetrieoperationen oder angegeben in der Frénicle-Standardform, gibt es auch nur ein einziges normales magisches Quadrat mit Kantenlänge 3 (siehe unter Lo-Shu). Alle 880 magischen Quadrate mit Kantenlänge 4 wurden bereits 1693 von Frénicle de Bessy gefunden. Mit Kantenlänge 5 gibt es 275.305.224 magische Quadrate; darüber hinaus sind keine genauen Zahlen bekannt, es gibt jedoch bis etwa formula_17 relativ verlässliche Abschätzungen. Die weitestreichenden Berechnungen wurden von Walter Trump durchgeführt. Auch die Anzahl symmetrischer, pandiagonaler und ultramagischer Quadrate für kleinere formula_1 ist bekannt, beispielsweise gibt es 48 symmetrische magische Quadrate mit Kantenlänge 4 und 16 ultramagische Quadrate mit Kantenlänge 5.

Ein Beispiel ist das älteste bekannte magische Quadrat aus China ca. 2800 v. Chr. In Europa wurde es im 16./17. Jahrhundert "Saturn-Siegel" (Heinrich Cornelius Agrippa von Nettesheim, ca. 1510 und Athanasius Kircher, Arithmologia 1665) genannt.
Das Lo-Shu ist das einzige normale magische Quadrat der Größe 3 mal 3.

Eines der berühmtesten magischen Quadrate ist in Albrecht Dürers Kupferstich "Melencolia I" zu finden.

Das Dürer-Quadrat hat folgende Eigenschaften:
Normale Symmetrieeigenschaften magischer Quadrate 4 mal 4:
Zusätzliche Symmetrieeigenschaften des Dürer-Quadrates:

Sonstige Struktureigenschaften


Im 16./17. Jahrhundert setzte eine intensive Beschäftigung mit magischen Quadraten ein. Die Universalgelehrten Heinrich Cornelius Agrippa von Nettesheim und Athanasius Kircher entwickelten mehrere magische Quadrate höherer (bis 9 mal 9) Ordnung. Es wurden auch Algorithmen für Erstellung gerader und ungerader magische Quadrate in den Werken angegeben. Auf Agrippa geht die Zuordnung von bestimmten magischen Quadraten zu Gestirnen zurück. Das Jupiter-Quadrat des Agrippa ist identisch mit dem 4 mal 4 Quadrat des Yang Hui. Die magischen Quadrate mit der Bezeichnung/ Zuordnung zu Gestirnen fanden auf vielen Amuletten Verwendung.

Die der Passion gewidmete Fassade der Sagrada Família in Barcelona, ein Werk des Bildhauers Josep Maria Subirachs, enthält ein magisches Quadrat:

Es ist kein magisches Quadrat im engeren Sinne, weil nicht alle Zahlen von 1 bis 16 vorkommen (es fehlen 12 und 16), 10 und 14 kommen hingegen doppelt vor. Die magische Zahl ist 33, eine Anspielung auf das Lebensalter Christi. Das Zahlenquadrat an der Sagrada Família kann durch Subtraktion von 1 bei 4 Elementen aus dem Dürer-Quadrat erzeugt werden. Es stimmen daher die Werte von 12 Elementen mit dem Dürer-Quadrat überein. Die 4 veränderten Elemente wurden so gewählt, dass alle Zeilen, Spalten, Diagonalen und Blöcke/ Quadranten jeweils einmal erreicht werden.

Elemente im Dürer-Quadrat, von deren Wert jeweils 1 subtrahiert wird:
Danach ist noch eine Rotation um 180° vorzunehmen. Die Subtraktion bei den 4 Elementen bewirkt eine Strukturänderung. Das Quadrat an der Sagrada Família ist nicht zentralsymmetrisch. Es hat eine bipolare Struktur, d. h., die Summe der gegenüberliegenden Elemente beträgt 16 oder 17.

Es gibt viele Interpretationen des Hexeneinmaleins aus Goethes Faust. Neben der Annahme, dass es sich schlicht um Unsinn handelt, wurde es auch als Konstruktionsanleitung für ein magisches Quadrat gedeutet – eine Deutung, die nicht hundertprozentig überzeugt.

Zur Konstruktion magischer Quadrate gibt es verschiedene Verfahren, die von der Kantenlänge abhängen.
Das einfachste Verfahren, genannt siamesische Methode oder De-la-Loubère-Methode, funktioniert für alle magischen Quadrate mit ungerader Kantenlänge (also 3×3, 5×5, 7×7 etc.). Man fängt oben in der Mitte mit 1 an und füllt dann die anderen Zahlen der Reihe nach gemäß der folgenden Regel in die anderen Felder ein:

Hierbei wird das magische Quadrat als periodisch wiederholt angesehen, d. h., wenn man über den oberen Rand hinausgeht (das passiert schon beim ersten Schritt), kommt man von unten wieder hinein, und wenn man rechts hinausgeht, dann kommt man von links wieder hinein. Hier ein nach dieser Regel konstruiertes 7×7-Quadrat:

Aufbauend auf der siamesischen Methode können mit Hilfe der LUX-Methode von John Horton Conway weitere magische Quadrate mit doppelter Ordnung erzeugt werden.

Zwei weitere Verfahren sind für Quadrate mit gerader Kantenlänge, wobei das eine für alle Quadrate ist, deren Kantenlänge durch 4 teilbar ist, das andere für die, bei denen der Rest 2 beim Teilen durch 4 bleibt.

Ein spielerisches Verfahren zur Konstruktion magischer Quadrate gerader Ordnungen größer als 4 geht mit Hilfe von Medjig-Lösungen. Hierzu braucht man die Spielteile des Medjig-Puzzles. Das sind in vier Quadranten verteilte Quadrate, worauf mit Punkten die Zahlen 0, 1, 2 und 3 in verschiedenen Anordnungen angegeben sind. Das Puzzle hat 18 Teile, alle Anordnungen gibt es dreimal. Siehe Abbildung unten. Das Ziel des Puzzles ist willkürlich 9 Quadrate der Versammlung zu entnehmen und diese Teilversammlung in ein 3 × 3 Quadrat zu legen, so dass in jeder entstandenen Zeile, Spalte und Diagonale die Summe von 9 (Punkten) ergibt.

Die Konstruktion eines magischen Quadrates der Ordnung 6 mit Hilfe des Medjig-Puzzles geht wie folgt:
Mache eine 3×3-Medjig-Lösung, dazu kann man diesmal unbeschränkt aus der Totalversammlung wählen. Dann nimmt man das bekannte klassische magische Quadrat der Ordnung 3, und verteile alle Felder davon in vier Quadranten. Als Nächstes fülle man die Quadranten mit der ursprünglichen Zahl und den drei abgeleiteten modulo-9-Zahlen bis 36, der Medjig-Lösung folgend. Das ursprüngliche Feld mit der Zahl 8 wird also verteilt in vier Feldern mit den Zahlen formula_29, formula_30, formula_31 und formula_32, das Feld mit der Zahl 3 wird 3, 12, 21 und 30 usw; siehe untenstehendes Beispiel.

Auf gleiche Weise kann man magische Quadrate der Ordnung 8 erzeugen. Man erzeuge dazu erst eine 4×4-Medjig-Lösung (Summe der Punkte jeder Reihe, Spalte, Diagonale 12), und vergrößere danach z. B. das oben abgebildete 4×4-Quadrat von Dürer modulo 16 bis 64.
Im Allgemeinen braucht man für die Konstruktion magischer Quadrate der Ordnung größer als 9 auf diese Weise mehrere Sätze Medjig-Teile.
Für die Ordnung 12 kann man eine 3×3-Medjig-Lösung horizontal und vertikal verdoppeln, und danach das oben konstruierte 6×6-Quadrat modulo 36 ausbreiten nach 144. Ähnlich geht es mit Ordnung 16.

Magische Quadrate der Größe 4×4 mit der magischen Zahl S kann man anhand des folgenden Schemas konstruieren, wobei die Variablen a und b für beliebige ganze Zahlen stehen:

Die magische Zahl S beträgt jeweils formula_33. Soll S z. B. den Wert 88 betragen, zieht man ein ganzzahliges formula_34 Vielfaches von 21 ab, der Rest ist dann die Zahl b. Zum Beispiel (wie im rechten Quadrat gezeigt): formula_35.

Magische Quadrate dieser Art bestehen im Allgemeinen nicht aus den Zahlen 1, 2, 3, … 16, und bei ungünstiger Wahl der Werte a und b können zwei Felder die gleiche Zahl enthalten. Die magische Zahl formula_33 ist dafür nicht nur in den Zeilen, Spalten und Diagonalen enthalten, sondern auch in den vier Quadranten, in den vier Eckfeldern sowie im kleinen Quadrat der vier innen liegenden Felder.

Die magischen 4×4-Quadrate, bei denen auch die Quadranten die magische Summe ergeben, können – wenn man auf die Eigenschaft, dass jede der Zahlen von 1 bis 16 "genau einmal" vorkommen soll, verzichtet – als Linearkombination der folgenden acht erzeugenden, zueinander kongruenten Quadrate dargestellt werden:

Man beachte, dass diese acht erzeugenden Quadrate nicht linear unabhängig sind, denn

d. h., es gibt eine nichttriviale Linearkombination (eine Linearkombination, deren Koeffizienten nicht alle = 0 sind), die das 0-Quadrat ergibt. Anders ausgedrückt: Jedes der acht erzeugenden Quadrate lässt sich als Linearkombination der übrigen sieben darstellen. Sieben erzeugende Quadrate sind aber nötig, um alle magischen 4×4-Quadrate mit der Zusatzeigenschaft „Quadranten“ zu erzeugen; der Vektorraum der magischen 4×4-Quadrate, die von diesen Quadraten erzeugt wird, ist in diesem Sinn 7-dimensional.
Bemerkenswert ist, dass in allen acht erzeugenden Quadraten A–H wie in Albrecht Dürers magischem Quadrat nicht nur "Zeilen, Spalten" und "Diagonalen" immer dieselbe Summe liefern (1), sondern auch jeder der vier "„Quadranten“," die vier "Zentrumsfelder" und die vier "Eckfelder." Das heißt, dass alle magischen Quadrate, die wir als Linearkombinationen dieser Erzeugenden gewinnen, diese Eigenschaft haben. Die Kongruenz der erzeugenden Quadrate ermöglicht z. B., aus A durch Drehung F, E und G zu erzeugen und daraus D, B, H und C durch Spiegelung.

Das magische Quadrat aus dem Kupferstich "Melencolia I" Albrecht Dürers als Linearkombination der erzeugenden Quadrate A–G:

Die Summe der Koeffizienten ist natürlich formula_39.

Dass die 4 Quadranten auch die magische Summe ergeben, muss nicht unbedingt so sein. Folgendes magische Quadrat hat diese Eigenschaft nicht und ist daher linear unabhängig zu den Quadraten A–H:

Nimmt man dieses Quadrat noch zu 7 der Quadrate A–H, so erhält man eine Basis für den 8-dimensionalen Vektorraum aller magischen 4×4-Quadrate.
Die Summe der Ecken und der vier Zentrumsfelder ist auch bei diesem Quadrat (wie bei allen magischen 4×4-Quadraten) die magische Summe.

Ein magisches Buchstabenquadrat ist eine "Denksportaufgabe," wobei in den Zeilen und Spalten des Quadrats jeweils gleiche Wörter entstehen. Ein Beispiel hierfür ist das Sator-Quadrat:





</doc>
<doc id="10696" url="https://de.wikipedia.org/wiki?curid=10696" title="Pierre-Auguste Renoir">
Pierre-Auguste Renoir

Pierre-Auguste Renoir [] (* 25. Februar 1841 in Limoges, Limousin; † 3. Dezember 1919 in Cagnes-sur-Mer, Côte d’Azur), oft nur Auguste Renoir genannt, war einer der bedeutendsten französischen Maler des Impressionismus.

Renoir wurde als Kind einer Familie der Arbeiterklasse geboren. Sein Vater war Schneider und seine Mutter Zuschneiderin. Als Pierre-Auguste drei Jahre alt war (1845), zog die Familie nach Paris und fand Unterkunft in der Nähe des Louvre, das damals nicht nur ein Museum war, sondern auch Büros und Wohnräume beherbergte.

Mit 13 Jahren trat Renoir eine Lehre als Porzellanmaler an. Bereits mit 15 Jahren beherrschte er dies so gut, dass ihm die Manufaktur anspruchsvolle Malarbeiten anvertraute, die sonst den erfahrenen Porzellanmalern vorbehalten waren. Von seinem Lohn konnte er eigenständig leben und sogar seine Eltern unterstützen. Um diese Zeit setzten sich jedoch mechanische Druckverfahren für Porzellan durch, und die Manufaktur musste schließen, als er 17 Jahre alt war.

Renoir musste seinen Lebensunterhalt nun mit dem Bemalen von Fächern und Markisen und dem Kolorieren von Wappen bestreiten.

1861–1864 studierte Renoir Malerei in der Klasse des Schweizer Malers Charles Gleyre. Bald jedoch suchte er sich andere künstlerische Vorbilder als seinen Lehrer, nämlich Gustave Courbet und Díaz de la Peña, denen er zufällig bei der Malarbeit im Wald begegnet war und die ihn ermunterten, stets nach dem Leben und dem Modell zu malen.
Er schloss Freundschaft mit Claude Monet, Alfred Sisley und Frédéric Bazille und malte mit ihnen gemeinsam im Freien. Im Jahr 1864 wurde zum ersten Mal ein Bild von ihm für den Pariser Salon, oft einfach nur Salon genannt, angenommen. Im Salon von 1868 war er mit dem Bild "Lise mit dem Sonnenschirm" vertreten, für das Lise Tréhot Modell stand. Sie war von etwa 1865 bis 1871 Renoirs Geliebte.

Seine Erfahrungen im Freien wirkten sich auch auf seine Atelierbilder aus. Kritiker wurden auf ihn aufmerksam und lobten die Frische und Natürlichkeit seiner Bilder. Trotzdem fanden sich kaum Käufer. 1869 lebte Renoir in solch bitterer Armut, dass er, wie er später selbst schrieb, nicht einmal jeden Tag etwas zu essen hatte.

1870, im Deutsch-Französischen Krieg, meldete sich Renoir freiwillig zu einem Kavallerieregiment, hatte jedoch das Glück, weit weg von den Kampfhandlungen stationiert zu werden. 1871, nach Paris zurückgekehrt, geriet er in den Aufstand der Pariser Kommune. Von den Kommunarden in die Wehrpflicht gezwungen, bekam er große Schwierigkeiten, als er aus Paris zu fliehen versuchte und von den Truppen der Gegenseite gefangen genommen wurde.

Nach dem Krieg nahm er bald wieder Kontakt zu seinen Freunden Monet und Sisley auf und verbrachte in den Sommern der 1870er viel gemeinsame Zeit mit ihnen und mit Édouard Manet. Ein sehr bekanntes Gemälde von ihm aus jener Zeit zeigt die Familie Monet im Garten ihres Hauses in Argenteuil. Von Manet gibt es eine eigene Interpretation des gleichen Themas. Beide, Manet und Renoir, hatten ihre Staffeleien nebeneinander gestellt und die gleiche Szene gemalt.

Renoir liebte es, gesellschaftliche Anlässe darzustellen und Lebensfreude in Bilder umzusetzen. Trotz der Bewegungen der dargestellten Personen wie bei "Tanz im Moulin de la Galette" und der Ausgelassenheit integrierte er kleine Stillleben.
Anders als Monet und die anderen Impressionisten bemühte sich Renoir weiterhin um die Aufnahme seiner Bilder in den Salon, beteiligte sich jedoch 1874 mit großem Enthusiasmus an der Vorbereitung und Durchführung der ersten Impressionisten-Ausstellung, ebenso an der Ausstellung von 1876.

Es gelang ihm, Bilder an die Kunsthändler Paul Durand-Ruel und Père-Martin zu verkaufen. Durand-Ruel, ein großer Förderer der Impressionisten, gab ihm Geld, so dass sich Renoir ein Atelier mieten konnte. Diese Einnahmen waren jedoch so knapp bemessen, dass sie gerade eben ausreichten, um den Lebensunterhalt zu bestreiten.

Seine finanzielle Situation wendete sich Mitte der 1870er Jahre zum Guten, als Renoir den Zollbeamten Victor Chocquet und den Verleger Georges Charpentier kennenlernte und von ihnen Aufträge für Porträts und ein großes Tafelbild bekam. Durch die Fürsprache der einflussreichen Madame Charpentier weitete sich sein Bekanntenkreis in der besseren Gesellschaft aus, und er erhielt in den folgenden Jahren so viele Porträtaufträge, dass sie ihm zeitweise sogar lästig wurden.

In den Jahren 1881/1882 unternahm Renoir drei große Reisen nach Algerien, Italien und wieder nach Algerien. 1882 porträtierte er in Palermo den Komponisten Richard Wagner.

Nach einem Aufenthalt 1881 in Italien, während er ein um 1400 verfasstes Handbuch für Maler las, orientierte er sich stark an Raffaels Fresken und an Jean-Auguste-Dominique Ingres, es begann die "Ingres-Periode" oder auch "trockene Periode". Renoir begann sich von Grund auf neu zu orientieren, er wandte sich vom Spontanen ab und zeichnete die Formen schärfer, blieb aber bei den Motiven voller Lebensfreude. Er wandte sich auch vom Impressionismus ab und dem Klassizismus zu. Eine Reise im September 1883 führte ihn auf die Insel Guernsey, wo eine Reihe von Gemälden entstanden, unter anderem "Moulin Huet Bay".
Um 1883 herum geriet Renoir in eine schöpferische Krise. Beim Publikum und bei der Kritik spürte er in jener Zeit laues Desinteresse, und über sich selbst äußerte er, dass er sich in einer künstlerischen Sackgasse befinde. Die Arbeit jener Jahre kulminierte in dem Bild "Die großen Badenden" von 1887, in das er Jahre an Vorstudien investiert hatte und das eine Fülle kunsthistorischer Zitate enthält.

Am 23. März 1885 schenkte ihm seine Geliebte Aline Charigot, die er Anfang der 1880er Jahre kennengelernt und die ihn nach Italien begleitet hatte, sein erstes Kind, den Sohn Pierre Renoir, der später als Schauspieler bekannt wurde. Am 14. April 1890 heiratete Renoir Aline. Der zweite Sohn Jean Renoir, geboren 1894, ergriff später den Beruf des Filmregisseurs. Der dritte Sohn Claude, auch „Coco“ genannt, wurde am 4. August 1901 geboren. 

Ende der 1880er Jahre fand er seine Freude an der Farbigkeit und am flüssigen, sinnlichen Malen wieder. Die Abkehr von seinem impressionistischen Malstil der 1870er Jahre blieb jedoch endgültig.

Um 1892 zeigten sich bei Renoir die ersten Anzeichen von rheumatoider Arthritis. Damals wurde fälschlicherweise Gicht diagnostiziert. Er merkte durch mehrere Kuraufenthalte, dass es ihm im milden Mittelmeerklima besser ging und zog 1907 dauerhaft nach "Les Collettes", einem Landhaus mit großem Garten in Cagnes-sur-Mer bei Nizza. Im 20. Jahrhundert entstand dort ihm zu Ehren ein Museum.

Trotz seiner Krankheit malte er unaufhörlich. Renoir saß mittlerweile im Rollstuhl und ließ sich, nach eigenen Angaben, täglich den Pinsel an die Hand binden, da er ihn nicht mehr halten konnte.

Pïerre-Auguste Renoir starb im Jahr 1919 im Alter von 78 Jahren und hinterließ rund 6000 Werke: Landschaftsbilder, Stillleben, Porträts von Erwachsenen und Kindern, Aktbilder, Bilder vom Tanzvergnügen und vom Familienleben. Sein Grab befindet sich auf dem Friedhof in Essoyes im Département Aube in der Champagne.

In der von Kurator Colin Bailey konzipierten Ausstellung "Renoir, Impressionism, and Full-Length Painting" in der Frick Collection in New York City 2012 kann man Renoir nicht nur als Farb-, sondern insbesondere auch als Kleidermode-Kenner erleben. In die Schau wurden ausschließlich seine hochformatigen Ganzkörperbilder aus den Jahren zwischen 1874 und 1885 einbezogen.

1952 entstand mit "Joy of Living; The Art of Renoir" ein Oscar-nominierter Kurzfilm von Jean Oser, der sich mit dem Leben und Werk des Künstlers beschäftigt.

Der 2012 gedrehte Film "Renoir" zeigt neben dem Protagonisten Renoir die Schauspielerin Catherine Hessling, eines seiner letzten Aktmodelle, die mit seinem Sohn Jean Renoir verheiratet war.

Der Asteroid (6677) Renoir und der Merkurkrater Renoir sind nach ihm benannt.




</doc>
<doc id="10699" url="https://de.wikipedia.org/wiki?curid=10699" title="George Spencer-Brown">
George Spencer-Brown

George Spencer-Brown, auch George Spencer Brown (Pseudonyme "James Keys, Richard Leroy," * 2. April 1923 in Grimsby, Lincolnshire; † 25. August 2016 in Market Lavington nahe Devizes, Wiltshire), war ein britischer Mathematiker, Psychologe, Dichter und Songwriter.

Spencer-Brown studierte an der Universität London und am London Hospital Medical College von 1940 bis 1943. Von 1943 bis 1947 war er bei der Royal Navy (Funker, Nachrichtentechniker, Hypno-Schmerztherapeut; Leutnant 1946).

1947 begann er ein Studium am Trinity College an der University of Cambridge. Er verließ Cambridge 1952, um sein Studium in Oxford fortzusetzen, wo er bis 1958 auch wissenschaftlicher Mitarbeiter war. 1957 veröffentlichte er seine Doktorarbeit über die Wahrscheinlichkeitstheorie mit dem Titel "Probability and Scientific Inference." Betreuer der Arbeit war der britische Logiker William Kneale.

Seit 1960 stand Spencer-Brown mit Bertrand Russell in Kontakt. In den 1960er Jahren war er als Ingenieur für die britische Bahn tätig. Es folgte eine mehrjährige Zusammenarbeit mit dem Psychiater Ronald D. Laing auf den Gebieten der Psychotherapie und Kindererziehung.

1976 wurde er Gastprofessor für Mathematik an der University of Western Australia, 1977 für Informatik an der Stanford-Universität, 1980–81 für reine Mathematik an der Universität von Maryland. Seine Vorlesungen befassten sich mit dem Vierfarbenproblem bei Landkarten und mit "Formal Arithmetics of Second Order." Spencer Brown war auch militärischer Berater in Washington, D.C. für Codes, Code-Entschlüsselung und Optik.

Spencer-Brown legte 1977 eine Abhandlung vor, in der er den Vierfarbensatz zu beweisen versuchte. Dieser „Beweis“ wurde bislang von der Fachgemeinschaft nicht akzeptiert und nicht einmal als diskutabler Beitrag anerkannt. Im Jahr 2006 veröffentlichte er weiterhin eine Beweisskizze, mit der er die Riemannsche Vermutung in Grundzügen bewiesen zu haben behauptete. Der Autor selbst erkannte jedoch, dass dieser Beweis untauglich war und veröffentlichte 2008 eine zweite Beweisskizze, die einer ganz anderen Argumentationslinie folgte und ebenfalls in Laws of Form erschienen ist. Außerdem versicherte Spencer-Brown auch, nur mit der Annahme imaginärer Wahrheitswerte, wie sie in seinem Kalkül vorgesehen ist, ließen sich die Goldbachsche Vermutung und die Fermatsche Vermutung beweisen. All diese Behauptungen haben dazu geführt, dass Spencer-Brown als Mathematiker nicht mehr ernst genommen wurde, zumal das Vierfarbenproblem und die Fermatsche Vermutung auch ohne Spencer-Browns Kalkül bewiesen wurden.

Spencer-Brown war während seiner Studentenzeit in Cambridge ein Half-Blue im Schach (d. h. ein ausgezeichneter Schachspieler beim Universitätswettbewerb), hielt außerdem zwei Weltrekorde im Segelfliegen und war Sportkorrespondent beim Daily Express.

Hauptwerk Spencer-Browns sind die Laws of Form (deutsch: "Gesetze der Form") aus dem Jahr 1969. Es behandelt klassische Probleme der Logik in einer heute unüblichen Herangehensweise. Das Besondere ist, dass Spencer-Brown für seine „Gesetze“ lediglich zwei verschiedene Zeichen benutzt: zum einen das bekannte Gleichheitszeichen, zum anderen eine Art Negations- oder Abgrenzungs-Operator. Das Buch ist unter Experten umstritten: Die einen betrachten es als genial, andere als zwar originell, aber vom Erkenntniswert banal, weil es lediglich eine operationale Umformulierung der Aussagenlogik darstelle. Tatsächlich folgt der Kalkül früheren Versuchen von Charles Sanders Peirce und Maurice Sheffer, die Boolesche Algebra mit nur einem Zeichen zu schreiben. Spätere Arbeiten von Peirce, zunächst entitative, dann existentielle Graphen zu schreiben, mit denen dieses Ziel weiterverfolgt werden konnte, blieben Spencer-Brown nach eigener Aussage unbekannt. 

Die Originalität des von Spencer-Brown in den Laws of Form entwickelten Calculus of Indications liegt in der Einführung des "unmarked state" und der Entdeckung seiner Bedeutung. Erst mit dem "unmarked state" wird der Kalkül selbstreferenz- und paradoxietauglich. Auf dem Umweg über "the void" führt die Form der Unterscheidung zurück auf den Beobachter, der die Unterscheidung trifft. Dabei wird die Unterscheidung - und mit ihr der Beobachter - jedoch zugleich, was sie nicht ist, eine Referenz auf die Ununterscheidbarkeit als Voraussetzung jeder Unterscheidung. Die Laws of Form haben unter anderem das Denken der Wissenschaftler Heinz von Foerster, Louis Kauffman, Niklas Luhmann, Humberto Maturana und Francisco Varela beeinflusst und geprägt.

Spencer-Brown definiert den englischen Begriff „form“ als Einheit aus einer umschließenden Unterscheidung mit deren Innen- und Außenseite im dadurch hervorgebrachten Raum der Unterscheidung. Unter Verwendung einer solchen Unterscheidung kann man danach nur die Innenseite benennen, die Außenseite und die Unterscheidung selbst bleiben unbenannt.

Der Autor beschreibt in den "Laws of Form" auch das "Beobachterdilemma:" Jede von einem Beobachter getroffene Beobachtung, somit Unterscheidung, impliziert demnach eine zweite Unterscheidung: Die erste ist die Unterscheidung des jeweils beobachteten Gegenstands (indication) – die zweite die Unterscheidung der mit der ersten Unterscheidung implizit getroffenen Unterscheidung (distinction) des "marked state" von einem "unmarked state." 

Eine solche "Beobachtung der Beobachtung" wird auch „re-entry“ genannt und ist als Theoriefigur universell, über die Mathematik hinaus, einsetzbar. Sie wird etwa bei dem Soziologen Niklas Luhmann als "Wiedereintritt in die Unterscheidung" zu einer zentralen Theoriefigur der luhmannschen Systemtheorie.

Fünf Jahre vor der Publikation der Laws of Form erzählt Italo Calvino in seiner Kurzgeschichte "Un segno nello spazio" die Geschichte eines sich in seine eigenen Markierungen verwickelnden Beobachters, namens Qfwfq, die sich wie ein literarisches Experiment zu den epistemologischen Grundlagen (und Gefahren) einer Beobachtung zweiter Ordnung liest.


Zwei Jahre später schrieb Spencer-Brown unter dem Pseudonym James Keys "Only two can play this game" (deutsch: "Dieses Spiel geht nur zu zweit"). Im Kontrast zu den "Gesetzen der Form" handelt es sich hierbei um ein Buch über die Liebe. Er schrieb es nach einer zerbrochenen Liebesbeziehung zu einer jungen Studentin. Es ist zu fast einem Drittel ein offener Liebesbrief aus zwölf Gedichten und Geschichten an die ehemalige Freundin. Brown selbst sagt über das Buch: „In den Gesetzen der Form habe ich versucht, soweit ich es konnte, die männliche Seite der Dinge zu beschreiben, ebenso wie ich in diesem Buch versuche, soweit es meine begrenzten Fähigkeiten erlauben, etwas über die weibliche Seite zu sagen.“





</doc>
<doc id="10700" url="https://de.wikipedia.org/wiki?curid=10700" title="RSS (Web-Feed)">
RSS (Web-Feed)

RSS (Rich Site Summary) sind Dateiformate für Web-Feeds. Sie zeigen Änderungen auf Websites, z. B. auf News-Seiten, Blogs, Audio-/Video-Logs etc. Das Backronym steht aktuell für Really Simple Syndication (etwa "sehr einfache Verbreitung"), vormals waren bereits andere Bedeutungen gegeben.

RSS-Dienste werden meist auf speziellen Service-Websites angeboten, sogenannten RSS-Channels. Ein gewöhnlicher RSS-Channel versorgt den Adressaten, ähnlich einem Nachrichtenticker, mit kurzen Informationsblöcken, die aus einer Schlagzeile mit Textanriss und einem Link zur Originalseite bestehen. Zunehmend werden aber auch komplette Inhalte klassischer Webangebote ergänzend als Volltext-RSS bereitgestellt.

Die Bereitstellung von Daten im RSS-Format bezeichnet man auch als RSS-Feed, von engl. "to feed" – im Sinne von füttern, einspeisen, zuführen. Wenn ein Benutzer einen RSS-Channel abonniert hat, so sucht der Client in regelmäßigen Abständen beim Server nach Aktualisierungen im RSS-Feed.

Nachdem der RSS-Feed abonniert wurde, kann der Abonnent die Nachrichten im Feedreader einlesen. Der Abonnent des RSS-Feeds kann sich dann den (in vielen Feeds enthaltenen) Inhalt direkt anzeigen lassen oder den angebotenen Links folgen und die vollständige Meldung der verlinkten Seite lesen. Die Adresse eines RSS-Feeds entspricht dem Aufbau einer URL, wie sie auch für Webseiten verwendet wird.

Zum Lesen eines RSS-Feeds dienen herkömmliche Webbrowser oder spezielle Programme, die auf die Ähnlichkeit zum Nachrichtenticker angepasst sind. Letztere nennt man (synonym) RSS-Aggregatoren, RSS-Reader oder Feedreader. Auch einige aktuelle E-Mail-Programme bieten bereits RSS-Lesefunktionen, ältere können durch Plugins erweitert werden. Daneben gibt es auch Anwendungen wie Bildschirmschoner.

Im Unterschied zur Benachrichtigung per E-Mail geht die Initiative bei RSS vom Empfänger aus, der den Feed abonniert hat. Das bedeutet, dass der Anbieter die Leser nicht auswählen kann, sich im Gegenzug aber auch nicht um eine Verwaltung des Leserstammes (zum Beispiel mit einer Mailinglisten-Software) kümmern muss. Der Leser muss nicht offenlegen, dass er die Quelle beobachtet, und kann Quellen wesentlich leichter abonnieren bzw. das Abonnement widerrufen, indem er einfach die Einstellung in seinem RSS-Aggregator vornimmt.

RSS vereinfacht insbesondere die Beobachtung einer großen Menge von Quellen wie z. B. Blogs, in denen es eher selten zu Änderungen kommt, deren Aktualisierung der Leser aber ggf. nicht verpassen möchte.

Weil die Inhalte via RSS in einem standardisierten Format vorliegen, eignen sie sich auch für die maschinelle Weiterverarbeitung. So lassen sich mittels RSS beispielsweise Texte einer Webseite automatisch mit Hilfe eines RSS-Parsers in eine andere Webseite integrieren oder sehr einfach auf verschiedenen Endgeräten speziell aufbereitet darstellen.

Das Aufbereiten von Informationen in ein standardisiertes Austauschformat/-objekt nennt man auch "Aggregation", das Veröffentlichen auf anderen Seiten Content-Syndication. Webseiten können damit automatisch mit neuesten Nachrichten aktualisiert werden, ohne dass der Seitenbetreiber jeweils eine Aktualisierung vornehmen muss. Eine Reihe von Content-Management-Systemen unterstützen diese Funktionalität.

RSS wird verwendet, um Artikel einer Website oder deren Kurzbeschreibungen (insbesondere Nachrichtenmeldungen) zu speichern und in maschinenlesbarer Form bereitzustellen. Ein sogenannter "RSS-Feed" oder "Newsfeed" (engl. etwa "Nachrichteneinspeisung") besteht aus einer XML-Datei, die den reinen strukturierten Inhalt – beispielsweise einer Nachrichtenseite – bereithält, aber keinerlei Layout, keine Navigation oder sonstige Zusatzinformationen beinhaltet. Zahlreiche Webangebote, die regelmäßig Artikel publizieren, stellen eine automatisch generierte RSS-Datei mit den neuesten Artikeln zur Verfügung.

Ursprünglich wurden RSS-Feeds von Nachrichtenseiten (zu Beginn auf dem Netscape.com-Portal) zur Content-Syndication verwendet. Das Format erlangte seine heutige Popularität vor allem durch den Einsatz in Blogs. Mittlerweile haben auch MP3-Portale begonnen, RSS-Feeds zusammen mit Podcasting-Funktionalität einzusetzen.

Ein Benutzer kann nun ein sogenanntes Aggregatorprogramm bzw. einen sogenannten "Feedreader" benutzen, um die für ihn wichtigsten Schlagzeilen und Kurzbeschreibungen automatisch herunterzuladen und die gesammelten Artikel geordnet anzeigen zu lassen. Hierfür benötigt der Aggregator lediglich einen Link auf den RSS-Feed.

RSS-Feeds eignen sich auch zur Verarbeitung durch spezialisierte Suchmaschinen und Alert-Dienste. Beispielsweise können die Artikel innerhalb eines RSS-Feeds durch einschlägige Dienste nach Quellen oder Stichworten gefiltert und zu einem neuen RSS-Feed zusammengesetzt werden.

RSS zählt zu den ersten Anwendungsgebieten des semantischen Webs.

Zunehmend werden RSS-Feeds auch zur Bekanntmachung von Links zu Dateien (z. B. Torrent-Dateien) verwendet. Diverse Torrent-Programme besitzen die Möglichkeit zum Abonnement von RSS-Feeds mit entsprechenden Filtereinstellungen zum automatisierten Herunterladen.

In Mozilla Firefox können dynamische Lesezeichen aus den RSS-Feeds erzeugt werden.

RSS hat sich vor allem durch Weblogs durchgesetzt, da die meisten Autoren sehr früh RSS-Feeds für ihre Artikel anboten und viele Weblog-Systeme diese automatisch generieren und in die Webseite einbinden.

Ursprünglich ging es dabei vor allem um Text. Dies hat sich inzwischen geändert: Podcasts etwa zeigen, dass man auch Audio- oder Video-Inhalte gut via RSS verbreiten kann, die dann z. B. auf tragbare Abspielgeräte ladbar sind.

Technisch gesehen ist "RSS" eine Familie von XML-basierten Dateiformaten. Die Abkürzung "RSS" hat in den verschiedenen technischen Spezifikationen eine unterschiedliche Bedeutung:


Derzeit gibt es mehrere Versionen von RSS, deren Versionsnummern zwar aufeinander Bezug nehmen, die aber von verschiedenen Firmen bzw. Entwicklergruppen zum Teil unabhängig voneinander herausgegeben wurden und auch zueinander jeweils inkompatibel sind.


In Konkurrenz dazu steht das ebenfalls auf XML basierende Format Atom. RSS und Atom sind nicht miteinander kompatibel, die beiden Formate können jedoch ineinander umgewandelt werden.

Das folgende Beispiel zeigt den Quelltext eines einfachen RSS-Feeds, welcher dem Dokumenttyp "RSS 2.0" entspricht. Der Feed enthält einen Channel mit zwei Beispieleinträgen (item).
<?xml version="1.0" encoding="utf-8"?>

<rss version="2.0">

</rss>
Der Autor des Eintrags sollte in der Form „codice_1“
eingegeben werden. Dies entspricht einer nach RFC 822 (Sektion 6 ADDRESS SPECIFICATION) geformten Adresse, die mit SGML-Entitäten codiert wurde. Das Datum entspricht auch der RFC 822 (Beispiel: Sat, 15 Nov 2003 09:59:01 +0200). Das Datum der RFC 2822 wird aber von den meisten RSS-Readern auch verstanden.

Man kann eine RSS-Datei in der HTML-Seite, deren Inhalte sie maschinenlesbar enthält, verknüpfen. Dieses Verfahren wurde für RSS nie spezifiziert, allerdings können fast alle Aggregatorprogramme dadurch selbständig die Adresse des RSS-Feeds eines Webangebots herausfinden (genannt "auto-discovery"). Moderne Browser ermöglichen es dem Seitenbesucher, den so verknüpften RSS-Feed zu abonnieren. Beispielsweise in Firefox wird in der Adress- oder Statusleiste des Browser-Fensters eine RSS-Schaltfläche angezeigt; dies jedoch derzeit nur noch, wenn ein entsprechendes Add-on in dem Browser hinzuinstalliert wurde. Eine elementare Lese-Funktion für RSS-Feeds ist aber weiterhin Bestandteil aller heute verbreiteten Webbrowser.

Dazu wird im codice_2-Bereich ein codice_3-Element eingefügt:
<link rel="alternate" type="application/rss+xml"
Es ist ebenfalls möglich, mehrere dieser Verknüpfungen zu verwenden.






</doc>
<doc id="10701" url="https://de.wikipedia.org/wiki?curid=10701" title="Darm">
Darm

Der Darm (lateinisch Intestinum, griech. ἔντερον, "enteron") ist der wichtigste Teil des Verdauungstraktes von höheren vielzelligen Tieren einschließlich des Menschen. Er erstreckt sich vom Magenpförtner bis zum After, davor liegen der Magen, die Speiseröhre und die Mundhöhle. Der Darm ist beim erwachsenen Menschen ca. 5,5 - 7,5 Meter lang und besitzt wegen der feinen Darmzotten eine Oberfläche von etwa 32 m². Die Gesamtheit der Mikroorganismen im Darm ist die Darmflora.

Die Länge des Darmes hängt bei verschiedenen Tierarten – besonders im Verhältnis zur Körperlänge – hauptsächlich von der prinzipiellen Ernährung der Art ab. Fleischfresser (Carnivoren) haben einen sehr kurzen Darm, da Fleisch leicht verdaut werden kann. Allesfresser (Omnivoren) haben einen längeren Darm, da pflanzliche Nahrung langsamer verdaut wird. Die längsten Därme haben Pflanzenfresser (Herbivoren), da das Verdauen von Pflanzenfasern (meist indirekt mit Hilfe von einzelligen Symbionten) viel Zeit benötigt.

Das Verhältnis von Darmlänge zu Körperlänge (Kopf und Rumpf ohne Arme und Beine) beträgt beim Menschen (einem Allesfresser) etwa 4:1 und liegt damit zwischen dem eines reinen Fleischfressers wie der Katze (3:1) und dem eines Pflanzenfressers wie dem Schaf (24:1).

Der Darm ist unterteilt in den

Auf den Mastdarm, aber feingeweblich kein Darmbestandteil im engeren Sinn, da von äußerer Haut und nicht von Schleimhaut ausgekleidet, folgt der After (lat. "Anus"), der mit dem endständigen Venengeflecht des Mastdarmes und dem inneren und äußeren Schließmuskel zusammen das Kontinenzorgan bildet.


Die Darmwand zeigt den typischen dreischichtigen Aufbau eines häutig-muskulösen Schlauches. Der Innenraum wird durch eine Schleimhaut (Mukosa) ausgekleidet. Ihr liegt außen eine zweischichtige Tunica muscularis an, die aus einer inneren Ring- und äußeren Längsmuskelschicht besteht. Zwischen Mukosa und Muskelschicht befindet sich der Plexus submucosus, zwischen den beiden Muskelschichten der Plexus myentericus – beides Anteile des darmeigenen Nervensystems. Außen grenzt – je nach Lage des Darmabschnitts – entweder eine Tunica serosa oder eine Tunica adventitia das Organ ab.

Der Darm ist zum Teil abtastbar und abhörbar. Weitergehende diagnostische Möglichkeiten bieten die Ultraschalluntersuchung (Sonografie), Kontrastmitteluntersuchungen, Darmspiegelung (Koloskopie) und Computertomografie (CT) bzw. Magnetresonanztomografie (MRT). Zusätzlich kann durch eine zu schluckende Endokapsel mit einer Minikamera der Dünndarm und auch der Dickdarm untersucht werden.

Weitere diagnostische Hinweise bietet die Untersuchung des Stuhlgangs, Gewebeprobenentnahme und Blutuntersuchung.

In der Jägersprache werden Weiddarm (insbesondere der Mastdarm), Harnblase und innere Geschlechtsorgane als "kleines Gescheide" bezeichnet.

Allgemeine Bezeichnung dafür ist Enteropathie
Diese Liste versteht sich ohne Anspruch auf Vollständigkeit.




</doc>
<doc id="10705" url="https://de.wikipedia.org/wiki?curid=10705" title="Androide">
Androide

Androide, auch Android, (von "aner" „Mensch, Mann“ und "eidos" „Aussehen“, „Gestalt“ → „einem Menschen (oder Mann) ähnlich“) ist die Bezeichnung für ein Maschinenwesen bzw. einen Roboter, der einem Menschen täuschend ähnlich sieht und sich menschenähnlich verhält. Ein Androide ist somit ein spezieller humanoider Roboter. Ein humanoider Roboter in Form einer Frau wird gelegentlich auch Gynoid(e) (gr.: "gyne" „Frau“) genannt.

Der Begriff Androide wurde bereits um 1740 von Eberhard David Hauber verwendet. Laut Hauber hat Gabriel Naudé den Begriff für eine sprechende Bildsäule von Albertus Magnus verwendet. Im 19. Jahrhundert wurden Automaten wie Jacques de Vaucansons Flötenspieler oder auch der Schachtürke als Androiden bezeichnet. Auch Pierre Jaquet-Droz hatte zwischen 1770 und 1774 drei Androiden konstruiert, die "Jaquet-Droz-Automaten". Geforscht wurde zu dieser Zeit auch an sprechenden Maschinen, etwa durch Friedrich von Knauss, Valentin Merbitz und Wolfgang von Kempelen. Die Konstruktion eines Sprachautomaten gelang jedoch nicht. Als der Schachtürke als Fälschung entlarvt wurde, ließ auch das Interesse an menschenähnlichen Automaten nach.

In der Literatur wurden menschenähnliche Roboter im frühen 19. Jahrhundert bei Jean Paul ("Der Maschinenmann") und E. T. A. Hoffmann ("Der Sandmann", "Die Automate") thematisiert. Von Julius Stettenheim wurde 1895 ("Muckenich’s Reden und Thaten") auch der Begriff Androide verwendet.

Seit dem 20. Jahrhundert werden Androiden regelmäßig in der Science-Fiction-Literatur und der Futurologie beschrieben. Zu Beginn des 21. Jahrhunderts wurden auch wieder reale Androiden, wie der Repliee Q1 (2003), entwickelt.

Ein Androide unterscheidet sich von einem anderen humanoiden Roboter vor allem durch einen noch menschenähnlicheren Körperbau und menschliche Gesichtszüge. Idealerweise besteht der Androide aus Material, das menschlichem Gewebe ähnelt, einschließlich einer der Haut entsprechenden Hülle.

Eine abstraktere Unterscheidung zwischen Androiden und anderen humanoiden Robotern erfolgt durch die Betrachtung des Uncanny-Valley-Phänomens. Dabei wird die Akzeptanz gemessen, die ein menschlicher Beobachter Robotern entgegenbringt, die einem Menschen mehr oder weniger ähnlich sind. Ist ein (humanoider) Roboter deutlich als solcher zu erkennen und weist er menschliche Eigenschaften auf, wird dies als angenehm und positiv empfunden. Nimmt die Menschenähnlichkeit aber weiter zu, dann beginnt der Beobachter, die vermeintlichen Defizite (in der Bewegungsfähigkeit, bei der Sprache, etc.) nach tatsächlichen menschlichen Maßstäben zu beurteilen und die Akzeptanz nimmt ab (das "Uncanny Valley"). Erst mit stark zunehmender Menschenähnlichkeit und wachsender Perfektion steigt die Akzeptanz wieder. In diesem Bereich hoher Menschenähnlichkeit spricht man von "Androiden".

Von einer mechanischen Puppe unterscheidet den Androiden seine besonders hoch ausgeprägte Fähigkeit, sich wie ein Mensch zu bewegen und auf äußere Reize zu reagieren.


Androiden sind nicht nur wegen ihres dramaturgischen Potentials beliebte Elemente der Science-Fiction. Auch ihre einfache Darstellung durch menschliche Schauspieler machte sie in der Vergangenheit zu attraktiven Figuren für Film und Fernsehen.

Generell lässt sich dabei eine Entwicklung in der Darstellung der künstlichen Menschen erkennen. Während in den 1950er und 1960er Jahren Androiden vor allem rein logisch denkende, vollkommen emotionslose und damit bedrohliche Wesen waren, wurden sie in den folgenden Jahrzehnten zunehmend menschlicher dargestellt. Obwohl sie weiterhin häufig als Antagonisten auftraten, waren sie zunehmend emotionalere Feinde, die Liebe und Hass, Zuneigung und Verachtung empfinden konnten.

Besonders konsequent zeigt sich diese Entwicklung in den Star-Trek-Serien. Während in der Originalserie "Raumschiff Enterprise" (TOS, 1966–1969) Androiden und künstliche Intelligenzen durchgehend als gefühllose Bedrohung dargestellt wurden, trat in "Raumschiff Enterprise – Das nächste Jahrhundert" (TNG, 1987–1994) mit Data ein Android als Besatzungsmitglied und Sympathieträger auf, der in einigen Folgen und in den Star-Trek-Kinofilmen sogar (durch einen „Emotions-Chip“) über Emotionen verfügt. Wenn man den holographischen Arzt aus "" (VOY, 1995–2001) trotz seines nicht dauerhaft physischen Körpers als Androiden auffasst, bildet er den Abschluss dieser Entwicklung der Androiden hin zum Menschlichen. Der Android ist nicht mehr nur – wie zuvor bereits Data – rechtlich und sozial mit den humanoiden Besatzungsmitgliedern gleichgestellt, sondern verfügt auch charakterlich über eine vollkommen menschliche Persönlichkeit mit allen Begleiterscheinungen wie Ärger oder Eitelkeit.

Häufig werden Androiden als eine äußerlich fast perfekte Imitation des Menschen dargestellt, weswegen sie von anderen Charakteren nicht als Android erkannt werden.
In Battlestar Galactica (2003) geht die physikalische und selbst psychische Ähnlichkeit bis zu dem Punkt, an dem die Androiden über sich selbst nicht wissen, dass sie Androiden sind.
Im Director’s Cut von Blade Runner (1982) ist es nicht eindeutig, ob es sich bei dem Protagonisten um einen Androiden handelt oder nicht. Selbst dem Zuschauer bleibt die Wahrheit verborgen.

<nowiki>*</nowiki> In der Neuverfilmung 2004 sind die Frauen hingegen Cyborgs

In Deutschland ist gemäß des Strafgesetzbuches (StGB) die Darstellung von Gewalt gegen „menschenähnliche Wesen“ seit dem 1. April 2004 jener gegen Menschen gleichgestellt. Damit ist auch die Darstellung von Gewalt gegen Androiden, die unter diesen Begriff fallen, strafbar, sofern sie „grausame oder sonst unmenschliche Gewalttätigkeiten“ gegen diese „in einer Art schildern, die eine Verherrlichung oder Verharmlosung solcher Gewalttätigkeiten ausdrückt oder die das Grausame oder Unmenschliche des Vorgangs in einer die Menschenwürde verletzenden Weise darstellt“.





</doc>
<doc id="10706" url="https://de.wikipedia.org/wiki?curid=10706" title="Alien">
Alien

Alien steht für:

alien steht für:
Aliens steht für:
Siehe auch:


</doc>
<doc id="10707" url="https://de.wikipedia.org/wiki?curid=10707" title="Grundbedürfnis">
Grundbedürfnis

Grundbedürfnisse sind Bedürfnisse, die bei einer hierarchischen Aufteilung der Bedürfnisse des Menschen eine hohe Wichtigkeit haben und die im Rahmen des alltäglichen Subsistenz­prozesses vordringlich befriedigt werden.

Eine allgemeingültige Definition von Grundbedürfnissen, oder ein allgemeines Verständnis, welche Bedürfnisse hierzu zählen, besteht nicht. Der Begriff wird in unterschiedlichsten Wissenschaften (z. B. der Anthropologie, der Medizin, der Psychologie, Volkswirtschaftslehre, Theologie oder Rechtswissenschaft) und in politischen Diskussionen verwendet.

Ein bekanntes hierarchisches Modell der Bedürfnisse ist die Maslowsche Bedürfnispyramide:

Grundbedürfnisse finden sich in diesem Modell in den unteren Stufen:

Eine Abgrenzung oder Definition, die erklärt, was Grundbedürfnisse sind, trifft das Modell nicht. Die unterste Stufe des Modells beschreibt körperliche Grundbedürfnisse.

In den Wirtschaftswissenschaften werden Bedürfnisse nach Dringlichkeit ihrer Erfüllung unterschieden. 


In der politischen Auseinandersetzung wird der Begriff des Grundbedürfnisses hauptsächlich im Bereich der Sozial-, der Steuer- und der Entwicklungshilfepolitik verwendet.

In der öffentlichen Diskussion wird der Begriff "Grundbedürfnisse" meist im Zusammenhang mit der Armutsgrenze oder Sozialleistungen verwendet. Ziel der Sozialpolitik in Deutschland ist, jedermann das sozio-ökonomische Existenzminimum zu gewährleisten. Voraussetzung hierfür ist die Definition der zu Grunde liegenden Grundbedürfnisse. Dies erfolgt in Deutschland über einen Warenkorb, der in einer repräsentativen Umfrage unter den 20 % der ärmsten Haushalte („Einkommens- und Verbrauchsstichprobe“ (EVS)) erhoben wird. Die Kosten hierfür stellen den Regelsatz der Sozialhilfe dar.

In der Steuerpolitik sind Grundbedürfnisse in zwei Bereichen Gegenstand der öffentlichen Diskussion. Zum einen besteht das Verfassungsgebot, das sozio-ökonomische Existenzminimum steuerfrei zu halten.

Im Bereich der Umsatzsteuer bestehen in den meisten Ländern gespaltene Mehrwertsteuersätze. Waren und Dienstleistungen, die zur Deckung der Grundbedürfnisse dienen, unterliegen niedrigeren Steuersätzen, als andere. Der Katalog der Waren und Dienstleistungen, die dem ermäßigten Steuersatz unterliegen (für Deutschland: zum Umsatzsteuergesetz) stellt eine mögliche Definition von Grundbedürfnissen dar.

In der Entwicklungshilfe orientiert sich die Grundbedürfnisstrategie an der Vorstellung von Grundbedürfnissen.

Die Internationale Arbeitsorganisation (IAO) definierte die Grundbedürfnisse wie folgt: Demnach müssen Mindesterfordernisse wie „ausreichende Ernährung, Wohnung und Bekleidung“ sowie „bestimmte Haushaltsgeräte und Möbel“ verfügbar sein. Außerdem gehören lebenswichtige Dienstleistungen wie Gesundheits- und Bildungseinrichtungen, sowie eine Bereitstellung von sanitären Anlagen und sauberem Trinkwasser zu den Grundbedürfnissen.

Die öffentliche Meinung, was ein „Grundbedürfnis“ sei, unterliegt starkem Wertewandel. 

Vor allem die seelisch-geistigen Grundbedürfnisse, die sich in bestimmten Erwartungshaltungen manifestieren, sind in hohem Maße kulturell und gesellschaftlich geprägt und können Veränderungen unterliegen. So kann beobachtet werden, dass in Zeiten der existenziellen Krisen (Kriege, Hungersnöte u. a. m.) die seelisch-geistigen Bedürfnisse gegenüber der Befriedigung der physischen Grundbedürfnisse zurücktreten oder scheinbar völlig verschwinden. Sie äußern sich aber doch in Anfälligkeiten z. B. für neue religiöse Angebote. Dagegen tritt die Erwartung, dass diese abgeleiteten oder "höheren" Bedürfnisse befriedigt werden, in Zeiten der existentiellen Sicherung sogar in den Vordergrund und kann eine ebenso große Dringlichkeit erreichen.

Die Psychologie betrachtet die subjektive Zufriedenheit (z. B. Maslowsche Bedürfnispyramide) und geht von vier Säulen (Grundwerten) aus, die zum Wohlbefinden in einem dynamischen Gleichgewicht sein sollen: Sicherheit, Veränderung (Wechsel), Freiheit und Verbundenheit.

Eine neuere psychologische Theorie, die mit dem Konzept von Grundbedürfnissen arbeitet, ist die Selbstbestimmungstheorie von Deci und Ryan. Diese Autoren postulieren drei psychische Grundbedürfnisse, das Bedürfnis nach Kompetenz (competence), nach Autonomie/ Selbstbestimmung (autonomy) und nach sozialer Eingebundenheit (relatedness). Die Grundbedürfnisse werden hier als Anpassungsmechanismen des Individuums an seine physikalische und sozio-kulturelle Umwelt verstanden, deren Befriedigung sich auf die Qualität von Verhalten sowie auf das mit der Ausübung dieses Verhaltens verbundene Wohlbefinden auswirkt.

Es gibt viele weitere psychologische Theorien, die unterschiedliche Grundbedürfnisse aufzählen. Klaus Grawe postuliert vier Grundbedürfnisse:

Der Sozialpsychologe Erich Fromm maß in seinem Werk "Anatomie der menschlichen Destruktivität" dem „Streben nach Spannung und Erregung“ eine entscheidende Bedeutung bei. Nach seiner Auffassung ist dieses Grundbedürfnis ein elementarer Antrieb, der sich sowohl in konstruktivem (Kreativität, soziales Engagement, Karrierestreben uvm.) als auch in destruktivem Handeln (Vandalismus, asoziales Verhalten, Grausamkeit uvm.) ausdrücken kann – je nach den Möglichkeiten, die sich dem Einzelnen bieten.

Beispiele für weitere psychische Grundbedürfnisse

Nach Schulz von Thun lassen sich diese Grundbedürfnisse in vier zusammenfassen: wertvoll sein, geliebt sein, frei sein, verbunden sein.

Die Medizin betrachtet die Funktionen des Körpers zu ihrer Erfüllung unter (mindestens) drei Aspekten:

Die Pflegewissenschaft, selbst eine junge Disziplin, setzt sich im Rahmen der so genannten "Aktivitäten des Täglichen Lebens" (ATL-Konzept, stark von der amerikanischen Psychologie beeinflusst) oder der "Lebensaktivitäten" mit diesen Begriffen und ihrer Konkretisierung auseinander.




</doc>
<doc id="10708" url="https://de.wikipedia.org/wiki?curid=10708" title="Treibstoff">
Treibstoff

Treibstoff steht für:


Siehe auch: 


</doc>
<doc id="10709" url="https://de.wikipedia.org/wiki?curid=10709" title="Öle">
Öle

Öle (von "oleum," von ,Olivenöl‘) ist eine Sammelbezeichnung für organische Flüssigkeiten, die sich nicht mit Wasser mischen lassen. Öle weisen eine höhere Viskosität auf als Wasser.

"Fette Öle" (beim Seetransport als Süßöl bezeichnet) sind Fette, also Gemische von Fettsäuretriglyceriden, die bei Raumtemperatur flüssig sind. Der niedrige Schmelzbereich wird hauptsächlich durch einen hohen Anteil an „ungesättigten“ oder „mehrfach ungesättigten“ Fettsäuren verursacht.



Fette Öle können auch als lebensmittelverträgliche Schmieröle in der Lebensmittelindustrie benutzt werden. Auch finden sie als biologisch abbaubare Alternative zu Schmierstoffen aus Mineralöl Verwendung, etwa zur Schmierung von Antriebsketten oder Sägeketten in der freien Natur.

"Ätherische Öle" sind ölige, wasserdampfflüchtige Extrakte aus Pflanzen oder Pflanzenteilen, die abhängig von der Herkunftspflanze einen starken, charakteristischen Geruch haben. Sie bestehen größtenteils aus Terpenen (Beispiele: Zitronenöl, Rosenöl).

"Mineralöle" werden aus Erdöl oder Kohle gewonnen und sind Kohlenwasserstoffverbindungen. Die meisten Verbindungen in den Stoffgemischen gehören chemisch gesehen zur Gruppe der Alkane, geradkettig oder verzweigt. Neben den Alkanen enthalten die meisten Rohöle unter anderem auch Aromaten, oft auch schwefelhaltige organisch-chemische Verbindungen.

Mineralöle sind Ausgangsstoffe für viele Verbindungen der organischen Chemie, beispielsweise zur Herstellung von Kunststoffen.

Mineralöle werden vorzugsweise als Energieträger genutzt und in Kraft- und Treibstoff umgeformt („raffiniert“). Sie stellen daher einen der wichtigsten Energieträger unserer Zivilisation (zum Beispiel Heizöl, Dieselöl, Schweröl) dar. Mineralöle dienen auch als Schmieröl, um direkten Verschleißkontakt zueinander bewegter Flächen zu vermeiden, und als Imprägnier- und Trennmittel (Weißöl). 

Leichtflüchtige, ebenfalls aus Erdöl gewonnene Substanzen wie Benzin oder Kerosin werden nicht zu den Ölen gezählt.

Sogenannte „synthetische Öle'“ basieren ebenfalls auf Erdölraffinaten und besitzen eine spezielle Molekülstruktur, die so beim Rohöl nicht vorkommt. Es werden synthetisch hergestellte Kohlenwasserstoffe zugesetzt. Die Annahme, synthetische Öle würden chemisch hergestellt und enthielten ausschließlich nicht in der Natur vorkommende Substanzen, ist daher falsch.

„Silikonöle“ basieren auf Polymeren und Copolymeren aus Silizium-Sauerstoff-Einheiten und organischen Seitenketten. Silikonöl ist relativ unempfindlich gegenüber Oxidation, Wärme und anderen Einflüssen. Es findet als Bestandteil von Kosmetika, als Entschäumer und Schmiermittel Verwendung. Im chemischen Labor wird Silikonöl als Wärmeübertragungsflüssigkeit benutzt.





</doc>
<doc id="10710" url="https://de.wikipedia.org/wiki?curid=10710" title="Ätherische Öle">
Ätherische Öle

Ätherische Öle (auch etherische Öle) sind leicht flüchtige und häufig leicht entzündbare Stoffgemische, die aus verschiedenen ineinander löslichen, organischen Stoffen wie Alkohole, Ester, Ketone oder Terpene bestehen. Sie werden synthetisch oder aus natürlichen Quellen durch Wasserdampfdestillation, Extraktion oder Auspressen der Pflanzen oder der Pflanzenteile gewonnen. Ätherische Öle werden häufig in den Blättern von Pflanzen produziert und im Pflanzen-Gewebe gespeichert. Die Pflanzen locken damit Insekten an oder wehren Schädlinge ab.

Ätherische Öle bestehen größtenteils aus Gemischen verschiedener Terpene, Sesquiterpene oder aromatischer Verbindungen (z. B. Phenylpropan-Derivate). Terpene leiten sich formal aus Isopreneinheiten ab. Monoterpene bestehen aus zwei, Sesquiterpene aus drei Isopreneinheiten. Untenstehende Tabelle zeigt einige Beispiele für die vielfältigen Moleküle, die in ätherischen Ölen vorkommen. Rückstände fettlöslicher Pestizide im Ausgangsmaterial können sich im ebenfalls fettlöslichen ätherischen Öl anreichern.

Ätherische Öle enthalten sekundäre Pflanzeninhaltsstoffe, die dazu dienen können, Insekten zur Bestäubung anzulocken, Schädlinge fernzuhalten oder sich gegen Krankheiten zu schützen (z. B. durch Bakterien oder Pilze hervorgerufen).

Ätherische Öle sind aus vielen verschiedenen chemischen Verbindungen zusammengesetzt. Sie sind fettlöslich, enthalten jedoch keine Fette. Im Gegensatz zu fetten Ölen verdampfen ätherische Öle rückstandsfrei. In Wasser sind sie nur sehr wenig löslich. Bei Normaldruck liegt ihr Siedepunkt weit über dem von Wasser, von überhitztem Wasserdampf jedoch werden sie überdestilliert. Sie besitzen meist eine geringere Dichte als Wasser und bilden daher auf der Wasseroberfläche schwimmende Flüssigkeitstropfen (eine Ausnahme ist z. B. Zimtöl).

Ätherische Öle werden in Öldrüsen von Pflanzen gebildet und im Pflanzengewebe gespeichert. Sie befinden sich in Blüten, Blättern, Samen, Fruchtschalen, Wurzeln, Harzen, Rinden oder im Holz. Manche Pflanzen liefern aus verschiedenen Pflanzenteilen ätherische Öle, die sich in ihrer chemischen Zusammensetzung sehr stark unterscheiden, z. B. Zimtrinden- und Zimtblätteröl.

Aus den Pflanzenteilen werden ätherische Öle durch Wasserdampfdestillation gewonnen. Nach der Kondensation liegen die Stoffe von der wässrigen Phase getrennt vor und können abgeschieden werden. Die Ausbeute in Bezug auf das Ausgangsmaterial liegt in der Regel im ein- bis zweistelligen Promillebereich.

Das gebräuchlichste Verfahren zur Gewinnung von ätherischen Ölen ist die Wasserdampfdestillation. Dazu wird in einem verschlossenen Brennkessel mit zerkleinertem Pflanzenmaterial heißer Wasserdampf eingeblasen. Der Wasserdampf treibt das ätherische Öl aus der Pflanze. In einem gekühlten Rohr kondensiert das Öl-Wasser-Gemisch, und in einem Auffangbehälter wird das ätherische Öl vom Wasser getrennt. Einige Pflanzen, die sich nicht alleine destillieren lassen, wie z. B. Algen, Brennnessel oder Heu, können mittels "Co-Destillation" zusammen mit einer anderen Pflanze als Trägerstoff destilliert werden. Öle einiger Blütenarten, wie Jasmin, Tuberose oder Mimose, können nicht per Wasserdampfdestillation gewonnen werden.

Die Kaltpressung wird nur für Zitrusöle angewandt. Die Schalen werden gepresst, so dass eine Emulsion aus Flüssigkeit und ätherischem Öl entsteht. Das Öl wird durch Zentrifugierung abgetrennt.

Extraktion wird vor allem bei Blütenölen praktiziert. Dazu werden die Pflanzen in ein Lösungsmittel, meist Hexan, gelegt, das alle löslichen Aromastoffe, auch Wachse und Farbstoffe entzieht. Anschließend wird das Lösungsmittel abdestilliert. Zurück bleibt eine wachsartige Masse, die mit Alkohol nochmals extrahiert oder destilliert wird. Solche ätherischen Öle nennt man auch Absolues. Eine Rückstandskontrolle kann gewährleisten, dass sich kein Lösungsmittel mehr im ätherischen Öl befindet. Die sehr kostspielige Extraktion mit Fetten, die sogenannte Enfleurage, wird heute kaum mehr praktiziert.

Meist werden ätherische Öle unverändert benutzt. Einige jedoch werden zunächst aufkonzentriert oder weiter zerlegt, beispielsweise durch Destillation oder Adsorption. So können für die Wirkung erwünschte Bestandteile des ätherischen Öls konzentriert werden, ungeeignete Bestandteile dagegen entfernt werden. Gemische, die nur einen oder wenige Hauptbestandteile enthalten, können über Destillation oder Kristallisation gewonnen werden, so bei der Gewinnung von Eugenol aus Nelkenöl. Die Bedeutung der Gewinnung einzelner Komponenten natürlicher ätherischer Öle hat mit der Entwicklung synthetischer Herstellungsverfahren stark abgenommen.

Bereits die Ägypter kannten Destillationsverfahren und benutzten Zedernöl, wie auch die Aromata verschiedener Pflanzen. Die Griechen übernahmen wahrscheinlich die Destillationskunst von den Ägyptern; so werden bei Dioskurides bereits einige Destillationsverfahren beschrieben. Auch die Römer verwendeten gerne Parfum und Räucherwerk, entwickelten die Destillationskunst jedoch nicht weiter. Ob es sich insbesondere bei den Parfums um ätherische oder um aromatisierte fette Öle handelte, ist nicht bekannt. In Verbindung mit der Alkoholdestillation lebte die Destillationskunst ab dem 9. Jahrhundert bei den Arabern wieder auf. Hauptaugenmerk der Destillationsbücher bis zum 16. Jahrhundert lag auf den "gebrannten Weinen" und "gebrannten Wässern". Im 17. Jahrhundert begann die halbindustrielle Herstellung ätherischer Öle, die zunächst der Parfum- als der Arzneimittelherstellung diente. Seit 1826 setzte man die Dampfdestillation in Industrie und Laboratorien ein, aus der sich die bis heute übliche Destillation mit gespanntem Wasserdampf entwickelte. Die Entwicklung von Herstellungs- und Analysemethoden lässt sich anhand der Arzneibuchliteratur nachvollziehen. In der "Pharmacopoea Germanica" (1872) war den ätherischen Ölen nur ein kurzer Abschnitt gewidmet. Erst spät, im DAB 5 (1910) und DAB 6 (1926), wurden die Prüfungen für ätherische Öle vermehrt. Den Grundstein für die Entwicklung moderner Analysemethoden legte die Strukturaufklärung der Inhaltsstoffe ätherischer Öle durch Otto Wallach (1847–1931) und die synthetische Herstellung durch Friedrich Wilhelm Semmler (1860–1931).

Ätherische Öle werden je nach Eigenschaft unterschiedlich genutzt. Häufig steht der Einsatz als Duftstoff in Kosmetik- und Parfümindustrie im Vordergrund, aber auch als medizinische Wirkstoffe und als technische Lösungsmittel haben bestimmte ätherische Öle Bedeutung.

Sie werden in der Kosmetikindustrie und zur Wohnraumaromatisierung in Duftlampen verwendet. Zudem haben sie Bedeutung als geschmacksverbessernde Inhaltsstoffe in Gewürzen und anderen Lebensmitteln. Einige in großem Umfang produzierte Öle wie Orangenschalenöl und Terpentinöl werden auch als technische Lösemittel benutzt.

Einige nicht verschreibungspflichtige Arzneimittel enthalten ätherische Öle als Wirkstoffe, z. B. Eukalyptus oder Menthol zur Schleimlösung bei Katarrhen der oberen Atemwege, Bronchitis, etc. Auch Wirkungen gegen Blähungen und Krämpfe im Magen-Darm-Bereich, z. B. durch Tees mit Fenchel-Kümmel-Anis, besonders in der Kinderheilkunde, und bei Entzündungen im Mund- und Rachenraum (Salbei, Kamille), werden auf ätherische Öle zurückgeführt.

Eine zentrale Rolle spielen ätherische Öle bei der naturheilkundlichen Methode der Aromatherapie, eine Form der Pflanzenheilkunde zur Behandlung von Empfindungsstörungen und Erkrankungen durch Duftstoffe. Neben der Anwendung durch Therapeuten (in der Regel Heilpraktiker) ist auch die Selbstbehandlung durch Duftlampen, Badezusätze, Saunaaufgüsse oder Tees verbreitet, wobei die Grenzen zwischen Heilbehandlung und reiner Wohnraumaromatisierung fließend sind.

Die meisten ätherischen Öle sind hautreizend und werden daher nur stark verdünnt angewendet, z. B. als Bestandteil ölbasierter Hautpflegeprodukte oder in Verbindung mit Pflanzenölen. Allergien und Unverträglichkeiten gegenüber ätherischen Ölen kommen vor, ebenso asthmatische Anfälle bei Personen, die auf einzelne Substanzen (z. B. Menthol) empfindlich reagieren. Häufig treten bei einer Unverträglichkeit gegenüber bestimmten Pflanzen auch Reaktionen auf die entsprechenden ätherischen Öle auf.

Ätherische Öle gelangen relativ leicht beim Hautkontakt oder beim Einatmen in den Blutkreislauf und das Gewebe. Beim Schlucken von Arzneien wird ein Teil der Wirkstoffe über den Magen-Darm-Trakt aufgenommen, größtenteils gelangen sie aber über die Mundschleimhaut in den Blutkreislauf. Sie beeinflussen den gesamten Organismus: Über die Sinneszellen der Nase gelangen die Duft-Informationen in das Gehirn. Nach der Aromatherapie üben die Düfte Einfluss auf die Gefühle, das vegetative Nervensystem, die Hormon-Produktion oder das Immunsystem aus.

Einige ätherische Öle besitzen ein hohes Allergiepotenzial. Es betrifft nicht nur künstliche ätherische Öle, sondern vor allem auch natürliche. In Deutschland leben nach einer Studie des Umweltbundesamtes mindestens 500.000 Duftstoff-Allergiker. Besonders problematisch ist es, wenn natürliche ätherische Öle wie Geraniol, Linalool oder Limonen als Aerosol verdampfen und am Luftsauerstoff oxidieren. Dabei entstehen stark sensiblisierend wirkende Oxidationsprodukte, die asthmaartige Symptome auslösen können oder die Atemwegsorgane schädigen. Die Verwendung solcher Öle in Duftlampen oder in Haushalts-Produkten wie Haarsprays oder Cremes ist problematisch, weil sie durch Verdampfen in einer Wohnung oder im Schlafzimmer verbreitet werden. Nicht ohne Grund hat das Wissenschaftliche Beratungskomitees der EU (SCCNFP) eine Liste mit 26 sensibilisierend wirkenden deklarationspflichtigen Duftstoffen publiziert. Die Liste richtet sich nach den Untersuchungen des Informationsverbundes Dermatologischer Kliniken (IVDK). Es existieren auch ätherische Öle wie Estragol mit dem Verdacht auf ein krebserzeugendes Potenzial.

Ätherische Öle hinterlassen im Gegensatz zu den fetten Ölen keine Flecken auf Textilien, was darauf zurückzuführen ist, dass sie vollständig verdunsten. Aus diesem Grund werden in Parfums häufig ätherische Öle eingesetzt. Da die meisten ätherischen Öle stark haut- und schleimhautreizend sind, werden sie mit Wasser oder Alkohol verdünnt. Wie hoch die Konzentration des enthaltenen Duftstoffes in einem Parfum ist, erkennt man bereits am Namen. Das „Eau“ im Eau de Parfum steht für Wasser und kennzeichnet damit ein verdünntes Parfum. Produkte mit der Bezeichnung Parfum haben die höchste Konzentration an ätherischen Ölen (bis zu 40 %), dann folgt das Eau de Parfum (bis zu 15 %), das Eau de Toilette (bis zu 8 %), die geringste Konzentration an ätherischen Ölen hat das Eau de Cologne (bis zu 4 %). Stark verdünnte Parfums werden auch als Duftwasser bezeichnet.

Zur Differenzierung der ätherischen Öle werden die Bezeichnungen naturbelassen, natürlich, naturidentisch und künstlich verwendet. Naturbelassene Öle werden direkt aus Pflanzen gewonnen. Unterschieden werden die Öle nach Herkunft, Eigenschaften, Prozess- und Produktqualität. Die Beschreibung eines naturbelassenen Öls kann umfassen:


Natürliche Öle bestehen aus mehreren naturreinen Komponenten, werden also nicht ausschließlich aus der namensgebenden Pflanze gewonnen. Natürliche Öle dürfen keine synthetischen Zusätze enthalten. Eine Mischung eines naturreinen Öles mit synthetischen Zusätzen bezeichnet man als natürlich/naturidentisch (N/NI).

Die Bestandteile naturidentischer Öle werden nach dem Vorbild der chemischen Zusammensetzung natürlicher ätherischer Öle synthetisch hergestellt, so dass sie ähnlich wie natürliche Öle riechen. Die Zusammensetzung naturidentischer Öle ist häufig weniger komplex als die der natürlichen Varianten, so besteht beispielsweise naturidentisches Rosmarinöl aus ca. elf Bestandteilen, während das naturbelassene ätherische Öl ca. 150 Inhaltsstoffe hat.

Künstliche Öle kommen in der Natur nicht vor. Sie werden gezielt auf einen bestimmten Geruch hin entworfen. 

Im Gegensatz zu den fetten Ölen werden ätherische Öle nicht ranzig. Allerdings können einige ätherische Öle bei unsachgemäßer Aufbewahrung mit dem Luft-Sauerstoff oxidieren, so dass toxische Reaktionsprodukte entstehen. Auch Reaktionen zwischen den Komponenten in einem Parfum sind möglich. Auf diese Art und Weise kann ein Parfum wie ein guter Wein „reifen“.

Der weltweite Markt für insgesamt rund 120 verschiedene ätherische Öle wird auf über 600 Mio. € geschätzt, die Nachfrage ist relativ stabil bei 50.000 bis 60.000 Tonnen pro Jahr, davon rund ein Drittel Zitrusöle. Mehr als 50 % der Menge auf dem Weltmarkt stammt aus China. In Deutschland werden kaum ätherische Öle produziert, da die wenigsten Ursprungspflanzen für die Öle in heimischem Anbau gedeihen. Wegen der sehr energieintensiven Destillation sind die Energiekosten ein weiterer Standortnachteil. Die Produktion in Deutschland ist lediglich bei Kamille und Zitronenmelisse wirtschaftlich.




</doc>
<doc id="10711" url="https://de.wikipedia.org/wiki?curid=10711" title="Stadtbahn">
Stadtbahn

Eine Stadtbahn – oft (vor allem außerhalb des deutschen Sprachraums) auch Metro genannt (aus Kurzform von "" ‚Stadtbahn‘) – ist ein Schienenverkehrssystem des öffentlichen Personennahverkehrs (ÖPNV).

In der Geschichte sind hauptsächlich drei Perioden zu unterscheiden. Besonders populär ist dabei die Entwicklung ab den 1970er Jahren in Westdeutschland, die sich als eine Mischform aus U-Bahn und Straßenbahn darstellt. Während diese Bahnen in Innenstädten oder an anderen verkehrlichen Engpässen hauptsächlich wie U-Bahnen in Tunneln und streckenweise auch als Hochbahn oder im Trog verkehren, haben andere Strecken einen modifizierten, ausgebauten Straßenbahncharakter. Berücksichtigung findet eine Verkehrstrennung (vgl. autogerechte Stadt); auch Strecken an der Oberfläche verlaufen überwiegend auf besonderen Bahnkörpern, niveaugleiche Kreuzungen mit dem Individualverkehr werden eisenbahnähnlich gesichert. Diese Bahnsysteme waren als Vorstufe für einen später vollständig auf unabhängige Bahnkörper umgestellten Betrieb gedacht. Wegen der hohen Baukosten wurde hiervon jedoch in fast allen Fällen Abstand genommen (Ausnahmen u. a. Wien, Brüssel).

Der Begriff "Stadtbahn" kam in der zweiten Hälfte des 19. Jahrhunderts auf und stammt ursprünglich von der Eisenbahn ab. Eine alternative Bezeichnung lautet daher "Stadteisenbahn". Bereits 1869 legte in Wien Baurat Carl von Schwarz einen sogenannten „Stadtbahnentwurf“ ein. Damit war für die 1898 eröffnete Wiener Dampfstadtbahn – die 1925 von der Wiener Elektrischen Stadtbahn abgelöst wurde – ein Name fixiert, der bald in den allgemeinen Sprachgebrauch überging. Spätestens ab 1872 war der Begriff auch in Berlin geläufig, als sich die Planungen für die 1882 eröffnete Berliner Stadtbahn konkretisierten.

Während es sich in Berlin und Wien um klassische Vollbahnen auf unabhängigem Bahnkörper handelte, eröffnete in Kassel 1884 eine klassische Pferdestraßenbahn, die von der im gleichen Jahr gegründeten "Actiengesellschaft Casseler Stadteisenbahn" betrieben wurde. Diesem Beispiel folgte die am 30. August 1889 eröffnete "Stadtbahn Halle", wiederum eine Pferdestraßenbahn. Sie erhielt ihren Namen in Abgrenzung zur konkurrierenden "Halleschen Straßenbahn-AG" und wurde schon 1890, anlässlich der bevorstehenden Elektrifizierung, in "Allgemeine Elektricitäts-Gesellschaft Stadtbahn Halle" umbenannt.

Analog zu Kassel und Halle eröffneten in den folgenden Jahren weitere elektrische Straßenbahnen, bei denen die Bezeichnung "Stadtbahn" Bestandteil des Betreibernamens war. Darunter die am 30. Dezember 1896 durch die Berliner Union-Elektricitäts-Gesellschaft (UEG) gegründete "Solinger Stadtbahn" sowie in Österreich die 1902 eröffnete Elektrische Stadtbahn Marienbad und die 1909 elektrifizierte Stadtbahn Salzburg. Auch die 1905 eröffnete erste Strecke der Straßenbahn Innsbruck wurde in Abgrenzung zur etwas älteren Lokalbahn nach Hall ursprünglich Stadtbahn genannt.

Analog dazu trugen auch einige, damals üblicherweise zweisprachig protokollierte, Straßenbahn-Aktiengesellschaften in der transleithanischen Landeshälfte Österreich-Ungarns um die Jahrhundertwende den Begriff Stadtbahn offiziell im Namen:

Unter der Bezeichnung "Hamburg-Altonaer Stadt- und Vorortbahn" wurde 1906 zwischen den damaligen Städten Blankenese, Altona (Elbe) und Hamburg eine weitere "Stadtbahn" eröffnet, die heutige S-Bahn Hamburg, der vertraglich vereinbarte elektrische Betrieb begann allerdings erst im Folgejahr. Im heute französischen Mülhausen verkehrte außerdem zwischen 1908 und 1918 die sogenannte Gleislose Stadtbahn Mülhausen, ein früher Oberleitungsbus-Betrieb.

Eine Unterscheidung von zwei Systemtypen (vergleichbar mit heutigen S- beziehungsweise U-/Stadtbahnen) findet sich bereits in Meyers Konversationslexikon von 1908: „"Stadtbahnen bleiben entweder auf den binnenstädtischen Personenverkehr, unter Umständen nebst gepäcklosem Vorortverkehr, beschränkt und sind dann hinsichtlich ihrer Bau- und Betriebsart ganz unabhängig, können also den Eigenheiten des großstädtischen Personenverkehrs in vollkommenster Weise angepasst werden; oder sie ermöglichen an ihren Endpunkten wie an andern Stellen mittels direkten Anschlusses an äußere Fern- und Vorortbahnen den Übergang von Zügen zu und von diesen Bahnen und nehmen dann den Fern-, Vorort- und binnenstädtischen Personenverkehr, unter Umständen auch Güterverkehr, auf."“

Der Begriff S-Bahn für "Stadtschnellbahn" und das weiße S auf grünem Grund als Symbol wurden allerdings erst im Dezember 1930 eingeführt, als bei der S-Bahn Berlin die Elektrifizierung des dortigen Vorortnetzes so gut wie abgeschlossen war.

Ab den 1960er Jahren wurden in Deutschland immer mehr Straßenbahnstrecken in den Innenstädten in Tunnel verlegt. Während kaum ausgebaute Straßenbahnsysteme mit wenigen in den Tunnel verlegten Strecken als U-Straßenbahnen bezeichnet werden, etablierte sich der Begriff "Stadtbahn" für die modernisierten Systeme mit einem hohen Anteil an Tunnelstrecken. Im Köln-Bonner Raum (Köln gilt als Vorbild für andere vergleichbare Systeme) wurde sogar der regionale, ehemals als Eisenbahn betriebene Teil, zur „Stadtbahn“ ernannt. Weitere Entwicklungen verwendeten dafür Bezeichnung wie "Regionalstadtbahn" oder "RegioTram". Im französischsprachigen Ausland werden vergleichbare Systeme als „Métro léger“ oder „Prémétro“ bezeichnet, wobei der zweite Begriff den Betrieb der Tunnelstrecken mit Straßenbahnen als Vorläufer einer kreuzungsfreien U-Bahn bezeichnet. Andere Länder verwenden „Schnellstraßenbahn“ (z. B. niederländisch "sneltram").

In einer dritten Verwendungsperiode des Begriffs wird lediglich auf die rein innerstädtische Bedienung der Bahnen Bezug genommen – vergleichbar dem Stadtbus. So wird u. a. die herkömmlich gebaute Straßenbahn Erfurt heute als Stadtbahn bezeichnet. Der Begriff entwickelt sich in diesem Sinne auch zu einer Sammelbezeichnung für sämtliche innerstädtischen schienengebundenen Verkehrsmittel und kann Straßen-, U- und S-Bahn- oder Stadtbahnsysteme nach 1970er Vorbild (die „eigentlichen“ Stadtbahnen) umfassen. Eine "Stadtbahn" ist damit kein besonderer Verkehrsträger mehr, sondern einfach eine Bahn der Stadt und gleichzeitig Straßen-, U- oder S-Bahn.

Im englischen Sprachraum ist die Bezeichnung "" (kurz "," siehe auch "Boeing LRV") verbreitet. Er bezeichnet jedoch gegenüber dem deutschen Begriff "Stadtbahn" unterschiedlichere ÖPNV-Verkehrssysteme, die gegenüber herkömmlichen Straßenbahnen höherwertige Standards haben, jedoch nicht den Kriterien einer vollwertigen U-Bahn entsprechen.
"Light-rail" (engl. Leichtbahn) ist das Gegensatzwort zu "Heavy-rail" (engl. Schwerbahn) für Stadtschnellbahnen und Regionalbahnen. Während letztere auch auf Vollbahnstrecken verkehren können, fahren Stadtbahnen ähnlich wie Straßenbahnen größtenteils in einem eigenen Gleisnetz.

In der neueren Bedeutung wird "Light Rail" zur Charakterisierung von "" "()" / Stadtbahnsystemen genutzt, die eine höhere Kapazität und höhere Geschwindigkeit als Straßenbahnen haben, aber mit leichteren Fahrzeugen und geringeren Anforderungen an die Sicherungssysteme als die überregionalen Eisenbahnstrecken auskommen.

Die Bezeichnung ' wurde erstmals 1972 von der US-amerikanischen "Urban Mass Transportation Administration" (ab 1991 ' kurz ') verwendet, die Regelungen für den städtischen Personennahverkehr (einschließlich Monorails, Fähren, u. ä.) erlassen. Ursprünglich wollte man den deutschen Begriff "Stadtbahn" übernehmen, in der direkten englischen Übersetzung "," entschied sich dann jedoch anders. Das "light" beziehungsweise „leicht“ steht hierbei nicht für das Gewicht (auch wenn die Fahrzeuge im Regelfall leichter sind als Vorortbahnen), sondern für leichtere Anforderungen / geringere Passagierzahlen "(intended for light loads and fast movement)". Außerdem sind die Investitionen in Strecken „leichter“ zu machen, also mit geringeren Kosten und einfacheren Streckeneinrichtungen. Wörtlich heißt es ' Obwohl von dieser Definition nicht erfasst, verwenden auch einige dieselelektrische Bahnen die Bezeichnung Light-rail, z. B. der O-Train in Ottawa.

Unter den Begriff Light-rail-transit fallen auch Tram-Train- und Schienenbus-Konzepte (mit ihren "Leichtverbrennungstriebwagen"), die im deutschen Sprachraum eher unter den Nebenbahnen eingeordnet werden und der früheren Kategorie der Nahverkehrszüge entsprechen, z. B. die River Line in New Jersey. Nicht darunter fallen jedoch die im britischen Englisch mit "" bezeichneten Feldbahnen.

Nach dem Erlass über Verwendung von Stadtbahnen wurde das erste Light-rail-Nahverkehrssystem 1978 in Edmonton (Kanada) errichtet. Verwendet wurden für den Edmonton LRT dort die Siemens-Duewag U2-Stadtbahnwagen. Die neueren Stadtbahnsysteme waren so erfolgreich, dass mittlerweile mehr als 30 LRT-Systeme in den USA existieren. Man beachte, dass in der US-amerikanischen Verwendung auch viele Straßenbahnsysteme als LRT eingeordnet werden – man wählt die Bezeichnung ' hier in Abgrenzung zum vorherigen "streetcar," das auch andere über Straßenwege geführte Nahverkehrsmittel umfasste. Der Begriff ' verbleibt jedoch bei Systemen mit zumindest teilweise eigenen Trassen ("").

In Großbritannien dagegen wurden ehemalige Vorortbahnen zu LRT-Systemen umgebaut, wobei man im Rückgriff auf den Light Railways Act von 1896 diese als Light-rail bezeichnete, auch wenn sie eher einer S-Bahn gleichen, z. B. die Tyne and Wear Metro in und um Newcastle. Der Trend setzte sich mit der Docklands Light Railway (DLR) in London (1987) und dem Manchester Metrolink (1992) fort. Der Manchester Metrolink verdeutlicht den Light-Rail-Trend, denn dort wurden bestehende Eisenbahnvorortstrecken als LRT-Link reaktiviert und untereinander verbunden, indem die Züge in der Stadtmitte als Straßenbahn (mit Hochbahnsteigen) verkehren, und damit den Bau eines teuren Eisenbahntunnels unter der Stadt (Picc-Vic-Tunnel) nicht benötigen.

Neuere Light-Rail-Strecken werden vor allem für Niederflurwagen errichtet, die mit niedrigen Bahnsteighöhe harmonieren. Neben geringen Stationskosten erlaubt dies auch eine größere Flexibilität, denn auch wenn die LRT-Strecken im Regelfall eigene Bahnkörper aufweisen, ist trotzdem fallweise ein straßenbündiger Betrieb wie bei der klassischen Straßenbahn möglich. Im Vergleich zu historischen Straßenbahnen, bei denen meist Züge mit ein bis drei Wagen fuhren, sind Light-Rail-Züge meist länger – durch die Nutzung von Vielfachsteuerung bis zu zehn Wagen. Dies gründet sich auch darauf, dass Busse im Vergleich mit einzelnfahrendenen Straßenbahnwagen vergleichbare Kapazität zu geringeren Anlagenkosten ermöglichen, sodass neuere LRT-Strecken nur bei entsprechendem Fahrgastaufkommen errichtet werden.

Die meisten Stadtbahnen sind Mischsysteme, die sowohl kreuzungsfreie Abschnitten im Tunnel (Untergrundbahn), Hochbahnteile, Strecken im Einschnitt oder ebenerdig als auch klassische Straßenbahnstrecken enthalten. Stadtbahnen besitzen meist einen eigenen Gleiskörper. Sie haben – anders als die völlig vom übrigen Verkehr getrennten U-Bahnen – niveaugleiche Kreuzungen mit dem Straßenverkehr. Kreuzungsfreie Stadtbahnstrecken sind in der Regel signalgesichert. Straßenbahnähnliche Strecken werden dagegen meist auf Sicht betrieben. Stadtbahnen werden häufig durch Ampelvorrangschaltung an Kreuzungen beschleunigt.

Die meisten älteren Stadtbahnsysteme nutzen Hochflurfahrzeuge. Für einen stufenlosen Einstieg in die Züge haben alle Tunnelbahnhöfe dieser Systeme Hochbahnsteige, wodurch sie kaum von echten U-Bahnhöfen unterscheidbar sind. Wegen eines Mischbetriebs mit Niederflurwagen wurden jedoch in einigen Städten wie z. B. Köln nicht alle Stationen von Anfang an mit Hochbahnsteigen ausgestattet. In Duisburg fahren bis heute Straßenbahnzüge durch den Tunnel der Stadtbahn, weshalb in den Tunnelbahnhöfen sowohl Hoch- als auch Niedrigbahnsteig-Abschnitte vorhanden sind. An den Anschlussstrecken an der Oberfläche wurden beim Stadtbahnbau an den meisten Haltestellen ebenfalls Hochbahnsteige angelegt. In manchen Städten gibt es jedoch weiterhin Haltestellen an der Oberfläche ohne Hochbahnsteige, sei es wegen eines Mischbetriebes mit klassischen Straßenbahnfahrzeugen oder aus Platzgründen oder ästhetischen Gründen. Beim Mischbetrieb mit Fernbahnfahrzeugen sind aus Gründen des unterschiedlichen Lichtraumprofils ebenfalls keine stufenlosen Hochbahnsteige realisierbar. Für Haltestellen ohne Hochbahnsteige besitzen viele Hochflur-Stadtbahnwagen Klapptrittstufen.

Neuere Stadtbahnsysteme werden dagegen meistens mit Niederflurwagen betrieben, die keine Hochbahnsteige benötigen und auch an schlecht ausgebauten Haltestellen, an denen es gar keine Bahnsteige gibt, einen relativ einfachen Einstieg ermöglichen. Die Kosten für die Umrüstung bestehender Straßen-, aber auch Eisenbahnstrecken können dadurch gering gehalten werden. Auch in Köln entschied man sich in den 1990er Jahren, zwei Stammstrecken und die dazugehörigen Linienäste nicht mit Hochbahnsteigen auszurüsten und die wenigen bereits gebauten Hochbahnsteige wieder abzubauen. Durch den Einsatz von Niederflur-Stadtbahnwagen verschwimmt die Grenze zwischen Stadtbahnen und Straßenbahnen jedoch immer mehr, auch weil normale Straßenbahnstrecken ohne größeren Ausbau, u. a. dem Bau von Hochbahnsteigen, an Tunnelstrecken angeschlossen werden können.
So wird zum Beispiel die 2006 eröffnete Tunnelstrecke der Bochumer Straßenbahn mit den als Straßenbahn bezeichneten, niederflurigen Linien 302 und 310 befahren (auch sämtliche andere Niederflurstrecken im Verkehrsverbund Rhein-Ruhr, außer folgender Ausnahme), während die 2007 eröffnete Ost-West-Strecke der Dortmunder Stadtbahn durch die Niederflur-Stadtbahnlinien U43 und U44 bedient wird.

Durchschnittliche Betriebsgeschwindigkeiten in Düsseldorf im Jahr 2002:

Anfang der 1960er Jahre suchten viele mittlere Großstädte nach neuen Wegen, um den öffentlichen Personennahverkehr neben dem Individualverkehr attraktiver zu gestalten und von diesem zu trennen. Die Stadtplaner empfanden die im zunehmenden PKW-Verkehr mitschwimmende Straßenbahn als Verkehrshindernis. Eine Umstellung auf reinen Busverkehr war oft wegen des hohen Fahrgastaufkommens nicht sinnvoll, wurde besonders in Westdeutschland jedoch in vielen Mittel- und auch Großstädten durchgeführt. Städte mit U- und S-Bahn-Systemen (u. a. Hamburg, Berlin) ersetzten Straßenbahnen durch gebrochene Verkehre und bauten Busbahnhöfe an Schnellbahnstationen. Der Bau reiner U-Bahn-Systeme erwies sich als zu teuer und zeitlich zu langwierig, daher gingen auch nur München (U-Bahn München) und Nürnberg (U-Bahn Nürnberg) diesen Weg. In beiden Städten blieben reduzierte Straßenbahnnetze als Ergänzung zur U-Bahn erhalten. Als Alternativmodell entstand die "Stadtbahn," die mindestens auf eigenem Gleiskörper, in Innenstadtbereichen aber unterirdisch geführt werden sollte und durch Rampen an bestehende Straßenbahnstrecken angeschlossen werden konnte. Damit ließen sich neue Tunnelabschnitte oder Gleisbetten recht schnell in bestehende Systeme integrieren. Auf das Gesamtnetz umgerechnet sind Stadtbahnen erheblich billiger als Voll-U-Bahnen, da eine bestehende Straßenbahn-Infrastruktur weiter genutzt werden kann, aber erheblich teurer als klassische Straßenbahnen, da sie erhebliche Tunnel- und Rampenbauten sowie häufig Hochbahnsteige an den Haltestellen erfordern.

Das erste Stadtbahnnetz mit U-Bahn-Strecken wurden 1966 in Stuttgart (Stadtbahn Stuttgart) eröffnet, es folgte Ende 1968 Frankfurt am Main (Stadtbahn Frankfurt am Main) und Köln (Stadtbahn Köln als Unterpflaster-Straßenbahn). Außer in Frankfurt wurden zuerst normale Straßenbahnfahrzeuge eingesetzt. In Frankfurt am Main wurden auf der Linie U5 bis 2016 straßenbahnkompatible Stadtbahnwagen mit Klapptrittstufen (Typ Ptb) eingesetzt.
In Stuttgart wurden nur von Meter- auf Normalspur umgerüstete Strecken als Stadtbahn bezeichnet, inzwischen ist das Gesamtnetz umgespurt.

Die Tunnelanlagen wurden daher so ausgelegt, dass diese von normalen Straßenbahnwagen befahren werden konnten. Da die meisten Betriebe Einrichtungswagen einsetzten, entstanden in der Überzahl der Stadtbahnstädte in den Tunnelbahnhöfen Seitenbahnsteige – zuerst in niedriger Höhe. Mit dem Übergang zu speziellen Stadtbahnwagen (z. B. Stadtbahnwagen B) wurden auf Stadtbahnstrecken vermehrt Mittelbahnsteige eingebaut. Diese entstanden gleich als Hochbahnsteige, die Seitenbahnsteige wurden in fast allen Betrieben mit Stadtbahnwagen zu Hochbahnsteigen umgebaut.

Im Ruhrgebiet und Düsseldorf (Stadtbahnnetz Rhein-Ruhr) sowie Frankfurt am Main und Stuttgart tragen Stadtbahnlinien das von echten U-Bahn-Systemen (Berlin, Hamburg, München, Nürnberg) bekannte „U“ vor der Liniennummer, wobei das „U“ nicht in jedem Fall für 'Untergrundbahn' stehen muss: so bedeutet es in Stuttgart 'unabhängig'. Die Zugänge zu den Bahnsteigen oder Bahnhöfen der Stadtbahnen sind aus werblichen Gründen ebenfalls mit dem entsprechenden Hinweisschild (weißes U auf blauem Grund) ausgestattet.

In Hannover (Stadtbahn Hannover; Eröffnung 1975) sind die Zugänge zu den U-Bahn-Stationen und die Haltestellen an der Oberfläche mit einem Hochbahnsteig mit einem modifizierten U-Zeichen versehen (farbliche Absetzung der oberen beiden Enden des U: durch dieses „Ü“ wird somit auch auf die Betreiberin üstra Hannoversche Verkehrsbetriebe hingewiesen). Die verbliebenen oberirdischen Haltestellen mit Niedrigbahnsteigen werden langfristig mit Hochbahnsteigen ausgerüstet werden. Sie sind mit dem klassischen grün-gelben „H“-Zeichen gekennzeichnet.

In Köln sind alle Haltestellen, die sich im Tunnel und auf aufgeständerten Strecken befindlichen sowie jene an der Oberfläche, die einem vollständigen Ausbau nach Stadtbahn-Standard entsprechen, mit dem klassischen blauen „U“ gekennzeichnet. Köln war Vorbild für andere Städte, u. a. für die Stadtbahn Bielefeld. Karlsruhe verwendet auf den Stadtabschnitten der Mischbetriebsstrecken als einziger Betrieb das S-Bahn-Symbol.

Der Begriff „Stadtbahn“ hat sich im allgemeinen Sprachgebrauch nicht durchgesetzt. In weiten Bevölkerungskreisen werden die Netze daher trotzdem als U-Bahn wahrgenommen. Das ist vielen Betrieben recht, da sich die Marke „U-Bahn“ als sehr werbewirksam erweist und eine Reminiszenz an eine Metropole gestattet. Andererseits wird der in der lokalen Bevölkerung weiterhin gebräuchliche Begriff „Straßenbahn“ von einigen Unternehmen (z. B. Bielefeld) massiv bekämpft.

Ein späterer Übergang zu reinem U-Bahn-Betrieb war bei vielen Systemen (Frankfurt am Main, Hannover, Stuttgart) berücksichtigt, doch diese Entwicklung erscheint derzeit als extrem unwahrscheinlich.

In Düsseldorf (Stadtbahn Düsseldorf) wird die Wehrhahnlinie mit den Stadtbahn-Linien U71, U72 und U73 mit Niederflurwagen betrieben, da für den oberirdischen Einsatz dieser Fahrzeuge weniger störende besondere Ausbauten (Tief- anstatt Hochbahnsteige) nötig sind als bei einer herkömmlichen hochflurigen Stadtbahn. Dies zeigt sich unter anderem an den Linien U78 und U79, die streckenweise immer noch mehr an eine Straßen- als an eine Stadtbahn erinnern.

In Hannover ist die Umwandlung der Straßenbahn zu einer Stadtbahn seit 1996 weitgehend abgeschlossen, in Stuttgart ist dies seit 2008 der Fall. In anderen Städten wird neben der Stadtbahn auch weiter an der herkömmlichen Straßenbahn (Bonn, Düsseldorf, Frankfurt, Essen, Oberhausen), allerdings in Niederflurausführung, festgehalten. Das Stadtbahnnetz in Köln ist als Besonderheit in ein Hoch- und Niederflurnetz geteilt. In Mülheim an der Ruhr, Essen und Bochum werden im Tunnel liegende Meterspur-Abschnitte als Straßenbahnlinien geführt und zunehmend mit modernen niederflurigen Straßenbahnwagen befahren, während die älteren Hochflurwagen mittelfristig abgelöst werden sollen. In Duisburg verkehren Straßen- und Stadtbahnlinien auf gemeinsamen Strecken. Dort verfügen die Straßenbahnwagen lediglich über ein kurzes Niederflurteil-Segment. In Bielefeld wird die Stadtbahn als U-Straßenbahn in Meterspur betrieben, eine Umrüstung auf Normalspur wäre jedoch möglich.

In Dortmund wurde seit 1983 die klassische Straßenbahn durch eine Stadtbahn ersetzt. Dieser Umbau ist seit 2008 mit der Inbetriebnahme des Ost-West-Tunnels (Tunnel III) vorläufig abgeschlossen. Die Tunnelstrecken I und II sind bereits stadtbahnmäßig ausgebaut und werden mit hochflurigen Stadtbahnwagen des Typs B80C und B100S betrieben, doch im neuen Tunnel auf dem Ost-West-Netz kommen Niederflurstraßenbahnwagen des Typs Bombardier Flexity Classic zum Einsatz. Dadurch ist der Einstieg auch an den Haltestellen an der Oberfläche bereits wesentlich bequemer, allerdings wird der vollständige barrierefreie Ausbau dieser Haltestellen auf den neuen Stadtbahn-Linien U43 und U44 mit Tiefbahnsteigen noch bis voraussichtlich 2018 dauern.

Beim Tunnelbau wird zwischen dem Ausbau in Straßenbahn-Manier mit vielen niveaugleichen Kreuzungen und Abzweigen (typisch für Köln) und der Bauweise in U-Bahn-Manier mit meist kreuzungsfrei ausgeführten Abzweigen (Bielefeld, Stadtbahnnetz Rhein-Ruhr, Frankfurt, Hannover, Stuttgart) unterschieden. Die Trassierungselemente der Stadtbahn-Tunnelstrecken entsprechen weitgehend denen einer U-Bahn. Allerdings ist der Ausbau zum Teil teurer, da ein straßenbündiger Betrieb mit seitlichen Stromschienen aus Sicherheitsgründen unvertretbar ist. In dem Tunnelanlagen muss der Raum für die Fahrleitungsanlagen freigehalten werden. Daher muss das Tunnelprofil höher gehalten werden als bei mit Stromschienen betriebenen U-Bahnen. Bei den Neubaustrecken der letzten Jahre kommen zunehmend an der Tunneldecke aufgehängte Deckenstromschienen zur Anwendung.

Für die U-Bahn Frankfurt fertigte die DUEWAG 1965 erstmals zwei sechsachsige Stadtbahnwagen-Prototypen, die weitgehend auf den bisher gelieferten Straßenbahnwagen, wie dem N-Wagen basierten. Er wurde 1965 erstmals auf der Internationalen Verkehrsausstellung in München präsentiert. Neu waren die elektronische Steuerung des Typs Simatic und die Möglichkeit, mehrere Triebwagen zu Zugverbänden kuppeln zu können. Eine Serienfertigung unterblieb jedoch. Sie wurden hauptsächlich für Fahrschul- und Probefahrten verwendet und verkehrten nur wenige Jahre im Linienbetrieb. Sie wurden bereits 1976 abgestellt, da sie nicht mit den Stadtbahnwagen des Typs "U2" kuppelbar waren. Die mit den Prototypen gemachten Erfahrungen flossen in den Nachfolger "U2" ein, der in insgesamt 104 Exemplaren nach Frankfurt geliefert wurde und dort bis 04/2016 im Einsatz waren. Auch Edmonton, Calgary und San Diego beschafften in der Folgezeit U2-Triebwagen.

In der DDR wurden keine Stadtbahnen gebaut. Dort setzte man auf klassische Straßenbahnnetze mit vielen Linien, so dass dadurch eine höhere Flächendeckung (gegenüber Stadtbahnen) erreicht wurde. Neubaustrecken, die Neubaugebiete an den Stadträndern erschließen sollten, wurden allerdings weitgehend mit eigenen Bahnkörpern und möglichst großzügiger Trassierung angelegt.

Seit Mitte der 1990er Jahre bezeichnen einige reine Straßenbahnbetriebe ihre Netze als Stadtbahn. So wurde 1996 die Erfurter Straßenbahn per Stadtratsbeschluss in Stadtbahn Erfurt umbenannt. Auch die Freiburger Verkehrs AG ist dazu übergegangen, ihre Straßenbahnen als Stadtbahn zu bezeichnen. Die Stadt Chemnitz führte nach dem "Chemnitzer Modell" die Stadtbahn Chemnitz ein, bei der die Straßenbahn überwiegend vom Straßenverkehr getrennt ausschließlich oberirdisch und teilweise auf Eisenbahngleisen verkehrt. Den hier genannten Stadtbahnen gingen Streckenneu- und -ausbauten mit vom Individualverkehr unabhängigen Gleisführungen voraus, jedoch wurden keine Tunnelabschnitte eingeplant. Die Höchstgeschwindigkeit wurde erhöht (z. B. in den Außenbezirken von Erfurt auf 60 km/h), die Durchschnittsgeschwindigkeit im Stadtzentrum blieb aber gering. Der Begriff bezeichnet jetzt das rein "innerstädtische" Verkehrsmittel unabhängig vom Verkehrsträger. Eine Stadtbahn kann auf anderer Ebene auch einfach eine Straßenbahn sein.
Die Fahrzeuge verkehren weiterhin auf Sicht, werden aber durch besondere Bahnkörper vom Straßenverkehr getrennt und können diesem damit wie Schnellbahnen Konkurrenz machen. Angewendet wird im Gegensatz zum U-, S- und Eisenbahnverkehr bevorzugt die Niederflurtechnik. In Leipzig wurden nach 1990 drei stark frequentierte Straßenbahnlinien mit weitgehend eigenem Gleiskörper zu Stadtbahnlinien ausgebaut (siehe Leipziger Verkehrsbetriebe). In Dresden werden die Niederflurwagen seit Erstlieferung als Stadtbahnwagen bezeichnet und die Strecken dahingehend ausgebaut. Bis 2009 bestehen drei Tramlinien, die durchaus mit „klassischen“ Stadtbahnlinien konkurrieren können, da sie hauptsächlich vom Straßenverkehr getrennt sind. Ziel der Dresdner Verkehrsbetriebe ist ein nahezu kompletter Ausbau der Straßenbahnstrecken zu Stadtbahnstrecken.

Damit wird die Abgrenzung, ob es sich um eine Straßen- oder „klassische“ Stadtbahn handelt, verwischt. Nach diesem Konzept, das seine Vorteile vor allem in geringen Baukosten im Vergleich zu Stadtbahnen mit strikterer baulicher Trennung zum Straßenverkehr aufweist, wurde auch die politisch gescheiterte Stadtbahn Hamburg geplant, die teilweise zusammen mit dem Straßenverkehr geführt werden sollte.

Der Netzausbau erfolgte in einigen Städten durch Mitnutzung oder Reaktivierung von Eisenbahnstrecken, beispielsweise wurde die Straßenbahn Kassel auf die Bahnstrecke Kassel–Naumburg geleitet und bis Baunatal geführt. Im Raum Köln–Bonn entstand durch den Umbau zweier früherer Eisenbahnstrecken (Rheinuferbahn und Vorgebirgsbahn der ehemaligen Köln-Bonner Eisenbahnen) eine betriebliche Einheit (Hochflurstrecken) der Kölner Stadtbahn mit der 1974 eröffneten Stadtbahn Bonn.

Ebenso in Karlsruhe mit der Albtalbahn. Richtungsweisend war dann dort das „Karlsruher Modell“. Eingesetzt werden hier Zweisystemtriebwagen, die mit 750 Volt Gleichspannung aus der Straßenbahnfahrleitung und 15 kV Wechselspannung im Fernbahnnetz verkehren können. So werden Eisenbahn- (bzw. S-Bahn-) und Straßenbahnnetz umsteigefrei verbunden. Das oft kopierte, dabei manchmal variierte „Karlsruher Modell“ wird international, insbesondere in Frankreich, meistens als Tram-train bezeichnet, gelegentlich auch als „Light rail“ (s. o.).
Kiel erweitert die Begriffswelt um die StadtRegionalBahn Kiel, Saarbrücken um die Saarbahn, Kassel um RegioTram.
Im Zuge der Netzausdehnungen aus Stadtgebieten in Regionen und den teilweisen Einsatz von Mehrsystemfahrzeugen wurden neue Bezeichnungen wie "Regionalstadtbahn," "RegioStadtbahn" oder "City-Bahn," "Stadt-Umland-Bahn" gebildet. Vergleichbare Ausdrücke mit historischem Ursprung sind Kreisbahn, Lokalbahn, Überlandstraßenbahn. Ähnlich wie bei Busverkehren wurde auch hier „Überland“ durch „Regional“ ersetzt (Überlandbus → Regionalbus). „Regionalbahn“ bezeichnet heute in Deutschland jedoch ausschließlich einen klassischen Personenzug der Eisenbahn.
In Zwickau fahren dagegen als Regionalzüge verkehrende Dieseltriebwagen der Vogtlandbahn auf einer dreischienig ausgebauten Straßenbahnstrecke in die Innenstadt.

Folgende Stadtbahnsysteme befinden sich oder waren in Planung:

Darüber hinaus wird in den folgenden Städten und Regionen über Stadtbahnsysteme diskutiert:


In folgenden Städten und Regionen wurden die bereits diskutierten Stadtbahnpläne wieder verworfen:


In Wien gab es ab Ende der 1920er-Jahre bis 1945 bereits eine Kombination aus Straßenbahn und Stadtbahn. Damals wechselte die Straßenbahnlinie 18G vom Ostbahnhof kommend an der Gumpendorfer Straße zur Gürtellinie der Wiener Stadtbahn. Die verwendeten Triebwagen waren für den Straßenbahn- und Stadtbahnbetrieb geeignet – damit war diese Linie ein Vorläufer moderner Stadtbahnsysteme. Heute gehört die teils als Einschnittbahn, teils auf einem Viadukt verlaufende Gürtellinie zur U-Bahn (U6). Der Betrieb erfolgt heute mit Niederflurwagen.

Die Badner Bahn ist eine Überlandstraßenbahn mit Höchstgeschwindigkeit 80 km/h. Von der Wiener Oper bis Wien Schedifkaplatz sowie zwischen Baden Leesdorf und Baden Josefsplatz verkehrt sie als Straßenbahn, im Überlandbereich zwischen Wien Schedifkaplatz und Baden Leesdorf als Vollbahn auf eigenem Gleiskörper.

Im Großraum Innsbruck kann die Linie STB (frühere Bezeichnung: Stubaitalbahn) als Regionalstadtbahn bezeichnet werden. Sie verkehrt zwischen Fulpmes und Innsbruck-Wilten auf eigenem Gleiskörper und setzt ihre Fahrt von dort bis zum Hauptbahnhof auf Gleisen der Innsbrucker Straßenbahn teilweise im Mischverkehr fort. Sie ist rechtlich keine Straßenbahn, sondern eine Nebenbahn, wird aber mit denselben Fahrzeugen wie die Straßenbahnlinien betrieben. Seit 2003 läuft die infrastrukturelle Umrüstung auf Stadtbahnstandard, sie wird der Nord-Süd-Ast des künftig T-förmigen Innsbrucker Stadtbahnnetzes.

Die Linie 1 der Grazer Straßenbahn fährt in Fahrtrichtung Mariatrost ab der Haltestelle Hilmteich großteils auf einem eigenen Gleiskörper, da sie dem Streckenverlauf der ehemals eigenständigen Mariatroster Bahn folgt, die 1941 umgebaut und in das reguläre Straßenbahnnetz eingebunden wurde. Am Grazer Hauptbahnhof fahren seit November 2012 die Straßenbahnlinien 1, 3, 6 und 7 eine neue unterirdische Haltestelle am Bahnhofsvorplatz an, der Bahnhofgürtel wird ab dieser Haltestelle in einem Tunnel unterfahren.

Die Linzer Straßenbahn besitzt einen Innenstadttunnel, über den alle vier Linien den Hauptbahnhof anfahren. Dabei werden auch zwei unterirdische Stationen und eine nach oben geöffnete Haltestelle angefahren.
Bei den Strecken Salzburg–Lamprechtshausen und Bürmoos–Trimmelkam der Salzburg AG handelt es sich auf den Überlandabschnitten zwischen Salzburg Itzling und Lamprechtshausen beziehungsweise Trimmelkam um einen Stadtbahnbetrieb auf einer Vollbahnstrecke. Der bestehende Tunnelabschnitt zwischen Salzburg Itzling und Salzburg Lokalbahnhof und dessen geplante Verlängerung durch die gesamte Innenstadt, der sich derzeit in Planung befindet, ist eine reine Stadtbahnstrecke mit eingeschränktem Stadtbahn-Lichtraumprofil. Auf ihr kommen ausschließlich Stadtbahnfahrzeuge zum Einsatz. Die beiden Strecken sind in die S-Bahn Salzburg eingegliedert, es findet derzeit aus Mangel geeigneter Fahrzeuge (unterschiedliche Stromsysteme) im Personenverkehr jedoch kein Übergang zwischen dem Netz der Salzburg AG und ÖBB-Netz statt.

Ein kleines Teilstück der eingestellten schmalspurigen Ybbstalbahn wird im Raum Waidhofen als Stadtbahn weitergeführt, mit der Stadtbahn Waidhofen gibt es nach der Einstellung der Straßenbahn Ybbs in Österreich wieder eine Stadtbahn auf Bosnaspur (760 mm).

In der Schweiz werden verschiedene Nahverkehrsbahnen als Stadtbahnen bezeichnet. Die Glattalbahn verbindet mehrere Gemeinden und den Flughafen Kloten im Norden von Zürich mit drei Linien. Sie stellt eine Mischung aus Straßenbahn/Tram und einer Eisenbahn dar; der größte Teil der Glattalbahn ist eigentrassiert, und als Rollmaterial werden die als Cobra bekannten Tramfahrzeuge der Verkehrsbetriebe Zürich verwendet. Eine weitere Stadtbahn soll auf einer anderen Seite Zürichs mit der Limmattalbahn entstehen. Ähnlich präsentieren sich heute verschiedene Basler Vorortsstrecken, allerdings hat die BLT noch einige Einspurabschnitte.

Die Stadtbahn Lausanne (Linie m1) wurde beim Bau als Stadtbahn konzipiert, sie ist weitgehend einspurig mit Ausweichstellen und hat eisenbahnmässig gesicherte Strassenkreuzungen. Nach den sukzessiven Erneuerungen präsentiert sich heute die Überlandlinie 5 (ab Dezember 2013 Linie 215) Neuenburg–Boudry in gleicher Weise.

Viele schmalspurige Vorortsbahnen in der Schweiz sind durch Ausbauten und Modernisierungen zu einem Stadtbahn-ähnlichen Standard gekommen, allerdings verwenden sie Fahrzeuge mit der Standardbreite für Meterspurbahnen. Ausnahmen dazu sind die Forchbahn und die Trogenerbahn, die im Innenstadtbereich im Strassenbereich ohne Eigentrasse fahren.

Teilweise stadtbahnmässig ausgebaut sind heute auch die Tramnetze von Zürich (z. B. Tunnel nach Schwamendingen), Bern (z. B. Linie 9 nach Wabern, Linie 6 nach Worb), Genf (meist neu angelegte Strecken) und Basel (z. B. Linie 6 nach Riehen).

Die Stadtbahn Zug ist eigentlich eine S-Bahn, sie wird von den SBB mit Stadler FLIRT betrieben. Die Bezeichnung Stadtbahn geht darauf zurück, dass sechs Stationen in der Stadt Zug bedient werden, von denen fünf neu gebaut wurden. Dabei entsprechen die Stationsabstände durchaus einer Stadtbahn.

Ähnliche Systeme wie in Mitteleuropa entstanden teilweise als Eigenentwicklung, teilweise aber auch durch Übernahme von Konzepten aus Österreich (Unterpflasterstraßenbahn in Wien) oder Deutschland (Karlsruher Modell). In Nordamerika wird oft die Bezeichnung "MetroRail" (Kurzform von "Metropolitan rail") verwendet, in romanischen Ländern teilweise "Métro légér/Metropolitana leggera".

Das Stadtbahnnetz in Newcastle upon Tyne (Großbritannien) besteht seit 1984. Dort wurden neben neuen Tunnelanlagen auch Eisenbahnstrecken ins Netz einbezogen. Manchester und Birmingham erhielten ebenfalls Stadtbahnsysteme. Für die Midland Metro Birmingham–Wolverhampton wird die Bezeichnung MetroTram verwendet.

In London entstand mit der Docklands Light Railway (DLR) ein System, das auf Stadtbahntechnik mit den entsprechenden Fahrzeugen basiert, aber fahrerlos und mit Stromschiene – zum Teil auf ehemaligen Eisenbahnstrecken – betrieben wird. Ein Teil der dort beschafften Wagen ist seit einigen Jahren nach Umbauten mit Fahrern auf Essener Normalspur-Stadtbahnstrecken mit Oberleitung im Einsatz.

In Alicante (Spanien) wurde eine bestehende Schmalspurbahnstrecke zu einem Regiostadtbahnsystem weiter entwickelt. Die Stadtbahn Alicante wurde im Mai 2007 mit dem ersten Teil des Innenstadttunnels und zwei Tunnel-Stationen in Betrieb genommen.

In Porto (Portugal) entstand die Metro do Porto. Die Bahn benutzt neue Tunnelstrecken im Innenstadtbereich und von Meter- auf Normalspur umgerüstete Eisenbahnstrecken.

Stadtbahnsysteme, die teilweise als Straßenbahn geführt werden und teilweise als Untergrund- oder Hochbahn bzw. auf innerörtlichen Abschnitten von Eisenbahnstrecken, werden mancherorts als Métro léger („Leichte Metro“) oder auch als Metro-Tram bezeichnet, so die aus einer bestehenden Straßenbahn entwickelte Métro léger de Charleroi in Belgien, seit 1985 die Métro léger de Tunis (المترو الخفيف لمدينة تونس / al-Mītrū al-chafīf al-Madīna Tūnis). Auch die am 12. Dezember 2012 eröffnete Tram von Casablanca (ترامواي الدار البيضاء / Trāmwāy ad-Dār al-Bayḍā') wird teilweise als „Métro léger“ bezeichnet.

In Italien existieren zwei Straßenbahnstrecken, die auf alten Eisenbahntrassen gebaut wurden und als Schnellstraßenbahnen betrieben werden. Sie werden als "Metrotranvia" bezeichnet und verkehren in Bergamo (Stadtbahn Bergamo–Albino) und in Cagliari (Stadtbahn Cagliari). Die in den 1980er Jahren als Stadtbahnen in Genua und Neapel entworfenen Systeme wurden heute als reine U-Bahnen betrieben, also die U-Bahn Genua sowie die Linie 6 der U-Bahn Neapel.

In Polen existieren in zwei Straßenbahnnetzen stadtbahnmäßig ausgebaute und betriebene Abschnitte. In Posen existieren zwei kreuzungsfreie Stadtbahnlinien. Die ältere der Strecken im Nordwesten der Stadt, die teilweise im Einschnitt und teilweise als Hochbahn gebaut wurde, wird (2013) ins Stadtzentrum von Posen im Einschnitt und in einem Tunnel verlängert. Die neuere Strecke im Südosten der Stadt ist im Einschnitt und im Tunnel mit zwei glasüberdachten Tunnelhaltestellen geführt. Ebenfalls existiert in Krakau eine Stadtbahnlinie mit einem Tunnel und zwei Stationen. Die Stadtbahnen in Posen und Krakau werden von Niederflurfahrzeugen bedient und tragen eine Bezeichnung "Schnelle Straßenbahn" ("Szybki tramwaj"). In anderen polnischen Städten handelt es sich hingegen bei den Strecken, die als "Schnelle Straßenbahn" bezeichnet werden, um konventionelle Straßenbahnlinien mit niveaugleichen Kreuzungen.

In den Niederlanden fahren einzelne Linien der Metros in Amsterdam und Rotterdam abschnittsweise als Stadtbahn, dort als "Sneltram" bezeichnet. Die Fahrzeuge werden dabei in den Tunnelstrecken durch eine Stromschiene versorgt, auf den Stadtbahnabschnitten dagegen wie üblich durch eine Oberleitung. Die Sneltram Utrecht ist als reines Stadtbahnsystem weitgehend mit den Hochflurnetzen im Ruhrgebiet oder Köln vergleichbar, besitzt jedoch keine Tunnelstrecken. In der Region Den Haag ist 2006 das Stadtbahnnetz RandstadRail in Betrieb genommen worden, das neben umgebauten Eisenbahnstrecken auch das Straßenbahnnetz von Den Haag sowie das U-Bahn-Netz von Rotterdam benutzt.

Die Metro Wolgograd in Russland sowie die Krivoy Rog Schnellbahn in der Ukraine werden als "Metrotram" bezeichnet.

In Belgrad soll die seit Jahren geplante Metro Belgrad als Stadtbahn gebaut werden.

Am 18. Dezember 2012 beschloss der Stadtrat von Maastricht in den Niederlanden, dass das länderübergreifende Projekt „Tramverbinding Vlaanderen-Maastricht“ umgesetzt wird. Dabei handelt es sich um eine Verbindung der Zentren von Hasselt in Belgien und Maastricht in den Niederlanden. Zwischen den Städten übernimmt sie Aufgaben wie die Euregiobahn in Aachen, innerhalb der Orte fährt sie wie die geplante Campusbahn Aachen bis ins Stadtzentrum. Der größte Teil der Strecke befindet sich auf belgischem Gebiet. Dieser Teil gehört zum 300 Millionen schweren Spartacus-Plan, der eine Reihe von Verbesserungen im Regionalverkehr in Belgisch-Limburg bringen soll. In Belgisch-Limburg soll 2013 die Entscheidung für das Projekt fallen. Damit wären dann die Weichen für das neue Projekt gestellt, und wenn alles nach Plan verlaufen würde, würde die erste Stadtbahn bereits 2018 durch Maastricht und Hasselt rollen.

In Dänemark gab es in den drei Städten Kopenhagen, Aarhus und Odense Straßenbahnbetriebe, die zwischen 1952 und 1972 eingestellt wurden. Für alle drei Städte wurde im 21. Jahrhundert mit dem Aufbau von Stadtbahnen unter der Bezeichnung "Letbane" (Leichtbahn) begonnen. Als erstes ging im Dezember 2017 die Stadtbahn Aarhus mit 107 km in Betrieb (gestaltet nach dem Vorbild der RegioTram Kassel). Die Odense Letbane soll 2020 folgen, die Stadtbahn Kopenhagen 2023/24.

In den 1970er und 1980er Jahren entstanden Systeme mit deutscher Fahrzeugtechnik (Frankfurter Typ U2). Ein erstes Netz wurde 1978 im kanadischen Edmonton eröffnet, in der gleichen Provinz wurde 1981 auch eines in Calgary eröffnet.
Ebenso wurde 1981 in San Diego eine Stadtbahn mit deutschen Fahrzeugen eröffnete. Später folgten St. Louis (mit Tunnelstrecken), Baltimore, Salt Lake City, Denver, Dallas und Jersey City (gegenüber von New York City gelegen) und andere Städte. Aus bestehenden Straßenbahnstrecken wurden die Stadtbahnnetze in Pittsburgh, Newark, New Jersey und in San Francisco entwickelt. Neue Stadtbahnnetze mit deutschen Technikparametern mit Tunnelanlagen entstanden zudem in den mexikanischen Städten Mexiko-Stadt, Guadalajara und Monterrey. Im Jahr 2005 wurde eine Stadtbahn mit Flughafenanbindung in Minneapolis eröffnet. In Houston, Texas, fährt seit 2004 eine Light Railway 12 km durch die Innenstadt. 2009 wurde die "Link Light Rail" Stadtbahn in Seattle eröffnet. Bei dieser gibt es die Besonderheit, dass ein Innenstadttunnel im Mischbetrieb von Stadtbahnen und Duo-Bussen befahren wird. Ein weiteres Stadtbahnsystem fährt in San José.

Die grüne Linie der Bostoner Metro (Light rail) könnte als Stadtbahn bezeichnet werden, da hier Straßenbahnwagen im Innenstadtbereich in Tunnelanlagen, sonst als Straßenbahnen verkehren. Die Linie wurde 1897/1898 eröffnet und war die erste im Tunnel fahrende Straßenbahn der Welt.

Das Londoner Docklands-Modell wurde in der türkischen Hauptstadt Ankara mit dem „Ankaray“-System nachgebaut. Weitere Stadtbahnsysteme wurden in Istanbul, Izmir, Bursa und Antalya angelegt.

Im Osten Asiens erhielt die philippinische Hauptstadt Manila ein Stadtbahnsystem. Dieses wurde so gut wie kreuzungsfrei gebaut und wird mit Fahrzeugen der belgischen Straßenbahn-Standardbauart (Lüttich, Oostende) sowie Fahrzeugen des tschechischen Herstellers ČKD Tatra betrieben.

In Saudi-Arabien wurde 2011 der zweite Abschnitt der Metro Mekka in Betrieb genommen.




</doc>
<doc id="10716" url="https://de.wikipedia.org/wiki?curid=10716" title="Chnum">
Chnum

Chnum (eigentlich: Chenemu) ist ein altägyptischer Gott, der seit dem Alten Reich belegt ist. Die ihm in der ägyptischen Mythologie zugedachte Rolle als Neb-Qebehu („Herr von Qebehu“) nahm Chnum insbesondere erst seit dem Neuen Reich ein, obwohl seine frühesten Belege in Verbindung mit Elephantine bereits im Alten Reich bezeugt sind. Dort trat er zunächst nicht als Schöpfungsgottheit, sondern als „Helfer der Sopdet und der Satis“ in Erscheinung.

Im Verlauf des Mittleren Reiches wird bezüglich der Nilflut ein eigener Kult des Chnum erkennbar, da er seit dem Neubau des Satis-Tempels dort nicht mehr in seiner früheren Funktion erwähnt wurde. Erst in der 19. Dynastie des Neuen Reiches übernahm Chnum den Titel "Neb-Abu" („Herr von Elephantine“). Zuvor trug allein die Göttin Satis die Bezeichnung „Herrin von Elephantine“.

Die Lesung und Aussprache "Chnum" ist aus dem Griechischen bekannt. Jede Sprache hat historische Schreibungen, die wenig mit Logik zu tun haben - hier „Chnum“ statt „Chenemu“, obwohl das 'w' der Transkription eindeutig am Ende des Wortes steht, und die tatsächlich geschriebenen Hieroglyphen eigentlich als „Chenem-u“ zu lesen wären. Ausgesprochen wurde "Chenemu" wahrscheinlich "Xanamu". In der arabischen Sprache entspricht dies "yanam", was noch heute übersetzt „Schaf“ bedeutet. Der Göttername kann sich daher auch auf das Schaf beziehen.

In früheren Zeiten ausschließlich tiergestaltig, wurde er seit etwa 2400 v. Chr. als widderköpfiger Gott in Menschengestalt dargestellt.

Chnum war vor allem ein Schöpfergott, der auf der Töpferscheibe sowohl Götter und Menschen als auch Tiere und Pflanzen erschuf und mithilfe eines Zauberstabes zum Leben erwecken konnte. Als Fruchtbarkeitsgott und Gatte der Heket war er Herr über Zeugung und Geburt.

Chnum galt insbesondere seit dem Neuen Reich als Schutzgott von Elephantine und des Gebietes um den 1. Katarakt, weswegen sein späterer gebräuchlichster Beiname „Herr des Kataraktes“ ("Neb-Qebehu") lautete. Hier bildete er mit Satis und der gemeinsamen Tochter Anukis seit dem Neuen Reich die Triade von Elephantine. In Esna hingegen bestand die Triade aus Chnum, Menhit und dem Sohn Heka. Während der ersten Zwischenzeit (8. Dynastie) verschmolz er durch den allgemeinen Sonnenkult mit dem Sonnengott Re zu Chnum-Re, erstmals belegt im Tempel von Debod.

Chnum wurde an vielen Orten in Oberägypten und Nubien, seltener in Unterägypten verehrt. Zu den wichtigsten Kultzentren zählen: Elephantine, Bigge bei Philae, Esna und Hut-wer. Andere Kultzentren des Gottes lagen in Schas-hotep (Rifeh), Herwer (Chnum, „Herr von Herwer“), im 16. oberägyptischen Gau und bei Tarchan im ersten unterägyptischen Gau.




</doc>
<doc id="10718" url="https://de.wikipedia.org/wiki?curid=10718" title="Hathor (ägyptische Mythologie)">
Hathor (ägyptische Mythologie)

Hathor ist eine Göttin in der ägyptischen Mythologie. In ihren Anfängen nahm sie den Rang einer Lokalgöttin ein und trat damals kuhgestaltig in Erscheinung. Später stieg Hathor zur Himmelsgöttin des Westens auf und wurde zu einer allumfassenden Muttergottheit. Sie war auch Totengöttin und Göttin der Liebe, des Friedens, der Schönheit, des Tanzes, der Kunst und der Musik.

Spätestens seit der 1. Dynastie ist Hathor unter Narmer als kuhgestaltige Göttin belegt. Auf einem Elfenbeintäfelchen aus dem Grab des Djer in Umm el-Qaab bei Abydos ist sie als liegende Kuh vor dem Serech als „Hathor in den Sümpfen von König Djers Stadt Dep“ zu sehen. Ihre ikonografische Darstellung unterscheidet sich nur wenig von der älteren Himmelsgöttin Bat. Abbildungen auf Gefäßbruchstücken belegen im Aussehen der Göttin Hathor einen nur kleinen Unterschied zu Bat: Die Hörnerspitzen der Hathor verlaufen nach außen, im Gegensatz zu Bat. 

Auf der Statuengruppe des Mykerinos aus der 4. Dynastie ist Hathor an der linken Seite von Mykerinos mit dem Bat-Emblem abgebildet, während Hathor an seiner rechten Seite in ihrer Eigenschaft als Personifikation des siebten oberägyptischen Gaus auftritt. Gut erkennbar ist das Gehörn der Hathor mit der dazwischen liegenden Sonnenscheibe, das einen leichten Schwung nach außen aufweist, während das Bat-Emblem die nach innen geneigte Hörnerwindung der Bat zeigt. Der Hintergrund einer abweichenden Gehörnform ist wahrscheinlich in zwei verschiedenen Bovidenarten zu sehen. Ab der 11. Dynastie verschmolz die Göttin Bat vollständig mit Hathor. 

Ihr Name bedeutet „Haus des Hor“ beziehungsweise „Haus des Horus“, wobei sich der Namensbestandteil „Haus“ von der Bedeutung „Mutterschoß“ ableitet, der Horus umgibt. Das Ideogramm stellt daher meist einen Horusfalken im „Mutterschoß“ dar. Als spätere Gemahlin des Re und Mutter des Horus bildete sie den umschließenden Mutterleib, aus welchem Horus als ihr Sohn entsprang. 

Seit dem Alten Reich wird sie oft als das "Gold" bezeichnet.

Ihre mythologischen Anfänge mit Re werden wie folgt beschrieben: Re öffnet im Inneren des Lotos seine Augen in dem Moment, in dem er das Urchaos verließ. In seinen Augen bildete sich eine Flüssigkeit, die zu Boden fiel: Sie verwandelte sich in eine schöne Frau, der man den Namen „Gold der Götter, Hathor die Große, Herrin von Dendera“ gab. In einem Mythos verwahrt Hathor über Nacht Re in ihrem Leib und gebärt ihn jeden Morgen neu. In anderen Mythen ist Hathor das Auge des Re selbst.

Im Neuen Reich wird Re entsprechend mit dem Epitheton Kamutef als „Stier seiner Mutter“ genannt, der sich „durch Hathor selbst zeugte“. Damit repräsentiert Hathor das weibliche Element des göttlichen Königtums und ermöglicht so die zyklische Wiedergeburt des Königs als ursprünglich herrschender Horus. 

Im Mythos „Die Vernichtung der Menschheit“ ist Re über die Schlechtigkeit der Menschen enttäuscht und schickt Sachmet, um die bösen Menschen zu töten. Sachmet verfällt jedoch in einen Blutrausch und tötet immer mehr Menschen. Durch einen Plan des Thot wird Sachmet betrunken gemacht, um sie aufzuhalten und während sie schläft, verwandelt Re sie in Hathor.

Als eine der ältesten altägyptischen Göttinnen trat sie später einige ihrer Symbole und Funktionen an die jüngere Isis ab. Ihre enge Verbindung zu Isis besteht in den Gemeinsamkeiten als Mutter- und als Totengöttin. Seit dem Neuen Reich ist Hathor nur noch durch die hieroglyphische Beischrift von Isis zu unterscheiden. 
In ihren zahlreichen Funktionen galt sie auch als Beschützerin des Landes am Nil, der Fremden, der Bergleute (beispielsweise in den königlichen Kupfer- und Türkisminen auf dem Sinai), aller weiblichen Wesen und als Behüterin der Toten. Sie wurde auch als die Gemahlin des Horus angesehen.
Der Göttin Hathor wurde unter anderem "jrp" (irep) – Wein in Krügen – geopfert, galt doch dieses alkoholische Getränk als Symbol des Blutes und der Kraft der Wiederauferstehung nach dem Tode. So wurde Hathor auch „Herrin der Trunkenheit“ genannt.

Hathor wurde an vielen Orten im Alten Ägypten verehrt, darunter in Theben, Memphis, Sais und Abu Simbel, wobei Dendera seit dem Alten Reich als ihr Hauptkultort gilt. Auf dem Sinai, wo sie als "Herrin des Türkises" verehrt wurde, war ihr der Tempel von Sarabit al-Chadim geweiht. Aber auch im Ausland fand die Göttin Verehrung: in Byblos, Libanon und Timna.
Zusammen mit Horus von Edfu und den Söhnen Ihi (Sistrumgott) und Harsomtus (Vereiniger der beiden Länder) bildet Hathor in Dendera eine Familie. In Theben gehörte sie zur dortigen Götterneunheit. In Kom Ombo bildete Hathor mit Sobek und ihrem Sohn Chons eine Triade.

In der Interpretatio Graeca wurde Hathor mit Aphrodite identifiziert.

Die Hathorsäule, welche auch Sistrumsäule genannt wird, ist eine trommelförmige Säule mit einem Hathorkapitell, bei dem an zwei gegenüberliegenden, oder allen vier Seiten das Gesicht der Göttin Hathor unter einem blockförmigen Aufsatz (Sistrum) gezeigt wird. 

Dieser Göttin war, ebenso wie der Tempel von Dendera, der von Ramses II. für seine Frau Nefertari erbaute zweite Tempel von Abu Simbel geweiht. Auch der kleine Tempel von Deir el-Medina war hauptsächlich Hathor gewidmet.

Die Priesterinnen der Hathor wurden „Hathore“ genannt. Hathoren waren Tänzerinnen, Sängerinnen und Musikerinnen und dieser Begriff bezeichnete später weissagende Frauen und Prophetinnen. Beispielsweise diente auch dem Pharao Cheops eine Hathore als persönliche Prophetin, die Hathor- und Neith-Priesterin Hetepheres.




</doc>
<doc id="10719" url="https://de.wikipedia.org/wiki?curid=10719" title="Isis">
Isis

Isis (von ägypt. Aset) ist eine Göttin der ägyptischen Mythologie. Sie war die Göttin der Geburt, der Wiedergeburt und der Magie, aber auch Totengöttin. Sie erscheint erstmals in Inschriften des Alten Reiches. Popularität und Ansehen erlangte sie, gemeinsam mit ihrem Gemahl Osiris und ihrer Zwillingsschwester Nephthys, durch den sogenannten Osiris-Mythos und den Isis-Hymnus. Isis wurde noch von den in Ägypten lebenden Griechen und Römern bis in die christliche Zeit hinein verehrt.

Die häufigste und traditionellste Darstellungsform der Isis war die einer zierlichen, aufrecht stehenden oder knienden Frau mit Thronsitz auf dem Kopf. Sie hielt oft ein Papyrus-Zepter oder ein Anchkreuz in der Hand, in späterer Zeit manchmal auch ein Sistrum oder ein Menit. Wird sie kniend dargestellt, hält sie häufig einen Schen-Ring oder auch das Zeichen für Ewigkeit. Bereits ab dem späten Alten Reich konnte sie auch mit Kuhhörnern und Sonnenscheibe auf dem Kopf erscheinen und ähnelte so der kuhköpfigen, und ebenfalls stets Hörner tragenden, Göttin Hathor. Beide Göttinnen sind einzig durch die Inschrift neben der Darstellung zu unterscheiden. Isis konnte aber auch als Schwarzmilan dargestellt werden, in späterer Zeit auch mit Menschenkopf. Sie stellte nun einen sogenannten „Klagevogel“ dar, der um den verstorbenen Gott Osiris trauert und schützend seine Schwingen über dem Leichnam ausbreitet.

Ab dem Mittleren Reich sind Figurinen bekannt, die Isis mit dem kleinen Horusknaben zeigen. Horus sitzt auf Isis' Schoß und wird von ihr gestillt. Es wird angenommen, dass diese figürliche Darstellung das spätere Christentum zu zahlreichen, bekannten Madonnenbildnissen inspirierte.

In der griechisch-römischen Epoche wurden Isis-Darstellungen dem eigenen Kunststil angepasst. Isisstatuen in typisch hellenistischer Gestaltung zeigen die Göttin mit Tunika und geknotetem Umhang, in den Händen Sistrum und Weinkanne haltend.

Der Name Isis (ägypt. "Aset") wurde allgemein in zwei Arten geschrieben: Die erste alte Form wurde mit den Symbolen eines Thronsitzes ("as" oder auch "is" gelesen), einem Brotlaib ("t" oder "et") und dem Determinativ für eine sitzende Frau (unausgesprochen) gebildet. Die zweite alte Version begann ebenfalls mit dem Thronsitz und dem Brotlaib, endete jedoch mit einem Ei-Symbol („set“, aber auch hier unausgesprochen). Das Thronsitz-Symbol war immer auch als Kopfschmuck über der (meist aufrecht stehenden) Figur der Isis zu sehen. Das machte sie leicht identifizierbar. Die symbolische und metaphorische Bedeutung des Namens Isis (d. h. "Aset") bleibt unklar und umstritten. Das Thronsitz-Symbol könnte auf ihre Rolle als Königtum-Gottheit verweisen, als Göttin des Königsthrons. Ihr Name würde daher „Die von dem Thron des Königs“ bedeuten. Aber alle anderen Namen diverser Gottheiten verweisen auf kosmische und naturelementare Bedeutungen, die Bezug auf ihre Funktionen und Handlungsbereiche nehmen. Daher sollte auch der Name von Isis nicht auf den irdischen König selbst verweisen. Eine weitere Namensbedeutung in Bezug auf das Thron-Symbol könnte „Thron-Mutter der Götter“ sein, so dass sie die höchste weibliche Göttin vor allen anderen Göttinnen wäre. Doch dies würde eine sehr alte und lange Existenz von Isis voraussetzen, lange vor ihrer frühesten sicheren Erwähnung im Alten Reich. Eine dritte mögliche Bedeutung von Isis könnte in dem Ei-Symbol versteckt sein, das ebenfalls als Namenselement verwendet wurde. Das Ei-Symbol bedeutet „Mutterschaft“ und „Mutter“ und könnte auf die Mutter-Sohn-Verbindung zwischen Isis und Horus hinweisen. In diesem Fall würde Isis' Name einfach „Mutter-Göttin“ bedeuten. Das wäre aber auch problematisch, weil die ursprüngliche, mythologische Mutter von Horus eine Göttin namens Hathor war, nicht Isis.

Die Göttin Isis wird immer als Schutzherrin, Bewacherin und Betreuerin aller Wesen beschrieben, die leiden oder in großer Sorge sind. Aus diesem Grund wurde sie als mütterliche Göttin, als Göttin der Genesung, des Schutzes und der Magie angesehen. Gemäß dem berühmten Osiris-Mythos wurde Isis auch als Totengottheit und als die Göttin der Reanimation verehrt. Dies zeigt sich deutlich in mehreren Sargtexten des Neuen Reiches, in denen der Verstorbene um magische Unterstützung durch Isis bittet, wenn er vor dem Unterweltgericht angeklagt wird. Die Ägypter hatten große Sorge, dass sie beim Betreten der Anderswelt ihre menschlichen Fähigkeiten, wie zum Beispiel Sehen, Sprechen, Hören und unabhängiges Denken, verlieren könnten. Isis sollte alle Dämonen abwehren, die für das Verlorengehen der menschlichen Fähigkeiten verantwortlich waren.

Aber in erster Linie wurde Isis als himmlische Muttergestalt verehrt. Der Kult von Isis und Osiris beschreibt Isis als Mutter diverser Gottheiten wie Ihi, Horus und auch als Mutter des verstorbenen Königs. Die Mutterschaftsfunktion der Isis wird unter anderem eindrucksvoll in dem Papyrus Westcar (13. Dynastie) beschrieben, in dessen Erzählung sie ihre Magie benutzt, um die Geburt von drei künftigen Königen vorauszusagen und zu unterstützen. Isis wurde daher neben Gottheiten wie der Krötengöttin Heqet und dem Zwergengott Bes auch als Gottheit der Geburt verehrt.

Innerhalb der Götterschaft genoss Isis eine ganz besondere Rolle: Sie war die einzige Göttin mit magischen Kräften. In Sargtext-Spalte 147–148 fürchtet die schwangere Isis das eifersüchtige und rachsüchtige Verhalten ihres (Halb-)Bruders Seth. Als der Schöpfergott Atum sie fragt, warum sie und ihr noch ungeborener Sohn besonderen Schutzes bedürften, kann sie Auskunft über die zukünftige Rolle von Horus geben und glaubhaft darlegen, warum Seth versuchen könnte, Horus zu töten. Atum ist verblüfft und fragt Isis, wie sie das wissen könne. Isis erklärt dies mit ihrer magischen Kraft: „Ich bin Isis, der magische Ach, und ich habe mehr Weisheit als jeder andere Gott“.

Auf der anderen Seite wurden die Kräfte der Isis und ihr Charakter gleichermaßen gefürchtet. Nach altägyptischem Glauben war es immer möglich, jederzeit in Konflikt mit einem Gott zu geraten. Dies galt auch für Isis. Daher enthielten viele Papyri, die Schutzzauber für die Reise durch die Unterwelt aufzählten, auch Bitten und Gebete an verschiedene Götter, dass sie im Namen des Verstorbenen ein gutes Wort bei Isis einlegen mögen, um sie gnädig zu stimmen. Man glaubte von Isis, dass sie die Verstorbenen durch Versiegelung ihres Gedächtnisses und Verschließen ihres Mundes bestrafte, wenn der Verstorbene zu Lebzeiten Böses getan hatte oder nicht gerechtfertigt verstorben war. Wenn ein Verstorbener nicht fähig war, seinen Namen vor dem Totengericht aufzusagen, war er verloren und wurde verurteilt.

Überraschenderweise ist die tatsächliche und ursprüngliche Herkunft einer Göttin namens Isis Ägyptologen und Archäologen so gut wie unbekannt. Die früheste, sicher belegte Erwähnung ihres Namens erscheint während der 5. Dynastie im Sonnenheiligtum des Königs Niuserre und innerhalb des Titels eines Priesters der 6. Dynastie: „Pepi-anch, Hohepriester der Isis und der Hathor“. Zu diesem Zeitpunkt wurde Isis bei Qusae und Abydos verehrt, in Qusae zusammen mit Hathor, in Abydos zusammen mit Osiris und Anubis. Die Belege aus der 5. und 6. Dynastie könnten darauf hinweisen, dass Isis seit längerem bekannt war, allerdings eine eher untergeordnete Rolle spielte und ihr Name deshalb nur selten erwähnt wurde. Siegelabdrücke aus der Zeit des Königs Narmer und Aha (1. Dynastie) erwähnen eine Person namens "Sa-Iset", was als „Sohn der Isis“ interpretiert werden könnte, aber das ist höchst spekulativ und der vermeintliche Name dürfte eher als ein Titel („Sohn des Königsthrons“, „Kronprinz“) zu verstehen sein.

Während des Alten Reiches wurde Isis an folgenden Orten verehrt: Qusae, Edfu, Abydos und Achmim. Interessanterweise wird Isis an allen kultischen Orten immer zusammen mit anderen Göttern erwähnt, von denen es heißt, sie sei deren Frau oder deren Mutter. Sie erscheint nie allein. Bei Edfu, zum Beispiel, wird sie „Mutter des Horus-von-Edfu“ genannt, in Abydos wird sie als „Große Gemahlin von Osiris-Chontamenti“ bezeichnet. In Achmim wird sie mit „Große Mutter des Min“ betitelt. In Koptos stand für sie ein Doppeltempel, der ihr in Verbindung mit Hathor, Min und Horus geweiht war. Aus Kerma (im heutigen Sudan) stammt die Statue von "Senui", die Frau des Priesters "Djefai-Hap" (Mittleres Reich), der Verstorbene wird hier als „von Osiris, Ptah-Sokar, Tefnut, Nut und Isis geehrt“ beschrieben.

Als Göttin der Geburt und Mutterschaft wurde Isis mit anderen Muttergöttinnen wie Hathor, Meschenet, Nut und Nechbet gleichgesetzt. Teilweise scheint es, dass Isis diese Göttinnen tatsächlich ersetzte. Besonders oft wurde Isis zusammen neben Hathor und Nut erwähnt. Gebete und Zaubersprüche wurden während des Alten Reiches an Isis und ihre Begleiterinnen gleichzeitig gerichtet, in späteren Zeiten wurde Isis schnell unabhängig. Dennoch blieb Isis eng mit vielen anderen Gottheiten verbunden, diese Art von Synkretismus war sehr verbreitet und beliebt im alten Ägypten, zumindest seit Beginn des Alten Reiches. Das Problem solcher Synkretismen ist die Veränderung der ursprünglichen Charaktere, Funktionen und Wirkungskreise diverser Gottheiten, die besten Beispiele sind die Gottheiten Seth und Horus.

Isis war die Frau des Gottes Osiris (ägypt. "Usir"). Ägyptologen und Historiker weisen immer wieder darauf hin, dass Isis und ihr Gatte Osiris fast synchron auftauchten und in beiden Fällen jenes Ersterscheinen recht plötzlich erfolgte. Für Osiris finden sich die frühesten, sicher belegten Namensnennungen im Totentempel des Königs Djedkare-Isesi, möglicherweise wird er bereits indirekt im Sonnenheiligtum des Königs Niuserre erwähnt. Genau wie Isis, so scheint Osiris keinen göttlichen Vorgänger oder eine sicher nachweisbare, länger zurückreichende Vergangenheit zu besitzen. Sogar die Namen sind fast identisch: Osiris' Name setzt sich aus den Hieroglyphen für „Thronsitz“ und „Auge“ zusammen. Und wie bei Isis, so herrscht auch bei Osiris Uneinigkeit bezüglich der möglichen Bedeutung des Namens. „Sitz des Auges“, „Auge des Throns“ und „Thronendes Auge“ sind die geläufigsten Übersetzungen. Unklar bleibt, worauf sich die Bedeutung des Namens bezieht. 

Osiris war der Gott der Unterwelt, Vorsitzender des Totengerichts und Herrscher über Tod und Wiedergeburt. Die Rolle als Unterweltherrscher scheint er von Sokar übernommen zu haben, die Aspekte der Todbeherrschung und der Wiedergeburt knüpfen an den Sonnengott Re an, der ebenfalls wiedergeboren wird.

Isis wurde von Anbeginn an als „Große Gemahlin des Osiris“ verehrt. Gemäß dem Isis-Hymnus und der Osiris-Legende zufolge war sie es, die den ermordeten und zerstückelten Osiris gemeinsam mit ihrer Zwillingsschwester Nephthys aufspürte, wieder zusammenfügte und durch Zaubersprüche, Gebete, Klagen und Litaneien wieder zum Leben erweckte. Aus diesem Grund wurde Isis auch häufig mit Nephthys und Osiris während des Totengerichts abgebildet.

Gemäß der ägyptischen Mythologie war Nephthys die Zwillingsschwester von Isis und die Gemahlin des Seth. Ihr ägyptischer Name "Nebet-hut" bedeutet „Herrin des Hauses“. Seine religiös-symbolische Bedeutung ist genauso unklar wie bei Isis und Osiris. Auch Nephthys war eine Totengöttin, Göttin der Totenklage und der Wiedergeburt, besaß allerdings keine Zauber- und Orakelkräfte wie Isis. Gemäß dem Isis-Hymnus und der Osiris-Legende half Nephthys ihrer Schwester dabei, den zerstückelten Leichnam des Osiris wiederzufinden, mit Mumienbinden zusammenzufügen und durch Gebete, Klagen und Litaneien wieder zum Leben zu erwecken. Obwohl Nephthys große Ähnlichkeiten mit Isis aufweist, scheint Isis sie nie ersetzt oder irgendwelche Fähigkeiten von ihr übernommen zu haben.

Die Göttin Hathor war die „Herrin der Himmelskörper, die Horus und Seth gebar und die die jüngsten Götter in ihrem Schoß verbirgt während der nächtlichen Reise“. Ihr ägyptischer Name "Hut-hor" (auch: "Hat-hor") bedeutet „Haus (Mutterschoß) des Horus“. Sie wurde als eine Frau mit Kuh-Hörnern dargestellt, oft mit einer Sonnenscheibe zwischen den Hörnern. Alternativ wurde Hathor als ruhende oder schreitende Kuh mit einer kahlen Palmenrispe oder Sonnenscheibe zwischen den Hörnern dargestellt. Sie spielte eine wichtige Rolle als beschützende Mutter und eifersüchtige „Gouvernante“. In Anbetracht dieser Rolle ist es keine Überraschung, dass Isis noch im Alten Reich zunächst sehr eng mit Hathor verknüpft wurde, und bald – etwa ab dem Mittleren Reich – wurde Hathor durch Isis förmlich ersetzt. Jetzt trennten nur die kultischen Orte die beiden Göttinnen: Hathor hatte ihr wichtigstes Kultzentrum bei Dendera, und Isis wurde anderswo verehrt. Isis und Hathor verschmolzen so stark (auch in ihren Darstellungen), dass ergänzende und erklärende Beischriften notwendig wurden, die durch die Erwähnung ihrer Namen und Funktionen Verwechselungen vermeiden sollten.

Während der griechisch-römischen Epoche erfuhr Isis eine ungeahnte Popularität. Sie wurde von den Griechen vornehmlich mit der Göttin Demeter gleichgesetzt und besonders in Alexandria verehrt. Ihr ägyptischer Gatte Osiris wurde mit dem Unterwelt-Gott Serapis identifiziert. In der alexandrinischen Vorstadt "Eleusis" befand sich der Haupttempel. Als sich Ptolemaios I. Soter (323–283 v. Chr.) in Alexandria niederließ und sie zu seiner neuen Hauptstadt in Ägypten ernannte, ließ er eigens den angesehenen Priester "Timotheus" nach Eleusis kommen.

Isis verschmolz aber auch mit anderen Göttinnen, besonders häufig wurde sie – neben Demeter – mit Aphrodite gleichgesetzt. Viele Statuenbildnisse von Isis-Aphrodite zeigen die Göttin, wie sie ihre Hand verhüllend vor ihre Scham hält, wie bei der Aphrodite von Knidos des Künstlers Praxiteles zu sehen ist. Alternativ verknüpfte man sie zum Beispiel mit Hera, Athena und Artemis. In römischer Zeit waren es die entsprechenden Göttinnen Iuno, Diana und Ceres. Ein interessanter Synkretismus ging aus einer Verbindung von Isis mit der ägyptischen Göttin Maat hervor: "Dikaiosyne". Dabei wurden Isis unzählige Beinamen und Titel zugesprochen, weshalb sie von den Griechen "Myrionýmos" (dt. „die mit zehntausend Namen“) genannt wurde. Oder sie wurde "Euthenia" (dt. „Überfluss“ oder „Üppigkeit“), "Lóchia" (dt. „Hebamme“) und/oder "Outeira" (dt. „Retterin“) geheißen. In römischen Widmungen an sie findet sich besonders oft der Beiname "Invicta" (dt. „die Unbezwingbare“). 

Die Gleichsetzung der Isis mit der aus der griechischen Mythologie bekannten Io ist eine vielmals beschriebene Verbindung der griechischen mit der ägyptischen Mythologie. So schreibt Ovid in Metamorphosen "Hoch nun prangt sie als Göttin im Volk leintragender Männer." (als der Ägypter). Da Io, in eine Kuh verwandelt, bis nach Ägypten irrte, fällt besonders auf, dass Isis oftmals mit Kuhkopf oder Kuhhörnern dargestellt wird.
In späthellenistischer bis nachchristlicher Zeit gelangte der Isis-Kult über Griechenland bis nach Spanien. Zu dieser Zeit galt Isis als Beschützerin der Seefahrer. Die Isis wird deshalb häufig, vor allem bei Alexandrinischen Münzen stehend auf einem Schiff mit einem geblähten Segel in der Hand dargestellt. Antike Kultorte entstanden in Athen, Samothraki, in Rom und auf der Insel Delos. Die dort tätigen Priester wurden als "Pastophóroi" (dt. „Schreinträger“) bezeichnet. Aus Pompeji stammen mehrere Mosaike, die Isis in römischer Tracht und mit Geierhaube zeigen. Als der römische Diktator Sulla um 80 v. Chr. auf dem Kapitol einen Isis-Tempel errichten ließ, wurde umgehend ein Kollegium aus Pastophoroi gegründet.

Im Hellenismus setzte man den lebenden König, der mit Horus gleichsetzt wurde, mit Osiris als dem verstorbenen König in Verbindung. So wurde Isis auch mit dem Osirismythos in Beziehung gebracht und dadurch Teil des sogenannten Isis-und-Osiris-Kultes. Der griechische Historiker Plutarch beschrieb die Göttin im 2. Jahrhundert als das weibliche Prinzip in der Natur.

Bei Apuleius von Madaura, einem eklektischen Platoniker, wird Isis zur universellen Allgöttin, die in die Mysterienkulte einweiht. In den von Apuleius verfassten "Metamorphosen" wird sie als „Himmelskönigin“ angerufen und mit der „allernährenden Ceres“, der „Urmutter der Früchte“, der „himmlischen Venus“, verehrt im „meerumfluteten Heiligtum von Paphos“, der „Schwester des Phoebus“, angebetet im „Tempel von Ephesus“, oder der „dreigestaltigen Proserpina“ gleichgesetzt. Die Göttin stellt sich danach selbst vor, als „die Mutter der Natur "(rerum naturae parens)", die Herrin aller Elemente, erstgeborenes Kind der Zeit "(saeculorum progenies initialis)", die Höchste der Gottheiten, Königin der Toten, Erste der Himmlischen, die alle Götter und Göttinnen in einer Erscheinung vereinigt "(deorum dearumque facies uniformis)", die ich mit meinem Wink über des Himmels lichte Gewölbe, des Meeres heilsame Lüfte und der Unterwelt vielbeweinte Stille gebiete, die alleinige Gottheit, welche unter mannigfacher Gestalt, verschiedenartigen Riten und vielerlei Namen der ganze Erdkreis verehrt, so nennen die Phrygier ... mich Pessinuntia ..., die Athener ... nennen mich kekropische Athena, die Kyprier nennen mich paphische Venus, die Kreter Diktynna, die Sizilianer ortygische Proserpina, die Eleusinier nennen mich Demeter, andere Hera, wieder andere Bellona und Hekate und Rhamnusia. Aber die Äthiopier und die Ägypter, die die ursprüngliche Lehre besitzen, ehren mich mit eigenen Bräuchen und nennen mich mit meinem wahren Namen Königin Isis.“

Der einzige vollständig erhaltene lateinische Roman der Antike, der "Goldene Esel" des Apuleius, handelt von den Isis-Mysterien. Der Kult breitete sich sogar in den Alpen und nördlich davon aus. Dort gab es beispielsweise Isis-Tempel in Maria Saal, Köln, Mainz und London, wie auch das Presbyterium von Isis in Szombathely.

Während der Isis-Kult in nachchristlicher Zeit in Ägypten bald nachließ, erfuhr er besonders im Römischen Reich ein wahres Auf- und Ab. So gab es römische Kaiser, die den Isis-Kult zeitweise verboten, aber auch solche (unter anderem Trajan, Hadrian und Commodus), die sich für die Priesterschaften der Isis (und des Sarapis) einsetzen und Tempeldienste erlaubten. Zu dieser Zeit waren Statuenbildnisse der Isis sehr gefragt, auch kamen unzählige Münzen mit dem Bildnis der Isis in Umlauf. Ab etwa 300 n. Chr. setzte sich das Bild der stehenden Isis mit Knotenpallas, Sistrum und Situla durch. Der Isis-Kult hielt sich bis etwa 500 n. Chr.

Darstellungen der „Isis mit dem Horusknaben“ aus der Isis-Ikonografie, vor allem die "Isis lactans" (die „stillende Isis“), erscheinen in Art und Weise verwandt mit späteren Darstellungen Marias, der Mutter Jesu, mit dem Jesuskind. 

Ein vergoldeter spindelförmiger Gegenstand wurde Mitte 2015 auf einem Friedhof in Jerusalem gefunden. Israels Altertumsbehörde (IAA) rätselte sechs Monate über Herkunft, Zweck und Funktion. Letztlich brachte ein Aufruf via Facebook binnen Stunden die Klärung der Herkunft: Der länglich-drehsymmetrische Metallteil wird von einer deutschen Bio-Energie-System-Firma als „Isis-Beamer“ verkauft. 







</doc>
<doc id="10725" url="https://de.wikipedia.org/wiki?curid=10725" title="Seth">
Seth

Seth steht für:

Seth ist der Name folgender Personen oder Figuren:

Seth ist der Familienname folgender Personen:

Seth ist der Vorname folgender Personen:

SETh steht als Abkürzung für:

Siehe auch:



</doc>
<doc id="10727" url="https://de.wikipedia.org/wiki?curid=10727" title="Thot">
Thot

Thot (oder Thoth, Tehut, Tahuti, Djehuti) ist in der ägyptischen Mythologie der ibisköpfige oder paviangestaltige Gott des Mondes, der Magie, der Wissenschaft, der Schreiber, der Weisheit und des Kalenders. In den Pyramidentexten galt Thot als Gott des Westens.

Thot wurde vorwiegend menschengestaltig mit Ibiskopf, als stehender oder hockender Ibis oder als Mantelpavian dargestellt. Andere Abbildungen zeigen die Gottheit auch als weibliche Person mit Ibiskopf oder männliche Darstellung mit Paviankopf oder rein als das Sechem-Zepter.

Die Verehrung von Thot ist einer der ältesten Götterkulte des Alten Ägypten und der Kultort war Hermopolis. Seine Bedeutung ist durch Inschriften in Bauwerken und Papyrus-Aufzeichnungen gut belegt. Bereits während der Pyramidenzeit (Altes Reich) war Thot als Mondgott bekannt; in der Spätzeit erhielt er das Epitheton „Silberner Aton“. Schreibtafel und Binse sind gewöhnlich seine Attribute und er gilt als Sekretär der Götter sowie als Erfinder der Hieroglyphen. Im Osirismythos war er Schreiber und Wesir des Osiris. Thot war der Nachfolger von Horus und regierte 3000 Jahre lang friedlich über Ägypten. Danach stieg er als Mond zum Himmel hinauf, doch ein Dämon fraß beständig von ihm, so dass er von einer periodischen Auszehrung betroffen war (verschiedene Mondphasen).

Thot ist spätestens ab dem Neuen Reich auch der erste Monat der Jahreszeit Achet im alten Ägypten. Als Mondgott ist er zugleich der Gott der Zeit und der Zeitabschnitte, da diese sich nach dem Mondlauf richten. Dies macht ihn auch zum Messenden, dem Gott des Maßes. Er repräsentiert die gleichmäßige Ordnung der Welt, er ist der ihr innewohnende Geist der Ordnung und der Gesetzmäßigkeit. So wird er der Vertreter des Geistes überhaupt und insbesondere der Schutzgott aller irdischen Gesetze. Zugleich ist er der Gott der Intelligenz, der Anordner der gottesdienstlichen Gebräuche, der Lehrer der Künste und Wissenschaften, der Erfinder von Sprache und Schrift, der Schutzherr der Bibliotheken.

Schließlich hat Thot auch eine Bedeutung in der Jenseitsvorstellung der ägyptischen Mythologie. Er ist der Protokollant des Totengerichts und notiert, ob die Verstorbenen würdig sind, in das Reich der Wiederkehr beziehungsweise in das Totenreich aufgenommen zu werden.

Thot wurde in der griechischen Mythologie mit Hermes gleichgesetzt und später mit ihm zu Hermes Trismegistos verschmolzen.

Aleister Crowley schrieb "Das Buch Thot", in dem er das Wahrsagen mit Hilfe des von ihm entworfenen und von Frieda Harris gezeichneten Thot-Tarotkartendecks und dessen mythologische Hintergründe erläuterte. Im Roman "American Gods" von Neil Gaiman tritt Thot zu Anfang unter dem Decknamen "Mr. Ibis" auf und betreibt mit Anubis und Bastet ein kleines Bestattungsinstitut. Auch in der Serienumsetzung kommt diese Figur vor und wird von Demore Barnes dargestellt.

Im Online-Computerspiel Smite ist Thot ein spielbarer Charakter.




</doc>
<doc id="10728" url="https://de.wikipedia.org/wiki?curid=10728" title="Zellkern">
Zellkern

Ein Zellkern oder Nukleus ( „Kern“) ist ein im Cytoplasma gelegenes, meist rundlich geformtes Organell der eukaryotischen Zelle, welches das Erbgut enthält. Mit "nukleär" oder "karyo" (altgriechisch κάρυον "káryon" „Kern“) wird ein Bezug auf den Zellkern ausgedrückt.

Der Zellkern ist das Hauptmerkmal zur Unterscheidung zwischen Eukaryoten (Lebewesen mit abgegrenztem Zellkern) und Prokaryoten (Lebewesen ohne abgegrenzten Zellkern, also Bakterien und Archaeen). Er enthält den größten Teil des genetischen Materials der eukaryontischen Zellen in Form von mehreren Chromosomen. Weitere Gene finden sich in den Mitochondrien und bei Pflanzen auch in Chloroplasten. Die meisten Zellen enthalten genau einen Kern. Es gibt jedoch auch Ausnahmen; beispielsweise enthalten Myotuben, die durch Verschmelzung von Myoblasten entstehen, mehrere Kerne. Der Kern selbst ist durch eine Kernhülle oder Kernmembran, die zum Schutz des Erbguts sowie der Regulierung des Stofftransports zwischen Nucleoplasma und Cytoplasma dient, vom sie umgebenden Cytoplasma abgetrennt. In Embryonen der Fruchtfliege teilen sich Kerne sehr schnell, ohne dass zunächst trennende Zellmembranen entstehen. Reife Erythrozyten der Säuger enthalten keinen Kern mehr, er wird während der Reifung abgestoßen.

Wichtige Vorgänge, die innerhalb des Zellkerns ablaufen, sind DNA-Replikation (die Duplizierung des in Form von DNA vorliegenden genetischen Materials) und Transkription (das Erstellen einer mRNA-Kopie eines gegebenen DNA-Abschnitts, der oft, aber nicht immer, einem Gen entspricht).

Die Wissenschaft vom Zellkern wird auch Karyologie genannt.

Zellkerne können je nach Zelltyp sehr unterschiedlich aussehen. Meistens sind sie kugelförmig oder oval. In einigen Zellen sehen sie eher geweihförmig aus. Manchmal kann der Zellkern in knotenartige Abschnitte untergliedert sein, so beim rosenkranzförmigen Zellkern der Trompetentierchen. Auch die Granulocyten der Säuger enthalten gelappte Kerne.

Der Zellkern, welcher bei Säugern typischerweise einen Durchmesser von 5 bis 16 µm hat, ist das im Mikroskop am leichtesten zu erkennende Organell der Zelle. Er wird durch die Kernhülle, bestehend aus zwei biologischen Membranen, der inneren und äußeren Kernmembran, begrenzt, welche die sogenannte perinukleäre Zisterne (Breite 10–15 nm, gefestigt von Mikrofilamenten – Dicke 2 bis 3 nm), umschließen. Die Gesamtdicke der Kernhülle beträgt etwa 35 nm. Die äußere Kernmembran geht fließend in das raue endoplasmatische Retikulum über und hat wie dieses auch Ribosomen auf ihrer Oberfläche. Die innere Kernmembran grenzt an einem 20–100 nm breiten „Filz“, der Kernlamina (Lamina fibrosa nuclei), die aus Laminen, einer Gruppe von Intermediärfilamenten, besteht, den Zellkern stützt und die innere Membran vom Chromatin des Zellkerns trennt. Durch die in der Kernhülle enthaltenen Kernporen, die ca. 25 % der Oberfläche bedecken, findet der aktive Stoffaustausch (z. B. rRNA oder mRNA) zwischen dem Kern und dem Zellplasma, gesteuert von einem Kernporenkomplex, statt. Regulatorische Proteine gelangen aus dem Cytoplasma in den Zellkern, Transkriptionsprodukte wie die mRNA werden zur Proteinsynthese, die an den Ribosomen des Cytoplasmas stattfindet, aus dem Kern in das Plasma exportiert. Die Flüssigkeit im Kern wird auch als Karyoplasma bezeichnet.
Zellkerne können durch Anfärben der DNA lichtmikroskopisch hervorgehoben werden, z. B. durch die Feulgen-Färbung, durch Giemsa oder durch Fluoreszenzfarbstoffe wie DAPI.

Lichtmikroskopisch fallen in vielen Zellkernen ein oder mehrere rundliche Gebilde auf, die Kernkörperchen oder Nucleoli. Sie enthalten die Gene für ribosomale RNA. Hier werden die Untereinheiten der Ribosomen gebildet, welche durch die Kernporen ins Cytoplasma gelangen. Nucleoli enthalten im Vergleich zum Rest des Kerns nur geringe Konzentrationen von DNA, stattdessen mehr RNA.
Andere „Körperchen“ des Zellkerns lassen sich nur durch spezielle Färbetechniken darstellen, etwa durch Antikörperfärbung. Die Funktion dieser Körperchen ist meistens noch unbekannt. Hierunter fallen etwa „Speckles“ (Ansammlungen von Faktoren, die für Splicing benötigt werden), Cajal Bodies oder PML-bodies.

Das Vorhandensein einer Kernmatrix wurde erstmals in den 1970er Jahren vorgeschlagen. Ihre Existenz ist jedoch weiterhin umstritten.

Das im Zellkern vorhandene Erbgut der Zelle befindet sich in den Chromosomen, mehrere zu Chromatin verpackte DNA-Fäden, die neben der DNA auch Proteine wie Histone enthalten. Neben den Histonen kommen auch andere Kernproteine, wie z. B. DNA-Polymerasen und RNA-Polymerasen, weitere Transkriptionsfaktoren sowie Ribonukleinsäuren im Kern vor.

Chromosomen nehmen während der Interphase abgegrenzte Bereiche im Zellkern ein, die Chromosomenterritorien. Deren Existenz wurde zuerst von Carl Rabl (1885) und Theodor Boveri (1909) vorgeschlagen, der direkte Nachweis gelang erst 1985 mit Hilfe der Fluoreszenz-in-situ-Hybridisierung.

Die Verteilung des Chromatins und somit der Chromosomen innerhalb des Zellkerns erscheint auf den ersten Blick zufällig: Die Anordnung der Chromosomen zueinander wechselt von Kern zu Kern, Nachbarn in einem können im nächsten weit auseinanderliegen. Seit den 1990er Jahren konnten jedoch einige Ordnungsprinzipien gefunden werden. Die DNA-Replikation erfolgt während der S-Phase nicht gleichmäßig, sondern an manchen Stellen der Chromosomen früher, an anderen später. Frühe oder späte Replikation sind dabei Eigenschaften, die für alle Abschnitte der Chromosomen in einem gegebenen Zelltyp konstant sind. Es stellte sich heraus, dass sich früh replizierte Bereiche vorwiegend im Inneren des Kerns befinden, während spät replizierte Bereiche vorwiegend an der Kernhülle und um die Nucleoli herum lokalisiert sind. Für die Anordnung der Chromosomenterritorien im Zellkern wurde beobachtet, dass Chromosomen mit hoher Gendichte bevorzugt in der Mitte des Kerns liegen während Chromosomen mit niedriger Gendichte häufiger an der Peripherie zu finden sind. Für manche Zelltypen wurde auch beschrieben, dass kleine Chromosomen eher in der Mitte liegen während große außen sind. Beide Motive sind dabei miteinander vereinbar.

Bei der Mitose und der Meiose, den bei eukaryotischen Zellen vorkommenden Arten der Kernteilung, verschwindet der Zellkern zeitweilig, weil die Kernhülle während des Teilungsvorgangs aufgelöst wird. Während Chromosomen in der Interphase keine lichtmikroskopisch sichtbaren Abgrenzungen ausbilden, kondensieren sie für die Kernteilung zu den kompakten Metaphase-Chromosomen. In dieser Transportform wird das Erbgut auf die Tochterzellen verteilt. Nach der Teilung bilden sich die Kernhüllen um die Chromosomen der Tochterzellen wieder aus und die Chromosomen dekondensieren wieder.

Der Zellkern ist das zuerst entdeckte Organell der Zelle. Die älteste erhaltene Zeichnung geht zurück auf den frühen Mikroskopiker Antoni van Leeuwenhoek (1632–1723). Dieser untersuchte rote Blutkörperchen des Lachses und beschrieb darin ein „Lumen“, den Zellkern. Im Gegensatz zu den roten Blutkörperchen der Säugetiere haben jene der anderen Wirbeltiere Zellkerne. Eine weitere Erwähnung erfolgte 1804 durch Franz Andreas Bauer. 1831 wurde der Zellkern vom schottischen Botaniker Robert Brown in einem Vortrag vor der Linnéschen Gesellschaft in London als „areola“ beschrieben. Mögliche Bedeutungen erwähnte er nicht. Eine solche wurde zuerst 1838 von Matthias Schleiden vorgeschlagen, nämlich dass er eine Rolle bei der Bildung der Zelle spielt. Daher führte Schleiden den Namen „Cytoblast“ (Zellenbildner) ein. Er meinte beobachtet zu haben, dass sich neue Zellen an diesen Cytoblasten bildeten. Franz Julius Ferdinand Meyen widersprach entschieden der Ansicht, dass „der Zellenkern die Zelle selbst erzeuge“. Er hatte schon zuvor beschrieben, dass sich Zellen durch Teilung vermehren. Allerdings war Meyen auch der Ansicht, dass viele Zellen keine Zellkerne hätten. Überwunden wurde die Vorstellung einer Neubildung von Zellen erst durch die Arbeiten von Robert Remak (1852) und durch Rudolf Virchow ("Omnis cellula e cellula", 1855), welcher die neue Lehre von der ausschließlichen Bildung von Zellen aus Zellen offensiv vertrat. Die Funktion des Zellkerns blieb weiter ungeklärt.

Christian Gottfried Ehrenberg hatte 1838 erstmals die Teilung eines Zellkerns beobachtet und auf dessen Rolle aufmerksam gemacht.

1876–1878 veröffentlichte Oscar Hertwig mehrere Studien über die Befruchtungsvorgänge des Seeigel-Eies, aus denen hervorging, dass der Zellkern des Spermiums in das Ei eindringt und dort mit dem Zellkern des Eies verschmilzt. Damit wurde zum ersten Mal behauptet, dass sich ein Individuum aus einer (einzelnen) kernhaltigen Zelle entwickele. Dies widersprach der von Ernst Haeckel vertretenen Ansicht, dass während der Embryonalentwicklung die gesamte Stammesgeschichte wiederholt würde, insbesondere auch die Entstehung der ersten kernhaltigen Zelle aus einer „Monerula“, einer strukturlosen Masse aus Urschleim. Die Notwendigkeit des Spermienkerns zur Befruchtung wurde daher noch lange Zeit kontrovers diskutiert. Hertwig bestätigte jedoch seine Befunde an anderen Tiergruppen, z. B. Amphibien und Mollusken. Eduard Strasburger kam an Pflanzen zum gleichen Ergebnis (1884). Dies ebnete den Weg, dem Kern eine wichtige Bedeutung bei der Vererbung zuzuweisen. Bereits 1873 hatte August Weismann die Gleichwertigkeit der mütterlichen und väterlichen Keim"zellen" für die Vererbung postuliert. Die Rolle des Kerns hierbei wurde erst später offenbar, nachdem die Mitose beschrieben wurde und Anfang des 20. Jahrhunderts die Mendel’schen Regeln wiederentdeckt wurden: Die Chromosomentheorie der Vererbung wurde entwickelt (siehe dort und Chromosom).

1874 isolierte Friedrich Miescher aus Zellkernen eine Substanz, die er als Nuclein bezeichnete (siehe Entdeckungsgeschichte im Artikel DNA). Nur wenige Jahre später kamen weitere Bestandteile wie Histone und Adenin (Albrecht Kossel) hinzu. Es ist erst seit dem 21. Jahrhundert möglich, das Genom, das Transkriptom oder durch Massenspektrometrie auch das Proteom einer Zelle zu einem bestimmten Zeitpunkt zu bestimmen, um sich so ein umfassendes Bild dieses Systems zu machen.





</doc>
<doc id="10729" url="https://de.wikipedia.org/wiki?curid=10729" title="Fields-Medaille">
Fields-Medaille

Die Fields-Medaille, offizieller Name "" (deutsch: „Internationale Medaille für herausragende Entdeckungen in der Mathematik“), ist eine der höchsten Auszeichnungen, die ein Mathematiker erhalten kann. Sie wird alle vier Jahre von der Internationalen Mathematischen Union (IMU) anlässlich des Internationalen Mathematikerkongresses (ICM) an zwei bis vier Mathematiker verliehen, die jünger als 40 Jahre sind und sich in besonderer Weise auf dem Gebiet der mathematischen Forschung hervorgetan haben. Mit der Verleihung ist ein Preisgeld von 15.000 kanadischen Dollar verbunden. Beim ICM werden gleichzeitig zwei weitere Preise verliehen: der Carl-Friedrich-Gauß-Preis für Beiträge zur angewandten Mathematik und der Nevanlinna-Preis für Beiträge zur theoretischen Informatik.

Das vom Exekutivkomitee der IMU bestimmte Auswahlkomitee, dessen Mitglieder außer dem Vorsitzenden bis zur Preisverleihung geheim bleiben, hat die Aufgabe, mindestens zwei, vorzugsweise aber vier Empfänger auszuwählen, die eine Vielfalt von Gebieten in der Mathematik repräsentieren. Der Begründer des Preises John Charles Fields betrachtete als Grundprinzipien für die Auszeichnung die Lösung eines schwierigen Problems und die Formulierung einer neuen Theorie, die die Anwendungsbereiche der Mathematik erweitert.

Die Empfänger der Medaille müssen vor dem 1. Januar des Jahres, in dem sie ausgezeichnet werden, jünger als 40 Jahre gewesen sein. Die 1966 formalisierte und später weiter präzisierte Regel geht zurück auf die bei der Einrichtung von Fields formulierte Erwartung, .

Dies verhinderte zum Beispiel die Verleihung an Andrew Wiles (* 1953), dem der Beweis des Modularitätssatzes (aus dem der große fermatsche Satz folgt) erst 1993 teilweise und 1995 vollständig gelang. Wiles erhielt stattdessen auf dem ICM 1998 in Berlin eine Sonderauszeichnung der IMU, verbunden mit einer Silberplakette. Auch Anfang des 20. Jahrhunderts geborene Mathematiker wie Kolmogorow, Cartan, Weil, Leray, Pontrjagin, Chern und Whitney wurden durch die Alterseinschränkung ausgeschlossen, da die Auszeichnung zwischen 1936 und 1950 nicht verliehen wurde.

Die Fields-Medaille wird wegen ihres langjährigen höchsten Prestiges oftmals als gleichrangiger Ersatz für einen nicht existierenden Nobelpreis für Mathematik angesehen. Mit dem 2002 gestifteten Abelpreis gibt es jedoch ein neueres Gegenstück, das durch die fehlende Altersbeschränkung, die jährliche Verleihung, das erheblich höhere Preisgeld und das skandinavische Auswahlkomitee den Nobelpreisen ähnlicher ist.

Die von der Royal Canadian Mint geprägte Medaille ist aus Gold und wurde 1933 von dem kanadischen Bildhauer Robert Tait McKenzie (1867–1938) gestaltet. Auf der Vorderseite ist der Kopf von Archimedes dargestellt, daneben befinden sich die Inschrift ΑΡΧΙΜΗΔΟΥΣ (griechisch ‚von Archimedes‘), der antike Sinnspruch TRANSIRE SVVM PECTVS MVNDOQVE POTIRI (lateinisch ‚Den eigenen Verstand überschreiten und sich der Welt bemächtigen‘) und die Initialen RTM des Künstlers mit der falsch geschriebenen römischen Zahl MCNXXXIII für das Jahr 1933 (korrekt wäre MCMXXXIII). Die Rückseite trägt die Inschrift CONGREGATI / EX TOTO ORBE / MATHEMATICI / OB SCRIPTA INSIGNIA / TRIBVERE (lateinisch ‚Die aus der ganzen Welt zusammengekommenen Mathematiker verliehen [die Medaille] aufgrund ausgezeichneter Schriften‘), dahinter ist ein Lorbeerzweig vor einem Diagramm einer einem Zylinder einbeschriebenen Kugel, das auf dem Grabstein von Archimedes eingraviert gewesen sein soll, abgebildet. Auf dem Rand ist der Name des Preisträgers eingeprägt.

Der Mathematiker John Charles Fields war Präsident des Organisationskomitees des ICM 1924 in Toronto, Kanada. Das Komitee hatte nach Abschluss der Planung einen Überschuss von etwa 2.700 kanadischen Dollar und beschloss, 2.500 davon für die Auszeichnung zweier verdienter Mathematiker bei einem der nächsten Kongresse zu verwenden. Als Fields 1932 starb, vermachte er der geplanten Stiftung 47.000 kanadische Dollar. Die Medaille wurde entgegen seinem ausdrücklichen Wunsch, dass sie international und unpersönlich und daher mit keinem Namen verbunden sein sollte, unter seinem Namen bekannt. Das Preisgeld betrug zunächst 1.500 kanadische Dollar und stieg 1983 auf 3.000, 1986 auf 6.000 und 1990 auf 15.000 kanadische Dollar.

Die ersten zwei Fields-Medaillen wurden 1936 verliehen, dem ersten Auswahlkomitee gehörten Birkhoff, Carathéodory, Cartan, Severi und Takagi an. Eine anonyme Stiftung ermöglicht es seit 1966, die Fields-Medaille an bis zu vier Mathematiker zu vergeben. Jean-Pierre Serre wurde 1954 im Alter von 27 Jahren der seither jüngste Preisträger. 1990 erhielt Edward Witten als erster und bisher einziger Physiker den Preis. 2014 wurde die erste und bislang einzige Frau, Maryam Mirzakhani, ausgezeichnet. Sie verstarb 2017 im Alter von 40 Jahren an Krebs.

Der Mathematiker Grigori Perelman, ein Experte auf dem Gebiet des Ricci-Flusses, sollte im Jahr 2006 den Preis für seinen 2002 veröffentlichten Beweis der Poincaré-Vermutung erhalten, lehnte die Auszeichnung jedoch als bisher Einziger ab.

Von den bis 2014 in 18 Verleihungen insgesamt 55 mit der Fields-Medaille ausgezeichneten Personen leben (Stand 15. Juli 2017) noch 41. In sieben Verleihungen wurden je zwei, in drei Verleihungen je drei und in acht Verleihungen je vier Medaillen vergeben. Der bei der ersten Verleihung ausgezeichnete Jesse Douglas starb als erster Fields-Medaillen-Träger. Seit dem Tod von Klaus Friedrich Roth im November 2015 ist Serre der älteste noch lebende Träger. Der jüngste Träger ist der 1979 geborene Artur Ávila. Fünf Medaillen-Träger bekamen ihre Medaille in dem Jahr, in dem sie 40 wurden, reizten das Maximalalter also aus. 26, also knapp die Hälfte, bekamen die Medaille in einem Jahr, in dem sie älter als 36 wurden. Damit war es für sie der letztmögliche Zeitpunkt, mit einer Fields-Medaille ausgezeichnet zu werden.

Die Preiskomitees bestehen in der Regel aus neun Mathematikern, die von ICM zu ICM wechseln, wobei vor der Preisverleihung nur der Vorsitzende des aktuellen Komitees bekanntgegeben wird. Der Vorsitzende ist in der Regel der Präsident der IMU und die Komiteemitglieder werden vom Exekutivkomitee der IMU bestimmt. Mitglieder des Komitees waren:




</doc>
<doc id="10733" url="https://de.wikipedia.org/wiki?curid=10733" title="Gesetz">
Gesetz

Unter Gesetz versteht man einerseits inhaltlich (materiell) alle abstrakt-generellen Rechtsnormen, die menschliches Verhalten regeln und andererseits formell jeden im verfassungsmäßig vorgesehenen Gesetzgebungsverfahren zustande gekommenen Willensakt der Gesetzgebungsorgane eines Staates.

Der Gesetzesbegriff ist immer mit der politischen Struktur der jeweiligen Gemeinschaft verbunden, für welche das Gesetz gilt. Auch Gesetze selbst benutzen das Wort Gesetz, ohne es zu präzisieren. So ist in Abs. 2 GG ein "förmliches Gesetz", in Abs. 1 GG jedoch ein "materielles Gesetz" gemeint. Der Blick in ein bestimmtes Gesetz erfordert genaue Kenntnis der verfassungsrechtlichen Gesetzgebungskompetenzen ( ff., GG), woraus sich ergibt, ob eine bestimmte Regelungsmaterie durch Bundes- oder/und Landesrecht angeordnet werden kann. Das gilt meist auch international bei dezentral organisierten Staaten. Da die Gerichte bei der Kontrolle der Exekutive an das Gesetz gebunden sind ( Abs. 3 GG), dürfen sie ihren Entscheidungen nur materielles Recht (Verfassungsrecht, förmliche Gesetze, Rechtsverordnungen, autonome Satzungen und auch Gewohnheitsrecht) zugrunde legen.

Nach der Wortherkunft bezeichnet der Begriff „Gesetz“ etwas Gesetztes, etwas Festgelegtes. Ein Gesetz ist also im eigentlichen Sinn des Wortes eine Festlegung von Regeln. Daher bezeichnet man den Gesetzgebungsvorgang auch als Rechtsetzung – im Gegensatz zur Rechtsprechung. Laut Duden ist das Gesetz „eine vom Staat festgesetzte, rechtlich bindende Vorschrift“. Von dem Verb „setzen“ leitet sich der Begriff „Satzung“ ab.

Als älteste überlieferte Rechtssammlung gilt der Codex Ur-Nammu, der auf etwa 2100 v. Chr. datiert wird. Um 450 v. Chr. wurde in Rom mit den Zwölftafelgesetzen die erste auf allgemeine Regelungen ausgerichtete Kodifikation geschaffen. Das römische Recht war in der ausgehenden Spätantike (533/534 n. Chr.) im "Corpus Iuris Civilis" aufgezeichnet worden. Der Begriff des Gesetzes wurde in der Antike von Platon und Aristoteles geprägt ("Nomoi" als Tugend), für Aristoteles war die Allgemeinheit das Wesensmerkmal eines Gesetzes. Nach weitgehend unbestrittener Ansicht kam es in vielen griechischen Gemeinwesen des Mutterlandes, Kleinasiens, Siziliens und der Magna Graecia im 6. Jahrhundert zu einer Feststellung des Rechtes durch schriftliche Fixierung der Gesetze, die öffentlich gemacht und dadurch allgemein zugänglich wurden.

Nicht nur Gesetze, die als solche bezeichnet werden (Bürgerliches Gesetzbuch), sondern auch andere Rechtsnormen haben Gesetzescharakter. Die Rechtsverordnung befreit ein vorgeschaltetes, abstrakteres Gesetz von technischen Details und entlastet es von fallspezifischen Anordnungen. Die Ermächtigung zur Rechtsverordnung ist die Übertragung rechtsetzender Gewalt durch die Legislative auf die Exekutive bis hinunter auf Behördenebene ( Abs. 1 GG). Allgemeine Verwaltungsvorschriften und sonstige Anweisungen, durch die eine vorgesetzte Behörde verwaltungsintern auf ein einheitliches Verfahren oder eine bestimmte Ermessensausübung, aber auch auf eine bestimmte Gesetzesauslegung und -anwendung durch die ihr nachgeordneten Behörden hinwirkt, sind jedoch keine Gesetze im Sinne des Abs. 3 GG und des Abs. 1 GG. Die Gerichte sind an das Gesetz gebunden und dürfen ihren Entscheidungen also nur materielles Recht - Verfassungsrecht, förmliche Gesetze, Rechtsverordnungen, autonome Satzungen und auch Gewohnheitsrecht – zugrunde legen. 

Im Regelfall sind Gesetze auf Dauer angelegt. Es gibt jedoch auch Gesetze, die nur zeitlich befristet gelten sollen. Es handelt sich um "Zeitgesetze", die bewusst vom Gesetzgeber nur für einen bestimmten Zeitraum erlassen werden und danach ihre Wirksamkeit verlieren (wie etwa die jährlichen Haushaltsgesetze, Steueränderungsgesetze).

Die rechtswissenschaftliche Terminologie unterscheidet zwischen dem "Gesetz im formellen Sinne" und dem "Gesetz im materiellen Sinne". Dieses Begriffspaar darf nicht mit dem Begriffspaar „formelles Recht“ und „materielles Recht“ verwechselt werden.

Gesetz im materiellen Sinn (auch: "materielles Gesetz") ist jede generell-abstrakte Regelung mit Außenwirkung (Rechtsnorm).

Das ist jede Maßnahme eines Trägers öffentlicher Gewalt, die darauf gerichtet ist, in einer unbestimmten Vielzahl von Einzelfällen bestimmte Rechtsfolgen herbeizuführen, die sich nicht ausschließlich innerhalb dieses Trägers öffentlicher Gewalt auswirken und in diesem Sinne sogenannte Außenwirkung entfalten.

Gesetz im materiellen Sinne ist daher beispielsweise die "16. Verordnung zur Durchführung des Bundes-Immissionsschutzgesetzes (BImSchG)", die kommunale "Abwassergebührensatzung" oder die ordnungsbehördliche "Verordnung über die Benutzung öffentlicher Straßen". Kein Gesetz im materiellen Sinne ist dagegen eine Verwaltungsvorschrift, da sich ihre Rechtswirkungen auf den Innenbereich des erlassenden Trägers öffentlicher Gewalt beschränken. Ebenso wenig Gesetz im materiellen Sinne ist die Baugenehmigung, da sie Rechtsfolgen nicht für eine unbestimmte Vielzahl von Einzelfällen, sondern allein für einen einzigen ganz bestimmten Lebenssachverhalt (nämlich ein individuelles Bauvorhaben) entfaltet. Auch die DIN-Norm ist kein Gesetz. Weder ist das Deutsche Institut für Normung ein Träger öffentlicher Gewalt noch ist die DIN-Norm darauf gerichtet, aus sich heraus Rechtsfolgen irgendwelcher Art herbeizuführen.

Gesetz im formellen Sinn (auch: "formelles Gesetz", "Parlamentsgesetz") ist jede Maßnahme, die in einem Verfahren zustande gekommen ist, das von Verfassungs wegen für den Erlass von Gesetzen vorgesehen ist, von den in der Verfassung dazu bestimmten Organen erlassen worden ist und die in der Verfassung für Gesetze bestimmte Form hat. Gesetz im formellen Sinn ist daher regelmäßig nur diejenige Maßnahme, die vom Parlament in einem Gesetzgebungsverfahren beschlossen und im Gesetzblatt bekannt gemacht worden ist. Beispiele: Das Bürgerliche Gesetzbuch ist daher ein formelles Gesetz, nicht aber die 16. Verordnung zur Durchführung des Bundes-Immissionsschutzgesetzes.

Die beiden Begriffe sind nicht deckungsgleich. Das Gesetz im formellen Sinn kann, aber muss nicht zwingend auch ein Gesetz im materiellen Sinn sein. So dürfte beispielsweise das Magnetschwebebahnbedarfsgesetz, das ausschließlich die Feststellung enthielt, dass Bedarf für eine Magnetschwebebahnverbindung von Hamburg nach Berlin bestehe, kaum als materielles Gesetz anzusehen sein, weil es nicht eine unbestimmte Vielzahl von Einzelfällen, sondern einen ganz individuellen Lebenssachverhalt betraf. Umgekehrt ist nicht jedes Gesetz im materiellen Sinn auch ein Gesetz im formellen Sinn. Letzteres gilt für Verordnungen und Satzungen seitens der öffentlichen Verwaltung.


Die Gesetzgebungsverfahren in Demokratien unterscheiden sich nur gering. Meist wird in den zuständigen Parlamenten oder Abgeordnetenhäusern ein Gesetzesantrag eingebracht "(Gesetzesinitiative)", welcher von parteiübergreifenden Fachgremien ausgearbeitet und anschließend zur Abstimmung vorgelegt wird. Damit ein Gesetz rechtswirksam ist, muss ein festgelegter Verfahrensweg eingehalten werden.

Die Gesetzgebung ist der Legislative vorbehalten. Sie kann die Exekutive ermächtigen, untergesetzliche Normen – Rechtsverordnungen und Satzungen – zu erlassen. Je nach Ausformung der Demokratie sind plebiszitäre Elemente („Volksgesetzgebung“) denkbar.

International und in Deutschland hat sich der Gesetzgeber für eine numerisch gegliederte Einteilung eines Gesetzes entschieden, die mit Paragrafen oder Artikeln bezeichnet wird. In dieser Form werden dann gesetzliche Bestimmungen im Einzelnen zitiert (z. B. BGB). Dabei beginnen die meisten Gesetze häufig mit der Abgrenzung ihres Geltungsbereichs, der durch eine Legaldefinition der verwendeten Begriffe näher beschrieben werden kann. Weitere Untergliederungen in detaillierte Sachgebiete können Abschnitte, Titel und Untertitel sein. Gesetze bedienen sich einer Gesetzessprache, die oft nicht mit der Umgangssprache übereinstimmt. Nach § 42 Abs. 5 Satz 1 GGO müssen Gesetze sprachlich richtig und möglichst für jedermann verständlich gefasst sein. Wer Rechtsvorschriften formuliert, muss sie sprachlich so genau fassen, wie es nach der Eigenart der zu ordnenden Lebenssachverhalte mit Rücksicht auf den Normzweck möglich ist. Die Betroffenen sollen auf Grund der gesetzlichen Regelung in der Lage sein, den rechtlichen Rahmen ohne juristische Beratung zu erkennen und ihr Verhalten entsprechend auszurichten. Aber auch Juristen müssen häufig im Wege der Auslegung den Gesetzesinhalt klären, auch dann, wenn der Gesetzgeber bewusste oder unbewusste Gesetzeslücken hinterlassen hat. Der systematische Aufbau eines Gesetzes beinhaltet Normen, die durch Verbote, Gebote und Kannvorschriften kodifiziert werden. Gesetze befassen sich zunächst mit dem Tatbestand, an den die Rechtsfolge anknüpft. 
Auch heute noch ist die Veröffentlichung eines Gesetzes in offiziellen Publikationen (Bundesgesetzblatt, Bundesblatt etc.) die Rechtsgrundlage für die deklaratorische Rechtswirksamkeit eines Gesetzes, während die konstitutive Rechtswirksamkeit mit seinem Inkrafttreten beginnt. Die Regelung des Inkrafttretens gehört zu den Schlussbestimmungen eines Gesetzes. Der Grundsatz Nulla poena sine lege ("Keine Strafe ohne Gesetz") verbietet die Rückwirkung von Strafvorschriften, so dass solche nur vom Tag des Inkrafttretens an für die Zukunft gelten können.

Zwischen verschiedenen (materiellen) Gesetzen besteht eine Rangfolge in der Weise, dass das jeweils untergeordnete Gesetz den inhaltlichen Vorgaben des übergeordneten Gesetzes, auf dem es beruht, entsprechen muss (sogenannte Normenhierarchie). Im innerstaatlichen Recht steht die Verfassung an der Spitze; in ihr die Normen, die mit der sogenannten Ewigkeitsgarantie ausgestattet sind. Unter der Verfassung stehen die formellen Gesetze (so genannte "einfache Gesetze"), hierunter die Verordnungen und Satzungen. Recht, das den übergeordneten Normen nicht entspricht, ist üblicherweise nichtig (zur Ausnahme in der Schweiz bezüglich Bundesgesetzen siehe im Artikel Verfassungsgerichtsbarkeit unter Schweiz). In Deutschland kann bei nachkonstitutionellen Gesetzen im formellen Sinne die Nichtigkeit nur vom Bundesverfassungsgericht bzw. dem zuständigen Landesverfassungsgericht ausgesprochen werden (Verwerfungsmonopol).

In der Bundesrepublik Deutschland gab es im Jahr 2003 insgesamt 2.197 Bundesgesetze mit 45.511 Paragraphen und 3.131 Bundesrechtsverordnungen. Am 31. Dezember 2009 umfasste das deutsche Bundesrecht 1.924 Gesetze und 3.440 Verordnungen mit insgesamt 76.382 Artikeln und Paragraphen (Angaben nach Fundstellennachweis A, ohne Änderungsvorschriften und Normen zu völkerrechtlichen Vereinbarungen).
Hinzu kommen die Gesetze und Rechtsverordnungen der 16 Länder.

31,5 % aller deutschen Gesetze beruhen der Bundestagsverwaltung zufolge auf EU-Vorgaben. Dabei ist die Verteilung innerhalb der Ressorts jedoch sehr unterschiedlich. Während im Innenministerium 23 % aller Gesetze durch die EU veranlasst waren, kam das Wirtschaftsressort auf 38 %.

Auf Ebene der Europäischen Union (EU) bestanden im Jahr 2011 etwa 32.000 Rechtsakte. Davon waren insgesamt 1.844 Richtlinien oder Rahmengesetze sowie 8.471 Verordnungen.

Gesetze im Rechtswesen gelten meist lediglich in einem bestimmten nationalen Rechtsgebiet, ausnahmsweise gibt es auch supranationales Recht wie das UN-Kaufrecht oder EU-Recht. Die Wissenschaften außerhalb der Rechtswissenschaft kennen jedoch auch orts-, zeit- und kulturunabhängige Gesetze, etwa physikalische Gesetze wie Gaußsches Gesetz, Faradaysche Gesetze oder Ohmsches Gesetz (Naturwissenschaften), die jeweils aus einer Theorie abgeleitet wurden. Gesetze sind in der Naturwissenschaft ausnahmslos geltende Regeln für den Ablauf des Geschehens, sie gelten daher weltweit. Auch die Wirtschaftswissenschaften kennen Gesetze wie das Bodenertragsgesetz, Gesetz der Massenproduktion oder Greshamsches Gesetz. Ludwig von Mises zufolge strebe die Nationalökonomie „nach allgemeingültigen Gesetzen des menschlichen Handelns“, also „nach Gesetzen, die Geltung beanspruchen ohne Rücksicht auf Ort, Zeit, Rasse, Volkstum oder Klasse der Handelnden“. Gesetz ist, was keine Ausnahmen zulässt, „Regel“ ist, was Ausnahmefälle zu denken erlaubt.

In anderen Ländern mit rechtsstaatlicher Verfassung erfüllen Gesetze (, , , ) materiell und formell dieselben Voraussetzungen. Sie beruhen allerdings auf unterschiedlichen Rechtskreisen. Zum deutschen Rechtskreis gehören Österreich, die Schweiz, Liechtenstein, Luxemburg sowie Griechenland. Das französische Recht basiert auf dem Code civil, das angelsächsische (insbesondere Großbritannien und die USA) auf dem Common Law, das islamische fußt auf der Scharia. Wo unterschiedliche Rechtskreise und Gesetzesnormen bei Auslandsberührung kollidieren, kommt das Internationale Privatrecht zum Einsatz.



</doc>
<doc id="10734" url="https://de.wikipedia.org/wiki?curid=10734" title="Wolf Vostell">
Wolf Vostell

Wolf Vostell (* 14. Oktober 1932 in Leverkusen; † 3. April 1998 in Berlin) war ein deutscher Maler, Bildhauer und Happeningkünstler der zweiten Hälfte des 20. Jahrhunderts.

Wolf Vostell gilt als einer der Wegbereiter des Environments, der Installation, der Videokunst, des Happenings und der Fluxus-Bewegung. Techniken wie die Verwischung, die Dé-coll/age oder das Einbetonieren sind Kennzeichen seiner Werke.

Wolf Vostell war der Sohn von Hubert Schäfer (1896–1980) und dessen Ehefrau Regina Schäfer (1901–1976), geborene Vostell.

1939 siedelten seine Eltern mit ihm und seiner jüngeren Schwester Isolde ins Sudetenland um, wo sie in Komotau die Kriegsjahre verbrachten. Im Jahr 1945, nach der Befreiung Deutschlands vom Nationalsozialismus, kehrte die Familie nach Leverkusen zurück. Als Schüler zeichnete er in den Jahren 1945 bis 1950 mit Tusche und Aquarell.

1952 nahm er den Geburtsnamen seiner Mutter an.

1958 lernte er in Guadalupe die junge Lehrerin Mercedes Guardado Olivenza Vostell kennen und verliebte sich in sie. 1959 heirateten beide in Cáceres und gingen anschließend nach Köln. Sie war für ihn „Muse, Mutter, Modell, engste Mitarbeiterin, Museumsgründerin, Familienunternehmerin“ wie aus einem Feature mit ihr hervorgeht. Er bezeichnet sie als seine „unzertrennliche Kooperantin“.

1974 besuchte Vostell das westspanische Dorf Malpartida de Cáceres in der Extremadura und die in der Nähe liegende Felsenlandschaft Los Barruecos. Die bizarren Granit-Findlinge erinnerten ihn an seine eigenen Betonplastiken und er erklärte den Ort zu einem „Kunstwerk der Natur“. Inmitten dieser „surrealen“ Landschaft liegt die Anlage des „Lavadero de Lanas“, einer Wollwäscherei aus dem 18. Jahrhundert und gemäß seinem Kunstbegriff "Kunst ist Leben, Leben ist Kunst" beschloss er hier einen „Treffpunkt für Kunst, Leben und Natur“ einzurichten.

Die Idee zum „Museum für den Kunstbegriff der zweiten Hälfte des 20. Jahrhunderts“ war geboren und daher ist für den Visionär Vostell 1974 auch das Gründungsjahr des Museums. Zunächst musste jedoch Überzeugungsarbeit geleistet werden. Einen Unterstützer fand Vostell im Bürgermeister, der auch den zunächst skeptischen Gemeinderat für das Projekt gewinnen konnte. 1976 erwarb die Gemeinde das Areal der Lavadero und stellte es zusammen mit einem angrenzenden Teil der Barruecos dem Künstler zur Verfügung.
Im Oktober 1976 wurde schließlich das Museo Vostell Malpartida (MVM) zusammen mit der Aktionsplastik "VOAEX" ("Viaje de (H)ormigon por la Alta Extremadura" / "Betonreise durch die Obere Extremadura") einen inmitten von Granitfelsen einbetonierten Opel Admiral feierlich eingeweiht. Vostell schuf extra für dieses Museum einige weitere Werke wie etwa die Installation "Requiem für die Vergessenen" oder "Das Ende von Parzival" ("El Fin de Parzival") einen Vorhang aus 20 Motorrädern nach einer Idee von Salvador Dali. Ende 1993 hielt er den Aufbau des Museums für abgeschlossen. Zum Bestand des Museums gehören etwa 50 Arbeiten Vostells aus vier Jahrzehnten: Skulpturen, Reliefs, Gemälde, Zeichnungen und Installationen.
Mercedes und Wolf Vostell erwarben 1977 das schlecht erhaltene Herrenhaus "Palacio de Topete" in Malpartida de Cáceres aus dem 18. Jahrhundert und renovierten es nach und nach. Im Januar 1978 organisiert Vostell hier die "Woche der Zeitgenössischen Kunst" ("SACOM"), eine der ersten Ausstellungen zeitgenössischer Kunst in der Extremadura mit dem Titel "Koexistenz". So wurde dieses Dorf neben Berlin zu ihrem zweiten Wohnsitz. Für den Rest seines Lebens sollte er mit dem Ort verbunden bleiben und ständig zwischen Berlin und Malpartida pendeln.

1998 starb Wolf Vostell während eines Berlinaufenthalts an Herzversagen. Sein Grab befindet sich, wie es sein Wunsch war, auf dem Cementerio de la Almudena in Madrid. Danach übernahm seine Frau die künstlerische Leitung des Museums und kuratiert den Nachlass ihres Mannes. Mercedes Guardado Olivenza Vostell, wie ihr vollständiger Namen lautet, verwendet gelegentlich auch eine kürzere Form: „Mercedes Guardado de Vostell“, ein kleines Wortspiel unter Verwendung ihres ersten Nachnamens, der dem Partizip Perfekt des spanischen Wortes „guardar“ entspricht und die Bedeutungen von halten, bewahren oder hüten hat. Dadurch wird sie buchstäblich zur „Bewahrerin von Vostell“. Das Prinzip des Bewahrens findet sich auch in der Biografie, die sie 2011 auf Spanisch und 2012 auf Deutsch veröffentlichte.
Von 1950 an setzte Vostell erste künstlerische Ideen um, 1953 begann er eine Lithografenlehre und besuchte die Werkkunstschule an der Bergischen Universität in Wuppertal. Am 6. September 1954 fand er in Paris auf der Titelseite des Le Figaro das Wort "décollage" (dt. "abheben, losmachen, sich Lösen des Geleimten, trennen"), das im Zusammenhang mit einem Absturz einer Lockheed Super Constellation in den Shannon benutzt wurde. Vostell änderte für sich die Schreibweise in "Dé-coll/age" und übertrug den Begriff auf seine Plakatabrisse und Happenings. "Dé-coll/age" wurde für Wolf Vostell zum Gestaltungsprinzip und umfassenden Kunstbegriff.

1955/1956 besuchte er die Pariser École nationale supérieure des beaux-arts und 1957 die Kunstakademie Düsseldorf. Vostells Happening "Das Theater ist auf der Straße" von 1958 in Paris war das erste Happening in Europa. Sein Happening "Cityrama" von 1961 in Köln war das erste Happening in Deutschland. Vostell produzierte Objekte mit Fernsehern und Autoteilen. Beeinflusst von der Arbeit Karlheinz Stockhausens im elektronischen Studio des WDR im Jahre 1954, entstanden 1959 elektronische "TV-Dé-coll/agen". Damit begann sein Engagement in der Fluxus-Bewegung, die er Anfang der 1960er Jahre mitbegründete.

1959 gründete Vostell das Vostell-Archiv. Wolf Vostell sammelte Fotografien, künstlerische Texte, persönliche Korrespondenz mit Weggefährten wie Nam June Paik, Joseph Beuys, Dick Higgins, sowie weitere Objekte, die das Schaffen der Künstler seiner Generation dokumentierten. Seit den 1990er Jahren ist Vostells Privatbibliothek Teil des Archivs. Sein Werk ist fotografisch dokumentiert und ebenfalls Bestandteil des Archivs, das sich seit 2006 im Museo Vostell Malpartida befindet.

Vostell initiierte weitere Happenings, unter anderem 1963 "9-Nein-dé-coll/agen" in Wuppertal, 1964 in New York das Happening "You" und weitere in Berlin, Köln, Wuppertal und Ulm. 1963 wurde Wolf Vostell mit der Installation "6 TV Dé-coll/age" heute in der Sammlung des Museo Reina Sofía Madrid und mit dem Video "Sun in your head" zum Pionier der Videokunst. 1965 nahm er am 24-Stunden-Happening in der Galerie Parnass in Wuppertal teil. 1967 setzte er sich im Happening "Miss Vietnam" mit dem Vietnamkrieg auseinander. 1968 kam es in Zusammenarbeit mit dem Komponisten Mauricio Kagel und anderen zur Gründung des "Labor e. V.", welches akustische und visuelle Ereignisse erforschen sollte.

Vostell gilt als der erste Künstler, der ein Fernsehgerät in ein Kunstwerk integrierte. Dieses aus drei Assemblagen bestehende Environment aus dem Jahre 1958 mit dem Titel "Das schwarze Zimmer" ("Deutscher Ausblick", "Auschwitz-Scheinwerfer", "Treblinka") ist Teil der Sammlung der Berlinischen Galerie. Frühe Werke mit Fernsehern sind "Transmigracion" I bis III, aus dem Jahre 1958 und "Elektronischer dé-coll/age Happening Raum", eine Installation aus dem Jahr 1968.

1953 entstanden zunächst traditionell gefertigte Arbeiten wie "Korea" und "Korea Massaker" (beide Öl auf Papier), "Kriegskreuzigung II" (Öl auf Leinwand) sowie die Aquarelle "Das Paar", "Familie", "Flugzeug" und "Kriegskreuzigung". 1955 zeichnete er einen Zyklus von Tusche-Zeichnungen zu Peter Schlemihls wundersamer Geschichte.

1962 nahm Vostell an der Fluxus-Manifestation "Fluxus: Internationale Festspiele Neuester Musik" in Wiesbaden und 1963 am Fluxus-Festival "Festum Fluxorum Fluxus" in Düsseldorf teil. 1962 gründete er die Zeitschrift "Dé-coll/age – Bulletin aktueller Ideen". 1963 zeigte er die Installation "Das schwarze Zimmer", die in einem dunklen Raum mit schwarz bemalten Wänden installiert ist, in der Galerie Parnass. 1964 initiierte Vostell das Happening "In Ulm, um Ulm und um Ulm herum" – im selben Jahr hatte er seine erste Ausstellungsbeteiligung an der 13. Ausstellung des Deutschen Künstlerbundes in Berlin. 1965 folgten "Berlin 100 Ereignisse" und 1967 "Miss Vietnam". Er griff oft politische und soziale Themen auf.

In den Jahren 1965 bis 1969 entstanden in Zusammenarbeit mit René Block Ausstellungen, Happenings, Multiples und Publikationen. 1968 entstand der Siebdruck "B-52 – statt Bomben". 1969 entstand – in Zusammenarbeit mit der Galerie "art intermedia" von Helmut Rywelski in Köln – Vostells erste Auto-Beton-Skulptur, der "Ruhender Verkehr".
1970 zog Vostell nach Berlin. 1970 entstand "Heuschrecken", eine Installation mit 20 Monitoren und einer Videokamera. Die Installationen "TV-Schuhe" und "TEK" entstanden im selben Jahr. 1973 entstand der Zyklus "Mania". 40 Arbeiten, bei denen Vostell auf Fotografien aus Zeitschriften zeichnete und Objekte auf die Fotografien klebte. 1973 entstanden die Installationen "Auto Fieber" und "Energie". 1976 gründete Vostell in Malpartida de Cáceres das Museo Vostell Malpartida. In Berlin realisierte er 1974 das Happening "Erdbeeren".

Ab 1975 beschäftigte er sich mit spanischen Themen wie mit den Gemälden des Zyklus "Extremadura", dem Zyklus "El muerto que tiene sed" ("Der Tote der Durst hat") von 1976 oder 1985 "El entierro de la Sardina" ("Das Begräbnis der Sardine"). In den 1980er Jahren entstanden die Installation "Die Winde", das Gemälde "Die Schlacht von Anghiari" von 1982, eine Reminiszenz an Leonardo da Vincis gleichnamiges Gemälde "Schlacht von Anghiari", der Zyklus "Milonga" von 1985, und die "Tauromaqie mit BMW-Teil" von 1988.

In Berlin entstanden großformatige Gemälde wie zum Beispiel das Triptychon "Berlin" aus dem Jahr 1990, der Zyklus "Weinende" von 1992 und "Weinende Hommage an Anne Frank". Bronze-Skulpturen wie zum Beispiel "Berlinerin" von 1994 in einer kleinen Auflage. Es entstanden grafische Arbeiten, Skulpturen und Assemblagen wie "Arc de Triomphe N°1" von 1993, "Ritz" von 1998 und Multiples wie das "Berliner Brot" aus dem Jahr 1995.

Während eines Aufenthalts in Paris las Vostell im September 1954 in einer Schlagzeile des Le Figaro das Wort Décollage (deutsche Übersetzung losmachen, losgehen des Geleimten, trennen). Vostell änderte für sich die Schreibweise. Er benannte von 1954 an seine Plakatabrisse Dé-coll/age. Später übertrug er den Begriff Dé-coll/age auf seine Happenings. Für Wolf Vostell wurde die Dé-coll/age zum Gestaltungsprinzip und umfassenden Kunstbegriff. "Ceres" aus dem Jahr 1960, "Coca-Cola", "Ihr Kandidat", "Grosse Sitzung mit Da" (alles Bilder aus dem Jahr 1961), "Wochenspiegel Beatles" und "Livio" aus dem Jahr 1966 sind Beispiele für Wolf Vostells Dé-coll/agen.

In den 1960er Jahren arbeitete Wolf Vostell mit der Technik der Verwischung. Mit einer Mischung aus Terpentin und Tetrachlorkohlenstoff lassen sich Fotografien in Zeitschriften verwischen. Der Zyklus "Kleenex" von 1962, "Kennedy vor Corham" von 1964, "Goethe Heute" von 1967 und "Hommage an Henry Ford und Jaqueline Kennedy" von 1967 sind Beispiele für Wolf Vostells Verwischungen. Er kombinierte die Dé-coll/age mit der Verwischung wie zum Beispiel bei "Jayne Mansfield" von 1968 und "Marilyn Monroe" von 1962 oder "Hours of fun" aus dem Jahr 1968.

Wolf Vostell setzte sich in seinem künstlerischen Schaffen seit den 1950er Jahren mit weltpolitischen Ereignissen auseinander. Er thematisierte schon 1958 den Zweiten Weltkrieg und den Holocaust in der Installation "Das schwarze Zimmer". Der Koreakrieg und der Vietnamkrieg wurden Themen seiner Werke, so wie bei seiner Verwischung "Miss America" von 1968. Die Ermordung von John F. Kennedy und weitere internationale politische Ereignisse thematisierte er in seinen Bildern und Assemblagen.

Wolf Vostell thematisierte innenpolitische Themen der Bundesrepublik. Die Studentenrevolten, das Wirtschaftswunder und die Kapitalismuskritik sind in seinen Werken dokumentiert. Der Kalte Krieg und der Bosnienkrieg sind in seinen Werken präsent. Den Fall der Berliner Mauer dokumentierte und verarbeitete Wolf Vostell in über 50 Werken. Vom 6 Meter breiten Triptychon "9. November 1989" bis zu kleineren Arbeiten ist durch den Fall der Berliner Mauer bei Wolf Vostell ein weiterer Werkzyklus entstanden. Über die Jahrzehnte ist in Wolf Vostells Werk ein politisches Werk entstanden.

Seit 1958 integrierte Wolf Vostell Fernsehgeräte in seine Werke. Bilder, Assemblagen, Installationen und Skulpturen Wolf Vostells sind oftmals mit TV-Geräten gestaltet. Meistens sind die Geräte auf normales Programm eingestellt. Wolf Vostell bezieht so die Aktualität und das Zeitgeschehen in seine Werke mit ein.

Ab 1976 reiste Wolf Vostell regelmäßig zwischen Berlin und Malpartida de Cáceres. In seinem spanischen Atelier entstanden über die Jahre eine Reihe von Bildern und Zeichnungen, die das Thema Tauromaquia zeigen. Großformatige Leinwände zeigen Stiere, meist blutend und zerfetzt. Er fertigte Assemblagen, bei denen er gemalte Stierköpfe mit Glühlampen, Autoteilen oder anderen Objekten verband.

Seit den frühen 1960er Jahren arbeitete Wolf Vostell mit Beton, was zu einer Art Erkennungszeichen seiner Werke wurde. Er schuf Skulpturen, wie zum Beispiel seine Auto-Beton-Skulpturen. Er verarbeitete den Beton auch flüssig als Farbe für seine Bilder und Zeichnungen. Er malte mit flüssigem Beton, Acrylfarbe und Kohle. In seinen Bildern und Zeichnungen sind vielmals gezeichnete Betonblöcke zu sehen. Menschliche Körper sind oft als eckige Betonformen zu erkennen. In den 1980er und 1990er Jahren arbeitete er mit flüssigem Blei. Er goss flüssiges Blei über seine Leinwände, kombinierte Acrylfarbe, flüssiges Blei und flüssigen Beton. Wolf Vostell arbeitete auch mit Blattgold, welches er direkt auf die Leinwand auftrug.

1989 eröffnete das "Art’otel Berlin Kudamm", das Wolf Vostell als Thema hat und somit zu einer Dauerausstellung wurde.

1990 wurden Vostells Triptychon "9. November 1989" und Entwurfszeichnungen dazu erstmals im Ostteil Berlins in der Galerie am Weidendamm in der Friedrichstraße 103 ausgestellt.

1992 ehrte die Stadt Köln Vostell mit einer Retrospektive seines Schaffens. Seine Werke wurden auf sechs Ausstellungsorte verteilt: das Kölnische Stadtmuseum, die Kunsthalle Köln, das Rheinische Landesmuseum Bonn, die Kunsthalle Mannheim, das Schloss Morsbroich in Leverkusen und das Kunstmuseum Mülheim an der Ruhr. Unter der künstlerischen Leitung von David Vostell entstand über diese Retrospektive der Dokumentarfilm "Vostell 60 - Rückblick 92".

Seit 1989 steht auf dem Mittelstreifen des Hohenzollernrings in Köln die Auto-Beton-Skulptur "Ruhender Verkehr" aus dem Jahr 1969. Vostell goss hierfür einen Opel Kapitän in Beton. Weitere Auto-Beton-Skulpturen sind "Concrete Traffic" aus dem Jahr 1970 in Chicago, im Museo Vostell Malpartida "VOAEX" aus dem Jahr 1976 und "Zwei Beton Cadillacs in Form der nackten Maja" in Berlin aus dem Jahr 1987.


In seiner Geburtsstadt Leverkusen ist Wolf Vostell im Museum Morsbroich mit Arbeiten aus den Jahren 1959 bis 1982 ständig vertreten.

In der Sammlung der Berlinischen Galerie befinden sich einige Werke von Wolf Vostell. Unter anderem die Installation "Das schwarze Zimmer" aus dem Jahr 1958, "Wir waren so eine Art Museumsstück" von 1964, "Hours of fun" von 1968 oder "Die Schlacht von Anghiari" aus dem Jahr 1986. Eine umfangreiche Sammlung von Werken ist im Museum Fluxus Plus zu sehen.

Das Museo Vostell Malpartida zeigt in seiner ständigen Sammlung Werke aus den 1970er Jahren, wie "Auto-Fieber", "Energie" und "VOAEX", aus den 1980er Jahren, wie "El Entierro de la Sardina", "Las Chicas del Billar" und "Mythos Berlin" und aus den 1990er Jahren, wie zum Beispiel der Zyklus "Trashumancia". Im Museo Vostell Malpartida befindet sich das "Vostell-Archiv".

Mehrere Werke von Wolf Vostell, wie zum Beispiel die Dé-coll/age "Coca-Cola" von 1961, die Installation "Hommage an Henry Ford und Jaqueline Kennedy" von 1967 und die Verwischung "Miss America" von 1968, befinden sich in der Sammlung des Museum Ludwig in Köln. Frühe Werke wie zum Beispiel der "Elektronischer dé-coll/age Happening Raum" von 1968 befinden sich in der Neue Nationalgalerie in Berlin. "Heuschrecken" aus dem Jahr 1970 ist im Museum Moderner Kunst Stiftung Ludwig Wien zu sehen und "Marilyn Monroe" in der Neuen Galerie.

Weitere Werke befinden sich im Zentrum für Kunst und Medientechnologie, im Haus der Geschichte der Bundesrepublik Deutschland, im Germanischen Nationalmuseum, im Rheinischen Landesmuseum Bonn, im Museo Reina Sofia, im Musée d’art moderne de la Ville de Paris, im Musée d’Art Moderne et Contemporain de Strasbourg, in der "Fondazione Mudima" in Mailand, auf öffentlichen Straßen und Plätzen und in weiteren Museen und privaten Sammlungen weltweit.







</doc>
<doc id="10737" url="https://de.wikipedia.org/wiki?curid=10737" title="Ruhrgebiet">
Ruhrgebiet

Das Ruhrgebiet (auch Revier, Ruhrpott, Kohlenpott, Pott oder Ruhrstadt genannt) ist mit rund 5,1 Millionen Einwohnern und einer Fläche von 4435 Quadratkilometern der größte Ballungsraum Deutschlands und der fünftgrößte Europas. Namensgebend für diese dicht besiedelte zentrale nordrhein-westfälische Region ist der am südlichen Rand verlaufende Fluss Ruhr. Mit seinem ebenfalls dicht besiedelten Umland und den Ballungsräumen an der Rheinschiene, die weit in die Kölner Bucht reichen, bildet es die Metropolregion Rhein-Ruhr, in der auf einem Gebiet von rund 7000 Quadratkilometern etwa zehn Millionen Menschen leben. Sie ist der zentrale Teil der europäischen Megaregion „Blaue Banane“. Pläne zur Bildung einer "Metropole Ruhr" werden oft unter dem Begriff "Ruhrstadt" zusammengefasst.

Das Ruhrgebiet wird im Wesentlichen von mehreren zusammengewachsenen Großstädten gebildet. Von den Ansiedlungen am mittleren Niederrhein geht die Städtelandschaft nach Westen nahtlos in den Rhein-Ruhr-Raum und nach Süden in die Rheinschiene über. Die Oberzentren und Kernstädte des Ruhrgebiets Dortmund, Bochum, Essen und Duisburg entstanden bereits im Mittelalter entlang des westfälischen Hellwegs und erreichten ihre heutige Struktur mit der Industrialisierung und dem Bergbau im 19. und 20. Jahrhundert.

Der Begriff "Ruhrgebiet" orientiert sich üblicherweise an den Grenzen des 1920 gegründeten "Siedlungsverbands Ruhrkohlenbezirk", dem heutigen Regionalverband Ruhr (RVR). Zum RVR gehören die kreisfreien Städte Bochum, Bottrop, Dortmund, Duisburg, Essen, Gelsenkirchen, Hagen, Hamm, Herne, Mülheim an der Ruhr und Oberhausen sowie die Kreise Recklinghausen, Unna, Wesel und der Ennepe-Ruhr-Kreis, die den Landesteilen Rheinland und Westfalen angehören. Die Daten im Folgenden beziehen sich auf das Verwaltungsgebiet des RVR.

Das Ruhrgebiet war im Jahr 2010 unter der Kurzbezeichnung RUHR.2010 neben Pécs (Ungarn) und Istanbul Kulturhauptstadt Europas.

Der Regionalverband Ruhr hat im Jahre 2012 die räumliche Ausdehnung und die Grenzen des Ruhrgebiets bestimmt. In diesem Zusammenhang wurde der Mittelpunkt des Ruhrgebiets rechnerisch zwischen den westlichsten und östlichsten sowie den nördlichsten und südlichsten Punkten ermittelt. Der Schnittpunkt und somit der Mittelpunkt der „Metropole Ruhr“ liegt im Herner Stadtteil Röhlinghausen an der Rolandstr. 49 in . An dieser Stelle wurde am Rand des Gehwegs ein Granitstein mit der Aufschrift "Sie befinden sich am geografischen Mittelpunkt des Ruhrgebiets in Herne-Röhlinghausen" aufgestellt.

"Zur Kartografie siehe: Ruhr3.de"
Das Ruhrgebiet hat an mehreren naturräumlichen Einheiten Anteil. Die Städtelandschaft liegt im Schnittpunkt der Westfälischen Tieflandebene, der Niederrheinischen Ebene und des Rheinischen Schiefergebirges. Nördlich der Lippe schließen die naturräumlichen Einheiten des Westmünsterlands und des Kernmünsterlands an. Südlich der Ruhr reicht es ins Bergische und Märkische Hügelland. Nördlich der Ruhr schließen sich die Lößebenen des Naturraums Westenhellweg an. Zwischen der Lippe und dem Westenhellweg liegt das Emscherland. Die Emscher trennt die Westfälische Bucht vom Rheinischen Schiefergebirge. Eckpunkte sind im Nordwesten Wesel (Kreis Wesel), im Südwesten Duisburg, im Südosten Hagen und im Nordosten Hamm. Die West-Ost-Ausdehnung von Sonsbeck bis Hamm beträgt 116 Kilometer, die Nord-Süd-Ausdehnung von Haltern am See bis Breckerfeld 67 Kilometer.

Den Angaben des Regionalverbandes Ruhr (RVR) zufolge sind 37,6 Prozent der Fläche des Ruhrgebiets bebaut. 40,7 Prozent der Fläche werden landwirtschaftlich genutzt. Der Waldanteil beträgt 17,6 Prozent. Die übrigen Anteile entfallen auf Wasserflächen und sonstige Flächen. Der für eine Industrieregion relativ hohe Anteil an Wald- und Landwirtschaftsflächen erklärt sich zunächst durch die ebenfalls zum RVR gehörigen vier überwiegend ländlich geprägten Kreise. Außerdem besitzen auch die kreisfreien Städte des Ruhrgebiets in ihren Außenbezirken ländlichen Charakter. Dazu gehört die Siepentallandschaft, die schon die zu Beginn des 20. Jahrhunderts geschlossenen Eingemeindungsverträge als schützenswerte „Talmulden“ eingestuft hatten. Auch der Siedlungsverband Ruhrkohlenbezirk hatte das Ziel, das Zusammenwachsen der einzelnen Städte und eine Zersiedelung zu verhindern. Dazu kaufte er ab 1923 Grundstücke auf, hielt sie von Bebauungen jeder Art frei und legte sie als Regionale Grünzüge planerisch fest. Ihr Nord-Süd-Verlauf ist bis heute zwischen den Städten im Ballungsraum des Ruhrgebietes trotz grundsätzlicher Zielkonflikte erhalten geblieben.

Auf einer Karte betrachtet könnte man das Ruhrgebiet für eine einzige Großstadt halten, da es, zumindest in der West-Ost-Ausdehnung, keine erkennbaren Grenzen zwischen den einzelnen Städten gibt. So ist das Ruhrgebiet als polyzentrische Städtelandschaft zu bezeichnen. Man spricht in diesem Zusammenhang auch von der Ruhrstadt oder „Metropole Ruhr“. Der Raum ist gekennzeichnet durch seine ähnliche stadt- und wirtschaftsgeografische Entwicklung.

Das Ruhrgebiet ist aufgrund seiner Geschichte anders strukturiert als monozentrische Agglomerationen wie Paris, die durch das rasche Zusammenwachsen kleinerer Orte und Städte mit einer Kernstadt entstanden sind. Die einzelnen Städte und Stadtteile des Ruhrgebiets sind während der Industrialisierung unabhängig voneinander gewachsen. Die Bevölkerungsdichte der Kernzone des Ruhrgebiets liegt bei knapp 2.100 Einwohnern pro Quadratkilometer.
Hätte Berlin die Bevölkerungsdichte des Ruhrgebiet, so lebten dort nur etwa 1,8 Millionen Menschen.

Die Übergänge zwischen den Städten sind durch eine lockere Vorortbebauung, unbebaute Gebiete und mitunter sogar durch landwirtschaftlich genutzte Flächen geprägt. In der Kernzone des Ruhrgebiets verlaufen die Stadtgrenzen teilweise quer durch dicht bebaute Außenbezirke und sind nur schwer zu erkennen. Häufig ist der Wechsel des Stadtgebiets nicht einmal an einem Wechsel der Straßennamen zu ersehen, da die Straßen in Randlage die Stadtgrenzen mehrfach überschreiten können und, um Verwirrung zu vermeiden, durchgängig benannt und nummeriert sind.

Die Entwicklung des Ruhrgebiets vom ursprünglichen Naturraum zum Standort der Montanindustrie und die rasante Besiedlung während der Industrialisierung ist ein häufig gewählter Forschungsgegenstand der Anthropogeografie. So wird aktuell beispielsweise die Siedlungsgeschichte des Ruhrgebiets in Bezug auf das klassische System der zentralen Orte untersucht.

Im Zuge der Rekultivierung von Industriebrachen entstehen neue Parklandschaften und Naherholungsgebiete wie etwa der Hoheward, ein Landschaftspark im nördlichen Ruhrgebiet. Entlang der erst teilweise renaturierten Emscher bildet der Emscher Landschaftspark, der die durch den SVR in Nord-Süd-Richtung angelegten regionalen Grünzüge verbindet, einen in Ost-West-Richtung verlaufenden Grüngürtel zwischen den Städten. Die zahlreichen Garten- und Parkanlagen der Region sind in das European Garden Heritage Network eingebunden.

Geologisch wird das Ruhrgebiet regelmäßig über das Vorkommen von kohleführenden Schichten des Oberkarbon definiert, mehr oder weniger unabhängig von deren Tiefenlage. Die Kohlenflöze streifen entlang der Ruhr die Oberfläche und senken sich nach Norden ab. In Höhe der Lippe liegen sie in einer Tiefe von 600 bis 800 Meter. Die Mächtigkeit der Schichten liegt durchschnittlich bei 1–3 Meter.
Die Geologie des Untergrundes war entscheidend für die Entwicklung des Kohlebergbaus im Ruhrgebiet. Sie hängt mit der Entstehung des Superkontinentes Pangaea zusammen. Zu Beginn der variszischen Gebirgsbildung vor 400 bis 300 Millionen Jahren in den Zeitabschnitten Devon und Karbon (der Name bedeutet "Kohlezeit") begann im Zuge der Gebirgsbildung an tektonischen Störungslinien der Aufstieg von Erzlösungen und es entstanden einige Erzlagerstätten.

Gleichzeitig mit dem Aufstieg des Rheinischen Schiefergebirges im Oberkarbon setzte eine Absenkung des nördlichen Vorlandes ein, in das periodisch Sedimente geschüttet wurden. Das Ablagerungsmilieu wechselte über Jahrmillionen hinweg zwischen einem Flachmeer, der Entstehung von Flussdeltas und der Verlandung durch erodierte Sedimente aus dem neuen Gebirge. Im damals feucht-warmen Klima konnten sich große Moore bilden, die häufig von mächtigen sandigen Sedimenten überschichtet wurden, was die Inkohlung des pflanzlichen Materials bewirkte. So entstanden im Untergrund hunderte von kohleführenden Schichten. Von ihnen waren und sind allerdings nur jene 70–80 Flöze abbauwürdig, die eine ausreichende Mächtigkeit erreichen. Die großräumige Absenkung bewirkte, dass heute bei Witten (Südrand des Ruhrgebietes) die Kohle bis zur Erdoberfläche heraufreicht, aber am Nordrand (zum Beispiel bei Marl) etwa 1500 Meter tief liegt.

Die Landschaft des heutigen Ruhrgebietes ähnelte Ende des 18. Jahrhunderts dem Münsterland, dem Niederrhein oder der Soester Börde. Einzelne Städte, darunter etliche Hansestädte, vor allem am Hellweg, sowie durch Landwirtschaft geprägte Freiheiten und Dörfer bestimmten das Bild. Anfang des 19. Jahrhunderts waren Duisburg und Dortmund die größten Städte mit lediglich etwa 5.000 Einwohnern. Zur selben Zeit lebten in der Munizipalität Mülheim an der Ruhr im Süden der Region bereits mehr als 11.000 Menschen. Dagegen hatten Gelsenkirchen und Herne im nördlich gelegenen Emscherland zu dieser Zeit erst einige hundert Einwohner.

Einzelne Eisenhütten bildeten frühe Kerne der Industrialisierung. Hervorzuheben sind die 1758 entstandene St.-Antony-Hütte in Oberhausen-Osterfeld, die 1782 gegründete Gutehoffnungshütte in Oberhausen-Sterkrade und die Eisenhütte Neu-Essen in Oberhausen-Lirich, in der ab 1791 produziert wurde. Hier entstanden bereits früh wichtige Technologien der Eisenerzeugung bei der Verhüttung der abgebauten Erze unter Verwendung von Holzkohle.

Kohle wurde zwar schon im 13. Jahrhundert abgebaut, jedoch konnte zu dieser Zeit noch nicht von Bergbau, sondern eher von Kohlengräberei gesprochen werden. Ein Ausgangspunkt des Ruhrbergbaus war das Muttental bei Witten. Industriell wurde der Bergbau erst ab Anfang des 19. Jahrhunderts betrieben.

Innerhalb weniger Jahrzehnte entstanden über 220 Zechen, im Jahre 1850 waren es bereits fast 300. In Kokereien wurde aus der Kohle Koks erzeugt, der in den Hochöfen der angesiedelten Eisen- und Stahlhütten zur Roheisen- und Stahlerzeugung benötigt wurde. Noch bevor die Kohlevorkommen entlang der Ruhr erschöpft waren, entstanden weiter nördlich neue Zechen. Der Ruhrbergbau wanderte, den Flözen in die Tiefe folgend, von Süden nach Norden, von der Ruhr an die Emscher und schließlich zur Lippe. Laut Roland Günter existierten in den rund 200 Jahren des Bergbaus insgesamt etwa 3.200 Zechen im Ruhrrevier. Die Erschließung des Ruhrgebiets als Lieferanten für Kohle und Stahl förderte wiederum die Gründung vieler Eisenbahngesellschaften. (Siehe hierzu: Liste der Eisenbahnen in Nordrhein-Westfalen bis 1930)

Die wirtschaftliche Expansion machte die Anwerbung neuer Arbeitskräfte erforderlich. Die Bevölkerungszahlen stiegen explosionsartig. Ursache hierfür waren die Zuwanderung aus anderen Teilen Deutschlands, aber auch eine überdurchschnittlich hohe Geburtenrate. Betrug sie im deutschen Kaiserreich fünf Kinder je Frau, so wurden im Ruhrgebiet fast sechs Kinder je Frau geboren. Hatte Bochum im Jahre 1800 noch 2.200 Einwohner, so wuchs die Zahl bis zur Jahrhundertwende auf 65.000 und im Jahre 1905 auf 117.000. Auch vormalige Dörfer entlang der Emscher entwickelten sich zu Großstädten. Facharbeiter der Bergwerke fanden ihre Bleibe vielfach in neu errichteten Arbeitersiedlungen, sogenannten Zechenkolonien. In den folgenden Jahrzehnten wuchs der "Ruhrkohlenbezirk" zum größten industriellen Ballungszentrum Europas an. Seit Beginn der Kohlekrise im Jahre 1957 und insbesondere mit Einsetzen der Stahlkrise seit 1973 und der nachfolgenden Wirtschaftskrise befindet sich das Ruhrgebiet in einer anhaltenden Phase des Strukturwandels, die von wirtschaftlichen Anpassungsschwierigkeiten gekennzeichnet ist.

Die geläufigsten Bezeichnungen der Region sind "Ruhrgebiet" oder "Revier". In der gesamtdeutschen Umgangssprache sind auch die Begriffe "Kohlenpott", "Ruhrpott" oder "Pott" weit verbreitet.

Lange Zeit wurden verschiedene Namen für die Region benutzt: Ausdrücke wie "Rheinisch-Westfälischer Industriebezirk", "Rheinisch-Westfälisches Industriegebiet", "Niederrheinisch-Westfälisches Industriegebiet" oder "Ruhrrevier" schlossen jedoch oft auch Gebiete ein, die nicht zum späteren Ruhrgebiet zählen, wie etwa industriell geprägte Gebiete im Bergischen Land oder um Düsseldorf. In den Postleitkarten des Deutschen Reichs wurde unter der Bezeichnung "Rheinisch-Westfälisches Industriegebiet" praktisch das gesamte heutige Landesgebiet Nordrhein-Westfalens erfasst. Demgegenüber wurde unter "Ruhrgebiet" zunächst nur der engere Einzugsbereich des Flusses Ruhr verstanden. In diesem Sinne finden diese Bezeichnungen heute kaum noch Verwendung.

Die heute gängige Bezeichnung "Ruhrgebiet" wurde im Laufe der 1920er Jahre geprägt und bürgerte sich erst um 1930 als fester Name für die Industrieregion ein. Ihrer geografischen Lage entsprechend müsste die Kernregion eher „Emschergebiet“ heißen, da der Lauf der Ruhr bereits den Südrand des Ruhrgebietes markiert, während die Emscher mitten hindurch fließt. Allerdings nahm der für die industrielle Entwicklung der Region seit den 1830er Jahren prägende Steinkohleabbau historisch tatsächlich im Ruhrtal zwischen Essen und Mülheim seinen Ausgang und wanderte von dort aus nach Norden zu den tiefer gelegenen Lagerstätten.

Neuerdings wird aus Marketinggründen die Bezeichnung "Metropole Ruhr" verwendet. Zusammen mit der Rheinschiene bildet das Ruhrgebiet die Region "Rhein-Ruhr" oder den "Rhein-Ruhr-Raum".

Eine allgemein anerkannte Eigenbezeichnung der im Ruhrgebiet lebenden Menschen existiert nicht. Die meisten Einwohner betrachten sich in erster Linie als Bewohner ihrer jeweiligen Heimatstädte, würden sich selbst also als Dortmunder, Essener usw. bezeichnen. Gelegentlich findet man die Bezeichnung „Ruhri“, wenn zum Ausdruck gebracht werden soll, dass das Ruhrgebiet insgesamt als Heimatregion gemeint ist. Die Verwendung dieser Bezeichnung durch Außenstehende kann aber wegen ihres manchmal als despektierlich empfundenen Charakters zu Irritationen führen. Nach der Wahl Essens zur Europäischen Kulturhauptstadt für das Jahr 2010 (RUHR.2010) wurde Ende 2008 unter dem Titel „Ruhri.2010“ eine Imagekampagne gestartet, die den Begriff als Bezeichnung für Ruhrgebietsbewohner bekannter machen sollte. Der Westdeutsche Rundfunk benutzte den Ausdruck „Ruhri der Woche“ im Vorfeld des Kulturhauptstadtjahres regelmäßig in seinem Regionalprogramm.

Die vorherrschende Wahrnehmung des Ruhrgebietes als eine industriell geprägte Einheit führte dazu, die Sprache der dort lebenden Menschen als einheitliches Ruhrdeutsch zu bezeichnen. Die Varietät der im Ruhrgebiet gesprochenen Dialekte ist jedoch Hochdeutsch mit niederdeutschen Substraten. Die oft behaupteten Einflüsse durch polnische Einwanderer um das Jahr 1900 sind nur vereinzelt im Wortschatz zu erkennen und auch nur sehr gering. In den Wortschatz eingegangen sind nur die beiden polnischen Worte "Mottek" und "Matka". Aber auch diese Begriffe sind kaum noch Teil des aktiven Wortschatzes der ortsansässigen Bevölkerung.

Historisch gehörte die Region an Rhein, Ruhr, Emscher und Lippe zum niederländischen und niedersächsischen Sprachgebiet. Speziell konnten Niederrheinisch oder Westfälisch unterschieden werden. Doch ist die Zahl der Sprecher des Plattdeutschen inzwischen verschwindend gering. Die Pflege dieser historischen Sprachen ist zumeist bei speziellen Gruppen in Heimatvereinen zu finden. Auch Kurse an Volkshochschulen vermitteln vereinzelt noch den aktiven Gebrauch alter Dialekte. So wird in Mülheim beispielsweise seit 1984 "Wir lernen Mölmsch Platt" angeboten.

Das Ruhrgebiet wird in erster Linie von den Städten und Kreisen des Ruhrgebiets selbst verwaltet, die in einem Zweckverband zusammengeschlossen sind. Der Regionalverband Ruhr (RVR) hat seinen Sitz in Essen. Beim Verband liegt insbesondere die Regionalplanung, die für die Flächennutzungspläne der Kommunen ausschlaggebend ist. Sie umfasst unter anderem die Darstellung von Bereichen für künftige Wohnbauflächen, von Flächen für die Ansiedlung neuer Gewerbebetriebe und die Planung von Folgenutzungen ehemaliger Bergbaustandorte in der Region.

Zum Verband gehören die kreisfreien Städte Bochum, Bottrop, Dortmund, Duisburg, Essen, Gelsenkirchen, Hagen, Hamm, Herne, Mülheim an der Ruhr und Oberhausen sowie der Ennepe-Ruhr-Kreis und die Kreise Recklinghausen, Unna und Wesel.

Mit an der Verwaltung beteiligt sind die Regierungsbezirke Arnsberg, Düsseldorf und Münster. Das westliche Ruhrgebiet mit den Städten Essen, Duisburg, Oberhausen, Mülheim an der Ruhr und dem Kreis Wesel gehört zum Regierungsbezirk Düsseldorf. Die Städte Dortmund, Bochum, Herne, Hamm, Hagen, der Kreis Unna und der Ennepe-Ruhr-Kreis sind Teile des Regierungsbezirks Arnsberg. Der Emscher-Lippe-Raum mit dem Kreis Recklinghausen und den Städten Gelsenkirchen und Bottrop werden von Münster verwaltet.

Zudem gehören die Städte und Kreise des Reviers dem jeweiligen Landschaftsverband Rheinland oder dem Landschaftsverband Westfalen-Lippe an.

Insgesamt ist bei der Verwaltung des Ruhrgebiets besonders auffällig, dass die meisten Verwaltungsstrukturen sich im Wesentlichen auf die historisch-politische Gliederung der preußischen Provinzen Rheinprovinz und Westfalen beziehen, sodass von einer einheitlichen Verwaltung des Ruhrgebiets zurzeit noch nicht gesprochen werden kann.

Das Ruhrgebiet ist ein Teil der Metropolregion Rhein-Ruhr und gehört mit seinen etwas mehr als fünf Millionen Einwohnern neben der Île-de-France (Großraum Paris), Moskau, Greater London, der Randstad in den Niederlanden und Istanbul zu den größten Ballungsgebieten Europas. Die gesamte Metropolregion hat rund 10 Millionen Einwohner und wurde bereits 1995 von der Ministerkonferenz für Raumordnung, die in Deutschland über so genannte "Europäische Metropolregionen" entscheidet, geschaffen. Damit ist das Ruhrgebiet auch Teil des von der Europäischen Kommission im Jahr 1999 aufgestellten Europäischen Raumentwicklungskonzeptes (EUREK).

Mit dem Strukturwandel verlor die Montanindustrie im Ruhrgebiet an Bedeutung, allerdings haben auch heute noch Montanunternehmen wie die RAG Aktiengesellschaft, Degussa oder ThyssenKrupp ihren Sitz und größte Produktionsstandorte im Ruhrgebiet. Der Anteil der Beschäftigten im primären und sekundären Sektor lag 2008 noch bei 28 %.

Nach einer Erhebung der Tageszeitung Die Welt haben von den 500 größten Unternehmen der Bundesrepublik 37 ihren Sitz im Ruhrgebiet, wovon 16 dem Industrie- und 21 dem Handels- und Dienstleistungsbereich zugeordnet werden können. So ist der Dienstleistungssektor unter anderem mit den Konzernzentralen von Energie- und Wasserversorgern wie der RWE und E.ON Ruhrgas und Handelskonzernen wie der Aldi-Gruppe, Douglas Holding, Arcandor oder Tengelmann vertreten. Außerdem gibt es in den häufig als Fußgängerzonen ausgewiesenen Innenstädten und den Einkaufszentren Ruhr-Park Bochum, Uni-Center, RheinRuhrZentrum und CentrO zahllose Einzelhändler. Die Kombination von Innenstadt und Einkaufszentrum wagt die Stadt Essen mit dem Einkaufszentrum Limbecker Platz (Einkaufszentrum) in der westlichen Innenstadt. Auch zahlreiche Unternehmen der Logistikbranche haben ihren Sitz oder Standorte wegen der guten infrastrukturellen Anbindung im Ruhrgebiet.

Das Ruhrgebiet und insbesondere Dortmund war für seine Brauereien bekannt. Mittlerweile sind viele Brauereien geschlossen, wenn auch die bekannten Markennamen weitergeführt werden. Hingegen weist das Ruhrgebiet zahlreiche kleinere Privatbrauereien in den Städten auf, so zum Beispiel die Brauerei Fiege in Bochum oder die Brauerei Stauder in Essen.

Alle großen regionalen Tageszeitungen der Region gehören zur Funke Mediengruppe oder zu den Ruhr Nachrichten (RN). Nach dem Ende der "Taz Ruhr" im Jahr 2005 ist die "Bild" die einzige überregionale Tageszeitung mit einer Ruhrgebietsausgabe. Zudem gibt es im Ruhrgebiet eine Reihe von Stadt- und Szenemagazinen. Das heute als Prinz bundesweit erscheinende Stadtmagazin hatte seinen Ursprung 1978 in Herne unter dem Namen "Guckloch". Neben dem "Prinz", der noch immer mit einer Regionalredaktion in Duisburg in der Region vertreten ist, erscheinen die Gratistitel Coolibri, "Heinz", "Smag" und "trailer". Mit dem Wirtschaftsmagazin Ruhr gibt es auch eine Zeitschrift mit diesem Thema für das Ruhrgebiet. Mit der Wissenschaft im Revier beschäftigt sich zudem das Magazin "Transfer".

Der Westdeutsche Rundfunk (WDR) unterhält Studios in Essen, Dortmund und Duisburg. In Essen werden die Regionalprogramme für das mittlere Ruhrgebiet produziert und ausgestrahlt. In Dortmund produziert der WDR die Sendung "Planet Wissen" sowie das Regionalprogramm für das östliche Ruhrgebiet. Neben verschiedenen Beiträgen für andere WDR-Programme wird von hier auch das komplette Tagesprogramm von WDR 4 gesendet. Das Regionalprogramm für den Niederrhein bzw. für das westliche Ruhrgebiet um Duisburg und den Kreis Wesel entsteht in Duisburg. Dort ist auch der türkische Sender Kanal Avrupa beheimatet. Studio 47 mit Sitz in Duisburg ist der erste private lokale Fernsehsender in Nordrhein-Westfalen. Des Weiteren unterhält der Fernsehsender Sat.1 ein Studio in Dortmund. Dort wird die Sendung "17:30" produziert. Das Adolf-Grimme-Institut mit Sitz in Marl vergibt jährlich die renommierte Fernsehauszeichnung Grimme-Preis.

Das gesamte Ruhrgebiet ist im Gegensatz zu den anderen großen Ballungsräumen Deutschlands traditionell kein exponierter Medienstandort. Allmählich etabliert sich aber auch hier eine respektable Agenturlandschaft. Mittlerweile gibt es im Ruhrgebiet sechs Werbeagenturen mit einem jährlichen Umsatz von mehr als 10 Millionen Euro. Zurzeit (Stand 2012) sind die drei größten Werbeagenturen im Ruhrgebiet die Westpress in Hamm mit einem Umsatz von 24,7 Millionen Euro, B&W Media-Service in Essen (20 Millionen Euro) und Move Elevator in Oberhausen (15 Millionen Euro).

Die Gesamtarbeitslosenquote des Ruhrgebiets liegt bei etwa 10,5 % und ist damit unter den regionalen Großräumen die höchste der westdeutschen Bundesländer. Auch die Arbeitslosenquoten einzelner Städte in der Kernzone des Ruhrgebiets gehören zu den höchsten der alten Bundesländer: In Gelsenkirchen beträgt die Arbeitslosenquote 14,2 %, Duisburg 13,3 %, Herne 12,8 %, Essen 12,1 % und Dortmund 11,6 % (alle Arbeitslosenquoten Stand Februar 2017).

Ein prägendes Strukturmerkmal der ehemaligen montanindustriellen Kernzonen des Ruhrgebiets ist die immer noch weit unter dem Bundesdurchschnitt liegende Quote der Frauenerwerbstätigkeit. In Nordrhein-Westfalen (und im Saarland) arbeiten so wenige Frauen in Vollzeittätigkeiten wie in keinem anderen Bundesland. 2013 waren hier nur 28 Prozent der Frauen im Alter von 15 bis 64 Jahren in Vollzeit berufstätig. Insgesamt waren 2014 nur 47,5 Prozent der Frauen in NRW sozialversicherungspflichtig beschäftigt (im Vergleich: in Sachsen 58,5 Prozent). Das geht vor allem auf die niedrige Quote in den Ruhrgebietsstädte wie Gelsenkirchen (39,7 Prozent) und Herne (40,7 Prozent) zurück. Das hängt mit den Schichtarbeitssystemen in der Schwerindustrie, aber auch mit den früher vergleichsweise hohen Löhnen der Männer zusammen, die eine „Rundumversorgung“ der arbeitenden Männer (Wäschewechsel usw.) notwendig machten und es nicht erforderlich erschienen ließen, dass die Frauen „dazu verdienen“ mussten. Aufgrund des unterdurchschnittlichen Dienstleistungsbesatzes der Industrieregionen lebten viele Familien beinahe als Selbstversorger in Siedlungen weitab vom Stadtkern mit Garten, Kleinvieh usw. Umgekehrt ist die niedrige Frauenerwerbsquote im Ruhrgebiet bis heute eine Ursache dafür, dass Dienstleistungsunternehmen hier nur schwer hochqualifizierte weibliche Vollzeitarbeitskräfte finden. Industrien mit einem hohen Anteil an gering qualifizierten weiblichen Beschäftigten mussten sich in der Nähe der Hauptbahnhöfe niederlassen, um wegen der Defizite des Nahverkehrs überhaupt Arbeitskräfte rekrutieren zu können. Das galt vor allem für die Bekleidungsindustrie und für Callcenter.

Trotz einiger Erfolge des Strukturwandels der letzten Jahrzehnte leidet das Ruhrgebiet immer noch unter erheblichen Strukturschwächen. Problematisch sind insbesondere das Kirchturmdenken, die eher kleinräumigen Aktionsradien der Menschen und Unternehmen, ferner die durch den demographischen Wandel schrumpfende Bevölkerung mit einem wachsenden Anteil sozial schwacher Bevölkerungsgruppen und die sich verstärkende Ungleichheit der Lebenschancen in den Städten. 

Die Bundesautobahn 40 markiert in vielen Teilen des Ruhrgebiets einen „Sozialäquator“, eine Grenze zwischen dem ärmeren Norden und dem wohlhabenderen Süden. Diese Zweiteilung zeigt sich insbesondere innerhalb der zentralen Großstädte Duisburg, Essen, Bochum und Dortmund, in welchen die südlichen Stadtteile oftmals deutlich gehobenere Einkommensstrukturen aufweisen, als die zumeist ärmeren nördlichen Stadtteile. Jedoch zeigen sich auch deutliche Unterschiede zwischen den nördlichen und den südlichen Randgemeinden des Ruhrgebiets. Während die durchschnittlichen Einkommen in kleineren bis mittleren nördlichen Städten wie etwa Gladbeck, Herten, Marl, Lünen, Bergkamen und Bönen deutlich unter dem landesweiten Durchschnitt liegen, liegen sie in kleineren südlichen und südöstlichen Städten wie Sprockhövel, Ennepetal, Herdecke, Schwerte und Holzwickede mitunter deutlich über dem Landesdurchschnitt. 

Die in Teilen des Ruhrgebiets stattfindende Abwanderung der leistungsfähigeren, gebildeteren Menschen hat ein schwindendes Humanvermögen und das Anwachsen eines Prekariats, Menschen in unsicheren wirtschaftlichen Verhältnissen, zur Folge. Hinzu kommen kommunale Finanznöte sowie Mängel der bisherigen Strukturpolitik. Infolge fehlerhafter Problemanalysen sowie fehlender Schwerpunktbildung blieben die Maßnahmen weitgehend wirkungslos und eine Verbesserung der Strukturen konnte nicht erzielt werden. Der Armutsbericht der Sozialverbände 2016 zeigt, dass die Armutsquote mit 20 Prozent und die Kinderarmutsquote im Ruhrgebiet mit 19 Prozent deutlich über dem Bundesdurchschnitt liegt. Die Hälfte dieser Kinder lebt im Haushalt eines alleinerziehenden Elternteils. Erstmals lag 2016 auch die Armutsrisikoquote von Rentnern mit 15,6 Prozent über dem Durchschnitt. Schließlich führen Arbeitslosigkeit, Armut, prekäre Lebensverhältnisse, schlechte Wohnquartiere und höhere Immissionsbelastungen zu einer signifikant geringeren Lebenserwartung.

In einem regionalwirtschaftlichen Vergleich deutscher Agglomerationen aus dem Jahr 2008 wurde festgestellt, dass das Ruhrgebiet hinsichtlich der wirtschaftlichen Dynamik und der Beschäftigungsentwicklung gegenüber anderen Agglomerationsräumen deutlich zurückfällt und eine Trendwende nicht in Sicht ist, was zur Folge hat, dass das Image der nordrhein-westfälischen Wirtschaft insgesamt negativ geprägt wird. Obwohl Teile des Ruhrgebiets (vor allem Dortmund und Essen) einen sukzessiven Turnaround erleben und Investitionen und Dienstleistungsbesatz steigen, gehen in anderen Regionen Investitionen, Beschäftigung und sogar der Anteil qualifizierter Arbeitskräfte zurück. So ist zwischen 2008 und 2014 der Anteil der Gelsenkirchener Bevölkerung mit einem hohen Bildungsgrad (Meister-, Techniker-, Hochschulabschluss) von 24.000 auf 18.000 stark gesunken, zugleich ist aber der Anteil der Personen ohne jeden Ausbildungsabschluss von 83.000 auf 92.000 gestiegen.

Negativ für die Attraktivität des Ruhrgebietes für Unternehmen ist die deutlich über dem Bundesdurchschnitt liegende Höhe der kommunalen Steuern im Ruhrgebiet infolge der sehr schlechten Finanzlage fast aller Ruhrgebietsstädte.

Seit Beginn der Kohlekrise im Jahr 1957 befindet sich das Ruhrgebiet in einer anhaltenden Phase des Strukturwandels, die von wirtschaftlichen Anpassungsschwierigkeiten gekennzeichnet ist. Mittels staatlicher Subventionen versuchte man die negativen Folgen zu begrenzen. Steinkohleförderung und Stahlindustrie waren stark rückläufig. Das Bergwerk Prosper-Haniel in Bottrop ist seit der Schließung der Zeche Auguste Victoria am 18. Dezember 2015 das letzte aktive Steinkohlen-Bergwerk im Ruhrgebiet.

Der Steinkohleabbau hatte bereits zu Beginn des 20. Jahrhunderts mit der Nordwanderung die Lippe erreicht und zum Teil bereits überschritten, noch in den 1980er Jahren wurden Pläne betrieben von der Zeche Radbod in das südliche Münsterland nördlich von Hamm vorzustoßen. Zwischen 1980 und 2002 ging etwa die Hälfte der eine Million Arbeitsplätze im produzierenden Gewerbe verloren, während etwa 300.000 Arbeitsplätze im Dienstleistungssektor geschaffen wurden.

In der Ruhrzone ist der Strukturwandel schon vollzogen. Die meisten Zechen einschließlich der Kleinzechen an der Ruhr wurden bis 1930 stillgelegt. Heute ist das Ruhrtal ein Naherholungsgebiet.

Im Rahmen der Energiewende und des damit verbundenen Kohleausstiegs zeichnet sich bei der Energieerzeugung ein weiterer tiefgreifender Strukturwandel im Ruhrgebiet ab.

Als Beispiel des Strukturwandels kann man den Bau der drei Automobilwerke des Autoherstellers Opel 1962 in Bochum bezeichnen. Die Werke boten den "unter Tage" ausgebildeten Schlossern, Elektrikern usw. einen Arbeitsplatz in einer anderen Branche. Allerdings hat mittlerweile auch Opel mit Strukturproblemen zu kämpfen und so wurde die Automobilproduktion in Bochum Ende 2014 eingestellt.

Erfolgreicher arbeiten die Technologieparks, in denen kleine und mittlere Unternehmen Hochtechnologie produzieren. Ein Beispiel dafür ist der Technologiepark Dortmund.

Industrien wie Fahrzeug- und Maschinenbau, Elektrotechnik, Feinmechanik sowie auch Nahrungs- und Genussmittelindustrie und nichtindustrielle Branchen wie der Dienstleistungssektor sind noch nicht ausreichend nachgewachsen. Insgesamt verzeichnete das Dienstleistungsgewerbe den größten Aufschwung. Seit Beginn der neunziger Jahre sind bereits über 50 Prozent der Beschäftigten in der Dienstleistung tätig. Aufgrund der verkehrsgünstigen Lage in der EU und des günstigen Grundstücksangebots ließen sich viele Logistikunternehmen sowie große Handelsketten in der Region nieder.

Ein Großprojekt, das oft als Zeichen des Strukturwandels angesehen wird, ist die Neue Mitte Oberhausen mitsamt dem Einkaufszentrum CentrO, die auf dem Gelände der stillgelegten Gutehoffnungshütte Mitte der 1990er Jahre erbaut wurde.

Einige Großkonzerne setzten neue Schwerpunkte, vor allem im Bereich der Informations- und Kommunikationstechnik sowie der Umweltsicherung. Einige Unternehmen bauten ihre Aktivitäten im Ruhrgebiet ab, so der einstige Stahlerzeuger und -verarbeiter Mannesmann, und konzentrierten sich auf neue Geschäftsfelder. Der Konzern baute Anfang der 1990er Jahre mit Mannesmann Mobilfunk ein Mobilfunknetz (D2). Um an die deutsche Mobilfunksparte zu gelangen, kaufte die englische Vodafone-Gruppe den Mannesmann Konzern auf und verkaufte einzelne Bereiche des Stahlgeschäfts im Ruhrgebiet und in Düsseldorf.

Ein wichtiger Schritt vom Produktions- zum Forschungsstandort war die Gründung mehrerer Universitäten. Als erste Universität im Ruhrgebiet wurde 1962 die Universität Bochum gegründet, es war auch die erste Gründung in der Bundesrepublik Deutschland. Es folgten die Technische Universität Dortmund und die Gesamthochschulen Essen und Duisburg, die zur Universität Duisburg-Essen fusionierten, sowie die Fernuniversität in Hagen. Hilfreich für den Zuwachs im tertiären Sektor waren auch die Gründungen von Gesamthochschulen, Technologiezentren und Beratungseinrichtungen. In den vergangenen Jahren hat sich die Forschungslandschaft im Ruhrgebiet weiter ausdifferenziert. So kamen 2009 auf Initiative der Landesregierung mit der Hochschule Ruhr West mit Standorten in Mülheim an der Ruhr und Bottrop sowie der Hochschule Hamm-Lippstadt zwei weitere staatliche Fachhochschulen hinzu.

Die Internationale Bauausstellung Emscher Park (IBA) war von 1989 bis 1999 im Ruhrgebiet tätig und versuchte den Strukturwandel zu begleiten. Dabei wurden etwa zweieinhalb Milliarden Euro in die Region investiert und Industriebrachen von stillgelegten Bergwerken, Kokereien und Stahlwerken als Industriedenkmäler erhalten und neue Nutzungsmöglichkeiten entwickelt, wie der Emscher Landschaftspark. Ähnlich ist die Hütte Duisburg-Meiderich als Landschaftspark Duisburg-Nord umgenutzt worden, der stillgelegte Gasometer Oberhausen wurde zur Ausstellungshalle umfunktioniert. Weitere Beispiele für neue Nutzungen sind der Nordsternpark in Gelsenkirchen, der Bottroper Tetraeder, die Essener Schurenbachhalde, der Duisburger Innenhafen, die Jahrhunderthalle in Bochum und der Phoenix-See in Dortmund. Seit Mitte der 1990er Jahre wird die Emscher, lange der kanalisierte Abwasserkanal des Ruhrgebiets, renaturiert.

Die Route der Industriekultur steuert als touristische Themenstraße die wichtigsten industriegeschichtlichen Stätten des Ruhrgebiets an und dient als Ausgangsbasis für die Vermarktung des Ruhrgebiets als Tourismusregion.

Im Ruhrgebiet befinden sich zahlreiche Technik- und Industriemuseen wie das Deutsche Bergbau-Museum in Bochum, das Museum der Deutschen Binnenschifffahrt in Duisburg, das Umspannwerk Recklinghausen, die DASA – Arbeitswelt Ausstellung und das Hoesch-Museum in Dortmund, das Eisenbahnmuseum Bochum-Dahlhausen in Bochum und die dezentralen Museen Westfälisches Industriemuseum und Rheinisches Industriemuseum. Außerdem gibt es auch im Ruhrgebiet mehrere Kunstmuseen wie das Museum Folkwang in Essen, das Lehmbruck-Museum und Museum Küppersmühle in Duisburg, die Ludwig-Galerie im Schloss Oberhausen, das Karl-Ernst-Osthaus-Museum Hagen oder das Museum Ostwall in Dortmund. Mit der Eröffnung der Kulturhauptstadt 2010 wurde das Ruhrlandmuseum als Ruhr Museum in der ehemaligen Kohlenwäsche der Zeche Zollverein neu eröffnet. Die Zeche und Kokerei Zollverein in Essen wurde 2001 von der UNESCO zum Welterbe erklärt. Essen war 2010 stellvertretend für die Region europäische Kulturhauptstadt.

Ähnlich vielfältig ist die Theaterlandschaft im Ruhrgebiet. Zu den bekanntesten Schauspielbühnen gehören das Schauspielhaus Bochum, das Grillo-Theater in Essen sowie das Theater Oberhausen. Auch das Musiktheater ist im Ruhrgebiet vertreten, so das Musiktheater im Revier in Gelsenkirchen, die Deutsche Oper am Rhein in Duisburg, das Aalto-Theater in Essen, das Theater Hagen und das Dortmunder Opernhaus mit der angeschlossenen Kinderoper. Daneben gibt es Konzerthäuser in Bochum, Dortmund und Essen und Amateurbühnen wie die Waldbühne Heessen in Hamm.

In Bochum wird seit 1988 das erfolgreichste Musical der Welt Starlight Express im eigens dafür gebauten Starlight Express Theater gespielt. Darüber hinaus haben sich zwei Musicalspielstätten der Stage Entertainment in Essen und Oberhausen etabliert.

Die bekanntesten regionalen Volkstheater sind der Mondpalast in Herne und Stratmanns Theater Europahaus in Essen.

Auch im Ruhrgebiet wird Karneval gefeiert. Umzüge finden in zahlreichen Städten statt, Weiberfastnacht ist für viele der wesentliche „Feiertag“. Im Archiv der Stadt Duisburg befindet sich die erste überhaupt in deutsch geschriebene Stadtrechnung aus dem Jahre 1377, aus der hervorgeht, dass die Ratsherren und die Bürgerschaft ausgiebig Fastabend ("Vastavent") feierten. In der zweiten Hälfte des 19. Jahrhunderts werden in Duisburg die ersten Karnevalsgesellschaften gegründet. Den ersten Anlauf zur Etablierung eines Rosenmontagszuges in Duisburg geht auf das Jahr 1928 zurück. Duisburg ist Sitz des Landesverbands Rechter Niederrhein im Bund Deutscher Karneval e. V.

Von 2006 bis 2010 fand die Loveparade im Ruhrgebiet statt. Die 2010 im Rahmen der Veranstaltungen zur Kulturhauptstadt Europas organisierte Loveparade auf dem Gelände des ehemaligen Duisburger Güterbahnhofs endete in einem Unglück. Bei einem Gedränge tausender Besucher in einer Unterführung verloren 21 Menschen ihr Leben, 511 wurden zum Teil schwer verletzt.

Die "Cranger Kirmes", ein jährlich wiederkehrendes Volksfest in Crange, einem Ortsteil des Herner Stadtbezirkes Wanne, welches seit 580 Jahren stattfindet und jährlich ca. 4.000.000 Besucher anlockt, zählt zu den größten Festen dieser Art in Deutschland. Zu den im Ruhrgebiet stattfindenden Festivals zählen das Juicy Beats in Dortmund, das Ruhr Reggae Summer in Dortmund und Mülheim, das Bochum Total in Bochum, das UZ-Pressefest in Dortmund, das Essen Original in Essen, Olgas Rock in Oberhausen, das Traumzeit-Festival in Duisburg sowie die Mayday in Dortmund.

Die Ruhrtriennale, die Ruhrfestspiele, die ExtraSchicht und ähnliche Großveranstaltungen zeugen von einer lebendigen Kulturszene im Ruhrgebiet. Aufgrund der hohen Dichte kultureller Einrichtungen bewarb sich das Ruhrgebiet unter Führung der Stadt Essen erfolgreich als Kulturhauptstadt Europas 2010:
Die Kraft von RUHR.2010 ist die Fähigkeit zum Wandel durch Kultur. Die Kulturhauptstadt Europas präsentiert das Ergebnis eines mehrjährigen und tief greifenden Wandlungsprozesses des Ruhrgebiets. Hunderte Kulturinstitutionen, Künstler und Kulturschaffende in der Metropole Ruhr sind seit Jahren die Basis dieses Wandels und bilden eine der reichsten Kulturlandschaften Europas.
RUHR.2010 zeigt anhand ausgewählter Projekte den erreichten Stand und ist ein vorläufiger Höhepunkt der stetigen Entwicklung. Das Ziel ist, durch gezielte Auswahl von Projekten das dauerhafte Kulturangebot weit über 2010 hinaus in Europa zu etablieren.

Fünf Universitäten, eine Kunsthochschule und fünfzehn weitere Hochschulen mit etwa 256.000 eingeschriebenen Studenten (WS 2013/14) in 600 Studiengängen machen das Ruhrgebiet zu Europas dichtester Bildungs- und Forschungslandschaft. Hinzu kommen zahlreiche Forschungsinstitute und Technologiezentren. Die erste Universität des Ruhrgebiets bestand bereits von 1655 bis 1818 in Duisburg. Die meisten Hochschulen sind jedoch in den 1960er und 1970er Jahren gegründet worden: 1962 wurde die Ruhr-Universität Bochum gegründet, 1968 die Universität Dortmund. Zu den bekanntesten Hochschulen zählen weiter die fusionierte Universität Duisburg-Essen, die private Universität Witten/Herdecke, die Fernuniversität in Hagen und die Folkwang Hochschule im Ruhrgebiet mit den Schwerpunkten Musik, Darstellende Künste und Gestaltung.

Eng verbunden mit den Hochschulen sind die Forschungsinstitute. Drei Max-Planck-Institute haben ihren Sitz im Ruhrgebiet: das Max-Planck-Institut für molekulare Physiologie in Dortmund, das Max-Planck-Institut für Kohlenforschung in Mülheim an der Ruhr und das Max-Planck-Institut für Chemische Energiekonversion ebenfalls in Mülheim. Vier Fraunhofer-Institute befinden sich im Ruhrgebiet: das UMSICHT genannte Oberhausener Fraunhofer-Institut für Umwelt-, Sicherheits- und Energietechnik, das Fraunhofer-Institut für Materialfluss und Logistik und das Fraunhofer-Institut für Software- und Systemtechnik in Dortmund sowie das Fraunhofer-Institut für Mikroelektronische Schaltungen und Systeme, Duisburg. Zu den bekannten Forschungsinstituten gehören auch Einrichtungen der Sozial- und Geisteswissenschaften wie das Rheinisch-Westfälische Institut für Wirtschaftsforschung, das Zentrum für Türkeistudien und das Kulturwissenschaftliche Institut, die alle ihren Sitz in Essen haben; des Weiteren das Landesinstitut Sozialforschungsstelle Dortmund sowie das Institut Arbeit und Technik in Gelsenkirchen, das Landesspracheninstitut NRW in Bochum und das DMT-Forschungsinstitut für Montangeschichte in Bochum.

Technologieparks und Gründerzentren bilden das Bindeglied zwischen den Hochschulen und der Wirtschaft. Im TechnologieZentrum Dortmund siedelten sich beispielsweise seit 1988 mehr als 225 Firmen mit über 8.500 Mitarbeitern an. Dabei haben Unternehmen der Mikrotechnikbranche einen besonders hohen Anteil. Mit dem Wissenschaftspark entstand in Gelsenkirchen ein auf erneuerbare Energien spezialisiertes Gründerzentrum. Wissenstransfer zwischen mittelständischen Unternehmen die keine eigene Forschung betreiben und Hochschulen und Instituten bietet das Mülheimer Zentrum für Innovation und Technik an.
Der Fußballsport hat im Ruhrgebiet eine wichtige soziale und integrative Funktion. Die beiden größten Vereine sind der FC Schalke 04 und Borussia Dortmund. Das Aufeinandertreffen dieser beiden Vereine gilt als ein Höhepunkt der Saison und wird, wie alle Spiele zwischen Ruhrgebietsvereinen, als „Revierderby“ bezeichnet. Der FC Schalke 04 und der BVB sind zusammen mit dem MSV Duisburg Gründungsmitglieder der Fußball-Bundesliga. Der VfL Bochum ist einer der ältesten heutigen Bundesligavereine (Gründungsjahr 1848) im Ruhrgebiet. Neben diesen Vereinen existiert eine Vielzahl anderer erfolgreicher Klubs in allen Ligen; zudem besitzt das Revier unzählige Amateur- und Hobbyvereine. Viele dieser Vereine haben ihren Ursprung bei Werksmannschaften von Hütten und Zechen.

Einen einheitlichen Fußballverband Ruhrgebiet gibt es nicht. Die Vereine des Ruhrgebiets sind in den entsprechenden Verbänden Fußballverband Niederrhein mit Sitz in Duisburg oder Fußball- und Leichtathletik-Verband Westfalen in Kamen eingegliedert.

Der Ruhrmarathon führte von 2003 bis 2008 jährlich quer durch das mittlere und östliche Ruhrgebiet. Rund um den Baldeneysee in Essen führt seit 1963 der älteste Marathonlauf Deutschlands. Seit 1981 findet in Duisburg der Rhein-Ruhr-Marathon statt, der somit einer der ältesten deutschen Stadtmarathons ist. Das Weltranglisten-Punkte vergebende Radrennen Sparkassen Giro Bochum führt von der Bochumer Innenstadt nach Stiepel, das Sechstagerennen fand bis 2008 in der Westfalenhalle Dortmund statt.

Etwa 3,1 Millionen zugelassene Kraftfahrzeuge waren im Jahr 2002 im Ruhrgebiet gezählt. Diese können auf 4.700 km überörtlichen Straßen fahren. Weil sich jedoch Stadt-, Regional- und Fernverkehr insbesondere zu den Hauptzeiten des Berufsverkehrs überlagern, kommt es häufig zu Staus. Diese sollen in Zukunft durch fortschrittliche Verkehrsinformationssysteme wie "OLSIM", "Ruhrpilot" und dem RVR-Projekt "Informationssystem Verkehr Ruhrgebiet" vermieden werden.

Die Hauptachsen des Kraftfahrzeugverkehrs in Ost-West-Richtung bilden die drei Autobahnen A 2, A 42 und A 40. Letztere wird inklusive ihres weiteren Verlaufs in Dortmund über den Rheinlanddamm und den Westfalendamm (beides Teile der Bundesstraße B 1) aus historischen Gründen regional auch immer noch „Ruhrschnellweg“ nach einem zum Zeitpunkt der Eröffnung der ersten Autobahnen bereits fertiggestellten Straßenbauprojekt genannt. Gleichwohl ist er spöttisch auch für seine Beinamen „Ruhrschleichweg“ oder „der längste/größte Parkplatz des Ruhrgebiets“ bekannt, da er eine der Straßen mit dem bundesweit höchsten Verkehrsaufkommen ist und durch tägliche Verkehrsstaus geprägt ist.

Daneben verlaufen als Nebenachsen von Nord nach Süd die Autobahnen A 1, A 3, A 43, A 45, A 57 und A 59, die insbesondere für Pendler zur Landeshauptstadt Düsseldorf bedeutsame A 52, A 535 und die B 227.

Wichtigste Knotenbahnhöfe des Personenfernverkehrs sind die Hauptbahnhöfe in Duisburg, Essen, Dortmund, Hamm, Hagen, Oberhausen, Bochum und Wanne-Eickel.

Wesentlich zur infrastrukturellen Erschließung des Ruhrgebietes mit Anbindung des Rheinlands trägt die S-Bahn Rhein-Ruhr bei. Die Hauptlast der regionalen Verkehrsleistungen tragen allerdings die Regional-Express-Linien. Fast alle RE-Linien führen vom Rheinland quer durch das Ruhrgebiet von Duisburg über Essen, Bochum, Dortmund nach Hamm und teilweise weiter ins östliche Westfalen. Ab 2018 soll mit dem Rhein-Ruhr-Express ein neues System von schnellen Nahverkehrszügen im 15-Minuten-Takt verkehren.

Der Öffentliche Personennahverkehr wird weitestgehend vom Verkehrsverbund Rhein-Ruhr (VRR) organisiert. Der ÖPNV im Kreis Unna sowie im Bereich der Stadt Hamm wird über die Verkehrsgemeinschaft Ruhr-Lippe (VRL) angeboten.

In den ersten beiden Jahrzehnten des 20. Jahrhunderts entstand ein umfassendes Straßenbahnnetz, das mit Umsteigen eine Straßenbahnfahrt von Bonn nach Werne ermöglichte. Zwischen den 1950er und den 1970er Jahren wurden viele Straßenbahnlinien stillgelegt, dennoch ist es auch heute noch möglich, von Witten über Bochum, Gelsenkirchen, Essen, Mülheim an der Ruhr, Duisburg und Düsseldorf bis nach Krefeld mit der Straßenbahn bzw. Stadtbahn zu fahren.

In den 1960er Jahren entstand der Plan, die überwiegend meterspurigen Straßenbahnstrecken durch ein normalspuriges städteübergreifendes Stadtbahnnetz zu ersetzen. Dieses Vorhaben konnte bislang jedoch nur teilweise verwirklicht werden. Heute besteht das Netz der Stadtbahn Rhein-Ruhr im Ruhrgebiet aus vier nicht miteinander verbundenen Netzen der
Dabei kommt es unterhalb des Mülheimer Hauptbahnhofs zu dem Kuriosum, dass dort mit der Stadtbahn-Linie U 18 aus Essen und der Straßenbahnlinie 901 aus Duisburg zwei normalspurige Bahnen enden, eine Durchbindung trotzdem derzeit nicht möglich ist, da die Signalsysteme nicht kompatibel sind.

Neben Zügen, S-Bahnen, Straßen- und Stadtbahnen sind Omnibusse die wichtigsten Verkehrsmittel des öffentlichen Personennahverkehrs im Ruhrgebiet.

Im Güterverkehr ist das Ruhrgebiet als Ganzes auch bei insgesamt zurückgehender Bedeutung der Eisenbahn in Deutschland, nach der Bahnprivatisierung und der Verlagerung vieler Eisenbahntransporte auf den Straßenverkehr weiterhin der größte Eisenbahnkomplex Europas mit mehreren Rangierbahnhöfen ("Hagen-Vorhalle", "Hamm (Westf) Rbf", "Oberhausen-Osterfeld Süd", "Schwerte (Ruhr)" und "Wanne-Eickel Hbf") sowie mit zahlreichen Anschlussbahnen der Industrie.

Das bedeutendste Gewässer in verkehrstechnischer Hinsicht im Ruhrgebiet ist in der heutigen Zeit der Rhein. Bis zur Mitte des 19. Jahrhunderts war die Namensgeberin des Ruhrgebiets, die Ruhr, einer der wichtigsten Transportwege, siehe Hauptlemma: Ruhrschifffahrt.

In Datteln kreuzen sich vier Kanäle, Rhein-Herne-Kanal (RHK), Wesel-Datteln-Kanal (WDK), Datteln-Hamm-Kanal (DHK) und Dortmund-Ems-Kanal (DEK), die damit den größten europäischen Knotenpunkt für die Binnenschifffahrt bilden. Eine Sehenswürdigkeit ist das Schiffshebewerk Henrichenburg in Waltrop. Der Ruhrschifffahrtskanal verbindet außerdem den Rhein (Duisburger Hafen) mit dem Mülheimer Rhein-Ruhr-Hafen. Der Gesamtumschlag an den Kanälen des Ruhrgebiets beträgt etwa 25 Millionen Tonnen.

Sowohl der größte Binnenhafen als auch der größte Kanalhafen Europas befinden sich im Ruhrgebiet. Der Duisburger Hafen „duisport“, der vom Rhein, von der Ruhr und vom Rhein-Herne-Kanal zu erreichen ist, gilt als Verkehrsdrehscheibe der deutschen Binnenschifffahrt. Er hat einen jährlichen Gesamtumschlag von etwa 96 Millionen Tonnen. Im Gegensatz dazu hat der Dortmunder Kanalhafen trotz seiner Größe in den vergangenen Jahrzehnten mit dem Rückgang der Stahlerzeugung erheblich an Bedeutung verloren.

Der einzige bedeutende Verkehrsflughafen im Ruhrgebiet ist der Flughafen Dortmund, auf dem 2014 knapp zwei Millionen Passagiere abgefertigt wurden. Wichtiger für die Region sind die internationalen Flughäfen Düsseldorf und Köln/Bonn, die für Passagiere aus dem Ruhrgebiet gut erreichbar sind. Beide Flughäfen sind über das Schienennetz der Eisenbahn und die Autobahnen in kurzer Zeit aus dem Ruhrgebiet erreichbar. Eine wichtige Rolle spielt auch der im Jahre 2003 eröffnete Flughafen Weeze im nordwestlich des Ruhrgebiets gelegenen Kreis Kleve.

Privatflugverkehr findet außerdem auf dem Verkehrslandeplätzen Flughafen Essen/Mülheim und Marl-Loemühle statt. Darüber hinaus existieren im Ruhrgebiet und seiner Peripherie zahlreiche Flugplätze für Segel- und Motorflugbetrieb, unter anderem in Hamm und Kirchhellen/Schwarze Heide. Sie werden von Flugsportvereinen genutzt und teilweise auch betrieben.






</doc>
<doc id="10738" url="https://de.wikipedia.org/wiki?curid=10738" title="Wellenlänge">
Wellenlänge

Die Wellenlänge "formula_1" (griechisch: "Lambda") einer periodischen Welle ist der kleinste Abstand zweier Punkte gleicher Phase. Dabei haben zwei Punkte die gleiche Phase, wenn sie im zeitlichen Ablauf die gleiche Auslenkung (Elongation) und die gleiche Bewegungsrichtung haben. Die Wellenlänge ist das räumliche Analogon zur zeitlichen Periodendauer.

Allgemein gilt
wobei formula_3 die Phasengeschwindigkeit und formula_4 die Frequenz der Welle ist.

Jedoch hängen bei gegebener Frequenz Phasengeschwindigkeit und Wellenlänge vom Ausbreitungsmedium ab und von der Geometrie der Welle. Gegebenenfalls spricht man zur Unterscheidung von Vakuumwellenlänge oder von Freiraumwellenlänge, wenn man nicht die Welle im Medium bzw. nicht die Welle in einem Wellenleiter meint.

Das menschliche Ohr ist für Frequenzen von maximal etwa 16 Hertz bis 20.000 Hertz empfindlich (das entspricht einem Wellenlängenbereich von ca. 21 m bis 17 mm bei einer Schallausbreitungsgeschwindigkeit im Medium Luft von formula_3 = 343 m/s), wobei die Wahrnehmungsfähigkeit für höhere Frequenzen in der Regel mit zunehmendem Alter nachlässt. Da sich die Wellenlänge proportional zur Schallausbreitungsgeschwindigkeit im Ausbreitungsmedium verhält, hat ein Ton mit einer Frequenz von 16 Hertz im Wasser (formula_3 = 1484 m/s) eine Wellenlänge von etwa 90 m. Der Höreindruck, die Tonhöhe, ist durch die Frequenz gegeben, nicht durch die Wellenlänge in einem Medium außerhalb des Ohrs, da die Schallausbreitungsgeschwindigkeiten der Medien im Innenohr – und damit die dort auftretenden Wellenlängen eines bestimmten Tones – unabhängig davon sind, durch welche Medien der Ton das Trommelfell erreicht. Bestimmte Tierarten können auch Schallwellen mit niedrigeren oder höheren Frequenzen wahrnehmen, daher auch Schall anderer Wellenlängenbereiche.

Das menschliche Auge ist in einem Wellenlängenbereich von etwa 380 nm (Violett) bis 780 nm (Rot) empfindlich. Bienen sehen auch kurzwelligere Strahlung (Ultraviolett), können dafür aber kein rotes Licht wahrnehmen.

Für die Wellenlänge in einem Medium gilt:
Dabei ist formula_3 die Lichtgeschwindigkeit im Vakuum, formula_9 die magnetische Permeabilität und formula_10 die relative Permittivität des Mediums. Wenn elektromagnetische Wellen ein Medium durchqueren, dessen Brechungsindex formula_11 größer als formula_12 ist, so reduziert dies die Wellenlänge und die Ausbreitungsgeschwindigkeit. Die Frequenz der Welle bleibt gleich. Die Wellenlänge im Medium beträgt
wobei formula_14 die Wellenlänge der elektromagnetischen Welle im Vakuum ist.

Louis de Broglie entdeckte, dass alle Teilchen durch Materiewellen beschrieben werden können. Die Wellenlänge einer solchen Materiewelle wird De-Broglie-Wellenlänge genannt und hängt vom Impuls "p" des Teilchens ab. Für ein relativistisches Teilchen kann die Wellenlänge mit folgender Gleichung bestimmt werden:

Dabei ist "h" das Plancksche Wirkungsquantum, "c" die Lichtgeschwindigkeit, "m" die Masse und "v" die Geschwindigkeit des Teilchens.



</doc>
<doc id="10740" url="https://de.wikipedia.org/wiki?curid=10740" title="Harry Mulisch">
Harry Mulisch

Harry Kurt Victor Mulisch (* 29. Juli 1927 in Haarlem; † 30. Oktober 2010 in Amsterdam) war ein niederländischer Schriftsteller. Beachtung fand er vor allem durch seine Romane "Das Attentat" (1982) und "Die Entdeckung des Himmels" (1992).

Harry Mulisch war der Sohn von Karl Viktor Kurt Mulisch, einem ehemaligen österreichischen Offizier, und Alice Schwarz, einer Jüdin aus einer Frankfurter Bankiersfamilie. Sein Vater war während der Zeit der deutschen Besetzung der Niederlande (1940–45) Personaldirektor von Lippmann, Rosenthal & Co. Sarphatistraat, einer Bank, deren Aufgabe die Arisierung jüdischen Eigentums war. Für diese Tätigkeit musste der Vater nach dem Krieg drei Jahre in ein Internierungslager, er verstarb 1957 an den Folgen des Aufenthalts in diesem Internierungslager für Kollaborateure. Allerdings hatte der Vater durch seine leitende Position seine jüdische Ex-Gattin und den Sohn vor den Nationalsozialisten und der Deportation schützen können, während Mulischs Großmutter und Urgroßmutter mütterlicherseits im KZ Sobibor ermordet wurden. 1936 ließen sich seine Eltern scheiden; Harry Mulisch wohnte bei seiner Mutter und wurde großenteils durch die Hausangestellte Frieda Falk erzogen. Nach dem Umzug der Mutter nach Amsterdam lebte er bei seinem Vater in Haarlem. Mulisch wuchs zweisprachig (deutsch und niederländisch) auf. Die Mutter emigrierte 1951 in die USA.

Diese Bindung Mulischs zwischen Verfolgung wegen seiner jüdischen Herkunft einerseits (über die Mutter) und der Kollaboration mit den nationalsozialistischen deutschen Besatzern andererseits (über den Vater) prägte ganz erheblich sein schriftstellerisches Werk. Mulisch behauptete von sich aufgrund dieser Verbindung, er sei der Zweite Weltkrieg ().

Mulisch besuchte von 1933 bis 1939 die Grundschule in Leiden und wechselte anschließend auf das Christliche Lyceum in Haarlem, das er im Mai 1945 ohne Abschluss verließ. Seine erste Kurzgeschichte "De Kamer" wurde am 8. Februar 1947 in der Wochenzeitschrift Elseviers Weekblad veröffentlicht.

Neben der Arbeit als Schriftsteller war Mulisch von 1958 bis 1962 als Redakteur für die Zeitschrift "Podium" tätig und arbeitete für die Zeitschriften "Randstad" (1961–1969) und "De Gids" (1965–1990). Ab 1962 war er Vorstandsmitglied des einflussreichen Literaturverlags "De Bezige Bij".

Mulisch war 1961 Berichterstatter beim Eichmann-Prozess in Israel. Daraus entstand seine Reportage "Strafsache 40/61", die 1963 mit dem Vijverberg-Prijs ausgezeichnet wurde. Seit 1962 war er mit Hannah Arendt befreundet, die ebenfalls Prozessbeobachterin war und das Werk "Eichmann in Jerusalem" verfasst hat.

In den 1960er und 1970er Jahren engagierte sich Mulisch öffentlich gegen den Kalten Krieg und den Vietnamkrieg und war zeitweise Anhänger der niederländischen Provo-Bewegung. Ab Anfang der 1980er Jahre beteiligte er sich an der niederländischen Friedensbewegung.

Weltweite Beachtung fanden seine Romane "Das Attentat" (1982) und "Die Entdeckung des Himmels" (1992); im ersteren Roman geht es um die Folgen der Ermordung eines mit dem NS-Regime kollaborierenden niederländischen Polizisten, in "Die Entdeckung des Himmels" wird das Verhältnis von Wissenschaft und Religion auf mystische Weise behandelt.

In der niederländischen Nachkriegsliteratur war oft von den „großen Drei“ die Rede – gemeint sind Willem Frederik Hermans, Gerard Reve und Harry Mulisch. Nach dem Tod Hermans’ und der fortschreitenden Demenzerkrankung Reves nannte sich Mulisch manchmal scherzhaft den „großen Einen“ ().

Harry Mulisch zog nach dem Tod seines Vaters 1958 nach Amsterdam. 1971 heiratete er die 21 Jahre jüngere Künstlerin Sjoerdje Woudenberg, mit der er zwei Töchter (* 1971 und * 1974) bekam. Seit 1989 lebte er mit seiner Freundin Kitty Saal zusammen, mit der er einen Sohn (* 1992) bekam.

Im Jahr 2002 wurde ihm vom Deutschen Botschafter in Amsterdam, Edmund Duckwitz, das Bundesverdienstkreuz erster Klasse für "Das Attentat" und "Die Entdeckung des Himmels" aufgrund der „wichtigen Vermittlerrolle seiner Werke“ überreicht.

Im Jahr 2006 wurde zu seinen Ehren der 1971 entdeckte Planetoid Nr. 10251 mit dem Namen "Mulisch" benannt.

Das literarische Schaffen Mulischs umfasst ein weites Spektrum aus journalistischen Arbeiten, Erzählungen, Romanen, Dramatik, Lyrik, Opernlibretti und philosophischen Essays.

Harry Mulisch starb am 30. Oktober 2010 im Alter von 83 Jahren in seinem Haus in Amsterdam an den Folgen seiner Krebserkrankung.











</doc>
<doc id="10741" url="https://de.wikipedia.org/wiki?curid=10741" title="Tron">
Tron

TRON oder Tron steht für:

außerdem folgende Personen:

sowie folgende geografische Bezeichnungen:

Siehe auch:



</doc>
<doc id="10742" url="https://de.wikipedia.org/wiki?curid=10742" title="Terry Pratchett">
Terry Pratchett

Sir Terence David John Pratchett, OBE (* 28. April 1948 in Beaconsfield, Buckinghamshire; † 12. März 2015 in Broad Chalke, Wiltshire) war ein britischer Fantasy-Schriftsteller. Seine bekanntesten Werke sind seine Scheibenwelt-Romane, die in 37 Sprachen übersetzt wurden. Weltweit wurden rund 85 Millionen seiner Bücher verkauft.

Terry Pratchett veröffentlichte sein erstes Werk mit 13 Jahren. Es war die Kurzgeschichte "The Hades Business", die erst in der Schülerzeitung und später im "Science Fantasy Magazine" veröffentlicht wurde.

Nachdem er 1965 von der Schule abgegangen war, begann Pratchett im selben Jahr eine Ausbildung zum Journalisten bei einer Lokalzeitung. Während seiner Tätigkeit als Journalist erwähnte er bei einem Interview mit Peter Bander van Duren, einem Leiter eines kleinen Verlages, dass er ebenfalls einen Roman geschrieben habe: "Die Teppichvölker".

Pratchett war seit 1968 mit Lyn Marian Purves verheiratet; ihre Tochter Rhianna (* 1976) ist ebenfalls als Autorin tätig.

1980 wurde Pratchett Pressesprecher des Central Electricity Generating Board (CEGB). Das CEGB war ein staatlicher Betrieb in Großbritannien, der die Aufteilung der Stromproduktion auf verschiedene Erzeugungsmethoden regelte. Als klar wurde, dass er von seinen Büchern leben konnte, beendete Pratchett 1987 seine Arbeit beim CEGB und veröffentlichte ab dann etwa zwei Romane pro Jahr. 2003 war er nach Joanne K. Rowling der erfolgreichste Autor Großbritanniens.

Im Dezember 2007 gab Pratchett bekannt, dass bei ihm eine sehr seltene, früh beginnende Form der Alzheimer-Krankheit diagnostiziert worden war. Über die Krankheit sprach Pratchett am 13. März 2008 in einem Interview in der BBC-Radio-Sendung "Today Programme". Nach eigener Aussage hat er seinen Führerschein abgegeben und Schwierigkeiten beim Maschinenschreiben, weshalb er seine Texte seitdem mit Hilfe einer Spracherkennungssoftware verfasste. Pratchett spendete eine Million Dollar an den Alzheimer Research Trust und kritisierte, dass für die Erforschung von Demenzerkrankungen zu wenige Mittel bereitgestellt werden. „Ich würde den Hintern eines toten Maulwurfs essen, wenn mir damit geholfen wäre“, sagte er. In diesem Zusammenhang sprach er sich auch für Sterbehilfe aus. Pratchett führte eine Kampagne gegen das Verbot der Sterbehilfe in Großbritannien. Er hat einen BBC-Dokumentarfilm produziert, in dem er zwei Menschen zum Freitod in die Schweiz begleitet. Neil Gaiman erzählte während eines Vortrages, dass Pratchett in seinem Tresor Pillen für einen Selbstmord gelagert hatte, sodass er im Zweifelsfall selbst hätte entscheiden können, wann er sterben würde.

1998 wurde Pratchett zum Officer des Order of the British Empire (OBE) ernannt. Am 31. Dezember 2008 wurde er für seine Verdienste um die Literatur von der Queen zum Knight Bachelor ernannt und durfte sich seitdem "Sir" Terry Pratchett nennen. Am 28. April 2010 wurde ihm vom Clarenceux King of Arms ein eigenes Wappen verliehen. Dieses führt unter anderem ein Ankh und eine Morpork-Eule, welche aus dem Wappen der von ihm erdachten Stadt Ankh-Morpork, dem Schauplatz vieler seiner Werke, entnommen sind, und das Motto „Noli timere Messorem“ („Fürchte den Sensenmann nicht“, eine Anspielung auf das Lied "(Don’t Fear) The Reaper" von Blue Öyster Cult und auf die sympathische Art der Figur „Tod“, der in vielen Scheibenweltromanen eine tragende Rolle spielt). 2004 erhielt er zum ersten Mal den Locus Award, 2011 den Karl Edward Wagner Special Award. 2011 erhielt er auch den Margaret A. Edwards Award der American Library Association für großen Verdienste in der Jugendliteratur.

Pratchett starb am 12. März 2015 im Alter von 66 Jahren auf seinem Anwesen in Broad Chalke in der Grafschaft Wiltshire, an den Folgen einer posterioren kortikalen Atrophie (PKA, auch Benson-Syndrom), einer der Alzheimer-Erkrankung sehr ähnlichen neurodegenerativen Erkrankung.

Einer seiner Fans reagierte auf die Todesnachricht mit einer Petition bei Change.org mit der Forderung, der Tod möge Terry Pratchett zurückgeben. Binnen zweier Tage wurde sie von über 25.000 Fans unterzeichnet. Betreiber verschiedener Internet-Server fügen zum Gedenken an Pratchett – und in Anlehnung an eine in "Ab die Post" dargestellte Form des Gedenkens – zusätzliche Header-Zeilen in die ausgehenden Daten ihrer Server ein.

Neben Pratchetts sehr eigenem Schreibstil, insbesondere durch seinen in der Fantasyliteratur genreunüblichen Humor bis hin zur Persiflage, zeichnen sich einige seiner Bücher durch die zum Teil überbordende Verwendung von Fußnoten aus. Die niederländische Übersetzung von "Good Omens", das Pratchett in Co-Autorenschaft mit Neil Gaiman schrieb, beginnt mit einem ironischen Vorwort des Übersetzers, in dem er versichert, keine zusätzlichen Fußnoten eingebaut zu haben, um eventuelle Unklarheiten zu beseitigen – ergänzt um Fußnoten zur Klärung von Omen und Crowley.

Bis auf wenige Ausnahmen sind Pratchetts Werke nicht in Kapitel untergliedert. In einem Interview begründete er dies damit, dass das Leben ebenfalls für gewöhnlich nicht in Kapiteln stattfinde und er abgesehen von ihrer Verwendung in Kinderbüchern keinen Zweck von Kapiteln erkennen könne. Dementsprechend enthalten vor allem Pratchetts Jugendbücher Kapitel, daneben aber auch die Romane um die Figur Feucht von Lipwig. Hier erfüllen sie allerdings eine Funktion, die über eine reine Gliederung des Textes hinausgeht: Jedes Kapitel beginnt mit einer ganzen Reihe von Überschriften, die auf Teile des Inhalts vorgreifen und damit bestimmte Erwartungshaltungen hervorrufen können.

Pratchetts Bücher finden ein für dieses Genre eher unübliches Echo. Eine Sammlung von Essays über sein Werk findet sich in dem Buch "Terry Pratchett: Guilty of Literature", herausgegeben von Andrew M. Butler, Edward James und Farah Mendlesohn; eine deutsche Studie, „The Turtle Moves!“ von Johannes Rüster, befasst sich mit kosmologischen und theologischen Fragen in den Scheibenweltromanen. Zwei weitere Bücher sind erwähnenswert, die beide von David Langford zusammengestellt wurden, nämlich "The Unseen University Challenge" und "The Wyrdest Link".

Seinen ab 1983 erschienenen Scheibenwelt-Romanen verdankte Terry Pratchett seine weltweite Bekanntheit und seine große Fangemeinde. Die Geschichten dieser Roman-Reihe spielen auf der „Scheibenwelt“, die flach ist und von vier Elefanten getragen wird, die ihrerseits auf dem Rücken einer riesigen Schildkröte stehen, welche durch das Weltall „rudert“.

Bei den Scheibenwelt-Geschichten handelt es sich jedoch nicht nur um klassische Fantasy-Romane, die in einer fiktiven Welt spielen – vielmehr werden in ihnen sowohl klassische Fantasy- und Science-Fiction-Motive parodiert als auch Themen des alltäglichen Lebens wie Rock ’n’ Roll, Filme, Glaubwürdigkeit der Presse, Religion, Philosophie, Wirtschaft, chinesische und ägyptische Geschichte, Politik (z. B. Regierungsformen), Krieg und vieles mehr.

Gut erhaltene Erstausgaben von Pratchetts frühen Scheibenweltromanen sind innerhalb der Fangemeinde sehr wertvoll: Die gebundene Erstausgabe von „The Colour of Magic“ („Die Farben der Magie“) ist derzeit mehr als £ 2000 wert. Insgesamt wurden 4500 Stück gedruckt, 506 davon wurden in Großbritannien verkauft. „The Light Fantastic“ („Das Licht der Phantasie“) wird um £ 1000–1500 gehandelt. Die Umschläge aller Scheibenweltromane, die bis 2001 in Großbritannien verkauft wurden, hat Josh Kirby gestaltet. Nach Kirbys Tod übernahm Paul Kidby, der zuvor schon Scheibenwelt-Illustrationen angefertigt hatte, die Umschlaggestaltung der britischen Ausgaben. Teilweise wurden die Umschlaggestaltungen mit farblichen Abwandlungen auch für die deutschsprachigen Ausgaben verwendet.

Pratchett wurde in seinem Fankreis oft respektvoll "Pterry" genannt, eine Reverenz an die stummen P der Figuren (wie zum Beispiel "Pteppic") in dem Roman "Pyramiden", die ihrerseits auf "Ptolemaios", den griechischen Namen diverser hellenistischer Pharaonen anspielen, und obendrein eine Verknüpfung (des Initials) seines Nachnamens mit seinem Vornamen.

Pratchett hatte ein ausgeprägtes Interesse an Orang-Utans. Dieses beschränkte sich nicht nur auf die auffallende Figur des Bibliothekars seiner Scheibenwelt-Romane, einen seiner populärsten Charaktere. Er arbeitete auch für die "Orang-Utan Foundation", etwa in Form eines Besuchs auf Borneo mit einer Channel-4-Filmcrew, um eine Episode von „Jungle Quest“ zu drehen, die Orang-Utans in ihrer natürlichen Umgebung zeigt. Dem guten Beispiel Pratchetts folgend, haben Fan-Events wie die Scheibenwelt-Convention die Orang-Utan-Foundation zu ihrem Anliegen erklärt. Wenn Pratchett solche Treffen besuchte, fand stets eine Auktion statt, bei der Fans die Nennung ihres Namens im nächsten Scheibenweltroman ersteigern konnten. Alle Erlöse gingen direkt an die Orang-Utan-Foundation.

"Liste der Scheibenwelt-Romane"

Romane
Reihen
Geschichten u. a.



Spielfilme

Serien

Animationsfilme


Scheibenwelt-Romane

Andere Romane

Geschichten u. a.



Interviews


</doc>
<doc id="10743" url="https://de.wikipedia.org/wiki?curid=10743" title="Scheibenwelt">
Scheibenwelt

Die Scheibenwelt (engl. "Discworld") ist eine fiktive Welt und der Schauplatz zahlreicher bizarrer, humorvoller Romane des englischen Schriftstellers Terry Pratchett.

Die Scheibenwelt ist eine flache, scheibenförmige Welt mit einem Durchmesser von 10.000 Meilen (16.093 km). Ihr Umfang beträgt 31.415 Meilen (50.558 km). Die Oberfläche ist demnach 78.539.816 Meilen² (203.406.067 km²) groß, was etwas weniger als der Hälfte der Erdoberfläche entspricht.

Die Welt ruht auf den Rücken von vier Elefanten ("Berilia", "Tubul", "Groß-T'Phon" und "Jerakeen"), die wiederum auf dem Rücken der Sternen-Schildkröte "Groß-A’Tuin" stehen. Die durch den Weltraum „schwimmende“ Schildkröte ist ein von der indischen Mythologie inspiriertes Weltbild.

Auf den ersten Blick erscheinen die Scheibenwelt und ihre Bewohner wie normales, durchschnittliches Fantasy-Interieur: Hexen, Zauberer, Trolle, Zwerge und Magier. Tatsächlich aber persiflieren die Geschichten sowohl klassische Fantasy- und Science-Fiction-Motive wie auch viele Themen aus unserer Welt, die bei Pratchett die „Rundwelt“ heißt.

Immer wieder Thema ist unsere Art narrativen Denkens. Die Scheibenwelt ist ein Ort, an dem Geschichten, Allegorien und Metaphern "real" sind. Es gibt dort die Zahnfee, einen Weihnachtsmann, den „Schneevater“, und vor allem Hunderte Götter. Die Scheibenwelt lässt Dinge real werden, wenn man nur genügend an sie glaubt. Klassische Humor-Klischees, wie die rauchenden Stiefel, die stehen bleiben, wenn eine Explosion eine Person zerfetzt, oder das brennende Rad, das bei einer Kutschenexplosion unweigerlich aus den Trümmern rollt, werden ebenso thematisiert wie die berühmte Chance von Eins zu einer Million, die selbstverständlich zwingend eintreten muss.

Alltägliche Rundwelt-Phänomene wie der Rock ’n’ Roll, Kino und Film, die freie Presse, Religion, Philosophie oder die Geldwirtschaft werden ironisch gebrochen auf den Leser zurück gespiegelt. Geschichtsklischees über chinesische oder ägyptische Geschichte, verschiedene Regierungsformen, vom Despotismus bis zur Demokratie, Ursachen für die Entstehung von Krieg, kaum ein Thema, das auf der Scheibenwelt nicht aus einer eigenen, neuartigen Perspektive gesehen wird. Computer ("HEX") fehlen dabei genauso wenig wie die schnelle digitale Nachrichtenübertragung via Klackertürmen. Ein ganz eigenes Kapitel ist Terry Pratchetts Verhältnis zu PDAs, ihrem Sinn und ihren Nutzungsbedingungen. Auf der Scheibenwelt sind es Kästen, in denen ein eingesperrter Kobold seinen Dienst versieht. Kommandeur Mumm wird von seiner Gattin Lady Sybil kontinuierlich mit den neuesten Versionen dieser Geräte versorgt.

Pratchett parodiert das Genre Fantasy und erschafft gleichzeitig eine eigene durchaus glaubhafte Welt, in der mit abgründigem Humor überaus ernsthafte Themen diskutiert werden. Das gesamte Personal gängiger Fantasy kommt zum Einsatz. Zauberer, ständig rauchend und essend und deswegen dick und kurzatmig, bekämpfen gräßliche, namenlose Dinge, aus den "Kerkerdimensionen", die ständig versuchen, in die „reale“ Dimension herüberzuwechseln – in Anspielung auf das Werk von Lovecraft. Es gibt weibliche Zwerge, die von den traditionellen Zwergen diskriminiert werden, die darauf beharren, es gebe nur männliche Zwerge – der Feminismus macht auch vor der Scheibenwelt nicht halt. Es gibt Helden im Pensionsalter, abstinente Vampire, eine multiethnische Polizeitruppe sowie Hexen, Kobolde, Trolle, Golems, Elfen und Banshees. In den neuesten Romanen ("Club der unsichtbaren Gelehrten" und "Steife Prise") verwendete Pratchett vermehrt Elemente aus dem Werk von J. R. R. Tolkien, z. B. durch die Einführung neuer Rassen wie Orks und Goblins.

Einige Charaktere dienen quasi als Prototypen für bestimmte verallgemeinerbare Phänomene und tauchen deshalb in fast allen Romanen der Scheibenwelt auf. Die anthropomorphe Personifizierung von "Tod" ist, wie in der Rundwelt auch, immer präsent, und wenn er es nicht ist, wird seine Präsenz unverwechselbar angedeutet. Etwa dadurch, dass eine Nebenfigur im Gedränge der Stadt Ankh-Morpork jemanden anrempelt, sich entschuldigt, und der Angerempelte in den für die Stimme des Todes typischen Versalien antwortet und andeutet, dass man sich sicherlich bald beruflich wiedersehen werde. Diese dauerhafte Präsenz des Todes ist jedoch nicht angstbesetzt, sondern lässt viel Spielraum für Humor – in vielen Fällen Galgenhumor.

Die scheibenweltumspannende Präsenz von Handel und Geschäft repräsentiert die Figur des immer wieder tragisch scheiternden Geschäftsmannes T.M.S.I.D.R. Schnapper. Sein Basisgeschäft ist der Verkauf grässlicher Würstchen bzw. – je nach Weltgegend, in der er auftaucht – eine andere lokale „Spezialität“.

Schließlich "der Bibliothekar" der Unsichtbaren Universität, ein Zauberer, den ein magischer Unfall in einen Orang-Utan verwandelt hat. Er repräsentiert die wilde, unbändige Verwandlungskraft, die Bildung in die Welt bringen kann, wenn man sie denn lässt. Aber auch das Fremdartige, das von Wissen ausgelöst werden kann, findet in seiner Figur Platz. Obwohl er nur eine Silbe spricht, nämlich „Ugh“, wird er von jedem verstanden, der sich die Mühe macht, gut zuzuhören. Als Herrscher über den sogenannten "B-Raum" (im englischen Original: "L-Space"), ein multidimensionales Konstrukt, das sämtliche Bibliotheken durch Raum und Zeit miteinander verbindet, repräsentiert "Der Bibliothekar" auch die vielen Querverbindungen zwischen den verschiedenen Romanen.

Als eine Art Running Gag lassen sich die ethnospezifischen Sprachfehler (der Satzbau der Trolle, das Lispeln der Igors) oder ganz spezifische Ausdrucksweise einzelner Akteure betrachten. Sie durchziehen konsequent alle Bücher und charakterisieren manche Gruppen besser, als eine Beschreibung es könnte.

"Für weitergehende Informationen zu Personen und Orten, siehe: Figuren und Schauplätze der Scheibenwelt-Romane."

Alle 41 bisher zur Scheibenwelt erschienenen Romane wurden ins Deutsche übersetzt. Die einzelnen Romane erzählen teilweise zusammenhängende Geschichten, können aber in einer beliebigen Reihenfolge gelesen werden. Einige Geschichten, die Personen und Orte sind aber deutlich besser zu verstehen und einzuordnen, wenn man andere Romane schon gelesen hat.

Viele Bücher gibt es als Hörbuch-, Comic- oder Filmbearbeitungen.

Ian Stewart und Jack Cohen erläutern innerhalb einer Rahmenhandlung von Terry Pratchett die Geschichte der Erde und Probleme moderner Wissenschaften und ihrer Didaktik. Diese Tetralogie wird oft fälschlicherweise nicht in das Handlungsgefüge der Scheibenwelt miteinbezogen. In Wirklichkeit nimmt der Band Einfluss auf die Zauberer-Reihe, weil u. a. Rincewind in "Die Gelehrten der Scheibenwelt" vom stellvertretenden Bibliothekar zum „Professor für ungewöhnliche und grausame Geographie“ befördert wird, was in "Wahre Helden" erwähnt wird.




Stephen Briggs und andere setzten verschiedene Bücher auch Scripte für Theaterstücke um, die in verschiedener Auflagengröße (zwischen 10 und 28800 Exemplaren) von verschiedenen Verlagen, hauptsächlich in englischer Sprache herausgegeben wurden.





Der Keyboarder Dave Greenslade veröffentlichte im Jahr 1994 das Scheibenwelt-Konzeptalbum "From the Discworld", welches samt Covergestaltung von Josh Kirby und Booklet-Anmerkungen von Pratchett selbst den Eindruck eines „offiziellen“ Produkts erweckte. Neben überwiegend instrumentalen Stücken waren auch das in den Romanen häufig erwähnte Lied "Des Zauberers Stab hat einen Knauf am Ende" (engl.: "The Wizard’s Staff Has a Knob on the End") sowie die Musik zum "Stock-und-Eimer-Tanz" zu hören.

Von "Soul Music" und "Wyrd Sisters" gibt es Zeichentrick–Fernsehverfilmungen. Dazu gibt es einen achtminütigen Trailer, dessen Szenen aus dem Buch "Alles Sense (engl.: Reaper Man)" entnommen sind. Der Trailer erschien nur in englischer Sprache und trägt den Namen "Welcome to the Discworld". Des Weiteren wurden "Wyrd Sisters" und "Lords and Ladies" von "No Budget Productions" verfilmt.

Das Buch "Hogfather" wurde unter der Regie von Vadim Jean zu Weihnachten 2006 für den britischen Fernsehsender Sky One verfilmt. Seit Dezember 2007 gibt es eine deutsch synchronisierte Version auch auf DVD; beide Teile wurden am 25. Dezember 2007 auf ProSieben erstmals im deutschen Fernsehen ausgestrahlt.

Des Weiteren wurden Pratchetts erste beiden "Scheibenwelt"-Romane "Die Farbe der Magie" und "Das Licht der Fantasie" von dem „Hogfather“-Team zusammen unter dem Titel "The Colour of Magic" verfilmt und am 23. und 24. März 2008 zweiteilig erstausgestrahlt; in Deutschland ist der 190 Minuten lange Film seit dem 9. Oktober 2008 auf einer DVD erhältlich und wurde am 11. Juli 2009 von RTL (unter dem Titel "The Color of Magic – Die Reise des Zauberers") erstmals im deutschen Fernsehen gezeigt.

"Going Postal" (deutscher Titel "Ab die Post") wurde von Regisseur Jon Jones verfilmt und erschien am 30. und 31. Mai 2010 zweiteilig auf Sky One und in Deutschland am 15. November 2010 auf DVD und Blu-ray. RTL brachte am 19. Mai 2013 den Film unter dem Titel "Terry Pratchett – Ab die Post" erstmals im deutschen Fernsehen. Terry Pratchett hat hier einen Cameo-Auftritt als Postzusteller.

Die Firma "Clarecraft" hat eine große Menge an Scheibenweltminiaturen herausgebracht. Sie sind in der Regel 5 bis 20 cm groß und stellen jeweils eine, manchmal auch mehrere, der in den Romanen vorkommenden Figuren dar. Zusätzlich wurden von derselben Firma Zinnminiaturen der Scheibenweltfiguren angeboten. Allerdings werden diese Figuren nicht weiter produziert, so dass sie nur noch schwer erhältlich sind.

2008 hat die polnische Firma "Micro Art Studio" die Rechte für Scheibenwelt-Miniaturen übernommen und produziert Zinnfiguren zu den verschiedenen Figuren im 30-mm-Maßstab.

Die britische Firma "The Cunning Artificer" produziert Miniaturen von Gebäuden und Geländestücken der Scheibenwelt. Sie stellt auch eine Reihe von Scheibenwelt-Briefmarken her.

Es existiert eine große Bandbreite von Produkten mit Motiven der Scheibenwelt.

Die deutschen Übersetzungen stammen von Andreas Brandhorst (Ausnahmen: "Schöne Scheine", übersetzt von Bernhard Kempen sowie "Der Club der unsichtbaren Gelehrten" und "Steife Prise", beide übersetzt von Gerald Jung) und sind bei den Lesern umstritten.

Im deutschen Text geht unvermeidlicherweise nicht nur viel von Pratchetts direktem Wortwitz verloren, sondern bei der Übersetzung müssen auch ganze "Wortspiel-Systeme", die sich durch einen oder mehrere Bände ziehen, umformuliert und an meist weniger (oder gar nicht) komische Analogien angepasst werden. Kritiker bemängeln zusätzlich mehr oder weniger vermeidbare Übersetzungsfehler.



</doc>
<doc id="10744" url="https://de.wikipedia.org/wiki?curid=10744" title="September 2002">
September 2002

Dieser Artikel behandelt aktuelle Nachrichten und Ereignisse im September 2002.












</doc>
<doc id="10747" url="https://de.wikipedia.org/wiki?curid=10747" title="Fiktives Universum">
Fiktives Universum

Ein fiktives Universum (auch fiktive Welt, fiktiver Ort oder Fantasiewelt) ist eine fiktionale Realität, die sich durch mehr oder minder große Abweichungen von der Realität unterscheidet. Diese Abweichungen können sich auf die bloße Existenz von Fantasiefiguren wie Sherlock Holmes beschränken oder bis hin zu grundlegend andersartigen Welten wie der Scheibenwelt oder Narnia reichen, in denen Magie existiert oder Naturgesetze auf andere Weise außer Kraft gesetzt werden bzw. variieren. Im weitesten Sinne spielt damit jede Fernsehserie, jeder Spielfilm, jeder Roman, jedes Comic o. Ä. in einem fiktiven Universum, das bei Fernsehserien auch Serienuniversum genannt wird. In einem engeren Verständnis werden jedoch vor allem umfangreich von der Realität abweichende fiktive Universen als solche wahrgenommen. Solch ein fiktives Universum kann eine Vielzahl "fiktiver Orte" umfassen, kann aber auch aus lediglich einem oder gar keinem fiktiven Ort bestehen. Die Erfindung fiktiver Universen bzw. fiktiver Welten ist ein beliebtes Element nicht nur in Science-Fiction-, Fantasy- und Utopie-Werken, sondern auch der politischen Philosophie.

In Rollenspielen, insbesondere in Pen-&-Paper-Rollenspielen bilden die fiktiven Welten einen zentralen Punkt. Eine solche fiktive Spielwelt dient als Hintergrund und Handlungsort eines Spiels. Der Begriff wird hauptsächlich bei Pen-&-Paper-Rollenspielen und Computerspielen verwendet. Eine fiktive Spielwelt beinhaltet prinzipiell die Beschreibung aller Aspekte, die auch die reale Welt aufweist, also unter anderem der geographischen, soziologischen, politischen, wirtschaftlichen und klimatischen Bedingungen. Da Fantasy und Science Fiction zu den beliebtesten Genres für Spielwelten gehören, kommen oft auch Kosmologie, Religion und Magie hinzu. Manche Rollenspielwelten sind so umfangreich ausgebaut, dass ihre Beschreibung den Rahmen des Basisspiels sprengen würde. Zusätzliche Veröffentlichungen zur Beschreibung der Welt werden als Quellenbücher bezeichnet. Oft werden auch fiktive Welten aus der Literatur oder anderen Medien als Spielwelt übernommen.

Ähnlich ist es bei Computerspielwelten. Diese werden jedoch meist nur implizit durch die Ereignisse im Spiel beschrieben, manchmal gibt es aber auch zu Computerspielewelten umfangreiche Informationen, etwa durch Romane zum Spiel oder ausführliche Texte, die im Spiel entdeckt werden können.

Die Tätigkeit des Erfindens solcher fiktiver Universen bzw. Orte und Welten wird auch als "Weltenbasteln" oder "Weltenbau" bezeichnet.

Fiktive Welten müssen sich nicht maßgeblich von der Realität unterscheiden. Grundsätzlich entspricht jeder Handlungsort von Fiktion einer eigenständigen Wirklichkeit. Gerade im Science-Fiction- und Fantasy-Bereich werden aber oft übernatürliche Elemente eingeflochten. Fantastik spielt oft in einer mythologisierten Vergangenheit. Auch Märchen, Sagen und Mythen fallen in diese Kategorie, genauso wie moderne Bearbeitungen davon („Die Nebel von Avalon“ von Marion Zimmer Bradley oder der Zyklus „Wintersonnenwende“ von Susan Cooper). Daneben gibt es genauso Welten, die durch einen Übergang in einer der Realität nachempfundenen Wirklichkeit erreicht werden. Ein klassisches Beispiel hierfür ist "Alice im Wunderland".

Viele Fantasiewelten sind jedoch eigenständig. Als Vorreiter der Fantasyliteratur gilt Mittelerde aus der Feder J. R. R. Tolkiens, an dem sich viele spätere Fantasywelten und Rollenspiele orientiert haben. Tolkien hat auch zum Prozess der Erfindung einer Fantasiewelt, dem Weltenbasteln, den er als "Subcreation" bezeichnete, geschrieben.

In der Philosophie und den klassischen Science-Fiction dienen solche Welten als Gleichnis auf reale gesellschaftliche Probleme (siehe auch Utopie, Dystopie). Im Falle der Terra Australis von Ptolemäus hat sich ein Gedankenexperiment im Nachhinein sogar als Realität herausgestellt.

Speziell im Bereich der Science-Fiction- und Fantasy-Literatur wird oft viel Wert auf einen stimmigen Hintergrund gelegt. Auch bei der Entwicklung von Rollenspielsystemen sind solche Überlegungen notwendig, doch während ein Autor sich meist nur mit den Bereichen beschäftigen muss, die für seine Geschichte relevant sind, muss ein Rollenspielautor den Spielern die Freiheit geben, die verschiedensten Bereiche zu erkunden. Rollenspielwelten neigen daher dazu, eher breitflächig angelegt zu sein. Durch den Austausch im Internet gibt es inzwischen auch Einzelpersonen, die das „Gestalten“ fiktiver Welten als reinen Selbstzweck in ihrer Freizeit betreiben.

Im kommerziellen Bereich dienen elaborierte Realitäten oft auch der Kundenbindung. In den 60er Jahren begründeten Stan Lee und Jack Kirby von Marvel Comics mittels vielfältiger Gastauftritte der Superhelden durch ihre Comic-Reihen den bis heute andauernden Erfolg des Verlags. Auch in Film- und Fernsehbereich werden derartige Gastauftritte oft genutzt, um auf neue Formate hinzuweisen.

Zum Teil wird das „Konstruieren“ von Welten auch wissenschaftlich und sogar experimentell im Labor betrieben. So erforscht etwa die NASA alternative Voraussetzungen und Entwicklungen zur Entstehung des Lebens auf anderen Planeten oder versucht herauszufinden, wie Lebensformen in anderen Ökosystemen beschaffen sein könnten. Dies bildet mit der Astrobiologie einen eigenen Wissenschaftszweig. Die dazu nötigen Gedankengänge ähneln stark dem Weltenbasteln.

Ein Weltenbastler erfindet – oder bastelt – fiktive Welten beliebigen Ausmaßes. Dazu gehören mitunter das Erfinden von Sprachen, das Entwerfen von Landkarten, Völker- und Rassenbeschreibungen, Gesetzestexten und vieles mehr. Auf diese Weise können Dörfer, Länder oder sogar ganze Parallelwelt-Komplexe entstehen. Im Rollenspiel- und Fantasy-Bereich wird dabei weniger assoziativ von einer Idee zur Nächsten entwickelt, sondern klar strukturiert eine Welt geplant. Viele Weltenbastler beginnen mit dem Zeichnen einer Karte oder dem Schreiben einer Geschichte. Im Folgenden werden zwei Ansätze dazu erläutert. In den nachfolgenden Listen finden sich viele Beispiele von fiktiven Welten, die maßgeblich von Einzelpersonen erdacht wurden.

Begonnen wird mit einem groben Überblick über die Welt. Am Anfang stehen eine Weltkarte und grundlegende Eckdaten zu Geografie, Klimazonen, Bewohnern der Welt, einer allgemein gehaltenen Weltgeschichte oder dem Stand der Technik dieser Welt. Von hier ausgehend wird immer weiter verfeinert, über Kontinente, Zivilisationen, Nationen bis hin zu Städten und Dörfern, bis schließlich alle nötigen Details der interessanten Regionen bekannt sind.

Viele Science-Fiction-Planeten entstehen auf diese Art, indem zuerst Kennwerte wie Hydrographik, Durchschnittstemperatur, Atmosphäre, Bevölkerung und andere gewählt werden und danach zu den regionalen Details übergegangen wird.

Mit dieser Methode lassen sich insgesamt stimmige und widerspruchsarme Welten erstellen. Zum Teil wird viel Wert auf die Einhaltung der heute bekannten physikalischen Gesetze gelegt, ihnen aber auch bewusst widersprochen. Allerdings benötigt dieser Ansatz vom Allgemeinen zum Speziellen viel Zeit, bis eine Region so weit ausgearbeitet ist, dass man sie für einen Roman oder ein Rollenspiel nutzen kann.

Der andere Ansatz ist, sich zunächst eine Region vorzunehmen, um diese in allen Details zu beschreiben, Fakten über lokale Geografie, Kulturen, Sozialstrukturen, Politik, Wirtschaft und Geschichte festzulegen, die wichtigsten vorkommenden Personen vorzustellen und ihre Beziehungen zueinander zu erläutern. Die umgebenden Gebiete werden auf einer weniger detailgenauen Ebene beschrieben. Je weiter die beschriebene Region vom beschriebenen Ort entfernt ist, desto geringer werden die Details. Erst wenn der Weltenbastler andere Teile seiner Welt benötigt, werden diese bei Bedarf ausgebaut und beschrieben.

Häufig findet man diesen Ansatz bei Fantasy-Autoren, die zunächst beschreiben, was für ihren Held und dessen Geschichte von unmittelbarer Wichtigkeit ist, während sie die übrige Welt nur grob andeuten und weitere Regionen erst dann und auch nur so weit beschreiben, wie es für die Dramaturgie wichtig ist.

Der Vorteil dieser Vorgehensweise ist, dass die Region sehr schnell zur Verfügung steht, beispielsweise als Hintergrund für Romane oder Rollenspiele. Nachteilig macht sich allerdings häufig ein unzusammenhängender Gesamtaufbau der Welt bemerkbar. So sind zum Beispiel oft zu viele unterschiedliche Kulturen auf zu engem Raum zu finden.

Ein typisches Beispiel für eine auf diese Art entstandene Welt ist die Welt von Elric von Melniboné des Autors Michael Moorcock.

Eines der frühesten und populärsten Beispiele ist George Lucas' "Star Wars", was in Folge der drei ursprünglichen Filme schon früh eine Vielzahl an Comics, Literatur, Fernsehprogrammen oder Videospielen hervorgebracht hat. Da sich Lucas selbst die Kanonisierung der einzelnen Erweiterungen vorbehalten hat, widerspricht einiges in Expanded Universe den späteren „offizielleren“ Kinofilmen. Mit dem Kinostart von "Iron Man" 2008 begannen die Marvel Studios damit, strukturiert ihre vielfach verknüpfte Comic-Welt auf Film und Fernsehen zu übertragen. Dies bezeichnen sie selbst als Marvel Cinematic Universe.

Gewöhnlicherweise gibt es keine umfassenden (externen) Beschreibungen zu den Welten von Film und Fernsehen, sie sind also in der Regel auf das beschränkt, was dort auch dargestellt wird. Vielfältig gibt es aber Gastauftritte von Figuren aus anderen Serien (siehe Crossover (Medien)) oder aber Figuren aus einer Serie werden in eine neue übernommen (siehe Ableger (Medien), Backdoor-Pilot). Dies geschieht meist, um das Publikum eines bereits etablierten Programms auf ein neues aufmerksam zu machen. Als Gedankenspiel kann man beide fiktiven Realitäten miteinander verknüpfen, was aufgrund umfangreicher Gastauftritte gerade im amerikanischen Fernsehen eine gewaltige zusammenhängende Welt schafft, die von "Verliebt in eine Hexe" über "Star Trek" bis hin zu "The Wire" reicht und sich bis heute erweitert.

Zur Illustration der Struktur und Vielfalt fiktiver Welten folgen einige Beispiele in chronologischer Ordnung. Eine Auflistung weiterer fiktiver Orte und Welten findet sich unter den weiterführenden Informationen.

Die frühesten Beispiele bilden philosophische Utopien, klassische Mythen und die Kinderliteratur des 19. Jahrhunderts.


Nach Vorbild von Tolkiens Mittelerde wird die Welt hier oft an einem mythologisierten europäischen Mittelalter angelehnt, angereichert mit klassischen fantastischen Elementen wie Fabelwesen oder Magie










</doc>
<doc id="10748" url="https://de.wikipedia.org/wiki?curid=10748" title="Utopie">
Utopie

Eine Utopie ist der Entwurf einer fiktiven Gesellschaftsordnung, die nicht an zeitgenössische historisch-kulturelle Rahmenbedingungen gebunden ist. 

Der Begriff bezieht sich auf „Nicht-Ort“; aus altgriechisch ' „nicht-“ und ' „Ort“. Die mit Utopie beschriebene fiktive Gesellschaftsordnung ist meist positiv. Deshalb handelt es sich in dem Sinne um ein Sprachspiel zwischen Utopie und Eutopie aus "εὖ" (eu) „gut“ und "τόπος". Dagegen bezeichnet die Dystopie die pessimistische Beschreibung einer unethisch negativen Gesellschaftsordnung.

Im alltäglichen Sprachgebrauch wird "Utopie" (insb. als Adjektiv "utopisch") auch als Synonym für eine von der jeweils vorherrschenden Gesellschaft überwiegend als schöne, aber unausführbar betrachtete Zukunftsvision benutzt.

Hinsichtlich ihrer Umsetzbarkeit wird zwischen deskriptiven, evasiven und konstruktiven Utopien unterschieden, die sich auf Staats- und Wirtschaftsformen, die Zukunft von Kultur, Kunst oder Religion, verschiedene Arten des Zusammenlebens, Innovationen des Bildungswesens oder der Geschlechterkonstellationen u. a. beziehen können.

Der Begriff entstammt dem Titel "De optimo rei publicae statu deque nova insula Utopia" (Vom besten Zustand des Staates oder von der neuen Insel Utopia) des 1516 erschienenen Romans des englischen Staatsmanns Thomas Morus, der darin eine ideale Gesellschaft beschreibt, mit deren Hilfe er seinen Zeitgenossen einen kritischen Spiegel vorhält. 

Oft trifft man aber auch auf die vereinfachte Bezeichnung "Utopia", welche eigentlich nur die Insel bezeichnet, auf der die Mitglieder der idealen Gesellschaft leben. Thomas Morus' "Utopia" liegt nicht in der Zukunft, sondern in einer fernen Weltgegend. 

Erst im 18. Jahrhundert lässt sich eine "Verzeitlichung der Utopie" (Reinhart Koselleck) feststellen. Im heutigen Sprachgebrauch wird eine Utopie fast immer in der Zukunft verortet und selten in der Vergangenheit oder der räumlichen Ferne.

Charakteristisch ist in allen Fällen, dass in der Gegenwart bereits vorhandene Ansätze weitergedacht oder hinterfragt werden, somit haben Utopien meist einen gesellschaftskritischen Charakter,


In diesem Sinne ist der Hauptinhalt einer Utopie häufig eine Gesellschaftsvision, in der Menschen ein alternatives Gesellschaftssystem praktisch leben (Beispiel: New Harmony). Über den Inhalt hinaus kann der Begriff Utopie außerdem auf die Präsentation bezogen werden, so dass er auch literarische oder filmische Werke bezeichnet, die eine solche utopisch bessere oder schlechtere Gesellschaft vorstellen.

Obgleich man den Begriff "Utopie" herkömmlich als Synonym für optimistisch-fantastische Ideale benutzt, kann eine Utopie in ihrem gesellschaftskritischen Aspekt durchaus gegenwärtig-praktisch ausgelegt werden und erlangt somit neben ihrer fantastischen Perspektive eine gegenwartsbezogen-kritische. Die Dichotomie "möglich − unmöglich" ist dabei Gegenstand von Diskussionen: Befürworter sehen neue Möglichkeiten am Horizont heraufziehen. Gegner verneinen diese und warnen vor unerwünschten oder unbedachten möglichen Folgen.

Dennoch zeichnet sich eine Utopie im engeren Sinne dadurch aus, dass sie zur Zeit ihrer Entstehung als nicht sofort realisierbar gilt. Diese Unmöglichkeit der schnellen Realisierung hat stets einen (oder mehrere) der folgenden Gründe:


Die Tragik der langen Arbeit, die bevorsteht, um in weiter Ferne utopische Vorstellungen Wirklichkeit werden zu lassen, ist ein elementarer Aspekt der Utopie. Tragisch ist dabei, dass sich − sowohl auf der Ebene des Fiktionalen als auch bei Versuchen der politischen Umsetzung einer Utopie − die Absicht der gesellschaftlichen Verbesserung leicht in ihr Gegenteil verwandeln kann.

Versuche, utopische Entwürfe mit Gewalt umzusetzen, führen fast zwangsläufig zu einer Verschlechterung der gesellschaftlichen Situation (Unfreiheit, Krieg, Hass). Da viele utopische Entwürfe aber ihrem Wesen nach auf einer totalitären Regierungsform basieren, können diese kaum Abweichungen dulden und neigen deshalb zur Gewalt. Auf der gegebenen Möglichkeit einer Realisierung baut dagegen die Konkrete Utopie auf.

Weil die Utopien jedoch nur aus ihrem jeweiligen historischen Kontext als unrealistisch zu verstehen sind, gleichen schon manche Aspekte des Alltagslebens am Beginn des 21. Jahrhunderts technischen und sozialen Utopien aus den 1950er Jahren (Internet, Raumfahrt) aus oder übertreffen diese noch (Gentechnik). Auch Elemente von Dystopien (Big Brother) finden sich (Überwachung).

Robert Jungk verstand Utopien als Antrieb für soziale Erfindungen in einer wünschenswerten Zukunft. Er setzte sich für eine Demokratisierung des utopischen Denkens durch Förderung der Phantasie ein und begriff dies als politisches Mittel, um angesichts gesellschaftlicher Krisen nicht in Passivität und Resignation zu versinken. Das von ihm entwickelte Zukunftswerkstatt-Konzept beinhaltet eine "Utopie-Phase".

Utopien können medienübergreifend auftauchen. Zwar werden sie häufig mit dem Medium der Literatur in Verbindung gebracht (vgl. Utopische Literatur), doch können utopische Intentionen durchaus auch in der Kunst (z.B. Wenzel Habliks "Große bunte utopische Bauten"), in der Architektur (z.B. Filaretes Plan vom Idealstaat "Sforzinda"; vgl. auch Utopische Revolutionsarchitektur), im Film (z.B. Fritz Langs "Metropolis") oder auch in Videospielen (z.B. Bethesda Softworks' "Fallout 3", oder die "Bioshock"-Serie) auftauchen. Ernst Bloch (Konkrete Utopie) und Theodor W. Adorno gehen sogar davon aus, dass die utopische Intention eine zutiefst menschliche Eigenschaft ist, die egal in welcher Lebenslage, einfach zum Menschen dazugehört. Daher können Utopien in jeder kulturellen Ausdrucksform wiedergefunden werden.

Thematisch existieren utopische Vorstellungen daher auf jedem Gebiet, u.a. also im technischen, gesellschaftlichen, kulturellen und religiösen Gebiet. In der Praxis stellen sie aber auch Mischformen dar (z. B. Technokratie). So bilden in Dystopien etwa häufig Endzeitszenarien den Erzählraum für die eigentlichen (häufig anarchischen oder totalitären) gesellschaftlichen Entwürfe.

Politische Utopien, wie sie erstmals Thomas Morus entwickelt hat, sind dadurch gekennzeichnet, dass sie die in ihrer Zeit bestehenden sozio-ökonomischen Verhältnisse und Institutionen umfassend kritisieren und aus ihrer Kritik heraus eine fiktive, in sich nachvollziehbare Alternative entwerfen. Damit werden Utopien gegen Chiliasmen und Mythen abgegrenzt. 

In der Geschichte der politischen Utopien lassen sich zwei grundlegend gesellschaftlich-staatliche Ausrichtungen feststellen: Sie bewegen sich zwischen den Idealtypen staatszentrierter Entwürfe auf der einen Seite und anarchistischer Konstruktionsprinzipien auf der anderen Seite. Gemeinsam ist den politischen Utopien von der frühen Neuzeit bis in das späte 20. Jahrhundert, dass sie Ungerechtigkeit, Ungleichheit und Unterdrückung kritisieren. 

Was die jeweiligen Utopien dagegen als Institutionen vorschlagen, um eine bessere und gerechtere Gesellschaft zu gewährleisten, wandelt sich in der Geschichte der politischen Utopien. Das Ziel von Gleichheit und Freiheit bildet zugleich die Grundlage politischer Utopien, wird aber konzeptionell in gegensätzlicher Weise in staatszentrierten und anarchistischen Utopien entwickelt.

Sozialistische und kommunistische Utopien behandeln bevorzugt die gerechte Verteilung von Gütern, oft bei gleichzeitiger Abschaffung des Geldes („jedem nach seinen Bedürfnissen“).

Es existieren sogar Vorstellungen, die ökonomisch bestimmte Erwerbsarbeit abzuschaffen (Muße, Paul Lafargue, „Das Recht auf Faulheit“, Situationismus). Die Bürger gehen nur noch solchen Arbeiten nach, die ihrer Selbstverwirklichung entsprechen.

Es bleibt viel Zeit, die Künste und Wissenschaften zu pflegen (s. auch utopischer Sozialismus, Freizeit).

Ob das von Francis Fukuyama behauptete "Ende der Geschichte" auch eine Utopie darstellt, ist fraglich, da diese in der bereits vorhandenen Welt bestünde.

Christliche und islamische Vorstellungen vom Himmel sind utopischer Natur, speziell in volkstümlichen Vorstellungen, die ein Leben ohne Sorgen und Leid enthalten. Es existieren auch utopische Vorstellungen, das Reich Gottes auf Erden zu verwirklichen.

Die christlichen Zukunftsvorstellungen vom Paradies bzw. Garten Eden auf der Erde, dem durchgesetzten Reich Gottes also, sind nach christlicher Ansicht jedoch nicht als Utopie zu bezeichnen. Zwar bezeichnen sie eine ideale Wunschvorstellung für die Zukunft, jedoch werden sie durch Gottes Gnade (und, je nach theologischer oder konfessioneller Ausrichtung, durch die Mitwirkung des Menschen) erreicht. Vor allem aber ist die theologische Aussage, dass mit der Deszendenz Jesu Christi, der Menschwerdung Jesu also, das Reich Gottes schon begonnen habe, eine explizit nicht-utopische. 

Die christliche Zukunftsvorstellung ist also keine rein futurische, sondern bezeichnet ein gleichzeitiges „schon“ und „noch nicht“: Das Reich Gottes hat mit Jesus Christus schon begonnen, wird in der Kirche fortgesetzt und ist im Himmel bereits durchgesetzt. In der gesamten Welt jedoch ist diese Vorstellung noch nicht akzeptiert und wartet somit noch auf Vollendung. Es wird dementsprechend keine neue Welt gepredigt, sondern die Erneuerung der alten Welt. Diese Vorstellung bezeichnet man in deutlicher Abgrenzung zu der "Utopie" als Eschatologie.

Utopische Strömungen sind jedoch im Christentum durchaus vorhanden, etwa der Millenarismus oder die Dominionisten. Zu allen Zeiten der Kirchengeschichte gab es Gruppen in und außerhalb der Kirche, die utopische Ziele verfolgten, etwa die Taboriten oder die Täufer in Münster. Vor allem auch im Islam gibt es vergleichbare Strömungen, die einen ganz realen "Gottesstaat" (Theokratie) errichten wollen, der stark utopische Züge trägt (siehe auch: Iran, Islamische Revolution).

In wissenschaftlich-technischen Utopien werden dank technischen Fortschritts nicht nur die menschlichen Lebensbedingungen, sondern auch die Menschen selbst manipulierbar. So sollen Krankheit, Hunger und Tod durch technische Mittel besiegt und das Wesen des Menschen gezielt verändert werden (s. Transhumanismus).

In der wissenschaftlichen Welt erhofft man sich aus den Utopien oft auch eine „Theorie für Alles“ sowie die Möglichkeit, metaphysische Entitäten wie Leben oder Bewusstsein zu verstehen, zu beschreiben und nachzubilden (vgl. künstliche Intelligenz).

Hilmar Schmundt gibt in seinem Buch „Hightechmärchen“ unter anderem folgende Beispiele für wissenschaftlich-technische Utopien:


Utopie ist „Denken nach Vorn“ (Ernst Bloch) als „die Kritik dessen, was ist, und die Darstellung dessen, was sein soll“ (Max Horkheimer). Inwieweit Utopie jedoch als „Konkrete Utopie“ (Ernst Bloch) ausgestaltet werden kann, ist bereits seit dem „Bilderverbot“ von Georg Lukács 1916 strittig. „Jeder Versuch, das Utopische als seiend zu gestalten, endet nur formzerstörend“ 

Quasi als Antithese zu dieser Aussage zeigt Bloch im "Prinzip Hoffnung" das „Fragmentarische“, den „Utopischen Bildrest in der Verwirklichung“ quer durch die Philosophie-, Literatur- und Kunstgeschichte auf und wendet sich gegen die „abgerundete Befriedigung“ und „Immanenz ohne sprengenden Sprung“ des scheinbar Vollendeten, verweist beständig auf das „Noch Nicht“, das im „Nicht“ enthalten ist. Bereits in der„Grundlegung“ seines Hauptwerks setzt er als konstituierendes Moment des Utopischen den Tagtraum als „bewußt gestaltende, umgestaltende Phantasie“ dem „unterbewußte(n) Chaos“ des Nachttraums entgegen und das Utopische in den Gegensatz zum Mythischen, in dem er gleichwohl stets wieder das Unerledigte aufzeigt, das es noch zu verwirklichen gilt mit dem dialektischen Ziel der „Naturalisierung des Menschen, Humanisierung der Natur“

Die Utopie wurzelt im Mythos. Anders als dieser ist sie jedoch nicht vorbewusste kollektive Erzählung, sondern bewusste individuelle Schöpfung. Dies zeigt schon ihre Etymologie. Der 1516 erstmals öffentlich gewordene Begriff des Renaissance-Humanisten und späteren Schatzkanzlers Heinrich VIII. Thomas Morus ist ein gelehrtes Wortspiel : außer „ou-topos“, dem „Nirgendort“, bezieht sich der Namensgeber auch auf „eu-topos“, den „schönen Ort“, und beides ist als „Utopia“ in der englischen Aussprache phonetisch nicht unterscheidbar. Utopie verweist so bereits seit und mit ihrer Namensgebung auf das Mögliche und die Alternative zum Bestehenden, auch und gerade als gesellschaftliche Alternative. „Mit der Utopie Mores beginnt der moderne Sozialismus“ (Karl Kautsky).

Trotz ihrer literarischen Tradition ist die Utopie keine literarische Gattung, „eine linguistische Textsortenbestimmung (…) ist nicht möglich“ Utopie ist vielmehr auch als literarische untrennbar mit der utopischen Denkform verbunden, sie entwirft „Gegenbilder zur jeweils bestehenden Realität“

Ernst Bloch hat mit seinem „Prinzip Hoffnung“ eine Art „Geschichte der Utopie“ geschrieben, philosophiegeschichtlich ausgehend vom „dynamei on“, dem „der Möglichkeit nach Seienden“ des Aristoteles mit Utopie als „Vor-Schein“, der schon bei Immanuel Kant als „ästhetischer Schein“ abgegrenzt ist vom „transzendentalen Schein“ des subjektiven Trugschlußes. Blochs Utopiebegriff des „Noch Nicht“ fußt wesentlich auch auf der Aussage von Marx, dass in der Welt schon längst der Traum einer Sache gegenwärtig ist, die sie sich nur noch ins Bewusstsein rufen müsse, um sie wirklich zu besitzen. Die Abgrenzung der Utopie vom nur Utopistischen bedingt somit ein Verständnis der Welt als einer im Werden begriffenen, als offene, noch nicht zu Ende gebrachte und gedachte, mit Tendenz der Geschichte und Latenz des Horizonts („Der Mensch ist immer ein Lernender, die Welt ist ein Versuch, und der Mensch hat ihr zu leuchten“).

Der Entwurf einer besseren Welt („Wohlan, sprach ich, lasst uns also in Gedanken eine Stadt von Anfang an gründen“) in der „Politeia“ (2. Buch, XI) und die detaillierte Schilderung des sagenhaften Atlantis mit dem zentralen Tempel des Poseidon, der Burg mit silbernen Mauern und goldenen Zinnen und den die Stadt konzentrisch durchziehenden Kanälen im „Kritias“ (113b-121a) durch Platon sind, als zwei Idealbilder der „polis“, die wohl wichtigsten Wurzeln der Utopie. 

Platons "Staat," der weder Gelderwerb sucht noch Handel treibt und dessen Oberschicht maximal das vierfache der „Unterschicht“ besitzt, steht zwar konträr zur bestehenden Gesellschaft der Zeit, ist aber durch seine strenge Hierarchie mit exakt 5040 Gemeinwesen aus Herrschern, Wächtern und Arbeitern, einem Reiseverbot für unter 40-Jährige und der Begrenzung der Kunst auf das Lob des bestehenden Staates nicht auf das subjektive Wohlbefinden seiner Einwohner, sondern unbedingt auf das Funktionieren des Gemeinwesens als bestem Staat ausgerichtet. 

Seine Polygamie dient allein der Eugenik, die Sklavenhaltung ist nicht abgeschafft. Atlantis wiederum wird lediglich architektonisch geschildert, wobei allerdings „mit der idealen Stadtarchitektur (…) auch eine ideale Gemeinschaft“ intendiert sein dürfte, so auch in der „Politika“ des Aristoteles mit der Überlieferung der architektonischen Ordnung des Hippodamus, die weiterwirkte bis zu den Plänen der italienischen Architekten der Renaissance.

Konträr zum platonischen Staat steht die Sonneninsel des Jambulos im 3. Jahrhundert v. Chr. als „anarchistisch-egalitäres Schlaraffenland“, das „die Institution der Sklaverei nicht kennt“ auf den sich – vermittelt durch die Diodor-Überlieferung – noch Lukian mit den "Wahren Geschichten" und der "Reise zum Mond" im 2. nachchristlichen Jahrhundert ausdrücklich bezieht. Bezeichnenderweise sind es in Zeiten der römischen Weltherrschaft die Hellenen aus den Kolonien, die ihre fiktiven Reisen in eine bessere Welt als Satire des Bestehenden schildern, während die Römer selbst eher das „beatus ille“ des Horaz und die bukolische Idylle als Wunschbild bevorzugen.

Aus dem christlichen Mittelalter sind eine Reihe auch architektonischer Schilderungen des Himmlischen Jerusalems vom 9. bis 12. Jahrhundert erhalten, mit zentralem Tempel und Gold- und Silbermauern analog zu Atlantis, aber auch die ideale Mönchsrepublik des Tausendjährigen Reichs des Joachim di Fiore, deren Chiliasmus weiterwirkt über die Täufer der Lutherzeit bis hin zu dem Sonnenstaat von Tommaso Campanella. Heimkehrende Kreuzritter mischten schließlich in ihren Erzählungen das heilige Jerusalem mit den Märchenstädten des Morgenlandes wie in der Chronik des Herzog Ernst aus dem 13. Jahrhundert, die über das ferne Grippia berichtet, mit einer Stadtmauer aus Marmor und goldgedeckten Palästen – ähnlich der Messingstadt aus tausendundeiner Nacht.

Die italienische Renaissance mit ihren griechischen Quellen bereitet dann den Boden für die erste Utopie, die diesen Namen trägt, und es sind ihre Architekten, allen voran Leon Battista Alberti (De re sedificatoria, 1451) und Fioreti mit seinen Plänen für Sforzinda (1464), das sich stark an Atlantis orientiert, die mit der idealen Stadt auch die ideale Gesellschaft schaffen wollen.

Zu Beginn der Neuzeit bekommt die Utopie dann Namen und Programm. 1516, ein Jahr bevor Luther seine Thesen an die Kirchentür zu Wittenberg schlägt und Magellan zur ersten Weltumseglung aufbricht, erscheint die "Utopia" des Thomas Morus als fiktiver Reisebericht über eine Insel, deren Hauptstadt Amaurotum (Nebelstadt) ersichtlich auf London weist. So ist Utopia einerseits „Phantasieland, zugleich aber verschlüsste(s) Reformprogramm“ Die Errungenschaften der Utopier, Abschaffung des Privateigentums, sechs Stunden tägliche Arbeit, Zusammenschluss von jeweils 30 Familien zu einem Familienverband, Wahl der Beamten auf ein Jahr, Toleranz in Glaubensfragen, werden hier der Realität der englischen Gesellschaft gegenübergestellt. Ausdrücklichen Bezug auf Utopia nimmt der französische Renaissance-Humanist Rabelais 1534 in seinem "Gargantua" mit der Schilderung der Abtei Thélemè, wo ohne die üblichen Gelübde junge Männer und Frauen nach dem Motto „Fais ce que vouldras“(Macht, was ihr wollt) zusammenleben. Diese „anarchistische Luxuskommune“ erhebt jedoch keinerlei Anspruch, als allgemeines Vorbild zu dienen.

Die Reihe der dann im 19. Jahrhundert als solche etikettierten „Staatsromane“ der Renaissance (etwa bei Robert von Mohl 1855) setzt der kalabresische Mönch und Humanist Campanella 1604 in neapolitanischer Festungshaft fort, nachdem er der Verschwörung gegen die spanische Herrschaft in Süditalien angeklagt war. Campanellas "Città del Sole," identifizierbar auf Tapobrane, also Sri Lanka gelegen, wird regiert durch den Metaphysikus Sol und determiniert durch den Lauf der Gestirne, von der Gattenwahl bis zur Einnahme der Mahlzeiten. Die Siebenzahl der Planeten bestimmt auch den architektonischen Aufbau der Sonnenstadt, die Platons Staat weit näher steht als Morus’ Utopia, wenn Campanella sich auch des Öfteren auf Morus bezieht. Die dritte der „klassischen“ Utopien, das „Nova Atlantis“ des Francis Bacon erscheint 1627, an der Schwelle zum Barock. Auch Francis Bacon, Lordkanzler unter Jakob I. und bis heute bekannt durch sein Diktum „Wissen ist Macht“ sieht sich in der Nachfolge von Morus und beabsichtigt, ein Buch „über die beste Staatsverfassung“ zu schreiben. Geschildert wird die Insel Bensalem im Indischen Ozean, und Zentrum der Gemeinschaft ist das Haus Salomon. Es ist die Wissenschaft, die hier herrscht, aber wiederum durch eine kleine Elite dem Volk nähergebracht wird.

Ausdrücklich auf Morus bezieht sich auch Johann Valentin Andreaes "Christianopolis" von 1619 nach den Idealen der Rosenkreuzer mit einer Stadt ohne Hunger, Armut und Krankheit mit Allgemeinbesitz und materieller Gleichheit. jedoch ist dem schwäbischen Pfarrer Andreae das Leben vor allem Gottesdienst.

Nach dem Humanismus der Renaissance herrscht in und nach den Wirren des Dreißigjährigen Krieges und des folgenden Englischen Bürgerkriegs im Barock generell eine Dürrezeit für das utopische Denken, und wenn es in Erscheinung tritt, ist es in der Regel gottgefällig. 1648 erscheint Samuel Gotts "Nova Solyma" (mit dem bezeichnenden Untertitel „Jerusalem regained“), das häufig auch John Milton zugeschrieben wird, mit der Schilderung eines in Israel errichteten „Gottesstaats“. Ein erstes Glimmen der Frühaufklärung zeigt sich 1656 durch James Harringtons "Oceana". In der direkten Auseinandersetzung mit Thomas Hobbes’ absolutischem Souveränitskonzept im "Leviathan" (1651) wird hier ein ausgearbeiteter Vertragsentwurf mit Repräsentation, Ämterrotation und Zweikammersystem erstellt, der später über John Adams in wesentlichen Teilen Aufnahme in die Verfassung der Vereinigten Staaten fand. Aber erst auf der Basis der Philosophie John Lockes und nach der Glorious Revolution von 1688 fasst das Utopische in der Aufklärung des 18. Jahrhunderts wieder Fuß, wobei es meist ins Satirische spielt wie bei den Yahoos in Jonathan Swifts "Gullivers Reisen" von 1726 oder im El Dorado in Voltaires "Candide" 1759, wo die Kinder mit Edelsteinen spielen, das Essen kostenlos ist und Theologen unbekannt sind. Wie stark das Utopische aber auch hier an seine Zeit gebunden bleibt, zeigt noch 1770 Merciers „L’an 2440“ in dem Gewaltenteilung und Föderalismus herrschen – allerdings unter Ludwig XXXIV.

Im 19. Jahrhundert werden die Utopien dann als Sozialutopie zum konkreten Projekt, und die Autoren arbeiten an der Umsetzung ihrer Pläne in die Wirklichkeit; Fouriers nach den Leidenschaften ihrer Bewohner geordnete Gesellschaft, in der der Pyromane zum idealen Feuerwehrmann wird, mit ihren „Phalensteres“ ("Theorie des quattre mouvements," 1808) blieb jedoch ein Traum und Fourier wartete sein Leben lang vergeblich auf einen Sponsor, durch den er seine Pläne in die Realität hätte umsetzen können. Auch Robert Owens "New Harmony" ohne Ehe, Religion und Privateigentum, zugrundegelegt 1820 in "The Social System" war in der Wirklichkeit nicht überlebensfähig, das Projekt ruinierte Owen innerhalb von drei Jahren. 1842 erscheint Étienne Cabets "Reise nach Ikarien" als kommunistisches Idealbild., Wie Owen wollte auch Cabet sein Projekt in Amerika realisieren, wobei er ebenfalls nach kurzer Zeit scheiterte. Die Theorien von Karl Marx sind dann das „Blei in den Flügelschuhen“ (Bloch) der Utopie und nach Friedrich Engels „Entwicklung des Sozialismus von der Utopie zur Wissenschaft“ von 1880 ist kein utopischer Systementwurf mehr entstanden, der die Wirklichkeit zu transzendieren suchte, zumal nun auch die letzten weißen Flecken von der Weltkarte verschwunden waren und die Utopie vom Raum in die Zeit wandert.

Edward Bellamys "Looking Backward 2000–1887" zeigt eine technische Zukunftsutopie „industrieller Republiken“, während praktisch gleichzeitig 1890 William Morris in "News from Nowhere" ein London imaginiert, in dem der Protagonist nach 40-jährigem Schlaf erlebt, dass die Industrie wieder abgeschafft wurde, die Stadtteile sind wieder zu Dörfern geworden, die Eisenbrücken durch Holzbrücken ersetzt.

Die philosophische Reflexion über den Utopiebegriff erfolgte in Anfängen nach dem Ersten Weltkrieg erstmals durch Ernst Blochs "Geist der Utopie" 1918 und verstärkt ab ca. 1930 dann auch durch Walter Benjamin, Theodor W. Adorno, Max Horkheimer und Herbert Marcuse. Zentral bleibt der philosophische Utopie-Begriff jedoch mit Bloch vor allem auf der Basis des "Prinzip Hoffnung" (1954–1959) verbunden.
Eine systematische Fortführung der Philosophie Blochs steht bis heute aus. So wird nach Bloch die Weiterentwicklung der Begrifflichkeit des Utopischen auch theoretisch im Wesentlichen von den Literaten vorangetrieben, in vorderster Front von Lars Gustafsson („Charakteristisch für eine Utopie ist, dass sie eine systemtranszendente Kritik impliziert“) und Italo Calvino („É sempre il luogo qui mette in crisi l'utopia“). Calvino sieht die Utopie von heute als „polverizzata“ und lässt Marco Polo in den letzten Zeilen der „Unsichtbaren Städte“ resumieren, man müsse „suchen und zu erkennen wissen, wer und was inmitteln der Hölle nicht Hölle ist und ihm Bestand und Raum geben“

Auch die literarische Utopie im 20. Jahrhundert, jenseits des Pessimismus der Dystopie von George Orwells "1984" und Aldous Huxleys "Schöner neuer Welt" - führt nur noch ein Nischendasein. Robert Musils Protagonist Ulrich im "Mann ohne Eigenschaften" von 1930 reflektiert zwar über das Utopische, will sein Leben jedoch als individuelle Utopie ohne notwendige Veränderung der Gemeinschaft gestalten. Utopische Aspekte erscheinen in der zweiten Hälfte des 20. Jahrhunderts am offensichtlichsten – vor allem mit den „verborgenen Städten“ - in den bereits oben genannten „Citta invisibili“ Italo Calvinos von 1972. Als „grüne“ Utopie erscheint 1975 "Ökotopia" von Ernest Callenbach, wobei eine Reihe der dort geschilderten ökologischen Aspekte in der Zwischenzeit verwirklicht wurden, soziale und politische Zustände mit Präsidentin, Ministern und Staatssekretären sowie beibehaltener Geldwirtschaft samt (immerhin begrenzter)Verdienstunterschiede und Privatschulen (ohne öffentliche Konkurrenz) jedoch im Systemimmanenten verbleiben oder gar den herrschenden US-Wirtschaftsliberalismus noch verstärken. Steuern existieren nach wie vor – allerdings lediglich als Grundstückssteuer.

Wie zum Beleg von Calvinos These bleiben im Bereich der Philosophie das utopische Denken und die Nachwirkung Blochs im Wortsinne sporadisch. So hat Jean-François Lyotard in "Macht der Spuren" (Berlin 1977) Blochs erstmals 1930 in den „Spuren“ erläuterte Methodik zur Entdeckung utopischer Momente gewürdigt, ohne jedoch auf die Systematik des Blochschen Denkens Bezug zu nehmen. Stärker zeigt sich das Erbe Blochs bei Alexander Kluge, wenn dieser auf die Frage „Was tun?“ in einem Spiegel-Interview zu seinem 80. Geburtstag antwortet: „Im Konjunktiv denken, im Licht der Geschichte und der Zukunft nach Optionen, Möglichkeiten suchen.“







</doc>
<doc id="10750" url="https://de.wikipedia.org/wiki?curid=10750" title="Hammurapi I. (Babylon)">
Hammurapi I. (Babylon)

Hammurapi (auch: "Hammurabi" oder mit "Ḫ" geschrieben) war gemäß mittlerer Chronologie von 1792 bis zu seinem Tode 1750 v. Chr. der 6. König der ersten Dynastie von Babylonien und trug den Titel "König von Sumer und Akkad".

Quellen für die Regierungszeit Hammurapis sind die Jahresformeln, die einzelne Ereignisse bestimmten Regierungsjahren Hammurapis zuordnen. Weiterhin stellen in Mari und Larsa aufgefundene Briefe wichtige Quellen für die politischen Hintergründe der Zeit dar. Die Anzahl dieser Briefe geht in die Hunderte, oft verfasst von der Kanzlei Hammurapis, insbesondere von einem wahrscheinlich hohen Funktionär namens Awel-Ninurta. Empfänger der Briefe waren neben fremden Herrschern auch Beamte Hammurapis, wobei sich besonders viele an Personen (Sin-iddinam, Šamaš-hasir) im südmesopotamischen Raum gerichtete Briefe aufgefunden haben.

Hammurapi war der sechste Herrscher von Babylon und wurde 1792 v. Chr. Nachfolger seines Vaters Sin-muballit. Bereits Hammurapis unmittelbare Vorgänger konnten das Herrschaftsgebiet des Stadtstaates ausdehnen, sodass Borsippa, Kiš, Dilbat, Kazallu, Marad und Sippar den Babyloniern unterstanden. Dennoch war Babylon zu Beginn von Hammurapis Amtszeit ein Staat neben einer Reihe anderer in Mesopotamien; wichtige weitere Stadtstaaten waren Larsa, Ešnunna und Elam im Süden und Osten, sowie Mari und Assyrien im Norden. In Syrien nahm das Reich von Jamchad, im Bündnis mit Mari, eine Machtposition ein.

Hammurapi hat zu Beginn seiner Regierungszeit möglicherweise in einem Abhängigkeitsverhältnis zum assyrischen König Šamši-Adad I. gestanden. Dies wird aus einer im zehnten Regierungsjahr Hammurapis ausgestellten Urkunde geschlossen, in der der Eid neben Hammurapi selbst auch bei Šamši-Adad I. beschworen wird. Zeugnis für enge Kontakte zwischen Hammurapi und Šamši-Adad in dieser Zeit sind in Mari, damals beherrscht von Šamši-Adads Sohn Jasmaḫ-Addu, aufgefundene Briefe. Als Konsequenz hieraus wird bezweifelt, dass die Feldzüge Hammurapis etwa im ersten Drittel seiner Regierungszeit eigenständige Unternehmungen waren und nicht unter dem Oberbefehl bzw. auf Anweisung Šamši-Adads erfolgten. Weiterhin würden die Feldzüge ohne Unterstützung aus Assur ein zu großes Wagnis dargestellt haben. So errang Hammurapi in seinem siebten Regierungsjahr einen Sieg über Uruk und Isin, in seinem achten fand eine militärische Unternehmung nach Emutbal statt, die teils als gegen Rim-Sin I. von Larsa gerichtet, teils auch als mit diesem gegen Unruhestifter gemeinsam erfolgte Aktion interpretiert wird. Im zehnten Regierungsjahr unterwarf Hammurapi Malgum und im elften Rapiqum und Schalibi, Ortschaften, die dem Machtbereich Ešnunnas angehörten.

Nach Šamši-Adads Tod im 17. Regierungsjahr Hammurapis schwand der Einfluss Assurs in Mesopotamien und auch Hammurapi scheint nicht länger unter dessen Oberhoheit gestanden zu haben. Gleichwohl zeugt ein Brief von Šamši-Adads Sohn Išme-Dagan I. für weiterhin gute Beziehungen zwischen beiden Staaten. Für diese Jahre nennen die Jahresformeln die Anschaffung religiöser Objekte und Maßnahmen, die auf den Ausbau der Infrastruktur zielten. Auch darf mit einem Anstieg des Wohlstands und der Einwohnerschaft Babylons gerechnet werden.

In der folgenden Zeit entwickelte sich ein enges Verhältnis zwischen Hammurapi und Zimri-Lim von Mari, der den dort regierenden Sohn Šamši-Adads gestürzt hatte und Schwiegersohn des Königs von Jamschad war. Oft wird auch ein "Dreierbund" Babylon-Mari-Jamschad genannt. In den folgenden zwei Jahrzehnten stellten sich Hammurapi und Zimri-Lim untereinander mehrmals Truppen zur Verfügung, die von Zimri-Lim teilweise in Jamschad angeworben wurden und deren Zahl in die zehntausende ging. Mehrere Hinweise auf Verzögerungen von Truppenlieferungen seitens Hammurapis werden so gedeutet, dass dieser den größeren Nutzen aus dem Bündnis gezogen habe. Eingesetzt wurden diese Truppen im Falle Hammurapis wohl zum Kampf gegen Ešnunna, Elam und Larsa.

Hammurapi verfügte, wie auch Zimri-Lim in Babylon, über ein ausgeklügeltes Netz von Botschaftern und Agenten in allen wichtigen Stadtstaaten. So stand Hammurapi in Briefkontakt mit Buqaqum und Bachdi-Lim, hohen Beamten in Mari, die ihm Informationen über militärische Aktionen Maris lieferten und, zumindest im Falle Bachdi-Lims, auch als seine Gesandten fungierten.

Etwa 1763 v. Chr., im 30. Regierungsjahr Hammurapis, drängten die Elamiter unter ihrem König Siwe-Palar-Khuppak von Osten in die mesopotamische Ebene und bedrängten die Stadt Larsa unter Rim-Sin I. Diese Situation nutzte Hammurapi, um sich zunächst mit Larsa zu verbünden und gemeinsam die Elamiter zu vertreiben. Im selben Jahr siegte Hammurapi noch über Heere Ešnunnas, der Gutäer, der Stadt Malgum und Assurs.

Im gleichen Jahr brachen auch Feindseligkeiten zwischen Hammurapi und Rim-Sin von Larsa aus. Laut einem Brief eines Gesandten Zimri-Lims in Babylon war zuvor ein Bündnis Rim-Sins mit Hammurapi geplant, in dem gegenseitiger Schutz bei Angriffen eines nicht namentlich genannten Feindes zugesichert worden wäre. Die Initiative zu dieser Abmachung sei von Rim-Sin in einem Brief an Hammurapi ausgegangen. Ein endgültiger Abschluss dieses Vertrages ist nicht bekannt.

In einem ebenfalls aus Mari stammenden Brief werden Übergriffe von Untertanen Rim-Sins auf dem Gebiet Hammurapis erwähnt, welche dieser als Begründung des Krieges gegen Rim-Sin anführen konnte. Gemeinsam mit Truppen aus Mari belagerten und eroberten die Babylonier Rim-Sins Residenz Maschkanschapir. Larsa selbst soll von 40.000 Soldaten verteidigt worden sein. Aus diesem Grund soll Hammurapi weitere Truppen ausgehoben haben. Larsa selbst wurde noch im selben Jahr eingenommen, aber nicht zerstört, sondern zum Zentrum eines Verwaltungsbezirks ausgebaut.

In seinem 32. Regierungsjahr fanden siegreiche Kämpfe Hammurapis gegen Assur, Ešnunna und die Gutäer statt, wodurch Hammurapi seinen Einflussbereich nach Norden erweitern konnte.

In seinem 33. Regierungsjahr eroberte Hammurapi, neben in den Jahresformeln genannten Kanalausbesserungen wegen Zerstörungen während der Kämpfe gegen Larsa, die früher verbündete Stadt Mari. Texte aus Mari, in denen Weissagungen gegen Hammurapi erwähnt werden, zeigen, dass man die Machtsteigerung Babylons durchaus als Bedrohung empfand. Außerdem wurden Malgum erneut und einige assyrische Städte erobert. Beide Städte rebellierten jedoch gegen Hammurapi und wurden in dessen 35. Regierungsjahr endgültig besiegt, wobei in Mari möglicherweise Zerstörungen vorkamen, deren Umfang nicht bestimmbar ist.

Nachdem er in einem nicht datierten Brief Zimri-Lims von diesem gebeten worden war, den Thron Ešnunnas zu besteigen, eroberte Hammurapi dieses in seinem 38. Regierungsjahr. Möglicherweise hatte er es vorher mittels der Errichtung künstlicher Dammbauten überschwemmt.

In seinem letzten Regierungsjahrzehnt führte Hammurapi Kriege gegen die Assyrer. Im Prolog des "Codex Hammurapi" werden Assur und Ninive als dem Herrschaftsbereich Hammurapis eingegliederte Städte genannt. Andere Belege hierfür fehlen aber. In Diyarbakır wurde allerdings eine Stele des Hammurapi gefunden, die als Zeichen für ein weites Vordringen am Tigris gedeutet werden kann.

Hammurapis Herrschaftsgebiet erstreckte sich nunmehr vom Persischen Golf und dem Zagros-Gebirge bis zum Euphratbogen. Seinem Reich war aber keine lange Lebensdauer vergönnt. Schon während der Regierungszeit seines Sohnes Šamšu-iluna kam es zu Unruhen in Südmesopotamien, und an den Grenzen erschien ein neues Volk, die Kassiten. Aus westlicher Richtung drangen fast gleichzeitig die Hethiter vor, die sich aber nach der Eroberung Babylons durch Muršili I. wieder zurückzogen. Die Kassiten lösten schließlich die Hammurapi-Dynastie ab. Damit endete die altbabylonische Epoche in Mesopotamien.

→"siehe auch Hauptartikel: Codex Hammurapi"

Berühmt geworden ist Hammurapi jedoch durch die älteste vollständig erhaltene Rechtssammlung, den Codex Hammurapi. Dieser umfasste einen Prolog, die 282 Gesetzesparagraphen und den Epilog. Aufgezeichnet wurde er unter anderem auf einer ca. 2,25 m hohen Stele (ein freistehender Pfeiler) aus Diorit.

Eine Stele mit dem Text des Codex wurde 1902 bei Ausgrabungen in Susa gefunden. Ihr ursprünglicher Standort ist unbekannt, vermutlich wurde sie von einem Eroberer aus einer babylonischen Stadt geraubt. Die Stele von Susa befindet sich heute im Louvre in Paris.

Hammurapis Rechtssammlung war keineswegs einzigartig. Bereits 300 Jahre zuvor schuf der sumerische König Ur-Nammu ein ähnliches Werk, und etwa 150 Jahre vor Hammurapi ließ Lipit-Ištar, König von Isin, ebenfalls eine Stele beschriften. Beide Werke sind aber nur fragmentarisch erhalten. Hammurapis Schriften wurden dagegen vielfach aufgezeichnet. In der Bibliothek des Aššurbanipal in Ninive hat sich eine Abschrift auf Tontafeln erhalten. Jedoch lassen sich keine Einflüsse auf andere Rechtskreise nachweisen. Die allgemeine Hochschätzung galt nicht dem Recht, sondern dem literarischen Kunstwerk.

Der Name Hammurapi ist ein Kompositum, welches in der Keilschrift durch die Syllabogramme "ḫa-am-mu-ra-bi" wiedergegeben wird. Während es sich bei ḫa-am-mu eindeutig um das amurritische Wort hammu(m) (Vaterbruder) handelt, ermöglicht die Keilschrift zwei Lesarten für den zweiten Namensteil:
Dementsprechend wird sein Name von denjenigen mit „Hammurabi“ transkribiert, die davon ausgehen, dass sich der Name aus einem amurritischen und einem akkadischen Teil zusammensetzt, der insgesamt mit „Großer Onkel“, „Großer Vater“ oder ähnlich zu übersetzen wäre. Diese Lesart hat in der jüngeren Vergangenheit viel Kritik erfahren, da bislang keine Begründung vorgelegt wurde, warum der Name aus zwei Begriffen verschiedener Sprachen komponiert sein sollte. Deshalb transkribieren viele Forscher den Namen heute mit „Hammurapi“, so dass er als „heilender Vater“ oder ähnlich zu übersetzen wäre.

1997 wurde der Asteroid (7207) Hammurabi in der alternativen Transkription nach ihm benannt.


Literarische Bearbeitung


</doc>
<doc id="10752" url="https://de.wikipedia.org/wiki?curid=10752" title="Tibetische Sprache">
Tibetische Sprache

Das Tibetische (Tibetisch: , Wylie: "bod skad") gehört zu den tibeto-birmanischen Sprachen Asiens. Es wird von ca. sechs Millionen Menschen gesprochen, von denen die meisten in Tibet (Volksrepublik China) leben. Daneben gibt es etwa 130.000 Tibeter im Exil, hauptsächlich in Nepal, Indien und Bhutan. Die Sprache wird mit dem tibetischen Alphabet geschrieben, das wahrscheinlich aus einem Typ der altindischen Brahmi-Schrift abgeleitet ist.

Tibetisch ist neben Hochchinesisch Amtssprache im Autonomen Gebiet Tibet und anderen Teilen Chinas mit tibetischer Bevölkerung.

Die Tibeter sind eine der am wenigsten assimilierten Volksgruppen Chinas. 84 % der Tibeter in Tibet kommunizieren vor allem auf Tibetisch.

In der Verfassung der Volksrepublik China von 1982 heißt es:

Im Jahr 1987 erließ die tibetische Regierung „Provisorische Vorschriften des Autonomen Gebietes Tibet über die Lehre, den Gebrauch und die Entwicklung der tibetischen Sprache und Schrift“, 1988 „Detaillierte Durchführungsbestimmungen zu den provisorischen Vorschriften des Autonomen Gebietes Tibet über die Lehre, den Gebrauch und die Entwicklung der tibetischen Sprache und Schrift“ und 2002 schließlich die „Vorschriften des Autonomen Gebietes Tibet über die Lehre, den Gebrauch und die Entwicklung der tibetischen Sprache und Schrift“

Für die Entwicklung und Standardisierung der Sprache ist das staatliche "Komitee für die terminologische Standardisierung des Tibetischen" (, ) zuständig.

Nach den Daten der letzten beiden Volkszählungen lag die Analphabetenrate unter Tibetern im Jahr 1990 bei 69,39 % (gegenüber 22,21 % der Gesamtbevölkerung Chinas); bis zum Jahr 2000 konnte sie um 31,47 % auf 47,55 % (Gesamtbevölkerung: 9,08 %) gesenkt werden.

An 98 % der Grundschulen in Tibet ist die Unterrichtssprache Tibetisch und 92 % der Grundschullehrer sind Tibeter; gleichzeitig wird Chinesisch als Fremdsprache unterrichtet. Im Jahr 2002 gab es 181 Lehrbücher für 16 Unterrichtsgegenstände auf Tibetisch und es wurden zwar acht Glossare naturwissenschaftliche Fachterminologie erstellt, an den Mittelschulen werden jedoch Mathematik, Physik und Chemie generell auf Chinesisch unterrichtet. Die Texte in den Lehrbüchern zur tibetischen Sprache und Literatur ("gaiyig" , ) stammen zu 47 % aus moderner und zeitgenössischer tibetischer Literatur, zu 29 % aus traditioneller tibetischer Literatur und zu 24 % aus Übersetzungen aus dem Chinesischen. An den tibetischen Universitäten und Hochschulen ist die Unterrichtssprache meist Chinesisch, außer in Fächern im Zusammenhang mit tibetischer Geschichte, Sprache und Literatur sowie traditioneller tibetischer Medizin.

Nach den Vorschriften sollen Han-Chinesen in Tibet auch Tibetisch lernen, doch diese Regelung wird heute generell ignoriert.

An den tibetischen Schulen in Indien war die Unterrichtssprache bis 1985 ausschließlich Englisch; heute wird an einigen Grundschulen in den ersten fünf Jahren teilweise auf Tibetisch unterrichtet, ab dem sechsten Schuljahr nur auf Englisch und alle Mittelschullehrbücher sind auf Englisch.

Allein in Tibet selbst erscheinen 14 Zeitschriften und 10 Tageszeitungen auf Tibetisch, dazu kommt eine Handvoll regionaler und nationaler tibetischer Zeitungen und Zeitschriften in anderen Teilen Chinas, es gibt zahlreiche Radio- und Fernsehsender sowie Kinofilme auf Tibetisch (in den Varietäten von Lhasa und der Kamba); neun Verlage in China publizieren regelmäßig Bücher auf Tibetisch, jährlich erscheinen rund tausend Titel; Regierung, Justiz, Verwaltung etc. sowie Straßenschilder und Werbung sind laut Vorschriften zweisprachig.

Vor der Zeit der Volksrepublik China gab es drei verschiedene Formen des Tibetischen: Erstens die in den Klöstern geübte Liturgiesprache ("Chos-shad"), zum zweiten die höfische Sprache, das stark formalisierte "she-sa," heute noch die Sprache der gebildeten Oberklasse Lhasas. Drittens das „Volkstibetisch“ ("Phal-skad"), die Umgangssprache mit zahlreichen aufgrund der Weite des Landes untereinander oft kaum verständlichen Dialekten. Besonders in den oberen Stilebenen werden zahlreiche Ehrentitel verwendet. Wie in vielen asiatischen Sprachen besitzen häufig gebrauchte Wörter unterschiedliche Formen, um hierarchische Unterschiede auszudrücken. All diesen Varianten fehlte ein neuzeitliches Vokabular. Beginnend seit den 1960ern wurde von Sprachwissenschaftlern ein „Neutibetisch“ entwickelt, bei dem sich Schreibung und Aussprache decken und das um zusätzliche Wörter erweitert wurde, so dass z. B. Schulunterricht in Physik, Chemie usw. möglich wurde. Auch die modernen Medien bedienen sich dieser auf Basis des Lhasa-Dialekts entwickelten Variante.

Die modernen tibetischen Dialekte kann man wie folgt einteilen:

Dzongkha, die Amtssprache in Bhutan, steht dem Tibetischen sehr nahe bzw. ist ein Dialekt des Tibetischen. Tibetische Dialekte werden auch in Nepal (Sherpa und Mustang), Indien (Ladakhi) und Pakistan (Baltistan) gesprochen. Die tibetische Exil-Koine basiert auf dem dBus-Dialekt.

Das klassische Tibetisch und die moderne tibetische Schriftsprache unterscheiden sich in ihrer schriftlichen Form phonologisch nicht voneinander.

Es haben sich jedoch verschiedene tibetische Dialekte entwickelt, die untereinander teilweise nicht verständlich sind. Die moderne Schriftsprache ist pan-dialektal, d. h. wird von Sprechern verschiedener Dialekte verwendet.

Einige zentraltibetische Dialekte haben Töne entwickelt, aber weil östliche Dialekte wie Amdo und westliche wie Balti keine phonemischen Töne haben, kann das Tibetische nicht durchgängig als Tonsprache bezeichnet werden.

Die tatsächliche Aussprache des klassischen Tibetisch ist eine Rekonstruktion auf der Grundlage ihrer geschriebenen Form und der modernen tibetischen Dialekte. In der folgenden Darstellung wird neben der tibetischen Schrift die Transkription von Wylie und eine mögliche Rekonstruktion in Internationaler Lautschrift (IPA) angegeben.

Neben den oben angeführten einfachen Anlauten sind auch Konsonantenkombinationen als Silbenanlaute möglich. Traditionell wird nach der Schreibweise unterschieden zwischen Grundanlauten mit darüber-, darunter- und vorangestellten Konsonanten.

Die tibetische Schriftsprache unterscheidet fünf Vokale: "a", "i", "u", "e" und "o".

Am Silbenende kommen folgende einfache Konsonanten (in Wylie-Transkription) vor: "-g", "-ng", "-d", "-n", "-b", "-m", "-’", "-r", "-l" und "-s". Außerdem können noch folgende Konsonantenkombinationen auftreten: "-gs", "-ngs", "-bs" und "-ms".

Als Dialekt der Hauptstadt der Autonomen Region Tibets und des Großteils der tibetischen Exilgemeinde kommt dem Lhasa-Dialekt eine besondere Rolle zu. In der folgenden Darstellung wird das Lautinventar des Lhasa-Dialekts in Internationaler Lautschrift und der offiziellen Transkription in China (die auf der chinesischen Pinyin-Umschrift beruht) beschrieben, außerdem sind die schriftsprachlichen Entsprechungen in Wylie-Transkription angeführt.

Der Lhasa-Dialekt hat vier Töne. Für die Angabe in IPA wird hier der Vokal "a" verwendet. Bei der Angabe in Ziffern bezeichnet "1" die niedrigste Tonhöhe, "5" die höchste.

Das Register wird durch den Silbenanlaut bestimmt (s.u.). Die Konsonanten *"g", *"gs", *"b", *"bs", *"d", *"s", *"ngs" und *"ms" am Silbenende der geschriebenen Formen bewirken, dass eine Silbe im Hochton fallend () bzw. dass eine Silbe im Tiefton steigend () ausgesprochen wird.

Die pränasalisierten Anlaute () werden nicht von allen Sprechern bzw. nicht in allen Kontexten pränasalisiert ausgesprochen.

Der Ton einer Silbe hängt vom Anlautkonsonanten ab. Zur Veranschaulichung sind in der Tabelle die Anlaute in Lautschrift jeweils mit dem Vokal a und einem Tonzeichen für das jeweilige Register (hoch oder tief) versehen.

Im Lhasa-Dialekt gibt es 17 Vokale: und . Diese bilden mit den Konsonanten folgende Silbenauslaute:

Auslautendes "-r" fällt häufig aus und führt nur zur Längung des Vokals. Auslautendes "-n" der geschriebenen Formen führt meist zur Nasalisierung des vorhergehenden Vokals.

In zwei- und mehrsilbigen Wörtern kommt es darüber hinaus zu einigen lautlichen Veränderungen. (In den folgenden Beispielen ist der schriftlichen Form in Wylie-Transliteration ein Stern vorangesetzt, darauf folgt die Aussprache in IPA in eckigen Klammern und die offizielle Transkription in runden Klammern.)



Wenn *"bu" die zweite Silbe ist, wird es [] gesprochen.
Wenn *"ba" oder *"bo" die zweite Silbe ist, werden sie [] (wa) bzw. [] (wo) gesprochen.








Tibetisch gehört zu den Ergativsprachen und ist flektierend.

Wie im Chinesischen werden abstrakte Substantive gerne durch Zusammenstellung von gegensätzlichen Adjektiven gebildet. Beispiel: "tsha-grang" wörtlich „heiß-kalt“, d. h. „Temperatur“.

In der klassischen Schriftsprache werden neun Fälle mit Suffixen markiert, die in der modernen Schriftsprache weitgehend erhalten sind:


Es gibt mehrere Pluralsuffixe ("-rnams", "-dag"), die jedoch nicht verwendet werden, wenn aus dem Kontext hervorgeht, dass das betreffende Wort im Plural ist.

Die Tibetische Verbalmorphologie beruht sowohl auf Agglutionation - Verben flektieren Person und Numerus was durch Endungen deutlich gemacht wird, unterscheiden hier jedoch nur die erste Person von den beiden restlichen - als auch auf Wurzelflexion - hier wird mit Ton und Ablaut gearbeitet. Jedes Verb hat bis zu vier verschiedene Stämme, die von tibetischen Grammatikern traditionell als Gegenwart "(lda-ta)", Vergangenheit "(’das-pa)", Zukunft "(ma-’ongs-pa)" und Befehlsform "(skul-tshigs)" bezeichnet werden. Die verschiedenen Stämme werden meist durch Ablaut gebildet, z. B. "byed", "byas", "bya", "byos" „machen“. Die genaue Funktion dieser Stammformen ist bis heute umstritten.

Die wenigsten Verben können sämtliche vier Stammformen bilden. Dieser Mangel an zeitlichen Ausdrucksformen wird im modernen Tibetisch durch Hilfsverben oder die Beifügung von Suffixen ausgeglichen.

Die Satzstellung ist grundsätzlich Subjekt-Objekt-Verb. Adjektive stehen nach dem Substantiv. Adverbialbestimmungen stehen vor dem Verb. Nomen im Genitiv stehen vor dem regierenden Substantiv.

Hauptartikel: Tibetische Schrift, Tibetische Literatur

Das tibetische Alphabet soll im 7. Jahrhundert von Thonmi Sambhoṭa geschaffen worden sein. Der Legende nach erfand er nicht nur die tibetische Schrift, sondern auch die Sprache selbst, die er in einem zweibändigen Werk vollständig beschrieben haben soll.




Das erste von einem Europäer zusammengestellte Wörterbuch stammt von den Italienern da Ascoli, da Tours und Domenico da Fano. Es erreichte Europa im Jahr 1714 und ist als unveröffentlichtes Manuskript in der Bibliothèque Nationale in Paris erhalten. Die ersten vier Seiten des Manuskripts befassen sich mit der tibetischen Schrift, während die Seiten 5–41 das Lateinisch-Tibetische Wörterbuch bilden, das folgenden Titel trägt:

Das zweite von Europäern verfasste Wörterbuch (Tibetisch-Italienisch) stammt von Horazio della Penna (1690–1745). Es wurde von F. C. G. Schroeter ins Englische übertragen und ist im Druck erschienen:

Das dritte von einem Europäer verfasste Wörterbuch stammt con Csoma de Körös, der als Begründer der Tibetologie gilt:




</doc>
<doc id="10753" url="https://de.wikipedia.org/wiki?curid=10753" title="Indoarische Sprachen">
Indoarische Sprachen

Die indoarischen Sprachen bilden eine Unterfamilie des indoiranischen Zweigs der indogermanischen Sprachfamilie. Die insgesamt über hundert heute gesprochenen indoarischen Sprachen haben rund eine Milliarde Sprecher vorwiegend in Nord- und Zentralindien, in Pakistan, Bangladesch, Nepal und auf Sri Lanka und den Malediven. Zu den wichtigsten indoarischen Sprachen gehören Hindi-Urdu, Bengali und die klassische Sprache Sanskrit. Auch das von den Roma in Europa gesprochene Romanes zählt zu den indoarischen Sprachen. Mit den vor allem in Südindien gesprochenen dravidischen Sprachen sind die indoarischen Sprachen nicht verwandt, doch haben sie durch jahrtausendelangen Sprachkontakt zahlreiche gemeinsame Merkmale entwickelt.
Die indoarischen Sprachen bilden einen Unterzweig der indogermanischen Sprachfamilie, zu der auch die Mehrzahl der in Europa gesprochenen Sprachen gehört. Andere Zweige der indogermanischen Sprachfamilie sind etwa das Griechische, die romanischen, slawischen oder germanischen Sprachen. Somit sind die indoarischen Sprachen – wenn auch entfernte – Verwandte des Deutschen. Spuren dieser Verwandtschaft lassen sich bei den modernen Sprachen nur noch an einigen wenigen Wörtern auf den ersten Blick erkennen: So lautet das bengalische Wort für „Name“ "nām", das Hindi-Wort für „neu“ ist "nayā" und die „Kuh“ heißt auf Marathi "gau". In anderen Fällen wie Englisch "wheel" und Nepali "cakkā" (beides bedeutet „Rad“) ist der gemeinsame Ursprung, wenngleich vorhanden, nur durch komplizierte Etymologien nachvollziehbar. Für einen Großteil des Wortschatzes und insbesondere der Grammatik der modernen indoarischen Sprachen lässt sich indes gar keine Entsprechung in den heutigen europäischen Sprachen finden. Zwischen im Altertum gesprochenen Sprachen wie dem Sanskrit und dem Lateinischen oder Altgriechischen sind die Übereinstimmungen hingegen weitaus größer, sowohl was den Wortschatz als auch die Morphologie angeht. Man vergleiche hierzu Formen wie Sanskrit "dantam" und Latein "dentem" „den Zahn“ oder Sanskrit "abharan" und Altgriechisch "epheron" „sie trugen“.

Die Erkenntnis der Verwandtschaft des Sanskrit mit den Sprachen Europas war maßgeblich für die Entwicklung der vergleichenden Sprachwissenschaft. Der Engländer William Jones hatte während seiner Richtertätigkeit in Kolkata (Kalkutta) Sanskrit gelernt und postulierte 1786 als erster die Verwandtschaft des Sanskrit mit dem Griechischen, Lateinischen, Gotischen und Keltischen. Auf dieser Grundlage begründete der deutsche Sprachwissenschaftler Franz Bopp (1791–1867) die historisch-vergleichende Disziplin der Indogermanistik. Dass die modernen indoarischen Sprachen mit Sanskrit verwandt sind, erkannte man erst später, schoss nun aber gewissermaßen über das Ziel hinaus und hielt auch die dravidischen Sprachen für Abkömmlinge des Sanskrit. Erst Robert Caldwell erkannte 1856 die Eigenständigkeit der dravidischen Sprachfamilie.

Innerhalb der indogermanischen Sprachfamilie stehen die indoarischen Sprachen den iranischen Sprachen, zu denen unter anderem Persisch (Farsi), Kurdisch und Paschtunisch gehören, nahe, welche von einigen Linguisten auch als iranoarische Sprachen bezeichnet werden. Auch hier zeigt sich die Verwandtschaft bei den ältesten Sprachformen am deutlichsten: Im Altpersischen, der Sprache der achämenidischen Großkönige, und dem Sanskrit sind viele Wörter wie "daiva" und "deva" „Gott“, "būmi" und "bhūmi" „Erde“ oder "aspa" und "aśva" „Pferd“ nahezu formengleich, während die modernen Sprachen sich auseinanderentwickelt haben. Man fasst die indoarischen und iranischen Sprachen unter dem Zweig der indoiranischen Sprachen zusammen. Zu diesen gehört außerdem als separater Unterzweig noch die zahlenmäßig kleine Gruppe der in Afghanistan und Pakistan gesprochenen Nuristani-Sprachen. Die Stellung der ebenfalls im äußersten Nordwesten des Subkontinents verbreiteten dardischen Sprachen innerhalb des Indoiranischen ist unsicher. Während man sie früher entweder mit den Nuristani-Sprachen zusammenfasste oder als eigenständigen Zweig ansah, hält man sie heute für eine Untergruppe der indoarischen Sprachen.

Die indoarischen Sprachen teilen sich den indischen Subkontinent mit drei anderen Sprachfamilien: den hauptsächlich in Südindien verbreiteten dravidischen Sprachen (deren wichtigste Vertreter Tamil, Malayalam, Telugu und Kannada sind), der kleineren Gruppe der in Mittelindien verstreuten Munda-Sprachen (einem Zweig der austroasiatischen Sprachen) und den tibeto-birmanischen Sprachen (einem Zweig der sinotibetischen Sprachen) am Nord- und Ostrand des Subkontinents. Mit diesen Sprachfamilien sind die indoarischen Sprachen nicht genetisch verwandt, doch haben sie sich durch jahrtausendelangen Sprachkontakt in Wortschatz, Morphologie und Phonetik (besonders charakteristisch etwa das Vorhandensein von retroflexen Konsonanten) gegenseitig stark beeinflusst. Aufgrund der zahlreichen gemeinsamen Merkmale kann man diese Sprachen zu einem südasiatischen Sprachbund zusammenfassen. Vor allem die Wechselwirkung zwischen den indoarischen und dravidischen Sprachen ist beachtlich gewesen, wobei die dravidischen Sprachen in großem Maße Wörter aus dem Sanskrit übernommen haben, während sie selbst einen starken strukturellen Einfluss auf die Phonetik und Syntax der indoarischen Sprachen ausgeübt haben.

Die indoarischen Sprachen können auf eine Sprachgeschichte von fast vier Jahrtausenden zurückblicken. Man teilt sie in drei historische Stufen ein: altindoarisch (Vedisch, klassisches Sanskrit), mittelindoarisch (Prakrit, Pali, Apabhramsha) und neuindoarisch, die seit etwa 1000 n. Chr. bis heute gesprochenen indoarischen Sprachen.

Als Mitglieder der indogermanischen Sprachfamilie stammen die indoarischen Sprachen von einer angenommenen indogermanischen Ursprache oder auch Proto-Indoeuropäischen (PIE) ab, die wohl im 4. oder 3. Jahrtausend v. Chr. in den Steppen Südrusslands gesprochen wurde. Von der indogermanischen Urbevölkerung spaltete sich eine Gruppe ab, die sich selbst als „Arier“ ("ārya") bezeichnete und die eine Vorstufe der indoiranischen Sprachen sprach. Nachdem sie sich vermutlich eine Zeit lang in Baktrien aufgehalten hatte, teilte sie sich um 2000 v. Chr. in einen iranischen und indoarischen Zweig auf. Die Iraner ließen sich im Nord- und West-Iran nieder, die Indoarier wanderten wohl um 1500 v. Chr. in mehreren Wellen auf den indischen Subkontinent ein. Der älteste sprachliche Hinweis auf die Indoarier stammt indes aus dem hurritischen Mitanni-Reich im Norden Mesopotamiens und Nordosten Syriens. Im 16.–13. Jahrhundert v. Chr. sind einige der Thronnamen der mitannischen Könige vermutlich indoarisch. Götter wie in-da-ra (mit Indra gleichgesetzt) und mi-it-ra-aš (mit Mitra gleichgesetzt) werden in einem Vertragstext erwähnt. In einem Lehrbuch der Pferdehaltung, das der Mitannier Kikkuli im 15. Jahrhundert v. Chr. in hethitischer Sprache verfasste, finden sich einige aus dem Indoarischen entlehnte Fachbegriffe. Diese frühindoarischen Sprachspuren im Westen Vorderasiens verschwanden nach dem Untergang des Mitanni-Reichs wieder.

Die altindoarische Phase beginnt mit der Einwanderung der Indoarier nach Indien im 2. Jahrtausend v. Chr. Diese fand wohl in mehreren Wellen über einen längeren Zeitraum statt. Nach und nach breiteten sich die Indoarier in Nordindien aus und verdrängten dort die Sprachen der Urbevölkerung, nicht jedoch ohne von deren Substratwirkung beeinflusst worden zu sein. Vieles spricht dafür, dass die dravidischen und Munda-Sprachen einst in einem weit größeren Gebiet gesprochen wurden, bevor sie durch die indoarische Expansion nach Südindien bzw. die unwegsamen Berg- und Waldgegenden Zentralindiens zurückgedrängt wurden. Die in Indien populäre Sichtweise, die Indoarier seien in Indien autochthon gewesen und hätten dort bereits die Indus-Kultur begründet, ist aus wissenschaftlicher Sicht zu bezweifeln.

Als Altindoarisch oder Altindisch fasst man das Vedische und das klassische Sanskrit zusammen. Das Vedische, die Sprache der Veda-Schriften, ist die frühest überlieferte indoarische Sprachform. Die Datierung der lange Zeit nur mündlich überlieferten Texte ist unsicher, die ältesten Hymnen des Rigveda dürften aber kurz nach der Einwanderung der Indoarier nach Indien Mitte des 2. Jahrtausends v. Chr. entstanden sein. Das Vedische stellt eine archaische Form des Sanskrit mit einem größeren grammatikalischen Formenreichtum und einigen Unterschieden in Phonologie und Wortschatz dar. Die Unterschiede zum klassischen Sanskrit entsprechen etwa denen zwischen der Sprache Homers und dem klassischen Altgriechischen. Die Sprache der Brahmanas und Sutras ist eine Zwischenstufe zwischen Vedisch und klassischem Sanskrit.

Um das Verständnis und die fehlerfreie Rezitation der heiligen Texte sicherzustellen, entwickelte sich in Indien früh die Wissenschaft der Phonetik und Grammatik. Diese fand im Werk des Panini ihre Vollendung. Um 300 v. Chr. kodifizierte dieser in seiner Grammatik die Sprache der gebildeten Oberschicht. Das einfache Volk sprach zu dieser Zeit bereits mittelindoarische Idiome. So steht die Bezeichnung „Sanskrit“ ("saṃskr̥ta" „zurechtgemacht, kultiviert“) auch im Gegensatz zum Begriff „Prakrit“ ("prākr̥ta" „natürlich“), mit dem man die mittelindoarischen Sprachen zusammenfasst. Paninis Grammatik wurde normativ für das klassische Sanskrit. Somit wurde Sanskrit als Literatursprache in einem archaischen Stadium konserviert und existierte, ähnlich wie Latein im mittelalterlichen Europa, über einen langen Zeitraum parallel zu den mittelindoarischen Sprachen als Sprache der Religion und Gelehrsamkeit. Diese Stellung hat das Sanskrit in abgeschwächter Form bis heute behalten können. Die indische Verfassung erkennt Sanskrit sogar als eine von 22 Nationalsprachen an.

Die Blütezeit der Sanskrit-Literatur fällt in die Mitte des 1. Jahrtausends n. Chr. Das bedeutet, dass etwa ein Dichter wie Kalidasa, der wohl im 5. Jahrhundert lebte, seine Werke zu einer Zeit schrieb, als Sanskrit längst keine gesprochene Sprache mehr war, und sich an die Regeln eines Grammatikers hielt, der 700 Jahre vor ihm gelebt hatte. Anders als die Laut- und Formenlehre war die Syntax aber durch Panini kaum reglementiert und konnte daher unter dem Einfluss der mittelindoarischen Sprachen Eigenarten entwickeln, die in den frühen Stufen des Altindoarischen unbekannt waren. Charakteristisch für das klassische Sanskrit sind die Bevorzugung von Passivkonstruktionen und die Bildung riesiger Komposita mit bis zu 20 Bestandteilen.

Die mittelindoarischen Sprachen entstanden schon ab etwa 600 v. Chr. aus dem Altindoarischen. Da die gesprochenen Formen des Altindoarischen keineswegs einheitlich waren, ist die oft geäußerte Aussage, bestimmte mittelindoarische Sprachen seien „aus dem Sanskrit entstanden“ irreführend. Kennzeichnend für die Entwicklung vom Alt- zum Mittelindoarischen ist eine Vereinfachung der Formenlehre und der lautlichen Gestalt der Wörter (z. B. Sanskrit "trividya" zu Pali "tevijja"). Es sind mehrere mittelindoarische Idiome überliefert, für die man oft den Oberbegriff „Prakrit“ verwendet. Die ältesten Sprachzeugnisse des Mittelindoarischen und zugleich die ältesten Schriftdenkmäler Indiens sind die in einer Reihe regionaler Dialekte abgefassten Edikte Kaiser Ashokas aus dem 3. Jahrhundert v. Chr. Sie sind in Steininschriften in der Brahmi-Schrift aus verschiedenen Teilen Indiens überliefert. Die reformerischen Religionen des Buddhismus und Jainismus bevorzugten für ihre Schriften Prakrit. Auch in der Kunstdichtung kamen stilisierte Formen der Prakrits zum Einsatz, teils parallel zum Sanskrit. Das klassische Sanskrit-Drama etwa ist mehrsprachig: Die Protagonisten sprechen Sanskrit, Frauen Sauraseni-Prakrit, komische Charaktere Magadhi-Prakrit und die lyrischen Lieder sind in Maharashtri-Prakrit verfasst.

Die mittelindoarischen Sprachen lassen sich in drei Phasen einteilen. Die früheste Phase verkörpert Pali, als Sprache des Hinayana-Kanons und zahlreicher anderer buddhistischer Literatur die wichtigste mittelindoarische Literatursprache. In buddhistischen Ländern wie Sri Lanka, Burma und Thailand gilt Pali als klassische Sprache. Die späteren Prakrits werden in einen westlichen und östlichen Zweig unterteilt. Die Hauptform des westlichen Prakrit, Sauraseni, war im Gebiet der Flüsse Ganges und Yamuna verbreitet. Es war zudem das Standard-Prakrit des Dramas und die Sprache einiger Jaina-Texte. Zum östlichen Prakrit gehörte Magadhi, die Sprache des Landes Magadha im heutigen Bihar. Es wurde auch zur Charakterisierung niedriger Klassen in Sanskrit-Dramen verwendet. Geografisch wie sprachlich nahm das in Kosala (heute östliches Uttar Pradesh) gesprochene Ardhamagadhi („Halb-Magadhi“) eine Zwischenstellung ein. In Ardhamagadhi ist der frühe Jaina-Kanon abgefasst. Mit ihm verwandt war Maharashtri, der Vorläufer des heutigen Marathi. Es wurde vor allem als Sprache der Poesie verwendet, so auch für die Lieder der Sanskrit-Dramen. Phonologisch stellt es den fortschrittlichsten Dialekt der mittleren Phase dar. Außerhalb Indiens ist das Niya-Prakrit in Handschriften aus dem 3.–7. Jahrhundert als Verwaltungssprache indoarischer Gruppen im heutigen Ostturkestan belegt. Mit ihm verwandt ist das etwas ältere Gandhari, die Sprache indoarischer Khotan-Manuskripte aus dem 1. Jahrhundert.

Um die Mitte des 1. Jahrtausends bildete sich die nächste Stufe des Mittelindoarischen heraus, die man Apabhramsha ("apabhraṃśa" „verdorbene Sprache“) nennt. Der Begriff wird generalisierend für alle indoarischen Dialekte der späten mittelindoarischen Phase verwendet. Das Apabhramsha ist grammatikalisch noch weiter vereinfacht als die Prakrits und stellt bereits eine Übergangssprache zum Neuindoarischen dar. Die wichtigste Literatursprache dieser Periode war das Nagara-Apabhramsha, daneben existierten mehrere regionale Apabhramshas, die bereits Vorläufer der heutigen indoarischen Sprachen darstellen.

Singhalesisch stellt einen Sonderfall dar, da die Singhalesen schon um 500 v. Chr. wohl aus Gujarat nach Sri Lanka einwanderten und ihre Sprache sich, von den übrigen indoarischen Sprachen isoliert, auf eigenen Wegen entwickelt hat. Ab dem 1. Jahrhundert v. Chr. ist ein singhalesisches Prakrit in Inschriften überliefert. Die singhalesische Entsprechung zur Apabhramsha-Phase ist Elu.

Der Übergang vom Mittel- zum Neuindoarischen fand etwa 900–1100 n. Chr. statt. Diese Phase ist schlecht dokumentiert, die ersten Texte in neuindoarischen Sprachen treten erst recht spät auf: Aus dem 12. Jahrhundert sind eine kurze Inschrift in Marathi und eine Glosse in Bengali überliefert. Das älteste literarische Werk in Marathi entstand 1290, in Gujarati 1394 und in Urdu um das Jahr 1400.

In den neuindoarischen Sprachen wird die grammatikalische Entwicklung, die sich bereits in der mittelindoarischen Phase abzeichnete, zu Ende geführt. Vom alten flektierenden Sprachbau sind nur noch Rudimente vorhanden, stattdessen setzt sich die analytische Struktur durch und einzelne Sprachen entwickeln periphrastische und agglutinierende Formen. Dabei sind die westlichen Sprachen generell konservativer als die östlichen, besonders viele archaische Elemente haben die dardischen Sprachen erhalten. Vor allem im Bereich des Wortschatzes hinterließen die Herrschaft der muslimischen Sultane von Delhi und Moguln, die Persisch als Hofsprache verwendeten, und die britische Kolonialzeit Spuren in den indoarischen Sprachen.

Das Hauptverbreitungsgebiet der heutigen indoarischen Sprachen umfasst den nördlichen Teil des indischen Subkontinents etwa vom Indus im Westen bis nach Assam im Osten sowie vom Himalaya im Norden bis etwa zum 18. Breitengrad im Süden. Die indoarischen Sprachen sind die größte Sprachfamilie Südasiens. 15 von 22 offiziellen Sprachen Indiens sind indoarisch, drei von vier Indern sprechen eine indoarische Sprache als Muttersprache. Auch in Pakistan, Bangladesch, Nepal, Sri Lanka und auf den Malediven ist jeweils eine indoarische Sprache Amtssprache.

Die offizielle Nationalsprache Indiens ist Hindi. Die Anzahl der Muttersprachler hängt davon ab, in welchem Umfang man benachbarte verwandte Sprachen bzw. Dialekte zum Hindi dazurechnet oder als selbstständige Sprachen betrachtet. Im engeren Sinne hat Hindi über 200 Millionen Muttersprachler, legt man die erweiterte politische Definition der indischen Regierung zugrunde (s. u.), sind es 420 Millionen. Mit Zweitsprachlern wird Hindi von 500 Millionen Indern gesprochen, diese Zahl nimmt ständig zu. Die Hindi-Standardsprache beruht auf dem Hindustani, einer überregionalen Verkehrssprache auf Grundlage des Khari Boli, dem Dialekt von Delhi und Umgebung. Es dient in den nordindischen Bundesstaaten Uttar Pradesh, Bihar, Jharkhand, Chhattisgarh, Madhya Pradesh, Rajasthan, Haryana, Uttarakhand und Himachal Pradesh sowie im Unionsterritorium Delhi als Amtssprache und wird von der Bevölkerung als Schriftsprache verwendet. In diesem zentralindischen Gebiet wird eine Reihe von nah verwandten, teils auch als Hindi-Dialekte klassifizierten Regionalsprachen gesprochen. Diese unterteilen sich in zwei Gruppen, „West-Hindi“ oder west-zentralindisch (Haryani, Braj-Kanauji, Bundeli) und „Ost-Hindi“ oder ost-zentralindisch (Awadhi, Bagheli, Chhattisgarhi).

Aus politischen Gründen klassifiziert die indische Regierung eine Reihe weiterer Sprachen, die aus sprachwissenschaftlicher Sicht eigenständig sind, zu verschiedenen Untergruppen des Indoarischen gehören und teils sogar eine eigene Schriftsprache haben, als „Hindi-Dialekte“ Dies sind die Sprachen der ostindischen Bihari-Gruppe (mit Bhojpuri, Maithili und Magahi), die westindischen Rajasthani-Sprachen sowie im Norden die Gruppe der am Rand des Himalaya gesprochenen nordindischen Pahari-Sprachen. Diese Definition ist nicht linguistisch, sondern ausschließlich politisch motiviert. Ziel ist es, das Hindi zu einer wirklichen Nationalsprache auszudehnen. Allerdings beeinflusst Hindi als Medien- und Prestigesprache im zunehmenden Maße andere indoarische Sprachen.

Urdu, die Sprache der indischen und pakistanischen Muslime, und Hindi sind im Bereich der Alltagssprache nahezu identisch; sie beruhen beide auf dem Hindustani und sind nicht einmal unterschiedliche Dialekte. Die Schriftsprache des Urdu unterscheidet sich aber durch einen hohen Anteil von Wörtern persisch-arabischer Herkunft und die Verwendung der arabischen Schrift. Trotz 65 Millionen Sprechern (mit Zweitsprechern 105 Mio.) ist Urdu eine Sprache ohne territoriale Basis. Einen Großteil ihrer Sprecher macht die muslimische Stadtbevölkerung Nordindiens aus, daneben ist auch in südindischen Städten wie Hyderabad ein als Dakhini bekannter Urdu-Dialekt verbreitet. In Pakistan wird Urdu nur von einem kleinen Teil der Bevölkerung als Muttersprache gesprochen (etwa 10 Mio.). Sie besteht aus Nachkommen eingewanderter nordindischer Muslime, die sich über das ganze Land verbreiteten, wirtschaftlich wie politisch sehr aktiv sind und fast ausschließlich in den Städten leben. Das Urdu etablierte sich bald als überregionale Verkehrs- und Bildungssprache und ist in Pakistan offizielle Nationalsprache, weshalb auch die Anzahl der Urdu-Sprecher stetig zunimmt.

Zu den ostindischen Sprachen wird die oben schon erwähnte Bihari-Gruppe (insgesamt 65 Mio. Sprecher) mit den Hauptsprachen Bhojpuri, Maithili und Magahi gerechnet, die in Bihar zwischen den zentralindischen Idiomen und dem Bengali gesprochen werden. Bengali (mit 210 Millionen Sprechern die zweitgrößte indoarische Sprache) ist die Sprache der indischen Bundesstaaten Westbengalen und Tripura sowie von Bangladesch. Einige der Bengali-Varietäten (Chittagong, Sylhetti und Rajbangsi) werden auch als eigenständige Sprachen klassifiziert. Nordöstlich anschließend wird Asamiya im Bundesstaat Assam von 15 Millionen Sprechern gesprochen.

Die Sprache des an der Ostküste Indiens gelegenen Bundesstaates Orissa ist Oriya, das von 32 Millionen Menschen gesprochen wird. In den Wald- und Berggegenden Zentralindiens werden neben den nichtindoarischen Sprachen der Adivasi-Stammesbevölkerung Bhatri und Halbi, zwei indoarische Übergangsdialekte gesprochen.

Marathi ist im nordwestlichen Dekkan im Bundesstaat Maharashtra verbreitet und hat insgesamt 80 Millionen Sprecher. Nah verwandt mit Marathi ist Konkani (8 Millionen Sprecher), das Amtssprache in Goa ist und außerdem im äußersten Süden Maharashtras sowie an der Küste von Karnataka und Kerala gesprochen wird.

In den Stammesgebieten von Nord-Maharashtra, Ost-Gujarat und Süd-Rajasthan spricht man Bhili und Khandeshi, zwei indoarische Sprachen, die früher als Gujarati-Dialekte betrachtet wurden. Das sich westlich anschließende Gujarati hat 45 Millionen Sprecher und wird im Bundesstaat Gujarat sowie von einem Teil der Bevölkerung Mumbais (Bombays) gesprochen. Nördlich schließen sich die Sprachen Rajasthans an, die sog. Rajasthani-Gruppe mit den Sprachen Marwari (15 Mio.), Malvi, Bagri, Lambardi und Nimadi, jeweils 1 bis 2 Mio. Sprecher.

Das Sprachgebiet des Sindhi (22 Mio. Sprecher) beginnt im Westen Gujarats und setzt sich jenseits der pakistanischen Grenze in der Provinz Sindh am Unterlauf des Indus fort. Mit dem Sindhi eng verwandt ist die Gruppe der westlichen sog. Panjabi-Dialekte, die auch als Lahnda-Gruppe bezeichnet wird. Von den Lahnda-Dialekten hat sich Siraiki als Schriftsprache durchgesetzt, eine weitere westpanjabische Sprache ist Hindko. Insgesamt sprechen ca. 80 Mio. Lahnda, Hindko oder Siraiki. Das eigentliche (östliche) Panjabi hat insgesamt 30 Millionen Sprecher und ist im Norden des pakistanischen Industals sowie im indischen Teil des Panjab verbreitet. Dogri-Kangri (2,2 Mio. Sprecher) wird im Gebiet von Jammu im indischen Bundesstaat Jammu und Kashmir gesprochen, es wurde früher als Panjabi-Dialekt angesehen, gehört aber einem separaten Sprachzweig an und ist mittlerweile in Indien offiziell als eigenständige Sprache anerkannt.

Nördlich des Hindi-Sprachgebiets wird Nepali von 16 Mio. Menschen gesprochen. Es ist die Nationalsprache Nepals und außerdem in Sikkim, Darjiling und Teilen Bhutans verbreitet. Weitere wichtige nordindische Sprachen sind Garhwali und Kumauni mit jeweils rund 2 Mio. Sprechern. Sie werden im Vorgebirge des Himalayas westlich des Nepali-Sprachgebiets gesprochen (sog. West-Pahari-Sprachen).

Im äußersten Nordwesten des Subkontinents liegt das Verbreitungsgebiet der dardischen Sprachen. Deren wichtigste ist das im Kaschmir-Tal gesprochene Kashmiri mit 4,5 Mio. Sprechern, die einzige dardische Literatursprache. Die übrigen dardischen Sprachen (hierzu gehören u. a. Pashai, Khowar, Kalasha, Shina und Indus-Kohistani) werden insgesamt von 1,2 Millionen Menschen im Hindukusch-Gebiet Pakistans und Afghanistans gesprochen.

Räumlich vom restlichen indoarischen Sprachgebiet getrennt ist das Singhalesische (Sinhala). Es wird von der Mehrheit der Bevölkerung Sri Lankas gesprochen (15 Mio. Sprecher). Divehi, die Sprache der Malediven, hat 300.000 Sprecher und ist eng mit dem Singhalesischen verwandt.

Einen Sonderfall stellt Romani (Romanes) dar, die in zahlreichen Dialekten über die Länder Europas und des vorderen Orients verstreute Sprache der Roma mit etwa 3,5 Mio. Sprechern. Verwandt mit dem Romani – zu dem auch die in Deutschland verbreitete Sinti-Sprache als Dialekt gehört –, sind die ebenfalls außerhalb Indiens im Nahen Osten und Europa gesprochenen Idiome Domari und Lomavren.

Als Folge neuerer Migrationsprozesse während der britischen Kolonialzeit werden indoarische Sprachen in größerer Zahl u. a. auch in der Karibik, Guyana, Südafrika, im Vereinigten Königreich, in Mauritius und Fidschi verwendet. In Fidschi dient sogar eine Variante des Hindustani als Amtssprache.

Eine interne Klassifikation der neuindoarischen Sprachen, die seit etwa 1000 n. Chr. gesprochen werden, stößt auf viele Probleme. Idealerweise kann ein Stammbaum die genetische Abspaltung von Sprachgruppen wiedergeben, die sich durch räumliche Entfernung im Laufe der Zeit auseinanderentwickelt haben. Dieser Prozess hat im Prinzip auch bei den indoarischen Sprachen stattgefunden, ist aber aufgrund diverser Wanderungsbewegungen zum Teil historisch nicht mehr eindeutig nachzuvollziehen. Gründe für die immer wieder erfolgenden Migrationen und die damit verbundenen Durchmischungsprozesse sind die kaum vorhandenen natürlichen Barrieren im indischen Kernland und instabile politische Einheiten mit multiethnischen und multilingualen Gesellschaften. Diese Prozesse haben schließlich ein Dialektkontinuum ergeben, das sich über den ganzen indoarischen Sprachraum von West nach Ost und von Nord nach Süd erstreckt.

Die Folge sind erstens große Schwierigkeiten bei der Identifikation von Einzelsprachen, zweitens bei der Abgrenzung von Dialekt und Sprache und schließlich bei der Klassifikation, das heißt, der inneren Gliederung der neuindoarischen Sprachen insgesamt. Erschwerend kommt der Umstand hinzu, dass der Übergang vom späten Mittelindoarischen zum frühen Neuindoarischen etwa um 900 bis 1100 n. Chr. nur sehr schwach schriftlich belegt ist; dadurch wird es fast unmöglich, neuindoarische Sprachen auf bestimmte mittelindoarische Sprachen zurückzuführen und damit eine natürliche Gruppenbildung der neuindoarischen Sprachen zu erzielen.

Da ein einfaches, gut begründbares Stammbaummodell also nicht leicht zu erreichen ist, hat es Ansätze gegeben, mit Hilfe des Wellenmodells die Strukturierung der neuindoarischen Sprachen zu verstehen. Dabei werden von bestimmten Zentren ausgehende Innovationen untersucht, die sich im Laufe der Zeit durch Teilbereiche der neuindoarischen Sprachen bewegt haben und in Isoglossen nachzuvollziehen sind. Hier spielt auch das Phänomen der Prestigesprachen eine große Rolle, deren Merkmale und Innovationen durch Kontakt verstärkt auf benachbarte Sprachen übergegangen sind. (Indoarische Prestigesprachen mit dieser Funktion waren das Vedische, Sanskrit, Magadhi, Sauraseni, Apabhramsha und heutzutage Hindi.) Das Problem bei der Anwendung der Wellentheorie ist, dass verschiedene Isoglossen zu völlig unterschiedlichen Gliederungen führen und somit auch dieses Modell keine Klassifikation ermöglicht.

Klassifikationsversuche im klassischen genetischen Sinne gab es bereits seit dem frühen 19. Jahrhundert. Aber erst Hoernle 1880 gibt eine Übersicht, die bereits auf einer größeren Zahl neuindoarischer Sprachen basiert und somit mit moderneren Fassungen vergleichbar ist. Hoernles Hauptgliederung ist eine nordwestliche und eine südöstliche, welche er auf zeitlich getrennte Einwanderungswellen zurückführt:


Die Grundstruktur dieser auch areal bedingten Klassifikation haben viele spätere Forscher übernommen, allerdings wurde die These der verschiedenen Einwanderungsströme schon bald verworfen. Einen nächsten wichtigen Schritt machte George Abraham Grierson in seinem "Linguistic Survey of India" (1903-28), der noch heute eine wichtige Arbeitsgrundlage darstellt. Er ging von einem Konzept „äußerer“ und „innerer“ neuindoarischen Sprachen aus. Zu den inneren zählte er die Pahari-Gruppe, Panjabi, Rajasthani, Gujarati und Hindi, zu den äußeren die Ostgruppe (Bengali, Assami, Oriya), die Südgruppe (Marathi, Konkani, Singhalesisch) und eine Nordwestgruppe (Lahnda, Sindhi). Dazwischen positionierte er eine „mittlere“ Gruppe von Übergangssprachen (z. B. Awadhi, Chhattisgarhi). Das Innen-Außen-Konzept konnte sich ebenso wenig wie die Migrationsthese halten.

Eine neue Klassifikation legte dann Chatterji 1926 vor, die bereits im Wesentlichen mit heutigen Ansätzen korrespondiert. Obwohl die Gruppen wieder areale Namen tragen, geht Chatterji von linguistischen Merkmalen und bestimmten phonetischen Isoglossen aus und kommt damit zu folgender nicht-hierarchischen Klassifikation:


Grierson revidiert 1931 seinen ursprünglichen Ansatz und kommt zu einer sehr ähnlichen Binnengliederung wie Chatterji. Auch die Klassifikationen von Turner (1960), Katre (1965) und Cardona (1974) sind jeweils begründete Varianten des Chatterji-Ansatzes.

Während man also zum Kern der neuindoarischen Sprachen nach und nach einen annähernden Konsens gefunden hatte, ohne allerdings in jedem Detail zu einer allgemein akzeptierten Einteilung zu gelangen, gab es noch längere Dispute um Randgruppen, nämlich das Dardische, die Zigeunersprachen (Romani, Domari) und das Singhalesische und Maledivische (Divehi). Letztere hat man entweder den südindoarischen Sprachen (Marathi, Konkani) zugerechnet oder aber als eigene Gruppe behandelt.

Beim Dardischen ist bis heute nicht endgültig geklärt, welche Sprachen dazugehören sollen. Rechnete man ursprünglich die Nuristani-Sprachen dazu, so tendiert heute die Mehrheit der Forscher dahin, Nuristani als dritten Zweig des Indoiranischen gleichrangig neben Iranisch und Indoarisch aufzufassen und nicht mehr den dardischen Sprachen zuzuordnen. Strittig ist dann immer noch die Position der (restlichen) dardischen Sprachen (die wichtigste ist Kashmiri) innerhalb des Neuindoarischen. Während manche Forscher es als einen Unterzweig des Nordwestindischen betrachten (etwa zusammen mit Lahnda und Sindhi), setzt sich die Positionierung als selbstständiger Zweig des Indoarischen durch.

Besonders schwierig gestaltet sich die Zuordnung des Romani (und der anderen Idiome der Roma und Sinti), deren Zugehörigkeit zum Indoarischen Mitte des 19. Jahrhunderts erkannt wurde. Die moderne Darstellung des Romani und seiner Dialekte von Matras (2002) positioniert es im Zentralindischen nahe dem Hindi, frühere Auffassungen tendierten wegen mancher Ähnlichkeiten in der Phonetik eher zum Nordwestindischen. In dieser Sache ist die letzte Entscheidung noch nicht getroffen. Dieser Artikel stellt das Romani zusammen mit dem Domari und Lomavren als separaten Zweig des Neuindoarischen dar.

Somit deckt sich die hier gegebene Klassifikation weitgehend mit der von Gippert im "Metzler Lexikon Sprache" (2. Auflage 2000), die von ihm als „zur Zeit beste Arbeitshypothese“ bezeichnet wird. Eine stabile, für alle Zeiten gültige Klassifikation der neuindoarischen Sprachen wird es wahrscheinlich auch in Zukunft nicht geben, aber große Abweichungen vom hier vorgestellten Modell sind allerdings wohl auch nicht zu erwarten.

Die folgende Aufzählung gibt die Hauptzweige des Neuindoarischen mit den wichtigsten Sprachen wieder. Die vollständige Klassifikation aller neuindoarischen Sprachen wird im nächsten Abschnitt dargestellt.


Für jeden Hauptzweig des Neuindoarischen werden in der folgenden Übersicht die strukturelle Gliederung und die zugehörigen Sprachen mit ihren aktuellen Sprecherzahlen angegeben. Zur Sprachidentifikation (und Abgrenzung gegenüber Dialekten) wurde vor allem David Dalby "The Linguasphere Register" (2000) herangezogen. Es sei darauf hingewiesen, dass die dargestellten Einheiten tatsächlich „Sprachen“ und nicht nur „Dialekte“ sind; jede angeführte Sprache hat in der Regel ihrerseits etliche Dialekte. Zwischen benachbarten Sprachen gibt es normalerweise Übergangsdialekte, deren Zuordnung natürlich problematisch ist. Für eine vollständige und detaillierte Aufstellung "mit Dialekten und Unterdialekten" siehe den unten angegeben Weblink, auf dem diese Klassifikation basiert. Die Sprecherzahlen stammen im Wesentlichen aus Ethnologue (15. Auflage 2005), bei größeren Sprachen wurden statistische Jahrbücher und zusätzliche Quellen zur Absicherung herangezogen.

"Hauptzweige in Großbuchstaben, genetische Untergruppen in Fettdruck, Sprachnamen im Normaldruck."

DARDISCH (23 Sprachen mit 5,7 Mio Sprechern)

NORDINDISCH oder PAHARI (3 Sprachen mit 21 Mio Sprechern)

NORDWESTINDISCH (20 Sprachen mit 135 Mio Sprechern)

WESTINDISCH (13 Sprachen mit 78 Mio Sprechern)

ZENTRALINDISCH (14 Sprachen mit 320 Mio Sprechern, inkl. S2 655 Mio)

OSTINDISCH (26 Sprachen mit 347 Mio Sprechern)

SÜDINDISCH (4 Sprachen mit 89 Mio Sprechern)

SINHALA-DIVEHI (2 Sprachen mit 13,2 Mio Sprechern)

ROMANI-DOMARI (3 Sprachen mit 4 Mio Sprechern)

NICHT-KLASSIFIZIERT (8 Sprachen mit 220 Tsd Sprechern)
Zusätzlich zu den klassifizierten neuindoarischen Sprachen gibt es einige schriftlose Sprachen, die bisher keinem der Hauptzweige zuzuordnen waren; dennoch sind die hier genannten Sprachen zweifelsfrei indoarisch. Möglicherweise sind einige dieser Sprachen Dialekte von klassifizierten Sprachen. Von keiner dieser Sprachen gibt es bisher linguistische Untersuchungen oder gar Grammatiken. Es handelt sich um:

Das Phoneminventar der indoarischen Sprachen ist in den verschiedenen Sprachstufen recht stabil geblieben. Charakteristische Laute wie die retroflexen und aspirierten Konsonanten kommen sowohl in alt-, mittel- als auch fast allen neuindoarischen Sprachen vor. Hingegen haben die verschiedenen Sprachstufen vor allem hinsichtlich der Verteilung der Laute im Wort tiefgreifende Änderungen durchlaufen, wodurch sich die Lautgestalt der Wörter teils erheblich verändert hat.

Charakteristisch für das Konsonantensystem der indoarischen Sprachen ist eine große Zahl (in der Regel 20) an Plosiven (Verschlusslauten), die nach fünf Artikulationsorten (velar, palatal, retroflex, dental und labial) unterschieden werden. Der Kontrast zwischen retroflexem "ṭ" und dentalem "t" (vgl. Hindi "totā" „Papagei“ und "ṭoṭā" „Mangel“) ist typisch für die Sprachen Südasiens. Obwohl man "c" und "j" traditionell als Plosive klassifiziert, werden sie in der Praxis eher als Affrikaten, also [] und [], gesprochen. Der Unterschied zwischen Stimmhaftigkeit und Stimmlosigkeit (z. B. "p" vs. "b") ist ebenso bedeutungsunterscheidend wie die Aspiration, die sowohl bei stimmlosen als auch stimmhaften Plosiven vorkommt (z. B. "p", "b" vs. "ph", "bh"). Nach der Beschreibung der traditionellen indischen Grammatik existiert zu jeder der fünf Reihen von Plosiven ein homorganer (am gleichen Artikulationsort gesprochener) Nasal. Somit ergibt sich folgendes System der Plosive und Nasale (Angegeben ist die IAST-Transkription und der Lautwert in IPA-Lautschrift):

Einige periphere indoarische Sprachen haben dieses System vereinfacht. Im Singhalesischen ist (wohl unter tamilischem Einfluss) die Aspiration verloren gegangen, während Asamiya keine retroflexen Laute kennt. Andere Sprachen haben zusätzliche Phoneme entwickelt, Sindhi etwa die Implosive [], [], [], und []. Was die Nasale angeht, waren ursprünglich nur "m", das dentale "n" und das retroflexe "ṇ" eigenständige Phoneme, auch die Unterscheidung zwischen den letzten beiden wird nicht in allen modernen Sprachen gewahrt. Die Laute "ṅ" und "ñ" sind meist nur positionsbedingte Allophone, die nur vor den entsprechenden Plosiven vorkommen, in manchen Sprachen haben sie aber sekundären Phonemstatus erlangt.

Im klassischen Sanskrit kamen der Vibrant "r" [] und der Lateral "l" [] vor. Andere indoarische Sprachen haben ihr Phoneminventar in diesem Bereich erweitert: Ein retroflexer Lateral "ḷ" [] kommt bereits im Vedischen und später u. A. in Oriya, Marathi, Gujarati und Panjabi vor. Hindi, Bengali, Panjabi und Sindhi kennen den retroflexen Flap []. Während im Altindoarischen noch vier Frikative vorkamen – die drei Zischlaute "ś" [], "ṣ" [] und "s" [] sowie "h" [] – sind in den modernen Sprachen die drei ursprünglichen Sibilanten zu einem Laut, im Westen meist [s], im Osten [], zusammengefallen. Meist ist aber durch Lehnwörter wieder eine Unterscheidung zwischen [s] und [ʃ] eingeführt worden. An Halbvokalen kommen "y" [] und "v" [] vor.

Zusätzlich zu diesen ursprünglichen indoarischen Konsonanten haben viele neuindoarische Sprachen durch Lehnwörter aus dem Persischen und Englischen neue Phoneme übernommen, namentlich [], [], [], [] und []. In allen Sprachen außer Urdu ist die Stellung dieser Phoneme aber nicht sehr gefestigt, bei nachlässiger Aussprache werden sie oft durch ähnlich klingende Laute ersetzt, also etwa "pilm" statt "film".

Die Anzahl der Vokalphoneme bewegt sich in den meisten neuindoarischen Sprachen zwischen sechs und zehn. Romani hat nur fünf Vokale, das Singhalesische dagegen ein System von 13 Vokalen, das in erster Linie auf der Unterscheidung nach Vokallänge beruht. Für die dardischen Sprachen und bestimmte Marathi-Dialekte werden Systeme mit bis zu 18 Vokalen beschrieben, die aber nur unzureichend erforscht sind.

Die Vokalsysteme der wichtigsten indoarischen Sprachen sind wie folgt:
Anmerkung: Der kurze "a"-Laut kann als [] oder [] wiedergegeben werden.

Das symmetrische Zehn-Vokal-System des Hindi und Panjabi steht dem Sanskrit am nächsten. Im Sanskrit bestand aber der Unterschied zwischen Paaren wie "i" / "ī" primär in der Vokallänge: [] / []. In den neuindoarischen Sprachen ist dieser quantitative Unterschied durch einen qualitativen ersetzt worden: [] / []. Es ist aber möglich, dass der qualitative Unterschied bereits von Anfang mit der Unterscheidung nach der Vokallänge einherging. Zumindest für das kurze "a" [] und das lange "ā" [] wird bereits in den ältesten Grammatiken ein Unterschied in der Vokalqualität beschrieben. Zusätzlich kannte das Sanskrit die „konsonantischen Vokale“ "r̥", "r̥̄" und "l̥". Die letzten beiden sind sehr selten, das "r̥" kommt hingegen auch in den modernen Sprachen in Sanskrit-Lehnwörtern vor und wird heutzutage je nach Region als [] oder [] gesprochen (z. B. "r̥ṣi" [] „Rishi“).

Die Phoneme [] und [] im Hindi und Panjabi gehen ursprünglich auf die Diphthonge [] und [] zurück und werden in manchen Dialekten auch noch als solche gesprochen. Während diese beiden Diphthonge im Sanskrit phonematisch sind, werden die zahlreichen Vokalverbindungen der neuindoarischen Sprachen nicht als eigenständige Phoneme aufgefasst.

Den reinen Vokalen stehen in den meisten neuindoarischen Sprachen Nasalvokale gegenüber (z. B. Hindi "cā̃d" „Mond“). Das Sanskrit kennt ebenfalls eine als Anusvara ("ṃ") bezeichnete Nasalisierung (z. B. "māṃsa" „Fleisch“), die aber nur in vorhersagbaren Fällen auftritt und deshalb im Gegensatz zu den Nasalvokalen der modernen Sprachen nicht phonematisch ist. Selbiges gilt für den im Sanskrit vorhandenen stimmlosen Hauchlaut Visarga ("ḥ"), der meist am Wortende auftritt und sprachhistorisch auf "s" oder "r" zurückgeht (vgl. die Nominativendung "-aḥ" im Sanskrit mit Griechisch "-os" und Latein "-us").

Die älteste indoiranische Sprachform, das Vedische, verfügte über einen tonalen Akzent, der dem des Altgriechischen entsprach (vgl. Vedisch "pā́t, padáḥ" mit Altgriechisch "poús", "podós" „Fuß“). Der Akzent konnte auf jede Silbe des Wortes fallen und wurde mit einem Hochton ("udātta") gesprochen. Im klassischen Sanskrit wandelte sich der tonale Akzent zu einem auf der Schallfülle beruhenden dynamischen Akzent, wie er auch im Deutschen vorkommt. Die Position des Akzents stimmte nicht mit dem alten tonalen Akzent überein, sondern fiel ähnlich wie im Lateinischen nach vorhersagbaren Regeln auf die zweit-, dritt- oder viertletzte Silbe. Die Betonung folgt in den neuindoarischen Sprachen unterschiedlichen Regeln, ist aber nie bedeutungsunterscheidend. Eine Ausnahme ist Asamiya (vgl. "ˈpise" „er trinkt“ und "piˈse" „dann“).

Panjabi stellt als Tonsprache einen Sonderfall dar. Die drei bedeutungsunterscheidenden Töne (z. B. "koṛā" „Peitsche“, "kóṛā" „Aussätziger“, "kòṛā" „Pferd“) sind sekundär unter dem Einfluss eines früheren aspirierten Konsonanten entstanden (vgl. Panjabi "kòṛā" mit Hindi "ghoṛā").

Die altindoarischen Sprachen hatten eine komplizierte Phonologie, die dem indogermanischen Typus noch recht nahesteht. Die wichtigsten Punkte, in denen sich Sanskrit von der rekonstruierten indogermanischen Ursprache unterscheidet, sind folgende:

Am Wortanfang und im Wortinneren treten im Sanskrit komplexe Konsonantenhäufungen auf (z. B. "jyotsna" „Mondschein“). Dagegen können Wörter nur auf bestimmte Konsonanten enden, Verbindungen von mehreren Konsonanten kommen in der Regel nicht vor (vgl. lat. "vox" und Avestisch "vāxš" mit Sanskrit "vāk" „Stimme“). Beim Zusammentreffen von Lauten innerhalb eines Wortes oder beim Aufeinandertreffen zweier Wörter treten Sandhi-Erscheinungen auf (z. B. wird "na uvāca" zu "novāca" „er sagte nicht“).

In der mittelindoarischen Periode vereinfachte sich die Phonologie erheblich. Es kamen keine Sandhi-Regeln mehr zur Anwendung, das Phoneminventar wurde etwas verkleinert. Die wichtigste Änderung in den mittelindoarischen Sprachen war die radikale Vereinfachung der Silbenstruktur hin zu einem Typus, der dem der dravidischen Sprachen ähnelte: Konsonantenverbindungen am Wortanfang waren nicht mehr möglich, im Wortinneren kamen nur bestimmte einfach auszusprechende Konsonantenverbindungen (verdoppelte Konsonanten oder Verbindungen mit einem Nasal als erster Bestandteil) vor, am Wortende waren gar keine Konsonanten außer dem nasalisierten "ṃ" zulässig. Die wichtigsten Lautwandel des Mittelindoarischen sind:


In den neuindoarischen Sprachen hat sich die Silbenstruktur durch den Ausfall kurzer Vokale wieder vom simplen Typus des Mittelindoarischen wegentwickelt. So kommen Konsonanten am Wortende sogar weitaus öfter vor als im Sanskrit, auch im Wortinneren sind wieder Konsonantenverbindungen möglich. Verstärkt wird diese Entwicklung durch Lehnwörter aus nichtindoarischen Sprachen. Viele neuindoarische Sprachen haben spezielle Entwicklungen durchlaufen, auf die hier nicht näher eingegangen werden kann. Zentrale Merkmale, die die Phonetik der Mehrzahl der neuindoarischen Sprachen charakterisieren, sind:


Die Morphologie der indoarischen Sprachen hat im Laufe ihrer Entwicklung grundlegende Änderungen erfahren. Das altindoarische Sanskrit war eine hochgradig synthetisch-flektierende Sprache mit einer komplizierten Formenlehre, dem Lateinischen und Altgriechischen nicht unähnlich. Die Entwicklung hin zu den mittelindoarischen Sprachen ging mit einer deutlichen Vereinfachung der Formenbildung einher. Die neuindoarischen Sprachen sind zu einem weitgehend analytischen Sprachbau mit agglutinierenden Elementen übergegangen. Typologisch sind die indoarischen Sprachen stark von ihren dravidischen Nachbarsprachen beeinflusst worden, vor allem im Bereich der Syntax schlägt sich dieser Einfluss bereits im klassischen Sanskrit deutlich nieder.

Die Morphologie der Nomina ist im Sanskrit komplex. Sie haben alle acht Kasus (Nominativ, Akkusativ, Instrumental, Dativ, Ablativ, Genitiv, Lokativ, Vokativ) und drei Numeri (Singular, Dual, Plural) der indogermanischen Ursprache bewahrt. Je nach Stammauslaut und Genus werden die Nomina in verschiedene Deklinationstypen mit jeweils unterschiedlichen Kasusendungen eingeteilt. Manche Stämme setzen quantitativen Ablaut ein und sind dadurch höchst variabel (z. B. bildet der Stamm "pitr̥-" „Vater“ folgende Formen: "pitā", "pitar-am", "pitr-e", "pitr̥-bhyām", "pitr̥̄-n").

Im Mittelindoarischen wurde dieses komplizierte System vereinfacht: Der Dual ging verloren, das Kasussystem wurde durch den Zusammenfall von Genitiv und Dativ reduziert und die variablen Konsonantenstämme in regelmäßige Vokalstämme umgewandelt (z. B. Sanskrit "gacchant-/gacchat-" „gehend“ zu Pali "gacchanta-"), bis in der Apabhramsha-Phase nur noch ein allgemeiner Deklinationstyp vorhanden ist. Im Großen und Ganzen bleibt aber im Mittelindoarischen das alte Kasussystem, wenn auch vereinfacht, bestehen. Als Beispiel ist die Deklination des Wortes "putra-"/"putta-" („Sohn“) im Singular in Sanskrit, Pali und Apabhramsha angegeben.

Die neuindoarischen Sprachen haben dagegen das Deklinationssystem grundlegend umgestaltet. Das flektierende System des Alt- und Mittelindoarischen ist nur noch in Rudimenten erhalten. Meist sind nur noch zwei primäre Kasus vorhanden, nur vereinzelt finden sich noch Reste der alten Kasus Instrumental, Lokativ und Ablativ. Nominativ und Akkusativ, schon durch Lautwandel im Apabhramsha zusammengefallen, werden zum Rektus zusammengefasst. In Opposition zum Rektus steht in der Regel ein Obliquus (z. B. Hindi "laṛkā" – "laṛke" „Junge“, Gujarati "ghoḍo" – "ghoḍā" „Pferd“). Manche Sprachen wie Bengali oder Asamiya haben keine spezielle Form für den Obliquus. Formal geht der Obliquus meist auf den Genitiv zurück und hat in einigen wenigen Sprachen auch noch dessen Funktion behalten. In den meisten Sprachen kommt er aber nicht allein vor, sondern wird durch ein System von Postpositionen oder sekundären Affixen in seiner Bedeutung weiter differenziert (z. B. Hindi "laṛke ko" „dem Jungen“, Gujarati "ghoḍānuṃ" „des Pferdes“). Diese Affixe gehen ursprünglich auf eigenständige Wörter zurück, sind aber teils mit dem Obliquus zu sekundären agglutinierenden Kasusendungen verschmolzen. Die Genitivendung "-er" im Bengali leitet sich etwa über die Partikel "kera" auf das altindoarische Substantiv "kārya" mit der Bedeutung „Angelegenheit“ ab.

Der Plural wird auf unterschiedliche Weisen gebildet. Geschieht dies etwa im Hindi flektierend, mit einer Endung, die gleichzeitig Kasus und Numerus ausdrückt (vgl. Nominativ Singular "laṛkā", Plural "laṛke"; Obliquus Singular "laṛke", Plural "laṛkõ"), so setzen andere Sprachen wie Bengali dagegen agglutinierende Pluralsuffixe ein, an die zusätzlich Kasusformantien treten (vgl. Nominativ Singular "chele", Plural "chele-gulo"; Objektiv Singular "chele-ke", Plural "chele-gulo-ke").

Die alt- und mittelindoarischen Sprachen kennen die drei indogermanischen Genera Maskulinum, Femininum und Neutrum. Unter den neuindoarischen Sprachen ist dieses System in den westlichen Sprachen (Gujarati, Marathi, Konkani) beibehalten worden. Im Singhalesischen kommen ebenfalls drei Genera vor, doch handelt es sich hierbei um ein anders gelagertes System, das wie in den dravidischen Sprachen auf Belebtheit und natürlichem Geschlecht beruht. In den meisten neuindoarischen Sprachen sind Maskulinum und Neutrum zusammengefallen. Nach Osten hin ist die Genuskategorie weniger stark ausgeprägt. Die östlichsten Sprachen Bengali, Asamiya und Oriya haben sie gänzlich verloren, ebenso Khowar und Kalasha am entgegengesetzten Ende des indoarischen Sprachraums.

Das Verb zeichnet sich im Altindoarischen (im Vedischen noch stärker als im klassischen Sanskrit) durch einen großen Reichtum an Formen aus. Die Verben werden in drei Personen, drei Numeri (Singular, Dual, Plural) und drei Genera Verbi (Aktiv oder "parasmaipada", Medium oder "ātmanepada" und Passiv) konjugiert. Das Tempussystem ist mit Präsens, Imperfekt, Futur, Aorist, Perfekt sowie im Vedischen noch Plusquamperfekt ausgeprägt. Ursprünglich unterschieden sich die Vergangenheitstempora noch in ihrer Bedeutung, später werden sie aber gleichbedeutend verwendet. Die gebräuchlichste Möglichkeit, die Vergangenheit auszudrücken, ist im klassischen Sanskrit indes ein Nominalsatz mit dem Partizip Perfekt Passiv. An Modi existieren Indikativ, Konjunktiv, Optativ und Imperativ. Dazu kommen mehrere Partizipien des Aktivs und Passivs, Gerundien, ein Infinitiv sowie ein System von abgeleiteten Verben (Kausativ, Desiderativ, Intensiv). Die Verben werden nach der Bildung des Präsensstammes in zehn Klassen eingeteilt. Die Hauptunterscheidung liegt hierbei zwischen den thematischen Verben, die den Themavokal "a" zwischen Stamm und Endung einfügen, und den athematischen Verben, bei denen dies nicht der Fall ist. Das Imperfekt wird ebenso wie der Imperativ und Optativ vom Präsensstamm gebildet, die Formen der übrigen Tempora sind unabhängig vom Präsensstamm. Die Verbalmorphologie des Sanskrit ist kompliziert und setzt regelmäßig Mittel wie Reduplikation und quantitativen Ablaut ("guṇa"- und "vr̥ddhi"-Stufe) ein (z. B. werden vom Stamm "kr̥-" „machen“ die Formen "kr̥-ta" „gemacht“, "kar-oti" „er macht“ und "ca-kār-a" „er hat gemacht“ gebildet).

In den mittelindoarischen Sprachen wird dieses System vereinfacht und regelmäßiger gestaltet. Die Vergangenheitstempora, deren Unterscheidung schon im Sanskrit nur künstlich aufrechterhalten wurde, werden gänzlich durch die Partizipialkonstruktion ersetzt. Der Konjunktiv stirbt ebenso aus wie das Medium und die abgeleiteten Verben mit Ausnahme des Kausativs.

Die neuindoarischen Sprachen verwenden neben den alten synthetischen Formen, die nach Person und Numerus konjugiert werden, in größerem Maße Partizipialformen, die sich nach Genus und Numerus verändern, sowie analytische (zusammengesetzte) Verbformen aus Partizip und Hilfsverb. Die verschiedenen neuindoarischen Sprachen unterscheiden sich darin, wie sie diese Möglichkeiten einsetzen, wie an folgendem Vergleich einiger Formen des Verbs für „kommen“ in den wichtigsten neuindoarischen Sprachen deutlich wird:

Die normale Satzstellung ist in allen Sprachstufen des Indoarischen Subjekt-Objekt-Verb (SOV). Im Sanskrit kann diese Wortfolge noch recht frei variiert werden, in den neuindoarischen Sprachen ist die Wortfolge fester reglementiert. Nur zur besonderen Betonung kann ein Satzglied hinter das Verb gestellt werden. Die indoarischen Sprachen teilen auch die übrigen typologischen Merkmale, die für SOV-Sprachen charakteristisch sind: Sie benutzen Postpositionen statt Präpositionen (z. B. Sanskrit "rāmena saha" „mit Rama“) und setzen das bestimmende Element vor das bestimmte. Das bedeutet, dass Attribute ihren Bezugswörtern und Nebensätze Hauptsätzen vorangehen. Beispiele für die SOV-Wortstellung mit Interlinearübersetzung:
Hindi: „Ich gebe dir dieses Buch.“
Bengali: „Ich brachte diese Mangos vom neuen Markt.“
Singhalesisch: „Der Lehrer brachte mir, als ich in der Schule war, die singhalesische Schrift bei.“

Schon im klassischen Sanskrit war die bevorzugte Möglichkeit einen Satz der Vergangenheit auszudrücken, eine Passivkonstruktion mit dem Partizip Perfekt Passiv, bei der die handelnde Person im Instrumental steht (z. B. "bālena kanyā dr̥ṣṭā" wörtl. „das Mädchen [ist] vom Jungen gesehen“ statt "bālaḥ kanyām apaśyat" „der Junge sah das Mädchen“). Diese Konstruktion wird auch auf intransitive Verben ausgeweitet (z. B. "mayā suptam" wörtl. „[es war] von mir geschlafen“ für „ich schlief“). In den neuindoarischen Sprachen hat sich hieraus eine ergativähnliche Konstruktion entwickelt. Charakteristisch hierfür ist, dass bei transitiven Sätzen der Vergangenheit das Subjekt eine spezielle Form annimmt, die als Agentiv bezeichnet wird, während es bei intransitiven Verben und bei Gegenwartssätzen in der Grundform steht. Vergleiche folgende Beispielsätze aus dem Hindi:
„Der Junge kauft das Buch.“
„Der Junge kaufte das Buch.“

Die einheimische Grammatik teilt den Wortschatz der modernen indoarischen Sprachen in vier Kategorien, die mit Sanskrit-Namen bezeichnet werden:

Den Kern der neuindoarischen Lexik bilden die Tadbhava-Wörter, die auf natürlichem Wege aus dem Altindoarischen über die Zwischenstufe der mittelindoarischen Prakrits entlehnt worden und dabei durch eine Reihe von Lautwandeln in ihrer Gestalt verändert worden sind. So geht das Hindi-Wort "khet" („Feld“) über Prakrit "khetta" auf Sanskrit "kṣetra" zurück. Manche Wörter wie "deva" („Gott“) oder "nāma" („Name“) hatten schon im Altindischen eine so einfache Gestalt, dass sie keiner weiteren Veränderung unterlagen. Tadbhava-Wörter können einen ursprünglich nichtindogermanischen Ursprung haben, denn bereits im Sanskrit sind Entlehnungen aus den dravidischen und Munda-Sprachen vorhanden.

Einige indoarische Wortgleichungen

Wörter, die in unveränderter Gestalt (oder besser: Schreibweise) direkt aus dem Sanskrit entlehnt worden sind, bezeichnet man als Tatsamas. Die Aussprache kann dabei durchaus abweichen: die Unterscheidung zwischen bestimmten Lauten wie "ś" und "ṣ" wird meist nicht mehr gewahrt, in Hindi und Marathi fällt das kurze "a" am Wortende oft aus, im Bengali werden Konsonantenverbindungen assimiliert. So wird das Tatsama "ātmahatyā" („Selbstmord“) auf Hindi [], auf Bengali dagegen [] ausgesprochen. Im Singhalesischen werden auch aus dem Pali, das als Sprache des buddhistischen Kanons eine ähnlich wichtige Rolle wie das Sanskrit einnimmt, übernommene Wörter zu den Tatsamas gerechnet. Teils sind Doubletten von Tadbhava und Tatsama-Wörtern vorhanden, wobei das Tatsama dann meist eine spezialisiertere Bedeutung hat. So existiert im Hindi neben dem erwähnten Tadbhava "khet" für ein Feld im konkreten Sinne (d. h. eines, das man pflügen kann) das Tatsama-Wort "kṣetra", das ein Feld im übertragenen Sinne (also ein Beschäftigungsfeld o. Ä.) bezeichnet.

In den modernen indoarischen Literatursprachen (außer denen wie Urdu, die dem kulturellen Einfluss des Islam unterliegen) hat die Verwendung von Sanskrit-Wörtern sehr große Ausmaße angenommen. Vor allem im Wortschatz des höheren Registers finden sich viele Sanskritismen, ähnlich wie in den europäischen Sprachen lateinische und griechische Fremdwörter verwendet werden. Nationalistische Kreise fördern die Verwendung von Sanskritwörtern als ein Symbol des politischen Hinduismus und versuchen in der Schriftsprache auch für neuere Begriffe wie „Elektrizität“ Sanskrit-Neologismen zu etablieren. In der Alltagssprache können sich künstliche Sanskrit-Neologismen aber nur schwerlich gegen englische Lehnwörter durchsetzen.

Zu den Deśya-Wörtern rechnet man Wörter ohne Parallelen im Sanskrit. Hierzu gehören aus altindischen Dialekten ererbte Wörter, die im Sanskrit fehlen, sowie Entlehnungen aus den dravidischen und Munda-Sprachen. Dazu kommen in den neuindoarischen Sprachen in großer Zahl aus außerindischen Sprachen, vor allem dem Persischen, Arabischen, Portugiesischen und Englischen, übernommene Lehnwörter, die die indische Grammatik zur "videśi"-Kategorie rechnet.

Während der etwa achthundertjährigen islamischen Herrschaft in Nordindien war das Persische die Hofsprache der Oberschicht. So gelangten viele persische und über persische Vermittlung auch arabische Wörter in die indoarischen Sprachen. Für Urdu, die Sprache der indischen Muslime, übernimmt das Persisch-Arabische eine ähnliche Rolle als Quelle für Wörter höherer Stilebenen wie Sanskrit für die mehrheitlich von Hindus gesprochenen Sprachen. Dementsprechend groß ist deren Anteil im Urdu, besonders niedrig ist er naturgemäß in Sprachen wie Nepali, Asamiya oder Singhalesisch, die keinem nachhaltigen islamischen Einfluss ausgesetzt waren.

Einen verhältnismäßig kleinen Anteil unter den Fremdwörtern machen Entlehnungen aus dem Portugiesischen, mit der die indischen Sprachen ab dem 16. Jahrhundert durch europäische Seefahrer in Kontakt kamen. Aus der portugiesischen Sprache wurden Wörter wie "chave" für „Schlüssel“ (Hindi "cābhī", Marathi "cāvī"), "janela" für „Fenster“ (Hindi "janglā", Bengali "jānālā", Singhalesisch "janēlaya") oder "mestre" für „Handwerker“ (Hindi "mistrī", Marathi "mestrī") übernommen. Äußerst zahlreich sind seit der britischen Kolonialzeit die englischen Lehnwörter. Vor allem moderne Begriffe wie „Hotel“ ("hoṭal"), „Ticket“ ("ṭikaṭ") oder „Fahrrad“ ("sāikil", von "cycle") wurden aus dem Englischen entnommen.

Die indoarischen Sprachen werden in einer Vielzahl von Schriften geschrieben: verschiedenen indischen Schriften, der persisch-arabischen Schrift und in Einzelfällen der lateinischen Schrift. Dhivehi, die Sprache der Malediven, hat eine gänzlich eigene Schrift, Thaana genannt. Sie wurde im 15. Jahrhundert nach dem Vorbild von arabischen Ziffernzeichen und anderen Elementen geschaffen.

Die meisten für die indoarischen Sprachen verwendeten Schriften gehören ebenso wie die Schriften Südindiens, Südostasiens und Tibets zur Familie der indischen Schriften, die allesamt von der Brahmi-Schrift abstammen. Die Brahmi-Schrift tritt erstmals im 3. Jahrhundert v. Chr. in den Inschriften Kaiser Ashokas zu Tage. Ihre Ursprünge sind ungeklärt, als wahrscheinlich gilt, dass sie nach dem Vorbild des aramäischen Alphabets geschaffen wurde, während die in Indien populäre These einer Abstammung von der Indus-Schrift von westlichen Forschern abgelehnt wird. Im Laufe der Zeit spaltete sich die Brahmi-Schrift in zahlreiche regionale Varianten auf, die grafisch teils sehr stark voneinander abweichen. Strukturell sind sie sich aber sehr ähnlich und teilen alle dasselbe Funktionsprinzip. Es handelt sich bei ihnen um eine Zwischenform aus Alphabet und Silbenschrift, sogenannte Abugidas, bei denen jedes Konsonantenzeichen einen inhärenten Vokal "a" besitzt, der durch diakritische Zeichen modifiziert werden kann. Konsonantenverbindungen werden durch Ligaturen ausgedrückt. Die Reihenfolge der Zeichen ist in den indischen Schriften anders als etwa im lateinischen Alphabet nicht beliebig, sondern spiegelt die Phonologie der indoarischen Sprachen wider. Die Buchstaben werden folgendermaßen angeordnet:

Das Zeicheninventar ist in den verschiedenen Schriften im Wesentlichen dasselbe. Manche Schriften kennen ein spezielles Zeichen für das retroflexe "ḷ", weitere Sonderzeichen könnten durch einen untergesetzten Punkt geschaffen werden.

Folgende indische Schriften werden für indoarische Sprachen verwendet (als Beispiel ist die erste Konsonantenreihe "ka", "kha", "ga", "gha", "ṅa" angegeben):

Sanskrit wurde traditionell in der Schrift der jeweiligen Regionalsprache geschrieben, heute hat sich Devanagari als übliche Schrift für Sanskrit-Texte durchgesetzt. Für manche Sprachen werden parallel mehrere Schriften verwendet: Kashmiri wird in Pakistan in persisch-arabischer Schrift, in Indien in Devanagari geschrieben. Für Panjabi sind sogar drei Schriften im Einsatz: die persisch-arabische in Pakistan, Gurmukhi unter den Sikhs und Devanagari unter den panjabisprachigen Hindus.

Urdu, die Sprache der indischen Muslime, wird ebenso wie die übrigen in Pakistan verwendeten indoarischen Sprachen (Sindhi, Panjabi, Kashmiri) in der persisch-arabischen Schrift, einer um einige Sonderzeichen erweiterten Version des arabischen Alphabets, geschrieben. Die arabische Schrift eignet sich nicht allzu gut für die Wiedergabe indoarischer Sprachen. Zum einen werden kurze Vokale nicht ausgedrückt und auch bei den langen Vokalen kann etwa nicht zwischen "ū", "ō" und "au" unterschieden werden. In arabischen Lehnwörtern kommen redundante Buchstaben vor, die gleich ausgesprochen werden (z. B. Sin, Sad und Tha alle als "s"). Für andere Laute, die in den indoarischen Sprachen vorkommen, existieren in der arabischen Schrift aber keine Zeichen, so dass diese mithilfe von diakritischen Zeichen neu geschaffen werden mussten (z. B. "ṭ", "ḍ" und "ṛ" für die retroflexen Laute im Urdu). Bei der Bildung dieser Sonderzeichen weisen die Alphabete von Urdu und Sindhi Unterschiede auf (so sind die Retroflexe in Sindhi "ṭ", "ḍ" und "ṛ"), während sich Panjabi und Kashmiri an der Urdu-Orthografie orientieren. Auch verwendet Sindhi für die aspirierten Konsonanten eigene Sonderzeichen, während sie im Urdu durch die Kombination des nichtaspirierten Konsonanten und "h" ausgedrückt werden (z. B. Sindhi und Urdu für "th"). Weiterhin unterscheidet sich Urdu durch die Verwendung des geschwungenen Nastaliq-Duktus von Sindhi, das man vorzugsweise im simpleren Naskhi schreibt.

Die einzigen indoarischen Sprachen, die regulär in lateinischer Schrift geschrieben werden, sind Konkani und Romani. Für Konkani, die Sprache Goas, wurde im 16. Jahrhundert eine Orthografie auf Grundlage des Portugiesischen geschaffen. Daneben wird Konkani auch in Devanagari-Schrift geschrieben. Für Kalasha, die bislang illiterate Sprache der Kalasha von Chitral, wird seit neuestem im Schulunterricht das lateinische Alphabet verwendet.

Im wissenschaftlichen Kontext ist die lateinische Transliteration gebräuchlich. Der übliche Standard ist das "International Alphabet of Sanskrit Transliteration" (IAST). In der Darstellung der Konsonanten orientiert sie sich am Lautwert der Buchstaben im Englischen, deshalb wird z. B. "y" für [j] geschrieben. Aspirierte Konsonanten werden durch die Digraphen "kh", "th" etc. ausgedrückt. Andere Laute, für die es keinen entsprechenden lateinischen Buchstaben gibt, drückt die IAST-Transliteration durch diakritische Zeichen aus, etwa das Makron zur Kennzeichnung von Langvokalen oder untergesetzte Punkte für retroflexe Laute.


"Allgemein"

"Indoarisch – in chronologischer Folge"



</doc>
<doc id="10758" url="https://de.wikipedia.org/wiki?curid=10758" title="Tibetobirmanische Sprachen">
Tibetobirmanische Sprachen

Die tibetobirmanischen Sprachen stellen einen der beiden Hauptzweige der sinotibetischen Sprachfamilie dar, der andere Zweig ist das Sinitische. Die etwa 330 tibetobirmanischen Sprachen werden in Südchina, dem Himalayagebiet und Südostasien von zusammen knapp 70 Millionen Menschen gesprochen. (Demgegenüber besitzen die acht chinesischen Sprachen zusammen 1,2 Mrd. Sprecher.)

Die mit Abstand sprecherreichste tibetobirmanische Sprache ist das Birmanische mit ungefähr 35 Millionen Muttersprachlern und weiteren 15 Mio. Zweitsprechern in Birma.

Folgende tibetobirmanische Sprachen haben mindestens eine Million Sprecher:


Der Artikel enthält im Anhang eine Tabelle mit allen tibetobirmanischen Sprachen, die mindestens 500.000 Sprecher haben. Der angegebene Weblink enthält sämtliche tibetobirmanische Sprachen mit Klassifikation und Sprecherzahl.

Die interne Klassifikation der etwa 330 tibetobirmanischen Sprachen kann heute keineswegs als gesichert gelten. Zwar hat sich die Forschung auf eine Reihe kleinerer genetischer Einheiten einigen können – darunter "Tibetisch", "Kiranti", "Tani", "Bodo-Koch", "Karenisch", "Jingpho-Sak", "Kuki-Chin" und "Birmanisch" –, jedoch konnte die Frage nach mittleren und größeren Untergruppen, die diese kleineren Einheiten zusammenfassen, bisher nicht konsensfähig geklärt werden. Die Gründe sind fehlende Detailforschungen, Grammatiken und Lexika bei vielen tibetobirmanischen Einzelsprachen, intensive wechselseitige areale Beeinflussungen, die die genetischen Zusammenhänge verdunkeln, und die große Anzahl der zu vergleichenden Sprachen.

Während Matisoff 2003 die Zusammenfassung recht großer Einheiten „wagt“, tendiert van Driem 2001 zum anderen Extrem: er gliedert das Tibetobirmanische in viele kleine Untergruppen und macht nur vage Angaben über umfassendere Verwandtschaftsverhältnisse. Einen mittleren Weg geht Thurgood 2003. Die Darstellung des vorliegenden Artikels basiert – was die Zwischeneinheiten angeht – vor allem auf Thurgood, für die Detailgliederung auf dem umfangreichen Werk van Driem 2001, in dem sämtliche inzwischen bekannten tibetobirmanischen Sprachen und ihre engeren Verwandtschaftsverhältnisse behandelt werden. Insgesamt ergibt sich eine relativ kleinteilige Gliederung des Tibetobirmanischen in genetisch gesicherte Einheiten.

Auf Grund der angeführten aktuellen Forschungslage lässt sich die folgende interne Gliederung des Tibetobirmanischen begründen, wenn auch noch nicht über alle Untereinheiten ein vollständiger Konsens erzielt wurde:

Interne Gliederung des Tibetobirmanischen


Die folgende Tabelle gibt eine statistische und geographische Übersicht über die Untereinheiten des Tibetobirmanischen. Die Daten beruhen auf dem unten angegebenen Weblink „Klassifikation der sinotibetischen Sprachen“. Die Anzahl der Sprachen ist deutlich niedriger als in Ethnologue, da Ethnologue – entgegen der mehrheitlichen Forschungsmeinung – viele Dialekte zu eigenständigen Sprachen erklärt. Die hier verwendeten Daten (Anzahl der Sprachen, Sprecherzahlen) basieren vor allem auf der detaillierten Darstellung in van Driem 2001. 

Die Untereinheiten des Tibetobirmanischen"mit Anzahl der Sprachen und Sprecher und ihren Hauptverbreitungsgebieten"

"Die Primärzweige des Tibetobirmanischen sind halbfett gedruckt, dahinter folgen jeweils die Untereinheiten."

Der Artikel Sinotibetische Sprachen enthält eine ausführliche Diskussion über die Gültigkeit der hier dargestellten und weiterer von der Forschung vorgeschlagener Untereinheiten des Tibetobirmanischen.

Das Tibetobirmanische bildet innerhalb des Sinotibetischen eine genetische Einheit. Die tibetobirmanischen Proto-Formen konnten in großem Umfang rekonstruiert werden (Matisoff 2003). Das gemeinsame lexikalische Material ist äußerst umfangreich und wird durch die Erforschung weiterer Sprachen zunehmend zuverlässiger (siehe die Tabelle der Wortgleichungen). Neben dem lexikalischen Material gibt es genügend phonologische und grammatische Gemeinsamkeiten, die die genetische Einheit des Tibetobirmanischen absichern.

Das Proto-Tibetobirmanische war – wie das Proto-Sinotibetische – eine durchgehend monosyllabische Sprache. Seine Silbenstruktur lässt sich als

rekonstruieren (potentielle Slots sind durch (.) gekennzeichnet). Die ersten beiden Konsonanten sind ursprünglich bedeutungsrelevante „Präfixe“, die eigentliche Wurzel hat die Form K(G)V(K), der Schlusskonsonant muss aus der Gruppe /p,t,k,s,m,n,ŋ,l,r,w,j/ stammen, vokalischer Auslaut ist selten. Der Vokal kann kurz oder lang sein, die Länge ist phonemisch. Zwischen den Präfixkonsonanten und dem Initialkonsonant kann ein schwacher Vokal /ə/ stehen (ein sogenanntes Schwa). Diese ursprüngliche Silbenstruktur ist im klassischen Tibetisch und einigen modernen westtibetischen Sprachen und im Gyalrong belegt (die deswegen für die Rekonstruktion besonders wichtig sind), weniger vollständig im Jingpho und Mizo. Die komplexen Initialcluster sind in vielen Sprachen reduziert worden. Diese Strukturvereinfachung führte offensichtlich häufig zur Ausbildung differenzierender Töne.

Nach Benedict 1972 und Matisoff 2003 bestand das Konsonanteninventar des Proto-Tibetobirmanischen – das vor allem für die Initialkonsonanten der Wurzel im vollen Umfang genutzt wurde – aus folgenden Phonemen:

Als Initialkonsonant der Wortwurzel fanden diese Phoneme in einzelnen Gruppen folgende reguläre Lautentsprechungen:

Die alternativen Entsprechungen sind in der Regel sekundär, Aspiration kann unter bestimmten Bedingungen auftreten, sie ist nicht phonemisch. Basis der obigen Tabelle ist Benedict 1972, wo für diese Lautentsprechungen geeignete Wortgleichungen aufgeführt werden.

Das tibetobirmanische "Vokalsystem" wurde als /a, o, u, i, e/ rekonstruiert. Vokale können in der Protosprache in der Silbenmitte und im Silbenauslaut erscheinen, nicht am Silbenanfang. Allerdings sind andere Vokale als /a/ im Silbenauslaut der Protosprache sehr selten zu finden. Dagegen sind Endungen auf /-Vw/ und /-Vj/ besonders häufig.

Eine klassische relationale Morphologie (also eine systematische morphologische Veränderung der Nomina und Verben mit Kategorien wie Kasus, Numerus, Tempus-Aspekt, Person, Diathese u. a.) hat es nach einhelliger Meinung der Forschung in der Protosprache nicht gegeben. Die heute bei den tibetobirmanischen Sprachen feststellbare relationale Morphologie der Nomina und Verben ist als Innovation zu betrachten, die auf areale Einflüsse benachbarter Sprachen oder auf die Wirkung von Substraten zurückzuführen ist. Infolge sehr unterschiedlicher Einflüsse konnten sich sehr verschiedene morphologische Typen herausbilden.

Mit Sicherheit lassen sich aber Elemente einer Derivationsmorphologie für das Proto-Tibetobirmanische rekonstruieren, deren Reflexe in vielen tibetobirmanischen Sprachen nachzuweisen sind. Dabei handelt es sich um konsonantische Präfixe und Suffixe sowie Anlautalternationen, die die Bedeutung von Verben aber auch von Nomina modifizieren. Die Existenz gemeinsamer Derivationsaffixe und Anlautalternationen mit identischer oder ähnlicher semantischer Wirkung in fast allen Gruppen des Tibetobirmanischen ist ein starkes Indiz für seine genetische Einheit. 

s-Präfix

Das s-Präfix hat eine kausative und denominative Funktion, der ursprünglich eine allgemeinere „direktive“ Bedeutung zu Grunde liegt. Beispiele:


In anderen tibetobirmanische Sprachen (z. B. Birmanisch, Lahu, Lolo-Sprachen) ging das s-Präfix verloren, hat aber Veränderungen des Initialkonsonanten oder tonale Differenzierungen bewirkt. Bei schwachen Initialkonsonanten kann aber auch in diesen Sprachen noch ein s-Präfix erkennbar sein, zum Beispiel


Anlautalternierung

In nahezu allen tibetobirmanischen Sprachen gibt es Paare semantisch verwandter Wörter, die sich lautlich nur darin unterscheiden, dass der Anlautkonsonant "stimmlos" oder "stimmhaft" ist. Die stimmlose Variante hat dann in der Regel eine "transitive", die stimmhafte eine "intransitive" Bedeutung. Es gibt die Theorie, dass die Anlautveränderung durch ein ursprüngliches *h-Präfix – einen nicht-syllabischen, pharyngalen Gleitlaut – bewirkt worden sei (Pulleyblank 2000). 

Diesen Kontrast gibt es jedoch nicht im Tibetischen. Sowohl intransitive wie auch transitive Verbwurzeln können einen stimmhaften oder einen stimmlosen Anlaut haben, gelegentlich gibt es auch alte stimmlos-stimmhafte intransitive Paare, z.B. sowohl "gang" als auch "ḥkheng, khengs" „vollwerden, s. füllen“. Das transitive Gegenstück ist entweder "ḥgengs, bkang, dgang, khengs" (zu "gang") oder "skong, bskangs, bskang, skongs" (zu "kheng, khengs"). 

Beispiele:


n-Suffix

Das n-Suffix (auch in der Variante /-m/, im Tibetischen häufig auch /-d/) hat primär eine nominalisierende, manchmal auch eine kollektivierende Funktion. Beispiele:


s-Suffix

Auch das s-Suffix hatte im Tibetischen mehrere Funktionen, die aber nicht mehr produktiv sind

1. resultativ bzw. vergangenheitsbildend bei Adjektivalen und Verben

z.B. "che" „groß werden“, "ches" „groß geworden sein“

2. als Kollektivbilder (ähnlich dem dt. Ge- in Gebirge), insbesondere noch in Komposita bis ins Alttibetische bewahrt

z.B. "rnam" „Einheit, Teil“ > "rnams" als Pluralmorphem, "sku" „(höfl.) Körper, Person“ + "srung" „schützen“ > "skusrungs" „(Kollektiv der) Leibgarde“ eine militärische Spezialeinheit 

Weitere Derivationssuffixe

Außer den genannten gibt es noch andere für das Tibetobirmanische postulierte Derivationssuffixe, z. B. /-t/, /-j/ und /-k/. Für keines dieser Suffixe lässt sich aber bisher eine befriedigende Funktionsbeschreibung angeben, die zumindest in einigen Einheiten des Sinotibetischen gültig wäre. Für weitere Details wird auf LaPolla (in Thurgood 2003) und Matisoff 2003 verwiesen.

Die folgenden Wortgleichungen zeigen besonders deutlich die genetische Verwandtschaft der tibetobirmanischen Sprachen. Sie basieren auf Peiros-Starostin 1996, Matisoff 2003 und der unten angegeben Internet-Datenbank Starostins. Für die Wortauswahl wird die Liste der „stabilen Etymologien“ von Dolgopolsky und einige Wörter aus der Swadesh-Liste zugrunde gelegt, wodurch Lehnwörter und Lautmalereien weitgehend ausgeschlossen sind. Jede Wortgleichung hat Vertreter aus bis zu fünf Sprachen bzw. Spracheinheiten: Klassisches Tibetisch, Klassisches Birmanisch, Jingpho (Kachin), Mizo (Lushai), Lepcha, Proto-Kiranti (Rekonstruktion Starostin) und Proto-Tibetobirmanisch (Matisoff 2003). Die Transkription erfolgt ebenfalls nach Matisoff und der zugrunde gelegten Datenbank.

Tibetobirmanische Wortgleichungen

Die folgende Tabelle enthält alle tibetobirmanischen Sprachen mit mindestens 500.000 Sprechern. Angegeben sind die Sprecherzahlen, die Klassifikation und geographische Verbreitung dieser Sprachen. Diese Daten basieren auf dem unten angegeben Weblink.

Die tibetobirmanische Sprachen mit mindestens 500.000 Sprechern





</doc>
<doc id="10760" url="https://de.wikipedia.org/wiki?curid=10760" title="Weltdokumentenerbe">
Weltdokumentenerbe

Das Weltdokumentenerbe ist ein Verzeichnis im Rahmen des 1992 von der UNESCO gegründeten Programms Memory of the World (MOW, für "Gedächtnis der Welt") . Dieses Programm dient dazu, den freien Zugang zu bedeutsamen Dokumenten zu sichern und das dokumentarische Erbe zu bewahren.

1997 wurden die ersten Dokumente in das Register eingetragen. Aufgenommen werden sollen wertvolle Buchbestände, Handschriften, Partituren, Unikate, Bild-, Ton- und Filmdokumente, . Die Ernennung ist keine finanzielle Unterstützung, sondern soll als Auszeichnung verstanden werden: Die Heimatstaaten verpflichten sich – wie bei den anderen Welterbe-Programmen – mit der Nominierung, im Dienste der internationalen Staatengemeinschaft für die des jeweiligen dokumentarischen Erbes zu sorgen.

Das Programm "Memory of the World" wird mit der "Charta zum Erhalt des Digitalen Kulturerbes" 2003 zur Frage der Langzeitarchivierung digitalisierter Dokumente sowie von ausschließlich digital vorhandenen Materialien fortgesetzt.

Staaten können alle zwei Jahre bis zu zwei Dokumente zum neuen Eintrag in die Liste nominieren, über deren Aufnahme dann ein internationales Beratergremium entscheidet. Aktuell umfasst die Liste des Weltdokumentenerbes 348 Dokumente .




</doc>
<doc id="10761" url="https://de.wikipedia.org/wiki?curid=10761" title="Legislative">
Legislative

Die Legislative (spätantik ‚Beschließung des Gesetzes‘, von ,Gesetz‘ und ,tragen‘, davon das PPP ,getragen‘; auch gesetzgebende Gewalt) ist in der Staatstheorie neben der Exekutive (ausführenden Gewalt) und Judikative (Rechtsprechung) eine der drei – bei Gewaltenteilung voneinander unabhängigen – Gewalten. Die Legislative ist zuständig für die Beratung und Verabschiedung von Gesetzen (Gesetzgebung) im inhaltlichen und formellen Sinn sowie für die Kontrolle der Exekutive und der Judikative, wobei sie in Österreich nur die Exekutive kontrolliert und die Judikative unabhängig bleibt. In einer repräsentativen Demokratie bilden die Parlamente die Legislative. In Staaten mit Elementen direkter Demokratie tritt im Einzelfall auch das Volk als Gesetzgeber auf (Volksgesetzgebung).

In Deutschland wird die Legislative wie folgt ausgeübt:

Die Gesetzgebung ist an die verfassungsmäßige Ordnung gebunden.

Auf Ebene der Kreise und Gemeinden gibt es nach herrschender Meinung keine Legislative, da es sich bei den Kommunen insgesamt aus staatsrechtlicher Sicht lediglich um Selbstverwaltungskörperschaften innerhalb der Landesexekutive handele. Gemeinderäte sind nach dieser Ansicht mithin auch keine Parlamente; die Selbstverwaltungsorgane der Gemeinde seien lediglich Verwaltungsorgane, denen es an legislativen Befugnissen mangele. Wesentliches Indiz hierfür sei neben dem Fehlen der Judikative die landesgesetzliche Vorgabe einer Gemeindeordnung an Stelle einer selbst gewählten Verfassung. Die Mitglieder der Organe genießen auch nicht den für Abgeordnete von Parlamenten verfassungsgemäß garantierten Schutz der Immunität und Indemnität. Die Entscheidungen dieser Organe können zudem durch die Kommunalaufsicht aufgehoben oder ersetzt werden.

Die Vertreter der Gegenmeinung argumentieren wie folgt:

In der Schweiz bildet sich die Legislative auf Bundesebene aus der vereinigten Bundesversammlung, bestehend aus Nationalrat und Ständerat. Auf Kantonsebene bildet der Kantonsrat (je nach Kanton auch Grosser Rat oder Landrat genannt) die Legislative. Die gesetzgebende Gewalt auf Gemeindeebene ist die Gemeindeversammlung oder der Einwohnerrat (je nach Gemeinde auch [Grosser] Gemeinderat, [Grosser] Stadtrat oder Generalrat genannt).

In Österreich bilden der Nationalrat und der Bundesrat die Legislative auf Bundesebene. Auf Landesebene ist die gesetzgebende Gewalt der Landtag.

Als föderaler Staat üben die USA auf nationaler Ebene ihre gesetzgebende Gewalt durch den Kongress ("i. e." das Parlament der USA) aus und auf subnationaler Ebene durch die Parlamente der einzelnen Bundesstaaten (→ "State Legislature").
Das Verfahren zur Verabschiedung von Bundesgesetzen (für deren Erlassung sämtlich der Kongress (zusammen mit dem US-Präsidenten) zuständig ist) ist in der US-Verfassung festgeschrieben; für das Verfahren bei Gesetzen, die in die Zuständigkeit eines Bundesstaats fallen, ist "dessen" jeweilige Verfassung maßgeblich.

Sowohl der Kongress als auch die Parlamente der Bundesstaaten (außer das von Nebraska) verfügen über jeweils zwei Kammern.

Die Legislative des Vereinigten Königreichs Großbritannien und Nordirland wird ausgeübt durch das Parlament, das formal aus drei Teilen besteht: Krone, Oberhaus und Unterhaus.

In Frankreich bildet die Nationalversammlung zusammen mit dem Senat die Legislative. Beide Kammern sind gleichberechtigt. Bei Uneinigkeit kann aber die Nationalversammlung den Senat überstimmen. Dieser besitzt ein Vetorecht bei Verfassungsänderungen.

Supranationale legislative Funktionen werden in der Europäischen Union durch den Rat der Europäischen Union sowie das Europäische Parlament ausgeübt. Dabei kommt jedoch der Europäischen Kommission durch ihr Initiativrecht eine Schlüsselkompetenz zu, obwohl die Kommission gewöhnlich der Exekutive zugeordnet wird.



</doc>
<doc id="10762" url="https://de.wikipedia.org/wiki?curid=10762" title="Sinustachykardie">
Sinustachykardie

Als Sinustachykardie wird in der Medizin eine beschleunigte Herzfrequenz bezeichnet, wenn die elektrische Erregung auf normale Weise im Sinusknoten entsteht und durch das Erregungsleitungssystem zum Herzmuskel geleitet wird. Beim erwachsenen Menschen wird eine Herzfrequenz von mehr als 100 Schlägen pro Minute in Ruhe als Tachykardie eingestuft.

Bei Säuglingen und Kleinkindern, bei körperlicher Anstrengung oder psychischer Belastung wird eine Sinustachykardie als physiologisch, also ohne Krankheitswert, angesehen.

Die pathologische (krankhafte) Sinustachykardie wird unterschieden in primäre und sekundäre Form. Die primäre Form hat keine erkennbare Ursache. In Einzelfällen liegt ihr eine kreisende Erregung im Vorhof zu Grunde, die durch ihre Nähe zum Sinusknoten im Elektrokardiogramm (EKG) das Bild einer Sinustachykardie erzeugt (Sinusknoten-Reentry).

Die sekundäre Sinustachykardie entspricht häufig einem Kompensationsmechanismus, unter anderem bei Volumenmangel (z. B. bei Exsikkose oder nach großem Blutverlust), Anämie, Fieber, Lungenembolie, Herzinsuffizienz oder Myokarditis. Sie kann außerdem Ausdruck einer hormonellen Fehlregulation im Rahmen einer Schilddrüsenüberfunktion oder eines Phäochromozytoms sein. Auch Arzneimittel (z. B. Sympathomimetika bei Asthma bronchiale) sowie Genuss- und Rauschmittel wie Coffein oder Ecstasy können zu einer Sinustachykardie führen.

Die Diagnose einer Sinustachykardie wird anhand des Elektrokardiogramms gestellt. Dabei geht jeder Kammeraktion (QRS-Komplex) eine Vorhoferregung (P-Welle) voraus. Differentialdiagnostisch muss Vorhofflattern und eine AV-Knoten-Reentry-Tachykardie in Erwägung gezogen werden.

Für die Therapie ist das Erkennen und die Behandlung der Ursache entscheidend. Eine rein symptomatische Therapie sollte nicht erfolgen. Bei primärer Sinustachykardie werden zur Frequenzsenkung zum Beispiel Betablocker eingesetzt.


</doc>
<doc id="10763" url="https://de.wikipedia.org/wiki?curid=10763" title="Männliches Geschlecht">
Männliches Geschlecht

Das männliche Geschlecht ist bei der zweigeschlechtlichen Fortpflanzung dasjenige Geschlecht, das die größere Menge an Keimzellen (Samenzellen) bereitstellt, mit denen die weiblichen Keimzellen (Eizellen) befruchtet werden und einen oder mehrere Nachkommen (Mehrlinge) entstehen lassen. Es wird mit dem Marssymbol ♂ gekennzeichnet.

Viele Tiere und Pflanzen benötigen zwei Geschlechter zu ihrer Fortpflanzung: das männliche (maskuline) "und" das weibliche (feminine) Geschlecht – im Unterschied zu Arten mit Selbstbefruchtung. Die Zweigeschlechtlichkeit hat sich im Laufe der Evolution mehrmals unabhängig voneinander entwickelt. Unterscheiden sich beide Keimzellen nicht nach Größe oder Form, liegt eine Isogamie vor.

Eine "Vermännlichung" liegt vor, wenn bei einem Lebewesen im Laufe seiner Entwicklung Eigenschaften deutlicher werden, die den männlichen Phänotypen seiner Spezies entsprechen.

Beim Menschen wird das männliche Geschlecht durch drei Kennzeichen (Geschlechtsmerkmale) bestimmt:

Bei menschlicher Intersexualität sind die primären Geschlechtsmerkmale weniger stark ausgeprägt und es sind teilweise daneben auch weibliche Geschlechtsmerkmale vorhanden. Im Laufe des Lebens bilden sich vor allem die sekundären Geschlechtsmerkmale wie der Bartwuchs heraus. Männlichkeit wird - abhängig vom kulturellen Umfeld - vor allem durch soziale Rollenverständnisse geprägt (siehe auch Mann).

Bei Tieren bestimmen unterschiedliche körperliche und genetische Mechanismen das Geschlecht eines Individuums:


Bei Samenpflanzen wird danach unterschieden, ob ein Pflanzenindividuum



</doc>
<doc id="10765" url="https://de.wikipedia.org/wiki?curid=10765" title="Pfeilschwanzkrebse">
Pfeilschwanzkrebse

Die Pfeilschwanzkrebse (Limulidae) (auch Molukkenkrebse, Hufeisenkrebse) bilden die einzige rezente Familie innerhalb der Ordnung der Schwertschwänze (Xiphosura). Die Schwertschwänze sind eine basale Gruppe der Kieferklauenträger, möglicherweise die Schwestergruppe aller (rezent) landlebenden Spinnentiere (alle außer den Asselspinnen). Ihre Stellung innerhalb der ausgestorbenen, nur fossil erhaltenen Gruppen wird weiterhin kontrovers diskutiert. Ihre Vereinigung mit den (ausgestorbenen) Seeskorpionen (Eurypterida) in einem Merostomata genannten Taxon galt jahrzehntelang als die Standardhypothese, wird jedoch heute als unwahrscheinlich betrachtet.

Der Körper der Xiphosuren ist untergliedert in das hufeisenförmige Prosoma und das kleinere Opisthosoma. Letzteres ist seinerseits untergliedert in Mesosoma aus sieben verschmolzenen Segmenten sowie dem aus drei Segmenten bestehenden Metasoma, das in den namensgebenden spitzen, beweglichen Schwanzstachel endet. Vorder- und Hinterkörper sind durch ein Gelenk verbunden, das im Gegensatz zu den Spinnentieren nicht der Verbindung zwischen Pro- und Opisthosoma entspricht. Das erste und Teile des zweiten Opisthosomasegments sind dem Vorderkörper angegliedert. Die Cuticula ist dick, fest und frei von Kalkeinlagerungen.

Laufen Pfeilschwanzkrebse, so werden die Beine alternierend bewegt. Während des Schwimmens, mit der Ventralseite nach oben, schlagen die Beine synchron. Der Schwanzstachel dient als Hilfe beim Umdrehen, wenn die Tiere auf dem Rücken liegen, sowie als Steuer. Das Prosoma besitzt fünf aus je sechs Segmenten bestehende Beinpaare, die der Fortbewegung dienen. Die ersten vier Paare tragen eine Schere, das fünfte hat basal Borsten. Nur das fünfte Beinpaar besitzt einen blattförmigen Epipodit, der als Flabellum bezeichnet wird. Er dient in erster Linie der Lenkung des Wasserstroms in den Kiemenraum, hat aber wahrscheinlich auch eine sensorische Funktion. Die Scheren des ersten und zweiten Beinpaares der erwachsenen Männchen sind im Vergleich zu jenen der Weibchen vergrößert und dienen als Klammerorgane während der Paarung. Hinter dem fünften Beinpaar befindet sich ein Paar kleiner, beweglicher Anhänge, die Chilaria. Diese gehen vermutlich auf ein weiteres, rückgebildetes Beinpaar zurück; viele fossile Arten besaßen an dieser Stelle ein weiteres Beinpaar. Vor den Beinen befinden sich die dreigliedrigen, klauenartigen Cheliceren, die als Mundwerkzeuge dienen. An den Coxen der Beine befinden sich nach innen gerichtete, gestachelte Endite (Coxalladen), die Nahrungsteile vom Mundvorraum zum Mund befördern. Dieser liegt zwischen den Coxen der Beinpaare und somit in der Mitte der Ventralseite des Vorderkörpers. Der Hinterkörper besteht bei Ansicht von oben aus einer großen, hinten oft bestachelten Rückenplatte, einer kleinen Rückenplatte (Tergum oder Thoracetron), die aus drei verschmolzenen Segmenten besteht, und dem Schwanzstachel. Er besitzt sechs Paare plattenförmiger Extremitäten. Die erste davon, Operculum genannt, trägt die paarigen Geschlechtsöffnungen. An den Segmenten drei bis sieben des Opisthosoma befinden sich an den Außenästen der Extremitäten insgesamt fünf Paare Buchkiemen, die aus bis zu 150 dicht übereinander liegenden Lamellen bestehen. Der dreigliedrige Telepodit an diesen Extremitäten dient der Reinigung der Kiemen.

Den zwei oben an den Seiten des Rückenschilds sitzenden Komplex- bzw. Facettenaugen fehlen die Kristallkegel; sie sind somit einfacher gebaut als die der Mandibeltiere (Mandibulata). Mittig auf dem Prosoma liegen dorsal die sogenannten Medianaugen. Sie bestehen aus je einer Linse. Von außen nicht sichtbar liegt unterhalb der Medianaugen ein zweites reduziertes Augenpaar, die Endoparietalaugen. An der Basis der Oberlippe, dicht vor dem Gehirn befindet sich ein drittes Augenpaar. Während jenes bei den Larven noch gut entwickelt ist, verschmilzt es später mit dem Frontalorgan, das wohl den Chemorezeptor darstellt.

Gonaden befinden sich im Prosoma und münden an den verschmolzenen Extremitäten des zweiten Segments des Opisthosoma, dem Genitaloperculum. Spermien der Xiphosuren zählen zu den ursprünglichsten der Arthropoden.

Pfeilschwanzkrebse werden bis zu 85 cm lang. Ihre Färbung reicht von dunkel-rotbraun bis schwarzbraun.

Normalerweise leben Pfeilschwanzkrebse auf dem Meeresboden, können aber auch mit der Bauchseite nach oben schwimmen. Sie ernähren sich von Muscheln und anderen Weichtieren sowie Aas, das sie im Boden finden und mit der Chelicere oder den Beinen zum Mundvorraum führen. Alle bekannten Arten können sich einrollen und so vor Feinden schützen. Durch wiederholtes Zusammenrollen und Auseinanderklappen können die Tiere sich im weichen Sand eingraben. Zur Paarungszeit kommen sie nahe ans Ufer. Die charakteristischen Fährten von Pfeilschwanzkrebsen sind oft auch fossil leicht identifizierbar, da sich die Endglieder der ersten vier Laufbeinpaare von denen des fünften Beinpaares unterscheiden und zudem meist die Schleifspur des Schwanzstachels zu erkennen ist. Diese Spurenfossilien heißen Kouphichnium.

Pfeilschwanzkrebse kommen an den flachen Sandküsten tropischer Meere in Tiefen zwischen 10 und 40 Metern vor. Die Art "Limulus polyphemus" ist an der amerikanischen Atlantikküste verbreitet. "Carcinoscorpoius rotundicauda" sowie die beiden Arten "Tachypleus gigas" und "Tachypleus tridentatus " leben in Südostasien.

Die geschlechtsreifen Tiere sammeln sich im Frühsommer im Gezeitenbereich an den flachen Küsten ihrer Heimatmeere, wo sich die Männchen mit Hilfe ihrer entsprechend gestalteten Vorderbeine auf den Weibchen festkrallen. Diese legen ihre 200 bis 1000 Eier in eine flache Sandmulde, wo sie dann besamt und zugedeckt werden.

Die erste freischwimmende Larve der Pfeilschwanzkrebse wird aufgrund ihrer Form als Trilobitenlarve bezeichnet. Sie besitzt bereits alle Segmente, jedoch nur 9 Paar Extremitäten. Die restlichen Beinpaare sowie den Schwanzstachel erhalten sie nach der ersten Larvenhäutung, geschlechtsreif werden die Tiere nach 9 bis 12 Jahren.

Die Pfeilschwanzkrebse sind seit dem Ordovizium bekannt und hatten vom Silur bis ins Jura ihre Blütezeit. Rezent ist die Familie nur noch mit vier Arten aus drei Gattungen vertreten.

Fast identische Formen sind aus dem Mesozoikum bekannt, weshalb die Pfeilschwanzkrebse oft als lebende Fossilien bezeichneten werden.

Neben den Pfeilschwanzkrebsen wurden auch die ausgestorbenen Seeskorpione (Eurypterida) häufig zu den Merostomata gestellt. Neuere phylogenetische Analysen, anhand der kladistischen Methodik, lassen diese Position unwahrscheinlich erscheinen. Die meisten gemeinsamen Merkmale der fossilen Formen sind vermutlich Symplesiomorphien (gemeinsame Stammgruppen-Merkmale), die sich aus der aquatischen Lebensweise ergeben haben. Vermutlich waren die Seeskorpione daher tatsächlich näher mit den Spinnentieren verwandt. Ihre Stellung zu weiteren, allesamt ausgestorbenen Gruppen wie den Chasmataspidida ist nicht völlig geklärt. Zudem existieren im Kambrium wohl zahlreiche Stammgruppenvertreter der Kieferklauenträger mit oberflächlich sehr ähnlich aussehendem Körperbau, deren genaue Verwandtschaft ungeklärt ist; vermutlich würde aber ihre Einbeziehung in die Xiphosura diese paraphyletisch machen. Die ältesten Pfeilschwanzkrebse im engeren Sinne, wie die Gattung "Lunataspis" stammen damit wohl aus dem Ordovizium. Die Zusammenfassung der basalen Formen in einem Taxon Synziphosurina gilt heute ebenfalls als überholt. Die nähere Verwandtschaft der rezenten Formen, die Familie Limulidae, könnte aus dem Perm stammen. Die rezenten Gattungen haben sich, der Methodik der molekularen Uhr zufolge, vielleicht schon in der frühen Kreide getrennt. Die ostasiatischen Gattungen sind miteinander näher verwandt als jeweils mit der amerikanischen Gattung "Limulus".

In den 1970er-Jahren wurde ein erster in vitro-Test zum Nachweis pyrogener Stoffe entwickelt. Für diesen Test wird dem Pfeilschwanzkrebs sein durch den Sauerstoff-Transporter Hämocyanin blau gefärbtes Blut abgenommen. Das Verfahren dient zum Nachweis von bakteriellen Endotoxinen (Lipopolysacchariden), die nach dem sterilisationsbedingten Zerfall von Bakterien aus den Zellwänden in oder auf dem Medium (Injectabilia, medizinische Geräte) entstehen. Das Blut der Pfeilschwänze reagiert auf diese bakteriellen Zerfallsstoffe (Endotoxin) und gerinnt dabei zu einem Gel. 

Der Limulus-Amöbozyten-Lysat-Test (LAL-Test) misst die Gerinnung eines aus Blutzellen (Amöbozyten) des Pfeilschwanzkrebses gewonnenen Lysates, ausgelöst durch Endotoxin. Nach der Aktivierung der Faktoren C und B durch Lipopolysaccharid aktiviert ein Gerinnungsenzym die Koagulation, welche dann turbidimetrisch oder mit Hilfe einer Farbreaktion bewertet wird.

Teilweise werden Pfeilschwanzkrebse zur Lysatgewinnung getötet, was auf heftige Kritik stößt. Dies insbesondere, weil es möglich und vielerorts üblich ist, die Blutentnahme vorzunehmen, ohne die Tiere zu schädigen (Verluste von 15 % oder weniger).



</doc>
<doc id="10766" url="https://de.wikipedia.org/wiki?curid=10766" title="Warane">
Warane

Die Warane (lat. "Varanus") bilden eine etwa 80 Arten umfassende Gattung der Schuppenkriechtiere (Squamata) aus der Teilordnung der Schleichenartigen (Anguimorpha). Sie kommen in den tropischen und subtropischen Gebieten von Afrika, Asien und Australien vor und bewohnen eine Vielzahl von Lebensräumen. Die meisten Warane sind lang gestreckte Echsen mit spitz zulaufendem Kopf und einem langen Schwanz. Je nach Art wird eine Länge von 20 cm bis 3 m erreicht. Die größten heute lebenden Echsen gehören der Gattung der Warane an. Ein auffallendes Merkmal der Warane ist die lange und an der Spitze tief gespaltene Zunge; sie dient beim Züngeln der geruchlichen Wahrnehmung, welche bei Waranen der wohl wichtigste Sinn ist.

Alle Warane sind tagaktiv und verbringen die Nacht je nach Art in selbst gegrabenen Bauen, Baumhöhlen oder ähnlichen Unterschlüpfen. Die saisonale Aktivität von vielen Waranen wird von der Trockenzeit in ihren Lebensräumen geprägt. Während dieser Zeit mangelt es an Nahrung, und die Warane überdauern die Trockenzeit in einem Versteck.

Es gibt sowohl bodenbewohnende und baumbewohnende als auch teils wasserbewohnende (semiaquatische) Arten. Durch besondere Anpassungen von Herz, Lunge und Ventilation können Warane weit mehr Sauerstoff als andere Schuppenkriechtiere aufnehmen, sie haben also eine effizientere Atmung und sind zu einer aktiveren Lebensweise und größerer Leistung befähigt. Die meisten Warane suchen große Gebiete züngelnd nach Beute ab. Nahezu alle Warane sind Fleischfresser und ernähren sich von Insekten, anderen Wirbellosen oder auch kleinen bis mittelgroßen Wirbeltieren. Einige Arten fressen auch Aas. Nur drei Arten auf den Philippinen fressen neben tierischer Nahrung auch zu einem großen Teil Früchte.

Einige Arten der Warane sind von hoher wirtschaftlicher Bedeutung für den Menschen und werden besonders in Afrika und Südostasien für den Lederhandel und als Fleischlieferanten gejagt. Während eine Reihe von Arten diesem Bejagungsdruck augenscheinlich standhält, verzeichnen andere kommerziell genutzte Waranarten beträchtliche Bestandseinbußen. Daneben sind Warane oft durch den Verlust ihres Lebensraumes gefährdet. In der Roten Liste gefährdeter Arten der IUCN wird eine Art als "stark gefährdet" eingestuft, zwei weitere Arten als "gefährdet". Für die meisten Arten liegen jedoch nur unzureichende Informationen zum Gefährdungsstatus vor.

Der Name "Waran" sowie der Gattungsname "Varanus" leiten sich etymologisch vom arabischen Wort ab, welches für Warane insgesamt steht, und von der gleichlautenden altägyptischen Bezeichnung für den Nilwaran ("V. niloticus").

Warane leben in den Tropen, Subtropen und in geringerem Maß auch in den gemäßigten Zonen der alten Welt. Das Verbreitungsgebiet der Gattung erstreckt sich in Afrika über fast den gesamten Kontinent und reicht von dort über die arabische Halbinsel, Mittelasien, Kontinental-Südostasien und die südostasiatische Inselwelt bis nach Australien. Daneben erreichen einige Arten die westlichsten Inselgruppen des Pazifiks, etwa die Salomonen, die Marshallinseln, die Karolinen und die Marianen. Das nördlichste Vorkommen aller Warane hat der Wüstenwaran, dessen Verbreitung sich von Nordafrika und Mittelasien bis zum Aralsee und zum Kaspischen Meer auf etwa 46°  nördliche Breite erstreckt. Warane fehlen auf Madagaskar, Tasmanien und Neuseeland sowie in Europa, Amerika und der Antarktis.

Ihre größte Diversität haben Warane in Australien; dort sind 30 Arten nachgewiesen. Stellenweise kommen bis zu 11 Arten sympatrisch vor. Ein weiterer „Hotspot“ für Warane ist Neuguinea, welches 5 Arten mit Australien teilt. Auf Neuguinea, den Salomonen und dem Bismarck-Archipel zusammen sind 16 Arten von Waranen bekannt. Auf den Molukken könnten bis zu 10 Arten vorkommen, die Zahl gilt jedoch als nicht gesichert. Die Philippinen beherbergen 8 Arten, darunter auch alle Früchte fressenden Arten der Untergattung "Philippinosaurus". Seit 2010 sind 3 weitere Arten aus den Philippinen beschrieben worden. Das Vorkommen des Rauhnackenwarans ("V. rudicollis") auf den Philippinen ist nicht gesichert, zusammen wären es dann 12 Arten. Im übrigen malaiischen Archipel leben 12 Arten, in Kontinental-Asien 7 Arten. In Afrika schließlich gibt es 5 Arten.

In ihrem großen Verbreitungsgebiet besiedeln Warane eine Vielzahl von Lebensräumen in diversen Höhenlagen, beispielsweise Regenwald, Wüste und Mangroven. Einige Arten besiedeln auch anthropogene und urbane Räume. Die tropischen Lebensräume der Warane sind durch saisonale Schwankungen geprägt. Meist lassen sich diese in eine nahrungsreiche Regenzeit und eine nahrungsarme Trockenzeit unterteilen.

Warane entsprechen in ihrem Äußeren der Grundform einer Echse, mit vier Beinen und einem Schwanz. Der Kopf ist meist mäßig hoch, vergleichsweise lang und läuft zur Schnauze hin spitz zu, es gibt jedoch eine Reihe von Arten mit hohem Schädel oder auch kurzem Kopf und stumpfer Schnauze. Warane haben wie Schlangen eine lange gespaltene Zunge, die das Doppelte der Kopflänge erreichen kann. Das Auge hat eine runde Pupille. Die Nasenlöcher sind rund oder schlitzförmig und können direkt an der Schnauzenspitze, direkt vor dem Auge oder dazwischen liegen. Lage und Form des Nasenlochs können zur Unterscheidung einzelner Arten herangezogen werden. Der Kopf ist gut vom recht langen Hals abgesetzt. Die Gliedmaßen sind vergleichsweise lang und tragen immer 5 Finger. Die Hintergliedmaßen sind länger als die Vordergliedmaßen. Der Schwanz ist bei den meisten Arten im Querschnitt rund, bei teils wasserbewohnenden (semiaquatischen) Arten ist der Schwanz jedoch als Ruderschwanz seitlich zusammengedrückt. So erzeugt er beim seitlichen Schlagen mehr Antrieb im Wasser. Die Vertreter der "V. prasinus"-Gruppe hingegen haben lange, dünne Greifschwänze, die sie als Kletterhilfe einsetzen. Die Schwanzlänge übertrifft meistens die Kopf-Rumpf-Länge. Warane sehen den nicht näher verwandten Schienenechsen (Teiidae) ähnlich.

Die Färbung von Waranen ist höchst variabel und reicht vom leuchtend grünen Smaragdwaran ("V. prasinus") bis hin zum vollkommen schwarzen (melanistischen) Panay-Waran ("V. mabitang"). Oft kommen Punktmuster oder Querbänderungen vor und die Grundfarbe stellt im jeweiligen Lebensraum meist eine Tarnfarbe dar. Längsstreifen sind bei Waranen selten. Die Bauchseite ist in den meisten Fällen heller als die Körperoberseite. Jungtiere sind bei einigen Arten deutlich heller oder bunter als Alttiere.

Warane sind bekannt für ihre große Spannweite an Körpergröße und Gewicht: Innerhalb keiner anderen Gattung der Wirbeltiere ist der Unterschied zwischen kleinen und großen Arten größer. Der kleinste Waran ist der Kurzschwanzwaran ("V. brevicauda"), der eine maximale Gesamtlänge von 23 cm und ein Höchstgewicht von 17 g erreichen kann. Der größte heute lebende Waran ist der Komodowaran ("V. komodoensis"), der eine Höchstlänge von bis zu rund 3 m bei einem Gewicht von über 70 kg erreichen kann. Der Komodowaran ist die größte heute lebende Echse; auch andere mittelgroße bis große Warane gehören zu den größten heute lebenden Echsen. Innerhalb der Warane entwickelten sich mehrmals voneinander unabhängig besonders große bzw. kleine Arten.

Männchen werden bei den meisten Arten etwas größer als die Weibchen, da die Wachstumsrate der Weibchen im Laufe der Individualentwicklung (Ontogenese) schneller abnimmt als bei Männchen. Außerdem haben Männchen manchmal leicht abweichende Proportionen des Kopfes und der Gliedmaßen, doch ohne eingehendere Untersuchung ist eine sichere Geschlechtsbestimmung bei den meisten Arten nicht möglich.

Warane haben größtenteils kleine, einfach gebaute Schuppen. Der Kopf trägt kleine, polygonale Schuppen. Der Schnauzenschild (Rostrale) ist nur undeutlich ausgebildet. Das gilt auch für die nicht sehr deutlich ausgeprägten Nasenschilde (Nasalia), stattdessen sind die Nasenlöcher von vielen kleinen Schuppen umgeben. Bei einigen Arten sind innerhalb der Überaugenschild-Reihen (Supraocularia) auffallend vergrößerte Schuppen ausgebildet. Auch die Nackenschuppen erfuhren bei einigen Arten eine Vergrößerung oder Zuspitzung, als Beispiele seien "V. nuchalis" und der Rauhnackenwaran ("V. rudicollis") genannt. Die Schuppen des Rumpfes sind länglich oval und in recht regelmäßigen Querreihen angeordnet. Am Schwanz haben viele Zwergwarane der Untergattung "Odatria" stachelige Schuppen. Bei seitlich zusammengedrückten Schwänzen bilden meist die beiden obersten Schuppenreihen des Schwanzes Kiele aus. Einige Warane (z. B. Grays Waran, "V. olivaceus") haben auch besonders gekielte Schuppen auf der Körperunterseite, um beim Klettern zusätzlichen Halt zu haben.

Auffallend am Gesichtsschädel sind die großen, relativ weit hinten liegenden Nasenfenster. Der Oberkieferknochen (Maxillare) ist recht lang. Im Unterkiefer findet sich zwischen dem Unterkieferknochen (Dentale) und einigen angrenzenden Knochen (Coronoid, Supraangulare und Angulare) eine breite, mit Bindegewebe gefüllte Naht. Der Hirnschädel zeigt nur wenige Besonderheiten.

Bedeutend für Warane sind die kinetischen Eigenschaften ihres Schädels, wodurch sie große Beutetiere oder große Stücke dieser ganz verschlucken können. So wird die fehlende Fähigkeit zum Kauen kompensiert. Es sind Fälle bekannt geworden, in denen Warane Beutetiere von 42 % ihres eigenen Körpergewichts verschlungen haben; derart große Beute stellt jedoch die Ausnahme dar. Einerseits ist der Waranschädel metakinetisch: Die Schädelelemente des Hinterkopfes (Occipitalregion) sind mit dem restlichen Schädel beweglich verbunden, der Rest des Schädels kann also gegen den Hinterkopf bewegt werden. Der Waranschädel ist auch mesokinetisch, der Oberkiefer kann an einem Knickgelenk hinter den Augenfenstern (Orbitae) gegen den Hirnschädel bewegt werden. Die Bindegewebenaht zwischen einigen Unterkieferknochen macht diese ebenfalls gegeneinander beweglich. Wie bei allen Schuppenkriechtieren zeichnet sich auch der Waranschädel durch Streptostylie aus: Das Quadratum ist gelenkig mit seinen angrenzenden Schädelelementen verbunden, was den Schädel weiter beweglich macht.

Die Zähne der Warane sind bei den meisten Arten seitlich zusammengedrückt, laufen spitz zu und sind nach hinten gekrümmt. Bei einigen Arten sind die Schneiden gesägt. Ausgefallene Zähne werden erneuert, indem neue Zähne im hinteren Teil des Kiefers gebildet werden und kontinuierlich auf frei gewordene Plätze nachrücken (Polyphyodontie). Nach Mertens (1942) besitzt ein vollständiges Warangebiss je nach Art 37 bis 71 Zähne. Die ungerade Zahl ergibt sich aus der Besonderheit, dass sich am Zwischenkieferbein (Prämaxillare) fast immer eine ungerade Zahl von Zähnen befindet. Die Anzahl von Zähnen am Oberkiefer entspricht ungefähr der Zahl im Unterkiefer; meist sind es 1–2 mehr im Unterkiefer, es können jedoch auch gleich viele oder weniger sein. Die Zähne sind subpleurodont befestigt. Im Fall von Waranen heißt das, dass je ein mikroskopisch kleines knöchernes Plättchen die Zähne mit den Kieferknochen verbindet. Kleineren Waranen dienen ihre Zähne vor allem zum Festhalten von Beute, große Warane hingegen nutzen ihre Zähne auch zum Herausschneiden von Stücken aus größerer Beute. Hierzu sind die Zähne durch ihre Sägungen besonders gut geeignet.

Eine Reihe von Waranarten entwickelt im Lauf ihrer Individualentwicklung hingegen stumpfe, backsteinartige Zähne. Während die Jungtiere solcher Arten meist spitze Zähne zur Jagd auf Insekten haben, ernähren sich die Alttiere vor allem von Weichtieren (z. B. Schnecken). Bekannt ist dieser ontogenetische Zahnwechsel unter anderem vom Nilwaran ("V. niloticus"). Ebenso ist dieser Zahnwechsel typisch für den Grays Waran ("V. olivaceus"), der nach abgeschlossenem Zahnwechsel auch Früchte isst.

Der Zungenbeinapparat (die funktionelle Einheit aus Zungenbein und anhängenden Muskeln) der Warane entspricht im Grundmuster dem Zungenbeinapparat der meisten Schuppenkriechtiere. Die einzelnen Elemente sind jedoch gegeneinander sehr beweglich und die dem Zungenbeinskelett anhängenden Muskeln sind ungewöhnlich gut ausgeprägt. So kann das Zungenbein zusammen mit dem Mundboden in viele verschiedene Richtungen bewegt werden. Der Zungenbeinapparat spielt eine wichtige Rolle beim Schlucken von Beute, bei der Atmung und bei Drohgebärden.

Das Postcranialskelett (Skelett exklusive Schädel) ist für Schuppenkriechtiere typisch gebaut. Die Wirbel sind an der Vorderseite konkav (procoel). Die Zentren sind flach gedrückt und somit nicht zylindrisch. Mertens (1942) gibt nach Untersuchung von sechs Exemplaren (vier Arten) folgende Zahlen an: 7 Halswirbel, davon die 1–2 hinteren mit kurzen Rippen, 22–23 Rückenwirbel, davon bis auf die letzten 1–3 alle mit Rippen, 2 rippenlose Sakralwirbel und 101–148 Schwanzwirbel. Warane sind nicht zur Autotomie befähigt, können also nicht wie Eidechsen ihren Schwanz abwerfen.

Der Oberarmknochen ("Humerus") ist kurz und gedrungen, die Elle ("Ulna") ist länger als die Speiche ("Radius"). Es sind fünf Zehen vorhanden, die Phalangenformel (Anzahl der Zehengliedknochen pro Vorderzehe) der Vorderbeine ist 2–3–4–5–3. Am Oberschenkelknochen ("Femur") ist der Gelenkkopf für das Schienbein ("Trochanter tibialis") sehr groß, der Gelenkkopf für das Wadenbein ("Trochanter fibularis") sehr klein. Das Wadenbein ("Fibula") ist etwas länger als das Schienbein ("Tibia"). Auch am Hinterfuß finden sich fünf Zehen, die Phalangenformel der Hinterbeine ist 2–3–4–5–4.

Einige Arten der Warane besitzen unter ihren Schuppen wurmförmige Osteoderme, speziell an den Beinen, dem Schwanzansatz, am Kopf sowie an Hals und Bauchunterseite. Bei alten Exemplaren können die kleinen Osteoderme lokal zu durchgehenden Panzern verwachsen. Man geht davon aus, dass diese Knochengebilde unter anderem bei innerartlichen Konflikten einen gewissen Schutz vor Verletzungen darstellen. Eine weitere Verknöcherung des Integuments ist das Hemibaculum, eine verknöcherte Struktur am Ende der Hemipenes und der Hemiclitoris. Der Nutzen dieser Struktur ist nicht bekannt. Das Hemibaculum stellt eine Autapomorphie der Warane dar.

Von besonderer Bedeutung für die Warane sind die ungewöhnlich gebauten Organe Herz und Lunge. Das Waranherz liegt recht weit hinten im Körper und beginnt erst nach dem hinteren Ende des Brustbeins (Sternum). Wie bei allen Schuppenkriechtieren besteht das Waranherz aus zwei Vorhöfen und drei nicht vollständig abgetrennten Kammern, nämlich "Cavum arteriosum", "C. venosum" und "C. pulmonale". "C. arteriosum" und "C. venosum" werden durch eine Scheidewand ("Septum") unvollständig getrennt. "C. venosum" und "C. pulmonale" hingegen werden durch die "Muskelleiste" nahezu vollständig getrennt, jedoch bleibt zwischen der Oberseite der "Muskelleiste" und der Herzwand ein kleiner Spalt frei. Das "C. venosum" ist relativ klein. Von dem Septum, das die zwei Vorhöfe trennt, gehen die zwei "septalen atrioventricularen Klappen" aus. Im Waranherz sind speziell die gut ausgebildete "Muskelleiste" und die gut ausgeprägten Septen und Klappen wichtig.

Während der Füllungsphase (Diastole) fließt sauerstoffarmes Blut aus dem Körperkreislauf vom rechten Vorhof in das "C. venosum" und von dort durch eine Öffnung zwischen "Muskelleiste" und Herzwand weiter ins "C. pulmonale". Gleichzeitig fließt sauerstoffreiches Blut aus dem Lungenkreislauf mit höherem Druck aus dem linken Vorhof in das "C. arteriosum". Dabei wird die "linke septale atrioventriculare Klappe" gegen das Septum zwischen "C. arteriosum" und "C. venosum" gepresst, wodurch eine vorübergehende, recht effiziente funktionelle Trennung zwischen den beiden Kammern entsteht. Am Anfang der Austreibungsphase (Systole) werden die septalen Vorhof-Kammer-Klappen durch den Blutdruckanstieg in den Herzkammern wieder geschlossen. So werden die Herzkammern von den Vorhöfen abgegrenzt, welche sich erneut mit Blut füllen. Gleichzeitig wird der kleine Spalt zwischen "Muskelleiste" und Innenwand der Kammer geschlossen. Bei zunehmender Kammerkompression wird das sauerstoffarme Blut des "C. pulmonale" in den Lungenkreislauf gedrückt. Gleichzeitig wird das sauerstoffreiche Blut des "C. arteriosum" durch das zuvor noch dem sauerstoffarmen Blut dienlichen "C. venosum" in den Körperkreislauf gepresst. Praktisch kommt dem "C. venosum" also nur die Rolle eines Kanals für Blut zu, nicht die Funktion einer autonomen Herzkammer. Während das sauerstoffarme Blut des "C. pulmonale" praktisch ohne Vermischung zum Lungenkreislauf gepumpt wird, mischt sich das sauerstoffreiche Blut des "C. arteriosum" mit sauerstoffarmem Blut des "C. venosum", welches nicht in das "C. pulmonale" gelangte. Die fortgeschrittene Trennung von sauerstoffarmen und sauerstoffreichen Blut im Herzen ermöglicht eine effektivere Verteilung des Sauerstoffs. Nur etwa 30 % sauerstoffarmes, für den Lungenkreislauf bestimmtes Blut gelangt erneut in den Körperkreislauf, und nur etwa 10 % von sauerstoffreichem Blut aus den Lungen gelangt erneut in den Lungenkreislauf.

Die Lungen der Warane sind recht groß. Sie beginnen in beträchtlicher Entfernung hinter dem Herzen und erstrecken sich bis zum vorderen Ende der Leber. Die Bronchien spalten sich in der Lunge in je zwei Äste. Von diesen gehen wiederum kleine Seitenzweige aus, welche in geräumige alveolöse (lungenbläschenreiche) Kammern münden. Dieser mehrkammerige Bau ist eine Autapomorphie der Warane; andere Schuppenkriechtiere haben einfache, sackartige Lungen. Somit gibt es in den Lungen von Waranen eine größere Fläche für den Gasaustausch, welcher daher bei Waranen auch besonders effizient ist.

Auch die Ventilation der Lungen ist bei Waranen verschieden zu anderen Schuppenkriechtieren. Die meisten Reptilien atmen vorwiegend mithilfe der Zwischenrippenmuskulatur ("Musculi intercostales"). Diese Muskeln können zu beiden Seiten des Rumpfes die Rippen leicht drehen, den Brustkorb dadurch erweitern und so durch Volumenzunahme die Füllung der Lungen bewirken. Allerdings spielen bei der Fortbewegung von Echsen seitliche Wellenbewegungen des Rumpfes eine wichtige Rolle. Bei mittleren und hohen Geschwindigkeiten wird die Zwischenrippenmuskulatur einseitig zur Biegung des Rumpfes stark angespannt. Dadurch tragen die "Musculi intercostales" zur Fortbewegung bei, gleichzeitig wird jedoch bei erhöhter Geschwindigkeit die Atmung behindert, obwohl gerade dann eine erhöhte Sauerstoffzufuhr wichtig wäre. Dies bezeichnet man als "axial constraint" („axiale Beschränkung“). Warane sind in der Lage, mithilfe des Zungenbeinapparats durch "gular pumping" („Kehlpumpen“) die axiale Beschränkung zu kompensieren. Bei mittleren bis hohen Geschwindigkeiten wird zuerst ein normaler Atemzug getan, der die Lunge nicht vollständig füllen kann. Dann wird der Zungenbeinapparat gesenkt und somit der Kehlraum erweitert und Luft eingesogen. Dann wird der Kehlraum durch den Zungenbeinapparat wieder zusammengepresst und Luft in die Lunge gepumpt. Im Schnitt wird je normalem Atemzug dreimal gepumpt. Diese Form der Atmung kommt auch bei anderen Schuppenkriechtieren vor, ist aber bei den Waranen besonders stark ausgeprägt. "siehe auch:" Röntgenaufnahme des "gular pumping" (MOV; 3,0 MB)

Aus diesen Anpassungen resultiert eine besonders hohe Fähigkeit zur Aufnahme von Sauerstoff. Die meisten Schuppenkriechtiere haben eine nur geringe aerobe Stoffwechselkapazität, und somit eine niedrige anaerobe Schwelle. Für kurze, intensive körperliche Belastungen haben Schuppenkriechtiere die gut ausgeprägte Fähigkeit zur anaerobischen Energiebereitstellung. Schuppenkriechtiere ermüden jedoch schnell, und der pH-Wert des Blutes sinkt durch Milchsäureproduktion (Abfallprodukt des anaeroben Stoffwechsels). Bei Überbelastung entsteht eine metabolische Azidose. Warane hingegen sind für ihre großen aeroben Kapazitäten bekannt. Neben besonderen Anpassungen der Ventilation, der Lungen und des Herzens sind Herz- und Skelettmuskulatur zudem mit einem hohen Gehalt von Myoglobin ausgestattet, wodurch zusätzlicher Sauerstoff gespeichert werden kann. Auch der Hämatokrit der Warane ist höher als bei anderen Echsen. Diese Anpassungen ermöglichen besonders hohe körperliche Leistungen und eine für Schuppenkriechtiere höchst aktive Lebensweise. Neben ihrer größeren Ausdauer verbrauchen Warane im Ruhezustand jedoch nicht mehr Energie als andere Echsen und Schlangen.

Bestätigt wurde dies bei Experimenten, in denen der Leistungsstoffwechsel von Steppenwaranen ("V. exanthematicus") und Grünen Leguanen ("Iguana iguana") bei 35 °C während 20-45 Minuten Beanspruchung auf einem Laufband verglichen wurde. Der maximale Sauerstoffverbrauch beim Steppenwaran beträgt 1.26 Milliliter pro Gramm Körpergewicht des Tieres pro Stunde. Damit ist er in der Lage, über den Versuchszeitraum eine beständige Laufgeschwindigkeit von 1,2 km/h vollständig aerob zu bestreiten. Für den Grünen Leguan hingegen wurde ein maximaler Sauerstoffverbrauch von 0.82 Milliliter pro Gramm Körpergewicht des Tieres pro Stunde errechnet, damit konnte er auf dem Laufband nur 0,5 km/h vollkommen aerob aufrechterhalten.

Besonders stark ans Wasser gebundene und regelmäßig tauchende Arten der Warane zeigen weitere Anpassungen hinsichtlich der Atmung. Das Blut solcher Arten hat einen besonders hohen Gehalt an Blutpuffern, wodurch der Körper über längere Zeit anaerob Energie gewinnen kann. Zusätzlich kann beim Tauchen die Herzfrequenz um bis zu 85 % gesenkt werden.

Die Stoffwechselrate von freilebenden Waranen wurde mehrfach untersucht; die Werte reichten von 2,3 kJ/d bei einem 10,4 g schweren "V. caudolineatus" bis hin zu 1330 kJ/d bei einem 16,62 kg schweren Komodowaran ("V. komodoensis"). Dazwischen lag z. B. ein 3,28 kg schwerer Arguswaran ("V. panoptes") mit 468 kJ/d. Bei Waranen in stark saisonalen Gebieten ist der Stoffwechselumsatz ebenso starken Schwankungen unterworfen, da dann die meisten Arten eine Ruheperiode halten. In der Trockenzeit lag die Stoffwechselrate des untersuchten Arguswarans bei nur 168 kJ/d. Ähnlich verhält es sich mit dem Wasserhaushalt: In der Regenzeit schied der Arguswaran 135 ml/d aus, in der Trockenzeit 58,5 ml/d. Speziell Warane aus Trockengebieten scheiden nur wenig Wasser mit dem Urin aus. Ihren Wasserbedarf decken Warane fast ausschließlich aus dem Wassergehalt ihrer Beutetiere.

Um beutearme Hungerperioden zu überdauern, legen Warane Fettkörper an. Ein Fettkörper findet sich am Schwanzansatz, zwei weitere sind sich gegenüberliegende, lappenartige Gebilde an der Körperunterseite zwischen Bauchfell und Bauchwand. Warane zehren vor allem während der nahrungsarmen Trockenzeit von diesem Fett; Weißkehlwarane ("V. albigularis") etwa verlieren über die Trockenzeit bis zu 50 % ihres Körpergewichts. Bei vielen Waranen zehren die Weibchen von ihren Fettkörpern, um Dotter für ihre Eier zu bilden.

Die lange, gespaltene Zunge der Warane spielt eine wichtige Rolle bei der olfaktorischen Wahrnehmung. Die Zunge wird im Rahmen des Züngelns zur olfaktorischen Wahrnehmung wiederholt eingezogen und ausgestreckt. Dabei werden an der Zungenspitze Geruchspartikel aus der Luft oder von Oberflächen aufgenommen. Anschließend werden die Geruchspartikel an der Zungenspitze zum Jacobson-Organ am Gaumendach transportiert. Das Jacobson-Organ spielt vor allem bei der Ortung von Beute auf größere Distanzen und beim Sozialverhalten eine Rolle und ist bei Waranen leistungsfähig genug, um vergrabene Beute aufzuspüren. Die Zunge wird von verschiedenen Muskeln bewegt: Einerseits vom M. genioglossus, der an der Unterseite der Zunge und am Unterkiefer ansetzt, sowie durch Muskeln, die vom Inneren der Zunge ausgehen. Diese setzen größtenteils am Zungenbeinskelett an. Die Zunge wird in eine Scheide am Mundboden eingezogen, in welche sie nahezu vollständig passt.

Die Augen der Warane sind für Reptilien sehr gut entwickelt. Warane haben ein oberes Augenlid, ein unteres Augenlid und eine Nickhaut, die über das ganze Auge gezogen werden kann. In seinem Feinbau ähnelt das Auge der Warane stark dem Auge anderer tagaktiver Reptilien. Die Netzhaut der Warane enthält größtenteils oder ausschließlich Zapfen, somit sind Warane zum Farbsehen befähigt. Jeder Zapfen enthält 2 Öltröpfchen, diese ungewöhnliche Eigenschaft ist wohl eine Eigenart der Warane. Da Warane tagaktiv sind und oft Lebensräume mit hoher Lichtintensität (z. B. Wüsten) bewohnen, sind diese Öltröpfchen wahrscheinlich eine Art Sonnenschutz vor schädlicher kurzwelliger Strahlung.

Warane nehmen besonders Bewegungen gut wahr und erkennen zum Beispiel einen sich bewegenden Menschen aus rund 200 m Entfernung. Stationäre Objekte werden nur unscharf gesehen. Das Gesichtsfeld beläuft sich auf etwa 240°, davon 25° stereoskopisch. Der Sehsinn spielt in der Feindvermeidung, bei der Jagd auf geringe Distanz und im Sozialverhalten eine Rolle. Sprackland (1999) vermutet sogar, dass sich nahe verwandte Waranarten (z. B. in der "V. indicus"-Gruppe) an den Farben ihrer Zunge unterscheiden können.

Das Parietalorgan (Scheitelauge) der Warane ist gut entwickelt; äußerlich erscheint es als heller Fleck auf einer vergrößerten Schuppe, dem sogenannten Interparietale. Das Parietalorgan spielt eine zentrale Rolle bei der Thermoregulation (durch Sonnen) und dem Tagesrhythmus; wenn das Parietalorgan experimentell verdeckt wird, so schlafen die Warane oft außerhalb von Verstecken, sind wenig aktiv, sind teils auch in der Nacht aktiv und zeigen kein thermoregulatorisches Verhalten mehr.

Das Gehör der Warane ist nur wenig leistungsfähig, viele Individuen reagieren auch auf laute Geräusche (z. B. Gewehrschuss) nicht.

Jüngste Studien lassen vermuten, dass alle Warane giftig sind. Fry et al (2006) erstellten cDNA-Bibliotheken von serösem Gewebe im Unterkiefer von 4 Waranarten und untersuchten mittels Massenspektrometrie auch die Mundhöhlensekretionen dieser Arten. In den DNA-Bibliotheken von allen Arten fanden sich Gene, die für Reptiliengifte typische, toxische Proteine codieren. Die Massenspektrometrie zeigte, dass sich im Speichel von Waranen eine ganze Reihe von toxischen Proteinen finden, die auch in den DNA-Bibliotheken codiert sind. Die toxischen Proteine werden somit aller Wahrscheinlichkeit nach von Giftdrüsen im Unterkiefer produziert. Das Vorhandensein von Giftdrüsen würden die Warane mit allen Mitgliedern des Taxons Toxicofera teilen. Eine weitere Studie von Fry et al (2010) wies Giftproduktion bei 11 weiteren Arten nach, mit großer Sicherheit besitzen also alle Warane Giftdrüsen. Von den grundlegenden Toxicofera-Proteinen enthält das Warangift Proteine der AVIT-Familie, Natriuretische Peptide (B-Typ), CRISP-Proteine, Cobra Venom Factor, Kallikrein und Nerve Growth Factor. Crotamin, Cystatin und Vespryn gingen sekundär verloren, hinzu kam jedoch Phospholipase A (PLA).

Mithilfe von Magnetresonanztomographie (MRT) konnten erstmals beim Komodowaran ("V.komodoensis") (Fry et al 2009) Giftdrüsen nachgewiesen werden, später wurden bei insgesamt 15 Arten (Fry et al 2010) gleich gebaute Giftdrüsen gefunden. Warane besitzen zu jeder Seite des Unterkiefers eine längliche Giftdrüse, die sich unter den Zahnreihen erstreckt. Diese Drüsen sind jeweils von Bindegewebe eingehüllt und in ein großes hinteres und fünf kleinere vordere Kompartimente eingeteilt. Von jedem Kompartiment führt ein separater Gang nach oben, der sich zwischen je zwei Zähnen in die Mundhöhle öffnet. Warane besitzen keine gefurchten oder hohlen Zähne zur Giftübertragung, daher mischt sich das Gift mit anderen Sekreten der Mundhöhle.

Die Wirkung und der Nutzen von Warangift sind nur unzureichend erforscht. Das Gift des Komodowarans ist allerdings recht gut untersucht, es verursacht primär einen Volumenmangelschock, hemmt die Blutgerinnung und unterstützt somit den Beutefang (siehe auch Rolle von Gift und Bakterien im Jagdverhalten beim Komodowaran). Bei anderen Arten herrscht noch Unklarheit. Werden die Mundhöhlensekrete eines Buntwarans ("V. varius") in eine anästhesierte Ratte injiziert, so führt dies zur Entspannung der glatten Muskulatur der Aorta, wodurch sich Blutgefäße stark erweitern. Ebenso mindert das in dem Gemisch enthaltene Gift die Blutgerinnung (Koagulopathie). Bei einer nicht anästhesierten Ratte würden diese Effekte zu einem starken Abfall des Blutdrucks und Bewusstlosigkeit durch Volumenmangelschock führen. Ein Nutzen beim Beutefang ist bei den meisten Waranen jedoch sehr unwahrscheinlich, da Warane ihre kleine bis mittelgroße Beute üblicherweise lebend verschlucken oder durch rein mechanische Kraft töten. Nach Arbuckle (2009) ist es wahrscheinlicher, dass das Gift durch Bestandteile wie PLA die Verdauung unterstützt. Die artspezifischen Variationen der Giftwirkung sind unbekannt.

Die Wirkung des Gifts auf Menschen ist nur unzureichend erforscht. In einigen Fällen wurde von Vergiftungserscheinungen nach Bissen von Waranen berichtet. Laut Fry et al (2006) führten Bisse vom Komodowaran ("V. komodensis"), Buntwaran ("V. varius") und "V. scalaris" zu starkem Anschwellen der Bissstelle, Schwindel, stechendem Schmerz und Störung der Blutgerinnung. Die Symptome hielten mehrere Stunden an. Vom Wüstenwaran ("V. griseus") ist zudem ein Ausnahmefall publiziert, bei dem zusätzlich Herzrasen (Tachykardie), Muskelschwäche und Atemschwierigkeiten auftraten.

Wie alle Echsen laufen Warane vierbeinig mit seitlich abgespreizten Gliedmaßen. Der Rumpf wird beim Laufen abwechselnd seitlich gebogen (Undulation). Die Vorderbeine tragen etwa 40 % des Körpergewichts, die Hinterbeine etwa 60 %. Beim Laufen halten Warane ihren Kopf und Rumpf weit über dem Boden, und nur die hintere Hälfte des Schwanzes und die Füße berühren den Boden. Wenn Warane im Sand laufen, entstehen daher typische Spuren mit Fußabdrücken und eine Schleifspur in deren Mitte. Der auffallend lange Schwanz und der ungewöhnlich lange Hals der Warane spielen auch bei der Fortbewegung eine Rolle. Der lange Hals erleichtert aufgrund seiner Beweglichkeit den Fang von schneller, wendiger Beute. Der Schwanz bildet dabei eine Art Gegengewicht zum sich schnell bewegenden Hals. Der Schwanz kann zudem zum schnellen Richtungswechsel verlagert werden. Angaben zur Geschwindigkeit von Waranen sind rar: Goulds Warane ("V. gouldii") laufen auf größere Distanzen mit durchschnittlich rund 1,6 km/h, die Geschwindigkeit kann von rund 1,1 km/h bis 2,4 km/h reichen. Der Komodowaran ("V. komodoensis") bewegt sich mit durchschnittlich 4,8 km/h fort und kann bei kurzen Sprints bis zu 18,5 km/h erreichen.

Viele Warane sind gute Kletterer. Von mehreren Arten ist bekannt, dass sie ihren Schwanz beim Klettern als Greiforgan einsetzen können. Zahlreiche Arten sind geschickte Schwimmer. Schwimmende Warane legen ihre Beine lose an den Rumpf an und erzeugen durch seitliche Wellenbewegungen von Rumpf und Schwanz Antrieb. Der Kopf wird dabei über Wasser gehalten. Einige Arten tauchen auch regelmäßig und können teils bis zu einer Stunde unter Wasser bleiben. Reguläre Tauchgänge sind deutlich kürzer. Die allermeisten Warane sind sowohl zum Klettern als auch zum Schwimmen fähig, die Ausprägung dieser Fähigkeiten schwankt jedoch von Art zu Art und hängt von der jeweiligen Lebensweise ab. Es gibt sowohl spezialisierte Baumbewohner, Bodenbewohner und stark ans Wasser gebundene Arten als auch Generalisten.

Alle Warane sind tagaktiv. Abends ziehen sich Warane in ihr Versteck zurück und ruhen bis zum nächsten Morgen. Die meisten Warane sonnen sich dann am Morgen ausgiebig. Je nach den klimatischen Bedingungen in ihrem Verbreitungsgebiet verstecken sich Warane um die Mittagszeit vor zu starker Hitze oder sind zu dieser Zeit aufgrund optimaler Temperaturen besonders aktiv. Wie alle Schuppenkriechtiere sind Warane ektotherm und erhöhen ihre Körpertemperatur durch Sonnen, oder sie kühlen sich durch Rückzug in ein Versteck, in den Schatten oder ins Wasser ab. Warane können durch schnelles Heben und Senken des Mundbodens mittels des Zungenbeinapparates auch "hecheln" und ihre Körpertemperatur senken; dieses Verhalten führt jedoch zu beträchtlichem Wasserverlust und wird nur bei unmittelbarer Gefahr der Überhitzung angewandt. Aktive Warane haben üblicherweise eine Körpertemperatur von 22–38 °C. Die meisten Warane versuchen, durch aktive Thermoregulation eine Vorzugstemperatur um die 36 °C aufrechtzuerhalten. Die Vorzugstemperatur unterscheidet sich jedoch von Art zu Art und insbesondere semiaquatische Arten bevorzugen niedrigere Körpertemperaturen. Einige Arten sind wenig umsichtige Thermoregulatoren und erhalten dennoch eine günstige Körpertemperatur aufrecht. Dies hängt offenbar mit einer größeren Lichtabsorption ihrer Haut zusammen.

Warane nutzen viele verschieden Arten von Verstecken, so etwa Baumhöhlen, dichte Vegetation, Felsspalten und Termitenhügel. Die Mehrheit der Arten hingehen graben sich selber einen Bau oder übernehmen den Bau eines anderen Tieres. Einen eigenen Bau legen Warane bevorzugt unter Felsen oder Wurzelwerk an. Bei einigen Arten können selbst gegrabene Baue mehrere Meter lang sein.

Waranarten aus den nördlichen und südlichen Verbreitungsgebieten halten meist eine Ruheperiode. Insbesondere Arten aus Nord- und Südafrika, Australien und Zentralasien bleiben während der Trockenzeit in ihrem Lebensraum weitgehend inaktiv, da zu dieser Zeit Nahrungsmangel herrscht. Zu Beginn der Trockenzeit ziehen sich die Warane in ein Versteck zurück und harren bis zur Regenzeit aus. Arten aus tropischen Gebieten hingegen sind oft das ganze Jahr über aktiv.

Die meisten individuellen Warane bewegen sich in einem angestammten Gebiet, das als Aktionsraum bezeichnet werden kann. Die Aktionsräume von Männchen sind meist deutlich größer als die Aktionsräume von Weibchen. Die Größe von solchen Aktionsräumen hängt auch sehr stark vom Lebensraum und der Waranart ab. Die Aktionsräume von Individuen überlappen sich bei den meisten Arten, und das Streifgebiet wird üblicherweise nicht verteidigt. In nahrungsreichen Gebieten können die Aktionsräume kleiner sein, in nahrungsarmen Gebieten hingegen müssen größere Gebiete genutzt werden.

Die täglich von Waranen zurückgelegten Strecken sind je nach Art und Umgebung höchst variabel: Der maximal 80 cm lang werdende "V. glauerti" etwa legt täglich im Mittel 37 m zurück, der bis zu 1,5 m lange Weißkehlwaran ("V. albigularis") hingegen bis zu 5 km. Mit ihrer höheren aerobischen Kapazität sind Warane weit aktiver als andere Echsen und ihre Aktionsräume sind im Vergleich zu ähnlich großen Echsen besonders groß.

Alle Warane sind Einzelgänger und die Individuen eines Gebietes begegnen sich nur selten. Vom Komodowaran ("V. komodoensis") ist auch bekannt, dass sie Konfrontationen mit dominanten Individuen aktiv vermeiden. Wenn sich Warane dennoch treffen, so kommt es oft zu Konflikten, da nicht selten beide Warane von ein und derselben Ressource angezogen werden, beispielsweise Aas, Versteckplätze oder Fortpflanzungspartner. Diese Konflikte werden üblicherweise mit einem Kommentkampf gelöst. Solche Kämpfe können in allen Geschlechterkonstellationen auftreten und der Ablauf ist von Art zu Art verschieden. Anfänglich werden meist Drohgebärden ausgetauscht: Die Warane beginnen intensiv zu züngeln, nicken mit dem Kopf und blähen mithilfe des Zungenbeinapparats ihre Kehle auf. Die Rivalen beginnen laut zu hissen und richten sich teilweise auch leicht auf die Hinterbeine auf. Lässt sich keiner der Rivalen einschüchtern, so beginnt die "clinch"-Phase, die von wenigen Sekunden bis zu einer Stunde dauern kann. Beide Kontrahenten richten sich auf ihren Hinterbeinen auf, legen ihre Vorderbeine um den Schulterbereich des Rivalen und versuchen, sich gegenseitig niederzuringen. Schließlich wird ein Waran niedergerungen und der Sieger besteigt das unterlegene Exemplar (Pseudokopulation). Solch ein Kampf legt ein kurzzeitiges Dominanzverhältnis fest und der Sieger kann die umkämpfte Ressource nutzen. Die Kommentkämpfe folgen zwar meist dem hier dargestellten Grundmuster, können sich aber von Art zu Art unterscheiden. Anders als bei Beschädigungskämpfen kommt beim Kommentkampf keiner der Rivalen zu bleibendem körperlichem Schaden, da im Kommentkampf nicht gebissen wird. Beschädigungskämpfe können bei Waranen auch vorkommen, sind aber weit seltener. Nicht alle Warane binden eine "clinch"-Phase in den Kampf ein, auch wenn dieses Verhalten bei Waranen ursprünglich ist. Die "clinch"-Phase ging in der Indo-Asien B-Gruppe (siehe Biogeographische Entwicklung der heutigen Gruppen) sekundär verloren. Dasselbe ist bei den Zwergwaranen der Untergattung "Odatria" der Fall, diese führen einen Ringkampf am Boden aus.

Warane gelten als vergleichsweise intelligent und werden oft als intelligenteste Echsen überhaupt bezeichnet. Zum Beispiel können Warane zählen. Dies wurde mit einem Experiment bewiesen, bei dem Weißkehlwarane ("V. albigularis") daran gewöhnt wurden, in einem bestimmten Raum stets eine gegebene Anzahl von Schnecken vorzufinden. Wurde nach mehreren Malen eine Schnecke entfernt, so begannen die Warane nach Verzehr aller vorhandenen Schnecken den ganzen Raum nach der fehlenden Schnecke abzusuchen. Auch die Möglichkeit, in eine weitere Kammer mit Schnecken zu gelangen, wurde nicht genutzt. Erst die Gabe einer weiteren Schnecke beruhigte die Warane. Bei bis zu 6 Schnecken bemerkten die Warane eine fehlende Schnecke. Bei einem anderen Experiment wurden Goulds Waran ("V. gouldii"), Papuawaran ("V. salvadorii") und Buntwaran ("V. varius") für intelligent befunden. Man warf einem Waran eine Maus vor, welche dieser sogleich tötete. Dann wurde dem Waran eine weitere Maus gegeben; er unterbrach den Schluckvorgang und tötete die neue Maus. Dies konnte mehrmals wiederholt werden und am Ende fraßen die Warane alle getöteten Mäuse. Ebenfalls können Warane in Gefangenschaft sehr zahm werden und ihre Pfleger von anderen Personen visuell unterscheiden. Es existieren auch Berichte über Nilwarane ("V. niloticus"), die bei der Jagd kooperierten. Krebs (2007) schließt aus seinen Beobachtungen und der vorliegenden Literatur, dass Warane Probleme lösen können, aus Erfahrungen lernen und ein gutes Gedächtnis haben. Ebenso spricht er Waranen die Fähigkeit zur Generalisation, Kategorisierung und Unterscheidung ähnlicher Individuen zu.

Die meisten Warane sind Fleischfresser und jagen eine große Vielfalt von Beutetieren, sowohl Wirbellose als auch Wirbeltiere. Zu den typischen Beuteobjekten gehören verschiedenste Gliederfüßer (vor allem Insekten und Spinnen), Weichtiere (z. B. Schnecken), Krebstiere, Fische, Amphibien (v. a. Frösche), Reptilien, Vögel (v. a. Jungvögel) und kleine Säuger. Daneben werden auch die Eier von Reptilien und Vögeln erbeutet, und eine Reihe von Waranen frisst auch Aas.

Das Nahrungsspektrum eines individuellen Warans hängt stark von seiner Größe, seiner Umwelt und der Jahreszeit ab. Kleine Arten und Jungtiere großer Arten ernähren sich fast ausschließlich von kleinen Wirbellosen, und auch bei großen Arten machen Wirbellose üblicherweise den mengenmäßigen Großteil der Beute aus. Daneben jagen größere Warane auch kleine bis mittelgroße Wirbeltiere, diese sind dann energetisch wohl oft ebenso wichtig wie die Wirbellosen. Alle Warane jagen Beute, die kleiner ist als sie selbst, auch wenn Beutetiere durchaus um die 20 % des eigenen Körpergewichts ausmachen können. Nur der Komodowaran ("V. komodoensis") jagt große Säugetiere wie beispielsweise Hirsche.

Eine Ausnahme unter den größtenteils fleischfressenden Waranen ist die Untergattung "Philippinosaurus" mit den 3 Arten Grays Waran ("V. olivaceus"), Panay-Waran ("V. mabitang") und "V. bitatawa". Diese Arten fressen neben einem gewissen Anteil an kleinen Wirbellosen fast ausschließlich Früchte, bevorzugt von Schraubenbäumen ("Pandanus"). Die drei Arten von "Philippinosaurus" entwickelten einen ausgeprägten Blinddarm. Er enthält symbiontische Bakterien und erleichtert den Aufschluss der Pflanzennahrung. Bei allen anderen Waranen fehlt der Blinddarm oder ist nur rudimentär ausgeprägt.

Die meisten Arten der Warane suchen züngelnd große Gebiete nach Nahrung ab. Mit ihrer durch hohe Sauerstoffkapazität bedingten großen Ausdauer verwenden sie einen verhältnismäßig großen Teil ihrer Zeit zur Nahrungssuche. Während ihrer Suche verbringen sie wiederum viel Zeit damit, erfolgversprechende Orte wie Wurzelwerk, Laubhaufen, Baue oder hohle Baumstämme zu untersuchen. In Laub o. ä. versteckte Beute wird mit der Schnauze oder den Vordergliedmaßen hervorgewühlt. In der Nähe verlassen sich Warane bei der Jagd auf den Sehsinn: Sobald sich die Beute bewegt, wird sie in einer schnellen Vorwärtsbewegung gepackt. Kleine Beutetiere werden lebendig verschluckt, große Beutetiere werden totgeschüttelt oder gegen harte Gegenstände geschlagen. Etliche Warane jagen auch in Bäumen. Teils wasserbewohnende Arten hingegen suchen u. a. auf dem Gewässerboden laufend und züngelnd nach Beute. Wieder andere Arten schwimmen bei der Jagd frei im Wasser und verfolgen teilweise auch aktiv schwimmend Fische. Ebenso können semiaquatische Warane durch heftige Seitwärtsbewegungen ihres Schwanzes Fische an Land oder in seichtes Wasser befördern, wo sie leicht zu fangen sind. Mit ihrem Geruchssinn spüren Warane vergrabene Reptiliennester auf, die sie ausgraben. Nur wenige Warane scheinen Lauerjäger zu sein, über deren Jagdverhalten ist jedoch nur wenig bekannt. Das Jagdverhalten von Waranen korreliert mit ihrer artspezifischen Stoffwechselrate und aerobischen Kapazität: Während Arten mit hohen Stoffwechselrate weite Gebiete absuchen, zeichnen sich die Lauerjäger durch recht niedrige aerobische Kapazitäten aus.

Beute wird üblicherweise mit dem Kopf voran und ganz verschluckt. Die dünne Zunge der Warane ist nicht in der Lage, ein im Maul befindliches Beuteobjekt Richtung Speiseröhre zu bewegen. Anfänglich wird unter Ausnutzung der Schwerkraft der Kopf hochgestreckt, um das Beutetier in den geweiteten Schlund zu befördern. Reicht dies nicht aus, so wird das Beutetier mithilfe von Felsen oder der Erdoberfläche als Widerstand weiter in den Rachen gedrückt oder der Waran setzt den Zungenbeinapparat zur weiteren Manipulation der Beute ein. Dabei wird zuerst der Mundboden mithilfe des Zungenbeinapparats gehoben. Anschließend wird der Zungenbeinapparat zurückgezogen und wieder entspannt. Das Beuteobjekt wird auf diese Weise in Richtung Kehlregion und Speiseröhre gezogen. Sobald das Beuteobjekt noch tiefer im Schlund ist, verändert sich das Bewegungsmuster: Der Zungenbeinapparat wird vor das Beuteobjekt bewegt. Dann wird der Zungenbeinapparat angehoben, um die Kehlregion zu komprimieren. Anschließend wird der Zungenbeinapparat nach hinten gezogen und das Beuteobjekt Richtung Speiseröhre geschoben. Beim Trinken spielen die Muskeln des Zungenbeinapparats offenbar keine Rolle. Größere Beute wird teilweise mit den Vorderbeinen fixiert, um dann mit den Kiefern einzelne Stücke aus ihr herauszureißen.

Die Paarung findet üblicherweise nur während eines kurzen Zeitfensters des Jahres statt; Arten aus besonders äquatornahen Gebieten haben jedoch recht ausgedehnte Paarungszeiten. Bei den meisten Arten sondern die Weibchen offenbar Pheromone ab, welche die Männchen anlocken. Diese Duftstoffe werden aller Wahrscheinlichkeit nach in sogenannten Präanaldrüsen produziert, welche vor der Kloake in die Haut eingelagert sind. Von anderen Arten ist wiederum bekannt, dass sich die Geschlechter oft an Aas treffen. Zur Paarungszeit sind die Männchen besonders aktiv und legen ungewöhnlich große Distanzen auf der Suche nach Weibchen zurück. Wenn sie ein Weibchen finden, so umwerben die Männchen der meisten Arten die potenzielle Partnerin durch Bezüngeln, Kratzen und Anstupsen mit der Schnauze. Die Paarung verläuft wie bei den meisten Echsen: Das Männchen besteigt das Weibchen, legt seine Vorderbeine um ihre Schultern und führt von der Seite einen Hemipenis in die Kloake des Weibchens. Bei einigen Arten wehren sich die Weibchen gegen die ersten Paarungsversuche, indem sie nach den Männchen schlagen oder sie beißen; die Männchen dieser Arten fixieren die Weibchen mit ihren Vorderbeinen besonders stark. Auch ist bekannt, dass sich einige Arten nicht unmittelbar paaren, sondern erst 1–2 Tage nach dem Aufeinandertreffen. Treffen sich mehrere Männchen bei einem Weibchen, so kommt es zum Kommentkampf um das Recht zur Paarung.

Die Trächtigkeit dauert bei den meisten Arten in Gefangenschaft um die 4–6 Wochen. Die Gelege umfassen bei frei lebenden Tieren je nach Art im Schnitt 2,5–24,5 Eier. Besonders fruchtbar sind die afrikanischen Arten. Die Eier von Waranen haben eine lederartige Schale und wiegen im Schnitt artabhängig 3,1–131,9 g. Größe und Anzahl der Eier eines Geleges nehmen mit der Größe des Weibchens und dem Nahrungsangebot zu. Das gesamte Gelege kann bei hochträchtigen Weibchen um die 50 % des Körpergewichts ausmachen. Der Zeitpunkt der Eiablage variiert stark von Art zu Art und mit dem Klima in ihrem Verbreitungsgebiet. Meist werden die Eier so gelegt, dass die Jungtiere zum Höhepunkt der Regenzeit schlüpfen; so haben sie nach der Geburt das höchstmögliche Nahrungsangebot. Die Weibchen bodenbewohnender Arten legen ihre Eier meist in selbstgegrabene und anschließend wieder zugeschüttete Nisthöhlen (oft in Böschungen gegraben), baumbewohnende Arten oft in Baumhöhlen. Eine ganze Reihe von Arten legt ihre Eier in Termitenhügel, baumbewohnende Warane auch in die Nester von baumbewohnenden Termiten. Dazu wird ein Tunnel in den Hügel gegraben und am Ende eine Kammer zur Eiablage ausgehöhlt. Die Weibchen füllen das Loch nur teilweise auf; die Termiten bauen den Rest wieder zu. In den Termitenbauten sind Luftfeuchtigkeit und Temperatur weit stabiler als außerhalb des Baus, und die Eier sind vor Beutegreifern weitgehend in Sicherheit.

Die durchschnittliche Brutdauer (Inkubationszeit) bei 30 °C beträgt von Art zu Art 91,7–226 Tage (Thompson & Pianka 2001, 33 Arten). In der Natur kommen bei einigen Arten auch Inkubationszeiten von bis zu 300 Tagen vor, die Eier überdauern also die Trockenzeit und schlüpfen zur nächsten Regenzeit. Die Geschlechtsdetermination erfolgt bei Waranen genetisch: Die Weibchen sind hemizygot mit einem WZ-Paar von Geschlechtschromosomen, die Männchen sind mit ZZ homozygot (ZW/ZZ-System). In Termitenbauten geschlüpfte Jungtiere graben sich bei einigen Arten selber frei, von anderen in Termitenbauten nistenden Arten ist hingegen bekannt, dass die Weibchen die geschlüpften Jungtiere aus dem harten Bau freigraben. Offenbar erinnern sich die Weibchen an ihren Eiablageplatz und kehren regelmäßig dorthin zurück. Genaueres ist über diese mütterliche Fürsorge nicht bekannt. Jungtiere können in einem Termitenhügel 2–3 Wochen überleben, indem sie von ihrem Dotter zehren. Ansonsten zeigen Warane keine Fürsorge für ihre Jungtiere.

Über das Wachstum von Waranen in der Natur liegen kaum Daten vor. In Gefangenschaft erreichen kleine Arten oft nach rund einem Jahr ihre nahezu endgültige Größe und wachsen dann nur noch sehr langsam. Große Arten hingegen wachsen oft noch im Alter von über 5 Jahren. Die Geschlechtsreife tritt je nach Art früher oder später ein, beim Komodowaran ("V. komodoensis") zum Beispiel nach 5 Jahren und beim Kurzschwanzwaran ("V. brevicauda") teilweise schon nach 10 Monaten.

Bisher wurde bei drei Arten der Warane von Parthenogenese berichtet, wahrscheinlich verfügen also alle Arten über diese Fähigkeit. Fälle von Parthenogenese sind sehr selten, und Berichte stammen ausschließlich von in Gefangenschaft lebenden Weibchen, die keinen Kontakt zu männlichen Tieren hatten. Die Parthenogenese erfolgt bei Waranen automiktisch mit terminaler Fusion, das heißt, dass anfänglich eine ganz normale Meiose stattfindet. Es liegen also haploide Keimzellen vor. Durch besondere Polkörperchen verschmelzen anschließend haploide Keimzellen mit dem gleichen Erbgut wieder zu diploiden Zygoten (also Selbstbefruchtung). In der Konsequenz bestehen alle Chromosomenpaare aus gleichen Chromosomen, auch die Geschlechtschromosomen. Bei Waranen liegt das ZW-System zur Geschlechtsdetermination vor; Weibchen haben das Geschlechtschromosomenpaar ZW, Männchen ZZ. Ein Jungtier mit zwei W-Geschlechtschromosomen stirbt bereits im Ei ab. Daher schlüpfen nur Männchen, diese haben von ihrer Mutter zwei Z-Chromosomen erhalten. Da gewissermaßen nur „eine Hälfte“ des mütterlichen Erbguts ausgeprägt ist, sind zahlreiche Gene homozygot. Die Auswirkungen durch ansonsten rezessive, schädliche Mutationen kann mit 10 bis 15 Generationen Inzucht zwischen Geschwistern verglichen werden. So sterben auch männliche Tiere oft schon im Ei ab und nur in seltenen Fällen sind parthenogenetisch gezeugte Warane lebensfähig. Der Nutzen von Parthenogenese bleibt höchst spekulativ.

Den meisten Waranen stellen Schlangen, andere Waranarten, Greifvögel und Raubsäuger nach. Wasserlebende Arten werden auch von großen Raubfischen gejagt. Ausgewachsene Exemplare großer Arten haben hingegen nur wenige Feinde. Daneben werden Warane von diversen Ekto- und Endoparasiten befallen; am häufigsten sind Zecken aus den Gattungen "Aponomma" und "Amblyomma" sowie Fadenwürmer aus der Gattung "Abbreviata".

Meistens fliehen Warane vor Feinden in ein Versteck, speziell größere Arten können aber auch aggressiv auf Feinde reagieren. Sie zeigen ein ähnliches Drohverhalten wie gegenüber Artgenossen und zischen laut. Warane wehren sich gegen Feinde durch Bisse und durch Schläge mit ihrem Schwanz. Nach einzelnen Berichten können Schwanzschläge von großen Exemplaren die Beine von Hunden brechen. Menschen gegenüber fliehen die allermeisten Arten sofort, und auch der große Komodowaran ("V. komodoensis") beißt nur, wenn er in die Enge getrieben wird. Nur von wenigen Waranen ist bekannt, dass sie sich tot stellen.

Daten zur Mortalität und Lebenserwartung sind rar. Speziell junge Warane dürften in der Natur eine außerordentlich hohe Mortalität haben. Daten zur Lebenserwartung sind praktisch nur aus Gefangenschaft bekannt, wo sich Warane als vergleichsweise langlebig erweisen. Für mehrere Arten sind Lebensalter um die 10 Jahre belegt. Der Komodowaran ("V. komodoensis") kann wahrscheinlich über 30 Jahre alt werden, und auch Exemplare von kleinen Waranarten wurden in Ausnahmefällen bis zu 20 Jahre in Gefangenschaft gehalten.

Die Gattung der Warane ("Varanus") bildet mit einigen ausgestorbenen Gattungen die Familie Varanidae. Der nächste rezente Verwandte ist der Borneo-Taubwaran ("Lanthanotus borneensis"), der in eine eigenständige, monotypische Familie (Lanthanotidae) eingeordnet wird. Varanidae und Lanthanotidae bilden die Schwestergruppe der Shinisauridae mit nur einer rezenten Art, der Krokodilschwanzechse ("Shinisaurus crocodilurus"). Die Klade aus diesen drei Familien bildet zusammen mit den Krustenechsen (Helodermatidae), den Höckerechsen (Xenosauridae), Schleichen (Anguidae) und Ringelschleichen (Anniellidae), die Gruppe der Schleichenartigen (Anguimorpha), die zusammen mit den Leguanartigen (Iguania) und den Schlangen (Serpentes) die Gruppe der Toxicofera innerhalb der Schuppenkriechtiere (Squamata) bilden.

Ungelöst ist das Verhältnis der Warane zu den kretazischen Aigialo- und Mosasauriern, auch wenn diese früher oft in die Nähe der Warane gestellt wurden.

Als Begründer der Waransystematik gilt der deutsche Herpetologe Robert Mertens (1894–1975). 1942 wurden drei wegweisende Arbeiten von Mertens über Warane in den "Abhandlungen der senckenbergischen naturforschenden Gesellschaft" veröffentlicht. Mertens’ Systematik gilt heute zwar als überholt, seine Arbeiten ebneten jedoch den Weg für moderne Systematiker.

Aktuell werden innerhalb der Warane etwa 80 rezente Arten als gültig anerkannt. Momentan werden diese auf 9 Untergattungen verteilt. Diese Unterteilung wurde mit Untersuchungen der Hemipenis­morphologie durch die deutschen Herpetologen Wolfgang Böhme und Thomas Ziegler im Jahr 1997 etabliert, zuvor erschienen bereits einige Arbeiten von Böhme. Sie begründeten die Untergattung "Soterosaurus" (Ziegler & Böhme, 1997) und verwendeten alte Untergattungen oder definierten diese neu, nämlich "Empagusia" (Gray, 1838), "Euprepiosaurus" (Fitzinger, 1843), "Odatria" (Gray, 1838), "Papusaurus" (Mertens, 1958), "Philippinosaurus" (Mertens, 1959), "Polydaedalus" (Wagler, 1830), "Psammosaurus" (Mertens, 1942) und "Varanus" (Merrem, 1820). Innerhalb vom "Empagusia" wird eine "V. bengalensis"-Gruppe separiert, in "Euprepiosaurus" zwischen "V. prasinus"- und "V- indicus"-Gruppe unterschieden, "Odatria" in "V. acanthurus"-Gruppe und "V. timorensis"-Gruppe aufgeteilt, "Polydaedalus" setzt sich aus einer "V. niloticus"-Gruppe und einer "V. exanthematicus"-Gruppe zusammen und in "Varanus" wird eine "V. gouldii"-Gruppe abgesondert. Diese Einteilung stimmt bis auf wenige Punkte mit später durchgeführten molekularbiologischen Untersuchungen überein. Dennoch hat sich die Unterteilung anhand des Hemipenisbaus etabliert, und die Gattungsnamen werden in molekularbiologischen Untersuchungen wieder aufgegriffen. Da noch nicht alle Warane genetisch untersucht wurden, ist noch keine rein molekularbiologisch begründete Systematik in Verwendung.

Eine komplette Liste aller Arten ist unter Systematik der Warane verfügbar. Die Liste ist nach Untergattung sortierbar, ebenso können die Waranarten nach Ergebnissen aus der Molekularbiologie angeordnet werden.

Während der Fossilbeleg der Warane recht spärlich ist, so kann anhand molekularbiologischer Studien (z. B. Ast 2001, Fitch et al 2006, Ziegler et al 2007, Amer & Kumazawa 2008) und einiger wichtiger Fossilien (Hocknull et al 2009) die Entwicklungsgeschichte der Warane rekonstruiert werden. Begünstigt wurde die Ausbreitung der Warane wahrscheinlich durch ihre guten Fähigkeiten zur Fortbewegung. Einen großen Einfluss auf die Ausbreitung der Warane spielten die sinkenden und steigenden Meeresspiegel während des Pleistozäns. Während der Eiszeiten banden Gletscher große Mengen Meerwasser in sich, und in der Folge sanken die Meeresspiegel um bis zu 100 m. Durch das tendenziell eher flache Meer in der indoaustralischen Inselwelt wurde die Ausbreitung auf den Archipeln begünstigt.

Höchstwahrscheinlich entstanden die Warane in Zentralasien oder in Afrika. Hierfür sprechen einerseits die mtDNA-Analysen von Ast (2001), nach denen alle 6 afrikanischen Arten die Schwestergruppe zu den übrigen Waranen bilden, andererseits auch der Fossilbeleg. Primitive Schleichenartige wurden überwiegend in Zentralasien gefunden, und die ältesten bekannten Fossilien von Waranen sind 37 Millionen Jahre alte Wirbel aus Ägypten. Die Gattung der Warane spaltete sich laut molekularer Uhr von Amer & Kumazawa (2008) vor etwa 60 Millionen Jahren ab.

Also wanderten basale "Varanus" entweder aus Zentralasien nach Südasien und Afrika, oder nach Afrika und von dort aus nach Asien. Nach Ast (2001) teilen sich die nicht-afrikanischen Warane in 2 große Kladen auf: Den Indo-Asien-Kladus und den Indo-Australien-Kladus. Der Indo-Asien-Kladus teilt sich in 2 große Gruppen auf: Indo-Asien A und Indo-Asien B. Diese beiden Entwicklungslinien trennten sich vor etwa 51 Millionen Jahren. Indo-Asien A enthält einerseits die bereits von Ziegler & Böhme (1997) postulierte Untergattung "Empagusia", welche bis auf den Rauhnackenwaran ("V.rudicollis") monophyletisch ist. Dieser ist stattdessen das Schwestertaxon zum sogenannten "V. salvator"-Komplex (bei Ziegler & Böhme "Soterosaurus"), welcher zusammen mit "V. rudicollis" das Schwestertaxon zu "Empagusia" excl. "V. rudicollis" ist. Einerseits entwickelte sich in Südostasien und im Sunda-Archipel also "Empagusia", andererseits eine "rudicollis"-ähnliche Art. Das Ausmaß genetischer Variabilität innerhalb verschiedener "V. salvator"-Arten und Ast's (2001) Analysen lassen vermuten, dass eine "rudicollis"-ähnliche Art während einer Periode von global niedrigem Meeresspiegel während des Pleistozäns in die Philippinen einwanderte. Dort entstanden der heutige "V. rudicollis" sowie "V. nuchalis" mit ebenfalls rauhen Nackenschuppen, während eine "V. cumingi"-ähnliche Form der Ursprung für eine Radiation Richtung Süden und Westen war. Aus dieser Radiation gingen zahlreiche Arten des "V. salvator"-Komplexes hervor (z. B. "V. salvator", "V. togianus").

In Indo-Asien B fand die erste Aufspaltung vor etwa 34 Millionen Jahren statt. Daraus ging die philippinische Untergattung "Philippinosaurus" und die Untergattung "Euprepiosaurus" hervor. "Euprepiosaurus" entwickelte sich aller Wahrscheinlichkeit nach auf den Molukken, durch den schlechten Fossilbeleg ist dies jedoch nur eine von mehreren Möglichkeiten. Die Untergattung "Euprepiosaurus" unterteilt man in die zierlich gebaute, baumbewohnende "V. prasinus"-Gruppe und die oft ans Wasser gebundene "V. indicus"-Gruppe, welche kräftiger gebaut ist und seitlich zusammengedrückte Schwänze aufweist. Von den Molukken wanderte diese höchst diverse Gruppe nach Neuguinea und auf die Salomonen aus, einzelne Arten auch bis nach Australien. Die genauen Speziationsprozesse bleiben ungeklärt, einzig die Monophylie der beiden Gruppen ist bestätigt. Wahrscheinlich spielte allopatrische Artbildung auf den zahlreichen kleinen Inseln eine entscheidende Rolle und begründete die Vielfalt sowie den hohen Grad an Endemismus.

Der Indo-Australische Kladus erreichte vor etwa 15 Millionen Jahren Australien; als Ausbreitungskorridor kommen die Kleinen Sunda-Inseln in Frage. Anfangs bildeten sich in sehr schneller Speziation drei Gruppen aus: Einerseits die Zwergwarane der Untergattung "Odatria", andererseits die zwei Schwestergruppen "V. gouldii" und "V. varius"-Gruppe. Der Split zwischen geringer und enormer Körpergröße ist innerhalb der australischen Warane basal. Die Artbildungsrate nahm zwar bis heute wieder ab, erfolgte jedoch nach der Kolonisation sehr schnell. Bis heute leben die meisten Arten der Warane in Australien. "Odatria" wird in die eher baumbewohnende "V. tristis"-Gruppe und die bodenbewohnende "V. acanthurus"-Gruppe gespalten. Die "V. gouldii"-Gruppe enthält alle typischen großen australischen Warane bis auf den Buntwaran ("V. varius"). Dieser ist näher mit dem Papuawaran ("V. salvadorii") auf Neuguinea und dem Komodowaran ("V. komodoensis") verwandt. Diese sehr großwüchsige Gruppe (Buntwaran 2 m, Papua-Waran und Komodowaran > 2,5 m) entwickelte sich in Australien. Während der niedrigen Meeresspiegel während des Pleistozäns wanderten einige Vertreter dieser Gruppe wieder aus Australien aus. Am Fossilbeleg kann die schrittweise Ausbreitung gen Nordwesten über Timor und die kleinen Sunda-Inseln bis nach Java belegt werden. Erst in jüngerer Zeit starben Vertreter der "V. varius"-Gruppe in großen Teilen ihrer Verbreitung aus, so dass heute nur noch "V. varius" in Australien und "V. salvadorii" sowie "V. komodoensis" außerhalb von Australien bleiben. Einige Warane der "V. gouldii"-Gruppe erreichten später wieder Neuguinea; dazu gehört z. B. eine Unterart des Arguswarans ("V. panoptes horni").

Die Evolution der Warane wurde maßgeblich von der Wallace-Linie beeinflusst. Östlich dieser biogeographischen Grenze existieren keine Raubtiere (Carnivora). Westlich der Wallace-Linie leben vor allem große Waranarten und nur sehr wenige kleine Arten. Östlich der Wallace-Linie hingegen nimmt die Anzahl kleiner Waranarten (z. B. "V. prasinus"-Gruppe und "Odatria") enorm zu, während die Anzahl kleiner Raubsäuger (z. B. Marder) stark abnimmt. Westlich der Wallace-Linie können große Waranarten existieren, da sie viele Jungtiere haben und diese schnell wachsen. Somit sind diese Arten gegen Bejagungsdruck von kleinen bis mittelgroßen Raubsäugern resistent. Kleine Arten sind in jedem Alter diesem Druck ausgesetzt. In Wallacea hingegen konnten sie entstehen und existieren bis heute. Gleichzeitig nehmen sie die ökologische Nische von kleinen Raubsäugern ein.

Von Waranen liegen als Fossilien meist Wirbel vor, insgesamt ist der Fossilbeleg sehr spärlich. In Afrika kennt man mit "V. rusingensis" nur eine benannte fossile Waranart, welche gleichzeitig der älteste mit einem binominalen Namen beschriebene Waran überhaupt ist. Das kenianische Fossil stammt aus dem frühen Miozän. Auch in Europa lebten Warane, besonders weit verbreitet war der pliozäne "V. marathonensis". In Deutschlands und Frankreichs Miozän fand man "V. hofmanni". In Europa starben die Warane wahrscheinlich im Zuge einer Klimaabkühlung etwa während der Eiszeiten aus. In Asien und Australien fanden Paläontologen ebenfalls einige Fossilien von ausgestorbenen und heute noch lebenden Arten, insbesondere auch einige sehr große Arten. Der wohl bekannteste fossile Waran ist "V. priscus", der im Pleistozän von Australien lebte und eine Länge von etwa 6 m erreichte.
Anhand seines Schädelbaus kann "V. priscus" der "V. varius"-Gruppe zugeordnet werden.

Warane sind bedeutend für den internationalen Lederhandel; Waranleder ist neben der oft attraktiven Musterung auch lange haltbar und wird zu Uhrarmbändern, Schuhen, Geldbeuteln, Handtaschen und anderen Gütern verarbeitet. Daneben ist das Fleisch von Waranen für die lokale Bevölkerung ein wichtiges Nahrungsmittel, bevorzugt gegessen werden Leber und Schwanzansatz sowie die Eier der Tiere. In Asien werden insbesondere Bindenwaran ("V. salvator"), Gelbwaran ("V. flavescens") und Bengalenwaran ("V. bengalensis") bejagt, in Afrika vor allem der Nilwaran ("V. niloticus"), der Steppenwaran ("V. exanthematicus") und der Weißkehlwaran ("V. albigularis"). Wichtige Exporteure in Asien sind Indonesien, die Philippinen, Thailand, Bangladesch, Indien und Pakistan, in Afrika Nigeria, Sudan, Mali und Kamerun. In Australien sind Warane keiner Verfolgung durch den Menschen ausgesetzt. Die Anzahl der getöteten Exemplare pro Jahr geht bei einigen Arten wahrscheinlich in die Millionen. Von einigen Arten werden jährlich auch mehrere Tausend Exemplare für den Heimtierhandel gefangen, insbesondere der Steppenwaran ("V. exanthematicus") und der Nilwaran ("V. niloticus") sind in dieser Hinsicht bedeutend. Gewerbliche Zucht von Waranen wäre gegenüber der Jagd auf frei lebende Exemplare sehr unrentabel, daher stammen alle Waranhäute von Wildfängen. Gelegentlich werden auch die Praktiken der Lederindustrie kritisiert; in Südostasien werden Bindenwarane aufgrund unzureichender Tötungsmethoden (Hammerschläge auf den Kopf) oft lebendig gehäutet. Zuvor werden die Tiere tagelang mit zusammengebundenen Beinen gelagert. Daneben stellen eine Reihe von Ethnien aus Waranen traditionelle Medizin her. Warane machen sich als Vertilger von Schädlingen wie Nagern und Insekten nützlich. Andererseits sind sie oft wegen Angriffen auf kleine Haustiere wie Hühner unbeliebt.

Daneben existieren in zahlreichen Ethnien kulturelle Bezüge zu Waranen, sowohl positive als auch negative. Aus Höhlen in der Nähe von Bhopal (Indien) sind 10.000 Jahre alte Zeichnungen von Waranen bekannt. Ein besonders ungewöhnliches Verhältnis zu Waranen haben die Bugis und Makassaren auf Sulawesi: Sie sehen Warane als Zwillinge ihrer Kinder und schreiben ihnen eine menschliche Seele zu. Die Echsen werden in den Familienalltag eingebunden.

Einige Arten der Warane sind beliebt in der Terraristik. Dies ist jedoch auch mit massenhaften Lebendimporten von Wildfängen sowie teils auch unverantwortlicher oder unartgerechter Haltung verbunden, etwa wegen falscher Ernährung oder zu kleinen Unterkünften.

Die Rote Liste gefährdeter Arten der IUCN hat Einträge für 20 Arten von Waranen. Von diesen 20 Arten bezeichnet die IUCN 13 als ungefährdet ("least concern"), 1 als gering gefährdet ("near threatened") und 3 als nicht ausreichend bekannt ("data deficient"). Als gefährdet ("vulnerable") werden der Komodowaran ("V. komodoensis") und der Grays Waran ("V. olivaceus") geführt und der Panay-Waran ("V. mabitang") wird als stark gefährdet eingestuft. Das Washingtoner Artenschutzabkommen (CITES) legt Handelsbeschränkungen auf alle Waranarten und aus ihnen hergestellte Produkte, diese werden jedoch teilweise nicht beachtet. 5 Arten sind in Anhang I gelistet, alle restlichen Arten in Anhang II.

Eine Reihe von Waranarten ist durch Habitatzerstörung, Habitatfragmentierung und Jagd bedroht, einige besonders stark bejagte Arten scheinen jedoch dem Verfolgungsdruck durch hohe Fortpflanzungsraten standzuhalten und gelten daher auch als nicht gefährdet (z. B. Nilwaran, "V. niloticus" & Bindenwaran, "V. salvator"). Ebenso sind viele Arten sehr anpassungsfähig und daher durch Habitatzerstörung nur wenig bedroht, während andere starke Bestandseinbußen erleiden. Kleine Waranarten, etwa Vertreter der Untergattung "Odatria" in Australien, können von räuberischen Neozoen wie etwa Hauskatzen dezimiert werden. In Australien erleiden größere, Amphibien jagende Warane starke Rückgänge durch die Einbürgerung der Aga-Kröte ("Bufo marinus"). Die Echsen kennen diese giftige Kröte nicht und sterben an deren Hautgift. Hierzu genügt es, die Kröte beim Beutefang ins Maul zu nehmen. Populationen von großen Waranarten nehmen oft um etwa 90 % ab, wenn Agakröten in ihren Lebensraum einwandern.




</doc>
<doc id="10767" url="https://de.wikipedia.org/wiki?curid=10767" title="Chaos Communication Congress">
Chaos Communication Congress

Der Chaos Communication Congress ist ein mehrtägiges, in Deutschland stattfindendes Treffen der internationalen Hackerszene, das vom Chaos Computer Club (CCC) ausgerichtet und organisiert wird. Der Kongress widmet sich in zahlreichen Vorträgen und Workshops technischen und gesellschaftspolitischen Themen. 2015 haben mehr als 13.000 Menschen am Congress teilgenommen.

Der Kongress findet einmal im Jahr statt, von der Gründung 1984 an bis 2004 vom 27. bis zum 29. Dezember, seit 2005 vom 27. bis zum 30. Dezember. Als Abkürzung dient die laufende Nummer der Veranstaltung, ergänzt um den Zusatz C3 (für „Chaos Communication Congress“, Details s. u.).

Nachdem der Kongress, der seit 1984 im Eidelstedter Bürgerhaus in Hamburg stattfand, für diesen Ort zu groß geworden war, zog er 1998 nach Berlin ins Haus am Köllnischen Park, wo er von mehr als 4.000 Teilnehmern besucht wurde. Von 2003 bis 2011 fand der Kongress im Berliner Congress Center am Alexanderplatz statt. 2012 wurde er ins Congress Centrum Hamburg (CCH) verlegt. Im Dezember 2013 besuchten ihn über 9.000 Teilnehmer. Das gesteigerte Interesse wurde der Globalen Überwachungs- und Spionageaffäre und den Veröffentlichungen Edward Snowdens zugerechnet. 2017 zog der Kongress in die Leipziger Messe, da das CCH wegen Sanierungsarbeiten nicht mehr zur Verfügung stand.

Der Kongress bemüht sich um möglichst niedrige Eintrittspreise – vor allem, um Jugendlichen die Teilnahme zu ermöglichen. 2011 kostete ein Ticket für die gesamte Kongressdauer 80 Euro, für Jugendliche unter 18 Jahren 25 Euro. Ein großer Teil der Referenten rekrutiert sich aus der Szene selbst, und die organisatorische Arbeit vor Ort wird von freiwilligen Helfern geleistet, die im CCC-Jargon als Engel bezeichnet werden.

Teil des Kongresses ist das "Hackcenter", ein großes Areal, in dem die verschiedenen regionalen Gruppierungen des Clubs mit ihrer Technik auf dem Kongress präsent sind. Das Hackcenter und die anderen Bereiche der Veranstaltung sind über eine breitbandige Anbindung mit dem Internet verbunden. Der CCC legt aber Wert auf die Feststellung, dass es sich beim Hackcenter nicht um eine LAN-Party handelt, sondern um ein „Hands-On“-Labor zum gemeinsamen Erforschen und Testen von Netzwerktechnologie. Mit dem Umzug ins Congress Centrum Hamburg im Jahr 2012 wurde das Hackcenter um so genannte "„Assemblies“" erweitert, abgegrenzte Bereiche außerhalb der Vortragssäle, die verschiedenen sozialen Gruppierungen und Projekten als Präsentationsfläche dienen konnten.

Von 1997 bis 2004 wurde während des Kongresses gleichzeitig auch die "Deutsche Meisterschaft im Lockpicking" ausgetragen.

Das Streaming der Vorträge wurde die letzten Jahre von der Forschungsgemeinschaft elektronische Medien e. V. (FeM) umgesetzt. Durch die hohe Nachfrage war 2007 und 2008 die 1-Gbit/s-Anbindung der TU Ilmenau zu 99 Prozent ausgelastet. Beim Wechsel des Chaos Communication Congress nach Hamburg (29C3), konnten die Rechnerressourcen und Bandbreite anderer Studentennetzwerke in Deutschland genutzt werden. Außerdem erhielt man Unterstützung aus dem CCC-Umfeld. Im Jahr darauf wurde innerhalb des CCC das Video Operation Center (VOC) ins Leben gerufen, welches unterstützt wurde. Seit dem 31C3 hat das VOC die Leitung übernommen und wird von der FeM sowie der ags (TU Braunschweig) unterstützt.

Statt einer Creative-Commons-by-nc-nd-Lizenz für 32C3-Videos wurden die meisten 33C3-Videos mit einer CC-by-Lizenz publiziert.

Im Rahmen des Chaos Communication Congress 2009 verschafften sich Unbekannte vermutlich illegal Zugang zu internen Daten der Singlebörse Ma-flirt.de, zudem wurden öffentlich zugängliche Profilfotos von der Singlebörse Harzflirt.de heruntergeladen. Zu diesen Daten wurden Download-Links im Kongress-Wiki des CCC erstellt. Passwörter wurden dort direkt veröffentlicht. Ein älterer Hack der Kundendatenbanken des Bekleidungshändlers Thor Steinar wurde ebenfalls bekanntgemacht. Zu den veröffentlichten Daten gehörten Profilnamen, Passwörter, E-Mail-Adressen, Ortsangaben, Wohnadressen, Fotos und Umsatzzahlen. Zwei der Seiten stehen im Ruf, von Mitgliedern der rechten Szene frequentiert zu werden, die anderen nicht. Der Verein wollte zu den Datenschutzverletzungen keine Stellungnahme geben. Kongressteilnehmer distanzierten sich jedoch von dem Vorfall. Er stehe im Widerspruch zur Hackerethik.

Der Chaos Communication Congress steht nahezu jedes Jahr unter einem Motto, meist in Bezug auf wichtige Themen des zurückliegenden oder kommenden Jahres.

Seit dem Chaos Communication Congress 1999 hat sich eine abkürzende Schreibweise eingebürgert. Anstatt "16. Chaos Communication Congress" wurde der Begriff "16C3" verwendet. Die offizielle Schreibweise des Chaos Communication Congress 2004 lautet somit "„21C3: The Usual Suspects“ 21. Chaos Communication Congress". Der 20. Kongress 2003 hingegen bildete mit dem Kürzel NaN eine zum Motto passende Bezeichnung.




</doc>
<doc id="10769" url="https://de.wikipedia.org/wiki?curid=10769" title="Federal Reserve System">
Federal Reserve System

Das Federal Reserve System [], oft auch Federal Reserve oder kurz Fed (auch FED, obwohl es sich nicht um ein Akronym handelt) genannt, ist das Zentralbank-System der Vereinigten Staaten, das allgemein auch "US-Notenbank" genannt wird. Es besteht aus dem "Board of Governors", zwölf regionalen "Federal Reserve Banks", dem Federal Open Market Committee (FOMC), einer Vielzahl von Mitgliedsbanken (Mitgliedspflicht ab einer bestimmten Größe) und anderen Institutionen.

Die Fed berichtet regelmäßig an den Kongress der Vereinigten Staaten über ihre Aktivitäten und ihre Pläne zur Geldpolitik. Das Tagesgeschäft und die operativen Entscheidungen der Fed werden von ihr frei und eigenständig entschieden. Der Kongress hat allerdings die Befugnis, die Gesetze betreffend die Geschäftstätigkeit der Fed zu ändern.

Kritik am Federal Reserve System wird bereits seit seiner Konzeption im Jahre 1913 geäußert. Kritiker machten es unter anderem für die Great Depression von 1929 und später für die Finanzkrise ab 2007 verantwortlich.

1790 wurde auf Initiative des damaligen US-Finanzministers Alexander Hamilton die „First National Bank of the United States“ gegründet. Die Zentralbank war mit ein Grund für die Gründung der ersten politischen Parteien der USA. Die Federalists befürworteten eine Nationalbank, während Jeffersons Republikaner sie vehement ablehnten. Der Konzessionsvertrag dieser ersten Zentralbank der USA lief 1811 während der Amtszeit des demokratisch-republikanischen Präsidenten James Madison aus und wurde nicht verlängert.

Madison sah sich durch eine nicht zu kontrollierende Inflation Ende 1815 gezwungen, zusammen mit dem Kongress einen Kompromiss zur Stabilisierung der Währung auszuarbeiten, der 1816 zur Gründung der Second Bank of the United States führte. Die „Second Bank“ entsprach in ihrer Aufgabe und Struktur weitestgehend der „First Bank“. Die Erneuerung der Charta der „Second Bank“ wurde jedoch von Präsident Andrew Jackson durch sein Veto 1832 verhindert, und es setzte ein langsamer Auflösungsprozess ein, der mit dem Auslaufen der Charta 1836 sein Ende fand.

1863 und 1864 wurden basierend auf den National Bank Acts Nationalbanken geschaffen, welche durch das US-Finanzministerium abgesicherte und gedruckte Banknoten ausgeben durften. Hauptziel dieser Gesetze war die Schaffung einer einheitlichen Währung und die Lösung des Problems, dass Banknoten von verschiedenen Mitgliedsstaaten gleichzeitig in Umlauf waren.

Ende des 19. Jahrhunderts erlebte die amerikanische Wirtschaft eine der schlimmsten Finanzkrisen, durch Bankzusammenbrüche und mehrfache Geldsystemschwankungen.
Der Vorschlag zur Etablierung einer Zentralbank nach europäischem Vorbild stammte vom Bankier Paul Moritz Warburg (1868-1932) aus der Hamburger Bankiersdynastie Warburg. Paul M. Warburg war nach seiner Ankunft 1902 in New York fassungslos über den primitiven Zustand des amerikanischen Bankensystems. Als ausgemachter Experte auf dem Gebiet nationaler Zentralbanken in Europa bemängelte Warburg das Fehlen einer US-Zentralbank und schlug die Etablierung einer privaten amerikanischen Zentralbank nach Muster der deutschen Reichsbank vor, um die Geldhoheit vom Staat zu übernehmen. 1903 erstellte Warburg eine Schrift mit dem Titel "Plan für eine Zentralbank". Jakob „Jacob“ Heinrich Schiff (1847-1920), Warburgs Schwager und Seniorpartner bei der führenden Wall Street-Bank Kuhn, Loeb & Co., nahm diese Expertise und präsentierte sie seinem Geschäftspartner James Jewett Stillmann, dem Vorstandsvorsitzenden der "National City Bank" (heute Citibank), der damals größten Bank der USA. Einige Tage später trafen sich dann auch Warburg und Stillman und es kam zu einer konfliktreichen Unterhaltung. Stillman warnte Warburg seine Expertise irgendjemand anderem zu zeigen, da das amerikanische Volk eine Zentralbank strikt ablehnen würde, in der nur Wenige die Einlagen Aller kontrollieren kann. Die Frage der Etablierung einer Zentralbank war Teil des dauerhaften inneramerikanischen Konflikts zwischen Befürwortern zentralstaatlicher Gewalt, die die Rechte des Gesamtstaates ausbauen wollten ("Föderalismus") und derer, die die Einhaltung und Wahrung der Gesetze den einzelnen US-Bundesstaaten überlassen wollte ("Anti-Föderalisten"). Warburg wiess Stillman daraufhin, dass Stillman im Falle einer Panik an den Finanzmärkten das Fehlen einer Zentralbank bereuen werde, woraufhin Stillman das Treffen mit Groll verließ.

Nach der Lektüre von Warburgs Plädoyer für eine US-Zentralbank warnte Jacob Schiff über Jahre hinweg vor den Folgen einer Finanzkrise und ließ die New Yorker Handelskammer bei einer Rede Anfang 1907 wissen: „Wenn wir keine Zentralbank mit einer ausreichenden Kontrolle über die Kreditbeschaffung bekommen, dann wird dieses Land die schärfste und tiefgreifendste Geldpanik seiner Geschichte erleben.“ 
Kurz danach im Herbst 1907 wurde durch die vorübergehende Zahlungsunfähigkeit der Knickerbocker Trust Company die schwere Finanzkrise ausgelöst. Die Krise zwang Stillman zum Rücktritt seines Vorstandsposten bei der "National City Bank" - und verlieh zeitgleich Warburgs und Schiffs Forderung zur Gründung einer US-Zentralbank neue Aktualität.

Infolge der Finanzkrise beschloss der US-Kongress nach dem Ende der Wirtschaftskrise, Rahmenbedingungen für ein sicheres und flexibleres Bankensystem zu schaffen. Warburg wurde als inoffizieller Berater der neu gegründeten "National Monetary Commission" einberufen, die Vorschläge zu einer Reform des US-Bankensystems ausarbeitete. Die "National Monetary Commission" beantragte die Gründung einer Institution, welche die Banken lenkt, Kreditbeschaffungen kontrolliert und Finanz- und Geldkrisen vorbeugt beziehungsweise diese vermindert. Paul M. Warburg publizierte zahlreiche Zeitungsartikel und hielt Reden, die die Notwendigkeit zur Etablierung einer Zentralbank thematisierten. Ein weiterer Meilenstein in Paul M. Warburgs Bemühungen war ein 10-tägiges Treffen im überaus elitären "Jekyll Island Club" (Besitzer: John D. Rockefeller und J.P. Morgan) auf Jekyll Island vor der Küste Georgias im November 1910. Warburg traf sich hier mit drei weiteren US-Bankiers (Frank Vanderlip, Henry P. Davison, Arthur Shelton), dem einflussreichen Senator Nelson W. Aldrich sowie Andrew Piatt, einem führenden Wirtschaftsökonom aus Harvard. Die fünf anderen Teilnehmer standen Warburg zunächst aufgrund seines Status’ als Ausländer und Jude skeptisch gegenüber, doch konnte er sie letztlich durch seine Brillanz überzeugen. In den nächsten Tagen wurde ein detaillierter und umfassender Plan zur Gründung einer US-Zentralbank ausgearbeitet, der als "Aldrich-Plan" zunächst in der Gründung der "National Reserve Association" mündete. Das Geheimnis um die Teilnehmer sowie den Zweck des Treffens vom 20. bis 30. November 1910 auf Jekyll Island wurde bis in die 1930er Jahre streng gehütet.

Das Federal Reserve System wurde vom Kongress der Vereinigten Staaten geschaffen, um ein „Zentralbanksystem zu etablieren, das so gestaltet wurde, dem nationalen Finanzsystem sowohl Flexibilität als auch Stärke hinzuzufügen“. Das Bundesgesetz wurde am 18. September 1913 vom Kongress mit 287 zu 85 Stimmen angenommen; der Senat stimmte nach mehreren Anhörungen am 19. Dezember 1913 mit 54 zu 34 Stimmen ebenfalls zu. Unterschiede der abgestimmten Fassungen wurden von einer gemeinsamen Kommission überarbeitet; die Überarbeitung wurde vom Kongress am 22. Dezember 1913 mit 298 zu 60 Stimmen und vom Senat am folgenden Tag mit 43 zu 25 Stimmen angenommen und am 23. Dezember 1913 von Präsident Woodrow Wilson als "Federal Reserve Act" in Kraft gesetzt.
Das Gesetz sah ein System aus mehreren Regionalbanken und einem siebenköpfigen Verwaltungsrat vor. Banken, die auf nationaler Ebene agierten, mussten sich dem Federal Reserve System anschließen, anderen Banken war die Beteiligung freigestellt. Für ihre Anteile erhalten die Mitgliedsbanken eine festgelegte Dividende von 6 %, sind jedoch nicht am Gewinn beteiligt, der dem Finanzministerium zufällt.

Das Resultat der Bemühungen der Zentralbank-Befürworter war schließlich nach der Wahl Woodrow Wilsons zum US-Präsidenten der Federal Reserve Act vom 23. Dezember 1913, der noch am selben Tag die Gründung der US-Zentralbank FED besiegelte. Dem "Federal Reserve Act" war eine Untersuchung des Kongresses durch Samuel Untermyer, die "Pujo Money Trust Investigation", vorangegangen. Untermyer, als Anwalt Teilhaber der Kanzlei Guggenheimer, Untermyer & Marshall, assistierte auch beim Entwurf des Gesetzes. Der Federal Reserve Act ermöglicht es der Federal Reserve bis heute, Geld ohne intrinsischen Wert als Kreditgeld zu schaffen und es beispielsweise der amerikanischen Regierung gegen Zinsen zu leihen (→ "fractional-reserve banking"). Den ihm angebotenen Vorsitz der Zentralbank lehnte Paul M. Warburg als eben erst eingebürgerter deutscher Jude ab. Stattdessen wurde Warburg Mitglied des ersten Aufsichtsrates in der Geschichte der FED. Während des Ersten Weltkriegs wurde Warburg am 10. August 1916 zum stellvertretenden Vorsitzenden des Federal Reserve-Aufsichtsrats bestellt. Diese Funktion erfüllte er bis zum 9. August 1918. Als Mitglied des Beraterstabes ("Federal Advisory Council") blieb Warburg der US-Zentralbank noch zwischen 1921 und 1926 verbunden. 

Seit dem Beginn der Weltwirtschaftskrise im Herbst 1929 gab es Kritik am Federal Reserve System sowie an der Wirtschaftspolitik des damaligen Präsidenten, des Republikaners Herbert Hoover. Sie war 1932 auch Wahlkampfthema und trug dazu bei, dass Roosevelt die Präsidentschaftswahl Ende 1932 gewann.

Ursprünglich waren die Leiter der regionalen Banken berechtigt, Entscheidungen bezüglich der Politik der Fed zu treffen, ohne dabei Rücksicht auf die Beschlüsse des Board of Governors (Vorstand des Federal Reserve System) zu nehmen, was zu Konflikten zwischen den beiden Parteien führen konnte. Roosevelt berief Marriner S. Eccles;
dieser wirkte beim Entwurf des "Emergency Banking Act" von 1933, beim Banking Act von 1933 und beim "Federal Housing Act" von 1934 mit.

Angesichts der Wirtschaftslage ("Great Depression") änderte die Fed ihre Geldpolitik.
Eccles entwarf den "Eccles-Bill", der als "Banking Act von 1935" das Federal Reserve System restrukturierte (siehe nächsten Abschnitt). Eccles wurde zum Vorsitzenden des Board of Governors des Federal Reserve Systems ernannt; dieses Amt hatte er bis zum 31. Januar 1948 inne.

Der ursprüngliche Federal Reserve Act wurde im Laufe der Jahre mehrfach (insbesondere 1978 und 1981) erweitert beziehungsweise reformiert, um der Fed mehr Flexibilität und Funktionalität zu ermöglichen.

Der Banking Act 1935 gab dem Board of Governors umfangreichere Kontrollrechte.
Er wurde nach dem Emergency Banking Act am 9. März 1935 vom Kongress verabschiedet. Das Gesetz beinhaltete Folgendes:

Die Federal Reserve spielte auch während des Zweiten Weltkrieges eine wichtige Rolle. Damit die Regierung ihre Kriegsschulden finanzieren konnte, drückte sie die Zinssätze nach unten (d. h., sie waren niedrig). Die Politik der Fed verfolgte während der Kriegszeiten zwei Ziele:

Die Verbindung zwischen der Fed und dem US-Kongress war bis Mitte der 1970er-Jahre relativ schwach. Dies änderte sich durch den Federal Reserve Reform Act von 1977 und den Humphrey–Hawkins Full Employment Act (vom damaligen US-Präsident Jimmy Carter im Oktober unterschrieben bzw. in Kraft gesetzt). Die Unabhängigkeit der Fed wurde durch diese zwei Gesetze eingeschränkt; sie war fortan verpflichtet, zweimal jährlich einen verbindlichen Bericht über ihre Pläne bezüglich des Umfangs verschiedener Geldaggregate abzugeben.

Die Fed unterlag bis zum Jahr 1978 nicht der externen Finanzkontrolle durch den amerikanischen Rechnungshof (United States Government Accountability Office, GAO). Bis dahin wurden nur die Aktivitäten der Fed im Rahmen der Finanzierung des Staates geprüft. Seit dem Jahr 1978 (Federal Banking Agency Audit Act) darf das GAO alles prüfen bis auf folgende Ausnahmen:

Mit dem Währungskontrollgesetz ("Monetary Control Act"), das im Juni 1981 in Kraft trat, wurde den Federal Reserve Banks unter anderem die Befugnis gegeben, nicht nur US-Staatsschuldtitel, sondern auch Staatsschuldtitel anderer Länder zu erwerben.

Das Federal Reserve System setzt sich aus den folgenden fünf Bestandteilen zusammen:

Das Federal Reserve System besteht aus zwölf Bankbezirken, in denen es jeweils eine Federal Reserve Bank gibt. Dies sind:

Diese Banken bestreiten ihr Finanzkapital aus dem Finanzkapital ihrer privaten Mitgliedsbanken. Hierbei handelt es sich jedoch nicht um am Markt gehandelte Anteile – vielmehr sind in den USA Banken ab einer bestimmten Größe gesetzlich verpflichtet, Mitglied im Fed zu sein. Die größte Federal Reserve Bank ist in New York City, die auch als einzige unter ihnen Auslandsgeschäfte betreibt.

Das "Federal Open Market Committee" (FOMC, dt.: der Offenmarktausschuss) betreibt die Geld- und Währungspolitik der Vereinigten Staaten; er gilt als wichtigstes Gremium des Fed.
Sein Vorsitzender war von August 1979 bis August 1987 Paul Volcker, vom 11. August 1987 bis 31. Januar 2006 Alan Greenspan, vom 1. Februar 2006 bis 31. Januar 2014 Ben Bernanke und am 1. Februar 2014 folgte diesem Janet Yellen.
Vorstand des Fed ist der "Board of Governors of the Federal Reserve System" (Bundesbankrat) in Washington, D.C. Er besteht aus sieben vom Präsidenten der Vereinigten Staaten benannten und mit Zustimmung des Senats für 14 Jahre gewählten Mitgliedern. Die Mitglieder des Vorstands können im unmittelbaren Anschluss an ihre Amtszeit nicht wiedergewählt werden. Der Vorstand besteht (Stand 13. Oktober 2017) aus:

Aufgabe des Boards ist die Umsetzung der Entscheidungen, die vom "Federal Open Market Committee" ("FOMC") beschlossen werden. Abgesehen von seinen wirtschaftspolitischen Kompetenzen ernennt der Rat auch je drei Direktoren für die zwölf Federal Reserve Banks. Die übrigen sechs Direktoren jeder Federal Reserve Bank werden von den Mitgliedsbanken ernannt.

Als wirtschaftspolitisch wichtigstes Gremium des Fed bestehen die Aufgaben des "Federal Open Market Committee" ("FOMC") u. a. in der Durchführung von Offenmarktgeschäften.
Das FOMC entscheidet, ob der US-Leitzins (die "Target Rate" der Federal Funds Rate) geändert wird. Darüber hinaus kann das Gremium auch Eingriffe in den Devisenmarkt beschließen und so den Wechselkurs des US-Dollar zu anderen Währungen beeinflussen. Deshalb sind Sitzungen des FOMC und Aussagen seiner Mitglieder von den Finanzmärkten Objekt des öffentlichen Interesses.

Das FOMC besteht aus zwölf Mitgliedern: dem Präsidenten der Federal Reserve Bank of New York, den sieben Mitgliedern des "Board of Governors" und vier Mitgliedern, die im jährlichen Wechsel aus den zwölf Vorsitzenden der regionalen Federal Reserve Banks ausgewählt werden. Zu diesem Zweck sind elf der zwölf Banken nach geografischen Aspekten zu vier Gruppen zusammengefasst, die jeweils ein Mitglied des FOMC stellen. Innerhalb der Gruppen erfolgt eine Rotation zwischen den einzelnen Federal Reserve Banks. Aus historischen Gründen nimmt die Federal Reserve Bank of New York an diesem Rotationsverfahren nicht teil – sie hat ein ständiges Stimmrecht im FOMC. Außerdem nehmen die einzelnen Reserve-Bank-Präsidenten an den Sitzungen teil, sind aber nicht stimmberechtigt. Das Gremium tagt acht Mal pro Jahr.

Dem Board untersteht die Federal Reserve Police.

Das Federal Reserve System ist eine staatliche Einrichtung, die allerdings private Anteilseigner hat. Es wurde durch ein Bundesgesetz gegründet, Änderungen an seiner Struktur und seinen Aufgaben sind daher nur durch den Gesetzgeber möglich. Zwar sind die zwölf regionalen Federal Reserve Banks als Aktiengesellschaften organisiert, deren Aktionäre die in ihren Bezirken tätigen privaten Banken sind. Jedoch haben die Aktionärsrechte im Fall der Federal Reserve Banks mit denen privater Banken wenig gemeinsam. Die privaten Banken sind kraft Gesetzes Aktionäre der Federal Reserve Banks und haben keine freie Entscheidung, ob bzw. wie viel sie investieren. Auch sind die Anteile an den Federal Reserve Banks, anders als bei Aktien üblich, nicht übertragbar. (Allerdings sind die Anteile der privaten Banken, welche Aktionäre der zwölf Federal Reserve Banks sind, je nach Rechtsform privatrechtlich frei übertragbar.) Die Mitglieder der Gremien, die über die Geldpolitik der Fed entscheiden, werden nicht – wie das in einer privaten Aktiengesellschaft geschehen würde – durch die Aktionäre gewählt, sondern politisch ernannt (Nominierung durch den US-Präsidenten und Bestätigung durch den Senat).

Auch die Gewinnverteilung der Fed unterscheidet sich erheblich von der privater Aktiengesellschaften, so erhalten die privaten Banken, die Aktien an der Federal Reserve Banks halten, eine vorab gesetzlich fixierte Dividende. Übrig bleibender Gewinn fließt an den amerikanischen Bundeshaushalt. In Relation sind die Dividenden an die Aktionäre vernachlässigbar, so beliefen sich im Jahr 2011 die Dividendenzahlungen an die privaten Banken auf 1,6 Milliarden Dollar, die Gewinnausschüttung an den Bundeshaushalt auf 78,4 Milliarden Dollar. Die Dividende an die Aktionäre ist in erster Linie eine Kompensation dafür, dass die Fed – anders als beispielsweise das Eurosystem – traditionell keine Zinsen auf die Zentralbankguthaben der privaten Banken zahlt.

In Anbetracht dieser Unterschiede zu privaten Aktiengesellschaften bezeichnet sich das Federal Reserve System selbst als „independent entity within the government“. Auch durch amerikanische Bundesgerichte wurde bereits entschieden, dass es sich bei den Federal Reserve Banks um Institutionen des Bundes („federal instrumentalities“) handelt.

Die Hauptaufgaben der Federal Reserve sind:


Die Ziele der Geldmarktpolitik der Fed sind im Federal Reserve Act definiert:


Ihre geldpolitischen Instrumente sind:

Das Federal Reserve System wird seit seiner Gründung 1913 von verschiedenen Seiten kritisiert. Der bis heute gültige "Federal Reserve Act" von 1913 wurde über die Parteigrenzen hinweg erst diskutiert, nachdem US-Präsident Woodrow Wilson erheblichen politischen Druck auf die Kongressabgeordneten ausgeübt hatte, um eine Zustimmung zu erreichen. Die frühesten Auseinandersetzungen über zentrale Banken in den Vereinigten Staaten konzentrieren sich auf ihre Verfassungsmäßigkeit, den privaten Status der Banken und auf die Frage, in welchem ​​Maße die Wirtschaft zentral gelenkt werden sollte. Einige der bekanntesten frühen Kritiker an einem Zentralbanksystem waren Thomas Jefferson, James Madison und Andrew Jackson. Die Kritik begründet sich vor allem darauf, dass es sich bei den Mitgliedsbanken und Eigentümern der Federal Reserve Bank um private Gesellschaften handelt. Kritiker wie beispielsweise der republikanische Kongressabgeordnete Ron Paul bemängeln bis heute, dass durch die Einsetzung des Fed als US-Notenbank der privatwirtschaftliche Einfluss dieser Mitgliedsbanken auf die Geld- und Zinspolitik der USA zu groß sei. Woodrow Wilson soll das Gesetz nach seiner Amtszeit wiederholt als Fehler bezeichnet haben.

Die Wirtschaftswissenschaftler Milton Friedman und Anna J. Schwartz kritisierten erstmals: Das Fed habe die Rezession von 1929 verschärft und so die Große Depression ausgelöst. Nach dem Börsenkrach im Jahr 1929 habe das Fed nichts dagegen getan, dass sich die Geldmenge verringerte, und sich geweigert, Banken vor dem Zusammenbruch zu retten. Dieser Fehler habe dazu geführt, dass eine vergleichsweise milde Rezession in der Katastrophe endete. Friedman und Schwartz vermuten, die Depression sei „ein tragisches Zeugnis für die Bedeutung der monetären Kräfte“ gewesen.

Einige Ökonomen wie John B. Taylor behaupten, das Fed sei zumindest teilweise verantwortlich für die Finanzkrise ab 2007 in den USA: Das Fed habe die Zinsen nach der Rezession von 2001 zu lange zu niedrig gehalten. Anhänger der heterodoxen Österreichischen Schule gehen von ihrer Überinvestitionstheorie aus und geben der Abweichung der Zinspolitik der Fed von "natürlichen Zinsen" die Schuld an der Finanzkrise ab 2007.

Im November 2009 brachte Senator Chris Dodd von der Demokratischen Partei, damals Vorsitzender des Bankenausschusses im Senat der Vereinigten Staaten, einen Gesetzentwurf ein, der die Kompetenzen der US-Notenbank einschränken und eine neue Aufsichtsbehörde für den Bankensektor schaffen sollte. Nach Dodds Ansicht habe das Fed bei der Bewältigung der aktuellen Finanzkrise „auf ganzer Linie versagt“. Risikoreiche Geschäfte der Banken, die zur Finanzkrise geführt hätten, seien vom Fed nicht unterbunden worden.

Vor allem deutschsprachige Antisemiten wiesen seit 1913 oft auf die Beteiligung einzelner Juden wie Paul Warburg an der FED-Gründung hin, um eine Lenkung der FED wie auch der von ihr angeblich gelenkten Reichsbank durch das „Finanzjudentum“ zu behaupten oder anzudeuten: so zum Beispiel der Nationalsozialist Gottfried Feder (1926) und antisemitische Flugblätter des NS-Regimes im Zweiten Weltkrieg.

Die Hauptvertreter der deutschen Mahnwachen für den Frieden von 2014 stellten die FED als angebliche Hauptursache vergangener und gegenwärtiger Kriege und Krisen dar. Lars Mährholz, Gründer der Mahnwachen, sagte bei der Berliner Mahnwache am 7. April 2014, die FED stehe hinter allen Weltkriegen und Konflikten der letzten 100 Jahre und sei eine Privatbank. Das wurde als antisemitischer Code und Leugnung der deutschen Verantwortlichkeit für die Weltkriege kritisiert. Der Querfront-Propagandist Jürgen Elsässer sagte am 21. April 2014 auf der Berliner Mahnwache:

Diese Hervorhebung bestimmter jüdischer Personen als angeblicher Lenker des globalen Finanzsystems gilt als Variante der Verschwörungstheorie vom Weltjudentum. Auch wenn Juden nicht genannt werden, gilt diese Kritikform an der FED als struktureller Antisemitismus, weil sie der kleinen Personengruppe einer Einzelbank ungeheure globale Lenkungsmacht und heimliche Kontrolle über historische Ereignisse zuschreibt. Derartige verkürzte Kapitalismuskritik war im Antisemitismus und Nationalsozialismus übliche Tradition und wird von Antisemiten als Bestätigung ihres Weltbildes verstanden, da die angeblichen Drahtzieher sich leicht mit Juden verknüpfen oder austauschen lassen. Indem auf den Mahnwachen Juden als eigentliche Verursacher von NS-Herrschaft und Zweitem Weltkrieg hingestellt werden, wird die deutsche Geschichte geschichtsrevisionistisch umgedeutet, Schuld und Verantwortung für die Zeit des Nationalsozialismus werden abgewehrt. Laut der Politikwissenschaftlerin Laura Luise Hammel läuft dies auf eine „Strategie zur Relativierung oder sogar Leugnung des Holocaust“ hinaus.

Auch außerhalb Deutschlands lässt sich diese Verschwörungstheorie nachweisen. So verbreitet der amerikanische Verschwörungstheoretiker Des Griffin seit 1976, eine satanistische Verschwörung von Illuminaten, die älter sei als die Welt, plane, eine Neue Weltordnung zu errichten. Zu diesem Zweck hätten sie die Französische und die Russische Revolution angezettelt und eben auch die Federal Reserve gegründet. Als Belege zitiert Griffin ausführlich die Protokolle der Weisen von Zion, ein antisemitisches Pamphlet des frühen 20. Jahrhundert, das vorgibt, eine jüdische Weltverschwörung zu beweisen. Khalid Abdul Muhammad, ein prominenter Sprecher der Nation of Islam, einer Organisation muslimischer Afroamerikaner, behauptete in einer Rede 1993, die Federal Reserve befände sich im Besitz von Juden.




</doc>
<doc id="10774" url="https://de.wikipedia.org/wiki?curid=10774" title="Blüte (Begriffsklärung)">
Blüte (Begriffsklärung)

Blüte ( „Blüte“) steht für:
Siehe auch:



</doc>
<doc id="10776" url="https://de.wikipedia.org/wiki?curid=10776" title="Überwachung">
Überwachung

Überwachung ist die zielgerichtete Beobachtung und Informationserhebung von Objekten, Personen, Personenvereinigungen oder Gegenständen durch am Geschehen unbeteiligte Dritte. Die Überwachung von Personen bezeichnet man auch als Observierung oder Observation, die von Naturphänomenen als Monitoring.

Der Begriff wird auch in einigen anderen Kontexten verwendet, er wird teilweise
negativ konnotiert (zum Beispiel Überwachungsstaat).

Maßnahmen der Überwachung können der Erhöhung der Sicherheit des menschlichen Lebens dienen, der Beobachtung von Naturerscheinungen, militärisch-nachrichtendienstlichen Zwecken, oder dem Werterhalt von Bauwerken und Investitionen.

Man unterscheidet unter anderem:


Die moderne Datenerfassung macht sich zunehmend Technologien aus dem Bereich des elektronischen Kommunikation, insbesondere auch des Internet der Dinge zunutze, wo jeder Sensor in einem Sensornetz auch gleichzeitig einen Prozessor und eine Kommunikationseinheit darstellt. Diese Technologien erlauben schnelles und großräumiges bzw. flächendeckendes Sammeln von Informationen. Die Effektivität der Auswertung der so gewonnenen "Massendaten" (Schlagwort: Big Data) hängt sehr stark an effizienten Methoden aus dem Data-Mining, der Mustererkennung und der künstlichen Intelligenz.

Seit das Thema „Überwachung“ in der Gesellschaft so stark diskutiert wird, ist der Begriff ins Negative abgerutscht. Es gibt jedoch zahlreiche Überwachungsbereiche, die allgemein gewünscht werden oder gegen die es kaum Kritik gibt. Diese fallen etwa in Deutschland je nach individuellem Aufgabengebiet und Gesetzeslage in die Hoheit des Bundes, der Bundesländer, der Kreise, Bezirke oder Kommunen, oder zum Beispiel in das Aufgabengebiet von Betreibern technischer Anlagen. Dazu gehören unter anderem:




Die Überwachung von Privatpersonen oder Unternehmen durch technische oder sonstige Maßnahmen von staatlichen Organen ist in Rechtsstaaten im Allgemeinen streng reglementiert. In Deutschland zählt dazu etwa die Telekommunikations-Überwachungsverordnung sowie zahlreiche andere, zum Teil sehr spezifische Gesetze wie das BKA-Gesetz. Zudem sind in der Strafprozessordnung (StPO) zahlreiche rechtliche Beschränkungen der Staatsorgane vorgesehen, so dürfen polizeiliche Überwachungsmaßnahmen (siehe StPO) generell, außer bei Ausnahmen wie Gefahr im Verzug, nur nach einem richterlichen Beschluss durchgeführt werden (siehe etwa StPO).

Personenbezogene Überwachungsmaßnahmen werden üblicherweise von staatlichen Diensten (Polizei, Staatspolizei, Geheimdienste) eingesetzt, können aber auch der Kontrolle von Arbeitnehmern in Unternehmen dienen. Der Austausch der von staatlichen Diensten ermittelten Daten mit denen von Unternehmen wird als zunehmend problematisch erachtet.

Audiovisuelle Arbeitnehmerüberwachung ist in Deutschland illegal, während beispielsweise in den USA oder in Großbritannien den Arbeitgebern zugestanden wird, ihre Angestellten legal mittels am Arbeitsplatz installierten Kameras zu überwachen. Auch das Mitlesen des E-Mail-Verkehrs ihrer Angestellten ist US-Firmen im Gegensatz etwa zu deutschen Firmen erlaubt.

Der Grad der Überwachung ist ein heiß umstrittenes und sehr problematisches Thema. Einerseits werden beispielsweise in den skandinavischen Ländern und in Großbritannien die neuen Formen der elektronischen Kontrolle als „Errungenschaft der Demokratie“ gepriesen. Andererseits befürchtet beispielsweise der Europäische Gerichtshof in seiner Herleitung für das Recht auf Datenschutz eine Einschränkung der Meinungsfreiheit. Wenn die Bürger nicht mehr wissen, wann und in welchem Maße sie beobachtet werden, werden sie sich aus Angst vor Repressionen auch vorsichtiger (im Sinne von „angepasster“) verhalten.
In Deutschland ist im privaten Bereich der Einsatz von GPS-Ortungstechnik im Rahmen von Personenüberwachungen oder Observationen strafbar. Das Landgericht Lüneburg hat das Anbringen eines GPS-Senders an ein fremdes Fahrzeug durch eine Detektei als strafbar bewertet (Az. 26 Qs 45/11). Das Erstellen eines Bewegungsprofils der betroffenen Person stellt nach Auffassung des Gerichts einen Verstoß gegen das Bundesdatenschutzgesetz (BDSG) dar. Es verletzt die Grundrechte auf informelle Selbstbestimmung. Dieser Auffassung hat sich nun auch das Landgericht Mannheim in einem Urteil im Dezember 2012 angeschlossen (Az.: KLs 408 Js 27973/08).

Ermittlungsbehörden, z. B. Polizeien, dürfen GPS-Sender nur unter bestimmten Voraussetzungen zum Einsatz bringen; dies ist in Deutschland in StPO geregelt. Es muss (der Verdacht auf) eine Straftat von erheblicher Bedeutung vorliegen.

In Österreich werden routinemäßig Ortungsgeräte an Fahrzeuge bei Observationen angebracht. Erst wenn die Zielperson das Ortungsgerät entdeckt sollte jeder Detektiv schnell von sich auch eine Unterlassungserklärung abgeben und so einer Unterlassungsklage vorbeugen. Damit ergeben sich keine weiteren Folgen für die Detektive. Da durch ein Ortungsgerät an einem Fahrzeug nicht zwingend nur Bewegungsdaten einer Person erfasst werden gibt es hier keine Probleme mit der Staatsgewalt. In der Regel haben mehr als nur eine Person Zugang zum Fahrzeug. Ein Ortungsgerät ist heutzutage beinahe unverzichtbar für eine Observation.

Eine andere Form der Überwachung, meist durch Kameras, wird an öffentlichen Plätzen, z. B. Bahnhöfen, als Sicherheitsmaßnahme eingesetzt. In Deutschland wurden diesbezüglich Modellprojekte, etwa in Regensburg durchgeführt, die auf heftigen Widerstand unter Datenschützern stießen. Mittlerweile ist die Videoüberwachung kein Modellprojekt mehr, sondern wird in vielen Städten an öffentlichen Plätzen eingesetzt. Als Begründung werden manchmal „Erfordernisse des Marketings“ genannt, wie etwa in der oberösterreichischen Stadt Wels. Auch Kaufhäuser werden in der Regel videoüberwacht, um Ladendiebstählen vorzubeugen.

Es gibt Anstrengungen, die Videoaufnahmen mittels einer Software, häufig Gesichtserkennung oder Pattern Matching genannt, automatisch auszuwerten und mit bestehenden Personenbildern zu vergleichen. Zur zweifelsfreien Erkennung genügen inzwischen schon kurze Aufnahmen von wenigen Signalen, beispielsweise der Augenpartie. Mit dem Einsatz dieser Technik wäre es nicht mehr möglich, anonym an beispielsweise politischen Demonstrationen teilzunehmen. Bürgerrechtler befürchten eine globale Demonstranten-Datenbank oder enorme Repressalien, wenn beispielsweise die Polizei Fotos von Demonstranten an die jeweiligen Arbeitgeber weitergäbe.

Erste Überwachungskameras wurden schon um 1950 als sogenannte Robotkameras entwickelt, bei denen die Auslösung und der Filmvorschub automatisiert waren. Sie wurden u.a. in der Verkehrsüberwachung und bei motorisierten Messvorgängen oder für spezielle Serienaufnahmen eingesetzt. Spätere Exemplare konnten magnetisch oder elektrisch angesteuert werden.

Im Flugverkehr verlangen die USA die Weitergabe von Fluggastdaten (Passagierliste). Es wird ein System zur Früherkennung von „Terroristen“ weiterentwickelt. Man sucht nach verdächtigen Mustern, um so Terroristen zu entlarven. Der Rüstungskonzern Lockheed-Martin wurde von der US-Transportbehörde Transportation Security Administration beauftragt, das System „Computer Assisted Passenger Pre-Screening“ (CAPPS) weiter auszubauen. Dagegen formieren sich auch Widerstände. Ausländer und Kriegsgegner werden besonders genau kontrolliert.

Da heute mehr und mehr Menschen Fax und E-Mail verwenden, verringert sich die Bedeutung v. a. des internationalen Briefverkehrs. Das Abfangen von Post bleibt dennoch eine wichtige Aufgabe des Geheimdienstes.

Es gibt keinen einfachen Weg festzustellen, ob die persönliche Post gelesen wurde oder nicht. Da die Post Sortiermaschinen benutzt, die gelegentlich Briefe beschädigen, ist auch eine solche Beschädigung kein sicheres Anzeichen für eine Überwachung.

Teilweise werden große Datenmengen heute auch mit CDs auf dem Postweg verschickt. Möchte man diese Daten vor unberechtigtem Zugriff schützen, sollte man sie z. B. vor dem „Brennen“ mit einem sicheren Verschlüsselungsprogramm, etwa GPG, verschlüsseln.

Neben den konventionellen Methoden wie versteckten Abhörgeräten (umgangssprachlich auch „Wanzen“) gibt es noch die ausgefallenere Methode der optischen Mithöreinrichtung mittels eines Lasermikrofons.

Bei der Einführung und Anwendung technischer Einrichtungen zur Überwachung der Leistungen und des Verhaltens von Mitarbeitern sind in Deutschland neben datenschutzrechtlichen Bestimmungen auch die Bestimmungen des Betriebsverfassungsgesetzes zu beachten.

Gerade im Bereich der Geheimdienste und der Kriminalpolizei ist die gezielte Überwachung von Personen ein wichtiges Mittel, um die Aktivitäten von Verdächtigen zu registrieren, strafbare Handlungen aufzuklären oder gar zu verhindern. Dabei wird je nach Brisanz der Operation durchaus immenser Aufwand an Personal und Material betrieben. So kann eine Observation im Rauschgift-Milieu durchaus ein Dutzend Personen und mehrere Fahrzeuge binden, über Zeiträume von Tagen bis hin zu Wochen oder gar Jahren. In solch einem Fall ist es üblich, dass ein Team in der Dienststelle die Kommunikationsverbindungen des oder der Verdächtigen überwacht (siehe auch tapping) und per Funk oder Telefon in Verbindung zu den Leuten vor Ort steht, um aus der Überwachung gewonnene Erkenntnisse unverzüglich auf ihre Relevanz für das Einsatzgeschehen zu bewerten und den Leuten vor Ort mitzuteilen.

Im direkten Umfeld des Aufenthaltsortes der observierten Person(en) halten sich mehrere Observationseinheiten auf, üblicherweise Einzelpersonen oder Zweier-Gruppen. Je nach den zu erwartenden Bewegungen des Verdächtigen werden passende Verkehrsmittel vorgehalten und besetzt, sowohl Zweiräder wie auch PKW. Auch ist es durchaus im Rahmen des Üblichen, dass Zimmer oder Wohnungen angemietet werden, von denen aus eine visuelle Beobachtung erfolgt, und wo zugleich die Kommunikationsverbindungen der beteiligten Kräfte zusammenlaufen. Ebenso gibt es Fälle, in denen in einem unbemannten Fahrzeug Kameras verborgen sind, die z. B. den Hauseingang überwachen und die aufgenommenen Bilder per Richtfunk zu einem etwas entfernter positionierten Fahrzeug übertragen, in welchem das Observationsteam sitzt.

Die einzelnen observierenden Kräfte halten vor Ort normalerweise per Sprechfunk zueinander Kontakt. Dabei werden die Geräte meist verborgen getragen, gehört wird über drahtlose Ohrhörer, die kaum zu erkennen sind und ohnehin aussehen wie handelsübliche Hörgeräte. Gesprochen wird meist über in der Kleidung versteckte Mikrophone, zum Beispiel am Hemdkragen oder an der Jacke befestigt. Je nach Brisanz der Observation und Art der ausführenden Dienststelle erfolgt der Funkverkehr offen und für jedermann mit einem Funkscanner abhörbar oder auch digital verschlüsselt. Verlässt die Zielperson den Aufenthaltsort, dann wird versucht, mit zwei bis drei Teams die Person zu beschatten. Wenn im Voraus nicht bekannt ist, wie die Person sich fortbewegt, dann ist das Verlassen des Aufenthaltsortes ein kritischer Moment, bei dem die Überwacher schnell feststellen müssen, welches Verkehrsmittel genutzt wird, um möglichst verzugslos passend die Verfolgung aufzunehmen.

Unter den Observationsteams hat sich auch ein gewisser Jargon entwickelt, der je nach Region variieren mag. So werden Beobachter, die als Fußgänger unterwegs sind, gerne als „Füßler“ bezeichnet. Die überwachte Person wird als „Zielperson“ oder „ZP“ bezeichnet, eventuelle Zuträger oder verdeckte Ermittler, die mit der Zielperson und den Ermittlern gleichermaßen in Kontakt stehen, werden als „Vertrauensperson“ oder „VP“ bezeichnet. Soll die Observation in einer Festnahme enden, dann wird diese als „Zugriff“ bezeichnet, und das Kommando dazu ist oftmals ein zuvor abgesprochenes Kennwort oder auch ein Signalton über Funk.

Die längerfristige Observation, d. h. durchgehend länger als 24 Stunden oder an mehr als zwei Tagen, ist eine strafprozessuale Maßnahme nach § 163f StPO und steht unter Richtervorbehalt. Bei Gefahr im Verzug darf auch die Staatsanwaltschaft oder die Polizei die längerfristige Observation anordnen, allerdings muss binnen drei Werktagen die richterliche Genehmigung nachträglich eingeholt werden.

Das Abhören von Telefongesprächen ist in Deutschland für Geheimdienste und Strafverfolgungsbehörden relativ einfach möglich. Der Heise News-Ticker bezeichnet Deutschland als Weltmeister der Telefonüberwachung. Im Jahr 2006 wurden von der Regulierungsbehörde für Telekommunikation und Post mehr als 40.000 Telefonüberwachungen (nicht zu verwechseln mit Abhöraktionen) in Deutschland gezählt.

Dieses gilt aber nur für die Zahl der überwachten Anschlüsse. Häufig haben die Betroffenen mehrere Anschlüsse (Bsp.: ISDN und verschiedene Pre-paid-Karten fürs Mobiltelefon) oder wechseln diese auch während der laufenden Überwachung. Die hohe Zahl der überwachten Anschlüsse entsteht, da für "jeden" Anschluss (= Rufnummer), im Gegensatz zu anderen Ländern, ein Beschluss vorliegen muss. Bei der Zahl der überwachten Personen liegt Deutschland im unteren Mittelfeld.

Neben dem direkten Abhören von Telefongesprächen und der gezielten Überwachung von Telefonanschlüssen kommt es verstärkt dazu, ungezielt eine große Anzahl von Anschlüssen zu überwachen. Dies wird mit "Gefahrenabwehr" (z. B. Terrorismusbekämpfung) begründet.

Hierbei werden einerseits die Verbindungsdaten aufgelistet und die Kommunikationszusammenhänge über lange Zeiträume ausgewertet. Beispielsweise wird überprüft, wer mit wem telefoniert und in welcher Beziehung die Partner stehen. Andererseits erlauben Spracherkennungsprogramme, automatisch nach Stichworten wie „Bombe“ oder nach verdächtigen Wortkombinationen wie Palästina und Freiheit zu horchen, die Verbindungsdaten zu markieren und für eine intensive Überprüfung zu empfehlen. Alle Auslandsleitungen Deutschlands liefen lange Zeit durch den Frankfurter Standort eines weltweiten Computernetzes der National Security Agency (NSA), welches unter dem Namen Echelon bekannt wurde.

Einige Bundesländer, darunter Thüringen, Niedersachsen und Rheinland-Pfalz, haben mittlerweile in ihren Polizeigesetzen bzw. Gefahrenabwehrgesetzen Ermächtigungsnormen eingeführt, die die Telefonüberwachung zu präventiven Zwecken ermöglichen. Der landesgesetzlichen Regelung der präventiven Telekommunikationsüberwachung sind jedoch enge Grenzen gesetzt, so hat das Bundesverfassungsgericht die fragliche Vorschrift (§ 33a NSOG) im Niedersächsischen Sicherheits- und Ordnungsgesetz für verfassungswidrig erklärt. Die sächsische Regelung wurde vom sächsischen Staatsgerichtshof als verfassungswidrig verworfen.

Für das Information Awareness Office des Verteidigungsministeriums der Vereinigten Staaten wurde seit Anfang 2002 ein umfassendes elektronisches Überwachungssystem namens "Total Information Awareness" (TIA) (später "Terrorist Information Awareness") für Data-Mining im In- und Ausland geplant. Es sollte alle verfügbaren Informationsquellen erschließen.
Die US-amerikanische Universität Massachusetts Institute of Technology (MIT) hat als Gegenprojekt zu TIA das Informationsprojekt "Government Information Awareness" (GIA) ins Leben gerufen. Mit Hilfe dieser Plattform sollen Daten zu Personen und Institutionen von Regierungen zusammengetragen werden und der Öffentlichkeit zugänglich gemacht werden.

Nach der Einstellung von TIA durch den Kongress Mitte 2003 wurde das Nachfolgeprogramm "ADVISE" (Analysis, Dissemination, Visualization, Insight, and Semantic Enhancement) initiiert.

Das EU-Projekt INDECT erforscht „präventive Verbrechensbekämpfung“ auf der Basis der automatisierten Auswertung und Verknüpfung von Bildern von Überwachungskameras des öffentlichen Raums mit einer großen Zahl weiterer Datenquellen, wie etwa Daten aus Sozialen Netzwerken und der Telekommunikationsüberwachung. Dabei soll unter anderem durch Videoanalyse automatisiert „abnormales Verhalten“ von Menschen in der Öffentlichkeit erkannt werden. Kritiker sehen in dem bis 2013 laufenden EU-Forschungsprojekt Tendenzen hin zu einem Überwachungsstaat.

Mit bestimmten Überwachungsprogrammen können ahnungslose Computer-„Mitbenutzer“ unbemerkt ausspioniert werden. Der „Controller“ kann sämtliche Aktivitäten nachträglich observieren. Auch Passwörter (PIN, TAN) sind davor ungeschützt, bei Online-Bankgeschäften kann sich dadurch eine geänderte Haftung bei einem Schadensfall ergeben, da die Banken das Aufzeichnen der Passwörter verbieten. Die Anschaffung und Installation derartiger Programme ist legal – die Anwendung nur, wenn man seine eigenen Aktivitäten kontrolliert. Auch bei Besitzstörungen und Scheidungsverfahren ist der Einsatz illegal, er kann aber trotzdem in die "freie Beweiswürdigung" des Richters Eingang finden. In Österreich gibt es nur das Recht auf Unterlassung einer illegalen Überwachung.
Zu PC-Überwachungsprogrammen zählen auch Bildschirmüberwachungsprogramme, die den Bildschirminhalt aufzeichnen oder übertragen.

Weitere Möglichkeiten der Datensammlung und Überwachung bietet der Einsatz der RFID-Technologie. RFID steht für "Remote Frequency Identifier" bzw. "Radio Frequency Identification" und erlaubt das kontaktlose Lesen von Daten (einer gegebenenfalls weltweit eindeutigen ID) ohne besonderes Positionieren, ursprünglich entwickelt, um den Strichcode z. B. auf Lebensmitteln oder anderen Objekten ohne Handhabung zu ermöglichen. Um ein Objekt mittels RFID zu markieren, muss ein sogenannter "RFID-Tag" angebracht werden, dessen Antenne nur wenige Millimeter groß zu sein braucht, um Daten je nach Frequenzbereich und Energiequelle über mehrere Meter senden zu können.

RFID-Tags werden stillschweigend im Interesse der Hersteller oder Vertreiber in immer mehr Produkte des Konsums eingearbeitet, ohne die Benutzer zu informieren. Da solch ein „Produkt-Kennzeichen“ theoretisch Lebensdauer gleich der Produktlebensdauer besitzt, wird der Benutzer zu einem wandelnden Informationssender über die Waren bzw. Produkte, die er bei sich trägt.

Eingesetzt werden RFID unter anderem auch auf Ausweisdokumenten (Reisepass) und in Geldkarten.

Hauptrisiko der Überwachung ist, dass der Besitzer der bei Überwachung gewonnenen Daten nicht der Eigentümer der Daten ist und dieser keine Kontrolle über die Daten besitzt. Die bei der Überwachung anfallenden Daten werden gegebenenfalls ohne Zustimmung zweckentfremdet, verfälscht oder gezielt missbraucht. Solange die Begriffe Datensicherheit und Datenschutz in den betreffenden Gesetzen zufällig verwendet werden, ist keine Klarheit zu erwarten. Zudem ist aus Gründen tradierten staatlichen Gewaltverständnisses das Eigentum an Personendaten nicht allgemein und selbstständig definiert.

Häufig kommen Irrtümer und Fehlentscheidungen infolge falscher, falsch gelesener oder falsch interpretierter Daten vor. Gefährlich erscheint vielen der mit (angenommener oder tatsächlicher) Überwachung einhergehende Anpassungsdruck. Speziell diese Fiktion wurde 1983 in der Urteilsbegründung des Bundesverfassungsgerichts zur Volkszählung hervorgehoben.

In Anlehnung an Roger Clarke sind die folgenden Risiken einer Überwachung durch Verwendung von Daten („dataveillance“) zu nennen:


Die besondere Sensibilität der Deutschen gegenüber jeder Form der Überwachung im Gegensatz zu anglo-amerikanischen Ländern lässt sich unter anderem auf die im Nationalsozialismus praktizierte Überwachung der Bevölkerung zurückführen. Auch das in der DDR durch die Staatssicherheit etablierte und nach der Wende aufgedeckte Netz von Inoffiziellen Mitarbeitern, die weite Teile der Bevölkerung bespitzelten, trägt zu einer besonderen Sensibilität bei. Unter bestimmten Voraussetzungen können die Verfassungsschutzämter oder Polizeien in Deutschland eine Observation von Personen vornehmen.

Überwachung hat unter anderem die Folge, dass die Überwachten sich konformer (zu dem, was nach den aktuellen Moral- und Wertvorstellungen jeweils vorgegeben wird) verhalten, ihr Verhalten also vorauseilend „normalisieren“, jedenfalls dann, wenn sie sich überwacht glauben und das angepasste Verhalten eine glaubwürdige Perspektive eröffnet. Das heißt nicht notwendigerweise, dass dadurch der Wille der Überwachten dauerhaft gebeugt wird, doch achten sie in der Regel mehr auf ihre äußerliche Wirkung – ganz ähnlich der eines Schauspielers. Diesen „Zwang zum Schauspiel“ den Michel Foucault auch in seinem Werk Überwachen und Strafen beschrieb, erfährt der Überwachte in der Regel als Bürde, die ihn in seiner (gefühlten) Freiheit einschränkt, eine zuvor von außen an das Individuum herangetragene Disziplinierung und Sanktionierung wird in das einzelne Individuum selbst verlagert (z. B. als "Schere im Kopf", vorauseilender Gehorsam, siehe auch Panoptismus).
Des Weiteren besteht die Gefahr, dass die Überwachung, die nahezu jeder unbewusst wahrnimmt (z. B. an Tankstellen, Bahnhöfen, Flughäfen …) für den Menschen so alltäglich wird und er sich so an sie gewöhnt, dazu führt, dass es für diverse Organisationen ein Leichtes sein wird, ihn nach dem Prinzip des Panopticons (man muss immer damit rechnen gesehen und gehört zu werden) zu überwachen.

Neuere wissenschaftliche Erkenntnisse des Max-Planck-Instituts für evolutionäre Anthropologie haben ergeben, dass allein die Anwesenheit eines Gesichts in einem Raum (z. B. auf einem Foto) die Konformität des „durch das Gesicht Überwachten“ erheblich erhöht, selbst wenn dem Überwachten klar ist, dass dieses Gesicht eben nur eine Abbildung ist. Offensichtlich ist der Vorgang, bei "Überwachung" sein Verhalten anzupassen, sehr tief im Menschen verwurzelt. In einem Experiment der Universität von Newcastle upon Tyne zeigte es sich, dass die bloße Anwesenheit eines Bilds von Augen aber auch egoistische Handlungsweisen verhindert und zu mehr Kooperation führt.

Konkret wird in den Medien hervorgehoben, dass das Gefühl dauerhafter Beobachtung dazu führen kann, dass sich weniger Menschen auf einer Demonstration zeigen; die Überwachung könne „soziale und demokratische Aktivitäten genauso untergraben wie das Vertrauen in Staat oder Gesellschaft“. Auch könne bereits ein „diffuses Gefühl des Beobachtetseins“ zu einer Verhaltensänderung führen, nämlich wenn eine Person die Empfindung hat – ganz gleich, ob diese objektiv begründet oder nur subjektiv ist – dass sie sich, wenn sie sich in einem Gebiet mit hoher Kriminalitätswahrscheinlichkeit bewegt, einem Kriminalitätsverdacht aussetzt.

Für den systematischen Missbrauch von Überwachungssystemen gab es 2006 in Italien ein gravierendes Beispiel, bei dem mehrere tausend Menschen unter der Beteiligung des Sicherheitsverantwortlichen der Telecom Italia, der organisierten Kriminalität und von Mitarbeitern verschiedener Polizeieinheiten und Geheimdienste systematisch abgehört und mit diesen Daten erpresst wurden. Verhaftet wurde damals auch Marco Mancini, der Vize-Chef des italienischen Militär-Geheimdienstes SISMI, der eine führende Rolle in dem Abhör- und Erpresserring spielte, und bei dem darüber hinaus umfangreiche Unterlagen über das illegale Ausspionieren von politischen Gegnern des damaligen Regierungschefs Silvio Berlusconi gefunden wurden. Roberto Preatoni, eine der Schlüsselpersonen des Skandals, nannte die Vorgänge so komplex, dass sie „wahrscheinlich nie ganz aufgeklärt“ werden könnten, beteiligt gewesen seien unter anderem italienische und US-Geheimdienste, korrupte italienische Polizisten, sowie italienische und US-Sicherheitsunternehmen. Aufsehen erregte, dass der Hauptbelastungszeuge der Staatsanwaltschaft, der ehemalige Sicherheitsbeauftragte der Mobilfunk-Sparte der Telecom Italia, einen Monat nach der Aufdeckung des Skandals unter ungeklärten Umständen in Neapel von einer Autobahnbrücke stürzte und starb.


zum Thema Ortungstechnik:

zur Personenüberwachung:

Romane:

Filme, die Überwachung thematisieren:




</doc>
<doc id="10779" url="https://de.wikipedia.org/wiki?curid=10779" title="Biometrie">
Biometrie

Die Biometrie (auch "Biometrik" - von altgriechisch "bíos" „Leben“ und "métron" „Maß, Maßstab“) ist eine Wissenschaft, die sich mit Messungen an Lebewesen und den dazu erforderlichen Mess- und Auswerteverfahren beschäftigt.

Je nach Anwendungsbereich gibt es unterschiedliche Detaildefinitionen. Christoph Bernoulli benutzte 1841 als einer der ersten Wissenschaftler den Begriff "Biometrie" in einer sehr wörtlichen Interpretation für die "Messung" und statistische Auswertung der menschlichen "Leben"sdauer.

Der Begriff der Biometrie besitzt die zwei Facetten der "biometrischen Statistik" und der "biometrischen Erkennungsverfahren", die auch in der Praxis getrennt sind.

Bei "biometrischer Statistik" geht es um die Entwicklung und Anwendung statistischer Methoden zur Auswertung von Messungen aller Art an lebenden Wesen. Sie wird intensiv von allen Lebenswissenschaften genutzt. Wegbereiter der wissenschaftlichen Methodik war Karl Pearson (1857–1936). In diesem Kontext wird "Biometrie" auch als Synonym für Biostatistik verwendet.

Als "Erkennungsverfahren" setzte man schon früh die Biometrie zur Personenidentifikation ein. So entwickelte Alphonse Bertillon 1879 ein später Bertillonage genanntes System zur Identitätsfeststellung, das auf 11 Körperlängenmaßen basierte (Anthropometrie). 1892 legte Francis Galton den wissenschaftlichen Grundstein für die Nutzung des Fingerabdrucks (Daktyloskopie).

Heute definiert man Biometrie im Bereich der Personenerkennung auch als "automatisierte Erkennung von Individuen, basierend auf ihren Verhaltens- und biologischen Charakteristika".

Weitere Anwendungsgebiete der Biometrie sind beispielsweise automatisierte Krankheits-Diagnoseverfahren.

Biometrie lebt vom Zusammenspiel der Disziplinen Lebenswissenschaften, Statistik, Mathematik und Informatik. Erst die heutige Informationstechnologie macht es möglich, die hohen Rechenleistungsanforderungen üblicher biometrischer Verfahren zu bewältigen.

Biometrie als Entwicklung und Anwendung statistischer Methoden im Rahmen empirischer Untersuchungen an Lebewesen dient dem wissenschaftlichen Erkenntnisgewinn, der Entscheidungsfindung und der wirtschaftlichen Optimierung von Produkten. Hier einige Beispiele:


Biometrische Erkennungsmethoden haben in den letzten Jahren einen enormen Aufschwung erlebt. Der technologische Fortschritt erlaubt in zunehmendem Maße die rasche Messung biologischer Charakteristika und deren Auswertung mit vertretbarem Aufwand und hoher Qualität. Der Einsatz von Biometrie ist ein vielversprechender Ansatz, das ungelöste Problem vieler Sicherheitskonzepte zu lösen: Wie verbindet man Identitäten und die dazugehörigen Rechte mit den die richtige Identität aufweisenden physischen Personen?

Das im Jahr 2001 in Australien gegründete Biometrics Institute hat satzungsgemäß die Aufgabe, den verantwortungsbewussten Gebrauch von biometrischen Technologien zu fördern.

Beim Einsatz der Biometrie zur automatisierten Erkennung von Personen kommt es darauf an, individuelle biometrische Verhaltens- oder Körpercharakteristika zu finden, die sich u. a. durch folgende Eigenschaften auszeichnen:

Biometrische Charakteristika werden häufig unterschieden in aktiv/passiv, verhaltens-/physiologiebasiert oder dynamisch/statisch. Zu den langfristig stabilen verhaltensbasierten Charakteristika zählen die Stimme, die Hand- oder Unterschrift, das Tippverhalten und die Gangdynamik. Langfristig stabile physiologische Charakteristika sind beispielsweise der Fingerabdruck, die Iris oder die Handgeometrie. Diese Unterscheidung ist zwar weitgehend akzeptiert, es existieren aber Grenzbereiche. So sind die meisten verhaltensbasierten biometrischen Charakteristika beeinflusst durch die Physiologie, etwa die Stimme durch den Sprachapparat des Menschen.

Als biometrische Charakteristika können u. a. verwendet werden:

Ein biometrisches Erkennungssystem setzt sich im Wesentlichen aus den Komponenten "Sensor" (Messwertaufnehmer), "Merkmalsextraktion" und "Merkmalsvergleich" zusammen. Welche Arten von "Sensoren" zum Einsatz kommen, hängt stark vom biometrischen Charakteristikum ab. So ist eine Videokamera für die meisten Charakteristika geeignet; für die Fingerabdruckerkennung kommen auch andere bildgebende Verfahren in Frage. Die Sensorkomponente liefert als Ergebnis ein "biometrisches Sample". Die "Merkmalsextraktion" entfernt mittels komplexer Algorithmen alle vom Sensor gelieferten Informationen, die nicht die geforderten Merkmalseigenschaften erfüllen und liefert als Ergebnis die "biometrischen Merkmale". Der "Merkmalsvergleicher" errechnet schließlich einen "Vergleichswert" (Score) zwischen dem in der "Einlernphase" gespeicherten "biometrischen Template" und dem aktuellen, von der Merkmalsextraktion gelieferten Datensatz. Über- bzw. unterschreitet dieser Vergleichswert eine (einstellbare) Schwelle, gilt die Erkennung als erfolgreich.

In der „Einlernphase“, dem "Enrolment", werden die biometrischen Merkmalsdaten als Referenzmuster in digitaler Form verschlüsselt abgespeichert. Beim nächsten Kontakt mit dem biometrischen System wird ein aktuelles Sample aufgenommen und mit dem Referenzmuster ("Template") verglichen. Das System entscheidet dann, ob die Ähnlichkeit der beiden Muster hinreichend hoch ist und damit beispielsweise ein Zutritt erfolgen darf oder nicht.

Die wichtigsten Erkennungsarten sind die Verifikation und die Identifikation. Bei der Verifikation muss die zu verifizierende Person dem System zunächst ihren Namen oder ihre User-ID mitteilen. Danach entscheidet das biometrische System, ob die Person zum zugehörigen Referenzmerkmalsdatensatz gehört oder nicht. Bei der Identifikation offenbart die zu erkennende Person ausschließlich ihr biometrisches Charakteristikum, das System ermittelt daraus durch Vergleich mit den Referenzmerkmalsdatensätzen aller Nutzer den zugehörigen Namen bzw. die User-ID.

Da die vom biometrischen Sensor gelieferten Samples starken statistischen Schwankungen unterliegen, kann es gelegentlich zu Falscherkennungen kommen. Die Zuverlässigkeit der Identifikation bzw. Verifikation wird hauptsächlich nach zwei Kriterien beurteilt: nach der Zulassungsrate Unberechtigter und nach der Abweisungsrate Berechtigter:
Beide Raten hängen gegenläufig vom Entscheidungsschwellwert ab: Eine höher gewählte Schwelle verringert zwar die FAR, erhöht zugleich aber die FRR und umgekehrt. Deshalb ergibt z. B. die alleinige Angabe der FAR ohne zugehörige FRR keinen Sinn. Bei einer FRR von 10 % kann die (Verifikations-) FAR bei guten biometrischen Systemen je nach Charakteristikum Werte von 0,1 % bis < 0,000001 % erreichen.

Während die FAR bei Verfikationssystemen bei gegebener Entscheidungsschwelle eine Konstante ist, wächst sie bei Identifikationssystemen mit der Zahl der gespeicherten Referenzdatensätze. Näherungsweise ergibt sich die resultierende Gesamt-FAR aus der Multiplikation der zugrunde liegenden Verifikations-FAR mit der Zahl der Datensätze. Dies ist der Grund, warum nur stark distinktive Charakteristika wie Iris und Zehnfingerprint eine zuverlässige Identifikation über große Datenbasen mit Millionen von Einträgen ermöglichen.

Schließlich beschreibt die
den Umstand, dass nicht jedes biometrische Charakteristikum bei jedem Menschen jederzeit in ausreichender Qualität zur Verfügung steht. Die FER hängt nicht nur von der jeweiligen Verfassung des biometrischen Charakteristikums ab, sie wird wie die anderen Fehlerraten auch durch die Leistungsfähigkeit der Technik und die Mitwirkung der "enrolten Testperson" beeinflusst.

In der Regel lassen sich die beschriebenen Fehlerraten nicht theoretisch berechnen, sondern sind in aufwändigen statistischen Untersuchungen zu ermitteln. Dabei steigt der Aufwand mit abnehmenden Fehlerraten umgekehrt proportional an. Verfahren zur Leistungsprüfung und -auswertung für biometrische Systeme beschreibt die Norm ISO/IEC 19795.

Bei biometrischen Systemen spielt aber auch die Erkennungszeit eine große Rolle. Neben der Sicherheit und Zuverlässigkeit sind die Benutzerakzeptanz und die Gebrauchstauglichkeit ("usability") bei der Beurteilung eines biometrischen Systems entscheidende Kriterien.

Biometrische Erkennungsverfahren sind fast überall einsetzbar, wo die Identität einer Person direkt oder indirekt eine Rolle spielt. Allerdings sind nicht notwendigerweise alle Anwendungen erfolgreich. Wichtig ist, dass die Anwendung und die Möglichkeiten eines speziellen biometrischen Charakteristikums zusammenpassen. Die gängigsten Verfahren sind die Verifikation mit Karte/Ausweis und die reine Identifikation, bei der der Anwender ausschließlich über das biometrische Charakteristikum authentifiziert wird. Letzteres ist zwar sehr komfortabel, stellt aber mit steigender Nutzerzahl hohe Anforderungen an das biometrische Charakteristikum (FAR), die Rechenleistung und den Datenschutz und ist in der Regel nicht für sicherheitskritische Bereiche geeignet. Bei Benutzung eines Ausweises können die biometrischen Referenzdaten in einem Chip gespeichert oder auf der Karte als 2D-Strichcode aufgedruckt sein. Es gibt auch Systeme, die die Karte nur als Pointer für den in einer Datenbank gespeicherten Referenzdatensatz nutzen.

Automatisierte Fingerabdruck-Identifizierungssysteme (AFIS) unterstützen den Daktyloskopen beim Vergleich von Tatortfingerabdruckspuren mit den gespeicherten oder abzunehmenden Fingerabdrücken von Straftätern bzw. Verdächtigen. Während die manuelle Auswertung von Fingerabdrücken in Deutschland bereits seit 1903 zu den bewährten Ermittlungswerkzeugen der Kriminalpolizei gehört, fanden die ersten computergestützten Verfahren in den 1980er Jahren in den USA und 1993 in Deutschland Eingang in die Ermittlungsarbeit.

PC-Anmeldung per Fingerabdruck: Mit dem Erscheinen kostengünstiger Halbleiter-Fingerprintsensoren ab ca. 1998 etablierten sich die ersten Produkte am Markt, die die Passwort-Anmeldung am PC bzw. am Firmennetzwerk durch eine Fingerprinterkennung ersetzten oder ergänzten. Obwohl sich solche Systeme bisher nur im professionellen Bereich durchsetzen konnten, ist in Zukunft zu erwarten, dass die meisten Notebooks standardmäßig mit noch kostengünstigeren Streifensensoren ausgestattet sein werden. (Streifensensoren erfordern vom Nutzer eine aktive Bewegung über den Sensor.) Als Hauptargument wird die Kosteneinsparung durch Wegfall vergessener Passwörter genannt.

Biometrische Reisepässe und Personalausweise: Basierend auf dem internationalen Standard 9303 der ICAO werden in Deutschland seit dem 1. November 2005 nur noch Reisepässe mit integriertem Chip ausgegeben, auf dem ein digitales Lichtbild als biometrisches Sample gespeichert ist. Seit November 2007 werden auch die Fingerabdrücke erfasst. Biometrische Reisepässe zeichnen sich durch folgende Eigenschaften aus: eventuelle Personaleinsparungen bei der Grenzkontrolle durch höhere Abfertigungsrate, Unterstützung bei der Feststellung der Zugehörigkeit von Pass und Inhaber, hohe Kosten, die der Passinhaber zu tragen hat, sowie ungeklärte datenschutzrechtliche Situation bei Nutzung der biometrischen Daten durch Fremdstaaten. In der Schweiz ist die Aufnahme elektronischer biometrischer Charakteristika in den Pass freiwillig. Ab dem 1. November 2010 sind auch die deutschen Personalausweise mit biometrischen Merkmalen versehen. Hiervon teilweise ausgenommen sind die vorläufigen Reisepässe (erkennbar am grünen Umschlag), die Kinderreisepässe oder die vorläufigen Personalausweise. Diese haben zwar keinen integrierten Chip, setzen aber trotzdem ein biometrisches Foto voraus. Bei Kindern sind mehr Abweichungen auf den Fotos zugelassen und Fingerabdrücke können wahlweise erst ab dem 6. Lebensjahr abgegeben werden.

Dauerkarten: Für nicht übertragbare Dauerkarten bietet sich der Einsatz biometrischer Erkennung an, um eine Weitergabe an Nichtberechtigte zu verhindern. Der Zoo Hannover setzt für diesen Zweck bereits seit einigen Jahren erfolgreich ein Gesichtserkennungssystem ein. Weitere Anwendungen, meist auf Basis Fingerprint, finden immer mehr Verbreitung in Fitnessstudios, Solarien und Thermalbädern.

Physischer Zutritt: Für den Zugang zu besonders schützenswerten Bereichen werden herkömmliche Authentifikationsmethoden um biometrische Verfahren ergänzt. Beispiele sind Gesichtserkennung in Personenschleusen zu Chipkartenentwicklungsbereichen, Fingerprinterkennung in Kernkraftwerksbereichen und Iriserkennung in der Babystation einer Berchtesgadener Klinik. In Japan erfreut sich die Handvenenerkennung großer Beliebtheit.

Bezahlen per Fingerabdruck: Immer mehr Geschäfte bieten ihren registrierten Stammkunden die Möglichkeit, statt mit einer Kundenkarte per Fingerabdruck zu bezahlen, wobei die Bezahlung durch Abbuchung erfolgt. Eigenschaften: der Kunde braucht weder Bargeld noch eine Karte; es bestehen datenschutzrechtlich ähnliche Probleme wie bei Rabattkartensystemen.

Erfassung von Asylsuchenden: Von Asylsuchenden werden bei ihrer Einreise in die EU die Abdrücke aller 10 Finger erfasst. Mit Hilfe der zentralen EURODAC-Datenbank kann dann festgestellt werden, ob ein Asylsuchender bereits von einem anderen EU-Land abgewiesen wurde.

Spielkasinos setzen gelegentlich Biometrie ein (meist Gesichtserkennung und Fingerprint), um Spielsüchtige am Zutritt zu hindern. Spieler, die von sich selbst wissen, dass sie zeitweise süchtig sind, können freiwillig beim Spielkasino ihre biometrischen Daten hinterlegen, um sich auf diese Weise vor der Ausübung ihres Suchtverhaltens zu schützen.

Zweifelhafte Anwendungen: Der Einsatz von Biometrie ist nur sinnvoll, wenn das biometrische Charakteristikum die spezifischen Anforderungen einer Anwendung erfüllen kann. So ist beispielsweise mit extrem hohen Fehlerraten (FRR) zu rechnen, wenn man versucht, Bauarbeiter zwecks Anwesenheitskontrolle vor Ort mit Fingerprintsystemen zu identifizieren. Grund sind die Verschmutzung und temporäre Abnutzung der Fingerlinien. Eine vollautomatisierte Suche von Zielpersonen per Gesichtserkennung an herkömmlichen Überwachungskameras scheitert in der Regel an der zu geringen Erkennungsrate, hervorgerufen durch eine für die Identifikation zu schlechte Bildqualität und eine zu niedrige Auftretenswahrscheinlichkeit der Gesuchten. Experten raten dringend von Anwendungen ab, die Angreifer dazu verleiten könnten, Finger von Berechtigten abzuschneiden (Beispiele: Wegfahrsperre oder Geldautomat im Identifikationsmodus).

In Anwendungen, in denen eine fehlerhafte Verifikation oder Identifikation einen Schaden herbeiführen kann, ist nicht nur eine hinreichend niedrige Falschakzeptanzrate (FAR) von Bedeutung. Da sich biometrische Charakteristika als mechanische Muster oder als Datensatz kopieren lassen, ist je nach Anwendung und Charakteristikum auch sicherzustellen, dass das biometrische Erkennungssystem in der Lage ist, Faksimile von Originalen zu unterscheiden und erstere gegebenenfalls abzuweisen. Dies ist besonders deshalb wichtig, weil sich ein biometrisches Charakteristikum in der Regel nicht wie ein Passwort auswechseln lässt.

Zur Lösung dieses Problems existieren unterschiedlich leistungsfähige Verfahren zur automatisierten Kopienerkennung. Die Abwehr der missbräuchlichen Verwendung abgetrennter Körperteile erfolgt hingegen durch Methoden der Lebenderkennung. Kopien- und Lebenderkennung kommen allerdings aus Kostengründen meist nur bei hohen Sicherheitsanforderungen in Frage. Andere Methoden setzen auf die Kombination mehrerer Charakteristika, auf die Verbindung mit herkömmlichen Authentifikationsmethoden oder auf manuelle Überwachung zur Erkennung von Angriffsversuchen. Die meisten einfachen biometrischen Systeme für geringe Schutzhöhe sind derzeit nicht mit einer Kopien- oder Lebenderkennung ausgestattet, was im Einzelnen zu Kritik an Biometrie führt. Die meisten dokumentierten Fälschungsversuche gehen allerdings von bewusst und in guter Qualität hinterlassenen Latenzfingerabdrücken aus. Wissenschaftliche Untersuchungen, wie hoch das Risiko im wirklichen Leben ist, scheinen derzeit nicht zu existieren.

Biometrische Authentifikationssysteme unterliegen in der Regel dem gesetzlichen Datenschutz. Für den Datenschutz sind folgende Eigenschaften von Bedeutung:


Aus all diesen Gründen ist die Einhaltung datenschutzrechtlicher Grundprinzipien unerlässlich. Dazu gehören im Fall der Biometrie:







</doc>
<doc id="10780" url="https://de.wikipedia.org/wiki?curid=10780" title="Zelle (Biologie)">
Zelle (Biologie)

Eine Zelle (‚ kleine Kammer, Zelle‘ "kytos" ‚Zelle‘) ist die kleinste lebende Einheit aller Organismen. Man unterscheidet "Einzeller" und "Mehrzeller". Besteht das Lebewesen aus vielen Zellen ("Vielzeller") können Zellen zu funktionellen Einheiten verbunden sein und dadurch Gewebe bilden. Der menschliche Körper besteht aus mehreren hundert verschiedenen Zell- und Gewebetypen. Evolutionsbiologisch betrachtet und im Vergleich zu Einzellern haben die Zellen von Vielzellern größtenteils ihre Fähigkeit für sich allein leben zu können verloren und haben sich auf eine Arbeitsteilung in Geweben spezialisiert.

Die Wissenschaft und Lehre von den Zellen der Lebewesen ist die Zellbiologie.

Jede Zelle stellt ein strukturell abgrenzbares, eigenständiges und selbsterhaltendes System dar. Sie ist in der Lage, Nährstoffe aufzunehmen und die darin gebundene Energie durch Stoffwechsel für sich nutzbar zu machen. Neue Zellen entstehen durch Zellteilung. Die Zelle enthält die Informationen für all diese Funktionen bzw. Aktivitäten. Zellen haben grundlegende Fähigkeiten, die als Merkmale des Lebens bezeichnet werden, wobei nicht jede Zelle alle diese Eigenschaften haben muss:

Im Laufe der Evolution haben sich zwei verschiedene Gruppen von Lebewesen gebildet, die sich durch die Struktur ihrer Zellen stark unterscheiden: zum einen die Prokaryoten, die aus einfach gebauten Zellen ohne Zellkern bestehen, und zum anderen die Eukaryoten, die aus Zellen bestehen, die wesentlich komplizierter strukturiert sind und einen Zellkern besitzen. Prokaryoten und Eukaryoten können sowohl als Einzeller als auch als Mehrzeller auftreten. Bei den Mehrzellern bilden Zellen sogenannte Zweckverbände. Meistens teilen sie sich Funktionen und sind oft einzeln nicht mehr lebensfähig. Durch die Spezialisierung in Vielzellern sind die oben beschriebenen Fähigkeiten eingeschränkt.

Die Größe von Zellen variiert stark. Normalerweise haben sie einen Durchmesser zwischen 1 und 30 Mikrometer, Eizellen höherer Tiere sind jedoch oft wesentlich größer als die übrigen Zellen. Beispielsweise hat die Eizelle eines Straußes einen Durchmesser von über 70 mm, die des Menschen hat einen Durchmesser von 0.15 mm und ist seine größte Zelle und die einzige, die mit bloßem Auge erkennbar ist.

Prokaryotische Zellen besitzen keinen echten Zellkern wie die eukaryotischen Zellen und weisen eine einfachere innere Organisation im Vergleich zu den eukaryotischen Zellen auf. Man bezeichnet sie auch als "Procyten" oder "Protocyten". Lebewesen mit prokaryotischen Zellen nennt man "Prokaryoten". Zu ihnen gehören die Bakterien und die Archaeen. Sie treten meist als einzellige Organismen auf.

Prokaryotische Zellen kann man im Allgemeinen durch folgende Merkmale von den eukaryotischen Zellen unterscheiden:

Prokaryoten zeichnen sich durch ein weites Spektrum physiologischer und ökologischer Typen aus. Einige sind auch unter extremen Bedingungen lebensfähig (Temperaturbereich bis über 100 °C); oxisches oder anoxisches Milieu; saures Milieu (pH-Wert 1-4); hohe hydrostatische Drücke (1000 bar). Viele leben parasitär, symbiotisch oder saprovor, einige sind pathogen (krankheitserregend). Häufig enthalten sie Plasmide (extrachromosomale, in sich geschlossene oder lineare DNA-Elemente). Weiterhin besitzen Prokaryoten nur beschränkt die Fähigkeit, sich zu differenzieren, zum Beispiel bei der Sporenbildung (unter anderem Endosporenbildung bei "Bacillus subtilis").

Eukaryotische Zellen werden auch als "Eucyten" bezeichnet. Der wesentliche Unterschied zu prokaryotischen Zellen (Procyten) ist die Existenz eines Zellkerns mit einer Kernhülle um die in Chromosomen organisierte DNA. Die Kernhülle besteht aus zwei Membran­lagen mit Zwischenraum, einer sog. Doppelmembran, und ist typischerweise etwa 15 Nanometer dick. Eukaryotische Zellen sind wesentlich differenzierter als prokaryotische. Ihre Vielzahl resultiert aus den sehr verschiedenen Funktionen, die sie zu erfüllen haben. – Die mittlere Zellmasse von Eucyten beträgt etwa 2,5 Nanogramm. Ihre Länge reicht von einigen Mikrometern bis hin zu mehreren Zentimetern bei Myozyten (Muskelfaserzellen).

Eine Sonderstellung unter den Eucyten nehmen die Nervenzellen (Neuronen) ein. Diese reichen vom Rückenmark bis hinein in die peripheren Extremitäten.

Zellen von Tieren, Pflanzen und Pilzen gehören zu den eukaryotischen Zellen, aber es gibt einige Unterschiede in ihrer Struktur. Im Folgenden werden charakteristische Unterschiede tabellarisch aufgelistet. 

Besonderheiten pflanzlicher Zellen


Jede Zelle, ob prokaryotisch oder eukaryotisch, besitzt eine Zellmembran, die die Zelle von der Umgebung abgrenzt. Durch die Zellmembran wird kontrolliert, was in die Zelle aufgenommen und was hinaustransportiert wird. Auf jeder Seite befinden sich Ionen (elektrostatisch geladene Atome oder Moleküle) unterschiedlicher Konzentration, die durch die Zellmembran getrennt gehalten werden. Dadurch wird ein Konzentrationsunterschied aufrechterhalten, welcher ein chemisches Potential nach sich zieht. Das durch die Zellmembran umschlossene Medium ist das Zytoplasma. Alle teilungsfähigen Zellen besitzen DNA, in der die Erbinformationen gespeichert sind, sowie Proteine, die als Enzyme Reaktionen in der Zelle katalysieren oder Strukturen in der Zelle bilden, und RNA, die vor Allem zum Aufbau der Proteine notwendig ist. Im Folgenden sind wichtige Zellkomponenten aufgelistet und kurz beschrieben:

Jede Zelle ist von einer Zellmembran oder auch Plasmamembran umschlossen. Diese Membran trennt die Zelle von der Umgebung ab und schützt sie auch. Sie besteht hauptsächlich aus einer Doppellipidschicht und verschiedenen Proteinen, die unter anderem den Austausch von Ionen oder Molekülen zwischen der Zelle und ihrer Umgebung möglich machen. Ihre Dicke beträgt etwa 4 bis 5 nm.

Das Zellskelett ist eine wichtige, komplexe und trotz des eventuell irreführenden Namens eine höchst dynamische Struktur in der Zelle. Es besteht aus Proteinen, die insgesamt drei große Systeme bildenden Mikrofilamente (Aktinfilamente), die Mikrotubuli und die Intermediärfilamente.

In seiner Gesamtheit ist es verantwortlich für die Elastizität und die mechanische Stabilität der Zelle und ihrer äußeren Form, für aktive Bewegungen der Zelle als Ganzes, sowie für Bewegungen und Transporte innerhalb der Zelle. Es spielt zudem wichtige Rollen in der Zellteilung und der Rezeption von äußeren Reizen und deren Weitervermittlung in die Zelle hinein.

Die Existenz der drei Zytoskelettelemente als Grundausstattung jeder Zelle wurde in den 1960er Jahren unter Einsatz der Elektronenmikroskopie und neuartigen Fixier- (Glutaraldehydfixierung) und Detektionsverfahren (Aktindekoration durch Myosinkopfgruppen) erkannt und geht auf bahnbrechende Arbeiten von Sabatini und Ishikawa zurück.

In der Zelle existieren zwei Arten von genetischem Material: die Desoxyribonukleinsäuren (DNA) und die Ribonukleinsäuren (RNA). Für die Speicherung der Informationen über lange Zeit wird von den Organismen DNA genutzt. Die RNA wird häufig zum Transport der Information (zum Beispiel mRNA) und für enzymähnliche Reaktionen (zum Beispiel rRNA) verwendet.

Bei Prokaryoten liegt die DNA in einfacher, in sich geschlossener („circulärer“) Form vor. Diese Struktur nennt man Bakterienchromosom, obwohl sie sich von Chromosomen der eukaryotischen Zellen beträchtlich unterscheidet. In eukaryotischen Zellen ist die DNA an verschiedenen Orten verteilt: im Zellkern und in den Mitochondrien und Plastiden, Zellorganellen mit doppelter Membran. In den Mitochondrien und den Plastiden liegt die DNA wie in Prokaryoten „circulär“ vor. Die DNA im Zellkern ist linear in sogenannten Chromosomen organisiert. Die Anzahl der Chromosomen variiert von Art zu Art. Die menschliche Zelle besitzt 46 Chromosomen.

Die Ribosomen sind aus RNA und Proteinen bestehende Komplexe in Pro- und Eukaryoten. Sie sind für die Synthese von Proteinen aus Aminosäuren verantwortlich. Die mRNA dient als Information für Art und Reihenfolge der Aminosäuren in den Proteinen. Die Proteinbiosynthese ist sehr wichtig für alle Zellen, weshalb die Ribosomen in vielfacher Zahl in den Zellen vorliegen, zum Teil hunderte bis tausende von Ribosomen pro Zelle. Ihr Durchmesser beträgt 18 bis 20 nm.

Zentriolen sind zylinderförmige Strukturen im Ausmaß von etwa 170 × 500 Nanometern. Sie sind an der Bildung des MTOC (Mikrotubuli-organizing centers) beteiligt, das während der Mitose den Spindelapparat zur Trennung der Chromosomen bildet, aber auch während der Interphase zur Organisation und physikalischen Stabilisierung der Zelle beiträgt. Zentriolen kommen in den meisten tierischen Zellen und den Zellen niederer Pflanzen vor, nicht jedoch bei den höheren Pflanzen (Angiospermen).

Bei mehrzelligen Organismen sind die Zellen meistens zu Geweben zusammengefasst, die auf bestimmte Funktionen spezialisiert sind. Oft bilden solche Gewebe einen Komplex, den man Organ nennt. Beim Menschen ist zum Beispiel die Lunge für den Gasaustausch von Kohlendioxid und Sauerstoff verantwortlich. Ähnliche funktionsbezogene Strukturen gibt es in kleinstem Maßstab auch innerhalb der Zelle. Solche Organellen sind in jeder eukaryotischen Zelle zu finden. Der Aufbau von pflanzlichen und tierischen Zellen unterscheidet sich teilweise durch Anzahl und Funktion mancher Organellen. Im Folgenden werden wichtige Organellen aufgeführt.

Der Zellkern bildet die Steuerzentrale der eukaryotischen Zelle: er enthält die chromosomale DNA und somit die Mehrzahl der Gene. Bei Säugerzellen hat er einen Durchmesser um 6 µm. Durch die Kernhülle, eine doppelte Membran mit Zwischenraum, Gesamtdicke etwa 35 nm, wird der Kern vom Cytoplasma abgegrenzt. Sie wird von Kernporen durchbrochen, wodurch ein Austausch von Molekülen zwischen der Substanz des Kerninneren, dem sogenannten Karyoplasma, und dem Cytoplasma möglich ist. Die äußere Membran der Kernhülle steht mit dem endoplasmatischen Retikulum in Verbindung. Im Zellkern findet die Synthese der RNA (Transkription) statt. Jene RNA-Arten, die für die Proteinsynthese (Translation) benötigt werden, werden aus dem Zellkern durch die Kernporen ins Cytoplasma transportiert. Lichtmikroskopisch ist im Kern eine globuläre Struktur mit einem Durchmesser von etwa 2 bis 5 µm zu erkennen, die man Kernkörperchen oder Nukleolus nennt. Die DNA in diesem Bereich des Kerns enthält die Baupläne für die ribosomale RNA, also für die katalytische RNA der Ribosomen.

Die Mitochondrien gehören zu den selbstvermehrenden Organellen und sind nur in Eukaryoten-Zellen enthalten, und zwar in unterschiedlicher Anzahl. Sie enthalten ein eigenes Genom, das viele, aber nicht alle der für die Mitochondrien wichtigen Gene enthält. Die anderen Gene befinden sich in den Chromosomen im Zellkern. Deshalb sind die Mitochondrien semiautonom. Mitochondrien werden als „Energiekraftwerke“ der Zelle bezeichnet. In ihnen findet die Oxidation organischer Stoffe mit molekularem Sauerstoff statt, wobei Energie freigesetzt und in Form von chemischer Energie (als ATP) gespeichert wird. Sie haben einen Durchmesser von etwa 0,5 bis 1,5 µm und sind etwa 0,8 bis 4 µm lang.

Plastiden existieren nur in Eukaryoten, die Photosynthese betreiben, also Pflanzen und Algen. Wie die Mitochondrien besitzen die Plastiden ihr eigenes Genom und sind wie die Mitochondrien selbstvermehrend, also auch semiautonom. Es gibt verschiedene Plastiden, die alle von dem sogenannten „Proplastiden“ abstammen. Sie sind in der Lage, sich in eine andere Plastidenform umzuwandeln. Der Chloroplast ist der am häufigsten erwähnte. Er dient der Nutzung von Licht zum Aufbau organischer Stoffe (Photosynthese) und enthält alle für die Photosynthese erforderlichen Zellbestandteile, vor allem Membransysteme mit Chlorophyll, Hilfsfarbstoffen, Elektronen- und Wasserstoff­überträgern und ATP-Synthase sowie Enzyme des Calvin-Zyklus für die CO-Assimilation. Ein anderer Plastid ist zum Beispiel der Amyloplast, der in der Lage ist, Stärke, ein Photosynthese-Endprodukt, zu speichern.

Diese beiden Systeme bestehen aus von Membranen begrenzten Hohlräumen und sind in den meisten Eukaryoten zu finden. Sie sind funktionell eng miteinander verknüpft. Das Endoplasmatische Retikulum (ER) ist das schnelle Transportsystem für chemische Stoffe, weiterhin wird in der Mitose die neue Kernmembran vom ER abgeschnürt. Außerdem ist es für die Translation, Proteinfaltung, posttranslationale Modifikationen von Proteinen und Proteintransport von Bedeutung. Diese Proteine werden anschließend vom Golgi-Apparat „verteilt“. Im Golgi-Apparat werden die Proteine modifiziert, sortiert und an den Bestimmungsort transportiert. Defekte Proteine werden dabei aussortiert und abgebaut.

Lysosomen sind winzige, von einer Membran umschlossene Zellorganellen in Eukaryoten. Sie enthalten hydrolytische Enzyme und Phosphatasen. Ihre Hauptfunktion besteht darin, mittels der in ihnen enthaltenen Enzyme aufgenommene Fremdstoffe zu verdauen. Bei Pflanzen nehmen Zellsaftvakuolen die Aufgaben der Lysosomen wahr.

Peroxisomen (Glyoxisomen im Speichergewebe von Pflanzensamen), auch Microbodies genannt, sind evolutionär sehr alte Zellorganellen in eukaryotischen Zellen. Sie fungieren als Entgiftungsapparate. In den Peroxisomen befinden sich ca. 60 Monooxygenasen und Oxidasen genannte Enzyme, die den oxidativen Abbau von Fettsäuren, Alkohol und anderen schädlichen Verbindungen katalysieren.
Vakuolen sind große, von einer Membran umschlossenen Reaktionsräume vorwiegend in Pflanzen, die bis zu 90 % des Zellvolumens einnehmen können, aber zum Beispiel auch im Pantoffeltierchen (Paramecium) vorkommen können. Sie erfüllen die vielfältigsten Aufgaben, unter anderem Aufrechterhaltung des Zelldrucks (Turgor), Lager für toxische Stoffe, Farbgebung der Zelle, Verdauung von Makromolekülen und im Falle der kontraktilen Vakuole der Wasserausscheidung.

"Siehe:" Geschichte der Zellbiologie

Zellen und Gewebe können auch als Arzneimittel für neuartige Therapien zur Behandlung von Krankheiten verwendet werden.





</doc>
<doc id="10781" url="https://de.wikipedia.org/wiki?curid=10781" title="Kapitalmarkt">
Kapitalmarkt

Der Kapitalmarkt ist derjenige Teilmarkt des Finanzmarktes, auf dem der mittel- und langfristige Kapitalbedarf auf das Kapitalangebot trifft. Kurzfristige Transaktionen erfolgen auf dem Geldmarkt.

Das Kompositum „Kapitalmarkt“ setzt sich aus dem Homonym „Kapital“ und Markt zusammen. Unter Kapital ist hier nicht der Produktionsfaktor zu verstehen, sondern die auf diesem Markt als Handelsobjekte dienenden mittel- oder langfristigen Finanzierungsinstrumente. Marktteilnehmer sind alle Wirtschaftssubjekte (Privathaushalte, Unternehmen, der Staat mit seinen Untergliederungen (wie öffentliche Verwaltung und Staatsunternehmen oder Kommunalunternehmen). Sie treten als Kapitalgeber (Anleger), Finanzintermediäre (Kreditinstitute, Versicherungen, Investmentfonds) oder Kapitalnehmer auf. Handelsobjekte sind konkret mittel- oder langfristige Kredite (Investitionskredite, Kommunalkredite), Darlehen (Hypothekendarlehen, Immobilienfinanzierungen) oder Mezzanine-Kapital (Kreditmarkt), Anleihen jeder Art (Rentenmarkt), Aktien und Partizipationsscheine oder Genussscheine (Aktienmarkt). Der Preis auf dem Kapitalmarkt ist verallgemeinernd der Kapitalmarktzins, der jedoch wegen der Verschiedenartigkeit der Finanzprodukte kein einheitlicher Zins darstellt. Als Marktzins fungieren bei Anleihen die Emissionsrendite (Primärmarkt) oder die Umlaufrendite (Sekundärmarkt) bei Aktien die Dividendenrendite, bei Krediten der Kreditzins. Den einzigen organisierten Kapitalmarkt bilden die Börsen. 

Der Kapitalmarkt unterscheidet sich vom Geldmarkt vor allem durch die Fristigkeit der Handelsobjekte. Diese Einteilung führte im Jahre 1909 der Ökonom Arthur Spiethoff ein. Sie betrifft auf dem Kapitalmarkt Laufzeiten oder Fälligkeiten von mehr als vier Jahren, wobei die Abgrenzung unterschiedlich vorgenommen wird. Die mittlere Fristigkeit (2-4 Jahre) wird in der Fachliteratur entweder dem Geldmarkt oder dem Kapitalmarkt zugeordnet. Der Kapitalmarkt wird häufig auch auf den Wertpapiermarkt verengt, welcher sowohl Dividendenwerte, beispielsweise Aktien, als auch festverzinsliche Wertpapiere, wie Anleihen beinhaltet.

Das "Kapitalangebot" stammt von Anlegern, die bereit sind, ihr Kapital langfristig zwecks Geldvermögensbildung zur Verfügung zu stellen. Das sind einerseits diejenigen Anleger, die von vorneherein hierzu bereit waren (Sparer), und andererseits die Anleger, denen der Geldmarktzins auf dem Geldmarkt zu niedrig erscheint. Bei letzteren wirkt sich ihre Anlageentscheidung negativ auf das Geldangebot auf dem Geldmarkt und erhöhend auf das Kapitalangebot auf dem Kapitalmarkt aus. Steigt das Kapitalangebot bei gegebener Kapitalnachfrage, sinkt der Kapitalmarktzins und umgekehrt. Der Grenzertrag nimmt für den Kapitalanbieter mit steigendem Kapitalangebot ab. Die Höhe des Kapitalmarktzinses ist einerseits ein Signal für die Knappheit, andererseits auch stets ein Risikomaß für das mit der Kapitalüberlassung verbundene Kreditrisiko. Stammt das Kapitalangebot aus dem Ausland, spricht man vom Kapitalimport.

Als "Kapitalnachfrager" kommen die öffentliche Hand (Kommunalanleihen, Kommunalobligationen), die Privatwirtschaft (Industrie: Investitionskredite; Immobilienwirtschaft: Wohnungsbau, Gewerbeimmobilien) und Privathaushalte (Immobilienfinanzierung) in Betracht. Kapitalnachfrager werden nur dann investieren, wenn die Grenzleistungsfähigkeit des Kapitals den aktuellen Marktzins übersteigt. Steigt der Kapitalmarktzins über die Grenzleistungsfähigkeit des Kapitals, sinkt die Kapitalnachfrage und umgekehrt. Steigt die Kapitalnachfrage bei gegebenem Kapitalangebot, steigt auch der Kapitalmarktzins und umgekehrt. Ausländische Kapitalnachfrage führt zum Kapitalexport.

Der Kapitalmarkt befindet sich im Marktgleichgewicht, wenn das gesamtwirtschaftliche Kapitalangebot formula_1 der gesamtwirtschaftlichen Kapitalnachfrage formula_2 entspricht: 
Das "langfristige Marktgleichgewicht" ist hergestellt, wenn sich die Kapitalintensität (Kapitalausstattung pro Kopf) nicht mehr verändert. Befindet sich der Kapitalmarkt im Gleichgewicht, so gelangen Ersparnis und Investitionen beim Gleichgewichtszinssatz zum Ausgleich. Ein hoher Kapitalmarktzins kann Privathaushalte zur Kapitalanlage (zu Lasten des Konsums) anregen und damit über ein höheres Kapitalangebot zur Reduzierung des Zinses beitragen und umgekehrt.

Die Aufgabe der Intermediäre liegt darin, das Gleichgewicht zwischen Kapitalangebot und -nachfrage zu erleichtern, indem sie Transaktionen in den Zahlungsströmen der Kapitalnachfrager und -anbieter durchführen, den Informationsstand verbessern und Transaktionsabwicklungen unterstützen.

Zu unterscheiden ist zwischen der Allokations-, Informations- und Bewertungsfunktion:

Man unterscheidet zwischen Mengentransformation, Fristentransformation, Losgrößentransformation und Risikotransformation.

Die Mengentransformation umfasst die Ansammlung der in einer Volkswirtschaft gebildeten Ersparnisse und deren Verteilung zu den Investoren in gewünschter Fristigkeit und Mengenordnung.

Die Fristentransformation ermöglicht den Ausgleich der Fristen zwischen Kapitalgebern und -nehmern. Dabei handelt es sich um die Frist, während der ein Kredit durch einen Anleger in Anspruch genommen wird und um die Frist, die verstreicht, bis ein Sparer seine finanziellen Mittel zur Verfügung stellt. Diese Fristen weichen in der Regel voneinander ab.

Die Losgrößentransformation ermöglicht durch eine Zusammenführung von mehreren Kapitalgebern eine Übereinstimmung, der durch die Kapitalnehmer nachgefragten Beträge, die ein einzelner Kapitalgeber nicht zur Verfügung stellen könnte.

Eine Risikotransformation findet auf Kapitalmärkten statt, wenn Finanzintermediäre zwischen die Marktteilnehmer mit unterschiedlicher Risikobereitschaft treten und das Ausfallrisiko verändern. Durch die Risikotransformation erhalten die Sparer die Möglichkeit, ihr Kreditrisiko abzusichern oder zu verteilen. Unsichere Zahlungsströme können so in sichere Zahlungsströme umgewandelt werden. So können beispielsweise Risiken durch schwankende Wechselkurse umgewandelt werden. 

Marcus Tullius Cicero berichtete im Jahre 66 vor Christus darüber, dass eine asiatische Finanzkrise wegen ihrer Verflechtungen auch Rom ansteckte: „Dieses Kreditwesen und diese Geldgeschäfte, welche in Rom, welche auf dem Forum getätigt werden, sind eng verflochten mit jenen Geldern in Asien“. 

Im Spätmittelalter kam es zwischen der zweiten Hälfte des 14. Jahrhunderts und dem Ende des 15. Jahrhunderts durch die herrschende Edelmetallknappheit und die hieraus resultierende monetäre Kontraktion zu einer Liquiditätskrise. Die europäische Edelmetallförderung versiegte, die Münzstätten verringerten ihre Produktion oder stellten sie sogar völlig ein. Das Geldangebot verknappte sich, weil auch die Kreditversorgung auf den Edelmetallvorräten beruhte. Grund war aber nicht nur das geringere Edelmetallangebot, sondern auch die Hortung von Münzen. Zwischen 1331-1340 und 1491-1500 schätzte man den Rückgang der europäischen Münzproduktion auf 80 %. 

Kapitalmärkte begannen institutionell mit der Errichtung von Börsen. Die Antwerpener Börse startete 1532 mit einem geregelten Handel von Anleihen, worunter sich niederländische Hofbriefe (Staatsanleihen), Privat-Obligationen der niederländischen Staatsbeamten und Magnaten (für Rechnung der Regierung), Obligationen der niederländischen Provinzialstände, Stadtobligationen, Rentmeisterbriefe und Obligationen der englischen Krone und des Königs von Portugal befanden. Die erste Aktienbörse entstand mit der Amsterdam Stock Exchange () im Jahre 1612. Sie gilt als erste Aktienbörse, die im 17. Jahrhundert einen dauerhaften Aktienhandel ermöglichte. Es folgten Börsen in Königsberg (1613), Lübeck (1614), Frankfurt am Main (1615) oder Leipzig (1635), die zunächst ausschließlich mit Wechseln und Sorten handelten.
Eine der ersten Kapitalmarktkrisen war der Gründerkrach, der erstmals am 5. Mai 1873 zu größeren Kursverlusten an der Wiener Börse führte, wo die Kursstürze am 9. Mai 1873 (Schwarzer Freitag) ihren vorläufigen Höhepunkt erreichten. Die Krise übertrug sich vor allem im Wege des Contagion-Effekts als Große Depression auf das Deutsche Reich. 

Der Volkswirt Rudolph Eberstadt hat für seine Monographie aus dem Jahre 1901 über den deutschen Kapitalmarkt sein Material hauptsächlich durch direkte Anfragen bei den Stadtverwaltungen beschafft. Er wies hierin darauf hin, dass die „dauernde Schwäche des deutschen Kapitalmarktes, die Unfähigkeit, zu produktiven Zwecken das nötige Kapital aufzubringen, dürfte durch die Ansprüche der Bodenverschuldung [Hypothekendarlehen, d. Verf.] … zur Genüge erklärt sein“. Eberstadts Hinweis entstand noch in einer Zeit, als die Kapitalmärkte wenig entwickelt und noch weniger erforscht waren. 

Die systematischen Untersuchungen über Kapitalmärkte begannen in der Volkswirtschaftslehre erst mit der Entstehung der Kapitalmarkttheorien. Die "klassische Kapitalmarkttheorie" analysiert, welche Wertpapierkurse oder Wertpapierrenditen sich im Marktgleichgewicht auf einem vollkommenen Kapitalmarkt einstellen. Sie beruht auf dem Prinzip, dass es eine lineare Beziehung zwischen Risiko und Rendite gibt, wonach höhere Renditen nur durch höheres Risiko erzielt werden können. Sie geht von der Existenz eines vollkommenen Kapitalmarktes aus. 

Die klassische Kapitalmarkttheorie entwickelte Harry Markowitz im Jahre 1952. James Tobin wandte 1958 das Markowitz-Modell bei der Entwicklung seiner Geldnachfragetheorie an. Dabei erweiterte er die klassische Theorie um die Möglichkeit einer risikofreien Kapitalanlage. William F. Sharpe definierte 1964 das Risiko einer Kapitalanlage ausschließlich als deren statistische Volatilität, also das Ausmaß der Schwankungen der Börsenkurse. Jack Treynor trug 1965 mit der nach ihm benannten Kennzahl Treynor-Quotient zum weiteren Verständnis des Capital Asset Pricing Model (CAPM) bei. Jan Mossin vervollständigte 1966 das nunmehr entstandene CAPM, das als das wichtigste Preisbildungsmodell auf dem Kapitalmarkt gilt.

Eugene Fama entwickelte 1970 den Begriff der Markteffizienz. Demnach ist ein Markt effizient, wenn seine Marktpreise alle verfügbaren Informationen reflektieren. Robert C. Merton erweiterte 1973 die CAPM durch die Mitarbeit am Black-Scholes-Modell zur Bewertung von Finanzoptionen. Die von Stephen Ross 1976 entwickelte Arbitragepreistheorie fordert im Gegensatz zum CAPM kein Marktgleichgewicht mehr, sondern lediglich einen arbitragefreien Wertpapiermarkt.

Die "neoklassische Kapitalmarkttheorie" baut auf der durch John von Neumann und Oskar Morgenstern 1944 entwickelten Erwartungsnutzentheorie auf, bei der rational handelnde Akteure den Erwartungswert ihrer Risikonutzenfunktion maximieren. Sie bildet die Grundlage rationalen Handelns bei Entscheidungen unter Risiko. Sie postuliert, dass, wenn die Präferenz eines entscheidenden Akteurs bezüglich riskanter Handlungsalternativen die Axiome der Vollständigkeit, Stetigkeit und Unabhängigkeit erfüllt, eine Nutzenfunktion existiert, deren Erwartungsnutzen die Präferenz abbildet.

Sowohl die Klassiker als auch die neoklassische Kapitalmarkttheorie gehen zunächst vom idealtypischen Zustand vollkommener Kapitalmärkte aus. In der Realität liegt jedoch aufgrund von Transaktionskosten, Informationsasymmetrien, begrenzt rationalem Verhalten, Liquidationskosten und nicht risikodiversifizierten Portfolios eine Kapitalmarktunvollkommenheit vor.

Kapitalmärkte werden anhand des Organisationsgrads und der Einteilung in Primär- oder Sekundärmärkte unterschieden.

Der Kapitalmarkt wird in der Praxis in zwei Hauptsegmente gegliedert, den Primärmarkt und den Sekundärmarkt. Der Primärmarkt liefert Informationen über den Emittenten und dessen Finanzprodukt und ist daher besonders für die Anleger von großer Bedeutung. Der Sekundärmarkt umfasst die Durchführung und Abwicklung der Wertpapiergeschäfte. Der Primärmarkt beschäftigt sich mit dem Angebot von neu herausgebrachten Wertpapieren, die von Investoren nachgefragt werden sollen. Dieser Markt wird auch als Emissionsmarkt bezeichnet, da unter diesem Segment die Erstplatzierung der Aktien und Anleihen während des Emissionsverlaufs zu verstehen ist. Der Sekundärmarkt, auch als Zirkulationsmarkt bezeichnet, umfasst den Wertpapierhandel zwischen den Marktteilnehmern, also den Wiederverkauf der neu emittierten Wertpapiere durch den Ersterwerber an die neuen Anleger. Der bekannteste Ort des Sekundärmarktes sind die Wertpapierbörsen.

Beim Organisationsgrad wird unterschieden in "organisierte Märkte" und in "nicht organisierte Märkte". 

Ein hoch organisierter Kapitalmarkt, wie der börslich organisierte Markt, zeichnet sich durch kostengünstige, schnelle, sichere und jederzeit handelbare, staatlich genehmigte Transaktionen aus. Die Wertpapierbörsen, wie beispielsweise die Frankfurter Wertpapierbörse, sind die höchst organisierten Kapitalmärkte weltweit. Der organisierte Kapitalmarkt untergliedert sich unter anderem in die Aktien- und Rentenmärkte, Emissionsmärkte und Märkte für Schuldscheindarlehen.

Der freie Kapitalmarkt und der Interbankenhandel weisen hingegen, mit nur wenigen Marktregulierungen, einen sehr geringen Grad an Organisation auf. Dort finden hauptsächlich Transaktionen ohne Mitwirkung von Banken, Börsen und Versicherungen statt, die meist unsicher und nicht überschaubar sind. Der in Deutschland am geringsten organisierte Markt wird als Grauer Kapitalmarkt bezeichnet, an dem beispielsweise der Handel von Anteilen an Immobilienfonds im Vordergrund steht.

Sowohl in der Volkswirtschaftslehre als auch in der Betriebswirtschaftslehre wird versucht, die oben genannten charakteristischen Merkmale durch Modelle abzubilden. Dabei kommen insbesondere die theoretischen Konstruktionen des vollkommenen und unvollkommenen Kapitalmarktes zur Anwendung.

Charakteristisch für dieses vereinfachte theoretische Modell des "vollkommenen Kapitalmarktes" ist, dass die Handelsobjekte auf dem Markt homogen sind und vollkommene Markttransparenz vorliegt. Die Möglichkeiten der Aufnahme und Anlage von Kapital sind unbegrenzt. Die Teilnehmer des Marktes können schnell auf Änderungen von Menge und Preis reagieren, da es keine Zeitverzögerungen () gibt. Auf dem vollkommenen Kapitalmarkt werden Eigen- und Fremdkapital nicht unterschieden, womit es folglich nur einen einheitlichen und gleich bleibenden Marktzins gibt. Diese Annahmen werden schrittweise an die Realität angepasst.

Von einem unvollkommenen Kapitalmarkt (auch "imperfekter Kapitalmarkt" genannt) spricht man, wenn mindestens eine der vorangegangenen Annahmen nicht erfüllt ist.

Von einem vollständigen Kapitalmarkt wird gesprochen, wenn durch Linearkombinationen der gehandelten Zahlungsströme (Wertpapiere) der gesamte Zustandsraum abgebildet werden kann.




</doc>
<doc id="10782" url="https://de.wikipedia.org/wiki?curid=10782" title="Hyperinflation">
Hyperinflation

Hyperinflation ist eine Form der Inflation, in der sich das Preisniveau sehr schnell erhöht. Eine allgemein akzeptierte Definition existiert nicht, eine 1956 von Phillip D. Cagan aufgestellte Faustregel von monatlichen Inflationsraten von 50 % (entsprechend einer jährlichen Rate von umgerechnet rund 13.000 %) ist aber weit verbreitet. Vereinfacht ausgedrückt ist eine Hyperinflation eine unkontrollierbare Inflation mit extrem hoher monatlicher Rate. Meist dauern Hyperinflationen nur eine kurze Zeit und enden in einer Währungsreform.

Vor dem 20. Jahrhundert waren Hyperinflationen selten, da die Ökonomien bei Überschreitung eines gewissen Inflationsniveaus zu ungeprägten Edelmetallen als Geldersatz oder zu Naturaltausch übergingen. Die immer weitere Verbreitung von ungedecktem Geld (Fiatgeld) ermöglichte Hyperinflationen. Der Verursacher der (Hyper-)Inflation ist immer der Staat, da er sich zur Deckung seiner Ausgaben (Erfüllung von Leistungsversprechen) permanent verschulden muss und damit letztlich das Vertrauen in die eigene Währung untergräbt.

Während gewöhnliche Inflationen meist mit ökonomischen Ursachen begründet werden, sind Hyperinflationen darüber hinaus fast immer mit schwerwiegenden Erschütterungen der Volkswirtschaft infolge von Krieg, Bürgerkrieg oder gesellschaftlichen Umbruchsituationen verbunden. Die sowjetische Hyperinflation von 1919 bis 1922 hatte das Ziel der Abschaffung des Geldes als Zahlungsmittel.

Wie bei einer Inflation kommt es sehr schnell zu Anlagen in fremder Währung. Um die damit verbundene Kapitalflucht zu stoppen, kommt es während der Hyperinflation zu Devisenbewirtschaftung und massiver Devisenverkehrsbeschränkung. Angesichts des seit Ende des 20. Jahrhunderts möglichen weltweiten bargeldlosen Zahlungsverkehrs sind jedoch solche Maßnahmen nur noch begrenzt möglich.

Eine Hyperinflation führt bei den Geldanlegern oft zu einer „Flucht in Sachwerte“ und zu einem weitgehenden Verlust aller anderen Geldanlagen wie z. B. Anleihen, welche auf die betreffende Währung lauten. Dies ist ein sich selbst verstärkender Vorgang.

Sachwerte sind vorrangig Immobilien und Rohstoffe, aber auch Edelmetalle oder Aktien. Die Folge ist oft eine vorübergehende Verknappung von Zahlungsmitteln, wenn beispielsweise die Kunden einer Bank ihre gesamten Ersparnisse abheben.

Eine Erklärung für das Ansteigen des allgemeinen Preisniveaus in der Hyperinflation bietet die Quantitätsgleichung von Irving Fisher:

Diese Formel lässt sich umformen zu:

Das Preisniveau steigt also demnach u. a.


Es gibt verschiedene geschichtliche Episoden von Hyperinflationen mit monatlichen Inflationsraten von über 50 Prozent. Beispiele sind

Auch vor dem 20. Jahrhundert gab es schwere Inflationen:



</doc>
<doc id="10783" url="https://de.wikipedia.org/wiki?curid=10783" title="Kfz-Kennzeichen (Deutschland)">
Kfz-Kennzeichen (Deutschland)

Das Kfz-Kennzeichen (allgemeinsprachlich auch Nummernschild) ist in Deutschland die gemäß der Fahrzeug-Zulassungsverordnung (FZV) von den Kraftfahrzeug-Zulassungsstellen ausgegebene amtliche Kennzeichnung von Fahrzeugen für Kraftfahrzeuge und gegebenenfalls deren Anhänger. Das Kfz-Kennzeichen besteht aus einem Unterscheidungszeichen (ein bis drei Buchstaben, z. B. RA) und der Erkennungsnummer (ein oder zwei Buchstaben und bis zu vier Ziffern, z. B. KL 8136). Für zulassungspflichtige Kraftfahrzeuge dienen sie zusammen mit der Zulassungsbescheinigung als Nachweis für die Zulassung von Fahrzeugen zum Straßenverkehr durch eine örtlich und sachlich zuständige Straßenverkehrsbehörde (je nach Wohnsitz bzw. Unternehmenssitz). Fahrzeuge, für die eine allgemeine Betriebserlaubnis oder Typgenehmigung genügt (zulassungsfreie Fahrzeuge), zeigen Versicherungskennzeichen. Diese gelten zulassungsrechtlich nicht als amtliche Kennzeichen, da sie von der Kfz-Haftpflichtversicherung ausgegeben werden. Der Begriff Kfz-Kennzeichen steht gleichermaßen für die alphanumerische Zeichenfolge als auch für das eigentliche Kennzeichenschild.

Die Liste der Kfz-Kennzeichen in Deutschland enthält alle derzeit festgelegten Unterscheidungszeichen, also auch inklusive aller ehemals aufgehobenen und nach der Änderung der Fahrzeug-Zulassungsverordnung 2012 wiedereingeführten Unterscheidungszeichen. Zu den aufgehobenen Unterscheidungszeichen, also solchen, die nicht mehr zugeteilt werden dürfen, siehe die Liste der deutschen Kfz-Kennzeichen, die nicht mehr ausgegeben werden. Zu allen in Deutschland bisher ausgegebenen Unterscheidungszeichen mit Angaben zu den Zeiträumen siehe die Liste aller Kfz-Kennzeichen der Bundesrepublik Deutschland.

In den deutschen Staaten begannen einige örtliche Behörden zwischen 1870 und 1890 wegen vermehrter Fälle von Fahrerflucht Nummernschilder für Fahrräder vorzuschreiben, die lokal ausgegeben wurden und sich farblich unterschieden. Im Jahr 1896 wurde in Baden das erste Nummernschild an einem Automobil befestigt. Am 1. Oktober 1906 wurde die erste einheitliche Regelung erlassen, die am 1. Oktober 1907 für die 26 Bundesstaaten des Deutschen Reichs in Kraft trat. 10.115 Pkw, 15.954 Krafträder und 957 Lkw waren damals zugelassen.

Die einheitlichen Kennzeichen der Länder im Deutschen Reich begannen bei einigen größeren Ländern mit einer römischen Zahl für das Territorium – I = Preußen, II = Königreich Bayern bis VI = Reichsland Elsaß-Lothringen – gefolgt von einem Buchstaben für den Verwaltungsbezirk – I A = Berlin, II A = München, III A = Stuttgart … – und zum Schluss einer Ziffernfolge. Im Königreich Sachsen erfolgte die Kennung entgegengesetzt: ohne Buchstabenfolge, lediglich über römische Zahlen von I bis V. Die Kennzeichen einiger kleinerer Staaten erhielten ihrem Namen entsprechend ein oder zwei Buchstaben, wie A für Anhalt (zum Teil gefolgt von einer römischen Zahl). Darunter die freien Hansestädte Bremen, Hamburg und Lübeck, mit den Kennzeichen HB, HH, HL, die (mit Unterbrechung in der Besatzungszeit) bis heute erhalten blieben.

Nach dem Zweiten Weltkrieg wurden die Kennzeichen in den Besatzungszonen Deutschlands anfänglich farblich unterschieden – schwarz auf orangefarbenem Grund: amerikanische Zone, schwarz auf rotem Grund: französische Zone, schwarz auf blauem Grund: britische Zone, und in der sowjetischen Zone verblieb schwarz auf weißem Grund. 1947 beschlossen die Vier Mächte ein einheitliches System, das ab 1948 eingeführt wurde. Die neuen Kennzeichen in den vier Besatzungszonen wurden nun einheitlich weiß auf schwarzem Grund gehalten, deren Registriernummer enthielt jeweils vorne zwei Buchstaben (die übereinander geschrieben waren) für den Verwaltungsbereich, z. B. "BR" für die Britische Zone Rheinland oder "AB" für die Amerikanische Zone Bayern. Daran schlossen sich vier Ziffern für die Nummerierung der Fahrzeuge innerhalb eines Verwaltungsbereiches an. Diese Kennzeichen galten bis zur Einführung eigener Systeme in den Nachkriegsstaaten Bundesrepublik Deutschland und Deutsche Demokratische Republik.

Im September 1949 hatte die "Verwaltung für Verkehr des Vereinigten Wirtschaftsgebietes" in Offenbach die Länder darauf hingewiesen, dass das geltende Kfz-Kennzeichensystem nicht der zunehmenden Motorisierung gewachsen sei, da die vier Ziffern der Nummerierung nicht mehr für alle Kfz eines Verwaltungsbezirks ausreichten. Im November 1951 legte daher der Bundesverkehrsminister Hans-Christoph Seebohm (DP) einen Entwurf für ein neues Kennzeichensystem vor, das das bisherige ersetzen sollte. Die Verabschiedung durch den Bundesrat, die für den 14. Mai 1952 vorgesehen war, wurde jedoch, durch Absetzung von der Tagesordnung, unterlassen, da die Westmächte einwendeten, die Ersetzung des alten Systems werde nicht die Zustimmung der Sowjetunion finden. Diese würde dann nur noch nach dem alten System gekennzeichneten Fahrzeuge in oder durch das Gebiet der DDR fahren lassen. Die entsprechende Verordnung blieb dann bis nach dem Erlöschen der meisten alliierten Vorbehaltsrechte durch den Deutschlandvertrag liegen und wurde Ende 1955 wieder aufgegriffen und verabschiedet. Mit der am 14. März 1956 veröffentlichten "Verordnung zur Änderung von Vorschriften des Verkehrsrechts" () wurde dieses für die Bundesrepublik Deutschland und West-Berlin eingeführt, ebenso am 31. Dezember 1956 im Saarland. Die DDR hatte bereits 1953 ein eigenes System eingeführt, das auch weiß mit schwarzen Rahmen und DIN-Schrift gestaltet war.

Das heutige System wurde in der Bundesrepublik Deutschland am 1. Juli 1956 eingeführt und nach der Wiedervereinigung 1990 mit leichter Verzögerung am 1. Januar 1991 auch auf die neuen Bundesländer übertragen. Ausgestaltung und Anbringung der amtlichen Kennzeichen sind in Fahrzeug-Zulassungsverordnung vom 25. April 2006 geregelt.

Derzeit existieren in Deutschland zwei unterschiedliche Versionen der Kennzeichen. Ihnen gemeinsam ist die schwarze Schrift auf weißem Grund mit schwarzer Rahmenlinie. Es handelt sich dabei zum einen um die älteren, seit 1956 verwendeten DIN-Kennzeichen, benannt nach ihrer Schriftart, die nach DIN 1451 (Mittelschrift) festgelegt ist und die 1949 vereinheitlichten Schilder der drei westlichen Besatzungszonen (weiße Schrift auf schwarzem Grund) ablösten. Zum anderen um die neuen Euro-Kennzeichen, die die FE-Schrift (FE = fälschungserschwerend) verwenden. Bei dieser unterscheiden sich die Buchstaben deutlicher voneinander als bei der alten DIN-Schrift, sodass Verfälschungen erschwert und die automatische Erkennung mit Kamerasystemen erleichtert werden (siehe auch Mautbrücken, Lkw-Maut). Mit Einführung der FE-Schrift wurde es durch jeweilige Änderung der Straßenverkehrs-Zulassungs-Ordnung, die bis zum Inkrafttreten der Fahrzeug-Zulassungsverordnung auch die Zulassung von Fahrzeugen in Deutschland regelte, möglich, für die laufende Erkennungsnummer auch die Buchstaben "B, F, G, I, O" und "Q" zu verwenden, die ursprünglich wegen Verwechslungsgefahr gesperrt waren. Somit stehen bei der Vergabe von Kennzeichen deutlich mehr Kombinationen zur Verfügung. Die Euro-Kennzeichen wurden das erste Mal 1994 von Berlin und Brandenburg verwendet, noch bevor sie deutschlandweit Verwendung fanden. Seit dem 1. November 2000 waren bei Neuzulassungen nur noch die Euro-Kennzeichen am Fahrzeug anzubringen (außer Bundeswehr-Fahrzeuge), was allerdings in Einzelfällen nicht immer der Fall war.

Ein weiterer Vorteil der Euro-Kennzeichen ist, dass bei Reisen innerhalb der Europäischen Union sowie in die Schweiz auf das ovale Nationalitätszeichen (z. B. "D") am Fahrzeugheck verzichtet werden kann.

Am 29. September 1989 wurden reflektierende Kfz-Kennzeichen (spezielle Folie zur besonders starken Lichtreflexion am weißen Flächenhintergrund) für Neuwagen und auch für Fahrzeuge mit beschädigten Schildern eingeführt, die es bereits seit 1967 auf dem Markt gab und für die sich nur 15 Prozent der Halter freiwillig entschieden. Eine Ausnahme bilden aus militärtaktischen Gründen die Fahrzeuge der Bundeswehr. Diese reflektierenden Kennzeichen sollen für mehr Sicherheit sorgen, beispielsweise für Fahrzeuge, die unbeleuchtet in der Dämmerung oder bei schlechtem Wetter fahren, sowie bei einem Ausfall der Schlussleuchte. Mit der Einführung der neuen Sicherheitskennzeichen gab es auch eine Preiserhöhung von in der Regel 20 auf 40 DM pro Kennzeichensatz.

Die heutigen Kfz-Kennzeichen in Deutschland sind als Euro-Kennzeichen ausgeführt. Sie bestehen aus zwei Teilen:
Zusammen sind es jedoch maximal acht Zeichen, bei Saisonkennzeichen maximal sieben Zeichen. Bei Kennzeichen mit zwei Zeilen, wie bei Krafträdern oder auch manchmal am Heck verwendet, sind jedoch aus Platzgründen auch bei Schmalschrift nur insgesamt sieben Zeichen erlaubt. Zwischen dem Unterscheidungszeichen und der Erkennungsnummer befindet sich Platz für die Prüfplaketten und das Siegel der Zulassungsbehörde. Auf den Bindestrich nach dem Unterscheidungszeichen wurde fortan verzichtet.

Anders als in einigen anderen Staaten sind die Kennzeichen dem Fahrzeug und nicht dem Halter zugeordnet. Aus diesem Grund geht das Kennzeichen bei Veräußerung auf den neuen Halter über, es sei denn, der Veräußerer meldet das Fahrzeug vor der Veräußerung ab und der Erwerber mit neuem Kennzeichen wieder an.

In Deutschland gibt es, anders als zum Beispiel in Liechtenstein oder in einigen Kantonen der Schweiz, keine allgemein einsehbaren Listen, aus denen anhand des Kennzeichens auf den Halter geschlossen werden kann.

Der Zeitpunkt der Zulassung ist nicht im Kennzeichen vermerkt. Allerdings vergeben viele Zulassungsstellen (zum Beispiel Erlangen, wenn kein Wunschkennzeichen beantragt wird) die Kennzeichen nach einem (früher in Paragraf 23 Abs. II Satz 4 i. V. m. Anlage II der StVZO vorgegebenen) fortlaufenden System (vgl. Abschnitt Erkennungsnummer, Gruppen a bis e), sodass dadurch grob auf den Zeitraum der Zulassung geschlossen werden kann.

Die Unterscheidungszeichen bestehen aus einem, zwei oder drei Buchstaben:

Die Unterscheidungszeichen der Verwaltungsbezirke werden auf Antrag der Länder vom Bundesministerium für Verkehr, Bau und Stadtentwicklung festgelegt oder aufgehoben. Die Festlegung und Aufhebung von Unterscheidungszeichen wird im Bundesanzeiger veröffentlicht. Die Buchstabenkombination eines Unterscheidungszeichens darf nicht gegen die guten Sitten verstoßen. Auf Antrag können Verwaltungsbezirke seit dem 1. November 2012 infolge der Kennzeichenliberalisierung mehr als ein Unterscheidungszeichen führen, wobei nur solche Unterscheidungszeichen beantragt werden dürfen, die vor dem 25. Oktober 2012 vergeben worden sind. Kennzeichen, deren Unterscheidungszeichen aufgehoben ist, dürfen bis zur Außerbetriebsetzung des betroffenen Fahrzeuges weitergeführt werden.

Umkennzeichnung

Wenn der Standort eines Fahrzeugs in einen anderen Verwaltungsbezirk verlegt wird, musste dort bis Ende 2014 in jedem Fall ein neues Kennzeichen beantragt werden (Umkennzeichnungspflicht). Seit September 2008 konnten die Bundesländer entscheiden, ob bei einem Wechsel in einen anderen Zulassungsbezirk innerhalb des eigenen Landes neue Kennzeichen zugeteilt werden mussten oder nicht. Seit dem 1. Januar 2015 ist die Umkennzeichnungspflicht bundesweit entfallen.

Die Erkennungsnummer besteht aus

Gemeinsam mit dem Unterscheidungszeichen darf das Kennzeichen nicht mehr als acht Stellen haben, d. h. bei Unterscheidungszeichen mit drei Buchstaben darf die Erkennungsnummer höchstens fünf Zeichen lang sein.

Ab dem 1. Juli 1956 wurden zunächst nur die folgenden 20 Buchstaben verwendet: A, C, D, E, H, I, K, L, M, N, P, R, S, T, U, V, W, X, Y und Z. Mit Wirkung vom 7. November 1956 wurde anstelle des Buchstabens I nur noch der Buchstabe J verwendet. Mit Wirkung vom 12. August 1992 wurde zusätzlich die Zuteilung der drei Buchstaben B, F und G und seit dem 26. Mai 2000 auch die Zuteilung der Buchstaben I, O und Q zugelassen. 

Gelegentlich kann man an der Anzahl der mittleren Buchstaben und der Ziffern den genaueren Zulassungsbezirk ermitteln. "(siehe Liste aller deutschen Kfz-Kennzeichen mit einer Gebietseinteilung)". Dieses System beruht darauf, dass die möglichen Erkennungsnummern in Gruppen eingeteilt sind:

Die angegebenen 7.019.298 Kombinationsmöglichkeiten sind theoretischer Natur. Einige Kombinationen sind als unerwünschte Erkennungsnummern gesperrt, sodass die Gesamtzahl der tatsächlich nutzbaren Möglichkeiten geringer ist als oben angegeben.

Diese Gruppen finden Verwendung beispielsweise bei der Zuweisung desselben Unterscheidungszeichens an eine kreisfreie Stadt und an den umliegenden Landkreis (Beispiele: "KS", "FÜ", "HN", "MZ", "PS"), bei denen sich die Zuordnung zu Stadt oder Land aus der Gruppe ergibt. Aber auch bei der Neuzuteilung von Unterscheidungszeichen sind sie relevant. In den alten Bundesländern ist meist einem von zwei Bezirken mit gleichem Kennzeichen zunächst nur Gruppe c zugeordnet worden. Um auch kürzere Kennzeichen zu ermöglichen, bekam dieser Bezirk üblicherweise alle diejenigen Kennzeichen der Gruppen a und b zugeordnet, die die ursprünglich nicht vergebenen Buchstaben "B", "F", "G", "I", "O" und "Q" enthalten.

Nicht alle Gruppen werden von allen Zulassungsbezirken benutzt. Viele, vor allem kleinere Bezirke, benutzen regulär nur die Gruppen a bis c und erlauben Kennzeichen der Gruppe d und eventuell e als Wunschkennzeichen. In Bezirken mit dreistelligem Unterscheidungszeichen ist die Gruppe e nicht möglich. Auch in Fällen, wo früher zwei Zulassungsstellen dasselbe Unterscheidungszeichen (mit der o. g. Differenzierung) vergaben und heute nur noch eine dies benutzt, werden die dadurch frei gewordenen Kennzeichen-Gruppen oft nicht verwendet. So werden beispielsweise bei "LD" (Stadt Landau in der Pfalz) nur die Gruppen a, d und e sowie teilweise c genutzt.

Die Zeichenkombination der Erkennungsnummer sowie die Kombination aus Unterscheidungszeichen und Erkennungsnummer dürfen nicht gegen die guten Sitten verstoßen.

Nach dem Unterscheidungszeichen befindet sich auf dem hinteren Kennzeichen eine runde Plakette, die die Frist zur Anmeldung für die nächste Hauptuntersuchung zeigt (umgangssprachlich "TÜV-Plakette"). In der Regel sind die Prüfplaketten Aufkleber, die beim Abziehen zerstört werden, was Verfälschungen (z. B. durch einfaches Verdrehen oder durch die Übertragung auf fremde Kennzeichenschilder) erschweren soll; einzelne Zulassungsstellen verwenden (wie auch für die Dienstsiegel) bis in die heutige Zeit Feststoffplaketten. Heutzutage sind die Plaketten – dies betrifft auch das Steuersiegel – in der Regel als Folienaufkleber ausgeführt. In manchen Zulassungsstellen werden auch noch die früher gebräuchlichen Feststoffplaketten verwendet, die in einen – auf dem Kennzeichen festgenieteten – Aluhalter geclipst werden.

Von 1985 bis 2009 wurden sechseckige Plaketten für die "Abgasuntersuchung" (AU) – anfangs als "Abgassonderuntersuchung" (ASU) bezeichnet – ausgegeben. Die Prüfplakette für die Abgasuntersuchung wurde stets auf dem vorderen Kennzeichen angebracht. Sie folgte dem Farbschema der Prüfplaketten für die Hauptuntersuchung und wurde wie diese in einigen Zulassungsbezirken auch als harte Kunststoffplakette ausgegeben.

Da Dieselfahrzeuge bis Ende 1993 von der Abgasuntersuchung ausgenommen waren, erhielten sie bis dahin keine Prüfplaketten. Somit gab das vordere Kennzeichen auch Auskunft über die Kraftstoffart eines Fahrzeugs.

Seit 1. Januar 2010 ist die Abgasuntersuchung ein Teil der Hauptuntersuchung. Damit entfiel von diesem Zeitpunkt an die Plakette auf dem vorderen Kennzeichen. Abgelaufene Plaketten wurden üblicherweise bei der nächsten Hauptuntersuchung entfernt und bei Neuzulassungen, Umschreibungen etc. keine AU-Plaketten mehr verklebt, so dass diese bis Ende 2012 aus dem deutschen Straßenbild verschwanden.

Prüfplaketten für die Hauptuntersuchung werden in Deutschland seit 1960 ausgegeben. Bevor man die Plaketten einführte, wurden die Fahrzeughalter bei Erreichen des Hauptuntersuchungstermins von den Zulassungsstellen angeschrieben. Um den Verwaltungsaufwand zu reduzieren, führte man Prüfplaketten ein.

Pkw müssen alle zwei Jahre zur Hauptuntersuchung vorgeführt werden, jedoch erstmals drei Jahre nach der Erstzulassung, Nutzfahrzeuge bis 3,5 Tonnen zulässigem Gesamtgewicht und Motorräder alle zwei Jahre, schwere Nutzfahrzeuge und solche zur Personenbeförderung (insbesondere Busse und Taxis) jährlich. Für Nutzfahrzeuge bestehen darüber hinaus weitere Prüfpflichten, etwa besondere Bremsuntersuchungen.

Das Erscheinungsbild ist seit der Einführung 1960 annähernd gleich geblieben. 1974 wurde das Farbschema von vier auf sechs Farben erweitert und folgt seit der 1974er Plakette dem bis heute gültigen Rhythmus, der sich alle sechs Jahre wiederholt. Die Jahre 1977 (Gelb statt Orange) und 1979 (Orange statt Gelb), waren dabei allerdings Ausnahmen. Seit 1975 haben die Plaketten im Bereich des Monats Dezember zur besseren Ablesbarkeit schwarze Segmente.

Die unterschiedliche Farbgebung sorgt dafür, dass sich abgelaufene Plaketten meist aus einigen Metern Entfernung erkennen lassen, etwa durch dem Fahrzeug folgende Polizeistreifen. Anhand der schwarzen Segmente kann der Monat der fälligen Untersuchung wie auf einer Uhr abgelesen werden. Ist beispielsweise die HU im Monat August fällig, steht die "8" oben und das schwarze Segment erscheint auf "8 Uhr". Diese Regel gilt allerdings erst seit 1983. Bis 1982 waren die Ziffern auf der Prüfplakette in aufsteigender Folge im Uhrzeigersinn aufgedruckt, das heißt, bei den Plaketten der Jahre 1975 bis 1982 erschienen die schwarzen Balken noch in seitenverkehrter Position (zum Beispiel bei Fälligkeit im August auf "4 Uhr"), bei Fälligkeit im Juni und Dezember blieb die Position der schwarzen Balken demnach unverändert bei "6 Uhr" bzw. bei "12 Uhr".

Das für die HU-Plaketten verwendete Farbschema galt auch für die Prüfplaketten der Abgasuntersuchung.

Zwischen Unterscheidungszeichen und Erkennungsnummer befindet sich eine Plakette der Zulassungsbehörde mit dem Dienstsiegel (amtlich: "Stempelplakette") des jeweiligen Stadt- bzw. Landkreises, in dem das Fahrzeug zugelassen wurde. Etwa gleichzeitig mit der Einführung der Euro-Kennzeichen trat an die Stelle der ursprünglichen grauen oder weißen Stempelplaketten eine größere mehrfarbige Plakette, die den Namen und das Wappen des Bundeslandes, in dem das Fahrzeug zugelassen ist, sowie den Namen der Zulassungsstelle enthält. In einer Übergangsphase wurde auf viele Euro-Kennzeichen allerdings auch noch die alte Version und in den letzten Jahren der DIN-Schilder auf viele DIN-Kennzeichen die neue Version der Stempelplakette geklebt.

Bei den alten DIN-Kennzeichen findet man zwischen den Prüf- und Stempelplaketten einen Bindestrich, der das Unterscheidungszeichen und die Erkennungsnummer voneinander trennt. Die ersten Euro-Kennzeichen in Berlin, Brandenburg, Bayern (seltener) und Sachsen trugen ebenfalls noch einen Bindestrich. Da bei Verwendung der neuen, größeren Stempelplaketten der Platz aber nicht mehr ausreicht, wird der Bindestrich bei den Euro-Kennzeichen seither nicht mehr verwendet.

Je nach Landkreis oder Stadt wurden Siegel in unterschiedlicher Anfertigung verwendet: meist flache Klebeplaketten, in vielen Bezirken, vor allem im süddeutschen Raum (Baden-Württemberg, Bayern, Rheinland-Pfalz) sowie in einigen thüringischen und niedersächsischen Zulassungsbezirken (Helmstedt, Hameln-Pyrmont, früher auch Stadt Hannover und Landkreis Celle), wurden Feststoffplaketten aus Kunststoff (umgangssprachlich "Töpfchensiegel") verwendet. In einigen Fällen verwendeten kreisfreie Städte und Landkreise mit denselben Unterscheidungszeichen (UL, FÜ, HD, LU) verschiedene Materialien. Manche Bezirke ließen dem Fahrzeughalter auch die Wahl.

Zu Beginn des Jahres 2015 wurden neue Stempelplaketten eingeführt. Diese enthalten (wie bei den Siegeln der Marke SicoTra bereits vorher) links oben das Dienstsiegel der Zulassungsbehörde und, neu, eine achtstellige Druckstücknummer, rechts neben dem Landeswappen als 2D-DataMatrix-Code sowie links neben dem Wappen (bei den Plaketten der Marken SicoTra, HöKo und Juvikett) oder über dem 2D-Code (bei SecuRasta Light/Perfect, SicoTra (anfangs) und HöKo (anfangs)) als Klartext dargestellt. Diese Siegel weisen, angepasst an den zusätzlichen Platzbedarf von Code und Nummer, ein etwas kleineres farbiges Landeswappen und ein neues holografisches Design auf. Die ersten „Testplaketten“ der Marken SicoTra und SecuRasta für den Feldversuch in Ingolstadt wurden jedoch mit dem alten Hologrammdesign bzw. einem Übergangsdesign versehen. Ebenfalls besaßen die Testplaketten der Marke "SecuRasta Perfect" noch keine Prüfziffer am Ende der Druckstücknummer. Wenn man das Dienstsiegel vom Kennzeichen abzieht, erscheint darunter ein dreistelliger Sicherheitscode, der ebenfalls zusätzlich als DataMatrix dargestellt ist. Mit diesen Dienstsiegeln ist bei einer Zulassung ab 2015 eine Online-Außerbetriebsetzung möglich. Feststoffplaketten und Dienstsiegel werden seither für Zivil- und Behördenkennzeichen nicht mehr vergeben. Die internetbasierte Fahrzeugzulassung über die Anwendung i-Kfz des Kraftfahrt-Bundesamtes ist derzeit nur für die "Außerbetriebsetzung" möglich. Voraussetzung hierfür sind der neue Personalausweis mit Identifikationsfunktion und ein Kartenlesegerät. Es müssen die Sicherheitscodes unter den Dienstsiegeln der Kennzeichenschilder und unter dem Sicherheitssiegel der Zulassungsbescheinigung Teil 1 eingegeben werden, der Personalausweis eingelesen werden und die Gebühren online mittels E-Paymentfunktion bezahlt werden. Der Bescheid der Zulassungsstelle über die tatsächlich durchgeführte Außerbetriebsetzung erfolgt postalisch oder per De-Mail. Als nächster Schritt ist die Einführung der „Wiederzulassung eines Fahrzeug auf denselben Halter“ vorgesehen.

Hersteller

Bei den Siegeln im Durchmesser von 45 mm gibt es zwölf verschiedene Versionen von Klebeplaketten der Marken "SecuRasta", "SicoTra", "SecuPrint", "HöKo", "Coloco", "ProSecure", "Schreiner" und "Juvikett".

Die ersten Exemplare nach der Einführung der Eurokennzeichen wurden nahezu alle von dem Münchner Unternehmen "SecuRasta" hergestellt. Knapp zehn Jahre später kam die Firma "Trautwein" aus Herne mit dem silbrigen reflektierenden Siegel "SicoTra" auf den Markt, das zusätzlich gegen das Licht gedreht nochmals das Dienstsiegel des jeweiligen Zulassungsbezirkes oben links erscheinen lässt sowie den Namen "SicoTra" zum Vorschein bringt. SecuRasta ging daraufhin mit "SecuRasta Light" an den Start, das auf den ersten Blick ebenfalls die gleiche Silberoptik besitzt; seit ca. 2007 gibt es als Drittes auch "SecuRasta Perfect".

Einige Zeit später fing die Firma „HöKo“ an, ebenfalls Klebeplaketten herzustellen.
Mit der Einführung der neuen Zulassungsplaketten 2015 gibt es diese ebenfalls von der Marke Juvikett, deren Siegel einen dunkelgrauen Untergrund besitzen.

Die Ausführungen aller Kfz-Kennzeichen in Deutschland (Formate, Schrift, Farben und seit etwa Mitte der 1980er Jahre auch Reflexion) sind in der Fahrzeug-Zulassungsverordnung geregelt und werden durch die DIN 74069 vereinheitlicht. Die Herstellungsverfahren und die Konformität mit diesen Regeln werden durch die DIN-CERTCO überwacht.

 der Fahrzeug-Zulassungsverordnung gibt die folgenden Maße der Kennzeichenschilder vor:
Die Kraftradkennzeichen wurden mit der Änderung der Fahrzeug-Zulassungsverordnung vom 8. April 2011 neu eingeführt, vorher waren für Motorräder die breiteren zweizeiligen Kennzeichen zu verwenden. Verkleinerte zweizeilige Kennzeichen sind nur für Leichtkrafträder sowie für Zugmaschinen mit einer bauartbedingten Höchstgeschwindigkeit von nicht mehr als 40 km/h und Anhänger mit einer bauartbedingten Höchstgeschwindigkeit von nicht mehr als 40 km/h, wenn diese mit einem Geschwindigkeitsschild für die betreffende Geschwindigkeit gekennzeichnet sind, zuzuteilen.

Als Schriftart ist in der Fahrzeug-Zulassungsverordnung die fälschungserschwerende FE-Schrift der Bundesanstalt für Straßenwesen vorgegeben, die in den Varianten "Mittelschrift" und "Engschrift" jeweils eine Schrifthöhe von 75 mm sowie bei der "verkleinerten Mittelschrift" eine Schrifthöhe von 49 mm (nur für verkleinerte zweizeilige Kennzeichen und Kraftradkennzeichen) verwendet. Die FE-Schrift ist eine nichtproportionale Schriftart, d. h. alle Zeichen sind gleich breit. Für normal große Nummernschilder kann in der Regel bei bis zu sieben Zeichen die "Mittelschrift" verwendet werden. Erst bei acht Zeichen wird für alle Zeichen die "Engschrift" benutzt.

Für Kennzeichen der Bundeswehr sowie für Versicherungskennzeichen ist eine abweichende Schriftart vorgegeben.

Für die bis 2000 ausgegebenen DIN-Kennzeichen mit "Mittelschrift" nach DIN 1451 galt: Reichte der Platz für die maximal acht Zeichen nicht aus, so konnte die Prägestelle schlankere Zeichen "(Engschrift)" verwenden. Es wurde meist eine gemischte Schreibweise benutzt, d. h. der Zulassungsbezirk in normaler Breite, die Erkennungsnummer in "Engschrift" und die Ziffernfolge wieder in normaler Breite.

Die Unterscheidungszeichen und Erkennungsnummern sind mit schwarzer Beschriftung auf weißem, schwarz gerandetem Grund auf ein Kennzeichenschild aufzubringen (jedoch Kennzeichen für Probe-, Überführungs- und Werkstattfahrten: rot; steuerbefreite Fahrzeuge: grün), welche in Leserichtung waagerecht, gut erkennbar, sauber und nicht umgedreht an der Fahrzeugaußenseite angebracht sein müssen. Es sind Mindest- und Höchstgrenzen hinsichtlich der Anbringungshöhe zu beachten; auch dürfen Kennzeichenschilder nur einen gewissen Neigungswinkel (max. 30°) aufweisen. Sie dürfen nicht überdeckt (transparenter Plastikschutz) oder verdeckt (Anhängerkupplung, Reserverad) sein. Sie müssen fest mit dem Fahrzeug verbunden sein, außer die Kennzeichen für Probe-, Überführungs- und Werkstattfahrten. Rechtlich stellt das amtliche Kennzeichen eine "zusammengesetzte Urkunde" dar. Manipulationen sind u. a. als Urkundenfälschung und Kennzeichenmissbrauch strafbar.

Bei Anhängern, die kein eigenes Kennzeichen führen müssen (z. B. Anhänger landwirtschaftlicher Fahrzeuge), muss der Anhänger mit einem Kennzeichen versehen sein, das der Halter des Zugfahrzeugs für eines seiner Zugfahrzeuge verwenden darf. Wird das hintere Kennzeichen des Kfz durch einen Ladungsträger oder mitgeführte Ladung teilweise oder vollständig verdeckt (z. B. Fahrradträger auf der Anhängerkupplung), so muss am Fahrzeug oder am Ladungsträger das Kennzeichen wiederholt werden. Eine Abstempelung ist in beiden Fällen nicht erforderlich ( Abs. 8 und 9 FZV).

Kennzeichenschilder müssen gemäß Abs. 2 Satz 2 FZV reflektierend sein und dem Normblatt DIN 74069, Ausgabe Juli 1996, entsprechen sowie auf der Vorderseite das DIN-Prüf- und Überwachungszeichen mit der zugehörigen Registernummer tragen. Die Mehrheit der deutschen Kfz-Kennzeichenrohlinge wird nach diesen Richtlinien aus Aluminium gefertigt. Zur Herstellung wird heute üblicherweise das Heißprägeverfahren angewendet. Dieses Verfahren wurde 1990 entwickelt und löste die bisherige Verwendung von lösungsmittelhaltigen Lacken ab.

Eine technische Innovation sind selbstleuchtende Kennzeichenschilder aus Kunststoff, die seit November 2006 in Deutschland für den allgemeinen Straßenverkehr zugelassen sind. Diese ähneln den gewöhnlichen Metallschildern, werden ebenfalls erhaben geprägt und besitzen eine Reflexionsschicht. Die Besonderheit ist, dass diese lichtdurchlässig sind und von hinten durch LED-Elemente weiß beleuchtet werden. So ergibt sich eine gleichmäßige und gut lesbare Ausleuchtung, die zusätzliche Sicherheit geben soll.

Ende 2006 wurden auch Kennzeichen aus Acryl-Kunststoff als Alternative zu den Metallschildern angeboten. Diese ähneln dem Aussehen nach britischen Kennzeichen. Diese Kennzeichen sind nicht mehr erhältlich.

Seit November 2013 sind unter dem Markennamen 3D-Kennzeichen zulassungsfähige Kennzeichen aus Kunststoff auf dem deutschen Markt, bei denen Kunststofflettern mit einem Steck-Prägeverfahren auf einer Polypropylen-Grundplatte befestigt werden. Als Vorteile seiner Entwicklung gegenüber Aluminiumschildern gibt der Hersteller die Flexibilität und Schlagzähigkeit der Materialien, ein geringeres Gewicht, eine günstigere CO₂-Bilanz sowie weniger Verletzungsgefahr an. Da die Lettern im Material durchgefärbt sind, sind diese Schilder außerdem unempfindlich gegen Abrieb bei der Reinigung. Beulen und Verformungen, wie es beim herkömmlichen Aluminiumschild der Fall ist, stehen bei den Kunststoffkennzeichen in 3D-Optik nicht zur Debatte.

Bis zum 28. Februar 2007 zugelassene Behördenfahrzeuge tragen das Kürzel des jeweiligen Zulassungsbezirks, in dem die Behörde ihren Dienststellensitz hat, gefolgt von einer Ziffernfolge. Die Ziffernfolgen geben in der Regel Aufschluss über die Behörde, für die das Kennzeichen zugeteilt wurde:

Seit dem 1. März 2007 werden diese Behördenkennzeichen aufgrund der neuen Fahrzeug-Zulassungsverordnung (FZV) – bis auf die von den konsularischen Vertretungen verwendeten Nummernkreise – nicht mehr zugeteilt. Viele Kreise und Städte eröffnen nun neue Vergabegruppen bzw. sperren ganze Buchstabenfolgen für den Behördenfuhrpark. Einige Städte behalten sich weiterhin Kombinationen für spezielle Fahrzeuge vor, wie z. B. "TX" für Taxis oder S bzw. SW für städtische Fahrzeuge (Stadtwerke). Beispielsweise erhalten die Busse der Berliner Verkehrsbetriebe immer die Kombination "B V XXXX". In Baden-Württemberg tragen die Fahrzeuge der Katastrophenschutzeinheiten meist das Kürzel BS oder KS (z. B. Stadt Freiburg) für Bevölkerungs- bzw. Katastrophenschutz vor der Ziffernfolge 8XXX.

Kraftfahrzeuge von Landesregierungen und -behörden haben nach der Fahrzeug-Zulassungsverordnung eigene Unterscheidungszeichen. Zulassungsbehörde ist diejenige der jeweiligen Landeshauptstadt.
So haben beispielsweise Fahrzeuge des Landes Thüringen Kennzeichen der Form "THL 4-9999".

Für Bundeslandkennzeichen gibt es eine Empfehlung für die Benutzung der Ziffer vor dem Trennstrich:

Die Ziffern 2, 8 und 9 sind nicht belegt.

Nordrhein-Westfalen

Für Nordrhein-Westfalen gibt es folgende Regelung: Die dem Unterscheidungszeichen nachfolgende Ziffer ist wie folgt zugeordnet:

Der Mobilitätsbedarf bei den Ministerien wird grundsätzlich über die Fahrbereitschaft der Staatskanzlei "(NRW 3-XXXX)" gedeckt. Bei den Polizeifahrzeugen hat man auf die regionalen Zulassungen verzichtet, weil die geleasten Fahrzeuge in Stadtgebieten weniger Kilometerleistung erreichen als in ländlichen Gebieten. Um extreme Abweichungen bei den Kilometerständen der Fahrzeuge zu verhindern, können die Fahrzeuge mit NRW-Nummer laufend ausgetauscht werden.

Die Vergabe der Polizeikennzeichen ist nach dem Wegfall der Behördenkennzeichen in den Bundesländern derzeit unterschiedlich geregelt.

In Nordrhein-Westfalen, Brandenburg, Rheinland-Pfalz, Baden-Württemberg und dem Saarland werden für Polizeifahrzeuge derzeit die Unterscheidungszeichen der jeweiligen Landesverwaltung nach den Mustern "NRW 4-XXXX", "NRW 5-XXXX" und "NRW 6-XXXX" sowie "NRW 5-XXX" und "NRW 6-XXX" (Motorräder), "BBL 4-XXXX", "RPL 4-XXXX", "SAL 4-XXXX" und "BWL 4-XXXX" vergeben, wobei die führende 4 (in Nordrhein-Westfalen auch 5 und 6) dem Innenministerium zugeordnet ist. In Schleswig-Holstein, Mecklenburg-Vorpommern und Sachsen-Anhalt bevorzugt man Zulassungen nach den Mustern "SH 3XXXX", "MVL 3XXXX" und "LSA 4XXXX".

In Baden-Württemberg war ursprünglich geplant, die Polizeifahrzeuge weiterhin am Sitz des Regierungspräsidiums, dem sie zugeordnet sind (Freiburg im Breisgau = FR, Karlsruhe = KA, Stuttgart = S und Tübingen = TÜ), bzw. bei Fahrzeugen der Bereitschaftspolizei, am Sitz des Bereitschaftspolizeipräsidiums (Göppingen = GP), zuzulassen. Den Unterscheidungskennzeichen sollte eine bis zu zweistellige Buchstaben- und vierstellige Ziffernkombination folgen; Fahrzeuge des Polizeipräsidiums Stuttgart sollten die Kennzeichen "S PP XXXX" bekommen. Es wurden bereits einige Fahrzeuge mit diesem Schema zugelassen. Seit August 2008 bekommen die Fahrzeuge Kennzeichen nach dem Schema "BWL 4-XXXX", wobei die erste Ziffer auch hier für das Innenministerium als oberste Dienstbehörde steht.

In einigen Bundesländern wurden die Systeme den normalen Kennzeichen angepasst:

Die bayerischen Polizeifahrzeuge der Polizeipräsidien Oberbayern-Nord mit Sitz in Ingolstadt, Mittelfranken in Nürnberg, Unterfranken in Würzburg, Schwaben Süd/West in Kempten (Allgäu) und Oberpfalz in Regensburg nutzen die Kennung "IN PP 9XXX", "N PP XXX", "WÜ PP XXXX", "KE PP XXX", "R PP XXX" und "R PR XXX". Diejenigen in Augsburg die Kennung "A PS XXX", wobei "PS" für das Polizeipräsidium Schwaben Nord steht. Dem Polizeipräsidium Oberfranken in Bayreuth reicht ein Buchstabe "BT P 8XXX", genauso wie dem Polizeipräsidium Niederbayern in Straubing "SR P 1XXX" und dem Polizeipräsidium Oberbayern Süd in Rosenheim "RO P XXX". Von Seiten des Polizeipräsidiums München wird ein Teil des Nummernkreises aus dem Bereich "M PM XXXX", welcher der Zulassungsstelle der Landeshauptstadt München zugeordnet ist, verwendet. Eine Umrüstung wird nur bei neu zugelassenen Fahrzeugen durchgeführt, da die Umstellung kostenneutral erfolgen soll. Die Bereitschaftspolizei mit Sitz in Bamberg verwendet "BA P XXXX" als Kennzeichen.

In den Stadtstaaten Berlin, Hamburg und Bremen werden die numerischen Kennzeichen nach dem bisherigen Muster beibehalten.

In Hessen tragen neu zugelassene Polizeifahrzeuge Kennzeichen mit der Kombination "WI HP XXXX" (immer mit vier Ziffern, bei Motorrädern auch mit drei Ziffern). Dabei ersetzen die Zeichen "HP" die bisherige Ziffer 3. Die nächstfolgende Ziffer weist auf das Polizeipräsidium (PP) oder die zentralen Polizeibehörden hin: 1 = PP Südhessen (Darmstadt), 2 = PP Osthessen (Fulda), 3 = PP Südosthessen (Offenbach am Main), 4 = PP Nordhessen (Kassel), 5 = PP Frankfurt am Main, 7 = PP Westhessen (Wiesbaden), 8 = PP Mittelhessen (Gießen) sowie 9 = zentrale Polizeibehörden (Wiesbaden).

In Niedersachsen tragen die Polizeifahrzeuge die Kennzeichen der örtlichen Inspektion bzw. Direktion, z. B. "CE PI 950" oder "GÖ PD 599" ("PI" für Polizeiinspektion, "PD" für Polizeidirektion). Fahrzeuge der Zentralen Polizeidirektion Hannover, der auch die Bereitschaftspolizei mit weiteren Abteilungen in Braunschweig und Oldenburg angehört, tragen die Kürzel "H ZD XXXX" ("ZD" für Zentrale Polizeidirektion) oder "PA" für die Polizeiakademien.

In Sachsen erhalten seit dem 1. März 2007 grundsätzlich alle Polizeifahrzeuge, auch zivile (mit Ausnahme von Tarnkennzeichen), die Kennung "DD Q XXXX" (mit drei oder vier Ziffern). Die Bereitschaftspolizei erhält Kennzeichen der Zifferngruppe "DD Q 7XXX".

In Thüringen nutzte man für die Polizeifahrzeuge von 2007 bis 2010 die Kennung "EF TP XXXX" (immer mit vier Ziffern). Dabei ersetzten die Zeichen TP die bisherige Ziffer 3. Die nächstfolgende Ziffer wies auf die Polizeidirektion (PD) oder die Bereitschaftspolizei in Thüringen hin: 1 = PD Erfurt, 2 = PD Gera, 3 = PD Gotha, 4 = PD Jena, 5 = PD Nordhausen, 6 = PD Saalfeld, 7 = PD Suhl sowie 9 = Bereitschaftspolizei. Seit 2011 werden in Thüringen die Polizeikennzeichen "EF LP XXXX" zentral vergeben. Die Zuordnung zu einer bestimmten Polizeidirektion ist nicht mehr erkennbar.


Die Kennzeichen aller anderen Dienstwagen des Bundestags, des Bundesrats, der Bundesregierung, des Bundespräsidialamts und des Bundesverfassungsgerichts beginnen mit "BD". Sie werden wie folgt zugeteilt:

Die nicht vergebenen Kennzeichenkombinationen "BD 2–…", "BD 8–…" usw. dienen als Reserve.

Kennzeichen der Zollbehörden

Die Bundeszollverwaltung stellte im Jahr 2007 mit Auslieferung neuer Fahrzeuge vom Behördenkennzeichen (z. B. "HB 123") auf zivile Kennzeichen um (z. B. "OS Z 9XXX").
Seit dem 1. April 2009 werden von der Bundesfinanzverwaltung (Zoll) wieder Kennzeichen mit dem Unterscheidungszeichen "BD", zuzüglich der Unterscheidungsnummer 16 und einer fortlaufenden Vergabenummer ausgegeben (z. B. "BD 16–315"). Dafür ist bundesweit nun die Kfz-Zulassungsstelle der Bundesfinanzdirektion Südwest – Referat RF 5 – zuständig. Diese ist beim Beschaffungsamt der Bundesfinanzverwaltung in Offenbach am Main angesiedelt. Auf der Zulassungsplakette steht „Bundesrepublik Deutschland • KfzSt der Bundesfinanzverwaltung“, wobei KfzSt für Kraftfahrzeugstelle steht.

Die Deutsche Bundesbahn (DB) und Deutsche Bundespost (BP) hatten bis zu ihrer Privatisierung in den 1990er Jahren eigene Unterscheidungszeichen. Bei der Bahn codierten die ersten beiden – nach "DB" folgenden – Ziffern den Fahrzeugtyp. Bei den Kraftfahrzeugkennzeichen der Deutschen Bundespost wurde zusätzlich nach Postdienst ("BP 10" bis "BP 59") sowie Fernmeldedienst ("BP 60" bis "BP 99") unterschieden.

Die Wasserstraßen- und Schifffahrtsverwaltung des Bundes führt das Unterscheidungszeichen "BW". Die Zulassungsplakette entspricht der des jeweiligen Kreises, in dem das Fahrzeug zuerst angemeldet wurde; die erste Ziffer steht für eine Direktion.

Dienstwagen der Bundespolizei führen seit 30. April 2006 die Kennung "BP". Ein Teil des Fuhrparks ist noch mit dem früheren Unterscheidungszeichen "BG" für die ehemalige Bezeichnung Bundesgrenzschutz zugelassen, das seit der Umbenennung ausläuft.

Die Kfz-Kennzeichen der Bundespolizei und des früheren BGS werden den ersten beiden Ziffern abhängig vom Fahrzeugtyp vergeben:

Die Kennung "BP" wurde bis Ende 1994 an die Deutsche Bundespost ausgegeben.

Der Bundeswehr ist der Buchstabe "Y" für ihre Kfz-Kennzeichen zugeordnet. "Y" wurde gewählt, da bei Gründung der Bundeswehr im Jahre 1955 alle in Frage kommenden Kombinationen wie "BW" bereits vergeben waren und für die voraussichtlich große Anzahl von Militärfahrzeugen das Unterscheidungszeichen (der Zulassungsbezirk) nur aus einem Buchstaben bestehen durfte, zumal das Kennzeichen auch noch die deutsche Flagge enthält. Weil keine größere Stadt in Deutschland einen mit "Y" beginnenden Namen hat, wurde dieser Buchstabe von Brigadegeneral Kurt Vogel für die Streitkräfte aus den beiden verbliebenen Unterscheidungsmerkmalen "X" und "Y" ausgewählt. ("X" wird mittlerweile für NATO-Fahrzeuge verwendet.)

Weiterhin befinden sich die deutsche Flagge, eine bis zu sechsstellige Nummer und der Stempel der Zentralen Militärkraftfahrtstelle auf dem Kennzeichen, das aus militärischem (taktischem) Grund nicht reflektierend ist. Bei den ranghöchsten Bediensteten der Streitkräfte sind auch dreistellige Kennzeichen möglich, dies gilt ebenso für Kennzeichen an handelsüblichen Fahrzeugen der Bundeswehr in den Vereinigten Staaten. Die Nummern werden willkürlich vergeben, das heißt, sie sind an keine Systematik wie Fahrzeugtyp oder Truppenteil gebunden. Dadurch bleiben aus taktischen Gründen der Standort und der Truppenteil des Fahrzeugs unerkannt.

Des Weiteren nutzt die Bundeswehr bei Fahrzeugen des BwFuhrparkService ein normales Kennzeichen, das mit "SU" für den Rhein-Sieg-Kreis (Siegburg) beginnt, danach die Buchstaben "BW" und anschließend eine beliebige Zahl trägt, z. B. "SU BW 123". Somit sind solche Fahrzeuge, die der Bundeswehr angehören, nicht mehr als solche zu erkennen, es sei denn, man kennt die Buchstaben-Kombination des Kennzeichens (falls das Fahrzeug nicht die Aufschrift des BW-Fuhrparkservices trägt).

Weiterhin gibt es einige Kennzeichen für Erprobungsfahrten, die in roter Farbe mit rotem Rand gedruckt werden. Die Ziffernfolge beginnt mit "06". Geleaste oder geliehene Fahrzeuge nutzen ebenfalls diese Kennzeichen, jedoch beginnt hier die Ziffernfolge mit "01". Die Zulassung aller Fahrzeuge der Bundeswehr (mit Ausnahme der Fahrzeuge des Fuhrpark-Services) erfolgt durch die Zentrale Militärkraftfahrtstelle (ZMK) in Mönchengladbach-Rheindahlen. Die Fahrzeuge der Bundeswehr unterliegen einer internen Überwachung in Anlehnung an die straßenverkehrsrechtlichen Vorschriften, z. B. der Hauptuntersuchung und der Sicherheitsprüfung, und werden in einer technischen Durchsicht gemäß speziellen technischen Dienstvorschriften (TDv) durch eigenes Personal geprüft. Fahrzeuge zivilen Typs, die bei der Bundeswehr als „handelsüblich“ (HÜ) bezeichnet werden (z. B. VW Golf oder Opel Astra), können zur Hauptuntersuchung wie jedes zivile Fahrzeug bei einer amtlich anerkannten Prüforganisation (z. B. TÜV, DEKRA) vorgeführt werden.

Die Kfz-Kennzeichen der Bundeswehr werden unverändert in DIN-Schrift und nicht in der neuen FE-Schrift ausgegeben.

Die Dienstfahrzeuge des Technischen Hilfswerks tragen das Unterscheidungszeichen mit den Buchstaben "THW". Vor der Einführung des neuen Euro-Kennzeichens gliederten sich die Fahrzeuge des THW in die Gruppe der Behördenkennzeichen des Katastrophenschutzes ein. Beibehalten wurde zunächst die Ziffernstruktur der Behördenkennzeichen (8000–8999; 80000–89999, der für den Katastrophenschutz verwendete Nummernkreis). Dabei werden vierstellige Zahlenkombinationen vor allem an die hauptamtlichen Organisationsstellen (Geschäftsstellen, Landesverbände, Bundesschule und Leitung) und fünfstellige an die Ortsverbände vergeben. Der Kennzeichenbereich wurde mittlerweile um Blöcke mit führender "9" erweitert. Die Kennzeichen werden von der Kfz-Zulassungsstelle beim Beschaffungsamt des Bundesministeriums des Innern in Bonn vergeben. Zusätzlich existieren auch beim THW rote Überführungskennzeichen, deren Ziffernfolge mit "06" beginnt.

Seit dem 1. März 1997 werden in Deutschland Saisonkennzeichen vergeben. Auf diesen werden hinter der Erkennungsnummer übereinander der erste und der letzte Monat des Gültigkeitszeitraums durch einen waagerechten Strich getrennt angegeben. Der Zulassungszeitraum ist zwischen zwei und elf Monaten innerhalb eines beliebigen Zwölf-Monatszeitraums frei wählbar, allerdings müssen der Anfang und das Ende des Zeitraums mit vollen Kalendermonaten zusammenfallen. Der große Vorteil des Saisonkennzeichens ist, dass die Anmeldung zu Saisonbeginn und Abmeldung zum Saisonende entfällt; als auch Kraftfahrzeugsteuer nach Abs. 1 Nr. 5 KraftStG und Versicherungsprämien nur anteilig anfallen. Man findet diese Kennzeichen vornehmlich an Fahrzeugen, die nicht das ganze Jahr genutzt werden, beispielsweise an Motorrädern, Cabriolets und Wohnmobilen, aber auch auf Fahrzeugen des Winterdienstes.

Beim Wechsel von ganzjähriger Zulassung zu einer saisonalen Zulassung muss trotz bestehendem ganzjährigem Versicherungsschutz dem Straßenverkehrsamt eine Versicherungsbestätigungsnummer für den zukünftig angestrebten Zeitraum genannt werden. Ohne diese ist der Wechsel nicht möglich. Die Versicherungsbestätigungsnummern sind an die Stelle der früher erforderlichen Deckungskarten getreten. Wichtig ist, dass das Fahrzeug auf öffentlichen Straßen nur während des angegebenen Betriebszeitraums in Betrieb genommen oder auf öffentlichem Verkehrsgrund abgestellt werden darf.

Saisonkennzeichen können maximal sieben Zeichen enthalten, da an der achten Stelle der Gültigkeitszeitraum angegeben wird.

Es gibt spezielle Kennzeichen für Oldtimer als Saisonkennzeichen, die sogenannten H-Saisonkennzeichen.

Seit dem 1. Juli 2012 besteht die Möglichkeit, zwei Fahrzeuge mit nur einem Kennzeichen zuzulassen. Voraussetzung ist, dass die Fahrzeuge in die gleiche Fahrzeugklasse fallen und die Fahrzeughalter die Kennzeichenschilder mit gleichen Abmessungen an den jeweiligen Fahrzeugen verwenden können. Das Wechselkennzeichen darf allerdings nicht gleichzeitig an beiden Fahrzeugen geführt werden. Die Bundesregierung geht von Zulassungskosten von rund 65 Euro aus, wenn ein Halter für zwei Fahrzeuge aus dem vorhandenen Bestand Wechselkennzeichen beantragt. Bereits vor der Einführung wurde in Frage gestellt, ob das neue Wechselkennzeichen tatsächlich die gewünschte Resonanz in der Bevölkerung bringen wird, da die Bundesregierung den Besitzern mehrerer Fahrzeuge bei der Benutzung von Wechselkennzeichen keine Steuerersparnis gewährt und auch die Versicherungswirtschaft keine nennenswerten Vergünstigungen in Aussicht gestellt hatte. Von Juli bis Dezember 2012 wurden dann tatsächlich nur 2115 Wechselkennzeichen von den Zulassungsstellen ausgegeben. Die Bundesregierung ging im Vorfeld von 54.000 Zulassungen pro Jahr aus, so dass die Regelung als Flop gilt.

Das Oldtimer­kennzeichen (auch "H-Kennzeichen" genannt), bei dem der eigentlichen Zulassungsnummer ein "H" nachgestellt wird, ist eine deutsche Kennzeichnung eines historischen Kraftfahrzeugs nach FZV, die nach einer Prüfung auf zeitgenössisch originalen Zustand erteilt wird. Eine weitere Voraussetzung ist, dass das Fahrzeug nachweislich mindestens 30 Jahre alt ist („Fahrzeuge, die vor mindestens 30 Jahren erstmals in Verkehr gekommen sind.“ Nr. 22 FZV).

Das Kennzeichen folgt dem gleichen Schema wie reguläre Nummernschilder für Zivil-, Behörden- oder Diplomatenkennzeichen. Der einzige Unterschied ist ein "H" als abschließendes Zeichen. Eine Einschränkung besteht darin, dass bei einzeiligen Kennzeichen die Gesamtzahl aller Zeichen ohne dieses "H" nicht mehr als sieben betragen darf. Beispiel: "AB DE 123H". Mit dem H-Kennzeichen können – je nach Hubraum des Fahrzeugs – Steuer- und oftmals auch Versicherungsvorteile verbunden sein. Zudem sind mit Oldtimerkennzeichen zugelassene Fahrzeuge von den mit einer fehlenden Feinstaubplakette einhergehenden Einschränkungen ausgenommen. Historische Kennzeichen mit befristetem Saisonzeitraum (sogenannte H-Saisonkennzeichen) dürfen ab dem 1. Oktober 2017 ausgegeben werden.

Durch die jahrzehntelange Vorarbeit durch den DEUVET – Bundesverband für Clubs klassischer Fahrzeuge für das „Kulturgut Auto“ konnte das erste für historische Fahrzeuge ausgegebene H-Kennzeichen am 1. Juli 1997 zugeteilt werden. Die Kriterien zur Vergabe eines H-Kennzeichens werden uneinheitlich angewandt: Oftmals werden Abweichungen vom Originalzustand geduldet, insoweit sie bereits als zeitgenössische Umbauten vor 30 Jahren oder früher anzutreffen waren.

Seit Anfang 2010 werden in Bremen H-Kennzeichen in der bis zum 31. Oktober 2000 verwendeten Schriftnorm (DIN 1451) und ohne Euro-Balken gegen eine zusätzliche Bearbeitungsgebühr von 100 Euro ausgegeben. Zwischen Juli 2010 und Februar 2012 erlaubte das hessische Verkehrsministerium seinen Zulassungsstellen, ebenfalls auf Antrag Schilder mit der vor November 2000 vorgeschriebenen Schrift auszugeben und sich bei den Gebührensätzen am Bremer Modell zu orientieren. Damit wird es den Haltern ermöglicht, ihr Fahrzeug nicht mit – von vielen Oldtimerfreunden als unpassend oder störend empfundenen – Euro-Kennzeichen kennzeichnen zu müssen.

H-Kennzeichen werden nicht erteilt, wenn erkennbar deutlich jüngere Komponenten eingebaut wurden: Manchmal ist schon ein stärkerer Motor ähnlichen Typs, der erst später erhältlich war, ein Negativkriterium. Anfangs wurden sogar Katalysator-Nachrüstungen als zeituntypisches Zubehör gewertet und als Ablehnungsgrund genannt; die einschlägige Rechtsprechung ist hier mittlerweile eindeutig umweltfreundlich. Auch schlecht gepflegten Fahrzeugen wird oftmals der H-Status verweigert. Als allgemeine Orientierung können hier die Zustandsnoten nach DEUVET gelten. Diese klassifizieren den Zustand eines Fahrzeugs mit Schulnoten (z. B. 1 = sehr gut).

Ein Fahrzeug, das für ein H-Kennzeichen angemeldet wird, sollte demnach in einem Zustand sein, der nicht schlechter als "3" (gebrauchter Zustand, kleine Mängel, aber vollständig fahrbereit, keine Durchrostungen) ist.

Zum 1. November 2011 wurden die Kriterien verändert: Bis dahin musste der Zustand der Fahrzeuge mindestens Note 3 sein, um ein H-Kennzeichen erhalten zu können. Die Note 3 erhalten Fahrzeuge mit leichten Mängeln und Alltagsspuren, solange sie gebrauchsfertig und rostfrei sind. Seitdem haben die Prüforganisationen einen größeren Ermessensspielraum: Gemäß § 2 Nr. 22 FZV wird ein "guter Pflege- und Erhaltungszustand" als Abgrenzung zu "normalen alten" Fahrzeugen (Richtlinie für die Begutachtung von Oldtimern nach StVZO vom 6. April 2011) gefordert. Die kurz nach Bekanntwerden der Reform verbreitete Auffassung, mit dieser Formulierung sei eine Verschärfung der Kriterien verbunden, übersieht, dass ein guter Erhaltungszustand nicht mit der Zustandsnote 2 gleichzusetzen ist. Die Beurteilung des erhaltungswürdigen Zustands ist nunmehr unabhängig von den Definitionen des Zustandsnotensystems vorzunehmen.

Da das "H" weder zum Unterscheidungszeichen noch zur Erkennungsnummer gehört, erscheint es nicht in Dokumenten wie dem Fahrzeugbrief oder der Grünen Versicherungskarte – da aber etwaig kontrollierenden Beamten im Ausland die Zusammensetzung der deutschen Kennzeichen nicht immer so detailliert bekannt ist und womöglich die Identität des Fahrzeugs bezweifelt werden könnte, wird das "H" im Fahrzeugschein abgedruckt und kann auf Antrag auch in der Grünen Versicherungskarte angegeben werden.

Historische Fahrzeuge können auch mit einem roten Kennzeichen (siehe unten) mit der Kennziffer "07" betrieben werden.

Nach dem 2015 verabschiedeten Elektromobilitätsgesetz wurden spezielle Kennzeichen für Elektrofahrzeuge, Plug-In-Hybrid- und Brennstoffzellenfahrzeuge eingeführt, um Sonderregeln für elektrisch betriebene Fahrzeuge umsetzen und kontrollieren zu können. Der Bundesverband eMobilität e. V. schlug ein zusätzliches im Kennzeichen (analog zum H-Kennzeichen) als Kennzeichnung vor. Grundsätzlich dürfen Kohlendioxidemissionen von höchstens 50 Gramm je gefahrenen Kilometer ausgestoßen werden, oder die Reichweite unter ausschließlicher Nutzung der elektrischen Antriebsmaschine muss mindestens 40 Kilometer betragen.

Seit 26. September 2015 werden die neuen E-Nummernschilder, die es auch in Kombination mit einem Saisonkennzeichen gibt, von den Zulassungsstellen ausgegeben. Ausländische Fahrzeuge, die auch die Rechte der Kennzeichen für Elektrofahrzeuge in Anspruch nehmen wollen, benötigen statt des "E-Schildes" eine "E-Plakette", die von einer Zulassungsstelle für 11 EUR ausgegeben wird – ausgenommen das Fahrzeug besitzt ein ausländisches E-Schild oder eine ausländische E-Plakette.

Rote Kennzeichen existieren mindestens seit den 1920er Jahren in roter Schrift auf weißem Grund und bestehen seit 1956 aus dem Zulassungskürzel und einer Erkennungsnummer (ohne Erkennungsbuchstaben).

Rote Kennzeichen werden nach der aktuellen Fassung der Fahrzeugzulassungsverordnung vergeben als:

Alte Kurzzeitkennzeichen waren ebenfalls rot und wurden nach demselben Nummernschema beginnend mit "04" ausgegeben. Seit 1998 verwenden sie schwarze Zahlen; seit dem 1. März 2007 beginnen sie mit "03" oder "04".

Rote Kennzeichen mit den Folgenummern "05" und "06" werden nur an Kraftfahrzeughersteller, Kraftfahrzeugteilehersteller, Kraftfahrzeugwerkstätten und Kraftfahrzeughändler (Nummer beginnend mit "06") sowie Technische Prüfstellen und anerkannte Überwachungsorganisationen (Nummer beginnend mit "05") zum Zweck von Prüfungs-, Probe- und Überführungsfahrten ausgegeben. Sie sind nicht an ein Fahrzeug gebunden.

Für jedes Fahrzeug ist eine gesonderte Seite des Fahrzeugscheinheftes zu dessen Beschreibung zu verwenden; die Angaben zum Fahrzeug sind vollständig und in dauerhafter Schrift vor Antritt der ersten Fahrt einzutragen. Das Fahrzeugscheinheft ist bei jeder Fahrt mitzuführen und zuständigen Personen auf Verlangen auszuhändigen. Über jede Prüfungs-, Probe- oder Überführungsfahrt sind fortlaufende Aufzeichnungen zu führen, aus denen das verwendete Kennzeichen, das Datum der Fahrt, deren Beginn und Ende, der Fahrzeugführer mit dessen Anschrift, die Fahrzeugklasse und der Hersteller des Fahrzeugs, die Fahrzeug-Identifizierungsnummer und die Fahrtstrecke ersichtlich sind.

Rote Kennzeichen mit der Folgenummer "07" können auch an Privatleute ausgegeben werden, jedoch ausschließlich für Fahrzeuge, die mindestens 30 Jahre alt sind. Vor dem 1. März 2007 war die rote 07er-Nummer auch für mindestens 20 Jahre alte Youngtimer vorgesehen.

Mit den Kennzeichen dürfen nur Erprobungs- und Bewegungsfahrten, Probefahrten zum Fahrzeugverkauf sowie Fahrten zu Fahrzeugtreffen gemacht werden; für die regelmäßige Teilnahme am Straßenverkehr haben diese Fahrzeuge ein reguläres Kfz-Kennzeichen oder ein Oldtimer-Kennzeichen zu führen. Zum Nachweis ist ein Fahrzeugscheinheft für rote Oldtimerkennzeichen nach dem Muster der FZV vorgesehen. Das Kennzeichen darf nur an den Fahrzeugen verwendet werden, für die es ausgegeben worden ist.

Je nach Zulassungsstelle können pro roter 07er-Nummer bis zu zehn, in anderen Fällen aber auch beliebig viele Fahrzeuge genehmigt werden. Es können auch mehrere Kennzeichen mit gleicher Nummer ausgegeben werden, beispielsweise ein großes längliches für einen Pkw und ein kleines quadratisches für ein Zweirad. Dieses Kennzeichen ist steuerlich begünstigt, und Versicherungen bieten oft günstige Tarife hierfür an. Die zur Genehmigung vorzulegenden Dokumente können je nach Zulassungsstelle variieren.

Das rote 07-Kennzeichen ist nicht nur in der Bundesrepublik gültig. Aufgrund internationaler Abkommen mit verschiedenen Staaten können Fahrzeuge mit solchen Kennzeichen auch im Ausland genutzt werden.

Hiernach gilt das Rote Kennzeichen 07 wie jedes andere deutsche Kennzeichen auch in den Vertragsstaaten unter den folgenden Bedingungen:

Die Nutzung des Roten Kennzeichens 07 ist in folgenden Ländern grundsätzlich zulässig:

Die Zulassung von Oldtimern mit rotem 07er-Kennzeichen ist in den o. g. Ländern nach internationalem Recht gültig. Zwar entsprechen das Rote Kennzeichen bzw. das Kurzzeitkennzeichen internationalen Vorschriften, allerdings kann es vorkommen, dass der rote Fahrzeugschein, der auch bei dem neuen Kurzzeitkennzeichen ausgegeben wird, im Ausland nicht akzeptiert wird, da er nicht den internationalen Straßenverkehrsübereinkommen von 1926, 1949 und 1968 entspricht. Die Verwendung Roter Kennzeichen kann im Ausland vereinzelt zu Problemen führen. Auf deutscher ministerieller Ebene wird eine Anerkennung empfohlen. Es besteht allerdings keinerlei Rechtsanspruch und keine Gewähr für die Beibehaltung dieser Praxis.

Abkommen über die gegenseitige Anerkennung der jeweiligen nationalen Überführungs- und Probekennzeichen und der entsprechenden Fahrzeugpapiere bestehen seit 1979 mit Österreich und seit dem 1. Januar 1994 mit Italien. Eine diesbezügliche Vereinbarung mit Dänemark wurde 1990 gekündigt.

Grüne Kennzeichen sind Kennzeichen mit grüner Schrift auf weißem Grund und ansonsten identisch mit normalen Kennzeichen. Sie werden für steuerbefreite Fahrzeuge ( KraftStG) wie z. B. landwirtschaftliche Fahrzeuge, Fahrzeuge von gemeinnützigen oder Hilfsorganisationen, Schaustellerfahrzeuge und selbstfahrende Arbeitsmaschinen (z. B. Kräne und Betonpumpen) ausgegeben, sowie außerdem für Anhänger mit bestimmtem Einsatzzweck (z. B. für Boote, Segelflugzeuge, Hunde und Pferde). Ausgegeben werden die grünen Kennzeichen von der Zulassungsstelle nur, wenn die Genehmigung zur Steuerbefreiung vom Finanzamt vorliegt. Fahrzeuge mit grünen Kennzeichen zu anderen Zwecken zu verwenden ist ein Vergehen gegen das Steuergesetz.

Bei Zahlung einer erhöhten Kraftfahrzeugsteuer für das Zugfahrzeug (nicht bei Pkw oder Krad) kann ein Lastanhänger steuerfrei gestellt werden; dieser darf jedoch nur von entsprechend hochbesteuerten Fahrzeugen gezogen werden. Anhänger für den Containertransport, die im kombinierten Verkehr verwendet werden, sind steuerbefreit, unabhängig vom steuerlichen Status des Zugfahrzeugs ( KraftStG).

Kurzzeitkennzeichen sind für Fahrzeugüberführungen, Prüfungs- und Probefahrten für ein bestimmtes, nicht anderweitig zugelassenes Fahrzeug vorgesehen. Rechtliche Basis für diese Kennzeichen ist FZV (Probefahrten und Überführungsfahrten mit Kurzzeitkennzeichen). Seit dem 1. April 2015 muss bei der Zuteilung eines Kurzzeitkennzeichen zusätzlich zur bisher schon nachzuweisenden Kraftfahrzeug-Haftpflichtversicherung auch die technischen Daten des nicht zugelassenen Fahrzeugs, für das das Kurzzeitkennzeichen verwendet werden soll, in der neu gestalteten Zulassungsbescheinigung Teil 1 eingetragen werden. Falls es sich um ein verkehrssicheres Fahrzeug, das keinem genehmigten Typ entspricht oder für das keine Einzelgenehmigung erteilt ist, handelt, darf das Fahrzeug mit dem Kennzeichen nur im Rahmen der in der Zulassungsbescheinigung Teil 1 eingetragenen Beschränkung bewegt werden. Ebenso gibt es eine in der Zulassungsbescheinigung Teil 1 einzutragende Beschränkung, falls für das Fahrzeug keine gültige Hauptuntersuchung/Sicherheitsprüfung nachgewiesen werden kann. Genutzt werden dürfen diese Kennzeichen nur mit einem einzigen Fahrzeug, eine wechselnde Verwendung mit mehreren Fahrzeugen ist nicht zulässig. Von den Regelungen hinsichtlich der Umweltplakette sind diese Kennzeichen ausgenommen.

Sie gelten für höchstens fünf Tage, der letzte Tag der Gültigkeit ist in einem gelben Feld am rechten Rand vermerkt, oben der Tag, darunter der Monat und unten das Jahr, jeweils zweistellig. Voraussetzung für die Erteilung ist bei einer natürlichen Person die Vorlage eines gültigen Personalausweises oder eines Reisepasses nebst Meldebestätigung sowie eine gültige Versicherungsbestätigung (eVB-Nummer) für bis zu fünf Tage. Bei vielen Versicherungen besteht die Möglichkeit, sich die Versicherungsprämien der Kurzzeitzulassung auf eine folgende normale Anmeldung anrechnen zu lassen. Zwischen dem 1. November 2012 und dem 1. April 2015 konnten Kurzzeitkennzeichen nur noch bei der Zulassungsstelle des Wohnortes des Halters beantragt werden. Seit dem 1. April 2015 reicht der Nachweis des Standorts des Fahrzeugs gegenüber der Zulassungsstelle aus. Für die Erteilung eines Kurzzeitkennzeichens fällt eine bundeseinheitliche Gebühr von insgesamt 13,10 Euro an. Die Gebühr setzt sich aus 10,20 Euro für die Zuteilung des Kurzzeitkennzeichens + 2,60 Euro für das Kraftfahrtbundesamt + 0,30 Euro für ein Klebesiegel zusammen. (Geb.-Nr. 221.4, Geb.-Nr. 124, Geb.-Nr. 233 der zur Gebührenordnung für Maßnahmen im Straßenverkehr). Die Gebühr kann sich noch um bis zu 0,60 EUR erhöhen, wenn aufgrund der technischen Eintragungen noch bis zu zwei Beiblätter ausgestellt werden.

Das Kennzeichen enthält das Standard-Unterscheidungszeichen des Zulassungsbezirks (keine Alternative) und eine Nummer, die mit "03" (seit 1. März 2007) oder "04" beginnt. Die amtliche Stempelplakette ist blau (und meist aus der alten Version der jeweiligen Zulassungsplakette abgeleitet), und das Kennzeichen hat kein Eurofeld am linken Rand ( FZV, relevant sind Abschnitt 1 sowie 6 und 7).

Das Kurzzeitkennzeichen in seiner heutigen Form löste 1998 das rote 04er-Kennzeichen ab, das sich Privatleute von der Zulassungsstelle für maximal fünf Tage geben lassen konnten und zurückgeben mussten. Nachdem der Missbrauch von Kurzzeitkennzeichen stark angestiegen und eine Zunahme des Handels mit Kurzzeitkennzeichen festzustellen gewesen war, gab es zum 1. April 2015 eine Gesetzesänderung. Seither wird das Kurzkennzeichen erst zugeteilt, wenn das Fahrzeug einem genehmigten Typ entspricht oder eine Einzelgenehmigung erteilt ist und eine Kraftfahrzeug-Haftpflichtversicherung besteht. Durch den Fahrzeugbezug kann das Kurzzeitkennzeichen nicht mehr an einem anderen Fahrzeug verwendet werden.

Die Zuteilung eines Kurzzeitkennzeichens ist ein nationaler Verwaltungsakt, und somit ist die Anbringung eines Kurzzeitkennzeichens an ein Fahrzeug, das sich im Ausland befindet, um dieses z. B. nach Deutschland zu überführen, nicht zulässig (verbotene Fernzulassung).

Für Auslandsfahrten werden die nationalen Zulassungsdokumente durch die Teilnehmerstaaten des Wiener Übereinkommens über den Straßenverkehr gegenseitig anerkannt. Allerdings sind Kurzzeitkennzeichen und der entsprechende Fahrzeugschein genau genommen keine offiziellen Zulassungsdokumente, da damit eine Nutzung von Fahrzeugen außerhalb des Zulassungsverfahrens gestattet wird, die in dieser Form nicht unter das Straßenverkehrsübereinkommen fällt. Deshalb können für Kurzzeitkennzeichen im Ausland andere Regeln gelten als für reguläre Kennzeichen.

Innerhalb der Europäischen Union ist Teilnahme am grenzüberschreitenden öffentlichen Straßenverkehr grundsätzlich zu gestatten. Gründe zur Verweigerung können Mängel in der Verkehrssicherheit, Fahrzeugdiebstahl oder die Ungültigkeit der Zulassungsbescheinigung sein.

Internationale Kurzzeitzulassungen mit rotem Rand auf der rechten Seite sind Zulassungen zu Überführungszwecken ins Ausland. Das Datum auf dem roten Streifen am rechten Rand bezeichnet nicht die Gültigkeitsdauer der Kennzeichen und des zugehörigen Fahrzeugbriefes, die immer zwölf Monate betragen, sondern das Ablaufdatum des in Deutschland gültigen Versicherungsschutzes. Das Fahrzeug muss vor Ablauf des angegebenen Datums ins Ausland ausgeführt worden sein und darf auf deutschen Straßen anschließend nicht mehr bewegt werden. So werden im Ausland teilweise Fahrzeuge mit abgelaufenen Daten des Versicherungsschutzes geführt. Dort muss dann unter Umständen eine neue Versicherung beantragt werden. Anfangs war auf der roten Nummer das Ablaufdatum nur auf den Monat genau angegeben, später wurde auf eine tagesgenaue Angabe umgestellt.

Das Kennzeichen enthält das Kürzel des Zulassungsbezirkes, eine rote Stempelplakette (die meist aus der alten Version der jeweiligen Zulassungsplakette abgeleitet ist) und eine Nummer mit zwei bis vier Ziffern, gefolgt von einem Buchstaben, der die laufende Serie angibt und keine besondere Bedeutung hat. Ironischerweise gehören diese internationalen Kennzeichen zu den wenigen Kennzeichentypen, die es nicht mit dem Europa-Merkmal (Sternenkranz) und der Landeskennung gibt.
Von 1910 bis 1988 hatte das Kennzeichen die Form eines ovalen Schildes, das ein Siegel der Zollbehörde trug. Dieses Siegel enthielt früher den Reichsadler und später den Bundesadler. Eine Ausnahme bezüglich des Siegels stellte West-Berlin dar, da es bis 1990 kein Bestandteil der Bundesrepublik war.

Die alten, ovalen Kennzeichen hießen "Zollkennzeichen" und hatten jahrzehntelang eine Doppelfunktion als

Fahrzeugkennzeichen des diplomatischen Corps beginnen mit der Ziffer Null (Botschafter und gleichgestellte Personen) oder dem Kennzeichen des Zulassungsbezirkes (üblicherweise "B" oder "BN", sonstiges Botschaftspersonal und Konsulate).

Rechts der Plaketten besitzen diese Kennzeichen einen Ländercode und nachfolgend eine ein- bis dreistellige Zahl, die üblicherweise im Zusammenhang mit dem Rang des Inhabers steht. Kleinere Zahlen bezeichnen in der Regel einen höheren Rang. Diplomatische Kennzeichen werden nicht nur an Personal von Botschaften, sondern auch an Mitarbeiter zahlreicher internationaler (zwischenstaatlicher) Organisationen ausgegeben, jedoch nicht an deutsche Staatsbürger. Als personengebundene Kennzeichen beschränken sie die Benutzung entsprechender Fahrzeuge auf Inhaber eines diplomatischen Ausweises (der unter Umständen auch an Familienangehörige ohne eigenes Einkommen ausgestellt wird, jedoch auch nicht an Deutsche) und Fahrer im Dienst der jeweiligen diplomatischen Missionen. Diplomaten von sehr niedrigem Rang, z. B. Honorarkonsul, erhalten keine Diplomatenkennzeichen, dürfen aber einen CC-Aufkleber (Corps Consulaire) anbringen und können je nach Standort ein – einem Behördenkennzeichen ähnelndes – Kennzeichen mit dem Kürzel des Zulassungsbezirks und einer mit "9" beginnenden Ziffernfolge erhalten.

Wird ein Diplomatenkennzeichen gestohlen oder ist aus anderen Gründen abhandengekommen, bekommt das Fahrzeug eine "Alias-Nummer": Das bisherige Kennzeichen wird durch den Buchstaben "A" ergänzt und das bisherige Kennzeichen für ungültig erklärt, bis die Sperrfrist von einem Jahr abgelaufen ist. Dann darf die Zulassungsstelle es wieder ausgeben. Wird auch die Alias-Nummer vermisst, kommt der Zusatzbuchstabe "B" zum Einsatz usw.

Internationale Hauptquartiere der NATO in Deutschland führen auf den amtlichen Kennzeichen ihrer Dienstfahrzeuge als Unterscheidungszeichen ein "X", dem eine vierstellige Zahl folgt. Auch wenn FZV die Aufgaben der Zulassungsbehörde für diese Fahrzeuge der Zentralen Militärkraftfahrtstelle der Bundeswehr übertragen hat, sind Fahrzeuge mit einem X-Kennzeichen keine Dienstfahrzeuge der Bundeswehr. Die Zulassung und technische Überwachung der Fahrzeuge erfolgen nach den Vorschriften der StVZO, der Fahrzeug-Zulassungsverordnung, dem Kraftfahrzeugsachverständigengesetz und der 15. Ausnahmeverordnung zur Straßenverkehrszulassungsordnung.

Danach müssen die mit "X" gekennzeichneten Fahrzeuge zur regulären Hauptuntersuchung und Abgasuntersuchung. Die Sicherheitsprüfung kann aber auch von Werkstätten der Bundeswehr durchgeführt werden. Damit stehen diese Fahrzeuge im Gegensatz zu denen der Bundeswehr mit dem Kennzeichen "Y", die im Rahmen der Technischen Materialprüfung (TMP) von Fachpersonal der Bundeswehr geprüft werden.

Auch diese Schilder müssen nicht reflektierend sein und es gibt sie nicht in der Euro-Version. Es gibt auch rote Kennzeichen, die mit "X" beginnen.

In Frankreich stationierte Angehörige der Bundeswehr (deutsche Soldaten und deren ziviles Gefolge, d. h. Bundeswehrverwaltung bzw. berechtigte Familienangehörige) haben ein eigenes Nummernschild, das mit "DF" beginnt und weiße Schrift auf schwarzem Grund hat. Darauf folgen vier Ziffern von 0001 bis 9999. Das Kürzel "DF" ist ein sogenanntes französisches Domänenkennzeichen (Staatskennzeichen) und bedeutet "Douanes Françaises". Es handelt sich damit um ein Zollausschlusskennzeichen.

In den Niederlanden stationierte deutsche Soldaten haben dort auch ein eigenes Kennzeichen. Es hat gelbe Schrift auf schwarzem Grund und beginnt mit "AF". Seit der Änderung des Seedorfer-Vertrages sieht das Kennzeichen anders aus: Es hat schwarze Schrift auf gelbem Grund und ist von normalen niederländischen Kennzeichen nicht zu unterscheiden.
Auch die in Deutschland stationierten Soldaten der US-Streitkräfte verwendeten in den Jahren 2000 bis 2005 ein Nummernschild, das mit dem deutschen bis auf den Inhalt des Eurobandes identisch ist (sogenanntes Lookalike-Kennzeichen; mit "AD", "AF" oder "HK" beginnend; das heutige Kennzeichen "HK" für den Heidekreis existierte bis 2011 noch nicht). Aufgrund von Sicherheitsbedenken wird seit Ende 2005 ein reguläres deutsches Kennzeichen des jeweiligen Zulassungsbezirks verwendet, in dem der Soldat wohnt bzw. seinen Dienstsitz hat. Für Dienstfahrzeuge wird weiterhin die Kennung "IF" verwendet. Weiterhin wird "QQ" für Überführungskennzeichen verwendet sowie "T" für rote Nummernschilder.

Als temporäre Kennzeichen mit roter Nummer werden auch Kennzeichen mit dem Buchstaben "T", gefolgt von einer Abkürzung für die ausgebende Garnison und einer fünfstelligen Zahl herausgegeben, z. B. "T GR 00042" aus dem Bereich Grafenwöhr oder "T HS 00150" für Hohenfels. 

Für die Soldaten folgender Länder, die in Deutschland stationiert sind bzw. waren, existieren eigene Kennzeichen:

Das neue, ab 1956 in Westdeutschland eingeführte System sollte ausreichend sein für einen erwarteten erheblichen Zuwachs an Kraftfahrzeugen bei gleichzeitiger Anpassungsfähigkeit an veränderte europolitische Gegebenheiten. So konnten das Saarland (1957) und die Kreise in der ehemaligen DDR (1991) ohne größere Schwierigkeiten in das System übernommen werden. Dazu mag beigetragen haben, dass für diese bereits im Verordnungsentwurf von 1956 Kennzeichen im sogenannten Ostzonenverzeichnis reserviert waren. In Letzterem waren auch die Deutschen Ostgebiete enthalten, da die Bundesrepublik zum damaligen Zeitpunkt darauf noch Anspruch erhob. Nach dem völkerrechtlichen Verzicht auf diese Gebiete sind diese Vorstellungen hinfällig.

Im Kontext mit der Gründung der Stadt Lahn wurde 1977 entschieden, als Unterscheidungszeichen für die Stadt und den Lahn-Dill-Kreis das "L" zu nutzen, obwohl dessen Verwendung im Falle einer Wiedervereinigung für die Stadt und den Landkreis Leipzig nahe lag. Dass es dazu kommen würde, erschien damals unvorstellbar. Auch nachdem die Stadt Lahn wieder aufgelöst worden war, blieb das Unterscheidungszeichen für den Lahn-Dill-Kreis erhalten. Erst am 1. November 1990 erhielt dieser die neue, bis heute gültige Kennung "LDK". Bei der Einführung des "L" in Leipzig und im gleichnamigen Landkreis behalf man sich damit, dass für Leipziger Kennzeichen die im Lahn-Dill-Kreis noch nicht ausgegebenen Nummerngruppen, vor allem die damalige Gruppe IIIb – heute Gruppe e – (siehe oben unter Erkennungsnummer), verwendet wurden.

Mit der Gebietsreform in Sachsen-Anhalt 2007 wurden wiederum auslaufende Unterscheidungszeichen neu vergeben: "HZ" wurde ursprünglich vom 1. Januar 1991 bis zum 31. Dezember 1993 für den Kreis Herzberg (heute: Landkreis Elbe-Elster) ausgegeben und wird seit dem 1. Juli 2007 für den Landkreis Harz verwendet, ebenso wie "BK" für den ehemaligen Landkreis Backnang und heute für den Landkreis Börde in Haldensleben.

Die Verkehrsministerkonferenz der Länder empfahl im April 2011, die Wiedereinführung von auslaufenden Kfz-Kennzeichen durch eine Änderung der Fahrzeug-Zulassungsverordnung möglich zu machen. Bundesverkehrsminister Peter Ramsauer stellte im August 2012 in Aussicht, dass die Städte und Gemeinden ihre Unterscheidungszeichen künftig frei wählen dürfen. Neben der Wiedereinführung von Altkennzeichen sollte dann auch die Einführung völlig neuer Unterscheidungszeichen möglich sein. Die entsprechende Verordnung beschloss der Bundesrat am 21. September 2012, allerdings mit der Einschränkung, entsprechend der Forderung der Verkehrsministerkonferenz lediglich auslaufende Unterscheidungszeichen wieder zuzulassen. Die diesbezügliche Erste Verordnung zur Änderung der Fahrzeug-Zulassungsverordnung und anderer straßenverkehrsrechtlicher Vorschriften wurde am 25. Oktober 2012 im Bundesgesetzblatt verkündet und trat am 1. November 2012 in Kraft.

Entscheidend für diesen Beschluss war unter anderem die "Initiative Kennzeichenliberalisierung" der Hochschule Heilbronn. Die Initiative hat von 2010 bis 2012 über 50.000 Personen in über 200 Städten befragt, ob sie eine Wiedereinführung der alten Kennzeichen wünschen. Die Auswertung der Umfrageergebnisse hat ergeben, dass mehr als 72 Prozent der befragten Personen sich die Wiedereinführung der alten Kennzeichen wünschen.

In allen Flächenländern mit Ausnahme des Saarlandes wurden daraufhin ab dem 9. November 2012 ehemals auslaufende Unterscheidungszeichen wiedereingeführt. Da Anträge für die Wiedereinführung von Altkennzeichen jederzeit möglich sind, ändert sich die Anzahl der Wiedereinführungen stetig.

Nach der Fahrzeug-Zulassungsverordnung sind Unterscheidungszeichen, Erkennungsnummern sowie Kombinationen aus Unterscheidungszeichen und Erkennungsnummern, die gegen die guten Sitten verstoßen, unzulässig. Die Verwaltungsvorschrift zur Fahrzeug-Zulassungsverordnung empfiehlt den Zulassungsstellen, keine Buchstabenpaare zu vergeben, die auf nationalsozialistische Organisationen Bezug nehmen. Dies sind: "HJ" (Hitlerjugend), "KZ" (Konzentrationslager), "NS" (Nationalsozialismus), "SA" (Sturmabteilung) und "SS" (Schutzstaffel).

"AH" (Adolf Hitler), "HH" (Heil Hitler) und "SD" (Sicherheitsdienst) werden nur von wenigen Zulassungsbehörden nicht ausgegeben. "IS" (Islamischer Staat) wird in Düsseldorf, im Rhein-Sieg-Kreis, im Landkreis Marburg-Biedenkopf und in Darmstadt nicht mehr vergeben. Weiterhin sind Kombinationen mit dem Zulassungsbezirk unerwünscht, wenn diese eine der o. g. Kombinationen ergibt. Für Stuttgart werden beispielsweise die Erkennungszeichen "A", "S", und "D", für Köln wird "Z" nicht vergeben. Allerdings wurde in Einzelfällen hiervon abgewichen: So war im Zulassungsbezirk der Region Hannover "J" ein zulässiger und vom zuständigen Minister nicht weiter beanstandeter Erkennungsbuchstabe. Zwischenzeitlich wurden Kennzeichen mit "J" nicht mehr, aber aktuell wieder ausgegeben. Weitere nicht vergebene Buchstabenkombinationen sind in Stuttgart "S ED" (Sozialistische Einheitspartei Deutschlands), in Nürnberg "N PD" (Nationaldemokratische Partei Deutschlands), im Landkreis Nürnberger Land "N S" und "N SU", im Kreis Warendorf "WAF FE", im Kreis Steinburg "IZ AN" (Nazi rückwärts gelesen), im Kreis Dithmarschen "HEI L". Der Landkreis Regensburg in Bayern vergab entgegen den Empfehlungen des Bundesverkehrsministeriums bis Anfang Oktober 2012 noch das Buchstabenpaar "NS". Erst nachdem eine lokale Zeitung die Behörde darauf aufmerksam gemacht hatte, wurden solche Kennzeichen nicht mehr vergeben. Der Landkreis Schwandorf hat nach der Wiedereinführung des Unterscheidungszeichens "BUL" die Buchstabenkombination "BUL LE" als mögliche Beleidigung für anstößig befunden und gibt diese nicht aus. Im Gegensatz dazu vergibt das Straßenverkehrsamt Aachen das Buchstabenpaar "AB" und damit die Kombination "AC AB" ("All Cops Are Bastards" – ‚Alle Polizisten sind Bastarde‘). Im Kreis Wesel wird auf die Kombination "MO RD" verzichtet. Im Rhein-Sieg-Kreis wird die Kombination "SU FF" in Einzelfällen nicht vergeben.

In Brandenburg werden seit Juni 2010 von den dortigen Kfz-Zulassungsstellen keine Kennzeichen mehr neu vergeben, die mit Adolf Hitler, dem Hitlergruß bzw. ähnlichen rechtsextremen Symbolen assoziiert werden können. Betroffen sind Kennzeichen, die auf "88", "888", "8888", "188", "1888" sowie "8818" enden. Auch die Kombinationen "HH 18" sowie "AH 18" werden seitdem nicht mehr ausgegeben.

Seit mindestens 1994 ist es möglich, gegen eine bundeseinheitliche Gebühr von derzeit 10,20 Euro (Geb.-Nr. 221 der zur Gebührenordnung für Maßnahmen im Straßenverkehr) ein Wunschkennzeichen zu erhalten. Fast alle Zulassungsstellen bieten inzwischen eine Online-Reservierung an. Für eine derartige Vorabreservierung fällt grundsätzlich eine zusätzliche Gebühr von 2,60 Euro an, wodurch die Gesamtgebühren 12,80 Euro für ein Wunschkennzeichen mit Vorabreservierung betragen.

Bereits vor Inkrafttreten der Änderung der Fahrzeug-Zulassungsverordnung, mit der seit dem 1. November 2012 die Vergabe mehrerer Unterscheidungszeichen innerhalb eines Zulassungsbereiches möglich gemacht wurde (Kennzeichenliberalisierung), gab es eine ganze Reihe von Besonderheiten bei der Zuweisung von Unterscheidungszeichen:

Die Gemeinde Büsingen am Hochrhein (Kennzeichen "BÜS", zum Landkreis Konstanz mit dem Kennzeichen "KN" gehörend) hat als deutsche Exklave in der Schweiz seit dem 1. Januar 1968 ein eigenes Unterscheidungszeichen zur Erleichterung der Grenzkontrollen. Vergeben werden nur die Buchstaben-Kombinationen "BÜS-A" (verzollte Fahrzeuge) und "BÜS-Z" (innerhalb von zwei Jahren zu verzollen).

Die kreisfreie Stadt Coburg und der Landkreis Coburg haben zum 1. Dezember 2014 den Zweckverband Zulassungsstelle Coburg gebildet. Die seitdem neu zugelassenen Fahrzeuge können nicht mehr nach dem Zulassungsbezirk Stadt oder Landkreis unterschieden werden.

Im Land Bremen führen die kreisfreien Städte Bremen und Bremerhaven mit "HB" das gleiche Unterscheidungszeichen, obwohl sie etwa 60 Kilometer auseinanderliegen. Zur Unterscheidung haben die Bremerhavener Kennzeichen immer einen Buchstaben und vier Ziffern (Gruppe d; siehe oben unter "Erkennungsnummer").

Hanau durfte als kreisangehörige Stadt mit Sonderstatus im Main-Kinzig-Kreis am 1. Juni 2005 das Kennzeichen "HU" behalten, während alle anderen Gemeinden des Landkreises, der seinen Sitz von Hanau nach Gelnhausen verlagerte, die Kennung "MKK" erhielten.

Die Sonderstatusstadt Wetzlar im Lahn-Dill-Kreis wurde am 1. Juli 2012 Träger einer eigenen Zulassungsbehörde und erhielt das eigene bereits vor der Kreisgebietsreform in Hessen vom Landkreis Wetzlar geführte Unterscheidungszeichen "WZ". Auf derselben Grundlage strebte die kreisangehörige Sonderstatusstadt Rüsselsheim an, 2014 das eigene Unterscheidungszeichen "RÜS" zu erhalten.

Nach der Kreisgebietsreform Mecklenburg-Vorpommern 2011 behielten die ehemaligen kreisfreien Städte Greifswald, Neubrandenburg, Stralsund und Wismar ihre früheren Unterscheidungszeichen, während die neu gebildeten Landkreise neue Unterscheidungszeichen erhielten. Anfangs behielt die Insel Rügen auch ihr ehemaliges Unterscheidungskennzeichen, welches aber in ein Alternativkennzeichen für den Landkreis Vorpommern-Rügen umgewandelt wurde.

St. Ingbert (Kennzeichen "IGB", im Saarpfalz-Kreis mit Kennzeichen "HOM") und Völklingen (Kennzeichen "VK", im Regionalverband Saarbrücken mit Kennzeichen "SB") führen als Mittelstädte nach saarländischem Kommunalrecht ein eigenes Unterscheidungszeichen.

Zweiräder, Trikes und verwandte Fahrzeuge haben heute grundsätzlich nur ein Kennzeichenschild, das am Heck des Fahrzeugs befestigt ist. Bei Motorrädern war noch in der ersten Hälfte des 20. Jahrhunderts ein gebogenes Schild auf dem vorderen Schutzblech (längs zur Fahrrichtung) üblich, das aber in der Nachkriegszeit in Deutschland und anderen Ländern wegen der von ihnen ausgehenden Gefährdung anderer Verkehrsteilnehmer bei Zusammenstößen abgeschafft wurde. Gleichwohl ist die Verwendung solcher Kennzeichenschilder bis heute nicht verboten, was etwa bei Oldtimern genutzt wird.

Seit Anfang April 2011 lässt die Fahrzeug-Zulassungsverordnung für Motorräder die Verwendung eines Kraftradkennzeichens mit der bisher Kleinkrafträdern und speziellen, bspw. amerikanischen Fahrzeugen vorbehaltenen kleineren Schrift zu; Die Höhe dieser Kennzeichen ist auf das normale Maß zweizeiliger Kennzeichen (200 mm) festgelegt, die Breite darf zwischen 180 mm und 220 mm betragen. Zweizeilige Kennzeichen an Krafträdern dürfen, entsprechend denen bei Pkw, weiterhin bis zu 280 mm breit sein, wenn sie mit normal großen Zeichen versehen sind.

Einige Fahrzeugklassen sind von der Zulassung ausgenommen, müssen aber ein Versicherungskennzeichen zum Nachweis einer gültigen Versicherung tragen, um am Straßenverkehr teilnehmen zu dürfen:

Das Kennzeichen wird ab 1. März jedes Jahres bis Ende Februar des folgenden Jahres (Versicherungsjahr) in einer jeweils anderen Schriftfarbe ausgegeben und kann bei Banken und Versicherungen erworben werden. Das Schild ist zweizeilig (drei Ziffern und drei Buchstaben), hochformatig und deutlich kleiner (130 mm × 105,5 mm) als gewöhnliche Kfz-Kennzeichen. Die jeweilige Nummer ist nicht speziell an das Fahrzeug gebunden, sondern wird meist zufällig vergeben. Anhand der drei Buchstaben kann die Versicherungsgesellschaft ermittelt werden. Das Kennzeichen ist keine behördliche Zulassung, da (mit einer Haftpflichtversicherung) die Erlaubnis zur Teilnahme am öffentlichen Straßenverkehr durch die ABE des Fahrzeugs dokumentiert wird. Die Schriftfarben sind, im jährlichen Wechsel zum 1. März, Schwarz, Blau und Grün auf reflektierendem, weißem Hintergrund. Das Jahr, in dem das Kennzeichen gültig ist, ist nochmals in der untersten Zeile angegeben. Deshalb ist es nicht möglich, ein Kennzeichen drei Jahre später noch einmal zu benutzen.
Auf dem unteren Rand steht je nach Versicherungsunternehmen GDV (ehemals: "HUK Verband"). Darüber hinaus gibt es noch rote Kennzeichen, die nur an Händler für Prüfungs-, Probe- und Überführungsfahrten ausgegeben werden. Diese Kennzeichen beginnen immer mit dem Buchstaben "Z", um einen Missbrauch mit anderen Versicherungskennzeichen zu vermeiden, da in den Begleitpapieren kein spezielles Fahrzeug eingetragen ist.

Bis zur Kennzeichenliberalisierung war das seltenste in Deutschland vergebene Kennzeichen das der Exklave Büsingen "BÜS". Seither gibt es neu eingeführte Kennzeichen, die bislang noch seltener sind. Da aber die betreffenden Zulassungsbezirke allesamt ein Vielfaches an Einwohnern haben, kann es sich um einen vorübergehenden Zustand handeln. Büsingen ist nach wie vor der kleinste Zulassungsbezirk Deutschlands.

Die folgende Tabelle zeigt die Zulassungsbezirke mit den wenigsten angemeldeten Fahrzeugen in Deutschland 

Die Umlaute (Ä, Ö und Ü) finden lediglich bei den Unterscheidungszeichen, aber nicht bei den Erkennungsnummern Verwendung. Gegenwärtig sind lediglich Unterscheidungszeichen mit "Ö" (z. B. in "GÖ") und "Ü" (z. B. in "WÜ") festgesetzt; der Buchstabe "Ä" fand sich bisher nur im derzeit aufgehobenen Unterscheidungszeichen des am 1. Januar 1973 aufgelösten Landkreises Säckingen "(SÄK)". Dennoch wurde auch für das "Ä" im Rahmen der FE-Schrift ein Schriftzeichen für die seit 1994 vergebenen Euro-Kennzeichen entwickelt. Die Schrifthöhe der Umlaute (einschließlich der Punkte) ist auch in der FE-Schrift identisch mit den übrigen Buchstaben und Ziffern.

Bis 1994 galt der Grundsatz, Kombinationen für unterschiedliche Zulassungsbezirke, die sich nur durch den Umlaut und den dazugehörigen Vokal voneinander unterscheiden, nicht zu vergeben, um Verwechslungen zu vermeiden. Mit der Vergabe der Kombination "BÖ" an den Bördekreis in Sachsen-Anhalt wurde dieser Grundsatz 1996 gebrochen, da die Kombination "BO" bereits durch die Stadt Bochum verwendet wurde. Nachdem dies vor allem im Ausland zu Verwechslungen geführt hatte, wurde 2007 das "BÖ" im Zusammenhang mit der Zusammenlegung des Bördekreises mit dem Ohrekreis zum Landkreis Börde durch "BK" ersetzt, jedoch im November 2012 im Zuge der Kennzeichenliberalisierung erneut als Option zugelassen.

Für Kraftfahrzeuge, die als Requisite in Film- und Fernsehproduktionen vorkommen, werden statt amtlich zugelassener Kfz-Kennzeichen häufig fiktive Film- bzw. so genannte Spielkennzeichen verwendet, da aus Gründen des Datenschutzes amtlich vergebene Kennzeichen in Film- und Werbeaufnahmen nur dann erkennbar sein dürfen, wenn die Zustimmung des Fahrzeughalters vorliegt.






</doc>
<doc id="10787" url="https://de.wikipedia.org/wiki?curid=10787" title="Onkogen">
Onkogen

Onkogene (wörtlich "Krebs-Gene") sind Teile des Erbgutes einer Zelle, die den Übergang vom normalen Wachstumsverhalten der Zelle zu ungebremstem Tumorwachstum fördern.
Das „gen“ in Onkogen wird hier nicht, wie in den Worten karzinogen oder mutagen, im Sinne von „erzeugend“ oder „fördernd“ benutzt, sondern leitet sich direkt von dem Wort Gen als Teil des Erbgutes ab.

Onkogene entstehen durch Veränderungen von Gensequenzen (Mutationen), die für das normale Zellwachstum, die Zellteilung und die Zelldifferenzierung eine Rolle spielen. Die sogenannten Protoonkogene sind Vorstufen von Onkogenen und werden durch schädliche Einflüsse (ionisierende Strahlung, chemische Substanzen oder Viren) in die krebserzeugende Form (das Onkogen) verwandelt. Es sind heute mehr als 100 (Stand: 2004) Protoonkogene bekannt. Alle Zellzyklus-Kontrollgene sind potentielle Protoonkogene, da ihre Veränderung bzw. Dysfunktion den Verlust der Kontrolle über die Zellteilung bedeuten kann.

Protoonkogene werden anhand der durch sie kodierten Proteine in mehrere Gruppen eingeteilt:

Protoonkogene sind normale Gene, die in jeder Zelle vorkommen und Proteine kodieren, die Wachstum, Teilung und Differenzierung einer Zelle kontrollieren und steuern. Viele Komponenten, die das Wachstum einer Zelle beeinflussen, können als Protoonkogene angesehen werden. 
Mutiert ein solches Gen, kommt es im häufigsten Fall zu einem Funktionsverlust, die Zellteilung wird nicht mehr gefördert und die Zelle kann sich nicht mehr teilen. Meist zieht das den programmierten Zelltod, die sogenannte Apoptose, nach sich, was für den Organismus kein Problem darstellt, da sich normalerweise genügend andere teilbare Zellen in der Nachbarschaft befinden. 
Es gibt aber auch die Möglichkeit, dass durch die Mutation des Protoonkogens die Zellteilung gefördert wird. Es kann passieren, dass durch Chromosomenumlagerungen ein Wachstumsgen unter den Einfluss eines Promotors gerät, der normalerweise stark aktivierend wirkt. So sind z. B. die Promotoren der Immunglobuline in der Lage, Protoonkogene zu Onkogenen zu aktivieren und damit zur Entstehung von Tumoren beizutragen.



</doc>
<doc id="10789" url="https://de.wikipedia.org/wiki?curid=10789" title="Urokinase">
Urokinase

Urokinase oder "Urokinase-Typ Plasminogen Aktivator" (kurz "uPA") ist ein Enzym aus der Gruppe der Peptidasen (auch "Proteasen"), das zur Behandlung des Herzinfarktes, der Lungenembolie und sonstiger thrombotischer Gefäßverschlüsse sowie zur Therapie und Prophylaxe thrombotischer Katheterverschlüsse eingesetzt wird. 

Urokinase wurde erstmals in menschlichem Urin entdeckt und als Protease beschrieben. Physiologisch zirkuliert es im Blutstrom und setzt Plasminogen zu Plasmin um, welches eine Serinproteinase ist, die diverse Proteine im Plasma und insbesondere Fibrin-Gerinnsel auflöst. Dieser Vorgang wird als Fibrinolyse bezeichnet und die Wirksamkeit von Urokinase als Medikament beruht auf diesem Mechanismus. Urokinase wird durch die Plasminogen-Aktivator-Inhibitoren PAI-1 und PAI-2 inhibiert.

Man stellte fest, dass die Expression von Urokinase und PAI-1 in verschiedenen Krebserkrankungen signifikant erhöht ist und so als prognostischer Marker dienen kann.

Seine Wirkung kann durch Gabe von Tranexamsäure aufgehoben werden.

Wenn Urokinase an seinen zellulären Rezeptor, den per Glycosylphosphatidylinositol-Anker (GPI-Anker) an der Zellmembran befestigten Urokinase-Rezeptor (uPAR) gebunden ist, ist seine proteolytische Aktivität stark erhöht. Außerdem werden durch die Bindung von Urokinase an den uPAR mitotische Signalwege der Zelle aktiviert und die zelluläre Migration erhöht. Diese Prozesse sind unabhängig von der proteolytischen Aktivität der Urokinase.

Urokinase ist in Deutschland zugelassen für den Einsatz bei 
Urokinase ist in Deutschland, Österreich und der Schweiz unter dem Namen Urokinase HS medac in fünf Wirkstärken (10.000/ 50.000/ 100.000/ 250.000/ 500.000 I.E.) erhältlich.


</doc>
<doc id="10790" url="https://de.wikipedia.org/wiki?curid=10790" title="Fibrin">
Fibrin

Fibrin ( ‚Faser‘, Faktor Ia der Blutgerinnungskaskade) ist der aktivierte, vernetzte „Klebstoff“ der plasmatischen Blutgerinnung. Es handelt sich um ein Protein, das durch die Einwirkung des Enzyms Thrombin (Faktor IIa der Gerinnungskaskade) aus der fadenförmigen löslichen Vorstufe, dem Fibrinogen (Faktor I der Gerinnungskaskade), gebildet wird. Das Fibrin polymerisiert anschließend und bildet ein Netz, das Blutgerinnsel („weißer Thrombus“), das die Wunde verschließt. Erst später wird durch Quervernetzung mithilfe des Faktors XIIIa der weiche Thrombus zu einer harten Kruste. Fibrin kann in Gegenwart von reinem Sauerstoff oder speziellen oxidativen Wundspüllösungen die Wundheilung beschleunigen.

Bei der Bildung des weißen Thrombus wird zunächst durch Thrombin von der α-Kette des Fibrinogens das 16 Aminosäuren lange "Fibrinopeptid A" und von der β-Kette das 14 Aminosäuren lange "Fibrinopeptid B" abgespalten. Hierdurch wird die N-terminale Position an den Peptiden freigelegt und diese binden damit an der γ-Kette des Fibrinogens und lagern sich dort zu so genannten "Protofibrillen" zusammen. Im nächsten Schritt treten nun Protofibrillen zu mehr oder weniger dicken Fibrinfasern in einem Prozess zusammen, der als "Lateralassoziation" bezeichnet wird. Dabei kommt es auch zu Verzweigungen, so dass ein dreidimensionales Gebilde entsteht.

Die Gene FGA, FGB und FGG, welche die Unterketten des Fibrinogens codieren, können verschiedene Mutationen aufweisen, welche die Bildung von Fibrinogen und damit der Fibrinopeptide beeinträchtigen können.
So sind Afibrinogenämien (kein Fibrinogen), Hypofibrinogenämien (verringerter Fibrinogengehalt des Blutes) und Dysfibrinogenämien (abnorme Fibrinogenmoleküle) bekannt.

Strukturveränderungen am Fibrinogen können verschiedene Defekte bei der Gerinnselbildung zur Folge haben:

Etwa 60 Prozent der Defekte sind asymptomatisch. Bei den Symptomen dominieren Blutungsneigungen, in 15 Prozent gibt es eine Thromboseneigung. Erwähnenswert ist eine Gruppe von Defekten mit Einlagerung von Proteinaggregaten in Nieren und Milz (renale Amyloidose), wo die Nierenfunktionsstörung das Bild dominiert.


</doc>
<doc id="10791" url="https://de.wikipedia.org/wiki?curid=10791" title="Karzinogen">
Karzinogen

Ein Karzinogen [] ist eine Substanz, ein Organismus oder eine Strahlung, die Krebs erzeugen oder die Krebserzeugung fördern kann. Eine andere Bezeichnung lautet Kanzerogen.

Karzinogen heißt "Krebserzeuger" oder "Krebserreger" und setzt sich aus Karzinom und Genese (von griech. "karkínos" „Krebs“ und "genesis" „Erzeugung, Geburt“) zusammen. Besser ist der Begriff "Kanzerogen", der das lateinische Wort "cancer" enthält und damit alle Krebsarten, nicht nur die Karzinome, einschließt. Häufig wird der Begriff auch adjektivisch benutzt (eine Substanz wirkt "karzinogen", auch "carcinogen", "kanzerogen" oder "cancerogen").

Sollte es zum Auslösen einer Krebserkrankung führen, spricht man von einer "Krebsinduktion" (vom lateinischen: "inducere", auslösen, einleiten).

1775 wurde von dem englischen Arzt Percivall Pott erkannt, dass bei Schornsteinfegern durch Kontakt mit Ruß der sogenannte Schornsteinfegerkrebs entstand, zurückzuführen auf aromatische Kohlenwasserstoffe im Ruß.
Zu Beginn des 19. Jahrhunderts wurde über Hautkrebs bei Arbeitern in Kupferschmelzen und Zinngießereien in Cornwall berichtet. Hier waren Arsenverbindungen die Ursache.
Jonathan Hutchinson diagnostizierte 1888 bei Patienten Hautkrebs als Folge von Anwendungen mit arsenhaltigen Salben.
Seit etwa 1925 wurden Arsenverbindungen in Schädlingsbekämpfungsmitteln im Wein- und Obstbau verwendet. Später beobachtete man dann bei Winzern eine Häufung von für Arsenverbindungen typischen Krebsarten, sodass es zu einem Verbot dieser Präparate kam.
Der Chirurg Ludwig Rehn stellte 1895 das gehäufte Auftreten von Blasenkrebs bei Arbeitern in Anilinfabriken fest, zurückzuführen auf verschiedene aromatische Amine.
Seit Beginn der Kunststoffproduktion von PVC in den 1930er Jahren traten bei Arbeitern bestimmte Formen von Leberkrebs auf, was zur Folge hatte, dass der MAK-Wert von Vinylchlorid mehrmals drastisch herabgesetzt wurde.
Unterschiedliche Krebsarten traten auch bei Arbeitern in Betrieben auf, in denen Beryllium-, Cobalt- und Nickelverbindungen, Chromate oder Asbest verarbeitet wurden, sowie in Teer- und Farbenfabriken.

Karzinogene kann man in zwei Gruppen unterteilen: 

Weiterhin spricht man von "Co-Karzinogenen", wenn ein Stoff selbst nicht krebserzeugend ist, jedoch in bestimmten Kombinationen mit anderen Stoffen (die ebenfalls nicht krebserzeugend sind), Krebs erzeugen können.

Viele Karzinogene sind erst nach einer Metabolisierung im Körper wirksam. Beispielsweise ist 3,4-Benzpyren erst nach enzymatischer Umwandlung in Epoxybenzpyren karzinogen. Ähnliches gilt für Nitrosamine, die in die entsprechenden Aldehyde und reaktive Carbeniumionen metabolisiert werden. Nitrosamine können nicht nur aus der Umwelt aufgenommen (z. B. Zigarettenrauch), sondern auch im Magen aus Aminen und Nitriten gebildet werden. Die Wirkung der Karzinogene beruht im Wesentlichen auf genotoxischen Veränderungen der DNA und führt damit zu einer Entartung der Zelle.

Bis zur Einführung des globalen harmonisierten Systems zur Einstufung und Kennzeichnung von Chemikalien (GHS) wurden Karzinogene in der Europäischen Union entsprechend der Richtlinie 67/548/EWG eingestuft – in Deutschland umgesetzt nach § 1.4.2.1 GefStoffV Anhang 1. Die folgende Tabelle stellt die Einstufungen gegenüber:

Das (GHS) ist eine Initiative der Vereinten Nationen, die unterschiedlichen Systeme der Chemikalieneinstufung in der ganzen Welt, die bisher bestanden, anzupassen. Hier wurden zwei Kategorien geschaffen, von der die erste weiter unterteilt werden kann, wenn die entsprechende Behörde es so verfügt:


Gesicherte human-epidemiologische und/oder Tierversuchsdaten bewirken eine Einstufung in die Kategorie 1. Eine weitere Differenzierung in Kategorie 1A und 1B erfolgt aufgrund der Aussagekraft der Nachweise in Verbindung mit zusätzlichen Hinweisen. Es ist im Einzelfall möglich, aufgrund einer wissenschaftlichen Beurteilung eine wahrscheinliche karzinogene Wirkung beim Menschen auf Untersuchungen zu stützen, die nur begrenzte Nachweise auf eine karzinogene Wirkung beim Menschen in Verbindung mit begrenzten Nachweisen bei Versuchstieren ergaben.

Bei nicht ausreichend gesicherten Daten für eine Einstufung in die Kategorie 1 kann die Einstufung eines Stoffes in Kategorie 2 erfolgen, wenn Studien beim Menschen einen Verdacht auf karzinogene Wirkung begründen, oder Tierstudien einen Verdacht auf karzinogene Wirkungen ergeben.

Vor der Einführung des GHS regelte die Richtlinie 67/548/EWG die Einstufungen in Europa. Die Kategorien bedeuteten:

In die Kategorie 1 wurden Stoffe eingeordnet, von denen die krebserzeugende Wirkung beim Menschen bekannt ist und es hinreichende Anhaltspunkte für einen Kausalzusammenhang zwischen der Exposition eines Menschen gegenüber dem Stoff und der Entstehung von Krebs gibt. Die Einstufung und Kennzeichnung erfolgt mit Gefahrensymbol T und R45: „Kann Krebs erzeugen (canc. cat. 1)“ oder R 49: „Kann Krebs erzeugen beim Einatmen (canc. cat. 1)“. (Nur wenn sie aus anderen Gründen sehr giftig sind, werden sie mit T+ gekennzeichnet).

Beispiele:

In die Kategorie 2 wurden Stoffe eingeordnet, die für den Menschen als krebserzeugend angesehen werden, wenn also hinreichende Anhaltspunkte zu der begründeten Annahme bestehen, dass die Exposition eines Menschen gegenüber dem Stoff Krebs erzeugen kann. Diese Annahme beruht im Allgemeinen auf Langzeitversuchen und/oder sonstigen relevanten Informationen. Die Einstufung und Kennzeichnung erfolgt mit Gefahrensymbol T und R45: „Kann Krebs erzeugen (canc. cat. 2)“ oder R 49: „Kann Krebs erzeugen beim Einatmen (canc. cat. 2)“. (Nur wenn sie aus anderen Gründen sehr giftig sind, werden sie mit T+ gekennzeichnet). Beispiele:

In die Kategorie 3 werden Stoffe eingeordnet, wenn sie wegen möglicher krebserzeugender Wirkung beim Menschen Anlass zur Besorgnis geben, aber nicht genügend Informationen für eine befriedigende Beurteilung vorliegen, wenn z. B. aus geeigneten Tierversuchen zwar Anhaltspunkte vorliegen, aber nicht ausreichen, um den Stoff in Kategorie 2 einzustufen. Die Einstufung und Kennzeichnung erfolgt mit R40: „Verdacht auf krebserzeugende Wirkung“. Beispiele: 

Die Internationale Agentur für Krebsforschung (IARC) veröffentlicht regelmäßig Untersuchungsergebnisse in umfangreichen Monographien und teilt anhand der bekannten Daten bisher 985 Substanzen und Mischungen in 5 Gruppen ein, zu denen im Folgenden einige Beispiele genannt sind:





Klassifizierungssysteme, die auf der Identifizierung von Gefährdungen beruhen (wie die der IARC oder GHS), sind nach Auffassung von Boobis et al. (2016) veraltet und dienen daher weder Wissenschaft noch Öffentlichkeit. Derartige Systeme führten zur Klassifizierung von Stoffen mit unterschiedlicher Potenz und Wirkungsweise in derselben Kategorie, beispielsweise der Konsum von Fleischprodukten und Senfgas. Eine Charakterisierung von Gefährdungen und Risiko hingegen böte eine ausgewogenes Bild von Gefährdungen, Dosis-Wirkungs-Kurven und Exposition, und ermögliche so besser informierte Risikomanagemententscheidungen. Auf die Identifizierung von Gefährdungen ausgelegte Systeme würden nach deren Meinung dagegen Panikmache, unnötige wirtschaftliche Kosten, den Verlust nützlicher Produkte, höhere Gesundheitskosten und eine Förderung überflüssiger Forschung befördern.

Zahlreiche Karzinogene kommen in der Natur vor. Beispielsweise wird Aflatoxin B1, eine der potentesten krebserzeugenden Verbindungen überhaupt, vom Schimmelpilz Aspergillus flavus gebildet. Dieser befällt häufig fett- und stärkehaltige Samen wie Nüsse, Getreide, Mais oder Pistazien.

Tumorviren, z. B.:

Elektromagnetische sowie Teilchenstrahlung kann ab Energien von etwa 4 Elektronenvolt – was gerade der Bindungsenergie der Nukleotiden im DNA-Strang entspricht − karzinogen sein. Eingeschlossen ist somit auch Radioaktivität, da ebenfalls hochenergetische Strahlung emittiert wird. UV-C-Strahlung ist an der Risikogrenze und daher auch bereits karzinogen. Sichtbares Licht ist aufgrund der geringen elektromagnetischen Energie ungefährlich.





</doc>
<doc id="10792" url="https://de.wikipedia.org/wiki?curid=10792" title="Plasma">
Plasma

Plasma () steht für:
PLASMA steht für:


</doc>
<doc id="10793" url="https://de.wikipedia.org/wiki?curid=10793" title="Triglyceride">
Triglyceride

Triglyceride, Triglyzeride, auch Glycerol-Triester, seltener veraltet Neutralfette, sind dreifache Ester des dreiwertigen Alkohols Glycerin mit drei Säuremolekülen und sollten nach der IUPAC-Empfehlung ausschließlich als Triacylglycerole, kurz TAGs, (bzw. exakter "Tri-O-acylglycerole") bezeichnet werden. Die Vorsilbe "Tri" verweist auf drei Acyl-Säurereste, die mit Glycerin verestert sind.

"Triacylglycerole" mit drei Fettsäuren sind die Verbindungen in Fetten und fetten Ölen. Natürliche Fette bestehen zum überwiegenden Teil aus Triglycerolen mit drei langkettigen Fettsäuren, die meist aus unverzweigten Ketten mit 4 bis 26, typischerweise 12 bis 22 Kohlenstoff-Atomen bestehen. Sind sie bei Raumtemperatur flüssig, werden sie auch als Öle oder, um sie von Mineralölen oder ätherischen Ölen zu unterscheiden, "fette Öle" bezeichnet. Reine Triacylglycerole von Fettsäuren werden auch als "Neutralfette" bezeichnet.

Man kann zwischen mittel- und langkettigen Triglyceriden unterscheiden. Dabei haben mittelkettige Triglyceride (engl.: "medium-chain triglycerides", MCT) Fettsäuren mittlerer Länge (6 bis 12 C-Atome) und langkettige Triglyceride (engl.: "long-chain triglycerides", LCT) Fettsäuren großer Länge (14 bis 24 C-Atome) gebunden. Kurzkettige Triglyceride (SCT) sind zum Beispiel Triacetin und Tributyrin (Fettsäuren mit 2 oder 4 C-Atomen).

Darüber hinaus gibt es zwei Arten von Triacylglycerolen: einfache und gemischte Triacylglycerole. Bei einfachen Triacylglycerolen sind die Seitenketten (also die Fettsäurereste) identisch, bei gemischten sind sie verschieden.

Die Ursache dafür, dass Fett fest und Öl flüssig ist, liegt im wesentlich höheren Anteil an ungesättigten Fettsäureresten in den Triglyceriden von Ölen. Die ungesättigten Fettsäuren besitzen meist "cis"-Doppelbindungen, was die Kristallbildung der Triglyceride erschwert und somit den Schmelzpunkt heruntersetzt.

Sind in einem Triacylglycerol die Seitenketten R und R verschieden, so liegt ein chirales Molekül vor und man kann eine optische Aktivität beobachten, d. h., das Spiegelbild des Moleküls ist nicht deckungsgleich mit dem Original und eine Lösung des Moleküles ist in der Lage, einfallendes polarisiertes Licht zu drehen.

Phosphoglyceride wie z. B. Lecithine sind Triester des Glycerins mit zwei Fettsäuren und einer organischen Phosphorsäure. Beide Verbindungstypen zählen zur Klasse der Lipide mit meist pflanzlichem und tierischem Vorkommen in der Natur, eine Darstellung durch chemische Synthese ist jedoch auch möglich.

Für chirale Derivate des Glycerins gilt zudem die sn-Nomenklatur.

Die Ausführungen unter Stoffgruppen und Benennungen lassen erkennen, dass native Triglycerid-Gemische eine hohe Komplexität haben können. Beim Vorliegen von n unterschiedlichen Fettsäure-Arten sind n verschiedene Isomere (einschließlich der Stellungsisomere und der optischen Isomere) möglich. Da inzwischen mehr als 100 relativ häufig natürlich vorkommende Fettsäuren bekannt sind, wird erkennbar, dass nur sehr leistungsfähige analytische Verfahren geeignet sind, die unterschiedlichen Triglyceride eindeutig zu charakterisieren und zu quantifizieren.

Zur qualitativen und quantitativen Analytik der Triglyceride werden daher bevorzugt chromatographische Verfahren eingesetzt. Je nach den zu untersuchenden Matrices sind adäquate Probenvorbereitungsmethoden erforderlich. So sind aus physiologischen Matrices (z. B. Serum oder Liquor) oder aus Lebensmitteln die Triglyceride vor der Analytik durch geeignete Extraktionsverfahren zu isolieren. Native Öle und Fette können meist ohne aufwändigere Probenvorbereitungen mit Hilfe der "Argentations-Chromatographie" oder der HPLC mit Propionitril als Eluent untersucht werden. Auch die "Hochtemperatur-Gaschromatographie" findet Einsatz bei der Bestimmung der einzelnen Triglyceride.

Im medizinischen Bereich werden bei der Erstellung einer Blutanalyse die Triglyceridwerte im Blut gemessen. Erhöhte Werte (über 150 mg pro dl bzw. 1,7 mmol pro l) weisen auf eine Fettstoffwechselstörung (Hypertriglyceridämie) oder Übergewicht hin. Auch bei anderen Erkrankungen wie Hypothyreose oder Nierenerkrankungen sind diese Werte erhöht. Erhöhte Triglyceridwerte stellen ein Risiko dar, da sie die Bildung von Thrombosen oder eine Arteriosklerose der Blutgefäße fördern können, insbesondere wenn sie mit einem erhöhten Cholesterinspiegel einhergehen.

Beispiele einiger Triacylglycerole mit drei "gleichen" Säureresten:
Oft sind die in den Triacylglycerolen enthaltenen drei Säurereste jedoch verschieden.


</doc>
<doc id="10798" url="https://de.wikipedia.org/wiki?curid=10798" title="Fettsäuren">
Fettsäuren

Fettsäuren sind aliphatische Monocarbonsäuren mit zumeist unverzweigter Kohlenstoffkette. Die Bezeichnung „Fettsäuren“ fußt auf der Erkenntnis, dass natürliche Fette und Öle aus den Estern langkettiger Carbonsäuren mit Glycerin bestehen. Aus dieser Sicht werden Fettsäuren auch zu den Lipiden gezählt. Später wurden auch alle anderen Alkylcarbonsäuren und deren ungesättigte Vertreter den Fettsäuren zugeordnet.

Fettsäuren unterscheiden sich durch die Anzahl der C-Atome (Kettenlänge) sowie – bei ungesättigten Fettsäuren – in der Anzahl und Position von Doppelbindungen. Man kann Fettsäuren aufgrund ihrer Kettenlängen in "niedere" (bis sieben C-Atome), "mittlere" (acht bis zwölf C-Atome) und "höhere" (mehr als zwölf C-Atome) Fettsäuren einteilen. Fettsäuren mit mehr als 22-C Atomen werden auch als VLCFAs (Very Long Chain Fatty Acids) bezeichnet. Die Namensgebung als „Fettsäure“ suggeriert, dass eine individuelle Verbindung einmal eine Komponente eines Fettes gewesen sein muss, um eine Fettsäure zu sein. Dies ist aber nicht zwangsläufig der Fall. Unter diesem Begriff werden heute Carbonsäuren (≥ Buttersäure) mit kettenförmigen Organylgruppen zusammengefasst.

Natürliche Fettsäuren bestehen in der Regel aus einer geraden Zahl von Kohlenstoffatomen und sind unverzweigt. Ausnahmen davon lassen sich jedoch in allen Reichen finden. Eine Definition ist, dass die Kohlenstoffkette mindestens vier C-Atome lang sein muss; somit ist die Buttersäure die einfachste natürliche Fettsäure. Nach anderer Definition nach der Formel CH (CH)COOH; wobei x die Anzahl der Kohlenstoffatome in der Kohlenwasserstoffkette ist, können auch nur drei C-Atome vorhanden sein wenn x = 1 ist. Fettsäuren mit C=C-Doppelbindungen werden ungesättigte Fettsäuren genannt. Diese Doppelbindung ist in der Regel "cis"-konfiguriert. Liegen mehrere Doppelbindungen vor, sind diese in der Regel durch eine Methylengruppe (CH) voneinander getrennt.

Eine große Vielfalt von Fettsäuren (mehr als 400 verschiedene Strukturen, wovon aber nur etwa 10–12 häufig sind) kommt – meist in Form der Triacylglyceride, also verestert mit Glycerin – in den Samenölen des Pflanzenreichs vor. Seltene Fettsäuren, die verestert in größeren Prozentgehalten in Samen bestimmter Pflanzenfamilien auftreten, können entwicklungsgeschichtliche Zusammenhänge illustrieren (Verwandtschaftsbeziehungen, Chemotaxonomie, Evolution; vgl. z. B. auch Weltwirtschaft) wie zum Beispiel Petroselinsäure, Taririnsäure, Erucasäure, Cyclopentenfettsäuren und Cyclopropenfettsäuren. Manche Bakterienarten können anhand ihrer Fettsäurenzusammensetzung unterschieden werden.

Als essenzielle Fettsäuren bezeichnet man Fettsäuren, die ein Organismus benötigt, aber nicht selbst herstellen kann. Für Säugetiere sind Fettsäuren essenziell, die eine oder mehrere Doppelbindungen an höheren Positionen als C-9 (vom Carbonyl-Kohlenstoff aus gezählt) besitzen, da ihnen die Enzyme fehlen, solche Doppelbindungen einzufügen. Für den Menschen sind dies streng genommen nur Linolsäure und α-Linolensäure.

Fettsäuren werden in der Lebensmittelindustrie hauptsächlich als Rohstoff für verschiedene Emulgatoren verwendet, daneben jedoch auch als Trägerstoffe, Trennmittel (z. B. in Kaugummi) oder als Überzugsmittel (z. B. für Obst).
Sie sind in der EU als Lebensmittelzusatzstoff der Sammelbezeichnung "E 570" ohne Höchstmengenbeschränkung "(quantum satis)" für Lebensmittel allgemein zugelassen.

Die Natrium- oder Kalium-Salze der höheren Fettsäuren sind als Seifen bekannt und werden als Tenside verwendet.

Eine gesättigte Fettsäure ("SFA", von engl. "saturated fatty acids") ist – als Untergruppe der Alkansäuren – eine Fettsäure, die keine Doppelbindungen zwischen C-Atomen aufweist. Die gesättigten Fettsäuren bilden eine homologe Reihe mit der Summenformel CHCOOH.

Ungesättigte Fettsäuren besitzen als "Alkensäuren" mindestens eine C=C-Doppelbindung ("MUFA", von engl. "Monounsaturated fatty acids"). "Mehrfach ungesättigte Fettsäuren" ("PUFA", von engl. "Polyunsaturated fatty acids") besitzen zwei oder mehr Doppelbindungen zwischen den Kohlenstoffatomen der Kette. Da in natürlichen Fettsäuren die Doppelbindungen meist in der "cis"-Konfiguration vorliegen, entsteht ein Knick von etwa 30° in der Kohlenwasserstoffkette. Dadurch ist die Van-der-Waals-Wechselwirkung zu anderen Molekülen abgeschwächt; der Schmelzpunkt wird verringert. Einige ungesättigte Fettsäuren sind für den Menschen essentiell, da sie vom menschlichen Körper nicht synthetisiert werden können, aber benötigt werden. Dazu zählen Fettsäuren, die Doppelbindungen an bestimmten Positionen tragen, die Omega-"n"-Fettsäuren. 

Man unterscheidet einfach (Monoensäuren), doppelt (Diensäuren), dreifach (Triensäuren) oder mehrfach (Polyensäuren) ungesättigte Fettsäuren.

In den Omega-n-Fettsäuren steht n für eine Zahl und beschreibt die Position einer der Doppelbindungen. Bei der in der Lebensmittelchemie oft benutzten Omega-Zählweise wird vom „ω-Ende“ der Kohlenstoffkette aus gezählt, das der Carboxygruppe gegenübersteht. Die Doppelbindung nahe der Carboxygruppe erhält daher die größte Zahl; die Position der dem ω-Ende am nächsten stehenden Doppelbindung bestimmt den Typ der Omega-"n"-Fettsäure. In der Abbildung der Linolensäure ist die ω-Zählweise in Rot dargestellt. Für die Einteilung in die verschiedenen Gruppen der Omega-"n"-Fettsäuren ist nur die als erstes gezählte Doppelbindung entscheidend.

Neben ungesättigten Fettsäuren in der "cis"-Konfiguration kommen in seltenen Fällen in der Natur auch Fettsäuren mit "trans"-konfigurierten Doppelbindungen vor, die "trans"-Fettsäuren. Glyceride der "trans"-Fettsäuren fallen teilweise als unerwünschtes Nebenprodukt bei der Margarineherstellung an und stehen unter Verdacht, gesundheitsschädliche Eigenschaften zu haben. Insbesondere wird in der Literatur die negative Beeinflussung der koronaren Herzkrankheit angeführt.

Liegen mehrere Doppelbindungen – genauer C=C-Doppelbindungen – in einer Fettsäure vor, sind diese in der Regel – analog der oben rechts gezeigten Linolensäure – durch eine Methylengruppe ("CH-Gruppe") voneinander getrennt, man spricht dann von "Isolensäuren". Sind die Doppelbindungen durch zwei oder mehrere Methylengruppen voneinander getrennt, so nennt man diese speziellen Fettsäuren "bis"- oder polymethylen-unterbrochene oder nicht-methylen-unterbrochene "Isolensäuren" (NMI; Non-Methylene-Interrupted oder PMI; Poly-Methylene-Interrupted). 

Es existieren jedoch auch konjugierte Fettsäuren (Konjuensäuren), bei denen die Doppelbindungen enger beieinander, nämlich konjugiert vorliegen. In der Abbildung der Rumensäure Octadeca-9c,11t-diensäure liegen die Doppelbindungen konjugiert vor. Da eine der Doppelbindungen als "trans"-Doppelbindung vorliegt, ist diese Verbindung gleichzeitig eine "trans"-Fettsäure. Für die Bildung dieser Fettsäuren sind oft Bakterien im Verdauungstrakt der Wiederkäuer Ursache. Konjugierte Fettsäuren sind daher in allen Milchprodukten vertreten.
Fettsäuren mit einer ungeraden Anzahl von Kohlenstoffatomen besitzen geringe Bedeutung und entstehen unter anderem durch die α-Oxidation aus Fettsäuren mit geradzahligen Kohlenstoffatomen. Beim Menschen betrifft dies vor allem die Phytansäure und die Pristansäure, welche anschließend in der β-Oxidation zu Propionyl-CoA abgebaut wird.

 

Niedere Fettsäuren mit Verzweigungen in der Kohlenstoffkette finden sich in einigen Ätherischen Ölen. So enthalten die Extrakte aus Baldrian Ester der Isovaleriansäure.

Phytansäure (3,7,11,15-Tetramethylhexadecansäure) ist eine verzweigtkettige Carbonsäure, die als Abbauprodukt des Chlorophylls auftritt. In vielen Nahrungsmitteln (z. B. der Milch) sind Spuren dieser Verbindung zu finden. Die krankhafte Unfähigkeit zum Abbau dieser Carbonsäure führt zum Refsum-Syndrom.

Verzweigtkettige Fettsäuren finden sich in den Membranen zahlreicher Prokaryoten. Ihr Vorkommen wird genutzt, um eine Bakterienart zu identifizieren und um verwandtschaftliche Beziehungen der Organismen zu erforschen. Vor allem Fettsäuren mit einer Methylgruppe als Verzweigung in der Nähe vom „ω-Ende“ der Kohlenstoffkette sind von Bedeutung, wie die "iso"-Pentadecansäure (Methylgruppe am vorletzten Kohlenstoffatom) und die "anteiso"-Pentadecansäure (Methylgruppe am vorvorletzten Kohlenstoffatom). Sie kommen in geringen Mengen auch im Milchfett vor. Man geht davon aus, dass sie durch Bakterien im Pansen produziert werden und von den Kühen aufgenommen und in deren Fettgewebe bzw. im Milchfett eingelagert werden.


Fettsäuren mit einer Hydroxygruppe kommen in den Lipiden von Tieren, Pflanzen und Prokaryoten vor. Häufig findet sich die Hydroxygruppe am zweiten Kohlenstoffatom (vergleiche α-Hydroxycarbonsäuren). Auch β-Hydroxyfettsäuren kommen vor, ebenso wie Fettsäuren, bei denen die funktionelle Gruppe mitten in der Kohlenstoffkette vorkommt, wie bei der Rizinolsäure. Weitere funktionelle Gruppen mit einem Sauerstoffatom sind die Epoxygruppe, die Ketogruppe und die Furangruppe, die ebenfalls in Fettsäuren zu finden sind.

Fettsäuren in den Membranlipiden von Bakterien weisen zum Teil ungewöhnliche Bestandteile im Molekül auf. So weisen alicyclische Fettsäuren einen Ring aus Kohlenwasserstoffen auf. Dieser kann sich, als Cyclopropan, mitten in der Kohlenstoffkette befinden, wie dies bei den Mykolsäuren oder der Lactobacillsäure der Fall ist. Weiterhin können sie auch eine Ketogruppe aufweisen. Mykolsäuren sind außerdem die längsten natürlich vorkommenden Fettsäuren. Sie sind über Arabinogalaktan an das Murein in der Bakterienzellwand gebunden.

Ringe mit sechs oder sieben Kohlenstoffatomen (Cyclohexan bzw. Cycloheptan) finden sich häufig am Ende der eigentlichen Fettsäurekette, sie werden dann als "Omega-alicyclische" (ω-alicyclische) Fettsäuren bezeichnet, wobei der griechische Kleinbuchstabe ω als Lokant verwendet wird. Die Bakteriengattung "Alicyclobacillus" ist nach diesen Fettsäuren benannt worden, da sie diese in großen Mengen in den Membranlipiden enthält. Ein Beispiel ist die Omega-Cyclohexyltridecansäure, eine ω-alicyclische Fettsäure mit einem Cyclohexan-Rest und einer Kette mit 13 Kohlenstoffatomen.

Fettsäuren werden als Triglyceride im Fettgewebe gespeichert. Bei Bedarf, der durch die Botenstoffe Adrenalin, Noradrenalin, Glucagon oder ACTH angezeigt wird, findet dort eine Lipolyse statt.

Die freien Fettsäuren werden dann im Blutkreislauf zu den energiebenötigenden Zellen transportiert, wo sie zuerst unter ATP-Verbrauch an Coenzym A (CoA) gebunden (aktiviert) werden. Diese Reaktion wird durch die Hydrolyse des dabei entstehenden Pyrophosphats zu zwei Phosphaten (P) vorangetrieben.

Danach werden sie durch das Enzym Carnitin-Acyltransferase I an Carnitin gebunden und aktiv in die Matrix der Mitochondrien transportiert, wo sie durch Carnitin-Acyltransferase II wieder an CoA gebunden werden. Diese Aktivierung ist notwendig, da Fettsäuren durch die Mitochondriummembran diffundieren können. Nur aktiv transportierte Fettsäuren werden zur β-Oxidation der Fettsäuren herangezogen. Die Acyl-Carnitin-Aktivierung ist nicht reversibel, eine aktivierte Fettsäure wird abgebaut.

In der Matrix des Mitochondriums findet die β-Oxidation der Fettsäuren zu Acetyl-CoA statt, welches im Citratzyklus weiterverwendet werden kann, um ATP zu gewinnen. Bei längeren Hungerperioden oder Ernährung mit sehr wenig Kohlenhydraten, wie z. B. der Atkins-Diät, werden die Fette stattdessen zu Ketonkörpern verstoffwechselt.

Zusätzlich zur mitochondrialen Fettsäureoxidation findet auch in den Peroxisomen eine Verwertung von Fettsäuren statt. Vor allem sehr langkettige Fettsäuren werden meist dort zuerst verkürzt, ehe sie in den Mitochondrien weiterverarbeitet werden können. Diese peroxisomale Funktion ist erheblich. Ein Ausfall führt zu Adrenoleukodystrophie.

Die Fettsäuresynthese erfolgt im Gegensatz zum Abbau im Cytosol. Bei höheren Organismen sind alle dafür notwendigen Enzyme in einem einzigen Enzymkomplex, der Fettsäure-Synthase, zusammengefasst. Bei grünen Pflanzen jedoch findet der Aufbau bis höchstens zur C18-Fettsäure hauptsächlich in den Plastiden statt und wird dann erst ins Cytosol transportiert.

Dazu wird zuerst Malonyl-CoA aus Acetyl-CoA unter ATP-Verbrauch durch Carboxylierung gebildet. Dieses wird dann zu Malonyl-ACP umgewandelt, denn im Gegensatz zum Abbau dient bei der Synthese Acyl carrier protein (ACP) statt CoA als Carriermolekül. Die nachfolgende Kondensationsreaktion ist grob betrachtet eine Umkehr der Fettsäureoxidation (β-Oxidation). Jedoch finden sich im Detail einige bedeutende Unterschiede, die eine unabhängige, gezielte Steuerung beider Vorgänge erlauben.

Arttypisch vorkommende Fettsäuren können als Biomarker verwendet werden. Actinomyceten sind Gram-positive Bakterien, welche bei der Zersetzung von organischem Material vorkommen und unter anderem dabei einen erdigen Geruch erzeugen. Fettsäuren von Actinomyceten sind gelegentlich am C10 mit einer Methylgruppe verzweigt, z. B. 16:0 10-Methyl und 18:0 10-Methyl. Bodenlebende Actinomyceten sind z. B. "Rhodococcus, Nocardia, Corynebacterium" und "Streptomyces". Gram-positive Bakterien sind z. B. auch "Bacillus spp." wie "Bacillus cereus" und "Bacillus subtilis". Die Anzahl der Bakterien der "Bacillus spp." nimmt in der Rhizosphäre zu. Sie bilden verzweigte Fettsäuren wie 15:0 iso and 15:0 anteiso.

Gram-negative Bakterien sind ein bedeutender Bestandteil der Rhizosphäre und Erhöhen die Verfügbarkeit von Phosphat, Eisen und anderen Mineralien, manche produzieren auch Fungizide. Gram-negative Bakterien erzeugen höhere Konzentrationen an einfach ungesättigten Fettsäuren wie 16:1 Omega-7 und 18:1 Omega-9, die großteils zu Cyclopropyl-Fettsäuren wie 17:0 Cyclopropan und 19:0 Cyclopropan weiterverstoffwechselt werden. Unter anaeroben Bedingungen entstehen Dimethylacetale (DMA), die als Biomarker verwendet werden können. Bei strikt anaeroben Bedingungen, wie während einer Überflutung, nimmt die Anzahl fakultativ aerober Bakterien ab, die Anzahl der anaeroben Bakterien und Archaeen zu.

Die Fettsäuren in den Lipiden von Archaeen sind nicht über eine Esterbindung verbunden, sondern über eine Etherbindung. Mykorrhiza-Pilze bilden Speichervesikel, die unter anderem 18:2 (ω-6c) und 16:1 (ω-5c) enthalten.

Verschiedene Fettsäuren als Biomarker:






Sowohl gesättigte als auch ungesättigte Fettsäuren liefern viel Energie, unterstützen das Immunsystem, vermindern u. a. Depressionen und wirken sich auf viele weitere Stoffwechselprozesse positiv aus. Fette mit hohem Anteil an mittelkettigen Fettsäuren sind einfacher zu verdauen als solche mit langkettigen Fettsäuren.

Die Deutsche Gesellschaft für Ernährung (DGE) hat im Jahr 2010 in einer Auswertung von Interventionsstudien mit über 13.600 Teilnehmern herausgefunden, dass ein hoher Anteil mehrfach ungesättigter Fettsäuren, zusammen mit einem niedrigen Anteil gesättigter Fettsäuren, das Risiko für koronare Herzkrankheiten (z. B. Herzinfarkt) senkt. Sie bestätigte damit Ergebnisse, die Daniel und Hecht bereits 1990 veröffentlichten. Günstige Verhältnisse mehrfach ungesättigter zu gesättigter Fettsäuren finden sich vor allem in Pflanzenfetten: Distelöl (74,5 %/8,6 %), Hanföl (70 %/10 %), Sonnenblumenöl (60,7 %/11,5 %), Sojaöl (61,0 %/13,4 %) und Rapsöl (27 %/6 %). Ausnahmen bilden Kokos- und Palmkernfett (1,4 %/86,5 %).

Ungesättigte "trans"-Fettsäuren wirken sich ungünstig auf den Cholesterinspiegel aus. Insbesondere durch die Senkung des HDL-Cholesterol-Spiegels bei gleichzeitiger Erhöhung des LDL-Cholesterol-Lipoprotein(a)-Spiegels sowie "proinflammatorische" Effekte kommt es zu einem negativen Einfluss auf die endotheliale Funktion der Arterienwände. Auch gibt es Vermutungen auf eine Verstärkung von Insulin-Resistenz und Adipositas, Zellmembranveränderungen und negative Effekte auf die Blutgerinnung. Außerdem ist die Evidenz von Observationsstudien für einen Zusammenhang zwischen "trans"-Fettsäuren und erhöhtem Risiko für koronare Herzkrankheiten sehr überzeugend. Lebensmittel mit "trans"-Fettsäure-haltigen Triglyceriden sind in den Inhaltsangaben oft mit dem Vermerk „Pflanzliches Öl, teilweise gehärtet“ gekennzeichnet.

In Populationen, die im mediterranen Raum angesiedelt sind, beträgt die Zufuhr von einfach ungesättigten Fettsäuren zwischen 16 und 29 % der täglichen Gesamtenergiezufuhr (vor allem in Form von Ölsäure, z. B. Olivenöl). Untersuchungen zeigen, dass ein Austausch von gesättigten Fettsäuren durch Kohlenhydrate, mehrfach ungesättigte oder einfach ungesättigte Fettsäuren kardiovaskuläre Risikofaktoren reduziert. Im Vergleich zu Kohlenhydraten wirkten sich MUFAs positiv auf Triglyzeride, HDL-Cholesterin und das Verhältnis Gesamtcholesterin:HDL-Cholesterin aus. Zwei Metaanalysen zeigten kürzlich positive Auswirkungen einer erhöhten Zufuhr von einfach ungesättigten Fettsäuren auf folgende kardiovaskuläre Risikofaktoren: systolischer und diastolischer Blutdruck, glykiertes Hämoglobin (HbA1c) und "Nüchternglukose".

Die Omega-6-Fettsäuren (z. B. Linolsäure, Gamma-Linolensäure) und die Omega-3-Fettsäuren gehören zu den essentiellen Fettsäuren, da sie nicht vom menschlichen Organismus selbst hergestellt werden können. In Pflanzenölen kommt Linolsäure (Sonnenblumenöl, Sojaöl, Maiskeimöl) in recht hohen Konzentrationen (50–70 % bezogen auf den Gesamtfettsäureanteil) vor. Durch Dehydrierung und Kettenverlängerung kann der menschliche Organismus Linolsäure über mehrere Zwischenstufen bis zur Arachidonsäure umwandeln. Arachidonsäure kann im Körper weiter zu den Prostaglandinen umgewandelt werden. Lein- und Hanföl sind reich an Linolensäure, die Arachidonsäure wird nur in tierischen Produkten wie Leber, Eiern und Schmalz vorgefunden. Die essentiellen Fettsäuren sind am Aufbau von Zellmembranen beteiligt und senken den Blutfett- und Cholesterinspiegel.

Omega-6-Fettsäuren werden meist über die Arachidonsäure – aber nicht immer oder ausschließlich – zu entzündungsfördernden Prostaglandinen verstoffwechselt, Omega-3-Fettsäuren zu entzündungshemmenden.

Von der DGE wird empfohlen, etwa 30 % des Energiebedarfs mit Fett zu decken. 10 % sollte mit gesättigten Fettsäuren gedeckt werden, 10 bis 13 % mit einfach ungesättigten und der Rest mit mehrfach ungesättigten. Die amerikanische Herzgesellschaft (ADA), die europäische Behörde für Lebensmittelsicherheit (EFSA) sowie die amerikanische "Academy of Nutrition and Dietetics" empfehlen, weniger als 35 % des Energiebedarfs aus Fett zu beziehen, wobei die ADA eine Energiezufuhr von weniger als 20 % an einfach ungesättigten Fettsäuren empfiehlt. Um das Herz-Kreislauf-Risiko gering zu halten, sollte das Verhältnis von Omega-6- zu Omega-3-Fettsäuren maximal 5:1 betragen. Eine internationale Expertenkommission unter Leitung von "Berthold Koletzko" (Stiftung Kindergesundheit) hat Richtlinien für die Ernährung von Müttern und Babys entwickelt und veröffentlicht. Darin wird beschrieben, dass der heranwachsende Fötus vermehrt langkettige, mehrfach ungesättigte Fettsäuren, so genannte LC-PUFA (Longchain polyunsaturated fatty acid), benötigt. Insbesondere sind dies die Arachidonsäure (Omega-6-Fettsäure, AA) und die Docosahexaensäure (Omega-3-Fettsäure, DHA). Die genannten Fettsäuren sind in fetten Seefischen (z. B. Hering, Makrele und Lachs) enthalten.

Substituierte Fettsäuren mit Keto- und Hydroxygruppen sind in verdorbenen Ölen vorhanden. Sie sind teilweise für den menschlichen Organismus giftig. Eine weitere wichtige substituierte Fettsäure, die Ricinolsäure, ist im Ricinusöl zu etwa 80 % enthalten. Ricinusöl wird nicht im Darm aufgenommen und wirkt daher abführend.

Die moderne qualitative und quantitative Analytik der Fettsäuren in der Lebensmittelchemie und in der physiologischen Forschung bedient sich in der Regel der chromatographischen Verfahren. Zum Einsatz kommen die Kapillar-Gaschromatographie (nach Umesterung zum Methylester), die HPLC und die Kopplung dieser Verfahren mit der Massenspektrometrie. Meist werden die Fettsäuren in Form geeigneter Derivate, wie z. B. der Fettsäuremethylester oder ihrer TMS-Derivate, chromatographisch getrennt. In besonderen Fällen wird auch noch heute die klassische Säulen- und Dünnschichtchromatografie eingesetzt; so erfolgt die Trennung von Isomeren über Silbernitrat-Dünnschichtchromatographie.

Die Anzahl der unverzweigten Fettsäuren (einschließlich kürzerer Monocarbonsäuren) mit verschieden vielen Doppelbindungen an verschiedenen Positionen als Funktion der Kettenlänge gehorcht der in der Zahlentheorie sehr bekannten Fibonacci-Folge. Das folgt unter anderem daraus, dass (bis auf seltene Ausnahmen) bei Fettsäuren keine benachbarten Doppelbindungen auftreten. Speziell gibt es nur eine aliphatische Monocarbonsäure mit einem C-Atom: Ameisensäure, eine mit zwei C-Atomen: Essigsäure, zwei mit dreien: Propionsäure und Acrylsäure, usw. Bei 18 C-Atomen ergeben sich 2.584 Varianten (wovon Stearinsäure, Ölsäure, Linolsäure und Linolensäure vier Beispiele sind).





</doc>
<doc id="10799" url="https://de.wikipedia.org/wiki?curid=10799" title="Juan Gris">
Juan Gris

Juan Gris (* 23. März 1887 in Madrid; † 11. Mai 1927 in Boulogne-sur-Seine, Frankreich; eigentlich "José Victoriano Carmelo Carlos González-Pérez") war ein spanischer Maler.

Neben Pablo Picasso und Georges Braque ist er der Hauptvertreter des synthetischen Kubismus. Gris malte vornehmlich Stillleben, in denen er Bildelemente als Collage neben- und übereinandersetzte. Gris fügte die neuen Gestaltungsprinzipien des Kubismus in ein rationales System ein und war zeit seines Schaffens bemüht, sein künstlerisches Vorgehen auch theoretisch zu vermitteln.

Juan Gris, Sohn eines wohlhabenden Kaufmanns, wurde am 23. März 1887 als José Victoriano González Pérez in Madrid geboren. Er war das dreizehnte von vierzehn Kindern. Bereits in seinen ersten Lebensjahren unterrichtete ihn der Onkel in der Technik des Malens. 1902 begann er sein Studium an der Kunsthochschule "Escuela de Artes y Manufacturas" in Madrid. 1904 beendete er das Studium und begann eine Künstlerausbildung bei seinem engen Freund José Moreno Carbonero, der später Lehrer von Salvador Dalí wurde. Bereits zu dieser Zeit malte er einige Bilder, die sich am Jugendstil orientierten. Seinen Lebensunterhalt verdiente er mit Buchillustrationen zu Gedichten von José Santos Chocanos. Seine Werke signierte er mit dem Künstlernamen „Juan Gris“.

1906 verließ Gris im Alter von 19 Jahren Spanien und zog nach Paris. Dort hielt er sich mit Karikaturen für satirische Zeitschriften über Wasser, zwei Jahre später zog er ins Bateau-Lavoir. Die Ateliers des Bateau-Lavoir waren zu dieser Zeit ein Sammelpunkt für viele junge Maler und Literaten. Gris traf dort auf Pablo Picasso; von dessen Studien angeregt, wandte er sich wiederum der Malerei zu.
Gris konzentrierte sich von nun an auf den analytischen Kubismus. 1911 entstanden seine ersten Werke, so unter anderem "Häuser in Paris", die erste kubistische Züge aufweisen. Seine erste Ausstellung mit 15 Werken hatte er bei Clovis Sagot. Noch im selben Jahr schloss Gris Freundschaft mit dem deutschen Kunsthändler Daniel-Henry Kahnweiler, der Gris unter Vertrag nahm und ihm so Ausstellungsflächen für seine Kunstwerke in Museen und Ausstellungen garantierte. 1912 malte Gris ein Porträt von Pablo Picasso.

1913 begann Gris’ Periode des synthetischen Kubismus. Aus der Auseinandersetzung mit dem Werk Picassos und Braques entstanden seine ersten synthetischen Werke. Elemente wie Zeitungspapier, Tapeten und Scherben fügte er in seine Werke ein. Nach dem Vorbild Braques und Picassos fertigte er seine ersten "Papiers collés", eine Frühform des Collage-Verfahrens. Im Jahr 1914 traf Gris bei einem Aufenthalt in Südfrankreich erstmals auf den Maler, Bildhauer und Grafiker Henri Matisse, der seine Maltechnik stark beeinflusste und verfeinerte. Seit dieser Zeit fand Gris zu einer eigenen Bildsprache, in der seine Ausdrucksweise gefestigt scheint. Amedeo Modigliani schuf im Jahr 1915 ein Porträt von Gris.
Rückblickend auf seine Anfänge äußerte der Theoretiker Gris in seinem 1925 veröffentlichten Aufsatz "Chez les cubistes" im "Bulletin de la Vie Artistique":

Im Jahr 1916 begann Gris’ architektonische Phase, in der er bei seinen Bildern mehr Wert auf die Formen als auf die Farben legte. Durch die im Jahr darauf folgende Bekanntschaft mit dem französischen Bildhauer Jacques Lipchitz begann Gris neben seiner Malerei mit dem Formen von Skulpturen. Ab den 1920er Jahren wurde Gris’ Stil poetischer. Er brachte Stillleben und Landschaften in einer Bildebene zusammen. Für die Umrissgestaltung verwendete er nun häufig eine Wellenform, die beispielsweise in seinen Pierrot- und Harlekindarstellungen sichtbar werden. Gris arbeitete nun auch häufig für das Theater und schuf unter anderem Kostüme und Dekorationen für Djagilews "Ballets Russes" sowie für Charles Gounods Oper "La Colombe". Weiterhin war er ein gefragter Buchillustrator.

1925 erkrankte Juan Gris schwer, sein Zustand verschlechterte sich schnell. Am 11. Mai 1927 starb er in Paris vierzigjährig an einer Harnvergiftung. Einige seiner Werke wurden postum auf der documenta 1 (1955), der documenta II (1959) und der documenta III im Jahr 1964 in Kassel gezeigt. Juan Gris wurde in der Pariser Freimaurerloge "Voltaire" in den Bund der Freimaurer aufgenommen.





</doc>
<doc id="10800" url="https://de.wikipedia.org/wiki?curid=10800" title="Buttersäure">
Buttersäure

Buttersäure ist der Trivialname der Butansäure, einer Carbonsäure und gleichzeitig der einfachsten Fettsäure. Sie entsteht in der Natur durch Buttersäuregärung. Ihre Dämpfe reizen die Augen sowie die Atemwege. Die Salze (siehe unten) und Ester (siehe Buttersäureester) der Buttersäure heißen Butyrate (systematisch auch Butanoate).

Die Buttersäure wurde 1814 von Eugène Chevreul unter den Verseifungsprodukten der Butter entdeckt und sorgfältig beschrieben. Die Herkunft aus dem Butterfett und der Geruch nach Butter (lateinisch "butryum") führten zum Namen der Säure. Théophile-Jules Pelouze beschrieb 1843 sie und ihre Reaktionen genauer und nannte dabei folgende Eigenschaften:

„Die Buttersäure ist eine vollkommen farblose Flüssigkeit, durchsichtig, in hohem Grade beweglich, sie besitzt einen Geruch, welcher gleichzeitig an Essigsäure und kräftige Butter erinnert. Sie ist in allen Verhältnissen, im Wasser, im Alkohol und Holzgeist löslich. Bei gewöhnlicher Temperatur siedet sie bei 164° und destilliert ohne bemerkliche Veränderung. Ihr Dampf ist entzündlich und brennt mit blauer Flamme […] ihr Geschmack ist stark sauer und brennend. Sie greift die Haut an und zerstört sie, wie die stärksten Säuren.“

Buttersäure macht im Wesentlichen den unangenehmen Geruch von Erbrochenem oder von ranziger Butter aus. Buttersäure trägt auch zum Schweißgeruch und in manchen Fällen zum Mundgeruch bei.

Da die Buttersäure unter aneroben Bedingungen durch Buttersäurebakterien aus Kohlenhydraten gebildet wird, kommt sie in Lebensmitteln vor, zu deren Zubereitung Gärprozesse notwendig sind. Also z. B. Käse, Sauerkraut, Bier und Brot, sie kommt auch in Milch, Fleischsaft und Schweiß, sowie in Holzessig vor. Sie kommt auch in einigen Pflanzenlipiden, meistens in geringer Konzentration vor. Die ursprüngliche Annahme, dass die übelriechende, scharfe und ätzende Flüssigkeit, die verschiedene Arten der Laufkäfer (Carabidae) wie die Echten Laufkäfer ("Carabus" spp.) zur Abwehr aus der Pygiadialdrüse versprühen, Buttersäure enthält, wurde in späteren Untersuchungen relativiert.

Im menschlichen Dickdarm entsteht Buttersäure, vor allem beim Abbau von präbiotischen Kohlenhydraten durch Darmbakterien. Durch die damit verbundene pH-Wert-Verschiebung in den sauren Bereich wird das Milieu für Salmonellen und andere Krankheitserreger ungünstig. Buttersäure scheint darüber hinaus direkt die Darmbewegungen anzuregen und dient den Epithelzellen des Dickdarms als Energiequelle.

Der Geruch von Buttersäure kann von Menschen und Tieren in kleinen Spuren wahrgenommen werden. Für den Menschen sind bereits Konzentrationen ab 0,06 mg pro Kubikmeter wahrnehmbar. Der Mensch bewertet den Geruch negativ, die Stubenfliege dagegen positiv. Zecken dient der Geruch von Buttersäure zum Auffinden ihrer Wirte. Buttersäure wird unter anderem dazu verwendet, Tiere mit feinem Geruchssinn zu vertreiben, beispielsweise Maulwürfe.

Buttersäure ist neben Propionsäure, Schwefelwasserstoff und flüchtigen schwefelhaltigen organischen Verbindungen (Methanthiol, Dimethylsulfid) ein Verursacher von Mundgeruch beim Menschen.

Da die Entstehung von Buttersäure ein Zeichen von Fäulnis darstellt, dient ihre Geruchswahrnehmung als Warngeruch. Der Geruch von Buttersäure kann mit Basen, wie Natronlauge, Lösungen von Carbonaten usw. vermindert werden. Dabei bilden sich geruchlose Butyrate.

"Butyrate" (systematisch auch "Butanoate") ist neben einer Bezeichnung für Buttersäureester auch die Bezeichnung für die Salze der Buttersäure. Diese bestehen aus Butyrat-Anionen CHCOO und einem Kation. Beispiele sind Natriumbutyrat (NaCHCOO), Magnesiumbutyrat [Mg(CHCOO)] und Ammoniumbutyrat (NHCHCOO). Bei Feuchtigkeit besitzen sie den gleichen charakteristischen Geruch wie Buttersäure. Wird ein Butyrat-Salz mit einer stärkeren Säure behandelt, entsteht wiederum Buttersäure.

Die Ester der Buttersäure haben in vielen Fällen einen Geruch nach Früchten und kommen in vielen Fruchtaromen natürlich vor.



</doc>
<doc id="10801" url="https://de.wikipedia.org/wiki?curid=10801" title="Sarkom">
Sarkom

Das Sarkom (v. griech. "σάρκωμα", "sárkoma", zu σάρξ, "sárx" „Fleisch“, „Weichteile“ und "-om" „Geschwulst“) ist ein bösartiger Tumor, der von mesenchymalem Gewebe ausgeht und frühzeitig in die Blutgefäße ("hämatogen") metastasiert.

Zusammen mit den malignen Tumoren des Deckepithels (Karzinom) und den Erkrankungen des Blutes und Knochenmarks (Leukämie und Lymphom) gehören Sarkome in die Gruppe der malignen Tumorerkrankungen (Krebserkrankungen). Sarkome sind viel seltener als Karzinome und machen nur etwa 1 % aller malignen Erkrankungen beim Menschen aus. Der genaue Ursprung der Sarkome ist das Binde- und Stützgewebe (Knochen, Knorpel und Fettgewebe) oder das Muskelgewebe.

Sarkome werden nach der aktuellen WHO-Klassifikation in etwa 100 verschiedene Entitäten unterteilt. Diese unterscheiden sich nach ihrer (teilweise) vermuteten Zellabstammung, ihren molekulargenetischen Veränderungen, ihrer Morphologie und ihrer Biologie.
Die genaue Einordnung eines Sarkoms in die zutreffende diagnostische Gruppe hat jedoch große Bedeutung für die weitere Behandlung, da die einzelnen Entitäten ein unterschiedlich großes Risiko für das Auftreten von Rezidiven und Tochtergeschwülsten (Metastasen) haben. Sarkome metastasieren überwiegend auf dem Blutweg.





</doc>
<doc id="10802" url="https://de.wikipedia.org/wiki?curid=10802" title="Karzinom">
Karzinom

Ein Karzinom [] (von griech. "karkínos", „Krebs“, und "karkínoma", „krebsartige Krankheit“) ist eine Krebserkrankung, die von Zellen im Deckgewebe von Haut oder Schleimhaut (Epithel) ausgeht. Genauer ist es eine ektodermale oder entodermale Neubildung; daraus ergibt sich eine weitere Differenzierung je nach Art des entarteten Epithels. Die meisten Karzinome gehen vom Plattenepithel ("Plattenepithelkarzinom" oder squamöses Karzinom) oder vom Drüsenepithel ("Adenokarzinom") aus. Die primäre lymphogene Metastasierung ist besonders bei Karzinomen anzutreffen.

Karzinome machen circa 80 % aller bösartigen Tumoren aus. Das Stadium beschreibt man mit der TNM-Klassifikation. Als Therapie kommen operative Entfernung, Strahlen- und Chemotherapie, in sehr frühen Stadien auch oberflächliche Abtragungen in Frage. Die alternative medizinische Schreibweise ist "Carcinom".




</doc>
<doc id="10805" url="https://de.wikipedia.org/wiki?curid=10805" title="Epithel">
Epithel

Das Epithel [] ( "epí" ‚auf‘, ‚über‘ und "thēlē" "Mutterbrust", "Brustwarze") ist eine biologische Sammelbezeichnung für Deckgewebe und Drüsengewebe. Es handelt sich um ein- oder mehrlagige Zellschichten, die alle inneren und äußeren Körperoberflächen der vielzelligen Organismen bedecken (Ausnahme: Gelenkkapseln und Schleimbeutel des Bewegungsapparates).

Das Epithel ist neben Muskel-, Nerven- und Bindegewebe eine der vier Grundgewebearten.

Epithelien sind durch die Basalmembran klar vom Bindegewebe getrennt und enthalten keine Blutgefäße.

Eine weitere allen Epithelzellen gemeinsame Eigenschaft ist ihre Polarität:
Die Polarität von Epithelzellen ist zudem durch strukturelle und funktionelle Unterschiede von apikaler und basaler Membran der Epithelzellen geprägt. Man spricht in diesem Zusammenhang auch von einer apikalen und basolateralen Domäne.

Des Weiteren besitzen Epithelzellen einen "Haftkomplex" ("Schlussleistenkomplex") bestehend aus Zonula occludens ("Tight junction"), Zonula adhaerens ("Adhaerens junction") und Desmosom ("Macula adhaerens"). Der Haftkomplex stellt zum einen eine physikochemische Barriere dar und verbindet zum anderen angrenzende Epithelzellen miteinander.

Die Zellen liegen dicht beieinander und sind reich an Zellkontakten. Demzufolge besitzt das Gewebe nur kleine Interzellularräume mit entsprechend wenig Interzellularsubstanz.
Mit Hilfe der Emperipolesis durchdringen andere Zellen die Epithelien.

Epithelien sind auf vielfältige Weise und je nach Organ spezifisch differenziert. Zunächst kann man Oberflächenepithelien und Drüsenepithelien unterscheiden:

Für die Unterscheidung der zahlreichen Epitheltypen hat es sich bewährt, zwei Merkmale hervorzuheben: die Zahl der Zellschichten und die Form der Zellen in der oberflächlichen Zellschicht (siehe unten).

Auch das mehrreihige Epithel ist noch einschichtig, alle Zellen sind wie beim einschichtigen Epithel auf der Basallamina verankert, aber nicht alle erreichen das Lumen. Hochprismatische Zellen erfüllen die eigentliche Funktion, während kleine "Basalzellen" als Reserve für untergegangene Zellen bereitstehen. Die Zellkerne liegen so in unterschiedlicher Höhe und bilden dadurch scheinbare Schichten (Reihen).

Im mehrschichtigen Epithel liegen viele (mehr als zehn) Zellschichten übereinander. Es lässt sich grundsätzlich eine Dreiteilung vornehmen: In der basalen Schicht, die an der Basallamina verankert ist, finden Zellteilungen statt. Die Zellen steigen auf und differenzieren in einer Mittel- oder Intermediärschicht auf spezifische Weise. Schließlich erreichen sie die Oberflächen- oder Superfizialschicht.


Als Übergangsepithel („Urothel“) wird ein spezielles, je nach Blasenfüllung (respektive Dehnung des Urothels) mehrreihig bis mehrschichtiges Epithel der Harnwege (Nierenbecken, Harnleiter, Harnblase) bezeichnet. Hierbei sind besonders die Deck-/Schirm-/ umbrella cells von großer Bedeutung. Sie bilden die sogenannte Crusta, welche die Aufgabe des Harnsäureschutzes hat. Im Gegensatz zum Plattenepithel zeigt sich die obere Zellschicht eher kubisch.

Das Epithel erfüllt im Grunde zwei verschiedene Schutzfunktionen: Zum einen der rein mechanische Schutz vor allem durch die mehrschichtigen Epithelien. So muss die Epidermis der Haut ausreichende Reißfestigkeit besitzen und darf sich nicht vom darunterliegenden Bindegewebe ablösen.
Zum anderen muss das Epithel die inneren Körperöffnungen abdichten: Magen- und Darminhalt müssen kontrolliert verwertet werden (hochprismatisches Epithel), der Urin muss in Blase und Harnleiter bleiben (Übergangsepithel), die Blut-Hirn-Schranke muss gewahrt bleiben (Kapillarendothel). Natürlich müssen auch hier mechanische Belastungen ausgehalten werden, entscheidend für die Abdichtung sind aber die Tight junctions, die in solchen Zellen vermehrt auftreten.

Unter Resorption versteht man den Transport von genau bestimmten Stoffen von apikal nach basal. Das klassische Beispiel ist die Resorption von Nährstoffen in der Darmschleimhaut. Die apikalen Oberflächen sind häufig differenziert, so kann eine Epithelienzelle ihre Oberfläche beispielsweise durch die Ausbildung zahlreicher Mikroplicae (Einfaltungen) oder Mikrovilli vergrößern. Die genauen Mechanismen (Transport, Phagozytose, Pinozytose, Lysosomen) sind Gegenstand anderer Artikel.

Sämtliche Sekretionsvorgänge des Körpers geschehen von den Drüsenepithelien aus. Dementsprechend gibt es hier eine große Vielfalt, von der einzelnen Becherzelle der Darmschleimhaut über die Schweißdrüsen der Haut bis hin zu ganzen Organen wie den Speicheldrüsen oder der Bauchspeicheldrüse. Drüsen sind Organe aus spezialisierten Epithelzellen; sie dienen der Sekretion.
Man unterscheidet:

Auch den Sekretionsweg kann man unterscheiden, also
wobei die letzten nach der Zusammensetzung des Sekrets unterteilt werden in

Außerdem unterscheidet man intraepitheliale und extraepitheliale Drüsen:

Ein Großteil der menschlichen Sinneszellen ist in epitheliale Zellverbände eingebettet. Diese Konstruktion bietet sich an, da Epithelien als oberflächliche Zelllagen naturgemäß eine vermittelnde Position zwischen Innen und Außen einnehmen. Beispiele:

Manche Epithelien besitzen zusätzlich Flimmerhärchen auf ihrer Oberfläche, welche eine Transportfunktion haben. Sie können mit ihrem kräftigen Schlag Fremdkörper aus dem Organismus ausschleusen.



</doc>
<doc id="10811" url="https://de.wikipedia.org/wiki?curid=10811" title="KZ Sachsenhausen">
KZ Sachsenhausen

Das Konzentrationslager Sachsenhausen (kurz "KZ Sachsenhausen") war ein ab 1936 eingerichtetes nationalsozialistisches deutsches Konzentrationslager. Es befand sich im Ortsteil Sandhausen der Stadt Oranienburg nördlich von Berlin.

Durch die Nähe zu Berlin und damit auch zur Gestapozentrale in der Prinz-Albrecht-Straße hatte dieses Lager eine Sonderrolle im KZ-System. Ein großes SS-Kontingent war hier stationiert. Das Lager diente als Ausbildungsort für KZ-Kommandanten und das Bewachungspersonal im ganzen NS-Machtbereich (ähnlich wie das KZ Dachau). Insgesamt wurden etwa 200.000 Häftlinge nach Sachsenhausen deportiert, nur etwa 140.000 davon wurden registriert. Im August 1941 wurde eine Massenerschießungsanlage errichtet, in der etwa 13.000 bis 18.000 sowjetische Kriegsgefangene ermordet wurden. Insgesamt sollen mehrere zehntausend Häftlinge ermordet worden sein.

Das KZ Sachsenhausen ist weder örtlich noch zeitlich identisch mit dem KZ Oranienburg, das 1933 bis 1934 in Oranienburg in der Nähe des Stadtzentrums bestand.

Das Konzentrationslager Sachsenhausen wurde seit dem Hochsommer 1936 auf Befehl Heinrich Himmlers durch Häftlinge der aufgelösten Lager Esterwegen, Berlin-Columbia und Lichtenburg erbaut. Obwohl es nach der nordwestlich angrenzenden, damals selbstständigen Gemeinde Sachsenhausen benannt wurde, befand sich das Konzentrationslager auf dem Gebiet des Ortsteils Sandhausen der Stadt Oranienburg.

Das KZ Sachsenhausen nahm eine Sonderrolle unter den nationalsozialistischen Konzentrationslagern ein. Es war der erste große KZ-Komplex, der von einem SS-Architekten geplant wurde. Himmler hatte ihm den Auftrag erteilt, mit Sachsenhausen ein „vollkommen neuzeitliches, modernes und jederzeit erweiterbares“ Lager zu errichten. Der SS-Architekt Bernhard Kuiper entwarf ein gleichseitiges Dreieck, in dessen Fläche er das Häftlingslager, die Kommandantur sowie das SS-Truppenlager unterbrachte. Die Architektur des Häftlingslagers folgte einer „Geometrie des totalen Terrors“. Vom Wachturm A aus sollte ein einziges Maschinengewehr die in vier Ringen um den halbkreisförmigen Appellplatz herum gruppierten 68 Häftlingsbaracken ungehindert erreichen können. Das Lager wurde nach dem Modell einer panoptischen Anlage konstruiert. Es zeigte sich jedoch schon bald, dass anders als von Himmler erwünscht die panoptische Anlage nicht beliebig erweiterbar war. Deshalb fand dieses Modell in keinem weiteren Lager seine Fortsetzung.

Im Schutzhaftlager befand sich eines der drei von der Schutzstaffel betriebenen Übungslager. Dort erfolgte nicht nur die Ausbildung von SS-Wachmannschaften, die später in anderen Konzentrationslagern eingesetzt wurden, sondern hier fand auch die regelmäßige vor- und nachmilitärische Schulung der Allgemeinen SS statt. Seit 1938 befand sich dort auch der Inspekteur der Konzentrationslager und der Führer der SS-Totenkopfverbände, dem die zentrale Verwaltung aller Konzentrationslager des „Dritten Reiches“ unterstellt war.

In etwa 100 KZ-Außenlagern leisteten Häftlinge Zwangsarbeit, vor allem in der Rüstungsindustrie. Im Sommer 1945 diente das Revier des ehemaligen KZ Sachsenhausen als Übergangs-Lazarett für ehemalige Häftlinge und andere Opfer des Krieges, die auf Grund ihres Gesundheitszustandes nicht in die Heimat zurückkehren konnten.

Ab August 1945 wurde das Gelände des KZ Sachsenhausen von der Sowjetischen Militäradministration (SMAD) als "Speziallager Nr. 7" verwendet. In diesem sowjetischen Gefangenenlager wurden Sozialdemokraten, NS-Funktionäre der unteren und mittleren Ebene, Angehörige der Wehrmacht, Jugendliche unter „Werwolf-Verdacht“, Gegner der neuen politischen Ordnung und zum Teil völlig willkürlich Verhaftete interniert. Die DDR schloss das 1948 in "Speziallager Nr. 1" umbenannte Lager 1950 als letztes der Speziallager. Die Kasernierte Volkspolizei übernahm das Gelände im selben Jahr und nutzte einen Teil davon als Kaserne.

1961 wurde die "Nationale Mahn- und Gedenkstätte Sachsenhausen" eröffnet und später mehrfach erweitert. Sie gehört heute als "Gedenkstätte und Museum Sachsenhausen" zu den Gedenkstätten von nationaler und internationaler Bedeutung in Deutschland.

Seit 2006 nutzt die Fachhochschule der Polizei des Landes Brandenburg einen Teil des ehemaligen SS-Truppenlagers des Lagerkomplexes.

Das KZ Sachsenhausen wurde im Sommer 1936 von Häftlingen aus den Emslandlagern errichtet. Diese Aufbauphase wurde in einem viele Jahre später entdeckten Fotoalbum des Kommandanten Karl Otto Koch penibel dokumentiert.

Die von SS-Architekten am Reißbrett als idealtypisches KZ konzipierte Anlage sollte dem Weltbild der SS architektonisch Ausdruck geben und die Häftlinge auch symbolisch der absoluten Macht der SS unterwerfen. Das Häftlingslager wurde in Form eines gleichschenkligen Dreiecks angelegt. Alle Gebäude waren symmetrisch um die Mittelachse gruppiert und auf den Turm A, den Sitz der SS-Lagerleitung, auf der Mitte der Grundlinie des Dreiecks bezogen. Vor diesem Turm lag der halbkreisförmige Appellplatz, der wiederum von vier Ringen fächerförmig angeordneter Baracken umschlossen wurde. Um die Fortsetzung der Mittelachse über den Turm A und die Lagerstraße hinaus wurde das SS-Truppenlager angelegt, in dem die Axialität und Symmetrie des Häftlingslagers und des Kommandanturbereichs sich fortsetzte. Zum 388 Hektar umfassenden SS-Komplex in Oranienburg gehörten darüber hinaus umfangreiche Wohnsiedlungen für die höheren SS-Dienstgrade und ihre Familien sowie das ab 1938 an der Lehnitzschleuse errichtete Außenlager Klinkerwerk (Lehnitz; Einsatzort der Strafkompanien und Lagerbereich „Isolierung“; dort standen ab 1941 zehn Häftlingsbaracken).

Zwischen 1936 und 1945 waren im KZ Sachsenhausen mehr als 200.000 Menschen aus ca. 40 Nationen inhaftiert. Häftlinge waren zunächst politische Gegner des NS-Regimes, dann in immer größerer Zahl Angehörige der von den Nationalsozialisten als rassisch und/oder sozial minderwertig erklärten Gruppen (Juden, Homosexuelle, „Zigeuner“, sogenannte „Asoziale“), die dem Regime hauptsächlich wegen ihrer Ablehnung des Militärdienstes verhassten Zeugen Jehovas und ab 1939 zunehmend Bürger der besetzten Staaten Europas. Zehntausende kamen durch Hunger, Krankheiten, Zwangsarbeit und Misshandlungen um. Andere wurden Opfer systematischer Vernichtungsaktionen. So wurden hier im Herbst 1941 mindestens 12.000 sowjetische Kriegsgefangene ermordet. Die beteiligten SS-Männer erhielten anschließend einen mehrwöchigen Italien-Urlaub. Weitere Häftlinge starben an den Folgen medizinischer Experimente. So wurden ihnen unter anderem schwere Wundinfektionen zugefügt, um die Wirkung von Medikamenten zu testen. Kinder wurden mit Hepatitis B infiziert, um Erkenntnisse über die Veränderungen an der Leber zu gewinnen.

Der Zellenbau wurde 1936 als T-förmiges Gebäude errichtet, das mit 80 Zellen für Einzelhaft, Dunkelarrest und Massenunterbringung als Lagergefängnis und Sondergefängnis der Gestapo diente. Im vom übrigen Lager isolierten Hof des Zellenbaus dienten ein Erdbunker und Vorrichtungen zum „Pfahlhängen“ sowie der sogenannte „Bock“ dem Vollzug besonders brutaler Strafen.

Das Krematorium befand sich auf dem durch die Lagermauer vom Häftlingslager abgetrennten Industriehof und wurde ab Herbst 1939 eingesetzt. 1942 wurde das provisorische Krematorium durch einen Neubau mit Krematorium und Genickschussanlage ersetzt, in dem 1943 auch eine Gaskammer eingerichtet wurde. In dem 11 Quadratmeter großen Raum konnten zu einem Zeitpunkt maximal 60 Personen ermordet werden. In der Gaskammer wurden neue Vergasungstechniken erprobt.

In der Kantine und im Lagerbordell konnten Gutscheine eingelöst werden, die in manchen der Werkstätten oder als Funktionshäftling erarbeitet werden konnten.

Um neue Häftlinge unterbringen zu können, wurde in Abweichung vom „Idealplan“ im Sommer 1938 das „kleine Lager“ als Barackenkomplex errichtet, in dem bis zu ihrer Deportation nach Auschwitz im Oktober 1942 die meisten der jüdischen Häftlinge untergebracht waren.

Auf der 1940 auf dem Appellplatz angelegten Schuhprüfstrecke mit unterschiedlichen Bodenbelägen mussten Häftlinge des Schuhläufer-Kommandos durch Marschieren von bis zu 40 km am Tag Sohlenmaterial für die deutsche Lederindustrie testen.

Von 1942 bis 1945 mussten im KZ Sachsenhausen bis zu 144 jüdische Häftlinge unter Zwang ausländische Währungen, vor allem englische Pfundnoten, in Milliardenhöhe für die Aktion Bernhard fälschen. Dafür wurde im sogenannten „kleinen Lager“ in zwei Baracken die „Fälscherwerkstatt“ eingerichtet.

Am 27. März 1944 entdeckte die SS im KZ Sachsenhausen, dass der Häftling Friedrich Büker Radio Moskau abhörte und die Nachrichten auf Flugblättern verteilte. Daraufhin versuchte eine Sonderabteilung des Reichssicherheitshauptamtes mit Verhören und Spitzeln, die internationale Widerstandsorganisation im Lager zu zerschlagen. Obwohl innerhalb eines halben Jahres lediglich eine Solidaritätsaktion deutscher Kommunisten nachgewiesen werden konnte, sollten 27 Häftlinge vor allen Lagerinsassen erhängt werden. Aus Angst vor Unruhe wurde der Plan jedoch geändert und 24 deutsche und drei französische Häftlinge am Abend des 11. Oktober 1944 nach dem Zählappell in der „Station Z“ erschossen. 102 weitere Häftlinge wurden am 20. Oktober in das KZ Mauthausen abgeschoben.

Als Modell- und Schulungslager der SS und Konzentrationslager in unmittelbarer Nähe der Reichshauptstadt nahm Sachsenhausen eine Sonderstellung im System der nationalsozialistischen Konzentrationslager ein. Diese wurde unterstrichen, als 1938 die Inspektion der Konzentrationslager, die Verwaltungszentrale für alle Konzentrationslager im deutschen Machtbereich, von Berlin nach Oranienburg verlegt wurde. Die Inspektion der Konzentrationslager und die Führung der SS-Totenkopfverbände zogen im August 1938 in ein großes Stabsgebäude südlich des KZ Sachsenhausen, das wegen seiner charakteristischen dreiflügeligen Form „T-Gebäude“ genannt wird. Die Inspektion war für die Lebensbedingungen der Häftlinge im Lager verantwortlich. Sie legte grundsätzlich und in Einzelfällen fest, in welches Lager die Häftlinge kamen, welche Zwangsarbeit sie zu leisten hatten und welche Nahrungsration sie erhielten.

Häftlinge wurden zunächst in SS-eigenen Werkstätten und Betrieben des dem Häftlingslager benachbarten Industriehofes zur Arbeit eingesetzt, wo sich eine Schneiderei, Tischler-, Schlosser- und Elektrikerwerkstätten befanden. Vor allem im Zuge des massenhaften Einsatzes der Zwangsarbeit von KZ-Häftlingen in der Rüstungsindustrie ab 1942 entstanden mehr als 100 KZ-Außenlager und Außenkommandos des KZ Sachsenhausen in der Nähe der Rüstungsbetriebe und bei Berliner Industriebetrieben wie Siemens, DEMAG-Panzer, Henschel-Werke Berlin, Daimler-Benz, I.G. Farben und AEG sowie BRABAG Schwarzheide. Mit dem Begriff „Außenkommando“ sind die Gruppen oder Kolonnen von Häftlingen gemeint, die vom Lager aus zu einer Fabrik oder einem sonstigen Arbeitseinsatz marschieren mussten, abends dann aber wieder im Hauptlager nächtigten. Das geschah oft über Wochen und Monate. Die Zusammensetzung der Gruppe hing vom Arbeitsanfall und der körperlichen Verfassung der Gefangenen ab. Krankheit oder Arbeitsunfall kam oft einem Todesurteil gleich, weil Arbeitsunfähige in Sammeltransporten immer wieder nach Auschwitz weggeschafft wurden.

Außenlager hingegen waren Lager, in denen die Häftlinge arbeiteten und auch dort wohnten. Sie hatten unterschiedliche Größe und zählten zum Stammlager, wurden von dort aus mit verwaltet. Auch sie dienten überwiegend der „Lieferung“ von Häftlingen an Produktionsbetriebe. Zum Teil fand die Unterbringung direkt auf dem Fabrikgelände statt, zum Teil marschierten von einem Außenlager sternförmig die Häftlingskolonnen zu verschiedenen Fabriken in der Umgebung.

Von Mai 1936 bis Mai 1937 wurden die Heinkel-Werke Oranienburg in Oranienburg-Annahof und Germendorf errichtet, da das Stammwerk in Rostock-Marienehe ausgelastet war. In diesem Werk bestand spätestens ab März 1943 ebenfalls ein Außenlager, in dem bis zu 6000 Häftlinge aus dem KZ Sachsenhausen arbeiten mussten. Erster Lagerleiter war der SS-Hauptsturmführer Johannes Hassebroek. Ab September 1944 übernahm das KZ Sachsenhausen das KZ-Außenlager Velten vom KZ Ravensbrück. Dort mussten Frauen Zwangsarbeit für die Ikaria/Veltener Maschinenbau und die Havelschmelzwerk GmbH leisten.

Die "Mordfabrik" des KZ Sachsenhausens war das Klinkerwerk, ein Großziegelwerk mit eigenem Hafen an der Lehnitzschleuse. Hier wurden Ziegel für Albert Speers Großbauvorhaben in Berlin produziert, dem Aufbau der Reichshauptstadt Germania. Die Häftlinge selbst hatten Fabrik und Hafenanlage außerhalb des Hauptlagers zu bauen. Später kam ein eigenes Häftlings-Außenlager hinzu.

Von Juli bis September 1942 fielen hier fast alle damaligen Rosa-Winkel-Häftlinge einer gezielten Mordaktion der SS zum Opfer. Der ehemalige Lagerälteste Harry Naujoks berichtet in seinen Erinnerungen von der Ermordung von 200 Homosexuellen und Amtsanmaßern. Der ehemalige Häftling Emil Büge notierte die Namen von 89 Häftlingen, die in den sechs Wochen ermordet wurden.

Der Opfer der Mordaktion von 1942 wurde am 30. Juni 2002 und am 26. August 2007 mit einem temporären Denkmal aus 200 Gedenksteinen gedacht.

Unter den inhaftierten politischen Gefangenen befanden sich auch circa 700 Geistliche, darunter mehr als 600 polnische Priester, Bischöfe und zwei Subdiakone.

Bis 1941 waren im Zellenbau in Sachsenhausen 230 Geistliche inhaftiert, darunter Martin Niemöller von März 1938 bis 1941 als „persönlicher Gefangener“ Hitlers bis zu seiner Überführung ins KZ Dachau sowie von Dezember 1939 bis August 1940 der Jesuitenpater Rupert Mayer. Weitere bekannte Inhaftierte waren Franz von Galen (1879–1961), preußischer Landtagsabgeordneter und Bruder von Clemens August Graf von Galen, Hw. Kazimierz Majdański, der spätere Bischof von Szczecin-Kamien und der Selige Karl Leisner, damals noch Seminarist. Zudem befanden sich im Lager zeitweise protestantische Widerstandsfrauen aus den Niederlanden, die in der Region Achterhoek Juden geholfen hatten; mehrere tausend französische katholische Laien der Résistance waren zeitweise in Sachsenhausen inhaftiert.

Die Räumung des KZ Sachsenhausen durch die SS begann in den Morgenstunden des 21. April 1945, als die Rote Armee nur noch wenige Kilometer entfernt war. 33.000 der noch verbliebenen 36.000 Häftlinge wurden in Gruppen von 500 Häftlingen nach Nordwesten in Marsch gesetzt.
Nur die ersten Kolonnen erhielten einige Lebensmittel. Viele Häftlinge, die am Tag zwischen 20 und 40 Kilometer marschieren mussten, starben bei nasskaltem Wetter an Entkräftung oder wurden von der SS erschossen. Mitarbeiter des Internationalen Komitees vom Roten Kreuz verteilten auf den Märschen Lebensmittel-Pakete an die Häftlinge und retteten somit viele vor dem Hungertod. Trotzdem starben auf den Todesmärschen nach der Evakuierung des Lagers im April 1945 noch einmal Tausende von Häftlingen.

Im Belower Wald, dem Stadtforst von Wittstock/Dosse, wurden ab dem 23. April 1945 etwa 18.000 Häftlinge zusammengezogen, die dort bis zum 29. April 1945 lagerten. Die überlebenden Häftlinge erreichten anschließend auf unterschiedlichen Wegen den Raum zwischen Parchim und Schwerin, wo sie, inzwischen von ihren SS-Bewachern verlassen, auf Einheiten der Roten Armee und der US Army trafen.

Am 22. und 23. April erreichten sowjetische und polnische Truppen das Hauptlager. Etwa 3000 Kranke, Ärzte und Pfleger wurden befreit. In den folgenden Wochen starben noch mindestens 300 ehemalige Häftlinge an den Folgen der KZ-Haft. Sie wurden in sechs Massengräbern an der Lagermauer im Bereich des Krankenreviers bestattet.

Die befreiten Häftlinge wurden mit Gefangenen aus dem Frauen-KZ Ravensbrück und dem Außenlager Wöbbelin des KZ Neuengamme in zwei Kasernen in Schwerin untergebracht. Im Mai konnten die meisten westeuropäischen Häftlinge in ihre Heimatländer zurückkehren, während Häftlinge aus Osteuropa nicht selten zunächst eine Überprüfung in Repatriierungslagern über sich ergehen lassen mussten.

Im Auftrag der vom Obersten Sowjet in Moskau eingesetzten Außerordentlichen Staatlichen Kommission zur Untersuchung von Verbrechen des NS-Regimes führten sowjetische Gerichtsmediziner an den Massengräbern Exhumierungen durch; die Expertengruppe führte der Leiter des Wissenschaftlichen Forschungsinstituts für Gerichtsmedizin (NISM) beim Volkskommissariat für Gesundheitswesen der UdSSR, Wiktor Prosorowski, der 1946 als Zeuge beim Nürnberger Prozess gegen die Hauptkriegsverbrecher aussagte.

"(mit † versehene Personen überlebten das NS-Regime nicht)"




Nach der Nutzung des Geländes durch die sowjetische Armee (Speziallager Sachsenhausen bis 1950) und die Kasernierte Volkspolizei begannen 1956 die Planungen für die "Nationale Mahn- und Gedenkstätte Sachsenhausen". 1955 waren durch einen Spendenmarkenverkauf des "Kuratoriums für den Aufbau nationaler Gedenkstätten" in kurzer Zeit zwei Millionen Mark zusammengekommen. An der Planung waren der Landschafts- und Gartenarchitekt Reinhold Lingner und die Architekten Ludwig Deiters, Horst Kutzat und Kurt Tausendschön beteiligt. René Graetz schuf die Plastik „Befreiung“. 1961 wurde die Plastik „Die Anklagende“ von Fritz Cremer am Schloss Oranienburg aufgestellt.

Am 22. April 1961 wurde die nationale Mahn- und Gedenkstätte feierlich eröffnet. Die Entwürfe für die Halle stammen von Ludwig Deiters und Horst Kutzat. Die Grünanlage gestalteten die Gartenarchitekten Hubert Matthes und Hugo Namslauer. In der Halle steht eine Bronzeplastik, die drei Figuren darstellt, die Widerstand/Siegesbewußtsein, Trauer und Tod symbolisieren sollen. Diese wurde von Professor Waldemar Grzimek geschaffen.

Die Gedenkstätte beschränkte sich auf den Bereich des ehemaligen Häftlingslagers und umfasste lediglich etwa fünf Prozent der Fläche des ehemaligen Konzentrationslagers. Lediglich die „Station Z“ sowie der Erschießungsgraben, ursprünglich Teil des Industriehofes, wurden durch Versetzung der Lagermauer in die Gedenkstätte integriert. Um den Appellplatz wurde eine halbkreisförmige Mauer aus kreuzförmigen Betonelementen angelegt, in der die Giebel des ersten Barackenringes angedeutet sind.

Der größte Teil des gesamten ehemaligen Lagerbereichs wurde abgerissen, aufgeforstet, von der Sowjetarmee und von der Nationalen Volksarmee der DDR als Kaserne genutzt, für Wohn- und Wirtschaftszwecke freigegeben bzw. weitergenutzt oder verfiel. 1976 wurden 200 einheitliche Tafeln an den vier Hauptstrecken des Todesmarsches zwischen Oranienburg und Raben-Steinfeld aufgestellt. Bis zur Wende 1989 war die Gedenkstätte Ziel von tausenden Schulklassen aus der DDR, Delegationen aus dem In- und Ausland sowie Austragungsort sportlicher, politischer und militärischer Veranstaltungen (Vereidigungen u. a.).

Am 26. September 1992 setzten Neonazis die Baracke 38 in der Gedenkstätte des ehemaligen KZ Sachsenhausen in Brand. Das Gebäude, in dem ein „Museum für die Leiden der jüdischen Kameraden“ untergebracht war, wurde zerstört. Der Anschlag fand zehn Tage nach dem Besuch des damaligen israelischen Ministerpräsidenten Jitzchak Rabin in der Nacht vor dem jüdischen Neujahrsfest Rosch ha-Schana statt. Zwei der Täter wurden ermittelt und 1995 zu Haftstrafen verurteilt.

Die "Gedenkstätte und Museum Sachsenhausen" ist seit Januar 1993 Teil der Stiftung Brandenburgische Gedenkstätten, einer gemeinsam von der Bundesrepublik Deutschland und dem Land Brandenburg finanzierten Stiftung öffentlichen Rechts. Eine Außenstelle bildet die Gedenkstätte Todesmarsch im Belower Wald.

Zu heftigen Diskussionen in der Stadt führte 1997 eine Ausstellung von Skulpturen des Berliner Künstlers Stuart Wolff auf dem Weg vom Oranienburger Bahnhof zum KZ. Diese wurden wenige Tage nach ihrer Aufstellung von Neonazis beschädigt, die Stadt Oranienburg wollte sie daraufhin entfernen lassen. Erst nach Protesten der Stiftung Brandenburgische Gedenkstätten, kehrten die Skulpturen nach der Reparatur wieder in den öffentlichen Raum zurück.

Ende 2001 eröffnete die Gedenkstätte Sachsenhausen in einem Museumsneubau eine neue Dauerausstellung zur Geschichte des sowjetischen Speziallagers Nr. 7/Nr. 1 (1945–1950). Im Rahmen der kompletten Sanierung und Neugestaltung der Gedenkstätte Sachsenhausen erhielt der Ort des Gedenkens ein neues Gesicht. 2004 wurde in den original erhaltenen Baracken R I und R II eine auf Dauer angelegte Ausstellung zum Thema „Medizin und Verbrechen“ eröffnet, mit 800 m² und etwa 100 Exponaten die größte innerhalb der Gedenkstätte. Die Sanierungsarbeiten wurden zu den Feierlichkeiten anlässlich des 60. Jahrestages der Befreiung im April 2005 weitgehend abgeschlossen. Die Gesamtkonzeption der Gedenkstätte Sachsenhausen stammt von "hg merz architekten museumsgestalter".

Der Berliner Kardinal Georg Sterzinsky hat 2006 auf dem Gelände des KZ Sachsenhausen einen Gedenkstein der Berliner Bildhauer Stefan Sprenker und Thomas Reifferscheid für die über 700 inhaftierten katholischen Geistlichen aufstellen lassen. Auf dem Stein sind die Namen der 96 in Sachsenhausen gestorbenen Geistlichen verzeichnet, die aus mehreren Ländern Europas stammten. Es gibt ebenso seit 2006 eine Gedenkstelle für die evangelischen Häftlinge in Sachsenhausen.



Zeitzeugen

Historische Darstellungen

Außenlager

Gedenkstätte



</doc>
<doc id="10812" url="https://de.wikipedia.org/wiki?curid=10812" title="Revolution">
Revolution

Eine Revolution ist ein grundlegender und nachhaltiger struktureller Wandel eines oder mehrerer Systeme, der meist abrupt oder in relativ kurzer Zeit erfolgt. Er kann friedlich oder gewaltsam vor sich gehen. Es gibt Revolutionen in Herrschaftssystemen, in der Wirtschaft, in der Sozialordnung eines Staates, in der Technik und in der Wissenschaft.

Als gegensätzlich gelten die Begriffe Evolution und Reform: Sie stehen für langsamer ablaufende Entwicklungen beziehungsweise für Änderungen ohne radikalen Wandel.

Das Fremdwort "Revolution" wurde im 15. Jahrhundert aus dem spätlateinischen "revolutio" („Umdrehung“, wörtlich „das Zurückwälzen“) entlehnt und bezeichnete zunächst als Fachwort in der Astronomie den Umlauf der Himmelskörper. Nikolaus Kopernikus verwendete das lateinische Wort "revolutio" mit dieser Bedeutung in seinem berühmten Werk "De revolutionibus orbium coelestium" (1543).

Im England des 17. Jahrhunderts wurde der Begriff in Bezug auf die Glorious Revolution im Jahr 1688 im Sinne einer Wiederherstellung des alten legitimen Zustandes verwendet (ein „Zurückwälzen“ der gesellschaftlichen Verhältnisse). Die heutige Hauptbedeutung „gewaltsamer politischer Umsturz“ kam erst im 18. Jahrhundert auf, ausgehend vom französischen .

Heute ist mit "Revolution" meist eine politische Revolution „von unten“ gemeint: eine meist durch militante Mittel, seltener auf friedlichem Wege erzwungene grundlegende Änderung einer bestehenden staatlichen Ordnung. Das Ziel ist die Einführung eines neuen politischen Systems (siehe auch Staatsform) und/oder ein Austausch der Machthaber (Inhaber der Staatsgewalt).

Der Wandel vollzieht sich außerhalb der vorgesehenen Rechtsformen des alten Systems, d. h. nach dessen Definition illegal. Er kann von zahlenmäßig relativ kleinen Gruppen ausgehen, das Gelingen einer Revolution ist jedoch meist von einer breiten Zustimmung der Bevölkerung abhängig. Die Bevölkerung kann ihre Zustimmung auf vielfältige Weise bezeugen (Massendemonstrationen, Generalstreik, Boykott, Sabotage, Gewaltanwendung) und nach dem Umsturz die neue Herrschaft durch Wahlen, Volksabstimmungen, Volksentscheide legitimieren.

Ein erfolgloser, das heißt niedergeschlagener Revolutionsversuch wird manchmal auch als Revolte oder Aufstand bezeichnet.

Als "Palastrevolution" wird der Sturz von Herrschern oder Staatsmännern bezeichnet, der nicht durch Volksaufstände oder Erhebungen der Bevölkerung, sondern durch Intrigen im Umfeld der jeweiligen Herrscher herbeigeführt wird. Eine Palastrevolution ist daher mit einem Putsch vergleichbar.

Umgangssprachlich wird auch die Auflehnung gegen Vorgesetzte in Firmen und Organisationen als "Palastrevolution" bezeichnet.

In der Vorstellungswelt der traditionalen vorindustriellen Gesellschaften, die auf einer harmonischen Ordnung, auf einem Einklang von Mensch, Gesellschaft und Natur mit der göttlichen Schöpfung basierte, waren die Gemeinschaft, einzelne Gruppen und auch der einzelne Mensch durch die "corruptio" (Verderbnis) bedroht, die immer dann gegeben ist, wenn eine Ordnung (Herrschaftsform) ihre positiven Züge verliert, wenn etwa freie Bürger von anderen einseitig abhängig werden, und wenn dabei die „Tugend“ "(virtus)" verloren geht, die das eigene Wohl mit dem Gemeinwohl vereinigen soll. In einer solchen Situation ist es geboten, an den Ausgangspunkt zurückzukehren (Machiavelli: "Ritorno ai principi"), Unordnung wieder in Ordnung zurückzuführen. Tatsächlich findet man bis in die Neuzeit bei revolutionären Bewegungen bis hin zu den Anfängen der Französischen Revolution immer wieder die anfängliche Forderung, zum „alten Recht“ zurückzukehren. Dass eine „Revolution“ im heutigen Sinn etwas Neues schaffe, hat sich erst nach der Revolution von 1789 als Auffassung durchgesetzt.

Eine „Revolution“ bezeichnet in der Soziologie sowie umgangssprachlich einen radikalen und meist, jedoch nicht immer, gewalttätigen sozialen Wandel (Umsturz) der bestehenden politischen und gesellschaftlichen Verhältnisse. Gegebenenfalls kommt es dabei zu einer Umwälzung des kulturellen „Normensystems einer Gesellschaft“. Eine Revolution wird entweder von einer organisierten, möglicherweise geheimen, Gruppierung von Neuerern ("vgl." Avantgarde, Elite) getragen und findet die Unterstützung größerer Bevölkerungsteile, oder sie ist von vornherein eine Massenbewegung.

Teils wird der Begriff der Emanzipation hinzugenommen, d. h. die Idee der Befreiung von gewachsenen Strukturen und eines sozialen oder politischen Freiheitsgewinns für den Einzelnen. Der Stellenwert der einzelnen Kriterien für die Definition einer Revolution ist durchaus umstritten.

Wenn ohne tiefgreifenden (radikalen) sozialen Wandel nur eine kleine Organisation oder ein eng verknüpftes soziales Netzwerk mit relativ geringer Massenbasis einen gewaltsamen Umsturz unternimmt, bezeichnet man dies als Staatsstreich oder, insbesondere unter Beteiligung des Militärs, als „Putsch“. Nach erfolgreichen Staatsstreichen wird der Begriff der „Revolution“ anschließend oft als ideologische Rechtfertigung genutzt, indem der Putsch als Revolution umgedeutet wird.

Der Begriff „Revolution“ wird auch verwendet, um einen allgemeineren, tiefgreifenden Wandel der Gesellschaftsstruktur zu bezeichnen, auch wenn es sich dabei nicht zwangsläufig um besonders plötzlich und rapide auftretende Veränderungen handelt. So spricht man etwa von der – global mehrere tausend Jahre dauernden – „Neolithischen Revolution“ oder von der sich zwischen 1750 und 1850 von England über den europäischen Kontinent ausbreitenden „Industriellen Revolution“, die ihrerseits wiederum Vorbedingung für verschiedene politische Revolutionen in diesem Zeitraum war.

Die heutige politikwissenschaftliche Revolutionstheorie nennt u. a. fünf Hauptfaktoren, die wesentliche Voraussetzungen zur Entstehung einer Revolution darstellen, wobei Entwicklungsländer nicht berücksichtigt werden:


Das "Revolutionsrecht" geht in Deutschland begrifflich auf philosophische Überlegungen Johann Gottlieb Fichtes zur Französischen Revolution (1793) zurück. Infolge der Novemberrevolution bildete sich in der Weimarer Republik das Revolutionsrecht in der zivilrechtlichen Rechtsprechung des Reichsgerichts aus, welches 1926 auch vom Staatsgerichtshof verfassungsrechtlich anerkannt und übernommen wurde: Diese Rechtsprechung und die damit verbundene Denkweise legitimierte später auch die Machtergreifung der Nationalsozialisten. Die "normative Kraft des Revolutionsrechts" wurde 1952 nochmals vom Bundesgerichtshof bestätigt.

Das Revolutionsrecht im weiten Sinne ist heute nur noch von rechtsgeschichtlichem Interesse. Das in Artikel 20 des Grundgesetzes für die Bundesrepublik Deutschland verankerte Gewaltmonopol des Staates steht solchen Überlegungsansätzen entgegen, Art. 20 GG enthält allerdings seit 1968 in Abs. 4 die Relikte eines Revolutionsrechts in Form des Widerstandsrechts.



Sowie (alphabetisch) Bakunin, Bolívar, Danton, Debord, Guevara, Ho Chi Minh, Mao Zedong, Marat, Mazzini, Nkrumah, Robespierre, Saint-Just, Schariati, Torres, Trotzki und andere Revolutionäre des 18. bis 20. Jahrhunderts.

Radikaler und rapider sozialer Wandel („Revolutionen“) knüpfte sich auch an erfolgreiche politische, oft auch charismatische Persönlichkeiten, deren soziologische Urteilskraft sich eher nur implizit erschließt, deren soziale Wirkung jedoch bewusst und gewollt revolutionär war.

Revolutionen „von unten“:

Revolutionen „von oben“:


Ähnliche Begriffe:

Marxistische Begriffe:

Sonstiges:



</doc>
<doc id="10814" url="https://de.wikipedia.org/wiki?curid=10814" title="Giacomo Balla">
Giacomo Balla

Giacomo Balla (* 18. Juli 1871 in Turin; † 1. März 1958 in Rom) war ein italienischer Maler des Futurismus. 

Nach einem kurzen Studium an der Albertina in Turin siedelte Balla 1895 nach Rom über. 1900/01 hielt er sich in Paris auf und setzte sich mit der divisionistischen Technik der Neoimpressionisten auseinander.

Nachdem er das 1909 durch Filippo Tommaso Marinetti verfasste „Futuristische Manifest“ unterzeichnet hatte, verfasste er 1910 zusammen mit seinen Schülern Umberto Boccioni, Carlo Carrà, Luigi Russolo und Gino Severini das „Technische Manifest der futuristischen Maler“. 1912 unterzeichnete er zusammen mit denselben Künstlern den Aufruf „Die Aussteller an das Publikum“ für die Futuristen-Ausstellung in Berlin. Mit eigenen Werken beteiligte er sich 1913 an der „Mostra Futurista“ in Rom, an der Ausstellung "Italian Futurist Painters and Sculptors" des Rotterdamsche Kunstring in Rotterdam und schließlich im gleichen Jahr noch an Herwarth Waldens erstem deutschen Herbstsalon in Berlin. Die Darstellung von zeitlichen Abläufen, die Dynamik und Rhythmik in einem Bild war das Ziel eines Großteils seiner Arbeit.

Ein Auftrag für ein Wandbild führte ihn in den Jahren zwischen 1912 und 1914 wiederholt nach Düsseldorf. 1917 stattete er das Bühnenbild für die Ballets Russes von Sergei Pawlowitsch Djagilew aus. Balla war Teilnehmer der documenta 1 (1955) in Kassel, seine Werke wurden auch postum auf der documenta 8 im Jahr 1987 gezeigt.





</doc>
<doc id="10818" url="https://de.wikipedia.org/wiki?curid=10818" title="Kaspisches Meer">
Kaspisches Meer

Das Kaspische Meer (auch Kaspisee, , , , , ) ist der größte See der Erde. Der Salzsee liegt in West-Asien und im äußersten Osteuropa ohne natürliche Verbindung zu den Ozeanen innerhalb der großen Aralo-Kaspischen Niederung. Im Norden grenzt er an Russland und Kasachstan, im Osten an Turkmenistan, im Süden an den Iran und im Westen an Aserbaidschan.

Der internationale Status des Kaspischen Meeres ist bis heute nicht endgültig geklärt. Deshalb wurde von den Anrainerstaaten, Aserbaidschan, Iran, Kasachstan, Russland und Turkmenistan 1992 die Kooperationsgemeinschaft Kaspischer Staaten gegründet. Ziel ist ein Abkommen zum Schutze und zur Nutzung des Kaspischen Meeres.

Vor diesem Schritt gab es nur zwei gültige Verträge aus den Jahren 1921 und 1940 zwischen dem Iran und der Sowjetunion zur Regelung der Schifffahrt und der Fischerei. In ihnen wurde das Kaspische Meer als "Binnengewässer mit dem Recht der gemeinsamen Nutzung" definiert.

Die neuen Anrainer Aserbaidschan, Kasachstan und Turkmenistan sehen darin für sich eine Benachteiligung und möchten, dass das Kaspische Meer als internationales Gewässer behandelt wird. Hintergrund dieser Forderungen sind vor allem die Förderrechte für Erdöl und Erdgas.

Käme es zu jenem Status, den Russland und der Iran favorisieren, würde es zu einer Aufteilung der Bodenschätze unter den Anrainern zu gleichen Teilen kommen. Käme jedoch – entsprechend der überwiegenden Meinung der Völkerrechtler – das internationale Seerechtsabkommen von 1994 zur Geltung, hätte jeder Anrainer das alleinige Recht der Ausbeutung seiner Zone. Unterstützung finden die drei neuen Anrainerstaaten durch die westlichen Staaten und deren Mineralölkonzerne, die keine Beteiligung Russlands oder des Irans möchten. Die Staaten konnten sich bis heute nicht einigen, bei der Erschließung neuer Erdölfelder sind sich die neuen Staaten mittlerweile auch nicht mehr einig.

Älteste Kulturzeugnisse finden sich auf Inschriften assyrischer Tonwaren und nennen ein „Südliches Meer“. Hekataios von Milet erwähnt es im 6. Jh. v. Chr. als „Kaspisches und Hyrkanisches Meer“; die erste Volksbezeichnung bezieht sich auf den Stamm der Caspi, die am Südwestufer des Kaspischen Kaukasus lebten, im heutigen Aserbaidschan, die zweite bezeichnet das Ufer bei Hyrkanien, einer Landschaft an der heutigen Iranischen und südlichen Turkmenischen Küste. Weitere antike Bezeichnungen sind die Ethnonyme „Alban“, „Joshgun“ und „Hyrcan“. Die wechselnde Besiedelungsgeschichte führte zu zahlreichen weiteren Namen wie z. B. der tatarischen Bezeichnung „Ag Deniz“ (Weißes Meer, vgl. auch Chasarisches Meer und Verwechslungen, z. B. „Blaues Meer“ in alten russischen Dokumenten mit dem Aralsee) oder „Kasar Danizi“ bei den türkischsprachigen Chasaren, die im 5. bis 10. Jh. nordwestlich siedelten. Insgesamt sollen bis zu 70 Begriffe für das Kaspische Meer historisch überliefert sein, darunter auch weniger etablierte Begriffe wie „Baku-Meer“, den der Botschafter der Republik Venedig im Iran A. Kontarini im 15. Jh. nannte.

Das Kaspische Meer, das in einer weitläufigen und bis zu 1.023 m tiefen natürlichen Depression liegt, befindet sich unter anderem zwischen dem trockenliegenden Teil der großen Kaspischen Senke im Norden, der Kasachensteppe im Nordosten, dem großen Tiefland von Turan im Osten, dem Elburs im Süden und dem Kaukasus im Westen. Aserbaidschan (Küstenlänge: ca. 800 km), Iran (Küstenlänge: 750 km), Kasachstan (Küstenlänge: 1894 km), Russland (Küstenlänge: ca. 960 km) und Turkmenistan (Küstenlänge: 1768 km) grenzen daran.

Das Kaspische Meer ist – je nach Definition – Teil der Grenze von Europa und Asien und zerteilt somit Eurasien in zwei Kontinente.

Zum Verlauf dieser Grenze der ineinander übergehenden Erdteile siehe unter innereurasische Grenze.

Die Fläche des Kaspischen Meeres beträgt 386.400 km², damit ist es die größte von Land umschlossene Wasserfläche der Erde beziehungsweise deren größter See. Die Fläche des Kaspischen Meeres entspricht ungefähr der Fläche von Deutschland und Belgien oder auch der Ostsee ohne das Kattegat. Seine Nord-Süd-Ausdehnung beträgt 1200 km, seine West-Ost-Ausdehnung umfasst 435 km (im Mittel 300 km). Während der große Nordteil im Mittel nur etwa 6 m tief ist, beträgt seine tiefste Stelle im Süden 995 m. Weil seine Wasseroberfläche liegt, befindet sich dieses Tiefenmaximum und ist damit die zweittiefste natürliche Depression der Erde nach dem Baikalsee, dessen Seegrund sich befindet.

Das Kaspische Meer besitzt keine natürliche Verbindung zu den Ozeanen. Es ist damit ein See und trägt die Bezeichnung „Meer“ nur aufgrund seiner Größe und des Salzgehalts des Wassers. Ein früher geläufiger Name war Kaspisee. Über die Wolga, den Wolga-Don-Kanal und den Don besteht aber eine schiffbare Verbindung über das Asowsche Meer zum Schwarzen Meer, über die Wolga, den Wolga-Ostsee-Kanal, Onegasee und die Newa zur Ostsee und vom Onegasee abzweigend über den Weißmeer-Ostsee-Kanal zum Weißen Meer.

Das Kaspische Meer ist wie das Schwarze Meer und der Aralsee ein Rest der Paratethys, eines Binnenmeeres, das sich während des Oligozäns und des Großteils des Neogens von Westeuropa bis nach Zentralasien erstreckte. Gegen Ende des Miozäns bildete sich eine Grenze zum Schwarzen Meer heraus, seit Beginn des Pliozäns kam es zu einer Serie von starken Wasserstandsschwankungen, wodurch die Größe stark variierte. Bei niedrigem Wasserstand schrumpfte das Kaspische Meer auf einen See in den tiefsten Bereichen im Süden, in Zeiten hohen Wasserstandes kam es zu Wiedervereinigungen mit dem Schwarzen Meer. Zum bisher letzten Mal geschah dies zu Ende der Eiszeiten, als die Eismassen der sibirischen Gletscher abtauten und die Manytschniederung geflutet wurde. In Richtung Osten entstand in der Aralo-Kaspischen Niederung eine Verbindung zum Aralsee.

Eine direkte Verbindung zum Ozean bestand nie, da das Schwarze Meer zum Zeitpunkt seiner Verbindung mit dem Kaspischen Meer nach gängiger Lehrmeinung vom Mittelmeer getrennt war.

Im 20. Jahrhundert ging die Wasserfläche von Anfang der 1930er Jahre bis in die 1980er Jahre dramatisch zurück; zu Beginn dieses Zeitraums soll die Seefläche etwa 420.000 km² groß gewesen sein. Das Absinken des Seespiegels vollzog sich vor allem in den Jahren 1930–1941 und 1970–1977 mit einer Geschwindigkeit von 16 beziehungsweise 14 cm pro Jahr, insgesamt um rund drei Meter, seit Beginn der Aufzeichnungen und seinem vorläufigen Höchststand 1896 sogar um 3,5 m. Die Wassermassen, die dem See durch die Wolga, den Ural und die Kura zugeführt wurden, reichten damals nicht aus, um seinen Wasserinhalt aufrechtzuerhalten; die Wasserentnahme zu Bewässerungszwecken war an seinen wenigen Zuflüssen enorm groß und die Verdunstung, die auf der riesigen Wasserfläche entstand, ließ seinen Inhalt und damit seine Größe ständig schrumpfen. Mitverantwortlich war auch der Bau der großen Wolga-Staustufen, welche die Verdunstungsfläche der Wolga vergrößerten, so dass die Wolga als Hauptzufluss weniger Wasser einspeisen konnte.

Die Kara-Bogas-Bucht, eine ehemals sehr flache, aber große östliche Ausbuchtung des Kaspischen Meeres, wurde 1980 an der schmalsten Verbindungsstelle durch einen Damm abgeriegelt, weil in diesem trockenen, heißen Gebiet die Verdunstung besonders hoch war. Nach dem Dammbau kam es zur völligen Austrocknung der Lagune und zur Umwandlung in eine für die Umwelt gefährliche Salzwüste. Da der Einbau von Schleusen in den Jahren 1985–1991 die Situation nicht wesentlich verbesserte, wurde der Damm 1992 beseitigt.

Zwischen 1978 und 1994 stieg der Seespiegel anhaltend und intensiv mit einer jährlichen Rate von 14 cm bis 40 cm an. Das führte in dieser Zeit zu weiträumigen Überschwemmungen des Festlandes in einer Breite von 5–25 km und über eine Länge von 1500 km. Dadurch wurden 2 Millionen Hektar Land überflutet. Der Schaden wurde mit rd. 12 Mrd. US-$ beziffert, eine Million Menschen waren betroffen.

Der Anstieg des Wasserspiegels um über zweieinhalb Meter führte 1995 zu einem vorläufigen Maximum und stagniert seither, von geringen Änderungen abgesehen. Die Ursachen für die starken Schwankungen werden vielfach diskutiert. Die wahrscheinlichste Erklärung liegt in Änderungen der Wasserbilanz. Sie wird maßgeblich beeinflusst von der Wolga (sie ist für etwa 80 Prozent des Wasserfluss verantwortlich) und von den ausgedehnten Verdunstungsflächen v. a. im Norden und in der Kara-Bogas-Bucht. Die statistisch signifikante Korrelation mit säkularen Veränderungen in der Entwässerung durch die Wolga wurde 1994 durch Rodionov untersucht. Die Wasserbilanz wird von zahlreichen weiteren Ursachen beeinflusst, die in den letzten 2500 Jahren für Schwankungen bis zu sechs Metern verantwortlich waren. Für Ramiz M. Mammedov vom geografischen Institut der Akademie der Wissenschaften in Baku ist klar, dass von den drei Faktoren Geologie, Mensch, Klima der Faktor Klima die wichtigste Rolle spielt. Saisonale Pegelschwankungen von rund 40 cm werden in der Untersuchung der langfristigen Auswirkungen nicht einberechnet, sind aber bei der kurzfristigen Gefährdung küstennaher Industrieanlagen erheblich. Als weitere Faktoren zur Entwicklung der Wasserbilanz und ihren weiteren Auswirkungen werden genannt:

Der Anstieg des Wasserspiegels hat die Anrainerstaaten vor die Notwendigkeit gestellt, die Siedlungen und Industrieanlagen in den überfluteten Gebieten zu schützen. Bedroht sind insbesondere die Gebiete intensiver Erdöl- und Erdgasförderung und die Industriedeponien mit Gefahrgut. Die Voraussage von 2002, die bis 2010 einen weiteren Anstieg um 2,30 m voraussagte, ist offensichtlich nicht eingetreten. Russische Hydrometeorologen, die sich an bekannten Daten der Klimageschichte orientieren, prognostizierten einen Anstieg bis 2050 um 4,5 bis 5 Meter, das würde fast die halbe Landesfläche Aserbaidschans betreffen. Allerdings sei das Zusammenwirken der vielen verschiedenen Faktoren für verlässliche Prognosen noch nicht ausreichend erforscht.

Im Kaspischen Meer befinden sich zahlreiche Inseln. Die meisten sind klein und unbesiedelt, aber es gibt auch einige besiedelte. Viele der Inseln nahe Aserbaidschan sind wegen ihrer Erdölvorkommen bedeutsam.

So hat die Bulla-Insel vor der Küste Aserbaidschans bedeutende Erdölvorkommen. Gleiches gilt für die Pirallahı-Insel. Hier fand die erste Ölbohrung im Kaspischen Meer statt und hier gab es auch einen der ersten Erdölfunde in Aserbaidschan.

Nargin, die größte Insel in der Baku-Bucht, ist ein früherer sowjetischer Militärstützpunkt. Aschūradeh liegt am östlichen Ende der Miankaleh-Halbinsel nordöstlich der Gorgan-Bucht nahe der Iranischen Küste. Aschuradeh wurde durch einen Kanal von der Halbinsel getrennt.

Verschiedene Inseln, speziell nahe Aserbaidschan, erlitten durch die Ölproduktion enorme Umweltschäden, beispielsweise Dasch Sirja, obwohl dort immer noch Robben leben.

Im Nordosten des Kaspischen Meeres liegen die Tjuleni-Inseln (Robbeninseln).

Vor der Küste Dagestans liegt die Insel "Tschetschen" und die Robbeninsel.

Einige Inseln liegen vor der Küste des Wolgadeltas und gehören zu Kalmückien und zur Oblast Astrachan, bzw. zum Gebiet Atyrau in Kasachstan.

Die Inseln, die zu Russland gehören, wie Werchni Oseredok, liegen in der Grenzzone der Russischen Föderation und können nicht betreten werden.

Unter dem Seeboden befinden sich insbesondere bei Baku sehr große Reserven an Erdöl und Erdgas. Geologen vermuten zwischen 15 und 50 Milliarden Barrel Erdöl auf dem Grund und an den Küsten des Kaspischen Meeres. Optimistische Schätzungen lauten auf bis zu 100 Milliarden Barrel, die einen Wert von fünf Billionen US-Dollar verkörpern sollen.

In der Kara-Bogas-Bucht wird Salz abgebaut.

Zu den größten Zuflüssen des Kaspischen Meeres zählen

Im Norden, wo die beiden Hauptzuflüsse Wolga und Ural einmünden, ist der Salzgehalt nur sehr gering; in Richtung Süden, wo es kaum noch nennenswerte Zuflüsse gibt, steigt er an: Das Maximum fand sich mit über 30 % an den Salzlagerstätten in der "Kara-Bogas-Bucht" ("Kara-Bogas-Gol") in Turkmenistan. Im Mittel beträgt der Salzgehalt 1,1 bis 1,3 % und liegt damit bei etwa einem Drittel der Konzentration in den Ozeanen.

Im Kaspischen Meer leben etwa 150 Fischarten, trotz des brackigen Wassers vor allem Süßwasserfische. Wirtschaftliche Bedeutung haben vor allem die verschiedenen Störe sowie zahlreiche zu Fischereizwecken eingeführte Fischarten. Eine kulinarische Spezialität des Kaspischen Meeres ist der Stör, von dem Kaviar gewonnen wird. Außerdem gibt es reichlich z. T. endemische Heringsverwandte und wilde Karpfen. Die Kaspische Robbe ist eine endemische Robbe des Kaspischen Meeres.




</doc>
<doc id="10819" url="https://de.wikipedia.org/wiki?curid=10819" title="Weiße Rose">
Weiße Rose

Weiße Rose nannte sich eine in ihrem Kern von Studenten dominierte, sich wesentlich auf christliche und humanistische Werte aus der Tradition der bündischen Jugend berufende deutsche Widerstandsgruppe gegen die Diktatur des Nationalsozialismus. Sie entstand in der Zeit des Zweiten Weltkriegs auf Initiative eines Freundeskreises um Hans Scholl und Alexander Schmorell ab Juni 1942 in München. Zwischen Ende Februar und April 1943 wurde sie mit der Enttarnung, Verhaftung und schließlich der Hinrichtung ihrer prägenden Mitglieder nach – heute als rechtswidrig geltenden – Todesurteilen des Volksgerichtshofes unter dem Vorsitz Roland Freislers zerschlagen.

Die Gruppe verfasste, druckte und verteilte auf verschiedenen klandestinen Verbreitungswegen zunächst in der Region München selbst, später über Kuriere auch in einigen anderen Städten des Deutschen Reiches – vor allem in Süddeutschland – insgesamt sechs Flugblätter in unterschiedlicher, tendenziell steigender Auflage von zuletzt bis zu 9000 Exemplaren. In diesen Veröffentlichungen thematisierten sie Verbrechen des Regimes und riefen zum Widerstand gegen den Nationalsozialismus auf. In der Schlussphase ihres Bestehens versuchte die Weiße Rose über Falk Harnack ihre Kontakte zu weiteren Widerstandsgruppen bis in die Reichshauptstadt Berlin und zu systemoppositionellen Kreisen der Wehrmacht auszuweiten. Nach dem Ende der Schlacht von Stalingrad bemalten ihre Mitglieder in nächtlichen Aktionen zusätzlich auch öffentliche Fassaden in München mit Parolen gegen Hitler und die NS-Herrschaft.

Bis in die Gegenwart gilt die "Weiße Rose" als bekanntestes und symbolgebendes Beispiel für den studentisch-bürgerlichen Widerstand gegen das NS-Regime innerhalb Deutschlands; in einem darüber hinausgehenden Sinn steht sie für moralische Lauterkeit, Mut (Zivilcourage) und Opferbereitschaft im Einsatz für humanistisch-demokratische Ideale vor dem Hintergrund einer totalitären Diktatur.

Den inneren Kreis der Weißen Rose bildeten die beiden Geschwister Hans und Sophie Scholl, Alexander Schmorell, Christoph Probst, Willi Graf sowie der Universitätsprofessor Kurt Huber.

Darüber hinaus sind der Weißen Rose weitere Mitarbeiter und Unterstützer zuzurechnen, von denen einige auch nach der Verhaftung der Geschwister Scholl und deren Freunde an Aktionen der Weißen Rose oder ähnlicher Gruppen in anderen Universitätsstädten teilnahmen. Zu ihnen gehörten Traute Lafrenz, Hans Conrad Leipelt, Marie-Luise Jahn, Hans Hirzel, Susanne Hirzel, Heinz Brenner, Franz J. Müller, Eugen Grimminger, Jürgen Wittenstein, Lilo Ramdohr, Gisela Schertling und der später auch als Regisseur bekannt gewordene Falk Harnack. Hinzu kamen Harald Dohrn, der Schwiegervater von Christoph Probst, der Architekt Manfred Eickemeyer, in dessen Atelier sich die Weiße Rose traf, der Kunstmaler Wilhelm Geyer, der Eickemeyers Atelier mietete und Hans Scholl den Schlüssel zu den Räumen überließ, sowie der Buchhändler Josef Söhngen, dessen Keller als Versteck für die Flugblätter diente.

Außerdem gab es ein größeres Umfeld von Unterstützern, wie etwa die Brüder Wilhelm und Heinrich Bollinger, Rudolf Alt, Helmut Bauer, August Sahm, Hellmut Hartert, Michael Brink (Emil Piepke), Lilo Dreyfeldt, Hubert Furtwängler, Werner Bergengruen, Josef Furtmeier, Fritz Leist, Günter Ammon, Fred Thieler, Kurt Huber u. v. a. Mehrere Mitglieder kamen aus der Bündischen Jugend, so aus der dj.1.11, dem Bund Neudeutschland oder dem Grauen Orden. In Berlin wurden Flugblätter von der Gruppe "Onkel Emil" verbreitet, in Hamburg hatten sich Studenten (ein „Kreis von 50 aktiven Personen“, zu denen auch Hans Leipelt gehörte und von denen im Spätherbst 30 verhaftet wurden) um Heinz Kucharski und Margaretha Rothe zu einer Gruppe zusammengefunden, die nach 1945 als Weiße Rose Hamburg bezeichnet wurde.

Der Widerstand bestimmter Mitglieder des studentischen Freundeskreises um die Weiße Rose war in starkem Maße christlich motiviert. So wuchsen z. B. von der später als „Ulmer Abiturienten“ bezeichneten Gruppe, die zum Sympathisantenkreis der Weißen Rose gehörte, Hans und Susanne Hirzel in einem evangelischen Pfarrhaus auf; ihr Vater gehörte der Bekennenden Kirche an. Franz J. Müller, Heinrich Guter, Heinz Brenner und Walter Hetzel waren katholisch und gingen in einen freiwilligen Religionsunterricht, nachdem der reguläre in Schulräumen 1941 verboten worden war. Dieser wurde erteilt von Adolf Eisele, einem Pater des Missionsordens der Weißen Väter, der antinationalsozialistisch eingestellt war. Er unterrichtete z. B. mit Texten von Thomas von Aquin und diskutierte mit den Jugendlichen kritische Texte wie z. B. die gegen die NS-Euthanasie gerichteten Predigten des Münsteraner Bischofs Clemens August von Galen und ein Protestschreiben von Galens an die Reichskanzlei. Alexander Schmorell gehörte der russisch-orthodoxen Kirche an. Hans und Sophie Scholl wurden christlich und mit Idealen wie Freiheit, Gerechtigkeit und Selbstständigkeit erzogen und waren deshalb empört über die Deportation und Behandlung sowohl von Juden als auch von Regimegegnern. Außerdem waren sie durch die Frömmigkeit ihrer Mutter geprägt. Die Beschäftigung mit Literatur, Kunst und Musik war ein selbstverständlicher Teil ihrer Kindheit. Hans Scholl, Alexander Schmorell und Willi Graf hatten 1942 bei ihrem Fronteinsatz von Massenermordungen in Polen erfahren und das Elend im Warschauer Ghetto beobachtet, was sie nach ihrer Rückkehr nach Deutschland zusätzlich zum Widerstand bewegte.

Nach den Erfahrungen an der Front des Zweiten Weltkriegs und den Berichten von Freunden über Massenmorde in Polen und Russland genügten ihnen Lesen und Diskutieren allein nicht mehr. Im Juni 1942 handelten Alexander Schmorell und Hans Scholl. Die ersten vier Flugblätter wurden von Ende Juni bis Mitte Juli 1942 verfasst und anonym mit der Post an Intellektuelle im Raum München verschickt. Im Winter desselben Jahres wurde die Gruppe um Sophie Scholl und Willi Graf erweitert.

Vom 23. Juli bis 30. Oktober 1942 mussten Graf, Scholl und Schmorell als Sanitäter an die Ostfront. Nach ihrer Rückkehr nahmen die Studenten ihre Widerstandstätigkeit wieder auf. Das fünfte Flugblatt „Aufruf an alle Deutsche!“ (mit einer geschätzten Auflage zwischen 6000 und 9000) wurde zwischen 27. und 29. Januar 1943 durch Kurierfahrten in mehreren süddeutschen und auch in einigen österreichischen Städten verteilt. Die Weiße Rose zielte ab Sommer 1942 vor allem darauf ab, „auf die breite Volksmasse“ einzuwirken, wie es Sophie Scholl nach ihrer Verhaftung am 18. Februar 1943 sagte. Dieses Ziel wird dadurch deutlich, dass das Flugblatt in einer klar verständlichen Sprache verfasst ist. Nach ihrer Fronterfahrung im Osten waren die Studenten davon überzeugt, dass der Krieg nicht mehr gewonnen werden könne („Hitler kann den Krieg nicht gewinnen, nur noch verlängern.“). Sie riefen dazu auf, sich vom „nationalsozialistischen Untermenschentum“, Imperialismus und preußischen Militarismus „für alle Zeit“ zu trennen. Ihre Zukunftsvision war ein föderalistisches Deutschland in einem vereinten Europa nach dem Krieg.
Ende Januar 1943 ging die Schlacht von Stalingrad mit der Kapitulation der gesamten 6. Armee unter Generalfeldmarschall Paulus gegenüber der Roten Armee für das Deutsche Reich verloren. Um die 90.000 Angehörige der Wehrmacht kamen in Kriegsgefangenschaft, etwa 150.000 Soldaten waren dabei allein auf deutscher Seite gefallen; mehr als doppelt so viele Menschen starben auf der Seite der Sowjetunion. Stalingrad bedeutete eine entscheidende Wende im Verlauf des Zweiten Weltkriegs und führte zum verstärkten Widerstand in den von Deutschland besetzten europäischen Ländern. Der Großteil der deutschen Bevölkerung war durch diese Nachricht verunsichert. Im Kongresssaal des Deutschen Museums kam es anlässlich der 470-Jahr-Feier der Münchner Universität am 13. Januar zu spontanen Studentenprotesten gegen die mit Beleidigungen gegen angebliche „Drückeberger“ und vulgären Anspielungen gegen die anwesenden Studentinnen durchsetzte Rede des Gauleiters von München-Oberbayern Paul Giesler. Empört verließen die jungen Menschen, in der Mehrzahl Soldaten in Uniform, darunter Kriegsversehrte, den Saal und durchbrachen die Polizeisperren. Angeführt von einem hochdekorierten Leutnant in Uniform befreite eine Gruppe bereits verhaftete Kommilitoninnen aus den Händen der Polizei.

Die Ereignisse beflügelten die Mitglieder der Weißen Rose zu verstärktem Aktivismus. Die Bekanntgabe des Endes der Kämpfe um Stalingrad gab den Anstoß zu ihrem sechsten Flugblatt „Kommilitoninnen! Kommilitonen!“. Der von patriotischer Leidenschaft durchzogene Appell stammte von Kurt Huber. Hans Scholl und Alexander Schmorell redigierten den Text an der Stelle, in der Huber zum Eintritt in die „herrliche Wehrmacht“ aufforderte. Durch Helmuth von Moltke, den Begründer des Kreisauer Kreises, gelangte dieses Flugblatt über Skandinavien bis nach England. Hunderttausende davon wurden von britischen Flugzeugen Ende 1943 über Deutschland abgeworfen. Sie waren jetzt überschrieben: „Ein deutsches Flugblatt – Manifest der Münchner Studenten.“

In anderen Städten arbeiteten Freunde der Weißen Rose in kleinen Gruppen, verteilten Flugblätter und hielten Kontakt. „Nieder mit Hitler“ und „Freiheit“ stand am 3., 8. und 15. Februar an den Mauern der Universität und zahlreicher anderer Gebäude in München. Alexander Schmorell, Hans Scholl und Willi Graf hatten die Parolen nachts mit schwarzer Teerfarbe und grüner Ölfarbe unter Verwendung von Schablonen (vgl. auch Stencil) angeschrieben.

Die Gestapo leitete bereits im Sommer 1942 Untersuchungen zu den Flugblättern der Weißen Rose ein, die als „staatsfeindliche Bestrebungen“ gesehen wurden. Diese Nachforschungen blieben zunächst erfolglos und wurden bald eingestellt. Ab Ende Januar setzte die Gestapo wegen der erneut verteilten Flugblätter eine Sonderkommission in München ein.

In der Nacht vom 15. auf den 16. Februar 1943 verteilte die Gruppe 800 bis 1200 Flugblätter in München. Noch in der Nacht vom 17. auf den 18. Februar legte die Gestapo die beiden zuletzt aufgetauchten Flugblätter dem Münchner Gräzisten Richard Harder vor, mit dem Auftrag, ein Täterprofil zu ihnen abzugeben; wenig später erhielt er auch die vier älteren.

Am 18. Februar kamen Hans und Sophie Scholl gegen 10:45 Uhr durch den Haupteingang in das Universitätsgebäude. Sie trugen einen rotbraunen Koffer und eine Aktentasche, beide gefüllt mit dem sechsten Flugblatt und einer kleinen Menge des fünften. Die Geschwister legten diese vor den noch geschlossenen Hörsälen und in den Gängen die Flugblätter stoßweise aus. Als sie schon am rückwärtigen Ausgang Amalienstraße waren, kehrten sie um und liefen in den ersten Stock, wo sie nochmals Flugblätter ablegten. Dann rannten sie in den zweiten Stock, von wo Sophie den Rest der Flugblätter über die Brüstung in den Lichthof der Münchener Universität warf. Dabei wurden die beiden vom Hörsaaldiener Jakob Schmid entdeckt und von diesem (und anderen) so lange festgehalten, bis die Gestapo eintraf.

Hans und Sophie Scholl wurden nach ihrer Festnahme zunächst zum Wittelsbacher Palais, der Gestapo-Zentrale, transportiert und dort getrennt bis zum 21. Februar stundenlang vernommen. Hans Scholl hatte bei seiner Festnahme einen Flugblattentwurf von Christoph Probst bei sich, sodass auch dieser festgenommen und angeklagt wurde. Die Geschwister Scholl und Christoph Probst wurden vom sogenannten „Blutrichter“ Roland Freisler am Volksgerichtshof zum Tode durch das Fallbeil verurteilt. Das „gleichgeschaltete“ Gericht nannte als Gründe für dieses Urteil „Wehrkraftzersetzung“, „Feindbegünstigung“ und „Vorbereitung zum Hochverrat“. Das Urteil wurde am 22. Februar vollstreckt. Kurz vor der Vollstreckung sahen die Geschwister Scholl ihre Eltern ein letztes Mal.

Kurt Huber, Willi Graf und Alexander Schmorell wurden am 19. April 1943 in einem zweiten Prozess vor dem Volksgerichtshof ebenfalls zum Tode verurteilt. Kurt Huber und Alexander Schmorell wurden am 13. Juli 1943 im Gefängnis München-Stadelheim enthauptet, die Hinrichtung Willi Grafs erfolgte am 12. Oktober 1943 ebenfalls durch das Fallbeil, nachdem die Gestapo über Monate hinweg versucht hatte, aus Willi Graf Namen aus dem Umfeld der Weißen Rose herauszupressen.

Ebenfalls angeklagt waren in diesem Zweiten Prozess Hans und Susanne Hirzel, Franz Müller, Hans Guter, Eugen Grimminger, Heinrich Bollinger, Helmut Bauer, Falk Harnack, Gisela Schertling, Katharina Schüddekopf und Traute Lafrenz.

Die Haftstrafen fielen unterschiedlich hoch aus: Eugen Grimminger wurde zu zehn Jahren Haft verurteilt, Heinrich Bollinger und Helmut Bauer zu jeweils sieben Jahren, Hans Hirzel und Franz Müller zu jeweils fünf Jahren, Hans Guter zu achtzehn Monaten. Gisela Schertling, Katharina Schüddekopf und Traute Lafrenz wurden zu einem Jahr Gefängnis verurteilt, Susanne Hirzel zu sechs Monaten. Falk Harnack wurde freigesprochen.

Falk Harnack wurde zunächst aus „Mangel an Beweisen“ freigesprochen. Als er im Dezember 1943 erneut verhaftet und in ein Konzentrationslager gebracht werden sollte, gelang ihm die Flucht.

Andere Helfer und Mitwisser wurden in weiteren Prozessen zu Freiheitsstrafen zwischen sechs Monaten und zehn Jahren verurteilt.

Die Herkunft des Namens "Weiße Rose" – abgeleitet von der Überschrift "Weiße Rose" über den ersten vier Flugblättern der Gruppe – ist ungeklärt. Einige sehen einen Bezug zum Buch "Die weiße Rose" von B. Traven. Nach seiner Verhaftung am 18. Februar 1943 gab Hans Scholl an, den Namen „willkürlich gewählt“ zu haben:

Der Aussagewert dieser Verhörsituation ist jedoch unklar; möglicherweise wollte Scholl seine Motive geheim halten, um die anderen Mitglieder der Gruppe zu schützen. Als sicher kann gelten, dass Hans Scholl das Buch von Traven kannte und schätzte. 

In einem Brief vom 27. Juni 1938 an seine Schwester Inge hatte Hans Scholl geschrieben:
Das Symbol der weißen Rose könnte auch von der Kirschblüte beeinflusst worden sein, einem Symbol der dj.1.11, der Hans und Sophie Scholl angehörten. Möglicherweise geht der Name auf die Zeichnung einer weißen Rose auf einer Postkarte aus dem Verlag Max Baur zurück. Dies veranlasste im Oktober 1941 den Soldaten Fritz Rook zu einem Text darüber, was eine weiße Rose für ihn bedeutet. Dieser Text wiederum gefiel Alexander Schmorell so gut, dass er die Adressatin, Lilo Ramdohr, bat, diesen kopieren zu dürfen, um ihn Hans Scholl zu zeigen.

Der Historiker Sönke Zankel führte die Namensgebung in seiner Dissertation hingegen auf eine angebliche Grundhaltung der Gruppe von begabten Studenten gutbürgerlicher Herkunft zurück:

Diese Deutung, die dem Widerstandskreis anfänglich noch unzureichendes demokratisches Wertebewusstsein zuschreibt, ist für einen holzschnittartigen Umgang mit den Quellen kritisiert worden.

Die Hoffnung der Weißen Rose, dass die Katastrophe von Stalingrad in Deutschland offenen Widerstand gegen das Regime entfachen würde, erfüllte sich nicht. Die nationalsozialistische Propaganda benutzte die Niederlage im Gegenteil, um die Bevölkerung auf den „totalen Krieg“ einzuschwören. Am 18. Februar 1943, dem Tag der Verhaftung der Scholls, hielt Propagandaminister Joseph Goebbels unter dem Jubel seiner Zuhörer seine Sportpalastrede.

Kurz nach der Verhaftung der Geschwister Scholl und Christoph Probsts veröffentlichten die Zeitungen Fahndungsaufrufe nach Alexander Schmorell. Am 22. Februar 1943 mussten sich die Münchener Studenten versammeln und offiziell gegen die „Verräter aus ihren Reihen“ protestieren. Am 23. Februar 1943 veröffentlichten der "Völkische Beobachter" und die "Münchener Neueste Nachrichten" kurze Notizen über die Verhaftung und Hinrichtung einiger „degenerierte[r] Einzelgänger“. Das Netzwerk der Freunde und Unterstützer der Weißen Rose erwies sich jedoch als zu groß, die Behörden konnten die Gerüchte nicht vollständig unterdrücken. Bis zum Ende des Zweiten Weltkriegs fanden Verfolgungen statt, und deutsche Zeitungen berichteten, meist in kurzen Artikeln, über die Verhaftung und Bestrafung weiterer Personen. Am 15. März 1943 dokumentierte ein Bericht des SS-Sicherheitsdiensts, dass Gerüchte um die Flugblätter „beträchtliche Unruhe“ unter der Bevölkerung auslösten. Besonders besorgt zeigte sich der Bericht über die Tatsache, dass die Flugblätter nicht mehr so zuverlässig bei den Behörden abgeliefert würden wie bisher.

Am 18. April 1943 publizierte die "New York Times" einen Artikel unter der Überschrift „Signs of strain seen in German populace“ („Anzeichen von Spannung in der deutschen Bevölkerung“), und erwähnt den Widerstand der Studenten in München. Die "New York Times" veröffentlichte am 29. März und 25. April 1943 weitere Artikel über den ersten Prozess unter dem Titel „Nazis Execute 3 Munich Students For Writing Anti-Hitler Pamphlets“ („Nazis richten drei Münchener Studenten wegen Anti-Hitler-Flugblättern hin“) und „Germans Clinging to Victory Hope in Fear of Reprisals“ („Deutsche klammern sich aus Furcht vor Vergeltung an den Sieg“). Auch wenn nicht alle Informationen über den Widerstand, die Prozesse und die Urteile korrekt waren, stellen diese Artikel die ersten Nachrichten über die Weiße Rose in den Vereinigten Staaten dar.

Am 27. Juni 1943 äußerte sich der Schriftsteller und Literaturnobelpreisträger Thomas Mann in seiner monatlichen Sendung "Deutsche Hörer!" über die BBC bewundernd über den Mut der Münchener Studenten. Die sowjetische Rote Armee verbreitete hinter der deutschen Front ein Propagandaflugblatt „Senkt die Fahnen über frischen Gräbern deutscher Freiheitskämpfer!“ zu Ehren der Studenten, das später fälschlich dem Nationalkomitee Freies Deutschland zugeschrieben wurde.

Der Text des sechsten Flugblatts der Weißen Rose wurde von dem deutschen Anwalt und Mitglied des Kreisauer Kreises, Helmuth James Graf von Moltke über Skandinavien nach Großbritannien geschmuggelt. Im Juli 1943 wurde der Text unter dem Titel „Ein deutsches Flugblatt“ von Flugzeugen der Alliierten über Deutschland abgeworfen. Der Widerstand der Weißen Rose war somit großen Teilen der deutschen Bevölkerung schon während des Krieges bekannt.

Heute sind die beiden Plätze vor dem Universitätshauptgebäude in München nach den Geschwistern Scholl und Prof. Huber benannt, vor dem Eingang erinnern in den Boden eingelassene steinerne Flugblätter an die Weiße Rose. Diese wurden in der Nacht auf den 4. April 2006 von Unbekannten zerstört, eine Erneuerung der Flugblätter war jedoch sowieso vorgesehen. Innerhalb des Hauptgebäudes der Universität erinnern eine steinerne weiße Rose und ein Relief mit dem Bild der Mitglieder der Weißen Rose in der südwestlichen Ecke des Lichthofs mit darüber eingemeißelten Namen der Mitglieder an die Widerstandsgruppe. Am Lichthof befindet sich die 1997 vom Verein Weiße Rose Stiftung e. V. errichtete "DenkStätte Weiße Rose" mit der Dauerausstellung "Die Weiße Rose. Der Widerstand von Studenten gegen Hitler, München 1942/43". Am 22. Februar 2005 wurde in der nordwestlichen Ecke eine von Nikolai Tregor Jr. angefertigte Bronze-Büste von Sophie Scholl enthüllt. Sie und die beiden Herrscher König Ludwig I. und Prinzregent Luitpold sind die einzigen Menschen, denen in diesem Bereich der LMU ein Denkmal gesetzt wurde.

Das Institut für Politische Wissenschaften der Universität trägt seit 1968 den Namen Geschwister-Scholl-Institut. In der in den 1960er Jahren errichteten "Studentenstadt Freimann" wurden mehrere Straßen nach Mitgliedern der "Weißen Rose" benannt. Zusätzlich dazu strebten die Fachschaften und der AStA der Ludwig-Maximilians-Universität vergeblich eine Umbenennung der Universität in „Geschwister-Scholl-Universität“ an.

Der erste Prozess gegen Sophie und Hans Scholl sowie gegen Christoph Probst fand am 22. Februar 1943 im Schwurgerichtssaal des Münchener Justizpalastes, Prielmayerstraße 7, statt, der zweite Prozess gegen weitere 14 Angeklagte, darunter gegen Professor Huber, Alexander Schmorell und Willi Graf, am 19. April 1943 im Sitzungssaal 216 (heute: 253). Dieser Sitzungssaal ist heute als Gedenkstätte ausgestattet und kann werktags von 9 Uhr bis 16 Uhr besichtigt werden, nicht aber vom 10. April bis 31. Mai und vom 10. Oktober bis 30. November (wegen der zu diesen Zeiten stattfindenden Juristischen Staatsprüfungen).

Eines der wenigen bekannten Fotos, auf dem mehrere Mitglieder der Weißen Rose zusammen zu sehen sind (Sophie Scholl, Hans Scholl, Alexander Schmorell, Willi Graf und Hubert Furtwängler) entstand am 23. Juli 1942 an der Orleansstraße, gegenüber der Hausnummer 63. Ende 2017 wurde bekannt, dass der Zaun möglicherweise aufgrund des anstehenden S-Bahn-Ausbaus abgerissen werden könnte. Der Bezirksausschuss Au-Haidhausen setzt sich für den Erhalt des Zauns als „Originalschauplatz von historischer Bedeutung“ ein.

1946 wurden Willi Grafs sterbliche Überreste nach Saarbrücken auf den Friedhof St. Johann überführt und ruhen seitdem in einem Ehrengrab. Am 12. Oktober 2009, anlässlich des 66. Todestages, wurde eine Gedenkstätte in Form eines kleinen Gebäudes in Nähe des Grabes errichtet. Darin finden sich Bilder und Zitate von Willi Graf und eine Zusammenfassung seiner Lebensgeschichte. Bei der Gestaltung der Texte half seine Schwester Anneliese Knoop-Graf, die kurz vor der Eröffnung der Ausstellung verstarb.

Die russisch-orthodoxe Kirche im Ausland hat im Jahr 2007 die Heiligsprechung von Alexander Schmorell beschlossen. Der Festakt zur Heiligsprechung fand am 4. Februar 2012 in der Münchner Kathedralkirche, nahe den Grabstätten der Geschwister Scholl, Christoph Probsts und Alexander Schmorells auf dem Friedhof am Perlacher Forst, statt.

In Orenburg, Russland, werden seit 2000 alljährlich von der Stiftung Weiße Rose finanzierte Alexander-Schmorell-Stipendien an vier Studenten vergeben. Seit 2004 besteht das Orenburger Memorialzentrum Weiße Rose (zweisprachige, deutsch-russische Dauerausstellung in der Orenburger staatlichen pädagogischen Universität).

Seit 1980 wird der mit 10.000 Euro dotierte Geschwister-Scholl-Preis vergeben. Der Literaturpreis wird vom Börsenverein des Deutschen Buchhandels – Landesverband Bayern gemeinsam mit dem Kulturreferat der Landeshauptstadt München ausgelobt. Sinn und Ziel des Geschwister-Scholl-Preises ist es, jährlich ein Buch jüngeren Datums auszuzeichnen, das von geistiger Unabhängigkeit zeugt und geeignet ist, bürgerliche Freiheit, moralischen, intellektuellen und ästhetischen Mut zu fördern und dem gegenwärtigen Verantwortungsbewusstsein wichtige Impulse zu geben.

1987 gründeten Mitglieder der Weißen Rose und Verwandte der hingerichteten Mitglieder der Weißen Rose in München die Weiße Rose Stiftung e. V. als einen eingetragenen gemeinnützigen Verein. Die Geschäftsstelle befindet sich im Hauptgebäude der Ludwig-Maximilians-Universität. Die Gründung wurde unterstützt von Städten und Gemeinden, in denen die Mitglieder der Weißen Rose lebten und Widerstand leisteten. Ziel der spendenfinanzierten Weiße Rose Stiftung ist es, im In- und Ausland die Erinnerung an den Widerstand der Weißen Rose wach zu halten und Zeichen für die Zukunft zu setzen. Sie betreut zudem die DenkStätte am Lichthof der Ludwig-Maximilians-Universität sowie mehrere Wanderausstellungen im In- und Ausland mit über 20 Stationen jährlich.

Die Dauer- und Wanderausstellung der Ulmer DenkStätte Weiße Rose mit dem Titel "„wir wollten das andere“ – Jugendliche in Ulm 1933 bis 1945" entstand auf Initiative von Franz J. Müller (Ehrenvorsitzender der Weißen Rose Stiftung). Sie ist ein Projekt der Weißen Rose Stiftung, Ulmer Volkshochschule (vh Ulm) und des Deutschen Volkshochschul-Verbandes – gefördert von der Robert Bosch Stiftung. Die DenkStätte befindet sich in der Ulmer Innenstadt im EinsteinHaus der vh am Kornhausplatz. Die vh wurde 1946 von Inge Aicher-Scholl im Geiste der „Weißen Rose“ in der Martin Luther Kirche neu gegründet.

Neben den Ulmer Mitgliedern der Weißen Rose Hans und Sophie Scholl, Franz J. Müller, Hans und Susanne Hirzel sowie Heiner Guter werden in der Dauerausstellung der Ulmer DenkStätte Weiße Rose 22 Ulmer porträtiert, die zwar nicht zur „Weißen Rose“ gehörten, aber ebenfalls als Jugendliche Widerstand gegen den Nationalsozialismus leisteten oder sich auf andere Art dem Regime verweigerten.

In der Sowjetischen Besatzungszone und späteren Deutschen Demokratischen Republik wurden zahlreiche Straßen und Einrichtungen nach den Geschwistern Scholl benannt, obwohl die Gruppe einen christlichen Hintergrund hatte, während die DDR-Führung den kommunistischen Widerstand herausstellte. Die meisten Benennungen nach den Scholls erfolgten unmittelbar nach Kriegsende bis Anfang der 50er Jahre. Häufiger Initiator war die Vereinigung der Verfolgten des Naziregimes (VVN). Die VVN galt zwar in den Westzonen bzw. der frühen Bundesrepublik bald als kommunistisch unterwandert, betonte selbst aber ihre Überparteilichkeit und verstand es insbesondere in der Erinnerungs- sowie Gedenkarbeit, entgegen vielfältiger Vereinnahmungsversuche durch die KPD/SED, eine gewisse Eigenständigkeit zu wahren. Dies führte 1953 letztlich zum Verbot der VVN in der DDR. 

Die Geschwister Scholl sollten insbesondere Kindern und Jugendlichen als gewissenhaftes und humanistisches Vorbild dienen, weshalb viele Schulen nach ihnen benannt wurden (so z.Bsp. in Löbau, Freiberg, Sondershausen). In Leipzig wurde das ehemalige Gebäude der Handelshochschule 1948 in Geschwister-Scholl-Haus umgewidmet und dient seitdem der Universität als Sitz verschiedener Einrichtungen.

Im Zuge der Stalinisierung geriet die Vorliebe für die Geschwister-Scholl bzw. für andere Protagonisten der Weißen Rose bei Namensgebungen in die Kritik. Der Leiter der Berliner VVN-Forschungsstelle Klaus Lehmann bezeichnete die häufigen Widmungen in einem Schreiben vom 6. Januar 1951 an Hermann Axen, Leiter der Abteilung Agitation und Propaganda des ZK der SED, als einen Hinweis für das Agieren „reaktionärer Kräfte“. Die bisherigen Ehrungen der Gruppe stünden „in keinem Verhältnis zu ihrer Tätigkeit und schon gar nicht zu dem Kampf der proletarischen Widerstandskämpfer.“ Stattdessen sollten vermehrt Widmungen nach Ernst Thälmann und anderen Kommunisten durchgeführt werden. Weitere Ehrungen blieben in der Folge weitgehend aus. Zu einer aktiven Dekanonisierung des christlich motivierten Widerstandes kam es hingegen nicht. 

Im Gedenken an die Weiße Rose gab Freimut Börngen als Entdecker eines Asteroiden diesem den Namen (7571) Weisse Rose.

Im Marburger Stadtteil Ockershausen wurde auf dem Gelände der ehemaligen Tannenbergkaserne eine Gedenkstätte errichtet. Auf dem sogenannten "Platz der Weißen Rose" findet sich ein abstraktes Denkmal, das auf einem Brunnen steht. In Verlängerung der Rampe des Brunnens finden sich einige dutzend Meter entfernt Gedenktafeln.

Im Mai 2003 gründeten Angehörige der Mitglieder der Widerstandsgruppe das Weisse Rose Institut, das die Leistung der Gruppe wissenschaftlich untersuchen und würdigen soll. Der Verein initiiert und fördert die Durchführung von Forschungsvorhaben.

Es handelt sich um eine Dauerausstellung im Foyer der Ulmer Volkshochschule; die Wanderausstellung ist in deutscher Sprache ausleihbar.






Dokumente


</doc>
<doc id="10822" url="https://de.wikipedia.org/wiki?curid=10822" title="Wiedervereinigung">
Wiedervereinigung

Unter Wiedervereinigung versteht man die Wiederherstellung der Einheit von politischen oder rechtlichen Gebilden. Sie ist zu unterscheiden von einer einfachen Vereinigung von Gebilden, die zuvor nicht friedlich oder gewaltsam geteilt wurden.

Wiedervereinigung steht territorial (staatliche Einheit) für:

Wiedervereinigung steht bei Personenzusammenhängen für:

Siehe auch:


</doc>
<doc id="10825" url="https://de.wikipedia.org/wiki?curid=10825" title="Pierre Curie">
Pierre Curie

Pierre Curie (* 15. Mai 1859 in Paris; † 19. April 1906 ebenda) war ein französischer Physiker und Nobelpreisträger.

Pierre Curie wurde als zweiter Sohn des Arztes Eugène Curie und der Fabrikantentochter Sophie-Claire Depouilly in Paris geboren. Er wurde von Privatlehrern unterrichtet und legte bereits mit 16 Jahren das Abitur ab. Mit 19 Jahren erwarb er einen Universitätsabschluss in Physik. In der Folge wurde Curie zum Lehrer an der Schule für Physik und Chemie in Paris berufen, deren Leitung er 1882 übernahm. Er schloss 1895 seine Promotion ab und wurde zum Professor ernannt. 1900 wurde Curie Repetitor an der École polytechnique.

Am 26. Juli 1895 heiratete er die polnische Physikerin Maria Skłodowska (später bekannt als Marie Curie), mit der er zwei Töchter hatte: Irène und Ève.
Pierre Curie starb am 19. April 1906 in Paris im Alter von 46 Jahren bei einem Verkehrsunfall, als er unter ein Pferdefuhrwerk geriet und dabei einen Schädelbruch erlitt.

Am 20. April 1995 wurden die sterblichen Überreste von Pierre und Marie Curie mit einem Staatsbegräbnis ins Panthéon überführt.

In seinen frühen Studien über die Kristallographie, die er mit seinem älteren Bruder Jacques durchführte, entdeckte er 1880 die Piezoelektrizität. Weitere Arbeiten zur Symmetrie richteten seine Aufmerksamkeit auf das Gebiet des Magnetismus. Dabei entdeckte er die Curie-Temperatur und das Curie-Gesetz. Auch die Curie-Konstante ist nach ihm benannt.

Zusammen mit seiner Frau Marie entdeckte er 1898 das Radium und das Polonium als Spaltprodukte der Pechblende. Im Jahre 1903 erhielt er gemeinsam mit seiner Frau Marie Curie eine Hälfte des Physik-Nobelpreises für „ihre gemeinsamen Arbeiten über die von H. Becquerel entdeckten Strahlungsphänomene“. Die zweite Hälfte des Preises ging an Henri Becquerel.






</doc>
<doc id="10829" url="https://de.wikipedia.org/wiki?curid=10829" title="Hispaniola">
Hispaniola

Hispaniola () oder "Kiskeya" (in der Sprache der Taínos), span. "Quisqueya", ist mit einer Fläche von etwa 76.480 km² die zweitgrößte der Westindischen Inseln und gleichzeitig der Großen Antillen. Auf der Insel liegen die Staaten Haiti und Dominikanische Republik.

Ungefähr 90 km westlich liegt die größte Antilleninsel Kuba und 190 km westlich Jamaika, 120 km östlich Puerto Rico, 250 km nördlich die Gruppe der Turks- und Caicosinseln und 180 km nordnordwestlich die Inselgruppe Inagua.
Die Insel erstreckt sich 600 km in Ost-West- und 250 km in Nord-Süd-Richtung. Sie hat die Form einer nach Westen geöffneten Hand, wobei zwei gebirgige Halbinseln weit gegen Kuba bzw. in den Jamaica Channel hervorragen. Relativ flach sind nur der Osten und ein im Norden zwischen zwei Bergketten durchziehendes Längstal.

Der größere östliche Teil der Insel bildet heute die Dominikanische Republik, der kleinere westliche Teil die Republik Haiti. ("Siehe auch:" Liste geteilter Inseln)

Mit seinen mehr als einundzwanzig Millionen Einwohnern ist Hispaniola die bevölkerungsstärkste Insel der Antillen.
Im Jahr 2015 betrug die Bevölkerungszahl auf der Insel Hispaniola bereits 21,396 Mill. Die Bevölkerungsdichte erreichte somit 279,8/km².

Die einheimischen Tainos nannten die Insel "Kiskeya" (übersetzt etwa „wunderbares Land“) oder auch "Ayití" (übersetzt „gebirgiges Land“), woraus die heutigen Bezeichnungen „Quisqueya“ und „Haiti“ entstanden. Haiti bezeichnete also ursprünglich die gesamte Insel. Der Begriff Quisqueya findet sich in der ersten Zeile der Dominikanischen Nationalhymne ("Quisqueyanos valientes, alcemos: Nuestro canto con viva emoción ...") und wird auch als Markenname verschiedener Produkte verwendet. Es gibt auch eine kleinere, nicht sehr bedeutsame politische Bewegung, die anstrebt, die beiden Staaten unter dem gemeinsamen Namen "Quisqueya" zu vereinen.

Christoph Kolumbus nannte die Insel "La Isla Española" („die spanische Insel“). Die Engländer verballhornten den Namen zu "Hispaniola" („Kleinspanien“).

Die Insel Hispaniola wurde in der Kolonialzeit politisch in einen spanischen Ostteil, "Santo Domingo" (oder "San Domingo") genannt (nach der gleichnamigen Stadt), und einen französischen Westteil, "Saint Domingue" (oder "Saint-Domingue"), getrennt. Aus dem Ostteil wurde die Dominikanische Republik, aus dem Westteil Haiti, das zeitweise in das nördliche Nord-Haiti und die südliche Mulatten-Republik geteilt war.

In diesem Artikel ist, wenn nicht ausdrücklich von der Stadt gesprochen wird, mit Santo Domingo immer der Ostteil Hispaniolas gemeint. Auch ist mit Haiti der Klarheit wegen immer der Staat im Westteil der Insel gemeint.

Hispaniola, Jamaika, Kuba und Puerto Rico sind zusammen bekannt als die Großen Antillen. Die größten vorgelagerten Inseln sind auf haitianischer Seite die Île de la Gonâve und die Île de la Tortue sowie auf Seiten der Dominikanischen Republik die Isla Saona.

Auf der Insel liegen fünf große Bergketten.


Die zum Teil großen Höhenunterschiede auf der Insel Hispaniola in Verbindung mit tropischen Regenfällen haben schon häufiger, zuletzt zweimal im Jahr 2004, zu schweren Überschwemmungen mit Tausenden von Todesopfern geführt:
Im Mai 2004 war die Region um Jimaní im Süden der Insel betroffen, der Arroyo Blanco trat über die Ufer (nördlich der Gebirgskette Massif de la Selle/Sierra de Baoruco, zwischen den Seen Étang de Saumatre und Lago Enriquillo), im September 2004 der Norden, besonders das Cibao-Tal in der Nähe des Río Yaque del Norte, und am schwersten die Region um die haitianische Stadt Gonaïves.

Die Insel liegt auf der Grenze der Nordamerikanischen und der Karibischen Platte und ist deshalb ein potentielles Erdbebengebiet. Am 4. August 1946 gab es in der Dominikanischen Republik ein Beben der Stärke 8,1 (Epizentrum auf der Halbinsel Samana), am 26. September 2003 ein Beben der Stärke 6,8 (Epizentrum nahe Puerto Plata). Am 12. Januar 2010 erschütterte ein verheerendes Erdbeben der Stärke 7,0 Haiti (Nähe Carrefour, Port-au-Prince, Delmas).
Das Klima auf Hispaniola ist allgemein feucht und tropisch. Die Insel hat vier verschiedene Ökoregionen. Feuchtwälder bedecken etwa 50 % der Insel, besonders den nördlichen und östlichen Teil, vorwiegend das Tiefland, aber auch bis in eine Höhe von 2100 m. Die Region der Trockenwälder bedeckt etwa 20 % der Insel im Regenschatten der Berge im Süden und Westen sowie im Cibao-Tal im mittleren Norden der Insel. Die hispaniolischen Kiefernwälder bedecken die bergigsten 15 % der Insel oberhalb von 850 m. Die Enriquillo-Feuchtlande sind eine Region überschwemmter Weiden und Savannen, die die Seenkette des Enriquillo-Sees, der Rincón-Lagune, des Caballero-Sees, der Saumatre-Lagune und des Trou Cayman umgibt.
Im Teil der heutigen Dominikanischen Republik ist die Tierwelt sehr vielfältig, in den Ökonischen gibt es z. B. Seevögel, Kolibris, Reptilien (Land- und Meeresschildkröten, Wirtelschwanzleguane), Amphibien (Frösche etc.), Reiher, Flamingos sowie viele Fischarten. Die Republik Haiti legt weniger Wert auf den Schutz ihrer Öko-Ressourcen und erkannte nicht das wichtige Potenzial für den Tourismus. Wälder werden bedenkenlos abgeholzt; Land verkarstet oder Lawinen bilden sich.

Bis 1492 lebten auf Hispaniola hauptsächlich die indianischen Völker der Arawak, Ciboney und der Kariben. In seinen Aufzeichnungen schätzte Las Casas die Anzahl der Indios von 1494 auf gut 3 Millionen. Wegen ungenügend verfügbarem historischem Material gibt es von Historikern nur ungenaue Schätzungen über die Anzahl, diese gehen von 400.000 bis 8 Millionen Einwohnern aus.

Vielleicht der Höhepunkt der vorkolonialen Kulturgeschichte war die Kultur der Arawak, die aus Venezuela stammten und seit dem 7. Jahrhundert v. Chr. über die Kleinen Antillen eingewandert waren. Um 1600 starben die Arawak aus.

Am 5. Dezember 1492 entdeckte Christoph Kolumbus Hispaniola für Europa. Nach Goldlagerstätten forschend, entdeckte Kolumbus die Häfen von Valparaiso (heute Port-de-Paix), Punta Santa und errichtete vor seiner Rückkehr nach Europa in der Nähe des Letzteren mit Hilfe der Arawak aus den Trümmern des gestrandeten Schiffs "Santa Maria" ein kleines Fort, La Navidad, worin er eine Besatzung von 40 Mann zurückließ. La Navidad war die erste Kolonie Spaniens in Amerika.

Bei seiner Rückkehr nach Hispaniola am 28. November 1493 fand er das Fort in Trümmern; Arawaken angeführt vom Kaziken Caonabo hatten – gereizt durch die Gewalttaten und Plünderungszüge der 40 Spanier – das Fort zerstört und die Besatzung beendet. Kolumbus ließ daraufhin in einem Feldzug gegen die Arawaken viele von ihnen versklaven und nach Spanien schicken, was nicht auf Zustimmung des spanischen Königspaares stieß. Die Spanier legten im Osten des Kap Montecristi im Januar 1494 die Stadt La Isabela an, von wo aus sie sich in den Besitz der reichen Goldminen von Cibao setzten und zur Sicherung derselben das Fort St. Thomas errichteten.

Als Kolumbus 1496 die Heimreise antrat, gründete sein Bruder Bartolomeo im Süden, an der Mündung des Flusses Ozama, eine neue Stadt, Santo Domingo, welche die Hauptstadt der Insel wurde und ihr (bzw. dem Ostteil) später ihren Namen gab. Seitdem La Isabela aufgegeben wurde, ist Santo Domingo die älteste noch bestehende von Europäern gegründete Siedlung in Amerika.

Am 31. August 1498 erreichte Kolumbus erneut die Stadt Santo Domingo. Er versuchte, Streitigkeiten der Siedler mit seinem Bruder zu schlichten und verstärkte die Christianisierung sowie die Suche nach Gold. Aufgrund negativer Berichte ersetzte der spanische Hof Kolumbus als Gouverneur durch Francisco de Bobadilla, der am 23. August 1500 Hispaniola erreicht. Er nahm Christoph und Bartolomeo Kolumbus gefangen und schickte sie in Ketten nach Spanien. Hier wurden die beiden Männer durch das Königspaar begnadigt, jedoch nicht wieder in ihre ehemaligen Ämter eingesetzt.

Unter dem 1503 eingeführten "Encomienda-System", das die Indios zur Zwangsarbeit verpflichtete, litten diese sehr. Nach den Aufzeichnungen vom Zeugen Las Casas lebten auf Hispaniola 1508 nur noch 60.000 Indios. Neben den unmenschlichen Arbeitsbedingungen in der Sklavenarbeit und der Verfolgung von Flüchtigen starben zusätzlich viele Indios durch aus Europa und Afrika eingeschleppte Seuchen, gegen die sie keine Abwehrkräfte hatten. Eine der Stätten dieses raschen Sterbens waren die von Francisco de Bobadilla aufgefundenen und von ihm sowie seinem Nachfolger Nicolás de Ovando ausgebeuteten Goldminen von San Cristoforo, die reiche Ausbeute lieferten.

1517 brachte Pedro d’Atenza das Zuckerrohr von den Kanarischen Inseln nach Haiti, und Gonzalez gab den Impuls zum Plantagen- und Zuckermühlenbau. Zu deren Betreibung holte Ovando, da viele der einheimischen Indios bereits umgekommen waren, 40.000 Kariben von den Bahamas. Aber auch diese starben infolge der Seuchen bald, worauf (ab 1503 oder 1505) Menschen aus Afrika verbracht und als Sklaven eingeführt wurden.

1509 wurde Diego Colón, der Sohn von Christoph Kolumbus, Gouverneur, später auch Vizekönig Hispaniolas. 1512 fand die Einweihung der Universität von Santo Domingo, der ersten Universität in der Neuen Welt, statt.

In der Zeit zwischen 1519 und 1533 erhoben sich die überlebenden Indios (etwa 4000) unter ihrem Führer ("Kaziken") Enriquillo (oder Enrico) erfolglos gegen die Spanier. Ihr Volk wurde in den folgenden Jahren und Jahrzehnten fast vollständig ausgerottet. Nach einem Friedensschluss auf Geheiß der Spanischen Krone überließen ihnen die Spanier ein kleines Gebiet bei Boyà bzw. Azua, ca. 100 Kilometer nordöstlich von Santo Domingo. Dass sich dort bis heute Nachkommen der Kaziken erhalten haben, beruht aber auf einer Legende. Vielmehr vermischten sich die Indios mit den Mulatten und verloren mit der Zeit ihre kulturelle und ethnische Identität. Anderen Berichten zufolge starben sie schon im späten 16. Jahrhundert durch eine Seuche aus.

Von 1537 bis 1548 kam es zudem zu Aufständen geflohener schwarzer Sklaven, die Cimarrones genannt wurden. 1542 lebten auf der Insel 200 Indios, 5000 Spanier und 30.000 schwarze Sklaven. 1586 eroberte und plünderte der englische Freibeuter Francis Drake die Stadt Santo Domingo. Ein weiterer englischer Angriff fand 1655 unter Admiral William Penn statt.

Ab 1625 setzten sich französische und englische Seeräuber (Bukanier oder Flibustier genannt) auf dem nahen, nördlich gelegenen Eiland Île de la Tortue fest. Sie wurden zwar später vertrieben, aber ein vorwiegend aus Franzosen bestehender Überrest von ihnen siedelte sich als Pflanzer auf der menschenleeren Nordküste Hispaniolas an und bat Frankreich, sie gegen die Spanier zu unterstützen. Ludwig XIV. sandte daraufhin 1661 Bertrand d'Ogeron als Gouverneur nach Hispaniola und gründete im westlichen Teil der Insel 1665 eine französische Kolonie, welche indes 1686 von den Spaniern zerstört wurde. Schon 1691 aber wurde eine neue französische Kolonie durch Jean Baptiste du Casse gegründet. Im Frieden von Rijswijk verzichtete Spanien 1697 zugunsten Frankreichs auf den westlichen Teil („Saint Domingue“) der Insel.

Der französische und der spanisch verbliebene Teil Hispaniolas entwickelten sich sehr unterschiedlich.

1776 wurde die Grenze zwischen beiden Landesteilen reguliert (die in etwa der heutigen entspricht).

In Santo Domingo lahmte die Entwicklung. Die Goldfunde, die viele Spanier in die Kolonie gezogen hatten, gingen zur Neige. Viele Spanier zogen weg und diejenigen, die blieben, verarmten oft und ließen ihre Sklaven häufig frei. Von den 125.000 Einwohnern, die 1790 gezählt wurden, waren 15.000 Sklaven.

Am 22. Juli 1795 wurde zwischen Spanien und Frankreich der Friede von Basel beschlossen, in dem Spanien Santo Domingo Frankreich überlassen musste. Das Land wurde an das französische Saint Domingue angeschlossen, das die Oberhoheit über Santo Domingo jedoch nur theoretisch ausübte.

Am 26. Januar 1801 besetzte Toussaint L’Ouverture (auch mit Hilfe von Weißen) das (praktisch noch) spanische Santo Domingo. Die Sklaverei wurde abgeschafft.

Nach Saint-Domingue wurden sehr viele Sklaven importiert, die entsprechend dem 1685 erlassenen Code noir leben mussten. Der Plantagenbau wuchs ungemein. Die Wirtschaft florierte, und die Kolonie gelangte nach dem spanischen Erbfolgekrieg bis 1714 zur höchsten kolonialen Blüte. Saint Domingue war zeitweise die reichste Kolonie Frankreichs. Bei einer Zählung 1788 lebten dort 455.089 Menschen, davon 27.717 Europäer (Oberschicht), 21.808 Mulatten (Mischlinge, meist frei, aber gegenüber den Europäern nicht als gesellschaftlich ebenbürtig anerkannt), der Rest – knapp 90 % – Schwarze und zugleich Sklaven als die unterste Schicht.

Am 26. November 1749 wurde Port-au-Prince gegründet und zur Hauptstadt gemacht.

Die Behandlung der Sklaven war sehr schlecht, es gab wiederholt Aufstände. Beispielsweise wurde im März 1758 der 18 Jahre zuvor geflohene Sklave Mackandal, der zahlreiche Aufstände angeführt hatte, zur Strafe lebendig verbrannt.

Am 19. Februar 1788 wurde die "Société des Amis des Noirs" (dt.: „Gesellschaft der Freunde der Schwarzen“) in Paris gegründet. Ihr Ziel war die Abschaffung des Sklavenhandels und eine schrittweise Abschaffung der Sklaverei. Sie sollte ideologisch großen Einfluss auf die Geschichte Saint Domingues gewinnen.

Angeregt durch die französische Revolution forderten die Europäer der Kolonie mehr Autonomie von Frankreich, die Mulatten ihre Gleichstellung und die Sklaven ihre Freiheit.

Die zahlenmäßig geringe europäische Bevölkerung Haitis (ca. 6 %) war durch die französische Revolution gespalten in „große“ und „kleine Weiße“ (Grundbesitzer und Gewerbsleute), Konstitutionelle und Monarchisten sowie in Anhänger und Gegner der Kolonialregierung.

Am 8. März 1790 erging der Beschluss über die Bildung von „Kolonialversammlungen“ (in denen nur Kolonisten, also Europäer, vertreten waren), die den Kolonien eine Art Autonomie ermöglichte. Mit Mulatten oder gar Schwarzen wollten diese ihre Macht nicht teilen (man sprach von einer „entarteten Menschenrasse“).

Der Versuch der Mulatten unter der Führung von Vincent Ogé und Jean-Baptiste Chavannes, ihre Forderungen durchzusetzen, endeten mit der Niederschlagung des Aufstandes im Oktober 1790 und der Folterung und Hinrichtung der beiden in Cap Français im Februar 1791.

Der 14. August 1791, als sich im Bois-Caïman, dem „Krokodilwald“ in der Nordebene des heutigen Haiti, mehrere Sklaven zu einer Voodoo-Zeremonie trafen, gilt als der Beginn des Aufstandes der Sklaven, der letztlich zur Unabhängigkeit Haitis führte. Der Aufstand brach am 22. oder 23. des Monats los und wurde von Boukman, Biassou und Jean-François angeführt. Er begann in der Umgebung von Cap Français und verbreitete sich nach der Einnahme von Cap Français durch die Sklaven (21.–23. Juni 1793) über die ganze Kolonie. Die von Frankreich zur Ordnung der Angelegenheiten in die Kolonie entsandten Bevollmächtigten Polverél, Santhonax (die Schreibweise Sonthonax kommt auch vor) und Ailhaud, die im September 1792 ankamen, konnten und wollten nicht dagegen einschreiten. Vielmehr erließen sie im August bzw. September 1793 die Abschaffung der Sklaverei.

In den folgenden Jahren der europäischen Koalitionskriege (auch Revolutionskriege genannt), insbesondere zwischen Frankreich und Großbritannien, schaffte es Toussaint L’Ouverture (auch Louverture geschrieben), ein freigelassener Sklave und heutiger Nationalheld Haitis, der wenige Wochen nach Beginn des Aufstandes hinzu stieß, in wechselnden Allianzen eine weitgehende Selbstständigkeit der Kolonie zu erkämpfen.

Als 1793 die Spanier und Engländer mehrere Plätze der Kolonie besetzten, verband sich das Heer der Sklaven mit dem der französischen Truppen, die unter General Lavaux zur Behauptung der Insel gelandet waren.

Die weißen Kolonisten wurden von den Insurgentengeneralen Rigaud und Toussaint schließlich 1797 gezwungen, die Insel ganz zu verlassen, worauf das französische Direktorium am 4. Februar 1798 den Schwarzen in den französischen Kolonien völlige Freiheit und gleiche Rechte mit den Weißen bewilligte. Gleichzeitig wurde Toussaint zum Obergeneral aller Truppen in Haiti ernannt. 1799 wurde er Gouverneur der Kolonie.

Von 1799 bis 1800 tobte ein Bürgerkrieg zwischen Schwarzen und Mulatten, in dem Letztere unterlagen.

Toussaint besetzte nicht nur Santo Domingo, sondern besiegte auch die englischen Freibeuter. Er strebte nach Unabhängigkeit von Frankreich und gab der Insel am 9. Mai 1801 (eine Quelle nennt Juli 1801) eine eigene Verfassung. Toussaint wurde dabei Gouverneur und Alleinherrscher auf Lebenszeit. Die Plantagen wurden wieder in Betrieb genommen und von ehemaligen Sklaven in Zwangsarbeit bewirtschaftet. Eine andere Quelle würdigt die wirtschaftlichen Maßnahmen Toussaints als Landreform.

Napoléon Bonaparte schickte 1801 General Charles Victoire Emmanuel Leclerc als Capitaine général mit 25.000 Mann nach Haiti, wo er im Februar 1802 ankam. Toussaint widersetzte sich anfangs seiner Landung bei Cap François, musste sich jedoch bald ins Innere zurückziehen. Am 25. Februar 1802 wurde Santo Domingo besetzt und die Sklaverei wiederhergestellt, obwohl Bonaparte erst am 20. Mai 1802 die Wiedereinführung der Sklaverei in den französischen Kolonien erließ. Toussaint wurde am 6. oder 7. Juni 1802 gefangen genommen und nach Frankreich deportiert, wo er am 7. April 1803 in der Haft starb.

Geschickte militärische Operationen, eine britische Seeblockade und eine Gelbfieber-Epidemie machten den Interventionstruppen Napoléons jedoch schwer zu schaffen. Auch Leclerc starb daran. Sein Nachfolger wurde Rochambeau. Da die verbliebenen weißen Pflanzer die Sklaverei durchzusetzen suchten, kam es erneut zum Aufstand – diesmal unter dem schwarzen General Jean-Jacques Dessalines. Er besiegte am 18. November 1803 die Franzosen unter Rochambeau und fügte damit Napoléon seine erste Niederlage zu. Die Franzosen und anderen Weißen mussten die Insel räumen.

Am 1. Januar 1804 proklamierte Jean-Jacques Dessalines die Unabhängigkeit von Saint Domingue (gefeiert wird heute in Haiti der Tag der Verfassungsgebung, der 9. Mai 1801, als Unabhängigkeitstag). Am selben Tag besetzten französische Truppen Santo Domingo, wo die Sklaverei wieder eingeführt wurde. Praktisch wurde damit nur der Westteil Hispaniolas unabhängig.

Das Land erhielt den Namen „Haiti“, die Selbstbezeichnung lautete damals „Erster Freier Negerstaat“. Aus dem vielleicht einzigen erfolgreichen Sklavenaufstand der Weltgeschichte ging damit die erste selbstständige (aber instabile) Nation Lateinamerikas hervor. Dessalines ist heute einer der Nationalhelden Haitis.

Dessalines entwarf eine Flagge, indem er einfach das Weiß der französischen Tricolore entfernte. Er ernannte sich selbst am 8. Oktober (oder Dezember) zum Kaiser Jakob I. ("Empereur Jacques I") und erließ am 20. Mai 1805 eine neue Verfassung. Die meisten der im Lande verbliebenen Franzosen wurden ermordet. Die Plantagen wurden enteignet und aufgeteilt, besetzt oder verlassen. Die auf dem Export der Landwirtschaft beruhende wirtschaftliche Stärke Saint Domingues schwand. Das Ziel einer egalitären Gesellschaft, die Triebfeder der französischen Revolution und auch des haitianischen Freiheitskampfes war, wurde verfehlt. Die Mulatten wurden die neue Elite, die Schwarzen blieben weitgehend eine ungebildete und rechtlose Landbevölkerung.

1805 eroberte Haiti das seit einem Jahr unter französischer Herrschaft stehende Santo Domingo.

Dessalines Grausamkeit rief schon im folgenden Jahr eine Verschwörung unter dem Schwarzen Henri Christophe und dem Mulatten Alexandre Pétion hervor, durch welche er am 17. Oktober 1806 ermordet wurde. Mit seinem Tod endete auch das Kaisertum; Haiti wurde wieder Republik.

Als Führer des Freiheitskampfes (der Schwarzen) wurde auch Henri Christophe ein Nationalheld Haitis.

Alsbald brach auch die durch den gemeinsamen Hass gegen die Weißen in den Hintergrund gedrängte Rivalität zwischen Mulatten und Schwarzen offen aus und blieb fortan das Motiv aller inneren Kämpfe des neuen Staats. Pétion, als Anführer der Mulatten, und Christophe, als Anführer der Schwarzen, kämpften miteinander um die Oberherrschaft. Das Land spaltete sich in eine südliche Mulatten-Republik mit Pétion als Präsident an der Spitze und in einen nördlichen Staat (Nord-Haiti), dem Henri Christophe als ernannter Präsident vorstand.

Beide Staaten trennte ein breiter Landstrich, den man absichtlich unbebaut ließ, und der bald, von Lianen und Dorngesträuch überdeckt, eine natürliche Grenze bildete.

1808 verlor Haiti die Herrschaft über Santo Domingo. Einer Ansicht nach eroberten die Spanier Santo Domingo zurück; einer anderen Ansicht nach konnten die spanischen Kreolen (einheimische Nachfahren von Spaniern) von Santo Domingo mit britischer Unterstützung die Haitianer vertreiben, legten dann aber ihr Land wieder in spanische Hände.

Am 26. März 1811 verwandelte Christophe Nord-Haiti in eine erbliche Monarchie und ließ sich unter dem Namen "Henri I" zum König krönen. Er ahmte auf naive Weise den französischen Hofstaat nach und vergab viele komisch anmutende Titel, Hof- und Staatsämter. Schließlich gab es vier Prinzen, acht Herzöge, 22 Grafen und eine große Anzahl von Angehörigen des niederen Adels.

Auf dem 945 Meter hohen Pic La Ferriere ließ er von bis zu 20.000 Zwangsarbeitern die mächtigste Festung seiner Zeit außerhalb Europas errichten, die . Zugleich erschien ein neues Staatsgesetzbuch (Code Henri).

Die Sklaverei blieb im Grunde die alte, nur trat an die Stelle der Peitsche der Säbel. Zwischen beiden Staaten (des Westteils) herrschte unversöhnliche Feindschaft, und nur in der Zurückweisung der nach dem Wiener Kongress erneuerten Ansprüche Frankreichs waren sie einig. Pétion gab am 2. Juni 1816 seiner Republik eine Verfassung, welche Abschaffung aller Sklaverei, Pressefreiheit etc. festsetzte. Nach Pétions Tod am 27. März 1818 versuchte Henri I. die Mulatten-Republik mit seinem Königreich zu vereinigen; allein der Mulatten-General Jean-Pierre Boyer, der als Präsident Nachfolger Pétions geworden war, wusste diesen Versuch zu vereiteln. Henri I. selbst, welchen ein Aufruhr republikanisch gesinnter Mulatten in seinem Reich zu Grausamkeiten gereizt hatte, wurde immer verhasster, und im September 1820 brach ein Aufstand gegen ihn aus, der bald das ganze Reich erfasste und den Abfall seiner Truppen zur Folge hatte, worauf sich König Henri I. am 8. Oktober 1820 erschoss. Hierauf fand, da sich das Heer dem Präsidenten Boyer unterwarf, am 26. November 1820 die Vereinigung beider Teile Haitis zu einer einzigen Republik statt.

Am 1. Dezember 1821 proklamierte José Núñez de Cáceres den „Unabhängigen Staat Spanisch-Haiti“ ("Estado Independiente de Haití Español").

1822 kam es zum erneuten Anschluss Santo Domingos an Saint Domingue. Zu dem Ablauf gibt es zwei Ansichten: (1) Der Plan von Cáceres, das Land Großkolumbien unter Simón Bolívar anzuschließen, scheiterte, weil die Mehrzahl der Schwarzen und Mulatten eine Union mit Haiti vorzog, wo die Sklaverei bereits abgeschafft war. Der Anschluss an Haiti (und Abschaffung der Sklaverei) erfolgte 1822. Möglich ist auch (2), dass Jean-Pierre Boyer, nachdem er Nord- und Süd-Haiti in seiner Macht hatte, mit den nun frei gewordenen militärischen Kräften 1822 Santo Domingo unterwarf und es am 8. Februar annektierte. Hauptmotiv war dabei die Verstaatlichung der spanischen Kirchengüter, die Sklavenbefreiung und die Einsetzung einer effizienteren nach französischem Vorbild ausgerichteten Landesverwaltung.

Die Republik Haiti wurde in der Folge von den meisten Staaten anerkannt. Nach mehreren vergeblichen Wiedereroberungsversuchen erkannte selbst Frankreich sie 1825 an, allerdings gegen eine an die ehemaligen Plantagenbesitzer zu zahlende Entschädigung von 150 Mio. Franc, die 1838 bei Gelegenheit des Abschlusses eines Handelsvertrags zwischen Frankreich und Haiti auf 60 Mio., in 30 Raten bis 1867 zu zahlen, herabgesetzt wurde. Dieser Betrag ruinierte die haitianische Wirtschaft.

Haiti musste zur Bezahlung der Schulden Steuern einführen, die langanhaltende Unzufriedenheit, besonders im spanisch geprägten Ostteil, verursachte. Insbesondere finanzierte Boyer sie durch Anleihen bei französischen Banken, und diese Auslandsverschuldung wurde chronisch.

Seit 1822 regierte Boyer nach der Verfassung vom 2. Juni 1816 als Staatspräsident auf Lebenszeit, jedoch unter beständigem Zerwürfnis mit dem Repräsentantenhaus.

Im Frühjahr 1842 wurde Haiti von einem furchtbaren Erdbeben heimgesucht, das einige Städte fast vernichtete; besonders hart wurde die Stadt Cap-Haïtien betroffen. Boyer wurde 1843 durch eine von den Mulatten Dumesle und Charles Rivière-Hérard geleitete Verschwörung gestürzt, ging nach Europa ins Exil, wo er 1850 in Paris verstarb.

Die siegreichen Parteihäupter teilten darauf die Stellen unter sich auf. Widerstand zeigte sich nur in dem spanisch geprägten Ostteil (Santo Domingo), weshalb Rivière eilig mit Truppen dahin zog, die vornehmsten Einwohner von Santo Domingo gefangennahm und eine Besatzung unter seinem Bruder, dem Obersten Leo Herard, zurückließ. Aber kaum wurde eine neue Verfassung eingeführt und hatte Rivière als Präsident die Macht übernommen, als im August 1843 im Ostteil wieder ein offener Aufstand ausbrach.

Am 27. Februar 1844 erkämpfte sich und proklamierte Santo Domingo als Dominikanische Republik ("República Dominicana") seine Unabhängigkeit vom westlichen Landesteil Haiti.




</doc>
<doc id="10831" url="https://de.wikipedia.org/wiki?curid=10831" title="Rutherfordsches Atommodell">
Rutherfordsches Atommodell

Das rutherfordsche Atommodell ist ein Atommodell, das 1911 von Ernest Rutherford aufgestellt wurde. Es bildet die Grundlage für das heutige Bild vom Atom, indem es den Atomkern einführte, der als außerordentlich kleine, positiv geladene Kugel im Zentrum des Atoms fast dessen ganze Masse vereinigt. Damit überwand das rutherfordsche Atommodell das etwas ältere thomsonsche Atommodell und diente seinerseits als Ausgangspunkt des bohrschen Atommodells von 1913, mit dem die Energiestufen der Atomhülle erstmals erfolgreich beschrieben werden konnten.

Vor dem rutherfordschen Streuversuch (1909) von Hans Geiger, Ernest Marsden und Ernest Rutherford war bekannt, dass Atome negativ geladene Elektronen und die gleiche Menge an positiver Ladung enthalten. Einen Erklärungsversuch für den Aufbau der Atome stellte das thomsonsche Atommodell dar. Demnach besteht das Atom aus gleichmäßig verteilten positiven Ladungen und Elektronen, die sich darin bewegen. Der rutherfordsche Streuversuch zeigte, dass die positive Ladung und ein Großteil der Masse in einem kleinen Atomkern vereinigt sind und widerlegte damit dieses Atommodell.

Rutherfords Mitarbeiter Hans Geiger und Ernest Marsden führten einen Versuch mit Alpha-Teilchen durch. Zunächst wurde entgegen der damals gängigen Vorstellung, dass Alpha-Teilchen von Materie nicht reflektiert werden, beobachtet, dass von Wismut-214 ausgesandte Alpha-Teilchen zumindest teilweise von einer Platinplatte reflektiert wurden. Es war also völlig unerwartet, dass einige Teilchen von der Metallschicht zurückgeworfen wurden.

In einem verfeinerten Versuchsaufbau wurde die Verteilung der Ablenkwinkel (zwischen 0° und 180°) im Vakuum mit dünnen Folien verschiedener Metalle, darunter Gold, untersucht. Auch hier zeigte sich, dass etwa eines von 8000 Alphateilchen zurückgeworfen wurde, was auf ein kleines massives Zentrum im Inneren der Atome schließen ließ. Dieses massive Zentrum im Inneren des Atoms bezeichnete Rutherford als Atomkern.

Unter Verwendung der nach ihm benannten Streuformel leitete Rutherford aus den Experimenten Werte für die Größe und Ladung der positiven Ladungsverteilung von Gold und anderen Elementen ab. Dabei kam er zu dem Schluss, dass die enorme elektrische Feldstärke, die für die gemessene starke Ablenkung von Alpha-Teilchen erforderlich ist, nur unter der Annahme erklärbar ist, dass die positive Ladung des Atoms vollständig in einem kompakten Atomkern konzentriert ist, dessen Radius um ca. einen Faktor 3000 kleiner ist als der Atomradius.

Zur Erklärung der elektrischen Neutralität von Atomen ging Rutherford davon aus, dass der Atomkern von Elektronen umgeben wird, wobei die Gesamtanzahl der Elektronen pro Atom genau der Kernladungszahl entspricht. Über die räumliche Verteilung der Elektronen ließen sich allerdings aus den Experimenten keine Informationen ableiten, da die Elektronen aufgrund ihrer geringen Masse nicht in nachweisbarem Umfang zur Ablenkung der Alphastrahlen beitragen. Entgegen häufig zu findenden Darstellungen in Lehrbüchern und anderen Sekundärquellen entwickelte Rutherford kein eigenes Modell der Elektronenstruktur von Atomen, er zitierte lediglich im Februar 1911 bei einem Vortrag vor der "Manchester Literary and Philosophical Society", der Basis eines im Mai im "Philosophical Magazine" erschienenen Artikel war, Nagaokas „planetarisches Modell“, um seine Abschätzung der Kernladungszahl von Gold zu plausibilisieren.

Ein Problem besteht in der Erklärung von Emissionen und Absorptionen von Energiequanten: Mit dem Modell von Rutherford kann keine Erklärung für die so genannten Spektrallinien diverser Gase gegeben werden. Es wurde daher durch das bohrsche Atommodell abgelöst, das den Elektronen unterschiedliche Energieniveaus zuordnet.

Ein weiteres Problem, das auch durch das bohrsche Atommodell nicht gelöst werden konnte, besteht darin, dass das Modell keine Erklärung dafür liefert, warum die Elektronen nicht in den Kern stürzen, obwohl kreisende und damit beschleunigte Ladung nach Maxwell ständig Energie abstrahlt. Des Weiteren könnte ein langsam in den Kern stürzendes Elektron Photonen mit jeder beliebigen Frequenz emittieren, was aber, aufgrund der quantisierten Energieniveaus nach formula_1, unmöglich ist.


</doc>
<doc id="10833" url="https://de.wikipedia.org/wiki?curid=10833" title="Taublatt">
Taublatt

Das Taublatt ("Drosophyllum lusitanicum"), eine fleischfressende Pflanze, ist die einzige Art der Familie der Taublattgewächse (Drosophyllaceae). Sie findet sich fast ausschließlich auf der Iberischen Halbinsel.

Das Taublatt ist ein mehrjähriger Halbstrauch mit einem nicht oder nur schwach verzweigten, verholzenden Stamm, der üblicherweise eine Gesamthöhe von vierzig Zentimetern, selten aber auch bis zu 1,60 Meter erreicht. Die Pflanzen können bis zu acht Jahre alt werden.

Das Wurzelsystem ist für eine karnivore Pflanze extrem gut ausgeprägt, es besteht aus einer starken Pfahlwurzel mit vielen feinen Seitenwurzeln. Zweck dieses Wurzelsystems ist es vor allem, zu Zeiten starker Trockenheit tiefliegende Wasserreserven zu erschließen.

Das Taublatt hat zahlreiche, etwa 30 Zentimeter lange, linealische, auf der Blattoberfläche gerillte Blätter, die der Pflanze als Fallen dienen. Die Blattknospen sind ungewöhnlicherweise nicht nach innen, sondern nach außen eingerollt. Als junge Blätter zeigen sie aufwärts und weisen erst mit zunehmendem Alter mehr und mehr in die Horizontale. Sobald sie diese Position erreicht haben, sterben sie allmählich ab, während am oberen Ende der Sprossachse kontinuierlich neue Blätter gebildet werden. Das abgestorbene Blattwerk fällt jedoch nicht ab, sondern bleibt an der Pflanze und hängt buschig entgegen der Sprossachsenrichtung herab. Es ist stark UV-reflektierend und zieht damit Beutetiere an, möglicherweise dient es aber auch zur Unterdrückung konkurrierender Vegetation.

Die Blätter des Taublatts sind Klebefallen, die an den Blatträndern mit zwei verschiedenen Typen von Drüsen besetzt sind. Die rotgefärbten Fangdrüsen mit mehrzelligen Stielen scheiden ein klebriges Sekret aus, in dem sich die Insekten verfangen. Die meist farblosen, gelegentlich aber ebenfalls rotgefärbten Verdauungsdrüsen sitzen direkt auf der Blattoberfläche und scheiden das Verdauungssekret aus. Es gibt 5- bis 10-mal so viele Verdauungsdrüsen wie gestielte Fangtentakeln. Die Sekretproduktion ist ungewöhnlich intensiv, darum und weil das Sekret eine geringere Viskosität als das anderer Karnivoren aufweist, tropft das Sekret gelegentlich von den Blättern herab. Als Verdauungsenzyme finden sich Esterasen, Phosphatasen, Proteasen, Peroxidase und Leucinaminopeptidase. Die Fallen des Taublatts sind, anders als bei den meisten Karnivoren mit Klebefallen, passiv, also unbeweglich. Trotzdem ist die Pflanze ein äußerst effektiver Insektenfänger. Zum Anlocken der Insekten dient unter anderem der stark honigartige Duft des Sekrets.

Die Blätter enthalten größere Mengen Plumbagin, das durch seine mikrobizide Wirkung die Pflanze wahrscheinlich vor Pilzen und Bakterien schützt.

Die vier bis fünfzehn fünfzähligen Blüten blühen ab Februar bis Juni/Juli. Sie stehen in einer Doldentraube und haben einen Durchmesser von 2,5 bis 4 Zentimetern, die Blütenstiele, die linealischen Nebenblätter (die zum Apex hin immer kürzer werden) und die am Grunde miteinander verwachsenen Kelchblätter sind dicht mit Tentakeln behaart. Die fünf freien Kronblätter sind zitronengelb, das Androeceum besteht aus zehn bis zwanzig in zwei Kreisen angeordneten Staubblättern mit fadenförmigen Staubfäden (Filamenten), das Gynoeceum hat fünf freie, fadenförmige Griffel. Das Taublatt ist selbstbefruchtend, als Bestäuber finden sich Zottelbienen ("Panurgus"), Schwebfliegen und Käfer.

Die Blüten öffnen sich nur für wenige Stunden. Nach erfolgter Bestäubung reift über einen Monat eine durchscheinende Kapselfrucht, diese öffnet sich über die Länge und gibt fünf bis zehn umgekehrt eiförmige, lackschwarze Samen mit einem Durchmesser von bis zu 2,5 Millimeter frei. Die Samen bleiben bis zu mehreren Jahren keimfähig. 

Die Chromosomenzahl beträgt 2n = 12.

Das Taublatt ist beheimatet auf bis zu 800 m über Meereshöhe an den westlichen Küsten Portugals und Spaniens (Andalusien), sein Verbreitungsgebiet strahlt aber aus bis ins nördliche Marokko (um Tanger). Auf der Iberischen Halbinsel finden sich vereinzelt auch küstenferne Standorte.

Es wächst bevorzugt auf schwach sauren oder neutralen, im Sommer extrem trockenen Fels-, Kies- und Sandböden in vollsonniger Lage, gern auch als Pionierpflanze an erodierten Standorten. Zur Deckung des Wasserbedarfs in Trockenzeiten dienen dabei vermutlich Küstennebel. Kurze und oberflächliche Feuer schaden den Pflanzen nur wenig und sorgen zugleich für eine Öffnung der umgebenden Vegetation zugunsten der Pflanzen, schwere und längere Feuer töten sie jedoch. Seinen Standorten angemessen ist es sehr hitzefest (Temperaturen bis zu 45 °C übersteht es schadlos), aber auch bedingt winterhart.

Häufig findet es sich gemeinsam mit Korkeichen, Steineichen, Wacholder, Erika und Kiefern, in letzterem Fall dann auch mit Zistrosen ("Cistus") und Stechginster ("Ulex"). Weitere Pflanzengattungen, mit denen das Taublatt vergesellschaftet vorkommt, sind unter anderem Lavendel, Gänseblümchen, Seggen, Schwingel und Kreuzblumen.

Die Art ist zunehmend bedroht, die Vorkommen gehen immer weiter zurück, aktuell gelten 80 % aller historisch bekannten Bestände als vernichtet. Als wichtigste Einflüsse gelten dabei Siedlungsdruck und Infrastrukturmaßnahmen (z. B. Straßenbau), Aufforstungen, die die konkurrenzschwachen Pflanzen verdrängen, sowie speziell in Marokko, aber auch Andalusien die Nutzung der Standorte als Weidegebiet für Rinder. Als die intaktesten Standorte gelten die andalusischen, da dort der menschliche Einfluss am geringsten ist.

Die Gattung ist monotypisch, das heißt, sie enthält nur die eine Art. Da die Familie keine weiteren Gattungen enthält, ist sie auch monogenerisch.

Die nächsten Verwandten der Art stellen die (bis auf das Hakenblatt) nichtkarnivoren Ancistrocladaceae und Hakenblattgewächse (Dioncophyllaceae) dar, sowie etwas entfernter die Kannenpflanzengewächse (Nepenthaceae).

Erstmals beschrieben wurde die Pflanze 1661 in Gabriel Grisleys "Viridarium Lusitanum" als „chamaeleontioides“. J.P. Tournefort führte sie 1689 in seiner portugiesischen Flora als „ros solis lusitanicus maximus“ auf. Linné stellte die Pflanze 1753 als "Drosera lusitanica" zu den Sonnentau-Arten. 1806 trennte Heinrich Friedrich Link sie als eigene Gattung ab, sie blieb allerdings weiterhin der Familie der Sonnentaugewächse zugeordnet. Seit den Forschungen von Chrtek u. a. 1989 wird sie jedoch in eine eigene Familie, die Taublattgewächse (Drosophyllaceae) gestellt.

Der botanische Name "Drosophyllum" stammt aus dem Griechischen - von „drosos“ für „Tau“ und „phyllon“ für „Blatt“, daher auch der deutsche Name „Taublatt“. Die Bezeichnung "lusitanicum" leitet sich von einem keltischen Stammesnamen ab und wurde von den Römern als Bezeichnung für die Provinz Lusitania übernommen, die große Teile des heutigen Portugal umfasste.

Nach dem deutschen Trivialnamen ist auch die von der Gesellschaft für Fleischfressende Pflanzen herausgegebene Zeitschrift "Das Taublatt" benannt.




</doc>
<doc id="10834" url="https://de.wikipedia.org/wiki?curid=10834" title="Koma">
Koma

Das Koma () ist eine über längere Zeit bestehende völlige Bewusstlosigkeit. In der Medizin ist ein voll ausgeprägtes Koma die schwerste Form einer quantitativen Bewusstseinsstörung, bei der ein Patient auch durch starke äußere Stimuli, wie wiederholte Schmerzreize, nicht geweckt werden kann. Ist dieser Zustand nicht voll ausgeprägt, spricht man von Sopor (Präkoma).

Das Koma ist ein Symptom (Krankheitszeichen) und keine Krankheit. In der internationalen Klassifikation der Gesundheitsstörungen (ICD-10) wurde es daher in die Rubrik „R“ (Symptome und Befunde) eingeordnet (R40.2). Das Koma ist Ausdruck einer schweren Störung der Großhirnfunktion und zumeist lebensbedrohend. Die weitere Entwicklung (Prognose) des Komatösen ist von der zugrunde liegenden Erkrankung und medizinischen Versorgung abhängig.





Die Einteilung erfolgt nach klinischen Gesichtspunkten, also entsprechend der Reaktion auf bestimmte Reize. Je nach verwendeter Klassifikation werden zumeist drei bis vier Grade unterschieden:


In der Notfallmedizin etabliert ist die Glasgow-Koma-Skala – die auch als Entscheidungshilfe z. B. für Beatmung herangezogen wird. Sie umfasst auch leichtere Bewusstseinsstörungen.

Diese vor allem in den Medien genutzten Begriffe bezeichnen eine medikamentös herbeigeführte Bewusstseinsminderung, die nach dem Absetzen der Arzneistoffe reversibel ist. Darum sollte hier die Benutzung des Begriffes "Koma" vermieden werden, da "Koma" im medizinischen Sinne einen ungeregelten Bewusstseinsverlust beschreibt. Treffender sind die Begriffe Sedierung oder Langzeit-Narkose. Sedierung ist ein kontrollierter Zustand. Patienten, die in schwierigen Phasen einer Intensivbehandlung betäubt werden, erhalten zu diesem Zweck Medikamente in wirkungsabhängiger Dosierung. Dabei werden, meist in Kombination, Medikamente mit verschiedener Wirkung eingesetzt: Beruhigungs- und Schlafmittel (Sedativa, Hypnotika, etwa Benzodiazepine oder Propofol), Schmerzmittel (Opioidanalgetika), andere Narkotika sowie Psychopharmaka. Auch beatmete Patienten werden manchmal nicht die ganze Zeit in tiefer Narkose gehalten, wenn möglich nur sediert (vgl. Richmond Agitation Sedation Scale).

Durch Beobachtung, Patientenbefragungen und technische Überwachungs- und Untersuchungsmethoden ist das Bild immer differenzierter geworden, welche Leistungen des Gehirns während einer Narkose, gerade auch Dauernarkose, herabgesetzt werden: Wachheit (Vigilanz), Stress, Schmerzempfindung, Angst, motorische Reaktion, Erinnerung. Die meisten eingesetzten Medikamente beeinflussen mehrere Hirnleistungen, mit unterschiedlichem Schwergewicht.

Dabei gibt es nicht nur Unterschiede von Medikament zu Medikament, sondern auch in der Wirkung desselben Medikamentes auf verschiedene Patienten. So kann ein gut sedierter, aber durchaus nicht komatöser Patient bei Behandlungsmaßnahmen kooperieren, ohne sich anschließend an irgendetwas zu erinnern (Amnesie), ein bewegungslos und ohne vegetative Stresszeichen im Bett liegender Patient sich nachher an zahlreiche Einzelheiten erinnern, ein dritter trotz hoher Dosen an Beruhigungs- und Schmerzmitteln zwar nicht ansprechbar, aber motorisch unruhig sein.

Hierbei handelt es sich um eine schwere Hirnschädigung, bei der die Funktion des Großhirns stark beeinträchtigt, teilweise ausgefallen oder sogar ganz erloschen ist. Daher wird sie auch als „apallisches Syndrom“ („ohne Hirnrinde“) bezeichnet. Die Lebensfunktionen werden – wie normalerweise auch – durch den Hirnstamm aufrechterhalten, die Patienten erlangen aber mangels kognitiver Funktionen nicht das Bewusstsein. Als Folge werden die Betroffenen zwar wach, können aber weder aktiv noch passiv in Kontakt mit der Umwelt treten. Fachlich exakt wird das Wachkoma als Persistierender Vegetativer Status (PVS) bezeichnet.

Wachkomapatienten haben, soweit das Großhirn nicht zu stark geschädigt ist, eine gute Prognose, wieder aufzuwachen. Entsprechendes wird weltweit immer wieder berichtet. Der Zeitraum kann jedoch – wie beim gewöhnlichen Koma auch – stark variieren: Von wenigen Tagen bis hin zu etlichen Jahren. Durch entsprechende Rehabilitationsmaßnahmen kann der Prozess erheblich unterstützt werden, insbesondere, wenn der Betroffene schon Anzeichen der Rückbildung des Komas zeigt.




</doc>
<doc id="10835" url="https://de.wikipedia.org/wiki?curid=10835" title="Wasserfalle">
Wasserfalle

Die Wasserfalle ("Aldrovanda vesiculosa"), auch Wasserhade oder Blasige Aldrovandie, ist eine fleischfressende Pflanze aus der Familie der Sonnentaugewächse (Droseraceae). Die Wasserfalle ist eine Wasserpflanze.

Die Wasserfalle ist die einzige rezente Art in der monotypischen Gattung "Aldrovanda". Es gibt jedoch weitere fossile Arten in dieser Gattung. Innerhalb der Art gibt es signifikante geografische Unterschiede: So kennt z. B. die australische Form weder eine Winterruhe durch Turionen, noch ist sie frosthart.

Die Wasserfalle ist eine ausdauernde, krautige Süßwasser<nowiki>pflanze</nowiki>. Sie ist wurzellos, nur der Keimling besitzt eine rudimentäre Wurzel, die aber früh abstirbt.

Die Pflanze wird etwa 10 bis 30 cm lang. Entlang der Sprossachse stehen in kurzen Abständen in wirtelförmiger Anordnung fünf bis neun 2 bis 3 mm lange Fangblätter an einem Blattstiel, den allerdings Diels als einen „verlängerten Blattgrund“ charakterisiert. Der Blattgrund enthält mehrere luftgefüllte Hohlräume, die für den größten Teil des Auftriebs der Pflanze sorgen. Die Pflanze wächst an der einen Seite und stirbt am anderen Ende ab; unter guten Bedingungen werden so ein bis zwei Wirtel pro Tag gebildet.

Mit ihren Fangblättern, einer Klappfalle ähnlich einer kleineren Ausgabe der Venusfliegenfalle, fängt die Wasserfalle kleine Tiere, vorzugsweise Wasserflöhe, aber auch beispielsweise junge Mückenlarven. Am Rand der Fallen stehen vier bis sechs auffällig steife Borsten; auch im Inneren ist die Falle fein behaart mit sensiblen Härchen. Dabei handelt es sich um Fühlhärchen, die das Schließen der beiden Hälften der Blattspreite in maximal 1/50 Sekunde veranlassen, wobei der Fang nur bei warmen Wassertemperaturen möglich ist (ab etwa 20 °C). Hat die Falle erst einmal eine Beute gefangen, so wird diese mit Hilfe von Verdauungssäften zersetzt.

Die kleine, weiße Blüte der Wasserfalle erhebt sich an kurzen Stielen über die Wasseroberfläche; sie bleibt nur wenige Stunden geöffnet. Die nachfolgende Bildung der Samenkapsel hingegen erfolgt wieder unter Wasser. Die Samen keimen kryptokotylar, das heißt, die Keimblätter verbleiben innerhalb des Samenkorns und nehmen dessen Reserven, das so genannte Endosperm, auf. Allerdings blüht die Wasserfalle – zumindest in temperierten Bedingungen – eher selten.

Die Wasserfalle vermehrt sich meist vegetativ. Dazu verzweigt sich die Pflanze während ihrer Wachstumsphase stark. Durch das nachfolgende Absterben des Hauptsprosses entstehen voneinander unabhängige Individuen. Da die Pflanze starkwüchsig ist, können so schnell zahlreiche Individuen entstehen.

Eine zweite Methode vegetativer Vermehrung, die allerdings nur bei winterharten Formen vorkommt, ist die durch so genannte Turionen im Rahmen der Überwinterungsstrategie der Pflanze. Dabei lösen sich zum Ende der Wachstumsperiode Blattwirtel von der Sprossspitze und sinken wegen des hohen Gewichts und des Ausstoßes von Gasen auf den Grund des Wassers. Die Turionen sind frosthart bis zu −15 °C. Mit dem Neubeginn des Wachstums im Frühjahr steigen die Turionen wieder auf und beginnen erneut mit dem Wachstum.

Die Chromosomenzahl beträgt 2n = 48.

Die Wasserfalle ist die am weitesten verbreitete Karnivorenart überhaupt, denn sie ist in Europa, Asien, Afrika und Australien beheimatet. In all ihren Arealen ist sie jedoch selten. Die Art breitet sich über Epichorie aus: sie haftet am Gefieder von Wasservögeln, die sie so in andere Gewässer verschleppen. Dadurch findet sich die Wasserfalle gehäuft entlang von Vogelzugrouten.

Die Wasserfalle bedarf äußerst sauberer, seichter, heller und warmer stehender Gewässer, die zugleich nährstoffarm und schwach sauer (pH-Wert um 6) sind. Sie ist zwischen Binsen oder Schilf, aber auch Reis frei schwimmend zu finden. Mit zunehmender Verdichtung des Bewuchses ihres Areals geht die Wasserfalle dann wieder zurück und taucht an anderen Stellen wieder auf. Sie reagiert empfindlich auf den Befall durch Algen.

Die gedeiht in Gesellschaften des Verbands Hydrocharition.

In europäischen Ländern ist die Wasserfalle selten, vom Aussterben bedroht oder bereits ausgestorben. Sie wird hier häufig als tertiäres Relikt betrachtet. Vor 200 Jahren ließen sich noch 150 Standorte nachweisen; gegenwärtig sind nur noch knapp unter vierzig bekannt, meist in Ost- und Südosteuropa gelegen (z. B. 10 in Polen, 1 in Ungarn, 1 in Rumänien, sowie wenige im ehemaligen Jugoslawien, in Bulgarien, der Ukraine und Russland). In den letzten 30 Jahren starb die Art in Europa in Frankreich, Italien, der Slowakei, Österreich (Bodensee) und Deutschland aus. Der zu beobachtende Rückgang der Wasserfalle ist im Allgemeinen auf zivilisationsbedingte Eutrophierung (Erhöhung der Nährstoffzufuhr) ihrer Gewässer zurückzuführen.

In Deutschland ist sie erneut in Brandenburg und Worms nachgewiesen; die dortigen Bestände gelten jedoch als angesalbt, offiziell ist sie seit 1986 ausgestorben. Einige Bestände existieren auch in der Schweiz, wo sie eigentlich nicht heimisch ist; diese Standorte gehen auf Ansalbungen aus dem Jahre 1908 zurück. Sie sind aber trotzdem streng geschützt, unter anderem, weil sie auf die in Deutschland selbst erloschenen Bestände aus dem Bodensee zurückgeführt werden.

Auch in Asien ist die Art im Rückgang begriffen; um die Jahrtausendwende ist die Art als Wildform in Japan ausgestorben, nachgewiesen ist sie noch in Bengalen.

In Australien sind die Vorkommen der Wasserfalle noch ungestört. Sie kommt dort sowohl in tropischen Formen (z. B. um Darwin oder in Queensland) als auch subtropisch (z. B. um Esperance) vor.

Über detaillierte Standorte der Pflanze in Afrika ist wenig bekannt. Berichtete Vorkommen ziehen sich von Nordostafrika bis nach Zentral- (Sudan, Uganda, Ruanda, Tansania, Simbabwe, Mosambik) und Südafrika (z. B. das Okavango-Delta in Botswana). Aufgrund der vergleichsweise ungestörten afrikanischen Flora und der geringen Agrarisierung des Kontinents ist eine Gefährdung der Art dort als unwahrscheinlich anzusehen.

In Australien und allen europäischen Ländern, in denen sie noch existiert, ist die Art streng geschützt.

Anhand von fossilen Samen- und Pollenfunden lässt sich die Evolution der Gattung weit zurückverfolgen. Mitte der 1980er Jahre wurden im heutigen Tschechien Samenfragmente einer Art aus dem Ende der Kreidezeit gefunden, die als der älteste bekannte Vorgänger der Gattung gedeutet wurden und zugleich den zweitältesten Fossilfund einer karnivoren Art überhaupt darstellten. Die als "Palaeoaldrovanda splendens" beschriebene Pflanze wäre demnach eine Zeitgenossin der Dinosaurier gewesen und hätte unter tropischen Bedingungen gelebt. Eine Studie aus dem Jahr 2010 zeigte jedoch, dass die vermeintlichen Samenfragmente keiner näher verwandten Droseraceae zuzuordnen sind, sondern dass es sich mit hoher Wahrscheinlichkeit um die fossilen Eier eines Insektes handelt.

Das durch vor 65 Millionen Jahren an der Kreide-Tertiär-Grenze ausgelöste Massensterben beeinträchtigte das weitere Gedeihen dieser Gattung nicht. Fast zwanzig weitere Arten sind aus dem frühen Känozoikum bekannt. Die trennten sich bereits im Eozän in die Sektionen Aldrovanda, Obliquae und Clavatae. Ob nun Warm- oder Kaltzeiten folgten, die Gattung blieb stets mit mehreren Arten präsent. Selbst im Pleistozän, dem unserer Gegenwart vorausgehenden Eiszeitalter, lassen sich noch sechs Arten nachweisen, von denen jedoch nur "A. vesiculosa" bis in die Gegenwart überlebte.

Da auf Grund der geringen Masse der Pflanzen stets nur Samen oder Pollen fossil erhalten sind, lässt sich kaum eine Aussage über die frühere Gestalt der Pflanzen treffen. Umso bedeutender war der bisher einzigartige Fund eines fossilen Blattes einer ca. 6 Millionen Jahre alten "Aldrovanda inopinata" aus dem Miozän. Dieser Fund wurde 1963 in Wackersdorf gemacht. Das Blatt ist dem der heutigen Art sehr ähnlich; ein wichtiger Unterschied liegt jedoch im Fehlen der sensiblen Härchen im Zentrum der Blattspreite.

Entdeckt wurde die Wasserfalle 1699 von Leonard Plukenet in Indien, der sie "Lenticula palustris Indica" nannte. Ihren heutigen wissenschaftlichen Namen erhielt sie 1747 durch Giuseppe Monti, der italienische Exemplare beschrieb und zu Ehren des italienischen Gelehrten Ulisse Aldrovandi "Aldrovandia vesiculosa" nannte. Bei der Übernahme des Namens durch Carl von Linné im Jahre 1753 ging allerdings das erste „i“ des Namens verloren. Ihr erster Nachweis in Deutschland erfolgte 1846 in einem Teich in Pleß (Pszczyna) in Oberschlesien durch Emanuel Friedrich Hausleutner.

Charles Darwin führte noch eine Unterscheidung der tropischen und subtropischen Formen der Wasserfalle von der temperierten Form unter den Bezeichnungen "Aldrovanda vesiculosa" var. "australis" bzw. "Aldrovanda vesiculosa" var. "verticillata" an. Von dieser Systematik ist man abgekommen; heutzutage werden trotz unterschiedlicher Wuchsformen alle Wasserfallen als ein Taxon geführt.

Die nächstverwandte Art der Wasserfalle ist die morphologisch ähnliche Venusfliegenfalle.

Wie alle fleischfressenden Pflanzen ist auch die Wasserfalle Gegenstand des Interesses von Sammlern. In den 1990er Jahren wurde die Art verstärkt in Sammlungen aufgenommen, nachdem australische Typen importiert wurden, deren tropische bzw. subtropische Wuchsform ein Durchkultivieren unter gleichmäßigen Bedingungen ohne Winterruhe ermöglichte. Ihre dauerhafte Kultur gilt jedoch, auch wegen der aquatischen Haltung und ihrer speziellen Ansprüche, weiterhin als schwierig.

Eine stilisierte Wasserfalle ist das Symbol der deutschen Gesellschaft für Fleischfressende Pflanzen.




</doc>
<doc id="10836" url="https://de.wikipedia.org/wiki?curid=10836" title="Carl Benz">
Carl Benz

Carl Friedrich Benz (* 25. November 1844 in Mühlburg als "Karl Friedrich Michael Vaillant"; † 4. April 1929 in Ladenburg) war ein deutscher Ingenieur und Automobilpionier. Sein Benz Patent-Motorwagen Nummer 1 von 1885 gilt als erstes praxistaugliches Automobil. Am 29. Januar 1886 meldete er seinen Motorwagen zum Patent an.

Aus seinem 1883 gegründeten Maschinenbau- und Automobilunternehmen Benz & Cie. entstand 1926 durch Fusion mit der Daimler-Motoren-Gesellschaft die Daimler-Benz AG (heute Daimler AG).

Carl Benz wurde am 25. November 1844 in der Stadt Mühlburg (heute ein Stadtteil von Karlsruhe) als uneheliches Kind geboren. Im Kirchenbuch der evangelischen Gemeinde von Mühlburg wurde der Name "Karl Friedrich Michael Wailand" eingetragen. Seine Eltern waren die Karlsruher Dienstmagd Josephine Vaillant (im Kirchenbuch versehentlich "Wailand" geschrieben) und der 1809 geborene Lokomotivführer Johann Georg Benz. Die Mutter war evangelisch, der Vater katholisch. Johann Georg Benz stammte aus Pfaffenrot (heute Gemeinde Marxzell), wo seine Vorfahren über Generationen eine Schmiede betrieben hatten. Er arbeitete bei der Badischen Eisenbahn.

Taufzeugen waren laut Kirchenbuch der „Bürger, Gastwirth und Bierbrauer“ Michael Kramer aus Mühlburg und der Schuhmachermeister Karl Axtmann aus Karlsruhe, dessen Vorfahren aus Schielberg, ganz in der Nähe von Pfaffenrot kommen. Es ist anzunehmen, dass Michael Kramer der damalige Dienstherr der Mutter war und seiner hochschwangeren Magd weiterhin Quartier gewährt hatte. Sein Gasthaus in der Rheinstraße 22 war wahrscheinlich das Geburtshaus. Später erhielt es den Namen „Stadt Karlsruhe“. Ende der 1950er Jahre wurde es abgerissen.

Rund ein Jahr später, am 16. November 1845, heirateten die Eltern in der katholischen Stadtkirche St. Stephan. Trauzeuge war wiederum Michael Kramer. Das Kind hieß nun "Karl Friedrich Michael Benz". (Carl Benz bevorzugte später die Schreibweise "Carl" und veröffentlichte seine Lebenserinnungen unter dem Namen "Carl Friedrich Benz".) Nach der Hochzeit zogen die Eltern mit ihrem Kind nach Karlsruhe in die Erbprinzenstraße 13. Carl Benz war noch keine zwei Jahre alt, als sein Vater im Sommer 1846 an einer Lungenentzündung starb.

Ab 1853 besuchte Benz das naturwissenschaftlich orientierte Karlsruher Lyzeum. Seine Mutter konnte allein von ihrer kargen Witwenrente nicht leben. Sie vergab in Karlsruhe Kost und Logis an Studenten des Polytechnikums. Damit finanzierte sie auch die Ausbildung ihres Sohnes.

Am 30. September 1860 bestand der 15-jährige Karl Friedrich die Aufnahmeprüfung am Polytechnikum Karlsruhe. Dort studierte er Maschinenbau bei Ferdinand Redtenbacher, dem Begründer des wissenschaftlichen Maschinenbaus, der den Maschinenbau von seiner vorwiegend handwerklich-empirischen Basis zur angewandten höheren Mathematik führte, und nach dessen Tod bei Franz Grashof, einem genialen Theoretiker. Vier Jahre später beendete er am 9. Juli 1864 mit Erfolg seine Zeit als Eleve.

Carl Benz gründete 1871 in Mannheim mit den Mitteln seiner künftigen Ehefrau Bertha Ringer die "Eisengießerei und mechanische Werkstätte", die er später in "Fabrik für Maschinen zur Blechbearbeitung" umbenannte.

Am 20. Juli 1872 heiratete er Bertha Ringer. Aus der Ehe gingen fünf Kinder hervor: Eugen (* 1. Mai 1873; † 9. März 1958), Richard (* 21. Oktober 1874; † 19. September 1955), Clara (* 1. August 1877; † 18. Februar 1968), Thilde (* 2. Februar 1882; † 13. Januar 1974) und Ellen (* 16. März 1890; † 21. April 1973).

1878/79 entwickelte Carl Benz einen verdichtungslosen Zweitaktmotor und später einen leichten Viertaktmotor. Benz entwickelte den Differentialantrieb und andere Kraftfahrzeugelemente weiter, wie die Achsschenkellenkung, die Zündkerze, die Riemenverschiebung als Kupplung, den Vergaser, den Wasserkühler und die Gangschaltung.

Wegen der kostspieligen Entwicklungsarbeiten verlangte seine Hausbank 1882 die Umwandlung des Unternehmens in eine Aktiengesellschaft. Es firmierte nun als "Gasmotorenfabrik in Mannheim A. G." Im Aufsichtsrat der neu entstandenen Gesellschaft fand der Konstrukteur jedoch wenig Verständnis für seine Visionen. Benz verließ deshalb das Unternehmen.

Über diese als schwierig erlebte Zeit schrieb Benz später in seinen Lebenserinnerungen: „Nur ein Mensch harrte in diesen Tagen, wo es dem Untergange entgegen ging, neben mir im Lebensschifflein aus. Das war meine Frau. Tapfer und mutig hisste sie neue Segel der Hoffnung auf.“

1883 gründete Carl Benz die Benz & Cie. Rheinische Gasmotorenfabrik Mannheim.

1885 baute er das erste Benzinauto, den Benz Patent-Motorwagen Nummer 1, ein dreirädriges Fahrzeug ("Tricycle" laut Patenttext) mit Verbrennungsmotor und elektrischer Zündung. Es fuhr erstmals im Sommer 1885 in Mannheim, wie Bertha Benz im Jahre 1941 noch einmal schriftlich versichert hat. Das Fahrzeug hatte einen schiebergesteuerten Einzylinder-Viertaktmotor, der Benz zufolge bei einer Drehzahl von 250/min eine Leistung von 0,67 PS abgab. Damit erreichte das Fahrzeug 16 km/h Höchstgeschwindigkeit. Am 29. Januar 1886 schrieb Karl Friedrich Benz Industriegeschichte, indem er dieses Fahrzeug beim Reichspatentamt unter der Nummer 37435 zum Patent anmeldete.

Eine Fachpublikation kommt zu dem Schluss, dass Carl Benz mit dem dreirädrigen Patent-Motorwagen Nummer 1 den ersten praxistauglichen Kraftwagen konstruiert hat. Zunächst erntete Carl Benz für seine Arbeit jedoch viel Spott. Seine motorisierte Kutsche wurde als „Wagen ohne Pferde“ belächelt. Andererseits meinte der "Generalanzeiger der Stadt Mannheim" im September 1886, dass dieses Fuhrwerk eine Zukunft haben wird, weil es „ohne viele Umstände in Gebrauch gesetzt werden kann und weil es, bei möglichster Schnelligkeit, das billigste Beförderungsmittel für Geschäftsreisende, eventuell auch für Touristen werden wird“. Carl Friedrich Benz sah dies ähnlich und verbesserte seine Fahrzeuge stetig.
Carl Benz erhielt für seinen Motorwagen die erste Fahrerlaubnis der Welt, ausgestellt am 1. August 1888 vom Großherzoglich-Badischen Bezirksamt. Wenige Tage später unternahm seine Ehefrau Bertha mit dem Benz Patent-Motorwagen Nummer 3 die erste erfolgreiche automobile Fernfahrt. Sie fuhr mit ihren Söhnen Eugen und Richard von Mannheim in ihre Geburtsstadt Pforzheim (etwa 104 km), wo sie nach 12 Stunden und 57 Minuten ankam, und wieder zurück. An diese Fahrt erinnert heute die "Bertha Benz Memorial Route". Die auf dem Weg gelegene Wieslocher Stadt-Apotheke wurde zur ersten Tankstelle der Welt, als der dortige Apotheker das Gefährt der Reisegruppe mit Ligroin als Kraftstoff versorgte. So wurde auch Bertha Benz neben ihrem Ehemann zu einem Pionier der Automobilgeschichte.

1888 wurde das neuartige Vehikel („Vollständiger Ersatz für Wagen mit Pferden!“) durch die Teilnahme an der Münchner "Kraft- und Arbeitsmaschinenausstellung" zwar über die Grenzen Deutschlands bekannt, doch mögliche Käufer blieben zunächst skeptisch. 1889 wurden die neuen Benz-Modelle auf der Pariser Weltausstellung präsentiert. In Frankreich, das damals über die besten Straßen verfügte, nahm dann auch die Verbreitung des Automobils ihren Anfang.

Der konkurrierende Konstrukteur Gottlieb Daimler hatte zusammen mit seinem Freund Wilhelm Maybach die Glührohrzündung entwickelt, eine wesentliche Voraussetzung für die Weiterentwicklung des von Nicolaus Otto erfundenen Viertakt-Gasmotors zum Benzinmotor mit hohen Umdrehungszahlen. Auf die Glührohrzündung hatte Daimler 1883 ein Patent erhalten. 1896 verklagte er Benz’ Unternehmen erfolgreich wegen Verletzung seines Patents. Benz & Cie. musste daraufhin Lizenzgebühren an die Daimler-Motoren-Gesellschaft zahlen. Obwohl Daimler zum Gerichtstermin nach Mannheim reiste, lernten sich Benz und Daimler nicht persönlich kennen. Auch als die beiden 1897 anlässlich der Gründung des "Mitteleuropäischen Motorwagen-Vereins" noch einmal zusammentrafen, sprachen sie nicht miteinander. 1900 starb Gottlieb Daimler.

Im Jahr 1899 wurde die Benz & Cie. Rheinische Gasmotorenfabrik Mannheim in eine Aktiengesellschaft umgewandelt (Benz & Cie. AG). Um 1900 war sie die größte Automobilfabrik der Welt. Trotz des gewaltigen Erfolges zog sich Benz 1903 verärgert aus dem Unternehmen zurück.

1906 gründete Carl Benz mit seinen Söhnen in Ladenburg das Unternehmen Carl Benz Söhne, das sich auf den Fahrzeugbau spezialisierte und in dessen ehemaligen Räumlichkeiten heute das Automuseum Dr. Carl Benz zu finden ist.

Am 25. November 1914 verlieh die Technische Hochschule Karlsruhe Carl Benz den Ehrendoktortitel.

1926 kam es zur Vereinigung von "Benz & Cie. Rheinische Gasmotorenfabrik Mannheim" und der von Gottlieb Daimler gegründeten Daimler-Motoren-Gesellschaft zur Daimler-Benz AG.

Benz starb am 4. April 1929 im Alter von 84 Jahren in Ladenburg an den Folgen einer Entzündung der Bronchien und wurde dort bestattet.

Die Schreibweise des Vornamens sorgt für Verwirrung. Beispielsweise gibt es in Stuttgart-Untertürkheim einen "Karl-Benz-Platz", der ursprünglich "Carl-Benz-Platz" geschrieben wurde. Der Austausch der Straßenschilder im Jahr 1986 ging auf die Initiative von Daimler-Benz zurück. Der damals 60 Jahre alte Automobilkonzern bevorzugte selbst "Karl Benz" als die historisch besser begründete Schreibweise des Namens. Im Geburtsregister von Mühlburg stehen nämlich die Vornamen "Karl Friedrich Michael" verzeichnet. Auf dem Grabstein in Ladenburg steht "Karl Benz". Für den Gebrauch der Schreibweise "Karl" sprechen also gute Gründe.
Heute wird jedoch überwiegend die Schreibweise "Carl" verwendet. Dafür hat der Autopionier selbst gesorgt. Am Polytechnikum in Karlsruhe hatte er sich 1860 noch handschriftlich als "Karl Benz" eingetragen. Ende des 19. Jahrhunderts kam aber die französische Schreibweise deutscher Namen in Mode, "Karlsruhe" wurde "Carlsruhe" geschrieben. Seit etwa 1881/1882 hat Karl Benz zumeist als "Carl Benz" signiert. Während auf seiner ersten Patentschrift von 1880 noch "Karl Benz zu Mannheim" steht, wurde die nächste Patentschrift von 1882 auf "Carl Benz in Mannheim" ausgestellt. Das 1906 in Ladenburg gegründete Unternehmen firmierte als "C. Benz Söhne". 1925 erschien die Autobiografie mit dem Namen "Carl Friedrich Benz" im Titel.

Auch die Daimler AG verwendet seit Juli 2010 konzernweit nur noch die Schreibweise "Carl Benz". 2007 wurde an der Universität Karlsruhe, dem heutigen Karlsruher Institut für Technologie (KIT), für den englischsprachigen Bachelorstudiengang Maschinenbau der Name "Carl Benz School" eingeführt.

Das Stadion des Fußballclubs SV Waldhof Mannheim ist nach ihm Carl-Benz-Stadion benannt. Gleiches gilt für den Benz-Pass, einen Gebirgspass in der Antarktis.

Am 23. Mai 2011 strahlte Das Erste den biografischen Fernsehfilm "Carl & Bertha" aus.




</doc>
<doc id="10837" url="https://de.wikipedia.org/wiki?curid=10837" title="Sonnentau">
Sonnentau

Die Gattung Sonnentau ("Drosera") zählt zur Familie der Sonnentaugewächse (Droseraceae) und bildet mit ihren annähernd 200 Arten die zweitgrößte Gattung fleischfressender Pflanzen. Charakteristisch sind die mit Klebedrüsen besetzten Blätter der Pflanzen, die ihr den Fang von Beute und so das Gedeihen auch in nährstoffarmen Gebieten ermöglichen.

Die Gattung ist annähernd weltweit verbreitet, Hauptverbreitungsgebiete sind Australien, Südamerika und Südafrika. Zahlreiche der Arten sind durch den Menschen gefährdet. Einige wenige Arten allerdings werden als Zierpflanzen geschätzt.

Sonnentauarten sind selten ein-, meist aber mehrjährige krautige Pflanzen, rosettenbildend, aufrecht oder kletternd mit einer Wuchshöhe von einem bis einhundert Zentimetern, je nach Art; kletternde Sonnentau-Arten können jedoch eine wesentlich größere Länge erreichen, über 3 Meter sind berichtet worden ("Drosera erythrogyne"). Sie können nachweislich ein Alter von über 50 Jahren erreichen. Die Gattung ist so sehr auf die Aufnahme von Stickstoff durch Insektenfänge spezialisiert, dass ihr, zumindest bei den Zwergsonnentauarten, das Enzym Nitratreduktase vollständig fehlt, das Pflanzen normalerweise zur Aufnahme von bodengebundenem Nitrat benötigen. Vegetative Vermehrung findet durch oberirdische Ausläufer, Stolonen, oder – je nach Wuchsform – durch Knollenbildung oder Brutschuppen statt.

Die Gattung lässt sich in verschiedene Wuchsformen einteilen:


Obwohl nicht durch eine Wuchsform im strengen Sinne definiert, wird häufig noch eine weitere Gruppierung angeführt:


Das Wurzelsystem der meisten Sonnentau-Arten ist nur schwach ausgeprägt. Es dient hauptsächlich der Verankerung der Pflanze im Untergrund und zur Wasseraufnahme; für die Nährstoffversorgung sind die Wurzeln nahezu bedeutungslos. Einige südafrikanische Arten speichern in ihrer Wurzel Wasser und auch Nährstoffe. Bei manchen australischen Arten sind zu diesem Zwecke Knollen als Speicherorgane angelegt; sie dienen zur Überdauerung der Pflanze in extremer Trockenheit. Die Pfahlwurzeln von Zwergsonnentauarten sind oft extrem verlängert im Verhältnis zu ihrer Größe, eine ein Zentimeter große Pflanze kann eine Pfahlwurzel von bis zu 15 Zentimetern Länge ausbilden. Stämmchenbildende Zwergsonnentauarten bilden häufig im Alter Stützwurzeln aus, die von der Krone herab zum Boden wachsen.

Innerhalb der Gattung haben sich zahlreiche, teils sehr verschiedene Blattformen entwickelt, mit oder ohne Stiel. Die ungewöhnlichste Form hat dabei sicher die ein- bis mehrfach gegabelte "Drosera binata". Je nach Art ist das gesamte Fangblatt unterschiedlich stark beweglich und unterstützt so den Fangvorgang, so kann der Kap-Sonnentau ("Drosera capensis") sein Blatt um mehr als 360° biegen und seine Beute dadurch nahezu völlig einschließen.
"Siehe auch: Emergenzen bei Drosera"

Unabhängig von ihrer Form zeichnen sich alle Sonnentauarten durch ihre mit klebrigen Sekreten besetzten Tentakel auf den Blättern aus, die bei allen Arten der Gattung bewegt werden können. Diese sind gestielte Drüsen, die ein klebriges, zuckerhaltiges Sekret absondern, dessen Schimmern Insekten anzieht, die dann am Sekret kleben bleiben. Die Tentakeln in der unmittelbaren Umgebung um die Beute neigen sich daraufhin ebenfalls in Richtung des Fangs und verstärken so die Haftung und spätere Verdauung. Die gefangenen Tiere finden entweder durch Erschöpfung den Tod oder ersticken am zähen Sekret, das in ihre Tracheen einsickert und diese verstopft. Die Tentakel sondern derweil Enzyme wie Esterase, Peroxidase, Phosphatase und Protease ab, die nun die Beute langsam zersetzen und die darin enthaltenen Nährstoffe lösen. Die so gelösten Nährstoffe werden dann von den auf der Blattoberfläche sitzenden Drüsen aufgenommen und für den Wachstumsprozess verwendet. Letztere können bei einigen Arten aber auch fehlen, so zum Beispiel bei "Drosera erythrorhiza".

Der Begriff Schnelltentakel wurde Anfang des Jahrtausends von Jan Schlauer geprägt, weil diese aufwärts schnellen und dabei gleichzeitig sehr schnell sein können. Viele Droseraarten bilden zumindest als Sämlinge Schnelltentakel, deren Geschwindigkeit, Funktion und Morphologie sich jedoch in verschiedenen Sektionen unterscheidet. Sogar schneller als die Venus Fliegenfalle zuklappt biegen sich diese in den Katapult-Leimfallen von "D. glanduligera" in nur 75 ms um etwa 180° und schleudern dabei Beutetiere von der Peripherie der Rosette mit einer Beschleunigung von 7,98 m/s meist rücklings in die Leimtentakel der Falle. Allerdings ist der bei dieser Geschwindigkeit auftretende hydraulische Druck so hoch, dass die Gelenkzone in welcher die Bewegung stattfindet, dadurch bei dieser Art zerstört wird. Daher funktionieren solche Katapulte nur einmal. Eigentlich biegen sich die katapultierenden Tentakel in der Gelenkzone sogar um 360°, allerdings wird diese Bewegung durch das Auftreffen auf die Lamina vorzeitig gestoppt. Alle anderen bisher untersuchten Schnelltentakel funktionieren mehrmals, wobei die Katapult-Leimfallen der Zwergdrosera (Sektion "Bryastrum") im Bereich von Zehntelsekunden in etwa die Geschwindigkeit von "Dionaea" zeigen. Im Unterschied zu den übrigen Schnelltentakeln, die sich im Bereich weniger Sekunden bis hin zu mehreren Minuten einbiegen, dienen die schnellen Katapulte mit ihren sehr dünnen Stielen nicht der Fixierung der Beute. Schnelltentakel entspringen mit einer breiten Basis waagerecht am äußersten Punkt der Blattspreiten, sind deutlich verlängert und sondern weder Klebetropfen noch Enzyme ab. Die Bewegung findet immer in einer Gelenkzone statt, deren Funktion und Morphologie jedoch unterschiedlich ausfällt. Im Gegensatz zu den in alle Richtungen beweglichen, senkrecht auf der Lamina stehenden Leimtentakeln, können sich Schnelltentakel nur aufwärts oder abwärts bewegen, das jedoch aufgrund der breiten Basis recht kraftvoll und schnell. Unter Berücksichtigung der Katapult-Leimfallen, verfügen nun alle Gattungen der Sonnentaufamilie (Droseraceae) über Fangmechanismen im Millisekundenbereich (<= 100 ms).

Einige Arten ("Drosera hartmeyerorum", "Drosera indica") haben neben den Fangtentakeln auch modifizierte Tentakeln entwickelt mit teils noch ungeklärter Funktion. Diese scheiden weder Fangsekrete noch Enzyme aus und unterscheiden sich in Größe und Struktur deutlich von Fangtentakeln. Im Falle von "Drosera hartmeyerorum" dienen sie möglicherweise der Anlockung durch ihre auffällige Färbung.

Die auf den Fangblättern über die ganze Blattfläche verteilten Emergenzen von "Drosera indica" sind zwischen 0,1 und 1,0 mm klein, pilzförmig und besitzen bei australischen Varietäten einen halbkugelförmigen gelben Kopf, während afrikanische Varietäten einen transluziden, gewellt tellerförmigen Kopf aufweisen. Diese sind so klein, dass sie mit bloßem Auge kaum wahrnehmbar sind, eine optische Attraktivität für Insekten gilt daher als eher unwahrscheinlich.

Bei "Drosera hartmeyerorum" befinden sich die gut sichtbaren, 3–4 mm großen, leuchtend gelben Emergenzen konzentriert an der Blattbasis der immer dunkelroten Fangblätter sowie über den dunkelroten sichelförmigen Brakteen des Blütenstandes, wo sie eine regelrechte Lichterkette bilden. Sie zeigen eine komplexe Struktur: Auf einem transparenten Tentakelstiel sitzt als Kopf eine aus wabenförmigen, transparenten Riesenzellen gebildete, linsenartige Struktur, die einfallendes Licht auf ein kompaktes, leuchtend gelbes Zentrum fokussiert. Fällt nun Licht auf die Emergenzenköpfe, leuchten diese hellgelb auf. Besonders durch die auf den roten Brakteen des Blütenstandes sitzenden „Linsententakel“ entsteht durch Lichteinfall eine regelrechte gelbe Lichterkette. Da Insekten eine andere Farbwahrnehmung haben, ist das Dunkelrot der Pflanze für sie ein fast schwarzer Hintergrund, vor dem die Emergenzen kontrastreich leuchten.

Die Blüten des Sonnentaus stehen, wie bei fast allen Karnivoren üblich, an sehr langen Blütenständen über der Pflanze, damit mögliche Bestäuberinsekten nicht durch die Blätter gefangen werden. Die meist ungegabelten Blütenstände sind in der Regel Wickel, deren Blüten sich einzeln öffnen und meist nur kurz blühen. Entscheidend für die Öffnung der Blüte ist vor allem die Intensität der Sonne; die Blütenstände sind außerdem „heliotrop“, wenden sich also zur Sonne hin.

Die radiären, zwittrigen Blüten sind immer einfach und fünfzählig; nur zwei Arten fallen diesbezüglich aus dem Rahmen, nämlich die vierzählige "Drosera pygmaea" und die acht- bis zwölfzählige "Drosera heterophylla".

Die Blüten der meisten Arten sind ausgesprochen klein (unter 1,5 cm), einige wenige ("Drosera regia" und "Drosera cistiflora") haben jedoch Blüten mit einer Größe von bis zu vier Zentimetern Durchmesser. In der Regel sind Sonnentaublüten weiß oder rosa. Eine etwas größere Farbvielfalt herrscht bei den australischen und afrikanischen Arten; dort kommen vereinzelt auch orange ("Drosera callistos"), rote ("Drosera cistiflora"), gelbe ("Drosera zigzagia") oder gar violett-metallicfarbene ("Drosera microphylla") vor.

Die Fruchtknoten sind oberständig. Es werden Kapselfrüchte mit sehr vielen kleinen Samen gebildet. Viele Sonnentauarten sind selbstbefruchtend; häufig werden große Mengen an Samen produziert. Die Samen sind schwarz, staubfein und lichtkeimend, verlieren aber schnell an Keimfähigkeit. Fast alle Arten sind Windstreuer, bei einigen wenigen Arten ("Drosera felix", "Drosera kaieteurensis") gibt es eine spezielle Verbreitungsform, bei denen die Samen durch den „Aufschlag“ eines Regentropfens aus der Samenkapsel herausgeschleudert werden (Regentropfen- oder "Splash-Cup-"verbreitung). Arten temperierter Zonen sind Frostkeimer.

Die Areale der Gattung erstrecken sich insgesamt von Kanada im Norden bis Neuseeland im Süden. Die Hauptverbreitungsgebiete sind mit annähernd 50 Prozent aller Arten Australien, Südamerika mit zwanzig bis dreißig Arten sowie das südliche Afrika. Einige wenige Arten kommen großflächig in Eurasien und Nordamerika vor; diese Areale sind aber eher als Randgebiet der Gattung anzusehen, ebenso wie die äußersten arktischen Vorkommen. Möglicherweise ist die evolutionäre Trennung der Gattung auf das Auseinanderdriften der ehemals als Superkontinent Gondwana zusammengehörenden Kontinente zurückzuführen, aber auch eine nachfolgende Zerstreuung über weite Entfernung hin wird diskutiert. Dabei wird als Ursprung der Gattung Australien oder Afrika angenommen.

In Europa existieren (neben dem Naturhybriden "Drosera × obovata") nur drei Arten: der Rundblättrige Sonnentau ("D. rotundifolia"), der Langblättrige Sonnentau ("D. anglica") und der Mittlere Sonnentau ("D. intermedia").

Häufig wird die Gattung als kosmopolitisch bezeichnet, also als weltweit vorkommend. Der Botaniker Ludwig Diels, Autor der bisher einzigen Monographie über die Familie, bezeichnete dies jedoch als „arge Verkennung ihrer höchst eigentümlichen Verbreitungsverhältnisse“, obwohl die Sonnentau-Arten „einen beträchtlichen Teil der Erdoberfläche besetzt“ hielten. Insbesondere wies er auf ihr Fehlen in nahezu allen ariden Zonen, zahlreichen Regenwaldgebieten, an der amerikanischen Pazifikküste, in Polynesien, dem Mittelmeerraum und Nordafrika hin sowie auf die sehr geringe Artenvielfalt in temperierten Zonen, zum Beispiel Europa und Nordamerika.

Sonnentauarten wachsen in der Regel in saisonal feuchten, seltener dauernassen Gebieten mit nährstoffarmen, sauren Böden und viel Sonne, z. B. in Mooren, Heiden, Sümpfen, im Wallum, Fynbos, auf Inselbergen, aber auch in Marschland und an den Ufern von Fließgewässern. Viele Formen wachsen gemeinsam mit Torfmoosen, die dem Untergrund Nährstoffe entziehen und ihn zugleich versauern, wodurch sie das Wachstum möglicher Konkurrenten behindern.

Allerdings ist die Gattung in ihren Habitatansprüchen sehr variabel; in einzelnen Fällen schaffen Arten es sogar, in sehr untypischen Gebieten wie Regenwäldern, Wüsten (z. B. "Drosera burmannii" und "Drosera indica") oder auch in Biotopen mit starker Beschattung zu siedeln (Queenslanddrosera). Auch die temperierten Arten, die über den Winter Hibernakel ausbilden, stellen eine solche Form der Anpassung an abweichende Habitate dar, da die Arten der Gattung üblicherweise eher warme Klimata bevorzugen und nur bedingt frosthart sind.

Alle heimischen "Drosera"-Arten stehen in Deutschland, Österreich und der Schweiz unter Naturschutz. Auch in anderen europäischen Ländern wie Finnland, Ungarn, Frankreich oder Bulgarien sind "Drosera"-Arten gesetzlich geschützt. In Mitteleuropa stellte über lange Zeit die Nutzung der Lebensräume durch Trockenlegung und Torfabbau die Hauptgefährdung dar. Dadurch sind in zahlreichen Regionen die Bestände dieser empfindlichen Pflanzen inzwischen verschollen bzw. ausgestorben. Die Erfahrungen haben gezeigt, dass einmal verlorene Standorte nicht mehr durch Wiederansiedelung zurückgewonnen werden können, da der ökologische Spielraum hinsichtlich der Standortfaktoren sehr eng begrenzt ist. Durch den verstärkten gesetzlichen Schutz der Moore und Anmoore sowie die Bemühungen um deren Renaturierung konnte der Rückgang des Sonnentaus zwar gebremst werden, dennoch sind die meisten Sonnentau-Arten weiterhin stark gefährdet. Das relativ unscheinbare Erscheinungsbild sowie der kleine, niedrige Wuchs dieser Pflanzen erschwert generell die Schutzbemühungen vor Ort. Oft werden Sonnentaugewächse im Gelände übersehen oder gar nicht erkannt.

In zwei der drei Hauptverbreitungsgebiete, in Südafrika und Australien, unterliegen die dortigen Lebensräume der Sonnentaue starkem Nutzungsdruck durch den Menschen. Insbesondere expandierende Siedlungsgebiete (Queensland, Perth, Kapstadt) sowie die Trockenlegung von Feuchtgebieten für die Land- und Forstwirtschaft gefährden die häufig nur in isolierten Gebieten existierenden Bestände. Auch durch die Dürren, die sich in Teilen Australiens bereits mehr als zehn Jahre hinziehen und vermutlich eine Folge der globalen Erwärmung sind, fallen zunehmend Standorte trocken, dies stellt ebenfalls mittelbar eine Bedrohung der dortigen Arten dar.

Gerade die nur in äußerst eng umgrenzten Standorten zu findenden Arten unterliegen durch die Absammlung von Wildpflanzen der größten Gefahr von Totalverlusten. Aufgrund massiven Raubbaus für den Export in Madagaskar gilt "Drosera madagascariensis" als stark gefährdet, jährlich werden dort 10–200 Millionen Pflanzen für Vermarktungszwecke abgesammelt.

Das folgende Kladogramm stellt die Beziehungen zwischen den verschiedenen Sektionen bzw. Untergattungen anhand der Analysen von Rivadavia u. a. 2003 dar. Die monotypische Sektion "Meristocaulis" wurde nicht in die Untersuchungen mit einbezogen, so dass ihre Stellung in diesem System unklar ist, neuere Untersuchungen stellen sie aber in die Nähe der Sektion "Bryastrum" bzw. gliedern sie dort ein. Da die Sektion Drosera polyphyletisch ist, taucht sie mehrfach innerhalb des Kladogramms auf ( * ).

Diese phylogenetische Untersuchung hat die Notwendigkeit einer Revision der Gattung noch deutlicher werden lassen.

Die Gattung "Drosera" wird nach Seine & Barthlott, 1994, ergänzt um Revisionen und Neubeschreibungen in drei Untergattungen und elf Sektionen aufgeteilt, Grundlage für diese sind morphologische Merkmale.

Seit Jahrzehnten werden immer neue Arten entdeckt und beschrieben, noch in den 1940ern waren erst etwas über 80 Arten bekannt, 2009 bereits fast 200. Zahlreiche australische Arten wurden vor allem durch den Australier Allen Lowrie erstbeschrieben. Seine diesbezügliche Taxonomie wurde zwar 1996 durch den deutschen Botaniker Jan Schlauer in Frage gestellt, diese hat sich aber nicht durchgesetzt.

Im Sonnentau sind verschiedene medizinisch wirksame Inhaltsstoffe enthalten, nämlich Naphthochinonderivate (Plumbagin, Droseron, Ramentaceon) und Flavonglykoside (Quercetin, Myricetin, Kampferöl).

Sonnentau wurde gegen Reizhusten, zur Herzstärkung und als Aphrodisiakum, aber auch zur Behandlung von Sonnenbrand und gegen Sommersprossen verwendet. Als Hustenmedizin wurde er Anfang der 1990er Jahre noch in 200-300 zugelassenen Präparaten der Medizin eingesetzt, zumeist in Kombination mit weiteren Wirkstoffen. Unter den Präparaten sind heutzutage auch einige aus der Homöopathie vertreten, wobei Sonnentau und andere Wirkstoffe als Urtinktur verwendet werden.

Auf Wildsammlungen in Deutschland wird allerdings mittlerweile verzichtet; stattdessen werden entweder Gebiete in Madagaskar, Spanien, Frankreich, Polen und dem Baltikum abgeerntet oder es wird Sonnentau aus deutschen Zuchten verwendet, dort vor allem die schnellwüchsigen Arten "Drosera madagascariensis", "Drosera ramentacea", aber auch der Rundblättrige und der Mittlere Sonnentau.

Die, durch den Sonnentau gebildeten klebrigen Sekrete (adhäsive Stoffe) finden bereits in der Biomedizin Anwendung. Sie sind ein natürliches Hydrogel und damit biokompatibel sowie gewebeähnlich. Da sich mit dem Sekret Zellen aneinanderkleben lassen, eignet es sich optimal für die Züchtung von Gewebe.

Durch ihre Karnivorie und die als anmutig empfundenen Fangblätter sind Sonnentauarten beliebte Zierpflanzen. Die meisten Arten haben allerdings aufgrund meist schwieriger Haltungsbedingungen oder der komplizierten Vermehrung nur geringe Marktchancen. Wenige, robuste Arten sind jedoch neben der Venusfliegenfalle als geläufige Karnivoren für den Massenmarkt mittlerweile in vielen Gartencentern oder Baumärkten erhältlich, insbesondere der Kap-Sonnentau und "Drosera aliciae".

Auch die anderen Sonnentauarten werden von einem mehrere Tausende starken, weltweiten Kreis von Sammlern kultiviert; es befinden sich derzeit so gut wie alle Arten in Kultur. Da viele Sonnentau-Arten sehr eng begrenzte Verbreitungsgebiete haben und auch in diesen selten sind, hat dies durch starke Absammlungen zu Rückgang und Gefährdung einiger Arten beigetragen.

Bei den australischen Aborigines stellen die Knollen der dort heimischen Knollendrosera ein beliebtes Nahrungsmittel dar.

Der botanische Name entstammt dem griechischen δρόσος, "drosos" für „Tau“. Der deutsche Name ist eine Übersetzung des älteren botanischen Namens "„Ros solis“". All diese Namen leiten sich vom glänzenden Aussehen der zahlreichen Drüsensekrettropfen an der Spitze der Tentakel ab, die an morgendliche Tautropfen erinnern.

1539 beschrieb Hieronymus Bock einheimische Sonnentau-Arten: 

Nach Bock wurden die Sonnentau-Arten, wie auch das Goldene Frauenhaarmoos im 16. Jh. hauptsächlich im Sympathiezauber der Volksmedizin verwendet. Aus der Sicht der gelehrten Medizin ordnete er sie dem von Dioskurides beschriebenen „adianton“ zu. Danach hatten sie folgende Wirkungen: Harn und Harnwegssteine treiben, den Haarwuchs befördern, Heilung von Erkrankungen der Brust, der Leber, der Milz und der Haut.

Die Alchemisten verwendeten zur Darstellung der Materia prima u. a. Sonnentau-Arten, das Goldene Frauenhaarmoos und Schöllkraut. Auswahlkriterium war die gold-gelbe Farbe dieser Pflanzen. Wie den Maientau betrachteten die Alchemisten auch die Drüsensekretstropfen der Sonnentaupflanze („ros solis“) als „mit astralem Samen geschwängertes Wasser“.




</doc>
<doc id="10839" url="https://de.wikipedia.org/wiki?curid=10839" title="Daniel Bernoulli">
Daniel Bernoulli

Daniel Bernoulli (* in Groningen; † 17. März 1782 in Basel) war ein Schweizer Mathematiker und Physiker aus der Gelehrtenfamilie Bernoulli. Er war ein Schüler des deutschen Universalgelehrten Gottfried Wilhelm Leibniz (1646–1716) und arbeitete mit Leonhard Euler an den Gleichungen, die ihre Namen tragen. Die nach ihm benannte Bernoulli-Gleichung ist von überragender Bedeutung in der Hydraulik und Aerodynamik.

Bernoulli war der Sohn des Mathematikers Johann Bernoulli und dessen Ehefrau Dorothea Falkner. Der Mathematiker Nikolaus II. Bernoulli war sein Bruder, der Mathematiker Jakob I. Bernoulli (1655–1705) sein Onkel. Mit fünf Jahren kam Bernoulli zusammen mit seiner Familie nach Basel.

Ab seinem 16. Lebensjahr studierte Bernoulli in Basel Medizin und wechselte 1718 nach Heidelberg. Nach einem Aufenthalt 1719 in Straßburg kehrte Bernoulli nach Basel zurück. Dort promovierte er im darauffolgenden Jahr zum Dr. med. Da von keiner Universität ein Ruf an ihn erging, unternahm Bernoulli 1723 eine Studienreise nach Venedig, um sich dort beim Stadtphysikus Pietro Antonio Michelotti weiterzubilden. Während seiner dortigen Assistenz machte Bernoulli Bekanntschaft mit dem Kartenspiel Pharo.

Mit einem Büchlein über dieses Kartenspiel debütierte er als Mathematiker; mit Arbeiten über die Riccati-Gleichung wurde er europaweit bekannt. 1725 wurde Bernoulli zusammen mit seinem Bruder an die Russische Akademie der Wissenschaften nach Sankt Petersburg berufen. In einem Brief an Christian Goldbach vom 6. Oktober 1729 gab Bernoulli als erster eine mögliche Darstellung der Gammafunktion an. Stadt, Land und Arbeitsplatz gefielen Bernoulli überhaupt nicht, und so nahm er 1733 eine Erkrankung zum Anlass für seine Heimreise. Er kehrte nach Basel zurück und lehrte an der Universität bis an sein Lebensende. 1733 übernahm er den Lehrstuhl für Anatomie und Botanik und wechselte zehn Jahre später auf einen Lehrstuhl für Anatomie und Physiologie. Aber 1750 erfüllte sich dann Bernoullis Traum, als man ihn mit dem Lehrstuhl für Physik betraute. Zweimal (1744 und 1756) amtierte er als Rektor der Universität. Seit 1746 war er auswärtiges Mitglied der Preußischen Akademie der Wissenschaften.

Offenbar hatte er eine schlechte Beziehung zu seinem Vater. Als beide an einem wissenschaftlichen Wettbewerb der Akademie der Wissenschaften in Paris teilnahmen und sich den ersten Platz teilten, wurde Daniel von seinem Vater verstoßen, da dieser angeblich nicht die Schande ertragen konnte, mit seinem Sohn verglichen zu werden. Insgesamt gewann Bernoulli zehnmal diesen Preis.

1738 veröffentlichte er sein Hauptwerk "Hydrodynamica". Die darin enthaltenen Forschungsergebnisse veröffentlichte sein Vater Johann unter dem Titel "Hydraulica" als Plagiat, indem er dieses um sieben Jahre vordatierte. Trotz Daniels Versöhnungsversuchen blieb es beim Bruch zwischen ihm und seinem Vater.

Bernoulli war ein Zeitgenosse und enger Freund Leonhard Eulers.

Sein frühestes mathematisches Werk war das 1724 veröffentlichte "Exercitationes", das eine Lösung der von Jacopo Riccati vorgeschlagenen Riccati-Gleichung enthielt. Zwei Jahre später wies er das erste Mal auf die oftmals gewünschte Zerlegung einer zusammengesetzten Bewegung in Translations- und Rotations-Bewegungen hin. Der Aufbau ähnelt Lagranges "Méchanique Analytique", da alle Ergebnisse als Konsequenz eines einzigen Prinzips erscheinen, in diesem Fall der Energieerhaltung.

Ihm folgte die Denkschrift "Traité sur le flux et le reflux de la mer" über die Theorie der Gezeiten, für die er 1740 – neben Euler, Antoine Cavalleri und Colin Maclaurin – einen Preis der Französischen Akademie erhielt. Die Schriften von Maclaurin, Euler und Bernoulli enthalten alles, was zu diesem Thema zwischen der Veröffentlichung von Isaac Newtons "Principia" und den Forschungen von Laplace erarbeitet wurde. Der Aufsatz von Antoine Cavallieri behandelt die auf Ätherwirbeln basierende Theorie von René Descartes.

Bernoulli schrieb auch eine große Zahl von Artikeln über verschiedene mechanische Fragen, insbesondere über Probleme im Zusammenhang mit schwingenden Saiten und die von Brook Taylor und d’Alembert gegebenen Lösungen. Er ist der erste, der eine kinetische Theorie der Gase zu formulieren versuchte, und wandte sie an, um das Boyle-Mariotte-Gesetz zu erklären, das mit den Namen von Robert Boyle und Edme Mariotte verbunden ist.

Des Weiteren präsentierte Bernoulli 1738 auch das Sankt-Petersburg-Paradoxon.

In Basel wurde 1875 zu Ehren von Daniel Bernoulli beim Eingang des Bernoullianums eine Büste aufgestellt.




</doc>
