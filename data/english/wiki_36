<doc id="5046" url="https://en.wikipedia.org/wiki?curid=5046" title="Belfast">
Belfast

Belfast (; is the capital city of Northern Ireland, located on the banks of the River Lagan on the east coast of Ireland. It is the largest city of state of Northern Ireland and second largest city on the island. It had a population of 333,871 in 2015.

By the early 1800s the former town was home to a major port. Belfast played a key role in the Industrial Revolution in the 19th century, becoming the biggest linen producer in the world, earning it the nickname "Linenopolis". By the time it was granted city status in 1888, it was a major centre of the Irish linen as well as tobacco-processing, rope-making and shipbuilding industries. Harland and Wolff, which built the , was the world's biggest and most productive shipyard. It later also sustained a major aerospace and missiles industry. Industrialisation and the inward migration it brought made Belfast Ireland's biggest city at the time. It became the capital of Northern Ireland following the Partition of Ireland in 1922. Its status as a global industrial centre ended in the decades after the Second World War.

The city suffered greatly during the Troubles, and was once considered in the 1970s and 1980s as one of the world's most dangerous cities. But since the 21st century the city has undergone a sustained period of calm, free from the intense political violence of former years, and substantial economic and commercial growth. Today, Belfast remains a centre for industry, as well as the arts, higher education, business, and law, and is the economic engine of Northern Ireland. Belfast is still a major port, with commercial and industrial docks dominating the Belfast Lough shoreline, including the Harland and Wolff shipyard. It is served by two airports: George Best Belfast City Airport in the city, and Belfast International Airport west of the city. It is listed by the Globalization and World Cities Research Network (GaWC) as a global city.

The name Belfast is derived from the Irish ', which was later spelt '. The word ' means "mouth" or "rivermouth" while ' is the genitive singular of ' and refers to a sandbar or tidal ford across a river's mouth. The name would thus translate literally as "(river) mouth of the sandbar" or "(river) mouth of the ford". This sandbar was formed at the confluence of two rivers at what is now Donegall Quay: the Lagan, which flows into Belfast Lough, and its tributary the Farset. This area was the hub around which the original settlement developed. The Irish name ' is shared by a townland in County Mayo, whose name has been anglicised as "Belfarsad".

An alternative interpretation of the name is "mouth of [the river] of the sandbar", an allusion to the River Farset, which flows into the Lagan where the sandbar was located. This interpretation was favoured by Edmund Hogan and John O'Donovan. It seems clear, however, that the river itself was named after the tidal crossing.

In Ulster-Scots, the name of the city has been variously translated as "Bilfawst", "Bilfaust" or "Baelfawst", although "Belfast" is also used.

Although the county borough of Belfast was created when it was granted city status by Queen Victoria in 1888, the city continues to be viewed as straddling County Antrim and County Down.

The site of Belfast has been occupied since the Bronze Age. The Giant's Ring, a 5,000-year-old henge, is located near the city, and the remains of Iron Age hill forts can still be seen in the surrounding hills. Belfast remained a small settlement of little importance during the Middle Ages. John de Courcy built a castle on what is now Castle Street in the city centre in the 12th century, but this was on a lesser scale and not as strategically important as Carrickfergus Castle to the north, which was built by de Courcy in 1177. The O'Neill clan had a presence in the area.

In the 14th century, Cloinne Aodha Buidhe, descendants of Aodh Buidhe O'Neill built Grey Castle at Castlereagh, now in the east of the city. Conn O'Neill of the Clannaboy O'Neills owned vast lands in the area and was the last inhabitant of Grey Castle, one remaining link being the Conn's Water river flowing through east Belfast.

Belfast became a substantial settlement in the 17th century after being established as a town by Sir Arthur Chichester. It was initially settled by Protestant English and Scottish migrants at the time of the Plantation of Ulster. (Belfast and County Antrim, however, did not form part of this particular Plantation scheme as they were privately colonised.) In 1791, the Society of United Irishmen was founded in Belfast, after Henry Joy McCracken and other prominent Presbyterians from the city invited Theobald Wolfe Tone and Thomas Russell to a meeting, after having read Tone's "Argument on Behalf of the Catholics of Ireland". Evidence of this period of Belfast's growth can still be seen in the oldest areas of the city, known as the Entries.
Belfast blossomed as a commercial and industrial centre in the 18th and 19th centuries and became Ireland's pre-eminent industrial city. Industries thrived, including linen, rope-making, tobacco, heavy engineering and shipbuilding, and at the end of the 19th century, Belfast briefly overtook Dublin as the largest city in Ireland. The Harland and Wolff shipyards became one of the largest shipbuilders in the world, employing up to 35,000 workers. In 1886 the city suffered intense riots over the issue of home rule, which had divided the city.

In 1920–22, Belfast became the capital of the new entity of Northern Ireland as the island of Ireland was partitioned. The accompanying conflict (the Irish War of Independence) cost up to 500 lives in Belfast, the bloodiest sectarian strife in the city until the Troubles of the late 1960s onwards.
Belfast was heavily bombed during World War II. In one raid, in 1941, German bombers killed around one thousand people and left tens of thousands homeless. Apart from London, this was the greatest loss of life in a night raid during the Blitz.

Belfast has been the capital of Northern Ireland since its establishment in 1921 following the Government of Ireland Act 1920. It had been the scene of various episodes of sectarian conflict between its Catholic and Protestant populations. These opposing groups in this conflict are now often termed republican and loyalist respectively, although they are also loosely referred to as 'nationalist' and 'unionist'. The most recent example of this conflict was known as the Troubles – a civil conflict that raged from around 1969 to 1998.
Belfast saw some of the worst of the Troubles in Northern Ireland, particularly in the 1970s, with rival paramilitary groups formed on both sides. Bombing, assassination and street violence formed a backdrop to life throughout the Troubles. The Provisional IRA detonated 22 bombs within the confines of Belfast city centre in 1972, on what is known as "Bloody Friday", killing eleven people. Loyalist paramilitaries including the Ulster Volunteer Force (UVF) and the Ulster Defence Association (UDA) claimed that the killings they carried out were in retaliation for the IRA campaign. Most of their victims were Catholics with no links to the Provisional IRA. A particularly notorious group, based on the Shankill Road in the mid-1970s, became known as the Shankill Butchers.

In all, over 1,600 people were killed in political violence in the city between 1969 and 2001.
Belfast city centre has undergone considerable expansion and regeneration in recent years, notably around Victoria Square.

Belfast was granted borough status by James VI and I in 1613 and official city status by Queen Victoria in 1888. Since 1973 it has been a local government district under local administration by Belfast City Council. Belfast is represented in both the British House of Commons and in the Northern Ireland Assembly. For elections to the European Parliament, Belfast is within the Northern Ireland constituency.

Belfast City Council is the local council with responsibility for the city. The city's elected officials are the Lord Mayor of Belfast, Deputy Lord Mayor and High Sheriff who are elected from among 60 councillors. The first Lord Mayor of Belfast was Daniel Dixon, who was elected in 1892. The Lord Mayor for 2016–17 is Alderman Brian Kingston of the Democratic Unionist Party, while the Deputy Lord Mayor is Mary Ellen Campbell of Sinn Féin, both of whom were elected in June 2016 to serve a one-year term. The Lord Mayor's duties include presiding over meetings of the council, receiving distinguished visitors to the city, and representing and promoting the city on the national and international stage.

In 1997, Unionists lost overall control of Belfast City Council for the first time in its history, with the Alliance Party of Northern Ireland gaining the balance of power between Nationalists and Unionists. This position was confirmed in the three subsequent council elections, with mayors from Sinn Féin and the Social Democratic and Labour Party (SDLP), both of whom are Nationalist parties, and the cross-community Alliance Party regularly elected since. The first nationalist Lord Mayor of Belfast was Alban Maginness of the SDLP, in 1997.

The last elections to Belfast City Council were held on 22 May 2014, with the city's voters electing sixty councillors across ten district electoral areas. The results were: 19(+3) Sinn Féin, 13(−2) Democratic Unionist Party (DUP), 8(+2) Alliance Party, 7(−1) SDLP, 7(+4) Ulster Unionist Party (UUP), 3(+1) Progressive Unionist Party (PUP), with the Traditional Unionist Voice. Greens and People Before Profit Alliance all winning their first seats.

Belfast council takes part in the twinning scheme, and is twinned with Nashville, in the United States, Hefei in China, and Boston, in the United States.

As Northern Ireland's capital city, Belfast is host to the Northern Ireland Assembly at Stormont, the site of the devolved legislature for Northern Ireland. Belfast is divided into four Northern Ireland Assembly and UK parliamentary constituencies: Belfast North, Belfast West, Belfast South and Belfast East. All four extend beyond the city boundaries to include parts of Castlereagh, Lisburn and Newtownabbey districts. In the Northern Ireland Assembly Elections in 2017, Belfast elected 20 Members of the Legislative Assembly (MLAs), 5 from each constituency. Belfast elected 7 Sinn Féin, 5 DUP, 2 SDLP, 3 Alliance Party, 1 UUP, 1 Green and 1 PBPA MLAs. In the 2017 UK general election, Belfast elected one MP from each constituency to the House of Commons at Westminster, London. This comprised 3 DUP and 1 Sinn Féin.
The city of Belfast has the Latin motto "." This is taken from Psalms 116 Verse 12 in the Latin Vulgate Bible and is literally "For so much what shall we repay " The verse has been translated in bibles differently – for example as "What shall I render unto the Lord for all his benefits toward me?". It is also translated as "In return for so much, what shall we give back?" The Queen's University Students' Union Rag Week publication "PTQ" derives its name from the first three words of the motto.

The coat of arms of the city were designed by John Vinycomb and are blazoned as "Party per fesse argent and azure, in chief a pile vair and on a canton gules a bell argent, in base a ship with sails set argent on waves of the sea proper". This heraldic language describes a shield that is divided in two horizontally ("party per fesse"). The top ("chief") of the shield is silver ("argent"), and has a point-down triangle ("a pile") with a repeating blue-and-white pattern that represents fur ("vair"). There is also a red square in the top corner ("a canton gules") on which there is a silver bell. It is likely that the bell is an example here of "canting" (or punning) heraldry, representing the first syllable of Belfast. In the lower part of the shield ("in base") there is a silver sailing ship shown sailing on waves coloured in the actual colours of the sea ("proper"). The supporter on the "dexter" side (the right hand side, to note that in heraldry "right and "left" are from the wearer of the shield's perspective) is a chained wolf, while on the "sinister" (the left side from the bearer's perspective) is a sea-horse. The crest above the shield is also a sea-horse. These arms date back to 1613, when James VI and I granted Belfast town status. The seal was used by Belfast merchants throughout the 17th century on their signs and trade-coins. A large stained glass window in the City Hall displays the arms, where an explanation suggests that the seahorse and the ship refer to Belfast's significant maritime history. The wolf may be a tribute to the city's founder, Sir Arthur Chichester, and refer to his own coat of arms.

Belfast is at the western end of Belfast Lough and at the mouth of the River Lagan giving it the ideal location for the shipbuilding industry that once made it famous. When the "Titanic" was built in Belfast in 1911–1912, Harland and Wolff had the largest shipyard in the world.
Belfast is situated on Northern Ireland's eastern coast at . A consequence of this northern latitude is that it both endures short winter days and enjoys long summer evenings. During the winter solstice, the shortest day of the year, local sunset is before 16:00 while sunrise is around 08:45. This is balanced by the summer solstice in June, when the sun sets after 22:00 and rises before 05:00.
In 1994, a weir was built across the river by the Laganside Corporation to raise the average water level so that it would cover the unseemly mud flats which gave Belfast its name (). The area of Belfast Local Government District is .

The River Farset is also named after this silt deposit (from the Irish "feirste" meaning "sand spit"). Originally a more significant river than it is today, the Farset formed a dock on High Street until the mid 19th century. Bank Street in the city centre referred to the river bank and Bridge Street was named for the site of an early Farset bridge. Superseded by the River Lagan as the more important river in the city, the Farset now languishes in obscurity, under High Street. There are no less than eleven other minor rivers in and around Belfast, namely the Blackstaff, the Colin, the Connswater, the Cregagh, the Derriaghy, the Forth, the Knock, the Legoniel, the Milewater, the Purdysburn and the Ravernet.
The city is flanked on the north and northwest by a series of hills, including Divis Mountain, Black Mountain and Cavehill, thought to be the inspiration for Jonathan Swift's "Gulliver's Travels". When Swift was living at Lilliput Cottage near the bottom of Belfast's Limestone Road, he imagined that the Cavehill resembled the shape of a sleeping giant safeguarding the city. The shape of the giant's nose, known locally as "Napoleon's Nose", is officially called McArt's Fort probably named after Art O'Neill, a 17th-century chieftain who controlled the area at that time. The Castlereagh Hills overlook the city on the southeast.

As with the rest of Ireland, Belfast has a temperate or oceanic climate, with a narrow range of temperatures and rainfall throughout the year. The climate of Belfast is significantly milder than some other locations in the world at a similar latitude, due to the warming influence of the Gulf Stream. There are currently 5 weather observing stations in the Belfast area: Helens Bay, Stormont, Newforge, Castlereagh, and Ravenhill Road. Slightly further afield is Aldergrove Airport. The highest temperature recorded at any official weather station in the Belfast area was at Shaws Bridge on 12 July 1983. Belfast holds the record for Northern Ireland's warmest night time minimum, at Whitehouse on 14 August 2001.

The city gets significant precipitation (greater than 1mm) on 157 days in an average year with an average annual rainfall of , less than areas of northern England or most of Scotland, but higher than Dublin or the south-east coast of Ireland. As an urban and coastal area, Belfast typically gets snow on fewer than 10 days per year. The absolute maximum temperature at the weather station at Stormont is , set during July 1983. In an average year the warmest day will rise to a temperature of with a day of or above occurring roughly once every two in three years. The absolute minimum temperature at Stormont is , during January 1982, although in an average year the coldest night will fall no lower than with air frost being recorded on just 26 nights. The lowest temperature to occur in recent years was on 22 December 2010.

The nearest weather station for which sunshine data and longer term observations are available is Belfast International Airport (Aldergrove). Temperature extremes here have slightly more variability due to the more inland location. The average warmest day at Aldergrove for example will reach a temperature of , ( higher than Stormont) and 2.1 days should attain a temperature of or above in total. Conversely the coldest night of the year averages (or lower than Stormont) and 39 nights should register an air frost. Some 13 more frosty nights than Stormont. The minimum temperature at Aldergrove was , during December 2010.

Belfast expanded very rapidly from being a market town to becoming an industrial city during the course of the 19th century. Because of this, it is less an agglomeration of villages and towns which have expanded into each other, than other comparable cities, such as Manchester or Birmingham. The city expanded to the natural barrier of the hills that surround it, overwhelming other settlements. Consequently, the arterial roads along which this expansion took place (such as the Falls Road or the Newtownards Road) are more significant in defining the districts of the city than nucleated settlements. Belfast remains segregated by walls, commonly known as "peace lines", erected by the British Army after August 1969, and which still divide 14 districts in the inner city. In 2008 a process was proposed for the removal of the 'peace walls'. In June 2007, a £16 million programme was announced which will transform and redevelop streets and public spaces in the city centre. Major arterial roads (quality bus corridor) into the city include the Antrim Road, Shore Road, Holywood Road, Newtownards Road, Castlereagh Road, Cregagh Road, Ormeau Road, Malone Road, Lisburn Road, Falls Road, Springfield Road, Shankill Road, and Crumlin Road, Four Winds.
Belfast city centre is divided into two postcode districts, "BT1" for the area lying north of the City Hall, and "BT2" for the area to its south. The industrial estate and docklands "BT3". The rest of the Belfast post town is divided in a broadly clockwise system from "BT3" in the north-east round to "BT15", with "BT16" and "BT17" further out to the east and west respectively. Although "BT" derives from "Belfast", the BT postcode area extends across the whole of Northern Ireland.

Since 2001, boosted by increasing numbers of tourists, the city council has developed a number of cultural quarters. The Cathedral Quarter takes its name from St Anne's Cathedral (Church of Ireland) and has taken on the mantle of the city's key cultural locality. It hosts a yearly visual and performing arts festival.

Custom House Square is one of the city's main outdoor venues for free concerts and street entertainment. The Gaeltacht Quarter is an area around the Falls Road in west Belfast which promotes and encourages the use of the Irish language. The Queen's Quarter in south Belfast is named after Queen's University. The area has a large student population and hosts the annual Belfast International Arts Festival each autumn. It is home to Botanic Gardens and the Ulster Museum, which was reopened in 2009 after major redevelopment. The Golden Mile is the name given to the mile between Belfast City Hall and Queen's University. Taking in Dublin Road, Great Victoria Street, Shaftesbury Square and Bradbury Place, it contains some of the best bars and restaurants in the city. Since the Good Friday Agreement in 1998, the nearby Lisburn Road has developed into the city's most exclusive shopping strip. Finally, the Titanic Quarter covers of reclaimed land adjacent to Belfast Harbour, formerly known as "Queen's Island". Named after "RMS Titanic", which was built here in 1912, work has begun which promises to transform some former shipyard land into "one of the largest waterfront developments in Europe". Plans include apartments, a riverside entertainment district, and a major Titanic-themed museum.

The architectural style of Belfast's buildings range from Edwardian, like the City Hall, to modern, like Waterfront Hall. Many of the city's Victorian landmarks, including the main "Lanyon Building" at Queen's University Belfast and the Linenhall Library, were designed by Sir Charles Lanyon.

The City Hall was finished in 1906 and was built to reflect Belfast's city status, granted by Queen Victoria in 1888. The Edwardian architectural style of Belfast City Hall influenced the Victoria Memorial in Calcutta, India, and Durban City Hall in South Africa. The dome is high and figures above the door state "Hibernia encouraging and promoting the Commerce and Arts of the City".

Among the city's grandest buildings are two former banks: Ulster Bank in Waring Street (built in 1860) and Northern Bank, in nearby Donegall Street (built in 1769). The Royal Courts of Justice in Chichester Street are home to Northern Ireland's Supreme Court. Many of Belfast's oldest buildings are found in the Cathedral Quarter area, which is currently undergoing redevelopment as the city's main cultural and tourist area. Windsor House, high, has 23 floors and is the second tallest building (as distinct from structure) in Ireland. Work has started on the taller Obel Tower, which already surpasses the height of Windsor House in its unfinished state.
The ornately decorated Crown Liquor Saloon, designed by Joseph Anderson in 1876, in Great Victoria Street is one of only two pubs in the UK that are owned by the National Trust (the other is the George Inn, Southwark in London). It was made internationally famous as the setting for the classic film, "Odd Man Out", starring James Mason. The restaurant panels in the Crown Bar were originally made for "Britannic", the sister ship of the "Titanic", built in Belfast.

The Harland and Wolff shipyard has two of the largest dry docks in Europe, where the giant cranes, Samson and Goliath stand out against Belfast's skyline.
Including the Waterfront Hall and the Odyssey Arena, Belfast has several other venues for performing arts. The architecture of the Grand Opera House has an oriental theme and was completed in 1895. It was bombed several times during the Troubles but has now been restored to its former glory. The Lyric Theatre, (re-opened 1 May 2011 after undergoing a rebuilding programme) the only full-time producing theatre in the country, is where film star Liam Neeson began his career. The Ulster Hall (1859–1862) was originally designed for grand dances but is now used primarily as a concert and sporting venue. Lloyd George, Parnell and Patrick Pearse all attended political rallies there.

Sitting at the mouth of the River Lagan where it becomes a deep and sheltered lough, Belfast is surrounded by mountains that create a micro-climate conducive to horticulture. From the Victorian Botanic Gardens in the heart of the city to the heights of Cave Hill Country Park, the great expanse of Lagan Valley Regional Park to Colin Glen, Belfast contains an abundance of parkland and forest parks.

Parks and gardens are an integral part of Belfast's heritage, and home to an abundance of local wildlife and popular places for a picnic, a stroll or a jog. Numerous events take place throughout including festivals such as Rose Week and special activities such as bird watching evenings and great beast hunts.

Belfast has over forty public parks. The Forest of Belfast is a partnership between government and local groups, set up in 1992 to manage and conserve the city's parks and open spaces. They have commissioned more than 30 public sculptures since 1993. In 2006, the City Council set aside £8 million to continue this work. The Belfast Naturalists' Field Club was founded in 1863 and is administered by National Museums and Galleries of Northern Ireland.

With an average of 670,000 visitors per year between 2007 and 2011, one of the most popular parks is Botanic Gardens in the Queen's Quarter. Built in the 1830s and designed by Sir Charles Lanyon, Botanic Gardens Palm House is one of the earliest examples of a curvilinear and cast iron glasshouse. Other attractions in the park include the Tropical Ravine, a humid jungle glen built in 1889, rose gardens and public events ranging from live opera broadcasts to pop concerts. U2 played here in 1997. Sir Thomas and Lady Dixon Park, to the south of the city centre, attracts thousands of visitors each year to its International Rose Garden. Rose Week in July each year features over 20,000 blooms. It has an area of of meadows, woodland and gardens and features a Diana, Princess of Wales Memorial Garden, a Japanese garden, a walled garden, and the Golden Crown Fountain commissioned in 2002 as part of the Queen's Golden Jubilee celebrations.

In 2008, Belfast was named a finalist in the Large City (200,001 and over) category of the RHS Britain in Bloom competition along with London Borough of Croydon and Sheffield.

Belfast Zoo is owned by Belfast City Council. The council spends £1.5 million every year on running and promoting the zoo, which is one of the few local government-funded zoos in the UK and Ireland. The zoo is one of the top visitor attractions in Northern Ireland, receiving more than 295,000 visitors a year. The majority of the animals are in danger in their natural habitat. The zoo houses more than 1,200 animals of 140 species including Asian elephants, Barbary lions, Malayan sun bears (one of the few in the United Kingdom), two species of penguin, a family of western lowland gorillas, a troop of common chimpanzees, a pair of red pandas, a pair of Goodfellow's tree-kangaroos and Francois' langurs. The zoo also carries out important conservation work and takes part in European and international breeding programmes which help to ensure the survival of many species under threat.

At the 2001 census, the population was 276,459, while 579,554 people lived in the wider Belfast Metropolitan Area.

This made it the fifteenth-largest city in the United Kingdom, but the eleventh-largest conurbation.

Belfast experienced a huge growth in population in the first half of the twentieth century. This rise slowed and peaked around the start of the Troubles with the 1971 census showing almost 600,000 people in the Belfast Urban Area. Since then, the inner city numbers have dropped dramatically as people have moved to swell the Greater Belfast suburb population. The 2001 census population in the same Urban Area had fallen to 277,391 people, with 579,554 people living in the wider Belfast Metropolitan Area.

The 2001 census recorded 81,650 people from Catholic backgrounds and 79,650 people from Protestant backgrounds of working age living in Belfast. The population density in 2011 was 24.88 people/hectare (compared to 1.34 for the rest of Northern Ireland).

As with many cities, Belfast's inner city is currently characterised by the elderly, students and single young people, while families tend to live on the periphery. Socio-economic areas radiate out from the Central Business District, with a pronounced wedge of affluence extending out the Malone Road and Upper Malone Road to the south. An area of greater deprivation extends to the west of the city. The areas around the Falls (Catholic nationalist) and the Shankill Road (Protestant loyalist) are the most deprived wards in Northern Ireland.

Despite a period of relative peace, most areas and districts of Belfast still reflect the divided nature of Northern Ireland as a whole. Many areas are still highly segregated along ethnic, political and religious lines, especially in working-class neighbourhoods.

These zones – Catholic/Republican on one side and Protestant/Loyalist on the other – are invariably marked by flags, graffiti and murals. Segregation has been present throughout the history of Belfast, but has been maintained and increased by each outbreak of violence in the city. This escalation in segregation, described as a "ratchet effect", has shown little sign of decreasing.

The highest levels of segregation in the city are in west Belfast with many areas greater than 90% Catholic. Opposite but comparatively high levels are seen in the predominantly Protestant east Belfast. Areas where segregated working-class areas meet are known as interface areas and sometimes marked by peace lines. When violence flares, it tends to be in interface areas.

Ethnic minority communities have been in Belfast since the 1930s. The largest groups are Poles, Chinese and Indians.

Since the expansion of the European Union, numbers have been boosted by an influx of Eastern European immigrants. Census figures (2011) showed that Belfast has a total non-white population of 10,219 or 3.3%, while 18,420 or 6.6% of the population were born outside the UK and Ireland. Almost half of those born outside the UK and Ireland live in south Belfast, where they comprise 9.5% of the population. The majority of the estimated 5,000 Muslims and 200 Hindu families living in Northern Ireland live in the Greater Belfast area.

The IRA Ceasefire in 1994 and the signing of the Good Friday Agreement in 1998 have given investors increased confidence to invest in Belfast. This has led to a period of sustained economic growth and large-scale redevelopment of the city centre. Developments include Victoria Square, the Cathedral Quarter, and the Laganside with the Odyssey complex and the landmark Waterfront Hall. 
Other major developments include the regeneration of the Titanic Quarter, and the erection of the Obel Tower, a skyscraper set to be the tallest tower on the island.
Today, Belfast is Northern Ireland's educational and commercial hub. In February 2006, Belfast's unemployment rate stood at 4.2%, lower than both the Northern Ireland and the UK average of 5.5%. Over the past 10 years employment has grown by 16.4 per cent, compared with 9.2 per cent for the UK as a whole.

Northern Ireland's peace dividend has led to soaring property prices in the city. In 2007, Belfast saw house prices grow by 50%, the fastest rate of growth in the UK. In March 2007, the average house in Belfast cost £91,819, with the average in south Belfast being £141,000. In 2004, Belfast had the lowest owner occupation rate in Northern Ireland at 54%.

Peace has boosted the numbers of tourists coming to Belfast. There were 6.4 million visitors in 2005, which was a growth of 8.5% from 2004. The visitors spent £285.2 million, supporting more than 15,600 jobs. Visitor numbers rose by 6% to reach 6.8 million in 2006, with tourists spending £324 million, an increase of 15% on 2005. The city's two airports have helped make the city one of the most visited weekend destinations in Europe.

Belfast has been the fastest-growing economy of the thirty largest cities in the UK over the past decade, a new economy report by Howard Spencer has found. ""That's because [of] the fundamentals of the UK economy and [because] people actually want to invest in the UK,"" he commented on that report.

BBC Radio 4's World reported furthermore that despite higher levels of corporation tax in the UK than in the Republic. There are "huge amounts" of foreign investment coming into the country.

"The Times" wrote about Belfast's growing economy: "According to the region's development agency, throughout the 1990s Northern Ireland had the fastest-growing regional economy in the UK, with GDP increasing 1 per cent per annum faster than the rest of the country. As with any modern economy, the service sector is vital to Northern Ireland's development and is enjoying excellent growth. In particular, the region has a booming tourist industry with record levels of visitors and tourist revenues and has established itself as a significant location for call centres."
Since the ending of the regions conflict tourism has boomed in Northern Ireland, greatly aided by low cost.

Der Spiegel, a German weekly magazine for politics and economy, titled Belfast as "The New Celtic Tiger" which is "open for business".

When the population of Belfast town began to grow in the 17th century, its economy was built on commerce. It provided a market for the surrounding countryside and the natural inlet of Belfast Lough gave the city its own port. The port supplied an avenue for trade with Great Britain and later Europe and North America. In the mid-17th century, Belfast exported beef, butter, hides, tallow and corn and it imported coal, cloth, wine, brandy, paper, timber and tobacco.

Around this time, the linen trade in Northern Ireland blossomed and by the middle of the 18th century, one fifth of all the linen exported from Ireland was shipped from Belfast. The present city however is a product of the Industrial Revolution. It was not until industry transformed the linen and shipbuilding trades that the economy and the population boomed. By the turn of the 19th century, Belfast had transformed into the largest linen producing centre in the world, earning the nickname "Linenopolis".

Belfast harbour was dredged in 1845 to provide deeper berths for larger ships. Donegall Quay was built out into the river as the harbour was developed further and trade flourished. The Harland and Wolff shipbuilding firm was created in 1861, and by the time the "Titanic" was built, in 1912, it had become the largest shipyard in the world.

Short Brothers plc is a British aerospace company based in Belfast. It was the first aircraft manufacturing company in the world. The company began its association with Belfast in 1936, with Short & Harland Ltd, a venture jointly owned by Shorts and Harland and Wolff. Now known as Shorts Bombardier it works as an international aircraft manufacturer located near the Port of Belfast.

The rise of mass-produced and cotton clothing following World War I were some of the factors which led to the decline of Belfast's international linen trade. Like many British cities dependent on traditional heavy industry, Belfast suffered serious decline since the 1960s, exacerbated greatly in the 1970s and 1980s by the Troubles. More than 100,000 manufacturing jobs have been lost since the 1970s. For several decades, Northern Ireland's fragile economy required significant public support from the British exchequer of up to £4 billion per year.

Belfast saw the worst of the Troubles in Northern Ireland, with nearly half of the total deaths in the conflict occurring in the city. However, since the Good Friday Agreement in 1998, there has been significant urban regeneration in the city centre including Victoria Square, Queen's Island and Laganside as well as the Odyssey complex and the landmark Waterfront Hall. The city is served by two airports: The George Best Belfast City Airport adjacent to Belfast Lough and Belfast International Airport which is near Lough Neagh. Queen's University of Belfast is the main university in the city. The Ulster University also maintains a campus in the city, which concentrates on fine art, design and architecture.

Belfast is one of the constituent cities that makes up the Dublin-Belfast corridor region, which has a population of just under 3 million.

Most of Belfast's water is supplied from the Silent Valley Reservoir in County Down, created to collect water from the Mourne Mountains. The rest of the city's water is sourced from Lough Neagh, via "Dunore Water Treatment Works" in County Antrim. The citizens of Belfast pay for their water in their rates bill. Plans to bring in additional water tariffs have been deferred by devolution in May 2007. Belfast has approximately of sewers, which are currently being replaced in a project costing over £100 million and due for completion in 2009.

Northern Ireland Electricity is responsible for transmitting electricity in Northern Ireland. Belfast's electricity comes from Kilroot Power Station, a 520 MegaWatt dual coal and oil fired plant, situated near Carrickfergus. Phoenix Natural Gas Ltd. started supplying customers in Larne and Greater Belfast with natural gas in 1996 via the newly constructed Scotland-Northern Ireland pipeline. Rates in Belfast (and the rest of Northern Ireland) were reformed in April 2007. The discrete capital value system means rates bills are determined by the capital value of each domestic property as assessed by the "Valuation and Lands Agency". The recent dramatic rise in house prices has made these reforms unpopular.

The Belfast Health & Social Care Trust is one of five trusts that were created on 1 April 2007 by the Department of Health. Belfast contains most of Northern Ireland's regional specialist centres. The Royal Victoria Hospital is an internationally renowned centre of excellence in trauma care and provides specialist trauma care for all of Northern Ireland. It also provides the city's specialist neurosurgical, ophthalmology, ENT, and dentistry services. The Belfast City Hospital is the regional specialist centre for haematology and is home to a cancer centre that rivals the best in the world. The Mary G McGeown Regional Nephrology Unit at the City Hospital is the kidney transplant centre and provides regional renal services for Northern Ireland.
Musgrave Park Hospital in south Belfast specialises in orthopaedics, rheumatology, sports medicine and rehabilitation. It is home to Northern Ireland's first Acquired Brain Injury Unit, costing £9 million and opened by the Prince of Wales and the Duchess of Cornwall in May 2006. Other hospitals in Belfast include the Mater Hospital in north Belfast and the Children's Hospital.

Belfast is a relatively car-dependent city by European standards, with an extensive road network including the M2 and M22 motorway route. A 2005 survey of how people travel in Northern Ireland showed that people in Belfast made 77% of all journeys by car, 11% by public transport and 6% on foot. It showed that Belfast has 0.70 cars per household compared to figures of 1.18 in the East and 1.14 in the West of Northern Ireland. A road improvement-scheme in Belfast began early in 2006, with the upgrading of two junctions along the Westlink dual-carriageway to grade-separated standard. The improvement scheme was completed five months ahead of schedule on February 2009, with the official opening taking place on 4 March 2009.

Commentators have argued that this may create a bottleneck at York Street, the next at-grade intersection, until that too is upgraded. On 25 October 2012 the stage 2 report for the York Street intersection was approved and in December 2012 the planned upgrade moved into stage 3 of the development process. If successfully completing the necessary statutory procedures, work on a grade separated junction to connect the Westlink to the M2/M3 motorways is scheduled to take place between 2014 and 2018, creating a continuous link between the M1 and M2, the two main motorways in Northern Ireland.
Black taxis are common in the city, operating on a share basis in some areas. These are outnumbered by private hire taxis. Bus and rail public transport in Northern Ireland is operated by subsidiaries of Translink. Bus services in the city proper and the nearer suburbs are operated by Translink Metro, with services focusing on linking residential districts with the city centre on 12 quality bus corridors running along main radial roads,

More distant suburbs are served by Ulsterbus. Northern Ireland Railways provides suburban services along three lines running through Belfast's northern suburbs to Carrickfergus, Larne and Larne Harbour, eastwards towards Bangor and south-westwards towards Lisburn and Portadown. This service is known as the Belfast Suburban Rail system. Belfast is linked directly to Coleraine, Portrush and Derry. Belfast has a direct rail connection with Dublin called "Enterprise" which is operated jointly by NIR and Iarnród Éireann, the state railway company of the Republic of Ireland.
There are no rail services to cities in other countries of the United Kingdom, due to the lack of a bridge or tunnel connecting Great Britain to the island of Ireland. There is, however, a combined ferry and rail ticket between Belfast and cities in Great Britain, which is referred to as "Sailrail".

In April 2008, the Department for Regional Development reported on a plan for a light-rail system, similar to that in Dublin. The consultants said Belfast does not have the population to support a light rail system, suggesting that investment in bus-based rapid transit would be preferable.The study found that bus-based rapid transit produces positive economic results, but light rail does not. The report by Atkins & KPMG, however, said there would be the option of migrating to light rail in the future should the demand increase.

The city has two airports: Belfast International Airport offering, domestic, European and international flights such as Newark (New York) operated by United Airlines, Orlando, and Las Vegas both operated by Thomas Cook. The seasonal flight to Orlando is also operated by Virgin Atlantic. The airport is located northwest of the city, near Lough Neagh, while the George Best Belfast City Airport, which is closer to the city centre by train from Sydenham on the Bangor Line, adjacent to Belfast Lough, offers UK domestic flights and a few European flights. In 2005, Belfast International Airport was the 11th busiest commercial airport in the UK, accounting for just over 2% of all UK terminal passengers while the George Best Belfast City Airport was the 16th busiest and had 1% of UK terminal passengers. The Belfast – Liverpool route is the busiest domestic flight route in the UK excluding London with 555,224 passengers in 2009. Over 2.2 million passengers flew between Belfast and London in 2009.

Belfast has a large port used for exporting and importing goods, and for passenger ferry services. Stena Line runs regular routes to Cairnryan in Scotland using its conventional vessels – with a crossing time of around 2 hours 15 minutes. Until 2011 the route went to Stranraer and used inter alia a HSS (High Speed Service) vessel – with a crossing time of around 90 minutes. Stena Line also operates a route to Liverpool. A seasonal sailing to Douglas, Isle of Man is operated by the Isle of Man Steam Packet Company.

Belfast's population is evenly split between its Protestant and Catholic residents. These two distinct cultural communities have both contributed significantly to the city's culture. Throughout the Troubles, Belfast artists continued to express themselves through poetry, art and music. In the period since the Good Friday Agreement in 1998, Belfast has begun a social, economic and cultural transformation giving it a growing international cultural reputation. In 2003, Belfast had an unsuccessful bid for the 2008 European Capital of Culture. The bid was run by an independent company, "Imagine Belfast", who boasted that it would "make Belfast the meeting place of Europe's legends, where the meaning of history and belief find a home and a sanctuary from caricature, parody and oblivion." According to "The Guardian" the bid may have been undermined by the city's history and volatile politics.

In 2004–05, art and cultural events in Belfast were attended by 1.8 million people (400,000 more than the previous year). The same year, 80,000 people participated in culture and other arts activities, twice as many as in 2003–04. A combination of relative peace, international investment and an active promotion of arts and culture is attracting more tourists to Belfast than ever before. In 2004–05, 5.9 million people visited Belfast, a 10% increase from the previous year, and spent £262.5 million.

The Ulster Orchestra, based in Belfast, is Northern Ireland's only full-time symphony orchestra and is well renowned in the United Kingdom. Founded in 1966, it has existed in its present form since 1981, when the BBC Northern Ireland Orchestra was disbanded. The music school of Queen's University is responsible for arranging a notable series of lunchtime and evening concerts, often given by renowned musicians which are usually given in The Harty Room at the university (University Square).
There are many Traditional Irish bands playing throughout the city and quite a few music schools concentrate on teaching Traditional music.

Musicians and bands who have written songs about or dedicated to Belfast:
U2, Van Morrison, Snow Patrol, Simple Minds, Elton John, Rogue Male, Katie Melua, Boney M, Paul Muldoon, Stiff Little Fingers, Nanci Griffith, Glenn Patterson, Orbital, James Taylor, Fun Boy Three, Spandau Ballet, The Police, Barnbrack, Gary Moore, Neon Neon, Toxic Waste, Energy Orchard, and Billy Bragg.

Further in Belfast the Oh Yeah Music Centre is located (Cathedral Quarter), a project founded to give young musicians and artists a place where they can share ideas and kick-start their music careers as a chance to be supported and promoted by professional musicians of Northern Ireland's music-scene.

Belfast has a longstanding underground club scene which was established in the early 1980s.

Like all areas of the island of Ireland outside of the Gaeltacht, the Irish language in Belfast is not that of an unbroken intergenerational transmission. Due to community activity in the 1960s, including the establishment of the Shaws Road Gaeltacht community, the expanse in the Irish language arts, and the advancements made in the availability of Irish medium education throughout the city, it can now be said that there is a 'mother-tongue' community of speakers. The language is heavily promoted in the city and is particularly visible in the Falls Road area, where the signs on both the iconic black taxis and on the public buses are bilingual. Belfast has the highest concentration of Irish speakers in Northern Ireland. Projects to promote the language in the city are funded by various sources, notably Foras na Gaeilge, an all-Ireland body funded by both the Irish and British governments. There are a number Irish language Primary schools and one secondary school in Belfast. The provision of certain resources for these schools (for example, such as the provision of textbooks) is supported by the charitable organisation TACA.

Belfast is the home of the "Belfast Telegraph", "Irish News", and "The News Letter", the oldest English-language newspaper in the world still in publication. The city has a number of free publications including "Fate" magazine, "Go Belfast", and the "Vacuum", that are distributed through bar, cafes and public venues.

The city is the headquarters of BBC Northern Ireland, ITV station UTV and commercial radio stations Belfast CityBeat and U105. Two community radio stations, Blast 106 and Irish-language station Raidió Fáilte, broadcast to the city from west Belfast, as does Queen's Radio, a student-run radio station which broadcasts from Queen's University Students' Union. One of Northern Ireland's two community TV stations, NvTv, is based in the Cathedral Quarter of the city. There are two independent cinemas in Belfast: the Queen's Film Theatre and the Strand Cinema, which host screenings during the Belfast Film Festival and the Belfast Festival at Queen's. Broadcasting only over the Internet is Homely Planet, the Cultural Radio Station for Northern Ireland, supporting community relations.

The city has become a popular film location; The Paint Hall at Harland and Wolff has become one of the UK Film Council's main studios. The facility comprises four stages of . Shows filmed at The Paint Hall include the film "City of Ember" (2008) and HBO's "Game of Thrones" series (beginning in late 2009).

In November 2011, Belfast became the smallest city to host the MTV Europe Music Awards. The event was hosted by Selena Gomez and celebrities such as Justin Bieber, Jessie J, Hayden Panettiere, and Lady Gaga travelled to Northern Ireland to attend the event, held in the Odyssey Arena.

Belfast has several notable sports teams playing a diverse variety of sports such as football, Gaelic games, rugby, cricket, and ice hockey. The Belfast Marathon is run annually on May Day, and attracted 20,000 participants in 2011.

The Northern Ireland national football team, ranked 23rd in August 2017 in the FIFA World Rankings, plays its home matches at Windsor Park. The current Irish League league leaders Crusaders are based at Seaview, in the north of the city. Other senior clubs are Glentoran, Linfield, Cliftonville, Harland & Wolff Welders and PSNI. Intermediate-level clubs are: Donegal Celtic, Dundela, Newington Youth, Queen's University and Sport & Leisure Swifts, who compete in the NIFL Premier Intermediate League; Albert Foundry, Bloomfield, Colin Valley, Crumlin Star, Dunmurry Rec., Dunmurry Young Men, East Belfast, Grove United, Immaculata, Iveagh United, Malachians, Orangefield Old Boys, Rosario Youth Club, St Luke's, St Patrick's Young Men, Shankill United, Short Brothers and Sirocco Works of the Northern Amateur Football League and Brantwood of the Ballymena & Provincial League. Belfast was the home town of Manchester United legend George Best who died in November 2005. On the day he was buried in the city, 100,000 people lined the route from his home on the Cregagh Road to Roselawn cemetery. Since his death the City Airport was named after him and a trust has been set up to fund a memorial to him in the city centre.

Belfast is home to over twenty Gaelic football and hurling clubs. Casement Park in west Belfast, home to the Antrim county teams, has a capacity of 32,000 which makes it the second largest Gaelic Athletic Association ground in Ulster. The 1999 Heineken Cup champions Ulster Rugby play at the Kingspan Stadium in the south of the city. Belfast has four teams in rugby's All-Ireland League: Belfast Harlequins in Division 1B; and Instonians, Queen's University and Malone in Division 2A.

Belfast is home to the Stormont cricket ground since 1949 and was the venue for the Irish cricket team's first ever one day international (ODI) against England in 2006.

In 2007, Pro Wrestling Ulster formed. This is wrestling promotion on the independent circuit, holding events and PPV's in Europa Hotel and The Mandela Hall. It runs to this day.

Belfast is home to one of the biggest British ice hockey clubs, the Belfast Giants. The Giants were founded in 2000 and play their games at the 9,500 capacity Odyssey Arena, crowds normally range from 4,000–7,000. Many ex-NHL players have featured on the Giants roster, none more famous than world superstar Theo Fleury. The Giants play in the 10 team professional Elite Ice Hockey League which is the top league in Britain. The Giants have been league champions 4 times, most recently in the 2013–14 season. The Belfast Giants are a huge brand in Northern Ireland and their increasing stature in the game led to the Belfast Giants playing the Boston Bruins of the NHL on 2 October 2010 at the Odyssey Arena in Belfast, losing the game 5–1.

Other significant sportspeople from Belfast include double world snooker champion Alex "Hurricane" Higgins and world champion boxers Wayne McCullough and Rinty Monaghan.
Leander A.S.C is a well known swimming club in Belfast. Belfast produced the Formula One racing stars John Watson who raced for five different teams during his career in the 1970s and 1980s and Ferrari driver Eddie Irvine.

Academia and Science

Arts and Media

Politics

Sports

Other
Belfast has two universities. Queen's University Belfast was founded in 1845 and is a member of the Russell Group, an association of 24 leading research-intensive universities in the UK. It is one of the largest universities in the UK with 25,231 undergraduate and postgraduate students spread over 250 buildings, 120 of which are listed as being of architectural merit. 

Ulster University, created in its current form in 1984, is a multi-centre university with a campus in the Cathedral Quarter of Belfast. The Belfast campus has a specific focus on Art and Design and Architecture, and is currently undergoing major redevelopment. The Jordanstown campus, just from Belfast city centre concentrates on engineering, health and social science. The Coleraine campus, about from Belfast city centre concentrates on a broad range of subjects. Course provision is broad – biomedical sciences, environmental science and geography, psychology, business, the humanities and languages, film and journalism, travel and tourism, teacher training and computing are among the campus strengths. The Magee campus, about from Belfast city centre has many teaching strengths; including business, computing, creative technologies, nursing, Irish language and literature, social sciences, law, psychology, peace and conflict studies and the performing arts. The Conflict Archive on the INternet (CAIN) Web Service receives funding from both universities and is a rich source of information and source material on the Troubles as well as society and politics in Northern Ireland.

Belfast Metropolitan College is a large further education college with three main campuses around the city, including several smaller buildings. Formerly known as Belfast Institute of Further and Higher Education, it specialises in vocational education. The college has over 53,000 students enrolled on full-time and part-time courses, making it one of the largest further education colleges in the UK and the largest in the island of Ireland.

The Belfast Education and Library Board was established in 1973 as the local council responsible for education, youth and library services within the city. There are 184 primary, secondary and grammar schools in the city.

The Ulster Museum is located in Belfast.

Belfast is one of the most visited cities in the UK, and the second most visited on the island of Ireland. In 2008, 7.1 million tourists visited the city. Numerous popular tour bus companies and boat tours run there throughout the year.

Frommer's, the American travel guidebook series, listed Belfast as the only United Kingdom destination in its "Top 12 Destinations to Visit" in 2009. The other listed destinations were Berlin (Germany), Cambodia, Cape Town (South Africa), Cartagena (Colombia), Istanbul (Turkey), the Lassen Volcanic National Park (USA), Saqqara (Egypt), the Selma To Montgomery National Historic Trail (USA), Waiheke Island (New Zealand), Washington, D.C. (USA), and Waterton Lakes National Park (Canada).

The Belfast City Council is currently investing into the complete redevelopment of the Titanic Quarter, which is planned to consist of apartments, hotels, and a riverside entertainment district. A major visitor attraction, Titanic Belfast is a monument to Belfast's maritime heritage on the site of the former Harland & Wolff shipyard, opened on 31 March 2012. It features a criss-cross of escalators and suspended walkways and nine high-tech galleries. They also hope to invest in a new modern transport system (including high-speed rail and others) for Belfast, with a cost of £250 million.

There is a tourist information centre located at Donegall Square North.

Belfast has the following sister cities:





</doc>
<doc id="5047" url="https://en.wikipedia.org/wiki?curid=5047" title="Biotite">
Biotite

Biotite is a common phyllosilicate mineral within the mica group, with the approximate chemical formula . More generally, it refers to the dark mica series, primarily a solid-solution series between the iron-endmember annite, and the magnesium-endmember phlogopite; more aluminous end-members include siderophyllite. Biotite was named by J.F.L. Hausmann in 1847 in honor of the French physicist Jean-Baptiste Biot, who performed early research into the many optical properties of mica.

Biotite is a sheet silicate. Iron, magnesium, aluminium, silicon, oxygen, and hydrogen form sheets that are weakly bound together by potassium ions. It is sometimes called "iron mica" because it is more iron-rich than phlogopite. It is also sometimes called "black mica" as opposed to "white mica" (muscovite) – both form in the same rocks, and in some instances side-by-side.

Like other mica minerals, biotite has a highly perfect basal cleavage, and consists of flexible sheets, or lamellae, which easily flake off. It has a monoclinic crystal system, with tabular to prismatic crystals with an obvious pinacoid termination. It has four prism faces and two pinacoid faces to form a pseudohexagonal crystal. Although not easily seen because of the cleavage and sheets, fracture is uneven. It appears greenish to brown or black, and even yellow when weathered. It can be transparent to opaque, has a vitreous to pearly luster, and a grey-white streak. When biotite is found in large chunks, they are called “books” because it resembles a book with pages of many sheets. The color of biotite is usually black and the mineral has a hardness of 2.5-3 on the Mohs scale of mineral hardness.

Biotite dissolves in both acid and alkaline aqueous solutions, with the highest dissolution rates at low pH. However, biotite dissolution is highly anisotropic with crystal edge surfaces ("h k"0) reacting 45 to 132 times faster than basal surfaces (001).

Under cross-polarized light biotite can generally be identified by the gnarled bird's eye extinction.

Biotite is found in a wide variety of igneous and metamorphic rocks. For instance, biotite occurs in the lava of Mount Vesuvius and in the Monzoni intrusive complex of the western Dolomites. Biotite in granite tends to be poorer in magnesium than the biotite found in its volcanic equivalent, rhyolite. Biotite is an essential phenocryst in some varieties of lamprophyre. Biotite is occasionally found in large cleavable crystals, especially in pegmatite veins, as in New England, Virginia and North Carolina. Other notable occurrences include Bancroft and Sudbury, Ontario. It is an essential constituent of many metamorphic schists, and it forms in suitable compositions over a wide range of pressure and temperature. It has been estimated that biotite comprises up to 7% of the exposed continental crust.

The largest documented single crystals of biotite were approximately sheets found in Iveland, Norway.

Biotite is used extensively to constrain ages of rocks, by either potassium-argon dating or argon–argon dating. Because argon escapes readily from the biotite crystal structure at high temperatures, these methods may provide only minimum ages for many rocks. Biotite is also useful in assessing temperature histories of metamorphic rocks, because the partitioning of iron and magnesium between biotite and garnet is sensitive to temperature.


</doc>
<doc id="5048" url="https://en.wikipedia.org/wiki?curid=5048" title="Brigham Young">
Brigham Young

Brigham Young (; June 1, 1801August 29, 1877) was an American leader in the Latter Day Saint movement, politician, and a settler in the Western United States. He was the second president of The Church of Jesus Christ of Latter-day Saints (LDS Church) from 1847 until his death in 1877. He founded Salt Lake City and he served as the first governor of the Utah Territory. Young also led the foundings of the precursors to the University of Utah and Brigham Young University.

Young had many nicknames, among the most popular being "American Moses" (alternatively, the "Modern Moses" or "Mormon Moses"), because, like the biblical figure, Young led his followers, the Mormon pioneers, in an exodus through a desert, to what they saw as a promised land. Young was dubbed by his followers the "Lion of the Lord" for his bold personality and was also commonly called "Brother Brigham" by Latter-day Saints. Young was a polygamist and was involved in controversies regarding black people and the Priesthood, the Utah War, and the Mountain Meadows massacre.

Young was born to John Young and Abigail "Nabby" Howe, a farming family in Whitingham, Vermont, and worked as a travelling carpenter and blacksmith, among other trades. Young was first married in 1824 to Miriam Angeline Works. Though he had converted to the Methodist faith in 1823, Young was drawn to Mormonism after reading the Book of Mormon shortly after its publication in 1830. He officially joined the new church in 1832 and traveled to Upper Canada as a missionary. After his wife died in 1832, Young joined many Mormons in establishing a community in Kirtland, Ohio. Young was ordained a member of the original Quorum of the Twelve Apostles in 1835, and he assumed a leadership role within that organization in taking Mormonism to the United Kingdom and organizing the exodus of Latter Day Saints from Missouri in 1838.

In 1844, while in jail awaiting trial for treason charges, Joseph Smith, president of the church, was killed by an armed mob. Several claimants to the role of church president emerged during the succession crisis that ensued. Before a large meeting convened to discuss the succession in Nauvoo, Illinois, Sidney Rigdon, the senior surviving member of the church's First Presidency, argued there could be no successor to the deceased prophet and that he should be made the "Protector" of the church. Young opposed this reasoning and motion. Smith had earlier recorded a revelation which stated the Quorum of the Twelve Apostles was "equal in authority and power" to the First Presidency, so Young claimed that the leadership of the church fell to the Twelve Apostles. The majority in attendance were persuaded that the Quorum of the Twelve Apostles was to lead the church with Young as the Quorum's president. Many of Young's followers would later reminisce that while Young spoke to the congregation, he looked or sounded exactly like Smith, which they attributed to the power of God. Young was ordained President of the Church in December 1847, three and a half years after Smith's death. Rigdon became the president of a separate church organization based in Pittsburgh, Pennsylvania, and other potential successors emerged to lead what became other denominations of the movement.

Repeated conflict led Young to relocate his group of Latter-day Saints to the Salt Lake Valley, which was then part of Mexico. Young organized the journey that would take the Mormon pioneers to Winter Quarters, Nebraska, in 1846, then to the Salt Lake Valley. By the time Young arrived at the final destination, it had come under American control as a result of war with Mexico, although U.S. sovereignty would not be confirmed until 1848. Young arrived in the Salt Lake Valley on July 24, 1847, a date now recognized as Pioneer Day in Utah. Young's expedition was one of the largest and one of the best organized westward treks. On August 22, 29 days after arriving in the Salt Lake Valley, Young organized the Mormon Tabernacle Choir.

After three years of leading the church as the President of the Quorum of the Twelve Apostles, Young reorganized a new First Presidency and was declared president of the church on December 27, 1847.

As colonizer and founder of Salt Lake City, Young was appointed the territory's first governor and superintendent of American Indian affairs by President Millard Fillmore on February 3, 1851. During his time as prophet, Young directed the establishment of settlements throughout present-day Utah, Idaho, Arizona, Nevada, California and parts of southern Colorado and northern Mexico. Under his direction, the Mormons built roads and bridges, forts, irrigation projects; established public welfare; organized a militia; issued an extermination order against the Timpanogos and after a series of wars eventually made peace with the Native Americans. Young was also one of the first to subscribe to Union Pacific stock, for the construction of the First Transcontinental Railroad. Young organized the first legislature and established Fillmore as the territory's first capital.

Young organized a Board of Regents to establish a university in the Salt Lake Valley. It was established on February 28, 1850, as the University of Deseret; its name was eventually changed to the University of Utah.

In 1851, Young and several federal officials, including territorial Secretary Broughton Harris, became unable to work cooperatively. Harris and the others departed Utah without replacements being named, and these individuals later became known as the Runaway Officials of 1851.

In 1852, Young led the efforts to reform slavery in Utah, based on his personal beliefs on slavery.

In 1856, Young organized an efficient mail service. In 1858, following the events of the Utah War, he stepped down to his successor Alfred Cumming.

Young was the longest-serving President of the LDS Church in history, having served for 29 years.

On October 16, 1875, Young deeded buildings and land in Provo, Utah to a Board of Trustees for establishing an institution of learning, ostensibly as part of the University of Deseret. Young said, "I hope to see an Academy established in Provo ... at which the children of the Latter-day Saints can receive a good education unmixed with the pernicious atheistic influences that are found in so many of the higher schools of the country." The school broke off from the University of Deseret and became Brigham Young Academy, the precursor to Brigham Young University.

Within the church, Young reorganized the Relief Society for women (1867), and he created organizations for young women (1869) and young men (1875).

Young was involved in temple building throughout his membership in the LDS Church and made temple building a priority of his church presidency. Under Smith's leadership, Young participated in the building of the Kirtland and Nauvoo temples. Just four days after arriving in the Salt Lake Valley, Young designated the location for the Salt Lake Temple; he presided over its groundbreaking on April 6, 1853. During his tenure, Young oversaw construction of the Salt Lake Tabernacle and he announced plans to build the St. George (1871), Manti (1875), and Logan (1877) temples. He also provisioned the building of the Endowment House, a "temporary temple" which began to be used in 1855 to provide temple ordinances to church members while the Salt Lake Temple was under construction.

Though polygamy was practiced by Young's predecessor Joseph Smith, the practice is often associated with Young. Some Latter Day Saint denominations, such as the Community of Christ, consider Young the "Father of Mormon Polygamy". In 1853, Young made the church's first official statement on the subject since the church had arrived in Utah. Young acknowledged the suffering the doctrine created for women, but stated its necessity for creating large families, proclaiming: "But the first wife will say, 'It is hard, for I have lived with my husband twenty years, or thirty, and have raised a family of children for him, and it is a great trial to me for him to have more women;' then I say it is time that you gave him up to other women who will bear children."

One of the more controversial teachings of Young was the Adam–God doctrine. According to Young, he was taught by Smith that Adam is "our Father and our God, and the only God with whom we have to do". According to the doctrine, Adam was once a mortal man who became resurrected and exalted. From another planet, Adam brought Eve, one of his wives, with him to the earth, where they became mortal by eating the fruit of the Garden of Eden. After bearing mortal children and establishing the human race, Adam and Eve returned to their heavenly thrones where Adam acts as the god of this world. Later, as Young is generally understood to have taught, Adam returned to the earth to become the biological father of Jesus. The LDS Church has since repudiated the Adam–God doctrine.

Young is generally considered to have instituted a church ban against conferring the priesthood on men of black African descent, who had been treated equally in this respect under Smith's presidency. After settling in Utah in 1848, Young announced the ban, which also forbade blacks from participating in Mormon temple rites such as the endowment or sealings. On many occasions, Young taught that blacks were denied the priesthood because they were "the seed of Cain", but also stated that they would eventually receive the priesthood after "all the other children of Adam have the privilege of receiving the Priesthood, and of coming into the kingdom of God, and of being redeemed from the four quarters of the earth, and have received their resurrection from the dead, then it will be time enough to remove the curse from Cain and his posterity."

In 1863, Young stated: "Shall I tell you the law of God in regard to the African race? If the white man who belongs to the chosen seed mixes his blood with the seed of Cain, the penalty, under the law of God, is death on the spot. This will always be so." These racial restrictions remained in place until 1978, when the policy was rescinded by LDS Church president Spencer W. Kimball, and the LDS Church subsequently "disavow[ed] theories advanced in the past" to explain this ban, thereby "plac[ing] the origins of black priesthood denial blame squarely on Brigham Young."

Shortly after the arrival of Young's pioneers, the new Mormon colonies were incorporated into the United States through the Mexican Cession. Young petitioned the U.S. Congress to create the State of Deseret. The Compromise of 1850 instead carved out Utah Territory and Young was installed as governor. As governor and church president, Young directed both religious and economic matters. He encouraged independence and self-sufficiency. Many cities and towns in Utah, and some in neighboring states, were founded under Young's direction. Young's leadership style has been viewed as autocratic. When federal officials received reports of widespread and systematic obstruction of federal officials in Utah (most notably judges), U.S. President James Buchanan decided to install a non-Mormon governor. Buchanan accepted the reports of the judges without any further investigation, and the new non-sectarian governor was accompanied by troops sent to garrison forts in the new territory. When Young received word that federal troops were headed to Utah with his replacement, he called out his militia to ambush the federal force. During the defense of Utah, now called the Utah War, Young held the U.S. Army at bay for a winter by taking their cattle and burning supply wagons. The Mormon forces were largely successful thanks to Lot Smith. Young eventually relented and agreed to step down as governor. He later received a pardon from Buchanan. Relations between Young and future governors and U.S. Presidents were mixed.

The degree of Young's involvement in the Mountain Meadows massacre, which took place in Washington County in 1857, is disputed. Leonard J. Arrington reports that Young received a rider at his office on the day of the massacre, and that when he learned of the contemplated attack by the members of the LDS Church in Parowan and Cedar City, he sent back a letter directing that the Fancher party be allowed to pass through the territory unmolested. Young's letter reportedly arrived on September 13, 1857, two days after the massacre. As governor, Young had promised the federal government he would protect immigrants passing through Utah Territory, but over 120 men, women and children were killed in this incident. There is no debate concerning the involvement of individual Mormons from the surrounding communities by scholars. Only children under the age of seven, who were cared for by local Mormon families, survived, and the murdered members of the wagon train were left unburied. The remains of about forty people were later found and buried, and Union Army officer James Henry Carleton had a large cross made from local trees, the transverse beam bearing the engraving, "Vengeance Is Mine, Saith The Lord: I Will Repay" and erected a cairn of rocks at the site. A large slab of granite was put up on which he had the following words engraved: "Here 120 men, women and children were massacred in cold blood early in September, 1857. They were from Arkansas." For two years the monument stood as a memorial to those travelling the Spanish Trail through Mountain Meadow. Some claim that, in 1861, Young brought an entourage to Mountain Meadows and had the cairn and cross destroyed, while exclaiming, "Vengeance is mine and I have taken a little".

Before his death in Salt Lake City on August 29, 1877, Young was suffering from cholera morbus and inflammation of the bowels. It is believed that he died of peritonitis from a ruptured appendix. His last words were "Joseph! Joseph! Joseph!", invoking the name of the late Joseph Smith, founder of the Mormon faith. On September 2, 1877, Young's funeral was held in the Tabernacle with an estimated 12,000 to 15,000 people in attendance. He is buried on the grounds of the Mormon Pioneer Memorial Monument in the heart of Salt Lake City. A bronze marker was placed at the grave site June 10, 1938, by members of the Young Men and Young Women organizations, which he founded.

A century after his death, one writer stated that

He credited Young's leadership with helping to settle much of the American West:

Memorials to Young include a bronze statue in front of the Abraham O. Smoot Administration Building, Brigham Young University; a marble statue in the National Statuary Hall Collection at the United States Capitol, donated by the State of Utah in 1950; and a statue atop the "This is the Place Monument" in Salt Lake City.
Young's teachings were the 1998–99 course of study in the LDS Church's Sunday Relief Society and Melchizedek priesthood classes.

Young was a polygamist, marrying a total of 55 wives, 54 of them after he converted to Mormonism. The policy was difficult for many in the church. Young stated that upon being taught about plural marriage, "It was the first time in my life that I desired the grave." By the time of his death, Young had 56 children by 16 of his wives; 46 of his children reached adulthood.

Sources have varied on the number of Young's wives, due to differences in what scholars have considered to be a "wife". There were 55 women that Young was sealed to during his lifetime. While the majority of the sealings were "for eternity", some were "for time only". Researchers believe that not all of the 55 marriages were conjugal. Young did not live with a number of his wives or publicly hold them out as wives, which has led to confusion on the number and identities. This is in part due to the complexity of how wives were identified in the Mormon society at the time.

Of Young's 55 wives, 21 had never been married before; 16 were widows; six were divorced; six had living husbands; and the marital status of six others are unknown. In 1856, Young built the Lion House to accommodate his sizable family. This building remains a Salt Lake City landmark, together with the Beehive House, another Young family home. A contemporary of Young wrote: "It was amusing to walk by Brigham Young's big house, a long rambling building with innumerable doors. Each wife has an establishment of her own, consisting of parlor, bedroom, and a front door, the key of which she keeps in her pocket." At the time of Young's death, 19 of his wives had predeceased him, he was divorced from ten, and 23 survived him. The status of four was unknown. One of his wives, Zina Huntington Young, served as the third president of the Relief Society. In his will, Young shared his estate with the 16 surviving wives who had lived with him; the six surviving non-conjugal wives were not mentioned in the will.

In 1902, 25 years after his death, "The" "New York Times" established that Young's direct descendants numbered more than 1,000. Some of Young's descendants have become leaders in the LDS Church, while other have become notable for events outside of LDS Church service.

The Scottish poet John Lyon, who was an intimate friend of Young, wrote "Brigham the Bold" in tribute to him after his death.

Florence Claxton's graphic novel, "The Adventures of a Woman in Search of her Rights" (1872), satirizes a would-be emancipated woman whose failure to establish an independent career results in her marriage to Young before she wakes to discover she's been dreaming.

Arthur Conan Doyle based his first Sherlock Holmes novel, "A Study in Scarlet", on Mormon history, mentioning Young by name. When asked to comment on the story, which had "provoked the animosity of the Mormon faithful", Doyle noted, "all I said about the Danite Band and the murders is historical so I cannot withdraw that though it is likely that in a work of fiction it is stated more luridly than in a work of history." Doyle's daughter stated: "You know father would be the first to admit that his first Sherlock Holmes novel was full of errors about the Mormons."

Mark Twain devoted a chapter and much of an appendix to Young in "Roughing It".

Oliver Wendell Holmes Sr., talking about his fondness of trees, joked in his "The Autocrat of the Breakfast Table": "I call all trees mine that I have put my wedding-ring on, and I have as many tree-wives as Brigham Young has human ones."

Byron Morrow played Young in a cameo appearance in the "Death Valley Days" episode, "An Organ for Brother Brigham" (1966). In the storyline, the organ built and guided west to Salt Lake City by Joseph Harris Ridges (1827–1914) of Australia becomes mired in the sand. Wagonmaster Luke Winner (portrayed Morgan Woodward) feels compelled to leave the instrument behind until Ridges finds solid rock under the sand.

Gregg Henry depicts Young in the fourth (2014) and fifth (2015) seasons of the TV series "Hell on Wheels", a fictional story about the construction of the First Transcontinental Railroad. As the competing rail lines approach Utah from the east and west coasts, Young supplies Mormon laborers to both railroad companies and negotiates with the railways to have them make Salt Lake City their meeting point. In the Season 5 mid-season finale, "False Prophets", Young's son, Phineas, attempts to murder his father. Persuaded by The Swede, Phineas believed he was the chosen one to go forward to lead the Mormons, instead of his father.

Since Young's death, a number of works have published collections of his discourses and sayings.




</doc>
<doc id="5049" url="https://en.wikipedia.org/wiki?curid=5049" title="Burns supper">
Burns supper

A Burns supper is a celebration of the life and poetry of the poet Robert Burns (25 January 175921 July 1796), the author of many Scots poems. The suppers are normally held on or near the poet's birthday, 25 January, occasionally known as Robert Burns Day (or Robbie Burns Day or Rabbie Burns Day) but more commonly known as Burns Night (). However, in principle, celebrations may be held at any other time of the year.

The first supper was held "in memoriam" at Burns Cottage by Burns's friends, on 21 July 1801, the fifth anniversary of his death; it has been a regular occurrence ever since. The first still extant Burns Club was founded in Greenock in 1801 by merchants who were born in Ayrshire, some of whom had known Burns. They held the first Burns supper on what they thought was his birthday, 29 January 1802, but in 1803, they discovered the Ayr parish records that noted his date of birth was actually 25 January 1759. Since then, suppers have been held on or about 25 January.

Burns suppers may be formal or informal. Both typically include haggis (a traditional Scottish dish celebrated by Burns in ""), Scotch whisky and the recitation of Burns's poetry. Formal dinners are hosted by organisations such as Burns clubs, the Freemasons or St Andrews Societies; they occasionally end with dancing when ladies are present. Formal suppers follow a standard order.

A piper generally greets the guests, who gather and mix as at any informal party. At less formal gatherings, traditional Scottish music is played.

The host says a few words welcoming everyone to the supper and perhaps stating the reason for it.

All the guests are seated and grace is said, usually using the "Selkirk Grace", a well-known thanksgiving said before meals that uses the Scots language. Although attributed to Burns, the Selkirk Grace was already known in the 17th century as the "Galloway Grace" or the "Covenanters' Grace". It came to be called the Selkirk Grace because Burns was said to have delivered it at a dinner given by the Earl of Selkirk.

The supper starts with the soup course. Normally, a Scottish soup, such as Scotch broth, potato soup, cullen skink, or cock-a-leekie, is served.

Everyone stands as the haggis is brought in. It is usually brought in by the cook on a large dish, generally while a piper plays the bagpipe and leads the way to the host's table, where the haggis is laid down. "A Man's A Man for A' That", "Robbie Burns Medley" or "The Star O' Robbie Burns" might be played. The host, or perhaps a guest, then recites the "

At the line "His knife see rustic Labour dicht", the speaker normally draws and sharpens a knife. At the line "An' cut you up wi' ready slicht", he plunges it into the haggis and cuts it open from end to end. When done properly, the "ceremony" is a highlight of the evening.

At the end of the poem, a whisky toast will be proposed to the haggis, and the company will sit down to the meal. The haggis is traditionally served with mashed potatoes (tatties) and mashed swede (neeps).

A dessert course, cheese courses, coffee, etc., may also be part of the meal. The courses normally use traditional Scottish recipes. For instance, dessert may be cranachan or tipsy laird (whisky trifle), followed by oatcakes and cheese, all washed down with the "water of life" (uisge beatha), Scotch whisky.

When the meal reaches the coffee stage, various speeches and toasts are given.

The main speaker gives a speech remembering some aspect of Burns's life or poetry. It may be either light-hearted or serious and may include the recitation of a poem or a song by Burns. A toast to the Immortal Memory of Robert Burns then follows.

This was originally a short speech given by a male guest in thanks to the women who had prepared the meal. However, it is now much more wide-ranging and generally covers the male speaker's view on women. It is normally amusing and not offensive, particularly since it will be followed by a reply from the "lassies" concerned. The men drink a toast to the women's health.

This is occasionally (and humorously) called the "Toast to the Laddies". Like the previous toast, it is generally now quite wide-ranging. A female guest will give her views on men and reply to any specific points raised by the previous speaker. Like the previous speech, it should be amusing but not offensive. Quite often, the speakers giving this toast and the previous one will collaborate so that the two toasts complement each other.

After the speeches there may be singing of songs by Burns (such as "Ae Fond Kiss", "Parcel o' Rogues" and "A Man's a Man") and more poetry (such as "To a Mouse", "To a Louse", "Tam o' Shanter", "The Twa Dogs" and "Holy Willie's Prayer").

That may be done by the individual guests or by invited experts, and it goes on for as long as the guests wish. It may include other works by poets influenced by Burns, particularly poets writing in Scots. Foreign guests may also be invited to sing or say works from their land.

Finally, the host will call on one of the guests to give the vote of thanks. Then, everyone is asked to stand, join hands, and sing " Auld Lang Syne" to bring the evening to an end.




</doc>
<doc id="5050" url="https://en.wikipedia.org/wiki?curid=5050" title="Bill Bryson">
Bill Bryson

William McGuire Bryson (; born 8 December 1951) is an Anglo-American author of books on travel, the English language, science, and other non-fiction topics. Born in the United States, he has been a resident of Britain for most of his adult life, returning to the United States between 1995 and 2003. He served as the chancellor of Durham University from 2005 to 2011.

Bryson came to prominence in the United Kingdom with the publication of "Notes from a Small Island" (1995), an exploration of Britain, and its accompanying television series. He received widespread recognition again with the publication of "A Short History of Nearly Everything" (2003), a book widely acclaimed for its accessible communication of science.

Bryson was born in Des Moines, Iowa, the son of Agnes Mary (née McGuire) and sports journalist Bill Bryson Sr. His mother was of Irish descent. He had an older brother, Michael (1942–2012), and a sister, Mary Jane Elizabeth. In 2006 Bryson published "The Life and Times of the Thunderbolt Kid", a humorous account of his childhood years in Des Moines.

Bryson attended Drake University for two years before dropping out in 1972, deciding instead to backpack around Europe for four months. He returned to Europe the following year with a high-school friend, Matt Angerer (the pseudonymous Stephen Katz). Bryson wrote about some of his experiences from this trip in his book "".

Bryson first visited Britain in 1973 during his tour of Europe and decided to stay after landing a job working in a psychiatric hospital—the now-defunct Holloway Sanatorium in Virginia Water, Surrey. He met a nurse there named Cynthia Billen, whom he married in 1975. They moved to Bryson's hometown of Des Moines, Iowa in 1975 so that Bryson could complete his college degree at Drake University. In 1977 they settled in Britain.

He worked as a journalist, first for the "Bournemouth Evening Echo" and eventually became chief copy editor of the business section of "The Times" and then deputy national news editor of the business section of "The Independent". He left journalism in 1987, three years after the birth of his third child. Bryson started writing independently and in 1990 their fourth child, Samuel, was born.

He has moved around the UK and lived in Virginia Water (Surrey), Purewell (Dorset), Burton (Dorset), Kirkby Malham (North Yorkshire, in the 1980s and '90s), and the Old Rectory in Wramplingham, Norfolk (2003–2013). He currently lives in rural Hampshire and maintains a small flat in South Kensington, London. From 1995 to 2003 he lived in Hanover, New Hampshire, USA.

Although able to apply for British citizenship, Bryson said in 2010 that he had declined a citizenship test, declaring himself "too cowardly" to take it. However, in 2014, he said that he was preparing to take it and in the prologue to his 2015 book "" he describes doing so, in Eastleigh. His citizenship ceremony took place in Winchester and he now holds dual citizenship.

While living in the US in the 1990s Bryson wrote a column for a British newspaper for several years, reflecting on humorous aspects of his repatriation in the United States. These columns were selected and adapted to become his book "I'm a Stranger Here Myself", alternatively titled "Notes from a Big Country" in Britain, Canada, and Australia. During his time in the United States, Bryson decided to walk the Appalachian Trail with his friend Stephen Katz (a pseudonym), about which he wrote the book "A Walk in the Woods". In the 2015 film adaptation of "A Walk in the Woods", Bryson is portrayed by Academy Award winner Robert Redford and Katz is portrayed by Nick Nolte (Bryson is portrayed as being much older than he was at the time of his actual walk).

In 2003, in conjunction with World Book Day, British voters chose Bryson's book "Notes from a Small Island" as that which best sums up British identity and the state of the nation. In the same year, he was appointed a Commissioner for English Heritage.

His popular science book, "A Short History of Nearly Everything" is 500 pages long and explores not only the histories and current statuses of the sciences, but also reveals their humble and often humorous beginnings. Although one "top scientist" is alleged to have jokingly described the book as "annoyingly free of mistakes", Bryson himself makes no such claim and a list of some reported errors in the book is available online.

In November 2006, Bryson interviewed the then British prime minister, Tony Blair, on the state of science and education.

Bryson has also written two popular works on the history of the English language — "The Mother Tongue" and "Made in America" — and, more recently, an update of his guide to usage, "Bryson's Dictionary of Troublesome Words" (published in its first edition as "The Penguin Dictionary of Troublesome Words" in 1983).

In 2012 Bryson sued his agent, Jed Mattes Inc., in New York County Supreme Court, claiming they had "failed to perform some of the most fundamental duties of an agent". The case was settled out of court, with part of the settlement being that Bryson not discuss it.

In 2005 Bryson was appointed chancellor of Durham University, succeeding the late Sir Peter Ustinov, and became more active with student activities than is common for holders of that post, even appearing in a Durham student film and promoting litter picks in the city. He had praised Durham as "a perfect little city" in "Notes from a Small Island". In October 2010, it was announced that Bryson would step down at the end of 2011.

In May 2007, he became the president of the Campaign to Protect Rural England. His first area of focus in this role was the establishment of an anti-littering campaign across England. He discussed the future of the countryside with Richard Mabey, Sue Clifford, Nicholas Crane and Richard Girling at CPRE's Volunteer Conference in November 2007.

Bryson has received numerous awards for his ability to communicate science with passion and enthusiasm. In 2004, he won the prestigious Aventis Prize for best general science book that year, with "A Short History of Nearly Everything". In 2005, the book won the EU Descartes Prize for science communication. In 2005 he received the President's Award from the Royal Society of Chemistry for advancing the cause of the chemical sciences. In 2007, he won the Bradford Washburn Award from the Museum of Science in Boston, MA for contributions to the popularization of science. In 2012, he received the Kenneth B. Myer Award from the Florey Institute of Neuroscience in Melbourne, Australia.

With the Royal Society of Chemistry the Bill Bryson prize for Science Communication was established in 2005.

He was awarded an honorary Officer of the Order of the British Empire (OBE) for his contribution to literature on 13 December 2006. The following year, he was awarded the James Joyce Award by the Literary and Historical Society of University College Dublin. After he received British citizenship his OBE was made substantive.

In 2011 he won the Golden Eagle Award from the Outdoor Writers and Photographers Guild. On 22 November 2012, Durham University officially renamed the Main Library the Bill Bryson Library for his contributions as the university's 11th chancellor (2005–11).

Bryson was elected an Honorary Fellow of the Royal Society (FRS) in 2013, becoming the first non-Briton upon whom this honour has been conferred. His biography at the Society reads: "Bill Bryson is a popular author who is driven by a deep curiosity for the world we live in. Bill's books and lectures demonstrate an abiding love for science and an appreciation for its social importance. His international bestseller, "A Short History of Nearly Everything" (2003), is widely acclaimed for its accessible communication of science and has since been adapted for children."

In 2006 Frank Cownie, the mayor of Des Moines, awarded Bryson the key to the city and announced that October 21, 2006 would be known as "Bill Bryson, The Thunderbolt Kid, Day".

In January 2007, he was the Schwartz Visiting Fellow at the Pomfret School in Connecticut.



Bryson has written the following books:


 
 


</doc>
<doc id="5051" url="https://en.wikipedia.org/wiki?curid=5051" title="Big Audio Dynamite">
Big Audio Dynamite

Big Audio Dynamite (later known as Big Audio Dynamite II and Big Audio, and often abbreviated BAD) are a British musical group formed in 1984 by the ex-guitarist and singer of The Clash, Mick Jones. The group is noted for its effective mixture of varied musical styles, incorporating elements of punk rock, dance music, hip hop, reggae, and funk. BAD's one constant throughout frequent shifts in membership and musical direction is the vocals provided by Mick Jones. After releasing a number of well-received albums and touring extensively throughout the 1980s and 1990s, Big Audio Dynamite disbanded in 1997. In 2011, the band embarked on a reunion tour.

After being ousted from the Clash in 1983 and following a brief stint with the band General Public, Mick Jones formed a new band called Top Risk Action Company (T.R.A.C.). He recruited bassist Leo "E-Zee Kill" Williams, saxophone player John "Boy" Lennard (from Theatre of Hate), and ex-Clash drummer Nicky "Topper" Headon. Headon was quickly sacked for his heroin addiction and Lennard either left or was fired and the band folded. Although the band released no material (only demos were recorded which have yet to be officially released), T.R.A.C. can be seen as a forerunner to Big Audio Dynamite in much the same way London SS can be seen as an early incarnation of the Clash.

Jones then formed Big Audio Dynamite with film director Don Letts (maker of "The Punk Rock Movie", various Clash music videos, and later the Clash documentary "Westway to the World"), bassist Leo Williams (from T.R.A.C.), drummer Greg Roberts, and keyboardist Dan Donovan. In 1985 the group's debut, "This Is Big Audio Dynamite," was released. The album's cover shows the group as a four-piece (minus Donovan). In 2016 "This is Big Audio Dynamite" was reissued for the first time, with the album mastered using analog tapes and pressing it on 180-gram vinyl.
1986's "No. 10, Upping St." reunited Jones for one album with former Clash bandmate Joe Strummer, who was a co-producer of the album and co-writer of a number of its songs. The cover painting, based on a still taken from the Brian de Palma film "Scarface," was painted by Tim Jones. BAD supported U2 on their 1987 world tour, then released 1988's "Tighten Up, Vol. '88" and 1989's "Megatop Phoenix". "Tighten Up, Vol. 88" contained "Just Play Music!", which was the second No. 1 single on Billboard's Modern Rock Tracks. The band also recorded an unreleased track called "Keep off the Grass" which was a rock-style instrumental of the theme to the classic western film, "The Magnificent Seven". A promo video can be seen on YouTube.

In 1990, the original line-up wrote and recorded the song "Free" for the soundtrack to the movie "Flashback". This would be the final song written with the original lineup, as the band would dissolve shortly after. "Bottom Line" from the first LP was remixed and used as the title track for "Flashback". However this track was not included on the soundtrack. It can be found on the 12" or by download. Later in 1990, Mick Jones debuted Big Audio Dynamite II and release the UK only album "Kool-Aid". Dan Donovan remained in BAD II for one song, a re-working of the final BAD track "Free" renamed "Kickin' In".

For 1990's "The Globe", only Jones remained from BAD, and the band was now called "Big Audio Dynamite II". This new line-up featured two guitarists. "The Globe" featured the band's most commercially successful single, "Rush," which hit No. 1 on both the US modern rock chart and the Australian National Aria Chart. "Innocent Child" and "The Globe" were also released as singles.

BAD supported U2 on their ZOOTV Tour and released the live EP "On The Road Live '92".

The band later recruited keyboardist Andre Shapps (co-producer of "The Globe" and Mick Jones's cousin) and Michael "DJ Zonka" Custance as DJ and vocalist. Both appeared on the band's 1994 album "Higher Power", which was released under the shortened name "Big Audio".

After signing with Gary Kurfirst's Radioactive Records in 1995, the band reverted to the original "Big Audio Dynamite" moniker and released their least successful album to date, "F-Punk".

Radioactive Records refused to release the next proposed BAD album, "Entering a New Ride". The line-up contained Mc vocals by Joe Attard (Punks Jump Up), Ranking Roger (The Beat, General Public) and drummer Bob Wond (Under Two Flags) In 1998, the band launched a new web site, primarily as a means to distribute songs from the "Entering a New Ride" album.

Since 2005, Jones has been working on a project with Tony James (ex-member of Generation X and Sigue Sigue Sputnik) called Carbon/Silicon.

In early 2007, a BAD II live DVD was released.

In April 2010, Don Letts revealed to Billboard.com that he and Mick Jones broached the idea of a Big Audio Dynamite reunion in 2011. He explained, "I could lie to you and say 'Not in a million years,' but... if Mick wasn't tied up with Gorillaz it might happen this year. (Jones) has looked at me and said, 'Maybe next year,' but who knows. I've got to admit that in the past I'm not a great one for reformations; I always think if you're lucky in life, you get a window of opportunity, use it to the best of your ability and then fuck off and let someone else have their turn. But here I am 25 years down the line considering the thing." Besides a Big Audio Dynamite reunion, Letts said he was also hopeful for more Legacy Editions of the group's albums after finding more unreleased material—including live recordings—in the vaults. "There's definitely more stuff; whether Sony thinks it's worthwhile, that's another matter. But there seems to be a lot of respect for Big Audio Dynamite. Time has shown that a lot of the things we were dabbling in back then have come to manifest themselves today...so hopefully we'll get to do some more."

The reformation of the original line-up of B.A.D was confirmed on 25 January 2011 with the announcement of a UK tour. The 9-date tour was a commercial and critical success. The first of their two sold out Shepherd's Bush Empire shows received a 4 star review in "The Times" ('Not just a reformation - this is "their" time'), "The Observer" welcomed B.A.D's return with a glowing review declaring, 'they remain a joy'. "News Of The World" awarded their Manchester Academy show a 5 star review and proclaimed, 'Easily the reformation of the year'. Their headline slot at Beautiful Days festival was favourably reviewed on the Louder Than War music website.

Big Audio Dynamite played sets at the 2011 Outside Lands Music and Arts Festival, Coachella Valley Music and Arts Festival, Glastonbury Festival 2011, and Lollapalooza.

Big Audio Dynamite (1984–1990, 2011–present)

Big Audio Dynamite II (1990–1993)

Big Audio (1994–1995)

Big Audio Dynamite (1996–1998)




</doc>
<doc id="5052" url="https://en.wikipedia.org/wiki?curid=5052" title="Bentley">
Bentley

Bentley Motors Limited () is a British manufacturer and marketer of luxury cars and SUVs—and a subsidiary of Volkswagen AG since 1998.

Headquartered in Crewe, England, the company was founded as Bentley Motors Limited by W. O. Bentley in 1919 in Cricklewood, North London—and became widely known for winning the 24 Hours of Le Mans in 1924, 1927, 1928, 1929, 1930, and 2003.

Prominent models extend from the historic sports-racing Bentley 4½ Litre and Bentley Speed Six; the more recent Bentley R Type Continental, Bentley Turbo R, and Bentley Arnage; to its current model line—including the Continental Flying Spur, Continental GT, Bentley Bentayga and the Mulsanne—which are marketed worldwide, with China as its largest market as of November 2012.

Today most Bentleys are assembled at the company's Crewe factory, with a small number assembled at Volkswagen's Dresden factory, Germany, and with bodies for the Continental manufactured in Zwickau and for the Bentayga manufactured at the Volkswagen Bratislava Plant.

The joining and eventual separation of Bentley and Rolls-Royce followed a series of mergers and acquisitions, beginning with the 1931 purchase by Rolls-Royce of Bentley, then in receivership. In 1971, Rolls-Royce itself was forced into receivership and the UK government nationalised the company—splitting into two companies the aerospace division (Rolls-Royce Plc) and automotive (Rolls-Royce Motors Limited) divisions—the latter retaining the Bentley subdivision. Rolls-Royce Motors was subsequently sold to engineering conglomerate, Vickers and in 1998, Vickers sold Rolls-Royce to Volkswagen AG.

Intellectual property rights to both the name "Rolls-Royce" as well as the company's logo had been retained not by Rolls-Royce Motors, but by aerospace company, Rolls-Royce Plc, which had continued to license both to the automotive division. Thus the sale of "Rolls-Royce" to VW included the Bentley name and logos, vehicle designs, model nameplates, production and administrative facilities, the Spirit of Ecstasy and Rolls-Royce grille shape trademarks (subsequently sold to BMW by VW)—but not the rights to the Rolls-Royce name or logo. The aerospace company, Rolls-Royce Plc, ultimately sold both to BMW AG.

Before World War I, Walter Owen Bentley and his brother, Horace Millner Bentley, sold French DFP cars in Cricklewood, North London, but W.O, as Walter was known, always wanted to design and build his own cars. At the DFP factory, in 1913, he noticed an aluminium paperweight and thought that aluminium might be a suitable replacement for cast iron to fabricate lighter pistons. The first Bentley aluminium pistons were fitted to Sopwith Camel aero engines during World War I.

In August 1919, W.O. registered Bentley Motors Ltd. and in October he exhibited a car chassis, with dummy engine, at the London Motor Show. Ex–Royal Flying Corps officer Clive Gallop designed an innovative four valves per cylinder engine for the chassis. By December the engine was built and running. Delivery of the first cars was scheduled for June 1920, but development took longer than estimated so the date was extended to September 1921. The durability of the first Bentley cars earned widespread acclaim and they competed in hill climbs and raced at Brooklands.

Bentley's first major event was the 1922 Indianapolis 500, a race dominated by specialized cars with Duesenberg racing chassis. They entered a modified road car driven by works driver, Douglas Hawkes, accompanied by riding mechanic, H. S. "Bertie" Browning. Hawkes completed the full and finished 13th with an average speed of after starting in 19th position. The team was then rushed back to England to compete in the 1922 RAC Tourist Trophy.

In an ironic reference to his heavyweight boxer's stature, Captain Woolf Barnato was nicknamed "Babe". In 1925, he acquired his first Bentley, a 3-litre. With this car he won numerous Brooklands races. Just a year later he acquired the Bentley business itself.

The Bentley enterprise was always underfunded, but inspired by the 1924 Le Mans win by John Duff and Frank Clement, Barnato agreed to finance Bentley's business. Barnato had incorporated Baromans Ltd in 1922, which existed as his finance and investment vehicle. Via Baromans, Barnato initially invested in excess of £100,000, saving the business and its workforce. A financial reorganisation of the original Bentley company was carried out and all existing creditors paid off for £75,000. Existing shares were devalued from £1 each to just 1 shilling, or 5% or their original value. Barnato held 149,500 of the new shares giving him control of the company and he became chairman. Barnato injected further cash into the business: £35,000 secured by debenture in July 1927; £40,000 in 1928; £25,000 in 1929. With renewed financial input, W. O. Bentley was able to design another generation of cars.

The Bentley Boys were a group of British motoring enthusiasts that included Barnato, Sir Henry "Tim" Birkin, steeple chaser George Duller, aviator Glen Kidston, automotive journalist S.C.H. "Sammy" Davis, and Dudley Benjafield. The Bentley Boys favoured Bentley cars. Many were independently wealthy and many had a military background. They kept the marque's reputation for high performance alive; Bentley was noted for its four consecutive victories at the 24 Hours of Le Mans, from 1927 to 1930.

In 1929, Birkin developed the 4½-litre, lightweight Blower Bentley at Welwyn Garden City and produced five racing specials, starting with Bentley Blower No.1 which was optimised for the Brooklands racing circuit. Birkin overruled Bentley and put the model on the market before it was fully developed. As a result, it was unreliable.

In March 1930, during the Blue Train Races, Barnato raised the stakes on Rover and its Rover Light Six, having raced and beaten "Le Train Bleu" for the first time, to better that record with his 6½-litre Bentley Speed Six on a bet of £100. He drove against the train from Cannes to Calais, then by ferry to Dover, and finally London, travelling on public highways, and won.

Barnato drove his H.J. Mulliner–bodied formal saloon in the race against the Blue Train. Two months later, on 21 May 1930, he took delivery of a Speed Six with streamlined fastback "sportsman coupé" by Gurney Nutting. Both cars became known as the "Blue Train Bentleys"; the latter is regularly mistaken for, or erroneously referred to as being, the car that raced the Blue Train, while in fact Barnato named it in memory of his race. A painting by Terence Cuneo depicts the Gurney Nutting coupé racing along a road parallel to the Blue Train, which scenario never occurred as the road and railway did not follow the same route.


The original model was the three-litre, but as customers put heavier bodies on the chassis, a larger 4½-litre model followed. Perhaps the most iconic model of the period is the 4½-litre "Blower Bentley", with its distinctive supercharger projecting forward from the bottom of the grille. Uncharacteristically fragile for a Bentley it was not the racing workhorse the 6½-litre was, though in 1930 Birkin remarkably finished second in the French Grand Prix at Pau in a stripped-down racing version of the Blower Bentley, behind Philippe Etancelin in a Bugatti Type 35.

The 4½-litre model later became famous in popular media as the vehicle of choice of James Bond in the original novels, but this has been seen only briefly in the films. John Steed in the television series "The Avengers" also drove a Bentley.

The new eight-litre was such a success that when Barnato's money seemed to run out in 1931 and Napier was planning to buy Bentley's business, Rolls-Royce purchased Bentley Motors to prevent it from competing with their most expensive model, the Phantom II.


Bentley withdrew from motor racing just after winning at Le Mans in 1930, claiming that they had learned enough about speed and reliability.

The Wall Street Crash of 1929 and the resulting Great Depression throttled the demand for Bentley's expensive motor cars. In July 1931, two mortgage payments were due which neither the company nor Barnato, the guarantor, were able to meet. On 10 July 1931 a receiver was appointed.

Napier offered to buy Bentley with the purchase to be final in November 1931. Instead, British Central Equitable Trust made a winning sealed bid of £125,000. British Central Equitable Trust later proved to be a front for Rolls-Royce Limited. Not even Bentley himself knew the identity of the purchaser until the deal was completed.

Barnato received £42,000 for his shares in Bentley Motors. In 1934 he was appointed to the board of the new Bentley Motors (1931) Ltd. In the same year Bentley confirmed that it would continue racing.

Rolls-Royce took over the assets of Bentley Motors (1919) Ltd and formed a subsidiary, Bentley Motors (1931) Ltd. Rolls-Royce had acquired the Bentley showrooms in Cork Street, the service station at Kingsbury, the complex at Cricklewood and the services of Bentley himself. This last was disputed by Napier in court without success. Bentley had neglected to register their trademark so Rolls-Royce immediately did so. They also sold the Cricklewood factory in 1932. Production stopped for two years, before resuming at the Rolls-Royce works in Derby. Unhappy with his role at Rolls-Royce, when his contract expired at the end of April 1935 W. O. Bentley left to join Lagonda.

When the new Bentley 3½ litre appeared in 1933, it was a sporting variant of the Rolls-Royce 20/25, which disappointed some traditional customers yet was well received by many others. W. O. Bentley was reported as saying, "Taking all things into consideration, I would rather own this Bentley than any other car produced under that name". Rolls-Royce's advertisements for the  Litre called it "the silent sports car", a slogan Rolls-Royce continued to use for Bentley cars until the 1950s.

All Bentleys produced from 1931 to 2004 used inherited or shared Rolls-Royce chassis, and adapted Rolls-Royce engines, and are described by critics as badge-engineered Rolls-Royces.


In preparation for war, Rolls-Royce and the British Government searched for a location for a shadow factory to ensure production of aero-engines. Crewe, with its excellent road and rail links, as well as being located in the northwest away from the aerial bombing starting in mainland Europe, was a logical choice. Crewe also had extensive open farming land. Construction of the factory started on a 60-acre area on the potato fields of Merrill's Farm in July 1938, with the first Rolls-Royce Merlin aero-engine rolling off the production line five months later. 25,000 Merlin engines were produced and at its peak, in 1943 during World War II, the factory employed 10,000 people. With the war in Europe over and the general move towards the then new jet engines, Rolls-Royce concentrated its aero engine operations at Derby and moved motor car operations to Crewe.

Until some time after World War II, most high-end motorcar manufacturers like Bentley and Rolls-Royce did not supply complete cars. They sold rolling chassis, near-complete from the instrument panel forward. Each chassis was delivered to the coach builder of the buyer's choice. The biggest specialist car dealerships had coachbuilders build standard designs for them which were held in stock awaiting potential buyers.
To meet post-war demand, particularly UK Government pressure to export and earn overseas currency, Rolls-Royce developed an all steel body using pressings made by Pressed Steel to create a "standard" ready-to-drive complete saloon car. The first steel-bodied model produced was the Bentley Mark VI: these started to emerge from the newly reconfigured Crewe factory early in 1946. Some years later, initially only for export, the Rolls-Royce Silver Dawn was introduced, a standard steel Bentley but with a Rolls-Royce radiator grille for a small extra charge, and this convention continued.

Chassis remained available to coachbuilders until the end of production of the Bentley S3, which was replaced for October 1965 by the chassis-less monocoque construction T series.

The Continental fastback coupé was aimed at the UK market, most cars, 164 plus a prototype, being right-hand drive. The chassis was produced at the Crewe factory and shared many components with the standard R type. Other than the R-Type standard steel saloon, R-Type Continentals were delivered as rolling chassis to the coachbuilder of choice. Coachwork for most of these cars was completed by H. J. Mulliner & Co. who mainly built them in fastback coupe form. Other coachwork came from Park Ward (London) who built six, later including a drophead coupe version. Franay (Paris) built five, Graber (Wichtrach, Switzerland) built three, one of them later altered by Köng (Basel, Switzerland), and Pininfarina made one. James Young (London) built in 1954 a Sports Saloon for the owner of James Young's, James Barclay.

The early R Type Continental has essentially the same engine as the standard R Type, but with modified carburation, induction and exhaust manifolds along with higher gear ratios. After July 1954 the car was fitted with an engine, having now a larger bore of 94.62 mm (3.7 in) with a total displacement of . The compression ratio was raised to 7.25:1.

The problems of Bentley's owner with Rolls-Royce aero engine development, the RB211, brought about the financial collapse of its business in 1970.

The motorcar division was made a separate business, Rolls-Royce Motors Limited, which remained independent until bought by Vickers plc in August 1980. By the 1970s and early 1980s Bentley sales had fallen badly; at one point less than 5% of combined production carried the Bentley badge. Under Vickers, Bentley set about regaining its high-performance heritage, typified by the 1980 Mulsanne. Bentley's restored sporting image created a renewed interest in the name and Bentley sales as a proportion of output began to rise. By 1986 the Bentley:Rolls-Royce ratio had reached 40:60; by 1991 it achieved parity.


In October 1997, Vickers announced that it had decided to sell Rolls-Royce Motors. BMW AG seemed to be a logical purchaser because BMW already supplied engines and other components for Bentley and Rolls-Royce branded cars and because of BMW and Vickers joint efforts in building aircraft engines. BMW made a final offer of £340m, but was outbid by Volkswagen AG, which offered £430m. Volkswagen AG acquired the vehicle designs, model nameplates, production and administrative facilities, the Spirit of Ecstasy and Rolls-Royce grille shape trademarks, but not the rights to the use of the Rolls-Royce name or logo, which are owned by Rolls-Royce Holdings plc. In 1998, BMW started supplying components for the new range of Rolls-Royce and Bentley cars—notably V8 engines for the Bentley Arnage and V12 engines for the Rolls-Royce Silver Seraph, however, the supply contract allowed BMW to terminate its supply deal with Rolls-Royce with 12 months' notice, which would not be enough time for Volkswagen to re-engineer the cars.
BMW paid Rolls-Royce plc £40m to license the Rolls-Royce name and logo. After negotiations, BMW and Volkswagen AG agreed that, from 1998 to 2002, BMW would continue to supply engines and components and would allow Volkswagen temporary use of the Rolls-Royce name and logo. All BMW engine supply ended in 2003 with the end of Silver Seraph production.

From 1 January 2003 forward, Volkswagen AG would be the sole provider of cars with the "Bentley" marque. BMW established a new legal entity, Rolls-Royce Motor Cars Limited, and built a new administrative headquarters and production facility for Rolls-Royce branded vehicles in Goodwood, West Sussex, England.

After acquiring the business, Volkswagen spent GBP500 million (about US$845 million) to modernise the Crewe factory and increase production capacity.
As of early 2010, there are about 3,500 working at Crewe, compared with about 1,500 in 1998 before being taken over by Volkswagen. It was reported that Volkswagen invested a total of nearly US$2 billion in Bentley and its revival. As a result of upgrading facilities at Crewe the bodywork now arrives fully painted at the Crewe facility for final assembly, with the parts coming from Germany—similarly Rolls-Royce body shells are painted and shipped to the UK for assembly only.

In 2002, Bentley presented Queen Elizabeth II with an official State Limousine to celebrate her Golden Jubilee. In 2003, Bentley's two-door convertible, the Bentley Azure, ceased production, and Bentley introduced a second line, Bentley Continental GT, a large luxury coupé powered by a W12 engine built in Crewe.

Demand had been so great that the factory at Crewe was unable to meet orders despite an installed capacity of approximately 9,500 vehicles per year; there was a waiting list of over a year for new cars to be delivered. Consequently, part of the production of the new Flying Spur, a four-door version of the Continental GT, was assigned to the Transparent Factory (Germany), where the Volkswagen Phaeton luxury car is also assembled. This arrangement ceased at the end of 2006 after around 1,000 cars, with all car production reverting to the Crewe plant.

In April 2005, Bentley confirmed plans to produce a four-seat convertible model—the Azure, derived from the Arnage Drophead Coupé prototype—at Crewe beginning in 2006. By the autumn of 2005, the convertible version of the successful Continental GT, the Continental GTC, was also presented. These two models were successfully launched in late 2006.

A limited run of a Zagato modified GT was also announced in March 2008, dubbed "GTZ".

A new version of the Bentley Continental was introduced at the 2009 Geneva Auto Show: The Continental Supersports. This new Bentley is a supercar combining extreme power with environmentally friendly FlexFuel technology, capable of using petrol (gasoline) and biofuel (E85 ethanol).

Bentley sales continued to increase, and in 2005 8,627 were sold worldwide, 3,654 in the United States. In 2007, the 10,000 cars-per-year threshold was broken for the first time with sales of 10,014. For 2007, a record profit of €155 million was also announced. Bentley reported a sale of about 7,600 units in 2008. However, its global sales plunged 50 percent to 4,616 vehicles in 2009 (with the U.S. deliveries dropped 49% to 1,433 vehicles) and it suffered an operating loss of €194 million, compared with an operating profit of €10 million in 2008. As a result of the slump in sales, production at Crewe was shut down during March and April 2009. Though vehicle sales increased by 11% to 5,117 in 2010, operating loss grew by 26% to €245 million. In Autumn 2010, workers at Crewe staged a series of protests over proposal of compulsory work on Fridays and mandatory overtime during the week.

Vehicle sales in 2011 rose 37% to 7,003 vehicles, with the new Continental GT accounting for over one-third of total sales. The current workforce is about 4,000 people.

The business earned a profit in 2011 after two years of losses as a result of the following sales results:

Sources 

Sources 

Unsold cars: During the years 2011 and 2012 production exceeded deliveries by 1,187 cars which is estimated to have trebled inventory.




A Bentley Continental GT3 entered by the M-Sport factory team won the Silverstone round of the 2014 Blancpain Endurance Series. This was Bentley's first official entry in a British race since the 1930 RAC Tourist Trophy.





</doc>
<doc id="5131" url="https://en.wikipedia.org/wiki?curid=5131" title="Chordate">
Chordate

A chordate is an animal belonging to the phylum Chordata; chordates possess a notochord, a hollow dorsal nerve cord, pharyngeal slits, an endostyle, and a post-anal tail, for at least some period of their life cycle. Chordates are deuterostomes, as during the embryo development stage the anus forms before the mouth. They are also bilaterally symmetric coelomates with metameric segmentation and a circulatory system. In the case of vertebrate chordates, the notochord is usually replaced by a vertebral column during development.

Taxonomically, the phylum includes the following subphyla: the Vertebrata, which includes fish, amphibians, reptiles, birds, and mammals; the Tunicata, which includes salps and sea squirts; and the Cephalochordata, which include the lancelets. There are also additional extinct taxa such as the Vetulicolia. The Vertebrata are sometimes considered as a subgroup of the clade Craniata, consisting of chordates with a skull; the Craniata and Tunicata compose the clade Olfactores.

Of the more than 65,000 living species of chordates, about half are bony fish of the superclass Osteichthyes. The world's largest and fastest animals, the blue whale and peregrine falcon respectively, are chordates, as are humans. Fossil chordates are known from at least as early as the Cambrian explosion.

Hemichordata, which includes the acorn worms, has been presented as a fourth chordate subphylum, but it now is usually treated as a separate phylum. The Hemichordata, along with the Echinodermata (which includes starfish, sea urchins, sea cucumbers, and crinoids), form the Ambulacraria, the sister taxon of the Chordates. The Chordata and Ambulacraria form the superphylum Deuterostomia, composed of the deuterostomes.

Attempts to work out the evolutionary relationships of the chordates have produced several hypotheses. The current consensus is that chordates are monophyletic, meaning that the Chordata include all and only the descendants of a single common ancestor, which is itself a chordate, and that craniates' nearest relatives are tunicates.

All of the earliest chordate fossils have been found in the Early Cambrian Chengjiang fauna, and include two species that are regarded as fish, which implies that they are vertebrates. Because the fossil record of early chordates is poor, only molecular phylogenetics offers a reasonable prospect of dating their emergence. However, the use of molecular phylogenetics for dating evolutionary transitions is controversial.

It has also proved difficult to produce a detailed classification within the living chordates. Attempts to produce evolutionary "family trees" shows that many of the traditional classes are paraphyletic.

While this has been well known since the 19th century, an insistence on only monophyletic taxa has resulted in vertebrate classification being in a state of flux.

Although the name Chordata is attributed to William Bateson (1885), it was already in prevalent use by 1880. Ernst Haeckel described a taxon comprising tunicates, cephalochordates, and vertebrates in 1866. Though he used the German vernacular form, it is allowed under the ICZN code because of its subsequent latinization.

Chordates form a phylum of animals that are defined by having at some stage in their lives all of the following:


There are soft constraints that separate chordates from certain other biological lineages, but have not yet been made part of the formal definition:


There is still much ongoing differential (DNA sequence based) comparison research that is trying to separate out the simplest forms of chordates. As some lineages of the 90% of species that lack a backbone or notochord might have lost these structures over time, this complicates the classification of chordates. Some chordate lineages may only be found by DNA analysis, when there is no physical trace of any chordate-like structures.

Craniates, one of the three subdivisions of chordates, all have distinct skulls. They include the hagfish which have no vertebrae. Michael J. Benton commented that "craniates are characterized by their heads, just as chordates, or possibly all deuterostomes, are by their tails".

Most are vertebrates, in which the notochord is replaced by the vertebral column. These consist of a series of bony or cartilaginous cylindrical vertebrae, generally with neural arches that protect the spinal cord, and with projections that link the vertebrae. However hagfish have incomplete braincases and no vertebrae, and are therefore not regarded as vertebrates,
but as members of the craniates, the group from which vertebrates are thought to have evolved. However the cladistic exclusion of hagfish from the vertebrates is controversial, as they may be degenerate vertebrates who have lost their vertebral columns.

The position of lampreys is ambiguous. They have complete braincases and rudimentary vertebrae, and therefore may be regarded as vertebrates and true fish. However, molecular phylogenetics, which uses biochemical features to classify organisms, has produced both results that group them with vertebrates and others that group them with hagfish. If lampreys are more closely related to the hagfish than the other vertebrates, this would suggest that they form a clade, which has been named the Cyclostomata.

Most tunicates appear as adults in two major forms, both of which are soft-bodied filter-feeders that lack the standard features of chordates: "sea squirts" are sessile and consist mainly of water pumps and filter-feeding apparatus; salps float in mid-water, feeding on plankton, and have a two-generation cycle in which one generation is solitary and the next forms chain-like colonies. However, all tunicate larvae have the standard chordate features, including long, tadpole-like tails; they also have rudimentary brains, light sensors and tilt sensors. The third main group of tunicates, Appendicularia (also known as Larvacea) retain tadpole-like shapes and active swimming all their lives, and were for a long time regarded as larvae of sea squirts or salps. The etymology of the term Urochorda(ta) (Balfour 1881) is from the ancient Greek οὐρά (oura, "tail") + Latin chorda ("cord"), because the notochord is only found in the tail. The term Tunicata (Lamarck 1816) is recognised as having precedence and is now more commonly used.

Cephalochordates are small, "vaguely fish-shaped" animals that lack brains, clearly defined heads and specialized sense organs. These burrowing filter-feeders compose the earliest-branching chordate sub-phylum.

The majority of animals more complex than jellyfish and other Cnidarians are split into two groups, the protostomes and deuterostomes, the latter of which contains chordates. It seems very likely the "Kimberella" was a member of the protostomes. If so, this means the protostome and deuterostome lineages must have split some time before "Kimberella" appeared—at least , and hence well before the start of the Cambrian . The Ediacaran fossil "Ernietta", from about , may represent a deuterostome animal.
Fossils of one major deuterostome group, the echinoderms (whose modern members include starfish, sea urchins and crinoids), are quite common from the start of the Cambrian, . The Mid Cambrian fossil "Rhabdotubus johanssoni" has been interpreted as a pterobranch hemichordate. Opinions differ about whether the Chengjiang fauna fossil "Yunnanozoon", from the earlier Cambrian, was a hemichordate or chordate. Another fossil, "Haikouella lanceolata", also from the Chengjiang fauna, is interpreted as a chordate and possibly a craniate, as it shows signs of a heart, arteries, gill filaments, a tail, a neural chord with a brain at the front end, and possibly eyes—although it also had short tentacles round its mouth. "Haikouichthys" and "Myllokunmingia", also from the Chengjiang fauna, are regarded as fish. "Pikaia", discovered much earlier (1911) but from the Mid Cambrian Burgess Shale (505 Ma), is also regarded as a primitive chordate. On the other hand, fossils of early chordates are very rare, since invertebrate chordates have no bones or teeth, and only one has been reported for the rest of the Cambrian.
The evolutionary relationships between the chordate groups and between chordates as a whole and their closest deuterostome relatives have been debated since 1890. Studies based on anatomical, embryological, and paleontological data have produced different "family trees". Some closely linked chordates and hemichordates, but that idea is now rejected. Combining such analyses with data from a small set of ribosome RNA genes eliminated some older ideas, but opened up the possibility that tunicates (urochordates) are "basal deuterostomes", surviving members of the group from which echinoderms, hemichordates and chordates evolved. Some researchers believe that, within the chordates, craniates are most closely related to cephalochordates, but there are also reasons for regarding tunicates (urochordates) as craniates' closest relatives.

Since early chordates have left a poor fossil record, attempts have been made to calculate the key dates in their evolution by molecular phylogenetics techniques—by analyzing biochemical differences, mainly in RNA. One such study suggested that deuterostomes arose before and the earliest chordates around . However, molecular estimates of dates often disagree with each other and with the fossil record, and their assumption that the molecular clock runs at a known constant rate has been challenged.

Traditionally, Cephalochordata and Craniata were grouped into the proposed clade "Euchordata", which would have been the sister group to Tunicata/Urochordata. More recently, Cephalochordata has been thought of as a sister group to the "Olfactores", which includes the craniates and tunicates. The matter is not yet settled.

The following schema is from the third edition of "Vertebrate Palaeontology". The invertebrate chordate classes are from Fishes of the World. While it is structured so as to reflect evolutionary relationships (similar to a cladogram), it also retains the traditional ranks used in Linnaean taxonomy.


Hemichordates ("half (½) chordates") have some features similar to those of chordates: branchial openings that open into the pharynx and look rather like gill slits; stomochords, similar in composition to notochords, but running in a circle round the "collar", which is ahead of the mouth; and a dorsal nerve cord—but also a smaller ventral nerve cord.

There are two living groups of hemichordates. The solitary enteropneusts, commonly known as "acorn worms", have long proboscises and worm-like bodies with up to 200 branchial slits, are up to long, and burrow though seafloor sediments. Pterobranchs are colonial animals, often less than long individually, whose dwellings are interconnected. Each filter feeds by means of a pair of branched tentacles, and has a short, shield-shaped proboscis. The extinct graptolites, colonial animals whose fossils look like tiny hacksaw blades, lived in tubes similar to those of pterobranchs.

Echinoderms differ from chordates and their other relatives in three conspicuous ways: they possess bilateral symmetry only as larvae - in adulthood they have radial symmetry, meaning that their body pattern is shaped like a wheel; they have tube feet; and their bodies are supported by skeletons made of calcite, a material not used by chordates. Their hard, calcified shells keep their bodies well protected from the environment, and these skeletons enclose their bodies, but are also covered by thin skins. The feet are powered by another unique feature of echinoderms, a water vascular system of canals that also functions as a "lung" and surrounded by muscles that act as pumps. Crinoids look rather like flowers, and use their feather-like arms to filter food particles out of the water; most live anchored to rocks, but a few can move very slowly. Other echinoderms are mobile and take a variety of body shapes, for example starfish, sea urchins and sea cucumbers.




</doc>
<doc id="5132" url="https://en.wikipedia.org/wiki?curid=5132" title="Charlize Theron">
Charlize Theron

Charlize Theron ( ; ; born 7 August 1975) is a South African and American actress and film producer. She is known for starring in numerous Hollywood films, such as "The Devil's Advocate" (1997), "Mighty Joe Young" (1998), "The Cider House Rules" (1999), "Monster" (2003), "The Italian Job" (2003), "Hancock" (2008), "The Road" (2009), "Snow White and the Huntsman" (2012), "Prometheus" (2012), "A Million Ways to Die in the West " (2014), "" (2015), "The Fate of the Furious" (2017), and "Atomic Blonde" (2017).

Theron received critical acclaim for her portrayal of serial killer Aileen Wuornos in "Monster", for which she won the Academy Award, Silver Bear, Golden Globe Award, and Screen Actors Guild Award for Best Actress, among other accolades, becoming the first South African to win an Academy Award in a major acting category. She received Academy Award and Golden Globe Award nominations for her performance in the sexual harassment-themed drama "North Country" (2005), and a Golden Globe Award nomination for her performance in Jason Reitman's film "Young Adult" (2011).

Theron moved into the field of producing in the late 2000s. She founded and owns the production company Denver and Delilah Productions. She has produced numerous films, many of which she had a starring role in, including "The Burning Plain" (2008) and "Dark Places" (2015). Theron became a U.S. citizen in 2007, while retaining her South African citizenship. In 2016, "Time" named her in the annual "Time 100" most influential people list.

Theron was born in Benoni, in the then-Transvaal Province (now Gauteng Province) of South Africa, the only child of Gerda Jacoba Aletta (née Maritz) and Charles Jacobus Theron (born 27 November 1947). Second Boer War figure Danie Theron was her great-great-uncle. She is from an Afrikaner family, and her ancestry includes Dutch as well as French and German; her French forebears were early Huguenot settlers in South Africa. "Theron" is an Occitan surname (originally spelled Théron) pronounced in Afrikaans as .

She grew up on her parents' farm in Benoni, near Johannesburg. On 21 June 1991, Theron's father, an alcoholic, threatened both teenaged Charlize and her mother while drunk, physically attacking her mother. Theron's mother then shot and killed him. The shooting was legally adjudged to have been self-defence, and her mother faced no charges.

Theron attended Putfontein Primary School (Laerskool Putfontein), a period during which she has said she was not "fitting in." At thirteen, Theron was sent to boarding school and began her studies at the National School of the Arts in Johannesburg. Although Theron is fluent in English, her first language is Afrikaans.

Although seeing herself as a dancer, Theron at 16 won a one-year modelling contract at a local competition in Salerno and with her mother moved to Milan, Italy. After Theron spent a year modelling throughout Europe, she and her mother moved to the US, both New York City and Miami. In New York, she attended the Joffrey Ballet School, where she trained as a ballet dancer until a knee injury closed this career path. As Theron recalled in 2008:

At 19, Theron flew to Los Angeles, on a one-way ticket her mother bought for her, intending to work in the film industry. During the initial months there, she went to a Hollywood Boulevard bank to cash a cheque her mother had sent to help with the rent. When the teller refused to cash it, Theron engaged in a shouting match with him. Upon seeing this, talent agent John Crosby, waiting behind her, handed her his business card and subsequently introduced her to casting agents and also an acting school. She later fired him as her manager after he kept sending her scripts for films similar to "Showgirls" and "Species". After several months in the city, she made her film debut with a non-speaking role in the horror film "" (1995). Her first speaking role was a supporting but significant and attention-garnering part as a hitwoman in "2 Days in the Valley" (1996). Larger roles in widely released Hollywood films followed, and her career expanded in the late 1990s with box-office successes like "The Devil's Advocate" (1997), "Mighty Joe Young" (1998), and "The Cider House Rules" (1999). She was on the cover of the January 1999 issue of "Vanity Fair" as the "White Hot Venus". She also appeared on the cover of the May 1999 issue of "Playboy" magazine, in photos taken several years earlier when she was an unknown model; Theron unsuccessfully sued the magazine for publishing them without her consent.

She starred in five films in 2000: "Reindeer Games", "The Yards", "The Legend of Bagger Vance" and "Men of Honor", "Sweet November" and was briefly considered a new "It girl". Theron has said of this period in her career that, "I kept finding myself in a place where directors would back me but studios didn't. [I began] a love affair with directors, the ones I really, truly admired. I found myself making really bad movies, too. "Reindeer Games" was not a good movie, but I did it because I loved John Frankenheimer."

After appearing in other films, Theron starred as serial killer Aileen Wuornos in "Monster" (2003). Film critic Roger Ebert called it "one of the greatest performances in the history of the cinema". For her role, she won the Academy Award for Best Actress at the 76th Academy Awards in February 2004, as well as the Screen Actors Guild Award and the Golden Globe Award. She is the first South African to win an Oscar for Best Actress. The Oscar win pushed her to "The Hollywood Reporter's" 2006 list of highest-paid actresses in Hollywood, earning US$10 million for both her subsequent films, "North Country" and "Aeon Flux", she ranked seventh, behind Halle Berry, Cameron Diaz, Drew Barrymore, Renée Zellweger, Reese Witherspoon and Nicole Kidman. AskMen also named her the number one most desirable woman of 2003.

In 2005, Theron portrayed Rita, Michael Bluth's (Jason Bateman) love interest, on the third season of Fox's television series "Arrested Development". She also received Golden Globe Award and Primetime Emmy Award nominations for her role of Britt Ekland in the 2004 HBO film "The Life and Death of Peter Sellers". On 30 September, Theron received a star on the Hollywood Walk of Fame. In the same year, she starred in the financially unsuccessful science fiction thriller "Aeon Flux". She also received the 2005 Spike Video Game Award for Best Performance by a Human Female for her voiceover work in the "Aeon Flux" video game. Theron was listed for the role of Susan Storm in the film "Fantastic Four" (2005).

Theron received Best Actress Academy Award and Golden Globe Award nominations for her lead performance in the drama "North Country". "Ms." magazine also honoured her for this performance with a feature article in its Fall 2005 issue. She was supposed to star in the screen adaption of the short story "The Ice at the Bottom of the World" by Mark Richard, and it was to be directed by Kimberly Peirce and produced by Theron's company Denver and Delilah Productions (named after Theron's two dogs). Theron has owned the rights for many years. She was also supposed to star in a movie adaption of the graphic novel "Jinx", but neither project has been produced yet.

In 2008, Theron was named the Hasty Pudding Theatricals Woman of the Year. That year she also starred with Will Smith in the superhero film "Hancock", and in late 2008 she was asked to be a UN Messenger of Peace by the UN Secretary General Ban Ki-moon.

On 4 December 2009, Theron co-presented the draw for the 2010 FIFA World Cup in Cape Town, South Africa, accompanied by several other celebrities of South African nationality or ancestry. During rehearsals she drew an Ireland ball instead of France as a joke at the expense of FIFA, referring to Thierry Henry's handball controversy in the play-off match between France and Ireland. The stunt alarmed FIFA enough for it to fear she might do it again in front of a live global audience.

Following a two-year hiatus from the big screen, Theron returned to the spotlight in 2011 with "Young Adult". Directed by Jason Reitman, the film earned critical acclaim, especially for Theron's performance. She was nominated for a Golden Globe Award and several other awards. Theron then played the Evil Queen Ravenna, Snow White's evil stepmother, in the film "Snow White and the Huntsman", which began production in 2011 and was released in 2012. In 2011, she described her process for becoming the characters in her film:
In 2012, she starred in Ridley Scott's science fiction film "Prometheus". In 2013, Vulture/NYMag named her the 68th Most Valuable Star in Hollywood saying: "We’re just happy that Theron can stay on the list in a year when she didn’t come out with anything … any actress who’s got that kind of skill, beauty, and ferocity ought to have a permanent place in Hollywood."

In 2015, Theron played Libby Day, the lead character in the film adaptation of the Gillian Flynn novel "Dark Places", directed by Gilles Paquet-Brenner. Theron also had a producer credit. The same year, Theron also starred as Imperator Furiosa in "" (2015), opposite Tom Hardy.

Theron reprised her role as Queen Ravenna in the fantasy epic "", a sequel to "Snow White and the Huntsman". The film was released on 22 April 2016. Theron also starred in "The Last Face, Kubo and the Two Strings," and "Brain on Fire".

In 2017, Theron starred in "The Fate of the Furious", where she played Cipher, who is the main antagonist of the entire "The Fast and the Furious" series, and in "Atomic Blonde", an adaptation of the graphic novel "The Coldest City", directed by David Leitch.

The Charlize Theron Africa Outreach Project (CTAOP) was created in 2007 by Theron, who the next year was named a UN Messenger of Peace, in an effort to support African youth in the fight against HIV/AIDS. CTAOP's mission is to help keep African youth safe from HIV/AIDS. The project is committed to supporting community-engaged organizations that address the key drivers of the disease. Although the geographic scope of CTAOP is Sub-Saharan Africa, the primary concentration has mostly been Charlize's home country of South Africa. CTAOP's approach is based on the belief that community-based organizations on the ground understand the social and structural relationships of their communities better than anyone. By supporting these organizations through grant giving, networking, and spotlighting their work, CTAOP enables communities to mobilize and empower themselves to prevent HIV.

In 2008, Theron was named a United Nations Messenger of Peace. In his citation, Ban Ki-Moon said of Theron "You have consistently dedicated yourself to improving the lives of women and children in South Africa, and to preventing and stopping violence against women and girls." She recorded a public service announcement in 2014 as part of their Stop Rape Now program.

In December 2009, CTAOP and TOMS Shoes partnered to create a limited edition unisex shoe. The shoe was made from vegan materials and inspired by the African baobab tree, the silhouette of which was embroidered on blue and orange canvas. Ten-thousand pairs were given to destitute children, and a portion of the proceeds went to CTAOP.

Theron is involved in women's rights organizations and has marched in pro-choice rallies. Theron also is a supporter of animal rights and active member of PETA. She appeared in a PETA ad for its anti-fur campaign.

Theron is a supporter of same-sex marriage and attended a march and rally to support that in Fresno, California, on 30 May 2009. She publicly stated that she refused to get married until same sex marriage became legal in the United States, saying: "I don't want to get married because right now the institution of marriage feels very one-sided, and I want to live in a country where we all have equal rights. I think it would be exactly the same if we were married, but for me to go through that kind of ceremony, because I have so many friends who are gays and lesbians who would so badly want to get married, that I wouldn't be able to sleep with myself." Theron further elaborated on her stance in a June 2011 interview on "Piers Morgan Tonight". She stated: "I do have a problem with the fact that our government hasn't stepped up enough to make this federal, to make [gay marriage] legal. I think everybody has that right."

In March 2014, CTAOP was among the charities that benefited from the annual Fame and Philanthropy fundraising event on the night of the 86th Academy Awards. Theron was an honoured guest along with Halle Berry and keynote speaker James Cameron.

In 2015, Theron signed an open letter which the ONE Campaign had been collecting signatures for; the letter was addressed to Angela Merkel and Nkosazana Dlamini-Zuma, urging them to focus on women as they serve as the head of the G7 in Germany and the AU in South Africa respectively, which will start to set the priorities in development funding before a main UN summit in September 2015 that will establish new development goals for the generation.

Having signed a deal with John Galliano in 2004, Theron replaced Estonian model Tiiu Kuik as the spokeswoman in the "J'adore" advertisements by Christian Dior. From October 2005 to December 2006, Theron earned US$3 million for the use of her image in a worldwide print media advertising campaign for Raymond Weil watches. In February 2006, she and her corporate entity were sued by Weil for breach of contract. The lawsuit was settled on 4 November 2008.

In 2007, Theron became a naturalized citizen of the United States, while retaining her South African citizenship.

Theron has two children, both adopted. In March 2012, she adopted a boy. In July 2015, she adopted a girl. She lives in Los Angeles.

Theron dated Irish actor Stuart Townsend after meeting him on the set of 2002's "Trapped". The couple lived together in Los Angeles and Ireland. Theron split from Townsend when she came back from a holiday in Mexico in January 2010.

In December 2013, Theron began dating actor Sean Penn. The two announced their engagement in December 2014. Theron ended their relationship in June 2015.
As a child, Theron had suffered from jaundice that caused dental problems. She said in an interview that "I had no teeth until I was 11. I had these fangs because I had jaundice when I was a kid and I was put on so many antibiotics that my teeth rotted. They had to cut them out. So I never had baby teeth."

While filming "Æon Flux" in Berlin, Germany, Theron suffered a herniated disc in her neck, caused by a fall while filming a series of back handsprings. It required her to wear a neck brace for a month. In July 2009, she was diagnosed with a serious stomach virus, thought to be contracted while overseas. While filming "The Road", Theron injured her vocal cords during the labour screaming scenes.

Both Theron and her mother, Gerda Maritz, have sleeping problems. For this, they each tried marijuana-laced edibles to see if it would help. Newspaper headlines subsequently identified her mother as her "weed supplier." However, Theron has since stopped using marijuana.



</doc>
<doc id="5134" url="https://en.wikipedia.org/wiki?curid=5134" title="Chess">
Chess

Chess is a two-player strategy board game played on a chessboard, a checkered gameboard with 64 squares arranged in an 8×8 grid. The game is played by millions of people worldwide. Each player begins with 16 pieces: one king, one queen, two rooks, two knights, two bishops, and eight pawns. Each of the six piece types moves differently, with the most powerful being the queen and the least powerful the pawn. The objective is to "checkmate" the opponent's king by placing it under an inescapable threat of capture. To this end, a player's pieces are used to attack and capture the opponent's pieces, while supporting each other. In addition to checkmate, the game can be won by of the opponent, which typically occurs when too much material is lost or checkmate appears inevitable. There are also several ways a game can end in a draw.

Chess is believed to have originated in India sometime before the 7th century. The game was derived from the Indian game chaturanga, which is also the likely ancestor of the Eastern strategy games xiangqi, janggi, and shogi. (A minority view holds that chess originated in China.) Chess reached Europe by the 9th century, due to the Moorish conquest of Spain. The pieces assumed their current powers in Spain in the late 15th century; the rules were standardized in the 19th century.

The first generally recognized World Chess Champion, Wilhelm Steinitz, claimed his title in 1886. Since 1948, the World Championship has been regulated by the Fédération Internationale des Échecs (FIDE), the game's international governing body. FIDE also awards life-time master titles to skilled players, the highest of which is grandmaster. Many national chess organizations have a title system of their own. FIDE also organizes the Women's World Championship, the World Junior Championship, the World Senior Championship, the Blitz and Rapid World Championships, and the Chess Olympiad, a popular competition among international teams. FIDE is a member of the International Olympic Committee, which can be considered as a recognition of chess as a sport. Several national sporting bodies (for example the Spanish "Consejo Superior de Deportes") also recognize chess as a sport. Chess was included in the 2006 and 2010 Asian Games. There is also a Correspondence Chess World Championship and a World Computer Chess Championship. Online chess has opened amateur and professional competition to a wide and varied group of players. 

Since the second half of the 20th century, computers have been programmed to play chess with increasing success, to the point where the strongest personal computers play at a higher level than the best human players. Since the 1990s, computer analysis has contributed significantly to chess theory, particularly in the endgame. The IBM computer Deep Blue was the first machine to overcome a reigning World Chess Champion in a match when it defeated Garry Kasparov in 1997. The rise of strong computer programs (called "engines") runnable on hand-held devices has led to increasing concerns about cheating during tournaments.

There are many variants of chess that utilize different rules, pieces, or boards. One of these, Chess960 (originally named "Fischerandom"), has gained widespread popularity as well as some FIDE recognition.

The rules of chess are published by FIDE ("Fédération Internationale des Échecs"), chess's international governing body, in its Handbook. Rules published by national governing bodies, or by unaffiliated chess organizations, commercial publishers, etc., may differ. FIDE's rules were most recently revised in 2017.

Chess is played on a square board of eight rows (called ' and denoted with numbers "1" to "8") and eight columns (called ' and denoted with letters "a" to "h"). The colors of the 64 squares alternate and are referred to as "light" and "dark" squares. The chessboard is placed with a light square at the right-hand end of the rank nearest to each player.

By convention, the game pieces are divided into white and black sets, and the players are referred to as "White" and "Black" respectively. Each player begins the game with 16 pieces of the specified color, which consist of one king, one queen, two rooks, two bishops, two knights, and eight pawns. The pieces are set out as shown in the diagram and photo, with each queen on a square of its own color, the white queen on a light square and the black queen on a dark.

The player with the white pieces always moves first. After the first move, players alternately move one piece per turn (except for castling, when two pieces are moved). Pieces are moved to either an unoccupied square or one occupied by an opponent's piece, which is captured and removed from play. With the sole exception of "en passant", all pieces capture by moving to the square that the opponent's piece occupies. A player may not make any move that would put or leave the player's own king under attack. A player cannot "pass"; at each turn one must make a legal move (this is the basis for the finesse called zugzwang).

If the player to move has no legal move, the game is over; it is either a checkmate (a loss for the player with no legal moves) if the king is under attack, or a stalemate (a draw) if the king is not.

Each chess piece has its own way of moving. In the diagrams, the dots mark the squares where the piece can move if there are no intervening piece(s) of either color.

Once in every game, each king is allowed to make a special move, known as "castling". Castling consists of moving the king two squares along the first rank toward a rook (which is on the player's first rank) and then placing the rook on the last square that the king has just crossed. Castling is permissible under the following conditions:

When a pawn advances two squares from its starting position and there is an opponent's pawn on an adjacent file next to its destination square, then the opponent's pawn can capture it "en passant" (in passing), and move to the square the pawn passed over. This can only be done on the very next move, otherwise the right to do so is forfeit. For example, in the animated diagram, the black pawn advances two squares from g7 to g5, and the white pawn on f5 can take it via "en passant" on g6 (but only on White's next move).

When a pawn advances to the eighth rank, as a part of the move it is "promoted" and must be exchanged for the player's choice of queen, rook, bishop, or knight of the same color. Usually, the pawn is chosen to be promoted to a queen, but in some cases another piece is chosen; this is called underpromotion. In the animated diagram, the pawn on c7 can be advanced to the eighth rank and be promoted to an allowed piece. There is no restriction placed on the piece that is chosen on promotion, so it is possible to have more pieces of the same type than at the start of the game (for example, two queens).

When a king is under immediate attack by one or two of the opponent's pieces, it is said to be in "check". A response to a check is a legal move if it results in a position where the king is no longer under direct attack (that is, not in check). This can involve capturing the checking piece; interposing a piece between the checking piece and the king (which is possible only if the attacking piece is a queen, rook, or bishop and there is a square between it and the king); or moving the king to a square where it is not under attack. Castling is not a permissible response to a check. The object of the game is to checkmate the opponent; this occurs when the opponent's king is in check, and there is no legal way to remove it from attack. It is illegal for a player to make a move that would put or leave the player's own king in check.

In casual games it is common to announce "check" when putting the opponent's king in check, but this is not required by the rules of the game, and is not usually done in tournaments.

Games can be won in the following ways:

There are several ways games can end in a draw:

Chess games may also be played with a time control. If a player's time runs out before the game is completed, the game is automatically lost (provided the opponent has enough pieces left to deliver checkmate). The duration of a game ranges from long (or "classical") games which can take up to seven hours (even longer if adjournments are permitted) to bullet chess (under 3 minutes per player for the entire game). Intermediate between these are rapid chess games, lasting between 20 minutes and two hours per game, a popular time control in amateur weekend tournaments. 

Time is controlled using a chess clock that has two displays, one for each player's remaining time. Analog chess clocks have been largely replaced by digital clocks, which allow for time controls with increments.

Chess games and positions are recorded using a system of notation, most commonly algebraic chess notation. Abbreviated (or short) algebraic notation generally records moves in the format "abbreviation of the piece moved – file where it moved – rank where it moved". The pieces are identified by their initials. In English, these are K (King), Q (Queen), R (Rook), B (Bishop), and N (Knight; N is used to avoid confusion with King). For example, Qg5 means "queen moves to the g-file and the 5th rank" (that is, to the square g5). Chess literature published in other languages may use different initials to indicate the pieces, or Figurine Algebraic Notation may be used to avoid language difficulties. To resolve ambiguities, one more letter or number is added to indicate the file or rank from which the piece moved, e.g. Ngf3 means "knight from the g-file moves to the square f3", and R1e2 means "rook on the first rank moves to e2". The letter "P" for a pawn is not used, so that e4 means "pawn moves to the square e4".

If the piece makes a capture, "x" is inserted before the destination square. Thus Bxf3 means "bishop captures on f3". When a pawn makes a capture, the file from which the pawn departed is used in place of a piece initial, and ranks may be omitted if unambiguous. For example, exd5 (pawn on the e-file captures the piece on d5) or exd (pawn on the e-file captures a piece somewhere on the d-file). Particularly in Germany, some publications have used ":" rather than "x" to indicate a capture, but this is now rare. Some publications omit the capture symbol altogether, so that exd5 would be rendered simply as "ed".

If a pawn moves to its last rank, achieving promotion, the piece chosen is indicated after the move, for example e1Q or e1=Q. Castling is indicated by the special notations 0-0 for castling and 0-0-0 for castling. An "en passant" capture is sometimes marked with the notation "e.p." A move that places the opponent's king in check usually has the notation "+" added. (The notation "++" for a double check is considered obsolete.) Checkmate can be indicated by "#". At the end of the game, "1–0" means "White won", "0–1" means "Black won", and "½–½" indicates a draw.
Chess moves can be annotated with punctuation marks and other symbols. For example, "!" indicates a good move, "!!" an excellent move, "?" a mistake, "??" a blunder, "!?" an interesting move that may not be best, or "?!" a dubious move not easily refuted.

For example, one variation of a simple trap known as the Scholar's mate (see animated diagram) can be recorded:

The text-based Portable Game Notation (PGN), which is understood by chess software, is based on short form English language algebraic notation.

Until about 1980, the majority of English language chess publications used a form of descriptive notation. In descriptive notation, files are named according to the piece which occupies the back rank at the start of the game, and each square has two different names depending on whether it is from White's or Black's point of view. For example, the square known as "e3" in algebraic notation is "K3" (King's 3rd) from White's point of view, and "K6" (King's 6th) from Black's point of view. When recording captures, the captured piece is named rather than the square on which it is captured (except to resolve ambiguities). Thus, Scholar's mate is rendered in descriptive notation:

A few players still prefer descriptive notation, but it is no longer recognized by FIDE.

Another system is ICCF numeric notation, recognized by the International Correspondence Chess Federation though its use is in decline. Squares are identified by numeric coordinates, for example a1 is "11" and h8 is "88". Moves are described by the "from" and "to" squares, and captures are not indicated. For example, the opening move 1.e4 is rendered as 1.5254. Castling is described by the king's move only, for example 5171 for White castling kingside, 5838 for Black castling queenside.

Chess strategy consists of setting and achieving long-term positioning advantages during the game – for example, where to place different pieces – while tactics concentrate on immediate maneuver. These two parts of the chess-playing process cannot be completely separated, because strategic goals are mostly achieved through tactics, while the tactical opportunities are based on the previous strategy of play. A game of chess is normally divided into three phases: opening, typically the first 10 moves, when players move their pieces to useful positions for the coming battle; then middlegame; and last the endgame, when most of the pieces are gone, kings typically take a more active part in the struggle, and pawn promotion is often decisive.

In chess, tactics in general concentrate on short-term actions – so short-term that they can be calculated in advance by a human player or by a computer. The possible depth of calculation depends on the player's ability. In quiet positions with many possibilities on both sides, a deep calculation is more difficult and may not be practical, while in "tactical" positions with a limited number of forced variations, strong players can calculate long sequences of moves.

Simple one-move or two-move tactical actions – threats, exchanges of material, and double attacks – can be combined into more complicated combinations, sequences of tactical maneuvers that are often forced from the point of view of one or both players. Theoreticians describe many elementary tactical methods and typical maneuvers; for example, pins, forks, skewers, batteries, discovered attacks (especially discovered checks), zwischenzugs, deflections, decoys, sacrifices, underminings, overloadings, and interferences.

A forced variation that involves a sacrifice and usually results in a tangible gain is called a combination. Brilliant combinations – such as those in the Immortal Game – are considered beautiful and are admired by chess lovers. A common type of chess exercise, aimed at developing players' skills, is showing players a position where a decisive combination is available and challenging them to find it.

Chess strategy is concerned with evaluation of chess positions and with setting up goals and long-term plans for the future play. During the evaluation, players must take into account numerous factors such as the value of the pieces on the board, control of the center and centralization, the pawn structure, king safety, and the control of key squares or groups of squares (for example, diagonals, open files, and dark or light squares).

The most basic step in evaluating a position is to count the total value of pieces of both sides. The point values used for this purpose are based on experience; usually pawns are considered worth one point, knights and bishops about three points each, rooks about five points (the value difference between a rook and a bishop or knight being known as the exchange), and queens about nine points. The king is more valuable than all of the other pieces combined, since its checkmate loses the game. But in practical terms, in the endgame the king as a fighting piece is generally more powerful than a bishop or knight but less powerful than a rook. These basic values are then modified by other factors like position of the piece (e.g. advanced pawns are usually more valuable than those on their initial squares), coordination between pieces (e.g. a pair of bishops usually coordinate better than a bishop and a knight), or the type of position (e.g. knights are generally better in with many pawns while bishops are more powerful in ).
Another important factor in the evaluation of chess positions is the pawn structure (sometimes known as the pawn skeleton), or the configuration of pawns on the chessboard. Since pawns are the least mobile of the chess pieces, the pawn structure is relatively static and largely determines the strategic nature of the position. Weaknesses in the pawn structure, such as isolated, doubled, or backward pawns and , once created, are often permanent. Care must therefore be taken to avoid these weaknesses unless they are compensated by another valuable asset (for example, by the possibility of developing an attack).

A chess opening is the group of initial moves of a game (the "opening moves"). Recognized sequences of opening moves are referred to as "openings" and have been given names such as the Ruy Lopez or Sicilian Defense. They are catalogued in reference works such as the "Encyclopaedia of Chess Openings". There are dozens of different openings, varying widely in character from quiet positional play (for example, the Réti Opening) to very aggressive (the Latvian Gambit). In some opening lines, the exact sequence considered best for both sides has been worked out to more than 30 moves. Professional players spend years studying openings and continue doing so throughout their careers, as opening theory continues to evolve.

The fundamental strategic aims of most openings are similar:

Most players and theoreticians consider that White, by virtue of the first move, begins the game with a small advantage. This initially gives White the initiative. Black usually strives to neutralize White's advantage and achieve , or to develop in an unbalanced position.

The middlegame is the part of the game which starts after the opening. There is no clear line between the opening and the middlegame, but typically the middlegame will start when most pieces have been developed. (Similarly, there is no clear transition from the middlegame to the endgame; see start of the endgame.) Because the opening theory has ended, players have to form plans based on the features of the position, and at the same time take into account the tactical possibilities of the position. The middlegame is the phase in which most combinations occur. Combinations are a series of tactical moves executed to achieve some gain. Middlegame combinations are often connected with an attack against the opponent's king. Some typical patterns have their own names; for example, the Boden's Mate or the Lasker–Bauer combination.

Specific plans or strategic themes will often arise from particular groups of openings which result in a specific type of pawn structure. An example is the , which is the attack of queenside pawns against an opponent who has more pawns on the queenside. The study of openings is therefore connected to the preparation of plans that are typical of the resulting middlegames.

Another important strategic question in the middlegame is whether and how to reduce material and transition into an endgame (i.e. ). Minor material advantages can generally be transformed into victory only in an endgame, and therefore the stronger side must choose an appropriate way to achieve an ending. Not every reduction of material is good for this purpose; for example, if one side keeps a light-squared bishop and the opponent has a dark-squared one, the transformation into a bishops and pawns ending is usually advantageous for the weaker side only, because an endgame with bishops on opposite colors is likely to be a draw, even with an advantage of a pawn, or sometimes even with a two-pawn advantage.

The endgame (also "end game" or "ending") is the stage of the game when there are few pieces left on the board. There are three main strategic differences between earlier stages of the game and the endgame:

Endgames can be classified according to the type of pieces remaining on the board. Basic checkmates are positions in which one side has only a king and the other side has one or two pieces and can checkmate the opposing king, with the pieces working together with their king. For example, king and pawn endgames involve only kings and pawns on one or both sides, and the task of the stronger side is to promote one of the pawns. Other more complicated endings are classified according to pieces on the board other than kings, such as "rook and pawn versus rook" endgames.

Chess is believed to have originated in Eastern India, c. 280–550, in the Gupta Empire, where its early form in the 6th century was known as "chaturaṅga" (), literally "four divisions" [of the military] – infantry, cavalry, elephants, and chariotry, represented by the pieces that would evolve into the modern pawn, knight, bishop, and rook, respectively. Thence it spread eastward and westward along the Silk Road. The earliest evidence of chess is found in the nearby Sassanid Persia around 600, where the game came to be known by the name "chatrang". Chatrang was taken up by the Muslim world after the Islamic conquest of Persia (633–44), where it was then named "shatranj", with the pieces largely retaining their Persian names. In Spanish "shatranj" was rendered as "ajedrez" ("al-shatranj"), in Portuguese as "xadrez", and in Greek as ζατρίκιον ("zatrikion", which comes directly from the Persian "chatrang"), but in the rest of Europe it was replaced by versions of the Persian "shāh" ("king"), which was familiar as an exclamation and became the English words "check" and "chess".

The oldest archaeological chess artifacts, ivory pieces, were excavated in ancient Afrasiab, today's Samarkand, in Uzbekistan, central Asia, and date to about 760, with some of them possibly older. The oldest known chess manual was in Arabic and dates to 840–850, written by al-Adli ar-Rumi (800–870), a renowned Arab chess player, titled "Kitab ash-shatranj" (Book of the chess). This is a lost manuscript, but referenced in later works. The eastern migration of chess, into China and Southeast Asia, has even less documentation than its migration west. The first reference to chess, called "Xiang Qi", in China comes in the "xuán guaì lù" (玄怪录, record of the mysterious and strange) dating to about 800. Alternatively, some contend that chess arose from Chinese chess or one of its predecessors, although this has been contested.

The game reached Western Europe and Russia by at least three routes, the earliest being in the 9th century. By the year 1000, it had spread throughout Europe. Introduced into the Iberian Peninsula by the Moors in the 10th century, it was described in a famous 13th-century manuscript covering shatranj, backgammon, and dice named the "Libro de los juegos".

Around 1200, the rules of shatranj started to be modified in southern Europe, and around 1475, several major changes made the game essentially as it is known today. These modern rules for the basic moves had been adopted in Italy and Spain.
Pawns gained the option of advancing two squares on their first move, while bishops and queens acquired their modern abilities. The queen replaced the earlier vizier chess piece towards the end of the 10th century and by the 15th century had become the most powerful piece; consequently modern chess was referred to as "Queen's Chess" or "Mad Queen Chess". Castling, derived from the "kings leap" usually in combination with a pawn or rook move to bring the king to safety, was introduced. These new rules quickly spread throughout western Europe. The rules concerning stalemate were finalized in the early 19th century. Also in the 19th century, the convention that White moves first was established (formerly either White or Black could move first). Finally the rules around castling were standardized – variations in the castling rules had persisted in Italy until the late 19th century. The resulting standard game is sometimes referred to as "Western chess" or "international chess", particularly in Asia where other games of the chess family such as xiangqi are prevalent. Since the 19th century, the only rule changes have been technical in nature, for example establishing the correct procedure for claiming a draw by repetition.
Writings about the theory of how to play chess began to appear in the 15th century. The "Repetición de Amores y Arte de Ajedrez" ("Repetition of Love and the Art of Playing Chess") by Spanish churchman Luis Ramirez de Lucena was published in Salamanca in 1497. Lucena and later masters like Portuguese Pedro Damiano, Italians Giovanni Leonardo Di Bona, Giulio Cesare Polerio and Gioachino Greco, and Spanish bishop Ruy López de Segura developed elements of openings and started to analyze simple endgames.

The romantic era was characterized by opening gambits (sacrificing pawns or even pieces), daring attacks, and brazen sacrifices. Many elaborate and beautiful but unsound move sequences called "combinations" were played by the masters of the time. The game was played more for art than theory. A profound belief that chess merit resided in the players' genius rather than inherent in the position on the board pervaded chess practice.
In the 18th century, the center of European chess life moved from the Southern European countries to France. The two most important French masters were François-André Danican Philidor, a musician by profession, who discovered the importance of pawns for chess strategy, and later Louis-Charles Mahé de La Bourdonnais, who won a famous series of matches with the Irish master Alexander McDonnell in 1834. Centers of chess activity in this period were coffee houses in major European cities like "Café de la Régence" in Paris and "Simpson's Divan" in London.

As the 19th century progressed, chess organization developed quickly. Many chess clubs, chess books, and chess journals appeared. There were correspondence matches between cities; for example, the London Chess Club played against the Edinburgh Chess Club in 1824. Chess problems became a regular part of 19th-century newspapers; Bernhard Horwitz, Josef Kling, and Samuel Loyd composed some of the most influential problems. In 1843, von der Lasa published his and Bilguer's "Handbuch des Schachspiels" ("Handbook of Chess"), the first comprehensive manual of chess theory.

Chess was occasionally criticised in the 19th century as a waste of time.
The first modern chess tournament was organized by Howard Staunton, a leading English chess player, and was held in London in 1851. It was won by the German Adolf Anderssen, who was hailed as the leading chess master. His brilliant, energetic attacking style was typical for the time. Sparkling games like Anderssen's "Immortal game" and "Evergreen game" or Morphy's "Opera game" were regarded as the highest possible summit of the chess art.

Deeper insight into the nature of chess came with two younger players. American Paul Morphy, an extraordinary chess prodigy, won against all important competitors (except Howard Staunton, who refused to play), including Anderssen, during his short chess career between 1857 and 1863. Morphy's success stemmed from a combination of brilliant attacks and sound strategy; he intuitively knew how to prepare attacks.

Prague-born Wilhelm Steinitz beginning in 1873 described how to avoid weaknesses in one's own position and how to create and exploit such weaknesses in the opponent's position. The scientific approach and positional understanding of Steinitz revolutionized the game. Steinitz was the first to break a position down into its components. Before Steinitz, players brought their queen out early, did not completely develop their other pieces, and mounted a quick attack on the opposing king, which either succeeded or failed. The level of defense was poor and players did not form any deep plan. In addition to his theoretical achievements, Steinitz founded an important tradition: his triumph over the leading German master Johannes Zukertort in 1886 is regarded as the first official World Chess Championship. Steinitz lost his crown in 1894 to a much younger player, the German mathematician Emanuel Lasker, who maintained this title for 27 years, the longest tenure of all World Champions.
After the end of the 19th century, the number of master tournaments and matches held annually quickly grew. Some sources state that in 1914 the title of chess Grandmaster was first formally conferred by Tsar Nicholas II of Russia to Lasker, Capablanca, Alekhine, Tarrasch, and Marshall, but this is a disputed claim. The tradition of awarding such titles was continued by the World Chess Federation (FIDE), founded in 1924 in Paris. In 1927, the Women's World Chess Championship was established; the first to hold the title was Czech-English master Vera Menchik.

It took a prodigy from Cuba, José Raúl Capablanca (World Champion 1921–1927), who loved simple positions and endgames, to end the German-speaking dominance in chess; he was undefeated in tournament play for eight years, until 1924. His successor was Russian-French Alexander Alekhine, a strong attacking player who died as the World champion in 1946. He briefly lost the title to Dutch player Max Euwe in 1935 and regained it two years later.

Between the world wars, chess was revolutionized by the new theoretical school of so-called hypermodernists like Aron Nimzowitsch and Richard Réti. They advocated controlling the center of the board with distant pieces rather than with pawns, thus inviting opponents to occupy the center with pawns, which become objects of attack.

After the death of Alekhine, a new World Champion was sought. FIDE, which has controlled the title since then (except for one interruption), ran a tournament of elite players. The winner of the 1948 tournament, Russian Mikhail Botvinnik, started an era of Soviet dominance in the chess world. Until the end of the Soviet Union, there was only one non-Soviet champion, American Bobby Fischer (champion 1972–1975). Botvinnik revolutionized opening theory. Previously Black strove for equality, to neutralize White's first-move advantage. As Black, Botvinnik strove for the initiative from the beginning. In the previous informal system of World Championships, the current champion decided which challenger he would play for the title and the challenger was forced to seek sponsors for the match. FIDE set up a new system of qualifying tournaments and matches. The world's strongest players were seeded into Interzonal tournaments, where they were joined by players who had qualified from Zonal tournaments. The leading finishers in these Interzonals would go on the "Candidates" stage, which was initially a tournament, and later a series of knockout matches. The winner of the Candidates would then play the reigning champion for the title. A champion defeated in a match had a right to play a rematch a year later. This system operated on a three-year cycle. Botvinnik participated in championship matches over a period of fifteen years. He won the world championship tournament in 1948 and retained the title in tied matches in 1951 and 1954. In 1957, he lost to Vasily Smyslov, but regained the title in a rematch in 1958. In 1960, he lost the title to the 23-year-old Latvian prodigy Mikhail Tal, an accomplished tactician and attacking player. Botvinnik again regained the title in a rematch in 1961.

Following the 1961 event, FIDE abolished the automatic right of a deposed champion to a rematch, and the next champion, Armenian Tigran Petrosian, a player renowned for his defensive and positional skills, held the title for two cycles, 1963–1969. His successor, Boris Spassky from Russia (champion 1969–1972), won games in both positional and sharp tactical style. The next championship, the so-called Match of the Century, saw the first non-Soviet challenger since World War II, American Bobby Fischer, who defeated his Candidates opponents by unheard-of margins and clearly won the world championship match. In 1975, however, Fischer refused to defend his title against Soviet Anatoly Karpov when FIDE did not meet his demands, and Karpov obtained the title by default. Fischer modernized many aspects of chess, especially by extensively preparing openings.

Karpov defended his title twice against Viktor Korchnoi and dominated the 1970s and early 1980s with a string of tournament successes. Karpov's reign finally ended in 1985 at the hands of Garry Kasparov, another Soviet player from Baku, Azerbaijan. Kasparov and Karpov contested five world title matches between 1984 and 1990; Karpov never won his title back. In 1993, Garry Kasparov and Nigel Short broke with FIDE to organize their own match for the title and formed a competing Professional Chess Association (PCA). From then until 2006, there were two simultaneous World Champions and World Championships: the PCA or Classical champion extending the Steinitzian tradition in which the current champion plays a challenger in a series of many games, and the other following FIDE's new format of many players competing in a tournament to determine the champion. Kasparov lost his Classical title in 2000 to Vladimir Kramnik of Russia. The World Chess Championship 2006, in which Kramnik beat the FIDE World Champion Veselin Topalov, reunified the titles and made Kramnik the undisputed World Chess Champion. In September 2007, he lost the title to Viswanathan Anand of India, who won the championship tournament in Mexico City. Anand defended his title in the revenge match of 2008, 2010 and 2012. In 2013, Magnus Carlsen beat Anand in the 2013 World Chess Championship. He defended his title the following year, again against Anand, and is the reigning world champion.

In the Middle Ages and during the Renaissance, chess was a part of noble culture; it was used to teach war strategy and was dubbed the "King's Game". Gentlemen are "to be meanly seene in the play at Chestes", says the overview at the beginning of Baldassare Castiglione's "The Book of the Courtier" (1528, English 1561 by Sir Thomas Hoby), but chess should not be a gentleman's main passion. Castiglione explains it further:

And what say you to the game at chestes? It is truely an honest kynde of enterteynmente and wittie, quoth Syr Friderick. But me think it hath a fault, whiche is, that a man may be to couning at it, for who ever will be excellent in the playe of chestes, I beleave he must beestowe much tyme about it, and applie it with so much study, that a man may assoone learne some noble scyence, or compase any other matter of importaunce, and yet in the ende in beestowing all that laboure, he knoweth no more but a game. Therfore in this I beleave there happeneth a very rare thing, namely, that the meane is more commendable, then the excellency.

Many of the elaborate chess sets used by the aristocracy have been lost, but others partially survive, such as the Lewis chessmen.

Chess was often used as a basis of sermons on morality. An example is "Liber de moribus hominum et officiis nobilium sive super ludo scacchorum" ('Book of the customs of men and the duties of nobles or the Book of Chess'), written by an Italian Dominican monk Jacobus de Cessolis c. 1300. This book was one of the most popular of the Middle Ages. The work was translated into many other languages (the first printed edition was published at Utrecht in 1473) and was the basis for William Caxton's "The Game and Playe of the Chesse" (1474), one of the first books printed in English. Different chess pieces were used as metaphors for different classes of people, and human duties were derived from the rules of the game or from visual properties of the chess pieces:

The knyght ought to be made alle armed upon an hors in suche wyse that he haue an helme on his heed and a spere in his ryght hande/ and coueryd wyth his sheld/ a swerde and a mace on his lyft syde/ Cladd wyth an hawberk and plates to fore his breste/ legge harnoys on his legges/ Spores on his heelis on his handes his gauntelettes/ his hors well broken and taught and apte to bataylle and couerid with his armes/ whan the knyghtes ben maad they ben bayned or bathed/ that is the signe that they shold lede a newe lyf and newe maners/ also they wake alle the nyght in prayers and orysons vnto god that he wylle gyue hem grace that they may gete that thynge that they may not gete by nature/ The kynge or prynce gyrdeth a boute them a swerde in signe/ that they shold abyde and kepe hym of whom they take theyr dispenses and dignyte.

Known in the circles of clerics, students, and merchants, chess entered into the popular culture of Middle Ages. An example is the 209th song of Carmina Burana from the 13th century, which starts with the names of chess pieces, "Roch, pedites, regina..."

During the Age of Enlightenment, chess was viewed as a means of self-improvement. Benjamin Franklin, in his article "The Morals of Chess" (1750), wrote:
The Game of Chess is not merely an idle amusement; several very valuable qualities of the mind, useful in the course of human life, are to be acquired and strengthened by it, so as to become habits ready on all occasions; for life is a kind of Chess, in which we have often points to gain, and competitors or adversaries to contend with, and in which there is a vast variety of good and ill events, that are, in some degree, the effect of prudence, or the want of it. By playing at Chess then, we may learn:

I. Foresight, which looks a little into futurity, and considers the consequences that may attend an action [...]

II. Circumspection, which surveys the whole Chess-board, or scene of action: – the relation of the several Pieces, and their situations [...]

III. Caution, not to make our moves too hastily [...]
With these or similar views, chess is taught to children in schools around the world today. Many schools host chess clubs, and there are many scholastic tournaments specifically for children. Tournaments are held regularly in many countries, hosted by organizations such as the United States Chess Federation and the National Scholastic Chess Foundation.
Chess is often depicted in the arts; significant works where chess plays a key role range from Thomas Middleton's "A Game at Chess" to "Through the Looking-Glass" by Lewis Carroll, to Vladimir Nabokov's "The Defense", to "The Royal Game" by Stefan Zweig. Chess is featured in films like Ingmar Bergman's "The Seventh Seal" and Satyajit Ray's "The Chess Players". 

Chess is also present in contemporary popular culture. For example, the characters in "Star Trek" play a futuristic version of the game called "Tri-Dimensional Chess". "Wizard's Chess" is featured in J.K. Rowling's "Harry Potter" plays. The hero of "Searching for Bobby Fischer" struggles against adopting the aggressive and misanthropic views of a world chess champion. Chess is used as the core theme in the musical "Chess" by Tim Rice, Björn Ulvaeus, and Benny Andersson. The thriller film "Knight Moves" is about a chess grandmaster who is accused of being a serial killer. "Pawn Sacrifice", starring Tobey Maguire as Bobby Fischer and Liev Schreiber as Boris Spassky, depicts the drama surrounding the 1972 World Chess Championship in Iceland during the Cold War.
In 2016 in Saudi Arabia, Grand Mufti Abdul-Aziz ibn Abdullah Al ash-Sheikh issued a religious fatwa declaring that chess is banned for Muslims. He stated that "chess is a waste of time and an opportunity to squander money. It causes enmity and hatred between people". However, this fatwa is not legally binding and chess remains a popular game in Muslim countries.

Chess composition is the art of creating chess problems (also called chess compositions). The creator is known as a chess composer. There are many types of chess problems; the two most important are:

Chess composition is a distinct branch of chess sport, and tournaments exist for both the composition and solving of chess problems.

This is one of the most famous chess studies; it was published by Richard Réti 4 December 1921. It seems impossible to catch the advanced black pawn, while the black king can easily stop the white pawn. The solution is a diagonal advance, which brings the king to "both" pawns simultaneously:
Or 2...h3 3.Ke7 and the white king can support its pawn.
Now the white king comes just in time to support his pawn, or catch the black one.

Contemporary chess is an organized sport with structured international and national leagues, tournaments, and congresses. Chess's international governing body is FIDE (Fédération Internationale des Échecs). Most countries have a national chess organization as well (such as the US Chess Federation and English Chess Federation) which in turn is a member of FIDE. FIDE is a member of the International Olympic Committee, but the game of chess has never been part of the Olympic Games; chess does have its own Olympiad, held every two years as a team event.
The current World Chess Champion is Magnus Carlsen of Norway. The reigning Women's World Champion is Hou Yifan from China. The world's highest rated female player, Judit Polgár, has never participated in the Women's World Chess Championship, instead preferring to compete with the leading men and maintaining a ranking among the top male players.

Other competitions for individuals include the World Junior Chess Championship, the European Individual Chess Championship, and the National Chess Championships. Invitation-only tournaments regularly attract the world's strongest players. Examples include Spain's Linares event, Monte Carlo's Melody Amber tournament, the Dortmund Sparkassen meeting, Sofia's M-tel Masters, and Wijk aan Zee's Tata Steel tournament.

Regular team chess events include the Chess Olympiad and the European Team Chess Championship. The World Chess Solving Championship and World Correspondence Chess Championships include both team and individual events.

Besides these prestigious competitions, there are thousands of other chess tournaments, matches, and festivals held around the world every year catering to players of all levels. Chess is promoted as a "mind sport" by the Mind Sports Organisation, alongside other mental-skill games such as Contract Bridge, Go, and Scrabble.

The best players can be awarded specific lifetime titles by the world chess organization FIDE:

All the titles are open to men and women. Separate women-only titles, such as Woman Grandmaster (WGM), are available. Beginning with Nona Gaprindashvili in 1978, a number of women have earned the GM title, and most of the top ten women in 2006 hold the unrestricted GM title.

As of August 2011, there are 1363 active grandmasters and 3153 international masters in the world. Top three countries with the largest numbers of grandmasters are Russia, Ukraine, and Germany, with 208, 78, and 76. The country with most grandmasters per capita is Iceland, with 11 GMs and 13 IMs among the population of 310,000.

International titles are awarded to composers and solvers of chess problems and to correspondence chess players (by the International Correspondence Chess Federation). National chess organizations may also award titles, usually to the advanced players still under the level needed for international titles; an example is the Chess expert title used in the United States.

In order to rank players, FIDE, ICCF, and national chess organizations use the Elo rating system developed by Arpad Elo. Elo is a statistical system based on the assumption that the chess performance of each player in his or her games is a random variable. Arpad Elo thought of a player's true skill as the average of that player's performance random variable, and showed how to estimate the average from results of player's games. The US Chess Federation implemented Elo's suggestions in 1960, and the system quickly gained recognition as being both fairer and more accurate than older systems; it was adopted by FIDE in 1970. The highest FIDE rating of all time, 2881, was achieved by Magnus Carlsen on the March 2014 FIDE rating list.

Chess has a very extensive literature. In 1913, the chess historian H.J.R. Murray estimated the total number of books, magazines, and chess columns in newspapers to be about 5,000. B.H. Wood estimated the number, as of 1949, to be about 20,000. David Hooper and Kenneth Whyld write that, "Since then there has been a steady increase year by year of the number of new chess publications. No one knows how many have been printed." There are two significant public chess libraries: the John G. White Chess and Checkers Collection at Cleveland Public Library, with over 32,000 chess books and over 6,000 bound volumes of chess periodicals; and the Chess & Draughts collection at the National Library of the Netherlands, with about 30,000 books. Grandmaster Lothar Schmid owned the world's largest private collection of chess books and memorabilia. David DeLucia's chess library contains 7,000 to 8,000 chess books, a similar number of autographs (letters, score sheets, manuscripts), and about 1,000 items of "ephemera". Dirk Jan ten Geuzendam opines that DeLucia's collection "is arguably the finest chess collection in the world".

The game structure and nature of chess are related to several branches of mathematics. Many combinatorical and topological problems connected to chess have been known for hundreds of years.

The number of legal positions in chess is estimated to be about 10, and is provably less than 10, with a game-tree complexity of approximately 10. The game-tree complexity of chess was first calculated by Claude Shannon as 10, a number known as the Shannon number. Typically an average position has thirty to forty possible moves, but there may be as few as zero (in the case of checkmate or stalemate) or as many as 218.

Chess has inspired many combinatorial puzzles, such as the knight's tour and the eight queens puzzle.

One of the most important mathematical challenges of chess is the development of algorithms that can play chess. The idea of creating a chess-playing machine dates to the 18th century; around 1769, the chess-playing automaton called The Turk became famous before being exposed as a hoax. Serious trials based on automata, such as El Ajedrecista, were too complex and limited to be useful.

Since the advent of the digital computer in the 1950s, chess enthusiasts, computer engineers and computer scientists have built, with increasing degrees of seriousness and success, chess-playing machines and computer programs. The groundbreaking paper on computer chess, "Programming a Computer for Playing Chess", was published in 1950 by Shannon. He wrote:

The chess machine is an ideal one to start with, since: (1) the problem is sharply defined both in allowed operations (the moves) and in the ultimate goal (checkmate); (2) it is neither so simple as to be trivial nor too difficult for satisfactory solution; (3) chess is generally considered to require "thinking" for skillful play; a solution of this problem will force us either to admit the possibility of a mechanized thinking or to further restrict our concept of "thinking"; (4) the discrete structure of chess fits well into the digital nature of
modern computers.

The Association for Computing Machinery (ACM) held the first major chess tournament for computers, the North American Computer Chess Championship, in September 1970. CHESS 3.0, a chess program from Northwestern University, won the championship. Nowadays, chess programs compete in the World Computer Chess Championship, held annually since 1974. At first considered only a curiosity, the best chess playing programs have become extremely strong. In 1997, a computer won a chess match using classical time controls against a reigning World Champion for the first time: IBM's Deep Blue beat Garry Kasparov 3½–2½ (it scored two wins, one loss, and three draws). In 2009, a mobile phone won a category 6 tournament with a performance rating 2898: chess engine Hiarcs 13 running on the mobile phone HTC Touch HD won the Copa Mercosur tournament with nine wins and one draw. The best chess programs are now able to consistently beat the strongest human players, to the extent that human-computer matches no longer attract interest from chess players or media.

With huge databases of past games and high analytical ability, computers can help players to learn chess and prepare for matches. Internet Chess Servers allow people to find and play opponents all over the world. The presence of computers and modern communication tools have raised concerns regarding cheating during games, most notably the "bathroom controversy" during the 2006 World Championship.

In 1913, Ernst Zermelo used chess as a basis for his theory of game strategies, which is considered as one of the predecessors of game theory. Zermelo's theorem states that it is possible to solve chess, i.e. to determine with certainty the outcome of a perfectly played game (either white can force a win, or black can force a win, or both sides can force at least a draw). However, according to Claude Shannon, there are 10 legal positions in chess, so it will take an impossibly long time to compute a perfect strategy with any feasible technology.
The 11-category, game theoretical taxonomy of chess includes: two player, no-chance, combinatorial, Markov state (present state is all a player needs to move; although past state led up to that point, knowledge of the sequence of past moves is not required to make the next move, except to take into account of en passant and castling, which "do" depend on the past moves), zero sum, symmetric, perfect information, non-cooperative, discrete, extensive form (tree decisions, not payoff matrices), sequential.

Generalized chess (played on "n" × "n" board, without the fifty-move rule) is EXPTIME-complete.

Some applications of combinatorial game theory to chess endgames were found by Elkies (1996).

There is an extensive scientific literature on chess psychology. Alfred Binet and others showed that knowledge and verbal, rather than visuospatial, ability lies at the core of expertise. In his doctoral thesis, Adriaan de Groot showed that chess masters can rapidly perceive the key features of a position. According to de Groot, this perception, made possible by years of practice and study, is more important than the sheer ability to anticipate moves. De Groot showed that chess masters can memorize positions shown for a few seconds almost perfectly. The ability to memorize does not alone account for chess-playing skill, since masters and novices, when faced with random arrangements of chess pieces, had equivalent recall (about half a dozen positions in each case). Rather, it is the ability to recognize patterns, which are then memorized, which distinguished the skilled players from the novices. When the positions of the pieces were taken from an actual game, the masters had almost total positional recall.

More recent research has focused on chess as mental training; the respective roles of knowledge and look-ahead search; brain imaging studies of chess masters and novices; blindfold chess; the role of personality and intelligence in chess skill; gender differences; and computational models of chess expertise. The role of practice and talent in the development of chess and other domains of expertise has led to much recent research. Ericsson and colleagues have argued that deliberate practice is sufficient for reaching high levels of expertise in chess. Recent research indicates that factors other than practice are also important. For example, Fernand Gobet and colleagues have shown that stronger players started playing chess at a young age and that experts born in the Northern Hemisphere are more likely to have been born in late winter and early spring. Compared to general population, chess players are more likely to be non-right-handed, though they found no correlation between handedness and skill.

Although the link between performance in chess and general intelligence is often assumed, researchers have largely failed to confirm its existence. For example, a 2006 study found no differences in fluid intelligence, as measured by Raven's Progressive Matrices, between strong adult chess players and regular people. There is some evidence towards a correlation between performance in chess and intelligence among beginning players. However, performance in chess also relies substantially on one's experience playing the game, and the role of experience may overwhelm the role of intelligence. Chess experts are estimated to have in excess of 10,000 and possibly as many as 300,000 position patterns stored in their memory; long training is necessary to acquire that amount of data.

A 2007 study of young chess players in the United Kingdom found that strong players tended to have above-average IQ scores, but, within that group, the correlation between chess skill and IQ was moderately negative, meaning that smarter children tended to achieve a lower level of chess skill. This result was explained by a negative correlation between intelligence and practice in the elite subsample, and by practice having a higher influence on chess skill.

There are more than two thousand published chess variants, most of them of relatively recent origin, including:

In the context of chess variants, regular (i.e. FIDE) chess is sometimes referred to as "Western chess", "international chess", "orthodox chess", and "orthochess".

Reference aids

Lists

Bibliography





</doc>
<doc id="5142" url="https://en.wikipedia.org/wiki?curid=5142" title="Charlie Chaplin">
Charlie Chaplin

Sir Charles Spencer Chaplin, (16 April 1889 – 25 December 1977) was an English comic actor, filmmaker, and composer who rose to fame in the era of silent film. Chaplin became a worldwide icon through his screen persona "the Tramp" and is considered one of the most important figures in the history of the film industry. His career spanned more than 75 years, from childhood in the Victorian era until a year before his death in 1977, and encompassed both adulation and controversy.

Chaplin's childhood in London was one of poverty and hardship. As his father was absent and his mother struggled financially, he was sent to a workhouse twice before the age of nine. When he was 14, his mother was committed to a mental asylum. Chaplin began performing at an early age, touring music halls and later working as a stage actor and comedian. At 19, he was signed to the prestigious Fred Karno company, which took him to America. Chaplin was scouted for the film industry and began appearing in 1914 for Keystone Studios. He soon developed the Tramp persona and formed a large fan base. Chaplin directed his own films from an early stage and continued to hone his craft as he moved to the Essanay, Mutual, and First National corporations. By 1918, he was one of the best-known figures in the world.

In 1919, Chaplin co-founded the distribution company United Artists, which gave him complete control over his films. His first feature-length was "The Kid" (1921), followed by "A Woman of Paris" (1923), "The Gold Rush" (1925), and "The Circus" (1928). He refused to move to sound films in the 1930s, instead producing "City Lights" (1931) and "Modern Times" (1936) without dialogue. Chaplin became increasingly political, and his next film, "The Great Dictator" (1940), satirised Adolf Hitler. The 1940s were a decade marked with controversy for Chaplin, and his popularity declined rapidly. He was accused of communist sympathies, while his involvement in a paternity suit and marriages to much younger women caused scandal. An FBI investigation was opened, and Chaplin was forced to leave the United States and settle in Switzerland. He abandoned the Tramp in his later films, which include "Monsieur Verdoux" (1947), "Limelight" (1952), "A King in New York" (1957), and "A Countess from Hong Kong" (1967).

Chaplin wrote, directed, produced, edited, starred in, and composed the music for most of his films. He was a perfectionist, and his financial independence enabled him to spend years on the development and production of a picture. His films are characterised by slapstick combined with pathos, typified in the Tramp's struggles against adversity. Many contain social and political themes, as well as autobiographical elements. In 1972, as part of a renewed appreciation for his work, Chaplin received an Honorary Academy Award for "the incalculable effect he has had in making motion pictures the art form of this century". He continues to be held in high regard, with "The Gold Rush", "City Lights", "Modern Times", and "The Great Dictator" often ranked on industry lists of the greatest films of all time.

Charles Spencer Chaplin was born on 16 April 1889 to Hannah Chaplin (born Hannah Harriet Pedlingham Hill) and Charles Chaplin Sr. There is no official record of his birth, although Chaplin believed he was born at East Street, Walworth, in South London. His mother and father had married four years previously, at which time Charles Sr. became the legal carer of Hannah's illegitimate son, Sydney John Hill. At the time of his birth, Chaplin's parents were both music hall entertainers. Hannah, the daughter of a shoemaker, had a brief and unsuccessful career under the stage name Lily Harley, while Charles Sr., a butcher's son, was a popular singer. Although they never divorced, Chaplin's parents were estranged by around 1891. The following year, Hannah gave birth to a third son – George Wheeler Dryden – fathered by the music hall entertainer Leo Dryden. The child was taken by Dryden at six months old, and did not re-enter Chaplin's life for 30 years.

Chaplin's childhood was fraught with poverty and hardship, making his eventual trajectory "the most dramatic of all the rags to riches stories ever told" according to his authorised biographer David Robinson. Chaplin's early years were spent with his mother and brother Sydney in the London district of Kennington; Hannah had no means of income, other than occasional nursing and dressmaking, and Chaplin Sr. provided no financial support. As the situation deteriorated, Chaplin was sent to Lambeth Workhouse when he was seven years old. The council housed him at the Central London District School for paupers, which Chaplin remembered as "a forlorn existence". He was briefly reunited with his mother 18 months later, before Hannah was forced to readmit her family to the workhouse in July 1898. The boys were promptly sent to Norwood Schools, another institution for destitute children.

In September 1898, Hannah was committed to Cane Hill mental asylum – she had developed a psychosis seemingly brought on by an infection of syphilis and malnutrition. For the two months she was there, Chaplin and his brother Sydney were sent to live with their father, whom the young boys scarcely knew. Charles Sr. was by then a severe alcoholic, and life there was bad enough to provoke a visit from the National Society for the Prevention of Cruelty to Children. Chaplin's father died two years later, at 38 years old, from cirrhosis of the liver.

Hannah entered a period of remission but, in May 1903, became ill again. Chaplin, then 14, had the task of taking his mother to the infirmary, from where she was sent back to Cane Hill. He lived alone for several days, searching for food and occasionally sleeping rough, until Sydney – who had enrolled in the Navy two years earlier – returned. Hannah was released from the asylum eight months later, but in March 1905, her illness returned, this time permanently. "There was nothing we could do but accept poor mother's fate", Chaplin later wrote, and she remained in care until her death in 1928.

Between his time in the poor schools and his mother succumbing to mental illness, Chaplin began to perform on stage. He later recalled making his first amateur appearance at the age of five years, when he took over from Hannah one night in Aldershot. This was an isolated occurrence, but by the time he was nine Chaplin had, with his mother's encouragement, grown interested in performing. He later wrote: "[she] imbued me with the feeling that I had some sort of talent". Through his father's connections, Chaplin became a member of the Eight Lancashire Lads clog-dancing troupe, with whom he toured English music halls throughout 1899 and 1900. Chaplin worked hard, and the act was popular with audiences, but he was not satisfied with dancing and wished to form a comedy act.

In the years Chaplin was touring with the Eight Lancashire Lads, his mother ensured that he still attended school but, by age 13, he had abandoned education. He supported himself with a range of jobs, while nursing his ambition to become an actor. At 14, shortly after his mother's relapse, he registered with a theatrical agency in London's West End. The manager sensed potential in Chaplin, who was promptly given his first role as a newsboy in Harry Arthur Saintsbury's "Jim, a Romance of Cockayne". It opened in July 1903, but the show was unsuccessful and closed after two weeks. Chaplin's comic performance, however, was singled out for praise in many of the reviews.

Saintsbury secured a role for Chaplin in Charles Frohman's production of "Sherlock Holmes", where he played Billy the pageboy in three nationwide tours. His performance was so well received that he was called to London to play the role alongside William Gillette, the original Holmes. "It was like tidings from heaven", Chaplin recalled. At 16 years old, Chaplin starred in the play's West End production at the Duke of York's Theatre from October to December 1905. He completed one final tour of "Sherlock Holmes" in early 1906, before leaving the play after more than two-and-a-half years.

Chaplin soon found work with a new company, and went on tour with his brother – who was also pursuing an acting career – in a comedy sketch called "Repairs". In May 1906, Chaplin joined the juvenile act "Casey's Circus", where he developed popular burlesque pieces and was soon the star of the show. By the time the act finished touring in July 1907, the 18-year-old had become an accomplished comedic performer. He struggled to find more work, however, and a brief attempt at a solo act was a failure.

Meanwhile, Sydney Chaplin had joined Fred Karno's prestigious comedy company in 1906 and, by 1908, he was one of their key performers. In February, he managed to secure a two-week trial for his younger brother. Karno was initially wary, and considered Chaplin a "pale, puny, sullen-looking youngster" who "looked much too shy to do any good in the theatre." However, the teenager made an impact on his first night at the London Coliseum and he was quickly signed to a contract. Chaplin began by playing a series of minor parts, eventually progressing to starring roles in 1909. In April 1910, he was given the lead in a new sketch, "Jimmy the Fearless". It was a big success, and Chaplin received considerable press attention.

Karno selected his new star to join the section of the company, one that also included Stan Laurel, that toured North America's vaudeville circuit. The young comedian headed the show and impressed reviewers, being described as "one of the best pantomime artists ever seen here". His most successful role was a drunk called the "Inebriate Swell", which drew him significant recognition. The tour lasted 21 months, and the troupe returned to England in June 1912. Chaplin recalled that he "had a disquieting feeling of sinking back into a depressing commonplaceness" and was, therefore, delighted when a new tour began in October.

Six months into the second American tour, Chaplin was invited to join the New York Motion Picture Company. A representative who had seen his performances thought he could replace Fred Mace, a star of their Keystone Studios who intended to leave. Chaplin thought the Keystone comedies "a crude mélange of rough and rumble", but liked the idea of working in films and rationalised: "Besides, it would mean a new life." He met with the company and signed a $150-per-week ($ in dollars) contract in September 1913.

Chaplin arrived in Los Angeles, home of the Keystone studio, in early December 1913. His boss was Mack Sennett, who initially expressed concern that the 24-year-old looked too young. He was not used in a picture until late January, during which time Chaplin attempted to learn the processes of filmmaking. The one-reeler "Making a Living" marked his film acting debut and was released on 2 February 1914. Chaplin strongly disliked the picture, but one review picked him out as "a comedian of the first water". For his second appearance in front of the camera, Chaplin selected the costume with which he became identified. He described the process in his autobiography:

The film was "Mabel's Strange Predicament", but "the Tramp" character, as it became known, debuted to audiences in "Kid Auto Races at Venice" – shot later than "Mabel's Strange Predicament" but released two days earlier. Chaplin adopted the character as his screen persona and attempted to make suggestions for the films he appeared in. These ideas were dismissed by his directors. During the filming of his eleventh picture, "Mabel at the Wheel", he clashed with director Mabel Normand and was almost released from his contract. Sennett kept him on, however, when he received orders from exhibitors for more Chaplin films. Sennett also allowed Chaplin to direct his next film himself after Chaplin promised to pay $1,500 ($ in dollars) if the film was unsuccessful.

"Caught in the Rain", issued 4 May 1914, was Chaplin's directorial debut and was highly successful. Thereafter he directed almost every short film in which he appeared for Keystone, at the rate of approximately one per week, a period which he later remembered as the most exciting time of his career. Chaplin's films introduced a slower form of comedy than the typical Keystone farce, and he developed a large fan base. In November 1914, he had a supporting role in the first feature length comedy film, "Tillie's Punctured Romance", directed by Sennett and starring Marie Dressler, which was a commercial success and increased his popularity. When Chaplin's contract came up for renewal at the end of the year, he asked for $1,000 a week ($ in dollars) – an amount Sennett refused as too large.

The Essanay Film Manufacturing Company of Chicago sent Chaplin an offer of $1,250 a week with a signing bonus of $10,000. He joined the studio in late December 1914, where he began forming a stock company of regular players, including Leo White, Bud Jamison, Paddy McGuire and Billy Armstrong. He soon recruited a leading lady – Edna Purviance, whom Chaplin met in a cafe and hired on account of her beauty. She went on to appear in 35 films with Chaplin over eight years; the pair also formed a romantic relationship that lasted into 1917.

Chaplin asserted a high level of control over his pictures and started to put more time and care into each film. There was a month-long interval between the release of his second production, "A Night Out", and his third, "The Champion". The final seven of Chaplin's 14 Essanay films were all produced at this slower pace. Chaplin also began to alter his screen persona, which had attracted some criticism at Keystone for its "mean, crude, and brutish" nature. The character became more gentle and romantic; "The Tramp" (April 1915) was considered a particular turning point in his development. The use of pathos was developed further with "The Bank", in which Chaplin created a sad ending. Robinson notes that this was an innovation in comedy films, and marked the time when serious critics began to appreciate Chaplin's work. At Essanay, writes film scholar Simon Louvish, Chaplin "found the themes and the settings that would define the Tramp's world."

During 1915, Chaplin became a cultural phenomenon. Shops were stocked with Chaplin merchandise, he was featured in cartoons and comic strips, and several songs were written about him. In July, a journalist for "Motion Picture Magazine" wrote that "Chaplinitis" had spread across America. As his fame grew worldwide, he became the film industry's first international star. When the Essanay contract ended in December 1915, Chaplin – fully aware of his popularity – requested a $150,000 signing bonus from his next studio. He received several offers, including Universal, Fox, and Vitagraph, the best of which came from the Mutual Film Corporation at $10,000 a week.

A contract was negotiated with Mutual that amounted to $670,000 a year, which Robinson says made Chaplin – at 26 years old – one of the highest paid people in the world. The high salary shocked the public and was widely reported in the press. John R. Freuler, the studio president, explained: "We can afford to pay Mr. Chaplin this large sum annually because the public wants Chaplin and will pay for him."

Mutual gave Chaplin his own Los Angeles studio to work in, which opened in March 1916. He added two key members to his stock company, Albert Austin and Eric Campbell, and produced a series of elaborate two-reelers: "The Floorwalker", "The Fireman", "The Vagabond", "One A.M.", and "The Count". For "The Pawnshop", he recruited the actor Henry Bergman, who was to work with Chaplin for 30 years. "Behind the Screen" and "The Rink" completed Chaplin's releases for 1916. The Mutual contract stipulated that he release a two-reel film every four weeks, which he had managed to achieve. With the new year, however, Chaplin began to demand more time. He made only four more films for Mutual over the first ten months of 1917: "Easy Street", "The Cure", "The Immigrant", and "The Adventurer". With their careful construction, these films are considered by Chaplin scholars to be among his finest work. Later in life, Chaplin referred to his Mutual years as the happiest period of his career. However, Chaplin also felt that those films became increasingly formulaic over the period of the contract and he was increasingly dissatisfied with the working conditions encouraging that. 
Chaplin was attacked in the British media for not fighting in the First World War. He defended himself, revealing that he would fight for Britain if called and had registered for the American draft, but he was not summoned by either country. Despite this criticism Chaplin was a favourite with the troops, and his popularity continued to grow worldwide. "Harper's Weekly" reported that the name of Charlie Chaplin was "a part of the common language of almost every country", and that the Tramp image was "universally familiar". In 1917, professional Chaplin imitators were so widespread that he took legal action, and it was reported that nine out of ten men who attended costume parties dressed as the Tramp. The same year, a study by the Boston Society for Psychical Research concluded that Chaplin was "an American obsession". The actress Minnie Maddern Fiske wrote that "a constantly increasing body of cultured, artistic people are beginning to regard the young English buffoon, Charles Chaplin, as an extraordinary artist, as well as a comic genius".

Mutual were patient with Chaplin's decreased rate of output, and the contract ended amicably. With his aforementioned concern about the declining quality of his films because of contract scheduling stipulations, Chaplin's primary concern in finding a new distributor was independence; Sydney Chaplin, then his business manager, told the press, "Charlie [must] be allowed all the time he needs and all the money for producing [films] the way he wants ... It is quality, not quantity, we are after." In June 1917, Chaplin signed to complete eight films for First National Exhibitors' Circuit in return for $1 million. He chose to build his own studio, situated on five acres of land off Sunset Boulevard, with production facilities of the highest order. It was completed in January 1918, and Chaplin was given freedom over the making of his pictures.

"A Dog's Life", released April 1918, was the first film under the new contract. In it, Chaplin demonstrated his increasing concern with story construction and his treatment of the Tramp as "a sort of Pierrot". The film was described by Louis Delluc as "cinema's first total work of art". Chaplin then embarked on the Third Liberty Bond campaign, touring the United States for one month to raise money for the Allies of the First World War. He also produced a short propaganda film, donated to the government for fund-raising, called "The Bond". Chaplin's next release was war-based, placing the Tramp in the trenches for "Shoulder Arms". Associates warned him against making a comedy about the war but, as he later recalled: "Dangerous or not, the idea excited me." He spent four months filming the 45-minute-long picture, which was released in October 1918 with great success.

After the release of "Shoulder Arms", Chaplin requested more money from First National, which was refused. Frustrated with their lack of concern for quality, and worried about rumours of a possible merger between the company and Famous Players-Lasky, Chaplin joined forces with Douglas Fairbanks, Mary Pickford, and D. W. Griffith to form a new distribution company – United Artists, established in January 1919. The arrangement was revolutionary in the film industry, as it enabled the four partners – all creative artists – to personally fund their pictures and have complete control. Chaplin was eager to start with the new company and offered to buy out his contract with First National. They refused and insisted that he complete the final six films owed.

Before the creation of United Artists, Chaplin married for the first time. The 16-year-old actress Mildred Harris had revealed that she was pregnant with his child, and in September 1918, he married her quietly in Los Angeles to avoid controversy. Soon after, the pregnancy was found to be false. Chaplin was unhappy with the union and, feeling that marriage stunted his creativity, struggled over the production of his film "Sunnyside". Harris was by then legitimately pregnant, and on 7 July 1919, gave birth to a son. Norman Spencer Chaplin was born malformed and died three days later. The marriage ended in April 1920, with Chaplin explaining in his autobiography that they were "irreconcilably mismated".

Losing the child, plus his own childhood experiences, are thought to have influenced Chaplin's film, which turned the Tramp into the caretaker of a young boy. For this new venture, Chaplin also wished to do more than comedy and, according to Louvish, "make his mark on a changed world." Filming on "The Kid" began in August 1919, with four-year-old Jackie Coogan his co-star. It was developing into a long project, so to placate First National, he halted production and quickly filmed "A Day's Pleasure". "The Kid" was in production for nine months until May 1920 and, at 68 minutes, it was Chaplin's longest picture to date. Dealing with issues of poverty and parent–child separation, "The Kid" was one of the earliest films to combine comedy and drama. It was released in January 1921 with instant success, and, by 1924, had been screened in over 50 countries.

Chaplin spent five months on his next film, the two-reeler "The Idle Class". Following its September 1921 release, he chose to return to England for the first time in almost a decade. He then worked to fulfil his First National contract, releasing "Pay Day" in February 1922. "The Pilgrim" – his final short film – was delayed by distribution disagreements with the studio, and released a year later.

Having fulfilled his First National contract, Chaplin was free to make his first picture as an independent producer. In November 1922, he began filming "A Woman of Paris", a romantic drama about ill-fated lovers. Chaplin intended it to be a star-making vehicle for Edna Purviance, and did not appear in the picture himself other than in a brief, uncredited cameo. He wished the film to have a realistic feel and directed his cast to give restrained performances. In real life, he explained, "men and women try to hide their emotions rather than seek to express them". "A Woman of Paris" premiered in September 1923 and was acclaimed for its innovative, subtle approach. The public, however, seemed to have little interest in a Chaplin film without Chaplin, and it was a box office disappointment. The filmmaker was hurt by this failure – he had long wanted to produce a dramatic film and was proud of the result – and soon withdrew "A Woman of Paris" from circulation.

Chaplin returned to comedy for his next project. Setting his standards high, he told himself "This next film must be an epic! The Greatest!" Inspired by a photograph of the 1898 Klondike Gold Rush, and later the story of the Donner Party of 1846–47, he made what Geoffrey Macnab calls "an epic comedy out of grim subject matter." In "The Gold Rush", the Tramp is a lonely prospector fighting adversity and looking for love. With Georgia Hale as his new leading lady, Chaplin began filming the picture in February 1924. Its elaborate production, costing almost $1 million, included location shooting in the Truckee mountains with 600 extras, extravagant sets, and special effects. The last scene was shot May 1925 after 15 months of filming.

Chaplin felt "The Gold Rush" was the best film he had made. It opened in August 1925 and became one of the highest-grossing films of the silent era with a U.S. box-office of $5 million. The comedy contains some of Chaplin's most famous sequences, such as the Tramp eating his shoe and the "Dance of the Rolls". Macnab has called it "the quintessential Chaplin film". Chaplin stated at its release, "This is the picture that I want to be remembered by".

While making "The Gold Rush", Chaplin married for the second time. Mirroring the circumstances of his first union, Lita Grey was a teenage actress, originally set to star in the film, whose surprise announcement of pregnancy forced Chaplin into marriage. She was 16 and he was 35, meaning Chaplin could have been charged with statutory rape under California law. He therefore arranged a discreet marriage in Mexico on 25 November 1924. Their first son, Charles Spencer Chaplin, Jr., was born on 5 May 1925, followed by Sydney Earl Chaplin on 30 March 1926.

It was an unhappy marriage, and Chaplin spent long hours at the studio to avoid seeing his wife. In November 1926, Grey took the children and left the family home. A bitter divorce followed, in which Grey's application – accusing Chaplin of infidelity, abuse, and of harbouring "perverted sexual desires" – was leaked to the press. Chaplin was reported to be in a state of nervous breakdown, as the story became headline news and groups formed across America calling for his films to be banned. Eager to end the case without further scandal, Chaplin's lawyers agreed to a cash settlement of $600,000the largest awarded by American courts at that time. His fan base was strong enough to survive the incident, and it was soon forgotten, but Chaplin was deeply affected by it.

Before the divorce suit was filed, Chaplin had begun work on a new film, "The Circus". He built a story around the idea of walking a tightrope while besieged by monkeys, and turned the Tramp into the accidental star of a circus. Filming was suspended for 10 months while he dealt with the divorce scandal, and it was generally a trouble-ridden production. Finally completed in October 1927, "The Circus" was released in January 1928 to a positive reception. At the 1st Academy Awards, Chaplin was given a special trophy "For versatility and genius in acting, writing, directing and producing "The Circus"". Despite its success, he permanently associated the film with the stress of its production; Chaplin omitted "The Circus" from his autobiography, and struggled to work on it when he recorded the score in his later years.

By the time "The Circus" was released, Hollywood had witnessed the introduction of sound films. Chaplin was cynical about this new medium and the technical shortcomings it presented, believing that "talkies" lacked the artistry of silent films. He was also hesitant to change the formula that had brought him such success, and feared that giving the Tramp a voice would limit his international appeal. He, therefore, rejected the new Hollywood craze and began work on a new silent film. Chaplin was nonetheless anxious about this decision and remained so throughout the film's production.

When filming began at the end of 1928, Chaplin had been working on the story for almost a year. "City Lights" followed the Tramp's love for a blind flower girl (played by Virginia Cherrill) and his efforts to raise money for her sight-saving operation. It was a challenging production that lasted 21 months, with Chaplin later confessing that he "had worked himself into a neurotic state of wanting perfection". One advantage Chaplin found in sound technology was the opportunity to record a musical score for the film, which he composed himself.

Chaplin finished editing "City Lights" in December 1930, by which time silent films were an anachronism. A preview before an unsuspecting public audience was not a success, but a showing for the press produced positive reviews. One journalist wrote, "Nobody in the world but Charlie Chaplin could have done it. He is the only person that has that peculiar something called 'audience appeal' in sufficient quality to defy the popular penchant for movies that talk." Given its general release in January 1931, "City Lights" proved to be a popular and financial success – eventually grossing over $3 million. The British Film Institute cites it as Chaplin's finest accomplishment, and the critic James Agee hails the closing scene as "the greatest piece of acting and the highest moment in movies". "City Lights" became Chaplin's personal favourite of his films and remained so throughout his life.

"City Lights" had been a success, but Chaplin was unsure if he could make another picture without dialogue. He remained convinced that sound would not work in his films, but was also "obsessed by a depressing fear of being old-fashioned." In this state of uncertainty, early in 1931, the comedian decided to take a holiday and ended up travelling for 16 months. He spent months travelling Western Europe, including extended stays in France and Switzerland, and spontaneously decided to visit Japan. The day after he arrived in Japan, Prime Minister Inukai Tsuyoshi was assassinated by ultra-nationalists in the May 15 Incident. The group's original plan had been to provoke a war with the United States by assassinating Chaplin at a welcome reception organised by the prime minister, but the plan had been foiled due to delayed public announcement of the event's date.

In his autobiography, Chaplin recalled that on his return to Los Angeles, "I was confused and without plan, restless and conscious of an extreme loneliness". He briefly considered retiring and moving to China. Chaplin's loneliness was relieved when he met 21-year-old actress Paulette Goddard in July 1932, and the pair began a relationship. He was not ready to commit to a film, however, and focused on writing a serial about his travels (published in "Woman's Home Companion"). The trip had been a stimulating experience for Chaplin, including meetings with several prominent thinkers, and he became increasingly interested in world affairs. The state of labour in America troubled him, and he feared that capitalism and machinery in the workplace would increase unemployment levels. It was these concerns that stimulated Chaplin to develop his new film.

"Modern Times" was announced by Chaplin as "a satire on certain phases of our industrial life." Featuring the Tramp and Goddard as they endure the Great Depression, it took ten and a half months to film. Chaplin intended to use spoken dialogue but changed his mind during rehearsals. Like its predecessor, "Modern Times" employed sound effects but almost no speaking. Chaplin's performance of a gibberish song did, however, give the Tramp a voice for the only time on film. After recording the music, Chaplin released "Modern Times" in February 1936. It was his first feature in 15 years to adopt political references and social realism, a factor that attracted considerable press coverage despite Chaplin's attempts to downplay the issue. The film earned less at the box-office than his previous features and received mixed reviews, as some viewers disliked the politicising. Today, "Modern Times" is seen by the British Film Institute as one of Chaplin's "great features," while David Robinson says it shows the filmmaker at "his unrivalled peak as a creator of visual comedy."

Following the release of "Modern Times", Chaplin left with Goddard for a trip to the Far East. The couple had refused to comment on the nature of their relationship, and it was not known whether they were married or not. Some time later, Chaplin revealed that they married in Canton during this trip. By 1938, the couple had drifted apart, as both focused heavily on their work, although Goddard was again his leading lady in his next feature film, "The Great Dictator". She eventually divorced Chaplin in Mexico in 1942, citing incompatibility and separation for more than a year.

The 1940s saw Chaplin face a series of controversies, both in his work and in his personal life, which changed his fortunes and severely affected his popularity in the United States. The first of these was his growing boldness in expressing his political beliefs. Deeply disturbed by the surge of militaristic nationalism in 1930s world politics, Chaplin found that he could not keep these issues out of his work. Parallels between himself and Adolf Hitler had been widely noted: the pair were born four days apart, both had risen from poverty to world prominence, and Hitler wore the same toothbrush moustache as Chaplin. It was this physical resemblance that supplied the plot for Chaplin's next film, "The Great Dictator", which directly satirised Hitler and attacked fascism.

Chaplin spent two years developing the script, and began filming in September 1939 – six days after Britain declared war on Germany. He had submitted to using spoken dialogue, partly out of acceptance that he had no other choice, but also because he recognised it as a better method for delivering a political message. Making a comedy about Hitler was seen as highly controversial, but Chaplin's financial independence allowed him to take the risk. "I was determined to go ahead," he later wrote, "for Hitler must be laughed at." Chaplin replaced the Tramp (while wearing similar attire) with "A Jewish Barber", a reference to the Nazi party's belief that he was Jewish. In a dual performance, he also played the dictator "Adenoid Hynkel", who parodied Hitler.

"The Great Dictator" spent a year in production and was released in October 1940. The film generated a vast amount of publicity, with a critic for "The New York Times" calling it "the most eagerly awaited picture of the year", and it was one of the biggest money-makers of the era. The ending was unpopular, however, and generated controversy. Chaplin concluded the film with a five-minute speech in which he abandoned his barber character, looked directly into the camera, and pleaded against war and fascism. Charles J. Maland has identified this overt preaching as triggering a decline in Chaplin's popularity, and writes, "Henceforth, no movie fan would ever be able to separate the dimension of politics from [his] star image". "The Great Dictator" received five Academy Award nominations, including Best Picture, Best Original Screenplay and Best Actor.

In the mid-1940s, Chaplin was involved in a series of trials that occupied most of his time and significantly affected his public image. The troubles stemmed from his affair with an aspirant actress named Joan Barry, with whom he was involved intermittently between June 1941 and the autumn of 1942. Barry, who displayed obsessive behaviour and was twice arrested after they separated, reappeared the following year and announced that she was pregnant with Chaplin's child. As Chaplin denied the claim, Barry filed a paternity suit against him.

The director of the Federal Bureau of Investigation (FBI), J. Edgar Hoover, who had long been suspicious of Chaplin's political leanings, used the opportunity to generate negative publicity about him. As part of a smear campaign to damage Chaplin's image, the FBI named him in four indictments related to the Barry case. Most serious of these was an alleged violation of the Mann Act, which prohibits the transportation of women across state boundaries for sexual purposes. The historian Otto Friedrich has called this an "absurd prosecution" of an "ancient statute", yet if Chaplin was found guilty, he faced 23 years in jail. Three charges lacked sufficient evidence to proceed to court, but the Mann Act trial began in March 1944. Chaplin was acquitted two weeks later. The case was frequently headline news, with "Newsweek" calling it the "biggest public relations scandal since the Fatty Arbuckle murder trial in 1921."

Barry's child, Carol Ann, was born in October 1944, and the paternity suit went to court in February 1945. After two arduous trials, in which the prosecuting lawyer accused him of "moral turpitude", Chaplin was declared to be the father. Evidence from blood tests which indicated otherwise were not admissible, and the judge ordered Chaplin to pay child support until Carol Ann turned 21. Media coverage of the paternity suit was influenced by the FBI, as information was fed to the prominent gossip columnist Hedda Hopper, and Chaplin was portrayed in an overwhelmingly critical light.

The controversy surrounding Chaplin increased when, two weeks after the paternity suit was filed, it was announced that he had married his newest protégée, 18-year-old Oona O'Neill – daughter of the American playwright Eugene O'Neill. Chaplin, then 54, had been introduced to her by a film agent seven months earlier. In his autobiography, Chaplin described meeting O'Neill as "the happiest event of my life", and claimed to have found "perfect love". Chaplin's son, Charles Jr., reported that Oona "worshipped" his father. The couple remained married until Chaplin's death, and had eight children over 18 years: Geraldine Leigh (b. July 1944), Michael John (b. March 1946), Josephine Hannah (b. March 1949), Victoria (b. May 1951), Eugene Anthony (b. August 1953), Jane Cecil (b. May 1957), Annette Emily (b. December 1959), and Christopher James (b. July 1962).

Chaplin claimed that the Barry trials had "crippled [his] creativeness", and it was some time before he began working again. In April 1946, he finally began filming a project that had been in development since 1942. "Monsieur Verdoux" was a black comedy, the story of a French bank clerk, Verdoux (Chaplin), who loses his job and begins marrying and murdering wealthy widows to support his family. Chaplin's inspiration for the project came from Orson Welles, who wanted him to star in a film about the French serial killer Henri Désiré Landru. Chaplin decided that the concept would "make a wonderful comedy", and paid Welles $5,000 for the idea.

Chaplin again vocalised his political views in "Monsieur Verdoux", criticising capitalism and arguing that the world encourages mass killing through wars and weapons of mass destruction. Because of this, the film met with controversy when it was released in April 1947; Chaplin was booed at the premiere, and there were calls for a boycott. "Monsieur Verdoux" was the first Chaplin release that failed both critically and commercially in the United States. It was more successful abroad, and Chaplin's screenplay was nominated at the Academy Awards. He was proud of the film, writing in his autobiography, ""Monsieur Verdoux" is the cleverest and most brilliant film I have yet made."

The negative reaction to "Monsieur Verdoux" was largely the result of changes in Chaplin's public image. Along with damage of the Joan Barry scandal, he was publicly accused of being a communist. His political activity had heightened during World War II, when he campaigned for the opening of a Second Front to help the Soviet Union and supported various Soviet–American friendship groups. He was also friendly with several suspected communists, and attended functions given by Soviet diplomats in Los Angeles. In the political climate of 1940s America, such activities meant Chaplin was considered, as Larcher writes, "dangerously progressive and amoral." The FBI wanted him out of the country, and launched an official investigation in early 1947.

Chaplin denied being a communist, instead calling himself a "peacemonger", but felt the government's effort to suppress the ideology was an unacceptable infringement of civil liberties. Unwilling to be quiet about the issue, he openly protested against the trials of Communist Party members and the activities of the House Un-American Activities Committee. Chaplin received a subpoena to appear before HUAC but was not called to testify. As his activities were widely reported in the press, and Cold War fears grew, questions were raised over his failure to take American citizenship. Calls were made for him to be deported; in one extreme and widely published example, Representative John E. Rankin, who helped establish HUAC, told Congress in June 1947: "[Chaplin's] very life in Hollywood is detrimental to the moral fabric of America. [If he is deported] ... his loathsome pictures can be kept from before the eyes of the American youth. He should be deported and gotten rid of at once."

Although Chaplin remained politically active in the years following the failure of "Monsieur Verdoux", his next film, about a forgotten vaudeville comedian and a young ballerina in Edwardian London, was devoid of political themes. "Limelight" was heavily autobiographical, alluding not only to Chaplin's childhood and the lives of his parents, but also to his loss of popularity in the United States. The cast included various members of his family, including his five oldest children and his half-brother, Wheeler Dryden.

Filming began in November 1951, by which time Chaplin had spent three years working on the story. He aimed for a more serious tone than any of his previous films, regularly using the word "melancholy" when explaining his plans to his co-star Claire Bloom. "Limelight" featured a cameo appearance from Buster Keaton, whom Chaplin cast as his stage partner in a pantomime scene. This marked the only time the comedians worked together.

Chaplin decided to hold the world premiere of "Limelight" in London, since it was the setting of the film. As he left Los Angeles, he expressed a premonition that he would not be returning. At New York, he boarded the with his family on 18 September 1952. The next day, attorney general James P. McGranery revoked Chaplin's re-entry permit and stated that he would have to submit to an interview concerning his political views and moral behaviour in order to re-enter the US. Although McGranery told the press that he had "a pretty good case against Chaplin", Maland has concluded, on the basis of the FBI files that were released in the 1980s, that the US government had no real evidence to prevent Chaplin's re-entry. It is likely that he would have gained entry if he had applied for it. However, when Chaplin received a cablegram informing him of the news, he privately decided to cut his ties with the United States:

Because all of his property remained in America, Chaplin refrained from saying anything negative about the incident to the press. The scandal attracted vast attention, but Chaplin and his film were warmly received in Europe. In America, the hostility towards him continued, and, although it received some positive reviews, "Limelight" was subjected to a wide-scale boycott. Reflecting on this, Maland writes that Chaplin's fall, from an "unprecedented" level of popularity, "may be the most dramatic in the history of stardom in America".

Chaplin did not attempt to return to the United States after his re-entry permit was revoked, and instead sent his wife to settle his affairs. The couple decided to settle in Switzerland and, in January 1953, the family moved into their permanent home: Manoir de Ban, a estate overlooking Lake Geneva in Corsier-sur-Vevey. Chaplin put his Beverly Hills house and studio up for sale in March, and surrendered his re-entry permit in April. The next year, his wife renounced her US citizenship and became a British citizen. Chaplin severed the last of his professional ties with the United States in 1955, when he sold the remainder of his stock in United Artists, which had been in financial difficulty since the early 1940s.

Chaplin remained a controversial figure throughout the 1950s, especially after he was awarded the International Peace Prize by the communist-led World Peace Council, and after his meetings with Zhou Enlai and Nikita Khrushchev. He began developing his first European film, "A King in New York", in 1954. Casting himself as an exiled king who seeks asylum in the United States, Chaplin included several of his recent experiences in the screenplay. His son, Michael, was cast as a boy whose parents are targeted by the FBI, while Chaplin's character faces accusations of communism. The political satire parodied HUAC and attacked elements of 1950s culture – including consumerism, plastic surgery, and wide-screen cinema. In a review, the playwright John Osborne called it Chaplin's "most bitter" and "most openly personal" film.

Chaplin founded a new production company, Attica, and used Shepperton Studios for the shooting. Filming in England proved a difficult experience, as he was used to his own Hollywood studio and familiar crew, and no longer had limitless production time. According to Robinson, this had an effect on the quality of the film. "A King in New York" was released in September 1957, and received mixed reviews. Chaplin banned American journalists from its Paris première and decided not to release the film in the United States. This severely limited its revenue, although it achieved moderate commercial success in Europe. "A King in New York" was not shown in America until 1973.

In the last two decades of his career, Chaplin concentrated on re-editing and scoring his old films for re-release, along with securing their ownership and distribution rights. In an interview he granted in 1959, the year of his 70th birthday, Chaplin stated that there was still "room for the Little Man in the atomic age". The first of these re-releases was "The Chaplin Revue" (1959), which included new versions of "A Dog's Life", "Shoulder Arms", and "The Pilgrim".

In America, the political atmosphere began to change and attention was once again directed to Chaplin's films instead of his views. In July 1962, "The New York Times" published an editorial stating that "we do not believe the Republic would be in danger if yesterday's unforgotten little tramp were allowed to amble down the gangplank of a steamer or plane in an American port". The same month, Chaplin was invested with the honorary degree of Doctor of Letters by the universities of Oxford and Durham. In November 1963, the Plaza Theater in New York started a year-long series of Chaplin's films, including "Monsieur Verdoux" and "Limelight", which gained excellent reviews from American critics. September 1964 saw the release of Chaplin's memoirs, "My Autobiography", which he had been working on since 1957. The 500-page book, which focused on his early years and personal life, became a worldwide best-seller, despite criticism over the lack of information on his film career.

Shortly after the publication of his memoirs, Chaplin began work on "A Countess from Hong Kong" (1967), a romantic comedy based on a script he had written for Paulette Goddard in the 1930s. Set on an ocean liner, it starred Marlon Brando as an American ambassador and Sophia Loren as a stowaway found in his cabin. The film differed from Chaplin's earlier productions in several aspects. It was his first to use Technicolor and the widescreen format, while he concentrated on directing and appeared on-screen only in a cameo role as a seasick steward. He also signed a deal with Universal Pictures and appointed his assistant, Jerome Epstein, as the producer. Chaplin was paid $600,000 director's fee as well as a percentage of the gross receipts. "A Countess from Hong Kong" premiered in January 1967, to unfavourable reviews, and was a box-office failure. Chaplin was deeply hurt by the negative reaction to the film, which turned out to be his last.

Chaplin suffered a series of minor strokes in the late 1960s, which marked the beginning of a slow decline in his health. Despite the setbacks, he was soon writing a new film script, "The Freak", a story of a winged girl found in South America, which he intended as a starring vehicle for his daughter, Victoria. His fragile health prevented the project from being realised. In the early 1970s, Chaplin concentrated on re-releasing his old films, including "The Kid" and "The Circus". In 1971, he was made a Commander of the National Order of the Legion of Honour at the Cannes Film Festival. The following year, he was honoured with a special award by the Venice Film Festival.

In 1972, the Academy of Motion Picture Arts and Sciences offered Chaplin an Honorary Award, which Robinson sees as a sign that America "wanted to make amends". Chaplin was initially hesitant about accepting but decided to return to the US for the first time in 20 years. The visit attracted a large amount of press coverage and, at the Academy Awards gala, he was given a twelve-minute standing ovation, the longest in the Academy's history. Visibly emotional, Chaplin accepted his award for "the incalculable effect he has had in making motion pictures the art form of this century".

Although Chaplin still had plans for future film projects, by the mid-1970s he was very frail. He experienced several further strokes, which made it difficult for him to communicate, and he had to use a wheelchair. His final projects were compiling a pictorial autobiography, "My Life in Pictures" (1974) and scoring "A Woman of Paris" for re-release in 1976. He also appeared in a documentary about his life, "The Gentleman Tramp" (1975), directed by Richard Patterson. In the 1975 New Year Honours, Chaplin was awarded a knighthood by Queen Elizabeth II, though he was too weak to kneel and received the honour in his wheelchair.

By October 1977, Chaplin's health had declined to the point that he needed constant care. In the early morning of 25 December 1977, Chaplin died at home after suffering a stroke in his sleep. He was 88 years old. The funeral, on 27 December, was a small and private Anglican ceremony, according to his wishes. Chaplin was interred in the Corsier-sur-Vevey cemetery. Among the film industry's tributes, director René Clair wrote, "He was a monument of the cinema, of all countries and all times ... the most beautiful gift the cinema made to us." Actor Bob Hope declared, "We were lucky to have lived in his time."

On 1 March 1978, Chaplin's coffin was dug up and stolen from its grave by two unemployed immigrants, Roman Wardas, from Poland, and Gantcho Ganev, from Bulgaria. The body was held for ransom in an attempt to extort money from Oona Chaplin. The pair were caught in a large police operation in May, and Chaplin's coffin was found buried in a field in the nearby village of Noville. It was re-interred in the Corsier cemetery surrounded by reinforced concrete.

Chaplin believed his first influence to be his mother, who entertained him as a child by sitting at the window and mimicking passers-by: "it was through watching her that I learned not only how to express emotions with my hands and face, but also how to observe and study people." Chaplin's early years in music hall allowed him to see stage comedians at work; he also attended the Christmas pantomimes at Drury Lane, where he studied the art of clowning through performers like Dan Leno. Chaplin's years with the Fred Karno company had a formative effect on him as an actor and filmmaker. Simon Louvish writes that the company was his "training ground", and it was here that Chaplin learned to vary the pace of his comedy. The concept of mixing pathos with slapstick was learnt from Karno, who also used elements of absurdity that became familiar in Chaplin's gags. From the film industry, Chaplin drew upon the work of the French comedian Max Linder, whose films he greatly admired. In developing the Tramp costume and persona, he was likely inspired by the American vaudeville scene, where tramp characters were common.

Chaplin never spoke more than cursorily about his filmmaking methods, claiming such a thing would be tantamount to a magician spoiling his own illusion. Little was known about his working process throughout his lifetime, but research from film historians – particularly the findings of Kevin Brownlow and David Gill that were presented in the three-part documentary "Unknown Chaplin" (1983) – has since revealed his unique working method.

Until he began making spoken dialogue films with "The Great Dictator", Chaplin never shot from a completed script. Many of his early films began with only a vague premise – for example "Charlie enters a health spa" or "Charlie works in a pawn shop." He then had sets constructed and worked with his stock company to improvise gags and "business" using them, almost always working the ideas out on film. As ideas were accepted and discarded, a narrative structure would emerge, frequently requiring Chaplin to reshoot an already-completed scene that might have otherwise contradicted the story. From "A Woman of Paris" onward Chaplin began the filming process with a prepared plot, but Robinson writes that every film up to "Modern Times" "went through many metamorphoses and permutations before the story took its final form."

Producing films in this manner meant Chaplin took longer to complete his pictures than almost any other filmmaker at the time. If he was out of ideas, he often took a break from the shoot, which could last for days, while keeping the studio ready for when inspiration returned. Delaying the process further was Chaplin's rigorous perfectionism. According to his friend Ivor Montagu, "nothing but perfection would be right" for the filmmaker. Because he personally funded his films, Chaplin was at liberty to strive for this goal and shoot as many takes as he wished. The number was often excessive, for instance 53 takes for every finished take in "The Kid". For "The Immigrant", a 20 minute-short, Chaplin shot 40,000 feet of film – enough for a feature-length.

Describing his working method as "sheer perseverance to the point of madness", Chaplin would be completely consumed by the production of a picture. Robinson writes that even in Chaplin's later years, his work continued "to take precedence over everything and everyone else." The combination of story improvisation and relentless perfectionism – which resulted in days of effort and thousands of feet of film being wasted, all at enormous expense – often proved taxing for Chaplin who, in frustration, would lash out at his actors and crew.

Chaplin exercised complete control over his pictures, to the extent that he would act out the other roles for his cast, expecting them to imitate him exactly. He personally edited all of his films, trawling through the large amounts of footage to create the exact picture he wanted. As a result of his complete independence, he was identified by the film historian Andrew Sarris as one of the first auteur filmmakers. Chaplin did receive help, notably from his long-time cinematographer Roland Totheroh, brother Sydney Chaplin, and various assistant directors such as Harry Crocker and Charles Reisner.

While Chaplin's comedic style is broadly defined as slapstick, it is considered restrained and intelligent, with the film historian Philip Kemp describing his work as a mix of "deft, balletic physical comedy and thoughtful, situation-based gags". Chaplin diverged from conventional slapstick by slowing the pace and exhausting each scene of its comic potential, with more focus on developing the viewer's relationship to the characters. Unlike conventional slapstick comedies, Robinson states that the comic moments in Chaplin's films centre on the Tramp's attitude to the things happening to him: the humour does not come from the Tramp bumping into a tree, but from his lifting his hat to the tree in apology. Dan Kamin writes that Chaplin's "quirky mannerisms" and "serious demeanour in the midst of slapstick action" are other key aspects of his comedy, while the surreal transformation of objects and the employment of in-camera trickery are also common features.

Chaplin's silent films typically follow the Tramp's efforts to survive in a hostile world. The character lives in poverty and is frequently treated badly, but remains kind and upbeat; defying his social position, he strives to be seen as a gentleman. As Chaplin said in 1925, "The whole point of the Little Fellow is that no matter how down on his ass he is, no matter how well the jackals succeed in tearing him apart, he's still a man of dignity." The Tramp defies authority figures and "gives as good as he gets", leading Robinson and Louvish to see him as a representative for the underprivileged – an "everyman turned heroic saviour". Hansmeyer notes that several of Chaplin's films end with "the homeless and lonely Tramp [walking] optimistically ... into the sunset ... to continue his journey".

The infusion of pathos is a well-known aspect of Chaplin's work, and Larcher notes his reputation for "[inducing] laughter and tears". Sentimentality in his films comes from a variety of sources, with Louvish pinpointing "personal failure, society's strictures, economic disaster, and the elements." Chaplin sometimes drew on tragic events when creating his films, as in the case of "The Gold Rush" (1925), which was inspired by the fate of the Donner Party. Constance B. Kuriyama has identified serious underlying themes in the early comedies, such as greed ("The Gold Rush") and loss ("The Kid"). Chaplin also touched on controversial issues: immigration ("The Immigrant", 1917); illegitimacy ("The Kid", 1921); and drug use ("Easy Street", 1917). He often explored these topics ironically, making comedy out of suffering.

Social commentary was a feature of Chaplin's films from early in his career, as he portrayed the underdog in a sympathetic light and highlighted the difficulties of the poor. Later, as he developed a keen interest in economics and felt obliged to publicise his views, Chaplin began incorporating overtly political messages into his films. "Modern Times" (1936) depicted factory workers in dismal conditions, "The Great Dictator" (1940) parodied Adolf Hitler and Benito Mussolini and ended in a speech against nationalism, "Monsieur Verdoux" (1947) criticised war and capitalism, and "A King in New York" (1957) attacked McCarthyism.

Several of Chaplin's films incorporate autobiographical elements, and the psychologist Sigmund Freud believed that Chaplin "always plays only himself as he was in his dismal youth". "The Kid" is thought to reflect Chaplin's childhood trauma of being sent into an orphanage, the main characters in "Limelight" (1952) contain elements from the lives of his parents, and "A King in New York" references Chaplin's experiences of being shunned by the United States. Many of his sets, especially in street scenes, bear a strong similarity to Kennington, where he grew up. Stephen M. Weissman has argued that Chaplin's problematic relationship with his mentally ill mother was often reflected in his female characters and the Tramp's desire to save them.

Regarding the structure of Chaplin's films, the scholar Gerald Mast sees them as consisting of sketches tied together by the same theme and setting, rather than having a tightly unified storyline. Visually, his films are simple and economic, with scenes portrayed as if set on a stage. His approach to filming was described by the art director Eugène Lourié: "Chaplin did not think in 'artistic' images when he was shooting. He believed that action is the main thing. The camera is there to photograph the actors". In his autobiography, Chaplin wrote, "Simplicity is best ... pompous effects slow up action, are boring and unpleasant ... The camera should not intrude." This approach has prompted criticism, since the 1940s, for being "old fashioned", while the film scholar Donald McCaffrey sees it as an indication that Chaplin never completely understood film as a medium. Kamin, however, comments that Chaplin's comedic talent would not be enough to remain funny on screen if he did not have an "ability to conceive and direct scenes specifically for the film medium".

Chaplin developed a passion for music as a child and taught himself to play the piano, violin, and cello. He considered the musical accompaniment of a film to be important, and from "A Woman of Paris" onwards he took an increasing interest in this area. With the advent of sound technology, Chaplin began using a synchronised orchestral soundtrack – composed by himself – for "City Lights" (1931). He thereafter composed the scores for all of his films, and from the late 1950s to his death, he scored all of his silent features and some of his short films.

As Chaplin was not a trained musician, he could not read sheet music and needed the help of professional composers, such as David Raksin, Raymond Rasch and Eric James, when creating his scores. Musical directors were employed to oversee the recording process, such as Alfred Newman for "City Lights". Although some critics have claimed that credit for his film music should be given to the composers who worked with him, Raksin – who worked with Chaplin on "Modern Times" – stressed Chaplin's creative position and active participation in the composing process. This process, which could take months, would start with Chaplin describing to the composer(s) exactly what he wanted and singing or playing tunes he had improvised on the piano. These tunes were then developed further in a close collaboration among the composer(s) and Chaplin. According to film historian Jeffrey Vance, "although he relied upon associates to arrange varied and complex instrumentation, the musical imperative is his, and not a note in a Chaplin musical score was placed there without his assent."

Chaplin's compositions produced three popular songs. "Smile", composed originally for "Modern Times" (1936) and later set to lyrics by John Turner and Geoffrey Parsons, was a hit for Nat King Cole in 1954. For "Limelight", Chaplin composed "Terry's Theme", which was popularised by Jimmy Young as "Eternally" (1952). Finally, "This Is My Song", performed by Petula Clark for "A Countess from Hong Kong" (1967), reached number one on the UK and other European charts. Chaplin also received his only competitive Oscar for his composition work, as the "Limelight" theme won an Academy Award for Best Original Score in 1973 following the film's re-release.

In 1998, the film critic Andrew Sarris called Chaplin "arguably the single most important artist produced by the cinema, certainly its most extraordinary performer and probably still its most universal icon". He is described by the British Film Institute as "a towering figure in world culture", and was included in "Time" magazine's list of the "" for the "laughter [he brought] to millions" and because he "more or less invented global recognizability and helped turn an industry into an art".

The image of the Tramp has become a part of cultural history; according to Simon Louvish, the character is recognisable to people who have never seen a Chaplin film, and in places where his films are never shown. The critic Leonard Maltin has written of the "unique" and "indelible" nature of the Tramp, and argued that no other comedian matched his "worldwide impact". Praising the character, Richard Schickel suggests that Chaplin's films with the Tramp contain the most "eloquent, richly comedic expressions of the human spirit" in movie history. Memorabilia connected to the character still fetches large sums in auctions: in 2006 a bowler hat and a bamboo cane that were part of the Tramp's costume were bought for $140,000 in a Los Angeles auction.

As a filmmaker, Chaplin is considered a pioneer and one of the most influential figures of the early twentieth century. He is often credited as one of the medium's first artists. Film historian Mark Cousins has written that Chaplin "changed not only the imagery of cinema, but also its sociology and grammar" and claims that Chaplin was as important to the development of comedy as a genre as D.W. Griffith was to drama. He was the first to popularise feature-length comedy and to slow down the pace of action, adding pathos and subtlety to it. Although his work is mostly classified as slapstick, Chaplin's drama "A Woman of Paris" (1923) was a major influence on Ernst Lubitsch's film "The Marriage Circle" (1924) and thus played a part in the development of "sophisticated comedy". According to David Robinson, Chaplin's innovations were "rapidly assimilated to become part of the common practice of film craft." Filmmakers who cited Chaplin as an influence include Federico Fellini (who called Chaplin "a sort of Adam, from whom we are all descended"), Jacques Tati ("Without him I would never have made a film"), René Clair ("He inspired practically every filmmaker"), Michael Powell, Billy Wilder, Vittorio De Sica, and Richard Attenborough. Russian filmmaker Andrei Tarkovsky praised Chaplin as "the only person to have gone down into cinematic history without any shadow of a doubt. The films he left behind can never grow old."

Chaplin also strongly influenced the work of later comedians. Marcel Marceau said he was inspired to become a mime artist after watching Chaplin, while the actor Raj Kapoor based his screen persona on the Tramp. Mark Cousins has also detected Chaplin's comedic style in the French character Monsieur Hulot and the Italian character Totò. In other fields, Chaplin helped inspire the cartoon characters Felix the Cat and Mickey Mouse, and was an influence on the Dada art movement. As one of the founding members of United Artists, Chaplin also had a role in the development of the film industry. Gerald Mast has written that although UA never became a major company like MGM or Paramount Pictures, the idea that directors could produce their own films was "years ahead of its time".

In the 21st century, several of Chaplin's films are still regarded as classics and among the greatest ever made. The 2012 "Sight & Sound" poll, which compiles "top ten" ballots from film critics and directors to determine each group's most acclaimed films,
saw "City Lights" rank among the critics' top 50, "Modern Times" inside the top 100, and "The Great Dictator" and "The Gold Rush" placed in the top 250. The top 100 films as voted on by directors included "Modern Times" at number 22, "City Lights" at number 30, and "The Gold Rush" at number 91. Every one of Chaplin's features received a vote. In 2007, the American Film Institute named "City Lights" the 11th greatest American film of all time, while "The Gold Rush" and "Modern Times" again ranked in the top 100. Books about Chaplin continue to be published regularly, and he is a popular subject for media scholars and film archivists. Many of Chaplin's film have had a DVD and Blu-Ray release.

Chaplin's final home, Manoir de Ban in Corsier-sur-Vevey, Switzerland, has been converted into a museum named "Chaplin's World". It opened on 17 April 2016 after 15 years of development, and is described by Reuters as "an interactive museum showcasing the life and works of Charlie Chaplin". On the 128th anniversary of his birth, a record-setting 662 people dressed as the Tramp in an event organised by the museum. Previously, the Museum of the Moving Image in London held a permanent display on Chaplin, and hosted a dedicated exhibition to his life and career in 1988. The London Film Museum hosted an exhibition called "Charlie Chaplin – The Great Londoner", from 2010 until 2013.

In London, a statue of Chaplin as the Tramp, sculpted by John Doubleday and unveiled in 1981, is located in Leicester Square. The city also includes a road named after him in central London, "Charlie Chaplin Walk", which is the location of the BFI IMAX. There are nine blue plaques memorialising Chaplin in London, Hampshire, and Yorkshire. The Swiss town of Vevey named a park in his honour in 1980 and erected a statue there in 1982. In 2011, two large murals depicting Chaplin on two 14-storey buildings were also unveiled in Vevey. Chaplin has also been honoured by the Irish town of Waterville, where he spent several summers with his family in the 1960s. A statue was erected in 1998; since 2011, the town has been host to the annual Charlie Chaplin Comedy Film Festival, which was founded to celebrate Chaplin's legacy and to showcase new comic talent.

In other tributes, a minor planet, 3623 Chaplin – discovered by Soviet astronomer Lyudmila Karachkina in 1981 – is named after Chaplin. Throughout the 1980s, the Tramp image was used by IBM to advertise their personal computers. Chaplin's 100th birthday anniversary in 1989 was marked with several events around the world, and on 15 April 2011, a day before his 122nd birthday, Google celebrated him with a special Google Doodle video on its global and other country-wide homepages. Many countries, spanning six continents, have honoured Chaplin with a postal stamp.

Chaplin's legacy is managed on behalf of his children by the Chaplin office, located in Paris. The office represents Association Chaplin, founded by some of his children "to protect the name, image and moral rights" to his body of work, Roy Export SAS, which owns the copyright to most of his films made after 1918, and Bubbles Incorporated S.A., which owns the copyrights to his image and name. Their central archive is held at the archives of Montreux, Switzerland and scanned versions of its contents, including 83,630 images, 118 scripts, 976 manuscripts, 7,756 letters, and thousands of other documents, are available for research purposes at the Chaplin Research Centre at the Cineteca di Bologna. The photographic archive, which includes approximately 10,000 photographs from Chaplin's life and career, is kept at the Musée de l'Elysée in Lausanne, Switzerland. The British Film Institute has also established the Charles Chaplin Research Foundation, and the first international Charles Chaplin Conference was held in London in July 2005.

Chaplin is the subject of a biographical film, "Chaplin" (1992) directed by Richard Attenborough, and starring Robert Downey Jr. in the title role. He is also a character in the period drama film "The Cat's Meow" (2001), played by Eddie Izzard, and in the made-for-television movie "The Scarlett O'Hara War" (1980), played by Clive Revill. A television series about Chaplin's childhood, "Young Charlie Chaplin", ran on PBS in 1989, and was nominated for an Emmy Award for Outstanding Children's Program.

Chaplin's life has also been the subject of several stage productions. Two musicals, "Little Tramp" and "Chaplin", were produced in the early 1990s. In 2006, Thomas Meehan and Christopher Curtis created another musical, "Limelight: The Story of Charlie Chaplin", which was first performed at the La Jolla Playhouse in San Diego in 2010. It was adapted for Broadway two years later, re-titled "Chaplin – A Musical". Chaplin was portrayed by Robert McClure in both productions. In 2013, two plays about Chaplin premiered in Finland: "Chaplin" at the Svenska Teatern, and "Kulkuri" ("The Tramp") at the Tampere Workers' Theatre.

Chaplin has also been characterised in literary fiction. He is the protagonist of Robert Coover's short story "Charlie in the House of Rue" (1980; reprinted in Coover's 1987 collection "A Night at the Movies"), and of Glen David Gold's "Sunnyside" (2009), a historical novel set in the First World War period. A day in Chaplin's life in 1909 is dramatised in the chapter entitled "Modern Times" in Alan Moore's "Jerusalem" (2016), a novel set in the author's home town of Northampton, England.

Chaplin received many awards and honours, especially later in life. In the 1975 New Year Honours, he was appointed a Knight Commander of the Most Excellent Order of the British Empire (KBE). He was also awarded honorary Doctor of Letters degrees by the University of Oxford and the University of Durham in 1962. In 1965, he and Ingmar Bergman were joint winners of the Erasmus Prize and, in 1971, he was appointed a Commander of the National Order of the Legion of Honour by the French government.

From the film industry, Chaplin received a special Golden Lion at the Venice Film Festival in 1972, and a Lifetime Achievement Award from the Lincoln Center Film Society the same year. The latter has since been presented annually to filmmakers as The Chaplin Award. Chaplin was given a star on the Hollywood Walk of Fame in 1972, having been previously excluded because of his political beliefs.

Chaplin received three Academy Awards: an Honorary Award for "versatility and genius in acting, writing, directing, and producing "The Circus"" in 1929, a second Honorary Award for "the incalculable effect he has had in making motion pictures the art form of this century" in 1972, and a Best Score award in 1973 for "Limelight" (shared with Ray Rasch and Larry Russell). He was further nominated in the Best Actor, Best Original Screenplay, and Best Picture (as producer) categories for "The Great Dictator", and received another Best Original Screenplay nomination for "Monsieur Verdoux". In 1976, Chaplin was made a Fellow of the British Academy of Film and Television Arts (BAFTA).

Six of Chaplin's films have been selected for preservation in the National Film Registry by the United States Library of Congress: "The Immigrant" (1917), "The Kid" (1921), "The Gold Rush" (1925), "City Lights" (1931), "Modern Times" (1936), and "The Great Dictator" (1940).

Directed features:




</doc>
<doc id="5163" url="https://en.wikipedia.org/wiki?curid=5163" title="The World Factbook">
The World Factbook

The World Factbook, also known as the CIA World Factbook, is a reference resource produced by the Central Intelligence Agency (CIA) with almanac-style information about the countries of the world. The official print version is available from the Government Printing Office. Other companies—such as Skyhorse Publishing—also print a paper edition. "The Factbook" is available in the form of a website that is partially updated every week. It is also available for download for use off-line. It provides a two- to three-page summary of the demographics, geography, communications, government, economy, and military of each of 267 international entities including U.S.-recognized countries, dependencies, and other areas in the world.

"The World Factbook" is prepared by the CIA for the use of U.S. government officials, and its style, format, coverage, and content are primarily designed to meet their requirements. However, it is frequently used as a resource for academic research papers and news articles. As a work of the U.S. government, it is in the public domain in the United States.

In researching the "Factbook", the CIA uses the sources listed below. Other public and private sources are also consulted.


Because the "Factbook" is in the public domain, people are free under United States law to redistribute it or parts of it in any way that they like, without permission of the CIA. However, the CIA requests that it be cited when the "Factbook" is used. Copying the official seal of the CIA without permission is prohibited by U.S. federal law—specifically, the Central Intelligence Agency Act of 1949 ().

Before November 2001 "The World Factbook" website was updated yearly; from 2004 to 2010 it was updated every two weeks; since 2010 it has been updated weekly. Generally, information currently available as of January 1 of the current year is used in preparing the "Factbook".

The first, classified, edition of "Factbook" was published in August 1962, and the first unclassified version in June 1971. "The World Factbook" was first available to the public in print in 1975. In 2008 the CIA discontinued printing the "Factbook" themselves, instead turning printing responsibilities over to the Government Printing Office. This happened due to a CIA decision to "focus Factbook resources" on the online edition. The "Factbook" has been on the World Wide Web since October 1994. The web version gets an average of 6 million visits per month; it can also be downloaded. The official printed version is sold by the Government Printing Office and National Technical Information Service. In past years, the "Factbook" was available on CD-ROM, microfiche, magnetic tape, and floppy disk.

Many Internet sites use information and images from the CIA "World Factbook". Several publishers, including Grand River Books, Potomac Books (formerly known as Brassey's Inc.), and Skyhorse Publishing have re-published the "Factbook" in recent years.

As of July 2011, "The World Factbook" consists of 267 entities. These entities can be divided into categories. They are:














The Factbook is full of usually minor errors, inaccuracies, and out-of-date information, which are often repeated elsewhere due to the "Factbook"s widespread use as a reference. For example, Albania was until recently, described in the "Factbook" as 70% Muslim, 20% Eastern Orthodox, and 10% Roman Catholic, which was based on a survey conducted in 1939, before World War II; numerous surveys conducted since the fall of the Communist regime since 1990 have given quite different figures. Another example is Singapore, which the "Factbook" states has a total fertility rate of 0.78 children per woman, despite figures in Statistics Singapore which state that the rate has been about 1.2–1.3 children per woman for at least the past several years, and it is unclear when, or even whether, it ever dropped as low as 0.78. This low and inaccurate value then gets cited in news articles which state that Singapore has the world's lowest fertility, or at least use the figure for its shock value. Another serious problem is that the Factbook never cites its sources, making verification of the information it presents difficult if not impossible.

In June 2009, National Public Radio (NPR), relying on information obtained from the "CIA World Factbook", put the number of Israeli Jews living in settlements in the West Bank and Israeli-annexed East Jerusalem at 250,000. However, a better estimate, based on State Department and Israeli sources put the figure at about 500,000. NPR then issued a correction. Chuck Holmes, foreign editor for NPR Digital, said, "I'm surprised and displeased, and it makes me wonder what other information is out-of-date or incorrect in the CIA "World Factbook"."

Scholars have acknowledged that some entries in the "Factbook" are out of date.







</doc>
<doc id="5165" url="https://en.wikipedia.org/wiki?curid=5165" title="Country">
Country

A country is a region that is identified as a distinct national entity in political geography. A country may be an independent sovereign state or one that is occupied by another state, as a non-sovereign or formerly sovereign political division, or a geographic region associated with sets of previously independent or differently associated people with distinct political characteristics. Regardless of the physical geography, in the modern internationally accepted legal definition as defined by the League of Nations in 1937 and reaffirmed by the United Nations in 1945, a resident of a country is subject to the independent exercise of legal jurisdiction.

Sometimes "countries" refers both to sovereign states and to other political entities, while other times it refers only to states. For example, the "CIA World Factbook" uses the word in its "Country name" field to refer to "a wide variety of dependencies, areas of special sovereignty, uninhabited islands, and other entities in addition to the traditional countries or independent states".

The word "country" comes from Old French "contrée", which derives from Vulgar Latin ("terra") "contrata" ("(land) lying opposite"; "(land) spread before"), derived from "contra" ("against, opposite"). It most likely entered the English language after the Franco-Norman invasion during the 11th century.

In English the word has increasingly become associated with political divisions, so that one sense, associated with the indefinite article – "a country" – through misuse and subsequent conflation is now a synonym for state, or a former sovereign state, in the sense of sovereign territory or "district, native land". Areas much smaller than a political state may be called by names such as the West Country in England, the Black Country (a heavily industrialized part of England), "Constable Country" (a part of East Anglia painted by John Constable), the "big country" (used in various contexts of the American West), "coal country" (used of parts of the US and elsewhere) and many other terms.

The equivalent terms in French and other Romance languages ("pays" and variants) have not carried the process of being identified with political sovereign states as far as the English "country", instead derived from, pagus, which designated the territory controlled by a medieval count, a title originally granted by the Roman Church. In many European countries the words are used for sub-divisions of the national territory, as in the German Bundesländer, as well as a less formal term for a sovereign state. France has very many "pays" that are officially recognised at some level, and are either natural regions, like the Pays de Bray, or reflect old political or economic entities, like the Pays de la Loire.

A version of "country" can be found in the modern French language as "contrée", based on the word "cuntrée" in Old French, that is used similarly to the word "pays" to define non-state regions, but can also be used to describe a political state in some particular cases. The modern Italian "contrada" is a word with its meaning varying locally, but usually meaning a ward or similar small division of a town, or a village or hamlet in the countryside.

The term "country" can refer to a sovereign state. There is no universal agreement on the number of "countries" in the world, since a number of states have disputed sovereignty status. There are 206 sovereign states, of which 193 states are members of the United Nations, two states have observer status at the U.N. (the Holy See and Palestine), and 11 other states are neither a member or observer at the U.N. All are defined as states by declarative theory of statehood and constitutive theory of statehood. The latest proclaimed state is South Sudan in 2011.

Although not sovereign states, England, Scotland, Wales and Northern Ireland are usually referred to as countries (depending on context), which collectively form the United Kingdom—a sovereign state that is also referred to as a country. The Kingdom of Denmark, a sovereign state, comprises Mainland Denmark and two nominally separate countries—the Faroe Islands, and Greenland—which are almost fully internally self-governing. The Kingdom of the Netherlands, a sovereign state, comprises four separate countries: Netherlands, Aruba, Curaçao, and Sint Maarten. In the Kingdom of Spain, the regions of Galicia, the Catalan speaking parts (Catalonia, Valencia and Balearic Islands) and the Basque Country are sometimes recognized as non-sovereign states or group of states (namely, autonomous communities under the Spanish law), specially within nationalist movements.

The degree of autonomy of non-sovereign countries varies widely. Some are possessions of sovereign states, as several states have overseas territories (such as French Polynesia or the British Virgin Islands), with citizenry at times identical and at times distinct from their own. Such territories, with the exception of distinct dependent territories, are usually listed together with sovereign states on lists of countries, but may nonetheless be treated as a separate "country of origin" in international trade, as Hong Kong is.





</doc>
<doc id="5166" url="https://en.wikipedia.org/wiki?curid=5166" title="Copenhagen">
Copenhagen

Copenhagen ( ; ) is the capital and most populous city of Denmark. The city has a population of 775,033 (), of whom 613,288 live in the Municipality of Copenhagen and the Copenhagen urban area has a population of 1,308,893 (). Copenhagen is situated on the eastern coast of the island of Zealand; another small portion of the city is located on Amager, and is separated from Malmö, Sweden, by the strait of Øresund. The Øresund Bridge connects the two cities by rail and road.

Originally a Viking fishing village founded in the 10th century, Copenhagen became the capital of Denmark in the early 15th century. Beginning in the 17th century it consolidated its position as a regional centre of power with its institutions, defences and armed forces. After suffering from the effects of plague and fire in the 18th century, the city underwent a period of redevelopment. This included construction of the prestigious district of Frederiksstaden and founding of such cultural institutions as the Royal Theatre and the Royal Academy of Fine Arts. After further disasters in the early 19th century when Nelson attacked the Dano-Norwegian fleet and bombarded the city, rebuilding during the Danish Golden Age brought a Neoclassical look to Copenhagen's architecture. Later, following the Second World War, the Finger Plan fostered the development of housing and businesses along the five urban railway routes stretching out from the city centre.

Since the turn of the 21st century, Copenhagen has seen strong urban and cultural development, facilitated by investment in its institutions and infrastructure. The city is the cultural, economic and governmental centre of Denmark; it is one of the major financial centres of Northern Europe with the Copenhagen Stock Exchange. Copenhagen's economy has seen rapid developments in the service sector, especially through initiatives in information technology, pharmaceuticals and clean technology. Since the completion of the Øresund Bridge, Copenhagen has become increasingly integrated with the Swedish province of Scania and its largest city, Malmö, forming the Øresund Region. With a number of bridges connecting the various districts, the cityscape is characterised by parks, promenades and waterfronts. Copenhagen's landmarks such as Tivoli Gardens, "The Little Mermaid" statue, the Amalienborg and Christiansborg palaces, Rosenborg Castle Gardens, Frederik's Church, and many museums, restaurants and nightclubs are significant tourist attractions. The largest lake of Denmark, Arresø, lies around 27 miles (43 kilometers) northwest of the City Hall Square.

Copenhagen is home to the University of Copenhagen, the Technical University of Denmark and Copenhagen Business School. The University of Copenhagen, founded in 1479, is the oldest university in Denmark. Copenhagen is home to the FC København and Brøndby football clubs. The annual Copenhagen Marathon was established in 1980. Copenhagen is one of the most bicycle-friendly cities in the world.

The Copenhagen Metro launched in 2002 serves central Copenhagen while the Copenhagen S-train and Lokaltog () and the Coast Line network serves and connects central Copenhagen to outlying boroughs. To relieve traffic congestion, which is partly the result of increased traffic because of the Fehmarn Belt Fixed Link road and rail construction is planned because the narrow 9-9.5 mile isthmus between Roskilde Fjord and Køge Bugt (Køge Bay) forms a traffic bottleneck. The Copenhagen-Ringsted Line will relieve traffic congestion in the corridor between Roskilde and Copenhagen. 

Serving roughly two million passengers a month, Copenhagen Airport, Kastrup, is the busiest airport in the Nordic countries.

The name of the city reflects its origin as a harbour and a place of commerce. The original designation, from which the contemporary Danish name derives, was "Køpmannæhafn", meaning "merchants' harbour", often simply "Hafn" or "Havn" ("harbour"). The literal English translation would be "chapman's haven". The English name for the city was adapted from its Low German name, "Kopenhagen". The abbreviations "Kbh." or "Kbhvn" are often used in Danish for "København", and "kbh." for "københavnsk" (of Copenhagen).

The chemical element hafnium is named after Copenhagen (Latin name "Hafnia"), where it was discovered. The bacterium "Hafnia" is also named after Copenhagen: Vagn Møller of the State Serum Institute in Copenhagen named it in 1954.

Although the earliest historical records of Copenhagen are from the end of the 12th century, recent archaeological finds in connection with work on the city's metropolitan rail system revealed the remains of a large merchant's mansion near today's Kongens Nytorv from c. 1020. Excavations in Pilestræde have also led to the discovery of a well from the late 12th century. The remains of an ancient church, with graves dating to the 11th century, have been unearthed near where Strøget meets Rådhuspladsen.

These finds indicate that Copenhagen's origins as a city go back at least to the 11th century. Substantial discoveries of flint tools in the area provide evidence of human settlements dating to the Stone Age. Many historians believe the town dates to the late Viking Age, and was possibly founded by Sweyn I Forkbeard. 
The natural harbour and good herring stocks seem to have attracted fishermen and merchants to the area on a seasonal basis from the 11th century and more permanently in the 13th century. The first habitations were probably centred on Gammel Strand (literally "old shore") in the 11th century or even earlier.

The earliest written mention of the town was in the 12th century when Saxo Grammaticus in Gesta Danorum referred to it as "Portus Mercatorum", meaning Merchants' Harbour or, in the Danish of the time, "Købmannahavn". Traditionally, Copenhagen's founding has been dated to Bishop Absalon's construction of a modest fortress on the little island of Slotsholmen in 1167 where Christiansborg Palace stands today. The construction of the fortress was in response to attacks by Wendish pirates who plagued the coastline during the 12th century. Defensive ramparts and moats were completed and by 1177 St. Clemens Church had been built. Attacks by the Germans continued, and after the original fortress was eventually destroyed by the marauders, islanders replaced it with Copenhagen Castle.

In 1186, a letter from Pope Urban III states that the castle of "Hafn" (Copenhagen) and its surrounding lands, including the town of Hafn, were given to Absalon, Bishop of Roskilde 1158–1191 and Archbishop of Lund 1177–1201, by King Valdemar I. On Absalon's death, the property was to come into the ownership of the Bishopric of Roskilde. Around 1200, the Church of Our Lady was constructed on higher ground to the northeast of the town, which began to develop around it.

As the town became more prominent, it was repeatedly attacked by the Hanseatic League. As the fishing industry thrived in Copenhagen, particularly in the trade of herring, the city began expanding to the north of Slotsholmen. In 1254, it received a charter as a city under Bishop Jakob Erlandsen who garnered support from the local fishing merchants against the king by granting them special privileges. In the mid 1330s, the first land assessment of the city was published.

With the establishment of the Kalmar Union (1397–1523) between Denmark, Norway and Sweden, by about 1416 Copenhagen had emerged as the capital of Denmark when Eric of Pomerania moved his seat to Copenhagen Castle. The University of Copenhagen was inaugurated on 1 June 1479 by King Christian I, following approval from Pope Sixtus IV. This makes it the oldest university in Denmark and one of the oldest in Europe. Originally controlled by the Catholic Church, the university's role in society was forced to change during the Reformation in Denmark in the late 1530s.

In disputes prior to the Reformation of 1536, the city which had been faithful to Christian II, who was Catholic, was successfully besieged in 1523 by the forces of Frederik I, who supported Lutheranism. Copenhagen's defences were reinforced with a series of towers along the city wall. After an extended siege from July 1535 to July 1536, during which the city supported Christian II's alliance with Malmö and Lübeck, it was finally forced to capitulate to Christian III. During the second half of the century, the city prospered from increased trade across the Baltic supported by Dutch shipping. Christoffer Valkendorff, a high-ranking statesman, defended the city's interests and contributed to its development. The Netherlands had also become primarily Protestant, as were northern German states.

During the reign of Christian IV between 1588 and 1648, Copenhagen had dramatic growth as a city. On his initiative at the beginning of the 17th century, two important buildings were completed on Slotsholmen: the Tøjhus Arsenal and Børsen, the stock exchange. To foster international trade, the East India Company was founded in 1616. To the east of the city, inspired by Dutch planning, the king developed the district of Christianshavn with canals and ramparts. It was initially intended to be a fortified trading centre but ultimately became part of Copenhagen. Christian IV also sponsored an array of ambitious building projects including Rosenborg Slot and the Rundetårn. In 1658–59, the city withstood a siege by the Swedes under Charles X and successfully repelled a major assault.

By 1661, Copenhagen had asserted its position as capital of Denmark and Norway. All the major institutions were located there, as was the fleet and most of the army. The defences were further enhanced with the completion of the Citadel in 1664 and the extension of Christianshavns Vold with its bastions in 1692, leading to the creation of a new base for the fleet at Nyholm.

Copenhagen lost around 22,000 of its population of 65,000 to the plague in 1711. The city was also struck by two major fires which destroyed much of its infrastructure. The Copenhagen Fire of 1728 was the largest in the history of Copenhagen. It began on the evening of 20 October, and continued to burn until the morning of 23 October, destroying approximately 28% of the city, leaving some 20% of the population homeless. No less than 47% of the medieval section of the city was completely lost. Along with the 1795 fire, it is the main reason that few traces of the old town can be found in the modern city.

A substantial amount of rebuilding followed. In 1733, work began on the royal residence of Christiansborg Palace which was completed in 1745. In 1749, development of the prestigious district of Frederiksstaden was initiated. Designed by Nicolai Eigtved in the Rococo style, its centre contained the mansions which now form Amalienborg Palace. Major extensions to the naval base of Holmen were undertaken while the city's cultural importance was enhanced with the Royal Theatre and the Royal Academy of Fine Arts.

In the second half of the 18th century, Copenhagen benefited from Denmark's neutrality during the wars between Europe's main powers, allowing it to play an important role in trade between the states around the Baltic Sea. After Christiansborg was destroyed by fire in 1794 and another fire caused serious damage to the city in 1795, work began on the classical Copenhagen landmark of Højbro Plads while Nytorv and Gammel Torv were converged.

On 2 April 1801, a British fleet under the command of Admiral Sir Hyde Parker attacked and defeated the neutral Danish-Norwegian fleet anchored near Copenhagen. Vice-Admiral Horatio Nelson led the main attack. He famously disobeyed Parker's order to withdraw, destroying many of the Dano-Norwegian ships before a truce was agreed. Copenhagen is often considered to be Nelson's hardest-fought battle, surpassing even the heavy fighting at Trafalgar. It was during this battle that Lord Nelson was said to have "put the telescope to the blind eye" in order not to see Admiral Parker's signal to cease fire.

The Second Battle of Copenhagen (or the Bombardment of Copenhagen) (16 August – 5 September 1807) was from a British point of view a preemptive attack on Copenhagen, targeting the civilian population in order to seize the Dano-Norwegian fleet. But from a Danish point of view the battle was a terror bombardment on their capital. Particularly notable was the use of incendiary Congreve rockets (containing phosphorus, which cannot be extinguished with water) that randomly hit the city. Few houses with straw roofs remained after the bombardment. The largest church, "Vor frue kirke", was destroyed by the sea artillery. Several historians consider this battle the first terror attack against a major European city in modern times.

Despite the disasters of the early 19th century, Copenhagen experienced a period of intense cultural creativity known as the Danish Golden Age. Painting prospered under C.W. Eckersberg and his students while C.F. Hansen and Gottlieb Bindesbøll brought a Neoclassical look to the city's architecture. In the early 1850s, the ramparts of the city were opened to allow new housing to be built around The Lakes () that bordered the old defences to the west. By the 1880s, the districts of Nørrebro and Vesterbro developed to accommodate those who came from the provinces to participate in the city's industrialization. This dramatic increase of space was long overdue, as not only were the old ramparts out of date as a defence system but bad sanitation in the old city had to be overcome. From 1886, the west rampart (Vestvolden) was flattened, allowing major extensions to the harbour leading to the establishment of the Freeport of Copenhagen 1892–94. Electricity came in 1892 with electric trams in 1897. The spread of housing to areas outside the old ramparts brought about a huge increase in the population. In 1840, Copenhagen was inhabited by approximately 120,000 people. By 1901, it had some 400,000 inhabitants.

By the beginning of the 20th century, Copenhagen had become a thriving industrial and administrative city. With its new city hall and railway station, its centre was drawn towards the west. New housing developments grew up in Brønshøj and Valby while Frederiksberg became an enclave within the city of Copenhagen. The northern part of Amager and Valby were also incorporated into the City of Copenhagen in 1901–02.

As a result of Denmark's neutrality in the First World War, Copenhagen prospered from trade with both Britain and Germany while the city's defences were kept fully manned by some 40,000 soldiers for the duration of the war.

In the 1920s there were serious shortages of goods and housing. Plans were drawn up to demolish the old part of Christianshavn and to get rid of the worst of the city's slum areas. However, it was not until the 1930s that substantial housing developments ensued, with the demolition of one side of Christianhavn's Torvegade in order to build five large blocks of flats.

 

During World War II in Denmark, Copenhagen was occupied by German troops along with the rest of the country from 9 April 1940 until 4 May 1945. German leader Adolf Hitler hoped that Denmark would be "a model protectorate" and initially the Nazi authorities sought to arrive at an understanding with the Danish government. The 1943 Danish parliamentary election was also allowed to take place, with only the Communist Party excluded. But in August 1943, after the government's collaboration with the occupation forces collapsed, several ships were sunk in Copenhagen Harbor by the Royal Danish Navy to prevent their use by the Germans. Around that time the Nazis started to arrest Jews, although most managed to escape to Sweden.

In 1945 Ole Lippman, leader of the Danish section of the Special Operations Executive, invited the British Royal Air Force to assist their operations by attacking Nazi headquarters in Copenhagen. Accordingly, Air Vice-Marshal Sir Basil Embry drew up plans for a spectacular precision attack on the Sicherheitsdienst and Gestapo building, the former offices of the Shell Oil Company. Political prisoners were kept in the attic to prevent an air raid, so the RAF had to bomb the lower levels of the building.

The attack, known as "Operation Carthage", came on 22 March 1945, in three small waves. In the first wave, all six planes (carrying one bomb each) hit their target, but one of the aircraft crashed near Frederiksberg Girls School. Because of this crash, four of the planes in the two following waves assumed the school was the military target and aimed their bombs at the school, leading to the death of 123 civilians (of which 87 were schoolchildren). However, 18 of the 26 political prisoners in the Shell Building managed to escape while the Gestapo archives were completely destroyed.

On 8 May 1945 Copenhagen was officially liberated by British troops commanded by Field Marshal Bernard Montgomery who supervised the surrender of 30,000 Germans situated around the capital.

Shortly after the end of the war, an innovative urban development project known as the Finger Plan was introduced in 1947, encouraging the creation of new housing and businesses interspersed with large green areas along five "fingers" stretching out from the city centre along the S-train routes. With the expansion of the welfare state and women entering the work force, schools, nurseries, sports facilities and hospitals were established across the city. As a result of student unrest in the late 1960s, the former Bådsmandsstræde Barracks in Christianshavn was occupied, leading to the establishment of Freetown Christiania in September 1971.
Motor traffic in the city grew significantly and in 1972 the trams were replaced by buses. From the 1960s, on the initiative of the young architect Jan Gehl, pedestrian streets and cycle tracks were created in the city centre. Activity in the port of Copenhagen declined with the closure of the Holmen naval base. Copenhagen Airport underwent considerable expansion, becoming a hub for the Nordic countries. In the 1990s, large-scale housing developments were realized in the harbour area and in the west of Amager. The national library's Black Diamond building on the waterfront was completed in 1999.

Since the summer of 2000, Copenhagen and the Swedish city of Malmö have been connected by the Øresund Bridge, which carries rail and road traffic. As a result, Copenhagen has become the centre of a larger metropolitan area spanning both nations. The bridge has brought about considerable changes in the public transport system and has led to the extensive redevelopment of Amager. The city's service and trade sectors have developed while a number of banking and financial institutions have been established. Educational institutions have also gained importance, especially the University of Copenhagen with its 35,000 students. Another important development for the city has been the Copenhagen Metro, the railway system which opened in 2000 with additions until 2007, transporting some 54 million passengers by 2011.

On the cultural front, the lavish Copenhagen Opera House, a gift to the city from the shipping magnate Mærsk Mc-Kinney Møller on behalf of the A.P. Møller foundation, was completed in 2004. In December 2009 Copenhagen gained international prominence when it hosted the worldwide climate meeting COP15.

Copenhagen is part of the Øresund Region, which consists of Zealand, Lolland-Falster and Bornholm in Denmark and Scania in Sweden. It is located on the eastern shore of the island of Zealand, partly on the island of Amager and on a number of natural and artificial islets between the two. Copenhagen faces the Øresund to the east, the strait of water that separates Denmark from Sweden, and which connects the North Sea with the Baltic Sea. The Swedish towns of Malmö and Landskrona lie on the Swedish side of the sound directly across from Copenhagen. By road, Copenhagen is northwest of Malmö, Sweden, northeast of Næstved, northeast of Odense, east of Esbjerg and southeast of Aarhus by sea and road via Sjællands Odde.

The city centre lies in the area originally defined by the old ramparts, which are still referred to as the Fortification Ring ("Fæstningsringen") and kept as a partial green band around it. Then come the late 19th and early 20th century residential neighbourhoods of Østerbro, Nørrebro, Vesterbro and Amagerbro. The outlying areas of Kongens Enghave, Valby, Vigerslev, Vanløse, Brønshøj, Utterslev and Sundby followed from 1920 to 1960. They consist mainly of residential housing and apartments often enhanced with parks and greenery.

The central area of the city consists of relatively low-lying flat ground formed by moraines from the last ice age while the hilly areas to the north and west frequently rise to above sea level. The slopes of Valby and Brønshøj reach heights of over , divided by valleys running from the northeast to the southwest. Close to the centre are the Copenhagen lakes of Sortedams Sø, Peblinge Sø and Sankt Jørgens Sø.

Copenhagen rests on a subsoil of flint-layered limestone deposited in the Danian period some 60 to 66 million years ago. Some greensand from the Selandian is also present. There are a few faults in the area, the most important of which is the Carlsberg fault which runs northwest to southeast through the centre of the city. During the last ice age, glaciers eroded the surface leaving a layer of moraines up to thick.

Geologically Copenhagen lies in the northern part of Denmark where the land is rising because of post-glacial rebound.

Amager Strandpark, which opened in 2005, is a long artificial island, with a total of of beaches. It is located just 15 minutes by bicycle or a few minutes by metro from the city centre. In Klampenborg, about 10 kilometers from downtown Copenhagen, is Bellevue Beach. It is long and has both lifeguards and freshwater showers on the beach.

The beaches are supplemented by a system of Harbour Baths along the Copenhagen waterfront. The first and most popular of these is located at Islands Brygge and has won international acclaim for its design.

Copenhagen is in the oceanic climate zone (Köppen: "Cfb "). Its weather is subject to low-pressure systems from the Atlantic which result in unstable conditions throughout the year. Apart from slightly higher rainfall from July to September, precipitation is moderate. While snowfall occurs mainly from late December to early March, there can also be rain, with average temperatures around the freezing point.

June is the sunniest month of the year with an average of about eight hours of sunshine a day. July is the warmest month with an average daytime high of 21 °C. By contrast, the average hours of sunshine are less than two per day in November and only one and a half per day from December to February. In the spring, it gets warmer again with four to six hours of sunshine per day from March to May. February is the driest month of the year. Exceptional weather conditions can bring as much as 50 cm of snow to Copenhagen in a 24-hour period during the winter months while summer temperatures have been known to rise to heights of .

Because of Copenhagen's northern latitude, the number of daylight hours varies considerably between summer and winter. On the summer solstice, the sun rises at 04:26 and sets at 21:58, providing 17 hours 32 minutes of daylight. On the winter solstice, it rises at 08:37 and sets at 15:39 with 7 hours and 1 minute of daylight. There is therefore a difference of 10 hours and 31 minutes in the length of days and nights between the summer and winter solstices.

According to Statistics Denmark, the urban area of Copenhagen () consists of the municipalities of Copenhagen, Frederiksberg, Albertslund, Brøndby, Gentofte, Gladsaxe, Glostrup, Herlev, Hvidovre, Lyngby-Taarbæk, Rødovre, Tårnby and Vallensbæk as well as parts of Ballerup, Rudersdal and Furesø municipalities, along with the cities of Ishøj and Greve Strand. They are located in the Capital Region (). Municipalities are responsible for a wide variety of public services, which include land-use planning, environmental planning, public housing, management and maintenance of local roads, and social security. Municipal administration is also conducted by a mayor, a council, and an executive.

Copenhagen Municipality is by far the largest municipality, with the historic city at its core. The seat of Copenhagen's municipal council is the Copenhagen City Hall (""), which is situated on City Hall Square. The second largest municipality is Frederiksberg, an enclave within Copenhagen Municipality.

Copenhagen Municipality is divided into ten districts ("bydele"): Indre By, Østerbro, Nørrebro, Vesterbro/Kongens Enghave, Valby, Vanløse, Brønshøj-Husum, Bispebjerg, Amager Øst, and Amager Vest. Neighbourhoods of Copenhagen include Slotsholmen, Frederiksstaden, Islands Brygge, Holmen, Christiania, Carlsberg, Sluseholmen, Amagerbro, Ørestad, Nordhavnen, Bellahøj, Brønshøj, Ryparken, and Vigerslev.

Most of Denmark's top legal courts and institutions are based in Copenhagen. A modern style court of justice, "Hof- og Stadsretten", was introduced in Denmark, specifically for Copenhagen, by Johann Friedrich Struensee in 1771. Now known as the City Court of Copenhagen ("Københavns Byret"), it is the largest of the 24 city courts in Denmark with jurisdiction over the municipalities of Copenhagen, Dragør and Tårnby. With its 42 judges, it has a Probate Division, an Enforcement Division and a Registration and Notorial Acts Division while bankruptcy is handled by the Maritime and Commercial Court of Copenhagen. Established in 1862, the Maritime and Commercial Court ("Sø- og Handelsretten") also hears commercial cases including those relating to trade marks, marketing practices and competition for the whole of Denmark. Denmark's Supreme Court ("Højesteret"), located in Christiansborg Palace on Prins Jørgens Gård in the centre of Copenhagen, is the country's final court of appeal. Handling civil and criminal cases from the subordinate courts, it has two chambers which each hear all types of cases.

The Danish National Police and Copenhagen Police headquarters is situated in the Neoclassical-inspired Politigården building built in 1918–24 under architects Hack Kampmann and Holger Alfred Jacobsen. The building also contains administration, management, emergency department and radio service offices. In their efforts to deal with drugs, the police have noted considerable success in the two special drug consumption rooms opened by the city where addicts can use sterile needles and receive help from nurses if necessary. Use of these rooms does not lead to prosecution; the city treats drug use as a public health issue, not a criminal one.

The Copenhagen Fire Department forms the largest municipal fire brigade in Denmark with some 500 fire and ambulance personnel, 150 administration and service workers, and 35 workers in prevention. The brigade began as the Copenhagen Royal Fire Brigade on 9 July 1687 under King Christian V. After the passing of the Copenhagen Fire Act on 18 May 1868, on 1 August 1870 the Copenhagen Fire Brigade became a municipal institution in its own right. The fire department has its headquarters in the Copenhagen Central Fire Station which was designed by Ludvig Fenger in the Historicist style and inaugurated in 1892.

Copenhagen is recognized as one of the most environmentally friendly cities in the world. As a result of its commitment to high environmental standards, Copenhagen has been praised for its green economy, ranked as the top green city for the second time in the 2014 "Global Green Economy Index (GGEI)". In 2001 a large offshore wind farm was built just off the coast of Copenhagen at Middelgrunden. It produces about 4% of the city's energy. Years of substantial investment in sewage treatment have improved water quality in the harbour to an extent that the inner harbour can be used for swimming with facilities at a number of locations.
Copenhagen aims to be carbon-neutral by 2025. Commercial and residential buildings are to reduce electricity consumption by 20 percent and 10 percent respectively, and total heat consumption is to fall by 20 percent by 2025. Renewable energy features such as solar panels are becoming increasingly common in the newest buildings in Copenhagen. District heating will be carbon-neutral by 2025, by waste incineration and biomass. New buildings must now be constructed according to Low Energy Class ratings and in 2020 near net-zero energy buildings. By 2025, 75% of trips should be made on foot, by bike, or by using public transit. The city plans that 20–30% of cars will run on electricity or biofuel by 2025. The investment is estimated at $472 million public funds and $4.78 billion private funds.

The city's architectural planning authorities continue to take full account of these priorities. Special attention is given both to climate issues and efforts to ensure maximum application of low-energy standards. Priorities include sustainable drainage systems, recycling rainwater, green roofs and efficient waste management solutions. In city planning, streets and squares are to be designed to encourage cycling and walking rather than driving.

Copenhagen is the most populous city in Denmark and one of the most populous in the Nordic countries. For statistical purposes, Statistics Denmark considers the City of Copenhagen ("Byen København") to consist of the Municipality of Copenhagen plus three adjacent municipalities: Dragør, Frederiksberg, and Tårnby. Their combined population stands at 763,908 ().

The Municipality of Copenhagen is by far the most populous in the country and one of the most populous Nordic municipalities with 601,448 inhabitants (). There was a demographic boom in the 1990s and first decade of the 21st century, largely due to immigration to Denmark. According to figures from the first quarter of 2016, approximately 76% of the municipality's population was of Danish descent, defined as having at least one parent who was born in Denmark and has Danish citizenship. Much of the remaining 24% were of a foreign background, defined as immigrants (18%) or descendants of recent immigrants (6%). There are no official statistics on ethnic groups. The table to the right shows the most common countries of birth of Copenhagen residents.

According to Statistics Denmark, Copenhagen's urban area has a larger population of 1,280,371 (). The urban area consists of the municipalities of Copenhagen and Frederiksberg plus 16 of the 20 municipalities of the former counties Copenhagen and Roskilde, though five of them only partially. Metropolitan Copenhagen has a total of 2,016,285 inhabitants (). The area of Metropolitan Copenhagen is defined by the Finger Plan. Since the opening of the Øresund Bridge in 2000, commuting between Zealand and Scania in Sweden has increased rapidly, leading to a wider, integrated area. Known as the Øresund Region, it has 3.8 million inhabitants (of whom 2.5 million live in the Danish part of the region).

With 58.1% a majority of those living in Copenhagen are members of the Lutheran Church of Denmark which is 1.2% lower than one year earlier according to 2017 figures. The National Cathedral, the Church of Our Lady, is one of the dozens of churches in Copenhagen. There are also several other Christian communities in the city, of which the largest is Roman Catholic.

Foreign migration to Copenhagen, rising over the last three decades, has contributed to increasing religious diversity; the Grand Mosque of Copenhagen, the first in Denmark, opened in 2014. Islam is the second largest religion in Copenhagen, accounting for approximately 10% of the population. While there are no official statistics, a significant portion of the estimated 175,000–200,000 Muslims in the country live in the Copenhagen urban area, with the highest concentration in Nørrebro and the Vestegnen. There are also some 7,000 Jews in Denmark, most of them in the Copenhagen area where there are several synagogues.
For a number of years, Copenhagen has ranked high in international surveys for its quality of life. Its stable economy together with its education services and level of social safety make it attractive for locals and visitors alike. Although it is one of the world's most expensive cities, it is also one of the most liveable with its public transport, facilities for cyclists and its environmental policies. In elevating Copenhagen to "most liveable city" in 2013, "Monocle" pointed to its open spaces, increasing activity on the streets, city planning in favour of cyclists and pedestrians, and features to encourage inhabitants to enjoy city life with an emphasis on community, culture and cuisine. Other sources have ranked Copenhagen high for its business environment, accessibility, restaurants and environmental planning. However, Copenhagen ranks only 39th for student friendliness in 2012. Despite a top score for quality of living, its scores were low for employer activity and affordability.

Copenhagen is the major economic and financial centre of Denmark. The city's economy is based largely on services and commerce. Statistics for 2010 show that the vast majority of the 350,000 workers in Copenhagen are employed in the service sector, especially transport and communications, trade, and finance, while less than 10,000 work in the manufacturing industries. The public sector workforce is around 110,000, including education and healthcare. From 2006 to 2011, the economy grew by 2.5% in Copenhagen, while it fell by some 4% in the rest of Denmark. In 2010, the wider Capital Region of Denmark had a gross domestic product (GDP) of €88,366 million, and the 15th largest GDP per capita of regions in the European Union.
Several financial institutions and banks have headquarters in Copenhagen, including Alm. Brand, Danske Bank, Nykredit and Nordea Bank Danmark. The Copenhagen Stock Exchange (CSE) was founded in 1620 and is now owned by Nasdaq, Inc.. Copenhagen is also home to a number of international companies including A.P. Møller-Mærsk, Novo Nordisk, Carlsberg and Novozymes. City authorities have encouraged the development of business clusters in several innovative sectors, which include information technology, biotechnology, pharmaceuticals, clean technology and smart city solutions.
Life science is a key sector with extensive research and development activities. Medicon Valley is a leading bi-national life sciences cluster in Europe, spanning the Øresund Region. Copenhagen is rich in companies and institutions with a focus on research and development within the field of biotechnology, and the Medicon Valley initiative aims to strengthen this position and to promote cooperation between companies and academia. Many major Danish companies like Novo Nordisk and Lundbeck, both of which are among the 50 largest pharmaceutical and biotech companies in the world, are located in this business cluster.

Shipping is another import sector with Maersk, the world's largest shipping company, having their world headquarters in Copenhagen. The city has an industrial harbour, Copenhagen Port. Following decades of stagnation, it has experienced a resurgence since 1990 following a merger with Malmö harbour. Both ports are operated by Copenhagen Malmö Port (CMP). The central location in the Øresund Region allows the ports to act as a hub for freight that is transported onward to the Baltic countries. CMP annually receives about 8,000 ships and handled some 148,000 TEU in 2012.

Copenhagen has some of the highest gross wages in the world. High taxes mean that wages are reduced after mandatory deduction. A "beneficial researcher scheme" with low taxation of foreign specialists has made Denmark an attractive location for foreign labour. It is however also among the most expensive cities in Europe.

Denmark's Flexicurity model features some of the most flexible hiring and firing legislation in Europe, providing attractive conditions for foreign investment and international companies looking to locate in Copenhagen. In Dansk Industri's 2013 survey of employment factors in the ninety-six municipalities of Denmark, Copenhagen came in first place for educational qualifications and for the development of private companies in recent years, but fell to 86th place in local companies' assessment of the employment climate. The survey revealed considerable dissatisfaction in the level of dialogue companies enjoyed with the municipal authorities.

Tourism is a major contributor to Copenhagen's economy, attracting visitors due to the city's harbour, cultural attractions and award-winning restaurants. Since 2009, Copenhagen has been one of the fastest growing metropolitan destinations in Europe. Hotel capacity in the city is growing significantly. From 2009 to 2013, it experienced a 42% growth in international bed nights (total number of nights spent by tourists), tallying a rise of nearly 70% for Chinese visitors. The total number of bed nights in the Capital Region surpassed 9 million in 2013, while international bed nights reached 5 million.

In 2010, it is estimated that city break tourism contributed to DKK 2 billion in turnover. However, 2010 was an exceptional year for city break tourism and turnover increased with 29% in that one year. 680,000 cruise passengers visited the port in 2015.

The city's appearance today is shaped by the key role it has played as a regional centre for centuries. Copenhagen has a multitude of districts, each with its distinctive character and representing its own period. Other distinctive features of Copenhagen include the abundance of water, its many parks, and the bicycle paths that line most streets.

The oldest section of Copenhagen's inner city is often referred to as "Middelalderbyen" (the medieval city). However, the city's most distinctive district is Frederiksstaden, developed during the reign of Frederick V. It has the Amalienborg Palace at its centre and is dominated by the dome of Frederik's Church (or the Marble Church) and several elegant 18th-century Rococo mansions. The inner city includes Slotsholmen, a little island on which Christiansborg Palace stands and Christianshavn with its canals. Børsen on Slotsholmen and Frederiksborg Palace in Hillerød are prominent examples of the Dutch Renaissance style in Copenhagen. Around the historical city centre lies a band of congenial residential boroughs (Vesterbro, Inner Nørrebro, Inner Østerbro) dating mainly from late 19th century. They were built outside the old ramparts when the city was finally allowed to expand beyond its fortifications.

Sometimes referred to as "the City of Spires", Copenhagen is known for its horizontal skyline, broken only by the spires and towers of its churches and castles. Most characteristic of all is the Baroque spire of the Church of Our Saviour with its narrowing external spiral stairway that visitors can climb to the top. Other important spires are those of Christiansborg Palace, the City Hall and the former Church of St. Nikolaj that now houses a modern art venue. Not quite so high are the Renaissance spires of Rosenborg Castle and the "dragon spire" of Christian IV's former stock exchange, so named because it resembles the intertwined tails of four dragons.

Copenhagen is recognised globally as an exemplar of best practice urban planning. Its thriving mixed use city centre is defined by striking contemporary architecture, engaging public spaces and an abundance of human activity. These design outcomes have been deliberately achieved through careful replanning in the second half of the 20th century.

Recent years have seen a boom in modern architecture in Copenhagen both for Danish architecture and for works by international architects. For a few hundred years, virtually no foreign architects had worked in Copenhagen, but since the turn of the millennium the city and its immediate surroundings have seen buildings and projects designed by top international architects. British design magazine "Monocle" named Copenhagen the "World's best design city 2008".

Copenhagen's urban development in the first half of the 20th century was heavily influenced by industrialisation. After World War II, Copenhagen Municipality adopted Fordism and repurposed its medieval centre to facilitate private automobile infrastructure in response to innovations in transport, trade and communication. Copenhagen’s spacial planning in this time frame was characterised by the separation of land uses: an approach which requires residents to travel by car to access facilities of different uses.

The boom in urban development and modern architecture has brought some changes to the city's skyline. A political majority has decided to keep the historical centre free of high-rise buildings, but several areas will see or have already seen massive urban development. Ørestad now has seen most of the recent development. Located near Copenhagen Airport, it currently boasts one of the largest malls in Scandinavia and a variety of office and residential buildings as well as the IT University and a high school.

Copenhagen is a green city with many parks, both large and small. King's Garden (""), the garden of Rosenborg Castle, is the oldest and most frequented of them all. It was Christian IV who first developed its landscaping in 1606. Every year it sees more than 2.5 million visitors and in the summer months it is packed with sunbathers, picnickers and ballplayers. It serves as a sculpture garden with both a permanent display and temporary exhibits during the summer months. Also located in the city centre are the Botanical Gardens noted for their large complex of 19th-century greenhouses donated by Carlsberg founder J. C. Jacobsen. Fælledparken at is the largest park in Copenhagen.

It is popular for sports fixtures and hosts several annual events including a free opera concert at the opening of the opera season, other open-air concerts, carnival and Labour Day celebrations, and the Copenhagen Historic Grand Prix, a race for antique cars. A historical green space in the northeastern part of the city is Kastellet, a well-preserved Renaissance citadel that now serves mainly as a park. Another popular park is the Frederiksberg Gardens, a 32-hectare romantic landscape park. It houses a colony of tame grey herons and other waterfowl. The park offers views of the elephants and the elephant house designed by world-famous British architect Norman Foster of the adjacent Copenhagen Zoo. Langelinie, a park and promenade along the inner Øresund coast, is home to one of Copenhagen's most-visited tourist attractions, the Little Mermaid statue.

In Copenhagen, many cemeteries double as parks, though only for the more quiet activities such as sunbathing, reading and meditation. Assistens Cemetery, the burial place of Hans Christian Andersen, is an important green space for the district of Inner Nørrebro and a Copenhagen institution. The lesser known Vestre Kirkegaard is the largest cemetery in Denmark () and offers a maze of dense groves, open lawns, winding paths, hedges, overgrown tombs, monuments, tree-lined avenues, lakes and other garden features.

It is official municipal policy in Copenhagen that by 2015 all citizens must be able to reach a park or beach on foot in less than 15 minutes. In line with this policy, several new parks, including the innovative Superkilen in the Nørrebro district, have been completed or are under development in areas lacking green spaces.

The historic centre of the city, Indre By or the Inner City, features many of Copenhagen's most popular monuments and attractions. The area known as Frederiksstaden, developed by Frederik V in the second half of the 18th century in the Rococo style, has the four mansions of Amalienborg, the royal residence, and the wide-domed Marble Church at its centre. Directly across the water from Amalienborg, the recently completed Copenhagen Opera stands on the island of Holmen. To the south of Frederiksstaden, the Nyhavn canal is lined with colourful houses from the 17th and 18th centuries, many now with lively restaurants and bars. The canal runs from the harbour front to the spacious square of Kongens Nytorv which was laid out by Christian V in 1670. Important buildings include Charlottenborg Palace, famous for its art exhibitions, the Thott Palace (now the French embassy), the Royal Danish Theatre and the Hotel D'Angleterre, dated to 1755. Other landmarks in Indre By include the parliament building of Christiansborg, the City Hall and Rundetårn, originally an observatory. There are also several museums in the area including Thorvaldsen Museum dedicated to the 18th-century sculptor Bertel Thorvaldsen. Closed to traffic since 1964, Strøget, the world's oldest and longest pedestrian street, runs the from Rådhuspladsen to Kongens Nytorv. With its speciality shops, cafés, restaurants, and buskers, it is always full of life and includes the old squares of Gammel Torv and Amagertorv, each with a fountain. Rosenborg Castle on Øster Voldgade was built by Christian IV in 1606 as a summer residence in the Renaissance style. It houses the Danish crown jewels and crown regalia, the coronation throne and tapestries illustrating Christian V's victories in the Scanian War.

Christianshavn lies to the southeast of Indre By on the other side of the harbour. The area was developed by Christian IV in the early 17th century. Impressed by the city of Amsterdam, he employed Dutch architects to create canals within its ramparts which are still well preserved today. The canals themselves, branching off the central Christianshavn Canal and lined with house boats and pleasure craft are one of the area's attractions. Another interesting feature is Freetown Christiania, a fairly large area which was initially occupied by squatters during student unrest in 1971. Today it still maintains a measure of autonomy. The inhabitants openly sell drugs on "Pusher Street" as well as their arts and crafts. Other buildings of interest in Christianshavn include the Church of Our Saviour with its spiralling steeple and the magnificent Rococo Christian's Church. Once a warehouse, the North Atlantic House now displays culture from Iceland and Greenland and houses the Noma restaurant, known for its Nordic cuisine.

Vesterbro, to the southwest of Indre By, begins with the Tivoli Gardens, the city's top tourist attraction with its fairground atmosphere, its Pantomime Theatre, its Concert Hall and its many rides and restaurants. The Carlsberg neighbourhood has some interesting vestiges of the old brewery of the same name including the Elephant Gate and the Ny Carlsberg Brewhouse. The Tycho Brahe Planetarium is located on the edge of Skt. Jørgens Sø, one of the Copenhagen lakes. Halmtorvet, the old haymarket behind the Central Station, is an increasingly popular area with its cafés and restaurants. The former cattle market Øksnehallen has been converted into a modern exhibition centre for art and photography. Radisson Blu Royal Hotel, built by Danish architect and designer Arne Jacobsen for the airline Scandinavian Airlines System (SAS) between 1956 and 1960 was once the tallest hotel in Denmark with a height of and the city's only skyscraper until 1969. Completed in 1908, Det Ny Teater (the New Theatre) located in a passage between Vesterbrogade and Gammel Kongevej has become a popular venue for musicals since its reopening in 1994, attracting the largest audiences in the country.

Nørrebro to the northwest of the city centre has recently developed from a working-class district into a colourful cosmopolitan area with antique shops, ethnic food stores and restaurants. Much of the activity is centred on Sankt Hans Torv. Copenhagen's historic cemetery, Assistens Kirkegård halfway up Nørrebrogade, is the resting place of many famous figures including Søren Kierkegaard, Niels Bohr, and Hans Christian Andersen but is also used by locals as a park and recreation area.

Just north of the city centre, Østerbro is an upper middle-class district with a number of fine mansions, some now serving as embassies. The district stretches from Nørrebro to the waterfront where "The Little Mermaid" statue can be seen from the promenade known as Langelinie. Inspired by Hans Christian Andersen's fairy tale, it was created by Edvard Eriksen and unveiled in 1913. Not far from the Little Mermaid, the old Citadel ("Kastellet") can be seen. Built by Christian IV, it is one of northern Europe's best preserved fortifications. There is also a windmill in the area. The large Gefion Fountain ("Gefionspringvandet") designed by Anders Bundgaard and completed in 1908 stands close to the southeast corner of Kastellet. Its figures illustrate a Nordic legend.

Frederiksberg, a separate municipality within the urban area of Copenhagen, lies to the west of Nørrebro and Indre By and north of Vesterbro. Its landmarks include Copenhagen Zoo founded in 1869 with over 250 species from all over the world and Frederiksberg Palace built as a summer residence by Frederick IV who was inspired by Italian architecture. Now a military academy, it overlooks the extensive landscaped Frederiksberg Gardens with its follies, waterfalls, lakes and decorative buildings. The wide tree-lined avenue of Frederiksberg Allé connecting Vesterbrogade with the Frederiksberg Gardens has long been associated with theatres and entertainment. While a number of the earlier theatres are now closed, the Betty Nansen Theatre and Aveny-T are still active.

Not far from Copenhagen Airport on the Kastrup coast, The Blue Planet completed in March 2013 now houses the national aquarium. With its 53 aquariums, it is the largest facility of its kind in Scandinavia. Grundtvig's Church, located in the northern suburb of Bispebjerg, was designed by P.V. Jensen Klint and completed in 1940. A rare example of Expressionist church architecture, its striking west façade is reminiscent of a church organ.

Apart from being the national capital, Copenhagen also serves as the cultural hub of Denmark and wider Scandinavia. Since the late 1990s, it has undergone a transformation from a modest Scandinavian capital into a metropolitan city of international appeal in the same league as Barcelona and Amsterdam. This is a result of huge investments in infrastructure and culture as well as the work of successful new Danish architects, designers and chefs. Copenhagen Fashion Week, the largest fashion event in Northern Europe, takes place every year in February and August.

Copenhagen has a wide array of museums of international standing. The National Museum, "Nationalmuseet", is Denmark's largest museum of archaeology and cultural history, comprising the histories of Danish and foreign cultures alike. Denmark's National Gallery ("Statens Museum for Kunst") is the national art museum with collections dating from the 12th century to the present. In addition to Danish painters, artists represented in the collections include Rubens, Rembrandt, Picasso, Braque, Léger, Matisse, Emil Nolde, Olafur Eliasson, Elmgreen and Dragset, Superflex and Jens Haaning.
Another important Copenhagen art museum is the Ny Carlsberg Glyptotek founded by second generation Carlsberg philanthropist Carl Jacobsen and built around his personal collections. Its main focus is classical Egyptian, Roman and Greek sculptures and antiquities and a collection of Rodin sculptures, the largest outside France. Besides its sculpture collections, the museum also holds a comprehensive collection of paintings of Impressionist and Post-Impressionist painters such as Monet, Renoir, Cézanne, van Gogh and Toulouse-Lautrec as well as works by the Danish Golden Age painters.

Louisiana is a museum of modern art situated on the coast just north of Copenhagen. It is located in the middle of a sculpture garden on a cliff overlooking Øresund. Its collection of over 3,000 items includes works by Picasso, Giacometti and Dubuffet. The Danish Design Museum is housed in the 18th-century former Frederiks Hospital and displays Danish design as well as international design and crafts.

Other museums include: the Thorvaldsens Museum, dedicated to the oeuvre of romantic Danish sculptor Bertel Thorvaldsen who lived and worked in Rome; the Cisternerne museum dedicated to modern glass art, located in former cisterns that come complete with stalactites formed by the changing water levels; and the Ordrupgaard Museum, located just north of Copenhagen, which features 19th-century French and Danish art and is noted for its works by Paul Gauguin.

The new Copenhagen Concert Hall opened in January 2009. Designed by Jean Nouvel, it has four halls with the main auditorium seating 1,800 people. It serves as the home of the Danish National Symphony Orchestra and along with the Walt Disney Concert Hall in Los Angeles is the most expensive concert hall ever built. Another important venue for classical music is the Tivoli Concert Hall located in the Tivoli Gardens. Designed by Henning Larsen, the Copenhagen Opera House ("Operaen") opened in 2005. It is among the most modern opera houses in the world. The Royal Danish Theatre also stages opera in addition to its drama productions. It is also home to the Royal Danish Ballet. Founded in 1748 along with the theatre, it is one of the oldest ballet troupes in Europe, and is noted for its Bournonville style of ballet. 

Copenhagen has a significant jazz scene that has existed for many years. It developed when a number of American jazz musicians such as Ben Webster, Thad Jones, Richard Boone, Ernie Wilkins, Kenny Drew, Ed Thigpen, Bob Rockwell, Dexter Gordon, and others such as rock guitarist Link Wray came to live in Copenhagen during the 1960s. Every year in early July, Copenhagen's streets, squares, parks as well as cafés and concert halls fill up with big and small jazz concerts during the Copenhagen Jazz Festival. One of Europe's top jazz festivals, the annual event features around 900 concerts at 100 venues with over 200,000 guests from Denmark and around the world.

The largest venue for popular music in Copenhagen is Vega in the Vesterbro district. It was chosen as "best concert venue in Europe" by international music magazine "Live". The venue has three concert halls: the great hall, Store Vega, accommodates audiences of 1,550, the middle hall, Lille Vega, has space for 500 and Ideal Bar Live has a capacity of 250. Every September since 2006, the Festival of Endless Gratitude (FOEG) has taken place in Copenhagen. This festival focuses on indie counterculture, experimental pop music and left field music combined with visual arts exhibitions.

Copenhagen is home to the "K-Town" punk and hardcore music community. This community developed around the underground scene venue Ungdomshuset in the late 90's punk scene, with punk- and hardcore acts such as Snipers, Amdi Petersens Armé, Gorilla Angreb, Young Wasteners, and No Hope For The Kids emerging as significant bands. The term "K-town" got international recognition within the punk-scene with the emergence of "K-Town" festivals. In 2001, the first of these was held in Ungdomshuset, on Jagtvej 69, Nørrebro, Copenhagen. The festival temporarily moved to Freetown Christiania after Ungdomshuset was evicted from its original location until a new Ungdomshuset location was opened on Dortheavej 61.

For free entertainment one can stroll along Strøget, especially between Nytorv and Højbro Plads, which in the late afternoon and evening is a bit like an impromptu three-ring circus with musicians, magicians, jugglers and other street performers.

Most of Denmarks's major publishing houses are based in Copenhagen. These include the book publishers Gyldendal and Akademisk Forlag and newspaper publishers Berlingske and Politiken (the latter also publishing books). Many of the most important contributors to Danish literature such as Hans Christian Andersen (1805–1875) with his fairy tales, the philosopher Søren Kierkegaard (1813–1855) and playwright Ludvig Holberg (1684–1754) spent much of their lives in Copenhagen. Novels set in Copenhagen include "Baby" (1973) by Kirsten Thorup, "The Copenhagen Connection" (1982) by Barbara Mertz, "Number the Stars" (1989) by Lois Lowry, "Miss Smilla's Feeling for Snow" (1992) and "Borderliners" (1993) by Peter Høeg, "Music and Silence" (1999) by Rose Tremain, "The Danish Girl" (2000) by David Ebershoff, and "Sharpe's Prey" (2001) by Bernard Cornwell. Michael Frayn's 1998 play "Copenhagen" about the meeting between the physicists Niels Bohr and Werner Heisenberg in 1941 is also set in the city. On 15–18 August 1973, an oral literature conference took place in Copenhagen as part of the 9th International Congress of Anthropological and Ethnological Sciences.

The Royal Library, belonging to the University of Copenhagen, is the largest library in the Nordic countries with an almost complete collection of all printed Danish books since 1482. Founded in 1648, the Royal Library is located at four sites in the city, the main one being on the Slotsholmen waterfront. Copenhagen's public library network has over 20 outlets, the largest being the Central Library ("Københavns Hovedbibliotek") on Krystalgade in the inner city.

Copenhagen has a wide selection of art museums and galleries displaying both historic works and more modern contributions. They include Statens Museum for Kunst, i.e. the Danish national art gallery, in the Østre Anlæg park, and the adjacent Hirschsprung Collection specialising in the 19th and early 20th century. Kunsthal Charlottenborg in the city centre exhibits national and international contemporary art. Den Frie Udstilling near the Østerport Station exhibits paintings created and selected by contemporary artists themselves rather than by the official authorities. The Arken Museum of Modern Art is located in southwestern Ishøj. Among artists who have painted scenes of Copenhagen are Martinus Rørbye (1803–1848), Christen Købke (1810–1848) and the prolific Paul Gustav Fischer (1860–1934).

A number of notable sculptures can be seen in the city. In addition to "The Little Mermaid" on the waterfront, there are two historic equestrian statues in the city centre: Jacques Saly's "Frederik V on Horseback" (1771) in Amalienborg Square and the statue of Christian V on Kongens Nytorv created by Abraham-César Lamoureux in 1688 who was inspired by the statue of Louis XIII in Paris. Rosenborg Castle Gardens contains several sculptures and monuments including August Saabye's Hans Christian Andersen, Aksel Hansen's Echo, and Vilhelm Bissen's Dowager Queen Caroline Amalie.

Copenhagen is believed to have invented the photomarathon photography competition, which has been held in the City each year since 1989.

, Copenhagen has 15 Michelin-starred restaurants, the most of any Scandinavian city. The city is increasingly recognized internationally as a gourmet destination. These include Den Røde Cottage, Formel B Restaurant, Grønbech & Churchill, Søllerød Kro, Kadeau, Kiin Kiin (Denmark's first Michelin-starred Asian gourmet restaurant), the French restaurant Kong Hans Kælder, Relæ, Restaurant AOC, Noma (short for Danish: "no"rdisk "ma"d, English: Nordic food) with two Stars and Geranium with three. Noma, was ranked as the Best Restaurant in the World by "Restaurant" in 2010, 2011, 2012, and again in 2014, sparking interest in the New Nordic Cuisine.

Apart from the selection of upmarket restaurants, Copenhagen offers a great variety of Danish, ethnic and experimental restaurants. It is possible to find modest eateries serving open sandwiches, known as smørrebrød – a traditional, Danish lunch dish; however, most restaurants serve international dishes. Danish pastry can be sampled from any of numerous bakeries found in all parts of the city. The Copenhagen Baker's Association dates back to the 1290s and Denmark's oldest confectioner's shop still operating, "Conditori La Glace", was founded in 1870 in Skoubogade by Nicolaus Henningsen, a trained master baker from Flensburg.

Copenhagen has long been associated with beer. Carlsberg beer has been brewed at the brewery's premises on the border between the Vesterbro and Valby districts since 1847 and has long been almost synonymous with Danish beer production. However, recent years have seen an explosive growth in the number of microbreweries so that Denmark today has more than 100 breweries, many of which are located in Copenhagen. Some like "Nørrebro Bryghus" also act as brewpubs where it is also possible to eat on the premises.

Copenhagen has one of the highest number of restaurants and bars per capita in the world. The nightclubs and bars stay open until 5 or 6 in the morning, some even longer. Denmark has a very liberal alcohol culture and a strong tradition for beer breweries, although binge drinking is frowned upon and the Danish Police take driving under the influence very seriously. Inner city areas such as Istedgade and Enghave Plads in Vesterbro, Sankt Hans Torv in Nørrebro and certain places in Frederiksberg are especially noted for their nightlife. Notable nightclubs include Bakken Kbh, ARCH (previously ZEN), Jolene, The Jane, Chateau Motel, KB3, At Dolores (previously Sunday Club), Rust, Vega Nightclub, Culture Box and Gefährlich, which also serves as a bar, café, restaurant, and art gallery.

Copenhagen has several recurring community festivals, mainly in the summer. Copenhagen Carnival has taken place every year since 1982 during the Whitsun Holiday in Fælledparken and around the city with the participation of 120 bands, 2,000 dancers and 100,000 spectators. Since 2010, the old B&W Shipyard at Refshaleøen in the harbour has been the location for Copenhell, a heavy metal rock music festival. Copenhagen Pride is a gay pride festival taking place every year in August. The Pride has a series of different activities all over Copenhagen, but it is at the City Hall Square that most of the celebration takes place. During the Pride the square is renamed Pride Square. Copenhagen Distortion has emerged to be one of the biggest street festivals in Europe with 100.000 people joining to parties in the beginning of June every year.

Copenhagen has the two oldest amusement parks in the world.

Dyrehavsbakken, a fair-ground and pleasure-park established in 1583, is located in Klampenborg just north of Copenhagen in a forested area known as Dyrehaven. Created as an amusement park complete with rides, games and restaurants by Christian IV, it is the oldest surviving amusement park in the world. Pierrot (), a nitwit dressed in white with a scarlet grin wearing a boat-like hat while entertaining children, remains one of the park's key attractions. In Danish, Dyrehavsbakken is often abbreviated as "Bakken". There is no entrance fee to pay and Klampenborg Station on the C-line, is situated nearby.

The Tivoli Gardens is an amusement park and pleasure garden located in central Copenhagen between the City Hall Square and the Central Station. It opened in 1843, making it the second oldest amusement park in the world. Among its rides are the oldest still operating rollercoaster "Rutschebanen" from 1915 and the oldest ferris wheel still in use, opened in 1943. Tivoli Gardens also serves as a venue for various performing arts and as an active part of the cultural scene in Copenhagen.

Copenhagen has over 94,000 students enrolled in its largest universities and institutions: University of Copenhagen (38,867 students), Copenhagen Business School (19,999 students), Metropolitan University College and University College Capital (10,000 students each), Technical University of Denmark (7,000 students), KEA (c. 4,500 students), IT University of Copenhagen (2,000 students) and Aalborg University – Copenhagen (2,300 students).

The University of Copenhagen is Denmark's oldest university founded in 1479. It attracts some 1,500 international and exchange students every year. The Academic Ranking of World Universities placed it 30th in the world in 2016.

The Technical University of Denmark is located in Lyngby in the northern outskirts of Copenhagen. In 2013, it was ranked as one of the leading technical universities in Northern Europe. The IT University is Denmark's youngest university, a mono-faculty institution focusing on technical, societal and business aspects of information technology.

The Danish Academy of Fine Arts has provided education in the arts for more than 250 years. It includes the historic School of Visual Arts, and has in later years come to include a School of Architecture, a School of Design and a School of Conservation. Copenhagen Business School (CBS) is an EQUIS-accredited business school located in Frederiksberg.
There are also branches of both University College Capital and Metropolitan University College inside and outside Copenhagen.

The city has a variety of sporting teams. The major football teams are the historically successful FC København and Brøndby. FC København plays at Parken in Østerbro. Formed in 1992, it is a merger of two older Copenhagen clubs, B 1903 (from the inner suburb Gentofte) and KB (from Frederiksberg). Brøndby plays at Brøndby Stadion in the inner suburb of Brøndbyvester. BK Frem is based in the southern part of Copenhagen (Sydhavnen, Valby). Other teams are FC Nordsjælland (from suburban Farum), Fremad Amager, B93, AB, Lyngby and Hvidovre IF.
Copenhagen has several handball teams—a sport which is particularly popular in Denmark. Of clubs playing in the "highest" leagues, there are Ajax, Ydun, and HIK (Hellerup). The København Håndbold women's club has recently been established. Copenhagen also has ice hockey teams, of which three play in the top league, Rødovre Mighty Bulls, Herlev Eagles and Hvidovre Ligahockey all inner suburban clubs. Copenhagen Ice Skating Club founded in 1869 is the oldest ice hockey team in Denmark but is no longer in the top league.

Rugby union is also played in the Danish capital with teams such as CSR-Nanok, Copenhagen Business School Sport Rugby, Frederiksberg RK, Exiles RUFC and Rugbyklubben Speed. Rugby league is now played in Copenhagen, with the national team playing out of Gentofte Stadion. The Danish Australian Football League, based in Copenhagen is the largest Australian rules football competition outside of the English-speaking world.

Copenhagen Marathon, Copenhagen's annual marathon event, was established in 1980.
Round Christiansborg Open Water Swim Race is a open water swimming competition taking place each year in late August. This amateur event is combined with a Danish championship. In 2009 the event included a FINA World Cup competition in the morning. Copenhagen hosted the 2011 UCI Road World Championships in September 2011, taking advantage of its bicycle-friendly infrastructure. It was the first time that Denmark had hosted the event since 1956, when it was also held in Copenhagen.

The greater Copenhagen area has a very well established transportation infrastructure making it a hub in Northern Europe. Copenhagen Airport, opened in 1925, is Scandinavia's largest airport, located in Kastrup on the island of Amager. It is connected to the city centre by metro and main line railway services. October 2013 was a record month with 2.2 million passengers, and November 2013 figures reveal that the number of passengers is increasing by some 3% annually, about 50% more than the European average.
Copenhagen has an extensive road network including motorways connecting the city to other parts of Denmark and to Sweden over the Øresund Bridge. The car is still the most popular form of transport within the city itself, representing two-thirds of all distances travelled. This can however lead to serious congestion in rush hour traffic. The Øresund train links Copenhagen with Malmö 24 hours a day, 7 days a week. 
Copenhagen is also served by a daily ferry connection to Oslo in Norway. In 2012, Copenhagen Harbour handled 372 cruise ships and 840,000 passengers.
The Copenhagen S-Train, Copenhagen Metro and the regional train networks are used by about half of the city's passengers, the remainder using bus services. Nørreport Station near the city centre serves passengers travelling by main-line rail, S-train, regional train, metro and bus. Some 750,000 passengers make use of public transport facilities every day. Copenhagen Central Station is the hub of the DSB railway network serving Denmark and international destinations.

Copenhagen is cited by urban planners for its exemplary integration of public transport and urban development. In implementing its Finger Plan, Copenhagen is considered the world's first example of a transit metropolis and areas around S-Train stations like Ballerup and Brøndby Strand are among the earliest examples of transit-oriented development.

The Danish capital is known as one of the most bicycle-friendly cities in the world, with bicycles actually outnumbering its inhabitants. In 2012 some 36% of all working or studying city-dwellers cycled to work, school, or university. With 1.27 million km covered every working day by Copenhagen's cyclists (including both residents and commuters), and 75% of Copenhageners cycling throughout the year. The city's bicycle paths are extensive and well used, boasting of cycle lanes not shared with cars or pedestrians, and sometimes have their own signal systems – giving the cyclists a lead of a couple of seconds to accelerate.
Promoting health is an extremely important issue for Copenhagen's municipal authorities. Central to its sustainability mission is its "Long Live Copenhagen" ("Længe Leve København") scheme in which it has the goal of increasing the life expectancy of citizens, improving quality of life through better standards of health, and encouraging more productive lives and equal opportunities. The city has targets to encourage people to exercise regularly and to reduce the number who smoke and consume alcohol.
Copenhagen University Hospital forms a conglomerate of several hospitals in Region Hovedstaden and Region Sjælland, together with the faculty of health sciences at the University of Copenhagen; Rigshospitalet and Bispebjerg Hospital in Copenhagen belong to this group of university hospitals. Rigshospitalet began operating in March 1757 as Frederiks Hospital, and became state-owned in 1903. With 1,120 beds, Rigshospitalet has responsibility for 65,000 inpatients and approximately 420,000 outpatients annually. It seeks to be the number one specialist hospital in the country, with an extensive team of researchers into cancer treatment, surgery and radiotherapy. In addition to its 8,000 personnel, the hospital has training and hosting functions. It benefits from the presence of in-service students of medicine and other healthcare sciences, as well as scientists working under a variety of research grants. The hospital became internationally famous as the location of Lars von Trier's television horror mini-series "The Kingdom". Bispebjerg Hospital was built in 1913, and serves about 400,000 people in the Greater Copenhagen area, with some 3,000 employees. Other large hospitals in the city include Amager Hospital (1997), Herlev Hospital (1976), Hvidovre Hospital (1970), and Gentofte Hospital (1927).

Many Danish media corporations are located in Copenhagen. DR, the major Danish public service broadcasting corporation consolidated their activities in a new headquarters, DR Byen, in 2006 and 2007. Similarly TV2 which is based in Odense has concentrated its Copenhagen activities in a modern media house in Teglholmen. The two national daily newspapers "Politiken" and "Berlingske Tidende" and the two tabloids "Ekstra Bladet" and "B.T." are based in Copenhagen. "Kristeligt Dagblad" is based in Copenhagen and is published six days a week. Other important media corporations include Aller Media which is the largest publisher of weekly and monthly magazines in Scandinavia, the Egmont media group and Gyldendal, the largest Danish publisher of books.

Copenhagen also has a sizable film and television industry. Nordisk Film, established in Valby, Copenhagen in 1906 is the oldest continuously operating film production company in the world. In 1992 it merged with the Egmont media group and currently runs the 17-screen Palads Cinema in Copenhagen. Filmbyen (movie city), located in a former military camp in the suburb of Hvidovre, houses several movie companies and studios. Among the movie companies is Zentropa, co-owned by Danish movie director Lars von Trier who is behind several international movie productions as well as a founding force behind the Dogme Movement. is Copenhagen's international feature film festival, established in 2009 as a fusion of the 20-year-old Natfilm festival and the four-year-old CIFF. The CPH:PIX festival takes place in mid-April. CPH:DOX is Copenhagen's international documentary film festival, every year in November. On top of its documentary film programme of over 100 films, CPH:DOX includes a wide event programme with dozens of events, concerts, exhibitions and parties all over town.

Copenhagen is twinned or cooperating with several cities, including:







</doc>
<doc id="5170" url="https://en.wikipedia.org/wiki?curid=5170" title="Combinatorics">
Combinatorics

Combinatorics is an area of mathematics primarily concerned with counting, both as a means and an end in obtaining results, and certain properties of finite structures. It is closely related to many other areas of mathematics and has many applications ranging from logic to statistical physics, from evolutionary biology to computer science, etc. 

To fully understand the scope of combinatorics requires a great deal of further amplification, the details of which are not universally agreed upon. According to H. J. Ryser, a definition of the subject is difficult because it crosses so many mathematical subdivisions. In so far as an area can be described by the types of problems it addresses, combinatorics is involved with

Leon Mirsky has said: "combinatorics is a range of linked studies which have something in common and yet diverge widely in their objectives, their methods, and the degree of coherence they have attained." One way to define combinatorics is, perhaps, to describe its subdivisions with their problems and techniques. This is the approach that is used below. However, there are also purely historical reasons for including or not including some topics under the combinatorics umbrella. Although primarily concerned with finite systems, some combinatorial questions and techniques can be extended to an infinite (specifically, countable) but discrete setting. 

Combinatorics is well known for the breadth of the problems it tackles. Combinatorial problems arise in many areas of pure mathematics, notably in algebra, probability theory, topology, and geometry, as well as in its many application areas. Many combinatorial questions have historically been considered in isolation, giving an "ad hoc" solution to a problem arising in some mathematical context. In the later twentieth century, however, powerful and general theoretical methods were developed, making combinatorics into an independent branch of mathematics in its own right. One of the oldest and most accessible parts of combinatorics is graph theory, which by itself has numerous natural connections to other areas. Combinatorics is used frequently in computer science to obtain formulas and estimates in the analysis of algorithms.

A mathematician who studies combinatorics is called a "".

Basic combinatorial concepts and enumerative results appeared throughout the ancient world. In the 6th century BCE, ancient Indian physician Sushruta asserts in Sushruta Samhita that 63 combinations can be made out of 6 different tastes, taken one at a time, two at a time, etc., thus computing all 2 − 1 possibilities. Greek historian Plutarch discusses an argument between Chrysippus (3rd century BCE) and Hipparchus (2nd century BCE) of a rather delicate enumerative problem, which was later shown to be related to Schröder–Hipparchus numbers. In the "Ostomachion", Archimedes (3rd century BCE) considers a tiling puzzle.

In the Middle Ages, combinatorics continued to be studied, largely outside of the European civilization. The Indian mathematician Mahāvīra (c. 850) provided formulae for the number of permutations and combinations, and these formulas may have been familiar to Indian mathematicians as early as the 6th century CE. The philosopher and astronomer Rabbi Abraham ibn Ezra (c. 1140) established the symmetry of binomial coefficients, while a closed formula was obtained later by the talmudist and mathematician Levi ben Gerson (better known as Gersonides), in 1321.
The arithmetical triangle— a graphical diagram showing relationships among the binomial coefficients— was presented by mathematicians in treatises dating as far back as the 10th century, and would eventually become known as Pascal's triangle. Later, in Medieval England, campanology provided examples of what is now known as Hamiltonian cycles in certain Cayley graphs on permutations.

During the Renaissance, together with the rest of mathematics and the sciences, combinatorics enjoyed a rebirth. Works of Pascal, Newton, Jacob Bernoulli and Euler became foundational in the emerging field. In modern times, the works of J. J. Sylvester (late 19th century) and Percy MacMahon (early 20th century) helped lay the foundation for enumerative and algebraic combinatorics. Graph theory also enjoyed an explosion of interest at the same time, especially in connection with the four color problem.

In the second half of the 20th century, combinatorics enjoyed a rapid growth, which led to establishment of dozens of new journals and conferences in the subject. In part, the growth was spurred by new connections and applications to other fields, ranging from algebra to probability, from functional analysis to number theory, etc. These connections shed the boundaries between combinatorics and parts of mathematics and theoretical computer science, but at the same time led to a partial fragmentation of the field.

Enumerative combinatorics is the most classical area of combinatorics and concentrates on counting the number of certain combinatorial objects. Although counting the number of elements in a set is a rather broad mathematical problem, many of the problems that arise in applications have a relatively simple combinatorial description. Fibonacci numbers is the basic example of a problem in enumerative combinatorics. The twelvefold way provides a unified framework for counting permutations, combinations and partitions.

Analytic combinatorics concerns the enumeration of combinatorial structures using tools from complex analysis and probability theory. In contrast with enumerative combinatorics, which uses explicit combinatorial formulae and generating functions to describe the results, analytic combinatorics aims at obtaining asymptotic formulae.

Partition theory studies various enumeration and asymptotic problems related to integer partitions, and is closely related to q-series, special functions and orthogonal polynomials. Originally a part of number theory and analysis, it is now considered a part of combinatorics or an independent field. It incorporates the bijective approach and various tools in analysis and analytic number theory, and has connections with statistical mechanics.

Graphs are basic objects in combinatorics. The questions range from counting (e.g., the number of graphs on "n" vertices with "k" edges) to structural (e.g., which graphs contain Hamiltonian cycles) to algebraic questions (e.g., given a graph "G" and two numbers "x" and "y", does the Tutte polynomial "T"("x","y") have a combinatorial interpretation?). Although there are very strong connections between graph theory and combinatorics, these two are sometimes thought of as separate subjects. This is due to the fact that while combinatorial methods apply to many graph theory problems, the two are generally used to seek solutions to different problems.

Design theory is a study of combinatorial designs, which are collections of subsets with certain intersection properties. Block designs are combinatorial designs of a special type. This area is one of the oldest parts of combinatorics, such as in Kirkman's schoolgirl problem proposed in 1850. The solution of the problem is a special case of a Steiner system, which systems play an important role in the classification of finite simple groups. The area has further connections to coding theory and geometric combinatorics.

Finite geometry is the study of geometric systems having only a finite number of points. Structures analogous to those found in continuous geometries (Euclidean plane, real projective space, etc.) but defined combinatorially are the main items studied. This area provides a rich source of examples for design theory. It should not be confused with discrete geometry (combinatorial geometry).

Order theory is the study of partially ordered sets, both finite and infinite. Various examples of partial orders appear in algebra, geometry, number theory and throughout combinatorics and graph theory. Notable classes and examples of partial orders include lattices and Boolean algebras.

Matroid theory abstracts part of geometry. It studies the properties of sets (usually, finite sets) of vectors in a vector space that do not depend on the particular coefficients in a linear dependence relation. Not only the structure but also enumerative properties belong to matroid theory. Matroid theory was introduced by Hassler Whitney and studied as a part of order theory. It is now an independent field of study with a number of connections with other parts of combinatorics.

Extremal combinatorics studies extremal questions on set systems. The types of questions addressed in this case are about the largest possible graph which satisfies certain properties. For example, the largest triangle-free graph on "2n" vertices is a complete bipartite graph "K". Often it is too hard even to find the extremal answer "f"("n") exactly and one can only give an asymptotic estimate.

Ramsey theory is another part of extremal combinatorics. It states that any sufficiently large configuration will contain some sort of order. It is an advanced generalization of the pigeonhole principle.

In probabilistic combinatorics, the questions are of the following type: what is the probability of a certain property for a random discrete object, such as a random graph? For instance, what is the average number of triangles in a random graph? Probabilistic methods are also used to determine the existence of combinatorial objects with certain prescribed properties (for which explicit examples might be difficult to find), simply by observing that the probability of randomly selecting an object with those properties is greater than 0. This approach (often referred to as "the" probabilistic method) proved highly effective in applications to extremal combinatorics and graph theory. A closely related area is the study of finite Markov chains, especially on combinatorial objects. Here again probabilistic tools are used to estimate the mixing time.

Often associated with Paul Erdős, who did the pioneering work on the subject, probabilistic combinatorics was traditionally viewed as a set of tools to study problems in other parts of combinatorics. However, with the growth of applications to analysis of algorithms in computer science, as well as classical probability, additive and probabilistic number theory, the area recently grew to become an independent field of combinatorics.

Algebraic combinatorics is an area of mathematics that employs methods of abstract algebra, notably group theory and representation theory, in various combinatorial contexts and, conversely, applies combinatorial techniques to problems in algebra. Algebraic combinatorics is continuously expanding its scope, in both topics and techniques, and can be seen as the area of mathematics where the interaction of combinatorial and algebraic methods is particularly strong and significant.

Combinatorics on words deals with formal languages. It arose independently within several branches of mathematics, including number theory, group theory and probability. It has applications to enumerative combinatorics, fractal analysis, theoretical computer science, automata theory and linguistics. While many applications are new, the classical Chomsky–Schützenberger hierarchy of classes of formal grammars is perhaps the best-known result in the field.

Geometric combinatorics is related to convex and discrete geometry, in particular polyhedral combinatorics. It asks, for example, how many faces of each dimension a convex polytope can have. Metric properties of polytopes play an important role as well, e.g. the Cauchy theorem on the rigidity of convex polytopes. Special polytopes are also considered, such as permutohedra, associahedra and Birkhoff polytopes. We should note that combinatorial geometry is an old fashioned name for discrete geometry.

Combinatorial analogs of concepts and methods in topology are used to study graph coloring, fair division, partitions, partially ordered sets, decision trees, necklace problems and discrete Morse theory. It should not be confused with combinatorial topology which is an older name for algebraic topology.

Arithmetic combinatorics arose out of the interplay between number theory, combinatorics, ergodic theory and harmonic analysis. It is about combinatorial estimates associated with arithmetic operations (addition, subtraction, multiplication, and division). Additive number theory (sometimes also called additive combinatorics) refers to the special case when only the operations of addition and subtraction are involved. One important technique in arithmetic combinatorics is the ergodic theory of dynamical systems.

Infinitary combinatorics, or combinatorial set theory, is an extension of ideas in combinatorics to infinite sets. It is a part of set theory, an area of mathematical logic, but uses tools and ideas from both set theory and extremal combinatorics.

Gian-Carlo Rota used the name "continuous combinatorics" to describe geometric probability, since there are many analogies between "counting" and "measure".

Combinatorial optimization is the study of optimization on discrete and combinatorial objects. It started as a part of combinatorics and graph theory, but is now viewed as a branch of applied mathematics and computer science, related to operations research, algorithm theory and computational complexity theory.

Coding theory started as a part of design theory with early combinatorial constructions of error-correcting codes. The main idea of the subject is to design efficient and reliable methods of data transmission. It is now a large field of study, part of information theory.

Discrete geometry (also called combinatorial geometry) also began as a part of combinatorics, with early results on convex polytopes and kissing numbers. With the emergence of applications of discrete geometry to computational geometry, these two fields partially merged and became a separate field of study. There remain many connections with geometric and topological combinatorics, which themselves can be viewed as outgrowths of the early discrete geometry.

Combinatorial aspects of dynamical systems is another emerging field. Here dynamical systems can be defined on combinatorial objects. See for example 
graph dynamical system.

There are increasing interactions between combinatorics and physics, particularly statistical physics. Examples include an exact solution of the Ising model, and a connection between the Potts model on one hand, and the chromatic and Tutte polynomials on the other hand.





</doc>
<doc id="5176" url="https://en.wikipedia.org/wiki?curid=5176" title="Calculus">
Calculus

Calculus (from Latin "calculus", literally 'small pebble', used for counting and calculations, as on an abacus), is the mathematical study of continuous change, in the same way that geometry is the study of shape and algebra is the study of generalizations of arithmetic operations. It has two major branches, differential calculus (concerning rates of change and slopes of curves), and integral calculus (concerning accumulation of quantities and the areas under and between curves). These two branches are related to each other by the fundamental theorem of calculus. Both branches make use of the fundamental notions of convergence of infinite sequences and infinite series to a well-defined limit. Generally, modern calculus is considered to have been developed in the 17th century by Isaac Newton and Gottfried Wilhelm Leibniz. Today, calculus has widespread uses in science, engineering, and economics.

Calculus is a part of modern mathematics education. A course in calculus is a gateway to other, more advanced courses in mathematics devoted to the study of functions and limits, broadly called mathematical analysis. Calculus has historically been called "the calculus of infinitesimals", or "infinitesimal calculus". The term "calculus" (plural "calculi") is also used for naming specific methods of calculation or notation as well as some theories, such as propositional calculus, Ricci calculus, calculus of variations, lambda calculus, and process calculus.

Modern calculus was developed in 17th-century Europe by Isaac Newton and Gottfried Wilhelm Leibniz (independently of each other, first publishing around the same time) but elements of it have appeared in ancient Greece, then in China and the Middle East, and still later again in medieval Europe and in India.

The ancient period introduced some of the ideas that led to integral calculus, but does not seem to have developed these ideas in a rigorous and systematic way. Calculations of volume and area, one goal of integral calculus, can be found in the Egyptian Moscow papyrus (13th dynasty,  BC), but the formulas are simple instructions, with no indication as to method, and some of them lack major components. From the age of Greek mathematics, Eudoxus ( BC) used the method of exhaustion, which foreshadows the concept of the limit, to calculate areas and volumes, while Archimedes ( BC) developed this idea further, inventing heuristics which resemble the methods of integral calculus. The method of exhaustion was later discovered independently in China by Liu Hui in the 3rd century AD in order to find the area of a circle. In the 5th century AD, Zu Gengzhi, son of Zu Chongzhi, established a method that would later be called Cavalieri's principle to find the volume of a sphere.

In the Middle East, Alhazen ( ) derived a formula for the sum of fourth powers. He used the results to carry out what would now be called an integration of this function, where the formulae for the sums of integral squares and fourth powers allowed him to calculate the volume of a paraboloid. In the 14th century, Indian mathematicians gave a non-rigorous method, resembling differentiation, applicable to some trigonometric functions. Madhava of Sangamagrama and the Kerala School of Astronomy and Mathematics thereby stated components of calculus. A complete theory encompassing these components is now well-known in the Western world as the "Taylor series" or "infinite series approximations". However, they were not able to "combine many differing ideas under the two unifying themes of the derivative and the integral, show the connection between the two, and turn calculus into the great problem-solving tool we have today".

In Europe, the foundational work was a treatise due to Bonaventura Cavalieri, who argued that volumes and areas should be computed as the sums of the volumes and areas of infinitesimally thin cross-sections. The ideas were similar to Archimedes' in "The Method", but this treatise is believed to have been lost in the 13th century, and was only rediscovered in the early 20th century, and so would have been unknown to Cavalieri. Cavalieri's work was not well respected since his methods could lead to erroneous results, and the infinitesimal quantities he introduced were disreputable at first.

The formal study of calculus brought together Cavalieri's infinitesimals with the calculus of finite differences developed in Europe at around the same time. Pierre de Fermat, claiming that he borrowed from Diophantus, introduced the concept of adequality, which represented equality up to an infinitesimal error term. The combination was achieved by John Wallis, Isaac Barrow, and James Gregory, the latter two proving the second fundamental theorem of calculus around 1670.
The product rule and chain rule, the notions of higher derivatives and Taylor series, and of analytic functions were introduced by Isaac Newton in an idiosyncratic notation which he used to solve problems of mathematical physics. In his works, Newton rephrased his ideas to suit the mathematical idiom of the time, replacing calculations with infinitesimals by equivalent geometrical arguments which were considered beyond reproach. He used the methods of calculus to solve the problem of planetary motion, the shape of the surface of a rotating fluid, the oblateness of the earth, the motion of a weight sliding on a cycloid, and many other problems discussed in his "Principia Mathematica" (1687). In other work, he developed series expansions for functions, including fractional and irrational powers, and it was clear that he understood the principles of the Taylor series. He did not publish all these discoveries, and at this time infinitesimal methods were still considered disreputable.

These ideas were arranged into a true calculus of infinitesimals by Gottfried Wilhelm Leibniz, who was originally accused of plagiarism by Newton. He is now regarded as an independent inventor of and contributor to calculus. His contribution was to provide a clear set of rules for working with infinitesimal quantities, allowing the computation of second and higher derivatives, and providing the product rule and chain rule, in their differential and integral forms. Unlike Newton, Leibniz paid a lot of attention to the formalism, often spending days determining appropriate symbols for concepts.

Today, Leibniz and Newton are usually both given credit for independently inventing and developing calculus. Newton was the first to apply calculus to general physics and Leibniz developed much of the notation used in calculus today. The basic insights that both Newton and Leibniz provided were the laws of differentiation and integration, second and higher derivatives, and the notion of an approximating polynomial series. By Newton's time, the fundamental theorem of calculus was known.

When Newton and Leibniz first published their results, there was great controversy over which mathematician (and therefore which country) deserved credit. Newton derived his results first (later to be published in his "Method of Fluxions"), but Leibniz published his "Nova Methodus pro Maximis et Minimis" first. Newton claimed Leibniz stole ideas from his unpublished notes, which Newton had shared with a few members of the Royal Society. This controversy divided English-speaking mathematicians from continental European mathematicians for many years, to the detriment of English mathematics. A careful examination of the papers of Leibniz and Newton shows that they arrived at their results independently, with Leibniz starting first with integration and Newton with differentiation. It is Leibniz, however, who gave the new discipline its name. Newton called his calculus "the science of fluxions".

Since the time of Leibniz and Newton, many mathematicians have contributed to the continuing development of calculus. One of the first and most complete works on both infinitesimal and integral calculus was written in 1748 by Maria Gaetana Agnesi.
In calculus, "foundations" refers to the rigorous development of the subject from axioms and definitions. In early calculus the use of infinitesimal quantities was thought unrigorous, and was fiercely criticized by a number of authors, most notably Michel Rolle and Bishop Berkeley. Berkeley famously described infinitesimals as the ghosts of departed quantities in his book "The Analyst" in 1734. Working out a rigorous foundation for calculus occupied mathematicians for much of the century following Newton and Leibniz, and is still to some extent an active area of research today.

Several mathematicians, including Maclaurin, tried to prove the soundness of using infinitesimals, but it would not be until 150 years later when, due to the work of Cauchy and Weierstrass, a way was finally found to avoid mere "notions" of infinitely small quantities. The foundations of differential and integral calculus had been laid. In Cauchy's "Cours d'Analyse", we find a broad range of foundational approaches, including a definition of continuity in terms of infinitesimals, and a (somewhat imprecise) prototype of an (ε, δ)-definition of limit in the definition of differentiation. In his work Weierstrass formalized the concept of limit and eliminated infinitesimals (although his definition can actually validate nilsquare infinitesimals). Following the work of Weierstrass, it eventually became common to base calculus on limits instead of infinitesimal quantities, though the subject is still occasionally called "infinitesimal calculus". Bernhard Riemann used these ideas to give a precise definition of the integral. It was also during this period that the ideas of calculus were generalized to Euclidean space and the complex plane.

In modern mathematics, the foundations of calculus are included in the field of real analysis, which contains full definitions and proofs of the theorems of calculus. The reach of calculus has also been greatly extended. Henri Lebesgue invented measure theory and used it to define integrals of all but the most pathological functions. Laurent Schwartz introduced distributions, which can be used to take the derivative of any function whatsoever.

Limits are not the only rigorous approach to the foundation of calculus. Another way is to use Abraham Robinson's non-standard analysis. Robinson's approach, developed in the 1960s, uses technical machinery from mathematical logic to augment the real number system with infinitesimal and infinite numbers, as in the original Newton-Leibniz conception. The resulting numbers are called hyperreal numbers, and they can be used to give a Leibniz-like development of the usual rules of calculus. There is also smooth infinitesimal analysis, which differs from non-standard analysis in that it mandates neglecting higher power infinitesimals during derivations.

While many of the ideas of calculus had been developed earlier in Greece, China, India, Iraq, Persia, and Japan, the use of calculus began in Europe, during the 17th century, when Isaac Newton and Gottfried Wilhelm Leibniz built on the work of earlier mathematicians to introduce its basic principles. The development of calculus was built on earlier concepts of instantaneous motion and area underneath curves.

Applications of differential calculus include computations involving velocity and acceleration, the slope of a curve, and optimization. Applications of integral calculus include computations involving area, volume, arc length, center of mass, work, and pressure. More advanced applications include power series and Fourier series.

Calculus is also used to gain a more precise understanding of the nature of space, time, and motion. For centuries, mathematicians and philosophers wrestled with paradoxes involving division by zero or sums of infinitely many numbers. These questions arise in the study of motion and area. The ancient Greek philosopher Zeno of Elea gave several famous examples of such paradoxes. Calculus provides tools, especially the limit and the infinite series, that resolve the paradoxes.

Calculus is usually developed by working with very small quantities. Historically, the first method of doing so was by infinitesimals. These are objects which can be treated like real numbers but which are, in some sense, "infinitely small". For example, an infinitesimal number could be greater than 0, but less than any number in the sequence 1, 1/2, 1/3, ... and thus less than any positive real number. From this point of view, calculus is a collection of techniques for manipulating infinitesimals. The symbols "dx" and "dy" were taken to be infinitesimal, and the derivative formula_1 was simply their ratio.

The infinitesimal approach fell out of favor in the 19th century because it was difficult to make the notion of an infinitesimal precise. However, the concept was revived in the 20th century with the introduction of non-standard analysis and smooth infinitesimal analysis, which provided solid foundations for the manipulation of infinitesimals.

In the 19th century, infinitesimals were replaced by the epsilon, delta approach to limits. Limits describe the value of a function at a certain input in terms of its values at nearby inputs. They capture small-scale behavior in the context of the real number system. In this treatment, calculus is a collection of techniques for manipulating certain limits. Infinitesimals get replaced by very small numbers, and the infinitely small behavior of the function is found by taking the limiting behavior for smaller and smaller numbers. Limits were the first way to provide rigorous foundations for calculus, and for this reason they are the standard approach.

Differential calculus is the study of the definition, properties, and applications of the derivative of a function. The process of finding the derivative is called "differentiation". Given a function and a point in the domain, the derivative at that point is a way of encoding the small-scale behavior of the function near that point. By finding the derivative of a function at every point in its domain, it is possible to produce a new function, called the "derivative function" or just the "derivative" of the original function. In formal terms, the derivative is a linear operator which takes a function as its input and produces a second function as its output. This is more abstract than many of the processes studied in elementary algebra, where functions usually input a number and output another number. For example, if the doubling function is given the input three, then it outputs six, and if the squaring function is given the input three, then it outputs nine. The derivative, however, can take the squaring function as an input. This means that the derivative takes all the information of the squaring function—such as that two is sent to four, three is sent to nine, four is sent to sixteen, and so on—and uses this information to produce another function. The function produced by deriving the squaring function turns out to be the doubling function.

In more explicit terms the "doubling function" may be denoted by and the "squaring function" by . The "derivative" now takes the function , defined by the expression "", as an input, that is all the information —such as that two is sent to four, three is sent to nine, four is sent to sixteen, and so on— and uses this information to output another function, the function , as will turn out.

The most common symbol for a derivative is an apostrophe-like mark called prime. Thus, the derivative of a function called is denoted by , pronounced "f prime". For instance, if is the squaring function, then is its derivative (the doubling function from above). This notation is known as Lagrange's notation.

If the input of the function represents time, then the derivative represents change with respect to time. For example, if is a function that takes a time as input and gives the position of a ball at that time as output, then the derivative of is how the position is changing in time, that is, it is the velocity of the ball.

If a function is linear (that is, if the graph of the function is a straight line), then the function can be written as , where is the independent variable, is the dependent variable, is the "y"-intercept, and:

This gives an exact value for the slope of a straight line. If the graph of the function is not a straight line, however, then the change in divided by the change in varies. Derivatives give an exact meaning to the notion of change in output with respect to change in input. To be concrete, let be a function, and fix a point in the domain of . is a point on the graph of the function. If is a number close to zero, then is a number close to . Therefore, is close to . The slope between these two points is

This expression is called a "difference quotient". A line through two points on a curve is called a "secant line", so is the slope of the secant line between and . The secant line is only an approximation to the behavior of the function at the point because it does not account for what happens between and . It is not possible to discover the behavior at by setting to zero because this would require dividing by zero, which is undefined. The derivative is defined by taking the limit as tends to zero, meaning that it considers the behavior of for all small values of and extracts a consistent value for the case when equals zero:

Geometrically, the derivative is the slope of the tangent line to the graph of at . The tangent line is a limit of secant lines just as the derivative is a limit of difference quotients. For this reason, the derivative is sometimes called the slope of the function .

Here is a particular example, the derivative of the squaring function at the input 3. Let be the squaring function.

The slope of the tangent line to the squaring function at the point (3, 9) is 6, that is to say, it is going up six times as fast as it is going to the right. The limit process just described can be performed for any point in the domain of the squaring function. This defines the "derivative function" of the squaring function, or just the "derivative" of the squaring function for short. A computation similar to the one above shows that the derivative of the squaring function is the doubling function.

A common notation, introduced by Leibniz, for the derivative in the example above is
In an approach based on limits, the symbol is to be interpreted not as the quotient of two numbers but as a shorthand for the limit computed above. Leibniz, however, did intend it to represent the quotient of two infinitesimally small numbers, being the infinitesimally small change in caused by an infinitesimally small change applied to . We can also think of as a differentiation operator, which takes a function as an input and gives another function, the derivative, as the output. For example:

In this usage, the in the denominator is read as "with respect to ". Another example of correct notation could be:

formula_8

Even when calculus is developed using limits rather than infinitesimals, it is common to manipulate symbols like and as if they were real numbers; although it is possible to avoid such manipulations, they are sometimes notationally convenient in expressing operations such as the total derivative.

"Integral calculus" is the study of the definitions, properties, and applications of two related concepts, the "indefinite integral" and the "definite integral". The process of finding the value of an integral is called "integration". In technical language, integral calculus studies two related linear operators.

The "indefinite integral", also known as the "antiderivative", is the inverse operation to the derivative. is an indefinite integral of when is a derivative of . (This use of lower- and upper-case letters for a function and its indefinite integral is common in calculus.)

The "definite integral" inputs a function and outputs a number, which gives the algebraic sum of areas between the graph of the input and the x-axis. The technical definition of the definite integral involves the limit of a sum of areas of rectangles, called a Riemann sum.

A motivating example is the distances traveled in a given time.

If the speed is constant, only multiplication is needed, but if the speed changes, a more powerful method of finding the distance is necessary. One such method is to approximate the distance traveled by breaking up the time into many short intervals of time, then multiplying the time elapsed in each interval by one of the speeds in that interval, and then taking the sum (a Riemann sum) of the approximate distance traveled in each interval. The basic idea is that if only a short time elapses, then the speed will stay more or less the same. However, a Riemann sum only gives an approximation of the distance traveled. We must take the limit of all such Riemann sums to find the exact distance traveled.

When velocity is constant, the total distance traveled over the given time interval can be computed by multiplying velocity and time. For example, travelling a steady 50 mph for 3 hours results in a total distance of 150 miles. In the diagram on the left, when constant velocity and time are graphed, these two values form a rectangle with height equal to the velocity and width equal to the time elapsed. Therefore, the product of velocity and time also calculates the rectangular area under the (constant) velocity curve. This connection between the area under a curve and distance traveled can be extended to "any" irregularly shaped region exhibiting a fluctuating velocity over a given time period. If in the diagram on the right represents speed as it varies over time, the distance traveled (between the times represented by and ) is the area of the shaded region .

To approximate that area, an intuitive method would be to divide up the distance between and into a number of equal segments, the length of each segment represented by the symbol . For each small segment, we can choose one value of the function . Call that value . Then the area of the rectangle with base and height gives the distance (time multiplied by speed ) traveled in that segment. Associated with each segment is the average value of the function above it, . The sum of all such rectangles gives an approximation of the area between the axis and the curve, which is an approximation of the total distance traveled. A smaller value for will give more rectangles and in most cases a better approximation, but for an exact answer we need to take a limit as approaches zero.

The symbol of integration is formula_10, an elongated "S" (the "S" stands for "sum"). The definite integral is written as:

and is read "the integral from "a" to "b" of "f"-of-"x" with respect to "x"." The Leibniz notation is intended to suggest dividing the area under the curve into an infinite number of rectangles, so that their width becomes the infinitesimally small . In a formulation of the calculus based on limits, the notation

is to be understood as an operator that takes a function as an input and gives a number, the area, as an output. The terminating differential, , is not a number, and is not being multiplied by , although, serving as a reminder of the limit definition, it can be treated as such in symbolic manipulations of the integral. Formally, the differential indicates the variable over which the function is integrated and serves as a closing bracket for the integration operator.

The indefinite integral, or antiderivative, is written:

Functions differing by only a constant have the same derivative, and it can be shown that the antiderivative of a given function is actually a family of functions differing only by a constant. Since the derivative of the function , where is any constant, is , the antiderivative of the latter given by:
The unspecified constant present in the indefinite integral or antiderivative is known as the constant of integration.

The fundamental theorem of calculus states that differentiation and integration are inverse operations. More precisely, it relates the values of antiderivatives to definite integrals. Because it is usually easier to compute an antiderivative than to apply the definition of a definite integral, the fundamental theorem of calculus provides a practical way of computing definite integrals. It can also be interpreted as a precise statement of the fact that differentiation is the inverse of integration.

The fundamental theorem of calculus states: If a function is continuous on the interval and if is a function whose derivative is on the interval , then

Furthermore, for every in the interval ,

This realization, made by both Newton and Leibniz, who based their results on earlier work by Isaac Barrow, was key to the proliferation of analytic results after their work became known. The fundamental theorem provides an algebraic method of computing many definite integrals—without performing limit processes—by finding formulas for antiderivatives. It is also a prototype solution of a differential equation. Differential equations relate an unknown function to its derivatives, and are ubiquitous in the sciences.

Calculus is used in every branch of the physical sciences, actuarial science, computer science, statistics, engineering, economics, business, medicine, demography, and in other fields wherever a problem can be mathematically modeled and an optimal solution is desired. It allows one to go from (non-constant) rates of change to the total change or vice versa, and many times in studying a problem we know one and are trying to find the other.

Physics makes particular use of calculus; all concepts in classical mechanics and electromagnetism are related through calculus. The mass of an object of known density, the moment of inertia of objects, as well as the total energy of an object within a conservative field can be found by the use of calculus. An example of the use of calculus in mechanics is Newton's second law of motion: historically stated it expressly uses the term "change of motion" which implies the derivative saying "The" change "of momentum of a body is equal to the resultant force acting on the body and is in the same direction." Commonly expressed today as Force = Mass × acceleration, it implies differential calculus because acceleration is the time derivative of velocity or second time derivative of trajectory or spatial position. Starting from knowing how an object is accelerating, we use calculus to derive its path.

Maxwell's theory of electromagnetism and Einstein's theory of general relativity are also expressed in the language of differential calculus. Chemistry also uses calculus in determining reaction rates and radioactive decay. In biology, population dynamics starts with reproduction and death rates to model population changes.

Calculus can be used in conjunction with other mathematical disciplines. For example, it can be used with linear algebra to find the "best fit" linear approximation for a set of points in a domain. Or it can be used in probability theory to determine the probability of a continuous random variable from an assumed density function. In analytic geometry, the study of graphs of functions, calculus is used to find high points and low points (maxima and minima), slope, concavity and inflection points.

Green's Theorem, which gives the relationship between a line integral around a simple closed curve C and a double integral over the plane region D bounded by C, is applied in an instrument known as a planimeter, which is used to calculate the area of a flat surface on a drawing. For example, it can be used to calculate the amount of area taken up by an irregularly shaped flower bed or swimming pool when designing the layout of a piece of property.

Discrete Green's Theorem, which gives the relationship between a double integral of a function around a simple closed rectangular curve "C" and a linear combination of the antiderivative's values at corner points along the edge of the curve, allows fast calculation of sums of values in rectangular domains. For example, it can be used to efficiently calculate sums of rectangular domains in images, in order to rapidly extract features and detect object; another algorithm that could be used is the summed area table.

In the realm of medicine, calculus can be used to find the optimal branching angle of a blood vessel so as to maximize flow. From the decay laws for a particular drug's elimination from the body, it is used to derive dosing laws. In nuclear medicine, it is used to build models of radiation transport in targeted tumor therapies.

In economics, calculus allows for the determination of maximal profit by providing a way to easily calculate both marginal cost and marginal revenue.

Calculus is also used to find approximate solutions to equations; in practice it is the standard way to solve differential equations and do root finding in most applications. Examples are methods such as Newton's method, fixed point iteration, and linear approximation. For instance, spacecraft use a variation of the Euler method to approximate curved courses within zero gravity environments.

Over the years, many reformulations of calculus have been investigated for different purposes.

Imprecise calculations with infinitesimals were widely replaced with the rigorous (ε, δ)-definition of limit starting in the 1870s. Meanwhile, calculations with infinitesimals persisted and often led to correct results. This led Abraham Robinson to investigate if it were possible to develop a number system with infinitesimal quantities over which the theorems of calculus were still valid. In 1960, building upon the work of Edwin Hewitt and Jerzy Łoś, he succeeded in developing non-standard analysis. The theory of non-standard analysis is rich enough to be applied in many branches of mathematics. As such, books and articles dedicated solely to the traditional theorems of calculus often go by the title non-standard calculus.

This is another reformulation of the calculus in terms of infinitesimals. Based on the ideas of F. W. Lawvere and employing the methods of category theory, it views all functions as being continuous and incapable of being expressed in terms of discrete entities. One aspect of this formulation is that the law of excluded middle does not hold in this formulation.

Constructive mathematics is a branch of mathematics that insists that proofs of the existence of a number, function, or other mathematical object should give a construction of the object. As such constructive mathematics also rejects the law of excluded middle. Reformulations of calculus in a constructive framework are generally part of the subject of constructive analysis.





</doc>
<doc id="5177" url="https://en.wikipedia.org/wiki?curid=5177" title="Communication">
Communication

Communication (from Latin "commūnicāre", meaning "to share") is the act of conveying intended meanings from one entity or group to another through the use of mutually understood signs and semiotic rules.

The main steps inherent to all communication are: 

The scientific study of communication can be divided into:

The channel of communication can be visual, auditory, tactile (such as in Braille) and haptic, olfactory, electromagnetic, or biochemical. 

Human communication is unique for its extensive use of abstract language. Development of civilization has been closely linked with progress in telecommunication.

Nonverbal communication describes the processes of conveying a type of information in the form of non-linguistic representations. Examples of nonverbal communication include haptic communication, chronemic communication, gestures, body language, facial expressions, eye contact, and how one dresses. Nonverbal communication also relates to the intent of a message. Examples of intent are voluntary, intentional movements like shaking a hand or winking, as well as involuntary, such as sweating. Speech also contains nonverbal elements known as paralanguage, e.g. rhythm, intonation, tempo, and stress. It affects communication most at the subconscious level and establishes trust. Likewise, written texts include nonverbal elements such as handwriting style, the spatial arrangement of words and the use of emoticons to convey emotion.

Nonverbal communication demonstrates one of Wazlawick's laws: you cannot not communicate. Once proximity has formed awareness, living creatures begin interpreting any signals received. Some of the functions of nonverbal communication in humans are to complement and illustrate, to reinforce and emphasize, to replace and substitute, to control and regulate, and to contradict the denovative message.

Nonverbal cues are heavily relied on to express communication and to interpret others’ communication and can replace or substitute verbal messages. However, non-verbal communication is ambiguous. When verbal messages contradict non-verbal messages, observation of non-verbal behaviour is relied on to judge another’s attitudes and feelings, rather than assuming the truth of the verbal message alone. 

There are several reasons as to why non-verbal communication plays a vital role in communication:

“Non-verbal communication is omnipresent.” They are included in every single communication act. To have total communication, all non-verbal channels such as the body, face, voice, appearance, touch, distance, timing, and other environmental forces must be engaged during face-to-face interaction. Written communication can also have non-verbal attributes. E-mails and web chats allow an individual’s the option to change text font colours, stationary, emoticons, and capitalization in order to capture non-verbal cues into a verbal medium. 

“Non-verbal behaviours are multifunctional.” Many different non-verbal channels are engaged at the same time in communication acts and allow the chance for simultaneous messages to be sent and received. 

“Non-verbal behaviours may form a universal language system.” Smiling, crying, pointing, caressing, and glaring are non-verbal behaviours that are used and understood by people regardless of nationality. Such non-verbal signals allow the most basic form of communication when verbal communication is not effective due to language barriers.

Verbal communication is the spoken or written conveyance of a message. Human language can be defined as a system of symbols (sometimes known as lexemes) and the grammars (rules) by which the symbols are manipulated. The word "language" also refers to common properties of languages. Language learning normally occurs most intensively during human childhood. Most of the thousands of human languages use patterns of sound or gesture for symbols which enable communication with others around them. Languages tend to share certain properties, although there are exceptions. There is no defined line between a language and a dialect. Constructed languages such as Esperanto, programming languages, and various mathematical formalism is not necessarily restricted to the properties shared by human languages.

As previously mentioned, language can be characterized as symbolic. Charles Ogden and I.A Richards developed The Triangle of Meaning model to explain the symbol (the relationship between a word), the referent (the thing it describes), and the meaning (the thought associated with the word and the thing) 

The properties of language are governed by rules. Language follows phonological rules (sounds that appear in a language), syntactic rules (arrangement of words and punctuation in a sentence), semantic rules (the agreed upon meaning of words), and pragmatic rules (meaning derived upon context). 

The meanings that are attached to words can be literal, or otherwise known as denotative; relating to the topic being discussed, or, the meanings take context and relationships into account, otherwise known as connotative; relating to the feelings, history, and power dynamics of the communicators.

Over time the forms of and ideas about communication have evolved through the continuing progression of technology. Advances include communications psychology and media psychology, an emerging field of study.

The progression of written communication can be divided into three "information communication revolutions":

Communication is thus a process by which meaning is assigned and conveyed in an attempt to create shared understanding. Gregory Bateson called it "the replication of tautologies in the universe. This process, which requires a vast repertoire of skills in interpersonal processing, listening, observing, speaking, questioning, analyzing, gestures, and evaluating enables collaboration and cooperation.

Business communication is used for a wide variety of activities including, but not limited to: strategic communications planning, media relations, public relations (which can include social media, broadcast and written communications, and more), brand management, reputation management, speech-writing, customer-client relations, and internal/employee communications.

Companies with limited resources may choose to engage in only a few of these activities, while larger organizations may employ a full spectrum of communications. Since it is difficult to develop such a broad range of skills, communications professionals often specialize in one or two of these areas but usually have at least a working knowledge of most of them. By far, the most important qualifications communications professionals can possess are excellent writing ability, good 'people' skills, and the capacity to think critically and strategically.

Communication is one of the most relevant tools in political strategies, including persuasion and propaganda. In mass media research and online media research, the effort of the strategist is that of getting a precise decoding, avoiding "message reactance", that is, message refusal. The reaction to a message is referred also in terms of approach to a message, as follows:
Holistic approaches are used by communication campaign leaders and communication strategists in order to examine all the options, "actors" and channels that can generate change in the semiotic landscape, that is, change in perceptions, change in credibility, change in the "memetic background", change in the image of movements, of candidates, players and managers as perceived by key influencers that can have a role in generating the desired "end-state".

The modern political communication field is highly influenced by the framework and practices of "information operations" doctrines that derive their nature from strategic and military studies. According to this view, what is really relevant is the concept of acting on the Information Environment. The information environment is the aggregate of individuals, organizations, and systems that collect, process, disseminate, or act on information. This environment consists of three interrelated dimensions, which continuously interact with individuals, organizations, and systems. These dimensions are known as physical, informational, and cognitive.

Family communication is the study of the communication perspective in a broadly defined family, with intimacy and trusting relationship. The main goal of family communication is to understand the interactions of family and the pattern of behaviors of family members in different circumstances. Open and honest communication creates an atmosphere that allows family members to express their differences as well as love and admiration for one another. It also helps to understand the feelings of one another.

Family communication study looks at topics such as family rules, family roles or family dialectics and how those factors could affect the communication between family members. Researchers develop theories to understand communication behaviors. Family communication study also digs deep into certain time periods of family life such as marriage, parenthood or divorce and how communication stands in those situations. It is important for family members to understand communication as a trusted way which leads to a well constructed family.

In simple terms, interpersonal communication is the communication between one person and another (or others). It is often referred to as face-to-face communication between two (or more) people. Both verbal and nonverbal communication, or body language, play a part in how one person understands another. In verbal interpersonal communication there are two types of messages being sent: a content message and a relational message. Content messages are messages about the topic at hand and relational messages are messages about the relationship itself. This means that relational messages come across in "how" one says something and it demonstrates a person’s feelings, whether positive or negative, towards the individual they are talking to, indicating not only how they feel about the topic at hand, but also how they feel about their relationship with the other individual.

There are many different aspects of interpersonal communication including; 

- Audiovisual Perception of Communication Problems 
- The Attachment Theory 

- Emotional Intelligence and Triggers 

- Attribution Theory 

- The Power of Words (Verbal communications) 

- Nonverbal Communication

- Ethics in Personal Relations 

- Deception in Communication 

- Conflict in Couples 

Barriers to effective communication can retard or distort the message or intention of the message being conveyed. This may result in failure of the communication process or cause an effect that is undesirable. These include filtering, selective perception, information overload, emotions, language, silence, communication apprehension, gender differences and political correctness

This also includes a lack of expressing "knowledge-appropriate" communication, which occurs when a person uses ambiguous or complex legal words, medical jargon, or descriptions of a situation or environment that is not understood by the recipient.

Cultural differences exist within countries (tribal/regional differences, dialects etc.), between religious groups and in organisations or at an organisational level - where companies, teams and units may have different expectations, norms and idiolects. Families and family groups may also experience the effect of cultural barriers to communication within and between different family members or groups. For example: words, colours and symbols have different meanings in different cultures. In most parts of the world, nodding your head means agreement, shaking your head means no, except in some parts of the world.

Communication to a great extent is influenced by culture and cultural variables. Understanding "cultural aspects of communication" refers to having knowledge of different cultures in order to communicate effectively with cross culture people. Cultural aspects of communication are of great relevance in today's world which is now a global village, thanks to globalisation. Cultural aspects of communication are the cultural differences which influences communication across borders. Impact of cultural differences on communication components are explained below:

1) Verbal communication refers to form of communication which uses spoken and written words for expressing and transferring views and ideas. Language is the most important tool of verbal communication and it is the area where cultural difference play its role. All countries have different languages and to have a better understanding of different culture it is required to have knowledge of languages of different countries.

2) Non verbal communication is a very wide concept and it includes all the other forms of communication which do not uses written or spoken words. Non verbal communication takes following forms:

So in order to have an effective communication across world it is desirable to have a knowledge of cultural variables effecting communication.

According to Michael Walsh and Ghil'ad Zuckermann, Western conversational interaction is typically "dyadic", between two particular people, where eye contact is important and the speaker controls the interaction; and "contained" in a relatively short, defined time frame. However, traditional Aboriginal conversational interaction is "communal", broadcast to many people, eye contact is not important, the listener controls the interaction; and "continuous", spread over a longer, indefinite time frame.

Arising from research in Risk Communication, the "4 Distances Model" (Acronym 4DM, originally by Daniele Trevisani, 1990) highlights the presence of "relational distances" in system-to-system or human-to-human communication, a distance whose effect is that of degrading progressively both understanding and agreement. The higher the relational distance, the more communication results become difficult to achieve in terms of effectiveness and expected output. The 4 Distances regard differences in (1) the "Self's Distance", acceptance or refusal of other's self-perception of roles (e.g. teacher-student); (2) Communication Codes (linguistic and non verbal) (3) underlying values and world views, and (d) personal experiences (both emotional and objectual). The approach has been applied in several fields including health professions, analysis of critical incidents due to communications misunderstanding in the International Space Station., and in "Intelligent Decision Support System" for leadership .

Every information exchange between living organisms — i.e. transmission of signals that involve a living sender and receiver can be considered a form of communication; and even primitive creatures such as corals are competent to communicate. Nonhuman communication also include cell signaling, cellular communication, and chemical transmissions between primitive organisms like bacteria and within the plant and fungal kingdoms.

The broad field of animal communication encompasses most of the issues in ethology. Animal communication can be defined as any behavior of one animal that affects the current or future behavior of another animal. The study of animal communication, called "zoo semiotics" (distinguishable from anthroposemiotics, the study of human communication) has played an important part in the development of ethology, sociobiology, and the study of animal cognition. Animal communication, and indeed the understanding of the animal world in general, is a rapidly growing field, and even in the 21st century so far, a great share of prior understanding related to diverse fields such as personal symbolic name use, animal emotions, animal culture and learning, and even sexual conduct, long thought to be well understood, has been revolutionized.

Communication is observed within the plant organism, i.e. within plant cells and between plant cells, between plants of the same or related species, and between plants and non-plant organisms, especially in the root zone. Plant roots communicate with rhizome bacteria, fungi, and insects within the soil. Recent research has shown that most of the microorganism plant communication processes are neuron-like. Plants also communicate via volatiles when exposed to herbivory attack behavior, thus warning neighboring plants. In parallel they produce other volatiles to attract parasites which attack these herbivores.

Fungi communicate to coordinate and organize their growth and development such as the formation of Marcelia and fruiting bodies. Fungi communicate with their own and related species as well as with non fungal organisms in a great variety of symbiotic interactions, especially with bacteria, unicellular eukaryote, plants and insects through biochemicals of biotic origin. The biochemicals trigger the fungal organism to react in a specific manner, while if the same chemical molecules are not part of biotic messages, they do not trigger the fungal organism to react. This implies that fungal organisms can differentiate between molecules taking part in biotic messages and similar molecules being irrelevant in the situation. So far five different primary signalling molecules are known to coordinate different behavioral patterns such as filamentation, mating, growth, and pathogenicity. Behavioral coordination and production of signaling substances is achieved through interpretation processes that enables the organism to differ between self or non-self, a biotic indicator, biotic message from similar, related, or non-related species, and even filter out "noise", i.e. similar molecules without biotic content.

Communication is not a tool used only by humans, plants and animals, but it is also used by microorganisms like bacteria. The process is called quorum sensing. Through quorum sensing, bacteria are able to sense the density of cells, and regulate gene expression accordingly. This can be seen in both gram positive and gram negative bacteria.
This was first observed by Fuqua "et al." in marine microorganisms like "V. harveyi" and "V. fischeri".

The first major model for communication was introduced by Claude Shannon and Warren Weaver for Bell Laboratories in 1949 The original model was designed to mirror the functioning of radio and telephone technologies. Their initial model consisted of three primary parts: sender, channel, and receiver. The sender was the part of a telephone a person spoke into, the channel was the telephone itself, and the receiver was the part of the phone where one could hear the other person. Shannon and Weaver also recognized that often there is static that interferes with one listening to a telephone conversation, which they deemed noise.

In a simple model, often referred to as the transmission model or standard view of communication, information or content (e.g. a message in natural language) is sent in some form (as spoken language) from an emisor/ sender/ encoder to a destination/ receiver/ decoder. This common conception of communication simply views communication as a means of sending and receiving information. The strengths of this model are simplicity, generality, and quantifiability. Claude Shannon and Warren Weaver structured this model based on the following elements:

Shannon and Weaver argued that there were three levels of problems for communication within this theory.

Daniel Chandler critiques the transmission model by stating:

In 1960, David Berlo expanded on Shannon and Weaver's (1949) linear model of communication and created the SMCR Model of Communication. The Sender-Message-Channel-Receiver Model of communication separated the model into clear parts and has been expanded upon by other scholars.

Communication is usually described along a few major dimensions: Message (what type of things are communicated), source / emisor / sender / encoder (by whom), form (in which form), channel (through which medium), destination / receiver / target / decoder (to whom), and Receiver. Wilbur Schram (1954) also indicated that we should also examine the impact that a message has (both desired and undesired) on the target of the message. Between parties, communication includes acts that confer knowledge and experiences, give advice and commands, and ask questions. These acts may take many forms, in one of the various manners of communication. The form depends on the abilities of the group communicating. Together, communication content and form make messages that are sent towards a destination. The target can be oneself, another person or being, another entity (such as a corporation or group of beings).

Communication can be seen as processes of information transmission with three levels of semiotic rules:

Therefore, communication is social interaction where at least two interacting agents share a common set of signs and a common set of semiotic rules. This commonly held rule in some sense ignores autocommunication, including intrapersonal communication via diaries or self-talk, both secondary phenomena that followed the primary acquisition of communicative competences within social interactions.

In light of these weaknesses, Barnlund (2008) proposed a transactional model of communication. The basic premise of the transactional model of communication is that individuals are simultaneously engaging in the sending and receiving of messages.

In a slightly more complex form a sender and a receiver are linked reciprocally. This second attitude of communication, referred to as the constitutive model or constructionist view, focuses on how an individual communicates as the determining factor of the way the message will be interpreted. Communication is viewed as a conduit; a passage in which information travels from one individual to another and this information becomes separate from the communication itself. A particular instance of communication is called a speech act. The sender's personal filters and the receiver's personal filters may vary depending upon different regional traditions, cultures, or gender; which may alter the intended meaning of message contents. In the presence of "communication noise" on the transmission channel (air, in this case), reception and decoding of content may be faulty, and thus the speech act may not achieve the desired effect. One problem with this encode-transmit-receive-decode model is that the processes of encoding and decoding imply that the sender and receiver each possess something that functions as a codebook, and that these two code books are, at the very least, similar if not identical. Although something like code books is implied by the model, they are nowhere represented in the model, which creates many conceptual difficulties.

Theories of coregulation describe communication as a creative and dynamic continuous process, rather than a discrete exchange of information. Canadian media scholar Harold Innis had the theory that people use different types of media to communicate and which one they choose to use will offer different possibilities for the shape and durability of society. His famous example of this is using ancient Egypt and looking at the ways they built themselves out of media with very different properties stone and papyrus. Papyrus is what he called 'Space Binding'. it made possible the transmission of written orders across space, empires and enables the waging of distant military campaigns and colonial administration. The other is stone and 'Time Binding', through the construction of temples and the pyramids can sustain their authority generation to generation, through this media they can change and shape communication in their society.

In any communication model, noise is interference with the decoding of messages sent over a channel by an encoder. There are many examples of noise:
To face communication noise, redundancy and acknowledgement must often be used. Acknowledgements are messages from the addressee informing the originator that his/her communication has been received and is understood. Message repetition and feedback about message received are necessary in the presence of noise to reduce the probability of misunderstanding.
The act of disambiguation regards the attempt of reducing noise and wrong interpretations, when the semantic value or meaning of a sign can be subject to noise, or in presence of multiple meanings, which makes the sense-making difficult. Disambiguation attempts to decrease the likelihood of misunderstanding. This is also a fundamental skill in communication processes activated by counselors, psychotherapists, interpreters, and in coaching sessions based on colloquium. In Information Technology, the disambiguation process and the automatic disambiguation of meanings of words and sentences has also been an interest and concern since the earliest days of computer treatment of language.

The academic discipline that deals with processes of human communication is communication studies. The discipline encompasses a range of topics, from face-to-face conversation to mass media outlets such as television broadcasting. Communication studies also examines how messages are interpreted through the political, cultural, economic, semiotic, hermeneutic, and social dimensions of their contexts. Statistics, as a quantitative approach to communication science, has also been incorporated into research on communication science in order to help substantiate claims.




</doc>
<doc id="5178" url="https://en.wikipedia.org/wiki?curid=5178" title="Classics">
Classics

Classics or classical studies is the study of classical antiquity. It encompasses the study of the Greco-Roman world, particularly of its languages and literature (Ancient Greek and Classical Latin) but also of Greco-Roman philosophy, history, and archaeology. Traditionally in the West, the study of the Greek and Roman classics was considered one of the cornerstones of the humanities and a necessary part of a rounded education. The study of Classics has been traditionally a cornerstone of a typical elite education.

Study encompasses specifically a time-period of history from the mid-2nd millennium BC to the 6th century AD.

The word "Classics" is derived from the Latin adjective "classicus", meaning "belonging to the highest class of citizens". The word was originally used to describe the members of the highest class in ancient Rome. By the 2nd century AD the word was used in literary criticism to describe writers of the highest quality. For example, Aulus Gellius, in his "Attic Nights", contrasts "classicus" and "proletarius" writers. By the 6th century AD, the word had acquired a second meaning, referring to pupils at a school. Thus the two modern meanings of the word, referring both to literature considered to be of the highest quality, and to the standard texts used as part of a curriculum, both derive from Roman use.

In the Middle Ages, classics and education were tightly intertwined; according to Jan Ziolkowski, there is no era in history in which the link was tighter. Medieval education taught students to imitate earlier classical models, and Latin continued to be the language of scholarship and culture, despite the increasing difference between literary Latin and the vernacular languages of Europe during the period.

While Latin was hugely influential, however, Greek was barely studied, and Greek literature survived almost solely in Latin translation. The works of even major Greek authors such as Hesiod, whose names continued to be known by educated Europeans, were unavailable in the Middle Ages. In the thirteenth century, the English philosopher Roger Bacon wrote that "there are not four men in Latin Christendom who are acquainted with the Greek, Hebrew, and Arabic grammars."

Along with the unavailability of Greek authors, there were other differences between the classical canon known today and the works valued in the Middle Ages. Catullus, for instance, was almost entirely unknown in the medieval period. The popularity of different authors also waxed and waned throughout the period: Lucretius, popular during the Carolingian period, was barely read in the twelfth century, while for Quintilian the reverse is true.

The Renaissance led to the increasing study of both ancient literature and ancient history, as well as a revival of classical styles of Latin. From the 14th century, first in Italy and then increasingly across Europe, Renaissance Humanism, an intellectual movement that "advocated the study and imitation of classical antiquity", developed. Humanism saw a reform in education in Europe, introducing a wider range of Latin authors as well as bringing back the study of Greek language and literature to Western Europe. This reintroduction was initiated by Petrarch (1304–1374) and Boccaccio (1313–1375) who commissioned a Calabrian scholar to translate the Homeric poems. This humanist educational reform spread from Italy, in Catholic countries as it was adopted by the Jesuits, and in countries that became Protestant such as England, Germany, and the Low Countries, in order to ensure that future clerics were able to study the New Testament in the original language.

The late 17th and 18th centuries are the period in Western European literary history which is most associated with the classical tradition, as writers consciously adapted classical models. Classical models were so highly prized that the plays of William Shakespeare were rewritten along neoclassical lines, and these "improved" versions were performed throughout the 18th century.

From the beginning of the 18th century, the study of Greek became increasingly important relative to that of Latin.
In this period Johann Winckelmann's claims for the superiority of the Greek visual arts influenced a shift in aesthetic judgements, while in the literary sphere, G.E. Lessing "returned Homer to the centre of artistic achievement".
In the United Kingdom, the study of Greek in schools began in the late 18th century. The poet Walter Savage Landor claimed to have been one of the first English schoolboys to write in Greek during his time at Rugby School.

The 19th century saw the influence of the classical world, and the value of a classical education, decline, especially in the US, where the subject was often criticised for its elitism. By the 19th century, little new literature was still being written in Latin – a practice which had continued as late as the 18th century – and a command of Latin declined in importance. Correspondingly, classical education from the 19th century onwards began to increasingly de-emphasise the importance of the ability to write and speak Latin. In the United Kingdom this process took longer than elsewhere. Composition continued to be the dominant classical skill in England until the 1870s, when new areas within the discipline began to increase in popularity.
In the same decade came the first challenges to the requirement of Greek at the universities of Oxford and Cambridge, though it would not be finally abolished for another 50 years.

Though the influence of classics as the dominant mode of education in Europe and North America was in decline in the 19th century, the discipline was rapidly evolving in the same period. Classical scholarship was becoming more systematic and scientific, especially with the "new philology" created at the end of the 18th and beginning of the 19th century. Its scope was also broadening: it was during the 19th century that ancient history and classical archaeology began to be seen as part of Classics, rather than separate disciplines.

During the 20th century, the study of classics became less common. In England, for instance, Oxford and Cambridge universities stopped requiring students to have qualifications in Greek in 1920, and in Latin at the end of the 1950s. When the National Curriculum was introduced in England, Wales, and Northern Ireland in 1988, it did not mention the classics. By 2003, only about 10% of state schools in Britain offered any classical subjects to their students at all.

However, the study of classics has not declined as fast elsewhere in Europe. In 2009, a review of "Meeting the Challenge", a collection of conference papers about the teaching of Latin in Europe, noted that though there is opposition to the teaching of Latin in Italy, it is nonetheless still compulsory in most secondary schools. The same can be said in the case of France or Greece, too. Indeed, Ancient Greek is one of the compulsory subjects in Greek secondary education, whereas in France, Latin is one of the optional subjects that can be chosen in a majority of middle schools and high schools. Ancient Greek is also still being taught, but not as much as Latin.

One of the most notable characteristics of the modern study of Classics is the diversity of the field. Although traditionally focused on ancient Greece and Rome, the study now encompasses the entire ancient Mediterranean world, thus expanding the studies to Northern Africa as well as parts of the Middle East.

Philology is the study of language preserved in written sources; classical philology is thus concerned with understanding any texts from the classical period written in the classical languages of Latin and Greek.
The roots of classical philology lie in the Renaissance, as humanist intellectuals attempted to return to the Latin of the classical period, especially of Cicero, and as scholars attempted to produce more accurate editions of ancient texts.
Some of the principles of philology still used today developed during this period. For instance, the observation that if a manuscript could be shown to be a copy of an earlier extant manuscript, then it provides no further evidence of the original text, was made as early as 1489 by Angelo Poliziano.
Other philological tools took longer to be developed: the first statement, for instance, of the principle that a more difficult reading should be preferred over a simpler one, was in 1697 by Jean Le Clerc.

The modern discipline of classical philology began in Germany at the turn of the nineteenth century. It was during this period that scientific principles of philology began to be put together into a coherent whole, in order to provide a set of rules by which scholars could determine which manuscripts were most accurate. This "new philology", as it was known, centred around the construction of a genealogy of manuscripts, with which a hypothetical common ancestor, closer to the original text than any existing manuscript, could be reconstructed.

Classical archaeology is the oldest branch of archaeology, with its roots going back to J.J. Winckelmann's work on Herculaneum in the 1760s. It was not until the last decades of the 19th century, however, that classical archaeology became part of the tradition of Western classical scholarship. It was included as part of Cambridge University's Classical Tripos for the first time after the reforms of the 1880s, though it did not become part of Oxford's Greats until much later.

The second half of the 19th century saw Schliemann's excavations of Troy and Mycenae; the first excavations at Olympia and Delos; and Arthur Evans' work in Crete, particularly on Knossos. This period also saw the foundation of important archaeological associations (e.g. the Archaeological Institute of America in 1879), including many foreign archaeological institutes in Athens and Rome (the American School of Classical Studies at Athens in 1881, British School at Athens in 1886, American Academy in Rome in 1895, and British School at Rome in 1900).

More recently, classical archaeology has taken little part in the theoretical changes in the rest of the discipline, largely ignoring the popularity of "New Archaeology", which emphasised the development of general laws derived from studying material culture, in the 1960s. New Archaeology is still criticized by traditional minded scholars of classical archaeology despite a wide acceptance of its basic techniques.

Some art historians focus their study on the development of art in the classical world. Indeed, the art and architecture of Ancient Rome and Greece is very well regarded and remains at the heart of much of our art today. For example, Ancient Greek architecture gave us the Classical Orders: Doric, Ionic, and Corinthian. The Parthenon is still the architectural symbol of the classical world.

Greek sculpture is well known and we know the names of several Ancient Greek artists: for example, Phidias.

With philology, archaeology, and art history, scholars seek understanding of the history and culture of a civilisation, through critical study of the extant literary and physical artefacts, in order to compose and establish a continual historic narrative of the Ancient World and its peoples. The task is difficult due to a dearth of physical evidence: for example, Sparta was a leading Greek city-state, yet little evidence of it survives to study, and what is available comes from Athens, Sparta's principal rival; likewise, the Roman Empire destroyed most evidence (cultural artefacts) of earlier, conquered civilizations, such as that of the Etruscans.

The English word "philosophy" comes from the Greek word φιλοσοφία, meaning "love of wisdom", probably coined by Pythagoras. Along with the word itself, the discipline of philosophy as we know it today has its roots in ancient Greek thought, and according to Martin West "philosophy as we understand it is a Greek creation". Ancient philosophy was traditionally divided into three branches: logic, physics, and ethics. However, not all of the works of ancient philosophers fit neatly into one of these three branches. For instance, Aristotle's "Rhetoric" and "Poetics" have been traditionally classified in the West as "ethics", but in the Arabic world were grouped with logic; in reality, they do not fit neatly into either category.

From the last decade of the eighteenth century, scholars of ancient philosophy began to study the discipline historically. Previously, works on ancient philosophy had been unconcerned with chronological sequence and with reconstructing the reasoning of ancient thinkers; with what Wolfgang-Ranier Mann calls "New Philosophy", this changed.

A relatively recent new discipline within the classics is "reception studies", which developed in the 1960s at the University of Konstanz.
Reception studies is concerned with how students of classical texts have understood and interpreted them.
As such, reception studies is interested in a two-way interaction between reader and text, taking place within a historical context.

Though the idea of an "aesthetics of reception" was first put forward by Hans Robert Jauss in 1967, the principles of reception theory go back much earlier than this.
As early as 1920, T.S. Eliot wrote that "the past [is] altered by the present as much as the present is directed by the past"; Charles Martindale describes this as a "cardinal principle" for many versions of modern reception theory.

Ancient Greece was the civilization belonging to the period of Greek history lasting from the Archaic period, beginning in the eighth century BC, to the Roman conquest of Greece after the Battle of Corinth in 146 BC. The Classical period, during the fifth and fourth centuries BC, has traditionally been considered the height of Greek civilisation. The Classical period of Greek history is generally considered to have begun with the first and second Persian invasions of Greece at the start of the Greco-Persian wars, and to have ended with the death of Alexander the Great.

Classical Greek culture had a powerful influence on the Roman Empire, which carried a version of it to many parts of the Mediterranean region and Europe; thus Classical Greece is generally considered to be the seminal culture which provided the foundation of Western civilization.

Ancient Greek is the historical stage in the development of the Greek language spanning the Archaic (c. 8th to 6th centuries BC), Classical (c. 5th to 4th centuries BC), and Hellenistic (c. 3rd century BC to 6th century AD) periods of ancient Greece and the ancient world. It is predated in the 2nd millennium BC by Mycenaean Greek. Its Hellenistic phase is known as Koine ("common") or Biblical Greek, and its late period mutates imperceptibly into Medieval Greek. Koine is regarded as a separate historical stage of its own, although in its earlier form it closely resembles Classical Greek. Prior to the Koine period, Greek of the classical and earlier periods included several regional dialects.

Ancient Greek was the language of Homer and of classical Athenian historians, playwrights, and philosophers. It has contributed many words to the vocabulary of English and many other European languages, and has been a standard subject of study in Western educational institutions since the Renaissance. Latinized forms of Ancient Greek roots are used in many of the scientific names of species and in other scientific terminology.

The earliest surviving works of Greek literature are epic poetry. Homer's "Iliad" and "Odyssey" are the earliest to survive to us today, probably composed in the eighth century BC. These early epics were oral compositions, created without the use of writing.
Around the same time that the Homeric epics were composed, the Greek alphabet was introduced; the earliest surviving inscriptions date from around 750 BC.
European drama was invented in ancient Greece. Traditionally this was attributed to Thespis, around the middle of the sixth century BC, though the earliest surviving work of Greek drama is Aeschylus' tragedy "The Persians", which dates to 472 BC. Early Greek tragedy was performed by a chorus and two actors, but by the end of Aeschylus' life, a third actor had been introduced, either by him or by Sophocles. The last surviving Greek tragedies are the "Bacchae" of Euripides and Sophocles' Oedipus at Colonus, both from the end of the fifth century BC.

Surviving Greek comedy begins later than tragedy; the earliest surviving work, Aristophanes' "Acharnians", comes from 425 BC. However, comedy dates back as early as 486 BC, when the Dionysia added a competition for comedy to the much earlier competition for tragedy. The comedy of the fifth century is known as Old Comedy, and it comes down to us solely in the eleven surviving plays of Aristophanes, along with a few fragments. Sixty years after the end of Aristophanes' career, the next author of comedies to have any substantial body of work survive is Menander, whose style is known as New Comedy.

Two historians flourished during Greece's classical age: Herodotus and Thucydides. Herodotus is commonly called the father of history, and his "History" contains the first truly literary use of prose in Western literature. Of the two, Thucydides was the more careful historian. His critical use of sources, inclusion of documents, and laborious research made his History of the Peloponnesian War a significant influence on later generations of historians. The greatest achievement of the 4th century was in philosophy. There were many Greek philosophers, but three names tower above the rest: Socrates, Plato, and Aristotle. These have had a profound influence on Western society.

Greek mythology is the body of myths and legends belonging to the ancient Greeks concerning their gods and heroes, the nature of the world, and the origins and significance of their own cult and ritual practices. They were a part of religion in ancient Greece. Modern scholars refer to the myths and study them in an attempt to throw light on the religious and political institutions of Ancient Greece and its civilization, and to gain understanding of the nature of myth-making itself.

Greek religion encompassed the collection of beliefs and rituals practiced in ancient Greece in the form of both popular public religion and cult practices. These different groups varied enough for it to be possible to speak of Greek religions or "cults" in the plural, though most of them shared similarities. Also, the Greek religion extended out of Greece and out to neighbouring islands.

Many Greek people recognized the major gods and goddesses: Zeus, Poseidon, Hades, Apollo, Artemis, Aphrodite, Ares, Dionysus, Hephaestus, Athena, Hermes, Demeter, Hestia and Hera; though philosophies such as Stoicism and some forms of Platonism used language that seems to posit a transcendent single deity. Different cities often worshipped the same deities, sometimes with epithets that distinguished them and specified their local nature.

The earliest surviving philosophy from ancient Greece dates back to the 6th century BC, when according to Aristotle Thales of Miletus was considered to have been the first Greek philosopher. Other influential pre-Socratic philosophers include Pythagoras and Heraclitus. The most famous and significant figures in classical Athenian philosophy, from the 5th to the 3rd centuries BC, are Socrates, his student Plato, and Aristotle, who studied at Plato's Academy before founding his own school, known as the Lyceum. Later Greek schools of philosophy, including the Cynics, Stoics, and Epicureans, continued to be influential after the Roman annexation of Greece, and into the post-Classical world.

Greek philosophy dealt with a wide variety of subjects, including political philosophy, ethics, metaphysics, ontology, and logic, as well as disciplines which are not today thought of as part of philosophy, such as biology and rhetoric.

The language of ancient Rome was Latin, a member of the Italic family of languages. The earliest surviving inscription in Latin comes from the 7th century BC, on a brooch from Palestrina. Latin from between this point and the early 1st century BC is known as Old Latin. Most surviving Latin literature is Classical Latin, from the 1st century BC to the 2nd century AD. Latin then evolved into Late Latin, in use during the late antique period. Late Latin survived long after the end of classical antiquity, and was finally replaced by written Romance languages around the 9th century AD. Along with literary forms of Latin, there existed various vernacular dialects, generally known as Vulgar Latin, in use throughout antiquity. These are mainly preserved in sources such as graffiti and the Vindolanda tablets.

The earliest surviving Latin authors, writing in Old Latin, include the playwrights Plautus and Terence. Much of the best known and most highly thought of Latin literature comes from the classical period, with poets such as Virgil, Horace, and Ovid; historians such as Julius Caesar and Tacitus; orators such as Cicero; and philosophers such as Seneca the Younger and Lucretius. Late Latin authors include many Christian writers such as Lactantius, Tertullian and Ambrose; non-Christian authors, such as the historian Ammianus Marcellinus, are also preserved.

According to legend, the city of Rome was founded in 753 BC; in reality, there had been a settlement on the site since around 1000 BC, when the Palatine Hill was settled. The city was originally ruled by kings, first Roman, and then Etruscan – according to Roman tradition, the first Etruscan king of Rome, Tarquinius Priscus, ruled from 616 BC. Over the course of the 6th century BC, the city expanded its influence over the entirety of Latium. Around the end of the 6th century – traditionally in 510 BC – the kings of Rome were driven out, and the city became a republic.

Around 387 BC, Rome was sacked by the Gauls following the Battle of the Allia. It soon recovered from this humiliating defeat, however, and in 381 the inhabitants of Tusculum in Latium were made Roman citizens. This was the first time Roman citizenship was extended in this way. Rome went on to expand its area of influence, until by 269 the entirety of the Italian peninsula was under Roman rule. Soon afterwards, in 264, the First Punic War began; it lasted until 241. The Second Punic War began in 218, and by the end of that year, the Carthaginian general Hannibal had invaded Italy. The war saw Rome's worst defeat to that point at Cannae; the largest army Rome had yet put into the field was wiped out, and one of the two consuls leading it was killed. However, Rome continued to fight, annexing much of Spain and eventually defeating Carthage, ending her position as a major power and securing Roman preeminence in the Western Mediterranean.
The classical languages of the Ancient Mediterranean world influenced every European language, imparting to each a learned vocabulary of international application. Thus, Latin grew from a highly developed cultural product of the Golden and Silver eras of Latin literature to become the "international lingua franca" in matters diplomatic, scientific, philosophic and religious, until the 17th century. Long before this, Latin had evolved into the Romance languages and Ancient Greek into Modern Greek and its dialects. In the specialised science and technology vocabularies, the influence of Latin and Greek is notable. Ecclesiastical Latin, the Roman Catholic Church's official language, remains a living legacy of the classical world in the contemporary world.

Latin had an impact far beyond the classical world. It continued to be the pre-eminent language for serious writings in Europe long after the fall of the Roman empire. The modern Romance languages – such as French, Spanish, and Italian – all derive from Latin. Latin is still seen as a foundational aspect of European culture.

The legacy of the classical world is not confined to the influence of classical languages. The Roman empire was taken as a model by later European empires, such as the Spanish and British empires. Classical art has been taken as a model in later periods – medieval Romanesque architecture and Enlightenment-era neoclassical literature were both influenced by classical models, to take but two examples, while Joyce's "Ulysses" is one of the most influential works of twentieth century literature.






</doc>
<doc id="5180" url="https://en.wikipedia.org/wiki?curid=5180" title="Chemistry">
Chemistry

Chemistry is the scientific discipline involved with compounds composed of atoms, i.e. elements, and molecules, i.e. combinations of atoms: their composition, structure, properties, behavior and the changes they undergo during a reaction with other compounds. Chemistry addresses topics such as how atoms and molecules interact via chemical bonds to form new chemical compounds. There are four types of chemical bonds: covalent bonds, in which compounds share one or more electron(s); ionic bonds, in which a compound donates one or more electrons to another compound to produce ions: cations and anions; hydrogen bonds; and Van der Waals force bonds. See glossary of chemistry.

In the scope of its subject, chemistry occupies an intermediate position between physics and biology. It is sometimes called the central science because it provides a foundation for understanding both basic and applied scientific disciplines at a fundamental level. Examples include plant chemistry (botany), the formation of igneous rocks (geology), how atmospheric ozone is formed and how environmental pollutants are degraded (ecology), the properties of the soil on the moon (astrophysics), how medications work (pharmacology), and how to collect DNA evidence at a crime scene (forensics).

The history of chemistry spans a period from very old times to the present. Since several millennia BC, civilizations were using technologies that would eventually form the basis of the various branches of chemistry. Examples include extracting metals from ores, making pottery and glazes, fermenting beer and wine, extracting chemicals from plants for medicine and perfume, rendering fat into soap, making glass, and making alloys like bronze. Chemistry was preceded by its protoscience, alchemy, which is an intuitive but non-scientific approach to understanding the constituents of matter and their interactions. It was unsuccessful in explaining the nature of matter and its transformations, but, by performing experiments and recording the results, alchemists set the stage for modern chemistry. Chemistry as a body of knowledge distinct from alchemy began to emerge when a clear differentiation was made between them by Robert Boyle in his work "The Sceptical Chymist" (1661). While both alchemy and chemistry are concerned with matter and its transformations, the crucial difference was given by the scientific method that chemists employed in their work. Chemistry is considered to have become an established science with the work of Antoine Lavoisier, who developed a law of conservation of mass that demanded careful measurement and quantitative observations of chemical phenomena. The history of chemistry is intertwined with the history of thermodynamics, especially through the work of Willard Gibbs.

The word "chemistry" comes from "alchemy," which referred to an earlier set of practices that encompassed elements of chemistry, metallurgy, philosophy, astrology, astronomy, mysticism and medicine. It is often seen as linked to the quest to turn lead or another common starting material into gold, though in ancient times the study encompassed many of the questions of modern chemistry being defined as the study of the composition of waters, movement, growth, embodying, disembodying, drawing the spirits from bodies and bonding the spirits within bodies by the early 4th century Greek-Egyptian alchemist Zosimos. An alchemist was called a 'chemist' in popular speech, and later the suffix "-ry" was added to this to describe the art of the chemist as "chemistry".

The modern word "alchemy" in turn is derived from the Arabic word "al-kīmīā" (الكیمیاء). In origin, the term is borrowed from the Greek χημία or χημεία. This may have Egyptian origins since "al-kīmīā" is derived from the Greek χημία, which is in turn derived from the word Kemet, which is the ancient name of Egypt in Egyptian. Alternately, "al-kīmīā" may derive from χημεία, meaning "cast together".

The current model of atomic structure is the quantum mechanical model. Traditional chemistry starts with the study of elementary particles, atoms, molecules, substances, metals, crystals and other aggregates of matter. This matter can be studied in solid, liquid, or gas states, in isolation or in combination. The interactions, reactions and transformations that are studied in chemistry are usually the result of interactions between atoms, leading to rearrangements of the chemical bonds which hold atoms together. Such behaviors are studied in a chemistry laboratory.

The chemistry laboratory stereotypically uses various forms of laboratory glassware. However glassware is not central to chemistry, and a great deal of experimental (as well as applied/industrial) chemistry is done without it.

A chemical reaction is a transformation of some substances into one or more different substances. The basis of such a chemical transformation is the rearrangement of electrons in the chemical bonds between atoms. It can be symbolically depicted through a chemical equation, which usually involves atoms as subjects. The number of atoms on the left and the right in the equation for a chemical transformation is equal. (When the number of atoms on either side is unequal, the transformation is referred to as a nuclear reaction or radioactive decay.) The type of chemical reactions a substance may undergo and the energy changes that may accompany it are constrained by certain basic rules, known as chemical laws.

Energy and entropy considerations are invariably important in almost all chemical studies. Chemical substances are classified in terms of their structure, phase, as well as their chemical compositions. They can be analyzed using the tools of chemical analysis, e.g. spectroscopy and chromatography. Scientists engaged in chemical research are known as chemists. Most chemists specialize in one or more sub-disciplines. Several concepts are essential for the study of chemistry; some of them are:

In chemistry, matter is defined as anything that has rest mass and volume (it takes up space) and is made up of particles. The particles that make up matter have rest mass as well – not all particles have rest mass, such as the photon. Matter can be a pure chemical substance or a mixture of substances.

The atom is the basic unit of chemistry. It consists of a dense core called the atomic nucleus surrounded by a space hosting an electron cloud. The nucleus is made up of positively charged protons and uncharged neutrons (together called nucleons), while the electron cloud consists of negatively charged electrons which orbit the nucleus. In a neutral atom, the negatively charged electrons balance out the positive charge of the protons. The nucleus is dense; the mass of a nucleon is appromixately 1,836 times that of an electron, yet the radius of an atom is about 10,000 times that of its nucleus.

The atom is also the smallest entity that can be envisaged to retain the chemical properties of the element, such as electronegativity, ionization potential, preferred oxidation state(s), coordination number, and preferred types of bonds to form (e.g., metallic, ionic, covalent).

A chemical element is a pure substance which is composed of a single type of atom, characterized by its particular number of protons in the nuclei of its atoms, known as the atomic number and represented by the symbol "Z". The mass number is the sum of the number of protons and neutrons in a nucleus. Although all the nuclei of all atoms belonging to one element will have the same atomic number, they may not necessarily have the same mass number; atoms of an element which have different mass numbers are known as isotopes. For example, all atoms with 6 protons in their nuclei are atoms of the chemical element carbon, but atoms of carbon may have mass numbers of 12 or 13.

The standard presentation of the chemical elements is in the periodic table, which orders elements by atomic number. The periodic table is arranged in groups, or columns, and periods, or rows. The periodic table is useful in identifying periodic trends.

A "compound" is a pure chemical substance composed of more than one element. The properties of a compound bear little similarity to those of its elements. The standard nomenclature of compounds is set by the International Union of Pure and Applied Chemistry (IUPAC). Organic compounds are named according to the organic nomenclature system. The names for Inorganic compounds are created according to the inorganic nomenclature system. When a compound has more than one component, then they are divided into two classes, the electropositive and the electronegative components. In addition the Chemical Abstracts Service has devised a method to index chemical substances. In this scheme each chemical substance is identifiable by a number known as its CAS registry number.

A "molecule" is the smallest indivisible portion of a pure chemical substance that has its unique set of chemical properties, that is, its potential to undergo a certain set of chemical reactions with other substances. However, this definition only works well for substances that are composed of molecules, which is not true of many substances (see below). Molecules are typically a set of atoms bound together by covalent bonds, such that the structure is electrically neutral and all valence electrons are paired with other electrons either in bonds or in lone pairs.

Thus, molecules exist as electrically neutral units, unlike ions. When this rule is broken, giving the "molecule" a charge, the result is sometimes named a molecular ion or a polyatomic ion. However, the discrete and separate nature of the molecular concept usually requires that molecular ions be present only in well-separated form, such as a directed beam in a vacuum in a mass spectrometer. Charged polyatomic collections residing in solids (for example, common sulfate or nitrate ions) are generally not considered "molecules" in chemistry. Some molecules contain one or more unpaired electrons, creating radicals. Most radicals are comparatively reactive, but some, such as nitric oxide (NO) can be stable.
The "inert" or noble gas elements (helium, neon, argon, krypton, xenon and radon) are composed of lone atoms as their smallest discrete unit, but the other isolated chemical elements consist of either molecules or networks of atoms bonded to each other in some way. Identifiable molecules compose familiar substances such as water, air, and many organic compounds like alcohol, sugar, gasoline, and the various pharmaceuticals.

However, not all substances or chemical compounds consist of discrete molecules, and indeed most of the solid substances that make up the solid crust, mantle, and core of the Earth are chemical compounds without molecules. These other types of substances, such as ionic compounds and network solids, are organized in such a way as to lack the existence of identifiable molecules "per se". Instead, these substances are discussed in terms of formula units or unit cells as the smallest repeating structure within the substance. Examples of such substances are mineral salts (such as table salt), solids like carbon and diamond, metals, and familiar silica and silicate minerals such as quartz and granite.

One of the main characteristics of a molecule is its geometry often called its structure. While the structure of diatomic, triatomic or tetra atomic molecules may be trivial, (linear, angular pyramidal etc.) the structure of polyatomic molecules, that are constituted of more than six atoms (of several elements) can be crucial for its chemical nature.

A chemical substance is a kind of matter with a definite composition and set of properties. A collection of substances is called a mixture. Examples of mixtures are air and alloys.

The mole is a unit of measurement that denotes an amount of substance (also called chemical amount). The mole is defined as the number of atoms found in exactly 0.012 kilogram (or 12 grams) of carbon-12, where the carbon-12 atoms are unbound, at rest and in their ground state. The number of entities per mole is known as the Avogadro constant, and is determined empirically to be approximately 6.022 mol. Molar concentration is the amount of a particular substance per volume of solution, and is commonly reported in moldm.

In addition to the specific chemical properties that distinguish different chemical classifications, chemicals can exist in several phases. For the most part, the chemical classifications are independent of these bulk phase classifications; however, some more exotic phases are incompatible with certain chemical properties. A "phase" is a set of states of a chemical system that have similar bulk structural properties, over a range of conditions, such as pressure or temperature.

Physical properties, such as density and refractive index tend to fall within values characteristic of the phase. The phase of matter is defined by the "phase transition", which is when energy put into or taken out of the system goes into rearranging the structure of the system, instead of changing the bulk conditions.

Sometimes the distinction between phases can be continuous instead of having a discrete boundary, in this case the matter is considered to be in a supercritical state. When three states meet based on the conditions, it is known as a triple point and since this is invariant, it is a convenient way to define a set of conditions.

The most familiar examples of phases are solids, liquids, and gases. Many substances exhibit multiple solid phases. For example, there are three phases of solid iron (alpha, gamma, and delta) that vary based on temperature and pressure. A principal difference between solid phases is the crystal structure, or arrangement, of the atoms. Another phase commonly encountered in the study of chemistry is the "aqueous" phase, which is the state of substances dissolved in aqueous solution (that is, in water).

Less familiar phases include plasmas, Bose–Einstein condensates and fermionic condensates and the paramagnetic and ferromagnetic phases of magnetic materials. While most familiar phases deal with three-dimensional systems, it is also possible to define analogs in two-dimensional systems, which has received attention for its relevance to systems in biology.

Atoms sticking together in molecules or crystals are said to be bonded with one another. A chemical bond may be visualized as the multipole balance between the positive charges in the nuclei and the negative charges oscillating about them. More than simple attraction and repulsion, the energies and distributions characterize the availability of an electron to bond to another atom.

A chemical bond can be a covalent bond, an ionic bond, a hydrogen bond or just because of Van der Waals force. Each of these kinds of bonds is ascribed to some potential. These potentials create the interactions which hold atoms together in molecules or crystals. In many simple compounds, valence bond theory, the Valence Shell Electron Pair Repulsion model (VSEPR), and the concept of oxidation number can be used to explain molecular structure and composition.

An ionic bond is formed when a metal loses one or more of its electrons, becoming a positively charged cation, and the electrons are then gained by the non-metal atom, becoming a negatively charged anion. The two oppositely charged ions attract one another, and the ionic bond is the electrostatic force of attraction between them. For example, sodium (Na), a metal, loses one electron to become an Na cation while chlorine (Cl), a non-metal, gains this electron to become Cl. The ions are held together due to electrostatic attraction, and that compound sodium chloride (NaCl), or common table salt, is formed.
In a covalent bond, one or more pairs of valence electrons are shared by two atoms: the resulting electrically neutral group of bonded atoms is termed a molecule. Atoms will share valence electrons in such a way as to create a noble gas electron configuration (eight electrons in their outermost shell) for each atom. Atoms that tend to combine in such a way that they each have eight electrons in their valence shell are said to follow the octet rule. However, some elements like hydrogen and lithium need only two electrons in their outermost shell to attain this stable configuration; these atoms are said to follow the "duet rule", and in this way they are reaching the electron configuration of the noble gas helium, which has two electrons in its outer shell.

Similarly, theories from classical physics can be used to predict many ionic structures. With more complicated compounds, such as metal complexes, valence bond theory is less applicable and alternative approaches, such as the molecular orbital theory, are generally used. See diagram on electronic orbitals.

In the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structures, it is invariably accompanied by an increase or decrease of energy of the substances involved. Some energy is transferred between the surroundings and the reactants of the reaction in the form of heat or light; thus the products of a reaction may have more or less energy than the reactants.

A reaction is said to be exergonic if the final state is lower on the energy scale than the initial state; in the case of endergonic reactions the situation is the reverse. A reaction is said to be exothermic if the reaction releases heat to the surroundings; in the case of endothermic reactions, the reaction absorbs heat from the surroundings.

Chemical reactions are invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The "speed" of a chemical reaction (at given temperature T) is related to the activation energy E, by the Boltzmann's population factor formula_1 – that is the probability of a molecule to have energy greater than or equal to E at the given temperature T. This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation.
The activation energy necessary for a chemical reaction to occur can be in the form of heat, light, electricity or mechanical force in the form of ultrasound.

A related concept free energy, which also incorporates entropy considerations, is a very useful means for predicting the feasibility of a reaction and determining the state of equilibrium of a chemical reaction, in chemical thermodynamics. A reaction is feasible only if the total change in the Gibbs free energy is negative, formula_2; if it is equal to zero the chemical reaction is said to be at equilibrium.

There exist only limited possible states of energy for electrons, atoms and molecules. These are determined by the rules of quantum mechanics, which require quantization of energy of a bound system. The atoms/molecules in a higher energy state are said to be excited. The molecules/atoms of substance in an excited energy state are often much more reactive; that is, more amenable to chemical reactions.

The phase of a substance is invariably determined by its energy and the energy of its surroundings. When the intermolecular forces of a substance are such that the energy of the surroundings is not sufficient to overcome them, it occurs in a more ordered phase like liquid or solid as is the case with water (HO); a liquid at room temperature because its molecules are bound by hydrogen bonds. Whereas hydrogen sulfide (HS) is a gas at room temperature and standard pressure, as its molecules are bound by weaker dipole-dipole interactions.

The transfer of energy from one chemical substance to another depends on the "size" of energy quanta emitted from one substance. However, heat energy is often transferred more easily from almost any substance to another because the phonons responsible for vibrational and rotational energy levels in a substance have much less energy than photons invoked for the electronic energy transfer. Thus, because vibrational and rotational energy levels are more closely spaced than electronic energy levels, heat is more easily transferred between substances relative to light or other forms of electronic energy. For example, ultraviolet electromagnetic radiation is not transferred with as much efficacy from one substance to another as thermal or electrical energy.

The existence of characteristic energy levels for different chemical substances is useful for their identification by the analysis of spectral lines. Different kinds of spectra are often used in chemical spectroscopy, e.g. IR, microwave, NMR, ESR, etc. Spectroscopy is also used to identify the composition of remote objects – like stars and distant galaxies – by analyzing their radiation spectra.
The term chemical energy is often used to indicate the potential of a chemical substance to undergo a transformation through a chemical reaction or to transform other chemical substances.

When a chemical substance is transformed as a result of its interaction with another substance or with energy, a chemical reaction is said to have occurred. A "chemical reaction" is therefore a concept related to the "reaction" of a substance when it comes in close contact with another, whether as a mixture or a solution; exposure to some form of energy, or both. It results in some energy exchange between the constituents of the reaction as well as with the system environment, which may be designed vessels—often laboratory glassware.

Chemical reactions can result in the formation or dissociation of molecules, that is, molecules breaking apart to form two or more smaller molecules, or rearrangement of atoms within or across molecules. Chemical reactions usually involve the making or breaking of chemical bonds. Oxidation, reduction, dissociation, acid-base neutralization and molecular rearrangement are some of the commonly used kinds of chemical reactions.

A chemical reaction can be symbolically depicted through a chemical equation. While in a non-nuclear chemical reaction the number and kind of atoms on both sides of the equation are equal, for a nuclear reaction this holds true only for the nuclear particles viz. protons and neutrons.

The sequence of steps in which the reorganization of chemical bonds may be taking place in the course of a chemical reaction is called its mechanism. A chemical reaction can be envisioned to take place in a number of steps, each of which may have a different speed. Many reaction intermediates with variable stability can thus be envisaged during the course of a reaction. Reaction mechanisms are proposed to explain the kinetics and the relative product mix of a reaction. Many physical chemists specialize in exploring and proposing the mechanisms of various chemical reactions. Several empirical rules, like the Woodward–Hoffmann rules often come in handy while proposing a mechanism for a chemical reaction.

According to the IUPAC gold book, a chemical reaction is "a process that results in the interconversion of chemical species." Accordingly, a chemical reaction may be an elementary reaction or a stepwise reaction. An additional caveat is made, in that this definition includes cases where the interconversion of conformers is experimentally observable. Such detectable chemical reactions normally involve sets of molecular entities as indicated by this definition, but it is often conceptually convenient to use the term also for changes involving single molecular entities (i.e. 'microscopic chemical events').

An "ion" is a charged species, an atom or a molecule, that has lost or gained one or more electrons. When an atom loses an electron and thus has more protons than electrons, the atom is a positively charged ion or cation. When an atom gains an electron and thus has more electrons than protons, the atom is a negatively charged ion or anion. Cations and anions can form a crystalline lattice of neutral salts, such as the Na and Cl ions forming sodium chloride, or NaCl. Examples of polyatomic ions that do not split up during acid-base reactions are hydroxide (OH) and phosphate (PO).

Plasma is composed of gaseous matter that has been completely ionized, usually through high temperature.

A substance can often be classified as an acid or a base. There are several different theories which explain acid-base behavior. The simplest is Arrhenius theory, which states than an acid is a substance that produces hydronium ions when it is dissolved in water, and a base is one that produces hydroxide ions when dissolved in water. According to Brønsted–Lowry acid–base theory, acids are substances that donate a positive hydrogen ion to another substance in a chemical reaction; by extension, a base is the substance which receives that hydrogen ion.

A third common theory is Lewis acid-base theory, which is based on the formation of new chemical bonds. Lewis theory explains that an acid is a substance which is capable of accepting a pair of electrons from another substance during the process of bond formation, while a base is a substance which can provide a pair of electrons to form a new bond. According to this theory, the crucial things being exchanged are charges. There are several other ways in which a substance may be classified as an acid or a base, as is evident in the history of this concept.

Acid strength is commonly measured by two methods. One measurement, based on the Arrhenius definition of acidity, is pH, which is a measurement of the hydronium ion concentration in a solution, as expressed on a negative logarithmic scale. Thus, solutions that have a low pH have a high hydronium ion concentration, and can be said to be more acidic. The other measurement, based on the Brønsted–Lowry definition, is the acid dissociation constant (K), which measures the relative ability of a substance to act as an acid under the Brønsted–Lowry definition of an acid. That is, substances with a higher K are more likely to donate hydrogen ions in chemical reactions than those with lower K values.

Redox ("red"uction-"ox"idation) reactions include all chemical reactions in which atoms have their oxidation state changed by either gaining electrons (reduction) or losing electrons (oxidation). Substances that have the ability to oxidize other substances are said to be oxidative and are known as oxidizing agents, oxidants or oxidizers. An oxidant removes electrons from another substance. Similarly, substances that have the ability to reduce other substances are said to be reductive and are known as reducing agents, reductants, or reducers.

A reductant transfers electrons to another substance, and is thus oxidized itself. And because it "donates" electrons it is also called an electron donor. Oxidation and reduction properly refer to a change in oxidation number—the actual transfer of electrons may never occur. Thus, oxidation is better defined as an increase in oxidation number, and reduction as a decrease in oxidation number.

Although the concept of equilibrium is widely used across sciences, in the context of chemistry, it arises whenever a number of different states of the chemical composition are possible, as for example, in a mixture of several chemical compounds that can react with one another, or when a substance can be present in more than one kind of phase.

A system of chemical substances at equilibrium, even though having an unchanging composition, is most often not static; molecules of the substances continue to react with one another thus giving rise to a dynamic equilibrium. Thus the concept describes the state in which the parameters such as chemical composition remain unchanged over time.

Chemical reactions are governed by certain laws, which have become fundamental concepts in chemistry. Some of them are:

The definition of chemistry has changed over time, as new discoveries and theories add to the functionality of the science. The term "chymistry", in the view of noted scientist Robert Boyle in 1661, meant the subject of the material principles of mixed bodies. In 1663 the chemist Christopher Glaser described "chymistry" as a scientific art, by which one learns to dissolve bodies, and draw from them the different substances on their composition, and how to unite them again, and exalt them to a higher perfection.

The 1730 definition of the word "chemistry", as used by Georg Ernst Stahl, meant the art of resolving mixed, compound, or aggregate bodies into their principles; and of composing such bodies from those principles. In 1837, Jean-Baptiste Dumas considered the word "chemistry" to refer to the science concerned with the laws and effects of molecular forces. This definition further evolved until, in 1947, it came to mean the science of substances: their structure, their properties, and the reactions that change them into other substances - a characterization accepted by Linus Pauling. More recently, in 1998, Professor Raymond Chang broadened the definition of "chemistry" to mean the study of matter and the changes it undergoes.

Early civilizations, such as the Egyptians Babylonians, Indians amassed practical knowledge concerning the arts of metallurgy, pottery and dyes, but didn't develop a systematic theory.

A basic chemical hypothesis first emerged in Classical Greece with the theory of four elements as propounded definitively by Aristotle stating that fire, air, earth and water were the fundamental elements from which everything is formed as a combination. Greek atomism dates back to 440 BC, arising in works by philosophers such as Democritus and Epicurus. In 50 BC, the Roman philosopher Lucretius expanded upon the theory in his book "De rerum natura" (On The Nature of Things). Unlike modern concepts of science, Greek atomism was purely philosophical in nature, with little concern for empirical observations and no concern for chemical experiments.

In the Hellenistic world the art of alchemy first proliferated, mingling magic and occultism into the study of natural substances with the ultimate goal of transmuting elements into gold and discovering the elixir of eternal life. Work, particularly the development of distillation, continued in the early Byzantine period with the most famous practitioner being the 4th century Greek-Egyptian Zosimos of Panopolis. Alchemy continued to be developed and practised throughout the Arab world after the Muslim conquests, and from there, and from the Byzantine remnants, diffused into medieval and Renaissance Europe through Latin translations. Some influential Muslim chemists, Abū al-Rayhān al-Bīrūnī, Avicenna and Al-Kindi refuted the theories of alchemy, particularly the theory of the transmutation of metals; and al-Tusi described a version of the conservation of mass, noting that a body of matter is able to change but is not able to disappear.
The development of the modern scientific method was slow and arduous, but an early scientific method for chemistry began emerging among early Muslim chemists, beginning with the 9th century Perso-Arab chemist Jābir ibn Hayyān (known as "Geber" in Europe), who is sometimes referred to as "the father of chemistry". He introduced a systematic and experimental approach to scientific research based in the laboratory, in contrast to the ancient Greek and Egyptian alchemists whose works were largely allegorical and often unintelligble. Under the influence of the new empirical methods propounded by Sir Francis Bacon and others, a group of chemists at Oxford, Robert Boyle, Robert Hooke and John Mayow began to reshape the old alchemical traditions into a scientific discipline. Boyle in particular is regarded as the founding father of chemistry due to his most important work, the classic chemistry text "The Sceptical Chymist" where the differentiation is made between the claims of alchemy and the empirical scientific discoveries of the new chemistry. He formulated Boyle's law, rejected the classical "four elements" and proposed a mechanistic alternative of atoms and chemical reactions that could be subject to rigorous experiment.
The theory of phlogiston (a substance at the root of all combustion) was propounded by the German Georg Ernst Stahl in the early 18th century and was only overturned by the end of the century by the French chemist Antoine Lavoisier, the chemical analogue of Newton in physics; who did more than any other to establish the new science on proper theoretical footing, by elucidating the principle of conservation of mass and developing a new system of chemical nomenclature used to this day.

Before his work, though, many important discoveries had been made, specifically relating to the nature of 'air' which was discovered to be composed of many different gases. The Scottish chemist Joseph Black (the first experimental chemist) and the Dutchman J. B. van Helmont discovered carbon dioxide, or what Black called 'fixed air' in 1754; Henry Cavendish discovered hydrogen and elucidated its properties and Joseph Priestley and, independently, Carl Wilhelm Scheele isolated pure oxygen.

English scientist John Dalton proposed the modern theory of atoms; that all substances are composed of indivisible 'atoms' of matter and that different atoms have varying atomic weights.

The development of the electrochemical theory of chemical combinations occurred in the early 19th century as the result of the work of two scientists in particular, J. J. Berzelius and Humphry Davy, made possible by the prior invention of the voltaic pile by Alessandro Volta. Davy discovered nine new elements including the alkali metals by extracting them from their oxides with electric current.

British William Prout first proposed ordering all the elements by their atomic weight as all atoms had a weight that was an exact multiple of the atomic weight of hydrogen. J. A. R. Newlands devised an early table of elements, which was then developed into the modern periodic table of elements in the 1860s by Dmitri Mendeleev and independently by several other scientists including Julius Lothar Meyer. The inert gases, later called the noble gases were discovered by William Ramsay in collaboration with Lord Rayleigh at the end of the century, thereby filling in the basic structure of the table.
At the turn of the twentieth century the theoretical underpinnings of chemistry were finally understood due to a series of remarkable discoveries that succeeded in probing and discovering the very nature of the internal structure of atoms. In 1897, J. J. Thomson of Cambridge University discovered the electron and soon after the French scientist Becquerel as well as the couple Pierre and Marie Curie investigated the phenomenon of radioactivity. In a series of pioneering scattering experiments Ernest Rutherford at the University of Manchester discovered the internal structure of the atom and the existence of the proton, classified and explained the different types of radioactivity and successfully transmuted the first element by bombarding nitrogen with alpha particles.

His work on atomic structure was improved on by his students, the Danish physicist Niels Bohr and Henry Moseley. The electronic theory of chemical bonds and molecular orbitals was developed by the American scientists Linus Pauling and Gilbert N. Lewis.

The year 2011 was declared by the United Nations as the International Year of Chemistry. It was an initiative of the International Union of Pure and Applied Chemistry, and of the United Nations Educational, Scientific, and Cultural Organization and involves chemical societies, academics, and institutions worldwide and relied on individual initiatives to organize local and regional activities.

Organic chemistry was developed by Justus von Liebig and others, following Friedrich Wöhler's synthesis of urea which proved that living organisms were, in theory, reducible to chemistry. Other crucial 19th century advances were; an understanding of valence bonding (Edward Frankland in 1852) and the application of thermodynamics to chemistry (J. W. Gibbs and Svante Arrhenius in the 1870s).

Chemistry is typically divided into several major sub-disciplines. There are also several main cross-disciplinary and more specialized fields of chemistry.

Other disciplines within chemistry are traditionally grouped by the type of matter being studied or the kind of study. These include inorganic chemistry, the study of inorganic matter; organic chemistry, the study of organic (carbon-based) matter; biochemistry, the study of substances found in biological organisms; physical chemistry, the study of chemical processes using physical concepts such as thermodynamics and quantum mechanics; and analytical chemistry, the analysis of material samples to gain an understanding of their chemical composition and structure. Many more specialized disciplines have emerged in recent years, e.g. neurochemistry the chemical study of the nervous system (see subdisciplines).

Other fields include agrochemistry, astrochemistry (and cosmochemistry), atmospheric chemistry, chemical engineering, chemical biology, chemo-informatics, electrochemistry, environmental chemistry, femtochemistry, flavor chemistry, flow chemistry, geochemistry, green chemistry, histochemistry, history of chemistry, hydrogenation chemistry, immunochemistry, marine chemistry, materials science, mathematical chemistry, mechanochemistry, medicinal chemistry, molecular biology, molecular mechanics, nanotechnology, natural product chemistry, oenology, organometallic chemistry, petrochemistry, pharmacology, photochemistry, physical organic chemistry, phytochemistry, polymer chemistry, radiochemistry, solid-state chemistry, sonochemistry, supramolecular chemistry, surface chemistry, synthetic chemistry, thermochemistry, and many others.

The chemical industry represents an important economic activity worldwide. The global top 50 chemical producers in 2013 had sales of US$980.5 billion with a profit margin of 10.3%.








</doc>
<doc id="5184" url="https://en.wikipedia.org/wiki?curid=5184" title="Cytoplasm">
Cytoplasm

In cell biology, the cytoplasm is the material within a living cell, excluding the cell nucleus. It comprises cytosol (the gel-like substance enclosed within the cell membrane) and the organelles – the cell's internal sub-structures. All of the contents of the cells of prokaryotic organisms (such as bacteria, which lack a cell nucleus) are contained within the cytoplasm. Within the cells of eukaryotic organisms the contents of the cell nucleus are separated from the cytoplasm, and are then called the nucleoplasm. The cytoplasm is about 80% water and usually colorless.

The submicroscopic ground cell substance or cytoplasmatic matrix which remains after exclusion the cell organelles and particles is groundplasm. It is the hyaloplasm of light microscopy, and high complex, polyphasic system in which all of resolvable cytoplasmic elements of are suspended, including the larger organelles such as the ribosomes, mitochondria, the plant plastids, lipid droplets, and vacuoles.

It is within the cytoplasm that most cellular activities occur, such as many metabolic pathways including glycolysis, and processes such as cell division. The concentrated inner area is called the endoplasm and the outer layer is called the cell cortex or the ectoplasm.

Movement of calcium ions in and out of the cytoplasm is a signaling activity for metabolic processes.

In plants, movement of the cytoplasm around vacuoles is known as cytoplasmic streaming.

The term was introduced by Rudolf von Kölliker in 1863, originally as a synonym for protoplasm, but later it has come to mean the cell substance and organelles outside the nucleus.

There has been certain disagreement on the definition of cytoplasm, as some authors prefer to exclude from it some organelles, especially the vacuoles and sometimes the plastids.

The physical properties of the cytoplasm have been contested in recent years. It remains uncertain how the varied components of the cytoplasm interact to allow movement of particles and organelles while maintaining the cell’s structure. The flow of cytoplasmic components plays an important role in many cellular functions which are dependent on the permeability of the cytoplasm. An example of such function is cell signalling, a process which is dependent on the manner in which signaling molecules are allowed to diffuse across the cell. While small signaling molecules like calcium ions are able to diffuse with ease, larger molecules and subcellular structures often require aid in moving through the cytoplasm. The irregular dynamics of such particles have given rise to various theories on the nature of the cytoplasm.

There has long been evidence that the cytoplasm behaves like a sol-gel. It is thought that the component molecules and structures of the cytoplasm behave at times like a disordered colloidal solution (sol) and at other times like an integrated network, forming a solid mass (gel). This theory thus proposes that the cytoplasm exists in distinct fluid and solid phases depending on the level of interaction between cytoplasmic components, which may explain the differential dynamics of different particles observed moving through the cytoplasm.

Recently it has been proposed that the cytoplasm behaves like a glass-forming liquid approaching the glass transition. In this theory, the greater the concentration of cytoplasmic components, the less the cytoplasm behaves like a liquid and the more it behaves as a solid glass, freezing larger cytoplasmic components in place (it is thought that the cell's metabolic activity is able to fluidize the cytoplasm to allow the movement of such larger cytoplasmic components). A cell's ability to vitrify in the absence of metabolic activity, as in dormant periods, may be beneficial as a defence strategy. A solid glass cytoplasm would freeze subcellular structures in place, preventing damage, while allowing the transmission of very small proteins and metabolites, helping to kickstart growth upon the cell's revival from dormancy.

There has been research examining the motion of cytoplasmic particles independent of the nature of the cytoplasm. In such an alternative approach, the aggregate random forces within the cell caused by motor proteins explain the non-Brownian motion of cytoplasmic constituents.

The three major elements of the cytoplasm are the cytosol, organelles and inclusions.

The cytosol is the portion of the cytoplasm not contained within membrane-bound organelles. Cytosol makes up about 70% of the cell volume and is a complex mixture of cytoskeleton filaments, dissolved molecules, and water. The cytosol's filaments include the protein filaments such as actin filaments and microtubules that make up the cytoskeleton, as well as soluble proteins and small structures such as ribosomes, proteasomes, and the mysterious vault complexes. The inner, granular and more fluid portion of the cytoplasm is referred to as endoplasm.

Due to this network of fibres and high concentrations of dissolved macromolecules, such as proteins, an effect called macromolecular crowding occurs and the cytosol does not act as an ideal solution. This crowding effect alters how the components of the cytosol interact with each other.

Organelles (literally "little organs"), are usually membrane-bound structures inside the cell that have specific functions. Some major organelles that are suspended in the cytosol are the mitochondria, the endoplasmic reticulum, the Golgi apparatus, vacuoles, lysosomes, and in plant cells, chloroplasts.

The inclusions are small particles of insoluble substances suspended in the cytosol. A huge range of inclusions exist in different cell types, and range from crystals of calcium oxalate or silicon dioxide in plants, to granules of energy-storage materials such as starch, glycogen, or polyhydroxybutyrate. A particularly widespread example are lipid droplets, which are spherical droplets composed of lipids and proteins that are used in both prokaryotes and eukaryotes as a way of storing lipids such as fatty acids and sterols. Lipid droplets make up much of the volume of adipocytes, which are specialized lipid-storage cells, but they are also found in a range of other cell types.

The cytoplasm, mitochondria and most organelles are contributions to the cell from the maternal gamete. Contrary to the older information that disregards any notion of the cytoplasm being active, new research has shown it to be in control of movement and flow of nutrients in and out of the cell by viscoplastic behavior and a measure of the reciprocal rate of bond breakage within the cytoplasmic network.

The material properties of the cytoplasm remain an ongoing investigation. Recent measurements using force spectrum microscopy reveal that the cytoplasm can be likened to an elastic solid, rather than a viscoelastic fluid.



</doc>
<doc id="5185" url="https://en.wikipedia.org/wiki?curid=5185" title="Christ (title)">
Christ (title)

In Christianity, Christ (Greek Χριστός, "Christós", meaning "the anointed one") is a title for the saviour and redeemer who would bring salvation to the Jewish people and mankind. Christians believe Jesus is the Jewish messiah prophercized in both the Hebrew Bible and the Christian Old Testament. As the New Testament was written in Greek, the Greek word for Christ was used as a translation of "Messiah". Its Old Testament use by Christians is historically derived from its use in the Greek Septuagint also as a translation of "Messiah". "Christ", used by Christians as both a name and a title, is synonymous with Jesus.

The role of the Christ in Christianity originated from the concept of the messiah in Judaism. Though the conceptions of the messiah in each religion are similar, for the most part they are distinct from one another due to the split of early Christianity and Judaism in the 1st century.

Though the original followers of Jesus believed Jesus to be the Jewish messiah, e.g. in the Confession of Peter, before the crucifixion and resurrection, Jesus was usually referred to as "Jesus of Nazareth" or "Jesus, son of Joseph". Jesus came to be called "Jesus Christ" (meaning "Jesus the "Khristós"", i.e. "Jesus the Messiah" or "Jesus the Anointed") by his followers after his crucifixion and resurrection. Christians believe that the messianic prophecies were fulfilled in his mission, death, and resurrection. The Pauline epistles, the earliest texts of the New Testament, often refer to Jesus as "Christ Jesus" or "Christ". The word "Christ" was originally a title, but later became part of the name "Jesus Christ". It is also used as a title, in the reciprocal use "Christ Jesus", meaning "the Messiah Jesus", and independently as "the Christ".

The followers of Jesus became known as Christians (as in Acts ) because they believed Jesus to be the "Khristós" or "Mashiach" prophesied in the Hebrew Bible. Jesus was not, and is not, accepted in Judaism as a Jewish messiah, and the concept of a divine messiah was always rejected by Judaism as idolatry. Religious Jews still await their messiah's first coming and the Messianic prophecies of Jewish tradition to be accomplished. Religious Christians believe in the Second Coming of Christ, and they await the rest of Christian messianic prophecies to be fulfilled. One of those prophecies, distinctive in both the Jewish and Christian concept of the messiah, is that a Jewish king from the Davidic line, who will be "anointed" with holy anointing oil, will be king of God's kingdom on earth, and rule the Jewish people and mankind during the Messianic Age and World to come. Muslims accept Jesus () as "al-Masih", the messiah in Islam, and believe he will come again, but don't believe that the messiah is divine or the Son of God.

The area of Christian theology called Christology is primarily concerned with the nature and person of Jesus Christ as recorded in the canonical gospels and the letters of the New Testament.

Christ comes from ("Christos"), meaning "anointed one". In the Greek Septuagint, "christos" was used to translate the Hebrew מָשִׁיחַ ("Mašíaḥ," messiah), meaning "[one who is] anointed.", a title allegedely adopted from the term for the tradition of anointing the Egyptian pharaoh during coronation or marriage with oil drawn from the fat of "messeh", who was the sacred crocodile or crocodile star in the spells and the same anointing ritual may be traced to earlier Mesopotamian Mušḫuššu. In coffins of Egyptian mummies the word "krst" is found as a blessing and anointing from Horus and Osiris, hence the word "Christos" is thought as loaned. "Krst" denoted the process of preparation of the mummy by embalming, purifying and anointing, and can mean anointed, buried or covered in oil.

The word "Christ" (and similar spellings) appears in English and in most European languages. English-speakers now often use "Christ" as if it were a name, one part of the name "Jesus Christ", though it was originally a title ("the Messiah"). Its usage in "Christ Jesus" emphasizes its nature as a title. Compare the usage "the Christ".

The spelling "Christ" in English became standardized in the 18th century, when, in the spirit of the Enlightenment, the spelling of certain words changed to fit their Greek or Latin origins. Prior to this, scribes writing in Old and Middle English usually used the spelling "Crist" - the "i" being pronounced either as , preserved in the names of churches such as St Katherine Cree, or as a short , preserved in the modern pronunciation of "Christmas". The spelling "Christ" in English is attested from the 14th century.

In modern and ancient usage, even in secular terminology, "Christ" usually refers to Jesus, based on the centuries-old tradition of such usage. Since the Apostolic Age, the[...] use of the definite article before the word Christ and its gradual development into a proper name show the Christians identified the bearer with the promised Messias of the Jews.

At the time of Jesus, there was no single form of Second Temple Judaism, and there were significant political, social, and religious differences among the various Jewish groups. However, for centuries the Jews had used the term "moshiach" ("anointed") to refer to their expected deliverer. A large number of Old Testament passages were regarded as messianic by the Jews, many more than are commonly considered messianic by Christians, and different groups of Jews assigned varying degrees of significance to them.

The Greek word "messias" appears only twice in the Septuagint of the promised prince (; ). This title was used when a name was wanted for the promised one who was to be at once King and Savior. The New Testament states that the long-awaited messiah had come and describes this savior as "the Christ". In , the apostle Peter said, in what has become a famous proclamation of faith among Christians since the first century, "You are the Christ, the Son of the living God."

Mark ("The beginning of the gospel of Jesus Christ, the Son of God") identifies Jesus as both Christ and the Son of God. The divinity is re-affirmed in . Thereafter, Mark never applies the term "Christ" to Jesus as a name. uses Christ as a name and Matthew explains it again with: "Jesus, who is called Christ". In the Gospel of John, Jesus referred to himself as the Son of God far more frequently than in the Synoptic Gospels.

The use of the definite article before the word "Christ" and its gradual development into a proper name show that the Christians identified Jesus with the promised messiah of the Jews who fulfilled all the Messianic predictions in a fuller and a higher sense than had been given them by the rabbis.

The Gospels of Mark and Matthew begin by calling Jesus both Christ and the Son of God, but these are two distinct attributions. They develop in the New Testament along separate paths and have distinct theological implications. At the time in Roman Judaea, the Jews had been awaiting the "messiah", and many people were wondering who it would be. When John the Baptist appeared and began preaching, he attracted disciples who assumed that he would be announced as the messiah, or "the one" that they had been awaiting. But the title Son of God was not attributed to John.

The first instance of Jesus being called the Son of God appears during his baptism by John the Baptist. In the narrative, a voice from heaven called Jesus "My Son". John the Baptist was in prison in the Messengers from John the Baptist episode ( and Luke ), and two of his disciples ask Jesus a question on his behalf: "Are you the one to come after me or shall we wait for another?"—indicating that John doubted the identity of Jesus as Christ at that time (see also Rejection of Jesus).

In Martha told Jesus, "you are the Christ, the Son of God, who is coming into the world", signifying that both titles were generally accepted (yet considered distinct) among the followers of Jesus before the raising of Lazarus.

Explicit claims of Jesus being the messiah are found in the canonical gospels in the Confession of Peter (e.g. ) and the words of Jesus before his judges at his trial before the Sanhedrin. These incidents involve far more than a mere Messianic claim; taken in their setting, they constitute a claim to be the Son of God.

In the trial of Jesus before the Sanhedrin and Pontius Pilate, it might appear from the narratives of Matthew and Luke that Jesus at first refused a direct reply to the high priest's question: "Art thou the Christ?", where his answer is given merely as ""su eipas"" ("thou hast said it"). The Gospel of Mark, however, states the answer as ""ego eimi"" ("I am"), and there are instances from Jewish literature in which the expression "thou hast said it" is equivalent to "you are right". The Messianic claim was less significant than the claim to divinity, which caused the high priest's horrified accusation of blasphemy and the subsequent call for the death sentence. Before Pilate, on the other hand, it was merely the assertion of his royal dignity which gave grounds for his condemnation.

The word "Christ" is closely associated with Jesus in the Pauline epistles, which suggests that there was no need for the early Christians to claim that Jesus is Christ because it was considered widely accepted among them. Hence Paul can use the term "Khristós" with no confusion as to whom it refers, and he can use expressions such as "in Christ" to refer to the followers of Jesus, as in and . Paul proclaimed him as the Last Adam, who restored through obedience what Adam lost through disobedience. The Pauline epistles are a source of some key Christological connections; e.g., relates the love of Christ to the knowledge of Christ, and considers the love of Christ as a necessity for knowing him.

There are also implicit claims to him being the Christ in the words and actions of Jesus. Episodes in the life of Jesus and statements about what he accomplished during his public ministry are found throughout the New Testament. Trinitarianism summarily claims: "Jesus Christ was fully God and fully man in one person, and will be so forever."

There are distinct, and differing, views among Christians regarding the existence of Christ before his conception. A key passage in the New Testament is where John 1:17 specifically mentions that "grace and truth came through Jesus Christ." Those who believe in the Trinity, consider Christ a pre-existent divine hypostasis called the Logos or the Word. Other, non-Trinitarian views, question the aspect of personal pre-existence or question the aspect of divinity, or both. An example is the Orthodox Gnomic view, which asserts that Christ was, in fact, not a pre-existent divine being.

The concept of Christ as Logos derives from : "In the beginning was the Word, and the Word was with God, and the Word was God." In the original Greek, "Logos" (λόγος) is used for "Word," and is often used untranslated. In the Christology of the Logos, Christ is viewed as the Incarnation of the "Divine Logos", i.e. The Word.

In the 2nd century, with his theory of "recapitulation", Irenaeus connected "Christ the Creator" with "Christ the Savior", relying on ("when the times reach their fulfillment – to bring unity to all things in heaven and on earth under Christ") to gather together and "wrap up" the cycle of the Nativity and Resurrection of Christ.

In Apostle Paul viewed the Nativity of Jesus as an event of cosmic significance which changed the nature of the world by paving the way for salvation.

Christian teachings present the Love of Christ as a basis for his sacrificial act that brought forth salvation. In Jesus explains that his sacrifice was performed so: "that the world may know that I love the Father, and as the Father gave me commandment, even so I do." then states that: "Christ also loved the church, and gave himself up for it".

In the 2nd century, Irenaeus expressed his views of salvation in terms of the imitation of Christ and his theory of "recapitulation". For Irenaeus the imitation of Christ is based on God's plan of salvation, which involved Christ as the "Last Adam" He viewed the incarnation as the way in which Christ repaired the damage done by Adam's disobedience. For Irenaeus, salvation was achieved by Christ restoring humanity to the image of God, and he saw the Christian imitation of Christ as a key component on the path to salvation. For Irenaeus Christ succeeded on every point on which Adam failed. Irenaeus drew a number of parallels, e.g. just as in the fall of Adam resulted from the fruit of a tree, Irenaeus saw redemption and salvation as the fruit of another tree: the cross of crucifixion.

Following in the Pauline tradition, in the 5th century Augustine of Hippo viewed Christ as the mediator of the New Covenant between God and man and as the conqueror over sin. He viewed Christ as the cause and reason for the reconciliation of man with God after the fall of Adam, and he saw in Christ the path to Christian salvation. Augustine believed that salvation is available to those who are worthy of it, through faith in Christ.

In the 13th century Thomas Aquinas aimed to recapture the teachings of the Church Fathers on the role of the Holy Trinity in the economy of salvation. In Aquinas' view angels and humans were created for salvation from the very beginning. For Aquinas the Passion of Christ poured out the grace of salvation and all its virtues unto humanity.

Martin Luther distinguished the history of salvation between the Old and the New Testament, and saw a new dimension to salvation with the arrival of Christ.

The focus on human history was an important element of the biblically grounded 16th-century theology of John Calvin. Calvin considered the first coming of Christ as the key turning point in human history. He viewed Christ as "the one through whom salvation began" and he saw the completion of Christ's plan of salvation as his death and Resurrection.

The use of "Χ," derived from Chi, the Greek alphabet initial, as an abbreviation for Christ (most commonly in the abbreviation "Χmas") is often misinterpreted as a modern secularization of the term. Thus understood, the centuries-old English word Χmas, is actually a shortened form of CHmas, which is, itself, a shortened form for Christmas. Christians are sometimes referred to as "Xians," with the 'X' replacing 'Christ.

A very early Christogram is the "Chi Rho" symbol formed by superimposing the first two Greek letters in Christ ( ), chi = ch and rho = r, to produce ☧.




</doc>
<doc id="5187" url="https://en.wikipedia.org/wiki?curid=5187" title="Capital">
Capital

Capital may refer to:














</doc>
<doc id="5188" url="https://en.wikipedia.org/wiki?curid=5188" title="Central Europe">
Central Europe

Central Europe is the region comprising the central part of Europe. It is said to occupy continuous territory that are otherwise conventionally Eastern Europe and Western Europe. The concept of Central Europe is based on a common historical, social and cultural identity. Central Europe is going through a phase of "strategic awakening", with initiatives such as the CEI, Centrope and the Visegrád Four. While the region's economy shows high disparities with regard to income, all Central European countries are listed by the Human Development Index as very highly developed.

Elements of unity for Western and Central Europe were Roman Catholicism and Latin. However Eastern Europe, which remained Eastern Orthodox Christian, was the area of Graeco-Byzantine cultural influence; after the schism (1054), Eastern Europe developed cultural unity and resistance to the Western world (Catholic and Protestant) within the framework of Church Slavonic language and the Cyrillic alphabet.
According to Hungarian historian Jenő Szűcs, foundations of Central European history at the first millennium were in close connection with Western European development. He explained that between the 11th and 15th centuries not only Christianization and its cultural consequences were implemented, but well-defined social features emerged in Central Europe based on Western characteristics. The keyword of Western social development after millennium was the spread of liberties and autonomies in Western Europe. These phenomena appeared in the middle of the 13th century in Central European countries. There were self-governments of towns, counties and parliaments.

In 1335 under the rule of the King Charles I of Hungary, the castle of Visegrád, the seat of the Hungarian monarchs was the scene of the royal summit of the Kings of Poland, Bohemia and Hungary. They agreed to cooperate closely in the field of politics and commerce, inspiring their late successors to launch a successful Central European initiative.

In the Middle Ages, countries in Central Europe adopted Magdeburg rights.

Before 1870, the industrialization that had developed in Western and Central Europe and the United States did not extend in any significant way to the rest of the world. Even in Eastern Europe, industrialization lagged far behind. Russia, for example, remained largely rural and agricultural, and its autocratic rulers kept the peasants in serfdom.
The concept of Central Europe was already known at the beginning of the 19th century, but its real life began in the 20th century and immediately became an object of intensive interest. However, the very first concept mixed science, politics and economy – it was strictly connected with intensively growing German economy and its aspirations to dominate a part of European continent called "Mitteleuropa". The German term denoting Central Europe was so fashionable that other languages started referring to it when indicating territories from Rhine to Vistula, or even Dnieper, and from the Baltic Sea to the Balkans. An example of that-time vision of Central Europe may be seen in J. Partsch’s book of 1903.

On 21 January 1904, "Mitteleuropäischer Wirtschaftsverein" (Central European Economic Association) was established in Berlin with economic integration of Germany and Austria–Hungary (with eventual extension to Switzerland, Belgium and the Netherlands) as its main aim. Another time, the term Central Europe became connected to the German plans of political, economic and cultural domination. The "bible" of the concept was Friedrich Naumann’s book "Mitteleuropa" in which he called for an economic federation to be established after the war. Naumann's idea was that the federation would have at its centre Germany and the Austro-Hungarian Empire but would also include all European nations outside the Anglo-French alliance, on one side, and Russia, on the other. The concept failed after the German defeat in World War I and the dissolution of Austria–Hungary. The revival of the idea may be observed during the Hitler era.

According to Emmanuel de Martonne, in 1927 the Central European countries included: Austria, Czechoslovakia, Germany, Hungary, Poland, Romania and Switzerland. The author use both Human and Physical Geographical features to define Central Europe.

The interwar period (1918–1939) brought new geopolitical system and economic and political problems, and the concept of Central Europe took a different character. The centre of interest was moved to its eastern part – the countries that have (re)appeared on the map of Europe: Czechoslovakia, Hungary and Poland. Central Europe ceased to be the area of German aspiration to lead or dominate and became a territory of various integration movements aiming at resolving political, economic and national problems of "new" states, being a way to face German and Soviet pressures. However, the conflict of interests was too big and neither Little Entente nor Intermarium ("Międzymorze") ideas succeeded.

The interwar period brought new elements to the concept of Central Europe. Before World War I, it embraced mainly German states (Germany, Austria), non-German territories being an area of intended German penetration and domination – German leadership position was to be the natural result of economic dominance. After the war, the Eastern part of Central Europe was placed at the centre of the concept. At that time the scientists took interest in the idea: the International Historical Congress in Brussels in 1923 was committed to Central Europe, and the 1933 Congress continued the discussions.

Hungarian scholar Magda Adam wrote in her study "Versailles System and Central Europe" (2006): "Today we know that the bane of Central Europe was the Little Entente, military alliance of Czechoslovakia, Romania and Kingdom of Serbs, Croats and Slovenes (later Yugoslavia), created in 1921 not for Central Europe's cooperation nor to fight German expansion, but in a wrong perceived notion that a completely powerless Hungary must be kept down".

The avant-garde movements of Central Europe were an essential part of modernism’s evolution, reaching its peak throughout the continent during the 1920s. The "Sourcebook of Central European avantgards" (Los Angeles County Museum of Art) contains primary documents of the avant-gardes in Austria, Czechoslovakia, Germany, Hungary, and Poland from 1910 to 1930. The manifestos and magazines of Western European radical art circles are well known to Western scholars and are being taught at primary universities of their kind in the western world.

The German term "Mitteleuropa" (or alternatively its literal translation into English, "Middle Europe") is an ambiguous German concept. It is sometimes used in English to refer to an area somewhat larger than most conceptions of 'Central Europe'; it refers to territories under Germanic cultural hegemony until World War I (encompassing Austria–Hungary and Germany in their pre-war formations but usually excluding the Baltic countries north of East Prussia). According to Fritz Fischer "Mitteleuropa" was a scheme in the era of the Reich of 1871–1918 by which the old imperial elites had allegedly sought to build a system of German economic, military and political domination from the northern seas to the Near East and from the Low Countries through the steppes of Russia to the Caucasus. Later on, professor Fritz Epstein argued the threat of a Slavic "Drang nach Westen" (Western expansion) had been a major factor in the emergence of a "Mitteleuropa" ideology before the Reich of 1871 ever came into being.

In Germany the connotation was also sometimes linked to the pre-war German provinces east of the Oder-Neisse line which were lost as the result of World War II, annexed by People's Republic of Poland and the Soviet Union, and ethnically cleansed of Germans by communist authorities and forces ("see expulsion of Germans after World War II") due to Yalta Conference and Potsdam Conference decisions. In this view Bohemia and Moravia, with its dual Western Slavic and Germanic heritage, combined with the historic element of the "Sudetenland", is a core region illustrating the problems and features of the entire Central European region.

The term "Mitteleuropa" conjures up negative historical associations among some elder people, although the Germans have not played an exclusively negative role in the region. Most Central European Jews embraced the enlightened German humanistic culture of the 19th century. German-speaking Jews from turn of the 20th century Vienna, Budapest and Prague became representatives of what many consider to be Central European culture at its best, though the Nazi version of "Mitteleuropa" destroyed this kind of culture instead. However, the term "Mitteleuropa" is now widely used again in German education and media without negative meaning, especially since the end of communism. In fact, many people from the new states of Germany do not identify themselves as being part of Western Europe and therefore prefer the term "Mitteleuropa".

Following World War II, large parts of Europe that were culturally and historically Western became part of the Eastern bloc. Czech author Milan Kundera (emigrant to France) thus wrote in 1984 about the "Tragedy of Central Europe" in the New York Review of Books. Consequently, the English term "Central Europe" was increasingly applied only to the westernmost former Warsaw Pact countries (East Germany, Poland, Czechoslovakia, Hungary) to specify them as communist states that were culturally tied to Western Europe. This usage continued after the end of the Warsaw Pact when these countries started to undergo transition.

The post-World War II period brought blocking of the research on Central Europe in the Eastern Bloc countries, as its every result proved the dissimilarity of Central Europe, which was inconsistent with the Stalinist doctrine. On the other hand, the topic became popular in Western Europe and the United States, much of the research being carried out by immigrants from Central Europe. At the end of the communism, publicists and historians in Central Europe, especially anti-communist opposition, came back to their research.

According to Karl A. Sinnhuber ("Central Europe: Mitteleuropa: Europe Centrale: An Analysis of a Geographical Term") most Central European states were unable to preserve their political independence and became Soviet Satellite Europe. Besides Austria, only the marginal Central European states of Finland and Yugoslavia preserved their political sovereignty to a certain degree, being left out of any military alliances in Europe.

According to "Meyers Enzyklopädisches Lexikon", Central Europe is a part of Europe composed of Austria, Belgium, Czechoslovakia, Germany, Hungary, Luxembourg, Netherlands, Poland, Romania and Switzerland, and northern marginal regions of Italy and Yugoslavia (northern states – Croatia, Vojvodina and Slovenia), as well as northeastern France.

Rather than a physical entity, Central Europe is a concept of shared history which contrasts with that of the surrounding regions. The issue of how to name and define the Central European region is subject to debates. Very often, the definition depends on the nationality and historical perspective of its author.

Main propositions, gathered by Jerzy Kłoczowski, include:


According to Ronald Tiersky, the 1991 summit held in Visegrád, Hungary and attended by the Polish, Hungarian and Czechoslovak presidents was hailed at the time as a major breakthrough in Central European cooperation, but the Visegrád Group became a vehicle for coordinating Central Europe's road to the European Union, while development of closer ties within the region languished.

Peter J. Katzenstein described Central Europe as a way station in a Europeanization process that marks the transformation process of the Visegrád Group countries in different, though comparable ways. According to him, in Germany's contemporary public discourse "Central European identity" refers to the civilizational divide between Roman Catholicism and Eastern Orthodoxy. He says there's no precise, uncontestable way to decide whether the Baltic states, Serbia, Croatia, Slovenia, Romania, and Bulgaria are parts of Central Europe or not.

Lonnie R. Johnson points out criteria to distinguish Central Europe from Western, Eastern and Southeast Europe:

He also thinks that Central Europe is a dynamic historical concept, not a static spatial one. For example, Lithuania, a fair share of Belarus and western Ukraine are in Eastern Europe today, but years ago they were in Polish–Lithuanian Commonwealth. Johnson's study on Central Europe received acclaim and positive reviews in the scientific community. However, according to Romanian researcher Maria Bucur this very ambitious project suffers from the weaknesses imposed by its scope (almost 1600 years of history).

"The Columbia Encyclopedia" defines Central Europe as: Germany, Switzerland, Liechtenstein, Austria, Poland, the Czech Republic, Slovakia, and Hungary. The World Factbook uses the same definition adding Slovenia too. Encarta Encyclopedia and Encyclopædia Britannica do not clearly define the region, but Encarta places the same countries into Central Europe in its individual articles on countries, adding Slovenia in "south central Europe".

The German Encyclopaedia "Meyers Grosses Taschenlexikon" ("Meyers Big Pocket Encyclopedia"), 1999, defines Central Europe as the central part of Europe with no precise borders to the East and West. The term is mostly used to denominate the territory between the Schelde to Vistula and from the Danube to the Moravian Gate. Usually the countries considered to be Central European are Austria, Croatia, the Czech Republic, Germany, Hungary, Poland, Slovakia, Slovenia, Switzerland; in the broader sense Romania too, occasionally also Belgium, the Netherlands, and Luxembourg.

The comprehension of the concept of "Central Europe" is an ongoing source of controversy, though the Visegrád Group constituents are almost always included as "de facto" C.E. countries. Although views on which countries belong to Central Europe are vastly varied, according to many sources (see section Current views on Central Europe) the region includes the states listed in the sections below.

Depending on context, Central European countries are sometimes grouped as Eastern or Western European countries, collectively or individually but some place them in Eastern Europe instead: for instance Austria can be referred to as Central European, as well as Eastern European or Western European.

Some sources also add neighbouring countries for historical reasons (the former Austro-Hungarian and German Empires, and modern Baltic states), or based on geographical and/or cultural reasons:


The Baltic states, geographically located in Northern Europe, have been considered part of Central Europe in the German tradition of the term, "Mitteleuropa". Benelux countries are generally considered a part of Western Europe, rather than Central Europe. Nevertheless, they are occasionally mentioned in the Central European context due to cultural, historical and linguistic ties.

The following states or some of their regions may sometimes be included in Central Europe:

Geography defines Central Europe's natural borders with the neighbouring regions to the North across the Baltic Sea namely the Northern Europe (or Scandinavia), and to the South across the Alps, the Apennine peninsula (or Italy), and the Balkan peninsula across the Soča-Krka-Sava-Danube line. The borders to Western Europe and Eastern Europe are geographically less defined and for this reason the cultural and historical boundaries migrate more easily West-East than South-North. The Rhine river which runs South-North through Western Germany is an exception.
Southwards, the Pannonian Plain is bounded by the rivers Sava and Danube- and their respective floodplains. The Pannonian Plain stretches over the following countries: Austria, Croatia, Hungary, Romania, Serbia, Slovakia and Slovenia, and touches borders of Bosnia and Herzegovina (Republika Srpska) and Ukraine ("peri- Pannonian states").

As southeastern division of the Eastern Alps, the Dinaric Alps extend for 650 kilometres along the coast of the Adriatic Sea (northwest-southeast), from the Julian Alps in the northwest down to the Šar-Korab massif, north-south. According to the Freie Universitaet Berlin, this mountain chain is classified as South Central European.

The Central European flora region stretches from Central France (the Massif Central) to Central Romania (Carpathians) and Southern Scandinavia.

At times, the term "Central Europe" denotes a geographic definition as the Danube region in the heart of the continent, including the language and culture areas which are today included in the states of Croatia, the Czech Republic, Hungary, Poland, Serbia, Slovakia, Slovenia and usually also Austria and Germany, but "never" Russia and other countries of the former Soviet Union towards the Ural mountains.


Central Europe is one of continent's most populous regions. It includes countries of varied sizes, ranging from tiny Liechtenstein to Germany, the largest European country by population (that is entirely placed in Europe). Demographic figures for countries entirely located within notion of Central Europe ("the core countries") number around 165 million people, out of which around 82 million are residents of Germany. Other populations include: Poland with around 38.5 million residents, Czech Republic at 10.5 million, Hungary at 10 million, Austria with 8.5 million, Switzerland with its 8 million inhabitants, Slovakia at 5.4 million, Croatia with its 4.3 million residents, Slovenia at 2 million (2014 estimate) and Liechtenstein at a bit less than 40,000.
If the countries which are occasionally included in Central Europe were counted in, partially or in whole – Romania (20 million), Serbia (6.9 million), Lithuania (2.9 million), Latvia (2 million), Estonia (1.3 million) – it would contribute to the rise of between 25–35 million, depending on whether regional or integral approach was used. If smaller, western and eastern historical parts of Central Europe would be included in the demographic corpus, further 20 million people of different nationalities would also be added in the overall count, it would surpass the 200 million people figure.

Currently, the members of the Eurozone include Austria, Germany, Luxembourg, Slovakia, and Slovenia. Croatia, the Czech Republic, Hungary and Poland use their currencies (Croatian kuna, Czech koruna, Hungarian forint, Polish złoty), but are obliged to adopt the Euro. Switzerland uses its own currency, Swiss franc.

Countries in descending order of Human Development Index (2014 data):

The index of globalization in Central European countries (2015 data):


Legatum Prosperity Index demonstrates an average and high level of prosperity in Central Europe (2016 data):

Most countries in Central Europe score tend to score above the average in the Corruption Perceptions Index (2015 data):

According to the Bribe Payers Index, released yearly since 1995 by the Berlin-based NGO Transparency International, Germany and Switzerland, the only two Central European countries examined in the study, were respectively ranked 2nd and 4th in 2011.

Industrialisation occurred early in Central Europe. That caused construction of rail and other types of infrastructure.

Central Europe contains the continent's earliest railway systems, whose greatest expansion was recorded in Austro-Hungarian and German territories between 1860-1870s. By the mid-19th century Berlin, Vienna, and Buda/Pest were focal points for network lines connecting industrial areas of Saxony, Silesia, Bohemia, Moravia and Lower Austria with the Baltic (Kiel, Szczecin) and Adriatic (Rijeka, Trieste). Rail infrastructure in Central Europe remains the densest in the world. Railway density, with total length of lines operated (km) per 1,000 km2, is the highest in the Czech Republic (198.6), Poland (121.0), Slovenia (108.0), Germany (105.5), Hungary (98.7), Slovakia (73.9) and Croatia (72.5). when compared with most of Europe and the rest of the world.

Before the first railroads appeared in the 1840s, river transport constituted the main means of communication and trade. Earliest canals included Plauen Canal (1745), Finow Canal, and also Bega Canal (1710) which connected Timișoara to Novi Sad and Belgrade via Danube. The most significant achievement in this regard was the facilitation of navigability on Danube from the Black sea to Ulm in the 19th century.

Compared to most of Europe, the economies of Austria, Croatia, the Czech Republic, Germany, Hungary, Poland, Slovakia, Slovenia and Switzerland tend to demonstrate high complexity. Industrialisation has reached Central Europe relatively early: Luxembourg and Germany by 1860, the Czech Republic, Poland, Slovakia and Switzerland by 1870, Austria, Croatia, Hungary, Liechtenstein, Romania, Serbia and Slovenia by 1880.

Central European countries are some of the most significant food producers in the world. Germany is the world's largest hops producer with 34.27% share in 2010, third producer of rye and barley, 5th rapeseed producer, sixth largest milk producer, and fifth largest potato producer. Poland is the world's largest triticale producer, second largest producer of raspberry, currant, third largest of rye, the fifth apple and buckwheat producer, and seventh largest producer of potatoes. The Czech Republic is world's fourth largest hops producer and 8th producer of triticale. Hungary is world's fifth hops and seventh largest triticale producer. Serbia is world's second largest producer of plums and second largest of raspberries. Slovenia is world's sixth hops producer.

Central European business has a regional organisation, Central European Business Association (CEBA), founded in 1996 in New York as a non-profit organization dedicated to promoting business opportunities within Central Europe and supporting the advancement of professionals in America with a Central European background.

Central European countries, especially Austria, Croatia, Germany and Switzerland are some of the most competitive tourism destinations. Poland is presently a major destination for outsourcing.

Kraków, Warsaw, and Wroclaw, Poland; Prague and Brno, Czech Republic; Budapest, Hungary; Bucharest, Romania; Bratislava, Slovakia; Ljubljana, Slovenia and Zagreb, Croatia are among the world's top 100 outsourcing destinations.

Central European countries are very literate. All of them have the literacy rate of 96% or over (for both sexes):
Languages taught as the first language in Central Europe are: Croatian, Czech, French, German, Hungarian, Italian, Polish, Romansh, Slovak and Slovenian. The most popular language taught at schools in Central Europe as foreign languages are: English, French and German.

Proficiency in English is ranked as high or moderate, according to the EF English Proficiency Index:

Other languages, also popular (spoken by over 5% as a second language):

Student performance has varied across Central Europe, according to the Programme for International Student Assessment. In the last study, countries scored medium, below or over the average scores in three fields studied.

In maths:


In the sciences:


In reading:


The first university east of France and north of the Alps was the Charles University in Prague established in 1347 or 1348 by Charles IV, Holy Roman Emperor and modeled on the University of Paris, with the full number of faculties (law, medicine, philosophy and theology). The list of Central Europe's oldest universities in continuous operation, established by 1500, include (by their dates of foundation):

The Central European University (CEU) is a graduate-level, English-language university promoting a distinctively Central European perspective. It was established in 1991 by the Hungarian philanthropist George Soros, who has provided an endowment of US$880 million, making the university one of the wealthiest in Europe. In the academic year 2013/2014, the CEU had 1,381 students from 93 countries and 388 faculty members from 58 countries.

Central European Exchange Program for University Studies (CEEPUS) is an international exchange program for students and teachers teaching or studying in participating countries. Its current members include (year it joined for the first time in brackets):

Research centres of Central European literature include Harvard (Cambridge, MA), Purdue University

Central European architecture has been shaped by major European styles including but not limited to: Brick Gothic, Rococo, Secession (art) and Modern architecture. Six Central European countries are amongst those countries with higher numbers of World Heritage Sites:

Central European countries are mostly Roman Catholic (Austria, Croatia, Czech Republic, Hungary, Liechtenstein, Luxembourg, Poland, Slovakia, Slovenia) or mixed Catholic and Protestant, (Germany and Switzerland). Large Protestant groups include Lutheran and Calvinist. Significant populations of Eastern Catholicism and Old Catholicism are also prevalent throughout Central Europe. Central Europe has been a centre of Protestantism in the past; however, it has been mostly eradicated by the Counterreformation. The Czech Republic (Bohemia) was historically the first Protestant country, then violently recatholised, and now overwhelmingly non-religious, nevertheless the largest number of religious people are Catholic (10.3%). Romania and Serbia are mostly Eastern Orthodox with significant Protestant and Catholic minorities.

Before the Holocaust (1941–45), there was also a sizeable Ashkenazi Jewish community in the region, numbering approximately 16.7 million people.

In some of these countries, there is a number of atheists, undeclared and non-religious people: the Czech Republic (non-religious 34.2% and undeclared 45.2%), Germany (non-religious 38%), Slovenia (atheist 30.2%), Luxembourg (25% non-religious), Switzerland (20.1%), Hungary (27.2% undeclared, 16.7% "non-religious" and 1.5% atheists), Slovakia (atheists and non-religious 13.4%, "not specified" 10.6%) Austria (19.7% of "other or none"), Liechtenstein (10.6% with no religion), Croatia (4%) and Poland (3% of non-believers/agnostics and 1% of undeclared).

Central European cuisine has evolved through centuries due to social and political change. Most countries share many dishes. The most popular dishes typical to Central Europe are sausages and cheeses, where the earliest evidence of cheesemaking in the archaeological record dates back to 5,500 BCE (Kujawy, Poland). Other foods widely associated with Central Europe are goulash and beer. List of countries by beer consumption per capita is led by the Czech Republic, followed by Germany and Austria. Poland comes 5th, Croatia 7th and Slovenia 13th.

Human rights have a long tradition in Central Europe. In 1222 Hungary defined for the first time the rights of the nobility in its "Golden Bull". In 1264 the Statute of Kalisz and the General Charter of Jewish Liberties introduced numerous rights for the Jews in Poland, granting them de facto autonomy. In 1783 for the first time, Poland forbid corporal punishment of children in schools. In the same year, a German state of Baden banned slavery.

On the other hand, there were also major regressions, such as "Nihil novi" in Poland in 1505 which forbade peasants from leaving their land without permission from their feudal lord.

Generally, the countries in the region are progressive on the issue of human rights: death penalty is illegal in all of them, corporal punishment is outlawed in most of them and people of both genders can vote in elections. Nevertheless, Central European countries struggle to adopt new generations of human rights, such as same-sex marriage. Austria, the Czech Republic, Germany, and Poland also have a history of participation in the CIA's extraordinary rendition and detention program, according to the Open Society Foundation.

Regional writing tradition revolves around the turbulent history of the region, as well as its cultural diversity. Its existence is sometimes challenged. Specific courses on Central European literature are taught at Stanford University, Harvard University and Jagiellonian University The as well as cultural magazines dedicated to regional literature. Angelus Central European Literature Award is an award worth 150,000.00 PLN (about $50,000 or £30,000) for writers originating from the region. Likewise, the Vilenica International Literary Prize is awarded to a Central European author for "outstanding achievements in the field of literature and essay writing."

There is a whole spectrum of media active in the region: newspapers, television and internet channels, radio channels, internet websites etc.
Central European media are regarded as free, according to the Press Freedom Index, although the situation in Poland, Hungary and Croatia is described as "problematic". Some of the top scoring countries are in Central Europe include:

There is a number of Central European Sport events and leagues. They include:

Football is one of the most popular sports. Countries of Central Europe had many great national teams throughout history and hosted several major competitions.
Yugoslavia hosted UEFA Euro 1976 before the competition expanded to 8 teams and Germany (at that times as West Germany) hosted UEFA Euro 1988. Recently, 2008 and 2012 UEFA European Championships were held in Austria & Switzerland and Poland & Ukraine respectively.
Germany hosted 2 FIFA World Cups (1974 and 2006) and are the current champions (as of 2014).

Central Europe is a birthplace of regional political organisations:

Central Europe is a home to some of world's oldest democracies. However, most of them have been impacted by totalitarian rule, particularly Nazism (Germany, Austria, other occupied countries) and Communism. Most of Central Europe have been occupied and later allied with the USSR, often against their will through forged referendum (e.g., Polish people's referendum in 1946) or force (northeast Germany, Poland, Hungary et alia). Nevertheless, these experiences have been dealt in most of them. Most of Central European countries score very highly in the Democracy Index:

In spite of its turbulent history, Central Europe is currently one of world's safest regions. Most Central European countries are in top 20%:

The time zone used in most parts of the European Union is a standard time which is 1 hour ahead of Coordinated Universal Time. It is commonly called Central European Time because it has been first adopted in central Europe (by year):

Central Europe is mentioned in 35th episode of Lovejoy, entitled "The Prague Sun", filmed in 1992. While walking over the famous Charles Bridge, the main character, Lovejoy says: " I've never been to Prague before. Well, it is one of the great unspoiled cities in Central Europe. Notice: I said: "Central", not "Eastern"! The Czechs are a bit funny about that, they think of Eastern Europeans as "turnip heads"."

Wes Anderson's Oscar-winning film The Grand Budapest Hotel is regarded as a fictionalised celebration of the 1930s in Central Europe and region's musical tastes





</doc>
<doc id="5192" url="https://en.wikipedia.org/wiki?curid=5192" title="Geography of Canada">
Geography of Canada

The geography of Canada describes the geographic features of Canada, the world's second largest country in total area.

Situated in northern North America (constituting 41% of the continent's area), Canada spans a vast, diverse territory between the North Pacific Ocean to the west and the North Atlantic Ocean to the east and the Arctic Ocean to the north (hence the country's motto "From sea to sea"), with the United States to the south (contiguous United States) and northwest (Alaska). Greenland is to the northeast; off the southern coast of Newfoundland lies Saint-Pierre and Miquelon, an overseas collectivity of France. Since 1925, Canada has claimed the portion of the Arctic between 60°W and 141°W longitude to the North Pole; however, this claim is contested. While the magnetic North Pole lies within the Canadian Arctic territorial claim as of 2011, recent measurements indicate it is moving towards Siberia.

Covering (land: ; freshwater: ), Canada is slightly less than three-fifths as large as Russia and slightly smaller than Europe. In total area, Canada is slightly larger than both the U.S. and China; however, Canada ranks fourth in land area (i.e. total area minus the area of lakes and rivers)—China is and the U.S. is .

The population of Canada, some 35,151,728 as of May 10, 2016, is concentrated in the south in proximity to its border with the contiguous U.S.; with a population density of 3.5 people per square kilometre (9.1/sq mi), it is one of the most sparsely populated countries in the world. The northernmost settlement in Canada—and in the world—is Canadian Forces Station (CFS) Alert (just north of Alert, Nunavut) on the northern tip of Ellesmere Island at 82°30′N 62°19′W, just from the North Pole.

Canada has a diverse climate. The climate varies from temperate on the west coast of British Columbia to a subarctic climate in the north. Extreme northern Canada can have snow for most of the year with a Polar climate. Landlocked areas tend to have a warm summer continental climate zone with the exception of Southwestern Ontario which has a hot summer humid continental climate. Parts of Western Canada have a semi-arid climate, and parts of Vancouver Island can even be classified as cool summer Mediterranean climate. Temperature extremes in Canada range from 45.0 °C (113 °F) in Midale and Yellow Grass, Saskatchewan on July 5, 1937 to −63.0 °C (−81.4 °F) in Snag, Yukon on Monday, February 3, 1947.

Canada covers 9,984,670 km (3,855,103 sq. miles) and a panoply of various geoclimatic regions. There are 8 main regions. Canada also encompasses vast maritime terrain, with the world's longest coastline of . The physical geography of Canada is widely varied. Boreal forests prevail throughout the country, ice is prominent in northerly Arctic regions and through the Rocky Mountains, and the relatively flat Canadian Prairies in the southwest facilitate productive agriculture. The Great Lakes feed the St. Lawrence River (in the southeast) where lowlands host much of Canada's population.

The Appalachian mountain range extends from Alabama through the Gaspé Peninsula and the Atlantic Provinces, creating rolling hills indented by river valleys. It also runs through parts of southern Quebec.

The Appalachian mountains (more specifically the Notre Dame and Long Range Mountains) are an old and eroded range of mountains, approximately 380 million years in age. Notable mountains in the Appalachians include Mount Jacques-Cartier (Quebec, and Mount Carleton (New Brunswick, ). Parts of the Appalachians are home to a rich endemic flora and fauna and are considered to have been nunataks during the last glaciation era.

The southern parts of Quebec and Ontario, in the section of the Great Lakes (bordered entirely by Ontario on the Canadian side) and St. Lawrence basin (often called St. Lawrence Lowlands), is another particularly rich sedimentary plain. Prior to its colonization and heavy urban sprawl of the 20th century, this Eastern Great Lakes lowland forests area was home to large mixed forests covering a mostly flat area of land between the Appalachian Mountains and the Canadian Shield. Most of this forest has been cut down through agriculture and logging operations, but the remaining forests are for the most part heavily protected. In this part of Canada the Gulf of St. Lawrence is one of the world's largest estuary (see Gulf of St. Lawrence lowland forests).

While the relief of these lowlands is particularly flat and regular, a group of batholites known as the Monteregian Hills are spread along a mostly regular line across the area. The most notable are Montreal's Mount Royal and Mont Saint-Hilaire. These hills are known for a great richness in precious minerals.

The northeastern part of Alberta, northern parts of Saskatchewan, Manitoba, Ontario, and Quebec, as well as most of Labrador (the mainland portions of the province of Newfoundland and Labrador), are located on a vast rock base known as the Canadian Shield. The Shield mostly consists of eroded hilly terrain and contains many lakes and important rivers used for hydroelectric production, particularly in northern Quebec and Ontario. The shield also encloses an area of wetlands, the Hudson Bay lowlands. Some particular regions of the Shield are referred to as mountain ranges, including the Torngat and Laurentian Mountains.

The Shield cannot support intensive agriculture, although there is subsistence agriculture and small dairy farms in many of the river valleys and around the abundant lakes, particularly in the southern regions. Boreal forest covers much of the shield, with a mix of conifers that provide valuable timber resources in areas such as the Central Canadian Shield forests ecoregion that covers much of Northern Ontario. The region is known for its extensive mineral reserves.

The Canadian Shield is known for its vast minerals, such as emeralds, diamonds and copper. The Canadian shield is also called the mineral house.

The Canadian Prairies are part of a vast sedimentary plain covering much of Alberta, southern Saskatchewan, and southwestern Manitoba, as well as much of the region between the Rocky Mountains and the Great Slave and Great Bear lakes in Northwest Territories. The plains generally describes the expanses of (largely flat) arable agricultural land which sustain extensive grain farming operations in the southern part of the provinces. Despite this, some areas such as the Cypress Hills and the Alberta Badlands are quite hilly and the prairie provinces contain large areas of forest such as the Mid-Continental Canadian forests. The size is roughly ~.

The Canadian Cordillera, contiguous with the American cordillera, is bounded by the Rocky Mountains to the east and the Pacific Ocean to the west.

The Canadian Rockies are part of a major continental divide that extends north and south through western North America and western South America. The Columbia and the Fraser Rivers have their headwaters in the Canadian Rockies and are the second and third largest rivers respectively to drain to the west coast of North America. To the west of their headwaters, across the Rocky Mountain Trench, is a second belt of mountains, the Columbia Mountains, comprising the Selkirk, Purcell, Monashee and Cariboo Mountains sub-ranges.

Immediately west of the Columbia Mountains is a large and rugged Interior Plateau, encompassing the Chilcotin and Cariboo regions in central British Columbia (the Fraser Plateau), the Nechako Plateau further north, and also the Thompson Plateau in the south. The Peace River Valley in northeastern British Columbia is Canada's most northerly agricultural region, although it is part of the Prairies. The dry, temperate climate of the Okanagan Valley in south central British Columbia provides ideal conditions for fruit growing and a flourishing wine industry; the semi-arid belt of the Southern Interior also includes the Fraser Canyon, and Thompson, Nicola, Similkameen, Shuswap and Boundary regions and fruit-growing is common in these areas also, and also in the West Kootenay. Between the plateau and the coast is the province's largest mountain range, the Coast Mountains. The Coast Mountains contain some of the largest temperate-latitude icefields in the world.

On the south coast of British Columbia, Vancouver Island is separated from the mainland by the continuous Juan de Fuca, Georgia, and Johnstone Straits. Those straits include a large number of islands, notably the Gulf Islands and Discovery Islands. North, near the Alaskan border, Haida Gwaii lies across Hecate Strait from the North Coast region and to its north, across Dixon Entrance from Southeast Alaska. Other than in the plateau regions of the Interior and its many river valleys, most of British Columbia is coniferous forest. The only temperate rain forests in Canada are found along the Pacific Coast in the Coast Mountains, on Vancouver Island, and on Haida Gwaii, and in the Cariboo Mountains on the eastern flank of the Plateau.

The Western Cordillera continues northwards past the Liard River in northernmost British Columbia to include the Mackenzie and Selwyn Ranges which lie in the far western Northwest Territories and the eastern Yukon Territory. West of them is the large Yukon Plateau and, west of that, the Yukon Ranges and Saint Elias Mountains, which include Canada's and British Columbia's highest summits, Mount Saint Elias in the Kluane region and Mount Fairweather in the Tatshenshini-Alsek region. The headwaters of the Yukon River, the largest and longest of the rivers on the Pacific Slope, lie in northern British Columbia at Atlin and Teslin Lakes.

Western Canada has many volcanoes and is part of the Pacific Ring of Fire, a system of volcanoes found around the margins of the Pacific Ocean. There are over 200 young volcanic centres that stretch northward from the Cascade Range to Yukon. They are grouped into five volcanic belts with different volcano types and tectonic settings. The Northern Cordilleran Volcanic Province was formed by faulting, cracking, rifting, and the interaction between the Pacific Plate and the North American Plate. The Garibaldi Volcanic Belt was formed by subduction of the Juan de Fuca Plate beneath the North American Plate. The Anahim Volcanic Belt was formed as a result of the North American Plate sliding westward over the Anahim hotspot. The Chilcotin Group is believed to have formed as a result of back-arc extension behind the Cascadia subduction zone. The Wrangell Volcanic Field formed as a result of subduction of the Pacific Plate beneath the North American Plate at the easternmost end of the Aleutian Trench.

Volcanism has also occurred in the Canadian Shield. It contains over 150 volcanic belts (now deformed and eroded down to nearly flat plains) that range from 600 million to 2.8 billion years old. Many of Canada's major ore deposits are associated with Precambrian volcanoes. There are pillow lavas in the Northwest Territories that are about 2.6 billion years old and are preserved in the Cameron River Volcanic Belt. The pillow lavas in rocks over 2 billion years old in the Canadian Shield signify that great oceanic volcanoes existed during the early stages of the formation of the Earth's crust. Ancient volcanoes play an important role in estimating Canada's mineral potential. Many of the volcanic belts bear ore deposits that are related to the volcanism.

While the largest part of the Canadian Arctic is composed of seemingly endless permafrost and tundra north of the tree line, it encompasses geological regions of varying types: the Arctic Cordillera (with the British Empire Range and the United States Range on Ellesmere Island) contains the northernmost mountain system in the world. The Arctic Lowlands and Hudson Bay lowlands comprise a substantial part of the geographic region often designated as the Canadian Shield (in contrast to the sole geologic area). The ground in the Arctic is mostly composed of permafrost, making construction difficult and often hazardous, and agriculture virtually impossible.

The Arctic, when defined as everything north of the tree line, covers most of Nunavut and the northernmost parts of Northwest Territories, Yukon, Manitoba, Ontario, Quebec, and Labrador.

Canada holds vast reserves of water: its rivers discharge nearly 9% of the world's renewable water supply, it contains a quarter of the world's wetlands, and it has the third largest amount of glaciers (after Antarctica and Greenland). Because of extensive glaciation, Canada hosts more than two million lakes: of those that are entirely within Canada, more than 31,000 are between in area, while 563 are larger than .

Canada’s two longest rivers are the Mackenzie, which empties into the Arctic Ocean and drains a large part of northwestern Canada, and the St. Lawrence, which drains the Great Lakes and empties into the Gulf of St. Lawrence. The Mackenzie is over in length while the St. Lawrence is over in length. Rounding out the ten longest rivers within Canada are the Nelson, Churchill, Peace, Fraser, North Saskatchewan, Ottawa, Athabasca and Yukon rivers.

The Atlantic watershed drains the entirety of the Atlantic provinces (parts of the Quebec-Labrador border are fixed at the Atlantic Ocean-Arctic Ocean continental divide), most of inhabited Quebec and large parts of southern Ontario. It is mostly drained by the economically important St. Lawrence River and its tributaries, notably the Saguenay, Manicouagan and Ottawa rivers. The Great Lakes and Lake Nipigon are also drained by the St. Lawrence. The Churchill River and Saint John River are other important elements of the Atlantic watershed in Canada.

The Hudson Bay watershed drains over a third of Canada. It covers Manitoba, northern Ontario and Quebec, most of Saskatchewan, southern Alberta, southwestern Nunavut and the southern half of Baffin Island. This basin is most important in fighting drought in the prairies and producing hydroelectricity, especially in Manitoba, northern Ontario and Quebec. Major elements of this watershed include Lake Winnipeg, Nelson River, the North Saskatchewan and South Saskatchewan Rivers, Assiniboine River, and Nettilling Lake on Baffin Island. Wollaston Lake lies on the boundary between the Hudson Bay and Arctic Ocean watersheds and drains into both. It is the largest lake in the world that naturally drains in two directions.

The continental divide in the Rockies separates the Pacific watershed in British Columbia and Yukon from the Arctic and Hudson Bay watersheds. This watershed irrigates the agriculturally important areas of inner British Columbia (such as the Okanagan and Kootenay valleys), and is used to produce hydroelectricity. Major elements are the Yukon, Columbia and Fraser rivers.

The northern parts of Alberta, Manitoba and British Columbia, most of Northwest Territories and Nunavut, and parts of Yukon are drained by the Arctic watershed. This watershed has been little used for hydroelectricity, with the exception of the Mackenzie River, the longest river in Canada. The Peace, Athabasca and Liard Rivers, as well as Great Bear Lake and Great Slave Lake (respectively the largest and second largest lakes wholly enclosed by Canada) are significant elements of the Arctic watershed. Each of these elements eventually merges with the Mackenzie, thereby draining the vast majority of the Arctic watershed.

The southernmost part of Alberta drains into the Gulf of Mexico through the Milk River and its tributaries. The Milk River originates in the Rocky Mountains of Montana, then flows into Alberta, then returns into the United States, where it is drained by the Missouri River. A small area of southwestern Saskatchewan is drained by Battle Creek, which empties into the Milk River.

Canada has produced a Biodiversity Action Plan in response to the 1992 international accord; the plan addresses conservation of endangered species and certain habitats. The main biomes of Canada are:


Canada is divided into ten provinces and three territories. According to Statistics Canada, 72.0 percent of the population is concentrated within of the nation's southern border with the United States, 70.0% live south of the 49th parallel, and over 60 percent of the population lives along the Great Lakes and St. Lawrence River between Windsor, Ontario and Quebec City. This leaves the vast majority of Canada's territory as sparsely populated wilderness; Canada's population density is 3.5 people/km (9.1/mi), among the lowest in the world. Despite this, 79.7 percent of Canada's population resides in urban areas, where population densities are increasing.

Canada shares with the U.S. the world's longest undefended border at ; are with Alaska. The Danish island dependency of Greenland lies to Canada's northeast, separated from the Canadian Arctic islands by Baffin Bay and Davis Strait. The French islands of Saint-Pierre and Miquelon lie off the southern coast of Newfoundland in the Gulf of St. Lawrence and have a maritime territorial enclave within Canada's exclusive economic zone. Canada also shares a land border with Denmark, as maps released in December 2006 show that the agreed upon boundaries run through the middle of Hans Island.

Canada's geographic proximity to the United States has historically bound the two countries together in the political world as well. Canada's position between the Soviet Union (now Russia) and the U.S. was strategically important during the Cold War since the route over the North Pole and Canada was the fastest route by air between the two countries and the most direct route for intercontinental ballistic missiles. Since the end of the Cold War, there has been growing speculation that Canada's Arctic maritime claims may become increasingly important if global warming melts the ice enough to open the Northwest Passage.

Similarly, the disputed—and tiny—Hans Island (with Denmark), in the Nares Strait between Ellesmere Island and northern Greenland, may be a flashpoint for challenges to overall claims of Canadian sovereignty in the Arctic.

Canada's abundance of natural resources is reflected in their continued importance in the economy of Canada. Major resource-based industries are fisheries, forestry, agriculture, petroleum products and mining.

The fisheries industry has historically been one of Canada's strongest. Unmatched cod stocks on the Grand Banks off Newfoundland launched this industry in the 16th century. Today these stocks are nearly depleted, and their conservation has become a preoccupation of the Atlantic Provinces. On the West Coast, tuna stocks are now restricted. The less depleted (but still greatly diminished) salmon population continues to drive a strong fisheries industry. Canada claims of territorial sea, a contiguous zone of , an exclusive economic zone of and a continental shelf of or to the edge of the continental margin.

Forestry has long been a major industry in Canada. Forest products contribute one fifth of the nation's exports. The provinces with the largest forestry industries are British Columbia, Ontario and Quebec. Fifty-four percent of Canada's land area is covered in forest. The boreal forests account for four-fifths of Canada's forestland.
Five per cent of Canada's land area is arable, none of which is for permanent crops. Three per cent of Canada's land area is covered by permanent pastures. Canada has 7,200 square kilometres (2,800 mi) of irrigated land (1993 estimate). Agricultural regions in Canada include the Canadian Prairies, the Lower Mainland and various regions within the Interior of British Columbia, the St. Lawrence Basin and the Canadian Maritimes. Main crops in Canada include flax, oats, wheat, maize, barley, sugar beets and rye in the prairies; flax and maize in Western Ontario; Oats and potatoes in the Maritimes. Fruit and vegetables are grown primarily in the Annapolis Valley of Nova Scotia, Southwestern Ontario, the Golden Horseshoe region of Ontario, along the south coast of Georgian Bay and in the Okanagan Valley of British Columbia. Cattle and sheep are raised in the valleys and plateaus of British Columbia. Cattle, sheep and hogs are raised on the prairies, cattle and hogs in Western Ontario, sheep and hogs in Quebec, and sheep in the Maritimes. There are significant dairy regions in central Nova Scotia, southern New Brunswick, the St. Lawrence Valley, northeastern Ontario, southwestern Ontario, the Red River valley of Manitoba and the valleys in the British Columbia Interior, on Vancouver Island and in the Lower Mainland.

Fossil fuels are a more recently developed resource in Canada, with oil and gas being extracted from deposits in the Western Canadian Sedimentary Basin since the mid 1900s. While Canada's crude oil deposits are fewer, technological developments in recent decades have opened up oil production in Alberta's Oil Sands to the point where Canada now has some of the largest reserves of oil in the world. In other forms, Canadian industry has a long history of extracting large coal and natural gas reserves.

Canada's mineral resources are diverse and extensive. Across the Canadian Shield and in the north there are large iron, nickel, zinc, copper, gold, lead, molybdenum, and uranium reserves. Large diamond concentrations have been recently developed in the Arctic, making Canada one of the world's largest producers. Throughout the Shield there are many mining towns extracting these minerals. The largest, and best known, is Sudbury, Ontario. Sudbury is an exception to the normal process of forming minerals in the Shield since there is significant evidence that the Sudbury Basin is an ancient meteorite impact crater. The nearby, but less known Temagami Magnetic Anomaly has striking similarities to the Sudbury Basin. Its magnetic anomalies are very similar to the Sudbury Basin, and so it could be a second metal-rich impact crater. The Shield is also covered by vast boreal forests that support an important logging industry.

Canada's many rivers have afforded extensive development of hydroelectric power. Extensively developed in British Columbia, Ontario, Quebec and Labrador, the many dams have long provided a clean, dependable source of energy.

Continuous permafrost in the north is a serious obstacle to development. Cyclonic storms form east of the Rocky Mountains, a result of the mixing of air masses from the Arctic, Pacific, and North American interior, and produce most of the country's rain and snow east of the mountains.

Air pollution and resulting acid rain severely affects lakes and damages forests. Metal smelting, coal-burning utilities, and vehicle emissions impact agricultural and forest productivity. And ocean waters are becoming contaminated from agricultural, industrial, mining, and forestry activities.

Global climate change and the warming of the polar region will likely cause significant changes to the environment, including loss of the polar bear, the exploration for resource then the extraction of these resources and an alternative transport route to the Panama Canal through the Northwest Passage.

The northernmost point within the boundaries of Canada is Cape Columbia, Ellesmere Island, Nunavut . The northernmost point of the Canadian mainland is Zenith Point on Boothia Peninsula, Nunavut .

The southernmost point is Middle Island, in Lake Erie, Ontario (41°41′N, 82°40′W); the southernmost water point lies just south of the island, on the Ontario–Ohio border (41°40′35″N). The southernmost point of the Canadian mainland is Point Pelee, Ontario .

The westernmost point is Boundary Peak 187 (60°18′22.929″N, 141°00′7.128″W) at the southern end of the Yukon–Alaska border which is roughly following 141°W but leans very slightly east as it goes North .

The easternmost point is Cape Spear, Newfoundland (47°31′N, 52°37′W) . The easternmost point of the Canadian mainland is Elijah Point, Cape St. Charles, Labrador (52°13′N, 55°37′W) .

The lowest point is sea level at 0 m, whilst the highest point is Mount Logan, Yukon, at 5,959 m / 19,550 ft .

The Canadian pole of inaccessibility is allegedly near Jackfish River, Alberta (Latitude: 59°2′ 60 N, Longitude: 112°49′ 60 W).

The furthest straight-line distance that can be travelled to Canadian points of land is between the northwest tip of Ivvavik National Park (at Clarence Lagoon) and Cripple Cove, NL (near Cape Race) at a distance of .




</doc>
<doc id="5193" url="https://en.wikipedia.org/wiki?curid=5193" title="Demographics of Canada">
Demographics of Canada

This article is about the demographic features of the population of Canada, including population density, ethnicity, religious affiliations and other aspects of the population, the People of Canada.

The Canada 2016 Census had a total population count of 35,151,728 individuals, making up approximately 0.5% of the world's total population.

According to Organisation for Economic Co-operation and Development (OECD)/World Bank, the population in Canada increased from 1990 to 2008 with 5.6 million and 20.4% growth in population, compared to 21.7% growth in the United States and 31.2% growth in Mexico. According to the OECD/World Bank population statistics, for the same period the world population growth was 27%, a total of 1,423 million people. However, over the same period, the population of France grew by 8.0%. And from 1991 to 2011, the population of the UK increased by 10.0%.


Age characteristics:
Net migration rate: 5.65 migrant(s)/1,000 population (2013 est.)

Urbanization:
Sex ratio:

Maternal mortality rate: 7 deaths/100,000 live births (2015. World Health Organization)

Life expectancy:


Median age by province and territory, 2011

Total: 40.6

As data is completely self-reported, and reporting individuals may have varying definitions of "Ethnic origin" (or may not know their ethnic origin), these figures should not be considered an exact record of the relative prevalence of different ethno-cultural ancestries but rather how Canadians self-identify.

Statistics Canada projects that, by 2031, about 28% of the population will be foreign-born. The number of people belonging to visible minority groups will double, the majority of which will live in Toronto and Vancouver.

Counting both single and multiple responses, the most commonly identified ethnic origins were (2016):
The most common ethnic origins per province are as follows in 2006 (total responses; only percentages 10% or higher shown; ordered by percentage of "Canadian"):

Bold indicates either that this response is dominant within this province, or that this province has the highest ratio (percentage) of this response among provinces.

Statistics Canada identifies visible minorities in accordance with the "Employment Equity Act". Statistics Canada states the ""Employment Equity Act" defines visible minorities as 'persons, other than Aboriginal peoples, who are non-Caucasian in race or non-white in colour.'"

All statistics are from the Canada 2011 Census.

"Note: Inuit, other Aboriginal and mixed Aboriginal groups are not listed as their own, but they are all accounted for in total Aboriginal"

All statistics are from the Canada 2011 Census.

Language used most often at work:

Languages by language used most often at home:

Languages by mother tongue:

Statistics Canada (StatCan) grouped responses to the 2011 National Household Survey (NHS) question on religion into nine core religious categories – Buddhist, Christian, Hindu, Jewish, Muslim, Sikh, Traditional (Aboriginal) Spirituality, other religions and no religious affiliation. Among these, of Canadians were self-identified as Christians in 2011. The second and third-largest categories were of Canadians with no religious affiliation at and Canadian Muslims at .

Within the 2011 NHS results, StatCan further subcategorized Christianity in nine groups of its own – Anglican, Baptist, Catholic, Christian Orthodox, Lutheran, Pentecostal, Presbyterian, United Church and Other Christian. Among these, of Canadians were self-identified as Catholic in 2011. The second and third-largest ungrouped subcategories of Christian Canadians were United at and Anglican at , while of Christians were grouped into the Other Christian subcategory comprising numerous denominations.

Of the 3,036,785 or of Canadians identified as Other Christians:




</doc>
<doc id="5194" url="https://en.wikipedia.org/wiki?curid=5194" title="Politics of Canada">
Politics of Canada

The politics of Canada function within a framework of parliamentary democracy and a federal system of parliamentary government with strong democratic traditions. Canada is a constitutional monarchy, in which the Monarch is head of state. The country has a multi-party system in which many of its legislative practices derive from the unwritten conventions of and precedents set by the Westminster Parliament of the United Kingdom. However, Canada has evolved variations: party discipline in Canada is stronger than in the United Kingdom and more parliamentary votes are considered motions of confidence, which tends to diminish the role of non-Cabinet Members of Parliament, (MPs). Such members, in the government caucus, and junior or lower-profile members of opposition caucuses, are known as backbenchers. Backbenchers can, however, exert their influence by sitting in parliamentary committees, like the Public Accounts Committee or the National-Defence Committee.

The two dominant political parties in Canada have historically been the Liberal Party of Canada and Conservative Party of Canada (or its predecessors), however, the social democratic New Democratic Party (NDP) has risen to prominence, and even threatened to upset the two other established parties during the 2011 federal election and the 2015 federal election. Smaller parties like the Quebec nationalist Bloc Québécois, and the Green Party of Canada have also been able to exert their own influence over the political process. Far-right and Far-left politics has never been a prominent force in Canadian society.

The Economist Intelligence Unit has rated Canada as "full democracy" in 2016.

Canada's governmental structure was originally established by the British Parliament through the British North America Act (now known as the Constitution Act, 1867), but the federal model and division of powers were devised by Canadian politicians. Particularly after World War I, citizens of the self-governing Dominions, such as Canada, began to develop a strong sense of identity, and, in the Balfour Declaration of 1926, the British government expressed its intent to grant full autonomy to these regions.

Thus in 1931, the British Parliament passed the Statute of Westminster, giving legal recognition to the autonomy of Canada and other Dominions. Following this, Canadian politicians were unable to obtain consensus on a process for amending the constitution until 1982, meaning amendments to Canada's constitution continued to require the approval of the British parliament until that date. Similarly, the Judicial Committee of the Privy Council in Britain continued to make the final decision on criminal appeals until 1933 and on civil appeals until 1949.












The bicameral Parliament of Canada consists of three parts: the monarch, the Senate, and the House of Commons.

Currently, the Senate, which is frequently described as providing "regional" representation, has 105 members appointed by the Governor General on the advice of the Prime Minister to serve until age 75. It was created with equal representation from each of Ontario, Quebec, the Maritime region and the Western Provinces. However, it is currently the product of various specific exceptions, additions and compromises, meaning that regional equality is not observed, nor is representation-by-population. The normal number of senators can be exceeded by the monarch on the advice of the Prime Minister, as long as the additional senators are distributed equally with regard to region (up to a total of eight additional Senators). This power of additional appointment has only been used once, when Prime Minister Brian Mulroney petitioned Queen Elizabeth II to add eight seats to the Senate so as to ensure the passage of the Goods and Services Tax legislation.

The House of Commons currently has 338 members elected in single-member districts in a plurality voting system (first past the post), meaning that members must attain only a plurality (the most votes of any candidate) rather than a majority (50 percent plus one). The electoral districts are also known as ridings.

Mandates cannot exceed five years; an election must occur by the end of this time. This fixed mandate has been exceeded only once, when Prime Minister Robert Borden perceived the need to do so during World War I. The size of the House and apportionment of seats to each province is revised after every census, conducted every five years, and is based on population changes and approximately on representation-by-population.

Canadians vote for their local Member of Parliament (MP) only. An MP need not be a member of any political party: such MPs are known as independents. When a number of MPs share political opinions they may form a body known as a political party.

The Canada Elections Act defines a political party as "an organization one of whose fundamental purposes is to participate in public affairs by endorsing one or more of its members as candidates and supporting their election." Forming and registering a federal political party are two different things. There is no legislation regulating the formation of federal political parties. Elections Canada cannot dictate how a federal political party should be formed or how its legal, internal and financial structures should be established.

Parties elect their leaders in run-off elections to ensure that the winner receives more than 50% of the votes. Normally the party leader stands as a candidate to be an MP during an election. Canada's parliamentary system empowers political parties and their party leaders. Where one party gets a majority of the seats in the House of Commons, that party is said to have a "majority government." Through party discipline, the party leader, who is elected in only one riding, exercises a great deal of control over the cabinet and the parliament.

Historically the prime minister and senators are selected by the governor general as a representative of the Queen, though in modern practice the monarch's duties are ceremonial. Consequently, the prime minister while technically selected by the governor general is for all practical purposes selected by the party with the majority of seats. That is, the party that gets the most seats normally forms the government, with that party's leader becoming prime minister. The prime minister is not directly elected by the general population, although the prime minister is almost always directly elected as an MP within his or her constituency. Again senators while technically selected at the pleasure of the monarch, are ceremonially selected by the governor general at the advice (and for most practical purposes authority) of the prime minister.

A minority government situation occurs when the party that holds the most seats in the House of Commons holds fewer seats than the opposition parties combined. In this scenario usually the party leader whose party has the most seats in the House is selected by the governor general to lead the government, however, to create stability, the leader chosen must have the support of the majority of the House, meaning they need the support of at least one other party.

In Canada, the provinces are considered co-sovereign; sovereignty of the provinces is passed on, not by the Governor General or the Canadian parliament, but through the Crown itself. This means that the Crown is "divided" into 11 legal jurisdictions; into 11 "Crowns" – one federal and ten provincial.

Federal-provincial (or intergovernmental, formerly Dominion-provincial) relations is a regular issue in Canadian politics: Quebec wishes to preserve and strengthen its distinctive nature, western provinces desire more control over their abundant natural resources, especially energy reserves; industrialized Central Canada is concerned with its manufacturing base, and the Atlantic provinces strive to escape from being less affluent than the rest of the country.

In order to ensure that social programs such as health care and education are funded consistently throughout Canada, the "have-not" (poorer) provinces receive a proportionately greater share of federal "transfer (equalization) payments" than the richer, or "have", provinces do; this has been somewhat controversial. The richer provinces often favour freezing transfer payments, or rebalancing the system in their favour, based on the claim that they already pay more in taxes than they receive in federal government services, and the poorer provinces often favour an increase on the basis that the amount of money they receive is not sufficient for their existing needs.

Particularly in the past decade, some scholars have argued that the federal government's exercise of its unlimited constitutional spending power has contributed to strained federal-provincial relations. This power, which allows the federal government to spend the revenue it raises in any way that it pleases, allows it to overstep the constitutional division of powers by creating programs that encroach on areas of provincial jurisdiction. The federal spending power is not expressly set out in the Constitution Act, 1867; however, in the words of the Court of Appeal for Ontario the power "can be inferred" from s. 91(1A), "the public debt and property".

A prime example of an exercise of the spending power is the Canada Health Act, which is a conditional grant of money to the provinces. Regulation of health services is, under the Constitution, a provincial responsibility. However, by making the funding available to the provinces under the Canada Health Act contingent upon delivery of services according to federal standards, the federal government has the ability to influence health care delivery. This spending power, coupled with Supreme Court rulings – such as Reference re Canada Assistance Plan (B.C.) – that have held that funding delivered under the spending power can be reduced unilaterally at any time, has contributed to strained federal-provincial relations.

Except for three short-lived transitional or minority governments, prime ministers from Quebec led Canada continuously from 1968 to early 2006. Québécois led both Liberal and Progressive Conservative governments in this period.

Monarchs, governors general, and prime ministers are now expected to be at least functional, if not fluent, in both English and French. In selecting leaders, political parties give preference to candidates who are fluently bilingual.

Also, by law, three of the nine positions on the Supreme Court of Canada must be held by judges from Quebec. This representation makes sure that at least three judges have sufficient experience with the civil law system to treat cases involving Quebec laws.

Canada has a long and storied history of secessionist movements (see Secessionist movements of Canada). National unity has been a major issue in Canada since the forced union of Upper and Lower Canada in 1840.

The predominant and lingering issue concerning Canadian national unity has been the ongoing conflict between the French-speaking majority in Quebec and the English-speaking majority in the rest of Canada. Quebec's continued demands for recognition of its "distinct society" through special political status has led to attempts for constitutional reform, most notably with the failed attempts to amend the constitution through the Meech Lake Accord and the Charlottetown Accord (the latter of which was rejected through a national referendum).

Since the Quiet Revolution, sovereigntist sentiments in Quebec have been variably stoked by the patriation of the Canadian constitution in 1982 (without Quebec's consent) and by the failed attempts at constitutional reform. Two provincial referenda, in 1980 and 1995, rejected proposals for sovereignty with majorities of 60% and 50.6% respectively. Given the narrow federalist victory in 1995, a reference was made by the Chrétien government to the Supreme Court of Canada in 1998 regarding the legality of unilateral provincial secession. The court decided that a unilateral declaration of secession would be unconstitutional. This resulted in the passage of the Clarity Act in 2000.

The Bloc Québécois, a sovereigntist party which runs candidates exclusively in Quebec, was started by a group of MPs who left the Progressive Conservative (PC) party (along with several disaffected Liberal MPs), and first put forward candidates in the 1993 federal election. With the collapse of the PCs in that election, the Bloc and Liberals were seen as the only two viable parties in Quebec. Thus, prior to the 2006 election, any gain by one party came at the expense of the other, regardless of whether national unity was really at issue. The Bloc, then, benefited (with a significant increase in seat total) from the impressions of corruption that surrounded the Liberal Party in the leadup to the 2004 election. However, the newly unified Conservative party re-emerged as a viable party in Quebec by winning 10 seats in the 2006 election. In the 2011 election, the New Democratic Party succeeded in winning 59 of Quebec's 75 seats, successfully reducing the number of seats of every other party substantially. The NDP surge nearly destroyed the Bloc, reducing them to 4 seats, far below the minimum requirement of 12 seats for Official party status.

Newfoundland and Labrador is also a problem regarding national unity. As the Dominion of Newfoundland was a self-governing country equal to Canada until 1949, there are large, though uncoordinated, feelings of Newfoundland nationalism and anti-Canadian sentiment among much of the population. This is due in part to the perception of chronic federal mismanagement of the fisheries, forced resettlement away from isolated settlements in the 1960s, the government of Quebec still drawing inaccurate political maps whereby they take parts of Labrador, and to the perception that mainland Canadians look down upon Newfoundlanders. In 2004, the Newfoundland and Labrador First Party contested provincial elections and in 2008 in federal ridings within the province. In 2004, then-premier Danny Williams ordered all federal flags removed from government buildings as a result of lost offshore revenues to equalization clawbacks. On December 23, 2004, premier Williams made this statement to reporters in St. John's, 

Western alienation is another national-unity-related concept that enters into Canadian politics. Residents of the four western provinces, particularly Alberta, have often been unhappy with a lack of influence and a perceived lack of understanding when residents of Central Canada consider "national" issues. While this is seen to play itself out through many avenues (media, commerce, and so on.), in politics, it has given rise to a number of political parties whose base constituency is in western Canada. These include the United Farmers of Alberta, who first won federal seats in 1917, the Progressives (1921), the Social Credit Party (1935), the Co-operative Commonwealth Federation (1935), the Reconstruction Party (1935), New Democracy (1940) and most recently the Reform Party (1989).

The Reform Party's slogan "The West Wants In" was echoed by commentators when, after a successful merger with the PCs, the successor party to both parties, the Conservative Party won the 2006 election. Led by Stephen Harper, who is an MP from Alberta, the electoral victory was said to have made "The West IS In" a reality. However, regardless of specific electoral successes or failures, the concept of western alienation continues to be important in Canadian politics, particularly on a provincial level, where opposing the federal government is a common tactic for provincial politicians. For example, in 2001, a group of prominent Albertans produced the Alberta Agenda, urging Alberta to take steps to make full use of its constitutional powers, much as Quebec has done.

Canada is considered by most sources to be a very stable democracy. In 2006, "The Economist" ranked Canada the third-most democratic nation in its Democracy Index, ahead of all other nations in the Americas and ahead of every nation more populous than itself. In 2008, Canada was ranked World No. 11 and again ahead of all countries more populous and No. 1 for the Americas. (In 2008, the United States was ranked World No. 18, Uruguay World No. 23, and Costa Rica World No. 27.)

The Liberal Party of Canada, under the leadership of Paul Martin, won a minority victory in the June 2004 general elections. In December 2003, Martin had succeeded fellow Liberal Jean Chrétien, who had, in 2000, become the first prime minister to lead three consecutive majority governments since 1945. However, in 2004 the Liberals lost seats in Parliament, going from 172 of 301 parliamentary seats to 135 of 308, and from 40.9% to 36.7% in the popular vote. The Canadian Alliance, which did well in western Canada in the 2000 election but was unable to make significant inroads in the East, merged with the Progressive Conservative Party to form the Conservative Party of Canada in late 2003.

They proved to be moderately successful in the 2004 campaign, gaining seats from a combined Alliance-PC total of 78 in 2000 to 99 in 2004. However, the new Conservatives lost in popular vote, going from 37.7% in 2000 down to 29.6%. In 2006, the Conservatives, led by Stephen Harper, won a minority government with 124 seats. They improved their percentage from 2004, garnering 36.3% of the vote. During this election, the Conservatives also made major breakthroughs in Quebec. They gained 10 seats here, whereas in 2004 they had no seats.

At the 2011 federal election, the Conservatives won a majority government with 167 seats. For the first time, the NDP became the Official Opposition, with 102 seats; the Liberals finished in third place with 34 seats. This was the first election in which the Green Party won a seat, that of leader Elizabeth May; the Bloc won 4 seats, losing official party status.

The Liberal Party, after dominating Canadian politics since the 1920s, was in decline in early years of the 21st century. As Lang (2010) concluded, they lost their majority in Parliament in the 2004 election, were defeated in 2006, and in 2008 became little more than a "rump", falling to their lowest seat count in decades and a mere 26% of the popular vote. Furthermore, said Lang (a Liberal himself), its prospects "are as bleak as they have ever been." In the 2011 election, the Liberals suffered a crushing defeat, managing to secure only 18.9% of the vote share and only 34 seats. As a result, the Liberals lost their status as official opposition to the NDP.

In explaining those trends, Behiels (2010) synthesized major studies and reported that "a great many journalists, political advisors, and politicians argue that a new political party paradigm is emerging" She claimed they saw a new power configuration based on a right-wing political party capable of sharply changing the traditional role of the state (federal and provincial) in the twenty-first-century. Behiels said that unlike Brian Mulroney, who tried but failed to challenge the long-term dominance of the Liberals, Harper's attempt had proven to be more determined, systematic and successful.

Many commentators thought it signalled a major realignment. The "Economist" said, "the election represents the biggest realignment of Canadian politics since 1993." Lawrence Martin, commentator for the "Globe and Mail" said, "Harper has completed a remarkable reconstruction of a Canadian political landscape that endured for more than a century. The realignment saw both old parties of the moderate middle, the Progressive Conservatives and the Liberals, either eliminated or marginalized." "Maclean's" said, the election marked "an unprecedented realignment of Canadian politics" as "the Conservatives are now in a position to replace the Liberals as the natural governing party in Canada."

Despite the grim outlook and poor early poll numbers, when the 2015 election was held, the Liberals under Justin Trudeau had an unprecedented comeback and the realignment was proved only temporary. Gaining 148 seats, they won a majority government for the first time since 2000. The "Toronto Star" claimed the comeback was "headed straight for the history books" and that Harper's name would "forever be joined with that of his Liberal nemesis in Canada’s electoral annals". Spencer McKay for the "National Post" suggested that "maybe we’ve witnessed a revival of Canada’s 'natural governing party'".

Funding changes were made to ensure greater reliance on personal contributions. Personal donations to federal parties and campaigns benefit from tax credits, although the amount of tax relief depends on the amount given. Also only people paying income taxes receive any benefit from this.

A good part of the reasoning behind the change in funding was that union or business funding should not be allowed to have as much impact on federal election funding as these are not contributions from citizens and are not evenly spread out between parties. They are still allowed to contribute to the election but only in a minor fashion. The new rules stated that a party had to receive 2% of the vote nationwide in order to receive the general federal funding for parties. Each vote garnered a certain dollar amount for a party (approximately $1.75) in future funding. For the initial disbursement, approximations were made based on previous elections. The NDP received more votes than expected (its national share of the vote went up) while the new Conservative Party of Canada received fewer votes than had been estimated and was asked to refund the difference. Quebec was the first province to implement a similar system of funding many years before the changes to funding of federal parties.

Federal funds are disbursed quarterly to parties, beginning at the start of 2005. For the moment, this disbursement delay leaves the NDP and the Green Party in a better position to fight an election, since they rely more on individual contributors than federal funds. The Green Party now receives federal funds, since it for the first time received a sufficient share of the vote in the 2004 election.

In 2007, news emerged of a funding loophole that "could cumulatively exceed the legal limit by more than $60,000," through anonymous recurrent donations of $200 to every riding of a party from corporations or unions. At the time, for each individual, the legal annual donation limit was $1,100 for each party, $1,100 combined total for each party's associations, and in an election year, an additional $1,100 combined total for each party's candidates. All three limits increase on 1 April every year based on the inflation rate.



Leaders debates in Canada consist of two debates, one English and one French, both produced by a consortium of Canada's five major television broadcasters (CBC/SRC, CTV, Global and TVA) and usually consist of the leaders of all parties with representation in the House of Commons.

These debates air on the networks of the producing consortium as well as the public affairs and parliamentary channel CPAC and the American public affairs network C-SPAN.

The highest court in Canada is the Supreme Court of Canada and is the final court of appeal in the Canadian justice system. The court is composed of nine judges: eight Puisne Justices and the Chief Justice of Canada. Justices of the Supreme Court of Canada are appointed by the Governor-in-Council. The Supreme Court Act limits eligibility for appointment to persons who have been judges of a superior court, or members of the bar for ten or more years. Members of the bar or superior judge of Quebec, by law, must hold three of the nine positions on the Supreme Court of Canada.

The Canadian government operates the public service using departments, smaller agencies (for example, commissions, tribunals, and boards), and crown corporations. There are two types of departments: central agencies such as Finance, Privy Council Office, and Treasury Board Secretariat have an organizing and oversight role for the entire public service; line departments are departments which perform tasks in a specific area or field, such as the departments of Agriculture, Environment, or Defence.

Scholar Peter Aucoin, writing about the Canadian Westminster system, has raised concerns in the early 2000s about the centralization of power; an increased number, role and influence of partisan-political staff; personal-politicization of appointments to the senior public service; and, the assumption that the public service is promiscuously partisan for the government of the day.

In 1967, Canada established a point-based system to determine if immigrants should be eligible to enter the country, using meritorious qualities such as the applicant's ability to speak both French and English, their level of education, and other details that may be expected of a natural-born Canadian. This system was considered ground-breaking at the time since prior systems were slanted on the basis of ethnicity. However, many foreign nationals still found it challenging to secure work after emigrating, resulting in a higher unemployment rate amongst the immigrant population. After winning power at the 2006 federal election, the Conservative Party has sought to curb this issue by placing weight on whether or not the applicant has a standing job offer in Canada. The change has been a source of some contention as opponents argue that businesses use this change to suppress wages, with corporate owners leveraging the knowledge that an immigrant should hold a job to successfully complete the immigration process.



</doc>
<doc id="5195" url="https://en.wikipedia.org/wiki?curid=5195" title="Economy of Canada">
Economy of Canada

The economy of Canada is a highly developed mixed economy with 10th largest GDP by nominal and 17th largest GDP by PPP in the world. As with other developed nations, the country's economy is dominated by the service industry, which employs about three quarters of Canadians. Canada has the fourth highest total estimated value of natural resources, valued at US$33.2 trillion in 2016. It has the world's third largest proven petroleum reserves and is the fourth largest exporter of petroleum. It is also the fourth largest exporter of natural gas. Canada is considered an "energy superpower" due to its abundant natural resources.

Canada is unusual among developed countries in the importance of the primary sector, with the logging and oil industries being two of Canada's most important. Canada also has a sizable manufacturing sector, based in Central Canada, with the automobile industry and aircraft industry being especially important. With the world's longest coastline, Canada has the 8th largest commercial fishing and seafood industry in the world. Canada is one of the global leaders of the entertainment software industry. It is a member of the APEC, NAFTA, G7, G20, OECD and WTO.

With the exception of a few island nations in the Caribbean, Canada is the only major parliamentary democracy in the western hemisphere. As a result, Canada has developed its own social and political institutions, distinct from most other countries in the world. Though the Canadian economy is closely integrated with the American economy, it has developed unique economic institutions.

The Canadian economic system generally combines elements of private enterprise and public enterprise. Many aspects of public enterprise, most notably the development of an extensive social welfare system to redress social and economic inequities, were adopted after the end of World War Two in 1945.

Canada has a private to public (Crown) property ratio of 60:40 and one of the highest levels of economic freedom in the world. Today Canada closely resembles the U.S. in its market-oriented economic system and pattern of production. As of 2017, Canada has 58 companies in the Forbes Global 2000 list, ranking seventh behind France and ahead of India.

International trade makes up a large part of the Canadian economy, particularly of its natural resources. In 2009, agriculture, energy, forestry and mining exports accounted for about 58% of Canada's total exports. Machinery, equipment, automotive products and other manufactures accounted for a further 38% of exports in 2009. In 2009, exports accounted for about 30% of Canada's GDP. The United States is by far its largest trading partner, accounting for about 73% of exports and 63% of imports as of 2009. Canada's combined exports and imports ranked 8th among all nations in 2006.

About 4% of Canadians are directly employed in primary resource fields, and they account for 6.2% of GDP. They are still paramount in many parts of the country. Many, if not most, towns in northern Canada, where agriculture is difficult, exist because of a nearby mine or source of timber. Canada is a world leader in the production of many natural resources such as gold, nickel, uranium, diamonds, lead, and in recent years, crude petroleum, which, with the world's second-largest oil reserves, is taking an increasingly prominent position in natural resources extraction. Several of Canada's largest companies are based in natural resource industries, such as Encana, Cameco, Goldcorp, and Barrick Gold. The vast majority of these products are exported, mainly to the United States. There are also many secondary and service industries that are directly linked to primary ones. For instance one of Canada's largest manufacturing industries is the pulp and paper sector, which is directly linked to the logging business.

The reliance on natural resources has several effects on the Canadian economy and Canadian society. While manufacturing and service industries are easy to standardize, natural resources vary greatly by region. This ensures that differing economic structures developed in each region of Canada, contributing to Canada's strong regionalism. At the same time the vast majority of these resources are exported, integrating Canada closely into the international economy. Howlett and Ramesh argue that the inherent instability of such industries also contributes to greater government intervention in the economy, to reduce the social impact of market changes.

Natural resource industries also raise important questions of sustainability. Despite many decades as a leading producer, there is little risk of depletion. Large discoveries continue to be made, such as the massive nickel find at Voisey's Bay. Moreover, the far north remains largely undeveloped as producers await higher prices or new technologies as many operations in this region are not yet cost effective. In recent decades Canadians have become less willing to accept the environmental destruction associated with exploiting natural resources. High wages and Aboriginal land claims have also curbed expansion. Instead many Canadian companies have focused their exploration, exploitation and expansion activities overseas where prices are lower and governments more amenable. Canadian companies are increasingly playing important roles in Latin America, Southeast Asia, and Africa.

The depletion of renewable resources has raised concerns in recent years. After decades of escalating overutilization the cod fishery all but collapsed in the 1990s, and the Pacific salmon industry also suffered greatly. The logging industry, after many years of activism, has in recent years moved to a more sustainable model, or to other countries.

Productivity measures are key indicators of economic performance and a key source of economic growth and competitiveness. The Organisation for Economic Co-operation and Development (OECD)'s "Compendium of Productivity Indicators", published annually, presents a broad overview of productivity levels and growth in member nations, highlighting key measurement issues. It analyses the role of "productivity as the main driver of economic growth and convergence" and the "contributions of labour, capital and MFP in driving economic growth". According to the definition above "MFP is often interpreted as the contribution to economic growth made by factors such as technical and organisational innovation" (OECD 2008,11). Measures of productivity include Gross Domestic Product (GDP)(OECD 2008,11) and multifactor productivity.

The OECD provides data for example comparing labour productivity levels in the total economy of each member nation. In their 2012 report Canada's Gross Domestic Product (GDP) was $CDN 1,773,763,000,000.

In the International Monetary Fund's (IMF) quarterly World Economic Outlook released in April 2015, the IMF forecast that Canada's real gross domestic product (GDP) would grow 2.2 percent. In the July World Economic Outlook the IMF forecast that Canada's real GDP would grow by 1.5 per cent in 2015.

According to CTV News real estate accounts for half of all GDP growth.

Another productivity measure, used by the OECD, is the long-term trend in multifactor productivity (MFP) also known as total factor productivity (TFP). This indicator assesses an economy's "underlying productive capacity ('potential output'), itself an important measure of the growth possibilities of economies and of inflationary pressures". MFP measures the residual growth that cannot be explained by the rate of change in the services of labour, capital and intermediate outputs, and is often interpreted as the contribution to economic growth made by factors such as technical and organisational innovation. (OECD 2008,11)

According to the OECD's annual economic survey of Canada in June 2012, Canada has experienced weak growth of multi-factor productivity (MFP) and has been declining further since 2002. One of the ways MFP growth is raised is by boosting innovation and Canada's innovation indicators such as business R&D and patenting rates were poor. Raising MFP growth is "needed to sustain rising living standards, especially as the population ages".

The Bank of Canada, a federal crown corporation, has the responsibility of Canada's monetary system. During the period that John Crow was Governor of the Bank of Canada—1987 to 1994— there was a worldwide recession and the bank rate rose to around 14% and unemployment topped 11%. In 1991, with Prime Minister Brian Mulroney in office, the federal government and the Bank of Canada announced a new inflation-targeting monetary policy that has been the cornerstone of Canada's monetary and fiscal policy ever since. Although since that time inflation-targeting has been adopted by "most advanced-world central banks", in 1991 it was innovative and Canada was an early adopter when the then-Finance Minister Michael Wilson approved the Bank of Canada's first inflation-targeting in the 1991 federal budget. The inflation target was set at 2 per cent, which is the midpoint of an inflation range of 1 to 3 per cent. They established a set of inflation-reduction targets to keep inflation "low, stable and predictable" and to foster "confidence in the value of money", contribute to Canada's sustained growth, employment gains and improved standard of living. Inflation is measured by the total consumer price index (CPI). In 2011 the Government of Canada and the Bank of Canada extended Canada's inflation-control target to December 31, 2016. The Bank of Canada uses three unconventional instruments to achieve the inflation target: "a conditional statement on the future path of the policy rate", quantitative easing, and credit easing.

As a result, interest rates and inflation eventually came down along with the value of the Canadian dollar. From 1991 to 2011 the inflation-targeting regime kept "price gains fairly reliable".

Following the Financial crisis of 2007–08 the narrow focus of inflation-targeting as a means of providing stable growth in the Canadian economy was questioned. By 2011, the then-Bank of Canada Governor Mark Carney argued that the central bank's mandate would allow for a more flexible inflation-targeting in specific situations where he would consider taking longer "than the typical six to eight quarters to return inflation to 2 per cent".

The central bank—the Bank of Canada—issues its rate announcement through its Monetary Policy Report which is released eight times a year. On July 15, 2015, the Bank of Canada announced that it was lowering its target for the overnight rate by another one-quarter percentage point, to 0.5 per cent "to try to stimulate an economy that appears to have failed to rebound meaningfully from the oil shock woes that dragged it into decline in the first quarter". According to the Bank of Canada announcement, in the first quarter of 2015, the total Consumer price index (CPI) inflation was about 1 per cent. This reflects "year-over-year price declines for consumer energy products". Core inflation in the first quarter of 2015 was about 2 per cent with an underlying trend in inflation at about 1.5 to 1.7 per cent.

In response to the Bank of Canada's July 15, 2015 rate adjustment, Prime Minister Stephen Harper explained that the economy was "being dragged down by forces beyond Canadian borders such as global oil prices, the European debt crisis, and China's economic slowdown" which has made the global economy "fragile".

The Chinese stock market had lost about US$3 trillion of wealth by July 2015 when panicked investors sold stocks, which created declines in the commodities markets, which in turn negatively impacted resource-producing countries like Canada.

The Bank's main priority has been to keep inflation at a moderate level. As part of that strategy, interest rates were kept at a low level for almost seven years. Since September 2010, the key interest rate (overnight rate) was 0.5%. In mid 2017, inflation remained below the Bank's 2% target, (at 1.6%) mostly because of reductions in the cost of energy, food and automobiles; as well, the economy was in a continuing spurt with a predicted GDP growth of 2.8 percent by year end. Early on 12 July 2017, the bank issued a statement that the benchmark rate would be increased to 0.75%. "The economy can handle very well this move we have today and of course you need to preface that with an acknowledgment that of course interest rates are still very low", Governor Stephen Poloz subsequently said. In its press release, the bank had confirmed that the rate would continue to be evaluated at least partly on the basis of inflation. "Future adjustments to the target for the overnight rate will be guided by incoming data as they inform the bank's inflation outlook, keeping in mind continued uncertainty and financial system vulnerabilities." Poloz refused to speculate on the future of the economy but said, "I don't doubt that interest rates will move higher, but there's no predetermined path in mind at this stage".

In 2016, the Canadian economy had the following relative weighting by industry, as percentage value of GDP:


The service sector in Canada is vast and multifaceted, employing about three quarters of Canadians and accounting for 70% of GDP. The largest employer is the retail sector, employing almost 12% of Canadians. The retail industry is mainly concentrated in a small number of chain stores clustered together in shopping malls. In recent years, there has been an increase in the number of big-box stores, such as Wal-Mart (of the United States), Real Canadian Superstore, and Best Buy (of the United States). This has led to fewer workers in this sector and a migration of retail jobs to the suburbs.

The second largest portion of the service sector is the business service and hire only a slightly smaller percentage of the population. This includes the financial services, real estate, and communications industries. This portion of the economy has been rapidly growing in recent years. It is largely concentrated in the major urban centres, especially Toronto, Montreal and Vancouver (see Banking in Canada).

The education and health sectors are two of Canada's largest, but both are largely under the influence of the government. The health care industry has been quickly growing, and is the third largest in Canada. Its rapid growth has led to problems for governments who must find money to fund it.

Canada has an important high tech industry, and a burgeoning film, television, and entertainment industry creating content for local and international consumption (see Media in Canada). Tourism is of ever increasing importance, with the vast majority of international visitors coming from the United States. Casino gaming is currently the fastest-growing component of the Canadian tourism industry, contributing $5 billion in profits for Canadian governments and employing 41,000 Canadians as of 2001.

The general pattern of development for wealthy nations was a transition from a primary industry based economy to a manufacturing based one, and then to a service based economy. Canada did not escape this pattern – at its (abnormally high World War II) peak in 1944, manufacturing accounted for 29% of GDP, declining to 15.6% in 2005. Canada has not suffered as greatly as most other rich, industrialized nations from the pains of the relative decline in the importance of manufacturing since the 1960s. A 2009 study by Statistics Canada also found that, while manufacturing declined as a relative percentage of GDP from 24.3% in the 1960s to 15.6% in 2005, manufacturing volumes between 1961 and 2005 kept pace with the overall growth in the volume index of GDP. Manufacturing in Canada was especially hit hard by the financial crisis of 2007–08. As of 2010, manufacturing accounts for 13% of Canada's GDP, a relative decline of more than 2% of GDP since 2005.

Central Canada is home to branch plants to all the major American and Japanese automobile makers and many parts factories owned by Canadian firms such as Magna International and Linamar Corporation.

Canada is one of the few developed nations that is a net exporter of energy—in 2009 net exports of energy products amounted to 2.9% of GDP. Most important are the large oil and gas resources centred in Alberta and the Northern Territories, but also present in neighbouring British Columbia and Saskatchewan. The vast Athabasca oil sands give Canada the world's third largest reserves of oil after Saudi Arabia and Venezuela according to USGS. In British Columbia and Quebec, as well as Ontario, Saskatchewan, Manitoba and the Labrador region, hydroelectric power is an inexpensive and relatively environmentally friendly source of abundant energy. In part because of this, Canada is also one of the world's highest per capita consumers of energy. Cheap energy has enabled the creation of several important industries, such as the large aluminum industries in British Columbia and Quebec.

Historically, an important issue in Canadian politics is the interplay between the oil and energy industry in Western Canada and the industrial heartland of Southern Ontario. Foreign investment in Western oil projects has fueled Canada's rising dollar. This has raised the price of Ontario's manufacturing exports and made them less competitive, a problem similar to the decline of the manufacturing sector in the Netherlands. Also, Ontario has relatively fewer native sources of power. However, it is cheaper for Alberta to ship its oil to the western United States than to eastern Canada. The eastern Canadian ports thus import significant quantities of oil from overseas, and Ontario makes significant use of nuclear power.

The National Energy Policy of the early 1980s attempted to force Alberta to sell low-priced oil to eastern Canada. This policy proved deeply divisive, and quickly lost its importance as oil prices collapsed in the mid-1980s. One of the most controversial sections of the Canada–United States Free Trade Agreement of 1988 was a promise that Canada would never charge the United States more for energy than fellow Canadians.

Canada is also one of the world's largest suppliers of agricultural products, particularly of wheat and other grains. Canada is a major exporter of agricultural products, to the United States and Asia. As with all other developed nations the proportion of the population and GDP devoted to agriculture fell dramatically over the 20th century.

As with other developed nations, the Canadian agriculture industry receives significant government subsidies and supports. However, Canada has been a strong supporter of reducing market influencing subsidies through the World Trade Organization. In 2000, Canada spent approximately CDN$4.6 billion on supports for the industry. Of this, $2.32 billion was classified under the WTO designation of "green box" support, meaning it did not directly influence the market, such as money for research or disaster relief. All but $848.2 million were subsidies worth less than 5% of the value of the crops they were provided for.



Canada is negotiating bilateral FTAs with the following countries and trade blocs:

Canada has been involved in negotiations to create the following regional trade blocks:


Canada and the United States share a common trading relationship. Canada's job market continues to perform well along with the US, reaching a 30-year low in the unemployment rate in December 2006, following 14 consecutive years of employment growth.

The United States is by far Canada's largest trading partner, with more than $1.7 billion CAD in trade per day in 2005. In 2009, 73% of Canada's exports went to the United States, and 63% of Canada's imports were from the United States. Trade with Canada makes up 23% of the United States' exports and 17% of its imports. By comparison, in 2005 this was more than U.S. trade with all countries in the European Union combined, and well over twice U.S. trade with all the countries of Latin America combined. Just the two-way trade that crosses the Ambassador Bridge between Michigan and Ontario equals all U.S. exports to Japan. Canada's importance to the United States is not just a border-state phenomenon: Canada is the leading export market for 35 of 50 U.S. states, and is the United States' largest foreign supplier of energy.

Bilateral trade increased by 52% between 1989, when the U.S.–Canada Free Trade Agreement (FTA) went into effect, and 1994, when the North American Free Trade Agreement (NAFTA) superseded it. Trade has since increased by 40%. NAFTA continues the FTA's moves toward reducing trade barriers and establishing agreed-upon trade rules. It also resolves some long-standing bilateral irritants and liberalizes rules in several areas, including agriculture, services, energy, financial services, investment, and government procurement. NAFTA forms the largest trading area in the world, embracing the 405 million people of the three North American countries.

The largest component of U.S.–Canada trade is in the commodity sector.

The U.S. is Canada's largest agricultural export market, taking well over half of all Canadian food exports. Similarly, Canada is the largest market for U.S. agricultural goods, with nearly 20% of American food exports going to its northern neighbour. Nearly two-thirds of Canada's forest products, including pulp and paper, are exported to the United States; 72% of Canada's total newsprint production also is exported to the U.S.

At $73.6 billion in 2004, U.S.-Canada trade in energy is the largest U.S. energy trading relationship, with the overwhelming majority ($66.7 billion) being exports from Canada. The primary components of U.S. energy trade with Canada are petroleum, natural gas, and electricity. Canada is the United States' largest oil supplier and the fifth-largest energy producing country in the world. Canada provides about 16% of U.S. oil imports and 14% of total U.S. consumption of natural gas. The United States and Canada's national electricity grids are linked, and both countries share hydropower facilities on the western borders.

While most of U.S.-Canada trade flows smoothly, there are occasionally bilateral trade disputes, particularly in the agricultural and cultural fields. Usually these issues are resolved through bilateral consultative forums or referral to World Trade Organization (WTO) or NAFTA dispute resolution. In May 1999, the U.S. and Canadian governments negotiated an agreement on magazines that provides increased access for the U.S. publishing industry to the Canadian market. The United States and Canada also have resolved several major issues involving fisheries. By common agreement, the two countries submitted a Gulf of Maine boundary dispute to the International Court of Justice in 1981; both accepted the court's 12 October 1984 ruling which demarcated the territorial sea boundary. A current issue between the United States and Canada is the ongoing softwood lumber dispute, as the U.S. alleges that Canada unfairly subsidizes its forestry industry.

In 1990, the United States and Canada signed a bilateral Fisheries Enforcement Agreement, which has served to deter illegal fishing activity and reduce the risk of injury during fisheries enforcement incidents. The U.S. and Canada signed a Pacific Salmon Agreement in June 1999 that settled differences over implementation of the 1985 Pacific Salmon Treaty for the next decade.

Canada and the United States signed an aviation agreement during Bill Clinton's visit to Canada in February 1995, and air traffic between the two countries has increased dramatically as a result. The two countries also share in operation of the St. Lawrence Seaway, connecting the Great Lakes to the Atlantic Ocean.

The U.S. is Canada's largest foreign investor and the most popular destination for Canadian foreign investments; at the end of 2007, the stock of U.S. direct investment in Canada was estimated at $293 billion, while Canadian direct investment (stock) in the United States was valued at $213 billion. U.S. FDI accounts for 59.5% of total foreign direct investment in Canada while Canadian FDI in the U.S. accounts for 10% (5th largest foreign investor). US investments are primarily directed at Canada's mining and smelting industries, petroleum, chemicals, the manufacture of machinery and transportation equipment, and finance, while Canadian investment in the United States is concentrated in manufacturing, wholesale trade, real estate, petroleum, finance, and insurance and other services.

The OECD reports the Central Government Debt as percentage of the GDP. In 2000 Canada's was 40.9 percent, in 2007 it was 25.2 percent, in 2008 it was 28.6 percent and by 2010 it was 36.1 percent. The OECD reports net financial liabilities measure used by the OECD, reports the net number at 25.2%, as of 2008, making Canada's total government debt burden as the lowest in the G8. The gross number was 68% in 2011.

The CIA World Factbook, updated weekly, measures financial liabilities by using gross general government debt, as opposed to net federal debt used by the OECD and the Canadian federal government. Gross general government debt includes both "intragovernmental debt and the debt of public entities at the sub-national level". For example, the CIA measured Canada's public debt as 84.1% of GDP in 2012 and 87.4% of GDP in 2011 making it 22nd in the world.

In March 2015 the International Monetary Fund reported that Canada's high household debt was one of two vulnerable domestic areas in Canada's economy; the second is its overheated housing market.

According to a July 2015 report by Laura Cooper, an economist with the RBC—the largest financial institution in Canada—"outstanding household credit balances" had reached $1.83 trillion. Canadian household credit growth had reached a peak in 2009 then plummeted to a cycle-low in late 2013. There was a quickened pace of growth in household debt in December 2012 and another in April and May 2015.

According to the August 2013 third annual Ipsos Reid Debt Poll only 24 per cent of Canadians were debt free in 2013 compared to 26 per cent in 2012. The average personal non-mortgage debt in 2013 was $15,920 up from $13,141 in 2012. According to an IPSOS chart produced in 2013 debt levels increased "a staggering 35 per cent" in Western Canada compared to 10 per cent in Eastern Canada since 2012 even before the Alberta floods. In Alberta in 2013 household debt rose 63 per cent to $24,271 per household from 2012 after the 2013 Alberta floods. In 2013 the average personal debt load in British Columbia was "up 38 per cent to $15,549"; in "Manitoba and Saskatchewan, up 32 per cent to $16,145"; in Ontario, "up 13 per cent to $17,416", in Quebec up "3 per cent to $10,458"; and in Atlantic Canada, "up 12 per cent to $15,243".

Statistics Canada announced in December 2014 that Canada's household debt-to-income ratio "hit a record high in the third quarter of 2014, climbing to 162.6 percent from 161.5 percent in the second quarter". However "household assets and net worth increased much faster than debt", with the national net worth at C$8.12 trillion in the third quarter of 2014, a increase of 2.8 percent from the second quarter. Also through the inflation-targeting policy of the Bank of Canada, interest rates are kept low improving the ability of households to service their debt. "The debt-service ratio, or interest paid as a proportion of disposable income, fell to a record low 6.8 percent in the third quarter."

By 2015 according to "The Globe and Mail", "The total debt owed by all Canadians at the end of March 2015 was a record $1.8-trillion with mortgage debt making up $1.29-trillion."

According to Philip Cross of the Fraser Institute, in May 2015, while the Canadian household debt-to-income ratio is similar to that in the US, however lending standards in Canada are tighter than those in the United States to protect against high-risk borrowers taking out unsustainable debt.

Household debt, the amount of money that all adults in the household owe financial institutions, includes consumer debt and mortgage loans. Paul Krugman argued that by 2007 household debt in the United States, prior to the financial crisis, had reached 130 percent of household income. Krugman distinguished between the total domestic non-financial debt (public plus private) relative to GDP which is "money we owe to ourselves" and net foreign debt. Statistics Canada reported in March 2013 that "credit-market debt such as mortgages rose to 165% of disposable income, compared with 164.7% in the prior three-month period" in 2013 According to the IMF in 2012, "Housing-related debt (mortgages) comprises about 70 percent of gross household debt in advanced economies. The remainder consists mainly of credit card debt and auto loans."

As shown in the table below—based on the RBC Economic and Financial Market Outlook March 11, 2016 report—in Canada in 2015—while business investments decreased—consumption, housing and government spending along with net exports contributed to a real GDP increase at a subpar 1.2% pace. In December 2015 export volumes reached $1.2 billion—the sixth time since 2010 with sales growing by such a large amount-evidence that the Canadian economy is transitioning. In November and December 2015, with the weakening in the Canadian dollar, manufacturing sales and exports increased and employment rose. Job losses in construction, mining, oil and gas were countered by gains in the service sector.

Between early December, 2015 and mid-January the price of oil unexpectedly dropped 24%. RBC economists argued that fear not fundamentals led the shift in financial conditions. Risk averse investors contributed to a global double-digit decline in the first six weeks of 2016. In Canada, the US, UK and Euro-area yields on long-term government bonds reached an all-time low. As financial market volatility continued in March 2016 the Bank of Canada and Bank of England held their policy rate at 0.5%.

Since 1985 63,755 deals in- and outbound Canada have been announced. This cummulates to an overall value of 3700.5 bil. USD.. Almost 50% of the targets of canadian companies (outbound deals) have a parent company in the US. Inbound deals are 82% percent from the US.

Here is a list of the biggest deals in canadian history:



</doc>
<doc id="5196" url="https://en.wikipedia.org/wiki?curid=5196" title="Telecommunications in Canada">
Telecommunications in Canada

Present-day Telecommunications in Canada include telephone, radio, television, and internet usage. In the past, telecommunications included telegraphy available through Canadian Pacific and Canadian National.

Telephones - fixed lines: total subscriptions: 14,987,520 (July 2016 est.)

Telephones - mobile cellular: 30.45 million (July 2016 est.)

Telephone system: (2016)

The history of telegraphy in Canada dates back to the Province of Canada. While the first telegraph company was the Toronto, Hamilton and Niagara Electro-Magnetic Telegraph Company, founded in 1846, it was the Montreal Telegraph Company, controlled by Hugh Allan and founded a year later, that dominated in Canada during the technology's early years.

Following the 1852 Telegraph Act, Canada's first permanent transatlantic telegraph link was a submarine cable built in 1866 between Ireland and Newfoundland.Telegrams were sent through networks built by Canadian Pacific and Canadian National.

In 1868 Montreal Telegraph began facing competition from the newly established Dominion Telegraph Company. 1880 saw the Great North Western Telegraph Company established to connect Ontario and Manitoba but within a year it was taken over by Western Union, leading briefly to that company's control of almost all telegraphy in Canada. In 1882, Canadian Pacific transmitted its first commercial telegram over telegraph lines they had erected alongside its tracks, breaking Western Union's monopoly. Great North Western Telegraph, facing bankruptcy, was taken over in 1915 by Canadian Northern.

By the end of World War II, Canadians communicated by telephone, more than any other country. In 1967 the CP and CN networks were merged to form CNCP Telecommunications.

As of 1951, approximately 7000 messages were sent daily from the United States to Canada. An agreement with Western Union required that U.S. company to route messages in a specified ratio of 3:1, with three telegraphic messages transmitted to Canadian National for every message transmitted to Canadian Pacific. The agreement was complicated by the fact that some Canadian destinations were served by only one of the two networks.

ITU prefixes: Letter combinations available for use in Canada as the first two letters of a television or radio station's call sign are CF, CG, CH, CI, CJ, CK, CY, CZ, VA, VB, VC, VD, VE, VF, VG, VO, VX, VY, XJ, XK, XL, XM, XN and XO. Only CF, CH, CI, CJ and CK are currently in common use, although four radio stations in St. John's, Newfoundland and Labrador retained call letters beginning with VO when Newfoundland joined Canadian Confederation in 1949. Stations owned by the Canadian Broadcasting Corporation use CB through a special agreement with the government of Chile. Some codes beginning with VE and VF are also in use to identify radio repeater transmitters.

Radio broadcast stations: AM 245, FM 582, shortwave 6 (2004)

Television broadcast stations: 1456 (128 originating stations, 1328 re-transmitters) (2003)

Cable and satellite television services are available throughout Canada. The largest cable providers are Rogers Cable, Shaw Cable, Vidéotron, Telus and Cogeco, while the two licensed satellite providers are Bell TV and Shaw Direct.


The three major mobile network operators are Rogers Wireless (10.6 million), Bell Mobility (9.0 million) and Telus Mobility (8.8 million), which have a combined 91% of market share.

Federally, telecommunications are overseen by the Canadian Radio-television and Telecommunications Commission ()–CRTC as outlined under the provisions of both the Telecommunications Act and Radiocommunication Acts. CRTC further works with Innovation, Science and Economic Development Canada (formerly Industry Canada) on various technical aspects including: allocating frequencies and call signs, managing the broadcast spectrum, and regulating other technical issues such as interference with electronics equipment. As Canada comprises a part of the North American Numbering Plan for area codes, the Canadian Numbering Administration Consortium within Canada is responsible for allocating and managing area codes in Canada.





</doc>
<doc id="5197" url="https://en.wikipedia.org/wiki?curid=5197" title="Transportation in Canada">
Transportation in Canada

Transportation in Canada, the world's second-largest country in total area, is dedicated to having an efficient, high-capacity multimodal transport spanning often vast distances between natural resource extraction sites, agricultural and urban areas. Canada's transportation system includes more than of roads, 10 major international airports, 300 smaller airports, of functioning railway track, and more than 300 commercial ports and harbours that provide access to the Pacific, Atlantic and Arctic oceans as well as the Great Lakes and the St. Lawrence Seaway. In 2005, the transportation sector made up 4.2% of Canada's GDP, compared to 3.7% for Canada's mining and oil and gas extraction industries.

Transport Canada oversees and regulates most aspects of transportation within federal jurisdiction, including interprovincial transport. This primarily includes rail, air and maritime transportation. Transport Canada is under the direction of the federal government's Minister of Transport. The Transportation Safety Board of Canada is responsible for maintaining transportation safety in Canada by investigating accidents and making safety recommendations.

There is a total of of roads in Canada, of which are paved, including of expressways (the third-longest in the world, behind the Interstate Highway System of the United States and the China's National Trunk Highway System). As of 2008, were unpaved.

In 2009, there were 20,706,616 road vehicles registered in Canada, of which 96% were vehicles under , 2.4% were vehicles between tonnes and 1.6% were or greater. These vehicles travelled a total of 333.29 billion kilometres, of which 303.6 billion was for vehicles under , 8.3 billion was for vehicles between and 21.4 billion was for vehicles over . For the trucks, 88.9% of vehicle-kilometres were intra-province trips, 4.9% were inter-province, 2.8% were between Canada and the US and 3.4% made outside of Canada. For trucks over , 59.1% of vehicle-kilometres were intra-province trips, 20% inter-province trips, 13.8% Canada-US trips and 7.1% trips made outside of Canada.

Canada's vehicles consumed a total of of gasoline and of diesel. Trucking generated 35% of the total GDP from transport, compared to 25% for rail, water and air combined (the remainder being generated by the industry's transit, pipeline, scenic and support activities). Hence roads are the dominant means of passenger and freight transport in Canada.

Roads and highways were managed by provincial and municipal authorities until construction of the Northwest Highway System (the Alaska Highway) and the Trans-Canada Highway project initiation. The Alaska Highway of 1942 was constructed during World War II for military purposes connecting Fort St. John, British Columbia with Fairbanks, Alaska. The transcontinental highway, a joint national and provincial expenditure, was begun in 1949 under the initiation of the Trans Canada Highway Act on December 10, 1949. The highway was completed in 1962 at a total expenditure of $1.4 billion.

Internationally, Canada has road links with both the lower 48 US states and Alaska. The Ministry of Transportation maintains the road network in Ontario and also employs Ministry of Transport Enforcement Officers for the purpose of administering the Canada Transportation Act and related regulations. The Department of Transportation in New Brunswick performs a similar task in that province as well.

Regulations enacted in regards to Canada highways are the 1971 Motor Vehicle Safety Act and the 1990 Highway Traffic Act

The safety of Canada's roads is moderately good by international standards, and is improving both in terms of accidents per head of population and per billion vehicle kilometers.

Air transportation made up 9% of the transport sector's GDP generation in 2005. Canada's largest air carrier and its flag carrier is Air Canada, which had 34 million customers in 2006 and, as of April 2010, operates 363 aircraft (including Air Canada Jazz). CHC Helicopter, the largest commercial helicopter operator in the world, is second with 142 aircraft and WestJet, a low-cost carrier formed in 1996, is third with 100 aircraft. Canada's airline industry saw significant change following the signing of the US-Canada open skies agreement in 1995, when the marketplace became less regulated and more competitive.

The Canadian Transportation Agency employs transportation enforcement officers to maintain aircraft safety standards, and conduct periodic aircraft inspections, of all air carriers. The Canadian Air Transport Security Authority is charged with the responsibility for the security of air traffic within Canada. In 1994 the National Airports Policy was enacted

Of over 1,800 registered Canadian aerodromes, certified airports, heliports, and floatplane bases, 26 are specially designated under Canada's National Airports System (NAS): these include all airports that handle 200,000 or more passengers each year, as well as the principal airport serving each federal, provincial, and territorial capital. However, since the introduction of the policy only one, Iqaluit Airport, has been added and no airports have been removed despite dropping below 200,000 passengers. The Government of Canada, with the exception of the three territorial capitals, retains ownership of these airports and leases them to local authorities. The next tier consists of 64 regional/local airports formerly owned by the federal government, most of which have now been transferred to other owners (most often to municipalities).

Below is a table of Canada's ten biggest airports by passenger traffic in 2011.

In 2007, Canada had a total of of freight and passenger railway, of which is electrified. While intercity passenger transportation by rail is now very limited, freight transport by rail remains common. Total revenues of rail services in 2006 was $10.4 billion, of which only 2.8% was from passenger services. The Canadian National and Canadian Pacific Railway are Canada's two major freight railway companies, each having operations throughout North America. In 2007, 357 billion tonne-kilometres of freight were transported by rail, and 4.33 million passengers travelled 1.44 billion passenger-kilometres (an almost negligible amount compared to the 491 billion passenger-kilometres made in light road vehicles). 34,281 people were employed by the rail industry in the same year.

Nationwide passenger services are provided by the federal crown corporation Via Rail. Three Canadian cities have commuter rail services: in the Montreal area by AMT, in the Toronto area by GO Transit, and in the Vancouver area by West Coast Express. Smaller railways such as Ontario Northland, Rocky Mountaineer, and Algoma Central also run passenger trains to remote rural areas.

In Canada railways are served by standard gauge, , rails. See also track gauge in Canada.

Canada has railway links with the lower 48 US States, but no connection with Alaska other than a train ferry service from Prince Rupert, British Columbia, although a line has been proposed. There are no other international rail connections.

In 2005, 139.2 million tonnes of cargo was loaded and unloaded at Canadian ports. The Port of Vancouver is the busiest port in Canada, moving 68 million tonnes or 15% of Canada's total in domestic and international shipping in 2003.

Transport Canada oversees most of the regulatory functions related to marine registration, safety of large vessel, and port pilotage duties. Many of Canada's port facilities are in the process of being divested from federal responsibility to other agencies or municipalities.

Inland waterways comprise , including the St. Lawrence Seaway. Transport Canada enforces acts and regulations governing water transportation and safety.

The St. Lawrence waterway was at one time the world's greatest inland water navigation system. The main route canals of Canada are those of the St. Lawrence River and the Great Lakes. The others are subsidiary canals.

The National Harbours Board administered Halifax, Saint John, Chicoutimi, Trois-Rivières, Churchill, and Vancouver until 1983. At one time, over 300 harbours across Canada were supervised by the Department of Transport. A program of divestiture was implemented around the turn of the millennium, and as of 2014, 493 of the 549 sites identified for divestiture in 1995 have been sold or otherwise transferred, as indicated by a DoT list. The government maintains an active divestiture programme, and after divestiture Transport Canada oversees only 17 Canada Port Authorities for the 17 largest shipping ports.


Canada's merchant marine comprised a "total" of 173 ships ( or over) or at the end of 2007.

Pipelines are part of the energy extraction and transportation network of Canada and are used to transport natural gas, natural gas liquids, crude oil, synthetic crude and other petroleum based products. Canada has of pipeline for transportation of crude and refined oil, and for liquefied petroleum gas.

Most Canadian cities have public transport, if only a bus system. Three Canadian cities have rapid transit systems, four have light rail systems, and three have commuter rail systems (see below). In 2006, 11% of Canadians used public transportation to get to work. This compares to 80.0% that got to work using a car (72.3% by driving, 7.7% as a passenger), 6.4% that walked and 1.3% that rode a bike.

There are three rapid transit systems operating in Canada: the Montreal Metro, the Toronto subway, and the Vancouver SkyTrain.

There is also an Airport Circulator, the LINK Train, at Toronto Pearson International Airport. It operates 24 hours a day, 7 days a week and is wheelchair-accessible. It is free of cost.

Three cities have light rail systems—the Calgary CTrain, the Edmonton Light Rail Transit, and the O-Train in Ottawa—and Toronto has an extensive streetcar system.
Commuter trains serve the cities and surrounding areas of Montreal, Toronto and Vancouver:
The standard history covers the French regime, fur traders, the canals, and early roads, and gives extensive attention to the railways.

Aboriginal peoples in Canada walked. They also used canoes, kayaks, umiaks and Bull Boats, in addition to the snowshoe, toboggan and sled in winter. They had no wheeled vehicles, and no animals larger than dogs.

Europeans adopted canoes as they pushed deeper into the continent's interior, and were thus able to travel via the waterways that fed from the St. Lawrence River and Hudson Bay.

In the 19th century and early 20th century transportation relied on harnessing oxen to "Red River ox carts" or horse to waggon. Maritime transportation was via manual labour such as canoe or wind on sail. Water or land travel speeds was approximately .

Settlement was along river routes. Agricultural commodities were perishable, and trade centres were within . Rural areas centred around villages, and they were approximately apart. The advent of steam railways and steamships connected resources and markets of vast distances in the late 19th century. Railways also connected city centres, in such a way that the traveller went by sleeper, railway hotel, to the cities. Crossing the country by train took four or five days, as it still does by car. People generally lived within of the downtown core thus the train could be used for inter-city travel and the tram for commuting.

The advent of the interstate or Trans-Canada Highway in Canada in 1963 established ribbon development, truck stops, and industrial corridors along throughways.

The Federal Department of Transport (established 2 November 1936) supervised railways, canals, harbours, marine and shipping, civil aviation, radio and meteorology. The Transportation Act of 1938 and the amended Railway Act, placed control and regulation of carriers in the hands of the Board of Transport commissioners for Canada. The Royal Commission on Transportation was formed 29 December 1948, to examine transportation services to all areas of Canada to eliminate economic or geographic disadvantages. The Commission also reviewed the Railway Act to provide uniform yet competitive freight-rates.





</doc>
<doc id="5199" url="https://en.wikipedia.org/wiki?curid=5199" title="Canada–United States relations">
Canada–United States relations

Relations between Canada and the United States of America historically have been extensive, given a shared border and ever-increasing close cultural, economical ties and similarities. The shared historical and cultural heritage has resulted in one of the most stable and mutually beneficial international relationships in the world. For both countries, the level of trade with the other is at the top of the annual combined import-export total. Tourism and migration between the two nations have increased rapport, but border security was heightened after the terrorist attacks in the United States on September 11, 2001. The U.S. is approximately 9.25 times larger in population and has the dominant cultural and economic influence. Starting with the American Revolution, when anti-American Loyalists fled to Canada, a vocal element in Canada has warned against US dominance or annexation. The War of 1812 saw invasions across the border. In 1815, the war ended with the border unchanged and demilitarized, as were the Great Lakes. The British ceased aiding First Nation attacks on American territory, and the United States never again attempted to invade Canada. Apart from minor raids, it has remained peaceful.

As Britain decided to disengage, fears of an American takeover played a role in the formation of the Dominion of Canada (1867), and Canada's rejection of free trade (1911). Military collaboration was close during World War II and continued throughout the Cold War, bilaterally through NORAD and multilaterally through NATO. A very high volume of trade and migration continues between the two nations, as well as a heavy overlapping of popular and elite culture, a dynamic which has generated closer ties, especially after the signing of the Canada–United States Free Trade Agreement in 1988.

Canada and the United States are the world's largest trading partners. The two nations have the world's longest shared border (), and also have significant interoperability within the defense sphere. Recent difficulties have included repeated trade disputes, environmental concerns, Canadian concern for the future of oil exports, and issues of illegal immigration and the threat of terrorism. Trade has continued to expand, especially following the 1988 FTA and North American Free Trade Agreement (NAFTA) in 1994 which has further merged the two economies.
Co-operation on many fronts, such as the ease of the flow of goods, services, and people across borders are to be even more extended, as well as the establishment of joint border inspection agencies, relocation of U.S. food inspectors agents to Canadian plants and vice versa, greater sharing of intelligence, and harmonizing regulations on everything from food to manufactured goods, thus further increasing the American-Canadian assemblage.

The foreign policies of the neighbours have been closely aligned since the Cold War. Canada has disagreed with American policies regarding the Vietnam War, the status of Cuba, the Iraq War, Missile Defense, and the War on Terror. A diplomatic debate has been underway in recent years on whether the Northwest Passage is in international waters or under Canadian sovereignty.

Today there are close cultural ties, many similar and identical traits and according to Gallup's annual public opinion polls, Canada has consistently been Americans' favorite nation, with 96% of Americans viewing Canada favorably in 2012. According to a 2013 BBC World Service Poll, 84% of Americans view their northern neighbor's influence positively, with only 5% expressing a negative view, the most favorable perception of Canada in the world. As of spring 2013, 64% of Canadians had a favorable view of the U.S. and 81% expressed confidence in then-US President Obama to do the right thing in international matters. According to the same poll, 30% viewed the U.S. negatively. Also, according to a 2014 BBC World Service Poll, 86% of Americans view Canada's influence positively, with only 5% expressing a negative view. However, according to the same poll, 43% of Canadians view U.S. influence positively, with 52% expressing a negative view. In addition, according to Spring 2017 Global Attitudes Survey, 43% of Canadians view U.S. positively, while 51% hold a negative view.

Leaders of Canada and the United States from 1950

Before the British conquest of French Canada in 1760, there had been a series of wars between the British and the French which were fought out in the colonies as well as in Europe and the high seas. In general, the British heavily relied on American colonial militia units, while the French heavily relied on their First Nation allies. The Iroquois Nation were important allies of the British. Much of the fighting involved ambushes and small-scale warfare in the villages along the border between New England and Quebec. The New England colonies had a much larger population than Quebec, so major invasions came from south to north. The First Nation allies, only loosely controlled by the French, repeatedly raided New England villages to kidnap women and children, and torture and kill the men. Those who survived were brought up as Francophone Catholics. The tension along the border was exacerbated by religion, the French Catholics and English Protestants had a deep mutual distrust. There was a naval dimension as well, involving privateers attacking enemy merchant ships.

England seized Quebec from 1629 to 1632, and Acadia in 1613 and again from 1654 to 1670; These territories were returned to France by the peace treaties. The major wars were (to use American names), King William's War (1689–1697); Queen Anne's War (1702–1713); King George's War (1744–1748), and the French and Indian War (1755–1763). In Canada, as in Europe, this era is known as the Seven Years' War.

New England soldiers and sailors were critical to the successful British campaign to capture the French fortress of Louisbourg in 1745, and (after it had been returned by treaty) to capture it again in 1758.

From the 1750s to the 21st century, there has been extensive mingling of the Canadian and American populations, with large movements in both directions.

New England Yankees settled large parts of Nova Scotia before 1775, and were neutral during the American Revolution. At the end of the Revolution, about 75,000 Loyalists moved out of the new United States to Nova Scotia, New Brunswick, and the lands of Quebec, east and south of Montreal. From 1790 to 1812 many farmers moved from New York and New England into Ontario (mostly to Niagara, and the north shore of Lake Ontario). In the mid and late 19th century gold rushes attracted American prospectors, mostly to British Columbia after the Cariboo Gold Rush, Fraser Canyon Gold Rush, and later to the Yukon. In the early 20th century, the opening of land blocks in the Prairie Provinces attracted many farmers from the American Midwest. Many Mennonites immigrated from Pennsylvania and formed their own colonies. In the 1890s some Mormons went north to form communities in Alberta after The Church of Jesus Christ of Latter-day Saints rejected plural marriage. The 1960s saw the arrival of about 50,000 draft-dodgers who opposed the Vietnam War.

In the late 19th and early 20th centuries, about 900,000 French Canadians moved to the U.S., with 395,000 residents there in 1900. Two-thirds went to mill towns in New England, where they formed distinctive ethnic communities. By the late 20th century, they had abandoned the French language, but most kept the Catholic religion. About twice as many English Canadians came to the U.S., but they did not form distinctive ethnic settlements.

Canada was a way-station through which immigrants from other lands stopped for a while, ultimately heading to the U.S. In 1851–1951, 7.1 million people arrived in Canada (mostly from Continental Europe), and 6.6 million left Canada, most of them to the U.S.

At the outset of the American Revolutionary War, the American revolutionaries hoped the French Canadians in Quebec and the Colonists in Nova Scotia would join their rebellion and they were pre-approved for joining the United States in the Articles of Confederation. When Canada was invaded, thousands joined the American cause and formed regiments that fought during the war; however most remained neutral and some joined the British effort. Britain advised the French Canadians that the British Empire already enshrined their rights in the Quebec Act, which the American colonies had viewed as one of the Intolerable Acts. The American invasion was a fiasco and Britain tightened its grip on its northern possessions; in 1777, a major British invasion into New York led to the surrender of the entire British army at Saratoga, and led France to enter the war as an ally of the U.S. The French Canadians largely ignored France's appeals for solidarity. After the war Canada became a refuge for about 75,000 Loyalists who either wanted to leave the U.S., or were compelled by Patriot reprisals to do so.

Among the original Loyalists there were 3,500 free black people. Most went to Nova Scotia and in 1792, 1200 migrated to Sierra Leone. About 2000 black slaves were brought in by Loyalist owners; they remained slaves in Canada until the Empire abolished slavery in 1833. Before 1860, about 30,000–40,000 black people entered Canada; many were already free and others were escaped slaves who came through the Underground Railroad.

The Treaty of Paris (1783), which ended the war, called for British forces to vacate all their forts south of the Great Lakes border. Britain refused to do so, citing failure of the United States to provide financial restitution for Loyalists who had lost property in the war. The Jay Treaty in 1795 with Great Britain resolved that lingering issue and the British departed the forts. Thomas Jefferson saw the nearby British imperial presence as a threat to the United States, and so he opposed the Jay Treaty, and it became one of the major political issues in the United States at the time. Thousands of Americans immigrated to Upper Canada (Ontario) from 1785 to 1812 to obtain cheaper land and better tax rates prevalent in that province; despite expectations that they would be loyal to the U.S. if a war broke out, in the event they were largely non-political.

Tensions mounted again after 1805, erupting into the War of 1812, when the Americans declared war on Britain. The Americans were angered by British harassment of U.S. ships on the high seas and seizure ("Impressment") of 6,000 sailors from American ships, severe restrictions against neutral American trade with France, and British support for hostile Indian tribes in Ohio and territories the U.S. had gained in 1783. American "honor" was an implicit issue. The Americans were outgunned by more than 10 to 1 by the Royal Navy, but could call on an army much larger than the British garrison in Canada, and so a land invasion of Canada was proposed as the only feasible, and most advantegous means of attacking the British Empire. Americans on the western frontier also hoped an invasion would bring an end to British support of Native American resistance to the westward expansion of the United States, typified by Tecumseh's coalition of tribes. Americans may also have wanted to annex Canada.

Once war broke out, the American strategy was to seize Canada—perhaps as a means of forcing concessions from the British Empire, or perhaps in order to annex it. There was some hope that settlers in western Canada—most of them recent immigrants from the U.S.—would welcome the chance to overthrow their British rulers. However, the American invasions were defeated primarily by British regulars with support from Native Americans and Upper Canada (Ontario) militia. Aided by the powerful Royal Navy, a series of British raids on the American coast were highly successful, culminating with an attack on Washington that resulted in the British burning of the White House, Capitol, and other public buildings. Major British invasions of New York in 1814 and Louisiana in 1814–15 were fiascoes, with the British retreating from New York and decisively defeated at the Battle of New Orleans. At the end of the war, Britain's American Indian allies had largely been defeated, and the Americans controlled a strip of Western Ontario centered on Fort Malden. However, Britain held much of Maine, and, with the support of their remaining American Indian allies, huge areas of the Old Northwest, including Wisconsin and much of Michigan and Illinois. With the surrender of Napoleon in 1814, Britain ended naval policies that angered Americans; with the defeat of the Indian tribes the threat to American expansion was ended. The upshot was both sides had asserted their honour, Canada was not annexed, and London and Washington had nothing more to fight over. The war was ended by the Treaty of Ghent, which took effect in February 1815. A series of postwar agreements further stabilized peaceful relations along the Canadian-US border. Canada reduced American immigration for fear of undue American influence, and built up the Anglican church as a counterweight to the largely American Methodist and Baptist churches.

In later years, Anglophone Canadians, especially in Ontario, viewed the War of 1812 as a heroic and successful resistance against invasion and as a victory that defined them as a people. The myth that the Canadian militia had defeated the invasion almost single-handed, known logically as the "militia myth", became highly prevalent after the war, having been propounded by John Strachan, Anglican Bishop of York. Meanwhile, the United States celebrated victory in its "Second War of Independence," and war heroes such as Andrew Jackson and William Henry Harrison headed to the White House.

In the aftermath of the War of 1812, pro-imperial conservatives led by Anglican Bishop John Strachan took control in Ontario ("Upper Canada"), and promoted the Anglican religion as opposed to the more republican Methodist and Baptist churches. A small interlocking elite, known as the Family Compact took full political control. Democracy, as practiced in the US, was ridiculed. The policies had the desired effect of deterring immigration from United States. Revolts in favor of democracy in Ontario and Quebec ("Lower Canada") in 1837 were suppressed; many of the leaders fled to the US. The American policy was to largely ignore the rebellions, and indeed ignore Canada generally in favor of westward expansion of the American Frontier.

At the end of the American Civil War in 1865, Americans were angry at British support for the Confederacy. One result was toleration of Fenian efforts to use the U.S. as a base to attack Canada. More serious was the demand for a huge payment to cover the damages caused, on the notion that British involvement had lengthened the war. Senator Charles Sumner, the chairman of the Senate Foreign Relations Committee, originally wanted to ask for $2 billion, or alternatively the ceding of all of Canada to the United States. When American Secretary of State William H. Seward negotiated the Alaska Purchase with Russia in 1867, he intended it as the first step in a comprehensive plan to gain control of the entire northwest Pacific Coast. Seward was a firm believer in Manifest Destiny, primarily for its commercial advantages to the U.S. Seward expected British Columbia to seek annexation to the U.S. and thought Britain might accept this in exchange for the "Alabama" claims. Soon other elements endorsed annexation, Their plan was to annex British Columbia, Red River Colony (Manitoba), and Nova Scotia, in exchange for the dropping the damage claims. The idea reached a peak in the spring and summer of 1870, with American expansionists, Canadian separatists, and British anti-imperialists seemingly combining forces. The plan was dropped for multiple reasons. London continued to stall, American commercial and financial groups pressed Washington for a quick settlement of the dispute on a cash basis, growing Canadian nationalist sentiment in British Columbia called for staying inside the British Empire, Congress became preoccupied with Reconstruction, and most Americans showed little interest in territorial expansion. The "Alabama Claims" dispute went to international arbitration. In one of the first major cases of arbitration, the tribunal in 1872 supported the American claims and ordered Britain to pay $15.5 million. Britain paid and the episode ended in peaceful relations.

Canada became a self-governing dominion in 1867 in internal affairs while Britain controlled diplomacy and defense policy. Prior to Confederation, there was an Oregon boundary dispute in which the Americans claimed the 54th degree latitude. That issue was resolved by splitting the disputed territory; the northern half became British Columbia, and the southern half the states of Washington and Oregon. Strained relations with America continued, however, due to a series of small-scale armed incursions named the Fenian raids by Irish-American Civil War veterans across the border from 1866 to 1871 in an attempt to trade Canada for Irish independence. The American government, angry at Canadian tolerance of Confederate raiders during the American Civil War, moved very slowly to disarm the Fenians. The British government, in charge of diplomatic relations, protested cautiously, as Anglo-American relations were tense. Much of the tension was relieved as the Fenians faded away and in 1872 by the settlement of the Alabama Claims, when Britain paid the U.S. $15.5 million for war losses caused by warships built in Britain and sold to the Confederacy.

Disputes over ocean boundaries on Georges Bank and over fishing, whaling, and sealing rights in the Pacific were settled by international arbitration, setting an important precedent.

After 1850, the pace of industrialization and urbanization was much faster in the United States, drawing a wide range of immigrants from the North. By 1870, 1/6 of all the people born in Canada had moved to the United States, with the highest concentrations in New England, which was the destination of Francophone emigrants from Quebec and Anglophone emigrants from the Maritimes. It was common for people to move back and forth across the border, such as seasonal lumberjacks, entrepreneurs looking for larger markets, and families looking for jobs in the textile mills that paid much higher wages than in Canada.

The southward migration slacked off after 1890, as Canadian industry began a growth spurt. By then, the American frontier was closing, and thousands of farmers looking for fresh land moved from the United States north into the Prairie Provinces. The net result of the flows were that in 1901 there were 128,000 American-born residents in Canada (3.5% of the Canadian population) and 1.18 million Canadian-born residents in the United States (1.6% of the U.S. population).

A short-lived controversy was the Alaska boundary dispute, settled in favor of the United States in 1903. No one cared until a gold rush brought tens of thousands of men to Canada's Yukon, and they had to arrive through American ports. Canada needed its port and claimed that it had a legal right to a port near the present American town of Haines, Alaska. It would provide an all-Canadian route to the rich goldfields. The dispute was settled by arbitration, and the British delegate voted with the Americans—to the astonishment and disgust of Canadians who suddenly realized that Britain considered its relations with the United States paramount compared to those with Canada. The arbitrartion validated the status quo, but made Canada angry at Britain.

1907 saw a minor controversy over USS "Nashville" sailing into the Great Lakes via Canada without Canadian permission. To head off future embarrassments, in 1909 the two sides signed the International Boundary Waters Treaty and the International Joint Commission was established to manage the Great Lakes and keep them disarmed. It was amended in World War II to allow the building and training of warships.

Anti-Americanism reached a shrill peak in 1911 in Canada. The Liberal government in 1911 negotiated a Reciprocity treaty with the U.S. that would lower trade barriers. Canadian manufacturing interests were alarmed that free trade would allow the bigger and more efficient American factories to take their markets. The Conservatives made it a central campaign issue in the 1911 election, warning that it would be a "sell out" to the United States with economic annexation a special danger. Conservative slogan was "No truck or trade with the Yankees", as they appealed to Canadian nationalism and nostalgia for the British Empire to win a major victory.

Canada demanded and received permission from London to send its own delegation to the Versailles Peace Talks in 1919, with the proviso that it sign the treaty under the British Empire. Canada subsequently took responsibility for its own foreign and military affairs in the 1920s. Its first ambassador to the United States, Vincent Massey, was named in 1927. The United States first ambassador to Canada was William Phillips. Canada became an active member of the British Commonwealth, the League of Nations, and the World Court, none of which included the U.S.

In July 1923, as part of his Pacific Northwest tour and a week before his death, US President Warren Harding visited Vancouver, making him the first head of state of the United States to visit Canada. The then Premier of British Columbia, John Oliver, and then mayor of Vancouver, Charles Tisdall, hosted a lunch in his honor at the Hotel Vancouver. Over 50,000 people heard Harding speak in Stanley Park. A monument to Harding designed by Charles Marega was unveiled in Stanley Park in 1925.

Relations with the United States were cordial until 1930, when Canada vehemently protested the new Smoot–Hawley Tariff Act by which the U.S. raised tariffs (taxes) on products imported from Canada. Canada retaliated with higher tariffs of its own against American products, and moved toward more trade within the British Commonwealth. U.S.–Canadian trade fell 75% as the Great Depression dragged both countries down.

Down to the 1920s the war and naval departments of both nations designed hypothetical war game scenarios with the other as an enemy. These were primarily exercises; the departments were never told to get ready for a real war. In 1921, Canada developed Defence Scheme No. 1 for an attack on American cities and for forestalling invasion by the United States until Imperial reinforcements arrived. Through the later 1920s and 1930s, the United States Army War College developed a plan for a war with the British Empire waged largely on North American territory, in War Plan Red.

Herbert Hoover meeting in 1927 with British Ambassador Sir Esme Howard agreed on the "absurdity of contemplating the possibility of war between the United States and the British Empire."

In 1938, as the roots of World War II were set in motion, U.S. President Franklin Roosevelt gave a public speech at Queens University in Kingston, Ontario, declaring that the United States would not sit idly by if another power tried to dominate Canada. Diplomats saw it as a clear warning to Germany not to attack Canada.

The two nations cooperated closely in World War II, as both nations saw new levels of prosperity and a determination to defeat the Axis powers. Prime Minister William Lyon Mackenzie King and President Franklin D. Roosevelt were determined not to repeat the mistakes of their predecessors. They met in August 1940 at Ogdensburg, issuing a declaration calling for close cooperation, and formed the Permanent Joint Board on Defense (PJBD).

King sought to raise Canada's international visibility by hosting the August 1943 Quadrant conference in Quebec on military and political strategy; he was a gracious host but was kept out of the important meetings by Winston Churchill and Roosevelt.

Canada allowed the construction of the Alaska Highway and participated in the building of the atomic bomb. 49,000 Americans joined the RCAF (Canadian) or RAF (British) air forces through the Clayton Knight Committee, which had Roosevelt's permission to recruit in the U.S. in 1940–42.

American attempts in the mid-1930s to integrate British Columbia into a united West Coast military command had aroused Canadian opposition. Fearing a Japanese invasion of Canada's vulnerable coast, American officials urged the creation of a united military command for an eastern Pacific Ocean theater of war. Canadian leaders feared American imperialism and the loss of autonomy more than a Japanese invasion. In 1941, Canadians successfully argued within the PJBD for mutual cooperation rather than unified command for the West Coast.

The United States built large military bases in Newfoundland, at the time, a British dominion. The American involvement ended the depression and brought new prosperity; Newfoundland's business community sought closer ties with the United States as expressed by the Economic Union Party. Ottawa took notice and wanted Newfoundland to join Canada, which it did after hotly contested referenda. There was little demand in the United States for the acquisition of Newfoundland, so the United States did not protest the British decision not to allow an American option on the Newfoundland referendum.

Following co-operation in the two World Wars, Canada and the United States lost much of their previous animosity. As Britain's influence as a global imperial power declined, Canada and the United States became extremely close partners. Canada was a close ally of the United States during the Cold War.

The United States had become Canada's largest market, and after the war the Canadian economy became dependent on smooth trade flows with the United States so much that in 1971 when the United States enacted the "Nixon Shock" economic policies (including a 10% tariff on all imports) it put the Canadian government into a panic. This led in a large part to the articulation of Prime Minister Trudeau's "Third Option" policy of diversifying Canada's trade and downgrading the importance of Canada – United States relations. In a 1972 speech in Ottawa, Nixon declared the "special relationship" between Canada and the United States dead.

The main issues in Canada–U.S. relations in the 1990s focused on the NAFTA agreement, which was signed in 1994. It created a common market that by 2014 was worth $19 trillion, encompassed 470 million people, and had created millions of jobs. Wilson says, "Few dispute that NAFTA has produced
large and measurable gains for Canadian consumers, workers, and businesses." However, he adds, "NAFTA has fallen well short of expectations."

Since the arrival of the Loyalists as refugees from the American Revolution in the 1780s, historians have identified a constant theme of Canadian fear of the United States and of "Americanization" or a cultural takeover. In the War of 1812, for example, the enthusiastic response by French militia to defend Lower Canada reflected, according to Heidler and Heidler (2004), "the fear of Americanization." Scholars have traced this attitude over time in Ontario and Quebec.

Canadian intellectuals who wrote about the U.S. in the first half of the 20th century identified America as the world center of modernity, and deplored it. Imperialists (who admired the British Empire) explained that Canadians had narrowly escaped American conquest with its rejection of tradition, its worship of "progress" and technology, and its mass culture; they explained that Canada was much better because of its commitment to orderly government and societal harmony. There were a few ardent defenders of the nation to the south, notably liberal and socialist intellectuals such as F. R. Scott and Jean-Charles Harvey (1891–1967).

Looking at television, Collins (1990) finds that it is in English Canada that fear of cultural Americanization is most powerful, for there the attractions of the U.S. are strongest. Meren (2009) argues that after 1945, the emergence of Quebec nationalism and the desire to preserve French-Canadian cultural heritage led to growing anxiety regarding American cultural imperialism and Americanization. In 2006 surveys showed that 60 percent of Quebecers had a fear of Americanization, while other surveys showed they preferred their current situation to that of the Americans in the realms of health care, quality of life as seniors, environmental quality, poverty, educational system, racism and standard of living. While agreeing that job opportunities are greater in America, 89 percent disagreed with the notion that they would rather be in the United States, and they were more likely to feel closer to English Canadians than to Americans. However, there is evidence that the elites and Quebec are much less fearful of Americanization, and much more open to economic integration than the general public.

The history has been traced in detail by a leading Canadian historian J.L. Granatstein in "Yankee Go Home: Canadians and Anti-Americanism" (1997). Current studies report the phenomenon persists. Two scholars report, "Anti-Americanism is alive and well in Canada today, strengthened by, among other things, disputes related to NAFTA, American involvement in the Middle East, and the ever-increasing Americanization of Canadian culture." Jamie Glazov writes, "More than anything else, Diefenbaker became the tragic victim of Canadian anti-Americanism, a sentiment the prime minister had fully embraced by 1962. [He was] unable to imagine himself (or his foreign policy) without enemies." Historian J. M. Bumsted says, "In its most extreme form, Canadian suspicion of the United States has led to outbreaks of overt anti-Americanism, usually spilling over against American residents in Canada." John R. Wennersten writes, "But at the heart of Canadian anti-Americanism lies a cultural bitterness that takes an American expatriate unaware. Canadians fear the American media's influence on their culture and talk critically about how Americans are exporting a culture of violence in its television programming and movies." However Kim Nossal points out that the Canadian variety is much milder than anti-Americanism in some other countries. By contrast Americans show very little knowledge or interest one way or the other regarding Canadian affairs. Canadian historian Frank Underhill, quoting Canadian playwright Merrill Denison summed it up: "Americans are benevolently ignorant about Canada, whereas Canadians are malevolently informed about the United States."

The executive of each country is represented differently. The President of the United States serves as both the head of state and head of government, and his "administration" is the executive, while the Prime Minister of Canada is head of government only, and his or her "government" or "ministry" directs the executive.
In 1940, W.L. Mackenzie King and Franklin D. Roosevelt signed a defense pact, known as the Ogdensburg Agreement.

Relations between Brian Mulroney and Ronald Reagan were famously close. This relationship resulted in negotiations for the Canada–United States Free Trade Agreement, and the U.S.–Canada Air Quality Agreement to reduce acid-rain-causing emissions, both major policy goals of Mulroney, that would be finalized under the presidency of George H. W. Bush.

Although Jean Chrétien was wary of appearing too close to the President, personally, he and Bill Clinton were known to be golfing partners. Their governments had many small trade quarrels over the Canadian content of American magazines, softwood lumber, and so on, but on the whole were quite friendly. Both leaders had run on reforming or abolishing NAFTA, but the agreement went ahead with the addition of environmental and labor side agreements. Crucially, the Clinton administration lent rhetorical support to Canadian unity during the 1995 referendum in Quebec on separation from Canada.

Relations between Chrétien and George W. Bush were strained throughout their overlapping times in office. After the September 11 attacks terror attacks, Jean Chrétien publicly mused that U.S. foreign policy might be part of the "root causes" of terrorism. Some Americans criticized his "smug moralism", and Chrétien's public refusal to support the 2003 Iraq war was met with negative responses in the United States, especially among conservatives.

Stephen Harper and George W. Bush were thought to share warm personal relations and also close ties between their administrations. Because Bush was so unpopular among liberals in Canada (particularly in the media), this was underplayed by the Harper government.

Shortly after being congratulated by Bush for his victory in February 2006, Harper rebuked U.S. ambassador to Canada David Wilkins for criticizing the Conservatives' plans to assert Canada's sovereignty over the Arctic Ocean waters with military force.

President Barack Obama's first international trip was to Canada on February 19, 2009, thereby sending a strong message of peace and cooperation. With the exception of Canadian lobbying against "Buy American" provisions in the U.S. stimulus package, relations between the two administrations were smooth.

They also held friendly bets on hockey games during the Winter Olympic season. In the 2010 Winter Olympics hosted by Canada in Vancouver, Canada defeated the US in both gold medal matches, entitling Stephen Harper to receive a case of Molson Canadian beer from Barack Obama; in reverse, if Canada had lost, Harper would have provided a case of Yuengling beer to Obama. During the 2014 Winter Olympics, alongside U.S. Secretary of State John Kerry & Minister of Foreign Affairs John Baird, Stephen Harper was given a case of Samuel Adams beer by Obama for the Canadian gold medal victory over the US in women's hockey, and the semi-final victory over the US in men's hockey.

On February 4, 2011, Harper and Obama issued a "Declaration on a Shared Vision for Perimeter Security and Economic Competitiveness" and announced the creation of the Canada–United States Regulatory Cooperation Council (RCC) "to increase regulatory transparency and coordination between the two countries."

Health Canada and the United States Food and Drug Administration (FDA) under the RCC mandate, undertook the "first of its kind" initiative by selecting "as its first area of alignment common cold indications for certain over-the-counter antihistamine ingredients (GC 2013-01-10)."

On December 7, 2011, Harper flew to Washington, met with Obama and signed an agreement to implement the joint action plans that had been developed since the initial meeting in February. The plans called on both countries to spend more on border infrastructure, share more information on people who cross the border, and acknowledge more of each other's safety and security inspection on third-country traffic. An editorial in "The Globe and Mail" praised the agreement for giving Canada the ability to track whether failed refugee claimants have left Canada via the U.S. and for eliminating "duplicated baggage screenings on connecting flights". The agreement is not a legally binding treaty, and relies on the political will and ability of the executives of both governments to implement the terms of the agreement. These types of executive agreements are routine—on both sides of the Canada–U.S. border.

President Barack Obama and Prime Minister Justin Trudeau first met formally at the APEC summit meeting in Manila, Philippines in November 2015, nearly a week after the latter was sworn into the office. Both leaders expressed eagerness for increased cooperation and coordination between the two countries during the course of Trudeau's government with Trudeau promising an "enhanced Canada–U.S. partnership".

On November 6, 2015, Obama announced the U.S. State Department's rejection of the proposed Keystone XL pipeline, the fourth phase of the Keystone oil pipeline system running between Canada and the United States, to which Trudeau expressed disappointment but said that the rejection would not damage Canada–U.S. relations and would instead provide a "fresh start" to strengthening ties through cooperation and coordination, saying that "the Canada–U.S. relationship is much bigger than any one project." Obama has since praised Trudeau's efforts to prioritize the reduction of climate change, calling it "extraordinarily helpful" to establish a worldwide consensus on addressing the issue.

Although Trudeau has told Obama his plans to withdraw Canada's McDonnell Douglas CF-18 Hornet jets assisting in the American-led intervention against ISIL, Trudeau said that Canada will still "do more than its part" in combating the terrorist group by increasing the number of Canadian special forces members training and fighting on ground in Iraq and Syria.

Trudeau visited the White House for an official visit and state dinner on March 10, 2016. Trudeau and Obama were reported to have shared warm personal relations during the visit, making humorous remarks about which country was better at hockey and which country had better beer. Obama complimented Trudeau's 2015 election campaign for its "message of hope and change" and "positive and optimistic vision". Obama and Trudeau also held "productive" discussions on climate change and relations between the two countries, and Trudeau invited Obama to speak in the Canadian parliament in Ottawa later in the year.

Following the victory of Donald Trump in the 2016 U.S. presidential election, Trudeau congratulated him and invited him to visit Canada at the "earliest opportunity." Prime Minister Trudeau and President Trump formally met for the first time at the White House on February 13, 2017, nearly a month after Trump was sworn into the office. Trump has ruffled relations with Canada with tariffs on softwood lumber. Diafiltered Milk has also been brought up by Trump as an area that needs to be negotiated. Trump is expected to renegotiate NAFTA with Canada.

The Canadian military, like forces of other NATO countries, fought alongside the United States in most major conflicts since World War II, including the Korean War, the Gulf War, the Kosovo War, and most recently the war in Afghanistan. The main exceptions to this were the Canadian government's opposition to the Vietnam War and the Iraq War, which caused some brief diplomatic tensions. Despite these issues, military relations have remained close.

American defense arrangements with Canada are more extensive than with any other country. The Permanent Joint Board of Defense, established in 1940, provides policy-level consultation on bilateral defense matters. The United States and Canada share North Atlantic Treaty Organization (NATO) mutual security commitments. In addition, American and Canadian military forces have cooperated since 1958 on continental air defense within the framework of the North American Aerospace Defense Command (NORAD). Canadian forces have provided indirect support for the American invasion of Iraq that began in 2003. Moreover, interoperability with the American armed forces has been a guiding principle of Canadian military force structuring and doctrine since the end of the Cold War. Canadian navy frigates, for instance, integrate seamlessly into American carrier battle groups.

In commemoration of the 200th Anniversary of the War of 1812 ambassadors from Canada and the US, and naval officers from both countries gathered at the Pritzker Military Library on August 17, 2012, for a panel discussion on Canada-US relations with emphasis on national security-related matters. Also as part of the commemoration, the navies of both countries sailed together throughout the Great Lakes region.

Canada's elite JTF2 unit joined American special forces in Afghanistan shortly after the al-Qaida attacks on September 11, 2001. Canadian forces joined the multinational coalition in Operation Anaconda in January 2002. On April 18, 2002, an American pilot bombed Canadian forces involved in a training exercise, killing four and wounding eight Canadians. A joint American-Canadian inquiry determined the cause of the incident to be pilot error, in which the pilot interpreted ground fire as an attack; the pilot ignored orders that he felt were "second-guessing" his field tactical decision. Canadian forces assumed a six-month command rotation of the International Security Assistance Force in 2003; in 2005, Canadians assumed operational command of the multi-national Brigade in Kandahar, with 2,300 troops, and supervises the Provincial Reconstruction Team in Kandahar, where al-Qaida forces are most active. Canada has also deployed naval forces in the Persian Gulf since 1991 in support of the UN Gulf Multinational Interdiction Force.

The Canadian Embassy in Washington, DC maintains a public relations website named CanadianAlly.com, which is intended "to give American citizens a better sense of the scope of Canada's role in North American and Global Security and the War on Terror".

The New Democratic Party and some recent Liberal leadership candidates have expressed opposition to Canada's expanded role in the Afghan conflict on the ground that it is inconsistent with Canada's historic role (since the Second World War) of peacekeeping operations.

According to contemporary polls, 71% of Canadians were opposed to the 2003 invasion of Iraq. Many Canadians, and the former Liberal Cabinet headed by Paul Martin (as well as many Americans such as Bill Clinton and Barack Obama), made a policy distinction between conflicts in Afghanistan and Iraq, unlike the Bush Doctrine, which linked these together in a "Global war on terror".

Canada has been involved in international responses to the threats from Daesh/ISIS/ISIL in Syria and Iraq, and is a member of the Global Coalition to Counter Daesh. In October 2016, Foreign Affairs Minister Dion and National Defence Minister Sajjan meet U.S. special envoy for this coalition. The Americans thanked Canada "for the role of Canadian Armed Forces (CAF) in providing training and assistance to Iraqi security forces, as well as the CAF's role in improving essential capacity-building capabilities with regional forces."

Canada and the United States have the world's largest trading relationship, with huge quantities of goods and people flowing across the border each year. Since the 1987 Canada–United States Free Trade Agreement, there have been no tariffs on most goods passed between the two countries.

In the course of the softwood lumber dispute, the U.S. has placed tariffs on Canadian softwood lumber because of what it argues is an unfair Canadian government subsidy, a claim which Canada disputes. The dispute has cycled through several agreements and arbitration cases. Other notable disputes include the Canadian Wheat Board, and Canadian cultural "restrictions" on magazines and television (See CRTC, CBC, and National Film Board of Canada). Canadians have been criticized about such things as the ban on beef since a case of Mad Cow disease was discovered in 2003 in cows from the United States (and a few subsequent cases) and the high American agricultural subsidies. Concerns in Canada also run high over aspects of the North American Free Trade Agreement (NAFTA) such as Chapter 11.

A principal instrument of this cooperation is the International Joint Commission (IJC), established as part of the Boundary Waters Treaty of 1909 to resolve differences and promote international cooperation on boundary waters. The Great Lakes Water Quality Agreement of 1972 is another historic example of joint cooperation in controlling trans-border water pollution. However, there have been some disputes. Most recently, the Devil's Lake Outlet, a project instituted by North Dakota, has angered Manitobans who fear that their water may soon become polluted as a result of this project.

Beginning in 1986 the Canadian government of Brian Mulroney began pressing the Reagan administration for an "Acid Rain Treaty" in order to do something about U.S. industrial air pollution causing acid rain in Canada. The Reagan administration was hesitant, and questioned the science behind Mulroney's claims. However, Mulroney was able to prevail. The product was the signing and ratification of the Air Quality Agreement of 1991 by the first Bush administration. Under that treaty, the two governments consult semi-annually on trans-border air pollution, which has demonstrably reduced acid rain, and they have since signed an annex to the treaty dealing with ground level ozone in 2000. Despite this, trans-border air pollution remains an issue, particularly in the Great Lakes-St. Lawrence watershed during the summer. The main source of this trans-border pollution results from coal-fired power stations, most of them located in the Midwestern United States. As part of the negotiations to create NAFTA, Canada and the U.S. signed, along with Mexico, the North American Agreement On Environmental Cooperation which created the Commission for Environmental Cooperation which monitors environmental issues across the continent, publishing the North American Environmental Atlas as one aspect of its monitoring duties.

Currently neither of the countries' governments support the Kyoto Protocol, which set out time scheduled curbing of greenhouse gas emissions. Unlike the United States, Canada has ratified the agreement. Yet after ratification, due to internal political conflict within Canada, the Canadian government does not enforce the Kyoto Protocol, and has received criticism from environmental groups and from other governments for its climate change positions. In January 2011, the Canadian minister of the environment, Peter Kent, explicitly stated that the policy of his government with regards to greenhouse gas emissions reductions is to wait for the United States to act first, and then try to harmonize with that action – a position that has been condemned by environmentalists and Canadian nationalists, and as well as scientists and government think-tanks.

The United States and Britain had a long-standing dispute about the rights of Americans fishing in the waters near Newfoundland. Before 1776, there was no question that American fishermen, mostly from Massachusetts, had rights to use the waters off Newfoundland. In the peace treaty negotiations of 1783, the Americans insisted on a statement of these rights. However, France, an American ally, disputed the American position because France had its own specified rights in the area and wanted them to be exclusive. The Treaty of Paris (1783) gave the Americans not rights, but rather "liberties" to fish within the territorial waters of British North America and to dry fish on certain coasts.

After the War of 1812, the Convention of 1818 between the United States and Britain specified exactly what liberties were involved. Canadian and Newfoundland fishermen contested these liberties in the 1830s and 1840s. The Canadian–American Reciprocity Treaty of 1854, and the Treaty of Washington of 1871 spelled-out the liberties in more detail. However the Treaty of Washington expired in 1885, and there was a continuous round of disputes over jurisdictions and liberties. Britain and the United States sent the issue to the Permanent Court of Arbitration in The Hague in 1909. It produced a compromise settlement that permanently ended the problems.

In 2003 the American government became concerned when members of the Canadian government announced plans to decriminalize marijuana. David Murray, an assistant to U.S. Drug Czar John P. Walters, said in a CBC interview that, "We would have to respond. We would be forced to respond." However the election of the Conservative Party in early 2006 halted the liberalization of marijuana laws for the foreseeable future.

A 2007 joint report by American and Canadian officials on cross-border drug smuggling indicated that, despite their best efforts, "drug trafficking still occurs in significant quantities in both directions across the border. The principal illicit substances smuggled across our shared border are MDMA ("Ecstasy"), cocaine, and marijuana." The report indicated that Canada was a major producer of "Ecstasy" and marijuana for the U.S. market, while the U.S. was a transit country for cocaine entering Canada.

Presidents and prime ministers typically make formal or informal statements that indicate the diplomatic policy of their administration. Diplomats and journalists at the time—and historians since—dissect the nuances and tone to detect the warmth or coolness of the relationship.

Canada's first Prime Minister also said:


United States President George W. Bush was "deeply disliked" by a majority of Canadians according to the "Arizona Daily Sun". A 2004 poll found that more than two thirds of Canadians favoured Democrat John Kerry over Bush in the 2004 presidential election, with Bush's lowest approval ratings in Canada being in the province of Quebec where just 11% of the population supported him. Canadian public opinion of Barack Obama was significantly more positive. A 2012 poll found that 65% of Canadians would vote for Obama in the 2012 presidential election "if they could" while only 9% of Canadians would vote for his Republican opponent Mitt Romney. The same study found that 61% of Canadians felt that the Obama administration had been "good" for America, while only 12% felt it had been "bad". Similarly, a Pew Research poll conducted in June 2016 found that 83% of Canadians were "confident in Obama to do the right thing regarding world affairs". The study also found that a majority of members of all three major Canadian political parties supported Obama, and also found that Obama had slightly higher approval ratings in Canada in 2012 than he did in 2008. John Ibbitson of "The Globe and Mail" stated in 2012 that Canadians generally supported Democratic presidents over Republican presidents, citing how President Richard Nixon was "never liked" in Canada and that Canadians generally did not approve of Prime Minister Brian Mulroney's friendship with President Ronald Reagan.

A January 2017 poll found that 66% of Canadians "disapproved" of Donald Trump, with 23% approving of him and 11% being "unsure". The poll also found that only 18% of Canadians believed Trump's presidency would have a positive impact on Canada, while 63% believed it would have a negative effect.

These include maritime boundary disputes:

Territorial land disputes:

and disputes over the international status of the:

A long-simmering dispute between Canada and the U.S. involves the issue of Canadian sovereignty over the Northwest Passage (the sea passages in the Arctic). Canada's assertion that the Northwest Passage represents internal (territorial) waters has been challenged by other countries, especially the U.S., which argue that these waters constitute an international strait (international waters). Canadians were alarmed when Americans drove the reinforced oil tanker through the Northwest Passage in 1969, followed by the icebreaker Polar Sea in 1985, which actually resulted in a minor diplomatic incident. In 1970, the Canadian parliament enacted the Arctic Waters Pollution Prevention Act, which asserts Canadian regulatory control over pollution within a 100-mile zone. In response, the United States in 1970 stated, "We cannot accept the assertion of a Canadian claim that the Arctic waters are internal waters of Canada. ... Such acceptance would jeopardize the freedom of navigation essential for United States naval activities worldwide." A compromise of sorts was reached in 1988, by an agreement on "Arctic Cooperation," which pledges that voyages of American icebreakers "will be undertaken with the consent of the Government of Canada." However the agreement did not alter either country's basic legal position. Paul Cellucci, the American ambassador to Canada, in 2005 suggested to Washington that it should recognize the straits as belonging to Canada. His advice was rejected and Harper took opposite positions. The U.S. opposes Harper's proposed plan to deploy military icebreakers in the Arctic to detect interlopers and assert Canadian sovereignty over those waters.

Canada and the United States both hold membership in a number of multinational organizations such as:

Canada's chief diplomatic mission to the United States is the Canadian Embassy in Washington, D.C.. It is further supported by many consulates located through United States.
The Canadian Government maintains consulates-general in several major U.S. cities including: Atlanta, Boston, Chicago, Dallas, Denver, Detroit, Los Angeles, Miami, Minneapolis, New York City, San Francisco and Seattle. Canadian consular services are also available in Honolulu at the consulate of Australia through the Canada–Australia Consular Services Sharing Agreement.

There are also Canadian trade offices located in Houston, Palo Alto and San Diego.

The United States's chief diplomatic mission to Canada is the United States Embassy in Ottawa. It is further supported by many consulates located throughout Canada.
The U.S government maintains consulates-general in several major Canadian cities including:
Calgary, Halifax, Montreal, Quebec City, Toronto, Vancouver and Winnipeg.

The United States also maintains Virtual Presence Posts (VPP) in the: Northwest Territories, Nunavut, Southwestern Ontario and Yukon.





</doc>
<doc id="5211" url="https://en.wikipedia.org/wiki?curid=5211" title="Christianity">
Christianity

Christianity is an Abrahamic monotheistic religion based on the life, teachings, and miracles of Jesus of Nazareth, known by Christians as the Christ, or "Messiah", who is the focal point of the Christian faiths. It is the world's largest religion, with over 2.4 billion followers, or 33% of the global population, known as Christians. Christians make up a majority of the population in about two-thirds of the countries and territories in the world. They believe that Jesus is the Son of God and the savior of humanity whose coming as the Messiah (the Christ) was prophesied in the Old Testament. Christianity has played a prominent role in the shaping of Western civilization.

Christianity grew out of Judaism and began as a Second Temple Judaic sect in the mid-1st century. Originating in the Roman province of Judea, it quickly spread to Syria, Europe, Anatolia, Mesopotamia, Transcaucasia, Egypt, Ethiopia and the Indian subcontinent, and by the end of the 4th century had become the official state church of the Roman Empire. Following the Age of Discovery, Christianity spread to the Americas, Oceania, sub-Saharan Africa and the rest of the world through missionary work and colonization.

Christian theology is summarized in creeds such as the Apostles' Creed and the Nicene Creed. These professions of faith state that Jesus suffered, died, was buried, descended into hell, and rose from the dead, in order to grant eternal life to those who believe in him and trust in him for the remission of their sins. The creeds further maintain that Jesus physically ascended into heaven, where he reigns with God the Father in the unity of the Holy Spirit, and that he will return to judge the living and the dead and grant eternal life to his followers. His incarnation, earthly ministry, crucifixion and resurrection are often referred to as "the gospel", meaning "good news". The term "gospel" also refers to written accounts of Jesus' life and teaching, four of which—Matthew, Mark, Luke, and John—are considered canonical and included in the Christian Bible, as established by the 5th century for the ancient undivided Catholic and Eastern Orthodox traditions before the East–West Schism.

Throughout its history, Christianity has weathered schisms and theological disputes that have resulted in many distinct churches and denominations. Worldwide, the three largest branches of Christianity are the Catholic Church, Protestantism, and the Eastern Orthodox Church. The Catholic and Eastern Orthodox churches broke communion with each other in the East–West Schism of 1054. Protestantism came into existence in the Reformation in the 16th century, splitting from the Catholic Church.

There are many important differences of interpretation and opinion of the Bible and sacred tradition on which Christianity is based. Because of these irreconcilable differences in theology and a lack of consensus on the core tenets of Christianity, Catholics, Protestants and Orthodox often deny that members of certain other branches are Christians.

Concise doctrinal statements or confessions of religious beliefs are known as creeds (from Latin "credo", meaning "I believe"). They began as baptismal formulae and were later expanded during the Christological controversies of the 4th and 5th centuries to become statements of faith.

Many evangelical Protestants reject creeds as definitive statements of faith, even while agreeing with some or all of the substance of the creeds. The Baptists have been non-creedal "in that they have not sought to establish binding authoritative confessions of faith on one another." Also rejecting creeds are groups with roots in the Restoration Movement, such as the Christian Church (Disciples of Christ), the Evangelical Christian Church in Canada and the Churches of Christ.
The Apostles' Creed is the most widely accepted statement of the articles of Christian faith. It is used by a number of Christian denominations for both liturgical and catechetical purposes, most visibly by liturgical churches of Western Christian tradition, including the Latin Church of the Catholic Church, Lutheranism, Anglicanism and Western Rite Orthodoxy. It is also used by Presbyterians, Methodists and Congregationalists. This particular creed was developed between the 2nd and 9th centuries. Its central doctrines are those of the Trinity and God the Creator. Each of the doctrines found in this creed can be traced to statements current in the apostolic period. The creed was apparently used as a summary of Christian doctrine for baptismal candidates in the churches of Rome.

Its main points include:

The Nicene Creed was formulated, largely in response to Arianism, at the Councils of Nicaea and Constantinople in 325 and 381 respectively and ratified as the universal creed of Christendom by the First Council of Ephesus in 431.

The Chalcedonian Definition, or Creed of Chalcedon, developed at the Council of Chalcedon in 451, though rejected by the Oriental Orthodox churches, taught Christ "to be acknowledged in two natures, inconfusedly, unchangeably, indivisibly, inseparably": one divine and one human, and that both natures, while perfect in themselves, are nevertheless also perfectly united into one person.

The Athanasian Creed, received in the Western Church as having the same status as the Nicene and Chalcedonian, says: "We worship one God in Trinity, and Trinity in Unity; neither confounding the Persons nor dividing the Substance."

Most Christians (Catholic, Eastern Orthodox, Oriental Orthodox and Protestant alike) accept the use of creeds, and subscribe to at least one of the creeds mentioned above.

The central tenet of Christianity is the belief in Jesus as the Son of God and the Messiah (Christ). Christians believe that Jesus, as the Messiah, was anointed by God as savior of humanity and hold that Jesus' coming was the fulfillment of messianic prophecies of the Old Testament. The Christian concept of the Messiah differs significantly from the contemporary Jewish concept. The core Christian belief is that through belief in and acceptance of the death and resurrection of Jesus, sinful humans can be reconciled to God and thereby are offered salvation and the promise of eternal life.

While there have been many theological disputes over the nature of Jesus over the earliest centuries of Christian history, generally Christians believe that Jesus is God incarnate and "true God and true man" (or both fully divine and fully human). Jesus, having become fully human, suffered the pains and temptations of a mortal man, but did not sin. As fully God, he rose to life again. According to the New Testament, he rose from the dead, ascended to heaven, is seated at the right hand of the Father and will ultimately return to fulfill the rest of Messianic prophecy, including the resurrection of the dead, the Last Judgment and final establishment of the Kingdom of God.

According to the canonical gospels of Matthew and Luke, Jesus was conceived by the Holy Spirit and born from the Virgin Mary. Little of Jesus' childhood is recorded in the canonical gospels, although infancy gospels were popular in antiquity. In comparison, his adulthood, especially the week before his death, is well documented in the gospels contained within the New Testament, because that part of his life is believed to be most important. The biblical accounts of Jesus' ministry include: his baptism, miracles, preaching, teaching and deeds.

Christians consider the resurrection of Jesus to be the cornerstone of their faith (see 1 Corinthians 15) and the most important event in history. Among Christian beliefs, the death and resurrection of Jesus are two core events on which much of Christian doctrine and theology is based. According to the New Testament, Jesus was crucified, died a physical death, was buried within a tomb and rose from the dead three days later. 

The New Testament mentions several resurrection appearances of Jesus on different occasions to his twelve apostles and disciples, including "more than five hundred brethren at once", before Jesus' Ascension to heaven. Jesus' death and resurrection are commemorated by Christians in all worship services, with special emphasis during Holy Week which includes Good Friday and Easter Sunday.

The death and resurrection of Jesus are usually considered the most important events in Christian theology, partly because they demonstrate that Jesus has power over life and death and therefore has the authority and power to give people eternal life.

Christian churches accept and teach the New Testament account of the resurrection of Jesus with very few exceptions. Some modern scholars use the belief of Jesus' followers in the resurrection as a point of departure for establishing the continuity of the historical Jesus and the proclamation of the early church. Some liberal Christians do not accept a literal bodily resurrection, seeing the story as richly symbolic and spiritually nourishing myth. Arguments over death and resurrection claims occur at many religious debates and interfaith dialogues. Paul the Apostle, an early Christian convert and missionary, wrote, "If Christ was not raised, then all our preaching is useless, and your trust in God is useless." 

Paul the Apostle, like Jews and Roman pagans of his time, believed that sacrifice can bring about new kinship ties, purity and eternal life. For Paul, the necessary sacrifice was the death of Jesus: Gentiles who are "Christ's" are, like Israel, descendants of Abraham and "heirs according to the promise". The God who raised Jesus from the dead would also give new life to the "mortal bodies" of Gentile Christians, who had become with Israel the "children of God" and were therefore no longer "in the flesh". 

Modern Christian churches tend to be much more concerned with how humanity can be saved from a universal condition of sin and death than the question of how both Jews and Gentiles can be in God's family. According to both Catholic and Protestant doctrine, salvation comes by Jesus' substitutionary death and resurrection. The Catholic Church teaches that salvation does not occur without faithfulness on the part of Christians; converts must live in accordance with principles of love and ordinarily must be baptized. Martin Luther taught that baptism was necessary for salvation, but modern Lutherans and other Protestants tend to teach that salvation is a gift that comes to an individual by God's grace, sometimes defined as "unmerited favor", even apart from baptism.

Christians differ in their views on the extent to which individuals' salvation is pre-ordained by God. Reformed theology places distinctive emphasis on grace by teaching that individuals are completely incapable of self-redemption, but that sanctifying grace is irresistible. In contrast Catholics, Orthodox Christians and Arminian Protestants believe that the exercise of free will is necessary to have faith in Jesus.

"Trinity" refers to the teaching that the one God comprises three distinct, eternally co-existing persons; the "Father", the "Son" (incarnate in Jesus Christ) and the "Holy Spirit". Together, these three persons are sometimes called the Godhead, although there is no single term in use in Scripture to denote the unified Godhead. In the words of the Athanasian Creed, an early statement of Christian belief, "the Father is God, the Son is God and the Holy Spirit is God, and yet there are not three Gods but one God". They are distinct from another: the Father has no source, the Son is begotten of the Father and the Spirit proceeds from the Father. Though distinct, the three persons cannot be divided from one another in being or in operation. While some Christians also believe that God appeared as the Father in the Old Testament, it is agreed that he appeared as the Son in the New Testament, and will still continue to manifest as the Holy Spirit in the present. But still, God still existed as three persons in each of these times. However, traditionally there is a belief that it was the Son who appeared in the Old Testament because, for example, when the Trinity is depicted in art, the Son typically has the distinctive appearance, a cruciform halo identifying Christ, and in depictions of the Garden of Eden this looks forward to an Incarnation yet to occur. In some Early Christian sarcophagi the Logos is distinguished with a beard, "which allows him to appear ancient, even preexistent."

The Trinity is an essential doctrine of mainstream Christianity. From earlier than the times of the Nicene Creed, 325, Christianity advocated the triune mystery-nature of God as a normative profession of faith. According to Roger E. Olson and Christopher Hall, through prayer, meditation, study and practice, the Christian community concluded "that God must exist as both a unity and trinity", codifying this in ecumenical council at the end of the 4th century.

According to this doctrine, God is not divided in the sense that each person has a third of the whole; rather, each person is considered to be fully God (see Perichoresis). The distinction lies in their relations, the Father being unbegotten; the Son being begotten of the Father; and the Holy Spirit proceeding from the Father and (in Western Christian theology) from the Son. Regardless of this apparent difference, the three "persons" are each eternal and omnipotent. Other Christian religions including Unitarian Universalism, Jehovah's Witnesses, Mormonism and others do not share those views on the Trinity.

The Latin word "trias", from which "trinity" is derived, is first seen in the works of Theophilus of Antioch. He wrote of "the Trinity of God (the Father), His Word (the Son) and His Wisdom (Holy Spirit)". The term may have been in use before this time. Afterwards it appears in Tertullian. In the following century the word was in general use. It is found in many passages of Origen.

"Trinitarianism" denotes those Christians who believe in the concept of the Trinity. Almost all Christian denominations and churches hold Trinitarian beliefs. Although the words "Trinity" and "Triune" do not appear in the Bible, theologians beginning in the 3rd century developed the term and concept to facilitate comprehension of the New Testament teachings of God as being Father, Son and Holy Spirit. Since that time, Christian theologians have been careful to emphasize that Trinity does not imply that there are three gods (the antitrinitarian heresy of Tritheism), nor that each hypostasis of the Trinity is one-third of an infinite God (partialism), nor that the Son and the Holy Spirit are beings created by and subordinate to the Father (Arianism). Rather, the Trinity is defined as one God in three Persons.

"Nontrinitarianism" (or "antitrinitarianism") refers to theology that rejects the doctrine of the Trinity. Various nontrinitarian views, such as adoptionism or modalism, existed in early Christianity, leading to the disputes about Christology. Nontrinitarianism later appeared again in the Gnosticism of the Cathars in the 11th through 13th centuries, among groups with Unitarian theology in the Protestant Reformation of the 16th century, in the 18th-century Enlightenment and in some groups arising during the Second Great Awakening of the 19th century.

Christianity, like other religions, has adherents whose beliefs and biblical interpretations vary. Christianity regards the biblical canon, the Old Testament and the New Testament, as the inspired word of God. The traditional view of inspiration is that God worked through human authors so that what they produced was what God wished to communicate. The Greek word referring to inspiration in is "theopneustos", which literally means "God-breathed".

Some believe that divine inspiration makes our present Bibles inerrant. Others claim inerrancy for the Bible in its original manuscripts, although none of those are extant. Still others maintain that only a particular translation is inerrant, such as the King James Version. Another closely related view is Biblical infallibility or limited inerrancy, which affirms that the Bible is free of error as a guide to salvation, but may include errors on matters such as history, geography or science.

The books of the Bible accepted by the Orthodox, Catholic and Protestant churches vary somewhat, with Jews accepting only the Hebrew Bible as canonical; there is however substantial overlap. These variations are a reflection of the range of traditions, and of the councils that have convened on the subject. Every version of the Old Testament always includes the books of the Tanakh, the canon of the Hebrew Bible. The Catholic and Orthodox canons, in addition to the Tanakh, also include the Deuterocanonical Books as part of the Old Testament. These books appear in the Septuagint, but are regarded by Protestants to be apocryphal. However, they are considered to be important historical documents which help to inform the understanding of words, grammar and syntax used in the historical period of their conception. Some versions of the Bible include a separate Apocrypha section between the Old Testament and the New Testament. The New Testament, originally written in Koine Greek, contains 27 books which are agreed upon by all churches.

Modern scholarship has raised many issues with the Bible. While the Authorized King James Version is held to by many because of its striking English prose, in fact it was translated from the Erasmus Greek Bible which in turn "was based on a single 12th Century manuscript that is one of the worst manuscripts we have available to us". Much scholarship in the past several hundred years has gone into comparing different manuscripts in order to reconstruct the original text. Another issue is that several books are considered to be forgeries. The injunction that women "be silent and submissive" in 1 Timothy 2 is thought by many to be a forgery by a follower of Paul, a similar phrase in 1 Corinthians 14, which is thought to be by Paul, appears in different places in different manuscripts and is thought to originally be a margin note by a copyist. Other verses in 1 Corinthians, such as 1 Corinthians 11:2–16 where women are instructed to wear a covering over their hair "when they pray or prophesies", contradict this verse.

A final issue with the Bible is the way in which books were selected for inclusion in the New Testament. Other Gospels have now been recovered, such as those found near Nag Hammadi in 1945, and while some of these texts are quite different from what Christians have been used to, it should be understood that some of this newly recovered Gospel material is quite possibly contemporaneous with, or even earlier than, the New Testament Gospels. The core of the Gospel of Thomas, in particular, may date from as early as AD 50 (although some major scholars contest this early dating), and if so would provide an insight into the earliest gospel texts that underlie the canonical Gospels, texts that are mentioned in Luke 1:1–2. The Gospel of Thomas contains much that is familiar from the canonical Gospels—verse 113, for example ("The Father's Kingdom is spread out upon the earth, but people do not see it"), is reminiscent of Luke 17:20–21—and the Gospel of John, with a terminology and approach that is suggestive of what was later termed "Gnosticism", has recently been seen as a possible response to the Gospel of Thomas, a text that is commonly labelled "proto-Gnostic". Scholarship, then, is currently exploring the relationship in the Early Church between mystical speculation and experience on the one hand and the search for church order on the other, by analyzing new-found texts, by subjecting canonical texts to further scrutiny, and by an examination of the passage of New Testament texts to canonical status.

In antiquity, two schools of exegesis developed in Alexandria and Antioch. Alexandrine interpretation, exemplified by Origen, tended to read Scripture allegorically, while Antiochene interpretation adhered to the literal sense, holding that other meanings (called "theoria") could only be accepted if based on the literal meaning.

Catholic theology distinguishes two senses of scripture: the literal and the spiritual.

The "literal" sense of understanding scripture is the meaning conveyed by the words of Scripture. The "spiritual" sense is further subdivided into:

Regarding exegesis, following the rules of sound interpretation, Catholic theology holds:

Protestant Christians believe that the Bible is a self-sufficient revelation, the final authority on all Christian doctrine, and revealed all truth necessary for salvation. This concept is known as "sola scriptura". Protestants characteristically believe that ordinary believers may reach an adequate understanding of Scripture because Scripture itself is clear (or "perspicuous"), because of the help of the Holy Spirit, or both. Martin Luther believed that without God's help Scripture would be "enveloped in darkness". He advocated "one definite and simple understanding of Scripture". John Calvin wrote, "all who refuse not to follow the Holy Spirit as their guide, find in the Scripture a clear light". The Second Helvetic Confession, composed by the pastor of the Reformed church in Zürich (successor to Protestant reformer Zwingli) was adopted as a declaration of doctrine by most European Reformed churches.

Protestants stress the meaning conveyed by the words of Scripture, the historical-grammatical method. The historical-grammatical method or grammatico-historical method is an effort in Biblical hermeneutics to find the intended original meaning in the text. This original intended meaning of the text is drawn out through examination of the passage in light of the grammatical and syntactical aspects, the historical background, the literary genre as well as theological (canonical) considerations. The historical-grammatical method distinguishes between the one original meaning and the significance of the text. The significance of the text includes the ensuing use of the text or application. The original passage is seen as having only a single meaning or sense. As Milton S. Terry said: "A fundamental principle in grammatico-historical exposition is that the words and sentences can have but one significance in one and the same connection. The moment we neglect this principle we drift out upon a sea of uncertainty and conjecture." Technically speaking, the grammatical-historical method of interpretation is distinct from the determination of the passage's significance in light of that interpretation. Taken together, both define the term (Biblical) hermeneutics.

Some Protestant interpreters make use of typology.

The end of things, whether the end of an individual life, the end of the age, or the end of the world, broadly speaking is Christian eschatology; the study of the destiny of humans as it is revealed in the Bible. The major issues in Christian eschatology are the Tribulation, death and the afterlife, the Rapture, the Second Coming of Jesus, Resurrection of the Dead, Heaven and Hell, Millennialism, the Last Judgment, the end of the world and the New Heavens and New Earth.

Christians believe that the second coming of Christ will occur at the end of time after a period of severe persecution (the Great Tribulation). All who have died will be resurrected bodily from the dead for the Last Judgment. Jesus will fully establish the Kingdom of God in fulfillment of scriptural prophecies.

Most Christians believe that human beings experience divine judgment and are rewarded either with eternal life or eternal damnation. This includes the general judgement at the resurrection of the dead as well as the belief (held by Catholics, Orthodox and most Protestants) in a judgment particular to the individual soul upon physical death.

In Catholicism, those who die in a state of grace, i.e., without any mortal sin separating them from God, but are still imperfectly purified from the effects of sin, undergo purification through the intermediate state of purgatory to achieve the holiness necessary for entrance into God's presence. Those who have attained this goal are called "saints" (Latin "sanctus", "holy").

Some Christian groups, such as Seventh-day Adventists, hold to mortalism, the belief that the human soul is not naturally immortal, and is unconscious during the intermediate state between bodily death and resurrection. These Christians also hold to Annihilationism, the belief that subsequent to the final judgement, the wicked will cease to exist rather than suffer everlasting torment. Jehovah's Witnesses hold to a similar view.

Justin Martyr described 2nd-century Christian liturgy in his "First Apology" (c. 150) to Emperor Antoninus Pius, and his description remains relevant to the basic structure of Christian liturgical worship:

And on the day called Sunday, all who live in cities or in the country gather together to one place, and the memoirs of the apostles or the writings of the prophets are read, as long as time permits; then, when the reader has ceased, the president verbally instructs, and exhorts to the imitation of these good things. Then we all rise together and pray, and, as we before said, when our prayer is ended, bread and wine and water are brought, and the president in like manner offers prayers and thanksgivings, according to his ability, and the people assent, saying Amen; and there is a distribution to each, and a participation of that over which thanks have been given, and to those who are absent a portion is sent by the deacons. And they who are well to do, and willing, give what each thinks fit; and what is collected is deposited with the president, who succours the orphans and widows and those who, through sickness or any other cause, are in want, and those who are in bonds and the strangers sojourning among us, and in a word takes care of all who are in need.

Thus, as Justin described, Christians assemble for communal worship on Sunday, the day of the resurrection, though other liturgical practices often occur outside this setting. Scripture readings are drawn from the Old and New Testaments, but especially the gospel accounts. Often these are arranged on an annual cycle, using a book called a lectionary. Instruction is given based on these readings, called a sermon, or homily. There are a variety of congregational prayers, including thanksgiving, confession and intercession, which occur throughout the service and take a variety of forms including recited, responsive, silent, or sung. The Lord's Prayer, or Our Father, is regularly prayed.
Some groups depart from this traditional liturgical structure. A division is often made between "High" church services, characterized by greater solemnity and ritual, and "Low" services, but even within these two categories there is great diversity in forms of worship. Seventh-day Adventists meet on Saturday, while others do not meet on a weekly basis. Charismatic or Pentecostal congregations may spontaneously feel led by the Holy Spirit to action rather than follow a formal order of service, including spontaneous prayer. Quakers sit quietly until moved by the Holy Spirit to speak.

Some evangelical services resemble concerts with rock and pop music, dancing and use of multimedia. For groups which do not recognize a priesthood distinct from ordinary believers the services are generally led by a minister, preacher, or pastor. Still others may lack any formal leaders, either in principle or by local necessity. Some churches use only a cappella music, either on principle (for example, many Churches of Christ object to the use of instruments in worship) or by tradition (as in Orthodoxy).

Nearly all forms of churchmanship celebrate the Eucharist (Holy Communion), which consists of a consecrated meal. It is reenacted in accordance with Jesus' instruction at the Last Supper that his followers do in remembrance of him as when he gave his disciples bread, saying, "This is my body", and gave them wine saying, "This is my blood". Some Christian denominations practice closed communion. They offer communion to those who are already united in that denomination or sometimes individual church. Catholics restrict participation to their members who are not in a state of mortal sin. Most other churches practice open communion since they view communion as a means to unity, rather than an end, and invite all believing Christians to participate.

Worship can be varied for special events like baptisms or weddings in the service or significant feast days. In the early church, Christians and those yet to complete initiation would separate for the Eucharistic part of the worship. In many churches today, adults and children will separate for all or some of the service to receive age-appropriate teaching. Such children's worship is often called Sunday school or Sabbath school (Sunday schools are often held before rather than during services).

In Christian belief and practice, a "sacrament" is a rite, instituted by Christ, that confers grace, constituting a sacred mystery. The term is derived from the Latin word "sacramentum", which was used to translate the Greek word for "mystery". Views concerning both which rites are sacramental, and what it means for an act to be a sacrament, vary among Christian denominations and traditions.

The most conventional functional definition of a sacrament is that it is an outward sign, instituted by Christ, that conveys an inward, spiritual grace through Christ. The two most widely accepted sacraments are Baptism and the Eucharist (or Holy Communion), however, the majority of Christians also recognize five additional sacraments: Confirmation (Chrismation in the Orthodox tradition), Holy orders (ordination), Penance (or Confession), Anointing of the Sick and Matrimony (see Christian views on marriage).

Taken together, these are the Seven Sacraments as recognized by churches in the High Church tradition—notably Catholic, Eastern Orthodox, Oriental Orthodox, Independent Catholic, Old Catholic, many Anglicans and some Lutherans. Most other denominations and traditions typically affirm only Baptism and Eucharist as sacraments, while some Protestant groups, such as the Quakers, reject sacramental theology. Christian denominations, such as Baptists, which believe these rites do not communicate grace, prefer to call Baptism and Holy Communion "ordinances" rather than sacraments.

In addition to this, the Church of the East has two additional sacraments in place of the traditional sacraments of Matrimony and the Anointing of the Sick. These include Holy Leaven (Melka) and the sign of the cross.

Catholics, Anglicans, Eastern Christians and traditional Protestant communities frame worship around the liturgical year. The liturgical cycle divides the year into a series of seasons, each with their theological emphases, and modes of prayer, which can be signified by different ways of decorating churches, colours of paraments and vestments for clergy, scriptural readings, themes for preaching and even different traditions and practices often observed personally or in the home.

Western Christian liturgical calendars are based on the cycle of the Roman Rite of the Catholic Church, and Eastern Christians use analogous calendars based on the cycle of their respective rites. Calendars set aside holy days, such as solemnities which commemorate an event in the life of Jesus, Mary or the saints, and periods of fasting, such as Lent and other pious events such as memoria or lesser festivals commemorating saints. Christian groups that do not follow a liturgical tradition often retain certain celebrations, such as Christmas, Easter and Pentecost: these are the celebrations of Christ's birth, resurrection and the descent of the Holy Spirit upon the Church, respectively. A few denominations make no use of a liturgical calendar.

Christianity has not generally practiced aniconism, or the avoidance or prohibition of types of images, even if the early Jewish Christians sects, as well as some modern denominations, preferred to some extent not to use figures in their symbols, by invoking the Decalogue's prohibition of idolatry.

The cross, which is today one of the most widely recognized symbols in the world, was used as a Christian symbol from the earliest times. Tertullian, in his book "De Corona", tells how it was already a tradition for Christians to trace repeatedly on their foreheads the sign of the cross. Although the cross was known to the early Christians, the crucifix did not appear in use until the 5th century.

Among the symbols employed by the primitive Christians, that of the fish or Ichthys seems to have ranked first in importance. From monumental sources such as tombs it is known that the symbolic fish was familiar to Christians from the earliest times. The fish was depicted as a Christian symbol in the first decades of the 2nd century. Its popularity among Christians was due principally, it would seem, to the famous acrostic consisting of the initial letters of five Greek words forming the word for fish (Ichthys), which words briefly but clearly described the character of Christ and the claim to worship of believers: "Iesous Christos Theou Yios Soter" (Ίησοῦς Χριστός, Θεοῦ Υἱός, Σωτήρ), meaning, "Jesus Christ, Son of God, Savior".

Other major Christian symbols include the chi-rho monogram, the dove (symbolic of the Holy Spirit), the sacrificial lamb (symbolic of Christ's sacrifice), the vine (symbolizing the necessary connectedness of the Christian with Christ) and many others. These all derive from writings found in the New Testament.

Baptism is the ritual act, with the use of water, by which a person is admitted to membership of the Church. Beliefs on baptism vary among denominations. Differences occur firstly on whether the act has any spiritual significance. Some, such as the Catholic and Eastern Orthodox churches, as well as Lutherans and Anglicans, hold to the doctrine of baptismal regeneration, which affirms that baptism creates or strengthens a person's faith, and is intimately linked to salvation. Others view baptism as a purely symbolic act, an external public declaration of the inward change which has taken place in the person, but not as spiritually efficacious. Secondly, there are differences of opinion on the methodology of the act. These methods are: by "immersion"; if immersion is total, by "submersion"; by affusion (pouring); and by aspersion (sprinkling). Those who hold the first view may also adhere to the tradition of infant baptism; the Orthodox Churches all practice infant baptism and always baptize by total immersion repeated three times in the name of the Father, the Son and the Holy Spirit. The Catholic Church also practices infant baptism, usually by affusion, and utilizing the Trinitarian formula.

Jesus' teaching on prayer in the Sermon on the Mount displays a distinct lack of interest in the external aspects of prayer. A concern with the techniques of prayer is condemned as 'pagan', and instead a simple trust in God's fatherly goodness is encouraged. Elsewhere in the New Testament this same freedom of access to God is also emphasized. This confident position should be understood in light of Christian belief in the unique relationship between the believer and Christ through the indwelling of the Holy Spirit.

In subsequent Christian traditions, certain physical gestures are emphasized, including medieval gestures such as genuflection or making the sign of the cross. Kneeling, bowing and prostrations (see also poklon) are often practiced in more traditional branches of Christianity. Frequently in Western Christianity the hands are placed palms together and forward as in the feudal commendation ceremony. At other times the older orans posture may be used, with palms up and elbows in.

"Intercessory prayer" is prayer offered for the benefit of other people. There are many intercessory prayers recorded in the Bible, including prayers of the Apostle Peter on behalf of sick persons and by prophets of the Old Testament in favor of other people. In the Epistle of James, no distinction is made between the intercessory prayer offered by ordinary believers and the prominent Old Testament prophet Elijah. The effectiveness of prayer in Christianity derives from the power of God rather than the status of the one praying.

The ancient church, in both Eastern Christianity and Western Christianity, developed a tradition of asking for the intercession of (deceased) saints, and this remains the practice of most Eastern Orthodox, Oriental Orthodox, Catholic, and some Anglican churches. Churches of the Protestant Reformation, however, rejected prayer to the saints, largely on the basis of the sole mediatorship of Christ. The reformer Huldrych Zwingli admitted that he had offered prayers to the saints until his reading of the Bible convinced him that this was idolatrous.

According to the Catechism of the Catholic Church: "Prayer is the raising of one's mind and heart to God or the requesting of good things from God." The Book of Common Prayer in the Anglican tradition is a guide which provides a set order for church services, containing set prayers, scripture readings, and hymns or sung Psalms.

Christianity began as a Jewish sect in the Levant of the middle east in the mid-1st century. Other than Second Temple Judaism, the primary religious influences of early Christianity are Zoroastrianism and Gnosticism. John Bowker states that Christian ideas such as "angels, the end of the world, a final judgment, the resurrection and heaven and hell received form and substance from ... Zoroastrian beliefs". Its earliest development took place under the leadership of the remaining Twelve Apostles, particularly Saint Peter, and Paul the Apostle, followed by the early bishops, whom Christians consider the successors of the Apostles.

According to the Christian scriptures, Christians were from the beginning subject to persecution by some Jewish and Roman religious authorities, who disagreed with the apostles' teachings (See Split of early Christianity and Judaism). This involved punishments, including death, for Christians such as Stephen and James, son of Zebedee. Larger-scale persecutions followed at the hands of the authorities of the Roman Empire, first in the year 64, when Emperor Nero blamed them for the Great Fire of Rome. According to Church tradition, it was under Nero's persecution that early Church leaders Peter and Paul of Tarsus were each martyred in Rome.

Further widespread persecutions of the Church occurred under nine subsequent Roman emperors, most intensely under Decius and Diocletian. From the year 150, Christian teachers began to produce theological and apologetic works aimed at defending the faith. These authors are known as the Church Fathers, and study of them is called Patristics. Notable early Fathers include Ignatius of Antioch, Polycarp, Justin Martyr, Irenaeus, Tertullian, Clement of Alexandria and Origen. However, Armenia is considered the first nation to accept Christianity in AD 301.

King Trdat IV made Christianity the state religion in Armenia between 301 and 314, it was not an entirely new religion in Armenia. It penetrated into the country from at least the third century, but may have been present even earlier.

State persecution ceased in the 4th century, when Constantine I issued an edict of toleration in 313. On 27 February 380, Emperor Theodosius I enacted a law establishing Nicene Christianity as the state church of the Roman Empire. From at least the 4th century, Christianity has played a prominent role in the shaping of Western civilization.

Constantine was also instrumental in the convocation of the First Council of Nicaea in 325, which sought to address the Arian heresy and formulated the Nicene Creed, which is still used by the Catholic Church, Eastern Orthodoxy, Anglican Communion and many Protestant churches. Nicaea was the first of a series of Ecumenical (worldwide) Councils which formally defined critical elements of the theology of the Church, notably concerning Christology. The Assyrian Church of the East did not accept the third and following Ecumenical Councils, and are still separate today.

The presence of Christianity in Africa began in the middle of the 1st century in Egypt, and by the end of the 2nd century in the region around Carthage. Mark the Evangelist started the Coptic Orthodox Church of Alexandria in about AD 43. Important Africans who influenced the early development of Christianity includes Tertullian, Clement of Alexandria, Origen of Alexandria, Cyprian, Athanasius and Augustine of Hippo. The later rise of Islam in North Africa reduced the size and numbers of Christian congregations, leaving only the Coptic Church in Egypt, the Ethiopian Orthodox Tewahedo Church in the Horn of Africa and the Nubian Church in the Sudan (Nobatia, Makuria and Alodia).

In terms of prosperity and cultural life, the Byzantine Empire was one of the peaks in Christian history and Christian civilization, and Constantinople remained the leading city of the Christian world in size, wealth and culture. There was a renewed interest in classical Greek philosophy, as well as an increase in literary output in vernacular Greek. Byzantine art and literature held a pre-eminent place in Europe, and the cultural impact of Byzantine art on the west during this period was enormous and of long lasting significance.

With the decline and fall of the Roman Empire in the west, the papacy became a political player, first visible in Pope Leo's diplomatic dealings with Huns and Vandals. The church also entered into a long period of missionary activity and expansion among the various tribes. While Arianists instituted the death penalty for practicing pagans (see Massacre of Verden as example), Catholicism also spread among the Germanic peoples, the Celtic and Slavic peoples, the Hungarians and the Baltic peoples. Christianity has been an important part of the shaping of Western civilization, at least since the 4th century.

Around 500, St. Benedict set out his Monastic Rule, establishing a system of regulations for the foundation and running of monasteries. Monasticism became a powerful force throughout Europe, and gave rise to many early centers of learning, most famously in Ireland, Scotland and Gaul, contributing to the Carolingian Renaissance of the 9th century.

In the 7th century Muslims conquered Syria (including Jerusalem), North Africa and Spain. Part of the Muslims' success was due to the exhaustion of the Byzantine empire in its decades long conflict with Persia. Beginning in the 8th century, with the rise of Carolingian leaders, the papacy began to find greater political support in the Frankish Kingdom.

The Middle Ages brought about major changes within the church. Pope Gregory the Great dramatically reformed ecclesiastical structure and administration. In the early 8th century, iconoclasm became a divisive issue, when it was sponsored by the Byzantine emperors. The Second Ecumenical Council of Nicaea (787) finally pronounced in favor of icons. In the early 10th century, Western Christian monasticism was further rejuvenated through the leadership of the great Benedictine monastery of Cluny.

Hebraism, like Hellenism, has been an all-important factor in the development of Western Civilization; Judaism, as the precursor of Christianity, has indirectly had much to do with shaping the ideals and morality of western nations since the Christian era.

In the west, from the 11th century onward, older cathedral schools developed into universities (see University of Oxford, University of Paris and University of Bologna.) The traditional medieval universities—evolved from Catholic and Protestant church schools—then established specialized academic structures for properly educating greater numbers of students as professionals. Prof. Walter Rüegg, editor of "A History of the University in Europe", reports that universities then only trained students to become clerics, lawyers, civil servants and physicians.

Originally teaching only theology, universities steadily added subjects including medicine, philosophy and law, becoming the direct ancestors of modern institutions of learning.
The university is generally regarded as an institution that has its origin in the Medieval Christian setting. Prior to the establishment of universities, European higher education took place for hundreds of years in Christian cathedral schools or monastic schools ("Scholae monasticae"), in which monks and nuns taught classes; evidence of these immediate forerunners of the later university at many places dates back to the 6th century AD.

Accompanying the rise of the "new towns" throughout Europe, mendicant orders were founded, bringing the consecrated religious life out of the monastery and into the new urban setting. The two principal mendicant movements were the Franciscans and the Dominicans founded by St. Francis and St. Dominic respectively. Both orders made significant contributions to the development of the great universities of Europe. Another new order were the Cistercians, whose large isolated monasteries spearheaded the settlement of former wilderness areas. In this period church building and ecclesiastical architecture reached new heights, culminating in the orders of Romanesque and Gothic architecture and the building of the great European cathedrals.

From 1095 under the pontificate of Urban II, the Crusades were launched. These were a series of military campaigns in the Holy Land and elsewhere, initiated in response to pleas from the Byzantine Emperor Alexios I for aid against Turkish expansion. The Crusades ultimately failed to stifle Islamic aggression and even contributed to Christian enmity with the sacking of Constantinople during the Fourth Crusade.

Over a period stretching from the 7th to the 13th century, the Christian Church underwent gradual alienation, resulting in a schism dividing it into a so-called Latin or Western Christian branch, the Catholic Church, and an Eastern, largely Greek, branch, the Orthodox Church. These two churches disagree on a number of administrative, liturgical and doctrinal issues, most notably papal primacy of jurisdiction. The Second Council of Lyon (1274) and the Council of Florence (1439) attempted to reunite the churches, but in both cases the Eastern Orthodox refused to implement the decisions and the two principal churches remain in schism to the present day. However, the Catholic Church has achieved union with various smaller eastern churches.

Beginning around 1184, following the crusade against the Cathar heresy, various institutions, broadly referred to as the Inquisition, were established with the aim of suppressing heresy and securing religious and doctrinal unity within Christianity through conversion and prosecution.

15th-century Renaissance brought about a renewed interest in ancient and classical learning. Another major schism, the Reformation, resulted in the splintering of the Western Christendom into several branches. Martin Luther in 1517 protested against the sale of indulgences and soon moved on to deny several key points of Catholic doctrine.

Other reformers like Zwingli, Oecolampadius, Calvin, Knox and Arminius further criticized Catholic teaching and worship. These challenges developed into the movement called Protestantism, which repudiated the primacy of the pope, the role of tradition, the seven sacraments and other doctrines and practices. The Reformation in England began in 1534, when King Henry VIII had himself declared head of the Church of England. Beginning in 1536, the monasteries throughout England, Wales and Ireland were dissolved.

Thomas Müntzer, Andreas Karlstadt and other theologians perceived both the Catholic Church and the confessions of the Magisterial Reformation as corrupted. Their activity brought about the Radical Reformation, which gave birth to various Anabaptist denominations.
Partly in response to the Protestant Reformation, the Catholic Church engaged in a substantial process of reform and renewal, known as the Counter-Reformation or Catholic Reform. The Council of Trent clarified and reasserted Catholic doctrine. During the following centuries, competition between Catholicism and Protestantism became deeply entangled with political struggles among European states.

Meanwhile, the discovery of America by Christopher Columbus in 1492 brought about a new wave of missionary activity. Partly from missionary zeal, but under the impetus of colonial expansion by the European powers, Christianity spread to the Americas, Oceania, East Asia and sub-Saharan Africa.

Throughout Europe, the divides caused by the Reformation led to outbreaks of religious violence and the establishment of separate state churches in Europe. Lutheranism spread into northern, central and eastern parts of present-day Germany, Livonia and Scandinavia. Anglicanism was established in England in 1534. Calvinism and its varieties (such as Presbyterianism) were introduced in Scotland, the Netherlands, Hungary, Switzerland and France. Arminianism gained followers in the Netherlands and Frisia. Ultimately, these differences led to the outbreak of conflicts in which religion played a key factor. The Thirty Years' War, the English Civil War and the French Wars of Religion are prominent examples. These events intensified the Christian debate on persecution and toleration.

In the era known as the Great Divergence, when in the West the Age of Enlightenment and the Scientific revolution brought about great societal changes, Christianity was confronted with various forms of skepticism and with certain modern political ideologies such as versions of socialism and liberalism. Events ranged from mere anti-clericalism to violent outbursts against Christianity such as the Dechristianisation during the French Revolution, the Spanish Civil War and certain Marxist movements, especially the Russian Revolution and the persecution of Christians in the Soviet Union under state atheism.

Especially pressing in Europe was the formation of nation states after the Napoleonic era. In all European countries, different Christian denominations found themselves in competition, to greater or lesser extents, with each other and with the state. Variables are the relative sizes of the denominations and the religious, political and ideological orientation of the state. Urs Altermatt of the University of Fribourg, looking specifically at Catholicisms in Europe, identifies four models for the European nations. In traditionally Catholic countries such as Belgium, Spain and to some extent Austria, religious and national communities are more or less identical. Cultural symbiosis and separation are found in Poland, Ireland and Switzerland, all countries with competing denominations. Competition is found in Germany, the Netherlands and again Switzerland, all countries with minority Catholic populations who to a greater or lesser extent did identify with the nation. Finally, separation between religion (again, specifically Catholicism) and the state is found to a great degree in France and Italy, countries where the state actively opposed itself to the authority of the Catholic Church.

The combined factors of the formation of nation states and ultramontanism, especially in Germany and the Netherlands but also in England (to a much lesser extent), often forced Catholic churches, organizations and believers to choose between the national demands of the state and the authority of the Church, specifically the papacy. This conflict came to a head in the First Vatican Council, and in Germany would lead directly to the Kulturkampf, where liberals and Protestants under the leadership of Bismarck managed to severely restrict Catholic expression and organization.

Christian commitment in Europe dropped as modernity and secularism came into their own in Europe, particularly in the Czech Republic and Estonia, while religious commitments in America have been generally high in comparison to Europe. The late 20th century has shown the shift of Christian adherence to the Third World and southern hemisphere in general, with the western civilization no longer the chief standard bearer of Christianity.

Some Europeans (including diaspora), Indigenous peoples of the Americas and natives of other continents have revived their respective peoples' historical folk religions. Approximately 7.1 to 10% of Arabs are Christians, most prevalent in Egypt, Syria and Lebanon.

With around 2.4 billion adherents, split into three main branches of Catholic, Protestant and Eastern Orthodox, Christianity is the world's largest religion. The Christian share of the world's population has stood at around 33% for the last hundred years, which says that one in three persons on earth are Christians. This masks a major shift in the demographics of Christianity; large increases in the developing world have been accompanied by substantial declines in the developed world, mainly in Europe and North America. According to a 2015 Pew Research Center study, within the next four decades, Christians will remain the world's largest religion; and by 2050, the Christian population is expected to exceed 3 billion.

As a percentage of Christians, the Catholic Church and Orthodoxy (both Eastern and Oriental) are declining, while Protestants and other Christians are on the rise. The so-called "popular Protestantism" is one of the fastest growing religious categories in the world.

Christianity is the predominant religion in Europe, the Americas and Southern Africa. In Asia, it is the dominant religion in Georgia, Armenia, East Timor and the Philippines. However, it is declining in many areas including the Northern and Western United States, Oceania (Australia and New Zealand), northern Europe (including Great Britain, Scandinavia and other places), France, Germany, the Canadian provinces of Ontario, British Columbia and Quebec, and parts of Asia (especially the Middle East – due to the Christian emigration, South Korea, Taiwan, and Macau).

The Christian population is not decreasing in Brazil, the Southern United States and the province of Alberta, Canada, but the percentage is decreasing. In countries such as Australia and New Zealand, the Christian population are declining in both numbers and percentage.

Despite the declining numbers, Christianity remains the dominant religion in the Western World, where 70% are Christians. A 2011 Pew Research Center survey found that 76.2% of Europeans, 73.3% in Oceania and about 86.0% in the Americas (90.0% in Latin America and 77.4% in North America) identified themselves as Christians. By 2010 about 157 countries and territories in the world had Christian majorities.

However, there are many charismatic movements that have become well established over large parts of the world, especially Africa, Latin America and Asia. Since 1900, primarily due to conversion, Protestantism has spread rapidly in Africa, Asia, Oceania and Latin America. From 1960 to 2000, the global growth of the number of reported Evangelical Protestants grew three times the world's population rate, and twice that of Islam. St. Mary's University study estimated about 10.2 million Muslim convert to Christianity in 2015. as well a significant numbers of Muslims converts to Christianity in Afghanistan, Albania, Azerbaijan Algeria, Belgium, France, Germany, Iran, India, Indonesia, Malaysia, Morocco, Russia, Netherlands, Saudi Arabia, Tunisia, Turkey, Kazakhstan, Kyrgyzstan, Kosovo, United States, and Central Asia. It is also reported that Christianity is popular among people of different backgrounds in India (mostly Hindus), and Malaysia, Mongolia, Nigeria, Vietnam, Singapore, Indonesia, China, Japan, and South Korea.

In most countries in the developed world, church attendance among people who continue to identify themselves as Christians has been falling over the last few decades. Some sources view this simply as part of a drift away from traditional membership institutions, while others link it to signs of a decline in belief in the importance of religion in general. Europe's Christian population, though in decline, still constitutes the largest geographical component of the religion. According to data from the 2012 European Social Survey, around a third of European Christians say they attend services once a month or more, Conversely about more than two-thirds of Latin American Christians and according to the World Values Survey about 90% of African Christians (in Ghana, Nigeria, Rwanda, South Africa and Zimbabwe) said they attended church regularly.

Christianity, in one form or another, is the sole state religion of the following nations: Argentina (Catholic), Tuvalu (Reformed), Tonga (Methodist), Norway (Lutheran), Costa Rica (Catholic), Kingdom of Denmark (Lutheran), England (Anglican), Georgia (Georgian Orthodox), Greece (Greek Orthodox), Iceland (Lutheran), Liechtenstein (Catholic), Malta (Catholic), Monaco (Catholic), and Vatican City (Catholic).

There are numerous other countries, such as Cyprus, which although do not have an established church, still give official recognition and support to a specific Christian denomination.

<br>
<br>

The three primary divisions of Christianity are Catholicism, Eastern Orthodoxy and Protestantism. However, there are other present and historical Christian groups that do not fit neatly into one of these primary categories. The Nicene Creed is accepted as authoritative by most Christians, including the Catholic, Eastern Orthodox, Anglican and major Protestant churches.

There is a diversity of doctrines and practices among groups calling themselves Christian. These groups are sometimes classified under denominations, though for theological reasons many groups reject this classification system. A broader distinction that is sometimes drawn is between Eastern Christianity and Western Christianity, which has its origins in the East–West Schism (Great Schism) of the 11th century.

In addition to the Lutheran and Reformed (or Calvinist) branches of the Reformation, there is Anglicanism after the English Reformation. The Anabaptist tradition was largely ostracized by the other Protestant parties at the time, but has achieved a measure of affirmation in more recent history. Adventist, Baptist, Methodist, Pentecostal and other Protestant confessions arose in the following centuries.

The Catholic Church consists of those particular Churches, headed by bishops, in communion with the Pope, the Bishop of Rome, as its highest authority in matters of faith, morality and Church governance. Like Eastern Orthodoxy, the Catholic Church, through apostolic succession, traces its origins to the Christian community founded by Jesus Christ. Catholics maintain that the "one, holy, catholic and apostolic church" founded by Jesus subsists fully in the Catholic Church, but also acknowledges other Christian churches and communities and works towards reconciliation among all Christians. The Catholic faith is detailed in the "Catechism of the Catholic Church".

The 2,834 sees are grouped into 24 particular autonomous Churches (the largest of which being the Latin Church), each with its own distinct traditions regarding the liturgy and the administering the sacraments. With more than 1.1 billion baptized members, the Catholic Church is the largest Christian church and represents over half of all Christians as well as one sixth of the world's population.

The Eastern Orthodox Church consists of those churches in communion with the Patriarchal Sees of the East, such as the Ecumenical Patriarch of Constantinople. Like the Catholic Church, the Eastern Orthodox Church also traces its heritage to the foundation of Christianity through apostolic succession and has an episcopal structure, though the autonomy of its component parts is emphasized, and most of them are national churches. A number of conflicts with Western Christianity over questions of doctrine and authority culminated in the Great Schism. Eastern Orthodoxy is the second largest single denomination in Christianity, with an estimated 225–300 million adherents.

The Oriental Orthodox churches (also called "Old Oriental" churches) are those eastern churches that recognize the first three ecumenical councils—Nicaea, Constantinople and Ephesus—but reject the dogmatic definitions of the Council of Chalcedon and instead espouse a Miaphysite christology. The Oriental Orthodox communion consists of six groups: Syriac Orthodox, Coptic Orthodox, Ethiopian Orthodox, Eritrean Orthodox, Malankara Orthodox Syrian Church (India) and Armenian Apostolic churches. These six churches, while being in communion with each other are completely independent hierarchically. These churches are generally not in communion with Eastern Orthodox Churches with whom they are in dialogue for erecting a communion.

The Assyrian Church of the East, with an unbroken patriarchate established in the 17th century, is an independent Eastern Christian denomination which claims continuity from the Church of the East – in parallel to the Catholic patriarchate established in the 16th century that evolved into the Chaldean Catholic Church, an Eastern Catholic church in full communion with the Pope.

In the 16th century, Martin Luther, and subsequently Huldrych Zwingli and John Calvin, inaugurated what has come to be called Protestantism. Luther's primary theological heirs are known as Lutherans. Zwingli and Calvin's heirs are far broader denominationally, and are broadly referred to as the Reformed tradition. The oldest Protestant groups separated from the Catholic Church in the Protestant Reformation, often followed by further divisions.

In the 18th century, for example, Methodism grew out of Anglican minister John Wesley's evangelical and revival movement. Several Pentecostal and non-denominational churches, which emphasize the cleansing power of the Holy Spirit, in turn grew out of Methodism. Because Methodists, Pentecostals and other evangelicals stress "accepting Jesus as your personal Lord and Savior", which comes from Wesley's emphasis of the New Birth, they often refer to themselves as being born-again.

Estimates of the total number of Protestants are very uncertain, but it seems clear that Protestantism is the second largest major group of Christians after Catholicism in number of followers (although the Eastern Orthodox Church is larger than any single Protestant denomination). Often that number is put at more than 800 million, corresponding to nearly 40% of world's Christians. The majority of Protestants are members of just a handful of denominational families, i.e. Adventists, Anglicans, Baptists, Reformed (Calvinists), Lutherans, Methodists and Pentecostals. Nondenominational, evangelical, charismatic, neo-charismatic, independent and other churches are on the rise, and constitute a significant part of Protestant Christianity.

A special grouping are the Anglican churches descended from the Church of England and organized in the Anglican Communion. Some Anglican churches consider themselves both Protestant and Catholic. Some Anglicans consider their church a branch of the "One Holy Catholic Church" alongside of the Catholic and Eastern Orthodox churches, a concept rejected by the Catholic Church and some Eastern Orthodox.

While Anglicans, Lutherans and the Reformed branches of Protestantism originated in the Magisterial Reformation, other Protestant groups such as the Anabaptists originated in the Radical Reformation and are distinguished by their rejection of infant baptism; they believe in baptism only of adult believers — credobaptism. (Anabaptists are made up mostly of Amish, Mennonites, Hutterites and Schwarzenau Brethren/German Baptist groups.) 

Some groups of individuals who hold basic Protestant tenets identify themselves simply as "Christians" or "born-again Christians". They typically distance themselves from the confessionalism and/or creedalism of other Christian communities by calling themselves "non-denominational" or "evangelical". Often founded by individual pastors, they have little affiliation with historic denominations.<ref name="Pew Forum on Religion & Public Life / U.S. Religious Landscape Survey"></ref>

The Second Great Awakening, a period of religious revival that occurred in the United States during the early 1800s, saw the development of a number of unrelated churches. They generally saw themselves as restoring the original church of Jesus Christ rather than reforming one of the existing churches. A common belief held by Restorationists was that the other divisions of Christianity had introduced doctrinal defects into Christianity, which was known as the Great Apostasy. In Asia, Iglesia ni Cristo is a known restorationist religion that was established during the early 1900s.

Some of the churches originating during this period are historically connected to early 19th-century camp meetings in the Midwest and Upstate New York. American Millennialism and Adventism, which arose from Evangelical Protestantism, influenced the Jehovah's Witnesses movement and, as a reaction specifically to William Miller, the Seventh-day Adventists. Others, including the Christian Church (Disciples of Christ), Evangelical Christian Church in Canada, Churches of Christ, and the Christian churches and churches of Christ, have their roots in the contemporaneous Stone-Campbell Restoration Movement, which was centered in Kentucky and Tennessee. Other groups originating in this time period include the Christadelphians and Latter Day Saint movement. While the churches originating in the Second Great Awakening have some superficial similarities, their doctrine and practices vary significantly.

Various smaller Independent Catholic communities, such as the Old Catholic Church, include the word "Catholic" in their title, and arguably have more or less liturgical practices in common with the Catholic Church, but are no longer in full communion with the Holy See.

Esoteric Christians regard Christianity as a mystery religion, and profess the existence and possession of certain esoteric doctrines or practices, hidden from the public but accessible only to a narrow circle of "enlightened", "initiated", or highly educated people. Some of the esoteric Christian institutions include the Rosicrucian Fellowship, the Anthroposophical Society and Martinism.

Messianic Judaism (or Messianic Movement) is the name of a Christian movement comprising a number of streams, whose members may consider themselves Jewish. The movement originated in the 1960s and 1970s, and it blends elements of religious Jewish practice with evangelical Christianity. Messianic Judaism affirms Christian creeds such as the messiahship and divinity of "Yeshua" (the Hebrew name of Jesus) and the Triune Nature of God, while also adhering to some Jewish dietary laws and customs.

Western culture, throughout most of its history, has been nearly equivalent to Christian culture, and a large portion of the population of the Western hemisphere can be described as cultural Christians. The notion of "Europe" and the "Western World" has been intimately connected with the concept of "Christianity and Christendom" many even attribute Christianity for being the link that created a unified European identity.

Though Western culture contained several polytheistic religions during its early years under the Greek and Roman empires, as the centralized Roman power waned, the dominance of the Catholic Church was the only consistent force in Europe. Until the Age of Enlightenment, Christian culture guided the course of philosophy, literature, art, music and science. Christian disciplines of the respective arts have subsequently developed into Christian philosophy, Christian art, Christian music, Christian literature etc.

Christianity has had a significant impact on education as the church created the bases of the Western system of education, and was the sponsor of founding universities in the Western world; as the university is generally regarded as an institution that has its origin in the Medieval Christian setting. Historically, Christianity has often been a patron of science and medicine. It has been prolific in the foundation of schools, universities and hospitals, and many Catholic clergy; Jesuits in particular, have been active in the sciences throughout history and have made significant contributions to the development of science. Protestantism also has had an important influence on science. According to the Merton Thesis, there was a positive correlation between the rise of English Puritanism and German Pietism on the one hand and early experimental science on the other. The Civilizing influence of Christianity includes social welfare, founding hospitals, economics (as the Protestant work ethic), politics, architecture, literature, personal hygiene, and family life.

Eastern Christians (particularly Nestorian Christians) contributed to the Arab Islamic Civilization during the reign of the Ummayad and the Abbasid by translating works of Greek philosophers to Syriac and afterwards to Arabic. They also excelled in philosophy, science, theology and medicine. And many scholars of the House of Wisdom were of Christian background.

Christians have made a myriad of contributions to human progress in a broad and diverse range of fields, including philosophy, science and technology, fine arts and architecture, politics, literatures, music, and business. According to "100 Years of Nobel Prizes" a review of Nobel prizes award between 1901 and 2000 reveals that (65.4%) of Nobel Prizes Laureates, have identified Christianity in its various forms as their religious preference.

"Postchristianity" is the term for the decline of Christianity, particularly in Europe, Canada, Australia and to a minor degree the Southern Cone, in the 20th and 21st centuries, considered in terms of postmodernism. It refers to the loss of Christianity's monopoly on values and world view in historically Christian societies.

Cultural Christians are secular people with a Christian heritage who may not believe in the religious claims of Christianity, but who retain an affinity for the popular culture, art, music and so on related to it. Another frequent application of the term is to distinguish political groups in areas of mixed religious backgrounds.

Christian groups and denominations have long expressed ideals of being reconciled, and in the 20th century, Christian ecumenism advanced in two ways. One way was greater cooperation between groups, such as the World Evangelical Alliance founded in 1846 in London or the Edinburgh Missionary Conference of Protestants in 1910, the Justice, Peace and Creation Commission of the World Council of Churches founded in 1948 by Protestant and Orthodox churches, and similar national councils like the National Council of Churches in Australia which includes Catholics.

The other way was institutional union with United and uniting churches, a practice that can be traced back to unions between Lutherans and Calvinists in early 19th-century Germany. Congregationalist, Methodist and Presbyterian churches united in 1925 to form the United Church of Canada, and in 1977 to form the Uniting Church in Australia. The Church of South India was formed in 1947 by the union of Anglican, Baptist, Methodist, Congregationalist and Presbyterian churches.

The ecumenical, monastic Taizé Community is notable for being composed of more than one hundred brothers from Protestant and Catholic traditions. The community emphasizes the reconciliation of all denominations and its main church, located in Taizé, Saône-et-Loire, France, is named the "Church of Reconciliation". The community is internationally known, attracting over 100,000 young pilgrims annually.
Steps towards reconciliation on a global level were taken in 1965 by the Catholic and Orthodox churches mutually revoking the excommunications that marked their Great Schism in 1054; the Anglican Catholic International Commission (ARCIC) working towards full communion between those churches since 1970; and some Lutheran and Catholic churches signing the Joint Declaration on the Doctrine of Justification in 1999 to address conflicts at the root of the Protestant Reformation. In 2006, the World Methodist Council, representing all Methodist denominations, adopted the declaration.

Criticism of Christianity and Christians goes back to the Apostolic Age, with the New Testament recording friction between the followers of Jesus and the Pharisees and scribes (e.g. and ). In the 2nd century, Christianity was criticized by the Jews on various grounds, e.g. that the prophecies of the Hebrew Bible could not have been fulfilled by Jesus, given that he did not have a successful life. Additionally a sacrifice to remove sins in advance, for everyone or as a human being, did not fit to the Jewish sacrifice ritual, furthermore God is said to judge people on their deeds instead of their beliefs. One of the first comprehensive attacks on Christianity came from the Greek philosopher Celsus, who wrote "The True Word", a polemic criticizing Christians as being unprofitable members of society. In response, the church father Origen published his treatise "Contra Celsum", or "Against Celsus", a seminal work of Christian apologetics, which systematically addressed Celsus's criticisms and brought Christianity a level of academic respectability.

By the 3rd century, criticism of Christianity had mounted, partly as a defense against it. Wild rumors about Christians were widely circulated, claiming that they were atheists and that, as part of their rituals, they devoured human infants and engaged in incestuous orgies. The Neoplatonist philosopher Porphyry wrote the fifteen-volume "Adversus Christianos" as a comprehensive attack on Christianity, in part building on the teachings of Plotinus.

By the 12th century, the Mishneh Torah (i.e., Rabbi Moses Maimonides) was criticizing Christianity on the grounds of idol worship, in that Christians attributed divinity to Jesus who had a physical body. In the 19th century, Nietzsche began to write a series of polemics on the "unnatural" teachings of Christianity (e.g. sexual abstinence), and continued his criticism of Christianity to the end of his life. In the 20th century, the philosopher Bertrand Russell expressed his criticism of Christianity in "Why I Am Not a Christian", formulating his rejection of Christianity in the setting of logical arguments.

Criticism of Christianity continues to date, e.g. Jewish and Muslim theologians criticize the doctrine of the Trinity held by most Christians, stating that this doctrine in effect assumes that there are three Gods, running against the basic tenet of monotheism. New Testament scholar Robert M. Price has outlined the possibility that some Bible stories are based partly on myth in "The Christ Myth Theory and its problems".

Christian apologetics aims to present a rational basis for Christianity. The word "apologetic" comes from the Greek word "apologeomai", meaning "in defense of". Christian apologetics has taken many forms over the centuries, starting with Paul the Apostle. The philosopher Thomas Aquinas presented five arguments for God's existence in the "Summa Theologica", while his "Summa contra Gentiles" was a major apologetic work. Another famous apologist, G. K. Chesterton, wrote in the early twentieth century about the benefits of religion and, specifically, Christianity. Famous for his use of paradox, Chesterton explained that while Christianity had the most mysteries, it was the most practical religion. He pointed to the advance of Christian civilizations as proof of its practicality. The physicist and priest John Polkinghorne, in his "Questions of Truth" discusses the subject of religion and science, a topic that other Christian apologists such as Ravi Zacharias, John Lennox and William Lane Craig have engaged, with the latter two men opining that the inflationary Big Bang model is evidence for the existence of God.






</doc>
<doc id="5213" url="https://en.wikipedia.org/wiki?curid=5213" title="Computing">
Computing

Computing is any goal-oriented activity requiring, benefiting from, or creating computers. Computing includes designing, developing and building hardware and software systems; designing a mathematical sequence of steps known as an algorithm; processing, structuring, and managing various kinds of information; doing scientific research on and with computers; making computer systems behave intelligently; and creating and using communications and entertainment media. The field of computing includes computer engineering, software engineering, computer science, information systems, and information technology.

The ACM "Computing Curricula 2005" defined "computing" as follows:

"In a general way, we can define computing to mean any goal-oriented activity requiring, benefiting from, or creating computers. Thus, computing includes designing and building hardware and software systems for a wide range of purposes; processing, structuring, and managing various kinds of information; doing scientific studies using computers; making computer systems behave intelligently; creating and using communications and entertainment media; finding and gathering information relevant to any particular purpose, and so on. The list is virtually endless, and the possibilities are vast."

and it defines five sub-disciplines of the "computing" field: Computer Science, Computer Engineering, Information Systems, information technology, and Software Engineering.

However, "Computing Curricula 2005" also recognizes that the meaning of "computing" depends on the context:

"Computing also has other meanings that are more specific, based on the context in which the term is used. For example, an information systems specialist will view computing somewhat differently from a software engineer. Regardless of the context, doing computing well can be complicated and difficult. Because society needs people to do computing well, we must think of computing not only as a profession but also as a discipline."

The term "computing" has sometimes been narrowly defined, as in a 1989 ACM report on "Computing as a Discipline":

"The discipline of computing is the systematic study of algorithmic
processes that describe and transform information: their theory, analysis, design, efficiency, implementation, and application. The fundamental question underlying all computing is "What can be (efficiently) automated?"

The term "computing" is also synonymous with counting and calculating. In earlier times, it was used in reference to the action performed by mechanical computing machines, and before that, to human computers .

The history of computing is longer than the history of computing hardware and modern computing technology and includes the history of methods intended for pen and paper or for chalk and slate, with or without the aid of tables.

Computing is intimately tied to the representation of numbers. But long before abstractions like "the number" arose, there were mathematical concepts to serve the purposes of civilization. These concepts include one-to-one correspondence (the basis of counting), comparison to a standard (used for measurement), and the "3-4-5" right triangle (a device for assuring a "right angle").

The earliest known tool for use in computation was the abacus, and it was thought to have been invented in Babylon circa 2400 BC. Its original style of usage was by lines drawn in sand with pebbles. Abaci, of a more modern design, are still used as calculation tools today. This was the first known calculation aid - preceding Greek methods by 2,000 years.

The first recorded idea of using digital electronics for computing was the 1931 paper "The Use of Thyratrons for High Speed Automatic Counting of Physical Phenomena" by C. E. Wynn-Williams. Claude Shannon's 1938 paper "A Symbolic Analysis of Relay and Switching Circuits" then introduced the idea of using electronics for Boolean algebraic operations.

A computer is a machine that manipulates data according to a set of instructions called a computer program. The program has an executable form that the computer can use directly to execute the instructions. The same program in its human-readable source code form, enables a programmer to study and develop a sequence of steps known as an algorithm. Because the instructions can be carried out in different types of computers, a single set of source instructions converts to machine instructions according to the central processing unit type.

The execution process carries out the instructions in a computer program. Instructions express the computations performed by the computer. They trigger sequences of simple actions on the executing machine. Those actions produce effects according to the semantics of the instructions.

Computer software or just "software", is a collection of computer programs and related data that provides the instructions for telling a computer what to do and how to do it. Software refers to one or more computer programs and data held in the storage of the computer for some purposes. In other words, software is a set of "programs, procedures, algorithms" and its "documentation" concerned with the operation of a data processing system. Program software performs the function of the program it implements, either by directly providing instructions to the computer hardware or by serving as input to another piece of software. The term was coined to contrast with the old term hardware (meaning physical devices). In contrast to hardware, software is intangible. Software is also sometimes used in a more narrow sense, meaning application software only.

Application software, also known as an "application" or an "app", is a computer software designed to help the user to perform specific tasks. Examples include enterprise software, accounting software, office suites, graphics software and media players. Many application programs deal principally with documents. Apps may be bundled with the computer and its system software, or may be published separately. Some users are satisfied with the bundled apps and need never install one.

Application software is contrasted with system software and middleware, which manage and integrate a computer's capabilities, but typically do not directly apply them in the performance of tasks that benefit the user. The system software serves the application, which in turn serves the user.

Application software applies the power of a particular computing platform or system software to a particular purpose. Some apps such as Microsoft Office are available in versions for several different platforms; others have narrower requirements and are thus called, for example, a Geography application for Windows or an Android application for education or Linux gaming. Sometimes a new and popular application arises that only runs on one platform, increasing the desirability of that platform. This is called a killer application.

System software, or systems software, is computer software designed to operate and control the computer hardware and to provide a platform for running application software. System software includes operating systems, utility software, device drivers, window systems, and firmware. Frequently development tools such as compilers, linkers, and debuggers are classified as system software.

A computer network, often simply referred to as a network, is a collection of hardware components and computers interconnected by communication channels that allow sharing of resources and information. Where at least one process in one device is able to send/receive data to/from at least one process residing in a remote device, then the two devices are said to be in a network.

Networks may be classified according to a wide variety of characteristics such as the medium used to transport the data, communications protocol used, scale, topology, and organizational scope.

Communications protocols define the rules and data formats for exchanging information in a computer network, and provide the basis for network programming. Well-known communications protocols are Ethernet, a hardware and Link Layer standard that is ubiquitous in local area networks, and the Internet Protocol Suite, which defines a set of protocols for internetworking, i.e. for data communication between multiple networks, as well as host-to-host data transfer, and application-specific data transmission formats.

Computer networking is sometimes considered a sub-discipline of electrical engineering, telecommunications, computer science, information technology or computer engineering, since it relies upon the theoretical and practical application of these disciplines.

The Internet is a global system of interconnected computer networks that use the standard Internet protocol suite (TCP/IP) to serve billions of users that consists of millions of private, public, academic, business, and government networks, of local to global scope, that are linked by a broad array of electronic, wireless and optical networking technologies. The Internet carries an extensive range of information resources and services, such as the inter-linked hypertext documents of the World Wide Web (WWW) and the infrastructure to support email.

Computer programming in general is the process of writing, testing, debugging, and maintaining the source code and documentation of computer programs. This source code is written in a programming language, which is an artificial language often more restrictive or demanding than natural languages, but easily translated by the computer. The purpose of programming is to invoke the desired behavior (customization) from the machine. The process of writing high quality source code requires knowledge of both the application's domain "and" the computer science domain. The highest-quality software is thus developed by a team of various domain experts, each person a specialist in some area of development. But the term "programmer" may apply to a range of program quality, from hacker to open source contributor to professional. And a single programmer could do most or all of the computer programming needed to generate the proof of concept to launch a new "killer" application.

A programmer, computer programmer, or coder is a person who writes computer software. The term "computer programmer" can refer to a specialist in one area of computer programming or to a generalist who writes code for many kinds of software. One who practices or professes a formal approach to programming may also be known as a programmer analyst. A programmer's primary computer language (C, C++, Java, Lisp, Python, etc.) is often prefixed to the above titles, and those who work in a web environment often prefix their titles with "web". The term "programmer" can be used to refer to a software developer, software engineer, computer scientist, or software analyst. However, members of these professions typically possess other software engineering skills, beyond programming.

The computer industry is made up of all of the businesses involved in developing computer software, designing computer hardware and computer networking infrastructures, the manufacture of computer components and the provision of information technology services including system administration and maintenance.

The software industry includes businesses engaged in development, maintenance and publication of software. The industry also includes software services, such as training, documentation, and consulting.

Computer engineering is a discipline that integrates several fields of electrical engineering and computer science required to develop computer hardware and software. Computer engineers usually have training in electronic engineering (or electrical engineering), software design, and hardware-software integration instead of only software engineering or electronic engineering. Computer engineers are involved in many hardware and software aspects of computing, from the design of individual microprocessors, personal computers, and supercomputers, to circuit design. This field of engineering not only focuses on how computer systems themselves work, but also how they integrate into the larger picture.

Software engineering (SE) is the application of a systematic, disciplined, quantifiable approach to the design, development, operation, and maintenance of software, and the study of these approaches; that is, the application of engineering to software. In layman's terms, it is the act of using insights to conceive, model and scale a solution to a problem. The first reference to the term is the 1968 NATO Software Engineering Conference and was meant to provoke thought regarding the perceived "software crisis" at the time. "Software development", a much used and more generic term, does not necessarily subsume the engineering paradigm. The generally accepted concepts of Software Engineering as an engineering discipline have been specified in the Guide to the Software Engineering Body of Knowledge (SWEBOK). The SWEBOK has become an internationally accepted standard ISO/IEC TR 19759:2005.

Computer science or computing science (abbreviated CS or Comp Sci) is the scientific and practical approach to computation and its applications. A computer scientist specializes in the theory of computation and the design of computational systems.

Its subfields can be divided into practical techniques for its implementation and application in computer systems and purely theoretical areas. Some, such as computational complexity theory, which studies fundamental properties of computational problems, are highly abstract, while others, such as computer graphics, emphasize real-world applications. Still others focus on the challenges in implementing computations. For example, programming language theory studies approaches to description of computations, while the study of computer programming itself investigates various aspects of the use of programming languages and complex systems, and human–computer interaction focuses on the challenges in making computers and computations useful, usable, and universally accessible to humans.

"Information systems (IS)" is the study of complementary networks of hardware and software (see information technology) that people and organizations use to collect, filter, process, create, and distribute data. Computing Careers says on their website that "A majority of IS programs are located in business schools; however, they may have different names such as management information systems, computer information systems, or business information systems. All IS degrees combine business and computing topics, but the emphasis between technical and organizational issues varies among programs. For example, programs differ substantially in the amount of programming required."
The study bridges business and computer science using the theoretical foundations of information and computation to study various business models and related algorithmic processes within a computer science discipline. Computer Information System(s) (CIS) is a field studying computers and algorithmic processes, including their principles, their software and hardware designs, their applications, and their impact on society while IS emphasizes functionality over design.

Information technology (IT) is the application of computers and telecommunications equipment to store, retrieve, transmit and manipulate data, often in the context of a business or other enterprise. The term is commonly used as a synonym for computers and computer networks, but it also encompasses other information distribution technologies such as television and telephones. Several industries are associated with information technology, such as computer hardware, software, electronics, semiconductors, internet, telecom equipment, e-commerce and computer services.

A system administrator, IT systems administrator, systems administrator, or sysadmin is a person employed to maintain and operate a computer system and/or network. The duties of a system administrator are wide-ranging, and vary widely from one organization to another. Sysadmins are usually charged with installing, supporting and maintaining servers or other computer systems, and planning for and responding to service outages and other problems. Other duties may include scripting or light programming, project management for systems-related projects, supervising or training computer operators, and being the consultant for computer problems beyond the knowledge of technical support staff.

DNA-based computing and quantum computing are areas of active research in both hardware and software (such as the development of quantum algorithms). Potential infrastructure for future technologies includes DNA origami on photolithography and quantum antennae for transferring information between ion traps. By 2011, researchers had entangled 14 qubits. Fast digital circuits (including those based on Josephson junctions and rapid single flux quantum technology) are becoming more nearly realizable with the discovery of nanoscale superconductors.

Fiber-optic and photonic (optical) devices, which already have been used to transport data over long distances, have started being used by data centers, side by side with CPU and semiconductor memory components. This allows the separation of RAM from CPU by optical interconnects. IBM has created an integrated circuit with both electronic and optical information processing in one chip. This is denoted "CMOS-integrated nanophotonics" or (CINP). One benefit of optical interconnects is that motherboards which formerly required a certain kind of system on a chip (SoC) can now move formerly dedicated memory and network controllers off the motherboards, spreading the controllers out onto the rack. This allows standardization of backplane interconnects and motherboards for multiple types of SoCs, which allows more timely upgrades of CPUs.




</doc>
<doc id="5215" url="https://en.wikipedia.org/wiki?curid=5215" title="Casino">
Casino

A casino is a facility which houses and accommodates certain types of gambling activities. The industry that deals in casinos is called the gaming industry. Casinos are most commonly built near or combined with hotels, restaurants, retail shopping, cruise ships or other tourist attractions. There is much debate over whether the social and economic consequences of casino gambling outweigh the initial revenue that may be generated. Some casinos are also known for hosting live entertainment events, such as stand-up comedy, concerts, and sporting events.

The term "casino" is a confusing linguistic false friend for translators.

"Casino" is of Italian origin; the root "casa" (house) originally meant a small country villa, summerhouse, or social club. During the 19th century, the term "casino" came to include other public buildings where pleasurable activities took place; such edifices were usually built on the grounds of a larger Italian villa or palazzo, and were used to host civic town functions, including dancing, gambling, music listening, and sports; examples in Italy include Villa Farnese and Villa Giulia, and in the US the Newport Casino in Newport, Rhode Island. In modern-day Italian—the source-language of the word—a "casino" is either a brothel (also called "casa chiusa", literally "closed house"), a mess, or a noisy environment, while a gaming house is spelt "casinò", with an accent..

Not all casinos were used for gaming. The Catalina Casino, a famous landmark overlooking Avalon Harbor on Santa Catalina Island, California, has never been used for traditional games of chance, which were already outlawed in California by the time it was built. The Copenhagen Casino was a theatre, known for the mass public meetings often held in its hall during the 1848 Revolution, which made Denmark a constitutional monarchy. Until 1937, it was a well-known Danish theatre. The Hanko Casino in Hanko, Finland—one of that town's most conspicuous landmarks—was never used for gambling. Rather, it was a banquet hall for the Russian nobility which frequented this spa resort in the late 19th century and is now used as a restaurant.

In military and non-military usage in German and Spanish, a "casino" or "kasino" is an officers' mess.

The precise origin of gambling is unknown. It is generally believed that gambling in some form or another has been seen in almost every society in history. From the Ancient Greeks and Romans to Napoleon's France and Elizabethan England, much of history is filled with stories of entertainment based on games of chance.

The first known European gambling house, not called a casino although meeting the modern definition, was the Ridotto, established in Venice, Italy in 1638 by the Great Council of Venice to provide controlled gambling during the carnival season. It was closed in 1774 as the city government felt it was impoverishing the local gentry.

In American history, early gambling establishments were known as saloons. The creation and importance of saloons was greatly influenced by four major cities: New Orleans, St. Louis, Chicago and San Francisco. It was in the saloons that travelers could find people to talk to, drink with, and often gamble with. During the early 20th century in America, gambling became outlawed and banned by state legislation and social reformers of the time. However, in 1931, gambling was legalized throughout the state of Nevada. America's first legalized casinos were set up in those places. In 1976 New Jersey allowed gambling in Atlantic City, now America's second largest gambling city.

Most jurisdictions worldwide have a minimum gambling age (16 to 21 years of age in most countries which permit the operation of casinos).

Customers gamble by playing games of chance, in some cases with an element of skill, such as craps, roulette, baccarat, blackjack, and video poker. Most games played have mathematically determined odds that ensure the house has at all times an overall advantage over the players. This can be expressed more precisely by the notion of expected value, which is uniformly negative (from the player's perspective). This advantage is called the "house edge". In games such as poker where players play against each other, the house takes a commission called the rake. Casinos sometimes give out complimentary items or comps to gamblers.

"Payout" is the percentage of funds ("winnings") returned to players.

Casinos in the United States say that a player staking money won from the casino is "playing with the house's money".

Video Lottery Machines (slot machines) have become one of the most popular forms of gambling in casinos. investigative reports have started calling into question whether the modern-day slot-machine is addictive.
Casino design—regarded as a psychological exercise—is an intricate process that involves optimising floor plan, décor and atmospherics to encourage gambling.

Factors influencing gambling tendencies include sound, odour and lighting. Natasha Dow Schüll, an anthropologist at the Massachusetts Institute of Technology, highlights the decision of the audio directors at Silicon Gaming to make its slot machines resonate in "the universally pleasant tone of C, sampling existing casino soundscapes to create a sound that would please but not clash".

Dr Alan Hirsch, founder of the Smell & Taste Treatment and Research Foundation in Chicago, studied the impact of certain scents on gamblers, discerning that a pleasant albeit unidentifiable odour released by Las Vegas slot machines generated about 50% more in daily revenue. He suggested that the scent acted as an aphrodisiac, causing a more aggressive form of gambling.

Casino designer Roger Thomas is credited with implementing a successful, disruptive design for the Las Vegas Wynn Resorts casinos in 2008. He broke casino design convention by introducing natural sunlight and flora to appeal to women. Thomas put in skylights and antique clocks, defying the commonplace notion that a casino should be a timeless space.

The following lists major casino markets in the world with casino revenue of over US$1 billion as published in PricewaterhouseCoopers's report on 
the outlook for the global casino market:

According to Bloomberg, accumulated revenue of the biggest casino operator companies worldwide amounted almost US$55 billion in 2011. SJM Holdings Ltd. was the leading company in this field, and earned $9.7 billion in 2011, followed by Las Vegas Sands Corp. ($7.4 bn). The third-biggest casino operator company (based on revenue) was Caesars Entertainment, with revenue of US$6.2 bn.

While there are casinos in many places, a few places have become well known specifically for gambling. Perhaps the place almost defined by its casino is Monte Carlo, but other places are known as gambling centers.

Monte Carlo Casino, located in Monte Carlo city, in Monaco, is a famous casino and a tourist attraction popular with well-off visitors. The casino is mentioned in the song The Man Who Broke the Bank at Monte Carlo as well as the film of the same name.

Monte Carlo Casino has been depicted in many books, including Ben Mezrich's "Busting Vegas", where a group of Massachusetts Institute of Technology students beat the casino out of nearly $1 million. This book is based on real people and events; however, many of those events are contested by main character Semyon Dukach. Monte Carlo Casino has also been featured in multiple James Bond novels and films.

The former Portuguese colony of Macau, a special administrative region of China since 1999, is a popular destination for visitors who wish to gamble. This started in Portuguese times, when Macau was popular with visitors from nearby British Hong Kong, where gambling was more closely regulated. The Venetian Macao is currently the largest casino in the world. Macau also surpassed Las Vegas as the largest gambling market in the world.

The Casino Estoril, located in the municipality of Cascais, on the Portuguese Riviera, near Lisbon, is the largest casino in Europe.

During the Second World War, it was reputed to be a gathering point for spies, dispossessed royals, and wartime adventurers; it became an inspiration for Ian Fleming's James Bond 007 novel "Casino Royale".

Singapore is an up-and-coming destination for visitors wanting to gamble, although there are currently only two casinos (both foreign owned), in Singapore. The Marina Bay Sands is the most expensive standalone casino in the world, at a price of US$8 billion, and is among the world's ten most expensive buildings. The Resorts World Sentosa has the world's largest oceanarium.

With currently over 1,000 casinos, the United States has the largest number of casinos in the world. The number continues to grow steadily as more states seek to legalize casinos. 40 states now have some form of casino gambling. Relatively small places such as Las Vegas are best known for gambling; larger cities such as Chicago are not defined by their casinos in spite of the large turnover.

The Las Vegas Valley has the largest concentration of casinos in the United States. Based on revenue, Atlantic City, New Jersey ranks second, and the Chicago region third.

Top American casino markets by revenue (2015 annual revenues):


The Nevada Gaming Control Board divides Clark County, which is coextensive with the Las Vegas metropolitan area, into seven market regions for reporting purposes.

Native American gaming has been responsible for a rise in the number of casinos outside of Las Vegas and Atlantic City.

Given the large amounts of currency handled within a casino, both patrons and staff may be tempted to cheat and steal, in collusion or independently; most casinos have security measures to prevent this. Security cameras located throughout the casino are the most basic measure.

Modern casino security is usually divided between a physical security force and a specialized surveillance department. The physical security force usually patrols the casino and responds to calls for assistance and reports of suspicious or definite criminal activity. A specialized surveillance department operates the casino's closed circuit television system, known in the industry as the eye in the sky. Both of these specialized casino security departments work very closely with each other to ensure the safety of both guests and the casino's assets, and have been quite successful in preventing crime. Some casinos also have catwalks in the ceiling above the casino floor, which allow surveillance personnel to look directly down, through one way glass, on the activities at the tables and slot machines.

When it opened in 1989, The Mirage was the first casino to use cameras full-time on all table games.

In addition to cameras and other technological measures, casinos also enforce security through rules of conduct and behavior; for example, players at card games are required to keep the cards they are holding in their hands visible at all times.

Over the past few decades, casinos have developed many different marketing techniques for attracting and maintaining loyal patrons. Many casinos use a loyalty rewards program used to track players' spending habits and target their patrons more effectively, by sending mailings with free slot play and other promotions.

One area of controversy surrounding casinos is their relationship to crime rates. Economic studies that show a positive relationship between casinos and crime usually fail to consider the visiting population at risk when they calculate the crime rate in casino areas. Such studies thus count the crimes committed by visitors, but do not count visitors in the population measure, and this overstates the crime rates in casino areas. Part of the reason this methodology is used, despite it leading to an overstatement of crime rates is that reliable data on tourist count are often not available.
In a 2004 report by the US Department of Justice, researchers interviewed people who had been arrested in Las Vegas and Des Moines and found that the percentage of problem or pathological gamblers among the arrestees was three to five times higher than in the general population. According to some police reports, incidences of reported crime often double and triple in communities within three years of a casino opening.

Casinos have also been linked to organised crime, with early casinos in Las Vegas originally dominated by the American Mafia and in Macau by Triad syndicates.



</doc>
<doc id="5216" url="https://en.wikipedia.org/wiki?curid=5216" title="Khmer language">
Khmer language

Khmer or Cambodian (natively "phiəsaa khmae" , or more formally "kheemaʾraʾ phiəsaa" ) is the language of the Khmer people and the official language of Cambodia. With approximately 16 million speakers, it is the second most widely spoken Austroasiatic language (after Vietnamese). Khmer has been influenced considerably by Sanskrit and Pali, especially in the royal and religious registers, through Hinduism and Buddhism. The more colloquial registers have influenced, and have been influenced by, Thai, Lao, Vietnamese and Cham, all of which, due to geographical proximity and long-term cultural contact, form a sprachbund in peninsular Southeast Asia. It is also the earliest recorded and earliest written language of the Mon–Khmer family, predating Mon and by a significant margin Vietnamese, due to Old Khmer being the language of the historical empires of Chenla, Angkor and, presumably, their earlier predecessor state, Funan.

The vast majority of Khmer speakers speak Central Khmer, the dialect of the central plain where the Khmer are most heavily concentrated. Within Cambodia, regional accents exist in remote areas but these are regarded as varieties of Central Khmer. Two exceptions are the speech of the capital, Phnom Penh, and that of the Khmer Khe in Stung Treng province, both of which differ sufficiently enough from Central Khmer to be considered separate dialects of Khmer. Outside of Cambodia, three distinct dialects are spoken by ethnic Khmers native to areas that were historically part of the Khmer Empire. The Northern Khmer dialect is spoken by over a million Khmers in the southern regions of Northeast Thailand and is treated by some linguists as a separate language. Khmer Krom, or Southern Khmer, is the first language of the Khmer of Vietnam while the Khmer living in the remote Cardamom mountains speak a very conservative dialect that still displays features of the Middle Khmer language.

Khmer is primarily an analytic, isolating language. There are no inflections, conjugations or case endings. Instead, particles and auxiliary words are used to indicate grammatical relationships. General word order is subject–verb–object, and modifiers follow the word they modify. Classifiers appear after numbers when used to count nouns, though not always so consistently as in languages like Chinese. In spoken Khmer, topic-comment structure is common and the perceived social relation between participants determines which sets of vocabulary, such as pronouns and honorifics, are proper.

Khmer differs from neighboring languages such as Thai, Burmese, Lao and Vietnamese in that it is not a tonal language. Words are stressed on the final syllable, hence many words conform to the typical Mon–Khmer pattern of a stressed syllable preceded by a minor syllable. The language has been written in the Khmer script, an abugida descended from the Brahmi script via the southern Indian Pallava script, since at least the seventh century. The script's form and use has evolved over the centuries; its modern features include subscripted versions of consonants used to write clusters and a division of consonants into two series with different inherent vowels. Approximately 79% of Cambodians are able to read Khmer.

Khmer is a member of the Austroasiatic language family, the autochthonous family in an area that stretches from the Malay Peninsula through Southeast Asia to East India. Austroasiatic, which also includes Mon, Vietnamese and Munda, has been studied since 1856 and was first proposed as a language family in 1907. Despite the amount of research, there is still doubt about the internal relationship of the languages of Austroasiatic. Diffloth places Khmer in an eastern branch of the Mon-Khmer languages. In these classification schemes Khmer's closest genetic relatives are the Bahnaric and Pearic languages. More recent classifications doubt the validity of the Mon-Khmer sub-grouping and place the Khmer language as its own branch of Austroasiatic equidistant from the other 12 branches of the family.

Khmer is spoken by some 13 million people in Cambodia, where it is the official language. It is also a second language for most of the minority groups and indigenous hill tribes there. Additionally there are a million speakers of Khmer native to southern Vietnam (1999 census) and 1.4 million in northeast Thailand (2006).

Khmer dialects, although mutually intelligible, are sometimes quite marked. Notable variations are found in speakers from Phnom Penh (Cambodia's capital city), the rural Battambang area, the areas of Northeast Thailand adjacent to Cambodia such as Surin province, the Cardamom Mountains, and southern Vietnam. The dialects form a continuum running roughly north to south. Standard Cambodian Khmer is mutually intelligible with the others but a Khmer Krom speaker from Vietnam, for instance, may have great difficulty communicating with a Khmer native of Sisaket Province in Thailand.

The following is a classification scheme showing the development of the modern Khmer dialects.

Standard Khmer, or Central Khmer, the language as taught in Cambodian schools and used by the media, is based on the dialect spoken throughout the Central Plain, a region encompassed by the northwest and central provinces.

Northern Khmer (called "Khmer Surin" in Khmer) refers to the dialects spoken by many in several border provinces of present-day northeast Thailand. After the fall of the Khmer Empire in the early 15th century, the Dongrek Mountains served as a natural border leaving the Khmer north of the mountains under the sphere of influence of the Kingdom of Lan Xang. The conquests of Cambodia by Naresuan the Great for Ayutthaya furthered their political and economic isolation from Cambodia proper, leading to a dialect that developed relatively independently from the midpoint of the Middle Khmer period. This has resulted in a distinct accent influenced by the surrounding tonal languages Lao and Thai, lexical differences, and phonemic differences in both vowels and distribution of consonants. Syllable-final , which has become silent in other dialects of Khmer, is still pronounced in Northern Khmer. Some linguists classify Northern Khmer as a separate but closely related language rather than a dialect.

Western Khmer, also called Cardamom Khmer or Chanthaburi Khmer, is spoken by a very small, isolated population in the Cardamom mountain range extending from western Cambodia into eastern Central Thailand. Although little studied, this variety is unique in that it maintains a definite system of vocal register that has all but disappeared in other dialects of modern Khmer.

Phnom Penh Khmer is spoken in the capital and surrounding areas. This dialect is characterized by merging or complete elision of syllables, considered by speakers from other regions to be a "relaxed" pronunciation. For instance, "Phnom Penh" will sometimes be shortened to "m'Penh". Another characteristic of Phnom Penh speech is observed in words with an "r" either as an initial consonant or as the second member of a consonant cluster (as in the English word "bread"). The "r", trilled or flapped in other dialects, is either pronounced as a uvular trill or not pronounced at all. This alters the quality of any preceding consonant, causing a harder, more emphasized pronunciation. Another unique result is that the syllable is spoken with a low-rising or "dipping" tone much like the "hỏi" tone in Vietnamese. For example, some people pronounce ('fish') as : the is dropped and the vowel begins by dipping much lower in tone than standard speech and then rises, effectively doubling its length. Another example is the word ('study'), which is pronounced , with the uvular "r" and the same intonation described above.

Khmer Krom or Southern Khmer is spoken by the indigenous Khmer population of the Mekong Delta, formerly controlled by the Khmer Empire but part of Vietnam since 1698. Khmers are persecuted by the Vietnamese government for using their native language and, since the 1950s, have been forced to take Vietnamese names. Consequently, very little research has been published regarding this dialect. It has been generally influenced by Vietnamese for three centuries and accordingly displays a pronounced accent, tendency toward monosyllablic words and lexical differences from Standard Khmer.

Khmer Khe is spoken in the Se San, Srepok and Sekong river valleys of Sesan and Siem Pang districts in Stung Treng Province. Following the decline of Angkor, the Khmer abandoned their northern territories which were then settled by the Lao. In the 17th century, Chey Chetha XI led a Khmer force into Stung Treng to retake the area. The Khmer Khe living in this area of Stung Treng in modern times are presumed to be the descendants of this group. Their dialect is thought to resemble that of pre-modern Siem Reap.

Linguistic study of the Khmer language divides its history into four periods one of which, the Old Khmer period, is subdivided into pre-Angkorian and Angkorian. Pre-Angkorian Khmer, the Old Khmer language from 600 CE through 800, is only known from words and phrases in Sanskrit texts of the era. Old Khmer (or Angkorian Khmer) is the language as it was spoken in the Khmer Empire from the 9th century until the weakening of the empire sometime in the 13th century. Old Khmer is attested by many primary sources and has been studied in depth by a few scholars, most notably Saveros Pou, Phillip Jenner and Heinz-Jürgen Pinnow. Following the end of the Khmer Empire the language lost the standardizing influence of being the language of government and accordingly underwent a turbulent period of change in morphology, phonology and lexicon. The language of this transition period, from about the 14th to 18th centuries, is referred to as Middle Khmer and saw borrowing from Thai, Lao and, to a lesser extent, Vietnamese. The changes during this period are so profound that the rules of Modern Khmer can not be applied to correctly understand Old Khmer. The language became recognizable as Modern Khmer, spoken from the 19th century till today.

The following table shows the conventionally accepted historical stages of Khmer.

Just as modern Khmer was emerging from the transitional period represented by Middle Khmer, Cambodia fell under the influence of French colonialism. Thailand, which had for centuries claimed suzerainty over Cambodia and controlled succession to the Cambodian throne, began losing its influence on the language. In 1887 Cambodia was fully integrated into French Indochina which brought in a French-speaking aristocracy. This led to French becoming the language of higher education and the intellectual class. By 1907, the French had wrested over half of modern-day Cambodia, including the north and northwest where Thai had been the prestige language, back from Thai control and reintegrated it into the country.

Many native scholars in the early 20th century, led by a monk named Chuon Nath, resisted the French and Thai influences on their language. Forming the government sponsored Cultural Committee to define and standardize the modern language, they championed Khmerization, purging of foreign elements, reviving affixation, and the use of Old Khmer roots and historical Pali and Sanskrit to coin new words for modern ideas. Opponents, led by Keng Vannsak, who embraced "total Khmerization" by denouncing the reversion to classical languages and favoring the use of contemporary colloquial Khmer for neologisms, and Ieu Koeus, who favored borrowing from Thai, were also influential. Koeus later joined the Cultural Committee and supported Nath. Nath's views and prolific work won out and he is credited with cultivating modern Khmer-language identity and culture, overseeing the translation of the entire Pali Buddhist canon into Khmer. He also created the modern Khmer language dictionary that is still in use today, thereby ensuring that Khmer would survive, and indeed flourish, during the French colonial period.

The phonological system described here is the inventory of sounds of the standard spoken language, represented using appropriate symbols from the International Phonetic Alphabet (IPA).

The voiceless plosives may occur with or without aspiration (as vs. , etc.); this difference is contrastive before a vowel. However, the aspirated sounds in that position may be analyzed as sequences of two phonemes: . This analysis is supported by the fact that infixes can be inserted between the stop and the aspiration; for example ('big') becomes ('size') with a nominalizing infix. When one of these plosives occurs initially before another consonant, aspiration is no longer contrastive and can be regarded as mere phonetic detail: slight aspiration is expected when the following consonant is not one of (or if the initial plosive is ).

The voiced plosives are pronounced as implosives by most speakers, but this feature is weak in educated speech, where they become .

In syllable-final position, and approach and respectively. The stops are unaspirated and have no audible release when occurring as syllable finals.

In addition, the consonants , , and occur occasionally in recent loan words in the speech of Cambodians familiar with French and other languages.

Various authors have proposed slightly different analyses of the Khmer vowel system. This may be in part because of the wide degree of variation in pronunciation between individual speakers, even within a dialectal region. The description below follows Huffman (1970). The number of vowel nuclei and their values vary between dialects; differences exist even between the Standard Khmer system and that of the Battambang dialect on which the standard is based.

In addition, there are diphthongs and triphthongs which are analyzed as a vowel nucleus plus a semivowel ( or ) coda because they can not be followed by a final consonant. These include: (with short monophthongs) , , , , ; (with long monophthongs) , ; (with long diphthongs) , , , , and .

A Khmer syllable begins with a single consonant, or else with a cluster of two, or rarely three, consonants. The only possible clusters of three consonants at the start of a syllable are , and (with aspirated consonants analyzed as two-consonant sequences) . There are 85 possible two-consonant clusters (including [pʰ] etc. analyzed as /ph/ etc.). All the clusters are shown in the following table, phonetically, i.e. superscript ʰ can mark either contrastive or non-contrastive aspiration (see above).

Slight vowel epenthesis occurs in the clusters consisting of a plosive followed by , in those beginning , and in the cluster .

After the initial consonant or consonant cluster comes the syllabic nucleus, which is one of the vowels listed above. This vowel may end the syllable or may be followed by a coda, which is a single consonant. If the syllable is stressed and the vowel is short, there must be a final consonant. All consonant sounds except and the aspirates can appear as the coda (although final /r/ is heard in some dialects, most notably in Northern Khmer).

A minor syllable (unstressed syllable preceding the main syllable of a word) has a structure of CV-, CrV-, CVN- or CrVN- (where C is a consonant, V a vowel, and N a nasal consonant). The vowels in such syllables are usually short; in conversation they may be reduced to , although in careful or formal speech, including on television and radio, they are clearly articulated. An example of such a word is "mɔnuh, mɔnɨh, mĕəʾnuh" ('person'), pronounced , or more casually .

Stress in Khmer falls on the final syllable of a word. Because of this predictable pattern, stress is non-phonemic in Khmer (it does not distinguish different meanings).

Most Khmer words consist of either one or two syllables. In most native disyllabic words, the first syllable is a minor (fully unstressed) syllable. Such words have been described as "sesquisyllabic" (i.e. as having one-and-a-half syllables). There are also some disyllabic words in which the first syllable does not behave as a minor syllable, but takes secondary stress. Most such words are compounds, but some are single morphemes (generally loanwords). An example is ('language'), pronounced .

Words with three or more syllables, if they are not compounds, are mostly loanwords, usually derived from Pali, Sanskrit, or more recently, French. They are nonetheless adapted to Khmer stress patterns. Primary stress falls on the final syllable, with secondary stress on every second syllable from the end. Thus in a three-syllable word, the first syllable has secondary stress; in a four-syllable word, the second syllable has secondary stress; in a five-syllable word, the first and third syllables have secondary stress, and so on. Long polysyllables are not often used in conversation.

Compounds, however, preserve the stress patterns of the constituent words. Thus , the name of a kind of cookie (literally 'bird's nest'), is pronounced , with secondary stress on the second rather than the first syllable, because it is composed of the words ('nest') and ('bird').

Khmer once had a phonation distinction in its vowels, but this now survives only in the most archaic dialect (Western Khmer). The distinction arose historically when vowels after Old Khmer voiced consonants became breathy voiced and diphthongized; for example became . When consonant voicing was lost, the distinction was maintained by the vowel (); later the phonation disappeared as well (). These processes explain the origin of what are now called a-series and o-series consonants in the Khmer script.

Although most Cambodian dialects are not tonal, colloquial Phnom Penh dialect has developed a tonal contrast (level versus peaking tone) to compensate for the elision of .

Intonation often conveys semantic context in Khmer, as in distinguishing declarative statements, questions and exclamations. The available grammatical means of making such distinctions are not always used, or may be ambiguous; for example, the final interrogative particle can also serve as an emphasizing (or in some cases negating) particle.

The intonation pattern of a typical Khmer declarative phrase is a steady rise throughout followed by an abrupt drop on the last syllable.

Other intonation contours signify a different type of phrase such as the "full doubt" interrogative, similar to yes-no questions in English. Full doubt interrogatives remain fairly even in tone throughout, but rise sharply towards the end.

Exclamatory phrases follow the typical steadily rising pattern, but rise sharply on the last syllable instead of falling.

Khmer is primarily an analytic language with no inflection. Syntactic relations are mainly determined by word order. Old and Middle Khmer used particles to mark grammatical categories and many of these have survived in Modern Khmer but are used sparingly, mostly in literary or formal language. Khmer makes extensive use of auxiliary verbs, "directionals" and serial verb construction. Colloquial Khmer is a zero copula language, instead preferring predicative adjectives (and even predicative nouns) unless using a copula for emphasis or to avoid ambiguity in more complex sentences. Basic word order is subject–verb–object (SVO), although subjects are often dropped; prepositions are used rather than postpositions. Topic-Comment constructions are common and the language is generally head-initial (modifiers follow the words they modify). Some grammatical processes are still not fully understood by western scholars. For example, it's not clear if certain features of Khmer grammar, such as actor nominalization, should be treated as a morphological process or a purely syntactic device, and some derivational morphology seems to be "purely decorative" and performs no known syntactic work.

Lexical categories have been hard to define in Khmer. Henri Maspero, an early scholar of Khmer, claimed the language had no parts of speech, while a later scholar, Judith Jacob, posited four parts of speech and innumerable particles. John Haiman, on the other hand, identifies "a couple dozen" parts of speech in Khmer with the caveat that Khmer words have the freedom to perform a variety of syntactic functions depending on such factors as word order, relevant particles, location within a clause, intonation and context. Some of the more important lexical categories and their function are demonstrated in the following example sentence taken from a hospital brochure:

Modern Khmer is an isolating language, which means that it uses little productive morphology. There is some derivation by means of prefixes and infixes, but this is a remnant of Old Khmer and not always productive in the modern language. Khmer morphology is evidence of a historical process through which the language was, at some point in the past, changed from being an agglutinative language to adopting an isolating typology. Affixed forms are lexicalized and cannot be used productively to form new words. Below are some of the most common affixes with examples as given by Huffman.
Compounding in Khmer is a common derivational process that takes two forms, coordinate compounds and repetitive compounds. Coordinate compounds join two unbound morphemes (independent words) of similar meaning to form a compound signifying a concept more general than either word alone. Coordinate compounds join either two nouns or two verbs. Repetitive compounds, one of the most productive derivational features of Khmer, use reduplication of an entire word to derive words whose meaning will depend on the class of the reduplicated word. A repetitive compound of a noun indicates plurality or generality while that of an adjectival verb could mean either an intensification or plurality.

Coordinate compounds:

Repetitive compounds:

Khmer nouns do not inflect for grammatical gender or singular/plural. There are no articles, but indefiniteness is often expressed by the word for "one" (, ) following the noun as in ( "a dog"). Plurality can be marked by postnominal particles, numerals, or reduplication of a following adjective, which, although similar to intensification, is usually not ambiguous due to context.

Classifying particles are used after numerals, but are not always obligatory as they are in Thai or Chinese, for example, and are often dropped in colloquial speech. Khmer nouns are divided into two groups: mass nouns, those which take classifiers, and specific nouns, which do not. The overwhelming majority are mass nouns.

Possession is colloquially expressed by word order. The possessor is placed after that which is possessed. Alternatively, in more complex sentences or when emphasis is required, a possessive construction using the word (, "property, object") may be employed. In formal and literary contexts, the possessive particle () is used:

Pronouns are subject to a complicated system of social register, the choice of pronoun depending on the perceived relationships between speaker, audience and referent (see Social registers below). Kinship terms, nicknames and proper names are often used as pronouns (including for the first person) among intimates. Subject pronouns are frequently dropped in colloquial conversation.

Adjectives, verbs and verb phrases may be made into nouns by the use of nominalization particles. Three of the more common particles used to create nouns are , , and . These particles are prefixed most often to verbs in order to form abstract nouns. The latter, derived from Sanskrit, also occurs as a suffix in fixed forms borrowed from Sanskrit and Pali such as ("health") from ("to be healthy").

Adjectives, demonstratives and numerals follow the noun they modify. Adverbs likewise follow the verb. Morphologically, adjectives and adverbs are not distinguished, with many words often serving either function. Adjectives are also employed as verbs as Khmer sentences rarely use a copula.

Degrees of comparison are constructed syntactically. Comparatives are expressed using the word : "A X [B]" (A is more X [than B]). The most common way to express superlatives is with : "A X " (A is the most X). Intensity is also expressed syntactically, similar to other languages of the region, by reduplication or with the use of intensifiers.

As is typical of most East Asian languages, Khmer verbs do not inflect at all; tense, aspect and mood can be expressed using auxiliary verbs, particles (such as កំពុង , placed before a verb to express continuous aspect) and adverbs (such as "yesterday", "earlier", "tomorrow"), or may be understood from context. Serial verb construction is quite common.

Khmer verbs are a relatively open class and can be divided into two types, main verbs and auxiliary verbs. Huffman defined a Khmer verb as "any word that can be (negated)", and further divided main verbs into three classes.

Transitive verbs are verbs which may be followed by a direct object:

Intransitive verbs are verbs which can not be followed by an object:

Adjectival verbs are a word class that has no equivalent in English. When modifying a noun or verb, they function as adjectives or adverbs, respectively, but they may also be used as main verbs equivalent to English "be + "adjective"".

Syntax is the rules and processes that describe how sentences are formed in a particular language, how words relate to each other within clauses or phrases and how those phrases relate to each other within a sentence to convey meaning. Khmer syntax is very analytic. Relationships between words and phrases are signified primarily by word order supplemented with auxiliary verbs and, particularly in formal and literary registers, grammatical marking particles. Grammatical phenomena such as negation and aspect are marked by particles while interrogative sentences are marked either by particles or interrogative words equivalent to English "wh-words".

A complete Khmer sentence consists of four basic elements which include an optional topic, an optional subject, an obligatory predicate and various adverbials and particles. The topic and subject are noun phrases, predicates are verb phrases and another noun phrase acting as an object or verbal attribute often follows the predicate.

When combining these noun and verb phrases into a sentence the order is typically SVO:

When both a direct object and indirect object are present without any grammatical markers, the preferred order is SV(DO)(IO). In such a case, if the direct object phrase contains multiple components, the indirect object immediately follows the noun of the direct object phrase and the direct object's modifiers follow the indirect object:

This ordering of objects can be changed and the meaning clarified with the inclusion of particles. The word , which normally means "to arrive" or "towards", can be used as a preposition meaning "to":

Alternatively, the indirect object could precede the direct object if the object marking preposition /nəw/ were used:

However, in spoken discourse OSV is possible when emphasizing the object in a topic-comment-like structure.

The noun phrase in Khmer typically has the following structure:
The elements in parentheses are optional. Honorifics are a class of words that serve to index the social status of the referent. Honorifics can be kinship terms or personal names, both of which are often used as first and second person pronouns, or specialized words such as ('god') before royal and religious objects. The most common demonstratives are ('this, these') and ('that, those'). The word ('those over there') has a more distal or vague connotation. If the noun phrase contains a possessive adjective, it follows the noun and precedes the numeral. If a descriptive attribute co-occurs with a possessive, the possessive construction () is expected.

Some examples of typical Khmer noun phrases are:
The Khmer particle marked attributes in Old Khmer noun phrases and is used in formal and literary language to signify that what precedes is the noun and what follows is the attribute. Modern usage may carry the connotation of mild intensity.

Khmer verbs are completely uninflected, and once a subject or topic has been introduced or is clear from context the noun phrase may be dropped. Thus, the simplest possible sentence in Khmer consists of a single verb. For example, /tɨw/ can mean "I'm going.", "He went.", "They've gone.", "Let's go.", etc. This also results in long strings of verbs such as:

Khmer uses three verbs for what translates into English as the copula. The general copula is ; it is used to convey identity with nominal predicates. For locative predicates, the copula is . The verb is the "existential" copula meaning "there is" or "there exists".

Negation is achieved by putting មិន before the verb and the particle ទេ at the end of the sentence or clause. In colloquial speech, verbs can also be negated without the need for a final particle, by placing ឥត before them.

Past tense can be conveyed by adverbs, such as "yesterday" or by the use of perfective particles such as 

Different senses of future action can also be expressed by the use of adverbs like "tomorrow" or by the future tense marker , which is placed immediately before the verb, or both:

Imperatives are often unmarked. For example, in addition to the meanings given above, the "sentence" can also mean "Go!". Various words and particles may be added to the verb to soften the command to varying degrees, including to the point of politeness (jussives):

Prohibitives take the form " + V" and also are often softened by the addition of the particle to the end of the phrase.

There are three basic types of questions in Khmer. Questions requesting specific information use question words. Polar questions are indicated with interrogative particles, most commonly a homonym of the negation particle. Tag questions are indicated with various particles and rising inflection. The SVO word order is generally not inverted for questions.

In more formal contexts and in polite speech, questions are also marked at their beginning by the particle .

Khmer does not have a passive voice, but there is a construction utilizing the main verb ("to hit", "to be correct", "to affect") as an auxiliary verb meaning "to be subject to" or "to undergo" which results in sentences that are translated to English using the passive voice.

Complex sentences are formed in Khmer by the addition of one or more clauses to the main clause. The various types of clauses in Khmer include the coordinate clause, the relative clause and the subordinate clause. Word order in clauses is the same for that of the basic sentences described above. Coordinate clauses do not necessarily have to be marked; they can simply follow one another. When explicitly marked, they are joined by words similar to English conjunctions such as ("and") and ("and then") or by clause-final conjunction-like adverbs and , both of which can mean "also" or "and also"; disjunction is indicated by ("or"). Relative clauses can be introduced by /dael/ ("that") but, similar to coordinate clauses, often simply follow the main clause. For example, both phrases below can mean "the hospital bed that has wheels".

Relative clauses are more likely to be introduced with if they do not immediately follow the head noun. Khmer subordinate conjunctions always precede a subordinate clause. Subordinate conjunctions include words such as ("because"), ("seems as if") and ("in order to").

Counting in Khmer is based on a biquinary system (the numbers from 6 to 9 have the form "five one", "five two", etc.) However, the words for multiples of ten from 30 to 90 are not related to the basic Khmer numbers, but are probably borrowed from Thai. The Khmer script has its own versions of the Arabic numerals.

The principal number words are listed in the following table, which gives Western and Khmer digits, Khmer spelling and IPA transcription.

Intermediate numbers are formed by compounding the above elements. Powers of ten are denoted by loan words: (100), (1,000), (10,000), (100,000) and (1,000,000) from Thai and (10,000,000) from Sanskrit.

Ordinal numbers are formed by placing the particle before the corresponding cardinal number.

Khmer employs a system of registers in which the speaker must always be conscious of the social status of the person spoken to. The different registers, which include those used for common speech, polite speech, speaking to or about royals and speaking to or about monks, employ alternate verbs, names of body parts and pronouns. This results in what appears to foreigners as separate languages and, in fact, isolated villagers often are unsure how to speak with royals and royals raised completely within the court do not feel comfortable speaking the common register. As an example, the word for "to eat" used between intimates or in reference to animals is . Used in polite reference to commoners, it is . When used of those of higher social status, it is or . For monks the word is and for royals, . Another result is that the pronominal system is complex and full of honorific variations, just a few of which are shown in the table below.

Khmer is written with the Khmer script, an abugida developed from the Pallava script of India before the 7th century when the first known inscription appeared. Written left-to-right with vowel signs that can be placed after, before, above or below the consonant they follow, the Khmer script is similar in appearance and usage to Thai and Lao, both of which were based on the Khmer system. The Khmer script is also distantly related to the Mon script, the ancestor of the modern Burmese script. Khmer numerals, which were inherited from Indian numerals, are used more widely than Hindu-Arabic numerals. Within Cambodia, literacy in the Khmer alphabet is estimated at 77.6%.

Consonant symbols in Khmer are divided into two groups, or series. The first series carries the inherent vowel while the second series carries the inherent vowel . The Khmer names of the series, ('voiceless') and ('voiced'), respectively, indicate that the second series consonants were used to represent the voiced phonemes of Old Khmer. As the voicing of stops was lost, however, the contrast shifted to the phonation of the attached vowels which, in turn, evolved into a simple difference of vowel quality, often by diphthongization. This process has resulted in the Khmer alphabet having two symbols for most consonant phonemes and each vowel symbol having two possible readings, depending on the series of the initial consonant:




</doc>
<doc id="5218" url="https://en.wikipedia.org/wiki?curid=5218" title="Central processing unit">
Central processing unit

A central processing unit (CPU) is the electronic circuitry within a computer that carries out the instructions of a computer program by performing the basic arithmetic, logical, control and input/output (I/O) operations specified by the instructions. The computer industry has used the term "central processing unit" at least since the early 1960s. Traditionally, the term "CPU" refers to a processor, more specifically to its processing unit and control unit (CU), distinguishing these core elements of a computer from external components such as main memory and I/O circuitry.

The form, design, and implementation of CPUs have changed over the course of their history, but their fundamental operation remains almost unchanged. Principal components of a CPU include the arithmetic logic unit (ALU) that performs arithmetic and logic operations, processor registers that supply operands to the ALU and store the results of ALU operations and a control unit that orchestrates the fetching (from memory) and execution of instructions by directing the coordinated operations of the ALU, registers and other components.

Most modern CPUs are microprocessors, meaning they are contained on a single integrated circuit (IC) chip. An IC that contains a CPU may also contain memory, peripheral interfaces, and other components of a computer; such integrated devices are variously called microcontrollers or systems on a chip (SoC). Some computers employ a multi-core processor, which is a single chip containing two or more CPUs called "cores"; in that context, one can speak of such single chips as "sockets".

Array processors or vector processors have multiple processors that operate in parallel, with no unit considered central. There also exists the concept of virtual CPUs which are an abstraction of dynamical aggregated computational resources.

Early computers such as the ENIAC had to be physically rewired to perform different tasks, which caused these machines to be called "fixed-program computers". Since the term "CPU" is generally defined as a device for software (computer program) execution, the earliest devices that could rightly be called CPUs came with the advent of the stored-program computer.

The idea of a stored-program computer had been already present in the design of J. Presper Eckert and John William Mauchly's ENIAC, but was initially omitted so that it could be finished sooner. On June 30, 1945, before ENIAC was made, mathematician John von Neumann distributed the paper entitled "First Draft of a Report on the EDVAC". It was the outline of a stored-program computer that would eventually be completed in August 1949. EDVAC was designed to perform a certain number of instructions (or operations) of various types. Significantly, the programs written for EDVAC were to be stored in high-speed computer memory rather than specified by the physical wiring of the computer. This overcame a severe limitation of ENIAC, which was the considerable time and effort required to reconfigure the computer to perform a new task. With von Neumann's design, the program that EDVAC ran could be changed simply by changing the contents of the memory. EDVAC, however, was not the first stored-program computer; the Manchester Small-Scale Experimental Machine, a small prototype stored-program computer, ran its first program on 21 June 1948 and the Manchester Mark 1 ran its first program during the night of 16–17 June 1949.

Early CPUs were custom designs used as part of a larger and sometimes distinctive computer. However, this method of designing custom CPUs for a particular application has largely given way to the development of multi-purpose processors produced in large quantities. This standardization began in the era of discrete transistor mainframes and minicomputers and has rapidly accelerated with the popularization of the integrated circuit (IC). The IC has allowed increasingly complex CPUs to be designed and manufactured to tolerances on the order of nanometers. Both the miniaturization and standardization of CPUs have increased the presence of digital devices in modern life far beyond the limited application of dedicated computing machines. Modern microprocessors appear in electronic devices ranging from automobiles to cellphones, and sometimes even in toys.

While von Neumann is most often credited with the design of the stored-program computer because of his design of EDVAC, and the design became known as the von Neumann architecture, others before him, such as Konrad Zuse, had suggested and implemented similar ideas. The so-called Harvard architecture of the Harvard Mark I, which was completed before EDVAC, also utilized a stored-program design using punched paper tape rather than electronic memory. The key difference between the von Neumann and Harvard architectures is that the latter separates the storage and treatment of CPU instructions and data, while the former uses the same memory space for both. Most modern CPUs are primarily von Neumann in design, but CPUs with the Harvard architecture are seen as well, especially in embedded applications; for instance, the Atmel AVR microcontrollers are Harvard architecture processors.

Relays and vacuum tubes (thermionic tubes) were commonly used as switching elements; a useful computer requires thousands or tens of thousands of switching devices. The overall speed of a system is dependent on the speed of the switches. Tube computers like EDVAC tended to average eight hours between failures, whereas relay computers like the (slower, but earlier) Harvard Mark I failed very rarely. In the end, tube-based CPUs became dominant because the significant speed advantages afforded generally outweighed the reliability problems. Most of these early synchronous CPUs ran at low clock rates compared to modern microelectronic designs. Clock signal frequencies ranging from 100 kHz to 4 MHz were very common at this time, limited largely by the speed of the switching devices they were built with.

The design complexity of CPUs increased as various technologies facilitated building smaller and more reliable electronic devices. The first such improvement came with the advent of the transistor. Transistorized CPUs during the 1950s and 1960s no longer had to be built out of bulky, unreliable and fragile switching elements like vacuum tubes and relays. With this improvement more complex and reliable CPUs were built onto one or several printed circuit boards containing discrete (individual) components.

In 1964, IBM introduced its IBM System/360 computer architecture that was used in a series of computers capable of running the same programs with different speed and performance. This was significant at a time when most electronic computers were incompatible with one another, even those made by the same manufacturer. To facilitate this improvement, IBM utilized the concept of a microprogram (often called "microcode"), which still sees widespread usage in modern CPUs. The System/360 architecture was so popular that it dominated the mainframe computer market for decades and left a legacy that is still continued by similar modern computers like the IBM zSeries. In 1965, Digital Equipment Corporation (DEC) introduced another influential computer aimed at the scientific and research markets, the PDP-8.

Transistor-based computers had several distinct advantages over their predecessors. Aside from facilitating increased reliability and lower power consumption, transistors also allowed CPUs to operate at much higher speeds because of the short switching time of a transistor in comparison to a tube or relay. The increased reliability and dramatically increased speed of the switching elements (which were almost exclusively transistors by this time), CPU clock rates in the tens of megahertz were easily obtained during this period. Additionally while discrete transistor and IC CPUs were in heavy usage, new high-performance designs like SIMD (Single Instruction Multiple Data) vector processors began to appear. These early experimental designs later gave rise to the era of specialized supercomputers like those made by Cray Inc and Fujitsu Ltd.

During this period, a method of manufacturing many interconnected transistors in a compact space was developed. The integrated circuit (IC) allowed a large number of transistors to be manufactured on a single semiconductor-based die, or "chip". At first, only very basic non-specialized digital circuits such as NOR gates were miniaturized into ICs. CPUs based on these "building block" ICs are generally referred to as "small-scale integration" (SSI) devices. SSI ICs, such as the ones used in the Apollo guidance computer, usually contained up to a few dozen transistors. To build an entire CPU out of SSI ICs required thousands of individual chips, but still consumed much less space and power than earlier discrete transistor designs.

IBM's System/370, follow-on to the System/360, used SSI ICs rather than Solid Logic Technology discrete-transistor modules. DEC's PDP-8/I and KI10 PDP-10 also switched from the individual transistors used by the PDP-8 and PDP-10 to SSI ICs, and their extremely popular PDP-11 line was originally built with SSI ICs but was eventually implemented with LSI components once these became practical.

Lee Boysel published influential articles, including a 1967 "manifesto", which described how to build the equivalent of a 32-bit mainframe computer from a relatively small number of large-scale integration circuits (LSI). At the time, the only way to build LSI chips, which are chips with a hundred or more gates, was to build them using a MOS process (i.e., PMOS logic, NMOS logic, or CMOS logic). However, some companies continued to build processors out of bipolar chips because bipolar junction transistors were so much faster than MOS chips; for example, Datapoint built processors out of transistor–transistor logic (TTL) chips until the early 1980s. At the time, MOS ICs were so slow that they were considered useful only in a few niche applications that required low power.

As the microelectronic technology advanced, an increasing number of transistors were placed on ICs, decreasing the number of individual ICs needed for a complete CPU. MSI and LSI ICs increased transistor counts to hundreds, and then thousands. By 1968, the number of ICs required to build a complete CPU had been reduced to 24 ICs of eight different types, with each IC containing roughly 1000 MOSFETs. In stark contrast with its SSI and MSI predecessors, the first LSI implementation of the PDP-11 contained a CPU composed of only four LSI integrated circuits.

Since the introduction of the first commercially available microprocessor, the Intel 4004 in 1970, and the first widely used microprocessor, the Intel 8080 in 1974, this class of CPUs has almost completely overtaken all other central processing unit implementation methods. Mainframe and minicomputer manufacturers of the time launched proprietary IC development programs to upgrade their older computer architectures, and eventually produced instruction set compatible microprocessors that were backward-compatible with their older hardware and software. Combined with the advent and eventual success of the ubiquitous personal computer, the term "CPU" is now applied almost exclusively to microprocessors. Several CPUs (denoted "cores") can be combined in a single processing chip.
Previous generations of CPUs were implemented as discrete components and numerous small integrated circuits (ICs) on one or more circuit boards. Microprocessors, on the other hand, are CPUs manufactured on a very small number of ICs; usually just one. The overall smaller CPU size, as a result of being implemented on a single die, means faster switching time because of physical factors like decreased gate parasitic capacitance. This has allowed synchronous microprocessors to have clock rates ranging from tens of megahertz to several gigahertz. Additionally, the ability to construct exceedingly small transistors on an IC has increased the complexity and number of transistors in a single CPU many fold. This widely observed trend is described by Moore's law, which has proven to be a fairly accurate predictor of the growth of CPU (and other IC) complexity.

While the complexity, size, construction and general form of CPUs have changed enormously since 1950, it is notable that the basic design and function has not changed much at all. Almost all common CPUs today can be very accurately described as von Neumann stored-program machines. As the aforementioned Moore's law continues to hold true, concerns have arisen about the limits of integrated circuit transistor technology. Extreme miniaturization of electronic gates is causing the effects of phenomena like electromigration and subthreshold leakage to become much more significant. These newer concerns are among the many factors causing researchers to investigate new methods of computing such as the quantum computer, as well as to expand the usage of parallelism and other methods that extend the usefulness of the classical von Neumann model.

The fundamental operation of most CPUs, regardless of the physical form they take, is to execute a sequence of stored instructions that is called a program. The instructions to be executed are kept in some kind of computer memory. Nearly all CPUs follow the fetch, decode and execute steps in their operation, which are collectively known as the instruction cycle.

After the execution of an instruction, the entire process repeats, with the next instruction cycle normally fetching the next-in-sequence instruction because of the incremented value in the program counter. If a jump instruction was executed, the program counter will be modified to contain the address of the instruction that was jumped to and program execution continues normally. In more complex CPUs, multiple instructions can be fetched, decoded and executed simultaneously. This section describes what is generally referred to as the "classic RISC pipeline", which is quite common among the simple CPUs used in many electronic devices (often called microcontroller). It largely ignores the important role of CPU cache, and therefore the access stage of the pipeline.

Some instructions manipulate the program counter rather than producing result data directly; such instructions are generally called "jumps" and facilitate program behavior like loops, conditional program execution (through the use of a conditional jump), and existence of functions. In some processors, some other instructions change the state of bits in a "flags" register. These flags can be used to influence how a program behaves, since they often indicate the outcome of various operations. For example, in such processors a "compare" instruction evaluates two values and sets or clears bits in the flags register to indicate which one is greater or whether they are equal; one of these flags could then be used by a later jump instruction to determine program flow.

The first step, fetch, involves retrieving an instruction (which is represented by a number or sequence of numbers) from program memory. The instruction's location (address) in program memory is determined by a program counter (PC), which stores a number that identifies the address of the next instruction to be fetched. After an instruction is fetched, the PC is incremented by the length of the instruction so that it will contain the address of the next instruction in the sequence. Often, the instruction to be fetched must be retrieved from relatively slow memory, causing the CPU to stall while waiting for the instruction to be returned. This issue is largely addressed in modern processors by caches and pipeline architectures (see below).

The instruction that the CPU fetches from memory determines what the CPU will do. In the decode step, performed by the circuitry known as the "instruction decoder", the instruction is converted into signals that control other parts of the CPU.

The way in which the instruction is interpreted is defined by the CPU's instruction set architecture (ISA). Often, one group of bits (that is, a "field") within the instruction, called the opcode, indicates which operation is to be performed, while the remaining fields usually provide supplemental information required for the operation, such as the operands. Those operands may be specified as a constant value (called an immediate value), or as the location of a value that may be a processor register or a memory address, as determined by some addressing mode.

In some CPU designs the instruction decoder is implemented as a hardwired, unchangeable circuit. In others, a microprogram is used to translate instructions into sets of CPU configuration signals that are applied sequentially over multiple clock pulses. In some cases the memory that stores the microprogram is rewritable, making it possible to change the way in which the CPU decodes instructions.

After the fetch and decode steps, the execute step is performed. Depending on the CPU architecture, this may consist of a single action or a sequence of actions. During each action, various parts of the CPU are electrically connected so they can perform all or part of the desired operation and then the action is completed, typically in response to a clock pulse. Very often the results are written to an internal CPU register for quick access by subsequent instructions. In other cases results may be written to slower, but less expensive and higher capacity main memory.

For example, if an addition instruction is to be executed, the arithmetic logic unit (ALU) inputs are connected to a pair of operand sources (numbers to be summed), the ALU is configured to perform an addition operation so that the sum of its operand inputs will appear at its output, and the ALU output is connected to storage (e.g., a register or memory) that will receive the sum. When the clock pulse occurs, the sum will be transferred to storage and, if the resulting sum is too large (i.e., it is larger than the ALU's output word size), an arithmetic overflow flag will be set.

Hardwired into a CPU's circuitry is a set of basic operations it can perform, called an instruction set. Such operations may involve, for example, adding or subtracting two numbers, comparing two numbers, or jumping to a different part of a program. Each basic operation is represented by a particular combination of bits, known as the machine language opcode; while executing instructions in a machine language program, the CPU decides which operation to perform by "decoding" the opcode. A complete machine language instruction consists of an opcode and, in many cases, additional bits that specify arguments for the operation (for example, the numbers to be summed in the case of an addition operation). Going up the complexity scale, a machine language program is a collection of machine language instructions that the CPU executes.

The actual mathematical operation for each instruction is performed by a combinational logic circuit within the CPU's processor known as the arithmetic logic unit or ALU. In general, a CPU executes an instruction by fetching it from memory, using its ALU to perform an operation, and then storing the result to memory. Beside the instructions for integer mathematics and logic operations, various other machine instructions exist, such as those for loading data from memory and storing it back, branching operations, and mathematical operations on floating-point numbers performed by the CPU's floating-point unit (FPU).

The control unit of the CPU contains circuitry that uses electrical signals to direct the entire computer system to carry out stored program instructions. The control unit does not execute program instructions; rather, it directs other parts of the system to do so. The control unit communicates with both the ALU and memory.

The arithmetic logic unit (ALU) is a digital circuit within the processor that performs integer arithmetic and bitwise logic operations. The inputs to the ALU are the data words to be operated on (called operands), status information from previous operations, and a code from the control unit indicating which operation to perform. Depending on the instruction being executed, the operands may come from internal CPU registers or external memory, or they may be constants generated by the ALU itself.

When all input signals have settled and propagated through the ALU circuitry, the result of the performed operation appears at the ALU's outputs. The result consists of both a data word, which may be stored in a register or memory, and status information that is typically stored in a special, internal CPU register reserved for this purpose.

Most high-end microprocessors (in desktop, laptop, server computers) have a memory management unit, translating logical addresses into physical RAM addresses, providing memory protection and paging abilities, useful for virtual memory. Simpler processors, especially microcontrollers, usually don't include an MMU.

Most CPUs are synchronous circuits, which means they employ a clock signal to pace their sequential operations. The clock signal is produced by an external oscillator circuit that generates a consistent number of pulses each second in the form of a periodic square wave. The frequency of the clock pulses determines the rate at which a CPU executes instructions and, consequently, the faster the clock, the more instructions the CPU will execute each second.

To ensure proper operation of the CPU, the clock period is longer than the maximum time needed for all signals to propagate (move) through the CPU. In setting the clock period to a value well above the worst-case propagation delay, it is possible to design the entire CPU and the way it moves data around the "edges" of the rising and falling clock signal. This has the advantage of simplifying the CPU significantly, both from a design perspective and a component-count perspective. However, it also carries the disadvantage that the entire CPU must wait on its slowest elements, even though some portions of it are much faster. This limitation has largely been compensated for by various methods of increasing CPU parallelism (see below).

However, architectural improvements alone do not solve all of the drawbacks of globally synchronous CPUs. For example, a clock signal is subject to the delays of any other electrical signal. Higher clock rates in increasingly complex CPUs make it more difficult to keep the clock signal in phase (synchronized) throughout the entire unit. This has led many modern CPUs to require multiple identical clock signals to be provided to avoid delaying a single signal significantly enough to cause the CPU to malfunction. Another major issue, as clock rates increase dramatically, is the amount of heat that is dissipated by the CPU. The constantly changing clock causes many components to switch regardless of whether they are being used at that time. In general, a component that is switching uses more energy than an element in a static state. Therefore, as clock rate increases, so does energy consumption, causing the CPU to require more heat dissipation in the form of CPU cooling solutions.

One method of dealing with the switching of unneeded components is called clock gating, which involves turning off the clock signal to unneeded components (effectively disabling them). However, this is often regarded as difficult to implement and therefore does not see common usage outside of very low-power designs. One notable recent CPU design that uses extensive clock gating is the IBM PowerPC-based Xenon used in the Xbox 360; that way, power requirements of the Xbox 360 are greatly reduced. Another method of addressing some of the problems with a global clock signal is the removal of the clock signal altogether. While removing the global clock signal makes the design process considerably more complex in many ways, asynchronous (or clockless) designs carry marked advantages in power consumption and heat dissipation in comparison with similar synchronous designs. While somewhat uncommon, entire asynchronous CPUs have been built without utilizing a global clock signal. Two notable examples of this are the ARM compliant AMULET and the MIPS R3000 compatible MiniMIPS.

Rather than totally removing the clock signal, some CPU designs allow certain portions of the device to be asynchronous, such as using asynchronous ALUs in conjunction with superscalar pipelining to achieve some arithmetic performance gains. While it is not altogether clear whether totally asynchronous designs can perform at a comparable or better level than their synchronous counterparts, it is evident that they do at least excel in simpler math operations. This, combined with their excellent power consumption and heat dissipation properties, makes them very suitable for embedded computers.

Every CPU represents numerical values in a specific way. For example, some early digital computers represented numbers as familiar decimal (base 10) numeral system values, and others have employed more unusual representations such as ternary (base three). Nearly all modern CPUs represent numbers in binary form, with each digit being represented by some two-valued physical quantity such as a "high" or "low" voltage.

Related to numeric representation is the size and precision of integer numbers that a CPU can represent. In the case of a binary CPU, this is measured by the number of bits (significant digits of a binary encoded integer) that the CPU can process in one operation, which is commonly called "word size", "bit width", "data path width", "integer precision", or "integer size". A CPU's integer size determines the range of integer values it can directly operate on. For example, an 8-bit CPU can directly manipulate integers represented by eight bits, which have a range of 256 (2) discrete integer values.

Integer range can also affect the number of memory locations the CPU can directly address (an address is an integer value representing a specific memory location). For example, if a binary CPU uses 32 bits to represent a memory address then it can directly address 2 memory locations. To circumvent this limitation and for various other reasons, some CPUs use mechanisms (such as bank switching) that allow additional memory to be addressed.

CPUs with larger word sizes require more circuitry and consequently are physically larger, cost more and consume more power (and therefore generate more heat). As a result, smaller 4- or 8-bit microcontrollers are commonly used in modern applications even though CPUs with much larger word sizes (such as 16, 32, 64, even 128-bit) are available. When higher performance is required, however, the benefits of a larger word size (larger data ranges and address spaces) may outweigh the disadvantages. A CPU can have internal data paths shorter than the word size to reduce size and cost. For example, even though the IBM System/360 instruction set was a 32-bit instruction set, the System/360 Model 30 and Model 40 had 8-bit data paths in the arithmetic logical unit, so that a 32-bit add required four cycles, one for each 8 bits of the operands, and, even though the Motorola 68000 series instruction set was a 32-bit instruction set, the Motorola 68000 and Motorola 68010 had 16-bit data paths in the arithmetic logical unit, so that a 32-bit add required two cycles.

To gain some of the advantages afforded by both lower and higher bit lengths, many instruction sets have different bit widths for integer and floating-point data, allowing CPUs implementing that instruction set to have different bit widths for different portions of the device. For example, the IBM System/360 instruction set was primarily 32 bit, but supported 64-bit floating point values to facilitate greater accuracy and range in floating point numbers. The System/360 Model 65 had an 8-bit adder for decimal and fixed-point binary arithmetic and a 60-bit adder for floating-point arithmetic. Many later CPU designs use similar mixed bit width, especially when the processor is meant for general-purpose usage where a reasonable balance of integer and floating point capability is required.

The description of the basic operation of a CPU offered in the previous section describes the simplest form that a CPU can take. This type of CPU, usually referred to as "subscalar", operates on and executes one instruction on one or two pieces of data at a time, that is less than one instruction per clock cycle ().

This process gives rise to an inherent inefficiency in subscalar CPUs. Since only one instruction is executed at a time, the entire CPU must wait for that instruction to complete before proceeding to the next instruction. As a result, the subscalar CPU gets "hung up" on instructions which take more than one clock cycle to complete execution. Even adding a second execution unit (see below) does not improve performance much; rather than one pathway being hung up, now two pathways are hung up and the number of unused transistors is increased. This design, wherein the CPU's execution resources can operate on only one instruction at a time, can only possibly reach "scalar" performance (one instruction per clock cycle, ). However, the performance is nearly always subscalar (less than one instruction per clock cycle, ).

Attempts to achieve scalar and better performance have resulted in a variety of design methodologies that cause the CPU to behave less linearly and more in parallel. When referring to parallelism in CPUs, two terms are generally used to classify these design techniques:

Each methodology differs both in the ways in which they are implemented, as well as the relative effectiveness they afford in increasing the CPU's performance for an application.

One of the simplest methods used to accomplish increased parallelism is to begin the first steps of instruction fetching and decoding before the prior instruction finishes executing. This is the simplest form of a technique known as instruction pipelining, and is utilized in almost all modern general-purpose CPUs. Pipelining allows more than one instruction to be executed at any given time by breaking down the execution pathway into discrete stages. This separation can be compared to an assembly line, in which an instruction is made more complete at each stage until it exits the execution pipeline and is retired.

Pipelining does, however, introduce the possibility for a situation where the result of the previous operation is needed to complete the next operation; a condition often termed data dependency conflict. To cope with this, additional care must be taken to check for these sorts of conditions and delay a portion of the instruction pipeline if this occurs. Naturally, accomplishing this requires additional circuitry, so pipelined processors are more complex than subscalar ones (though not very significantly so). A pipelined processor can become very nearly scalar, inhibited only by pipeline stalls (an instruction spending more than one clock cycle in a stage).

Further improvement upon the idea of instruction pipelining led to the development of a method that decreases the idle time of CPU components even further. Designs that are said to be "superscalar" include a long instruction pipeline and multiple identical execution units, such as load-store units, arithmetic-logic units, floating-point units and address generation units. In a superscalar pipeline, multiple instructions are read and passed to a dispatcher, which decides whether or not the instructions can be executed in parallel (simultaneously). If so they are dispatched to available execution units, resulting in the ability for several instructions to be executed simultaneously. In general, the more instructions a superscalar CPU is able to dispatch simultaneously to waiting execution units, the more instructions will be completed in a given cycle.

Most of the difficulty in the design of a superscalar CPU architecture lies in creating an effective dispatcher. The dispatcher needs to be able to quickly and correctly determine whether instructions can be executed in parallel, as well as dispatch them in such a way as to keep as many execution units busy as possible. This requires that the instruction pipeline is filled as often as possible and gives rise to the need in superscalar architectures for significant amounts of CPU cache. It also makes hazard-avoiding techniques like branch prediction, speculative execution, register renaming, out-of-order execution and transactional memory crucial to maintaining high levels of performance. By attempting to predict which branch (or path) a conditional instruction will take, the CPU can minimize the number of times that the entire pipeline must wait until a conditional instruction is completed. Speculative execution often provides modest performance increases by executing portions of code that may not be needed after a conditional operation completes. Out-of-order execution somewhat rearranges the order in which instructions are executed to reduce delays due to data dependencies. Also in case of single instruction stream, multiple data stream—a case when a lot of data from the same type has to be processed—, modern processors can disable parts of the pipeline so that when a single instruction is executed many times, the CPU skips the fetch and decode phases and thus greatly increases performance on certain occasions, especially in highly monotonous program engines such as video creation software and photo processing.

In the case where a portion of the CPU is superscalar and part is not, the part which is not suffers a performance penalty due to scheduling stalls. The Intel P5 Pentium had two superscalar ALUs which could accept one instruction per clock cycle each, but its FPU could not accept one instruction per clock cycle. Thus the P5 was integer superscalar but not floating point superscalar. Intel's successor to the P5 architecture, P6, added superscalar capabilities to its floating point features, and therefore afforded a significant increase in floating point instruction performance.

Both simple pipelining and superscalar design increase a CPU's ILP by allowing a single processor to complete execution of instructions at rates surpassing one instruction per clock cycle. Most modern CPU designs are at least somewhat superscalar, and nearly all general purpose CPUs designed in the last decade are superscalar. In later years some of the emphasis in designing high-ILP computers has been moved out of the CPU's hardware and into its software interface, or ISA. The strategy of the very long instruction word (VLIW) causes some ILP to become implied directly by the software, reducing the amount of work the CPU must perform to boost ILP and thereby reducing the design's complexity.

Another strategy of achieving performance is to execute multiple threads or processes in parallel. This area of research is known as parallel computing. In Flynn's taxonomy, this strategy is known as multiple instruction stream, multiple data stream (MIMD).

One technology used for this purpose was multiprocessing (MP). The initial flavor of this technology is known as symmetric multiprocessing (SMP), where a small number of CPUs share a coherent view of their memory system. In this scheme, each CPU has additional hardware to maintain a constantly up-to-date view of memory. By avoiding stale views of memory, the CPUs can cooperate on the same program and programs can migrate from one CPU to another. To increase the number of cooperating CPUs beyond a handful, schemes such as non-uniform memory access (NUMA) and directory-based coherence protocols were introduced in the 1990s. SMP systems are limited to a small number of CPUs while NUMA systems have been built with thousands of processors. Initially, multiprocessing was built using multiple discrete CPUs and boards to implement the interconnect between the processors. When the processors and their interconnect are all implemented on a single chip, the technology is known as chip-level multiprocessing (CMP) and the single chip as a multi-core processor.

It was later recognized that finer-grain parallelism existed with a single program. A single program might have several threads (or functions) that could be executed separately or in parallel. Some of the earliest examples of this technology implemented input/output processing such as direct memory access as a separate thread from the computation thread. A more general approach to this technology was introduced in the 1970s when systems were designed to run multiple computation threads in parallel. This technology is known as multi-threading (MT). This approach is considered more cost-effective than multiprocessing, as only a small number of components within a CPU is replicated to support MT as opposed to the entire CPU in the case of MP. In MT, the execution units and the memory system including the caches are shared among multiple threads. The downside of MT is that the hardware support for multithreading is more visible to software than that of MP and thus supervisor software like operating systems have to undergo larger changes to support MT. One type of MT that was implemented is known as temporal multithreading, where one thread is executed until it is stalled waiting for data to return from external memory. In this scheme, the CPU would then quickly context switch to another thread which is ready to run, the switch often done in one CPU clock cycle, such as the UltraSPARC T1. Another type of MT is simultaneous multithreading, where instructions from multiple threads are executed in parallel within one CPU clock cycle.

For several decades from the 1970s to early 2000s, the focus in designing high performance general purpose CPUs was largely on achieving high ILP through technologies such as pipelining, caches, superscalar execution, out-of-order execution, etc. This trend culminated in large, power-hungry CPUs such as the Intel Pentium 4. By the early 2000s, CPU designers were thwarted from achieving higher performance from ILP techniques due to the growing disparity between CPU operating frequencies and main memory operating frequencies as well as escalating CPU power dissipation owing to more esoteric ILP techniques.

CPU designers then borrowed ideas from commercial computing markets such as transaction processing, where the aggregate performance of multiple programs, also known as throughput computing, was more important than the performance of a single thread or process.

This reversal of emphasis is evidenced by the proliferation of dual and more core processor designs and notably, Intel's newer designs resembling its less superscalar P6 architecture. Late designs in several processor families exhibit CMP, including the x86-64 Opteron and Athlon 64 X2, the SPARC UltraSPARC T1, IBM POWER4 and POWER5, as well as several video game console CPUs like the Xbox 360's triple-core PowerPC design, and the PlayStation 3's 7-core Cell microprocessor.

A less common but increasingly important paradigm of processors (and indeed, computing in general) deals with data parallelism. The processors discussed earlier are all referred to as some type of scalar device. As the name implies, vector processors deal with multiple pieces of data in the context of one instruction. This contrasts with scalar processors, which deal with one piece of data for every instruction. Using Flynn's taxonomy, these two schemes of dealing with data are generally referred to as single instruction stream, multiple data stream (SIMD) and single instruction stream, single data stream (SISD), respectively. The great utility in creating processors that deal with vectors of data lies in optimizing tasks that tend to require the same operation (for example, a sum or a dot product) to be performed on a large set of data. Some classic examples of these types of tasks include multimedia applications (images, video and sound), as well as many types of scientific and engineering tasks. Whereas a scalar processor must complete the entire process of fetching, decoding and executing each instruction and value in a set of data, a vector processor can perform a single operation on a comparatively large set of data with one instruction. This is only possible when the application tends to require many steps which apply one operation to a large set of data.

Most early vector processors, such as the Cray-1, were associated almost exclusively with scientific research and cryptography applications. However, as multimedia has largely shifted to digital media, the need for some form of SIMD in general-purpose processors has become significant. Shortly after inclusion of floating-point units started to become commonplace in general-purpose processors, specifications for and implementations of SIMD execution units also began to appear for general-purpose processors. Some of these early SIMD specifications - like HP's Multimedia Acceleration eXtensions (MAX) and Intel's MMX - were integer-only. This proved to be a significant impediment for some software developers, since many of the applications that benefit from SIMD primarily deal with floating-point numbers. Progressively, developers refined and remade these early designs into some of the common modern SIMD specifications, which are usually associated with one ISA. Some notable modern examples include Intel's SSE and the PowerPC-related AltiVec (also known as VMX).

Cloud computing can involve subdividing CPU operation into virtual central processing units (vCPUs).

A host is the virtual equivalent of a physical machine, on which a virtual system is operating. When there are several physical machines operating in tandem and managed as a whole, the grouped computing and memory resources form a cluster. In some systems, it is possible to dynamically add and remove from a cluster. Resources available at a host and cluster level can be partitioned out into resources pools with fine granularity.

The "performance" or "speed" of a processor depends on, among many other factors, the clock rate (generally given in multiples of hertz) and the instructions per clock (IPC), which together are the factors for the instructions per second (IPS) that the CPU can perform.
Many reported IPS values have represented "peak" execution rates on artificial instruction sequences with few branches, whereas realistic workloads consist of a mix of instructions and applications, some of which take longer to execute than others. The performance of the memory hierarchy also greatly affects processor performance, an issue barely considered in MIPS calculations. Because of these problems, various standardized tests, often called "benchmarks" for this purposesuch as SPECinthave been developed to attempt to measure the real effective performance in commonly used applications.

Processing performance of computers is increased by using multi-core processors, which essentially is plugging two or more individual processors (called "cores" in this sense) into one integrated circuit. Ideally, a dual core processor would be nearly twice as powerful as a single core processor. In practice, the performance gain is far smaller, only about 50%, due to imperfect software algorithms and implementation. Increasing the number of cores in a processor (i.e. dual-core, quad-core, etc.) increases the workload that can be handled. This means that the processor can now handle numerous asynchronous events, interrupts, etc. which can take a toll on the CPU when overwhelmed. These cores can be thought of as different floors in a processing plant, with each floor handling a different task. Sometimes, these cores will handle the same tasks as cores adjacent to them if a single core is not enough to handle the information.

Due to specific capabilities of modern CPUs, such as hyper-threading and uncore, which involve sharing of actual CPU resources while aiming at increased utilization, monitoring performance levels and hardware utilization gradually became a more complex task. As a response, some CPUs implement additional hardware logic that monitors actual utilization of various parts of a CPU and provides various counters accessible to software; an example is Intel's "Performance Counter Monitor" technology.



</doc>
<doc id="5221" url="https://en.wikipedia.org/wiki?curid=5221" title="Carnivora">
Carnivora

Carnivora (; from Latin "carō" (stem "carn-") "flesh" and "vorāre" "to devour") is a diverse scrotiferan order that includes over 280 species of placental mammals. Its members are formally referred to as carnivorans, whereas the word "carnivore" (often popularly applied to members of this group) can refer to any meat-eating organism. Carnivorans are the most diverse in size of any mammalian order, ranging from the least weasel ("Mustela nivalis"), at as little as and , to the polar bear ("Ursus maritimus"), which can weigh up to , to the southern elephant seal ("Mirounga leonina"), whose adult males weigh up to and measure up to in length.

Carnivorans have teeth and claws adapted for catching and eating other animals. Many hunt in packs and are social animals, giving them an advantage over larger prey. Some carnivorans, such as cats and pinnipeds, depend entirely on meat for their nutrition. Others, such as raccoons and bears, are more omnivorous, depending on the habitat. The giant panda is largely a herbivore, but feeds on fish, eggs and insects. The polar bear subsists mainly on seals.

Carnivorans are split into two suborders: feliforms ("cat-like") and caniforms ("dog-like").

Carnivorans all share the same arrangement of teeth in which the last upper premolar (named P4) and the first lower molar (named m1) have blade-like enamel crowns that work together as carnassial teeth to shear meat. Carnivorans have had this arrangement for over 60 million years with many adaptions, and these dental adaptions help identify carnivoran species and groupings of species.

Carnivorans evolved in North America out of members of the family Miacidae (miacids) about 42 million years ago. They soon split into cat-like and dog-like forms (Feliformia and Caniformia). Their molecular phylogeny shows the extant Carnivora are a monophyletic group, the crown group of the Carnivoramorpha.

Most carnivorans are terrestrial; they usually have strong, sharp claws, typically with five, but never fewer than four, toes on each foot, and well-developed, prominent canine teeth, cheek teeth (premolars, and molars) that generally have cutting edges. The last premolar of the upper jaw and first molar of the lower are termed the carnassials or sectorial teeth. These blade-like teeth occlude (close) with a scissor-like action for shearing and shredding meat. Carnassials are most highly developed in the Felidae and the least developed in the Ursidae. Carnivorans have six incisors and two conical canines in each jaw. The only two exceptions to this are the sea otter ("Enhydra lutris"), which has four incisors in the lower jaw, and the sloth bear ("Melursus ursinus"), which has four incisors in the upper jaw. The number of molars and premolars is variable between carnivoran species, but all teeth are deeply rooted and are diphyodont. Incisors are retained by carnivorans and the third incisor is commonly large and sharp (canine-like). Carnivorans have either four or five digits on each foot, with the first digit on the forepaws, also known as the dew claw, being vestigial in most species and absent in some.

The superfamily Canoidea (or suborder Caniformia) – Canidae (wolves, dogs and foxes), Mephitidae (skunks and stink badgers), Mustelidae (weasels, badgers, and otters), Procyonidae (raccoons), Ursidae (bears), Ailuridae (red panda), Otariidae (eared seals), Odobenidae (walrus), and Phocidae (earless seals) (the last three families formerly classified in the superfamily Pinnipedia) and the extinct family Amphicyonidae (bear-dogs) – are characterized by having nonchambered or partially chambered auditory bullae, nonretractable claws, and a well-developed baculum. Most species are rather plain in coloration, lacking the flashy spotted or rosetted coats like many species of felids and viverrids have. This is because Canoidea tend to range in the temperate and subarctic biomes, although Mustelidae and Procyonidae have a few tropical species. Most are terrestrial, although a few species, like procyonids, are arboreal. All families except the Canidae and a few species of Mustelidae are plantigrade. Diet is varied and most tend to be omnivorous to some degree, and thus the carnassial teeth are less specialized. Canoidea have more premolars and molars in an elongated skull.

The superfamily Feloidea (or suborder Feliformia)– Felidae (cats), Prionodontidae (Asiatic linsangs), Herpestidae (mongooses), Hyaenidae (hyenas), Viverridae (civets), and Eupleridae (Malagasy carnivorans), as well as the extinct family Nimravidae (paleofelids) – often have spotted, rosetted or striped coats, and tend to be more brilliantly colored than their Canoidean counterparts. This is because these species tend to range in tropical habitats, although a few species do inhabit temperate and subarctic habitats. Many are arboreal or semiarboreal, and the majority are digitigrade. Diet tends to be more strictly carnivorous, especially in the family Felidae. They have fewer teeth and shorter skulls, with much more specialized carnassials meant for shearing meat. Feliformia claws are often retractile, or rarely, semiretractile. The terminal phalanx, with the claw attached, folds back in the forefoot into a sheath by the outer side of the middle phalanx of the digit, and is retained in this position when at rest by a strong elastic ligament. In the hindfoot, the terminal joint or phalanx is retracted on to the top, and not the side of the middle phalanx. Deep flexor muscles straighten the terminal phalanges, so the claws protrude from their sheaths, and the soft "velvety" paw becomes suddenly converted into a formidable weapon. The habitual retraction of the claws preserves their points from wear.

The superfamily Pinnipedia (walruses, seals, and sea lions), now considered to be part of Caniformia, are medium to large (to 6.5 m) aquatic mammals. Being homeothermic (warm-blooded) marine mammals, pinnipeds need a low surface area to body mass ratio. Otherwise, they would suffer from excessive heat loss due to water's high capacity for heat conduction. The body is usually insulated with a thick layer of fat called blubber and typically covered with hair. The digits are not separate, but connected by a thick web that forms flippers for swimming; thus, the forelimbs and hindlimbs are transformed into paddles. This enables them to dive at extreme depths (600 m for the Weddell seal). They can remain underwater for long periods of time, sometimes an hour or more, but most dives are usually short. The facial region of skull is relatively small, with pinnae very small or lacking, and the vibrissae are well developed. The molariform teeth are mostly homodont and the canines are well developed. The tail is very short or absent, the ears are small or absent as well, and the external genitalia are hidden in slits or depressions in the body.

Members of Carnivora have a characteristic skull shape with relatively large brains encased in a heavy skull. The skull has a highly developed zygomatic arch just behind the maxilla (common to all mammals and their cynodont forebears), and they have ossified external auditory bullae. Feloidea have a two-chambered auditory bulla. In addition to allowing extra room for the passage of muscles to work the lower jaw, the zygomatic arch also allows for differentiation of separate muscle groups to be involved in biting and chewing. Masseters attach from the dentary (specifically, the masseteric fossa) to the zygomatic arch and onto the maxilla in front of the arch, providing crushing force. The temporalis attaches from the dentary (specifically, the coronoid process) to the side of the braincase, providing torque about the axis of jaw articulation.

In comparing the skulls of carnivores and herbivores, it can be seen that the shearing force of the temporalis is somewhat more important to carnivores, which have more room on the braincase (this is not unrelated to carnivoran intelligence) and commonly develop a sagittal crest (running from posterior to anterior on the skull), providing yet additional room for temporalis attachment. Carnivoran jaws can only move on a vertical axis, in an up-and-down motion, and cannot move from side-to-side. The jaw joint in carnivores tends to lie within the plane of tooth occlusion, an arrangement that further emphasizes shearing (as in a pair of scissors). In herbivores, the crushing force of the masseters is relatively more important than is shearing. The jaw joint is generally well above the plane of tooth occlusion, allowing extra room for masseteric attachment on the dentary and causing the rotation of the lower jaw to be translated into straight-ahead crushing force between the teeth of the upper and lower jaws.

Dentition relates to the arrangement of teeth in the mouth, with the dental notation for the upper-jaw teeth using the upper-case letters I to denote incisors, C for canines, P for premolars, and M for molars, and the lower-case letters i, c, p and m to denote the mandible teeth. Teeth are numbered using one side of the mouth and from the front of the mouth to the back. In carnivores, the upper premolar P4 and the lower molar m1 form the carnassials that are used together in a scissor-like action to shear the muscle and tendon of prey.

Carnivora have a simple stomach adapted to digest primarily meat, as compared to the elaborate digestive systems of herbivorous animals, which are necessary to break down tough, complex plant fibers. The caecum is either absent or short and simple, and the colon is not sacculated or much wider than the small intestine. Most species of Carnivora are, to some degree, omnivorous, except the Felidae and Pinnipedia, which are obligate carnivores. Most have highly developed senses, especially vision and hearing, and often a highly acute sense of smell in many species, such as in the Canoidea. They are excellent runners: some are long-distance runners, but more commonly are sprinters. Even bears and raccoons, although seemingly slow and clumsy, are capable of remarkable bursts of speed.

Carnivorans include carnivores, omnivores, and even a few primarily herbivorous species, such as the giant panda and the binturong. Important teeth for carnivorans are the large, slightly recurved canines, used to dispatch prey, and the carnassial complex, used to rend meat from bone and slice it into digestible pieces. Dogs have molar teeth behind the carnassials for crushing bones, but cats have only a greatly reduced, functionless molar behind the carnassial in the upper jaw. Cats will strip bones clean but will not crush them to get the marrow inside. Omnivores, such as bears and raccoons, have developed blunt, molar-like carnassials. Carnassials are a key adaptation for terrestrial vertebrate predation; all other placental orders are primarily herbivores, insectivores, or aquatic.

Most male carnivorans have a baculum, although it is relatively short in felids, and absent in hyenas. Carnivorans tend to produce a single litter annually, but some produce multiple litters a year, and larger carnivorans, like bears, have gaps of 2–3 yr between litters. The average gestation period lies between 50 and 115 days, although the ursids and mustelids have delayed implantation, thus extending the gestation period six to 9 months beyond the normal period. Litter sizes are usually small, ranging from one to 13 young, which are born with underdeveloped eyes and ears. In most species, the mother has exclusive or at least primary care of the offspring. Many species of carnivorans are solitary, but a few are gregarious.

Carnivorans evolved from members of the family Miacidae (miacids, now recognized as paraphyletic). The transition from Miacidae to Carnivora was a general trend in the middle and late Eocene, with taxa from both North America and Eurasia involved. The divergence of carnivorans from other miacids, as well as the divergence of the two clades within Carnivora, Caniformia and Feliformia, is now inferred to have happened in the middle Eocene, about 42 million years ago (mya).

Traditionally, the extinct family Viverravidae (viverravids) had been thought to be the earliest carnivorans, with fossil records first appearing in the Paleocene of North America about 60 mya, but recently described evidence from cranial morphology now places them outside the order Carnivora.

The Miacidae are not a monophyletic group, but a paraphyletic array of stem taxa. Today, Carnivora is restricted to the crown group, Carnivora and miacoids are grouped in the clade Carnivoramorpha, and the miacoids are regarded as basal carnivoramorphs. Based on dental features and braincase sizes, it is now known that Carnivora must have evolved from a form even more primitive than Creodonta, and thus these two orders may not even be sister groups. The Carnivora, Creodonta, Pholidota, and a few other extinct orders are informally grouped together in the clade Ferae. Older classification schemes divided the order into two suborders: Fissipedia (which included the families of primarily land Carnivora) and Pinnipedia (which included the true seals, eared seals, and walrus). However, it is now recognized that the Fissipedia is a paraphyletic group and that the pinnipeds were not the sister group to the fissipeds but rather had arisen from among them.

Carnivora are generally divided into the suborders Feliformia (cat-like) and Caniformia (dog-like), the latter of which includes the pinnipeds. The pinnipeds are part of a clade, known as the Arctoidea, which also includes the Ursidae (bears) and the superfamily Musteloidea. The Musteloidea in turn consists of the Mustelidae (mustelids: weasels), Procyonidae (procyonids: raccoons), Mephitidae (skunks) and "Ailurus" (red panda). The oldest caniforms are the "Miacis" species "Miacis cognitus", the Amphicyonidae (bear-dogs) such as "Daphoenus", and "Hesperocyon" (of the family Canidae, subfamily Hesperocyoninae). Hesperocyonine canids first appeared in North America, and the earliest species is currently dated at 39.74 mya, but they were not represented in Europe until well into the Miocene, and not into Asia and Africa until the Pliocene. "Miacis" and Amphicyonidae were the first of the caniforms to split from the others and are sometimes considered to be sister groups to Ursidae, but the exact closeness of Amphicyonidae and Ursidae, as well as Arctoidae to Ursidae, is still uncertain. The Canidae (wolves, coyotes, jackals, foxes and dogs) are generally considered to be the sister group to Arctoidea. The Ursidae first occur in North America in the Late Eocene (ca. 38 mya) as the very small and graceful "Parictis" that had a skull only 7 cm long. Like the canids, this family does not appear in Eurasia and Africa until the Miocene. The other caniform families Amphicyonidae, Mustelidae and Procyonidae occur in both the Old World and the New World by the Late Eocene and Early Oligocene.

The ancestor of all Feliformia evolved from the Caniformia-Feliformia split. "Nandinia", the African palm civet, seems to be the most primitive of all the feliforms and the very first to split from the others. The Asiatic linsangs of the genus "Prionodon" (traditionally placed in the Viverridae) form a family of their own, as some recent studies indicate that "Prionodon" is actually the closest living relative to the cats. The Nimravidae are sometimes seen as the most basal of all feliforms and the first to split from the others, but there is a possibility that Nimravidae might not even belong within the order, and therefore its position as a clade within Carnivora is currently unstable. Other studies indicate that the barbourofelids form a separate family, which is closely related to the true felids instead of being related to the nimravids. Recognizable nimravid fossils date from the late Eocene (37 mya), from the Chadronian White River Carnivora Formation at Flagstaff Rim, Wyoming. Nimravid diversity appears to have peaked about 28 mya. The hypercarnivorous (strictly meat-eating) nimravid feliforms were extinct in North America after 26 mya and felids did not arrive in North America until the early middle Miocene (16 mya).

It has been suggested that canids evolved hypercarnivorous morphologies because feliforms were absent during this period (the "cat-gap", 26-18.5 mya), however recent data do not support this hypothesis. Hypercarnivore feliforms (felids and nimravids) occupied an area that canids did not and where felids, nimravids, and hypercarnivorous creodonts are found. Hypercarnivorous canids were present before the disappearance of the nimravids, and all became extinct before the appearance of felids. Following the extinction of nimravids, only three taxa originated, two of which were relatively small in body size. Disparity increased during the "cat-gap" even with the extinction of the hypercarnivorous extremes. This was due to the extinction of morphological intermediates, and because carnivorans began to occupy hypocarnivorous (nonmeat-specialist) morphospace for the first time in North America. Procyonids did not arrive in North America until the early Miocene, and "modern" ursids (e.g., Ursinae), did not arrive until the late Miocene. Extinct lineages of Ursidae were present in North America from the late Eocene through the Miocene and amphicyonids (bear-dogs) were present during this period as well, but occupied a morphospace generally shared with canids and not in close proximity to ursids. A large question remains as to why there was a progressive decline in hypercarnivorous carnivoramorphans during the late Oligocene/early Miocene. During this period all hypercarnivorous forms disappeared from the fossil record, including hypercarnivorous feliforms, canids, and mustelids. One possible explanation is climate change. Earth was gradually cooling after the late Paleocene, and over a period spanning the Eocene/Oligocene boundary, a dramatic climatic cooling event occurred.

A recent study has finally resolved the exact position of "Ailurus": the red panda is neither a procyonid nor an ursid, but forms a monotypic family, with the other musteloids as its closest living relatives. The same study also showed that the mustelids are not a primitive family, as was once thought. Their small body size is a secondary trait—the primitive body form of the arctoids was large, not small. Recent molecular studies also suggest that the endemic Carnivora of Madagascar, including three genera usually classed with the civets and four genera of mongooses classed with the Herpestidae, are all descended from a single ancestor. They form a single sister taxon to the Herpestidae. The hyenas are also closely related to this clade.

When the order Carnivora was first named, there were only five families:

The most common modern classification scheme divides the Carnivora into sixteen living and a number of extinct families, as follows:

The cladogram is based on Flynn (2005).




</doc>
<doc id="5222" url="https://en.wikipedia.org/wiki?curid=5222" title="Colombia">
Colombia

Colombia ( ; ), officially the Republic of Colombia (), is a sovereign state largely situated in the northwest of South America, with territories in Central America. Colombia shares a border to the northwest with Panama, to the east with Venezuela and Brazil and to the south with Ecuador and Peru. It shares its maritime limits with Costa Rica, Nicaragua, Honduras, Jamaica, Haiti and the Dominican Republic. It is a unitary, constitutional republic comprising thirty-two departments. The territory of what is now Colombia was originally inhabited by indigenous peoples, including the Muisca, Quimbaya and the Tairona.

The Spanish set foot on Colombian soil for the first time in 1499 and in the first half of the 16th century initiated a period of conquest and colonization, ultimately creating the New Kingdom of Granada, with Santafé de Bogotá as its capital. Independence from Spain was acquired in 1819, but by 1830 the "Gran Colombia" Federation was dissolved. What is now Colombia and Panama emerged as the Republic of New Granada. The new nation experimented with federalism as the Granadine Confederation (1858), and then the United States of Colombia (1863), before the Republic of Colombia was finally declared in 1886. Panama seceded in 1903. Since the 1960s, the country has suffered from an asymmetric low-intensity armed conflict, which escalated in the 1990s but then decreased from 2005 onward. Colombia is one of the most ethnically and linguistically diverse countries in the world, and thereby possesses a rich cultural heritage. The urban centres are mostly located in the highlands of the Andes mountains.

Colombian territory also encompasses Amazon rainforest, tropical grassland and both Caribbean and Pacific coastlines. Ecologically, it is one of the world's 17 megadiverse countries, and the most densely biodiverse of these per square kilometer. Colombia is a middle power and a regional actor with the fourth-largest economy in Latin America, is part of the CIVETS group of six leading emerging markets and is a member of the UN, the WTO, the OAS, the Pacific Alliance, and other international organizations. Colombia has a diversified economy with macroeconomic stability and favorable growth prospects in the long run.

The name "Colombia" is derived from the last name of Christopher Columbus (, ). It was conceived by the Venezuelan revolutionary Francisco de Miranda as a reference to all the New World, but especially to those portions under Spanish rule (by then from Mississippi river to Patagonia). The name was later adopted by the Republic of Colombia of 1819, formed from the territories of the old Viceroyalty of New Granada (modern-day Colombia, Panama, Venezuela, Ecuador, and northwest Brazil).

When Venezuela, Ecuador and Cundinamarca came to exist as independent states, the former Department of Cundinamarca adopted the name "Republic of New Granada". New Granada officially changed its name in 1858 to the Granadine Confederation. In 1863 the name was again changed, this time to United States of Colombia, before finally adopting its present name – the Republic of Colombia – in 1886.

To refer to this country, the Colombian government uses the terms "Colombia" and "República de Colombia".

Owing to its location, the present territory of Colombia was a corridor of early human migration from Mesoamerica and the Caribbean to the Andes and Amazon basin. The oldest archaeological finds are from the Pubenza and El Totumo sites in the Magdalena Valley southwest of Bogotá. These sites date from the Paleoindian period (18,000–8000 BCE). At Puerto Hormiga and other sites, traces from the Archaic Period (~8000–2000 BCE) have been found. Vestiges indicate that there was also early occupation in the regions of El Abra and Tequendama in Cundinamarca. The oldest pottery discovered in the Americas, found at San Jacinto, dates to 5000–4000 BCE.
Indigenous people inhabited the territory that is now Colombia by 12,500 BCE. Nomadic hunter-gatherer tribes at the El Abra, Tibitó and Tequendama sites near present-day Bogotá traded with one another and with other cultures from the Magdalena River Valley. Between 5000 and 1000 BCE, hunter-gatherer tribes transitioned to agrarian societies; fixed settlements were established, and pottery appeared. Beginning in the 1st millennium BCE, groups of Amerindians including the Muisca, Zenú, Quimbaya, and Tairona developed the political system of "cacicazgos" with a pyramidal structure of power headed by caciques. The Muisca inhabited mainly the area of what is now the Departments of Boyacá and Cundinamarca high plateau ("Altiplano Cundiboyacense") where they formed the Muisca Confederation. They farmed maize, potato, quinoa and cotton, and traded gold, emeralds, blankets, ceramic handicrafts, coca and especially rock salt with neighboring nations. The Tairona inhabited northern Colombia in the isolated mountain range of Sierra Nevada de Santa Marta. The Quimbaya inhabited regions of the Cauca River Valley between the Western and Central Ranges of the Colombian Andes. Most of the Amerindians practiced agriculture and the social structure of each indigenous community was different. Some groups of indigenous people such as the Caribs lived in a state of permanent war, but others had less bellicose attitudes. The Incas expanded their empire onto the southwest part of the country.

Alonso de Ojeda (who had sailed with Columbus) reached the Guajira Peninsula in 1499. Spanish explorers, led by Rodrigo de Bastidas, made the first exploration of the Caribbean coast in 1500. Christopher Columbus navigated near the Caribbean in 1502. In 1508, Vasco Núñez de Balboa accompanied an expedition to the territory through the region of Gulf of Urabá and they founded the town of Santa María la Antigua del Darién in 1510, the first stable settlement on the continent. 

Santa Marta was founded in 1525, and Cartagena in 1533. Spanish conquistador Gonzalo Jiménez de Quesada led an expedition to the interior in April 1536, and christened the districts through which he passed "New Kingdom of Granada". In August 1538, he founded provisionally its capital near the Muisca cacicazgo of Bacatá, and named it "Santa Fe". The name soon acquired a suffix and was called Santa Fe de Bogotá. Two other notable journeys by early conquistadors to the interior took place in the same period. Sebastián de Belalcázar, conqueror of Quito, traveled north and founded Cali, in 1536, and Popayán, in 1537; from 1536 to 1539, German conquistador Nikolaus Federmann crossed the Llanos Orientales and went over the Cordillera Oriental in a search for El Dorado, the "city of gold". The legend and the gold would play a pivotal role in luring the Spanish and other Europeans to New Granada during the 16th and 17th centuries.

The conquistadors made frequent alliances with the enemies of different indigenous communities. Indigenous allies were crucial to conquest, as well as to creating and maintaining empire. Indigenous peoples in New Granada experienced a decline in population due to conquest as well as Eurasian diseases, such as smallpox, to which they had no immunity. With the risk that the land was deserted, the Spanish Crown sold properties to all persons interested in colonised territories creating large farms and possession of mines.

In the 16th century, the nautical science in Spain reached a great development thanks to numerous scientific figures of the Casa de Contratación and nautical science was an essential pillar of the Iberian expansion.

In 1542, the region of New Granada, along with all other Spanish possessions in South America, became part of the Viceroyalty of Peru, with its capital at Lima. In 1547, New Granada became the Captaincy-General of New Granada within the viceroyalty.

In 1549, the Royal Audiencia was created by a royal decree, and New Granada was ruled by the Royal Audience of Santa Fe de Bogotá, which at that time comprised the provinces of Santa Marta, Rio de San Juan, Popayán, Guayana and Cartagena. But important decisions were taken from the colony to Spain by the Council of the Indies.
In the 16th century, Europeans began to bring slaves from Africa. Spain was the only European power that could not establish factories in Africa to purchase slaves and therefore the Spanish empire relied on the asiento system, awarding merchants (mostly from Portugal, France, England and the Dutch Empire) the license to trade enslaved people to their overseas territories. Also there were people who defended the human rights and freedoms of oppressed peoples. The indigenous peoples could not be enslaved because they were legally subjects of the Spanish Crown and to protect the indigenous peoples, several forms of land ownership and regulation were established: "resguardos", "encomiendas" and "haciendas".
In 1717 the Viceroyalty of New Granada was originally created, and then it was temporarily removed, to finally be reestablished in 1739. The Viceroyalty had Santa Fé de Bogotá as its capital. This Viceroyalty included some other provinces of northwestern South America which had previously been under the jurisdiction of the Viceroyalties of New Spain or Peru and correspond mainly to today's Venezuela, Ecuador and Panama. So, Bogotá became one of the principal administrative centers of the Spanish possessions in the New World, along with Lima and Mexico City, though it remained somewhat backward compared to those two cities in several economic and logistical ways.

After Great Britain declared war on Spain in 1739, Cartagena quickly became the British forces' top target but an upset Spanish victory during the War of Jenkins' Ear, a war with Great Britain for economic control of the Caribbean, cemented Spanish dominance in the Caribbean until the Seven Years' War.

The 18th-century priest, botanist and mathematician José Celestino Mutis was delegated by Viceroy Antonio Caballero y Góngora to conduct an inventory of the nature of the New Granada. Started in 1783, this became known as the Royal Botanical Expedition to New Granada which classified plants, wildlife and founded the first astronomical observatory in the city of Santa Fe de Bogotá. In July 1801 the Prussian scientist Alexander von Humboldt reached Santa Fe de Bogotá where he met with Mutis. In addition, historical figures in the process of independence in New Granada emerged from the expedition as the astronomer Francisco José de Caldas, the scientist Francisco Antonio Zea, the zoologist Jorge Tadeo Lozano and the painter Salvador Rizo.

Since the beginning of the periods of conquest and colonization, there were several rebel movements against Spanish rule, but most were either crushed or remained too weak to change the overall situation. The last one that sought outright independence from Spain sprang up around 1810, following the independence of St. Domingue (present-day Haiti) in 1804, which provided some support to an eventual leader of this rebellion: Simón Bolívar. Francisco de Paula Santander also would play a decisive role.

A movement was initiated by Antonio Nariño, who opposed Spanish centralism and led the opposition against the Viceroyalty. Cartagena became independent in November 1811. In 1811 the United Provinces of New Granada were proclaimed, headed by Camilo Torres Tenorio. The emergence of two distinct ideological currents among the patriots (federalism and centralism) gave rise to a period of instability. Shortly after the Napoleonic Wars ended, Ferdinand VII, recently restored to the throne in Spain, unexpectedly decided to send military forces to retake most of northern South America. The viceroyalty was restored under the command of Juan Sámano, whose regime punished those who participated in the patriotic movements, ignoring the political nuances of the juntas. The retribution stoked renewed rebellion, which, combined with a weakened Spain, made possible a successful rebellion led by the Venezuelan-born Simón Bolívar, who finally proclaimed independence in 1819. The pro-Spanish resistance was defeated in 1822 in the present territory of Colombia and in 1823 in Venezuela.

The territory of the Viceroyalty of New Granada became the Republic of Colombia, organized as a union of the current territories of Colombia, Panama, Ecuador, Venezuela, parts of Guyana and Brazil and north of Marañón River. The Congress of Cúcuta in 1821 adopted a constitution for the new Republic. Simón Bolívar became the first President of Colombia, and Francisco de Paula Santander was made Vice President. However, the new republic was unstable and three countries emerged from the collapse of Gran Colombia in 1830 (New Granada, Ecuador and Venezuela).

Colombia was the first constitutional government in South America, and the Liberal and Conservative parties, founded in 1848 and 1849 respectively, are two of the oldest surviving political parties in the Americas. Slavery was abolished in the country in 1851.

Internal political and territorial divisions led to the dissolution of Gran Colombia in 1830. The so-called "Department of Cundinamarca" adopted the name "New Granada", which it kept until 1858 when it became the "Confederación Granadina" (Granadine Confederation). After a two-year civil war in 1863, the "United States of Colombia" was created, lasting until 1886, when the country finally became known as the Republic of Colombia. Internal divisions remained between the bipartisan political forces, occasionally igniting very bloody civil wars, the most significant being the Thousand Days' War (1899–1902).

The United States of America's intentions to influence the area (especially the Panama Canal construction and control) led to the separation of the Department of Panama in 1903 and the establishment of it as a nation. The United States paid Colombia $25,000,000 in 1921, seven years after completion of the canal, for redress of President Roosevelt's role in the creation of Panama, and Colombia recognized Panama under the terms of the Thomson–Urrutia Treaty. Colombia and Peru went to war because of territory disputes far in the Amazon basin. The war ended with a peace deal brokered by the League of Nations. The League finally awarded the disputed area to Colombia in June 1934.

Soon after, Colombia achieved some degree of political stability, which was interrupted by a bloody conflict that took place between the late 1940s and the early 1950s, a period known as "La Violencia" ("The Violence"). Its cause was mainly mounting tensions between the two leading political parties, which subsequently ignited after the assassination of the Liberal presidential candidate Jorge Eliécer Gaitán on 9 April 1948. The ensuing riots in Bogotá, known as El Bogotazo, spread throughout the country and claimed the lives of at least 180,000 Colombians.

Colombia entered the Korean War when Laureano Gómez was elected president. It was the only Latin American country to join the war in a direct military role as an ally of the United States. Particularly important was the resistance of the Colombian troops at Old Baldy.

The violence between the two political parties decreased first when Gustavo Rojas deposed the President of Colombia in a coup d'état and negotiated with the guerrillas, and then under the military junta of General Gabriel París.

After Rojas' deposition, the Colombian Conservative Party and Colombian Liberal Party agreed to create the National Front, a coalition which would jointly govern the country. Under the deal, the presidency would alternate between conservatives and liberals every 4 years for 16 years; the two parties would have parity in all other elective offices. The National Front ended "La Violencia", and National Front administrations attempted to institute far-reaching social and economic reforms in cooperation with the Alliance for Progress. Despite the progress in certain sectors, many social and political problems continued, and guerrilla groups were formally created such as the FARC, the ELN and the M-19 to fight the government and political apparatus.

Since the 1960s, the country has suffered from an asymmetric low-intensity armed conflict between government forces, leftist guerrilla groups and right wing paramilitaries. The conflict escalated in the 1990s, mainly in remote rural areas. Since the beginning of the armed conflict, human rights defenders have fought for the respect for human rights, despite staggering opposition. Several guerrillas' organizations decided to demobilize after peace negotiations in 1989–1994.

The United States has been heavily involved in the conflict since its beginnings, when in the early 1960s the U.S. government encouraged the Colombian military to attack leftist militias in rural Colombia. This was part of the U.S. fight against communism. Mercenaries and multinational corporations such as Chiquita Brands International are some of the international actors that have contributed to the violence of the conflict.

On 4 July 1991, a new Constitution was promulgated. The changes generated by the new constitution are viewed as positive by Colombian society.

The administration of President Álvaro Uribe (2002–10), adopted the democratic security policy which included an integrated counter-terrorism and counter-insurgency campaign. The Government economic plan also promoted confidence in investors. As part of a controversial peace process the AUC (right-wing paramilitaries) as a formal organization had ceased to function. In February 2008, millions of Colombians demonstrated against FARC and other outlawed groups.

After peace negotiations in Cuba, the Colombian government of President Juan Manuel Santos and guerrilla of FARC-EP announced a final agreement to end the conflict. However, a referendum to ratify the deal was unsuccessful. Afterward, the Colombian government and the FARC signed a revised peace deal in November 2016, which the Colombian congress approved. In 2016, President Santos was awarded the Nobel Peace Prize. The Government began a process of attention and comprehensive reparation for victims of conflict. Colombia shows modest progress in the struggle to defend human rights, as expressed by HRW. A Special Jurisdiction for Peace has been created to investigate, clarify, prosecute and punish serious human rights violations and grave breaches of international humanitarian law which occurred during the armed conflict and to satisfy victims' right to justice. During his visit to Colombia, Pope Francis paid tribute to the victims of the conflict.

Colombia's relations with Venezuela have fluctuated due to ideological differences between both governments. Colombia has offered humanitarian support with food and medicines to mitigate the shortage of supplies in Venezuela. Latin American countries often critical of Venezuela rejected U.S. military threat against Venezuela, as the United States has lost its credibility due to its interventions such as the infamous Operation Condor and the genocidal dictatorships supported by the U.S. government. Colombia's Foreign Ministry said that all efforts to resolve Venezuela's crisis should be peaceful and respect its sovereignty. Colombia proposed the idea of the Sustainable Development Goals and a final document was adopted by the United Nations. Colombia with a very clean electricity generation matrix reaffirms its support for the Paris Climate Agreement.

The geography of Colombia is characterized by its six main natural regions that present their own unique characteristics, from the Andes mountain range region shared with Ecuador and Venezuela; the Pacific coastal region shared with Panama and Ecuador; the Caribbean coastal region shared with Venezuela and Panama; the "Llanos" (plains) shared with Venezuela; the Amazon Rainforest region shared with Venezuela, Brazil, Peru and Ecuador; to the insular area, comprising islands in both the Atlantic and Pacific oceans.

Colombia is bordered to the northwest by Panama; to the east by Venezuela and Brazil; to the south by Ecuador and Peru; it established its maritime boundaries with neighboring countries through seven agreements on the Caribbean Sea and three on the Pacific Ocean. It lies between latitudes 12°N and 4°S, and longitudes 67° and 79°W.

Part of the Ring of Fire, a region of the world subject to earthquakes and volcanic eruptions, in the interior of Colombia the Andes are the prevailing geographical feature. Most of Colombia's population centers are located in these interior highlands. Beyond the Colombian Massif (in the south-western departments of Cauca and Nariño) these are divided into three branches known as "cordilleras" (mountain ranges): the Cordillera Occidental, running adjacent to the Pacific coast and including the city of Cali; the Cordillera Central, running between the Cauca and Magdalena River valleys (to the west and east respectively) and including the cities of Medellín, Manizales, Pereira and Armenia; and the Cordillera Oriental, extending north east to the Guajira Peninsula and including Bogotá, Bucaramanga and Cúcuta.

Peaks in the Cordillera Occidental exceed , and in the Cordillera Central and Cordillera Oriental they reach . At , Bogotá is the highest city of its size in the world.

East of the Andes lies the savanna of the "Llanos", part of the Orinoco River basin, and, in the far south east, the jungle of the Amazon rainforest. Together these lowlands comprise over half Colombia's territory, but they contain less than 6% of the population. To the north the Caribbean coast, home to 21.9% of the population and the location of the major port cities of Barranquilla and Cartagena, generally consists of low-lying plains, but it also contains the Sierra Nevada de Santa Marta mountain range, which includes the country's tallest peaks (Pico Cristóbal Colón and Pico Simón Bolívar), and the La Guajira Desert. By contrast the narrow and discontinuous Pacific coastal lowlands, backed by the Serranía de Baudó mountains, are sparsely populated and covered in dense vegetation. The principal Pacific port is Buenaventura.

The main rivers of Colombia are Magdalena, Cauca, Guaviare, Atrato, Meta, Putumayo and Caquetá. Colombia has four main drainage systems: the Pacific drain, the Caribbean drain, the Orinoco Basin and the Amazon Basin. The Orinoco and Amazon Rivers mark limits with Colombia to Venezuela and Peru respectively.

Protected areas and the "National Park System" cover an area of about and account for 12.77% of the Colombian territory. Compared to neighboring countries, rates of deforestation in Colombia are still relatively low. Colombia is the sixth country in the world by magnitude of total renewable freshwater supply, and still has large reserves of freshwater.

The climate of Colombia is characterized for being tropical presenting variations within six natural regions and depending on the altitude, temperature, humidity, winds and rainfall. The diversity of climate zones in Colombia is characterized for having tropical rainforests, savannas, steppes, deserts and mountain climate.

Mountain climate is one of the unique features of the Andes and other high altitude reliefs where climate is determined by elevation. Below in elevation is the warm altitudinal zone, where temperatures are above . About 82.5% of the country's total area lies in the warm altitudinal zone. The temperate climate altitudinal zone located between is characterized for presenting an average temperature ranging between . The cold climate is present between and the temperatures vary between . Beyond the cold land lie the alpine conditions of the forested zone and then the treeless grasslands of the páramos. Above , where temperatures are below freezing, the climate is glacial, a zone of permanent snow and ice.

Colombia is one of the megadiverse countries in biodiversity, ranking first in bird species. As for plants, the country has between 40,000 and 45,000 plant species, equivalent to 10 or 20% of total global species, which is even more remarkable given that Colombia is considered a country of intermediate size. Colombia is the second most biodiverse country in the world, lagging only after Brazil which is approximately 7 times bigger.

Colombia is the country in the planet more characterized by a high biodiversity, with the highest rate of species by area unit worldwide and it has the largest number of endemisms (species that are not found naturally anywhere else) of any country. About 10% of the species of the Earth live in Colombia, including over 1,900 species of bird, more than in Europe and North America combined, Colombia has 10% of the world's mammals species, 14% of the amphibian species and 18% of the bird species of the world.

Colombia has about 2,000 species of marine fish and is the second most diverse country in freshwater fish. Colombia is the country with more endemic species of butterflies, number 1 in terms of orchid species and approximately 7,000 species of beetles. Colombia is second in the number of amphibian species and is the third most diverse country in reptiles and palms. There are about 1,900 species of mollusks and according to estimates there are about 300,000 species of invertebrates in the country. In Colombia there are 32 terrestrial biomes and 314 types of ecosystems.

The government of Colombia takes place within the framework of a presidential participatory democratic republic as established in the Constitution of 1991. In accordance with the principle of separation of powers, government is divided into three branches: the executive branch, the legislative branch and the judicial branch.

As the head of the executive branch, the President of Colombia serves as both head of state and head of government, followed by the Vice President and the Council of Ministers. The president is elected by popular vote to serve four-year term (In 2015, Colombia's Congress approved the repeal of a 2004 constitutional amendment that eliminated the one-term limit for presidents). At the provincial level executive power is vested in department governors, municipal mayors and local administrators for smaller administrative subdivisions, such as "corregimientos" or "comunas". All regional elections are held one year and five months after the presidential election.

The legislative branch of government is represented nationally by the Congress, a bicameral institution comprising a 166-seat Chamber of Representatives and a 102-seat Senate. The Senate is elected nationally and the Chamber of Representatives is elected in electoral districts. Members of both houses are elected to serve four-year terms two months before the president, also by popular vote.

The judicial branch is headed by four high courts, consisting of the Supreme Court which deals with penal and civil matters, the Council of State, which has special responsibility for administrative law and also provides legal advice to the executive, the Constitutional Court, responsible for assuring the integrity of the Colombian constitution, and the Superior Council of Judicature, responsible for auditing the judicial branch. Colombia operates a system of civil law, which since 2005 has been applied through an adversarial system.

Despite a number of controversies, the democratic security policy has ensured that former President Uribe remained popular among Colombian people, with his approval rating peaking at 76%, according to a poll in 2009. However, having served two terms, he was constitutionally barred from seeking re-election in 2010. In the run-off elections on 20 June 2010 the former Minister of defense Juan Manuel Santos won with 69% of the vote against the second most popular candidate, Antanas Mockus. A second round was required since no candidate received over the 50% winning threshold of votes. Santos won nearly 51% of the vote in second-round elections on 15 June 2014, beating right-wing rival Óscar Iván Zuluaga, who won 45%. His term as Colombia's president runs for four years beginning 7 August 2014.

The foreign affairs of Colombia are headed by the President, as head of state, and managed by the Minister of Foreign Affairs. Colombia has diplomatic missions in all continents.

Colombia was one of the 4 founding members of the Pacific Alliance, which is a political, economic and co-operative integration mechanism that promotes the free circulation of goods, services, capital and persons between the members, as well as a common stock exchange and joint embassies in several countries. Colombia is also a member of the United Nations, the World Trade Organization, the Organization of American States, the Organization of Ibero-American States, the Union of South American Nations and the Andean Community of Nations. Colombia is a global partner of NATO. Colombia is currently in the accession process with the OECD.

The executive branch of government is responsible for managing the defense of Colombia, with the President commander-in-chief of the armed forces. The Ministry of Defence exercises day-to-day control of the military and the Colombian National Police. Colombia has 455,461 active military personnel. And in 2016 3.4% of the country's GDP went towards military expenditure, placing it 24th in the world. Colombia's armed forces are the largest in Latin America, and it is the second largest spender on its military after Brazil.

The Colombian military is divided into three branches: the National Army of Colombia; the Colombian Air Force; and the Colombian Navy. The National Police functions as a gendarmerie, operating independently from the military as the law enforcement agency for the entire country. Each of these operates with their own intelligence apparatus separate from the National Intelligence Directorate (DNI, in Spanish).

The National Army is formed by divisions, brigades, special brigades and special units; the Colombian Navy by the Naval Infantry, the Naval Force of the Caribbean, the Naval Force of the Pacific, the Naval Force of the South, the Naval Force of the East, Colombia Coast Guards, Naval Aviation and the Specific Command of San Andres y Providencia; and the Air Force by 15 air units. The National Police has a presence in all municipalities.

Colombia is divided into 32 departments and one capital district, which is treated as a department (Bogotá also serves as the capital of the department of Cundinamarca). Departments are subdivided into municipalities, each of which is assigned a municipal seat, and municipalities are in turn subdivided into "corregimientos" in rural areas and into "comunas" in urban areas. Each department has a local government with a governor and assembly directly elected to four-year terms, and each municipality is headed by a mayor and council. There is a popularly elected local administrative board in each of the "corregimientos" or "comunas".

In addition to the capital four other cities have been designated districts (in effect special municipalities), on the basis of special distinguishing features. These are Barranquilla, Cartagena, Santa Marta and Buenaventura. Some departments have local administrative subdivisions, where towns have a large concentration of population and municipalities are near each other (for example in Antioquia and Cundinamarca). Where departments have a low population (for example Amazonas, Vaupés and Vichada), special administrative divisions are employed, such as "department "corregimientos"", which are a hybrid of a municipality and a "corregimiento".

Historically an agrarian economy, Colombia urbanised rapidly in the 20th century, by the end of which just 15.8% of the workforce were employed in agriculture, generating just 6.6% of GDP; 19.6% of the workforce were employed in industry and 64.6% in services, responsible for 33.4% and 59.9% of GDP respectively. The country's economic production is dominated by its strong domestic demand. Consumption expenditure by households is the largest component of GDP.

Colombia's market economy grew steadily in the latter part of the 20th century, with gross domestic product (GDP) increasing at an average rate of over 4% per year between 1970 and 1998. The country suffered a recession in 1999 (the first full year of negative growth since the Great Depression), and the recovery from that recession was long and painful. However, in recent years growth has been impressive, reaching 6.9% in 2007, one of the highest rates of growth in Latin America. According to International Monetary Fund estimates, in 2012 Colombia's GDP (PPP) was US$500 billion (28th in the world and third in South America).

Total government expenditures account for 27.9 percent of the domestic economy. External debt equals 39.9 percent of gross domestic product. A strong fiscal climate was reaffirmed by a boost in bond ratings. Annual inflation closed 2017 at 4.09% YoY (vs. 5.75% YoY in 2016). The average national unemployment rate in 2017 was 9.4%, although the informality is the biggest problem facing the labour market (the income of formal workers climbed 24.8% in 5 years while labor incomes of informal workers rose only 9%). Colombia has Free trade Zone (FTZ), such as Zona Franca del Pacifico, located in the Valle del Cauca, one of the most striking areas for foreign investment.

The financial sector has grown favorably due to good liquidity in the economy, the growth of credit and the positive performance of the Colombian economy. The Colombian Stock Exchange through the Latin American Integrated Market (MILA) offers a regional market to trade equities. Colombia is now one of only three economies with a perfect score on the strength of legal rights index, according to the World Bank.

The electricity production in Colombia comes mainly from renewable energy sources. 69.93% is obtained from the hydroelectric generation. Colombia's commitment to renewable energy was recognized in the 2014 "Global Green Economy Index (GGEI)", ranking among the top 10 nations in the world in terms of greening efficiency sectors.

Colombia is rich in natural resources, and its main exports include mineral fuels, oils, distillation products, fruit and other agricultural products, sugars and sugar confectionery, food products, plastics, precious stones, metals, forest products, chemical goods, pharmaceuticals, vehicles, electronic products, electrical equipments, perfumery and cosmetics, machinery, manufactured articles, textile and fabrics, clothing and footwear, glass and glassware, furniture, prefabricated buildings, military products, home and office material, construction equipment, software, among others. Principal trading partners are the United States, China, the European Union and some Latin American countries.

Non-traditional exports have boosted the growth of Colombian foreign sales as well as the diversification of destinations of export thanks to new free trade agreements.

In 2017, the National Administrative Department of Statistics (DANE) reported that 26.9% of the population were living below the poverty line, of which 7.4% in "extreme poverty". The multidimensional poverty rate stands at 17.0 percent of the population. The Government has also been developing a process of financial inclusion within the country's most vulnerable population.

Recent economic growth has led to a considerable increase of new millionaires, including the new entrepreneurs, Colombians with a net worth exceeding US $1 billion.

The contribution of Travel & Tourism to GDP was USD5,880.3bn (2.0% of total GDP) in 2016. Tourism generated 556,135 jobs (2.5% of total employment) in 2016. Foreign tourist visits were predicted to have risen from 0.6 million in 2007 to 3.3 million in 2016.

Colombia has more than 3,950 research groups in science and technology. iNNpulsa, a government body that promotes entrepreneurship and innovation in the country, provides grants to startups, in addition to other services it and institutions like Apps.co provide. Co-working spaces have arisen to serve as communities for startups large and small. Organizations such as the Corporation for Biological Research (CIB) for the support of young people interested in scientific work has been successfully developed in Colombia. The International Center for Tropical Agriculture based in Colombia investigates the increasing challenge of global warming and food security.

Important inventions related to the medicine have been made in Colombia, such as the first external artificial pacemaker with internal electrodes, invented by the electronics engineer Jorge Reynolds Pombo, invention of great importance for those who suffer from heart failure. Also invented in Colombia were the microkeratome and keratomileusis technique, which form the fundamental basis of what now is known as LASIK (one of the most important techniques for the correction of refractive errors of vision) and the Hakim valve for the treatment of Hydrocephalus, among others. Colombia has begun to innovate in military technology for its army and other armies of the world; especially in the design and creation of personal ballistic protection products, military hardware, military robots, bombs, simulators and radar.

Some leading Colombian scientists are Joseph M. Tohme, researcher recognized for his work on the genetic diversity of food, Manuel Elkin Patarroyo who is known for his groundbreaking work on synthetic vaccines for malaria, Francisco Lopera who discovered the "Paisa Mutation" or a type of early-onset Alzheimer's, Rodolfo Llinás known for his study of the intrinsic neurons properties and the theory of a syndrome that had changed the way of understanding the functioning of the brain, Jairo Quiroga Puello recognized for his studies on the characterization of synthetic substances which can be used to fight fungus, tumors, tuberculosis and even some viruses and Ángela Restrepo who established accurate diagnoses and treatments to combat the effects of a disease caused by the "Paracoccidioides brasiliensis", among other scientists.

Transportation in Colombia is regulated within the functions of the Ministry of Transport and entities such as the National Roads Institute (INVÍAS) responsible for the Highways in Colombia, the Aerocivil, responsible for civil aviation and airports, the National Infrastructure Agency, in charge of concessions through public–private partnerships, for the design, construction, maintenance, operation, and administration of the transport infrastructure, the General Maritime Directorate (Dimar) has the responsibility of coordinating maritime traffic control along with the Colombian Navy, among others and under the supervision of the Superintendency of Ports and Transport. The road network in Colombia has a length of about 215,000 km of which 23,000 are paved. Rail transportation in Colombia is dedicated almost entirely to freight shipments and the railway network has a length of 1,700 km of potentially active rails. Colombia has 3,960 kilometers of gas pipelines, 4,900 kilometers of oil pipelines, and 2,990 kilometers of refined-products pipelines.

The target of Colombia's government is to build 7,000 km of roads for the 2016–2020 period and reduce travel times by 30 per cent and transport costs by 20 per cent. A toll road concession programme will comprise 40 projects, and is part of a larger strategic goal to invest nearly $50bn in transport infrastructure, including: railway systems; making the Magdalena river navigable again; improving port facilities; as well as an expansion of Bogotá's airport.

With an estimated 49 million people in 2017, Colombia is the third-most populous country in Latin America, after Brazil and Mexico. At the beginning of the 20th century, Colombia's population was approximately 4 million. Since the early 1970s Colombia has experienced steady declines in its fertility, mortality, and population growth rates. The population growth rate for 2016 is estimated to be 0.9%. The total fertility rate was 1.9 births per woman in 2015. About 26.8% of the population were 15 years old or younger, 65.7% were between 15 and 64 years old, and 7.4% were over 65 years old. The proportion of older persons in the total population has begun to increase substantially. Colombia is projected to have a population of 50.2 million by 2020 and 55.3 million by 2050.

The population is concentrated in the Andean highlands and along the Caribbean coast, also the population densities are generally higher in the Andean region. The nine eastern lowland departments, comprising about 54% of Colombia's area, have less than 6% of the population. Traditionally a rural society, movement to urban areas was very heavy in the mid-20th century, and Colombia is now one of the most urbanized countries in Latin America. The urban population increased from 31% of the total in 1938 to nearly 60% in 1973, and by 2014 the figure stood at 76%. The population of Bogotá alone has increased from just over 300,000 in 1938 to approximately 8 million today. In total seventy-two cities now have populations of 100,000 or more (2015). Colombia has the world's largest populations of internally displaced persons (IDPs), estimated to be up to 4.9 million people.

The life expectancy is 74.8 years in 2015 and infant mortality is 13.1 per thousand in 2016. In 2015, 94.58% of adults and 98.66% of youth are literate and the government spends about 4.49% of its GDP in education.

Colombia is ranked third in the world in the Happy Planet Index.

More than 99.2% of Colombians speak Spanish, also called Castilian; 65 Amerindian languages, two Creole languages, the Romani language and Colombian Sign Language are also spoken in the country. English has official status in the archipelago of San Andrés, Providencia and Santa Catalina.

Including Spanish, a total of 101 languages are listed for Colombia in the Ethnologue database. The specific number of spoken languages varies slightly since some authors consider as different languages what others consider to be varieties or dialects of the same language. Best estimates recorded 71 languages that are spoken in-country today—most of which belong to the Chibchan, Tucanoan, Bora–Witoto, Guajiboan, Arawakan, Cariban, Barbacoan, and Saliban language families. There are currently about 850,000 speakers of native languages.

Colombia is ethnically diverse, its people descending from the original native inhabitants, Spanish colonists, Africans originally brought to the country as slaves, and 20th-century immigrants from Europe and the Middle East, all contributing to a diverse cultural heritage. The demographic distribution reflects a pattern that is influenced by colonial history. Whites tend to live mainly in urban centers, like Bogotá, Medellín or Cali, and the burgeoning highland cities. The populations of the major cities also include mestizos. Mestizo "campesinos" (people living in rural areas) also live in the Andean highlands where some Spanish conquerors mixed with the women of Amerindian chiefdoms. Mestizos include artisans and small tradesmen that have played a major part in the urban expansion of recent decades.

The 2005 census reported that the "non-ethnic population", consisting of whites and mestizos (those of mixed white European and Amerindian ancestry), constituted 86% of the national population. 10.6% is of African ancestry. Indigenous Amerindians comprise 3.4% of the population. 0.01% of the population are Roma. An extraofficial estimate considers that the 49% of the Colombian population is Mestizo or of mixed European and Amerindian ancestry, and that approximately 37% is White, mainly of Spanish lineage, but there is also a large population of Middle East descent; in some sectors of society there is a considerable input of Italian and German ancestry.

Many of the Indigenous peoples experienced a reduction in population during the Spanish rule and many others were absorbed into the mestizo population, but the remainder currently represents over eighty distinct cultures. Reserves ("resguardos") established for indigenous peoples occupy (27% of the country's total) and are inhabited by more than 800,000 people. Some of the largest indigenous groups are the Wayuu, the Paez, the Pastos, the Emberá and the Zenú. The departments of La Guajira, Cauca, Nariño, Córdoba and Sucre have the largest indigenous populations.

The Organización Nacional Indígena de Colombia (ONIC), founded at the first National Indigenous Congress in 1982, is an organization representing the indigenous peoples of Colombia. In 1991, Colombia signed and ratified the current international law concerning indigenous peoples, Indigenous and Tribal Peoples Convention, 1989.

Black Africans were brought as slaves, mostly to the coastal lowlands, beginning early in the 16th century and continuing into the 19th century. Large Afro-Colombian communities are found today on the Caribbean and Pacific coasts. The population of the department of Chocó, running along the northern portion of Colombia's Pacific coast, is over 80% black. British and Jamaicans migrated mainly to the islands of San Andres and Providencia. A number of other Europeans and North Americans migrated to the country in the late 19th and early 20th centuries, including people from the former USSR during and after the Second World War.

Many immigrant communities have settled on the Caribbean coast, in particular recent immigrants from the Middle East. Barranquilla (the largest city of the Colombian Caribbean) and other Caribbean cities have the largest populations of Lebanese, Palestinian, and other Arabs. There are also important communities of Chinese, Japanese, Romanis and Jews. There is a major migration trend of Venezuelans, due to the political and economic situation in Venezuela.

The National Administrative Department of Statistics (DANE) does not collect religious statistics, and accurate reports are difficult to obtain. However, based on various studies and a survey, about 90% of the population adheres to Christianity, the majority of which (70.9%) are Roman Catholic, while a significant minority (16.7%) adhere to Protestantism (primarily Evangelicalism). Some 4.7% of the population is atheist or agnostic, while 3.5% claim to believe in God but do not follow a specific religion. 1.8% of Colombians adhere to Jehovah's Witnesses and Adventism and less than 1% adhere to other religions, such as Islam, Judaism, Buddhism, Mormonism, Hinduism, Indigenous religions, Hare Krishna movement, Rastafari movement, Orthodox Catholic Church, and spiritual studies. The remaining people either did not respond or replied that they did not know. In addition to the above statistics, 35.9% of Colombians reported that they did not practice their faith actively.

While Colombia remains a mostly Roman Catholic country by baptism numbers, the 1991 Colombian constitution guarantees freedom of religion and all religious faiths and churches are equally free before the law.

Colombia is a highly urbanized country. The largest cities in the country are Bogotá, with an estimated 8 million inhabitants, Medellín, with an estimated 2.5 million inhabitants, Cali, with an estimated 2.4 million inhabitants, and Barranquilla, with an estimated 1.2 million inhabitants. Cartagena highlights in number of inhabitants and the city of Bucaramanga is relevant in terms of metropolitan area population.
Colombia lies at the crossroads of Latin America and the broader American continent, and as such has been hit by a wide range of cultural influences. Native American, Spanish and other European, African, American, Caribbean, and Middle Eastern influences, as well as other Latin American cultural influences, are all present in Colombia's modern culture. Urban migration, industrialization, globalization, and other political, social and economic changes have also left an impression.

Many national symbols, both objects and themes, have arisen from Colombia's diverse cultural traditions and aim to represent what Colombia, and the Colombian people, have in common. Cultural expressions in Colombia are promoted by the government through the Ministry of Culture.

Colombian literature dates back to pre-Columbian era; a notable example of the period is the epic poem known as the "Legend of Yurupary". In Spanish colonial times, notable writers include Juan de Castellanos ("Elegías de varones ilustres de Indias"), Hernando Domínguez Camargo and his epic poem to San Ignacio de Loyola, Pedro Simón, Juan Rodríguez Freyle ("El Carnero"), Lucas Fernández de Piedrahita, and the nun Francisca Josefa de Castillo, representative of mysticism.

Post-independence literature linked to Romanticism highlighted Antonio Nariño, José Fernández Madrid, Camilo Torres Tenorio and Francisco Antonio Zea. In the second half of the nineteenth century and early twentieth century the literary genre known as "costumbrismo" became popular; great writers of this period were Tomás Carrasquilla, Jorge Isaacs and Rafael Pombo (the latter of whom wrote notable works of children's literature). Within that period, authors such as José Asunción Silva, José Eustasio Rivera, León de Greiff, Porfirio Barba-Jacob and José María Vargas Vila developed the modernist movement. In 1872, Colombia established the Colombian Academy of Language, the first Spanish language academy in the Americas. Candelario Obeso wrote the groundbreaking "Cantos Populares de mi Tierra" (1877), the first book of poetry by an Afro-Colombian author.

Between 1939 and 1940 seven books of poetry were published under the name "Stone and Sky" in the city of Bogotá that significantly impacted the country; they were edited by the poet Jorge Rojas. In the following decade, Gonzalo Arango founded the movement of "nothingness" in response to the violence of the time; he was influenced by nihilism, existentialism, and the thought of another great Colombian writer: Fernando González Ochoa. During the boom in Latin American literature, successful writers emerged, led by Nobel laureate Gabriel García Márquez and his magnum opus, "One Hundred Years of Solitude", Eduardo Caballero Calderón, Manuel Mejía Vallejo, and Álvaro Mutis, a writer who was awarded the Cervantes Prize and the Prince of Asturias Award for Letters. Other leading contemporary authors are Fernando Vallejo, William Ospina (Rómulo Gallegos Prize) and Germán Castro Caycedo.

Colombian art has over 3,000 years of history. Colombian artists have captured the country's changing political and cultural backdrop using a range of styles and mediums. There is archeological evidence of ceramics being produced earlier in Colombia than anywhere else in the Americas, dating as early as 3,000 BCE.

The earliest examples of gold craftsmanship have been attributed to the Tumaco people of the Pacific coast and date to around 325 BCE. Roughly between 200 BCE and 800 CE, the San Agustín culture, masters of stonecutting, entered its "classical period". They erected raised ceremonial centres, sarcophagi, and large stone monoliths depicting anthropomorphic and zoomorphhic forms out of stone.

Colombian art has followed the trends of the time, so during the 16th to 18th centuries, Spanish Catholicism had a huge influence on Colombian art, and the popular baroque style was replaced with rococo when the Bourbons ascended to the Spanish crown. More recently, Colombian artists Pedro Nel Gómez and Santiago Martínez Delgado started the Colombian Murial Movement in the 1940s, featuring the neoclassical features of Art Deco.

Since the 1950s, the Colombian art started to have a distinctive point of view, reinventing traditional elements under the concepts of the 20th century. Examples of this are the Greiff portraits by Ignacio Gómez Jaramillo, showing what the Colombian art could do with the new techniques applied to typical Colombian themes. Carlos Correa, with his paradigmatic "Naturaleza muerta en silencio" (silent dead nature), combines geometrical abstraction and cubism. Alejandro Obregón is often considered as the father of modern Colombian painting, and one of the most influential artist in this period, due to his originality, the painting of Colombian landscapes with symbolic and expressionist use of animals, (specially the Andean condor). Fernando Botero, Omar Rayo, Enrique Grau, Édgar Negret, David Manzur, Rodrigo Arenas Betancourt and Oscar Murillo are some of the Colombian artists featured at the international level.

The Colombian sculpture from the sixteenth to 18th centuries was mostly devoted to religious depictions of ecclesiastic art, strongly influenced by the Spanish schools of sacred sculpture. During the early period of the Colombian republic, the national artists were focused in the production of sculptural portraits of politicians and public figures, in a plain neoclassicist trend. During the 20th century, the Colombian sculpture began to develop a bold and innovative work with the aim of reaching a better understanding of national sensitivity.

Colombian photography was marked by the arrival of the daguerreotype. Jean-Baptiste Louis Gros was who brought the daguerreotype process to Colombia in 1841. The Piloto public library has Latin America's largest archive of negatives, containing 1.7 million antique photographs covering Colombia 1848 until 2005.

The Colombian press has promoted the work of the cartoonists. In recent decades, fanzines, internet and independent publishers have been fundamental to the growth of the comic in Colombia.

Throughout the times, there have been a variety of architectural styles, from those of indigenous peoples to contemporary ones, passing through colonial (military and religious), Republican, transition and modern styles.

Ancient habitation areas, longhouses, crop terraces, roads as the Inca road system, cemeteries, hypogeums and necropolises are all part of the architectural heritage of indigenous peoples. Some prominent indigenous structures are the preceramic and ceramic archaeological site of Tequendama, Tierradentro (a park that contains the largest concentration of pre-Columbian monumental shaft tombs with side chambers), the largest collection of religious monuments and megalithic sculptures in South America, located in San Agustín, Huila, Lost city (an archaeological site with a series of terraces carved into the mountainside, a net of tiled roads and several circular plazas) and also stand out the large villages mainly built with stone, wood, cane and mud.

Architecture during the period of conquest and colonization is mainly derived of adapting European styles to local conditions, and Spanish influence, especially Andalusian and Extremaduran, can be easily seen. When Europeans founded cities two things were making simultaneously: the dimensioning of geometrical space (town square, street), and the location of a tangible point of orientation. The construction of forts was common throughout the Caribbean and in some cities of the interior, because of the dangers that represented the English, French, and Dutch pirates and the hostile indigenous groups. Churches, chapels, schools, and hospitals belonging to religious orders cause a great urban impact. Baroque architecture is used in military buildings and public spaces. Marcelino Arroyo, Francisco José de Caldas and Domingo de Petrés were great representatives of neo-classical architecture.

The National Capitol is a great representative of romanticism. Wood is extensively used in doors, windows, railings and ceilings during the colonization of Antioquia. The Caribbean architecture acquires a strong Arabic influence. The Teatro Colón in Bogotá is a lavish example of architecture from the 19th century. The quintas houses with innovations in the volumetric conception are some of the best examples of the Republican architecture; the Republican action in the city focused on the design of three types of spaces: parks with forests, small urban parks and avenues and the Gothic style was most commonly used for the design of churches.

Deco style, modern neoclassicism, eclecticism folklorist and art deco ornamental resources significantly influenced the architecture of Colombia, especially during the transition period. Modernism contributed with new construction technologies and new materials (steel, reinforced concrete, glass and synthetic materials) and the topology architecture and lightened slabs system also have a great influence. The most influential architects of the modern movement were Rogelio Salmona and Fernando Martínez Sanabria.

The contemporary architecture of Colombia is designed to give greater importance to the materials, this architecture takes into account the specific natural and artificial geographies and is also an architecture that appeals to the senses. The conservation of the architectural and urban heritage of Colombia has been promoted in recent years.

Colombia has a vibrant collage of talent that touches a full spectrum of rhythms. Musicians, composers, music producers and singers from Colombia are recognized internationally such as Shakira, Juanes, Carlos Vives and others. Colombian music blends European-influenced guitar and song structure with large gaita flutes and percussion instruments from the indigenous population, while its percussion structure and dance forms come from Africa. Colombia has a diverse and dynamic musical environment.

Guillermo Uribe Holguín, an important cultural figure in the National Symphony Orchestra of Colombia, Luis Antonio Calvo and Blas Emilio Atehortúa are some of the greatest exponents of the art music. The Bogotá Philharmonic Orchestra is one of the most active orchestras in Colombia.

Caribbean music has many vibrant rhythms, such as cumbia (it is played by the maracas, the drums, the gaitas and guacharaca), porro (it is a monotonous but joyful rhythm), mapalé (with its fast rhythm and constant clapping) and the "vallenato", which originated in the northern part of the Caribbean coast (the rhythm is mainly played by the caja, the guacharaca, and accordion).

The music from the Pacific coast, such as the currulao is characterized by its strong use of drums (instruments such as the native marimba, the conunos, the bass drum, the side drum and the cuatro guasas or tubular rattle). An important rhythm of the south region of the Pacific coast is the contradanza (it is used in dance shows, as a result of the striking colours of the costumes). Marimba music, traditional chants and dances from the Colombia South Pacific region are on UNESCO's Representative List of the Intangible Cultural Heritage of Humanity.

Important musical rhythms of the Andean Region are the danza (dance of Andean folklore arising from the transformation of the European contredance), the bambuco (it is played with guitar, tiple and mandolin, the rhythm is danced by couples), the pasillo (a rhythm inspired by the Austrian waltz and the Colombian "danza", the lyrics have been composed by well-known poets), the guabina (the tiple, the bandola and the requinto are the basic instruments), the sanjuanero (it originated in Tolima and Huila Departments, the rhythm is joyful and fast). Apart from these traditional rhythms, salsa music has spread throughout the country, and the city of Cali is considered by many salsa singers to be 'The New Salsa Capital of the World'.

The instruments that distinguish the music of the Eastern Plains are the harp, the cuatro (a type of four-stringed guitar) and maracas. Important rhythms of this region are the joropo (a fast rhythm and there is also tapping as a result of its flamenco ancestry) and the galeron (it is heard a lot while cowboys are working).

The music of the Amazon region is strongly influenced by the indigenous religious practices. Some of the musical instruments used are the manguaré (a musical instrument of ceremonial type, consisting of a pair of large cylindrical drums), the quena (melodic instrument), the rondador, the congas, bells, and different types of flutes.

The music of the Archipelago of San Andrés, Providencia and Santa Catalina is usually accompanied by a mandolin, a tub-bass, a jawbone, a guitar and maracas. Some popular archipelago rhythms are the Schottische, the Calypso, the Polka and the Mento.

Theater was introduced in Colombia during the Spanish colonization in 1550 through zarzuela companies. Colombian theater is supported by the Ministry of Culture and a number of private and state owned organizations. The Ibero-American Theater Festival of Bogotá is the cultural event of the highest importance in Colombia and one of the biggest theater festivals in the world. Other important theater events are: The Festival of Puppet The Fanfare (Medellín), The Manizales Theater Festival, The Caribbean Theatre Festival (Santa Marta) and The Art Festival of Popular Culture "Cultural Invasion" (Bogotá).

Although the Colombian cinema is young as an industry, more recently the film industry was growing with support from the Film Act passed in 2003. Many film festivals take place in Colombia, but the two most important are the Cartagena Film Festival, which is the oldest film festival in Latin America, and the Bogotá Film Festival.

Some important national circulation newspapers are "El Tiempo" and "El Espectador". Television in Colombia has two privately owned TV networks and three state-owned TV networks with national coverage, as well as six regional TV networks and dozens of local TV stations. Private channels, RCN and Caracol are the highest-rated. The regional channels and regional newspapers cover a department or more and its content is made in these particular areas.

Colombia has three major national radio networks: Radiodifusora Nacional de Colombia, a state-run national radio; Caracol Radio and RCN Radio, privately owned networks with hundreds of affiliates. There are other national networks, including Cadena Super, Todelar, and Colmundo. Many hundreds of radio stations are registered with the Ministry of Information Technologies and Communications.

Colombia's varied cuisine is influenced by its diverse fauna and flora as well as the cultural traditions of the ethnic groups. Colombian dishes and ingredients vary widely by region. Some of the most common ingredients are: cereals such as rice and maize; tubers such as potato and cassava; assorted legumes; meats, including beef, chicken, pork and goat; fish; and seafood. Colombia cuisine also features a variety of tropical fruits such as cape gooseberry, feijoa, arazá, dragon fruit, mangostino, granadilla, papaya, guava, mora (blackberry), lulo, soursop and passionfruit. Colombia is one of the world's largest consumers of fruit juices.

Among the most representative appetizers and soups are patacones (fried green plantains), sancocho de gallina (chicken soup with root vegetables) and ajiaco (potato and corn soup). Representative snacks and breads are pandebono, arepas (corn cakes), aborrajados (fried sweet plantains with cheese), torta de choclo, empanadas and almojábanas. Representative main courses are bandeja paisa, lechona tolimense, mamona, tamales and fish dishes (such as arroz de lisa), especially in coastal regions where kibbeh, suero, costeño cheese and carimañolas are also eaten. Representative side dishes are papas chorreadas (potatoes with cheese), remolachas rellenas con huevo duro (beets stuffed with hard-boiled egg) and arroz con coco (coconut rice). Organic food is a current trend in big cities, although in general across the country the fruits and veggies are very natural and fresh.

Representative desserts are buñuelos, natillas, Maria Luisa cake, bocadillo made of guayaba (guava jelly), cocadas (coconut balls), casquitos de guayaba (candied guava peels), torta de natas, obleas, flan de mango, roscón, milhoja, manjar blanco, dulce de feijoa, dulce de papayuela, torta de mojicón, and esponjado de curuba. Typical sauces (salsas) are hogao (tomato and onion sauce) and Colombian-style ají.

Some representative beverages are coffee (Tinto), champús, cholado, lulada, avena colombiana, sugarcane juice, aguapanela, aguardiente, hot chocolate and fresh fruit juices (often made with water or milk).

Tejo is Colombia's national sport and is a team sport that involves launching projectiles to hit a target. But of all sports in Colombia, football is the most popular. Colombia was the champion of the 2001 Copa América, in which they set a new record of being undefeated, conceding no goals and winning each match. Interestingly, Colombia has been awarded "mover of the year" twice.

Colombia is a hub for roller skaters. The national team is a perennial powerhouse at the World Roller Speed Skating Championships. Colombia has traditionally been very good in cycling and a large number of Colombian cyclists have triumphed in major competitions of cycling.

Baseball is popular in the Caribbean, mainly in the cities Cartagena, Barranquilla and Santa Marta. Of those cities have come good players like: Orlando Cabrera, Édgar Rentería who was champion of the World Series in 1997 and 2010, and others who have played in Major League Baseball. Colombia was world amateur champion in 1947 and 1965.

Boxing is one of the sports that more world champions has produced for Colombia.
Motorsports also occupies an important place in the sporting preferences of Colombians; Juan Pablo Montoya is a race car driver known for winning 7 Formula One events. Colombia also has excelled in sports such as BMX, judo, shooting sport, taekwondo, wrestling, high diving and athletics, also has a long tradition in weightlifting and bowling.

The overall life expectancy in Colombia at birth is 74.8 years (71.2 years for males and 78.4 years for females). Health standards in Colombia have improved very much since the 1980s, healthcare reforms have led to the massive improvements in the healthcare systems of the country. Although this new system has widened population coverage by the social and health security system from 21% (pre-1993) to 96% in 2012, health disparities persist.

Through health tourism, many people from over the world travel from their places of residence to other countries in search of medical treatment and the attractions in the countries visited. Colombia is projected as one of Latin America's main destinations in terms of health tourism due to the quality of its health care professionals, a good number of institutions devoted to health, and an immense inventory of natural and architectural sites. Cities such as Bogotá, Cali, Medellín and Bucaramanga are the most visited in cardiology procedures, neurology, dental treatments, stem cell therapy, ENT, ophthalmology and joint replacements because of the quality of medical treatment.

A study conducted by "América Economía" magazine ranked 21 Colombian health care institutions among the top 44 in Latin America, amounting to 48 percent of the total. A cancer research and treatment centre was declared as a Project of National Strategic Interest.

The educational experience of many Colombian children begins with attendance at a preschool academy until age five ("Educación preescolar"). Basic education ("Educación básica") is compulsory by law. It has two stages: Primary basic education ("Educación básica primaria") which goes from first to fifth grade – children from six to ten years old, and Secondary basic education ("Educación básica secundaria"), which goes from sixth to ninth grade. Basic education is followed by Middle vocational education ("Educación media vocacional") that comprises the tenth and eleventh grades. It may have different vocational training modalities or specialties (academic, technical, business, and so on.) according to the curriculum adopted by each school.

After the successful completion of all the basic and middle education years, a high-school diploma is awarded. The high-school graduate is known as a "bachiller", because secondary basic school and middle education are traditionally considered together as a unit called "bachillerato" (sixth to eleventh grade). Students in their final year of middle education take the ICFES test (now renamed Saber 11) in order to gain access to higher education ("Educación superior"). This higher education includes undergraduate professional studies, technical, technological and intermediate professional education, and post-graduate studies. Technical professional institutions of Higher Education are also opened to students holder of a qualification in Arts and Business. This qualification is usually awarded by the SENA after a two years curriculum.

"Bachilleres" (high-school graduates) may enter into a professional undergraduate career program offered by a university; these programs last up to five years (or less for technical, technological and intermediate professional education, and post-graduate studies), even as much to six to seven years for some careers, such as medicine. In Colombia, there is not an institution such as college; students go directly into a career program at a university or any other educational institution to obtain a professional, technical or technological title. Once graduated from the university, people are granted a (professional, technical or technological) diploma and licensed (if required) to practice the career they have chosen. For some professional career programs, students are required to take the Saber-Pro test, in their final year of undergraduate academic education.

Public spending on education as a proportion of gross domestic product in 2015 was 4.49%. This represented 15.05% of total government expenditure. The primary and secondary gross enrolment ratios stood at 113.56% and 98.09% respectively. School-life expectancy was 14.42 years. A total of 94.58% of the population aged 15 and older were recorded as literate, including 98.66% of those aged 15–24.


General information

Government

Culture

Geography


</doc>
