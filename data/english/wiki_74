<doc id="9736" url="https://en.wikipedia.org/wiki?curid=9736" title="Empire State Building">
Empire State Building

The Empire State Building is a 102-story Art Deco skyscraper in Midtown Manhattan, New York City. Designed by Shreve, Lamb & Harmon and completed in 1931, the building has a roof height of and stands a total of tall, including its antenna. Its name is derived from "Empire State", the nickname of New York. the building is the 5th-tallest completed skyscraper in the United States and the 28th-tallest in the world. It is also the 6th-tallest freestanding structure in the Americas.

The site of the Empire State Building, located on the west side of Fifth Avenue between West 33rd and 34th Streets, was originally part of an early 18th century farm. In the late 1820s, it came into the possession of the prominent Astor family, with John Jacob Astor's descendants building the Waldorf–Astoria Hotel on the site in the 1890s. By the 1920s, the family had sold the outdated hotel and the site indirectly ended up under the ownership of Empire State Inc., a business venture that included businessman John J. Raskob and former New York governor Al Smith. The original design of the Empire State Building was a for a 50-story office building. However, after fifteen revisions, the final design was for a 86-story 1,250-foot building, with an airship mast on top. This ensured it would be the world's tallest building, beating the Chrysler Building and 40 Wall Street, two other Manhattan skyscrapers under construction at the time that were also vying for that distinction.

Demolition of the Waldorf–Astoria began in October 1929, and the foundation of the Empire State Building was excavated before demolition was even complete. Construction on the building itself started on March 17, 1930, with an average construction rate of one floor per day. A well-coordinated schedule meant that the 86 stories were topped out on September 19, six months after construction started, and the mast was completed by November 21. From that point, interior work proceeded at a quick pace, and it was opened on May 1, 1931, thirteen and a half months after the first steel beam was erected. Despite the publicity surrounding the building's construction, its owners failed to make a profit until the early 1950s. However, it has been a popular tourist attraction since opening, with around 4 million visitors to the building's 86th and 102nd floor observatories every year.

The Empire State Building stood as the world's tallest building for nearly 40 years until the completion of the World Trade Center's North Tower in Lower Manhattan in late 1970. Following the September 11 attacks in 2001, it was again the tallest building in New York until the new One World Trade Center was completed in April 2012.

The Empire State Building is an American cultural icon and has been featured in more than 250 TV shows and movies since the film "King Kong" was released in 1933. A symbol of New York City, the tower has been named as one of the Seven Wonders of the Modern World by the American Society of Civil Engineers. The Empire State Building and its ground-floor interior have been designated as a city landmark by the New York City Landmarks Preservation Commission, and were confirmed as such by the New York City Board of Estimate. It was also designated a National Historic Landmark in 1986, and was ranked number one on the American Institute of Architects' List of America's Favorite Architecture in 2007.

The Empire State Building is located on the west side of 350 Fifth Avenue in Manhattan, between 33rd and 34th Streets. Although physically located in South Midtown, a mixed residential and commercial area, the building is so large that it was assigned its own ZIP code, 10118; it is one of 43 buildings in New York City that has its own zip code. The area to the south and west features other major Manhattan landmarks as well, including Macy's at Herald Square on Sixth Avenue and 34th Street, Koreatown on 32nd Street between Fifth and Sixth Avenues, Penn Station and Madison Square Garden on Seventh Avenue between 32nd and 34th Streets, and the Flower District on 28th Street between Sixth and Seventh Avenues. The nearest New York City Subway stations are 34th Street–Herald Square at Sixth Avenue and Broadway, one block west, and 33rd Street at Park Avenue, two blocks east. There is also a PATH station at 33rd Street and Sixth Avenue.

To the east of the Empire State Building is Murray Hill, a neighborhood with a mix of residential, commercial, and entertainment. One block east of the Empire State Building, on Madison Avenue at 34th Street, is the New York Public Library's Science, Industry and Business Library, which is located on the same block as the City University of New York's Graduate Center.

The tract was originally part of Mary and John Murray's farm on Murray Hill. The earliest recorded major action on the site was during the American Revolutionary War, when General George Washington's troops were retreating from the British following the Battle of Kip's Bay. In 1799, John Thompson (or Thomson; accounts vary) bought a tract of land roughly bounded by Madison Avenue, 36th Street, Sixth Avenue, and 33rd Street, immediately north of the Caspar Samler farm, for 482 British pounds (roughly US$2400 at the time). Thompson was said to have sold the farm to Charles Lawton for $10,000 on September 24, 1825, although details of this sale are unclear, as details of the deed that certified the sale were later lost. In 1826, John Jacob Astor of the prominent Astor family bought the land from Lawton for $20,500. The Astors also purchased a parcel from the Murrays. John Jacob's son William Backhouse Astor Sr. bought a half interest on July 28, 1827, for $20,500, for a tract of land on Fifth Avenue from 32nd to 35th streets.

On March 13, 1893, John Jacob Astor Sr's grandson William Waldorf Astor opened the Waldorf Hotel on the site with the help of hotelier George Boldt. On November 1, 1897, Waldorf's cousin, John Jacob Astor IV, opened the 16-story Astoria Hotel on an adjacent site. The combined hotel had 1,300 bedrooms making it the largest hotel in the world at the time. After Boldt died, in early 1918, the hotel lease was purchased by Coleman du Pont. By the 1920s, the hotel was becoming dated and the elegant social life of New York had moved much farther north than 34th Street. The Astor family decided to build a replacement hotel further uptown, and sold the hotel to Bethlehem Engineering Corporation in 1928 for $14–16 million. They closed the hotel on May 3, 1929.

Bethlehem Engineering Corporation originally intended to build a 25-story office building on the Waldorf–Astoria site. The company's president, Floyd De L. Brown, paid $100,000 of the $1 million down payment required to start construction on the tower, with the promise that the difference would be paid later. Brown borrowed $900,000 from a bank, but then defaulted on the loan.

The land was then resold to Empire State Inc., a group of wealthy investors that included Louis G. Kaufman, Ellis P. Earle, John J. Raskob, Coleman du Pont, and Pierre S. du Pont. The name came from the state nickname for New York. Alfred E. Smith, a former Governor of New York and U.S. presidential candidate whose 1928 campaign had been managed by Raskob, was appointed head of the company. The group also purchased nearby land so they would have the needed for the tower's base, with the combined plot measuring wide by long. The Empire State Inc. consortium was announced to the public in August 1929.

Empire State Inc. contracted William F. Lamb, of architectural firm Shreve, Lamb and Harmon, to create the building design. Lamb produced the building drawings in just two weeks using the firm's earlier designs for the Reynolds Building in Winston-Salem, North Carolina as the basis. Concurrently, Lamb's partner Richmond Shreve created "bug diagrams" of the project requirements. The 1916 Zoning Act forced Lamb to design a structure that incorporated setbacks resulting in the lower floors being larger than the upper floors. Consequently, the tower was designed from the top down, giving it a "pencil"-like shape.

The original plan of the building was 50 stories, but was later increased to 60 and then 80 stories. Height restrictions were placed on nearby buildings to ensure that the top fifty floors of the planned 80-story, building would have unobstructed views of the city. "The New York Times" lauded the site's proximity to transportation, with the Brooklyn–Manhattan Transit's 34th Street station and the Hudson and Manhattan Railroad's 33rd Street terminal one block away, as well as Penn Station two blocks away and the Grand Central Terminal nine blocks away at its closest. It also praised the of proposed floor space near "one of the busiest sections in the world".

While plans for the Empire State Building were being finalized, an intense competition in New York for the title of "world's tallest building" was underway. 40 Wall Street (then the Bank of Manhattan Building) and the Chrysler Building in Manhattan both vied for this distinction and were already under construction when work began on the Empire State Building. The "Race into the Sky", as popular media called it at the time, was representative of the country's optimism in the 1920s, fueled by the building boom in major cities. The 40 Wall Street tower was revised, in April 1929, from to making it the world's tallest. The Chrysler Building added its steel tip to its roof in October 1929, thus bringing it to a height of and greatly exceeding the height of 40 Wall Street. The Chrysler Building's developer, Walter Chrysler, realized that his tower's height would exceed the Empire State Building's as well, having instructed his architect, William Van Alen, to change the Chrysler's original roof from a stubby Romanesque dome to a narrow steel spire. Raskob, wishing to have the Empire State Building be the world's tallest, reviewed the plans and had five floors added as well as a spire; however, the new floors would need to be set back because of projected wind pressure on the extension. On November 18, 1929, Smith acquired a lot at 27–31 West 33rd Street, adding to the width of the proposed office building's site. Two days later, Smith announced the updated plans for the skyscraper that included an observation deck on the 86th-floor roof at a height of , higher than the Chrysler's 71st-floor observation deck.

The 1,050-foot Empire State Building would only be taller than the Chrysler Building, and Raskob was afraid that Chrysler might try to "pull a trick like hiding a rod in the spire and then sticking it up at the last minute." The plans were revised one last time in December 1929, with a 16-story, metal "crown" and an additional dirigible mooring mast. The roof height was now , making it the tallest building in the world by far, even without the antenna. The addition of the dirigible station meant that another floor, the now-enclosed 86th floor, would have to be built below the crown; however, unlike the Chrysler's spire, the Empire State's mast would serve a practical purpose. The final plan was announced to the public on January 8, 1930, just before the start of construction. "The New York Times" reported that the spire was facing some "technical problems", but they were "no greater than might be expected under such a novel plan." By this time the blueprints for the building had gone through up to fifteen versions before they were approved. Lamb described the other specifications he was given for the final, approved plan:

The contractors were Starrett Brothers and Eken, Paul and William A. Starrett and Andrew J. Eken, who had also constructed other New York City buildings such as the original Stuyvesant Town, Starrett City and Trump Tower. The project was financed primarily by Raskob and Pierre du Pont, while James Farley's General Builders Supply Corporation supplied the building materials. John W. Bowser was the construction superintendent of the proejct, and the structural engineer of the building was Homer G. Balcom. The tight completion schedule necessitated the commencement of construction even though the design had yet to be finalized.

Demolition of the old Waldorf–Astoria began on October 1, 1929. Stripping the building down was an arduous process, as the hotel had been constructed using more rigid material than earlier buildings had been. Furthermore, the old hotel's granite, wood chips, and "'precious' metals such as lead, brass, and zinc" were not in high demand resulting in issues with disposal. Most of the wood was deposited into a woodpile on nearby 30th Street or was burned in a swamp elsewhere. Much of the other materials that made up the old hotel, including the granite and bronze, were dumped into the Atlantic Ocean near Sandy Hook, New Jersey.

By the time the hotel's demolition started, Raskob had secured the required funding for the construction of the building. The plan was to start construction later that year but, on October 24, the New York Stock Exchange suffered a sudden crash marking the beginning of the decade-long Great Depression. Despite the economic downturn, Raskob refused to cancel the project because of the progress that had been made up to that point. Neither Raskob, who had ceased speculation in the stock market the previous year, nor Smith, who had no stock investments, suffered financially in the crash. However, most of the investors were affected and as a result, in December 1929, Empire State Inc. obtained a $27.5 million loan from Metropolitan Life Insurance Company so construction could begin. The stock market crash resulted in no demand in new office space, Raskob and Smith nonetheless started construction, as canceling the project would have resulted in greater losses for the investors.

A structural steel contract was awarded on January 12, 1930, with excavation of the site beginning ten days later on January 22, before the old hotel had been completely demolished. Two twelve-hour shifts, consisting of 300 men each, worked continuously to dig the foundation. Small pier holes were sunk into the ground to house the concrete footings that would support the steelwork. Excavation was nearly complete by early March, and construction on the building itself started on March 17, with the builders placing the first steel columns on the completed footings before the rest of the footings had been finished. Around this time, Lamb held a press conference on the building plans. He described the reflective steel panels parallel to the windows, the large-block Indiana Limestone facade that was slightly more expensive than smaller bricks, and the tower's lines and rise. Four colossal columns, intended for installation in the center of the building site, were delivered; they would support a combined when the building was finished.

The structural steel was pre-ordered and pre-fabricated in anticipation of a revision to the city's building code that would have allowed the Empire State Building's structural steel to carry , up from , thus reducing the amount of steel needed for the building. Although the 18,000-psi regulation had been safely enacted in other cities, Mayor Jimmy Walker did not sign the new codes into law until March 26, 1930, just before construction was due to commence. The first steel framework was installed on April 1, 1930. From there, construction proceeded at a rapid pace; during one stretch of 10 working days, the builders erected fourteen floors. This was made possible through precise coordination of the building's planning, as well as the mass production of common materials such as windows and spandrels. On one occasion, when a supplier could not provide timely delivery of dark Hauteville marble, Starrett switched to using Rose Famosa marble from a German quarry that was purchased specifically to provide the project with sufficient marble.

The scale of the project was massive, with trucks carrying "16,000 partition tiles, 5,000 bags of cement, of sand and 300 bags of lime" arriving at the construction site every day. There were also cafes and concession stands on five of the incomplete floors so workers did not have to descend to the ground level to eat lunch. Temporary water taps were also built so workers did not waste time buying water bottles from the ground level. Additionally, carts running on a small railway system transported materials from the basement storage to elevators that brought the carts to the desired floors where they would then be distributed throughout that level using another set of tracks. The of steel ordered for the project was the largest-ever single order of steel at the time, comprising more steel than was ordered for the Chrysler Building and 40 Wall Street combined. According to historian John Tauranac, building materials were sourced from numerous, and distant, sources with "limestone from Indiana, steel girders from Pittsburgh, cement and mortar from upper New York State, marble from Italy, France, and England, wood from northern and Pacific Coast forests, [and] hardware from New England." The facade, too, used a variety of material, most prominently Indiana limestone but also Swedish black granite, terracotta, and brick.

By June 20, the skyscraper's supporting steel structure had risen to the 26th floor, and by July 27, half of the steel structure had been completed. Starrett Bros. and Eken endeavored to build one floor a day in order to speed up construction, a goal that they almost reached with their pace of stories per week; prior to this, the fastest pace of construction for a building of similar height had been stories per week. While construction progressed, the final designs for the floors were being designed from the ground up (as opposed to the general design, which had been from the roof down). Some of the levels were still undergoing final approval, with several orders placed within an hour of a plan being finalized. On September 10, as steelwork was nearing completion, Smith laid the building's cornerstone during a ceremony attended by thousands. The stone contained a box with contemporary artifacts including the previous day's "New York Times", a U.S. currency set containing all denominations of notes and coins minted in 1930, a history of the site and building, and photographs of the people involved in construction. The steel structure was topped out at on September 19, twelve days ahead of schedule and 23 weeks after the start of construction. Workers raised a flag atop the 86th floor to signify this milestone.

Afterward, work on the building's interior and crowning mast commenced. The mooring mast topped out on November 21, two months after the steelwork had been completed. Meanwhile, work on the walls and interior was progressing at a quick pace, with exterior walls built up to the 75th floor by the time steelwork had been built to the 95th floor. The majority of the facade was already finished by the middle of November. Because of the building's height, it was deemed infeasible to have many elevators or large elevator cabins, so the builders contracted with the Otis Elevator Company to make 66 cars that could speed at , which represented the largest-ever elevator order at the time.

In addition to the time constraint builders had, there were also space limitations because construction materials had to be delivered quickly, and trucks needed to drop off these materials without congesting traffic. This was solved by creating a temporary driveway for the trucks between 33rd and 34th Streets, and then storing the materials in the building's first floor and basements. Concrete mixers, brick hoppers, and stone hoists inside the building ensured that materials would be able to ascend quickly and without endangering or inconveniencing the public. At one point, over 200 trucks made material deliveries at the building site every day. A series of relay and erection derricks, placed on platforms erected near the building, lifted the steel from the trucks below and installed the beams at the appropriate locations. The Empire State Building was structurally completed on April 11, 1931, twelve days ahead of schedule and 410 days after construction commenced. Al Smith shot the final rivet, which was made of solid gold.

The project involved more than 3,500 workers at its peak, including 3,439 on a single day, August 14, 1930. Many of the workers were Irish and Italian immigrants, with a sizable minority of Mohawk ironworkers from the Kahnawake reserve near Montreal. According to official accounts, five workers died during the construction, although the "New York Daily News" gave reports of 14 deaths and a headline in the socialist magazine "The New Masses" spread unfounded rumors of up to 42 deaths. The Empire State Building cost $40,948,900 to build, including demolition of the Waldorf–Astoria (equivalent to $ in ). This was lower than the $60 million budgeted for construction.

Lewis Hine captured many photographs of the construction, documenting not only the work itself but also providing insight into the daily life of workers in that era. Hine's images were used extensively by the media to publish daily press releases. According to the writer Jim Rasenberger, Hine "climbed out onto the steel with the ironworkers and dangled from a derrick cable hundreds of feet above the city to capture, as no one ever had before (or has since), the dizzy work of building skyscrapers". In Rasenberger's words, Hine turned what might have been an assignment of "corporate flak" into "exhilarating art". These images were later organized into their own collection. Onlookers were enraptured by the sheer height at which the steelworkers operated. "New York" magazine wrote of the steelworkers: "Like little spiders they toiled, spinning a fabric of steel against the sky".

The Empire State Building was officially opened on May 1, 1931, forty five days ahead of its projected opening date, by United States President Herbert Hoover, who turned on the building's lights with the ceremonial button push from Washington, D.C.. Over 350 guests attended the opening ceremony, and following luncheon, at the 86th floor including Jimmy Walker, Governor Franklin D. Roosevelt, and Al Smith. An account from that day stated that the view from the luncheon was obscured by a fog, with other landmarks such as the Statue of Liberty being "lost in the mist". The building officially opened the next day. Advertisements for the observatories were placed in local newspapers, while nearby hotels also released advertisements that lauded their proximity to the newly opened tower.

According to "The New York Times", builders and real estate speculators predicted that the Empire State Building would be the world's tallest building "for many years", thus ending the great New York City skyscraper rivalry. At the time, most engineers agreed that it would be difficult to build a building taller than , even with the hardy Manhattan bedrock as a foundation. (Technically, it was believed possible to build a tower of up to , but it was deemed uneconomical to do so, especially during the Great Depression.) As the tallest building in the world, at that time, and the first one to exceed 100 floors, the Empire State Building became an icon of the city and, ultimately, of the nation.

The Empire State Building's opening coincided with the Great Depression in the United States, and as a result much of its office space was vacant from its opening. In the first year, only 23% of the available space was rented, as compared to the early 1920s, where the average building would have occupancy of 52% upon opening and 90% rented within five years. The lack of renters led New Yorkers to deride the building as the "Empty State Building".

Jack Brod, one of the building's longest resident tenants, co-established the Empire Diamond Corporation with his father in the building in mid-1931 and rented space in the building until he died in 2008. Brod recalled that there were only about 20 tenants at the time of opening, including him, and that Al Smith was the only real tenant in the space above his seventh-floor offices. Generally, during the early 1930s, it was rare for more than a single office space to be rented in the building, despite Smith's and Raskob's aggressive marketing efforts in the newspapers and to anyone they knew. The building's lights were continuously left on, even in the unrented spaces, to give the impression of occupancy. This was exacerbated by competition from Rockefeller Center as well as from buildings on 42nd Street, which, when combined with the Empire State Building, resulted in surplus of office space in a slow market.

Aggressive marketing efforts served to reinforce the Empire State Building's status as the world's tallest. The observatory was advertised in local newspapers as well as on railroad tickets. The building became a popular tourist attraction, with one million people each paying one dollar to ride elevators to the observation decks in 1931. In its first year of operation, the observation deck made approximately $2 million in revenue, as much as its owners made in rent that year. By 1936, the observation deck was crowded on a daily basis, with food and drink available for purchase at the top, and by 1944 the tower had received its 5 millionth visitor. In 1931, NBC took up tenancy, leasing space on the 85th floor for radio broadcasts. From the outset the building was in debt, losing $1 million per year by 1935. Real estate developer Seymour Durst recalled that the building was so underused in 1936 that there was no elevator service above the 45th floor, as the building above the 41st floor was empty except for the NBC offices and the Raskob/Du Pont offices on the 81st floor.

Per the original plans, the Empire State Building's spire was intended to be an airship docking station. Raskob and Smith had proposed dirigible ticketing offices and passenger waiting rooms on the 86th floor, while the airships themselves would be tied to the spire at the equivalent of the building's 106th floor. An elevator would ferry passengers from the 86th to the 101st floor after they had checked in on the 86th floor, after which passengers would have climbed steep ladders to the board the airship. The idea, however, was impractical and dangerous due to powerful updrafts caused by the building itself, the wind currents across Manhattan, and the spires of nearby skyscrapers. Furthermore, even if the airship were to successfully navigate all these obstacles, its crew would have to jettison some ballast by releasing water onto the streets below in order to maintain stability, and then tie the craft's nose to the spire with no mooring lines securing the tail end of the craft. On September 15, 1931, in the first and only instance of an airship using the building's mast, a small commercial United States Navy airship circled 25 times in winds. The airship then attempted to dock at the mast, but its ballast spilled and the craft was rocked by unpredictable eddies. The near-disaster scuttled plans to turn the building's spire into an airship terminal, although one blimp did manage to make a single newspaper delivery afterward.

In 1932, the Fifth Avenue Association gave the tower its 1931 "gold medal" for architectural excellence, signifying that the Empire State had been the best-designed building on Fifth Avenue to open in 1931. A year later, on March 2, 1933, the movie "King Kong" was released. The movie, which depicted a large stop motion ape named Kong climbing the Empire State Building, made the still-new building into a cinematic icon.

On July 28, 1945, a B-25 Mitchell bomber crashed into the north side of the Empire State Building, between the 79th and 80th floors. One engine completely penetrated the building and landed in a neighboring block, while the other engine and part of the landing gear plummeted down an elevator shaft. Fourteen people were killed in the incident, but the building escaped severe damage and was reopened two days later.

The Empire State Building only started becoming profitable in the 1950s, when it was finally able to break even for the first time. Despite the lack of nearby transportation centers, the Empire State Building started to attract renters due to its reputation. A radio antenna was erected on top of the tower starting in 1950, allowing the area's television stations to broadcast from the building.

However, despite the turnaround in the building's fortunes, Raskob put the tower up for sale in 1951, with a minimum asking price of $50 million. The property was purchased by business partners Roger L. Stevens, Henry Crown, Alfred R. Glancy and Ben Tobin. The sale was brokered by the Charles F. Noyes Company, a prominent real estate firm in upper Manhattan, for $51 million, the highest price paid for a single structure at the time. By this time, the Empire State had been fully leased for several years with a waiting list of parties looking to lease space in the building, according to the "Cortland Standard". That year, six news companies formed a partnership to pay a combined annual fee of $600,000 to use the tower's antenna, which was completed in 1953. Crown bought out his partners' ownership stakes in 1954, becoming the sole owner. The following year, the American Society of Civil Engineers named the building one of the "Seven Modern Civil Engineering Wonders".

In 1961, a group headed by Harry B. Helmsley, Lawrence A. Wien, and Wien's son-in-law Peter L. Malkin gained control of the building for $65 million, which became the new highest price for a single structure. Over 3,000 people paid $10,000 for one share each in a company called Empire State Building Associates. The company in turn subleased the building to another company headed by Helmsley and Wein, raising $33 million of the funds needed to pay the purchase price. In a separate transaction, the land underneath the building was sold to Prudential Insurance for $29 million. Helmsley, Wein, and Malkin quickly started a program of minor improvement projects, including the first-ever full-building facade refurbishment and window-washing in 1962, the installation of new flood lights on the 72nd floor in 1964, and replacement of the manually operated elevators with automatic units in 1966. The little-used western end of the second floor was used as a storage space until 1964, at which point it received escalators to the first floor as part of its conversion into a highly-sought retail area.

In 1961, the same year that Helmsley, Wien, and Malkin had purchased the Empire State Building, the Port Authority of New York and New Jersey formally backed plans for a new World Trade Center in Lower Manhattan. The plan originally included 66-story twin towers with column-free open spaces. The Empire State's owners and real estate speculators were worried that the twin towers' of office space would create a glut of rentable space in Manhattan as well as take away the Empire State Building's profits from lessees. A revision in the World Trade Center's plan brought the twin towers to each or 110 stories, taller than the Empire State. Opponents of the new project included prominent real-estate developer Robert Tishman, as well as Wien's Committee for a Reasonable World Trade Center. In response to Wein's opposition, Port Authority executive director Austin J. Tobin said that Wein was only opposing the project because it would overshadow his Empire State Building as the world's tallest building.

The World Trade Center's twin towers started construction in 1966. The following year, the Ostankino Tower succeeded the Empire State Building as the tallest freestanding structure in the world. In 1970, the Empire State surrendered its position as the world's tallest building, when the still under construction North Tower of the World Trade Center surpassed it, on October 19; the North Tower was topped out, on December 23, 1970.

In December 1975, the observation deck was opened on the 110th floor of the Twin Towers, significantly higher than the 86th floor observatory on the Empire state. The Empire State Building was also losing revenue during this period, particularly as a number of broadcast stations had moved to the World Trade Center in 1971; although the Port Authority continued to pay the broadcasting leases for the Empire State until 1984.

By 1980, there were nearly two million annual visitors, although a building official had previously estimated between 1.5 million and 1.75 million annual visitors. The building received its own ZIP code in May 1980 in a roll out of 63 new postal codes in Manhattan. At the time, the tenants of tower collectively received 35,000 pieces of mail daily. The Empire State Building celebrated its 50th anniversary on May 1, 1981, with a much-publicized, but poorly received, laser light show, as well as an "Empire State Building Week" that ran through to May 8.

The New York City Landmarks Preservation Commission voted to make the lobby a city landmark on May 19, 1981, citing the historic nature of the first and second floors, as well as "the fixtures and interior components" of the upper floors. The building became a National Historic Landmark in 1986 in close alignment to the New York City Landmarks report. That year, the Plaza Hotel and Metropolitan Museum of Art further uptown were also designated as National Historic Landmarks. The Empire State Building was added to the National Register of Historic Places the following year due to its architectural significance.

From the early to mid 1990s, the building underwent a $55 million series of upgrades with the alarm systems, elevators, windows, and air conditioning being replaced, the 86th floor observation deck made accessible to disabled visitors, and the facade again refurbished. Prudential sold the land under the building in 1991 for $42 million to a buyer representing hotelier Hideki Yokoi, who was imprisoned at the time in connection with a deadly fire at the Hotel New Japan hotel in Tokyo. The land was bought jointly by Donald Trump and Hideki Yokoi in 1994. Having secured a half-ownership of the land, Trump devised plans to take ownership of the building itself so he could renovate it, even though Helmsley and Malkin had already started their refurbishment project. He sued Empire State Building Associates in February 1995, claiming that the latter had caused the building to become a "high-rise slum" and a "second-rate, rodent-infested" office tower. Trump had intended to have Empire State Building Associates evicted for violating the terms of their lease, but was denied. this led to Helmsley's companies coutersuing Trump in May. This sparked a series of lawsuits and countersuits that lasted several years, partly arising from Trump's desire to obtain the building's master lease by taking it from Empire State Building Associates. Upon Harry Helmsley's death in 1997, the Malkins sued Helmsley's widow, Leona Helmsley, for ownership of the building.

With the destruction of the World Trade Center in the September 11 attacks in 2001, the Empire State Building again became the tallest building in New York City, but was only the second-tallest building in the Americas after the Willis Tower in Chicago. As a result of the attacks, transmissions from nearly all of the city's commercial television and FM radio stations were again broadcast from the Empire State Building. The attacks also led to an increase in security due to persistent terror threats against New York City landmarks.

In 2002, Trump and Yokoi sold their land claim to the Empire State Building Associates, now headed by Malkin, in a $57.5 million sale. This action merged the building's title and lease for the first time in half a century. Despite the lingering threat posed by the 9/11 attacks, the Empire State Building remained popular with 3.5 million visitors to the observatories in 2004, compared to about 2.8 million in 2003.

Leona Helmsley's remaining share in the building was bought by Peter Malkin's company in 2006. In 2008 the building was temporarily "stolen" by the "New York Daily News" to show how easy it was to transfer the deed on a property, since city clerks were not required to validate the submitted information, as well as to help demonstrate how fraudulent deeds could be used to obtain large mortgages and then have individuals disappear with the money. The paperwork submitted to the city included the names of Fay Wray, the famous star of "King Kong", and Willie Sutton, a notorious New York bank robber. The newspaper then transferred the deed back over to the legitimate owners, who at that time were Empire State Land Associates.

The building's public areas received a $550 million renovation in 2009 (see ). The building received new air conditioning, waterproofing, a renovated observation deck and lobby, and a relocated 80th-floor gift shop. This included $120 million of energy efficient upgrades, which allowed the building to receive a gold Leadership in Energy and Environmental Design (LEED) rating in September 2011. The new One World Trade Center surpassed the Empire State Building as the tallest LEED-certified building when it opened in 2014.

The height of the Empire State Building, to its 102nd floor, is , including its pinnacle. The building has 85 stories of commercial and office space representing a total of of rentable space. It has an indoor and outdoor observation deck on the 86th floor, the highest floor within the actual tower. The remaining 16 stories are part of the Art Deco spire, which is capped by an observatory on the 102nd-floor. The spire is hollow with no floors between levels 86 and 102. Atop the tower is the pinnacle, much of which is covered by broadcast antennas, and surmounted with a lightning rod.

According to the official fact sheets the building rises 1,860 steps from the first to the 102nd floor, weighs , has an internal volume of , and an exterior with of limestone and granite. Construction of the tower required ten million bricks, of steel, as well as of elevator cable and of electrical wires. The building has a capacity for 20,000 tenants and 15,000 visitors.

The building has been named as one of the Seven Wonders of the Modern World by the American Society of Civil Engineers. The building and its street floor interior are designated landmarks of the New York City Landmarks Preservation Commission, and confirmed by the New York City Board of Estimate. It was designated as a National Historic Landmark in 1986. In 2007, it was ranked number one on the AIA's List of America's Favorite Architecture.

The Empire State Building's art deco design is typical of pre–World War II architecture in New York. The modernistic, stainless steel canopies of the entrances on 33rd and 34th Streets lead to two-story-high corridors around the elevator core, crossed by stainless steel and glass-enclosed bridges at the second-floor level. The riveted steel frame of the building was originally designed to handle all of the building's gravitational stresses and wind loads. The exterior of the building is clad in Indiana limestone panels sourced from the Empire Mill in Sanders, Indiana, which give the building its signature blonde color. The limestone facade, which is lined with vertical steel mullions parallel to each window, also helps to increase the stiffness of the steel frame against high winds. The amount of material used in the building's construction resulted in a very stiff structure when compared to other skyscrapers, with a structural stiffness of versus the Willis Tower's and the John Hancock Center's . A December 1930 feature in "Popular Mechanics" estimated that a building with the Empire State's dimensions would still stand even if hit with an impact of .

The Empire State Building design featured one major setback and several smaller ones that reduce the level dimensions as the height increases, thus making upper 81 floors much smaller than the lower five floors. However, this design allows sunlight to illuminate the interiors of the top floors and, in addition, positions these floors away from the noisy streets below. This design was mandated as per the 1916 Zoning Resolution, which was intended to allow sunlight to reach the streets as well. Normally, a building of the Empire State's dimensions would be permitted to build up to 12 stories on the Fifth Avenue side, and up to 17 stories on the 33rd/34th Streets side, before it would have to utilize setbacks. However, the setbacks were arranged such that the largest setback was on the sixth floor, above the five-floor "base", so the rest of the building above the sixth floor would have a facade of uniform shape.

The Empire State Building was the first building to have more than 100 floors. It has 6,500 windows; 73 elevators; a total floor area of ; and a base covering . Its original 64 elevators, built by the Otis Elevator Company, are located in a central core and are of varying heights, with the longest of these elevators reaching from the lobby to the 80th floor. As originally built, there were four "express" elevators that connected the lobby, 80th floor, and several landings in between; the other 60 "local" elevators connected the landings with the floors above these intermediate landings. Of the 64 total elevators, 58 were for passenger use (comprising the four express elevators and 54 local elevators), and eight were for freight deliveries. The elevators were designed to move at . At the time of the skyscraper's construction, their practical speed was limited to as per city law, but this limit was removed shortly after the building opened. Additional elevators connect the 80th floor to the six floors above it, as the six extra floors were built after the original 80 stories were approved. The elevators were mechanically operated until 2011, when they were replaced with digital elevators during the $550 million renovation of the building. The Empire State Building has 73 elevators in all, including service elevators.

Utilities are grouped in a central shaft. On each floor between levels 6 and 86, the central shaft is surrounded by a main corridor on all four sides. As per the final specifications of the building, the corridor is surrounded in turn by office space deep. Each of the floors has 210 structural columns that pass through it, which provide structural stability, but limits the amount open space on these floors. However, the relative dearth of stone in the building allows for more space overall, with a 1:200 stone-to-building ratio in the Empire State compared to a 1:50 ratio in similar buildings.

The main lobby is accessed from Fifth Avenue, on the building's east side, and contains an entrance with one set of double doors between a pair of revolving doors. At the top of each doorway is a bronze motif depicting one of three "crafts or industries" used in the building's construction—Electricity, Masonry, and Heating. The lobby contains two tiers of marble, a lighter marble on the top, above the storefronts, and a darker marble on the bottom, flush with the storefronts. There is a pattern of zigzagging terrazzo tiles on the lobby floor, which leads from the entrance on the east to the aluminum relief on the west. The chapel-like three-story-high lobby, which runs parallel to 33rd and 34th Streets, contains storefronts on both its northern and southern sides. These storefronts are framed on each side by tubes of dark "modernistically rounded marble", according to the New York City Landmarks Preservation Commission, and above by a vertical band of grooves set into the marble. Immediately inside the lobby is an airport-style security checkpoint.

The walls on both the northern and southern sides of the lobby house storefronts and escalators to a mezzanine level. At the west end of the lobby is an aluminum relief of the skyscraper as it was originally built (i.e. without the antenna). The relief, which was intended to provide a welcoming effect, contains an embossing of the building's outline, accompanied by what the Landmarks Preservation Commission describes as "the rays of an aluminum sun shining out behind [the tower] and mingling with aluminum rays emanating from the spire of the Empire State Building". In the background is a state map of New York with the building's location marked by a "medallion" in the very southeast portion of the outline. A compass is located in the bottom right and a plaque to the tower's major developers is on the bottom left.

The plaque at the western end of the lobby is located on the eastern interior wall of a one-story tall rectangular-shaped corridor that surrounds the banks of escalators, with a similar design to the lobby. The rectangular shaped corridor actually consists of two long hallways on the northern and southern sides of the rectangle, as well as a shorter hallway on the eastern side and another long hallway on the western side. At both ends of the northern and southern corridors, there is a bank of four low-rise elevators in between the corridors. The western side of the rectangular elevator-bank corridor extends north to the 34th Street entrance and south to the 33rd Street entrance. It borders three large storefronts and leads to escalators that go both to the second floor and to the basement. Going from west to east, there are secondary entrances to 34th and 33rd Streets from both the northern and southern corridors, respectively, at approximately the two-thirds point of each corridor.

Until the 1960s, an art deco mural, inspired by both the sky and the Machine Age, was installed in the lobby ceilings. Subsequent damage to these murals, designed by artist Leif Neandross, resulted in reproductions being installed. Renovations to the lobby in 2009, such as replacing the clock over the information desk in the Fifth Avenue lobby with an anemometer and installing two chandeliers intended to be part of the building when it originally opened, revived much of its original grandeur. The north corridor contained eight illuminated panels created in 1963 by Roy Sparkia and Renée Nemorov, in time for the 1964 World's Fair, depicting the building as the Eighth Wonder of the World alongside the traditional seven. The building's owners installed a series of paintings by the New York artist Kysa Johnson in the concourse level. Johnson later filed a federal lawsuit, in January 2014, under the Visual Artists Rights Act alleging the negligent destruction of the paintings and damage to her reputation as an artist. As part of the building's 2010 renovation, Denise Amses commissioned a work consisting of 15,000 stars and 5,000 circles, superimposed on a etched-glass installation, in the lobby.

Capital improvements were made to the Empire State Building during the early to mid-1990s at a cost of $55 million. These improvements entailed replacing alarm systems, elevators, windows, and air conditioning; making the observation deck compliant with the Americans with Disabilities Act of 1990 (ADA); and refurbishing the limestone facade. The observatory renovation was added after disability rights groups and the United States Department of Justice filed a lawsuit against the building in 1992, in what was the first lawsuit filed by an organization under the new law. A settlement was reached in 1994, in which the Empire State Building Associates agreed to add ADA-compliant elements, such as new elevators, ramps, and automatic doors, during its ongoing renovation.

The building's public areas received a $550 million renovation in 2009 with improvements to the air conditioning and waterproofing, renovations to the observation deck and main lobby, and relocation of the gift shop to the 80th floor. $120 million of the budget was spent on improving the energy efficiency of the building with the goal of reducing energy emissions by 38% within five years. For example, all of the windows were refurbished onsite into film-coated "superwindows" which block heat but pass light. Air conditioning operating costs on hot days were reduced, saving $17 million of the project's capital cost immediately and partially funding some of the other retrofits. The Empire State Building won a gold Leadership in Energy and Environmental Design (LEED) rating in September 2011, as well as the World Federation of Great Towers' Excellence in Environment Award for 2010.

The final stage of the building was the installation of a hollow mast, a steel shaft fitted with elevators and utilities, above the 86th floor. At the top would be a conical roof and the 102nd-floor docking station. The elevators would ascend from the 86th floor ticket offices to a 101st-floor waiting room. From there, stairs would lead to the 102nd floor, where passengers would enter the airships. The airships would have been moored to the spire at the equivalent of the building's 106th floor.

On the 102nd floor of the Empire State Building (formerly the 101st floor), there is a door with stairs ascending to the 103rd floor (formerly the 102nd). This was built as a disembarkation floor for airships tethered to the building's spire, and has a circular balcony outside. It is now an access point to reach the spire for maintenance. The room now contains electrical equipment, but celebrities and dignitaries may also be given permission to take pictures there. Above the 103rd floor, there is a set of stairs and a ladder to reach the spire for maintenance work. The mast's 480 windows were all replaced in 2015.

Broadcasting began at the Empire State Building on December 22, 1931, when NBC and RCA began transmitting experimental television broadcasts from a small antenna erected atop the spire, with two separate transmitters for the visual and audio data. They leased the 85th floor and built a laboratory there. In 1934, RCA was joined by Edwin Howard Armstrong in a cooperative venture to test his FM system from the building's antenna. This setup, which entailed the installation of the world's first FM transmitter, continued only until October of the next year due to disputes between RCA and Armstrong. Specifically, NBC wanted to install more TV equipment in the room where Armstrong's transmitter was located.

After some time, the 85th floor became home to RCA's New York television operations initially as experimental station W2XBS channel 1 then, from 1941, as commercial station WNBT channel 1 (now WNBC-TV channel 4). NBC's FM station, W2XDG, began transmitting from the antenna in 1940. NBC retained exclusive use of the top of the building until 1950 when the Federal Communications Commission (FCC) ordered the exclusive deal be terminated. The FCC directive was based on consumer complaints that a common location was necessary for the seven extant New York-area television stations to transmit from so that receiving antennas would not have to be constantly adjusted. Other television broadcasters would later join RCA at the building on the 81st through 83rd floors, often along with sister FM stations. Construction of a dedicated broadcast tower began on July 27, 1950, with TV, and FM, transmissions starting in 1951. The broadcast tower was completed by 1953. From 1951, six broadcasters agreed to pay a combined $600,000 per year for the use of the antenna. In 1965, a separate set of FM antennae was constructed ringing the 103rd floor observation area to act as a master antenna.

The placement of the stations in the Empire State Building became a major issue with the construction of the World Trade Center Twin Towers in the late 1960s, and early 1970s. The greater height of the Twin Towers would reflect radio waves broadcast from the Empire State Building, eventually resulting in some broadcasters relocating to the newer towers instead of suing the developer, the Port Authority of New York and New Jersey. Even though the nine stations who were broadcasting from the Empire State Building were leasing their broadcast space until 1984, most of these stations moved to the World Trade Center as soon as it was completed in 1971. The broadcasters obtained a court order stipulating that the Port Authority had to build a mast and transmission equipment in the North Tower, as well as pay the broadcasters' leases in the Empire State Building until 1984. Only a few broadcasters renewed their leases in the Empire State Building.

The September 11 attacks in 2001 destroyed the World Trade Center and the broadcast centers atop it, leaving most of the city's stations without a station for ten days until a temporary tower was built in Alpine, New Jersey. By October 2001, nearly all of the city's commercial broadcast stations (both television and FM radio) were again transmitting from the top of the Empire State Building. In a report that Congress commissioned about the transition from analog television to digital television, it was stated that the placement of broadcast stations in the Empire State Building was considered "problematic" due to interference from other nearby towers. In comparison, the Congressional report stated that the former Twin Towers had very few buildings of comparable height nearby thus signals suffered little interference. In 2003, a few FM stations were relocated to the nearby Condé Nast Building to reduce the number of broadcast stations using the Empire State Building. Eleven television stations and twenty-two FM stations had signed 15-year leases in the building by May 2003. It was expected that a taller broadcast tower in Bayonne, New Jersey, or Governors Island, would be built in the meantime with the Empire State Building being used as a "backup" since signal transmissions from the building were generally of poorer quality.

, the Empire State Building is home to the following stations:

The 86th and 102nd floors contain observatories, which see a combined average of 4 million visitors per year. Since opening, the observatories have been more popular than similar observatories at 30 Rockefeller Plaza, the Chrysler Building, the first One World Trade Center, or the Woolworth Building, despite being more expensive. Tourists must pay to visit the observation deck on the 86th floor and an additional amount for the 102nd floor.

The 86th floor observatory contains both an enclosed section and a wide-open section. The 102nd floor observatory is completely enclosed and much smaller. The 102nd floor observatory was closed to the public from the late 1990s to 2005. The observation decks were redesigned in mid-1979.

According to a 2010 report by Concierge.com, the five lines to enter the observation decks are "as legendary as the building itself". Concierge.com stated that there are five lines: the sidewalk line, the lobby elevator line, the ticket purchase line, the second elevator line, and the line to get off the elevator and onto the observation deck. However, in 2016, New York City's official tourism website, NYCgo.com, made note of only three lines: the security check line, the ticket purchase line, and the second elevator line. For an extra fee tourists can skip to the front of the line. The Empire State Building garners significant revenue from ticket sales for its observation decks, making more money from ticket sales than it does from renting office space during some years.

In early 1994, a motion simulator attraction was built on the 2nd floor, as a complement to the observation deck. The cinematic presentation lasts approximately 25 minutes, while the simulation is about eight minutes.

The ride has had two incarnations. The original version, which ran from 1994 until around 2002, featured James Doohan, "" Scotty, as the airplane's pilot who humorously tried to keep the flight under control during a storm. After the World Trade Center terrorist attacks in September 11, 2001, the ride was closed. An updated version debuted in mid-2002, featuring actor Kevin Bacon as the pilot, with the new flight also going haywire. This new version served a more informative goal, as opposed to the old version's main purpose of entertainment, and contained details about the 9/11 attacks. The simulator has received mixed reviews, with assessments of the ride ranging from "great" to "satisfactory" to "corny".

The building was originally equipped with white searchlights atop the tower. They saw their first use in November 1932 when they lit up to signal Roosevelt's victory over Hoover in the presidential election of that year. These were later swapped for four "Freedom Lights" in 1956. In February 1964, flood lights were added on the 72nd floor to illuminate the top of the building at night so that the building could be seen from the World Fair later that year. The lights were shut off from November 1973 to July 1974 because of the energy crisis at the time. In 1976, the businessman Douglas Leigh suggested that Helmsley install 204 metal-halide lights, which were four times as bright as the 1,000 incandescent lights they were to replace. New red, white, and blue metal-halide lights were installed in time for the country's bicentennial that July. After the bicentennial, Helmsley retained the new lights due to the reduced maintenance cost, about $116 a year.

Since 1976, the spire has been lit in colors chosen to match seasonal events and holidays. Organizations are allowed to make requests through the building's website. The building is also lit in the colors of New York-based sports teams on nights when they hosted games. For example, orange, blue and white for the New York Knicks, red, white and blue for the New York Rangers. It was twice lit in scarlet to support New Jersey's Rutgers University, once for a football game against the University of Louisville on November 9, 2006, and again on April 3, 2007 when the women's basketball team played in the national championship game.

There have also been special occasions where the lights are modified from the usual schedule. After the eightieth birthday, and subsequent death, of Frank Sinatra in 1998, for example, the building was bathed in blue light to represent the singer's nickname "Ol' Blue Eyes". After actress Fay Wray, who starred in "King Kong", died in September 2004, the building lights were extinguished for 15 minutes. The floodlights bathed the building in red, white, and blue for several months after the destruction of the World Trade Center, then reverted to the standard schedule. On June 4, 2002, the Empire State Building donned purple and gold (the royal colors of Elizabeth II), in thanks for the United Kingdom playing the Star Spangled Banner during the Changing of the Guard at Buckingham Palace on September 12, 2001 (a show of support after the September 11 attacks). On January 13, 2012, the building was lit in red, orange, and yellow to honor the 60th anniversary of NBC program "The Today Show". From June 1 to 3, 2012, the building was lit in blue and white, the colors of the Israeli flag, in honor of the 49th annual Celebrate Israel Parade.

During 2012, the building's four hundred metal halide lamps and floodlights were replaced with 1,200 LED fixtures, increasing the available colors from nine to over 16 million. The computer-controlled system allows the building to be illuminated in ways that were unable to be done previously with plastic gels. For instance, on November 6, 2012, CNN used the top of the Empire State Building as a scoreboard for the 2012 United States presidential election. When incumbent president Barack Obama had reached the 270 electoral votes necessary to win re-election, the lights turned blue, representing the color of Obama's Democratic Party. Had Republican challenger Mitt Romney won, the building would have been lit red, the color of the Republican Party. Also, on November 26, 2012, the building had its first ever synchronized light show, using music from recording artist Alicia Keys. The building's owners adhere to strict standards in using the lights; for instance, they do not use the lights to play advertisements.

The longest world record held by the Empire State Building was for the tallest skyscraper (to structural height), which it held for 42 years until it was surpassed by the North Tower of the World Trade Center in October 1970. The Empire State Building was also the tallest man-made structure in the world before it was surpassed by the Griffin Television Tower Oklahoma (KWTV Mast) in 1954, and the tallest freestanding structure in the world until the completion of the Ostankino Tower in 1967. An early-1970s proposal to dismantle the spire and replace it with an additional 11 floors, which would have brought the building's height to 1,494 feet (455 m) and made it once again the world's tallest at the time, was considered but ultimately rejected.

With the destruction of the World Trade Center in the September 11 attacks, the Empire State Building again became the tallest building in New York City, and the second-tallest building in the Americas, surpassed only by the Willis Tower in Chicago. The Empire State Building remained the tallest building in New York until the new One World Trade Center reached a greater height in April 2012. , it is the third-tallest building in New York City after the One World Trade Center and 432 Park Avenue, and the fifth-tallest completed skyscraper in the United States behind the two other tallest buildings in New York City, as well as the Willis Tower and Trump International Hotel and Tower in Chicago. The Empire State Building is the 28th-tallest in the world , the tallest being Burj Khalifa in Dubai. It is also the sixth-tallest freestanding structure in the Americas behind the five tallest buildings and the CN Tower.

, the building houses around 1,000 businesses. Current tenants include:
Former tenants include:

At 9:40 am on July 28, 1945, a B-25 Mitchell bomber, piloted in thick fog by Lieutenant Colonel William Franklin Smith Jr., crashed into the north side of the Empire State Building between the 79th and 80th floors where the offices of the National Catholic Welfare Council were located. One engine completely penetrated the building landing on the roof of a nearby building where it started a fire that destroyed a penthouse. The other engine and part of the landing gear plummeted down an elevator shaft causing a fire, which was extinguished in 40 minutes. Fourteen people were killed in the incident. Elevator operator Betty Lou Oliver survived a plunge of 75 stories inside an elevator, which still stands as the Guinness World Record for the longest survived elevator fall recorded.

Despite the damage and loss of life, the building was open for business on many floors two days later. The crash helped spur the passage of the long-pending Federal Tort Claims Act of 1946, as well as the insertion of retroactive provisions into the law, allowing people to sue the government for the incident. Also as a result of the crash, the Civil Aeronautics Administration enacted strict regulations regarding flying over New York City, setting a minimum flying altitude of above sea level regardless of the weather conditions.

A year later, on July 24, 1946, another aircraft narrowly missed striking the building. The unidentified twin-engine plane scraped past the observation deck, scaring the tourists there.

On January 24, 2000, an elevator in the building suddenly descended 40 stories after a cable that controlled the cabin's maximum speed was severed. The elevator fell from the 44th floor to the fourth floor, where a narrowed elevator shaft provided a second safety system. Despite the 40-floor fall, both of the passengers in the cabin at the time were only slightly injured. Since that elevator had no fourth-floor doors, the passengers were rescued by an adjacent elevator. After the fall, building inspectors reviewed all of the building's elevators.

Because of the building's iconic status, it and other Midtown landmarks are popular locations for suicide attempts. More than 30 people have attempted suicide over the years by jumping from the upper parts of the building, with most attempts being successful.

The first suicide from the building occurred on April 7, 1931, before the tower was even completed, when a carpenter who had been laid-off went to the 58th floor and jumped. The first suicide after the building's opening occurred from the 86th floor observatory on February 1935, when Irma P. Eberhardt fell onto a marquee sign. On December 16, 1943, William Lloyd Rambo jumped to his death from the 86th floor, landing amidst Christmas shoppers on the street below. In the early morning of September 27, 1946, shell-shocked Marine Douglas W. Brashear Jr. jumped from the 76th-floor window of the Grant Advertising Agency; police found his shoes from his body.

On May 1, 1947, Evelyn McHale leapt to her death from the 86th floor observation deck and landed on a limousine parked at the curb. Photography student Robert Wiles took a photo of McHale's oddly intact corpse a few minutes after her death. The police found a suicide note among possessions that she left on the observation deck: "He is much better off without me... I wouldn't make a good wife for anybody". The photo ran in the edition of May 12, 1947 of "Life" magazine and is often referred to as "The Most Beautiful Suicide". It was later used by visual artist Andy Warhol in one of his prints entitled "Suicide (Fallen Body)". A mesh fence was put up around the 86th floor terrace in December 1947 after five people tried to jump during a three-week span in October and November of that year. By then, sixteen people had died from suicide jumps.

Only one person has jumped from the upper observatory. Frederick Eckert of Astoria ran past a guard in the enclosed 102nd floor gallery on November 3, 1932 and jumped a gate leading to an outdoor catwalk intended for dirigible passengers. He landed and died on the roof of the 86th floor observation promenade.

Two people have survived falls by not falling more than a floor. On December 2, 1979, Elvita Adams jumped from the 86th floor, only to be blown back onto a ledge on the 85th floor by a gust of wind and left with a broken hip. On April 25, 2013, a man fell from the 86th floor observation deck, but he landed alive with minor injuries on an 85th-floor ledge where security guards brought him inside and paramedics transferred him to a hospital for a psychiatric evaluation.

Two fatal shootings have occurred in the direct vicinity of the Empire State Building. Abu Kamal, a 69-year-old Palestinian teacher, shot seven people on the 86th floor observation deck during the afternoon of February 23, 1997. He killed one person and wounded six others before committing suicide. Kamal reportedly committed the shooting in response to events happening in Palestine and Israel.

On the morning of August 24, 2012, 58-year-old Jeffrey T. Johnson shot and killed a former co-worker on the building's Fifth Avenue sidewalk. He had been laid off from his job in 2011. Two police officers confronted the gunman, and he aimed his firearm at them. They responded by firing 16 shots, killing him but also wounding nine bystanders. Most of the injured were hit by bullet fragments, although three took direct hits from bullets.

As the tallest building in the world and the first one to exceed 100 floors, the Empire State Building immediately became an icon of the city and of the nation. In 2013, "Time" magazine noted that the Empire State Building "seems to completely embody the city it has become synonymous with". The historian John Tauranac calls the tower "'the' twentieth-century New York building", despite the existence of taller and more modernist buildings. Early in the building's history, travel companies such as Short Line Motor Coach Service and New York Central Railroad used the building as an icon to symbolize the city. After the construction of the first World Trade Center, architect Paul Goldberger noted that the Empire State Building "is famous for being tall, but it is good enough to be famous for being good."

As an icon of the United States, it is also very popular among Americans. In a 2007 survey, the American Institute of Architects found that the Empire State Building was "America's favorite building". The building was originally a symbol of hope in a country devastated by the Depression, as well as a work of accomplishment by newer immigrants. The writer Benjamin Flowers states that the Empire State was "a building intended to celebrate a new America, built by men (both clients and construction workers) who were themselves new Americans." The architectural critic Jonathan Glancey refers to the building as an "icon of American design".

The Empire State Building has been hailed as an example of a "wonder of the world" due to the massive effort expended during construction. "The Washington Star" listed it as part of one of the "seven wonders of the modern world" in 1931, while "Holiday" magazine wrote in 1958 that the Empire State's height would be taller than the combined heights of the Eiffel Tower and the Great Pyramid of Giza. The American Society of Civil Engineers also declared the building "A Modern Civil Engineering Wonder of the United States" in 1958, and one of the Seven Wonders of the Modern World in 1994. Ron Miller, in a 2010 book, also described the Empire State Building as one of the "seven wonders of engineering". It has often been called the Eighth Wonder of the World as well, an appellation that it has held since shortly after opening. The panels installed in the lobby in 1963 reflected this, showing the seven original wonders alongside the Empire State Building.

As an icon of New York City, the Empire State Building has been featured in various films, books, TV shows, and video games. According to the building's official website, more than 250 movies contain depictions of the Empire State Building. In his book about the building, John Tauranac writes that the first documented appearance of the tower in popular culture was "Swiss Family Manhattan", a 1932 children's story by Christopher Morley. A year later, the film "King Kong" depicted Kong, a large stop motion ape that climbs the Empire State Building, bringing the building into the popular imagination. Later movies such as "An Affair to Remember" (1957), "Sleepless in Seattle" (1993), and "Independence Day" (1996) also featured the building. The building has also been featured in other works, such as "Daleks in Manhattan", a 2007 episode of the TV series "Doctor Who"; and "Empire", an eight-hour black-and-white silent film by Andy Warhol, which was later added to the Library of Congress's National Film Registry.

The Empire State Building Run-Up, a foot race from ground level to the 86th-floor observation deck, has been held annually since 1978. Its participants are referred to both as runners and as climbers, and are often tower running enthusiasts. The race covers a vertical distance of 1,050 feet (320 m) and takes in 1,576 steps. The record time is 9 minutes and 33 seconds, achieved by Australian professional cyclist Paul Crake in 2003, at a climbing rate of per hour. ESRT began trading publicly on the New York Stock Exchange on October 2, 2013.




</doc>
<doc id="9737" url="https://en.wikipedia.org/wiki?curid=9737" title="Eugenics">
Eugenics

Eugenics (; from Greek εὐγενής "eugenes" 'well-born' from εὖ "eu", 'good, well' and γένος "genos", 'race, stock, kin') is a set of beliefs and practices that aims at improving the genetic quality of a human population.
The exact definition of "eugenics" has been a matter of debate since the term was coined by Francis Galton in 1883. The concept predates this coinage, with Plato suggesting applying the principles of selective breeding to humans around 400 BCE.

Frederick Osborn's 1937 journal article "Development of a Eugenic Philosophy" framed it as a social philosophy—that is, a philosophy with implications for social order. That definition is not universally accepted. Osborn advocated for higher rates of sexual reproduction among people with desired traits (positive eugenics), or reduced rates of sexual reproduction and sterilization of people with less-desired or undesired traits (negative eugenics).

Alternatively, gene selection rather than "people selection" has recently been made possible through advances in genome editing, leading to what is sometimes called new eugenics, also known as neo-eugenics, consumer eugenics, or liberal eugenics.

While eugenic principles have been practiced as far back in world history as ancient Greece, the modern history of eugenics began in the early 20th century when a popular eugenics movement emerged in the United Kingdom and spread to many countries including the United States, Canada and most European countries. In this period, eugenic ideas were espoused across the political spectrum. Consequently, many countries adopted eugenic policies with the intent to improve the quality of their populations' genetic stock. Such programs included both "positive" measures, such as encouraging individuals deemed particularly "fit" to reproduce, and "negative" measures such as marriage prohibitions and forced sterilization of people deemed unfit for reproduction. People deemed unfit to reproduce often included people with mental or physical disabilities, people who scored in the low ranges of different IQ tests, criminals and deviants, and members of disfavored minority groups. The eugenics movement became negatively associated with Nazi Germany and the Holocaust when many of the defendants at the Nuremberg trials attempted to justify their human rights abuses by claiming there was little difference between the Nazi eugenics programs and the U.S. eugenics programs.
In the decades following World War II, with the institution of human rights, many countries gradually began to abandon eugenics policies, although some Western countries, among them the United States, continued to carry out forced sterilizations.

Since the 1980s and 1990s, when new assisted reproductive technology procedures became available such as gestational surrogacy (available since 1985), preimplantation genetic diagnosis (available since 1989), and cytoplasmic transfer (first performed in 1996), fear about a possible revival of eugenics and widening of the gap between the rich and the poor has emerged.

A major criticism of eugenics policies is that, regardless of whether "negative" or "positive" policies are used, they are susceptible to abuse because the criteria of selection are determined by whichever group is in political power at the time. Furthermore, negative eugenics in particular is considered by many to be a violation of basic human rights, which include the right to reproduction. Another criticism is that eugenic policies eventually lead to a loss of genetic diversity, resulting in inbreeding depression due to lower genetic variation.

The concept of positive eugenics to produce better human beings has existed at least since Plato suggested selective mating to produce a guardian class. 
The first formal negative eugenics, that is a legal provision against birth of inferior human beings, was promulgated in Western European culture by the Christian Council of Agde in 506, which forbade marriage between cousins.

This idea was also promoted by William Goodell (1829–1894) who advocated the castration and spaying of the insane.

The idea of a modern project of improving the human population through a statistical understanding of heredity used to encourage good breeding was originally developed by Francis Galton and, initially, was closely linked to Darwinism and his theory of natural selection. Galton had read his half-cousin Charles Darwin's theory of evolution, which sought to explain the development of plant and animal species, and desired to apply it to humans. Based on his biographical studies, Galton believed that desirable human qualities were hereditary traits, though Darwin strongly disagreed with this elaboration of his theory. In 1883, one year after Darwin's death, Galton gave his research a name: "eugenics". With the introduction of genetics, eugenics became associated with genetic determinism, the belief that human character is entirely or in the majority caused by genes, unaffected by education or living conditions. Many of the early geneticists were not Darwinians, and evolution theory was not needed for eugenics policies based on genetic determinism. Throughout its recent history, eugenics has remained controversial.

Eugenics became an academic discipline at many colleges and universities and received funding from many sources. Organizations were formed to win public support and sway opinion towards responsible eugenic values in parenthood, including the British Eugenics Education Society of 1907 and the American Eugenics Society of 1921. Both sought support from leading clergymen and modified their message to meet religious ideals. In 1909 the Anglican clergymen William Inge and James Peile both wrote for the British Eugenics Education Society. Inge was an invited speaker at the 1921 International Eugenics Conference, which was also endorsed by the Roman Catholic Archbishop of New York Patrick Joseph Hayes.

Three International Eugenics Conferences presented a global venue for eugenists with meetings in 1912 in London, and in 1921 and 1932 in New York City. Eugenic policies were first implemented in the early 1900s in the United States. It also took root in France, Germany, and Great Britain. Later, in the 1920s and 1930s, the eugenic policy of sterilizing certain mental patients was implemented in other countries including Belgium, Brazil, Canada, Japan and Sweden.

In addition to being practiced in a number of countries, eugenics was internationally organized through the International Federation of Eugenics Organizations. Its scientific aspects were carried on through research bodies such as the Kaiser Wilhelm Institute of Anthropology, Human Heredity, and Eugenics, the Cold Spring Harbour Carnegie Institution for Experimental Evolution, and the Eugenics Record Office. Politically, the movement advocated measures such as sterilization laws. In its moral dimension, eugenics rejected the doctrine that all human beings are born equal and redefined moral worth purely in terms of genetic fitness. Its racist elements included pursuit of a pure "Nordic race" or "Aryan" genetic pool and the eventual elimination of "unfit" races.

Early critics of the philosophy of eugenics included the American sociologist Lester Frank Ward, the English writer G. K. Chesterton, the German-American anthropologist Franz Boas, who argued that advocates of eugenics greatly over-estimate the influence of biology, and Scottish tuberculosis pioneer and author Halliday Sutherland. Ward's 1913 article "Eugenics, Euthenics, and Eudemics", Chesterton's 1917 book "", and Boas' 1916 article "" (published in "The Scientific Monthly") were all harshly critical of the rapidly growing movement. Sutherland identified eugenists as a major obstacle to the eradication and cure of tuberculosis in his 1917 address "Consumption: Its Cause and Cure", and criticism of eugenists and Neo-Malthusians in his 1921 book "Birth Control" led to a writ for libel from the eugenist Marie Stopes. Several biologists were also antagonistic to the eugenics movement, including Lancelot Hogben. Other biologists such as J. B. S. Haldane and R. A. Fisher expressed skepticism in the belief that sterilization of "defectives" would lead to the disappearance of undesirable genetic traits.

Among institutions, the Catholic Church was an opponent of state-enforced sterilizations. Attempts by the Eugenics Education Society to persuade the British government to legalize voluntary sterilization were opposed by Catholics and by the Labour Party. The American Eugenics Society initially gained some Catholic supporters, but Catholic support declined following the 1930 papal encyclical "Casti connubii". In this, Pope Pius XI explicitly condemned sterilization laws: "Public magistrates have no direct power over the bodies of their subjects; therefore, where no crime has taken place and there is no cause present for grave punishment, they can never directly harm, or tamper with the integrity of the body, either for the reasons of eugenics or for any other reason."

As a social movement, eugenics reached its greatest popularity in the early decades of the 20th century, when it was practiced around the world and promoted by governments, institutions, and influential individuals. Many countries enacted various eugenics policies, including: genetic screenings, birth control, promoting differential birth rates, marriage restrictions, segregation (both racial segregation and sequestering the mentally ill), compulsory sterilization, forced abortions or forced pregnancies, ultimately culminating in genocide.

The scientific reputation of eugenics started to decline in the 1930s, a time when Ernst Rüdin used eugenics as a justification for the racial policies of Nazi Germany. Adolf Hitler had praised and incorporated eugenic ideas in "Mein Kampf" in 1925 and emulated eugenic legislation for the sterilization of "defectives" that had been pioneered in the United States once he took power. Some common early 20th century eugenics methods involved identifying and classifying individuals and their families, including the poor, mentally ill, blind, deaf, developmentally disabled, promiscuous women, homosexuals, and racial groups (such as the Roma and Jews in Nazi Germany) as "degenerate" or "unfit", and therefore led to segregation, institutionalization, sterilization, euthanasia, and even mass murder. The Nazi practice of euthanasia was carried out on hospital patients in the Aktion T4 centers such as Hartheim Castle.

By the end of World War II, many discriminatory eugenics laws were abandoned, having become associated with Nazi Germany. H. G. Wells, who had called for "the sterilization of failures" in 1904, stated in his 1940 book "The Rights of Man: Or What are we fighting for?" that among the human rights, which he believed should be available to all people, was "a prohibition on mutilation, sterilization, torture, and any bodily punishment". After World War II, the practice of "imposing measures intended to prevent births within [a national, ethnical, racial or religious] group" fell within the definition of the new international crime of genocide, set out in the Convention on the Prevention and Punishment of the Crime of Genocide. The Charter of Fundamental Rights of the European Union also proclaims "the prohibition of eugenic practices, in particular those aiming at selection of persons". In spite of the decline in discriminatory eugenics laws, some government mandated sterilizations continued into the 21st century. During the ten years President Alberto Fujimori led Peru from 1990 to 2000, 2,000 persons were allegedly involuntarily sterilized. China maintained its one-child policy until 2015 as well as a suite of other eugenics based legislation to reduce population size and manage fertility rates of different populations. In 2007 the United Nations reported coercive sterilizations and hysterectomies in Uzbekistan. During the years 2005 to 2013, nearly one-third of the 144 California prison inmates who were sterilized did not give lawful consent to the operation.

Developments in genetic, genomic, and reproductive technologies at the end of the 20th century are raising numerous questions regarding the ethical status of eugenics, effectively creating a resurgence of interest in the subject.
Some, such as UC Berkeley sociologist Troy Duster, claim that modern genetics is a back door to eugenics. This view is shared by White House Assistant Director for Forensic Sciences, Tania Simoncelli, who stated in a 2003 publication by the Population and Development Program at Hampshire College that advances in pre-implantation genetic diagnosis (PGD) are moving society to a "new era of eugenics", and that, unlike the Nazi eugenics, modern eugenics is consumer driven and market based, "where children are increasingly regarded as made-to-order consumer products". In a 2006 newspaper article, Richard Dawkins said that discussion regarding eugenics was inhibited by the shadow of Nazi misuse, to the extent that some scientists would not admit that breeding humans for certain abilities is at all possible. He believes that it is not physically different from breeding domestic animals for traits such as speed or herding skill. Dawkins felt that enough time had elapsed to at least ask just what the ethical differences were between breeding for ability versus training athletes or forcing children to take music lessons, though he could think of persuasive reasons to draw the distinction.

Lee Kuan Yew, the Founding Father of Singapore, started promoting eugenics as early as 1983.

In October 2015, the United Nations' International Bioethics Committee wrote that the ethical problems of human genetic engineering should not be confused with the ethical problems of the 20th century eugenics movements. However, it is still problematic because it challenges the idea of human equality and opens up new forms of discrimination and stigmatization for those who do not want, or cannot afford, the technology.

Transhumanism is often associated with eugenics, although most transhumanists holding similar views nonetheless distance themselves from the term "eugenics" (preferring "germinal choice" or "reprogenetics") to avoid having their position confused with the discredited theories and practices of early-20th-century eugenic movements.

Prenatal screening can be considered a form of contemporary eugenics because it may lead to preventing the birth of a child with undesirable traits.

The term eugenics and its modern field of study were first formulated by Francis Galton in 1883, drawing on the recent work of his half-cousin Charles Darwin. Galton published his observations and conclusions in his book "Inquiries into Human Faculty and Its Development".

The origins of the concept began with certain interpretations of Mendelian inheritance and the theories of August Weismann. The word "eugenics" is derived from the Greek word "eu" ("good" or "well") and the suffix "-genēs" ("born"), and was coined by Galton in 1883 to replace the word "stirpiculture", which he had used previously but which had come to be mocked due to its perceived sexual overtones. Galton defined eugenics as "the study of all agencies under human control which can improve or impair the racial quality of future generations".

Historically, the term eugenics has referred to everything from prenatal care for mothers to forced sterilization and euthanasia. To population geneticists, the term has included the avoidance of inbreeding without altering allele frequencies; for example, J. B. S. Haldane wrote that "the motor bus, by breaking up inbred village communities, was a powerful eugenic agent." Debate as to what exactly counts as eugenics continues today.

Edwin Black, journalist and author of "War Against the Weak", claims eugenics is often deemed a pseudoscience because what is defined as a genetic improvement of a desired trait is often deemed a cultural choice rather than a matter that can be determined through objective scientific inquiry. The most disputed aspect of eugenics has been the definition of "improvement" of the human gene pool, such as what is a beneficial characteristic and what is a defect. Historically, this aspect of eugenics was tainted with scientific racism and pseudoscience.

Early eugenists were mostly concerned with factors of perceived intelligence that often correlated strongly with social class. Some of these early eugenists include Karl Pearson and Walter Weldon, who worked on this at the University College London.

Eugenics also had a place in medicine. In his lecture "Darwinism, Medical Progress and Eugenics", Karl Pearson said that everything concerning eugenics fell into the field of medicine. He basically placed the two words as equivalents. He was supported in part by the fact that Francis Galton, the father of eugenics, also had medical training.

Eugenic policies have been conceptually divided into two categories. Positive eugenics is aimed at encouraging reproduction among the genetically advantaged; for example, the reproduction of the intelligent, the healthy, and the successful. Possible approaches include financial and political stimuli, targeted demographic analyses, "in vitro" fertilization, egg transplants, and cloning. The movie Gattaca provides a fictional example of a dystopian society that uses eugenics to decided what you are capable of and your place in the world. Negative eugenics aimed to eliminate, through sterilization or segregation, those deemed physically, mentally, or morally "undesirable". This includes abortions, sterilization, and other methods of family planning. Both positive and negative eugenics can be coercive; abortion for fit women, for example, was illegal in Nazi Germany.

Jon Entine claims that eugenics simply means "good genes" and using it as synonym for genocide is an "all-too-common distortion of the social history of genetics policy in the United States." According to Entine, eugenics developed out of the Progressive Era and not "Hitler's twisted Final Solution".

According to Richard Lynn, eugenics may be divided into two main categories based on the ways in which the methods of eugenics can be applied.

The first major challenge to conventional eugenics based upon genetic inheritance was made in 1915 by Thomas Hunt Morgan. He demonstrated the event of genetic mutation occurring outside of inheritance involving the discovery of the hatching of a fruit fly ("Drosophila melanogaster") with white eyes from a family with red-eyes. Morgan claimed that this demonstrated that major genetic changes occurred outside of inheritance and that the concept of eugenics based upon genetic inheritance was not completely scientifically accurate. Additionally, Morgan criticized the view that subjective traits, such as intelligence and criminality, were caused by heredity because he believed that the definitions of these traits varied and that accurate work in genetics could only be done when the traits being studied were accurately defined. Despite Morgan's public rejection of eugenics, much of his genetic research was absorbed by eugenics.

The heterozygote test is used for the early detection of recessive hereditary diseases, allowing for couples to determine if they are at risk of passing genetic defects to a future child. The goal of the test is to estimate the likelihood of passing the hereditary disease to future descendants.

Recessive traits can be severely reduced, but never eliminated unless the complete genetic makeup of all members of the pool was known, as aforementioned. As only very few undesirable traits, such as Huntington's disease, are dominant, it could be argued from certain perspectives that the practicality of "eliminating" traits is quite low.

There are examples of eugenic acts that managed to lower the prevalence of recessive diseases, although not influencing the prevalence of heterozygote carriers of those diseases. The elevated prevalence of certain genetically transmitted diseases among the Ashkenazi Jewish population (Tay–Sachs, cystic fibrosis, Canavan's disease, and Gaucher's disease), has been decreased in current populations by the application of genetic screening.

Pleiotropy occurs when one gene influences multiple, seemingly unrelated phenotypic traits, an example being phenylketonuria, which is a human disease that affects multiple systems but is caused by one gene defect. Andrzej Pękalski, from the University of Wrocław, argues that eugenics can cause harmful loss of genetic diversity if a eugenics program selects a pleiotropic gene that could possibly be associated with a positive trait. Pekalski uses the example of a coercive government eugenics program that prohibits people with myopia from breeding but has the unintended consequence of also selecting against high intelligence since the two go together.

Eugenic policies could also lead to loss of genetic diversity, in which case a culturally accepted "improvement" of the gene pool could very likely—as evidenced in numerous instances in isolated island populations —result in extinction due to increased vulnerability to disease, reduced ability to adapt to environmental change, and other factors both known and unknown. A long-term, species-wide eugenics plan might lead to a scenario similar to this because the elimination of traits deemed undesirable would reduce genetic diversity by definition.

Edward M. Miller claims that, in any one generation, any realistic program should make only minor changes in a fraction of the gene pool, giving plenty of time to reverse direction if unintended consequences emerge, reducing the likelihood of the elimination of desirable genes. Miller also argues that any appreciable reduction in diversity is so far in the future that little concern is needed for now.

While the science of genetics has increasingly provided means by which certain characteristics and conditions can be identified and understood, given the complexity of human genetics, culture, and psychology, at this point no agreed objective means of determining which traits might be ultimately desirable or undesirable. Some diseases such as sickle-cell disease and cystic fibrosis respectively confer immunity to malaria and resistance to cholera when a single copy of the recessive allele is contained within the genotype of the individual. Reducing the instance of sickle-cell disease genes in Africa where malaria is a common and deadly disease could indeed have extremely negative net consequences.

However, some genetic diseases cause people to consider some elements of eugenics.

Societal and political consequences of eugenics call for a place in the discussion on the ethics behind the eugenics movement. Many of the ethical concerns regarding eugenics arise from its controversial past, prompting a discussion on what place, if any, it should have in the future. Advances in science have changed eugenics. In the past, eugenics had more to do with sterilization and enforced reproduction laws. Now, in the age of a progressively mapped genome, embryos can be tested for susceptibility to disease, gender, and genetic defects, and alternative methods of reproduction such as in vitro fertilization are becoming more common. Therefore, eugenics is no longer "ex post facto" regulation of the living but instead preemptive action on the unborn.

With this change, however, there are ethical concerns which lack adequate attention, and which must be addressed before eugenic policies can be properly implemented in the future. Sterilized individuals, for example, could volunteer for the procedure, albeit under incentive or duress, or at least voice their opinion. The unborn fetus on which these new eugenic procedures are performed cannot speak out, as the fetus lacks the voice to consent or to express his or her opinion. Philosophers disagree about the proper framework for reasoning about such actions, which change the very identity and existence of future persons.

A common criticism of eugenics is that "it inevitably leads to measures that are unethical". Some fear future "eugenics wars" as the worst-case scenario: the return of coercive state-sponsored genetic discrimination and human rights violations such as compulsory sterilization of persons with genetic defects, the killing of the institutionalized and, specifically, segregation and genocide of "races"" "perceived as inferior. Health law professor George Annas and technology law professor Lori Andrews are prominent advocates of the position that the use of these technologies could lead to such human-posthuman caste warfare.

In his 2003 book "Enough: Staying Human in an Engineered Age", environmental ethicist Bill McKibben argued at length against germinal choice technology and other advanced biotechnological strategies for human enhancement. He writes that it would be morally wrong for humans to tamper with fundamental aspects of themselves (or their children) in an attempt to overcome universal human limitations, such as vulnerability to aging, maximum life span and biological constraints on physical and cognitive ability. Attempts to "improve" themselves through such manipulation would remove limitations that provide a necessary context for the experience of meaningful human choice. He claims that human lives would no longer seem meaningful in a world where such limitations could be overcome with technology. Even the goal of using germinal choice technology for clearly therapeutic purposes should be relinquished, since it would inevitably produce temptations to tamper with such things as cognitive capacities. He argues that it is possible for societies to benefit from renouncing particular technologies, using as examples Ming China, Tokugawa Japan and the contemporary Amish.

Some, for example Nathaniel C. Comfort from Johns Hopkins University, claim that the change from state-led reproductive-genetic decision-making to individual choice has moderated the worst abuses of eugenics by transferring the decision-making from the state to the patient and their family. Comfort suggests that "the eugenic impulse drives us to eliminate disease, live longer and healthier, with greater intelligence, and a better adjustment to the conditions of society; and the health benefits, the intellectual thrill and the profits of genetic bio-medicine are too great for us to do otherwise." Others, such as bioethicist Stephen Wilkinson of Keele University and Honorary Research Fellow Eve Garrard at the University of Manchester, claim that some aspects of modern genetics can be classified as eugenics, but that this classification does not inherently make modern genetics immoral. In a co-authored publication by Keele University, they stated that "[e]ugenics doesn't seem always to be immoral, and so the fact that PGD, and other forms of selective reproduction, might sometimes technically be eugenic, isn't sufficient to show that they're wrong."

In their book published in 2000, "From Chance to Choice: Genetics and Justice", bioethicists Allen Buchanan, Dan Brock, Norman Daniels and Daniel Wikler argued that liberal societies have an obligation to encourage as wide an adoption of eugenic enhancement technologies as possible (so long as such policies do not infringe on individuals' reproductive rights or exert undue pressures on prospective parents to use these technologies) in order to maximize public health and minimize the inequalities that may result from both natural genetic endowments and unequal access to genetic enhancements.

Original position, a hypothetical situation developed by American philosopher John Rawls, has been used as an argument for "negative eugenics".

Notes
Bibliography




Further reading



</doc>
<doc id="9738" url="https://en.wikipedia.org/wiki?curid=9738" title="Email">
Email

Electronic Mail (email or e-mail) is a method of exchanging messages ("mail") between people using electronic devices. Email first entered limited use in the 1960s and by the mid-1970s had taken the form now recognized as email. Email operates across computer networks, which today is primarily the Internet. Some early email systems required the author and the recipient to both be online at the same time, in common with instant messaging. Today's email systems are based on a store-and-forward model. Email servers accept, forward, deliver, and store messages. Neither the users nor their computers are required to be online simultaneously; they need to connect only briefly, typically to a mail server or a webmail interface, for as long as it takes to send or receive messages.

Originally an ASCII text-only communications medium, Internet email was extended by Multipurpose Internet Mail Extensions (MIME) to carry text in other character sets and multimedia content attachments. International email, with internationalized email addresses using UTF-8, has been standardized, but as of 2017 it has not been widely adopted.

The history of modern Internet email services reaches back to the early ARPANET, with standards for encoding email messages published as early as 1973 (RFC 561). An email message sent in the early 1970s looks very similar to a basic email sent today. Email had an important role in creating the Internet, and the conversion from ARPANET to the Internet in the early 1980s produced the core of the current services.

Historically, the term "electronic mail" was used generically for any electronic document transmission. For example, several writers in the early 1970s used the term to describe fax document transmission. As a result, it is difficult to find the first citation for the use of the term with the more specific meaning it has today.

Electronic mail has been most commonly called "email" or "e-mail" since around 1993, but variations of the spelling have been used:


An Internet e-mail consists of an envelope and content; the content in turn consists of a header and a body.

Computer-based mail and messaging became possible with the advent of time-sharing computers in the early 1960s, and informal methods of using shared files to pass messages were soon expanded into the first mail systems. Most developers of early mainframes and minicomputers developed similar, but generally incompatible, mail applications. Over time, a complex web of gateways and routing systems linked many of them. Many US universities were part of the ARPANET (created in the late-1960s), which aimed at software portability between its systems. That portability helped make the Simple Mail Transfer Protocol (SMTP) increasingly influential.

For a time in the late 1980s and early 1990s, it seemed likely that either a proprietary commercial system or the X.400 email system, part of the Government Open Systems Interconnection Profile (GOSIP), would predominate. However, once the final restrictions on carrying commercial traffic over the Internet ended in 1995, a combination of factors made the current Internet suite of SMTP, POP3 and IMAP email protocols the standard.

The diagram to the right shows a typical sequence of events that takes place when sender Alice transmits a message using a mail user agent (MUA) addressed to the email address of the recipient.

In addition to this example, alternatives and complications exist in the email system:

Many MTAs used to accept messages for any recipient on the Internet and do their best to deliver them. Such MTAs are called "open mail relays". This was very important in the early days of the Internet when network connections were unreliable. However, this mechanism proved to be exploitable by originators of unsolicited bulk email and as a consequence open mail relays have become rare, and many MTAs do not accept messages from open mail relays.

The Internet email message format is now defined by RFC 5322, with encoding of non-ASCII data and multimedia content attachments being defined in RFC 2045 through RFC 2049, collectively called "Multipurpose Internet Mail Extensions" or "MIME". RFC 5322 replaced the earlier RFC 2822 in 2008, and in turn RFC 2822 in 2001 replaced RFC 822 – which had been the standard for Internet email for nearly 20 years. Published in 1982, RFC 822 was based on the earlier RFC 733 for the ARPANET.

Internet email messages consist of two major sections, the message header and the message body, collectively known as content. 
The header is structured into fields such as From, To, CC, Subject, Date, and other information about the email. In the process of transporting email messages between systems, SMTP communicates delivery parameters and information using message header fields. The body contains the message, as unstructured text, sometimes containing a signature block at the end. The header is separated from the body by a blank line.

Each message has exactly one header, which is structured into fields. Each field has a name and a value. RFC 5322 specifies the precise syntax.

Informally, each line of text in the header that begins with a printable character begins a separate field. The field name starts in the first character of the line and ends before the separator character ":". The separator is then followed by the field value (the "body" of the field). The value is continued onto subsequent lines if those lines have a space or tab as their first character. Field names and values are restricted to 7-bit ASCII characters. Some non-ASCII values may be represented using MIME encoded words.

Email header fields can be multi-line, and each line should be at most 78 characters long and in no event more than 998 characters long. Header fields defined by RFC 5322 can only contain US-ASCII characters; for encoding characters in other sets, a syntax specified in RFC 2047 can be used. Recently the IETF EAI working group has defined some standards track extensions, replacing previous experimental extensions, to allow UTF-8 encoded Unicode characters to be used within the header. In particular, this allows email addresses to use non-ASCII characters. Such addresses are supported by Google and Microsoft products, and promoted by some governments.

The message header must include at least the following fields:

RFC 3864 describes registration procedures for message header fields at the IANA; it provides for permanent and provisional field names, including also fields defined for MIME, netnews, and HTTP, and referencing relevant RFCs. Common header fields for email include:


Note that the "To:" field is not necessarily related to the addresses to which the message is delivered. The actual delivery list is supplied separately to the transport protocol, SMTP, which may or may not originally have been extracted from the header content. The "To:" field is similar to the addressing at the top of a conventional letter which is delivered according to the address on the outer envelope. In the same way, the "From:" field does not have to be the real sender of the email message. Some mail servers apply email authentication systems to messages being relayed. Data pertaining to server's activity is also part of the header, as defined below.

SMTP defines the "trace information" of a message, which is also saved in the header using the following two fields:

Other fields that are added on top of the header by the receiving server may be called "trace fields", in a broader sense.

Internet email was originally designed for 7-bit ASCII. Most email software is 8-bit clean but must assume it will communicate with 7-bit servers and mail readers. The MIME standard introduced character set specifiers and two content transfer encodings to enable transmission of non-ASCII data: quoted printable for mostly 7-bit content with a few characters outside that range and base64 for arbitrary binary data. The 8BITMIME and BINARY extensions were introduced to allow transmission of mail without the need for these encodings, but many mail transport agents still do not support them fully. In some countries, several encoding schemes coexist; as the result, by default, the message in a non-Latin alphabet language appears in non-readable form (the only exception is coincidence, when the sender and receiver use the same encoding scheme). Therefore, for international character sets, Unicode is growing in popularity.

Most modern graphic email clients allow the use of either plain text or HTML for the message body at the option of the user. HTML email messages often include an automatically generated plain text copy as well, for compatibility reasons. Advantages of HTML include the ability to include in-line links and images, set apart previous messages in block quotes, wrap naturally on any display, use emphasis such as underlines and italics, and change font styles. Disadvantages include the increased size of the email, privacy concerns about web bugs, abuse of HTML email as a vector for phishing attacks and the spread of malicious software.

Some web-based mailing lists recommend that all posts be made in plain-text, with 72 or 80 characters per line for all the above reasons, but also because they have a significant number of readers using text-based email clients such as Mutt. Some Microsoft email clients allow rich formatting using their proprietary Rich Text Format (RTF), but this should be avoided unless the recipient is guaranteed to have a compatible email client.

Messages are exchanged between hosts using the Simple Mail Transfer Protocol with software programs called mail transfer agents (MTAs); and delivered to a mail store by programs called mail delivery agents (MDAs, also sometimes called local delivery agents, LDAs). Accepting a message obliges an MTA to deliver it, and when a message cannot be delivered, that MTA must send a bounce message back to the sender, indicating the problem.

Users can retrieve their messages from servers using standard protocols such as POP or IMAP, or, as is more likely in a large corporate environment, with a proprietary protocol specific to Novell Groupwise, Lotus Notes or Microsoft Exchange Servers. Programs used by users for retrieving, reading, and managing email are called mail user agents (MUAs).

Mail can be stored on the client, on the server side, or in both places. Standard formats for mailboxes include Maildir and mbox. Several prominent email clients use their own proprietary format and require conversion software to transfer email between them. Server-side storage is often in a proprietary format but since access is through a standard protocol such as IMAP, moving email from one server to another can be done with any MUA supporting the protocol.

Many current email users do not run MTA, MDA or MUA programs themselves, but use a web-based email platform, such as Gmail, Hotmail, or Yahoo! Mail, that performs the same tasks. Such webmail interfaces allow users to access their mail with any standard web browser, from any computer, rather than relying on an email client.

Upon reception of email messages, email client applications save messages in operating system files in the file system. Some clients save individual messages as separate files, while others use various database formats, often proprietary, for collective storage. A historical standard of storage is the "mbox" format. The specific format used is often indicated by special filename extensions:

Some applications (like Apple Mail) leave attachments encoded in messages for searching while also saving separate copies of the attachments. Others separate attachments from messages and save them in a specific directory.

The URI scheme, as registered with the IANA, defines the mailto: scheme for SMTP email addresses. Though its use is not strictly defined, URLs of this form are intended to be used to open the new message window of the user's mail client when the URL is activated, with the address as defined by the URL in the "To:" field.

Many email providers have a web-based email client (e.g. AOL Mail, Gmail, Outlook.com, Hotmail and Yahoo! Mail). This allows users to log into the email account by using any compatible web browser to send and receive their email. Mail is typically not downloaded to the client, so can't be read without a current Internet connection.

The Post Office Protocol 3 (POP3) is a mail access protocol used by a client application to read messages from the mail server. Received messages are often deleted from the server. POP supports simple download-and-delete requirements for access to remote mailboxes (termed maildrop in the POP RFC's).

The Internet Message Access Protocol (IMAP) provides features to manage a mailbox from multiple devices. Small portable devices like smartphones are increasingly used to check email while travelling, and to make brief replies, larger devices with better keyboard access being used to reply at greater length. IMAP shows the headers of messages, the sender and the subject and the device needs to request to download specific messages. Usually mail is left in folders in the mail server.

Messaging Application Programming Interface (MAPI) is used by Microsoft Outlook to communicate to Microsoft Exchange Server - and to a range of other email server products such as Axigen Mail Server, Kerio Connect, Scalix, Zimbra, HP OpenMail, IBM Lotus Notes, Zarafa, and Bynari where vendors have added MAPI support to allow their products to be accessed directly via Outlook.

Email has been widely accepted by business, governments and non-governmental organizations in the developed world, and it is one of the key parts of an 'e-revolution' in workplace communication (with the other key plank being widespread adoption of highspeed Internet). A sponsored 2010 study on workplace communication found 83% of U.S. knowledge workers felt email was critical to their success and productivity at work.

It has some key benefits to business and other organizations, including:

Email marketing via "opt-in" is often successfully used to send special sales offerings and new product information. Depending on the recipient's culture, email sent without permission—such as an "opt-in"—is likely to be viewed as unwelcome "email spam".

Many users access their personal email from friends and family members using a personal computer in their house or apartment.

Email has become used on smartphones and on all types of computers. Mobile "apps" for email increase accessibility to the medium for users who are out of their home. While in the earliest years of email, users could only access email on desktop computers, in the 2010s, it is possible for users to check their email when they are away from home, whether they are across town or across the world. Alerts can also be sent to the smartphone or other device to notify them immediately of new messages. This has given email the ability to be used for more frequent communication between users and allowed them to check their email and write messages throughout the day. , there were approximately 1.4 billion email users worldwide and 50 billion non-spam emails that were sent daily.

Individuals often check email on smartphones for both personal and work-related messages. It was found that US adults check their email more than they browse the web or check their Facebook accounts, making email the most popular activity for users to do on their smartphones. 78% of the respondents in the study revealed that they check their email on their phone. It was also found that 30% of consumers use only their smartphone to check their email, and 91% were likely to check their email at least once per day on their smartphone. However, the percentage of consumers using email on smartphone ranges and differs dramatically across different countries. For example, in comparison to 75% of those consumers in the US who used it, only 17% in India did.

As of 2010, the number of Americans visiting email web sites had fallen 6 percent after peaking in November 2009. For persons 12 to 17, the number was down 18 percent. Young people preferred instant messaging, texting and social media, and email was not designed for them anyway. Technology writer Matt Richtel said in "The New York Times" that email was like the VCR, vinyl records and film cameras--no longer cool and something older people do.

A 2015 survey of Android users showed that persons 13 to 24 used messaging apps 3.5 times as much as those over 45, and were far less likely to use email.

Email messages may have one or more attachments, which are additional files that are appended to the email. Typical attachments include Microsoft Word documents, pdf documents and scanned images of paper documents. In principle there is no technical restriction on the size or number of attachments, but in practice email clients, servers and Internet service providers implement various limitations on the size of files, or complete email - typically to 25MB or less. Furthermore, due to technical reasons, attachment sizes as seen by these transport systems can differ to what the user sees, which can be confusing to senders when trying to assess whether they can safely send a file by email. Where larger files need to be shared, file hosting services of various sorts are available; and generally suggested. Some large files, such as digital photos, color presentations and video or music files are too large for some email systems.

The ubiquity of email for knowledge workers and "white collar" employees has led to concerns that recipients face an "information overload" in dealing with increasing volumes of email. With the growth in mobile devices, by default employees may also receive work-related emails outside of their working day. This can lead to increased stress, decreased satisfaction with work, and some observers even argue it could have a significant negative economic effect, as efforts to read the many emails could reduce productivity.

Email "spam" is the term used to describe unsolicited bulk email. The low cost of sending such email meant that by 2003 up to 30% of total email traffic was already spam. and was threatening the usefulness of email as a practical tool. The US CAN-SPAM Act of 2003 and similar laws elsewhere had some impact, and a number of effective anti-spam techniques now largely mitigate the impact of spam by filtering or rejecting it for most users, but the volume sent is still very high—and increasingly consists not of advertisements for products, but malicious content or links.

A range of malicious email types exist. These range from various types of email scams, including "social engineering" scams such as advance-fee scam "Nigerian letters", to phishing, email bombardment and email worms.

Email spoofing occurs when the email message header is designed to make the message appear to come from a known or trusted source. Email spam and phishing methods typically use spoofing to mislead the recipient about the true message origin. Email spoofing may be done as a prank, or as part of a criminal effort to defraud an individual or organization. An example of a potentially fraudulent email spoofing is if an individual creates an email which appears to be an invoice from a major company, and then sends it to one or more recipients. In some cases, these fraudulent emails incorporate the logo of the purported organization and even the email address may appear legitimate.

Email bombing is the intentional sending of large volumes of messages to a target address. The overloading of the target email address can render it unusable and can even cause the mail server to crash.

Today it can be important to distinguish between Internet and internal email systems. Internet email may travel and be stored on networks and computers without the sender's or the recipient's control. During the transit time it is possible that third parties read or even modify the content. Internal mail systems, in which the information never leaves the organizational network, may be more secure, although information technology personnel and others whose function may involve monitoring or managing may be accessing the email of other employees.

Email privacy, without some security precautions, can be compromised because:

There are cryptography applications that can serve as a remedy to one or more of the above. For example, Virtual Private Networks or the Tor anonymity network can be used to encrypt traffic from the user machine to a safer network while GPG, PGP, SMEmail, or S/MIME can be used for end-to-end message encryption, and SMTP STARTTLS or SMTP over Transport Layer Security/Secure Sockets Layer can be used to encrypt communications for a single mail hop between the SMTP client and the SMTP server.

Additionally, many mail user agents do not protect logins and passwords, making them easy to intercept by an attacker. Encrypted authentication schemes such as SASL prevent this. Finally, attached files share many of the same hazards as those found in peer-to-peer filesharing. Attached files may contain trojans or viruses.

Flaming occurs when a person sends a message (or many messages) with angry or antagonistic content. The term is derived from the use of the word "incendiary" to describe particularly heated email discussions. The ease and impersonality of email communications mean that the social norms that encourage civility in person or via telephone do not exist and civility may be forgotten.

Also known as "email fatigue", email bankruptcy is when a user ignores a large number of email messages after falling behind in reading and answering them. The reason for falling behind is often due to information overload and a general sense there is so much information that it is not possible to read it all. As a solution, people occasionally send a "boilerplate" message explaining that their email inbox is full, and that they are in the process of clearing out all the messages. Harvard University law professor Lawrence Lessig is credited with coining this term, but he may only have popularized it.

Originally Internet email was completely ASCII text-based. MIME now allows body content text and some header content text in international character sets, but other headers and email addresses using UTF-8, while standardized have yet to be widely adopted.
The original SMTP mail service provides limited mechanisms for tracking a transmitted message, and none for verifying that it has been delivered or read. It requires that each mail server must either deliver it onward or return a failure notice (bounce message), but both software bugs and system failures can cause messages to be lost. To remedy this, the IETF introduced Delivery Status Notifications (delivery receipts) and Message Disposition Notifications (return receipts); however, these are not universally deployed in production. (A complete Message Tracking mechanism was also defined, but it never gained traction; see RFCs 3885 through 3888.)

Many ISPs now deliberately disable non-delivery reports (NDRs) and delivery receipts due to the activities of spammers:

In the absence of standard methods, a range of system based around the use of web bugs have been developed. However, these are often seen as underhand or raising privacy concerns, and only work with email clients that support rendering of HTML. Many mail clients now default to not showing "web content". Webmail providers can also disrupt web bugs by pre-caching images.



</doc>
<doc id="9739" url="https://en.wikipedia.org/wiki?curid=9739" title="Emoticon">
Emoticon

An emoticon (, , rarely pronounced ) is a pictorial representation of a facial expression using characters—usually punctuation marks, numbers, and letters—to express a person's feelings or mood, or as a time-saving method. The first ASCII emoticons, codice_1 and codice_2, were written by Scott Fahlman in 1982, but emoticons actually originated on the PLATO IV computer system in 1972.

In Western countries, emoticons are usually written at a right angle to the direction of the text. Users from Japan popularized a kind of emoticon called kaomoji (; lit. 顔(kao)=face, 文字(moji)=character(s)) that can be understood without tilting one's head to the left. This style arose on ASCII NET of Japan in 1986.

As SMS and the internet became widespread in the late 1990s, emoticons became increasingly popular and were commonly used on text messages, internet forums and e-mails. Emoticons have played a significant role in communication through technology, and some devices and applications have provided stylized pictures that do not use text punctuation. They offer another range of "tone" and feeling through texting that portrays specific emotions through facial gestures while in the midst of text-based cyber communication.

The word is a portmanteau word of the English words "emotion" and "icon". In web forums, instant messengers and online games, text emoticons are often automatically replaced with small corresponding images, which came to be called "emoticons" as well. Emoticons for a smiley face codice_1 and sad face codice_2 appear in the first documented use in digital form. Certain complex character combinations can only be accomplished in double-byte languages, giving rise to especially complex forms, sometimes known by their romanized Japanese name of kaomoji.

The use of emoticons can be traced back to the 17th century, drawn by a Slovak notary to indicate his satisfaction with the state of his town's municipal financial records in 1635, but they were commonly used in casual and humorous writing. Digital forms of emoticons on the Internet were included in a proposal by Scott Fahlman of Carnegie Mellon University in Pittsburgh, Pennsylvania, in a message on 19 September 1982.

The "National Telegraphic Review and Operators Guide" in April 1857 documented the use of the number 73 in Morse code to express "love and kisses" (later reduced to the more formal "best regards"). "Dodge's Manual" in 1908 documented the reintroduction of "love and kisses" as the number 88. Gajadhar and Green comment that both Morse code abbreviations are more succinct than modern abbreviations such as LOL.
A "New York Times" transcript from an Abraham Lincoln speech written in 1862 contains "codice_5"; there is some debate whether it is a typo, a legitimate punctuation construct, or an emoticon.
Four vertical typographical emoticons were published in 1881 by the U.S. satirical magazine "Puck", with the stated intention that the publication's letterpress department thus intended to "lay out [...] all the cartoonists that ever walked."

In 1912, Ambrose Bierce proposed "an improvement in punctuation – the snigger point, or note of cachinnation: it is written thus ‿ and presents a smiling mouth. It is to be appended, with the full stop, to every jocular or ironical sentence".

In a 1936 "Harvard Lampoon" article, Alan Gregg proposed (-) for smile, (--) for laugh (more teeth showing), (#) for frown, (*) for wink, and (#) for "intense interest, attention, and incredulity". Note that the symbols are correctly oriented and are not sideways.

Emoticons had already come into use in sci-fi fandom in the 1940s, although there seems to have been a lapse in cultural continuity between the communities.

The September 1962 issue of "MAD" magazine included an article titled "Typewri-toons." The piece, featuring typewriter-generated artwork credited to "Royal Portable," was entirely made up of repurposed typography, including a capital letter P having a bigger bust than a capital I, a lowercase b and d discussing their pregnancies, an asterisk on top of a letter to indicate the letter had just come inside from a snowfall, and a classroom of lowercase n's interrupted by a lowercase h "raising its hand." Two additional "Typewri-toons" articles subsequently appeared in "Mad", in 1965 and 1987.

In 1963, the "smiley face", a yellow button with two black dots representing eyes and an upturned thick curve representing a mouth was created by freelance artist Harvey Ball. It was realized on order of a large insurance company as part of a campaign to bolster the morale of its employees and soon became a big hit. This smiley presumably inspired many later emoticons; the most basic graphic emoticon that depicts this is, in fact, a small yellow smiley face.

In a "New York Times" interview in April 1969, Alden Whitman asked writer Vladimir Nabokov: "How do you rank yourself among writers (living) and of the immediate past?" Nabokov answered: "I often think there should exist a special typographical sign for a smile – some sort of concave mark, a supine round bracket, which I would now like to trace in reply to your question."

In 1971, a French journalist, Franklin Loufrani, created a smiley logo to mark good news in the French newspaper "France Soir". Loufrani was the first person to trademark the symbol, in 1972. Later, in 1996, Loufrani established The Smiley Company with his son, Nicolas Loufrani. Nicolas developed hundreds of different emoticons, including 3D versions. His designs were registered at the United States Copyright Office in 1997 and appeared online as .gif files in 1998. These were the first graphical representations of the originally text-based emoticon. He published his icons as well as emoticons created by others, along with their ASCII versions, in an online Smiley Dictionary in the early 2000s. This dictionary included over 3,000 different Smileys and was published as a book called "Dico Smileys" in 2002. The Smiley Company has trademarked its version of the smiley face in over 100 countries. In 1997, The Smiley Company filed a trademark application with the United States Patent and Trademark Office. In 2001, Walmart opposed the registration, citing a likelihood of confusion between the Loufrani smiley and a smiley face Walmart had been using since 1990. The USPTO eventually sided with Walmart and rejected The Smiley Company's application, due to the widespread use of smiley face designs. Seeking to prevent Walmart from using any smiley face design, Nicolas Loufrani next sued Walmart in federal court in 2009, while claiming that his smiley face was "readily distinguishable" from Walmart's. The case was closed in 2011 when the two parties agreed to settle out of court. The terms of the settlement were undisclosed, but Walmart continued to use its smiley design intermittently and returned to using it in a major marketing role in 2016.

Starting circa 1972, on the PLATO system, emoticons and other decorative graphics were produced as ASCII art, particularly with overprinting: typing a character, backing up, then typing another character. For example, WOBTAX and VICTORY both produced convincing smiley faces (where the overprinted characters produced the solid background, and pixels untouched by any of the characters produced the actual design). This developed into a sophisticated set, particularly in combination with superscript and subscript.

Scott Fahlman was the first documented person to use the emoticons codice_1 and codice_2, with a specific suggestion that they be used to express emotion. The text of his original proposal, posted to the Carnegie Mellon University computer science general board on 19 September 1982 (11:44), was thought to have been lost, but was recovered 20 years later by Jeff Baird from old backup tapes.

Other notable computer scientists who participated in this thread include David Touretzky, Guy Steele, and Jaime Carbonell.

Within a few months, it had spread to the ARPANET and Usenet. Many variations on the theme were immediately suggested by Scott and others.

Usually, emoticons in Western style have the eyes on the left, followed by nose and the mouth. The two character version codice_8 which omits the nose is also very popular.

The most basic emoticons are relatively consistent in form, but each of them can be transformed by being rotated (making them tiny ambigrams), with or without a hyphen (nose).
There are also some possible variations to emoticons to get new definitions, like changing a character to express a new feeling, or slightly change the mood of the emoticon. For example, codice_9 equals sad and codice_10 equals very sad. Weeping can be written as codice_11. A blush can be expressed as codice_12. Others include wink codice_13, a grin codice_14, smug codice_15, and tongue out codice_16, such as when blowing a raspberry. An often used combination is also codice_17 for a heart, and codice_18 for a broken heart. codice_19 is also sometimes used to depict shock.

A broad grin is sometimes shown with crinkled eyes to express further amusement; codice_20 and the addition of further "D" letters can suggest laughter or extreme amusement e.g. codice_21. There are hundreds of other variations including codice_22 for anger, or codice_23 for an evil grin, which can be, again, used in reverse, for an unhappy angry face, in the shape of codice_24. codice_25 for vampire teeth, codice_26 for grimace, and codice_27 can be used to denote a flirting or joking tone, or may be implying a second meaning in the sentence preceding it.

As computers offer increasing built-in support for non-Western writing systems, it has become possible to use other glyphs to build emoticons. The 'shrug' emoticon, codice_28, uses the glyph ツ from the Japanese katakana writing system.

An equal sign is often used for the eyes in place of the colon, seen as codice_29, without changing the meaning of the emoticon. In these instances, the hyphen is almost always either omitted or, occasionally, replaced with an "o" as in codice_30 . In most circles it has become acceptable to omit the hyphen, whether a colon or an equal sign is used for the eyes, but in some areas of usage people still prefer the larger, more traditional emoticon codice_1 or codice_32. One linguistic study has indicated that the use of a nose in an emoticon may be related to the user's age. Similar-looking characters are commonly substituted for one another: for instance, codice_33, codice_34, and codice_35 can all be used interchangeably, sometimes for subtly different effect or, in some cases, one type of character may look better in a certain font and therefore be preferred over another. It is also common for the user to replace the rounded brackets used for the mouth with other, similar brackets, such as codice_36 instead of codice_37.

Some variants are also more common in certain countries due to keyboard layouts. For example, the smiley codice_29 may occur in Scandinavia, where the keys for codice_39 and codice_37 are placed right beside each other. However, the codice_8 variant is without a doubt the dominant one in Scandinavia, making the codice_29 version a rarity. Diacritical marks are sometimes used. The letters codice_43 and codice_44 can be seen as an emoticon, as the upright version of codice_19 (meaning that one is surprised) and codice_14 (meaning that one is very happy) respectively.

Some emoticons may be read right to left instead, and in fact can only be written using standard ASCII keyboard characters this way round; for example codice_47 which refers to being shocked or anxious, opposite to the large grin of codice_14.

Users from Japan popularized a style of emoticons (, "kaomoji") that can be understood without tilting one's head to the left. This style arose on ASCII NET, an early Japanese online service, in 1986. Similar-looking emoticons were used on the Byte Information Exchange (BIX) around the same time.

These emoticons are usually found in a format similar to codice_49. The asterisks indicate the eyes; the central character, commonly an underscore, the mouth; and the parentheses, the outline of the face.

Different emotions can be expressed by changing the character representing the eyes: for example, "T" can be used to express crying or sadness: codice_50. codice_51 may also be used to mean "unimpressed". The emphasis on the eyes in this style is reflected in the common usage of emoticons that use only the eyes, e.g. codice_52. Looks of stress are represented by the likes of codice_53, while codice_54 is a generic emoticon for nervousness, the semicolon representing an anxiety-induced sweat drop (discussed further below). codice_55 can indicate embarrassment by symbolizing blushing. Characters like hyphens or periods can replace the underscore; the period is often used for a smaller, "cuter" mouth, or to represent a nose, e.g. codice_56. Alternatively, the mouth/nose can be left out entirely, e.g. codice_57.

Parentheses are sometimes replaced with braces or square brackets, e.g. codice_58 or codice_59. Many times, the parentheses are left out completely, e.g. codice_52,codice_61, codice_62, codice_63, codice_64, or codice_65. A quotation mark codice_66, apostrophe codice_67, or semicolon codice_68 can be added to the emoticon to imply apprehension or embarrassment, in the same way that a sweat drop is used in manga and anime.

Microsoft IME 2000 (Japanese) or later supports the input of emoticons like the above by enabling the Microsoft IME Spoken Language/Emotion Dictionary. In IME 2007, this support was moved to the Emoticons dictionary. Such dictionaries allow users to call up emoticons by typing words that represent them.

Communication software allowing the use of Shift JIS encoded Japanese characters rather than just ASCII allowed for the development of new kaomoji using the extended character set, such as codice_69 or codice_70.

Modern communication software generally utilizes Unicode, which allows for the incorporation of characters from other languages (e.g. from the Cyrillic alphabet), and a variety of symbols into the kaomoji, as in codice_71 or codice_72.

Further variations can be produced using Unicode combining characters, as in codice_73 or codice_74.

English-language anime forums adopted those Japanese-style emoticons that could be used with the standard ASCII characters available on Western keyboards. Because of this, they are often called "anime style" emoticons in English. They have since seen use in more mainstream venues, including online gaming, instant-messaging, and non-anime-related discussion forums. Emoticons such as codice_75, codice_76, codice_77, codice_78, codice_79, or codice_80 which include the parentheses, mouth or nose, and arms (especially those represented by the inequality signs < or >) also are often referred to as "" in reference to their likeness to Nintendo's video game character Kirby. The parentheses are sometimes dropped when used in the English language context, and the underscore of the mouth may be extended as an intensifier for the emoticon in question, e.g. codice_81 for very happy. The emoticon uses the Eastern style, but incorporates a depiction of the Western "middle-finger flick-off" using a "t" as the arm, hand, and finger. Another apparently Western invention is the use of emoticons like codice_82 or codice_83 to indicate vampires or other mythical beasts with fangs.

Exposure to both Western and Japanese style emoticons or kaomoji through blogs, instant messaging, and forums featuring a blend of Western and Japanese pop culture has given rise to many emoticons that have an upright viewing format. The parentheses are often dropped, and these emoticons typically only use alphanumeric characters and the most commonly used English punctuation marks. Emoticons such as codice_84, codice_85, codice_86, codice_87, codice_88, codice_51, codice_90, and codice_91 are used to convey mixed emotions that are more difficult to convey with traditional emoticons. Characters are sometimes added to emoticons to convey an anime- or manga-styled sweat drop, for example codice_92, codice_93, codice_94, codice_95, and codice_96. The equals sign can also be used for closed, anime-looking eyes, for example codice_97, codice_98, codice_99, codice_100, and codice_101.

In Brazil, sometimes combining characters (accents) are added to emoticons to represent eyebrows, as in codice_102, codice_103, codice_104, codice_105, or codice_106.

Users of the Japanese discussion board 2channel, in particular, have developed a wide variety of unique emoticons using characters from various languages, such as Kannada, as in codice_107 (for a look of disapproval, disbelief, or confusion). These were quickly picked up by 4chan and spread to other Western sites soon after. Some have taken on a life of their own and become characters in their own right, like Monā.

In South Korea, emoticons use Korean Hangul letters, and the Western style is rarely used. The structures of Korean and Japanese emoticons are somewhat similar, but they have some differences. Korean style contains Korean jamo (letters) instead of other characters. There are countless number of emoticons that can be formed with such combinations of Korean jamo letters. Consonant jamos : ㅅ or ㅁ or ㅂ as the mouth/nose component and ㅇ,ㅎ,ㅍ for the eyes. For example: codice_108, codice_109, codice_110 and codice_111. Faces such as codice_112, codice_113, codice_114 and codice_115, using quotation marks " and apostrophes ' are also commonly used combinations. Vowel jamos such as ㅜ,ㅠ depict a crying face. Example: codice_116, codice_117 and codice_118 (same function as T in western style). Sometimes ㅡ (not an em-dash "—" but a vowel jamo), a comma or an underscore is added, and the two character sets can be mixed together, as in codice_119, codice_120, codice_121, codice_122, codice_123 and codice_124. Also, semicolons and carets are commonly used in Korean emoticons; semicolons mean sweating (embarrassed). If they are used with ㅡ or - they depict a bad feeling. Examples: codice_125, codice_126, codice_127, codice_128 and codice_129. However, codice_130 means smile (almost all people use this without distinction of sex or age). Others include: codice_131, codice_132, codice_133, codice_134.

The character 囧 (U+56E7), which means "bright", is also used in the Chinese computing community for a frowning face. It is also combined with posture emoticon Orz, such as 囧rz. The character existed in Oracle bone script, but its use as emoticon was documented as early as January 20, 2005.

Other ideographic variants for 囧 include 崮 (king 囧), 莔 (queen 囧), 商 (囧 with hat), 囧興 (turtle), 卣 (Bomberman).

The character 槑 (U+69D1), which sounds like the word for "plum" (梅 (U+FA44)), is used to represent double of 呆 (dull), or further magnitude of dullness. In Chinese, normally full characters (as opposed to the stylistic use of 槑) may be duplicated to express emphasis.

Orz (other forms include: ) is an emoticon representing a kneeling or bowing person (the Japanese version of which is called "dogeza") with the "o" being the head, the "r" being the arms and part of the body, and the "z" being part of the body and the legs. This stick figure can represent failure and despair. It is also commonly used for representing a great admiration (sometimes with an overtone of sarcasm) for someone else's view or action.

It was first used in late 2002 at the forum on Techside, a Japanese personal website. At the "Techside FAQ Forum" (TECHSIDE教えて君BBS(教えてBBS) ), a poster asked about a cable cover, typing to show a cable and its cover. Others commented that it looked like a kneeling person, and the symbol became popular. These comments were soon deleted as they were considered off-topic. By 2005, Orz spawned a subculture: blogs have been devoted to the emoticon, and URL shortening services have been named after it. In Taiwan, Orz is associated with the phrase "nice guy"that is, the concept of males being rejected for a date by girls they are pursuing with a phrase like "You are a nice guy."

Orz should not be confused with which means "Thank you" or an apology.

A portmanteau of "emotion" and "sound", an emotisound is a brief sound transmitted and played back during the viewing of a message, typically an IM message or e-mail message. The sound is intended to communicate an emotional subtext. Many instant messaging clients automatically trigger sound effects in response to specific emoticons.

Some services, such as MuzIcons, combine emoticons and music player in an Adobe Flash-based widget.

In 2004, the Trillian chat application introduced a feature called "emotiblips", which allows Trillian users to stream files to their instant message recipients "as the voice and video equivalent of an emoticon".

In 2007, MTV and Paramount Home Entertainment promoted the "emoticlip" as a form of viral marketing for the second season of the show "The Hills". The emoticlips were twelve short snippets of dialogue from the show, uploaded to YouTube, which the advertisers hoped would be distributed between web users as a way of expressing feelings in a similar manner to emoticons. The emoticlip concept is credited to the Bradley & Montgomery advertising firm, which hopes they would be widely adopted as "greeting cards that just happen to be selling something".

In 2008, an emotion-sequence animation tool, called FunIcons was created. The Adobe Flash and Java-based application allows users to create a short animation. Users can then email or save their own animations to use them on similar social utility applications.

During the first half of the 2010s, there have been different forms of small audiovisual pieces to be sent through instant messaging systems to express one's emotion. These videos lack of a popular name yet and there are several ways to designate them: "emoticlips" (named above), "emotivideos" or more recently "emoticon videos". These are tiny little videos which can be easily transferred from one mobile phone to another or many other devices. The current video compression codecs (like H.264) allow these pieces of video to be light in terms of KB and very portable.

In 2000, Despair, Inc. obtained a U.S. trademark registration for the "frowny" emoticon codice_2 when used on "greeting cards, posters and art prints." In 2001, they issued a satirical press release, announcing that they would sue Internet users who typed the frowny; the joke backfired and the company received a storm of protest when its mock release was posted on technology news website Slashdot.

A number of patent applications have been filed on inventions that assist in communicating with emoticons. A few of these have been issued as US patents. , for example, discloses a method developed in 2001 to send emoticons over a cell phone using a drop-down menu. The stated advantage over the prior art was that the user saved on the number of keystrokes though this may not address the obviousness criteria.

The emoticon codice_1 was also filed in 2006 and registered in 2008 as a European Community Trademark (CTM). In Finland, the Supreme Administrative Court ruled in 2012 that the emoticon cannot be trademarked, thus repealing a 2006 administrative decision trademarking the emoticons codice_1, codice_29, codice_139, codice_8 and codice_9.

In 2005, a Russian court rejected a legal claim against Siemens by a man who claimed to hold a trademark on the codice_142 emoticon.

In 2008, Russian entrepreneur Oleg Teterin claimed to have been granted the trademark on the codice_142 emoticon. A license would not "cost that muchtens of thousands of dollars" for companies, but would be free of charge for individuals.

Some smiley faces were present in Unicode since 1.1.0, including a white frowning face, a white smiling face, and a black smiling face. ("Black" refers to a glyph which is filled, "white" refers to a glyph which is unfilled).

The Emoticons block was introduced in Unicode Standard version 6.0 (published in October 2010) and extended by 7.0. It covers Unicode range from U+1F600 to U+1F64F fully.
After that block had been filled, Unicode 8.0 (2015),9.0 (2016) and 10.0 (2017) added additional emoticons in the range from U+1F910 to U+1F9FF.Currently,U+1F90C to U+1F90F,U+1F93F,U+1F94D to U+1F94F,U+1F96C to U+1F97F,U+1F998 to U+1F9CF(excluding U+1F9C0 which contains an emoji representing cheese🧀) and 1F9E7 to 1F9FF does not contain any emoticons since Unicode 10.0 (2017).
For historic and compatibility reasons, some other heads and figures, which mostly represent different aspects like genders, activities and professions instead of emotions, are also found in Miscellaneous Symbols and Pictographs (especially U+1F466 through U+1F487) and Transport and Map Symbols. Body parts, mostly hands, are also encoded in the Dingbat and Miscellaneous Symbols blocks.



</doc>
<doc id="9740" url="https://en.wikipedia.org/wiki?curid=9740" title="Epoch">
Epoch

Epoch or EPOCH may refer to:









</doc>
<doc id="9742" url="https://en.wikipedia.org/wiki?curid=9742" title="Erdős number">
Erdős number

The Erdős number () describes the "collaborative distance" between mathematician and another person, as measured by authorship of mathematical papers.

The same principle has been applied in other fields where a particular individual has collaborated with a large and broad number of peers. The American Mathematical Society provides a free online tool to determine the Erdős number of every mathematical author listed in the Mathematical Reviews catalogue.

Paul Erdős (1913–1996) was an influential Hungarian mathematician who in the latter part of his life spent a great deal of time writing papers with a large number of colleagues, working on solutions to outstanding mathematical problems. He published more papers during his lifetime (at least 1,525) than any other mathematician in history. (Leonhard Euler published more total pages of mathematics but fewer separate papers: about 800.) Erdős spent a large portion of his later life living out of a suitcase, visiting his over 500 collaborators around the world.

The idea of the Erdős number was originally created by the mathematician's friends as a tribute to his enormous output. Later it gained prominence as a tool to study how mathematicians cooperate to find answers to unsolved problems. Several projects are devoted to studying connectivity among researchers, using the Erdős number as a proxy. For example, Erdős collaboration graphs can tell us how authors cluster, how the number of co-authors per paper evolves over time, or how new theories propagate.

Several studies have shown that leading mathematicians tend to have particularly low Erdős numbers. The median Erdős number of Fields Medalists is 3. Only 7,097 (about 5% of mathematicians with a collaboration path) have an Erdős number of 2 or lower. As time passes, the smallest Erdős number that can still be achieved will necessarily increase, as mathematicians with low Erdős numbers die and become unavailable for collaboration. Still, historical figures can have low Erdős numbers. For example, renowned Indian mathematician Srinivasa Ramanujan has an Erdős number of only 3 (through G.H. Hardy, Erdős number 2), even though Paul Erdős was only 7 years old when Ramanujan died.

To be assigned an Erdős number, someone must be a coauthor of a research paper with another person who has a finite Erdős number. Paul Erdős has an Erdős number of zero. Anybody else's Erdős number is where is the lowest Erdős number of any coauthor.

Erdős wrote around 1,500 mathematical articles in his lifetime, mostly co-written. He had 511 direct collaborators; these are the people with Erdős number 1. The people who have collaborated with them (but not with Erdős himself) have an Erdős number of 2 (9267 people as of 2010), those who have collaborated with people who have an Erdős number of 2 (but not with Erdős or anyone with an Erdős number of 1) have an Erdős number of 3, and so forth. A person with no such coauthorship chain connecting to Erdős has an Erdős number of infinity (or an undefined one). Since the death of Paul Erdős, the lowest Erdős number that a new researcher can obtain is 2.

There is room for ambiguity over what constitutes a link between two authors. The American Mathematical Society collaboration distance calculator uses data from Mathematical Reviews, which includes most mathematics journals but covers other subjects only in a limited way, and which also includes some non-research publications. The Erdős Number Project web site says:

but they do not include non-research publications such as elementary textbooks, joint editorships, obituaries, and the like. The “Erdős number of the second kind” restricts assignment of Erdős numbers to papers with only two collaborators.

The Erdős number was most likely first defined in print by Casper Goffman, an analyst whose own Erdős number is 2. Goffman published his observations about Erdős' prolific collaboration in a 1969 article entitled ""And what is your Erdős number?"" See also some comments in an obituary by Michael Golomb.

The median Erdős number among Fields medalists is as low as 3. Fields medalists with Erdős number 2 include Atle Selberg, Kunihiko Kodaira, Klaus Roth, Alan Baker, Enrico Bombieri, David Mumford, Charles Fefferman, William Thurston, Shing-Tung Yau, Jean Bourgain, Richard Borcherds, Manjul Bhargava, Jean-Pierre Serre and Terence Tao. There are no Fields medalists with Erdős number 1, however Endre Szemerédi is an Abel Prize Laureate with Erdős number 1.

While Erdős collaborated with hundreds of co-authors, there were some individuals with whom he co-authored dozens of papers. This is a list of the ten persons who most frequently co-authored with Erdős and their number of papers co-authored with Erdős (i.e. their number of collaborations).
, all Fields Medalists have a finite Erdős number, with values that range between 2 and 6, and a median of 3. In contrast, the median Erdős number across all mathematicians (with a finite Erdős number) is 5, with an extreme value of 13. The table below summarizes the Erdős number statistics for Nobel prize laureates in Physics, Chemistry, Medicine and Economics. The first column counts the number of laureates. The second column counts the number of winners with a finite Erdős number. The third column is the percentage of winners with a finite Erdős number. The remaining columns report the minimum, maximum, average and median Erdős numbers among those laureates.

Among the Nobel Prize laureates in Physics, Albert Einstein and Sheldon Lee Glashow have an Erdős number of 2. Nobel Laureates with an Erdős number of 3 include Enrico Fermi, Otto Stern, Wolfgang Pauli, Max Born, Willis E. Lamb, Eugene Wigner, Richard P. Feynman, Hans A. Bethe, Murray Gell-Mann, Abdus Salam, Steven Weinberg, Norman F. Ramsey, Frank Wilczek, and David Wineland. Fields Medal-winning physicist Ed Witten has an Erdős number of 3.

Computational biologist Lior Pachter has an Erdős number of 2. Evolutionary biologist Richard Lenski has an Erdős number of 3, having co-authored a publication with Lior Pachter and with mathematician Bernd Sturmfels, each of whom has an Erdős number of 2.

There are at least two winners of the Nobel Prize in Economics with an Erdős number of 2: Harry M. Markowitz (1990) and Leonid Kantorovich (1975). Other financial mathematicians with Erdős number of 2 include David Donoho, Marc Yor, Henry McKean, Daniel Stroock, and Joseph Keller.

Nobel Prize laureates in Economics with an Erdős number of 3 include Kenneth J. Arrow (1972), Milton Friedman (1976), Herbert A. Simon (1978), Gerard Debreu (1983), John Forbes Nash, Jr. (1994), James Mirrlees (1996), Daniel McFadden (1996), Daniel Kahneman (2002), Robert J. Aumann (2005), Leonid Hurwicz (2007), Roger Myerson (2007), Alvin E. Roth (2012), and Lloyd S. Shapley (2012) and Jean Tirole (2014).

Some investment firms have been founded by mathematicians with low Erdős numbers, among them James B. Ax of Axcom Technologies, and James H. Simons of Renaissance Technologies, both with an Erdős number of 3.

Judge Richard Posner, having coauthored with Alvin E. Roth, has an Erdős number of at most 4. Roberto Mangabeira Unger, a politician, philosopher and legal theorist who teaches at Harvard Law School, has an Erdős number of at most 4, having coauthored with Lee Smolin.

Some fields of engineering, in particular communication theory and cryptography, make direct use of the discrete mathematics championed by Erdős. It is therefore not surprising that practitioners in these fields have low Erdős numbers. For example, Robert McEliece, a professor of electrical engineering at Caltech, has an Erdős number of 1, having collaborated with Erdős himself.

Anthropologist Douglas R. White has an Erdős number of 2 via graph theorist Frank Harary. Sociologist Barry Wellman has an Erdős number of 3 via social network analyst and statistician Ove Frank, another collaborator of Harary's.

Erdős numbers have been a part of the folklore of mathematicians throughout the world for many years. Among all working mathematicians at the turn of the millennium who have a finite Erdős number, the numbers range up to 15, the median is 5, and the mean is 4.65; almost everyone with a finite Erdős number has a number less than 8. Due to the very high frequency of interdisciplinary collaboration in science today, very large numbers of non-mathematicians in many other fields of science also have finite Erdős numbers. For example, political scientist Steven Brams has an Erdős number of 2. In biomedical research, it is common for statisticians to be among the authors of publications, and many statisticians can be linked to Erdős via John Tukey, who has an Erdős number of 2. Similarly, the prominent geneticist Eric Lander and the mathematician Daniel Kleitman have collaborated on papers, and since Kleitman has an Erdős number of 1, a large fraction of the genetics and genomics community can be linked via Lander and his numerous collaborators. Similarly, collaboration with Gustavus Simmons opened the door for 
Erdős numbers within the cryptographic research community, and many linguists have finite Erdős numbers, many due to chains of collaboration with such notable scholars as Noam Chomsky (Erdős number 4), William Labov (3), Mark Liberman (3), Geoffrey Pullum (3), or Ivan Sag (4). There are also connections with arts fields.

According to Alex Lopez-Ortiz, all the Fields and Nevanlinna prize winners during the three cycles in 1986 to 1994 have Erdős numbers of at most 9.

Earlier mathematicians published fewer papers than modern ones, and more rarely published jointly written papers. The earliest person known to have a finite Erdős number is either Antoine Lavoisier (born 1743, Erdős number 13), Richard Dedekind (born 1831, Erdős number 7), or Ferdinand Georg Frobenius (born 1849, Erdős number 3), depending on the standard of publication eligibility. It seems that older historic figures such as Leonhard Euler (born 1707) do not (yet) have finite Erdős numbers.

Martin Tompa proposed a directed graph version of the Erdős number problem, by orienting edges of the collaboration graph from the alphabetically earlier author to the alphabetically later author and defining the "monotone Erdős number" of an author to be the length of a longest path from Erdős to the author in this directed graph. He finds a path of this type of length 12.

Also, Michael Barr suggests "rational Erdős numbers", generalizing the idea that a person who has written p joint papers with Erdős should be assigned Erdős number 1/p. From the collaboration multigraph of the second kind (although he also has a way to deal with the case of the first kind)—with one edge between two mathematicians for "each" joint paper they have produced—form an electrical network with a one-ohm resistor on each edge. The total resistance between two nodes tells how "close" these two nodes are.

It has been argued that "for an individual researcher, a measure such as Erdős number captures the structural properties of [the] network whereas the "h"-index captures the citation impact of the publications," and that "One can be easily convinced that ranking in coauthorship networks should take into account both measures to generate a realistic and acceptable ranking."

In 2004 William Tozier, a mathematician with an Erdős number of 4, auctioned off a co-authorship on eBay, hence providing the buyer with an Erdős number of 5. The winning bid of $1031 was posted by a Spanish mathematician, who however did not intend to pay but just placed the bid to stop what he considered a mockery.

A number of variations on the concept have been proposed to apply to other fields.

The best known is the Bacon number (as in the game Six Degrees of Kevin Bacon), connecting actors that appeared in a film together to the actor Kevin Bacon. It was created in 1994, 25 years after Goffman's article on the Erdős number.

A small number of people are connected to both Erdős and Bacon and thus have an Erdős–Bacon number, which combines the two numbers by taking their sum. One example is the actress-mathematician Danica McKellar, best known for playing Winnie Cooper on the TV series, "The Wonder Years". 
Her Erdős number is 4 and her Bacon number is 2.

Further extension is possible. For example, the Erdős–Bacon–Sabbath number is the addition of the Erdős–Bacon number and the collaborative distance to the band Black Sabbath in terms of singing in public. The lowest known Erdős–Bacon–Sabbath number is 8, for physicist Stephen Hawking who has an Erdős number of 4, a Bacon number of 2, and a Sabbath number of 2.




</doc>
<doc id="9750" url="https://en.wikipedia.org/wiki?curid=9750" title="School voucher">
School voucher

A school voucher, also called an education voucher, in a voucher system, is a certificate of government funding for a student at a school chosen by the student or the student's parents. The funding is usually for a particular year, term or semester. In some countries, states or local jurisdictions, the voucher can be used to cover or reimburse home schooling expenses. In some countries, vouchers only exist for tuition at private schools.

According to a 2017 review of the economics literature on school vouchers, "the evidence to date is not sufficient to warrant recommending that vouchers be adopted on a widespread basis; however, multiple positive findings support continued exploration." A 2006 survey of members of American Economic Association found that over two-thirds of economists support giving parents educational vouchers that can be used at government-operated or privately operated schools, and that support is greater if the vouchers are to be used by parents with low-incomes or parents with children in poorly performing schools.

France lost the Franco-Prussian War and many blamed the loss on France’s inferior military education system. Following the defeat in the Franco-Prussian War, the French assembly proposed a religious voucher that would hopefully improve schools by allowing students to seek out the best school. This proposal never moved forward due to the reluctance of the French to subsidize religious education. Despite its failure, this proposal is one of the earliest examples of a voucher system that closely resembles voucher systems proposed and used today in many countries.

The oldest continuing school voucher programs existing today in the United States are the Town Tuitioning programs in Vermont and Maine, beginning in 1869 and 1873 respectively. Because some towns in these states operate neither local high schools nor elementary schools, students in these towns "are eligible for a voucher to attend [either] public schools in other towns or non-religious private schools. In these cases, the 'sending' towns pay tuition directly to the 'receiving' schools."

Milton Friedman argued for the modern concept of vouchers in the 1950s, stating that competition would improve schools, cost less and yield superior educational outcomes. Friedman's reasoning in favor of vouchers gained additional attention in 1980 with the broadcast of his ten part television series "Free to Choose" and the publication of its companion book of the same name (co-written with his wife Rose Friedman, who was also an economist). Episode 6 of the series and chapter 6 of the book were both entitled, "What's Wrong with Our Schools?" and asserted that permitting parents and students to use vouchers to choose their schools would expand freedom of choice and produce more well-educated students.

In some Southern states during the 1960s, school vouchers were used as a way to perpetuate segregation. In a few instances, public schools were closed outright and vouchers were issued to parents. The vouchers, then known as tuition grants, in many cases, were only good at privately segregated schools, known as segregation academies.

In 2005, Dr. Allah Bakhsh Malik Managing Director Punjab Education Foundation, under the supervision of Professor Henry M. Levin introduced Education Vouchers scheme in Pakistan with the features of equity, productivity, social cohesion and freedom of choice. Today, all modern voucher programs prohibit racial discrimination.

There are important distinctions between different kinds of schools:

Education as a tool for human capital accumulation is often crucial to the development and progression of societies and thus governments have large incentives to continually intervene and improve public education. Additionally, education is often the tool with which societies instill a common set of values that underlie the basic norms of the society. Furthermore, there are positive externalities to society from education. These positive externalities can be in the form of reduced crime, more informed citizens and economic development, known as the neighborhood effect.

In terms of economic theory, families face a bundle of consumption choices that determine how much they will spend on education and private consumption. Any number of consumption bundles are available as long as they fit within the budget constraint. Meaning that any bundle of consumption of education and private consumption must not exceed budgetary constraints. Indifference curves represent the preferences of one good over another. The indifference curve determines how much education an individual will want to consume versus how much private consumption an individual will want to consume.

Government intervention in education typically takes two forms. The first approach can be broad, such as instituting charter schools, magnet schools, or for-profit schools and increasing competition. The second approach can be individually focused such as providing subsidies or loans for individuals to attend college or school vouchers for K-12.

Vouchers are typically instituted for 2 broad economic reasons. The first reason is consumer sovereignty. A family can choose to where their child goes to school and pick the school that is closest to their preference of education provider.

The second reason is vouchers are proposed to increase market competition amongst schools. Similar to the free market theorem, vouchers hope to make schools more competitive while lowering costs for schools and increasing the educational quality for consumers, the families.

In many instances where school voucher programs have been instituted, there have been mixed results, with some programs showing increased benefits of school vouchers and some instances showing detrimental effects.

In the United States, vouchers are usually funded with state dollars, and in other countries, through a variety of government funding vehicles. It is important to note that schools in the United States retain their federal and local funding regardless of enrollment- only state funding is dependent on enrollment size. Part of improving student performance involves improving teacher and school performance. In theory, more school vouchers would prompt the formation of more private schools which will give parents more choice in school. This increased competition would make both the private and public schools, who are both competing for the voucher funds, maintain a high-quality of teaching as well as keeping costs low. 
Indeed, there is evidence that school vouchers result in cost savings for school systems. A fiscal analysis of Indiana’s school voucher system showed annual savings, per student, for the state government.

Proponents of voucher schools argue that there is evidence of multiple benefits for students and families because of school vouchers. There is evidence to show that the use of school vouchers results in increased test scores and higher high school graduation rates for students. A case study in the country of Colombia showed that the presence of voucher programs resulted in an increase of 10 percentage points in a child’s likelihood of finishing the 8th grade and showed a 0.2 standard deviations increase in achievement on standardized tests. Furthermore, evidence shows that African Americans experience increased college enrollment rates under voucher programs. It is important to note that these gains for African American Students are not present for other racial and ethnic groups.

Research has also shown spatial benefits of voucher system. Public schools, which are near private schools that accept vouchers, often have better test scores than other public schools not near voucher ready private schools. Additional research by Caroline Hoxby shows that when voucher systems are available, both the public and private schools in that school system have increased test scores and graduation rates.

While there are some studies that show the positive effects of voucher programs, there is also research that shows the ineffectiveness of school vouchers. There have been some recent case studies showing that in voucher system school districts, students attending the public school, as opposed to the private school with a voucher, tend to outperform their private school peers.

Besides general lack of results, critics of school vouchers argue that vouchers will lead to segregation. Empirical studies show that there is some evidence that school vouchers can lead to racial or income segregation. However research on this topic is inconclusive, as there is also valid research that shows under certain circumstances, income and racial segregation can be reduced indirectly by increasing school choice.

A 2018 study by Abdulkadiroğlu et al. found that disadvantaged students who won a lottery (the Louisiana Scholarship Program) to get vouchers to attend private schools had worse education outcomes than disadvantaged students who did not win vouchers: "LSP participation lowers math scores by 0.4 standard deviations and also reduces achievement in reading, science, and social studies. These effects may be due in part to selection of low-quality private schools into the program."

The PACES voucher program was established by the Colombian government in late 1991. It aimed to assist low-income households by distributing school vouchers to students living in neighborhoods situated in the two lowest socioeconomic strata. Between 1991 and 1997, the PACES program awarded 125,000 vouchers to lower-income secondary school students. Those vouchers were worth about US $190 in 1998, and data shows that matriculation fees and other monthly expenses incurred by voucher students attending private schools averaged about US $340 in 1998, so a majority of voucher recipients supplemented the voucher with personal funds.

The students selected to be in the program were selected by lottery. The vouchers were able to be renewed annually, conditional on students achieving satisfactory academic success as indicated by scheduled grade promotion. The program also included incentives to study harder as well as widening schooling options. Empirical evidence showed that the program had some success. Joshua Angrist shows that after 3 years into the program, lottery winners were 15 percentage points more likely to attend private school and complete .1 more years of schooling, and were about 10 percentage points more likely to have finished the 8th grade.The study also reported that there were larger voucher effects for boys than for girls, especially in mathematics performance. It is important to note that the program did not have a significant impact on dropout rates. Angrist reports that lottery winners scored .2 standard deviations higher on standardized tests. The voucher program also reported some social effects. Lottery winners worked less on average than non-lottery winners. Angrist reports that this was correlated with a decreased likelihood to marry or cohabit as teenagers. In general, the school voucher program’s benefits outweighed the costs.

In 1981, Chile implemented a universal school voucher system for both elementary and secondary school students. As a result, over 1,000 private schools entered the market, and private enrollment increased by 20-40% by 1998, surpassing 50% in some urban areas. From 1981 to 1988, the private school enrollment rate in urban areas grew 11% more than the private school enrollment rate in rural areas. This change coincided with the transfer of public school administration from the central government to local municipalities. The financial value of a voucher didn’t depend on the income of the family receiving it, and the program allowed private voucher schools to be selective, while public schools had to accept and enroll every interested student. At the turn of the 21 century, student achievement in Chile was low compared to students in other nations based on international test-scores. This disparity led to the Chilean government enacting substantial educational reforms in 2008, including major changes in the school voucher system.

The Chilean government passed the Preferential School Subsidy Law (SEP) in January of 2008. This piece of legislation made the educational voucher system much more like the regulated compensatory model championed by Christopher Jencks. Under SEP, the voucher system was altered to take family incomes into account. The vouchers provided to “priority students,” students whose family income was in the bottom 40% of Chileans in were worth 50% more than those given to the families of students in the upper 60%. Schools with larger numbers of priority students were eligible to receive per-student bonuses, the size of which was tied to the percentage of priority students in the student body. When SEP was started, it covered preschool to fourth grade, and an additional school-year of coverage was added each subsequent year. Almost every public school chose to participate in SEP in 2008, as well as almost two-thirds of private subsidized elementary schools.

There were three important requirements attached to the program. The first requirement stipulated that participating schools could not charge fees to priority students, although private schools in the voucher system could do so for non-priority students. The second requirement ensured that schools could not select students based on their academic ability, not expel them on academic grounds. The third requirement postulated that schools had to self-enroll themselves in an accountability system that ensured that schools were responsible for the utilization of financial resources and student test scores.

In most European countries, education for all primary and secondary schools is fully subsidized. In some countries (e.g. Belgium or France), parents are free to choose which school their child attends.

Most schools in Ireland are state-aided parish schools, established under diocesan patronage but with capital costs, teachers salaries and a per head fee paid to the school. These are given to the school regardless of whether or not it requires its students to pay fees. (Although fee-paying schools are in the minority, there has been much criticism over the state aid they receive with opponents claiming this gives them an unfair advantage.)

There is a recent trend towards multi-denominational schools established by parents, which are organised as limited companies without share capital. Parents and students are free to choose their own school. In the event of a school failing to attract students it immediately loses its per-head fee and over time loses its teaching posts – and teachers are moved to other schools which are attracting students. The system is perceived to have achieved very successful outcomes for most Irish children.

The 1995–7 Rainbow Coalition (which contained parties of the centre right and the left) introduced free third-level education to primary degree level. Critics of the latter development charge that it has not increased the number of students from economically deprived backgrounds attending university. However, studies have shown that the removal of tuition fees at third level has increased the number of students overall and those from lower socio-economic backgrounds. This concurs with evidence from the UK of a decrease in attendance numbers after the introduction of fees. However, since the economic crisis, there has been extensive talk and debate regarding the reintroduction of third-level fees.

In Sweden, a system of school vouchers (called "skolpeng") was introduced in 1992 at primary and secondary school level, enabling free choice among publicly run schools and privately run "friskolor" ("free schools"). The voucher is paid with public funds from the local municipality ("kommun") directly to a school based solely on its number of students. Both public schools and free schools are funded the same way. Free schools can be run by not-for-profit groups as well as by for-profit companies, but may not charge top-up fees or select students other than on a first-come, first-served basis. Over 10% of Swedish pupils were enrolled in free schools in 2008 and the number is growing fast, leading the country to be viewed as a pioneer of the model.

Per Unckel, governor of Stockholm and former Minister of Education, has promoted the system, saying "Education is so important that you can’t just leave it to one producer, because we know from monopoly systems that they do not fulfill all wishes." The Swedish system has been recommended to Barack Obama by some commentators, including the Pacific Research Institute, which has released a documentary called "Not As Good As You Think: Myth of the Middle Class Schools", a movie depicting positive benefits for middle class schools resulting from Sweden's voucher programs.

A 2004 study concluded that school results in public schools improved due to the increased competition. However, Per Thulberg, director general of the Swedish National Agency for Education, has said that the system "has not led to better results" and in the 2000s Sweden's ranking in the PISA league tables worsened. Though Rachel Wolf, director of the New Schools Network, has suggested that Sweden's education standards had slipped for reasons other than as a result of free schools.

A voucher system for children three to six years-old who attend a non-profit kindergarten was implemented in Hong Kong in 2007. Each child will get HK$13,000 per year. The $13,000 subsidy will be separated into two parts. $10,000 is used to subsidize the school fee and the remaining $3,000 is used for kindergarten teachers to pursue further education and obtain a certificate in Education. Also, there are some restrictions on the voucher system. Parents can only choose non-profit schools with a yearly fee less than $24,000. The government hoped that all kindergarten teachers can obtain an Education certificate by the year 2011–12, at which point the subsidies are to be adjusted to $16,000 for each student, all of which will go toward the school fee.

Milton Friedman criticised the system, saying "I do not believe that CE Mr. Tsang's proposal is properly structured." He said that the whole point of a voucher system is to provide a competitive market place so should not be limited to non-profit kindergartens. 

After protests by parents with children enrolled in for profit kindergartens, the program was extended to children in for- profit kindergartens, but only for children enrolled in or before September 2007. The government will also provide up to HK$30,000 subsidy to for profit kindergartens wanting to convert to non profit.

In Pakistani Punjab, the Education Voucher Scheme (EVS) was introduced by Dr. Allah Bakhsh Malik Managing Director and Chief Executive of Punjab Education Foundation (PEF), especially in urban slums and poorest of the poor in 2005. The initial study was sponsored by Open Society Institute New York USA. Professor Henry M. Levin extended Pro-Bono services for children of poor families from Punjab. To ensure educational justice and integration, the government must ensure that the poorest families have equal access to quality education. The voucher scheme was designed by the Teachers College, Columbia University, and the Open Society Institute. It aims to promote freedom of choice, efficiency, equity, and social cohesion.

A pilot project was started in 2006 in the urban slums of Sukhnehar, Lahore, where a survey showed that all households lived below the poverty line. Through the EVS, the foundation would deliver education vouchers to every household with children 5–13 years of age. The vouchers would be redeemable against tuition payments at participating private schools. In the pilot stage, 1,053 households were given an opportunity to send their children to a private school of their choice. The EVS makes its partner schools accountable to the parents rather than to the bureaucrats at the Ministry of Education. In the FAS program, every school principal has the choice to admit a student or not. However, in the EVS, a school cannot refuse a student if the student has a voucher and the family has chosen that school. The partner schools are also accountable to the PEF: they are subject to periodic reviews of their student learning outcomes, additional private investments, and improvements in working conditions of the teachers. The EVS provides an incentive to parents to send their children to school, and so it has become a source of competition among private schools seeking to join the program.

When it comes to the selection of schools, the following criteria are applied across the board: (i) The fee paid by the PEF to EVS partner schools is PKR 300 per child per month. Schools charging higher fees can also apply to the program, but they will not be paid more than PKR 450, and they will not be entitled to charge the difference to students’ families. (ii) Total school enrollment should be between 100 and 500 children. (iii) The school should have an adequate infrastructure and a good learning environment. (iv) EVS partner schools should be located within a half-kilometer radius of the residences of voucher holders. However, if the parents prefer a particular school farther away, the PEF will not object, provided that the school fulfills the EVS selection criteria. (v) The PEF advertises to stimulate the interest of potential partner schools. It then gives students at short-listed schools preliminary tests in selected subjects, and conducts physical inspections of these schools. PEF offices display a list of all the EVS partner schools so that parents may consult it and choose a school for their children.

By now more than 140, 000 students are benefiting from EVS and the program is being scaled up by financing from Government of Punjab.

In the 1980s, the Reagan administration pushed for vouchers, as did the George W. Bush administration in the initial education-reform proposals leading up to the No Child Left Behind Act. As of December 2016, 17 states plus the District of Columbia had enacted school voucher programs. When including scholarship tax credits and education savings accounts – two alternatives to vouchers – there are 27 states plus the District of Columbia with private school choice programs. Most of these programs were offered to students in low-income families, low performing schools, or students with disabilities. By 2014, the number participating in either vouchers or tax-credit scholarships increased to 250,000, a 30% increase from 2010, but still a small fraction compared to the 55 million in traditional schools.

In 1990, the city of Milwaukee, Wisconsin's public schools were the first to offer vouchers and has nearly 15,000 students using vouchers as of 2011. The program, entitled the Milwaukee Parental Choice Program, originally funded school vouchers for nonreligious, private institutions. It was, however, eventually expanded to include private, religious institutions after it saw success with nonreligious, private institutions. The 2006/07 school year marked the first time in Milwaukee that more than $100 million was paid in vouchers. Twenty-six percent of Milwaukee students will receive public funding to attend schools outside the traditional Milwaukee Public School system. In fact, if the voucher program alone were considered a school district, it would mark the sixth-largest district in Wisconsin. St. Anthony Catholic School, located on Milwaukee's south side, boasts 966 voucher students, meaning that it very likely receives more public money for general school support of a parochial elementary or high school than any before it in American history. A 2013 study of Milwaukee’s program posited that the use of vouchers increased the probability that a student would graduate from high school, go to college, and stay in college. A 2015 paper published by the National Bureau of Economic Research found that participation in Louisiana's voucher program “substantially reduces academic achievement” although that the result may be reflective of the poor quality of private schools in the program.

Recent analysis of the competitive effects of school vouchers in Florida suggests that more competition improves performance in the regular public schools.

The largest school voucher program in the United States is Indiana's Indiana Choice Scholarships program.

Proponents of school voucher and education tax credit systems argue that those systems promote free market competition among both private and public schools by allowing parents and students to choose the school where to use the vouchers. This choice available to parents forces schools to perpetually improve in order to maintain enrollment. Thus, proponents argue that a voucher system increases school performance and accountability because it provides consumer sovereignty – allowing individuals to choose what product to buy, as opposed to a bureaucracy.

This argument is supported by studies such as "When Schools Compete: The Effects of Vouchers on Florida Public School Achievement" (Manhattan Institute for Policy Research, 2003), which concluded that public schools located near private schools that were eligible to accept voucher students made significantly more improvements than did similar schools not located near eligible private schools. Stanford's Caroline Hoxby, who has researched the systemic effects of school choice, determined that areas with greater residential school choice have consistently higher test scores at a lower per-pupil cost than areas with very few school districts. Hoxby studied the effects of vouchers in Milwaukee and of charter schools in Arizona and Michigan on nearby public schools. Public schools forced to compete made greater test-score gains than schools not faced with such competition, and that the so-called effect of cream skimming did not exist in any of the voucher districts examined. Hoxby's research has found that both private and public schools improved through the use of vouchers. Also, similar competition has helped in manufacturing, energy, transportation, and parcel postal (UPS, FedEx vs. USPS) sectors of government that have been socialized and later opened up to free market competition.

Similarly, it is argued that such competition has helped in higher education, with publicly funded universities directly competing with private universities for tuition money provided by the Government, such as the GI Bill and the Pell Grant in the United States. The Foundation for Educational Choice alleges that a school voucher plan "embodies exactly the same principle as the GI bills that provide for educational benefits to military veterans. The veteran gets a voucher good only for educational expense and he is completely free to choose the school at which he uses it, provided that it satisfies certain standards." The Pell Grant, a need-based aid, like the Voucher, can only be used for authorized school expenses at qualified schools, and, like the Pell, the money follows the student, for use against those authorized expenses (not all expenses are covered).

Proponents are encouraged by private school sector growth, as they believe that private schools are typically more efficient at achieving results at a much lower per-pupil cost than public schools. A CATO Institute study of public and private school per pupil spending in Phoenix, Los Angeles, D.C., Chicago, New York City, and Houston found that public schools spend 93% more than estimated median private schools.

Proponents claim that institutions often are forced to operate more efficiently when they are made to compete and that any resulting job losses in the public sector would be offset by the increased demand for jobs in the private sector.

Friedrich von Hayek on the privatizing of education:

Other notable supporters include New Jersey Senator Cory Booker, former Governor of South Carolina Mark Sanford, billionaire and American philanthropist John T. Walton, Former Mayor of Baltimore Kurt L. Schmoke, Former Massachusetts Governor Mitt Romney and John McCain. A random survey of 210 Ph.D. holding members of the American Economic Association, found that over two-thirds of economists support giving parents educational vouchers that can be used at government-operated or privately operated schools, and that support is greater if the vouchers are to be used by parents with low-incomes or parents with children in poorly performing schools.

Another prominent proponent of the voucher system was Apple co-founder and CEO, Steve Jobs, who said:

As a practical matter, proponents note, most U.S. programs only offer poor families the same choice more affluent families already have, by providing them with the means to leave a failing school and attend one where the child can get an education. Because public schools are funded on a per-pupil basis, the money simply follows the child, but the cost to taxpayers is less because the voucher generally is less than the actual cost.

In addition, they say, the comparisons of public and private schools on average are meaningless. Vouchers usually are utilized by children in failing schools, so they can hardly be worse off even if the parents fail to choose a better school. Also, focusing on the effect on the public school suggests that is more important than the education of children.

Some proponents of school vouchers, including the Sutherland Institute and many supporters of the Utah voucher effort, see it as a remedy for the negative cultural impact caused by under-performing public schools, which falls disproportionately on demographic minorities. During the run-up to the November referendum election, Sutherland issued a controversial publication: Voucher, Vows, & Vexations. Sutherland called the publication an important review of the history of education in Utah, while critics just called it revisionist history. Sutherland then released a companion article in a law journal as part of an academic conference about school choice.

EdChoice, founded by Milton and Rose Friedman in 1996, is a non-profit organization that promotes universal school vouchers and other forms of school choice. In defense of vouchers, it cites empirical research showing that students who were randomly assigned to receive vouchers had higher academic outcomes than students who applied for vouchers but lost a random lottery and did not receive them; and that vouchers improve academic outcomes at public schools, reduce racial segregation, deliver better services to special education students, and do not drain money from public schools.

The main critique of school vouchers and education tax credits is that they put public education in competition with private education, threatening to reduce and reallocate public school funding to private schools. Opponents question the belief that private schools are more efficient.

Public school teachers and teacher unions have also fought against school vouchers. In the United States, public school teacher unions, most notably the National Education Association (the largest labor union in the USA), argue that school vouchers erode educational standards and reduce funding, and that giving money to parents who choose to send their child to a religious or other school is unconstitutional. The latter issue was struck down by the Supreme Court case "Zelman v. Simmons-Harris", which upheld Ohio's voucher plan in a 5-4 ruling. In contrast, the use of public school funding for vouchers to private schools was disallowed by the Louisiana Supreme Court in 2013. The Louisiana Supreme Court did not declare vouchers unconstitutional, just the use of money earmarked for public schools via the Louisiana Constitution for funding Louisiana's voucher program. The National Education Association also points out that access to vouchers is just like “a chance in a lottery” where parents had to be lucky in order to get a space in this program. Since almost all students and their families would like to choose the best schools, those schools, as a result, quickly reach its maximum capacity number for students that state law permits. Those who did not get vouchers then have to compete again to look for some other less preferred and competitive schools or give up searching and go back to their assigned local schools. Jonathan Kozol, a prominent public school reform thinker and former public school teacher called vouchers the "single worst, most dangerous idea to have entered education discourse in my adult life".

People who can benefit from vouchers may not know it. In April 2012, a bill passed in Louisiana that made vouchers available to low-income families whose children attended poorly ranked schools. A student whose household income was low (up to about $44,000 for a family of three) who attended a school ranked "C", "D", or "F" could apply for vouchers to attend another school. Of the estimated 380,000 eligible students during the school year when the bill was passed (2012/13), only 5,000 students knew about and applied for the vouchers, and accepted them.

In 2006, the United States Department of Education released a report concluding that average test scores for reading and mathematics, when adjusted for student and school characteristics, tend to be very similar among public schools and private schools. Private schools performed significantly better than public schools only if results were not adjusted for factors such as race, gender, and free or reduced price lunch program eligibility. Other research questions assumptions that large improvements would result from a more comprehensive voucher system.

Given the limited budget for schools, it is claimed that a voucher system would weaken public schools while not providing enough money for people to attend private schools. 76% of the money given in Arizona’s voucher program went to children already in private schools.

Some sources claim that public schools' higher per-pupil spending is due to having a higher proportion of students with behavioral, physical and emotional problems, since in the United States, public schools must by law accept any student regardless of race, gender, religion, disability, educational aptitude, and so forth, while private schools are not so bound. They argue that some, if not all, of the cost difference between public and private schools comes from "cream skimming", whereby the private schools select only those students who belong to a preferred group – whether economic, religious, educational aptitude level, or ethnicity – rather than from differences in administration. The end result, it has been argued, is that a voucher system has led or would lead students who do not belong to the private schools' preferred groupings to become concentrated at public schools. However, of the ten state-run voucher programs in the United States at the beginning of 2011, four targeted low-income students, two targeted students in failing schools, and six targeted students with special needs. (Louisiana ran a single program targeting all three groups.)

It is also argued that voucher programs are often implemented without the necessary safeguards that prevent institutions from discriminating against marginalized communities. In the United States, as of 2016, there are currently no state laws that require voucher programs to not discriminate against marginalized communities. Further, while some voucher programs may explicitly be aimed at marginalized communities, this is not necessarily always the case. A common argument for school vouchers is that it allows for marginalized communities of color to be uplifted from poverty. Historically, however, data suggests that voucher programs have been used to further segregate Americans. Further, some data has shown that the effects of voucher programs such as the New York City School Choice Scholarship Program, are marginal when it comes to increasing student achievement.

Another argument against a school voucher system is its lack of accountability to taxpayers. In many states, members of a community's board of education are elected by voters. Similarly, a school budget faces a referendum. Meetings of the Board of Education must be announced in advance, and members of the public are permitted to voice their concerns directly to board members. By contrast, although vouchers may be used in private and religious schools, taxpayers cannot vote on budget issues, elect members of the board or even attend board meetings. Kevin Welner points out that vouchers funded through a convoluted tax credit system—a policy he calls "neovouchers"—present additional accountability concerns. With neovoucher systems, a taxpayer owing money to the state instead donates that money to a private, nonprofit organization. That organization then bundles donations and gives them to parents as vouchers to be used for private school tuition. The state then steps in and forgives (through a tax credit) some or all of the taxes that the donor has given to the organization. While conventional tax credit systems are structured to treat all private school participants equally, neovoucher systems effectively delegate to individual private taxpayers (those owing money to the state) the power to decide which private schools will benefit.

An example of lack of accountability is the voucher situation in Louisiana. In 2012, Louisiana State Superintendent of Education John White selected private schools to receive vouchers, then tried to fabricate criteria (including site visits) after schools had already received approval letters. One school of note, New Living Word in Ruston, Louisiana, did not have sufficient facilities for the over-300 students White and the state board of education had approved. Following a voucher audit in 2013, New Living Word had overcharged the state $395,000. White referred to the incident as a "lone substantive issue". However, most voucher schools did not undergo a complete audit for not having a separate checking account for state voucher money.

According to Susanne Wiborg, an expert on comparative education, Sweden's voucher system introduced in 1992 has "augmented social and ethnic segregation, particularly in relation to schools in deprived areas".

Tax-credit scholarships which are in most part disbursed to current private school students or to families which made substantial donations to the scholarship fund, rather than to low-income students attempting to escape from failing schools, amount to nothing more than a mechanism to use public funds in the form of foregone taxes to support private, often religiously based, private schools.

The school voucher question in the United States has also received a considerable amount of judicial review in the early 2000s.

A program launched in the city of Cleveland in 1995 and authorized by the state of Ohio was challenged in court on the grounds that it violated both the federal constitutional principle of separation of church and state and the guarantee of religious liberty in the Ohio Constitution. These claims were rejected by the Ohio Supreme Court, but the federal claims were upheld by the local federal district court and by the Sixth Circuit appeals court. The fact that nearly all of the families using vouchers attended Catholic schools in the Cleveland area was cited in the decisions.

This was later reversed during 2002 in a landmark case before the US Supreme Court, "Zelman v. Simmons-Harris", in which the divided court, in a 5–4 decision, ruled the Ohio school voucher plan constitutional and removed any constitutional barriers to similar voucher plans in the future, with conservative justices Anthony Kennedy, Sandra Day O'Connor, William Rehnquist, Antonin Scalia, and Clarence Thomas in the majority.

Chief Justice William Rehnquist, writing for the majority, stated that "The incidental advancement of a religious mission, or the perceived endorsement of a religious message, is reasonably attributable to the individual aid recipients not the government, whose role ends with the disbursement of benefits." The Supreme Court ruled that the Ohio program did not violate the Establishment Clause, because it passed a five-part test developed by the Court in this case, titled the Private Choice Test.

Dissenting opinions included Justice Stevens's, who wrote "...the voluntary character of the private choice to prefer a parochial education over an education in the public school system seems to me quite irrelevant to the question whether the government's choice to pay for religious indoctrination is constitutionally permissible." and Justice Souter's, whose opinion questioned how the Court could keep "Everson v. Board of Education" on as precedent and decide this case in the way they did, feeling it was contradictory. He also found that religious instruction and secular education could not be separated and this itself violated the Establishment Clause.

In 2006, the Florida Supreme Court struck down legislation known as the Florida Opportunity Scholarship Program (OSP), which would have implemented a system of school vouchers in Florida. The court ruled that the OSP violated article IX, section 1(a) of the Florida Constitution: "Adequate provision shall be made by law for a uniform, efficient, safe, secure, and high quality system of free public schools." This decision was criticized by Clark Neily, Institute for Justice senior attorney and legal counsel to Pensacola families using Florida Opportunity Scholarships, as, "educational policymaking".

Political support for school vouchers in the United States is mixed. On the left/right spectrum, conservatives are more likely to support vouchers. Some state legislatures have enacted voucher laws. In New Mexico, then-Republican Gary Johnson made school voucher provision the major issue of his second term as Governor. As of 2006, the federal government operates the largest voucher program, for evacuees from the region affected by Hurricane Katrina. The Federal government provided a voucher program for 7,500 residents of Washington, D.C. - the D.C. Opportunity Scholarship Program. until in early March 2009 congressional Democrats were moving to close down the program and remove children from their voucher-funded school places at the end of the 2009/10 school year under the $410 billion Omnibus Appropriations Act of 2009 which, as of March 7 had passed the House and was pending in the Senate. The Obama administration stated that it preferred to allow children already enrolled in the program to finish their schooling while closing the program to new entrants. However, its preference on this matter does not appear to be strong enough to prevent the President from signing the Bill.

Whether or not the public generally supports vouchers is debatable. Majorities seem to favor improving existing schools over providing vouchers, yet as many as 40% of those surveyed admit that they do not know enough to form an opinion or do not understand the system of school vouchers.

In November 2000, a voucher system proposed by Tim Draper was placed on the California ballot as Proposition 38. It was unusual among school voucher proposals in that it required neither accreditation on the part of schools accepting vouchers, nor proof of need on the part of families applying for them; neither did it have any requirement that schools accept vouchers as payment-in-full, nor any other provision to guarantee a reduction in the real cost of private school tuition. The measure was defeated by a final percentage tally of 70.6 to 29.4.

A statewide universal school voucher system providing a maximum tuition subsidy of $3,000 was passed in Utah in 2007, but 62% of voters repealed it in a statewide referendum before it took effect. On April 27, 2011 Indiana passed a statewide voucher program, the largest in the U.S. It offers up to $4,500 to students with household incomes under $41,000, and lesser benefits to households with higher incomes. The vouchers can be used to fund a variety of education options outside the public school system. In March 2013, the Indiana Supreme Court found that the program does not violate the state constitution.

Some private religious schools in voucher programs teach creationism instead of the theory of evolution, including religious schools that teach religious theology side-by-side with or in place of science. Over 300 schools in the US have been documented as teaching creation and receive taxpayer money. Contrary to popular belief , a strict definition of state-funded religious education was narrowly deemed constitutional in "Zelman v. Simmons-Harris" (2002). However, currently 35 states have passed various Blaine Amendments restricting or prohibiting public funding of religious education.



</doc>
<doc id="9751" url="https://en.wikipedia.org/wiki?curid=9751" title="E. B. White">
E. B. White

Elwyn Brooks "E. B." White (July 11, 1899 – October 1, 1985) was an American writer and a world federalist. For more than fifty years, he was a contributor to "The New Yorker" magazine. He was also a co-author of the English language style guide "The Elements of Style", which is commonly known as "Strunk & White". In addition, he wrote books for children, including "Stuart Little" (c. 1945), "Charlotte's Web" (c. 1952), and "The Trumpet of the Swan" (c. 1970). In a 2012 survey of "School Library Journal" readers, "Charlotte's Web" was voted the top children's novel.

White was born in Mount Vernon, New York, the youngest child of Samuel Tilly White, the president of a piano firm, and Jessie Hart White, the daughter of Scottish-American painter William Hart. Elwyn's older brother Stanley Hart White, known as Stan, a professor of landscape architecture and the inventor of the Vertical Garden, taught E. B. White to read and to explore the natural world. White graduated from Cornell University with a bachelor of arts degree in 1921. He got the nickname "Andy" at Cornell, where tradition confers that moniker on any male student whose surname is White, after Cornell co-founder Andrew Dickson White. While at Cornell, he worked as editor of "The Cornell Daily Sun" with classmate Allison Danzig, who later became a sportswriter for "The New York Times". White was also a member of the Aleph Samach and Quill and Dagger societies and Phi Gamma Delta ("Fiji") fraternity.

After graduation, White worked for the United Press (now United Press International) and the American Legion News Service in 1921 and 1922. In 1922-23, he was a cub reporter for "The Seattle Times". On one occasion, when White was stuck writing a story, a Times editor said, "Just say the words." He then worked for almost two years with the Frank Seaman advertising agency as a production assistant and copywriter before returning to New York City in 1924. When "The New Yorker" was founded in 1925, White submitted manuscripts to it. Katharine Angell, the literary editor, recommended to editor-in-chief and founder Harold Ross that White be hired as a staff writer. However, it took months to convince him to come to a meeting at the office and additional weeks to convince him to work on the premises. Eventually, he agreed to work in the office on Thursdays.

In 1929, White and Angell were married. They had a son, Joel White, a naval architect and boat builder, who later owned Brooklin Boat Yard in Brooklin, Maine. Katharine's son from her first marriage, Roger Angell, has spent decades as a fiction editor for "The New Yorker" and is well known as the magazine's baseball writer.

In her foreword to "Charlotte's Web", Kate DiCamillo quotes White as saying, "All that I hope to say in books, all that I ever hope to say, is that I love the world." White also loved animals, farms and farming implements, seasons, and weather formats.

James Thurber described White as a quiet man who disliked publicity and who, during his time at "The New Yorker", would slip out of his office via the fire escape to a nearby branch of Schrafft's to avoid visitors whom he didn't know. 

White suffered from Alzheimer's disease and died on October 1, 1985, at his farm home in North Brooklin, Maine. He is buried in the Brooklin Cemetery beside Katharine, who died in 1977.

E. B. White published his first article in "The New Yorker" in 1925, then joined the staff in 1927 and continued to contribute for almost six decades. Best recognized for his essays and unsigned "Notes and Comment" pieces, he gradually became the magazine's most important contributor, this at a time when it was arguably the most important literary magazine in America. From the beginning to the end of his career at "The New Yorker," he frequently provided what the magazine calls "Newsbreaks" (short, witty comments on oddly worded printed items from many sources) under various categories such as "Block That Metaphor." He also served as a columnist for "Harper's Magazine" from 1938 to 1943.

In 1949, White published "Here Is New York", a short book based on an article he had been commissioned to write for "Holiday". That article reflects the writer's appreciation of a city that provides its residents with both "the gift of loneliness and the gift of privacy." It concludes with a dark note touching on the forces that could destroy the city that he loved. This prescient "love letter" to the city was re-published in 1999 on his centennial with an introduction by his stepson, Roger Angell.

In 1959, White edited and updated "The Elements of Style". This handbook of grammatical and stylistic guidance for writers of American English was first written and published in 1918 by William Strunk Jr., one of White's professors at Cornell. White's reworking of the book was extremely well received, and later editions followed in 1972, 1979, and 1999. Maira Kalman illustrated an edition in 2005. That same year, a New York composer named Nico Muhly premiered a short opera based on the book. The volume is a standard tool for students and writers and remains required reading in many composition classes. The complete history of "The Elements of Style "is detailed in Mark Garvey's "Stylized: A Slightly Obsessive History of Strunk & White's The Elements of Style".

In 1978, White won a special Pulitzer Prize citing "his letters, essays and the full body of his work". He also received the Presidential Medal of Freedom in 1963 and honorary memberships in a variety of literary societies throughout the United States. The 1973 Oscar-nominated Canadian animated short "The Family That Dwelt Apart" is narrated by White and is based on his short story of the same name.

In the late 1930s, White turned his hand to children's fiction on behalf of a niece, Janice Hart White. His first children's book, "Stuart Little", was published in 1945, and "Charlotte's Web" appeared in 1952. "Stuart Little" initially received a lukewarm welcome from the literary community. However, both books went on to receive high acclaim, and "Charlotte's Web" won the Newbery Medal from the American Library Association.

White received the Laura Ingalls Wilder Medal from the U.S. professional children's librarians in 1970. "substantial and lasting contributions to children's literature." That year he was also the U.S. nominee and eventual runner-up for the biennial Hans Christian Andersen Award, as he was again in 1976. Also in 1970, White's third children's novel was published, "The Trumpet of the Swan". In 1973 it won the Sequoyah Award from Oklahoma and the William Allen White Award from Kansas, both selected by students voting for their favorite book of the year. In 2012, School Library Journal sponsored a survey of readers which identified "Charlotte's Web" as the best children's novel ("fictional title for readers 9–12" years old). The librarian who conducted it said, "It is impossible to conduct a poll of this sort and expect [White's novel] to be anywhere


The E.B. White Read Aloud Award is given by The Association of Booksellers for Children (ABC) to honor books that its membership feel embodies the universal read-aloud standards that E. B. White's works created.





</doc>
<doc id="9752" url="https://en.wikipedia.org/wiki?curid=9752" title="Evangelist (Latter Day Saints)">
Evangelist (Latter Day Saints)

In the Latter Day Saint movement, an evangelist is an ordained office of the ministry. In some denominations of the movement, an evangelist is referred to as a patriarch. However, the latter term was deprecated by the Community of Christ after the church began ordaining women to the priesthood. Other denominations, such as The Church of Jesus Christ (Bickertonite), have an evangelist position independent of the original "patriarch" office instituted movement founder Joseph Smith.

The first use of the term "evangelist" in Latter Day Saint theology were mainly consistent with how the term is used by Protestants and Catholics.

In 1833, Joseph Smith introduced the new office of Patriarch, to which he ordained his father. The elder Smith was given the "keys of the patriarchal Priesthood over the kingdom of God on earth", the same power said to be held by the Biblical Patriarchs, which included the power to give blessings upon one's posterity. The elder Smith, however, was also called to give patriarchal blessings to the fatherless within the church, and the church as a whole, a calling he passed onto his eldest surviving son Hyrum Smith prior to his death. Hyrum himself was killed in 1844 along with Joseph, resulting in a succession crisis that broke the Latter Day Saint movement into multiple denominations.

It is not known who first identified the term "evangelist" with the office of patriarch. However, in an 1835 church publication, W. W. Phelps stated,

In 1839, Joseph Smith equated an evangelist with the office of patriarch, stating that "an Evangelist is an Patriarch".

The necessity of an evangelist in the church organization has been reinforced repeatedly, based on the passage in Ephesians 4:11, which states, "And he gave some, apostles; and some, prophets; and some, evangelists; and some, pastors and teachers". In 1834, while writing what he called the "principles of salvation", prominent early Latter Day Saint Oliver Cowdery stated that:

Joseph Smith echoed Cowdery's statement in 1842, in a letter to a Chicago newspaper editor outlining the church's basic beliefs. Smith said that his religion "believe[s] in the same organization that existed in the primitive church, viz: apostles, prophets, pastors, teachers, evangelists".

In the Community of Christ, which was formerly known as the Reorganized Church of Jesus Christ of Latter Day Saints (RLDS Church), an evangelist is an office in the Melchizedec Order of the priesthood. The evangelist was originally called an evangelist-patriarch. This name derived from Latter Day Saint founder Joseph Smith's statement that "an Evangelist is a Patriarch. ... Wherever the Church of Christ is established in the earth, there should be a Patriarch for the benefit of the posterity of the Saints".

An evangelist-patriarch's primary responsibility was to provide special blessings to members of the church; these blessings were considered one of the eight sacraments in the RLDS Church. The local evangelist–patriarchs of the church were governed by an individual with church-wide authority known as the Presiding Patriarch.

In 1984, when the first women began to be ordained to the office of evangelist-patriarch, the RLDS Church changed the title of the local evangelist-patriarchs to simply "evangelist". Similarly, it changed the title of the Presiding Patriarch to the "Presiding Evangelist". To be an evangelist, a person must also be a high priest of the Melchizedec Order of the priesthood.

The primary duty of an evangelist in the Community of Christ remains the giving of sacramental "evangelist's blessings"; it is for this reason that evangelists are often referred to as "ministers of blessing". Ideally, an evangelist is free from administrative responsibilities in the church in order to allow them to be fully responsive to the Holy Spirit. Their blessings—which are given by the laying on of hands—provide counsel and advice and confer spiritual blessings upon the recipient. Evangelist's blessings may or may not be recorded. If it is recorded, a copy is stored in the church archives at Independence, Missouri. A recipient may receive multiple evangelist's blessings in their life.

All evangelists belong to the Order of Evangelists, which is directed by the Presiding Evangelist (currently Jane M. Gardner, since 2016).

In The Church of Jesus Christ (Bickertonite), the prescribed duties of an evangelist are to preach the gospel of Jesus Christ to every nation, kindred, language, and people. An evangelist is part of the Quorum of Seventy Evangelists.

The Quorum of Seventy Evangelists is responsible for management of the International Missionary Programs of the church and assists Regions of the church with their individual Domestic Missionary Programs. The Quorum of Seventy oversees the activities of its Missionary Operating Committees to ensure the fulfilling of Christ’s commandment to take the gospel to the entire world.

In 2007, the officers of the Quorum of Seventy Evangelists were:


In The Church of Jesus Christ of Latter-day Saints (LDS Church), an evangelist is considered to be an office of the Melchizedek priesthood. However, the term "evangelist" is rarely used for this position; instead, the church has retained the term "patriarch", the term most commonly used by Joseph Smith.

The most prominent reference to the term "evangelist" in the LDS Church's literature is found in its "Articles of Faith", derived from the Wentworth letter—a statement by Smith in 1842 to a Chicago newspaper editor—that the church believes in "the same organization that existed in the primitive church", including "evangelists". Smith taught that "an Evangelist is an Patriarch".



</doc>
<doc id="9755" url="https://en.wikipedia.org/wiki?curid=9755" title="Elegiac couplet">
Elegiac couplet

The elegiac couplet is a poetic form used by Greek lyric poets for a variety of themes usually of smaller scale than the epic. Roman poets, particularly Propertius, Tibullus, and Ovid, adopted the same form in Latin many years later. As with the English heroic, each couplet usually makes sense on its own, while forming part of a larger work.

Each couplet consists of a hexameter verse followed by a pentameter verse. The following is a graphic representation of its scansion. Note that - is a long syllable, u a short syllable, and U is either one long syllable or two short syllables:

The form was felt by the ancients to contrast the rising action of the first verse with a falling quality in the second. The sentiment is summarized in a line from Ovid's "Amores" I.1.27 "Sex mihi surgat opus numeris, in quinque residat" - "Let my work rise in six steps, fall back in five." The effect is illustrated by Coleridge as:
translating Schiller,

The elegiac couplet is presumed to be the oldest Greek form of epodic poetry (a form where a later verse is sung in response or comment to a previous one). Scholars, who even in the past did not know who created it, theorize the form was originally used in Ionian dirges, with the name "elegy" derived from the Greek "ε, λεγε ε, λεγε" - "Woe, cry woe, cry!" Hence, the form was used initially for funeral songs, typically accompanied by an aulos, a double-reed instrument. Archilochus expanded use of the form to treat other themes, such as war, travel, or homespun philosophy. Between Archilochus and other imitators, the verse form became a common poetic vehicle for conveying any strong emotion.

At the end of the 7th century BCE, Mimnermus of Colophon struck on the innovation of using the verse for erotic poetry. He composed several elegies celebrating his love for the flute girl Nanno, and though fragmentary today his poetry was clearly influential in the later Roman development of the form. Propertius, to cite one example, notes "Plus in amore valet Mimnermi versus Homero" - "The verse of Mimnermus is stronger in love than Homer".

The form continued to be popular throughout the Greek period and treated a number of different themes. Tyrtaeus composed elegies on a war theme, apparently for a Spartan audience. Theognis of Megara vented himself in couplets as an embittered aristocrat in a time of social change. Popular leaders were writers of elegy—Solon the lawgiver of Athens composed on political and ethical subjects—and even Plato and Aristotle dabbled with the meter. 

By the Hellenistic period, the Alexandrian school made elegy its favorite and most highly developed form. They preferred the briefer style associated with elegy in contrast to the lengthier epic forms, and made it the singular medium for short epigrams. The founder of this school was Philitas of Cos. He was eclipsed only by the school's most admired exponent, Callimachus; their learned character and intricate art would have a heavy influence on the Romans.

Like many Greek forms, elegy was adapted by the Romans for their own literature. The fragments of Ennius contain a few couplets, and scattered verses attributed to Roman public figures like Cicero and Julius Caesar also survive.

But it is the elegists of the mid-to-late first century BCE who are most commonly associated with the distinctive Roman form of the elegiac couplet. Catullus, the first of these, is an invaluable link between the Alexandrine school and the subsequent elegies of Tibullus and Propertius a generation later. His collection, for example, shows a familiarity with the usual Alexandrine style of terse epigram and a wealth of mythological learning, while his 66th poem is a direct translation of Callimachus' "Coma Berenices". Arguably the most famous elegiac couplet in Latin is his two-line 85th poem "Odi et Amo":

Many people, particularly students of Latin, who read this poem aloud often miss the metre because of the high amount of elision in this poem.

Cornelius Gallus is another important statesman/writer of this period, one who was generally regarded by the ancients as among the greatest of the elegists. Other than a few scant lines, all of his work has been lost.

The form reached its zenith with the collections of Tibullus, Propertius, and several collections of Ovid (the "Amores, Heroides, Tristia", and "Epistulae ex Ponto"). The vogue of elegy during this time is seen in the so-called 3rd and 4th books of Tibullus. Many poems in these books were clearly not written by Tibullus but by others, perhaps part of a circle under Tibullus' patron Mesalla. Notable in this collection are the poems of Sulpicia, the only surviving Latin literature written by a woman.

Through these poets—and in comparison with the earlier Catullus—it is possible to trace specific characteristics and evolutionary patterns in the Roman form of the verse:


Although no classical poet wrote collections of love elegies after Ovid, the verse retained its popularity as a vehicle for popular occasional poetry. Elegiac verses appear, for example, in Petronius' "Satyricon", and Martial's Epigrams uses it for many witty stand-alone couplets and for longer pieces. The trend continues through the remainder of the empire; short elegies appear in Apuleius's story "Psyche and Cupid" and the minor writings of Ausonius.

After the fall of the empire, one writer who produced elegiac verse was Maximianus. Various Christian writers also adopted the form; Venantius Fortunatus wrote some of his hymns in the meter, while later Alcuin and the Venerable Bede dabbled in the verse. The form also remained popular among the educated classes for gravestone epitaphs; many such epitaphs can be found in European cathedrals. 

"De tribus puellis" is an example of a Latin "fabliau", a genre of comedy which employed elegiac couplets in imitation of Ovid. The medieval theorist John of Garland wrote that "all comedy is elegy, but the reverse is not true." Medieval Latin had a developed comedic genre known as elegiac comedy. Sometimes narrative, sometimes dramatic, it deviated from ancient practice because, as Ian Thompson writes, "no ancient drama would ever have been written in elegiacs."

With the Renaissance, more skilled writers interested in the revival of Roman culture took on the form in a way which attempted to recapture the spirit of the Augustan writers. The Dutch Latinist Johannes Secundus, for example, included Catullus-inspired love elegies in his "Liber Basiorum", while the English poet John Milton wrote several lengthy elegies throughout his career. This trend continued down through the Recent Latin writers, whose close study of their Augustan counterparts reflects their general attempts to apply the cultural and literary forms of the ancient world to contemporary themes.




</doc>
<doc id="9756" url="https://en.wikipedia.org/wiki?curid=9756" title="Exabyte">
Exabyte

The exabyte is a multiple of the unit byte for digital information. In the International System of Units (SI), the prefix "exa" indicates multiplication by the sixth power of 1000 (10). Therefore, one exabyte is one quintillion bytes (short scale). The symbol for the exabyte is EB.

A related unit, the exbibyte, using a binary prefix, is equal to (=, about 15% larger.

One thousand exabytes (1000 EB) is equal to one zettabyte (1 ZB).


Allegedly, "all words ever spoken by human beings" could be stored in approximately 5 exabytes of data. This claim often cites a project at the UC Berkeley School of Information in support (although this project is now outdated and therefore not entirely accurate). The 2003 University of California Berkeley report credits the estimate to the website of Caltech researcher Roy Williams, where the statement can be found as early as May 1999. This statement has been criticized. Mark Liberman calculated the storage requirements for all human speech at 42 zettabytes (42,000 exabytes, and 8,400 times the original estimate), if digitized as 16 kHz 16-bit audio, although he did freely confess that "maybe the authors [of the exabyte estimate] were thinking about text".

Earlier studies from the University of California, Berkeley, estimated that by the end of 1999, the sum of human-produced information (including all audio, video recordings, and text/books) was about 12 exabytes of data. The 2003 Berkeley report stated that in 2002 alone, "telephone calls worldwide on both landlines and mobile phones contained 17.3 exabytes of new information if stored in digital form" and that "it would take 9.25 exabytes of storage to hold all U.S. [telephone] calls each year". International Data Corporation estimates that approximately 160 exabytes of digital information were created, captured, and replicated worldwide in 2006. Research from University of Southern California estimates that the amount of data stored in the world by 2007 was 295 exabytes and the amount of information shared on two-way communications technology, such as cell phones in 2007 as 65 exabytes.

The content of the Library of Congress is commonly estimated to hold 10 terabytes of data in all printed material. Recent estimates of the size including audio, video, and digital materials start at 3 petabytes to 20 petabytes. Therefore, one exabyte could hold a hundred thousand times the printed material, or 500 to 3000 times all content of the Library of Congress.

In 2013, Randall Munroe compiled published assertions about Google's data centers, and estimated that the company has about 10 exabytes stored on disk, and additionally approximately 5 exabytes on tape backup. The company has refused to comment on Munroe's estimate.



</doc>
<doc id="9758" url="https://en.wikipedia.org/wiki?curid=9758" title="Era">
Era

An era is a span of time defined for the purposes of chronology or historiography, as in the regnal eras in the history of a given monarchy, a calendar era used for a given calendar, or the geological eras defined for the history of Earth.

Comparable terms are epoch, age, period, saeculum, aeon (Greek "aion") and Sanskrit yuga.

The word has been in use in English since 1615, and is derived from Late Latin "aera" "an era or epoch from which time is reckoned," probably identical to Latin "æra" "counters used for calculation," plural of "æs" "brass, money".
The Latin word use in chronology seems to have begun in 5th century Visigothic Spain, where it appears in the "History" of Isidore of Seville, and in later texts. The Spanish era is calculated from 38 BC, perhaps because of a tax (cfr. indiction) levied in that year, or due to a miscalculation of the Battle of Actium, which occurred in 31 BC. 

Like epoch, "era" in English originally meant "the starting point of an age"; the meaning "system of chronological notation" is c.1646; that of "historical period" is 1741.

In chronology, an era is the highest level for the organization of the measurement of time. A calendar era indicates a span of many years which are numbered beginning at a specific reference date (epoch), which often marks the origin of a political state or cosmology, dynasty, ruler, the birth of a leader, or another significant historical or mythological event; it is generally called after its focus accordingly as in "Victorian era".

In large-scale natural science, there is need for another time perspective, independent from human activity, and indeed spanning a far longer period (mainly prehistoric), where "geologic era" refers to well-defined time spans. 
The next-larger division of geologic time is the eon. The Phanerozoic Eon is subdivided into eras. There are currently three eras defined in the Phanerozoic; the following table lists them from youngest to oldest (BP is an abbreviation for "before present").

The older Proterozoic and Archean eons are also divided into eras.

For periods in the history of the universe, the term "epoch" is typically preferred, but "era" is used e.g. of the "Stelliferous Era".

Calendar eras count the years since a particular date (epoch), often one with religious significance. Anno mundi ("year of the world") refers to a group of calendar eras based on a calculation of the age of the world, assuming it was created as described in the Book of Genesis. In Jewish religious contexts one of the versions is still used, and many Eastern Orthodox religious calendars used another version until 1728. Hebrew year 5772 AM began at sunset on 28 September 2011 and ended on 16 September 2012. In the Western church Anno Domini (=AD = CE), counting the years since the birth of Jesus on traditional calculations, was always dominant. 

The Islamic calendar, which also has variants, counts years from the Hijra or emigration of the Islamic prophet Muhammad from Mecca to Medina, which occurred in 622 CE. The Islamic year is some days shorter than 365; January 2012 fell in 1433 AH ("After Hijra").

For a time ranging from 1872 to the Second World War, the Japanese used the imperial year system ("kōki"), counting from the year when the legendary Emperor Jimmu founded Japan which occurred in 660 BC.

Many Buddhist calendars count from the death of the Buddha, which according to the most commonly used calculations was in 545-543 BCE or 483 BCE. Dates are given as "BE" for "Buddhist Era"; 2000 CE was 2543 BE in the Thai solar calendar.

Other calendar eras of the past counted from political events, such as the Seleucid era and the Ancient Roman "ab urbe condita" ("AUC"), counting from the foundation of the city.

The word era also denotes the units used under a different, more arbitrary system where time is not represented as an endless continuum with a single reference year, but each unit starts counting from one again, as if time starts again. The use of regnal years is a rather impractical system, and a challenge for historians if a single piece of the historical chronology is missing, and often reflects the preponderance in public life of an absolute ruler in many ancient cultures. Such traditions sometimes outlive the political power of the throne, and may even be based on mythological events or rulers who may not have existed (for example Rome numbering from the rule of Romulus and Remus). In a manner of speaking the use of the supposed date of the birth of Christ as a base year is a form of an era.
In East Asia, each emperor's reign may be subdivided into several reign periods, each being treated as a new era. The name of each was a motto or slogan chosen by the emperor. Different East Asian countries utilized slightly different systems, notably:


A similar practice survived in the United Kingdom until quite recently, but only for formal official writings: in daily life the ordinary year A.D. has been used for a long time, but Acts of Parliament were dated according to the years of the reign of the current Monarch, so that "61 & 62 Vict c. 37" refers to the Local Government (Ireland) Act 1898 passed in the session of Parliament in the 61st/62nd year of the reign of Queen Victoria.

"Era" can be used to refer to well-defined periods in historiography, such as the Roman era, Elizabethan era, Victorian era, etc.
Use of the term for more recent periods or topical history might include Soviet era, and "" in the history of modern popular music, such as the "Big Band era", "Disco era", etc.



</doc>
<doc id="9760" url="https://en.wikipedia.org/wiki?curid=9760" title="Eschatology">
Eschatology

Eschatology is a part of theology concerned with the final events of history, or the ultimate destiny of humanity. This concept is commonly referred to as the "end of the world" or "end times".

The word arises from the Greek "eschatos" meaning "last" and "-logy" meaning "the study of", and was first used in English around 1844. The Oxford English Dictionary defines eschatology as "the part of theology concerned with death, judgment, and the final destiny of the soul and of humankind".

In the context of mysticism, the phrase refers metaphorically to the end of ordinary reality and reunion with the Divine. In many religions it is taught as an existing future event prophesied in sacred texts or folklore.

History is often divided into "ages" (aeons), which are time periods each with certain commonalities. One age comes to an end and a new age or world to come, where different realities are present, begins. When such transitions from one age to another are the subject of eschatological discussion, the phrase, "end of the world", is replaced by "end of the age", "end of an era", or "end of life as we know it". Much apocalyptic fiction does not deal with the "end of time" but rather with the end of a certain period of time, the end of life as it is now, and the beginning of a new period of time. It is usually a crisis that brings an end to current reality and ushers in a new way of living, thinking, or being. This crisis may take the form of the intervention of a deity in history, a war, a change in the environment, or the reaching of a new level of consciousness.

Most modern eschatology and apocalypticism, both religious and secular, involve the violent disruption or destruction of the world; whereas Christian and Jewish eschatologies view the end times as the consummation or perfection of God's creation of the world, albeit with violent overtures, such as the Great Tribulation. For example, according to some ancient Hebrew worldviews, reality unfolds along a linear path (or rather, a spiral path, with cyclical components that nonetheless have a linear trajectory); the world began with God and is ultimately headed toward God's final goal for creation, the world to come.

Eschatologies vary as to their degree of optimism or pessimism about the future. In some eschatologies, conditions are better for some and worse for others, e.g. "heaven and hell". They also vary as to the time frame. Those claiming "imminent" eschatology are also referred to as Doomsday cults.

In Bahá'í belief, creation has neither a beginning nor an end. Instead, the eschatology of other religions is viewed as symbolic. In Bahá'í belief, human time is marked by a series of progressive revelations in which successive messengers or prophets come from God. The coming of each of these messengers is seen as the day of judgment to the adherents of the previous religion, who may choose to accept the new messenger and enter the "heaven" of belief, or denounce the new messenger and enter the "hell" of denial. In this view, the terms "heaven" and "hell" are seen as symbolic terms for the person's spiritual progress and their nearness to or distance from God. In Bahá'í belief, the coming of Bahá'u'lláh, the founder of the Bahá'í Faith, signals the fulfilment of previous eschatological expectations of Islam, Christianity and other major religions.

Christian eschatology is concerned with death, an intermediate state, Heaven, hell, the return of Jesus, and the resurrection of the dead. Several evangelical denominations include a rapture, a great tribulation, the Millennium, end of the world, the last judgment, a new heaven and a new earth (the World to Come), and the ultimate consummation of all of God's purposes. Eschatological passages are found in many places, esp. Isaiah, Daniel, Ezekiel, Matthew 24, Mark 13, "The Sheep and the Goats", and the Book of Revelation, but Revelation often occupies a central place in Christian eschatology.

The Second Coming of Christ is the central event in Christian eschatology. Most Christians believe that death and suffering will continue to exist until Christ's return. There are, however, various views concerning the order and significance of other eschatological events.

The Book of Revelation is at the core of Christian eschatology. The study of Revelation is usually divided into four interpretative methodologies or hermeneutics. In the Futurist approach, Revelation is treated mostly as unfulfilled prophecy taking place in some yet undetermined future. This is the approach which most applies to eschatological studies. In the Preterist approach, Revelation is chiefly interpreted as having prophetic fulfillment in the past, principally, the events of the first century CE, such as the struggle of Christianity to survive the persecutions of the Roman Empire, the fall of Jerusalem in 70 CE, and the desecration of the Temple in the same year. In the Historicist approach, Revelation provides a broad view of history, and passages in Revelation are identified with major historical people and events. In the Idealist (or Spiritualist or Symbolic) approach, the events of Revelation are neither past nor future, but are purely symbolic, dealing with the ongoing struggle and ultimate triumph of good over evil.

Contemporary Hindu eschatology is linked in the Vaishnavite tradition to the figure of Kalki, the tenth and last avatar of Vishnu before the age draws to a close who will reincarnate as Shiva and simultaneously dissolve and regenerate the universe.

Most Hindus believe that the current period is the Kali Yuga, the last of four "Yuga" that make up the current age. Each period has seen successive degeneration in the moral order, to the point that in the Kali Yuga quarrel and hypocrisy are the norm. In Hinduism, time is cyclic, consisting of cycles or "kalpas". Each kalpa lasts 4.1 – 8.2 billion years, which is a period of one full day and night for Brahma, who in turn will live for 311 trillion, 40 billion years. The cycle of birth, growth, decay, and renewal at the individual level finds its echo in the cosmic order, yet is affected by vagaries of divine intervention in Vaishnavite belief. Some Shaivites hold the view that Shiva is incessantly destroying and creating the world.

Islamic eschatology is documented in the sayings of the Prophet Muhammad, regarding the Signs of the Day of Judgement. The Prophet's sayings on the subject have been traditionally divided into Major and Minor Signs. He spoke about several Minor Signs of the approach of the Day of Judgment, including:

Regarding the Major Signs, a Companion of the Prophet narrated: "Once we were sitting together and talking amongst ourselves when the Prophet appeared. He asked us what it was we were discussing. We said it was the Day of Judgment. He said: 'It will not be called until ten signs have appeared: Smoke, Dajjal (the Antichrist), the creature (that will wound the people), the rising of the sun in the West, the Second Coming of Jesus, the emergence of Gog and Magog, and three sinkings (or cavings in of the earth): one in the East, another in the West and a third in the Arabian Peninsula.'" (note: the previous events were not listed in the chronological order of appearance)

Jewish eschatology is concerned with events that will happen in the end of days, according to the Hebrew Bible and Jewish thought. This includes the ingathering of the exiled diaspora, the coming of the Jewish Messiah, afterlife, and the revival of the dead Tzadikim.

In Judaism, the end times are usually called the "end of days" ("aḥarit ha-yamim", אחרית הימים), a phrase that appears several times in the Tanakh. The idea of a messianic age has a prominent place in Jewish thought, and is incorporated as part of the end of days.

Judaism addresses the end times in the Book of Daniel and numerous other prophetic passages in the Hebrew scriptures, and also in the Talmud, particularly Tractate Avodah Zarah.

Frashokereti is the Zoroastrian doctrine of a final renovation of the universe, when evil will be destroyed, and everything else will then be in perfect unity with God (Ahura Mazda). The doctrinal premises are (1) good will eventually prevail over evil; (2) creation was initially perfectly good, but was subsequently corrupted by evil; (3) the world will ultimately be restored to the perfection it had at the time of creation; (4) the "salvation for the individual depended on the sum of [that person's] thoughts, words and deeds, and there could be no intervention, whether compassionate or capricious, by any divine being to alter this." Thus, each human bears the responsibility for the fate of his own soul, and simultaneously shares in the responsibility for the fate of the world.

Researchers in futures studies and transhumanists investigate how the accelerating rate of scientific progress may lead to a "technological singularity" in the future that would profoundly and unpredictably change the course of human history, and result in "Homo sapiens" no longer being the dominant life form on Earth.

Occasionally the term "physical eschatology" is applied to the long-term predictions of astrophysics. The Sun will turn into a red giant in approximately 6 billion years. Life on Earth will become impossible due to a rise in temperature long before the planet is actually swallowed up by the Sun. Even later, the Sun will become a white dwarf.



</doc>
<doc id="9762" url="https://en.wikipedia.org/wiki?curid=9762" title="Ecumenical council">
Ecumenical council

An ecumenical council (or oecumenical council; also general council) is a conference of ecclesiastical dignitaries and theological experts convened to discuss and settle matters of Church doctrine and practice in which those entitled to vote are convoked from the whole world (oikoumene) and which secures the approbation of the whole Church.

The word "ecumenical" derives from the Late Latin "oecumenicus" "general, universal", from Greek "oikoumenikos" "from the whole world", from "he oikoumene ge" "the inhabited world (as known to the ancient Greeks); the Greeks and their neighbors considered as developed human society (as opposed to barbarian lands)", in later use "the Roman world" and in the Christian sense in ecclesiastical Greek, from "oikoumenos", present passive participle of "oikein" "inhabit", from "oikos" "house, habitation." The first seven Ecumenical Councils, recognised by both the eastern and western denominations comprising Chalcedonian Christianity, were convoked by Christian Roman Emperors, who also enforced the decisions of those councils within the state church of the Roman Empire.

Starting with the third ecumenical council, noteworthy schisms led to non-participation by some members of what had previously been considered a single Christian Church. Thus, some parts of Christianity did not attend later councils, or attended but did not accept the results. Bishops belonging to what became known as the Eastern Orthodox Church accept only seven ecumenical councils, as described below. Bishops belonging to what became known as the Church of the East only participated in the first two councils. Bishops belonging to what became known as Oriental Orthodoxy participated in the first four councils, but rejected the decisions of the fourth and did not attend any subsequent ecumenical councils.

Acceptance of councils as ecumenical and authoritative varies between different Christian denominations. Disputes over christological and other questions have led certain branches to reject some councils that others accept.

The Church of the East (accused by others of adhering to Nestorianism) accepts as ecumenical only the first two councils. Oriental Orthodox Churches accept the first three. Both the Eastern Orthodox Church and Roman Catholic Church recognise as ecumenical the first seven councils, held from the 4th to the 9th century. While the Eastern Orthodox Church accepts no later council or synod as ecumenical, the Roman Catholic Church continues to hold general councils of the bishops in full communion with the Pope, reckoning them as ecumenical. In all, the Roman Catholic Church recognises twenty-one councils as ecumenical. Anglicans and confessional Protestants accept either the first seven or the first four as ecumenical councils.

The doctrine of the "infallibility of ecumenical councils" states that solemn definitions of ecumenical councils, which concern faith or morals, and to which the whole Church must adhere, are infallible. Such decrees are often labeled as 'Canons' and they often have an attached anathema, a penalty of excommunication, against those who refuse to believe the teaching. The doctrine does not claim that every aspect of every ecumenical council is dogmatic, but that every aspect of an ecumenical council is free of errors or is indefectible. 

Both the Eastern Orthodox and the Roman Catholic churches uphold versions of this doctrine. However, the Roman Catholic Church holds that solemn definitions of ecumenical councils meet the conditions of infallibility only when approved by the Pope, while the Eastern Orthodox Church holds that an ecumenical council is itself infallible when pronouncing on a specific matter.

Protestant churches would generally view ecumenical councils as fallible human institutions that have no more than a derived authority to the extent that they correctly expound Scripture (as most would generally consider occurred with the first four councils in regard to their dogmatic decisions).

Church councils were, from the beginning, bureaucratic exercises. Written documents were circulated, speeches made and responded to, votes taken, and final documents published and distributed. A large part of what is known about the beliefs of heresies comes from the documents quoted in councils in order to be refuted, or indeed only from the deductions based on the refutations.

Most councils dealt not only with doctrinal but also with disciplinary matters, which were decided in "canons" ("laws"). Study of the canons of church councils is the foundation of the development of canon law, especially the reconciling of seemingly contradictory canons or the determination of priority between them. Canons consist of doctrinal statements and disciplinary measures – most Church councils and local synods dealt with immediate disciplinary concerns as well as major difficulties of doctrine. Eastern Orthodoxy typically views the purely doctrinal canons as dogmatic and applicable to the entire church at all times, while the disciplinary canons apply to a particular time and place and may or may not be applicable in other situations.

Of the seven councils recognised in whole or in part by both the Roman Catholic and the Eastern Orthodox Church as ecumenical, all were called by a Roman emperor. The emperor gave them legal status within the entire Roman Empire. All were held in the eastern part of the Roman Empire. The bishop of Rome (self-styled as "pope" since the end of the fourth century) did not attend, although he sent legates to some of them.

Church councils were traditional and the ecumenical councils were a continuation of earlier councils (also known as synods) held in the Empire before Christianity was made legal. These include the Council of Jerusalem (c. 50), the Council of Rome (155), the Second Council of Rome (193), the Council of Ephesus (193), the Council of Carthage (251), the Council of Iconium (258), the Council of Antioch (264), the Councils of Arabia (246–247), the Council of Elvira (306), the Council of Carthage (311), the Synod of Neo-Caesarea (c. 314), the Council of Ancyra (314) and the Council of Arles (314).

The first seven councils recognised in both East and West as ecumenical and several others to which such recognition is refused were called by the Byzantine emperors. In the first millennium, various theological and political differences such as Nestorianism or Dyophysitism caused parts of the Church to separate after councils such as those of Ephesus and Chalcedon, but councils recognised as ecumenical continued to be held.

The Council of Hieria of 754, held at the imperial palace of that name close to Chalcedon in Anatolia, was summoned by Byzantine Emperor Constantine V and was attended by 338 bishops, who regarded it as the seventh ecumenical council The Second Council of Nicaea, which annulled that of Hieria, was itself annulled at a synod held in 815 in Constantinople under Emperor Leo V. This synod, presided over by Patriarch Theodotus I of Constantinople, declared the Council of Hieria to be the seventh ecumenical council, but, although the Council of Hieria was called by an emperor and confirmed by another, and although it was held in the east, it later ceased to be considered ecumenical.

Similarly, the Second Council of Ephesus of 449, also held in Anatolia, was called by the Byzantine Emperor Theodosius II and, though annulled by the Council of Chalcedon, was confirmed by Emperor Basiliscus, who annulled the Council of Chalcedon. This too ceased to be considered an ecumenical council.

The Roman Catholic Church does not consider the validity of an ecumenical council's teaching to be in any way dependent on where it is held or on the granting or withholding of prior authorization or legal status by any state, in line with the attitude of the 5th-century bishops who "saw the definition of the church's faith and canons as supremely their affair, with or without the leave of the Emperor" and who "needed no one to remind them that Synodical process pre-dated the Christianisation of the royal court by several centuries".

The Roman Catholic Church recognizes as ecumenical various councils held later than the First Council of Ephesus (after which churches out of communion with the Holy See because of the Nestorian Schism did not participate), later than the Council of Chalcedon (after which there was no participation by churches that rejected Dyophysitism), later than the Second Council of Nicaea (after which there was no participation by the Eastern Orthodox Church), and later than the Fifth Council of the Lateran (after which groups that adhered to Protestantism did not participate).

Of the twenty-one ecumenical councils recognised by the Roman Catholic Church, some gained recognition as ecumenical only later. Thus the Eastern First Council of Constantinople became ecumenical only when its decrees were accepted in the West also.

In the history of Christianity, the first seven ecumenical councils, from the First Council of Nicaea (325) to the Second Council of Nicaea (787), represent an attempt to reach an orthodox consensus and to unify Christendom.

All of the original seven ecumenical councils as recognised in whole or in part were called by an emperor of the Eastern Roman Empire and all were held in the Eastern Roman Empire, a recognition denied to other councils similarly called by an Eastern Roman emperor and held in his territory, in particular the Second Council of Ephesus (449) and the Council of Hieria (754), which saw themselves as ecumenical.

As late as the 11th century, only seven councils were recognised as ecumenical in the Roman Catholic Church. Then, in the time of Pope Gregory VII (1073–1085), canonists who in the Investiture Controversy quoted the prohibition in canon 22 of the Council of Constantinople of 869–870 against laymen influencing the appointment of prelates elevated this council to the rank of ecumenical council. Only in the 16th century was recognition as ecumenical granted by Catholic scholars to the Councils of the Lateran, of Lyon and those that followed. The following is a list of further councils generally recognised as ecumenical by Roman Catholic theologians:

Eastern Orthodox catechisms teach that there are seven ecumenical councils and there are feast days for seven ecumenical councils. Nonetheless, some Eastern Orthodox consider the Council of Constantinople of 879–880, that of Constantinople in 1341–1351 and that of Jerusalem in 1672 to be ecumenical:

It is unlikely that formal ecumenical recognition will be granted to these councils, despite the acknowledged orthodoxy of their decisions, so that only seven are universally recognized among the Eastern Orthodox as ecumenical.

The 2016 Pan-Orthodox Council was sometimes referred to as a potential "Eighth Ecumenical Council".

Although some Protestants reject the concept of an ecumenical council establishing doctrine for the entire Christian faith, Roman Catholics, Lutherans, Anglicans, Eastern Orthodox and Oriental Orthodox all accept the authority of ecumenical councils in principle. Where they differ is in which councils they accept and what the conditions are for a council to be considered "ecumenical". The relationship of the Papacy to the validity of ecumenical councils is a ground of controversy between Roman Catholicism and the Eastern Orthodox Churches. The Roman Catholic Church holds that recognition by the Pope is an essential element in qualifying a council as ecumenical; Eastern Orthodox view approval by the Bishop of Rome (the Pope) as being roughly equivalent to that of other patriarchs.
Some have held that a council is ecumenical only when all five patriarchs of the Pentarchy are represented at it. Others reject this theory in part because there were no patriarchs of Constantinople and Jerusalem at the time of the first ecumenical council.

The Church of the East accepts two ecumenical councils, the First Council of Nicaea and the First Council of Constantinople. It was the formulation of Mary as the Theotokos which caused a schism with the Church of the East, now divided between the Assyrian Church of the East and the Ancient Church of the East, while the Chaldean Catholic Church entered into full communion with Rome in the 16th century. Meetings between Pope John Paul II and the Assyrian Patriarch Mar Dinkha IV led to a common Christological declaration on 11 November 1994 that "the humanity to which the Blessed Virgin Mary gave birth always was that of the Son of God himself". Both sides recognised the legitimacy and rightness, as expressions of the same faith, of the Assyrian Church's liturgical invocation of Mary as "the Mother of Christ our God and Saviour" and the Catholic Church's use of "the Mother of God" and also as "the Mother of Christ".

Oriental Orthodoxy accepts three ecumenical councils, the First Council of Nicaea, the First Council of Constantinople, and the Council of Ephesus. The formulation of the Chalcedonian Creed caused a schism in the Alexandrian and Syriac churches. Reconciliatory efforts between Oriental Orthodox with the Eastern Orthodox and the Catholic Church in the mid- and late-20th century have led to common Christological declarations. The Oriental and Eastern Churches have also been working toward reconciliation as a consequence of the ecumenical movement.

The Oriental Orthodox hold that the Dyophysite formula of two natures formulated at the Council of Chalcedon is inferior to the Miaphysite formula of "One Incarnate Nature of God the Word" (Byzantine Greek: Mia physis tou theou logou sarkousomene) and that the proceedings of Chalcedon themselves were motivated by imperial politics. The Alexandrian Church, the main Oriental Orthodox body, also felt unfairly underrepresented at the council following the deposition of their Pope, Dioscorus of Alexandria at the council.

The Eastern Orthodox Church accepts seven ecumenical councils, with the disputed Council in Trullo - rejected by Catholics - being incorporated into, and considered as a continuation of, the Third Council of Constantinople.

To be considered ecumenical, Orthodox accept a council that meets the condition that it was accepted by the whole church. That it was called together legally is also an important factor. A case in point is the Third Ecumenical Council, where two groups met as duly called for by the emperor, each claiming to be the legitimate council. The Emperor had called for bishops to assemble in the city of Ephesus. Theodosius did not attend but sent his representative Candidian to preside. However, Cyril managed to open the council over Candidian's insistent demands that the bishops disperse until the delegation from Syria could arrive. Cyril was able to completely control the proceedings, completely neutralizing Candidian, who favored Cyril's antagonist, Nestorius. When the pro-Nestorius Antiochene delegation finally arrived, they decided to convene their own council, over which Candidian presided. The proceedings of both councils were reported to the emperor, who decided ultimately to depose Cyril, Memnon and Nestorius. Nonetheless, the Orthodox accept Cyril's group as being the legitimate council because it maintained the same teaching that the church has always taught.

Paraphrasing a rule by St Vincent of Lérins, Hasler states
Orthodox believe that councils could over-rule or even depose popes. At the Sixth Ecumenical Council, Pope Honorius and Patriarch Sergius were declared heretics. The council anathematized them and declared them tools of the devil and cast them out of the church.

It is their position that, since the Seventh Ecumenical Council, there has been no synod or council of the same scope. Local meetings of hierarchs have been called "pan-Orthodox", but these have invariably been simply meetings of local hierarchs of whatever Eastern Orthodox jurisdictions are party to a specific local matter. From this point of view, there has been no fully "pan-Orthodox" (Ecumenical) council since 787. Unfortunately, the use of the term "pan-Orthodox" is confusing to those not within Eastern Orthodoxy, and it leads to mistaken impressions that these are "ersatz" ecumenical councils rather than purely local councils to which nearby Orthodox hierarchs, regardless of jurisdiction, are invited.

Others, including 20th century theologians Metropolitan Hierotheos (Vlachos) of Naupactus, Fr. John S. Romanides, and Fr. George Metallinos (all of whom refer repeatedly to the "Eighth and Ninth Ecumenical Councils"), Fr. George Dragas, and the 1848 Encyclical of the Eastern Patriarchs (which refers explicitly to the "Eighth Ecumenical Council" and was signed by the patriarchs of Constantinople, Jerusalem, Antioch, and Alexandria as well as the Holy Synods of the first three), regard other synods beyond the Seventh Ecumenical Council as being ecumenical.
From the Eastern Orthodox perspective, a council is accepted as being ecumenical if it is accepted by the Eastern Orthodox church at large – clergy, monks and assembly of believers. Teachings from councils that purport to be ecumenical, but which lack this acceptance by the church at large, are, therefore, not considered ecumenical.

Both the Roman Catholic and Eastern Orthodox churches recognize seven councils in the early centuries of the church, but Roman Catholics also recognize fourteen councils in later times called or confirmed by the Pope. At the urging of German King Sigismund, who was to become Holy Roman Emperor in 1433, the Council of Constance was convoked in 1414 by Antipope John XXIII, one of three claimants to the papal throne, and was reconvened in 1415 by the Roman Pope Gregory XII. The Council of Florence is an example of a council accepted as ecumenical in spite of being rejected by the East, as the Councils of Ephesus and Chalcedon are accepted in spite of being rejected respectively by the Church of the East and Oriental Orthodoxy.

The Roman Catholic Church teaches that an ecumenical council is a gathering of the College of Bishops (of which the Bishop of Rome is an essential part) to exercise in a solemn manner its supreme and full power over the whole Church. It holds that "there never is an ecumenical council which is not confirmed or at least recognized as such by Peter's successor". Its present canon law requires that an ecumenical council be convoked and presided over, either personally or through a delegate, by the Pope, who is also to decide the agenda; but the church makes no claim that all past ecumenical councils observed these present rules, declaring only that the Pope's confirmation or at least recognition has always been required, and saying that the version of the Nicene Creed adopted at the First Council of Constantinople (381) was accepted by the Church of Rome only seventy years later, in 451. One writer has even claimed that this council was summoned without the knowledge of the pope.

While the Councils are part of the "historic formularies" of Anglican tradition, it is difficult to locate an explicit reference in Anglicanism to the unconditional acceptance of all Seven Ecumenical Councils. There is little evidence of dogmatic or canonical acceptance beyond the statements of individual Anglican theologians and bishops.

Bishop Chandler Holder Jones, SSC, explains:
He quotes William Tighe, Associate Professor of History at Muhlenberg College in Allentown, Pennsylvania (another member of the Anglo-Catholic wing of Anglicanism):
Article XXI teaches: "General Councils ... when they be gathered together, forasmuch as they be an assembly of men, whereof all be not governed with the Spirit and word of God, they may err and sometime have erred, even in things pertaining to God. Wherefore things ordained by them as necessary to salvation have neither strength nor authority, unless it may be declared that they be taken out of Holy Scripture."

The 19th Canon of 1571 asserted the authority of the Councils in this manner: "Let preachers take care that they never teach anything...except what is agreeable to the doctrine of the Old and New Testament, and what the Catholic Fathers and ancient Bishops have collected from the same doctrine." This remains the Church of England's teaching on the subject. A modern version of this appeal to catholic consensus is found in the Canon Law of the Church of England and also in the liturgy published in "Common Worship":

Many Protestants (especially those belonging to the magisterial traditions, such as Lutherans, or those such as Methodists, that broke away from the Anglican Communion) accept the teachings of the first seven councils but do not ascribe to the councils themselves the same authority as Roman Catholics and the Eastern Orthodox do. The Lutheran World Federation, in ecumenical dialogues with the Ecumenical Patriarch of Constantinople has affirmed all of the first seven councils as ecumenical and authoritative.

Some, including some fundamentalist Christians, condemn the ecumenical councils for other reasons. Independency or congregationalist polity among Protestants may involve the rejection of any governmental structure or binding authority above local congregations; conformity to the decisions of these councils is therefore considered purely voluntary and the councils are to be considered binding only insofar as those doctrines are derived from the Scriptures. Many of these churches reject the idea that anyone other than the authors of Scripture can directly lead other Christians by original divine authority; after the New Testament, they assert, the doors of revelation were closed and councils can only give advice or guidance, but have no authority. They consider new doctrines not derived from the sealed canon of Scripture to be both impossible and unnecessary whether proposed by church councils or by more recent prophets. Catholic and Orthodox objections to this position point to the fact that the Canon of Scripture itself was fixed by these councils. They conclude that this would lead to a logical inconsistency of a non-authoritative body fixing a supposedly authoritative source.

Ecumenical councils are not recognised by nontrinitarian churches such as The Church of Jesus Christ of Latter-day Saints (and other denominations within the Latter Day Saint movement), Jehovah's Witnesses, Church of God (Seventh-Day), their descendants and Unitarians. They view the ecumenical councils as misguided human attempts to establish doctrine, and as attempts to define dogmas by debate rather than by revelation.





</doc>
<doc id="9763" url="https://en.wikipedia.org/wiki?curid=9763" title="Exoplanet">
Exoplanet

An exoplanet (, ) or extrasolar planet is a planet outside our solar system that orbits a star. The first evidence of an exoplanet was noted as early as 1917, but was not recognized as such. However, the first scientific detection of an exoplanet was in 1988. Shortly afterwards, the first confirmed detection was in 1992. 

The High Accuracy Radial Velocity Planet Searcher (HARPS, since 2004) has discovered about a hundred exoplanets while the "Kepler" space telescope (since 2009) has found more than two thousand. "Kepler" has also detected a few thousand candidate planets, of which about 11% may be false positives.
In several cases, multiple planets have been observed around a star.
About 1 in 5 Sun-like stars have an "Earth-sized" planet in the habitable zone. Assuming there are 200 billion stars in the Milky Way, one can hypothesize that there are 11 billion potentially habitable Earth-sized planets in the Milky Way, rising to 40 billion if planets orbiting the numerous red dwarfs are included.

The least massive planet known is Draugr (also known as PSR B1257+12 A or PSR B1257+12 b), which is about twice the mass of the Moon. The most massive planet listed on the NASA Exoplanet Archive is HR 2562 b, about 30 times the mass of Jupiter, although according to some definitions of a planet, it is too massive to be a planet and may be a brown dwarf instead. There are planets that are so near to their star that they take only a few hours to orbit and there are others so far away that they take thousands of years to orbit. Some are so far out that it is difficult to tell whether they are gravitationally bound to the star. Almost all of the planets detected so far are within the Milky Way. Nonetheless, evidence suggests that extragalactic planets, exoplanets further away in galaxies beyond the local Milky Way galaxy, may exist. The nearest exoplanet is Proxima Centauri b, located 4.2 light-years (1.3 parsecs) from Earth and orbiting Proxima Centauri, the closest star to the Sun.

The discovery of exoplanets has intensified interest in the search for extraterrestrial life. There is special interest in planets that orbit in a star's habitable zone, where it is possible for liquid water, a prerequisite for life on Earth, to exist on the surface. The study of planetary habitability also considers a wide range of other factors in determining the suitability of a planet for hosting life.

Besides exoplanets, there are also rogue planets, which do not orbit any star and which tend to be considered separately, especially if they are gas giants, in which case they are often counted, like WISE 0855−0714, as sub-brown dwarfs. The rogue planets in the Milky Way possibly number in the billions (or more).

<section begin=nomenclature />
The convention for designating exoplanets is an extension of the system used for designating multiple-star systems as adopted by the International Astronomical Union (IAU). For exoplanets orbiting a single star, the designation is normally formed by taking the name or, more commonly, designation of its parent star and adding a lower case letter. The first planet discovered in a system is given the designation "b" (the parent star is considered to be "a") and later planets are given subsequent letters. If several planets in the same system are discovered at the same time, the closest one to the star gets the next letter, followed by the other planets in order of orbital size. A provisional IAU-sanctioned standard exists to accommodate the designation of circumbinary planets. A limited number of exoplanets have IAU-sanctioned proper names. Other naming systems exist.<section end=nomenclature />

For centuries scientists, philosophers, and science fiction writers suspected that extrasolar planets existed, but there was no way of detecting them or of knowing their frequency or how similar they might be to the planets of the Solar System. Various detection claims made in the nineteenth century were rejected by astronomers. The first evidence of an exoplanet was noted as early as 1917, but was not recognized as such. However, the first scientific detection of an exoplanet began in 1988. Shortly afterwards, the first confirmed detection came in 1992, with the discovery of several terrestrial-mass planets orbiting the pulsar PSR B1257+12. The first confirmation of an exoplanet orbiting a main-sequence star was made in 1995, when a giant planet was found in a four-day orbit around the nearby star 51 Pegasi. Some exoplanets have been imaged directly by telescopes, but the vast majority have been detected through indirect methods, such as the transit method and the radial-velocity method. As of February 2018, researchers at the Chandra X-ray Observatory, combined with a planet detection technique called microlensing, found evidence that there are potentially one trillion extragalactic exoplanets, stating "Some of these exoplanets are as (relatively) small as the moon, while others are as massive as Jupiter. Unlike Earth, most of the exoplanets are not tightly bound to stars, so they're actually wandering through space or loosely orbiting between stars. We can estimate that the number of planets in this [faraway] galaxy is more than a trillion."

In the sixteenth century the Italian philosopher Giordano Bruno, an early supporter of the Copernican theory that Earth and other planets orbit the Sun (heliocentrism), put forward the view that the fixed stars are similar to the Sun and are likewise accompanied by planets.

In the eighteenth century the same possibility was mentioned by Isaac Newton in the "General Scholium" that concludes his "Principia". Making a comparison to the Sun's planets, he wrote "And if the fixed stars are the centres of similar systems, they will all be constructed according to a similar design and subject to the dominion of "One"."

In 1952, more than 40 years before the first hot Jupiter was discovered, Otto Struve wrote that there is no compelling reason why planets could not be much closer to their parent star than is the case in the Solar System, and proposed that Doppler spectroscopy and the transit method could detect super-Jupiters in short orbits.

Claims of exoplanet detections have been made since the nineteenth century. Some of the earliest involve the binary star 70 Ophiuchi. In 1855 William Stephen Jacob at the East India Company's Madras Observatory reported that orbital anomalies made it "highly probable" that there was a "planetary body" in this system. In the 1890s, Thomas J. J. See of the University of Chicago and the United States Naval Observatory stated that the orbital anomalies proved the existence of a dark body in the 70 Ophiuchi system with a 36-year period around one of the stars. However, Forest Ray Moulton published a paper proving that a three-body system with those orbital parameters would be highly unstable. During the 1950s and 1960s, Peter van de Kamp of Swarthmore College made another prominent series of detection claims, this time for planets orbiting Barnard's Star. Astronomers now generally regard all the early reports of detection as erroneous.

In 1991 Andrew Lyne, M. Bailes and S. L. Shemar claimed to have discovered a pulsar planet in orbit around PSR 1829-10, using pulsar timing variations. The claim briefly received intense attention, but Lyne and his team soon retracted it.

As of , a total of confirmed exoplanets are listed in the Extrasolar Planets Encyclopaedia, including a few that were confirmations of controversial claims from the late 1980s. The first published discovery to receive subsequent confirmation was made in 1988 by the Canadian astronomers Bruce Campbell, G. A. H. Walker, and Stephenson Yang of the University of Victoria and the University of British Columbia. Although they were cautious about claiming a planetary detection, their radial-velocity observations suggested that a planet orbits the star Gamma Cephei. Partly because the observations were at the very limits of instrumental capabilities at the time, astronomers remained skeptical for several years about this and other similar observations. It was thought some of the apparent planets might instead have been brown dwarfs, objects intermediate in mass between planets and stars. In 1990 additional observations were published that supported the existence of the planet orbiting Gamma Cephei, but subsequent work in 1992 again raised serious doubts. Finally, in 2003, improved techniques allowed the planet's existence to be confirmed.

On 9 January 1992, radio astronomers Aleksander Wolszczan and Dale Frail announced the discovery of two planets orbiting the pulsar PSR 1257+12. This discovery was confirmed, and is generally considered to be the first definitive detection of exoplanets. Follow-up observations solidified these results, and confirmation of a third planet in 1994 revived the topic in the popular press. These pulsar planets are thought to have formed from the unusual remnants of the supernova that produced the pulsar, in a second round of planet formation, or else to be the remaining rocky cores of gas giants that somehow survived the supernova and then decayed into their current orbits.

On 6 October 1995, Michel Mayor and Didier Queloz of the University of Geneva announced the first definitive detection of an exoplanet orbiting a main-sequence star, namely the nearby G-type star 51 Pegasi. This discovery, made at the Observatoire de Haute-Provence, ushered in the modern era of exoplanetary discovery. Technological advances, most notably in high-resolution spectroscopy, led to the rapid detection of many new exoplanets: astronomers could detect exoplanets indirectly by measuring their gravitational influence on the motion of their host stars. More extrasolar planets were later detected by observing the variation in a star's apparent luminosity as an orbiting planet passed in front of it.

Initially, most known exoplanets were massive planets that orbited very close to their parent stars. Astronomers were surprised by these "hot Jupiters", because theories of planetary formation had indicated that giant planets should only form at large distances from stars. But eventually more planets of other sorts were found, and it is now clear that hot Jupiters make up the minority of exoplanets. In 1999, Upsilon Andromedae became the first main-sequence star known to have multiple planets. Kepler-16 contains the first discovered planet that orbits around a binary main-sequence star system.

On 26 February 2014, NASA announced the discovery of 715 newly verified exoplanets around 305 stars by the Kepler Space Telescope. These exoplanets were checked using a statistical technique called "verification by multiplicity". Prior to these results, most confirmed planets were gas giants comparable in size to Jupiter or larger as they are more easily detected, but the Kepler planets are mostly between the size of Neptune and the size of Earth.

On 23 July 2015, NASA announced Kepler-452b, a near-Earth-size planet orbiting the habitable zone of a G2-type star.

As of June 2017, NASA's Kepler mission had identified more than 5,000 planetary candidates, several of them being nearly Earth-sized and located in the habitable zone, some around Sun-like stars.
The first exoplanet was detected on 6 October 1995, and was named 51 Pegasi b. When an extrasolar planet is observed to transit its parent star, astronomers are able to assess some physical properties of the planet from an interstellar distance, including planetary mass and size, which in turn provide fundamental constraints on models of their physical structure. Furthermore, such events afford the opportunity to study the dynamics and chemistry of its atmosphere.

Statistical surveys and individual characterization are the keys to addressing the fundamental questions in exoplanetology. As of August 2016, varying techniques have been used to discover 3,502 exoplanets. Documenting the properties of a large sample exoplanets at various ages, orbiting their parent stars of various types, will contribute to increased understanding —or better models— of planetary formation (accretion), geological evolution, orbit migration, and their potential habitability. Characterizing the atmospheres of extrasolar planets is the new frontier in exoplanetary science.

<section begin=detection />

About 97% of all the confirmed exoplanets have been discovered by indirect techniques of detection, mainly by radial velocity measurements and transit monitoring techniques. The following methods have proved successful for discovering a new planet or confirming an already discovered planet:
<section end=detection />

Planets form within a few tens of millions of years of their star forming. The planets of the Solar System can only be observed in their current state, but observations of different planetary systems of varying ages allows us to observe planets at different stages of evolution. Available observations range from young proto-planetary disks where planets are still forming to planetary systems of over 10 Gyr old. When terrestrial planets form in a gaseous protoplanetary disk, they have hydrogen envelopes that cool and contract over time and, depending on the mass of the planet, some or all of the hydrogen is eventually lost to space. This means that even terrestrial planets may start off with large radii if they form early enough. An example is Kepler-51b which has only about twice the mass of Earth but is almost the size of Saturn which is a hundred times the mass of Earth. Kepler-51b is quite young at a few hundred million years old.

There is at least one planet on average per star.
About 1 in 5 Sun-like stars have an "Earth-sized" planet in the habitable zone.

Most known exoplanets orbit stars roughly similar to the Sun, i.e. main-sequence stars of spectral categories F, G, or K. Lower-mass stars (red dwarfs, of spectral category M) are less likely to have planets massive enough to be detected by the radial-velocity method. Despite this, several tens of planets around red dwarfs have been discovered by the "Kepler" spacecraft, which uses the transit method to detect smaller planets.

Using data from Kepler, a correlation has been found between the metallicity of a star and the probability that the star host planets. Stars with higher metallicity are more likely to have planets, especially giant planets, than stars with lower metallicity.

Some planets orbit one member of a binary star system, and several circumbinary planets have been discovered which orbit around both members of binary star. A few planets in triple star systems are known and one in the quadruple system Kepler-64.

In 2013 the color of an exoplanet was determined for the first time. The best-fit albedo measurements of HD 189733b suggest that it is deep dark blue. Later that same year, the colors of several other exoplanets were determined, including GJ 504 b which visually has a magenta color, and Kappa Andromedae b, which if seen up close would appear reddish in color.

The apparent brightness (apparent magnitude) of a planet depends on how far away the observer is, how reflective the planet is (albedo), and how much light the planet receives from its star, which depends on how far the planet is from the star and how bright the star is. So, a planet with a low albedo that is close to its star can appear brighter than a planet with high albedo that is far from the star.

The darkest known planet in terms of geometric albedo is TrES-2b, a hot Jupiter that reflects less than 1% of the light from its star, making it less reflective than coal or black acrylic paint. Hot Jupiters are expected to be quite dark due to sodium and potassium in their atmospheres but it is not known why TrES-2b is so dark—it could be due to an unknown chemical.

For gas giants, geometric albedo generally decreases with increasing metallicity or atmospheric temperature unless there are clouds to modify this effect. Increased cloud-column depth increases the albedo at optical wavelengths, but decreases it at some infrared wavelengths. Optical albedo increases with age, because older planets have higher cloud-column depths. Optical albedo decreases with increasing mass, because higher-mass giant planets have higher surface gravities, which produces lower cloud-column depths. Also, elliptical orbits can cause major fluctuations in atmospheric composition, which can have a significant effect.

There is more thermal emission than reflection at some near-infrared wavelengths for massive and/or young gas giants. So, although optical brightness is fully phase-dependent, this is not always the case in the near infrared.

Temperatures of gas giants reduce over time and with distance from their star. Lowering the temperature increases optical albedo even without clouds. At a sufficiently low temperature, water clouds form, which further increase optical albedo. At even lower temperatures ammonia clouds form, resulting in the highest albedos at most optical and near-infrared wavelengths.

In 2014, a magnetic field around HD 209458 b was inferred from the way hydrogen was evaporating from the planet. It is the first (indirect) detection of a magnetic field on an exoplanet. The magnetic field is estimated to be about one tenth as strong as Jupiter's.

Interaction between a close-in planet's magnetic field and a star can produce spots on the star in a similar way to how the Galilean moons produce aurorae on Jupiter.
Auroral radio emissions could be detected with radio telescopes such as LOFAR.
The radio emissions could enable determination of the rotation rate of a planet which is difficult to detect otherwise.

Earth's magnetic field results from its flowing liquid metallic core, but in massive super-Earths with high pressure, different compounds may form which do not match those created under terrestrial conditions. Compounds may form with greater viscosities and high melting temperatures which could prevent the interiors from separating into different layers and so result in undifferentiated coreless mantles. Forms of magnesium oxide such as MgSiO could be a liquid metal at the pressures and temperatures found in super-Earths and could generate a magnetic field in the mantles of super-Earths.

Hot Jupiters have been observed to have a larger radius than expected. This could be caused by the interaction between the stellar wind and the planet's magnetosphere creating an electric current through the planet that heats it up causing it to expand. The more magnetically active a star is the greater the stellar wind and the larger the electric current leading to more heating and expansion of the planet. This theory matches the observation that stellar activity is correlated with inflated planetary radii.

In 2007, two independent teams of researchers came to opposing conclusions about the likelihood of plate tectonics on larger super-Earths with one team saying that plate tectonics would be episodic or stagnant and the other team saying that plate tectonics is very likely on super-Earths even if the planet is dry.

If super-Earths have more than 80 times as much water as Earth then they become ocean planets with all land completely submerged. However, if there is less water than this limit, then the deep water cycle will move enough water between the oceans and mantle to allow continents to exist.

Large surface temperature variations on 55 Cancri e have been attributed to possible volcanic activity releasing large clouds of dust which blanket the planet and block thermal emissions.

The star 1SWASP J140747.93-394542.6 is orbited by an object that is circled by a ring system much larger than Saturn's rings. However, the mass of the object is not known; it could be a brown dwarf or low-mass star instead of a planet.

The brightness of optical images of Fomalhaut b could be due to starlight reflecting off a circumplanetary ring system with a radius between 20 and 40 times that of Jupiter's radius, about the size of the orbits of the Galilean moons.

The rings of the Solar System's gas giants are aligned with their planet's equator. However, for exoplanets that orbit close to their star, tidal forces from the star would lead to the outermost rings of a planet being aligned with the planet's orbital plane around the star. A planet's innermost rings would still be aligned with the planet's equator so that if the planet has a tilted rotational axis, then the different alignments between the inner and outer rings would create a warped ring system.

In December 2013 a candidate exomoon of a rogue planet was announced. No exomoons have been confirmed so far.

Atmospheres have been detected around several exoplanets. The first to be observed was HD 209458 b in 2001.

KIC 12557548 b is a small rocky planet, very close to its star, that is evaporating and leaving a trailing tail of cloud and dust like a comet. The dust could be ash erupting from volcanos and escaping due to the small planet's low surface-gravity, or it could be from metals that are vaporized by the high temperatures of being so close to the star with the metal vapor then condensing into dust.

In June 2015, scientists reported that the atmosphere of GJ 436 b was evaporating, resulting in a giant cloud around the planet and, due to radiation from the host star, a long trailing tail long.

In May 2017, glints of light from Earth, seen as twinkling from an orbiting satellite a million miles away, were found to be reflected light from ice crystals in the atmosphere. The technology used to determine this may be useful in studying the atmospheres of distant worlds, including those of exoplanets.

Tidally locked planets in a 1:1 spin–orbit resonance would have their star always shining directly overhead on one spot which would be hot with the opposite hemisphere receiving no light and being freezing cold. Such a planet could resemble an eyeball with the hotspot being the pupil. Planets with an eccentric orbit could be locked in other resonances. 3:2 and 5:2 resonances would result in a double-eyeball pattern with hotspots in both eastern and western hemispheres. Planets with both an eccentric orbit and a tilted axis of rotation would have more complicated insolation patterns.
As more planets are discovered, the field of exoplanetology continues to grow into a deeper study of extrasolar worlds, and will ultimately tackle the prospect of life on planets beyond the Solar System. At cosmic distances, life
can only be detected if it is developed at a planetary scale and strongly modified the planetary
environment, in such a way that the modifications cannot be explained by classical physico-chemical processes (out of equilibrium processes). For example, molecular oxygen () in the atmosphere of Earth is a result of photosynthesis by living plants and many kinds of microorganisms, so it can be used as an indication of life on exoplanets, although small amounts of oxygen could also be produced by non-biological means. Furthermore, a potentially habitable planet must orbit a stable star at a distance within which planetary-mass objects with sufficient atmospheric pressure can support liquid water at their surfaces.




</doc>
<doc id="9764" url="https://en.wikipedia.org/wiki?curid=9764" title="Emma Goldman">
Emma Goldman

Emma Goldman (, 1869May 14, 1940) was an anarchist political activist and writer. She played a pivotal role in the development of anarchist political philosophy in North America and Europe in the first half of the 20th century.

Born in Kovno, Russian Empire (now Kaunas, Lithuania) to a Jewish family, Goldman emigrated to the United States in 1885. Attracted to anarchism after the Haymarket affair, Goldman became a writer and a renowned lecturer on anarchist philosophy, women's rights, and social issues, attracting crowds of thousands. She and anarchist writer Alexander Berkman, her lover and lifelong friend, planned to assassinate industrialist and financier Henry Clay Frick as an act of propaganda of the deed. Frick survived the attempt on his life in 1892 and Berkman was sentenced to 22 years in prison. Goldman was imprisoned several times in the years that followed, for "inciting to riot" and illegally distributing information about birth control. In 1906, Goldman founded the anarchist journal "Mother Earth".

In 1917, Goldman and Berkman were sentenced to two years in jail for conspiring to "induce persons not to register" for the newly-instated draft. After their release from prison, they were arrested—along with hundreds of others—and deported to Russia. Initially supportive of that country's October Revolution which brought the Bolsheviks to power, Goldman reversed her opinion in the wake of the Kronstadt rebellion and denounced the Soviet Union for its violent repression of independent voices. In 1923, she published a book about her experiences, "My Disillusionment in Russia". While living in England, Canada, and France, she wrote an autobiography called "Living My Life". After the outbreak of the Spanish Civil War, she traveled to Spain to support the anarchist revolution there. She died in Toronto on May 14, 1940, aged 70.

During her life, Goldman was lionized as a freethinking "rebel woman" by admirers, and denounced by detractors as an advocate of politically motivated murder and violent revolution. Her writing and lectures spanned a wide variety of issues, including prisons, atheism, freedom of speech, militarism, capitalism, marriage, free love, and homosexuality. Although she distanced herself from first-wave feminism and its efforts toward women's suffrage, she developed new ways of incorporating gender politics into anarchism. After decades of obscurity, Goldman gained iconic status by a revival of interest in her life in the 1970s, when feminist and anarchist scholars rekindled popular interest.

Emma Goldman's Orthodox Jewish family lived in Kovno in the Russian Empire, which is now the Lithuanian city of Kaunas. Goldman's mother Taube Bienowitch had been married before to a man with whom she had two daughters—Helena in 1860 and Lena in 1862. When her first husband died of tuberculosis, Taube was devastated. Goldman later wrote: "Whatever love she had had died with the young man to whom she had been married at the age of fifteen."

Taube's second marriage was arranged by her family and, as Goldman puts it, "mismated from the first". Her second husband, Abraham Goldman, invested Taube's inheritance in a business that quickly failed. The ensuing hardship combined with the emotional distance of husband and wife to make the household a tense place for the children. When Taube became pregnant, Abraham hoped desperately for a son; a daughter, he believed, would serve as one more sign of failure. They eventually had three sons, but their first child was Emma.

Emma Goldman was born on June 27, 1869. Her father used violence to punish his children, beating them when they disobeyed him. He used a whip on Emma, the most rebellious of them. Her mother provided scarce comfort, rarely calling on Abraham to tone down his beatings. Goldman later speculated that her father's furious temper was at least partly a result of sexual frustration.

Goldman's relationships with her elder half-sisters, Helena and Lena, were a study in contrasts. Helena, the oldest, provided the comfort they lacked from their mother; she filled Goldman's childhood with "whatever joy it had". Lena, however, was distant and uncharitable. The three sisters were joined by brothers Louis (who died at the age of six), Herman (born in 1872), and Moishe (born in 1879).

When Emma was a young girl, the Goldman family moved to the village of Papilė, where her father ran an inn. While her sisters worked, she became friends with a servant named Petrushka, who excited her "first erotic sensations". Later in Papilė she witnessed a peasant being whipped with a knout in the street. This event traumatized her and contributed to her lifelong distaste for violent authority.

At the age of seven, Goldman moved with her family to the Prussian city of Königsberg (then part of the German Empire), and she enrolled in a Realschule. One teacher punished disobedient students—targeting Goldman in particular—by beating their hands with a ruler. Another teacher tried to molest his female students and was fired when Goldman fought back. She found a sympathetic mentor in her German-language teacher, who loaned her books and took her to an opera. A passionate student, Goldman passed the exam for admission into a gymnasium, but her religion teacher refused to provide a certificate of good behavior and she was unable to attend.

The family moved to the Russian capital of Saint Petersburg, where her father opened one unsuccessful store after another. Their poverty forced the children to work, and Goldman took an assortment of jobs, including one in a corset shop. As a teenager Goldman begged her father to allow her to return to school, but instead he threw her French book into the fire and shouted: "Girls do not have to learn much! All a Jewish daughter needs to know is how to prepare gefilte fish, cut noodles fine, and give the man plenty of children."

Goldman pursued an independent education on her own, however, and soon began to study the political turmoil around her, particularly the Nihilists responsible for assassinating Alexander II of Russia. The ensuing turmoil intrigued Goldman, although she did not fully understand it at the time. When she read Chernyshevsky's novel, "What Is to Be Done?" (1863), she found a role model in the protagonist Vera, who adopts a Nihilist philosophy and escapes her repressive family to live freely and organize a sewing cooperative. The book enthralled Goldman and remained a source of inspiration throughout her life.

Her father, meanwhile, continued to insist on a domestic future for her, and he tried to arrange for her to be married at the age of fifteen. They fought about the issue constantly; he complained that she was becoming a "loose" woman, and she insisted that she would marry for love alone. At the corset shop, she was forced to fend off unwelcome advances from Russian officers and other men. One persistent suitor took her into a hotel room and committed what Goldman called "violent contact"; two biographers call it rape. She was stunned by the experience, overcome by "shock at the discovery that the contact between man and woman could be so brutal and painful." Goldman felt that the encounter forever soured her interactions with men.

In 1885, Helena made plans to move to New York in the United States to join her sister Lena and her husband. Goldman wanted to join her sister, but their father refused to allow it. Despite Helena's offer to pay for the trip, Abraham turned a deaf ear to their pleas. Desperate, Goldman threatened to throw herself into the Neva River if she could not go. He finally agreed, and on December 29, 1885, Helena and Emma arrived at New York City's Castle Garden, the entry for immigrants. They settled upstate, living in the Rochester home which Lena had made with her husband Samuel. Fleeing the rising antisemitism of Saint Petersburg, their parents and brothers joined them a year later. Goldman began working as a seamstress, sewing overcoats for more than ten hours a day, earning two and a half dollars a week. She asked for a raise and was denied; she quit and took work at a smaller shop nearby.

At her new job, Goldman met a fellow worker named Jacob Kershner, who shared her love for books, dancing, and traveling, as well as her frustration with the monotony of factory work. After four months, they married in February 1887. Once he moved in with Goldman's family, however, their relationship faltered. On their wedding night she discovered that he was impotent; they became emotionally and physically distant. Before long he became jealous and suspicious. She, meanwhile, was becoming more engaged with the political turmoil around her—particularly the fallout of the 1886 Haymarket affair in Chicago and the anti-authoritarian political philosophy of anarchism.

Less than a year after the wedding, they were divorced; he begged her to return and threatened to poison himself if she did not. They reunited, but after three months she left once again. Her parents considered her behavior "loose" and refused to allow Goldman into their home. Carrying her sewing machine in one hand and a bag with five dollars in the other, she left Rochester and headed southeast to New York City.

On her first day in the city, Goldman met two men who would forever change her life. At Sachs's Café, a gathering place for radicals, she was introduced to Alexander Berkman, an anarchist who invited her to a public speech that evening. They went to hear Johann Most, editor of a radical publication called "Freiheit" and an advocate of "propaganda of the deed"—the use of violence to instigate change. She was impressed by his fiery oration, and he took her under his wing, training her in methods of public speaking. He encouraged her vigorously, telling her that she was "to take my place when I am gone." One of her first public talks in support of "the Cause" was in Rochester. After convincing Helena not to tell their parents of her speech, Goldman found her mind a blank once on stage. Suddenly, she later wrote:

Excited by the experience, Goldman refined her public persona during subsequent engagements. Quickly, however, she found herself arguing with Most over her independence. After a momentous speech in Cleveland, she felt as though she had become "a parrot repeating Most's views" and resolved to express herself on the stage. Upon her return in New York, Most became furious and told her: "Who is not with me is against me!" She left "Freiheit" and joined with another publication, "Die Autonomie".

Meanwhile, she had begun a friendship with Berkman, whom she affectionately called Sasha. Before long they became lovers and moved into a communal apartment with his cousin Modest "Fedya" Stein and Goldman's friend, Helen Minkin, on 42nd Street. Although their relationship had numerous difficulties, Goldman and Berkman would share a close bond for decades, united by their anarchist principles and commitment to personal equality.
In 1892, Goldman joined with Berkman and Stein in opening an ice cream shop in Worcester, Massachusetts. After only a few months of operating the shop, however, Goldman and Berkman were deflected from the venture by their involvement in the Homestead Strike.

One of the first political moments that brought Berkman and Goldman together was the Homestead Strike. In June 1892, a steel plant in Homestead, Pennsylvania owned by Andrew Carnegie became the focus of national attention when talks between the Carnegie Steel Company and the Amalgamated Association of Iron and Steel Workers (AA) broke down. The factory's manager was Henry Clay Frick, a fierce opponent of the union. When a final round of talks failed at the end of June, management closed the plant and locked out the workers, who immediately went on strike. Strikebreakers were brought in and the company hired Pinkerton guards to protect them. On July 6, a fight broke out between 300 Pinkerton guards and a crowd of armed union workers. During the twelve-hour gunfight, seven guards and nine strikers were killed.

When a majority of the nation's newspapers expressed support of the strikers, Goldman and Berkman resolved to assassinate Frick, an action they expected would inspire the workers to revolt against the capitalist system. Berkman chose to carry out the assassination, and ordered Goldman to stay behind in order to explain his motives after he went to jail. He would be in charge of the deed; she of the word. Berkman tried and failed to make a bomb, then set off for Pittsburgh to buy a gun and a suit of decent clothes. Goldman, meanwhile, decided to help fund the scheme through prostitution. Remembering the character of Sonya in Fyodor Dostoevsky's novel "Crime and Punishment" (1866), she mused: "She had become a prostitute in order to support her little brothers and sisters...Sensitive Sonya could sell her body; why not I?" Once on the street, she caught the eye of a man who took her into a saloon, bought her a beer, gave her ten dollars, informed her she did not have "the knack," and told her to quit the business. She was "too astounded for speech". She wrote to Helena, claiming illness, and asked her for fifteen dollars.

On July 23, Berkman gained access to Frick's office with a concealed handgun and shot Frick three times, then stabbed him in the leg. A group of workers—far from joining in his "attentat"—beat Berkman unconscious, and he was carried away by the police. Berkman was convicted of attempted murder and sentenced to 22 years in prison. Goldman suffered during his long absence. Convinced Goldman was involved in the plot, police raided her apartment and—finding no evidence—pressured her landlord into evicting her. Worse, the "attentat" had failed to rouse the masses: workers and anarchists alike condemned Berkman's action. Johann Most, their former mentor, lashed out at Berkman and the assassination attempt. Furious at these attacks, Goldman brought a toy horsewhip to a public lecture and demanded, onstage, that Most explain his betrayal. He dismissed her, whereupon she struck him with the whip, broke it on her knee, and hurled the pieces at him. She later regretted her assault, confiding to a friend: "At the age of twenty-three, one does not reason."

When the Panic of 1893 struck in the following year, the United States suffered one of its worst economic crises. By year's end, the unemployment rate was higher than 20%, and "hunger demonstrations" sometimes gave way to riots. Goldman began speaking to crowds of frustrated men and women in New York City. On August 21, she spoke to a crowd of nearly 3,000 people in Union Square, where she encouraged unemployed workers to take immediate action. Her exact words are unclear: undercover agents insist she ordered the crowd to "take everything ... by force", while Goldman later recounted this message: "Well then, demonstrate before the palaces of the rich; demand work. If they do not give you work, demand bread. If they deny you both, take bread." Later in court, Detective-Sergeant Charles Jacobs offered yet another version of her speech.

A week later Goldman was arrested in Philadelphia and returned to New York City for trial, charged with "inciting to riot". During the train ride, Jacobs offered to drop the charges against her if she would inform on other radicals in the area. She responded by throwing a glass of ice water in his face. As she awaited trial, Goldman was visited by Nellie Bly, a reporter for the "New York World." She spent two hours talking to Goldman, and wrote a positive article about the woman she described as a "modern Joan of Arc."

Despite this positive publicity, the jury was persuaded by Jacobs' testimony and frightened by Goldman's politics. The assistant District Attorney questioned Goldman about her anarchism, as well as her atheism; the judge spoke of her as "a dangerous woman". She was sentenced to one year in the Blackwell's Island Penitentiary. Once inside she suffered an attack of rheumatism and was sent to the infirmary; there she befriended a visiting doctor and began studying medicine. She also read dozens of books, including works by the American activist-writers Ralph Waldo Emerson and Henry David Thoreau; novelist Nathaniel Hawthorne; poet Walt Whitman, and philosopher John Stuart Mill. When Goldman was released after ten months, a raucous crowd of nearly 3,000 people greeted her at the Thalia Theater in New York City. She soon became swamped with requests for interviews and lectures.

To make money, Goldman decided to pursue the medical work she had studied in prison. However, her preferred fields of specialization—midwifery and massage—were not available to nursing students in the US. She sailed to Europe, lecturing in London, Glasgow, and Edinburgh. She met with renowned anarchists such as Errico Malatesta, Louise Michel, and Peter Kropotkin. In Vienna, she received two diplomas and put them immediately to use back in the US. Alternating between lectures and midwifery, she conducted the first cross-country tour by an anarchist speaker. In November 1899 she returned to Europe, where she met the anarchist Hippolyte Havel, with whom she went to France and helped organize the International Anarchist Congress on the outskirts of Paris.

On September 6, 1901, Leon Czolgosz, an unemployed factory worker and registered Republican with a history of mental illness, shot US President William McKinley twice during a public speaking event in Buffalo, New York. McKinley was hit in the breastbone and stomach, and died eight days later. Czolgosz was arrested, and interrogated around the clock. During interrogation he claimed to be an Anarchist and said he had been inspired to act after attending a speech held by Goldman. The authorities used this as a pretext to charge Goldman with planning McKinley's assassination. They tracked her to a residence in Chicago she shared with Havel, as well as Mary and Abe Isaak, an anarchist couple. Goldman was arrested, along with Isaak, Havel, and ten other anarchists.
Earlier, Czolgosz had tried but failed to become friends with Goldman and her companions. During a talk in Cleveland, Czolgosz had approached Goldman and asked her advice on which books he should read. In July 1901, he had appeared at the Isaak house, asking a series of unusual questions. They assumed he was an infiltrator, like a number of police agents sent to spy on radical groups. They had remained distant from him, and Abe Isaak sent a notice to associates warning of "another spy".

Although Czolgosz repeatedly denied Goldman's involvement, the police held her in close custody, subjecting her to what she called the "third degree". She explained her housemates' distrust of Czolgosz, and it became clear that she had not had any significant contact with the attacker. No evidence was found linking Goldman to the attack, and she was released after two weeks of detention. Before McKinley died, Goldman offered to provide nursing care, referring to him as "merely a human being". Czolgosz, despite considerable evidence of mental illness, was convicted of murder and executed.

Throughout her detention and after her release, Goldman steadfastly refused to condemn Czolgosz's actions, standing virtually alone in doing so. Friends and supporters—including Berkman—urged her to quit his cause. But Goldman defended Czolgosz as a "supersensitive being" and chastised other anarchists for abandoning him. She was vilified in the press as the "high priestess of anarchy", while many newspapers declared the anarchist movement responsible for the murder. In the wake of these events, socialism gained support over anarchism among US radicals. McKinley's successor, Theodore Roosevelt, declared his intent to crack down "not only against anarchists, but against all active and passive sympathizers with anarchists".

After Czolgosz was executed, Goldman withdrew from the world. Scorned by her fellow anarchists, vilified by the press, and separated from her love, Berkman, she retreated into anonymity and nursing. "It was bitter and hard to face life anew," she wrote later. Using the name E. G. Smith, she vanished from public life and took on a series of private nursing jobs. When the US Congress passed the Anarchist Exclusion Act, however, a new wave of activism rose to oppose it, pulling Goldman back into the movement. A coalition of people and organizations across the left end of the political spectrum opposed the law on grounds that it violated freedom of speech, and she had the nation's ear once again.

When an English anarchist named John Turner was arrested under the Anarchist Exclusion Act and threatened with deportation, Goldman joined forces with the Free Speech League to champion his cause. The league enlisted the aid of attorneys Clarence Darrow and Edgar Lee Masters, who took Turner's case to the US Supreme Court. Although Turner and the League lost, Goldman considered it a victory of propaganda. She had returned to anarchist activism, but it was taking its toll on her. "I never felt so weighed down," she wrote to Berkman. "I fear I am forever doomed to remain public property and to have my life worn out through the care for the lives of others."

In 1906, Goldman decided to start a publication, "a place of expression for the young idealists in arts and letters". "Mother Earth" was staffed by a cadre of radical activists, including Hippolyte Havel, Max Baginski, and Leonard Abbott. In addition to publishing original works by its editors and anarchists around the world, "Mother Earth" reprinted selections from a variety of writers. These included the French philosopher Pierre-Joseph Proudhon, Russian anarchist Peter Kropotkin, German philosopher Friedrich Nietzsche, and British writer Mary Wollstonecraft. Goldman wrote frequently about anarchism, politics, labor issues, atheism, sexuality, and feminism.

On May 18 of the same year, Alexander Berkman was released from prison. Carrying a bouquet of roses, Goldman met him on the train platform and found herself "seized by terror and pity" as she beheld his gaunt, pale form. Neither was able to speak; they returned to her home in silence. For weeks, he struggled to readjust to life on the outside; an abortive speaking tour ended in failure, and in Cleveland he purchased a revolver with the intent of killing himself. He returned to New York, however, and learned that Goldman had been arrested with a group of activists meeting to reflect on Czolgosz. Invigorated anew by this violation of freedom of assembly, he declared, "My resurrection has come!" and set about securing their release.

Berkman took the helm of "Mother Earth" in 1907, while Goldman toured the country to raise funds to keep it operating. Editing the magazine was a revitalizing experience for Berkman; his relationship with Goldman faltered, however, and he had an affair with a 15-year-old anarchist named Becky Edelsohn. Goldman was pained by his rejection of her, but considered it a consequence of his prison experience. Later that year she served as a delegate from the US to the International Anarchist Congress of Amsterdam. Anarchists and syndicalists from around the world gathered to sort out the tension between the two ideologies, but no decisive agreement was reached. Goldman returned to the US and continued speaking to large audiences.

For the next ten years, Goldman traveled around the country nonstop, delivering lectures and agitating for anarchism. The coalitions formed in opposition to the Anarchist Exclusion Act had given her an appreciation for reaching out to those of other political positions. When the US Justice Department sent spies to observe, they reported the meetings as "packed". Writers, journalists, artists, judges, and workers from across the spectrum spoke of her "magnetic power", her "convincing presence", her "force, eloquence, and fire".

In the spring of 1908, Goldman met and fell in love with Ben Reitman, the so-called "Hobo doctor." Having grown up in Chicago's tenderloin district, Reitman spent several years as a drifter before earning a medical degree from the College of Physicians and Surgeons of Chicago. As a doctor, he attended to people suffering from poverty and illness, particularly venereal diseases. He and Goldman began an affair. They shared a commitment to free love and Reitman took a variety of lovers, but Goldman did not. She tried to reconcile her feelings of jealousy with a belief in freedom of the heart, but found it difficult.

Two years later, Goldman began feeling frustrated with lecture audiences. She yearned to "reach the few who really want to learn, rather than the many who come to be amused". She collected a series of speeches and items she had written for "Mother Earth" and published a book called "Anarchism and Other Essays." Covering a wide variety of topics, Goldman tried to represent "the mental and soul struggles of twenty-one years". In addition to a comprehensive look at anarchism and its criticisms, the book includes essays on patriotism, women's suffrage, marriage, and prisons.

When Margaret Sanger, an advocate of access to contraception, coined the term "birth control" and disseminated information about various methods in the June 1914 issue of her magazine "The Woman Rebel," she received aggressive support from Goldman, who had already been active in efforts to increase birth control access for several years. In 1916, Goldman was arrested for giving lessons in public on how to use contraceptives. Sanger, too, was arrested under the Comstock Law, which prohibited the dissemination of "obscene, lewd, or lascivious articles"—including information relating to birth control.

Although they later split from Sanger over charges of insufficient support, Goldman and Reitman distributed copies of Sanger's pamphlet "Family Limitation" (along with a similar essay of Reitman's). In 1915 Goldman conducted a nationwide speaking tour in part to raise awareness about contraception options. Although the nation's attitude toward the topic seemed to be liberalizing, Goldman was arrested on February 11, 1916, as she was about to give another public lecture. Goldman was charged with violating the Comstock Law. Refusing to pay a $100 fine, Goldman spent two weeks in a prison workhouse, which she saw as an "opportunity" to reconnect with those rejected by society.

Although US President Woodrow Wilson was re-elected in 1916 under the slogan "He kept us out of the war", at the start of his second term he decided that Germany's continued deployment of unrestricted submarine warfare was sufficient cause for the US to enter World War I. Shortly afterward, Congress passed the Selective Service Act of 1917, which required all males aged 21–30 to register for military conscription. Goldman saw the decision as an exercise in militarist aggression, driven by capitalism. She declared in "Mother Earth" her intent to resist conscription, and to oppose US involvement in the war.

To this end, she and Berkman organized the No Conscription League of New York, which proclaimed: "We oppose conscription because we are internationalists, antimilitarists, and opposed to all wars waged by capitalistic governments." The group became a vanguard for anti-draft activism, and chapters began to appear in other cities. When police began raiding the group's public events to find young men who had not registered for the draft, however, Goldman and others focused their efforts on distributing pamphlets and other written work. In the midst of the nation's patriotic fervor, many elements of the political left refused to support the League's efforts. The Women's Peace Party, for example, ceased its opposition to the war once the US entered it. The Socialist Party of America took an official stance against US involvement, but supported Wilson in most of his activities.

On June 15, 1917, Goldman and Berkman were arrested during a raid of their offices which yielded "a wagon load of anarchist records and propaganda" for the authorities. "The New York Times" reported that Goldman asked to change into a more appropriate outfit, and emerged in a gown of "royal purple". The pair were charged with conspiracy to "induce persons not to register" under the newly enacted Espionage Act, and were held on US$25,000 bail each. Defending herself and Berkman during their trial, Goldman invoked the First Amendment, asking how the government could claim to fight for democracy abroad while suppressing free speech at home:
We say that if America has entered the war to make the world safe for democracy, she must first make democracy safe in America. How else is the world to take America seriously, when democracy at home is daily being outraged, free speech suppressed, peaceable assemblies broken up by overbearing and brutal gangsters in uniform; when free press is curtailed and every independent opinion gagged? Verily, poor as we are in democracy, how can we give of it to the world?
However, the jury found Goldman and Berkman guilty. Judge Julius Marshuetz Mayer imposed the maximum sentence: two years' imprisonment, a $10,000 fine each, and the possibility of deportation after their release from prison. As she was transported to Missouri State Penitentiary (now Jefferson City Correctional Center), Goldman wrote to a friend: "Two years imprisonment for having made an uncompromising stand for one's ideal. Why that is a small price."

In prison, she was again assigned to work as a seamstress, under the eye of a "miserable gutter-snipe of a 21-year-old boy paid to get results". She met the socialist Kate Richards O'Hare, who had also been imprisoned under the Espionage Act. Although they differed on political strategy—Kate O'Hare believed in voting to achieve state power—the two women came together to agitate for better conditions among prisoners. Goldman also met and became friends with Gabriella Segata Antolini, an anarchist and follower of Luigi Galleani. Antolini had been arrested transporting a satchel filled with dynamite on a Chicago-bound train. She had refused to cooperate with authorities, and was sent to prison for 14 months. Working together to make life better for the other inmates, the three women became known as "The Trinity". Goldman was released on September 27, 1919.

Goldman and Berkman were released from prison during the United States' Red Scare of 1919–20, when public anxiety about wartime pro-German activities had morphed into a pervasive fear of Bolshevism and the prospect of an imminent radical revolution. Attorney General Alexander Mitchell Palmer and J. Edgar Hoover, head of the US Department of Justice's General Intelligence Division, were intent on using the Anarchist Exclusion Act and its 1918 expansion to deport any non-citizens they could identify as advocates of anarchy or revolution. "Emma Goldman and Alexander Berkman," Hoover wrote while they were in prison, "are, beyond doubt, two of the most dangerous anarchists in this country and return to the community will result in undue harm."

At her deportation hearing on October 27, Goldman refused to answer questions about her beliefs on the grounds that her American citizenship invalidated any attempt to deport her under the Anarchist Exclusion Act, which could be enforced only against non-citizens of the US. She presented a written statement instead: "Today so-called aliens are deported. Tomorrow native Americans will be banished. Already some patrioteers are suggesting that native American sons to whom democracy is a sacred ideal should be exiled." Louis Post at the Department of Labor, which had ultimate authority over deportation decisions, determined that the revocation of her husband's American citizenship in 1908 after his conviction had revoked hers as well. After initially promising a court fight, she decided not to appeal his ruling.

The Labor Department included Goldman and Berkman among 249 aliens it deported "en masse," mostly people with only vague associations with radical groups who had been swept up in government raids in November. "Buford", a ship the press nicknamed the "Soviet Ark," sailed from the Army's New York Port of Embarkation on December 21. Some 58 enlisted men and four officers provided security on the journey, and pistols were distributed to the crew. Most of the press approved enthusiastically. The Cleveland "Plain Dealer" wrote: "It is hoped and expected that other vessels, larger, more commodious, carrying similar cargoes, will follow in her wake." The ship landed her charges in Hanko, Finland on Saturday, January 17, 1920. Upon arrival in Finland, authorities there conducted the deportees to the Russian frontier under a flag of truce.

Goldman initially viewed the Bolshevik revolution in a positive light. She wrote in "Mother Earth" that despite its dependence on Communist government, it represented "the most fundamental, far-reaching and all-embracing principles of human freedom and of economic well-being". By the time she neared Europe, however, she expressed fears about what was to come. She was worried about the ongoing Russian Civil War and the possibility of being seized by anti-Bolshevik forces. The state, anti-capitalist though it was, also posed a threat. "I could never in my life work within the confines of the State," she wrote to her niece, "Bolshevist or otherwise."
She quickly discovered that her fears were justified. Days after returning to Petrograd (Saint Petersburg), she was shocked to hear a party official refer to free speech as a "bourgeois superstition". As she and Berkman traveled around the country, they found repression, mismanagement, and corruption instead of the equality and worker empowerment they had dreamed of. Those who questioned the government were demonized as counter-revolutionaries, and workers labored under severe conditions. They met with Vladimir Lenin, who assured them that government suppression of press liberties was justified. He told them: "There can be no free speech in a revolutionary period." Berkman was more willing to forgive the government's actions in the name of "historical necessity", but he eventually joined Goldman in opposing the Soviet state's authority.

In March 1921, strikes erupted in Petrograd when workers took to the streets demanding better food rations and more union autonomy. Goldman and Berkman felt a responsibility to support the strikers, stating: "To remain silent now is impossible, even criminal." The unrest spread to the port town of Kronstadt, where the government ordered a military response to suppress striking soldiers and sailors. In the Kronstadt rebellion, approximately 1,000 rebelling sailors and soldiers were killed and two thousand more were arrested; many were later executed. In the wake of these events, Goldman and Berkman decided there was no future in the country for them. "More and more", she wrote, "we have come to the conclusion that we can do nothing here. And as we can not keep up a life of inactivity much longer we have decided to leave."

In December 1921, they left the country and went to the Latvian capital city of Riga. The US commissioner in that city wired officials in Washington DC, who began requesting information from other governments about the couple's activities. After a short trip to Stockholm, they moved to Berlin for several years; during this time Goldman agreed to write a series of articles about her time in Russia for Joseph Pulitzer's newspaper, the "New York World." These were later collected and published in book form as "My Disillusionment in Russia" (1923) and "My Further Disillusionment in Russia" (1924). The publishers added these titles to attract attention; Goldman protested, albeit in vain.

Goldman found it difficult to acclimate to the German leftist community in Berlin. Communists despised her outspokenness about Soviet repression; liberals derided her radicalism. While Berkman remained in Berlin helping Russian exiles, Goldman moved to London in September 1924. Upon her arrival, the novelist Rebecca West arranged a reception dinner for her, attended by philosopher Bertrand Russell, novelist H. G. Wells, and more than 200 other guests. When she spoke of her dissatisfaction with the Soviet government, the audience was shocked. Some left the gathering; others berated her for prematurely criticizing the Communist experiment. Later, in a letter, Russell declined to support her efforts at systemic change in the Soviet Union and ridiculed her anarchist idealism.

In 1925, the spectre of deportation loomed again, but a Scottish anarchist named James Colton offered to marry her and provide British citizenship. Although they were only distant acquaintances, she accepted and they were married on June 27, 1925. Her new status gave her peace of mind, and allowed her to travel to France and Canada. Life in London was stressful for Goldman; she wrote to Berkman: "I am awfully tired and so lonely and heartsick. It is a dreadful feeling to come back here from lectures and find not a kindred soul, no one who cares whether one is dead or alive." She worked on analytical studies of drama, expanding on the work she had published in 1914. But the audiences were "awful," and she never finished her second book on the subject.

Goldman traveled to Canada in 1927, just in time to receive news of the impending executions of Italian anarchists Nicola Sacco and Bartolomeo Vanzetti in Boston. Angered by the many irregularities of the case, she saw it as another travesty of justice in the US. She longed to join the mass demonstrations in Boston; memories of the Haymarket affair overwhelmed her, compounded by her isolation. "Then," she wrote, "I had my life before me to take up the cause for those killed. Now I have nothing."

In 1928, she began writing her autobiography, with the support of a group of American admirers, including journalist H. L. Mencken, poet Edna St. Vincent Millay, novelist Theodore Dreiser and art collector Peggy Guggenheim, who raised $4,000 for her. She secured a cottage in the French coastal city of Saint-Tropez and spent two years recounting her life. Berkman offered sharply critical feedback, which she eventually incorporated at the price of a strain on their relationship. Goldman intended the book, "Living My Life," as a single volume for a price the working class could afford (she urged no more than $5.00); her publisher Alfred A. Knopf, however, released it as two volumes sold together for $7.50. Goldman was furious, but unable to force a change. Due in large part to the Great Depression, sales were sluggish despite keen interest from libraries around the US. Critical reviews were generally enthusiastic; "The New York Times", "The New Yorker", and "Saturday Review of Literature" all listed it as one of the year's top non-fiction books.

In 1933, Goldman received permission to lecture in the United States under the condition that she speak only about drama and her autobiography—but not current political events. She returned to New York on February 2, 1934 to generally positive press coverage—except from Communist publications. Soon she was surrounded by admirers and friends, besieged with invitations to talks and interviews. Her visa expired in May, and she went to Toronto in order to file another request to visit the US. However, this second attempt was denied. She stayed in Canada, writing articles for US publications.

In February and March 1936, Berkman underwent a pair of prostate gland operations. Recuperating in Nice and cared for by his companion, Emmy Eckstein, he missed Goldman's sixty-seventh birthday in Saint-Tropez in June. She wrote in sadness, but he never read the letter; she received a call in the middle of the night that Berkman was in great distress. She left for Nice immediately but when she arrived that morning, Goldman found that he had shot himself and was in a nearly comatose paralysis. He died later that evening.

In July 1936, the Spanish Civil War started after an attempted "coup d'état" by parts of the Spanish Army against the government of the Second Spanish Republic. At the same time, the Spanish anarchists, fighting against the Nationalist forces, started an anarchist revolution. Goldman was invited to Barcelona and in an instant, as she wrote to her niece, "the crushing weight that was pressing down on my heart since Sasha's death left me as by magic". She was welcomed by the Confederación Nacional del Trabajo (CNT) and Federación Anarquista Ibérica (FAI) organizations, and for the first time in her life lived in a community run by and for anarchists, according to true anarchist principles. "In all my life", she wrote later, "I have not met with such warm hospitality, comradeship and solidarity." After touring a series of collectives in the province of Huesca, she told a group of workers: "Your revolution will destroy forever [the notion] that anarchism stands for chaos." She began editing the weekly "CNT-FAI Information Bulletin" and responded to English-language mail.

Goldman began to worry about the future of Spain's anarchism when the CNT-FAI joined a coalition government in 1937—against the core anarchist principle of abstaining from state structures—and, more distressingly, made repeated concessions to Communist forces in the name of uniting against fascism. She wrote that cooperating with Communists in Spain was "a denial of our comrades in Stalin's concentration camps". Russia, meanwhile, refused to send weapons to anarchist forces, and disinformation campaigns were being waged against the anarchists across Europe and the US. Her faith in the movement unshaken, Goldman returned to London as an official representative of the CNT-FAI.

Delivering lectures and giving interviews, Goldman enthusiastically supported the Spanish anarcho-syndicalists. She wrote regularly for "Spain and the World", a biweekly newspaper focusing on the civil war. In May 1937, however, Communist-led forces attacked anarchist strongholds and broke up agrarian collectives. Newspapers in England and elsewhere accepted the timeline of events offered by the Second Spanish Republic at face value. British journalist George Orwell, present for the crackdown, wrote: "[T]he accounts of the Barcelona riots in May ... beat everything I have ever seen for lying."

Goldman returned to Spain in September, but the CNT-FAI appeared to her like people "in a burning house". Worse, anarchists and other radicals around the world refused to support their cause. The Nationalist forces declared victory in Spain just before she returned to London. Frustrated by England's repressive atmosphere—which she called "more fascist than the fascists"—she returned to Canada in 1939. Her service to the anarchist cause in Spain was not forgotten, however. On her seventieth birthday, the former Secretary-General of the CNT-FAI, Mariano Vázquez, sent a message to her from Paris, praising her for her contributions and naming her as "our spiritual mother". She called it "the most beautiful tribute I have ever received".

As the events preceding World War II began to unfold in Europe, Goldman reiterated her opposition to wars waged by governments. "[M]uch as I loathe Hitler, Mussolini, Stalin and Franco", she wrote to a friend, "I would not support a war against them and for the democracies which, in the last analysis, are only Fascist in disguise." She felt that Britain and France had missed their opportunity to oppose fascism, and that the coming war would only result in "a new form of madness in the world".

On Saturday, February 17, 1940, Goldman suffered a debilitating stroke. She became paralyzed on her right side, and although her hearing was unaffected, she could not speak. As one friend described it: "Just to think that here was Emma, the greatest orator in America, unable to utter one word." For three months she improved slightly, receiving visitors and on one occasion gesturing to her address book to signal that a friend might find friendly contacts during a trip to Mexico. She suffered another stroke on May 8, however, and on May 14 she died in Toronto, aged 70.

The US Immigration and Naturalization Service allowed her body to be brought back to the United States. She was buried in German Waldheim Cemetery (now named Forest Home Cemetery) in Forest Park, Illinois, a western suburb of Chicago, near the graves of those executed after the Haymarket affair. The bas relief on her grave marker was created by sculptor Jo Davidson.

Goldman spoke and wrote extensively on a wide variety of issues. While she rejected orthodoxy and fundamentalist thinking, she was an important contributor to several fields of modern political philosophy. She was influenced by many diverse thinkers and writers, including Mikhail Bakunin, Henry David Thoreau, Peter Kropotkin, Ralph Waldo Emerson, Nikolai Chernyshevsky, and Mary Wollstonecraft. Another philosopher who influenced Goldman was Friedrich Nietzsche. In her autobiography, she wrote: "Nietzsche was not a social theorist, but a poet, a rebel, and innovator. His aristocracy was neither of birth nor of purse; it was the spirit. In that respect Nietzsche was an anarchist, and all true anarchists were aristocrats."

Anarchism was central to Goldman's view of the world and she is today considered one of the most important figures in the history of anarchism. First drawn to it during the persecution of anarchists after the 1886 Haymarket affair, she wrote and spoke regularly on behalf of anarchism. In the title essay of her book "Anarchism and Other Essays", she wrote:
Anarchism, then, really stands for the liberation of the human mind from the dominion of religion; the liberation of the human body from the dominion of property; liberation from the shackles and restraint of government. Anarchism stands for a social order based on the free grouping of individuals for the purpose of producing real social wealth; an order that will guarantee to every human being free access to the earth and full enjoyment of the necessities of life, according to individual desires, tastes, and inclinations.
Goldman's anarchism was intensely personal. She believed it was necessary for anarchist thinkers to live their beliefs, demonstrating their convictions with every action and word. "I don't care if a man's theory for tomorrow is correct," she once wrote. "I care if his spirit of today is correct." Anarchism and free association were to her logical responses to the confines of government control and capitalism. "It seems to me that "these" are the new forms of life," she wrote, "and that they will take the place of the old, not by preaching or voting, but by living them."

At the same time, she believed that the movement on behalf of human liberty must be staffed by liberated humans. While dancing among fellow anarchists one evening, she was chided by an associate for her carefree demeanor. In her autobiography, Goldman wrote:
I told him to mind his own business, I was tired of having the Cause constantly thrown in my face. I did not believe that a Cause which stood for a beautiful ideal, for anarchism, for release and freedom from conventions and prejudice, should demand denial of life and joy. I insisted that our Cause could not expect me to behave as a nun and that the movement should not be turned into a cloister. If it meant that, I did not want it. "I want freedom, the right to self-expression, everybody's right to beautiful, radiant things."
Goldman, in her political youth, held targeted violence to be a legitimate means of revolutionary struggle. Goldman at the time believed that the use of violence, while distasteful, could be justified in relation to the social benefits it might accrue. She advocated propaganda of the deed—"attentat", or violence carried out to encourage the masses to revolt. She supported her partner Alexander Berkman's attempt to kill industrialist Henry Clay Frick, and even begged him to allow her to participate. She believed that Frick's actions during the Homestead strike were reprehensible and that his murder would produce a positive result for working people. "Yes," she wrote later in her autobiography, "the end in this case justified the means." While she never gave explicit approval of Leon Czolgosz's assassination of US President William McKinley, she defended his ideals and believed actions like his were a natural consequence of repressive institutions. As she wrote in "The Psychology of Political Violence": "the accumulated forces in our social and economic life, culminating in an act of violence, are similar to the terrors of the atmosphere, manifested in storm and lightning."

Her experiences in Russia led her to qualify her earlier belief that revolutionary ends might justify violent means. In the afterword to "My Disillusionment in Russia", she wrote: "There is no greater fallacy than the belief that aims and purposes are one thing, while methods and tactics are another... The means employed become, through individual habit and social practice, part and parcel of the final purpose..." In the same chapter, however, Goldman affirmed that "Revolution is indeed a violent process," and noted that violence was the "tragic inevitability of revolutionary upheavals..." Some misinterpreted her comments on the Bolshevik terror as a rejection of all militant force, but Goldman corrected this in the preface to the first US edition of "My Disillusionment in Russia":

The argument that destruction and terror are part of revolution I do not dispute. I know that in the past every great political and social change necessitated violence...Black slavery might still be a legalized institution in the United States but for the militant spirit of the John Browns. I have never denied that violence is inevitable, nor do I gainsay it now. Yet it is one thing to employ violence in combat, as a means of defense. It is quite another thing to make a principle of terrorism, to institutionalize it, to assign it the most vital place in the social struggle. Such terrorism begets counter-revolution and in turn itself becomes counter-revolutionary.

Goldman saw the militarization of Soviet society not as a result of armed resistance per se, but of the statist vision of the Bolsheviks, writing that "an insignificant minority bent on creating an absolute State is necessarily driven to oppression and terrorism."

Goldman believed that the economic system of capitalism was incompatible with human liberty. "The only demand that property recognizes," she wrote in "Anarchism and Other Essays", "is its own gluttonous appetite for greater wealth, because wealth means power; the power to subdue, to crush, to exploit, the power to enslave, to outrage, to degrade." She also argued that capitalism dehumanized workers, "turning the producer into a mere particle of a machine, with less will and decision than his master of steel and iron."

Originally opposed to anything less than complete revolution, Goldman was challenged during one talk by an elderly worker in the front row. In her autobiography, she wrote:
He said that he understood my impatience with such small demands as a few hours less a day, or a few dollars more a week... But what were men of his age to do? They were not likely to live to see the ultimate overthrow of the capitalist system. Were they also to forgo the release of perhaps two hours a day from the hated work? That was all they could hope to see realized in their lifetime.
Goldman realized that smaller efforts for improvement such as higher wages and shorter hours could be part of a social revolution.

Goldman viewed the state as essentially and inevitably a tool of control and domination. As a result, Goldman believed that voting was useless at best and dangerous at worst. Voting, she wrote, provided an illusion of participation while masking the true structures of decision-making. Instead, Goldman advocated targeted resistance in the form of strikes, protests, and "direct action against the invasive, meddlesome authority of our moral code". She maintained an anti-voting position even when many anarcho-syndicalists in 1930s Spain voted for the formation of a liberal republic. Goldman wrote that any power anarchists wielded as a voting bloc should instead be used to strike across the country. She disagreed with the movement for women's suffrage, which demanded the right of women to vote. In her essay "Woman Suffrage", she ridicules the idea that women's involvement would infuse the democratic state with a more just orientation: "As if women have not sold their votes, as if women politicians cannot be bought!" She agreed with the suffragists' assertion that women are equal to men, but disagreed that their participation alone would make the state more just. "To assume, therefore, that she would succeed in purifying something which is not susceptible of purification, is to credit her with supernatural powers."

Goldman was also a passionate critic of the prison system, critiquing both the treatment of prisoners and the social causes of crime. Goldman viewed crime as a natural outgrowth of an unjust economic system, and in her essay "Prisons: A Social Crime and Failure", she quoted liberally from the 19th-century authors Fyodor Dostoevsky and Oscar Wilde on prisons, and wrote: Year after year the gates of prison hells return to the world an emaciated, deformed, will-less, shipwrecked crew of humanity, with the Cain mark on their foreheads, their hopes crushed, all their natural inclinations thwarted. With nothing but hunger and inhumanity to greet them, these victims soon sink back into crime as the only possibility of existence.

Goldman was a committed war resister, believing that wars were fought by the state on behalf of capitalists. She was particularly opposed to the draft, viewing it as one of the worst of the state's forms of coercion, and was one of the founders of the No-Conscription League—for which she was ultimately arrested (1917), imprisoned and deported (1919).

Goldman was routinely surveilled, arrested, and imprisoned for her speech and organizing activities in support of workers and various strikes, access to birth control, and in opposition to World War I. As a result, she became active in the early 20th century free speech movement, seeing freedom of expression as a fundamental necessity for achieving social change. Her outspoken championship of her ideals, in the face of persistent arrests, inspired Roger Baldwin, one of the founders of the American Civil Liberties Union. Goldman's and Reitman's experiences in the San Diego free speech fight (1912) were notorious examples of state and capitalist repression of the Industrial Workers of the World's campaign of free speech fights.

Although she was hostile to the suffragist goals of first-wave feminism, Goldman advocated passionately for the rights of women, and is today heralded as a founder of anarcha-feminism, which challenges patriarchy as a hierarchy to be resisted alongside state power and class divisions. In 1897, she wrote: "I demand the independence of woman, her right to support herself; to live for herself; to love whomever she pleases, or as many as she pleases. I demand freedom for both sexes, freedom of action, freedom in love and freedom in motherhood."

A nurse by training, Goldman was an early advocate for educating women concerning contraception. Like many feminists of her time, she saw abortion as a tragic consequence of social conditions, and birth control as a positive alternative. Goldman was also an advocate of free love, and a strong critic of marriage. She saw early feminists as confined in their scope and bounded by social forces of Puritanism and capitalism. She wrote: "We are in need of unhampered growth out of old traditions and habits. The movement for women's emancipation has so far made but the first step in that direction."

Goldman was also an outspoken critic of prejudice against homosexuals. Her belief that social liberation should extend to gay men and lesbians was virtually unheard of at the time, even among anarchists. As German sexologist Magnus Hirschfeld wrote, "she was the first and only woman, indeed the first and only American, to take up the defense of homosexual love before the general public." In numerous speeches and letters, she defended the right of gay men and lesbians to love as they pleased and condemned the fear and stigma associated with homosexuality. As Goldman wrote in a letter to Hirschfeld, "It is a tragedy, I feel, that people of a different sexual type are caught in a world which shows so little understanding for homosexuals and is so crassly indifferent to the various gradations and variations of gender and their great significance in life."

A committed atheist, Goldman viewed religion as another instrument of control and domination. Her essay "The Philosophy of Atheism" quoted Bakunin at length on the subject and added:
Consciously or unconsciously, most theists see in gods and devils, heaven and hell, reward and punishment, a whip to lash the people into obedience, meekness and contentment... The philosophy of Atheism expresses the expansion and growth of the human mind. The philosophy of theism, if we can call it a philosophy, is static and fixed.
In essays like "The Hypocrisy of Puritanism" and a speech entitled "The Failure of Christianity", Goldman made more than a few enemies among religious communities by attacking their moralistic attitudes and efforts to control human behavior. She blamed Christianity for "the perpetuation of a slave society", arguing that it dictated individuals' actions on Earth and offered poor people a false promise of a plentiful future in heaven. She was also critical of Zionism, which she saw as another failed experiment in state control.

Goldman was well known during her life, described as—among other things—"the most dangerous woman in America". After her death and through the middle part of the 20th century, her fame faded. Scholars and historians of anarchism viewed her as a great speaker and activist, but did not regard her as a philosophical or theoretical thinker on par with, for instance, Kropotkin.

In 1970, Dover Press reissued Goldman's biography, "Living My Life", and in 1972, feminist writer Alix Kates Shulman issued a collection of Goldman's writing and speeches, "Red Emma Speaks". These works brought Goldman's life and writings to a larger audience, and she was in particular lionized by the women's movement of the late 20th century. In 1973, Shulman was asked by a printer friend for a quotation by Goldman for use on a T-shirt. She sent him the selection from "Living My Life" about "the right to self-expression, everybody's right to beautiful, radiant things", recounting that she had been admonished "that it did not behoove an agitator to dance". The printer created a statement based on these sentiments that has become one of Goldman's most famous quotations, even though she probably never said or wrote it as such: "If I can't dance I don't want to be in your revolution." Variations of this saying have appeared on thousands of T-shirts, buttons, posters, bumper stickers, coffee mugs, hats, and other items.

The women's movement of the 1970s that "rediscovered" Goldman was accompanied by a resurgent anarchist movement, beginning in the late 1960s, which also reinvigorated scholarly attention to earlier anarchists. The growth of feminism also initiated some reevaluation of Goldman's philosophical work, with scholars pointing out the significance of Goldman's contributions to anarchist thought in her time. Goldman's belief in the value of aesthetics, for example, can be seen in the later influences of anarchism and the arts. Similarly, Goldman is now given credit for significantly influencing and broadening the scope of activism on issues of sexual liberty, reproductive rights, and freedom of expression.

Goldman has been depicted in numerous works of fiction over the years, including Warren Beatty's 1981 film "Reds", in which she was portrayed by Maureen Stapleton, who won an Academy Award for her performance. Goldman has also been a character in two Broadway musicals, "Ragtime" and "Assassins". Plays depicting Goldman's life include Howard Zinn's play, "Emma"; Martin Duberman's "Mother Earth" (1991); Jessica Litwak's "Emma Goldman: Love, Anarchy, and Other Affairs" (Goldman's relationship with Berkman and her arrest in connection with McKinley's assassination); Lynn Rogoff's "Love Ben, Love Emma" (Goldman's relationship with Reitman); and Carol Bolt's "Red Emma". Ethel Mannin's 1941 novel "Red Rose" is also based on Goldman's Life.

Goldman has been honored by a number of organizations named in her memory. The Emma Goldman Clinic, a women's health center located in Iowa City, Iowa, selected Goldman as a namesake "in recognition of her challenging spirit." Red Emma's Bookstore Coffeehouse, an infoshop in Baltimore, Maryland adopted her name out of their belief "in the ideas and ideals that she fought for her entire life: free speech, sexual and racial equality and independence, the right to organize in our jobs and in our own lives, ideas and ideals that we continue to fight for, even today".

Paul Gailiunas and his late wife Helen Hill co-wrote the anarchist song "Emma Goldman", which was performed and released by the band Piggy: The Calypso Orchestra of the Maritimes in 1999. The song was later performed by Gailiunas' new band The Troublemakers and released on their 2004 album "Here Come The Troublemakers".

UK punk band Martha's song "Goldman's Detective Agency" reimagines Goldman as a private detective investigating police and political corruption.

Goldman was a prolific writer, penning countless pamphlets and articles on a diverse range of subjects. She authored six books, including an autobiography, "Living My Life", and a biography of fellow anarchist Voltairine de Cleyre.





</doc>
<doc id="9765" url="https://en.wikipedia.org/wiki?curid=9765" title="Equuleus">
Equuleus

Equuleus is a constellation. Its name is Latin for 'little horse', a foal. It was one of the 48 constellations listed by the 2nd century astronomer Ptolemy, and remains one of the 88 modern constellations. It is the second smallest of the modern constellations (after Crux), spanning only 72 square degrees. It is also very faint, having no stars brighter than the fourth magnitude.

The brightest star in Equuleus is Alpha Equulei, traditionally called Kitalpha, a yellow star magnitude 3.9, 186 light-years from Earth. Its traditional name means "the section of the horse".

There are few variable stars in Equuleus. Only around 25 are known, most of which are faint. Gamma Equulei is an alpha CVn star, ranging between magnitudes 4.58 and 4.77 over a period of around 12½ minutes. It is a white star 115 light-years from Earth, and has an optical companion of magnitude 6.1, 6 Equulei. It is divisible in binoculars. R Equulei is a Mira variable that ranges between magnitudes 8.0 and 15.7 over nearly 261 days.

Equuleus contains some double stars of interest. γ Equ consists of a primary star with a magnitude around 4.7 (slightly variable) and a secondary star of magnitude 11.6, separated by 2 arcseconds. Epsilon Equulei is a triple star also designated 1 Equulei. The system, 197 light-years away, has a primary of magnitude 5.4 that is itself a binary star; its components are of magnitude 6.0 and 6.3 and have a period of 101 years. The secondary is of magnitude 7.4 and is visible in small telescopes. The components of the primary are becoming closer together and will not be divisible in amateur telescopes beginning in 2015. δ Equ is a binary star with an orbital period of 5.7 years, which at one time was the shortest known orbital period for an optical binary. The two components of the system are never more than 0.35 arcseconds apart.

Due to its small size and its distance from the plane of the Milky Way, Equuleus contains no notable deep sky objects. Some very faint galaxies between magnitudes 13 and 15 include NGC 7015, NGC 7040, NGC 7045 and NGC 7046.

In Greek mythology, one myth associates Equuleus with the foal Celeris (meaning "swiftness" or "speed"), who was the offspring or brother of the winged horse Pegasus. Celeris was given to Castor by Mercury. Other myths say that Equuleus is the horse struck from Poseidon's trident, during the contest between him and Athena when deciding which would be the superior. Because this section of stars rises before Pegasus, it is often called Equus Primus, or the First Horse. Equuleus is also linked to the story of Philyra and Saturn.

Created by Hipparchus and included by Ptolemy, it abuts Pegasus; unlike the larger horse it is depicted as a horse's head alone.
In Chinese astronomy, the stars that correspond to Equuleus are located within the Black Tortoise of the North (北方玄武, "Běi Fāng Xuán Wǔ").



</doc>
<doc id="9766" url="https://en.wikipedia.org/wiki?curid=9766" title="Eridanus">
Eridanus

Eridanus can refer to:





</doc>
<doc id="9767" url="https://en.wikipedia.org/wiki?curid=9767" title="Eucharist">
Eucharist

The Eucharist (; also called Holy Communion or the Lord's Supper, among other names) is a Christian rite that is considered a sacrament in most churches and an ordinance in others. According to the New Testament, the rite was instituted by Jesus Christ during his Last Supper; giving his disciples bread and wine during the Passover meal, Jesus commanded his followers to "do this in memory of me" while referring to the bread as "my body" and the wine as "my blood". Through the Eucharistic celebration Christians remember both Christ's sacrifice of himself on the cross and his commission of the apostles at the Last Supper.

The elements of the Eucharist, bread (leavened or unleavened) and wine (or grape juice), are consecrated on an altar (or table) and consumed thereafter. Communicants (that is, those who consume the elements) may speak of "receiving the Eucharist", as well as "celebrating the Eucharist". Christians generally recognize a special presence of Christ in this rite, though they differ about exactly how, where, and when Christ is present. While all agree that there is no perceptible change in the elements, Roman Catholics believe that their substances actually become the body and blood of Christ (transubstantiation). Lutherans believe the true body and blood of Christ are really present "in, with, and under" the forms of the bread and wine (sacramental union or, by some, consubstantiation). Reformed Christians believe in a real spiritual presence of Christ in the Eucharist. Others, such as the Plymouth Brethren, take the act to be only a symbolic reenactment of the Last Supper.

In spite of differences among Christians about various aspects of the Eucharist, there is, according to the "Encyclopædia Britannica", "more of a consensus among Christians about the meaning of the Eucharist than would appear from the confessional debates over the sacramental presence, the effects of the Eucharist, and the proper auspices under which it may be celebrated."
The Greek noun εὐχαριστία ("eucharistia"), meaning "thanksgiving", is not used in the New Testament as a name for the rite; however, the related verb is found in New Testament accounts of the Last Supper, including the earliest such account:

The term "Eucharist" (thanksgiving) is that by which the rite is referred by the Didache (late 1st or early 2nd century), Ignatius of Antioch (who died between 98 and 117) and Justin Martyr (writing between 147 and 167). Today, "the Eucharist" is the name still used by Eastern Orthodox, Oriental Orthodox, Roman Catholics, Anglicans, Presbyterians, and Lutherans. Other Protestant or Evangelical denominations rarely use this term, preferring either "Communion", "the Lord's Supper", or "the Breaking of Bread".

The Lord's Supper, in Greek Κυριακὸν δεῖπνον ("Kyriakon deipnon"), was in use in the early 50s of the 1st century, as witnessed by the First Epistle to the Corinthians (): When you come together, it is not the Lord's Supper you eat, for as you eat, each of you goes ahead without waiting for anybody else. One remains hungry, another gets drunk. Those who use the term "eucharist" rarely use the expression "the Lord's Supper", but it is the predominant term among Evangelicals (Baptists and Pentecostals churches, who generally avoid using the term "Communion".

'Holy Communion' (or simply 'Communion') are used by some groups originating in the Protestant Reformation to mean the entire Eucharistic rite. Others, such as the Catholic Church, do not use this term for the rite, but instead mean by it the act of partaking of the consecrated elements: they speak of receiving Holy Communion even outside of the rite, and of participating in the rite without receiving Holy Communion. The term "Communion" is derived from Latin "communio" ("sharing in common"), which translates Greek κοινωνία ("koinōnía") in : The cup of blessing which we bless, is it not the "communion" of the blood of Christ? The bread which we break, is it not the "communion" of the body of Christ?

The phrase () appears five times in the New Testament (; , , and ) in contexts which, according to some, may refer to the celebration of the Eucharist, in either closer or symbolically more distant reference to the Last
Supper. It is the term used by the Plymouth Brethren.

The "Blessed Sacrament" and the "Blessed Sacrament of the Altar" are common terms used by Catholics, Lutherans and some Anglicans (Anglo-Catholicism) for the consecrated elements, especially when reserved in a tabernacle. "Sacrament of the Altar" is in common use also among Lutherans. In The Church of Jesus Christ of Latter-day Saints the term "The Sacrament" is used of the rite.

Mass is used in the Latin Rite of the Catholic Church, the Lutheran Churches (especially in the Church of Sweden, the Church of Norway, the Evangelical Lutheran Church of Finland), by many Anglicans (especially those of an Anglo-Catholic churchmanship), and in some other forms of Western Christianity. At least in the Catholic Church, the Mass is a longer rite which always consists of two main parts: the Liturgy of the Word and the Liturgy of the Eucharist, in that order. The Liturgy of the Word consists mainly of readings from scripture (the Bible) and a homily preached by a priest or deacon and is essentially distinct and separate from the Sacrament of the Eucharist, which comprises the entirety of the Liturgy of the Eucharist, so the Eucharist itself is only about one half of the Mass. (It is also possible and permissible in the Latin Rite for a priest to consecrate and distribute the Eucharist outside the ritual structure of the Mass—such an event is often called a communion service—but it is much more common to celebrate a full Mass.) Among the many other terms used in the Catholic Church are "Holy Mass", "the Memorial of the Passion, Death and Resurrection of the Lord", the "Holy Sacrifice of the Mass", and the "Holy Mysteries". The term "mass" derives from post-classical Latin "missa" "dismissal", found in the concluding phrase of the liturgy, "Ite, missa est". The term "missa" has come to imply a 'mission', because at the end of the Mass the congregation are sent out to serve Christ.

The term Divine Liturgy is used in Byzantine Rite traditions, whether in the Eastern Orthodox Church or among the Eastern Catholic Churches. These also speak of "the Divine Mysteries", especially in reference to the consecrated elements, which they also call "the Holy Gifts".

The term Divine Service (German: Gottesdienst) is used in the Lutheran Churches, in addition to the terms "Eucharist", "Mass" and "Holy Communion". The term reflects the Lutheran belief that the liturgy was instituted by God.

The Last Supper appears in all three Synoptic Gospels: Matthew, Mark, and Luke. It also is found in the First Epistle to the Corinthians, which suggests how early Christians celebrated what Paul the Apostle called the Lord's Supper. Although the Gospel of John does not reference the Last Supper explicitly, some argue that it contains theological allusions to the early Christian celebration of the Eucharist, especially in the chapter 6 Bread of Life Discourse but also in other passages.

In his First Epistle to the Corinthians (c. 54–55), Paul the Apostle gives the earliest recorded description of Jesus' Last Supper: "The Lord Jesus on the night when he was betrayed took bread, and when he had given thanks, he broke it and said, 'This is my body, which is for you. Do this in remembrance of me.' Those interested might note that the Greek word for remembrance is ἀνάμνησιν or "anamnesis," which itself has a much richer theological history than the English word for "remember."

The synoptic gospels, , and , depict Jesus as presiding over the Last Supper prior to his crucifixion. The versions in Matthew and Mark are almost identical, but Luke's Gospel presents a textual problem in that a few manuscripts omit the second half of verse 19 and all of v.20 ("given for you … poured out for you"), which are found in the vast majority of ancient witnesses to the text. If the shorter text is the original one, then Luke's account is independent of both that of Paul and that of Matthew/Mark. If the majority longer text comes from the author of the third gospel, then this version is very similar to that of Paul in 1 Corinthians, being somewhat fuller in its description of the early part of the Supper, particularly in making specific mention of a cup being blessed before the bread was broken.

Uniquely, in the one prayer given to posterity by Jesus, the Lord's Prayer, the word epiousios—which does not exist in Classical Greek literature—has been interpreted as meaning to mean "super-substantial," and most literally interpreted as a reference to the Bread of Life, the Eucharist.

In the gospel of John, however, the account of the Last Supper does not mention Jesus taking bread and "the cup" and speaking of them as his body and blood; instead, it recounts other events: his humble act of washing the disciples' feet, the prophecy of the betrayal, which set in motion the events that would lead to the cross, and his long discourse in response to some questions posed by his followers, in which he went on to speak of the importance of the unity of the disciples with him, with each other, and with the Father. Some would find in this unity and in the washing of the feet the deeper meaning of the Communion bread in the other three gospels. In , the evangelist attributes a long discourse to Jesus that deals with the subject of the living bread and in contains echoes of Eucharistic language. The interpretation of the whole passage has been extensively debated due to theological and scholarly disagreements. Sir Edwyn Hoskyns notes three main schools of thought: (a) the language is metaphorical, and verse 63: "The Spirit gives life; the flesh counts for nothing. The words I have spoken to you—they are full of the Spirit and life" gives the author's precise meaning; (b) vv 51–58 are a later interpolation that cannot be harmonized with the context; (c) the discourse is homogeneous, sacrificial, and sacramental and can be harmonized, though not all attempts are satisfactory.

The expression "The Lord's Supper", derived from St. Paul's usage in , may have originally referred to the Agape feast (or love feast), the shared communal meal with which the Eucharist was originally associated. The Agape feast is mentioned in but "The Lord's Supper" is now commonly used in reference to a celebration involving no food other than the sacramental bread and wine.

The Didache (Greek: teaching) is an early Church treatise that includes instructions for Baptism and the Eucharist. Most scholars date it to the late 1st century, and distinguish in it two separate Eucharistic traditions, the earlier tradition in chapter 10 and the later one preceding it in chapter 9. The Eucharist is mentioned again in chapter 14.

Ignatius of Antioch (born c. 35 or 50, died between 98 and 117), one of the Apostolic Fathers, mentions the Eucharist as "the flesh of our Saviour Jesus Christ", and Justin Martyr speaks of it as more than a meal: "the food over which the prayer of thanksgiving, the word received from Christ, has been said ... is the flesh and blood of this Jesus who became flesh ... and the deacons carry some to those who are absent."

Paschasius Radbertus (785–865) was a Carolingian theologian, and the abbot of Corbie, whose most well-known and influential work is an exposition on the nature of the Eucharist written around 831, entitled "De Corpore et Sanguine Domini".
He was canonized in 1073 by Pope Gregory VII. His works are edited in "Patrologia Latina" vol. 120 (1852).

Most Christians, even those who deny that there is any real change in the elements used, recognize a special presence of Christ in this rite. But Christians differ about exactly how, where and how long Christ is present in it. Catholicism, Eastern Orthodoxy, Oriental Orthodoxy, and the Church of the East teach that the reality (the "substance") of the elements of bread and wine is wholly changed into the body and blood of Jesus Christ, while the appearances (the "species") remain. The Orthodox use various terms such as Transelementation, but no 'explanation' is official as they prefer to leave it a mystery; transubstantiation is rejected as a philosophical definition and suspect because of the idea of substances smacks of magic. Transubstantiation (change of the reality) is the term used by Catholics to denote "what" is changed, not to explain "how" the change occurs, since the Catholic Church teaches that "the signs of bread and wine become, "in a way surpassing understanding", the Body and Blood of Christ". Lutherans and Reformed Christians believe that the whole Christ, including the body and blood of Jesus, are present in the supper, a concept known as the sacramental union. Lutherans specify that Christ is "in, with and under" the forms of bread and wine. Anglicans adhere to a range of views although the teaching in the Articles of Religion holds that body of Christ is received by the faithful only in a heavenly and spiritual manner. Some Christians reject the concept of the real presence, believing that the Eucharist is only a ceremonial remembrance or memorial of the death of Christ.

The "Baptism, Eucharist and Ministry" document of the World Council of Churches, attempting to present the common understanding of the Eucharist on the part of the generality of Christians, describes it as "essentially the sacrament of the gift which God makes to us in Christ through the power of the Holy Spirit", "Thanksgiving to the Father", "Anamnesis or Memorial of Christ", "the sacrament of the unique sacrifice of Christ, who ever lives to make intercession for us", "the sacrament of the body and blood of Christ, the sacrament of his real presence", "Invocation of the Spirit", "Communion of the Faithful", and "Meal of the Kingdom".

Many Christian denominations classify the Eucharist as a sacrament. Some Protestants (though not all) prefer to instead call it an "ordinance", viewing it not as a specific channel of divine grace but as an expression of faith and of obedience to Christ.

The Catholic Church teaches that once consecrated in the Eucharist, the elements cease to be bread and wine and "become" the "Body, Blood, Soul and Divinity" of Christ, "whole and entire" indeed under the species of bread, and of wine, via a conversion called "transubstantiation." Each of which is accompanied by the other and by Christ's soul and divinity, as long as the Eucharistic species subsist, that is, until the Eucharist is digested, physically destroyed, or decays by some natural process (at which point Aquinas argued that the substance of the bread and wine cannot return). The empirical appearance and physical properties (called the "species" or "accidents") are not changed, but in the view of Catholics, the reality (called the "substance") indeed is; hence the term "transubstantiation" to describe the phenomenon. The consecration of the bread (known as the Host) and wine represents the separation of Jesus' Body from his Blood at Calvary. However, since he has risen, the Church teaches that his Body and Blood can no longer be truly separated. Where one is, the other must be. Therefore, although the priest (or extraordinary minister of Holy Communion) says "The Body of Christ" when administering the Host and "The Blood of Christ" when presenting the chalice, the communicant who receives either one receives Christ, whole and entire.
The Catholic Church sees as the main basis for this belief the words of Jesus himself at his Last Supper: the Synoptic Gospels (; ; ) and Saint Paul's ) recount that in that context Jesus said of what to all appearances were bread and wine: "This is my body … this is my blood." The Catholic understanding of these words, from the Patristic authors onward, has emphasized their roots in the covenantal history of the Old Testament. The interpretation of Christ's words against this Old Testament background coheres with and supports belief in the Real presence of Christ in the Eucharist.

In 1551, the Council of Trent definitively declared, "Because Christ our Redeemer said that it was truly his body that he was offering under the species of bread, it has always been the conviction of the Church of God, and this holy Council now declares again that by the consecration of the bread and wine there takes place a change of the whole substance of the bread into the substance of the body of Christ our Lord and of the whole substance of the wine into the substance of his blood. This change the holy Catholic Church has fittingly and properly called transubstantiation." The Fourth Council of the Lateran in 1215 had spoken of "Jesus Christ, whose body and blood are truly contained in the sacrament of the altar under the forms of bread and wine, the bread being changed ("transsubstantiatis") by divine power into the body and the wine into the blood." The attempt by some twentieth-century Catholic theologians to present the Eucharistic change as an alteration of significance (transignification rather than transubstantiation) was rejected by Pope Paul VI in his 1965 encyclical letter "Mysterium fidei". In his 1968 "Credo of the People of God", he reiterated that any theological explanation of the doctrine must hold to the twofold claim that, after the consecration, 1) Christ's body and blood are really present; and 2) bread and wine are really absent; and this presence and absence is "real" and not merely something in the mind of the believer.

On entering a church, Latin Church Catholics genuflect to the tabernacle that holds the consecrated host in order to respectfully acknowledge the presence of Jesus in the Blessed Sacrament, a presence signalled by a sanctuary lamp or votive candle kept burning close to such a tabernacle. (If there is no such burning light, it indicates that the tabernacle is empty of the special presence of Jesus in the Eucharist.) Catholics will also often kneel or sit before the tabernacle, when the sanctuary light is lit, to pray directly to Jesus, materially present in the form of the Eucharist. Similarly, the consecrated Eucharistic host—the unleavened bread—is sometimes exposed on the altar, usually in an ornamental fixture called a Monstrance, so that Catholics may pray or contemplate in the direct presence and in direct view of Jesus in the Eucharist; this is sometimes called "exposition of the Blessed Sacrament", and the prayer and contemplation in front of the exposed Eucharist are often called "adoration of the Blessed Sacrament" or just "adoration". All of these practices stem from belief in the Real Presence of Jesus Christ in the Eucharist, which is an essential Article of Faith of the Catholic Church.

Within Eastern Christianity, the Eucharistic service is called the "Divine Liturgy" (Byzantine Rite) or similar names in other rites. It comprises two main divisions: the first is the "Liturgy of the Catechumens" which consists of introductory litanies, antiphons and scripture readings, culminating in a reading from one of the Gospels and, often, a homily; the second is the "Liturgy of the Faithful" in which the Eucharist is offered, consecrated, and received as Holy Communion. Within the latter, the actual Eucharistic prayer is called the "anaphora, " literally: "offering" or "carrying up" (). In the Rite of Constantinople, two different anaphoras are currently used: one is attributed to Saint John Chrysostom, the other to Saint Basil the Great. In the Oriental Orthodox Church, a variety of anaphoras are used, but all are similar in structure to those of the Constantinopolitan Rite, in which the Anaphora of Saint John Chrysostom is used most days of the year; Saint Basil's is offered on the Sundays of Great Lent, the eves of Christmas and Theophany, Holy Thursday, Holy Saturday, and upon his feast day (1 January). At the conclusion of the Anaphora the bread and wine are held to be the Body and Blood of Christ. Unlike the Latin Church, the Byzantine Rite uses leavened bread, with the leaven symbolizing the presence of the Holy Spirit. The Armenian Apostolic Church, like the Latin Church, uses unleavened bread.

Conventionally this change in the elements is understood to be accomplished at the "Epiclesis" (Greek: "invocation") by which the Holy Spirit is invoked and the consecration of the bread and wine as the true and genuine Body and Blood of Christ is specifically requested, but since the anaphora as a whole is considered a unitary (albeit lengthy) prayer, no one moment within it can be readily singled out.

Anglican eucharistic theology is not merely memorialist (the belief that nothing special happens at the Lord's Supper other than devotional reflection on Christ's death). Editions of the Book of Common Prayer from 1559 onwards repeatedly refuse to define the Presence most often referred to as the spiritual food of the Most Precious Body and Blood. The Words of Administration allowed for a Real Presence interpretation. Consecration effects a change, Christ is present objectively which does not depend on the faith of the recipient, but the Church refused to define the 'how' (and still does) asking that the bread and wine 'be' the Body and Blood of Jesus Christ rather than 'become.'

The so-called 'Black Rubric' in the 1552 Prayer Book which allowed kneeling for communion but denied the real and essential presence of Christ in the elements was omitted in the 1559 edition. It was re-instated in the 1662 Book modified to deny any corporeal presence to suggest Christ was present in his natural Body. The bread and wine are held to be outward symbols of an inward and spiritual grace received by the faithful as the instruments of God's grace and Jesus' self-offering to the communicant.

In most parishes of the Anglican Communion the Eucharist is celebrated every Sunday, having replaced Morning Prayer as the principal service. The rites for the Eucharist are found in the various prayer books of the Anglican churches. Wine and unleavened wafers or unleavened bread is used. Daily celebrations are the norm in many cathedrals and parish churches sometimes offer one or more services of Holy Communion during the week. The nature of the liturgy varies according to the theological tradition of the priests, parishes, dioceses and regional churches.

The bread and "fruit of the vine" indicated in Matthew, Mark and Luke as the elements of the "Lord's Supper" are interpreted by many Baptists as unleavened bread (although leavened bread is often used) and, in line with the historical stance of some Baptist groups (since the mid-19th century) against partaking of alcoholic beverages, grape juice, which they commonly refer to simply as "the Cup". The unleavened bread also underscores the symbolic belief attributed to Christ's breaking the bread and saying that it was his body. A soda cracker is often used.

Most Baptists consider the Communion to be primarily an act of remembrance of Christ's atonement, and a time of renewal of personal commitment.

However, with the rise of confessionalism, some Baptists have denied the Zwinglian doctrine of mere memorialism and have taken up a Reformed view of Communion. Confessional Baptists believe in pneumatic presence, which is expressed in the Second London Baptist Confession, specifically in Chapter 30, Articles 3 and 7. This view is prevalent among Southern Baptists, those in the Founders movement (a Calvinistic movement within the some Independent Baptists, Freewill Baptists, and several individuals in other Baptist associations.

Communion practices and frequency vary among congregations. A typical practice is to have small cups of juice and plates of broken bread distributed to the seated congregation. In other congregations, communicants may proceed to the altar to receive the elements, then return to their seats. A widely accepted practice is for all to receive and hold the elements until everyone is served, then consume the bread and cup in unison. Usually, music is performed and Scripture is read during the receiving of the elements.

Some Baptist churches are closed-Communionists (even requiring full membership in the church before partaking), with others being partially or fully open-Communionists. It is rare to find a Baptist church where The Lord's Supper is observed every Sunday; most observe monthly or quarterly, with some holding Communion only during a designated Communion service or following a worship service. Adults and children in attendance, who have not made a profession of faith in Christ, are expected to not participate.

Lutherans believe that the body and blood of Christ are "truly and substantially present in, with, and under the forms" of the consecrated bread and wine (the elements), so that communicants eat and drink the body and blood of Christ himself as well as the bread and wine in this sacrament. The Lutheran doctrine of the Real Presence is more accurately and formally known as the "sacramental union". It has been inaccurately called "consubstantiation". This term is specifically rejected by Lutheran churches and theologians since it creates confusion about the actual doctrine and subjects the doctrine to the control of a non-biblical philosophical concept in the same manner as, in their view, does the term "transubstantiation".

While an official movement exists in Lutheran congregations to celebrate Eucharist weekly, using formal rites very similar to the Catholic and "high" Anglican services, it was historically common for congregations to celebrate monthly or even quarterly. Even in congregations where Eucharist is offered weekly, there is not a requirement that every church service be a Eucharistic service, nor that all members of a congregation must receive it weekly.

Traditional Mennonite and German Baptist Brethren Churches such as the Church of the Brethren churches and congregations have the Agape Meal, footwashing and the serving of the bread and wine two parts to the Communion service in the Lovefeast. In the more modern groups, Communion is only the serving of the Lord's Supper. In the communion meal, the members of the Mennonite churches renew their covenant with God and with each other.

Among Open assemblies, also termed Plymouth Brethren, the Eucharist is more commonly called the Breaking of Bread or the Lord's Supper. It is seen as a symbolic memorial and is central to the worship of both individual and assembly. In principle, the service is open to all baptized Christians, but an individual's eligibility to participate depends on the views of each particular assembly. The service takes the form of non-liturgical, open worship with all male participants allowed to pray audibly and select hymns or readings. The breaking of bread itself typically consists of one leavened loaf, which is prayed over and broken by a participant in the meeting and then shared around. The wine is poured from a single container into one or several vessels, and these are again shared around.

The Exclusive Brethren follow a similar practice to the Open Brethren. They also call the Eucharist the Breaking of Bread or the Lord's Supper.

In the Reformed Churches the Eucharist is variously administered. The Calvinist view of the Sacrament sees a real presence of Christ in the supper which differs both from the objective ontological presence of the Catholic view, and from the real absence of Christ and the mental recollection of the memorialism of the Zwinglians and their successors.
The bread and wine become the means by which the believer has real communion with Christ in his death and Christ's body and blood are present to the faith of the believer as really as the bread and wine are present to their senses but this presence is "spiritual", that is the work of the Holy Spirit. There is no standard frequency; John Calvin desired weekly communion, but the city council only approved monthly, and monthly celebration has become the most common practice in Reformed churches today.

Many, on the other hand, follow John Knox in celebration of the Lord's supper on a quarterly basis, to give proper time for reflection and inward consideration of one's own state and sin. Recently, Presbyterian and Reformed Churches have been considering whether to restore more frequent communion, including weekly communion in more churches, considering that infrequent communion was derived from a memorialist view of the Lord's Supper, rather than Calvin's view of the sacrament as a means of grace. Some churches use bread without any raising agent (whether leaven or yeast), in view of the use of unleavened bread at Jewish Passover meals, while others use any bread available.

The Presbyterian Church (USA), for instance, prescribes "bread common to the culture". Harking back to the regulative principle of worship, the Reformed tradition had long eschewed coming forward to receive communion, preferring to have the elements distributed throughout the congregation by the presbyters (elders) more in the style of a shared meal. Over the last half a century it is much more common in Presbyterian churches to have Holy Communion monthly or on a weekly basis. It is also becoming common to receive the elements by intinction (receiving a piece of consecrated bread or wafer, dipping it in the blessed wine, and consuming it) Wine and grape juice are both used, depending on the congregation.

Most Reformed churches practice open communion" , i.e., all believers who are united to a church of like faith and practice, and who are not living in sin, would be allowed to join in the Sacrament.

The "Catechism for the use of the people called Methodists" states that, "[in the Eucharist] Jesus Christ is present with his worshipping people and gives himself to them as their Lord and Saviour". Methodist theology of this sacrament is reflected in one of the fathers of the movement, Charles Wesley, who wrote a Eucharistic hymn with the following stanza:
Reflecting Wesleyan covenant theology, Methodists also believe that the Lord's Supper is a sign and seal of the covenant of grace.
In many Methodist denominations, non-alcoholic wine (grape juice) is used, so as to include those who do not take alcohol for any reason, as well as a commitment to the Church's historical support of temperance. Variations of the Eucharistic Prayer are provided for various occasions, including communion of the sick and brief forms for occasions that call for greater brevity. Though the ritual is standardized, there is great variation amongst Methodist churches, from typically high-church to low-church, in the enactment and style of celebration. Methodist clergy are not required to be vested when celebrating the Eucharist.

John Wesley, a founder of Methodism, said that it was the duty of Christians to receive the sacrament as often as possible. Methodists in the United States are encouraged to celebrate the Eucharist every Sunday, though it is typically celebrated on the first Sunday of each month, while a few go as long as celebrating quarterly (a tradition dating back to the days of circuit riders that served multiple churches). Communicants may receive standing, kneeling, or while seated. Gaining more wide acceptance is the practice of receiving by intinction (receiving a piece of consecrated bread or wafer, dipping it in the blessed wine, and consuming it). The most common alternative to intinction is for the communicants to receive the consecrated juice using small, individual, specially made glass or plastic cups known as communion cups. The United Methodist Church practices open communion, inviting "all who intend a Christian life, together with their children" to receive Communion.

Many non-denominational Christians, including the Churches of Christ, receive communion every Sunday. Others, including Evangelical churches such as the Church of God, Calvary Chapel, and many forms of Baptist, typically receive communion on a monthly or periodic basis. Many non-denominational Christians hold to the Biblical autonomy of local churches and have no universal requirement among congregations.

Some Churches of Christ, among others, use grape juice and unleavened wafers or unleavened bread and practice open communion.

Holy Qurbana or Qurbana Qadisha, the "Holy Offering" or "Holy Sacrifice", refers to the Eucharist as celebrated according to the East Syrian and West Syrian traditions of Syriac Christianity. The main Anaphora of the East Syrian tradition is the Holy Qurbana of Addai and Mari, while that of the West Syrian tradition is the Liturgy of Saint James. Both are extremely old, going back at least to the third century, and are the oldest extant liturgies continually in use.

In the Seventh-day Adventist Church the Holy Communion service customarily is celebrated once per quarter. The service includes the ordinance of footwashing and the Lord's Supper. Unleavened bread and unfermented (non-alcoholic) grape juice is used. Open communion is practised: all who have committed their lives to the Saviour may participate. The communion service must be conducted by an ordained pastor, minister or church elder.

Jehovah's Witnesses commemorate Christ's death as a ransom or propitiatory sacrifice by observing a Memorial annually on the evening that corresponds to the Passover, Nisan 14, according to the ancient Jewish calendar. They believe that this is the only annual religious observance commanded for Christians in the Bible.

Of those who attend the Memorial a small minority worldwide partake of the wine and unleavened bread. Jehovah's Witnesses believe that only 144,000 people will receive heavenly salvation and immortal life and thus spend eternity with God and Christ in heaven, as under-priests and co-rulers under Christ the King and High Priest, in Jehovah's Kingdom. Paralleling the anointing of kings and priests, they are referred to as the "anointed" class and are the only ones who should partake of the bread and wine. They believe that the "other sheep" of Christ's flock also benefit from the ransom sacrifice, and are respectful observers of the Lord's Supper Remembrance, with hope of receiving everlasting life in Paradise restored on a "New Earth".

The Memorial, held after sundown, includes a sermon on the meaning and importance of the celebration and gathering, and includes the circulation and viewing among the audience of unadulterated red wine and unleavened bread (matzo). Jehovah's Witnesses believe that the bread symbolizes and represents Jesus Christ's perfect body which he gave on behalf of mankind, and that the wine represents his perfect blood which redeems fallen man from inherited sin and death. The wine and the bread (sometimes referred to as "emblems") are viewed as symbolic and commemorative; the Witnesses do not believe in transubstantiation or consubstantiation; so not a literal presence of flesh and blood in the emblems, but that the emblems are simply symbolisms denoting spiritual realities.

In The Church of Jesus Christ of Latter-day Saints (LDS Church), the "Holy Sacrament of the Lord's Supper", more simply referred to as the Sacrament, is administered every Sunday (except General Conference or other special Sunday meeting) in each LDS Ward or branch worldwide at the beginning of Sacrament meeting. The Sacrament, which consists of both ordinary bread and water (rather than wine or grape juice), is prepared by priesthood holders prior to the beginning of the meeting. At the beginning of the Sacrament, priests say specific prayers to bless the bread and water. The Sacrament is passed row-by-row to the congregation by priesthood holders (typically deacons).

The prayer recited for the bread and the water is found in the Book of Mormon and Doctrine and Covenants. The ancient American prayer contains the above essentials given by Jesus: “Always remember him, and keep his commandments … , that they may always have his Spirit to be with them.” (Moroni, 4:3.) 

While the Salvation Army does not reject the Eucharistic practices of other churches or deny that their members truly receive grace through this sacrament, it does not practice the sacraments of Communion or baptism. This is because they believe that these are unnecessary for the living of a Christian life, and because in the opinion of Salvation Army founders William and Catherine Booth, the sacrament placed too much stress on outward ritual and too little on inward spiritual conversion.

Emphasizing the inward spiritual experience of their adherents over any outward ritual, Quakers (members of the Religious Society of Friends) generally do not baptize or observe Communion.

Christian denominations differ in their understanding of whether they may receive the Eucharist with those with whom they are not in full communion. The famed apologist St. Justin Martyr (c. 150) wrote: "No one else is permitted to partake of it, except one who believes our teaching to be true..." For the first several hundred years, non-members were forbidden even to be present at the sacramental ritual; visitors and catechumens (those still undergoing instruction) were dismissed halfway through the Liturgy, after the Bible readings and sermon but before the Eucharistic rite. This ancient custom is still evident in the extraordinary form of the Roman Rite, where the Mass is divided into two parts; the Mass of the Catechumens, and the Mass of the Faithful. The Divine Liturgy of St. John Chrysostom, used in the Byzantine Rite, still has a formula of dismissal of catechumens (not usually followed by any action) at this point.

Churches such as the Catholic and the Eastern Orthodox Churches practice closed communion under normal circumstances. However, the Catholic Church allows administration of the Eucharist, at their spontaneous request, to properly disposed members of the eastern churches (Eastern Orthodox, Oriental Orthodox and Church of the East) not in full communion with it and of other churches that the Holy See judges to be sacramentally in the same position as these churches; and in grave and pressing need, such as danger of death, it allows the Eucharist to be administered also to individuals who do not belong to these churches but who share the Catholic Church's faith in the reality of the Eucharist and have no access to a minister of their own community. Some Protestant communities exclude non-members from Communion.

The Evangelical Lutheran Church in America (ELCA) practices open communion, provided those who receive are baptized, but the Lutheran Church–Missouri Synod and the Wisconsin Evangelical Lutheran Synod (WELS) practice closed communion, excluding non-members and requiring communicants to have been given catechetical instruction. The Evangelical Lutheran Church in Canada, the Evangelical Church in Germany, the Church of Sweden, and many other Lutheran churches outside of the US also practice open communion.
Some use the term "close communion" for restriction to members of the same denomination, and "closed communion" for restriction to members of the local congregation alone.

Most Protestant communities including Congregational churches, the Church of the Nazarene, the Assemblies of God, Methodists, most Presbyterians, Anglicans, and Churches of Christ and other non-denominational churches practice various forms of open communion. Some churches do not limit it to only members of the congregation, but to any person in attendance (regardless of Christian affiliation) who considers himself/herself to be a Christian. Others require that the communicant be a baptized person, or a member of a church of that denomination or a denomination of "like faith and practice". Some Progressive Christian congregations offer communion to any individual who wishes to commemorate the life and teachings of Christ, regardless of religious affiliation.

In the Episcopal Church (United States), those who do not receive Holy Communion may enter the communion line with their arms crossed over their chest, in order to receive a blessing from the priest, instead of receiving Holy Communion. This practice is also used in the Roman Catholic church at funeral masses, where attendees frequently include non-Catholics.

Most Latter-Day Saint churches practice closed communion; one notable exception is the Community of Christ, the second-largest denomination in this movement. While The Church of Jesus Christ of Latter-day Saints (the largest of the LDS denominations) technically practice a closed communion, their official direction to local Church leaders (in Handbook 2, section 20.4.1, last paragraph) is as follows: "Although the sacrament is for Church members, the bishopric should not announce that it will be passed to members only, and nothing should be done to prevent nonmembers from partaking of it."

The Catholic Church requires its members to receive the sacrament of Penance or Reconciliation before taking Communion if they are aware of having committed a mortal sin and to prepare by fasting, prayer, and other works of piety.

Traditionally, the Eastern Orthodox church has required its members to have observed all church-appointed fasts (most weeks, this will be at least Wednesday and Friday) for the week prior to partaking of communion, and to fast from all food and water from midnight the night before. In addition, Orthodox Christians are to have made a recent confession to their priest (the frequency varying with one's particular priest), and they must be at peace with all others, meaning that they hold no grudges or anger against anyone. In addition, one is expected to attend Vespers or the All-Night Vigil, if offered, on the night before receiving communion. Furthermore, various pre-communion prayers have been composed, which many (but not all) Orthodox churches require or at least strongly encourage members to say privately before coming to the Eucharist.

Many Protestant congregations generally reserve a period of time for self-examination and private, silent confession just before partaking in the Lord's Supper.

Seventh-day Adventists, Mennonites, and some other groups participate in "foot washing" (cf. ) as a preparation for partaking in the Lord's Supper. At that time they are to individually examine themselves, and confess any sins they may have between one and another.

Eucharistic adoration is a practice in the Roman Catholic, Anglo-Catholic and some Lutheran traditions, in which the Blessed Sacrament is exposed to and adored by the faithful. When this exposure and adoration is constant (twenty-four hours a day), it is called "Perpetual Adoration". In a parish, this is usually done by volunteer parishioners; in a monastery or convent, it is done by the resident monks or nuns. In the "Exposition of the Blessed Sacrament", the Eucharist is displayed in a monstrance, typically placed on an altar, at times with a light focused on it, or with candles flanking it.

The gluten in wheat bread is dangerous to people with celiac disease and other gluten-related disorders, such as non-celiac gluten sensitivity and wheat allergy. For the Catholic Church, this issue was addressed in the 24 July 2003 letter of the Congregation for the Doctrine of the Faith, which summarized and clarified earlier declarations. The Catholic Church believes that the matter for the Eucharist must be wheaten bread and fermented wine from grapes: it holds that, if the gluten has been entirely removed, the result is not true wheaten bread. For celiacs, but not generally, it allows low-gluten bread. It also permits Holy Communion to be received under the form of either bread or wine alone, except by a priest who is celebrating Mass without other priests or as principal celebrant. Many Protestant churches offer communicants gluten-free alternatives to wheaten bread, usually in the form of a rice-based cracker or gluten-free bread.

The Catholic Church believes that grape juice that has not begun even minimally to ferment cannot be accepted as wine, which it sees as essential for celebration of the Eucharist. For alcoholics, but not generally, it allows the use of mustum (grape juice in which fermentation has begun but has been suspended without altering the nature of the juice), and it holds that "since Christ is sacramentally present under each of the species, communion under the species of bread alone makes it possible to receive all the fruit of Eucharistic grace. For pastoral reasons, this manner of receiving communion has been legitimately established as the most common form in the Latin rite."

As already indicated, the one exception is in the case of a priest celebrating Mass without other priests or as principal celebrant. The water that in the Latin Church is prescribed to be mixed with the wine must be only a relatively small quantity. The practice of the Coptic Church is that the mixture should be two parts wine to one part water.

Many Protestant churches allow clergy and communicants to take mustum instead of wine. In addition to, or in replacement of wine, some churches offer grape juice which has been pasteurized to stop the fermentation process the juice naturally undergoes; de-alcoholized wine from which most of the alcohol has been removed (between 0.5% and 2% remains), or water. Exclusive use of unfermented grape juice is common in Baptist churches, the United Methodist Church, Seventh-day Adventists, Christian Churches/Churches of Christ, Churches of Christ, Church of God (Anderson, Indiana) some Lutherans, Assemblies of God, Pentecostals, Evangelicals, the Christian Missionary Alliance, and other American independent Protestant churches.,

Risk of infectious disease transmission related to use of a common communion cup is low, to the point of being undetectable. No case of transmission of an infectious disease related to a common communion cup has ever been documented. The most likely diseases to be transmitted would be common viral illnesses such as the common cold, but a study of 681 individuals found that taking communion up to daily from a common cup did not increase the risk of infection beyond that of those who did not attend services at all.

In influenza epidemics, some churches suspend the giving of communion under the form of wine, for fear of spreading the disease. This is in full accord with Catholic Church belief that communion under the form of bread alone makes it possible to receive all the fruit of Eucharistic grace. However, the same measure has also been taken by churches that normally insist on the importance of receiving communion under both forms. This was done in 2009 by the Church of England.

Some fear contagion through the handling involved in distributing the hosts to the communicants, even if they are placed on the hand rather than on the tongue. Accordingly, some churches use mechanical wafer dispensers or "pillow packs" (communion wafers with wine inside them). While these methods of distributing communion are not accepted in Catholic Church parishes, one such church provides a mechanical dispenser to allow those intending to communicate to place in a bowl, without touching them by hand, the hosts for use in the celebration.









</doc>
<doc id="9770" url="https://en.wikipedia.org/wiki?curid=9770" title="Eclipse">
Eclipse

An eclipse is an astronomical event that occurs when an astronomical object is temporarily obscured, either by passing into the shadow of another body or by having another body pass between it and the viewer. This alignment of three celestial objects is known as a syzygy. Apart from syzygy, the term eclipse is also used when a spacecraft reaches a position where it can observe two celestial bodies so aligned. An eclipse is the result of either an occultation (completely hidden) or a transit (partially hidden).

The term eclipse is most often used to describe either a solar eclipse, when the Moon's shadow crosses the Earth's surface, or a lunar eclipse, when the Moon moves into the Earth's shadow. However, it can also refer to such events beyond the Earth–Moon system: for example, a planet moving into the shadow cast by one of its moons, a moon passing into the shadow cast by its host planet, or a moon passing into the shadow of another moon. A binary star system can also produce eclipses if the plane of the orbit of its constituent stars intersects the observer's position.

For the special cases of solar and lunar eclipses, these only happen during an "eclipse season", the two times of each year when the plane of the Earth's orbit around the Sun crosses with the plane of the Moon's orbit around the Earth. The type of solar eclipse that happens during each season (whether total, annular, hybrid, or partial) depends on apparent sizes of the Sun and Moon. If the orbit of the Earth around the Sun, and the Moon's orbit around the Earth were both in the same plane with each other, then eclipses would happen each and every month. There would be a lunar eclipse at every full moon, and a solar eclipse at every new moon. And if both orbits were perfectly circular, then each solar eclipse would be the same type every month. It is because of the non-planar and non-circular differences that eclipses are not a common event. Lunar eclipses can be viewed from the entire nightside half of the Earth. But solar eclipses, particularly a total eclipse, as occurring at any one particular point on the Earth's surface, is a rare event that can span many decades from one to the next.

The term is derived from the ancient Greek noun ('), which means "the abandonment", "the downfall", or "the darkening of a heavenly body", which is derived from the verb (') which means "to abandon", "to darken", or "to cease to exist," a combination of prefix ('), from preposition ('), "out," and of verb (""), "to be absent".

For any two objects in space, a line can be extended from the first through the second. The latter object will block some amount of light being emitted by the former, creating a region of shadow around the axis of the line. Typically these objects are moving with respect to each other and their surroundings, so the resulting shadow will sweep through a region of space, only passing through any particular location in the region for a fixed interval of time. As viewed from such a location, this shadowing event is known as an eclipse.

Typically the cross-section of the objects involved in an astronomical eclipse are roughly disk shaped. The region of an object's shadow during an eclipse is divided into three parts:
A total eclipse occurs when the observer is within the umbra, an annular eclipse when the observer is within the antumbra, and a partial eclipse when the observer is within the penumbra. During a lunar eclipse only the umbra and penumbra are applicable. This is because Earth's apparent diameter from the viewpoint of the Moon is nearly four times that of the Sun. The same terms may be used analogously in describing other eclipses, e.g., the antumbra of Deimos crossing Mars, or Phobos entering Mars's penumbra.

The "first contact" occurs when the eclipsing object's disc first starts to impinge on the light source; "second contact" is when the disc moves completely within the light source; "third contact" when it starts to move out of the light; and "fourth" or "last contact" when it finally leaves the light source's disc entirely.

For spherical bodies, when the occulting object is smaller than the star, the length ("L") of the umbra's cone-shaped shadow is given by:

where "R" is the radius of the star, "R" is the occulting object's radius, and "r" is the distance from the star to the occulting object. For Earth, on average "L" is equal to 1.384 km, which is much larger than the Moon's semimajor axis of 3.844 km. Hence the umbral cone of the Earth can completely envelop the Moon during a lunar eclipse. If the occulting object has an atmosphere, however, some of the luminosity of the star can be refracted into the volume of the umbra. This occurs, for example, during an eclipse of the Moon by the Earth—producing a faint, ruddy illumination of the Moon even at totality.

On Earth, the shadow cast during an eclipse moves very approximately at 1 km per sec. This depends on the location of the shadow on the Earth and the angle in which it is moving.

An eclipse cycle takes place when eclipses in a series are separated by a certain interval of time. This happens when the orbital motions of the bodies form repeating harmonic patterns. A particular instance is the saros, which results in a repetition of a solar or lunar eclipse every 6,585.3 days, or a little over 18 years. Because this is not a whole number of days, successive eclipses will be visible from different parts of the world.

An eclipse involving the Sun, Earth, and Moon can occur only when they are nearly in a straight line, allowing one to be hidden behind another, viewed from the third. Because the orbital plane of the Moon is tilted with respect to the orbital plane of the Earth (the ecliptic), eclipses can occur only when the Moon is close to the intersection of these two planes (the nodes). The Sun, Earth and nodes are aligned twice a year (during an eclipse season), and eclipses can occur during a period of about two months around these times. There can be from four to seven eclipses in a calendar year, which repeat according to various eclipse cycles, such as a saros.

Between 1901 and 2100 there are the maximum of seven eclipses in:

Excluding penumbral lunar eclipses, there are a maximum of seven eclipses in:

As observed from the Earth, a solar eclipse occurs when the Moon passes in front of the Sun. The type of solar eclipse event depends on the distance of the Moon from the Earth during the event. A total solar eclipse occurs when the Earth intersects the umbra portion of the Moon's shadow. When the umbra does not reach the surface of the Earth, the Sun is only partially occulted, resulting in an annular eclipse. Partial solar eclipses occur when the viewer is inside the penumbra.

The eclipse magnitude is the fraction of the Sun's diameter that is covered by the Moon. For a total eclipse, this value is always greater than or equal to one. In both annular and total eclipses, the eclipse magnitude is the ratio of the angular sizes of the Moon to the Sun.

Solar eclipses are relatively brief events that can only be viewed in totality along a relatively narrow track. Under the most favorable circumstances, a total solar eclipse can last for 7 minutes, 31 seconds, and can be viewed along a track that is up to 250 km wide. However, the region where a partial eclipse can be observed is much larger. The Moon's umbra will advance eastward at a rate of 1,700 km/h, until it no longer intersects the Earth's surface.

During a solar eclipse, the Moon can sometimes perfectly cover the Sun because its apparent size is nearly the same as the Sun's when viewed from the Earth. A total solar eclipse is in fact an occultation while an annular solar eclipse is a transit.

When observed at points in space other than from the Earth's surface, the Sun can be eclipsed by bodies other than the Moon. Two examples include when the crew of Apollo 12 observed the in 1969 and when the Cassini probe observed in 2006.

Lunar eclipses occur when the Moon passes through the Earth's shadow. This happens only during a full moon, when the Moon is on the far side of the Earth from the Sun. Unlike a solar eclipse, an eclipse of the Moon can be observed from nearly an entire hemisphere. For this reason it is much more common to observe a lunar eclipse from a given location. A lunar eclipse lasts longer, taking several hours to complete, with totality itself usually averaging anywhere from about 30 minutes to over an hour.

There are three types of lunar eclipses: penumbral, when the Moon crosses only the Earth's penumbra; partial, when the Moon crosses partially into the Earth's umbra; and total, when the Moon crosses entirely into the Earth's umbra. Total lunar eclipses pass through all three phases. Even during a total lunar eclipse, however, the Moon is not completely dark. Sunlight refracted through the Earth's atmosphere enters the umbra and provides a faint illumination. Much as in a sunset, the atmosphere tends to more strongly scatter light with shorter wavelengths, so the illumination of the Moon by refracted light has a red hue, thus the phrase 'Blood Moon' is often found in descriptions of such lunar events as far back as eclipses are recorded.

Records of solar eclipses have been kept since ancient times. Eclipse dates can be used for chronological dating of historical records. A Syrian clay tablet, in the Ugaritic language, records a solar eclipse which occurred on March 5, 1223 B.C., while Paul Griffin argues that a stone in Ireland records an eclipse on November 30, 3340 B.C. Positing classical-era astronomers' use of Babylonian eclipse records mostly from the 13th century BC provides a feasible and mathematically consistent explanation for the Greek finding all three lunar mean motions (synodic, anomalistic, draconitic) to a precision of about one part in a million or better. Chinese historical records of solar eclipses date back over 4,000 years and have been used to measure changes in the Earth's rate of spin.

By the 1600s, European astronomers were publishing books with diagrams explaining how lunar and solar eclipses occurred. In order to disseminate this information to a broader audience and decrease fear of the consequences of eclipses, booksellers printed broadsides explaining the event either using the science or via astrology.

The gas giant planets (Jupiter, Saturn, Uranus, and Neptune) have many moons and thus frequently display eclipses. The most striking involve Jupiter, which has four large moons and a low axial tilt, making eclipses more frequent as these bodies pass through the shadow of the larger planet. Transits occur with equal frequency. It is common to see the larger moons casting circular shadows upon Jupiter's cloudtops.

The eclipses of the Galilean moons by Jupiter became accurately predictable once their orbital elements were known. During the 1670s, it was discovered that these events were occurring about 17 minutes later than expected when Jupiter was on the far side of the Sun. Ole Rømer deduced that the delay was caused by the time needed for light to travel from Jupiter to the Earth. This was used to produce the first estimate of the speed of light.

On the other three gas giants, eclipses only occur at certain periods during the planet's orbit, due to their higher inclination between the orbits of the moon and the orbital plane of the planet. The moon Titan, for example, has an orbital plane tilted about 1.6° to Saturn's equatorial plane. But Saturn has an axial tilt of nearly 27°. The orbital plane of Titan only crosses the line of sight to the Sun at two points along Saturn's orbit. As the orbital period of Saturn is 29.7 years, an eclipse is only possible about every 15 years.

The timing of the Jovian satellite eclipses was also used to calculate an observer's longitude upon the Earth. By knowing the expected time when an eclipse would be observed at a standard longitude (such as Greenwich), the time difference could be computed by accurately observing the local time of the eclipse. The time difference gives the longitude of the observer because every hour of difference corresponded to 15° around the Earth's equator. This technique was used, for example, by Giovanni D. Cassini in 1679 to re-map France.

On Mars, only partial solar eclipses (transits) are possible, because neither of its moons is large enough, at their respective orbital radii, to cover the Sun's disc as seen from the surface of the planet. Eclipses of the moons by Mars are not only possible, but commonplace, with hundreds occurring each Earth year. There are also rare occasions when Deimos is eclipsed by Phobos. Martian eclipses have been photographed from both the surface of Mars and from orbit.

Pluto, with its proportionately largest moon Charon, is also the site of many eclipses. A series of such mutual eclipses occurred between 1985 and 1990. These daily events led to the first accurate measurements of the physical parameters of both objects.

Eclipses are impossible on Mercury and Venus, which have no moons. However, both have been observed to transit across the face of the Sun. There are on average 13 transits of Mercury each century. Transits of Venus occur in pairs separated by an interval of eight years, but each pair of events happen less than once a century. According to NASA, the next pair of transits will occur on December 10, 2117 and December 8, 2125. Transits on Mercury are much more common.

A binary star system consists of two stars that orbit around their common centre of mass. The movements of both stars lie on a common orbital plane in space. When this plane is very closely aligned with the location of an observer, the stars can be seen to pass in front of each other. The result is a type of extrinsic variable star system called an eclipsing binary.

The maximum luminosity of an eclipsing binary system is equal to the sum of the luminosity contributions from the individual stars. When one star passes in front of the other, the luminosity of the system is seen to decrease. The luminosity returns to normal once the two stars are no longer in alignment.

The first eclipsing binary star system to be discovered was Algol, a star system in the constellation Perseus. Normally this star system has a visual magnitude of 2.1. However, every 2.867 days the magnitude decreases to 3.4 for more than nine hours. This is caused by the passage of the dimmer member of the pair in front of the brighter star. The concept that an eclipsing body caused these luminosity variations was introduced by John Goodricke in 1783.


Sun - Moon - Earth: Solar eclipse | annular eclipse | hybrid eclipse | partial eclipse

Sun - Earth - Moon: Lunar eclipse | penumbral eclipse | partial lunar eclipse | central lunar eclipse

Sun - Phobos - Mars: Transit of Phobos from Mars | Solar eclipses on Mars

Sun - Deimos - Mars: Transit of Deimos from Mars | Solar eclipses on Mars

Other types: Solar eclipses on Jupiter | Solar eclipses on Saturn | Solar eclipses on Uranus | Solar eclipses on Neptune | Solar eclipses on Pluto




</doc>
<doc id="9771" url="https://en.wikipedia.org/wiki?curid=9771" title="Ed (text editor)">
Ed (text editor)

The ed text editor was one of the first three key elements of the Unix operating system—assembler, editor, and shell—developed by Ken Thompson in August 1969 on a PDP-7 at AT&T Bell Labs. Many features of ed came from the qed text editor developed at Thompson's alma mater University of California, Berkeley. Thompson was very familiar with qed, and had reimplemented it on the CTSS and Multics systems. Thompson's versions of qed were notable as the first to implement regular expressions. Regular expressions are also implemented in ed, though their implementation is considerably less general than that in qed.

Dennis M. Ritchie produced what Doug McIlroy later described as the "definitive" ed, and aspects of ed went on to influence ex, which in turn spawned vi. The non-interactive Unix command grep was inspired by a common special use of qed and later ed, where the command g/re/p means globally search for the regular expression re and print the lines containing it. The Unix stream editor, sed implemented many of the scripting features of qed that were not supported by ed on Unix. In turn sed influenced the design of the programming language AWK – which inspired aspects of Perl.

Features of ed include:

(In)famous for its terseness, ed gives almost no visual feedback, and has been called (by Peter H. Salus) "the most user-hostile editor ever created", even when compared to the contemporary (and notoriously complex) TECO. For example, the message that ed will produce in case of error, or when it wants to make sure the user wishes to quit without saving, is "?". It does not report the current filename or line number, or even display the results of a change to the text, unless requested. Older versions (c. 1981) did not even ask for confirmation when a quit command was issued without the user saving changes. This terseness was appropriate in the early versions of Unix, when consoles were teletypes, modems were slow, and memory was precious. As computer technology improved and these constraints were loosened, editors with more visual feedback became the norm.

In current practice, ed is rarely used interactively, but does find use in some shell scripts. For interactive use, ed was subsumed by the sam, vi and Emacs editors in the 1980s. ed can be found on virtually every version of Unix and Linux available, and as such is useful for people who have to work with multiple versions of Unix. On Unix-based operating systems, some utilities like SQL*Plus run ed as the editor if the EDITOR and VISUAL environment variables are not defined. If something goes wrong, ed is sometimes the only editor available. This is often the only time when it is used interactively.

The ed commands are often imitated in other line-based editors. For example, EDLIN in early MS-DOS versions and 32-bit versions of Windows NT has a somewhat similar syntax, and text editors in many MUDs (LPMud and descendants, for example) use ed-like syntax. These editors, however, are typically more limited in function.

Here is an example transcript of an ed session. For clarity, commands and text typed by the user are in normal face, and output from ed is emphasized.

The end result is a simple text file containing the following text:

Started with an empty file, the "a" command appends text (all ed commands are single letters). The command puts ed in "insert mode", inserting the characters that follow and is terminated by a single dot on a line. The two lines that are entered before the dot end up in the file buffer. The codice_1 command also goes into insert mode, and will insert the entered text (a single empty line in our case) before line two. All commands may be prefixed by a line number to operate on that line.

In the line codice_2, the lowercase L stands for the list command. The command is prefixed by a range, in this case codice_3 which is a shortcut for codice_4. A range is two line numbers separated by a comma (codice_5 means the last line). In return, ed lists all lines, from first to last. These lines are ended with dollar signs, so that white space at the end of lines is clearly visible.

Once the empty line is inserted in line 2, the line which reads "This is line number two." is now actually the third line. This error is corrected with codice_6, a substitution command. The codice_7 will apply it to the correct line; following the command is the text to be replaced, and then the replacement. Listing all lines with codice_2 the line is shown now to be correct.

codice_9 writes the buffer to the file "text" making ed respond with "65", the number of characters written to the file. codice_10 will end an ed session.

The influence of ed on later Unix utilities has been noted. More generally, ed continues to serve as an interface model for programs that must modify record sequences and for which scriptability is extremely important, even when the records bear little resemblance to the text lines manipulated by ed itself.




</doc>
<doc id="9772" url="https://en.wikipedia.org/wiki?curid=9772" title="Edlin">
Edlin

Edlin is a line editor, and the only text editor provided with early versions of MS-DOS. Although superseded in MS-DOS 5.0 and later by the full-screen edit command, and by Notepad in Microsoft Windows, it continues to be included in the 32-bit versions of current Microsoft operating systems.

Edlin was created by Tim Paterson in two weeks in 1980, for Seattle Computer Products's 86-DOS (QDOS) based on the CP/M line editor "ED".

Microsoft acquired 86-DOS and sold it as MS-DOS, so Edlin was included in v1.0–v5.0 of MS-DOS, after which the only editor included was the new full-screen MS-DOS Editor in v6.0–v8.0. 

Early Windows versions ran on top of the later versions of MS-DOS, so Edlin was typically not available. 

However, Edlin is included in the 32-bit versions of Windows NT and its derivatives—up to and including Windows 10—because the NTVDM's DOS support in those operating systems is based on MS-DOS version 5.0. However, unlike most other external DOS commands, it has not been transformed into a native Win32 program. It also does not support long filenames, which were not added to MS-DOS and MS-Windows until long after Edlin was written.

There are only a few commands. The short list can be found by entering a ? at the edlin prompt.

When a file is open, typing L lists the contents (e.g., codice_1 lists lines 1 through 6). Each line is displayed with a line number in front of it.

The currently selected line has a *. To replace the contents of any line, the line number is entered and any text entered replaces the original. While editing a line pressing Ctrl-C cancels any changes. The * marker remains on that line.

Entering I (optionally preceded with a line number) inserts one or more lines before the * line or the line given. When finished entering lines, Ctrl-C returns to the edlin command prompt.

Edlin may be used as a non-interactive file editor in scripts by redirecting a series of edlin commands.

A GPL-licensed clone of Edlin that includes long filename support is available for download as part of the FreeDOS project. This runs on operating systems such as Linux or Unix as well as MS-DOS.




</doc>
<doc id="9773" url="https://en.wikipedia.org/wiki?curid=9773" title="EBCDIC">
EBCDIC

Extended Binary Coded Decimal Interchange Code (EBCDIC; ) is an eight-bit character encoding used mainly on IBM mainframe and IBM midrange computer operating systems. It descended from the code used with punched cards and the corresponding six bit binary-coded decimal code used with most of IBM's computer peripherals of the late 1950s and early 1960s. It is supported by various non-IBM platforms, such as Fujitsu-Siemens' BS2000/OSD, OS-IV, MSP, and MSP-EX, the SDS Sigma series, Unisys VS/9, Burroughs MCP and ICL VME.

EBCDIC was devised in 1963 and 1964 by IBM and was announced with the release of the IBM System/360 line of mainframe computers. It is an eight-bit character encoding, developed separately from the seven-bit ASCII encoding scheme. It was created to extend the existing Binary-Coded Decimal (BCD) Interchange Code, or BCDIC, which itself was devised as an efficient means of encoding the two "zone" and "number" punches on punched cards into six bits. The distinct encoding of 's' and 'S' (using position 2 instead of 1) was maintained from punched cards where it was desirable not to have hole punches too close to each other to ensure the integrity of the physical card.

While IBM was a chief proponent of the ASCII standardization committee, the company did not have time to prepare ASCII peripherals (such as card punch machines) to ship with its System/360 computers, so the company settled on EBCDIC. The System/360 became wildly successful, together with clones such as RCA Spectra 70, ICL System 4, and Fujitsu FACOM, thus so did EBCDIC.

All IBM mainframe and midrange peripherals and operating systems use EBCDIC as their inherent encoding (with toleration for ASCII, for example, ISPF in z/OS can browse and edit both EBCDIC and ASCII encoded files). Software and many hardware peripherals can translate to and from encodings, and modern mainframes (such as IBM zSeries) include processor instructions, at the hardware level, to accelerate translation between character sets.

There is an EBCDIC-oriented Unicode Transformation Format called UTF-EBCDIC proposed by the Unicode consortium, designed to allow easy updating of EBCDIC software to handle Unicode, but not intended to be used in open interchange environments. Even on systems with extensive EBCDIC support, it has not been popular. For example, z/OS supports Unicode (preferring UTF-16 specifically), but z/OS only has limited support for UTF-EBCDIC.

IBM AIX running on the RS/6000 and its descendants including the IBM Power Systems, Linux running on z Systems, and operating systems running on the IBM PC and its descendants use ASCII, as did AIX/370 and AIX/390 running on System/370 and System/390 mainframes.

The fact that all the code points were different was less of a problem for inter-operating with ASCII than the fact that sorting EBCDIC put lowercase letters before uppercase letters and letters before numbers, exactly the opposite of ASCII.

Software portability and data exchange are hindered by EBCDIC's lack of codes for several symbols (such as the brace characters) commonly used in programming and in network communications.

The gaps between letters made simple code that worked in ASCII fail on EBCDIC. For example, "codice_1" would set codice_2 to the 26 letters in the ASCII alphabet, but 41 characters including a number of unassigned ones in EBCDIC. Fixing this required complicating the code with function calls which was greatly resisted by programmers.

All ASCII codes stored within an eight-bit byte had nonnegative values on systems such as the PDP-11 that treated bytes as signed quantities. Software on those platforms often took advantage of that property, causing problems when it was ported to EBCDIC-based environments where many character codes had a 1 as the "sign" bit.

By using all eight bits EBCDIC may have encouraged the use of the eight-bit byte by IBM, while ASCII was more likely to be adopted by systems with 36 bits (as five seven-bit ASCII characters fit into one word). As eight-bit bytes became widespread, ASCII systems sometimes used the "unused" bit for other purposes such as parity, thus making it more difficult to transition to larger character sets.

The table below is based on CCSID 037, one of the code page variants of EBCDIC; it shows only the basic (English) EBCDIC characters. Characters 00–3F and FF are controls, 40 is space, 41 is no-break space ("RSP": "Required Space"), E1 is numeric space ("NSP": "Numeric Space"), and CA is soft hyphen. Characters are shown with their equivalent Unicode codes. Unassigned codes are typically filled with international or region-specific characters in the various EBCDIC code page variants, but the punctuation marks and other special characters, such as cent sign, are often moved around as well; only the letters and numbers and space have the same assignments in all EBCDIC code pages.

In each table cell below, the first row is an abbreviation for a control code or (for printable characters) the character itself; the second row is the Unicode code (blank for controls that don't exist in Unicode); and the third row is decimal value of the EBCDIC code.

EBCDIC-based Cyrillic DKOI character sets:


Open-source software advocate and hacker Eric S. Raymond writes in his "Jargon File" that EBCDIC was almost universally loathed by early hackers and programmers. The Jargon File 4.4.7 gives the following definition:
EBCDIC design was also the source of many jokes. One such joke went: 
References to the EBCDIC character set are made in the classic Infocom adventure game series "Zork". In the "Machine Room" in "Zork II", EBCDIC is used to imply an incomprehensible language:
A similar description can be found in the "Maintenance Room" in Zork:




</doc>
<doc id="9775" url="https://en.wikipedia.org/wiki?curid=9775" title="Endoplasmic reticulum">
Endoplasmic reticulum

The endoplasmic reticulum (ER) is a type of organelle found in eukaryotic cells that forms an interconnected network of flattened, membrane-enclosed sacs or tube-like structures known as cisternae. The membranes of the ER are continuous with the outer nuclear membrane. The endoplasmic reticulum occurs in most types of eukaryotic cells, but is absent from red blood cells and spermatozoa. There are two types of endoplasmic reticulum: rough and smooth. The outer (cytosolic) face of the rough endoplasmic reticulum is studded with ribosomes that are the sites of protein synthesis. The rough endoplasmic reticulum is especially prominent in cells such as hepatocytes. The smooth endoplasmic reticulum lacks ribosomes and functions in lipid manufacture and metabolism, the production of steroid hormones, and detoxification. The smooth ER is especially abundant in mammalian liver and gonad cells. The lacy membranes of the endoplasmic reticulum were first seen in 1945 using electron microscopy.

The ER was observed with light microscopy by Garnier in 1897, who coined the term "ergastoplasm". With electron microscopy, the lacy membranes of the endoplasmic reticulum were first seen in 1945 by Keith R. Porter, Albert Claude, Brody Meskers and Ernest F. Fullam. Later, the word "reticulum", which means "network", was applied by Porter in 1953 to describe this fabric of membranes.

The general structure of the endoplasmic reticulum is a network of membranes called cisternae. These sac-like structures are held together by the cytoskeleton. The phospholipid membrane encloses the cisternal space (or lumen), which is continuous with the perinuclear space but separate from the cytosol. The functions of the endoplasmic reticulum can be summarized as the synthesis and export of proteins and membrane lipids, but varies between ER and cell type and cell function. The quantity of both rough and smooth endoplasmic reticulum in a cell can slowly interchange from one type to the other, depending on the changing metabolic activities of the cell. Transformation can include embedding of new proteins in membrane as well as structural changes. Changes in protein content may occur without noticeable structural changes.

The surface of the rough endoplasmic reticulum (often abbreviated RER or Rough ER) (also called "granular endoplasmic reticulum") is studded with protein-manufacturing ribosomes giving it a "rough" appearance (hence its name). The binding site of the ribosome on the rough endoplasmic reticulum is the translocon. However, the ribosomes are not a stable part of this organelle's structure as they are constantly being bound and released from the membrane. A ribosome only binds to the RER once a specific protein-nucleic acid complex forms in the cytosol. This special complex forms when a free ribosome begins translating the mRNA of a protein destined for the secretory pathway. The first 5–30 amino acids polymerized encode a signal peptide, a molecular message that is recognized and bound by a signal recognition particle (SRP). Translation pauses and the ribosome complex binds to the RER translocon where translation continues with the nascent (new) protein forming into the RER lumen and/or membrane. The protein is processed in the ER lumen by an enzyme (a signal peptidase), which removes the signal peptide. Ribosomes at this point may be released back into the cytosol; however, non-translating ribosomes are also known to stay associated with translocons.

The membrane of the rough endoplasmic reticulum forms large double membrane sheets that are located near, and continuous with, the outer layer of the nuclear envelope. The double membrane sheets are stacked and connected through several right or left-handed helical ramps, the so-called Terasaki ramps, giving rise to a structure resembling a multi-storey car park. Although there is no continuous membrane between the endoplasmic reticulum and the Golgi apparatus, membrane-bound transport vesicles shuttle proteins between these two compartments. Vesicles are surrounded by coating proteins called COPI and COPII. COPII targets vesicles to the Golgi apparatus and COPI marks them to be brought back to the rough endoplasmic reticulum. The rough endoplasmic reticulum works in concert with the Golgi complex to target new proteins to their proper destinations. A second method of transport out of the endoplasmic reticulum involves areas called membrane contact sites, where the membranes of the endoplasmic reticulum and other organelles are held closely together, allowing the transfer of lipids and other small molecules.

The rough endoplasmic reticulum is key in multiple functions:

In most cells the smooth endoplasmic reticulum (abbreviated SER) is scarce. Instead there are areas where the ER is partly smooth and partly rough, this area is called the transitional ER. The transitional ER gets its name because it contains ER exit sites. These are areas where the transport vesicles that contain lipids and proteins made in the ER, detach from the ER and start moving to the Golgi apparatus. Specialized cells can have a lot of smooth endoplasmic reticulum and in these cells the smooth ER has many functions. It synthesizes lipids, phospholipids, and steroids. Cells which secrete these products, such as those in the testes, ovaries, and sebaceous glands have an abundance of smooth endoplasmic reticulum. It also carries out the metabolism of carbohydrates, detoxification of natural metabolism products and of alcohol and drugs, attachment of receptors on cell membrane proteins, and steroid metabolism. In muscle cells, it regulates calcium ion concentration. Smooth endoplasmic reticulum is found in a variety of cell types (both animal and plant), and it serves different functions in each. The smooth endoplasmic reticulum also contains the enzyme glucose-6-phosphatase, which converts glucose-6-phosphate to glucose, a step in gluconeogenesis. It is connected to the nuclear envelope and consists of tubules that are located near the cell periphery. These tubes sometimes branch forming a network that is reticular in appearance. In some cells, there are dilated areas like the sacs of rough endoplasmic reticulum. The network of smooth endoplasmic reticulum allows for an increased surface area to be devoted to the action or storage of key enzymes and the products of these enzymes.

The sarcoplasmic reticulum (SR), from the Greek σάρξ "sarx" ("flesh"), is smooth ER found in myocytes. The only structural difference between this organelle and the smooth endoplasmic reticulum is the medley of proteins they have, both bound to their membranes and drifting within the confines of their lumens. This fundamental difference is indicative of their functions: The endoplasmic reticulum synthesizes molecules, while the sarcoplasmic reticulum stores calcium ions and pumps them out into the sarcoplasm when the muscle fiber is stimulated. After their release from the sarcoplasmic reticulum, calcium ions interact with contractile proteins that utilize ATP to shorten the muscle fiber. The sarcoplasmic reticulum plays a major role in excitation-contraction coupling.

The endoplasmic reticulum serves many general functions, including the folding of protein molecules in sacs called cisternae and the transport of synthesized proteins in vesicles to the Golgi apparatus. Correct folding of newly made proteins is made possible by several endoplasmic reticulum chaperone proteins, including protein disulfide isomerase (PDI), ERp29, the Hsp70 family member BiP/Grp78, calnexin, calreticulin, and the peptidylpropyl isomerase family. Only properly folded proteins are transported from the rough ER to the Golgi apparatus – unfolded proteins cause an unfolded protein response as a stress response in the ER. Disturbances in redox regulation, calcium regulation, glucose deprivation, and viral infection or the over-expression of proteins can lead to endoplasmic reticulum stress response (ER stress), a state in which the folding of proteins slows, leading to an increase in unfolded proteins. This stress is emerging as a potential cause of damage in hypoxia/ischemia, insulin resistance, and other disorders.

Secretory proteins, mostly glycoproteins, are moved across the endoplasmic reticulum membrane. Proteins that are transported by the endoplasmic reticulum throughout the cell are marked with an address tag called a signal sequence. The N-terminus (one end) of a polypeptide chain (i.e., a protein) contains a few amino acids that work as an address tag, which are removed when the polypeptide reaches its destination. Nascent peptides reach the ER via the translocon, a membrane-embedded multiprotein complex. Proteins that are destined for places outside the endoplasmic reticulum are packed into transport vesicles and moved along the cytoskeleton toward their destination. In human fibroblasts, the ER is always co-distributed with microtubules and the depolymerisation of the latter cause its co-aggregation with mitochondria, which are also associated with the ER.

The endoplasmic reticulum is also part of a protein sorting pathway. It is, in essence, the transportation system of the eukaryotic cell. The majority of its resident proteins are retained within it through a retention motif. This motif is composed of four amino acids at the end of the protein sequence. The most common retention sequences are KDEL for lumen located proteins and KKXX for transmembrane protein. However, variations of KDEL and KKXX do occur, and other sequences can also give rise to endoplasmic reticulum retention. It is not known whether such variation can lead to sub-ER localizations. There are three KDEL (1, 2 and 3) receptors in mammalian cells, and they have a very high degree of sequence identity. The functional differences between these receptors remain to be established.

Abnormalities in XBP1 lead to a heightened endoplasmic reticulum stress response and subsequently causes a higher susceptibility for inflammatory processes that may even contribute to Alzheimer's disease. In the colon, XBP1 anomalies have been linked to the inflammatory bowel diseases including Crohn's disease.

The unfolded protein response (UPR) is a cellular stress response related to the endoplasmic reticulum. The UPR is activated in response to an accumulation of unfolded or misfolded proteins in the lumen of the endoplasmic reticulum. The UPR functions to restore normal function of the cell by halting protein translation, degrading misfolded proteins, and activating the signaling pathways that lead to increasing the production of molecular chaperones involved in protein folding. Sustained overactivation of the UPR has been implicated in prion diseases as well as several other neurodegenerative diseases and the inhibition of the UPR could become a treatment for those diseases.



</doc>
<doc id="9776" url="https://en.wikipedia.org/wiki?curid=9776" title="Enemy (disambiguation)">
Enemy (disambiguation)

An enemy or foe is an individual or group that is seen as forcefully adverse or threatening.

Enemy or The Enemy may refer to:












</doc>
<doc id="9778" url="https://en.wikipedia.org/wiki?curid=9778" title="Executive Order 9066">
Executive Order 9066

Executive Order 9066 was a United States presidential executive order signed and issued during World War II by United States President Franklin D. Roosevelt on February 19, 1942. This order authorized the Secretary of War to prescribe certain areas as military zones, clearing the way for the incarceration of Japanese Americans, German Americans, and Italian Americans in U.S. concentration camps.

The text of Executive Order 9066 was as follows:

On March 21, 1942, Roosevelt signed Public Law 503 (approved after only an hour of discussion in the Senate and thirty minutes in the House) in order to provide for the enforcement of his executive order. Authored by War Department official Karl Bendetsen—who would later be promoted to Director of the Wartime Civilian Control Administration and oversee the incarceration of Japanese Americans—the law made violations of military orders a misdemeanor punishable by up to $5,000 in fines and one year in prison.

As a result, approximately 120,000 men, women, and children of Japanese ancestry were evicted from the West Coast of the United States and held in American concentration camps and other confinement sites across the country. Japanese Americans in Hawaii were not incarcerated in the same way, despite the attack on Pearl Harbor. Although the Japanese American population in Hawaii was nearly 40% of the population of Hawaii itself, only a few thousand people were detained there, supporting the eventual finding that their mass removal on the West Coast was motivated by reasons other than "military necessity."

Japanese Americans and other Asians in the U.S. had suffered for decades from prejudice and racially-motivated fear. Laws preventing Asian Americans from owning land, voting, testifying against whites in court, and other racially discriminatory laws existed long before World War II. Additionally, the FBI, Office of Naval Intelligence and Military Intelligence Division had been conducting surveillance on Japanese American communities in Hawaii and the U.S. mainland from the early 1930s. In early 1941, President Roosevelt secretly commissioned a study to assess the possibility that Japanese Americans would pose a threat to U.S. security. The report, submitted exactly one month before Pearl Harbor was bombed, found that, "There will be no armed uprising of Japanese" in the United States. "For the most part," the Munson Report said, "the local Japanese are loyal to the United States or, at worst, hope that by remaining quiet they can avoid concentration camps or irresponsible mobs." A second investigation started in 1940, written by Naval Intelligence officer Kenneth Ringle and submitted in January 1942, likewise found no evidence of fifth column activity and urged against mass incarceration. Both were ignored.

Over two-thirds of the people of Japanese ethnicity were incarcerated—almost 70,000—were American citizens. Many of the rest had lived in the country between 20 and 40 years. Most Japanese Americans, particularly the first generation born in the United States (the "nisei"), considered themselves loyal to the United States of America. No Japanese American citizen or Japanese national residing in the United States was ever found guilty of sabotage or espionage.

Americans of Italian and German ancestry were also targeted by these restrictions, including internment. 11,000 people of German ancestry were interned, as were 3,000 people of Italian ancestry, along with some Jewish refugees. The interned Jewish refugees came from Germany, as the U.S. government did not differentiate between ethnic Jews and ethnic Germans (the term "Jewish" was defined as a religious practice, not an ethnicity). Some of the internees of European descent were interned only briefly, while others were held for several years beyond the end of the war. Like the Japanese American incarcerees, these smaller groups had American-born citizens in their numbers, especially among the children. A few members of ethnicities of other Axis countries were interned, but exact numbers are unknown.

Secretary of War Henry L. Stimson was responsible for assisting relocated people with transport, food, shelter, and other accommodations and delegated Colonel Karl Bendetsen to administer the removal of West Coast Japanese. Over the spring of 1942, Bendetsen issued Western Defense Command orders for Japanese Americans to present themselves for removal. The "evacuees" were taken first to temporary assembly centers, requisitioned fairgrounds and horse racing tracks where living quarters were often converted livestock stalls. As construction on the more permanent and isolated WRA camps was completed, the population was transferred by truck or train. These accommodations consisted of tar paper-walled frame buildings in parts of the country with bitter winters and often hot summers. The camps were guarded by armed soldiers and fenced with barbed wire (security measures not shown in published photographs of the camps). Camps held up to 18,000 people, and were small cities, with medical care, food, and education provided by the government. Adults were offered "camp jobs" with wages of $12 to $19 per month, and many camp services such as medical care and education were provided by the camp inmates themselves.

In December 1944, President Roosevelt suspended Executive Order 9066. Incarcerees were released, often to resettlement facilities and temporary housing, and the camps were shut down by 1946.

In the years after the war, the interned Japanese Americans had to rebuild their lives. United States citizens and long-time residents who had been incarcerated lost their personal liberties; many also lost their homes, businesses, property, and savings. Individuals born in Japan were not allowed to become naturalized US citizens until 1952.

U. S. President Gerald Ford rescinded Executive Order 9066 on February 19, 1976. In 1980, U. S. President Jimmy Carter signed legislation to create the Commission on Wartime Relocation and Internment of Civilians (CWRIC). The CWRIC was appointed to conduct an official governmental study of Executive Order 9066, related wartime orders, and their impact on Japanese Americans in the West and Alaska Natives in the Pribilof Islands.

In December 1982, the CWRIC issued its findings in "Personal Justice Denied", concluding that the incarceration of Japanese Americans had not been justified by military necessity. The report determined that the decision to incarcerate was based on "race prejudice, war hysteria, and a failure of political leadership". The Commission recommended legislative remedies consisting of an official Government apology and redress payments of $20,000 to each of the survivors; a public education fund was set up to help ensure that this would not happen again ().
On August 10, 1988, the Civil Liberties Act of 1988, based on the CWRIC recommendations, was signed into law by Ronald Reagan. On November 21, 1989, George H. W. Bush signed an appropriation bill authorizing payments to be paid out between 1990 and 1998. In 1990, surviving internees began to receive individual redress payments and a letter of apology. This bill applied to the Japanese Americans and to members of the Aleut people inhabiting the strategic Aleutian islands in Alaska who were also relocated.

The anniversary of the signing of Executive Order 9066 is now the Day of Remembrance, an annual commemoration of the unjust incarceration of the Japanese American community.




</doc>
<doc id="9779" url="https://en.wikipedia.org/wiki?curid=9779" title="Edvard Munch">
Edvard Munch

Edvard Munch (; ; 12 December 1863 – 23 January 1944) was a Norwegian painter and printmaker whose intensely evocative treatment of psychological themes built upon some of the main tenets of late 19th-century Symbolism and greatly influenced German Expressionism in the early 20th century. His best known work is "The Scream", painted in 1893.

Edvard Munch was born in a farmhouse in the village of Ådalsbruk in Løten, United Kingdoms of Sweden and Norway, to Laura Catherine Bjølstad and Christian Munch, the son of a priest. Christian was a doctor and medical officer who married Laura, a woman half his age, in 1861. Edvard had an elder sister, Johanne Sophie, and three younger siblings: Peter Andreas, Laura Catherine, and Inger Marie. Laura was artistically talented and may have encouraged Edvard and Sophie. Edvard was related to painter Jacob Munch and to historian Peter Andreas Munch.

The family moved to Christiania (renamed Kristiania in 1877, and now Oslo) in 1864 when Christian Munch was appointed medical officer at Akershus Fortress. Edvard's mother died of tuberculosis in 1868, as did Munch's favorite sister Johanne Sophie in 1877. After their mother's death, the Munch siblings were raised by their father and by their aunt Karen. Often ill for much of the winters and kept out of school, Edvard would draw to keep himself occupied. He was tutored by his school mates and his aunt. Christian Munch also instructed his son in history and literature, and entertained the children with vivid ghost-stories and the tales of American writer Edgar Allan Poe.

As Edvard remembered it, Christian's positive behavior toward his children was overshadowed by his morbid pietism. Munch wrote, "My father was temperamentally nervous and obsessively religious—to the point of psychoneurosis. From him I inherited the seeds of madness. The angels of fear, sorrow, and death stood by my side since the day I was born." Christian reprimanded his children by telling them that their mother was looking down from heaven and grieving over their misbehavior. The oppressive religious milieu, Edvard's poor health, and the vivid ghost stories helped inspire his macabre visions and nightmares; the boy felt that death was constantly advancing on him. One of Munch's younger sisters, Laura, was diagnosed with mental illness at an early age. Of the five siblings, only Andreas married, but he died a few months after the wedding. Munch would later write, "I inherited two of mankind's most frightful enemies—the heritage of consumption and insanity."

Christian Munch's military pay was very low, and his attempts to develop a private side practice failed, keeping his family in genteel but perennial poverty. They moved frequently from one cheap flat to another. Munch's early drawings and watercolors depicted these interiors, and the individual objects, such as medicine bottles and drawing implements, plus some landscapes. By his teens, art dominated Munch's interests. At thirteen, Munch had his first exposure to other artists at the newly formed Art Association, where he admired the work of the Norwegian landscape school. He returned to copy the paintings, and soon he began to paint in oils.

In 1879, Munch enrolled in a technical college to study engineering, where he excelled in physics, chemistry and math. He learned scaled and perspective drawing, but frequent illnesses interrupted his studies. The following year, much to his father's disappointment, Munch left the college determined to become a painter. His father viewed art as an "unholy trade", and his neighbors reacted bitterly and sent him anonymous letters. In contrast to his father's rabid pietism, Munch adopted an undogmatic stance toward art. He wrote his goal in his diary: "in my art I attempt to explain life and its meaning to myself."

In 1881, Munch enrolled at the Royal School of Art and Design of Kristiania, one of whose founders was his distant relative Jacob Munch. His teachers were sculptor Julius Middelthun and the naturalistic painter Christian Krohg. That year, Munch demonstrated his quick absorption of his figure training at the Academy in his first portraits, including one of his father and his first self-portrait. In 1883, Munch took part in his first public exhibition and shared a studio with other students. His full-length portrait of Karl Jensen-Hjell, a notorious bohemian-about-town, earned a critic's dismissive response: "It is impressionism carried to the extreme. It is a travesty of art." Munch's nude paintings from this period survive only in sketches, except for "Standing Nude" (1887). They may have been confiscated by his father.

During these early years, Munch experimented with many styles, including Naturalism and Impressionism. Some early works are reminiscent of Manet. Many of these attempts brought him unfavorable criticism from the press and garnered him constant rebukes by his father, who nonetheless provided him with small sums for living expenses. At one point, however, Munch's father, perhaps swayed by the negative opinion of Munch's cousin Edvard Diriks (an established, traditional painter), destroyed at least one painting (likely a nude) and refused to advance any more money for art supplies.

Munch also received his father's ire for his relationship with Hans Jæger, the local nihilist who lived by the code "a passion to destroy is also a creative passion" and who advocated suicide as the ultimate way to freedom. Munch came under his malevolent, anti-establishment spell. "My ideas developed under the influence of the bohemians or rather under Hans Jæger. Many people have mistakenly claimed that my ideas were formed under the influence of Strindberg and the Germans…but that is wrong. They had already been formed by then." At that time, contrary to many of the other bohemians, Munch was still respectful of women, as well as reserved and well-mannered, but he began to give in to the binge drinking and brawling of his circle. He was unsettled by the sexual revolution going on at the time and by the independent women around him. He later turned cynical concerning sexual matters, expressed not only in his behavior and his art, but in his writings as well, an example being a long poem called "The City of Free Love". Still dependent on his family for many of his meals, Munch's relationship with his father remained tense over concerns about his bohemian life.

After numerous experiments, Munch concluded that the Impressionist idiom did not allow sufficient expression. He found it superficial and too akin to scientific experimentation. He felt a need to go deeper and explore situations brimming with emotional content and expressive energy. Under Jæger's commandment that Munch should "write his life", meaning that Munch should explore his own emotional and psychological state, the young artist began a period of reflection and self-examination, recording his thoughts in his "soul's diary". This deeper perspective helped move him to a new view of his art. He wrote that his painting "The Sick Child" (1886), based on his sister's death, was his first "soul painting", his first break from Impressionism. The painting received a negative response from critics and from his family, and caused another "violent outburst of moral indignation" from the community.

Only his friend Christian Krohg defended him:
He paints, or rather regards, things in a way that is different from that of other artists. He sees only the essential, and that, naturally, is all he paints. For this reason Munch's pictures are as a rule "not complete", as people are so delighted to discover for themselves. Oh, yes, they are complete. His complete handiwork. Art is complete once the artist has really said everything that was on his mind, and this is precisely the advantage Munch has over painters of the other generation, that he really knows how to show us what he has felt, and what has gripped him, and to this he subordinates everything else.

Munch continued to employ a variety of brushstroke techniques and color palettes throughout the 1880s and early 1890s, as he struggled to define his style. His idiom continued to veer between naturalistic, as seen in "Portrait of Hans Jæger", and impressionistic, as in "Rue Lafayette". His "Inger On the Beach" (1889), which caused another storm of confusion and controversy, hints at the simplified forms, heavy outlines, sharp contrasts, and emotional content of his mature style to come. He began to carefully calculate his compositions to create tension and emotion. While stylistically influenced by the Post-Impressionists, what evolved was a subject matter which was symbolist in content, depicting a state of mind rather than an external reality. In 1889, Munch presented his first one-man show of nearly all his works to date. The recognition it received led to a two-year state scholarship to study in Paris under French painter Léon Bonnat.

Munch seems to have been an early critic of photography as an art form, and remarked that it "will never compete with the brush and the palette, until such time as photographs can be taken in Heaven or Hell!"

Munch's younger sister Laura was the subject of his 1899 interior "Melancholy: Laura". Amanda O'Neill says of the work, "In this heated claustrophobic scene Munch not only portrays Laura's tragedy, but his own dread of the madness he might have inherited."

Munch arrived in Paris during the festivities of the Exposition Universelle (1889) and roomed with two fellow Norwegian artists. His picture "Morning" (1884) was displayed at the Norwegian pavilion. He spent his mornings at Bonnat's busy studio (which included live female models) and afternoons at the exhibition, galleries, and museums (where students were expected to make copies as a way of learning technique and observation). Munch recorded little enthusiasm for Bonnat's drawing lessons—"It tires and bores me—it's numbing"—but enjoyed the master's commentary during museum trips.

Munch was enthralled by the vast display of modern European art, including the works of three artists who would prove influential: Paul Gauguin, Vincent van Gogh, and Henri de Toulouse-Lautrec—all notable for how they used color to convey emotion. Munch was particularly inspired by Gauguin's "reaction against realism" and his credo that "art was human work and not an imitation of Nature", a belief earlier stated by Whistler. As one of his Berlin friends said later of Munch, "he need not make his way to Tahiti to see and experience the primitive in human nature. He carries his own Tahiti within him." Influenced by Gauguin, as well as the etchings of German artist Max Klinger, Munch experimented with prints as a medium to create graphic versions of his works. In 1896 he created his first woodcuts—a medium that proved ideal to Munch's symbolic imagery. Together with his contemporary Nikolai Astrup, Munch is considered an innovator of the woodcut medium in Norway.

In December 1889 his father died, leaving Munch's family destitute. He returned home and arranged a large loan from a wealthy Norwegian collector when wealthy relatives failed to help, and assumed financial responsibility for his family from then on. Christian's death depressed him and he was plagued by suicidal thoughts: "I live with the dead—my mother, my sister, my grandfather, my father…Kill yourself and then it's over. Why live?" Munch's paintings of the following year included sketchy tavern scenes and a series of bright cityscapes in which he experimented with the pointillist style of Georges Seurat.

By 1892, Munch formulated his characteristic, and original, Synthetist aesthetic, as seen in "Melancholy" (1891), in which color is the symbol-laden element. Considered by the artist and journalist Christian Krohg as the first Symbolist painting by a Norwegian artist, "Melancholy" was exhibited in 1891 at the Autumn Exhibition in Oslo. In 1892, Adelsteen Normann, on behalf of the Union of Berlin Artists, invited Munch to exhibit at its November exhibition, the society's first one-man exhibition. However, his paintings evoked bitter controversy (dubbed "The Munch Affair"), and after one week the exhibition closed. Munch was pleased with the "great commotion", and wrote in a letter: "Never have I had such an amusing time—it's incredible that something as innocent as painting should have created such a stir."

In Berlin, Munch became involved in an international circle of writers, artists and critics, including the Swedish dramatist and leading intellectual August Strindberg, whom he painted in 1892. He also met Danish writer and painter Holger Drachmann, whom he painted in 1898. Drachmann was 17 years Munch's senior and a drinking companion at Zum schwarzen Ferkel in 1893-94. In 1894 Drachmann wrote of Munch: "He struggles hard. Good luck with your struggles, lonely Norwegian." 

During his four years in Berlin, Munch sketched out most of the ideas that would comprise his major work, "The Frieze of Life", first designed for book illustration but later expressed in paintings. He sold little, but made some income from charging entrance fees to view his controversial paintings. Already, Munch was showing a reluctance to part with his paintings, which he termed his "children".

His other paintings, including casino scenes, show a simplification of form and detail which marked his early mature style. Munch also began to favor a shallow pictorial space and a minimal backdrop for his frontal figures. Since poses were chosen to produce the most convincing images of states of mind and psychological conditions, as in "Ashes", the figures impart a monumental, static quality. Munch's figures appear to play roles on a theatre stage ("Death in the Sick-Room"), whose pantomime of fixed postures signify various emotions; since each character embodies a single psychological dimension, as in "The Scream", Munch's men and women began to appear more symbolic than realistic. He wrote, "No longer should interiors be painted, people reading and women knitting: there would be living people, breathing and feeling, suffering and loving."

"The Scream" exists in four versions: two pastels (1893 and 1895) and two paintings (1893 and 1910). There are also several lithographs of "The Scream" (1895 and later).

The 1895 pastel sold at auction on 2 May 2012 for US$119,922,500, including commission. It is the most colorful of the versions and is distinctive for the downward-looking stance of one of its background figures. It is also the only version not held by a Norwegian museum.

The 1893 version (shown here) was stolen from the National Gallery in Oslo in 1994 and recovered. The 1910 painting was stolen in 2004 from The Munch Museum in Oslo, but recovered in 2006 with limited damage.

"The Scream" is Munch's most famous work, and one of the most recognizable paintings in all art. It has been widely interpreted as representing the universal anxiety of modern man. Painted with broad bands of garish color and highly simplified forms, and employing a high viewpoint, it reduces the agonized figure to a garbed skull in the throes of an emotional crisis.

With this painting, Munch met his stated goal of "the study of the soul, that is to say the study of my own self". Munch wrote of how the painting came to be: "I was walking down the road with two friends when the sun set; suddenly, the sky turned as red as blood. I stopped and leaned against the fence, feeling unspeakably tired. Tongues of fire and blood stretched over the bluish black fjord. My friends went on walking, while I lagged behind, shivering with fear. Then I heard the enormous, infinite scream of nature." He later described the personal anguish behind the painting, "for several years I was almost mad… You know my picture, 'The Scream?' I was stretched to the limit—nature was screaming in my blood… After that I gave up hope ever of being able to love again."

In summing up the painting's effects, author Martha Tedeschi has stated: ""Whistler's Mother", Wood's "American Gothic", Leonardo da Vinci's "Mona Lisa" and Edvard Munch's "The Scream" have all achieved something that most paintings—regardless of their art historical importance, beauty, or monetary value—have not: they communicate a specific meaning almost immediately to almost every viewer. These few works have successfully made the transition from the elite realm of the museum visitor to the enormous venue of popular culture."

In December 1893, Unter den Linden in Berlin was the location of an exhibition of Munch's work, showing, among other pieces, six paintings entitled "Study for a Series: Love." This began a cycle he later called the "Frieze of Life—A Poem about Life, Love and Death." "Frieze of Life" motifs, such as "The Storm" and "Moonlight," are steeped in atmosphere. Other motifs illuminate the nocturnal side of love, such as "Rose and Amelie" and "Vampire". In "Death in the Sickroom", the subject is the death of his sister Sophie, which he re-worked in many future variations. The dramatic focus of the painting, portraying his entire family, is dispersed in the separate and disconnected figures of sorrow. In 1894, he enlarged the spectrum of motifs by adding "Anxiety", "Ashes", "Madonna" and "Women in Three Stages" (from innocence to old age).

Around the start of the 20th century, Munch worked to finish the "Frieze". He painted a number of pictures, several of them in larger format and to some extent featuring the Art Nouveau aesthetics of the time. He made a wooden frame with carved reliefs for the large painting "Metabolism" (1898), initially called "Adam and Eve". This work reveals Munch's preoccupation with the "fall of man" and his pessimistic philosophy of love. Motifs such as "The Empty Cross" and "Golgotha" (both c. 1900) reflect a metaphysical orientation, and also reflect Munch's pietistic upbringing. The entire "Frieze" was shown for the first time at the secessionist exhibition in Berlin in 1902.

"The Frieze of Life" themes recur throughout Munch's work but he especially focused on them in the mid-1890s. In sketches, paintings, pastels and prints, he tapped the depths of his feelings to examine his major motifs: the stages of life, the femme fatale, the hopelessness of love, anxiety, infidelity, jealousy, sexual humiliation, and separation in life and death. These themes are expressed in paintings such as "The Sick Child" (1885), "Love and Pain" (retitled "Vampire"; 1893–94), "Ashes" (1894), and "The Bridge". The latter shows limp figures with featureless or hidden faces, over which loom the threatening shapes of heavy trees and brooding houses. Munch portrayed women either as frail, innocent sufferers (see "Puberty" and "Love and Pain") or as the cause of great longing, jealousy and despair (see "Separation", "Jealousy", and "Ashes").

Munch often uses shadows and rings of color around his figures to emphasize an aura of fear, menace, anxiety, or sexual intensity. These paintings have been interpreted as reflections of the artist's sexual anxieties, though it could also be argued that they represent his turbulent relationship with love itself and his general pessimism regarding human existence. Many of these sketches and paintings were done in several versions, such as "Madonna", "Hands" and "Puberty", and also transcribed as wood-block prints and lithographs. Munch hated to part with his paintings because he thought of his work as a single body of expression. So to capitalize on his production and make some income, he turned to graphic arts to reproduce many of his most famous paintings, including those in this series. Munch admitted to the personal goals of his work but he also offered his art to a wider purpose, "My art is really a voluntary confession and an attempt to explain to myself my relationship with life—it is, therefore, actually a sort of egoism, but I am constantly hoping that through this I can help others achieve clarity."

While attracting strongly negative reactions, in the 1890s Munch began to receive some understanding of his artistic goals, as one critic wrote, "With ruthless contempt for form, clarity, elegance, wholeness, and realism, he paints with intuitive strength of talent the most subtle visions of the soul." One of his great supporters in Berlin was Walther Rathenau, later the German foreign minister, who strongly contributed to his success.

In 1896, Munch moved to Paris, where he focused on graphic representations of his "Frieze of Life" themes. He further developed his woodcut and lithographic technique. Munch's "Self-Portrait With Skeleton Arm" (1895) is done with an etching needle-and-ink method also used by Paul Klee. Munch also produced multi-colored versions of "The Sick Child", concerning tuberculosis, which sold well, as well as several nudes and multiple versions of "Kiss" (1892). Many of the Parisian critics still considered Munch's work "violent and brutal" but his exhibitions received serious attention and good attendance. His financial situation improved considerably and in 1897, Munch bought himself a summer house facing the fjords of Kristiania, a small fisherman's cabin built in the late 18th century, in the small town of Åsgårdstrand in Norway. He dubbed this home the "Happy House" and returned here almost every summer for the next 20 years. It was this place he missed when he was abroad and when he felt depressed and exhausted. "To walk in Åsgårdstrand is like walking among my paintings—I get so inspired to paint when I am here".
In 1897 Munch returned to Kristiania, where he also received grudging acceptance—one critic wrote, "A fair number of these pictures have been exhibited before. In my opinion these improve on acquaintance." In 1899, Munch began an intimate relationship with Tulla Larsen, a "liberated" upper-class woman. They traveled to Italy together and upon returning, Munch began another fertile period in his art, which included landscapes and his final painting in "The Frieze of Life" series, "The Dance of Life" (1899). Larsen was eager for marriage, and Munch begged off. His drinking and poor health reinforced his fears, as he wrote in the third person: "Ever since he was a child he had hated marriage. His sick and nervous home had given him the feeling that he had no right to get married." Munch almost gave in to Tulla, but fled from her in 1900, also turning away from her considerable fortune, and moved to Berlin. His "Girls on the Jetty", created in eighteen different versions, demonstrated the theme of feminine youth without negative connotations. In 1902, he displayed his works thematically at the hall of the Berlin Secession, producing "a symphonic effect—it made a great stir—a lot of antagonism—and a lot of approval." The Berlin critics were beginning to appreciate Munch's work even though the public still found his work alien and strange.

The good press coverage gained Munch the attention of influential patrons Albert Kollman and Max Linde. He described the turn of events in his diary, "After twenty years of struggle and misery forces of good finally come to my aid in Germany—and a bright door opens up for me." However, despite this positive change, Munch's self-destructive and erratic behavior involved him first with a violent quarrel with another artist, then with an accidental shooting in the presence of Tulla Larsen, who had returned for a brief reconciliation, which injured two of his fingers. She finally left him and married a younger colleague of Munch. Munch took this as a betrayal, and he dwelled on the humiliation for some time to come, channeling some of the bitterness into new paintings. His paintings "Still Life (The Murderess)" and "The Death of Marat I", done in 1906-7, clearly reference the shooting incident and the emotional after effects.

In 1903-4, Munch exhibited in Paris where the coming Fauvists, famous for their boldly false colors, likely saw his works and might have found inspiration in them. When the Fauves held their own exhibit in 1906, Munch was invited and displayed his works with theirs. After studying the sculpture of Rodin, Munch may have experimented with plasticine as an aid to design, but he produced little sculpture. During this time, Munch received many commissions for portraits and prints which improved his usually precarious financial condition. In 1906, he painted the screen for an Ibsen play in the small Kammerspiele Theatre located in Berlin's Deutsches Theater, in which the "Frieze of Life" was hung. The theatre's director Max Reinhardt later sold it; it is now in the Berlin Nationalgalerie. After an earlier period of landscapes, in 1907 he turned his attention again to human figures and situations.

In the autumn of 1908, Munch's anxiety, compounded by excessive drinking and brawling, had become acute. As he later wrote, "My condition was verging on madness—it was touch and go." Subject to hallucinations and feelings of persecution, he entered the clinic of Dr. Daniel Jacobson. The therapy Munch received for the next eight months included diet and "electrification" (a treatment then fashionable for nervous conditions, not to be confused with electroconvulsive therapy). Munch's stay in hospital stabilized his personality, and after returning to Norway in 1909, his work became more colorful and less pessimistic. Further brightening his mood, the general public of Kristiania finally warmed to his work, and museums began to purchase his paintings. He was made a Knight of the Royal Order of St. Olav "for services in art". His first American exhibit was in 1912 in New York.

As part of his recovery, Dr. Jacobson advised Munch to only socialize with good friends and avoid drinking in public. Munch followed this advice and in the process produced several full-length portraits of high quality of friends and patrons—honest portrayals devoid of flattery. He also created landscapes and scenes of people at work and play, using a new optimistic style—broad, loose brushstrokes of vibrant color with frequent use of white space and rare use of black—with only occasional references to his morbid themes. With more income, Munch was able to buy several properties giving him new vistas for his art and he was finally able to provide for his family.

The outbreak of World War I found Munch with divided loyalties, as he stated, "All my friends are German but it is France that I love." In the 1930s, his German patrons, many Jewish, lost their fortunes and some their lives during the rise of the Nazi movement. Munch found Norwegian printers to substitute for the Germans who had been printing his graphic work. Given his poor health history, during 1918 Munch felt himself lucky to have survived a bout of the Spanish Flu, the worldwide pandemic of that year.

Munch spent most of his last two decades in solitude at his nearly self-sufficient estate in Ekely, at Skøyen, Oslo. Many of his late paintings celebrate farm life, including several in which he used his work horse "Rousseau" as a model. Without any effort, Munch attracted a steady stream of female models, whom he painted as the subjects of numerous nude paintings. He likely had sexual relationships with some of them. Munch occasionally left his home to paint murals on commission, including those done for the Freia chocolate factory.

To the end of his life, Munch continued to paint unsparing self-portraits, adding to his self-searching cycle of his life and his unflinching series of takes on his emotional and physical states. In the 1930s and 1940s, the Nazis labeled Munch's work "degenerate art" (along with that of Picasso, Paul Klee, Matisse, Gauguin and many other modern artists) and removed his 82 works from German museums. Adolf Hitler announced in 1937, "For all we care, those prehistoric Stone Age culture barbarians and art-stutterers can return to the caves of their ancestors and there can apply their primitive international scratching."

In 1940, the Germans invaded Norway and the Nazi party took over the government. Munch was 76 years old. With nearly an entire collection of his art in the second floor of his house, Munch lived in fear of a Nazi confiscation. Seventy-one of the paintings previously taken by the Nazis had been returned to Norway through purchase by collectors (the other eleven were never recovered), including "The Scream" and "The Sick Child", and they too were hidden from the Nazis.

Munch died in his house at Ekely near Oslo on 23 January 1944, about a month after his 80th birthday. His Nazi-orchestrated funeral suggested to Norwegians that he was a Nazi sympathizer, a kind of appropriation of the independent artist. The city of Oslo bought the Ekely estate from Munch's heirs in 1946; his house was demolished in May 1960.

When Munch died, his remaining works were bequeathed to the city of Oslo, which built the Munch Museum at Tøyen (it opened in 1963). The museum holds a collection of approximately 1,100 paintings, 4,500 drawings, and 18,000 prints, the broadest collection of his works in the world. The Munch Museum serves as Munch's official estate, and has been active in responding to copyright infringements, as well as clearing copyright for the work, such as the appearance of Munch's "The Scream" in a 2006 M&M's advertising campaign. The U.S. copyright representative for the Munch Museum and the Estate of Edvard Munch is the Artists Rights Society.

Munch's art was highly personalized and he did little teaching. His "private" symbolism was far more personal than that of other Symbolist painters such as Gustave Moreau and James Ensor. Munch was still highly influential, particularly with the German Expressionists, who followed his philosophy, "I do not believe in the art which is not the compulsive result of Man's urge to open his heart." Many of his paintings, including "The Scream", have universal appeal in addition to their highly personal meaning.

Munch's works are now represented in numerous major museums and galleries in Norway and abroad. His cabin, "the Happy House", was given to the municipality of Åsgårdstrand in 1944; it serves as a small Munch Museum. The inventory has been maintained exactly as he left it.

One version of "The Scream" was stolen from the National Gallery in 1994. In 2004, another version of "The Scream", along with one of "Madonna", was stolen from the Munch Museum in a daring daylight robbery. All were eventually recovered, but the paintings stolen in the 2004 robbery were extensively damaged. They have been meticulously restored and are on display again. Three Munch works were stolen from the Hotel Refsnes Gods in 2005; they were shortly recovered, although one of the works was damaged during the robbery.

In October 2006, the color woodcut "Two people. The lonely" ("To mennesker. De ensomme") set a new record for his prints when it was sold at an auction in Oslo for 8.1 million NOK (US$1.27 million). It also set a record for the highest price paid in auction in Norway. On 3 November 2008, the painting "Vampire" set a new record for his paintings when it was sold for US$38.162 million at Sotheby's New York.

Munch's image appears on the Norwegian 1,000 kroner note, along with pictures inspired by his artwork.

In February 2012, a major Munch exhibition, "Edvard Munch. The Modern Eye," opened at the Schirn Kunsthalle Frankfurt; the exhibition was opened by Mette-Marit, Crown Princess of Norway.

In May 2012, "The Scream" sold for $119.9 million, and is the second most expensive artwork ever sold at an open auction. (It was surpassed in November 2013 by "Three Studies of Lucian Freud", which sold for $142.4 million).

In 2013, four of Munch's paintings were depicted in a series of stamps by the Norwegian postal service, to commemorate in 2014 the 150th anniversary of his birth.

On 14 November 2016 a version of Munch's The Girls on the Bridge sold for US$54.5 million at Sotheby's, New York, making it the second highest price achieved for one of his paintings.

In 1911 the final competition for the decoration of the large walls of the University of Oslo Aula (assembly hall) was held between Munch and Emanuel Vigeland. The episode is known as the "Aula Controversy". In 1914 Munch was finally commissioned to decorate the Aula and the work was completed in 1916. This major work in Norwegian monumental painting includes 11 paintings covering 223 m. "The Sun", "History" and "Alma Mater" are the key works in this sequence. Munch declared: “I wanted the decorations to form a complete and independent world of ideas, and I wanted their visual expression to be both distinctively Norwegian and universally human.” In 2014 it was suggested that the Aula paintings have a value of at least 500 million kroner.






</doc>
<doc id="9781" url="https://en.wikipedia.org/wiki?curid=9781" title="Extended Industry Standard Architecture">
Extended Industry Standard Architecture

The Extended Industry Standard Architecture (in practice almost always shortened to EISA and frequently pronounced "eee-suh") is a bus standard for IBM PC compatible computers. It was announced in September 1988 by a consortium of PC clone vendors (the "Gang of Nine") as a counter to IBM's use of its proprietary Micro Channel architecture (MCA) in its PS/2 series.

EISA extends the AT bus, which the Gang of Nine retroactively renamed to the ISA bus to avoid infringing IBM's trademark on its PC/AT computer, to 32 bits and allows more than one CPU to share the bus. The bus mastering support is also enhanced to provide access to 4 GB of memory. Unlike MCA, EISA can accept older XT and ISA boards — the lines and slots for EISA are a superset of ISA.

EISA was much favoured by manufacturers due to the proprietary nature of MCA, and even IBM produced some machines supporting it. It was somewhat expensive to implement (though not as much as MCA), so it never became particularly popular in desktop PCs. However, it was reasonably successful in the server market, as it was better suited to bandwidth-intensive tasks (such as disk access and networking). Most EISA cards produced were either SCSI or network cards. EISA was also available on some non-IBM compatible machines such as the AlphaServer, HP 9000-D, SGI Indigo2 and MIPS Magnum.

By the time there was a strong market need for a bus of these speeds and capabilities for desktop computers, the VESA Local Bus and later PCI filled this niche and EISA vanished into obscurity.

The original IBM PC included five 8-bit slots, running at the system clock speed of 4.77 MHz. The PC/AT, introduced in 1984, had three 8-bit slots and five 16-bit slots, all running at the system clock speed of 6 MHz in the earlier models and 8 MHz in the last version of the computer. The 16-bit slots were a superset of the 8-bit configuration, so "most" 8-bit cards were able to plug into a 16-bit slot (some cards used a "skirt" design that physically interfered with the extended portion of the slot) and continue to run in 8-bit mode. One of the key reasons for the success of the IBM PC (and the PC clones that followed it) was the active ecosystem of third-party expansion cards available for the machines. IBM was restricted from patenting the bus, and widely published the bus specifications.

As the PC-clone industry continued to build momentum in the mid- to late-1980s, several problems with the bus began to be apparent. First, because the "AT slot" (as it was known at the time) was not managed by any central standards group, there was nothing to prevent a manufacturer from "pushing" the standard. One of the most common issues was that as PC clones became more common, PC manufacturers began ratcheting up the processor speed to maintain a competitive advantage. Unfortunately, because the ISA bus was originally locked to the processor clock, this meant that some 286 machines had ISA buses that ran at 10, 12, or even 16 MHz. In fact, the first system to clock the ISA bus at 8 MHz was the turbo 8088 clones that clocked the processors at 8 MHz. This caused many issues with incompatibility, where a true IBM-compatible third-party card (designed for an 8 MHz or 4.77 MHz bus) might not work in a higher speed system (or even worse, would work unreliably). Most PC makers eventually decoupled the slot clock from the system clock, but there was still no standards body to "police" the industry.

As companies like Dell modified the AT bus design, the architecture was so well entrenched that no single clone manufacturer had the leverage to create a standardized alternative, and there was no compelling reason for them to cooperate on a new standard. Because of this, when the first 386-based system (the Compaq Deskpro 386) hit the market in 1986, it still supported 16-bit slots. Other 386 PCs followed suit, and the AT (later ISA) bus remained a part of most systems even into the late 1990s.

Meanwhile, IBM began to worry that it was losing control of the industry it had created. In 1987, IBM released the PS/2 line of computers, which included the MCA bus. MCA included numerous enhancements over the 16-bit AT bus, including bus mastering, burst mode, software configurable resources, and 32-bit capabilities. However, in an effort to reassert its dominant role, IBM patented the bus, and placed stringent licensing and royalty policies on its use. A few manufacturers did produce licensed MCA machines (most notably NCR), but overall the industry balked at IBM's restrictions.

Steve Gibson proposed that clone makers adopt NuBus. Instead, a group (the "Gang of Nine"), led by Compaq, created a new bus, which was named the Extended (or Enhanced) Industry Standard Architecture, or "EISA". (The 16-bit bus became known as Industry Standard Architecture, or "ISA".) This provided virtually all of the technical advantages of MCA, while remaining compatible with existing 8-bit and 16-bit cards, and (most enticing to system and card makers) minimal licensing cost.

The EISA bus slot is a two-level staggered pin system, with the upper part of the slot corresponding to the standard ISA bus pin layout. The additional features of the EISA bus are implemented on the lower part of the slot connector, using thin traces inserted into the insulating gap of the upper / ISA card card edge connector. Additionally the lower part of the bus has five keying notches, so an ISA card with unusually long traces cannot accidentally extend down into the lower part of the slot. 

Intel introduced their first EISA chipset (and also their first chipset in the modern sense of the word) as the 82350 in September 1989. Intel introduced a lower cost variant as the 82350DT announced in April 1991; it began shipping in June of that year.

The first EISA computer announced was the HP Vectra 486 in October 1989. The first EISA computers to hit the market were the Compaq Deskpro 486 and the SystemPro. The SystemPro, being one of the first PC-style systems designed as a network server, was built from the ground up to take full advantage of the EISA bus. It included such features as multiprocessing, hardware RAID, and bus-mastering network cards.

Ironically, one of the benefits to come out of the EISA standard was a final codification of the standard to which ISA slots and cards should be held (in particular, clock speed was fixed at an industry standard of 8.33 MHz). Thus, even systems which didn't use the EISA bus gained the advantage of having the ISA standardized, which contributed to its longevity.

The "Gang of Nine" was the informal name given to the consortium of personal computer manufacturing companies that together created the EISA bus. Rival members generally acknowledged Compaq's leadership, with one stating in 1989 that within the Gang of Nine "when you have 10 people sit down before a table to write a letter to the president, someone has to write the letter. Compaq is sitting down at the typewriter". The members were:

Although the MCA bus had a slight performance advantage over EISA (bus speed of 10 MHz, compared to 8.33 MHz), EISA contained almost all of the technological benefits that MCA boasted, including bus mastering, burst mode, software configurable resources, and 32-bit data/address buses. These brought EISA nearly to par with MCA from a performance standpoint, and EISA easily defeated MCA in industry support.

EISA replaced the tedious jumper configuration common with ISA cards with software-based configuration. Every EISA system shipped with an EISA configuration utility; this was usually a slightly customized version of the standard utilities written by the EISA chipset makers. The user would boot into this utility, either from floppy disk or on a dedicated hard drive partition. The utility software would detect all EISA cards in the system, and could configure any hardware resources (interrupts, memory ports, etc.) on any EISA card (each EISA card would include a disk with information that described the available options on the card), or on the EISA system motherboard. The user could also enter information about ISA cards in the system, allowing the utility to automatically reconfigure EISA cards to avoid resource conflicts.

Similarly, Windows 95, with its Plug-and-Play capability, was not able to change the configuration of EISA cards, but it could detect the cards, read their configuration, and reconfigure Plug and Play hardware to avoid resource conflicts. Windows 95 would also automatically attempt to install appropriate drivers for detected EISA cards.

EISA's success was far from guaranteed. Many manufacturers, including those in the "Gang of Nine", researched the possibility of using MCA. For example, Compaq actually produced prototype DeskPro systems using the bus. However, these were never put into production, and when it was clear that MCA had lost, Compaq allowed its MCA license to expire (the license actually cost relatively little; the primary costs associated with MCA, and at which the industry revolted, were royalties to be paid per system shipped).
On the other hand, when it became clear to IBM that Micro Channel was dying, IBM licensed EISA for use in a few server systems.



</doc>
<doc id="9789" url="https://en.wikipedia.org/wiki?curid=9789" title="Earthdawn">
Earthdawn

Earthdawn is a fantasy role-playing game, originally produced by FASA in 1993. In 1999 it was licensed to Living Room Games, which produced the "Second Edition". It was licensed to RedBrick in 2003, who released the Classic Edition in 2005 and the game's Third Edition in 2009 (the latter through Mongoose Publishing's Flaming Cobra imprint). The license is now held (again) by FASA Corporation through FASA Games, Inc., who have released the Fourth Edition, with updated mechanics and an advanced metaplot timeline.

The game is similar to fantasy games like "Dungeons & Dragons", but draws more inspiration from games like "RuneQuest". The rules of the game are tightly bound to the underlying magical metaphysics, with the goal of creating a rich, logical fantasy world. Like many role-playing games from the nineties, "Earthdawn" focuses much of its detail on its setting, a province called Barsaive.

Starting in 1993, FASA released over 20 gaming supplements describing this universe; however, it closed down production of "Earthdawn" in January 1999. During that time several novels and short-story anthologies set in the "Earthdawn" universe were also released. In late 1999, FASA granted Living Room Games a licensing agreement to produce new material for the game.

The "Second Edition" did not alter the setting, though it did update the timeline to include events that took place in Barsaive. There were a few changes to the rules in the "Second Edition"; some classes were slightly different or altered abilities from the original. The changes were meant to allow for more rounded characters and better balance of play. Living Room Games last published in 2005 and they no longer have a license with FASA to publish Earthdawn material.

In 2003 a second license was granted to RedBrick, who developed their own edition based on the FASA products, while releasing the original FASA books in PDF form. The "Earthdawn Classic Player's Compendium" and "Earthdawn Classic Gamemaster's Compendium" are essentially an alternative Second Edition, but without a version designation (since the material is compatible anyway). Each book has over 500 pages and summarizes much of what FASA published—not only the game mechanics, but also the setting, narrations, and stories. For example, each Discipline has its own chapter, describing it from the point of view of different adepts. Likewise, Barsaive gets a complete treatment, and the chapters contain a lot of log entries and stories in addition to the setting descriptions; the same applies to Horrors and Dragons. All previous Errata are merged into the text, correcting previous edition errors and providing rules clarifications.
In 2012, RedBrick announced the transfer of the Earthdawn license back to FASA Corporation (and subsequently to FASA Games, Inc.). FASA Games released RedBrick's Revised Third Edition Player's Guide, based on the Earthdawn Third Edition rules, but in a smaller format book. FASA noted, however, that there is no need for owners of the Third Edition to buy into the Revised Third Edition.

In 2014, FASA Games announced the forthcoming publication of Earthdawn Fourth Edition and launched a successful Kickstarter to support the project. Fourth Edition is described as a reworking of the game mechanics, with redundancies eliminated, and a simpler success level system. The game world is advanced five years, past the end of the Barsaive-Thera War, in order to clear dangling threads in the metaplot and open the game world to new stories. The first Fourth Edition title—the Player's Guide—was released in early 2015. In 2014 FASA Corporation also gave permission for Impact Miniatures to return the original Heartbreaker Hobbies & Games Official Earthdawn Miniatures range to production. In order to fund this, Impact Miniatures launched a successful Kickstarter project.

In Barsaive, magic, like many things in nature, goes through cycles. As the magic level rises, it allows alien creatures called Horrors to cross from their distant, otherworldly dimension into our own. The Horrors come in an almost infinite variety—from simple eating machines that devour all they encounter, to incredibly intelligent and cunning foes that feed off the negative emotions they inspire in their prey.

In the distant past of "Earthdawn"'s setting, an elf scholar discovered that the time of the Horrors was approaching, and founded the Eternal Library in order to discover a way to defeat them — or at the very least, survive them. The community that grew up around the library developed wards and protections against the Horrors, which they traded to other lands and eventually became the powerful Theran Empire, an extremely magically advanced civilization and the main antagonist of the "Earthdawn" setting.

The peoples of the world built kaers, underground towns and cities, which they sealed with the Theran wards to wait out the time of the Horrors, which was called the Scourge. Theran wizards and politicians warned many of the outlying nations around Thera of the coming of the Horrors, offering the protection of the kaers to those who would pledge their loyalty to the Empire. Most of these nations agreed at first though some became unwilling to fulfill their end of the bargain after the end of the Scourge, wanting to have nothing to do with the bureaucratic nation run on political conflict and powered by slavery. After four hundred years of hiding, the Scourge ended, and the people emerged to a world changed by the Horrors. The player characters explore this new world, discovering lost secrets of the past, and fighting Horrors that remain.

The primary setting of Earthdawn is Barsaive, a former province of the Theran Empire. Barsaive is a region of city-states, independent from the Therans since the dwarven Kingdom of Throal led a rebellion against their former overlords. The Theran presence in Barsaive has been limited to a small part of south-western Barsaive, located around the magical fortress of Sky Point and the city of Vivane.

The setting of Earthdawn is the same world as Shadowrun (i.e. a fictionalized version of Earth), but takes place millennia earlier. Indeed, the map of Barsaive and its neighboring regions established that most of the game takes place where Ukraine and Russia are in our world. However, the topography other than coastlines and major rivers is quite different, and the only apparent reference to the real world besides the map may be the Blood Wood, known as "Wyrm Wood" before the Scourge and similar in location and extent to the Chernobyl (Ukrainian for "wormwood") Zone of alienation. Note should be made that game world links between "Earthdawn" and "Shadowrun" were deliberately broken by the publisher when the "Shadowrun" property was licensed out, in order to avoid the necessity for coordination between publishing companies. FASA has announced since that there are no plans to return "Shadowrun" to in-house publication, nor to restore the links between the game worlds.

Two Earthdawn supplements cover territories outside Barsaive. "The Theran Empire" book (First Edition) covers the Theran Empire and its provinces (which roughly correspond to the territories of the Roman Empire, plus colonies in America and India). "Cathay: The Five Kingdoms" (Third Edition) covers the lands of Cathay (Far East).

The setting of "Earthdawn" features several fantasy races for characters and NPCs:


"Earthdawn"'s magic system is highly varied but the essential idea is that all player characters (called Adepts) have access to magic, used to perform abilities attained through their Disciplines.

Each Discipline is given a unique set of "Talents" which are used to access the world's magic. Legend points (the "Earthdawn" equivalent of experience points) can be spent to put up the characters level in the Talent, increasing his step level for the ability, making the user more proficient at using that specific type of magic.

Caster Disciplines use the same Talent system as others, but also have access to "spells". How a player character obtains spells varies depending on his Game Master; but how they are used is universal. Casters all have special Talents called "spell matrixes" which they can place spells into. A spell "attuned" (placed into) to a matrix is easily accessible and can be cast at any time. Spells can be switched at the players will while out of combat. Once engaged in combat, however, they must use an action to do so (called re-attuning on the fly), which requires a set difficulty they must achieve, or risk losing their turn.

It is generally recommended that Casters only use attuned spells, but this is not required. Casting a spell that is not in a matrix is referred to as "raw casting". Raw casting is perhaps the most dangerous aspect of the Earthdawn magic system. If the spell is successfully cast, it has its normal effects along with added consequences. Raw casting has a very good chance of drawing the attention of a Horror, which can quickly turn into death for low level characters (and for high level characters as well in some cases).

One of the most innovative ideas in "Earthdawn" is how magical items work. At first, most magical items work exactly like a mundane item of the same type. As a character searches for information about the item's history, performs certain tasks relating to that history, and spends legend points to activate the item, he unlocks some of the magic in the item. As the character learns more about the item and its history, he can unlock more and more power within the item.

Each magical item, therefore, is unique by virtue of its history and the scope of its powers. For example, one magical broadsword may have only 4 magical ranks and only increases the damage of the blade. On the other hand, the legendary sword Purifier, has 10 magical ranks and grants its wielder numerous powers.

"Earthdawn" stands out from other tabletop RPGs with a unique approach to skill tests. Players wanting to perform an action determine their level or "step" for the skill, talent, or ability to be used. This step can then be looked up in a list of dice to be thrown; it is the next-highest integer of the average roll of the dice(s) in question. For example, two six-sided dice will on average yield a result of 7, thus the step number 8 means that 2d6 will be rolled. The consequence is that each such dice roll has a 50% chance of yielding a result at least as high as the corresponding step number.

The result of each die is added (dice which reach their maximum value are thrown again, adding each maximum to the tally, along with the final result below maximum) and compared to a value decided by the game master/storyteller according to the difficulty of the task. This approach means it's always technically possible to succeed with a low step number, yet leaves room for failure on high step numbers. This will sometimes make combat last longer than in other games. As per the above, the difficulty value where the odds of success are perfectly even is identical to the step number.

The dice in steps 3 through 13 form the basis of an 11-step cycle. To form steps 14-24, add 1d20. To form steps 25-35, further add 1d10 + 1d8. For higher cycles, continue alternating between the addition of 1d20 and 1d10 + 1d8. Step 2 is rolled as step 3, but you subtract 1 from the result. This is notated as "1d4 - 1". Step 1 is 1d4 - 2.

The 3rd edition changes this by removing d4s and d20s from the system. Steps 6 through 12 (as listed above) form the basis of a 7-step cycle. To add 7 steps from then on, simply add 1d12.

"Earthdawn" was ranked 24th in the 1996 reader poll of "Arcane" magazine to determine the 50 most popular roleplaying games of all time. The UK magazine's editor Paul Pettengale commented: "Very good indeed. "Earthdawn" combined traditional fantasy with "Call of Cthulhu"-style horror and a detailed background to create an evocative and interesting setting. Combined with a clear, well-designed rules system and an impressive range of supporting supplements and adventures, this is an excellent fantasy game. It's also of special interest to fans of "Shadowrun", because it describes the past of the same gameworld."

In 1999 "Pyramid" magazine named "Earthdawn" as one of "The Millennium's Most Underrated Games". Editor Scott Haring noted (referring to the FASA edition) that ""Earthdawn" had an original, inventive magic system (no mean trick given the hundreds of fantasy RPGs that came before), and a game world that gave you the classic "monsters and dungeons" sort of RPG experience, but made sense doing it."




</doc>
<doc id="9790" url="https://en.wikipedia.org/wiki?curid=9790" title="Electronic data interchange">
Electronic data interchange

Electronic data interchange (EDI) is the concept of businesses communicating electronically information that was traditionally communicated on paper. The two classic examples of such information are purchase orders and invoices. Technical standards for EDI exist to facilitate parties transacting such instruments without having to make special arrangements.

EDI has existed at least since the early 70s, and there are many EDI standards (including X12, EDIFACT, ODETTE, etc.), some of which address the needs of specific industries or regions. It also refers specifically to a family of standards. In 1996, the National Institute of Standards and Technology defined electronic data interchange as "the computer-to-computer interchange of strictly formatted messages that represent documents other than monetary instruments. EDI implies a sequence of messages between two parties, either of whom may serve as originator or recipient. The formatted data representing the documents may be transmitted from originator to recipient via telecommunications or physically transported on electronic storage media." It distinguished mere electronic communication or data exchange, specifying that "in EDI, the usual processing of received messages is by computer only. Human intervention in the processing of a received message is typically intended only for error conditions, for quality review, and for special situations. For example, the transmission of binary or textual data is not EDI as defined here unless the data are treated as one or more data elements of an EDI message and are not normally intended for human interpretation as part of on-line data processing." In short, EDI can be defined as the transfer of structured data, by agreed message standards, from one computer system to another without human intervention.

Like many other early information technologies, EDI was inspired by developments in military logistics. The complexity of the 1948 Berlin airlift required the development of concepts and methods to exchange, sometimes over a 300 baud teletype modem, vast quantities of data and information about transported goods. These initial concepts later shaped the first TDCC (Transportation Data Coordinating Committee) standards in the US. Among the first integrated systems using EDI were Freight Control Systems. One such real-time system was the London Airport Cargo EDP Scheme (LACES) at Heathrow Airport, London, UK, in 1971. Implementing the direct trader input (DTI) method, it allowed forwarding agents to enter information directly into the Customs processing system reducing the time for clearance. The increase of maritime traffic and problems at Customs similar to those experienced at Heathrow Airport led to the implementation of DTI systems in individual ports or group of ports in the 1980s.

EDI provides a technical basis for automated commercial "conversations" between two entities, either internal or external. The term EDI encompasses the entire electronic data interchange process, including the transmission, message flow, document format, and software used to interpret the documents. However, EDI standards describe the rigorous format of electronic documents, and the EDI standards were designed by the implementers, initially in the Automotive industry, to be independent of communication and software technologies. EDI can be transmitted using any methodology agreed to by the sender and recipient. This includes a variety of technologies, including modem (asynchronous and synchronous), FTP, e-mail, HTTP, AS1, AS2, AS4 etc. It is important to differentiate between the EDI documents and the methods for transmitting them. When they compared the synchronous protocol 2400 bit/s modems, CLEO devices, and value-added networks used to transmit EDI documents to transmitting via the Internet, some people equated the non-Internet technologies with EDI and predicted erroneously that EDI itself would be replaced along with the non-Internet technologies. These non-internet transmission methods are being replaced by Internet protocols such as FTP, HTTP, telnet, and e-mail, but the EDI documents themselves still remain.

As more trading partners use the Internet for transmission, standards have emerged. In 2002, the IETF published RFC 3335, offering a standardized, secure method of transferring EDI data via e-mail. On July 12, 2005, an IETF working group ratified RFC4130 for MIME-based HTTP EDIINT (a.k.a. AS2) transfers, and the IETF has prepared a similar RFC for FTP transfers (a.k.a. AS3). EDI via web services (a.k.a. AS4) has also been standardised by the OASIS standards body. While some EDI transmission has moved to these newer protocols, the providers of value-added networks remain active.

EDI documents generally contain the same information that would normally be found in a paper document used for the same organizational function. For example, an EDI 940 ship-from-warehouse order is used by a manufacturer to tell a warehouse to ship product to a retailer. It typically has a 'ship-to' address, a 'bill-to' address, and a list of product numbers (usually a UPC) and quantities. Another example is the set of messages between sellers and buyers, such as request for quotation (RFQ), bid in response to RFQ, purchase order, purchase order acknowledgement, shipping notice, receiving advice, invoice, and payment advice. However, EDI is not confined to just business data related to trade but encompasses all fields such as medicine (e.g., patient records and laboratory results), transport (e.g., container and modal information), engineering and construction, etc. In some cases, EDI will be used to create a new business information flow (that was not a paper flow before). This is the case in the Advanced Shipment Notification (ASN) which was designed to inform the receiver of a shipment, the goods to be received and how the goods are packaged.

Some major sets of EDI standards:
Many of these standards first appeared in the early to mid 1980s. The standards prescribe the formats, character sets, and data elements used in the exchange of business documents and forms. The complete X12 Document List includes all major business documents, including purchase orders and invoices.

The EDI standard prescribes mandatory and optional information for a particular document and gives the rules for the structure of the document. The standards are like building codes. Just as two kitchens can be built "to code" but look completely different, two EDI documents can follow the same standard and contain different sets of information. For example, a food company may indicate a product's expiration date while a clothing manufacturer would choose to send color and size information.
Organizations that send or receive documents between each other are referred to as "trading partners" in EDI terminology. The trading partners agree on the specific information to be transmitted and how it should be used. This is done in human readable specifications (also called Message Implementation Guidelines). While the standards are analogous to building codes, the specifications are analogous to blue prints. (The specification may also be called a "mapping," but the term mapping is typically reserved for specific machine-readable instructions given to the translation software.) Larger trading "hubs" have existing Message Implementation Guidelines which mirror their business processes for processing EDI and they are usually unwilling to modify their EDI business practices to meet the needs of their trading partners. Often in a large company these EDI guidelines will be written to be generic enough to be used by different branches or divisions and therefore will contain information not needed for a particular business document exchange. For other large companies, they may create separate EDI guidelines for each branch/division.

Trading partners are free to use any method for the transmission of documents. Furthermore, they can either interact directly, or through an intermediary.

Trading partners can connect directly to each other. For example, an automotive manufacturer might maintain a modem-pool that all of its hundreds of suppliers are required to dial into to perform EDI. However, if a supplier does business with several manufacturers, it may need to acquire a different modem (or VPN device, etc.) and different software for each one.

To address the limitations in peer-to-peer adoption of EDI, VANs (value-added networks) were established. A VAN acts as a regional post office. It receives transactions, examines the 'from' and the 'to' information, and routes the transaction to the final recipient. VANs may provide a number of additional services, e.g. retransmitting documents, providing third party audit information, acting as a gateway for different transmission methods, and handling telecommunications support. Because of these and other services VANs provide, businesses frequently use a VAN even when both trading partners are using Internet-based protocols. Healthcare clearinghouses perform many of the same functions as a VAN, but have additional legal restrictions

VANs may be operated by various entities:

As more organizations connected to the Internet, eventually most or all EDI was pushed onto it. Initially, this was through ad hoc conventions, such as unencrypted FTP of ASCII text files to a certain folder on a certain host, permitted only from certain IP addresses. However, the IETF has published several informational documents (the "Applicability Statements"; see below under Protocols) describing ways to use standard Internet protocols for EDI.

As of 2002, Walmart have pushed the AS2 for EDI. Because of its significant presence in the global supply chain, AS2 have become a commonly adopted approach for EDI.

"EDI translation software" provides the interface between internal systems and the EDI format sent/received. For an "inbound" document the EDI solution will receive the file (either via a Value Added Network or directly using protocols such as FTP or AS2), take the received EDI file (commonly referred to as a "mailbag"), validate that the trading partner who is sending the file is a valid trading partner, that the structure of the file meets the EDI standards, and that the individual fields of information conform to the agreed upon standards. Typically the translator will either create a file of either fixed length, variable length or XML tagged format or "print" the received EDI document (for non-integrated EDI environments). The next step is to convert/transform the file that the translator creates into a format that can be imported into a company's back-end business system or ERP. This can be accomplished by using a custom program, an integrated proprietary "mapper" or an integrated standards based graphical "mapper," using a standard data transformation language such as XSLT. The final step is to import the transformed file (or database) into the company's back-end system.

For an "outbound" document the process for integrated EDI is to export a file (or read a database) from a company's information systems and transform the file to the appropriate format for the translator. The translation software will then "validate" the EDI file sent to ensure that it meets the standard agreed upon by the trading partners, convert the file into "EDI" format (adding the appropriate identifiers and control structures) and send the file to the trading partner (using the appropriate communications protocol).

Another critical component of any EDI translation software is a complete "audit" of all the steps to move business documents between trading partners. The audit ensures that any transaction (which in reality is a business document) can be tracked to ensure that they are not lost. In case of a retailer sending a Purchase Order to a supplier, if the Purchase Order is "lost" anywhere in the business process, the effect is devastating to both businesses. To the supplier, they do not fulfill the order as they have not received it thereby losing business and damaging the business relationship with their retail client. For the retailer, they have a stock outage and the effect is lost sales, reduced customer service and ultimately lower profits.

In EDI terminology "inbound" and "outbound" refer to the direction of transmission of an EDI document in relation to a particular system, not the direction of merchandise, money or other things represented by the document. For example, an EDI document that tells a warehouse to perform an outbound shipment is an inbound document in relation to the warehouse computer system. It is an outbound document in relation to the manufacturer or dealer that transmitted the document.

EDI and other similar technologies save a company money by providing an alternative to, or replacing, information flows that require a great deal of human interaction and paper documents. Even when paper documents are maintained in parallel with EDI exchange, e.g. printed shipping manifests, electronic exchange and the use of data from that exchange reduces the handling costs of sorting, distributing, organizing, and searching paper documents. EDI and similar technologies allow a company to take advantage of the benefits of storing and manipulating data electronically without the cost of manual entry. Another advantage of EDI is the opportunity to reduce or eliminate manual data entry errors, such as shipping and billing errors, because EDI eliminates the need to rekey documents on the destination side. One very important advantage of EDI over paper documents is the speed in which the trading partner receives and incorporates the information into their system thus greatly reducing cycle times. For this reason, EDI can be an important component of just-in-time production systems.

According to the 2008 Aberdeen report "A Comparison of Supplier Enablement around the World", only 34% of purchase orders are transmitted electronically in North America. In EMEA, 36% of orders are transmitted electronically and in APAC, 41% of orders are transmitted electronically. They also report that the average paper requisition to order costs a company $37.45 in North America, $42.90 in EMEA and $23.90 in APAC. With an EDI requisition to order costs are reduced to $23.83 in North America, $34.05 in EMEA and $14.78 in APAC.

There are a few barriers to adopting electronic data interchange. One of the most significant barriers is the accompanying business process change. Existing business processes built around paper handling may not be suited for EDI and would require changes to accommodate automated processing of business documents. For example, a business may receive the bulk of their goods by 1 or 2 day shipping and all of their invoices by mail. The existing process may therefore assume that goods are typically received before the invoice. With EDI, the invoice will typically be sent when the goods ship and will therefore require a process that handles large numbers of invoices whose corresponding goods have not yet been received.

Another significant barrier is the cost in time and money in the initial set-up. The preliminary expenses and time that arise from the implementation, customization and training can be costly. It is important to select the correct level of integration to match the business requirement. For a business with relatively few transactions with EDI-based partners, it may make sense for businesses to implement inexpensive "rip and read" solutions, where the EDI format is printed out in human-readable form and people, rather than computers, respond to the transaction. Another alternative is outsourced EDI solutions provided by EDI "Service Bureaus". For other businesses, the implementation of an integrated EDI solution may be necessary as increases in trading volumes brought on by EDI force them to re-implement their order processing business processes.

The key hindrance to a successful implementation of EDI is the perception many businesses have of the nature of EDI. Many view EDI from the technical perspective that EDI is a data format; it would be more accurate to take the business view that EDI is a system for exchanging business documents with external entities, and integrating the data from those documents into the company's internal systems. Successful implementations of EDI take into account the effect externally generated information will have on their internal systems and validate the business information received. For example, allowing a supplier to update a retailer's Accounts Payable system without appropriate checks and balances would put the company at significant risk. Businesses new to the implementation of EDI must understand the underlying business process and apply proper judgment.

Below are common EDI acknowledgement


Formats





</doc>
<doc id="9792" url="https://en.wikipedia.org/wiki?curid=9792" title="Extravehicular activity">
Extravehicular activity

Extravehicular activity (EVA) is any activity done by an astronaut or cosmonaut outside a spacecraft beyond the Earth's appreciable atmosphere. The term most commonly applies to a spacewalk made outside a craft orbiting Earth (such as the International Space Station), but also has applied to lunar surface exploration (commonly known as moonwalks) performed by six pairs of American astronauts in the Apollo program from 1969 to 1972. On each of the last three of these missions, astronauts also performed deep-space EVAs on the return to Earth, to retrieve film canisters from the outside of the spacecraft. Astronauts also used EVA in 1973 to repair launch damage to Skylab, the United States' first space station.

A "Stand-up" EVA (SEVA) is when an astronaut does not fully leave a spacecraft, but is completely reliant on the spacesuit for environmental support. Its name derives from the astronaut "standing up" in the open hatch, usually to record or assist a spacewalking astronaut.

EVAs may be either tethered (the astronaut is connected to the spacecraft; oxygen and electrical power can be supplied through an umbilical cable; no propulsion is needed to return to the spacecraft), or untethered. Untethered spacewalks were only performed on three missions in 1984 using the Manned Maneuvering Unit (MMU), and on a flight test in 1994 of the Simplified Aid For EVA Rescue (SAFER), a safety device worn on tethered U.S. EVAs.

The Soviet Union/Russia, the United States, and China have conducted EVAs.

NASA planners invented the term "extravehicular activity" (abbreviated with the acronym EVA) in the early 1960s for the Apollo program to land men on the Moon, because the astronauts would leave the spacecraft to collect lunar material samples and deploy scientific experiments. To support this, and other Apollo objectives, the Gemini program was spun off to develop the capability for astronauts to work outside a two-man Earth orbiting spacecraft. However, the Soviet Union was fiercely competitive in holding the early lead it had gained in manned spaceflight, so the Soviet Communist Party, led by Nikita Khrushchev, ordered the conversion of its single-pilot Vostok capsule into a two- or three-person craft named Voskhod, in order to compete with Gemini and Apollo. The Soviets were able to launch two Voskhod capsules before U.S. was able to launch its first manned Gemini.

The Voskhod's avionics required cooling by cabin air to prevent overheating, therefore an airlock was required for the spacewalking cosmonaut to exit and re-enter the cabin while it remained pressurized. By contrast, the Gemini avionics did not require air cooling, allowing the spacewalking astronaut to exit and re-enter the depressurized cabin through an open hatch. Because of this, the American and Soviet space programs developed different definitions for the duration of an EVA. The Soviet (now Russian) definition begins when the outer airlock hatch is open and the cosmonaut is in vacuum. An American EVA began when the astronaut had at least his head outside the spacecraft. The USA has changed its EVA definition since.

The first EVA was performed on March 18, 1965, by Soviet cosmonaut Alexey Leonov, who spent 12 minutes outside the Voskhod 2 spacecraft. Carrying a white metal backpack containing 45 minutes worth of breathing and pressurization oxygen, Leonov had no means to control his motion other than pulling on his tether. After the flight, he claimed this was easy, but his space suit ballooned from its internal pressure against the vacuum of space, stiffening so much that he could not activate the shutter on his chest-mounted camera.

At the end of his space walk, the suit stiffening caused a more serious problem: Leonov had to re-enter the capsule through the inflatable cloth airlock, in diameter and long. He improperly entered the airlock head-first and got stuck sideways. He could not get back in without reducing the pressure in his suit, risking "the bends". This added another 12 minutes to his time in vacuum, and he was overheated by from the exertion. It would be almost four years before the Soviets tried another EVA. They misrepresented to the press how difficult Leonov found it to work in weightlessness and concealed the problems encountered until after the end of the Cold War.

The first American spacewalk was performed on June 3, 1965, by Ed White from the second manned Gemini flight, Gemini 4, for 21 minutes. White was tethered to the spacecraft, and his oxygen was supplied through a umbilical, which also carried communications and biomedical instrumentation. He was the first to control his motion in space with a Hand-Held Maneuvering Unit, which worked well but only carried enough propellant for 20 seconds. White found his tether useful for limiting his distance from the spacecraft but difficult to use for moving around, contrary to Leonov's claim. However, a defect in the capsule's hatch latching mechanism caused difficulties opening and closing the hatch, which delayed the start of the EVA and put White and his crewmate at risk of not getting back to Earth alive.

No EVAs were planned on the next three Gemini flights. The next EVA was planned to be made by David Scott on Gemini 8, but that mission had to be aborted due to a critical spacecraft malfunction before the EVA could be conducted. Astronauts on the next three Gemini flights (Eugene Cernan, Michael Collins, and Richard Gordon), performed several EVAs, but none was able to successfully work for long periods outside the spacecraft without tiring and overheating. Cernan attempted but failed to test an Air Force Astronaut Maneuvering Unit which included a self-contained oxygen system.

On November 13, 1966, Edwin "Buzz" Aldrin became the first to successfully work in space without tiring, on the Gemini 12 last flight. Aldrin worked outside the spacecraft for 2 hours and 6 minutes, in addition to two stand-up EVAs in the spacecraft hatch for an additional 3 hours and 24 minutes. Aldrin's interest in scuba diving inspired the use of underwater EVA training to simulate weightlessness, which has been used ever since to allow astronauts to practice techniques of avoiding wasted muscle energy.

On January 16, 1969, Soviet cosmonauts Aleksei Yeliseyev and Yevgeny Khrunov transferred from Soyuz 5 to Soyuz 4, which were docked together. This was the second Soviet EVA, and it would be almost another nine years before the Soviets performed their third.

American astronauts Neil Armstrong and Buzz Aldrin performed the first EVA on the lunar surface on July 21, 1969 (UTC), after landing their Apollo 11 Lunar Module spacecraft. This first Moon walk, using self-contained Portable Life Support Systems, lasted 2 hours 36 minutes. A total of fifteen Moon walks were performed among six Apollo crews, including Charles "Pete" Conrad, Alan Bean, Alan Shepard, Edgar Mitchell, David Scott, James Irwin, John Young, Charles Duke, Eugene Cernan, and Harrison "Jack" Schmitt. Cernan was the last Apollo astronaut to step off the surface of the Moon.
Apollo 15 Command Module Pilot Al Worden made an EVA on August 5, 1971, on the return trip from the Moon, to retrieve a film and data recording canister from the Service Module. He was assisted by Lunar Module Pilot James Irwin standing up in the Command Module hatch. This procedure was repeated by Ken Mattingly and Charles Duke on Apollo 16, and by Ronald Evans and Harrison Schmitt on Apollo 17.

The first EVA repairs of a spacecraft were made by Charles "Pete" Conrad, Joseph Kerwin, and Paul J. Weitz on May 26, June 7, and June 19, 1973, on the Skylab 2 mission. They rescued the functionality of the launch-damaged Skylab space station by freeing a stuck solar panel, deploying a solar heating shield, and freeing a stuck circuit breaker relay. The Skylab 2 crew made three EVAs, and a total of ten EVAs were made by the three Skylab crews. They found that activities in weightlessness required about 2½ times longer than on Earth because many astronauts suffered spacesickness early in their flights.

After Skylab, no more EVAs were made by the United States until the advent of the Space Shuttle program in the early 1980s. In this period, the Soviets resumed EVAs, making four from the Salyut 6 and Salyut 7 space stations between December 20, 1977, and July 30, 1982.

When the United States resumed EVAs on April 7, 1983, astronauts started using an Extravehicular Mobility Unit (EMU) for self-contained life support independent of the spacecraft. STS-6 was the first Space Shuttle mission during which a spacewalk was conducted. Also, for the first time, American astronauts used an airlock to enter and exit the spacecraft like the Soviets. Accordingly, the American definition of EVA start time was redefined to when the astronaut switches the EMU to battery power.



The first spacewalk, made by Soviet cosmonaut Alexey Leonov, was commemorated in 1965 with several Eastern Bloc stamps (see Alexey Leonov#Stamps). Since the Soviet Union did not publish details of the Voskhod spacecraft at the time, the spaceship depiction in the stamps was purely fictional.

The U.S. Post Office issued a postage stamp in 1967 commemorating Ed White's first American spacewalk. The engraved image has an accurate depiction of the Gemini IV spacecraft and White's space suit.

NASA "spacewalkers" during the space shuttle program were designated as EV-1, EV-2, EV-3 and EV-4 (assigned to mission specialists for each mission, if applicable).

For EVAs from the International Space Station, NASA now routinely employs a "camp out" procedure to reduce the risk of decompression sickness. This was first tested by the Expedition 12 crew. During a camp out, astronauts sleep overnight in the airlock prior to an EVA, lowering the air pressure to , compared to the normal station pressure of . Spending a night at the lower air pressure helps flush nitrogen from the body, thereby preventing "the bends".



</doc>
<doc id="9799" url="https://en.wikipedia.org/wiki?curid=9799" title="Erin Brockovich">
Erin Brockovich

Erin Brockovich (née Pattee; born June 22, 1960) is an American legal clerk and environmental activist, who, despite her lack of formal education in the law, was instrumental in building a case against the Pacific Gas and Electric Company (PG&E) of California in 1993. Her successful lawsuit was the subject of a 2000 film, "Erin Brockovich", which starred Julia Roberts. Since then, Brockovich has become a media personality as well, hosting the TV series "Challenge America with Erin Brockovich" on ABC and "Final Justice" on Zone Reality. She is the president of Brockovich Research & Consulting. She also works as a consultant for Girardi & Keese, the New York law firm of Weitz & Luxenberg, which has a focus on personal injury claims for asbestos exposure, and Shine Lawyers in Australia.

She was born Erin Pattee in Lawrence, Kansas, the daughter of Betty Jo (née O'Neal; 1923–2008), a journalist, and Frank Pattee (1924–2011), an industrial engineer and football player. She has two brothers, Frank Jr. and Thomas (1954–1992), and a sister, Jodie. She graduated from Lawrence High School, then attended Kansas State University, in Manhattan, Kansas, and graduated with an Associate in Applied Arts Degree from Wade College in Dallas, Texas. She worked as a management trainee for Kmart in 1981 but quit after a few months and entered a beauty pageant. She won Miss Pacific Coast in 1981 and left the beauty pageant after the win. She has lived in California since 1982.

The case alleged contamination of drinking water with hexavalent chromium (also written as "chromium VI", "Cr-VI" or "Cr-6") in the southern California town of Hinkley. At the center of the case was a facility, the Hinkley compressor station, built in 1952 as a part of a natural-gas pipeline connecting to the San Francisco Bay Area. Between 1952 and 1966, PG&E used hexavalent chromium in a cooling tower system to fight corrosion. The wastewater was discharged to unlined ponds at the site, and some percolated into the groundwater, affecting an area near the plant approximately . The Regional Water Quality Control Board (RWQCB) put the PG&E site under its regulations in 1968.

The case was settled in 1996 for US$333 million, the largest settlement ever paid in a direct-action lawsuit in U.S. history. Masry & Vititoe, the law firm for which Brockovich was a legal clerk, received $133.6 million of that settlement, and Brockovich herself was given a bonus of $2.5 million.

A study released in 2010 by the California Cancer Registry showed that cancer rates in Hinkley "remained unremarkable from 1988 to 2008". An epidemiologist involved in the study said that the 196 cases of cancer reported during the most recent survey of 1996 through 2008 were fewer than what he would expect based on demographics and the regional rate of cancer. However, a June 2013 "Mother Jones" magazine article featured an extensive critique from the Center for Public Integrity of the author's work on the later epidemiological studies.

As of 2016, average Cr-6 levels in Hinkley were recorded as 1.19 ppb with a peak of 3.09 ppb. For comparison, the PG&E Topock Compressor Station on the California-Arizona border averaged 7.8 ppb with peaks of 31.8 ppb based on a PG&E Background Study.

Working with Edward L. Masry, a lawyer based in Thousand Oaks, California, Brockovich went on to participate in other anti-pollution lawsuits. One suit accused the Whitman Corporation of chromium contamination in Willits, California. Another, which listed 1,200 plaintiffs, alleged contamination near PG&E's Kettleman Hills compressor station in Kings County, California, along the same pipeline as the Hinkley site. The Kettleman suit was settled for $335 million in 2006.

In 2003, Brockovich received settlements of $430,000 from two parties and an undisclosed amount from a third party to settle her lawsuit alleging toxic mold in her Agoura Hills, California, home. After experiencing problems with mold contamination in her own home in the Conejo Valley, Brockovich became a prominent activist and educator in this area as well.

Brockovich and Masry filed suit against the Beverly Hills Unified School District in 2003, in which the district was accused of harming the health and safety of its students by allowing a contractor to operate a cluster of oil wells on campus. Brockovich and Masry alleged that 300 cancer cases were linked to the oil wells. Subsequent testing and epidemiological investigation failed to corroborate a substantial link, and Los Angeles County Superior Court Judge Wendell Mortimer granted summary judgment against the plaintiffs. In May 2007, the School District announced that it was to be paid $450,000 as reimbursement for legal expenses.

Brockovich assisted in the filing of a lawsuit against Prime Tanning Corp. of St. Joseph, Missouri, in April 2009. The lawsuit claims that waste sludge from the production of leather, containing high levels of hexavalent chromium, was distributed to farmers in northwest Missouri to use as fertilizer on their fields. It is believed to be a potential cause of an abnormally high number of brain tumors (70 since 1996) around the town of Cameron, Missouri, which is currently being investigated by the EPA.

In June 2009, Brockovich began investigating a case of contaminated water in Midland, Texas. "Significant amounts" of hexavalent chromium were found in the water of more than 40 homes in the area, some of which have now been fitted with state-monitored filters on their water supply. Brockovich said "The only difference between here and Hinkley is that I saw higher levels here than I saw in Hinkley."

In 2012, Brockovich got involved in the mysterious case of 14 students from LeRoy, New York, who began reporting perplexing medical symptoms including tics and speech difficulty. Brockovich believed environmental pollution from the 1970 Lehigh Valley Railroad derailment was the cause and conducted testing in the area. Brockovich was supposed to return to town to present her findings, but never did; in the meantime the students' doctors determined the cause was mass psychogenic illness and that the media exposure was making it worse. No environmental causes were found after repeat testing and the students improved once the media attention died down. In early 2016, Brockovich became involved in potential litigation against Southern California Gas for a large methane leak from its underground storage facility near the community of Porter Ranch north of Los Angeles (see Aliso Canyon gas leak).


Brockovich's work in bringing litigation against Pacific Gas and Electric was the focus of the 2000 feature film, "Erin Brockovich", starring Julia Roberts in the title role. The film was nominated for five Academy Awards: Best Actress in a Leading Role, Best Actor in a Supporting Role, Best Director, Best Picture, and Best Writing in a Screenplay Written Directly for the Screen. Roberts won the Academy Award for Best Actress for her portrayal of Erin Brockovich. Erin Brockovich herself had a cameo role as a waitress named Julia R.

Brockovich had a more extensive role in the 2012 documentary "Last Call at the Oasis", which focused on not only water pollution but also the overall state of water scarcity as it relates to water policy in the United States.

Brockovich's book, titled "Take It From Me: Life's a Struggle But You Can Win", () was published in 2001.



</doc>
<doc id="9804" url="https://en.wikipedia.org/wiki?curid=9804" title="Electric charge">
Electric charge

Electric charge is the physical property of matter that causes it to experience a force when placed in an electromagnetic field. There are two types of electric charges; "positive" and "negative" (commonly carried by protons and electrons respectively). Like charges repel and unlike attract. An object with an absence of net charge is referred to as "". The SI derived unit of electric charge is the coulomb (C). In electrical engineering, it is also common to use the ampere-hour (Ah), in physics and chemistry, it is common to use the elementary charge ("e" as a unit). Chemistry also uses the Faraday constant as the charge on a mole of electrons. The symbol "Q" often denotes charge. Early knowledge of how charged substances interact is now called classical electrodynamics, and is still accurate for problems that don't require consideration of quantum effects.

Electric charge is a conserved property; the net charge of an isolated system, the amount of positive charge minus the amount of negative charge, cannot change. Electric charge is carried by subatomic particles. In ordinary matter, negative charge is carried by electrons, and positive charge is carried by the protons in the nuclei of atoms. If there are more electrons than protons in a piece of matter, it will have a negative charge, if there are less it will have a positive charge, and if there are equal numbers it will be neutral. Charge is "quantized"; it comes in integer multiples of individual small units called the elementary charge, "e", about , which is the smallest charge which can exist free (particles called quarks have smaller charges, multiples of "e" but they are only found in combination). The proton has a charge of +"e", and the electron has a charge of −"e". 

Electric charges create an electric field, if they are moving they also generate a magnetic field. The combination of the electric and magnetic field is called the electromagnetic field, and its interaction with charges is the source of the electromagnetic force, which is one of the four fundamental forces in physics. The study of charged particles, and how their interactions are mediated by photons, is called quantum electrodynamics.

Charge is the fundamental property of forms of matter that exhibit electrostatic attraction or repulsion in the presence of other matter. Electric charge is a characteristic property of many subatomic particles. The charges of free-standing particles are integer multiples of the elementary charge "e"; we say that electric charge is "quantized". Michael Faraday, in his electrolysis experiments, was the first to note the discrete nature of electric charge. Robert Millikan's oil drop experiment demonstrated this fact directly, and measured the elementary charge. It has been discovered that one type of particle, quarks, have fractional charges of either − or +, but it is believed they always occur in multiples of integral charge; free-standing quarks have never been observed.

By convention, the charge of an electron is negative, "−e", while that of a proton is positive, "+e". Charged particles whose charges have the same sign repel one another, and particles whose charges have different signs attract. Coulomb's law quantifies the electrostatic force between two particles by asserting that the force is proportional to the product of their charges, and inversely proportional to the square of the distance between them. The charge of an antiparticle equals that of the corresponding particle, but with opposite sign. 

The electric charge of a macroscopic object is the sum of the electric charges of the particles that make it up. This charge is often small, because matter is made of atoms, and atoms typically have equal numbers of protons and electrons, in which case their charges cancel out, yielding a net charge of zero, thus making the atom neutral.

An "ion" is an atom (or group of atoms) that has lost one or more electrons, giving it a net positive charge (cation), or that has gained one or more electrons, giving it a net negative charge (anion). "Monatomic ions" are formed from single atoms, while "polyatomic ions" are formed from two or more atoms that have been bonded together, in each case yielding an ion with a positive or negative net charge.
During formation of macroscopic objects, constituent atoms and ions usually combine to form structures composed of neutral "ionic compounds" electrically bound to neutral atoms. Thus macroscopic objects tend toward being neutral overall, but macroscopic objects are rarely perfectly net neutral.

Sometimes macroscopic objects contain ions distributed throughout the material, rigidly bound in place, giving an overall net positive or negative charge to the object. Also, macroscopic objects made of conductive elements, can more or less easily (depending on the element) take on or give off electrons, and then maintain a net negative or positive charge indefinitely. When the net electric charge of an object is non-zero and motionless, the phenomenon is known as static electricity. This can easily be produced by rubbing two dissimilar materials together, such as rubbing amber with fur or glass with silk. In this way non-conductive materials can be charged to a significant degree, either positively or negatively. Charge taken from one material is moved to the other material, leaving an opposite charge of the same magnitude behind. The law of "conservation of charge" always applies, giving the object from which a negative charge is taken a positive charge of the same magnitude, and vice versa.

Even when an object's net charge is zero, charge can be distributed non-uniformly in the object (e.g., due to an external electromagnetic field, or bound polar molecules). In such cases the object is said to be polarized. The charge due to polarization is known as bound charge, while charge on an object produced by electrons gained or lost from outside the object is called "free charge". The motion of electrons in conductive metals in a specific direction is known as electric current.

The SI unit of quantity of electric charge is the coulomb, which is equivalent to about ("e" is the charge of a proton). Hence, the charge of an electron is approximately . The coulomb is defined as the quantity of charge that has passed through the cross section of an electrical conductor carrying one ampere within one second. The symbol "Q" is often used to denote a quantity of electricity or charge. The quantity of electric charge can be directly measured with an electrometer, or indirectly measured with a ballistic galvanometer.

After finding the quantized character of charge, in 1891 George Stoney proposed the unit 'electron' for this fundamental unit of electrical charge. This was before the discovery of the particle by J.J. Thomson in 1897. The unit is today treated as nameless, referred to as "elementary charge", "fundamental unit of charge", or simply as "e". A measure of charge should be a multiple of the elementary charge "e", even if at large scales charge seems to behave as a real quantity. In some contexts it is meaningful to speak of fractions of a charge; for example in the charging of a capacitor, or in the fractional quantum Hall effect.

The unit faraday is sometimes used in electrochemistry. One faraday of charge is the magnitude of the charge of one mole of electrons, i.e. 96485.33289(59) C.

In systems of units other than SI such as cgs, electric charge is expressed as combination of only three fundamental quantities (length, mass, and time), and not four, as in SI, where electric charge is a combination of length, mass, time, and electric current.

From ancient times, persons were familiar with four types of phenomena that today would all be explained using the concept of electric charge: (a) lightning, (b) the torpedo fish (or electric ray), (c) St Elmo's Fire, and (d) that amber rubbed with fur would attract small, light objects. The first account of the "amber effect" is often attributed to the ancient Greek mathematician Thales of Miletus, who lived from c. 624 – c. 546 BC, but there are doubts about whether Thales left any writings; his account about amber is known from an account from early 200s. This account can be taken as evidence that knowledge the phenomenon was known since at least c. 600 BC, but Thales explained this phenomenon as evidence for inanimate objects having a soul. In other words, there was no indication of any conception of electric charge. More generally, the ancient Greeks did not understand the connections among these four kinds of phenomena. The Greeks observed that the charged amber buttons could attract light objects such as hair. They also found that if they rubbed the amber for long enough, they could even get an electric spark to jump, but there is also a claim that no mention of electric sparks appeared until late 17th century. This property derives from the triboelectric effect. 
In late 1100s, the substance jet, a compacted form of coal, was noted to have an amber effect, and in the middle of the 1500s, Girolamo Fracastoro, discovered that diamond also showed this effect. Some efforts were made by Fracastoro and others, especially Gerolamo Cardano to develop explanations for this phenomenon.

In 1600, the English scientist William Gilbert returned to the "amber effect" (as he called it) in "De Magnete", addressing many of the earlier theories, and coined the New Latin word "electrica" (from (ēlektron), the Greek word for "amber"). The Latin word was translated into English as "electrics". Gilbert is also credited with the term "electrical", while the term "electricity" came later, first attributed to Sir Thomas Browne in his Pseudodoxia Epidemica from 1646. (For more linguistic details see Etymology of electricity.) Gilbert was followed in 1660 by Otto von Guericke, who invented what was probably the first electrostatic generator. Other European pioneers were Robert Boyle, who in 1675 stated that electric attraction and repulsion can act across a vacuum; Stephen Gray, who in 1729 classified materials as conductors and insulators. In 1733 Charles François de Cisternay du Fay, inspired by Gray's work, made a series of experiments (reported in "Mémoires de l'Académie Royale des Sciences"), showing that more or less all substances could be 'electrified' by rubbing, except for metals and fluids and proposed that electricity comes in two varieties that cancel each other, which he expressed in terms of a two-fluid theory. When glass was rubbed with silk, du Fay said that the glass was charged with "vitreous electricity", and, when amber was rubbed with fur, the amber was charged with "resinous electricity". Another important two-fluid theory from this time was proposed by Jean-Antoine Nollet (1745). In 1839, Michael Faraday showed that the apparent division between static electricity, current electricity, and bioelectricity was incorrect, and all were a consequence of the behavior of a single kind of electricity appearing in opposite polarities. It is arbitrary which polarity is called positive and which is called negative. Positive charge can be defined as the charge left on a glass rod after being rubbed with silk.

One of the foremost experts on electricity in the 18th century was Benjamin Franklin, who argued in favour of a one-fluid theory of electricity. Franklin imagined electricity as being a type of invisible fluid present in all matter; for example, he believed that it was the glass in a Leyden jar that held the accumulated charge. He posited that rubbing insulating surfaces together caused this fluid to change location, and that a flow of this fluid constitutes an electric current. He also posited that when matter contained too little of the fluid it was "negatively" charged, and when it had an excess it was "positively" charged. For a reason that was not recorded, he identified the term "positive" with vitreous electricity and "negative" with resinous electricity. William Watson independently arrived at the same explanation at about the same time (1746).

It is now known that the Franklin-Watson model was fundamentally correct. There is only one kind of electrical charge, and only one variable is required to keep track of the amount of charge. On the other hand, just knowing the charge is not a complete description of the situation. Matter is composed of several kinds of electrically charged particles, and these particles have many properties, not just charge.

Actually, all bodies are electrified, but may appear not electrified because of the relatively similar charge of neighboring objects in the environment. An object further electrified + or – creates an equivalent or opposite charge by default in neighboring objects, until those charges can equalize. The effects of attraction can be observed in high-voltage experiments, while lower voltage effects are merely weaker and therefore less obvious. The attraction and repulsion forces are codified by Coulomb's law (attraction falls off at the square of the distance, which has a corollary for acceleration in a gravitational field, suggesting that gravitation may be merely electrostatic phenomenon between relatively weak charges in terms of scale). See also Casimir effect.

Static electricity refers to the electric charge of an object and the related electrostatic discharge when two objects are brought together that are not at equilibrium. An electrostatic discharge creates a change in the charge of each of the two objects. 

When a piece of glass and a piece of resin—neither of which exhibit any electrical properties—are rubbed together and left with the rubbed surfaces in contact, they still exhibit no electrical properties. When separated, they attract each other.

A second piece of glass rubbed with a second piece of resin, then separated and suspended near the former pieces of glass and resin causes these phenomena:

This attraction and repulsion is an "electrical phenomena", and the bodies that exhibit them are said to be "electrified", or "electrically charged". Bodies may be electrified in many other ways, as well as by friction. The electrical properties of the two pieces of glass are similar to each other but opposite to those of the two pieces of resin: The glass attracts what the resin repels and repels what the resin attracts.

If a body electrified in any manner whatsoever behaves as the glass does, that is, if it repels the glass and attracts the resin, the body is said to be "vitreously" electrified, and if it attracts the glass and repels the resin it is said to be "resinously" electrified. All electrified bodies are either vitreously or resinously electrified.

An established convention in the scientific community defines vitreous electrification as positive, and resinous electrification as negative. The exactly opposite properties of the two kinds of electrification justify our indicating them by opposite signs, but the application of the positive sign to one rather than to the other kind must be considered as a matter of arbitrary convention—just as it is a matter of convention in mathematical diagram to reckon positive distances towards the right hand.

No force, either of attraction or of repulsion, can be observed between an electrified body and a body not electrified.

Electric current is the flow of electric charge through an object, which produces no net loss or gain of electric charge. The most common charge carriers are the positively charged proton and the negatively charged electron. The movement of any of these charged particles constitutes an electric current. In many situations, it suffices to speak of the "conventional current" without regard to whether it is carried by positive charges moving in the direction of the conventional current or by negative charges moving in the opposite direction. This macroscopic viewpoint is an approximation that simplifies electromagnetic concepts and calculations.

At the opposite extreme, if one looks at the microscopic situation, one sees there are many ways of carrying an electric current, including: a flow of electrons; a flow of electron "holes" that act like positive particles; and both negative and positive particles (ions or other charged particles) flowing in opposite directions in an electrolytic solution or a plasma.

Beware that, in the common and important case of metallic wires, the direction of the conventional current is opposite to the drift velocity of the actual charge carriers; i.e., the electrons. This is a source of confusion for beginners.

The total electric charge of an isolated system remains constant regardless of changes within the system itself. This law is inherent to all processes known to physics and can be derived in a local form from gauge invariance of the wave function. The conservation of charge results in the charge-current continuity equation. More generally, the rate of change in charge density "ρ" within a volume of integration "V" is equal to the area integral over the current density J through the closed surface "S" = ∂"V", which is in turn equal to the net current "I":

Thus, the conservation of electric charge, as expressed by the continuity equation, gives the result:

The charge transferred between times formula_2 and formula_3 is obtained by integrating both sides:
where "I" is the net outward current through a closed surface and "Q" is the electric charge contained within the volume defined by the surface.

Aside from the properties described in articles about electromagnetism, charge is a relativistic invariant. This means that any particle that has charge "Q", no matter how fast it goes, always has charge "Q". This property has been experimentally verified by showing that the charge of "one" helium nucleus (two protons and two neutrons bound together in a nucleus and moving around at high speeds) is the same as "two" deuterium nuclei (one proton and one neutron bound together, but moving much more slowly than they would if they were in a helium nucleus).




</doc>
<doc id="9806" url="https://en.wikipedia.org/wiki?curid=9806" title="Ellis Island">
Ellis Island

Ellis Island, in Upper New York Bay, was the gateway for over 12 million immigrants to the U.S. as the United States' busiest immigrant inspection station for over 60 years from 1892 until 1954. Ellis Island was opened January 1, 1892. The island was greatly expanded with land reclamation between 1892 and 1934. Before that, the much smaller original island was the site of Fort Gibson and later a naval magazine. The island was made part of the Statue of Liberty National Monument in 1965 and has hosted a museum of immigration since 1990.

It was long considered part of New York, but a 1998 United States Supreme Court decision found that most of the island is in New Jersey. The south side of the island, home to the Ellis Island Immigrant Hospital, is closed to the general public and the object of restoration efforts spearheaded by Save Ellis Island.

Ellis Island is in Upper New York Bay, east of Liberty State Park and north of Liberty Island, in Jersey City, New Jersey, with a small section that is part of New York City. Largely created through land reclamation, the island has a land area of , most of which is part of New Jersey. The natural island and contiguous areas comprise the that are part of New York.

The island has been owned and administered by the federal government of the United States since 1808 and operated by the National Park Service since 1965.

Since the September 11 attacks in 2001, the island is guarded by patrols of the United States Park Police Marine Patrol Unit. Public access is by ferry from either Communipaw Terminal in Liberty State Park or from the Battery at the southern tip of Manhattan. The ferry operator, Hornblower Cruises and Events, also provides service to the nearby Statue of Liberty. A bridge built for transporting materials and personnel during restoration projects connects Ellis Island with Liberty State Park but is not open to the public. The city of New York and the private ferry operator at the time opposed proposals to use it or replace it with a pedestrian bridge.

Much of the island, including the entire south side, has been closed to the public since 1954. The renovated area on the north side was again closed to the public after Hurricane Sandy in October 2012. The island was re-opened to the public and the museum partially re-opened on October 28, 2013, after major renovations.

Originally much of the west shore of Upper New York Bay consisted of large tidal flats which hosted vast oyster banks, a major source of food for the Lenape population who lived in the area prior to the arrival of Dutch settlers. There were several islands which were not completely submerged at high tide. Three of them (later to be known as Liberty Island, Black Tom Island and Ellis Island) were given the name Oyster Islands by the settlers of New Netherland, the first European colony in the region. The oyster beds remained a major source of food for nearly three centuries. Landfilling to build the railyards of the Lehigh Valley Railroad and the Central Railroad of New Jersey eventually obliterated the oyster beds, engulfed one island, and brought the shoreline much closer to the others. During the colonial period, Little Oyster Island was known as Dyre's, then Bucking Island. In the 1760s, after some pirates were hanged from one of the island's scrubby trees, it became known as Gibbet Island. It was acquired by Samuel Ellis, a colonial New Yorker and merchant possibly from Wales, around the time of the American Revolution. In 1785, he unsuccessfully attempted to sell the island: 

The State of New York leased the island in 1794 and started to fortify it in 1795. Ownership was in question and legislation was passed for acquisition by condemnation in 1807 and then ceded to the United States in 1808. Shortly thereafter the War Department established a circular stone 14-gun battery, a mortar battery (possibly of six mortars), magazine, and barracks. This was part of what was later called the second system of U.S. fortifications. From 1808 until 1814 it was a federal arsenal. The fort was initially called Crown Fort, but by the end of the War of 1812 the battery was named Fort Gibson, after Colonel James Gibson of the 4th Regiment of Riflemen, killed in the Siege of Fort Erie during the war. Parts of the wall foundations of the fort were uncovered while excavating for the Immigrant Wall of Honor, and they are preserved with an interpretive plaque. The island remained a military post for nearly 80 years before it was selected to be a federal immigration station.

In the 35 years before Ellis Island opened, more than eight million immigrants arriving in New York City had been processed by officials at Castle Garden Immigration Depot in Lower Manhattan, just across the bay. The federal government assumed control of immigration on April 18, 1890, and Congress appropriated $75,000 to construct America's first federal immigration station on Ellis Island. Artesian wells were dug, and fill material was hauled in from incoming ships' ballast and from construction of New York City's subway tunnels, which doubled the size of Ellis Island to over six acres. While the building was under construction, the Barge Office nearby at the Battery was used for immigrant processing.

The first station was a three-story-tall structure with outbuildings, built of Georgia Pine, containing the amenities thought to be necessary. It opened with fanfare on January 1, 1892. Three large ships landed on the first day, and 700 immigrants passed over the docks. Almost 450,000 immigrants were processed at the station during its first year. On June 15, 1897, a fire of unknown origin, possibly caused by faulty wiring, turned the wooden structures on Ellis Island into ashes. No loss of life was reported, but most of the immigration records dating back to 1855 were destroyed. About 1.5 million immigrants had been processed at the first building during its five years of use. Plans were immediately made to build a new, fireproof immigration station. During the construction period, passenger arrivals were again processed at the Barge Office. Edward Lippincott Tilton and William A. Boring won the 1897 competition to design the first phase, including the Main Building (1897–1900), Kitchen and Laundry Building (1900–01), Main Powerhouse (1900–01), and the Main Hospital Building (1900–01).

The present main structure was designed in French Renaissance Revival style and built of red brick with limestone trim. After it opened on December 17, 1900, the facilities proved barely able to handle the flood of immigrants that arrived in the years before World War I. In 1913, writer Louis Adamic came to America from Slovenia, then part of the Austro-Hungarian Empire, and described the night he and many other immigrants slept on bunk beds in a huge hall. Lacking a warm blanket, the young man "shivered, sleepless, all night, listening to snores" and dreams "in perhaps a dozen different languages". The facility was so large that the dining room could seat 1,000 people. It is reported the island’s first immigrant to be processed through was a teenager named Annie Moore from County Cork in Ireland.

After its opening, Ellis Island was again expanded, and additional structures were built. By the time it closed on November 12, 1954, 12 million immigrants had been processed by the U.S. Bureau of Immigration. It is estimated that 10.5 million immigrants departed for points across the United States from the Central Railroad of New Jersey Terminal, just across a narrow strait. Others would have used one of the other terminals along the North River (Hudson River) at that time. At first, the majority of immigrants arriving through the station were Northern and Western Europeans (Germany, France, Switzerland, Belgium, The Netherlands, Great Britain, and the Scandinavian countries). Eventually, these groups of peoples slowed in the rates that they were coming in, and immigrants came in from Southern and Eastern Europe, including Jews. Many reasons these immigrants came to the United States included escaping political and economic oppression, as well as persecution, destitution, and violence. Other groups of peoples being processed through the station were Poles, Hungarians, Czechs, Serbs, Slovaks, Greeks, Syrians, Turks, and Armenians.

Between 1905 and 1914, an average of one million immigrants per year arrived in the United States. Immigration officials reviewed about 5,000 immigrants per day during peak times at Ellis Island. Two-thirds of those individuals emigrated from eastern, southern and central Europe. The peak year for immigration at Ellis Island was 1907, with 1,004,756 immigrants processed. The all-time daily high occurred on April 17, 1907, when 11,747 immigrants arrived. After the Immigration Act of 1924 was passed, which greatly restricted immigration and allowed processing at overseas embassies, the only immigrants to pass through the station were those who had problems with their immigration paperwork, displaced persons, and war refugees. Today, over 100 million Americans — about one-third to 40% of the population of the United States — can trace their ancestry to immigrants who arrived in America at Ellis Island before dispersing to points all over the country.

Generally, those immigrants who were approved spent from two to five hours at Ellis Island. Arrivals were asked 29 questions including name, occupation, and the amount of money carried. It was important to the American government the new arrivals could support themselves and have money to get started. The average the government wanted the immigrants to have was between 18 and 25 dollars ($600 in 2015 adjusted for inflation). Those with visible health problems or diseases were sent home or held in the island's hospital facilities for long periods of time. More than 3,000 would-be immigrants died on Ellis Island while being held in the hospital facilities. Some unskilled workers were rejected because they were considered "likely to become a public charge." About 2% were denied admission to the U.S. and sent back to their countries of origin for reasons such as having a chronic contagious disease, criminal background, or insanity. Ellis Island was sometimes known as "The Island of Tears" or "Heartbreak Island" because of those 2% who were not admitted after the long transatlantic voyage. The Kissing Post is a wooden column outside the Registry Room, where new arrivals were greeted by their relatives and friends, typically with tears, hugs, and kisses.

During World War I, the German sabotage of the Black Tom Wharf ammunition depot damaged buildings on Ellis Island. The repairs included the Main Hall's current barrel-vaulted ceiling.

To support the activities of the United States Bureau of Immigration, the United States Public Health Service operated an extensive medical service at the immigrant station, called U.S. Marine Hospital Number 43, more widely known as the Ellis Island Immigrant Hospital. It was the nation's largest marine hospital. Uniformed military surgeons staffed the medical division, which was active in the hospital wards, the Barge Office at the Battery and the Main Building. They are best known for the role they played during the line inspection, in which they employed unusual techniques such as the use of the buttonhook to examine immigrants for signs of eye diseases (particularly, trachoma) and the use of a chalk mark code. Symbols were chalked on the clothing of potentially sick immigrants following the six-second medical examination. The doctors would look at the immigrants as they climbed the stairs from the baggage area to the Great Hall. Immigrants' behavior would be studied for difficulties in getting up the staircase. Some immigrants supposedly entered the country by surreptitiously wiping the chalk marks off, or by turning their clothes inside out.

The symbols used were:
U.S. Immigrant Inspectors used some other symbols or marks as they interrogated immigrants in the Registry Room to determine whether to admit or detain them, including:
Many of the people immigrating to America hailed from Europe, with Eastern Europe and Southern European immigrants being the primary groups. During this time period, eugenic ideals gained broad popularity and made heavy impact on immigration to the United States by way of exclusion of disabled and "morally defective" people.

Eugenicists of the late 19th and early 20th century believed reproductive selection should be carried out by the state as a collective decision. For many eugenicists, this was considered a patriotic duty as they held an interest in creating a greater national race. Henry Fairfield Osborn's opening words to the "New York Evening Journal" in 1911 were, "As a biologist as well as a patriot...," on the subject on advocating for tighter inspections of immigrants of the United States.

Eugenic selection occurred on two distinguishable levels:
At the time, it was a broadly popular idea that immigration policies had ought to be based off eugenics principles in order to help create a "superior race" in America. To do this, defective persons needed to be screened by immigration officials and denied entry on the basis of their disability.

Types of defects screened for included:

The people with moral or mental disability were of higher concern to officials and under the law, mandatorily excluded from immigrating to the United States. Persons with physical disability were under higher inspection and could be turned way on the basis of their disability. Much of this came in part of the eugenicist belief that defects were hereditary, especially those of the moral and mental nature those these were often outwardly signified by physical deformity as well.

In 1898, a Chicago surgeon named Eugene S. Talbot (Eugene Solomon) wrote "crime is hereditary, a tendency which is, in most cases, associated with bodily defects." Likewise, George Lydston, a medicine and criminal anthropology professor, argued further in 1906 that people with "defective physique" were not just criminally associated but that defectiveness was a primary factor "in the causation of crime."

Between 1891 and 1930, Ellis Island reviewed over 25 million attempted immigrations. Of this 25 million, 700,000 were given certificates of disability or disease and of these 79,000 were barred from entry. Approximately 4.4% of immigrants between 1909 and 1930 were classified as disabled or diseased per with 11% being deported when this number spiked to 8.0% in the years of 1918-1919. One percent of immigrants were deported yearly due to medical causes.

With the passing of the Emergency Quota Act of 1921, the number of immigrants being allowed into the United States declined greatly. The passing of the bill ended the era of mass immigration. After 1924, Ellis Island became primarily a detention and deportation processing station.

During and immediately following World War II, Ellis Island was used to hold German merchant mariners and "enemy aliens"—Axis nationals detained for fear of spying, sabotage, and other fifth column activity. In December 1941, Ellis Island held 279 Japanese, 248 Germans, and 81 Italians removed from the East Coast. Unlike other wartime immigration detention stations, Ellis Island was designated as a permanent holding facility and was used to hold foreign nationals throughout the war. A total of 7,000 Germans, Italians and Japanese would be ultimately detained at Ellis Island. It was also a processing center for returning sick or wounded U.S. soldiers, and a Coast Guard training base. Ellis Island still managed to process tens of thousands of immigrants per year during this time, but many fewer than the hundreds of thousands per year who arrived before the war. After the war, immigration rapidly returned to earlier levels.

The Internal Security Act of 1950 barred members of communist or fascist organizations from immigrating to the United States. Ellis Island saw detention peak at 1,500, but by 1952, after changes to immigration laws and policies, only 30 detainees remained.

One of the last detainees was the Indonesian Aceh separatist Hasan di Tiro who, while a student in New York in 1953, declared himself the "foreign minister" of the rebellious Darul Islam movement. Due to this action, he was immediately stripped of his Indonesian citizenship, causing him to be imprisoned for a few months on Ellis Island as "an illegal alien."

The station's commissioners were:


Other notable officials at Ellis Island included James R. O'Beirne (assistant commissioner, 1890–93), Edward F. McSweeney (assistant commissioner, 1893-1902), Joseph E. Murray (assistant commissioner, 1902–09), Byron Uhl (assistant commissioner, 1909-1940), Dr. George W. Stoner (chief surgeon), Augustus Frederick Sherman (chief clerk), Dr. Victor Heiser (surgeon) (surgeon), Dr. Thomas W. Salmon (surgeon), Dr. Howard Knox (surgeon), Antonio Frabasilis (interpreter), Peter Mikolainis (interpreter), Maud Mosher (matron), Fiorello H. La Guardia (interpreter), Samuel Hays, (special immigrant inspector)Roman Dobler (immigrant inspector), Philip Cowen (immigrant inspector), Philip Forman (immigrant inspector, 1930s; chief of detention, deportation and parole, 1940s, 1950s) and De Jalma West (immigrant inspector).

Prominent amongst the missionaries and immigrant aid workers were Rev. Michael J. Henry and Rev. Anthony J. Grogan (Irish Catholic), Rev. Gaspare Moretto (Italian Catholic), Alma E. Mathews (Methodist), Rev. Georg Doring (German Lutheran), Rev. Joseph L'Etauche (Polish Catholic), Rev. Reuben Breed (Episcopal), Michael Lodsin (Baptist), Brigadier Thomas Johnson (Salvation Army), Ludmila K. Foxlee (YWCA), Athena Marmaroff (Woman's Christian Temperance Union), Alexander Harkavy (HIAS), and Cecilia Greenstone and Cecilia Razovsky (National Council of Jewish Women).

A myth persists that government officials on Ellis Island compelled immigrants to take new names against their wishes. In fact, no historical records bear this out. Immigration inspectors used the passenger lists they received from the steamship companies to process each foreigner. These were the sole immigration records for entering the country and were prepared not by the U.S. Bureau of Immigration but by steamship companies such as the Cunard Line, the White Star Line, the North German Lloyd Line, the Hamburg-Amerika Line, the Italian Steam Navigation Company, the Red Star Line, the Holland America Line, and the Austro-American Line. The Americanization of many immigrant families' surnames was for the most part adopted by the family after the immigration process, or by the second or third generation of the family after some assimilation into American culture. However, many last names were altered slightly because of the disparity between English and other languages in the pronunciation of certain letters of the alphabet.

The first immigrant to pass through Ellis Island was Annie Moore, a 17-year-old girl from Cork, Ireland, who arrived on the ship "Nevada" on January 1, 1892. She and her two brothers were coming to America to meet their parents, who had moved to New York two years prior. She received a greeting from officials and a $10 gold coin. It was the largest sum of money she had ever owned.

The last person to pass through Ellis Island was Norwegian merchant seaman Arne Peterssen in 1954.

The wooden structure built in 1892 to house the immigration station burned down after five years. The station's new Main Building, which now houses the Immigration Museum, was opened in 1900.
Architects Edward Lippincott Tilton and William Alciphron Boring received a gold medal at the 1900 Paris Exposition for the building's design and constructed the building at a cost of $1.5 million. The architecture competition was the second under the Tarsney Act, which had permitted private architects rather than government architects in the Treasury Department's Office of the Supervising Architect to design federal buildings.

After the immigration station closed in November 1954, the buildings fell into disrepair and were abandoned. Attempts at redeveloping the site were unsuccessful until its landmark status was established. On October 15, 1965, Ellis Island was proclaimed a part of Statue of Liberty National Monument. It was listed on the National Register of Historic Places on October 15, 1966.

Boston-based architectural firm Finegold Alexander + Associates Inc, together with the New York architectural firm Beyer Blinder Belle, designed the restoration and adaptive use of the Beaux-Arts Main Building, one of the most symbolically important structures in American history. A construction budget of $150 million was required for this significant restoration. This money was raised by a campaign organized by the political fundraiser Wyatt A. Stewart. The building reopened on September 10, 1990. Exhibits include "Hearing Room", "Peak Immigration Years", the "Peopling of America", "Restoring a Landmark", "Silent Voices", "Treasures from Home", and "Ellis Island Chronicles". There are also three theaters used for film and live performances.

On May 20, 2015, the Ellis Island Immigration Museum was officially renamed the Ellis Island National Museum of Immigration, coinciding with the opening of the new Peopling of America galleries. The expansion tells the entire story of American immigration, including before and after the Ellis Island era. The Peopling of America Center was designed by ESI Design and fabricated by Hadley Exhibits, Inc. The architectural design was done by Highland Associates, with construction executed by Phelps Construction Group.

The Wall of Honor outside of the main building contains a partial list of immigrants processed on the island. Inclusion on the list is made possible by a donation to support the facility. In 2008 the museum's library was officially named the Bob Hope Memorial Library in honor of one the station's most famous immigrants.

The Ellis Island Medal of Honor is awarded annually at ceremonies on the island.

The south side of the island, home to the Ellis Island Immigrant Hospital, is closed to the general public and the object of restoration efforts spearheaded by Save Ellis Island.

Many of the facilities at Ellis Island were abandoned and remain unrenovated. The entire south side, called by some the "sad side" of the island, is off limits to the general public. The Ellis Island Immigrant Hospital operated here from early 1902 to 1930. The foundation Save Ellis Island is spearheading preservation efforts. The New Ferry Building, built in the Art Deco style to replace an earlier one, was renovated in 2008, but remains only partially accessible to the general public.

As part of the National Park Service's Centennial Initiative, the south side of the island was to be the target of a project to restore the 28 buildings that have not yet been rehabilitated.

The circumstances which led to an exclave of New York being located within New Jersey began in the colonial era, after the British takeover of New Netherland in 1664. An unusual clause in the colonial land grant outlined the territory that the proprietors of New Jersey would receive as being "westward of Long Island, and Manhitas Island and bounded on the east part by the main sea, and part by Hudson's river", rather than at the river's midpoint, as was common in other colonial charters.

Attempts were made as early as 1804 to resolve the status of the state line. The City of New York claimed the right to regulate trade on all the waters. This was contested in "Gibbons v. Ogden", which decided that the regulation of interstate commerce fell under the authority of the federal government, thus influencing competition in the newly developing steam ferry service in New York Harbor.

In 1830, New Jersey planned to bring suit to clarify the border, but the case was never heard. The matter was resolved with a compact between the states, ratified by U.S. Congress in 1834, which set the boundary line between them as the middle of the Hudson River and New York Harbor. This was later confirmed by the U.S. Supreme Court in other cases which also expounded on the compact.

The federal government, which had bought the island in 1808, began expanding the island by land fill, to accommodate the immigration station opened in 1892. Land filling continued in stages until 1934.

Nine-tenths of the current area is artificial island that did not exist at the time of the interstate compact. New Jersey contended that the new extensions were part of New Jersey, since they were outside New York's border and were in fact within New Jersey's border. In 1956, after the 1954 closing of the U.S. immigration station, the then Mayor of Jersey City, Bernard J. Berry, commandeered a U.S. Coast Guard cutter and led a contingent of New Jersey officials on an expedition to claim the island. In 1997, the state filed suit to establish its jurisdiction, leading New York City Mayor Rudolph Giuliani to remark dramatically that his father, an Italian who immigrated through Ellis Island, never intended to go to New Jersey. The border was redrawn using information based on studies using geographic information science.

The dispute eventually reached the Supreme Court of the United States, which ruled in "New Jersey v. New York" , that New Jersey had jurisdiction over all portions of the island created after the original compact was approved (effectively, more than 80% of the island's present land). This caused several immediate instances of confusion: some buildings, for instance, fell into the territory of both states. New Jersey and New York soon agreed to share jurisdiction of the island. It remains wholly a federal property, however, and these legal decisions do not result in either state taking any fiscal or physical responsibility for the maintenance, preservation, or improvement of any of the historic properties.

The ruling had no effect on the status of Liberty Island, of which was created by land reclamation.

For New York State tax purposes, it is assessed as Manhattan Block 1, Lot 201. Since 1998, the 22.8 acre portion of the island in New Jersey has been assessed in Jersey City as Block 21603, Lot 1.

Frank Lloyd Wright designed a key plan for the island that included housing, hotels, and large domes along the edges. The co-curator of the traveling exhibit, "Never Built New York" in which it is included told "AM New York", "It's pretty remarkable but at the same time it's a little bit horrifying that they could have gotten rid of Ellis Island."

In 1982 the National Parks Department embarked on an 8-year renovation. During that time, David Simonton was part of The Ellis Island Project: Documentation/Interpretation and captured stunning, black and white photos giving insight into immigrant's lives. Photographer Stephen Wilkes's series Ellis Island: Ghosts of Freedom (2006) captured the abandoned south side of Ellis Island.

Emergency services on Ellis Island are provided by the following emergency divisions of the National Park Service:

Ellis Island has been a source of inspiration or used as a subject in popular culture. Its imagery or representation has been employed in literature (including novels, short stories and poetry), in song, musical composition, dance, theatre, including vaudeville, burlesque, musical comedy, revue, legitimate theatre, motion pictures (silent and sound), newsreels, and in radio and television.

Early films, including those from the silent era, which feature the station include "Traffic in Souls" (1913), "How The Jews Care for Their Poor" (educational film, 1914) "The Yellow Passport" (1916), "My Boy" (1921), Frank Capra's "The Strong Man" (1926), "We Americans" (1928), "The Mating Call" (1928), "This is Heaven" (1929), "Paddy O'Day" (1935), "Ellis Island" (1936), "Gateway" (1938), "Exile Express" (1939), "I, Jane Doe" (1948), and "Gambling House" (1951). In "The Godfather Part II", Vito Corleone immigrates via Ellis Island as a boy. The opening scene of "The Brother From Another Planet" is set there. The island is visited by the characters in the 2005 romantic comedy, "Hitch", and is the setting for the climactic battle in "X-Men".

Over the decades, Ellis Island was also widely referenced or remarked on in books, such as "Mrs 'Arris Goes to New York" (1960) by Paul Gallico, and in popular films such as "Cafe Metropole" (1937) and "With a Song in My Heart" (1952).

Some films have focused on the immigrant experience, such as the 1984 TV miniseries "Ellis Island". The IMAX 3D movie "Across the Sea of Time" incorporates both modern footage and historical photographs of Ellis Island. The 2006 Italian movie "The Golden Door", directed by Emanuele Crialese, takes place largely on Ellis Island. "Forgotten Ellis Island", a film and book, focuses on the Ellis Island Immigrant Hospital. "The Immigrant" is a 2013 American drama film directed by James Gray, starring Marion Cotillard, Joaquin Phoenix, and Jeremy Renner. "Ellis", a short, premiered in November 2015.

Ellis Island as a port of entry is described in detail in "Mottel the Cantor's Son" by Sholom Aleichem.

"" is a work for actors and orchestra with projected images by Peter Boyer, composed in 2001-02. The song "The New Ground - Isle of Hope, Isle of Tears", on the 2010 album "" by the group Celtic Woman, is about Annie Moore and Ellis Island.

The USPS issued a 32¢ stamp on February 3, 1998 as part of the Celebrate the Century stamp sheet series.





</doc>
<doc id="9808" url="https://en.wikipedia.org/wiki?curid=9808" title="Euripides">
Euripides

Euripides (; ; ) (c. 480 – c. 406 BC) was a tragedian of classical Athens. Along with Aeschylus and Sophocles, he is one of the three ancient Greek tragedians for whom a significant number of plays have survived. Some ancient scholars attributed 95 plays to him but, according to the "Suda", it was 92 at most. Of these, 18 or 19 have survived more or less complete (there has been debate about his authorship of "Rhesus", largely on stylistic grounds) and there are also fragments, some substantial, of most of the other plays. More of his plays have survived intact than those of Aeschylus and Sophocles together, partly because his popularity grew as theirs declinedhe became, in the Hellenistic Age, a cornerstone of ancient literary education, along with Homer, Demosthenes, and Menander.

Euripides is identified with theatrical innovations that have profoundly influenced drama down to modern times, especially in the representation of traditional, mythical heroes as ordinary people in extraordinary circumstances. This new approach led him to pioneer developments that later writers adapted to comedy, some of which are characteristic of romance. Yet he also became "the most tragic of poets", focusing on the inner lives and motives of his characters in a way previously unknown. He was "the creator of...that cage which is the theatre of Shakespeare's "Othello", Racine's "Phèdre", of Ibsen and Strindberg," in which "...imprisoned men and women destroy each other by the intensity of their loves and hates", and yet he was also the literary ancestor of comic dramatists as diverse as Menander and George Bernard Shaw.

He was also unique among the writers of ancient Athens for the sympathy he demonstrated towards all victims of society, including women. His conservative male audiences were frequently shocked by the 'heresies' he put into the mouths of characters, such as these words of his heroine Medea:

His contemporaries associated him with Socrates as a leader of a decadent intellectualism, both of them being frequently lampooned by comic poets such as Aristophanes. Whereas Socrates was eventually put on trial and executed as a corrupting influence, Euripides chose a voluntary exile in old age, dying in Macedonia. Recent scholarship casts doubt on ancient biographies of Euripides. For example, it is possible that he never visited Macedonia at all, or, if he did, he might have been drawn there by King Archelaus with incentives that were also offered to other artists.

Traditional accounts of the author's life are found in many commentaries and include details such as these: He was born on Salamis Island around 480 BC, with parents Cleito (mother) and Mnesarchus (father), a retailer who lived in a village near Athens. Upon the receipt of an oracle saying that his son was fated to win "crowns of victory", Mnesarchus insisted that the boy should train for a career in athletics. In fact the boy was destined for a career on the stage, where however he was to win only five victories, one of which was after his death. He served for a short time as both dancer and torch-bearer at the rites of Apollo Zosterius. His education was not confined to athletics: he also studied painting and philosophy under the masters Prodicus and Anaxagoras. He had two disastrous marriages and both his wivesMelite and Choerine (the latter bearing him three sons)were unfaithful. He became a recluse, making a home for himself in a cave on Salamis (The Cave of Euripides, where a cult of the playwright developed after his death). "There he built an impressive library and pursued daily communion with the sea and sky". Eventually he retired to the "rustic court" of King Archelaus in Macedonia, where he died in 406 BC. However, as mentioned in the introduction, biographical details such as these should be regarded with scepticism. They are derived almost entirely from three unreliable sources:
This biography is divided into three sections corresponding to the three kinds of sources.
Euripides was the youngest in a set of three great tragedians who were almost contemporaries: his first play was staged thirteen years after Sophocles' debut and only three years after Aeschylus's masterpiece, the "Oresteia". The identity of the threesome is neatly underscored by a patriotic account of their roles during Greece's great victory over Persia at the Battle of SalamisAeschylus fought there, Sophocles was just old enough to celebrate the victory in a boys' chorus and Euripides was born on the very day of the battle. The apocryphal account that he composed his works in a cave on Salamis island was a late tradition and it probably symbolizes the isolation of an intellectual who was rather ahead of his time. Much of his life and his whole career coincided with the struggle between Athens and Sparta for hegemony in Greece but he didn't live to see the final defeat of his city. It is said that he died in Macedonia after being attacked by the Molossian hounds of King Archelaus and that his cenotaph near Piraeus was struck by lightningsigns of his unique powers, whether for good or ill (according to one modern scholar, his death might have been caused instead by the harsh Macedonian winter). In an account by Plutarch, the catastrophic failure of the Sicilian expedition led Athenians to trade renditions of Euripides' lyrics to their enemies in return for food and drink ("Life of Nicias" 29). Plutarch is the source also for the story that the victorious Spartan generals, having planned the demolition of Athens and the enslavement of its people, grew merciful after being entertained at a banquet by lyrics from Euripides' play "Electra": "they felt that it would be a barbarous act to annihilate a city which produced such men" ("Life of Lysander").

Tragic poets were often mocked by comic poets during the dramatic festivals Dionysia and Lenaia, and Euripides was travestied more than most. Aristophanes scripted him as a character in at least three plays: "The Acharnians", "Thesmophoriazusae" and "The Frogs". Yet Aristophanes borrowed rather than just satirized some of the tragedian's methods; he was once ridiculed by a colleague, Cratinus, as "a hair-splitting master of niceties, a "Euripidaristophanist"". According to another comic poet, Teleclides, the plays of Euripides were co-authored by the philosopher Socrates. According to Aristophanes, the alleged co-author was a celebrated actor, Cephisophon, who also shared the tragedian's house and his wife, while Socrates taught an entire school of quibblers like Euripides:

In "The Frogs", composed after Euripides and Aeschylus were both dead, Aristophanes imagines the god Dionysus venturing down to Hades in search of a good poet to bring back to Athens. After a debate between the two deceased bards, the god brings Aeschylus back to life as more useful to Athens on account of his wisdom, rejecting Euripides as merely clever. Such comic 'evidence' suggests that Athenians admired Euripides even while they mistrusted his intellectualism, at least during the long war with Sparta. Aeschylus had written his own epitaph commemorating his life as a warrior fighting for Athens against Persia, without any mention of his success as a playwright, and Sophocles was celebrated by his contemporaries for his social gifts and contributions to public life as a state official, but there are no records of Euripides' public life except as a dramatisthe could well have been "a brooding and bookish recluse". He is presented as such in "The Acharnians", where Aristophanes shows him to be living morosely in a precarious house, surrounded by the tattered costumes of his disreputable characters (and yet Agathon, another tragic poet, is discovered in a later play, "Thesmophoriazusae", to be living in circumstances almost as bizarre). Euripides' mother was a humble vendor of vegetables, according to the comic tradition, yet his plays indicate that he had a liberal education and hence a privileged background.

Euripides first competed in the City Dionysia, the famous Athenian dramatic festival, in 455 BC, one year after the death of Aeschylus, and it was not until 441 BC that he won a first prize. His final competition in Athens was in 408 BC. "The Bacchae" and "Iphigenia in Aulis" were performed after his death in 405 BC and first prize was awarded posthumously. Altogether his plays won first prize only five times.

His plays and those of Aeschylus and Sophocles indicate a difference in outlook between the three mena generation gap probably due to the Sophistic enlightenment in the middle decades of the 5th century: Aeschylus still looked back to the archaic period, Sophocles was in transition between periods, and Euripides was fully imbued with the new spirit of the classical age. When Euripides' plays are sequenced in time, they also reveal that his outlook might have changed, providing a "spiritual biography" along these lines:
However, about 80% of his plays have been lost and even the extant plays do not present a fully consistent picture of his 'spiritual' development (for example, "Iphigenia at Aulis" is dated with the 'despairing' "Bacchae", yet it contains elements that became typical of New Comedy). In the "Bacchae", he restores the chorus and messenger speech to their traditional role in the tragic plot, and the play appears to be the culmination of a regressive or archaizing tendency in his later works (for which see Chronology below). Believed to have been composed in the wilds of Macedonia, "Bacchae" also happens to dramatize a primitive side to Greek religion and some modern scholars have therefore interpreted this particular play biographically as:
One of his earliest extant plays, "Medea", includes a speech that he seems to have written in defence of himself as an intellectual ahead of his time, though he has put it in the mouth of the play's heroine:
Athenian tragedy in performance during Euripides' lifetime was a public contest between playwrights. The state funded it and awarded prizes to the winners. The language was spoken and sung verse, the performance area included a circular floor or orchestra where the chorus could dance, a space for actors (three speaking actors in Euripides' time), a backdrop or skene and some special effects: an ekkyklema (used to bring the skene's "indoors" outdoors) and a mechane (used to lift actors in the air, as in deus ex machina). With the introduction of the third actor (an innovation attributed to Sophocles), acting also began to be regarded as a skill to be rewarded with prizes, requiring a long apprenticeship in the chorus. Euripides and other playwrights accordingly composed more and more arias for accomplished actors to sing and this tendency becomes more marked in his later plays: tragedy was a "living and ever-changing genre" (other changes in his work are touched on in the previous section and in Chronology; a list of his plays is given in Extant plays below).

The comic poet, Aristophanes, is the earliest known critic to characterize Euripides as a spokesman for destructive, new ideas, associated with declining standards in both society and tragedy (see Reception for more). However, 5th century tragedy was a social gathering for "carrying out quite publicly the maintenance and development of mental infrastructure" and it offered spectators a "platform for an utterly unique form of institutionalized discussion". A dramatist's role was not just to entertain but also to educate his fellow citizenshe was expected to have a message. Traditional myth provided the subject matter but the dramatist was meant to be innovative so as to sustain interest, which led to novel characterization of heroic figures and to use of the mythical past to talk about present issues. The difference between Euripides and his older colleagues was one of degree: his characters talked about the present more controversially and more pointedly than did those of Aeschylus and Sophocles, sometimes even challenging the democratic order. Thus, for example, Odysseus is represented in "Hecuba" (lines 131–32) as "agile-minded, sweet-talking, demos-pleasing" i.e., a type of the war-time demagogues that were active in Athens during the Peloponnesian War. Speakers in the plays of Aeschylus and Sophocles sometimes distinguished between slaves who are servile by nature and those who are slaves by mere circumstance but Euripides' speakers go further, positing an individual's mental rather than social or physical condition as the true index of worth. Thus in "Hippolytus", a love-sick queen rationalizes her position and arrives at this comment on intrinsic merit while reflecting on adultery:

Euripides' characters resembled contemporary Athenians rather than heroic figures of myth.

As mouthpieces for contemporary issues, they "all seem to have had at least an elementary course in public speaking". The dialogue often contrasts so strongly with the mythical and heroic setting, it looks as if Euripides aimed at parody, as for example in "The Trojan Women", where the heroine's rationalized prayer provokes comment from Menelaus:

Athenian citizens were familiar with rhetoric in the assembly and law courts, and some scholars believe that Euripides was more interested in his characters as speakers with cases to argue than as characters with lifelike personalities. They are self-conscious about speaking formally and their rhetoric is shown to be flawed, as if Euripides was exploring the problematical nature of language and communication: "For speech points in three different directions at once, to the speaker, to the person addressed, to the features in the world it describes, and each of these directions can be felt as skewed". Thus in the example above, Hecuba presents herself as a sophisticated intellectual describing a rationalized cosmos yet the speech is ill-matched to her audience, Menelaus (a type of the unsophisticated listener), and soon it is found not to suit the cosmos either (her infant grandson is brutally murdered by the victorious Greeks). In "Hippolytus", speeches appear verbose and ungainly as if to underscore the limitations of language.

Like Euripides, both Aeschylus and Sophocles created comic effects contrasting the heroic with the mundane, but they employed minor supporting characters for that purpose, whereas the younger poet was more insistent, using major characters as well. His comic touches can be thought to intensify the overall tragic effect, and his realism, which often threatens to make his heroes look ridiculous, marks a world of debased heroism: "The loss of intellectual and moral substance becomes a central tragic statement". Psychological reversals are common and sometimes happen so suddenly that inconsistency in characterization is an issue for many critics, such as Aristotle, who cited "Iphigenia in Aulis" as an example ("Poetics" 1454a32). For others, psychological inconsistency is not a stumbling block to good drama: "Euripides is in pursuit of a larger insight: he aims to set forth the two modes, emotional and rational, with which human beings confront their own mortality." Some however consider unpredictable behaviour to be realistic in tragedy: "everywhere in Euripides a preoccupation with individual psychology and its irrational aspects is evident...In his hands tragedy for the first time probed the inner recesses of the human soul and let "passions spin the plot"." The tension between reason and passion is symbolized by his character's relationship with the gods, as in Hecuba's prayer, answered not by Zeus, nor by the Law of Reason, but by brutal Menelaus as if speaking on behalf of the old gods, and most famously in "Bacchae", where the god Dionysus savages his own converts. And yet when the gods appear deus ex machina, as they do in eight of the extant plays, they appear "lifeless and mechanical". Sometimes condemned by critics as an unimaginative way to end a story, the spectacle of a "god" making a judgement or announcement from a theatrical crane might actually have been intended to provoke scepticism about the religious and heroic dimension of his plays. Similarly his plays often begin in a banal manner that undermines theatrical illusion. Unlike Sophocles, who established the setting and background of his plays in the introductory dialogue, Euripides used a monologue in which a divinity or human character directly and simply tells the audience all it needs to know in order to understand the subsequent action.

Aeschylus and Sophocles were innovative, but Euripides had arrived at a position in the "ever-changing genre" where he could move easily between tragic, comic, romantic and political effects, a versatility that appears in individual plays and also over the course of his career. Potential for comedy lay in his use of 'contemporary' characters, in his sophisticated tone, his relatively informal Greek (see In Greek below), and in his ingenious use of plots centred on motifs that later became standard in Menander's New Comedy, such as the 'recognition scene'. Other tragedians also used recognition scenes but they were heroic in emphasis, as in Aeschylus's "The Libation Bearers", which Euripides parodied with his mundane treatment of it in "Electra" (Euripides was unique among the tragedians in incorporating theatrical criticism in his plays). Traditional myth, with its exotic settings, heroic adventures and epic battles, offered potential for romantic melodrama as well as for political comments on a war theme, so that his plays are an extraordinary mix of elements. "The Trojan Women" for example is a powerfully disturbing play on the theme of war's horrors, apparently critical of Athenian imperialism (it was composed in the aftermath of the Melian massacre and during the preparations for the Sicilian Expedition) yet it features the comic exchange between Menelaus and Hecuba quoted above and the chorus considers Athens, the "blessed land of Theus", to be a desirable refugesuch complexity and ambiguity are typical both of his "patriotic" and "anti-war" plays.

Tragic poets in the 5th century competed against one another at the City Dionysia, each with a tetralogy consisting of three tragedies and a satyr-play. The few extant fragments of satyr-plays attributed to Aeschylus and Sophocles indicate that these were a loosely structured, simple and jovial form of entertainment. However, in "Cyclops" (the only complete satyr-play that survives) Euripides structured the entertainment more like a tragedy and introduced a note of critical irony typical of his other work. His genre-bending inventiveness is shown above all in "Alcestis", a blend of tragic and satyric elements. This fourth play in his tetralogy for 438 BC (i.e., it occupied the position conventionally reserved for satyr-plays) is a "tragedy" that features Heracles as a satyric hero in conventional satyr-play scenes, involving an arrival, a banquet, a victory over an ogre (in this case, Death), a happy ending, a feast and a departure to new adventures. Most of the big innovations in tragedy were made by Aeschylus and Sophocles and yet "Euripides made innovations on a smaller scale that have impressed some critics as cumulatively leading to a radical change of direction".

The spoken language of the plays is not fundamentally different in style from that of Aeschylus or Sophoclesit employs poetic meters, a rarefied vocabulary, fullness of expression, complex syntax, and ornamental figures, all aimed at representing an elevated style. However, its rhythms are somewhat freer and more natural than that of his predecessors, and the vocabulary has been expanded to allow for intellectual and psychological subtleties. Euripides was also a great lyric poet. In "Medea", for example, he composed for his city, Athens, "the noblest of her songs of praise". His lyric skills however are not just confined to individual poems: "A play of Euripides is a musical whole...one song echoes motifs from the preceding song, while introducing new ones." For some critics, the lyrics often seem dislocated from the action but the extent and significance of this is "a matter of scholarly debate". See Chronology for details about his style in the original Greek.

Euripides has aroused and continues to arouse strongly contrasting opinions of his work, for and against:

Aeschylus gained thirteen victories as a dramatist, Sophocles at least twenty, Euripides only four in his lifetime, and this has often been taken as an indication of the latter's unpopularity with his contemporaries, and yet a first place might not have been the main criterion for success in those times (the system of selecting judges appears to have been flawed) and merely being chosen to compete was in itself a mark of distinction. Moreover, to have been singled out by Aristophanes for so much comic attention is proof of popular interest in his work. Sophocles was appreciative enough of the younger poet to be influenced by him, as is evident in his later plays "Philoctetes" and "Oedipus at Colonus". Less than a hundred years later, Aristotle developed an almost "biological' theory of the development of tragedy in Athens: according to this view, the art form grew under the influence of Aeschylus, matured in the hands of Sophocles then began its precipitous decline with Euripides. However, "his plays continued to be applauded even after those of Aeschylus and Sophocles had come to seem remote and irrelevant", they became school classics in the Hellenistic period (as mentioned in the introduction) and, due to Seneca's adaptation of his work for Roman audiences, "it was Euripides, not Aeschylus or Sophocles, whose tragic muse presided over the rebirth of tragedy in Renaissance Europe."

In the 17th century, Racine expressed admiration for Sophocles but was more influenced by Euripides (e.g. "Iphigenia at Aulis" and "Hippolytus" were the models for his plays "Iphigénie" and "Phèdre"). Euripides' reputation was to take a beating early in the 19th century when Friedrich Schlegel and his brother August Wilhelm Schlegel championed Aristotle's 'biological' model of theatre history, identifying Euripides with the moral, political and artistic degeneration of Athens. August Wilhelm's Vienna lectures on dramatic art and literature went through four editions between 1809 and 1846 and, in them, he opined that Euripides "not only destroyed the external order of tragedy but missed its entire meaning," a view that came to influence Friedrich Nietzsche, who however seems not to have known the Euripidean plays at all well. However literary figures such as the poet Robert Browning and his wife Elizabeth Barrett Browning could study and admire the Schlegels while still appreciating Euripides as "our Euripides the human" ("Wine of Cyprus" stanza 12). Classicists such as Arthur Verrall and Ulrich von Wilamowitz-Moellendorff reacted against the views of the Schlegels and Nietzsche, constructing arguments sympathetic to Euripides, which involved Wilamowitz in this restatement of Greek tragedy as a genre: "A [Greek] tragedy does not have to end 'tragically' or be 'tragic'. The only requirement is a serious treatment." In the English-speaking world, the pacifist Gilbert Murray played an important role in popularizing Euripides, influenced perhaps by his anti-war plays. Today, as in the time of Euripides, traditional assumptions are constantly under challenge and audiences therefore have a natural affinity with the Euripidean outlook which seems nearer to ours for example than the Elizabethan. As stated above, however, opinions continue to diverge, so that one recent critic might dismiss the debates in Euripides' plays as "self-indulgent digression for the sake of rhetorical display" and another springs to the poet's defence in terms such as: "His plays are remarkable for their range of tones and the gleeful inventiveness, which morose critics call cynical artificiality, of their construction."

The textual transmission of the plays from the 5th century BC, when they were first written, up until the era of the printing press, was largely a haphazard process in which much of Euripides' work was lost and corrupted, but it also included triumphs by scholars and copyists, thanks to whom much was also recovered and preserved. Summaries of the transmission are often found in modern editions of the plays, three of which are used as sources for this summary

The plays of Euripides, like those of Aeschylus and Sophocles, were circulated in written form in the 5th century among literary members of the audience and performers at minor festivals, as aide-memoirs. However, literary conventions that we take for granted today had not yet been inventedthere was no spacing between words, no consistency in punctuation nor in vowel elisions, no marks for breathings and accent (guides to pronunciation and hence word recognition), no convention to denote change of speaker and no stage directions, and verse was written straight across the page like prose. Possibly those who bought texts supplied their own interpretative markings. Papyri discoveries have indicated, for example, that a change in speakers was loosely denoted with a variety of signs, such as the equivalent of the modern dash, colon and full-stop. The absence of modern literary conventions, which are an aid to comprehension, was an early and persistent source of errors affecting transmission of the text. Errors crept in also when Athens replaced its old Attic alphabet with the Ionian alphabet, a change sanctioned by law in 403–402 BC, adding a new complication to the task of copying. Many more errors came from the tendency of actors to interpolate words and sentences, producing so many corruptions and variations that a law was proposed by Lycurgus of Athens in 330 BC "...that the plays of Aeschylus, Sophocles and Euripides should be written down and preserved in a public office; and that the town clerk should read the text over with the actors; and that all performances which did not comply with this regulation should be illegal." The law was soon disregarded and some actors continued to make their own changes up until about 200 BC, after which the habit dies out. It was about then that Aristophanes of Byzantium compiled an edition of all the extant plays of Euripides, collated from pre-Alexandrian texts, furnished with introductions and accompanied by a commentary that was "published" separately. This became the "standard edition" for the future and it featured some of the literary conventions that modern readers expectthere was still no spacing between words, little or no punctuation and no stage directions, but abbreviated names now denoted changes of speaker, lyrics are broken into "cola' and "strophai" or lines and stanzas, and a system of accentuation was introduced.

After this creation of a standard edition, the text was fairly safe from errors, apart from the slight and gradual corruption produced by the tedium of frequent copying. Many of these trivial errors occurred in the Byzantine period, following a change in script from uncial to minuscule, and many were "homophonic" errors, when scribes accidentally substituted homophones for words in the textequivalent in English to substituting "right" for "write", except that there were more opportunities for Byzantine scribes to make these errors because the Greek letters η, ι, οι and ει were pronounced similarly in the Byzantine period.

Around 200 AD, ten of the plays of Euripides began to be circulated in a select edition, possibly for use in schools, with some commentaries or scholia recorded in the margins. Similar editions had appeared for Aeschylus and Sophoclesthe only plays of theirs that survive today. Euripides however was more fortunate than the other tragedians in the survival of a second edition of his work, compiled in alphabetical order as if from a set of his collect works, but without scholia attached. This "Alphabetical" edition was combined with the "Select" edition by some unknown Byzantine scholar, bringing together all the nineteen plays that survive today. The "Select" plays are found in many medieval manuscripts but only two manuscripts preserve the "Alphabetical" playsoften denoted L and P, after the Laurentian Library at Florence, and the Bibliotheca Palatina in the Vatican, where they are stored. It is believed that P derived its Alphabet plays and some Select plays from copies of an ancestor of L, but the remainder is derived from elsewhere. P contains all the extant plays of Euripides, L is missing "The Trojan Women" and latter part of "The Bacchae".

In addition to L, P and many other medieval manuscripts, there are also fragments of plays recorded on papyrus. The papyrus fragments are often recovered only through modern technology. In June 2005, for example, classicists at Oxford University worked on a joint project with Brigham Young University, using multi-spectral imaging technology to retrieve previously illegible writing (see References). Some of this work employed infrared technology—previously used for satellite imaging—to detect previously unknown material by Euripides in fragments of the Oxyrhynchus papyri, a collection of ancient manuscripts held by the university.

It is from such materials that modern scholars try to piece together copies of the original plays. Sometimes the picture is almost lost. Thus for example two extant plays, "The Phoenician Women" and "Iphigenia at Aulis", are significantly corrupted by interpolations (the latter possibly being completed post mortem by the poet's son) and the very authorship of "Rhesus" is a matter of dispute. In fact, the very existence of the Alphabet plays, or rather the absence of an equivalent edition for Sophocles and Aeschylus, could distort our notions of distinctive Euripidean qualitiesmost of his least "tragic" plays are in the Alphabet edition and possibly the other two tragedians would appear just as genre-bending as this "restless experimenter" if we possessed more than their "select" editions.

"See Extant plays below for listing of "Select" and "Alphabetical" plays."

The original production dates of some of Euripides' plays are known from ancient records, such as lists of prize-winners at the Dionysia, and approximations are obtained for the remainder by various means. Both the playwright and his work were travestied by comic poets such as Aristophanes, the known dates of whose own plays thus serve as a terminus ad quem for those of Euripides, though sometimes the gap can be considerable (e.g. twenty-seven years separate "Telephus", known to have been produced in 438 BC, from its parody in "Thesmophoriazusae" in 411 BC.) References in Euripides' plays to contemporary events provide a terminus a quo, though sometimes the references might even precede a datable event (e.g. lines 1074–89 in "Ion" describe a procession to Eleusis, which was probably written before the Spartans occupied it during the Peloponnesian War). Other indications of dating are obtained by stylometry and this section therefore is an appropriate place to consider some aspects of his style as a Greek poet.

Greek tragedy comprised lyric and dialogue, the latter mostly in iambic trimeter (three pairs of iambic feet per line). Euripides sometimes 'resolved' the two syllables of the iamb (˘¯) into three syllables (˘˘˘) and this tendency increased so steadily over time that the number of resolved feet in a play can be understood to indicate the approximate date of composition (see Extant plays below for one scholar's list of resolutions per hundred trimeters). Associated with this increase in resolutions was an increasing vocabulary for tragic dialogue, often involving prefixes to refine meanings, allowing the language to assume a more natural rhythm while also becoming ever more capable of psychological and philosophical subtlety.

The trochaic tetrameter catalecticfour pairs of trochees per line, with the final syllable omittedwas identified by Aristotle as the original meter of tragic dialogue ("Poetics" 1449a21). Euripides however employs it here and there in his later plays. He seems not to have used it in his early plays at all, "The Trojan Women" being the earliest appearance of it in an extant play—it is symptomatic of a curious archaizing tendency evident in his later works.

The later plays also feature extensive use of stichomythia (i.e. a series of one-liners). The longest such scene comprises one hundred and five lines in "Ion" (lines 264–369). In contrast, Aeschylus never exceeded twenty lines of stichomythia; Sophocles' longest such scene was fifty lines and it is interrupted several times by αντιλαβή ("Electra", lines 1176–1226).

Euripides' use of lyrics in the sung portion of his work shows the influence of Timotheus of Miletus in the later plays the individual singer gained prominence and was given additional scope to demonstrate his virtuosity in lyrical duets between actors, as well as replacing some of the chorus's functions with monodies. At the same time, choral odes begin to take on something of the form of dithyrambs reminiscent of the poetry of Bacchylides, featuring elaborate treatment of myths. Sometimes these later choral odes seem to have only a tenuous connection with the plot, linked to the action only in their mood. The "Bacchae" however shows a reversion to old forms, possibly as a deliberate archaic effect or maybe because there were no virtuoso choristers in Macedonia, where it is said to have been written.

Key:

The following plays have come down to us today only in fragmentary form, if at all. They are known through quotations in other works, sometimes as little as a single line, or through pieces of papyrus or partial copies in manuscript form; some are known thanks to the survival of part of a collection of hypotheses (or summaries) in papyrus, and others through being parodied in the works of Aristophanes. Some of the fragments are extensive enough to allow tentative reconstructions to be proposed.

A two-volume selection from the fragments, with facing-page translation, introductions, and notes, was published by Collard, Cropp, Lee, and Gibert, as were two Loeb Classical Library volumes derived from them, and there are critical studies in T. B. L. Webster's older "The Tragedies of Euripides" based upon what were then believed to be the most likely reconstructions of the plays.

The following lost and fragmentary plays can be dated, and are arranged in rough chronological order:
The following lost and fragmentary plays are of uncertain date, and are arranged in English alphabetical order.



</doc>
<doc id="9810" url="https://en.wikipedia.org/wiki?curid=9810" title="Emily Brontë">
Emily Brontë

Emily Jane Brontë (, ; 30 July 1818 – 19 December 1848) was an English novelist and poet who is best known for her only novel, "Wuthering Heights", now considered a classic of English literature. Emily was the third-eldest of the four surviving Brontë siblings, between the youngest Anne and her brother Branwell. She wrote under the pen name Ellis Bell.

Emily Brontë was born on 30 July 1818 in the village of Thornton Market Street on the outskirts of Bradford, in the West Riding of Yorkshire, in Northern England, to Maria Branwell and an Irish father, Patrick Brontë. She was the younger sister of Charlotte Brontë and the fifth of six children. In 1820, shortly after the birth of Emily's younger sister Anne, the family moved eight miles away to Haworth, where Patrick was employed as perpetual curate; here the children developed their literary talents.

After the death of their mother on 15 September 1821 from cancer, when Emily was three years old, the older sisters Maria, Elizabeth and Charlotte were sent to the Clergy Daughters' School at Cowan Bridge, where they encountered abuse and privations later described by Charlotte in "Jane Eyre". At the age of six on 25 November 1824, Emily joined her sisters at school for a brief period. When a typhoid epidemic swept the school, Maria and Elizabeth caught it. Maria, who may actually have had tuberculosis, was sent home, where she died. Emily was subsequently removed from the school, in June 1825, along with Charlotte and Elizabeth. Elizabeth died soon after their return home.

The three remaining sisters and their brother Patrick Branwell were thereafter educated at home by their father and aunt Elizabeth Branwell, their mother's sister. A shy girl, Emily was very close to her siblings and was known as a great animal lover, being especially noted for befriending the stray dogs she found wandering around the countryside. Despite the lack of formal education, Emily and her siblings had access to a wide range of published material; favourites included Sir Walter Scott, Byron, Shelley, and "Blackwood's Magazine".

In their leisure time the children began to write fiction at home, inspired by a box of toy soldiers Branwell had received as a gift and created a number of fantasy worlds (including 'Angria') which featured in stories they wrote – all "very strange ones" according to Charlotte – and enacted about the imaginary adventures of their toy soldiers along with the Duke of Wellington and his sons, Charles and Arthur Wellesley. Little of Emily's work from this period survives, except for poems spoken by characters.
When Emily was 13, she and Anne withdrew from participation in the Angria story and began a new one about Gondal, a fictional island whose myths and legends were to preoccupy the two sisters throughout their lives. With the exception of their Gondal poems and Anne's lists of Gondal's characters and place-names, the writings on Gondal were not preserved. Some "diary papers" of Emily's have survived in which she describes current events in Gondal, some of which were written, others enacted with Anne. One dates from 1841, when Emily was twenty-three: another from 1845, when she was twenty-seven. The heroes of Gondal resemble the popular image of the Highlanders of Scotland as a sort of British version of the "noble savage", being romantic outlaws who were capable of more romanticism, nobility, passion and bravery than those from "civilization". One of the fictional works produced by the Brontë siblings was Branwell's "The Life of Alexander Percy", which tells the story of how he and his wife have such a complete love and understanding for one another that eventually their love becomes self-destructive. Her brother's story was to become the inspiration for "Wuthering Heights".

At seventeen, Emily attended the Roe Head Girls' School, where Charlotte was a teacher but managed to stay only a few months before being overcome by extreme homesickness. Charlotte later stated that: "Liberty was the breath of Emily's nostrils; without it she perished. The change from her own home to a school and from her own very noiseless, very secluded but unrestricted and unartificial mode of life, to one of disciplined routine (though under the kindest auspices), was what she failed in enduring... I felt in my heart she would die, if she did not go home, and with this conviction obtained her recall." She returned home and Anne took her place. At this time, the girls' objective was to obtain sufficient education to open a small school of their own.

Emily became a teacher at Law Hill School in Halifax beginning in September 1838, when she was twenty. Her health broke under the stress of the 17-hour work day and she returned home in April 1839. Thereafter she became the stay-at-home daughter, doing most of the cooking, ironing, and cleaning. She taught herself German out of books and also practised the piano.

In 1842, Emily accompanied Charlotte to the Héger Pensionnat in Brussels, Belgium, where they attended the girls' academy run by Constantin Héger. Unlike Charlotte, Emily felt uncomfortable in Brussels, and refused to adopt Belgian fashions, saying "I wish to be as God made me", which made her into something of an outcast. The sisters planned to perfect their French and German in anticipation of opening their school. Nine of Emily's French essays survive from this period. Héger seems to have been impressed with the strength of Emily's character, and made the following assertion:

The two sisters were committed to their studies and by the end of the term had attained such competence in French that Madame Héger made a proposal for both to stay another half-year, even offering to dismiss the English master, according to Charlotte, so that she could take his place, while Emily was to teach music as she had by that time become a competent piano teacher. However, the illness and death of their aunt meant that they returned to Haworth. Although in 1844 they did try to open a school at their home, they were unable to attract students to the remote area. 

In 1844, Emily began going through all the poems she had written, recopying them neatly into two notebooks. One was labelled "Gondal Poems"; the other was unlabelled. Scholars such as Fannie Ratchford and Derek Roper have attempted to piece together a Gondal storyline and chronology from these poems.
In the autumn of 1845, Charlotte discovered the notebooks and insisted that the poems be published. Emily, furious at the invasion of her privacy, at first refused, but relented when Anne brought out her own manuscripts and revealed to Charlotte that she had been writing poems in secret as well. As co-authors of Gondal stories, Anne and Emily were accustomed to read their Gondal stories and poems to each other, while Charlotte was excluded from their privacy. Around this time she had written one of her most famous poems "No coward soul is mine", probably as an answer to the violation of her privacy and her own transformation into a published writer. Despite Charlotte's later claim, it was not her last poem.

In 1846, the sisters' poems were published in one volume as "Poems by Currer, Ellis, and Acton Bell". The Brontë sisters had adopted pseudonyms for publication, preserving their initials: Charlotte was "Currer Bell", Emily was "Ellis Bell" and Anne was "Acton Bell". Charlotte wrote in the 'Biographical Notice of Ellis and Acton Bell' that their "ambiguous choice" was "dictated by a sort of conscientious scruple at assuming Christian names positively masculine, while we did not like to declare ourselves women, because... we had a vague impression that authoresses are liable to be looked on with prejudice". Charlotte contributed 19 poems, and Emily and Anne each contributed 21. Although the sisters were told several months after publication that only two copies had sold, they were not discouraged (of their two readers, one was impressed enough to request their autographs). "The Athenaeum" reviewer praised Ellis Bell's work for its music and power, singling out his poems as the best: "Ellis possesses a fine, quaint spirit and an evident power of wing that may reach heights not here attempted", and "The Critic" reviewer recognised "the presence of more genius than it was supposed this utilitarian age had devoted to the loftier exercises of the intellect."

Emily Brontë remains a mysterious figure and a challenge to biographers because information about her is sparse due to her solitary and reclusive nature. Except for Ellen Nussey and Louise de Bassompierre, Emily's fellow student in Brussels, she does not seem to have made any friends outside her family. Her closest friend was her sister Anne. Together they shared their own fantasy world, Gondal, and, according to Ellen Nussey, in childhood they were "like twins", "inseparable companions" and "in the very closest sympathy which never had any interruption". In 1845 Anne took Emily to visit some of the places she had come to know and love in the five years she spent as governess. A plan to visit Scarborough fell through and instead the sisters went to York where Anne showed Emily York Minster. During the trip the sisters acted out some of their Gondal characters.

Charlotte Brontë remains the primary source of information about Emily, although as an elder sister, writing publicly about her shortly after her death, she is not a neutral witness. Stevie Davies believes that there is what might be called Charlotte's smoke-screen and argues that Emily evidently shocked her, to the point where she may even have doubted her sister's sanity. After Emily's death, Charlotte rewrote her character, history and even poems on a more acceptable (to her and the bourgeois reading public) model. Charlotte presented Emily as someone whose "natural" love of the beauties of nature had become somewhat exaggerated owing to her shy nature, making her too fond of the Yorkshire moors, and causing her to become homesick whenever she was away. According to Lucasta Miller, in her analysis of Brontë biographies, "Charlotte took on the role of Emily's first mythographer." In the "Preface" to the Second Edition of "Wuthering Heights", in 1850, Charlotte wrote:
Emily's unsociability and extremely shy nature have subsequently been reported many times. According to Norma Crandall, her "warm, human aspect" was "usually revealed only in her love of nature and of animals". In a similar description, "Literary news" (1883) states: "[Emily] loved the solemn moors, she loved all wild, free creatures and things", and critics attest that her love of the moors is manifest in "Wuthering Heights". Over the years, Emily's love of nature has been the subject of many anecdotes. A newspaper dated 31 December 1899, gives the folksy account that "with bird and beast [Emily] had the most intimate relations, and from her walks she often came with fledgling or young rabbit in hand, talking softly to it, quite sure, too, that it understood". Elizabeth Gaskell, in her biography of Charlotte, told the story of Emily's punishing her pet dog Keeper for lying "on the delicate white counterpane" that covered one of the beds in the Parsonage. According to Gaskell, she struck him with her fists till he was "half-blind" with his eyes "swelled up". This story is apocryphal, and contradicts the following account of Emily's and Keeper's relationship:

In "Queens of Literature of the Victorian Era" (1886), Eva Hope summarises Emily's character as "a peculiar mixture of timidity and Spartan-like courage", and goes on to say, "She was painfully shy, but physically she was brave to a surprising degree. She loved few persons, but those few with a passion of self-sacrificing tenderness and devotion. To other people's failings she was understanding and forgiving, but over herself she kept a continual and most austere watch, never allowing herself to deviate for one instant from what she considered her duty."

Emily Brontë has often been characterised as a devout if somewhat unorthodox Christian, a heretic and a visionary "mystic of the moors".

Emily Brontë's "Wuthering Heights" was first published in London in 1847 by Thomas Cautley Newby, appearing as the first two volumes of a three-volume set that included Anne Brontë's "Agnes Grey". The authors were printed as being Ellis and Acton Bell; Emily's real name did not appear until 1850, when it was printed on the title page of an edited commercial edition. The novel's innovative structure somewhat puzzled critics.

"Wuthering Heights"'s violence and passion led the Victorian public and many early reviewers to think that it had been written by a man. According to Juliet Gardiner, "the vivid sexual passion and power of its language and imagery impressed, bewildered and appalled reviewers." Literary critic Thomas Joudrey further contextualizes this reaction: "Expecting in the wake of Charlotte Brontë's "Jane Eyre" to be swept up in an earnest Bildungsroman, they were instead shocked and confounded by a tale of unchecked primal passions, replete with savage cruelty and outright barbarism." Even though the novel received mixed reviews when it first came out, and was often condemned for its portrayal of amoral passion, the book subsequently became an English literary classic. Emily Brontë never knew the extent of fame she achieved with her only novel, as she died a year after its publication, aged 30.

Although a letter from her publisher indicates that Emily had begun to write a second novel, the manuscript has never been found. Perhaps Emily or a member of her family eventually destroyed the manuscript, if it existed, when she was prevented by illness from completing it. It has also been suggested that, though less likely, the letter could have been intended for Anne Brontë, who was already writing "The Tenant of Wildfell Hall", her second novel.

Emily's health was probably weakened by the harsh local climate and by unsanitary conditions at home, the source of water being contaminated by runoff from the church's graveyard. Branwell died suddenly, on Sunday, September 24, 1848. At his funeral service, a week later, Emily caught a severe cold which quickly developed into inflammation of the lungs and led to tuberculosis. Though her condition worsened steadily, she rejected medical help and all offered remedies, saying that she would have "no poisoning doctor" near her. On the morning of 19 December 1848, Charlotte, fearing for her sister, wrote this:

At noon, Emily was worse; she could only whisper in gasps. With her last audible words she said to Charlotte, "If you will send for a doctor, I will see him now" but it was too late. She died that same day at about two in the afternoon. According to Mary Robinson, an early biographer of Emily, it happened while she was sitting on the sofa. However, Charlotte's letter to William Smith Williams where she mentions Emily's dog, Keeper, lying at the side of her dying-bed, makes this statement seem unlikely.

It was less than three months since Branwell's death, which led Martha Brown, a housemaid, to declare that "Miss Emily died of a broken heart for love of her brother". Emily had grown so thin that her coffin measured only 16 inches wide. The carpenter said he had never made a narrower one for an adult. She was interred in the Church of St Michael and All Angels family capsule in Haworth.


Notes
Footnotes
Bibliography




</doc>
<doc id="9813" url="https://en.wikipedia.org/wiki?curid=9813" title="Extinction event">
Extinction event

An extinction event (also known as a mass extinction or biotic crisis) is a widespread and rapid decrease in the biodiversity on Earth. Such an event is identified by a sharp change in the diversity and abundance of multicellular organisms. It occurs when the rate of extinction increases with respect to the rate of speciation. Because most diversity and biomass on Earth is microbial, and thus difficult to measure, recorded extinction events affect the easily observed, biologically complex component of the biosphere rather than the total diversity and abundance of life.

Extinction occurs at an uneven rate. Based on the fossil record, the background rate of extinctions on Earth is about two to five taxonomic families of marine animals every million years. Marine fossils are mostly used to measure extinction rates because of their superior fossil record and stratigraphic range compared to land animals.

The Great Oxygenation Event was probably the first major extinction event. Since the Cambrian explosion five further major mass extinctions have significantly exceeded the background extinction rate. The most recent and arguably best-known, the Cretaceous–Paleogene extinction event, which occurred approximately million years ago (Ma), was a large-scale mass extinction of animal and plant species in a geologically short period of time. In addition to the five major mass extinctions, there are numerous minor ones as well, and the ongoing mass extinction caused by human activity is sometimes called the sixth extinction. Mass extinctions seem to be a mainly Phanerozoic phenomenon, with extinction rates low before large complex organisms arose.

Estimates of the number of major mass extinctions in the last 540 million years range from as few as five to more than twenty. These differences stem from the threshold chosen for describing an extinction event as "major", and the data chosen to measure past diversity.

In a landmark paper published in 1982, Jack Sepkoski and David M. Raup identified five mass extinctions. They were originally identified as outliers to a general trend of decreasing extinction rates during the Phanerozoic, but as more stringent statistical tests have been applied to the accumulating data, it has been established that multicellular animal life has experienced five major and many minor mass extinctions. The "Big Five" cannot be so clearly defined, but rather appear to represent the largest (or some of the largest) of a relatively smooth continuum of extinction events.


Despite the popularization of these five events, there is no definite line separating them from other extinction events; using different methods of calculating an extinction's impact can lead to other events featuring in the top five.

The older the fossil record gets, the more difficult it is to read. This is because:

It has been suggested that the apparent variations in marine biodiversity may actually be an artifact, with abundance estimates directly related to quantity of rock available for sampling from different time periods. However, statistical analysis shows that this can only account for 50% of the observed pattern, and other evidence (such as fungal spikes) provides reassurance that most widely accepted extinction events are real. A quantification of the rock exposure of Western Europe indicates that many of the minor events for which a biological explanation has been sought are most readily explained by sampling bias.

Research completed after the seminal 1982 paper has concluded that a sixth mass extinction event is ongoing:

More recent research has indicated that the End-Capitanian extinction event likely constitutes a separate extinction event from the Permian–Triassic extinction event; if so, it would be larger than many of the "Big Five" extinction events.

This is a list of extinction events:

Mass extinctions have sometimes accelerated the evolution of life on Earth. When dominance of particular ecological niches passes from one group of organisms to another, it is rarely because the new dominant group is "superior" to the old and usually because an extinction event eliminates the old dominant group and makes way for the new one.

For example, mammaliformes ("almost mammals") and then mammals existed throughout the reign of the dinosaurs, but could not compete for the large terrestrial vertebrate niches which dinosaurs monopolized. The end-Cretaceous mass extinction removed the non-avian dinosaurs and made it possible for mammals to expand into the large terrestrial vertebrate niches. Ironically, the dinosaurs themselves had been beneficiaries of a previous mass extinction, the end-Triassic, which eliminated most of their chief rivals, the crurotarsans.

Another point of view put forward in the Escalation hypothesis predicts that species in ecological niches with more organism-to-organism conflict will be less likely to survive extinctions. This is because the very traits that keep a species numerous and viable under fairly static conditions become a burden once population levels fall among competing organisms during the dynamics of an extinction event.

Furthermore, many groups which survive mass extinctions do not recover in numbers or diversity, and many of these go into long-term decline, and these are often referred to as "Dead Clades Walking".

Darwin was firmly of the opinion that biotic interactions, such as competition for food and space—the ‘struggle for existence’—were of considerably greater importance in promoting evolution and extinction than changes in the physical environment. He expressed this in "The Origin of Species": "Species are produced and exterminated by slowly acting causes…and the most import of all causes of organic change is one which is almost independent of altered…physical conditions, namely the mutual relation of organism to organism-the improvement of one organism entailing the improvement or extermination of others".

It has been suggested variously that extinction events occurred periodically, every 26 to 30 million years, or that diversity fluctuates episodically every ~62 million years.
Various ideas attempt to explain the supposed pattern, including the presence of a hypothetical companion star to the sun, 
oscillations in the galactic plane, or passage through the Milky Way's spiral arms. However, other authors have concluded the data on marine mass extinctions do not fit with the idea that mass extinctions are periodic, or that ecosystems gradually build up to a point at which a mass extinction is inevitable. Many of the proposed correlations have been argued to be spurious.
Others have argued that there is strong evidence supporting periodicity in a variety of records,
and additional evidence in the form of coincident periodic variation in nonbiological geochemical variables.

Mass extinctions are thought to result when a long-term stress is compounded by a short term shock. Over the course of the Phanerozoic, individual taxa appear to be less likely to become extinct at any time, which may reflect more robust food webs as well as less extinction-prone species and other factors such as continental distribution.
However, even after accounting for sampling bias, there does appear to be a gradual decrease in extinction and origination rates during the Phanerozoic. This may represent the fact that groups with higher turnover rates are more likely to become extinct by chance; or it may be an artefact of taxonomy: families tend to become more speciose, therefore less prone to extinction, over time; and larger taxonomic groups (by definition) appear earlier in geological time.

It has also been suggested that the oceans have gradually become more hospitable to life over the last 500 million years, and thus less vulnerable to mass extinctions, but susceptibility to extinction at a taxonomic level does not appear to make mass extinctions more or less probable.

There is still debate about the causes of all mass extinctions. In general, large extinctions may result when a biosphere under long-term stress undergoes a short-term shock. An underlying mechanism appears to be present in the correlation of extinction and origination rates to diversity. High diversity leads to a persistent increase in extinction rate; low diversity to a persistent increase in origination rate. These presumably ecologically controlled relationships likely amplify smaller perturbations (asteroid impacts, etc.) to produce the global effects observed.

A good theory for a particular mass extinction should: (i) explain all of the losses, not just focus on a few groups (such as dinosaurs); (ii) explain why particular groups of organisms died out and why others survived; (iii) provide mechanisms which are strong enough to cause a mass extinction but not a total extinction; (iv) be based on events or processes that can be shown to have happened, not just inferred from the extinction.

It may be necessary to consider combinations of causes. For example, the marine aspect of the end-Cretaceous extinction appears to have been caused by several processes which partially overlapped in time and may have had different levels of significance in different parts of the world.

Arens and West (2006) proposed a "press / pulse" model in which mass extinctions generally require two types of cause: long-term pressure on the eco-system ("press") and a sudden catastrophe ("pulse") towards the end of the period of pressure.
Their statistical analysis of marine extinction rates throughout the Phanerozoic suggested that neither long-term pressure alone nor a catastrophe alone was sufficient to cause a significant increase in the extinction rate.

Macleod (2001) summarized the relationship between mass extinctions and events which are most often cited as causes of mass extinctions, using data from Courtillot "et al." (1996), Hallam (1992) and Grieve "et al." (1996):

The most commonly suggested causes of mass extinctions are listed below.

The formation of large igneous provinces by flood basalt events could have:
Flood basalt events occur as pulses of activity punctuated by dormant periods. As a result, they are likely to cause the climate to oscillate between cooling and warming, but with an overall trend towards warming as the carbon dioxide they emit can stay in the atmosphere for hundreds of years.

It is speculated that massive volcanism caused or contributed to the End-Permian, End-Triassic and End-Cretaceous extinctions. The correlation between gigantic volcanic events expressed in the large igneous provinces and mass extinctions was shown for the last 260 Myr. Recently such possible correlation was extended for the whole Phanerozoic Eon.

These are often clearly marked by worldwide sequences of contemporaneous sediments which show all or part of a transition from sea-bed to tidal zone to beach to dry land – and where there is no evidence that the rocks in the relevant areas were raised by geological processes such as orogeny. Sea-level falls could reduce the continental shelf area (the most productive part of the oceans) sufficiently to cause a marine mass extinction, and could disrupt weather patterns enough to cause extinctions on land. But sea-level falls are very probably the result of other events, such as sustained global cooling or the sinking of the mid-ocean ridges.

Sea-level falls are associated with most of the mass extinctions, including all of the "Big Five"—End-Ordovician, Late Devonian, End-Permian, End-Triassic, and End-Cretaceous.

A study, published in the journal Nature (online June 15, 2008) established a relationship between the speed of mass extinction events and changes in sea level and sediment. The study suggests changes in ocean environments related to sea level exert a driving influence on rates of extinction, and generally determine the composition of life in the oceans.

The impact of a sufficiently large asteroid or comet could have caused food chains to collapse both on land and at sea by producing dust and particulate aerosols and thus inhibiting photosynthesis. Impacts on sulfur-rich rocks could have emitted sulfur oxides precipitating as poisonous acid rain, contributing further to the collapse of food chains. Such impacts could also have caused megatsunamis and/or global forest fires.

Most paleontologists now agree that an asteroid did hit the Earth about 66 Ma ago, but there is an ongoing dispute whether the impact was the sole cause of the Cretaceous–Paleogene extinction event.

Sustained and significant global cooling could kill many polar and temperate species and force others to migrate towards the equator; reduce the area available for tropical species; often make the Earth's climate more arid on average, mainly by locking up more of the planet's water in ice and snow. The glaciation cycles of the current ice age are believed to have had only a very mild impact on biodiversity, so the mere existence of a significant cooling is not sufficient on its own to explain a mass extinction.

It has been suggested that global cooling caused or contributed to the End-Ordovician, Permian–Triassic, Late Devonian extinctions, and possibly others. Sustained global cooling is distinguished from the temporary climatic effects of flood basalt events or impacts.

This would have the opposite effects: expand the area available for tropical species; kill temperate species or force them to migrate towards the poles; possibly cause severe extinctions of polar species; often make the Earth's climate wetter on average, mainly by melting ice and snow and thus increasing the volume of the water cycle. It might also cause anoxic events in the oceans (see below).

Global warming as a cause of mass extinction is supported by several recent studies.

The most dramatic example of sustained warming is the Paleocene–Eocene Thermal Maximum, which was associated with one of the smaller mass extinctions. It has also been suggested to have caused the Triassic–Jurassic extinction event, during which 20% of all marine families became extinct. Furthermore, the Permian–Triassic extinction event has been suggested to have been caused by warming.

Clathrates are composites in which a lattice of one substance forms a cage around another. Methane clathrates (in which water molecules are the cage) form on continental shelves. These clathrates are likely to break up rapidly and release the methane if the temperature rises quickly or the pressure on them drops quickly—for example in response to sudden global warming or a sudden drop in sea level or even earthquakes. Methane is a much more powerful greenhouse gas than carbon dioxide, so a methane eruption ("clathrate gun") could cause rapid global warming or make it much more severe if the eruption was itself caused by global warming.

The most likely signature of such a methane eruption would be a sudden decrease in the ratio of carbon-13 to carbon-12 in sediments, since methane clathrates are low in carbon-13; but the change would have to be very large, as other events can also reduce the percentage of carbon-13.

It has been suggested that "clathrate gun" methane eruptions were involved in the end-Permian extinction ("the Great Dying") and in the Paleocene–Eocene Thermal Maximum, which was associated with one of the smaller mass extinctions.

Anoxic events are situations in which the middle and even the upper layers of the ocean become deficient or totally lacking in oxygen. Their causes are complex and controversial, but all known instances are associated with severe and sustained global warming, mostly caused by sustained massive volcanism.

It has been suggested that anoxic events caused or contributed to the Ordovician–Silurian, late Devonian, Permian–Triassic and Triassic–Jurassic extinctions, as well as a number of lesser extinctions (such as the Ireviken, Mulde, Lau, Toarcian and Cenomanian–Turonian events). On the other hand, there are widespread black shale beds from the mid-Cretaceous which indicate anoxic events but are not associated with mass extinctions.

The bio-availability of essential trace elements (in particular selenium) to potentially lethal lows has been shown to coincide with, and likely have contributed to, at least three mass extinction events in the oceans, i.e. at the end of the Ordovician, during the Middle and Late Devonian, and at the end of the Triassic. During periods of low oxygen concentrations very soluble selenate (Se) is converted into much less soluble selenide (Se), elemental Se and organo-selenium complexes. Bio-availability of selenium during these extinction events dropped to about 1% of the current oceanic concentration, a level that has been proven lethal to many extant organisms.

Kump, Pavlov and Arthur (2005) have proposed that during the Permian–Triassic extinction event the warming also upset the oceanic balance between photosynthesising plankton and deep-water sulfate-reducing bacteria, causing massive emissions of hydrogen sulfide which poisoned life on both land and sea and severely weakened the ozone layer, exposing much of the life that still remained to fatal levels of UV radiation.

Oceanic overturn is a disruption of thermo-haline circulation which lets surface water (which is more saline than deep water because of evaporation) sink straight down, bringing anoxic deep water to the surface and therefore killing most of the oxygen-breathing organisms which inhabit the surface and middle depths. It may occur either at the beginning or the end of a glaciation, although an overturn at the start of a glaciation is more dangerous because the preceding warm period will have created a larger volume of anoxic water.

Unlike other oceanic catastrophes such as regressions (sea-level falls) and anoxic events, overturns do not leave easily identified "signatures" in rocks and are theoretical consequences of researchers' conclusions about other climatic and marine events.

It has been suggested that oceanic overturn caused or contributed to the late Devonian and Permian–Triassic extinctions.

A nearby gamma-ray burst (less than 6000 light-years away) would be powerful enough to destroy the Earth's ozone layer, leaving organisms vulnerable to ultraviolet radiation from the Sun. Gamma ray bursts are fairly rare, occurring only a few times in a given galaxy per million years.
It has been suggested that a supernova or gamma ray burst caused the End-Ordovician extinction.

One theory is that periods of increased geomagnetic reversals will weaken Earth's magnetic field long enough to expose the atmosphere to the solar winds, causing oxygen ions to escape the atmosphere in a rate increased by 3–4 orders, resulting in a disastrous decrease in oxygen.

Movement of the continents into some configurations can cause or contribute to extinctions in several ways: by initiating or ending ice ages; by changing ocean and wind currents and thus altering climate; by opening seaways or land bridges which expose previously isolated species to competition for which they are poorly adapted (for example, the extinction of most of South America's native ungulates and all of its large metatherians after the creation of a land bridge between North and South America). Occasionally continental drift creates a super-continent which includes the vast majority of Earth's land area, which in addition to the effects listed above is likely to reduce the total area of continental shelf (the most species-rich part of the ocean) and produce a vast, arid continental interior which may have extreme seasonal variations.

Another theory is that the creation of the super-continent Pangaea contributed to the End-Permian mass extinction. Pangaea was almost fully formed at the transition from mid-Permian to late-Permian, and the "Marine genus diversity" diagram at the top of this article shows a level of extinction starting at that time which might have qualified for inclusion in the "Big Five" if it were not overshadowed by the "Great Dying" at the end of the Permian.

Many other hypotheses have been proposed, such as the spread of a new disease, or simple out-competition following an especially successful biological innovation. But all have been rejected, usually for one of the following reasons: they require events or processes for which there is no evidence; they assume mechanisms which are contrary to the available evidence; they are based on other theories which have been rejected or superseded.

Scientists have been concerned that human activities could cause more plants and animals to become extinct than any point in the past. Along with human-made changes in climate (see above), some of these extinctions could be caused by overhunting, overfishing, invasive species, or habitat loss. A study published in May 2017 in "Proceedings of the National Academy of Sciences" argued that a “biological annihilation” akin to a sixth mass extinction event is underway as a result of anthropogenic causes, such as over-population and over-consumption. The study suggested that as much as 50% of the number of animal individuals that once lived on Earth were already extinct, threatening the basis for human existence too.

The eventual warming and expanding of the Sun, combined with the eventual decline of atmospheric carbon dioxide could actually cause an even greater mass extinction, having the potential to wipe out even microbes, where rising global temperatures caused by the expanding Sun will gradually increase the rate of weathering, which in turn removes more and more carbon dioxide from the atmosphere. When carbon dioxide levels get too low (perhaps at 50 ppm), all plant life will die out, although simpler plants like grasses and mosses can survive much longer, until levels drop to 10 ppm.

With all photosynthetic organisms gone, atmospheric oxygen can no longer be replenished, and is eventually removed by chemical reactions in the atmosphere, perhaps from volcanic eruptions. Eventually the loss of oxygen will cause all remaining aerobic life to die out via asphyxiation, leaving behind only simple anaerobic prokaryotes. When the Sun becomes 10% brighter in about a billion years, Earth will suffer a moist greenhouse effect resulting in its oceans boiling away, while the Earth's liquid outer core cools due to the inner core's expansion and causes the Earth's magnetic field to shut down. In the absence of a magnetic field, charged particles from the Sun will deplete the atmosphere and further increase the Earth's temperature to an average of ~420 K (147 °C, 296 °F) in 2.8 billion years, causing the last remaining life on Earth to die out. This is the most extreme instance of a climate-caused extinction event. Since this will only happen late in the Sun's life, such will cause the final mass extinction in Earth's history (albeit a very long extinction event).

The impact of mass extinction events varied widely. After a major extinction event, usually only weedy species survive due to their ability to live in diverse habitats. Later, species diversify and occupy empty niches. Generally, biodiversity recovers 5 to 10 million years after the extinction event. In the most severe mass extinctions it may take 15 to 30 million years.

The worst event, the Permian–Triassic extinction, devastated life on earth, killing over 90% of species. Life seemed to recover quickly after the P-T extinction, but this was mostly in the form of disaster taxa, such as the hardy "Lystrosaurus". The most recent research indicates that the specialized animals that formed complex ecosystems, with high biodiversity, complex food webs and a variety of niches, took much longer to recover. It is thought that this long recovery was due to successive waves of extinction which inhibited recovery, as well as prolonged environmental stress which continued into the Early Triassic. Recent research indicates that recovery did not begin until the start of the mid-Triassic, 4M to 6M years after the extinction; and some writers estimate that the recovery was not complete until 30M years after the P-T extinction, i.e. in the late Triassic. Subsequent to the P-T extinction, there was an increase in provincialization, with species occupying smaller ranges – perhaps removing incumbents from niches and setting the stage for an eventual rediversification.

The effects of mass extinctions on plants are somewhat harder to quantify, given the biases inherent in the plant fossil record. Some mass extinctions (such as the end-Permian) were equally catastrophic for plants, whereas others, such as the end-Devonian, did not affect the flora.



</doc>
<doc id="9814" url="https://en.wikipedia.org/wiki?curid=9814" title="E. E. Smith">
E. E. Smith

Edward Elmer Smith (also E. E. Smith, E. E. Smith, Ph.D., E. E. "Doc" Smith, Doc Smith, "Skylark" Smith, or—to his family—Ted; May 2, 1890 – August 31, 1965) was an American food engineer (specializing in doughnut and pastry mixes) and an early science-fiction author, best known for the "Lensman" and "Skylark" series. He is sometimes called the father of space opera.

Edward Elmer Smith was born in Sheboygan, Wisconsin on May 2, 1890, to Fred Jay Smith and Caroline Mills Smith, both staunch Presbyterians of British ancestry. His mother was a teacher born in Michigan in February 1855; his father was a sailor, born in Maine in January 1855 to an English father. They moved to Spokane, Washington, the winter after Edward Elmer was born, where Mr. Smith was working as a contractor in 1900. In 1902, the family moved to Seneaquoteen, near the Pend Oreille River, in Kootenai County, Idaho. He had four siblings, Rachel M. born September 1882, Daniel M. born January 1884, Mary Elizabeth born February 1886 (all of whom were born in Michigan), and Walter E. born July 1891 in Washington. In 1910, Fred and Caroline Smith and their son Walter were living in the Markham Precinct of Bonner County, Idaho; Fred is listed in census records as a farmer.

Smith worked primarily as a manual laborer until he injured his wrist, at the age of 19, while escaping from a fire. He attended the University of Idaho. (Many years later he would be installed in the 1984 Class of the University of Idaho Alumni Hall of Fame.) He entered its prep school in 1907, and graduated with two degrees in chemical engineering in 1914. He was president of the Chemistry Club, the Chess Club, and the Mandolin and Guitar Club, and captain of the Drill and Rifle Team; he also sang the bass lead in Gilbert and Sullivan operettas. His undergraduate thesis was "Some Clays of Idaho", co-written with classmate Chester Fowler Smith, who died in California of tuberculosis the following year, after taking a teaching fellowship at Berkeley. Whether the two were related is not known.

On October 5, 1915, in Boise, Idaho he married Jeanne Craig MacDougall, the sister of his college roommate, Allen Scott (Scotty) MacDougall. (Her sister was named Clarissa MacLean MacDougall; the heroine of the "Lensman" novels would later be named Clarissa MacDougall.) Jeanne MacDougall was born in Glasgow, Scotland; her parents were Donald Scott MacDougall, a violinist, and Jessica Craig MacLean. Her father had moved to Boise when the children were young, and later sent for his family; he died while they were en route in 1905. Jeanne's mother, who remarried businessman and retired politician John F. Kessler in 1914 worked at, and later owned, a boarding house on Ridenbaugh Street.

The Smiths had three children:

After college, Smith was a junior chemist for the National Bureau of Standards in Washington, D.C., developing standards for butter and for oysters. He may have served as a lieutenant in the U.S. Army during World War I, but details are unknown. His draft card, partly illegible, seems to show that Smith requested exemption from military service, based on his wife's dependence and on his contribution to the war effort as a civilian chemist.

One evening in 1915, the Smiths were visiting a former classmate from the University of Idaho, Dr. Carl Garby, who had also moved to Washington, D.C. He lived nearby in the Seaton Place Apartments with his wife, Lee Hawkins Garby. A long discussion about journeys into outer space ensued, and it was suggested that Smith should write down his ideas and speculations as a story about interstellar travel. Although he was interested, Smith believed that some thought that some romantic elements would be required and he was uncomfortable with that.

Mrs. Garby offered to take care of the love interest and the romantic dialogue, and Smith decided to give it a try. The sources of inspirations for the main characters in the novel were themselves; the "Seatons" and "Cranes" were based on the Smiths and Garbys, respectively. About one-third of "The Skylark of Space" was completed by the end of 1916, when Smith and Garby gradually abandoned work on it.

Smith earned his master's degree in chemistry from the George Washington University in 1917, studying under Dr. Charles E. Munroe. Smith completed his PhD in chemical engineering in 1918, with a food engineering focus; his dissertation, "The effect of bleaching with oxides of nitrogen upon the baking quality and commercial value of wheat flour", was published in 1919. (Warner and Fleischer give the title "The Effect of the Oxides of Nitrogen upon the Carotin Molecule – C40H56", which is difficult to explain. Sam Moskowitz gives the degree date 1919, perhaps reflecting different dates for thesis submission, thesis defense, and degree certification.)

In 1919, Smith was hired as chief chemist for F. W. Stock & Sons of Hillsdale, Michigan, at one time the largest family-owned mill east of the Mississippi, working on doughnut mixes.

One evening late in 1919, after moving to Michigan, Smith was baby-sitting (presumably for Roderick) while his wife attended a movie; he resumed work on "The Skylark of Space", finishing it in the spring of 1920. He submitted it to many book publishers and magazines, spending more in postage than he would eventually receive for its publication. Bob Davis, editor of "Argosy", sent an encouraging rejection letter in 1922, saying that he liked the novel personally, but that it was too far out for his readers. (According to Warner, but no other source, Smith began work on the sequel, "Skylark III", before the first book was accepted.) Finally, upon seeing the April 1927 issue of "Amazing Stories", he submitted it to that magazine; it was accepted, initially for $75, later raised to $125. It was published as a three-part serial in the August to October 1928 issues and it was such a success that managing editor Sloane requested a sequel before the second installment had been published.

Mrs. Garby was not interested in further collaboration, so Smith began work on "Skylark Three" alone. It was published as another three-part serial, in the August to October 1930 issues of "Amazing", introduced as the cover story for August. (In 1930, the Smiths were living in Michigan, at 33 Rippon Avenue in Hillsdale.) This was as far as he had planned to take the "Skylark" series; it was praised in "Amazing"s letter column, and he was paid ¾¢ per word, surpassing "Amazing"s previous record of half a cent.

Smith then began work on what he intended as a new series, starting with "Spacehounds of IPC," which he finished in the autumn of 1930. In this novel, he took pains to avoid the scientific impossibilities which had bothered some readers of the "Skylark" novels. Even in 1938, after he had written "Galactic Patrol", Smith considered it his finest work; he later said of it, "This was really scientific fiction; not, like the Skylarks, pseudo-science"; and even at the end of his career, he considered it his only work of true science fiction. It was published in the July through September 1931 issues of "Amazing," with Sloane making unauthorized changes. Fan letters in the magazine complained about the novel's containment within the solar system, and Sloane sided with the readers. So when Harry Bates, editor of "Astounding Stories", offered Smith 2¢/word—payable on publication—for his next story, he agreed; this meant that it could not be a sequel to "Spacehounds."

This book would be "Triplanetary", "in which scientific detail would not be bothered about, and in which his imagination would run riot." Indeed, characters within the story point out its psychological and scientific implausibilities, and sometimes even seem to suggest self-parody. At other times, they are conspicuously silent about obvious implausibilities. The January 1933 issue of "Astounding" announced that "Triplanetary" would appear in the March issue, and that issue's cover illustrated a scene from the story, but "Astounding"s financial difficulties prevented the story from appearing. Smith then submitted the manuscript to "Wonder Stories", whose new editor, 17-year-old Charles D. Hornig, rejected it, later boasting about the rejection in a fanzine. He finally submitted it to "Amazing", which published it beginning in January 1934, but for only half a cent a word. Shortly after it was accepted, F. Orlin Tremaine, the new editor of the revived "Astounding", offered one cent a word for "Triplanetary"; when he learned that he was too late, he suggested a third "Skylark" novel instead.

In the winter of 1933–34, Smith worked on "The Skylark of Valeron", but he felt that the story was getting out of control; he sent his first draft to Tremaine, with a distraught note asking for suggestions. Tremaine accepted the rough draft for $850, and announced it in the June 1934 issue, with a full-page editorial and a three-quarter-page advertisement. The novel was published in the August 1934 through February 1935 issues. "Astounding"s circulation rose by 10,000 for the first issue, and its two main competitors, "Amazing" and "Wonder Stories", fell into financial difficulties, both skipping issues within a year.

In January 1936, a time period where he was already an established science-fiction writer, he took a job for salary plus profit-sharing, as a food technologist (a cereal chemist) at the Dawn Doughnut Company of Jackson, Michigan. This initially entailed almost a year's worth of 18-hour days and seven-day workweeks. Individuals who knew Smith confirmed that he had a role in developing mixes for doughnuts and other pastries, but the contention that he developed the first process for making powdered sugar adhere to doughnuts cannot be substantiated. Smith was reportedly dislocated from his job at Dawn Doughnuts by prewar rationing in early 1940.

Smith had been contemplating writing a "space-police novel" since early 1927; once he had "the Lensmen's universe fairly well set up", he reviewed his science-fiction collection for "cops-and-robbers" stories. He cites Clinton Constantinescue's "War of the Universe" as a negative example, and Starzl and Williamson as positive ones. Tremaine responded extremely positively to a brief description of the idea.

Once Dawn Doughnuts became profitable in late 1936, Smith wrote an 85-page outline for what became the four core "Lensman" novels; in early 1937, Tremaine committed to buying them. Segmenting the story into four novels required considerable effort to avoid dangling loose ends; Smith cites Edgar Rice Burroughs as a negative example. After the outline was complete, he wrote a more detailed outline of "Galactic Patrol", plus a detailed graph of its structure, with "peaks of emotional intensity and the valleys of characterization and background material." He notes, however, that he was never able to follow any of his outlines at all closely, as the "characters get away from me and do exactly as they damn please." After completing the rough draft of "Galactic Patrol", he wrote the concluding chapter of the last book in the series, "Children of the Lens." "Galactic Patrol" was published in the September 1937 through February 1938 issues of "Astounding"; unlike the revised book edition, it was not set in the same universe as "Triplanetary".

"Gray Lensman", the fourth book in the series, appeared in "Astounding"s October 1939 through January 1940 issues. (Note that the frequent British spelling "grey" is simply a recurrent mistake, starting with the cover of the first installment; Moskowitz's usage, ""The Grey Lensman"," is even harder to justify.) "Gray Lensman" (and its cover illustration) was extremely well received. Campbell's editorial in the December issue suggested that the October issue was the best issue of "Astounding" ever, and "Gray Lensman" was first place in the Analytical Laboratory statistics "by a lightyear", with three runners-up in a distant tie for second place. The cover was also praised by readers in "Brass Tacks", and Campbell noted, "We got a letter from E. E. Smith saying he and Hubert Rogers agreed on how Kinnison looked."

Smith was the guest of honor at Chicon I, the second World Science Fiction Convention, held in Chicago over Labor Day weekend 1940, giving a speech on the importance of science fiction fandom entitled "What Does This Convention Mean?" He attended the convention's masquerade as C. L. Moore's Northwest Smith, and met fans living near him in Michigan, who would later form the Galactic Roamers, which previewed and advised him on his future work.

Smith worked for the US Army between 1941 and 1945. An extended segment in the novel version of "Triplanetary", set during World War II, suggests intimate familiarity with explosives and munitions manufacturing. Some biographers cite as fact that, just as Smith's protagonist in this segment lost his job over failure to approve substandard munitions, Smith did, as well. Smith began work for the J. W. Allen Company (a manufacturer of doughnut and frosting mixes) in 1946 and worked for them until his professional retirement in 1957.

After Smith retired, his wife and he lived in Clearwater, Florida, in the fall and winter, driving the smaller of their two trailers to Seaside, Oregon, each April, often stopping at science fiction conventions on the way. (Smith did not like to fly.) In 1963, he was presented the inaugural First Fandom Hall of Fame award at the 21st World Science Fiction Convention in Washington, D.C. Some of his biography is captured in an essay by Robert A. Heinlein, which was reprinted in the collection "Expanded Universe" in 1980. A more detailed, although allegedly error-ridden biography is in Sam Moskowitz's "Seekers of Tomorrow."

Robert Heinlein and Smith were friends. (Heinlein dedicated his 1958 novel "Methuselah's Children" "To Edward E. Smith, PhD".) Heinlein reported that E. E. Smith perhaps took his "unrealistic" heroes from life, citing as an example the extreme competence of the hero of "Spacehounds of IPC". He reported that E. E. Smith was a large, blond, athletic, very intelligent, very gallant man, married to a remarkably beautiful, intelligent, red-haired woman named MacDougal (thus perhaps the prototypes of 'Kimball Kinnison' and 'Clarissa MacDougal'). In Heinlein's essay, he reports that he began to suspect Smith might be a sort of "superman" when he asked Smith for help in purchasing a car. Smith tested the car by driving it on a back road at illegally high speeds with their heads pressed tightly against the roof columns to listen for chassis squeaks by bone conduction—a process apparently improvised on the spot.

In his nonseries novels written after his professional retirement, "Galaxy Primes", "Subspace Explorers", and "Subspace Encounter", E. E. Smith explores themes of telepathy and other mental abilities collectively called "psionics", and of the conflict between libertarian and socialistic/communistic influences in the colonization of other planets. "Galaxy Primes" was written after critics such as Groff Conklin and P. Schuyler Miller in the early '50s accused his fiction of being passé, and he made an attempt to do something more in line with the concepts about which " Astounding" editor John W. Campbell encouraged his writers to make stories. Despite this, it was rejected by Campbell, and it was eventually published by "Amazing Stories" in 1959. His late story "The Imperial Stars" (1964), featuring a troupe of circus performers involved in sabotage in a galactic empire, recaptured some of the atmosphere from his earlier works and was intended as the first in a new series, with outlines of later parts rumored to still exist.

The fourth "Skylark" novel, "Skylark DuQuesne", ran in the June to October 1965 issues of "If", beginning once again as the cover story. Editor Frederik Pohl introduced it with a one-page summary of the previous stories, which were all at least 30 years old.

Smith published two novelettes entitled "Tedric" in "Other Worlds Science Fiction Stories" (1953) and "Lord Tedric" in "Universe Science Fiction" (1954). These were almost completely forgotten until after Smith's death. In 1975, a compendium of Smith's works was published, entitled "The Best of E. E. "Doc" Smith", containing these two short stories, excerpts from several of his major works, and another short story first published in "Worlds of If" in 1964 entitled "The Imperial Stars".

In Smith's original short stories, Tedric was a smith (both blacksmith and whitesmith) residing in a small town near a castle in a situation roughly equivalent to England of the 1200s. He received instruction in advanced metallurgy from a time-traveler who wanted to change the situation in his own time by modifying certain events of the past. From this instruction, he was able to build better suits of armor and help defeat the villains of the piece. Unlike Eklund's later novels based on these short stories, the original Tedric never left his own time or planet, and fought purely local enemies of his own time period.

A few years later and 13 years after Smith's death, Verna Smith arranged with Gordon Eklund to publish another novel of the same name about the same fictional character, introducing it as "a new series conceived by E. E. 'Doc' Smith". Eklund later went on to publish the other novels in the series, one or two under the pseudonym "E. E. 'Doc' Smith" or "E. E. Smith". The protagonist possesses heroic qualities similar to those of the heroes in Smith's original novels and can communicate with an extra-dimensional race of beings known as the Scientists, whose archenemy is Fra Villion, a mysterious character described as a dark knight, skilled in whip-sword combat, and evil genius behind the creation of a planetoid-sized "iron sphere" armed with a weapon capable of destroying planets. As a result, Smith is believed by many to be the unacknowledged progenitor of themes that would appear in "Star Wars". In fact, however, these appear in the sequels written by others after Smith's death.

Smith's novels are generally considered to be classic space operas, and he is sometimes called the first of the three "novas" of 20th-century science fiction (with Stanley G. Weinbaum and Robert A. Heinlein as the second and third novas).

Heinlein credited him for being his main influence: "I have learned from many writers—from Verne and Wells and Campbell and Sinclair Lewis, et al.—but I have learned more from you than from any of the others and perhaps more than for all the others put together …"

Smith expressed a preference for inventing fictional technologies that were not strictly impossible (so far as the science of the day was aware) but highly unlikely: "the more highly improbable a concept is—short of being contrary to mathematics whose fundamental operations involve no neglect of infinitesimals—the better I like it" was his phrase.

"Lensman" was one of five finalists when the 1966 World Science Fiction Convention judged the Isaac Asimov's "Foundation" the Best All-Time Series.

The Science Fiction and Fantasy Hall of Fame inducted Smith in 2004.

"Vortex Blasters" (also known as "Masters of the Vortex") is set in the same universe as the "Lensman" novels. It is an extension to the main storyline which takes place between "Galactic Patrol" and "Children of the Lens", and introduces a different type of psionics from that used by the Lensmen. "Spacehounds of IPC" is not a part of the series, despite occasional erroneous statements to the contrary. (It is listed as a novel in the series in some paperback editions of the 1970s.)

Robert A. Heinlein reported that Smith had planned a seventh "Lensman" novel, set after the events described in "Children of the Lens", which was unpublishable at that time (the early 1960s). Smith told Heinlein that the new novel proceeded inexorably from matters left unresolved in "Children", a statement easily supported by a careful reading of "Children". Careful searches by people who knew Smith well (including Frederik Pohl, Smith's editor, and Verna Smith Trestrail, Smith's daughter) have failed to locate any material related to such a story. Smith apparently never wrote any of it down.

On July 14, 1965, barely a month before his death, Smith gave written permission to William B. Ellern to continue the "Lensman" series, which led to the publishing of "Moon Prospector" in 1965 and "New Lensman" in 1976. Smith's long-time friend, Dave Kyle, wrote three authorized added novels in the "Lensman" series that provided background about the major nonhuman Lensmen: "Dragon Lensman", "Lensman from Rigel", and "Z-Lensman".

Smith was widely read by scientists and engineers from the 1930s into the 1970s. Literary precursors of ideas which arguably entered the military-scientific complex include SDI ("Triplanetary"), stealth ("Gray Lensman"), the OODA Loop, C3-based warfare, and the AWACS ("Gray Lensman").

An inarguable influence was described in a June 11, 1947, letter to Doc from John W. Campbell (the editor of "Astounding", where much of the "Lensman" series was originally published). In it, Campbell relayed Captain Cal Laning's acknowledgment that he had used Smith's ideas for displaying the battlespace situation (called the "tank" in the stories) in the design of the United States Navy's ships' Combat Information Centers. "The entire set-up was taken specifically, directly, and consciously from the "Directrix". In your story, you reached the situation the Navy was in—more communication channels than integration techniques to handle it. You proposed such an integrating technique and proved how advantageous it could be. You, sir, were 100% right. As the Japanese Navy—not the hypothetical Boskonian fleet—learned at an appalling cost."

One underlying theme of the later "Lensman" novels was the difficulty in maintaining military secrecy—as advanced capabilities are revealed, the opposing side can often duplicate them. This point was also discussed extensively by John Campbell in his letter to Doc. Also in the later "Lensman" novels, and particular after the "Battle of Klovia" broke the Boskonian's power base at the end of "Second Stage Lensmen", the Boskonian forces and particularly Kandron of Onlo reverted to terroristic tactics to attempt to demoralize Civilization, thus providing an early literary glimpse into this modern problem of both law enforcement and military response. The use of "Vee-two" gas by the pirates attacking the "Hyperion" in "Triplanetary" (in both magazine and book appearances) also suggests anticipation of the terrorist uses of poison gases. (But note that Smith lived through WW I, when the use of poison gas on troops was well known to the populace; extending the assumption that pirates might use it if they could obtain it was no great extension of the present-day knowledge.)

The beginning of the story "Skylark of Space" describes in relative detail the protagonist's research into separation of platinum group residues, subsequent experiments involving electrolysis, and the discovery of a process evocative of cold fusion (over 50 years before Stanley Pons and Martin Fleischmann). He describes a nuclear process yielding large amounts of energy and producing only negligible radioactive waste—which then goes on to form the basis of the adventures in the Skylark books. Smith's general description of the process of discovery is highly evocative of Röntgen's descriptions of his discovery of the X-ray.

Another theme of the "Skylark" novels involves precursors of modern information technology. The humanoid aliens encountered in the first novel have developed a primitive technology called the "mechanical educator", which allows direct conversion of brain waves into intelligible thought for transmission to others or for electrical storage. By the third novel in the series, "Skylark of Valeron", this technology has grown into an "Electronic Brain" which is capable of computation on all "bands" of energy—electromagnetism, gravity, and "tachyonic" energy and radiation bands included. This is itself derived from a discussion of reductionist atomic theory in the second novel, "Skylark Three", which brings to mind modern quark and sub-quark theories of elementary particle physics.

In his 1947 essay "The Epic of Space", Smith listed (by last name only) authors he enjoyed reading: John W. Campbell, L. Sprague de Camp, Robert A. Heinlein, Murray Leinster, H. P. Lovecraft, and A. Merritt (specifically "The Ship of Ishtar", "The Moon Pool", "The Snake Mother", and "Dwellers in the Mirage", as well as the character John Kenton), C. L. Moore (specifically "Jirel of Joiry"), Roman Frederick Starzl, John Taine, A. E. van Vogt, Stanley G. Weinbaum (specifically "Tweerl"), and Jack Williamson. In a passage on his preparation for writing the "Lensman" novels, he notes that Clinton Constantinescu's "War of the Universe" was not a masterpiece, but says that Starzl and Williamson were masters; this suggests that Starzl's Interplanetary Flying Patrol may have been an influence on Smith's Triplanetary Patrol, later the "Galactic Patrol". The feeding of the Overlords of Delgon upon the life-force of their victims at the end of chapter five of "Galactic Patrol" seems a clear allusion to chapter 29 of "The Moon Pool", Merritt's account of the Taithu and the power of love in chapters 29 and 34 also bear some resemblance to the end of "Children of the Lens." Smith also mentions Edgar Rice Burroughs, complaining about loose ends at the end of one of his novels.

Smith acknowledges the help of the Galactic Roamers writers' workshop, plus E. Everett Evans, Ed Counts, an unnamed aeronautical engineer, Dr. James Enright, and Dr. Richard W. Dodson. Smith's daughter, Verna, lists the following authors as visitors to the Smith household in her youth: Lloyd Arthur Eshbach, Heinlein, Dave Kyle, Bob Tucker, Williamson, Pohl, Merritt, and the Galactic Roamers. Smith cites Bigelow's "Theoretical Chemistry–Fundamentals" as a justification for the possibility of the inertialess drive. Also, an extended reference is made to Rudyard Kipling's "Ballad of Boh Da Thone” in "Gray Lensman" (chapter 22, "Regeneration", in a conversation between Kinnison and MacDougall).

Sam Moskowitz's biographical essay on Smith in "Seekers of Tomorrow" states that he regularly read "Argosy" magazine, and everything by H.G. Wells, Jules Verne, H. Rider Haggard, Edgar Allan Poe, and Edgar Rice Burroughs. Moskowitz also notes that Smith's "reading enthusiasms included poetry, philosophy, ancient and medieval history, and all of English literature". (Smith's grandson notes that he spoke, and sang, German.) The influence of these is not readily apparent, except in the Roman section of "Triplanetary", and in the impeccable but convoluted grammar of Smith's narration. Some influence of 19th-century philosophy of language may be detectable in the account in "Galactic Patrol" of the Lens of Arisia as a universal translator, which is reminiscent of Frege's strong realism about "Sinn", that is, thought or sense.

Both Moskowitz and Smith's daughter Verna Smith Trestrail report that Smith had a troubled relationship with John Campbell, the editor of "Astounding". Smith's most successful works were published under Campbell, but the degree of influence is uncertain. The original outline for the "Lensman" series had been accepted by F. Orlin Tremaine, and Smith angered Campbell by showing loyalty to Tremaine at his new magazine, "Comet", when he sold him "The Vortex Blaster" in 1941. Campbell's announcement of "Children of the Lens", in 1947, was less than enthusiastic. Campbell later said that he published it only reluctantly, though he praised it privately, and bought little from Smith thereafter.


Doc himself appears as a character in the 2006 novel "The Chinatown Death Cloud Peril" by Paul Malmont. The novel describes friendship and rivalry among pulp writers of the 1930s. He also appears as "Lensman Ted Smith" in the 1980 novel "The Number of the Beast" and as "Commander Ted Smith" in the 1985 novel "The Cat Who Walks Through Walls", both by Robert A. Heinlein. It is also suggested that he was one of the inspirations for Heinlein's character Lazarus Long.

Because he died in 1965, the works of E. E. Smith are now public domain in countries where the term of copyright lasts 50 years after the death of the author, or less; generally this does not include works first published posthumously. Works first published before 1923, are also public domain in the United States. Additionally, a number of the author's works have become public domain in the United States due to non-renewal of copyright.






</doc>
<doc id="9815" url="https://en.wikipedia.org/wiki?curid=9815" title="Évariste Galois">
Évariste Galois

Évariste Galois (; ; 25 October 1811 – 31 May 1832) was a French mathematician. While still in his teens, he was able to determine a necessary and sufficient condition for a polynomial to be solvable by radicals, thereby solving a problem standing for 350 years. His work laid the foundations for Galois theory and group theory, two major branches of abstract algebra, and the subfield of Galois connections. He died at age 20 from wounds suffered in a duel.

Galois was born on 25 October 1811 to Nicolas-Gabriel Galois and Adélaïde-Marie (born Demante). His father was a Republican and was head of Bourg-la-Reine's liberal party. His father became mayor of the village after Louis XVIII returned to the throne in 1814. His mother, the daughter of a jurist, was a fluent reader of Latin and classical literature and was responsible for her son's education for his first twelve years. At the age of 10, Galois was offered a place at the college of Reims, but his mother preferred to keep him at home.
In October 1823, he entered the Lycée Louis-le-Grand, and despite some turmoil in the school at the beginning of the term (when about a hundred students were expelled), Galois managed to perform well for the first two years, obtaining the first prize in Latin. He soon became bored with his studies and, at the age of 14, he began to take a serious interest in mathematics.

He found a copy of Adrien-Marie Legendre's "Éléments de Géométrie", which, it is said, he read "like a novel" and mastered at the first reading. At 15, he was reading the original papers of Joseph-Louis Lagrange, such as the "Réflexions sur la résolution algébrique des équations" which likely motivated his later work on equation theory, and "Leçons sur le calcul des fonctions", work intended for professional mathematicians, yet his classwork remained uninspired, and his teachers accused him of "affecting" ambition and originality in a negative way.

In 1828, he attempted the entrance examination for the École Polytechnique, the most prestigious institution for mathematics in France at the time, without the usual preparation in mathematics, and failed for lack of explanations on the oral examination. In that same year, he entered the École Normale (then known as l'École préparatoire), a far inferior institution for mathematical studies at that time, where he found some professors sympathetic to him.
In the following year Galois' first paper, on continued fractions, was published. It was at around the same time that he began making fundamental discoveries in the theory of polynomial equations. He submitted two papers on this topic to the Academy of Sciences. Augustin-Louis Cauchy refereed these papers, but refused to accept them for publication for reasons that still remain unclear. However, in spite of many claims to the contrary, it is widely held that Cauchy recognized the importance of Galois' work, and that he merely suggested combining the two papers into one in order to enter it in the competition for the Academy's Grand Prize in Mathematics. Cauchy, an eminent mathematician of the time, though with political views that were at the opposite end from Galois', considered Galois' work to be a likely winner.

On 28 July 1829, Galois' father committed suicide after a bitter political dispute with the village priest. A couple of days later, Galois made his second and last attempt to enter the Polytechnique, and failed yet again. It is undisputed that Galois was more than qualified; however, accounts differ on why he failed. More plausible accounts state that Galois made too many logical leaps and baffled the incompetent examiner, which enraged Galois. The recent death of his father may have also influenced his behavior.

Having been denied admission to the Polytechnique, Galois took the Baccalaureate examinations in order to enter the École Normale. He passed, receiving his degree on 29 December 1829. His examiner in mathematics reported, "This pupil is sometimes obscure in expressing his ideas, but he is intelligent and shows a remarkable spirit of research."

He submitted his memoir on equation theory several times, but it was never published in his lifetime due to various events. Though his first attempt was refused by Cauchy, in February 1830 following Cauchy's suggestion he submitted it to the Academy's secretary Joseph Fourier, to be considered for the Grand Prix of the Academy. Unfortunately, Fourier died soon after, and the memoir was lost. The prize would be awarded that year to Niels Henrik Abel posthumously and also to Carl Gustav Jacob Jacobi. Despite the lost memoir, Galois published three papers that year, one of which laid the foundations for Galois theory. The second one was about the numerical resolution of equations (root finding in modern terminology). The third was an important one in number theory, in which the concept of a finite field was first articulated.

Galois lived during a time of political turmoil in France. Charles X had succeeded Louis XVIII in 1824, but in 1827 his party suffered a major electoral setback and by 1830 the opposition liberal party became the majority. Charles, faced with abdication, staged a coup d'état, and issued his notorious July Ordinances, touching off the July Revolution which ended with Louis-Philippe becoming king. While their counterparts at the Polytechnique were making history in the streets during "les Trois Glorieuses", Galois and all the other students at the École Normale were locked in by the school's director. Galois was incensed and wrote a blistering letter criticizing the director, which he submitted to the "Gazette des Écoles", signing the letter with his full name. Although the "Gazette"'s editor omitted the signature for publication, Galois was expelled.

Although his expulsion would have formally taken effect on 4 January 1831, Galois quit school immediately and joined the staunchly Republican artillery unit of the National Guard. He divided his time between his mathematical work and his political affiliations. Due to controversy surrounding the unit, soon after Galois became a member, on 31 December 1830, the artillery of the National Guard was disbanded out of fear that they might destabilize the government. At around the same time, nineteen officers of Galois' former unit were arrested and charged with conspiracy to overthrow the government.

In April 1831, the officers were acquitted of all charges, and on 9 May 1831, a banquet was held in their honor, with many illustrious people present, such as Alexandre Dumas. The proceedings grew riotous, and Galois proposed a toast to King Louis Philippe with a dagger above his cup, which was interpreted as a threat against the king's life. He was arrested the following day but was acquitted on 15 June 1831.

On the following Bastille Day (14 July 1831), Galois was at the head of a protest, wearing the uniform of the disbanded artillery, and came heavily armed with several pistols, a rifle, and a dagger. He was again arrested. On 23 October he was sentenced to six months in prison for illegally wearing a uniform. He was released on 29 April 1832. During his imprisonment, he continued developing his mathematical ideas.

Galois returned to mathematics after his expulsion from the École Normale, although he continued to spend time in political activities. After his expulsion became official in January 1831, he attempted to start a private class in advanced algebra which attracted some interest, but this waned, as it seemed that his political activism had priority. Siméon Poisson asked him to submit his work on the theory of equations, which he did on 17 January 1831. Around 4 July 1831, Poisson declared Galois' work "incomprehensible", declaring that "[Galois'] argument is neither sufficiently clear nor sufficiently developed to allow us to judge its rigor"; however, the rejection report ends on an encouraging note: "We would then suggest that the author should publish the whole of his work in order to form a definitive opinion." While Poisson's report was made before Galois' July 14 arrest, it took until October to reach Galois in prison. It is unsurprising, in the light of his character and situation at the time, that Galois reacted violently to the rejection letter, and decided to abandon publishing his papers through the Academy and instead publish them privately through his friend Auguste Chevalier. Apparently, however, Galois did not ignore Poisson's advice, as he began collecting all his mathematical manuscripts while still in prison, and continued polishing his ideas until his release on 29 April 1832, after which he was somehow talked into a duel.

Galois' fatal duel took place on 30 May. The true motives behind the duel are obscure. There has been much speculation as to the reasons behind it. What is known is that five days before his death, he wrote a letter to Chevalier which clearly alludes to a broken love affair.

Some archival investigation on the original letters suggests that the woman of romantic interest was a Mademoiselle Stéphanie-Félicie Poterin du Motel, the daughter of the physician at the hostel where Galois stayed during the last months of his life. Fragments of letters from her, copied by Galois himself (with many portions, such as her name, either obliterated or deliberately omitted), are available. The letters hint that Mlle. du Motel had confided some of her troubles to Galois, and this might have prompted him to provoke the duel himself on her behalf. This conjecture is also supported by other letters Galois later wrote to his friends the night before he died. Galois' cousin, Gabriel Demante, when asked if he knew the cause of the duel, mentioned that Galois "found himself in the presence of a supposed uncle and a supposed fiancé, each of whom provoked the duel." Galois himself famously exclaimed: "I am the victim of an infamous coquette and her two dupes."

Much more detailed speculation based on these scant historical details has been interpolated by many of Galois' biographers (most notably by Eric Temple Bell in "Men of Mathematics"), such as the frequently repeated speculation that the entire incident was stage-managed by the police and royalist factions to eliminate a political enemy.

As to his opponent in the duel, Alexandre Dumas names Pescheux d'Herbinville, who was actually one of the nineteen artillery officers whose acquittal was celebrated at the banquet that occasioned Galois' first arrest. However, Dumas is alone in this assertion, and if he were correct it is unclear why d'Herbinville would have been involved. It has been speculated that he might have been du Motel's "supposed fiancé" at the time (she ultimately married someone else), but no clear evidence has been found supporting this conjecture. On the other hand, extant newspaper clippings from only a few days after the duel give a description of his opponent (identified by the initials "L.D.") that appear to more accurately apply to one of Galois' Republican friends, most probably Ernest Duchatelet, who was imprisoned with Galois on the same charges. Given the conflicting information available, the true identity of his killer may well be lost to history.

Whatever the reasons behind the duel, Galois was so convinced of his impending death that he stayed up all night writing letters to his Republican friends and composing what would become his mathematical testament, the famous letter to Auguste Chevalier outlining his ideas, and three attached manuscripts. Mathematician Hermann Weyl said of this testament, "This letter, if judged by the novelty and profundity of ideas it contains, is perhaps the most substantial piece of writing in the whole literature of mankind." However, the legend of Galois pouring his mathematical thoughts onto paper the night before he died seems to have been exaggerated. In these final papers, he outlined the rough edges of some work he had been doing in analysis and annotated a copy of the manuscript submitted to the Academy and other papers.
Early in the morning of 30 May 1832, he was shot in the abdomen, abandoned by his opponents and seconds, and was found by a passing farmer. He died the following morning at ten o'clock in the Hôpital Cochin (probably of peritonitis), after refusing the offices of a priest. His funeral ended in riots. There were plans to initiate an uprising during his funeral, but during the same time frame the leaders heard of General Jean Maximilien Lamarque's death, and the rising was postponed without any uprising occurring until 5 June. Only Galois' younger brother was notified of the events prior to Galois' death. He was 20 years old. His last words to his younger brother Alfred were:
On 2 June, Évariste Galois was buried in a common grave of the Montparnasse Cemetery whose exact location is unknown. In the cemetery of his native town – Bourg-la-Reine – a cenotaph in his honour was erected beside the graves of his relatives.

Galois' mathematical contributions were published in full in 1843 when Liouville reviewed his manuscript and declared it sound. It was finally published in the October–November 1846 issue of the "Journal de Mathématiques Pures et Appliquées". The most famous contribution of this manuscript was a novel proof that there is no quintic formula – that is, that fifth and higher degree equations are not generally solvable by radicals. Although Abel had already proved the impossibility of a "quintic formula" by radicals in 1824 and Ruffini had published a solution in 1799 that turned out to be flawed, Galois' methods led to deeper research in what is now called Galois theory. For example, one can use it to determine, for "any" polynomial equation, whether it has a solution by radicals.

From the closing lines of a letter from Galois to his friend Auguste Chevalier, dated May 29, 1832, two days before Galois' death:

Within the 60 or so pages of Galois' collected works are many important ideas that have had far-reaching consequences for nearly all branches of mathematics. His work has been compared to that of Niels Henrik Abel, another mathematician who died at a very young age, and much of their work had significant overlap.

While many mathematicians before Galois gave consideration to what are now known as groups, it was Galois who was the first to use the word "group" (in French "groupe") in a sense close to the technical sense that is understood today, making him among the founders of the branch of algebra known as group theory. He developed the concept that is today known as a normal subgroup. He called the decomposition of a group into its left and right cosets a "proper decomposition" if the left and right cosets coincide, which is what today is known as a normal subgroup. He also introduced the concept of a finite field (also known as a Galois field in his honor), in essentially the same form as it is understood today.

In his last letter to Chevalier and attached manuscripts, the second of three, he made basic studies of linear groups over finite fields:

Galois' most significant contribution to mathematics is his development of Galois theory. He realized that the algebraic solution to a polynomial equation is related to the structure of a group of permutations associated with the roots of the polynomial, the Galois group of the polynomial. He found that an equation could be solved in radicals if one can find a series of subgroups of its Galois group, each one normal in its successor with abelian quotient, or its Galois group is solvable. This proved to be a fertile approach, which later mathematicians adapted to many other fields of mathematics besides the theory of equations to which Galois originally applied it.

Galois also made some contributions to the theory of Abelian integrals and continued fractions.

As written in his last letter, Galois passed from the study of elliptic functions to consideration of the integrals of the most general algebraic differentials, today called Abelian integrals. He classified these integrals into three categories.

In his first paper in 1828, Galois proved that the regular continued fraction which represents a quadratic surd ζ is purely periodic if and only if ζ is a reduced surd, that is, formula_1 and its conjugate formula_2
satisfies formula_3.

In fact, Galois showed more than this. He also proved that if ζ is a reduced quadratic surd and η is its conjugate, then the continued fractions for ζ and for (−1/η) are both purely periodic, and the repeating block in one of those continued fractions is the mirror image of the repeating block in the other. In symbols we have

where ζ is any reduced quadratic surd, and η is its conjugate.

From these two theorems of Galois a result already known to Lagrange can be deduced. If "r" > 1 is a rational number that is not a perfect square, then

In particular, if "n" is any non-square positive integer, the regular continued fraction expansion of √"n" contains a repeating block of length "m", in which the first "m" − 1 partial denominators form a palindromic string.





</doc>
<doc id="9820" url="https://en.wikipedia.org/wiki?curid=9820" title="Ennius">
Ennius

Quintus Ennius (; c. 239 – c. 169 BC) was a writer and poet who lived during the Roman Republic. He is often considered the father of Roman poetry. He was born in Rudiae, formerly a small town located near modern Lecce in the heel of Italy (ancient Calabria, today Salento), and could speak Oscan as well as Latin and Greek. Although only fragments of his works survive, his influence in Latin literature was significant, particularly in his use of Greek literary models.

Very little is reliably known about the life of Ennius. His contemporaries hardly mentioned him and much that is related about him could have been embroidered from references to himself in his now fragmentary writings. Some lines of the "Annales", as well as ancient testimonies, for example, suggest that Ennius opened his epic with a recollection of a dream in which the ancient epic-writer Homer informed him that his spirit had been reborn into Ennius. It is true that the doctrine of the transmigration of souls once flourished in the areas of Italy settled by Greeks, but the statement might have been no more than a literary flourish. Ennius seems to have been given to making large claims, as in the report by Maurus Servius Honoratus that he claimed descent from Messapus, the legendary king of his native district. The partly Hellenised city of Rudiae, his place of birth, was certainly in the area settled by the Messapians. And this, he used to say, according to Aulus Gellius, had endowed him with a triple linguistic and cultural heritage, fancifully described as "three hearts… Greek, Oscan and Latin”.

The public career of Ennius first really emerges in middle life, when he was serving in the army with the rank of centurion during the Second Punic War. While in Sardinia in the year 204 BC, he is said to have attracted the attention of Cato the Elder and was taken by him to Rome. There he taught Greek and adapted Greek plays for a livelihood, and by his poetical compositions gained the friendship of some of the greatest men in Rome whose achievements he praised. Amongst these were Scipio Africanus and Fulvius Nobilior, whom he accompanied on his Aetolian campaign (189). Afterwards he made the capture of Ambracia, at which he was present, the subject of a play and of an episode in the "Annales". It was through the influence of Nobilior's son Quintus that Ennius subsequently obtained Roman citizenship. But he himself lived plainly and simply in the literary quarter on the Aventine Hill with the poet Caecilius Statius, a fellow adapter of Greek plays. 

At about the age of 70 Ennius died, immediately after producing his tragedy "Thyestes". In the last book of his epic poem, in which he seems to have given various details of his personal history, he mentioned that he was in his 67th year at the date of its composition. He compared himself, in contemplation of the close of the great work of his life, to a gallant horse which, after having often won the prize at the Olympic Games, obtained his rest when weary with age. A similar feeling of pride at the completion of a great career is expressed in the memorial lines which he composed to be placed under his bust after death: “Let no one weep for me, or celebrate my funeral with mourning; for I still live, as I pass to and fro through the mouths of men.”

Ennius continued the nascent literary tradition by writing plays in Greek and Roman style (praetextae and palliatae), as well as his most famous work, a historic epic in hexameters called the "Annales". Other minor works include the "Epicharmus", the "Euhemerus", the "Hedyphagetica", and "Saturae".

The "Epicharmus" presented an account of the gods and the physical operations of the universe. In it, the poet dreamed he had been transported after death to some place of heavenly enlightenment.

The "Euhemerus" presented a theological doctrine of a vastly different type in a mock-simple prose style modelled on the Greek of Euhemerus of Messene and several other theological writers. According to this doctrine, the gods of Olympus were not supernatural powers still actively intervening in the affairs of men, but great generals, statesmen and inventors of olden times commemorated after death in extraordinary ways.

The "Hedyphagetica" took much of its substance from the gastronomical epic of Archestratus of Gela. The eleven extant hexameters have prosodical features avoided in the more serious "Annales".

The remains of six books of "Saturae" show a considerable variety of metres. There are signs that Ennius varied the metre sometimes even within a composition. A frequent theme was the social life of Ennius himself and his upper-class Roman friends and their intellectual conversation.

The "Annales" was an epic poem in fifteen books, later expanded to eighteen, covering Roman history from the fall of Troy in 1184 BC down to the censorship of Cato the Elder in 184 BC. It was the first Latin poem to adopt the dactylic hexameter metre used in Greek epic and didactic poetry, leading it to become the standard metre for these genres in Latin poetry. The "Annals" became a school text for Roman schoolchildren, eventually supplanted by Virgil's "Aeneid". About 600 lines survive. A copy of the work is among the Latin rolls of the Herculaneum library.






</doc>
<doc id="9822" url="https://en.wikipedia.org/wiki?curid=9822" title="Electronic">
Electronic

Electronic may refer to:





</doc>
<doc id="9823" url="https://en.wikipedia.org/wiki?curid=9823" title="Eris (mythology)">
Eris (mythology)

Eris (; , "Strife") is the Greek goddess of strife and discord. Her name is the equivalent of Latin Discordia, which means "discord". Eris' Greek opposite is Harmonia, whose Latin counterpart is Concordia. Homer equated her with the war-goddess Enyo, whose Roman counterpart is Bellona. The dwarf planet Eris is named after the goddess.

"Eris" is of uncertain etymology; connections with the verb ὀρίνειν "orinein", "to raise, stir, excite," and the proper name Ἐρινύες "Erinyes" have been suggested. R. S. P. Beekes rejects these derivations and suggested a Pre-Greek origin.

In Hesiod's "Works and Days" 11–24, two different goddesses named Eris are distinguished:

<poem>So, after all, there was not one kind of Strife alone, but all over the earth there are two. As for the one, a man would praise her when he came to understand her; but the other is blameworthy: and they are wholly different in nature. For one fosters evil war and battle, being cruel: her no man loves; but perforce, through the will of the deathless gods, men pay harsh Strife her honour due.

But the other is the elder daughter of dark Night (Nyx), and the son of Cronus who sits above and dwells in the aether, set her in the roots of the earth: and she is far kinder to men. She stirs up even the shiftless to toil; for a man grows eager to work when he considers his neighbour, a rich man who hastens to plough and plant and put his house in good order; and neighbour vies with his neighbour as he hurries after wealth. This Strife is wholesome for men. And potter is angry with potter, and craftsman with craftsman and beggar is jealous of beggar, and minstrel of minstrel.</poem>

In Hesiod's "Theogony" (226–232), Strife, the daughter of Night, is less kindly spoken of as she brings forth other personifications as her children:

The other Strife is presumably she who appears in Homer's "Iliad" Book IV; equated with Enyo as sister of Ares and so presumably daughter of Zeus and Hera:

Strife whose wrath is relentless, she is the sister and companion of murderous Ares, she who is only a little thing at the first, but thereafter grows until she strides on the earth with her head striking heaven. She then hurled down bitterness equally between both sides as she walked through the onslaught making men's pain heavier. She also has a son whom she named Strife.

Enyo is mentioned in Book 5, and Zeus sends Strife to rouse the Achaeans in Book 11, of the same work.

The most famous tale of Eris recounts her initiating the Trojan War by causing the Judgement of Paris. The goddesses Hera, Athena and Aphrodite had been invited along with the rest of Olympus to the forced wedding of Peleus and Thetis, who would become the parents of Achilles, but Eris had been snubbed because of her troublemaking inclinations.

She therefore (as mentioned at the "Kypria" according to Proclus as part of a plan hatched by Zeus and Themis) tossed into the party the Apple of Discord, a golden apple inscribed  – "For the most beautiful one", or "To the Fairest One" – provoking the goddesses to begin quarreling about the appropriate recipient. The hapless Paris, Prince of Troy, was appointed to select the fairest by Zeus. The goddesses stripped naked to try to win Paris' decision, and also attempted to bribe him. Hera offered political power; Athena promised infinite wisdom; and Aphrodite tempted him with the most beautiful woman in the world: Helen, wife of Menelaus of Sparta. While Greek culture placed a greater emphasis on prowess and power, Paris chose to award the apple to Aphrodite, thereby dooming his city, which was destroyed in the war that ensued.

In Nonnus' "Dionysiaca", 2.356, when Typhon prepares to battle with Zeus:

Eris ("Strife") was Typhon's escort in the melée, Nike ("Victory") led Zeus to battle.

Another story of Eris includes Hera, and the love of Polytekhnos and Aedon. They claimed to love each other more than Hera and Zeus were in love. This angered Hera, so she sent Eris to rack discord upon them. Polytekhnos was finishing off a chariot board, and Aedon a web she had been weaving. Eris said to them, "Whosoever finishes thine task last shall have to present the other with a female servant!" Aedon won. But Polytekhnos was not happy by his defeat, so he came to Khelidon, Aedon's sister, and raped her. He then disguised her as a slave, presenting her to Aedon. When Aedon discovered this was indeed her sister, she chopped up Polytekhnos' son and fed him to Polytekhnos. The gods were not pleased, so they turned them all into birds.

Eris has been adopted as the patron deity of the modern Discordian religion, which was begun in the late 1950s by Gregory Hill and Kerry Wendell Thornley under the pen names of "Malaclypse the Younger" and "Omar Khayyam Ravenhurst". The Discordian version of Eris is considerably lighter in comparison to the rather malevolent Graeco-Roman original, wherein she is depicted as a positive (albeit mischievous) force of chaotic creation.

A quote from the "Principia Discordia", the first holy book of Discordianism, attempts to clear up the matter:

The story of Eris being snubbed and indirectly starting the Trojan War is recorded in the "Principia", and is referred to as the Original Snub. The "Principia Discordia" states that her parents may be as described in Greek legend, or that she may be the daughter of Void. She is the Goddess of Disorder and Being, whereas her sister Aneris (called the equivalent of Harmonia by the Mythics of Harmonia) is the goddess of Order and Non-Being. Their brother is Spirituality.

Discordian Eris is looked upon as a foil to the preoccupation of western philosophy in attempting find order in the chaos of reality, in prescribing order to be synonymous with truth. Discordian Eris teaches us that the only truth is chaos, and that order and disorder are simply temporary filters applied to the lenses we view the chaos through. This is known as the Aneristic Illusion.

In this telling, Eris becomes something of a patron saint of chaotic creation:

The concept of Eris as developed by the "Principia Discordia" is used and expanded upon in the science fiction work "The Illuminatus! Trilogy" by Robert Shea and Robert Anton Wilson (in which characters from "Principia Discordia" appear). In this work, Eris is a major character.

The classic fairy tale "Sleeping Beauty" is partly inspired by Eris' role in the wedding of Peleus and Thetis. Like Eris, a malevolent fairy curses a princess after not being invited to the princess' christening.




</doc>
<doc id="9824" url="https://en.wikipedia.org/wiki?curid=9824" title="Edna St. Vincent Millay">
Edna St. Vincent Millay

Edna St. Vincent Millay (February 22, 1892 – October 19, 1950) was an American poet and playwright. She received the Pulitzer Prize for Poetry in 1923, the third woman to win the award for poetry, and was also known for her feminist activism. She used the pseudonym Nancy Boyd for her prose work. The poet Richard Wilbur asserted, "She wrote some of the best sonnets of the century."

Millay was born in Rockland, Maine, to Cora Lounella Buzelle, a nurse, and Henry Tolman Millay, a schoolteacher who would later become a superintendent of schools. Her middle name derives from St. Vincent's Hospital in New York, where her uncle's life had been saved just before her birth. The family's house was "between the mountains and the sea where baskets of apples and drying herbs on the porch mingled their scents with those of the neighboring pine woods." In 1904, Cora officially divorced Millay's father for financial irresponsibility, but they had already been separated for some years. Cora and her three daughters, Edna (who called herself "Vincent"), Norma Lounella (born 1893), and Kathleen Kalloch (born 1896), moved from town to town, living in poverty. Cora travelled with a trunk full of classic literature, including Shakespeare and Milton, which she read to her children. The family settled in a small house on the property of Cora's aunt in Camden, Maine, where Millay would write the first of the poems that would bring her literary fame.

The three sisters were independent and spoke their minds, which did not always sit well with the authority figures in their lives. Millay's grade school principal, offended by her frank attitudes, refused to call her Vincent. Instead, he called her by any woman's name that started with a V. At Camden High School, Millay began developing her literary talents, starting at the school's literary magazine, "The Megunticook". At 14 she won the St. Nicholas Gold Badge for poetry, and by 15, she had published her poetry in the popular children's magazine "St. Nicholas", the "Camden Herald", and the high-profile anthology "Current Literature". While at school, she had several relationships with women, including Edith Wynne Matthison, who would go on to become an actress in silent films.

Millay entered Vassar College in 1913 when she was 21 years old, later than usual. She had relationships with several fellow students during her time there and kept scrapbooks including drafts of plays written during the period.

After her graduation from Vassar in 1917, Millay moved to New York City. She lived in a number of places in Greenwich Village, including a house owned by the Cherry Lane Theatre and 75½ Bedford Street, renowned for being the narrowest in New York City. The critic Floyd Dell wrote that the red-haired and beautiful Millay was "a frivolous young woman, with a brand-new pair of dancing slippers and a mouth like a valentine." Millay described her life in New York as "very, very poor and very, very merry." While establishing her career as a poet, Millay initially worked with the Provincetown Players on Macdougal Street and the Theatre Guild. In 1924 Millay and others founded the Cherry Lane Theater "to continue the staging of experimental drama." Magazine articles under a pseudonym also helped support her early days in the village.

Counted among Millay's close friends were the writers Witter Bynner, Arthur Davison Ficke, and Susan Glaspell, as well as Floyd Dell and the critic Edmund Wilson, both of whom proposed marriage to her and were refused.

Millay's fame began in 1912 when she entered her poem "Renascence" in a poetry contest in "The Lyric Year". The poem was widely considered the best submission and when it was ultimately awarded fourth place, it created a scandal which brought Millay publicity. The first-place winner Orrick Johns was among those who felt that "Renascence" was the best poem, and stated that "the award was as much an embarrassment to me as a triumph". A second-prize winner offered Millay his $250 prize money. In the immediate aftermath of the "Lyric Year" controversy, wealthy arts patron Caroline B. Dow heard Millay reciting her poetry and playing the piano at the Whitehall Inn in Camden, Maine, and was so impressed that she offered to pay for Millay's education at Vassar College.

Her 1920 collection "A Few Figs From Thistles" drew controversy for its exploration of female sexuality and feminism. In 1919 she wrote the anti-war play "Aria da Capo" which starred her sister Norma Millay at the Provincetown Playhouse in New York City. Millay won the Pulitzer Prize for Poetry in 1923 for "The Ballad of the Harp-Weaver"; she was the third woman to win the poetry prize, after Sara Teasdale (1918) and Margaret Widdemer (1919).

In January 1921, she went to Paris, where she met and befriended the sculptor Thelma Wood.
In 1923 she married 43-year-old Eugen Jan Boissevain (1880–1949), the widower of the labor lawyer and war correspondent Inez Milholland, a political icon Millay had met during her time at Vassar. A self-proclaimed feminist, Boissevain supported her career and took primary care of domestic responsibilities. Both Millay and Boissevain had other lovers throughout their twenty-six-year marriage. For Millay, a significant such relationship was with the poet George Dillon. She met Dillon at one of her readings at the University of Chicago in 1928 where he was a student. He was fourteen years her junior, and the relationship inspired the sonnets in the collection "Fatal Interview" (published 1931).

In 1925, Boissevain and Millay bought Steepletop near Austerlitz, New York, which had been a blueberry farm. The couple built a barn (from a Sears Roebuck kit), and then a writing cabin and a tennis court. Millay grew her own vegetables in a small garden. The couple later bought Ragged Island in Casco Bay, Maine, as a summer retreat. The couple often had trouble with servants, with Millay writing, "The only people I really hate are servants. They are not really human beings at all." 

During the first world war Millay had been a dedicated and active pacifist; however, from 1940 she supported the Allied Forces, writing in celebration of the war effort and later working with Writers' War Board to create propaganda, including poetry. Her reputation in poetry circles was damaged by her war work. Merle Rubin noted: "She seems to have caught more flak from the literary critics for supporting democracy than Ezra Pound did for championing fascism." In "The New York Times Magazine", Millay mourned the Czechoslovak city of Lidice, the site of a Nazi massacre:

<poem>The whole world holds in its arms today
The murdered village of Lidice, 
Like the murdered body of a little child.</poem>

This article would serve as the basis her 32 page poem, Murder of Lidice in 1942 and loosely served as the basis of the 1943 MGM movie Hitler's Madman. Douglas Sirk directed the movie. Harper and Brothers published the poem in 1942. 

In 1943 Millay was the sixth person and the second woman to be awarded the Frost Medal for her lifetime contribution to American poetry.

Boissevain died in 1949 of lung cancer, and Millay lived alone for the last year of her life.

Millay died at her home on October 19, 1950. She had fallen down stairs and was found approximately eight hours after her death. Her physician reported that she had suffered a heart attack following a coronary occlusion. She was 58 years old. She is buried alongside her husband at Millay Colony for the Arts, Austerlitz, New York.

Millay's sister Norma and her husband, the painter and actor Charles Frederick Ellis, moved to Steepletop after Millay's death. In 1973, they established Millay Colony for the Arts on the seven acres around the house and barn. After the death of her husband in 1976, Norma continued to run the program until her death in 1986.
At 17, the poet Mary Oliver visited Steepletop and became a close friend of Norma. Oliver eventually lived there for seven years and helped to organize Millay's papers. Mary Oliver herself went on to become a Pulitzer Prize-winning poet, greatly inspired by Millay's work. In 2006, the state of New York paid $1.69 million to acquire of Steepletop, with the intention to add the land to a nearby state forest preserve. The proceeds of the sale were to be used by the Edna St. Vincent Millay Society to restore the farmhouse and grounds and turn it into a museum. The museum has been open to the public since summer 2010, and guided tours of Steepletop and Millay's gardens are available from the end of May through the middle of October. Parts of the grounds of Steepletop, including the Millay Poetry Trail that leads to her grave, are now open to the public year-round.

Details of Millay's life were compiled by biographer Nancy Milford in the book titled "Savage Beauty: The Life of Edna St Vincent Millay", published in 2001. Milford was sought out by Millay's only living connection at the time, her sister Norma Millay Ellis, and was chosen for her previous, successful biography "Zelda". Milford would then go on to edit and write an introduction for a collection of Millay's poems called "The Selected Poetry of Edna St. Vincent Millay."

In 2015, she was named by Equality Forum as one of their 31 Icons of the 2015 LGBT History Month.

Millay wrote five verse dramas early in her career, including "Two Slatterns and a King" and "The Lamp and the Bell", a poem written for Vassar College about love between women. She was commissioned by the Metropolitan Opera House to write a libretto for an opera composed by Deems Taylor. The result, "The King's Henchman", drew on the "Anglo-Saxon Chronicle's" account of Eadgar, King of Wessex, and was described as the most effectively and artistically wrought American opera ever to reach the stage. Within three weeks, her publishers had run through four editions of the book.

Her pacifist verse drama "Aria da Capo", a one-act play written for the Provincetown Players, is often anthologized. It aired live as an episode of "Academy Theatre" in 1949 on NBC.

"" (1922) is an homage to the geometry of Euclid. "Renascence" and "The Ballad of the Harp-Weaver" are often considered her finest poems. On her death, "The New York Times" described her as "an idol of the younger generation during the glorious early days of Greenwich Village [...] One of the greatest American poets of her time." Thomas Hardy said that America had two great attractions: the skyscraper and the poetry of Edna St. Vincent Millay.

The following comprises works published during her lifetime:






</doc>
<doc id="9825" url="https://en.wikipedia.org/wiki?curid=9825" title="Enlightenment">
Enlightenment

Enlightenment, enlighten or enlightened may refer to:







</doc>
<doc id="9827" url="https://en.wikipedia.org/wiki?curid=9827" title="Ethnocentrism">
Ethnocentrism

Ethnocentrism is judging another culture solely by the values and standards of one's own culture. Ethnocentric individuals judge other groups relative to their own ethnic group or culture, especially with concern for language, behavior, customs, and religion. These ethnic distinctions and subdivisions serve to define each ethnicity's unique cultural identity. Ethnocentrism may be overt or subtle, and while it is considered a natural proclivity of human psychology in everyday life, it has developed a generally negative connotation. In anthropology, cultural relativism is seen as an antithesis and an antonym to ethnocentrism.

The term "ethnocentrism" was coined by Ludwig Gumplowicz and subsequently employed by William G. Sumner. Gumplowicz defined ethnocentrism as the reasons by virtue of which each people believed it had always occupied the highest point not only among contemporaneous peoples and nations but also in relation to all peoples of the historical past (Der Rassenkampf, 1883). Sumner relied on observing the tendency for people to differentiate between the in-group and others, disseminating it in his 1906 work "Folkways: A Study of the Sociological Importance of Usages, Manners, Customs, Mores, and Morals." He defined it as "the technical name for the view of things in which one's own group is the center of everything, and all others are scaled and rated with reference to it." He further characterized it as often leading to pride, vanity, beliefs of one's own group's superiority, and contempt of outsiders. 

In 1996, Robert K. Merton commented that "although the practice of seeing one's own group as the center of things is empirically correlated with a belief in superiority, centrality and superiority need to be kept analytically distinct in order to deal with patterns of alienation from one's membership group and contempt for it."

Anthropologists such as Franz Boas and Bronisław Malinowski argued that any human science had to transcend the ethnocentrism of the scientist. Both urged anthropologists to conduct ethnographic fieldwork in order to overcome their ethnocentrism. Boas developed the principle of cultural relativism and Malinowski developed the theory of functionalism as guides for producing non-ethnocentric studies of different cultures. Classic examples of anti-ethnocentric anthropology include Margaret Mead's "Coming of Age in Samoa" (1928), Malinowski's "The Sexual Life of Savages in North-Western Melanesia" (1929), and Ruth Benedict's "Patterns of Culture" (1934). (Mead and Benedict were two of Boas's students.)

People born into a particular culture that grow up absorbing the values and behaviors of the culture will develop a worldview that considers their culture to be the norm. If people then experience other cultures that have different values and normal behaviors, they will find that the thought patterns appropriate to their birth culture and the meanings their birth culture attaches to behaviors are not appropriate for the new cultures. However, since people are accustomed to their birth culture, it can be difficult for them to see the behaviors of people from a different culture from the viewpoint of that culture rather than from their own.

Examples of ethnocentrism include religiocentric constructs claiming a divine association like "divine nation", "God's Own Country", "God's Chosen People", and "God's Promised Land".

In "Precarious Life", Judith Butler discusses recognizing the Other in order to sustain the Self and the problems of not being able to identify the Other. Butler writes:

A 2011 paper in PNAS suggested that ethnocentrism may be mediated by the oxytocin hormone. It found that in randomized controlled trials "oxytocin creates intergroup bias because oxytocin motivates in-group favoritism and, to a lesser extent, out-group derogation".

In "The Selfish Gene", evolutionary biologist Richard Dawkins writes that "Blood-feuds and inter-clan warfare are easily interpretable in terms of Hamilton's genetic theory." Simulation-based experiments in evolutionary game theory have attempted to provide an explanation for the selection of ethnocentric-strategy phenotypes.




</doc>
<doc id="9828" url="https://en.wikipedia.org/wiki?curid=9828" title="Execution unit">
Execution unit

In computer engineering, an execution unit (also called a functional unit) is a part of the central processing unit (CPU) that performs the operations and calculations as instructed by the computer program. It may have its own internal control sequence unit, which is not to be confused with the CPU's main control unit, some registers, and other internal units such as an arithmetic logic unit (ALU), address generation unit (AGU), floating-point unit (FPU), load-store unit (LSU), branch execution unit (BEU) or some smaller and more specific components.

It is common for modern CPUs to have multiple parallel execution units, which is referred to as superscalar design. The simplest arrangement is to use one, the bus manager, to manage the memory interface, and the others to perform calculations. Additionally, modern CPUs' execution units are usually pipelined.



</doc>
<doc id="9829" url="https://en.wikipedia.org/wiki?curid=9829" title="Eskilstuna Municipality">
Eskilstuna Municipality

Eskilstuna Municipality ("Eskilstuna kommun") is a municipality in Södermanland County in southeast Sweden, between the lakes Mälaren and Hjälmaren. Its seat is located in the city of Eskilstuna.

The present municipality was formed in 1971 when the "City of Eskilstuna", the "City of Torshälla" and five rural municipalities were amalgamated.


These are the results of the Riksdag elections of Eskilstuna Municipality since the 1972 municipality reform. The results of the Sweden Democrats were not published by SCB between 1988 and 1998 at a municipal level to the party's small nationwide size at the time. "Votes" denotes valid votes, whereas "Turnout" denotes also blank and invalid votes.

Blocs

This lists the relative strength of the socialist and centre-right blocs since 1973, but parties not elected to the Riksdag are inserted as "other", including the Sweden Democrats results from 1988 to 2006, but also the Christian Democrats pre-1991 and the Greens in 1982, 1985 and 1991. The sources are identical to the table above. The coalition or government mandate marked in bold formed the government after the election. New Democracy got elected in 1991 but are still listed as "other" due to the short lifespan of the party. "Elected" is the total number of percentage points from the municipality that went to parties who were elected to the Riksdag.

Eskilstuna is twinned with:




</doc>
<doc id="9830" url="https://en.wikipedia.org/wiki?curid=9830" title="European Convention on Human Rights">
European Convention on Human Rights

The European Convention on Human Rights (ECHR) (formally the Convention for the Protection of Human Rights and Fundamental Freedoms) is an international treaty to protect human rights and fundamental freedoms in Europe. Drafted in 1950 by the then newly formed Council of Europe, the convention entered into force on 3 September 1953. All Council of Europe member states are party to the Convention and new members are expected to ratify the convention at the earliest opportunity.

The Convention established the European Court of Human Rights (ECtHR). Any person who feels his or her rights have been violated under the Convention by a state party can take a case to the Court. Judgments finding violations are binding on the States concerned and they are obliged to execute them. The Committee of Ministers of the Council of Europe monitors the execution of judgements, particularly to ensure payment of the amounts awarded by the Court to the applicants in compensation for the damage they have sustained. The compensations imposed under ECHR can be large; in 2014 Russia was ordered to pay in excess of $2 billion in damages to former shareholders of Yukos.

The Convention has several protocols, which amend the convention framework.

The European Convention on Human Rights has played an important role in the development and awareness of Human Rights in Europe.
The development of a regional system of human rights protection operating across Europe can be seen as a direct response to twin concerns. First, in the aftermath of the Second World War, the convention, drawing on the inspiration of the Universal Declaration of Human Rights can be seen as part of a wider response of the Allied Powers in delivering a human rights agenda through which it was believed that the most serious human rights violations which had occurred during the Second World War could be avoided in the future. Second, the Convention was a response to the growth of Communism in Central and Eastern Europe and designed to protect the member states of the Council of Europe from communist subversion. This, in part, explains the constant references to values and principles that are "necessary in a democratic society" throughout the Convention, despite the fact that such principles are not in any way defined within the convention itself.

From 7 to 10 May 1948 with the attendance of politicians (such as Winston Churchill, François Mitterrand and Konrad Adenauer), civil society representatives, academics, business leaders, trade unionist and religious leader was organised gathering-The "Congress of Europe" in Hague. At the end of Congress the declaration and following pledge was issued which demonstrated the initial seeds of modern European institutes, including ECHR. The second and third Articles of Pledge stated: We desire a Charter of Human Rights guaranteeing liberty of thought, assembly and expression as well as right to form a political opposition. We desire a Court of Justice with adequate sanctions for the implementation of this Charter.

The Convention was drafted by the Council of Europe after the Second World War in response to a call issued by Europeans from all walks of life who had gathered at the Hague Congress. Over 100 parliamentarians from the twelve member states of the Council of Europe gathered in Strasbourg in the summer of 1949 for the first ever meeting of the Council's Consultative Assembly to draft a "charter of human rights" and to establish a court to enforce it. British MP and lawyer Sir David Maxwell-Fyfe, the Chair of the Assembly's Committee on Legal and Administrative Questions, was one of its leading members and guided the drafting of the Convention. As a prosecutor at the Nuremberg Trials, he had seen first-hand how international justice could be effectively applied. With his help, the French former minister and Resistance fighter Pierre-Henri Teitgen submitted a report to the Assembly proposing a list of rights to be protected, selecting a number from the Universal Declaration of Human Rights just agreed to in New York, and defining how the enforcing judicial mechanism might operate. After extensive debates, the Assembly sent its final proposal to the Council's Committee of Ministers, which convened a group of experts to draft the Convention itself.

The Convention was designed to incorporate a traditional civil liberties approach to securing "effective political democracy", from the strongest traditions in the United Kingdom, France and other member states of the fledgling Council of Europe, as said by Guido Raimondi, President of European Court of Human Rights:

The Convention was opened for signature on 4 November 1950 in Rome. It was ratified and entered into force on 3 September 1953. It is overseen and enforced by the European Court of Human Rights in Strasbourg, and the Council of Europe. Until procedural reforms in the late 1990s, the Convention was also overseen by a European Commission on Human Rights.

The Convention is drafted in broad terms, in a similar (albeit more modern) manner to the English Bill of Rights, the U.S. Bill of Rights, the French Declaration of the Rights of Man or the first part of the German Basic law. Statements of principle are, from a legal point of view, not determinative and require extensive interpretation by courts to bring out meaning in particular factual situations.

As amended by Protocol 11, the Convention consists of three parts. The main rights and freedoms are contained in Section I, which consists of Articles 2 to 18. Section II (Articles 19 to 51) sets up the Court and its rules of operation. Section III contains various concluding provisions.

Before the entry into force of Protocol 11, Section II (Article 19) set up the Commission and the Court, Sections III (Articles 20 to 37) and IV (Articles 38 to 59) included the high-level machinery for the operation of, respectively, the Commission and the Court, and Section V contained various concluding provisions.

Many of the Articles in Section I are structured in two paragraphs: the first sets out a basic right or freedom (such as Article 2(1) – the right to life) but the second contains various exclusions, exceptions or limitations on the basic right (such as Article 2(2) – which excepts certain uses of force leading to death).

Article 1 simply binds the signatory parties to secure the rights under the other Articles of the Convention "within their jurisdiction". In exceptional cases, "jurisdiction" may not be confined to a Contracting State's own national territory; the obligation to secure Convention rights then also extends to foreign territories, such as occupied land in which the State exercises effective control.

In "Loizidou v Turkey", the European Court of Human Rights ruled that jurisdiction of member states to the convention extended to areas under that state's effective control as a result of military action.

Article 2 protects the right of every person to their life. The right to life extends only to human beings, not to non-human animals, or to "legal persons" such as corporations. In "Evans v United Kingdom", the Court ruled that the question of whether the right to life extends to a human embryo fell within a state's margin of appreciation. In "Vo v France", the Court declined to extend the right to life to an unborn child, while stating that "it is neither desirable, nor even possible as matters stand, to answer in the abstract the question whether the unborn child is a person for the purposes of Article 2 of the Convention".

The Court has ruled that states have three main duties under Article 2:


The first paragraph of the article contains an exception for lawful executions, although this exception has largely been superseded by Protocols 6 and 13. Protocol 6 prohibits the imposition of the death penalty in peacetime, while Protocol 13 extends the prohibition to all circumstances. (For more on Protocols 6 and 13, see below).

The second paragraph of Article 2 provides that death resulting from defending oneself or others, arresting a suspect or fugitive, or suppressing riots or insurrections, will not contravene the Article when the use of force involved is "no more than absolutely necessary".

Signatory states to the Convention can only derogate from the rights contained in Article 2 for deaths which result from lawful acts of war.

The European Court of Human Rights did not rule upon the right to life until 1995, when in "McCann and Others v United Kingdom" it ruled that the exception contained in the second paragraph does not constitute situations when it is permitted to kill, but situations where it is permitted to use force which might result in the deprivation of life.

Article 3 prohibits torture and "inhuman or degrading treatment or punishment". There are no exceptions or limitations on this right. This provision usually applies, apart from torture, to cases of severe police violence and poor conditions in detention.

The Court has emphasized the fundamental nature of Article 3 in holding that the prohibition is made in "absolute terms ... irrespective of a victim's conduct". The Court has also held that states cannot deport or extradite individuals who might be subjected to torture, inhuman or degrading treatment or punishment, in the recipient state.

Initially, the Court took a restrictive view on what consisted of torture, preferring to find that states had inflicted inhuman and degrading treatment. Thus the court held that practices such as sleep deprivation, subjecting individual to intense noise and requiring them to stand against a wall with their limbs outstretched for extended periods of time, did not constitute torture. In fact the Court only found a state guilty of torture in 1996 in the case of a detainee who was suspended by his arms while his hands were tied behind his back. Since then the Court has appeared to be more open to finding states guilty of torture and has even ruled that since the Convention is a "living instrument", treatment which it had previously characterized as inhuman or degrading treatment might in future be regarded as torture.

Article 4 prohibits slavery, servitude and forced labour but exempts labour:

Article 5 provides that everyone has the right to liberty and security of person. Liberty and security of the person are taken as a "compound" concept – security of the person has not been subject to separate interpretation by the Court.

Article 5 provides the right to liberty, subject only to lawful arrest or detention under certain other circumstances, such as arrest on reasonable suspicion of a crime or imprisonment in fulfilment of a sentence. The article also provides those arrested with the right to be informed, in a language they understand, of the reasons for the arrest and any charge they face, the right of prompt access to judicial proceedings to determine the legality of the arrest or detention, to trial within a reasonable time or release pending trial, and the right to compensation in the case of arrest or detention in violation of this article.


Article 6 provides a detailed right to a fair trial, including the right to a public hearing before an independent and impartial tribunal within reasonable time, the presumption of innocence, and other minimum rights for those charged with a criminal offence (adequate time and facilities to prepare their defence, access to legal representation, right to examine witnesses against them or have them examined, right to the free assistance of an interpreter).

The majority of Convention violations that the Court finds today are excessive delays, in violation of the "reasonable time" requirement, in civil and criminal proceedings before national courts, mostly in Italy and France. Under the "independent tribunal" requirement, the Court has ruled that military judges in Turkish state security courts are incompatible with Article 6. In compliance with this Article, Turkey has now adopted a law abolishing these courts.

Another significant set of violations concerns the "confrontation clause" of Article 6 (i.e. the right to examine witnesses or have them examined). In this respect, problems of compliance with Article 6 may arise when national laws allow the use in evidence of the testimonies of absent, anonymous and vulnerable witnesses.


Article 7 prohibits the retroactive criminalisation of acts and omissions. No person may be punished for an act that was not a criminal offence at the time of its commission. The article states that a criminal offence is one under either national or international law, which would permit a party to prosecute someone for a crime which was not illegal under domestic law at the time, so long as it was prohibited by international law. The Article also prohibits a heavier penalty being imposed than was applicable at the time when the criminal act was committed.

Article 7 incorporates the legal principle "nullum crimen, nulla poena sine lege" into the convention.

Relevant cases are: 

Article 8 provides a right to respect for one's "private and family life, his home and his correspondence", subject to certain restrictions that are "in accordance with law" and "necessary in a democratic society". This article clearly provides a right to be free of unlawful searches, but the Court has given the protection for "private and family life" that this article provides a broad interpretation, taking for instance that prohibition of private consensual homosexual acts violates this article. There have been cases discussing consensual familial sexual relationships, and how the criminalisation of this may violate this article. However, the ECHR still deems such familial sexual acts to be criminal. This may be compared to the jurisprudence of the United States Supreme Court, which has also adopted a somewhat broad interpretation of the right to privacy. Furthermore, Article 8 sometimes comprises positive obligations: whereas classical human rights are formulated as prohibiting a State from interfering with rights, and thus "not" to do something (e.g. not to separate a family under family life protection), the effective enjoyment of such rights may also include an obligation for the State to become active, and to "do" something (e.g. to enforce access for a divorced parent to his/her child).

Notable case: "Roman Zakharov v. Russia" [2015] EHCR 47143/06

Article 9 provides a right to freedom of thought, conscience and religion. This includes the freedom to change a religion or belief, and to manifest a religion or belief in worship, teaching, practice and observance, subject to certain restrictions that are "in accordance with law" and "necessary in a democratic society"

Relevant cases are: 

Article 10 provides the right to freedom of expression, subject to certain restrictions that are "in accordance with law" and "necessary in a democratic society". This right includes the freedom to hold opinions, and to receive and impart information and ideas, but allows restrictions for:

Relevant cases are:

Article 11 protects the right to freedom of assembly and association, including the right to form trade unions, subject to certain restrictions that are "in accordance with law" and "necessary in a democratic society".


Article 12 provides a right for women and men of marriageable age to marry and establish a family.

Despite a number of invitations, the Court has so far refused to apply the protections of this article to same-sex marriage. The Court has defended this on the grounds that the article was intended to apply only to different-sex marriage, and that a wide margin of appreciation must be granted to parties in this area.

In "Goodwin v United Kingdom" the Court ruled that a law which still classified post-operative transsexual persons under their pre-operative sex, violated article 12 as it meant that transsexual persons were unable to marry individuals of their post-operative opposite sex. This reversed an earlier ruling in "Rees v United Kingdom". This did not, however, alter the Court's understanding that Article 12 protects only different-sex couples.

The European Court of Human Rights ruled in "Schalk and Kopf v Austria" that countries are not required to provide marriage licenses for same-sex couples, however if a country allows same-sex couple marriage it must be done so under the same conditions that opposite-sex couples marriage face: in order to prevent a breach of article 14 – the prohibition of discrimination. Additionally, the court ruled in the 2015 case of "Oliari and Others v Italy", that states have a positive obligation to ensure there is a specific legal framework for the recognition and protection of same-sex couples.

Article 13 provides for the right for an effective remedy before national authorities for violations of rights under the Convention. The inability to obtain a remedy before a national court for an infringement of a Convention right is thus a free-standing and separately actionable infringement of the Convention.

Article 14 contains a prohibition of discrimination. This prohibition is broad in some ways and narrow in others. It is broad in that it prohibits discrimination under a potentially unlimited number of grounds. While the article specifically prohibits discrimination based on "sex, race, colour, language, religion, political or other opinions, national or social origin, association with a national minority, property, birth or other status", the last of these allows the court to extend to Article 14 protection to other grounds not specifically mentioned such as has been done regarding discrimination based on a person's sexual orientation.

At the same time, the article's protection is limited in that it only prohibits discrimination with respect to rights under the Convention. Thus, an applicant must prove discrimination in the enjoyment of a specific right that is guaranteed elsewhere in the Convention (e.g. discrimination based on sex – Article 14 – in the enjoyment of the right to freedom of expression – Article 10). It has been said that laws regarding familial sexual relationships (or incest) are in breach of Article 14 when combined with Article 8.

Protocol 12 extends this prohibition to cover discrimination in any legal right, even when that legal right is not protected under the Convention, so long as it is provided for in national law.

Article 15 allows contracting states to derogate from certain rights guaranteed by the Convention in a time of "war or other public emergency threatening the life of the nation". Permissible derogations under article 15 must meet three substantive conditions:


In addition to these substantive requirements, the derogation must be procedurally sound. There must be some formal announcement of the derogation and notice of the derogation, any measures adopted under it, and the ending of the derogation must be communicated to the Secretary-General of the Council of Europe

As of 2016, eight member states had ever invoked derogations. The Court is quite permissive in accepting a state's derogations from the Convention but applies a higher degree of scrutiny in deciding whether measures taken by states under a derogation are, in the words of Article 15, "strictly required by the exigencies of the situation". Thus in "A v United Kingdom", the Court dismissed a claim that a derogation lodged by the British government in response to the September 11 attacks was invalid, but went on to find that measures taken by the United Kingdom under that derogation were disproportionate.

In order for a derogation itself to be valid, the emergency giving rise to it must be:

Examples of such derogations include:


Article 16 allows states to restrict the political activity of foreigners. The Court has ruled that European Union member states cannot consider the nationals of other member states to be aliens.

Article 17 provides that no one may use the rights guaranteed by the Convention to seek the abolition or limitation of rights guaranteed in the Convention. This addresses instances where states seek to restrict a human right in the name of another human right, or where individuals rely on a human right to undermine other human rights (for example where an individual issues a death threat).

Article 18 provides that any limitations on the rights provided for in the Convention may be used only for the purpose for which they are provided. For example, Article 5, which guarantees the right to personal freedom, may be explicitly limited in order to bring a suspect before a judge. To use pre-trial detention as a means of intimidation of a person under a false pretext is, therefore, a limitation of right (to freedom) which does not serve an explicitly provided purpose (to be brought before a judge), and is therefore contrary to Article 18.

, fifteen protocols to the Convention have been opened for signature. These can be divided into two main groups: those amending the framework of the convention system, and those expanding the rights that can be protected. The former require unanimous ratification by member states before coming into force, while the latter require a certain number of states to sign before coming into force.

This Protocol contains three different rights which the signatories could not agree to place in the Convention itself. Monaco and Switzerland have signed but never ratified Protocol 1.

Article 1 provides for the right to the peaceful enjoyment of one's possessions. The European Court of Human Rights acknowledged a violation of the fair balance between the demands of the general interest of the community and the requirements of the protection of the individual's fundamental rights, also, in the uncertainty – for the owner – about the future of the property, and in the absence of an allowance.

Article 2 provides for the right not to be denied an education and the right for parents to have their children educated in accordance with their religious and other views. It does not however guarantee any particular level of education of any particular quality.

Although phrased in the Protocol as a negative right, in "Şahin v. Turkey" the Court ruled that:
Article 3 provides for the right to elections performed by secret ballot, that are also free and that occur at regular intervals.


Article 1 prohibits the imprisonment of people for inability to fulfil a contract. Article 2 provides for a right to freely move within a country once lawfully there and for a right to leave any country. Article 3 prohibits the expulsion of nationals and provides for the right of an individual to enter a country of his or her nationality. Article 4 prohibits the collective expulsion of foreigners.

Turkey and the United Kingdom have signed but never ratified Protocol 4. Greece and Switzerland have neither signed nor ratified this protocol.

The United Kingdom's failure to ratify this protocol is due to concerns over the interaction of Article 2 and Article 3 with British nationality law. Specifically, several classes of "British national" (such as British National (Overseas)) do not have the right of abode in the United Kingdom and are subject to immigration control there. In 2009, the UK government stated that it had no plans to ratify Protocol 4 because of concerns that those articles could be taken as conferring that right.

Requires parties to restrict the application of the death penalty to times of war or "imminent threat of war".

Every Council of Europe member state has signed and ratified Protocol 6, except Russia, which has signed but not ratified.


Despite having signed the protocol more than thirty years ago Germany and the Netherlands have never ratified it. Turkey, which signed the protocol in 1985, ratified it in 2016, becoming the latest member state to do so. The United Kingdom has neither signed nor ratified the protocol.

Applies the current expansive and indefinite grounds of prohibited discrimination in Article 14 to the exercise of any legal right and to the actions (including the obligations) of public authorities.

The Protocol entered into force on 1 April 2005 and has () been ratified by 20 member states. Several member states—Bulgaria, Denmark, France, Lithuania, Monaco, Poland, Sweden, Switzerland, and the United Kingdom—have not signed the protocol.

The United Kingdom government has declined to sign Protocol 12 on the basis that they believe the wording of protocol is too wide and would result in a flood of new cases testing the extent of the new provision. They believe that the phrase "rights set forth by law" might include international conventions to which the UK is not a party, and would result in incorporation of these instruments by stealth. It has been suggested that the protocol is therefore in a catch-22, since the UK will decline to either sign or ratify the protocol until the European Court of Human Rights has addressed the meaning of the provision, while the court is hindered in doing so by the lack of applications to the court concerning the protocol caused by the decisions of Europe's most populous states—including the UK—not to ratify the protocol. The UK government, nevertheless, "agrees in principle that the ECHR should contain a provision against discrimination that is free-standing and not parasitic on the other Convention rights". The first judgment that found a violation of Protocol No. 12, "Sejdić and Finci v. Bosnia and Herzegovina", was delivered in 2009.

Protocol 13 provides for the total abolition of the death penalty. Currently all Council of Europe member states but three have ratified Protocol 13. Armenia has signed but not ratified the protocol. Russia and Azerbaijan have not signed it.

The Convention's provisions affecting institutional and procedural matters have been altered several times by means of protocols. These amendments have, with the exception of Protocol 2, amended the text of the convention. Protocol 2 did not amend the text of the convention as such but stipulated that it was to be treated as an integral part of the text. All of these protocols have required the unanimous ratification of all the member states of the Council of Europe to enter into force.

Protocols 2, 3, 5, 8, 9 and 10 have now been superseded by Protocol 11 which entered into force on 1 November 1998. It established a fundamental change in the machinery of the convention. It abolished the Commission, allowing individuals to apply directly to the Court, which was given compulsory jurisdiction and altered the latter's structure. Previously states could ratify the Convention without accepting the jurisdiction of the Court of Human Rights. The protocol also abolished the judicial functions of the Committee of Ministers.

Protocol 14 follows on from Protocol 11 in proposing to further improve the efficiency of the Court. It seeks to "filter" out cases that have less chance of succeeding along with those that are broadly similar to cases brought previously against the same member state. Furthermore, a case will not be considered admissible where an applicant has not suffered a "significant disadvantage". This latter ground can only be used when an examination of the application on the merits is not considered necessary and where the subject-matter of the application had already been considered by a national court.

A new mechanism was introduced by Protocol 14 to assist enforcement of judgements by the Committee of Ministers. The Committee can ask the Court for an interpretation of a judgement and can even bring a member state before the Court for non-compliance of a previous judgement against that state. Protocol 14 also allows for European Union accession to the Convention. The protocol has been ratified by every Council of Europe member state, Russia being last in February 2010. It entered into force on 1 June 2010.

A provisional Protocol 14bis had been opened for signature in 2009. Pending the ratification of Protocol 14 itself, 14bis was devised to allow the Court to implement revised procedures in respect of the states which have ratified it. It allowed single judges to reject manifestly inadmissible applications made against the states that have ratified the protocol. It also extended the competence of three-judge chambers to declare applications made against those states admissible and to decide on their merits where there already is a well-established case law of the Court. Now that all Council of Europe member states have ratified Protocol 14, Protocol 14bis has lost its "raison d'être" and according to its own terms ceased to have any effect when Protocol 14 entered into force on 1 June 2010.





</doc>
<doc id="9831" url="https://en.wikipedia.org/wiki?curid=9831" title="Ecclesia">
Ecclesia

Ecclesia (Greek: ἐκκλησία "ekklēsia") may refer to:






</doc>
<doc id="9833" url="https://en.wikipedia.org/wiki?curid=9833" title="Eureka Rebellion">
Eureka Rebellion

The Eureka Rebellion was a rebellion in 1854, instigated by gold miners in Ballarat, Victoria, Australia, who revolted against the colonial authority of the United Kingdom. It culminated in the Battle of the Eureka Stockade, which was fought between miners and the colonial forces of Australia on 3 December 1854 at Eureka Lead and named for the stockade structure built by miners during the conflict. The rebellion resulted in the deaths of at least 27 people, the majority of whom were rebels.

The rebellion was the culmination of a period of civil disobedience in the Ballarat region during the Victorian gold rush with miners objecting to the expense of a miner's licence, taxation via the licence without representation, and the actions of the government, the police and military. The local rebellion grew from a Ballarat Reform League movement and culminated in the erection by the rebels of a crude battlement and a swift and deadly siege by colonial forces.

Mass public support for the captured rebels in the colony's capital of Melbourne when they were placed on trial resulted in the introduction of the Electoral Act 1856, which mandated suffrage for male colonists in the lower house in the Victorian parliament. This is considered the second instituted act of political democracy in Australia. Female colonists of South Australia were awarded suffrage 5 years later on condition of owning property, much in the way men did not have full suffrage in the absence of property ownership. As such, the Eureka Rebellion is controversially identified with the birth of democracy in Australia and interpreted by some as a political revolt.

In 2015, a report commissioned by the City of Ballarat found that the most likely site of the rallies which led to the rebellion was 29 St. Paul's Way, Bakery Hill. Given documentary evidence and its elevation, this was likely to be the site where speeches were made and the Eureka Flag was symbolically hoisted for the first time. As of 2018, the area is a carpark awaiting residential development.

Hiscock's gold rush began on 12 August 1851 following the publication in the "Geelong Advertiser" of Thomas Hiscock's gold findings at Hiscock's, 3 kilometres west of Buninyong (now Magpie, approximately 10 kilometres south of Eureka). Just days later on 16 August 1851, Lieutenant-Governor Latrobe proclaimed in the Government Gazette crown rights for all mining proceeds and a licence fee of 30 shillings per month effective from 1 September 1851.

On 26 August, a rally of 40–50 miners opposing the fee was held at Hiscock's gully – the first of many such protests in the colony. The miners opposed government policies of oppression including the licence fee and demanded rights to vote and to buy land. This first meeting was followed by dissent across the colony's mining settlements.

In December the government announced that it intended to triple the licence fee from £1 to £3 a month, from 1 January 1852. This move incited protests around the colony, including the Forest Creek Monster Meeting of December 1851. In Ballarat, as historian Weston Bate noted, diggers became so agitated that they began to gather arms. The government hastily repealed its plans due to the reaction.

Nevertheless, the oppressive licence hunts continued and increased in frequency causing general dissent among the diggers. In addition, Weston Bate noted that the Ballarat diggings were in strong opposition to the strict liquor licensing laws imposed by the government.

Changes to the Goldfields Act in 1853 allowed licence searches to occur at any time which further incensed the diggers. In Bendigo in 1853, an Anti-Gold Licence Association was formed and the miners were apparently on the brink of an armed clash with authorities. Again in 1854, Bendigo miners responded to an increase in the frequency of twice weekly licence hunts with threats of armed rebellion.

On 7 October 1854, Scottish miner James Scobie was murdered at Bentley's Eureka Hotel. Ten days later, on 17 October 1854, between 1,000 and 10,000 miners gathered at the hotel to protest the acquittal of James Bentley, the hotel proprietor and prime suspect in Scobie's murder, by an allegedly corrupt magistrate.

The miners rioted and Bentley and his wife Catherine fled for their lives as the hotel was burnt down by the angry mob. A small group of soldiers were unable to suppress the riot.

On 22 October 1854, Ballarat Catholics met to protest the treatment of Father Smyth.
The next day, the arrests of miners McIntyre and Fletcher for the Eureka Hotel fire provoked a mass meeting which attracted 4,000 miners. The meeting resolved to establish a 'Digger's Rights Society', to protect their rights. On 1 November 1854, 10,000 miners met once again at Bakery Hill. They were addressed by Thomas Kennedy, Henry Holyoake, George Black and Henry Ross. The diggers were further angered by the arrest of another seven of their number for the Eureka Hotel fire.

On Saturday, 11 November 1854 a crowd estimated at more than 10,000 miners gathered at Bakery Hill, directly opposite the government encampment. At this meeting, the Ballarat Reform League was created, under the chairmanship of Chartist John Basson Humffray. Several other Reform League leaders, including Kennedy and Holyoake, had been involved with the Chartist movement in England. Many of the miners had past involvement in the Chartist movement and the social upheavals in Britain, Ireland, and continental Europe during the 1840s.

In setting its goals, the Ballarat Reform League used the first five of the British Chartist movement's principles as set out in the People's Charter of 1838. They did not adopt or agitate for the Chartist's sixth principle, secret ballots. The meeting passed a resolution "that it is the inalienable right of every citizen to have a voice in making the laws he is called on to obey, that taxation without representation is tyranny." The meeting also resolved to secede from the United Kingdom if the situation did not improve.

Throughout the following weeks, the League sought to negotiate with Commissioner Robert Rede and the Governor of Victoria, Sir Charles Hotham, both on the specific matters relating to Bentley and the Scobie's death, and the men being tried for the burning of the Eureka Hotel, and on the broader issues of abolition of the licence, suffrage and democratic representation of the gold fields, and disbanding of the Gold Commission. On 16 November 1854 Governor Hotham appointed a Royal Commission on the goldfields' problems and grievances. However, Commissioner Rede, rather than hear miners' grievances, increased the police presence in the goldfields and summoned reinforcements from Melbourne. Many historians (most notably Manning Clark) attribute this to his belief in his right to exert authority over the "rabble."

On 28 November 1854, the reinforcements marching from Melbourne were attacked by a crowd of miners. A number were injured. A rumour of the death of a drummer boy began, and there was even a memorial erected to him in Ballarat Cemetery for many years, although historical research has shown that the boy, John Egan, continued military service until dying in 1860.

At a meeting of about 12,000 'diggers' on the following day, (29 November), the Reform League delegation relayed its failure to achieve any success in negotiations with the authorities. The miners resolved on open resistance to the authorities and to burn the hated licences.

Rede responded by ordering police to conduct a licence search on 30 November. Eight defaulters were arrested, and most of the military resources available had to be summoned to extricate the arresting officers from the angry mob that had assembled.

This raid prompted a change in the leadership of the Reform League, to people who argued in favour of 'physical force' rather than the 'moral force' championed by Humffray and the old leadership.

In the rising tide of anger and resentment amongst the miners, a more militant leader, Peter Lalor, was elected. In swift fashion, a military structure was assembled. Brigades were formed, and captains were appointed. Licences were burned, and on 1 December at Bakery Hill, "The disaffected miners... held a meeting where at the Australian flag of independence was solemnly consecrated and vows proffered for its defence.", with the 'Eureka oath' being sworn by Peter Lalor to the affirmation of his fellow demonstrators, who encamped themselves around the flag to resist further licence hunts and harassment by the authorities: "We swear by the Southern Cross to stand truly by each other and fight to defend our rights and liberties."

The white and blue Eureka Flag, said to be designed by a Canadian miner, Captain Henry Ross, and bearing nothing but the Southern Cross, was then flown for the first (recorded) occasion; according to the Ballarat Times, which first mentioned the flag a week earlier on 24 November 1854, at "about eleven o'clock the 'Southern Cross' was hoisted, and its maiden appearance was a fascinating object to behold." The flag was believed to have been sewn by Anastasia Hayes. Reportedly influenced by earlier designs such as the Australian Federation Flag, as a gesture of defiance , it deliberately excluded the British Union Flag, which is included in the official flag of Australia. The Eureka flag was commonly referred to at the time as the Australian flag, and as the Southern Cross, with "The Age" variously reporting, on 28 November: "The Australian flag shall triumphantly wave in the sunshine of its own blue and peerless sky, over thousands of Australia's adopted sons"; the day after the battle: "They assembled round the Australian flag, which has now a permanent flag-staff"; and during the 1855 Eureka trials, that it was sworn that the Eureka flag was also known as the "digger's flag" and also as "the Southern Cross".

"The Argus" newspaper of 4 December 1854 reported that the Union Jack "had" to be hoisted underneath the Eureka flag at the stockade, and that both flags were by then in the possession of the foot police.

Some have questioned whether this sole contemporaneous report of the otherwise unaccounted for Union Jack being present is accurate. In defence of this alternative scenario it has been stressed that the investigating journalist may have had available eyewitness reports of the two flags having been seized, and that it was possibly an 11th hour response to the divided loyalties among the heterogeneous rebel force which was in the process of melting away (at one stage 1,500 of 17,280 men in Ballarat were present, with only 150 taking part in the battle), with Lalor's choice of password for the night of 2 December – "Vinegar Hill" – causing support for the rebellion to fall away among those who were otherwise disposed to resist the military, as word spread that the question of Irish home rule had become involved.

Gregory Black, military historian and author of "Eureka Stockade: A Ferocious and Bloody Battle", concedes two flags may have been flown on the day of the battle, as the miners were claiming to be defending their British rights, with a further article in "The Argus" on 9 December 1854, reporting that Constable Hugh King had found a Union Jack like flag being carried by a prisoner; and, according to "The Eureka Encyclopedia", Sergeant John McNeil at the time shredded a flag at the Spencer Street Barracks in Melbourne, which was said to be the Eureka flag, but which may well have been a Union Jack.

It is certain that Irish born people were strongly represented at the Eureka Stockade. Eureka historians have discovered that as well as comprising most of the miners inside the stockade at the finish, the area where the defensive position was established was overwhelmingly populated by the Irish to begin with. Professor Geoffrey Blainey has advanced the view, that the white cross behind the stars on the Eureka flag "really [is] an Irish cross rather than being [a] configuration of the Southern Cross".

During 2 December, the peak rebel force trained in and around the stockade. A further two hundred Americans, the Independent Californian Rangers, under the leadership of James McGill, arrived about 4pm. The Americans were armed with revolvers and Mexican knives and possessed horses. In a fateful decision, McGill decided to take most of the Californian Rangers away from the stockade to intercept rumoured British reinforcements coming from Melbourne. Rede's spies observed these actions. That night many of the miners went back to their own tents after the traditional Saturday night carousing, with the assumption that the Queen's military forces would not be sent to attack on the Sabbath (Sunday). A small contingent of miners remained at the stockade overnight, which the spies reported to Rede.

The stockade itself was a ramshackle affair which was hastily constructed over the following days from timber and overturned carts. The structure was never meant to be a military stockade or fortress. In the words of Lalor: "it was nothing more than an enclosure to keep our own men together, and was never erected with an eye to military defence". Lalor had already outlined a plan whereby, "if the government forces come to attack us, we should meet them on the Gravel Pits, and if compelled, we should retreat by the heights to the old Canadian Gully, and there we shall make our final stand".

By the beginning of December, the police contingent at Ballarat had been joined and surpassed in number by soldiers from British Army garrisons in Victoria, including detachments from the 12th (East Suffolk) Regiment of Foot and 40th (2nd Somersetshire) Regiment of Foot.

At 3 am on Sunday, 3 December, a party of 276 soldiers and police, under the command of Captain John W. Thomas approached the Eureka Stockade and a battle ensued.

There is no agreement as to which side fired first, but the battle was fierce, brief, and terribly one-sided. The ramshackle army of miners was hopelessly outclassed by a military regiment and was routed in about 10 minutes. During the height of the battle, Lalor was shot in his left arm, took refuge under some timber and was smuggled out of the stockade and hidden. His arm was later amputated.

Stories tell how women ran forward and threw themselves over the injured to prevent further indiscriminate killing. The Commission of Inquiry would later say that it was "a needless as well as a ruthless sacrifice of human life indiscriminate of innocent or guilty, and after all resistance had disappeared."
Early in the battle "Captain" Henry Ross was shot dead.

According to Lalor's report, fourteen miners (mostly Irish) died inside the stockade and an additional eight died later from injuries they sustained. A further dozen were wounded but recovered. Three months after the Eureka Stockade, Peter Lalor wrote: "As the inhuman brutalities practised by the troops are so well known, it is unnecessary for me to repeat them. There were 34 digger casualties of which 22 died. The unusual proportion of the killed to the wounded, is owing to the butchery of the military and troopers after the surrender."

During the battle, trooper John King the police constable, took down the Eureka flag. By 8 am, Captain Charles Pasley, the second in command of the British forces, sickened by the carnage, saved a group of prisoners from being bayoneted and threatened to shoot any police or soldiers who continued with the slaughter. Pasley's valuable assistance was acknowledged in despatches printed and laid before the Victorian Legislative Council.

One hundred and fourteen diggers, some wounded, were marched off to the Government camp about two kilometres away, where they were kept in an overcrowded lock-up, before being moved to a more spacious barn on Monday morning.

Of the soldiers and police, six were killed, including Captain Wise. Martial law was imposed, and all armed resistance collapsed. News of the battle spread quickly to Melbourne and other gold field regions, turning a perceived Government military victory in repressing a minor insurrection into a public relations disaster. Thousands of people in Melbourne turned out to condemn the authorities, in defiance of their mayor and some Legislative Councillors, who tried to rally support for the government. In Ballarat, only one man responded to the call for special constables, although in Melbourne 1500 were sworn in and armed with batons. Many people voiced their support for the diggers' requested reforms.

Exact numbers of deaths and injuries and persons are difficult to determine as many miners "fled to the surrounding bush and it is likely a good many more died a lonely death or suffered the agony of their wounds, hidden from the authorities for fear of repercussions." according to Eureka researcher and author Dorothy Wickham. The official register of deaths in the Ballarat District Register shows 27 names associated with the stockade battle at Eureka.

Historian Clare Wright quotes one source, Thomas Pierson, who noted in the margin to his diary "time has proved that near 60 have died of the diggers in all". According to Wright, Captain Thomas estimated that 30 diggers died on the spot and "many more died of their wounds subsequently." Even the Geelong Advertiser on 8 December 1854 stated that deaths were "more numerous than originally supposed."

While it has been thought all the deaths at Eureka were men, research by historian Clare Wright details that at least one woman lost her life in the massacre. Wright's research details the important role of women on the goldfields and in the reform movement. Her book "Forgotten Rebels of Eureka" details how Charles Evans' diary describes a funeral for a woman who was mercilessly butchered by a mounted trooper while pleading for the life of her husband during the Eureka massacre. Her name and the fate and identity of her husband remain unknown.

Historian Geoffrey Blainey has commented, "Every government in the world would probably have counter-attacked in the face of the building of the stockade." For a few weeks it appeared that the status quo had been restored, and Rede ruled the camps with an iron fist.

The first trial relating to the rebellion was a charge of sedition against Henry Seekamp of the "Ballarat Times". Seekamp was arrested in his newspaper office on 4 December 1854, for a series of articles that appeared in the "Ballarat Times". Many of these articles were written by George Lang, the son of the prominent republican and Presbyterian Minister of Sydney, the Reverend John Dunmore Lang. He was tried and convicted of seditious libel by a Melbourne jury on 23 January 1855 and, after a series of appeals, sentenced to six months imprisonment on 23 March. He was released from prison on 28 June 1855, precisely three months early. While he was in jail, Henry Seekamp's de facto wife, Clara Seekamp took over the business, and became the first female editor of an Australian newspaper.

Of the approximately 120 'diggers' detained after the rebellion, thirteen were brought to trial. They were:
The first trial started on 22 February 1855, with defendants being brought before the court on charges of high treason. Joseph was one of three Americans arrested at the stockade, with the United States Consul intervening for the release of the other two Americans. The prosecution was handled by Attorney-General William Stawell representing the Crown before Chief Justice William à Beckett. The jury deliberated for about half an hour before returning a verdict of "not guilty". "A sudden burst of applause arose in the court" reported "The Argus", but was instantly checked by court officers. The Chief Justice condemned this as an attempt to influence the jury; he sentenced two men identified by the Crown Solicitor as having applauded to a week in prison for contempt. Over 10,000 people had come to hear the jury's verdict. John Joseph was carried around the streets of Melbourne in a chair in triumph, according to the Ballarat newspaper "The Star".

Under the auspices of Victorian Chief Justice Redmond Barry, all the other 13 accused men were rapidly acquitted to great public acclaim. The trials have on several occasions been called a farce. Rede himself was quietly removed from the camps and reassigned to an insignificant position in rural Victoria.

When Hotham's Royal Commission report, initiated before the conflict, was finally handed down it was scathing in its assessment of all aspects of the administration of the gold fields, and particularly the Eureka Stockade affair. According to Blainey, "It was perhaps the most generous concession offered by a governor to a major opponent in the history of Australia up to that time. The members of the commission were appointed before Eureka...they were men who were likely to be sympathetic to the diggers."

The report made several major recommendations, one of which was to restrict Chinese immigration. Its recommendations were only put into effect after the Stockade. The gold licences were then abolished, and replaced by an annual miner's right and an export fee based on the value of the gold. Mining wardens replaced the gold commissioners, and police numbers were cut drastically. The Legislative Council was expanded to allow representation to the major goldfields. Peter Lalor and John Basson Humffray were elected for Ballarat, although there were property qualifications with regards to eligibility to vote in upper house elections in Victoria until the 1950s. After 12 months, all but one of the demands of the Ballarat Reform League had been granted. Lalor and Humffray both enjoyed distinguished careers as politicians, with Lalor later elected as Speaker of the Legislative Assembly of Victoria.

Following the battle, rebel leader, Irish Australian Peter Lalor, wrote in a statement to the colonists of Victoria, "There are two things connected with the late outbreak (Eureka) which I deeply regret. The first is, that we shouldn't have been forced to take up arms at all; and the second is, that when we were compelled to take the field in our own defence, we were unable (through want of arms, ammunition and a little organisation) to inflict on the real authors of the outbreak the punishment they so richly deserved."

Lalor stood for in the 1855 elections and was elected unopposed.

During a speech in the Legislative Council in 1856 he said, "I would ask these gentlemen what they mean by the term 'democracy'. Do they mean Chartism or Republicanism? If so, I never was, I am not now, nor do I ever intend to be a democrat. But if a democrat means opposition to a tyrannical press, a tyrannical people, or a tyrannical government, then I have been, I am still, and will ever remain a democrat."

The actual significance of Eureka upon Australia's politics is not decisive. It has been variously interpreted as a revolt of free men against imperial tyranny, of independent free enterprise against burdensome taxation, of labour against a privileged ruling class, or as an expression of republicanism. In his 1897 travel book "Following the Equator", American writer Mark Twain wrote of the Eureka Rebellion:
Raffaello Carboni, who was present at the Stockade, wrote that "amongst the foreigners ... there was no democratic feeling, but merely a spirit of resistance to the licence fee"; and he also disputes the accusations "that have branded the miners of Ballarat as disloyal to their QUEEN" (emphasis as in the original). The affair continues to raise echoes in Australian politics to the present day, and from time to time one group or another calls for the existing Australian flag to be replaced by the Eureka Flag.

Some historians believe that the prominence of the event in the public record has come about because Australian history does not include a major armed rebellion phase equivalent to the French Revolution, the English Civil War, or the American War of Independence, making the Eureka story inflated well beyond its real significance. Others, however, maintain that Eureka was a seminal event and that it marked a major change in the course of Australian history.

In 1980, historian Geoffrey Blainey drew attention to the fact that many miners were temporary migrants from Britain and the United States, who did not intend to settle permanently in Australia. He wrote:
In 1999, the Premier of New South Wales, Bob Carr, dismissed the Eureka Stockade as a "protest without consequence". Deputy Prime Minister John Anderson made the Eureka flag a federal election campaign issue in 2004 saying "I think people have tried to make too much of the Eureka Stockade...trying to give it a credibility and standing that it probably doesn't enjoy."

In 2004, the Premier of Victoria, Steve Bracks, delivered an opening address at the Eureka 150 Democracy Conference stating "that Eureka was about the struggle for basic democratic rights. It was not about a riot – it was about rights."

The materials used to build the stockade were rapidly removed to be used for the mines, and the entire area around the site was so extensively worked that the original landscape became unrecognisable, so identifying the exact location of the stockade is now virtually impossible.

A diggers' memorial was erected in the Ballarat Cemetery on 22 March 1856 near marked graves. Sculpted in stone from the Barrabool Hills by James Leggatt in Geelong it features a pillar bearing the names of the deceased miners and bearing the inscription "Sacred to the memory of those who fell on the memorable 3rd of December, 1854, in resisting the unconstitutional proceedings of the Victorian Government."

A soldiers' memorial was erected many years later in 1876 and is an obelisk constructed of limestone sourced from Waurn Ponds with the words "Victoria" and "Duty" carved in its north and south faces respectively. In 1879 a cast iron fence was added to the memorials and graves.

Over the next thirty years, press interest in the events that had taken place at the Eureka Stockade dwindled, but Eureka was kept alive at the campfires and in the pubs, and in memorial events in Ballarat. In addition, key figures such as Lalor and Humfray were still in the public eye.

Eureka had not been forgotten: it was readily remembered. Similar flags have been flown at rebellions since including a flag similar to the Eureka flag which was flown above the Barcaldine strike camp in the 1891 Australian shearers' strike.

In 1889, Melbourne businessmen employed renowned American cyclorama artist Thaddeus Welch, who teamed up with local artist Izett Watson to paint of canvas of the Eureka Stockade, wrapped around a wooden structure. When it opened in Melbourne, the exhibition was an instant hit. "The Age" reported in 1891 that "it afforded a very good opportunity for people to see what it might have been like at Eureka". "The Australasian" wrote "that many persons familiar with the incidents depicted, were able to testify to the fidelity of the painted scene". The people of Melbourne flocked to the cyclorama, paid up and had their picture taken before it. It was eventually dismantled and disappeared from sight.

Memorials to soldiers and miners are located in the Ballaarat Old Cemetery and the Eureka Stockade Memorial is located within the Eureka Stockade Gardens and is listed on the Australian National Heritage List.

In 1954, the centenary of the event was officially celebrated; according to Geoffrey Blainey, who was in attendance, no one, apart from a small group of communists, was there. Plays commemorating the events were held at major theatres. 
A purpose built Interpretation centre was erected in 1998 in suburb of Eureka near the site of the stockade. Designed to be a new landmark for Ballarat, the building featured an enormous sail emblazoned with the Eureka Flag. Before its development there was considerable debate over whether a replica or reconstruction of wooden structures was appropriate, however it was eventually decided against and this is seen by many as a reason for the apparent failure of the centre to draw significant tourist numbers. Due primarily to falling visitor numbers the centre was redeveloped between 2009 and 2011.

In 1992, Sovereign Hill commenced a commemorative son et lumière known as "Blood Under the Southern Cross" which became a tourist drawcard and was revised and expanded from 2003. In 2004, the 150th anniversary was celebrated. An Australian postage stamp featuring the Eureka Flag was released along with a set of commemorative coins. A ceremony in Ballarat known as the lantern walk was held at dawn. However, Prime Minister John Howard did not attend any commemorative events, and refused to allow the flag to fly over Parliament House.

In November 2004 then Premier of Victoria Steve Bracks announced that the Ballarat V/Line rail service would be renamed the "Eureka Line" to mark the 150th anniversary to take effect from late 2005 at the same time as a renaming of Spencer Street station to Southern Cross, however the proposal was criticised by community groups including the Public Transport Users Association. Renaming of the line did not go ahead, however Spencer Street (railway) Station did become Southern Cross Station on 13 December 2005 with Bracks stating the name would resonate with Victorians because it "stands for democracy and freedom because it flew over the Eureka Stockade".
Eureka Tower, completed in 2006 is named in honour of the event and features symbolic aspects in its design including an architectural red stripe representing the blood spilled during the battle.

The site of the Eureka Stockade in Ballarat is currently being redeveloped with the support of grants from the City of Ballarat and the Victorian and Federal Governments. It will feature the new Museum of Australian Democracy at Eureka (M.A.D.E) that will draw on the touchstone of Eureka and its newly restored flag, and put the Eureka Stockade into the context of 260 years of democracy.

M.A.D.E.'s highly interactive exhibition, based on the premise of "People + Power = Democracy", is expected to open in early 2013, followed by a national rollout of public onsite and online programs.

Deputy Premier, the Hon. Peter Ryan, told the Legislative Assembly, sitting in Ballarat in 2012, that M.A.D.E. would be "a magnificent tribute to the events" of the Eureka Stockade.

The Museum's "M.A.D.E. You Look" booklet says M.A.D.E will be 'an online platform and immersive museum with a refreshing approach to culture, civics, history and citizenship. M.A.D.E puts the past into a contemporary context, celebrates Australia's achievements and inspires new ways of thinking about issues like equality, freedom of speech, parliamentary representation and the rule of law'. The museum 'will ignite debate about what it means to be an effective Australian in the 21st Century'.



"Eureka Stockade" (1907), directed by Arthur and George Cornwell and produced by the Australasian Cinematograph Company, was the second feature film made in Australia (the first being the 1906 production, "The Story of the Kelly Gang"). The film was first screened on 19 October 1907 at the Melbourne Athenaeum. The film impressed critics of the time and was found to be a stirring portrayal of the events surrounding the Eureka Stockade, but failed to connect with audiences during the two weeks it was screened. The surviving seven-minute fragment (stored at the National Film and Sound Archive) shows street scenes of Ballarat. Other scenes in the lost reels of the film were believed to have included gold seekers leaving London, issuing of licences, licence hunting, diggers chained to logs and rescued by mates, diggers burning Bentley's Hotel, the Rebellion, building the stockade, troops storming the stockade and the stockade in ruins.

"The Loyal Rebel", also known as "Eureka Stockade", is an Australian silent film made in 1915. Directed by Alfred Rolfe, it starred Maisie Carte, Wynn Davies, Reynolds Denniston, Charles Villiers, Percy Walshe, Jena Williams, and Leslie Victor as Peter Lalor. It is considered a lost film.

A 1949 British film, titled "Eureka Stockade" (released in the United States as "Massacre Hill"), was shot in Australia. The film starred Chips Rafferty as Peter Lalor, and Peter Illing as Raffaello Carboni. It was directed by Harry Watt, produced by Leslie Norman and written by Walter Greenwood, Ralph Smart and Harry Watt.

"Stockade", a 1971 Australian musical film featuring Rod Mullinar as Peter Lalor, was directed by Hans Pomeranz and Ross McGregor. The film was written by Kenneth Cook, adapted from his musical play.

"Eureka Stockade" was a two-part television mini-series which aired on the Seven Network in 1984. starring Bryan Brown as Peter Lalor. Directed by Rod Hardy, produced by Henry Crawford and written by Tom Hegarty. The cast included Carol Burns, Bill Hunter and Brett Cullen.

"Riot or Revolution: Eureka Stockade 1854", an Australian documentary from 2006, directed by Don Parham. The film focuses mainly on Governor Sir Charles Hotham (played by Brian Lipson), Raffaello Carboni (Barry Kay), and Douglas Huyghue (Tim Robertson). The accounts of these eyewitnesses are the main source for the monologues directly aimed at the audience, and, as the caption at the start of the film says: "the lines spoken by actors in this film are the documented words of the historical characters."
The cast also included Julia Zemiro as Celeste de Chabrillan and Andrew Larkins as Peter Lalor.
It was filmed in Ballarat and "Toorac House" in Melbourne.

"Stockade", a musical play by Kenneth Cook and Patricia Cook, was first performed at Sydney's Independent Theatre in 1971. It was the basis for the film "Stockade".

"Carboni" is a dramatisation by John Romeril of Raffaello Carboni's eyewitness account of the Eureka Rebellion. It was first performed in 1980 by the Australian Performing Group at the Pram Factory in Melbourne, with Bruce Spence in the title role.

"Eureka Stockade", a three-act opera with music by Roberto Hazon and a libretto by John Picton-Warlow and Carlo Stransky, was completed in 1988.

The musical "Eureka" premiered in Melbourne in 2004 at Her Majesty's Theatre. With music by Michael Maurice Harvey, book and lyrics by Gale Edwards and John Senczuk and original book and lyrics by Maggie May Gordon, "Eureka" was nominated for the Helpmann Award for Best Musical in 2005.





</doc>
<doc id="9835" url="https://en.wikipedia.org/wiki?curid=9835" title="Escape from New York">
Escape from New York

Escape from New York is a 1981 American post-apocalyptic science-fiction action film co-written, co-scored and directed by John Carpenter. The film is set in what was near-future of 1997, in a crime-ridden United States that has converted Manhattan Island in New York City into the country's maximum security prison. When Air Force One is hijacked by terrorists and crashes into New York City, ex-soldier and federal prisoner Snake Plissken (Kurt Russell) is given 24 hours to rescue the President of the United States.

Carpenter wrote the film in the mid-1970s as a reaction to the Watergate scandal. After the success of "Halloween", he had enough influence to begin production and filmed it mainly in St. Louis, Missouri on an estimated budget of $6 million. Debra Hill and Larry J. Franco served as the producers. The film was co-written by Nick Castle, who had collaborated with Carpenter by portraying Michael Myers in "Halloween".

"Escape from New York" was released in the United States on July 10, 1981. The film received positive reviews from critics and was a commercial success, grossing over $25 million at the box office. The film was nominated for four Saturn Awards, including Best Science Fiction Film and Best Direction. The film became a cult classic and was followed by a sequel, "Escape from L.A." (1996), which was also directed and written by Carpenter and starred Russell but was much less favorably received.

In 1988, following a 400% increase in crime, the United States government has turned Manhattan into a giant maximum-security prison. A containment wall surrounds the island, and routes out of Manhattan have been dismantled or mined, while armed helicopters patrol the rivers, and all prisoners there are sentenced to life, with no means of leaving.

In 1997, while traveling to a peace summit between the United States, China and Russia, Air Force One is hijacked by a domestic terrorist posing as a stewardess. The President is given a tracking bracelet and his briefcase (containing an audiotape describing the secret to using nuclear fusion for power generation) handcuffed to his wrist. He makes it to an escape pod, and lands in Manhattan just before Air Force One crashes, killing everyone else aboard.

Police are dispatched to rescue the President. However, Romero, the right-hand man of the Duke of New York (the top crime boss in the prison) warns them that the Duke has taken the President hostage, and that he will be killed if any further rescue attempts are mounted. Commissioner Bob Hauk offers a deal to Snake Plissken, a former Special Forces soldier convicted of attempting to rob the Federal Reserve in Denver, Colorado: if Snake rescues the President and retrieves the cassette tape, Hauk will arrange a presidential pardon. To ensure his compliance, Hauk has Plissken injected with micro-explosives that will rupture Snake's carotid arteries within 22 hours; if Snake returns with the President and the tape in time, Hauk will have the explosives neutralized.

Snake is sent into Manhattan in a stealth glider, landing atop the World Trade Center. He tracks the President's life-monitor bracelet to a vaudeville theater, only to find it on the wrist of an insane old man. He meets "Cabbie," who takes Snake in his armored taxi cab to Harold "Brain" Hellman, an advisor to the Duke and a former associate of Snake's. Brain tells Snake that the Duke plans to unify the gangs in a mass exodus across the heavily guarded Queensboro Bridge, using the President as a human shield and a map Brain has created to avoid the landmines. Snake forces Brain and his girlfriend Maggie to lead him to the Duke's compound at Grand Central Terminal. He finds the President, but is captured by the Duke's men.

While Snake is forced to fight in a deathmatch with Slag, a prisoner, Brain and Maggie kill Romero and flee with the President. As Snake kills Slag, the Duke learns of Brain's treachery and rallies his gang to chase them. Snake, Brain, Maggie, and the President race to the World Trade Center in an attempt to use Snake's glider to escape from Manhattan. After a group of crazies destroy it, the group returns to the street and encounters Cabbie, who offers to take them across the bridge. When Cabbie reveals that he has the secret tape (having traded it to Romero earlier for his hat), the President demands it, but Snake keeps it.

The Duke pursues the group onto the bridge, setting off mines as he tries to catch up. With Brain navigating through the minefield, Snake manages to avoid most of the explosives, but the cab hits a mine and is blown in half, killing Cabbie. As the group flees on foot, Brain is killed when he steps on another mine. Maggie refuses to leave him. She stands in the middle of the road, shooting at the Duke's car until he runs her down, killing her. Snake and the President reach the perimeter wall, and the guards raise the President on a rope. The Duke opens fire on the wall, killing the guards and forcing Snake to dive for cover, but the President shoots the Duke dead. Snake is lifted to safety, and the micro-explosives in his neck are neutralized.

As the President prepares for a televised speech to the leaders at the summit meeting, he thanks Snake for saving him. Snake asks how he feels about the people who died saving him, but the President only offers half-hearted regret. As Snake walks away in disgust, Hauk offers Snake a job, which he refuses. The President's speech commences, and he offers the contents of the cassette; to his embarrassment, the tape is Cabbie's cassette of the swing song "Bandstand Boogie". As Snake walks away, he intentionally tears the magnetic tape out of the cassette reel with the actual message that was intended to be delivered by the President.

The character "Rehme" was named after producer Robert Rehme, while "Taylor", "Romero" and "Cronenberg" were named after the directors Don Taylor, George Romero and David Cronenberg respectively.

Carpenter originally wrote the screenplay for "Escape from New York" in 1976, in the aftermath of the Watergate scandal. Carpenter said, "The whole feeling of the nation was one of real cynicism about the President. I wrote the screenplay and no studio wanted to make it" because, according to Carpenter, "it was too violent, too scary, too weird." He had been inspired by the film "Death Wish", which was very popular at the time. He did not agree with this film's philosophy but liked how it conveyed "the sense of New York as a kind of jungle, and I wanted to make a science fiction film along these lines".

AVCO Embassy Pictures, the film's financial backer, preferred either Charles Bronson or Tommy Lee Jones to play the role of Snake Plissken to Carpenter's choice of Kurt Russell, who was trying to overcome the "lightweight" screen image conveyed by his roles in several Disney comedies. Carpenter refused to cast Bronson on the grounds that he was too old, and because he worried that he could lose directorial control over the picture with an experienced actor. At the time, Russell described his character as "a mercenary, and his style of fighting is a combination of Bruce Lee, The Exterminator, and Darth Vader, with Eastwood's vocal-ness." All that matters to Snake, according to the actor, is "the next 60 seconds. Living for exactly that next minute is all there is." Russell used a rigorous diet and exercise program in order to develop a lean and muscular build. He also endeavored to stay in character between takes and throughout the shooting, as he welcomed the opportunity to get away from the Disney comedies he had done previously. He did find it necessary to remove the eyepatch between takes, as wearing it constantly seriously affected his depth perception.

Carpenter had just made "Dark Star" but no one wanted to hire him as a director, so he assumed that he would make it in Hollywood as a screenwriter. The filmmaker went on to do other films with the intention of making "Escape" later. After the success of "Halloween", Avco-Embassy signed him and producer Debra Hill to a two-picture deal. The first film from this contract was "The Fog". Initially, the second film that he was going to make to finish the contract was "The Philadelphia Experiment", but because of script-writing problems, Carpenter rejected it in favor of this project. However, Carpenter felt that something was missing and recalls, "This was basically a straight action film. And at one point, I realized it really doesn't have this kind of crazy humor that people from New York would expect to see." He brought in Nick Castle, a friend from his film school days at University of Southern California who played "The Shape" in "Halloween". Castle invented the Cabbie character and came up with the film's ending.

The film's setting proved to be a potential problem for Carpenter, who needed to create a decaying, semi-destroyed version of New York City on a shoe-string budget. He and the film's production designer Joe Alves rejected shooting on location in New York City because it would be too hard to make it look like a destroyed city. Carpenter suggested shooting on a movie back lot but Alves nixed that idea "because the texture of a real street is not like a back lot." They sent Barry Bernardi, their location manager (and associate producer), "on a sort of all-expense-paid trip across the country looking for the worst city in America," producer Debra Hill remembers.

Bernardi suggested East St. Louis, Illinois, because it was filled with old buildings "that exist in New York now, and [that] have that seedy run-down quality" that the team was looking for. East St. Louis, sitting across the Mississippi River from the more prosperous St. Louis, Missouri, had entire neighborhoods burned out in 1976 during a massive urban fire. Hill said in an interview, "block after block was burnt-out rubble. In some places there was absolutely nothing, so that you could see three and four blocks away." As well, Alves found an old bridge to double for the "69th St. Bridge". The filmmaker purchased the Old Chain of Rocks Bridge for one dollar from the government and then gave it back to them, for the same amount, once production was completed, "so that they wouldn't have any liability," Hill remembers. Locations across the river in St. Louis, Missouri were used, including Union Station and the Fox Theatre, both of which have since been renovated, as well as the building which would eventually become the Schlafly Tap Room microbrewery.

Carpenter and his crew persuaded the city to shut off the electricity to ten blocks at a time at night. The film was shot from August to November 1980. It was a tough and demanding shoot for the filmmaker as he recalls. "We'd finish shooting at about 6 am and I'd just be going to sleep at 7 when the sun would be coming up. I'd wake up around 5 or 6 pm, depending on whether or not we had dailies, and by the time I got going, the sun would be setting. So for about two and a half months I never saw daylight, which was really strange." The gladiatorial fight to the death scene between Snake and Slag (played by professional wrestler Ox Baker) was filmed in the Grand Hall at St. Louis Union Station. Russell has stated, "That day was a nightmare. All I did was swing a [spiked] bat at that guy and get swung at in return. He threw a trash can in my face about five times ... I could have wound up in pretty bad shape." In addition to shooting on location in St. Louis, Carpenter shot parts of the film in Los Angeles. Various interior scenes were shot on a sound stage; the final scenes were shot at the Sepulveda Dam, in Sherman Oaks. New York served as a location, as did Atlanta, to use their futuristic-looking rapid-transit system. In New York City, Carpenter persuaded federal officials to grant access to Liberty Island. "We were the first film company in history allowed to shoot on Liberty Island at the Statue of Liberty at night. They let us have the whole island to ourselves. We were lucky. It wasn't easy to get that initial permission. They'd had a bombing three months earlier and were worried about trouble".
Carpenter was interested in creating two distinct looks for the movie. "One is the police state, high tech, lots of neon, a United States dominated by underground computers. That was easy to shoot compared to the Manhattan Island prison sequences which had few lights, mainly torch lights, like feudal England". Certain matte paintings were rendered by James Cameron, who was at the time a special effects artist with Roger Corman's New World Pictures. Cameron was also one of the directors of photography on the film. As Snake pilots the glider into the city, there are three screens on his control panel displaying wireframe animations of the landing target on the World Trade Center and surrounding buildings. Carpenter wanted high-tech computer graphics, which were very expensive, even for such a simple animation. The effects crew filmed the miniature model set of New York City they used for other scenes under black light, with reflective tape placed along every edge of the model buildings. Only the tape is visible and appears to be a 3D wireframe animation.

"Escape from New York" opened in New York and Los Angeles July 10, 1981. The film grossed $25.2 million in American theaters in summer 1981. The film received generally positive reviews. As of April 2, 2018, it had a rating of 86% on Rotten Tomatoes, with the critical consensus "Featuring an atmospherically grimy futuristic metropolis, "Escape from New York" is a strange, entertaining jumble of thrilling action and oddball weirdness". "Newsweek" magazine wrote "[He has a] deeply ingrained B-movie sensibility - which is both his strength and limitation. He does clean work, but settles for too little. He uses Russell well, however". In "Time" magazine, Richard Corliss wrote, "John Carpenter is offering this summer's moviegoers a rare opportunity: to escape from the air-conditioned torpor of ordinary entertainment into the hothouse humidity of their own paranoia. It's a trip worth taking". Vincent Canby, in his review for "The New York Times", wrote, "[The film] is not to be analyzed too solemnly, though. It's a toughly told, very tall tale, one of the best escape (and escapist) movies of the season." In his review for the "Chicago Reader", Dave Kehr, wrote "it fails to satisfy–it gives us too little of too much".

Cyberpunk pioneer William Gibson credits the film as an influence on his novel "Neuromancer". "I was intrigued by the exchange in one of the opening scenes where the Warden says to Snake 'You flew the Gullfire over Leningrad, didn't you?' It turns out to be just a throwaway line, but for a moment it worked like the best SF where a casual reference can imply a lot." Popular videogame director Hideo Kojima has referred to the movie frequently as an influence on his work, in particular the "Metal Gear" series. Solid Snake is partially influenced by Snake Plissken. In "Metal Gear Solid 2: Sons of Liberty" Snake actually uses the alias "Pliskin" to hide his real identity during most of the game. J. J. Abrams, producer of the 2008 film "Cloverfield", mentioned that a scene in his film, which shows the head of the Statue of Liberty crashing into a New York street, was inspired by the poster for "Escape from New York". "Empire" magazine ranked Snake Plissken #29 in their "The 100 Greatest Movie Characters" poll.

"Escape from New York" was released numerous times on VHS during the 1980s and 1990s.

"Escape from New York" was released on DVD twice by MGM (USA), and once by Momentum Pictures (UK). One MGM release is a barebones edition containing just the theatrical trailer. Another version is the Collector's Edition, a two-disc set featuring a High Definition remastered transfer with a 5.1 Stereo audio track, two commentaries (one by John Carpenter and Kurt Russell, another by producer Debra Hill and Joe Alves), a making-of featurette, the first issue of a comic book series titled "John Carpenter's Snake Plissken Chronicles", and the ten-minute Colorado bank robbery deleted opening sequence.

MGM's special edition of the 1981 film was not released until 2003 because the original negative had disappeared. The workprint containing deleted scenes finally turned up in the Hutchinson, Kansas salt mine film depository. The excised scenes feature Snake Plissken robbing a bank, introducing the character of Plissken and establishing a backstory. Director John Carpenter decided to add the original scenes into the special edition release as an extra only: "After we screened the rough cut, we realized that the movie didn't really start until Snake got to New York. It wasn't necessary to show what sent him there." The film has been released on the UMD format for Sony's PlayStation Portable.

On August 3, 2010, MGM Home Entertainment released "Escape From New York" as a bare-bones Blu-ray. Scream Factory, in association with Shout! Factory, released the film on a special edition Blu-ray on April 21, 2015.

In 1981, Bantam Books published a movie tie-in novelization written by Mike McQuay that adopts a lean, humorous style reminiscent of the film. The novel is significant because it includes scenes that were cut out of the film, such as the Federal Reserve Depository robbery that results in Snake's incarceration. The novel provides motivation and backstory to Snake and Hauk — both disillusioned war veterans — deepening their relationship that was only hinted at it in the film. The novel explains how Snake lost his eye during the Battle for Leningrad in World War III, how Hauk became warden of New York, and Hauk's quest to find his crazy son who lives somewhere in the prison. The novel fleshes out the world that these characters exist in, at times presenting a future even bleaker than the one depicted in the film. The book explains that the West Coast is a no-man's land, and the country's population is gradually being driven crazy by nerve gas as a result of World War III.

Marvel Comics released the one-shot "The Adventures of Snake Plissken" in January 1997. The story takes place sometime between "Escape from New York" and before his famous Cleveland escape mentioned in "Escape from L.A." Snake has robbed Atlanta's Center for Disease Control of some engineered metaviruses and is looking for buyers in Chicago. Finding himself in a deal that's really a set-up, he makes his getaway and exacts revenge on the buyer for ratting him out to the United States Police Force. In the meantime, a government lab has built a robot called A.T.A.C.S. (Autonomous Tracking And Combat System) that can catch criminals by imprinting their personalities upon its program in order to predict and anticipate a specific criminal's every move. The robot's first test subject is America's public enemy number one, Snake Plissken. After a brief battle, the tide turns when A.T.A.C.S. copies Snake to the point of fully becoming his personality. Now recognizing the government as the enemy, A.T.A.C.S. sides with Snake. Unamused, Snake sucker punches the machine and destroys it. As A.T.A.C.S. shuts down, it can only ask him, "Why?" Snake just walks off answering, "I don't need the competition".

In 2003, CrossGen published "John Carpenter's Snake Plissken Chronicles", a four-part comic book miniseries. The story takes place a day or so after the events of "Escape from New York". Snake has been given a military Humvee after his presidential pardon and makes his way to Atlantic City. Although the director's cut of "Escape from New York" shows Snake was caught after a bank job, this story has Snake finishing up a second heist that was pre-planned before his capture. The job entails stealing the car in which John F. Kennedy was assassinated from a casino before delivering it to a buyer in the Gulf of Mexico. Snake partners with a man named Marrs who ends up double crossing him. Left for dead in a sinking crab cage, Snake escapes and is saved by a passing fisherman named Captain Ron (an in-joke referring to Kurt Russell's 1992 comedy, "Captain Ron"). When Ron denies Snake's request to use his boat in order to beat Marrs to the robbery, Snake decides to kill him. When Snake ends up saving Ron from the Russian mob who wants money, Ron changes his mind and helps Snake. Once at the casino, Snake comes face-to-face with Marrs and his men, who arrive at the same time, ending in a high-speed shootout. Snake gets away with the car and its actress portraying Jackie Kennedy, leaving Marrs to be caught by the casino owner, who cuts him a deal to bring his car back and live. After some trouble, Snake manages to finally get the car to the buyer's yacht, using Ron's boat, and is then attacked by Marrs. Following the firefight, the yacht and car are destroyed, Marrs and Captain Ron are dead, and Snake makes his escape in a helicopter with the 30 million credits owed to him for the job.

In 2014, BOOM! Studios began publishing an "Escape From New York" comic book by writer, Christopher Sebela. The first issue of the series was released on December 3, 2014 and the story picks up moments after the end of the film.

BOOM! will release a crossover comics miniseries between Snake and Jack Burton titled "Big Trouble in Little China / Escape from New York" in October 2016.

An "Escape from New York" board game was released in 1981 by TSR, Inc.

Carpenter was planning an anime spin-off of "Escape from New York", with "Outlaw Star"s Mitsuru Hongo slated to direct. However, nothing new has emerged since that announcement.

A sequel, "Escape from L.A.", was released in 1996, with Carpenter returning along with Russell, now also acting as producer and co-writer.



</doc>
<doc id="9837" url="https://en.wikipedia.org/wiki?curid=9837" title="Ethylene">
Ethylene

Ethylene (IUPAC name: ethene) is a hydrocarbon which has the formula or HC=CH. It is a colorless flammable gas with a faint "sweet and musky" odour when pure. It is the simplest alkene (a hydrocarbon with carbon-carbon double bonds).

Ethylene is widely used in the chemical industry, and its worldwide production (over 150 million tonnes in 2016) exceeds that of any other organic compound. Much of this production goes toward polyethylene, a widely used plastic containing polymer chains of ethylene units in various chain lengths. Ethylene is also an important natural plant hormone, and is used in agriculture to force the ripening of fruits. Ethylene's hydrate is ethanol.

This hydrocarbon has four hydrogen atoms bound to a pair of carbon atoms that are connected by a double bond. All six atoms that comprise ethylene are coplanar. The H-C-H angle is 117.4°, close to the 120° for ideal sp² hybridized carbon. The molecule is also relatively rigid: rotation about the C-C bond is a high energy process that requires breaking the π-bond.

The π-bond in the ethylene molecule is responsible for its useful reactivity. The double bond is a region of high electron density, thus it is susceptible to attack by electrophiles. Many reactions of ethylene are catalyzed by transition metals, which bind transiently to the ethylene using both the π and π* orbitals.

Being a simple molecule, ethylene is spectroscopically simple. Its UV-vis spectrum is still used as a test of theoretical methods.

Major industrial reactions of ethylene include in order of scale: 1) polymerization, 2) oxidation, 3) halogenation and hydrohalogenation, 4) alkylation, 5) hydration, 6) oligomerization, and 7) hydroformylation. In the United States and Europe, approximately 90% of ethylene is used to produce ethylene oxide, ethylene dichloride, ethylbenzene and polyethylene. Most of the reactions with ethylene are electrophilic addition.

Polyethylene consumes more than half of the world's ethylene supply. Polyethylene, also called "polyethene", is the world's most widely used plastic. It is primarily used to make films in packaging, carrier bags and trash liners. Linear alpha-olefins, produced by oligomerization (formation of short polymers) are used as precursors, detergents, plasticisers, synthetic lubricants, additives, and also as co-monomers in the production of polyethylenes.

Ethylene is oxidized to produce ethylene oxide, a key raw material in the production of surfactants and detergents by ethoxylation. Ethylene oxide is also hydrolyzed to produce ethylene glycol, widely used as an automotive antifreeze as well as higher molecular weight glycols, glycol ethers and polyethylene terephthalate.
Ethylene undergoes oxidation by palladium to give acetaldehyde. This conversion remains a major industrial process (10M kg/y). The process proceeds via the initial complexation of ethylene to a Pd(II) center.

Major intermediates from the halogenation and hydrohalogenation of ethylene include ethylene dichloride, ethyl chloride and ethylene dibromide. The addition of chlorine entails "oxychlorination," i.e. chlorine itself is not used. Some products derived from this group are polyvinyl chloride, trichloroethylene, perchloroethylene, methyl chloroform, polyvinylidene chloride and copolymers, and ethyl bromide.

Major chemical intermediates from the alkylation with ethylene is ethylbenzene, precursor to styrene. Styrene is used principally in polystyrene for packaging and insulation, as well as in styrene-butadiene rubber for tires and footwear. On a smaller scale, ethyltoluene, ethylanilines, 1,4-hexadiene, and aluminium alkyls. Products of these intermediates include polystyrene, unsaturated polyesters and ethylene-propylene terpolymers.

The hydroformylation (oxo reaction) of ethylene results in propionaldehyde, a precursor to propionic acid and n-propyl alcohol.

Ethylene has long represented the major nonfermentative precursor to ethanol. The original method entailed its conversion to diethyl sulfate, followed by hydrolysis. The main method practiced since the mid-1990s is the direct hydration of ethylene catalyzed by solid acid catalysts:

Ethylene is dimerized by hydrovinylation to give "n"-butenes using processes licensed by Lummus or IFP. The Lummus process produces mixed "n"-butenes (primarily 2-butenes) while the IFP process produces 1-butene. 1-Butene is used as a comonomer in the production of certain kinds of polyethylene.

An example of a niche use is as an anesthetic agent (in an 85% ethylene/15% oxygen ratio). It can also be used to hasten fruit ripening, as well as a welding gas.

Global ethylene production was 107 million tonnes in 2005, 109 million tonnes in 2006, 138 million tonnes in 2010 and 141 million tonnes in 2011. By 2013 ethylene was produced by at least 117 companies in 32 countries. To meet the ever-increasing demand for ethylene, sharp increases in production facilities are added globally, particularly in the Mideast and in China.

Ethylene is produced in the petrochemical industry by steam cracking. In this process, gaseous or light liquid hydrocarbons are heated to 750–950 °C, inducing numerous free radical reactions followed by immediate quench to stop these reactions. This process converts large hydrocarbons into smaller ones and introduces unsaturation. Ethylene is separated from the resulting mixture by repeated compression and distillation. In a related process used in oil refineries, high molecular weight hydrocarbons are cracked over zeolite catalysts. Heavier feedstocks, such as naphtha and gas oils require at least two "quench towers" downstream of the cracking furnaces to recirculate pyrolysis-derived gasoline and process water. When cracking a mixture of ethane and propane, only one water quench tower is required.

The areas of an ethylene plant are:

Since ethylene production is energy intensive, much effort has been dedicated to recovering heat from the gas leaving the furnaces. Most of the energy recovered from the cracked gas is used to make high pressure (1200 psig) steam. This steam is in turn used to drive the turbines for compressing cracked gas, the propylene refrigeration compressor, and the ethylene refrigeration compressor. An ethylene plant, once running, does not need to import steam to drive its steam turbines. A typical world scale ethylene plant (about 1.5 billion pounds of ethylene per year) uses a cracked gas compressor, a propylene compressor, and a ethylene compressor.

Although of great value industrially, ethylene is rarely synthesized in the laboratory and is ordinarily purchased. 
It can be produced via dehydration of ethanol with sulfuric acid or in the gas phase with aluminium oxide.

Ethylene serves as a hormone in plants. It acts at trace levels throughout the life of the plant by stimulating or regulating the ripening of fruit, the opening of flowers, and the abscission (or shedding) of leaves.
Commercial ripening rooms use "catalytic generators" to make ethylene gas from a liquid supply of ethanol. Typically, a gassing level of 500 to 2,000 ppm is used, for 24 to 48 hours. Care must be taken to control carbon dioxide levels in ripening rooms when gassing, as high temperature ripening () has been seen to produce CO levels of 10% in 24 hours.

Ethylene has been used since the ancient Egyptians, who would gash figs in order to stimulate ripening (wounding stimulates ethylene production by plant tissues). The ancient Chinese would burn incense in closed rooms to enhance the ripening of pears. In 1864, it was discovered that gas leaks from street lights led to stunting of growth, twisting of plants, and abnormal thickening of stems. In 1901, a Russian scientist named Dimitry Neljubow showed that the active component was ethylene. Sarah Doubt discovered that ethylene stimulated abscission in 1917. Farmers in Florida would commonly get their crops to ripen in sheds by lighting kerosine lamps, which was originally thought to induce ripening from the heat. In 1924, Frank E. Denny discovered that it was the molecule ethylene emitted by the kerosene lamps that induced the ripening. It was not until 1934 that Gane reported that plants synthesize ethylene. In 1935, Crocker proposed that ethylene was the plant hormone responsible for fruit ripening as well as senescence of vegetative tissues.

Ethylene is produced from essentially all parts of higher plants, including leaves, stems, roots, flowers, fruits, tubers, and seeds.
Ethylene production is regulated by a variety of developmental and environmental factors. During the life of the plant, ethylene production is induced during certain stages of growth such as germination, ripening of fruits, abscission of leaves, and senescence of flowers. Ethylene production can also be induced by a variety of external aspects such as mechanical wounding, environmental stresses, and certain chemicals including auxin and other regulators. The pathway for ethylene biosynthesis is named the Yang cycle after the scientist Shang Fa Yang who made key contributions to elucidating this pathway.

Ethylene is biosynthesized from the amino acid methionine to "S"-adenosyl--methionine (SAM, also called Adomet) by the enzyme Met Adenosyltransferase. SAM is then converted to 1-aminocyclopropane-1-carboxylic acid (ACC) by the enzyme ACC synthase (ACS). The activity of ACS determines the rate of ethylene production, therefore regulation of this enzyme is key for the ethylene biosynthesis. The final step requires oxygen and involves the action of the enzyme ACC-oxidase (ACO), formerly known as the ethylene forming enzyme (EFE). Ethylene biosynthesis can be induced by endogenous or exogenous ethylene. ACC synthesis increases with high levels of auxins, especially indole acetic acid (IAA) and cytokinins.

Ethylene is perceived by a family of five transmembrane protein dimers such as the ETR1 protein in "Arabidopsis". The genes encoding ethylene receptors have been cloned in the reference plant "Arabidopsis thaliana" and many other plants. Ethylene receptors are encoded by multiple genes in plant genomes. Dominant missense mutations in any of the gene family, which comprises five receptors in "Arabidopsis" and at least six in tomato, can confer insensitivity to ethylene. Loss-of-function mutations in multiple members of the ethylene-receptor family result in a plant that exhibits constitutive ethylene responses. DNA sequences for ethylene receptors have also been identified in many other plant species and an ethylene binding protein has even been identified in Cyanobacteria.

A large portion of the soil has been affected by over salinity and it has been known to limit the growth of many plants. Globally, the total area of saline soil was 397,000,000 ha and in continents like Africa, it makes up 2 percent of the soil. The amount of soil salinization has reached 19.5% of the irrigated land and 2.1% of the dry-land agriculture around the world. Soil salinization affects the plants using osmotic potential by net solute accumulation. The osmotic pressure in the plant is what maintains water uptake and cell turgor to help with stomatal function and other cellular mechanisms. Over generations, many plant genes have adapted, allowing plants’ phenotypes to change and built different mechanisms to counter salinity effects.

The plant hormone ethylene is a combatant for salinity in most plants. Ethylene is known for regulating plant growth and development and adapted to stress conditions. Central membrane proteins in plants, such as ETO2, ERS1 and EIN2, are used for ethylene signaling in many plant growth processes. ETO2, Ethylene overproducer 2, is a protein that when mutated it will gain a function to continually produce ethylene even when there is no stress condition, causing the plant to grow short and stumpy. ERS1, Ethylene response sensor 1, is activated when ethylene is present in the signaling pathway and when mutated, it loses a function and cannot bind to ethylene. This means a response is never activated and the plant will not be able to cope with the abiotic stress. EIN2, Ethylene insensitive 2, is a protein that activates the pathway and when there is a mutation here the EIN2 will block ethylene stimulation and an ethylene response gene will not be activated. Mutations in these proteins can lead to heightened salt sensitivity and limit plant growth. The effects of salinity have been studied on "Arabidopsis" plants that have mutated ERS1 and EIN4 proteins. These proteins are used for ethylene signaling again certain stress conditions, such as salt and the ethylene precursor ACC is allowing suppress of any sensitivity to the salt stress. Mutations in these pathways can cause lack of ethylene signaling, causing stunt in plant growth and development.

Environmental cues such as flooding, drought, chilling, wounding, and pathogen attack can induce ethylene formation in plants. In flooding, roots suffer from lack of oxygen, or anoxia, which leads to the synthesis of 1-aminocyclopropane-1-carboxylic acid (ACC). ACC is transported upwards in the plant and then oxidized in leaves. The ethylene produced causes nastic movements (epinasty) of the leaves, perhaps helping the plant to lose water.


Ethylene shortens the shelf life of many fruits by hastening fruit ripening and floral senescence. Ethylene will shorten the shelf life of cut flowers and potted plants by accelerating floral senescence and floral abscission. Flowers and plants which are subjected to stress during shipping, handling, or storage produce ethylene causing a significant reduction in floral display. Flowers affected by ethylene include carnation, geranium, petunia, rose, and many others.

Ethylene can cause significant economic losses for florists, markets, suppliers, and growers. Researchers have developed several ways to inhibit ethylene, including inhibiting ethylene synthesis and inhibiting ethylene perception. Aminoethoxyvinylglycine (AVG), Aminooxyacetic acid (AOA), and silver salts are ethylene inhibitors. Inhibiting ethylene synthesis is less effective for reducing post-harvest losses since ethylene from other sources can still have an effect. By inhibiting ethylene perception, fruits, plants and flowers don't respond to ethylene produced endogenously or from exogenous sources. Inhibitors of ethylene perception include compounds that have a similar shape to ethylene, but do not elicit the ethylene response. One example of an ethylene perception inhibitor is 1-methylcyclopropene (1-MCP).

Commercial growers of bromeliads, including pineapple plants, use ethylene to induce flowering. Plants can be induced to flower either by treatment with the gas in a chamber, or by placing a banana peel next to the plant in an enclosed area.

Chrysanthemum flowering is delayed by ethylene gas and growers have found that carbon dioxide 'burners' and the exhaust fumes from inefficient glasshouse heaters can raise the ethylene concentration to 0.05 ppmv causing delay in flowering of commercial crops.

Ethylene is a ligand in organometallic chemistry. One of the first organometallic compounds, Zeise's salt is a complex of ethylene. Useful reagents containing ethylene include Pt(PPh)(CH) and RhCl(CH). The Rh-catalysed hydroformylation of ethylene is conducted on industrial scale to provide propionaldehyde.

Some geologists and scholars believe that the famous Greek Oracle at Delphi (the Pythia) went into her trance-like state as an effect of ethylene rising from ground faults.

Ethylene appears to have been discovered by Johann Joachim Becher, who obtained it by heating ethanol with sulfuric acid; he mentioned the gas in his "Physica Subterranea" (1669). Joseph Priestley also mentions the gas in his "Experiments and observations relating to the various branches of natural philosophy: with a continuation of the observations on air" (1779), where he reports that Jan Ingenhousz saw ethylene synthesized in the same way by a Mr. Enée in Amsterdam in 1777 and that Ingenhousz subsequently produced the gas himself. The properties of ethylene were studied in 1795 by four Dutch chemists, Johann Rudolph Deimann, Adrien Paets van Troostwyck, Anthoni Lauwerenburgh and Nicolas Bondt, who found that it differed from hydrogen gas and that it contained both carbon and hydrogen. This group also discovered that ethylene could be combined with chlorine to produce the "oil of the Dutch chemists", 1,2-dichloroethane; this discovery gave ethylene the name used for it at that time, "olefiant gas" (oil-making gas.)

In the mid-19th century, the suffix "-ene" (an Ancient Greek root added to the end of female names meaning "daughter of") was widely used to refer to a molecule or part thereof that contained one fewer hydrogen atoms than the molecule being modified. Thus, "ethylene" () was the "daughter of ethyl" (). The name ethylene was used in this sense as early as 1852.

In 1866, the German chemist August Wilhelm von Hofmann proposed a system of hydrocarbon nomenclature in which the suffixes -ane, -ene, -ine, -one, and -une were used to denote the hydrocarbons with 0, 2, 4, 6, and 8 fewer hydrogens than their parent alkane. In this system, ethylene became "ethene". Hofmann's system eventually became the basis for the Geneva nomenclature approved by the International Congress of Chemists in 1892, which remains at the core of the IUPAC nomenclature. However, by that time, the name ethylene was deeply entrenched, and it remains in wide use today, especially in the chemical industry.

Following experimentation by Luckhardt, Crocker, and Carter at the University of Chicago, ethylene was used as an anesthetic It remained in use through the 1940s use even while chloroform was being phased out. Its pungent odor and its explosive nature limit its use today.

The 1979 IUPAC nomenclature rules made an exception for retaining the non-systematic name ethylene, however, this decision was reversed in the 1993 rules so the IUPAC name is now "ethene".

Like all hydrocarbons, ethylene is an asphyxiant and combustible. It is listed as an IARC class 3 carcinogen as there is no evidence at present that it causes cancer in humans.




</doc>
<doc id="9838" url="https://en.wikipedia.org/wiki?curid=9838" title="Eiffel (programming language)">
Eiffel (programming language)

Eiffel is an object-oriented programming language designed by Bertrand Meyer (an object-orientation proponent and author of "Object-Oriented Software Construction") and Eiffel Software. Meyer conceived the language in 1985 with the goal of increasing the reliability of commercial software development; the first version becoming available in 1986. In 2005, Eiffel became an ISO-standardized language.

The design of the language is closely connected with the Eiffel programming method. Both are based on a set of principles, including design by contract, command–query separation, the uniform-access principle, the single-choice principle, the open–closed principle, and option–operand separation.

Many concepts initially introduced by Eiffel later found their way into Java, C#, and other languages. New language design ideas, particularly through the Ecma/ISO standardization process, continue to be incorporated into the Eiffel language.

The key characteristics of the Eiffel language include:


Eiffel emphasizes declarative statements over procedural code and attempts to eliminate the need for bookkeeping instructions.

Eiffel shuns coding tricks or coding techniques intended as optimization hints to the compiler. The aim is not only to make the code more readable, but also to allow programmers to concentrate on the important aspects of a program without getting bogged down in implementation details. Eiffel's simplicity is intended to promote simple, extensible, reusable, and reliable answers to computing problems. Compilers for computer programs written in Eiffel provide extensive optimization techniques, such as automatic in-lining, that relieve the programmer of part of the optimization burden.

Eiffel was originally developed by Eiffel Software, a company founded by Bertrand Meyer. "Object-Oriented Software Construction" contains a detailed treatment of the concepts and theory of the object technology that led to Eiffel's design.

The design goal behind the Eiffel language, libraries, and programming methods is to enable programmers to create reliable, reusable software modules. Eiffel supports multiple inheritance, genericity, polymorphism, encapsulation, type-safe conversions, and parameter covariance. Eiffel's most important contribution to software engineering is design by contract (DbC), in which assertions, preconditions, postconditions, and class invariants are employed to help ensure program correctness without sacrificing efficiency.

Eiffel's design is based on object-oriented programming theory, with only minor influence of other paradigms or concern for support of legacy code. Eiffel formally supports abstract data types. Under Eiffel's design, a software text should be able to reproduce its design documentation from the text itself, using a formalized implementation of the "Abstract Data Type".

EiffelStudio is an integrated development environment available under either an open source or a commercial license. It offers an object-oriented environment for software engineering. EiffelEnvision is a plug-in for Microsoft Visual Studio that allows users to edit, compile, and debug Eiffel projects from within the Microsoft Visual Studio IDE. Five other open source implementations are available: "The Eiffel Compiler" tecomp; Gobo Eiffel; SmartEiffel, the GNU implementation, based on an older version of the language; LibertyEiffel, based on the SmartEiffel compiler; and Visual Eiffel.

Several other programming languages incorporate elements first introduced in Eiffel. Sather, for example, was originally based on Eiffel but has since diverged, and now includes several functional programming features. The interactive-teaching language Blue, forerunner of BlueJ, is also Eiffel-based. The Apple Media Tool includes an Eiffel-based Apple Media Language.

The Eiffel language definition is an international standard of the ISO. The standard was developed by ECMA International, which first approved the standard on 21 June 2005 as Standard ECMA-367, Eiffel: Analysis, Design and Programming Language. In June 2006, ECMA and ISO adopted the second version. In November 2006, ISO first published that version. The standard can be found and used free of charge on the ECMA site. The ISO version is identical in all respects except formatting.

Eiffel Software, "The Eiffel Compiler" tecomp and Eiffel-library-developer Gobo have committed to implementing the standard; Eiffel Software's EiffelStudio 6.1 and "The Eiffel Compiler" tecomp implement some of the major new mechanisms—in particular, inline agents, assigner commands, bracket notation, non-conforming inheritance, and attached types. The SmartEiffel team has turned away from this standard to create its own version of the language, which they believe to be closer to the original style of Eiffel. Object Tools has not disclosed whether future versions of its Eiffel compiler will comply with the standard. LibertyEiffel implements a dialect somewhere in between the SmartEiffel language and the standard.

The standard cites the following, predecessor Eiffel-language specifications:


The current version of the standard from June 2006 contains some inconsistencies (e.g. covariant redefinitions). The ECMA committee has not yet announced any timeline and direction on how to resolve the inconsistencies.

An Eiffel "system" or "program" is a collection of "classes". Above the level of classes, Eiffel defines "cluster", which is essentially a group of classes, and possibly of "subclusters" (nested clusters). Clusters are not a syntactic language construct, but rather a standard organizational convention. Typically an Eiffel program will be organized with each class in a separate file, and each cluster in a directory containing class files. In this organization, subclusters are subdirectories. For example, under standard organizational and casing conventions, codice_1 might be the name of a file that defines a class called X.

A class contains "features", which are similar to "routines", "members", "attributes" or "methods" in other object-oriented programming languages. A class also defines its invariants, and contains other properties, such as a "notes" section for documentation and metadata. Eiffel's standard data types, such as codice_2, codice_3 and codice_4, are all themselves classes.

Every system must have a class designated as "root", with one of its creation procedures designated as "root procedure". Executing a system consists of creating an instance of the root class and executing its root procedure. Generally, doing so creates new objects, calls new features, and so on.

Eiffel has five basic executable instructions: assignment, object creation, routine call, condition, and iteration. Eiffel's control structures are strict in enforcing structured programming: every block has exactly one entry and exactly one exit.

Unlike many object-oriented languages, but like Smalltalk, Eiffel does not permit any assignment into attributes of objects, except within the features of an object, which is the practical application of the principle of information hiding or data abstraction, requiring formal interfaces for data mutation. To put it in the language of other object-oriented programming languages, all Eiffel attributes are "protected", and "setters" are needed for client objects to modify values. An upshot of this is that "setters" can, and normally do, implement the invariants for which Eiffel provides syntax.

While Eiffel does not allow direct access to the features of a class by a client of the class, it does allow for the definition of an "assigner command", such as:

While a slight bow to the overall developer community to allow something looking like direct access (e.g. thereby breaking the Information Hiding Principle), the practice is dangerous as it hides or obfuscates the reality of a "setter" being used. In practice, it is better to redirect the call to a setter rather than implying a direct access to a feature like codice_5 as in the example code above.

Unlike other languages, having notions of "public", "protected", "private" and so on, Eiffel uses an exporting technology to more precisely control the scoping between client and supplier classes. Feature visibility is checked statically at compile-time. For example, (below), the "{NONE}" is similar to "protected" in other languages. Scope applied this way to a "feature set" (e.g. everything below the 'feature' keyword to either the next feature set keyword or the end of the class) can be changed in descendant classes using the "export" keyword.
feature {NONE} -- Initialization
Alternatively, the lack of a {x} export declaration implies {ANY} and is similar to the "public" scoping of other languages.
feature -- Constants
Finally, scoping can be selectively and precisely controlled to any class in the Eiffel project universe, such as:
feature {DECIMAL, DCM_MA_DECIMAL_PARSER, DCM_MA_DECIMAL_HANDLER} -- Access
Here, the compiler will allow only the classes listed between the curly braces to access the features within the feature group (e.g. DECIMAL, DCM_MA_DECIMAL_PARSER, DCM_MA_DECIMAL_HANDLER).

A programming language's look and feel is often conveyed using a "Hello, world!" program. Such a program written in Eiffel might be:

class
create
feature
end 
This program contains the class codice_6. The constructor (create routine) for the class, named codice_7, invokes the codice_8 system library routine to write a codice_9 codice_10 message to the output.

The concept of Design by Contract is central to Eiffel. The contracts assert what must be true before a routine is executed (precondition) and what must hold to be true after the routine finishes (post-condition). Class Invariant contracts define what assertions must hold true both before and after any feature of a class is accessed (both routines and attributes). Moreover, contracts codify into executable code developer and designers assumptions about the operating environment of the features of a class or the class as a whole by means of the invariant.

The Eiffel compiler is designed to include the feature and class contracts in various levels. EiffelStudio, for example, executes all feature and class contracts during execution in the "Workbench mode." When an executable is created, the compiler is instructed by way of the project settings file (e.g. ECF file) to either include or exclude any set of contracts. Thus, an executable file can be compiled to either include or exclude any level of contract, thereby bringing along continuous levels of unit and integration testing. Moreover, contracts can be continually and methodically exercised by way of the Auto-Test feature found in EiffelStudio.

The Design by Contract mechanisms are tightly integrated with the language and guide redefinition of features in inheritance:


In addition, the language supports a "check instruction" (a kind of "assert"), loop invariants, and loop variants (which guarantee loop termination).

Void-safety, like static typing, is another facility for improving software quality. Void-safe software is protected from run time errors caused by calls to void references, and therefore will be more reliable than software in which calls to void targets can occur. The analogy to static typing is a useful one. In fact, void-safe capability could be seen as an extension to the type system, or a step beyond static typing, because the mechanism for ensuring void-safety is integrated into the type system.

The guard against void target calls can be seen by way of the notion of attachment and (by extension) detachment (e.g. detachable keyword). The void-safe facility can be seen in a short re-work of the example code used above:

The code example above shows how the compiler can statically address the reliability of whether codice_5 will be attached or detached at the point it is used. Notably, the codice_12 keyword allows for an "attachment local" (e.g. codice_13), which is scoped to only the block of code enclosed by the if-statement construct. Thus, within this small block of code, the local variable (e.g. codice_13) can be statically guaranteed to be non-void (i.e. void-safe).

The primary characteristic of a class is that it defines a set of features: as a class represents a set of run-time objects, or "instances", a feature is an operation on these objects. There are two kinds of features: queries and commands. A query provides information about an instance. A command modifies an instance.

The command-query distinction is important to the Eiffel method. In particular:


Eiffel does not allow argument overloading. Each feature name within a class always maps to a specific feature within the class. One name, within one class, means one thing. This design choice helps the readability of classes, by avoiding a cause of ambiguity about which routine will be invoked by a call. It also simplifies the language mechanism; in particular, this is what makes Eiffel's multiple inheritance mechanism possible.

Names can, of course, be reused in different classes. For example, the feature plus (along with its infix alias "+") is defined in several classes: INTEGER, REAL, STRING, etc.

A generic class is a class that varies by type (e.g. LIST [PHONE], a list of phone numbers; ACCOUNT [G->ACCOUNT_TYPE], allowing for ACCOUNT [SAVINGS] and ACCOUNT [CHECKING], etc.). Classes can be generic, to express that they are parameterized by types. Generic parameters appear in square brackets:
class LIST [G] ...
G is known as a "formal generic parameter". (Eiffel reserves "argument" for routines, and uses "parameter" only for generic classes.) With such a declaration G represents within the class an arbitrary type; so a function can return a value of type G, and a routine can take an argument of that type:
item: G do ... end
put (x: G) do ... end
The codice_17 and codice_18 are "generic derivations" of this class. Permitted combinations (with codice_19, codice_20, codice_21, codice_22) are:
n := il.item
wl.put (w)
codice_2 and codice_24 are the "actual generic parameters" in these generic derivations.

It is also possible to have 'constrained' formal parameters, for which the actual parameter must inherit from a given class, the "constraint". For example, in
a derivation codice_25 is valid only if codice_3 inherits from codice_27 (as it indeed does in typical Eiffel libraries). Within the class, having codice_28 constrained by codice_27 means that for codice_30 it is possible to apply to codice_31 all the features of codice_27, as in codice_33.

To inherit from one or more others, a class will include an codice_34 clause at the beginning:
class C inherit

-- ... Rest of class declaration ...
The class may redefine (override) some or all of the inherited features. This must be explicitly announced at the beginning of the class through a codice_35 subclause of the inheritance clause, as in
class C inherit
See for a complete discussion of Eiffel inheritance.

Classes may be defined with codice_36 rather than with codice_37 to indicate that the class may not be directly instantiated. Non-instantiatable classes are called abstract classes in some other object-oriented programming languages. In Eiffel parlance, only an "effective" class can be instantiated (it may be a descendent of a deferred class). A feature can also be deferred by using the codice_38 keyword in place of a codice_39 clause. If a class has any deferred features it must be declared as deferred; however, a class with no deferred features may nonetheless itself be deferred.

Deferred classes play some of the same role as interfaces in languages such as Java, though many object-oriented programming theorists believe interfaces are themselves largely an answer to Java's lack of multiple inheritance (which Eiffel has).

A class that inherits from one or more others gets all its features, by default under their original names. It may, however, change their names through codice_40 clauses. This is required in the case of multiple inheritance if there are name clashes between inherited features; without renaming, the resulting class would violate the no-overloading principle noted above and hence would be invalid.

Tuples types may be viewed as a simple form of class, providing only attributes and the corresponding "setter" procedure. A typical tuple type reads
and could be used to describe a simple notion of birth record if a class is not needed. An instance of such a tuple is simply a sequence of values with the given types, given in brackets, such as
Components of such a tuple can be accessed as if the tuple tags were attributes of a class, for example if codice_41 has been assigned the above tuple then codice_42 has value 3.5.

Thanks to the notion of assigner command (see below), dot notation can also be used to assign components of such a tuple, as in

The tuple tags are optional, so that it is also possible to write a tuple type as codice_43. (In some compilers this is the only form of tuple, as tags were introduced with the ECMA standard.)

The precise specification of e.g. codice_44 is that it describes sequences of "at least" three elements, the first three being of types codice_45, codice_46, codice_47 respectively. As a result, codice_44 conforms to (may be assigned to) codice_49, to codice_50 and to codice_51 (without parameters), the topmost tuple type to which all tuple types conform.

Eiffel's "agent" mechanism wraps operations into objects. This mechanism can be used for iteration, event-driven programming, and other contexts in which it is useful to pass operations around the program structure. Other programming languages, especially ones that emphasize functional programming, allow a similar pattern using continuations, closures, or generators; Eiffel's agents emphasize the language's object-oriented paradigm, and use a syntax and semantics similar to code blocks in Smalltalk and Ruby.

For example, to execute the codice_52 block for each element of codice_53, one would write:
To execute codice_52 only on elements satisfying codice_55, a limitation/filter can be added:
In these examples, codice_52 and codice_55 are routines. Prefixing them with codice_58 yields an object that represents the corresponding routine with all its properties, in particular the ability to be called with the appropriate arguments. So if codice_59 represents that object (for example because codice_59 is the argument to codice_61), the instruction
will call the original routine with the argument codice_31, as if we had directly called the original routine: codice_63. Arguments to codice_64 are passed as a tuple, here codice_65.

It is possible to keep some arguments to an agent open and make others closed. The open arguments are passed as arguments to codice_64: they are provided at the time of "agent use". The closed arguments are provided at the time of agent "definition". For example, if codice_67 has two arguments, the iteration
iterates codice_68 for successive values of codice_31, where the second argument remains set to codice_70. The question mark codice_71 indicates an open argument; codice_70 is a closed argument of the agent. Note that the basic syntax codice_73 is a shorthand for codice_74 with all arguments open. It is also possible to make the "target" of an agent open through the notation codice_75 where codice_76 is the type of the target.

The distinction between open and closed operands (operands = arguments + target) corresponds to the distinction between bound and free variables in lambda calculus. An agent expression such as codice_77 with some operands closed and some open corresponds to a version of the original operation "curried" on the closed operands.

The agent mechanism also allows defining an agent without reference to an existing routine (such as codice_52, codice_55, codice_67), through inline agents as in
my_list.do_all (agent (s: STRING)
The inline agent passed here can have all the trappings of a normal routine, including precondition, postcondition, rescue clause (not used here), and a full signature. This avoids defining routines when all that's needed is a computation to be wrapped in an agent. This is useful in particular for contracts, as in an invariant clause that expresses that all elements of a list are positive:
The current agent mechanism leaves a possibility of run-time type error (if a routine with "n" arguments is passed to an agent expecting "m" arguments with "m" < "n"). This can be avoided by a run-time check through the precondition codice_81 of codice_64. Several proposals for a purely static correction of this problem are available, including a language change proposal by Ribet et al.

A routine's result can be cached using the codice_83 keyword in place of codice_39. Non-first calls to a routine require no additional computation or resource allocation, but simply return a previously computed result. A common pattern for "once functions" is to provide shared objects; the first call will create the object, subsequent ones will return the reference to that object. The typical scheme is:
shared_object: SOME_TYPE
The returned object—codice_85 in the example—can itself be mutable, but its reference remains the same.

Often "once routines" perform a required initialization: multiple calls to a library can include a call to the initialization procedure, but only the first such call will perform the required actions. Using this pattern initialization can be decentralized, avoiding the need for a special initialization module. "Once routines" are similar in purpose and effect to the singleton pattern in many programming languages, and to the used in Python.

By default, a "once routine" is called "once per thread". The semantics can be adjusted to "once per process" or "once per object" by qualifying it with a "once key", e.g. codice_86.

Eiffel provides a mechanism to allow conversions between various types. The mechanisms coexists with inheritance and complements it. To avoid any confusion between the two mechanisms, the design enforces the following principle:

For example, codice_87 may conform to codice_88, but codice_2 converts to codice_90 (and does not inherit from it).

The conversion mechanism simply generalizes the ad hoc conversion rules (such as indeed between codice_2 and codice_90) that exist in most programming languages, making them applicable to any type as long as the above principle is observed. For example, a codice_93 class may be declared to convert to codice_3; this makes it possible to create a string from a date simply through

as a shortcut for using an explicit object creation with a conversion procedure:

To make the first form possible as a synonym for the second, it suffices to list the creation procedure (constructor) codice_95 in a codice_96 clause at the beginning of the class.

As another example, if there is such a conversion procedure listed from codice_97, then one can directly assign a tuple to a date, causing the appropriate conversion, as in

Exception handling in Eiffel is based on the principles of design by contract. For example, an exception occurs when a routine's caller fails to satisfy a precondition, or when a routine cannot ensure a promised postcondition. In Eiffel, exception handling is not used for control flow or to correct data-input mistakes.

An Eiffel exception handler is defined using the rescue keyword. Within the rescue section, the retry keyword executes the routine again. For example, the following routine tracks the number of attempts at executing the routine, and only retries a certain number of times:
connect_to_server (server: SOCKET)
This example is arguably flawed for anything but the simplest programs, however, because connection failure is to be expected. For most programs a routine name like attempt_connecting_to_server would be better, and the postcondition would not promise a connection, leaving it up to the caller to take appropriate steps if the connection was not opened.

A number of networking and threading libraries are available, such as EiffelNet and EiffelThreads. A concurrency model for Eiffel, based on the concepts of design by contract, is SCOOP, or "Simple Concurrent Object-Oriented Programming", not yet part of the official language definition but available in EiffelStudio.
CAMEO is an (unimplemented) variation of SCOOP for Eiffel.
Concurrency also interacts with exceptions. Asynchronous exceptions can be troublesome (where a routine raises an exception after its caller has itself finished).

Eiffel's view of computation is completely object-oriented in the sense that every operation is relative to an object, the "target". So for example an addition such as
a + b
is conceptually understood as if it were the method call
a.plus (b)
with target codice_59, feature codice_99 and argument codice_100.

Of course, the former is the conventional syntax and usually preferred. Operator syntax makes it possible to use either form by declaring the feature (for example in codice_2, but this applies to other basic classes and can be used in any other for which such an operator is appropriate):
plus alias "+" (other: INTEGER): INTEGER
The range of operators that can be used as "alias" is quite broad; they include predefined operators such as "+" but also "free operators" made of non-alphanumeric symbols. This makes it possible to design special infix and prefix notations, for example in mathematics and physics applications.

Every class may in addition have "one" function aliased to "[]", the "bracket" operator, allowing the notation codice_102 as a synonym for codice_103 where codice_104 is the chosen function. This is particularly useful for container structures such as arrays, hash tables, lists etc. For example, access to an element of a hash table with string keys can be written
"Assigner commands" are a companion mechanism designed in the same spirit of allowing well-established, convenient notation reinterpreted in the framework of object-oriented programming. Assigner commands allow assignment-like syntax to call "setter" procedures. An assignment proper can never be of the form codice_105 as this violates information hiding; you have to go for a setter command (procedure). For example, the hash table class can have the function and the procedure
item alias "[]" (key: STRING): ELEMENT [3]

put (e: ELEMENT; key: STRING)
Then to insert an element you have to use an explicit call to the setter command:
It is possible to write this equivalently as
(in the same way that codice_106 is a synonym for codice_107), provided the declaration of codice_108 now starts (replacement for [3]) with
This declares codice_109 as the assigner command associated with codice_108 and, combined with the bracket alias, makes [5] legal and equivalent to [4]. (It could also be written, without taking advantage of the bracket, as codice_111.

note: The argument list of a's assigner is constrained to be: (a's return type;all of a's argument list...)

Eiffel is not case-sensitive. The tokens codice_7, codice_113 and codice_114 all denote the same identifier. See, however, the "style rules" below.

Comments are introduced by codice_115 (two consecutive dashes) and extend to the end of the line.

The semicolon, as instruction separator, is optional. Most of the time the semicolon is just omitted, except to separate multiple instructions on a line. This results in less clutter on the program page.

There is no nesting of feature and class declarations. As a result, the structure of an Eiffel class is simple: some class-level clauses (inheritance, invariant) and a succession of feature declarations, all at the same level.

It is customary to group features into separate "feature clauses" for more readability, with a standard set of basic feature tags appearing in a standard order, for example:
class HASH_TABLE [ELEMENT, KEY -> HASHABLE] inherit TABLE [ELEMENT]

end
In contrast to most curly bracket programming languages, Eiffel makes a clear distinction between expressions and instructions. This is in line with the Command-Query Separation principle of the Eiffel method.

Much of the documentation of Eiffel uses distinctive style conventions, designed to enforce a consistent look-and-feel. Some of these conventions apply to the code format itself, and others to the standard typographic rendering of Eiffel code in formats and publications where these conventions are possible.

While the language is case-insensitive, the style standards prescribe the use of all-capitals for class names (codice_116), all-lower-case for feature names (codice_7), and initial capitals for constants (codice_118). The recommended style also suggests underscore to separate components of a multi-word identifier, as in codice_119.

The specification of Eiffel includes guidelines for displaying software texts in typeset formats: keywords in bold, user-defined identifiers and constants are shown in "codice_120", comments, operators, and punctuation marks in codice_121, with program text in codice_122 as in the present article to distinguish it from explanatory text. For example, the "Hello, world!" program given above would be rendered as below in Eiffel documentation:

Eiffel is a purely object-oriented language but provides an open architecture for interfacing with "external" software in any other programming language.

It is possible for example to program machine- and operating-system level operations in C. Eiffel provides a straightforward interface to C routines, including support for "inline C" (writing the body of an Eiffel routine in C, typically for short machine-level operations).

Although there is no direct connection between Eiffel and C, many Eiffel compilers (Visual Eiffel is one exception) output C source code as an intermediate language, to submit to a C compiler, for optimizing and portability. As such, they are examples of transcompilers. The Eiffel Compiler tecomp can execute Eiffel code directly (like an interpreter) without going via an intermediate C code or emit C code which will be passed to a C compiler in order to obtain optimized native code. On .NET, the EiffelStudio compiler directly generates CIL (Common Intermediate Language) code. The SmartEiffel compiler can also output Java bytecode.



</doc>
<doc id="9839" url="https://en.wikipedia.org/wiki?curid=9839" title="Ezra">
Ezra

Ezra (; , '; fl. 480–440 BCE), also called Ezra the Scribe (, ') and Ezra the Priest in the Book of Ezra, was a Jewish scribe and a priest. In Greco-Latin Ezra is called Esdras (). According to the Hebrew Bible he was a descendant of Seraiah () the last High Priest to serve in the First Temple (), and a close relative of Joshua the first High Priest of the Second Temple ( CJB and similar translations only; see also ). He returned from Babylonian exile and reintroduced the Torah in Jerusalem ( and ). According to 1 Esdras, a Greek translation of the Book of Ezra still in use in Eastern Orthodoxy, he was also a High Priest. Rabbinic tradition holds that he was only a common priest.

Several traditions have developed over his place of burial. One tradition says that he is buried in al-Uzayr near Basra (Iraq), while another tradition alleges that he is buried in Tadif near Aleppo, in northern Syria.

His name may be an abbreviation of ', "God-helps". In the Greek Septuagint the name is rendered ' (), from which the Latin name comes.

The Book of Ezra describes how he led a group of Judean exiles living in Babylon to their home city of Jerusalem () where he is said to have enforced observance of the Torah. He was described as exhorting the Israelite people to be sure to follow the Torah Law so as not to intermarry with people of particular different religions, a set of commandments described in the Pentateuch.

Ezra, known as "Ezra the scribe" in Chazalic literature, is a highly respected figure in Judaism.

The canonical Book of Ezra and Book of Nehemiah are the oldest sources for the activity of Ezra, whereas many of the other books ascribed to Ezra (First Esdras, 3–6 Ezra) are later literary works dependent on the canonical books of Ezra and Nehemiah.

The books of Ezra–Nehemiah were originally one scroll. Later the Jews divided this scroll and called it First and Second Ezra. Modern Hebrew Bibles call the two books Ezra and Nehemiah, as do other modern Bible translations. A few parts of the Book of Ezra (4:8 to 6:18 and 7:12–26) were written in Aramaic, and the majority in Hebrew, Ezra himself being skilled in both languages. Ezra was living in Babylon when in the seventh year ( BCE) of Artaxerxes, king of Persia, the king sent him to Jerusalem to teach the laws of God to any who did not know them. Ezra led a large body of exiles back to Jerusalem, where he discovered that Jewish men had been marrying non-Jewish women. He tore his garments in despair and confessed the sins of Israel before God, then braved the opposition of some of his own countrymen to purify the community by enforcing the dissolution of the sinful marriages. Some years later Artaxerxes sent Nehemiah (a Jewish noble in his personal service) to Jerusalem as governor with the task of rebuilding the city walls. Once this task was completed Nehemiah had Ezra read the Law of Moses (the Torah) to the assembled Israelites, and the people and priests entered into a covenant to keep the law and separate themselves from all other peoples.

1 Esdras, probably from the late 2nd/early 1st centuries BCE, preserves a Greek text of Ezra and a part of Nehemiah distinctly different from that of Ezra–Nehemiah – in particular it eliminates Nehemiah from the story and gives some of his deeds to Ezra, as well as telling events in a different order. Scholars are divided on whether it is based on Ezra–Nehemiah, or reflects an earlier literary stage before the combination of Ezra and Nehemiah accounts.

The first-century Jewish historian Josephus deals with Ezra in his "Antiquities of the Jews". He preferred 1 Esdras over the canonical Ezra–Nehemiah and placed Ezra as a contemporary of Xerxes, son of Darius – rather than of Artaxerxes.

The apocalyptic fourth book of Ezra (also called the second book of Esdras) was written c. CE 100, probably in Hebrew-Aramaic. It was one of the most important sources for Jewish theology at the end of the 1st century. In this book, Ezra has a seven part prophetic revelation, converses with an angel of God three times and has four visions. Ezra, thirty years into the Babylonian Exile (4 Ezra 3:1 / 2 Esdras 1:1), recounts the siege of Jerusalem and the destruction of Solomon's Temple. This would place these revelations in the year 557 BCE, a full century before the date given in the canonical Ezra. The central theological themes are "the question of theodicy, God's justness in the face of the triumph of the heathens over the pious, the course of world history in terms of the teaching of the four kingdoms, the function of the law, the eschatological judgment, the appearance on Earth of the heavenly Jerusalem, the Messianic Period, at the end of which the Messiah will die, the end of this world and the coming of the next, and the Last Judgment." Ezra restores the law that was destroyed with the burning of the Temple in Jerusalem. He dictates 24 books for the public (i.e. the Hebrew Bible) and another 70 for the wise alone (70 unnamed revelatory works). At the end, he is taken up to heaven like Enoch and Elijah. Ezra is seen as a new Moses in this book.

There is also another work, thought to be influenced by this one, known as the "Greek Apocalypse of Ezra".

Traditionally Judaism credits Ezra with establishing the Great Assembly of scholars and prophets, the forerunner of the Sanhedrin, as the authority on matters of religious law. The Great Assembly is credited with establishing numerous features of contemporary traditional Judaism in something like their present form, including Torah reading, the Amidah, and celebration of the feast of Purim.

In Rabbinic traditions, Ezra is metaphorically referred to as the "flowers that appear on the earth" signifying the springtime in the national history of Judaism. A disciple of Baruch ben Neriah, he favored study of the Law over the reconstruction of the Temple and thus because of his studies, he did not join the first party returning to Jerusalem in the reign of Cyrus. According to another opinion, he did not join the first party so as not to compete, even involuntarily, with Jeshua ben Jozadak for the office of chief priest.

According to Jewish tradition, Ezra was the writer of the Books of Chronicles, and is the same prophet known also as Malachi. There is a slight controversy within rabbinic sources as to whether or not Ezra had served as Kohen Gadol.

According to the Babylonian Talmud, Ezra the scribe is said to have enacted ten standing laws and orders, which are as follows: 1) That the public come together to read from the scroll of the Law on Sabbath days during the time of the afternoon oblation (Minchah), because of those travelling merchants who loiter in the closed shops in the street corners, and who may have missed the biblical lections that were read during the weekdays; 2) that the courts be opened throughout the Jewish townships on Mondays and Thursdays; 3) that women do not wait beyond Thursday to launder their clothes, because of the honor due to the Sabbath day; 4) that men would accustom themselves to eat [cooked] garlic on the eve of the Sabbath (believed to enhance love between a man and his wife); 5) that women would rise-up early on Friday mornings to bake bread, so that a piece of bread will be available for the poor; 6) that Jewish women in every place be girded with a wide belt (waist band), whether from the front or from behind, out of modesty; 7) that Jewish women, during their menses, wash and comb their hair three days prior to their purification in a ritual bath; 8) that the travelling merchants make regular rounds into the Jewish townships because of the honor due to the daughters of Israel; 9) that Jewish women and/or girls, as a precautionary measure, be accustomed to conversing with one another while one of their party goes out to relieve herself in the outhouse; 10) that men who may have suffered a seminal emission (especially after accompanying with their wives) be required to immerse themselves in a ritual bath before being permitted to read from the scroll of the Law.

In the Syrian village of Tedef, a synagogue said to be the place where Ezra stopped over has been venerated by Jews for centuries. Another tradition locates his tomb near Basra, Iraq.

Early Christian writers occasionally cited Ezra as author of the apocalyptic books attributed to him. Clement of Alexandria in his "Stromata" referred to Ezra as an example of prophetic inspiration, quoting a section from 2 Esdras.

In Islam he is known as Uzair (). He was mentioned in the Qur'an. Although he was not mentioned as one of the Prophets of Islam, he is considered as one of them by some Muslim scholars, based on Islamic traditions. His tomb at Al-ʻUzair on the banks of the Tigris near Basra, Iraq, is a pilgrimage site for the local Marsh Arabs. Many Islamic scholars and modern Western academics do not view Uzair as "Ezra"; for example Professor Gordon Darnell Newby associates Uzair with Enoch and Metatron. On this Timothy Winter (Abdal Hakim Murad) and Gordon Darnell Newby associate Uzair again with Enoch (ancestor of Noah) and by extension Metatron the creator-angel or "lesser Yahweh".

Koresh of Ezra 1:1 is called "king of Persia", which title was introduced not by Cyrus the Great but by his grandson and probable namesake Xerxes (486–465 BCE).

Scholars are divided over the chronological sequence of the activities of Ezra and Nehemiah. Ezra 7:8 says that Ezra arrived in Jerusalem in the seventh year of king Artaxerxes, while Nehemiah 2:1–9 has Nehemiah arriving in Artaxerxes' twentieth year. If this was Artaxerxes I (465–424 BCE), then Ezra arrived in 458 and Nehemiah in 445 BCE. Nehemiah 8–9, in which the two (possibly by editorial error) appear together, supports this scenario.

It was proposed that Ezra's Artaxerxes was Artaxerxes II (404–359 BCE), and that the sequence should be reversed, with Nehemiah arriving in 445 and Ezra in 398 BCE.
The argument has some persuasive evidence; for example:



In Ezra 4:8 the text changes from Hebrew to Aramaic, therefore the king's name in Ezra 4:7, also used in the following letter, possibly is the Aramaic version of the king's name AhaSuerus mentioned in Ezra 4:6.

The above suggests the following identifications:


Mary Joan Winn Leith in "The Oxford History of the Biblical World" believes that Ezra was a historical figure whose life was enhanced in the scripture and given a theological buildup. Gosta W. Ahlstrom argues the inconsistencies of the biblical tradition are insufficient to say that Ezra, with his central position as the 'father of Judaism' in the Jewish tradition, has been a later literary invention. Those who argue against the historicity of Ezra argue that the presentation style of Ezra as a leader and lawgiver resembles that of Moses. There are also similarities between Ezra the priest-scribe (but not high priest) and Nehemiah the secular governor on the one hand and Joshua and Zerubbabel on the other hand. The early 2nd-century BCE Jewish author Ben Sira praises Nehemiah, but makes no mention of Ezra.

Richard Friedman argued in his book "Who Wrote the Bible?" (p. 232 1997 edition) that Ezra is the one who redacted the Torah, and in fact effectively produced the first Torah. It has been argued that even if one does not accept the documentary hypothesis, Ezra was instrumental in the start of the process of bringing the Torah together.





</doc>
<doc id="9840" url="https://en.wikipedia.org/wiki?curid=9840" title="Elijah">
Elijah

Elijah (; ; , meaning "My God is Yahu/Jah") or Elias ( ; "Elías"; "Elyāe"; Arabic: إلياس or إليا, "Ilyās" or "Ilyā") was a prophet and a miracle worker who lived in the northern kingdom of Israel during the reign of King Ahab (9th century BC), according to the Books of Kings in the Hebrew Bible. In 1 Kings 18, Elijah defended the worship of the Jewish God over that of the Canaanite deity Baal. God also performed many miracles through Elijah, including resurrection (raising the dead), bringing fire down from the sky, and entering Heaven alive "by fire". He is also portrayed as leading a school of prophets known as "the sons of the prophets". Following his ascension, Elisha his disciple and most devoted assistant took over his role as leader of this school. The Book of Malachi prophesies Elijah's return "before the coming of the great and terrible day of the LORD", making him a harbinger of the Messiah and of the eschaton in various faiths that revere the Hebrew Bible. References to Elijah appear in Ecclesiasticus, the New Testament, the Mishnah and Talmud, the Quran, the Book of Mormon, the Doctrine and Covenants, and Bahá'í writings.

In Judaism, Elijah's name is invoked at the weekly Havdalah ritual that marks the end of Shabbat, and Elijah is invoked in other Jewish customs, among them the Passover Seder and the brit milah (ritual circumcision). He appears in numerous stories and references in the Haggadah and rabbinic literature, including the Babylonian Talmud.

The Christian New Testament notes that some people thought that Jesus was, in some sense, Elijah. But Jesus makes it clear that John the Baptist is "the Elijah" who was promised to come in Malachi 3:23 in the Septuagint. (Malachi 4:5) Elijah appears with Moses during the Transfiguration of Jesus. Elijah is also a figure in various Christian folk traditions, at times identified with earlier pagan thunder or sky gods.

In Islam, Elijah appears in the Quran as a prophet and messenger of God, where his biblical narrative of preaching against the worshipers of Baal is recounted in a concise form. Due to his importance to Muslims, Catholics and Orthodox Christians, Elijah has been venerated as the patron saint of Bosnia and Herzegovina since 1752.

According to the Bible, by the 9th century BC, the Kingdom of Israel, once united under Solomon, was divided into the northern Kingdom of Israel and southern Kingdom of Judah, which retained the historical capital of Jerusalem along with its Temple. However, scholars today are divided as to whether the united Kingdom under Solomon ever existed. Omri, King of Israel, continued policies dating from the reign of Jeroboam, contrary to religious law, that were intended to reorient religious focus away from Jerusalem: encouraging the building of local temple altars for sacrifices, appointing priests from outside the family of the Levites, and allowing or encouraging temples dedicated to Baal, an important deity in ancient Canaanite religion. Omri achieved domestic security with a marriage alliance between his son Ahab and princess Jezebel, a priestess of Baal and the daughter of the king of Sidon in Phoenicia. These solutions brought security and economic prosperity to Israel for a time, but did not bring peace with the Israelite prophets, who were interested in a strict deuteronomic interpretation of the religious law.

Under Ahab's kingship, these tensions were exacerbated. Ahab built a temple for Baal, and his wife Jezebel brought a large entourage of priests and prophets of Baal and Asherah into the country. It is in this context that Elijah is introduced in as Elijah "the Tishbite". He warns Ahab that there will be years of catastrophic drought so severe that not even dew will form, because Ahab and his queen stand at the end of a line of kings of Israel who are said to have "done evil in the sight of the Lord."

No background for the person of Elijah is given except for his brief description as being a "Tishbite." His name in Hebrew means "My God is Yahweh", and may be a title applied to him because of his challenge to worship of Baal.

As told in the Hebrew Bible, Elijah's challenge is bold and direct. Baal was the Canaanite god responsible for rain, thunder, lightning, and dew.
Elijah not only challenges Baal on behalf of God himself, but he also challenges Jezebel, her priests, Ahab and the people of Israel.

After Elijah's confrontation with Ahab, God tells him to flee out of Israel, to a hiding place by the brook Chorath, east of the Jordan, where he will be fed by ravens. When the brook dries up, God sends him to a widow living in the town of Zarephath in Phoenicia. When Elijah finds her and asks to be fed, she says that she does not have sufficient food to keep her and her own son alive. Elijah tells her that God will not allow her supply of flour or oil to run out, saying, “Do not be afraid ... For thus says the Lord the God of Israel: The jar of meal will not be emptied and the jug of oil will not fail until the day that the Lord sends rain on the earth.” She feeds him the last of their food, and Elijah's promise miraculously comes true. God gave her "manna" from heaven even while he was withholding food from his unfaithful people in the promised land. Some time later the widow's son dies and the widow cries, "You have come to me to bring my sin to remembrance, and to cause the death of my son!" Elijah prays that God might restore her son so that the trustworthiness of God's word might be demonstrated. 1 Kings 17:22 relates how God "listened to the voice of Elijah; the life of the child came into him again, and he revived." This is the first instance of raising the dead recorded in Scripture. This non-Israelite widow was granted the life of her son, the only hope for a widow in ancient society. The widow cried, "...the word of the Lord in your mouth is truth." She made a confession that the Israelites had failed to make.

After more than three years of drought and famine, God tells Elijah to return to Ahab and announce the end of the drought: not occasioned by repentance in Israel but by the command of the Lord, who had determined to reveal himself again to his people. While on his way, Elijah meets Obadiah, the head of Ahab's household, who had hidden a hundred Jewish prophets when Ahab and Jezebel had been killing them. Elijah sends Obadiah back to Ahab to announce his return to Israel.

When Ahab confronts Elijah, he refers to him as the "troubler of Israel." Elijah responds by throwing the charge back at Ahab, saying that it is Ahab who has troubled Israel by allowing the worship of false gods. Elijah then berates both the people of Israel and Ahab for their acquiescence in Baal worship. "How long will you go limping with two different opinions? If the Lord is God, follow him; but if Baal, then follow him." And the people were silent. The Hebrew for this word, "go limping" or "waver", is the same as that used for "danced" in verse 26, where the prophets of Baal frantically dance. Elijah speaks with sharp irony: in the religious ambivalence of Israel. 

Elijah proposes a direct test of the powers of Baal and the Jewish God. The people of Israel, 450 prophets of Baal, and 400 prophets of Asherah are summoned to Mount Carmel. Two altars are built, one for Baal and one for God. Wood is laid on the altars. Two oxen are slaughtered and cut into pieces; the pieces are laid on the wood. Elijah then invites the priests of Baal to pray for fire to light the sacrifice. They pray from morning to noon without success. Elijah ridicules their efforts. "At noon Elijah mocked them, saying, ‘Cry aloud! Surely he is a god; either he is meditating, or he has wandered away, or he is on a journey, or perhaps he is asleep and must be awakened.’" They respond by cutting themselves and adding their own blood to the sacrifice (such mutilation of the body was strictly forbidden in the Mosaic law). They continue praying until evening without success.

Elijah now orders that the altar of his god be drenched with water from "four large jars" poured three times. He asks God to accept the sacrifice. Fire falls from the sky, consuming the water, the sacrifice and the stones of the altar itself as well. Elijah then orders the deaths of the priests of Baal. Elijah prays earnestly for rain to fall again on the land. Then the rains begin, signaling the end of the famine.

Jezebel, enraged that Elijah had ordered the deaths of her priests, threatens to kill Elijah. Later Elijah would prophesy about Jezebel's death, because of her sin. Elijah flees to Beersheba in Judah, continues alone into the wilderness, and finally sits down under a shrub, praying for death. He falls asleep under the tree; the angel of the Lord touches him and tells him to wake up and eat. When he awakens he finds bread and a jar of water. He eats, drinks, and goes back to sleep. The angel comes a second time and tells him to eat and drink because he has a long journey ahead of him.

Elijah travels for forty days and forty nights to Mount Horeb, where Moses had received the Ten Commandments. Elijah is the only person described in the Bible as returning to Horeb, after Moses and his generation had left Horeb several centuries before. He seeks shelter in a cave. God again speaks to Elijah: "What doest thou here, Elijah?". Elijah did not give a direct answer to the Lord's question but evades and equivocates, implying that the work the Lord had begun centuries earlier had now come to nothing, and that his own work was fruitless. Unlike Moses, who tried to defend Israel when they sinned with the golden calf, Elijah bitterly complains over the Israelites' unfaithfulness and says he is the "only one left". Up until this time Elijah has only the word of God to guide him, but now he is told to go outside the cave and "stand before the Lord." A terrible wind passes, but God is not in the wind. A great earthquake shakes the mountain, but God is not in the earthquake. Then a fire passes the mountain, but God is not in the fire. Then a "still small voice" comes to Elijah and asks again, "What doest thou here, Elijah?" Elijah again evades the question and his lament is unrevised, showing that he did not understand the importance of the divine revelation he had just witnessed. God then sends him out again, this time to Damascus to anoint Hazael as king of Aram, Jehu as king of Israel, and Elisha as his replacement.

Elijah encounters Ahab again in , after Ahab has acquired possession of a vineyard by murder. Ahab desires to have the vineyard of Naboth of Jezreel. He offers a better vineyard or a fair price for the land. But Naboth tells Ahab that God has told him not to part with the land. Ahab accepts this answer with sullen bad grace. Jezebel, however, plots a method for acquiring the land. She sends letters, in Ahab's name, to the elders and nobles who lived near Naboth. They are to arrange a feast and invite Naboth. At the feast, false charges of cursing God and Ahab are to be made against him. The plot is carried out and Naboth is stoned to death. When word comes that Naboth is dead, Jezebel tells Ahab to take possession of the vineyard.

God again speaks to Elijah and sends him to confront Ahab with a question and a prophecy: "Have you killed, and also taken possession?" and, "In the place where dogs licked up the blood of Naboth, dogs will also lick up your blood." Ahab begins the confrontation by calling Elijah his enemy. Elijah responds by throwing the charge back at him, telling him that he has made himself the enemy of God by his own actions. Elijah then goes beyond the prophecy he was given and tells Ahab that his entire kingdom will reject his authority; that Jezebel will be eaten by dogs within Jezreel; and that his family will be consumed by dogs as well (if they die in a city) or by birds (if they die in the country). When Ahab hears this he repents to such a degree that God relents in punishing Ahab but will punish Jezebel and their son: Ahaziah.

Elijah's story continues now from Ahab to an encounter with Ahaziah. The scene opens with Ahaziah seriously injured in a fall. He sends to the priests of Baalzebub in Ekron, outside the kingdom of Israel, to know if he will recover. Elijah intercepts his messengers and sends them back to Ahaziah with a message "Is it because there is no God in Israel that you are sending to inquire of Baal-zebub, the god of Ekron?" Ahaziah asks the messengers to describe the person who gave them this message. They tell him he was a hairy man with a leather belt around his waist and he instantly recognizes the description as Elijah the Tishbite.

Ahaziah sends out three groups of soldiers to arrest Elijah. The first two are destroyed by fire which Elijah calls down from heaven. The leader of the third group asks for mercy for himself and his men. Elijah agrees to accompany this third group to Ahaziah, where he gives his prophecy in person. Ahaziah dies without recovering from his injuries in accordance with Elijah's word.

According to , Elisha (Eliseus) and "the sons of the prophets" knew beforehand that Elijah would one day be assumed into heaven. Elisha asked Elijah to "let a double portion" of Elijah's "spirit" be upon him. Elijah agreed, with the condition that Elisha would see him be "taken".

Elijah, in company with Elisha, approaches the Jordan. He rolls up his mantle and strikes the water. The water immediately divides and Elijah and Elisha cross on dry land. Suddenly, a chariot of fire and horses of fire appear and Elijah is lifted up in a whirlwind. As Elijah is lifted up, his mantle falls to the ground and Elisha picks it up.

Elijah is mentioned once more in , which will be his final mention in the Hebrew Bible. A letter is sent under the prophet's name to Jehoram of Judah. It tells him that he has led the people of Judah astray in the same way that Israel was led astray. The prophet ends the letter with a prediction of a painful death. This letter is a puzzle to readers for several reasons. First, it concerns a king of the southern kingdom, while Elijah concerned himself with the kingdom of Israel. Second, the message begins with "Thus says YHVH, God of your father David..." rather than the more usual "...in the name of YHVH the God of Israel." Also, this letter seems to come after Elijah's ascension into the whirlwind. Michael Wilcock, formerly of Trinity College, Bristol, suggests a number of possible reasons for this letter, among them that it may be an example of a better known prophet's name being substituted for that of a lesser known prophet. John Van Seters, however, rejects the letter as having any connection with the Elijah tradition. However, Wilcock argues that Elijah's letter, 'does address a very 'northern' situation in the southern kingdom', and thus is authentic.

While the final mention of Elijah in the Hebrew Bible is in the Book of Chronicles, the Christian Bible's ordering of the books of the Septuagint places the Book of Malachi, which prophesies a messiah, before the Gospels and means that Elijah's final Old Testament appearance is in the Book of Malachi, where it is written, "Lo, I will send you the prophet Elijah before the great and terrible day of the Lord comes." That day is described as the burning of a great furnace, "... so that it will leave them neither root nor branch." In Christianity it is traditionally believed that Elijah's appearance during the transfiguration of Jesus fulfilled this prophecy. Moreover, in the Gospel of Matthew, Jesus identifies John the Baptist as the spiritual successor to Elijah: "and if you are willing to accept it, he is Elijah who is to come." Finally, the verses in Malachi are believed to indicate that Elijah has a role in the end-times, immediately before the second coming of Jesus.

According to Susanne Otto, the Elijah stories were added to the Deuteronomistic History in four stages. The first stage dates from the final edition of the History, about 560 BC, when the three stories of Naboth’s vineyard, the death of Ahaziah, and the story of Jehu’s coup were included to embody the themes of the reliability of God's word and the cycle of Baal worship and religious reform in the history of the Northern Kingdom. The narratives about the Omride wars were added shortly afterwards to illustrate a newly introduced theme, that the attitude of the king towards God determines the fate of Israel. According to Otto, was added in early post-Exilic times (after 538 BC) to demonstrate the possibility of a new life in community with God after the time of judgment. Additionally, Otto suggests that in the fifth century BC, and the remaining Elisha stories were inserted to give prophecy a legitimate foundation in the history of Israel. The foregoing Otto analysis is heavily disputed amongst biblical scholars.

Jewish legends about Elijah abound in the aggadah, which is found throughout various collections of rabbinic literature, including the Babylonian Talmud. This varied literature does not merely discuss his life, but has created a new history of him, which, beginning with his death or "translation" ends only with the close of the history of the human race. The volume of references to Elijah in Jewish Tradition stands in marked contrast to that in the Canon. As in the case of most figures of Jewish legend, so in the case of Elijah, the biblical account became the basis of later legend. Elijah the precursor of the Messiah, Elijah zealous in the cause of God, Elijah the helper in distress: these are the three leading notes struck by the Aggadah, endeavoring to complete the biblical picture with the Elijah legends. His career is extensive, colorful, and varied. He has appeared the world over in the guise of a beggar and scholar.

From the time of Malachi, who says of Elijah that God will send him before "the great and dreadful day" (Mal. 3:23), down to the later stories of the Chasidic rabbis, reverence and love, expectation and hope, were always connected in the Jewish consciousness with Elijah.

Three different theories regarding Elijah's origin are presented in the Aggadah literature:
(1) he belonged to the tribe of Gad,
(2) he was a Benjamite from Jerusalem, identical with the Elijah mentioned in I Chronicles 8:27, and
(3) he was a priest.

Many Christian Church fathers also have stated that Elijah was a priest. Some Rabbis have speculated that he should be identified with Phinehas.

According to later Kabbalistic literature, Elijah was really an angel in human form, so that he had neither parents nor offspring. See Melchizedek.

The Midrash Rabbah Exodus 4:2 states "Elijah should have revived his parents as he had revived the son of the Zarephathite" indicating he surely had parents.

The Talmud states "Said he [Rabbah] to him (Elijah): Art thou not a priest: why then dost thou stand in a cemetery?"

In spite of Elijah's many miracles, the mass of the Jewish people remained as godless as before. A midrash tells that they even abolished the sign of the covenant, and the prophet had to appear as Israel's accuser before God.

In the same cave where God once appeared to Moses and revealed Himself as gracious and merciful, Elijah was summoned to appear before God. By this summons he perceived that he should have appealed to God's mercy, instead of becoming Israel's accuser. The prophet, however, remained relentless in his zeal and severity, so that God commanded him to appoint his successor.

The vision in which God revealed Himself to Elijah gave him at the same time a picture of the destinies of man, who has to pass through "four worlds." This world was shown to the prophet by God through symbolism: in the form of the wind, since it disappears as the wind; storm is the day of death, before which man trembles; fire is the judgment in Gehenna; and the stillness is the last day.

Three years after this vision Elijah was "translated." Concerning the place to which Elijah was transferred, opinions differ among Jews and Christians, but the old view was that Elijah was received among the heavenly inhabitants, where he records the deeds of men, a task which according to the apocalyptic literature is entrusted to Enoch.

But as early as the middle of the 2nd century, when the notion of translation to heaven underwent divergent possible interpretations by Christian theologians, the assertion was made that Elijah never entered into heaven proper. In later literature paradise is generally designated as the abode of Elijah, but since the location of paradise is itself uncertain, the last two statements may be identical.

In the Wisdom of Jesus ben Sira () his tasks are altered to: 1) herald the eschaton, 2) calm God’s fury, 3) restore familial peace, and 4) restore the 12 tribes.

At Jewish circumcision ceremonies, a chair is set aside for the use of the prophet Elijah. Elijah is said to be a witness at all circumcisions when the sign of the covenant is placed upon the body of the child. This custom stems from the incident at Mount Horeb (): Elijah had arrived at Mount Horeb after the demonstration of God's presence and power on Mount Carmel. () God asks Elijah to explain his arrival, and Elijah replies: "I have been very jealous for the Lord, the God of hosts; for the people of Israel have forsaken thy covenant, thrown down thy altars, and slain thy prophets with the sword; and I, even I only, am left; and they seek my life, to take it away" (). According to Rabbinic tradition, Elijah's words were patently untrue ( and ), and since Elijah accused Israel of failing to uphold the covenant, God would require Elijah to be present at every covenant of circumcision.

In the Talmudic literature, Elijah would visit rabbis to help solve particularly difficult legal problems. Malachi had cited Elijah as the harbinger of the eschaton. Thus, when confronted with reconciling impossibly conflicting laws or rituals, the rabbis would set aside any decision "until Elijah comes."

One such decision was whether the Passover Seder required four or five cups of wine. Each serving of wine corresponds to one of the "four expressions of redemption" in the Book of Exodus:

"I am the Lord, and "I will bring you out" from under the burdens of the Egyptians, and "I will deliver you" from their bondage, and "I will redeem you" with an out-stretched arm and with great acts of judgment, and "I will take you" for my people, and I will be your God; and you shall know that I am the Lord your God, who has brought you out from under the burdens of the Egyptians" ().

The next verse, "And "I will bring you" into the land which I swore to give to Abraham, to Isaac, and to Jacob; I will give it to you for a possession. I am the Lord." () was not fulfilled until the generation following the Passover story, and the rabbis could not decide whether this verse counted as part of the Passover celebration (thus deserving of another serving of wine). Thus, a cup was left for the arrival of Elijah.

In practice the fifth cup has come to be seen as a celebration of future redemption. Today, a place is reserved at the seder table and a cup of wine is placed there for Elijah. During the seder, the door of the house is opened and Elijah is invited in. Traditionally, the cup is viewed as Elijah’s and is used for no other purpose.

Havdalah is the ceremony that concludes the Sabbath Day (Saturday evening in Jewish tradition). As part of the concluding hymn, an appeal is made to God that Elijah will come during the following week. "Elijah the Prophet, Elijah the Tishbite. Let him come quickly, in our day with the messiah, the son of David."

The volume of references to Elijah in folklore stands in marked contrast to that in the canon. Elijah's miraculous transferral to heaven led to speculation as to his true identity. Louis Ginzberg equates him with Phinehas the grandson of Aaron (). Because of Phinehas' zealousness for God, he and his descendants were promised, "a covenant of lasting priesthood" (). Therefore, Elijah is a priest as well as a prophet. Elijah is also equated with the Archangel Sandalphon, whose four wing beats will carry him to any part of the earth. When forced to choose between death and dishonor, Rabbi Kahana chose to leap to his death. Before he could strike the ground, Elijah/Sandalphon had appeared to catch him. Yet another name for Elijah is "Angel of the Covenant"

References to Elijah in Jewish folklore range from short observations (e. g. It is said that when dogs are happy for no reason, it is because Elijah is in the neighborhood) to lengthy parables on the nature of God’s justice.

One such story is that of Rabbi Joshua ben Levi. The rabbi, a friend of Elijah’s, was asked what favor he might wish. The rabbi answered only that he be able to join Elijah in his wanderings. Elijah granted his wish only if he refrained from asking any questions about any of the prophet’s actions. He agreed and they began their journey. The first place they came to was the house of an elderly couple who were so poor they had only one old cow. The old couple gave of their hospitality as best they could. The next morning, as the travelers left, Elijah prayed that the old cow would die and it did. The second place they came to was the home of a wealthy man. He had no patience for his visitors and chased them away with the admonition that they should get jobs and not beg from honest people. As they were leaving, they passed the man’s wall and saw that it was crumbling. Elijah prayed that the wall be repaired and it was so. Next, they came to a wealthy synagogue. They were allowed to spend the night with only the smallest of provisions. When they left, Elijah prayed that every member of the synagogue might become a leader.

Finally, they came to a very poor synagogue. Here they were treated with great courtesy and hospitality. When they left, Elijah prayed that God might give them a single wise leader. At this Rabbi Joshua could no longer hold back. He demanded of Elijah an explanation of his actions. At the house of the old couple, Elijah knew that the Angel of Death was coming for the old woman. So he prayed that God might have the angel take the cow instead. At the house of the wealthy man, there was a great treasure hidden in the crumbling wall. Elijah prayed that the wall be restored thus keeping the treasure away from the miser. The story ends with a moral: A synagogue with many leaders will be ruined by many arguments. A town with a single wise leader will be guided to success and prosperity. "Know then, that if thou seest an evil-doer prosper, it is not always unto his advantage, and if a righteous man suffers need and distress, think not God is unjust."

The Elijah of legend did not lose any of his ability to afflict the comfortable. The case of Rabbi Eliezer son of Rabbi Simon ben Yohai is illustrative. Once, when walking a beach, he came upon a hideously ugly man—the prophet in disguise. The man greeted him courteously, "Peace be with thee, Rabbi." Instead of returning the greeting, the rabbi could not resist an insult, "How ugly you are! Is there anyone as ugly as you in your town?" Elijah responded with, "I don’t know. Perhaps you should tell the Master Architect how ugly is this, His construction." The rabbi realized his wrong and asked for pardon. But Elijah would not give it until the entire city had asked for forgiveness for the rabbi and the rabbi had promised to mend his ways.

Elijah was always seen as deeply pious, it seems only natural that he would be pitted against an equally evil individual. This was found in the person of Lilith. Lilith in legend was the first wife of Adam. She rebelled against Adam, the angels, and even God. She came to be seen as a demon and a witch.

Elijah encountered Lilith and instantly recognized and challenged her, "Unclean one, where are you going?" Unable to avoid or lie to the prophet, she admitted she was on her way to the house of a pregnant woman. Her intention was to kill the woman and eat the child.

Elijah pronounced his malediction, "I curse you in the Name of the Lord. Be silent as a stone!" But, Lilith was able to make a bargain with Elijah. She promises to "forsake my evil ways" if Elijah will remove his curse. To seal the bargain she gives Elijah her names so that they can be posted in the houses of pregnant women or new born children or used as amulets. Lilith promises, "where I see those names, I shall run away at once. Neither the child nor the mother will ever be injured by me."

In the New Testament, Jesus would say for those who believed, John the Baptist was Elijah, who would come before the "great and terrible day" as predicted by Malachi.

Some English translations of the New Testament use Elias, a Latin form of the name. In the King James Version, "Elias" appears only in the texts translated from Greek.

John the Baptist preached a message of repentance and baptism. He predicted the day of judgment using imagery similar to that of Malachi. He also preached that the Messiah was coming. All of this was done in a style that immediately recalled the image of Elijah to his audience. He wore a coat of camel's hair secured with a leather girdle (, ). He also frequently preached in wilderness areas near the Jordan River.

In the Gospel of John, when John the Baptist was asked by a delegation of priests (present tense) "Art thou Elias", he replied "I am not" (). and however, make it clear that John was the spiritual successor to Elijah. In the Nativity of St. John the Baptist in Luke, Gabriel appears to Zechariah, John's father, and told him that John "will turn many of the sons of Israel to the Lord their God," and that he will go forth "in the spirit and power of Elijah" ().

In the Gospel of Luke, Herod Antipas hears some of the stories surrounding Jesus Christ. Some tell Herod that Jesus is John the Baptist (whom Herod had executed) come back to life. Others tell him that Jesus is Elijah. Later in the same gospel, Jesus asks his disciples who the people say that he is. The apostles' answer includes Elijah among others.

However Jesus' ministry had little in common with that of Elijah; in particular, he preached the forgiveness of one's enemies, while Elijah killed his. Miracle stories similar to those of Elijah were associated with Jesus (e. g. raising of the dead, miraculous feeding). Jesus implicitly separates himself from Elijah when he rebukes James and John for desiring to call down fire upon an unwelcoming Samaritan village in a similar manner to Elijah. Likewise, Jesus rebukes a potential follower who wanted first to return home to say farewell to his family, whereas Elijah permitted this of his replacement Elisha.

During Jesus' crucifixion, some of the onlookers wonder if Elijah will come to rescue him, as by the time of Jesus, Elijah had entered folklore as a rescuer of Jews in distress.

Elijah makes an appearance in the New Testament during an incident known as the Transfiguration.

At the summit of an unnamed mount, Jesus' face begins to shine. The disciples who are with Him hear the voice of God announce that Jesus is "My beloved Son." The disciples also see Moses and Elijah appear and talk with Jesus. Peter is so struck by the experience that he asks Jesus if they should build three "tabernacles": one for Elijah, one for Jesus and one for Moses.

There is agreement among some Christian theologians that Elijah appears to hand over the responsibility of the prophets to Jesus as the woman by the well said to Jesus (John 4:19) "I perceive thou art a prophet." and Moses also likewise came to hand over the responsibility of the law for the divinely announced Son of God.

Elijah is mentioned four more times in the New Testament: in Luke, Romans, Hebrews, and James. In , Jesus uses Elijah as an example of rejected prophets. Jesus says, "No prophet is accepted in his own country," and then mentions Elijah, saying that there were many widows in Israel, but Elijah was sent to one in Phoenicia. In , Paul cites Elijah as an example of God's never forsaking his people (the Israelites). ("Women received their dead raised to life again...") refers to both Elijah raising the son of the widow of Zarephath and Elisha raising the son of the woman of Shunem, citing both Elijah and Elisha as Old Testament examples of faith. In , James says, "The effectual fervent prayer of a righteous man availeth much," and then cites Elijah's prayers which started and ended the famine in Israel as examples.

In Western Christianity, the Prophet Elijah is commemorated as a saint with a feast day on 20 July by the Roman Catholic Church and the Lutheran Church–Missouri Synod. Catholics believe that he was unmarried and celibate.

In the Eastern Orthodox Church and those Eastern Catholic Churches which follow the Byzantine Rite, he is commemorated on the same date (in the 21st century, Julian Calendar 20 July corresponds to Gregorian Calendar 2 August). He is greatly revered among the Orthodox as a model of the contemplative life. He is also commemorated on the Orthodox liturgical calendar on the Sunday of the Holy Fathers (the Sunday before the Nativity of the Lord).

Elijah has been venerated as the patron saint of Bosnia and Herzegovina since 26 August 1752, replacing George of Lydda at the request of Bishop Pavao Dragičević. The reasons for the replacement are unclear. It has been suggested that Elijah was chosen because of his importance to all three main religious groups in Bosnia and Herzegovina—Catholics, Muslims and Orthodox Christians. Pope Benedict XIV is said to have approved Bishop Dragičević's request with the remark that a wild nation deserved a wild patron.

Elijah is revered as the spiritual Father and traditional founder of the Catholic religious Order of Carmelites. In addition to taking their name from Mt. Carmel where the first hermits of the order established themselves, the Calced Carmelite and Discalced Carmelite traditions pertaining to Elijah focus upon the prophet’s withdrawal from public life. The medieval Carmelite Book of the First Monks offers some insight into the heart of the Orders' contemplative vocation and reverence for the prophet.

In the 17th Century the Bollandist Society, whose declared aim was to search out and classify materials concerning the saints venerated by the Church, and to print what seemed to be the most reliable sources of information entered into controversy with the Carmelites on this point. In writing of St. Albert, Patriarch of Jerusalem and author of the Carmelite rule, the Bollandist Daniel Papebroch stated that the attribution of Carmelite origin to Elijah was insufficiently grounded. The Carmelites reacted strongly. From 1681 to 1698 a series of letters, pamphlets and other documents was issued by each side. The Carmelites were supported by a Spanish tribunal, while the Bollandists had the support of Jean de Launoy and the Sorbonne. In November 1698, Pope Innocent XII ordered an end to the controversy.

Since most Eastern Churches either use Greek as their liturgical language or translated their liturgies from the Greek, "Elias" (or its modern iotacized form "Ilias") is the form of the prophet's name used among most members of the Eastern Orthodox Church and those Eastern Catholic Churches which follow the Byzantine Rite.

The feast day of saint Elias falls on July 20 of the Orthodox liturgical calendar (for those churches which follow the traditional Julian Calendar, July 20 currently falls on August 2 of the modern Gregorian Calendar). This day is a major holiday in Lebanon and is one of a handful of holidays there whose celebration is accompanied by a launching of fireworks by the general public. The full name of St. Elias in Lebanon translates to St. Elias the Living because it is believed that he did not die but rode his fiery chariot to heaven. The reference to the fiery chariot is likely why the Lebanese celebrate this holiday with fireworks.

Elias is also commemorated, together with all of the righteous persons of the Old Testament, on the Sunday of the Holy Fathers (the Sunday before the Nativity of the Lord).

The Apolytikion in the Fourth Tone for St. Elias:
The incarnate Angel, the Cornerstone of the Prophets, the second Forerunner of the Coming of Christ, the glorious Elias, who from above, sent down to Elisha the grace to dispel sickness and cleanse lepers, abounds therefore in healing for those who honor him.

The Kontakion in the Second Tone for St. Elias:
O Prophet and foreseer of the great works of God, O greatly renowned Elias, who by your word held back the clouds of rain, intercede for us to the only Loving One.

Starting in the fifth century, Elias is often connected with Helios, the Sun. The two words have very similar pronunciations in post-classical Greek; Elijah rode in his chariot of fire to heaven () just as Helios drove the chariot of the sun across the sky; and the holocaust sacrifice offered by Elijah and burned by fire from heaven () corresponds to the sun warming the earth.

Sedulius writes poetically in the fifth century that the "bright path to glittering heaven" suits Elias both "in merits and name", as changing one letter makes his name "Helios"; but he does not identify the two. A homily entitled "De ascensione Heliae", misattributed to Chrysostom, claims that poets and painters use the ascension of Elijah as a model for their depictions of the sun, and says that "Elijah is really Helios". Saint Patrick appears to conflate Helios and Elias. In modern times, much Greek folklore also connects Elias with the sun.

In Greece, chapels and monasteries dedicated to Prophet Elias (Προφήτης Ηλίας) are often found on mountaintops, which themselves are often named after him. Since Wachsmuth (1864), the usual explanation for this has been that Elias was identified with Helios, who had mountaintop shrines. But few shrines of Helios were on mountaintops, and sun-worship was subsumed by Apollo-worship by Christian times, and so could not be confused with Elias. The modern folklore is not good evidence for the "origin" of the association of the sun, Elias, and mountaintops. Perhaps Elias is simply a "natural patron of high places".

The association of Elias with mountaintops seems to come from a different pagan tradition: Elias took on the attributes and the locales associated with Zeus, especially his associations with mountains and his powers over rain, thunder, lighting, and wind. When Elias prevailed over the priests of Baal, it was on Mount Carmel (), which later became known as Mount St. Elias. When he spent forty days in a cave, it was on Mount Horeb (). When Elias confronted Ahab, he stopped the rains for three years ().

A map of mountain-cults of Zeus shows that most of these sites are now dedicated to Elias, including Mount Olympus, Mount Lykaion, Mount Arachnaion, and Mount Taleton on the mainland, and Mount Kenaion, Mount Oche, and Mount Kynados in the islands. Of these, the only one with a recorded tradition of a Helios cult is Mount Taleton.

Elias is associated with pre-Christian lightning gods in many other European traditions.

Among Albanians, pilgrimages are made to mountaintops to ask for rain during the summer. One such tradition that is gaining popularity is the 2 August pilgrimage to Ljuboten on the Sharr mountains. Muslims refer to this day as "Aligjyn" ("Ali Day"), and it is believed that Ali becomes Elias at midday.
As Elijah was described as ascending into heaven in a fiery chariot, the Christian missionaries who converted Slavic tribes likely found him an ideal analogy for Perun, the supreme Slavic god of storms, thunder and lightning bolts. In many Slavic countries Elijah is known as Elijah the Thunderer (Ilija Gromovnik), who drives the heavens in a chariot and administers rain and snow, thus actually taking the place of Perun in popular beliefs. Perun is also sometimes conflated with the legendary hero Elijah of Murom. The feast of St. Elias is known as "Ilinden" in South Slavic, and was chosen as the day of the Ilinden-Preobrazhenie Uprising in 1903; it is now the holiday of Republic Day in the Republic of Macedonia.

In Estonian folklore Elijah is considered to be the successor of Ukko, the lightning spirit.

In Georgian mythology, he replaces Elwa. A Georgian story about Elijah:
Once Jesus, the prophet Elijah, and St. George were going through Georgia. When they became tired and hungry they stopped to dine. They saw a Georgian shepherd and decided to ask him to feed them. First, Elijah went up to the shepherd and asked him for a sheep. After the shepherd asked his identity Elijah said that, he was the one who sent him rain to get him a good profit from farming. The shepherd became angry at him and told him that he was the one who also sent thunderstorms, which destroyed the farms of poor widows. (After Elijah, Jesus and St. George attempt to get help and eventually succeed).
Elias has other pagan associations: a modern legend about Elias mirrors precisely the legend of Odysseus seeking a place where the locals would not recognize an oar—hence the mountaintops.

The Church of Jesus Christ of Latter-day Saints (LDS Church) acknowledges Elijah as a prophet. The LDS Church teaches that the Malachi prophecy of the return of Elijah was fulfilled on April 3, 1836, when Elijah visited the prophet and founder of the church, Joseph Smith, along with Oliver Cowdery, in the Kirtland Temple as a resurrected being. This event is chronicled in . This experience forms the basis for the church's focus on genealogy and family history and belief in the eternal nature of marriage and families.

In Latter-day Saint theology, the name-title Elias is not always synonymous with Elijah and is often used for people other than the biblical prophet. According to Joseph Smith, The spirit of Elias is first, Elijah second, and Messiah last. Elias is a forerunner to prepare the way, and the spirit and power of Elijah is to come after, holding the keys of power, building the Temple to the capstone, placing the seals of the Melchizedek Priesthood upon the house of Israel, and making all things ready; then Messiah comes to His Temple, which is last of all.

People to whom the title Elias is applied in Mormonism include Noah, the angel Gabriel (who is considered to be the same person as Noah in Mormon doctrine), Elijah, John the Baptist, John the Apostle, and an unspecified man who was a contemporary of Abraham.

Detractors of Mormonism have often alleged that Smith, in whose time and place the King James Version was the only available English translation of the Bible, simply failed to grasp the fact that the Elijah of the Old Testament and the Elias of the New Testament are the same person. Latter-day Saints deny this and say that the difference they make between the two is deliberate and prophetic. The names Elias and Elijah refer to one who prepares the way for the coming of the Lord. This is applicable to John the Baptist coming to prepare the way for the Lord and His baptism; it also refers to Elijah appearing during the transfiguration to prepare for Jesus by restoring keys of sealing power. Jesus then gave this power to the Twelve saying, "Verily I say unto you, Whatsoever ye shall bind on earth shall be bound in heaven: and whatsoever ye shall loose on earth shall be loosed in heaven." 

Elijah ( or ; "Ilyas" or "Ilya") is also mentioned as a prophet in the Qur'an, al-An'am 85. Elijah's narrative in the Qur'an and later Muslim tradition resembles closely that in the Hebrew Bible and Muslim literature records Elijah's primary prophesying as taking place during the reign of Ahab and Jezebel as well as Ahaziah. He is seen by Muslims to be the prophetic predecessor to Elisha. While neither the Bible nor the Qur'an mentions the genealogy of Elijah, some scholars of Islam believe he may have come from the priestly family of the prophet Aaron. Elijah is rarely associated with Islamic eschatology and Islam views Jesus as the Messiah. However, Elijah is expected to come back along with the mysterious figure known as Khidr during the Last Judgment. Elijah's figure has been identified with a number of other prophets and saints, including Idris, which is believed by some scholars to have been another name for Elijah, and Khidr. Islamic legend later developed the figure of Elijah, greatly embellishing upon his attributes, and some apocryphal literature gave Elijah the status of a half-human, half-angel. Elijah also appears in later works of literature, including the "Hamzanama".

Elijah is mentioned in the Quran, where his preaching is recounted in a concise manner. The Quran narrates that Elijah told his people to come to the worship of God and to leave the worship of Baal, the primary idol of the area. The Quran states, "Verily Elijah was one of the apostles. When he said to his people: "Will you not fear God? "Will ye call upon Ba'al and leave the Best of Creators, God, your and Cherisher and the and Cherisher of your fathers of old?" As-Saaffat 123–126

The Quran makes it clear that the majority of Elijah's people denied the prophet and continued to follow idolatry. However, it mentions that a small number of devoted servants of God among them followed Elijah and believed in and worshiped God. The Quran states, "They denied him (Elijah), and will surely be brought to punishment, Except the sincere and devoted Servants of God (among them). And We left his (memory) for posterity." As-Saaffat 127–128

In the Quran, God praises Elijah in two places:

Numerous commentators, including Abdullah Yusuf Ali, have offered commentary on VI: 85 saying that Elijah, Zechariah, John the Baptist and Jesus were all spiritually connected. Abdullah Yusuf Ali says, "The third group consists not of men of action, but Preachers of Truth, who led solitary lives. Their epithet is: "the Righteous." They form a connected group round Jesus. Zachariah was the father of John the Baptist, who is referenced as "Elias, which was for to come" (Matt 11:14); and Elias is said to have been present and talked to Jesus at the Transfiguration on the Mount (Matt. 17:3)."

Muslim literature and tradition recounts that Elijah preached to the Kingdom of Israel, ruled over by Ahab and later his son Ahaziah. He is believed to have been a "prophet of the desert—like John the Baptist". Elijah is believed to have preached with zeal to Ahab and his wife Jezebel, who according to Muslim tradition was partly responsible for the worship of false idols in this area. Muslims believe that it was because the majority of people refused to listen to Elijah that Elisha had to continue preaching the message of God to Israel after him.

Elijah has been the subject of legends and folktales in Muslim culture, usually involving his meeting with Khidr, and in one legend, with Muhammad himself. Most such legends, however, are regarded as folktales rather than actual events. In Islamic mysticism, however, Elijah is associated closely with the sage Khidr. One legend reported that Elijah and Khidr met together every year in Jerusalem to go on the pilgrimage to Mecca. Elijah appears also in the "Hamzanama" numerous times, where he is spoken of as being the brother of Khidr as well as one who drunk from the Fountain of Youth.

Although most Muslim scholars believed that Elijah preached in Israel, some early commentators on the Qur'an stated that Elijah was sent to Baalbek, in Lebanon. Modern scholars have rejected this claim, stating that the connection of the city with Elijah would have been made because of the first half of the city's name, that of "Baal", which was the deity that Elijah exhorted his people to stop worshiping. Scholars who reject identification of Elijah's town with Baalbek further argue that the town of Baalbek is not mentioned with the narrative of Elijah in either the Qur'an or the Hebrew Bible.

In the Bahá'í Faith, the Báb, founder of the Bábí Faith, is believed to be the return of Elijah and John the Baptist. Both Elijah and John the Baptist are considered to be Lesser Prophets, whose stations are below that of a Manifestation of God like Jesus Christ, Buddha, Muhammad, the Báb or Bahá'u'lláh. The Báb is buried on Mount Carmel, where Elijah had his confrontation with the prophets of Baal.

That "ravens" fed Elijah by the brook Chorath has been questioned. The Hebrew text at uses the word "`ōrvīm", which means "ravens", but with a different vocalization might equally mean "Arabs". The Septuagint has , "ravens", and other traditional translations followed.

Alternatives have been proposed for many years; for example Adam Clarke (d. 1832) treated it as a discussion already of long standing. Objections to the traditional translation are that ravens are ritually unclean (see ) as well as physically dirty; it is difficult to imagine any method of delivery of the food which is not disgusting. The parallelism with the incident that follows, where Elijah is fed by the widow, also suggests a human, if mildly improbable, agent.

Prof. John Gray chooses "Arabs", saying "We adopt this reading solely because of its congruity with the sequel, where Elijah is fed by an alien Phoenician woman." His translation of the verses in question is: And the word of Jehovah came to Elijah saying, Go hence and turn eastward and hide thyself in the Wadi Chorath east of the Jordan, and it shall be that thou shalt drink of the wadi, and I have commanded the Arabs to feed thee there. And he went and did according to the word of Jehovah and went and dwelt in the Wadi Chorath east of the Jordan. And the Arabs brought him bread in the morning and flesh in the evening and he would drink of the wadi.

In the Gospel of John, Jesus says: "And no man hath ascended up to heaven, but he that came down from heaven, "[even]" the Son of man which is in heaven." (John 3:13)

Traditionally Christianity interprets the "Son of Man" as a title of Jesus, but this has never been an article of faith and there are other interpretations. Further interpreting this quote, some Christians believe that Elijah was not assumed into heaven but simply transferred to another assignment either in heaven or with King Jehoram of Judah. The prophets reacted in such a way that makes sense if he was carried away, and not simply straight up ().

The question of whether Elijah was in heaven or elsewhere on earth depends partly on the view of the letter Jehoram received from Elijah in 2 Chronicles 21 after Elijah had ascended. Some have suggested that the letter was written before Elijah ascended, but only delivered later. The rabbinical Seder Olam explains that the letter was delivered seven years after his ascension. This is also a possible explanation for some variation in manuscripts of Josephus' "Antiquities of the Jews" when dealing with this issue. Others have argued that Elijah was only "caught away" such as Philip in Acts 8:39 John Lightfoot reasoned that it must have been a different Elijah.

Elijah's name typically occurs in Jewish lists of those who have entered heaven alive.

Centuries after his departure the Jewish nation awaits the coming of Elijah to precede the coming of the Messiah. For many Christians this prophecy was fulfilled in the gospels, where he appears during the Transfiguration alongside Moses (). Commentators have said that Moses' appearance represented the law, while Elijah's appearance represented the prophets. 
The Church of Jesus Christ of Latter-day Saints believes that Elijah returned on April 3, 1836 in an appearance to Joseph Smith and Oliver Cowdery, fulfilling the prophecy in Malachi.

The Bahá'í Faith believes Elijah returned as the biblical prophet John the Baptist and as the Báb who founded the Bábí Faith in 1844.

The Nation of Islam believes Elijah returned as Elijah Muhammad, black separatist religious leader (who claimed to be a "messenger", not a prophet). This is considered less important than their belief that Allah himself showed up in the person of Fard Muhammad, the founder of the group. It differs notably from most beliefs about Elijah, in that his re-appearance is usually the precursor to a greater one's appearance, rather than an afterthought.











</doc>
<doc id="9841" url="https://en.wikipedia.org/wiki?curid=9841" title="Expressive aphasia">
Expressive aphasia

Expressive aphasia, also known as Broca's aphasia, is characterized by partial loss of the ability to produce language (spoken, manual, or written), although comprehension generally remains intact. A person with expressive aphasia will exhibit effortful speech. Speech generally includes important content words, but leaves out function words that have only grammatical significance and not real-world meaning, such as prepositions and articles. This is known as "telegraphic speech". The person's intended message may still be understood but his or her sentence will not be grammatically correct. In very severe forms of expressive aphasia, a person may only speak using single word utterances. Typically, comprehension is mildly to moderately impaired in expressive aphasia due to difficulty understanding complex grammar.

It is caused by acquired damage to the anterior regions of the brain, such as the left posterior inferior frontal gyrus or inferior frontal operculum, also described as Broca's area (Brodmann area 44 and Brodmann area 45). It is one subset of a larger family of disorders known collectively as aphasia. Expressive aphasia contrasts with receptive aphasia, in which patients are able to speak in grammatical sentences that lack semantic significance, and generally also have trouble with comprehension. Expressive aphasia differs from dysarthria, which is typified by a patient's inability to properly move the muscles of the tongue and mouth to produce speech. Expressive aphasia also differs from apraxia of speech which is a motor disorder characterized by an inability to create and sequence motor plans for speech.

Broca's (expressive) aphasia is a type of non-fluent aphasia in which an individual’s speech is halting and effortful. Misarticulations or distortions of consonants and vowels, namely phonetic dissolution, are common. Individuals with expressive aphasia may only produce single words, or words in groups of two or three. Long pauses between words are common and multi-syllabic words may be produced one syllable at a time with pauses between each syllable. The prosody of a person with Broca's aphasia is compromised by shortened length of utterances and the presence of self-repairs and disfluencies. Intonation and stress patterns are also deficient.

For example, in the following passage, a patient with Broca's aphasia is trying to explain how he came to the hospital for dental surgery and it may look like this:Yes... ah... Monday... er... Dad and Peter H... (his own name), and Dad... er... hospital... and ah... Wednesday... Wednesday, nine o'clock... and oh... Thursday... ten o'clock, ah doctors... two... an' doctors... and er... teeth... yah.The speech of a person with expressive aphasia contains mostly content words such as nouns, verbs, and some adjectives. However, function words like conjunctions, articles, and prepositions are rarely used except for “and” which is prevalent in the speech of most patients with aphasia. The omission of function words makes the person's speech agrammatic. A communication partner of a person with aphasia may say that the person's speech sounds telegraphic due to poor sentence construction and disjointed words. For example, a person with expressive aphasia might say "Smart... university... smart... good... good..."

Self-monitoring is typically well preserved in patients with Broca's aphasia. They are usually aware of their communication deficits, and are more prone to depression and outbursts from frustration than are patients with other forms of aphasia.

In general, word comprehension is preserved, allowing patients to have functional receptive language skills. Individuals with Broca's aphasia understand most of the everyday conversation around them, but higher-level deficits in receptive language can occur. Because comprehension is substantially impaired for more complex sentences, it is better to use simple language when speaking with an individual with expressive aphasia. This is exemplified by the difficulty to understand phrases or sentences with unusual structure. A typical patient with Broca's aphasia will misinterpret "the man is bitten by the dog" by switching the subject and object to “the dog is bitten by the man.”

Typically, people with expressive aphasia can understand speech and read better than they can produce speech and write. The person's writing will resemble his or her speech and will be effortful, lacking cohesion, and containing mostly content words. Letters will likely be formed clumsily and distorted and some may even be omitted. Although listening and reading are generally intact, subtle deficits in both reading and listening comprehension are almost always present during assessment of aphasia.

Because Broca's area is anterior to the primary motor cortex which is responsible for movement of the face, hands, and arms, a lesion affecting Broca's areas may also result in hemiparesis (weakness of both limbs on the same side of the body) or hemiplegia (paralysis of both limbs on the same side of the body). The brain is wired contralaterally, which means the limbs on right side of the body are controlled by the left hemisphere and vice versa. Therefore, when Broca's area or surrounding areas in the left hemisphere are damaged, hemiplegia or hemiparesis often occurs on the right side of the body in individuals with Broca's aphasia.

Severity of expressive aphasia varies among patients. Some people may only have mild deficits and detecting problems with their language may be difficult. In the most extreme cases, patients may be able to produce only a single word. Even in such cases, over-learned and rote-learned speech patterns may be retained- for instance, some patients can count from one to ten, but cannot produce the same numbers in novel conversation.

In deaf patients who use manual language (such as American Sign Language), damage to the left hemisphere of the brain leads to disruptions in their signing ability. Paraphasic errors similar to spoken language have been observed; whereas in spoken language a phonemic substitution would occur (e.g. "tagle" instead of "table"), in ASL case studies errors in movement, hand position, and morphology have been noted. Agrammatism, or the lack of grammatical morphemes in sentence production, has also been observed in lifelong users of American Sign Language who have left hemisphere damage. The lack of syntactic accuracy shows that the errors in signing are not due to damage to the motor cortex, but rather are a manifestation of the damage to the language-producing area of the brain. Similar symptoms have been seen in a patient with left hemisphere damage whose first language was British Sign Language, further showing that damage to the left hemisphere primarily hinders linguistic ability, not motor ability. In contrast, patients who have damage to non-linguistic areas on the left hemisphere have been shown to be fluent in signing, but are unable to comprehend written language.

In addition to difficulty expressing oneself, individuals with expressive aphasia are also noted to commonly have trouble with comprehension in certain linguistic areas. This agrammatism overlaps with receptive aphasia, but can be seen in patients who have expressive aphasia without being diagnosed as having receptive aphasia. The most well-noted of these are object-relative clauses, object Wh- questions, and topicalized structures (placing the topic at the beginning of the sentence). These three concepts all share phrasal movement, which can cause words to lose their thematic roles when they change order in the sentence. This is often not an issue for people without agrammatic aphasias, but many people with aphasia rely heavily on word order to understand roles that words play within the sentence.

The most common cause of expressive aphasia is stroke. A stroke is caused by hypoperfusion (lack of oxygen) to an area of the brain, which is commonly caused by thrombosis or embolism. Some form of aphasia occurs in 34 to 38% of stroke patients. Expressive aphasia occurs in approximately 12% of new cases of aphasia caused by stroke.

In most cases, expressive aphasia is caused by a stroke in Broca's area or the surrounding vicinity. Broca's area is in the lower part of the premotor cortex in the language dominant hemisphere and is responsible for planning motor speech movements. However, cases of expressive aphasia have been seen in patients with strokes in other areas of the brain. Patients with classic symptoms of expressive aphasia in general have more acute brain lesions, whereas patients with larger, widespread lesions exhibit a variety of symptoms that may be classified as global aphasia or left unclassified.

Expressive aphasia can also be caused by trauma to the brain, tumor, cerebral hemorrhage by extradural hematoma.

Understanding lateralization of brain function is important for understanding what areas of the brain cause expressive aphasia when damaged. In the past, it has been believed that the area for language production differs between left and right-handed individuals. If this were true, damage to the homologous region of Broca's area in the right hemisphere should cause aphasia in a left-handed individual. More recent studies have shown that even left-handed individuals typically have language functions only in the left hemisphere. However, left-handed individuals are more likely to have a dominance of language in the right hemisphere.

Expressive aphasia is classified as non-fluent aphasia, as opposed to fluent aphasia. Diagnosis is done on a case by case basis, as lesions often affect the surrounding cortex and deficits are highly variable among patients with aphasia.

A physician is typically the first person to recognize aphasia in a patient who is being treated for damage to the brain. Routine processes for determining the presence and location of lesion in the brain include Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) scans. The physician will complete a brief assessment of the patient's ability to understand and produce language. For further diagnostic testing, the physician will refer the patient to a speech-language pathologist, who will complete a comprehensive evaluation.

In order to diagnose a patient who is suffering from Broca’s aphasia, there are certain commonly used tests and procedures. The Western Aphasia Battery (WAB) classifies individuals based on their scores on the subtests; spontaneous speech, auditory comprehension, repetition, and naming. The Boston Diagnostic Aphasia Examination (BDAE) can inform users what specific type of aphasia they may have, infer the location of lesion, and assess current language abilities. The Porch Index of Communication Ability (PICA) can predict potential recovery outcomes of the patients with aphasia. Quality of life measurement is also an important assessment tool. Tests such as the Assessment for Living with Aphasia (ALA) and the Satisfaction with Life Scale (SWLS) allow for therapists to target skills that are important and meaningful for the individual.

In addition to formal assessments, patient and family interviews are valid and important sources of information. The patient’s previous hobbies, interests, personality, and occupation are all factors that will not only impact therapy but may motivate them throughout the recovery process. Patient interviews and observations allow professionals to learn the priorities of the patient and family and determine what the patient hopes to regain in therapy. Observations of the patient may also be beneficial to determine where to begin treatment. The current behaviors and interactions of the patient will provide the therapist with more insight about the client and his or her individual needs. Other information about the patient can be retrieved from medical records, patient referrals from physicians, and the nursing staff.

In non-speaking patients who use manual languages, diagnosis is often based on interviews from the patient's acquaintances, noting the differences in sign production pre- and post- damage to the brain. Many of these patients will also begin to rely on non-linguistic gestures to communicate, rather than signing since their language production is hindered.

Currently, there is no standard treatment for expressive aphasia. Most aphasia treatment is individualized based on a patient's condition and needs as assessed by a speech language pathologist. Patients go through a period of spontaneous recovery following brain injury in which they regain a great deal of language function.

In the months following injury or stroke, most patients receive traditional treatment for a few hours per day. Among other exercises, patients practice the repetition of words and phrases. Mechanisms are also taught in traditional treatment to compensate for lost language function such as drawing and using phrases that are easier to pronounce.

Emphasis is placed on establishing a basis for communication with family and caregivers in everyday life. Treatment is individualized based on the patient's own priorities, along with the family's input.

A patient may have the option of individual or group treatment. Although less common, group treatment has been shown to have advantageous outcomes. Some types of group treatments include family counseling, maintenance groups, support groups and treatment groups.

Melodic intonation therapy was inspired by the observation that individuals with non-fluent aphasia sometimes can sing words or phrases that they normally cannot speak. "Melodic Intonation Therapy was begun as an attempt to use the intact melodic/prosodic processing skills of the right hemisphere in those with aphasia to help cue retrieval words and expressive language." It is believed that this is because singing capabilities are stored in the right hemisphere of the brain, which is likely to remain unaffected after a stroke in the left hemisphere. However, recent evidence demonstrates that the capability of individuals with aphasia to sing entire pieces of text may actually result from rhythmic features and the familiarity with the lyrics.

The goal of Melodic Intonation Therapy is to utilize singing to access the language-capable regions in the right hemisphere and use these regions to compensate for lost function in the left hemisphere. The natural musical component of speech was used to engage the patients' ability to produce phrases. A clinical study revealed that singing and rhythmic speech may be similarly effective in the treatment of non-fluent aphasia and apraxia of speech. Moreover, evidence from randomized controlled trials is still needed to confirm that Melodic Intonation Therapy is suitable to improve propositional utterances and speech intelligibility in individuals with (chronic) non-fluent aphasia and apraxia of speech.

Melodic Intonation Therapy appears to work particularly well in patients who have had a unilateral, left hemisphere stroke, show poor articulation, are non-fluent or have severely restricted speech output, have moderately preserved auditory comprehension, and show good motivation. MIT therapy on average lasts for 1.5 hours per day for five days per week. At the lowest level of therapy, simple words and phrases (such as "water" and "I love you") are broken down into a series of high- and low-pitch syllables. With increased treatment, longer phrases are taught and less support is provided by the therapist. Patients are taught to say phrases using the natural melodic component of speaking and continuous voicing is emphasized. The patient is also instructed to use the left hand to tap the syllables of the phrase while the phrases are spoken. Tapping is assumed to trigger the rhythmic component of speaking to utilize the right hemisphere.

FMRI studies have shown that Melodic Intonation Therapy (MIT) uses both sides of the brain to recover lost function, as opposed to traditional therapies that utilize only the left hemisphere. In MIT, individuals with small lesions in the left hemisphere seem to recover by activation of the left hemisphere perilesional cortex. Meanwhile, individuals with larger left-hemisphere lesions show a recruitment of the use of language-capable regions in the right hemisphere. The interpretation of these results is still a matter of debate. For example, it remains unclear whether changes in neural activity in the right hemisphere result from singing or from the intensive use of common phrases, such as "thank you", "how are you?" or "I am fine." This type of phrases falls into the category of formulaic language and is known to be supported by neural networks of the intact right hemisphere.

A pilot study reported positive results when comparing the efficacy of a modified form of MIT to no treatment in people with nonfluent aphasia with damage to their left-brain. A randomized controlled trial was conducted and the study reported benefits of utilizing modified MIT treatment early in the recovery phase for people with nonfluent aphasia.

Melodic Intonation Therapy is used by music therapists, board-certified professionals that use music as a therapeutic tool to effect certain non-musical outcomes in their patients. Speech language pathologists can also use this therapy for individuals who have had a left hemisphere stroke and non-fluent aphasias such as Broca’s or even apraxia of speech. Candidates show good auditory comprehension, poor repetition and articulation skills, and good emotional stability and memory.

Constraint-induced aphasia therapy (CIAT) is based on similar principles as constraint-induced movement therapy developed by Dr. Edward Taub at the University of Alabama at Birmingham. Constraint-induced movement therapy is based on the idea that a person with an impairment (physical or communicative) develops a "learned nonuse" by compensating for the lost function with other means such as using an unaffected limb by a paralyzed individual or drawing by a patient with aphasia. In constraint-induced movement therapy, the alternative limb is constrained with a glove or sling and the patient is forced to use the affected limb. In constraint-induced aphasia therapy the interaction is guided by communicative need in a language game context, picture cards, barriers making it impossible to see other players' cards, and other materials, so that patients are encouraged ("constrained") to use the remaining verbal abilities to succeed in the communication game.

Two important principles of constraint-induced aphasia therapy are that treatment is very intense, with sessions lasting for up to 6 hours over the course of 10 days and that language is used in a communication context in which it is closely linked to (nonverbal) actions. These principles are motivated by neuroscience insights about learning at the level of nerve cells (synaptic plasticity) and the coupling between cortical systems for language and action in the human brain. Constraint-induced therapy contrasts sharply with traditional therapy by the strong belief that mechanisms to compensate for lost language function should not be used unless absolutely necessary, even in everyday life.

It is believed that CIAT works by the mechanism of increased neuroplasticity. By constraining an individual to use only speech, it is believed that the brain can reestablish old neural pathways and recruit new neural pathways to compensate for lost function.

The greatest advantage of CIAT has been seen in its treatment of chronic aphasia (lasting over 1 year). Studies of CIAT have shown that further improvement is possible even after a patient has reached a "plateau" period of recovery. It has also been proven that the benefits of CIAT are retained long term. However, improvements only seem to be made while a patient is undergoing intense therapy. A recent breakthrough has been achieved by combining constraint-induced aphasia therapy with drug treatment, which led to an amplification of therapy benefits.

In addition to active speech therapy, pharmaceuticals have also been considered as a useful treatment for expressive aphasia. This area of study is relatively new and much research continues to be conducted.

The following drugs have been suggested for use in treating aphasia and their efficacy has been studied in control studies.


The most effect has been shown by piracetam and amphetamine, which may increase cerebral plasticity and result in an increased capability to improve language function. It has been seen that piracetam is most effective when treatment is begun immediately following stroke. When used in chronic cases it has been much less efficient.

Bromocriptine has been shown by some studies to increase verbal fluency and word retrieval with therapy than with just therapy alone. Furthermore, its use seems to be restricted to non-fluent aphasia.

Donepezil has shown a potential for helping chronic aphasia.

No study has established irrefutable evidence that any drug is an effective treatment for aphasia therapy. Furthermore, no study has shown any drug to be specific for language recovery. Comparison between the recovery of language function and other motor function using any drug has shown that improvement is due to a global increase plasticity of neural networks.

In transcranial magnetic stimulation (TMS), magnetic fields are used to create electrical currents in specified cortical regions. The procedure is a painless and noninvasive method of stimulating the cortex. TMS works by suppressing the inhibition process in certain areas of the brain. By suppressing the inhibition of neurons by external factors, the targeted area of the brain may be reactivated and thereby recruited to compensate for lost function. Research has shown that patients can demonstrate increased object naming ability with regular transcranial magnetic stimulation than patients not receiving TMS. Furthermore, research suggests this improvement is sustained upon the completion of TMS therapy. However, some patients fail to show any significant improvement from TMS which indicates the need for further research of this treatment.

Described as the linguistic approach to the treatment of expressive aphasia, treatment begins by emphasizing and educating patients on the thematic roles of words within sentences. Sentences that are usually problematic will be reworded into active-voiced, declarative phrasings of their non-canonical counterparts. The simpler sentence phrasings are then transformed into variations that are more difficult to interpret. For example, many individuals who have expressive aphasia struggle with Wh- sentences. "What" and "who" questions are problematic sentences that this treatment method attempts to improve, and they are also two interrogative particles that are strongly related to each other because they reorder arguments from the declarative counterparts. For instance, therapists have used sentences like, "Who is the boy helping?" and "What is the boy fixing?" because both verbs are transitive- they require two arguments in the form of a subject and a direct object, but not necessarily an indirect object. In addition, certain question particles are linked together based on how the reworded sentence is formed. Training "who" sentences increased the generalizations of non-trained "who" sentences as well as untrained "what" sentences, and vice versa. Likewise, "where" and "when" question types are very closely linked. "What" and "who" questions alter placement of arguments, and "where" and "when" sentences move adjunct phrases. Training is in the style of: "The man parked the car in the driveway. What did the man park in the driveway?" Sentence training goes on in this manner for more domains, such as clefts and sentence voice.

Results: Patients’ use of sentence types used in the TUF treatment will improve, subjects will generalize sentences of similar category to those used for treatment in TUF, and results are applied to real-world conversations with others. Generalization of sentence types used can be improved when the treatment progresses in the order of more complex sentences to more elementary sentences. Treatment has been shown to affect on-line (real-time) processing of trained sentences and these results can be tracked using fMRI mappings. Training of Wh- sentences has led improvements in three main areas of discourse for aphasics: increased average length of utterances, higher proportions of grammatical sentences, and larger ratios of numbers of verbs to nouns produced. Patients also showed improvements in verb argument structure productions and assigned thematic roles to words in utterances with more accuracy. In terms of on-line sentence processing, patients having undergone this treatment discriminate between anomalous and non-anomalous sentences with more accuracy than control groups and are closer to levels of normalcy than patients not having participated in this treatment.

Mechanisms for recovery differ from patient to patient. Some mechanisms for recovery occur spontaneously after damage to the brain, whereas others are caused by the effects of language therapy. FMRI studies have shown that recovery can be partially attributed to the activation of tissue around the damaged area and the recruitment of new neurons in these areas to compensate for the lost function. Recovery may also be caused in very acute lesions by a return of blood flow and function to damaged tissue that has not died around an injured area. It has been stated by some researchers that the recruitment and recovery of neurons in the left hemisphere opposed to the recruitment of similar neurons in the right hemisphere is superior for long-term recovery and continued rehabilitation. It is thought that, because the right hemisphere is not intended for full language function, using the right hemisphere as a mechanism of recovery is effectively a "dead-end" and can lead only to partial recovery.

It has been proven that, among all types of therapies, one of the most important factors and best predictors for a successful outcome is the intensity of the therapy. By comparing the length and intensity of various methods of therapies, it was proven that intensity is a better predictor of recovery than the method of therapy used.

In most individuals with expressive aphasia, the majority of recovery is seen within the first year following a stroke or injury. The majority of this improvement is seen in the first four weeks in therapy following a stroke and slows thereafter. However, this timeline will vary depending upon the type of stroke experienced by the patient. Patients who experienced an ischemic stroke may recover in the days and weeks following the stroke, and then experience a plateau and gradual slowing of recovery. On the contrary, patients who experienced a hemorrhagic stroke experience a slower recovery in the first 4–8 weeks, followed by a faster recovery which eventually stabilizes.

Numerous factors impact the recovery process and outcomes. Site and extent of lesion greatly impacts recovery. Other factors that may affect prognosis are age, education, gender, and motivation. Occupation, handedness, personality, and emotional state may also be associated with recovery outcomes.

Studies have also found that prognosis of expressive aphasia correlates strongly with the initial severity of impairment. However, it has been seen that continued recovery is possible years after a stroke with effective treatment. Timing and intensity of treatment is another factor that impacts outcomes. Research suggests that even in later stages of recovery, intervention is effective at improving function, as well as, preventing loss of function.

Unlike receptive aphasia, patients with expressive aphasia are aware of their errors in language production. This may further motivate a person with expressive aphasia to progress in treatment, which would affect treatment outcomes. On the other hand, awareness of impairment may lead to higher levels of frustration, depression, anxiety, or social withdrawal, which have been proven to negatively affect a person's chance of recovery.

Expressive aphasia was first identified by the French neurologist Paul Broca. By examining the brains of deceased individuals having acquired expressive aphasia in life, he concluded that language ability is localized in the ventroposterior region of the frontal lobe. One of the most important aspects of Paul Broca's discovery was the observation that the loss of proper speech in expressive aphasia is due to the brain's loss of ability to produce language, as opposed to the mouth's loss of ability to produce words.

The discoveries of Paul Broca were made during the same period of time as the German Neurologist Carl Wernicke, who was also studying brains of aphasiacs post-mortem and identified the region now known as Wernicke's area. Discoveries of both men contributed to the concept of localization, which states that specific brain functions are all localized to a specific area of the brain. While both men made significant contributions to the field of aphasia, it was Carl Wernicke who realized the difference between patients with aphasia that could not produce language and those that could not comprehend language (the essential difference between expressive and receptive aphasia). it is really harmful to the health and needs to be taken care of as soon as possible





</doc>
<doc id="9843" url="https://en.wikipedia.org/wiki?curid=9843" title="Ephesus">
Ephesus

Ephesus (; "Ephesos"; ; may ultimately derive from Hittite "Apasa") was an ancient Greek city on the coast of Ionia, three kilometres southwest of present-day Selçuk in İzmir Province, Turkey. It was built in the 10th century BC on the site of the former Arzawan capital by Attic and Ionian Greek colonists. During the Classical Greek era it was one of the twelve cities of the Ionian League. The city flourished after it came under the control of the Roman Republic in 129 BC.

The city was famed for the nearby Temple of Artemis (completed around 550 BC), one of the Seven Wonders of the Ancient World. Among many other monumental buildings are the Library of Celsus, and a theatre capable of holding 25,000 spectators.

Ephesus was one of the seven churches of Asia that are cited in the Book of Revelation. The Gospel of John may have been written here. The city was the site of several 5th century Christian Councils (see Council of Ephesus).

The city was destroyed by the Goths in 263, and although rebuilt, the city's importance as a commercial centre declined as the harbour was slowly silted up by the Küçükmenderes River. It was partially destroyed by an earthquake in 614 AD.

The ruins of Ephesus are a favourite international and local tourist attraction, partly owing to their easy access from Adnan Menderes Airport or from the cruise ship port of Kuşadası, some 30 km to the South.

The area surrounding Ephesus was already inhabited during the Neolithic Age (about 6000 BC), as was revealed by excavations at the nearby "höyük" (artificial mounds known as tells) of Arvalya and Cukurici.

Excavations in recent years have unearthed settlements from the early Bronze Age at Ayasuluk Hill. According to Hittite sources, the capital of the Kingdom of Arzawa (another independent state in Western and Southern Anatolia/Asia Minor) was Apasa (or "Abasa"). Some scholars suggest that this is the later Greek Ephesus. In 1954, a burial ground from the Mycenaean era (1500–1400 BC) with ceramic pots was discovered close to the ruins of the basilica of St. John. This was the period of the Mycenaean Expansion when the "Achaioi" (as they were called by Homer) settled in Asia Minor during the 14th and 13th centuries BC. Scholars believe that Ephesus was founded on the settlement of Apasa (or "Abasa"), a Bronze Age city noted in 14th century BC Hittite sources as being under the rule of the Ahhiyawans, most probably the name of the Achaeans used in Hittite sources.

Ephesus was founded as an Attic-Ionian colony in the 10th century BC on a hill (now known as the Ayasuluk Hill), three kilometers () from the centre of ancient Ephesus (as attested by excavations at the Seljuk castle during the 1990s). The mythical founder of the city was a prince of Athens named Androklos, who had to leave his country after the death of his father, King Kodros. According to the legend, he founded Ephesus on the place where the oracle of Delphi became reality ("A fish and a boar will show you the way"). Androklos drove away most of the native Carian and Lelegian inhabitants of the city and united his people with the remainder. He was a successful warrior, and as a king he was able to join the twelve cities of Ionia together into the Ionian League. During his reign the city began to prosper. He died in a battle against the Carians when he came to the aid of Priene, another city of the Ionian League. Androklos and his dog are depicted on the Hadrian temple frieze, dating from the 2nd century. Later, Greek historians such as Pausanias, Strabo and Herodotos and the poet Kallinos reassigned the city's mythological foundation to Ephos, queen of the Amazons.

The Greek goddess Artemis and the great Anatolian goddess Kybele were identified together as "Artemis of Ephesus". The many-breasted "Lady of Ephesus", identified with Artemis, was venerated in the Temple of Artemis, one of the Seven Wonders of the World and the largest building of the ancient world according to Pausanias (4.31.8). Pausanias mentions that the temple was built by Ephesus, son of the river god Caystrus, before the arrival of the Ionians. Of this structure, scarcely a trace remains.

About 650 BC, Ephesus was attacked by the Cimmerians who razed the city, including the temple of Artemis. After the Cimmerians had been driven away, the city was ruled by a series of tyrants. Following a revolt by the people, Ephesus was ruled by a council. The city prospered again under a new rule, producing a number of important historical figures such as the elegiac poet Callinus and the iambic poet Hipponax, the philosopher Heraclitus, the great painter Parrhasius and later the grammarian Zenodotos and physicians Soranus and Rufus.

About 560 BC, Ephesus was conquered by the Lydians under king Croesus, who, though a harsh ruler, treated the inhabitants with respect and even became the main contributor to the reconstruction of the temple of Artemis. His signature has been found on the base of one of the columns of the temple (now on display in the British Museum). Croesus made the populations of the different settlements around Ephesus regroup ("synoikismos") in the vicinity of the Temple of Artemis, enlarging the city.

Later in the same century, the Lydians under Croesus invaded Persia. The Ionians refused a peace offer from Cyrus the Great, siding with the Lydians instead. After the Persians defeated Croesus, the Ionians offered to make peace, but Cyrus insisted that they surrender and become part of the empire. They were defeated by the Persian army commander Harpagos in 547 BC. The Persians then incorporated the Greek cities of Asia Minor into the Achaemenid Empire. Those cities were then ruled by satraps.

Ephesus has intrigued archaeologists because for the Archaic Period there is no definite location for the settlement. There are numerous sites to suggest the movement of a settlement between the Bronze Age and the Roman period, but the silting up of the natural harbours as well as the movement of the Kayster River meant that the location never remained the same.

Ephesus continued to prosper, but when taxes were raised under Cambyses II and Darius, the Ephesians participated in the Ionian Revolt against Persian rule in the Battle of Ephesus (498 BC), an event which instigated the Greco-Persian wars. In 479 BC, the Ionians, together with Athens, were able to oust the Persians from the shores of Asia Minor. In 478 BC, the Ionian cities with Athens entered into the Delian League against the Persians. Ephesus did not contribute ships but gave financial support.

During the Peloponnesian War, Ephesus was first allied to Athens but in a later phase, called the Decelean War, or the Ionian War, sided with Sparta, which also had received the support of the Persians. As a result, rule over the cities of Ionia was ceded again to Persia.

These wars did not greatly affect daily life in Ephesus. The Ephesians were surprisingly modern in their social relations: they allowed strangers to integrate and education was valued. In later times, Pliny the Elder mentioned having seen at Ephesus a representation of the goddess Diana by Timarata, the daughter of a painter.

In 356 BC the temple of Artemis was burnt down, according to legend, by a lunatic called Herostratus. The inhabitants of Ephesus at once set about restoring the temple and even planned a larger and grander one than the original.

When Alexander the Great defeated the Persian forces at the Battle of Granicus in 334 BC, the Greek cities of Asia Minor were liberated. The pro-Persian tyrant Syrpax and his family were stoned to death, and Alexander was greeted warmly when he entered Ephesus in triumph. When Alexander saw that the temple of Artemis was not yet finished, he proposed to finance it and have his name inscribed on the front. But the inhabitants of Ephesus demurred, claiming that it was not fitting for one god to build a temple to another. After Alexander's death in 323 BC, Ephesus in 290 BC came under the rule of one of Alexander's generals, Lysimachus.

As the river Cayster (Grk. name Κάϋστρος) silted up the old harbour, the resulting marshes caused malaria and many deaths among the inhabitants. Lysimachus forced the people to move from the ancient settlement around the temple of Artemis to the present site two kilometres () away, when as a last resort the king flooded the old city by blocking the sewers. The new settlement was officially called "Arsinoea" ( or Ἀρσινοΐα) after the king's second wife, Arsinoe II of Egypt. After Lysimachus had destroyed the nearby cities of Lebedos and Colophon in 292 BC, he relocated their inhabitants to the new city.

Ephesus revolted after the treacherous death of Agathocles, giving the Hellenistic king of Syria and Mesopotamia Seleucus I Nicator an opportunity for removing and killing Lysimachus, his last rival, at the Battle of Corupedium in 281 BC. After the death of Lysimachus the town again was named Ephesus.

Thus Ephesus became part of the Seleucid Empire. After the murder of king Antiochus II Theos and his Egyptian wife, pharaoh Ptolemy III invaded the Seleucid Empire and the Egyptian fleet swept the coast of Asia Minor. Ephesus came under Egyptian rule between 263 and 197 BC.

The Seleucid king Antiochus III the Great tried to regain the Greek cities of Asia Minor and recaptured Ephesus in 196 BC but he then came into conflict with Rome. After a series of battles, he was defeated by Scipio Asiaticus at the Battle of Magnesia in 190 BC. As a result of the subsequent Treaty of Apamea, Ephesus came under the rule of Eumenes II, the Attalid king of Pergamon, (ruled 197–159 BC). When his grandson Attalus III died in 133 BC without male children of his own, he left his kingdom to the Roman Republic, on condition that the city of Pergamon is kept free and autonomous.

 

Ephesus, as part of the kingdom of Pergamon, became a subject of the Roman Republic in 129BC after the revolt of Eumenes III was suppressed.

The city felt Roman influence at once; taxes rose considerably, and the treasures of the city were systematically plundered. Hence in 88 BC Ephesus welcomed Archelaus, a general of Mithridates the Great, king of Pontus, when he conquered Asia (the Roman name for western Asia Minor). From Ephesus Mithridates ordered every Roman citizen in the province to be killed which led to the Asiatic Vespers, the slaughter of 80,000 Roman citizens in Asia, or any person who spoke with a Latin accent. Many had lived in Ephesus, and statues and monument of Roman citizens in Ephesus were also destroyed. But when they saw how badly the people of Chios had been treated by Zenobius, a general of Mithridates, they refused entry to his army. Zenobius was invited into the city to visit Philopoemen, the father of Monime, the favourite wife of Mithridates, and the overseer of Ephesus. As the people expected nothing good of him, they threw him into prison and murdered him. Mithridates took revenge and inflicted terrible punishments. However, the Greek cities were given freedom and several substantial rights. Ephesus became, for a short time, self-governing. When Mithridates was defeated in the First Mithridatic War by the Roman consul Lucius Cornelius Sulla, Ephesus came back under Roman rule in 86 BC. Sulla imposed a huge indemnity, along with five years of back taxes, which left Asian cities heavily in debt for a long time to come.

King Ptolemy XII Auletes of Egypt retired to Ephesus in 57 BC, passing his time in the sanctuary of the temple of Artemis when he failed to get restoration of his throne from the Roman senate.

Mark Antony was welcomed by Ephesus for periods when he was proconsul and in 33 BC with Cleopatra when he gathered his fleet of 800 ships before the battle of Actium with Octavius.

When Augustus became emperor in 27 BC, the most important change was when he made Ephesus the capital of proconsular Asia (which covered western Asia Minor) instead of Pergamum. Ephesus then entered an era of prosperity, becoming both the seat of the governor and a major centre of commerce. According to Strabo, it was second in importance and size only to Rome.

The city and temple were destroyed by the Goths in 263 AD. This marked the decline of the city's splendour. However emperor Constantine the Great rebuilt much of the city and erected new public baths.

Until recently the population of Ephesus in Roman times was estimated to number up to 225,000 people. More recent scholarship regards these estimates as unrealistic. Such a large estimate would require population densities only possible in modern times, or extensive settlement outside the city walls. This would have been impossible at Ephesus because of the mountain ranges, coastline and quarries which surrounded the city.
The wall of Lysimachus has been estimated to enclose an area of . Not all of this area was inhabited due to public buildings and spaces in the centre and the steep slope of the Bülbül Dağı mountain, which was enclosed by the wall. Jerome Murphy-O'Connor uses an estimate of for the inhabited land. Using an average population density of 400 to 500 per hectare, he calculates that Ephesus would have had a population between 138,000 and 172,500, with a preference for the higher figure. J. W. Hanson estimates the inhabited space to be smaller at . He argues that population densities of 150 or 250 people per hectare are more realistic, which gives a range of 33,600 to 56,000 inhabitants. Even with these much lower population estimates, Ephesus was one of the largest cities of Roman Asia Minor, ranking it as the largest city after Sardis and Alexandria Troas.

Ephesus remained the most important city of the Byzantine Empire in Asia after Constantinople in the 5th and 6th centuries. Emperor Flavius Arcadius raised the level of the street between the theatre and the harbour. The basilica of St. John was built during the reign of emperor Justinian I in the 6th century.

The city was partially destroyed by an earthquake in 614 AD.

The importance of the city as a commercial centre declined as the harbour was slowly silted up by the river (today, Küçük Menderes) despite repeated dredging during the city's history. (Today, the harbour is 5 kilometres inland). The loss of its harbour caused Ephesus to lose its access to the Aegean Sea, which was important for trade. People started leaving the lowland of the city for the surrounding hills. The ruins of the temples were used as building blocks for new homes. Marble sculptures were ground to powder to make lime for plaster.

Sackings by the Arabs first in the year 654–655 by caliph Muawiyah I, and later in 700 and 716 hastened the decline further.

When the Seljuk Turks conquered Ephesus in 1090, it was a small village. The Byzantines resumed control in 1097 and changed the name of the town to Hagios Theologos. They kept control of the region until 1308. Crusaders passing through were surprised that there was only a small village, called Ayasalouk, where they had expected a bustling city with a large seaport. Even the temple of Artemis was completely forgotten by the local population. The Crusaders of the Second Crusade fought the Seljuks just outside the town in December 1147.

The town surrendered, on 24 October 1304, to Sasa Bey, a Turkish warlord of the Menteşoğulları principality. Nevertheless, contrary to the terms of the surrender the Turks pillaged the church of Saint John and deported most of the local population to Thyrea, Greece when a revolt seemed probable. During these events many of the remaining inhabitants were massacred.

Shortly afterwards, Ephesus was ceded to the Aydinid principality that stationed a powerful navy in the harbour of Ayasuluğ (the present-day Selçuk, next to Ephesus). Ayasoluk became an important harbour, from which the navy organised raids to the surrounding regions.

The town knew again a short period of prosperity during the 14th century under these new Seljuk rulers. They added important architectural works such as the İsa Bey Mosque, caravansaries and Turkish bathhouses (hamam).

Ephesians were incorporated as vassals into the Ottoman Empire for the first time in 1390. The Central Asian warlord Tamerlane defeated the Ottomans in Anatolia in 1402, and the Ottoman sultan Bayezid I died in captivity. The region was restored to the Anatolian beyliks. After a period of unrest, the region was again incorporated into the Ottoman Empire in 1425.

Ephesus was completely abandoned by the 15th century. Nearby Ayasuluğ was renamed Selçuk in 1914.

Ephesus was an important centre for Early Christianity from the AD 50s. From AD 52–54, the apostle Paul lived in Ephesus, working with the congregation and apparently organizing missionary activity into the hinterlands. Initially, according to the Acts of the Apostles, Paul attended the Jewish synagogue in Ephesus, but after three months he became frustrated with the stubbornness or hardness of heart of some of the Jews, and moved his base to the school of Tyrannus (). The Jamieson-Fausset-Brown Bible Commentary reminds readers that the unbelief of "some" () implies that "others, probably a large number, believed" and therefore there must have been a community of Jewish Christians in Ephesus. Paul introduced about twelve men to the 'baptism with the Holy Spirit' who had previously only experienced the baptism of John the Baptist (), and later became embroiled in a dispute with some artisans whose livelihood depended on selling statuettes of Artemis () in the Temple of Artemis (). Between 53 and 57 AD Paul wrote the letter 1 Corinthians from Ephesus (possibly from the 'Paul tower' near the harbour, where he was imprisoned for a short time). Later, Paul wrote the Epistle to the Ephesians while he was in prison in Rome (around 62 AD).

Roman Asia was associated with John, one of the chief apostles, and the Gospel of John might have been written in Ephesus, "c" 90–100. Ephesus was one of the seven cities addressed in the Book of Revelation, indicating that the church at Ephesus was strong.

Two decades later, the church at Ephesus was still important enough to be addressed by a letter written by Bishop Ignatius of Antioch to the Ephesians in the early 2nd century AD, that begins with, "Ignatius, who is also called Theophorus, to the Church which is at Ephesus, in Asia, deservedly most happy, being blessed in the greatness and fullness of God the Father, and predestinated before the beginning of time, that it should be always for an enduring and unchangeable glory" ("Letter to the Ephesians"). The church at Ephesus had given their support for Ignatius, who was taken to Rome for execution.
A legend, which was first mentioned by Epiphanius of Salamis in the 4th century AD, purported that Mary may have spent the last years of her life in Ephesus. The Ephesians derived the argument from John's presence in the city, and Jesus’ instructions to John to take care of Mary after his death. Epiphanius, however, was keen to point out that, while the Bible says John was leaving for Asia, it does not say specifically that Mary went with him. He later stated that she was buried in Jerusalem. Since the 19th century, The House of the Virgin Mary, about from Selçuk, has been considered to have been the last home of Mary, mother of Jesus in the Roman Catholic tradition, based on the visions of Sister Anne Catherine Emmerich. It is a popular place of Catholic pilgrimage which has been visited by three recent popes.

The Church of Mary near the harbour of Ephesus was the setting for the Third Ecumenical Council in 431, which resulted in the condemnation of Nestorius. A Second Council of Ephesus was held in 449, but its controversial acts were never approved by the Catholics. It came to be called the Robber Council of Ephesus or Robber Synod of Latrocinium by its opponents.

Ephesus is one of the largest Roman archaeological sites in the eastern Mediterranean. The visible ruins still give some idea of the city's original splendour, and the names associated with the ruins are evocative of its former life. The theatre dominates the view down Harbour Street, which leads to the silted-up harbour.

The Temple of Artemis, one of the Seven Wonders of the Ancient World, once stood 418' by 239' with over 100 marble pillars each 56' high. The temple earned the city the title "Servant of the Goddess". Pliny tells us that the magnificent structure took 120 years to build but is now represented only by one inconspicuous column, revealed during an archaeological excavation by the British Museum in the 1870s. Some fragments of the frieze (which are insufficient to suggest the form of the original) and other small finds were removed – some to London and some to the İstanbul Archaeology Museums.

The Library of Celsus, the façade of which has been carefully reconstructed from original pieces, was originally built c. 125 AD in memory of Tiberius Julius Celsus Polemaeanus, an Ancient Greek who served as governor of Roman Asia (105–107) in the Roman Empire. Celsus paid for the construction of the library with his own personal wealth and is buried in a sarcophagus beneath it. The library was mostly built by his son Gaius Julius Aquila and once held nearly 12,000 scrolls. Designed with an exaggerated entrance — so as to enhance its perceived size, speculate many historians — the building faces east so that the reading rooms could make best use of the morning light.

At an estimated 25,000 seating capacity, the theatre is believed to be the largest in the ancient world. This open-air theatre was used initially for drama, but during later Roman times gladiatorial combats were also held on its stage; the first archaeological evidence of a gladiator graveyard was found in May 2007.

There were two agoras, one for commercial and one for state business.

Ephesus also had several major bath complexes, built at various times while the city was under Roman rule.

The city had one of the most advanced aqueduct systems in the ancient world, with at least six aqueducts of various sizes supplying different areas of the city. They fed a number of water mills, one of which has been identified as a sawmill for marble.
The Odeon was a small roofed theatre constructed by Publius Vedius Antoninus and his wife around 150 AD. It was a small salon for plays and concerts, seating about 1,500 people. There were 22 stairs in the theatre. The upper part of the theatre was decorated with red granite pillars in the Corinthian style. The entrances were at both sides of the stage and reached by a few steps.

The Temple of Hadrian dates from the 2nd century but underwent repairs in the 4th century and has been reerected from the surviving architectural fragments. The reliefs in the upper sections are casts, the originals now being exhibited in the Ephesus Archaeological Museum. A number of figures are depicted in the reliefs, including the emperor Theodosius I with his wife and eldest son. The temple was depicted on the reverse of the Turkish 20 million lira banknote of 2001–2005 and of the 20 new lira banknote of 2005–2009.

The Temple of the Sebastoi (sometimes called the Temple of Domitian), dedicated to the Flavian dynasty, was one of the largest temples in the city. It was erected on a pseudodipteral plan with 8 × 13 columns. The temple and its statue are some of the few remains connected with Domitian.

The Tomb/Fountain of Pollio was erected in 97 AD in honour of C. Sextilius Pollio, who constructed the Marnas aqueduct, by Offilius Proculus. It has a concave façade.

A part of the site, Basilica of St. John, was built in the 6th century AD, under emperor Justinian I, over the supposed site of the apostle's tomb. It is now surrounded by Selçuk.

Ephesus is believed to be the city of the Seven Sleepers. The story of the Seven Sleepers, who are considered saints by Catholics and Orthodox Christians and whose story is also mentioned in the Qur'an, tells that they were persecuted because of their monotheistic belief in God and that they slept in a cave near Ephesus for centuries.

The history of archaeological research in Ephesus stretches back to 1863, when British architect John Turtle Wood, sponsored by the British Museum, began to search for the Artemision. In 1869 he discovered the pavement of the temple, but since further expected discoveries were not made the excavations stopped in 1874. In 1895 German archaeologist Otto Benndorf, financed by a 10,000 guilder donation made by Austrian Karl Mautner Ritter von Markhof, resumed excavations. In 1898 Benndorf founded the Austrian Archaeological Institute, which plays a leading role in Ephesus today.

Finds from the site are exhibited notably in the Ephesos Museum in Vienna, the Ephesus Archaeological Museum in Selçuk and in the British Museum.






</doc>
<doc id="9845" url="https://en.wikipedia.org/wiki?curid=9845" title="JavaScript">
JavaScript

JavaScript (), often abbreviated as JS, is a high-level, interpreted programming language. It is a language which is also characterized as dynamic, weakly typed, prototype-based and multi-paradigm. 

Alongside HTML and CSS, JavaScript is one of the three core technologies of the World Wide Web. It is used to make dynamic webpages interactive and provide online programs, including video games. The majority of websites employ it, and all modern web browsers support it without the need for plug-ins by means of a built-in JavaScript engine. Each of the many JavaScript engines represent a different implementation of JavaScript, all based on the ECMAScript specification, with some engines not supporting the spec fully, and with many engines supporting additional features beyond ECMA. 

As a multi-paradigm language, JavaScript supports event-driven, functional, and imperative (including object-oriented and prototype-based) programming styles. It has an API for working with text, arrays, dates, regular expressions, and basic manipulation of the DOM, but the language itself does not include any I/O, such as networking, storage, or graphics facilities, relying for these upon the host environment in which it is embedded.

Initially only implemented client-side in web browsers, JavaScript engines are now embedded in many other types of host software, including server-side in web servers and databases, and in non-web programs such as word processors and PDF software, and in runtime environments that make JavaScript available for writing mobile and desktop applications, including desktop widgets.

Although there are strong outward similarities between JavaScript and Java, including language name, syntax, and respective standard libraries, the two languages are distinct and differ greatly in design; JavaScript was influenced by programming languages such as Self and Scheme.

In 1993, the National Center for Supercomputing Applications (NCSA), a unit of the University of Illinois at Urbana-Champaign, released NCSA Mosaic, the first popular graphical Web browser, which played an important part in expanding the growth of the nascent World Wide Web. In 1994, a company called Mosaic Communications was founded in Mountain View, California and employed many of the original NCSA Mosaic authors to create Mosaic Netscape. However, it intentionally shared no code with NCSA Mosaic. The internal codename for the company's browser was Mozilla, which stood for "Mosaic killer", as the company's goal was to displace NCSA Mosaic as the world's number one web browser. The first version of the Web browser, Mosaic Netscape 0.9, was released in late 1994. Within four months it had already taken three-quarters of the browser market and became the main browser for the Internet in the 1990s. To avoid trademark ownership problems with the NCSA, the browser was subsequently renamed Netscape Navigator in the same year, and the company took the name Netscape Communications. Netscape Communications realized that the Web needed to become more dynamic. Marc Andreessen, the founder of the company believed that HTML needed a "glue language" that was easy to use by Web designers and part-time programmers to assemble components such as images and plugins, where the code could be written directly in the Web page markup. 

In 1995, Netscape Communications recruited Brendan Eich with the goal of embedding the Scheme programming language into its Netscape Navigator. Before he could get started, Netscape Communications collaborated with Sun Microsystems to include in Netscape Navigator Sun's more static programming language Java, in order to compete with Microsoft for user adoption of Web technologies and platforms. Netscape Communications then decided that the scripting language they wanted to create would complement Java and should have a similar syntax, which excluded adopting other languages such as Perl, Python, TCL, or Scheme. To defend the idea of JavaScript against competing proposals, the company needed a prototype. Eich wrote one in 10 days, in May 1995.

Although it was developed under the name Mocha, the language was officially called LiveScript when it first shipped in beta releases of Netscape Navigator 2.0 in September 1995, but it was renamed JavaScript when it was deployed in the Netscape Navigator 2.0 beta 3 in December. The final choice of name caused confusion, giving the impression that the language was a spin-off of the Java programming language, and the choice has been characterized as a marketing ploy by Netscape to give JavaScript the cachet of what was then the hot new Web programming language.

There is a common misconception that JavaScript was influenced by an earlier Web page scripting language developed by Nombas named Cmm (not to be confused with the later C-- created in 1997). Brendan Eich, however, had never heard of Cmm before he created LiveScript. Nombas did pitch their embedded Web page scripting to Netscape, though Web page scripting was not a new concept, as shown by the ViolaWWW Web browser. Nombas later switched to offering JavaScript instead of Cmm in their ScriptEase product and was part of the TC39 group that standardized ECMAScript.

In December 1995, soon after releasing JavaScript for browsers, Netscape introduced an implementation of the language for server-side scripting with Netscape Enterprise Server.

Since 1996, the IIS web-server has supported Microsoft's implementation of server-side Javascript -- JScript -- in ASP and .NET pages. 

Since the mid-2000s, additional server-side JavaScript implementations have been introduced, such as Node.js in 2009.

Microsoft script technologies including VBScript and JScript were released in 1996. JScript, a reverse-engineered implementation of Netscape's JavaScript, was part of Internet Explorer 3. JScript was also available for server-side scripting in Internet Information Server. Internet Explorer 3 also included Microsoft's first support for CSS and various extensions to HTML, but in each case the implementation was noticeably different to that found in Netscape Navigator at the time. These differences made it difficult for designers and programmers to make a single website work well in both browsers, leading to the use of "best viewed in Netscape" and "best viewed in Internet Explorer" logos that characterized these early years of the browser wars. JavaScript began to acquire a reputation for being one of the roadblocks to a cross-platform and standards-driven Web. Some developers took on the difficult task of trying to make their sites work in both major browsers, but many could not afford the time. With the release of Internet Explorer 4, Microsoft introduced the concept of Dynamic HTML, but the differences in language implementations and the different and proprietary Document Object Models remained and were obstacles to widespread take-up of JavaScript on the Web.

In November 1996, Netscape submitted JavaScript to Ecma International to carve out a standard specification, which other browser vendors could then implement based on the work done at Netscape. This led to the official release of the language specification ECMAScript published in the first edition of the ECMA-262 standard in June 1997, with JavaScript being the most well known of the implementations. ActionScript and JScript are other well-known implementations of ECMAScript.

The standards process continued in cycles, with the release of ECMAScript 2 in June 1998, which brings some modifications to conform to the ISO/IEC 16262 international standard. The release of ECMAScript 3 followed in December 1999, which is the baseline for modern day JavaScript. The original ECMAScript 4 work led by Waldemar Horwat (then at Netscape, now at Google) started in 2000 and at first, Microsoft seemed to participate and even implemented some of the proposals in their JScript .NET language.

Over time it was clear though that Microsoft had no intention of cooperating or implementing proper JavaScript in Internet Explorer, even though they had no competing proposal and they had a partial (and diverged at this point) implementation on the .NET server side. So by 2003, the original ECMAScript 4 work was mothballed.

The next major event was in 2005, with two major happenings in JavaScript's history. First, Brendan Eich and Mozilla rejoined Ecma International as a not-for-profit member and work started on ECMAScript for XML (E4X), the ECMA-357 standard, which came from ex-Microsoft employees at BEA Systems (originally acquired as Crossgain). This led to working jointly with Macromedia (later acquired by Adobe Systems), who were implementing E4X in ActionScript 3 (ActionScript 3 was a fork of original ECMAScript 4).

So, along with Macromedia, work restarted on ECMAScript 4 with the goal of standardizing what was in ActionScript 3. To this end, Adobe Systems released the ActionScript Virtual Machine 2, code named Tamarin, as an open source project. But Tamarin and ActionScript 3 were too different from web JavaScript to converge, as was realized by the parties in 2007 and 2008.

Alas, there was still turmoil between the various players; Douglas Crockford—then at Yahoo!—joined forces with Microsoft in 2007 to oppose ECMAScript 4, which led to the ECMAScript 3.1 effort. The development of ECMAScript 4 was never completed, but that work influenced subsequent versions.

While all of this was happening, the open source and developer communities set to work to revolutionize what could be done with JavaScript. This community effort was sparked in 2005 when Jesse James Garrett released a white paper in which he coined the term Ajax, and described a set of technologies, of which JavaScript was the backbone, used to create web applications where data can be loaded in the background, avoiding the need for full page reloads and leading to more dynamic applications. This resulted in a renaissance period of JavaScript usage spearheaded by open source libraries and the communities that formed around them, with libraries such as Prototype, jQuery, Dojo Toolkit, MooTools, and others being released.

In July 2008, the disparate parties on either side came together in Oslo. This led to the eventual agreement in early 2009 to rename ECMAScript 3.1 to ECMAScript 5 and drive the language forward using an agenda that is known as Harmony. ECMAScript 5 was finally released in December 2009.

In June 2011, ECMAScript 5.1 was released to fully align with the third edition of the ISO/IEC 16262 international standard. ECMAScript 2015 was released in June 2015. ECMAScript 2016 was released in June 2016. The current version is ECMAScript 2017, released in June 2017.

JavaScript has become one of the most popular programming languages on the Web. Initially, however, many professional programmers denigrated the language because, among other reasons, its target audience consisted of Web authors and other such "amateurs". The advent of Ajax returned JavaScript to the spotlight and brought more professional programming attention. The result was a proliferation of comprehensive frameworks and libraries, improved JavaScript programming practices, and increased usage of JavaScript outside Web browsers, as seen by the proliferation of Server-side JavaScript platforms.

In January 2009, the CommonJS project was founded with the goal of specifying a common standard library mainly for JavaScript development outside the browser.

With the rise of single-page applications and JavaScript-heavy sites, it is increasingly being used as a compile target for source-to-source compilers from both dynamic languages and static languages.

"JavaScript" is a trademark of Oracle Corporation in the United States. It is used under license for technology invented and implemented by Netscape Communications and current entities such as the Mozilla Foundation.

The terms "Vanilla JavaScript" and "Vanilla JS" refer to JavaScript not extended by any frameworks or additional libraries. Scripts written in Vanilla JS are plain JavaScript code.

The following features are common to all conforming ECMAScript implementations, unless explicitly specified otherwise.

All modern Web browsers support JavaScript with built-in interpreters.

JavaScript supports much of the structured programming syntax from C (e.g., if statements, while loops, switch statements, do while loops, etc.). One partial exception is scoping: JavaScript originally had only function scoping with var. ECMAScript 2015 added keywords let and const for block scoping, meaning JavaScript now has both function and block scoping. Like C, JavaScript makes a distinction between expressions and statements. One syntactic difference from C is automatic semicolon insertion, which allows the semicolons that would normally terminate statements to be omitted.


JavaScript is almost entirely object-based. In JavaScript, an object is an associative array, augmented with a prototype (see below); each string key provides the name for an object property, and there are two syntactical ways to specify such a name: dot notation (obj.x = 10) and bracket notation (obj['x'] = 10). A property may be added, rebound, or deleted at run-time. Most properties of an object (and any property that belongs to an object's prototype inheritance chain) can be enumerated using a for...in loop.

JavaScript has a small number of built-in objects, including and .


A function is first-class; a function is considered to be an object. As such, a function may have properties and methods, such as <samp>.call()</samp> and .bind(). A "nested" function is a function defined within another function. It is created each time the outer function is invoked. In addition, each nested function forms a lexical closure: The lexical scope of the outer function (including any constant, local variable, or argument value) becomes part of the internal state of each inner function object, even after execution of the outer function concludes. JavaScript also supports anonymous functions.

JavaScript supports implicit and explicit delegation.






JavaScript is officially managed by Mozilla Foundation, and new language features are added periodically. However, only some JavaScript engines support these new features:

Variables in JavaScript can be defined using the var keyword:
var x; // defines the variable x and assigns to it the special value "undefined" (not to be confused with an undefined value)
var y = 2; // defines the variable y and assigns to it the value 2
var z = "Hello, World!"; // defines the variable z and assigns to it a string containing "Hello, World!"
Note the comments in the example above, all of which were preceded with two forward slashes.

There is no built-in I/O functionality in JavaScript; the run-time environment provides that. The ECMAScript specification in edition 5.1 mentions:
… indeed, there are no provisions in this specification for input of external data or output of computed results.
However, most runtime environments have a console object that can be used to print output. Here is a minimalist Hello World program in JavaScript:
console.log("Hello World!");
A simple recursive function:
function factorial(n) {

factorial(3); // returns 6
An anonymous function (or lambda):
function counter() {

var closure = counter();
closure(); // returns 1
closure(); // returns 2
closure(); // returns 3
This example shows that, in JavaScript, function closures capture their non-local variables "by reference".

In JavaScript, objects are created in the same way as functions, this is known as a function object.

Object example:

function Ball(r) {
myBall = new Ball(5); //creates a new instance of the ball object with radius 5
myBall.show(); //this instance of the ball object has the show function performed on it
Variadic function demonstration (arguments is a special variable):
function sum() {
sum(1, 2); // returns 3
sum(1, 2, 3); // returns 6
Immediately-invoked function expressions are often used to create modules, as before ECMAScript 2015 there was no built-in construct in the language. Modules allow gathering properties and methods in a namespace and making some of them private:
var counter = (function () {

})(); // module

counter.get(); // shows 0
counter.set(6);
counter.increment(); // shows 7
counter.increment(); // shows 8
This sample code displays various JavaScript features.

/* Finds the lowest common multiple (LCM) of two numbers */
function LCMCalculator(x, y) { // constructor function

// The prototype of object instances created by a constructor is
// that constructor's "prototype" property.
LCMCalculator.prototype = { // object literal
};

// Define generic output function; this implementation only works for Web browsers
function output(x) {

// Note: Array's map() and forEach() are defined in JavaScript 1.6.
// They are used here to demonstrate JavaScript's inherent functional nature.
].map(function(pair) { // array literal + mapping function

function printResult(obj) {

The following output should be displayed in the browser window.

LCMCalculator: a = 28, b = 56, gcd = 28, lcm = 56
LCMCalculator: a = 21, b = 56, gcd = 7, lcm = 168
LCMCalculator: a = 25, b = 55, gcd = 5, lcm = 275
LCMCalculator: a = 22, b = 58, gcd = 2, lcm = 638
As of May 2017 94.5% of 10 million most popular web pages used JavaScript. The most common use of JavaScript is to add client-side behavior to HTML pages, also known as Dynamic HTML (DHTML). Scripts are embedded in or included from HTML pages and interact with the Document Object Model (DOM) of the page. Some simple examples of this usage are:


Because JavaScript code can run locally in a user's browser (rather than on a remote server), the browser can respond to user actions quickly, making an application more responsive. Furthermore, JavaScript code can detect user actions that HTML alone cannot, such as individual keystrokes. Applications such as Gmail take advantage of this: much of the user-interface logic is written in JavaScript, and JavaScript dispatches requests for information (such as the content of an e-mail message) to the server. The wider trend of Ajax programming similarly exploits this strength.

A JavaScript engine (also known as JavaScript interpreter or JavaScript implementation) is an interpreter that interprets JavaScript source code and executes the script accordingly. The first JavaScript engine was created by Brendan Eich at Netscape, for the Netscape Navigator Web browser. The engine, code-named SpiderMonkey, is implemented in C. It has since been updated (in JavaScript 1.5) to conform to ECMAScript 3. The Rhino engine, created primarily by Norris Boyd (formerly at Netscape, now at Google) is a JavaScript implementation in Java. Rhino, like SpiderMonkey, is ECMAScript 3 compliant.

A Web browser is by far the most common host environment for JavaScript. Web browsers typically create "host objects" to represent the DOM in JavaScript. The Web server is another common host environment. A JavaScript Web server would typically expose host objects representing HTTP request and response objects, which a JavaScript program could then interrogate and manipulate to dynamically generate Web pages.

Because JavaScript is the only language that the most popular browsers share support for, it has become a target language for many frameworks in other languages, even though JavaScript was never intended to be such a language. Despite the performance limitations inherent to its dynamic nature, the increasing speed of JavaScript engines has made the language a surprisingly feasible compilation target.

Below is a minimal example of a standards-conforming Web page containing JavaScript (using HTML 5 syntax) and the DOM:
<!DOCTYPE html>
<html>
</html>
Because JavaScript runs in widely varying environments, an important part of testing and debugging is to test and verify that the JavaScript works across multiple browsers.

The DOM interfaces for manipulating Web pages are not part of the ECMAScript standard, or of JavaScript itself. Officially, the DOM interfaces are defined by a separate standardization effort by the W3C; in practice, browser implementations differ from the standards and from each other, and not all browsers execute JavaScript.

To deal with these differences, JavaScript authors can attempt to write standards-compliant code that will also be executed correctly by most browsers; failing that, they can write code that checks for the presence of certain browser features and behaves differently if they are not available. In some cases, two browsers may both implement a feature but with different behavior, and authors may find it practical to detect what browser is running and change their script's behavior to match. Programmers may also use libraries or toolkits that take browser differences into account.

Furthermore, scripts may not work for some users. For example, a user may:


To support these users, Web authors can try to create pages that degrade gracefully on user agents (browsers) that do not support the page's JavaScript. In particular, the page should remain usable albeit without the extra features that the JavaScript would have added. Some sites use the HTML <noscript> tag, which contains alt content if JS is disabled. An alternative approach that many find preferable is to first author content using basic technologies that work in all browsers, then enhance the content for users that have JavaScript enabled. This is known as progressive enhancement.

JavaScript and the DOM provide the potential for malicious authors to deliver scripts to run on a client computer via the Web. Browser authors minimize this risk using two restrictions. First, scripts run in a sandbox in which they can only perform Web-related actions, not general-purpose programming tasks like creating files. Second, scripts are constrained by the same-origin policy: scripts from one Web site do not have access to information such as usernames, passwords, or cookies sent to another site. Most JavaScript-related security bugs are breaches of either the same origin policy or the sandbox.

There are subsets of general JavaScript—ADsafe, Secure ECMAScript (SES)—that provide greater levels of security, especially on code created by third parties (such as advertisements). Caja is another project for safe embedding and isolation of third-party JavaScript and HTML.

Content Security Policy is the main intended method of ensuring that only trusted code is executed on a Web page.

A common JavaScript-related security problem is cross-site scripting (XSS), a violation of the same-origin policy. XSS vulnerabilities occur when an attacker is able to cause a target Web site, such as an online banking website, to include a malicious script in the webpage presented to a victim. The script in this example can then access the banking application with the privileges of the victim, potentially disclosing secret information or transferring money without the victim's authorization. A solution to XSS vulnerabilities is to use "HTML escaping" whenever displaying untrusted data.

Some browsers include partial protection against "reflected" XSS attacks, in which the attacker provides a URL including malicious script. However, even users of those browsers are vulnerable to other XSS attacks, such as those where the malicious code is stored in a database. Only correct design of Web applications on the server side can fully prevent XSS.

XSS vulnerabilities can also occur because of implementation mistakes by browser authors.

Another cross-site vulnerability is cross-site request forgery (CSRF). In CSRF, code on an attacker's site tricks the victim's browser into taking actions the user didn't intend at a target site (like transferring money at a bank). It works because, if the target site relies only on cookies to authenticate requests, then requests initiated by code on the attacker's site will carry the same legitimate login credentials as requests initiated by the user. In general, the solution to CSRF is to require an authentication value in a hidden form field, and not only in the cookies, to authenticate any request that might have lasting effects. Checking the HTTP Referrer header can also help.

"JavaScript hijacking" is a type of CSRF attack in which a <nowiki><script></nowiki> tag on an attacker's site exploits a page on the victim's site that returns private information such as JSON or JavaScript. Possible solutions include:


Developers of client-server applications must recognize that untrusted clients may be under the control of attackers. The application author cannot assume that his JavaScript code will run as intended (or at all) because any secret embedded in the code could be extracted by a determined adversary. Some implications are:

Package management systems such as npm and Bower are popular with JavaScript developers. Such systems allow a developer to easily manage their program's dependencies upon other developer's program libraries. Developers trust that the maintainers of the libraries will keep them secure and up to date, but that is not always the case. A vulnerability has emerged because of this blind trust. Relied-upon libraries can have new releases that cause bugs or vulnerabilities to appear in all programs that rely upon the libraries. Inversely, a library can go unpatched with known vulnerabilities out in the wild. In a study done looking over a sample of 133k websites, researchers found 37% of the websites included a library with at-least one known vulnerability. "The median lag between the oldest library version used on each website and the newest available version of that library is 1,177 days in ALEXA, and development of some libraries still in active use ceased years ago." Another possibility is that the maintainer of a library may remove the library entirely. This occurred in March 2016 when Azer Koçulu removed his repository from npm. This caused all tens of thousands of programs and websites depending upon his libraries to break.

JavaScript provides an interface to a wide range of browser capabilities, some of which may have flaws such as buffer overflows. These flaws can allow attackers to write scripts that would run any code they wish on the user's system. This code is not by any means limited to another JavaScript application. For example, a buffer overrun exploit can allow an attacker to gain access to the operating system's API with superuser privileges.

These flaws have affected major browsers including Firefox, Internet Explorer, and Safari.

Plugins, such as video players, Adobe Flash, and the wide range of ActiveX controls enabled by default in Microsoft Internet Explorer, may also have flaws exploitable via JavaScript (such flaws have been exploited in the past).

In Windows Vista, Microsoft has attempted to contain the risks of bugs such as buffer overflows by running the Internet Explorer process with limited privileges. Google Chrome similarly confines its page renderers to their own "sandbox".

Web browsers are capable of running JavaScript outside the sandbox, with the privileges necessary to, for example, create or delete files. Of course, such privileges aren't meant to be granted to code from the Web.

Incorrectly granting privileges to JavaScript from the Web has played a role in vulnerabilities in both Internet Explorer and Firefox. In Windows XP Service Pack 2, Microsoft demoted JScript's privileges in Internet Explorer.

Microsoft Windows allows JavaScript source files on a computer's hard drive to be launched as general-purpose, non-sandboxed programs (see: Windows Script Host). This makes JavaScript (like VBScript) a theoretically viable vector for a Trojan horse, although JavaScript Trojan horses are uncommon in practice.

In 2015, a JavaScript-based proof-of-concept implementation of a rowhammer attack was described in a paper by security researchers.

In 2017, a JavaScript-based attack via browser was demonstrated that could bypass ASLR. It's called "ASLR⊕Cache" or AnC.

In addition to Web browsers and servers, JavaScript interpreters are embedded in a number of tools. Each of these applications provides its own object model that provides access to the host environment. The core JavaScript language remains mostly the same in each application.




Within JavaScript, access to a debugger becomes invaluable when developing large, non-trivial programs. Because there can be implementation differences between the various browsers (particularly within the DOM), it is useful to have access to a debugger for each of the browsers that a Web application targets.

Script debuggers are integrated within Internet Explorer, Firefox, Safari, Google Chrome, Opera and Node.js.

In addition to the native Internet Explorer Developer Tools, three debuggers are available for Internet Explorer: Microsoft Visual Studio is the richest of the three, closely followed by Microsoft Script Editor (a component of Microsoft Office), and finally the free Microsoft Script Debugger that is far more basic than the other two. The free Microsoft Visual Web Developer Express provides a limited version of the JavaScript debugging functionality in Microsoft Visual Studio. Internet Explorer has included developer tools since version 8.

In comparison to Internet Explorer, Firefox has a more comprehensive set of developer tools, which include a debugger as well. Old versions of Firefox without these tools used a Firefox addon called Firebug, or the older Venkman debugger. Also, WebKit's Web Inspector includes a JavaScript debugger, which is used in Safari. A modified version called Blink DevTools is used in Google Chrome. Node.js has Node Inspector, an interactive debugger that integrates with the Blink DevTools, available in Google Chrome. Opera includes a set of tools called Dragonfly.

In addition to the native computer software, there are online JavaScript IDEs, debugging aids that are themselves written in JavaScript and built to run on the Web. An example is the program JSLint, developed by Douglas Crockford who has written extensively on the language. JSLint scans JavaScript code for conformance to a set of standards and guidelines. Many libraries for JavaScript, such as three.js, provide links to demonstration code that can be edited by users. They are also used as a pedagogical tool by institutions such as Khan Academy to allow students to experience writing code in an environment where they can see the output of their programs, without needing any setup beyond a Web browser.

Since JavaScript is getting more important for web development (frontend overtakes many aspects which were done in backend before), there is also more consideration done about performance. Especially mobile devices could have problems with rendering and processing unoptimized complex logic.

A library for doing benchmarks is benchmark.js. A benchmarking library that supports high-resolution timers and returns statistically significant results.

Another tool is jsben.ch. An online JavaScript benchmarking tool, where code snippets can be tested against each other.

JavaScript was initially developed in 1996 for use in the Netscape Navigator Web browser. In the same year Microsoft released an implementation for Internet Explorer. This implementation was called JScript due to trademark issues. In 1997, the first standardized version of the language was released under the name ECMAScript in the first edition of the ECMA-252 standard. The explicit versioning and opt-in of language features was Mozilla-specific and has been removed. Firefox 4 was the last version which referred to a JavaScript version (1.8.5). With new editions of the ECMA-262 standard, JavaScript language features are now often mentioned with their initial definition in the ECMA-262 editions.

The following table is based on information from multiple sources.

JSON, or JavaScript Object Notation, is a general-purpose data interchange format that is defined as a subset of JavaScript's object literal syntax. Like much of JavaScript (regexps and anonymous functions as 1st class elements, closures, flexible classes, 'use strict'), JSON, except for replacing Perl's key-value operator '=>' by an RFC 822 inspired ':', is syntactically pure Perl.

jQuery is a popular JavaScript library designed to simplify DOM-oriented client-side HTML scripting along with offering cross-browser compatibility because various browsers respond differently to certain vanilla JavaScript code.

Underscore.js is a utility JavaScript library for data manipulation that is used in both client-side and server-side network applications.

Angular and AngularJS are web application frameworks to use for developing single-page applications and also cross-platform mobile apps.

React (JavaScript library) is an open-source JavaScript library providing a views that is rendered using components specified as custom HTML tags.

Mozilla browsers currently support LiveConnect, a feature that allows JavaScript and Java to intercommunicate on the Web. However, Mozilla-specific support for LiveConnect was scheduled to be phased out in the future in favor of passing on the LiveConnect handling via NPAPI to the Java 1.6+ plug-in (not yet supported on the Mac ). Most browser inspection tools, such as Firebug in Firefox, include JavaScript interpreters that can act on the visible page's DOM.

asm.js is a subset of JavaScript that can be run in any JavaScript engine or run faster in an ahead-of-time (AOT) compiling engine.

JSFuck is an esoteric programming language. Programs are written using only six different characters, but are still valid JavaScript code.

p5.js is an object oriented JavaScript library designed for artists and designers. It is based on the ideas of the Processing project but is for the web.

jsben.ch is an online JavaScript benchmarking tool, where different code snippets can be tested against each other.

CRISP: A Strategy guiding Cloud Application Development for Beginners is a strategy proposed by Ayush Sahu to develop optimized and secure JavaScript application to be used in mobiles, PC's and other devices. CRISP (Conversion, Reformat code, Isolate module, Sandbox, Partition) strategy has been proposed for refined conversion of native application to JavaScript for cloud application development. JavaScript is chosen as medium for writing application because it is mostly used language among developers and provides rich API (Application Programming Interface) for writing applications.

As JavaScript is the most widely supported client-side language that can run within a Web browser, it has become an intermediate language for other languages to target. This has included both newly created languages and ports of existing languages. Some of these include:
As JavaScript has unusual limitations – such as no explicit integer type, only double-precision binary floating point – languages that compile to JavaScript and do not take care to use the integer-converting shift and bitwise logical operators may have slightly different behavior than in other environments.

A common misconception is that JavaScript is similar or closely related to Java. It is true that both have a C-like syntax (the C language being their most immediate common ancestor language). They also are both typically sandboxed (when used inside a browser), and JavaScript was designed with Java's syntax and standard library in mind. In particular, all Java keywords were reserved in original JavaScript, JavaScript's standard library follows Java's naming conventions, and JavaScript's and objects are based on classes from Java 1.0, but the similarities end there.

Java and JavaScript both first appeared in 1995, but Java was developed by James Gosling of Sun Microsystems, and JavaScript by Brendan Eich of Netscape Communications.

The differences between the two languages are more prominent than their similarities. Java has static typing, while JavaScript's typing is dynamic. Java is loaded from compiled bytecode, while JavaScript is loaded as human-readable source code. Java's objects are class-based, while JavaScript's are prototype-based. Finally, Java did not support functional programming until Java 8, while JavaScript has done so from the beginning, being influenced by Scheme.

Starting in 2017, web browsers began supporting WebAssembly, a technology standardized by the W3C. The WebAssembly standard specifies a binary format, which can be produced by a compiler toolchain such as LLVM, to execute in the browser at near native speed. WebAssembly allows programming languages such as C, C++, C# and Java to be used as well as JavaScript to author client-side code for the World Wide Web.




</doc>
<doc id="9846" url="https://en.wikipedia.org/wiki?curid=9846" title="Elbing (disambiguation)">
Elbing (disambiguation)

Elbing is the German name of Elbląg, a city in northern Poland which until 1945 was a German city in the province of East Prussia.

Elbing may also refer to:





</doc>
<doc id="9855" url="https://en.wikipedia.org/wiki?curid=9855" title="Exile">
Exile

To be in exile means to be away from one's home (i.e. city, state, or country), while either being explicitly refused permission to return or being threatened with imprisonment or death upon return. It can be a form of punishment and solitude.
It is common to distinguish between "internal exile", i.e., forced resettlement within the country of residence, and "external exile", which is deportation outside the country of residence. Although most commonly used to describe an individual situation, the term is also used for groups (especially ethnic or national groups), or for an entire government. Terms such as "diaspora" and "refugee" describe group exile, both voluntary and forced, and "government in exile" describes a government of a country that has been forced to relocate and argue its legitimacy from outside that country.
Exile can also be a self-imposed departure from one's homeland. Self-exile is often depicted as a form of protest by the person who claims it, to avoid persecution or legal matters (such as tax or criminal allegations), an act of shame or repentance, or isolating oneself to be able to devote time to a particular pursuit.
Article 9 of the Universal Declaration of Human Rights states that "No one shall be subjected to arbitrary arrest, detention or exile."

In some cases the deposed head of state is allowed to go into exile following a coup or other change of government, allowing a more peaceful transition to take place or to escape justice.

A wealthy citizen who moves to a jurisdiction with lower taxes is termed a "tax exile". Creative people such as authors and musicians who achieve sudden wealth sometimes choose this solution. Examples include the British-Canadian writer Arthur Hailey, who moved to the Bahamas to avoid taxes following the runaway success of his novels "Hotel" and "Airport", and the English rock band the Rolling Stones who, in the spring of 1971, owed more in taxes than they could pay and left Britain before the government could seize their assets. Members of the band all moved to France for a period of time where they recorded music for the album that came to be called "Exile on Main Street", the Main Street of the title referring to the French Riviera. In 2012, Eduardo Saverin, one of the founders of Facebook, made headlines by renouncing his U.S. citizenship before his company's IPO. The dual Brazilian/U.S. citizen's decision to move to Singapore and renounce his citizenship spurred a bill in the U.S. Senate, the Ex-PATRIOT Act, which would have forced such wealthy "tax exiles" to pay a special tax in order to re-enter the United States.

In some cases a person voluntarily lives in exile to avoid legal issues, such as litigation or criminal prosecution. An example of this is Asil Nadir, who fled to the Turkish Republic of Northern Cyprus for 17 years rather than face prosecution in connection with the failed £1.7 bn company Polly Peck in the United Kingdom.

Examples include:

When a large group, or occasionally a whole people or nation is exiled, it can be said that this nation is in exile, or "diaspora". Nations that have been in exile for substantial periods include the Jews, who were deported by Babylonian king Nebuchadnezzar II in 586 BC and again following the destruction of the second Temple in Jerusalem in AD 70. Many Jewish prayers include a yearning to return to Jerusalem and the Jewish homeland.

After the partitions of Poland in the late 18th century, and following the uprisings (like Kościuszko Uprising, November Uprising and January Uprising) against the partitioning powers (Russian Empire, Prussia and Austro-Hungary), many Poles have chosen – or been forced – to go into exile, forming large diasporas (known as Polonia), especially in France and the United States. The entire population of Crimean Tatars (200,000) that remained in their homeland Crimea was exiled on 18 May 1944 to Central Asia as a form of ethnic cleansing and collective punishment on false accusations. At Diego Garcia, between 1967 and 1973 the British Government forcibly removed some 2,000 Chagossian resident islanders to make way for a military base today jointly operated by the US and UK.

Since the Cuban Revolution over one million Cubans have left Cuba. Most of these self-identify as exiles as their motivation for leaving the island is political in nature. It is to be noted that at the time of the Cuban Revolution, Cuba only had a population of 6.5 million, and was not a country that had a history of significant emigration, it being the sixth largest recipient of immigrants in the world as of 1958. Most of the exiles' children also consider themselves to be Cuban exiles. It is to be noted that under Cuban law, children of Cubans born abroad are considered Cuban citizens.

During a foreign occupation or after a coup d'état, a "government in exile" of a such afflicted country may be established abroad. One of the most well-known instances of this is the Polish government-in-exile, a government in exile that commanded Polish armed forces operating outside Poland after German occupation during World War II. Other examples include the Free French Forces government of Charles De Gaulle of the same time, and the Central Tibetan Administration, commonly known as the Tibetan government-in-exile, and headed by the 14th Dalai Lama.

Exile is an early motif in ancient Greek tragedy. In the ancient Greek world, this was seen as a fate worse than death. The motif reaches its peak on the play "Medea", written by Euripides in the fifth century BC, and rooted in the very old oral traditions of Greek mythology. Euripides’ Medea has remained the most frequently performed Greek tragedy through the 20th century.

After Medea was abandoned by Jason and had become a murderer out of revenge, she fled to Athens and married king Aigeus there, and became the stepmother of the hero Theseus. Due to a conflict with him, she must leave the Polis and go away into exile. John William Waterhouse (1849–1917), the English Pre-Raphaelite painter’s famous picture "Jason and Medea" shows a key moment before, when Medea tries to poison Theseus.

In ancient Rome, the Roman Senate had the power to declare the exile to individuals, families or even entire regions. One of the Roman victims was the poet Ovid, who lived during the reign of Augustus. He was forced to leave Rome and move away to the city of Tomis on the Black Sea, now Constanta. There he wrote his famous work "Tristia" (Sorrows) about his bitter feelings in exile.
Another, at least in a temporary exile, was Dante.

The German language writer of novels, Franz Kafka, called "the Dante of the twentieth century" by the poet W. H. Auden, describes the exile of Karl Rossmann in the posthumously published novel "Amerika".

During the period of National Socialism in the first few years after 1933, many Jews, as well as a significant number of German artists and intellectuals fled into exile; for instance, the authors Klaus Mann and Anna Seghers. So Germany’s own exile literature emerged and received worldwide credit. Klaus Mann finished his novel "" ("The Volcano. A Novel Among Emigrants") in 1939 describing the German exile scene, "to bring the rich, scattered and murky experience of exile into epic form", as he wrote in his literary balance sheet. At the same place and in the same year, Anna Seghers published her famous novel "Das siebte Kreuz" ("The Seventh Cross", published in the United States in 1942).

Important exile literatures in recent years include that of the Caribbean, many of whose artists emigrated to Europe or the United States for political or economic reasons. These writers include Nobel Prize winners V. S. Naipaul and Derek Walcott as well as the novelists Edwidge Danticat and Sam Selvon.




</doc>
